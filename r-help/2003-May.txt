From mkondrin at hppi.troitsk.ru  Thu May  1 06:46:34 2003
From: mkondrin at hppi.troitsk.ru (M.Kondrin)
Date: Wed, 30 Apr 2003 21:46:34 -0700
Subject: [R] skins
In-Reply-To: <48766.170.210.173.216.1051709808.squirrel@inter14.unsl.edu.ar>
References: <48766.170.210.173.216.1051709808.squirrel@inter14.unsl.edu.ar>
Message-ID: <3EB0A6AA.6060905@hppi.troitsk.ru>

solares at unsl.edu.ar wrote:

>Hello, 
>I wrote a for if exist a tcltk package .... essentially I wanted 
>to give a widget with corner rounded , tkbutton , tkframe, radiobuttons, etc
>and skins for toplevels.
>Any help will be greatly appreciated.... thanks
>
>Ruben Solares
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
>  
>
There is no skins for tk/tcl toolbox. It is not even fault of R but a 
feature of toolbox itself (you may check it on it's web page 
www.scriptics.com or send a message to its developers requesting skin 
support in later realeases of tk/tcl)


From macq at llnl.gov  Thu May  1 00:53:43 2003
From: macq at llnl.gov (Don MacQueen)
Date: Wed, 30 Apr 2003 15:53:43 -0700
Subject: [R-gui] Re: [R] Feedback about SciViews?
In-Reply-To: 
 <Pine.LNX.4.21.0304301716310.22965-100000@dollis-hill.inpharmatica.co.uk>
References: 
 <Pine.LNX.4.21.0304301716310.22965-100000@dollis-hill.inpharmatica.co.uk>
Message-ID: <p05210606bad602c92a85@[128.115.153.6]>

At 5:29 PM +0100 4/30/03, Luke Whitaker wrote:
>On Tue, 29 Apr 2003, Byron Ellis wrote:
>
>>  On Tuesday, April 29, 2003, at 07:13  AM, Duncan Murdoch wrote:
>
>>  > I think the best long term strategy is to have a clean division
>>  > between the user interface aspects of R (which are necessarily
>>  > platform dependent) and the underlying computing engine (which should
>>
>>  Precisely. I would actually say that R is -not- platform independent in
>>  that it expects a certain type of GUI--- a shell process living on
>>  STDIN and STDOUT that talks to an out-of-process Window Server of some
>>  sort. Most of the work done in the Windows GUI is spent faking that
>>  environment to make R think its still running on a X Server somewhere
>>  and similar work was done for the Mac/Carbon port (obviously, Darwin R
>>  can happily use Apple's X server). REventLoop takes some steps as does
>>  the work on embedding, but its still safer to run the "GUI" stuff
>>  out-of-process and even then not foolproof.
>
>At the risk of starting a religous war, isn't java the obvious choice
>for a platform independent GUI ? I know java suffered a lot from
>early over hypeing when it wasn't really ready, but in the last year
>or two I've seen some very impressive platform independent GUI's
>built with java.

Not unless it's a whole lot better than Insightful's initial effort on Solaris.

The GUI itself (i.e., how it operated, what menus were where, etc.) 
was fine, but it was completely useless for anyone sitting at a 
remote host, due to dreadful image quality and poor performance when 
displaying anywhere other than on the console of the machine on which 
SPlus was actually running.

(maybe it was ok displayed on a remote host of the same architecture; 
I don't remember; but neither I nor any of the potential additional 
users was)

-Don

>just my tuppence worth...
>
>Luke
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA


From andy_liaw at merck.com  Thu May  1 02:28:37 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 30 Apr 2003 20:28:37 -0400
Subject: [R-gui] Re: [R] Feedback about SciViews?
Message-ID: <3A822319EB35174CA3714066D590DCD5C4FA8D@usrymx25.merck.com>

> From: Don MacQueen [mailto:macq at llnl.gov]
> 
> At 5:29 PM +0100 4/30/03, Luke Whitaker wrote:
> >
> >At the risk of starting a religous war, isn't java the obvious choice
> >for a platform independent GUI ? I know java suffered a lot from
> >early over hypeing when it wasn't really ready, but in the last year
> >or two I've seen some very impressive platform independent GUI's
> >built with java.
> 
> Not unless it's a whole lot better than Insightful's initial 
> effort on Solaris.
> 
> The GUI itself (i.e., how it operated, what menus were where, etc.) 
> was fine, but it was completely useless for anyone sitting at a 
> remote host, due to dreadful image quality and poor performance when 
> displaying anywhere other than on the console of the machine on which 
> SPlus was actually running.
> 
> (maybe it was ok displayed on a remote host of the same architecture; 
> I don't remember; but neither I nor any of the potential additional 
> users was)

AFAIK the problem is the X server: it gives you a black window if the X
display is 16-bit.  If you can live with 8-bit display, the Java GUI will
work.  It's that way on all Unix (X?) platform.

Andy
 
> -Don
> 
> >just my tuppence worth...
> >
> >Luke
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 
> -- 
> --------------------------------------
> Don MacQueen
> Environmental Protection Department
> Lawrence Livermore National Laboratory
> Livermore, CA, USA
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------
Notice: This e-mail message, together with any attachments, cont... {{dropped}}


From raf1729 at hotmail.com  Thu May  1 02:51:50 2003
From: raf1729 at hotmail.com (R A F)
Date: Thu, 01 May 2003 00:51:50 +0000
Subject: [R] List of lists?  Data frames? (Or other data structures?)
Message-ID: <Law11-F73crenlB5VC400019e12@hotmail.com>

Hi, I'm faced with the following problem and would appreciate some
advice.

I could have a data frame x that looks like this:
         aa          bb
a        1           "A"
b        2           "B"

The advantage of this is that I could access all the individual
components easily.  Also I could access all the rows and columns
easily.

Alternatively, I could have a list of lists that looks like this:

xprime <- list()
xprime$a <- list()
xprime$b <- list()

xprime$a$aa <- 1
xprime$a$bb <- "A"

xprime$b$aa <- 2
xprime$b$bb <- "B"

etc.

If speed is important, would a list of lists be faster than a data
frame? (I know, for example, that scan is supposed to be faster than
read.table, but I don't know if that is related to issues with data
frames.)

My problem with a list of lists, though, is that if I want to access
all the bb subcomponents, a naive method like this one failed:

y <- c( "a", "b" )
xprime[[ y ]]$bb (Does not work)

So to get all the bb subcomponents I seem to need to loop, which may
slow things down (presumably).  But maybe people here know of a way.

Finally what would be the "best" way given the constraint of quick
access to all rows, columns and individual components?

I'd appreciate your thoughts and comments.  Thanks very much.


From rossini at blindglobe.net  Thu May  1 03:14:01 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Wed, 30 Apr 2003 18:14:01 -0700
Subject: [R-gui] Re: [R] Feedback about SciViews?
In-Reply-To: <3A822319EB35174CA3714066D590DCD5C4FA8D@usrymx25.merck.com>
	("Liaw, Andy"'s message of "Wed, 30 Apr 2003 20:28:37 -0400")
References: <3A822319EB35174CA3714066D590DCD5C4FA8D@usrymx25.merck.com>
Message-ID: <87of2njwo6.fsf@jeeves.blindglobe.net>

"Liaw, Andy" <andy_liaw at merck.com> writes:


>> The GUI itself (i.e., how it operated, what menus were where, etc.) 
>> was fine, but it was completely useless for anyone sitting at a 
>> remote host, due to dreadful image quality and poor performance when 
>> displaying anywhere other than on the console of the machine on which 
>> SPlus was actually running.
>
> AFAIK the problem is the X server: it gives you a black window if the X
> display is 16-bit.  If you can live with 8-bit display, the Java GUI will
> work.  It's that way on all Unix (X?) platform.

I thought Java on Linux would do 8 and 24, but not 16?  (or something
truly weird like that).

But that doesn't address performance issues, which still can be pretty
bad.

best,
-tony

-- 
A.J. Rossini rossini at u.washington.edu http://software.biostat.washington.edu/ 
Biostatistics, U Washington and Fred Hutchinson Cancer Research Center

FHCRC:Tu: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email 
UW  : Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX 

CONFIDENTIALITY NOTICE: This e-mail message and any attachments ... {{dropped}}


From rpeng at stat.ucla.edu  Thu May  1 03:25:32 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Wed, 30 Apr 2003 18:25:32 -0700 (PDT)
Subject: [R] List of lists?  Data frames? (Or other data structures?)
In-Reply-To: <Law11-F73crenlB5VC400019e12@hotmail.com>
Message-ID: <Pine.GSO.4.10.10304301821470.2486-100000@quetelet.stat.ucla.edu>

If you're talking about rows and columns, it seems like the appropriate
data structure for you is the data frame.  I think your list of lists
representation might get unwieldy after a while.  I can't really think of
why a data frame would be any slower than a list of lists -- I've never
experienced such behavior.

read.table() may be a little slower than scan() because read.table() reads
in an entire file and then converts each of the columns into an
appropriate data class.  So there is some post-processing going on.  It
doesn't have anything to do with data frames vs. lists.

-roger
_______________________________
UCLA Department of Statistics
http://www.stat.ucla.edu/~rpeng

On Thu, 1 May 2003, R A F wrote:

> Hi, I'm faced with the following problem and would appreciate some
> advice.
> 
> I could have a data frame x that looks like this:
>          aa          bb
> a        1           "A"
> b        2           "B"
> 
> The advantage of this is that I could access all the individual
> components easily.  Also I could access all the rows and columns
> easily.
> 
> Alternatively, I could have a list of lists that looks like this:
> 
> xprime <- list()
> xprime$a <- list()
> xprime$b <- list()
> 
> xprime$a$aa <- 1
> xprime$a$bb <- "A"
> 
> xprime$b$aa <- 2
> xprime$b$bb <- "B"
> 
> etc.
> 
> If speed is important, would a list of lists be faster than a data
> frame? (I know, for example, that scan is supposed to be faster than
> read.table, but I don't know if that is related to issues with data
> frames.)
> 
> My problem with a list of lists, though, is that if I want to access
> all the bb subcomponents, a naive method like this one failed:
> 
> y <- c( "a", "b" )
> xprime[[ y ]]$bb (Does not work)
> 
> So to get all the bb subcomponents I seem to need to loop, which may
> slow things down (presumably).  But maybe people here know of a way.
> 
> Finally what would be the "best" way given the constraint of quick
> access to all rows, columns and individual components?
> 
> I'd appreciate your thoughts and comments.  Thanks very much.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From rsadler at agric.uwa.edu.au  Thu May  1 05:07:58 2003
From: rsadler at agric.uwa.edu.au (rohan sadler)
Date: Thu, 01 May 2003 11:07:58 +0800
Subject: [R] mpl in spatstat
References: <2A5E377E.09E83E90.0D1322AF@netscape.net>
Message-ID: <3EB08F8E.8050607@agric.uwa.edu.au>

Hi Suzanne,

It sounds like you are dealing with an Inhomogeneous Poisson Point 
Process (the simplest). The intensity function lambda(mu) of this 
process is the density of points near mu. i.e. the process is poisson 
locally, and the intensity varies over the region according to some 
underlying function or surface (such as soil chemistry)

e.g.
 > plot(rpoispp(function(x,y){300*cos(2*pi*x)},300))  # taken from 
Adrian Baddeley's notes

The first step would then be interpolate your soil characteristics into 
global functions (either through delaunay triangulation, smoothing 
method (loess), or krigging). This allows you to estimate soil 
characteristics where your trees are, and derive vectors of the same 
length (although with some error).

There may also be away of involving the idea of a global funciton into 
the actual inference process, but I haven't thought about that deeply 
and my memory cells aren't stirred to recall a suitable reference.

Hope this was of some use.

Rohan Sadler

Suzanne E. Blatt wrote:

>Hello all,
>I'm attempting to conduct spatial analysis of trees within a plot.  I want to see if the trees are spatially correlated to soil characteristics, say pH, or   moisture content.  I think one way to do it is with mpl, however, my soil characteristics were not taken at exactly the same locations as my trees and further, the vectors aren't the same length.  I'm getting the impression, largely from the error messages, that length matters, ie. they must be the same.  In my case this is impossible.  The example listed in the file:///tmp/Rtmp1608/.R/library/spatstat/html/mpl.html regarding 'soilsurvey' using 'soilchem' as the covariate does not seem to be located in library(spatstat) nor library(splancs).  I'm trying to see how that example works, but can't locate it.  Can anyone tell me how to circumvent the 'length' problem or direct me to the location of 'soilsurvey' and 'soilchem' so I can see how those datasets are set up.
>Thanks,Suzanne 
>__________________________________________________________________Try AOL and get 1045 hours FREE for 45 days!http://free.aol.com/tryaolfree/index.adp?375380
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
PhD Student, Ecosystems Research Group (ERGO)
School of Plant Biology (Botany), Faculty of Natural & Agricultural Sciences,
The University of Western Australia, 35 Stirling Highway, Crawley  WA  6009, Australia

Ph:  +61 8 9380 7914
Fax: +61 8 9380 7925
email: rsadler at agric.uwa.edu.au
ERGO's web site:<http://www.botany.uwa.edu.au/ergo>


From genepi51 at yahoo.com  Thu May  1 07:04:27 2003
From: genepi51 at yahoo.com (Amanda Phipps)
Date: Wed, 30 Apr 2003 22:04:27 -0700 (PDT)
Subject: [R] poisson with overdispersion
Message-ID: <20030501050427.66972.qmail@web41610.mail.yahoo.com>

I am fitting a poisson model and it appears to have
overdispersion.  I am interested in using the
quasipoisson family (with the glm command).  Will this
account for the overdispersion in the model?  Is there
an additional method for accounting for a dispersion
parameter not equal to 1 (with the glm command)?  

And after fitting the model, how to I obtain the
fitted values and their respective standard errors?

Thank you-
Sarah Watson


From tobias_verbeke at skynet.be  Thu May  1 09:22:37 2003
From: tobias_verbeke at skynet.be (Tobias Verbeke)
Date: Thu, 1 May 2003 09:22:37 +0200
Subject: [R-gui] Re: [R] Feedback about SciViews?
In-Reply-To: <87k7dcorpd.fsf@jeeves.blindglobe.net>
References: <Pine.LNX.4.21.0304301716310.22965-100000@dollis-hill.inpharmatica.co.uk>
	<87k7dcorpd.fsf@jeeves.blindglobe.net>
Message-ID: <20030501092237.45797354.tobias_verbeke@skynet.be>

 
> > last year or two I've seen some very impressive platform
> > independent GUI's built with java.
> 
> Not for R.  One could argue for Python in the same light, as well. 

I fully agree. Platform-independence is one thing, 
freedom another. R is free-as-in-freedom-software, 
so it would really be a pity not to use a powerful
free-as-in-freedom-language to build R-GUI(s), be it
Python or another one.

This being said, any project to bring R
on any computer in the world is to be praised,
but please let R as such not be contaminated with
a language that doesn't come out of the mouth
of a healthy gnu...

acolyte of service,

Tobias


From ripley at stats.ox.ac.uk  Thu May  1 09:42:55 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 1 May 2003 08:42:55 +0100 (BST)
Subject: [R] List of lists?  Data frames? (Or other data structures?)
In-Reply-To: <Pine.GSO.4.10.10304301821470.2486-100000@quetelet.stat.ucla.edu>
Message-ID: <Pine.LNX.4.44.0305010834050.7578-100000@gannet.stats>

On Wed, 30 Apr 2003, Roger Peng wrote:

> If you're talking about rows and columns, it seems like the appropriate
> data structure for you is the data frame.  I think your list of lists
> representation might get unwieldy after a while.  I can't really think of
> why a data frame would be any slower than a list of lists -- I've never
> experienced such behavior.
> 
> read.table() may be a little slower than scan() because read.table() reads
> in an entire file and then converts each of the columns into an
> appropriate data class.  So there is some post-processing going on.  It
> doesn't have anything to do with data frames vs. lists.

Only if you don't specify colClasses: if you do (and you would need the
information to use scan()) there should be no performance penalty. (Note
that matrices can be scan()-ed into a vector and the dimensions added, and
that will be faster.)

> 
> -roger
> _______________________________
> UCLA Department of Statistics
> http://www.stat.ucla.edu/~rpeng
> 
> On Thu, 1 May 2003, R A F wrote:
> 
> > Hi, I'm faced with the following problem and would appreciate some
> > advice.
> > 
> > I could have a data frame x that looks like this:
> >          aa          bb
> > a        1           "A"
> > b        2           "B"
> > 
> > The advantage of this is that I could access all the individual
> > components easily.  Also I could access all the rows and columns
> > easily.
> > 
> > Alternatively, I could have a list of lists that looks like this:
> > 
> > xprime <- list()
> > xprime$a <- list()
> > xprime$b <- list()
> > 
> > xprime$a$aa <- 1
> > xprime$a$bb <- "A"
> > 
> > xprime$b$aa <- 2
> > xprime$b$bb <- "B"
> > 
> > etc.
> > 
> > If speed is important, would a list of lists be faster than a data
> > frame? (I know, for example, that scan is supposed to be faster than
> > read.table, but I don't know if that is related to issues with data
> > frames.)
> > 
> > My problem with a list of lists, though, is that if I want to access
> > all the bb subcomponents, a naive method like this one failed:
> > 
> > y <- c( "a", "b" )
> > xprime[[ y ]]$bb (Does not work)

You are supposed to use [[ ]] to extract a single component. I don't think
you expected

> xprime[[ y ]]
[1] "A"

(as from 1.7.0).

> > So to get all the bb subcomponents I seem to need to loop, which may
> > slow things down (presumably).  But maybe people here know of a way.

Something is going to have to loop, so it probably is not slow to use an 
explicit loop.

> > Finally what would be the "best" way given the constraint of quick
> > access to all rows, columns and individual components?
> > 
> > I'd appreciate your thoughts and comments.  Thanks very much.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Lsophir at wisemail.weizmann.ac.il  Thu May  1 10:04:22 2003
From: Lsophir at wisemail.weizmann.ac.il (Ron Ophir)
Date: Thu, 01 May 2003 11:04:22 +0300
Subject: [R] rotate plot
Message-ID: <seb0ff3f.050@wisemail.weizmann.ac.il>

Dear group members,
I am trying to plot two adjacent plots using layout function. One plot is scatter plot and the other is density plot. However, I would like that the density plot would be present horizonaly in respect to the scatter plot.
|                                        |
|                                        |
|                                        |
|                                        |
*
|                *                      |  *
|        *       *      *             |    * *
|    *        *                        |         *
|                                        |     * *
|------------------------------   |*-------------------------------

How do I rotate 90 dgrees the entire density plot?
Thanks in advance,
Ron


From luke at inpharmatica.co.uk  Thu May  1 12:02:15 2003
From: luke at inpharmatica.co.uk (Luke Whitaker)
Date: Thu, 1 May 2003 11:02:15 +0100 (BST)
Subject: [R-gui] Re: [R] Feedback about SciViews?
In-Reply-To: <87of2njwo6.fsf@jeeves.blindglobe.net>
Message-ID: <Pine.LNX.4.21.0305011033550.31070-100000@dollis-hill.inpharmatica.co.uk>

On Wed, 30 Apr 2003, A.J. Rossini wrote:

> "Liaw, Andy" <andy_liaw at merck.com> writes:
> 
> >> The GUI itself (i.e., how it operated, what menus were where, etc.) 
> >> was fine, but it was completely useless for anyone sitting at a 
> >> remote host, due to dreadful image quality and poor performance when 
> >> displaying anywhere other than on the console of the machine on which 
> >> SPlus was actually running.
> >
> > AFAIK the problem is the X server: it gives you a black window if the X
> > display is 16-bit.  If you can live with 8-bit display, the Java GUI will
> > work.  It's that way on all Unix (X?) platform.
> 
> I thought Java on Linux would do 8 and 24, but not 16?  (or something
> truly weird like that).
> 
> But that doesn't address performance issues, which still can be pretty
> bad.

It seems the problem here is limited to running R remotely. Given
the power of cheap consumer desktop machines these days, this seems
to me less of an issue than it used to be. Expensive commercial
software probably gets run remotely more than it needs to because
of licensing issues, which obviously don't apply to R.

If the GUI can be cleanly split from the compute engine of R, then
it should be quite easy to get the GUI running locally even if the
compute engine is remote - although I re-iterate my question for the
need to run free software remotely. My very modest desktop machine
is far more powerfull than the mainframe that I learnt to use SAS
on, and not so far short of the very expensive file server that I
use now.

Luke


From maechler at stat.math.ethz.ch  Thu May  1 12:05:38 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 1 May 2003 12:05:38 +0200
Subject: [R] rotate plot --> "grid" graphics!
In-Reply-To: <seb0ff3f.050@wisemail.weizmann.ac.il>
References: <seb0ff3f.050@wisemail.weizmann.ac.il>
Message-ID: <16048.61810.131984.224655@gargle.gargle.HOWL>

>>>>> "Ron" == Ron Ophir <Lsophir at wisemail.weizmann.ac.il>
>>>>>     on Thu, 01 May 2003 11:04:22 +0300 writes:

    Ron> Dear group members,
    Ron> I am trying to plot two adjacent plots using layout function. One plot is scatter plot and the other is density plot. However, I would like that the density plot would be present horizonaly in respect to the scatter plot.
    Ron> |                                        |
    Ron> |                                        |
    Ron> |                                        |
    Ron> |                                        |
    Ron> *
    Ron> |                *                      |  *
    Ron> |        *       *      *             |    * *
    Ron> |    *        *                        |         *
    Ron> |                                        |     * *
    Ron> |------------------------------   |*-------------------------------

    Ron> How do I rotate 90 dgrees the entire density plot?

Things like these are quite easily done using the 
recommended  "grid" package,  i.e.  library(grid).
using its much more powerful viewports instead of the layout()
function.

library(help = grid)  
## something you do with every non-standard package you start using !?

points you to
       http://www.stat.auckland.ac.nz/~paul/grid/grid.html
which contains a lot of nice documentation. 

Using "grid" graphics (instead of traditional "base" graphics)
is believed to be the real future of (static) graphics in R
   {take this with a grain of salt.  It's a hope mainly}

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><


From ripley at stats.ox.ac.uk  Thu May  1 12:55:58 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 1 May 2003 11:55:58 +0100 (BST)
Subject: [R-gui] Re: [R] Feedback about SciViews?
In-Reply-To: <Pine.LNX.4.21.0305011033550.31070-100000@dollis-hill.inpharmatica.co.uk>
Message-ID: <Pine.LNX.4.44.0305011135410.7915-100000@gannet.stats>

On Thu, 1 May 2003, Luke Whitaker wrote:

> On Wed, 30 Apr 2003, A.J. Rossini wrote:
> 
> > "Liaw, Andy" <andy_liaw at merck.com> writes:
> > 
> > >> The GUI itself (i.e., how it operated, what menus were where, etc.) 
> > >> was fine, but it was completely useless for anyone sitting at a 
> > >> remote host, due to dreadful image quality and poor performance when 
> > >> displaying anywhere other than on the console of the machine on which 
> > >> SPlus was actually running.
> > >
> > > AFAIK the problem is the X server: it gives you a black window if the X
> > > display is 16-bit.  If you can live with 8-bit display, the Java GUI will
> > > work.  It's that way on all Unix (X?) platform.
> > 
> > I thought Java on Linux would do 8 and 24, but not 16?  (or something
> > truly weird like that).
> > 
> > But that doesn't address performance issues, which still can be pretty
> > bad.
> 
> It seems the problem here is limited to running R remotely. 

No (and were we not discussing the *S-PLUS* Java GUI?). S-PLUS Java will
not start locally on Solaris in 96Mb of RAM (and my home Sun only has
64Mb).  In reality you need much more, as you need memory to do the
calculations too.

I've just fired it up on my new Dual Athlon 2600 with 1Gb RAM under RH8:
I'd say the GUI was about the speed of S-PLUS for Windows on a 133MHz 
Pentium, that is noticeably slow.  I have seen faster Java GUIs elsewhere, 
but none has approached the speed of a native GUI, and until recently they 
have been between irksome and intolerable.

> Given
> the power of cheap consumer desktop machines these days, this seems
> to me less of an issue than it used to be. Expensive commercial
> software probably gets run remotely more than it needs to because
> of licensing issues, which obviously don't apply to R.

In my experience R is often run remotely to share machines with large 
amounts of memory.  We don't routinely put 1Gb in people's desktops.

> If the GUI can be cleanly split from the compute engine of R, then

I think that is lot harder than you suppose, as the S model is inherently 
of sequential calculations on objects.  People expect GUIs to multitask.

> it should be quite easy to get the GUI running locally even if the
> compute engine is remote - although I re-iterate my question for the
> need to run free software remotely. My very modest desktop machine
> is far more powerfull than the mainframe that I learnt to use SAS
> on, and not so far short of the very expensive file server that I
> use now.

That's the perspective of someone in a first-world company (I guess from
the email address).  R is designed to run under 16Mb RAM on say 133MHz
machines, because some people using it really do have machines like that.
Our students often have machines with 128Mb or less.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ligges at statistik.uni-dortmund.de  Thu May  1 13:00:27 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 01 May 2003 13:00:27 +0200
Subject: [R] ylab in plot.POSIXct
References: <ulgptn3rebn.fsf@phz.com>
Message-ID: <3EB0FE4B.8F5B6116@statistik.uni-dortmund.de>

Ed Kademan wrote:
> 
> I am using R-1.7.0 and have some data which consist of one vector of
> numbers and a second corresponding vector of dates belonging to the
> POSIXct class.  I would like to plot the numbers against the dates.
> What is the best way to do this?
> 
> It almost works to just call `plot.'  However if I do this while using
> the `ylab' parameter I get a warning message:
> 
>   parameter "ylab" couldn't be set in high-level plot() function

In this case, you can ignore that warning message (it's a warning, not
an error).


> Here is a function that demonstrates the behavior.
> 
>   ylabProblem <- function() {
>     x <- ISOdate(2003, 4, 1:10)           # POSIXct vector
>     y <- rnorm(10)
>     plot(x, y, ylab = 'I am y')
>   }
> 
> It works to invoke the low-level plotting routines by hand as follows:
> 
>   ylabNoProblem <- function() {
>     x <- ISOdate(2003, 4, 1:10)           # POSIXct vector
>     y <- rnorm(10)
>     plot.default(x, y, xaxt = 'n', xlab = '', ylab = 'I am y')
>     axis.POSIXct(1, x)
>   }
> 
> But I don't like calling methods explicitly like this.


axis.POSIXct() is not a method, because axis() is not a generic function
(and hence not able to dispatch for POSIXct objects).
Calling axis.POSIXct() explicitly is a not a bad idea in this case.

Uwe Ligges


From fredrik.lundgren at norrkoping.mail.telia.com  Thu May  1 13:47:28 2003
From: fredrik.lundgren at norrkoping.mail.telia.com (Fredrik Lundgren)
Date: Thu, 1 May 2003 13:47:28 +0200
Subject: [R] "prediction intervals for glm"
References: 
	<200304290223.32871.fredrik.lundgren@norrkoping.mail.telia.com><3EADF4EA.6040204@pdf.com>
	<x2he8hl5qg.fsf@biostat.ku.dk>
Message-ID: <000f01c30fd7$74ed4d40$2d0ffea9@oemcomputer>

Hello again,

I wouldn't know anything about the theoretical problems with glm and a binary outcome but there is a "prediction interval" in predict.glm of  S-Plus(6.02 version something). I have failed to source it to R (and I do have difficulties with the higher forms of matrix manipulations). In the medical field where I'm active I think it has a high value to generate "prediction intervals" for risk and benefit calculations for individual patients. If it's theoretically fishy or unsound with a prediction interval maybe some bootstrap appraoch could do the trick?

Sincerely Fredrik Lundgren 
----- Original Message ----- 
From: "Peter Dalgaard BSA" <p.dalgaard at biostat.ku.dk>
To: "Spencer Graves" <spencer.graves at pdf.com>
Cc: "Fredrik Lundgren" <fredrik.lundgren at norrkoping.mail.telia.com>; <R-help at stat.math.ethz.ch>
Sent: Tuesday, April 29, 2003 4:48 PM
Subject: Re: [R] "prediction intervals for glm"


> Spencer Graves <spencer.graves at pdf.com> writes:
> 
> > "?predict.glm" produced something in my copy of R 1.6.2 under Windows
> > 2000.
> 
> .. but probably not what Fredrik wanted. Prediction intervals (i.e.
> intervals with 95% probability of catching a new observation) are
> somewhat tricky even to define for glms. For Normal responses you have
> the formula yhat +- qt(.975,df)* sqrt(s^2+se(yhat)^2), for other
> continuous responses that would become (approximately!) the error
> distribution convolved with a Gaussian density, for discrete responses
> - say 0/1 - I wouldn't know what to do.
> 
> > 
> > Fredrik Lundgren wrote:
> 
> > > Where can i find prediction intervals for glm in R?
> 
> 
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From raf1729 at hotmail.com  Thu May  1 13:49:52 2003
From: raf1729 at hotmail.com (R A F)
Date: Thu, 01 May 2003 11:49:52 +0000
Subject: [R] List of lists? Data frames? (Or other data structures?)
Message-ID: <Law11-F54vseE4D3MBh0001bc65@hotmail.com>

Thanks for your comments.  I'm not too familiar with these differences,
but here's a simple experiment.  In a data file with 139,000 rows and
5 columns (double string double double double),

>system.time( aaa <- read.table( "file" ) )
20.67 0.41 21.10 0.00 0.00

>system.time( aaa <- scan( "file", list( 0, "", 0, 0, 0 ) ) )
6.07 0.01 6.09 0.00 0.00

It seems like scan is much faster -- and as the data file grows,
read.table seems to choke.  (I actually tried this with a data file
with over 2 million rows.)

I'm using a Sun-Sparc, Solaris 2.8 and R 1.5.1.  Sorry I can't be
more specific about the hardware/software configurations, not being
too knowledgeable about this sort of thing.

By the way, it's not possible to create a matrix of mixed types, is
it?  (I don't know how anyway.)

Any ideas as to the speed differences?  Thanks again.

>From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
>To: Roger Peng <rpeng at stat.ucla.edu>
>CC: r-help at stat.math.ethz.ch, R A F <raf1729 at hotmail.com>
>Subject: Re: [R] List of lists?  Data frames? (Or other data structures?)
>Date: Thu, 1 May 2003 08:42:55 +0100 (BST)
>
>On Wed, 30 Apr 2003, Roger Peng wrote:
>
> > If you're talking about rows and columns, it seems like the appropriate
> > data structure for you is the data frame.  I think your list of lists
> > representation might get unwieldy after a while.  I can't really think 
>of
> > why a data frame would be any slower than a list of lists -- I've never
> > experienced such behavior.
> >
> > read.table() may be a little slower than scan() because read.table() 
>reads
> > in an entire file and then converts each of the columns into an
> > appropriate data class.  So there is some post-processing going on.  It
> > doesn't have anything to do with data frames vs. lists.
>
>Only if you don't specify colClasses: if you do (and you would need the
>information to use scan()) there should be no performance penalty. (Note
>that matrices can be scan()-ed into a vector and the dimensions added, and
>that will be faster.)


From plxmh at nottingham.ac.uk  Thu May  1 14:07:49 2003
From: plxmh at nottingham.ac.uk (Martin Hoyle)
Date: Thu, 01 May 2003 13:07:49 +0100
Subject: [R] poisson with overdispersion
Message-ID: <seb11c29.047@ccw0m1.nottingham.ac.uk>

Dear Amanda,
According to "Statistical Computing" by Crawley, p545, you can deal with overdispersion by any one of 3 ways;

1: Carry out significance tests using "F" rather than "Chi" in the anova function for comparison of deviances,
2: Use quasipoisson, and specify a variance function, or,
3: Use negative binomial error (see library(MASS), glm.nb).

To answer the second part of your qu, if you do summary(model), you will get the estimate  and s.e. of the log transform of your  response variable (log is the default link).

Cheers,
Martin.


Martin Hoyle,
School of Life and Environmental Sciences,
University of Nottingham,
University Park,
Nottingham,
NG7 2RD,
UK
Webpage: http://myprofile.cos.com/martinhoyle

>>> Amanda Phipps <genepi51 at yahoo.com> 05/01/03 06:04am >>>
I am fitting a poisson model and it appears to have
overdispersion.  I am interested in using the
quasipoisson family (with the glm command).  Will this
account for the overdispersion in the model?  Is there
an additional method for accounting for a dispersion
parameter not equal to 1 (with the glm command)?  

And after fitting the model, how to I obtain the
fitted values and their respective standard errors?

Thank you-
Sarah Watson

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From p.dalgaard at biostat.ku.dk  Thu May  1 14:19:32 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 01 May 2003 14:19:32 +0200
Subject: [R] List of lists? Data frames? (Or other data structures?)
In-Reply-To: <Law11-F54vseE4D3MBh0001bc65@hotmail.com>
References: <Law11-F54vseE4D3MBh0001bc65@hotmail.com>
Message-ID: <x2smrykgff.fsf@biostat.ku.dk>

"R A F" <raf1729 at hotmail.com> writes:

> Thanks for your comments.  I'm not too familiar with these differences,
> but here's a simple experiment.  In a data file with 139,000 rows and
> 5 columns (double string double double double),
> 
> >system.time( aaa <- read.table( "file" ) )
> 20.67 0.41 21.10 0.00 0.00
> 
> >system.time( aaa <- scan( "file", list( 0, "", 0, 0, 0 ) ) )
> 6.07 0.01 6.09 0.00 0.00
> 
> It seems like scan is much faster -- and as the data file grows,
> read.table seems to choke.  (I actually tried this with a data file
> with over 2 million rows.)

You're not taking Brian's hint!:

> >Only if you don't specify colClasses: if you do (and you would need the
> >information to use scan()) there should be no performance penalty. (Note
> >that matrices can be scan()-ed into a vector and the dimensions added, and
> >that will be faster.)

Try this:

cls <- sapply(list(0,"",0,0,0),class)
# older versions may need cls <- c("numeric","character",rep("numeric",3))
aaa <- read.table( "file", colClasses=cls )

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From raf1729 at hotmail.com  Thu May  1 14:20:57 2003
From: raf1729 at hotmail.com (R A F)
Date: Thu, 01 May 2003 12:20:57 +0000
Subject: [R] List of lists? Data frames? (Or other data structures?)
Message-ID: <Law11-F44BJM2XBPMrV0001c26c@hotmail.com>

Ah, thanks!

(It's not that I didn't reading it -- I didn't understand it and so
I thought that it'd be easier to ask again.  Thanks very much!)

>From: Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk>
>To: "R A F" <raf1729 at hotmail.com>
>CC: ripley at stats.ox.ac.uk, rpeng at stat.ucla.edu, r-help at stat.math.ethz.ch
>Subject: Re: [R] List of lists? Data frames? (Or other data structures?)
>Date: 01 May 2003 14:19:32 +0200
>
>You're not taking Brian's hint!:


From ripley at stats.ox.ac.uk  Thu May  1 14:29:32 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Thu, 1 May 2003 13:29:32 +0100 (GMT Daylight Time)
Subject: [R] "prediction intervals for glm"
In-Reply-To: <000f01c30fd7$74ed4d40$2d0ffea9@oemcomputer>
Message-ID: <Pine.WNT.4.44.0305011322520.4072-100000@gannet.stats.ox.ac.uk>

On Thu, 1 May 2003, Fredrik Lundgren wrote:

> I wouldn't know anything about the theoretical problems with glm and a
> binary outcome but there is a "prediction interval" in predict.glm of
> S-Plus(6.02 version something). I have failed to source it to R (and I do
> have difficulties with the higher forms of matrix manipulations). In the
> medical field where I'm active I think it has a high value to generate
> "prediction intervals" for risk and benefit calculations for individual
> patients. If it's theoretically fishy or unsound with a prediction
> interval maybe some bootstrap appraoch could do the trick?

It's more than fishy ... it uses the normal approximation on link scale (as
I recall) which is very unlikely to be valid except for the gaussian
family.  Indeed for 0/1 data the interval will have coverage 0, exactly.

I don't see how a bootstrap would help either: the issue is to combine the
(reasonably well-known) uncertainty in the prediction of the mean with the
variability in the observation.  That would be easy to do by simulation,
but not by re-sampling.  (Or did you think all simulation-based inference
was `some bootstrap approach'.)  However, you are not going to be able to
summarize that predictive distribution as an *interval* for 0/1 data.

>
> Sincerely Fredrik Lundgren
> ----- Original Message -----
> From: "Peter Dalgaard BSA" <p.dalgaard at biostat.ku.dk>
> To: "Spencer Graves" <spencer.graves at pdf.com>
> Cc: "Fredrik Lundgren" <fredrik.lundgren at norrkoping.mail.telia.com>; <R-help at stat.math.ethz.ch>
> Sent: Tuesday, April 29, 2003 4:48 PM
> Subject: Re: [R] "prediction intervals for glm"
>
>
> > Spencer Graves <spencer.graves at pdf.com> writes:
> >
> > > "?predict.glm" produced something in my copy of R 1.6.2 under Windows
> > > 2000.
> >
> > .. but probably not what Fredrik wanted. Prediction intervals (i.e.
> > intervals with 95% probability of catching a new observation) are
> > somewhat tricky even to define for glms. For Normal responses you have
> > the formula yhat +- qt(.975,df)* sqrt(s^2+se(yhat)^2), for other
> > continuous responses that would become (approximately!) the error
> > distribution convolved with a Gaussian density, for discrete responses
> > - say 0/1 - I wouldn't know what to do.
> >
> > >
> > > Fredrik Lundgren wrote:
> >
> > > > Where can i find prediction intervals for glm in R?
> >
> >
> > --
> >    O__  ---- Peter Dalgaard             Blegdamsvej 3
> >   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
> >  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> > ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu May  1 14:38:15 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Thu, 1 May 2003 13:38:15 +0100 (GMT Daylight Time)
Subject: [R] poisson with overdispersion
In-Reply-To: <seb11c29.047@ccw0m1.nottingham.ac.uk>
Message-ID: <Pine.WNT.4.44.0305011330170.4072-100000@gannet.stats.ox.ac.uk>

That's an answer about S-PLUS rather than R.  S-PLUS does not have a
quasipoisson family, and treats its poisson family in an inconsistent way
(sometimes as quasi-Poisson and sometimes not).

For R, use the quasipoisson family or the negative binomial family via
glm.nb.  See section 7.5 of MASS (the book, fourth edition) for fuller
details.

On Thu, 1 May 2003, Martin Hoyle wrote:

> Dear Amanda,
> According to "Statistical Computing" by Crawley, p545, you
> can deal with overdispersion by any one of 3 ways;
>
> 1: Carry out significance tests using "F" rather than "Chi" in the anova
> function for comparison of deviances,
> 2: Use quasipoisson, and specify a variance function, or,
> 3: Use negative binomial error (see library(MASS), glm.nb).
>
> To answer the second part of your qu, if you do summary(model), you will
> get the estimate and s.e. of the log transform of your response variable
> (log is the default link).

The model is for the log of the means, not the log of the variable.

You get the fitted values via fitted(fit).  For associated se's you need to
use predict(fit): if you use a quasipoisson model you will automatically
get over-dispersion taken into account.

> >>> Amanda Phipps <genepi51 at yahoo.com> 05/01/03 06:04am >>>
> I am fitting a poisson model and it appears to have
> overdispersion.  I am interested in using the
> quasipoisson family (with the glm command).  Will this
> account for the overdispersion in the model?  Is there
> an additional method for accounting for a dispersion
> parameter not equal to 1 (with the glm command)?
>
> And after fitting the model, how to I obtain the
> fitted values and their respective standard errors?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From djw1005 at cam.ac.uk  Thu May  1 14:56:23 2003
From: djw1005 at cam.ac.uk (Damon Wischik)
Date: Thu, 1 May 2003 13:56:23 +0100 (BST)
Subject: [R] Class troubles
Message-ID: <Pine.SOL.3.96.1030501134041.40A-100000@libra.cus.cam.ac.uk>


I would appreciate some guidance about classes. I think I'm
getting confused about S3 classes and S4 classes, in the following:

--------------
library(lattice)
library(methods)
s <- shingle(1:5)
class (s)

# this reports that s has class "shingle", as expected

foo <- function(x) as.factor(x)
setGeneric("foo")
setMethod("foo","numeric",function(x) as.shingle(x))
setMethod("foo","shingle",function(x) {cat("A shingle!\n"); x})

# gives me a warning:
# Class "shingle" not defined in: matchSignature(signature, fdef)

foo(s)

# Calls the "foo" for shingle, as I want it to.
---------------------------

If I defined a "shingle" S4 class, I expect I wouldn't get the warning
message when I try to define "foo" for "shingle".  But I want my routine
to work with the existing shingle S3 class from the lattice package. 

My code works as it is, but I get the warning message, which makes me
uneasy. What should I do?

Damon Wischik.


From raf1729 at hotmail.com  Thu May  1 14:57:56 2003
From: raf1729 at hotmail.com (R A F)
Date: Thu, 01 May 2003 12:57:56 +0000
Subject: [R] List of lists? Data frames? (Or other data structures?)
Message-ID: <Law11-F333onkhhid3f0000c3c9@hotmail.com>

For what it's worth, I followed the suggestion of using colClasses:

cls <- c( "numeric", "character", "numeric", "numeric", "numeric" )
system.time( bbb <- read.table( "file", colClasses = cls ) )

Here're the results from three tries:
8.21 0.06 8.28 0.00 0.00
8.94 0.10 9.10 0.00 0.00
8.55 0.06 8.69 0.00 0.00

I also did
system.time( aaa <- scan( "file", list( 0, "", 0, 0, 0 ) ) three
times:

6.46 0.04 6.59 0.00 0.00
5.27 0.04 5.33 0.00 0.00
5.14 0.05 5.19 0.00 0.00

By the way, I did the experiment in the order bbb, aaa, bbb, aaa,
bbb, aaa.

So it appears that read.table is still a little slower -- but it could
be just me doing something wrong.

Thanks.

>From: "R A F" <raf1729 at hotmail.com>
>To: p.dalgaard at biostat.ku.dk
>CC: r-help at stat.math.ethz.ch, rpeng at stat.ucla.edu, ripley at stats.ox.ac.uk
>Subject: Re: [R] List of lists? Data frames? (Or other data structures?)
>Date: Thu, 01 May 2003 12:20:57 +0000
>
>Ah, thanks!
>
>(It's not that I didn't reading it -- I didn't understand it and so
>I thought that it'd be easier to ask again.  Thanks very much!)
>
>>From: Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk>
>>To: "R A F" <raf1729 at hotmail.com>
>>CC: ripley at stats.ox.ac.uk, rpeng at stat.ucla.edu, r-help at stat.math.ethz.ch
>>Subject: Re: [R] List of lists? Data frames? (Or other data structures?)
>>Date: 01 May 2003 14:19:32 +0200
>>
>>You're not taking Brian's hint!:


From jmagalhaes at oninetspeed.pt  Thu May  1 15:41:40 2003
From: jmagalhaes at oninetspeed.pt (Jorge =?iso-8859-15?q?Magalh=E3es?=)
Date: Thu, 1 May 2003 14:41:40 +0100
Subject: [R] New factor from two olds factors
In-Reply-To: <200304261006.27258.jmagalhaes@oninetspeed.pt>
References: <200304261006.27258.jmagalhaes@oninetspeed.pt>
Message-ID: <200305011441.40606.jmagalhaes@oninetspeed.pt>


Hi, 

Suppose i have two factors:

factor1<-Structure(factor(c(1,3,2,1,2,1,2,1,3),levels=1:3), 
.Label=c("Yes","No","NY")))
factor2<-Structure(factor(c(2,1,2,1,3,2,2,1,3),levels=1:3), 
.Label=c("Yes","No", "NY")))
 
i want define a new factor from the factors 1 and 2. For that i tried:

>array3<- is.numeric(factor1)+is.numeric(factor2)

array3=(3,4,4,2,5,3,4,2,6)

Now i need to define two new classes: if 2,3 and 4 ----->> class1 else class2

What is the best way for making that?

Thanks in the advance.

Jorge M.


From ligges at statistik.uni-dortmund.de  Thu May  1 15:46:50 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 01 May 2003 15:46:50 +0200
Subject: [R] New factor from two olds factors
References: <200304261006.27258.jmagalhaes@oninetspeed.pt>
	<200305011441.40606.jmagalhaes@oninetspeed.pt>
Message-ID: <3EB1254A.36F18B43@statistik.uni-dortmund.de>

Jorge Magalh?es wrote:
> 
> Hi,
> 
> Suppose i have two factors:
> 
> factor1<-Structure(factor(c(1,3,2,1,2,1,2,1,3),levels=1:3),
> .Label=c("Yes","No","NY")))

For sure you mean 
 factor1 <- structure(factor(c(1,3,2,1,2,1,2,1,3), levels=1:3),
Label=c("Yes","No","NY"))


> factor2<-Structure(factor(c(2,1,2,1,3,2,2,1,3),levels=1:3),
> .Label=c("Yes","No", "NY")))
> 
> i want define a new factor from the factors 1 and 2. For that i tried:
> 
> >array3<- is.numeric(factor1)+is.numeric(factor2)

But using as.numeric(), I guess.


> array3=(3,4,4,2,5,3,4,2,6)
> 
> Now i need to define two new classes: if 2,3 and 4 ----->> class1 else class2
> 
> What is the best way for making that?
> 
> Thanks in the advance.
> 
> Jorge M.


For example: 
 factor(ifelse(array3 < 5, 1, 2))

Uwe Ligges


From adam at ajtee.uklinux.net  Thu May  1 17:57:38 2003
From: adam at ajtee.uklinux.net (Adam Tee)
Date: Thu, 01 May 2003 16:57:38 +0100
Subject: [R] Automating R for multiple data files
Message-ID: <3EB143F2.7000504@ajtee.uklinux.net>

Hi,

I'm new to R and have looked at the mail archives and not
seen a solution to my problem.

I have a set of data files with filenames in the following form
haydn1stmvt.jtf.sim0.142292.et.dist, where the latter half
changes, after the jtf.

What I am trying to do is process the set of these files using
R's batch mode. using the following :

library(mva)

mdsdata <- read.table(file)
cm <- cmdscale(mdsdata)
x <- cm[,1]
y <- -cm[,2]

postscript("file.eps", height=5, width=5)
plot(x,y,type="n", main="classical MDS")
text(x,y,names(mdsdata))
dev.off()

I want the variable file to contain the relevant file name with
having to input it manually for each file. Is there an easy solution to 
this ??


Thanks

Adam Tee
PhD Student
University of Leeds


From bmagill at earthlink.net  Thu May  1 14:45:18 2003
From: bmagill at earthlink.net (Brett Magill)
Date: Thu, 1 May 2003 07:45:18 -0500 (CDT)
Subject: [R] Test statistic for Spearman correlation
Message-ID: <4232706.1051800460111.JavaMail.nobody@misspiggy.psp.pas.earthlink.net>

In the ouput below, what is the "S" statistic (S = 96) that is used for Spearman?  I don't have easy access to the books cited on the help page.  Other texts and web sources that I have found use t or z as a test for Spearman, perhaps inappropriately.  Can anyone tell me how S is computed or refer to a web resource?

I see from the code for that: 

  q <- as.integer((n^3 - n) * (1 - ESTIMATE)/6)
  STATISTIC <- c(S = q)  

I couldn't decipher the next part.  Would appreciate some help.

R 1.7.0 Windows 98.
_________________________________________
        Spearman's rank correlation rho

data:  x and y 
S = 96, p-value = 0.2324
alternative hypothesis: true rho is not equal to 0 
sample estimates:
      rho 
0.4181818


From ripley at stats.ox.ac.uk  Thu May  1 16:56:15 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 1 May 2003 15:56:15 +0100 (BST)
Subject: [R] Automating R for multiple data files
In-Reply-To: <3EB143F2.7000504@ajtee.uklinux.net>
Message-ID: <Pine.LNX.4.44.0305011554520.1178-100000@gannet.stats>

On Thu, 1 May 2003, Adam Tee wrote:

> Hi,
> 
> I'm new to R and have looked at the mail archives and not
> seen a solution to my problem.
> 
> I have a set of data files with filenames in the following form
> haydn1stmvt.jtf.sim0.142292.et.dist, where the latter half
> changes, after the jtf.
> 
> What I am trying to do is process the set of these files using
> R's batch mode. using the following :
> 
> library(mva)
> 
> mdsdata <- read.table(file)
> cm <- cmdscale(mdsdata)
> x <- cm[,1]
> y <- -cm[,2]
> 
> postscript("file.eps", height=5, width=5)
> plot(x,y,type="n", main="classical MDS")
> text(x,y,names(mdsdata))
> dev.off()
> 
> I want the variable file to contain the relevant file name with
> having to input it manually for each file. Is there an easy solution to 
> this ??

files <- list.files(pattern="^haydn1stmvt.jtf")

and then a for loop over `files' would appear to do what I think (but am 
unsure) you want.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jmagalhaes at oninetspeed.pt  Thu May  1 17:07:50 2003
From: jmagalhaes at oninetspeed.pt (Jorge =?iso-8859-15?q?Magalh=E3es?=)
Date: Thu, 1 May 2003 16:07:50 +0100
Subject: [R] Sweave textwidth
Message-ID: <200305011607.50757.jmagalhaes@oninetspeed.pt>

Hi,

How i can fix the sweave textwidth.

For example, in the chunk

<<>>=
MOTin <- 
as.numeric(iinquee$Q1)+as.numeric(iinquee$Q2)+as.numeric(iinquee$Q3)+as.numeric(iinquee$Q4)
@

In the output page some text is omitted, appear like this:
> MOTin <- as.numeric(iinquee$Q1)+as.numeric(iinquee$Q2)+as.numeric(ii
+         as.numeric(iinquee$Q4)

I can change the tex file, but isn't what i want to do.

Thanks in the advance
Jorge M.


From RexBryan1 at attbi.com  Thu May  1 17:22:51 2003
From: RexBryan1 at attbi.com (Rex_Bryan@urscorp.com)
Date: Thu, 1 May 2003 09:22:51 -0600
Subject: [R] How to calculate the x to assymptotic value and curve
Message-ID: <001a01c30ff5$883f2670$3182fd0c@dell1700>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030501/faff7880/attachment.pl

From naumov at buffalo.edu  Thu May  1 17:38:07 2003
From: naumov at buffalo.edu (Aleksey Naumov)
Date: Thu, 1 May 2003 11:38:07 -0400 (EDT)
Subject: [R] List of lists? Data frames? (Or other data structures?)
In-Reply-To: <Law11-F333onkhhid3f0000c3c9@hotmail.com>
Message-ID: <Pine.GSO.4.05.10305011129260.14165-100000@hercules.acsu.buffalo.edu>


Try str(aaa) after running scan() and read.table():

scan() returns a list of vectors, while read.table() returns a data frame.
The extra time taken by read.table() (in my tries read.table is 1.2-1.5
times slower than scan, consistent with your numbers) must be due to
binding the vectors into a data frame (checking that they have the same
length, etc). 
In my runs trying to convert the result of scan() into a data frame (with
as.data.frame(aaa)) took about the same time as read.table(), so if you
want a data frame in the end, read.table() may be best.

Aleksey

On Thu, 1 May 2003, R A F wrote:

> For what it's worth, I followed the suggestion of using colClasses:
> 
> cls <- c( "numeric", "character", "numeric", "numeric", "numeric" )
> system.time( bbb <- read.table( "file", colClasses = cls ) )
> 
> Here're the results from three tries:
> 8.21 0.06 8.28 0.00 0.00
> 8.94 0.10 9.10 0.00 0.00
> 8.55 0.06 8.69 0.00 0.00
> 
> I also did
> system.time( aaa <- scan( "file", list( 0, "", 0, 0, 0 ) ) three
> times:
> 
> 6.46 0.04 6.59 0.00 0.00
> 5.27 0.04 5.33 0.00 0.00
> 5.14 0.05 5.19 0.00 0.00
> 
> By the way, I did the experiment in the order bbb, aaa, bbb, aaa,
> bbb, aaa.
> 
> So it appears that read.table is still a little slower -- but it could
> be just me doing something wrong.
> 
> Thanks.
> 
> >From: "R A F" <raf1729 at hotmail.com>
> >To: p.dalgaard at biostat.ku.dk
> >CC: r-help at stat.math.ethz.ch, rpeng at stat.ucla.edu, ripley at stats.ox.ac.uk
> >Subject: Re: [R] List of lists? Data frames? (Or other data structures?)
> >Date: Thu, 01 May 2003 12:20:57 +0000
> >
> >Ah, thanks!
> >
> >(It's not that I didn't reading it -- I didn't understand it and so
> >I thought that it'd be easier to ask again.  Thanks very much!)
> >
> >>From: Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk>
> >>To: "R A F" <raf1729 at hotmail.com>
> >>CC: ripley at stats.ox.ac.uk, rpeng at stat.ucla.edu, r-help at stat.math.ethz.ch
> >>Subject: Re: [R] List of lists? Data frames? (Or other data structures?)
> >>Date: 01 May 2003 14:19:32 +0200
> >>
> >>You're not taking Brian's hint!:
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
>


From tblackw at umich.edu  Thu May  1 17:40:30 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Thu, 1 May 2003 11:40:30 -0400 (EDT)
Subject: [R] Test statistic for Spearman correlation
In-Reply-To: <4232706.1051800460111.JavaMail.nobody@misspiggy.psp.pas.earthlink.net>
Message-ID: <Pine.SOL.4.44.0305011128550.8363-100000@asteroids.gpcc.itd.umich.edu>

Brett  -

I can give you a further reference, but you may not
find it much help !

E. G. Olds.  Distribution of sums of squares of rank
differences for small numbers of individuals.  Annals
of Mathematical Statistics, v.9, pp. 133-148, 1938.

My source says that "Olds (1938) tabulated the exact
distribution of a quantity S related to rho by the
equation

    R = 1 - 6 * S / (n^3 - n) ."

Olds must have been using a Comptometer or a Marchant
calculator, so presumably, this construct guarantees
always to be an integer.  Algorithm AS 89 is certainly
available on line from Statlib.

HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Thu, 1 May 2003, Brett Magill wrote:

> In the ouput below, what is the "S" statistic (S = 96) that
> is used for Spearman?  I don't have easy access to the books
> cited on the help page.  Other texts and web sources that I
> have found use t or z as a test for Spearman, perhaps
> inappropriately.  Can anyone tell me how S is computed or
> refer to a web resource?
>
> I see from the code for that:
>
>   q <- as.integer((n^3 - n) * (1 - ESTIMATE)/6)
>   STATISTIC <- c(S = q)
>
> I couldn't decipher the next part.  Would appreciate some help.
>
> R 1.7.0 Windows 98.
> _________________________________________
>         Spearman's rank correlation rho
>
> data:  x and y
> S = 96, p-value = 0.2324
> alternative hypothesis: true rho is not equal to 0
> sample estimates:
>       rho
> 0.4181818
>


From juli at ceam.es  Thu May  1 19:03:11 2003
From: juli at ceam.es (juli g. pausas)
Date: Thu, 01 May 2003 19:03:11 +0200
Subject: [R] var[i]
Message-ID: <3EB1534F.9050600@ceam.es>

Dear all,
How could I use variables in a loop that their names are in a vector? 
For example:

aaa <- 1:10
bbb <- aaa*2
ccc <- aaa+bbb

varn <- c("aaa", "bbb", "ccc")
m <- rep(NA, 3)

for (i in 1:length(varn)) m[i] <- mean(varn[i])  # wrong


thanks in advance

Juli



--
"Wars do not solve problems, wars generate even more problems"


From p.dalgaard at biostat.ku.dk  Thu May  1 19:20:04 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 01 May 2003 19:20:04 +0200
Subject: [R] Test statistic for Spearman correlation
In-Reply-To: <Pine.SOL.4.44.0305011128550.8363-100000@asteroids.gpcc.itd.umich.edu>
References: <Pine.SOL.4.44.0305011128550.8363-100000@asteroids.gpcc.itd.umich.edu>
Message-ID: <x2n0i6k2ij.fsf@biostat.ku.dk>

Thomas W Blackwell <tblackw at umich.edu> writes:

> Brett  -
> 
> I can give you a further reference, but you may not
> find it much help !
> 
> E. G. Olds.  Distribution of sums of squares of rank
> differences for small numbers of individuals.  Annals
> of Mathematical Statistics, v.9, pp. 133-148, 1938.
> 
> My source says that "Olds (1938) tabulated the exact
> distribution of a quantity S related to rho by the
> equation
> 
>     R = 1 - 6 * S / (n^3 - n) ."
> 
> Olds must have been using a Comptometer or a Marchant
> calculator, so presumably, this construct guarantees
> always to be an integer.  Algorithm AS 89 is certainly
> available on line from Statlib.

The title of Olds paper might have given you a hint:

> x <- rank(rnorm(10))
> y <- rank(rnorm(10))
> cor(x,y)
[1] -0.2242424
> 990/6*(1-cor(x,y))
[1] 202
> sum((x-y)^2)
[1] 202

BTW, the identity breaks down when there are ties, something that we
probably ought to look into at some point. The code does say that the
p values may be incorrect, but I suspect they may be more incorrect
than need be.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From andy_liaw at merck.com  Thu May  1 19:32:28 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 01 May 2003 13:32:28 -0400
Subject: [R] var[i]
Message-ID: <3A822319EB35174CA3714066D590DCD5C4FA9A@usrymx25.merck.com>

Here's an example:

> x1 <- 1:3
> x2 <- 4:6
> x3 <- 7:9
> xn <- paste("x", 1:3, sep="")
> m <- numeric(3)
> for(i in 1:3) m[i] <- mean(get(xn[i]))
> m
[1] 2 5 8

HTH,
Andy

> -----Original Message-----
> From: juli g. pausas [mailto:juli at ceam.es]
> Sent: Thursday, May 01, 2003 1:03 PM
> To: r-help
> Subject: [R] var[i]
> 
> 
> Dear all,
> How could I use variables in a loop that their names are in a vector? 
> For example:
> 
> aaa <- 1:10
> bbb <- aaa*2
> ccc <- aaa+bbb
> 
> varn <- c("aaa", "bbb", "ccc")
> m <- rep(NA, 3)
> 
> for (i in 1:length(varn)) m[i] <- mean(varn[i])  # wrong
> 
> 
> thanks in advance
> 
> Juli
> 
> 
> 
> --
> "Wars do not solve problems, wars generate even more problems"
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From sundar.dorai-raj at pdf.com  Thu May  1 19:33:07 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 01 May 2003 12:33:07 -0500
Subject: [R] var[i]
References: <3EB1534F.9050600@ceam.es>
Message-ID: <3EB15A53.6090505@pdf.com>



juli g. pausas wrote:
> Dear all,
> How could I use variables in a loop that their names are in a vector? 
> For example:
> 
> aaa <- 1:10
> bbb <- aaa*2
> ccc <- aaa+bbb
> 
> varn <- c("aaa", "bbb", "ccc")
> m <- rep(NA, 3)
> 
> for (i in 1:length(varn)) m[i] <- mean(varn[i])  # wrong
> 
> 


Use ?get.


for (i in 1:length(varn)) m[i]=mean(get(varn[i]))  # right

sundar


From p.dalgaard at biostat.ku.dk  Thu May  1 19:38:13 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 01 May 2003 19:38:13 +0200
Subject: [R] var[i]
In-Reply-To: <3EB1534F.9050600@ceam.es>
References: <3EB1534F.9050600@ceam.es>
Message-ID: <x2issuk1oa.fsf@biostat.ku.dk>

"juli g. pausas" <juli at ceam.es> writes:

> Dear all,
> How could I use variables in a loop that their names are in a vector?
> For example:
> 
> aaa <- 1:10
> bbb <- aaa*2
> ccc <- aaa+bbb
> 
> varn <- c("aaa", "bbb", "ccc")
> m <- rep(NA, 3)
> 
> for (i in 1:length(varn)) m[i] <- mean(varn[i])  # wrong

....mean(get(varn[i])).

However, the preferred method might be

sapply(list(aaa,bbb,ccc),var)

or

sapply(data.frame(aaa,bbb,ccc),var)

(which of course only works when the vectors have the same length, and
reminds me that one of the bricks in my road to Hell is to write an
nlist() which supplies element names like data.frame does...)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From kwan022 at stat.auckland.ac.nz  Thu May  1 19:32:23 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Fri, 2 May 2003 05:32:23 +1200 (NZST)
Subject: [R] var[i]
In-Reply-To: <3EB1534F.9050600@ceam.es>
Message-ID: <Pine.LNX.4.44.0305020530270.29722-100000@stat61.stat.auckland.ac.nz>

Hi,

If I understand you correctly, then:

On Thu, 1 May 2003, juli g. pausas wrote:

> How could I use variables in a loop that their names are in a vector? 
> For example:
> 
> aaa <- 1:10
> bbb <- aaa*2
> ccc <- aaa+bbb
> 
> varn <- c("aaa", "bbb", "ccc")

Take a look at your varn here.  You'll notice :
> varn
[1] "aaa" "bbb" "ccc"

> m <- rep(NA, 3)
> 
> for (i in 1:length(varn)) m[i] <- mean(varn[i])  # wrong

You can probably do this as a list:
aaa <- 1:10
bbb <- aaa*2
ccc <- aaa+bbb

varn <- list(aaa, bbb, ccc)
m <- rep(NA, 3)

for (i in 1:length(varn)) m[i] <- mean(varn[[i]])  # wrong   

m

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)


From cschuste at nd.edu  Thu May  1 20:41:19 2003
From: cschuste at nd.edu (Christof Schuster)
Date: Thu, 1 May 2003 13:41:19 -0500 (EST)
Subject: [R] factanal
Message-ID: <Pine.SOL.4.10.10305011330010.20775-100000@shakespeare.helios.nd.edu>


# I have a question about how factanal is calculating the regression factor
# scores based on an oblique rotation (promax) of the factors. 
#
# As is explained in the help file, regression factor scores are
# obtained as
#
#  hat f = Lambda' Sigma^-1 x
#
# However, according to Harman's "Modern Factor Analysis" (e.g. second
# edition, pp. 351-352) the formula is 
#
#  hat f = Phi Lambda' Sigma^-1 x,
#
# where Phi is the correlation between factors. Of course, for orthogonal 
# rotations the formulas are identical because in this case Phi=I.
#
# Let me illustrate the difference between the formulas numerically:
# X is a data (10x6) data matrix of standardized variables.

"X" <-
structure(c(-0.697, -1.787, 0.206, -0.191, -0.606, 0.171, 1.46, 
-0.639, 0.779, 1.304, -0.7, -1.538, -0.913, -0.43, -0.225, -0.417, 
1.038, 0.888, 1.595, 0.702, -1.268, -2.018, 0.079, 1.074, 0.296, 
-0.62, 0.532, 0.306, 0.775, 0.844, -2.245, 0.486, 0.801, 0.002, 
-0.602, -0.519, 1.261, -0.372, 0.499, 0.688, -1.973, -0.163, 
0.964, -0.071, -0.99, 0.694, -0.364, -0.305, 1.215, 0.992, -1.674, 
-0.065, 1.043, -0.159, -1.174, 0.648, 0.848, 1.101, -1.055, 0.488
), .Dim = c(10, 6))

library(mva)
res <- factanal(X, factors=2, rotation="promax", scores="regression")
round(res$scores, 3)

# yields the factor scores:
#        Factor1 Factor2
#   [1,]   0.031  -2.137
#   [2,]  -2.319   1.141
#   [3,]  -0.899   1.375
#   [4,]   0.098  -0.058
#   [5,]   0.215  -0.943
#   [6,]  -0.402   0.218
#   [7,]   0.828   0.488
#   [8,]   0.364  -0.364
#   [9,]   1.313  -0.204
#  [10,]   0.771   0.485

# Now, calculating the factor scores using the first formula I obtain
# (up to rounding differences) the same result
R <- cor(X)
L <- loadings(res)
round(t(t(L) %*% solve(R) %*% t(X)), 3)

# However, if I use the following SAS commands using the exactly the
# same data

# data x;
#    input x1 x2 x3 x4 x5 x6;
#    cards;
# -0.697 -0.700 -1.268 -2.245 -1.973 -1.674
# -1.787 -1.538 -2.018  0.486 -0.163 -0.065
#  0.206 -0.913  0.079  0.801  0.964  1.043
# -0.191 -0.430  1.074  0.002 -0.071 -0.159
# -0.606 -0.225  0.296 -0.602 -0.990 -1.174
#  0.171 -0.417 -0.620 -0.519  0.694  0.648
#  1.460  1.038  0.532  1.261 -0.364  0.848
# -0.639  0.888  0.306 -0.372 -0.305  1.101
#  0.779  1.595  0.775  0.499  1.215 -1.055
#  1.304  0.702  0.844  0.688  0.992  0.488
# ;
#
# proc factor data=x corr method=ml nfactors=2 prerotate=varimax rotate=promax out=fscores score;
# run;
#
# proc print data=fscores;
#   var factor1 factor2;
# run;
#
# The factor scores one obtains:
#     Obs     Factor1     Factor2
#       1    -1.00830    -2.12208
#       2    -1.76352     0.09283
#       3    -0.23031     0.96792
#       4     0.06982    -0.01378
#       5    -0.24412    -0.84552
#       6    -0.29643     0.03564
#       7     1.06502     0.86195
#       8     0.18723    -0.19927
#       9     1.21346     0.38882
#      10     1.00714     0.83347

# Clearly, these scores are very different from the ones factanal
# produced. However, because the promax-function does not calculate
# the Phi-matrix, one cannot readily calculate the factor scores
# according to the second formula from Harman's book.

# However, one may calculate Phi in the following way using varimax as
# the prerotation:
res <- factanal(X, factors=2, rotation="none")
vm <- varimax(loadings(res))
pm <- promax(loadings(vm), m=3) # m=3 is default in SAS
L <- loadings(pm)

# Calculate the "normalized oblique transformation matrix" (label from
# SAS output)
A <- vm$rotmat %*% pm$rotmat

# Calculate the "inter-factor correlation matrix" (label from SAS output
Phi <- solve(t(A) %*% A)

# Calculating regression factor scores according to the second formula
# as
t(Phi %*% t(L) %*% solve(R) %*% t(X))
# yields scores that are pretty close, although not identical to the 
# SAS factor scores. Specifically the scores one obtains are
#
# [1,] -0.95635745 -2.12230012
# [2,] -1.79135903  0.08454732
# [3,] -0.26372828  0.96485151
# [4,]  0.07127957 -0.01351224
# [5,] -0.22118873 -0.84499215
# [6,] -0.30174316  0.03427963
# [7,]  1.05315509  0.86483663
# [8,]  0.19603657 -0.19803312
# [9,]  1.21844347  0.39342954
#[10,]  0.99537610  0.83626200

# So, I guess, I am wondering does factanal calculate the
# regression factor scores correctly? Maybe I am missing
# something. Any comments will be highly appreciated.

# Thanks,
#   Christof Schuster

Christof Schuster
University of Notre Dame
Department of Psychology                       
103 Haggar Hall
Notre Dame, IN 46556

Tel: (574) 631-5473    email: cschuste at nd.edu
Fax: (574) 631-8883    www.nd.edu/~cschuste


From Guangchun.Song at stjude.org  Thu May  1 21:03:17 2003
From: Guangchun.Song at stjude.org (Song, Guangchun)
Date: Thu, 1 May 2003 14:03:17 -0500 
Subject: [R] What' wrong?
Message-ID: <A1DAD6685C12D511B20F0003472515138E6971@sjmemexc3.stjude.org>


I try to do single proportion test on my category data.  Here is my R
script:


library("ctest")

catSignifTest <- function( catFile ) {
    ###############################################################
    ##  Get the data sets from text file
	catData <- read.table( catFile )
	
    
	ncols <- length(catData)
	nrows <- length(catData[,1])
	ncol1 <- ncols - 1
	
	probeNbr <- catData[1,]
	Achip <- catData[,ncols]
	
	for ( row in 2:nrows ) {
		prob <- Achip[ row ] / Achip[ 1 ]
      	if ( prob <= 0 ) prob <- 0.0000001
      	if ( prob >= 1 ) prob <- 0.9999999
      	chip <- catData[row,]
		for ( col in 1:ncol1 )	{
			succ <- chip[col]
			trial <- probeNbr[col]
			print ( c(row, col, succ, trial, prob ) )
      		mytest <- prop.test( succ, trial, prob ) 
      		result [ row, col ] = mytest$p.value
      	}
	}	
	print ( result )
}

Here are the result:

> source("D:/song/R/Test/AML/test_GO_probes.R")
> catSignifTest( 'GOcat.txt')
[[1]]
[1] 2

[[2]]
[1] 1

$V1
[1] 6

$V1
[1] 30

[[5]]
[1] 0.1539431

Error in min(..., na.rm = na.rm) : invalid "mode" of argument
>

Could somebody tell me what's wrong?


Thanks.

Guangchun


From tblackw at umich.edu  Thu May  1 21:15:32 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Thu, 1 May 2003 15:15:32 -0400 (EDT)
Subject: [R] acf() with two df?
In-Reply-To: <3EB028A1.2A44F510@biozentrum.uni-wuerzburg.de>
Message-ID: <Pine.SOL.4.44.0305011356260.27456-100000@timepilot.gpcc.itd.umich.edu>

By way of clarifying an earlier request to this list,
on Wed, 30 Apr 2003, Martin Wegmann wrote:

> I have two kind of datasets, 1. environmental variables
> (several data frames) and  2. one data frame with the
> depending data (zoological data).  All of them are sampled
> on 200 plots, therefore the dataframes correspond column by
> column (not row by row).
>
> variable 1
>          plot 1 plot 2.....
> 1999   ....    ....
> 2000
> 2001
> ...
>
> variable 2
> ....
>
> and another data frame with the diversity and abundance etc. of
> animals for each plot:
>
>         plot 1 plot 2 ...
> div.     ...    ....
> abu.
> ..
>
> and I would like to know the p value of the whole animal data frame
> (not separated by plots [columns]) to each variable data frame.
> I thought that cancor() could do the job but that requires two df
> with matching rows and columns.

Martin  -

My present understanding of the data set is this:  for
each of 200 geographic sampling locations there is a short
time series of historical weather data on several variables
- I'll guess annual rainfall, minimum temperature, maximum
temperature, number of days of sunlight per year, etc. -
and there are many measured outcome variables from a field
study of the diversity and abundance of animal species on
that plot.

Given this understanding, I would regard this as primarily
a regression or correlation problem:  How are the weather
data related to the animal data ?   or   How well can we
predict the animal diversity (say) on each plot from the
climate characteristics of that plot ?  I think the time
series aspects of the climate data are secondary.

I would begin any data analysis by looking at scatterplots
of all the measured outcome data.  See function  pairs().
This function expects a matrix or data frame in which each
plot is one row, and each outcome variable is one column.
This is the transpose of the data frame you described, so
(if "animals" is the name of the data frame described above)
a command like

pairs(t(as.matrix(animals)))

should do the job.  These scatterplots are much easier to
look at than the corresponding correlation matrix.  This
will give an overview of the patterns present in the data
and maybe it will suggest appropriate further analyses.

When it's time to include the weather data, I would initially
do the following.  For each weather variable at each geographic
location, summarize the historical record by four characteristics:
its mean, trend, quadratic term and residual standard deviation.

Then examine scatterplots of the means of all weather variables
versus animal variables, or the trend of all weather variables
versus animal variables, etc.  This will treat the entire data
set as essentially a regression problem.

I know that I am taking a BIG risk by offering data analysis
suggestions in a public forum !  Other people will have quite
different preferences and strongly held opinions about them.
So be it.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -


From tblackw at umich.edu  Thu May  1 21:34:29 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Thu, 1 May 2003 15:34:29 -0400 (EDT)
Subject: [R] What' wrong?
In-Reply-To: <A1DAD6685C12D511B20F0003472515138E6971@sjmemexc3.stjude.org>
Message-ID: <Pine.SOL.4.44.0305011528010.27456-100000@timepilot.gpcc.itd.umich.edu>


Two suggestions:

(1) Initialize "result" before the loop by

result <- matrix(0, nrows, ncols)

(2) Truncate the values in "prob" by

prob <- ifelse(prob <= 0, 0.0000001,
	ifelse(prob >= 1, 0.9999999, prob))

HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Thu, 1 May 2003, Song, Guangchun wrote:

>
> I try to do single proportion test on my category data.  Here is my R
> script:
>
>
> library("ctest")
>
> catSignifTest <- function( catFile ) {
>     ###############################################################
>     ##  Get the data sets from text file
> 	catData <- read.table( catFile )
>
>
> 	ncols <- length(catData)
> 	nrows <- length(catData[,1])
> 	ncol1 <- ncols - 1
>
> 	probeNbr <- catData[1,]
> 	Achip <- catData[,ncols]
>
> 	for ( row in 2:nrows ) {
> 		prob <- Achip[ row ] / Achip[ 1 ]
>       	if ( prob <= 0 ) prob <- 0.0000001
>       	if ( prob >= 1 ) prob <- 0.9999999
>       	chip <- catData[row,]
> 		for ( col in 1:ncol1 )	{
> 			succ <- chip[col]
> 			trial <- probeNbr[col]
> 			print ( c(row, col, succ, trial, prob ) )
>       		mytest <- prop.test( succ, trial, prob )
>       		result [ row, col ] = mytest$p.value
>       	}
> 	}
> 	print ( result )
> }
>
> Here are the result:
>
> > source("D:/song/R/Test/AML/test_GO_probes.R")
> > catSignifTest( 'GOcat.txt')
> [[1]]
> [1] 2
>
> [[2]]
> [1] 1
>
> $V1
> [1] 6
>
> $V1
> [1] 30
>
> [[5]]
> [1] 0.1539431
>
> Error in min(..., na.rm = na.rm) : invalid "mode" of argument
> >
>
> Could somebody tell me what's wrong?
>
>
> Thanks.
>
> Guangchun
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From rgrubbfink at cox.net  Thu May  1 21:46:27 2003
From: rgrubbfink at cox.net (rgrubbfink@cox.net)
Date: Thu, 1 May 2003 15:46:27 -0400
Subject: [R] ld Problem with file libRlapack.so
Message-ID: <20030501194627.UZKU23505.lakemtao06.cox.net@smtp.central.cox.net>

While compiling R 1.7.0 on AIX4.3.3, I ran into a problem with the libRlapack.so file. The following command, as put out by the file src/modules/lapack/Makefile, would not work (I reformatted the command to make it fit in 72 columns):

/acct/rlg0301/bin/gcc -Wl,-bM:SRE -Wl,-H512 -Wl,-T512 \ -Wl,-bnoentry -Wl,-bexpall -Wl,-bI:../../../etc/R.exp \ -L/usr/local/lib -o lapack.so \ -Wl,-bI:../../../etc/Rlapack.exp Lapack.lo rgeev.lo \
rsyev.lo -L../../../bin -lRlapack -L/usr/local/lib \
-L/acct/rlg0301/lib/gcc-lib/rs6000-ibm-aix4.3.3.0/2.95.3 \
-L/acct/rlg0301/lib -lg2c -lm \
/acct/rlg0301/lib/gcc-lib/rs6000-ibm-aix4.3.3.0/2.95.3/libgcc.a \
-lg -lreadline -ldl -ltermcap -lm -lc

gcc (2.95) uses the AIX ld command, and the loader complained that it could "...not find or open library file -l Rlapack". But libRlapack.so existed in the proper directory. After much reading of the ld man page, the only thing I could figure out was that perhaps ld was not being run in the dynamic mode. I hacked a solution by creating a symbolic link, libRlapack.a in the same directory as, and pointing to libRlapack.so. I was able to finish the compilation and installation of R, but I have not yet done any tests to see if the lapack routines work properly.

Does anybody know why the loader was not able to find the Rlapack library? Is there a better solution than the one I used (besides using something other than AIX :-)?

Thanks


From maechler at stat.math.ethz.ch  Thu May  1 21:54:58 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 1 May 2003 21:54:58 +0200
Subject: [R] Test statistic for Spearman correlation
In-Reply-To: <x2n0i6k2ij.fsf@biostat.ku.dk>
References: <Pine.SOL.4.44.0305011128550.8363-100000@asteroids.gpcc.itd.umich.edu>
	<x2n0i6k2ij.fsf@biostat.ku.dk>
Message-ID: <16049.31634.243996.727963@gargle.gargle.HOWL>

>>>>> "PD" == Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk>
>>>>>     on 01 May 2003 19:20:04 +0200 writes:

    PD> Thomas W Blackwell <tblackw at umich.edu> writes:
    >> Brett -
    >> 
    >> I can give you a further reference, but you may not find
    >> it much help !
    >> 
    >> E. G. Olds.  Distribution of sums of squares of rank
    >> differences for small numbers of individuals.  Annals of
    >> Mathematical Statistics, v.9, pp. 133-148, 1938.
    >> 
    >> My source says that "Olds (1938) tabulated the exact
    >> distribution of a quantity S related to rho by the
    >> equation
    >> 
    >> R = 1 - 6 * S / (n^3 - n) ."
    >> 
    >> Olds must have been using a Comptometer or a Marchant
    >> calculator, so presumably, this construct guarantees
    >> always to be an integer.  Algorithm AS 89 is certainly
    >> available on line from Statlib.

    PD> The title of Olds paper might have given you a hint:

    >> x <- rank(rnorm(10)) y <- rank(rnorm(10)) cor(x,y)
    PD> [1] -0.2242424
    >> 990/6*(1-cor(x,y))
    PD> [1] 202
    >> sum((x-y)^2)
    PD> [1] 202

    PD> BTW, the identity breaks down when there are ties,
    PD> something that we probably ought to look into at some
    PD> point. The code does say that the p values may be
    PD> incorrect, but I suspect they may be more incorrect than
    PD> need be.

Yes, I'm quite sure of this (both/all statements).

Note that I still have uncommitted fixes to the problem large n.
For the "proper" fix, I did get interested, and during the last weeks have spent quite
some time reading several of the original papers on these.
I also found that there now are much better (i.e. faster)
methods available for exact calculation of P-values.

Currently I plan for 1.7.1 to have an improvement here, and for
1.8.0 to have more.

Martin


From tblackw at umich.edu  Fri May  2 00:12:47 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Thu, 1 May 2003 18:12:47 -0400 (EDT)
Subject: [R] What' wrong?
In-Reply-To: <A1DAD6685C12D511B20F0003472515138E6971@sjmemexc3.stjude.org>
Message-ID: <Pine.SOL.4.44.0305011705590.22493-100000@mspacman.gpcc.itd.umich.edu>


Please excuse my earlier suggestions.  I misunderstood
your code.  (That's always a problem when trying to debug
someone else's code.)

Now I see that "prob" is defined initially as a scalar,
and the same value will be used  (ncols - 1)  times, so
the  ifelse(...ifelse(...))  syntax is completely
unnecessary.

Failure to initialize "result" outside the loop SEEMS
not to cause a problem.  Assigning to "result" is the
only place where the code uses "=" as an assignment
operator.  Read the help for "=" and see whether you
think there's a scoping problem here.

In order to get the statement

	print ( c(row, col, succ, trial, prob ) )

to print as a vector rather than as a list, one would
assign both  probeNbr  and  chip  as

	probeNbr <- as.vector(catData[1, ])
	  chip   <- as.vector(catData[row, ]) ,

And the error message "invalid mode ..." suggests that
the difference between a vector and a list might be
what it is complaining about.  But it DOESN'T explain
to me why it got through the first iteration okay.
So to me, the mystery remains.

My own code for this would look quite different.
I truly don't understand what problem you are trying
to solve, so this may not even do what you intend,
but roughly, something like:

  ncols <- dim(catData)[2]
  nrows <- dim(catData)[1]
  ncol1 <- ncols - 1

  trial <- t(matrix(unlist(catData[1, 1:ncol1]),
	 	    ncol1, nrows - 1, byrow=FALSE))
  succ  <- unlist(catData[-1, 1:ncol1])
  temp  <- catData[-1, ncols] / catData[ 1, ncols]
  temp  <- ifelse(temp <= 0, 0.00000001,
	   ifelse(temp >= 1, 0.99999999, temp))
  prob  <- rep(temp, ncol1)
 result <- matrix(prop.test(succ, trial, prob)$p.value,
	 	 	  nrows - 1, ncol1, byrow=FALSE)
 dimnames(result) <- list(rownames(catData)[-1],
	 	 	     names(catData)[-ncols])

Now, I surely don't guarantee that this will do what you
want it to, but that's the style I would use:  a single
call to  prop.test()  with three long vectors as the
arguments, then munge the result into the shape you
want at the end.  No loops.

HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Thu, 1 May 2003, Song, Guangchun wrote:

> I try to do single proportion test on my category data.  Here is my R
> script:
>
> library("ctest")
>
> catSignifTest <- function( catFile ) {
>     ###############################################################
>     ##  Get the data sets from text file
> 	catData <- read.table( catFile )
>
> 	ncols <- length(catData)
> 	nrows <- length(catData[,1])
> 	ncol1 <- ncols - 1
>
> 	probeNbr <- catData[1,]
> 	Achip <- catData[,ncols]
>
> 	for ( row in 2:nrows ) {
> 		prob <- Achip[ row ] / Achip[ 1 ]
>       	if ( prob <= 0 ) prob <- 0.0000001
>       	if ( prob >= 1 ) prob <- 0.9999999
>       	chip <- catData[row,]
> 		for ( col in 1:ncol1 )	{
> 			succ <- chip[col]
> 			trial <- probeNbr[col]
> 			print ( c(row, col, succ, trial, prob ) )
>       		mytest <- prop.test( succ, trial, prob )
>       		result [ row, col ] = mytest$p.value
>       	}
> 	}
> 	print ( result )
> }
>
> Here are the result:
>
> > source("D:/song/R/Test/AML/test_GO_probes.R")
> > catSignifTest( 'GOcat.txt')
> [[1]]
> [1] 2
>
> [[2]]
> [1] 1
>
> $V1
> [1] 6
>
> $V1
> [1] 30
>
> [[5]]
> [1] 0.1539431
>
> Error in min(..., na.rm = na.rm) : invalid "mode" of argument
>
> Could somebody tell me what's wrong?
>
> Thanks.
>
> Guangchun


From JACQUELINE.LAW at ROCHE.COM  Fri May  2 02:45:26 2003
From: JACQUELINE.LAW at ROCHE.COM (Law, Jacqueline {Regu~Pleasanton})
Date: Thu, 01 May 2003 20:45:26 -0400
Subject: [R] Probit Analysis
Message-ID: <0F58D4CA9429D311B70A0090272A644611D9D167@rpbmsem1.ple.roche.com>

How can the CI be obtained using the Fieller's method?

- Jacqueline


From jun at galton.uchicago.edu  Fri May  2 04:26:46 2003
From: jun at galton.uchicago.edu (Mikyoung Jun)
Date: Thu, 1 May 2003 21:26:46 -0500 (CDT)
Subject: [R] question about image command
Message-ID: <Pine.LNX.4.44.0305012118250.17034-100000@paolu.uchicago.edu>

Hello,

I have a question about image command. When you draw a image plot, and 
let's say we use gray scale. then how can I generate a little bar next to 
the plot which shows the grey levels and the values which corresponds to 
the grey level? ( it doesn't matter whether I am using grey level or not. 
It could be just any colors...)

The only way that I can do right now is overlaying contour plot on the 
image plot...

Thank you!


From s195404 at student.uq.edu.au  Fri May  2 04:48:15 2003
From: s195404 at student.uq.edu.au (Andrew C. Ward)
Date: Fri,  2 May 2003 02:48:15 +0000
Subject: [R] question about image command
In-Reply-To: <Pine.LNX.4.44.0305012118250.17034-100000@paolu.uchicago.edu>
References: <Pine.LNX.4.44.0305012118250.17034-100000@paolu.uchicago.edu>
Message-ID: <1051843695.3eb1dc6feeaf4@my.uq.edu.au>

I wonder if filled.contour() does what you want:
   example(filled.contour)


Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au

Quoting Mikyoung Jun <jun at galton.uchicago.edu>:

> Hello,
> 
> I have a question about image command. When you draw a image plot,
> and 
> let's say we use gray scale. then how can I generate a little bar
> next to 
> the plot which shows the grey levels and the values which
> corresponds to 
> the grey level? ( it doesn't matter whether I am using grey level
> or not. 
> It could be just any colors...)
> 
> The only way that I can do right now is overlaying contour plot on
> the 
> image plot...
> 
> Thank you!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From deepayan at stat.wisc.edu  Fri May  2 04:50:27 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 1 May 2003 21:50:27 -0500
Subject: [R] question about image command
In-Reply-To: <Pine.LNX.4.44.0305012118250.17034-100000@paolu.uchicago.edu>
References: <Pine.LNX.4.44.0305012118250.17034-100000@paolu.uchicago.edu>
Message-ID: <200305012150.27143.deepayan@stat.wisc.edu>


There are several options, the simplest is to use filled.contour() instead of 
image(). The output is slightly different, but that usually doesn't matter.

On Thursday 01 May 2003 09:26 pm, Mikyoung Jun wrote:
> Hello,
>
> I have a question about image command. When you draw a image plot, and
> let's say we use gray scale. then how can I generate a little bar next to
> the plot which shows the grey levels and the values which corresponds to
> the grey level? ( it doesn't matter whether I am using grey level or not.
> It could be just any colors...)
>
> The only way that I can do right now is overlaying contour plot on the
> image plot...
>
> Thank you!
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From rpeng at stat.ucla.edu  Fri May  2 05:02:58 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Thu, 1 May 2003 20:02:58 -0700 (PDT)
Subject: [R] question about image command
In-Reply-To: <Pine.LNX.4.44.0305012118250.17034-100000@paolu.uchicago.edu>
Message-ID: <Pine.GSO.4.10.10305011954010.6998-100000@quetelet.stat.ucla.edu>

This is a regularly asked question and the solutions are varied.  The
default image() command does not place a legend on the plot.  There are 
three options that I know of:

1.  the image.plot()  function in the `fields' package.  This function has
similar syntax as image() but the resulting image can be difficult to
annotate sometime.

2.  the filled.contour() function in the `base' package produces nice
images but read the help page carefully if you want to add things
(text, points, etc) to the plot.

3.  the levelplot() function in the `lattice' package.  

The problem with 1 and 2 is that you cannot put more than one image on a
device because they use the layout() function.  levelplot() allows you to
put multiple images on the same device using a common legend.  Note that
levelplot() takes different arguments from image.plot() and
filled.contour().

-roger
_______________________________
UCLA Department of Statistics
http://www.stat.ucla.edu/~rpeng

On Thu, 1 May 2003, Mikyoung Jun wrote:

> Hello,
> 
> I have a question about image command. When you draw a image plot, and 
> let's say we use gray scale. then how can I generate a little bar next to 
> the plot which shows the grey levels and the values which corresponds to 
> the grey level? ( it doesn't matter whether I am using grey level or not. 
> It could be just any colors...)
> 
> The only way that I can do right now is overlaying contour plot on the 
> image plot...
> 
> Thank you!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From r.hankin at auckland.ac.nz  Fri May  2 06:28:17 2003
From: r.hankin at auckland.ac.nz (Robin Hankin)
Date: Fri, 2 May 2003 16:28:17 +1200
Subject: [R] letters to numbers conversion
Message-ID: <200305020428.h424SHMj011177@r.hankin.sges.auckland.ac.nz>

Hello List

How do I turn

R> simple.example.alphabetic
     [,1] [,2] [,3]
[1,] "a"  "b"  "c" 
[2,] "d"  "e"  "f" 
[3,] "g"  "h"  "i" 

into

R> simple.example.numeric
     [,1] [,2] [,3]
[1,]    1    2    3
[2,]    4    5    6
[3,]    7    8    9

[ie "a" becomes 1, ..., "z" becomes 26]
?






-- 

Robin Hankin, Lecturer,
School of Geography and Environmental Science
Tamaki Campus
Private Bag 92019 Auckland
New Zealand

r.hankin at auckland.ac.nz
tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042


From s195404 at student.uq.edu.au  Fri May  2 06:42:41 2003
From: s195404 at student.uq.edu.au (Andrew C. Ward)
Date: Fri,  2 May 2003 04:42:41 +0000
Subject: [R] letters to numbers conversion
In-Reply-To: <200305020428.h424SHMj011177@r.hankin.sges.auckland.ac.nz>
References: <200305020428.h424SHMj011177@r.hankin.sges.auckland.ac.nz>
Message-ID: <1051850561.3eb1f7413b6f8@my.uq.edu.au>

How about the following?
   t1 <- matrix(letters[1:9], nrow=3, byrow=TRUE)
   t1
   t2 <- t(apply(t1, 1, function(x) match(x, letters)))
   t2


Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au
  
   
Quoting Robin Hankin <r.hankin at auckland.ac.nz>:

> Hello List
> 
> How do I turn
> 
> R> simple.example.alphabetic
>      [,1] [,2] [,3]
> [1,] "a"  "b"  "c" 
> [2,] "d"  "e"  "f" 
> [3,] "g"  "h"  "i" 
> 
> into
> 
> R> simple.example.numeric
>      [,1] [,2] [,3]
> [1,]    1    2    3
> [2,]    4    5    6
> [3,]    7    8    9
> 
> [ie "a" becomes 1, ..., "z" becomes 26]
> ?
> 
> 
> 
> 
> 
> 
> -- 
> 
> Robin Hankin, Lecturer,
> School of Geography and Environmental Science
> Tamaki Campus
> Private Bag 92019 Auckland
> New Zealand
> 
> r.hankin at auckland.ac.nz
> tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From p.connolly at hortresearch.co.nz  Fri May  2 06:57:23 2003
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Fri, 2 May 2003 16:57:23 +1200
Subject: [R] letters to numbers conversion
In-Reply-To: <1051850561.3eb1f7413b6f8@my.uq.edu.au>
References: <200305020428.h424SHMj011177@r.hankin.sges.auckland.ac.nz>
	<1051850561.3eb1f7413b6f8@my.uq.edu.au>
Message-ID: <20030502045723.GS14368@hortresearch.co.nz>

On Fri, 02-May-2003 at 04:42AM +0000, Andrew C. Ward wrote:

|> How about the following?
|>    t1 <- matrix(letters[1:9], nrow=3, byrow=TRUE)
|>    t1
|>    t2 <- t(apply(t1, 1, function(x) match(x, letters)))
|>    t2

Or slightly more simply

t2 <- apply(t1, 2, function(x) match(x, letters))

Might not work for non-unique letters.

best

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~


From tplate at blackmesacapital.com  Fri May  2 07:08:48 2003
From: tplate at blackmesacapital.com (Tony Plate)
Date: Thu, 01 May 2003 23:08:48 -0600
Subject: [R] letters to numbers conversion
In-Reply-To: <200305020428.h424SHMj011177@r.hankin.sges.auckland.ac.nz>
Message-ID: <5.2.1.1.2.20030501225335.03904d48@mailhost.blackmesacapital.com>

If you're looking for something that works with matrices or arrays you 
could use the following.  Note that you would want to substitute LETTERS 
for letters if your original data was in uppercase.  The stuff with 
dimnames isn't necessary for this example, but it don't hurt and it will 
preserve dimnames when the original data has them.

 > x <- matrix(letters[1:9],ncol=3)
 > x
      [,1] [,2] [,3]
[1,] "a"  "d"  "g"
[2,] "b"  "e"  "h"
[3,] "c"  "f"  "i"
 > match(x, letters)
[1] 1 2 3 4 5 6 7 8 9
 > array(match(x, letters), dim=dim(x), dimnames=dimnames(x))
      [,1] [,2] [,3]
[1,]    1    4    7
[2,]    2    5    8
[3,]    3    6    9
 >

hope this helps,

Tony Plate

At Friday 04:28 PM 5/2/2003 +1200, Robin Hankin wrote:
>Hello List
>
>How do I turn
>
>R> simple.example.alphabetic
>      [,1] [,2] [,3]
>[1,] "a"  "b"  "c"
>[2,] "d"  "e"  "f"
>[3,] "g"  "h"  "i"
>
>into
>
>R> simple.example.numeric
>      [,1] [,2] [,3]
>[1,]    1    2    3
>[2,]    4    5    6
>[3,]    7    8    9
>
>[ie "a" becomes 1, ..., "z" becomes 26]
>?
>
>
>
>
>
>
>--
>
>Robin Hankin, Lecturer,
>School of Geography and Environmental Science
>Tamaki Campus
>Private Bag 92019 Auckland
>New Zealand
>
>r.hankin at auckland.ac.nz
>tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From ripley at stats.ox.ac.uk  Fri May  2 08:50:04 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 2 May 2003 07:50:04 +0100 (BST)
Subject: [R] letters to numbers conversion
In-Reply-To: <5.2.1.1.2.20030501225335.03904d48@mailhost.blackmesacapital.com>
Message-ID: <Pine.LNX.4.44.0305020746180.2930-100000@gannet.stats>

On Thu, 1 May 2003, Tony Plate wrote:

> If you're looking for something that works with matrices or arrays you 
> could use the following.  Note that you would want to substitute LETTERS 
> for letters if your original data was in uppercase.  The stuff with 
> dimnames isn't necessary for this example, but it don't hurt and it will 
> preserve dimnames when the original data has them.
> 
>  > x <- matrix(letters[1:9],ncol=3)
>  > x
>       [,1] [,2] [,3]
> [1,] "a"  "d"  "g"
> [2,] "b"  "e"  "h"
> [3,] "c"  "f"  "i"
>  > match(x, letters)
> [1] 1 2 3 4 5 6 7 8 9
>  > array(match(x, letters), dim=dim(x), dimnames=dimnames(x))
>       [,1] [,2] [,3]
> [1,]    1    4    7
> [2,]    2    5    8
> [3,]    3    6    9

A useful trick here is to assign to foo[] as in

> y <- x; mode(y) <- "numeric"; y[] <- match(x, letters)
> y
     [,1] [,2] [,3]
[1,]    1    4    7
[2,]    2    5    8
[3,]    3    6    9

That carries over all relevant attributes, so works for vectors, matrices, 
arrays ....  (Often you don't need to change the mode.)


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From roger at ysidro.econ.uiuc.edu  Fri May  2 12:49:30 2003
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Fri, 2 May 2003 05:49:30 -0500 (CDT)
Subject: [R] stepfuns:  R^2 -> R
Message-ID: <Pine.SOL.4.30.0305020537450.9685-100000@ysidro.econ.uiuc.edu>


Does anyone have any suggestions on perspective plotting of piecewise constant functions?
Ideally, I would like something like plot.stepfun for functions that are piecewise
constant on polygons.   Even pointers to non-R strategies would be welcome at this stage.

url:	www.econ.uiuc.edu	Roger Koenker		Dept. of Economics UCL,
email	rkoenker at uiuc.edu	Department of Economics Drayton House,
vox: 	217-333-4558		University of Illinois	30 Gordon St,
fax:   	217-244-6678		Champaign, IL 61820	London,WC1H 0AX, UK


From david.whiting at ncl.ac.uk  Fri May  2 16:20:44 2003
From: david.whiting at ncl.ac.uk (david.whiting@ncl.ac.uk)
Date: Fri, 2 May 2003 14:20:44 +0000
Subject: Sweave (was RE: [R] how to present a table in powerpoint?)
In-Reply-To: <200304291948.h3TJmLPp011300@thorin.ci.tuwien.ac.at>
References: 
	<Pine.LNX.4.44.0304300703400.19732-100000@stat56.stat.auckland.ac.nz>
	<200304291948.h3TJmLPp011300@thorin.ci.tuwien.ac.at>
Message-ID: <20030502142044.GS12170@192.168.57.2>

On Tue, Apr 29, 2003 at 09:48:21PM +0200, Achim Zeileis wrote:
> 
> What hasn't been mentioned explicitely on R-help (as it is very 
> obvious, I suppose) is that you can not only generate reproducible 
> reports using Sweave but also pdf slides for presentations. 

...and I like to use the Prosper class.  It gives you LaTeX quality
formatting of text and mathematical expressions with pretty layouts
and even slide transitions similar to Powerpoint if you want.  

Take a look at:  http://prosper.sourceforge.net/prosper.html

Dave


-- 
Dave Whiting
Dar es Salaam, Tanzania


From dmurdoch at pair.com  Fri May  2 14:09:00 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Fri, 02 May 2003 08:09:00 -0400
Subject: [R] stepfuns:  R^2 -> R
In-Reply-To: <Pine.SOL.4.30.0305020537450.9685-100000@ysidro.econ.uiuc.edu>
References: <Pine.SOL.4.30.0305020537450.9685-100000@ysidro.econ.uiuc.edu>
Message-ID: <jdn4bvsp30mv9be03a6899nmc37e4mfcfc@4ax.com>

On Fri, 2 May 2003 05:49:30 -0500 (CDT), you wrote:

>
>Does anyone have any suggestions on perspective plotting of piecewise constant functions?
>Ideally, I would like something like plot.stepfun for functions that are piecewise
>constant on polygons.   Even pointers to non-R strategies would be welcome at this stage.

You could use one of the 3D packages.  Daniel Adler and I have agreed
to merge our efforts, but you can get either one now.  Mine is
available from <http://www.stats.uwo.ca/faculty/murdoch/software> as
djmrgl.zip, his is available at
<http://wsopuppenkiste.wiso.uni-goettingen.de/~dadler/rgl>.  With
mine, you could use a function like persp() after evaluating the
function on a grid.  You could get a somewhat better looking result by
drawing the surface explicitly as triangles or quadrilaterals; that's
why my hist3d function does.

One disadvantage to both of these packages is that they only produce
bitmapped graphics, so the results don't look sharp if printed.  The
solution is to produce really big bitmaps.

Duncan Murdoch


From TyagiAnupam at aol.com  Fri May  2 14:42:07 2003
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Fri, 2 May 2003 08:42:07 EDT
Subject: Sweave (was RE: [R] how to present a table in powerpoint?)
Message-ID: <1e9.7d5c222.2be3c19f@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030502/8f9590cb/attachment.pl

From chrysopa at insecta.ufv.br  Fri May  2 15:32:22 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Fri, 2 May 2003 10:32:22 -0300
Subject: [R]  How to calculate the x to assymptotic value and curve
	inflection .
In-Reply-To: <6rvfwvdai5.fsf@bates4.stat.wisc.edu>
References: <200304301541.21103.chrysopa@insecta.ufv.br>
	<6rvfwvdai5.fsf@bates4.stat.wisc.edu>
Message-ID: <200305021021.32460.chrysopa@insecta.ufv.br>

Sorry, my answer is a bit confused.

I try to explain.

look this code:

> curve(115.251 - 118.69 * exp(-0.123517*x),from=0,to=100)
> lines(c(75,75),y=c(-10,115.251),col="red")
> lines(c(-10,75),y=c(115.251,115.251),col="red")
> lines(c(20,20),y=c(-10,105),col="blue")
> lines(c(-10,20),y=c(105,105),col="blue")

All values of this points are fictition, only curve values are real and the y 
assyntotic value.

in red is the  y assyntotic and your minimal x, the first value of x that y is  
assyntotic value.
The y assyntotic is easy, it is the first parameter = 115.251. To calculate 
the value of minimal x, I can make a program that increment x, and when y 
value is repeated, I know what is the minimal x. Exist another mean to make 
this?

The another point (blue) is more difficult. I try to explain. The curve  
velocity is very huge before this blue point than after this point. This 
point is something like the inflection point in a X^2 function. Biologically 
this point maybe very important. I try to calculate this with the firt 
derivate, but I cant resolve this.

Exist another solution for this?

Thanks for all

Inte
Ronaldo

Em Qua 30 Abr 2003 16:57, Douglas Bates escreveu:
> I think you need to refine your questions.  To me, the answers to the
> questions that you asked are: "x = Inf (by definition)" and "there
> isn't an inflection point".  I don't think those are what you had in
> mind.
>
> "Ronaldo Reis Jr." <chrysopa at insecta.ufv.br> writes:
> > Hi,
> >
> > I have this non-linear function:
> >
> > y=115.251 - 118.69 * exp(-0.123517*x)
> >
> > I try to discovery the x value for the assyntoptic value of y
> > and the x value where the behavior of curve change, the inflection
> > point.
> >
> > How to make this? Is poss?ble to make this on R?
> >
> > Thanks
> > Ronaldo
>
-- 
A necessidade nunca fez bons neg?cios.
                -- Benjamin Franklin
--
|   // | \\   [*****************************][*******************]
|| ( ?   ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|      V      [UFV/DBA-Entomologia          ][HD: 30 + 10 Gb     ]
||  /     \   [36571-000 Vi?osa - MG        ][RAM: 128 Mb        ]
|  /(.''`.)\  [Fone: 31-3899-2532           ][Video: SiS620-8Mb  ]
||/(: :'  :)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (`. `'` ) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( `-  )   [*****************************][*******************]
||| _/   \_Powered by GNU/Debian W/Sarge D+ || Lxuser#: 205366


From macq at llnl.gov  Fri May  2 16:19:43 2003
From: macq at llnl.gov (Don MacQueen)
Date: Fri, 2 May 2003 07:19:43 -0700
Subject: [R-gui] Re: [R] Feedback about SciViews?
In-Reply-To: 
 <Pine.LNX.4.21.0305011033550.31070-100000@dollis-hill.inpharmatica.co.uk>
References: 
 <Pine.LNX.4.21.0305011033550.31070-100000@dollis-hill.inpharmatica.co.uk>
Message-ID: <p05210601bad82c53e6d8@[128.115.153.6]>

At 11:02 AM +0100 5/1/03, Luke Whitaker wrote:
>On Wed, 30 Apr 2003, A.J. Rossini wrote:
>
>>  "Liaw, Andy" <andy_liaw at merck.com> writes:
>>
>>  >> The GUI itself (i.e., how it operated, what menus were where, etc.)
>>  >> was fine, but it was completely useless for anyone sitting at a
>>  >> remote host, due to dreadful image quality and poor performance when
>>  >> displaying anywhere other than on the console of the machine on which
>>  >> SPlus was actually running.
>>  >
>>  > AFAIK the problem is the X server: it gives you a black window if the X
>>  > display is 16-bit.  If you can live with 8-bit display, the Java GUI will
>>  > work.  It's that way on all Unix (X?) platform.
>>
>>  I thought Java on Linux would do 8 and 24, but not 16?  (or something
>>  truly weird like that).
>>
>>  But that doesn't address performance issues, which still can be pretty
>>  bad.
>
>It seems the problem here is limited to running R remotely. Given
>the power of cheap consumer desktop machines these days, this seems
>to me less of an issue than it used to be. Expensive commercial
>software probably gets run remotely more than it needs to because
>of licensing issues, which obviously don't apply to R.

Not only licensing issues, but platform issues. SPlus doesn't run on 
the platform that most of us here in my department have on our 
desktops.

That's not the case with R, thank goodness. But there are other 
factors, such as administration and maintenance. With each new 
version of R comes the job of installing it. Will that be 10 
installations or one? Running remotely on a server it's just one, and 
that is a considerable time savings.

-Don

>
>If the GUI can be cleanly split from the compute engine of R, then
>it should be quite easy to get the GUI running locally even if the
>compute engine is remote - although I re-iterate my question for the
>need to run free software remotely. My very modest desktop machine
>is far more powerfull than the mainframe that I learnt to use SAS
>on, and not so far short of the very expensive file server that I
>use now.
>
>Luke


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA


From mandevip at uaslp.mx  Fri May  2 19:06:07 2003
From: mandevip at uaslp.mx (Peter B. Mandeville)
Date: Fri, 02 May 2003 12:06:07 -0500
Subject: [R] stepAIC/lme (1.6.2)
Message-ID: <5.1.0.14.0.20030502115205.00aa8ec0@uaslp.mx>


Based on the stepAIC help, I have assumed that it only was for lm, aov, and 
glm models. I gather from the following correspondence that it also works 
with lme models.

Thomas Lumley	07:40 a.m. 28/04/03 -0700	 4	Re: [R] stepAIC/lme problem 
(1.7.0 only)
Prof Brian Ripley	04:19 p.m. 28/04/03 +0100	 6	Re: [R] stepAIC/lme problem 
(1.7.0 only)
Prof Brian Ripley	06:09 p.m. 29/04/03 +0100	 6	Re: [R] stepAIC/lme problem 
(1.7.0 only)

I am using windowsXP and have experimented with the data set HR from the 
SASmixed library without success with rw1.6.2.

I would greatly appreciate the correct syntax for version rw1.6.2.

Thank you very much,

Peter B.


From raf1729 at hotmail.com  Fri May  2 19:16:16 2003
From: raf1729 at hotmail.com (R A F)
Date: Fri, 02 May 2003 17:16:16 +0000
Subject: [R] Delete a list component?
Message-ID: <Law11-F92qNBkhbGU1s000207b7@hotmail.com>

Hi, how do I delete a component from a list?

For example, aaa <- list(), aaa$a <- 0, aaa$b <- 0.  How do I remove
aaa$a from aaa so that it's left with aaa$b?

Thanks very much.


From ripley at stats.ox.ac.uk  Fri May  2 19:16:49 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 2 May 2003 18:16:49 +0100 (BST)
Subject: [R] stepAIC/lme (1.6.2)
In-Reply-To: <5.1.0.14.0.20030502115205.00aa8ec0@uaslp.mx>
Message-ID: <Pine.LNX.4.44.0305021811320.5387-100000@gannet.stats>

On Fri, 2 May 2003, Peter B. Mandeville wrote:

> 
> Based on the stepAIC help, I have assumed that it only was for lm, aov, and 
> glm models. 

Even though the help does not mention those classes, and the book actually 
uses stepAIC for coxph?

> I gather from the following correspondence that it also works 
> with lme models.
> 
> Thomas Lumley	07:40 a.m. 28/04/03 -0700	 4	Re: [R] stepAIC/lme problem 
> (1.7.0 only)
> Prof Brian Ripley	04:19 p.m. 28/04/03 +0100	 6	Re: [R] stepAIC/lme problem 
> (1.7.0 only)
> Prof Brian Ripley	06:09 p.m. 29/04/03 +0100	 6	Re: [R] stepAIC/lme problem 
> (1.7.0 only)
> 
> I am using windowsXP and have experimented with the data set HR from the 
> SASmixed library without success with rw1.6.2.
> 
> I would greatly appreciate the correct syntax for version rw1.6.2.

It's as described on the help page, and in Robert Cuffe's example (to 
which those were replies).

data(HR)
fm1HR <- lme(HR ~ Time * Drug + baseHR, data = HR, 
             random = ~ Time | Patient, method = "ML")
stepAIC(fm1HR)

works.  What could be simpler?  (And you can't use method="REML" as this 
is step*AIC*.)

[And that works in 1.7.0 if you update VR.]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ligges at statistik.uni-dortmund.de  Fri May  2 19:25:15 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 02 May 2003 19:25:15 +0200
Subject: [R] Delete a list component?
In-Reply-To: <Law11-F92qNBkhbGU1s000207b7@hotmail.com>
References: <Law11-F92qNBkhbGU1s000207b7@hotmail.com>
Message-ID: <3EB2A9FB.3000906@statistik.uni-dortmund.de>

R A F wrote:
> Hi, how do I delete a component from a list?
> 
> For example, aaa <- list(), aaa$a <- 0, aaa$b <- 0.  How do I remove
> aaa$a from aaa so that it's left with aaa$b?
> 
> Thanks very much.


aaa$a <- NULL

Uwe Ligges


From langensk at fas.harvard.edu  Fri May  2 21:41:09 2003
From: langensk at fas.harvard.edu (langensk@fas.harvard.edu)
Date: Fri,  2 May 2003 15:41:09 -0400
Subject: [R] Creating Dummy Variables with if else phrase
Message-ID: <1051904469.3eb2c9d516257@webmail.fas.harvard.edu>

Dear All,

I want to do 52 state dummy variables. In order to make it easier for me, I 
thought of using the below commands. (x is the vector with state variables, 
matrix will correspond to the dummy variables)


x <- c(1,2,NA,4)
matrix <- matrix(0,nrow=4,ncol=4)

for (i in 1:4) {
if (is.real(x[i])) {
matrix[i,x[i]] <- 1 } else {
matrix[i,] <- rep(NA,4)
}
}

This gives me the following matrix:

1  0  0  0
0  1  0  0
0  0  0  0
0  0  0  1

But I want it to look as follows:

1   0  0  0
0   1  0  0
NA NA NA NA
0   0  0  1


I want the forth row to be NA, but it is unchanged, i.e., 0. The second "else" 
phrase does not seem to work, and I cannot see what is wrong.

I would be very grateful for your help.

Regards, Sophie


From zeileis at ci.tuwien.ac.at  Fri May  2 21:49:04 2003
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Fri, 2 May 2003 21:49:04 +0200
Subject: [R] Creating Dummy Variables with if else phrase
In-Reply-To: <1051904469.3eb2c9d516257@webmail.fas.harvard.edu>
References: <1051904469.3eb2c9d516257@webmail.fas.harvard.edu>
Message-ID: <200305021949.h42Jn43b031320@thorin.ci.tuwien.ac.at>

On Friday 02 May 2003 21:41, langensk at fas.harvard.edu wrote:

> Dear All,
>
> I want to do 52 state dummy variables. In order to make it easier
> for me, I thought of using the below commands. (x is the vector with
> state variables, matrix will correspond to the dummy variables)
>
>
> x <- c(1,2,NA,4)
> matrix <- matrix(0,nrow=4,ncol=4)
>
> for (i in 1:4) {
> if (is.real(x[i])) {
> matrix[i,x[i]] <- 1 } else {
> matrix[i,] <- rep(NA,4)
> }
> }
>
> This gives me the following matrix:
>
> 1  0  0  0
> 0  1  0  0
> 0  0  0  0
> 0  0  0  1
>
> But I want it to look as follows:
>
> 1   0  0  0
> 0   1  0  0
> NA NA NA NA
> 0   0  0  1
>

I don't really understand why you want to create a matrix that way, 
but if you want to do it the way described above
  is.real(x[i])
seems to be the wrong function (because x is a real vector in the 
example above). If you want to test for NA you should use
  !is.na(x[i])
instead.
Z

> I want the forth row to be NA, but it is unchanged, i.e., 0. The
> second "else" phrase does not seem to work, and I cannot see what is
> wrong.
>
> I would be very grateful for your help.
>
> Regards, Sophie
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From Guangchun.Song at stjude.org  Fri May  2 21:51:57 2003
From: Guangchun.Song at stjude.org (Song, Guangchun)
Date: Fri, 2 May 2003 14:51:57 -0500 
Subject: [R] Does R implement Hypergeometric test?
Message-ID: <A1DAD6685C12D511B20F0003472515138E6979@sjmemexc3.stjude.org>


From p.dalgaard at biostat.ku.dk  Fri May  2 22:08:44 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 02 May 2003 22:08:44 +0200
Subject: [R] Creating Dummy Variables with if else phrase
In-Reply-To: <1051904469.3eb2c9d516257@webmail.fas.harvard.edu>
References: <1051904469.3eb2c9d516257@webmail.fas.harvard.edu>
Message-ID: <x2k7d9i01f.fsf@biostat.ku.dk>

langensk at fas.harvard.edu writes:

> Dear All,
> 
> I want to do 52 state dummy variables. In order to make it easier for me, I 
> thought of using the below commands. (x is the vector with state variables, 
> matrix will correspond to the dummy variables)
> 
> 
> x <- c(1,2,NA,4)
> matrix <- matrix(0,nrow=4,ncol=4)
> 
> for (i in 1:4) {
> if (is.real(x[i])) {
> matrix[i,x[i]] <- 1 } else {
> matrix[i,] <- rep(NA,4)
> }
> }
> 
> This gives me the following matrix:
> 
> 1  0  0  0
> 0  1  0  0
> 0  0  0  0
> 0  0  0  1
> 
> But I want it to look as follows:
> 
> 1   0  0  0
> 0   1  0  0
> NA NA NA NA
> 0   0  0  1
> 
> 
> I want the forth row to be NA, but it is unchanged, i.e., 0. The second "else" 
> phrase does not seem to work, and I cannot see what is wrong.
> 
> I would be very grateful for your help.

is.real is true for all elements in x. You may have intended
!is.na(x[i]).

However, there are simpler ways, e.g.

0+outer(x,1:4,"==")
     [,1] [,2] [,3] [,4]
[1,]    1    0    0    0
[2,]    0    1    0    0
[3,]   NA   NA   NA   NA
[4,]    0    0    0    1

or simply use model formulas and code x as a factor.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From rolf at math.unb.ca  Fri May  2 22:14:48 2003
From: rolf at math.unb.ca (Rolf Turner)
Date: Fri, 2 May 2003 17:14:48 -0300 (ADT)
Subject: [R] Creating Dummy Variables with if else phrase
Message-ID: <200305022014.h42KEmQm004425@erdos.math.unb.ca>


There is a bit of a trap for young players involved, but:

	> x <- NA
	> is.real(x)
	[1] FALSE
	> x <- c(1,NA)
	> is.real(x[2])
	[1] TRUE
	> x <- as.real(NA)
	> is.real(x)
	[1] TRUE
	> typeof(x)
	[1] "double"
	> x <- NA
	> typeof(x)
	[1] "logical"

It makes sense when you think it through:  An ``NA'' could be
anything on its own.  When it's an entry of a vector with real
entries then it oughta be a ``not available real''.  It's a bit
subtle when you first bump into it, but it all clicks into place.

Be that as it may --- to avoid the trap, use is.na() if you want
to check whether a value is missing.

				cheers,

					Rolf Turner


From ligges at statistik.uni-dortmund.de  Fri May  2 22:32:59 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 02 May 2003 22:32:59 +0200
Subject: [R] Does R implement Hypergeometric test?
References: <A1DAD6685C12D511B20F0003472515138E6979@sjmemexc3.stjude.org>
Message-ID: <3EB2D5FB.E01135A1@statistik.uni-dortmund.de>

"Song, Guangchun" wrote:
> 
[Nothing]

Please don't use only the subject to ask questions.
In this particular case, it would be helpful to tell us what you mean
with a "Hypergeometric test" and "waste" some more lines in your e-mail.

Uwe Ligges


From sung-youn.kim at stonybrook.edu  Fri May  2 23:17:04 2003
From: sung-youn.kim at stonybrook.edu (sung-youn.kim@stonybrook.edu)
Date: Fri, 2 May 2003 17:17:04 -0400 (EDT)
Subject: [R] Bayesian SEM in R?
In-Reply-To: <5.1.0.14.0.20030502115205.00aa8ec0@uaslp.mx> (mandevip@uaslp.mx)
References: <5.1.0.14.0.20030502115205.00aa8ec0@uaslp.mx>
Message-ID: <200305022117.h42LH4P4025917@smtp.ic.sunysb.edu>

Hi,

I wonder if it is possible to do Bayesian (MCMC) analysis on SEM? I
found that TETRAD can be used for this, but does not seem to be
available for linux. Any information about this in R? 

best, 

-- 
__________________________
Sung-youn Kim
Dept. of Political Science
Stony Brook University 
SBS N-725
Stony Brook, NY  11794-4392

Tel: (631)-632-7664
Web: http://www.ic.sunysb.edu/stu/sungyoki


From yanyu at cs.ucla.edu  Sat May  3 02:59:32 2003
From: yanyu at cs.ucla.edu (Yan Yu)
Date: Fri, 2 May 2003 17:59:32 -0700 (PDT)
Subject: [R] how to call R function from my C++ program
Message-ID: <Pine.SOL.4.33.0305021752350.24075-100000@panther.cs.ucla.edu>

Hello, there,
  Is it possible to call R function from my C++ program?
If yes, How?  what function I should look up for that purpose?
If someone could provide some pointe, that would be very helpful..

THe reason I want to do that is that for my analysis, I need to do part of
the work in Matlab (I find the matrix operation in Matlab is very
convenient), and part of work in R, and I would like to connect
them automate the whole process using my C++ program..

THanks a lot in advance!
have a nice weekend,
yan


From rpeng at stat.ucla.edu  Sat May  3 03:33:16 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Fri, 2 May 2003 18:33:16 -0700 (PDT)
Subject: [R] how to call R function from my C++ program
In-Reply-To: <Pine.SOL.4.33.0305021752350.24075-100000@panther.cs.ucla.edu>
Message-ID: <Pine.GSO.4.10.10305021832010.29354-100000@quetelet.stat.ucla.edu>

It is possible to call R functions from a C++ program.  I suggest reading
the manual "Writing R Extensions" available under the manuals section of
CRAN.

-roger
_______________________________
UCLA Department of Statistics
http://www.stat.ucla.edu/~rpeng

On Fri, 2 May 2003, Yan Yu wrote:

> Hello, there,
>   Is it possible to call R function from my C++ program?
> If yes, How?  what function I should look up for that purpose?
> If someone could provide some pointe, that would be very helpful..
> 
> THe reason I want to do that is that for my analysis, I need to do part of
> the work in Matlab (I find the matrix operation in Matlab is very
> convenient), and part of work in R, and I would like to connect
> them automate the whole process using my C++ program..
> 
> THanks a lot in advance!
> have a nice weekend,
> yan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From kjetil at entelnet.bo  Sat May  3 03:44:24 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Fri, 02 May 2003 21:44:24 -0400
Subject: [R] install.packages, update.packages
Message-ID: <3EB2E6B8.15757.196B985@localhost>

Hola!

I am using update.packages() from the menu in Rgui (windows XP), and 
have a little problem. Sometimes the function terminates prematurely, 
for example because of some problems with one of the files it tries 
to download and install. In this case update.packages does not ask
if the downloaded packages should be deleted, and so I cannot answer 
N and have the tempdir location printed. I always store the 
downloaded files in a place to burn CD's to take to other machines, 
so I need this information. 

The relevant code is in install.packages, and I would like if the 
code fragment therefrom

if (!localcran && is.null(destdir)) {
            answer <- substr(readline("Delete downloaded files (y/N)? 
"), 
                1, 1)
            if (answer == "y" | answer == "Y") {
                for (file in foundpkgs[, 2]) unlink(file)
                unlink(tmpd)
            }
            else cat("The packages are in", tmpd)
            cat("\n")
        }


could be put into an on.exit(, add=TRUE) call. 

Also, in this situation, the packages already downloaded succefully, 
will not be installed, so at least to know where they are help in 
installing them from the local zip file, or could this part to be put 
into a call to on.exit() ?

Kjetil Halvorsen


From faheem at email.unc.edu  Sat May  3 05:06:10 2003
From: faheem at email.unc.edu (Faheem Mitha)
Date: Fri, 2 May 2003 23:06:10 -0400 (EDT)
Subject: [R] can't plot ylab in graph
Message-ID: <Pine.LNX.4.44.0305022248550.29823-100000@Chrestomanci>


Dear People,

I am sure I am missing something obvious as usual, but in the following
graph I can't plot ylab.

Ignoring unimportant details, I am plotting one instance of truehist() and
one instance of curve() on the same graph. Truehist() won't let me pass
the ylab argument. It gives me the error

Error in plot.default(xlim, c(0, ymax), type = "n", xlab = xlab, ylab =
"",  : formal argument "ylab" matched by multiple actual arguments

I don't understand the error. I looked at the help page for truehist().
The xlab argument was present but the ylab argument was missing.

I can pass the argument to curve but it is ignored. I tried adding it to
the line par(new=T) below, but that didn't do anything either.

Thanks in advance for any help.

                                                   Faheem.

************************************************************************

mg.hist <- function(len,theta,pos,size)
{
  x <- empmargdistvec(len,theta,pos,size)

  postscript(file="plot.ps", horizontal = FALSE, onefile = FALSE, paper
             = "special", width=6, height=4)
  par(mfcol=c(1,2),pch=20)

  truehist(x, nbins=100,xlab=expression(paste("Range ", (theta))))

  mydensityfn <- function(x)
    {
      mydensity(x,theta,pos,len)
    }
  par(new=T)
  curve(mydensityfn, col = "red", add=TRUE)

...
}


From ripley at stats.ox.ac.uk  Sat May  3 09:12:42 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 3 May 2003 08:12:42 +0100 (BST)
Subject: [R] can't plot ylab in graph
In-Reply-To: <Pine.LNX.4.44.0305022248550.29823-100000@Chrestomanci>
Message-ID: <Pine.LNX.4.44.0305030803490.6453-100000@gannet.stats>

On Fri, 2 May 2003, Faheem Mitha wrote:

> I am sure I am missing something obvious as usual, but in the following
> graph I can't plot ylab.
> 
> Ignoring unimportant details, I am plotting one instance of truehist() and
> one instance of curve() on the same graph. Truehist() won't let me pass
> the ylab argument. It gives me the error
> 
> Error in plot.default(xlim, c(0, ymax), type = "n", xlab = xlab, ylab =
> "",  : formal argument "ylab" matched by multiple actual arguments
> 
> I don't understand the error. I looked at the help page for truehist().
> The xlab argument was present but the ylab argument was missing.

Right, so why do you think it accepts `ylab'?  There seems to be a crop of
people asking questions or sending bug reports who think `xlab' and `ylab'
are graphical parameters, but that are actually arguments to title() which
plot.default passes through.

What you can do is call title(), as in

library(MASS)
truehist(rnorm(100))
title(ylab="some y label")

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Sat May  3 09:42:39 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 3 May 2003 08:42:39 +0100 (BST)
Subject: [R] failed to load MASS at start up
In-Reply-To: <6rd6jmm9z0.fsf@bates4.stat.wisc.edu>
Message-ID: <Pine.LNX.4.44.0305030832170.6734-100000@gannet.stats>

A belated follow-up on this -- I was on holiday over Easter.

On 16 Apr 2003, Douglas Bates wrote:

> Michael Na Li <lina at u.washington.edu> writes:
> 
> > Just installed R-1.7.0 (with recommended libraries) on RedHat 8.0.  
> > At R console, I can do
> > 
> > > library (MASS)
> > > 
> > 
> > just fine.  However, if I put a line 'library(MASS)' into ~/.Rprofile, it
> > fails to load,

Why would you want to do that?  There are options to set the list of
default packages, and

options(defaultPackages=c(getOption("defaultPackages"), "MASS"))

in .Rprofile is the preferred way to do this (and it works).

> > R : Copyright 2003, The R Development Core Team
> > Version 1.7.0  (2003-04-16)
> > ....
> > Type `q()' to quit R.
> > 
> > Error in get(x, envir, mode, inherits) : variable "biplot" was not found
> > Error in library(MASS) : package/namespace load failed
> > [Previously saved workspace restored]
> > 
> > >
> > 
> > What's happening?  I also tried to load 'lattice' (which I assume is where
> > biplot is defined) before 'MASS', but got the same error.
> 
> biplot is in mva

[...]

> By default mva is loaded but perhaps that does not occur until after
> ~/.Rprofile is executed.

That's true. Default packages are loaded right at the end of the startup 
options.

To fix this you could add the following line to .../library/MASS/NAMESPACE

importFrom(mva, biplot)

Unfortunately, that would load *two* copies of mva if MASS is loaded
before mva (as I understand it), which is why I removed it from the
NAMESPACE file.  I'll reinstate it for some future revision, possibly by 
a require(MASS) in a .onLoad.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Sat May  3 12:50:48 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 3 May 2003 12:50:48 +0200
Subject: [R] Question about PAM clustering method
In-Reply-To: <Sea1-F62Xa1y1gWrddI000067cf@hotmail.com>
References: <Sea1-F62Xa1y1gWrddI000067cf@hotmail.com>
Message-ID: <16051.40712.841260.918690@gargle.gargle.HOWL>

>>>>> "Isogai" == Isogai Takashi <t_isog at hotmail.com>
>>>>>     on Fri, 18 Apr 2003 08:57:15 +0000 writes:

(sorry for the late reaction, your e-mail got buried in a pile...)

    Isogai> Hello everyone.  I just started learning R for
    Isogai> clustering analysis in my research project.  I tried
    Isogai> k-means method and PAM method, both of which were
    Isogai> properly processed with my data.  I have some
    Isogai> questions about PAM graphical output.

    Isogai> Suppose to do the commands shown below;
    Isogai>  pm <- pam(D,6) ;  plot(pm)

    Isogai> I got two charts after prompted.  In the first
    Isogai> chart, 6 oval clusters are drawn together with data
    Isogai> markers.  I see four 'pink' lines that connect oval
    Isogai> clusters.  In this case, oval clusters are located
    Isogai> very near, and some of them are overlapped.  The
    Isogai> line starts from the edge of one oval, and it ends
    Isogai> at the edge of another oval.  Does anyone know the
    Isogai> meaning of this line?  I imagine that the line shows
    Isogai> close linkage of the corresponding clusters, but no
    Isogai> comments regarding this line can be found in the
    Isogai> help documents.

help(clusplot.default) has quite a list of references, one of
them even available on the web.  You should read at least one
(or alternatively look at the R source of these function; this
is open source !)

BTW (to all readers!):

  Use   
	    library(cluster,  keep.source = TRUE)
			      ^^^^^^^^^^^^^^^^^^
  for looking at the source code
  or instead even set

	    options(keep.source.pkgs = TRUE)
 
  in your Rprofile.
      
   
    Isogai> Second question is the meaning of the comment "these
    Isogai> two components explain x% of the point variability"
    Isogai> at the bottom oh the graph.  In my case, the data
    Isogai> has 6 (groups) x 20 (properties) dimension.  I think
    Isogai> that R extract the first and the second factors, and
    Isogai> map them on the graph.  Therefore, the number is the
    Isogai> total contribution of those two factors.  Am I
    Isogai> correct?  If so, how can I choose the factors other
    Isogai> than the first or the second?

help(clusplot[.default]) tells that these are principal components
or MDS coordinates depending on the input.

To choose other than the first two PCs is currently not
possible unless you change the clusplot.default().
It shouldn't be too hard and I will gladly accept patches which
implement such a new feature.
Even more interesting would be to provide other projection like
coordinates (from the literature) for cluster representation!

    Isogai> Lastly, I read a document that says about the
    Isogai> average silhouette, "even that highest width is
    Isogai> below (say) 0.25, one may conclude that no
    Isogai> substantial structure has been found".  Is this
    Isogai> true?  In my case, the value is far below 0.25,
    Isogai> possibly because some clusters overlap on the graph.
    Isogai> I can accept the overlapping clusters from the
    Isogai> viewpoint of my research, but I wonder if the PAM
    Isogai> method is also useful for these clusters.

The reference on clusplot is really Rousseeuw, Struyf and coworkers.
So I assume you read this in one of the references in
help(clusplot.default)  and they do give some indications on
this.  I believe the silhouette widths to be one "goodness of fit"
measure, useful in many but not all cases.  You have to *think*
about what these clusters *mean* in your data situation (and
also about what you really want to achieve with the clustering).
These real questions can never be answered by a single ASW (average
silhouette width) or any other statistic.

    Isogai> Thank you very much for your help in advance.
    Isogai> T. Isog Tokyo, Japan

You're welcome.
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><


From gmm at ds.unifi.it  Sat May  3 14:53:23 2003
From: gmm at ds.unifi.it (Giovanni Marchetti)
Date: Sat, 3 May 2003 12:53:23 +0000
Subject: [R] expand.grid and the first level of a factor
Message-ID: <200305031253.23754.gmm@ds.unifi.it>

I do not understand this behaviour of expand.grid:

> expand.grid(x = c("b", "a"), y = c(1, 2))$x
[1] b a b a
Levels: b a
> expand.grid(x = c("b", "a"))$x
[1] b a
Levels: a b

Why the first level of the factor x depends on the number
of arguments of expand.grid? Apparently, I can set 
the order of the levels only when the number of 
arguments in > 1. In the second example, the order 
is lexicographic.

-- Giovanni
-- 
< Giovanni M. Marchetti >
Dipartimento di Statistica, Univ. di Firenze   Phone:  +39 055 4237 204
viale Morgagni, 59                             Fax:    +39 055 4223 560
I 50134 Firenze, Italy                         email:  gmm at ds.unifi.it


From jfox at mcmaster.ca  Sat May  3 14:54:45 2003
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 03 May 2003 08:54:45 -0400
Subject: [R] expand.grid and the first level of a factor
In-Reply-To: <200305031253.23754.gmm@ds.unifi.it>
Message-ID: <5.1.0.14.2.20030503085011.01e85d58@mcmail.cis.mcmaster.ca>

Dear Giovanni,

At 12:53 PM 5/3/2003 +0000, Giovanni Marchetti wrote:
>I do not understand this behaviour of expand.grid:
>
> > expand.grid(x = c("b", "a"), y = c(1, 2))$x
>[1] b a b a
>Levels: b a
> > expand.grid(x = c("b", "a"))$x
>[1] b a
>Levels: a b
>
>Why the first level of the factor x depends on the number
>of arguments of expand.grid? Apparently, I can set
>the order of the levels only when the number of
>arguments in > 1. In the second example, the order
>is lexicographic.

As the help for expand.grid states, expand.grid generates all combinations 
of values of its arguments. Take a look at the entirety of the result:

 > expand.grid(x = c("b", "a"), y = c(1, 2))
   x y
1 b 1
2 a 1
3 b 2
4 a 2


Compare, for example, to

         expand.grid(x = c("b", "a"), y = c(1, 2), z=c(TRUE, FALSE))

which generates 8 rows.

I hope that this helps,
  John


-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox


From ligges at statistik.uni-dortmund.de  Sat May  3 15:23:59 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 03 May 2003 15:23:59 +0200
Subject: [R] expand.grid and the first level of a factor
In-Reply-To: <200305031253.23754.gmm@ds.unifi.it>
References: <200305031253.23754.gmm@ds.unifi.it>
Message-ID: <3EB3C2EF.2070200@statistik.uni-dortmund.de>

Giovanni Marchetti wrote:
> I do not understand this behaviour of expand.grid:
> 
> 
>>expand.grid(x = c("b", "a"), y = c(1, 2))$x
> 
> [1] b a b a
> Levels: b a
> 
>>expand.grid(x = c("b", "a"))$x
> 
> [1] b a
> Levels: a b
> 
> Why the first level of the factor x depends on the number
> of arguments of expand.grid? Apparently, I can set 
> the order of the levels only when the number of 
> arguments in > 1. In the second example, the order 
> is lexicographic.
> 
> -- Giovanni


It depends on the number of arguments, because of the implementation 
(look into the code):

In principle, expand.grid(x = c("b", "a")) does the following:

  x <- c("b", "a")
  factor(x)

whereas for expand.grid(x = c("b", "a"), y = c(1, 2)), the levels will 
be specified as in:

  factor(x, levels = unique(x))

Hence the difference.


Uwe Ligges


From maechler at stat.math.ethz.ch  Sat May  3 16:03:27 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 3 May 2003 16:03:27 +0200
Subject: [R] expand.grid and the first level of a factor
In-Reply-To: <3EB3C2EF.2070200@statistik.uni-dortmund.de>
References: <200305031253.23754.gmm@ds.unifi.it>
	<3EB3C2EF.2070200@statistik.uni-dortmund.de>
Message-ID: <16051.52271.791421.949573@gargle.gargle.HOWL>

>>>>> "UweL" == Uwe Ligges <ligges at statistik.uni-dortmund.de>
>>>>>     on Sat, 03 May 2003 15:23:59 +0200 writes:

    UweL> Giovanni Marchetti wrote:
    >> I do not understand this behaviour of expand.grid:
    >> 
    >> 
    >>> expand.grid(x = c("b", "a"), y = c(1, 2))$x
    >> 
    >> [1] b a b a
    >> Levels: b a
    >> 
    >>> expand.grid(x = c("b", "a"))$x
    >> 
    >> [1] b a
    >> Levels: a b
    >> 
    >> Why the first level of the factor x depends on the number
    >> of arguments of expand.grid? Apparently, I can set 
    >> the order of the levels only when the number of 
    >> arguments in > 1. In the second example, the order 
    >> is lexicographic.
    >> 
    >> -- Giovanni


    UweL> It depends on the number of arguments, because of the implementation 
    UweL> (look into the code):

    UweL> In principle, expand.grid(x = c("b", "a")) does the following:

    UweL> x <- c("b", "a")
    UweL> factor(x)

    UweL> whereas for expand.grid(x = c("b", "a"), y = c(1, 2)), the levels will 
    UweL> be specified as in:

    UweL>    factor(x, levels = unique(x))

    UweL> Hence the difference.

which seems not perfect to me.
Factor() itself,
  > str(factor)
  function (x, levels = sort(unique.default(x), na.last = TRUE), 
      labels = levels, exclude = NA, ordered = is.ordered(x))  

does sort the levels by default, and that's what happens in the
one argument case via data.frame().

S-plus 6.1 does the same for factor() but it doesn't sort the
levels of expand.grid() arguments in any case.

I'm just now testing a patch to our expand.grid() which doesn't
treat the one argument case specially as now and seems to cure
the whole "infelicity"...
I can not imagine that anyone's code relies on the current
behavior as opposed to the more consistent one.

Martin


From djw1005 at cam.ac.uk  Sat May  3 18:33:48 2003
From: djw1005 at cam.ac.uk (Damon Wischik)
Date: Sat, 3 May 2003 17:33:48 +0100 (BST)
Subject: [R] Grid gpar(col=NULL)
Message-ID: <Pine.SOL.3.96.1030503172547.7111A-100000@libra.cus.cam.ac.uk>


I have found that gpar(col=NULL) doesn't behave as I expect it to. Is this
due to a misconception on my part, or a bug?

library(grid)
grid.newpage()
grid.circle(gp=gpar(fill="yellow",col=NULL))
# Draws a yellow circle with no border, as it should.
# But if you resize the graphics window,
# the circle acquires a black border.

I am running Rgui for R 1.7.0 on Windows XP.

Damon Wischik.


From peterm at andrew.cmu.edu  Sat May  3 19:36:32 2003
From: peterm at andrew.cmu.edu (Peter Muhlberger)
Date: Sat, 03 May 2003 13:36:32 -0400
Subject: [R] SEM bootstrapping
In-Reply-To: <200305031025.h43A6PWE022272@hypatia.math.ethz.ch>
Message-ID: <BAD97660.4DCC%peterm@andrew.cmu.edu>

Has anyone created functions that apply bootstrapping to SEM models?  I'm
guessing that's a fairly straightforward application of existing functions,
but would rather not reinvent the wheel.  Coefficient p-values should be
straightforward, but I'm not sure what it would take to get bootstrapped
indicators like the Bollen-Stine p-value.

Peter


From shitao at hotmail.com  Sat May  3 20:09:07 2003
From: shitao at hotmail.com (Tao Shi)
Date: Sat, 03 May 2003 18:09:07 +0000
Subject: [R] Memory leakage?
Message-ID: <Sea2-F56jADXR27LyVH00006d6e@hotmail.com>

Hi, all:

I'm using R 1.7.0 on WinXP under SDI mode.  However, very often after I 
closed all R windows, my CPU usage was still 100%.  By checking the task 
manager, I found there are one or several "Rgui.exe" still running and took 
all the CPU.  I had to close them one by one manually.  This happened to me 
with R 1.6.1, R 1.6.2 also and also on Win2K.  Rememeber there was a "memory 
leakage" problem with the early release of 1.6.2.  Is this what I'm 
exprencing here?  Or this is due to I'm runing R under SDI mode, b/c my 
colleague hasn't found the problem with his R 1.7.0 or other versions which 
are runing under MDI mode.  Help............

...Tao


From ripley at stats.ox.ac.uk  Sat May  3 20:56:16 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 3 May 2003 19:56:16 +0100 (BST)
Subject: [R] Memory leakage?
In-Reply-To: <Sea2-F56jADXR27LyVH00006d6e@hotmail.com>
Message-ID: <Pine.LNX.4.44.0305031950420.7593-100000@gannet.stats>

I always use Rgui in SDI mode (under XP) and it always shuts down
completely for me.

There was only one release of R 1.6.2.  This not what is meant by `memory
leakage': that is when an application allocates memory and does not free
it: it goes away when the application is exit-ed.

I believe the problem is with your own computer (or how you use it,
including other software you may have installed): have you tried
re-installing Windows?

On Sat, 3 May 2003, Tao Shi wrote:

> I'm using R 1.7.0 on WinXP under SDI mode.  However, very often after I 
> closed all R windows, my CPU usage was still 100%.  By checking the task 
> manager, I found there are one or several "Rgui.exe" still running and took 
> all the CPU.  I had to close them one by one manually.  This happened to me 
> with R 1.6.1, R 1.6.2 also and also on Win2K.  Rememeber there was a "memory 
> leakage" problem with the early release of 1.6.2.  Is this what I'm 
> exprencing here?  Or this is due to I'm runing R under SDI mode, b/c my 
> colleague hasn't found the problem with his R 1.7.0 or other versions which 
> are runing under MDI mode.  Help............

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From shitao at hotmail.com  Sat May  3 22:33:49 2003
From: shitao at hotmail.com (Tao Shi)
Date: Sat, 03 May 2003 20:33:49 +0000
Subject: [R] Memory leakage?
Message-ID: <Sea2-F1406MjHDEQ0V6000499e0@hotmail.com>

Dear Prof. Ripley:

Thank you for your suggestions!

I haven't tried re-installing windows yet, because it seems to be a big task 
for me and also I kind of doubt that the problem is due to my own 
computer(s), because the same problem happens to 3 different computers: one 
Dell desktop in school runing Win2K and R 1.6.1, my Dell laptop runing Win 
XP Professional Edition and R 1.7.0 and my new Dell desktop at home (just 
bought less than a month and only a few basic softwares were installed) 
runing Win XP Home Edition and R1.7.0.  (may be they're all from Dell :-)) 
I'm still looking for the pattern of when this happens, but so far, it seems 
to be random.

...Tao





Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:Date: Sat, 3 May 2003 
19:56:16 +0100 (BST)
From: Prof Brian Ripley
To: tshi at itsa.ucsf.edu
CC: r-help at stat.math.ethz.ch
Subject: Re: [R] Memory leakage?

I always use Rgui in SDI mode (under XP) and it always shuts down
completely for me.

There was only one release of R 1.6.2. This not what is meant by `memory
leakage': that is when an application allocates memory and does not free
it: it goes away when the application is exit-ed.

I believe the problem is with your own computer (or how you use it,
including other software you may have installed): have you tried
re-installing Windows?

On Sat, 3 May 2003, Tao Shi wrote:

 > I'm using R 1.7.0 on WinXP under SDI mode. However, very often after I
 > closed all R windows, my CPU usage was still 100%. By checking the task
 > manager, I found there are one or several "Rgui.exe" still running and 
took
 > all the CPU. I had to close them one by one manually. This happened to me
 > with R 1.6.1, R 1.6.2 also and also on Win2K. Rememeber there was a 
"memory
 > leakage" problem with the early release of 1.6.2. Is this what I'm
 > exprencing here? Or this is due to I'm runing R under SDI mode, b/c my
 > colleague hasn't found the problem with his R 1.7.0 or other versions 
which
 > are runing under MDI mode. Help............

--
Brian D. Ripley, ripley at stats.ox.ac.uk
Professor of Applied Statistics, http://www.stats.ox.ac.uk/~ripley/
University of Oxford, Tel: +44 1865 272861 (self)
1 South Parks Road, +44 1865 272866 (PA)
Oxford OX1 3TG, UK Fax: +44 1865 272595


From gmm at ds.unifi.it  Sun May  4 01:48:48 2003
From: gmm at ds.unifi.it (Giovanni Marchetti)
Date: Sat, 3 May 2003 23:48:48 +0000
Subject: [R] expand.grid
Message-ID: <200305032348.49124.gmm@ds.unifi.it>


I recently posted a question concerning an inconsistency of 
expand.grid in defining the reference level of the factors.

> > expand.grid(x = c("b", "a"), y = c(1, 2))$x
> [1] b a b a
> Levels: b a            # reference level is b
> > expand.grid(x = c("b", "a"))$x
> [1] b a
> Levels: a b            # reference level is a

Thank you very much for the ready explanations and comments.

I found this inconsistency 
working with contingency tables and logistic models.  

I was working with a flat contingency table as for example,
 
> ft <- ftable(low ~ race + smoke, bwt)
> ft
            low  0  1
race  smoke
white FALSE     40  4
      TRUE      33 19
black FALSE     11  5
      TRUE       4  6
other FALSE     35 20
      TRUE       7  5

(here bwt is a transformation of the dataframe birthwt
in library(MASS)). 

I wanted to analyse
this table by a logistic model with low as response. 
So it seems useful to have a function that extracts the 
factors race and smoke from the table:

> row.factors(ft)
   race smoke
1 white FALSE
2 white  TRUE
3 black FALSE
4 black  TRUE
5 other FALSE
6 other  TRUE
  
in such a way that they can be directly used in glm:

> glm(ft ~ race + smoke, family=binomial, data = row.factors(ft))
...
Coefficients:
(Intercept)    raceblack    raceother    smokeTRUE
      1.841       -1.084       -1.109       -1.116
...
Note that the reference level for race is "white" (the first row). 

PS - Obviously, the same analysis is very easy from the original 
dataframe (which here is supposed to be missing): 

> glm(low ~ race + smoke, family=binomial, data = bwt)

except for the sign of the coefficients which are reversed
because the columns of ft are (failure, success) instead of
(success, failure). 

Thus, I wrote the function

"row.factors" <- function (ft)
{
# ft:    a flat table.
# Value: a data frame with the factors associated to the rows.
        vars <- attr(ft, "row.vars")
        k <- length(vars)
        expl <- expand.grid(vars[k:1])
        expl[,k:1, drop=FALSE]
}

The function worked pretty well except for the case of a simple 
contingency table.
 
> ft <- ftable(low ~ race, bwt)
> ft
      low  0  1
race
white     73 23
black     15 11
other     42 25
> row.factors(ft)
   race
1 white
2 black
3 other
> levels(row.fact(ft)$race)
[1] "black" "other" "white" 

Thus, here the reference level is "black" and this is a bit strange 
as the first row of the table is "white". This little "infelicity" 
is in fact caused by expand.grid. 


Thanks again


-- Giovanni

-- 
< Giovanni M. Marchetti >
Dipartimento di Statistica, Univ. di Firenze   Phone:  +39 055 4237 204
viale Morgagni, 59                             Fax:    +39 055 4223 560
I 50134 Firenze, Italy                         email:  gmm at ds.unifi.it


From dmurdoch at pair.com  Sun May  4 00:58:50 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sat, 03 May 2003 18:58:50 -0400
Subject: [R] Memory leakage?
In-Reply-To: <Sea2-F1406MjHDEQ0V6000499e0@hotmail.com>
References: <Sea2-F1406MjHDEQ0V6000499e0@hotmail.com>
Message-ID: <3ai8bvor08ng7k4sv2d69b2pk9f1envbv3@4ax.com>

On Sat, 03 May 2003 20:33:49 +0000, you wrote:

>I haven't tried re-installing windows yet, because it seems to be a big task 
>for me and also I kind of doubt that the problem is due to my own 
>computer(s), because the same problem happens to 3 different computers: one 
>Dell desktop in school runing Win2K and R 1.6.1, my Dell laptop runing Win 
>XP Professional Edition and R 1.7.0 and my new Dell desktop at home (just 
>bought less than a month and only a few basic softwares were installed) 
>runing Win XP Home Edition and R1.7.0.  (may be they're all from Dell :-)) 
>I'm still looking for the pattern of when this happens, but so far, it seems 
>to be random.

I don't think it's a Windows problem.  I've seen it occasionally, but
not reproducibly.  If you can figure out some sequence of operations
that reliably produces it, please let me know.

Duncan Murdoch


From yanyu at cs.ucla.edu  Sun May  4 02:25:29 2003
From: yanyu at cs.ucla.edu (Yan Yu)
Date: Sat, 3 May 2003 17:25:29 -0700 (PDT)
Subject: [R] how to call R function from my C++ program
In-Reply-To: <Pine.GSO.4.10.10305021832010.29354-100000@quetelet.stat.ucla.edu>
Message-ID: <Pine.SOL.4.33.0305031655060.4436-100000@panther.cs.ucla.edu>

Hi,
I read the manual, it seems that i have the following two choices:
1) use "eval(R_fcall, rho)" in a C function.

They use an example called lapply2

in C program, it has:
SEXP  lapply2(SEXP list, SEXP fn, SEXP rho)
{
.....
PROTECT( R_fcall = lang2(fn, R_nilValue) );
eval(R_fcall, rho)
......
}

but i am a little confused here, it seems like the C function "lapply2()"
is supposed to be called from R, not to be run standalone??
My Q is: if I use this approach, Can I run a standalone C program in which
I call a R function using eval()?

2) R have some API entry points for C code.
in section 5.12, it says "it is possible to build Mathlib, can be built in
directory "src/namth/standalone", and the instructions are supposed in
"README" in the same directory.
I am wondering using the same procedure, can I build API entry points for
other R functions I want to use?

I have another Q, there is no "src" subdirectory in my R directory.
i use i386 rpm to install R in my redhat..
i think the version i have now is R-1.6.1-1.i386.rpm..
Any idea where can i find this src subdirectory?

thanks a lot,
yan

On Fri, 2 May 2003, Roger Peng wrote:

> It is possible to call R functions from a C++ program.  I suggest reading
> the manual "Writing R Extensions" available under the manuals section of
> CRAN.
>
> -roger
> _______________________________
> UCLA Department of Statistics
> http://www.stat.ucla.edu/~rpeng
>
> On Fri, 2 May 2003, Yan Yu wrote:
>
> > Hello, there,
> >   Is it possible to call R function from my C++ program?
> > If yes, How?  what function I should look up for that purpose?
> > If someone could provide some pointe, that would be very helpful..
> >
> > THe reason I want to do that is that for my analysis, I need to do part of
> > the work in Matlab (I find the matrix operation in Matlab is very
> > convenient), and part of work in R, and I would like to connect
> > them automate the whole process using my C++ program..
> >
> > THanks a lot in advance!
> > have a nice weekend,
> > yan
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>


From savanosp at ieg.com.br  Sun May  4 03:48:52 2003
From: savanosp at ieg.com.br (Savano Pereira)
Date: Sun, 4 May 2003 01:48:52 GMT
Subject: [R] Some questions
Message-ID: <3eb47184.25e6.0@ieg.com.br>

Hello people,

I'd like to ask you some questions:

1-How can I introduce an intercept in arima.sim function?

2-How can I edit the initial values (=initial conditions) in arima.sim function?


3- How can I put my own x-axis in plot function?
Ex: It could be a vector or array with same dimension of the plotted variable.


4-How can I augment grid values on y-axis or x-axis in plot function?
Ex:Imagine that the gave grid is 10 by 10 and I would like the put it in 2 by
2 or 5 by 5.

5- Is it possible to introduce or to construct some kind of kernel on spectrum
function?
Ex: Parzen, Bartlet, etc..

Waiting for answers.





http://www.ieg.com.br


From ripley at stats.ox.ac.uk  Sun May  4 09:27:22 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 4 May 2003 08:27:22 +0100 (BST)
Subject: [R] how to call R function from my C++ program
In-Reply-To: <Pine.SOL.4.33.0305031655060.4436-100000@panther.cs.ucla.edu>
Message-ID: <Pine.LNX.4.44.0305040816170.15979-100000@gannet.stats>

I am inferring that you are using Linux, although you didn't say. Some of 
my answers are specific to Unix/Linux.

On Sat, 3 May 2003, Yan Yu wrote:

> I read the manual, it seems that i have the following two choices:
> 1) use "eval(R_fcall, rho)" in a C function.
> 
> They use an example called lapply2
> 
> in C program, it has:
> SEXP  lapply2(SEXP list, SEXP fn, SEXP rho)
> {
> .....
> PROTECT( R_fcall = lang2(fn, R_nilValue) );
> eval(R_fcall, rho)
> ......
> }
> 
> but i am a little confused here, it seems like the C function "lapply2()"
> is supposed to be called from R, not to be run standalone??
> My Q is: if I use this approach, Can I run a standalone C program in which
> I call a R function using eval()?

Yes.  You can build R as a shared library (libR.so) and link against that.
However, you will need to initialize R: see the examples in the directory
tests/Embedding in the sources, and the background URL

http://developer.r-project.org/embedded.html


> 2) R have some API entry points for C code.
> in section 5.12, it says "it is possible to build Mathlib, can be built in
> directory "src/namth/standalone", and the instructions are supposed in
> "README" in the same directory.
> I am wondering using the same procedure, can I build API entry points for
> other R functions I want to use?

No.  (Those are not for R functions, but for parts of R's C API, and 
considerable work was done to separate out that part of the API to make 
it work standalone.)

> I have another Q, there is no "src" subdirectory in my R directory.
> i use i386 rpm to install R in my redhat..
> i think the version i have now is R-1.6.1-1.i386.rpm..
> Any idea where can i find this src subdirectory?

In the sources.  You installed a binary version of R.  I suspect you will 
need to build from the sources to build libR.so.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tring at gvdnet.dk  Sun May  4 15:49:22 2003
From: tring at gvdnet.dk (Troels Ring)
Date: Sun, 04 May 2003 15:49:22 +0200
Subject: [R] array question on indexing
Message-ID: <5.2.0.9.0.20030504153331.009eb590@mail.gvdnet.dk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030504/79fa58f7/attachment.pl

From juli at ceam.es  Sun May  4 16:04:54 2003
From: juli at ceam.es (juli g. pausas)
Date: Sun, 04 May 2003 16:04:54 +0200
Subject: [R] image of expand.grid
Message-ID: <3EB51E06.4050003@ceam.es>

Hi all,
It is not clear to me why this cannot be ploted with image. Any help?

 > g <- data.frame(expand.grid(x= 1:5, y= 1:5), z= rnorm(25))
 > image(g)
Error in image.default(g) : increasing x and y values expected
 > is.list(g)
[1] TRUE
 > g$x
 [1] 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5
 > g$y
 [1] 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4 5 5 5 5 5
 >


Thanks in advance

Juli


From ligges at statistik.uni-dortmund.de  Sun May  4 16:22:06 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 04 May 2003 16:22:06 +0200
Subject: [R] Grid gpar(col=NULL)
In-Reply-To: <Pine.SOL.3.96.1030503172547.7111A-100000@libra.cus.cam.ac.uk>
References: <Pine.SOL.3.96.1030503172547.7111A-100000@libra.cus.cam.ac.uk>
Message-ID: <3EB5220E.7080507@statistik.uni-dortmund.de>

Damon Wischik wrote:
> I have found that gpar(col=NULL) doesn't behave as I expect it to. Is this
> due to a misconception on my part, or a bug?
>
 > library(grid)
> grid.newpage()
> grid.circle(gp=gpar(fill="yellow",col=NULL))
> # Draws a yellow circle with no border, as it should.
> # But if you resize the graphics window,
> # the circle acquires a black border.
> 
> I am running Rgui for R 1.7.0 on Windows XP.

It's a bug (at least on Windows, it works on X11).

Uwe Ligges



> Damon Wischik.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From tura at centroin.com.br  Sun May  4 16:08:12 2003
From: tura at centroin.com.br (Bernardo Rangel Tura)
Date: Sun, 04 May 2003 11:08:12 -0300
Subject: [R] How to save several matrix in a variable
In-Reply-To: <x2n0i6k2ij.fsf@biostat.ku.dk>
References: <Pine.SOL.4.44.0305011128550.8363-100000@asteroids.gpcc.itd.umich.edu>
	<Pine.SOL.4.44.0305011128550.8363-100000@asteroids.gpcc.itd.umich.edu>
Message-ID: <5.1.0.14.2.20030504110637.00a5d6a0@centroin.com.br>

Good morning R-masters,      
      
I would like to ask help to you for the a problem. 
I need to keep in a variable several matrix generated by my routine.
It?s  possible?
How to I make this?


Thanks in advance

Bernardo Rangel Tura, MD, MSc
National Institute of Cardiology Laranjeiras
Rio de Janeiro Brazil


From ligges at statistik.uni-dortmund.de  Sun May  4 16:31:37 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 04 May 2003 16:31:37 +0200
Subject: [R] image of expand.grid
In-Reply-To: <3EB51E06.4050003@ceam.es>
References: <3EB51E06.4050003@ceam.es>
Message-ID: <3EB52449.90801@statistik.uni-dortmund.de>

juli g. pausas wrote:
> Hi all,
> It is not clear to me why this cannot be ploted with image. Any help?
> 
>  > g <- data.frame(expand.grid(x= 1:5, y= 1:5), z= rnorm(25))
>  > image(g)
> Error in image.default(g) : increasing x and y values expected
>  > is.list(g)
> [1] TRUE
>  > g$x
> [1] 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5
>  > g$y
> [1] 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4 5 5 5 5 5
>  >
> 

The error message states: "increasing x and y values expected".
image() is really clever and you don't need expand.grid() in this case 
(in principle, image() does it itself):

  g <- list(x = 1:5, y = 1:5, z = matrix(rnorm(25), 5))
  image(g)

Uwe Ligges

> Thanks in advance
> 
> Juli
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From ligges at statistik.uni-dortmund.de  Sun May  4 16:33:59 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 04 May 2003 16:33:59 +0200
Subject: [R] How to save several matrix in a variable
In-Reply-To: <5.1.0.14.2.20030504110637.00a5d6a0@centroin.com.br>
References: 
	<Pine.SOL.4.44.0305011128550.8363-100000@asteroids.gpcc.itd.umich.edu>
	<Pine.SOL.4.44.0305011128550.8363-100000@asteroids.gpcc.itd.umich.edu>
	<5.1.0.14.2.20030504110637.00a5d6a0@centroin.com.br>
Message-ID: <3EB524D7.5040009@statistik.uni-dortmund.de>

Bernardo Rangel Tura wrote:
> Good morning R-masters,      
>       
> I would like to ask help to you for the a problem. 
> I need to keep in a variable several matrix generated by my routine.
> It?s  possible?
> How to I make this?

Use a list (of matrices), see ?list and the manuals for how to work with 
lists.

If all the matrices have the same dimensions, you might want to use an 
array instead, see ?array and the manuals for details.

Uwe Ligges

> Thanks in advance
> 
> Bernardo Rangel Tura, MD, MSc
> National Institute of Cardiology Laranjeiras
> Rio de Janeiro Brazil
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From fredrik.lundgren at norrkoping.mail.telia.com  Sun May  4 17:17:25 2003
From: fredrik.lundgren at norrkoping.mail.telia.com (Fredrik Lundgren)
Date: Sun, 4 May 2003 17:17:25 +0200
Subject: [R] 'rush of graphs on the screen'
Message-ID: <200305041717.25784.fredrik.lundgren@norrkoping.mail.telia.com>

Hello R experts,

When I try e. g. example(plot) in R 1.7.0 on Linux, the example graphs rush 
away on the screen before my eyes. How can I see them one at a time?

Sincerely Fredrik Lundgren


From mschwartz at medanalytics.com  Sun May  4 17:36:42 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Sun, 4 May 2003 10:36:42 -0500
Subject: [R] 'rush of graphs on the screen'
In-Reply-To: <200305041717.25784.fredrik.lundgren@norrkoping.mail.telia.com>
Message-ID: <00b201c31252$f6df3f70$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Fredrik
Lundgren
>Sent: Sunday, May 04, 2003 10:17 AM
>To: R-help at stat.math.ethz.ch
>Subject: [R] 'rush of graphs on the screen'
>
>
>Hello R experts,
>
>When I try e. g. example(plot) in R 1.7.0 on Linux, the 
>example graphs rush 
>away on the screen before my eyes. How can I see them one at a time?
>
>Sincerely Fredrik Lundgren


Use:

par(ask = TRUE)

before running example(plot)

You will then br prompted to "Hit <Return> to see next plot: " 

Be sure to reset 

par(ask = FALSE)

when done.

HTH,

Marc Schwartz


From ligges at statistik.uni-dortmund.de  Sun May  4 17:41:13 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 04 May 2003 17:41:13 +0200
Subject: [R] 'rush of graphs on the screen'
In-Reply-To: <200305041717.25784.fredrik.lundgren@norrkoping.mail.telia.com>
References: <200305041717.25784.fredrik.lundgren@norrkoping.mail.telia.com>
Message-ID: <3EB53499.1030709@statistik.uni-dortmund.de>

Fredrik Lundgren wrote:
> Hello R experts,
> 
> When I try e. g. example(plot) in R 1.7.0 on Linux, the example graphs rush 
> away on the screen before my eyes. How can I see them one at a time?


For example:

par(ask = TRUE)
example(plot)


Uwe Ligges

> Sincerely Fredrik Lundgren
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From von-hippel.1 at osu.edu  Sun May  4 20:15:04 2003
From: von-hippel.1 at osu.edu (Paul von Hippel)
Date: Sun, 04 May 2003 14:15:04 -0400
Subject: [R] port of Pan to R
Message-ID: <5.2.0.9.2.20030504141405.00ace2b8@mail.sociology.ohio-state.edu>

I'm looking for a port of Schafer's PAN module for multiple imputation of 
nested data.
It is written in S-Plus, and I would like to use it in R.

Any pointers most appreciated.

Best wishes,
Paul von Hippel


From p.dalgaard at biostat.ku.dk  Sun May  4 20:23:02 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 04 May 2003 20:23:02 +0200
Subject: [R] array question on indexing
In-Reply-To: <5.2.0.9.0.20030504153331.009eb590@mail.gvdnet.dk>
References: <5.2.0.9.0.20030504153331.009eb590@mail.gvdnet.dk>
Message-ID: <x2el3einax.fsf@biostat.ku.dk>

Troels Ring <tring at gvdnet.dk> writes:

> Dear friends,
> I have struggled to do what is likely rather simple but cannot get it working.
> I have a dataframe with 428 obs. of 5 variables on 26 patients. Two 
> variables are responses, one an index of patients (1:26), one a 
> period-indicator :1 :max 3, and one total time from min 1 to max 36 weeks 
> (max 21 entries). A complete set would be 26*21=546 long but here are only 
> 428 entries.
> Now, within each period nested within patients a max of one of the response 
> variables is found, with length 78, 6 are NA from MAX <- 
> by(response,list(period,id),max).
> Then how do I get the individual times corresponding to these within 
> period, within patient MAX values ?
> (Windows R 1.7)

Let's see...

if you had a data frame of one person in one period, you'd do 

time[which.max(response)]

so use by to split the data frame  and write a little function to
handle each subframe:

timeAtMax <- function(d) with(d, time[which.max(response)])
# or: function(d) d$time[which.max(d$response)])
by(mydata, list(period,id), timeAtMax)

[untested of course, and you might want to do something about the fact
that which.max returns a value even in the precense of NA's]

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From ripley at stats.ox.ac.uk  Sun May  4 21:15:17 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 4 May 2003 20:15:17 +0100 (BST)
Subject: [R] port of Pan to R
In-Reply-To: <5.2.0.9.2.20030504141405.00ace2b8@mail.sociology.ohio-state.edu>
Message-ID: <Pine.LNX.4.44.0305042013360.16692-100000@gannet.stats>

I don't think it has been done.  Given the problems I had with mix, it may 
be a difficult job -- most of those were problems that would have emerged 
in S-PLUS in due course.

On Sun, 4 May 2003, Paul von Hippel wrote:

> I'm looking for a port of Schafer's PAN module for multiple imputation of 
> nested data.
> It is written in S-Plus, and I would like to use it in R.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From yanyu at cs.ucla.edu  Mon May  5 01:38:35 2003
From: yanyu at cs.ucla.edu (Yan Yu)
Date: Sun, 4 May 2003 16:38:35 -0700 (PDT)
Subject: [R] trmat, or prmat in "spatial" package
Message-ID: <Pine.SOL.4.33.0305041633100.7310-100000@panther.cs.ucla.edu>

Hello, there,
   when i tried with trmat, or prmat (the interpolation/kriging function)
in "spatial package", i found it it only did interpolation for n x n grid.
however, my data is distributed in a rectangle field, not in square, so I
would like to set different size for x and y dimension.. HOw can I set it
to be m x n grid ( m != n)?
ANy hint on how to get around this is appreciated:)
yan


From yanyu at cs.ucla.edu  Mon May  5 04:40:49 2003
From: yanyu at cs.ucla.edu (Yan Yu)
Date: Sun, 4 May 2003 19:40:49 -0700 (PDT)
Subject: [R] package "sgeostat"
Message-ID: <Pine.SOL.4.33.0305041926400.12152-100000@panther.cs.ucla.edu>

Greetings, all:
  I am wondering have anyone used package "sgeosta" before,
I have a Q about its variogram fitting function:
fit.exponential, fit.gaussian and fit.wave

they ask for a few parameters, which I have no clue how to set them..
e.g., they list this example:
maas.vmod<-fit.gaussian(maas.v,c0=60000,cg=110000,ag=800,plot.it=TRUE,
iterations=30

In the manual page, they list the meaning of those paramters that have
model dependent meanings:

c0:                        initial estimate for nugget effect, valid for all
variogram types, partial sill (cX) and
                        (asymptotical) range (aX) as follows:
 ce, ae
                        initial estimates for the exponential variogram
model
 cg, ag
                        initial estimates for the gaussian variogram model
 cs, as
                        initial estimates for the sperical variogram model
 cw, aw
                        initial estimates for the periodical variogram model

Sorry for my ignorance on those models, my Qs is:
1) what is the rule of thumb to set the above parameters?
2) Does it really matter how I set those initial estimates? How much
influence the initial parameter setting is going to have on the final
model fitting?
3) How do I know if I set those parameters right or way off?

thanks a lot!
yan


From yanyu at cs.ucla.edu  Mon May  5 05:40:36 2003
From: yanyu at cs.ucla.edu (Yan Yu)
Date: Sun, 4 May 2003 20:40:36 -0700 (PDT)
Subject: [R] prmat in "spatial"
Message-ID: <Pine.SOL.4.33.0305042031290.16166-100000@panther.cs.ucla.edu>

HI,
sorry for many Qs posted here..  BIG THANKS to all the replies..
I have another Q for "prmat":
I have a 12 x 12 data points, i want to increase the granularity to
0.1x0.1, so I use the following function call:
data.pr <- prmat(data.kr, 1, 12, 1, 12, 120)

I would expect the data points is 121 x 121, and at 1, 1.1, 1.2, 1.3, ...,
11.9, 12 etc..
The result from the above prmat function call is 121x121 data
points, however, they are NOT at 1, 1.1, 1.2..
BUT at 1.000000  1.091667  1.183333  1.275000......11.908333 12.000000

Could anyone enlighten me If i want to get estimated value at 1, 1.1,
1.2, 1.3...,  what i should do?

many thanks,
yan


From p.connolly at hortresearch.co.nz  Mon May  5 05:50:21 2003
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Mon, 5 May 2003 15:50:21 +1200
Subject: [R] Matrix manipulation
Message-ID: <20030505035021.GC13579@hortresearch.co.nz>

I have a square matrix wherein a '*' indicates an HSD between the
levels indicated by row name and column name.  The '.' is simply
marking the diagonal.  A blank indicates the same group


  A B C D E F G H I J K L M N
A .                          
B   .                        
C * * .                      
D * *   .                    
E * * *   .                  
F * * *     .                
G * * *       .              
H * * *         .            
I * * * * * * *   .          
J * * * * * * *     .        
K * * * * * * * *     .      
L * * * * * * * * * *   .    
M * * * * * * * * * *     .  
N * * * * * * * * * * * *   .


I'm having trouble devising a method that ends up with groups of the
14 levels, such as this:

A a
B a
C b
D bc
E c
F c
G c
H cd
I d
J d
K d
L de
M de
N e

It's not important to make it vectorized, since the matrix is small,
but I could be doing this often enough to not want to do it by hand.

Suggestions welcome.

Thanks

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~


From juli at ceam.es  Mon May  5 09:15:33 2003
From: juli at ceam.es (juli g. pausas)
Date: Mon, 05 May 2003 09:15:33 +0200
Subject: [R] image of expand.grid
References: <3EB51E06.4050003@ceam.es>
	<3EB52449.90801@statistik.uni-dortmund.de>
Message-ID: <3EB60F95.8070701@ceam.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030505/9cea01d1/attachment.pl

From sandrine.mainard1 at etud.univ-ubs.fr  Mon May  5 09:41:52 2003
From: sandrine.mainard1 at etud.univ-ubs.fr (sandrine.mainard1@etud.univ-ubs.fr)
Date: Mon,  5 May 2003 09:41:52 +0200
Subject: [R] NA on multtest
Message-ID: <1052120512.3eb615c0cd18a@homae.univ-ubs.fr>


Hello, 

I have one question about the mt.rawp2adjp in the mulltest package. Indeed, i 
have a database about fit and ill mice,and there are some "NA". I wanted to 
realise the mt.rawp2adjp, in order to have pvalue of several tests, but the 
Hochberg,BH and BY return me "NA" for all lines. Don't they accept the "NA" 
value, contrary the other tests? 

Thanks a lot 


Sandrine Mainard 




--------------------------------------------------------------------------------
Universit de Bretagne sud                               http://www.univ-ubs.fr/



From ligges at statistik.uni-dortmund.de  Mon May  5 10:00:09 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 05 May 2003 10:00:09 +0200
Subject: [R] image of expand.grid
In-Reply-To: <3EB60F95.8070701@ceam.es>
References: <3EB51E06.4050003@ceam.es>
	<3EB52449.90801@statistik.uni-dortmund.de>
	<3EB60F95.8070701@ceam.es>
Message-ID: <3EB61A09.9030102@statistik.uni-dortmund.de>

juli g. pausas wrote:
>  Uwe Ligges wrote:
> 
>> juli g. pausas wrote:
>>
>>> Hi all,
>>> It is not clear to me why this cannot be ploted with image. Any help?
>>>
>>>  > g <- data.frame(expand.grid(x= 1:5, y= 1:5), z= rnorm(25))
>>>  > image(g)
>>> Error in image.default(g) : increasing x and y values expected 
>>
>>
>>
>> The error message states: "increasing x and y values expected".
>> image() is really clever and you don't need expand.grid() in this case 
>> (in principle, image() does it itself):
>>
>>  g <- list(x = 1:5, y = 1:5, z = matrix(rnorm(25), 5))
>>  image(g) 
> 
> 
> 
> Uwe,
> Thanks for your reply.
> I undertand that if z is a matrix, then x and y are not needed:
>    image( matrix(rnorm(25), 5) )
> 
> My question was, if I've got 'x', 'y' and 'z', where x and y are the 
> coordinates of the z values, can I use image to ploted them?
> Perhaps a more realistic example would be, when the grid is incomplete 
> such as in h:
> 
> g <- data.frame(expand.grid(x= 1:5, y= 1:5), z= rnorm(25))
> h <- g[sample(nrow(g), 20), ]    # remove some cells
> 
>  From the help pages I thought it was possible:
> 
> Arguments:
>     x,y: locations of grid lines at which the values in `z' are
>          measured.  These must be in (strictly) ascending order. By ...
> 
> this is why my suggestion was a list with x, y, and z of the same length 
> (coordinates and z-values). But I suppose I misunderstood the help, and 
> it is  not possible to use image() in this case, even with the complete 
> coordinates (g).
> I have found an alternative way,  using as.image() in the 'fields' library:
> 
> image(as.image(h$z, data.frame(x= h$x, y= h$y), ncol=5, nrow=5))
> 
> cheers
> Juli

 From ?image:

   z  a matrix containing .....

So z must be a matrix, even if used as a component of a list.
NAs are allowed in z.

Uwe Ligges



From ernesto at ipimar.pt  Mon May  5 10:45:59 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Mon, 05 May 2003 08:45:59 -0000
Subject: [R] package "sgeostat"
In-Reply-To: <Pine.SOL.4.33.0305041926400.12152-100000@panther.cs.ucla.edu>
References: <Pine.SOL.4.33.0305041926400.12152-100000@panther.cs.ucla.edu>
Message-ID: <1052124327.7356.5.camel@gandalf.ipimar.pt>

On Mon, 2003-05-05 at 03:40, Yan Yu wrote:
> Greetings, all:
>   I am wondering have anyone used package "sgeosta" before,
> I have a Q about its variogram fitting function:
> fit.exponential, fit.gaussian and fit.wave
> 
> they ask for a few parameters, which I have no clue how to set them..
> e.g., they list this example:
> maas.vmod<-fit.gaussian(maas.v,c0=60000,cg=110000,ag=800,plot.it=TRUE,
> iterations=30
> 
> In the manual page, they list the meaning of those paramters that have
> model dependent meanings:
> 
> c0:                        initial estimate for nugget effect, valid for all
> variogram types, partial sill (cX) and
>                         (asymptotical) range (aX) as follows:
>  ce, ae
>                         initial estimates for the exponential variogram
> model
>  cg, ag
>                         initial estimates for the gaussian variogram model
>  cs, as
>                         initial estimates for the sperical variogram model
>  cw, aw
>                         initial estimates for the periodical variogram model
> 
> Sorry for my ignorance on those models, my Qs is:
> 1) what is the rule of thumb to set the above parameters?
> 2) Does it really matter how I set those initial estimates? How much
> influence the initial parameter setting is going to have on the final
> model fitting?
> 3) How do I know if I set those parameters right or way off?
> 
> thanks a lot!
> yan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

Hi

Those are the parameters of the variogram function you want to adjust.
See some reference about spatial stats like "Statistics for Spatial
Data" from Cressie (1993) or "Spatial Statistics" from Ripley (1981).
Usually you should get an ideia of that parameters looking at the
empirical variogram.

EJ



From laurent.faisnel at ariase.com  Mon May  5 10:56:53 2003
From: laurent.faisnel at ariase.com (Laurent Faisnel)
Date: Mon, 05 May 2003 10:56:53 +0200
Subject: [R] my RMySQL connections are so SLOW
Message-ID: <3EB62755.3030807@ariase.com>

Hi all,
I'm using the latest RMySQL to send requests to a MySQL database (which 
is quite small for the time - let's say 20 tables with a total of 1000 
rows), and this should be part of a whole decisionnal system. It 
produces results which are displayed on a website, and therefore I need 
fast results (the database being quite small, I think this must be 
possible !).
Unfortunately, a simple request to the database, and R needs more than 
10 seconds. Even dbListTables() takes a long while. Imagine the problem 
with more data ! Can I hope something better  with RMySQL ? Did anyone 
have the same problem ?
If RMySQL (or is it MySQL's fault ?) is so slow, I could replace MySQL 
with Postgres, but this would imply a lot of extra work. R is perhaps 
very slow anyway ? Any piece of advice ?
Thanks.
Laurent



From ripley at stats.ox.ac.uk  Mon May  5 11:32:34 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 5 May 2003 10:32:34 +0100 (BST)
Subject: [R] my RMySQL connections are so SLOW
In-Reply-To: <3EB62755.3030807@ariase.com>
Message-ID: <Pine.LNX.4.44.0305051029530.27396-100000@gannet.stats>

What exactly are you timing?  For me running a query is instant.
Are you starting R for each query, for example?  What OS and what hardware 
are you using?

People have reported that RODBC is a lot faster than RMySQL for some tasks 
involving large datasets.

On Mon, 5 May 2003, Laurent Faisnel wrote:

> I'm using the latest RMySQL to send requests to a MySQL database (which 
> is quite small for the time - let's say 20 tables with a total of 1000 
> rows), and this should be part of a whole decisionnal system. It 
> produces results which are displayed on a website, and therefore I need 
> fast results (the database being quite small, I think this must be 
> possible !).
> Unfortunately, a simple request to the database, and R needs more than 
> 10 seconds. Even dbListTables() takes a long while. Imagine the problem 
> with more data ! Can I hope something better  with RMySQL ? Did anyone 
> have the same problem ?
> If RMySQL (or is it MySQL's fault ?) is so slow, I could replace MySQL 
> with Postgres, but this would imply a lot of extra work. R is perhaps 
> very slow anyway ? Any piece of advice ?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From laurent.faisnel at ariase.com  Mon May  5 11:55:48 2003
From: laurent.faisnel at ariase.com (Laurent Faisnel)
Date: Mon, 05 May 2003 11:55:48 +0200
Subject: [R] my RMySQL connections are so SLOW
References: <Pine.LNX.4.44.0305051029530.27396-100000@gannet.stats>
Message-ID: <3EB63524.500@ariase.com>

Thank you for your fast answer. I work on a 450MHz Pentium II with 192 
MBytes RAM.
dbListTables() takes about 3 seconds. For direct use it's OK, but when 
requests become included in programs, it makes very slow programs !
 I had to calculate an average score for each value of a column (i=1:12) 
to fill an array, and so the operation (pretty simple) took more than 30 
seconds (almost 3 seconds per "select avg(score)..." request).

I don't think my dataset is huge enough to make it worth using ODBC, 
which would cause other problems. I do not start R for each query. I 
have the same slowness when sending the requests to R directly (without 
using source code).

What makes me hope for a solution is when you say "For me running a 
query is instant". What could be the difference between our systems ? 
The CPU speed does not explain all, in my opinion.

Laurent


/
 > version
         _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    1
minor    6.2
year     2003
month    01
day      10
language R/


Prof Brian Ripley wrote:

>What exactly are you timing?  For me running a query is instant.
>Are you starting R for each query, for example?  What OS and what hardware 
>are you using?
>
>People have reported that RODBC is a lot faster than RMySQL for some tasks 
>involving large datasets.
>
>On Mon, 5 May 2003, Laurent Faisnel wrote:
>
>  
>
>>I'm using the latest RMySQL to send requests to a MySQL database (which 
>>is quite small for the time - let's say 20 tables with a total of 1000 
>>rows), and this should be part of a whole decisionnal system. It 
>>produces results which are displayed on a website, and therefore I need 
>>fast results (the database being quite small, I think this must be 
>>possible !).
>>Unfortunately, a simple request to the database, and R needs more than 
>>10 seconds. Even dbListTables() takes a long while. Imagine the problem 
>>with more data ! Can I hope something better  with RMySQL ? Did anyone 
>>have the same problem ?
>>If RMySQL (or is it MySQL's fault ?) is so slow, I could replace MySQL 
>>with Postgres, but this would imply a lot of extra work. R is perhaps 
>>very slow anyway ? Any piece of advice ?
>>    
>>
>
>  
>



From ernesto at ipimar.pt  Mon May  5 11:57:07 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Mon, 05 May 2003 09:57:07 -0000
Subject: [R] my RMySQL connections are so SLOW
In-Reply-To: <3EB62755.3030807@ariase.com>
References: <3EB62755.3030807@ariase.com>
Message-ID: <1052128612.7356.13.camel@gandalf.ipimar.pt>

On Mon, 2003-05-05 at 09:56, Laurent Faisnel wrote:
> Hi all,
> I'm using the latest RMySQL to send requests to a MySQL database (which 
> is quite small for the time - let's say 20 tables with a total of 1000 
> rows), and this should be part of a whole decisionnal system. It 
> produces results which are displayed on a website, and therefore I need 
> fast results (the database being quite small, I think this must be 
> possible !).
> Unfortunately, a simple request to the database, and R needs more than 
> 10 seconds. Even dbListTables() takes a long while. Imagine the problem 
> with more data ! Can I hope something better  with RMySQL ? Did anyone 
> have the same problem ?
> If RMySQL (or is it MySQL's fault ?) is so slow, I could replace MySQL 
> with Postgres, but this would imply a lot of extra work. R is perhaps 
> very slow anyway ? Any piece of advice ?
> Thanks.
> Laurent
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

Hi

Have you tried to run the sql statement in mysql to check if the problem
is really in RMySQL ? MySQL databases can be very slow if you don't
index the tables. 

Check
http://www.mysql.com/documentation/mysql/bychapter/manual_MySQL_Optimisation.html#MySQL_indexes

Regards

EJ



From ripley at stats.ox.ac.uk  Mon May  5 12:08:16 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 5 May 2003 11:08:16 +0100 (BST)
Subject: [R] my RMySQL connections are so SLOW
In-Reply-To: <3EB63524.500@ariase.com>
Message-ID: <Pine.LNX.4.44.0305051103020.27535-100000@gannet.stats>

On Mon, 5 May 2003, Laurent Faisnel wrote:

> Thank you for your fast answer. I work on a 450MHz Pentium II with 192 
> MBytes RAM.

And Linux.  That's a rather old spec --  4-5 years?

> dbListTables() takes about 3 seconds. For direct use it's OK, but when 
> requests become included in programs, it makes very slow programs !
>  I had to calculate an average score for each value of a column (i=1:12) 
> to fill an array, and so the operation (pretty simple) took more than 30 
> seconds (almost 3 seconds per "select avg(score)..." request).
> 
> I don't think my dataset is huge enough to make it worth using ODBC, 
> which would cause other problems. I do not start R for each query. I 
> have the same slowness when sending the requests to R directly (without 
> using source code).
> 
> What makes me hope for a solution is when you say "For me running a 
> query is instant". What could be the difference between our systems ? 
> The CPU speed does not explain all, in my opinion.

Well, I am using a dual Athlon 2600, 1Gb RAM and a fast local disc system,
so that is a considerable difference.  Maybe you need more RAM.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ernesto at ipimar.pt  Mon May  5 12:35:27 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Mon, 05 May 2003 10:35:27 -0000
Subject: [R] my RMySQL connections are so SLOW
In-Reply-To: <3EB63703.4020200@ariase.com>
References: <3EB62755.3030807@ariase.com>
	<1052128612.7356.13.camel@gandalf.ipimar.pt>
	<3EB63703.4020200@ariase.com>
Message-ID: <1052130913.7360.26.camel@gandalf.ipimar.pt>

On Mon, 2003-05-05 at 11:03, Laurent Faisnel wrote:
> Ernesto Jardim wrote:
> 
> >On Mon, 2003-05-05 at 09:56, Laurent Faisnel wrote:
> >  
> >
> >>Hi all,
> >>I'm using the latest RMySQL to send requests to a MySQL database (which 
> >>is quite small for the time - let's say 20 tables with a total of 1000 
> >>rows), and this should be part of a whole decisionnal system. It 
> >>produces results which are displayed on a website, and therefore I need 
> >>fast results (the database being quite small, I think this must be 
> >>possible !).
> >>Unfortunately, a simple request to the database, and R needs more than 
> >>10 seconds. Even dbListTables() takes a long while. Imagine the problem 
> >>with more data ! Can I hope something better  with RMySQL ? Did anyone 
> >>have the same problem ?
> >>If RMySQL (or is it MySQL's fault ?) is so slow, I could replace MySQL 
> >>with Postgres, but this would imply a lot of extra work. R is perhaps 
> >>very slow anyway ? Any piece of advice ?
> >>Thanks.
> >>Laurent
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >>    
> >>
> >
> >Hi
> >
> >Have you tried to run the sql statement in mysql to check if the problem
> >is really in RMySQL ? MySQL databases can be very slow if you don't
> >index the tables. 
> >
> >Check
> >http://www.mysql.com/documentation/mysql/bychapter/manual_MySQL_Optimisation.html#MySQL_indexes
> >
> >Regards
> >
> >EJ
> >
> >
> >  
> >
> I'll try at once. My tables are not indexed. But I thought this could 
> not explain everything. Anyway, a few tests will be profitable. Thanks
> 

I've had some surprises with table indexing ... The documentation says
it can be 100 times faster!

Regards

EJ



From bernard_ifoley_57 at kpmgjobworld.be  Mon May  5 13:23:17 2003
From: bernard_ifoley_57 at kpmgjobworld.be (Bernard I. Foley)
Date: Mon, 05 May 2003 11:23:17 +0000
Subject: [R] I wish I could be there
Message-ID: <DMAPKCOKJJCODECHDHIFBCINDDAA.bernard_ifoley_57@kpmgjobworld.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030505/ce2beb00/attachment.pl

From dcartwright_38 at zpok.demon.co.uk  Mon May  5 13:29:31 2003
From: dcartwright_38 at zpok.demon.co.uk (Denver Cartwright)
Date: Mon, 05 May 2003 11:29:31 +0000
Subject: [R] Im in
Message-ID: <APELJDNMGPGABOBDCDHENJJFNOAB.dcartwright_38@zpok.demon.co.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030505/907c1120/attachment.pl

From phgrosjean at sciviews.org  Mon May  5 14:14:01 2003
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Mon, 5 May 2003 14:14:01 +0200
Subject: [R-gui] Re: [R] Feedback about SciViews?
In-Reply-To: <6mvvavk97rgg4e1fraiifnfqtelsmidb29@4ax.com>
Message-ID: <MABBLJDICACNFOLGIHJOGENNDGAA.phgrosjean@sciviews.org>

Duncan Murdoch wrote (about a suggestion to make a java R GUI):

>I think the issue is that it's hard now to write any GUI at all,
>because too much UI is in R itself.  As we move towards a separation
>of UI and computation, it may well make sense to write a GUI in Java.

Yes, I fully agree. This is indeed the main, and leading idea of the
SciViews project: a separation of the frontend and the backend.

Otherwise, I was interested by the way this thread is deviated from its
orginal question about impression on the preview version of SciViews (RE:
[R-gui] Re: [R] Feedback about SciViews?). Now, we are once again discussing
which language to use to make a R GUI. I say once again, because it is at
least the fourth, or the fifth time we have this discussion. Well, if there
is something new, where is the problem? Indeed, there is not much new
ideas... nor much more people that move from just giving their own
impression to a more active behaviour. I understand that, because starting a
large project like a R GUI is a big task, and not everybody is willing to
spend a large part of its time and energy to coordinate such a project.

OK, that said, you must realize that, in our (almost) perfect community of
voluntair developers that makes the success of R, the initiation of a R GUI
project is not only a matter of deciding which tool to use in a global and
free discussion within the community. It is rather more fueled by one, or a
few people that actually decide to sacrifice a large amount of their time to
start and coordinate a project. Initiation of such a project is depending on
various criteria, among them:

1) the time the project starts (languages and graphical toolkits are
evolving rapidly, so, it is almost certain that an option taken today would
not necessarily be the same choice if it was done tomorrow; however, when a
project actually starts, many decisions have to be taken, and not delayed
till tomorrow!),

2) the skills, the tastes and the working habits of the people that initiate
a project.

3) the needs, I mean, someone that starts a project does it because he feel
there is a lack somewhere and its intention is to fill the gap. For R GUI,
early discussions last year ended with a conclusion that a
platform-independent GUI should be preferred, but if there is too much
difficulties to reach this independence, then, Windows users should be
targetted first (I was surprised at that time that Macinthosh users where
not reacting,... but at least they do from time to time).

Keep this in mind.

Also, I would say that, if R GUI projects are not evolving rapidly today, it
is precisely because many developers are still wandering which major choices
(like language, graphical toolkit, way to interface R) they would take.
Please, realize now that some people one moving forward. There ARE R GUI
projects in course: SciViews, ObveRsive, Poor Man's GUI, StatPaper,... (see
http://www.r-project.org/GUI). This implies these major choices have already
been done, and also for some projects, it means that several hundreds, or
even thousands of hours of work have been already invested. Please, respect
this. From now, there are two choices:

1) You help in a constructive way these project to move forward,

2) or, you are really unhappy to the choices they did, and more importantly,
YOU EXACTLY KNOW WHY (that is, having a vague idea on what should be good is
one thing, but are you really, really sure you master all the problems?
Certainly not, until you actually start designing and coding the
application!). This means also that, before critisizing choices made in the
current projects, or proposing alternatives, you must really have the same
skills as people that already worked the question of making a R GUI... Well,
fortunatelly, there are several people like that in our community.

To conclude this very long mail (sorry)! I ask the question again: I am
really interested by constructive suggestions and remarks about the first
implementation of a R GUI, as it is done in the SciViews project
(Insider)... and keep in mind that the main objectives of SciViews are:

1) Investigate a separation of the backend and frontend, while offering very
robust interprocess communication and control and,

2) Design an original GUI that is as much ergonomic, powerful, efficient,
and pleasant to use as it could be in the field of statistical and data
analysis.

The fact that it is a Windows-dependent solution is, I believe, less
important that the solutions it could provide to these two topics, and that
could be transposed into other systems/languages, when thay will be
optimized.

Best,

Philippe Grosjean

...........]<(({?<...............<?}))><...............................
 ) ) ) ) )
( ( ( ( (       Dr. Philippe Grosjean
 ) ) ) ) )
( ( ( ( (       LOV, UMR 7093
 ) ) ) ) )      Station Zoologique
( ( ( ( (       Observatoire Oceanologique
 ) ) ) ) )      BP 28
( ( ( ( (       06234 Villefranche sur mer cedex
 ) ) ) ) )      France
( ( ( ( (
 ) ) ) ) )      tel: +33.4.93.76.38.18, fax: +33.4.93.76.38.34
( ( ( ( (
 ) ) ) ) )      e-mail: phgrosjean at sciviews.org
( ( ( ( (       SciViews project coordinator (http://www.sciviews.org)
 ) ) ) ) )
.......................................................................



From laurent.faisnel at ariase.com  Mon May  5 14:22:53 2003
From: laurent.faisnel at ariase.com (Laurent Faisnel)
Date: Mon, 05 May 2003 14:22:53 +0200
Subject: [R] RMySQL connection very slow compared with PHP
References: <Pine.LNX.4.44.0305051103020.27535-100000@gannet.stats>
Message-ID: <3EB6579D.9090104@ariase.com>

Prof Brian Ripley wrote:

>On Mon, 5 May 2003, Laurent Faisnel wrote:
>
>  
>
>>Thank you for your fast answer. I work on a 450MHz Pentium II with 192 
>>MBytes RAM.
>>    
>>
>
>And Linux.  That's a rather old spec --  4-5 years?
>
>  
>
>>dbListTables() takes about 3 seconds. For direct use it's OK, but when 
>>requests become included in programs, it makes very slow programs !
>> I had to calculate an average score for each value of a column (i=1:12) 
>>to fill an array, and so the operation (pretty simple) took more than 30 
>>seconds (almost 3 seconds per "select avg(score)..." request).
>>
>>I don't think my dataset is huge enough to make it worth using ODBC, 
>>which would cause other problems. I do not start R for each query. I 
>>have the same slowness when sending the requests to R directly (without 
>>using source code).
>>
>>What makes me hope for a solution is when you say "For me running a 
>>query is instant". What could be the difference between our systems ? 
>>The CPU speed does not explain all, in my opinion.
>>    
>>
>
>Well, I am using a dual Athlon 2600, 1Gb RAM and a fast local disc system,
>so that is a considerable difference.  Maybe you need more RAM.
>
>  
>
OK. Clearly, I'm disadvantaged by my slow machine ! But there is another 
element I have to give you to help you understand my scepticism. R is 
called by PHP (which manages the web pages that  display amongst others 
statistical results). The first version of our system did not use R. 
Indeed PHP can access the database, and it did the work fine (and fast ! ).
Now I want to use R for a better analysis (in a in evolutive view), but 
I'm very disappointed to note how slow requests are treated. The problem 
cannot be at MySQL's level since it was so fast with PHP (about 100x 
faster I think). So I think there must be a problem with R/RMySQL. 
However, isn't there fast C code in RMySQL ?

Perhaps I do not use the best commands for the requests :

/# beginning of R program (once only)
library(DBI);
library(RMySQL);
con <- dbConnect("MySQL");

# typical request
dbGetQuery(con,"select avg(mark) from table1 where critere=1");
# this takes 2 sec. (instant with PHP & MySQL)
# table1 being a table without index, with 3 columns and only 500 rows/

By the way, how should I close ResultSets to clean the workspace (I 
tried dbSendQuery instead of dbGetQuery) ? Should I give an object name 
to dbSendQuery's result (res) and then delete it (how ? seems to be a 
problem with dbClearResult) ?

Thanks again,
Laurent



From andy_liaw at merck.com  Mon May  5 14:40:30 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 05 May 2003 08:40:30 -0400
Subject: [R] Matrix manipulation
Message-ID: <3A822319EB35174CA3714066D590DCD5C4FABF@usrymx25.merck.com>

Just a wild guess:  How about translating the blanks and diagonal to 0 and
'*' to 1, and do a complete linkage clustering?

Andy

> -----Original Message-----
> From: Patrick Connolly [mailto:p.connolly at hortresearch.co.nz]
> Sent: Sunday, May 04, 2003 11:50 PM
> To: R-help
> Subject: [R] Matrix manipulation
> 
> 
> I have a square matrix wherein a '*' indicates an HSD between the
> levels indicated by row name and column name.  The '.' is simply
> marking the diagonal.  A blank indicates the same group
> 
> 
>   A B C D E F G H I J K L M N
> A .                          
> B   .                        
> C * * .                      
> D * *   .                    
> E * * *   .                  
> F * * *     .                
> G * * *       .              
> H * * *         .            
> I * * * * * * *   .          
> J * * * * * * *     .        
> K * * * * * * * *     .      
> L * * * * * * * * * *   .    
> M * * * * * * * * * *     .  
> N * * * * * * * * * * * *   .
> 
> 
> I'm having trouble devising a method that ends up with groups of the
> 14 levels, such as this:
> 
> A a
> B a
> C b
> D bc
> E c
> F c
> G c
> H cd
> I d
> J d
> K d
> L de
> M de
> N e
> 
> It's not important to make it vectorized, since the matrix is small,
> but I could be doing this often enough to not want to do it by hand.
> 
> Suggestions welcome.
> 
> Thanks
> 
> -- 
> Patrick Connolly
> HortResearch
> Mt Albert
> Auckland
> New Zealand 
> Ph: +64-9 815 4200 x 7188
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
> ~.~.~.~.~
> I have the world`s largest collection of seashells. I keep it on all
> the beaches of the world ... Perhaps you`ve seen it.  
> ---Steven Wright 
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
> ~.~.~.~.~
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From mandevip at uaslp.mx  Mon May  5 14:50:20 2003
From: mandevip at uaslp.mx (Peter B. Mandeville)
Date: Mon, 05 May 2003 07:50:20 -0500
Subject: [R] multcomp and lme
Message-ID: <5.1.0.14.0.20030505074430.00ab0910@uaslp.mx>

I suppose that multcomp in R and multicomp in S-Plus are related and it 
appears that it is possible to use multicomp with lme in S-Plus given the 
following correspondence on s-news

sally.rodriguez at philips.com	12:57 p.m. 24/04/03 -0400	 7	[S] LME summary 
and multicomp.default()

Is it possible to use multicomp with lme in R and if so what is the syntax 
from a simple readily available example such as the data frame HR in the 
library SASmixed?.

Thank you very much.

Peter B.



From rossini at blindglobe.net  Mon May  5 15:43:00 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Mon, 05 May 2003 06:43:00 -0700
Subject: [R-gui] Re: [R] Feedback about SciViews?
In-Reply-To: <MABBLJDICACNFOLGIHJOGENNDGAA.phgrosjean@sciviews.org> ("Philippe
	Grosjean"'s message of "Mon, 5 May 2003 14:14:01 +0200")
References: <MABBLJDICACNFOLGIHJOGENNDGAA.phgrosjean@sciviews.org>
Message-ID: <87bryho6fv.fsf@jeeves.blindglobe.net>

"Philippe Grosjean" <phgrosjean at sciviews.org> writes:

> The fact that it is a Windows-dependent solution is, I believe, less
> important that the solutions it could provide to these two topics, and that
> could be transposed into other systems/languages, when thay will be
> optimized.

Of course, it keeps some of us from being able to easily check it out
without wasting lots of time, unless it happens to run under
Wine... (which I'll let someone else check; I'm a bit too busy these
days). 

best,
-tony

-- 
A.J. Rossini rossini at u.washington.edu http://software.biostat.washington.edu/ 
Biostatistics, U Washington and Fred Hutchinson Cancer Research Center

FHCRC:Tu: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email 
UW  : Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX 

CONFIDENTIALITY NOTICE: This e-mail message and any attachments ... {{dropped}}



From raf1729 at hotmail.com  Mon May  5 16:34:57 2003
From: raf1729 at hotmail.com (R A F)
Date: Mon, 05 May 2003 14:34:57 +0000
Subject: [R] commandArgs()
Message-ID: <Law11-F120XHwGrRDyj00024819@hotmail.com>

Apologies for asking about this, but I don't quite understand how
this works after looking through the FAQ and the Help archives.

Let's say I want to pass "1000" as an argument to R.  I did the
following:

>R CMD BATCH --1000 infile outfile

When I do print( commandArgs() ), I see

[1] ".../R.bin"         "--restore"
[3] "--save"            "--no-readline"
[5] "gui=none"          "--1000"

So commandArgs()[6] is the argument I want.  Does one then go on and
remove the "--" manually and cast this as numeric?  If so, what's the
usual way to do this?  Or am I not understanding this mechanism
properly?

Thanks very much.



From ripley at stats.ox.ac.uk  Mon May  5 16:47:32 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 5 May 2003 15:47:32 +0100 (BST)
Subject: [R] commandArgs()
In-Reply-To: <Law11-F120XHwGrRDyj00024819@hotmail.com>
Message-ID: <Pine.LNX.4.44.0305051541190.28434-100000@gannet.stats>

At present there is no official way to add arguments to R: commandArgs() 
is intended to let you retrieve the standard arguments.

This has been discussed for a long time, but there are problems with doing 
it consistently across platforms: for example Windows allows an extra 
argument, the name of a .RData file, to allow file-association to work.

What you can do reliably across platforms is to pass information in 
environment variables.  Something like

NRUNS=1000 R --vanilla < test.R > test.Rout   (Unix, sh)
Rterm NRUNS=100 --vanilla < test.R > test.Rout (Windows)

and have

nruns <- as.numeric(Sys.getenv("NRUNS"))

in the script test.R

On Mon, 5 May 2003, R A F wrote:

> Apologies for asking about this, but I don't quite understand how
> this works after looking through the FAQ and the Help archives.
> 
> Let's say I want to pass "1000" as an argument to R.  I did the
> following:
> 
> >R CMD BATCH --1000 infile outfile
> 
> When I do print( commandArgs() ), I see
> 
> [1] ".../R.bin"         "--restore"
> [3] "--save"            "--no-readline"
> [5] "gui=none"          "--1000"
> 
> So commandArgs()[6] is the argument I want.  Does one then go on and
> remove the "--" manually and cast this as numeric?  If so, what's the
> usual way to do this?  Or am I not understanding this mechanism
> properly?

There is no such mechanism at present.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From haret at grinnell.edu  Mon May  5 17:56:46 2003
From: haret at grinnell.edu (Timothy S. Hare)
Date: Mon, 05 May 2003 09:56:46 -0600
Subject: [R] Comparing bivariate kernel density estimates
Message-ID: <5.1.0.14.0.20030505093751.0220b9f0@mail.grinnell.edu>

Dear R-Users,

Using R, is there method for comparing two sets of kernel density surfaces? 
I need to implement either a goodness-of-fit test such as 
sm.density.compare [sm], but for bivariate kernel density surfaces, or find 
a means for calculating matrix comparison statistics for asymmetrical matrices.

Background:
I am investigating the territorial behavior of baboons in a closed habitat. 
My data are composed of point spatial coordinates marked with the length of 
occupation in seconds for each baboon observed (N=17). I want to estimate 
the spatial areas of habitual use and compare between individuals to assess 
wether the estimated territories are derived from the same distribution or 
not. I initially thought to use cross-K point pattern analysis, but I could 
not find a way to use the continuous variable attached to each data point. 
I also thought to use the method for comparing kernel density estimates 
describe by Fotheringham, Brunsdon and Charlton in "Quantitative Geography: 
Perspectives on Spatial Analysis", but I cannot find a way to implement the 
calculation of the variance for the comparison of the pairs of matrices.

I appreciate any help in this matter.

Thank You,
Timothy


Timothy S. Hare
Mellon Postdoctoral Fellow and Lecturer
Anthropology Department
Grinnell College                                (641) 269-3966
204 Goodnow Hall                                fax (641) 269-4330
Grinnell, IA 50112-1690                 haret at grinnell.edu

"If a geographer is not fascinated by maps to the extent of always needing 
to be surrounded by them, then that is a clue that he or she [or zie] has 
chosen the wrong profession." -- Carl Sauer
-------------- next part --------------

---




From tord.snall at ebc.uu.se  Mon May  5 17:00:52 2003
From: tord.snall at ebc.uu.se (Tord Snall)
Date: Mon, 05 May 2003 17:00:52 +0200
Subject: [R] Error in library(MASS) : package/namespace load failed
Message-ID: <3.0.6.32.20030505170052.00cf2ea8@mail.anst.uu.se>

Dear all,

I have installed 1.7.0 on my Win XP and want to use MASS. But I get this
error message:

> library(MASS)
Error in namespaceExport(ns, exports) : undefined exports: abbey,
accdeaths, Aids2, Animals, anorexia, austres, bacteria, beav1, beav2,
biopsy, birthwt, ...
Error in library(MASS) : package/namespace load failed

I therefore again downloaded VR.zip. When I extracted the files I always
answered yes to the question of "Would you like to replace the existing file?"

I also "Skip File" MASS.dll because password is needed....?

I've never had this probelm with previous R versions and there is no
problem with other libraries. What have I done wrong?


Thanks in advance for your help!

Sincerely,
Tord



-----------------------------------------------------------------------
Tord Sn?ll
Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
Villav?gen 14			
SE-752 36 Uppsala, Sweden
Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
E-mail: Tord.Snall at ebc.uu.se
Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!



From harald at cepba.upc.es  Mon May  5 17:45:03 2003
From: harald at cepba.upc.es (Harald Servat Gelabert)
Date: Mon, 05 May 2003 17:45:03 +0200
Subject: [R] problems compiling R on AIX5.1
Message-ID: <3EB686FF.B5A66B51@cepba.upc.es>


Hello,

I'm trying to compile R (versions 1.6.0, 1.6.1, 1.6.2 and 1.7.0) on
our IBM Power3 Machine for an external user.

I always used to configure with 
./configure --prefix=/scratch_tmp/harald/instala

I've never achieved to compile 1.7.0 because it seems that a file 
called R.exp is missing (or maybe it's not well referenced on the
makefile).

Output of make:

....
        xlc_r  -I. -I../../../src/include -I../../../src/include 
-I/usr/local/include -DHAVE_CONFIG_H    -O2 -qmaxmem=8192 -c dftables.c -o
dftables.o
        xlc_r -Wl,-brtl -Wl,-bdynamic -Wl,-bE:../../../etc/R.exp -Wl,-bM:SRE
-L/usr/local/lib -o dftables -O2 -qmaxmem=8192 dftables.o
ld: 0706-004 Cannot find or read export file: ../../../etc/R.exp
        ld:accessx(): A file or directory in the path name does not exist.
make: 1254-004 The error code from the last command is 255.

....

For this reason I tried to compile an older version (thos 1.6.x).
First with the XLC/XLF but seems it can't handle .lo files

...
        xlc_r -Wl,-bM:SRE -Wl,-H512 -Wl,-T512 -Wl,-bnoentry -Wl,-bexpall
-Wl,-bI:../../../etc/R.exp -L/usr/local/lib -o R_X11.so  dataentry.lo devX11.lo
rotated.lo rbitmap.lo -lSM -lICE -lX11  -ljpeg -lpng -lz  -lz -ldl -lm -lc
xlc_r: 1501-218 file dataentry.lo contains an incorrect file suffix
xlc_r: 1501-218 file devX11.lo contains an incorrect file suffix
xlc_r: 1501-218 file rotated.lo contains an incorrect file suffix
xlc_r: 1501-218 file rbitmap.lo contains an incorrect file suffix
ld: 0711-317 ERROR: Undefined symbol: .__fixsfsi
ld: 0711-345 Use the -bloadmap or -bnoquiet option to obtain more information.
make: 1254-004 The error code from the last command is 8.
...

Finally I tried to compile with GNU C/F77 adding the flags described
in a pdf where describes how to compile R.

setenv MAIN_LDFLAGS "-Wl,-brtl"
setenv SHLIB_LDFLAGS "-Wl,-G"

p630n17:~/xremora>gcc --version
gcc (GCC) 3.1

It seems to compile correctly, but the when I use q() in the prompt on
R I receive a segmentation fault. Furthermore, I'm unable to run the
checks due to this segfault, but it seems that demo run fine.

I've also tried to configure with --enable-shared, but I receive the
same error (core dump).

Can anyone tell how I could solve this problem?

Best regards and many thanks,


-- 
________________________________________________________________________
             Harald Servat Gelabert (harald at cepba.upc.es)
   o//o      Centre Europeu de Paral.lelisme de Barcelona          CEPBA
  o//o       WWW...: http://www.cepba.upc.es       Tel: +34-93-401 74 23
 o//o        e-mail: suport at cepba.upc.es           Fax: +34-93-401 25 77
o//o  CEPBA  c/Jordi Girona, 1-3, M?dul D6. E-08034 Barcelona, Catalunya
________________________________________________________________________

The optimist thinks that this is the best of all possible worlds,
and the pessimist knows it.
-- J. Robert Oppenheimer, "Bulletin of Atomic Scientists"

We scientists, whose tragic destiny it has been to make the methods
of annihilation ever more gruesome and more effective, must consider
it our solemn and transcendent duty to do all in our power in
preventing these weapons from being used for the brutal purpose for
which they were invented.
-- Albert Einstein,       "Bulletin of Atomic Scientists"



From ripley at stats.ox.ac.uk  Mon May  5 17:52:05 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 5 May 2003 16:52:05 +0100 (BST)
Subject: [R] Error in library(MASS) : package/namespace load failed
In-Reply-To: <3.0.6.32.20030505170052.00cf2ea8@mail.anst.uu.se>
Message-ID: <Pine.LNX.4.44.0305051646330.28587-100000@gannet.stats>

On Mon, 5 May 2003, Tord Snall wrote:

> I have installed 1.7.0 on my Win XP and want to use MASS. But I get this
> error message:
> 
> > library(MASS)
> Error in namespaceExport(ns, exports) : undefined exports: abbey,
> accdeaths, Aids2, Animals, anorexia, austres, bacteria, beav1, beav2,
> biopsy, birthwt, ...
> Error in library(MASS) : package/namespace load failed
> 
> I therefore again downloaded VR.zip. When I extracted the files I always
              ^^^^^
Had you done that before?  You didn't say so, but that would explain the 
symptoms.

> answered yes to the question of "Would you like to replace the existing file?"

*No* VR.zip is available for use with R 1.7.0: did you read the ReadMe in 
wherever you downloaded it from: it probably said `for rw1060/1/2 only'?

> I also "Skip File" MASS.dll because password is needed....?
> 
> I've never had this probelm with previous R versions and there is no
> problem with other libraries. What have I done wrong?

Most recently, installed a version of R 1.6.x on top of one for 1.7.0.
I suspect you've never done that before.

All I can suggest is that uninstall rw1070, remove all traces of the 
damage you have done, and try re-installing.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon May  5 17:55:24 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 5 May 2003 16:55:24 +0100 (BST)
Subject: [R] problems compiling R on AIX5.1
In-Reply-To: <3EB686FF.B5A66B51@cepba.upc.es>
Message-ID: <Pine.LNX.4.44.0305051653040.28587-100000@gannet.stats>

On Mon, 5 May 2003, Harald Servat Gelabert wrote:

> I'm trying to compile R (versions 1.6.0, 1.6.1, 1.6.2 and 1.7.0) on
> our IBM Power3 Machine for an external user.
> 
> I always used to configure with 
> ./configure --prefix=/scratch_tmp/harald/instala
> 
> I've never achieved to compile 1.7.0 because it seems that a file 
> called R.exp is missing (or maybe it's not well referenced on the
> makefile).

That one you can solve by installing pcre yourself, and then 
re-configuring.  You may have to do the same with bzip2 and zlib.
Or you can try deleting the reference to R.exp in the load command in the 
Makefile.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From harald at cepba.upc.es  Mon May  5 18:44:59 2003
From: harald at cepba.upc.es (Harald Servat Gelabert)
Date: Mon, 05 May 2003 18:44:59 +0200
Subject: [R] problems compiling R on AIX5.1
References: <Pine.LNX.4.44.0305051653040.28587-100000@gannet.stats>
Message-ID: <3EB6950B.C51CDF8E@cepba.upc.es>


Thanks for your help. 

I've tried to delete the references to R.exp (it was faster to check :)
but I receive a new error.

---
        xlc_r -Wl,-G -Wl,-bM:SRE -Wl,-H512 -Wl,-T512 -Wl,-bnoentry -Wl,-bexpall
-L/usr/local/lib -o methods.so do_substitute_direct.o methods_list_dispatch.o
method_meta_data.o slot.o class_support.o tests.o   -lm 
mkdir -p -- ../../../../library/methods/libs
dumping R code in package 'methods'
Error in dyn.load(x, as.logical(local), as.logical(now)) : 
        unable to load shared library
"/scratch_tmp/harald/R-1.7.0/library/methods/libs/methods.so":
  
Execution halted
make: 1254-004 The error code from the last command is 1.

---

But the shared library exists

p630n17:/scratch_tmp/harald/R-1.7.0>ls -la
/scratch_tmp/harald/R-1.7.0/library/methods/libs/
total 128
-rwxr-xr-x   1 harald   des           54758 May 05 18:10 methods.so

---

I've tried to compile with XLC and GCC3.1 and both fail on the same
location.

Does anyone any idea for solve this?

Best regards and many thanks,


Prof Brian Ripley wrote:
> 
> On Mon, 5 May 2003, Harald Servat Gelabert wrote:
> 
> > I'm trying to compile R (versions 1.6.0, 1.6.1, 1.6.2 and 1.7.0) on
> > our IBM Power3 Machine for an external user.
> >
> > I always used to configure with
> > ./configure --prefix=/scratch_tmp/harald/instala
> >
> > I've never achieved to compile 1.7.0 because it seems that a file
> > called R.exp is missing (or maybe it's not well referenced on the
> > makefile).
> 
> That one you can solve by installing pcre yourself, and then
> re-configuring.  You may have to do the same with bzip2 and zlib.
> Or you can try deleting the reference to R.exp in the load command in the
> Makefile.
> 
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-- 
________________________________________________________________________
             Harald Servat Gelabert (harald at cepba.upc.es)
   o//o      Centre Europeu de Paral.lelisme de Barcelona          CEPBA
  o//o       WWW...: http://www.cepba.upc.es       Tel: +34-93-401 74 23
 o//o        e-mail: suport at cepba.upc.es           Fax: +34-93-401 25 77
o//o  CEPBA  c/Jordi Girona, 1-3, M?dul D6. E-08034 Barcelona, Catalunya
________________________________________________________________________

The optimist thinks that this is the best of all possible worlds,
and the pessimist knows it.
-- J. Robert Oppenheimer, "Bulletin of Atomic Scientists"

We scientists, whose tragic destiny it has been to make the methods
of annihilation ever more gruesome and more effective, must consider
it our solemn and transcendent duty to do all in our power in
preventing these weapons from being used for the brutal purpose for
which they were invented.
-- Albert Einstein,       "Bulletin of Atomic Scientists"



From pjabardo at ipt.br  Mon May  5 19:36:47 2003
From: pjabardo at ipt.br (Paulo Jabardo)
Date: Mon, 05 May 2003 17:36:47 -0000
Subject: [R] Vectorizing a C call
Message-ID: <1052156325.20836.7.camel@vazao17>

Hello Guys!

I've written a few functions in C (actually jacobi polynomials and
thermodynamic properties of moist air) and I was wandering what is the
best way to vectorize the calls so that it will work as a standard R
function (say 'sin' or 'atan1' for example) and follow the recycling
rules. Do you think it's better to do it inside R or implement that in
my C code or is there any standard way to do it already implemented?

Thanks for any suggestion


Paulo Jabardo
IPT



From arrayprofile at yahoo.com  Mon May  5 19:44:18 2003
From: arrayprofile at yahoo.com (array chip)
Date: Mon, 5 May 2003 10:44:18 -0700 (PDT)
Subject: [R] polr in MASS
Message-ID: <20030505174418.52067.qmail@web41215.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030505/e7d42c38/attachment.pl

From Kosenkov.Kirill at nac.spb.ru  Mon May  5 19:44:03 2003
From: Kosenkov.Kirill at nac.spb.ru (Kosenkov Kirill Nikolaevich)
Date: Mon, 05 May 2003 21:44:03 +0400
Subject: [R] R and Unicode support
In-Reply-To: <3EB6950B.C51CDF8E@cepba.upc.es>
References: <Pine.LNX.4.44.0305051653040.28587-100000@gannet.stats>
	<3EB6950B.C51CDF8E@cepba.upc.es>
Message-ID: <3EB6A2E3.2070606@nac.spb.ru>

Hello!

I have a problem with displaying R plots with Unicode font.
I making labels for a plot in russian language and, when i am
trying to plot i see only strange characters instead of
cyrillic letters.
Fonts, installed in 'Rdevga', are Unicode fonts on my system
(Arial, Times... ).
When i am trying to use non-Unicode fonts (in fact, russian 
postscript fonts with windows-1251 encoding) everything is ok,
but whats wrong with Unicode fonts??

Can i use unicoded strings in R or not? And what type of
encoding R uses to store objects like char-vectors or strings?
How to change this?

I am using R 1.7.0 on Win2k platform.

Thanx and sorry for my English not very good.



From davison at midway.uchicago.edu  Mon May  5 19:57:52 2003
From: davison at midway.uchicago.edu (Daniel Edmund Davison)
Date: Mon, 5 May 2003 12:57:52 -0500 (CDT)
Subject: [R] DNA
In-Reply-To: <20030505174418.52067.qmail@web41215.mail.yahoo.com>
Message-ID: <Pine.GSO.4.21.0305051254430.25663-100000@harper.uchicago.edu>


Hi, is anyone using R for DNA sequence analyses / population
genetics?

Thanks,
Dan

________________________________________________________________________________
Daniel Davison

email: davison at uchicago.edu
tel.: +1 312 665 7010
fax:  +1 312 665 7754
http://home.uchicago.edu/~davison/

Committee on Evolutionary Biology  &  Division of Birds
University of Chicago                 Field Museum of Natural History
1025 E. 57th Street                   1400 S. Lake Shore Drive
Culver Hall 402                       Chicago, IL 60605-2496
Chicago, IL 60637                     U.S.A.
U.S.A.



From brahm at alum.mit.edu  Mon May  5 20:03:51 2003
From: brahm at alum.mit.edu (David Brahm)
Date: Mon, 5 May 2003 14:03:51 -0400
Subject: [R] how to call R function from my C++ program
References: <Pine.LNX.4.44.0305040816170.15979-100000@gannet.stats>
Message-ID: <16054.42887.352085.795162@arbres1a.fmr.com>

Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> ... You can build R as a shared library (libR.so) and link against that ...

The R Installation and Administration manual says,
  "Flag `--enable-R-shlib' [to `configure'] causes the make process to build R
  as a shared library, typically called `libR.so', and to take considerably
  longer, so you probably only want this if you will be using an application
  which embeds R."

Is there any disadvantage to using this flag, beside a longer "make" time?
Does it affect the normal running of R in any way?  I'm curious, because I'm
trying it for the first time now (with R-1.7.0).  Thanks.
-- 
                              -- David Brahm (brahm at alum.mit.edu)



From rossini at blindglobe.net  Mon May  5 20:07:05 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Mon, 05 May 2003 11:07:05 -0700
Subject: [R] DNA
In-Reply-To: <Pine.GSO.4.21.0305051254430.25663-100000@harper.uchicago.edu>
	(Daniel
	Edmund Davison's message of "Mon, 5 May 2003 12:57:52 -0500 (CDT)")
References: <Pine.GSO.4.21.0305051254430.25663-100000@harper.uchicago.edu>
Message-ID: <87ptmxqncm.fsf@jeeves.blindglobe.net>

Daniel Edmund Davison <davison at midway.uchicago.edu> writes:


> Hi, is anyone using R for DNA sequence analyses / population
> genetics?

Yes, but you'll have to be more specific.

-- 
A.J. Rossini rossini at u.washington.edu http://software.biostat.washington.edu/ 
Biostatistics, U Washington and Fred Hutchinson Cancer Research Center

FHCRC:Tu: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email 
UW  : Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX 

CONFIDENTIALITY NOTICE: This e-mail message and any attachments ... {{dropped}}



From arrayprofile at yahoo.com  Mon May  5 20:53:30 2003
From: arrayprofile at yahoo.com (array chip)
Date: Mon, 5 May 2003 11:53:30 -0700 (PDT)
Subject: [R] polr in MASS
In-Reply-To: <Pine.LNX.4.44.0305051913280.29159-100000@gannet.stats>
Message-ID: <20030505185330.67293.qmail@web41215.mail.yahoo.com>

--- Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> On Mon, 5 May 2003, array chip wrote:
> 
> > I misunderstand something here? Or the the way I
> used to reproduce the
> > predicted probabilities is not correct? Thanks
> 
> Yes:
> 
> 1) How to wrap lines in emails
> 
> 2) How to post plain text to mailing lists.
> 
> 3) What the model actually is.
> 
> -- 
> Brian D. Ripley,                 

Sorry that I didn't realize the formatting problem.
Hopefully this time it works:

Hi, I am trying to use the proportional-odds model
using the "polr" function in the MASS library. I tried
with the dataset of "housing" contained in the MASS
book ("Sat" (factor: low, medium, high) is the
dependent variable, "Infl" (low, medium, high), "Type"
(tower, apartment, atrium, terrace) and "Cont" (low,
high) are the predictor variables (factors). And I
have some questions, hope someone could help me out.
The following commands are from the MASS book as well.


>
house.plr<-polr(Sat~Infl+Type+Cont,data=housing,weights=Freq)
> summary(house.plr)

Call: polr(formula = Sat ~ Infl + Type + Cont, data =
housing, weights = Freq)

Coefficients:
                   Value Std. Error   t value
InflMedium     0.5663922 0.10465276  5.412109
InflHigh       1.2888137 0.12715609 10.135682
TypeApartment -0.5723552 0.11923800 -4.800107
TypeAtrium    -0.3661907 0.15517331 -2.359882
TypeTerrace   -1.0910073 0.15148595 -7.202036
ContHigh       0.3602803 0.09553577  3.771156 

Intercepts:
            Value   Std. Error t value
Low|Medium  -0.4961  0.1248    -3.9740
Medium|High  0.6907  0.1255     5.5049 

Residual Deviance: 3479.149 
AIC: 3495.149 

I also tried to predict the probabilities of the 3
categories of "Sat" using the predict function: 

> hnames<-lapply(housing[,-5],levels)
>
house.pr1<-predict(house.plr,expand.grid(hnames[-1]),type="probs")>
cbind(expand.grid(hnames[-1]),round(house.pr1,2))

     Infl      Type Cont  Low Medium High
1     Low     Tower  Low 0.38   0.29 0.33
2  Medium     Tower  Low 0.26   0.27 0.47
3    High     Tower  Low 0.14   0.21 0.65
4     Low Apartment  Low 0.52   0.26 0.22
5  Medium Apartment  Low 0.38   0.29 0.33
6    High Apartment  Low 0.23   0.26 0.51
7     Low    Atrium  Low 0.47   0.27 0.26
8  Medium    Atrium  Low 0.33   0.29 0.38
9    High    Atrium  Low 0.19   0.25 0.56
10    Low   Terrace  Low 0.64   0.21 0.14
11 Medium   Terrace  Low 0.51   0.26 0.23
12   High   Terrace  Low 0.33   0.29 0.38
13    Low     Tower High 0.30   0.28 0.42
14 Medium     Tower High 0.19   0.25 0.56
15   High     Tower High 0.10   0.17 0.72
16    Low Apartment High 0.43   0.28 0.29
17 Medium Apartment High 0.30   0.28 0.42
18   High Apartment High 0.17   0.23 0.60
19    Low    Atrium High 0.38   0.29 0.33
20 Medium    Atrium High 0.26   0.27 0.47
21   High    Atrium High 0.14   0.21 0.64
22    Low   Terrace High 0.56   0.25 0.19
23 Medium   Terrace High 0.42   0.28 0.30
24   High   Terrace High 0.26   0.27 0.47

what I am confused is that when I tried to reproduce
these predicted probabilities using the model
coefficients, I can sometimes get different results: 

for example, for low Infl, Type tower, cont low,  

logit(P(low))=P(low)/(1-P(low))=-0.4961, solve for
P(low)=exp(-0.4961)/(1+exp(-0.4961))=0.38;

and

logit(P(low,
medium))=P(low,medium)/(1-P(low,medium))=0.6907, solve
for P(low,medium)=exp(0.6907)/(1+exp(0.6907))=0.67,
which is the sum of 0.38 plus 0.29.

The above 2 examples showed that I can reproduce the
predicted probabilities when using the intercept
alone. However, for other combinations of the
predictor variables, I can NOT repreduce the results. 


For example, for medium Infl, Type tower, cont low,  

logit(P(low))=P(low)/(1-P(low))=-0.4961+0.56639=0.07029,
solve for P(low)=exp(0.07029)/(1+exp(0.07029))=0.52;
but the probability using "predict" function is 0.26.

and

logit(P(low,
medium))=P(low,medium)/(1-P(low,medium))=0.6907+0.56639=1.25709,
solve for
P(low,medium)=exp(1.25709)/(1+exp(1.25709))=0.78,
which certainly is NOT the sum of 0.26 plus 0.27, and
is not the sum of 0.52 and 0.27. 

Did I misunderstand something here? Or the the way I
used to reproduce the predicted probabilities is not
correct? 

Thanks very much!



From tblackw at umich.edu  Mon May  5 22:23:27 2003
From: tblackw at umich.edu (tblackw@umich.edu)
Date: Mon, 5 May 2003 16:23:27 -0400 (EDT)
Subject: [R] null plotting symbol ?
Message-ID: <200305052023.QAA11744@zektor.gpcc.itd.umich.edu>


I am calling  plot()  with argument pch as a vector of numeric 
symbol codes, the same length as x and y.  Is there some code 
which produces no symbol - a blank - so that I can come back 
with a second call to  points()  and fill in these locations 
using a different fill color and a different symbol size ?  

There's always a work-around, but both x and y are generated 
on the fly by calls to  cumsum(),  so it's inconvenient to put 
NAs into either x or y to suppress plotting that way.  Guess 
I should *try* mixing numeric and character symbol codes, 
although the example in  help("points")  explicitly uses a list 
at that point.  

THX  -  tom blackwell  -  u michigan medical school  -  ann arbor  -



From andy_liaw at merck.com  Mon May  5 22:37:32 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 05 May 2003 16:37:32 -0400
Subject: [R] null plotting symbol ?
Message-ID: <3A822319EB35174CA3714066D590DCD5C4FAC8@usrymx25.merck.com>

Don't know why you need to do that, as it seems to me that's why you pass a
vector to pch, etc., so you won't have to come back and use points().
Anyway, using NA would work.  (However, I suspect I still don't understand
your problem.)

Andy

> -----Original Message-----
> From: tblackw at umich.edu [mailto:tblackw at umich.edu]
> Sent: Monday, May 05, 2003 4:23 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] null plotting symbol ?
> 
> 
> 
> I am calling  plot()  with argument pch as a vector of numeric 
> symbol codes, the same length as x and y.  Is there some code 
> which produces no symbol - a blank - so that I can come back 
> with a second call to  points()  and fill in these locations 
> using a different fill color and a different symbol size ?  
> 
> There's always a work-around, but both x and y are generated 
> on the fly by calls to  cumsum(),  so it's inconvenient to put 
> NAs into either x or y to suppress plotting that way.  Guess 
> I should *try* mixing numeric and character symbol codes, 
> although the example in  help("points")  explicitly uses a list 
> at that point.  
> 
> THX  -  tom blackwell  -  u michigan medical school  -  ann arbor  -
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From ripley at stats.ox.ac.uk  Mon May  5 22:39:46 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 5 May 2003 21:39:46 +0100 (BST)
Subject: [R] null plotting symbol ?
In-Reply-To: <200305052023.QAA11744@zektor.gpcc.itd.umich.edu>
Message-ID: <Pine.LNX.4.44.0305052138420.29452-100000@gannet.stats>

NAs in pch cause the corresponding points to be omitted.

On Mon, 5 May 2003 tblackw at umich.edu wrote:

> I am calling  plot()  with argument pch as a vector of numeric 
> symbol codes, the same length as x and y.  Is there some code 
> which produces no symbol - a blank - so that I can come back 
> with a second call to  points()  and fill in these locations 
> using a different fill color and a different symbol size ?  
> 
> There's always a work-around, but both x and y are generated 
> on the fly by calls to  cumsum(),  so it's inconvenient to put 
> NAs into either x or y to suppress plotting that way.  Guess 
> I should *try* mixing numeric and character symbol codes, 
> although the example in  help("points")  explicitly uses a list 
> at that point.  

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Mon May  5 22:40:34 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon, 05 May 2003 20:40:34 -0000
Subject: [R] null plotting symbol ?
In-Reply-To: <200305052023.QAA11744@zektor.gpcc.itd.umich.edu>
References: <200305052023.QAA11744@zektor.gpcc.itd.umich.edu>
Message-ID: <x24r49azsx.fsf@biostat.ku.dk>

tblackw at umich.edu writes:

> I am calling  plot()  with argument pch as a vector of numeric 
> symbol codes, the same length as x and y.  Is there some code 
> which produces no symbol - a blank - so that I can come back 
> with a second call to  points()  and fill in these locations 
> using a different fill color and a different symbol size ?  
> 
> There's always a work-around, but both x and y are generated 
> on the fly by calls to  cumsum(),  so it's inconvenient to put 
> NAs into either x or y to suppress plotting that way.  Guess 
> I should *try* mixing numeric and character symbol codes, 
> although the example in  help("points")  explicitly uses a list 
> at that point.  

Doesn't NA work there??

plot(1:10,pch=c(1:4,NA,6:10))

works for me on Linux, but there could be device dependencies.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From spencer.graves at pdf.com  Mon May  5 23:09:00 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 05 May 2003 14:09:00 -0700
Subject: [R] null plotting symbol ?
References: <200305052023.QAA11744@zektor.gpcc.itd.umich.edu>
	<x24r49azsx.fsf@biostat.ku.dk>
Message-ID: <3EB6D2EC.3070003@pdf.com>

The following produced symbols of different shapes, sizes, and colors in 
R 1.6.2:

  plot(1:4, pch=1:4, col=1:4, cex=1:4)

The same command to S-Plus 6.1 generated a plot with one symbol, color 
and size, complaining, "Too many values for parameter" pch, col, and cex.

hth.  spencer graves

Peter Dalgaard BSA wrote:
> tblackw at umich.edu writes:
> 
> 
>>I am calling  plot()  with argument pch as a vector of numeric 
>>symbol codes, the same length as x and y.  Is there some code 
>>which produces no symbol - a blank - so that I can come back 
>>with a second call to  points()  and fill in these locations 
>>using a different fill color and a different symbol size ?  
>>
>>There's always a work-around, but both x and y are generated 
>>on the fly by calls to  cumsum(),  so it's inconvenient to put 
>>NAs into either x or y to suppress plotting that way.  Guess 
>>I should *try* mixing numeric and character symbol codes, 
>>although the example in  help("points")  explicitly uses a list 
>>at that point.  
> 
> 
> Doesn't NA work there??
> 
> plot(1:10,pch=c(1:4,NA,6:10))
> 
> works for me on Linux, but there could be device dependencies.
>



From chrysopa at insecta.ufv.br  Tue May  6 00:22:43 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Mon, 5 May 2003 19:22:43 -0300
Subject: [R] Help to make a for for index
Message-ID: <200305051920.34627.chrysopa@insecta.ufv.br>

Hi,

I try to make a vector in a for for loop, but it dont work.

Look:

> a <- 0;for(i in c(1:2)) { for(j in c(1:2)) { a <- i+j; print(a)}}
[1] 2
[1] 3
[1] 3
[1] 4

I try to make this a vector, like this:
[1] 2 3 3 4

> a <- 0;for(i in c(1:2)) { for(j in c(1:2)) { a[j] <- i+j}}; print(a)
[1] 3 4
> a <- 0;for(i in c(1:2)) { for(j in c(1:2)) { a[i] <- i+j}}; print(a)
[1] 3 4

In this way the vector have only the two last loop.

I try another way but it dont work.

How make a correct index for this loop inside loop?

Thanks
Ronaldo
-- 
As coisas por aqui n?o andam, arrastam-se lentamente em dire??o
a lugar nenhum.

Eu hoje acordei assim, otimista...
--
|   // | \\   [*****************************][*******************]
|| ( ?   ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|      V      [UFV/DBA-Entomologia          ][HD: 30 + 10 Gb     ]
||  /     \   [36571-000 Vi?osa - MG        ][RAM: 128 Mb        ]
|  /(.''`.)\  [Fone: 31-3899-2532           ][Video: SiS620-8Mb  ]
||/(: :'  :)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (`. `'` ) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( `-  )   [*****************************][*******************]
||| _/   \_Powered by GNU/Debian W/Sarge D+ || Lxuser#: 205366



From p.dalgaard at biostat.ku.dk  Tue May  6 00:40:47 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon, 05 May 2003 22:40:47 -0000
Subject: [R] Help to make a for for index
In-Reply-To: <200305051920.34627.chrysopa@insecta.ufv.br>
References: <200305051920.34627.chrysopa@insecta.ufv.br>
Message-ID: <x2r87d9fom.fsf@biostat.ku.dk>

"Ronaldo Reis Jr." <chrysopa at insecta.ufv.br> writes:

> Hi,
> 
> I try to make a vector in a for for loop, but it dont work.
> 
> Look:
> 
> > a <- 0;for(i in c(1:2)) { for(j in c(1:2)) { a <- i+j; print(a)}}
> [1] 2
> [1] 3
> [1] 3
> [1] 4
> 
> I try to make this a vector, like this:
> [1] 2 3 3 4
> 
> > a <- 0;for(i in c(1:2)) { for(j in c(1:2)) { a[j] <- i+j}}; print(a)
> [1] 3 4
> > a <- 0;for(i in c(1:2)) { for(j in c(1:2)) { a[i] <- i+j}}; print(a)
> [1] 3 4
> 
> In this way the vector have only the two last loop.
> 
> I try another way but it dont work.
> 
> How make a correct index for this loop inside loop?

Use a 3rd index:

k <- 0
a <- numeric(4)
for(i in 1:2)
   for(j in 1:2){
       k <- k + 1
       a[k] <- i+j
   }
a

or simply

as.vector(outer(1:2,1:2,"+"))

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From tplate at blackmesacapital.com  Tue May  6 00:43:21 2003
From: tplate at blackmesacapital.com (Tony Plate)
Date: Mon, 05 May 2003 16:43:21 -0600
Subject: [R] Help to make a for for index
In-Reply-To: <200305051920.34627.chrysopa@insecta.ufv.br>
Message-ID: <5.2.1.1.2.20030505163643.0391b5b0@mailhost.blackmesacapital.com>

Printing some intermediate expressions can make it clearer what R is trying 
to do:

 > a <- 0;for(i in c(1:2)) { for(j in c(1:2)) { e<-substitute(a[j] <- 
i+j,list(i=i,j=j)); cat("executing:", deparse(e),"\n"); eval(e)}}; print(a)
executing: a[1] <- 1 + 1
executing: a[2] <- 1 + 2
executing: a[1] <- 2 + 1
executing: a[2] <- 2 + 2
[1] 3 4
 >

Perhaps this is what you want: (?)

 > a <- numeric(0);for(i in c(1:2)) { for(j in c(1:2)) { a <- c(a,i+j); 
print(a)}}
[1] 2
[1] 2 3
[1] 2 3 3
[1] 2 3 3 4
 > a
[1] 2 3 3 4
 >

(This is not the most efficient way to construct a vector in a loop, but it 
works and the code captures the spirit of what I'm guessing you were trying 
to do.)

hope this helps,

-- Tony Plate

At Monday 07:22 PM 5/5/2003 -0300, Ronaldo Reis Jr. wrote:
>Hi,
>
>I try to make a vector in a for for loop, but it dont work.
>
>Look:
>
> > a <- 0;for(i in c(1:2)) { for(j in c(1:2)) { a <- i+j; print(a)}}
>[1] 2
>[1] 3
>[1] 3
>[1] 4
>
>I try to make this a vector, like this:
>[1] 2 3 3 4
>
> > a <- 0;for(i in c(1:2)) { for(j in c(1:2)) { a[j] <- i+j}}; print(a)
>[1] 3 4
> > a <- 0;for(i in c(1:2)) { for(j in c(1:2)) { a[i] <- i+j}}; print(a)
>[1] 3 4
>
>In this way the vector have only the two last loop.
>
>I try another way but it dont work.
>
>How make a correct index for this loop inside loop?
>
>Thanks
>Ronaldo
>--
>As coisas por aqui n?o andam, arrastam-se lentamente em dire??o
>a lugar nenhum.
>
>Eu hoje acordei assim, otimista...
>--
>|   // | \\   [*****************************][*******************]
>|| ( ?   ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
>|      V      [UFV/DBA-Entomologia          ][HD: 30 + 10 Gb     ]
>||  /     \   [36571-000 Vi?osa - MG        ][RAM: 128 Mb        ]
>|  /(.''`.)\  [Fone: 31-3899-2532           ][Video: SiS620-8Mb  ]
>||/(: :'  :)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
>|/ (`. `'` ) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
>||  ( `-  )   [*****************************][*******************]
>||| _/   \_Powered by GNU/Debian W/Sarge D+ || Lxuser#: 205366
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From spencer.graves at pdf.com  Tue May  6 00:46:31 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 05 May 2003 15:46:31 -0700
Subject: [R] Help to make a for for index
References: <200305051920.34627.chrysopa@insecta.ufv.br>
Message-ID: <3EB6E9C7.4040106@pdf.com>

Two alternative solutions:

as.vector(outer(1:2, 1:2, "+"))

a <- rep(NA, 4)
i1 <- 0
for(i in 1:2)for(j in 1:2){
	i1 <- i1+1
	a[i1] <- i+j
}
a

hth.  spencer graves

Ronaldo Reis Jr. wrote:
> Hi,
> 
> I try to make a vector in a for for loop, but it dont work.
> 
> Look:
> 
> 
>>a <- 0;for(i in c(1:2)) { for(j in c(1:2)) { a <- i+j; print(a)}}
> 
> [1] 2
> [1] 3
> [1] 3
> [1] 4
> 
> I try to make this a vector, like this:
> [1] 2 3 3 4
> 
> 
>>a <- 0;for(i in c(1:2)) { for(j in c(1:2)) { a[j] <- i+j}}; print(a)
> 
> [1] 3 4
> 
>>a <- 0;for(i in c(1:2)) { for(j in c(1:2)) { a[i] <- i+j}}; print(a)
> 
> [1] 3 4
> 
> In this way the vector have only the two last loop.
> 
> I try another way but it dont work.
> 
> How make a correct index for this loop inside loop?
> 
> Thanks
> Ronaldo



From jhowison at syr.edu  Tue May  6 02:43:26 2003
From: jhowison at syr.edu (James Howison)
Date: Mon, 5 May 2003 20:43:26 -0400
Subject: [R] R vs SPSS output for princomp
Message-ID: <BF63F939-7F5B-11D7-90EC-00306579408C@syr.edu>

Hi,

I am using R to do a principal components analysis for a class
which is generally using SPSS - so some of my question relates to
SPSS output (and this might not be the right place).  I have
scoured the mailing list and the web but can't get a feel for this.
It is annoying because they will be marking to the SPSS output.

Basically I'm getting different values for the component loadings
in SPSS and in R - I suspect that there is some normalization or
scaling going on that I don't understand (and there is plenty I
don't understand).  The scree-plots (and thus eigen values for each
component) and Proportion of Variance figures are identical - but
the factor loadings are an order of magnitude different.  Basically
the SPSS loadings are much higher than those shown by R.

Should the loadings returned by the R princomp function and the
SPSS "Component Matrix" be the same?

And subsidiary question would be:  How does one approximate the
"Kaiser's little jiffy" test for extracting the components (SPSS
by default eliminates those components with eigen values below 1)?
I've been doing this by loadings(DV.prcomped)[,1:x] after inspecting
the scree plot (to set x) - but is there another way?

The full R commands and SPSS syntax follow below along with the
differing output.

Thanks, James
http://freelancepropaganda.com

R analysis
===========
I run:

 > library(mva)
 > DVfmla
~webeval1 + webeval2 + webeval3 + webeval4 + webeval5 + webeval6 +
     webeval7 + webeval8
 > loadings(DV.pca <- princomp(DVfmla, scale=T, cor=T))

Loadings:
          Comp.1 Comp.2 Comp.3 Comp.4 Comp.5 Comp.6 Comp.7 Comp.8
webeval1 -0.357  0.258 -0.202  0.458  0.629 -0.350  0.112 -0.159
webeval2 -0.340  0.510         0.255 -0.305  0.651  0.136 -0.143
webeval3 -0.319  0.316 -0.276 -0.797  0.244        -0.145
webeval4  0.247  0.633  0.681               -0.248
webeval5  0.391  0.150 -0.357 -0.183 -0.158 -0.185  0.584 -0.513
webeval6  0.392  0.252 -0.282  0.140               -0.756 -0.334
webeval7 -0.382  0.128 -0.162        -0.651 -0.596 -0.114  0.121
webeval8  0.377  0.268 -0.428  0.158                0.143  0.746

<snip SS loadings>

 >plot(DV.pca)  # This is exactly the same as the SPSS scree-plot.

SPSS Analysis
=============

FACTOR
   /VARIABLES webeval1 webeval2 webeval3 webeval4
              webeval5 webeval6 webeval7 webeval8
   /MISSING LISTWISE
   /ANALYSIS webeval1 webeval2 webeval3 webeval4
			webeval5 webeval6 webeval7 webeval8
   /PRINT INITIAL EXTRACTION
   /PLOT EIGEN
   /CRITERIA FACTORS(8) ITERATE(25)
   /EXTRACTION PC
   /ROTATION NOROTATE
   /METHOD=CORRELATION .

As mentioned the proportions of varience explained and the scree
plot are identical.  However SPSS produces this "Component Matrix"
which we, in class, have been calling "the loadings":

WEBEVAL1  -0.798  0.253  0.178  0.317 -0.370  0.167 -0.033 -0.037
WEBEVAL2  -0.764  0.487  0.026  0.188  0.186 -0.309 -0.108 -0.043
WEBEVAL3  -0.719  0.309  0.217 -0.564 -0.125 -0.040  0.043  0.052
WEBEVAL4   0.558  0.591 -0.563 -0.063 -0.029  0.131  0.030 -0.019
WEBEVAL5   0.864  0.161  0.313 -0.128  0.075  0.138 -0.221 -0.200
WEBEVAL6   0.876  0.252  0.237  0.100  0.008  0.017 -0.088  0.308
WEBEVAL7  -0.858  0.128  0.133  0.054  0.349  0.308  0.090  0.037
WEBEVAL8   0.847  0.256  0.316  0.111  0.000 -0.087  0.296 -0.094

Can anyone tell me why these are different (It seems likely that
this is a scaling of some kind as the SPSS ones just look to have
been made larger in some way).  Or is it that SPSS is reporting
cumulatively while R is not?

Thanks in advance,
James



From Arnaud.Dowkiw at dpi.qld.gov.au  Tue May  6 04:57:59 2003
From: Arnaud.Dowkiw at dpi.qld.gov.au (Dowkiw, Arnaud)
Date: Tue, 6 May 2003 12:57:59 +1000
Subject: [R] S's plclust and R's hclust
Message-ID: <C2C6EA6C4DADB348BFDF58894B0390120127417F@kinsrv001.dpi.qld.gov.au>

Hello everyone,

Does anyone know how to implement the argument "unit" in R's plclust
function ? I used to use Splus where this argument exists but it has not
been implemented in R's plclust. The reason why I switched from Splus to
R is that Ward's method is not implemented for S's hclust whereas it is
implemented for R's hclust. What I would need is S's plclust and R's
hclust together, either in R or in S.
Many thanks to the ones who will help me solve that trick...

Arnaud 


*************************
Arnaud DOWKIW
Department of Primary Industries
J. Bjelke-Petersen Research Station
KINGAROY, QLD 4610
Australia
T : + 61 7 41 600 700
T : + 61 7 41 600 728 (direct)
F : + 61 7 41 600 760
**************************

********************************DISCLAIMER****************************
The information contained in the above e-mail message or messages 
(which includes any attachments) is confidential and may be legally 
privileged.  It is intended only for the use of the person or entity 
to which it is addressed.  If you are not the addressee any form of 
disclosure, copying, modification, distribution or any action taken 
or omitted in reliance on the information is unauthorised.  Opinions 
contained in the message(s) do not necessarily reflect the opinions 
of the Queensland Government and its authorities.  If you received 
this communication in error, please notify the sender immediately and 
delete it from your computer system network.



From ripley at stats.ox.ac.uk  Tue May  6 09:00:51 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 6 May 2003 08:00:51 +0100 (BST)
Subject: [R] R vs SPSS output for princomp
In-Reply-To: <BF63F939-7F5B-11D7-90EC-00306579408C@syr.edu>
Message-ID: <Pine.LNX.4.44.0305060751350.3194-100000@gannet.stats>

On Mon, 5 May 2003, James Howison wrote:

> I am using R to do a principal components analysis for a class
> which is generally using SPSS - so some of my question relates to
> SPSS output (and this might not be the right place).  I have
> scoured the mailing list and the web but can't get a feel for this.
> It is annoying because they will be marking to the SPSS output.
> 
> Basically I'm getting different values for the component loadings
> in SPSS and in R - I suspect that there is some normalization or
> scaling going on that I don't understand (and there is plenty I
> don't understand).  The scree-plots (and thus eigen values for each
> component) and Proportion of Variance figures are identical - but
> the factor loadings are an order of magnitude different.  Basically
> the SPSS loadings are much higher than those shown by R.
> 
> Should the loadings returned by the R princomp function and the
> SPSS "Component Matrix" be the same?

Only if they are defined the same.  The length of a PCA loading is 
arbitrary.  R's are of length (sum of squares of coefficients) one:
how are SPSS's defined?

> And subsidiary question would be:  How does one approximate the
> "Kaiser's little jiffy" test for extracting the components (SPSS
> by default eliminates those components with eigen values below 1)?
> I've been doing this by loadings(DV.prcomped)[,1:x] after inspecting
> the scree plot (to set x) - but is there another way?

eigen values of what exactly?  The component sdev is the aquare roots of
the eigenvalues of the (possibly scaled) covariance matrix: maybe you
intend this only for a correlation matrix?

In R you have the source code, so if you know what you want you can find 
the pieces.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From edgar at cs.uprm.edu  Tue May  6 10:04:38 2003
From: edgar at cs.uprm.edu (Edgar Acuna)
Date: Tue, 6 May 2003 04:04:38 -0400 (EDT)
Subject: [R] R vs SPSS output for princomp
In-Reply-To: <BF63F939-7F5B-11D7-90EC-00306579408C@syr.edu>
Message-ID: <Pine.GSO.4.33.0305060401300.9911-100000@cs.uprm.edu>

Hi,
I compared the R's results with those given by MINITAB and SAS and they
are OK. Your problem is with SPSS that unfortunately I have never used it.

Edgar
On Mon, 5 May 2003, James Howison wrote:

> Hi,
>
> I am using R to do a principal components analysis for a class
> which is generally using SPSS - so some of my question relates to
> SPSS output (and this might not be the right place).  I have
> scoured the mailing list and the web but can't get a feel for this.
> It is annoying because they will be marking to the SPSS output.
>
> Basically I'm getting different values for the component loadings
> in SPSS and in R - I suspect that there is some normalization or
> scaling going on that I don't understand (and there is plenty I
> don't understand).  The scree-plots (and thus eigen values for each
> component) and Proportion of Variance figures are identical - but
> the factor loadings are an order of magnitude different.  Basically
> the SPSS loadings are much higher than those shown by R.
>
> Should the loadings returned by the R princomp function and the
> SPSS "Component Matrix" be the same?
>
> And subsidiary question would be:  How does one approximate the
> "Kaiser's little jiffy" test for extracting the components (SPSS
> by default eliminates those components with eigen values below 1)?
> I've been doing this by loadings(DV.prcomped)[,1:x] after inspecting
> the scree plot (to set x) - but is there another way?
>
> The full R commands and SPSS syntax follow below along with the
> differing output.
>
> Thanks, James
> http://freelancepropaganda.com
>
> R analysis
> ===========
> I run:
>
>  > library(mva)
>  > DVfmla
> ~webeval1 + webeval2 + webeval3 + webeval4 + webeval5 + webeval6 +
>      webeval7 + webeval8
>  > loadings(DV.pca <- princomp(DVfmla, scale=T, cor=T))
>
> Loadings:
>           Comp.1 Comp.2 Comp.3 Comp.4 Comp.5 Comp.6 Comp.7 Comp.8
> webeval1 -0.357  0.258 -0.202  0.458  0.629 -0.350  0.112 -0.159
> webeval2 -0.340  0.510         0.255 -0.305  0.651  0.136 -0.143
> webeval3 -0.319  0.316 -0.276 -0.797  0.244        -0.145
> webeval4  0.247  0.633  0.681               -0.248
> webeval5  0.391  0.150 -0.357 -0.183 -0.158 -0.185  0.584 -0.513
> webeval6  0.392  0.252 -0.282  0.140               -0.756 -0.334
> webeval7 -0.382  0.128 -0.162        -0.651 -0.596 -0.114  0.121
> webeval8  0.377  0.268 -0.428  0.158                0.143  0.746
>
> <snip SS loadings>
>
>  >plot(DV.pca)  # This is exactly the same as the SPSS scree-plot.
>
> SPSS Analysis
> =============
>
> FACTOR
>    /VARIABLES webeval1 webeval2 webeval3 webeval4
>               webeval5 webeval6 webeval7 webeval8
>    /MISSING LISTWISE
>    /ANALYSIS webeval1 webeval2 webeval3 webeval4
> 			webeval5 webeval6 webeval7 webeval8
>    /PRINT INITIAL EXTRACTION
>    /PLOT EIGEN
>    /CRITERIA FACTORS(8) ITERATE(25)
>    /EXTRACTION PC
>    /ROTATION NOROTATE
>    /METHOD=CORRELATION .
>
> As mentioned the proportions of varience explained and the scree
> plot are identical.  However SPSS produces this "Component Matrix"
> which we, in class, have been calling "the loadings":
>
> WEBEVAL1  -0.798  0.253  0.178  0.317 -0.370  0.167 -0.033 -0.037
> WEBEVAL2  -0.764  0.487  0.026  0.188  0.186 -0.309 -0.108 -0.043
> WEBEVAL3  -0.719  0.309  0.217 -0.564 -0.125 -0.040  0.043  0.052
> WEBEVAL4   0.558  0.591 -0.563 -0.063 -0.029  0.131  0.030 -0.019
> WEBEVAL5   0.864  0.161  0.313 -0.128  0.075  0.138 -0.221 -0.200
> WEBEVAL6   0.876  0.252  0.237  0.100  0.008  0.017 -0.088  0.308
> WEBEVAL7  -0.858  0.128  0.133  0.054  0.349  0.308  0.090  0.037
> WEBEVAL8   0.847  0.256  0.316  0.111  0.000 -0.087  0.296 -0.094
>
> Can anyone tell me why these are different (It seems likely that
> this is a scaling of some kind as the SPSS ones just look to have
> been made larger in some way).  Or is it that SPSS is reporting
> cumulatively while R is not?
>
> Thanks in advance,
> James
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From ripley at stats.ox.ac.uk  Tue May  6 09:20:58 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 6 May 2003 08:20:58 +0100 (BST)
Subject: [R] S's plclust and R's hclust
In-Reply-To: <C2C6EA6C4DADB348BFDF58894B0390120127417F@kinsrv001.dpi.qld.gov.au>
Message-ID: <Pine.LNX.4.44.0305060813090.3271-100000@gannet.stats>

On Tue, 6 May 2003, Dowkiw, Arnaud wrote:

> Does anyone know how to implement the argument "unit" in R's plclust
> function ? I used to use Splus where this argument exists but it has not
> been implemented in R's plclust. The reason why I switched from Splus to
> R is that Ward's method is not implemented for S's hclust whereas it is
> implemented for R's hclust. What I would need is S's plclust and R's
> hclust together, either in R or in S.
> Many thanks to the ones who will help me solve that trick...

All `unit' does is to rescale the `height' component.  Follow this 
example:

data(USArrests)
hc <- hclust(dist(USArrests), "ward")
plot(hc)
hc1 <- hc
hc1$height <- rank(hc$height)
plot(hc1)


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From wl at eimb.ru  Tue May  6 10:23:36 2003
From: wl at eimb.ru (Wladimir Eremeev)
Date: Tue, 6 May 2003 12:23:36 +0400
Subject: [R] xyplot (lattice), strip.default
Message-ID: <9516.030506@eimb.ru>

Dear r-help,

  I've got data of the following structure
1979  93.428747  0
1979  87.298608  20
1979  78.506340  40
...
1979  45.567890  340
1980  60.815289  0
1980  49.630904  20
1980  24.981362  40
...

The first column is year and the last one is the longitude.
I need a set of graphs showing the dependence of the middle value on
the longitude, for each year, situated one blow the other.
I.e.
1979: --...---```--``--..
1980: ...--``../``\...---
...
etc.

Here characters ---...---``` denote the curve.
The middle value is on the vertical axis
and the latitude is on the horizontal axis of each graph.

To do this I use xyplot function from the Lattice package:

xyplot(ac15$"value"~ac15$lon|year,data=ac15,
       type="l",
       layout=c(1,24),
       xlab="Longitude",
       as.table=TRUE,
       bg="white"
      );

But I have some problems using it.

Questions:

1. How to make xyplot to draw the year value in the strip above each
graph instead of writing the word 'year'?

2. I'd like to produce a .png file with graphs without drawing them on
the screen.

I try:
png(filename = "Rplot.png", width = 480, height = 1024, pointsize = 12,
         bg = "white");

trellis.device(device=getOption("png"),
               color = FALSE,
               bg = "white" );

xyplot.... [see above]

But I get the error message:

Error in trellis.device(device = getOption("png"), color = FALSE, bg = "white") :
        couldn't find function "device.call"

Where's the problem?

I use R 1.7.0 and Windows NT 4.0 workstation.

Thank you for attention and help!

-- 
Best regards
Wladimir Eremeev                                     mailto:wl at eimb.ru

==========================================================================
Research Scientist                                Leninsky Prospect 33,
Space Monitoring & Ecoinformation Systems Sector, Moscow, Russia, 119071,
Institute of Ecology,                             Phone: (095) 135-9972;
Russian Academy of Sciences                       Fax: (095) 954-5534



From ernesto at ipimar.pt  Tue May  6 10:38:05 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Tue, 06 May 2003 08:38:05 -0000
Subject: [R] RMySQL connection very slow compared with PHP
In-Reply-To: <3EB6579D.9090104@ariase.com>
References: <Pine.LNX.4.44.0305051103020.27535-100000@gannet.stats>
	<3EB6579D.9090104@ariase.com>
Message-ID: <1052210269.10976.18.camel@gandalf.ipimar.pt>

On Mon, 2003-05-05 at 13:22, Laurent Faisnel wrote:
> Prof Brian Ripley wrote:
> 
> >On Mon, 5 May 2003, Laurent Faisnel wrote:
> >
> >  
> >
> >>Thank you for your fast answer. I work on a 450MHz Pentium II with 192 
> >>MBytes RAM.
> >>    
> >>
> >
> >And Linux.  That's a rather old spec --  4-5 years?
> >
> >  
> >
> >>dbListTables() takes about 3 seconds. For direct use it's OK, but when 
> >>requests become included in programs, it makes very slow programs !
> >> I had to calculate an average score for each value of a column (i=1:12) 
> >>to fill an array, and so the operation (pretty simple) took more than 30 
> >>seconds (almost 3 seconds per "select avg(score)..." request).
> >>
> >>I don't think my dataset is huge enough to make it worth using ODBC, 
> >>which would cause other problems. I do not start R for each query. I 
> >>have the same slowness when sending the requests to R directly (without 
> >>using source code).
> >>
> >>What makes me hope for a solution is when you say "For me running a 
> >>query is instant". What could be the difference between our systems ? 
> >>The CPU speed does not explain all, in my opinion.
> >>    
> >>
> >
> >Well, I am using a dual Athlon 2600, 1Gb RAM and a fast local disc system,
> >so that is a considerable difference.  Maybe you need more RAM.
> >
> >  
> >
> OK. Clearly, I'm disadvantaged by my slow machine ! But there is another 
> element I have to give you to help you understand my scepticism. R is 
> called by PHP (which manages the web pages that  display amongst others 
> statistical results). The first version of our system did not use R. 
> Indeed PHP can access the database, and it did the work fine (and fast ! ).
> Now I want to use R for a better analysis (in a in evolutive view), but 
> I'm very disappointed to note how slow requests are treated. The problem 
> cannot be at MySQL's level since it was so fast with PHP (about 100x 
> faster I think). So I think there must be a problem with R/RMySQL. 
> However, isn't there fast C code in RMySQL ?
> 
> Perhaps I do not use the best commands for the requests :
> 
> /# beginning of R program (once only)
> library(DBI);
> library(RMySQL);
> con <- dbConnect("MySQL");
> 
> # typical request
> dbGetQuery(con,"select avg(mark) from table1 where critere=1");
> # this takes 2 sec. (instant with PHP & MySQL)
> # table1 being a table without index, with 3 columns and only 500 rows/
> 
> By the way, how should I close ResultSets to clean the workspace (I 
> tried dbSendQuery instead of dbGetQuery) ? Should I give an object name 
> to dbSendQuery's result (res) and then delete it (how ? seems to be a 
> problem with dbClearResult) ?
> 
> Thanks again,
> Laurent
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


Hi

Have you tried to run the commands inside R whithout php calling R ? Was
it slow ? Why are you making an average inside SQL if you're using R ?
Should it be better to select the dataset you want to work with and than
make the analysis inside R ?

Once again in my opinion you'll win a lot of speed if you index your
tables.

Regards

EJ



From ripley at stats.ox.ac.uk  Tue May  6 10:40:32 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 6 May 2003 09:40:32 +0100 (BST)
Subject: [R] xyplot (lattice), strip.default
In-Reply-To: <9516.030506@eimb.ru>
Message-ID: <Pine.LNX.4.44.0305060937570.14252-100000@gannet.stats>

On Tue, 6 May 2003, Wladimir Eremeev wrote:

> 2. I'd like to produce a .png file with graphs without drawing them on
> the screen.
> 
> I try:
> png(filename = "Rplot.png", width = 480, height = 1024, pointsize = 12,
>          bg = "white");
> 
> trellis.device(device=getOption("png"),
>                color = FALSE,
>                bg = "white" );
> 
> xyplot.... [see above]
> 
> But I get the error message:
> 
> Error in trellis.device(device = getOption("png"), color = FALSE, bg = "white") :
>         couldn't find function "device.call"
> 
> Where's the problem?

Thare is no option "png".  Look at the help for trellis.device to see what 
you should be using as a `device' argument: it even lists how to use the 
png() device.

> I use R 1.7.0 and Windows NT 4.0 workstation.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From johnkyari2003 at netscape.net  Tue May  6 10:53:06 2003
From: johnkyari2003 at netscape.net (MR. JOHN KYARI)
Date: Tue, 06 May 2003 10:53:06
Subject: [R] dear friend
Message-ID: <200305060853.h468rAT2021475@hypatia.math.ethz.ch>

Dear Friend,                                    

Compliment of the day, I am JOHN KYARI, The son of late General Kubwa Kyari of the Democratic Republic of Congo. 

My father was a General in the Congolese Army. In his position (My father) with the office of the presidentcy during the regime of Laurent Kabila, he was assigned on a secret mission to source and acquire arms internationally in order to strengthen the Government forces against the rebels, which already had the support of Rwandan and Uganda Army.

Meanwhile, he was still negotiating for the purchase of the arms, he received on the 16th January 2001 news of the assassination of Laurent Kabila which force him to call off the assignment and deposited the sum of US$12.5M, Packed in a diplomatic case in a private security company in the Hague, the Netherlands, though he registered the content as precious stones while the real content is (US12.5M) meant for the purchase of arms for the Congolese Army.

My father went home for the funeral of the late president, but on his arrival he was arrested, detained and tortured, unfortunately my father suffer cardiac arrest and died on the 17th of March 2001. However,one of our numerous visits, my mother and I paid him while in prison, my father was able to reveal this secret to me and advice that i should proceed to the Netherlands to claim the money, he handed me all the relevant documents that will enable me claim the box from the security company.Already, I have made my first visit to the security company and the document entitled to clear this money is with a finance security company in Holland.

On our arrival in the Netherlands few months ago, we sought for political asylum; which was granted. My mother and I are making frantic effort on the best way to handle this money. We sought advice from an attorney who advised that we must seek for a trustworthy foreign business partner whom can invest this fund in a profitable venture. This we view as the best option because our refugee status dose not permit us to operate a bank account, hence we seek your assistance and hope you could be trusted.

I got your contact from the commercial section of the congolese embassy in Belgium. Meanwhile, I sincerely ask for your assistance to get this money through your account, Your share for assisting us will be 25% of the total sum, 5% will be use for upsetting all the expenses incurred in the course of concluding this venture and the remaining 70% that will be for me and my family. Also you stand to gain from any investment you might introduce us into after the conclusion of the transfer.

Please keep this confidential until we finalize and get this money into your account for security reasons. 

This is my e-mail address you can reach me:(johnkyari2003 at netscape.net)
Telephone number:0031-630664061

Thanks and GOD bless 

MR, JOHN KYARI



From uth at zhwin.ch  Tue May  6 11:57:24 2003
From: uth at zhwin.ch (=?iso-8859-1?Q?=22Untern=E4hrer_Thomas=2C_uth=22?=)
Date: Tue, 6 May 2003 11:57:24 +0200
Subject: [R] C++ - R - example
Message-ID: <6A4BCEF0FD65344A8F496D7E520DD8B9023E90A2@lobster.zhwin.ch>


Hi,

Does anybody has a simple example (a for loop, or so) how to use a C-function
In R? 
If it's possible, a *.cpp-file and what I need (wrapper or what ever).
I'm absolutly not a C++-hacker!

I try several ways, was reading the "writing R extension" and the windows-FAQ, but failed.

I try to programm a matrix inversion in a for-loop in C, which needs much time in R and want to 
load it as a function with dynload and .C into R.
If somebody has already done it...

I use VC++ and R 1.6.2


Thanks a lot

Thomas



From casiano at ull.es  Tue May  6 12:43:31 2003
From: casiano at ull.es (Casiano Rodriguez Leon)
Date: Tue, 6 May 2003 11:43:31 +0100 (WEST)
Subject: [R] searching for an analytical function 
Message-ID: <Pine.LNX.4.44.0305061127180.6038-100000@nereida.deioc.ull.es>

Hello all,

This is the problem I am dealing with:

I have an R data frame with the sample of observations of the control
variables "x1", "x2" , ... and the response variable "y".
I also have a set of "base" functions = "x1, "x2", ..., "log(x1)",
"log(x2)", ...

What I need is to have the ANALYTICAL function, i.e. a polynom of the
given base functions, (s.t like x1^3*log(x2) ) that represents my data,
i.e. that minimizes the average errors of the predictions.

I guess that using non-parametric regression I can obtain a non analytical
answer. Do you know of any solutions for that problem or similars?  If so,
where can I find them?

Many, many thanks,

Casiano



From Torsten.Hothorn at rzmail.uni-erlangen.de  Tue May  6 12:35:32 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Tue, 6 May 2003 12:35:32 +0200 (CEST)
Subject: [R] multcomp and lme
Message-ID: <Pine.LNX.4.51.0305061219320.5832@artemis.imbe.med.uni-erlangen.de>


> I suppose that multcomp in R and multicomp in S-Plus are related

not really, there are huge differences.

> and it
> appears that it is possible to use multicomp with lme in S-Plus given
> the
> following correspondence on s-news
>
> sally.rodriguez at philips.com     12:57 p.m. 24/04/03 -0400        7
> [S] LME
> summary
> and multicomp.default()
>
> Is it possible to use multicomp with lme in R and if so what is the
> syntax
> from a simple readily available example such as the data frame HR in the
> library SASmixed?.
>

it is possible, yes, but you have to do some extra work. The package
offers two low-level functions `csimint' and `csimtest' which compute
adjusted p-values based on the estimated effects and their covariance
matrix. That means that you have to

1) compute the appropriate contrast matrix (maybe using `contrMat')
2) define the contrasts of the factor of interest (there is a section
   in MASS on how to do it)
3) fit the model
4) and compute the covariance matrix via `vcov'

and you have everything you need to proceed. I attach a short example
using glm, lme should be along the same lines...

best,

Torsten

---------------------------------------------------------------------

library(multcomp)

set.seed(290875)

# a factor at three levels
group <- factor(c(rep(1,10), rep(2, 10), rep(3,10)))

# Williams contrasts
contrasts(group) <- mginv(contrMat(table(group), type="Will"))

# a binary response
z <- factor(rbinom(30, 1, 0.5))

# estimate the model
gmod <- glm( z ~ group, family=binomial(link = "logit"))

# exclude the intercept
summary(csimtest(coef(gmod)[2:3], vcov(gmod)[2:3,2:3],
                 cmatrix=diag(2), df=27))



> Thank you very much.
>
> Peter B.


 _______________________________________________________________________
|									|
|	Dipl.-Stat. Torsten Hothorn					|
|	Institut fuer Medizininformatik, Biometrie und Epidemiologie	|
|	Waldstrasse 6, D-91054 Erlangen, Deutschland			|
|	Tel: ++49-9131-85-22707	(dienstl.)				|
|	Fax: ++49-9131-85-25740						|
|	Email: Torsten.Hothorn at rzmail.uni-erlangen.de			|
|	Web: http://www.imbe.med.uni-erlangen.de/~hothorn		|
|_______________________________________________________________________|



From partha_bagchi at hgsi.com  Tue May  6 13:40:53 2003
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Tue, 6 May 2003 07:40:53 -0400
Subject: [R] null plotting symbol ?
Message-ID: <OF10341F8C.ACD6F05F-ON85256D1E.00401C33-85256D1E.00402B94@hgsi.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030506/2f3b8a82/attachment.pl

From ripley at stats.ox.ac.uk  Tue May  6 14:04:31 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 6 May 2003 13:04:31 +0100 (BST)
Subject: [R] null plotting symbol ?
In-Reply-To: <OF10341F8C.ACD6F05F-ON85256D1E.00401C33-85256D1E.00402B94@hgsi.com>
Message-ID: <Pine.LNX.4.44.0305061257510.1246-100000@gannet.stats>

On Tue, 6 May 2003 partha_bagchi at hgsi.com wrote:

> pch = 26 seems to produce a blank symbol.

More accurately, it plots nothing.  (A `blank' symbol' suggests to me that
it plots in the background colour.)  That is true *currently* (26-31 are
unassigned), but there is no guarantee that will remain so.

Why would one use that rather than NA, whose meaning is clear?

In brief: what exactly was your point?  Were you seriously suggesting 
using pch=26?

> Prof Brian Ripley <ripley at stats.ox.ac.uk>
> Sent by: r-help-bounces at stat.math.ethz.ch
> 05/05/2003 04:39 PM
> 
>  
>         To:     tblackw at umich.edu
>         cc:     r-help at stat.math.ethz.ch
>         Subject:        Re: [R] null plotting symbol ?
> 
> 
> NAs in pch cause the corresponding points to be omitted.
> 
> On Mon, 5 May 2003 tblackw at umich.edu wrote:
> 
> > I am calling  plot()  with argument pch as a vector of numeric
> > symbol codes, the same length as x and y.  Is there some code
> > which produces no symbol - a blank - so that I can come back
> > with a second call to  points()  and fill in these locations
> > using a different fill color and a different symbol size ?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From partha_bagchi at hgsi.com  Tue May  6 14:17:55 2003
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Tue, 6 May 2003 08:17:55 -0400
Subject: [R] null plotting symbol ?
Message-ID: <OFDEC882E1.3649F983-ON85256D1E.00435387-85256D1E.00438F7A@hgsi.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030506/ba1b4515/attachment.pl

From lancelot at sentoo.sn  Tue May  6 15:09:31 2003
From: lancelot at sentoo.sn (Renaud Lancelot)
Date: Tue, 06 May 2003 13:09:31 +0000
Subject: [R] xyplot (lattice), strip.default
In-Reply-To: <9516.030506@eimb.ru>
References: <9516.030506@eimb.ru>
Message-ID: <3EB7B40B.2030904@sentoo.sn>

Wladimir Eremeev wrote:
> Dear r-help,
> 
>   I've got data of the following structure
> 1979  93.428747  0
> 1979  87.298608  20
> 1979  78.506340  40
> ...
> 1979  45.567890  340
> 1980  60.815289  0
> 1980  49.630904  20
> 1980  24.981362  40
> ...
> 
> The first column is year and the last one is the longitude.
> I need a set of graphs showing the dependence of the middle value on
> the longitude, for each year, situated one blow the other.
> I.e.
> 1979: --...---```--``--..
> 1980: ...--``../``\...---
> ...
> etc.
> 
> Here characters ---...---``` denote the curve.
> The middle value is on the vertical axis
> and the latitude is on the horizontal axis of each graph.
> 
> To do this I use xyplot function from the Lattice package:
> 
> xyplot(ac15$"value"~ac15$lon|year,data=ac15,
>        type="l",
>        layout=c(1,24),
>        xlab="Longitude",
>        as.table=TRUE,
>        bg="white"
>       );
> 
> But I have some problems using it.
> 
> Questions:
> 
> 1. How to make xyplot to draw the year value in the strip above each
> graph instead of writing the word 'year'?

Look at ?strip.default and try style = 4, or style = 5:

fooData <- data.frame(
     year = factor(rep(2001:2010, each = 20)),
     y = rnorm(200),
     x = rep(1:20, time = 10))

library(lattice)

trellis.device(bg = "white")
xyplot(y ~  x | year, data = fooData,
        type = "l",
        layout = c(1, 10),
        xlab = "Longitude",
        as.table = TRUE,
        strip = function(...) strip.default(style = 5,...)
        )

> 
> 2. I'd like to produce a .png file with graphs without drawing them on
> the screen.

Look at ?trellis.device:

trellis.device(bg = "white",
                device = "png",
                filename = "d:/analyses/fig1.png")
xyplot(y ~  x | year, data = fooData,
        type = "l",
        layout = c(1, 10),
        xlab = "Longitude",
        as.table = TRUE,
        strip = function(...) strip.default(style = 5,...)
        )
dev.off()

Best,

Renaud

> 
> I try:
> png(filename = "Rplot.png", width = 480, height = 1024, pointsize = 12,
>          bg = "white");
> 
> trellis.device(device=getOption("png"),
>                color = FALSE,
>                bg = "white" );
> 
> xyplot.... [see above]
> 
> But I get the error message:
> 
> Error in trellis.device(device = getOption("png"), color = FALSE, bg = "white") :
>         couldn't find function "device.call"
> 
> Where's the problem?
> 
> I use R 1.7.0 and Windows NT 4.0 workstation.
> 
> Thank you for attention and help!
> 


-- 
Dr Renaud Lancelot, v?t?rinaire
CIRAD, D?partement Elevage et M?decine V?t?rinaire (CIRAD-Emvt)
Programme Productions Animales
http://www.cirad.fr/fr/pg_recherche/page.php?id=14

ISRA-LNERV                      tel    +221 832 49 02
BP 2057 Dakar-Hann              fax    +221 821 18 79 (CIRAD)
Senegal                         e-mail renaud.lancelot at cirad.fr



From robertl at sm.luth.se  Tue May  6 15:48:18 2003
From: robertl at sm.luth.se (Robert Lundqvist)
Date: Tue, 6 May 2003 15:48:18 +0200 (MEST)
Subject: [R] "Dumb" plots?
In-Reply-To: <3EB7B40B.2030904@sentoo.sn>
References: <9516.030506@eimb.ru> <3EB7B40B.2030904@sentoo.sn>
Message-ID: <Pine.GSO.4.53.0305061544150.13332@delta5.sm.luth.se>

Is there any neat way of producing character-based "dumb" plots in R
rather than the ordinary very good-looking graphics? It would at times be
both easy and sufficient to include such crude graphs in HTML pages rather
or similar.

--robert



From fredrik.lundgren at norrkoping.mail.telia.com  Tue May  6 15:46:26 2003
From: fredrik.lundgren at norrkoping.mail.telia.com (Fredrik Lundgren)
Date: Tue, 6 May 2003 15:46:26 +0200
Subject: [R] "help.start() and kde konqueror"
Message-ID: <200305061539.56926.fredrik.lundgren@norrkoping.mail.telia.com>

Hello,

When I attempt to use KDE 3.03 "konqueror" for help.start() I can't get the 
search engine to work but otherwise help.start() is OK. How should 
"konqueror" be setup for this?

The response to the command is below:
> help.start(browser= 'konqueror')
Making links in per-session dir ...
If konqueror is already running, it is *not* restarted, and you must
    switch to its window.
Otherwise, be patient ...
> konqueror: Ok?nd v?ljare "-remote". /Unknown chooser "-remote". - 
translation from Swedish/
konqueror: Anv?nd --help f?r att f? en lista med de tillg?ngliga 
kommandoradsv?ljarna./konqueror: Use --help for a list with the abvailable 
command line choosers. - translation from Swedish/

The response to the command with netscape (where the search engine works) is 
below):

> help.start(browser= 'netscape')
Changing the default browser (as specified by the `browser' option) to
    the given browser so that it gets used for all future help
    requests.
Making links in per-session dir ...
If netscape is already running, it is *not* restarted, and you must
    switch to its window.
Otherwise, be patient ...
> netscape: root window has no children on display :0.0




SuSE 8.1, KDE 3.03, R 1.7.0, java version "1.3.1_04"
Java(TM) 2 Runtime Environment, Standard Edition (build 1.3.1_04-b02)
Java HotSpot(TM) Client VM (build 1.3.1_04-b02, mixed mode)



Sincerely F Lundgren



From Saghir.Bashir at UCB-Group.com  Tue May  6 16:04:25 2003
From: Saghir.Bashir at UCB-Group.com (Bashir Saghir (Aztek Global))
Date: Tue, 6 May 2003 16:04:25 +0200 
Subject: [R] "Dumb" plots?
Message-ID: <3EBA5559F490D61189430002A5F0AE89030185D0@ntexcrd.braine.ucb>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030506/b680ca8b/attachment.pl

From Fabrizio.DeAmicis at git.generali.ch  Tue May  6 16:08:56 2003
From: Fabrizio.DeAmicis at git.generali.ch (De Amicis Fabrizio (G.I.T.))
Date: Tue, 6 May 2003 16:08:56 +0200 
Subject: [R] Sum by categorical variable
Message-ID: <6C9A2D9477234140A56E9D1B073B28E901DB5C@gitmanex01.git.generali.ch>

Dear R-list,
I have two variables (numerical and categorical) and  would like to have the
sum (and maybe some other statistics) of the numerical variable by the
categorical one. 
Can you help me,
Thank you,
Fabrizio


---------------------------------------------------------------
Fabrizio De Amicis

IT Department
Generali Information Technologies - (GIT)

Centro Galleria 2,
Via Cantonale
CH - 6928 Manno - Switzerland
Tel  +41 91 806 6220
Fax +41 91 806 6298
E-mail: fabrizio.deamicis at git.generali.ch  




************************************************************************
The information in this email is confidential and may be legally... {{dropped}}



From guido at sohne.net  Tue May  6 17:04:08 2003
From: guido at sohne.net (Guido Sohne)
Date: Tue, 6 May 2003 15:04:08 +0000
Subject: [R] "help.start() and kde konqueror"
In-Reply-To: <200305061539.56926.fredrik.lundgren@norrkoping.mail.telia.com>
References: <200305061539.56926.fredrik.lundgren@norrkoping.mail.telia.com>
Message-ID: <20030506150408.GB3020@localhost>

help.start(browser='kfmclient')

On Tue, May 06, 2003 at 03:46:26PM +0200, Fredrik Lundgren wrote:
> Hello,
> 
> When I attempt to use KDE 3.03 "konqueror" for help.start() I can't get the 
> search engine to work but otherwise help.start() is OK. How should 
> "konqueror" be setup for this?
> 
> The response to the command is below:
> > help.start(browser= 'konqueror')
> Making links in per-session dir ...
> If konqueror is already running, it is *not* restarted, and you must
>     switch to its window.
> Otherwise, be patient ...
 
----------------------------------------------------------
Guido Sohne 				   guido at sohne.net
At Large				  http://sohne.net
----------------------------------------------------------
He that composes himself is wiser than he that composes
a book.
		-- B. Franklin



From adrian_humbert at yahoo.com  Tue May  6 16:31:29 2003
From: adrian_humbert at yahoo.com (Adi Humbert)
Date: Tue, 6 May 2003 07:31:29 -0700 (PDT)
Subject: [R] how to read a web page and extract an html table?
Message-ID: <20030506143129.33487.qmail@web12105.mail.yahoo.com>

Hello all, 

I want to read a table from a given web page. 

If I do something like
> str="http://www...."      # this is the web address
> aux1 <- url(str,open="rt")# open connection 
> aux2 <- readLines(aux1)   # read web page 
aux2 contains the html file. 

I want to extract the table from the html file. 
Is there a function html2R, the opposite of R2html? 
How should I do this? 

Thanks, 
Adrian



From B.Rowlingson at lancaster.ac.uk  Tue May  6 16:38:11 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 06 May 2003 15:38:11 +0100
Subject: [R] "Dumb" plots?
In-Reply-To: <Pine.GSO.4.53.0305061544150.13332@delta5.sm.luth.se>
References: <9516.030506@eimb.ru> <3EB7B40B.2030904@sentoo.sn>
	<Pine.GSO.4.53.0305061544150.13332@delta5.sm.luth.se>
Message-ID: <3EB7C8D3.2020708@lancaster.ac.uk>

Robert Lundqvist wrote:
> Is there any neat way of producing character-based "dumb" plots in R
> rather than the ordinary very good-looking graphics? It would at times be
> both easy and sufficient to include such crude graphs in HTML pages rather
> or similar.

  You could always use Splus version 3. It had a crt() and a printer() 
graphics device, which produced ascii plots. I'd paste an example here 
but doubtless the widespread use of proportional fonts would make it 
look like what we used to call 'line noise' back in the old days.

  It can do simple line and point plots, but dont expect too much:

 > printer()
 > image(matrix(runif(100),10,10))
Error in image.default(matrix(runif(100), 10, 10)): Inactive device or
         unimplemented device primitive
Dumped
Error in image
 >

  For those of you with proportional fonts, here's 10 data points with a 
fitted linear model:

      25.........................................
        .                                    *.
        .                                  ...
     20..                               ...
        .                            *.. *
        .                         ...
     15..                    * ...
  y     .                *  ...  *
        .            *   ...
     10..             ...
        .        * ...
        .       ...
      5..*   ...
        . ...
        ..   *
        ........................................
             2       4       6       8       10

                           x


  Since R is open source, if you really really want this, you could 
either write a 'crt()' graphics device for R, or if you really really 
really want it, pay someone to do it!

Baz



From Fabrizio.DeAmicis at git.generali.ch  Tue May  6 16:53:39 2003
From: Fabrizio.DeAmicis at git.generali.ch (De Amicis Fabrizio (G.I.T.))
Date: Tue, 6 May 2003 16:53:39 +0200 
Subject: [R] FW: Sum by categorical variable
Message-ID: <6C9A2D9477234140A56E9D1B073B28E901DB5D@gitmanex01.git.generali.ch>


Another easy(/stupid) question:

with the following command
 j2<-xf1[1:10,"V4"]
I have 

> j2
 [1] CHROMOLI             LINEAGERMAI          RINALDI              GIUNTIMA
AUTOSTELLA          
 [6] CAIZZONE             CENTRO B PEL E C SNC CONSORZI             MAN NORD
PDM                 
1304 Levels:   MACHIAVELLI Snc  MENARINI MANUFACTURERS LOGISTICS SERVICES
... ZUCCHERIFICIO DEL MOLISE

  
Why j2 has 1304 Levels (I know that xf has 1304 rows)? How can I obtain a
vector of 10 elements?

Thank you 


>  
> 
> ---------------------------------------------------------------
> Fabrizio De Amicis
> 
> IT Department
> Generali Information Technologies - (GIT)
> 
> Centro Galleria 2,
> Via Cantonale
> CH - 6928 Manno - Switzerland
> Tel  +41 91 806 6220
> Fax +41 91 806 6298
> E-mail: fabrizio.deamicis at git.generali.ch  
> 
> 
> 
> 
************************************************************************
The information in this email is confidential and may be legally... {{dropped}}



From ma at ne.su.se  Tue May  6 16:59:06 2003
From: ma at ne.su.se (Mahmood ARAI)
Date: Tue, 06 May 2003 16:59:06 +0200
Subject: [R] Re: Sum by categorical variable
In-Reply-To: <6C9A2D9477234140A56E9D1B073B28E901DB5C@gitmanex01.git.generali.ch>
References: <6C9A2D9477234140A56E9D1B073B28E901DB5C@gitmanex01.git.generali.ch>
Message-ID: <20030506145906.AFFA33B89D@mbox2.su.se>

De Amicis Fabrizio (G.I.T.) writes: 

> Dear R-list,
> I have two variables (numerical and categorical) and  would like to have the
> sum (and maybe some other statistics) of the numerical variable by the
> categorical one. 
> Can you help me,
> Thank you,
> Fabrizio 
> 
> 
> ---------------------------------------------------------------
> Fabrizio De Amicis 
> 
> IT Department
> Generali Information Technologies - (GIT) 
> 
> Centro Galleria 2,
> Via Cantonale
> CH - 6928 Manno - Switzerland
> Tel  +41 91 806 6220
> Fax +41 91 806 6298
> E-mail: fabrizio.deamicis at git.generali.ch   
> 
>  
> 
> 
> ************************************************************************
> The information in this email is confidential and may be legally... {{dropped}} 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
 

ave is what your are looking for.
See ?ave. 

mahmood arai 

http://www.ne.su.se/~ma



From jhowison at syr.edu  Tue May  6 16:59:38 2003
From: jhowison at syr.edu (James Howison)
Date: Tue, 6 May 2003 10:59:38 -0400
Subject: [R] R vs SPSS output for princomp
In-Reply-To: <Pine.LNX.4.44.0305060751350.3194-100000@gannet.stats>
Message-ID: <5C0D050B-7FD3-11D7-90EC-00306579408C@syr.edu>

On Tuesday, May 6, 2003, at 03:00  AM, Prof Brian Ripley wrote:

> On Mon, 5 May 2003, James Howison wrote:
>
>> I am using R to do a principal components analysis for a class
>> which is generally using SPSS - so some of my question relates to
>> SPSS output (and this might not be the right place).  I have
>> scoured the mailing list and the web but can't get a feel for this.
>> It is annoying because they will be marking to the SPSS output.
>>
>> Basically I'm getting different values for the component loadings
>> in SPSS and in R - I suspect that there is some normalization or
>> scaling going on that I don't understand (and there is plenty I
>> don't understand).  The scree-plots (and thus eigen values for each
>> component) and Proportion of Variance figures are identical - but
>> the factor loadings are an order of magnitude different.  Basically
>> the SPSS loadings are much higher than those shown by R.
>>
>> Should the loadings returned by the R princomp function and the
>> SPSS "Component Matrix" be the same?
>
> Only if they are defined the same.  The length of a PCA loading is
> arbitrary.  R's are of length (sum of squares of coefficients) one:
> how are SPSS's defined?

I believe that, based on the "Factor Score Coefficients" section of the 
SPSS algorithm document (am I right in thinking that R's "loadings" are 
also "Factor Score coefficients") this is the calculations that SPSS is 
using?

http://www.spss.com/tech/stat/Algorithms/11.5/factor.pdf

To quote (in psuedo latex):

The matrix of factor ladings based on factor m is:

\lambda_m = \omega_m {\gamma_m}^{\frac{1}{2}}

where

\omega_m = (w_1,w_2,...,w_m)
\gamma_m = diag(abs{y_1},abs{y_2},....,abs{y_m})

For a correlation matrix

y_1 >= y_2 >= y_2 >= ... >= y_m are the eigenvalues and w_i are the 
corresponding eigenvectors of R, where R is the correlation matrix.

(skipping down to the bottom of the document)

the coefficients (loadings) are based on (PC without rotation (my 
example))

W = \lambda_m {\gamma_m}^-1

where
S_m = factor structure matrix and
\lambda_m = S_m for orthogonal rotations

I'm afraid that my mathematical skills are not up to comparing these 
algorithm explained in the SPSS document with the R source code :(  
Hopefully the difference is obvious to somebody here.

>> And subsidiary question would be:  How does one approximate the
>> "Kaiser's little jiffy" test for extracting the components (SPSS
>> by default eliminates those components with eigen values below 1)?
>> I've been doing this by loadings(DV.prcomped)[,1:x] after inspecting
>> the scree plot (to set x) - but is there another way?
>
> eigen values of what exactly?  The component sdev is the aquare roots 
> of
> the eigenvalues of the (possibly scaled) covariance matrix: maybe you
> intend this only for a correlation matrix?

Yes I do - I'm using only the correlation matrix.  I understood that it 
was common (following Kaiser's suggestion) to extract only components 
which have eigenvalues above 1 (i.e. explain as much variance as at 
least one of the input variables).  I understand that is considered 
statistically crude but is still common.

I guess I'm expecting an interface for PCA not too dissimilar to that 
of factanal (as it is in other statistical packages).  Perhaps there 
are sounds statisical reasons for not wanting to hide this step from 
the user but perhaps it is interesting to you to know people's 
expectations when using the princomp function.

> In R you have the source code, so if you know what you want you can 
> find
> the pieces.

Apologies that this is a bit beyond me right at the moment.  I do, 
however appreciate your comments and the fact that the source is 
available.

James
Doctoral Student
School of Information Studies
Syracuse University

> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From vito.muggeo at giustizia.it  Tue May  6 17:02:10 2003
From: vito.muggeo at giustizia.it (vito muggeo)
Date: Tue, 6 May 2003 17:02:10 +0200
Subject: [R] Sum by categorical variable
References: <6C9A2D9477234140A56E9D1B073B28E901DB5C@gitmanex01.git.generali.ch>
Message-ID: <006101c313e0$7b47a200$5c13070a@it.giustizia.it>

If I understand correctly what you are looking for, see ?tapply.
Below there is a toy example

> NumVar<-runif(100) #continuous variable
> CategVar<-rbinom(100,1,.7) #unbalanced categorical variable
> table(CategVar)
CategVar
 0  1
33 67
> tapply(NumVar,CategVar,sum)
       0        1
15.17833 32.11759

sum can be replaced by any function including mean, median, and
user-defined.
best,
vito


----- Original Message -----
From: "De Amicis Fabrizio (G.I.T.)" <Fabrizio.DeAmicis at git.generali.ch>
To: "'r-help at lists.R-project.org'" <r-help at stat.math.ethz.ch>
Sent: Tuesday, May 06, 2003 4:08 PM
Subject: [R] Sum by categorical variable


> Dear R-list,
> I have two variables (numerical and categorical) and  would like to have
the
> sum (and maybe some other statistics) of the numerical variable by the
> categorical one.
> Can you help me,
> Thank you,
> Fabrizio
>
>
> ---------------------------------------------------------------
> Fabrizio De Amicis
>
> IT Department
> Generali Information Technologies - (GIT)
>
> Centro Galleria 2,
> Via Cantonale
> CH - 6928 Manno - Switzerland
> Tel  +41 91 806 6220
> Fax +41 91 806 6298
> E-mail: fabrizio.deamicis at git.generali.ch
>
>
>
>
> ************************************************************************
> The information in this email is confidential and may be legally...
{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From murdoch at stats.uwo.ca  Tue May  6 17:17:10 2003
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 06 May 2003 11:17:10 -0400
Subject: [R] how to read a web page and extract an html table?
In-Reply-To: <20030506143129.33487.qmail@web12105.mail.yahoo.com>
References: <20030506143129.33487.qmail@web12105.mail.yahoo.com>
Message-ID: <vckfbv4fgkl299c7ovqv267s3tc00q6prg@4ax.com>

On Tue, 6 May 2003 07:31:29 -0700 (PDT), you wrote in message
<20030506143129.33487.qmail at web12105.mail.yahoo.com>:

>I want to extract the table from the html file. 
>Is there a function html2R, the opposite of R2html? 
>How should I do this? 

I don't think there is anything that does that, but the XML package
(from CRAN) contains a function called htmlTreeParse should get you
partway there.

Duncan Murdoch



From v_bill_pikounis at merck.com  Tue May  6 17:24:48 2003
From: v_bill_pikounis at merck.com (Pikounis, Bill)
Date: Tue, 06 May 2003 11:24:48 -0400
Subject: [R] how to read a web page and extract an html table?
Message-ID: <CFBD404F5E0C9547B4E10B7BDC3DFA2F662263@usrymx18.merck.com>

Adrian,

> I want to extract the table from the html file. 
> Is there a function html2R, the opposite of R2html? 
> How should I do this? 

Parsing arbitrary HTML is generally a nontrivial task.  I would recommend
using something like Perl to convert the HTML to delimited ASCII, and then
use read.table() for example. There are specific modules in Perl (for
example) that can help with the "HTML-2-ASCII" step, if not do it entirely.
I have never used one myself, but I am sure CPAN can be searched for one.

Hope that helps,
Bill


----------------------------------------
Bill Pikounis, Ph.D.
Biometrics Research Department
Merck Research Laboratories
PO Box 2000, MailDrop RY84-16  
126 E. Lincoln Avenue
Rahway, New Jersey 07065-0900
USA

v_bill_pikounis at merck.com

Phone: 732 594 3913
Fax: 732 594 1565


> -----Original Message-----
> From: Adi Humbert [mailto:adrian_humbert at yahoo.com]
> Sent: Tuesday, May 06, 2003 10:31 AM
> To: r-help at stat.math.ethz.ch
> Cc: adrian_humbert at yahoo.com
> Subject: [R] how to read a web page and extract an html table?
> 
> 
> Hello all, 
> 
> I want to read a table from a given web page. 
> 
> If I do something like
> > str="http://www...."      # this is the web address
> > aux1 <- url(str,open="rt")# open connection 
> > aux2 <- readLines(aux1)   # read web page 
> aux2 contains the html file. 
> 
> I want to extract the table from the html file. 
> Is there a function html2R, the opposite of R2html? 
> How should I do this? 
> 
> Thanks, 
> Adrian
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From spencer.graves at pdf.com  Tue May  6 17:25:45 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 06 May 2003 08:25:45 -0700
Subject: [R] searching for an analytical function
References: <Pine.LNX.4.44.0305061127180.6038-100000@nereida.deioc.ull.es>
Message-ID: <3EB7D3F9.7070107@pdf.com>

Have you considered stepwise regression, e.g., stepAIC from the MASS 
library or stepAIC.c dowloadable from "www.prodsyse.com"?  The latter is 
not solidly debugged but has worked with several examples with "lm".  If 
you have the time, you can dig through the code and modify the hierarchy 
rules to suit your needs.

hope this helps.  spencer graves

Casiano Rodriguez Leon wrote:
> Hello all,
> 
> This is the problem I am dealing with:
> 
> I have an R data frame with the sample of observations of the control
> variables "x1", "x2" , ... and the response variable "y".
> I also have a set of "base" functions = "x1, "x2", ..., "log(x1)",
> "log(x2)", ...
> 
> What I need is to have the ANALYTICAL function, i.e. a polynom of the
> given base functions, (s.t like x1^3*log(x2) ) that represents my data,
> i.e. that minimizes the average errors of the predictions.
> 
> I guess that using non-parametric regression I can obtain a non analytical
> answer. Do you know of any solutions for that problem or similars?  If so,
> where can I find them?
> 
> Many, many thanks,
> 
> Casiano
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Tue May  6 17:31:48 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 6 May 2003 16:31:48 +0100 (BST)
Subject: [R] R vs SPSS output for princomp
In-Reply-To: <5C0D050B-7FD3-11D7-90EC-00306579408C@syr.edu>
Message-ID: <Pine.LNX.4.44.0305061617110.20359-100000@gannet.stats>

On Tue, 6 May 2003, James Howison wrote:

> I guess I'm expecting an interface for PCA not too dissimilar to that 
> of factanal (as it is in other statistical packages).  Perhaps there 
> are sounds statisical reasons for not wanting to hide this step from 
> the user but perhaps it is interesting to you to know people's 
> expectations when using the princomp function.

Well, many other packages confuse (hopelessly) PCA and factor analysis,
including SPSS.  They are separate statistical methods with very different
purposes, that for factanal being quite rarely appropriate.  R is not
written to reproduce the mistakes of other packages, but to implement
sound statistical practice.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From spencer.graves at pdf.com  Tue May  6 17:40:54 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 06 May 2003 08:40:54 -0700
Subject: [R] "Dumb" plots?
References: <9516.030506@eimb.ru> <3EB7B40B.2030904@sentoo.sn>
	<Pine.GSO.4.53.0305061544150.13332@delta5.sm.luth.se>
Message-ID: <3EB7D786.2080709@pdf.com>

How about:

Dat <- array(1:10, dim=c(10,2))
dimnames(Dat) <- list(NULL, c("x", "y"))
Crt <- array(" ", dim=c(10,10))
Crt[Dat] <- "*"
for(i in 1:10)
	cat(Crt[,11-i], "\n")

This worked in both R 1.6.2 and S-Plus 6.1 under Windows 2000.
hth.  spencer graves

Robert Lundqvist wrote:
> Is there any neat way of producing character-based "dumb" plots in R
> rather than the ordinary very good-looking graphics? It would at times be
> both easy and sufficient to include such crude graphs in HTML pages rather
> or similar.
> 
> --robert
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From bates at stat.wisc.edu  Tue May  6 17:54:20 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 06 May 2003 15:54:20 -0000
Subject: [R] Workshop on multilevel modeling in R
Message-ID: <6r7k94t6oa.fsf@bates4.stat.wisc.edu>

We will present a workshop on "Multilevel Modeling in R" June 18-19,
2003 in Madison, WI, USA.  Details are available at
         http://www.stat.wisc.edu/shortcourse/Rworkshop.html



From deepayan at stat.wisc.edu  Tue May  6 17:55:54 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 6 May 2003 10:55:54 -0500
Subject: [R] "help.start() and kde konqueror"
In-Reply-To: <200305061539.56926.fredrik.lundgren@norrkoping.mail.telia.com>
References: <200305061539.56926.fredrik.lundgren@norrkoping.mail.telia.com>
Message-ID: <200305061055.54615.deepayan@stat.wisc.edu>

On Tuesday 06 May 2003 08:46 am, Fredrik Lundgren wrote:
> Hello,
>
> When I attempt to use KDE 3.03 "konqueror" for help.start() I can't get the
> search engine to work but otherwise help.start() is OK. How should
> "konqueror" be setup for this?

Do you have java enabled on Konqueror ? The search engine is java based, and 
konqueror (AFAIR) needs a little tweaking to have java usable.

Deepayan



From elvis at xlsolutions-corp.com  Tue May  6 18:01:44 2003
From: elvis at xlsolutions-corp.com (elvis@xlsolutions-corp.com)
Date: Tue, 6 May 2003 09:01:44 -0700
Subject: [R] Course***R/Splus Fundamentals and Programming Techniques,
	May-June 2003 @ 5 locations near you! (Raleigh, San Francisco, etc)
Message-ID: <APEHLKCMHHAKBGLAPKPCMELDCDAA.elvis@xlsolutions-corp.com>

XLSolutions Corporation (www.xlsolutions-corp.com) is proud
to announce May-June 2-day "R/S-plus Fundamentals and Programming
Techniques".

****Houston, Tx-----------------> May 22-23
****San Diego, CA --------------> May 29-30
****Raleigh, NC ----------------> June 5-6
****Boston, MA -----------------> June 12-13
****San Francisco -------------->  TBD

Reserve your seat now at the early bird rates! Payment due AFTER the class.
Interested in R/Splus Advanced course? email us.


Course Description:

This two-day R/S-plus course focuses on a broad spectrum of topics,
from reading raw data to a comparison of R and S. We will learn
the essentials of data manipulation, graphical visualization
and R/S-plus programming. We will explore statistical data analysis tools,
including graphics with data sets. How to enhance your plots.
We will perform basic statistics and fit linear regression models.
Participants are encouraged to bring data for interactive sessions


With the following outline:

- An Overview of R: Installation and Demonstration
- Data Manipulation and Graphics
- Using Lattice Graphics
- A Comparison of R and S-Plus
- How can R Complement SAS?
- Writing Functions
- Avoiding Loops
- Vectorization
- Statistical Modeling
- Project Management
- Techniques for Effective use of R and S
- Enhancing Plots
- Using High-level Plotting Functions
- Building and Distributing Packages (libraries)


Early Bird Research: $995 (Includes course materials, 90 days Technical
Support for R,
snacks and continental breakfast!); Email us for group discounts.

Email Sue Turner: sue at xlsolutions-corp.com
Phone: 206-686-1578 x221
Visit us: www.xlsolutions-corp.com/training.htm

Please let us know if you and your colleagues are interested in this class
to take advantage of group discount. Register now to secure your seat!

Interested in R/Splus Advanced course? email us.


Cheers,

Elvis Miller, PhD
Manager Training.
XLSolutions Corporation
206 686 1578
www.xlsolutions-corp.com
elvis at xlsolutions-corp.com
****************Need help? contact our consulting team!**********

--------------------------------------------------------------------
This message was distributed by s-news at lists.biostat.wustl.edu.  To
...(s-news.. clipped)...



From jhowison at syr.edu  Tue May  6 18:01:42 2003
From: jhowison at syr.edu (James Howison)
Date: Tue, 6 May 2003 12:01:42 -0400
Subject: [R] how to read a web page and extract an html table?
In-Reply-To: <vckfbv4fgkl299c7ovqv267s3tc00q6prg@4ax.com>
Message-ID: <07AC3439-7FDC-11D7-90EC-00306579408C@syr.edu>

> On Tue, 6 May 2003 07:31:29 -0700 (PDT), you wrote in message
> <20030506143129.33487.qmail at web12105.mail.yahoo.com>:
>
>> I want to extract the table from the html file.
>> Is there a function html2R, the opposite of R2html?
>> How should I do this?
>
> I don't think there is anything that does that, but the XML package
> (from CRAN) contains a function called htmlTreeParse should get you
> partway there.
>
> Duncan Murdoch

Or if you know (or can learn) perl here is a script that will do it 
(and output it as a csv).  You need to edit $url and @tableheaders and 
to install WWW::Mechanize and HTML::TableExtract from cpan.  
http://cpan.org

#!/usr/bin/perl

use HTML::TableExtract;
use WWW::Mechanize;

my $url = "http://shangorilla.syr.edu/testR.html";
my @tableheaders = qw (Firstcol Secondcol Thirdcol);

my $agent = WWW::Mechanize->new();
$agent->get($url);

# Output headers
print join(',', at tableheaders), "\n";

# Find table in html page
$te = new HTML::TableExtract( headers => \@tableheaders );
$te->parse( $agent->content() ); #parse contents

# Examine all matching tables (there is only be one?)
foreach $ts ($te->table_states) {
     foreach $row ($ts->rows) {
         print join(',', @$row), "\n";
             }
}

(copy into editor and save as testRtable.pl then chmod u+x 
testRtable.pl)
run as ./testRtable.pl to check content
then
./testRtable.pl > csvforReadingIntoR.txt

Then in R

 > data <- read.csv("csvforReadingIntoR.txt")

I think that should work for you. (or just send me the url and I'll run 
it and mail you back the csv - if this is a one off.)

Speaking of perl - Does anyone know if there is a standard way to use 
perl scripts from within R - I guess one can call them as one does from 
the commandline.  Is it possible to program R modules in perl (or would 
the cpan dependancies kill us?)

If this is a one off (ie not for scripting) then I think you can 
directly select a table in IE and paste it into Excel - then save as 
csv to read into R.

Cheers
James

On Tuesday, May 6, 2003, at 11:17  AM, Duncan Murdoch wrote:

> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From fredrik.lundgren at norrkoping.mail.telia.com  Tue May  6 17:59:40 2003
From: fredrik.lundgren at norrkoping.mail.telia.com (Fredrik Lundgren)
Date: Tue, 6 May 2003 17:59:40 +0200
Subject: [R] "help.start() and kde konqueror"
References: <200305061539.56926.fredrik.lundgren@norrkoping.mail.telia.com>
	<20030506150408.GB3020@localhost>
Message-ID: <001401c313e8$8156ddc0$2d0ffea9@oemcomputer>

Thanks,
but unfortunately this doesn't help
se output below

>help.start(browser = 'kfmclient')
Changing the default browser (as specified by the `browser' option) to
    the given browser so that it gets used for all future help
    requests.
Making links in per-session dir ...
If kfmclient is already running, it is *not* restarted, and you must
    switch to its window.
Otherwise, be patient ...
> Mutex destroy failure: Enhet eller resurs upptagen

helpstart works as before but unfortunately not the search engine

Fredrik

----- Original Message ----- 
From: "Guido Sohne" <guido at sohne.net>
To: "Fredrik Lundgren" <fredrik.lundgren at norrkoping.mail.telia.com>
Cc: <R-help at stat.math.ethz.ch>
Sent: Tuesday, May 06, 2003 5:04 PM
Subject: Re: [R] "help.start() and kde konqueror"


> help.start(browser='kfmclient')
> 
> On Tue, May 06, 2003 at 03:46:26PM +0200, Fredrik Lundgren wrote:
> > Hello,
> > 
> > When I attempt to use KDE 3.03 "konqueror" for help.start() I can't get the 
> > search engine to work but otherwise help.start() is OK. How should 
> > "konqueror" be setup for this?
> > 
> > The response to the command is below:
> > > help.start(browser= 'konqueror')
> > Making links in per-session dir ...
> > If konqueror is already running, it is *not* restarted, and you must
> >     switch to its window.
> > Otherwise, be patient ...
>  
> ----------------------------------------------------------
> Guido Sohne    guido at sohne.net
> At Large   http://sohne.net
> ----------------------------------------------------------
> He that composes himself is wiser than he that composes
> a book.
> -- B. Franklin
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From deepayan at stat.wisc.edu  Tue May  6 18:04:00 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 6 May 2003 11:04:00 -0500
Subject: [R] xyplot (lattice), strip.default
In-Reply-To: <9516.030506@eimb.ru>
References: <9516.030506@eimb.ru>
Message-ID: <200305061104.00589.deepayan@stat.wisc.edu>

On Tuesday 06 May 2003 03:23 am, Wladimir Eremeev wrote:
> Dear r-help,
>
>   I've got data of the following structure
> 1979  93.428747  0
> 1979  87.298608  20
> 1979  78.506340  40
> ...
> 1979  45.567890  340
> 1980  60.815289  0
> 1980  49.630904  20
> 1980  24.981362  40
> ...
>
> The first column is year and the last one is the longitude.
> I need a set of graphs showing the dependence of the middle value on
> the longitude, for each year, situated one blow the other.
> I.e.
> 1979: --...---```--``--..
> 1980: ...--``../``\...---
> ...
> etc.
>
> Here characters ---...---``` denote the curve.
> The middle value is on the vertical axis
> and the latitude is on the horizontal axis of each graph.
>
> To do this I use xyplot function from the Lattice package:
>
> xyplot(ac15$"value"~ac15$lon|year,data=ac15,
>        type="l",
>        layout=c(1,24),
>        xlab="Longitude",
>        as.table=TRUE,
>        bg="white"
>       );
>
> But I have some problems using it.
>
> Questions:
>
> 1. How to make xyplot to draw the year value in the strip above each
> graph instead of writing the word 'year'?

The simplest way would be to supply year as a factor, I think.

xyplot(value ~ lon | factor(year), data=ac15,
       type="l",
       layout=c(1,24),
       xlab="Longitude",
       as.table=TRUE)

The bg = "white" would have no effect here, as others have already pointed 
out.

Deepayan



From bates at stat.wisc.edu  Tue May  6 18:11:36 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 06 May 2003 16:11:36 -0000
Subject: [R] Re: [Socsci-stat] Workshop on multilevel modeling in R
In-Reply-To: <6r7k94t6oa.fsf@bates4.stat.wisc.edu>
References: <6r7k94t6oa.fsf@bates4.stat.wisc.edu>
Message-ID: <6rfznsrr6h.fsf@bates4.stat.wisc.edu>

Douglas Bates <bates at stat.wisc.edu> writes:

> We will present a workshop on "Multilevel Modeling in R" June 18-19,
> 2003 in Madison, WI, USA.  Details are available at
>          http://www.stat.wisc.edu/shortcourse/Rworkshop.html

Correction: the dates are June 19-20, 2003.  Registration is available
on the evening of June 18.  The web page has the correct information.



From arrayprofile at yahoo.com  Tue May  6 18:27:57 2003
From: arrayprofile at yahoo.com (array chip)
Date: Tue, 6 May 2003 09:27:57 -0700 (PDT)
Subject: [R] polr in MASS
Message-ID: <20030506162757.72730.qmail@web41210.mail.yahoo.com>

Hi,

It seems my last post had formatting problem, so
hopefully this time it works:

I am trying to use the proportional-odds model
(cumulative logistic regression) using the "polr"
function in the MASS library of R. 

I tried with the dataset of "housing" contained in the
MASS book where "Sat" (3 levels: low, medium, high) is
the dependent variable, "Infl" (low, medium, high),
"Type" (tower, apartment, atrium, terrace) and "Cont"
(low, high) are the predictor variables. And I have
some questions; hope someone could help me out. The
following commands are taken from the MASS book as
well. If you know R, it might be better to understand
my problem, if not, I hope it's still ok - my problem
is actually a statistically problem, not a programming
problem, ignore the codes, but just look at the
output.

For the dataset, the proportional odds model tried to
run cumulative logistic regression of the dependent
variable "Sat" on the 3 predictor variables "Infl",
"Type", and "Cont" without interactions. In R, the
lowest level of each variable is treated as the
reference level. 

> house.plr<-polr(Sat~Infl+Type+Cont,data=housing,
weights=Freq)
> summary(house.plr)

Call: polr(formula = Sat ~ Infl + Type + Cont, data =
housing, weights = Freq)

Coefficients:
                   Value Std. Error   t value
InflMedium     0.5663922 0.10465276  5.412109
InflHigh       1.2888137 0.12715609 10.135682
TypeApartment -0.5723552 0.11923800 -4.800107
TypeAtrium    -0.3661907 0.15517331 -2.359882
TypeTerrace   -1.0910073 0.15148595 -7.202036
ContHigh       0.3602803 0.09553577  3.771156 

Intercepts:
            Value   Std. Error t value
Low|Medium  -0.4961  0.1248    -3.9740
Medium|High  0.6907  0.1255     5.5049 

Residual Deviance: 3479.149 
AIC: 3495.149 

I also tried to predict the probabilities of the 3
categories of the dependent variable "Sat" for every
combination of the 3 predictor variables using the
predict function in R: 

> hnames<-lapply(housing[,-5],levels)
>
house.pr1<-predict(house.plr,expand.grid(hnames[-1]),type="probs")
> cbind(expand.grid(hnames[-1]),round(house.pr1,2))

     Infl      Type Cont  Low Medium High
1     Low     Tower  Low 0.38   0.29 0.33
2  Medium     Tower  Low 0.26   0.27 0.47
3    High     Tower  Low 0.14   0.21 0.65
4     Low Apartment  Low 0.52   0.26 0.22
5  Medium Apartment  Low 0.38   0.29 0.33
6    High Apartment  Low 0.23   0.26 0.51
7     Low    Atrium  Low 0.47   0.27 0.26
8  Medium    Atrium  Low 0.33   0.29 0.38
9    High    Atrium  Low 0.19   0.25 0.56
10    Low   Terrace  Low 0.64   0.21 0.14
11 Medium   Terrace  Low 0.51   0.26 0.23
12   High   Terrace  Low 0.33   0.29 0.38
13    Low     Tower High 0.30   0.28 0.42
14 Medium     Tower High 0.19   0.25 0.56
15   High     Tower High 0.10   0.17 0.72
16    Low Apartment High 0.43   0.28 0.29
17 Medium Apartment High 0.30   0.28 0.42
18   High Apartment High 0.17   0.23 0.60
19    Low    Atrium High 0.38   0.29 0.33
20 Medium    Atrium High 0.26   0.27 0.47
21   High    Atrium High 0.14   0.21 0.64
22    Low   Terrace High 0.56   0.25 0.19
23 Medium   Terrace High 0.42   0.28 0.30
24   High   Terrace High 0.26   0.27 0.47

What I am confused is that when I tried to reproduce
these predicted probabilities manually using the model
coefficients, I can sometimes get different results: 

According to cumulative logistic regression, the model
is:

  logit(P(Y<=k | x1,x2,x3) = a + b1*x1 + b2*x2 + b3*x3
for k=1,2,3

For example, for low Infl, Type tower, Cont low (all
on reference level),  

logit(P(Sat=low))=P(Sat=low)/(1-P(Sat=low))=-0.4961,
solve for
P(Sat=low)=exp(-0.4961)/(1+exp(-0.4961))=0.38;

and

logit(P(Sat=low, medium)) =
P(Sat=low,medium)/(1-P(Sat=low,medium)) = 0.6907,
solve for P(Sat=low,medium) =
exp(0.6907)/(1+exp(0.6907))=0.67, which is the sum of
0.38 plus 0.29.

The above 2 examples showed that I can reproduce the
predicted probabilities when using the intercept
alone. However, for other combinations of the
predictor variables, I can NOT reproduce the results. 

For example, for medium Infl, Type tower, cont low,  

logit(P(Sat=low))=P(Sat=low)/(1-P(Sat=low))=-0.4961+0.56639=0.07029,
solve for
P(Sat=low)=exp(0.07029)/(1+exp(0.07029))=0.52; but the
probability using "predict" function is 0.26.

and

logit(P(Sat=low, medium)) =
P(Sat=low,medium)/(1-P(Sat=low,medium)) =
0.6907+0.56639=1.25709, solve for P(Sat=low,medium) =
exp(1.25709)/(1+exp(1.25709))=0.78, which certainly is
NOT the sum of 0.26 plus 0.27, and is not the sum of
0.52 and 0.27. 

Did I misunderstand something here? Or the way I used
to reproduce the predicted probabilities is not
correct? 

Thanks very much!



From mschwartz at medanalytics.com  Tue May  6 18:41:09 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 6 May 2003 11:41:09 -0500
Subject: [R] "help.start() and kde konqueror"
In-Reply-To: <001401c313e8$8156ddc0$2d0ffea9@oemcomputer>
Message-ID: <002901c313ee$4d279610$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Fredrik
Lundgren
>Sent: Tuesday, May 06, 2003 11:00 AM
>To: Guido Sohne
>Cc: R-help at stat.math.ethz.ch
>Subject: Re: [R] "help.start() and kde konqueror"
>
>
>Thanks,
>but unfortunately this doesn't help
>se output below
>
>>help.start(browser = 'kfmclient')
>Changing the default browser (as specified by the `browser' option)
to
>    the given browser so that it gets used for all future help
>    requests.
>Making links in per-session dir ...
>If kfmclient is already running, it is *not* restarted, and you must
>    switch to its window.
>Otherwise, be patient ...
>> Mutex destroy failure: Enhet eller resurs upptagen
>
>helpstart works as before but unfortunately not the search engine
>
>Fredrik


I don't use Konqueror but I noted from the web site that there are
some Java related issues with it somewhat similar to those facing
Mozilla, which I do use under both WinXP and RH Linux running Gnome.

You might want to review the follow URL's to ensure that your Java
configuration is set up correctly. As was pointed out, the search
engine requires both JavaScript and Java being enabled and Java being
properly installed on your system.

http://konqueror.org/faq/#JavaAppletsonlyshowupasgreyrectangleswhatswr
ong
(Last question at the bottom of the page)

and

http://konqueror.org/javahowto/


Hope that helps,

Marc Schwartz



From murdoch at stats.uwo.ca  Tue May  6 19:04:24 2003
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 06 May 2003 13:04:24 -0400
Subject: [R] how to read a web page and extract an html table?
In-Reply-To: <07AC3439-7FDC-11D7-90EC-00306579408C@syr.edu>
References: <vckfbv4fgkl299c7ovqv267s3tc00q6prg@4ax.com>
	<07AC3439-7FDC-11D7-90EC-00306579408C@syr.edu>
Message-ID: <5fqfbvok6a73fe8v3r41nmtoea9odkmbol@4ax.com>

On Tue, 6 May 2003 12:01:42 -0400, you wrote in message
<07AC3439-7FDC-11D7-90EC-00306579408C at syr.edu>:


>Speaking of perl - Does anyone know if there is a standard way to use 
>perl scripts from within R - I guess one can call them as one does from 
>the commandline.  Is it possible to program R modules in perl (or would 
>the cpan dependancies kill us?)

I don't know the answers to those questions, but wanted to point out
that most users of R on Windows won't have Perl installed, so if you
do this, you should at least give them instructions on where to find
it (like those in the readme.packages, "available via
http://www.activestate.com/Products/ActivePerl/.").

Duncan Murdoch



From Kosenkov.Kirill at nac.spb.ru  Tue May  6 19:21:16 2003
From: Kosenkov.Kirill at nac.spb.ru (Kosenkov Kirill Nikolaevich)
Date: Tue, 06 May 2003 21:21:16 +0400
Subject: [R] pointsize - what is wrong?
Message-ID: <3EB7EF0C.6090809@nac.spb.ru>

Hello!
When I am trying to produce plot with text with pointsize 30 or
greater R sets up a default pointsize of 12 on plot.
I need to set up a large pointsize to make large jpeg or
png files (with good resolution).
I can write text on plot with pointsizes 18,20,22, but i cant
write text with pointsizes 25,26 and greater and i can not
understand - why? Is there are any restrictions in R? Or what?

I am using R 1.7.0 on Win2k

Thanx.



From ripley at stats.ox.ac.uk  Tue May  6 20:15:55 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 6 May 2003 19:15:55 +0100 (BST)
Subject: [R] pointsize - what is wrong?
In-Reply-To: <3EB7EF0C.6090809@nac.spb.ru>
Message-ID: <Pine.LNX.4.44.0305061902310.998-100000@gannet.stats>

You have the sources: look at src/gnuwin32/devga.c, line 2217.
You can change that as you please and recompile R.

*However* that is the base font size, and R uses graphics parameter cex to
scale the text thereafter.  There are limits of [2, 100] points for the
scaled font size.

The default is 12 point, on a 7" square window.  24 point might be
appropriate to a 14" or 1000 pixel png/jpeg.  That's pretty high
resolution, and if that is not enough, I would question why you are using
a bitmap format anyway, and if you absolutely needed to I would suggest
you used some other tools to rasterize (as R's bitmap() function does).

On Tue, 6 May 2003, Kosenkov Kirill Nikolaevich wrote:

> When I am trying to produce plot with text with pointsize 30 or
> greater R sets up a default pointsize of 12 on plot.
> I need to set up a large pointsize to make large jpeg or
> png files (with good resolution).
> I can write text on plot with pointsizes 18,20,22, but i cant
> write text with pointsizes 25,26 and greater and i can not
> understand - why? Is there are any restrictions in R? Or what?

> I am using R 1.7.0 on Win2k

Perhaps you should say that first, *and* that you are using a png() device 
(if you are).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jfox at mcmaster.ca  Tue May  6 20:24:10 2003
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 06 May 2003 14:24:10 -0400
Subject: [R] bitmap images in tcltk
Message-ID: <5.1.0.14.2.20030506141715.01e38068@mcmail.cis.mcmaster.ca>

Dear R-help list members,

I'm writing a package using tcltk. Thanks to Peter Dalgaard's excellent 
work on the tcltk package, almost everything has gone very smoothly. I'm 
stymied, however, by the following problem:

I want to incorporate a bitmap image, stored as an xbm file, in a widget. 
To take a simple example,

     top <- tktoplevel()
     tkgrid(tklabel(top, bitmap="@file.xbm", fg="red"))

will work as long as file.xbm is in the current directory; alternatively, I 
could specify the path to this file. The problem is that I can't figure out 
a reliable way of predicting (or discovering) where the bitmap file will 
reside when my package is installed.

Any suggestions would be appreciated.

Thanks,
  John
-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From Roger.Bivand at nhh.no  Tue May  6 20:44:56 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 6 May 2003 20:44:56 +0200 (CEST)
Subject: [R] bitmap images in tcltk
In-Reply-To: <5.1.0.14.2.20030506141715.01e38068@mcmail.cis.mcmaster.ca>
Message-ID: <Pine.LNX.4.44.0305062042250.10023-100000@reclus.nhh.no>

On Tue, 6 May 2003, John Fox wrote:

> Dear R-help list members,
> 
> I'm writing a package using tcltk. Thanks to Peter Dalgaard's excellent 
> work on the tcltk package, almost everything has gone very smoothly. I'm 
> stymied, however, by the following problem:
> 
> I want to incorporate a bitmap image, stored as an xbm file, in a widget. 
> To take a simple example,
> 
>      top <- tktoplevel()
>      tkgrid(tklabel(top, bitmap="@file.xbm", fg="red"))
> 
> will work as long as file.xbm is in the current directory; alternatively, I 
> could specify the path to this file. The problem is that I can't figure out 
> a reliable way of predicting (or discovering) where the bitmap file will 
> reside when my package is installed.
> 
> Any suggestions would be appreciated.

system.file(<file path relative to package root>, package="package")[1]

should do it.

> 
> Thanks,
>   John
> -----------------------------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario, Canada L8S 4M4
> email: jfox at mcmaster.ca
> phone: 905-525-9140x23604
> web: www.socsci.mcmaster.ca/jfox
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From raf1729 at hotmail.com  Tue May  6 20:53:49 2003
From: raf1729 at hotmail.com (R A F)
Date: Tue, 06 May 2003 18:53:49 +0000
Subject: [R] Loops and memory
Message-ID: <Law11-F29eLTJprKhfI0002ef5f@hotmail.com>

Hi, this question is meant to be a bit vague, since I'm really not
familiar with all the issues involved.  It's also a problem that I
think many would have encountered and would have useful suggestions.

According to MASS, 2nd ed., p. 158, "A major issue is that S is
designed to be able to back out from uncompleted calculations, so
that memory used in intermediate calculations is retained until
they are committed."  The end of the paragraph says that recent
versions of S are better.  And I seem to remember that R is also
better with memory management.

My question I guess is how bad loops are in R and what the best
way is to deal with memory if I want to use loops.  Are there flags
I can turn on or off if I don't care about uncompleted calculations
to make memory management more efficient, etc.?  I've already thought
about pushing looping into shell scripts and hope that this will
help somewhat.

The issue I'm facing is that it'd be easier for me to write a program
using a loop, but the loop itself would be a large one (looping over
potentially millions of entries say, with fairly nontrivial
calculations per loop).  Right now I've tried to avoid this through
some pre-processing followed by a more complex set of calculations
than I would have needed to do had I used a loop.  Of course it's
hard to know which method is better without actually trying both,
but I would like to hear your comments on loops in R before deciding
whether I should give the loop approach a try.

Thanks.



From edd at debian.org  Tue May  6 20:53:59 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 6 May 2003 13:53:59 -0500
Subject: [R] bitmap images in tcltk
In-Reply-To: <5.1.0.14.2.20030506141715.01e38068@mcmail.cis.mcmaster.ca>
References: <5.1.0.14.2.20030506141715.01e38068@mcmail.cis.mcmaster.ca>
Message-ID: <20030506185359.GA8156@sonny.eddelbuettel.com>

On Tue, May 06, 2003 at 02:24:10PM -0400, John Fox wrote:
> I'm writing a package using tcltk. Thanks to Peter Dalgaard's excellent 
> work on the tcltk package, almost everything has gone very smoothly. I'm 

Seconded. It is truly excellent, and cross-platform without any heachaches.

> stymied, however, by the following problem:
> 
> I want to incorporate a bitmap image, stored as an xbm file, in a widget. 
> To take a simple example,
> 
>     top <- tktoplevel()
>     tkgrid(tklabel(top, bitmap="@file.xbm", fg="red"))
> 
> will work as long as file.xbm is in the current directory; alternatively, I 
> could specify the path to this file. The problem is that I can't figure out 
> a reliable way of predicting (or discovering) where the bitmap file will 
> reside when my package is installed.
> 
> Any suggestions would be appreciated.

There is a much easier solution thanks to Luke's tkrplot which is available
for win32 and unix on CRAN.  A simple example is

> tt <- tktoplevel()
> pl <- tkrplot(tt, function() plot(1:10, main="foo"))
> tkpack(pl)

It can do fancier stuff too by using a 'replot' feature. The example from
the help page varies a simple function by tieing a callback command and
variable from a scale to a function around tkreplot():

     tt <- tktoplevel()
     bb<-1
     img <-tkrplot(tt, function() plot(1:20,(1:20)^bb))
     f<-function(...) {
         b <- as.numeric(tclvalue("bb"))
         if (b != bb) {
             bb <<- b
             tkrreplot(img)
         }
     }
     s <- tkscale(tt, command=f, from=0.05, to=2.00, variable="bb",
                  showvalue=FALSE, resolution=0.05, orient="horiz")
     tkpack(img,s)
			   
Dirk


-- 
Don't drink and derive. Alcohol and algebra don't mix.



From ripley at stats.ox.ac.uk  Tue May  6 21:03:08 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 6 May 2003 20:03:08 +0100 (BST)
Subject: [R] Loops and memory
In-Reply-To: <Law11-F29eLTJprKhfI0002ef5f@hotmail.com>
Message-ID: <Pine.LNX.4.44.0305061959200.1117-100000@gannet.stats>

On Tue, 6 May 2003, R A F wrote:

> Hi, this question is meant to be a bit vague, since I'm really not
> familiar with all the issues involved.  It's also a problem that I
> think many would have encountered and would have useful suggestions.
> 
> According to MASS, 2nd ed., p. 158, "A major issue is that S is
> designed to be able to back out from uncompleted calculations, so
> that memory used in intermediate calculations is retained until
> they are committed."  The end of the paragraph says that recent
> versions of S are better.  And I seem to remember that R is also
> better with memory management.

That was written in 1996, when rich people had 64Mb of RAM and teaching
labs often had 4 or 8Mb (and R would not run much of the code in the book
and crashed quite often).  Take a look at `S Programming' for a less
ancient view.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From raf1729 at hotmail.com  Tue May  6 21:14:33 2003
From: raf1729 at hotmail.com (R A F)
Date: Tue, 06 May 2003 19:14:33 +0000
Subject: [R] Loops and memory
Message-ID: <Law11-F84RGkQ6mBySs00000d8f@hotmail.com>

I'm afraid that I don't have your new book with Venables handy.  So
would it be fair to assume that there's no real need to avoid loops
these days?

Thanks again.

>From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
>To: R A F <raf1729 at hotmail.com>
>CC: r-help at stat.math.ethz.ch
>Subject: Re: [R] Loops and memory
>Date: Tue, 6 May 2003 20:03:08 +0100 (BST)

>That was written in 1996, when rich people had 64Mb of RAM and teaching
>labs often had 4 or 8Mb (and R would not run much of the code in the book
>and crashed quite often).  Take a look at `S Programming' for a less
>ancient view.



From halper at health.nyc.gov  Tue May  6 21:27:20 2003
From: halper at health.nyc.gov (Howard Alper)
Date: Tue, 06 May 2003 15:27:20 -0400
Subject: [R] Questons about R capabilities
Message-ID: <seb7d46c.048@healthsmtp.nycnet>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030506/79e9b3a9/attachment.pl

From ripley at stats.ox.ac.uk  Tue May  6 21:30:22 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 6 May 2003 20:30:22 +0100 (BST)
Subject: [R] Loops and memory
In-Reply-To: <Law11-F84RGkQ6mBySs00000d8f@hotmail.com>
Message-ID: <Pine.LNX.4.44.0305062026470.1186-100000@gannet.stats>

On Tue, 6 May 2003, R A F wrote:

> I'm afraid that I don't have your new book with Venables handy.  So
> would it be fair to assume that there's no real need to avoid loops
> these days?

No, but the issues are different from those in 1996.  It is a lot less 
common to have to avoid loops, simply because memory can often be 
squandered.  But vectorizing calculations still pays off, sometimes 
handsomely: there is an example in that book of going from several hours 
to one second (and it's a real example).

> >From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
> >To: R A F <raf1729 at hotmail.com>
> >CC: r-help at stat.math.ethz.ch
> >Subject: Re: [R] Loops and memory
> >Date: Tue, 6 May 2003 20:03:08 +0100 (BST)
> 
> >That was written in 1996, when rich people had 64Mb of RAM and teaching
> >labs often had 4 or 8Mb (and R would not run much of the code in the book
> >and crashed quite often).  Take a look at `S Programming' for a less
> >ancient view.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From raf1729 at hotmail.com  Tue May  6 21:35:01 2003
From: raf1729 at hotmail.com (R A F)
Date: Tue, 06 May 2003 19:35:01 +0000
Subject: [R] Loops and memory
Message-ID: <Law11-F110twoPhPVKP0002a2b8@hotmail.com>

Interesting.

The other day I was surprised by how much longer a for loop takes to
add two vectors a and b compared to a + b.  (I think that I made a and
b have a million entries.)

I guess my problem is that I don't really what the issues are, I guess,
so it's not clear to me when and where loops should be avoided.  I
guess I should try to get a copy of this new book to find out.

Thanks again.

>From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
>To: R A F <raf1729 at hotmail.com>
>CC: r-help at stat.math.ethz.ch
>Subject: Re: [R] Loops and memory
>Date: Tue, 6 May 2003 20:30:22 +0100 (BST)
>
>On Tue, 6 May 2003, R A F wrote:
>
> > I'm afraid that I don't have your new book with Venables handy.  So
> > would it be fair to assume that there's no real need to avoid loops
> > these days?
>
>No, but the issues are different from those in 1996.  It is a lot less
>common to have to avoid loops, simply because memory can often be
>squandered.  But vectorizing calculations still pays off, sometimes
>handsomely: there is an example in that book of going from several hours
>to one second (and it's a real example).



From spencer.graves at pdf.com  Tue May  6 21:51:41 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 06 May 2003 12:51:41 -0700
Subject: [R] Questons about R capabilities
References: <seb7d46c.048@healthsmtp.nycnet>
Message-ID: <3EB8124D.3060706@pdf.com>

	  Regarding the second question, did you try "library(mass)" before 
your mvrnorm command?

	  Regarding the first question:  I'm not certain what you want.  The 
function "lm", for example, minimizes the sums of squares of deviations 
between observed and predicted.  This also maximizes the likelihood 
assuming the deviations between observed and the "true model" are 
independent normal variates with constant variance.  Can you express 
your model in terms of a probability density function for your 
observations with the model related in some way to parameters of that 
probability density?

hope this helps.  spencer graves

Howard Alper wrote:
>  
>   Hello,
>  
> 1)  I am interested in performing a limited-dependent variable linear regression.  By this I mean a classical linear regression, but for the case where the values of the dependent variable cannot vary from -infinity to +infinity, but are truncated and so are between two finite limits L1 and L2.  Does R1.7 have this capability?  If so what is (are) the relevant command(s)?
>  
> 2)  I am also interested in sampling from a multivariate normal distribution.  I see that R has a command mvrnorm, but when I try to use it, I get a message to the effect that the command is not recognized.  Is there something I must do to enable this command, or is it not available in version 1.7?
> 
>   Thanks,
>  
>   Howard
> 
> 
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From murdoch at stats.uwo.ca  Tue May  6 22:09:44 2003
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 06 May 2003 16:09:44 -0400
Subject: [R] Loops and memory
In-Reply-To: <Law11-F110twoPhPVKP0002a2b8@hotmail.com>
References: <Law11-F110twoPhPVKP0002a2b8@hotmail.com>
Message-ID: <q55gbvsbvfe1i7m9043dcdfohru9jprvqu@4ax.com>

On Tue, 06 May 2003 19:35:01 +0000, you wrote in message
<Law11-F110twoPhPVKP0002a2b8 at hotmail.com>:

>Interesting.
>
>The other day I was surprised by how much longer a for loop takes to
>add two vectors a and b compared to a + b.  (I think that I made a and
>b have a million entries.)
>
>I guess my problem is that I don't really what the issues are, I guess,
>so it's not clear to me when and where loops should be avoided.  I
>guess I should try to get a copy of this new book to find out.

I think the main issue nowadays is that your code will go much slower
if it is interpreted R code (as a for loop would be) than if it is
compiled C or Fortran code (the way "a + b" is implemented
internally).  In the old days, there was an additional penalty for
doing a loop (S tried to allocate memory each step through the loop,
but wouldn't clean up until the end), but that isn't normally a
problem in R.  

But as a general principle, I think you should always write your code
to be readable first; if it turns out to be too slow that way, then
worry about optimizing it.  As you gain experience in R you'll find
the vectorized versions of formulas more readable than the loops and
you'll need to redo things less often, but at first, loops may be the
best way to get the right answer fast.

Duncan Murdoch



From murdoch at stats.uwo.ca  Tue May  6 22:19:01 2003
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 06 May 2003 16:19:01 -0400
Subject: [R] Questons about R capabilities
In-Reply-To: <seb7d46c.048@healthsmtp.nycnet>
References: <seb7d46c.048@healthsmtp.nycnet>
Message-ID: <hm5gbvs8ttafpjjhh2kegttev2qu6q4g0i@4ax.com>

On Tue, 06 May 2003 15:27:20 -0400, you wrote in message
<seb7d46c.048 at healthsmtp.nycnet>:

> 
>  Hello,
> 
>1)  I am interested in performing a limited-dependent variable linear regression.  By this I mean a classical linear regression, but for the case where the values of the dependent variable cannot vary from -infinity to +infinity, but are truncated and so are between two finite limits L1 and L2.  Does R1.7 have this capability?  If so what is (are) the relevant command(s)?

I don't think that's built in, but it's always worth looking at the
contributed packages on cran.r-project.org just in case.  There are
general purpose likelihood maximizers (nlm, optim).
 
>2)  I am also interested in sampling from a multivariate normal distribution.  I see that R has a command mvrnorm, but when I try to use it, I get a message to the effect that the command is not recognized.  Is there something I must do to enable this command, or is it not available in version 1.7?

When the help says "mvrnorm(MASS)", that means that the function is in
the package called "MASS".  You need to execute

 library(MASS)

to get that function loaded onto the search path.  You can see which
packages are already there by executing

 search()

Duncan Murdoch



From spencer.graves at pdf.com  Tue May  6 22:44:41 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 06 May 2003 13:44:41 -0700
Subject: [R] Loops and memory
References: <Law11-F110twoPhPVKP0002a2b8@hotmail.com>
	<q55gbvsbvfe1i7m9043dcdfohru9jprvqu@4ax.com>
Message-ID: <3EB81EB9.3060703@pdf.com>

Hi, Duncan:

I agree totally with your priorities:  First get the right answer.  Then 
worry about speed if necessary.  Regarding priority number 1, I often 
program simple special cases in Excel first.  Then if I can get the same 
answer in S-Plus or R, it gives me confidence in the algorithm.

Spencer Graves

Duncan Murdoch wrote:
> On Tue, 06 May 2003 19:35:01 +0000, you wrote in message
> <Law11-F110twoPhPVKP0002a2b8 at hotmail.com>:
> 
> 
>>Interesting.
>>
>>The other day I was surprised by how much longer a for loop takes to
>>add two vectors a and b compared to a + b.  (I think that I made a and
>>b have a million entries.)
>>
>>I guess my problem is that I don't really what the issues are, I guess,
>>so it's not clear to me when and where loops should be avoided.  I
>>guess I should try to get a copy of this new book to find out.
> 
> 
> I think the main issue nowadays is that your code will go much slower
> if it is interpreted R code (as a for loop would be) than if it is
> compiled C or Fortran code (the way "a + b" is implemented
> internally).  In the old days, there was an additional penalty for
> doing a loop (S tried to allocate memory each step through the loop,
> but wouldn't clean up until the end), but that isn't normally a
> problem in R.  
> 
> But as a general principle, I think you should always write your code
> to be readable first; if it turns out to be too slow that way, then
> worry about optimizing it.  As you gain experience in R you'll find
> the vectorized versions of formulas more readable than the loops and
> you'll need to redo things less often, but at first, loops may be the
> best way to get the right answer fast.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ypeng at math.mun.ca  Tue May  6 22:46:12 2003
From: ypeng at math.mun.ca (Paul Y. Peng)
Date: Tue, 06 May 2003 18:16:12 -0230
Subject: [R] Questons about R capabilities
References: <seb7d46c.048@healthsmtp.nycnet>
	<hm5gbvs8ttafpjjhh2kegttev2qu6q4g0i@4ax.com>
Message-ID: <3EB81F14.58853C53@math.mun.ca>

Duncan Murdoch wrote:
> 
> On Tue, 06 May 2003 15:27:20 -0400, you wrote in message
> <seb7d46c.048 at healthsmtp.nycnet>:
> ...
>
> >2)  I am also interested in sampling from a multivariate normal distribution.  I see that R has a command mvrnorm, but when I try to use it, I get a message to the effect that the command is not recognized.  Is there something I must do to enable this command, or is it not available in version 1.7?
> 
> When the help says "mvrnorm(MASS)", that means that the function is in
> the package called "MASS".  You need to execute
> 
>  library(MASS)
> 
> to get that function loaded onto the search path.  You can see which
> packages are already there by executing
> 
>  search()
> 
> Duncan Murdoch

You can also sample a multivariate normal distribution using rmvnorm
from a contributed package "mvtnorm". Execute

	library(mvtnorm)

before using it.

Paul Peng



From jfox at mcmaster.ca  Tue May  6 22:48:30 2003
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 06 May 2003 16:48:30 -0400
Subject: [R] bitmap images in tcltk
In-Reply-To: <Pine.LNX.4.44.0305062042250.10023-100000@reclus.nhh.no>
References: <5.1.0.14.2.20030506141715.01e38068@mcmail.cis.mcmaster.ca>
Message-ID: <5.1.0.14.2.20030506164522.01e96a88@mcmail.cis.mcmaster.ca>

Dear Roger,

Thanks -- that's exactly what I needed. I can just stick the files in a 
bitmaps subdirectory.

  John

At 08:44 PM 5/6/2003 +0200, you wrote:
>On Tue, 6 May 2003, John Fox wrote:
>
> > Dear R-help list members,
> >
> > I'm writing a package using tcltk. Thanks to Peter Dalgaard's excellent
> > work on the tcltk package, almost everything has gone very smoothly. I'm
> > stymied, however, by the following problem:
> >
> > I want to incorporate a bitmap image, stored as an xbm file, in a widget.
> > To take a simple example,
> >
> >      top <- tktoplevel()
> >      tkgrid(tklabel(top, bitmap="@file.xbm", fg="red"))
> >
> > will work as long as file.xbm is in the current directory; 
> alternatively, I
> > could specify the path to this file. The problem is that I can't figure 
> out
> > a reliable way of predicting (or discovering) where the bitmap file will
> > reside when my package is installed.
> >
> > Any suggestions would be appreciated.
>
>system.file(<file path relative to package root>, package="package")[1]
>
>should do it.
>
> >

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From jfox at mcmaster.ca  Tue May  6 22:54:10 2003
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 06 May 2003 16:54:10 -0400
Subject: [R] bitmap images in tcltk
In-Reply-To: <20030506185359.GA8156@sonny.eddelbuettel.com>
References: <5.1.0.14.2.20030506141715.01e38068@mcmail.cis.mcmaster.ca>
	<5.1.0.14.2.20030506141715.01e38068@mcmail.cis.mcmaster.ca>
Message-ID: <5.1.0.14.2.20030506165110.01e38320@mcmail.cis.mcmaster.ca>

Dear Dirk,

The tkrplot package is indeed interesting, but my understanding is that 
it's for putting R graphics in a widget. My bitmaps are for things like 
button-tops. Perhaps I'm missing something.

Regards,
  John

At 01:53 PM 5/6/2003 -0500, Dirk Eddelbuettel wrote:
>On Tue, May 06, 2003 at 02:24:10PM -0400, John Fox wrote:
> > I'm writing a package using tcltk. Thanks to Peter Dalgaard's excellent
> > work on the tcltk package, almost everything has gone very smoothly. I'm
>
>Seconded. It is truly excellent, and cross-platform without any heachaches.
>
> > stymied, however, by the following problem:
> >
> > I want to incorporate a bitmap image, stored as an xbm file, in a widget.
> > To take a simple example,
> >
> >     top <- tktoplevel()
> >     tkgrid(tklabel(top, bitmap="@file.xbm", fg="red"))
> >
> > will work as long as file.xbm is in the current directory; 
> alternatively, I
> > could specify the path to this file. The problem is that I can't figure 
> out
> > a reliable way of predicting (or discovering) where the bitmap file will
> > reside when my package is installed.
> >
> > Any suggestions would be appreciated.
>
>There is a much easier solution thanks to Luke's tkrplot which is available
>for win32 and unix on CRAN.  A simple example is
>
> > tt <- tktoplevel()
> > pl <- tkrplot(tt, function() plot(1:10, main="foo"))
> > tkpack(pl)
>
>It can do fancier stuff too by using a 'replot' feature. The example from
>the help page varies a simple function by tieing a callback command and
>variable from a scale to a function around tkreplot():
>
>      tt <- tktoplevel()
>      bb<-1
>      img <-tkrplot(tt, function() plot(1:20,(1:20)^bb))
>      f<-function(...) {
>          b <- as.numeric(tclvalue("bb"))
>          if (b != bb) {
>              bb <<- b
>              tkrreplot(img)
>          }
>      }
>      s <- tkscale(tt, command=f, from=0.05, to=2.00, variable="bb",
>                   showvalue=FALSE, resolution=0.05, orient="horiz")
>      tkpack(img,s)

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From chrysopa at insecta.ufv.br  Tue May  6 23:07:28 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Tue, 6 May 2003 18:07:28 -0300
Subject: [R] Concatenate dataframe
Message-ID: <200305061805.26073.chrysopa@insecta.ufv.br>

Hi,

thanks for help on index in a for for looping. its work.

Now I have another doubt.

I have a data.frame like this:

    nsps area
1      1    4
2      0    9
3      1    4
4      1    4
5      1    4
6      1    9
7      0    4
8      1    9
9      0    4
10     1    9
...

I try to make another data.frame like this:

    nsps area
1      4    4
2      3    9

using tapply, it work:

> tapply(betarea1$nsps,betarea1$area,sum)
  4   9  16  25  36  49  64  81 100 121 144 
  4  10  11  19  25  34  36  44  49  49  56 

But i need it on a data.frame where the first line of this tapply result is 
the area column and the second line is the nsps column.

Any idea for make this?

Thanks
Ronaldo

-- 
	A democracia e a arte e ciencia de administrar o circo a 
	partir da jaula dos macacos.
		-- H. L. Mencken 
--
|   // | \\   [*****************************][*******************]
|| ( ?   ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|      V      [UFV/DBA-Entomologia          ][HD: 30 + 10 Gb     ]
||  /     \   [36571-000 Vi?osa - MG        ][RAM: 128 Mb        ]
|  /(.''`.)\  [Fone: 31-3899-2532           ][Video: SiS620-8Mb  ]
||/(: :'  :)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (`. `'` ) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( `-  )   [*****************************][*******************]
||| _/   \_Powered by GNU/Debian W/Sarge D+ || Lxuser#: 205366



From edd at debian.org  Tue May  6 23:17:44 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 6 May 2003 16:17:44 -0500
Subject: [R] bitmap images in tcltk
In-Reply-To: <5.1.0.14.2.20030506165110.01e38320@mcmail.cis.mcmaster.ca>
References: <5.1.0.14.2.20030506141715.01e38068@mcmail.cis.mcmaster.ca>
	<5.1.0.14.2.20030506141715.01e38068@mcmail.cis.mcmaster.ca>
	<5.1.0.14.2.20030506165110.01e38320@mcmail.cis.mcmaster.ca>
Message-ID: <20030506211744.GA9374@sonny.eddelbuettel.com>

On Tue, May 06, 2003 at 04:54:10PM -0400, John Fox wrote:
> Dear Dirk,
> 
> The tkrplot package is indeed interesting, but my understanding is that 
> it's for putting R graphics in a widget. My bitmaps are for things like 
> button-tops. Perhaps I'm missing something.

No, I had misread the question. 

Sorry,  Dirk

> Regards,
>  John
> 
> At 01:53 PM 5/6/2003 -0500, Dirk Eddelbuettel wrote:
> >On Tue, May 06, 2003 at 02:24:10PM -0400, John Fox wrote:
> >> I'm writing a package using tcltk. Thanks to Peter Dalgaard's excellent
> >> work on the tcltk package, almost everything has gone very smoothly. I'm
> >
> >Seconded. It is truly excellent, and cross-platform without any heachaches.
> >
> >> stymied, however, by the following problem:
> >>
> >> I want to incorporate a bitmap image, stored as an xbm file, in a widget.
> >> To take a simple example,
> >>
> >>     top <- tktoplevel()
> >>     tkgrid(tklabel(top, bitmap="@file.xbm", fg="red"))
> >>
> >> will work as long as file.xbm is in the current directory; 
> >alternatively, I
> >> could specify the path to this file. The problem is that I can't figure 
> >out
> >> a reliable way of predicting (or discovering) where the bitmap file will
> >> reside when my package is installed.
> >>
> >> Any suggestions would be appreciated.
> >
> >There is a much easier solution thanks to Luke's tkrplot which is available
> >for win32 and unix on CRAN.  A simple example is
> >
> >> tt <- tktoplevel()
> >> pl <- tkrplot(tt, function() plot(1:10, main="foo"))
> >> tkpack(pl)
> >
> >It can do fancier stuff too by using a 'replot' feature. The example from
> >the help page varies a simple function by tieing a callback command and
> >variable from a scale to a function around tkreplot():
> >
> >     tt <- tktoplevel()
> >     bb<-1
> >     img <-tkrplot(tt, function() plot(1:20,(1:20)^bb))
> >     f<-function(...) {
> >         b <- as.numeric(tclvalue("bb"))
> >         if (b != bb) {
> >             bb <<- b
> >             tkrreplot(img)
> >         }
> >     }
> >     s <- tkscale(tt, command=f, from=0.05, to=2.00, variable="bb",
> >                  showvalue=FALSE, resolution=0.05, orient="horiz")
> >     tkpack(img,s)
> 
> -----------------------------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario, Canada L8S 4M4
> email: jfox at mcmaster.ca
> phone: 905-525-9140x23604
> web: www.socsci.mcmaster.ca/jfox
> -----------------------------------------------------
> 
> 

-- 
Don't drink and derive. Alcohol and algebra don't mix.



From nahua at crosswinds.net  Tue May  6 23:25:47 2003
From: nahua at crosswinds.net (nahua@crosswinds.net)
Date: Tue, 6 May 2003 17:25:47 EDT
Subject: [R] par.binary
Message-ID: <20030506212547.9909F2C360@out-mx1.crosswinds.net>

Hello,

I am trying to change the foreground and background colors of an owin mask object within SpatStat. Can anyone describe the syntax for specifting a list for par.binary?

Thank You,
Timothy

Timothy S. Hare
Grinnell College
nahua at crosswinds.net

___________________________________
Build high quality traffic with the Web's Premier traffic building system. 2 to 1 ratio! http://www.itrafficstar.com/?ref=6



From falk at ucalgary.ca  Wed May  7 00:28:50 2003
From: falk at ucalgary.ca (Falk Huettmann)
Date: Tue, 6 May 2003 16:28:50 -0600
Subject: [R] Compile R into a standalone EXE for WINNT
Message-ID: <HFEEJMLAODBKIBKEOIOGAEOHDAAA.falk@ucalgary.ca>


Hi,

I have an R script (transferred from SPLUS) and would like to compile a
standalone EXE (or DLL)
for WINNT. Would somebody know how this works or how it could be done ?

Thanks so much for any hints and suggestions; best regards

   F.


Falk Huettmann
Geography Dept.-Earth Science-
2500 University Drive N.W.
University of Calgary
Calgary AB, T2N 1N4 CANADA
Email: falk at ucalgary.ca
Tel. 403 210 5422 (lab)
     403 230 3122 (home)
 Fax 403 282 6561



From ross at biostat.ucsf.edu  Wed May  7 00:26:49 2003
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Tue, 06 May 2003 22:26:49 -0000
Subject: [R] Seeking packaging advice
Message-ID: <1052259969.7115.74.camel@epibiosun115-4>

I have 3 questions about creating a package for R, and would appreciate
any guidance.

1. Demonstrating the packaged code requires some support code files.  It
would seem natural to put these in the demo directory, but "Writing R
extensions" says files in demo should be suitable for runing from
demo().  The support files are not intended to be run from the top
level.  How should I handle them?

A further complication is that the demo won't actually work without some
prior setup outside of R, setup that can't be automated (the user must
pick a computational cluster).  I am planning to handle that by
documenting it.

2. Are there some base datasets I can assume present for use in my
demonstration?

3. Is this the right list for these questions?

Thanks.
-- 
Ross Boylan <ross at biostat.ucsf.edu>              wk: (415) 502-4031
University of California, San Francisco         fax: (415) 476-9856
Dept of Epidemiology and Biostatistics           hm: (415) 550-1062
530 Parnassus Avenue (Library) rm 115-4
San Francisco, CA 94143-0840



From bmagill at earthlink.net  Wed May  7 00:39:24 2003
From: bmagill at earthlink.net (Brett Magill)
Date: Tue, 06 May 2003 17:39:24 -0500
Subject: [R] R vs SPSS output for princomp
In-Reply-To: <Pine.LNX.4.44.0305061617110.20359-100000@gannet.stats>
References: <5C0D050B-7FD3-11D7-90EC-00306579408C@syr.edu>
Message-ID: <5.2.0.9.0.20030506173142.00b165a0@mail.earthlink.net>

If you want factor analysis, you should use factanal or more generally, 
MLE, true.  Nonetheless, I have use for PCA as a factor extraction method 
in a couple of situations:

1.  To replicate results from that method
2.  When the covariance matrix is non-positive definite

I have written some code to do this.  See:

http://home.earthlink.net/~bmagill/MyMisc.html

Find the function prinfact and associated methods and functions.  This 
would replicate SPSS results of "factor analysis by principal components".

Another better option might be OLS estimation for the second situation.  I 
haven't the ability to implement this myself.  Maybe a future version of R?

At 04:31 PM 5/6/2003 +0100, Prof Brian Ripley wrote:
>Well, many other packages confuse (hopelessly) PCA and factor analysis,
>including SPSS.  They are separate statistical methods with very different
>purposes, that for factanal being quite rarely appropriate.  R is not
>written to reproduce the mistakes of other packages, but to implement
>sound statistical practice.



From spencer.graves at pdf.com  Wed May  7 01:11:30 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 06 May 2003 16:11:30 -0700
Subject: [R] Compile R into a standalone EXE for WINNT
References: <HFEEJMLAODBKIBKEOIOGAEOHDAAA.falk@ucalgary.ca>
Message-ID: <3EB84122.8090107@pdf.com>

Hi, Falk:

	  When you wrote "transferred from SPLUS", I got concerned:  Is this 
S-Plus script something you or a colleague wrote or part of S-Plus?  I 
assume it is NOT part of Insightful's intellectual property (IP).  If it 
is, I would stay far away.  I'm not an attorney, but I would expect that 
Insightful might sue, and if they did, they might easily win.

	  We must meticulously respect Insightful's IP.  If any Insightful IP 
finds its way into an officially sanctioned R package, it could be very 
serious.

Spencer Graves

Falk Huettmann wrote:
> Hi,
> 
> I have an R script (transferred from SPLUS) and would like to compile a
> standalone EXE (or DLL)
> for WINNT. Would somebody know how this works or how it could be done ?
> 
> Thanks so much for any hints and suggestions; best regards
> 
>    F.
> 
> 
> Falk Huettmann
> Geography Dept.-Earth Science-
> 2500 University Drive N.W.
> University of Calgary
> Calgary AB, T2N 1N4 CANADA
> Email: falk at ucalgary.ca
> Tel. 403 210 5422 (lab)
>      403 230 3122 (home)
>  Fax 403 282 6561
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From tlumley at u.washington.edu  Wed May  7 01:29:01 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 6 May 2003 16:29:01 -0700 (PDT)
Subject: [R] Seeking packaging advice
In-Reply-To: <1052259969.7115.74.camel@epibiosun115-4>
Message-ID: <Pine.A41.4.44.0305061626320.23944-100000@homer14.u.washington.edu>

On 6 May 2003, Ross Boylan wrote:

> I have 3 questions about creating a package for R, and would appreciate
> any guidance.
>
> 1. Demonstrating the packaged code requires some support code files.  It
> would seem natural to put these in the demo directory, but "Writing R
> extensions" says files in demo should be suitable for runing from
> demo().  The support files are not intended to be run from the top
> level.  How should I handle them?

Perhaps put them in  inst/

> A further complication is that the demo won't actually work without some
> prior setup outside of R, setup that can't be automated (the user must
> pick a computational cluster).  I am planning to handle that by
> documenting it.
>
> 2. Are there some base datasets I can assume present for use in my
> demonstration?

The ones listed by data() in a plain installation of R.  Nearly all
installations will also have the data() sets from the recommended
packages, and you can use these if you check (eg with require()) that the
package is actually present.

> 3. Is this the right list for these questions?

It's not an egregiously wrong list. r-devel at r-project.org might be better.


	-thomas



From p.connolly at hortresearch.co.nz  Wed May  7 02:25:05 2003
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Wed, 7 May 2003 12:25:05 +1200
Subject: [R] Tick labels on y axis in lattice plots
Message-ID: <20030507002505.GN13579@hortresearch.co.nz>

I seem to remember this was discussed a year or two ago, but I can't
find it in the archives.


platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    7.0              
year     2003             
month    04               
day      16               
language R                


It appears to my eye that y-axis tick labels are about half a
millimetre lower than the tick they label -- at least when using the
postscript device with lattice.  For large font sizes it's
unnoticable, but there are times when a small pointsize is necessary
and I have to fudge the positioning.

Is that noticed by anyone else?

best

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From s2112930 at student.rmit.edu.au  Wed May  7 05:20:49 2003
From: s2112930 at student.rmit.edu.au (Skanda Kallur; MEngg)
Date: Wed, 07 May 2003 13:20:49 +1000
Subject: [R] -means, hybrid clustering or similar implementations on R
Message-ID: <1052277649.cbdcff00s2112930@student.rmit.edu.au>

Hi,

I would like to know if someone knows an extended implementation of k-means in R to find appropriate number of clusters for a given k-dimensional data. 

Also, I am working on clustering for forecasting, if someone is interested or has knowledge on implementational details please mail me, I would appreciate it.

Regards


 

Skanda Kallur

"Cogito, ergo sum" (I think, therefore I am) - Ren? D?scartes



From Robin.Thomson at csiro.au  Wed May  7 05:27:31 2003
From: Robin.Thomson at csiro.au (Robin.Thomson@csiro.au)
Date: Wed, 7 May 2003 13:27:31 +1000 
Subject: [R] graphics with rterm
Message-ID: <A8877251964B294BAB5BA1FC58B43FED319BA9@molly.tas.csiro.au>

I would like to use R as the graphical interface for a fortran program I am
writing. Presently my fortran code produces a set of data files then sends
an "rterm ..... <filename.r >out.out" line to my windows system. This causes
rterm to read in the data files, draw plots on my screen in milliseconds
.... and then terminate and disappear, plots and all, forever. It's this
last bit of efficiency that I would like to curb. I would like the graphs to
appear and stay until I'm ready to dismiss them. I would rather not have
rterm produce my plots as metafiles because I would like them to be
immediately visible on the screen - I don't want to have to fiddle around
opening graphics files. 

Any ideas? Is rterm the right thing to be using?

Thanks
Robin



From MZodet at ahrq.gov  Wed May  7 05:31:33 2003
From: MZodet at ahrq.gov (MZodet@ahrq.gov)
Date: Tue, 6 May 2003 23:31:33 -0400 
Subject: [R] "Program" files
Message-ID: <3598558AD728D41183350008C7CF291C0A5CD181@exchange1.ahrq.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030506/3a203900/attachment.pl

From MZodet at ahrq.gov  Wed May  7 05:36:08 2003
From: MZodet at ahrq.gov (MZodet@ahrq.gov)
Date: Tue, 6 May 2003 23:36:08 -0400 
Subject: [R] "Program" files...Additional comment
Message-ID: <3598558AD728D41183350008C7CF291C0A5CD182@exchange1.ahrq.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030506/11dbdbe7/attachment.pl

From umalvarez at fata.unam.mx  Wed May  7 05:01:15 2003
From: umalvarez at fata.unam.mx (Ulises Mora Alvarez)
Date: Tue, 6 May 2003 22:01:15 -0500 (CDT)
Subject: [R] "Program" files
In-Reply-To: <3598558AD728D41183350008C7CF291C0A5CD181@exchange1.ahrq.gov>
Message-ID: <Pine.LNX.4.44.0305062158070.8011-100000@fata.unam.mx>

Hi:

Take a look a Sweave....

> library(tools)
> ?Sweave

Or at the R News 2/3 December 2003.




On Tue, 6 May 2003 MZodet at ahrq.gov wrote:

> Is there any such thing as a program file in R?  That is, is it possible to
> compile and save code for performing data management and analytic tasks for
> a given project into a single/multiple file(s) (i.e., like a script file
> (S-Plus), a do file (STATA), or a *.sas file (SAS))?
> 
> Any words of wisdom or a point in the direction of some documentation would
> be helpful.  If it is not possible to work with such files I would not mind
> some advice on how I should be thinking about organizing my work differently
> in R compared to these other programs.  Typically, I provide relatively
> thorough project documentation in my program files so that if someone else
> inherits them they can pick-up on them quickly.
> 
> Thanks.
> 
> Marc
> 
> Marc W. Zodet, MS
> Health Statistician
> Agency for Healthcare Research and Quality
> Rockville, Maryland 20841
> mzodet at ahrq.gov
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Ulises M. Alvarez
LAB. DE ONDAS DE CHOQUE
FISICA APLICADA Y TECNOLOGIA AVANZADA
UNAM
umalvarez at fata.unam.mx



From rossini at blindglobe.net  Wed May  7 06:29:29 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Tue, 06 May 2003 21:29:29 -0700
Subject: [R] "Program" files
In-Reply-To: <Pine.LNX.4.44.0305062158070.8011-100000@fata.unam.mx> (Ulises
	Mora Alvarez's message of "Tue, 6 May 2003 22:01:15 -0500 (CDT)")
References: <Pine.LNX.4.44.0305062158070.8011-100000@fata.unam.mx>
Message-ID: <873cjrs7km.fsf@jeeves.blindglobe.net>


While I think Sweave is great it might be overkill for the specific
problem mentioned.

The point is that you can script R similarly to S-PLUS.  Not quite as
easily as the newer versions of S-PLUS, perhaps.  However, some of us
still use R, S-PLUS, Stata, and SAS using the same approach (via
unifying interfaces such as ESS/Emacs, or text editors and loading the
resulting files).  Is this what you are asking?

best,
-tony



Ulises Mora Alvarez <umalvarez at fata.unam.mx> writes:

> Hi:
>
> Take a look a Sweave....
>
>> library(tools)
>> ?Sweave
>
> Or at the R News 2/3 December 2003.
>
>
>
>
> On Tue, 6 May 2003 MZodet at ahrq.gov wrote:
>
>> Is there any such thing as a program file in R?  That is, is it possible to
>> compile and save code for performing data management and analytic tasks for
>> a given project into a single/multiple file(s) (i.e., like a script file
>> (S-Plus), a do file (STATA), or a *.sas file (SAS))?
>> 
>> Any words of wisdom or a point in the direction of some documentation would
>> be helpful.  If it is not possible to work with such files I would not mind
>> some advice on how I should be thinking about organizing my work differently
>> in R compared to these other programs.  Typically, I provide relatively
>> thorough project documentation in my program files so that if someone else
>> inherits them they can pick-up on them quickly.
>> 
>> Thanks.
>> 
>> Marc
>> 
>> Marc W. Zodet, MS
>> Health Statistician
>> Agency for Healthcare Research and Quality
>> Rockville, Maryland 20841
>> mzodet at ahrq.gov
>> 
>> 	[[alternate HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>> 
>
> -- 
> Ulises M. Alvarez
> LAB. DE ONDAS DE CHOQUE
> FISICA APLICADA Y TECNOLOGIA AVANZADA
> UNAM
> umalvarez at fata.unam.mx
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
A.J. Rossini rossini at u.washington.edu http://software.biostat.washington.edu/ 
Biostatistics, U Washington and Fred Hutchinson Cancer Research Center

FHCRC:Tu: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email 
UW  : Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX 

CONFIDENTIALITY NOTICE: This e-mail message and any attachments ... {{dropped}}



From Detlef.Steuer at unibw-hamburg.de  Wed May  7 08:18:59 2003
From: Detlef.Steuer at unibw-hamburg.de (Detlef Steuer)
Date: Wed, 07 May 2003 08:18:59 +0200 (CEST)
Subject: [R] how to read a web page and extract an html table?
In-Reply-To: <20030506143129.33487.qmail@web12105.mail.yahoo.com>
Message-ID: <XFMail.20030507081859.steuer@unibw-hamburg.de>

Hi!

On 06-May-2003 Adi Humbert wrote:
> Hello all, 
> 
> I want to read a table from a given web page. 
> 
> If I do something like
>> str="http://www...."      # this is the web address
>> aux1 <- url(str,open="rt")# open connection 
>> aux2 <- readLines(aux1)   # read web page 
> aux2 contains the html file. 
> 
> I want to extract the table from the html file. 
> Is there a function html2R, the opposite of R2html? 
> How should I do this? 

I think the easiest way is using perl as preprocessor:
http://www.devshed.com/Server_Side/Perl/DataMining/page3.html


hope this helps,
dst

> 
> Thanks, 
> Adrian
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

"There is no way to peace, peace is the way." -- Ghandi

Detlef Steuer --- http://fawn.unibw-hamburg.de/steuer.html
***** Encrypted mail preferred *****



From ripley at stats.ox.ac.uk  Wed May  7 09:02:45 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 7 May 2003 08:02:45 +0100 (BST)
Subject: [R] graphics with rterm
In-Reply-To: <A8877251964B294BAB5BA1FC58B43FED319BA9@molly.tas.csiro.au>
Message-ID: <Pine.LNX.4.44.0305070756550.1948-100000@gannet.stats>

On Wed, 7 May 2003 Robin.Thomson at csiro.au wrote:

> I would like to use R as the graphical interface for a fortran program I am
> writing. Presently my fortran code produces a set of data files then sends
> an "rterm ..... <filename.r >out.out" line to my windows system. This causes
> rterm to read in the data files, draw plots on my screen in milliseconds
> .... and then terminate and disappear, plots and all, forever. It's this
> last bit of efficiency that I would like to curb. I would like the graphs to
> appear and stay until I'm ready to dismiss them. 

Then put something in your script to say so when you want it to end.  The
user cannot interact via the keyboard (you have redirected stdin), but you
can put up a dialog box. (See ?winDialog.)

[This has come up several times, so you might want to consult the 
archives.]

> I would rather not have
> rterm produce my plots as metafiles because I would like them to be
> immediately visible on the screen - I don't want to have to fiddle around
> opening graphics files. 
> 
> Any ideas? Is rterm the right thing to be using?

Probably not, but then Fortran is not conducive to writing interfaces.
Why not call your Fortran from R rather than v.v.?  A more sophisticated 
approach would be to call R via a DCOM server directly from your code, but 
I think that is going to be hard/impossible from a 1950s language.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Saghir.Bashir at UCB-Group.com  Wed May  7 09:06:58 2003
From: Saghir.Bashir at UCB-Group.com (Bashir Saghir (Aztek Global))
Date: Wed, 7 May 2003 09:06:58 +0200 
Subject: [R] "Program" files
Message-ID: <3EBA5559F490D61189430002A5F0AE89030185D4@ntexcrd.braine.ucb>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030507/e0f36c22/attachment.pl

From ripley at stats.ox.ac.uk  Wed May  7 09:09:25 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 7 May 2003 08:09:25 +0100 (BST)
Subject: [R] Compile R into a standalone EXE for WINNT
In-Reply-To: <HFEEJMLAODBKIBKEOIOGAEOHDAAA.falk@ucalgary.ca>
Message-ID: <Pine.LNX.4.44.0305070804370.1948-100000@gannet.stats>

On Tue, 6 May 2003, Falk Huettmann wrote:

> I have an R script (transferred from SPLUS) and would like to compile a
> standalone EXE (or DLL)
> for WINNT. Would somebody know how this works or how it could be done ?

To do what exactly?  You cannot compile R code to machine code: you need
an R interpreter.

I don't see the point of having a single script as an application anyway: 
don't you need some control, e.g. of the input?

It is possible to write a graphical front end in e.g. Visual Basic and use 
that to send a script to an embedded R interpreter (most easily by DCOM 
under Windows, but it can be done directly).

Perhaps you could start at the beginning and tell us what you want to 
achieve (rather than asking for some specific technical solution)?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From sandrine.mainard at wanadoo.fr  Wed May  7 09:11:48 2003
From: sandrine.mainard at wanadoo.fr (Sandrine Mainard)
Date: Wed,  7 May 2003 09:11:48 +0200 (CEST)
Subject: [R] NA on multtest
Message-ID: <19065786.1052291508630.JavaMail.www@wwinf0601>

Hello,
I have one question about the mt.rawp2adjp in the mulltest package. Indeed, i 
have a database about fit and ill mice,and there are some "NA". I wanted to 
realise the mt.rawp2adjp, in order to have pvalue of several tests, but the 
Hochberg,BH and BY return me "NA" for all lines. Don't they accept the "NA" 
value, contrary the other tests? 

Thanks a lot 


Sandrine Mainard



From sandrine.mainard1 at etud.univ-ubs.fr  Wed May  7 09:08:16 2003
From: sandrine.mainard1 at etud.univ-ubs.fr (sandrine.mainard1@etud.univ-ubs.fr)
Date: Wed,  7 May 2003 09:08:16 +0200
Subject: [R] NA on multtest
Message-ID: <1052291296.3eb8b0e050545@homae.univ-ubs.fr>

Hello,
I have one question about the mt.rawp2adjp in the mulltest package. Indeed, i 
have a database about fit and ill mice,and there are some "NA". I wanted to 
realise the mt.rawp2adjp, in order to have pvalue of several tests, but the 
Hochberg,BH and BY return me "NA" for all lines. Don't they accept the "NA" 
value, contrary the other tests? 

Thanks a lot 


Sandrine Mainard 



--------------------------------------------------------------------------------
Universit de Bretagne sud                               http://www.univ-ubs.fr/



From maechler at stat.math.ethz.ch  Wed May  7 09:45:43 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 7 May 2003 09:45:43 +0200
Subject: [R] Questons about R capabilities
In-Reply-To: <3EB8124D.3060706@pdf.com>
References: <seb7d46c.048@healthsmtp.nycnet>
	<3EB8124D.3060706@pdf.com>
Message-ID: <16056.47527.696937.483189@gargle.gargle.HOWL>

Just a note:

>>>>> "Spencer" == Spencer Graves <spencer.graves at pdf.com>
>>>>>     on Tue, 06 May 2003 12:51:41 -0700 writes:

    Spencer> 	  Regarding the second question, did you try
    Spencer> "library(mass)" before your mvrnorm command?

it's an accident that this works -- on Windows only.
It will stop working in some future versions of R.
As Duncan Murdoch mentioned in his answer on this thread, the
correct command to activate the recommended package MASS is
	library(MASS)
        ##      ^^^^  capitalized.
As you all have learned, case does matter in the S language.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From hennig at stat.math.ethz.ch  Wed May  7 10:29:32 2003
From: hennig at stat.math.ethz.ch (Christian Hennig)
Date: Wed, 7 May 2003 10:29:32 +0200 (CEST)
Subject: [R] -means, hybrid clustering or similar implementations on R
In-Reply-To: <1052277649.cbdcff00s2112930@student.rmit.edu.au>
Message-ID: <Pine.LNX.4.44.0305071012570.1930-100000@florence>

Hi,

On Wed, 7 May 2003, Skanda Kallur; MEngg wrote:

> Hi,
> 
> I would like to know if someone knows an extended implementation of k-means in R to find appropriate number of clusters for a given k-dimensional data. 

You may use pam in library(cluster). Optimal number of clusters by maximizing
pam(x, k) $ silinfo $ avg.width
over k (number of clusters). Note that this does not work with k=1.
pam does not exactly the same as k-means. By default, it uses euclidean 
distances, not their squares ("k-median") and all cluster centers are
present data points (medoids). If you want to "emulate" k-means, you can
provide x as a distance matrix with squared euclidean distances (which is
often worse than the default, e.g. in case of outliers). 

An alternative is the use of EMclust in library(mclust), which decides
about the optimal number of clusters by Bayesian Information
Criterion (BIC). Set the parameter emModelNames="EII" for the mixture 
model analogon to k-means (but do this only if you are sure that you want
something k-means-like and not a more flexible model).

In general, the number of clusters-problem is difficult, because is does
not only depend on the data but also on your concept of a "cluster". The
BIC has a bit better theoretical support than pam's average silhouette
width, but the problem is far from being solved.

Christian

-- 
***********************************************************************
Christian Hennig
Seminar fuer Statistik, ETH-Zentrum (LEO), CH-8092 Zuerich (currently)
and Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at stat.math.ethz.ch, http://stat.ethz.ch/~hennig/
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag.de



From petr.pikal at precheza.cz  Wed May  7 11:43:44 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Wed, 07 May 2003 11:43:44 +0200
Subject: [R] FW: Sum by categorical variable
In-Reply-To: <6C9A2D9477234140A56E9D1B073B28E901DB5D@gitmanex01.git.generali.ch>
Message-ID: <3EB8F170.4720.5D6D02@localhost>

Hi

On 6 May 2003 at 16:53, De Amicis Fabrizio (G.I.T.) wrote:

> 
> Another easy(/stupid) question:
> 
> with the following command
>  j2<-xf1[1:10,"V4"]
> I have 
> 
> > j2
>  [1] CHROMOLI             LINEAGERMAI          RINALDI             
>  GIUNTIMA
> AUTOSTELLA          
>  [6] CAIZZONE             CENTRO B PEL E C SNC CONSORZI            
>  MAN NORD
> PDM                 
> 1304 Levels:   MACHIAVELLI Snc  MENARINI MANUFACTURERS LOGISTICS
> SERVICES ... ZUCCHERIFICIO DEL MOLISE
> 
> 
> Why j2 has 1304 Levels (I know that xf has 1304 rows)? How can I
> obtain a vector of 10 elements?
You actually have got first 10 elements of variable "V4" in j2 

see length(j2), 

but as it is a factor the level attribute has retained an information 
about all different levels of "V4" which I presume is 1304. To get 
rid of these levels just use

factor(j2)


> 
> Thank you 
> 
> 
> >  
> > 
> > ---------------------------------------------------------------
> > Fabrizio De Amicis
> > 
> > IT Department
> > Generali Information Technologies - (GIT)
> > 
> > Centro Galleria 2,
> > Via Cantonale
> > CH - 6928 Manno - Switzerland
> > Tel  +41 91 806 6220
> > Fax +41 91 806 6298
> > E-mail: fabrizio.deamicis at git.generali.ch  
> > 
> > 
> > 
> > 
> **********************************************************************
> ** The information in this email is confidential and may be legally...
> {{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

CheersPetr Pikal
petr.pikal at precheza.cz
p.pik at volny.cz



From Philippe.Hupe at curie.fr  Wed May  7 13:27:04 2003
From: Philippe.Hupe at curie.fr (=?ISO-8859-1?Q?Philippe_Hup=E9?=)
Date: Wed, 07 May 2003 13:27:04 +0200
Subject: [R] hierarchical clustering
In-Reply-To: <3EB8F170.4720.5D6D02@localhost>
References: <3EB8F170.4720.5D6D02@localhost>
Message-ID: <3EB8ED88.4070003@curie.fr>

Hi,

I would like to perform hierachical clustering on data which already 
represents clusters means. The cluster procedure of SAS software can 
take into account this information through the RMSSTD option.  Does 
anyone know a R function which can take into account the frequency of 
each cluster and its standard-deviation.

Thanks

Philippe.



From davidD at qimr.edu.au  Wed May  7 13:34:03 2003
From: davidD at qimr.edu.au (David Duffy)
Date: Wed, 7 May 2003 21:34:03 +1000 (EST)
Subject: [R] Parsing HTML tables and dumb plotting
In-Reply-To: <200305071002.h47A26nj025666@hypatia.math.ethz.ch>
References: <200305071002.h47A26nj025666@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.50.0305072124150.17443-100000@orpheus.qimr.edu.au>

Another approach to digest *simple* tables is via
lynx -dump <table url>

Dumb plotting is available using macanova, which is also related to early 
versions of S (eg plot(x,y,dumb:T)).
-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From martinl at mathinfo.ens.univ-reims.fr  Wed May  7 14:01:31 2003
From: martinl at mathinfo.ens.univ-reims.fr (MARTIN Ludovic)
Date: Wed, 07 May 2003 14:01:31 +0200
Subject: [R] [R ] Query : problems with the arithmetic operator "^" with
	function "lme" and "lmList"
Message-ID: <200305071257.h47CvcwR023819@tom.ens.univ-reims.fr>

Dear all,

I've got a problem in including square variables in lme and lmlist 
functions. I've tried to work on Oxboys data of Pinheiro and 
Bates'book, which consist of the heights of 26 boys, each mesured on 
nine different occasions :

 > Oxboys
Grouped Data: height ~ age | Subject
    Subject     age height Occasion
1         1 -1.0000 140.50        1
2         1 -0.7479 143.40        2
3         1 -0.4630 144.80        3
4         1 -0.1643 147.10        4
5         1 -0.0027 147.70        5
...

A quadratic model in "age" would be fit with lmList
(height~age+age^2,Oxboys).

We obtain:
 
> fm2Oxboys.lis<-lmList(height~age+age^2,Oxboys)
> fm2Oxboys.lis
Call:
  Model: height ~ age + age^2 | Subject 
   Data: Oxboys 

Coefficients:
   (Intercept)      age
10    130.2616 3.722915
26    137.9927 5.588783
25    139.2105 4.024081
9     138.1369 6.009057
2     142.8584 5.440176
...
19    164.5761 9.065620
4     165.0724 9.360561

Degrees of freedom: 234 total; 182 residual
Residual standard error: 0.6598878

They are not coefficients associated with the covariate "age^2" ! 
However, the model called is " Height~age+age^2 | Subject " .

I would be grateful if anyone could help me.

Cordially,

Martin Ludovic.



From azzalini at stat.unipd.it  Wed May  7 14:13:53 2003
From: azzalini at stat.unipd.it (Adelchi Azzalini)
Date: Wed, 7 May 2003 14:13:53 +0200
Subject: [R] Course***R/Splus Fundamentals and Programming Techniques,
	May-June 2003 @ 5 locations near you! (Raleigh, San Francisco, etc)
In-Reply-To: <APEHLKCMHHAKBGLAPKPCMELDCDAA.elvis@xlsolutions-corp.com>
References: <APEHLKCMHHAKBGLAPKPCMELDCDAA.elvis@xlsolutions-corp.com>
Message-ID: <20030507121353.B90DC7CA824@tango.stat.unipd.it>

On Tuesday 06 May 2003 18:01, elvis at xlsolutions-corp.com wrote:
> XLSolutions Corporation (www.xlsolutions-corp.com) is proud
> to announce May-June 2-day "R/S-plus Fundamentals and Programming
> Techniques".
>
> ****Houston, Tx-----------------> May 22-23
> ****San Diego, CA --------------> May 29-30
> ****Raleigh, NC ----------------> June 5-6
> ****Boston, MA -----------------> June 12-13
> ****San Francisco --------------> ?TBD
>

I am not clear what you mean by "near you".

Adelchi Azzalini

-- 
Adelchi Azzalini  <azzalini at stat.unipd.it>
Dipart.Scienze Statistiche, Universit? di Padova, Italia
http://azzalini.stat.unipd.it/



From Saghir.Bashir at UCB-Group.com  Wed May  7 14:33:01 2003
From: Saghir.Bashir at UCB-Group.com (Bashir Saghir (Aztek Global))
Date: Wed, 7 May 2003 14:33:01 +0200 
Subject: [R] [R ] Query : problems with the arithmetic operator "^" wi
	th function "lme" and "lmList"
Message-ID: <3EBA5559F490D61189430002A5F0AE89030185DD@ntexcrd.braine.ucb>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030507/60ec9f72/attachment.pl

From carlos.ortega at minorplanet.com  Wed May  7 14:56:58 2003
From: carlos.ortega at minorplanet.com (Carlos Ortega)
Date: Wed, 7 May 2003 14:56:58 +0200
Subject: [R] [R ] Query : problems with the arithmetic operator "^" with
	function "lme" and "lmList"
In-Reply-To: <3EBA5559F490D61189430002A5F0AE89030185DD@ntexcrd.braine.ucb>
Message-ID: <012301c31498$25005870$2d6ea8c0@MinorplanetDev>

Hello,

Check also function "AsIs"  ( Usage:  I(x) ).

Regards,
Carlos.


-----Mensaje original-----
De: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] En nombre de Bashir Saghir
(Aztek Global)
Enviado el: mi?rcoles, 07 de mayo de 2003 14:33
Para: 'MARTIN  Ludovic'
CC: 'r-help at stat.math.ethz.ch'
Asunto: RE: [R] [R ] Query : problems with the arithmetic operator "^"
with function "lme" and "lmList"


Dear Martin,

Have you try to create a new variable for age squared, say agesq? If you
fit the model using this new variable you should get the coefficients.
So your new model is something like height~age+agesq

I hope this helps,
Saghir



> -----Original Message-----
> From:	MARTIN   Ludovic [SMTP:martinl at mathinfo.ens.univ-reims.fr]
> Sent:	Wednesday, 07 May, 2003 2:02 PM
> To:	r-help at stat.math.ethz.ch
> Subject:	[R] [R ] Query : problems with the arithmetic operator
"^"
> with function "lme" and "lmList"
> 
> Dear all,
> 
> I've got a problem in including square variables in lme and lmlist
> functions. I've tried to work on Oxboys data of Pinheiro and 
> Bates'book, which consist of the heights of 26 boys, each mesured on 
> nine different occasions :
> 
>  > Oxboys
> Grouped Data: height ~ age | Subject
>     Subject     age height Occasion
> 1         1 -1.0000 140.50        1
> 2         1 -0.7479 143.40        2
> 3         1 -0.4630 144.80        3
> 4         1 -0.1643 147.10        4
> 5         1 -0.0027 147.70        5
> ...
> 
> A quadratic model in "age" would be fit with lmList 
> (height~age+age^2,Oxboys).
> 
> We obtain:
>  
> > fm2Oxboys.lis<-lmList(height~age+age^2,Oxboys)
> > fm2Oxboys.lis
> Call:
>   Model: height ~ age + age^2 | Subject 
>    Data: Oxboys
> 
> Coefficients:
>    (Intercept)      age
> 10    130.2616 3.722915
> 26    137.9927 5.588783
> 25    139.2105 4.024081
> 9     138.1369 6.009057
> 2     142.8584 5.440176
> ...
> 19    164.5761 9.065620
> 4     165.0724 9.360561
> 
> Degrees of freedom: 234 total; 182 residual
> Residual standard error: 0.6598878
> 
> They are not coefficients associated with the covariate "age^2" !
> However, the model called is " Height~age+age^2 | Subject " .
> 
> I would be grateful if anyone could help me.
> 
> Cordially,
> 
> Martin Ludovic.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 
--------------------------------------------------------- 
Legal Notice: This electronic mail and its attachments are inten... {{dropped}}



From mschwartz at medanalytics.com  Wed May  7 15:02:04 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 7 May 2003 08:02:04 -0500
Subject: [R] [R ] Query : problems with the arithmetic operator "^"
	withfunction "lme" and "lmList"
In-Reply-To: <200305071257.h47CvcwR023819@tom.ens.univ-reims.fr>
Message-ID: <008001c31498$dc751130$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of MARTIN
Ludovic
>Sent: Wednesday, May 07, 2003 7:02 AM
>To: r-help at stat.math.ethz.ch
>Subject: [R] [R ] Query : problems with the arithmetic 
>operator "^" withfunction "lme" and "lmList"
>
>
>Dear all,
>
>I've got a problem in including square variables in lme and lmlist 
>functions. I've tried to work on Oxboys data of Pinheiro and 
>Bates'book, which consist of the heights of 26 boys, each mesured on 
>nine different occasions :
>
> > Oxboys
>Grouped Data: height ~ age | Subject
>    Subject     age height Occasion
>1         1 -1.0000 140.50        1
>2         1 -0.7479 143.40        2
>3         1 -0.4630 144.80        3
>4         1 -0.1643 147.10        4
>5         1 -0.0027 147.70        5
>...
>
>A quadratic model in "age" would be fit with lmList
>(height~age+age^2,Oxboys).
>
>We obtain:
> 
>> fm2Oxboys.lis<-lmList(height~age+age^2,Oxboys)
>> fm2Oxboys.lis
>Call:
>  Model: height ~ age + age^2 | Subject 
>   Data: Oxboys 
>
>Coefficients:
>   (Intercept)      age
>10    130.2616 3.722915
>26    137.9927 5.588783
>25    139.2105 4.024081
>9     138.1369 6.009057
>2     142.8584 5.440176
>...
>19    164.5761 9.065620
>4     165.0724 9.360561
>
>Degrees of freedom: 234 total; 182 residual
>Residual standard error: 0.6598878
>
>They are not coefficients associated with the covariate "age^2" ! 
>However, the model called is " Height~age+age^2 | Subject " .
>
>I would be grateful if anyone could help me.
>
>Cordially,
>
>Martin Ludovic.


Respecify your model formula as:

fm2Oxboys.lis<-lmList(height ~ age + I(age^2),Oxboys)

Note the use of I() around the "age^2", which enables R to interpret
the transformation of age squared properly.

See:

?formula and ?I

Hope that helps.

Marc Schwartz



From dieter.menne at menne-biomed.de  Wed May  7 15:45:31 2003
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Wed, 7 May 2003 15:45:31 +0200
Subject: [R] simint or TukeyHSD for lme?
Message-ID: <JLEPLGAANFCEAEDCAGJNAEANCFAA.dieter.menne@menne-biomed.de>

simint and TukeyHSD work for aov objects.

Can someone point me to similar functions for lme objects?


Dieter Menne



From Fabrizio.DeAmicis at git.generali.ch  Wed May  7 16:33:29 2003
From: Fabrizio.DeAmicis at git.generali.ch (De Amicis Fabrizio (G.I.T.))
Date: Wed, 7 May 2003 16:33:29 +0200 
Subject: [R] levels 
Message-ID: <6C9A2D9477234140A56E9D1B073B28E901DB62@gitmanex01.git.generali.ch>


Hello,

Thanks to all for the previus answer. I want to be more detailed:

I have a dataset called gm20011231 with 1304 observations (or records). 

I want to create a subset with the followin command

j2<-gm20011231[1:10,"V4"]

the levels of "V4"  is 1304 and the and the length(j2) is 10. 

Do you know how to obtain a j2 with level 10?

Thank you
Fabrizio



---------------------------------------------------------------
Fabrizio De Amicis

IT Department
Generali Information Technologies - (GIT)

Centro Galleria 2,
Via Cantonale
CH - 6928 Manno - Switzerland
Tel  +41 91 806 6220
Fax +41 91 806 6298
E-mail: fabrizio.deamicis at git.generali.ch  




************************************************************************
The information in this email is confidential and may be legally... {{dropped}}



From mt at michaelltaylor.com  Wed May  7 17:01:03 2003
From: mt at michaelltaylor.com (michaell taylor)
Date: Wed, 07 May 2003 15:01:03 -0000
Subject: [R] building an expression
Message-ID: <1052319654.24166.44.camel@xeon>

Listers,

I am still attempting to apply regression results from one dataframe to
another.  A significant problem in this process is that the new
dataframe is quite large and has a complex missing data structure which
differs from the 'in-sample' data.frame.  Moreover, the equation
represents a time series simulation structure demanding that the
equation be applied iterative year by year.

I've seen various posts in the past about "tricks" to apply predict() to
new dataframe with a different missing data structure.  Many of these
require creating missing value indices from the data frame to be
predicting in.  In this particular case, the data so large as to make
this a undesirable route (16 x (53*14*5000)) when iterating over the 10
years of forecast.

I've toyed with constructing the equation from the model object.  This
route seemingly has the advantage of being more efficient when applied
to specific years of the data.frame and does nto require na.action
object creation.

I am close, but not quite there.  I am left with the eq object:
> eq
[1] "0.0188900087591286"         "d1$b * -0.0192141899003632"
[3] "d1$c * 0.158235007749465"  

which needs converting into a single eval() 'able.  seems like some sort
of do.call(expression, eq) sort of construction is the way to go, but
clearly I am not getting the syntax correct.

Any help in building the expression from eq would be appreciated.  More
generally, any suggestions on applying a model object to a new and very
large dataframe would be appreciated.


# simplified example

> d1 <- data.frame(a=rnorm(20),b=rnorm(20),c=rnorm(20))
> moda <- lm(d1$a~d1$b+d1$c)
> moda
Call:
lm(formula = d1$a ~ d1$b + d1$c)

Coefficients:
(Intercept)         d1$b         d1$c  
    0.01889     -0.01921      0.15824  
> 
> Vl <- labels(moda$coefficients)
> Vn <- as.vector(moda$coefficients)
> eq <- Vn[1]
> 
> for (n in 2:length(Vn)){ eq <- c(eq,paste(Vl[n],'*',Vn[n]))}
> eq
[1] "0.0188900087591286"         "d1$b * -0.0192141899003632"
[3] "d1$c * 0.158235007749465"  
>



From carlos.ortega at minorplanet.com  Wed May  7 17:02:35 2003
From: carlos.ortega at minorplanet.com (Carlos Ortega)
Date: Wed, 7 May 2003 17:02:35 +0200
Subject: [R] FW: Sum by categorical variable
In-Reply-To: <6C9A2D9477234140A56E9D1B073B28E901DB5D@gitmanex01.git.generali.ch>
Message-ID: <013801c314a9$b1827010$2d6ea8c0@MinorplanetDev>

Hello,

Because j2 is interpreted as a factor.
To get your vector of just 10 elements use as.vector(j2).

Regards,
Carlos.


-----Mensaje original-----
De: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] En nombre de De Amicis
Fabrizio (G.I.T.)
Enviado el: martes, 06 de mayo de 2003 16:54
Para: 'r-help at lists.R-project.org'
Asunto: [R] FW: Sum by categorical variable



Another easy(/stupid) question:

with the following command
 j2<-xf1[1:10,"V4"]
I have 

> j2
 [1] CHROMOLI             LINEAGERMAI          RINALDI
GIUNTIMA
AUTOSTELLA          
 [6] CAIZZONE             CENTRO B PEL E C SNC CONSORZI             MAN
NORD
PDM                 
1304 Levels:   MACHIAVELLI Snc  MENARINI MANUFACTURERS LOGISTICS
SERVICES
... ZUCCHERIFICIO DEL MOLISE

  
Why j2 has 1304 Levels (I know that xf has 1304 rows)? How can I obtain
a vector of 10 elements?

Thank you 


>  
> 
> ---------------------------------------------------------------
> Fabrizio De Amicis
> 
> IT Department
> Generali Information Technologies - (GIT)
> 
> Centro Galleria 2,
> Via Cantonale
> CH - 6928 Manno - Switzerland
> Tel  +41 91 806 6220
> Fax +41 91 806 6298
> E-mail: fabrizio.deamicis at git.generali.ch
> 
> 
> 
> 
************************************************************************
The information in this email is confidential and may be legally... {{dropped}}



From paulda at BATTELLE.ORG  Wed May  7 17:10:42 2003
From: paulda at BATTELLE.ORG (Paul, David  A)
Date: Wed, 07 May 2003 11:10:42 -0400
Subject: [R] Plot labeling question
Message-ID: <940250A9EB37A24CBE28D858EF077749136D2D@ws-bco-mse3.milky-way.battelle.org>

I have an older Splus script that generated some 
regression graphics for me.  In it, I used the commands

key(10,800,text="<blah1>",border=0)
key(10,750,text="<blah2>", border=0, background = 9)
text(locator(1),"95% Confidence Limits")
locator(n=2,type="l")
text(locator(1),"Model for Group 1")
locator(n=2,type="l")

There is no "key" function available in R; is there an 
equivalent that I can use?


Much thanks in advance,

 David Paul



From ripley at stats.ox.ac.uk  Wed May  7 17:17:53 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 7 May 2003 16:17:53 +0100 (BST)
Subject: [R] building an expression
In-Reply-To: <1052319654.24166.44.camel@xeon>
Message-ID: <Pine.LNX.4.44.0305071614241.5546-100000@gannet.stats>

On 7 May 2003, michaell taylor wrote:

[...]

> I am close, but not quite there.  I am left with the eq object:
> > eq
> [1] "0.0188900087591286"         "d1$b * -0.0192141899003632"
> [3] "d1$c * 0.158235007749465"  
> 
> which needs converting into a single eval() 'able.  seems like some sort
> of do.call(expression, eq) sort of construction is the way to go, but
> clearly I am not getting the syntax correct.

parse(text=paste(eq, collapse="+"))

would give you the expression 

0.0188900087591286 + d1$b * -0.0192141899003632 + d1$c * 0.158235007749465

which appears to be what you want (although you did not say addition was
involved: you also seem to be assuming a linear model in [...]).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From marion.cordie at gazdefrance.com  Wed May  7 18:13:28 2003
From: marion.cordie at gazdefrance.com (Marion CORDIE)
Date: Wed, 7 May 2003 17:13:28 +0100
Subject: [R] proc arima
Message-ID: <OFFCE467D4.12E245B3-ON41256D1F.0058DC93@notes.edfgdf.fr>



I'd like to know if there is a way in the proc arima of the ts package to
calculate the p-values of the parameters estimates if it used with the xreg
option.
Thank you for your answer.

Regards,

Marion Cordi?



From ripley at stats.ox.ac.uk  Wed May  7 17:25:25 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 7 May 2003 16:25:25 +0100 (BST)
Subject: [R] Re: proc arima
In-Reply-To: <OFFCE467D4.12E245B3-ON41256D1F.0058DC93@notes.edfgdf.fr>
Message-ID: <Pine.LNX.4.44.0305071621400.5595-100000@gannet.stats>

On Wed, 7 May 2003, Marion CORDIE wrote:

> I'd like to know if there is a way in the proc arima of the ts package to
> calculate the p-values of the parameters estimates if it used with the xreg
> option.

You would have to find the appropriate distribution theory first!  For
approximate normal-based theory the object does contain information to
find standard errors (as printed by print.Arima), and you could copy that
calculation, take ratios and refer to standard normal tables (via pnorm).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From anna at ptolemy.arc.nasa.gov  Wed May  7 17:25:08 2003
From: anna at ptolemy.arc.nasa.gov (Anna  H. Pryor)
Date: Wed, 7 May 2003 08:25:08 -0700
Subject: [R] plot vertical labels along x axis
Message-ID: <200305070825.08169.anna@ptolemy.arc.nasa.gov>


I know how to print my own labels along the x axis:

plot(1:10,xlab = "My label", axes = FALSE)

axis(1,at=seq(1,10,by=2),labels=c("first","second","third","fourth","fifth"))


Is there a way to make the labels print vertically along the axis rather than 
horizontally?  (I'm not sure if this is even going to look all right, but I 
want to check it out if it is possible.)

Anna



From ligges at statistik.uni-dortmund.de  Wed May  7 17:38:20 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 07 May 2003 17:38:20 +0200
Subject: [R] levels
In-Reply-To: <6C9A2D9477234140A56E9D1B073B28E901DB62@gitmanex01.git.generali.ch>
References: <6C9A2D9477234140A56E9D1B073B28E901DB62@gitmanex01.git.generali.ch>
Message-ID: <3EB9286C.5090806@statistik.uni-dortmund.de>

De Amicis Fabrizio (G.I.T.) wrote:
> Hello,
> 
> Thanks to all for the previus answer. I want to be more detailed:
> 
> I have a dataset called gm20011231 with 1304 observations (or records). 
> 
> I want to create a subset with the followin command
> 
> j2<-gm20011231[1:10,"V4"]
> 
> the levels of "V4"  is 1304 and the and the length(j2) is 10. 
> 
> Do you know how to obtain a j2 with level 10?
> 
> Thank you
> Fabrizio


I don't know why you are going to do that, but you can change the levels 
  with level(), see ?level for details.

Uwe Ligges



From ligges at statistik.uni-dortmund.de  Wed May  7 17:39:13 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 07 May 2003 17:39:13 +0200
Subject: [R] plot vertical labels along x axis
In-Reply-To: <200305070825.08169.anna@ptolemy.arc.nasa.gov>
References: <200305070825.08169.anna@ptolemy.arc.nasa.gov>
Message-ID: <3EB928A1.5050408@statistik.uni-dortmund.de>

Anna H. Pryor wrote:
> I know how to print my own labels along the x axis:
> 
> plot(1:10,xlab = "My label", axes = FALSE)
> 
> axis(1,at=seq(1,10,by=2),labels=c("first","second","third","fourth","fifth"))
> 
> 
> Is there a way to make the labels print vertically along the axis rather than 
> horizontally?  (I'm not sure if this is even going to look all right, but I 
> want to check it out if it is possible.)
> 
> Anna

See ?par, in particular its argument "las".

Uwe Ligges



From ligges at statistik.uni-dortmund.de  Wed May  7 17:39:57 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 07 May 2003 17:39:57 +0200
Subject: [R] Plot labeling question
In-Reply-To: <940250A9EB37A24CBE28D858EF077749136D2D@ws-bco-mse3.milky-way.battelle.org>
References: <940250A9EB37A24CBE28D858EF077749136D2D@ws-bco-mse3.milky-way.battelle.org>
Message-ID: <3EB928CD.8050807@statistik.uni-dortmund.de>

Paul, David A wrote:
> I have an older Splus script that generated some 
> regression graphics for me.  In it, I used the commands
> 
> key(10,800,text="<blah1>",border=0)
> key(10,750,text="<blah2>", border=0, background = 9)
> text(locator(1),"95% Confidence Limits")
> locator(n=2,type="l")
> text(locator(1),"Model for Group 1")
> locator(n=2,type="l")
> 
> There is no "key" function available in R; is there an 
> equivalent that I can use?

See ?legend

Uwe Ligges



From paulda at BATTELLE.ORG  Wed May  7 17:49:03 2003
From: paulda at BATTELLE.ORG (Paul, David  A)
Date: Wed, 07 May 2003 11:49:03 -0400
Subject: [R] Plot labeling question
Message-ID: <940250A9EB37A24CBE28D858EF077749136D2F@ws-bco-mse3.milky-way.battelle.org>

Thanks to:  Corey Moffet, Iyue Sung, and Uwe Ligges
for pointing out the legend( ) function.

With appreciation,
  david paul

-----Original Message-----
From: Paul, David A 
Sent: Wednesday, May 07, 2003 11:11 AM
To: 'r-help at stat.math.ethz.ch'
Subject: [R] Plot labeling question


I have an older Splus script that generated some 
regression graphics for me.  In it, I used the commands

key(10,800,text="<blah1>",border=0)
key(10,750,text="<blah2>", border=0, background = 9) text(locator(1),"95%
Confidence Limits")
locator(n=2,type="l")
text(locator(1),"Model for Group 1")
locator(n=2,type="l")

There is no "key" function available in R; is there an 
equivalent that I can use?


Much thanks in advance,

 David Paul

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From mschwartz at medanalytics.com  Wed May  7 17:56:17 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 7 May 2003 10:56:17 -0500
Subject: [R] plot vertical labels along x axis
In-Reply-To: <200305070825.08169.anna@ptolemy.arc.nasa.gov>
Message-ID: <009e01c314b1$33c5e500$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Anna H. Pryor
>Sent: Wednesday, May 07, 2003 10:25 AM
>To: R-help mailing list
>Subject: [R] plot vertical labels along x axis
>
>
>
>I know how to print my own labels along the x axis:
>
>plot(1:10,xlab = "My label", axes = FALSE)
>
>axis(1,at=seq(1,10,by=2),labels=c("first","second","third","fou
>rth","fifth"))
>
>
>Is there a way to make the labels print vertically along the 
>axis rather than 
>horizontally?  (I'm not sure if this is even going to look all 
>right, but I 
>want to check it out if it is possible.)
>
>Anna


Try this sequence:

plot(1:10,xlab = "My label", axes = FALSE)
axis(1, at=seq(1,10,by=2),
labels=c("first","second","third","fourth","fifth"), las = 2)


See ?par for more information on the use of the 'las = 2' argument,
which sets the labels to be printed perpendicular to the axis.

Hope that helps,

Marc Schwartz



From alexander.schnee at tuebingen.mpg.de  Wed May  7 17:59:23 2003
From: alexander.schnee at tuebingen.mpg.de (alexander.schnee@tuebingen.mpg.de)
Date: Wed, 07 May 2003 17:59:23 +0200
Subject: [R] element of
Message-ID: <3EB92D5B.3030905@tuebingen.mpg.de>

Dear all,

is there any funktion in R which i can use to check if a single value is element of a matrix or data.frame so that it returns me logical values like TRUE/FALSE.

Thanks in advance for your help!



From ligges at statistik.uni-dortmund.de  Wed May  7 18:19:31 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 07 May 2003 18:19:31 +0200
Subject: [R] element of
In-Reply-To: <3EB92D5B.3030905@tuebingen.mpg.de>
References: <3EB92D5B.3030905@tuebingen.mpg.de>
Message-ID: <3EB93213.2050401@statistik.uni-dortmund.de>

alexander.schnee at tuebingen.mpg.de wrote:
> Dear all,
> 
> is there any funktion in R which i can use to check if a single value is 
> element of a matrix or data.frame so that it returns me logical values 
> like TRUE/FALSE.
> 
> Thanks in advance for your help!

See help("%in%")

Uwe Ligges



From laurent.faisnel at ariase.com  Wed May  7 18:20:43 2003
From: laurent.faisnel at ariase.com (Laurent Faisnel)
Date: Wed, 07 May 2003 18:20:43 +0200
Subject: [R] how to order a dataframe ?
Message-ID: <3EB9325B.4010906@ariase.com>

Hi,
I've got a problem which seemed simple to me at first view, but which I 
haven't managed to solve yet. I have a dataframe, or a matrix, and I 
would like to order it along with one of the variables/columns. I tried 
to use order() but it remained quite unclear to me. How should I proceed ?
Thanks in advance (I guess that's not very difficult a question for most 
of you)

Laurent



From ripley at stats.ox.ac.uk  Wed May  7 18:23:03 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 7 May 2003 17:23:03 +0100 (BST)
Subject: [R] element of
In-Reply-To: <3EB92D5B.3030905@tuebingen.mpg.de>
Message-ID: <Pine.LNX.4.44.0305071717410.5816-100000@gannet.stats>

Do you mean *an* element or *this* element of a matrix?

is.element or %in% for the first
== for the second.

It doesn't really make sense for a data frame, where columns can be of 
arbitrary classes.

I am not sure if I have unscrambled your English correctly: if not a 
simple example of what you want to do would help.  (We don't need examples 
of logical values, though.)

On Wed, 7 May 2003 alexander.schnee at tuebingen.mpg.de wrote:

> is there any funktion in R which i can use to check if a single value is
> element of a matrix or data.frame so that it returns me logical values
> like TRUE/FALSE.

(or possibly NA if there are NAs in the matrix?)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mschwartz at medanalytics.com  Wed May  7 18:24:02 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 7 May 2003 11:24:02 -0500
Subject: [R] element of
In-Reply-To: <3EB92D5B.3030905@tuebingen.mpg.de>
Message-ID: <00a101c314b5$138f7270$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
>alexander.schnee at tuebingen.mpg.de
>Sent: Wednesday, May 07, 2003 10:59 AM
>To: r-help at stat.math.ethz.ch
>Subject: [R] element of
>
>
>Dear all,
>
>is there any funktion in R which i can use to check if a 
>single value is element of a matrix or data.frame so that it 
>returns me logical values like TRUE/FALSE.
>
>Thanks in advance for your help!


See help("%in%") which will give you a TRUE/FALSE value.

You can also use which() to get the actual position of the element in
the data structure.  See help("which") for more information on that
function.

HTH,

Marc Schwartz



From p.pagel at gsf.de  Wed May  7 18:26:41 2003
From: p.pagel at gsf.de (Philipp Pagel)
Date: Wed, 7 May 2003 18:26:41 +0200
Subject: [R] element of
In-Reply-To: <3EB92D5B.3030905@tuebingen.mpg.de>
References: <3EB92D5B.3030905@tuebingen.mpg.de>
Message-ID: <20030507162641.GA4437@porcupine.gsf.de>

On Wed, May 07, 2003 at 05:59:23PM +0200, alexander.schnee at tuebingen.mpg.de wrote:

> is there any funktion in R which i can use to check if a single value is 
> element of a matrix or data.frame so that it returns me logical values like 
> TRUE/FALSE.

is.element(foo, mymatrix) 

which is the same as 

foo %in% mymatrix


cu
	Philipp
	
-- 
Dr. Philipp Pagel                                Tel.  +49-89-3187-3675
Institute for Bioinformatics / MIPS              Fax.  +49-89-3187-3585
GSF - National Research Center for Environment and Health
Ingolstaedter Landstrasse 1
85764 Neuherberg
Germany



From spencer.graves at pdf.com  Wed May  7 18:44:45 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 07 May 2003 09:44:45 -0700
Subject: [R] plot vertical labels along x axis
References: <009e01c314b1$33c5e500$0201a8c0@MARC>
Message-ID: <3EB937FD.8010500@pdf.com>

If you want an angle other than vertical, the problem is harder.  The 
argument "srt" works with "axis" in S-Plus 6.1 but not in R.

Consider the following:

plot(1:2)
text(1:2, rep(2, 2), c("adsf", "qwer"), srt=45)

If all you want is vertical, then you don't want this.  However, this 
provides another range of options.

Spencer Graves

Marc Schwartz wrote:
>>-----Original Message-----
>>From: r-help-bounces at stat.math.ethz.ch 
>>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Anna H. Pryor
>>Sent: Wednesday, May 07, 2003 10:25 AM
>>To: R-help mailing list
>>Subject: [R] plot vertical labels along x axis
>>
>>
>>
>>I know how to print my own labels along the x axis:
>>
>>plot(1:10,xlab = "My label", axes = FALSE)
>>
>>axis(1,at=seq(1,10,by=2),labels=c("first","second","third","fou
>>rth","fifth"))
>>
>>
>>Is there a way to make the labels print vertically along the 
>>axis rather than 
>>horizontally?  (I'm not sure if this is even going to look all 
>>right, but I 
>>want to check it out if it is possible.)
>>
>>Anna
> 
> 
> 
> Try this sequence:
> 
> plot(1:10,xlab = "My label", axes = FALSE)
> axis(1, at=seq(1,10,by=2),
> labels=c("first","second","third","fourth","fifth"), las = 2)
> 
> 
> See ?par for more information on the use of the 'las = 2' argument,
> which sets the labels to be printed perpendicular to the axis.
> 
> Hope that helps,
> 
> Marc Schwartz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From chumpmonkey at hushmail.com  Wed May  7 18:46:50 2003
From: chumpmonkey at hushmail.com (chumpmonkey@hushmail.com)
Date: Wed,  7 May 2003 09:46:50 -0700
Subject: [R] Extracting the longest entry
Message-ID: <200305071646.h47Gkocj068526@mailserver2.hushmail.com>


I have a matrix with NAs and want to extract the longest column.

> is.matrix(foo)
[1] TRUE
> dim(foo)
[1] 2000   75
> GetLength <- function(x) {length(na.omit(x))}
> junk <- apply(foo, 2, GetLength)
> junk
 [1] 1004  512  432  523  691  396  607  838
 [9]  730  389  388  445  609  333  637 1024
[17] 1163  823  718  466  799  459  701  833
[25]  456  549  376  728  539  384  348  708
[33]  516  439  667 1115  711 1105  469  864
[41]  748  788  394  426  338  532  742  479
[49]  570  503  784  302  746  507  532  702
[57]  562  693  592  850  491  789  362  487
[65]  679  617  513  752  690  597  992  496
[73]  688  579  712
> 

Now I want to extract the greatest entry (i.e., 17). This is where I'm
stuck and feel foolish. This is clearly trivial. Help!

CM







Free, ultra-private instant messaging with Hush Messenger



From spencer.graves at pdf.com  Wed May  7 18:47:55 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 07 May 2003 09:47:55 -0700
Subject: [R] how to order a dataframe ?
References: <3EB9325B.4010906@ariase.com>
Message-ID: <3EB938BB.6050701@pdf.com>

I've used 'order' successfully.  Consider the following:

df1 <- data.frame(x=rnorm(9))
df1
df1[order(df1$x),, drop=F]

If you provide an example of what did not work, someone might be able to 
help more.

spencer graves

Laurent Faisnel wrote:
> Hi,
> I've got a problem which seemed simple to me at first view, but which I 
> haven't managed to solve yet. I have a dataframe, or a matrix, and I 
> would like to order it along with one of the variables/columns. I tried 
> to use order() but it remained quite unclear to me. How should I proceed ?
> Thanks in advance (I guess that's not very difficult a question for most 
> of you)
> 
> Laurent
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From murdoch at stats.uwo.ca  Wed May  7 18:56:41 2003
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 07 May 2003 12:56:41 -0400
Subject: [R] how to order a dataframe ?
In-Reply-To: <3EB9325B.4010906@ariase.com>
References: <3EB9325B.4010906@ariase.com>
Message-ID: <gieibvkfarihujm7hfvefmqd15ic1badv8@4ax.com>

On Wed, 07 May 2003 18:20:43 +0200, you wrote in message
<3EB9325B.4010906 at ariase.com>:

>Hi,
>I've got a problem which seemed simple to me at first view, but which I 
>haven't managed to solve yet. I have a dataframe, or a matrix, and I 
>would like to order it along with one of the variables/columns. I tried 
>to use order() but it remained quite unclear to me. How should I proceed ?
>Thanks in advance (I guess that's not very difficult a question for most 
>of you)

Try something like this:

x <- matrix(rnorm(100),10,10)
s <- x[order(x[,1]),]

Now s is a copy of x sorted on the first column.

Duncan Murdoch



From phgrosjean at sciviews.org  Wed May  7 19:00:52 2003
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Wed, 7 May 2003 19:00:52 +0200
Subject: [R] how to order a dataframe ?
In-Reply-To: <3EB9325B.4010906@ariase.com>
Message-ID: <MABBLJDICACNFOLGIHJOEEPODGAA.phgrosjean@sciviews.org>

mydf[order(mydf$colname), ]

Best,

Philippe Grosjean

...........]<(({?<...............<?}))><...............................
 ) ) ) ) )
( ( ( ( (       Dr. Philippe Grosjean
 ) ) ) ) )
( ( ( ( (       LOV, UMR 7093
 ) ) ) ) )      Station Zoologique
( ( ( ( (       Observatoire Oceanologique
 ) ) ) ) )      BP 28   
( ( ( ( (       06234 Villefranche sur mer cedex
 ) ) ) ) )      France
( ( ( ( (
 ) ) ) ) )      tel: +33.4.93.76.38.18, fax: +33.4.93.76.38.34
( ( ( ( ( 
 ) ) ) ) )      e-mail: phgrosjean at sciviews.org
( ( ( ( (       SciViews project coordinator (http://www.sciviews.org)
 ) ) ) ) )
.......................................................................

 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Laurent Faisnel
Sent: mercredi 7 mai 2003 6:21
To: r-help at stat.math.ethz.ch
Subject: [R] how to order a dataframe ?


Hi,
I've got a problem which seemed simple to me at first view, but which I 
haven't managed to solve yet. I have a dataframe, or a matrix, and I 
would like to order it along with one of the variables/columns. I tried 
to use order() but it remained quite unclear to me. How should I proceed ?
Thanks in advance (I guess that's not very difficult a question for most 
of you)

Laurent

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ligges at statistik.uni-dortmund.de  Wed May  7 19:21:36 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 07 May 2003 19:21:36 +0200
Subject: [R] Extracting the longest entry
In-Reply-To: <200305071646.h47Gkocj068526@mailserver2.hushmail.com>
References: <200305071646.h47Gkocj068526@mailserver2.hushmail.com>
Message-ID: <3EB940A0.9040208@statistik.uni-dortmund.de>

chumpmonkey at hushmail.com wrote:
> I have a matrix with NAs and want to extract the longest column.
> 
> 
>>is.matrix(foo)
> 
> [1] TRUE
> 
>>dim(foo)
> 
> [1] 2000   75
> 
>>GetLength <- function(x) {length(na.omit(x))}
>>junk <- apply(foo, 2, GetLength)
>>junk
> 
>  [1] 1004  512  432  523  691  396  607  838
>  [9]  730  389  388  445  609  333  637 1024
> [17] 1163  823  718  466  799  459  701  833
> [25]  456  549  376  728  539  384  348  708
> [33]  516  439  667 1115  711 1105  469  864
> [41]  748  788  394  426  338  532  742  479
> [49]  570  503  784  302  746  507  532  702
> [57]  562  693  592  850  491  789  362  487
> [65]  679  617  513  752  690  597  992  496
> [73]  688  579  712
> 
> 
> Now I want to extract the greatest entry (i.e., 17). This is where I'm
> stuck and feel foolish. This is clearly trivial. Help!
> 
> CM

which.max(junk)

Uwe Ligges



From upton at mitre.org  Wed May  7 19:26:25 2003
From: upton at mitre.org (Stephen C. Upton)
Date: Wed, 07 May 2003 13:26:25 -0400
Subject: [R] Extracting the longest entry
References: <200305071646.h47Gkocj068526@mailserver2.hushmail.com>
Message-ID: <3EB941C0.4BC86D30@mitre.org>

See max  or which.max

HTH
steve

chumpmonkey at hushmail.com wrote:

> I have a matrix with NAs and want to extract the longest column.
>
> > is.matrix(foo)
> [1] TRUE
> > dim(foo)
> [1] 2000   75
> > GetLength <- function(x) {length(na.omit(x))}
> > junk <- apply(foo, 2, GetLength)
> > junk
>  [1] 1004  512  432  523  691  396  607  838
>  [9]  730  389  388  445  609  333  637 1024
> [17] 1163  823  718  466  799  459  701  833
> [25]  456  549  376  728  539  384  348  708
> [33]  516  439  667 1115  711 1105  469  864
> [41]  748  788  394  426  338  532  742  479
> [49]  570  503  784  302  746  507  532  702
> [57]  562  693  592  850  491  789  362  487
> [65]  679  617  513  752  690  597  992  496
> [73]  688  579  712
> >
>
> Now I want to extract the greatest entry (i.e., 17). This is where I'm
> stuck and feel foolish. This is clearly trivial. Help!
>
> CM
>
> Free, ultra-private instant messaging with Hush Messenger
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From mschwartz at medanalytics.com  Wed May  7 19:32:51 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 7 May 2003 12:32:51 -0500
Subject: [R] plot vertical labels along x axis
In-Reply-To: <3EB937FD.8010500@pdf.com>
Message-ID: <00a601c314be$b0282ab0$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Spencer Graves
>Sent: Wednesday, May 07, 2003 11:45 AM
>To: mschwartz at medanalytics.com
>Cc: 'R-help mailing list'
>Subject: Re: [R] plot vertical labels along x axis
>
>
>If you want an angle other than vertical, the problem is harder.  The

>argument "srt" works with "axis" in S-Plus 6.1 but not in R.
>
>Consider the following:
>
>plot(1:2)
>text(1:2, rep(2, 2), c("adsf", "qwer"), srt=45)
>
>If all you want is vertical, then you don't want this.  However, this

>provides another range of options.
>
>Spencer Graves

>SNIPPED


Actually, there is a trick for using text() with 'srt' to achieve 45
degree rotated x-axis labels.  This involves using par("xpd") and
par("usr"). 

To wit, using Anna's initial example:

plot(1:10, xlab = "My label", axes = FALSE)
axis(1, at=seq(1, 10, by=2), labels = FALSE)
text(seq(1, 10, by=2), par("usr")[3] - 0.2, labels = c("first",
"second", "third", "fourth", "fifth"), srt = 45, pos = 1, xpd = TRUE)

By adjusting the negative offset of 'par("usr")[3] - 0.2', you can
move the labels vertically to account for the length of the text
components. A larger value moves the text down further below
par("usr")[3], which is the value of y at the intersection of the
x-axis.

HTH,

Marc Schwartz



From vograno at arbitrade.com  Wed May  7 19:47:00 2003
From: vograno at arbitrade.com (Vadim Ogranovich)
Date: Wed, 7 May 2003 12:47:00 -0500 
Subject: [R] assessing goodness of variance prediction
Message-ID: <AFD78192EC49D311BFAE00902798AB8F23DDBB@jupiter.arbitrade.com>

Dear R-Helpers,

I am looking for ways to assess quality of a predictor of variance of a
random variable. Here a two related, but yet distinct, setups.

1. I observe y_t, t=1,...,T which is normally distributed with unknown
variance v_t (note that the variance is time-dependent). I have two
"predictors" for v_t, dubbed v1_t and v2_t, and I want to tell which
predictor is better. Here better is to be defined, but intuitively it is
thought to be analogous to R^2 of an ordinary regression.
I was thinking along the lines of fitting a GLM of the form log(abs(y)) ~
log(v1) with some link function, but couldn't figure out which link function
would be appropriate.


2. I observe y_t, t=1,...,T which is multivariate normal iid with unknown
covariance matrix C (which is constant here). I have two estimations of C,
dubbed C1 and C2, and I want to tell which estimation is better. Here again
better is to be defined.
I could of course compute the sample covariance matrix of y_t and then the
L2 norm of the difference (C1 - sampleC), but I don't know if this is a
meaningful measure of a distance between two covariance matrices.


Any lead will be highly appreciated.

Thanks,
Vadim

-------------------------------------------------- 
DISCLAIMER\ This e-mail, and any attachments thereto, is intende... {{dropped}}



From raf1729 at hotmail.com  Wed May  7 23:38:14 2003
From: raf1729 at hotmail.com (R A F)
Date: Wed, 07 May 2003 21:38:14 +0000
Subject: [R] Sink for a subdirectory
Message-ID: <Law11-F4fyY0QUUBPcZ00004f16@hotmail.com>

Hi, how do I sink output to a subdirectory under which R is running?

For example, suppose R is running in ~me and I would like to sink output to
~me/Subdir/filename.

The obvious sink( "Subdir/filename" ) does not seem to work.

Thanks very much.



From ripley at stats.ox.ac.uk  Wed May  7 23:47:26 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 7 May 2003 22:47:26 +0100 (BST)
Subject: [R] Sink for a subdirectory
In-Reply-To: <Law11-F4fyY0QUUBPcZ00004f16@hotmail.com>
Message-ID: <Pine.LNX.4.44.0305072244580.17323-100000@gannet.stats>

On Wed, 7 May 2003, R A F wrote:

> Hi, how do I sink output to a subdirectory under which R is running?
> 
> For example, suppose R is running in ~me and I would like to sink output to
> ~me/Subdir/filename.
> 
> The obvious sink( "Subdir/filename" ) does not seem to work.

It works for me, provided Subdir exists. What does `does not seem to work' 
mean, precisely?

There's nothing special about sink(): it can take any valid filename or
any writeable connection.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.connolly at hortresearch.co.nz  Thu May  8 00:05:07 2003
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Thu, 8 May 2003 10:05:07 +1200
Subject: [R] Tick labels on y axis in lattice plots
In-Reply-To: <20030507002505.GN13579@hortresearch.co.nz>
References: <20030507002505.GN13579@hortresearch.co.nz>
Message-ID: <20030507220507.GT13579@hortresearch.co.nz>

On Wed, 07-May-2003 at 12:25PM +1200, Patrick Connolly wrote:

|> I seem to remember this was discussed a year or two ago, but I can't
|> find it in the archives.
|> 
|> 
|> platform i686-pc-linux-gnu
|> arch     i686             
|> os       linux-gnu        
|> system   i686, linux-gnu  
|> status                    
|> major    1                
|> minor    7.0              
|> year     2003             
|> month    04               
|> day      16               
|> language R                
|> 
|> 
|> It appears to my eye that y-axis tick labels are about half a
|> millimetre lower than the tick they label -- at least when using the
|> postscript device with lattice.  For large font sizes it's
|> unnoticable, but there are times when a small pointsize is necessary
|> and I have to fudge the positioning.
|> 
|> Is that noticed by anyone else?

I've looked more closely at this phenomenon by trying a wide range of
font sizes and now conclude that the perceived problem arises because
the centring is calculated (sensibly) from the capital letters.  The
centre line of lower case letters will appear to be below the centre
line that applies to the text as a whole.

In other words, there's nothing wrong with how it works.

best

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From dmurdoch at pair.com  Thu May  8 00:08:05 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed, 07 May 2003 18:08:05 -0400
Subject: [R] Sink for a subdirectory
In-Reply-To: <Law11-F4fyY0QUUBPcZ00004f16@hotmail.com>
References: <Law11-F4fyY0QUUBPcZ00004f16@hotmail.com>
Message-ID: <vf0jbv07h8185m1i5m7ghscqkkrs1bvlvv@4ax.com>

On Wed, 07 May 2003 21:38:14 +0000, you wrote:

>Hi, how do I sink output to a subdirectory under which R is running?
>
>For example, suppose R is running in ~me and I would like to sink output to
>~me/Subdir/filename.
>
>The obvious sink( "Subdir/filename" ) does not seem to work.

It works for me.  It would be helpful if you said what goes wrong, and
what OS you're running in.

I'm guessing that Subdir doesn't exist; R won't create it.  I don't
think there's a mkdir() function in R; you'll need to create the
subdir outside of R, or use system() to do it.  For example, in
Windows,

system('command /c mkdir Subdir')

would do it.

Duncan Murdoch



From jrsatobr at yahoo.com.br  Thu May  8 00:09:30 2003
From: jrsatobr at yahoo.com.br (=?iso-8859-1?q?joao=20sato?=)
Date: Wed, 7 May 2003 19:09:30 -0300 (ART)
Subject: [R] MIXED ANOVA and Repeated Measure
Message-ID: <20030507220930.42144.qmail@web20810.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030507/a27c156d/attachment.pl

From raf1729 at hotmail.com  Thu May  8 00:09:11 2003
From: raf1729 at hotmail.com (R A F)
Date: Wed, 07 May 2003 22:09:11 +0000
Subject: [R] Sink for a subdirectory
Message-ID: <Law11-F8z93MgPPf3L900004ffa@hotmail.com>

Sorry, my fault.  I was actually in Subdir while attempting this.  Thanks 
very much.

>From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
>To: R A F <raf1729 at hotmail.com>
>CC: r-help at r-project.org
>Subject: Re: [R] Sink for a subdirectory
>Date: Wed, 7 May 2003 22:47:26 +0100 (BST)
>
>On Wed, 7 May 2003, R A F wrote:
>
> > Hi, how do I sink output to a subdirectory under which R is running?
> >
> > For example, suppose R is running in ~me and I would like to sink output 
>to
> > ~me/Subdir/filename.
> >
> > The obvious sink( "Subdir/filename" ) does not seem to work.
>
>It works for me, provided Subdir exists. What does `does not seem to work'
>mean, precisely?
>
>There's nothing special about sink(): it can take any valid filename or
>any writeable connection.



From jerome at hivnet.ubc.ca  Thu May  8 00:29:37 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Wed, 7 May 2003 15:29:37 -0700
Subject: [R] Sink for a subdirectory
In-Reply-To: <vf0jbv07h8185m1i5m7ghscqkkrs1bvlvv@4ax.com>
References: <Law11-F4fyY0QUUBPcZ00004f16@hotmail.com>
	<vf0jbv07h8185m1i5m7ghscqkkrs1bvlvv@4ax.com>
Message-ID: <200305072235.PAA03051@hivnet.ubc.ca>

On May 7, 2003 03:08 pm, Duncan Murdoch wrote:
> Content-Length: 794
> Status: R
> X-Status: N
>
> On Wed, 07 May 2003 21:38:14 +0000, you wrote:
> >Hi, how do I sink output to a subdirectory under which R is running?
> >
> >For example, suppose R is running in ~me and I would like to sink
> > output to ~me/Subdir/filename.
> >
> >The obvious sink( "Subdir/filename" ) does not seem to work.
>
> It works for me.  It would be helpful if you said what goes wrong, and
> what OS you're running in.
>
> I'm guessing that Subdir doesn't exist; R won't create it.  I don't
> think there's a mkdir() function in R; you'll need to create the
> subdir outside of R, or use system() to do it.  For example, in
> Windows,
>
> system('command /c mkdir Subdir')
>
> would do it.
>
> Duncan Murdoch
>

There is a function to change the directory in R. See ?setwd .

Jerome



From jerome at hivnet.ubc.ca  Thu May  8 00:30:40 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Wed, 7 May 2003 15:30:40 -0700
Subject: [R] MIXED ANOVA and Repeated Measure
In-Reply-To: <20030507220930.42144.qmail@web20810.mail.yahoo.com>
References: <20030507220930.42144.qmail@web20810.mail.yahoo.com>
Message-ID: <200305072236.PAA03091@hivnet.ubc.ca>

On May 7, 2003 03:09 pm, joao sato wrote:
> Hi!How could I perform a ANOVA with Mixed Effects  and Repeated Measures
> using R?Thanks!!! Best RegardsJo?o Ricardo SatoBRAZIL
>

See ?lme in package "nlme".



From spencer.graves at pdf.com  Thu May  8 00:32:00 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 07 May 2003 15:32:00 -0700
Subject: [R] Sink for a subdirectory
References: <Law11-F4fyY0QUUBPcZ00004f16@hotmail.com>
	<vf0jbv07h8185m1i5m7ghscqkkrs1bvlvv@4ax.com>
Message-ID: <3EB98960.70202@pdf.com>

Did you specify the entire path, or only the ending segment?

spencer graves

Duncan Murdoch wrote:
> On Wed, 07 May 2003 21:38:14 +0000, you wrote:
> 
> 
>>Hi, how do I sink output to a subdirectory under which R is running?
>>
>>For example, suppose R is running in ~me and I would like to sink output to
>>~me/Subdir/filename.
>>
>>The obvious sink( "Subdir/filename" ) does not seem to work.
> 
> 
> It works for me.  It would be helpful if you said what goes wrong, and
> what OS you're running in.
> 
> I'm guessing that Subdir doesn't exist; R won't create it.  I don't
> think there's a mkdir() function in R; you'll need to create the
> subdir outside of R, or use system() to do it.  For example, in
> Windows,
> 
> system('command /c mkdir Subdir')
> 
> would do it.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Richard.Rowe at jcu.edu.au  Thu May  8 00:33:38 2003
From: Richard.Rowe at jcu.edu.au (Richard Rowe)
Date: Thu, 08 May 2003 08:33:38 +1000
Subject: [R] post hoc comparison regression slopes
Message-ID: <5.0.0.25.1.20030508082714.03e03680@pop.jcu.edu.au>

Displaying considerable ignorance.

I need to do a post hoc comparison of regression slopes.

I've used

lm(response ~ factors/predictor -1)

and have a nice anova table with slopes and standard errors, and I could 
contrast the slopes with a cludged t-test (they are massively different and 
awful liberties could be taken), but is there an elegant, prebuilt method 
somewhere?

Thanks,

Richard Rowe

Richard Rowe
Senior Lecturer
Department of Zoology and Tropical Ecology, James Cook University
Townsville, Queensland 4811, Australia
fax (61)7 47 25 1570
phone (61)7 47 81 4851
e-mail: Richard.Rowe at jcu.edu.au
http://www.jcu.edu.au/school/tbiol/zoology/homepage.html



From macq at llnl.gov  Thu May  8 01:16:14 2003
From: macq at llnl.gov (Don MacQueen)
Date: Wed, 7 May 2003 16:16:14 -0700
Subject: [R] IEEE standard for rounding?
Message-ID: <p05210609badf43274080@[128.115.153.6]>

?round states "Note that for rounding off a 5, the IEEE standard is used..."

I would like to properly reference the standard. I am searching a 
IEEE website and finding it difficult discover which IEEE standard 
this is.

Could someone tell me the IEEE standard number?

Thanks
-Don
-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From mikem at salter-point.com  Thu May  8 01:47:43 2003
From: mikem at salter-point.com (Michael M. Meyer)
Date: Wed, 07 May 2003 16:47:43 -0700
Subject: [R] MIXED ANOVA and Repeated Measure 
In-Reply-To: Message from Jerome Asselin <jerome@hivnet.ubc.ca> of "Wed,
	07 May 2003 15:30:40 PDT." <200305072236.PAA03091@hivnet.ubc.ca> 
Message-ID: <200305072347.h47NlhA16749@home.salter-point.com>

IEEE 754.
Remember, Google is your friend.

Mike Meyer, Seattle WA



From mikem at salter-point.com  Thu May  8 01:48:34 2003
From: mikem at salter-point.com (Michael M. Meyer)
Date: Wed, 07 May 2003 16:48:34 -0700
Subject: [R] IEEE standard for rounding? 
In-Reply-To: Message from Don MacQueen <macq@llnl.gov> of "Wed,
	07 May 2003 16:16:14 PDT." <p05210609badf43274080@[128.115.153.6]> 
Message-ID: <200305072348.h47NmYw16763@home.salter-point.com>

IEEE 754
(sorry for incorrectly replying to a different article)

Mike Meyer, Seattle WA



From mschwartz at medanalytics.com  Thu May  8 01:56:54 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 7 May 2003 18:56:54 -0500
Subject: [R] IEEE standard for rounding?
In-Reply-To: <p05210609badf43274080@[128.115.153.6]>
Message-ID: <00c701c314f4$56b87210$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Don MacQueen
>Sent: Wednesday, May 07, 2003 6:16 PM
>To: r-help at stat.math.ethz.ch
>Subject: [R] IEEE standard for rounding?
>
>
>?round states "Note that for rounding off a 5, the IEEE 
>standard is used..."
>
>I would like to properly reference the standard. I am searching a 
>IEEE website and finding it difficult discover which IEEE standard 
>this is.
>
>Could someone tell me the IEEE standard number?
>
>Thanks
>-Don


It is IEEE 754-1985.

More information is available here:

http://grouper.ieee.org/groups/754/


HTH,

Marc Schwartz



From anoy69 at yahoo.com  Thu May  8 02:35:19 2003
From: anoy69 at yahoo.com (zhu wang)
Date: Wed, 7 May 2003 17:35:19 -0700 (PDT)
Subject: [R] All possible subset selection?
Message-ID: <20030508003519.71612.qmail@web14410.mail.yahoo.com>

Hello,

I am wondering if there is a function in R to do all
possible subset selection, e.g. using AIC/BIC. It
seems to me the function step can not do all possible
selection.

I am also want to know why the following functions
give me different results. It seems I missed some
points here.

lm <- lm(y ~., data=somedata)
AIC(lm)
extractAIC(lm)

Many thanks,

Zheng Huang



From dmurdoch at pair.com  Thu May  8 03:46:58 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed, 07 May 2003 21:46:58 -0400
Subject: [R] Sink for a subdirectory
In-Reply-To: <3EB98960.70202@pdf.com>
References: <Law11-F4fyY0QUUBPcZ00004f16@hotmail.com>
	<vf0jbv07h8185m1i5m7ghscqkkrs1bvlvv@4ax.com>
	<3EB98960.70202@pdf.com>
Message-ID: <ohdjbvgb9l61i7ql7hr3d5eb59fkv0cja0@4ax.com>

On Wed, 07 May 2003 15:32:00 -0700, you wrote:

>Did you specify the entire path, or only the ending segment?

I gave the ending segment.  R doesn't do anything surprising here.  If
your current working directory is "/blah", then  

 sink( "Subdir/filename" )

will try to write to the file "/blah/Subdir/filename".  This will fail
if "/blah/Subdir" doesn't exist.

We have setwd() to change the working directory, and getwd() to find
it, but no mkdir() to create a directory that doesn't already exist.  

Duncan Murdoch



From arc at arcriswell.com  Thu May  8 04:38:48 2003
From: arc at arcriswell.com (Andrew Criswell)
Date: Thu, 8 May 2003 09:38:48 +0700
Subject: [R] Expanding upon expand.grid()
Message-ID: <002a01c3150a$f6efe900$0ed994cb@andrewhdh0e5oe>

Hello All:

The function expand.grid() does nearly exactly what I want for
permutation tests I wish to carry out, and it does so quickly when the
number is kept small as in the example below: 

expand.grid(rep(list(c(-1, 1)), 3))

  Var1 Var2 Var3
1   -1   -1   -1
2    1   -1   -1
3   -1    1   -1
4    1    1   -1
5   -1   -1    1
6    1   -1    1
7   -1    1    1
8    1    1    1

Understandably, for a larger number--16, for example--the grid expands
to a 65,536 x 16 = 1,048,576 element array of numbers.

My question is this: is it possible to compute a grid like the one above
on a row-by-row basis?  What I would like to do is to iteratively take
one row at a time, compute its sum, store the computed sum for the row,
and replace the latest row by the next row. In that way, memory burden
and computation time would be reduced.

Thanks for your help,
ANDREW



From r.hankin at auckland.ac.nz  Thu May  8 05:07:47 2003
From: r.hankin at auckland.ac.nz (Robin Hankin)
Date: Thu, 8 May 2003 15:07:47 +1200
Subject: [R] Expanding upon expand.grid()
In-Reply-To: <002a01c3150a$f6efe900$0ed994cb@andrewhdh0e5oe>
	(arc@arcriswell.com)
References: <002a01c3150a$f6efe900$0ed994cb@andrewhdh0e5oe>
Message-ID: <200305080307.h4837lqc018689@r.hankin.sges.auckland.ac.nz>

Andrew

as.binary <- function(n){if(n==0){return(NULL)
   } else {
   return(c((n%%2),Recall(as.integer(n/2))))}}


might help.


rksh



> 
> Hello All:
> 
> The function expand.grid() does nearly exactly what I want for
> permutation tests I wish to carry out, and it does so quickly when the
> number is kept small as in the example below: 
> 
> expand.grid(rep(list(c(-1, 1)), 3))
> 
>   Var1 Var2 Var3
> 1   -1   -1   -1
> 2    1   -1   -1
> 3   -1    1   -1
> 4    1    1   -1
> 5   -1   -1    1
> 6    1   -1    1
> 7   -1    1    1
> 8    1    1    1
> 
> Understandably, for a larger number--16, for example--the grid expands
> to a 65,536 x 16 = 1,048,576 element array of numbers.
> 
> My question is this: is it possible to compute a grid like the one above
> on a row-by-row basis?  What I would like to do is to iteratively take
> one row at a time, compute its sum, store the computed sum for the row,
> and replace the latest row by the next row. In that way, memory burden
> and computation time would be reduced.
> 
> Thanks for your help,
> ANDREW
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


-- 

Robin Hankin, Lecturer,
School of Geography and Environmental Science
Tamaki Campus
Private Bag 92019 Auckland
New Zealand

r.hankin at auckland.ac.nz
tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042



From tplate at blackmesacapital.com  Thu May  8 05:57:04 2003
From: tplate at blackmesacapital.com (Tony Plate)
Date: Wed, 07 May 2003 21:57:04 -0600
Subject: [R] Expanding upon expand.grid()
In-Reply-To: <002a01c3150a$f6efe900$0ed994cb@andrewhdh0e5oe>
Message-ID: <5.2.1.1.2.20030507212902.03756aa0@mailhost.blackmesacapital.com>

If you really need speed then it might make sense to think about what the 
algorithm is computing (or consider a different language).

If what you want is a vector containing the sum of every row in the output 
of expand.grid, then you could get it more efficiently by a recursive 
algorithm that computes just those sums, e.g.,

 > f <- function(x) {if (length(x)==1) return(x[[1]]) else {r <- f(x[-1]); 
return(rep(r,length(x[[1]]))+rep(x[[1]],each=length(r)))}}
 > f(rep(list(c(-1, 1)), 4))
  [1] -4 -2 -2  0 -2  0  0  2 -2  0  0  2  0  2  2  4
 > apply(expand.grid(rep(list(c(-1, 1)), 4)), 1, sum)
  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16
-4 -2 -2  0 -2  0  0  2 -2  0  0  2  0  2  2  4
 >

And for a larger input list:
 > tt <- proc.time()[1]
 > x <- f(rep(list(c(-1, 1)), 24))
 > length(x)
[1] 16777216
 > proc.time()[1]-tt
[1] 1.84
 >

The size of the output is still exponential in the length of the input 
list, so you still can't do very long lists, but it's much more efficient 
than using expand.grid (an example 1/64 of the size takes 5 times longer):

 > tt <- proc.time()[1]
 > x <- apply(expand.grid(rep(list(c(-1, 1)), 18)), 1, sum)
 > length(x)
[1] 262144
 > proc.time()[1]-tt
[1] 9.45
 >

If you only need some statistics on the vector of sums, you might be able 
to think of a clever way of getting those.  The mean is easy :-)

To answer your direct question, yes it is possible to calculate the rows 
one at a time (in R or in any other general purpose programming 
language).  That would be like a variable-size-dial counter (in which each 
dial can have a different number of clicks).  R is probably not the best 
language for a fast implementation of such a thing.

hope this helps,

Tony Plate

At Thursday 09:38 AM 5/8/2003 +0700, Andrew Criswell wrote:
>Hello All:
>
>The function expand.grid() does nearly exactly what I want for
>permutation tests I wish to carry out, and it does so quickly when the
>number is kept small as in the example below:
>
>expand.grid(rep(list(c(-1, 1)), 3))
>
>   Var1 Var2 Var3
>1   -1   -1   -1
>2    1   -1   -1
>3   -1    1   -1
>4    1    1   -1
>5   -1   -1    1
>6    1   -1    1
>7   -1    1    1
>8    1    1    1
>
>Understandably, for a larger number--16, for example--the grid expands
>to a 65,536 x 16 = 1,048,576 element array of numbers.
>
>My question is this: is it possible to compute a grid like the one above
>on a row-by-row basis?  What I would like to do is to iteratively take
>one row at a time, compute its sum, store the computed sum for the row,
>and replace the latest row by the next row. In that way, memory burden
>and computation time would be reduced.
>
>Thanks for your help,
>ANDREW
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Thu May  8 08:45:25 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 8 May 2003 07:45:25 +0100 (BST)
Subject: [R] All possible subset selection?
In-Reply-To: <20030508003519.71612.qmail@web14410.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0305080734340.18002-100000@gannet.stats>

On Wed, 7 May 2003, zhu wang wrote:

> I am wondering if there is a function in R to do all
> possible subset selection, e.g. using AIC/BIC. It
> seems to me the function step can not do all possible
> selection.

That's right, and I know of no function.  Potentially the computational 
burden is horrendous, even of sorting out which are valid subset models.
For continuous (rather than categorical) variables, look at package leaps.

> I am also want to know why the following functions
> give me different results. It seems I missed some
> points here.
> 
> lm <- lm(y ~., data=somedata)
> AIC(lm)
> extractAIC(lm)

Please don't call the result by the name of a function!

extractAIC (as its help says) is a helper function for step/add1/drop1,
and it is designed to report Cp in some lm cases when AIC is Cp plus a
constant. It predates AIC by several years.

Remember that AIC is only defined up to an additive constant, because a 
log-likelihood is (it depends on the dominating measure used).  
extractAIC.lm and AIC.lm use different ones, and in the case that the 
scale is known, they use different maximizations too.  (AIC.lm is only 
appropriate if the scale (error variance) is unknown.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Torsten.Hothorn at rzmail.uni-erlangen.de  Thu May  8 09:07:38 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Thu, 8 May 2003 09:07:38 +0200 (CEST)
Subject: [R] multcomp and lme (followup)
Message-ID: <Pine.LNX.4.51.0305080903040.16293@artemis.imbe.med.uni-erlangen.de>


I just realized that in the call to `csimint' the argument `asympt=TRUE'
is missing since we need to compute the confidence intervals for a glm
based on the normal approximation.

Torsten

---------------------------------------------------------------------

library(multcomp)

set.seed(290875)

# a factor at three levels
group <- factor(c(rep(1,10), rep(2, 10), rep(3,10)))

# Williams contrasts
contrasts(group) <- mginv(contrMat(table(group), type="Will"))

# a binary response
z <- factor(rbinom(30, 1, 0.5))

# estimate the model
gmod <- glm( z ~ group, family=binomial(link = "logit"))

# exclude the intercept
summary(csimtest(coef(gmod)[2:3], vcov(gmod)[2:3,2:3],
                 cmatrix=diag(2), df=27, asympt=TRUE))



> Thank you very much.
>
> Peter B.


 _______________________________________________________________________
|									|
|	Dipl.-Stat. Torsten Hothorn					|
|	Institut fuer Medizininformatik, Biometrie und Epidemiologie	|
|	Waldstrasse 6, D-91054 Erlangen, Deutschland			|
|	Tel: ++49-9131-85-22707	(dienstl.)				|
|	Fax: ++49-9131-85-25740						|
|	Email: Torsten.Hothorn at rzmail.uni-erlangen.de			|
|	Web: http://www.imbe.med.uni-erlangen.de/~hothorn		|
|_______________________________________________________________________|



From wl at eimb.ru  Thu May  8 10:54:28 2003
From: wl at eimb.ru (Wladimir Eremeev)
Date: Thu, 8 May 2003 12:54:28 +0400
Subject: [R] again troubles with lattice
Message-ID: <3537.030508@eimb.ru>

Dear r-help community,

  Thank you for your previous answers!
  
  Now I have strange behaviour of the lattice library funcitons.
  They do not draw graphics in the file when called from the script.
  I created the script file, called, for example, "a.R", containing
  the following
  
library(lattice);
trellis.device(device="png",
               filename="a.png",
               color = FALSE,
               bg = "white",
               width=600,
               height=800
              );

xyplot(ac15$value~ac15$year|factor(lon),data=ac15,
       type="o",
       layout=c(1,18),
       xlab="year",
       );
dev.off();


The structure of ac15 data frame is like following
year    value    lon
1979  93.428747  0
1979  87.298608  20
1979  78.506340  40
...
1979  45.567890  340
1980  60.815289  0
1980  49.630904  20
1980  24.981362  40
...

I execute command source("a.R") it works and after its running I've
got file a.png in the working directory. But it contains only white
background field and no graphs.

If I try copy commands of the script in clipboard and paste them to
the R console the graphs appear in the file.

-- 
Best regards
Wladimir Eremeev                                     mailto:wl at eimb.ru



From JonesW at kssg.com  Thu May  8 10:44:26 2003
From: JonesW at kssg.com (Wayne Jones)
Date: Thu, 8 May 2003 09:44:26 +0100 
Subject: [R] Returning the p-value of a factor analysis
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB01EE2165@gimli.middleearth.kssg.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030508/674d4482/attachment.pl

From enzmann at kfn.uni-hannover.de  Thu May  8 10:58:29 2003
From: enzmann at kfn.uni-hannover.de (Dirk Enzmann)
Date: Thu, 08 May 2003 10:58:29 +0200
Subject: [R] Avoiding loops to spare time and memory
Message-ID: <3EBA1C34.1FE1477C@kfn.uni-hannover.de>

Is it possible to avoid the loop in the following function (or make the
function otherwise more efficient) and can someone point me to a
possible solution? (It would be great if hours could be reduced to
seconds :-).

# ---------------------------------------------
RanEigen=function(items=x,cases=y,sample=z)
{
  X=matrix(rnorm(cases*items),nrow=cases,byrow=F)
  S=crossprod(X-rep(1,cases) %*% t(colMeans(X)))

EV=eigen((1/sqrt(diag(S))*diag(items))%*%S%*%(1/sqrt(diag(S))*diag(items)),only.values=T)$values

  for (i in 2:sample)
  {
  X=matrix(rnorm(cases*items),nrow=cases,byrow=F)
  S=crossprod(X-rep(1,cases) %*% t(colMeans(X)))

EV=rbind(EV,eigen((1/sqrt(diag(S))*diag(items))%*%S%*%(1/sqrt(diag(S))*diag(items)),only.values=T)$values)

  }
  REigV=(cbind(1:items,colMeans(EV)))
  REigV[,2]=as.numeric(formatC(REigV[,2],format="f",digits=7,flag="
",width=10))
  colnames(REigV)=c(' ','Eigenvalue')
  rownames(REigV)=rep('',items)
  return(REigV)
}
# ---------------------------------------------

Thanks in advance,
Dirk


*************************************************
Dr. Dirk Enzmann
Criminological Research Institute of Lower Saxony
Luetzerodestr. 9
D-30161 Hannover
Germany

phone: +49-511-348.36.32
fax:   +49-511-348.36.10
email: ENZMANN at KFN.uni-hannover.de

http://www.kfn.de



From ripley at stats.ox.ac.uk  Thu May  8 11:11:25 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 8 May 2003 10:11:25 +0100 (BST)
Subject: [R] again troubles with lattice
In-Reply-To: <3537.030508@eimb.ru>
Message-ID: <Pine.LNX.4.44.0305081007110.18567-100000@gannet.stats>

On Thu, 8 May 2003, Wladimir Eremeev wrote:

> Dear r-help community,
> 
>   Thank you for your previous answers!
>   
>   Now I have strange behaviour of the lattice library funcitons.
>   They do not draw graphics in the file when called from the script.
>   I created the script file, called, for example, "a.R", containing
>   the following

They do when called from a script running directly.  It's calling the 
script file from source() that gives the problem.

You haven't actually asked for anything to be plotted!  xyplot returns a
plottable object, which when *printed* is plotted.  Auto-printing works at
the top level in R, but not inside source.  You need to wrap your lattice
calls in print().

[...]

> I execute command source("a.R") it works and after its running I've
> got file a.png in the working directory. But it contains only white
> background field and no graphs.
> 
> If I try copy commands of the script in clipboard and paste them to
> the R console the graphs appear in the file.

And that is `running the script'.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu May  8 11:15:10 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 8 May 2003 10:15:10 +0100 (BST)
Subject: [R] Returning the p-value of a factor analysis
In-Reply-To: <6B5A9304046AD411BD0200508BDFB6CB01EE2165@gimli.middleearth.kssg.com>
Message-ID: <Pine.LNX.4.44.0305081012160.18567-100000@gannet.stats>

On Thu, 8 May 2003, Wayne Jones wrote:

> Does anyone know how to explicitly refer to the p-value of thet test that
> the chosen number of factors is significant in a factor analysis.
> It's not in the list of values for the factanal command output yet it is
> printed out with the results.

Right, so look at the code to compute it in print.factanal and write a 
small function to extract the value you want from the object.
Something like

Pval.factanal <- function(x)
{
    p <- nrow(x$loadings); factors <- x$factors
    if(!is.na(x$n.obs) && x$dof > 0) {
        dof <- x$dof
        stat <- (x$n.obs - 1 - (2 * p + 5)/6 -
                 (2 * factors)/3) * x$criteria["objective"]
        pchisq(stat, dof, lower.tail = FALSE)
    } else NA
}

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Thu May  8 11:16:07 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Thu, 08 May 2003 09:16:07 -0000
Subject: [R] Returning the p-value of a factor analysis
In-Reply-To: <6B5A9304046AD411BD0200508BDFB6CB01EE2165@gimli.middleearth.kssg.com>
References: <6B5A9304046AD411BD0200508BDFB6CB01EE2165@gimli.middleearth.kssg.com>
Message-ID: <x23cjpx09o.fsf@biostat.ku.dk>

Wayne Jones <JonesW at kssg.com> writes:

> Hi there, 
> 
> Does anyone know how to explicitly refer to the p-value of thet test that
> the chosen number of factors is significant in a factor analysis.
> It's not in the list of values for the factanal command output yet it is
> printed out with the results.
> 
> Thanks in advance.

It's calculated when printed. This is somewhat in bad style (according
to my tastes at least), but we have that happening in a few places. So
you need to redo the computations, which can be found inside
print.factanal. In 1.7.0, this function is hidden in the mva namespace
but you can view it with get("print.factanal",environment(factanal)).


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From pfm401 at lineone.net  Thu May  8 11:15:03 2003
From: pfm401 at lineone.net (pfm401@lineone.net)
Date: Thu, 8 May 2003 10:15:03 +0100
Subject: [R] Forward Stepwise regression with stepAIC and step
Message-ID: <3E7B8AA20004EF2B@mk-cpfrontend-4.mail.uk.tiscali.com>

Dear all,

I cannot seem to get the R functions step or stepAIC to perform forward
or stepwise regression as I expect. I have enclosed the example data in
a dataframe at the end of this mail. Note rubbish is and rnorm(17) variable
which I have deliberately added to the data to test the stepwise procedure.

I have used 

wateruse.lm<-lm(waterusage~.,data=wateruse)   # Fit full model
wateruse.lm.back<-stepAIC(wateruse.lm,trace=FALSE)

in which rubbish is removed (calling wateruse.lm.back$anova gives      

Step         Df Deviance Resid. Df Resid. Dev      AIC
1           NA       NA        11   743720.8 193.6655
2 - rubbish  1 76.67448        12   743797.5 191.6673

However if I run

wateruse.lm.forward<-stepAIC(wateruse.lm,trace=FALSE,direction="forward")

wateruse.lm.forward$anova gives 

Stepwise Model Path 
Analysis of Deviance Table

Initial Model:
waterusage ~ avetemp + product + days + payroll + rubbish

Final Model:
waterusage ~ avetemp + product + days + payroll + rubbish


  Step Df Deviance Resid. Df Resid. Dev      AIC
1      NA       NA        11   743720.8 193.6655


In other words no forward procedure has been run (similar results apply
if I use direction="step")!!

What am I doing wrong?? Thanks in advance for any help.

Thanks, Paul.







> wateruse
   waterusage avetemp product days payroll    rubbish
1        3067    58.8    7107   21     129 -0.8393514
2        2828    65.2    6373   22     141 -0.8781807
3        2891    70.9    6796   22     153  1.1939278
4        2994    77.4    9208   20     166  0.2230589
5        3082    79.3   14792   25     193  1.7165612
6        3898    81.0   14564   23     189 -0.3810258
7        3502    71.9   11964   20     175 -0.1891337
8        3060    63.9   13526   23     186  1.1204482
9        3211    54.5   12656   20     190  2.6239803
10       3286    39.5   14119   20     187  0.9282131
11       3542    44.5   16691   22     195 -1.7371026
12       3125    43.6   14571   19     206 -0.1368085
13       3022    56.0   13619   22     198  1.3408773
14       2922    64.7   14575   22     192 -0.1125558
15       3950    73.0   14556   21     191  0.4668919
16       4488    78.9   18573   21     200  0.6309489
17       3295    79.4   15618   22     200  1.0918370



From ripley at stats.ox.ac.uk  Thu May  8 11:22:58 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 8 May 2003 10:22:58 +0100 (BST)
Subject: [R] Avoiding loops to spare time and memory
In-Reply-To: <3EBA1C34.1FE1477C@kfn.uni-hannover.de>
Message-ID: <Pine.LNX.4.44.0305081016550.18567-100000@gannet.stats>

Have you profiled your code (see `Writing R Extensions')?

My guess is that most of the time is being spent in eigen(); if so you 
would have to use a different approach to gain much speed.

BTW, please make more use of the space bar: your code is nigh unreadable
(and so I've not tried to read it in detail).  `Writing R Extensions' 
also shows you how to format code well.

On Thu, 8 May 2003, Dirk Enzmann wrote:

> Is it possible to avoid the loop in the following function (or make the
> function otherwise more efficient) and can someone point me to a
> possible solution? (It would be great if hours could be reduced to
> seconds :-).
> 
> # ---------------------------------------------
> RanEigen=function(items=x,cases=y,sample=z)
> {
>   X=matrix(rnorm(cases*items),nrow=cases,byrow=F)
>   S=crossprod(X-rep(1,cases) %*% t(colMeans(X)))
> 
> EV=eigen((1/sqrt(diag(S))*diag(items))%*%S%*%(1/sqrt(diag(S))*diag(items)),only.values=T)$values
> 
>   for (i in 2:sample)
>   {
>   X=matrix(rnorm(cases*items),nrow=cases,byrow=F)
>   S=crossprod(X-rep(1,cases) %*% t(colMeans(X)))
> 
> EV=rbind(EV,eigen((1/sqrt(diag(S))*diag(items))%*%S%*%(1/sqrt(diag(S))*diag(items)),only.values=T)$values)
> 
>   }
>   REigV=(cbind(1:items,colMeans(EV)))
>   REigV[,2]=as.numeric(formatC(REigV[,2],format="f",digits=7,flag="
> ",width=10))
>   colnames(REigV)=c(' ','Eigenvalue')
>   rownames(REigV)=rep('',items)
>   return(REigV)
> }
> # ---------------------------------------------

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu May  8 11:34:50 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 8 May 2003 10:34:50 +0100 (BST)
Subject: [R] Forward Stepwise regression with stepAIC and step
In-Reply-To: <3E7B8AA20004EF2B@mk-cpfrontend-4.mail.uk.tiscali.com>
Message-ID: <Pine.LNX.4.44.0305081031570.18661-100000@gannet.stats>

On Thu, 8 May 2003 pfm401 at lineone.net wrote:

> I cannot seem to get the R functions step or stepAIC to perform forward
> or stepwise regression as I expect.

[...]

> wateruse.lm.forward<-stepAIC(wateruse.lm,trace=FALSE,direction="forward")

[...]

> In other words no forward procedure has been run (similar results apply
> if I use direction="step")!!

That's not a valid value for `direction': see the help page.

> What am I doing wrong?? Thanks in advance for any help.

You not given a `scope' argument, so there are no variables to add.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ernesto at ipimar.pt  Thu May  8 11:45:48 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Thu, 08 May 2003 09:45:48 -0000
Subject: [R] Avoiding loops to spare time and memory
In-Reply-To: <3EBA23EA.77EC9CB2@kfn.uni-hannover.de>
References: <3EBA1C34.1FE1477C@kfn.uni-hannover.de>
	<1052385629.1272.4.camel@gandalf.ipimar.pt>
	<3EBA23EA.77EC9CB2@kfn.uni-hannover.de>
Message-ID: <1052387072.1265.13.camel@gandalf.ipimar.pt>

On Thu, 2003-05-08 at 10:31, Dirk Enzmann wrote:
> I create vectors of eigenvalues of correlation matrices of random numbers for x items and y cases  i-1-times and
> add them via rbind to the already calculated eigenvalues. Thus, at the end of the loop I have a matrix of
> items*samples eigenvalues.
> 
> Ernesto Jardim schrieb:
> 
> > On Thu, 2003-05-08 at 09:58, Dirk Enzmann wrote:
> > > Is it possible to avoid the loop in the following function (or make the
> > > function otherwise more efficient) and can someone point me to a
> > > possible solution? (It would be great if hours could be reduced to
> > > seconds :-).
> > >
> > > # ---------------------------------------------
> > > RanEigen=function(items=x,cases=y,sample=z)
> > > {
> > >   X=matrix(rnorm(cases*items),nrow=cases,byrow=F)
> > >   S=crossprod(X-rep(1,cases) %*% t(colMeans(X)))
> > >
> > > EV=eigen((1/sqrt(diag(S))*diag(items))%*%S%*%(1/sqrt(diag(S))*diag(items)),only.values=T)$values
> > >
> > >   for (i in 2:sample)
> > >   {
> > >   X=matrix(rnorm(cases*items),nrow=cases,byrow=F)
> > >   S=crossprod(X-rep(1,cases) %*% t(colMeans(X)))
> > >
> > > EV=rbind(EV,eigen((1/sqrt(diag(S))*diag(items))%*%S%*%(1/sqrt(diag(S))*diag(items)),only.values=T)$values)
> > >
> > >   }
> > >   REigV=(cbind(1:items,colMeans(EV)))
> > >   REigV[,2]=as.numeric(formatC(REigV[,2],format="f",digits=7,flag="
> > > ",width=10))
> > >   colnames(REigV)=c(' ','Eigenvalue')
> > >   rownames(REigV)=rep('',items)
> > >   return(REigV)
> > > }
> > > # ---------------------------------------------
> > >
> > > Thanks in advance,
> > > Dirk
> > >
> > >
> > > *************************************************
> > > Dr. Dirk Enzmann
> > > Criminological Research Institute of Lower Saxony
> > > Luetzerodestr. 9
> > > D-30161 Hannover
> > > Germany
> > >
> > > phone: +49-511-348.36.32
> > > fax:   +49-511-348.36.10
> > > email: ENZMANN at KFN.uni-hannover.de
> > >
> > > http://www.kfn.de
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> > Hi
> >
> > You're not using the value of i inside your loop. Why do you need the
> > loop ?
> >
> > EJ
> 
> --
> *************************************************
> Dr. Dirk Enzmann
> Criminological Research Institute of Lower Saxony
> Luetzerodestr. 9
> D-30161 Hannover
> Germany
> 
> phone: +49-511-348.36.32
> fax:   +49-511-348.36.10
> email: ENZMANN at KFN.uni-hannover.de
> 
> http://www.kfn.de
> *************************************************
> 


To avoid the loop you can try someting like :

fun <- function(){
X=matrix(rnorm(cases*items),nrow=cases,byrow=F)
S=crossprod(X-rep(1,cases) %*% t(colMeans(X)))
EV=rbind(EV,eigen((1/sqrt(diag(S))*diag(items))%*%S%*%(1/sqrt(diag(S))*diag(items)),only.values=T)$values)
}

lst1 <- split(c(2:sample),c(2:sample))
lst2 <- lapply(lst1,fun)

This is not the most elegant way of doing it, but it worked for me. The
idea is to create a list with the number of samples you want and then
use "lapply" that is much faster then loop.

In the end you get a list with the results. You can use "unlist" to
change it into a vector.

Hope it helps

Regards

EJ



From edgar at cs.uprm.edu  Thu May  8 13:19:41 2003
From: edgar at cs.uprm.edu (Edgar Acuna)
Date: Thu, 8 May 2003 07:19:41 -0400 (EDT)
Subject: [R] Forward Stepwise regression with stepAIC and step
In-Reply-To: <3E7B8AA20004EF2B@mk-cpfrontend-4.mail.uk.tiscali.com>
Message-ID: <Pine.GSO.4.33.0305080714350.21736-100000@cs.uprm.edu>

Paul,
Try this
l1<-lm(waterusage~product,data=wateruse)
water.forw<-step(l1,scope=~.+avetemp+days+payroll+rubbish,direction="forward")

Good luck

Edgar
University of Puerto Rico

On Thu, 8 May 2003 pfm401 at lineone.net wrote:

> Dear all,
>
> I cannot seem to get the R functions step or stepAIC to perform forward
> or stepwise regression as I expect. I have enclosed the example data in
> a dataframe at the end of this mail. Note rubbish is and rnorm(17) variable
> which I have deliberately added to the data to test the stepwise procedure.
>
> I have used
>
> wateruse.lm<-lm(waterusage~.,data=wateruse)   # Fit full model
> wateruse.lm.back<-stepAIC(wateruse.lm,trace=FALSE)
>
> in which rubbish is removed (calling wateruse.lm.back$anova gives
>
> Step         Df Deviance Resid. Df Resid. Dev      AIC
> 1           NA       NA        11   743720.8 193.6655
> 2 - rubbish  1 76.67448        12   743797.5 191.6673
>
> However if I run
>
> wateruse.lm.forward<-stepAIC(wateruse.lm,trace=FALSE,direction="forward")
>
> wateruse.lm.forward$anova gives
>
> Stepwise Model Path
> Analysis of Deviance Table
>
> Initial Model:
> waterusage ~ avetemp + product + days + payroll + rubbish
>
> Final Model:
> waterusage ~ avetemp + product + days + payroll + rubbish
>
>
>   Step Df Deviance Resid. Df Resid. Dev      AIC
> 1      NA       NA        11   743720.8 193.6655
>
>
> In other words no forward procedure has been run (similar results apply
> if I use direction="step")!!
>
> What am I doing wrong?? Thanks in advance for any help.
>
> Thanks, Paul.
>
>
>
>
>
>
>
> > wateruse
>    waterusage avetemp product days payroll    rubbish
> 1        3067    58.8    7107   21     129 -0.8393514
> 2        2828    65.2    6373   22     141 -0.8781807
> 3        2891    70.9    6796   22     153  1.1939278
> 4        2994    77.4    9208   20     166  0.2230589
> 5        3082    79.3   14792   25     193  1.7165612
> 6        3898    81.0   14564   23     189 -0.3810258
> 7        3502    71.9   11964   20     175 -0.1891337
> 8        3060    63.9   13526   23     186  1.1204482
> 9        3211    54.5   12656   20     190  2.6239803
> 10       3286    39.5   14119   20     187  0.9282131
> 11       3542    44.5   16691   22     195 -1.7371026
> 12       3125    43.6   14571   19     206 -0.1368085
> 13       3022    56.0   13619   22     198  1.3408773
> 14       2922    64.7   14575   22     192 -0.1125558
> 15       3950    73.0   14556   21     191  0.4668919
> 16       4488    78.9   18573   21     200  0.6309489
> 17       3295    79.4   15618   22     200  1.0918370
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From B.Rowlingson at lancaster.ac.uk  Thu May  8 12:32:38 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 08 May 2003 11:32:38 +0100
Subject: [R] convert plot to device coords
Message-ID: <3EBA3246.7070602@lancaster.ac.uk>

Is there a function to convert from plot coordinates to device coordinates?

  It should be easy enough to work out from various par() parameters - 
namely usr, plt, and fig. 'usr' tells us where an (x,y) point is in the 
plot, then 'plt' tells us where it is in the figure, then 'fig' tells us 
where it is in the ((0,1),(0,1)) device space. Then there's the slight 
complication of log axes in the plot space, which makes me wonder if 
this exists somewhere in R already, rather than me writing a buggy version.

  I dont expect a version for lattice graphics, just base graphics!

Barry Rowlingson
Maths and Stats
Lancaster University
Lancaster, UK



From p.dalgaard at biostat.ku.dk  Thu May  8 12:56:53 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Thu, 08 May 2003 10:56:53 -0000
Subject: [R] Returning the p-value of a factor analysis
In-Reply-To: <x23cjpx09o.fsf@biostat.ku.dk>
References: <6B5A9304046AD411BD0200508BDFB6CB01EE2165@gimli.middleearth.kssg.com>
	<x23cjpx09o.fsf@biostat.ku.dk>
Message-ID: <x2ptmtvh1a.fsf@biostat.ku.dk>

Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk> writes:

> In 1.7.0, this function is hidden in the mva namespace
> but you can view it with get("print.factanal",environment(factanal)).

On closer thought, that should probably be

getS3method("print","factanal")


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From V.Khamenia at BioVisioN.de  Thu May  8 12:57:52 2003
From: V.Khamenia at BioVisioN.de (Khamenia, Valery)
Date: Thu, 8 May 2003 12:57:52 +0200 
Subject: [R] approximation of CDF
Message-ID: <D15343265276D31197BC00A024A6C11077403B@EXS_BDC>

Hi all,

  is there any package in R capable of smooth approximation of CDF
  basing on given sample? 
  (Thus, I am not speaking about ecdf)

  In particular, I expect very much that the approximation should  
  subject to the property: 

     f(x0)<=f(x1) for x0<x1, where x0 and x1 belong to range of 
     the sample given.

  Polynomial approximation could be OK for me as well.

P.S. whould you please to make Cc on me answering this mail?

kind regards,
Valery A.Khamenya
---------------------------------------------------------------------------
Bioinformatics Department
BioVisioN AG, Hannover



From Fabrizio.DeAmicis at git.generali.ch  Thu May  8 13:12:44 2003
From: Fabrizio.DeAmicis at git.generali.ch (De Amicis Fabrizio (G.I.T.))
Date: Thu, 8 May 2003 13:12:44 +0200 
Subject: [R] coulmns format
Message-ID: <6C9A2D9477234140A56E9D1B073B28E901DB64@gitmanex01.git.generali.ch>


> HI,
> with the command, 
> 
> jj<-tapply(j1,j2,sum)
> 
> the result is
> 
> > jj
>           AUTOSTELLA             CAIZZONE CENTRO B PEL E C SNC
> CHROMOLI             CONSORZI 
>               308178               152183               120468
> 150658               325459 
>             GIUNTIMA          LINEAGERMAI             MAN NORD
> PDM              RINALDI 
>               285285               403875               293926
> 145196               293923 
> 
> 
> question: there is a way to obtain the result in the following way?
> 
> 
> AUTOSTELLA			308178     
> CAIZZONE			152183
> CENTRO B PEL E C SNC	120468	
> CHROMOLI			150658
> CONSORZI			325459
> GIUNTIMA			285285
> LINEAGERMAI			403875
> MAN NORD			293926
> PDM				145196	
> RINALDI			293923
> 
> Thanks,
> Fabrizio 
> 
> ---------------------------------------------------------------
> Fabrizio De Amicis
> 
> IT Department
> Generali Information Technologies - (GIT)
> 
> Centro Galleria 2,
> Via Cantonale
> CH - 6928 Manno - Switzerland
> Tel  +41 91 806 6220
> Fax +41 91 806 6298
> E-mail: fabrizio.deamicis at git.generali.ch  
> 
> 
> 
> 
************************************************************************
The information in this email is confidential and may be legally... {{dropped}}



From ripley at stats.ox.ac.uk  Thu May  8 13:40:54 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 8 May 2003 12:40:54 +0100 (BST)
Subject: [R] approximation of CDF
In-Reply-To: <D15343265276D31197BC00A024A6C11077403B@EXS_BDC>
Message-ID: <Pine.LNX.4.44.0305081236320.18826-100000@gannet.stats>

Almost any method of fitting a density estimate would work on integrating 
(numerically) the result.

In particular, look at package polspline, where p(old)logspline does the 
integration for you.

On Thu, 8 May 2003, Khamenia, Valery wrote:

>   is there any package in R capable of smooth approximation of CDF
>   basing on given sample? 
>   (Thus, I am not speaking about ecdf)

I think it _is_ an ECDF you want to approximate, since you mention
`sample' below.

>   In particular, I expect very much that the approximation should  
>   subject to the property: 
> 
>      f(x0)<=f(x1) for x0<x1, where x0 and x1 belong to range of 
>      the sample given.
> 
>   Polynomial approximation could be OK for me as well.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Joris.DeWolf at cropdesign.com  Thu May  8 13:56:11 2003
From: Joris.DeWolf at cropdesign.com (Joris DeWolf)
Date: Thu, 08 May 2003 13:56:11 +0200
Subject: [R] strange behaviour of certain fields in data frame after rbind
Message-ID: <3EBA45DB.30602@cropdesign.com>

Can anybody explain me what is going wrong with the rbind command or how 
I could avoid the problem?
I have a script with loops which time has a dataframe as output (called 
T2sbdata). After each loop I would like to append that dataframe to the 
results I obtained from the previous loops (called T2sbdataALL) and use 
for that purpose rbind.

Below a part of the loop and the result I get. The rbind command does it 
job as I would expect, but cannot append the column PTGEvent properly.

I use R Version 1.6.2 under Linux.

Thanks

Joris

print("how original data look like")
print(T2sbdataALL[1:8])
print("how data to be appended look like")
print(T2sbdata[1:8])
T2sbdataALL <- rbind(T2sbdataALL,T2sbdata)
print("How all data look after rbind")
print(T2sbdataALL[1:8])




[1] "how original data look like"
   IDSSB IDSeed   CDnr   PTGEvent          ExpNr IDExp WPSNumber      
TypeExp
35 12102 150008 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
Confirmation
36 12103 150328 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
Confirmation
37 12104 150307 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
Confirmation
38 12105 150327 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
Confirmation
39 12106 150304 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
Confirmation
40 12107 149693 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
Confirmation
41 12108 150303 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
Confirmation
42 12109 149698 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
Confirmation
43 12110 150320 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
Confirmation
44 12111 150301 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
Confirmation
45 12112 150034 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
Confirmation
[1] "how data to be appended look like"
   IDSSB IDSeed   CDnr   PTGEvent          ExpNr IDExp WPSNumber      
TypeExp
46 12113 150335 CD3629 OS0934-09A E0.000.003.205  3116  YD03_17b 
Confirmation
47 12114 150032 CD3629 OS0934-09A E0.000.003.205  3116  YD03_17b 
Confirmation
48 12115 150293 CD3629 OS0934-09A E0.000.003.205  3116  YD03_17b 
Confirmation
49 12116 150599 CD3629 OS0934-09A E0.000.003.205  3116  YD03_17b 
Confirmation
50 12117 150332 CD3629 OS0934-09A E0.000.003.205  3116  YD03_17b 
Confirmation
51 12118 150287 CD3629 OS0934-09A E0.000.003.205  3116  YD03_17b 
Confirmation
52 12119 150595 CD3629 OS0934-09A E0.000.003.205  3116  YD03_17b 
Confirmation
53 12120 150038 CD3629 OS0934-09A E0.000.003.205  3116  YD03_17b 
Confirmation
54 12121 150286 CD3629 OS0934-09A E0.000.003.205  3116  YD03_17b 
Confirmation
55 12122 150333 CD3629 OS0934-09A E0.000.003.205  3116  YD03_17b 
Confirmation
[1] "How all data look after rbind"
   IDSSB IDSeed   CDnr   PTGEvent          ExpNr IDExp WPSNumber      
TypeExp
35 12102 150008 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
Confirmation
36 12103 150328 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
Confirmation
37 12104 150307 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
Confirmation
38 12105 150327 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
Confirmation
39 12106 150304 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
Confirmation
40 12107 149693 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
Confirmation
41 12108 150303 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
Confirmation
42 12109 149698 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
Confirmation
43 12110 150320 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
Confirmation
44 12111 150301 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
Confirmation
45 12112 150034 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
Confirmation
46 12113 150335 CD3629       <NA> E0.000.003.205  3116  YD03_17b 
Confirmation
47 12114 150032 CD3629       <NA> E0.000.003.205  3116  YD03_17b 
Confirmation
48 12115 150293 CD3629       <NA> E0.000.003.205  3116  YD03_17b 
Confirmation
49 12116 150599 CD3629       <NA> E0.000.003.205  3116  YD03_17b 
Confirmation
50 12117 150332 CD3629       <NA> E0.000.003.205  3116  YD03_17b 
Confirmation
51 12118 150287 CD3629       <NA> E0.000.003.205  3116  YD03_17b 
Confirmation
52 12119 150595 CD3629       <NA> E0.000.003.205  3116  YD03_17b 
Confirmation
53 12120 150038 CD3629       <NA> E0.000.003.205  3116  YD03_17b 
Confirmation
54 12121 150286 CD3629       <NA> E0.000.003.205  3116  YD03_17b 
Confirmation
55 12122 150333 CD3629       <NA> E0.000.003.205  3116  YD03_17b 
Confirmation

-- 

====================================================================== 
Joris De Wolf
CropDesign N.V. 
Plant Evaluation Group
Technologiepark 3 
B-9052 Zwijnaarde 
Belgium 
Tel. : +32 9 242 91 55
Fax  : +32 9 241 91 73
====================================================================== 
The information contained in this email is confidential and may ... {{dropped}}



From ripley at stats.ox.ac.uk  Thu May  8 14:09:21 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 8 May 2003 13:09:21 +0100 (BST)
Subject: [R] strange behaviour of certain fields in data frame after rbind
In-Reply-To: <3EBA45DB.30602@cropdesign.com>
Message-ID: <Pine.LNX.4.44.0305081301400.18981-100000@gannet.stats>

>From the NEWS for 1.7.0:

    o   The data.frame method for rbind() was
        - converting character columns to factors,
        - converting ordered factor columns to unordered factors,
        - failing to append correctly a factor to a character column
          and vice versa.

and my guess is that is what you are seeing.  But we can't tell the
classes of your columns from the printout.  It would have been helpful to 
ask yourself (and tell us) what is special about `certain fields'.
I believe this works properly in 1.6.2 if the fields are either factor or 
character and protected by I() (and hence of class "AsIs").

On Thu, 8 May 2003, Joris DeWolf wrote:

> Can anybody explain me what is going wrong with the rbind command or how 
> I could avoid the problem?
> I have a script with loops which time has a dataframe as output (called 
> T2sbdata). After each loop I would like to append that dataframe to the 
> results I obtained from the previous loops (called T2sbdataALL) and use 
> for that purpose rbind.
> 
> Below a part of the loop and the result I get. The rbind command does it 
> job as I would expect, but cannot append the column PTGEvent properly.
> 
> I use R Version 1.6.2 under Linux.
> 
> Thanks
> 
> Joris
> 
> print("how original data look like")
> print(T2sbdataALL[1:8])
> print("how data to be appended look like")
> print(T2sbdata[1:8])
> T2sbdataALL <- rbind(T2sbdataALL,T2sbdata)
> print("How all data look after rbind")
> print(T2sbdataALL[1:8])
> 
> 
> 
> 
> [1] "how original data look like"
>    IDSSB IDSeed   CDnr   PTGEvent          ExpNr IDExp WPSNumber      
> TypeExp
> 35 12102 150008 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
> Confirmation
> 36 12103 150328 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
> Confirmation
> 37 12104 150307 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
> Confirmation
> 38 12105 150327 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
> Confirmation
> 39 12106 150304 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
> Confirmation
> 40 12107 149693 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
> Confirmation
> 41 12108 150303 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
> Confirmation
> 42 12109 149698 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
> Confirmation
> 43 12110 150320 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
> Confirmation
> 44 12111 150301 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
> Confirmation
> 45 12112 150034 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
> Confirmation
> [1] "how data to be appended look like"
>    IDSSB IDSeed   CDnr   PTGEvent          ExpNr IDExp WPSNumber      
> TypeExp
> 46 12113 150335 CD3629 OS0934-09A E0.000.003.205  3116  YD03_17b 
> Confirmation
> 47 12114 150032 CD3629 OS0934-09A E0.000.003.205  3116  YD03_17b 
> Confirmation
> 48 12115 150293 CD3629 OS0934-09A E0.000.003.205  3116  YD03_17b 
> Confirmation
> 49 12116 150599 CD3629 OS0934-09A E0.000.003.205  3116  YD03_17b 
> Confirmation
> 50 12117 150332 CD3629 OS0934-09A E0.000.003.205  3116  YD03_17b 
> Confirmation
> 51 12118 150287 CD3629 OS0934-09A E0.000.003.205  3116  YD03_17b 
> Confirmation
> 52 12119 150595 CD3629 OS0934-09A E0.000.003.205  3116  YD03_17b 
> Confirmation
> 53 12120 150038 CD3629 OS0934-09A E0.000.003.205  3116  YD03_17b 
> Confirmation
> 54 12121 150286 CD3629 OS0934-09A E0.000.003.205  3116  YD03_17b 
> Confirmation
> 55 12122 150333 CD3629 OS0934-09A E0.000.003.205  3116  YD03_17b 
> Confirmation
> [1] "How all data look after rbind"
>    IDSSB IDSeed   CDnr   PTGEvent          ExpNr IDExp WPSNumber      
> TypeExp
> 35 12102 150008 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
> Confirmation
> 36 12103 150328 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
> Confirmation
> 37 12104 150307 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
> Confirmation
> 38 12105 150327 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
> Confirmation
> 39 12106 150304 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
> Confirmation
> 40 12107 149693 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
> Confirmation
> 41 12108 150303 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
> Confirmation
> 42 12109 149698 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
> Confirmation
> 43 12110 150320 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
> Confirmation
> 44 12111 150301 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
> Confirmation
> 45 12112 150034 CD3629 OS0934-07A E0.000.003.205  3116  YD03_17b 
> Confirmation
> 46 12113 150335 CD3629       <NA> E0.000.003.205  3116  YD03_17b 
> Confirmation
> 47 12114 150032 CD3629       <NA> E0.000.003.205  3116  YD03_17b 
> Confirmation
> 48 12115 150293 CD3629       <NA> E0.000.003.205  3116  YD03_17b 
> Confirmation
> 49 12116 150599 CD3629       <NA> E0.000.003.205  3116  YD03_17b 
> Confirmation
> 50 12117 150332 CD3629       <NA> E0.000.003.205  3116  YD03_17b 
> Confirmation
> 51 12118 150287 CD3629       <NA> E0.000.003.205  3116  YD03_17b 
> Confirmation
> 52 12119 150595 CD3629       <NA> E0.000.003.205  3116  YD03_17b 
> Confirmation
> 53 12120 150038 CD3629       <NA> E0.000.003.205  3116  YD03_17b 
> Confirmation
> 54 12121 150286 CD3629       <NA> E0.000.003.205  3116  YD03_17b 
> Confirmation
> 55 12122 150333 CD3629       <NA> E0.000.003.205  3116  YD03_17b 
> Confirmation
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From V.Khamenia at BioVisioN.de  Thu May  8 14:53:32 2003
From: V.Khamenia at BioVisioN.de (Khamenia, Valery)
Date: Thu, 8 May 2003 14:53:32 +0200 
Subject: AW: [R] approximation of CDF
Message-ID: <D15343265276D31197BC00A024A6C11077403C@EXS_BDC>

> Almost any method of fitting a density estimate would work on 
> integrating (numerically) the result.

it is a nice idea concerning the monotony property, which 
will be obtained automatically, but I am going to use results 
of approximation analytically

> In particular, look at package polspline, where 
> p(old)logspline does the integration for you.

thank you, I am going to install it.

> >   is there any package in R capable of smooth approximation of CDF
> >   basing on given sample?  (Thus, I am not speaking about ecdf)
> 
> I think it _is_ an ECDF you want to approximate, since you mention
> `sample' below.

no, it is not. I do not need the closeness to a ECDF but to a CDF.
classic ECDF (like that implemented in stepfun) is yet another 
approximation of CDF. In particular, if I try to pursue the best 
approximation of any ECDF function in polynomial basis, it will 
boost order of my polynomial approximation up to infinity. Meanwhile 
the CDF might be linear in the corresponding range (we could take 
uniform data as an example)

thank you for your reply,
kind regards,
Valery A.Khamenya
---------------------------------------------------------------------------
Bioinformatics Department
BioVisioN AG, Hannover



From th50 at leicester.ac.uk  Thu May  8 15:04:26 2003
From: th50 at leicester.ac.uk (Hotz, T.)
Date: Thu, 8 May 2003 14:04:26 +0100
Subject: R crashes with package SJava; was [R] Memory leakage?
Message-ID: <1F2CE8D4B0195E488213E8B8CCF714860161B649@saffron.cfs.le.ac.uk>

Dear all,

Maybe this has something to do with R crashing?
When my R version crashes, there is Rgui.exe still
running in the background (i.e. W2K's task manager
recognises it only as a process, which apparently 
is using almost 100% of the CPU).

I can reproduce that by "using" the SJava package 
(from Brian Ripley's homepage, as suggested on 
http://www.omegahat.org/RSJava/). When loading the 
package, and running the ttest example, my Rgui.exe 
crashes, and I end up with the process Rgui.exe 
still alive using the CPU extensively. The same 
happens on my stand-alone machine at home (with the 
same OS and R versions but newest Sun JDK).

Any comments greatly appreciated.

Best wishes

Thomas

P.S. At the end an error message appears, but I'm not 
able to sink it. I could run it in a terminal - but 
are there other possibilities?

--- R code pasted into Rgui

rm(list=ls())
# see below for ouput,
# used sink to get probale error messages
# (doesn't work; can one "sink" error messages?)
sink("k:/SJavaFault.rout")
version
# load SJava
library(SJava)
library(help=SJava)
.JavaInit()
# try SJava
.Java("Math","PI")
# load example
source("d:/R/rw1062/library/SJava/examples/ttest.R")
x<-rnorm(10)
y<-rnorm(10,1)
# test example, crashes after specifying x and y in the dialog and pressing "Submit"
dialog.t.test()
# Rgui.exe still running as a process, but not an application (according to task manager)


--- Output of sink and library(help=...)

         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    6.2            
year     2003           
month    01             
day      10             
language R              
using JAVA_HOME = Y:/Java Development Kit/Java2sdk1.4/jre 

[...]
Package: SJava
Version: 0.65
Date: 2002/07/17
Title: The Omegahat interface for R and Java.
Author: Duncan Temple Lang <duncan at research.bell-labs.com>, John
        Chambers <jmc at research.bell-labs.com>
Depends: R (>= 1.1.0)
Maintainer: Duncan Temple Lang <duncan at research.bell-labs.com>
Description: An interface from R to Java to create and call Java
        objects and methods.
License: GPL version 2 or newer. http://www.gnu.org/copyleft/gpl.html
URL: http://www.omegahat.org/RSJava, http://www.omegahat.org
        http://www.omegahat.org/bugs
Built: R 1.6.2; Win32; Thu Feb 27 19:18:38 GMTST 2003
[...]

[1] 3.141593
$id
[1] "1"

$value
$value$actionPerformed
function(ev) {
   cmd <- ev$getActionCommand()
   if(cmd == "Reset")
     reset()
   else {
     print(compute())
   }

  NULL
 }
<environment: 013B8AC4>


$className
character(0)

$targetClasses
character(0)

attr(,"class")
[1] "AnonymousRReference"

---

Thomas Hotz
Research Associate in Medical Statistics
University of Leicester
United Kingdom

Department of Epidemiology and Public Health
22-28 Princess Road West
Leicester
LE1 6TP
Tel +44 116 252-5410
Fax +44 116 252-5423

Division of Medicine for the Elderly
Department of Medicine
The Glenfield Hospital
Leicester
LE3 9QP
Tel +44 116 256-3643
Fax +44 116 232-2976


-----Original Message-----
From: Duncan Murdoch [mailto:dmurdoch at pair.com]
Sent: 03 May 2003 23:59
To: tshi at itsa.ucsf.edu
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Memory leakage?


On Sat, 03 May 2003 20:33:49 +0000, you wrote:

>I haven't tried re-installing windows yet, because it seems to be a big task 
>for me and also I kind of doubt that the problem is due to my own 
>computer(s), because the same problem happens to 3 different computers: one 
>Dell desktop in school runing Win2K and R 1.6.1, my Dell laptop runing Win 
>XP Professional Edition and R 1.7.0 and my new Dell desktop at home (just 
>bought less than a month and only a few basic softwares were installed) 
>runing Win XP Home Edition and R1.7.0.  (may be they're all from Dell :-)) 
>I'm still looking for the pattern of when this happens, but so far, it seems 
>to be random.

I don't think it's a Windows problem.  I've seen it occasionally, but
not reproducibly.  If you can figure out some sequence of operations
that reliably produces it, please let me know.

Duncan Murdoch

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From maechler at stat.math.ethz.ch  Thu May  8 15:21:40 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 8 May 2003 15:21:40 +0200
Subject: [R] coulmns format
In-Reply-To: <6C9A2D9477234140A56E9D1B073B28E901DB64@gitmanex01.git.generali.ch>
References: <6C9A2D9477234140A56E9D1B073B28E901DB64@gitmanex01.git.generali.ch>
Message-ID: <16058.23012.206756.824324@gargle.gargle.HOWL>

>>>>> "FabDeA" == De Amicis Fabrizio (G I T ) <Fabrizio.DeAmicis at git.generali.ch>
>>>>>     on Thu, 8 May 2003 13:12:44 +0200  writes:

    >> HI, with the command,
    >> 
    >> jj<-tapply(j1,j2,sum)
    >> 
    >> the result is
    >> 
    >> > jj
    >> AUTOSTELLA             CAIZZONE CENTRO B PEL E C SNC
    >> CHROMOLI             CONSORZI 
    >> 308178               152183               120468
    >> 150658               325459 
    >> GIUNTIMA          LINEAGERMAI             MAN NORD
    >> PDM              RINALDI 
    >> 285285               403875               293926
    >> 145196               293923 
    >> 
    >> 
    >> question: there is a way to obtain the result in the following way?
    >> 
    >> 
    >> AUTOSTELLA		308178     
    >> CAIZZONE			152183
    >> CENTRO B PEL E C SNC	120468	
    >> CHROMOLI			150658
    >> CONSORZI			325459
    >> GIUNTIMA			285285
    >> LINEAGERMAI		403875
    >> MAN NORD			293926
    >> PDM			145196	
    >> RINALDI			293923
    >> 

cbind(jj)

makes a 1-column matrix
and will probably print the way you want.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From ozric at web.de  Thu May  8 15:45:37 2003
From: ozric at web.de (Christian Schulz)
Date: Thu, 8 May 2003 15:45:37 +0200
Subject: R crashes with package SJava; was [R] Memory leakage?
References: <1F2CE8D4B0195E488213E8B8CCF714860161B649@saffron.cfs.le.ac.uk>
Message-ID: <000d01c31568$1bf2b9a0$ec01ebd9@pc>

Hmm,

this steps run without problems on my locale win2k.
Perhaps you make the same mistake like me in the past
and have no file named .Renviron  with entry

JAVA_HOME = c:/YourPath/j2re1.4.1_02

and saved in \rw1070 ?

>> library(sjava)
using JAVA_HOME = c:/Programme/Java/j2re1.4.1_02
>>.JavaInit()
>>source("C:/Chris/dm/rw1070/library/SJava/examples/calc.R")
>>calc()
[[1]]
$id
[1] "1"

$value
$value$actionPerformed
function(ev) {
   txt <- ev$getActionCommand()
   back <- 0
   if(txt == "=") {
     txt <- input$getText()
     val <- as.character(eval(parse(text=txt)))
     input$setText(val)
     jcombo$getModel()$insertElementAt(txt, as.integer(0))
     return(NULL)
   } else if(!is.na(match(txt, unaryOps))) {
     if(txt == "()")
       txt <- ""
     val <- paste(txt, "()",sep="")
     back <- -1
   } else if(txt == "Clear") {
      input$setText("")
      return(NULL)
   } else {
     val <- txt
   }

    doc <- input$getDocument()
    doc$insertString(input$getCaretPosition(), val, NULL)
    if(back < 0) {
      input$setCaretPosition(as.integer(input$getCaretPosition() + back))
    }
 }
<environment: 0194B3CC>


$className
character(0)

$targetClasses
character(0)

attr(,"class")
[1] "AnonymousRReference"

$input
$key
[1] "67"

$className
[1] "javax.swing.plaf.metal.MetalComboBoxEditor$1"

attr(,"class")
[1] "AnonymousOmegahatReference"

>>calc()



----- Original Message -----
From: "Hotz, T." <th50 at leicester.ac.uk>
To: <r-help at stat.math.ethz.ch>
Cc: "Duncan Murdoch" <dmurdoch at pair.com>; <tshi at itsa.ucsf.edu>
Sent: Thursday, May 08, 2003 3:04 PM
Subject: R crashes with package SJava; was [R] Memory leakage?


> Dear all,
>
> Maybe this has something to do with R crashing?
> When my R version crashes, there is Rgui.exe still
> running in the background (i.e. W2K's task manager
> recognises it only as a process, which apparently
> is using almost 100% of the CPU).
>
> I can reproduce that by "using" the SJava package
> (from Brian Ripley's homepage, as suggested on
> http://www.omegahat.org/RSJava/). When loading the
> package, and running the ttest example, my Rgui.exe
> crashes, and I end up with the process Rgui.exe
> still alive using the CPU extensively. The same
> happens on my stand-alone machine at home (with the
> same OS and R versions but newest Sun JDK).
>
> Any comments greatly appreciated.
>
> Best wishes
>
> Thomas
>
> P.S. At the end an error message appears, but I'm not
> able to sink it. I could run it in a terminal - but
> are there other possibilities?
>
> --- R code pasted into Rgui
>
> rm(list=ls())
> # see below for ouput,
> # used sink to get probale error messages
> # (doesn't work; can one "sink" error messages?)
> sink("k:/SJavaFault.rout")
> version
> # load SJava
> library(SJava)
> library(help=SJava)
> .JavaInit()
> # try SJava
> .Java("Math","PI")
> # load example
> source("d:/R/rw1062/library/SJava/examples/ttest.R")
> x<-rnorm(10)
> y<-rnorm(10,1)
> # test example, crashes after specifying x and y in the dialog and
pressing "Submit"
> dialog.t.test()
> # Rgui.exe still running as a process, but not an application (according
to task manager)
>
>
> --- Output of sink and library(help=...)
>
>          _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    6.2
> year     2003
> month    01
> day      10
> language R
> using JAVA_HOME = Y:/Java Development Kit/Java2sdk1.4/jre
>
> [...]
> Package: SJava
> Version: 0.65
> Date: 2002/07/17
> Title: The Omegahat interface for R and Java.
> Author: Duncan Temple Lang <duncan at research.bell-labs.com>, John
>         Chambers <jmc at research.bell-labs.com>
> Depends: R (>= 1.1.0)
> Maintainer: Duncan Temple Lang <duncan at research.bell-labs.com>
> Description: An interface from R to Java to create and call Java
>         objects and methods.
> License: GPL version 2 or newer. http://www.gnu.org/copyleft/gpl.html
> URL: http://www.omegahat.org/RSJava, http://www.omegahat.org
>         http://www.omegahat.org/bugs
> Built: R 1.6.2; Win32; Thu Feb 27 19:18:38 GMTST 2003
> [...]
>
> [1] 3.141593
> $id
> [1] "1"
>
> $value
> $value$actionPerformed
> function(ev) {
>    cmd <- ev$getActionCommand()
>    if(cmd == "Reset")
>      reset()
>    else {
>      print(compute())
>    }
>
>   NULL
>  }
> <environment: 013B8AC4>
>
>
> $className
> character(0)
>
> $targetClasses
> character(0)
>
> attr(,"class")
> [1] "AnonymousRReference"
>
> ---
>
> Thomas Hotz
> Research Associate in Medical Statistics
> University of Leicester
> United Kingdom
>
> Department of Epidemiology and Public Health
> 22-28 Princess Road West
> Leicester
> LE1 6TP
> Tel +44 116 252-5410
> Fax +44 116 252-5423
>
> Division of Medicine for the Elderly
> Department of Medicine
> The Glenfield Hospital
> Leicester
> LE3 9QP
> Tel +44 116 256-3643
> Fax +44 116 232-2976
>
>
> -----Original Message-----
> From: Duncan Murdoch [mailto:dmurdoch at pair.com]
> Sent: 03 May 2003 23:59
> To: tshi at itsa.ucsf.edu
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Memory leakage?
>
>
> On Sat, 03 May 2003 20:33:49 +0000, you wrote:
>
> >I haven't tried re-installing windows yet, because it seems to be a big
task
> >for me and also I kind of doubt that the problem is due to my own
> >computer(s), because the same problem happens to 3 different computers:
one
> >Dell desktop in school runing Win2K and R 1.6.1, my Dell laptop runing
Win
> >XP Professional Edition and R 1.7.0 and my new Dell desktop at home (just
> >bought less than a month and only a few basic softwares were installed)
> >runing Win XP Home Edition and R1.7.0.  (may be they're all from Dell
:-))
> >I'm still looking for the pattern of when this happens, but so far, it
seems
> >to be random.
>
> I don't think it's a Windows problem.  I've seen it occasionally, but
> not reproducibly.  If you can figure out some sequence of operations
> that reliably produces it, please let me know.
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From th50 at leicester.ac.uk  Thu May  8 15:59:45 2003
From: th50 at leicester.ac.uk (Hotz, T.)
Date: Thu, 8 May 2003 14:59:45 +0100
Subject: R crashes with package SJava; was [R] Memory leakage?
Message-ID: <1F2CE8D4B0195E488213E8B8CCF714860161B64A@saffron.cfs.le.ac.uk>

As is visible from the output, I set JAVA_HOME properly 
in my .Renviron file. Otherwise I couldn't even call .Java(). 
However, I use R 1.6.2, maybe that's the problem (although the
SJava version I use was built for R 1.6.2). Example calc() 
doesn't cause R to crash, but gives me the following warning
when called twice:

Warning message: 
`restart' is deprecated.
Use `try' instead.
See ?Deprecated. 

Moreover, I don't really understand the example: where am I
supposed to get the result of the calculation? I don't see it
in the Java Dialog, and can't spot it in the return value 
either.

Regards

Thomas

-----Original Message-----
From: Christian Schulz [mailto:ozric at web.de]
Sent: 08 May 2003 14:46
To: Hotz, T.; r-help at stat.math.ethz.ch
Subject: Re: R crashes with package SJava; was [R] Memory leakage?


Hmm,

this steps run without problems on my locale win2k.
Perhaps you make the same mistake like me in the past
and have no file named .Renviron  with entry

JAVA_HOME = c:/YourPath/j2re1.4.1_02

and saved in \rw1070 ?

>> library(sjava)
using JAVA_HOME = c:/Programme/Java/j2re1.4.1_02
>>.JavaInit()
>>source("C:/Chris/dm/rw1070/library/SJava/examples/calc.R")
>>calc()
[[1]]
$id
[1] "1"

$value
$value$actionPerformed
function(ev) {
   txt <- ev$getActionCommand()
   back <- 0
   if(txt == "=") {
     txt <- input$getText()
     val <- as.character(eval(parse(text=txt)))
     input$setText(val)
     jcombo$getModel()$insertElementAt(txt, as.integer(0))
     return(NULL)
   } else if(!is.na(match(txt, unaryOps))) {
     if(txt == "()")
       txt <- ""
     val <- paste(txt, "()",sep="")
     back <- -1
   } else if(txt == "Clear") {
      input$setText("")
      return(NULL)
   } else {
     val <- txt
   }

    doc <- input$getDocument()
    doc$insertString(input$getCaretPosition(), val, NULL)
    if(back < 0) {
      input$setCaretPosition(as.integer(input$getCaretPosition() + back))
    }
 }
<environment: 0194B3CC>


$className
character(0)

$targetClasses
character(0)

attr(,"class")
[1] "AnonymousRReference"

$input
$key
[1] "67"

$className
[1] "javax.swing.plaf.metal.MetalComboBoxEditor$1"

attr(,"class")
[1] "AnonymousOmegahatReference"

>>calc()



----- Original Message -----
From: "Hotz, T." <th50 at leicester.ac.uk>
To: <r-help at stat.math.ethz.ch>
Cc: "Duncan Murdoch" <dmurdoch at pair.com>; <tshi at itsa.ucsf.edu>
Sent: Thursday, May 08, 2003 3:04 PM
Subject: R crashes with package SJava; was [R] Memory leakage?


> Dear all,
>
> Maybe this has something to do with R crashing?
> When my R version crashes, there is Rgui.exe still
> running in the background (i.e. W2K's task manager
> recognises it only as a process, which apparently
> is using almost 100% of the CPU).
>
> I can reproduce that by "using" the SJava package
> (from Brian Ripley's homepage, as suggested on
> http://www.omegahat.org/RSJava/). When loading the
> package, and running the ttest example, my Rgui.exe
> crashes, and I end up with the process Rgui.exe
> still alive using the CPU extensively. The same
> happens on my stand-alone machine at home (with the
> same OS and R versions but newest Sun JDK).
>
> Any comments greatly appreciated.
>
> Best wishes
>
> Thomas
>
> P.S. At the end an error message appears, but I'm not
> able to sink it. I could run it in a terminal - but
> are there other possibilities?
>
> --- R code pasted into Rgui
>
> rm(list=ls())
> # see below for ouput,
> # used sink to get probale error messages
> # (doesn't work; can one "sink" error messages?)
> sink("k:/SJavaFault.rout")
> version
> # load SJava
> library(SJava)
> library(help=SJava)
> .JavaInit()
> # try SJava
> .Java("Math","PI")
> # load example
> source("d:/R/rw1062/library/SJava/examples/ttest.R")
> x<-rnorm(10)
> y<-rnorm(10,1)
> # test example, crashes after specifying x and y in the dialog and
pressing "Submit"
> dialog.t.test()
> # Rgui.exe still running as a process, but not an application (according
to task manager)
>
>
> --- Output of sink and library(help=...)
>
>          _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    6.2
> year     2003
> month    01
> day      10
> language R
> using JAVA_HOME = Y:/Java Development Kit/Java2sdk1.4/jre
>
> [...]
> Package: SJava
> Version: 0.65
> Date: 2002/07/17
> Title: The Omegahat interface for R and Java.
> Author: Duncan Temple Lang <duncan at research.bell-labs.com>, John
>         Chambers <jmc at research.bell-labs.com>
> Depends: R (>= 1.1.0)
> Maintainer: Duncan Temple Lang <duncan at research.bell-labs.com>
> Description: An interface from R to Java to create and call Java
>         objects and methods.
> License: GPL version 2 or newer. http://www.gnu.org/copyleft/gpl.html
> URL: http://www.omegahat.org/RSJava, http://www.omegahat.org
>         http://www.omegahat.org/bugs
> Built: R 1.6.2; Win32; Thu Feb 27 19:18:38 GMTST 2003
> [...]
>
> [1] 3.141593
> $id
> [1] "1"
>
> $value
> $value$actionPerformed
> function(ev) {
>    cmd <- ev$getActionCommand()
>    if(cmd == "Reset")
>      reset()
>    else {
>      print(compute())
>    }
>
>   NULL
>  }
> <environment: 013B8AC4>
>
>
> $className
> character(0)
>
> $targetClasses
> character(0)
>
> attr(,"class")
> [1] "AnonymousRReference"
>
> ---
>
> Thomas Hotz
> Research Associate in Medical Statistics
> University of Leicester
> United Kingdom
>
> Department of Epidemiology and Public Health
> 22-28 Princess Road West
> Leicester
> LE1 6TP
> Tel +44 116 252-5410
> Fax +44 116 252-5423
>
> Division of Medicine for the Elderly
> Department of Medicine
> The Glenfield Hospital
> Leicester
> LE3 9QP
> Tel +44 116 256-3643
> Fax +44 116 232-2976
>
>
> -----Original Message-----
> From: Duncan Murdoch [mailto:dmurdoch at pair.com]
> Sent: 03 May 2003 23:59
> To: tshi at itsa.ucsf.edu
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Memory leakage?
>
>
> On Sat, 03 May 2003 20:33:49 +0000, you wrote:
>
> >I haven't tried re-installing windows yet, because it seems to be a big
task
> >for me and also I kind of doubt that the problem is due to my own
> >computer(s), because the same problem happens to 3 different computers:
one
> >Dell desktop in school runing Win2K and R 1.6.1, my Dell laptop runing
Win
> >XP Professional Edition and R 1.7.0 and my new Dell desktop at home (just
> >bought less than a month and only a few basic softwares were installed)
> >runing Win XP Home Edition and R1.7.0.  (may be they're all from Dell
:-))
> >I'm still looking for the pattern of when this happens, but so far, it
seems
> >to be random.
>
> I don't think it's a Windows problem.  I've seen it occasionally, but
> not reproducibly.  If you can figure out some sequence of operations
> that reliably produces it, please let me know.
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From iwhite at staffmail.ed.ac.uk  Thu May  8 16:07:56 2003
From: iwhite at staffmail.ed.ac.uk (iwhite@staffmail.ed.ac.uk)
Date: Thu, 8 May 2003 15:07:56 +0100 (BST)
Subject: [R] natural splines
Message-ID: <Pine.GSO.4.33.0305081506001.27182-100000@holyrood.ed.ac.uk>

Apologies if this is this too obscure for R-help.

In package splines, ns(x,,knots,intercept=TRUE) produces an n by K+2
matrix N, the values of K+2 basis functions for the natural splines with K
(internal) knots, evaluated at x.  It does this by first generating an
n by K+4 matrix B of unconstrained splines, then postmultiplying B by
H, a K+4 by K+2 representation of the nullspace of C (2 by K+4), which
contains the 2nd derivatives of the unconstrained splines evaluated at
the boundary knots.  E.g. see Hastie and Tibshirani, Generalized Additive
Models, exercise 2.5, p36.  The QR decomposition is used to get H.

This can produce basis functions which, while technically correct (they
span the K+2 dim space of natural splines), can be counterintuitive.
E.g. equally spaced knots symmetrically placed between the data extremes
can produce very asymmetric arrangements, with N(K+2) not the mirror image
of N(1), for example, and considerable loss of sparseness.

This approach works for any basis B, but for B-splines, the second
derivatives are zero for all the unconstrained basis functions, apart
from 3 at each end. All that is required is to combine these 3 so that
the contributions to the 2nd derivatives cancel. In other words, we
only need to find the null space of two 2 by 3 matrices, rather than a
2 by K+4. If the left-most internal knots are t(1) and t(2), and the
left-hand boundary knot is t(0), we can replace B(1...3) with

B(1)+B(2)+B(3) and [t(2)-t(0)]*B(2) + [t(1)+t(2)-2*t(0)]*B(1),

(for example), and similarly at the right-hand end.

This seems simpler and more elegant than brute force QR on the full
matrix of derivatives. But I may have missed some reason why it can't be
used. Perhaps it doesn't work when intercept=FALSE?

======================================
I.White
ICAPB, University of Edinburgh
Ashworth Laboratories, West Mains Road
Edinburgh EH9 3JT
Fax: 0131 650 6564  Tel: 0131 650 5490
E-mail: iwhite at staffmail.ed.ac.uk



From ozric at web.de  Thu May  8 16:09:04 2003
From: ozric at web.de (Christian Schulz)
Date: Thu, 8 May 2003 16:09:04 +0200
Subject: R crashes with package SJava; was [R] Memory leakage?
References: <1F2CE8D4B0195E488213E8B8CCF714860161B64A@saffron.cfs.le.ac.uk>
Message-ID: <001601c3156b$6220b320$ec01ebd9@pc>

Uuups , i  show only the calc gui
pops-up, but you right, when i want
push buttons, get every time same
errors as you........

Warning message:
`restart' is deprecated.
Use `try' instead.
See ?Deprecated.

regards,christian


----- Original Message -----
From: "Hotz, T." <th50 at leicester.ac.uk>
To: "Christian Schulz" <ozric at web.de>; "Hotz, T." <th50 at leicester.ac.uk>;
<r-help at stat.math.ethz.ch>
Sent: Thursday, May 08, 2003 3:59 PM
Subject: RE: R crashes with package SJava; was [R] Memory leakage?


As is visible from the output, I set JAVA_HOME properly
in my .Renviron file. Otherwise I couldn't even call .Java().
However, I use R 1.6.2, maybe that's the problem (although the
SJava version I use was built for R 1.6.2). Example calc()
doesn't cause R to crash, but gives me the following warning
when called twice:

Warning message:
`restart' is deprecated.
Use `try' instead.
See ?Deprecated.

Moreover, I don't really understand the example: where am I
supposed to get the result of the calculation? I don't see it
in the Java Dialog, and can't spot it in the return value
either.

Regards

Thomas

-----Original Message-----
From: Christian Schulz [mailto:ozric at web.de]
Sent: 08 May 2003 14:46
To: Hotz, T.; r-help at stat.math.ethz.ch
Subject: Re: R crashes with package SJava; was [R] Memory leakage?


Hmm,

this steps run without problems on my locale win2k.
Perhaps you make the same mistake like me in the past
and have no file named .Renviron  with entry

JAVA_HOME = c:/YourPath/j2re1.4.1_02

and saved in \rw1070 ?

>> library(sjava)
using JAVA_HOME = c:/Programme/Java/j2re1.4.1_02
>>.JavaInit()
>>source("C:/Chris/dm/rw1070/library/SJava/examples/calc.R")
>>calc()
[[1]]
$id
[1] "1"

$value
$value$actionPerformed
function(ev) {
   txt <- ev$getActionCommand()
   back <- 0
   if(txt == "=") {
     txt <- input$getText()
     val <- as.character(eval(parse(text=txt)))
     input$setText(val)
     jcombo$getModel()$insertElementAt(txt, as.integer(0))
     return(NULL)
   } else if(!is.na(match(txt, unaryOps))) {
     if(txt == "()")
       txt <- ""
     val <- paste(txt, "()",sep="")
     back <- -1
   } else if(txt == "Clear") {
      input$setText("")
      return(NULL)
   } else {
     val <- txt
   }

    doc <- input$getDocument()
    doc$insertString(input$getCaretPosition(), val, NULL)
    if(back < 0) {
      input$setCaretPosition(as.integer(input$getCaretPosition() + back))
    }
 }
<environment: 0194B3CC>


$className
character(0)

$targetClasses
character(0)

attr(,"class")
[1] "AnonymousRReference"

$input
$key
[1] "67"

$className
[1] "javax.swing.plaf.metal.MetalComboBoxEditor$1"

attr(,"class")
[1] "AnonymousOmegahatReference"

>>calc()



----- Original Message -----
From: "Hotz, T." <th50 at leicester.ac.uk>
To: <r-help at stat.math.ethz.ch>
Cc: "Duncan Murdoch" <dmurdoch at pair.com>; <tshi at itsa.ucsf.edu>
Sent: Thursday, May 08, 2003 3:04 PM
Subject: R crashes with package SJava; was [R] Memory leakage?


> Dear all,
>
> Maybe this has something to do with R crashing?
> When my R version crashes, there is Rgui.exe still
> running in the background (i.e. W2K's task manager
> recognises it only as a process, which apparently
> is using almost 100% of the CPU).
>
> I can reproduce that by "using" the SJava package
> (from Brian Ripley's homepage, as suggested on
> http://www.omegahat.org/RSJava/). When loading the
> package, and running the ttest example, my Rgui.exe
> crashes, and I end up with the process Rgui.exe
> still alive using the CPU extensively. The same
> happens on my stand-alone machine at home (with the
> same OS and R versions but newest Sun JDK).
>
> Any comments greatly appreciated.
>
> Best wishes
>
> Thomas
>
> P.S. At the end an error message appears, but I'm not
> able to sink it. I could run it in a terminal - but
> are there other possibilities?
>
> --- R code pasted into Rgui
>
> rm(list=ls())
> # see below for ouput,
> # used sink to get probale error messages
> # (doesn't work; can one "sink" error messages?)
> sink("k:/SJavaFault.rout")
> version
> # load SJava
> library(SJava)
> library(help=SJava)
> .JavaInit()
> # try SJava
> .Java("Math","PI")
> # load example
> source("d:/R/rw1062/library/SJava/examples/ttest.R")
> x<-rnorm(10)
> y<-rnorm(10,1)
> # test example, crashes after specifying x and y in the dialog and
pressing "Submit"
> dialog.t.test()
> # Rgui.exe still running as a process, but not an application (according
to task manager)
>
>
> --- Output of sink and library(help=...)
>
>          _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    6.2
> year     2003
> month    01
> day      10
> language R
> using JAVA_HOME = Y:/Java Development Kit/Java2sdk1.4/jre
>
> [...]
> Package: SJava
> Version: 0.65
> Date: 2002/07/17
> Title: The Omegahat interface for R and Java.
> Author: Duncan Temple Lang <duncan at research.bell-labs.com>, John
>         Chambers <jmc at research.bell-labs.com>
> Depends: R (>= 1.1.0)
> Maintainer: Duncan Temple Lang <duncan at research.bell-labs.com>
> Description: An interface from R to Java to create and call Java
>         objects and methods.
> License: GPL version 2 or newer. http://www.gnu.org/copyleft/gpl.html
> URL: http://www.omegahat.org/RSJava, http://www.omegahat.org
>         http://www.omegahat.org/bugs
> Built: R 1.6.2; Win32; Thu Feb 27 19:18:38 GMTST 2003
> [...]
>
> [1] 3.141593
> $id
> [1] "1"
>
> $value
> $value$actionPerformed
> function(ev) {
>    cmd <- ev$getActionCommand()
>    if(cmd == "Reset")
>      reset()
>    else {
>      print(compute())
>    }
>
>   NULL
>  }
> <environment: 013B8AC4>
>
>
> $className
> character(0)
>
> $targetClasses
> character(0)
>
> attr(,"class")
> [1] "AnonymousRReference"
>
> ---
>
> Thomas Hotz
> Research Associate in Medical Statistics
> University of Leicester
> United Kingdom
>
> Department of Epidemiology and Public Health
> 22-28 Princess Road West
> Leicester
> LE1 6TP
> Tel +44 116 252-5410
> Fax +44 116 252-5423
>
> Division of Medicine for the Elderly
> Department of Medicine
> The Glenfield Hospital
> Leicester
> LE3 9QP
> Tel +44 116 256-3643
> Fax +44 116 232-2976
>
>
> -----Original Message-----
> From: Duncan Murdoch [mailto:dmurdoch at pair.com]
> Sent: 03 May 2003 23:59
> To: tshi at itsa.ucsf.edu
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Memory leakage?
>
>
> On Sat, 03 May 2003 20:33:49 +0000, you wrote:
>
> >I haven't tried re-installing windows yet, because it seems to be a big
task
> >for me and also I kind of doubt that the problem is due to my own
> >computer(s), because the same problem happens to 3 different computers:
one
> >Dell desktop in school runing Win2K and R 1.6.1, my Dell laptop runing
Win
> >XP Professional Edition and R 1.7.0 and my new Dell desktop at home (just
> >bought less than a month and only a few basic softwares were installed)
> >runing Win XP Home Edition and R1.7.0.  (may be they're all from Dell
:-))
> >I'm still looking for the pattern of when this happens, but so far, it
seems
> >to be random.
>
> I don't think it's a Windows problem.  I've seen it occasionally, but
> not reproducibly.  If you can figure out some sequence of operations
> that reliably produces it, please let me know.
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From andy_liaw at merck.com  Thu May  8 16:15:50 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 08 May 2003 10:15:50 -0400
Subject: [R] approximation of CDF
Message-ID: <3A822319EB35174CA3714066D590DCD5C4FAE0@usrymx25.merck.com>

You may need to clarify your terminologies.  My understanding is that
function *approximation* is for the situation where you have x1,..., xn and
f(x1), ..., f(xn), without any error (a numerical analysis problem).
Function *estimation* is when f() is not known, but estimated from data (a
statistical problem).  Sounds like you need estimation, not approximation.
(There's duality between the two, but they are different problems.)

As Prof. Ripley suggested, most density estimators give you proper
densities, so integrating those will give you a proper CDF, in addition to
the monotonicity property that you mentioned (e.g., f(-Inf)=0, f(Inf)=1).

Andy 

> From: Khamenia, Valery [mailto:V.Khamenia at BioVisioN.de]
> 
> > Almost any method of fitting a density estimate would work on 
> > integrating (numerically) the result.
> 
> it is a nice idea concerning the monotony property, which 
> will be obtained automatically, but I am going to use results 
> of approximation analytically
> 
> > In particular, look at package polspline, where 
> > p(old)logspline does the integration for you.
> 
> thank you, I am going to install it.
> 
> > >   is there any package in R capable of smooth approximation of CDF
> > >   basing on given sample?  (Thus, I am not speaking about ecdf)
> > 
> > I think it _is_ an ECDF you want to approximate, since you mention
> > `sample' below.
> 
> no, it is not. I do not need the closeness to a ECDF but to a CDF.
> classic ECDF (like that implemented in stepfun) is yet another 
> approximation of CDF. In particular, if I try to pursue the best 
> approximation of any ECDF function in polynomial basis, it will 
> boost order of my polynomial approximation up to infinity. Meanwhile 
> the CDF might be linear in the corresponding range (we could take 
> uniform data as an example)
> 
> thank you for your reply,
> kind regards,
> Valery A.Khamenya
> --------------------------------------------------------------
> -------------
> Bioinformatics Department
> BioVisioN AG, Hannover
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From V.Khamenia at BioVisioN.de  Thu May  8 16:45:03 2003
From: V.Khamenia at BioVisioN.de (Khamenia, Valery)
Date: Thu, 8 May 2003 16:45:03 +0200 
Subject: AW: [R] approximation of CDF
Message-ID: <D15343265276D31197BC00A024A6C11077403E@EXS_BDC>

> You may need to clarify your terminologies.  My understanding is that
> function *approximation* is for the situation where you have 
> x1,..., xn and f(x1), ..., f(xn), without any error (a numerical 
> analysis problem). Function *estimation* is when f() is not known, 
> but estimated from data (a statistical problem).  Sounds like you 
> need estimation, not approximation.
> (There's duality between the two, but they are different problems.)

more then clear, thank you. Indeed I have missed here that 
f(x1), ..., f(xn) are usually *implied* to be without any error.
However except of this issue the difference is rather 
symbolical. Indeed, for ordered data the only difference 
between "estimation" and "approximation" is that the convergence 
properties and the model adequacy are discussed in statistical 
terms for "estimation", i.e. in terms of confidence intervals 
and p-values. On the contrary, for "approximation" just the 
metric (the functional being optimized) should be chosen 
and not necessarily that this metric should be interpretable 
in probabilistic terms. Indeed, we shouldn't 
forget, that "degrees of freedom" (which really could make 
a difference in this context) for ordered data have no sense, 
therefore, the difference between those two terms is rather 
symbolical and negligible. 

Actually, I have really forgotten to say what are the 
values which should be treated as "true values without 
any error" Than we have just an approximation task. Or?..

thank you for a reasonable note,
kind regards,
Valery A.Khamenya
---------------------------------------------------------------------------
Bioinformatics Department
BioVisioN AG, Hannover



From anoy69 at yahoo.com  Thu May  8 16:50:39 2003
From: anoy69 at yahoo.com (zhu wang)
Date: Thu, 8 May 2003 07:50:39 -0700 (PDT)
Subject: [R] All possible subset selection?
In-Reply-To: <Pine.LNX.4.44.0305080734340.18002-100000@gannet.stats>
Message-ID: <20030508145039.18740.qmail@web14406.mail.yahoo.com>

Thanks to Prof Brian Ripley for the valuable
illustration.

Zheng Huang & Zhu Wang

--- Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> On Wed, 7 May 2003, zhu wang wrote:
> 
> > I am wondering if there is a function in R to do
> all
> > possible subset selection, e.g. using AIC/BIC. It
> > seems to me the function step can not do all
> possible
> > selection.
> 
> That's right, and I know of no function. 
> Potentially the computational 
> burden is horrendous, even of sorting out which are
> valid subset models.
> For continuous (rather than categorical) variables,
> look at package leaps.
> 
> > I am also want to know why the following functions
> > give me different results. It seems I missed some
> > points here.
> > 
> > lm <- lm(y ~., data=somedata)
> > AIC(lm)
> > extractAIC(lm)
> 
> Please don't call the result by the name of a
> function!
> 
> extractAIC (as its help says) is a helper function
> for step/add1/drop1,
> and it is designed to report Cp in some lm cases
> when AIC is Cp plus a
> constant. It predates AIC by several years.
> 
> Remember that AIC is only defined up to an additive
> constant, because a 
> log-likelihood is (it depends on the dominating
> measure used).  
> extractAIC.lm and AIC.lm use different ones, and in
> the case that the 
> scale is known, they use different maximizations
> too.  (AIC.lm is only 
> appropriate if the scale (error variance) is
> unknown.)
> 
> -- 
> Brian D. Ripley,                 
> ripley at stats.ox.ac.uk
> Professor of Applied Statistics, 
> http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865
> 272861 (self)
> 1 South Parks Road,                     +44 1865
> 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865
> 272595
>



From ripley at stats.ox.ac.uk  Thu May  8 16:55:16 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 8 May 2003 15:55:16 +0100 (BST)
Subject: R crashes with package SJava; was [R] Memory leakage?
In-Reply-To: <1F2CE8D4B0195E488213E8B8CCF714860161B64A@saffron.cfs.le.ac.uk>
Message-ID: <Pine.LNX.4.44.0305081554090.22179-100000@gannet.stats>

On Thu, 8 May 2003, Hotz, T. wrote:

> As is visible from the output, I set JAVA_HOME properly 
> in my .Renviron file. Otherwise I couldn't even call .Java(). 
> However, I use R 1.6.2, maybe that's the problem (although the
> SJava version I use was built for R 1.6.2). Example calc() 
> doesn't cause R to crash, but gives me the following warning
> when called twice:
> 
> Warning message: 
> `restart' is deprecated.
> Use `try' instead.
> See ?Deprecated. 

That's because the code in calc.R is old (pre R 1.6.0).

> Moreover, I don't really understand the example: where am I
> supposed to get the result of the calculation? I don't see it
> in the Java Dialog, and can't spot it in the return value 
> either.

Simon Urbanek told me that was a bug in the Java code for that example 
....

> Regards
> 
> Thomas
> 
> -----Original Message-----
> From: Christian Schulz [mailto:ozric at web.de]
> Sent: 08 May 2003 14:46
> To: Hotz, T.; r-help at stat.math.ethz.ch
> Subject: Re: R crashes with package SJava; was [R] Memory leakage?
> 
> 
> Hmm,
> 
> this steps run without problems on my locale win2k.
> Perhaps you make the same mistake like me in the past
> and have no file named .Renviron  with entry
> 
> JAVA_HOME = c:/YourPath/j2re1.4.1_02
> 
> and saved in \rw1070 ?
> 
> >> library(sjava)
> using JAVA_HOME = c:/Programme/Java/j2re1.4.1_02
> >>.JavaInit()
> >>source("C:/Chris/dm/rw1070/library/SJava/examples/calc.R")
> >>calc()
> [[1]]
> $id
> [1] "1"
> 
> $value
> $value$actionPerformed
> function(ev) {
>    txt <- ev$getActionCommand()
>    back <- 0
>    if(txt == "=") {
>      txt <- input$getText()
>      val <- as.character(eval(parse(text=txt)))
>      input$setText(val)
>      jcombo$getModel()$insertElementAt(txt, as.integer(0))
>      return(NULL)
>    } else if(!is.na(match(txt, unaryOps))) {
>      if(txt == "()")
>        txt <- ""
>      val <- paste(txt, "()",sep="")
>      back <- -1
>    } else if(txt == "Clear") {
>       input$setText("")
>       return(NULL)
>    } else {
>      val <- txt
>    }
> 
>     doc <- input$getDocument()
>     doc$insertString(input$getCaretPosition(), val, NULL)
>     if(back < 0) {
>       input$setCaretPosition(as.integer(input$getCaretPosition() + back))
>     }
>  }
> <environment: 0194B3CC>
> 
> 
> $className
> character(0)
> 
> $targetClasses
> character(0)
> 
> attr(,"class")
> [1] "AnonymousRReference"
> 
> $input
> $key
> [1] "67"
> 
> $className
> [1] "javax.swing.plaf.metal.MetalComboBoxEditor$1"
> 
> attr(,"class")
> [1] "AnonymousOmegahatReference"
> 
> >>calc()
> 
> 
> 
> ----- Original Message -----
> From: "Hotz, T." <th50 at leicester.ac.uk>
> To: <r-help at stat.math.ethz.ch>
> Cc: "Duncan Murdoch" <dmurdoch at pair.com>; <tshi at itsa.ucsf.edu>
> Sent: Thursday, May 08, 2003 3:04 PM
> Subject: R crashes with package SJava; was [R] Memory leakage?
> 
> 
> > Dear all,
> >
> > Maybe this has something to do with R crashing?
> > When my R version crashes, there is Rgui.exe still
> > running in the background (i.e. W2K's task manager
> > recognises it only as a process, which apparently
> > is using almost 100% of the CPU).
> >
> > I can reproduce that by "using" the SJava package
> > (from Brian Ripley's homepage, as suggested on
> > http://www.omegahat.org/RSJava/). When loading the
> > package, and running the ttest example, my Rgui.exe
> > crashes, and I end up with the process Rgui.exe
> > still alive using the CPU extensively. The same
> > happens on my stand-alone machine at home (with the
> > same OS and R versions but newest Sun JDK).
> >
> > Any comments greatly appreciated.
> >
> > Best wishes
> >
> > Thomas
> >
> > P.S. At the end an error message appears, but I'm not
> > able to sink it. I could run it in a terminal - but
> > are there other possibilities?
> >
> > --- R code pasted into Rgui
> >
> > rm(list=ls())
> > # see below for ouput,
> > # used sink to get probale error messages
> > # (doesn't work; can one "sink" error messages?)
> > sink("k:/SJavaFault.rout")
> > version
> > # load SJava
> > library(SJava)
> > library(help=SJava)
> > .JavaInit()
> > # try SJava
> > .Java("Math","PI")
> > # load example
> > source("d:/R/rw1062/library/SJava/examples/ttest.R")
> > x<-rnorm(10)
> > y<-rnorm(10,1)
> > # test example, crashes after specifying x and y in the dialog and
> pressing "Submit"
> > dialog.t.test()
> > # Rgui.exe still running as a process, but not an application (according
> to task manager)
> >
> >
> > --- Output of sink and library(help=...)
> >
> >          _
> > platform i386-pc-mingw32
> > arch     i386
> > os       mingw32
> > system   i386, mingw32
> > status
> > major    1
> > minor    6.2
> > year     2003
> > month    01
> > day      10
> > language R
> > using JAVA_HOME = Y:/Java Development Kit/Java2sdk1.4/jre
> >
> > [...]
> > Package: SJava
> > Version: 0.65
> > Date: 2002/07/17
> > Title: The Omegahat interface for R and Java.
> > Author: Duncan Temple Lang <duncan at research.bell-labs.com>, John
> >         Chambers <jmc at research.bell-labs.com>
> > Depends: R (>= 1.1.0)
> > Maintainer: Duncan Temple Lang <duncan at research.bell-labs.com>
> > Description: An interface from R to Java to create and call Java
> >         objects and methods.
> > License: GPL version 2 or newer. http://www.gnu.org/copyleft/gpl.html
> > URL: http://www.omegahat.org/RSJava, http://www.omegahat.org
> >         http://www.omegahat.org/bugs
> > Built: R 1.6.2; Win32; Thu Feb 27 19:18:38 GMTST 2003
> > [...]
> >
> > [1] 3.141593
> > $id
> > [1] "1"
> >
> > $value
> > $value$actionPerformed
> > function(ev) {
> >    cmd <- ev$getActionCommand()
> >    if(cmd == "Reset")
> >      reset()
> >    else {
> >      print(compute())
> >    }
> >
> >   NULL
> >  }
> > <environment: 013B8AC4>
> >
> >
> > $className
> > character(0)
> >
> > $targetClasses
> > character(0)
> >
> > attr(,"class")
> > [1] "AnonymousRReference"
> >
> > ---
> >
> > Thomas Hotz
> > Research Associate in Medical Statistics
> > University of Leicester
> > United Kingdom
> >
> > Department of Epidemiology and Public Health
> > 22-28 Princess Road West
> > Leicester
> > LE1 6TP
> > Tel +44 116 252-5410
> > Fax +44 116 252-5423
> >
> > Division of Medicine for the Elderly
> > Department of Medicine
> > The Glenfield Hospital
> > Leicester
> > LE3 9QP
> > Tel +44 116 256-3643
> > Fax +44 116 232-2976
> >
> >
> > -----Original Message-----
> > From: Duncan Murdoch [mailto:dmurdoch at pair.com]
> > Sent: 03 May 2003 23:59
> > To: tshi at itsa.ucsf.edu
> > Cc: r-help at stat.math.ethz.ch
> > Subject: Re: [R] Memory leakage?
> >
> >
> > On Sat, 03 May 2003 20:33:49 +0000, you wrote:
> >
> > >I haven't tried re-installing windows yet, because it seems to be a big
> task
> > >for me and also I kind of doubt that the problem is due to my own
> > >computer(s), because the same problem happens to 3 different computers:
> one
> > >Dell desktop in school runing Win2K and R 1.6.1, my Dell laptop runing
> Win
> > >XP Professional Edition and R 1.7.0 and my new Dell desktop at home (just
> > >bought less than a month and only a few basic softwares were installed)
> > >runing Win XP Home Edition and R1.7.0.  (may be they're all from Dell
> :-))
> > >I'm still looking for the pattern of when this happens, but so far, it
> seems
> > >to be random.
> >
> > I don't think it's a Windows problem.  I've seen it occasionally, but
> > not reproducibly.  If you can figure out some sequence of operations
> > that reliably produces it, please let me know.
> >
> > Duncan Murdoch
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From fharrell at virginia.edu  Thu May  8 16:59:45 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Thu, 8 May 2003 10:59:45 -0400
Subject: [R] natural splines
In-Reply-To: <Pine.GSO.4.33.0305081506001.27182-100000@holyrood.ed.ac.uk>
References: <Pine.GSO.4.33.0305081506001.27182-100000@holyrood.ed.ac.uk>
Message-ID: <20030508105945.5dbdab0c.fharrell@virginia.edu>

On Thu, 8 May 2003 15:07:56 +0100 (BST)
iwhite at staffmail.ed.ac.uk wrote:

> Apologies if this is this too obscure for R-help.
> 
> In package splines, ns(x,,knots,intercept=TRUE) produces an n by K+2
> matrix N, the values of K+2 basis functions for the natural splines with K
> (internal) knots, evaluated at x.  It does this by first generating an
> n by K+4 matrix B of unconstrained splines, then postmultiplying B by
> H, a K+4 by K+2 representation of the nullspace of C (2 by K+4), which
> contains the 2nd derivatives of the unconstrained splines evaluated at
> the boundary knots.  E.g. see Hastie and Tibshirani, Generalized Additive
> Models, exercise 2.5, p36.  The QR decomposition is used to get H.
> 
> This can produce basis functions which, while technically correct (they
> span the K+2 dim space of natural splines), can be counterintuitive.
> E.g. equally spaced knots symmetrically placed between the data extremes
> can produce very asymmetric arrangements, with N(K+2) not the mirror image
> of N(1), for example, and considerable loss of sparseness.
> 
> This approach works for any basis B, but for B-splines, the second
> derivatives are zero for all the unconstrained basis functions, apart
> from 3 at each end. All that is required is to combine these 3 so that
> the contributions to the 2nd derivatives cancel. In other words, we
> only need to find the null space of two 2 by 3 matrices, rather than a
> 2 by K+4. If the left-most internal knots are t(1) and t(2), and the
> left-hand boundary knot is t(0), we can replace B(1...3) with
> 
> B(1)+B(2)+B(3) and [t(2)-t(0)]*B(2) + [t(1)+t(2)-2*t(0)]*B(1),
> 
> (for example), and similarly at the right-hand end.
> 
> This seems simpler and more elegant than brute force QR on the full
> matrix of derivatives. But I may have missed some reason why it can't be
> used. Perhaps it doesn't work when intercept=FALSE?
> 
> ======================================
> I.White
> ICAPB, University of Edinburgh
> Ashworth Laboratories, West Mains Road
> Edinburgh EH9 3JT
> Fax: 0131 650 6564  Tel: 0131 650 5490
> E-mail: iwhite at staffmail.ed.ac.uk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

This is also a vote for using the truncated power basis which is extremely simple and exceptionally fast for large datasets (see the rcspline.eval function in the Hmisc package).  With modern matrix arithmetic (as in S), the collinearity of the bases produced by these simple regression splines is a moot point.
---
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From deepayan at stat.wisc.edu  Thu May  8 17:05:40 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 8 May 2003 10:05:40 -0500
Subject: [R] again troubles with lattice
In-Reply-To: <3537.030508@eimb.ru>
References: <3537.030508@eimb.ru>
Message-ID: <200305081005.40803.deepayan@stat.wisc.edu>

On Thursday 08 May 2003 03:54 am, Wladimir Eremeev wrote:
> Dear r-help community,
>
>   Thank you for your previous answers!
>
>   Now I have strange behaviour of the lattice library funcitons.
>   They do not draw graphics in the file when called from the script.
>   I created the script file, called, for example, "a.R", containing
>   the following
>
> library(lattice);
> trellis.device(device="png",
>                filename="a.png",
>                color = FALSE,
>                bg = "white",
>                width=600,
>                height=800
>               );
>
> xyplot(ac15$value~ac15$year|factor(lon),data=ac15,
>        type="o",
>        layout=c(1,18),
>        xlab="year",
>        );
> dev.off();

You have to print the result of xyplot, which does not happen inside another 
function unless you explicitly call print().

This is obviously somewhat confusing because base R graphics does not behave 
this way, and has led to many similar questions on this list. help(xyplot) 
has:

Value:

     An object of class ``trellis''. The `update' method can be used to
     update components of the object and the `print' method (usually
     called by default) will plot it on an appropriate plotting device.


and help(Lattice) has:


Note:

     High level Lattice functions (like `xyplot') are different from
     conventional S graphics functions because they don't actually draw
     anything. Instead, they return an object of class ``trellis''
     which has to be then `print'ed. This often causes confusion when
     the high level functions are called inside another function (most
     often `source') and hence don't produce any output.


Can you suggest any other place in the documentation where explaining this 
would have helped you find it ?

Deepayan



From brahm at alum.mit.edu  Thu May  8 17:25:55 2003
From: brahm at alum.mit.edu (David Brahm)
Date: Thu, 8 May 2003 11:25:55 -0400
Subject: [R] Avoiding loops to spare time and memory
References: <3EBA1C34.1FE1477C@kfn.uni-hannover.de>
Message-ID: <16058.30467.248106.535661@arbres1a.fmr.com>

Dirk Enzmann <enzmann at kfn.uni-hannover.de> wrote:
> Is it possible to avoid the loop in the following function (or make the
> function otherwise more efficient)...

Prof Brian Ripley <ripley at stats.ox.ac.uk> replied:
> My guess is that most of the time is being spent in eigen(); if so you 
> would have to use a different approach to gain much speed.

If M is an (p x q) matrix with q>>p, then at most the first p eigenvalues of
M'M are nonzero, and they can be found more efficiently using the left side of:
  La.svd(M)$d^2  =  eigen(crossprod(M))$values[1:p]

I've re-written your function for the situation items >> cases (I leave the
opposite situation as an exercise).  I also threw in some sweep's, a zapsmall,
and a few other tricks.  A timing test shows it runs 57x faster for this
example (with items=500 and cases=10):
  R> set.seed(1)
  R> system.time(res1 <- RanEigen.orig(500,10,30))
     [1] 229.80   0.07 230.38   0.00   0.00
  R> set.seed(1)
  R> system.time(res2 <- RanEigen(500,10,30))
     [1] 4.00 0.02 4.07 0.00 0.00
  R> all.equal(res1, res2)
     [1] TRUE

and here's my function:

RanEigen <- function(items, cases, sample) {
  if (items < cases) stop("I assume items >= cases")
  EV <- matrix(0, sample, items)
  for (i in 1:sample) {
    X <- matrix(rnorm(cases*items), nrow=cases)
    Xb <- sweep(X, 2, colMeans(X))
    S <- crossprod(Xb)
    Xc <- sweep(Xb, 2, 1/sqrt(diag(S)), "*")
    EV[i, 1:cases] <- zapsmall(La.svd(Xc)$d^2)  # The rest are zero
  }
  REigV <- cbind(1:items, colMeans(EV))
  dimnames(REigV) <- list(rep('',items), c(' ','Eigenvalue'))
  REigV
}

-- 
                              -- David Brahm (brahm at alum.mit.edu)



From angel_lul at hotmail.com  Thu May  8 17:38:55 2003
From: angel_lul at hotmail.com (Angel -)
Date: Thu, 08 May 2003 15:38:55 +0000
Subject: [R] nls, restrict parameter values
Message-ID: <Law11-F179ir3wSimD300007d65@hotmail.com>

Hi,
I posted a question (bellow) a few weeks ago and had a reply (thanks 
Christian) that partly solves the problem, but I still would like to be able 
to restrict some of the independent variables in a nls model to be always 
 >0, (is there a way to do it)??
Thanks,
Angel



>From: "Christian Ritz" <ritz at dina.kvl.dk>
>To: "Angel -" <angel_lul at hotmail.com>
>CC: <r-help at stat.math.ethz.ch>
>Subject: Re: [R] nls: Missing value or an Infinity produced when evaluating 
>the model
>Date: Wed, 23 Apr 2003 15:22:37 +0200
>
>Hi Angel,
>
>I tried reparametrise your model, setting:
>
>BirthMass^0.25=u
>MaxMass^0.25=v
>
>and giving the following formula in R:
>
>GrowthModel<-nls(BodyMass~(((1-(1-u/v)*exp(-a*Time/(4*v)))^4)*v^4),data=grow
>th,start=c(u=4,v=5,a=1.5),trace=TRUE)
>
>And this works for me, but the u estimate is negative (not significantly
>different from 0, though).
>
>Christian
>
>----- Original Message -----
>From: "Angel -" <angel_lul at hotmail.com>
>To: <r-help at stat.math.ethz.ch>
>Sent: Wednesday, April 23, 2003 2:29 PM
>Subject: [R] nls: Missing value or an Infinity produced when evaluating the
>model
>
>
> > Hi,
> > I am trying to fit a sigmoid curve to some data with nls but I am 
>getting
> > into some trouble.
> > Seems that the optimization method is getting down to some parameter
> > estimates that make the equation unsolvable. This is an example:
> >
> >> growth<-data.frame(Time=c(5,7,9,11,13,15,17,19,21,23,25,27),BodyMass=c
> >(45,85,125,210,300,485,570,700,830,940,1030,1120))

> >> 
>GrowthModel<-nls(BodyMass~(((1-(1-((BirthMass/MaxMass)^0.25))*exp(-a*Time/
> >(4*MaxMass^0.25)))^4)*MaxMass),data=growth,start=c
> >(BirthMass=3,MaxMass=2500,a=1.5),trace=TRUE)

> >56043.86 :     3.0 2500.0    1.5 >Error in numericDeriv(form[[3]], 
>names(ind), env) : >        Missing value or an Infinity produced when 
>evaluating the model
> >
> >Is there anyway I can restrict the parameter values used so it doesn't 
>get to this no return point.
> >Any other alternatives are also very welcome!
> >Thanks in advance,
> >Angel

_________________________________________________________________
Use MSN Messenger to send music and pics to your friends 
http://www.msn.co.uk/messenger



From cortega at unitec.edu  Thu May  8 17:43:43 2003
From: cortega at unitec.edu (Cesar Ortega)
Date: Thu, 08 May 2003 17:43:43 +0200
Subject: [R] EXCEL FILE
Message-ID: <2e2618bd438755d6.438755d62e2618bd@unitec.edu>

Hi gruop,



Pardon my question, but how could I import a excel file with 2 columns 
to R and then work with them as vecors.

Thanks in advance,



From Kosenkov.Kirill at nac.spb.ru  Thu May  8 18:01:25 2003
From: Kosenkov.Kirill at nac.spb.ru (Kosenkov Kirill)
Date: Thu, 08 May 2003 20:01:25 +0400
Subject: [R] function to compute entropy
Message-ID: <3EBA7F55.40400@nac.spb.ru>

Maybe its slightly off-topic, but can anybody
help with computing entropy on matrix of probabilities?

Guess we have a matrix of probabilites, A, 2x2, something
like this:
    z
x   0     1     2     3     4
   0 0.063 0.018 0.019 0.016 0.000
   1 0.011 0.162 0.040 0.042 0.003
   2 0.015 0.030 0.164 0.033 0.002
   3 0.012 0.035 0.036 0.159 0.002
   4 0.004 0.021 0.018 0.013 0.082

sum(A)=1

Can i compute entropy like this:
entropy<-sum(A*log2(A)) ?

is there a function for computing entropy in R?

Thanx.



From spencer.graves at pdf.com  Thu May  8 18:08:12 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 08 May 2003 09:08:12 -0700
Subject: [R] nls, restrict parameter values
References: <Law11-F179ir3wSimD300007d65@hotmail.com>
Message-ID: <3EBA80EC.2050403@pdf.com>

If I have a parameter I want to be positive, I replace it by its 
logaritm.  That sends 0 to (-Inf).  Often when I do this, I also get a 
log(likelihood) that is more closely parabolic, which reduces parameter 
effects and makes the standard normal approximations more accurate.

hth.  spencer graves

Angel - wrote:
> Hi,
> I posted a question (bellow) a few weeks ago and had a reply (thanks 
> Christian) that partly solves the problem, but I still would like to be 
> able to restrict some of the independent variables in a nls model to be 
> always >0, (is there a way to do it)??
> Thanks,
> Angel
> 
> 
> 
>> From: "Christian Ritz" <ritz at dina.kvl.dk>
>> To: "Angel -" <angel_lul at hotmail.com>
>> CC: <r-help at stat.math.ethz.ch>
>> Subject: Re: [R] nls: Missing value or an Infinity produced when 
>> evaluating the model
>> Date: Wed, 23 Apr 2003 15:22:37 +0200
>>
>> Hi Angel,
>>
>> I tried reparametrise your model, setting:
>>
>> BirthMass^0.25=u
>> MaxMass^0.25=v
>>
>> and giving the following formula in R:
>>
>> GrowthModel<-nls(BodyMass~(((1-(1-u/v)*exp(-a*Time/(4*v)))^4)*v^4),data=grow 
>>
>> th,start=c(u=4,v=5,a=1.5),trace=TRUE)
>>
>> And this works for me, but the u estimate is negative (not significantly
>> different from 0, though).
>>
>> Christian
>>
>> ----- Original Message -----
>> From: "Angel -" <angel_lul at hotmail.com>
>> To: <r-help at stat.math.ethz.ch>
>> Sent: Wednesday, April 23, 2003 2:29 PM
>> Subject: [R] nls: Missing value or an Infinity produced when 
>> evaluating the
>> model
>>
>>
>> > Hi,
>> > I am trying to fit a sigmoid curve to some data with nls but I am 
>> getting
>> > into some trouble.
>> > Seems that the optimization method is getting down to some parameter
>> > estimates that make the equation unsolvable. This is an example:
>> >
>> >> growth<-data.frame(Time=c(5,7,9,11,13,15,17,19,21,23,25,27),BodyMass=c
>> >(45,85,125,210,300,485,570,700,830,940,1030,1120))
> 
> 
>> >> 
>> GrowthModel<-nls(BodyMass~(((1-(1-((BirthMass/MaxMass)^0.25))*exp(-a*Time/ 
>>
>> >(4*MaxMass^0.25)))^4)*MaxMass),data=growth,start=c
>> >(BirthMass=3,MaxMass=2500,a=1.5),trace=TRUE)
> 
> 
>> >56043.86 :     3.0 2500.0    1.5 >Error in numericDeriv(form[[3]], 
>> names(ind), env) : >        Missing value or an Infinity produced when 
>> evaluating the model
>> >
>> >Is there anyway I can restrict the parameter values used so it 
>> doesn't get to this no return point.
>> >Any other alternatives are also very welcome!
>> >Thanks in advance,
>> >Angel
> 
> 
> _________________________________________________________________
> Use MSN Messenger to send music and pics to your friends 
> http://www.msn.co.uk/messenger
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From tlumley at u.washington.edu  Thu May  8 18:09:56 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 8 May 2003 09:09:56 -0700 (PDT)
Subject: [R] again troubles with lattice
In-Reply-To: <200305081005.40803.deepayan@stat.wisc.edu>
Message-ID: <Pine.A41.4.44.0305080905160.67374-100000@homer25.u.washington.edu>

On Thu, 8 May 2003, Deepayan Sarkar wrote:

> You have to print the result of xyplot, which does not happen inside another
> function unless you explicitly call print().
>
> This is obviously somewhat confusing because base R graphics does not behave
> this way, and has led to many similar questions on this list. help(xyplot)
> has:
>

Perhaps a FAQ entry?

Q: Why don't lattice/trellis graphics work?

A: The most likely reason is that you forgot to tell R to display the
graph.  Lattice functions such as xyplot() create a graph object, but do
not display it (the same is true of Trellis graphics in S-PLUS).  The
print() method for the graph object produces the actual display.  When you
use these functions interactively at the command line the result is
automatically print()ed, but in source() or inside your own functions you
will need an explicit print() statement.


	-thomas



From Kosenkov.Kirill at nac.spb.ru  Thu May  8 18:08:04 2003
From: Kosenkov.Kirill at nac.spb.ru (Kosenkov Kirill)
Date: Thu, 08 May 2003 20:08:04 +0400
Subject: [R] border of bars in lattice barchart
Message-ID: <3EBA80E4.9030800@nac.spb.ru>

Hello!

How to change a color (or linewidth) of
border in lattice 'barchart'?

I am trying

barchart(
	(......) - my arguments
            panel=function(x,y,color,subscripts,groups,...)
            {
panel.barchart(x=x,y=y,box.ratio=2,col=color,border=FALSE)
            }))

or
...
panel.barchart(x=x,y=y,box.ratio=2,col=color,border='transparent')
...
or
panel.barchart(x=x,y=y,box.ratio=2,col=color,border='red')

but it has no effect.

is there any other way to change a barchart border?



From spencer.graves at pdf.com  Thu May  8 18:14:38 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 08 May 2003 09:14:38 -0700
Subject: [R] function to compute entropy
References: <3EBA7F55.40400@nac.spb.ru>
Message-ID: <3EBA826E.4030204@pdf.com>

Have you considered:

	entropy<-sum(A*logb(A, 2))

hth.  spencer graves

Kosenkov Kirill wrote:
> Maybe its slightly off-topic, but can anybody
> help with computing entropy on matrix of probabilities?
> 
> Guess we have a matrix of probabilites, A, 2x2, something
> like this:
>    z
> x   0     1     2     3     4
>   0 0.063 0.018 0.019 0.016 0.000
>   1 0.011 0.162 0.040 0.042 0.003
>   2 0.015 0.030 0.164 0.033 0.002
>   3 0.012 0.035 0.036 0.159 0.002
>   4 0.004 0.021 0.018 0.013 0.082
> 
> sum(A)=1
> 
> Can i compute entropy like this:
> entropy<-sum(A*log2(A)) ?
> 
> is there a function for computing entropy in R?
> 
> Thanx.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From umalvarez at fata.unam.mx  Thu May  8 17:32:46 2003
From: umalvarez at fata.unam.mx (Ulises Mora Alvarez)
Date: Thu, 8 May 2003 10:32:46 -0500 (CDT)
Subject: [R] EXCEL FILE
In-Reply-To: <2e2618bd438755d6.438755d62e2618bd@unitec.edu>
Message-ID: <Pine.LNX.4.44.0305081030300.18766-100000@fata.unam.mx>

Hi!

Take a look at 'read.table' which will aloow you to import your excell 
file as a data frame. Then, you'll be able to easily construct your 
vectors.

Regards. 


On Thu, 8 May 2003, Cesar Ortega wrote:

> Hi gruop,
> 
> 
> 
> Pardon my question, but how could I import a excel file with 2 columns 
> to R and then work with them as vecors.
> 
> Thanks in advance,
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Ulises M. Alvarez
LAB. DE ONDAS DE CHOQUE
FISICA APLICADA Y TECNOLOGIA AVANZADA
UNAM
umalvarez at fata.unam.mx



From umalvarez at fata.unam.mx  Thu May  8 17:41:17 2003
From: umalvarez at fata.unam.mx (Ulises Mora Alvarez)
Date: Thu, 8 May 2003 10:41:17 -0500 (CDT)
Subject: [R] border of bars in lattice barchart
In-Reply-To: <3EBA80E4.9030800@nac.spb.ru>
Message-ID: <Pine.LNX.4.44.0305081034050.18766-100000@fata.unam.mx>

Hi!

Take a look at:

'trellis.par.get', and
'trellis.par.set'

Good look!


On Thu, 8 May 2003, Kosenkov Kirill wrote:

> Hello!
> 
> How to change a color (or linewidth) of
> border in lattice 'barchart'?
> 
> I am trying
> 
> barchart(
> 	(......) - my arguments
>             panel=function(x,y,color,subscripts,groups,...)
>             {
> panel.barchart(x=x,y=y,box.ratio=2,col=color,border=FALSE)
>             }))
> 
> or
> ...
> panel.barchart(x=x,y=y,box.ratio=2,col=color,border='transparent')
> ...
> or
> panel.barchart(x=x,y=y,box.ratio=2,col=color,border='red')
> 
> but it has no effect.
> 
> is there any other way to change a barchart border?
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Ulises M. Alvarez
LAB. DE ONDAS DE CHOQUE
FISICA APLICADA Y TECNOLOGIA AVANZADA
UNAM
umalvarez at fata.unam.mx



From deepayan at stat.wisc.edu  Thu May  8 18:38:35 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 8 May 2003 11:38:35 -0500
Subject: [R] border of bars in lattice barchart
In-Reply-To: <3EBA80E4.9030800@nac.spb.ru>
References: <3EBA80E4.9030800@nac.spb.ru>
Message-ID: <200305081138.35548.deepayan@stat.wisc.edu>

On Thursday 08 May 2003 11:08 am, Kosenkov Kirill wrote:
> Hello!
>
> How to change a color (or linewidth) of
> border in lattice 'barchart'?
>
> I am trying
>
> barchart(
> 	(......) - my arguments
>             panel=function(x,y,color,subscripts,groups,...)
>             {
> panel.barchart(x=x,y=y,box.ratio=2,col=color,border=FALSE)
>             }))
>
> or
> ...
> panel.barchart(x=x,y=y,box.ratio=2,col=color,border='transparent')
> ...
> or
> panel.barchart(x=x,y=y,box.ratio=2,col=color,border='red')
>
> but it has no effect.
>
> is there any other way to change a barchart border?


Write your own panel function. Start with the default (panel.barchart), and in 
the appropriate grid.rect() calls, change the 

gp = gpar(fill = <...>) 

to 

gp = gpar(fill = <...>, col = <whatever you want>, lwd = <whatever you want>) 

Deepayan



From jfkincaidsu at netscape.net  Thu May  8 18:43:47 2003
From: jfkincaidsu at netscape.net (Joel Kincaid)
Date: Thu, 08 May 2003 12:43:47 -0400
Subject: [R] EXCEL FILE
References: <2e2618bd438755d6.438755d62e2618bd@unitec.edu>
Message-ID: <3EBA8943.8050304@netscape.net>

Use 'save as' in excel to create 'foo.csv' and then

read.csv(file='foo.csv',sep',',header=T)

(use header=T only if first row has labels, and you may need to include 
a path with your filename)

cheers,
Joel

cortega at unitec.edu wrote:
> Hi gruop,
> 
> 
> 
> Pardon my question, but how could I import a excel file with 2 columns 
> to R and then work with them as vecors.
> 
> Thanks in advance,
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


-- 
Your favorite stores, helpful shopping tools and great gift ideas.
Experience the convenience of buying online with Shop at Netscape!
http://shopnow.netscape.com/



From xirui at cs.tu-berlin.de  Thu May  8 18:45:19 2003
From: xirui at cs.tu-berlin.de (Xirui Yang)
Date: Thu, 8 May 2003 18:45:19 +0200 (MEST)
Subject: [R] how to write text into a file
Message-ID: <Pine.SOL.4.53.0305081839260.14610@conde>

Hello,

Would somebody tell me how to write the text result into a postscript
file?  The command postscript() sents only the graphics output into
PostScript files.

best wishes,
Xirui



From alobo at ija.csic.es  Thu May  8 20:03:25 2003
From: alobo at ija.csic.es (Agustin Lobo)
Date: Thu, 8 May 2003 20:03:25 +0200 (MET DST)
Subject: [R] proj4
Message-ID: <Pine.OSF.3.91.1030508200014.24678h-100000@paleo.ija.csic.es>


Hi!

Does anyone know if there is a package to
call proj4 from R (or python)?
(proj4: library to make coordinate conversions
betwee different projections, http://remotesensing.org/proj/)

Thanks

Agus

Dr. Agustin Lobo
Instituto de Ciencias de la Tierra (CSIC)
Lluis Sole Sabaris s/n
08028 Barcelona SPAIN
tel 34 93409 5410
fax 34 93411 0012
alobo at ija.csic.es



From jerome at hivnet.ubc.ca  Thu May  8 20:04:01 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Thu, 8 May 2003 11:04:01 -0700
Subject: [R] how to write text into a file
In-Reply-To: <Pine.SOL.4.53.0305081839260.14610@conde>
References: <Pine.SOL.4.53.0305081839260.14610@conde>
Message-ID: <200305081809.LAA24996@hivnet.ubc.ca>


I'd suggest to write your text into a text file. See ?cat . In particular, 
look at the "file" option.

I wonder why you want to have your text in a postscript file rather than 
a text file. However, you can probably convert your text file using some 
utility of your OS. E.g., you could print it to a ps file instead of a 
printer.

HTH,
Jerome

On May 8, 2003 09:45 am, Xirui Yang wrote:
> Hello,
>
> Would somebody tell me how to write the text result into a postscript
> file?  The command postscript() sents only the graphics output into
> PostScript files.
>
> best wishes,
> Xirui
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From yanyu at cs.ucla.edu  Thu May  8 20:21:37 2003
From: yanyu at cs.ucla.edu (Yan Yu)
Date: Thu, 8 May 2003 11:21:37 -0700 (PDT)
Subject: [R] Kriging function ("prmat" and "semat") in spatial package
Message-ID: <Pine.SOL.4.33.0305081055160.20558-100000@panther.cs.ucla.edu>

Hello, there, I have two Qs about the kriging function in spatial pakcage.

(1) From what I read in some textbooks,
Kriging procedure is supposed to honor the sample data point, which means
at the sampling data point, the kriging value should be the same as the
input value, and the estimation variance(error) is 0.
but from my initial experience with "prmat" and "semat" function in the
"spatial" package, this is not true.
I am wondering did anyone  used those kriging functions have similar
experience? OR I used it wrong? (although I believe I used the function
correctly:)

(2) if consider x coordinate as row index, and y coordinate as column
index, the returned value from prmat, and semat seems to be stored
in column first order(i.e., first the 1st column, then the 2nd column..).
since the data order of returned valus is NOT explicitly specified in the
manual, and almost data from everywhere else I have seen is stored in row
first order, It would be nice if someone could confirm me on this.

thanks a lot in advance,
yan



From ripley at stats.ox.ac.uk  Thu May  8 20:52:58 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 8 May 2003 19:52:58 +0100 (BST)
Subject: [R] Kriging function ("prmat" and "semat") in spatial package
In-Reply-To: <Pine.SOL.4.33.0305081055160.20558-100000@panther.cs.ucla.edu>
Message-ID: <Pine.LNX.4.44.0305081945330.26156-100000@gannet.stats>

On Thu, 8 May 2003, Yan Yu wrote:

> Hello, there, I have two Qs about the kriging function in spatial pakcage.
> 
> (1) From what I read in some textbooks,
> Kriging procedure is supposed to honor the sample data point, which means
> at the sampling data point, the kriging value should be the same as the
> input value, and the estimation variance(error) is 0.
> but from my initial experience with "prmat" and "semat" function in the
> "spatial" package, this is not true.
> I am wondering did anyone  used those kriging functions have similar
> experience? OR I used it wrong? (although I believe I used the function
> correctly:)

You read the wrong textbooks!  How about reading the one that this code
was written to support?  Note that prmat and semat are not predicting at
the data points.  Even if you predict at the same point, this is taking a
new sample, not the previous sample.  So it will interpolate iff there is
no nugget effect: computationally you may see small inaccuracies since the
distances are binned.

> (2) if consider x coordinate as row index, and y coordinate as column
> index, the returned value from prmat, and semat seems to be stored
> in column first order(i.e., first the 1st column, then the 2nd column..).
> since the data order of returned valus is NOT explicitly specified in the
> manual, and almost data from everywhere else I have seen is stored in row
> first order, It would be nice if someone could confirm me on this.

*All* R matrices are stored in column first order ... so why does this
need to be specified on that help page?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Thu May  8 21:10:13 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Thu, 08 May 2003 19:10:13 -0000
Subject: [R] EXCEL FILE
In-Reply-To: <3EBA8943.8050304@netscape.net>
References: <2e2618bd438755d6.438755d62e2618bd@unitec.edu>
	<3EBA8943.8050304@netscape.net>
Message-ID: <x2k7d1uu71.fsf@biostat.ku.dk>

Joel Kincaid <jfkincaidsu at netscape.net> writes:

> Use 'save as' in excel to create 'foo.csv' and then
> 
> read.csv(file='foo.csv',sep',',header=T)

Those are the defaults... read.csv(file='foo.csv') should do. Use
header=FALSE if the header is absent. Notice also that in some
locales, CSV files have "," for decimal separator and ";" for the
value. That's where read.csv2 is relevant.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From zedshaw at zedshaw.com  Thu May  8 21:34:11 2003
From: zedshaw at zedshaw.com (Zed Shaw)
Date: Thu, 8 May 2003 12:34:11 -0700
Subject: [R] C++ - R - example
In-Reply-To: <6A4BCEF0FD65344A8F496D7E520DD8B9023E90A2@lobster.zhwin.ch>
Message-ID: <0B29229E-818C-11D7-8675-00039391E298@zedshaw.com>

Hi,

I have a fairly complete example of this in the Obversive project 
(http://obversive.sf.net) in our RBackend component.  You may even be 
able to re-use our RBackend depending on the type of programming you're 
using.  Please contact me off line to discuss it further.

Zed A. Shaw



On Tuesday, May 6, 2003, at 02:57 AM, Untern?hrer Thomas, uth wrote:

>
> Hi,
>
> Does anybody has a simple example (a for loop, or so) how to use a 
> C-function
> In R?
> If it's possible, a *.cpp-file and what I need (wrapper or what ever).
> I'm absolutly not a C++-hacker!
>
> I try several ways, was reading the "writing R extension" and the 
> windows-FAQ, but failed.
>
> I try to programm a matrix inversion in a for-loop in C, which needs 
> much time in R and want to
> load it as a function with dynload and .C into R.
> If somebody has already done it...
>
> I use VC++ and R 1.6.2
>
>
> Thanks a lot
>
> Thomas
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
-----
Zed A. Shaw
http://www.zedshaw.com/



From yanyu at cs.ucla.edu  Thu May  8 21:36:46 2003
From: yanyu at cs.ucla.edu (Yan Yu)
Date: Thu, 8 May 2003 12:36:46 -0700 (PDT)
Subject: [R] Kriging function ("prmat" and "semat") in spatial package
In-Reply-To: <Pine.LNX.4.44.0305081945330.26156-100000@gannet.stats>
Message-ID: <Pine.SOL.4.33.0305081231170.27619-100000@panther.cs.ucla.edu>

Thanks a lot for clarification!
Please forgive my ignorance on some R basics,
It is good to know that all R matrices are stored in column first order:)
it would be nice if it could be documented, so that new users to R can
quickly get to where they want w/o first going through some systematic R
learning..

thanks,
yan


On Thu, 8 May 2003, Prof Brian Ripley wrote:

> On Thu, 8 May 2003, Yan Yu wrote:
>
> > Hello, there, I have two Qs about the kriging function in spatial pakcage.
> >
> > (1) From what I read in some textbooks,
> > Kriging procedure is supposed to honor the sample data point, which means
> > at the sampling data point, the kriging value should be the same as the
> > input value, and the estimation variance(error) is 0.
> > but from my initial experience with "prmat" and "semat" function in the
> > "spatial" package, this is not true.
> > I am wondering did anyone  used those kriging functions have similar
> > experience? OR I used it wrong? (although I believe I used the function
> > correctly:)
>
> You read the wrong textbooks!  How about reading the one that this code
> was written to support?  Note that prmat and semat are not predicting at
> the data points.  Even if you predict at the same point, this is taking a
> new sample, not the previous sample.  So it will interpolate iff there is
> no nugget effect: computationally you may see small inaccuracies since the
> distances are binned.
>
> > (2) if consider x coordinate as row index, and y coordinate as column
> > index, the returned value from prmat, and semat seems to be stored
> > in column first order(i.e., first the 1st column, then the 2nd column..).
> > since the data order of returned valus is NOT explicitly specified in the
> > manual, and almost data from everywhere else I have seen is stored in row
> > first order, It would be nice if someone could confirm me on this.
>
> *All* R matrices are stored in column first order ... so why does this
> need to be specified on that help page?
>
>



From rpeng at stat.ucla.edu  Thu May  8 21:43:38 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Thu, 8 May 2003 12:43:38 -0700 (PDT)
Subject: [R] proj4
In-Reply-To: <Pine.OSF.3.91.1030508200014.24678h-100000@paleo.ija.csic.es>
Message-ID: <Pine.GSO.4.10.10305081243150.897-100000@quetelet.stat.ucla.edu>

You may want to look at Rmap at
http://www.maths.lancs.ac.uk/Software/Rmap.

-roger
_______________________________
UCLA Department of Statistics
http://www.stat.ucla.edu/~rpeng

On Thu, 8 May 2003, Agustin Lobo wrote:

> 
> Hi!
> 
> Does anyone know if there is a package to
> call proj4 from R (or python)?
> (proj4: library to make coordinate conversions
> betwee different projections, http://remotesensing.org/proj/)
> 
> Thanks
> 
> Agus
> 
> Dr. Agustin Lobo
> Instituto de Ciencias de la Tierra (CSIC)
> Lluis Sole Sabaris s/n
> 08028 Barcelona SPAIN
> tel 34 93409 5410
> fax 34 93411 0012
> alobo at ija.csic.es
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From ripley at stats.ox.ac.uk  Thu May  8 21:45:51 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 8 May 2003 20:45:51 +0100 (BST)
Subject: [R] Kriging function ("prmat" and "semat") in spatial package
In-Reply-To: <Pine.SOL.4.33.0305081231170.27619-100000@panther.cs.ucla.edu>
Message-ID: <Pine.LNX.4.44.0305082042470.26323-100000@gannet.stats>

On Thu, 8 May 2003, Yan Yu wrote:

> Thanks a lot for clarification!
> Please forgive my ignorance on some R basics,
> It is good to know that all R matrices are stored in column first order:)
> it would be nice if it could be documented, so that new users to R can
> quickly get to where they want w/o first going through some systematic R
> learning..

It *is* documented: in `An Introduction to R', for example.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From xirui at cs.tu-berlin.de  Thu May  8 22:04:26 2003
From: xirui at cs.tu-berlin.de (Xirui Yang)
Date: Thu, 8 May 2003 22:04:26 +0200 (MEST)
Subject: [R] how to write text into a file
In-Reply-To: <200305081809.LAA24996@hivnet.ubc.ca>
References: <Pine.SOL.4.53.0305081839260.14610@conde>
	<200305081809.LAA24996@hivnet.ubc.ca>
Message-ID: <Pine.SOL.4.53.0305082202370.22287@pepita>

Thank you, James, Roger and Jerome,

There is a long story...

I'm a computer science student (not statistician). About two year ago, I
was in a project "Survey and Analysis through WAP", which collects survey
datas via WAP. The customers may get the latest result per internet. A
survey may include many questions of different types. Statistics write R
programm in a .r file for each survey, which may contain many R commands.
Every time when a customer want to see the latest result, the R programm
file will be called and result files (a postscript file and a pdf file)
will be generated.

We have found that the command postscript() puts the graphics into a
postscript file. With the command text(), text may be added into graphics.
But the text ouput of commands like
max(), median()... will only be put on the screen. The result files
contain pages of graphics and no text!

And why do I ask this question today?  I am taking on this term another
lecture "Decentral System Design". The students should take part in an
open source project,  design a prototype and write code for it. I remember
that R-Project is an open source project. My group member and I think that
we may write a command for the R-Project to put the text ouput into a
postscript file, if there is not yet one.

best wishes,
Xirui


On Thu, 8 May 2003, Jerome Asselin wrote:

>
> I'd suggest to write your text into a text file. See ?cat . In particular,
> look at the "file" option.
>
> I wonder why you want to have your text in a postscript file rather than
> a text file. However, you can probably convert your text file using some
> utility of your OS. E.g., you could print it to a ps file instead of a
> printer.
>
> HTH,
> Jerome
>
> On May 8, 2003 09:45 am, Xirui Yang wrote:
> > Hello,
> >
> > Would somebody tell me how to write the text result into a postscript
> > file?  The command postscript() sents only the graphics output into
> > PostScript files.
> >
> > best wishes,
> > Xirui
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>



From jfkincaidsu at netscape.net  Thu May  8 22:14:10 2003
From: jfkincaidsu at netscape.net (Joel Kincaid)
Date: Thu, 08 May 2003 16:14:10 -0400
Subject: [R] EXCEL FILE
References: <2e2618bd438755d6.438755d62e2618bd@unitec.edu>	<3EBA8943.8050304@netscape.net>
	<x2k7d1uu71.fsf@biostat.ku.dk>
Message-ID: <3EBABA92.1050908@netscape.net>



Peter Dalgaard BSA wrote:
> Those are the defaults... read.csv(file='foo.csv') should do. Use
> header=FALSE if the header is absent. Notice also that in some
> locales, CSV files have "," for decimal separator and ";" for the
> value. That's where read.csv2 is relevant.
> 

This will save me some typing...
and also I goofed with the orginal specification:
 > Joel Kincaid <jfkincaidsu at netscape.net> writes:
 >
 >
 >>Use 'save as' in excel to create 'foo.csv' and then
 >>
 >>read.csv(file='foo.csv',sep',',header=T)
                ^^^^^                       Should have (unnecessarily :) written "sep=','" rather 
than the
syntax error inducing "sep','"      

Cheers, Joel



From jerome at hivnet.ubc.ca  Thu May  8 22:29:29 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Thu, 8 May 2003 13:29:29 -0700
Subject: [R] how to write text into a file
In-Reply-To: <Pine.SOL.4.53.0305082202370.22287@pepita>
References: <Pine.SOL.4.53.0305081839260.14610@conde>
	<200305081809.LAA24996@hivnet.ubc.ca>
	<Pine.SOL.4.53.0305082202370.22287@pepita>
Message-ID: <200305082035.NAA01368@hivnet.ubc.ca>

On May 8, 2003 01:04 pm, Xirui Yang wrote:
> [...]
> And why do I ask this question today?  I am taking on this term another
> lecture "Decentral System Design". The students should take part in an
> open source project,  design a prototype and write code for it. I
> remember that R-Project is an open source project. My group member and I
> think that we may write a command for the R-Project to put the text
> ouput into a postscript file, if there is not yet one.
> [...]

Just a suggestion... Perhaps the text output should be sent to the 
graphical device in use. This would be more general than restricting to 
the postscript device. The user could then choose to send the text to 
whatever graphical device available; e.g., jpeg, png, postscript, pdf, 
X11, etc.

Cheers,
Jerome



From xirui at cs.tu-berlin.de  Thu May  8 23:38:14 2003
From: xirui at cs.tu-berlin.de (Xirui Yang)
Date: Thu, 8 May 2003 23:38:14 +0200 (MEST)
Subject: [R] how to write text into a file
In-Reply-To: <200305082035.NAA01368@hivnet.ubc.ca>
References: <Pine.SOL.4.53.0305081839260.14610@conde>
	<200305081809.LAA24996@hivnet.ubc.ca>
	<Pine.SOL.4.53.0305082202370.22287@pepita>
	<200305082035.NAA01368@hivnet.ubc.ca>
Message-ID: <Pine.SOL.4.53.0305082337250.27916@pepita>

On Thu, 8 May 2003, Jerome Asselin wrote:

> Just a suggestion... Perhaps the text output should be sent to the
> graphical device in use. This would be more general than restricting to
> the postscript device. The user could then choose to send the text to
> whatever graphical device available; e.g., jpeg, png, postscript, pdf,
> X11, etc.
>
> Cheers,
> Jerome
>

A good suggestion. Thank you Jerome.



From info at rhkoning.com  Thu May  8 23:47:30 2003
From: info at rhkoning.com (Ruud H. Koning)
Date: Thu, 08 May 2003 23:47:30 +0200
Subject: [R] Questons about R capabilities
In-Reply-To: <seb7d46c.048@healthsmtp.nycnet>
References: <seb7d46c.048@healthsmtp.nycnet>
Message-ID: <200305082347300820.000BC994@192.168.1.66>

You can use the optim() function in MASS to optimize a loglikelihood
function. For inspiration on the form of the loglikelihoodfunction in your
case, you may consult G.S. Maddala "Limited dependent variables in
econometrics" 1983 (the title may not be completely correct). Ruud

*********** REPLY SEPARATOR  ***********

On 5/6/2003 at 3:27 PM Howard Alper wrote:

>Hello,
> 
>1)  I am interested in performing a limited-dependent variable linear
>regression.  By this I mean a classical linear regression, but for the
>case where the values of the dependent variable cannot vary from -infinity
>to +infinity, but are truncated and so are between two finite limits L1
>and L2.  Does R1.7 have this capability?  If so what is (are) the relevant
>command(s)?
> 
>2)  I am also interested in sampling from a multivariate normal
>distribution.  I see that R has a command mvrnorm, but when I try to use
>it, I get a message to the effect that the command is not recognized.  Is
>there something I must do to enable this command, or is it not available
>in version 1.7?
>
>  Thanks,
> 
>  Howard
>
>
>
>	[[alternate HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ibanez27 at inwind.it  Thu May  8 23:48:53 2003
From: ibanez27 at inwind.it (=?iso-8859-1?Q?Simona_Avanzo?=)
Date: Thu,  8 May 2003 23:48:53 +0200
Subject: [R] A problem in a glm model
Message-ID: <HEL8LH$8639F3ED1E2432179BBAE44D23F65A09@libero.it>

Hallo all, 

I have the following glm model:

f1 <- as.formula(paste("factor(y.fondi)~",
                  "flgsess + segmeta2 + udm + zona.geo + ultimo.prod.", 
                  "+flg.a2 + flg.d.na2 + flg.v2 + flg.cc2",
                  " +(flg.a1 + flg.d.na1 + flg.v1 + flg.cc1)^2",
                  " + flg.a2:flg.d.na2 + flg.a2:flg.v2 + flg.a2:flg.cc2",
                  " + flg.d.na2:flg.v2 + flg.v2:flg.cc2",
                 sep=""))

g1 <- glm(f1,family=binomial,data=camp.lavoro.meno.na)

The variables are all factors:
?	y.fondi takes value 0 or 1; 
?	flgsess has 2 levels;
?	segmeta2 has 4 levels;
?	udm has 6 levels;
?	zona.geo has 5 levels;
?	ultimo.prod. has 4 levels;
?	flg.a1, flg.d.na1, flg.v1, flg.cc1, flg.a2, flg.d.na2,  flg.v2, flg.cc2  are 8 factors that take values 0 or 1.

The number of observations is 1390. 
The observations with "y.fondi = 1" are 259.
The observations with "y.fondi = 0" are 1131.
 
The summary of the model is:
> summary(g1)
Call:
glm(formula = f1, family = binomial, data = camp.lavoro.meno.na)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.8955  -0.3586  -0.2692  -0.1642   2.9133  

Coefficients:
                                   Estimate    Std. Error  z value   Pr(>|z|)    
(Intercept)                    -2.7647     0.7523     -3.675    0.000238 ***
...                                      ...           ...              ...              ...        

flg.a21                           0.7898      0.4948     1.596     0.110475    
flg.d.na21                      0.2097      0.7336     0.286     0.774963    
flg.v21                           0.3928      0.5257     0.747     0.454994    
flg.cc21                         -0.8547      1.4954    -0.572     0.567625    
flg.a11                           0.7051      0.4889     1.442     0.149221    
flg.d.na11                       1.3582     0.5429     2.502     0.012353 *  
flg.v11                            2.2596     0.5079     4.449     8.62e-06 ***
flg.cc11                          -3.3658     8.5259    -0.395     0.693014    
flg.a21:flg.d.na21           -6.9392     26.5432  -0.261     0.793760    
flg.a21:flg.v21                -1.4355     4.0963    -0.350    0.726005    
flg.a21:flg.cc21               -6.0460    72.4807    -0.083    0.933521    
flg.d.na21:flg.v21            -2.4347     2.9045    -0.838    0.401888    
flg.v21:flg.cc21                11.7232   72.4814     0.162    0.871510    
flg.a11:flg.d.na11            -8.3843    30.4660    -0.275   0.783162 !!!!    
flg.a11:flg.v11                  6.5067    39.2569     0.166   0.868356    
flg.a11:flg.cc11                 13.5596   19.4693    0.696   0.486140  !!!!  
flg.d.na11:flg.v11            -0.7143     1.2673     -0.564   0.573013    
flg.d.na11:flg.cc11            12.0653   15.3880     0.784   0.432997    
flg.v11:flg.cc11                  6.2648    8.5808      0.730  0. 465331  !!!!  

Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 
(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 1336.79  on 1389  degrees of freedom
Residual deviance:  576.08  on 1354  degrees of freedom
AIC: 648.08

Number of Fisher Scoring iterations: 8

If  I apply the test anova, I obtain:

> g1.1 <- update(g1,~.-flg.a1:flg.d.na1,data=camp.lavoro.meno.na)
> anova(g1.1,g1,test="Chisq")
Analysis of Deviance Table
  Resid. Df Resid. Dev   Df Deviance P(>|Chi|)
1      1355     578.49                        
2      1354     576.08    1     2.41      0.12

> g1.1 <- update(g1,~.-flg.a1:flg.cc1,data=camp.lavoro.meno.na)
> anova(g1.1,g1,test="Chisq")
Analysis of Deviance Table
  Resid. Df Resid. Dev   Df Deviance P(>|Chi|)
1      1355     580.77                        
2      1354     576.08    1     4.69      0.03

> g1.1 <- update(g1,~.-flg.v1:flg.cc1,data=camp.lavoro.meno.na)
> anova(g1.1,g1,test="Chisq")
Analysis of Deviance Table
  Resid. Df Resid. Dev   Df Deviance P(>|Chi|)
1      1355     578.01                        
2      1354     576.08    1     1.94      0.16

Why I obtain these differences?
Many thanks for any help, 

Simona



From ripley at stats.ox.ac.uk  Fri May  9 00:05:42 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 8 May 2003 23:05:42 +0100 (BST)
Subject: [R] A problem in a glm model
In-Reply-To: <HEL8LH$8639F3ED1E2432179BBAE44D23F65A09@libero.it>
Message-ID: <Pine.LNX.4.44.0305082300270.22335-100000@gannet.stats>

You need to look up the Hauck-Donner phenomenon in MASS (4th, 3rd or 2nd 
edition).

In short, Wald tests of binomial or Poisson glms are highly unreliable:
a moderate p-value indicates no effect or a very large effect.

I suspect your model is in fact partially separable (that is can fit parts
of the data exactly), since those are large coefficients for indicator 
variables.  Try reducing the tolerance in glm.control (add epsilon=1e-10) 
and see if the coefficients change a lot.

On Thu, 8 May 2003, Simona Avanzo wrote:

> Hallo all, 
> 
> I have the following glm model:
> 
> f1 <- as.formula(paste("factor(y.fondi)~",
>                   "flgsess + segmeta2 + udm + zona.geo + ultimo.prod.", 
>                   "+flg.a2 + flg.d.na2 + flg.v2 + flg.cc2",
>                   " +(flg.a1 + flg.d.na1 + flg.v1 + flg.cc1)^2",
>                   " + flg.a2:flg.d.na2 + flg.a2:flg.v2 + flg.a2:flg.cc2",
>                   " + flg.d.na2:flg.v2 + flg.v2:flg.cc2",
>                  sep=""))
> 
> g1 <- glm(f1,family=binomial,data=camp.lavoro.meno.na)
> 
> The variables are all factors:
> ?	y.fondi takes value 0 or 1; 
> ?	flgsess has 2 levels;
> ?	segmeta2 has 4 levels;
> ?	udm has 6 levels;
> ?	zona.geo has 5 levels;
> ?	ultimo.prod. has 4 levels;
> ?	flg.a1, flg.d.na1, flg.v1, flg.cc1, flg.a2, flg.d.na2,  flg.v2, flg.cc2  are 8 factors that take values 0 or 1.
> 
> The number of observations is 1390. 
> The observations with "y.fondi = 1" are 259.
> The observations with "y.fondi = 0" are 1131.
>  
> The summary of the model is:
> > summary(g1)
> Call:
> glm(formula = f1, family = binomial, data = camp.lavoro.meno.na)
> 
> Deviance Residuals: 
>     Min       1Q   Median       3Q      Max  
> -2.8955  -0.3586  -0.2692  -0.1642   2.9133  
> 
> Coefficients:
>                                    Estimate    Std. Error  z value   Pr(>|z|)    
> (Intercept)                    -2.7647     0.7523     -3.675    0.000238 ***
> ...                                      ...           ...              ...              ...        
> 
> flg.a21                           0.7898      0.4948     1.596     0.110475    
> flg.d.na21                      0.2097      0.7336     0.286     0.774963    
> flg.v21                           0.3928      0.5257     0.747     0.454994    
> flg.cc21                         -0.8547      1.4954    -0.572     0.567625    
> flg.a11                           0.7051      0.4889     1.442     0.149221    
> flg.d.na11                       1.3582     0.5429     2.502     0.012353 *  
> flg.v11                            2.2596     0.5079     4.449     8.62e-06 ***
> flg.cc11                          -3.3658     8.5259    -0.395     0.693014    
> flg.a21:flg.d.na21           -6.9392     26.5432  -0.261     0.793760    
> flg.a21:flg.v21                -1.4355     4.0963    -0.350    0.726005    
> flg.a21:flg.cc21               -6.0460    72.4807    -0.083    0.933521    
> flg.d.na21:flg.v21            -2.4347     2.9045    -0.838    0.401888    
> flg.v21:flg.cc21                11.7232   72.4814     0.162    0.871510    
> flg.a11:flg.d.na11            -8.3843    30.4660    -0.275   0.783162 !!!!    
> flg.a11:flg.v11                  6.5067    39.2569     0.166   0.868356    
> flg.a11:flg.cc11                 13.5596   19.4693    0.696   0.486140  !!!!  
> flg.d.na11:flg.v11            -0.7143     1.2673     -0.564   0.573013    
> flg.d.na11:flg.cc11            12.0653   15.3880     0.784   0.432997    
> flg.v11:flg.cc11                  6.2648    8.5808      0.730  0. 465331  !!!!  
> 
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 
> (Dispersion parameter for binomial family taken to be 1)
> 
>     Null deviance: 1336.79  on 1389  degrees of freedom
> Residual deviance:  576.08  on 1354  degrees of freedom
> AIC: 648.08
> 
> Number of Fisher Scoring iterations: 8
> 
> If  I apply the test anova, I obtain:
> 
> > g1.1 <- update(g1,~.-flg.a1:flg.d.na1,data=camp.lavoro.meno.na)
> > anova(g1.1,g1,test="Chisq")
> Analysis of Deviance Table
>   Resid. Df Resid. Dev   Df Deviance P(>|Chi|)
> 1      1355     578.49                        
> 2      1354     576.08    1     2.41      0.12
> 
> > g1.1 <- update(g1,~.-flg.a1:flg.cc1,data=camp.lavoro.meno.na)
> > anova(g1.1,g1,test="Chisq")
> Analysis of Deviance Table
>   Resid. Df Resid. Dev   Df Deviance P(>|Chi|)
> 1      1355     580.77                        
> 2      1354     576.08    1     4.69      0.03
> 
> > g1.1 <- update(g1,~.-flg.v1:flg.cc1,data=camp.lavoro.meno.na)
> > anova(g1.1,g1,test="Chisq")
> Analysis of Deviance Table
>   Resid. Df Resid. Dev   Df Deviance P(>|Chi|)
> 1      1355     578.01                        
> 2      1354     576.08    1     1.94      0.16
> 
> Why I obtain these differences?
> Many thanks for any help, 
> 
> Simona
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From t_isog at hotmail.com  Fri May  9 00:37:46 2003
From: t_isog at hotmail.com (Isogai Takashi)
Date: Thu, 08 May 2003 22:37:46 +0000
Subject: [R] Question about PAM clustering method
Message-ID: <Sea1-F49rOYaEv1Kq2E000052fd@hotmail.com>

Hello Mr. Maechler.  Thank you very much for your comment 
and advice.  It helped me so much to understand more about 
PAM and CLUSPLOT.  

>help(clusplot.default) has quite a list of references, one of
>them even available on the web.  You should read at least one
>(or alternatively look at the R source of these function; this
>is open source !)

First, I must say that I didn't understand the role of clusplot(.default) 
when I call plot( ) in my R script; I used plot( ) function to get 
the graphic output displayed.  I finally understand that plot( ) 
method call the proper module, namely clusplot by polymorphic 
mechanism of R.  I should notice this much earlier, since the 
chart gave me a clue, labeled "clusplot(?)" at its top.  

I looked through the document "Displaying a Clustering with 
CLUSPLOT", and understand its flexible function with many 
options.  I can change the line, meaning of which is distance 
between ellipses, and eliminate them from the chart.  
Moreover, clusplot can be used to plot any partitions, 
depending the R's clustering methods or imported data 
made by other application.  

As for the silhouette value and clustering result, I understand 
that silhouette value is a good measure of fitness but not 
almighty.  I solved the very low silhouette value problem by 
reducing the dimension of data in much smaller size than 
before by using SVD.  Now, the value is above 0.25  that 
means not bad partitioning.  This is what I expected, since 
I am now trying to compare pre-defined partitions, which are 
already known externally, and clustering results based on 
extracted data.  

Also, the pointer to the source code is greatly appreciated.  
I will look into the source code to know the specifics of 
what I am interested.  

Again, thank you very much for your help.  

T. Isogai

_________________________________________________________________
????????????????? MSN Hotmail  http://www.hotmail.com/



From Ted.Harding at nessie.mcc.ac.uk  Fri May  9 01:32:41 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 09 May 2003 00:32:41 +0100 (BST)
Subject: [R] how to write text into a file
In-Reply-To: <Pine.SOL.4.53.0305081839260.14610@conde>
Message-ID: <XFMail.030509003241.Ted.Harding@nessie.mcc.ac.uk>

On 08-May-03 Xirui Yang wrote:
> Hello,
> 
> Would somebody tell me how to write the text result into a postscript
> file?  The command postscript() sents only the graphics output into
> PostScript files.

Thinking I might have an answer to Xirui's problem, I tried the
following.

Using R in Linux, which has the program 'enscript' for converting
a text file as it would appear on screen into PostScript:
based on examples given in "?pipe" and "?cat", I can make the
following work for making a postscript file which will display R
output as it normally appears on screen:

Ex 1:
  zz<-pipe("enscript -o tempout.ps","w")
  cat(format(round(rnorm(100),4)),sep="\n",file=zz)
  close(zz)

[ 2 pages * 1 copy ] left in tempout.ps

However, when I try the same idea for something more complicated:
Ex 2:
  ctl <- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,5.14)
  trt <- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)
  group <- gl(2,10,20, labels=c("Ctl","Trt"))
  weight <- c(ctl, trt)
  zz<-pipe("enscript -o tempout.ps","w")
  cat(anova(lm.D9 <- lm(weight ~ group)),sep="\n",file=zz)

I get the error message:

Error in cat(list(...), file, sep, fill, labels, append) : 
        argument 1 not yet handled by cat

Am I doing something wrong, or is there a gap in this area?

Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 09-May-03                                       Time: 00:32:41
------------------------------ XFMail ------------------------------



From Arnaud.Dowkiw at dpi.qld.gov.au  Fri May  9 02:00:15 2003
From: Arnaud.Dowkiw at dpi.qld.gov.au (Dowkiw, Arnaud)
Date: Fri, 9 May 2003 10:00:15 +1000
Subject: [R] Cluster analysis,
	proportion of SS retained at each grouping step
Message-ID: <C2C6EA6C4DADB348BFDF58894B03901201274190@kinsrv001.dpi.qld.gov.au>

Dear all,


I am doing cluster analysis using agnes() on a squared euclidean
distance matrix using Ward's method. Do you know how to get the
porportion of the initial sum of squares (when each of the n entries is
considered as a single cluster) retained at each grouping level (1
cluster, 2 clusters, 3 clusters, ... , n clusters ), i.e. an ascending
curve from 0 to 1 ?
Thanks for your help,


*************************
Arnaud DOWKIW
Department of Primary Industries
J. Bjelke-Petersen Research Station
KINGAROY, QLD 4610
Australia
T : + 61 7 41 600 700
T : + 61 7 41 600 728 (direct)
F : + 61 7 41 600 760
**************************

********************************DISCLAIMER**********************... {{dropped}}



From tlumley at u.washington.edu  Fri May  9 02:14:20 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 8 May 2003 17:14:20 -0700 (PDT)
Subject: [R] how to write text into a file
In-Reply-To: <XFMail.030509003241.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <Pine.A41.4.44.0305081703030.67374-100000@homer25.u.washington.edu>

On Fri, 9 May 2003 Ted.Harding at nessie.mcc.ac.uk wrote:

> On 08-May-03 Xirui Yang wrote:
> > Hello,
> >
> > Would somebody tell me how to write the text result into a postscript
> > file?  The command postscript() sents only the graphics output into
> > PostScript files.
>
> Thinking I might have an answer to Xirui's problem, I tried the
> following.
>
> Using R in Linux, which has the program 'enscript' for converting
> a text file as it would appear on screen into PostScript:
> based on examples given in "?pipe" and "?cat", I can make the
> following work for making a postscript file which will display R
> output as it normally appears on screen:
>
<snip>
> However, when I try the same idea for something more complicated:
> Ex 2:
>   ctl <- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,5.14)
>   trt <- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)
>   group <- gl(2,10,20, labels=c("Ctl","Trt"))
>   weight <- c(ctl, trt)
>   zz<-pipe("enscript -o tempout.ps","w")
>   cat(anova(lm.D9 <- lm(weight ~ group)),sep="\n",file=zz)
>
> I get the error message:
>
> Error in cat(list(...), file, sep, fill, labels, append) :
>         argument 1 not yet handled by cat
>
> Am I doing something wrong, or is there a gap in this area?

You can't use cat() on arbitrary objects.
You could use sink().

A fairly minor adjustment to capture.output(), to allow it to take an
arbitrary connection for its `file' argument works very nicely, and one
can then do eg
   capture.output(example(glm), file=pipe("enscript -o tempout.ps","w"))

However, I think the proposal was to put text on to graphics devices too.
A similar strategy would probably work, but as it's a class project it
would be kinder not to go much further in case the problem gets solved
from under them.


	-thomas



From mentus at gmx.de  Fri May  9 02:35:02 2003
From: mentus at gmx.de (Fernando Henrique Ferraz Pereira da Rosa)
Date: Fri, 9 May 2003 02:35:02 +0200 (MEST)
Subject: [R] Data-mining using R
Message-ID: <25258.1052440502@www37.gmx.net>

      Is it possible to use R as a data-mining tool? Here's the problem I've
got. I have a couple of data sets consisting of results from a cDNA
microarray experiment - the details about the biology don't really matter here, the
same theory applies for any other data-mining task (that's why I thought it'd
be more appropriate to post this on r-user).  Each of these datasets consists
of about 30000 rows by 20 to 30 columns. Let's say that each row represents
(very roughly speaking) a gene, and the columns are details about its level
of expression, reliability of the measurament, coordinates and so on.
      The main objetive here is identify some genes (rows) according to some
criteria. In order to do that, what I want to be able to do, is selectively
filter the rows, graph some convinient variables, do some further filtering
and so on.
      Let me take a more concrete example to make myself clear. Let's say
that I load a given dataset on a dataframe, namely expr1. This dataframe would
have the fields expr1$name, expr1$expression, expr1$reliablity, expr1$x,
expr1$y and so on, containing, for instance, 26000 rows. Now from these 26000 I'd
like to select only those ones satisfying expr1$expression > 2000,
expr1$reliability = 100 and plot a graph on expr1$x x expr1$y, for them. I'd have then
a reduced dataset of the first one. Let's say now that I want to narrow my
filter even more, selecting only (among the ones I have already selected) the
ones where expr1$x > 20.
      This would be done many times and in different orders. I'd like to be
able to, among those 26000 rows, take only the 100 whose expr$x are the 100
greatest
. And so on, many times, until I found a set of suitable rows.
      What is the proper way to do that using R, if any? I've played a
little with dataframes (I could for instance use: expr1$names[expr1$x > 20] to get
the names of those genes whose x > 20) but it seemed a little clumsy. Should
I keep trying to manipulate directly the dataframe, or perhaps should I save
it on a mysql database and do que queries using RMYSql? Or maybe there is a
better option?
      I know that these things I've said are pretty easy to implement using,
for instance M$ Excel (I've seen them working on it). You just select
drop-down menus and filter the rows to your liking. But I really would like to be
able to accomplish this task using R and other open source tools like MySql,
Perl, etc.
      

Thank you in advance,

--



From Arnaud.Dowkiw at dpi.qld.gov.au  Fri May  9 02:45:23 2003
From: Arnaud.Dowkiw at dpi.qld.gov.au (Dowkiw, Arnaud)
Date: Fri, 9 May 2003 10:45:23 +1000
Subject: [R] Principal coordinates analysis
Message-ID: <C2C6EA6C4DADB348BFDF58894B039012012730EA@kinsrv001.dpi.qld.gov.au>


Dear all,


Does anyone know how to run Principal Coordinates Analysis (PCoA) from a
squared euclidean dissimilarity matrix with R ?
Thanks,


*************************
Arnaud DOWKIW
Department of Primary Industries
J. Bjelke-Petersen Research Station
KINGAROY, QLD 4610
Australia
T : + 61 7 41 600 700
T : + 61 7 41 600 728 (direct)
F : + 61 7 41 600 760
**************************

********************************DISCLAIMER**********************... {{dropped}}



From rpeng at stat.ucla.edu  Fri May  9 03:12:40 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Thu, 8 May 2003 18:12:40 -0700 (PDT)
Subject: [R] Questons about R capabilities
In-Reply-To: <200305082347300820.000BC994@192.168.1.66>
Message-ID: <Pine.GSO.4.10.10305081811540.21918-100000@quetelet.stat.ucla.edu>

Just one note, optim() is in the `base' package.  You do not need to load
`MASS' (although you may want to read the book).

-roger
_______________________________
UCLA Department of Statistics
http://www.stat.ucla.edu/~rpeng

On Thu, 8 May 2003, Ruud H. Koning wrote:

> You can use the optim() function in MASS to optimize a loglikelihood
> function. For inspiration on the form of the loglikelihoodfunction in your
> case, you may consult G.S. Maddala "Limited dependent variables in
> econometrics" 1983 (the title may not be completely correct). Ruud
> 
> *********** REPLY SEPARATOR  ***********
> 
> On 5/6/2003 at 3:27 PM Howard Alper wrote:
> 
> >Hello,
> > 
> >1)  I am interested in performing a limited-dependent variable linear
> >regression.  By this I mean a classical linear regression, but for the
> >case where the values of the dependent variable cannot vary from -infinity
> >to +infinity, but are truncated and so are between two finite limits L1
> >and L2.  Does R1.7 have this capability?  If so what is (are) the relevant
> >command(s)?
> > 
> >2)  I am also interested in sampling from a multivariate normal
> >distribution.  I see that R has a command mvrnorm, but when I try to use
> >it, I get a message to the effect that the command is not recognized.  Is
> >there something I must do to enable this command, or is it not available
> >in version 1.7?
> >
> >  Thanks,
> > 
> >  Howard
> >
> >
> >
> >	[[alternate HTML version deleted]]
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From andyj at splash.princeton.edu  Fri May  9 04:24:17 2003
From: andyj at splash.princeton.edu (Andy Jacobson)
Date: Fri, 09 May 2003 02:24:17 -0000
Subject: [R] graphics on a map
Message-ID: <f2kof2cx3g7.fsf@tazman.Princeton.EDU>

Howdy,

        I'd like to draw graphical elements at specific areas on a
        map.  For instance, would it be possible to draw a pie chart
        at the center of each nation on a world map?  I'm interested
        in putting histograms, scatterplots, line graphs, etc., on
        geographical regions.

        Many thanks,

                Andy

-- 
Andy Jacobson

andyj at splash.princeton.edu

Program in Atmospheric and Oceanic Sciences
Sayre Hall, Forrestal Campus
Princeton University
PO Box CN710 Princeton, NJ 08544-0710 USA

Tel: 609/258-5260  Fax: 609/258-2850



From rossini at blindglobe.net  Fri May  9 04:27:46 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Thu, 08 May 2003 19:27:46 -0700
Subject: [R] Data-mining using R
In-Reply-To: <25258.1052440502@www37.gmx.net> (Fernando Henrique Ferraz
	Pereira da Rosa's message of "Fri, 9 May 2003 02:35:02 +0200 (MEST)")
References: <25258.1052440502@www37.gmx.net>
Message-ID: <87u1c4zwf1.fsf@jeeves.blindglobe.net>


See www.bioconductor.org for one reasonably full featured approach.

There are others (Rmaanova, etc, etc).


Fernando Henrique Ferraz Pereira da Rosa <mentus at gmx.de> writes:

>       Is it possible to use R as a data-mining tool? Here's the problem I've
> got. I have a couple of data sets consisting of results from a cDNA
> microarray experiment - the details about the biology don't really matter here, the
> same theory applies for any other data-mining task (that's why I thought it'd
> be more appropriate to post this on r-user).  Each of these datasets consists
> of about 30000 rows by 20 to 30 columns. Let's say that each row represents
> (very roughly speaking) a gene, and the columns are details about its level
> of expression, reliability of the measurament, coordinates and so on.
>       The main objetive here is identify some genes (rows) according to some
> criteria. In order to do that, what I want to be able to do, is selectively
> filter the rows, graph some convinient variables, do some further filtering
> and so on.
>       Let me take a more concrete example to make myself clear. Let's say
> that I load a given dataset on a dataframe, namely expr1. This dataframe would
> have the fields expr1$name, expr1$expression, expr1$reliablity, expr1$x,
> expr1$y and so on, containing, for instance, 26000 rows. Now from these 26000 I'd
> like to select only those ones satisfying expr1$expression > 2000,
> expr1$reliability = 100 and plot a graph on expr1$x x expr1$y, for them. I'd have then
> a reduced dataset of the first one. Let's say now that I want to narrow my
> filter even more, selecting only (among the ones I have already selected) the
> ones where expr1$x > 20.
>       This would be done many times and in different orders. I'd like to be
> able to, among those 26000 rows, take only the 100 whose expr$x are the 100
> greatest
> . And so on, many times, until I found a set of suitable rows.
>       What is the proper way to do that using R, if any? I've played a
> little with dataframes (I could for instance use: expr1$names[expr1$x > 20] to get
> the names of those genes whose x > 20) but it seemed a little clumsy. Should
> I keep trying to manipulate directly the dataframe, or perhaps should I save
> it on a mysql database and do que queries using RMYSql? Or maybe there is a
> better option?
>       I know that these things I've said are pretty easy to implement using,
> for instance M$ Excel (I've seen them working on it). You just select
> drop-down menus and filter the rows to your liking. But I really would like to be
> able to accomplish this task using R and other open source tools like MySql,
> Perl, etc.
>       
>
> Thank you in advance,
>
> --
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
A.J. Rossini rossini at u.washington.edu http://software.biostat.washington.edu/ 
Biostatistics, U Washington and Fred Hutchinson Cancer Research Center

FHCRC:Tu: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email 
UW  : Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX 

CONFIDENTIALITY NOTICE: This e-mail message and any attachments ... {{dropped}}



From gisar at nus.edu.sg  Fri May  9 05:00:49 2003
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Fri, 9 May 2003 11:00:49 +0800
Subject: [R] Data-mining using R
Message-ID: <024D6AEFCB92CB47BA1085751D184BB80105F258@MBXSRV03.stf.nus.edu.sg>

Yes all of this is possible in R and more.

You might find the which() command helpful for subsetting. You could
write a simple function to automate this. For graphing  facilities, see
plot(), par(), postscript() etc.

In my opinion, it might not be worth the effort and time to save it to
MYSQL if you only want to perform a couple of queries. Plus R has
excellent graphing facilities. If you really want to automate the
process, then a combination of Perl and GNUplot seems like a good
combination. The choice depends on which software you are most
comfortable with. 

Another advantage R has is that it is an interactive language. So it is
great for exploratory analysis with minimum effort (unlike Excel in
which you spend 90% of your time dragging the mouse and sorting the
data).

See the Bioconductor project, which focuses on genomic and expression
data and has many great functions specifically designed for microarray
etc. I doubt you will be able to find such vast collection of tools for
free.

Good luck.

-----Original Message-----
From: Fernando Henrique Ferraz Pereira da Rosa [mailto:mentus at gmx.de] 
Sent: Friday, May 09, 2003 8:35 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Data-mining using R


      Is it possible to use R as a data-mining tool? Here's the problem
I've got. I have a couple of data sets consisting of results from a cDNA
microarray experiment - the details about the biology don't really
matter here, the same theory applies for any other data-mining task
(that's why I thought it'd be more appropriate to post this on r-user).
Each of these datasets consists of about 30000 rows by 20 to 30 columns.
Let's say that each row represents (very roughly speaking) a gene, and
the columns are details about its level of expression, reliability of
the measurament, coordinates and so on.
      The main objetive here is identify some genes (rows) according to
some criteria. In order to do that, what I want to be able to do, is
selectively filter the rows, graph some convinient variables, do some
further filtering and so on.
      Let me take a more concrete example to make myself clear. Let's
say that I load a given dataset on a dataframe, namely expr1. This
dataframe would have the fields expr1$name, expr1$expression,
expr1$reliablity, expr1$x, expr1$y and so on, containing, for instance,
26000 rows. Now from these 26000 I'd like to select only those ones
satisfying expr1$expression > 2000, expr1$reliability = 100 and plot a
graph on expr1$x x expr1$y, for them. I'd have then a reduced dataset of
the first one. Let's say now that I want to narrow my filter even more,
selecting only (among the ones I have already selected) the ones where
expr1$x > 20.
      This would be done many times and in different orders. I'd like to
be able to, among those 26000 rows, take only the 100 whose expr$x are
the 100 greatest . And so on, many times, until I found a set of
suitable rows.
      What is the proper way to do that using R, if any? I've played a
little with dataframes (I could for instance use: expr1$names[expr1$x >
20] to get the names of those genes whose x > 20) but it seemed a little
clumsy. Should I keep trying to manipulate directly the dataframe, or
perhaps should I save it on a mysql database and do que queries using
RMYSql? Or maybe there is a better option?
      I know that these things I've said are pretty easy to implement
using, for instance M$ Excel (I've seen them working on it). You just
select drop-down menus and filter the rows to your liking. But I really
would like to be able to accomplish this task using R and other open
source tools like MySql, Perl, etc.
      

Thank you in advance,

--

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From joachim.brouwers at gmx.net  Fri May  9 08:04:48 2003
From: joachim.brouwers at gmx.net (Joachim Brouwers)
Date: Fri, 9 May 2003 08:04:48 +0200
Subject: [R] 3 functions on same plot
Message-ID: <002e01c315f0$e5e74860$fd56430a@jokke>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030509/f12d988e/attachment.pl

From Arnaud.Dowkiw at dpi.qld.gov.au  Fri May  9 08:30:35 2003
From: Arnaud.Dowkiw at dpi.qld.gov.au (Dowkiw, Arnaud)
Date: Fri, 9 May 2003 16:30:35 +1000
Subject: [R] 3 functions on same plot
Message-ID: <C2C6EA6C4DADB348BFDF58894B039012012730F4@kinsrv001.dpi.qld.gov.au>

I'd give the same xlim=c(-a,b) and ylim=(-c,d) parameters to these three
functions and then, after each function call 
>par(new=T)
But maybe someone has got a better solution.

Arnaud DOWKIW



-----Original Message-----
From: Joachim Brouwers [mailto:joachim.brouwers at gmx.net]
Sent: Friday, 9 May 2003 4:05 PM
To: r-help at stat.math.ethz.ch
Subject: [R] 3 functions on same plot


Hello,

How can i plot 3 functions (prior, likelihood and posterior) on the same
plot?

 Thx,

Jokke
	[[alternate HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help

********************************DISCLAIMER**********************... {{dropped}}



From ripley at stats.ox.ac.uk  Fri May  9 08:40:31 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 9 May 2003 07:40:31 +0100 (BST)
Subject: [R] Principal coordinates analysis
In-Reply-To: <C2C6EA6C4DADB348BFDF58894B039012012730EA@kinsrv001.dpi.qld.gov.au>
Message-ID: <Pine.LNX.4.44.0305090738040.22994-100000@gannet.stats>

?cmdscale.

which is what Gower called `Principal Coordinate Analysis':  I vaguely 
recall there are other definitions.

On Fri, 9 May 2003, Dowkiw, Arnaud wrote:

> Does anyone know how to run Principal Coordinates Analysis (PCoA) from a
> squared euclidean dissimilarity matrix with R ?


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri May  9 08:47:03 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 9 May 2003 07:47:03 +0100 (BST)
Subject: [R] 3 functions on same plot
In-Reply-To: <C2C6EA6C4DADB348BFDF58894B039012012730F4@kinsrv001.dpi.qld.gov.au>
Message-ID: <Pine.LNX.4.44.0305090741460.22994-100000@gannet.stats>

On Fri, 9 May 2003, Dowkiw, Arnaud wrote:

> I'd give the same xlim=c(-a,b) and ylim=(-c,d) parameters to these three
> functions and then, after each function call 
> >par(new=T)

Use par(xaxs="d", yaxs="d") is a better way to `lock' the scales (and you 
should omit the axes and annotations on subsequent plots).

> But maybe someone has got a better solution.

?matplot

However, my understanding is that those three functions are unlikely to 
share a common scale (likelihood being different from the other two) so
either two scales will be needed or the likelihood would need to rescaled.

> From: Joachim Brouwers [mailto:joachim.brouwers at gmx.net]
> 
> How can i plot 3 functions (prior, likelihood and posterior) on the same
> plot?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From maechler at stat.math.ethz.ch  Fri May  9 09:04:46 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 9 May 2003 09:04:46 +0200
Subject: [R] 3 functions on same plot
In-Reply-To: <C2C6EA6C4DADB348BFDF58894B039012012730F4@kinsrv001.dpi.qld.gov.au>
References: <C2C6EA6C4DADB348BFDF58894B039012012730F4@kinsrv001.dpi.qld.gov.au>
Message-ID: <16059.21262.383939.907239@gargle.gargle.HOWL>

>>>>> "ArnaudD" == Dowkiw, Arnaud <Arnaud.Dowkiw at dpi.qld.gov.au>
>>>>>     on Fri, 9 May 2003 16:30:35 +1000 writes:

    ArnaudD> I'd give the same xlim=c(-a,b) and ylim=(-c,d)
    ArnaudD> parameters to these three functions and then, after
    ArnaudD> each function call
    >> par(new=T)
    ArnaudD> But maybe someone has got a better solution.
 
Yes. One more high-level approach to this is

  matplot(x, cbind(y1,y2,y3), type = "l",  main = "3 curves ...")
and maybe
  legend(...)

See the respective help() pages.
A bit less highlevel with a bit more flexibility is

 plot(x, ..... xlim=.., ylim=.., type = "n")
 lines(x, y1, ........)
 lines(x, y2, ........)
 lines(x, y3, ........)

and legend() again.

Yet another even higher level approach is to work with 
lattice graphics.

Martin

    > -----Original Message----- 
    > From: Joachim Brouwers <joachim.brouwers at gmx.net>
    > Subject: [R] 3 functions on same plot

    > Hello,

    > How can i plot 3 functions (prior, likelihood and
    > posterior) on the same plot?



From bernd.ebersberger at vtt.fi  Fri May  9 10:34:08 2003
From: bernd.ebersberger at vtt.fi (Bernd Ebersberger)
Date: Fri, 09 May 2003 11:34:08 +0300
Subject: [R] windows data editor changes dimensions displayed data frames
Message-ID: <4.3.1.2.20030509112543.01856cf8@vttmail.vtt.fi>

dear R-tists,

i am experiencing a problem with the data editor in the windows version of 
R 1.6.1 envoked with the command 'fix'.

the data editor changes the size of large data frames.

a simple example illustrates this:

-------------------------------------------------------

 > dfrm <- data.frame(no=c(1:100000))
 > length(dfrm[,1])

[1] 100000

 > fix(dfrm)

 > length(dfrm[,1])

[1] 34464

--------------------------------------------------------


does anybody have a quick remedy for this?

i am not sure whether it is worth putting much developmental effort in 
solving this particular problem.

however, i believe that one should be aware of it when working with large 
data sets.


greetings from the northern edge of europe.

bernd.



From tobias_verbeke at skynet.be  Fri May  9 10:49:30 2003
From: tobias_verbeke at skynet.be (Tobias Verbeke)
Date: Fri, 9 May 2003 10:49:30 +0200
Subject: [R] how to write text into a file
In-Reply-To: <Pine.SOL.4.53.0305082202370.22287@pepita>
References: <Pine.SOL.4.53.0305081839260.14610@conde>
	<200305081809.LAA24996@hivnet.ubc.ca>
	<Pine.SOL.4.53.0305082202370.22287@pepita>
Message-ID: <20030509104930.2e12b0ec.tobias_verbeke@skynet.be>

[...]
> 
> We have found that the command postscript() puts the graphics into a
> postscript file. With the command text(), text may be added into
> graphics. But the text ouput of commands like
> max(), median()... will only be put on the screen.

Not if you use 

sink("fileyouwant") to begin the redirecting into the 
                    file you want

and

sink()

to stop redirecting into the named file.

See ?sink



From Ted.Harding at nessie.mcc.ac.uk  Fri May  9 10:34:39 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 09 May 2003 09:34:39 +0100 (BST)
Subject: [R] how to write text into a file
In-Reply-To: <Pine.A41.4.44.0305081703030.67374-100000@homer25.u.washington.edu>
Message-ID: <XFMail.030509093439.Ted.Harding@nessie.mcc.ac.uk>

On 09-May-03 Thomas Lumley wrote:
> On Fri, 9 May 2003 Ted.Harding at nessie.mcc.ac.uk wrote:
> <snip>
>> However, when I try the same idea for something more complicated:
>> Ex 2:
>>   ctl <- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,5.14)
>>   trt <- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)
>>   group <- gl(2,10,20, labels=c("Ctl","Trt"))
>>   weight <- c(ctl, trt)
>>   zz<-pipe("enscript -o tempout.ps","w")
>>   cat(anova(lm.D9 <- lm(weight ~ group)),sep="\n",file=zz)
>>
>> I get the error message:
>>
>> Error in cat(list(...), file, sep, fill, labels, append) :
>>         argument 1 not yet handled by cat
>>
>> Am I doing something wrong, or is there a gap in this area?
> 
> You can't use cat() on arbitrary objects.
> You could use sink().

Thanks, Thomas! It turns out I'd missed a trick when using 'sink':
when I tried
  sink(file=pipe("enscript -o tempout.ps","w")) 
  anova(lm.D9 <- lm(weight ~ group))
  sink()
it only placed the PS prologue into the file, and I gave up!

Of course I should have realised that the output of anova won't
be flushed into the pipe until the pipe is closed, so you have
to be able to close it which means you need to be able to refer
to it. Now I find that
  zz<-pipe("enscript -o tempout.ps","w")
  sink(zz)
  anova(lm.D9 <- lm(weight ~ group))
  sink()
  close(zz)
works (of course!).

> A fairly minor adjustment to capture.output(), to allow it to take an
> arbitrary connection for its `file' argument works very nicely, and one
> can then do eg
>    capture.output(example(glm), file=pipe("enscript -o
> tempout.ps","w"))

Hmm -- where does one find capture.output()? Doesn't seem to show up in
any libraries I have installed.

> However, I think the proposal was to put text on to graphics devices
> too.
> A similar strategy would probably work, but as it's a class project it
> would be kinder not to go much further in case the problem gets solved
> from under them.

Well, point taken ... but it's also a slightly subtle issue which might
concern any of us, and I think the clarifcation which has emerged is
of general use, just like other discussions on this list which we use
as people might discuss when physically gathered in a coffee-room and
questions come up, only on a global scale.

Anyway, thanks for the stimulation to think this issue out more clearly!
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 09-May-03                                       Time: 09:34:39
------------------------------ XFMail ------------------------------



From bm8 at st-andrews.ac.uk  Fri May  9 11:27:01 2003
From: bm8 at st-andrews.ac.uk (Bernie McConnell)
Date: Fri, 09 May 2003 10:27:01 +0100
Subject: [R] Going slow blues
Message-ID: <5.1.0.14.0.20030509101518.00ad54a8@bute.st-and.ac.uk>

Good Day,

Apologies for vagueness, but ... I run R 1.70 on a Win 2000 machine.  I am 
usually a very contented user, but occasionally my R scripts will run at 
about one tenth speed.  The only way to return to normal is to restart 
R.  This seems to be associated (perhaps not exclusively) with me resizing 
windows (esp graphics output windows ??).  I am unable to recreate this 
problem to order.  I am posting this request for help in the hope that 
someone may be able to recognize the problem without me having to delve 
further.
Many thanks ,

Bernie McConnell
Sea Mammal Reserach Unit, UK



From P.Eilers at lumc.nl  Fri May  9 12:02:43 2003
From: P.Eilers at lumc.nl (Eilers, P. (MStat))
Date: Fri, 9 May 2003 12:02:43 +0200 
Subject: [R] natural splines
Message-ID: <FC36BC0A298F59448477C5D7E1EDAD8464F1C6@mail1.lumc.nl>

Indeed truncated power functions (TPF) are very useful to compute B-splines.
But why take chances with their bad numerical condition? Simple differences
will
turn the TPF basis into a B-spline basis. See the functions at the end. Try

 B = bbase(1:100, 0, 101, 10, 3)
 matplot(B, type = 'b')

to see it work.

Here I use equally spaced knots (as I always do, adding a penalty to tune
smoothness and avoid singularity problems). But with divided differences
this scheme will work for arbitrary knots (if no knots are the same).

Paul Eilers
Department of Medical Statistics
Leiden University Medical Centre


======= R functions ===================

tpower <- function(x, t, p) {
# Truncated p-th power function
    (x - t) ^ p * (x > t)
}

bbase <- function(x, xl, xr, ndx, deg){
# Construct B-spline basis from differences of truncated power functions
# Input
#   x:      x for which to compute basis
#   xl, xr: left and right boundary
#   nseg:   number of B-spline segments between xl and xr
#   deg:    degree (of the polynomial segments) of the B-spline
#
# Paul Eilers, 2003

    dx <- (xr - xl) / ndx
    knots <- seq(xl - deg * dx, xr + deg * dx, by = dx)
    P <- outer(x, knots, tpower, deg)
    n <- dim(P)[2]
    D <- diff(diag(n), differences = deg + 1) / (gamma(deg + 1) * dx ^ deg)
    B <- (-1) ^ (deg + 1) * P %*% t(D)
    B
}

==========================================


On Thu, 8 May 2003 15:07:56 +0100 (BST)
iwhite at staffmail.ed.ac.uk wrote:

> Apologies if this is this too obscure for R-help.
> 
> In package splines, ns(x,,knots,intercept=TRUE) produces an n by K+2
> matrix N, the values of K+2 basis functions for the natural splines with K
> (internal) knots, evaluated at x.  It does this by first generating an
> n by K+4 matrix B of unconstrained splines, then postmultiplying B by
> H, a K+4 by K+2 representation of the nullspace of C (2 by K+4), which
> contains the 2nd derivatives of the unconstrained splines evaluated at
> the boundary knots.  E.g. see Hastie and Tibshirani, Generalized Additive
> Models, exercise 2.5, p36.  The QR decomposition is used to get H.
> 
> This can produce basis functions which, while technically correct (they
> span the K+2 dim space of natural splines), can be counterintuitive.
> E.g. equally spaced knots symmetrically placed between the data extremes
> can produce very asymmetric arrangements, with N(K+2) not the mirror image
> of N(1), for example, and considerable loss of sparseness.
> 
> This approach works for any basis B, but for B-splines, the second
> derivatives are zero for all the unconstrained basis functions, apart
> from 3 at each end. All that is required is to combine these 3 so that
> the contributions to the 2nd derivatives cancel. In other words, we
> only need to find the null space of two 2 by 3 matrices, rather than a
> 2 by K+4. If the left-most internal knots are t(1) and t(2), and the
> left-hand boundary knot is t(0), we can replace B(1...3) with
> 
> B(1)+B(2)+B(3) and [t(2)-t(0)]*B(2) + [t(1)+t(2)-2*t(0)]*B(1),
> 
> (for example), and similarly at the right-hand end.
> 
> This seems simpler and more elegant than brute force QR on the full
> matrix of derivatives. But I may have missed some reason why it can't be
> used. Perhaps it doesn't work when intercept=FALSE?
> 
> ======================================
> I.White
> ICAPB, University of Edinburgh
> Ashworth Laboratories, West Mains Road
> Edinburgh EH9 3JT
> Fax: 0131 650 6564  Tel: 0131 650 5490
> E-mail: iwhite at staffmail.ed.ac.uk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

This is also a vote for using the truncated power basis which is extremely
simple and exceptionally fast for large datasets (see the rcspline.eval
function in the Hmisc package).  With modern matrix arithmetic (as in S),
the collinearity of the bases produced by these simple regression splines is
a moot point.
---
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From dmurdoch at pair.com  Fri May  9 13:05:56 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Fri, 09 May 2003 07:05:56 -0400
Subject: [R] windows data editor changes dimensions displayed data frames
In-Reply-To: <4.3.1.2.20030509112543.01856cf8@vttmail.vtt.fi>
References: <4.3.1.2.20030509112543.01856cf8@vttmail.vtt.fi>
Message-ID: <el2nbvspada1s7enpl6uiov70at0b943bo@4ax.com>

On Fri, 09 May 2003 11:34:08 +0300, Bernd Ebersberger
<bernd.ebersberger at vtt.fi> wrote:

>dear R-tists,
>
>i am experiencing a problem with the data editor in the windows version of 
>R 1.6.1 envoked with the command 'fix'.
>
>the data editor changes the size of large data frames.

I can confirm this in the current R-patched.  I'll take a look.  It
might be that some limitation to the code means you won't be able to
edit big data frames (it looks like somewhere it's using a 16 bit row
count), but it certainly shouldn't silently change things.

Duncan Murdoch

>a simple example illustrates this:
>
>-------------------------------------------------------
>
> > dfrm <- data.frame(no=c(1:100000))
> > length(dfrm[,1])
>
>[1] 100000
>
> > fix(dfrm)
>
> > length(dfrm[,1])
>
>[1] 34464
>
>--------------------------------------------------------
>
>
>does anybody have a quick remedy for this?
>
>i am not sure whether it is worth putting much developmental effort in 
>solving this particular problem.
>
>however, i believe that one should be aware of it when working with large 
>data sets.
>
>
>greetings from the northern edge of europe.
>
>bernd.



From brostaux.y at fsagx.ac.be  Fri May  9 13:29:49 2003
From: brostaux.y at fsagx.ac.be (Yves Brostaux)
Date: Fri, 09 May 2003 13:29:49 +0200
Subject: [R] Re: R-help Digest, Vol 2, Issue 26
In-Reply-To: <200304231010.h3NA4RUn002432@hypatia.math.ethz.ch>
Message-ID: <5.1.0.14.1.20030509132443.04a04a90@fusamail.fsagx.ac.be>

With the same system configuration (WinNT4 SP6 and 1.7.0), I get such a Dr 
Watson crash each time I try to use the Change dir... command in the File 
menu of Rgui.exe. I doesn't seems to happen if I do this immediately after 
starting R but well if I already did some computation.

I don't have any problem by using directly setwd().

At 12:10 23/04/03, you wrote:
>Date: Tue, 22 Apr 2003 20:25:32 -0400
>From: "Liaw, Andy" <andy_liaw at merck.com>
>Subject: [R] changing dir to network drive in Rgui caused crash
>         (1.7.0)
>To: "'R-help at stat.math.ethz.ch'" <R-help at stat.math.ethz.ch>
>Message-ID:
>         <3A822319EB35174CA3714066D590DCD5C4FA32 at usrymx25.merck.com>
>Content-Type: text/plain; charset=iso-8859-1
>
>Dear R-help,
>
>Has anyone experienced similar problem?  On WinNT4(sp6), running Rgui from
>1.7.0, when try to change directory to some network drive using the "File /
>Change dir..." menu, Rgui gets a visit by Dr. Watson.  If I first change dir
>to a local drive, then again to a network drive, it works fine.  It also
>works fine with setwd() from the command prompt.
>
>Best,
>Andy
>
>Andy I. Liaw, PhD
>Biometrics Research          Phone: (732) 594-0820
>Merck & Co., Inc.              Fax: (732) 594-1565
>P.O. Box 2000, RY84-16            Rahway, NJ 07065
>mailto:andy_liaw at merck.com
>
>
>
>------------------------------------------------------------------------------
>Notice: This e-mail message, together with any attachments, contains
>information of Merck & Co., Inc. (Whitehouse Station, New Jersey,
>USA) that may be confidential, proprietary copyrighted and/or legally
>privileged, and is intended solely for the use of the individual or entity
>named on this message. If you are not the intended recipient, and
>have received this message in error, please immediately return this by
>e-mail and then delete it.



From Robert.Cunningham  Fri May  9 13:52:59 2003
From: Robert.Cunningham (Robert.Cunningham)
Date: Fri, 9 May 2003 18:52:59 +0700
Subject: [R] windows data editor changes dimensions displayed data frames
In-Reply-To: <el2nbvspada1s7enpl6uiov70at0b943bo@4ax.com>
References: <4.3.1.2.20030509112543.01856cf8@vttmail.vtt.fi>
	<el2nbvspada1s7enpl6uiov70at0b943bo@4ax.com>
Message-ID: <16059.38555.938335.998547@gargle.gargle.HOWL>

And I can confirm it with


platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    7.0              
year     2003             
month    04               
day      16               
language R                

so it is not a Windows issue.


Cheers, 


Robert Cunningham


Duncan Murdoch writes:
 > On Fri, 09 May 2003 11:34:08 +0300, Bernd Ebersberger
 > <bernd.ebersberger at vtt.fi> wrote:
 > 
 > >dear R-tists,
 > >
 > >i am experiencing a problem with the data editor in the windows version of 
 > >R 1.6.1 envoked with the command 'fix'.
 > >
 > >the data editor changes the size of large data frames.
 > 
 > I can confirm this in the current R-patched.  I'll take a look.  It
 > might be that some limitation to the code means you won't be able to
 > edit big data frames (it looks like somewhere it's using a 16 bit row
 > count), but it certainly shouldn't silently change things.
 > 
 > Duncan Murdoch
 > 
 > >a simple example illustrates this:
 > >
 > >-------------------------------------------------------
 > >
 > > > dfrm <- data.frame(no=c(1:100000))
 > > > length(dfrm[,1])
 > >
 > >[1] 100000
 > >
 > > > fix(dfrm)
 > >
 > > > length(dfrm[,1])
 > >
 > >[1] 34464
 > >
 > >--------------------------------------------------------
 > >
 > >
 > >does anybody have a quick remedy for this?
 > >
 > >i am not sure whether it is worth putting much developmental effort in 
 > >solving this particular problem.
 > >
 > >however, i believe that one should be aware of it when working with large 
 > >data sets.
 > >
 > >
 > >greetings from the northern edge of europe.
 > >
 > >bernd.
 > 
 > ______________________________________________
 > R-help at stat.math.ethz.ch mailing list
 > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
 >



From ligges at statistik.uni-dortmund.de  Fri May  9 14:04:39 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 09 May 2003 14:04:39 +0200
Subject: [R] Re: R-help Digest, Vol 2, Issue 26
In-Reply-To: <5.1.0.14.1.20030509132443.04a04a90@fusamail.fsagx.ac.be>
References: <5.1.0.14.1.20030509132443.04a04a90@fusamail.fsagx.ac.be>
Message-ID: <3EBB9957.6000009@statistik.uni-dortmund.de>

Yves Brostaux wrote:
> With the same system configuration (WinNT4 SP6 and 1.7.0), I get such a 
> Dr Watson crash each time I try to use the Change dir... command in the 
> File menu of Rgui.exe. I doesn't seems to happen if I do this 
> immediately after starting R but well if I already did some computation.
> 
> I don't have any problem by using directly setwd().

This is already fixed by Duncan Murdoch in R-patched.

Uwe Ligges



From ripley at stats.ox.ac.uk  Fri May  9 14:04:58 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 9 May 2003 13:04:58 +0100 (BST)
Subject: [R] Re: R-help Digest, Vol 2, Issue 26
In-Reply-To: <5.1.0.14.1.20030509132443.04a04a90@fusamail.fsagx.ac.be>
Message-ID: <Pine.LNX.4.44.0305091304280.5533-100000@gannet.stats>

This is already corrected in R-patched (April 22 is a long time ago in R 
terms).

On Fri, 9 May 2003, Yves Brostaux wrote:

> With the same system configuration (WinNT4 SP6 and 1.7.0), I get such a Dr 
> Watson crash each time I try to use the Change dir... command in the File 
> menu of Rgui.exe. I doesn't seems to happen if I do this immediately after 
> starting R but well if I already did some computation.
> 
> I don't have any problem by using directly setwd().
> 
> At 12:10 23/04/03, you wrote:
> >Date: Tue, 22 Apr 2003 20:25:32 -0400
> >From: "Liaw, Andy" <andy_liaw at merck.com>
> >Subject: [R] changing dir to network drive in Rgui caused crash
> >         (1.7.0)
> >To: "'R-help at stat.math.ethz.ch'" <R-help at stat.math.ethz.ch>
> >Message-ID:
> >         <3A822319EB35174CA3714066D590DCD5C4FA32 at usrymx25.merck.com>
> >Content-Type: text/plain; charset=iso-8859-1
> >
> >Dear R-help,
> >
> >Has anyone experienced similar problem?  On WinNT4(sp6), running Rgui from
> >1.7.0, when try to change directory to some network drive using the "File /
> >Change dir..." menu, Rgui gets a visit by Dr. Watson.  If I first change dir
> >to a local drive, then again to a network drive, it works fine.  It also
> >works fine with setwd() from the command prompt.
> >
> >Best,
> >Andy
> >
> >Andy I. Liaw, PhD
> >Biometrics Research          Phone: (732) 594-0820
> >Merck & Co., Inc.              Fax: (732) 594-1565
> >P.O. Box 2000, RY84-16            Rahway, NJ 07065
> >mailto:andy_liaw at merck.com
> >
> >
> >
> >------------------------------------------------------------------------------
> >Notice: This e-mail message, together with any attachments, contains
> >information of Merck & Co., Inc. (Whitehouse Station, New Jersey,
> >USA) that may be confidential, proprietary copyrighted and/or legally
> >privileged, and is intended solely for the use of the individual or entity
> >named on this message. If you are not the intended recipient, and
> >have received this message in error, please immediately return this by
> >e-mail and then delete it.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From u9801539 at adelong.anu.edu.au  Fri May  9 14:11:40 2003
From: u9801539 at adelong.anu.edu.au (John Maindonald)
Date: Fri, 9 May 2003 22:11:40 +1000 (EST)
Subject: [R] again troubles with lattice
Message-ID: <200305091211.h49CBee16902@leonard.anu.edu.au>

It might be helpful to include a brief comment on the need for
an implicit or explicit call to print() in the information that 
is displayed by typing help(package=lattice)
It might be an extra sentence under Description:

> Date: Thu, 8 May 2003 10:05:40 -0500
> From: Deepayan Sarkar <deepayan at stat.wisc.edu>
> Subject: Re: [R] again troubles with lattice
> To: Wladimir Eremeev <wl at eimb.ru>, r-help at stat.math.ethz.ch
> 
>.....
> 
> Can you suggest any other place in the documentation where explaining this 
> would have helped you find it ?
> 
> Deepayan
John Maindonald                     email : john.maindonald at anu.edu.au
Centre for Bioinformation Science,  phone : (6125)3473        
c/o MSI,                            fax   : (6125)5549 
John Dedman Mathematical Sciences Building (Building 27)
Australian National University
Canberra ACT 0200
Australia



From ayalahec at msu.edu  Fri May  9 14:27:45 2003
From: ayalahec at msu.edu (Hector L. Ayala)
Date: Fri, 09 May 2003 08:27:45 -0400
Subject: [R] biplot and prcomp
In-Reply-To: <5.1.0.14.1.20030509132443.04a04a90@fusamail.fsagx.ac.be>
References: <200304231010.h3NA4RUn002432@hypatia.math.ethz.ch>
Message-ID: <5.2.1.1.0.20030509081732.00b5a5c8@mail.msu.edu>

R users
   As was mentioned before, the princomp() function in R 1.7.0 will 
complain if the data set has more columns than rows.  The alternative 
functions to generate a PCA analysis that will not complain about such type 
of data set are prcomp() or pca() (multiv library).  Although the results 
of both of them are almost identical, the outputs are not compatible with 
the biplot() function from mva.  Does anybody know if there is an 
alternative way to generate the biplot??  I can generate a two dimensional 
graph with the sample scores by plotting the values from the object where 
the results are, but how do I plot the arrows that represent the loadings???

thanks


Hector



********************************************
H?ctor L. Ayala-del-R?o, Ph.D.
Center for Microbial Ecology
Michigan State University
540 Plant & Soil Sciences Building
East Lansing, MI 48824
Tel: 517-353-9021
Fax: 517-353-2917
ayalahec at msu.edu



From maechler at stat.math.ethz.ch  Fri May  9 14:31:10 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 9 May 2003 14:31:10 +0200
Subject: [R] how to write text into a file
In-Reply-To: <XFMail.030509093439.Ted.Harding@nessie.mcc.ac.uk>
References: <Pine.A41.4.44.0305081703030.67374-100000@homer25.u.washington.edu>
	<XFMail.030509093439.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <16059.40846.313786.753721@gargle.gargle.HOWL>

>>>>> "Ted" == Ted Harding <Ted.Harding at nessie.mcc.ac.uk>
>>>>>     on Fri, 09 May 2003 09:34:39 +0100 (BST) writes:

    Ted> On 09-May-03 Thomas Lumley wrote:

    .........

    >> A fairly minor adjustment to capture.output(), to allow
    >> it to take an arbitrary connection for its `file'
    >> argument works very nicely, and one can then do eg
    >> capture.output(example(glm), file=pipe("enscript -o
    >> tempout.ps","w"))

    Ted> Hmm -- where does one find capture.output()? Doesn't
    Ted> seem to show up in any libraries I have installed.

It's one of the many  "NEW FEATURES" (mentioned in "NEWS") of R version 1.7.0

Martin



From jarioksa at sun3.oulu.fi  Fri May  9 15:20:41 2003
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: Fri, 09 May 2003 13:20:41 -0000
Subject: [R] biplot and prcomp
In-Reply-To: <5.2.1.1.0.20030509081732.00b5a5c8@mail.msu.edu>
References: <200304231010.h3NA4RUn002432@hypatia.math.ethz.ch>
	<5.2.1.1.0.20030509081732.00b5a5c8@mail.msu.edu>
Message-ID: <1052486421.11656.146.camel@pc112145.oulu.fi>

On Fri, 2003-05-09 at 15:27, Hector L. Ayala wrote:
> R users
>    As was mentioned before, the princomp() function in R 1.7.0 will 
> complain if the data set has more columns than rows.  The alternative 
> functions to generate a PCA analysis that will not complain about such type 
> of data set are prcomp() or pca() (multiv library).  Although the results 
> of both of them are almost identical, the outputs are not compatible with 
> the biplot() function from mva.  Does anybody know if there is an 
> alternative way to generate the biplot??  I can generate a two dimensional 
> graph with the sample scores by plotting the values from the object where 
> the results are, but how do I plot the arrows that represent the loadings???
> 
biplot function (1) plots row and column scores in the same plot, (2)
scales both row and column scores in some peculiar ways, and (3) uses
different axis systems for these column and row scores. In principle you
can do all this using plotting primitives such as plot, text (or points)
and arrows. As an alternative, you can edit biplot.princomp so that it
uses prcomp objects instead of princomp objects: chanse x$scores to x$x,
x$loadings to x$rotation and x$n.obs to nrow(x$x). I think that prcomp
and princomp define eigenvalues (x$sdev) differently: one uses biased
another unbiased variances. I don't remember which one uses which. You
can either ignore this or adjust x$sdev like needed. As a net result the
following minimal edition may do what you need:

biplot.prcomp <- 
function (x, choices = 1:2, scale = 1, pc.biplot = FALSE, ...)
{
    if (length(choices) != 2)
        stop("length of choices must be 2")
    if (!length(scores <- x$x))
        stop(paste("object", deparse(substitute(x)), "has no scores"))
    lam <- x$sdev[choices]
    if (is.null(n <- nrow(x$x)))
        n <- 1
    lam <- lam * sqrt(n)
    if (scale < 0 || scale > 1)
        warning("scale is outside [0, 1]")
    if (scale != 0)
        lam <- lam^scale
    else lam <- 1
    if (pc.biplot)
        lam <- lam/sqrt(n)
    biplot.default(t(t(scores[, choices])/lam), t(t(x$rotation[,
        choices]) * lam), ...)
    invisible()
}

A more flexible alternative that automatically adapts to changes in
biplot.princomp would be:

> biplot.prcomp <- 
function(x, ...)
{
   tmp <- list()
   tmp$scores <- x$x
   tmp$loadings <- x$rotation
   tmp$sdev <- x$sdev
   tmp$n.obs <- nrow(x$scores)
   class(tmp) <- "princomp"
   biplot(tmp, ...)
   invisible()
}

I haven't tested this, but it draws a graph (correct or incorrect, I
don't know).

As an alternative, you may consider using function rda in the vegan
package. This is for Redundancy Analysis sensu ter Braak, but without
constraints it will be yet another PCA (and it uses svd like prcomp).
This has a plot function which will put both row and column results into
same graph. The scaling is very peculiar, but as the author (Prof.
Ripley?) writes in ?biplot.princomp "There is considerable confusion
over the precise definitions", so these definitions might be tolerated
as well. At least the rda plots are scaled so that the results are a
graphical approximation to the data, i.e., cross product of used scores
will give a least squares approximation of the data. Difference to
biplot.princomp scaling is that same scale is used for both sets of
scores instead of using separate axis systems. Moreover, no arrows are
used in graphs but both row and column scores are defined by points or
text strings.

cheers, jari oksanen
-- 
Jari Oksanen -- Dept Biology, Univ Oulu, 90014 Oulu, Finland
Ph. +358 8 5531526, cell +358 40 5136529, fax +358 8 5531061
email jari.oksanen at oulu.fi, homepage http://cc.oulu.fi/~jarioksa/



From ml-r-help at epigenomics.com  Fri May  9 15:39:13 2003
From: ml-r-help at epigenomics.com (Klaus Juenemann)
Date: Fri, 09 May 2003 15:39:13 +0200
Subject: [R] interrupting embedded R
Message-ID: <news2mail-3EBBAF81.FAE4442C@epigenomics.com>

Hi, 

I am using R in an embedded fashion, i.e. I am initialising R with
'Rf_initEmbeddedR'
from a C program (which in my application is in turn embedded into Java
through JNI).

Now I want to interrupt a running R function. My first idea was to send
a SIGINT from 
another thread but that caused the whole thing to crash. My guess is
that the longjmp 
involved does not interact well with the rest of my program.

Any comments ?
Any other ideas how I can savely interrupt an embedded R session ?
Any help is greatly appreciated. 

Best
Klaus




-- 
Dr. Klaus Juenemann
 
Epigenomics AG          www.epigenomics.com           Kastanienallee 24
+493024345393                                              10435 Berlin



From dvumani at hotmail.com  Fri May  9 15:49:57 2003
From: dvumani at hotmail.com (Vumani Dlamini)
Date: Fri, 09 May 2003 13:49:57 +0000
Subject: [R] manipulating elements of a matrix
Message-ID: <Law11-F270koBilYwfY0000b7dd@hotmail.com>

Dear R users:

I have the following matrix.

0 1 1
0 1 0
2 1 0
3 0 0

I would like to spread the matrix such that whenever the row sum is greater 
than 1 the row is repeated the number of times given by the row sum. 
Furthermore I would like to split the following cases:

0 1 1
such that it map to the following matrix

0 1 0
0 0 1

such that each row adds up to 1.

I have no problems with cases like c(3,0,0) using "lapply" but I have no 
splitting cases of the form c(1,1,0) and thats where I need your help.

Thanking you as always.


Vumani Dlamini



From tsvetan.stoyanov at mirant.com  Fri May  9 16:25:09 2003
From: tsvetan.stoyanov at mirant.com (Stoyanov, Tsvetan)
Date: Fri, 9 May 2003 10:25:09 -0400 
Subject: [R] getAttr problem
Message-ID: <BA5106B991DBAE49AEB14CB58EDFA7AA01188EE4@atlexm04.na.mirant.net>

Hi all,

It seems that getAttr doesn't return "names" attribute properly as in
getAttrib(x, R_NamesSymbol));

If you look at section 4.7.4 in "Writing R Extensions", the second example of
SEXP out(SEXP, SEXP) returns NULL for the names attribute of the 
outer product. 

This is true for  R 1.7.0 on both Win2000 with mingw and Redhat 9.0 with gcc.

Is there something I am missing?
Best,
Tsvetan



From tlumley at u.washington.edu  Fri May  9 16:29:12 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 9 May 2003 07:29:12 -0700 (PDT)
Subject: [R] how to write text into a file
In-Reply-To: <XFMail.030509093439.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <Pine.A41.4.44.0305090728470.57958-100000@homer41.u.washington.edu>

On Fri, 9 May 2003 Ted.Harding at nessie.mcc.ac.uk wrote:

> Hmm -- where does one find capture.output()? Doesn't seem to show up in
> any libraries I have installed.
>

In R 1.7.0.

	-thomas



From ripley at stats.ox.ac.uk  Fri May  9 16:43:46 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 9 May 2003 15:43:46 +0100 (BST)
Subject: [R] getAttr problem
In-Reply-To: <BA5106B991DBAE49AEB14CB58EDFA7AA01188EE4@atlexm04.na.mirant.net>
Message-ID: <Pine.LNX.4.44.0305091535230.18953-100000@gannet.stats>

On Fri, 9 May 2003, Stoyanov, Tsvetan wrote:

> It seems that getAttr doesn't return "names" attribute properly as in

Is this getAttrib?

> getAttrib(x, R_NamesSymbol));

Really?  As it is widely used inside R, that seems implausible.

> If you look at section 4.7.4 in "Writing R Extensions", the second example of
> SEXP out(SEXP, SEXP) returns NULL for the names attribute of the 
> outer product. 

But the outer product is a matrix and does not have names, so NULL is 
correct.

> This is true for  R 1.7.0 on both Win2000 with mingw and Redhat 9.0 with gcc.

Well, the source code is the same for both systems, so that is not 
surprising (and BTW `mingw' is on ix86 port of gcc, and RH9 (no .0?) 
uses another ix86 port of gcc).

> Is there something I am missing?

Yes: could you supply a complete example with the results you get and an 
explanation as to why you think it is wrong?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From spencer.graves at pdf.com  Fri May  9 16:53:24 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 09 May 2003 07:53:24 -0700
Subject: [R] manipulating elements of a matrix
References: <Law11-F270koBilYwfY0000b7dd@hotmail.com>
Message-ID: <3EBBC0E4.3010500@pdf.com>

	  Since you mentioned "lapply", I wondered if you had considered the 
following:

A0 <- array(c(0, 0, 2, 3, 1, 1, 1, 0, 1, 0, 0, 0),
	dim=c(4, 3))
ind0 <- rep(1:4, pmax(1, A0[,1]))
A0[ind0,]

	  With a bit more messing about, I believe I could change "0 1 1" to "0 
1 0 / 0 0 1".  However, I could not find a two-line solution, so I'll 
leave it for you.

hth.  spencer graves

Vumani Dlamini wrote:
> Dear R users:
> 
> I have the following matrix.
> 
> 0 1 1
> 0 1 0
> 2 1 0
> 3 0 0
> 
> I would like to spread the matrix such that whenever the row sum is 
> greater than 1 the row is repeated the number of times given by the row 
> sum. Furthermore I would like to split the following cases:
> 
> 0 1 1
> such that it map to the following matrix
> 
> 0 1 0
> 0 0 1
> 
> such that each row adds up to 1.
> 
> I have no problems with cases like c(3,0,0) using "lapply" but I have no 
> splitting cases of the form c(1,1,0) and thats where I need your help.
> 
> Thanking you as always.
> 
> 
> Vumani Dlamini
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From tsvetan.stoyanov at mirant.com  Fri May  9 16:55:13 2003
From: tsvetan.stoyanov at mirant.com (Stoyanov, Tsvetan)
Date: Fri, 9 May 2003 10:55:13 -0400 
Subject: [R] getAttr problem
Message-ID: <BA5106B991DBAE49AEB14CB58EDFA7AA01188EE5@atlexm04.na.mirant.net>

Correct,

I meant getAttrib, and the "names" attribute is indeed NULL. I meant to say that the "dimnames" attribute of the outer product id NULL, when it should be given by those of the arguments.

I am just trying to reproduce the example in section 4.7.4:

out.R:
------
out <- function(x, y) .Call("out", as.double(x),as.double(y))

out.c:
------
#include <R.h>
#include <Rinternals.h>
SEXP out(SEXP x, SEXP y)
{
  int i, j, nx, ny;
  double tmp;
  SEXP ans, dim, dimnames;
  nx = length(x); ny = length(y);
  PROTECT(ans = allocVector(REALSXP, nx*ny));
  for(i = 0; i < nx; i++) {
    tmp = REAL(x)[i];
    for(j = 0; j < ny; j++)
      REAL(ans)[i + nx*j] = tmp * REAL(y)[j];
  }
  PROTECT(dim = allocVector(INTSXP, 2));
  INTEGER(dim)[0] = nx; INTEGER(dim)[1] = ny;
  setAttrib(ans, R_DimSymbol, dim);
  PROTECT(dimnames = allocVector(VECSXP, 2));
  SET_VECTOR_ELT(dimnames, 0, getAttrib(x,R_NamesSymbol));
  SET_VECTOR_ELT(dimnames, 1, getAttrib(y, R_NamesSymbol));
  setAttrib(ans, R_DimNamesSymbol, dimnames);
  UNPROTECT(3);
  return(ans);
}

Create out.dll, start R and here is the output:
-----------------------------------------------

> a
a1 a2 
 1  2 
> b
b1 b2 b3 
 3  4  5 
> dyn.load("out.dll")
> out(a,b)
     [,1] [,2] [,3]
[1,]    3    4    5
[2,]    6    8   10


If you replace the last line of out.c with 
return(getAttrib(x, R_NamesSymbol));
you will see that getAttrib returns NULL.


Tsvetan

-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
Sent: Friday, May 09, 2003 10:44 AM
To: Stoyanov, Tsvetan
Cc: 'r-help at stat.math.ethz.ch'
Subject: Re: [R] getAttr problem


On Fri, 9 May 2003, Stoyanov, Tsvetan wrote:

> It seems that getAttr doesn't return "names" attribute properly as in

Is this getAttrib?

> getAttrib(x, R_NamesSymbol));

Really?  As it is widely used inside R, that seems implausible.

> If you look at section 4.7.4 in "Writing R Extensions", the second example of
> SEXP out(SEXP, SEXP) returns NULL for the names attribute of the 
> outer product. 

But the outer product is a matrix and does not have names, so NULL is 
correct.

> This is true for  R 1.7.0 on both Win2000 with mingw and Redhat 9.0 with gcc.

Well, the source code is the same for both systems, so that is not 
surprising (and BTW `mingw' is on ix86 port of gcc, and RH9 (no .0?) 
uses another ix86 port of gcc).

> Is there something I am missing?

Yes: could you supply a complete example with the results you get and an 
explanation as to why you think it is wrong?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tsvetan.stoyanov at mirant.com  Fri May  9 17:03:10 2003
From: tsvetan.stoyanov at mirant.com (Stoyanov, Tsvetan)
Date: Fri, 9 May 2003 11:03:10 -0400 
Subject: [R] getAttr problem
Message-ID: <BA5106B991DBAE49AEB14CB58EDFA7AA01188EE6@atlexm04.na.mirant.net>

Ok, 

it is trivial, it in in the R function, it has as.double which removes the names.
Anyhow, the example in the text should be clarified.

Tsvetan

-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
Sent: Friday, May 09, 2003 10:44 AM
To: Stoyanov, Tsvetan
Cc: 'r-help at stat.math.ethz.ch'
Subject: Re: [R] getAttr problem


On Fri, 9 May 2003, Stoyanov, Tsvetan wrote:

> It seems that getAttr doesn't return "names" attribute properly as in

Is this getAttrib?

> getAttrib(x, R_NamesSymbol));

Really?  As it is widely used inside R, that seems implausible.

> If you look at section 4.7.4 in "Writing R Extensions", the second example of
> SEXP out(SEXP, SEXP) returns NULL for the names attribute of the 
> outer product. 

But the outer product is a matrix and does not have names, so NULL is 
correct.

> This is true for  R 1.7.0 on both Win2000 with mingw and Redhat 9.0 with gcc.

Well, the source code is the same for both systems, so that is not 
surprising (and BTW `mingw' is on ix86 port of gcc, and RH9 (no .0?) 
uses another ix86 port of gcc).

> Is there something I am missing?

Yes: could you supply a complete example with the results you get and an 
explanation as to why you think it is wrong?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri May  9 17:03:14 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 9 May 2003 16:03:14 +0100 (BST)
Subject: [R] getAttr problem
In-Reply-To: <BA5106B991DBAE49AEB14CB58EDFA7AA01188EE5@atlexm04.na.mirant.net>
Message-ID: <Pine.LNX.4.44.0305091557470.18953-100000@gannet.stats>

On Fri, 9 May 2003, Stoyanov, Tsvetan wrote:

> I meant getAttrib, and the "names" attribute is indeed NULL. I meant to
> say that the "dimnames" attribute of the outer product id NULL, when it
> should be given by those of the arguments.

It is:  as.double(x) and as.double(y) have no names.

> I am just trying to reproduce the example in section 4.7.4:
> 
> out.R:
> ------
> out <- function(x, y) .Call("out", as.double(x),as.double(y))

That's the R code for the first version: that for the second version is 
not given.  Remember this is an illustration of expanding an example.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mschwartz at medanalytics.com  Fri May  9 17:40:04 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 9 May 2003 10:40:04 -0500
Subject: [R] getAttr problem
In-Reply-To: <BA5106B991DBAE49AEB14CB58EDFA7AA01188EE6@atlexm04.na.mirant.net>
Message-ID: <001901c31641$443dc510$0201a8c0@MARC>

>-----Original Message-----
>From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
>Sent: Friday, May 09, 2003 10:44 AM
>To: Stoyanov, Tsvetan
>Cc: 'r-help at stat.math.ethz.ch'
>Subject: Re: [R] getAttr problem
>
> SNIP
>
>> This is true for  R 1.7.0 on both Win2000 with mingw and 
>Redhat 9.0 with gcc.
>
>Well, the source code is the same for both systems, so that is not 
>surprising (and BTW `mingw' is on ix86 port of gcc, and RH9 (no .0?) 
>uses another ix86 port of gcc).
>
> SNIP
>
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595


Starting with RH 9 (no .0), RH is moving away from the minor version
numbering scheme to focus on incremental updates to the major versions
via the RH Network.  Presumably this is a marketing driven approach
to:

1. Secure additional incremental and predictable annual revenue via
RHN support programs 

and 

2. Reduce the typical delays in new x.0 version adoption as opposed to
having folks wait for a x.1 release. Combined with the shortened End
of Life timelines for older versions that have been announced by RH,
this would *in theory* reduce the number of versions RH has to support
in the market place, reducing RH's version specific support costs.

Thus, more revenue and lower cost -> enhanced profitability.

HTH,

Marc Schwartz



From xirui at cs.tu-berlin.de  Fri May  9 17:40:32 2003
From: xirui at cs.tu-berlin.de (Xirui Yang)
Date: Fri, 9 May 2003 17:40:32 +0200 (MEST)
Subject: [R] how to write text into a file
In-Reply-To: <Pine.A41.4.44.0305090728470.57958-100000@homer41.u.washington.edu>
References: <Pine.A41.4.44.0305090728470.57958-100000@homer41.u.washington.edu>
Message-ID: <Pine.SOL.4.53.0305091720490.3257@gulden>

Thank you, Dennis, Ray, Ted, Thomas, Adaikalavan, Tobias and Martin,

Now the status is:

1. The commands sink() and connection.output send text ouput to a text
file. This file may be converted to a postscript format With the
command enscript in Unix/Linux. But what is about the graphical output?
May I add the graphical ouptut into this file? Or there will be two
files, one for text output, one for graphical ouput?

2. Dennis and Adaikalavan have recommended the Sweave, which generates
statistical reports dynamically in pdf format. I will check it.

Thank you,
Xirui




On Fri, 9 May 2003, Thomas Lumley wrote:

> On Fri, 9 May 2003 Ted.Harding at nessie.mcc.ac.uk wrote:
>
> > Hmm -- where does one find capture.output()? Doesn't seem to show up in
> > any libraries I have installed.
> >
>
> In R 1.7.0.
>
> 	-thomas
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From ripley at stats.ox.ac.uk  Fri May  9 17:50:04 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 9 May 2003 16:50:04 +0100 (BST)
Subject: [R] getAttr problem
In-Reply-To: <BA5106B991DBAE49AEB14CB58EDFA7AA01188EE6@atlexm04.na.mirant.net>
Message-ID: <Pine.LNX.4.44.0305091644400.19127-100000@gannet.stats>

On Fri, 9 May 2003, Stoyanov, Tsvetan wrote:

> Ok, 
> 
> it is trivial, it in in the R function, it has as.double which removes the names.
> Anyhow, the example in the text should be clarified.


Let me point out the following extract from R-exts.R, *in the same directory*

## ----- outer products example -----

out <- function(x, y) .Call("out", as.double(x), as.double(y))
out(1:3, 2:4)

x <- as.double(1:3); names(x) <- letters[x]
# so as not to lose names
out <- function(x, y) .Call("out", x, y)
out(x, as.double(2:4))

so the lack of clarity is not in the R sources (which do at least get the 
function names right).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From huan.huang at bnpparibas.com  Fri May  9 18:04:59 2003
From: huan.huang at bnpparibas.com (huan.huang@bnpparibas.com)
Date: Fri, 9 May 2003 17:04:59 +0100
Subject: [R] VBA function InStrRev in RCOM
Message-ID: <OF8E50A85F.5884AD02-ON80256D21.00585919@bnpparibas.com>


Dear all,

I am trying to use R within Excel 97. Seems the VBA with Excel 97 does not
recognize
function "InStrRev" (it gives error message when I try to launch RExcel
Help, just the same as that it doesn't recognize function "Replace"). A
solution for frunction Replace has been provided (Ritter, Christian ,
http://mailman.csd.univie.ac.at/pipermail/rcom-l/2003-May/000005.html). I
am
wondering if someone has a solution for function InStrRev.

Many thanks.

Huan




This message and any attachments (the "message") is\ intended so... {{dropped}}



From pgilbert at bank-banque-canada.ca  Fri May  9 18:03:20 2003
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Fri, 09 May 2003 12:03:20 -0400
Subject: [R] building R 1.7.0 with gcc 3.2.3 on Solaris 
Message-ID: <3EBBD148.5050000@bank-banque-canada.ca>

With gcc 3.2.3 on SunOS 5.8 and R 1.7.0, configure fails for me unless I 
set LDFLAGS ( LDFLAGS=-L/apps/asd/unix/gnu/gcc/3.2.3/SunOS5.8/lib ). 
With that set it appears that configure succeeds (i.e. no error messages 
on the console), but config.log contains messages

configure:4099: checking for gcc option to accept ANSI C
configure:4160: gcc  -c -g -O2 -I/usr/local/include conftest.c >&5
In file included from configure:4124:
/usr/include/sys/stat.h:258: syntax error before "blksize_t"
/usr/include/sys/stat.h:262: syntax error before '}' token
/usr/include/sys/stat.h:318: syntax error before "blksize_t"
/usr/include/sys/stat.h:319: conflicting types for `st_blocks'
/usr/include/sys/stat.h:259: previous declaration of `st_blocks'
/usr/include/sys/stat.h:322: syntax error before '}' token
configure:4163: $? = 1
configure: failed program was:
| #line 4106 "configure"
| /* confdefs.h.  */
|
| #define PACKAGE_NAME "R"
| #define PACKAGE_TARNAME "R"
| #define PACKAGE_VERSION "1.7.0"
| #define PACKAGE_STRING "R 1.7.0"


Make then fails with

gcc -I. -I../../src/include -I../../src/include -I/usr/openwin/include 
-I/usr/local/include -DHAVE_CONFIG_H   -g -O2 -c sys-unix.c -o sys-unix.o
In file included from sys-unix.c:31:
/usr/include/sys/stat.h:258: syntax error before "blksize_t"
/usr/include/sys/stat.h:262: syntax error before '}' token
/usr/include/sys/stat.h:318: syntax error before "blksize_t"
/usr/include/sys/stat.h:319: conflicting types for `st_blocks'
/usr/include/sys/stat.h:259: previous declaration of `st_blocks'
/usr/include/sys/stat.h:322: syntax error before '}' token
make[3]: *** [sys-unix.o] Error 1
make[3]: Leaving directory `/home/com1/gilp/toolchain/R/R-1.7.0/src/unix'
make[2]: *** [R] Error 2

Any suggestions would be greatly appreciated.

Paul Gilbert



From rossini at blindglobe.net  Fri May  9 18:20:04 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Fri, 09 May 2003 09:20:04 -0700
Subject: [R] how to write text into a file
In-Reply-To: <Pine.SOL.4.53.0305091720490.3257@gulden> (Xirui Yang's message
	of "Fri, 9 May 2003 17:40:32 +0200 (MEST)")
References: <Pine.A41.4.44.0305090728470.57958-100000@homer41.u.washington.edu>
	<Pine.SOL.4.53.0305091720490.3257@gulden>
Message-ID: <87fznoxfbf.fsf@jeeves.blindglobe.net>

Xirui Yang <xirui at cs.tu-berlin.de> writes:

> 1. The commands sink() and connection.output send text ouput to a text
> file. This file may be converted to a postscript format With the
> command enscript in Unix/Linux. But what is about the graphical output?
> May I add the graphical ouptut into this file? Or there will be two
> files, one for text output, one for graphical ouput?

You don't want to go there.  You REALLY do not want to go there...

> 2. Dennis and Adaikalavan have recommended the Sweave, which generates
> statistical reports dynamically in pdf format. I will check it.

This would be a better starting point (and I think, MUCH more
interesting).  I'm sure Fritz could chime in, but there are MANY
places where things could be greatly simplified, documentation
improved, interface made better, prototypes/templates constructed,
etc.  It could easily be "dumbed down" to provide what you are talking
about; the difficulty would be in documenting how to configure, as
well as figuring out the proper interfaces/approaches.

Not nearly as exciting as pulling out a keyboard and coding furiously,
but much more useful and potentially having a broader impact.

best,
-tony

-- 
A.J. Rossini rossini at u.washington.edu http://software.biostat.washington.edu/ 
Biostatistics, U Washington and Fred Hutchinson Cancer Research Center

FHCRC:Tu: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email 
UW  : Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX 

CONFIDENTIALITY NOTICE: This e-mail message and any attachments ... {{dropped}}



From ripley at stats.ox.ac.uk  Fri May  9 18:32:08 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 9 May 2003 17:32:08 +0100 (BST)
Subject: [R] building R 1.7.0 with gcc 3.2.3 on Solaris 
In-Reply-To: <3EBBD148.5050000@bank-banque-canada.ca>
Message-ID: <Pine.LNX.4.44.0305091724080.23696-100000@gannet.stats>

On Fri, 9 May 2003, Paul Gilbert wrote:

> With gcc 3.2.3 on SunOS 5.8 and R 1.7.0, configure fails for me unless I 
> set LDFLAGS ( LDFLAGS=-L/apps/asd/unix/gnu/gcc/3.2.3/SunOS5.8/lib ). 

It works here with gcc installed in /usr/local/lib.  

> With that set it appears that configure succeeds (i.e. no error messages 
> on the console), but config.log contains messages
> 
> configure:4099: checking for gcc option to accept ANSI C
> configure:4160: gcc  -c -g -O2 -I/usr/local/include conftest.c >&5
> In file included from configure:4124:
> /usr/include/sys/stat.h:258: syntax error before "blksize_t"
> /usr/include/sys/stat.h:262: syntax error before '}' token
> /usr/include/sys/stat.h:318: syntax error before "blksize_t"
> /usr/include/sys/stat.h:319: conflicting types for `st_blocks'
> /usr/include/sys/stat.h:259: previous declaration of `st_blocks'
> /usr/include/sys/stat.h:322: syntax error before '}' token
> configure:4163: $? = 1
> configure: failed program was:
> | #line 4106 "configure"
> | /* confdefs.h.  */
> |
> | #define PACKAGE_NAME "R"
> | #define PACKAGE_TARNAME "R"
> | #define PACKAGE_VERSION "1.7.0"
> | #define PACKAGE_STRING "R 1.7.0"

No such entries here.

Those errors are in the stat structure, following a section

#if !defined(_XOPEN_SOURCE) && !defined(_POSIX_C_SOURCE) || \
        defined(__EXTENSIONS__)

Do you have any of those defined?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Fri May  9 18:41:57 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri, 09 May 2003 16:41:57 -0000
Subject: [R] building R 1.7.0 with gcc 3.2.3 on Solaris
In-Reply-To: <Pine.LNX.4.44.0305091724080.23696-100000@gannet.stats>
References: <Pine.LNX.4.44.0305091724080.23696-100000@gannet.stats>
Message-ID: <x265ok83v5.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> On Fri, 9 May 2003, Paul Gilbert wrote:
> 
> > With gcc 3.2.3 on SunOS 5.8 and R 1.7.0, configure fails for me unless I 
> > set LDFLAGS ( LDFLAGS=-L/apps/asd/unix/gnu/gcc/3.2.3/SunOS5.8/lib ). 
> 
> It works here with gcc installed in /usr/local/lib.  

A longshot: This sort of thing happens if you accidentally mix
multiple versions of gcc. Are you sure you don't also need to put
/apps/asd/unix/gnu/gcc/3.2.3/SunOS5.8/bin or so at the head of your
PATH so as not to pick up another gcc?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From pwallem at bio.puc.cl  Fri May  9 20:26:05 2003
From: pwallem at bio.puc.cl (Petra Wallem)
Date: Fri, 9 May 2003 13:26:05 -0500
Subject: [R] correspondence analysis
Message-ID: <200305091326.05048.pwallem@bio.puc.cl>

Hi everybody, I am starting my friendship with R. Now I want to do a 
Correspondence Analysis using the vegan library or multiv library. Both give 
me the same results which differ from the ones I get running other programs 
like Statistica... I wounder if there is a problem with my matrix. I have 
cualitataive variable in the columns and sampling units in the rows... I 
import my matrix into R with matrix(scan....), which dose not accept strings, 
so I have eliminated all the names of my rows and columns and just worked 
with the acctual values of my matrix, is that the problem I have?
Thanks a lot to everybody
Petra



From shitao at hotmail.com  Fri May  9 21:48:20 2003
From: shitao at hotmail.com (Tao Shi)
Date: Fri, 09 May 2003 19:48:20 +0000
Subject: R crashes with package SJava; was [R] Memory leakage?  
Message-ID: <Sea2-F50u64t1j9ynvZ00014b9d@hotmail.com>

I observe this even when I exit R naturally by close the R windows or type 
q().  I'm still searching for the patterns.............  One thing for sure 
(may be kind of obvious to you guys) is that this only happens when the CPU 
is already runing at 100% before I exit R.

...Tao

---------------------------------------------------------------------
Dear all,

Maybe this has something to do with R crashing?
When my R version crashes, there is Rgui.exe still
running in the background (i.e. W2K's task manager
recognises it only as a process, which apparently
is using almost 100% of the CPU).



From tothri2000 at yahoo.ca  Fri May  9 23:02:08 2003
From: tothri2000 at yahoo.ca (ge yreyt)
Date: Fri, 9 May 2003 17:02:08 -0400 (EDT)
Subject: [R] generate correlated dataset
Message-ID: <20030509210209.601.qmail@web41609.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030509/9df06569/attachment.pl

From reid_huntsinger at merck.com  Sat May 10 00:12:14 2003
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Fri, 09 May 2003 18:12:14 -0400
Subject: [R] generate correlated dataset
Message-ID: <2C23DE2983BE034CB1CB90DB6B813FD6061251F5@uswpmx11.merck.com>

You could use mvrnorm once for each cluster, with a different mean vector
each time (if you mean clusters in that sense.) 

You could draw the number of observations in a cluster randomly if that's
important.

Reid Huntsinger

-----Original Message-----
From: ge yreyt [mailto:tothri2000 at yahoo.ca] 
Sent: Friday, May 09, 2003 5:02 PM
To: r-help
Subject: [R] generate correlated dataset


Hi,I want to generate a dataset, which have more than one clusters (say 2)
and the elements in each cluster have high correlation (say 0.85)
andelements among different clusters have low (say 0.1) or zero
correlation.The correlation structure of final dataset should have a
block-diagonal structure, that likes  0.85 0.85 .. 0.85 0 0 0 0 ...0 0 0...0
0 0 .......................................................0.85 0.85  ..
0.85 0 0 0 0...0 0 0 ...0 0 0 0 0 0 0 000 0000 0.85 0.85 0.85 ....
0.85.........................................................0 0 0 0 0......
0 0 0.85 0.85 .............0.85 for each block (cluster), I can use mvrnorm
command to generate data,but the key problem is I do not know how to
generate data which have 0correlation when elements are among different
clusters???? Thank you very much for your help!!! pin   


---------------------------------
Post your free ad now! Yahoo! Canada Personals

	[[alternate HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help

------------------------------------------------------------------------------
Notice: This e-mail message, together with any attachments, cont... {{dropped}}



From spencer.graves at pdf.com  Sat May 10 00:48:12 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 09 May 2003 15:48:12 -0700
Subject: [R] generate correlated dataset
References: <2C23DE2983BE034CB1CB90DB6B813FD6061251F5@uswpmx11.merck.com>
Message-ID: <3EBC302C.3070002@pdf.com>

	  To get a target correlation between observations in different 
clusters, consider the following:

	  var(Y) = E(var(Y|X))+var(E(Y|X)).

	  The correlation between observations in a give cluster is determined 
by E(var(Y|X)).  To get a target correction between clusters, select 
E(Y|X)) so var(Y) is what you want.

hope this helps.  spencer graves

Huntsinger, Reid wrote:
> You could use mvrnorm once for each cluster, with a different mean vector
> each time (if you mean clusters in that sense.) 
> 
> You could draw the number of observations in a cluster randomly if that's
> important.
> 
> Reid Huntsinger
> 
> -----Original Message-----
> From: ge yreyt [mailto:tothri2000 at yahoo.ca] 
> Sent: Friday, May 09, 2003 5:02 PM
> To: r-help
> Subject: [R] generate correlated dataset
> 
> 
> Hi,I want to generate a dataset, which have more than one clusters (say 2)
> and the elements in each cluster have high correlation (say 0.85)
> andelements among different clusters have low (say 0.1) or zero
> correlation.The correlation structure of final dataset should have a
> block-diagonal structure, that likes  0.85 0.85 .. 0.85 0 0 0 0 ...0 0 0...0
> 0 0 .......................................................0.85 0.85  ..
> 0.85 0 0 0 0...0 0 0 ...0 0 0 0 0 0 0 000 0000 0.85 0.85 0.85 ....
> 0.85.........................................................0 0 0 0 0......
> 0 0 0.85 0.85 .............0.85 for each block (cluster), I can use mvrnorm
> command to generate data,but the key problem is I do not know how to
> generate data which have 0correlation when elements are among different
> clusters???? Thank you very much for your help!!! pin   
> 
> 
> ---------------------------------
> Post your free ad now! Yahoo! Canada Personals
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ------------------------------------------------------------------------------
> Notice: This e-mail message, together with any attachments, cont... {{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From contatti at componentsengine.com  Sat May 10 07:12:27 2003
From: contatti at componentsengine.com (contatti@componentsengine.com)
Date: Sat, 10 May 2003 06:12:27 +0100
Subject: [R] The spare parts revolution
Message-ID: <00b602712050a53PROGETPLUS01@i-vm.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030510/b00979ad/attachment.pl

From vprovi at essex.ac.uk  Fri May  9 14:35:20 2003
From: vprovi at essex.ac.uk (Provizionatou, Vikentia)
Date: Fri, 9 May 2003 13:35:20 +0100
Subject: [R] Anybody using the evir package?
Message-ID: <001501c31627$76181050$877ef59b@vic>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030509/9137f758/attachment.pl

From ligges at statistik.uni-dortmund.de  Sat May 10 15:16:38 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 10 May 2003 15:16:38 +0200
Subject: [R] Anybody using the evir package?
In-Reply-To: <001501c31627$76181050$877ef59b@vic>
References: <001501c31627$76181050$877ef59b@vic>
Message-ID: <3EBCFBB6.9030202@statistik.uni-dortmund.de>

Provizionatou, Vikentia wrote:
> I am trying to use the evir package but I cannot find a way to change my excel csv files into R-objects, which are used in the package.
> 
> In particular, I do not know how to change a csv list object into a numeric vector.
> 
> Anybody done this before?
> 
> Thanks in advance for your time.
>
> Vikentia

See the manual R Data Import/Export and ?read.csv.

Uwe Ligges



From m.wegmann at web.de  Sat May 10 20:01:38 2003
From: m.wegmann at web.de (Martin Wegmann)
Date: Sat, 10 May 2003 18:01:38 +0000
Subject: [R] error in qr(x)
Message-ID: <200305101801.39112.m.wegmann@web.de>

Hello, 

I get the following prompt when tring to compute rlm:

> x<-rlm(core.e, na.action=na.omit)
>Error in qr(x) : NA/NaN/Inf in foreign function call (arg 1)

I checked with is.finite and is.infinite but in both cases i get FALSE and my 
missing values are substituted by NA. 

what does this error prompt mean and how do I solve it?

thanks in advance, cheers Martin


-- 
Martin Wegmann
Department of Animal Ecology and Tropical Biology
Zoology III, Biocenter
Am Hubland
D-97074 W?rzburg
Germany
E-Mail: 
wegmann at biozentrum.uni-wuerzburg.de
m.wegmann at web.de



From wolski at molgen.mpg.de  Sat May 10 18:49:34 2003
From: wolski at molgen.mpg.de (Eryk Wolski)
Date: Sat, 10 May 2003 18:49:34 +0200 (MET DST)
Subject: [R] Http Get-Post
Message-ID: <Pine.OSF.4.31.0305101843120.21355-100000@molgix.molgen.mpg.de>

Hi!

How can i send http Post and Get messages to a Web server from within R?
Is there something like?
form(action="http://big.thing.inf/cgi-bin/answer.pl",list(test="my",something="there"),method="POST")
Or is is there an example how to write it with R?
What functions to use to write such a function?

Eryk



From ripley at stats.ox.ac.uk  Sat May 10 20:16:07 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 10 May 2003 19:16:07 +0100 (BST)
Subject: [R] Http Get-Post
In-Reply-To: <Pine.OSF.4.31.0305101843120.21355-100000@molgix.molgen.mpg.de>
Message-ID: <Pine.LNX.4.44.0305101914150.29543-100000@gannet.stats>

They are just text that you write to a socket, so try

help.search("socket")

On Sat, 10 May 2003, Eryk Wolski wrote:

> How can i send http Post and Get messages to a Web server from within R?
> Is there something like?
> form(action="http://big.thing.inf/cgi-bin/answer.pl",list(test="my",something="there"),method="POST")
> Or is is there an example how to write it with R?
> What functions to use to write such a function?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From spencer.graves at pdf.com  Sat May 10 20:56:32 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 10 May 2003 11:56:32 -0700
Subject: [R] error in qr(x)
References: <200305101801.39112.m.wegmann@web.de>
Message-ID: <3EBD4B60.70308@pdf.com>

Have you tried removing the NA's beforecalling "rlm"?

hth.  spencer graves

Martin Wegmann wrote:
> Hello, 
> 
> I get the following prompt when tring to compute rlm:
> 
> 
>>x<-rlm(core.e, na.action=na.omit)
>>Error in qr(x) : NA/NaN/Inf in foreign function call (arg 1)
> 
> 
> I checked with is.finite and is.infinite but in both cases i get FALSE and my 
> missing values are substituted by NA. 
> 
> what does this error prompt mean and how do I solve it?
> 
> thanks in advance, cheers Martin
> 
>



From chumpmonkey at hushmail.com  Sat May 10 22:36:09 2003
From: chumpmonkey at hushmail.com (chumpmonkey@hushmail.com)
Date: Sat, 10 May 2003 13:36:09 -0700
Subject: [R] Adding splines to a coplot?
Message-ID: <200305102036.h4AKa975032371@mailserver3.hushmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

I appologize in advance if this is trivial. However, is it possible to
fit a spline to each panel of a coplot and specify the color and lwd
and such? I searced the archive and found this from the heady days of
2000.

http://maths.newcastle.edu.au/~rking/R/help/00a/1598.html

Is there an easier non-fake way to do this?

- -Thanks, CM
-----BEGIN PGP SIGNATURE-----
Version: Hush 2.2 (Java)
Note: This signature can be verified at https://www.hushtools.com/verify

wmAEARECACAFAj69Yq8ZHGNodW1wbW9ua2V5QGh1c2htYWlsLmNvbQAKCRA20AL0XmId
oh91AKCCfcoUwV/6kv9w8wWyuQv877H8AgCeL4TMeewGBFXektY3mHtQvT3wK1Q=
=noyh
-----END PGP SIGNATURE-----



From fjmolina at lbl.gov  Mon May 12 02:34:05 2003
From: fjmolina at lbl.gov (Francisco J Molina)
Date: Sun, 11 May 2003 17:34:05 -0700
Subject: [R] I can not load MASS at starting R
Message-ID: <16062.60413.543039.521455@0-d0-68-1-df-fa.dhcp.lbl.gov>


I have istalled R with the rpm package available for RedHat 9.0.
My machine is a pentium4.

This is my .Rprofile file ( placed in my home directory ):

w <- function ( x, y ) write.table ( t ( x ), file = y, quote = F, col.names = F, row.names = F, sep = ',' )
q <- function () q ( save = 'no' )
library( stepfun )
library ( MASS )

The MASS library is not loaded when R is started. These are the error
messages I got:

Error in get(x, envir, mode, inherits) : variable "biplot" was not found
Error in library(MASS) : package/namespace load failed



From mschwartz at medanalytics.com  Sun May 11 03:29:00 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Sat, 10 May 2003 20:29:00 -0500
Subject: [R] I can not load MASS at starting R
In-Reply-To: <16062.60413.543039.521455@0-d0-68-1-df-fa.dhcp.lbl.gov>
Message-ID: <000401c3175c$b437c610$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
>Francisco J Molina
>Sent: Sunday, May 11, 2003 7:34 PM
>To: r-help
>Subject: [R] I can not load MASS at starting R
>
>
>
>I have istalled R with the rpm package available for RedHat 9.0.
>My machine is a pentium4.
>
>This is my .Rprofile file ( placed in my home directory ):
>
>w <- function ( x, y ) write.table ( t ( x ), file = y, quote 
>= F, col.names = F, row.names = F, sep = ',' )
>q <- function () q ( save = 'no' )
>library( stepfun )
>library ( MASS )
>
>The MASS library is not loaded when R is started. These are the error
>messages I got:
>
>Error in get(x, envir, mode, inherits) : variable "biplot" was 
>not found
>Error in library(MASS) : package/namespace load failed

Francisco,

Instead of using:

library(MASS)
library(stepfun)

Use:

options(defaultPackages=c(getOption("defaultPackages"), "MASS",
"stepfun"))

That should resolve the problem.

HTH,

Marc Schwartz



From ripley at stats.ox.ac.uk  Sun May 11 09:07:24 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 11 May 2003 08:07:24 +0100 (BST)
Subject: [R] I can not load MASS at starting R
In-Reply-To: <16062.60413.543039.521455@0-d0-68-1-df-fa.dhcp.lbl.gov>
Message-ID: <Pine.LNX.4.44.0305110801430.5571-100000@gannet.stats>

This is known: search the archives for the solutions (you are not intended
to use .Rprofile to call library(): that's the purpose of
options("defaultPackages") so set that, but there are at least two other 
solutions.)

Specifically, I sent a message to R-help on

Date: Sat, 3 May 2003 08:42:39 +0100 (BST)
Subject: Re: [R] failed to load MASS at start up


On Sun, 11 May 2003, Francisco J Molina wrote:

> I have istalled R with the rpm package available for RedHat 9.0.
> My machine is a pentium4.
> 
> This is my .Rprofile file ( placed in my home directory ):
> 
> w <- function ( x, y ) write.table ( t ( x ), file = y, quote = F, col.names = F, row.names = F, sep = ',' )
> q <- function () q ( save = 'no' )
> library( stepfun )
> library ( MASS )
> 
> The MASS library is not loaded when R is started. These are the error
> messages I got:
> 
> Error in get(x, envir, mode, inherits) : variable "biplot" was not found
> Error in library(MASS) : package/namespace load failed

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ozric at web.de  Sun May 11 12:00:43 2003
From: ozric at web.de (Christian Schulz)
Date: Sun, 11 May 2003 12:00:43 +0200
Subject: [R] simulating data
Message-ID: <001a01c317a4$3040bbd0$0100a8c0@pc>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030511/93991c48/attachment.pl

From wl at eimb.ru  Sun May 11 15:03:06 2003
From: wl at eimb.ru (Wladimir Eremeev)
Date: Sun, 11 May 2003 17:03:06 +0400
Subject: [R] what does boxplot draw?
In-Reply-To: <200305111010.h4BA2Yru016730@hypatia.math.ethz.ch>
References: <200305111010.h4BA2Yru016730@hypatia.math.ethz.ch>
Message-ID: <3710.030511@eimb.ru>

Dear r-help,

   Unfortunately I cannot find in the documentation what determines
   ranges of a 'box' in the box-and-whisker plot.
   
   It is said in "Simple R" (http://www.math.csi.cuny.edu/Statistics/R/simpleR)
   that they are 1st and 3rd Qus usually.

   I tried to add to boxplot lines with (quantile(x,probs=0.25)), but
   lines do not coincide with edges of boxes.

Here's the example. I've got 3 vectors of values, x1,x2,x3

The command

boxplot(list(x1,x2,x3))

draws 3 box-and-whisker diagrams.

Commands

lines(c(quantile(x1,probs=c(0.25)),quantile(x2,probs=c(0.25)),quantile(x3,probs=c(0.25))))
lines(c(quantile(x1,probs=c(0.75)),quantile(x2,probs=c(0.75)),quantile(x3,probs=c(0.75))))

draw lines with y values of quantiles.
Lines ends are close to the box edges but not exactly on them.
While command

lines(c(median(x1),median(x2),median(x3)))

puts lines with ends exactly on the middle line of the box-and-whisker
plots.

-- 
Best regards
Wladimir Eremeev                                     mailto:wl at eimb.ru



From ripley at stats.ox.ac.uk  Sun May 11 15:26:53 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 11 May 2003 14:26:53 +0100 (BST)
Subject: [R] what does boxplot draw?
In-Reply-To: <3710.030511@eimb.ru>
Message-ID: <Pine.LNX.4.44.0305111417430.6318-100000@gannet.stats>

?boxplot says

   stats: a matrix, each column contains the extreme of the lower
          whisker, the lower hinge, the median, the upper hinge and the
          extreme of the upper whisker for one group/plot.

and that's accurate: please prefer the primary documentation to notes you 
pick up somewhere on the Web.

For the definition of `hinge' see ?boxplot.stats and the references 
therein.  (The box goes from the lower hinge to the upper hinge.)

On Sun, 11 May 2003, Wladimir Eremeev wrote:

>    Unfortunately I cannot find in the documentation what determines
>    ranges of a 'box' in the box-and-whisker plot.

It's right there on the help pages for boxplot, bxp and boxplot.stats,
with references to the primary published literature.

>    It is said in "Simple R" (http://www.math.csi.cuny.edu/Statistics/R/simpleR)
>    that they are 1st and 3rd Qus usually.
> 
>    I tried to add to boxplot lines with (quantile(x,probs=0.25)), but
>    lines do not coincide with edges of boxes.

[...]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Sun May 11 15:31:29 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Sun, 11 May 2003 13:31:29 -0000
Subject: [R] what does boxplot draw?
In-Reply-To: <3710.030511@eimb.ru>
References: <200305111010.h4BA2Yru016730@hypatia.math.ethz.ch>
	<3710.030511@eimb.ru>
Message-ID: <x2isshzjyx.fsf@biostat.ku.dk>

Wladimir Eremeev <wl at eimb.ru> writes:

> Dear r-help,
> 
>    Unfortunately I cannot find in the documentation what determines
>    ranges of a 'box' in the box-and-whisker plot.
>    
>    It is said in "Simple R" (http://www.math.csi.cuny.edu/Statistics/R/simpleR)
>    that they are 1st and 3rd Qus usually.
> 
>    I tried to add to boxplot lines with (quantile(x,probs=0.25)), but
>    lines do not coincide with edges of boxes.

The full story is in help(boxplots.stats). It's all a bit quirky, but
faithful to the original reference by Tukey. It may be illustrative to
do something like

lapply(4:10,function(i)cbind(
     bxp=boxplot.stats(1:i)$stats,
      qu=quantile(1:i)))

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From rolf at math.unb.ca  Sun May 11 17:04:28 2003
From: rolf at math.unb.ca (Rolf Turner)
Date: Sun, 11 May 2003 12:04:28 -0300 (ADT)
Subject: [R] Prime or dash in plotmath().
Message-ID: <200305111504.h4BF4SGx002316@erdos.math.unb.ca>


I've had to struggle a bit to get the prime/dash derivative notation
into a plotmath expression.  The use of

		expression(K'(t))

gives me a syntax error.  The best I've been able to come up with is

		expression(paste(K,"'",(t),sep=""))

Is this the ``accepted'' procedure, or is there a more direct route?

				cheers,

					Rolf Turner
					rolf at math.unb.ca



From ligges at statistik.uni-dortmund.de  Sun May 11 19:57:55 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 11 May 2003 19:57:55 +0200
Subject: [R] Adding splines to a coplot?
References: <200305102036.h4AKa975032371@mailserver3.hushmail.com>
Message-ID: <3EBE8F23.E21E2677@statistik.uni-dortmund.de>



chumpmonkey at hushmail.com wrote:
> 
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
> 
> I appologize in advance if this is trivial. However, is it possible to
> fit a spline to each panel of a coplot and specify the color and lwd
> and such? I searced the archive and found this from the heady days of
> 2000.
> 
> http://maths.newcastle.edu.au/~rking/R/help/00a/1598.html
> 
> Is there an easier non-fake way to do this?

Lattice became available druing the last years, and in the 4th edition
of MASS (and the corresponding scripts) lattice is used, in particular
see the scripts for chapter 10.3. 
And as Brian Ripley promised in the cited message, coplot() has an
argument "subscripts".

Uwe Ligges



> - -Thanks, CM
> -----BEGIN PGP SIGNATURE-----
> Version: Hush 2.2 (Java)
> Note: This signature can be verified at https://www.hushtools.com/verify
> 
> wmAEARECACAFAj69Yq8ZHGNodW1wbW9ua2V5QGh1c2htYWlsLmNvbQAKCRA20AL0XmId
> oh91AKCCfcoUwV/6kv9w8wWyuQv877H8AgCeL4TMeewGBFXektY3mHtQvT3wK1Q=
> =noyh
> -----END PGP SIGNATURE-----
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ligges at statistik.uni-dortmund.de  Sun May 11 20:02:36 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 11 May 2003 20:02:36 +0200
Subject: [R] simulating data
References: <001a01c317a4$3040bbd0$0100a8c0@pc>
Message-ID: <3EBE903C.CAD560F5@statistik.uni-dortmund.de>

Christian Schulz wrote:
> 
> ..for a "unit test"   i need a lot of  rows in my database, so i simulate.
> 
> My problem, using  Win2k,R.1.7.0, 256RAM is that i'm getting memory-erros go about the  1000.000 border , but
> i need bigger test data. Ok is approriate buy more RAM, but is there a possibilty simulate a lot of single rows, one after
> another and between this 2 steps -> Add th row to database and delete them for memory-recover from R ?

In principle, yes. If the memory won't get too segmented it will work, I
think.
Simulating one row after another will certainly result in a huge speed
penalty, but maybe one block of rows after another is the solution you
are looking for.

Uwe Ligges


> Many thanks,Christian
> 
> In example:
> Nachname     <- round(runif(2000000,1,1000000000))
> Vorname      <- round(runif(2000000,1,1000000000))
> PLZ          <- round(runif(2000000,10000,14000))
> VermittlungskriteriumA   <- round(runif(2000000,1,2))
> VermittlungskriteriumB   <- round(runif(200000,1,5))
> klient0 <- cbind(Nachname,Vorname,PLZ,VermittlungskriteriumA,)
> klient <- as.data.frame(klient0)
> rm(klient0)
> klient$VermittlungskriteriumA <- as.factor(klient$VermittlungskriteriumA)
> levels(klient$VermittlungskriteriumA) <- c("MANN","FRAU")
> klient$VermittlungskriteriumB <- as.factor(klient$VermittlungskriteriumB)
> levels(klient$VermittlungskriteriumB) <- c("<3Monate","<6Monate","<12Monate","<18Monate","=>24Monate",)
> 
> library(RODBC)
> channel <- odbcConnect("dsn","root","pass")
> sqlSave(channel,klient)
> 
> ....and more tables
> 
>         [[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jerome at hivnet.ubc.ca  Sun May 11 20:01:28 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Sun, 11 May 2003 11:01:28 -0700
Subject: [R] Prime or dash in plotmath().
In-Reply-To: <200305111504.h4BF4SGx002316@erdos.math.unb.ca>
References: <200305111504.h4BF4SGx002316@erdos.math.unb.ca>
Message-ID: <200305111807.LAA07621@hivnet.ubc.ca>


It looks like these four examples give all the same thing. You may pick 
the one that suits best in your case.

par(mfrow=c(2,2))
plot(1,1,xlab=expression(paste(K,"'",(t),sep="")))
plot(1,1,xlab=expression(paste(K,"'",(t))))
plot(1,1,xlab=expression(paste("K'(t)")))
plot(1,1,xlab=expression("K'(t)"))

HTH,
Jerome

On May 11, 2003 08:04 am, Rolf Turner wrote:
> I've had to struggle a bit to get the prime/dash derivative notation
> into a plotmath expression.  The use of
>
> 		expression(K'(t))
>
> gives me a syntax error.  The best I've been able to come up with is
>
> 		expression(paste(K,"'",(t),sep=""))
>
> Is this the ``accepted'' procedure, or is there a more direct route?
>
> 				cheers,
>
> 					Rolf Turner
> 					rolf at math.unb.ca
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From fatman at aracnet.com  Sun May 11 20:16:39 2003
From: fatman at aracnet.com (John Jaynes)
Date: Sun, 11 May 2003 11:16:39 -0700
Subject: [R] lines(aline, type = 'b',
	col = "blue) does not work for POSIXct plot.
Message-ID: <200305111116.39775.fatman@aracnet.com>

Hello,

x <- ISOdate(2003, 4, 1:30)           # POSIXct vector
y <-c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30) 
aline <- c(30,29,28,27,26,25,24,23,22,21,20,19,18,17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1)
plot(x, y, xaxt = 'n', main = 'Number of Stuff for the Project, April 2003', xlab = 'Report Time', ylab = 'Number of Stuff', type = "b", col =  "purple")
axis.POSIXct(1, x)
lines(aline, type = "b", col = "blue")

These commands only produce one plot line on the resulting graph. Similar commands without the POSIXct lines 
generate the expected additional line on the plot, using the "lines" command. Any help on producing this additional 
line, while using POSIXct modifiers,  will be greatly appreciated, as I have yet to find a book on this Very interesting 
R Language, that would answer such useful minutiae.

Appreciatively,

John



From spencer.graves at pdf.com  Sun May 11 20:59:35 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 11 May 2003 11:59:35 -0700
Subject: [R] error in qr(x)
References: <200305101801.39112.m.wegmann@web.de> <3EBD4B60.70308@pdf.com>
Message-ID: <3EBE9D97.4030603@pdf.com>

df1 <- data.frame(x=c(1:3, NA), y=rnorm(4))
rlm(y~x, data=df1[!is.na(df1$x),])

hth.  spencer graves

Martin Wegmann wrote:
 > Hello,
 > how do I remove Na's in R? Or did you mean to remove them before I 
load them
 > into R? But I can't remove them totally because it is a series, I can
 > interpolate them (command?)
 >
 > cheers, Martin.
 >
Spencer Graves wrote:
> Have you tried removing the NA's beforecalling "rlm"?
> 
> hth.  spencer graves
> 
> Martin Wegmann wrote:
> 
>> Hello,
>> I get the following prompt when tring to compute rlm:
>>
>>
>>> x<-rlm(core.e, na.action=na.omit)
>>> Error in qr(x) : NA/NaN/Inf in foreign function call (arg 1)
>>
>>
>>
>> I checked with is.finite and is.infinite but in both cases i get FALSE 
>> and my missing values are substituted by NA.
>> what does this error prompt mean and how do I solve it?
>>
>> thanks in advance, cheers Martin
>>
>>
> 
>



From ripley at stats.ox.ac.uk  Sun May 11 21:20:52 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 11 May 2003 20:20:52 +0100 (BST)
Subject: [R] lines(aline, type = 'b', col = "blue) does not work for
	POSIXct plot.
In-Reply-To: <200305111116.39775.fatman@aracnet.com>
Message-ID: <Pine.LNX.4.44.0305112011250.7141-100000@gannet.stats>

On Sun, 11 May 2003, John Jaynes wrote:

> x <- ISOdate(2003, 4, 1:30)           # POSIXct vector
> y <-c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30) 
> aline <- c(30,29,28,27,26,25,24,23,22,21,20,19,18,17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1)
> plot(x, y, xaxt = 'n', main = 'Number of Stuff for the Project, April 2003', xlab = 'Report Time', ylab = 'Number of Stuff', type = "b", col =  "purple")
> axis.POSIXct(1, x)
> lines(aline, type = "b", col = "blue")
> 
> These commands only produce one plot line on the resulting graph.
> Similar commands without the POSIXct lines generate the expected
> additional line on the plot, using the "lines" command. Any help on
> producing this additional line, while using POSIXct modifiers, will be
> greatly appreciated, as I have yet to find a book on this Very
> interesting R Language, that would answer such useful minutiae.

What do you expect lines(aline) to do?  As the help page says

Arguments:

    x, y: coordinate vectors of points to join.

and you seem to have ignored the need to specify `x'!  If you had, it
would have worked.

lines(x, aline, type = "b", col = "blue")  # works as documented

You can hardly expect a book to tell you that you have failed to RTFM, but
several would not have led you to believe (incorrectly) that

> Similar commands without the POSIXct lines generate the expected
> additional line on the plot, using the "lines" command.


BTW, 1:30 and 30:1 are in R for a purpose and would make your example both
easier to understand and easier to reproduce (since you didn't wrap your
lines either: that's a piece of netiquette to bear in mind).

BDR

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jarioksa at sun3.oulu.fi  Sun May 11 21:21:51 2003
From: jarioksa at sun3.oulu.fi (jarioksa@sun3.oulu.fi)
Date: Sun, 11 May 2003 22:21:51 +0300
Subject: [R] correspondence analysis
In-Reply-To: <200305091326.05048.pwallem@bio.puc.cl>
References: <200305091326.05048.pwallem@bio.puc.cl>
Message-ID: <1052680911.3ebea2cf97620@webmail.oulu.fi>

Lainaus Petra Wallem <pwallem at bio.puc.cl>:

> Hi everybody, I am starting my friendship with R. Now I want to do a 
> Correspondence Analysis using the vegan library or multiv library. Both give
> 
> me the same results which differ from the ones I get running other programs
> 
> like Statistica... I wounder if there is a problem with my matrix. I have 
> cualitataive variable in the columns and sampling units in the rows... I 
> import my matrix into R with matrix(scan....), which dose not accept strings,
> 
> so I have eliminated all the names of my rows and columns and just worked 
> with the acctual values of my matrix, is that the problem I have?
> Thanks a lot to everybody
>
There really is not enough information to help you. Further, I don't have
Statistica to see how it works. How were the results different? Scaling is not
quite standardized in CA, and it may be that the scores are linearly related
although they look different at the first glance. Further, some opt for using
square roots of eigenvalues. Checke these first. Actually, you should start with
checking your data. Do the dimensions match, or did you lose some rows or
columns in input? Do the numbers look OK? Please, be more detailed with your
problems.

>From the description of your data matrix I would guess that you would rather
like to use correspondence analysis functions in MASS than those in vegan or
multiv. These all should give the same results, though, but they are geared to
different kind of problems.

Best wishes, jari oksanen



From mihastaut at hotmail.com  Sun May 11 21:40:49 2003
From: mihastaut at hotmail.com (Miha STAUT)
Date: Sun, 11 May 2003 19:40:49 +0000
Subject: [R] libpq-fe.h ???
Message-ID: <BAY2-F107GEm3EcPPzA0000dd9c@hotmail.com>

Hi all,

I tried to install the Rdbi_0.1-2.tar.gz and Rdbi.PgSQL_0.1-2 package. The 
Rdbi_0.1-2.tar.gz installed fine but the Rdbi.PgSQL_0.1-2 had some problems. 
The compilation routine tried to  find a header called libpq-fe.h but did 
not find it in the standard locations. I searched through the computer but 
did not find a file called in this way either. What should I do to 
successuffly install this package? In the Netleters introduction to R/GRASS 
interface there is  no mention about this problems.

The PostgreSQL_7.2.1 Users guide states: "Frontend programs that use libpq 
must include the header file libpq-fe.h and must link with the libpq 
library." Is Libpq a package that can be downloaded and how should I create 
this header and make a link to it?

I use R 1.6.2.1 and PostgreSQL 7.2 with RedHat 7.3.

[root at localhost pack]# R CMD INSTALL Rdbi.PgSQL_0.1-2.tar.gz
* Installing *source* package 'Rdbi.PgSQL' ...
creating cache ./config.cache
checking for PQconnectdb in -lpq... yes
checking how to run the C preprocessor... cc -E
checking for /usr/include/libpq-fe.h... no
checking how to run the C preprocessor... cc -E
checking for /usr/include/pgsql/libpq-fe.h... no
checking how to run the C preprocessor... cc -E
checking for /usr/include/postgresql/libpq-fe.h... no
checking how to run the C preprocessor... cc -E
checking for /usr/local/include/libpq-fe.h... no
checking how to run the C preprocessor... cc -E
checking for /usr/local/include/pgsql/libpq-fe.h... no
checking how to run the C preprocessor... cc -E
checking for /usr/local/include/postgresql/libpq-fe.h... no
checking how to run the C preprocessor... cc -E
checking for /opt/include/libpq-fe.h... no
checking how to run the C preprocessor... cc -E
checking for /opt/include/pgsql/libpq-fe.h... no
checking how to run the C preprocessor... cc -E
checking for /opt/include/postgresql/libpq-fe.h... no

I could not find your PostgreSQL client headers!
Use --with-pgsql-includes=PATH; if running R's INSTALL,
use --configure-args='--with-pgsql-includes=PATH'; or
set PG_INCLUDE_DIR in your environment to the library path,
and rerun the configure/install.

ERROR: configuration failed for package 'Rdbi.PgSQL'


Thanks for suggestions, Miha Staut



From ravishan at fas.harvard.edu  Sun May 11 21:51:27 2003
From: ravishan at fas.harvard.edu (Nirmala Ravishankar)
Date: Sun, 11 May 2003 15:51:27 -0400 (EDT)
Subject: [R] gee
Message-ID: <Pine.LNX.4.44.0305111538560.28774-100000@ice3.fas.harvard.edu>

I am trying to use gee() to calculate the robust standard errors for a 
logit model.  My dataset (zol) has 195019 observations; winner, racebl, 
raceas, racehi are all binary variables.   ID is saved as a vector of 
length 195019 with alternating 0's and 1's.   I get the following error 
message.  I also tried the same command with corstr set to "independence" 
and got the same error message.
 

> ID <- as.vector(array(0, nrow(zol)))
> k <- seq(2, nrow(zol), 2)
> ID[k] <- 1


> fm <- gee(winner ~ racebl + racehi + raceas, id = ID, data = zol, family 
= binomial(logit), corstr = "exchangeable")
[1] "Beginning Cgee S-function, @(#) geeformula.q 4.13 98/01/27"
[1] "running glm to get initial regression estimate"
[1]  0.4308219 -0.1929547 -0.1741733 -0.1925523
Error in rep(0, maxclsz * maxclsz) : invalid number of copies in "rep"
In addition: Warning message: 
NAs produced by integer overflow in: maxclsz * maxclsz 



What am I doing wrong?

Thanks,
Nirmala Ravishankar



From ripley at stats.ox.ac.uk  Sun May 11 22:33:59 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 11 May 2003 21:33:59 +0100 (BST)
Subject: [R] libpq-fe.h ???
In-Reply-To: <BAY2-F107GEm3EcPPzA0000dd9c@hotmail.com>
Message-ID: <Pine.LNX.4.44.0305112121001.7212-100000@gannet.stats>

1) What has this to do with GRASS?  It has very little to do with R, 
either, appearing to be a PostgreSQL installation problem.

2) Did you install PostgreSQL from source, or install RPMS: if the latter
did you install _all_ the RPMs?  I suspect you don't have the client files
installed.  On my system (installed from the sources under RH7.3)  
libpq-fe.h is in /usr/local/pgsql/include.

3) Rdbi/Rdbi.PgSQL are not on CRAN and appear not to be supported, but in
any case you would do best to ask the author(s)/maintainer(s) about
packages, and especially non-CRAN packages.

4) There is no such thing as R 1.6.2.1, and reports have it that
Rdbi.PgSQL does not work with the current versions of R.  The only
currently supported R interface to PostgreSQL would appear to be RODBC.

On Sun, 11 May 2003, Miha STAUT wrote:

> I tried to install the Rdbi_0.1-2.tar.gz and Rdbi.PgSQL_0.1-2 package. The 
> Rdbi_0.1-2.tar.gz installed fine but the Rdbi.PgSQL_0.1-2 had some problems. 
> The compilation routine tried to  find a header called libpq-fe.h but did 
> not find it in the standard locations. I searched through the computer but 
> did not find a file called in this way either. What should I do to 
> successuffly install this package? In the Netleters introduction to R/GRASS 
> interface there is  no mention about this problems.
> 
> The PostgreSQL_7.2.1 Users guide states: "Frontend programs that use libpq 
> must include the header file libpq-fe.h and must link with the libpq 
> library." Is Libpq a package that can be downloaded and how should I create 
> this header and make a link to it?

[...]


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ozric at web.de  Sun May 11 22:34:36 2003
From: ozric at web.de (Christian Schulz)
Date: Sun, 11 May 2003 22:34:36 +0200
Subject: [R] simulating data
References: <001a01c317a4$3040bbd0$0100a8c0@pc>
	<3EBE903C.CAD560F5@statistik.uni-dortmund.de>
Message-ID: <001901c317fc$bd92d560$0100a8c0@pc>

..the speed penalty is not really bad, because
i need the data one time, so it can run over night!
I'm just starting experiment with loop's
and thinks that's a good exercise...

..but i need the lot of rows to test
the mysql speed penalty  :-)

regards,christian



----- Original Message -----
From: "Uwe Ligges" <ligges at statistik.uni-dortmund.de>
To: "Christian Schulz" <ozric at web.de>
Cc: <r-help at stat.math.ethz.ch>
Sent: Sunday, May 11, 2003 8:02 PM
Subject: Re: [R] simulating data


> Christian Schulz wrote:
> >
> > ..for a "unit test"   i need a lot of  rows in my database, so i
simulate.
> >
> > My problem, using  Win2k,R.1.7.0, 256RAM is that i'm getting
memory-erros go about the  1000.000 border , but
> > i need bigger test data. Ok is approriate buy more RAM, but is there a
possibilty simulate a lot of single rows, one after
> > another and between this 2 steps -> Add th row to database and delete
them for memory-recover from R ?
>
> In principle, yes. If the memory won't get too segmented it will work, I
> think.
> Simulating one row after another will certainly result in a huge speed
> penalty, but maybe one block of rows after another is the solution you
> are looking for.
>
> Uwe Ligges
>
>
> > Many thanks,Christian
> >
> > In example:
> > Nachname     <- round(runif(2000000,1,1000000000))
> > Vorname      <- round(runif(2000000,1,1000000000))
> > PLZ          <- round(runif(2000000,10000,14000))
> > VermittlungskriteriumA   <- round(runif(2000000,1,2))
> > VermittlungskriteriumB   <- round(runif(200000,1,5))
> > klient0 <- cbind(Nachname,Vorname,PLZ,VermittlungskriteriumA,)
> > klient <- as.data.frame(klient0)
> > rm(klient0)
> > klient$VermittlungskriteriumA <-
as.factor(klient$VermittlungskriteriumA)
> > levels(klient$VermittlungskriteriumA) <- c("MANN","FRAU")
> > klient$VermittlungskriteriumB <-
as.factor(klient$VermittlungskriteriumB)
> > levels(klient$VermittlungskriteriumB) <-
c("<3Monate","<6Monate","<12Monate","<18Monate","=>24Monate",)
> >
> > library(RODBC)
> > channel <- odbcConnect("dsn","root","pass")
> > sqlSave(channel,klient)
> >
> > ....and more tables
> >
> >         [[alternate HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Sun May 11 22:46:15 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 11 May 2003 21:46:15 +0100 (BST)
Subject: [R] gee
In-Reply-To: <Pine.LNX.4.44.0305111538560.28774-100000@ice3.fas.harvard.edu>
Message-ID: <Pine.LNX.4.44.0305112143510.7314-100000@gannet.stats>

On Sun, 11 May 2003, Nirmala Ravishankar wrote:

> I am trying to use gee() to calculate the robust standard errors for a 
> logit model.  My dataset (zol) has 195019 observations; winner, racebl, 
> raceas, racehi are all binary variables.   ID is saved as a vector of 
> length 195019 with alternating 0's and 1's.   I get the following error 
> message.  I also tried the same command with corstr set to "independence" 
> and got the same error message.
>  
> 
> > ID <- as.vector(array(0, nrow(zol)))
> > k <- seq(2, nrow(zol), 2)
> > ID[k] <- 1
> 
> 
> > fm <- gee(winner ~ racebl + racehi + raceas, id = ID, data = zol, family 
> = binomial(logit), corstr = "exchangeable")
> [1] "Beginning Cgee S-function, @(#) geeformula.q 4.13 98/01/27"
> [1] "running glm to get initial regression estimate"
> [1]  0.4308219 -0.1929547 -0.1741733 -0.1925523
> Error in rep(0, maxclsz * maxclsz) : invalid number of copies in "rep"
> In addition: Warning message: 
> NAs produced by integer overflow in: maxclsz * maxclsz 
> 
> 
> 
> What am I doing wrong?

Using a much larger dataset that the author of gee envisaged: the warning
message is pretty explicit. Not that I think you will get clusters of size
1e5 to work, since rep(0, maxclsz * maxclsz) is a vector of about 80Gb,
and on a 32-bit machine the OS can only address 4Gb at most per process.

I cannot imagine a real statistical problem with a homogeneous group of
1e5 observations, but if you have one, a 1% subsample ought to suffice for
all practical purposes.  And any statistical fluctuations (variance)
will be swamped by model inadequacy (bias) for 2e5 binary observations.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ivo.welch at yale.edu  Sun May 11 22:53:34 2003
From: ivo.welch at yale.edu (Welch, Ivo)
Date: Sun, 11 May 2003 16:53:34 -0400
Subject: [R] X axis series labels?
Message-ID: <3EBEB84E.7030701@yale.edu>


I am about to become a new user of R, so apologies for a total beginner 
question.

I need to graph some time-series.  I would like to name the X-Axis with 
another series, say T.  For example, the T series may have observations 
like "2003-12", which I would like to be the label.  can this be easily 
done?

as a new user: it would be nice if the FAQ listed the add-on packages in 
logical order, rather than just alphabetical.  it would also be nice if 
this mailing list (R-help) had a search facility.

help appreciated.

/iaw



From andrejk at zrc-sazu.si  Sun May 11 23:12:54 2003
From: andrejk at zrc-sazu.si (Andrej Kveder)
Date: Sun, 11 May 2003 23:12:54 +0200
Subject: [R] NLME - multilevel model using binary outcome - logistic
	regression
Message-ID: <FDEAIKIBHNNFHKGBBPJHMEMJCAAA.andrejk@zrc-sazu.si>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030511/bf62a8ec/attachment.pl

From spencer.graves at pdf.com  Sun May 11 23:42:59 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 11 May 2003 14:42:59 -0700
Subject: [R] X axis series labels?
References: <3EBEB84E.7030701@yale.edu>
Message-ID: <3EBEC3E3.4080505@pdf.com>

R does have a search facility:  see "www.r-project.org".

Also, "?plot" revels that "plot" has an argument "xlab", which may do 
what you want.

hope this helps.  spencer graves

Welch, Ivo wrote:
> I am about to become a new user of R, so apologies for a total beginner 
> question.
> 
> I need to graph some time-series.  I would like to name the X-Axis with 
> another series, say T.  For example, the T series may have observations 
> like "2003-12", which I would like to be the label.  can this be easily 
> done?
> 
> as a new user: it would be nice if the FAQ listed the add-on packages in 
> logical order, rather than just alphabetical.  it would also be nice if 
> this mailing list (R-help) had a search facility.
> 
> help appreciated.
> 
> /iaw
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Sun May 11 23:53:50 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 11 May 2003 22:53:50 +0100 (BST)
Subject: [R] X axis series labels?
In-Reply-To: <3EBEB84E.7030701@yale.edu>
Message-ID: <Pine.LNX.4.44.0305112247410.7382-100000@gannet.stats>

On Sun, 11 May 2003, Welch, Ivo wrote:

> 
> I am about to become a new user of R, so apologies for a total beginner 
> question.
> 
> I need to graph some time-series.  I would like to name the X-Axis with 
> another series, say T.  For example, the T series may have observations 
> like "2003-12", which I would like to be the label.  can this be easily 
> done?

That's what the axis() function does: use xaxt="n" to suppress the normal 
x axis.

> as a new user: it would be nice if the FAQ listed the add-on packages in 
> logical order, rather than just alphabetical. 

What logic did you have in mind to order them?  It's not at all clear to 
the initiates how to do this, but you can search the FAQ list (or the CRAN 
list) using e.g. your browser's search mechanisms.

>  it would also be nice if 
> this mailing list (R-help) had a search facility.

It has more than one: http://cran.r-project.org/search.html

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From kjetil at entelnet.bo  Mon May 12 02:45:12 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Sun, 11 May 2003 20:45:12 -0400
Subject: [R] NLME - multilevel model using binary outcome -
	logistic	regression
In-Reply-To: <FDEAIKIBHNNFHKGBBPJHMEMJCAAA.andrejk@zrc-sazu.si>
Message-ID: <3EBEB658.23343.6C2184@localhost>

On 11 May 2003 at 23:12, Andrej Kveder wrote:

> Hi!
> 
> I'm pretty raw when working with the R models (linear or not).
> 
> I'm wondering has anybody worked with the NLME library and dichotomous
> outcomes.
> I have a binary outcome variable that I woul like to model in a nested
> (multilevel) model.

You can try glmmPQL in the MASS package, discussed in the book MASS.

Kjetil Halvorsen

> 
> I started to fit a logistic model to a NLS function, but could not suceed. I
> know there are better ways to do it in R with either the LRM or GLM wih
> family=binomial(logit) specification, but just as a paralel to the NLME... I
> was unsucsesful..
> 
> Any information or an example would be most welcome...
> 
> best
> 
> Andrej
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From kjetil at entelnet.bo  Mon May 12 02:45:12 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Sun, 11 May 2003 20:45:12 -0400
Subject: [R] error in qr(x)
In-Reply-To: <3EBE9D97.4030603@pdf.com>
Message-ID: <3EBEB658.15171.6C2136@localhost>

On 11 May 2003 at 11:59, Spencer Graves wrote:

> df1 <- data.frame(x=c(1:3, NA), y=rnorm(4))
> rlm(y~x, data=df1[!is.na(df1$x),])

or simpler:

> df1 <- data.frame(x=c(1:3, NA), y=rnorm(4))
> rlm(y~x, data=na.omit(df1) ) 

Kjetil Halvorsen



> 
> hth.  spencer graves
> 
> Martin Wegmann wrote:
>  > Hello,
>  > how do I remove Na's in R? Or did you mean to remove them before I 
> load them
>  > into R? But I can't remove them totally because it is a series, I can
>  > interpolate them (command?)
>  >
>  > cheers, Martin.
>  >
> Spencer Graves wrote:
> > Have you tried removing the NA's beforecalling "rlm"?
> > 
> > hth.  spencer graves
> > 
> > Martin Wegmann wrote:
> > 
> >> Hello,
> >> I get the following prompt when tring to compute rlm:
> >>
> >>
> >>> x<-rlm(core.e, na.action=na.omit)
> >>> Error in qr(x) : NA/NaN/Inf in foreign function call (arg 1)
> >>
> >>
> >>
> >> I checked with is.finite and is.infinite but in both cases i get FALSE 
> >> and my missing values are substituted by NA.
> >> what does this error prompt mean and how do I solve it?
> >>
> >> thanks in advance, cheers Martin
> >>
> >>
> > 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From assicma at yahoo.com  Mon May 12 02:50:03 2003
From: assicma at yahoo.com (assic ma)
Date: Sun, 11 May 2003 17:50:03 -0700 (PDT)
Subject: [R] calling other language program in R
Message-ID: <20030512005003.69692.qmail@web40102.mail.yahoo.com>


hello,

    I am a new user of R. I wonder whether I can
calling Fortran 77 subroutine in R? thanks a lot! 

assicma



From dmurdoch at pair.com  Mon May 12 03:22:55 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sun, 11 May 2003 21:22:55 -0400
Subject: [R] calling other language program in R
In-Reply-To: <20030512005003.69692.qmail@web40102.mail.yahoo.com>
References: <20030512005003.69692.qmail@web40102.mail.yahoo.com>
Message-ID: <qbttbvoeqelf57rlolvlsd7robtd56uqfb@4ax.com>

On Sun, 11 May 2003 17:50:03 -0700 (PDT), you wrote:

>
>hello,
>
>    I am a new user of R. I wonder whether I can
>calling Fortran 77 subroutine in R? thanks a lot! 

Yes.  See the R extensions manual for instructions.  If you're using
Windows, you'll want to install the "Source package installation
files".  I've got a web page for instructions for Windows compilers
at <http://www.stats.uwo.ca/faculty/murdoch/software/compilingDLLs>.

Duncan Murdoch



From wmusial at gmx.de  Mon May 12 03:47:33 2003
From: wmusial at gmx.de (Wojtek Musial)
Date: Mon, 12 May 2003 03:47:33 +0200
Subject: [R] Zeitreihen problem
Message-ID: <001e01c31828$759c93a0$5b33fe91@wojtek>

Hallo!

I lese gro?e Zeitreihen in R ein z.B. mit:

> disc<-read.table("F:/R/DATA/discount_rate_usa.txt")

disc hat dann folgende Struktur:

> disc[1:5]

           V1       V2
1  01/03/1955 1.5
2  01/04/1955 1.5
3  01/05/1955 1.5
4  01/06/1955 1.5
5  01/07/1955 1.5

ich will das disc als Zeitreihe erkannt wird und will z.B 01/03/1955 in ein
Datum verwandeln, aber es wird als factor aufgefasst:

> disc[1,1]
[1] 01/03/1955
17647 Levels: 01/01/1956 01/01/1957 01/01/1958 01/01/1959 ... 12/31/2002

Wie kann ich z.B. disc[1,1] in ein Datum verwandeln?

Mit as.date() geht es nicht:

> library(survival)
> as.date(disc[1,1])
Error in as.date(disc[1, 1]) : Cannot coerce to date format

Danke im Vorraus!



From edd at debian.org  Mon May 12 06:20:56 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 11 May 2003 23:20:56 -0500
Subject: [R] Zeitreihen problem
In-Reply-To: <001e01c31828$759c93a0$5b33fe91@wojtek>
References: <001e01c31828$759c93a0$5b33fe91@wojtek>
Message-ID: <20030512042056.GA30816@sonny.eddelbuettel.com>

On Mon, May 12, 2003 at 03:47:33AM +0200, Wojtek Musial wrote:
> I lese gro?e Zeitreihen in R ein z.B. mit:

[ Please note that the language on this list is English ]

> disc hat dann folgende Struktur:
> 
> > disc[1:5]
> 
>            V1       V2
> 1  01/03/1955 1.5
> 2  01/04/1955 1.5
> 3  01/05/1955 1.5
> 4  01/06/1955 1.5
> 5  01/07/1955 1.5
> 
> ich will das disc als Zeitreihe erkannt wird und will z.B 01/03/1955 in ein
> Datum verwandeln, aber es wird als factor aufgefasst:
> 
> > disc[1,1]
> [1] 01/03/1955
> 17647 Levels: 01/01/1956 01/01/1957 01/01/1958 01/01/1959 ... 12/31/2002

There are several ways to do this.  One way is to parse a date with strptime:

> datevec <- c("01/03/1955","01/04/1955","01/05/1955")
> strptime(datevec, format="%m/%d/%Y")
[1] "1955-01-03" "1955-01-04" "1955-01-05"

The return values from strptime are genuine POSIXlt time objects which you
can transform or compute on in very powerful ways.  There is quite a bit of
documentation to master, though. Start with help(DateTimeClasses) and look
for more examples in the mailing list archives. There are lots of them.

If you then want to do time-series statistics (such as ARIMA models, say),
you need to create ts() objects. The POSIXlt (or POSIXct) types are not used
for that, and the main restriction is that dates need to be in regular
increments. Working with daily data has its challenges.  Adrian has the
beginnings of an irregular time series class in the most recent tseries
package. 

Hth,  Dirk

-- 
Don't drink and derive. Alcohol and algebra don't mix.



From noel at univ-lille3.fr  Mon May 12 10:01:23 2003
From: noel at univ-lille3.fr (Noel Yvonnick)
Date: Mon, 12 May 2003 08:01:23 +0000
Subject: [R] Plotting expressions with indicies
Message-ID: <200305120801.23909.noel@univ-lille3.fr>

Hello,

I would like to plot a series of math symbols on a graph with ordered indicies 
: expression(delta[1]) expression(delta[2]) etc.

Is there a mean to write this in a for loop ?

for(i in 1:6) text(i,i,expression(delta[i]))

does not work ('i' is not evaluated).

Thanks in advance,

Y. Noel



From ripley at stats.ox.ac.uk  Mon May 12 09:12:55 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 12 May 2003 08:12:55 +0100 (BST)
Subject: [R] Plotting expressions with indicies
In-Reply-To: <200305120801.23909.noel@univ-lille3.fr>
Message-ID: <Pine.LNX.4.44.0305120811050.8158-100000@gannet.stats>

On Mon, 12 May 2003, Noel Yvonnick wrote:

> I would like to plot a series of math symbols on a graph with ordered indicies 
> : expression(delta[1]) expression(delta[2]) etc.
> 
> Is there a mean to write this in a for loop ?
> 
> for(i in 1:6) text(i,i,expression(delta[i]))
> 
> does not work ('i' is not evaluated).

Try

> plot(1:6, type="n")
> for(i in 1:6) text(i,i,substitute(delta[i], list(i=i)))



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From debene at unimc.it  Mon May 12 00:36:16 2003
From: debene at unimc.it (Luca De Benedictis)
Date: Mon, 12 May 2003 00:36:16 +0200
Subject: [R] rank correlation and distance between two different matrices
Message-ID: <3EBED060.66882A98@unimc.it>

Dear all,
in package Hmisc  `rcorr' computes a matrix of Spearman's `rho' rank
correlation coefficients for all possible pairs of columns of a matrix.
What if I want a matrix of  rank correlation coefficients for pair of
columns of two different matrices?

I have the same question about distance metrics in package Vegan. The
function 'vegdist' computes distance indexes for all possible pairs of
row of a matrix. What if I am interested in comparing each single row of
matrix A with the correspondent row of matrix B?

Any help would be appreciated.

Luca



From ripley at stats.ox.ac.uk  Mon May 12 09:28:03 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 12 May 2003 08:28:03 +0100 (BST)
Subject: [R] rank correlation and distance between two different matrices
In-Reply-To: <3EBED060.66882A98@unimc.it>
Message-ID: <Pine.LNX.4.44.0305120826420.8204-100000@gannet.stats>

Apply these to c/rbind(A,B) and extract the part of the result which you 
want.

On Mon, 12 May 2003, Luca De Benedictis wrote:

> in package Hmisc  `rcorr' computes a matrix of Spearman's `rho' rank
> correlation coefficients for all possible pairs of columns of a matrix.
> What if I want a matrix of  rank correlation coefficients for pair of
> columns of two different matrices?
> 
> I have the same question about distance metrics in package Vegan. The
> function 'vegdist' computes distance indexes for all possible pairs of
> row of a matrix. What if I am interested in comparing each single row of
> matrix A with the correspondent row of matrix B?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jarioksa at sun3.oulu.fi  Mon May 12 09:44:48 2003
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: Mon, 12 May 2003 07:44:48 -0000
Subject: [R] rank correlation and distance between two different matrices
In-Reply-To: <3EBED060.66882A98@unimc.it>
References: <3EBED060.66882A98@unimc.it>
Message-ID: <1052725479.2037.33.camel@pc112145.oulu.fi>

On Mon, 2003-05-12 at 01:36, Luca De Benedictis wrote:
> Dear all,
> in package Hmisc  `rcorr' computes a matrix of Spearman's `rho' rank
> correlation coefficients for all possible pairs of columns of a matrix.
> What if I want a matrix of  rank correlation coefficients for pair of
> columns of two different matrices?
> 
> I have the same question about distance metrics in package Vegan. The
> function 'vegdist' computes distance indexes for all possible pairs of
> row of a matrix. What if I am interested in comparing each single row of
> matrix A with the correspondent row of matrix B?

Wasteful, but may do what you asked for:

> A <- matrix(runif(120), nrow=10, ncol=12)
> B <- matrix(runif(120), nrow=10, ncol=12)
> diag(as.matrix(dist(rbind(A,B)))[11:20, 1:10])
 [1] 1.362722 1.381713 1.526918 1.565419 1.103431 1.384486 1.186895
 [8] 1.512283 1.401761 1.817098

cheers, jari oksanen

-- 
Jari Oksanen <jarioksa at sun3.oulu.fi>



From wolski at molgen.mpg.de  Mon May 12 10:54:43 2003
From: wolski at molgen.mpg.de (Wolski)
Date: Mon, 12 May 2003 10:54:43 +0200
Subject: [R] Http Get-Post?
Message-ID: <200305121054430122.002A22A4@harry.molgen.mpg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030512/f1cfcb00/attachment.pl

From Bernhard.Pfaff at drkw.com  Mon May 12 11:46:09 2003
From: Bernhard.Pfaff at drkw.com (Pfaff, Bernhard)
Date: Mon, 12 May 2003 11:46:09 +0200
Subject: [R] Http Get-Post?
Message-ID: <18D602BD42B7E24EB810D6454A58DB9004730374@ibfftce505.is.de.dresdnerkb.com>

Hi!
How can i send http Post and Get messages to a Web server from within R?
Has anybody implemented a function like?
form(action="http://big.thing.inf/cgi-bin/answer.pl",list(test="my",somethin
g="there"),method="POST").
Has anyone a package with a similar functionality like the
LWP  and HTTP::Request::Common packages in Perl?
Or has anybody a function that sends a post to a server?
Eryk

Dipl. bio-chem. Eryk Witold Wolski    @    MPI-MG Dep. Vertebrate Genomics
Ihnestrasse 73 14195 Berlin          'v'
tel: 0049-30-84131285               /   \
mail: wolski at molgen.mpg.de        ---W-W----



Hello Eryk,


the contributed package: "R2HTML" might be of use in achieving your goal.
Something along the lines:

testfile <- HTMLInitFile(.....your settings...)
HTML("form(action='http://big.thing.inf/cgi-bin/answer.pl',list(test='my',so
mething='there'),method='POST')", ...)
HTMLEndFile()



HTH,
Bernhard


----------------------------------------------------------------------
If you have received this e-mail in error or wish to read our e-mail 
disclaimer statement and monitoring policy, please refer to 
http://www.drkw.com/disc/email/ or contact the sender.



From D.Beare at marlab.ac.uk  Mon May 12 13:31:33 2003
From: D.Beare at marlab.ac.uk (Douglas Beare)
Date: Mon, 12 May 2003 12:31:33 +0100
Subject: [R] FW: S+ Script Files for R???
Message-ID: <67B92F9B2AFED611852500B0D0FE15097EAF08@mail3.marlab.ac.uk>



> Hi List,
> I'm trying to get a bunch of hardened S+ users to switch to R.  They won't
> move because they have got addicted to the S+ (.ssc)
> scripting files, available for MS windows versions.  In these files you
> highlight the code you want to execute by mouse, press an arrow in the
> menu, and it fires it off to the S+ compiler directly.  Is such a facility
> actually available for Linux/Windows and Unix versions of R? Is there
> something similar out there?
> Regards,
> Doug Beare
>



From D.Beare at marlab.ac.uk  Mon May 12 13:40:32 2003
From: D.Beare at marlab.ac.uk (Douglas Beare)
Date: Mon, 12 May 2003 12:40:32 +0100
Subject: [R] FW: S+ Script Files for R???
Message-ID: <67B92F9B2AFED611852500B0D0FE15097EAF09@mail3.marlab.ac.uk>



> Hi List,
> I'm trying to get a bunch of hardened S+ users to switch to R.  They won't
> move because they have got addicted to the S+ (.ssc)
> scripting files, available for MS windows versions.  In these files you
> highlight the code you want to execute by mouse, press an arrow in the
> menu, and it fires it off to the S+ compiler directly.  Is such a facility
> actually available for Linux/Windows and Unix versions of R? Is there
> something similar out there?
> Regards,
> Doug Beare
> 
>



From ligges at statistik.uni-dortmund.de  Mon May 12 13:41:22 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 12 May 2003 13:41:22 +0200
Subject: [R] FW: S+ Script Files for R???
In-Reply-To: <67B92F9B2AFED611852500B0D0FE15097EAF08@mail3.marlab.ac.uk>
References: <67B92F9B2AFED611852500B0D0FE15097EAF08@mail3.marlab.ac.uk>
Message-ID: <3EBF8862.30602@statistik.uni-dortmund.de>

Douglas Beare wrote:
> 
>>Hi List,
>>I'm trying to get a bunch of hardened S+ users to switch to R.  They won't
>>move because they have got addicted to the S+ (.ssc)
>>scripting files, available for MS windows versions.  In these files you
>>highlight the code you want to execute by mouse, press an arrow in the
>>menu, and it fires it off to the S+ compiler directly.  Is such a facility
>>actually available for Linux/Windows and Unix versions of R? Is there
>>something similar out there?
>>Regards,
>>Doug Beare

Not directly within R, but you can set up an editor to allow this kind 
of features.
The recommended one is Emacs with ESS, but there are others as well 
(with different amounts of support).
See http://cran.r-project.org/other-software.html and 
http://www.sciviews.org/_rgui/.

Uwe Ligges



From Detlef.Steuer at unibw-hamburg.de  Mon May 12 13:42:59 2003
From: Detlef.Steuer at unibw-hamburg.de (Detlef Steuer)
Date: Mon, 12 May 2003 13:42:59 +0200 (CEST)
Subject: [R] FW: S+ Script Files for R???
In-Reply-To: <67B92F9B2AFED611852500B0D0FE15097EAF08@mail3.marlab.ac.uk>
Message-ID: <XFMail.20030512134259.steuer@unibw-hamburg.de>

Hi,

take a look at ESS:
http://software.biostat.washington.edu/wikis/front/EmacsSpeaksStatistics

detlef


On 12-May-2003 Douglas Beare wrote:
> 
> 
>> Hi List,
>> I'm trying to get a bunch of hardened S+ users to switch to R.  They won't
>> move because they have got addicted to the S+ (.ssc)
>> scripting files, available for MS windows versions.  In these files you
>> highlight the code you want to execute by mouse, press an arrow in the
>> menu, and it fires it off to the S+ compiler directly.  Is such a facility
>> actually available for Linux/Windows and Unix versions of R? Is there
>> something similar out there?
>> Regards,
>> Doug Beare
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

"There is no way to peace, peace is the way." -- Ghandi

Detlef Steuer --- http://fawn.unibw-hamburg.de/steuer.html
***** Encrypted mail preferred *****



From berwin at maths.uwa.edu.au  Mon May 12 13:35:48 2003
From: berwin at maths.uwa.edu.au (Berwin Turlach)
Date: Mon, 12 May 2003 19:35:48 +0800
Subject: [R] Name spaces in R 1.7.0
Message-ID: <16063.34580.490276.358871@localhost.localdomain>

Dear all,

a colleague of mine has some code that calls "linbin2D" in package
"KernSmooth" directly.  That code is broken under R 1.7.0 since
"KernSmooth" does not export "linbin2D" from its namespace.  Via
trial and error we found to possible solutions:

1) Edit the file NAMESPACE in the directory where KernSmooth is
   installed such that linbin2D is exported too.

2) Add something like
       linbin2D <- get("linbin2D", envir=environment(bkde2D))
   to the code.

We don't like 1) since it messes around with R installation.  And 2)
is not nice in case that some students what to run the code under R
1.6.x . 

We wonder whether there is another way of accessing non-exported
objects from a package?

Cheers,

        Berwin



From ripley at stats.ox.ac.uk  Mon May 12 13:53:26 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 12 May 2003 12:53:26 +0100 (BST)
Subject: [R] FW: S+ Script Files for R???
In-Reply-To: <67B92F9B2AFED611852500B0D0FE15097EAF08@mail3.marlab.ac.uk>
Message-ID: <Pine.LNX.4.44.0305121246070.13705-100000@gannet.stats>

On Mon, 12 May 2003, Douglas Beare wrote:

> > I'm trying to get a bunch of hardened S+ users to switch to R.  They won't
> > move because they have got addicted to the S+ (.ssc)
> > scripting files, available for MS windows versions.  In these files you
> > highlight the code you want to execute by mouse, press an arrow in the
> > menu, and it fires it off to the S+ compiler directly. 

Scripts shown via the `Display file' option in R for Windows do that
(via Ctrl-V). It's not a compiler but an interpreter, BTW.

> >  Is such a facility
> > actually available for Linux/Windows and Unix versions of R? Is there
> > something similar out there?

Not AFAIK for non-GUI versions of R (nor of S-PLUS).  But various editors 
provide such a facility: see 
http://cran.r-project.org/other-software.html.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dmurdoch at pair.com  Mon May 12 14:13:19 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon, 12 May 2003 08:13:19 -0400
Subject: [R] FW: S+ Script Files for R???
In-Reply-To: <67B92F9B2AFED611852500B0D0FE15097EAF08@mail3.marlab.ac.uk>
References: <67B92F9B2AFED611852500B0D0FE15097EAF08@mail3.marlab.ac.uk>
Message-ID: <aa3vbvgk6iuop1kr02linpe0qbt1fos8gf@4ax.com>

On Mon, 12 May 2003 12:31:33 +0100, Douglas Beare
<D.Beare at marlab.ac.uk> wrote:

>
>
>> Hi List,
>> I'm trying to get a bunch of hardened S+ users to switch to R.  They won't
>> move because they have got addicted to the S+ (.ssc)
>> scripting files, available for MS windows versions.  In these files you
>> highlight the code you want to execute by mouse, press an arrow in the
>> menu, and it fires it off to the S+ compiler directly.  Is such a facility
>> actually available for Linux/Windows and Unix versions of R? Is there
>> something similar out there?

That's the nicest feature in the S-PLUS environment, and its something
I'd like in Rgui (but it's not there yet, and it probably won't be
there in 1.8.0 in the fall).

There are various possibilities for replacements.  If the users are
comfortable in EMACS, then ESS provides something very similar.  If
they aren't, it might be worth learning.  This is available on both
Windows and Linux.  Right now I'd say it's the best choice, but
learning EMACS is non-trivial.

Some external text editors in Windows (e.g. WinEDT) have macro
packages that let you highlight and paste text to the R console quite
easily.  I don't know if this approach has been done on Linux.  

I don't use either of the above; I tend to develop in an external
editor, and just use source() or plain old cut and paste to execute.

There are also some new front-ends in the works.  See the R-GUI web
page http://www.r-project.org/GUI and mailing list for current status.

Duncan Murdoch



From Bernhard.Pfaff at drkw.com  Mon May 12 14:39:28 2003
From: Bernhard.Pfaff at drkw.com (Pfaff, Bernhard)
Date: Mon, 12 May 2003 14:39:28 +0200
Subject: [R] FW: S+ Script Files for R???
Message-ID: <18D602BD42B7E24EB810D6454A58DB9004730376@ibfftce505.is.de.dresdnerkb.com>

Douglas Beare wrote:
> 
>>Hi List,
>>I'm trying to get a bunch of hardened S+ users to switch to R.  They won't
>>move because they have got addicted to the S+ (.ssc)
>>scripting files, available for MS windows versions.  In these files you
>>highlight the code you want to execute by mouse, press an arrow in the
>>menu, and it fires it off to the S+ compiler directly.  Is such a facility
>>actually available for Linux/Windows and Unix versions of R? Is there
>>something similar out there?
>>Regards,
>>Doug Beare

Not directly within R, but you can set up an editor to allow this kind 
of features.
The recommended one is Emacs with ESS, but there are others as well 
(with different amounts of support).
See http://cran.r-project.org/other-software.html and 
http://www.sciviews.org/_rgui/.

Uwe Ligges


In case you should decide using Emacs with ESS you can include the following
lines in your ".emacs" startup-file:

(global-set-key [f1] 'ess-eval-line)
(global-set-key [f2] 'ess-eval-region)

with this, you can execute your code line- or region-wise by hitting the f1
or f2 key, respectively; making things even more convenient, rather than
remembering and executing: C-c C-j or C-c M-r or mouse-clicking.

HTH
Bernhard 


----------------------------------------------------------------------
If you have received this e-mail in error or wish to read our e-mail 
disclaimer statement and monitoring policy, please refer to 
http://www.drkw.com/disc/email/ or contact the sender.



From mkondrin at hppi.troitsk.ru  Tue May 13 01:15:09 2003
From: mkondrin at hppi.troitsk.ru (M.Kondrin)
Date: Mon, 12 May 2003 16:15:09 -0700
Subject: [R] grid - deleting and erasing grobs?
Message-ID: <3EC02AFD.1010709@hppi.troitsk.ru>

Hello!
Don't quite understand how can I delete grobs and simultaneously erase 
graphic output they produce. I first change grob's "vp" field to null 
(grid.edit(gr,vp=NULL)) to erase it and then call rm(gr) (as grobs are 
external pointers I'm not shure what this method actually frees 
allocated memory).
May be there is simpler method?
Does garbage collector have any effect on grobs?
Thank you in advance



From mkondrin at hppi.troitsk.ru  Tue May 13 01:15:09 2003
From: mkondrin at hppi.troitsk.ru (M.Kondrin)
Date: Mon, 12 May 2003 16:15:09 -0700
Subject: [R] grid - deleting and erasing grobs?
Message-ID: <3EC02AFD.1010709@hppi.troitsk.ru>

Hello!
Don't quite understand how can I delete grobs and simultaneously erase 
graphic output they produce. I first change grob's "vp" field to null 
(grid.edit(gr,vp=NULL)) to erase it and then call rm(gr) (as grobs are 
external pointers I'm not shure what this method actually frees 
allocated memory).
May be there is simpler method?
Does garbage collector have any effect on grobs?
Thank you in advance



From mkondrin at hppi.troitsk.ru  Tue May 13 01:15:09 2003
From: mkondrin at hppi.troitsk.ru (M.Kondrin)
Date: Mon, 12 May 2003 16:15:09 -0700
Subject: [R] grid - deleting and erasing grobs?
Message-ID: <3EC02AFD.1010709@hppi.troitsk.ru>

Hello!
Don't quite understand how can I delete grobs and simultaneously erase 
graphic output they produce. I first change grob's "vp" field to null 
(grid.edit(gr,vp=NULL)) to erase it and then call rm(gr) (as grobs are 
external pointers I'm not shure what this method actually frees 
allocated memory).
May be there is simpler method?
Does garbage collector have any effect on grobs?
Thank you in advance



From mkondrin at hppi.troitsk.ru  Tue May 13 01:15:09 2003
From: mkondrin at hppi.troitsk.ru (M.Kondrin)
Date: Mon, 12 May 2003 16:15:09 -0700
Subject: [R] grid - deleting and erasing grobs?
Message-ID: <3EC02AFD.1010709@hppi.troitsk.ru>

Hello!
Don't quite understand how can I delete grobs and simultaneously erase 
graphic output they produce. I first change grob's "vp" field to null 
(grid.edit(gr,vp=NULL)) to erase it and then call rm(gr) (as grobs are 
external pointers I'm not shure what this method actually frees 
allocated memory).
May be there is simpler method?
Does garbage collector have any effect on grobs?
Thank you in advance



From mkondrin at hppi.troitsk.ru  Tue May 13 01:15:09 2003
From: mkondrin at hppi.troitsk.ru (M.Kondrin)
Date: Mon, 12 May 2003 16:15:09 -0700
Subject: [R] grid - deleting and erasing grobs?
Message-ID: <3EC02AFD.1010709@hppi.troitsk.ru>

Hello!
Don't quite understand how can I delete grobs and simultaneously erase 
graphic output they produce. I first change grob's "vp" field to null 
(grid.edit(gr,vp=NULL)) to erase it and then call rm(gr) (as grobs are 
external pointers I'm not shure what this method actually frees 
allocated memory).
May be there is simpler method?
Does garbage collector have any effect on grobs?
Thank you in advance



From mkondrin at hppi.troitsk.ru  Tue May 13 01:15:09 2003
From: mkondrin at hppi.troitsk.ru (M.Kondrin)
Date: Mon, 12 May 2003 16:15:09 -0700
Subject: [R] grid - deleting and erasing grobs?
Message-ID: <3EC02AFD.1010709@hppi.troitsk.ru>

Hello!
Don't quite understand how can I delete grobs and simultaneously erase 
graphic output they produce. I first change grob's "vp" field to null 
(grid.edit(gr,vp=NULL)) to erase it and then call rm(gr) (as grobs are 
external pointers I'm not shure what this method actually frees 
allocated memory).
May be there is simpler method?
Does garbage collector have any effect on grobs?
Thank you in advance



From maechler at stat.math.ethz.ch  Mon May 12 15:38:50 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 12 May 2003 15:38:50 +0200
Subject: same posting 6 times .. [Re: [R] grid - deleting grobs?]
In-Reply-To: <3EC02AFD.1010709@hppi.troitsk.ru>
References: <3EC02AFD.1010709@hppi.troitsk.ru>
Message-ID: <16063.41962.920691.609493@gargle.gargle.HOWL>

Before everyone else starts shouting:

This message seems to have been sent 6 times within a few
minutes from the poster's mail server.

I've stopped mail to our mailing lists from that server
completely for the moment.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From spencer.graves at pdf.com  Mon May 12 16:18:46 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 12 May 2003 07:18:46 -0700
Subject: [R] Name spaces in R 1.7.0
References: <16063.34580.490276.358871@localhost.localdomain>
Message-ID: <3EBFAD46.2000709@pdf.com>

	  If you get no better suggestions, modifying the code to include 
something like the following:

	  if(version$minor<7) {do the 1.6.2 code} else{your patch}

hope this helps.  spencer graves

Berwin Turlach wrote:
> Dear all,
> 
> a colleague of mine has some code that calls "linbin2D" in package
> "KernSmooth" directly.  That code is broken under R 1.7.0 since
> "KernSmooth" does not export "linbin2D" from its namespace.  Via
> trial and error we found to possible solutions:
> 
> 1) Edit the file NAMESPACE in the directory where KernSmooth is
>    installed such that linbin2D is exported too.
> 
> 2) Add something like
>        linbin2D <- get("linbin2D", envir=environment(bkde2D))
>    to the code.
> 
> We don't like 1) since it messes around with R installation.  And 2)
> is not nice in case that some students what to run the code under R
> 1.6.x . 
> 
> We wonder whether there is another way of accessing non-exported
> objects from a package?
> 
> Cheers,
> 
>         Berwin
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From tlumley at u.washington.edu  Mon May 12 16:23:55 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 12 May 2003 07:23:55 -0700 (PDT)
Subject: [R] gee
In-Reply-To: <Pine.LNX.4.44.0305111538560.28774-100000@ice3.fas.harvard.edu>
Message-ID: <Pine.A41.4.44.0305120720440.221714-100000@homer04.u.washington.edu>

On Sun, 11 May 2003, Nirmala Ravishankar wrote:

> I am trying to use gee() to calculate the robust standard errors for a
> logit model.  My dataset (zol) has 195019 observations; winner, racebl,
> raceas, racehi are all binary variables.   ID is saved as a vector of
> length 195019 with alternating 0's and 1's.   I get the following error
> message.  I also tried the same command with corstr set to "independence"
> and got the same error message.
>

You're using two clusters of size about 100000, which implies a
ridiculuously large within-cluster correlation matrix.

You could fit the working independence model with glm().  This wouldn't
give correct standard errors, but nothing will with only two clusters.

If you actually have 100000 clusters of size two, then everything will
work fine. You just need to construct a correct id variable.

	-thomas



From spencer.graves at pdf.com  Mon May 12 16:26:45 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 12 May 2003 07:26:45 -0700
Subject: [R] FW: S+ Script Files for R???
References: <18D602BD42B7E24EB810D6454A58DB9004730376@ibfftce505.is.de.dresdnerkb.com>
Message-ID: <3EBFAF25.50605@pdf.com>

	  How do you handle the S-Plus commands that don't work in R (or 
produce different results)?  My current favorite is as follows:

	  if(is.null(version$language)){S-Plus} else{R}

If R, I can, for example, define a function "survReg <- survreg", then 
use my S-Plus script.

hth.  spencer graves

Pfaff, Bernhard wrote:
> Douglas Beare wrote:
> 
>>>Hi List,
>>>I'm trying to get a bunch of hardened S+ users to switch to R.  They won't
>>>move because they have got addicted to the S+ (.ssc)
>>>scripting files, available for MS windows versions.  In these files you
>>>highlight the code you want to execute by mouse, press an arrow in the
>>>menu, and it fires it off to the S+ compiler directly.  Is such a facility
>>>actually available for Linux/Windows and Unix versions of R? Is there
>>>something similar out there?
>>>Regards,
>>>Doug Beare
>>
> 
> Not directly within R, but you can set up an editor to allow this kind 
> of features.
> The recommended one is Emacs with ESS, but there are others as well 
> (with different amounts of support).
> See http://cran.r-project.org/other-software.html and 
> http://www.sciviews.org/_rgui/.
> 
> Uwe Ligges
> 
> 
> In case you should decide using Emacs with ESS you can include the following
> lines in your ".emacs" startup-file:
> 
> (global-set-key [f1] 'ess-eval-line)
> (global-set-key [f2] 'ess-eval-region)
> 
> with this, you can execute your code line- or region-wise by hitting the f1
> or f2 key, respectively; making things even more convenient, rather than
> remembering and executing: C-c C-j or C-c M-r or mouse-clicking.
> 
> HTH
> Bernhard 
> 
> 
> ----------------------------------------------------------------------
> If you have received this e-mail in error or wish to read our e-mail 
> disclaimer statement and monitoring policy, please refer to 
> http://www.drkw.com/disc/email/ or contact the sender.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From fharrell at virginia.edu  Mon May 12 16:50:30 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Mon, 12 May 2003 10:50:30 -0400
Subject: [R] FW: S+ Script Files for R???
In-Reply-To: <3EBFAF25.50605@pdf.com>
References: <18D602BD42B7E24EB810D6454A58DB9004730376@ibfftce505.is.de.dresdnerkb.com>
	<3EBFAF25.50605@pdf.com>
Message-ID: <20030512105030.7b8184b2.fharrell@virginia.edu>

On Mon, 12 May 2003 07:26:45 -0700
Spencer Graves <spencer.graves at pdf.com> wrote:

> 	  How do you handle the S-Plus commands that don't work in R (or 
> produce different results)?  My current favorite is as follows:
> 
> 	  if(is.null(version$language)){S-Plus} else{R}
> 
> If R, I can, for example, define a function "survReg <- survreg", then 
> use my S-Plus script.
> 
> hth.  spencer graves


The Hmisc and Design packages use many such if statements and provide many function substitutions.  

---
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From myao at ou.edu  Mon May 12 17:10:27 2003
From: myao at ou.edu (Minghua Yao)
Date: Mon, 12 May 2003 10:10:27 -0500
Subject: [R] Problem in fetching from Oracle
Message-ID: <HDEPJCAKDEJMEEHKJOKEMEBMCBAA.myao@ou.edu>

Dear all,

I tried the following in R:

 >library(ROracle)
 >ora <- dbDriver("Oracle")
 >channel <- dbConnect(ora, user = "scott",
password="tiger",dbname="abcdef")
 >rs <- dbSendQuery(channel, "select * from USArrests")

 >while(!dbHasCompleted(rs))
  {
  	xxx <- fetch(rs, n = 5000)
  }
+ + + > xxx
Error: Object "xxx" not found

If I changed xxx to df and typed df, I got
+ + + > df
function (x, df1, df2, log = FALSE)
.Internal(df(x, df1, df2, log))
<environment: namespace:base>
>

Please help. Thanks.

Minghua



From spencer.graves at pdf.com  Mon May 12 17:27:48 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 12 May 2003 08:27:48 -0700
Subject: [R] Problem in fetching from Oracle
References: <HDEPJCAKDEJMEEHKJOKEMEBMCBAA.myao@ou.edu>
Message-ID: <3EBFBD74.5040107@pdf.com>

1.  "xxx" was defined local to the "while" statement and disappeared 
after it.  Have you tried the following:

xxx <- NULL
while(~dbHasCompleted(rs)){
	xxx <- c(xxx, fetch(rs, n=5000)
}

I have not accessed Oracle, so I don't know if this will work.  However, 
it will solve one problem with your code.

2.  "df" is the density function for the F distribution, which is what 
you got when you requested it after the "while".

hth.  spencer graves

Minghua Yao wrote:
> Dear all,
> 
> I tried the following in R:
> 
>  >library(ROracle)
>  >ora <- dbDriver("Oracle")
>  >channel <- dbConnect(ora, user = "scott",
> password="tiger",dbname="abcdef")
>  >rs <- dbSendQuery(channel, "select * from USArrests")
> 
>  >while(!dbHasCompleted(rs))
>   {
>   	xxx <- fetch(rs, n = 5000)
>   }
> + + + > xxx
> Error: Object "xxx" not found
> 
> If I changed xxx to df and typed df, I got
> + + + > df
> function (x, df1, df2, log = FALSE)
> .Internal(df(x, df1, df2, log))
> <environment: namespace:base>
> 
> 
> Please help. Thanks.
> 
> Minghua
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From pgilbert at bank-banque-canada.ca  Mon May 12 17:30:46 2003
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Mon, 12 May 2003 11:30:46 -0400
Subject: [R] FW: S+ Script Files for R???
References: <18D602BD42B7E24EB810D6454A58DB9004730376@ibfftce505.is.de.dresdnerkb.com>
	<3EBFAF25.50605@pdf.com>
Message-ID: <3EBFBE26.9C995F6@bank-banque-canada.ca>

Spencer Graves wrote:
> 
>           How do you handle the S-Plus commands that don't work in R (or
> produce different results)?  My current favorite is as follows:
> 
>           if(is.null(version$language)){S-Plus} else{R}

Another possibility is

    if(exists("is.R") && is.R()) {R} else {S-Plus}

but I find it more convenient to define a small library of functions to put in
an Splus library. These cover a few small differences (my list of these is
getting very short) and provide some functionality of R that is missing from
Splus. This includes

   is.R <- function() {F} #S version

which simplifies the above check to if(is.R()){R} else {S-Plus}.

I would be happy to forward the whole (short) list of functions if you like.

Paul Gilbert



From wmusial at gmx.de  Mon May 12 17:36:05 2003
From: wmusial at gmx.de (Wojtek Musial)
Date: Mon, 12 May 2003 17:36:05 +0200
Subject: [R] Zeitreihen problem
References: <001e01c31828$759c93a0$5b33fe91@wojtek>
	<20030512042056.GA30816@sonny.eddelbuettel.com>
Message-ID: <011d01c3189c$8b08f250$a33ffe91@wojtek>

Thanks for the answer(s), but my specific problem is to change the objects
like

> disc[1,1]
 [1] 01/03/1955
 17647 Levels: 01/01/1956 01/01/1957 01/01/1958 01/01/1959 ... 12/31/2002

which are factors to a string like "01/03/1955". I can't find any way to
convert it to such a string, which can then be converted using for example

> strptime(datevec, format="%m/%d/%Y")

Anyone an idea?

Wojtek Musial



From myao at ou.edu  Mon May 12 17:45:27 2003
From: myao at ou.edu (Minghua Yao)
Date: Mon, 12 May 2003 10:45:27 -0500
Subject: [R] Problem in fetching from Oracle
In-Reply-To: <3EBFBD74.5040107@pdf.com>
Message-ID: <HDEPJCAKDEJMEEHKJOKEMEBNCBAA.myao@ou.edu>



Thanks for the reply.

xxx<-NULL doesn't help.

If I disconnected the connection, then both
----------------------------------------------------------------------------
>channel <- dbConnect(ora, user = "scott", password="tiger",
dbname="abcdef")
>rs <- dbSendQuery(channel, "select * from USArrests")
>while(!dbHasCompleted(rs))
  {
    df <- fetch(rs, n = 5000)
  }
>df
----------------------------------------------------------------------------
and
----------------------------------------------------------------------------
>channel <- dbConnect(ora, user = "scott", password="tiger",
dbname="abcdef")
>rs <- dbSendQuery(channel, "select * from USArrests")
>while(!dbHasCompleted(rs))
  {
    xxx <- fetch(rs, n = 5000)
  }
>xxx
----------------------------------------------------------------------------
work.

So, the reason may be we shouldn't have had the previous connection when
using fetch. But I did.

Minghua

-----Original Message-----
From: Spencer Graves [mailto:spencer.graves at PDF.COM]
Sent: Monday, May 12, 2003 10:28 AM
To: Minghua Yao
Cc: R Help
Subject: Re: [R] Problem in fetching from Oracle


1.  "xxx" was defined local to the "while" statement and disappeared
after it.  Have you tried the following:

xxx <- NULL
while(~dbHasCompleted(rs)){
	xxx <- c(xxx, fetch(rs, n=5000)
}

I have not accessed Oracle, so I don't know if this will work.  However,
it will solve one problem with your code.

2.  "df" is the density function for the F distribution, which is what
you got when you requested it after the "while".

hth.  spencer graves

Minghua Yao wrote:
> Dear all,
>
> I tried the following in R:
>
>  >library(ROracle)
>  >ora <- dbDriver("Oracle")
>  >channel <- dbConnect(ora, user = "scott",
> password="tiger",dbname="abcdef")
>  >rs <- dbSendQuery(channel, "select * from USArrests")
>
>  >while(!dbHasCompleted(rs))
>   {
>   	xxx <- fetch(rs, n = 5000)
>   }
> + + + > xxx
> Error: Object "xxx" not found
>
> If I changed xxx to df and typed df, I got
> + + + > df
> function (x, df1, df2, log = FALSE)
> .Internal(df(x, df1, df2, log))
> <environment: namespace:base>
>
>
> Please help. Thanks.
>
> Minghua
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ligges at statistik.uni-dortmund.de  Mon May 12 17:48:14 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 12 May 2003 17:48:14 +0200
Subject: [R] Zeitreihen problem
In-Reply-To: <011d01c3189c$8b08f250$a33ffe91@wojtek>
References: <001e01c31828$759c93a0$5b33fe91@wojtek>	<20030512042056.GA30816@sonny.eddelbuettel.com>
	<011d01c3189c$8b08f250$a33ffe91@wojtek>
Message-ID: <3EBFC23E.4090002@statistik.uni-dortmund.de>

Wojtek Musial wrote:
> Thanks for the answer(s), but my specific problem is to change the objects
> like
> 
> 
>>disc[1,1]
> 
>  [1] 01/03/1955
>  17647 Levels: 01/01/1956 01/01/1957 01/01/1958 01/01/1959 ... 12/31/2002
> 
> which are factors to a string like "01/03/1955". I can't find any way to
> convert it to such a string, which can then be converted using for example
> 
> 
>>strptime(datevec, format="%m/%d/%Y")
> 
> 
> Anyone an idea?

?as.character

Uwe Ligges

> Wojtek Musial



From jerome at hivnet.ubc.ca  Mon May 12 17:55:19 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Mon, 12 May 2003 08:55:19 -0700
Subject: [R] Zeitreihen problem
In-Reply-To: <011d01c3189c$8b08f250$a33ffe91@wojtek>
References: <001e01c31828$759c93a0$5b33fe91@wojtek>
	<20030512042056.GA30816@sonny.eddelbuettel.com>
	<011d01c3189c$8b08f250$a33ffe91@wojtek>
Message-ID: <200305121601.JAA09091@hivnet.ubc.ca>


How about this:

strptime(as.character(datevec), format="%m/%d/%Y")

Cheers,
Jerome

On May 12, 2003 08:36 am, Wojtek Musial wrote:
> Thanks for the answer(s), but my specific problem is to change the
> objects like
>
> > disc[1,1]
>
>  [1] 01/03/1955
>  17647 Levels: 01/01/1956 01/01/1957 01/01/1958 01/01/1959 ...
> 12/31/2002
>
> which are factors to a string like "01/03/1955". I can't find any way to
> convert it to such a string, which can then be converted using for
> example
>
> > strptime(datevec, format="%m/%d/%Y")
>
> Anyone an idea?
>
> Wojtek Musial
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From wmusial at gmx.de  Mon May 12 17:59:05 2003
From: wmusial at gmx.de (Wojtek Musial)
Date: Mon, 12 May 2003 17:59:05 +0200
Subject: [R] Zeitreihen problem
References: <001e01c31828$759c93a0$5b33fe91@wojtek>
	<20030512042056.GA30816@sonny.eddelbuettel.com>
	<011d01c3189c$8b08f250$a33ffe91@wojtek>
	<200305121601.JAA09091@hivnet.ubc.ca>
Message-ID: <017301c3189f$6a7b5480$a33ffe91@wojtek>

Thanks to all, it works!


> How about this:
>
> strptime(as.character(datevec), format="%m/%d/%Y")
>
> Cheers,
> Jerome
>
> On May 12, 2003 08:36 am, Wojtek Musial wrote:
> > Thanks for the answer(s), but my specific problem is to change the
> > objects like
> >
> > > disc[1,1]
> >
> >  [1] 01/03/1955
> >  17647 Levels: 01/01/1956 01/01/1957 01/01/1958 01/01/1959 ...
> > 12/31/2002
> >
> > which are factors to a string like "01/03/1955". I can't find any way to
> > convert it to such a string, which can then be converted using for
> > example
> >
> > > strptime(datevec, format="%m/%d/%Y")
> >
> > Anyone an idea?
> >
> > Wojtek Musial
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From tblackw at umich.edu  Mon May 12 17:59:43 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Mon, 12 May 2003 11:59:43 -0400 (EDT)
Subject: [R] Zeitreihen problem
In-Reply-To: <011d01c3189c$8b08f250$a33ffe91@wojtek>
Message-ID: <Pine.SOL.4.44.0305121155440.14503-100000@mspacman.gpcc.itd.umich.edu>


as.character()  converts from a factor back to character strings.
In this context,

result <- strptime(as.character(disc[ ,1]), format="%m/%d/%y")

or something like that.  Thanks for asking a second time:  when I
saw the earlier response, I wondered whether this conversion would
be a problem.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Mon, 12 May 2003, Wojtek Musial wrote:

> Thanks for the answer(s), but my specific problem is to change the objects
> like
>
> > disc[1,1]
>  [1] 01/03/1955
>  17647 Levels: 01/01/1956 01/01/1957 01/01/1958 01/01/1959 ... 12/31/2002
>
> which are factors to a string like "01/03/1955". I can't find any way to
> convert it to such a string, which can then be converted using for example
>
> > strptime(datevec, format="%m/%d/%Y")
>
> Wojtek Musial



From rnelson at cariboo.bc.ca  Mon May 12 21:11:40 2003
From: rnelson at cariboo.bc.ca (Ross Nelson)
Date: Mon, 12 May 2003 12:11:40 -0700
Subject: [R] skew and kurtosis
Message-ID: <8F83F891-84AD-11D7-AB8F-000393BA1D66@cariboo.bc.ca>

Is there a simple function that returns skew and kurtosis estimates in 
R?

Ross



From zeileis at ci.tuwien.ac.at  Mon May 12 21:20:57 2003
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Mon, 12 May 2003 21:20:57 +0200
Subject: [R] skew and kurtosis
In-Reply-To: <8F83F891-84AD-11D7-AB8F-000393BA1D66@cariboo.bc.ca>
References: <8F83F891-84AD-11D7-AB8F-000393BA1D66@cariboo.bc.ca>
Message-ID: <200305121920.h4CJKvVP018280@thorin.ci.tuwien.ac.at>

On Monday 12 May 2003 21:11, Ross Nelson wrote:

> Is there a simple function that returns skew and kurtosis estimates
> in R?

  skewness()
and
  kurtosis()
in e1071.
Z


> Ross
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From paulda at BATTELLE.ORG  Tue May 13 00:45:47 2003
From: paulda at BATTELLE.ORG (Paul, David  A)
Date: Mon, 12 May 2003 18:45:47 -0400
Subject: [R] avas
Message-ID: <940250A9EB37A24CBE28D858EF077749136D5A@ws-bco-mse3.milky-way.battelle.org>

Are there any equivalent function(s) in R1.70/Win2k for the
avas( ) function in Splus 6.1/Win2k?

FYI: The implementation of avas( ) in Splus uses
.Fortran( ) to call to precompiled code.
 

Much thanks,
  david paul



From baron at psych.upenn.edu  Tue May 13 01:04:36 2003
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Mon, 12 May 2003 19:04:36 -0400
Subject: [R] avas
In-Reply-To: <940250A9EB37A24CBE28D858EF077749136D5A@ws-bco-mse3.milky-way.battelle.org>
References: <940250A9EB37A24CBE28D858EF077749136D5A@ws-bco-mse3.milky-way.battelle.org>
Message-ID: <20030512230436.GG14489@mail1.sas.upenn.edu>

On 05/12/03 18:45, Paul, David  A wrote:
>Are there any equivalent function(s) in R1.70/Win2k for the
>avas( ) function in Splus 6.1/Win2k?
>
>FYI: The implementation of avas( ) in Splus uses
>.Fortran( ) to call to precompiled code.

See the acepack package.



From Ted.Harding at nessie.mcc.ac.uk  Tue May 13 02:23:28 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue, 13 May 2003 01:23:28 +0100 (BST)
Subject: [R] FW: S+ Script Files for R???
In-Reply-To: <67B92F9B2AFED611852500B0D0FE15097EAF08@mail3.marlab.ac.uk>
Message-ID: <XFMail.030512223024.Ted.Harding@nessie.mcc.ac.uk>

On 12-May-03 Douglas Beare wrote:
>> I'm trying to get a bunch of hardened S+ users to switch to R.
>> They won't move because they have got addicted to the S+ (.ssc)
>> scripting files, available for MS windows versions.  In these files
>> you highlight the code you want to execute by mouse, press an arrow
>> in the menu, and it fires it off to the S+ compiler directly.  Is
>> such a facility actually available for Linux/Windows and Unix
>> versions of R? Is there something similar out there?

Despite recent replies (though mind you I'm not a user of ESS so can't
comment on what that offers, though my prior guess is that people who
like the pointy-clicky mindset of Windows are unlikely to adapt painlessly
to emacs), you can in fact do something very similar with X windows in
Unix/Linux. I have often done it, both with script files I'm writing
myself and especially with example scripts (sometimes complex applications
such as in the README for Schafer's MIX, working through it task by task
to see what happens along the way, sometimes the mini-examples which are
appended to the help files for R functions).

This works because in X windows highlighting a block of text automatically
copies it into the "paste" buffer, and middle-clicking the mouse copies
the "paste" buffer into whatever window is "in focus" at the moment of
clicking.

The procedure is very simple:

1. You have R running in an xterm in X windows.

Either:

2. You have another file with "script" (i.e. R code) open in another
   X window (you may be viewing the file with say 'less' or you may
   be editing it using whatever text editor you prefer). Then:

3. Position the mouse pointer to the beginning of the code you want to
   highlight, press the left button, and drag it to the end, thus
   highlighting the whole block. Then:

4. Move the mouse to the R window; bring this to the top by clicking
   on its top bar, and then with the mouse anywhere inside the window,
   press the middle button. The highlighted R code will then be copied
   into the R command window and executed. (Depending on how your
   window-manager is configured, it may be possible to short-cut this:
   highlight the code, move the pointer inside the R window, and simply
   press middle button).

Or:

5. You have been paging through a help file in the R window, and at the
   end there is some R code you want to try. While the pager is still up,
   highlight the block of code. Close the pager (e.g. with "q"). Then
   middle-click in the R window. Same effect as (4) above.

Since the basic moves in this are (A) Highlight the code, followed by
(B) Click the mouse, I don't see that this is any more demanding than
what your Windows users are used to, or indeed any different at all!

I hope this helps,
Ted.



From abunn at montana.edu  Tue May 13 06:18:18 2003
From: abunn at montana.edu (Andy Bunn)
Date: Mon, 12 May 2003 22:18:18 -0600
Subject: [R] Sorting a matrix in an odd way
Message-ID: <000201c31906$c1ab8f10$d4a00ecf@simATE>

Hi, I have a matrix not unlike this:

foo <- matrix(,5,5)
foo[5,1] <- 1
foo[1:3,2] <- 1
foo[3:4,3] <- 1
foo[4:5,4] <- 1
foo[2:4,5] <- 1
foo
     [,1] [,2] [,3] [,4] [,5]
[1,]   NA    1   NA   NA   NA
[2,]   NA    1   NA   NA    1
[3,]   NA    1    1   NA    1
[4,]   NA   NA    1    1    1
[5,]    1   NA   NA    1   NA

I want to get a vector that is the column numbers as sorted by the first
non-NA value.
Like this: 
2,5,3,4,1

I have been able to do this by adding an index and looping the matrix by
column. Can anybody think of a cleverer way to do this?

Thanks, as always, in advance.

Andy



From tplate at blackmesacapital.com  Tue May 13 06:46:08 2003
From: tplate at blackmesacapital.com (Tony Plate)
Date: Mon, 12 May 2003 22:46:08 -0600
Subject: [R] Sorting a matrix in an odd way
In-Reply-To: <000201c31906$c1ab8f10$d4a00ecf@simATE>
Message-ID: <5.2.1.1.2.20030512224217.0381a730@mailhost.blackmesacapital.com>

I assume you mean "a vector that is the column numbers as sorted by the 
*index* of the first non-NA value"

I think this will do what you want:

 > order(apply(foo, 2, function(col) which(!is.na(col))[1]))
[1] 2 5 3 4 1
 >

Fortuitously, this also gives correct results when a column contains all NA 
values (because [1] of an empty vector returns NA, and the default for 
order() is to put NA values last).

hope this helps,

Tony Plate

At Monday 10:18 PM 5/12/2003 -0600, Andy Bunn wrote:
>Hi, I have a matrix not unlike this:
>
>foo <- matrix(,5,5)
>foo[5,1] <- 1
>foo[1:3,2] <- 1
>foo[3:4,3] <- 1
>foo[4:5,4] <- 1
>foo[2:4,5] <- 1
>foo
>      [,1] [,2] [,3] [,4] [,5]
>[1,]   NA    1   NA   NA   NA
>[2,]   NA    1   NA   NA    1
>[3,]   NA    1    1   NA    1
>[4,]   NA   NA    1    1    1
>[5,]    1   NA   NA    1   NA
>
>I want to get a vector that is the column numbers as sorted by the first
>non-NA value.
>Like this:
>2,5,3,4,1
>
>I have been able to do this by adding an index and looping the matrix by
>column. Can anybody think of a cleverer way to do this?
>
>Thanks, as always, in advance.
>
>Andy
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From rossini at blindglobe.net  Tue May 13 07:55:41 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Mon, 12 May 2003 22:55:41 -0700
Subject: [R] FW: S+ Script Files for R???
In-Reply-To: <XFMail.030512223024.Ted.Harding@nessie.mcc.ac.uk> ((Ted
	Harding) <Ted.Harding@nessie.mcc.ac.uk>'s message of "Tue, 13 May 2003
	01:23:28 +0100 (BST)")
References: <XFMail.030512223024.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <87el33o0f6.fsf@jeeves.blindglobe.net>

(Ted Harding) <Ted.Harding at nessie.mcc.ac.uk> writes:


> Despite recent replies (though mind you I'm not a user of ESS so can't
> comment on what that offers, though my prior guess is that people who
> like the pointy-clicky mindset of Windows are unlikely to adapt painlessly
> to emacs), you can in fact do something very similar with X windows in
> Unix/Linux. I have often done it, both with script files I'm writing
> myself and especially with example scripts (sometimes complex applications
> such as in the README for Schafer's MIX, working through it task by task
> to see what happens along the way, sometimes the mini-examples which are
> appended to the help files for R functions).

What you are describing is exactly what ESS is designed to make much
simpler... 

> 2. You have another file with "script" (i.e. R code) open in another
>    X window (you may be viewing the file with say 'less' or you may
>    be editing it using whatever text editor you prefer). Then:

So, you split Emacs to have 2 buffers, one with R and the other (or
many others) with source files).  In the next version of ESS, John
Fox's simple split screen will be available, along with toolbar
buttons for R, S-PLUS, and (hopefully) SAS.

> 3. Position the mouse pointer to the beginning of the code you want to
>    highlight, press the left button, and drag it to the end, thus
>    highlighting the whole block. Then:

C-c C-r to send it to R.

Or if it's within a function block, C-c C-f to send it to R

Or to send the current line, or buffer, or send line and step to the
next non-comment, and well...

> 5. You have been paging through a help file in the R window, and at the
>    end there is some R code you want to try. While the pager is still up,
>    highlight the block of code. Close the pager (e.g. with "q"). Then
>    middle-click in the R window. Same effect as (4) above.

C-c C-v object.to.get.help.on

Press "l" on the example code to evaluate one line and step to the
next.

best,
-tony

-- 
A.J. Rossini rossini at u.washington.edu http://software.biostat.washington.edu/ 
Biostatistics, U Washington and Fred Hutchinson Cancer Research Center

FHCRC:Tu: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email 
UW  : Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX 

CONFIDENTIALITY NOTICE: This e-mail message and any attachments ... {{dropped}}



From gisar at nus.edu.sg  Tue May 13 09:05:17 2003
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Tue, 13 May 2003 15:05:17 +0800
Subject: [R] Sorting a matrix in an odd way
Message-ID: <024D6AEFCB92CB47BA1085751D184BB801053FF5@MBXSRV03.stf.nus.edu.sg>

You can use unique since it keeps the ordering intact (ie no sorting).

unique( unlist( apply(foo, 1, function(x) which(!is.na(x)) ) ) )
[1] 2 5 3 4 1


-----Original Message-----
From: Andy Bunn [mailto:abunn at montana.edu] 
Sent: Tuesday, May 13, 2003 12:18 PM
To: 'R-Help'
Subject: [R] Sorting a matrix in an odd way


Hi, I have a matrix not unlike this:

foo <- matrix(,5,5)
foo[5,1] <- 1
foo[1:3,2] <- 1
foo[3:4,3] <- 1
foo[4:5,4] <- 1
foo[2:4,5] <- 1
foo
     [,1] [,2] [,3] [,4] [,5]
[1,]   NA    1   NA   NA   NA
[2,]   NA    1   NA   NA    1
[3,]   NA    1    1   NA    1
[4,]   NA   NA    1    1    1
[5,]    1   NA   NA    1   NA

I want to get a vector that is the column numbers as sorted by the first
non-NA value. Like this: 
2,5,3,4,1

I have been able to do this by adding an index and looping the matrix by
column. Can anybody think of a cleverer way to do this?

Thanks, as always, in advance.

Andy

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From dtudor at evhr.net  Tue May 13 09:01:39 2003
From: dtudor at evhr.net (David Tudor)
Date: Tue, 13 May 2003 09:01:39 +0200
Subject: [R] Connection problem to MySQL
Message-ID: <5.2.0.9.0.20030513085211.00b2b8c0@pop3.evhr.net>


Dear All,

What am I doing wrong?


 >library(DBI)
 > library(RMySQL)
 > mgr <- dbDriver("MySQL")
 > con <- dbConnect(mgr, host="http://localhost", dbname="marketing")
Error in mysqlNewConnection(drv, ...) : RS-DBI driver: (could not connect 
(null)@http://localhost on dbname "marketing"
)
 > con <- dbConnect(mgr, host="http://localhost/", 
dbname="c:/mysql/data/marketing/")
Error in mysqlNewConnection(drv, ...) : RS-DBI driver: (could not connect 
(null)@http://localhost/ on dbname "c:/mysql/data/marketing/"
)


I am running:
R1.7.0
php 4.3.0
MySQL 3.23.55
Windows XP 5.1.2600
Apache 1.3.27

Thank you very much for your help.

David Tudor
-------------- next part --------------

---




From kgk at pharm.auth.gr  Tue May 13 09:09:00 2003
From: kgk at pharm.auth.gr (Kyriakos Kachrimanis)
Date: Tue, 13 May 2003 10:09:00 +0300
Subject: [R] 1) variable influence in PCR/PLS models 2) how to cite CRAN
	packages
Message-ID: <005901c3191e$87ea5320$5e05cf9b@pharm.auth.gr>

Dear list members,

I would like to ask two questions, although the second one must have been
answered a thousand times.

1) is there a simple way to estimate the influence of individual variables
in PCR and PLS models? What I have in mind is a way to rank the variables
according to their influence, using some numerical value of a statistic.

2) what is the proper way to cite a CRAN package? How should I cite the
authors of the package?

Thank you very much in advance.

K. Kachrimanis


---



From ripley at stats.ox.ac.uk  Tue May 13 09:38:10 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 13 May 2003 08:38:10 +0100 (BST)
Subject: [R] Connection problem to MySQL
In-Reply-To: <5.2.0.9.0.20030513085211.00b2b8c0@pop3.evhr.net>
Message-ID: <Pine.LNX.4.44.0305130835540.18433-100000@gannet.stats>

On Tue, 13 May 2003, David Tudor wrote:

> What am I doing wrong?
> 
> 
>  >library(DBI)
>  > library(RMySQL)
>  > mgr <- dbDriver("MySQL")
>  > con <- dbConnect(mgr, host="http://localhost", dbname="marketing")
> Error in mysqlNewConnection(drv, ...) : RS-DBI driver: (could not connect 
> (null)@http://localhost on dbname "marketing"
> )
>  > con <- dbConnect(mgr, host="http://localhost/", 
> dbname="c:/mysql/data/marketing/")
> Error in mysqlNewConnection(drv, ...) : RS-DBI driver: (could not connect 
> (null)@http://localhost/ on dbname "c:/mysql/data/marketing/"
> )
> 
> 
> I am running:
> R1.7.0
> php 4.3.0
> MySQL 3.23.55
> Windows XP 5.1.2600
> Apache 1.3.27


A couple of problems which are immediately obvious:

1) host="http://localhost/" is not a host.  Try "localhost".

2) The pre-compiled RMySQL for R 1.7.0 is for MySQL 4.0.x.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From knussear at biodiversity.unr.edu  Tue May 13 10:00:42 2003
From: knussear at biodiversity.unr.edu (knussear@biodiversity.unr.edu)
Date: Tue, 13 May 2003 01:00:42 -0700 (PDT)
Subject: [R] Barchart to make a graph like this??
Message-ID: <3614.24.205.101.9.1052812842.squirrel@Biodiversity>

Hi list,

I'm trying to get R to make a graph like the one shown in this pdf, where
males are white bars and females are black bars.

http://www.brrc.unr.edu/~knussear/mmgraph.pdf

I tried barchart, but I couldnt get the bars to share a common x axis.

Do you have any suggestions?

Thanks for your help

Ken



From christoph.lehmann at gmx.ch  Tue May 13 10:31:57 2003
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Tue, 13 May 2003 10:31:57 +0200
Subject: [R] discriminant analysis: prerequisites
Message-ID: <1052814716.1140.5.camel@christophl>

Dear R users
Could someone explain me, why I need more observations than variables to
conduct a discriminant analysis (as I was told by one of our teachers)?

I have n = 66 observations, and 133 + 3 + 7 + 8 variables. Well, for the
first 133 variables, I could conduct a PCA first, to reduce the amount
of information.

Thanks for an answer.

Cheers

Christoph
-- 
Christoph Lehmann <christoph.lehmann at gmx.ch>



From Isabelle.ZABALZA-MEZGHANI at ifp.fr  Tue May 13 10:52:30 2003
From: Isabelle.ZABALZA-MEZGHANI at ifp.fr (ZABALZA-MEZGHANI Isabelle)
Date: Tue, 13 May 2003 10:52:30 +0200
Subject: [R] Dopt for Windows
Message-ID: <488C02265C6AD611BF200002A542182F022B33A6@irnts22.ifp.fr>

Hi,

I would like to have some advise about how to install Dopt on R for Windows.
I can not manage to properly compile Dopt.f anf to get a suitable dll for R.
Can someone explain me step by step what should I do ?

Thanks in advance

Isabelle Zabalza-Mezghani



From erwan.barret at wanadoo.fr  Tue May 13 11:05:40 2003
From: erwan.barret at wanadoo.fr (Erwan BARRET)
Date: Tue, 13 May 2003 11:05:40 +0200 (CEST)
Subject: [R] How make a package
Message-ID: <18867749.1052816740797.JavaMail.www@wwinf0602>

I've used  "package.skeleton" and then I used "R cmd check" and it didn't work.
can you help me?



From erwan.barret at wanadoo.fr  Tue May 13 11:31:05 2003
From: erwan.barret at wanadoo.fr (Erwan BARRET)
Date: Tue, 13 May 2003 11:31:05 +0200 (CEST)
Subject: [R] HTMLplot
Message-ID: <31345738.1052818254397.JavaMail.www@wwinf0202>

can you explain how it works?
I tried to do like the example but it doesn't work



From wl at eimb.ru  Tue May 13 12:02:21 2003
From: wl at eimb.ru (Wladimir Eremeev)
Date: Tue, 13 May 2003 14:02:21 +0400
Subject: [R] SD
Message-ID: <19584.030513@eimb.ru>

Dear r-help,

  Function sd calculates the standard deviation 'with (n-1)
  denominator'.
  
  Are there any alternatives with n denominator?

  Thank you very much.
  
-- 
Best regards
Wladimir Eremeev                                     mailto:wl at eimb.ru



From ligges at statistik.uni-dortmund.de  Tue May 13 11:56:59 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 13 May 2003 11:56:59 +0200
Subject: [R] HTMLplot
In-Reply-To: <31345738.1052818254397.JavaMail.www@wwinf0202>
References: <31345738.1052818254397.JavaMail.www@wwinf0202>
Message-ID: <3EC0C16B.3030007@statistik.uni-dortmund.de>

Erwan BARRET wrote:
> can you explain how it works?

I hope it's in the documentation.

> I tried to do like the example but it doesn't work

It's a great idea to tell us

a) what you are going to do exactly,
b) what was not working, including any error message,
c) the package you are using (I guess R2HTML),
d) the version of R you are using,
e) the OS you are working with.

It's also a good idea to contact the package maintainer at first.

In other words: We can only guess what's going on, since almost all 
relevant information is missing ...

Uwe Ligges



From ligges at statistik.uni-dortmund.de  Tue May 13 11:59:32 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 13 May 2003 11:59:32 +0200
Subject: [R] How make a package
In-Reply-To: <18867749.1052816740797.JavaMail.www@wwinf0602>
References: <18867749.1052816740797.JavaMail.www@wwinf0602>
Message-ID: <3EC0C204.20901@statistik.uni-dortmund.de>

Erwan BARRET wrote:
> I've used  "package.skeleton" and then I used "R cmd check" and it didn't work.
> can you help me

For me it works after setting it up correctly (i.e. filling out the Rd 
files, editing DESCRIPTION, etc.). See the Writing R extensions manual 
for details.


So again:  It's a great idea to tell us
a) what was not working, including any error message,
b) the version of R you are using,
c) the OS you are working with.

Please, be more specific!

Uwe Ligges



From ligges at statistik.uni-dortmund.de  Tue May 13 12:07:24 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 13 May 2003 12:07:24 +0200
Subject: [R] SD
In-Reply-To: <19584.030513@eimb.ru>
References: <19584.030513@eimb.ru>
Message-ID: <3EC0C3DC.3030002@statistik.uni-dortmund.de>

Wladimir Eremeev wrote:
> Dear r-help,
> 
>   Function sd calculates the standard deviation 'with (n-1)
>   denominator'.
>   
>   Are there any alternatives with n denominator?
> 
>   Thank you very much.
>   

I don't know, but
  sqrt(sum((x - mean(x))^2) / n)
from the definition is a quick hack (computational not nice, for sure).

Uwe Ligges



From uth at zhwin.ch  Tue May 13 12:12:24 2003
From: uth at zhwin.ch (=?iso-8859-1?Q?=22Untern=E4hrer_Thomas=2C_uth=22?=)
Date: Tue, 13 May 2003 12:12:24 +0200
Subject: [R] Delete files from R
Message-ID: <6A4BCEF0FD65344A8F496D7E520DD8B9023E90A7@lobster.zhwin.ch>


Hi,

I have a file: d:\foo.txt and want to delete this.

I tried: 
system("del d:/foo.txt") works not
system("notepad d:/foo.txt") works

Is it possible that I can't delete files or do I have misunderstood something?

(del is a DOS-command. The "string works" under DOS "\")


Thanks a lot

Thomas


-----
Windows XP
R 1.6.2 (update!, I know)



From ligges at statistik.uni-dortmund.de  Tue May 13 12:13:58 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 13 May 2003 12:13:58 +0200
Subject: [R] Dopt for Windows
In-Reply-To: <488C02265C6AD611BF200002A542182F022B33A6@irnts22.ifp.fr>
References: <488C02265C6AD611BF200002A542182F022B33A6@irnts22.ifp.fr>
Message-ID: <3EC0C566.3080909@statistik.uni-dortmund.de>

ZABALZA-MEZGHANI Isabelle wrote:
> Hi,
> 
> I would like to have some advise about how to install Dopt on R for Windows.
> I can not manage to properly compile Dopt.f anf to get a suitable dll for R.
> Can someone explain me step by step what should I do ?
> 
> Thanks in advance
> 
> Isabelle Zabalza-Mezghani

Do you mean the Dopt version from CRAN/src/contrib/Devel/ ?

It works with
  Rcmd INSTALL Dopt_0.1-4.tar.gz
for me (at least comiling and installation). Just follow the Writing R 
Extensions manual and the file readme.packages in .../src/gnuwin32 of 
your R installation.

If you don't get it to work, I might set up a binary, but without 
guarantee that it works (there is for sure a reason why it's in the 
Devel directory; and read the Motes, Readme, STATEMENT and Porting.txt 
files from that package, please).

Uwe Ligges



From V.Khamenia at BioVisioN.de  Tue May 13 12:16:44 2003
From: V.Khamenia at BioVisioN.de (Khamenia, Valery)
Date: Tue, 13 May 2003 12:16:44 +0200
Subject: [R] homals for win32?
Message-ID: <D15343265276D31197BC00A024A6C110774047@EXS_BDC>

Hi All 

  is there "homals" package prepared for win32?

kind regards,
Valery A.Khamenya
---------------------------------------------------------------------------
Bioinformatics Department
BioVisioN AG, Hannover



From carlos.ortega at minorplanet.com  Tue May 13 12:31:41 2003
From: carlos.ortega at minorplanet.com (Carlos Ortega)
Date: Tue, 13 May 2003 12:31:41 +0200
Subject: [R] Barchart to make a graph like this??
In-Reply-To: <3614.24.205.101.9.1052812842.squirrel@Biodiversity>
Message-ID: <001101c3193a$d80f3a20$2d6ea8c0@MinorplanetDev>

Hello,

Please check the search engines available in the Mailing Lists and look
for "bar", there is a similar post dated February 2002 titled:
"Smoothed lines over barplots"

Hope it helps,
Carlos Ortega.


-----Mensaje original-----
De: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] En nombre de
knussear at biodiversity.unr.edu
Enviado el: martes, 13 de mayo de 2003 10:01
Para: r-help at stat.math.ethz.ch
Asunto: [R] Barchart to make a graph like this??


Hi list,

I'm trying to get R to make a graph like the one shown in this pdf,
where males are white bars and females are black bars.

http://www.brrc.unr.edu/~knussear/mmgraph.pdf

I tried barchart, but I couldnt get the bars to share a common x axis.

Do you have any suggestions?

Thanks for your help

Ken

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help

###  This email has been checked for all known viruses by the 
###  Firstnet anti-virus system - http://www.firstnet.net.uk 
###  Please email fav at firstnet.net.uk for details. 


_____
The information in this email is confidential and it may not be\... {{dropped}}



From krcabrer at epm.net.co  Tue May 13 12:46:25 2003
From: krcabrer at epm.net.co (Kenneth Cabrera)
Date: Tue, 13 May 2003 05:46:25 -0500
Subject: [R] Sorting a matrix in an odd way
References: <000201c31906$c1ab8f10$d4a00ecf@simATE>
Message-ID: <3EC0CD01.9070105@epm.net.co>

Try this, and tell me if it works.

foo <- matrix(,5,5)
foo[5,1] <- 1
foo[1:3,2] <- 1
foo[3:4,3] <- 1
foo[4:5,4] <- 1
foo[2:4,5] <- 1
foo
    [,1] [,2] [,3] [,4] [,5]
[1,]   NA    1   NA   NA   NA
[2,]   NA    1   NA   NA    1
[3,]   NA    1    1   NA    1
[4,]   NA   NA    1    1    1
[5,]    1   NA   NA    1   NA

I don't now if the rest non-NA values are only one, I suppose...

foo[is.na(foo)]<-0

biny<-function(x,l) sum(x*2^((l-1):0))

order(apply(foo,2,biny,nrow(foo)),decreasing=TRUE)

Hope, the idea helps.

Best Regards

Kenneth





Andy Bunn wrote:

>Hi, I have a matrix not unlike this:
>
>foo <- matrix(,5,5)
>foo[5,1] <- 1
>foo[1:3,2] <- 1
>foo[3:4,3] <- 1
>foo[4:5,4] <- 1
>foo[2:4,5] <- 1
>foo
>     [,1] [,2] [,3] [,4] [,5]
>[1,]   NA    1   NA   NA   NA
>[2,]   NA    1   NA   NA    1
>[3,]   NA    1    1   NA    1
>[4,]   NA   NA    1    1    1
>[5,]    1   NA   NA    1   NA
>
>I want to get a vector that is the column numbers as sorted by the first
>non-NA value.
>Like this: 
>2,5,3,4,1
>
>I have been able to do this by adding an index and looping the matrix by
>column. Can anybody think of a cleverer way to do this?
>
>Thanks, as always, in advance.
>
>Andy
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
>  
>

-- 
Kenneth Roy Cabrera Torres
Celular +57 (315) 405 9339



From trainor at transborder.org  Tue May 13 13:04:59 2003
From: trainor at transborder.org (Douglas Trainor)
Date: Tue, 13 May 2003 06:04:59 -0500
Subject: [R] homals for win32?
In-Reply-To: <D15343265276D31197BC00A024A6C110774047@EXS_BDC>
References: <D15343265276D31197BC00A024A6C110774047@EXS_BDC>
Message-ID: <3EC0D15B.5090700@transborder.org>

Khamenia, Valery wrote:

> Hi All
>
> is there "homals" package prepared for win32?


Jan de Leeuw sent out a release three days ago to the AlbertGifi list;
you might want to join.  Also a release with convex hull code, which
he calls hullplots, for variables...

    http://lists.stat.ucla.edu/mailman/listinfo/albertgifi

He said R code was submitted to CRAN.

Or you could check out the activity of the last 5 days:

    http://lists.stat.ucla.edu/pipermail/albertgifi/2003-May/thread.html

For example:

-------- Original Message --------
Subject: 	[AlbertGifi] R homals package
Date: 	Sat, 10 May 2003 10:34:50 -0700
From: 	Jan de Leeuw <deleeuw at stat.ucla.edu>
To: 	albertgifi at login.stat.ucla.edu
CC: 	statcompute at login.stat.ucla.edu




This is an R package which can be installed into Unix versions
of R (including the Darwin/X11 version for OS X) by

sudo R CMD INSTALL homals_0.1.1.tar.gz

The zip file is a precompiled R package for Windows which
can be installed from the package menu in Rgui.

The package give you access to the homals() and tkhomals()
commands. For tkhomals(), you need to be running an
X11 server under Unix. It runs fine under Windows with the
native Tcl/Tk. It also needs the tkrplot package installed.
tkhomals() provides a GUI to enter the parameters for the
homals() function and it provides some on-screen plots.
For the voronoi plots you also need the deldir package.

This includes the gubell, sleeping, mammals, house, senate,
and galo datasets.

Running one of the examples is as simple as

 > library(homals)
 > data(senate)
 > tkhomals(senate)

Documentation is skimpy. It will be expanded in subsequent
0.1.n versions.



From ligges at statistik.uni-dortmund.de  Tue May 13 13:05:08 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 13 May 2003 13:05:08 +0200
Subject: [R] Delete files from R
In-Reply-To: <6A4BCEF0FD65344A8F496D7E520DD8B9023E90A7@lobster.zhwin.ch>
References: <6A4BCEF0FD65344A8F496D7E520DD8B9023E90A7@lobster.zhwin.ch>
Message-ID: <3EC0D164.2000603@statistik.uni-dortmund.de>

Untern?hrer Thomas, uth wrote:
> Hi,
> 
> I have a file: d:\foo.txt and want to delete this.
> 
> I tried: 
> system("del d:/foo.txt") works not
> system("notepad d:/foo.txt") works
> 
> Is it possible that I can't delete files or do I have misunderstood something?
> 
> (del is a DOS-command. The "string works" under DOS "\")
> 
> 
> Thanks a lot
> 
> Thomas
> 

Two simple ways:
  file.remove("d:/foo.txt")
and
  shell("del d:\\foo.txt")

Uwe Ligges



From ripley at stats.ox.ac.uk  Tue May 13 13:07:56 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 13 May 2003 12:07:56 +0100 (BST)
Subject: [R] homals for win32?
In-Reply-To: <D15343265276D31197BC00A024A6C110774047@EXS_BDC>
Message-ID: <Pine.LNX.4.44.0305131207180.18665-100000@gannet.stats>

On Tue, 13 May 2003, Khamenia, Valery wrote:

>   is there "homals" package prepared for win32?

I presume the source code on CRAN works on all platforms, but why don't 
you try it and see?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Tue May 13 13:09:22 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 13 May 2003 13:09:22 +0200
Subject: [R] homals for win32?
In-Reply-To: <D15343265276D31197BC00A024A6C110774047@EXS_BDC>
References: <D15343265276D31197BC00A024A6C110774047@EXS_BDC>
Message-ID: <3EC0D262.9090901@statistik.uni-dortmund.de>

Khamenia, Valery wrote:
> Hi All 
> 
>   is there "homals" package prepared for win32?
> 

Not on CRAN. I think the maintainer, Brian D Ripley, of the binary 
packages for Windows is very busy these days.
But you can compile it yourself in the meantime, just read 
"readme.packages" in .../src/gnuwin32 how to set it up.

Uwe Ligges



From ripley at stats.ox.ac.uk  Tue May 13 13:11:41 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 13 May 2003 12:11:41 +0100 (BST)
Subject: [R] Delete files from R
In-Reply-To: <6A4BCEF0FD65344A8F496D7E520DD8B9023E90A7@lobster.zhwin.ch>
Message-ID: <Pine.LNX.4.44.0305131208420.18665-100000@gannet.stats>

On Tue, 13 May 2003, "Untern?hrer Thomas, uth" wrote:

> I have a file: d:\foo.txt and want to delete this.
> 
> I tried: 
> system("del d:/foo.txt") works not
> system("notepad d:/foo.txt") works
> 
> Is it possible that I can't delete files or do I have misunderstood something?
> 
> (del is a DOS-command. The "string works" under DOS "\")

And your OS appears to be *Windows* not DOS!

You could try ?shell to see how to run a shell and its commands.
However, ?unlink would be more profitable.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From V.Khamenia at BioVisioN.de  Tue May 13 13:12:44 2003
From: V.Khamenia at BioVisioN.de (Khamenia, Valery)
Date: Tue, 13 May 2003 13:12:44 +0200
Subject: AW: [R] homals for win32?
Message-ID: <D15343265276D31197BC00A024A6C110774049@EXS_BDC>

> >   is there "homals" package prepared for win32?
> I presume the source code on CRAN works on all platforms, but 
> why don't you try it and see?

Why don't? -- I did. 
It works even without proper installation...

But it would be better to have properly prepared package.

kind regards,
Valery A.Khamenya
---------------------------------------------------------------------------
Bioinformatics Department
BioVisioN AG, Hannover



From ripley at stats.ox.ac.uk  Tue May 13 13:16:49 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 13 May 2003 12:16:49 +0100 (BST)
Subject: AW: [R] homals for win32?
In-Reply-To: <D15343265276D31197BC00A024A6C110774049@EXS_BDC>
Message-ID: <Pine.LNX.4.44.0305131213040.18682-100000@gannet.stats>

On Tue, 13 May 2003, Khamenia, Valery wrote:

> > >   is there "homals" package prepared for win32?
> > I presume the source code on CRAN works on all platforms, but 
> > why don't you try it and see?
> 
> Why don't? -- I did. 
> It works even without proper installation...
> 
> But it would be better to have properly prepared package.

Please re-read the rw-FAQ Q3.1 for how to `properly prepare' a package.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dnogues at ipe.csic.es  Tue May 13 14:21:48 2003
From: dnogues at ipe.csic.es (=?ISO-8859-1?Q?David_Nogu=E9s?=)
Date: Tue, 13 May 2003 14:21:48 +0200
Subject: [R] gam.plot y axes meaning
Message-ID: <3EC0E35C.8030600@ipe.csic.es>

Hello to everybody:

Im starting to work with GAM using mgcv in R. When I plot a gam object 
using gam.plot, the y axes is labelled s(cov,edf), but I dont undertand 
what means the units of  y axes (is related with the predictor variable?).

Thanks in advance

-- 
David Nogu?s Bravo

Functional Ecology and Biodiversity Department
Pyrenean Institute of Ecology
Spanish Research Council

Av. Monta?ana 1005
Zaragoza - CP 50059
976716030 - 976716019 (fax)



From brostaux.y at fsagx.ac.be  Tue May 13 14:29:52 2003
From: brostaux.y at fsagx.ac.be (Yves Brostaux)
Date: Tue, 13 May 2003 14:29:52 +0200
Subject: [R] R compilation problem on Sun Solaris 2.5.1
Message-ID: <5.1.0.14.1.20030513142038.00b2f130@fusamail.fsagx.ac.be>

Dear members,

Always the same compilation problem. I'm still stuck with my old 
Sun/UltraSparc workstation running Solaris 2.5.1 while installing R.

I downloaded and installed following required and recommanded programs 
before installing R : perl 5.8.0, readline 4.3, gzip 1.3.5, bzip 1.02, zlib 
1.1.4, make 3.80, jpeg 6b, libpng 1.2.4 and gcc 3.2.

This time, I downloaded and unpacked R-patched.tgz to /usr/src and ran
 > ./configure --prefix=/usr/local
 > make

Some time ago, during make execution, I got following error with R 1.7.0 :

initializing class and method definition now... done
Error in gzfile (file, "wb"): unable to open connection
In addition: Warning message:
cannot open compressed file 'usr/share/src/R-1.7.0/library/methods/R/all.rda'
Execution halted

Now with R patched, I get :

dumping R code in package 'methods'
initializing class and method definition now... done
make[4]: *** [../../../library/methods/R/all.rda] Bus error (core dumped)
make[4]: Leaving directory 'usr/share/src/R-patched/src/library/methods'
make[3]: *** [all] Error 2
make[3]: Leaving directory 'usr/share/src/R-patched/src/library/methods'
make[2]: *** [R] Error 1
make[2]: Leaving directory 'usr/share/src/R-patched/src/library/'
make[1]: *** [R] Error 1
make[1]: Leaving directory 'usr/share/src/R-patched/src/'
make: *** [R] Error 1

So the problem seems to be this 'all.rda' file. Anybody have any idea about 
what going on here ?

-- 
Ir. Yves Brostaux - Statistics and Computer Science Dpt.
Gembloux Agricultural University
8, avenue de la Facult? B-5030 Gembloux (Belgium)
T?l : +32 (0)81 62 24 69
E-mail : brostaux.y at fsagx.ac.be
Web : http://www.fsagx.ac.be/si/



From simon at stats.gla.ac.uk  Tue May 13 14:41:14 2003
From: simon at stats.gla.ac.uk (Simon Wood)
Date: Tue, 13 May 2003 13:41:14 +0100 (BST)
Subject: [R] gam.plot y axes meaning
In-Reply-To: <3EC0E35C.8030600@ipe.csic.es>
Message-ID: <Pine.SOL.3.96.1030513133751.25605C-100000@moon.stats.gla.ac.uk>

> Im starting to work with GAM using mgcv in R. When I plot a gam object 
> using gam.plot, the y axes is labelled s(cov,edf), but I dont undertand 
> what means the units of  y axes (is related with the predictor variable?).

- The y axes are on the scale of the linear predictor of your model. i.e.
The units are link(response units). [Note that smooths are "centred" to
ensure model identifiability - they sum to 0 over the covariate values].

best,
Simon

_____________________________________________________________________
> Simon Wood simon at stats.gla.ac.uk        www.stats.gla.ac.uk/~simon/
>>  Department of Statistics, University of Glasgow, Glasgow, G12 8QQ
>>>   Direct telephone: (0)141 330 4530          Fax: (0)141 330 4814



From tblackw at umich.edu  Tue May 13 14:51:52 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Tue, 13 May 2003 08:51:52 -0400 (EDT)
Subject: [R] gam.plot y axes meaning
In-Reply-To: <3EC0E35C.8030600@ipe.csic.es>
Message-ID: <Pine.SOL.4.44.0305130844540.29931-100000@timepilot.gpcc.itd.umich.edu>

To me, the "s( )" suggests "spline".  The relationship
between the outcome variable (dependent variable)  y
and the linear predictor will depend on what link function
is used in the fitting.  See  help("gam"), help("plot.gam").

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Tue, 13 May 2003, [ISO-8859-1] David Nogus wrote:

> Hello to everybody:
>
> Im starting to work with GAM using mgcv in R. When I plot a gam object
> using gam.plot, the y axes is labelled s(cov,edf), but I dont undertand
> what means the units of  y axes (is related with the predictor variable?).
>
> Thanks in advance
> --
> David Nogus Bravo



From ripley at stats.ox.ac.uk  Tue May 13 15:04:32 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 13 May 2003 14:04:32 +0100 (BST)
Subject: [R] R compilation problem on Sun Solaris 2.5.1
In-Reply-To: <5.1.0.14.1.20030513142038.00b2f130@fusamail.fsagx.ac.be>
Message-ID: <Pine.LNX.4.44.0305131402080.29564-100000@gannet.stats>

I think both indicate a problem with your zlib installation.  Please try 
rebuilding (from scratch) with --without-zlib (which will use R's internal 
version of zlib).

I hope you do really have 3.2 and not 3.2.1 or 3.2.2 (which don't work 
under Sparc).

On Tue, 13 May 2003, Yves Brostaux wrote:

> Dear members,
> 
> Always the same compilation problem. I'm still stuck with my old 
> Sun/UltraSparc workstation running Solaris 2.5.1 while installing R.
> 
> I downloaded and installed following required and recommanded programs 
> before installing R : perl 5.8.0, readline 4.3, gzip 1.3.5, bzip 1.02, zlib 
> 1.1.4, make 3.80, jpeg 6b, libpng 1.2.4 and gcc 3.2.
> 
> This time, I downloaded and unpacked R-patched.tgz to /usr/src and ran
>  > ./configure --prefix=/usr/local
>  > make
> 
> Some time ago, during make execution, I got following error with R 1.7.0 :
> 
> initializing class and method definition now... done
> Error in gzfile (file, "wb"): unable to open connection
> In addition: Warning message:
> cannot open compressed file 'usr/share/src/R-1.7.0/library/methods/R/all.rda'
> Execution halted
> 
> Now with R patched, I get :
> 
> dumping R code in package 'methods'
> initializing class and method definition now... done
> make[4]: *** [../../../library/methods/R/all.rda] Bus error (core dumped)
> make[4]: Leaving directory 'usr/share/src/R-patched/src/library/methods'
> make[3]: *** [all] Error 2
> make[3]: Leaving directory 'usr/share/src/R-patched/src/library/methods'
> make[2]: *** [R] Error 1
> make[2]: Leaving directory 'usr/share/src/R-patched/src/library/'
> make[1]: *** [R] Error 1
> make[1]: Leaving directory 'usr/share/src/R-patched/src/'
> make: *** [R] Error 1
> 
> So the problem seems to be this 'all.rda' file. Anybody have any idea about 
> what going on here ?
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jgentry at jimmy.harvard.edu  Tue May 13 15:29:39 2003
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Tue, 13 May 2003 09:29:39 -0400 (EDT)
Subject: [R] Delete files from R
In-Reply-To: <6A4BCEF0FD65344A8F496D7E520DD8B9023E90A7@lobster.zhwin.ch>
Message-ID: <Pine.SOL.4.20.0305130929240.28099-100000@santiam.dfci.harvard.edu>



On Tue, 13 May 2003, [iso-8859-1] "Unternhrer Thomas, uth" wrote:
> I have a file: d:\foo.txt and want to delete this.
> I tried: 
> system("del d:/foo.txt") works not
> system("notepad d:/foo.txt") works
> Is it possible that I can't delete files or do I have misunderstood something?

unlink()



From paulda at BATTELLE.ORG  Tue May 13 15:33:18 2003
From: paulda at BATTELLE.ORG (Paul, David  A)
Date: Tue, 13 May 2003 09:33:18 -0400
Subject: [R] RE: avas
Message-ID: <940250A9EB37A24CBE28D858EF077749136D5D@ws-bco-mse3.milky-way.battelle.org>

I am using R1.7/Win2k.
After installing the acepack( ) library, I noticed
what may/may not be considered a bug in avas() --

When interested in

avas.object1 <- avas(x = foo1$X1, y = foo1$Y1)
avas.object2 <- avas(x = foo2$X2, y = foo2$Y2)

if I mistype and inadvertently use (say)

avas.object1 <- avas(x = foo1$X2, y = foo1$Y1)
avas.object2 <- avas(x = foo2$X2, y = foo2$Y2)

my RGui application crashes.

FYI,
  david paul



-----Original Message-----
From: Paul, David A 
Sent: Monday, May 12, 2003 6:46 PM
To: 'r-help at stat.math.ethz.ch'
Subject: avas


Are there any equivalent function(s) in R1.70/Win2k for the avas( ) function
in Splus 6.1/Win2k?

FYI: The implementation of avas( ) in Splus uses
.Fortran( ) to call to precompiled code.
 

Much thanks,
  david paul



From wl at eimb.ru  Tue May 13 16:14:43 2003
From: wl at eimb.ru (Wladimir Eremeev)
Date: Tue, 13 May 2003 18:14:43 +0400
Subject: [R] several regression lines in panel of xyplot (trellis graphics)
Message-ID: <11760.030513@eimb.ru>

Dear r-help,

  I need to draw xyplot() graphs with several regression lines:
  one line for the whole range of x (the variable on the horizontal
  axis) and two additional lines for subranges of x.
  
  Is it possible to make first regression line (panel.lmline(x,y,...);)
  to be drawn on the whole graph
  and regression lines of the subsets to be drawn only over their subsets?

  I have defined
plot.panel=function(x,y,...){
  panel.xyplot(x,y,...);
  panel.lmline(x,y,...);
  panel.lmline(x[1:9],y[1:9],...);
  panel.lmline(x[10:23],y[10:23],...);
  panel.grid(h=-1,v=-1,...);
};

then I draw plots:
  xyplot(<blah-blah-blah>,panel=plot.panel,<...>)

  This command draws graphics, but all regression lines on them are
  drawn from the left side to the right side, i.e. over the whole x
  range...

-- 
Best regards
Wladimir Eremeev                                     mailto:wl at eimb.ru

==========================================================================
Research Scientist                                Leninsky Prospect 33,
Space Monitoring & Ecoinformation Systems Sector, Moscow, Russia, 119071,
Institute of Ecology,                             Phone: (095) 135-9972;
Russian Academy of Sciences                       Fax: (095) 954-5534



From bates at stat.wisc.edu  Tue May 13 16:39:33 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 13 May 2003 14:39:33 -0000
Subject: [R] several regression lines in panel of xyplot (trellis graphics)
In-Reply-To: <11760.030513@eimb.ru>
References: <11760.030513@eimb.ru>
Message-ID: <6rptmm9ahz.fsf@bates4.stat.wisc.edu>

Wladimir Eremeev <wl at eimb.ru> writes:

> Dear r-help,
> 
>   I need to draw xyplot() graphs with several regression lines:
>   one line for the whole range of x (the variable on the horizontal
>   axis) and two additional lines for subranges of x.
>   
>   Is it possible to make first regression line (panel.lmline(x,y,...);)
>   to be drawn on the whole graph
>   and regression lines of the subsets to be drawn only over their subsets?
> 
>   I have defined
> plot.panel=function(x,y,...){
>   panel.xyplot(x,y,...);
>   panel.lmline(x,y,...);
>   panel.lmline(x[1:9],y[1:9],...);
>   panel.lmline(x[10:23],y[10:23],...);
>   panel.grid(h=-1,v=-1,...);
> };
> 
> then I draw plots:
>   xyplot(<blah-blah-blah>,panel=plot.panel,<...>)
> 
>   This command draws graphics, but all regression lines on them are
>   drawn from the left side to the right side, i.e. over the whole x
>   range...

I think you will need to do the linear model fits to the data subsets
within the panel function then use panel.segments to add the lines.



From brostaux.y at fsagx.ac.be  Tue May 13 16:56:58 2003
From: brostaux.y at fsagx.ac.be (Yves Brostaux)
Date: Tue, 13 May 2003 16:56:58 +0200
Subject: [R] R compilation problem on Sun Solaris 2.5.1
In-Reply-To: <Pine.LNX.4.44.0305131402080.29564-100000@gannet.stats>
References: <5.1.0.14.1.20030513142038.00b2f130@fusamail.fsagx.ac.be>
Message-ID: <5.1.0.14.1.20030513165354.00b06b70@fusamail.fsagx.ac.be>

It finally worked !!! Thank you very much for your advice.

PS : I'm using gcc 3.2, even if I heard about a new working 3.2.3 version, 
I didn't wanted to spend too much time updating this one for unknown benefits.

At 15:04 13/05/03, you wrote:
>I think both indicate a problem with your zlib installation.  Please try
>rebuilding (from scratch) with --without-zlib (which will use R's internal
>version of zlib).
>
>I hope you do really have 3.2 and not 3.2.1 or 3.2.2 (which don't work
>under Sparc).
>
>On Tue, 13 May 2003, Yves Brostaux wrote:
>
> > Dear members,
> >
> > Always the same compilation problem. I'm still stuck with my old
> > Sun/UltraSparc workstation running Solaris 2.5.1 while installing R.
> >
> > I downloaded and installed following required and recommanded programs
> > before installing R : perl 5.8.0, readline 4.3, gzip 1.3.5, bzip 1.02, 
> zlib
> > 1.1.4, make 3.80, jpeg 6b, libpng 1.2.4 and gcc 3.2.
> >
> > This time, I downloaded and unpacked R-patched.tgz to /usr/src and ran
> >  > ./configure --prefix=/usr/local
> >  > make
> >
> > Some time ago, during make execution, I got following error with R 1.7.0 :
> >
> > initializing class and method definition now... done
> > Error in gzfile (file, "wb"): unable to open connection
> > In addition: Warning message:
> > cannot open compressed file 
> 'usr/share/src/R-1.7.0/library/methods/R/all.rda'
> > Execution halted
> >
> > Now with R patched, I get :
> >
> > dumping R code in package 'methods'
> > initializing class and method definition now... done
> > make[4]: *** [../../../library/methods/R/all.rda] Bus error (core dumped)
> > make[4]: Leaving directory 'usr/share/src/R-patched/src/library/methods'
> > make[3]: *** [all] Error 2
> > make[3]: Leaving directory 'usr/share/src/R-patched/src/library/methods'
> > make[2]: *** [R] Error 1
> > make[2]: Leaving directory 'usr/share/src/R-patched/src/library/'
> > make[1]: *** [R] Error 1
> > make[1]: Leaving directory 'usr/share/src/R-patched/src/'
> > make: *** [R] Error 1
> >
> > So the problem seems to be this 'all.rda' file. Anybody have any idea 
> about
> > what going on here ?
> >
> >
>
>--
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From wl at eimb.ru  Tue May 13 17:14:52 2003
From: wl at eimb.ru (Wladimir Eremeev)
Date: Tue, 13 May 2003 19:14:52 +0400
Subject: [R] Re[2]:  unfortunately, no such function, panel.segments
In-Reply-To: <6rptmm9ahz.fsf@bates4.stat.wisc.edu>
References: <6rptmm9ahz.fsf@bates4.stat.wisc.edu>
Message-ID: <11801.030513@eimb.ru>

Dear Douglas,

>> plot.panel=function(x,y,...){
>>   panel.xyplot(x,y,...);
>>   panel.lmline(x,y,...);
>>   panel.lmline(x[1:9],y[1:9],...);
>>   panel.lmline(x[10:23],y[10:23],...);
>>   panel.grid(h=-1,v=-1,...);
>> };
>> 
>> then I draw plots:
>>   xyplot(<blah-blah-blah>,panel=plot.panel,<...>)
>> 
>>   This command draws graphics, but all regression lines on them are
>>   drawn from the left side to the right side, i.e. over the whole x
>>   range...

DB> I think you will need to do the linear model fits to the data subsets
DB> within the panel function then use panel.segments to add the lines.

But I've found lsegments, llines, and others.
Will study. :) Thank you!


-- 
Best regards
Wladimir Eremeev                                     mailto:wl at eimb.ru

==========================================================================
Research Scientist                                Leninsky Prospect 33,
Space Monitoring & Ecoinformation Systems Sector, Moscow, Russia, 119071,
Institute of Ecology,                             Phone: (095) 135-9972;
Russian Academy of Sciences                       Fax: (095) 954-5534



From f.calboli at ucl.ac.uk  Tue May 13 17:17:11 2003
From: f.calboli at ucl.ac.uk (Federico Calboli)
Date: Tue, 13 May 2003 16:17:11 +0100
Subject: [R] assessing the fit of a LME model
Message-ID: <3.0.6.32.20030513161711.02b957b8@pop-server.ucl.ac.uk>

Dear All,

I would like to ask a couple of questions on a LME model.

I tested 4 selection lines at 4 food concentrations against a standard
competitor stock. I had 3 replicate cages per selection line. In each cage
I have 10 vials. I counted the number of wild type flies and competitor
stock emerging in each vial. My main question is: is there any difference
between selection lines?

I did fit the following model:

mod1<-lme(wt~selection*food, random=~1|c1/food, competition)

The quantile plot is straight, the plot of residuals looks good, the
standardized residual plot seems ok... BUT if I do a bartlett test for
homogeneity of variance (done by cage*temperature, 48 cages in all) the
variance is NOT homogeneous. Is my model still accettable? if not, what
could I do?

The same model on asin(sqrt(wild type/total)) does not fit anywhere as well.

my dataset (NB *wt* is the number of wild type flies in each vial; *spa* is
the number of comepetitor stock flies in each vial, *p1* is
asin(sqrt(competition$prop)), *c1* is the cage nested in selection using
getGroups...):

    selection cage food wt spa tot       prop        p1   c1
1          25    1  100 21  22  43 0.48837209 0.7737692 25/1
2          25    1  100 21  22  43 0.48837209 0.7737692 25/1
3          25    1  100  5   5  10 0.50000000 0.7853982 25/1
4          25    1  100 21  17  38 0.55263158 0.8381274 25/1
5          25    1  100 13  22  35 0.37142857 0.6553659 25/1
6          25    1  100 24  18  42 0.57142857 0.8570719 25/1
7          25    1  100 22  19  41 0.53658537 0.8220163 25/1
8          25    1  100 15  23  38 0.39473684 0.6793415 25/1
9          25    1  100 19  19  38 0.50000000 0.7853982 25/1
10         25    1  100 18  19  37 0.48648649 0.7718830 25/1
11         25    2  100 21  22  43 0.48837209 0.7737692 25/2
12         25    2  100 24  18  42 0.57142857 0.8570719 25/2
13         25    2  100  9  21  30 0.30000000 0.5796397 25/2
14         25    2  100  2  13  15 0.13333333 0.3737922 25/2
15         25    2  100 10  11  21 0.47619048 0.7615796 25/2
16         25    2  100 26  20  46 0.56521739 0.8508019 25/2
17         25    2  100 11  17  28 0.39285714 0.6774179 25/2
18         25    2  100  9  22  31 0.29032258 0.5690309 25/2
19         25    2  100 15  22  37 0.40540541 0.6902300 25/2
20         25    2  100 19  24  43 0.44186047 0.7271268 25/2
21         25    3  100 22  23  45 0.48888889 0.7742861 25/3
22         25    3  100 13  22  35 0.37142857 0.6553659 25/3
23         25    3  100 18  21  39 0.46153846 0.7468986 25/3
24         25    3  100 12  20  32 0.37500000 0.6590580 25/3
25         25    3  100 17  20  37 0.45945946 0.7448131 25/3
26         25    3  100 15  26  41 0.36585366 0.6495880 25/3
27         25    3  100 19   0  19 1.00000000 1.5707963 25/3
28         25    3  100 25  23  48 0.52083333 0.8062375 25/3
29         25    3  100 15  19  34 0.44117647 0.7264381 25/3
30         25    3  100 12  21  33 0.36363636 0.6472848 25/3
31         18    1  100 30  23  53 0.56603774 0.8516294 18/1
32         18    1  100 18  22  40 0.45000000 0.7353145 18/1
33         18    1  100 20  26  46 0.43478261 0.7199944 18/1
34         18    1  100 21  16  37 0.56756757 0.8531731 18/1
35         18    1  100 17  14  31 0.54838710 0.8338611 18/1
36         18    1  100 26  21  47 0.55319149 0.8386905 18/1
37         18    1  100 19  23  42 0.45238095 0.7377068 18/1
38         18    1  100 24  19  43 0.55813953 0.8436695 18/1
39         18    1  100 25  21  46 0.54347826 0.8289314 18/1
40         18    1  100 14  20  34 0.41176471 0.6966984 18/1
41         18    2  100 18  16  34 0.52941176 0.8148269 18/2
42         18    2  100 23  19  42 0.54761905 0.8330895 18/2
43         18    2  100 19  20  39 0.48717949 0.7725762 18/2
44         18    2  100 25  20  45 0.55555556 0.8410687 18/2
45         18    2  100 19  21  40 0.47500000 0.7603877 18/2
46         18    2  100 20  23  43 0.46511628 0.7504861 18/2
47         18    2  100 23  24  47 0.48936170 0.7747591 18/2
48         18    2  100 22  20  42 0.52380952 0.8092167 18/2
49         18    2  100 25  19  44 0.56818182 0.8537931 18/2
50         18    2  100 19  26  45 0.42222222 0.7073032 18/2
51         18    3  100 21  20  41 0.51219512 0.7975945 18/3
52         18    3  100 22  24  46 0.47826087 0.7636522 18/3
53         18    3  100 19  26  45 0.42222222 0.7073032 18/3
54         18    3  100 17  22  39 0.43589744 0.7211187 18/3
55         18    3  100 22  23  45 0.48888889 0.7742861 18/3
56         18    3  100 20  25  45 0.44444444 0.7297277 18/3
57         18    3  100 25  23  48 0.52083333 0.8062375 18/3
58         18    3  100 24  21  45 0.53333333 0.8187562 18/3
59         18    3  100 23  25  48 0.47916667 0.7645588 18/3
60         18    3  100 25  22  47 0.53191489 0.8173348 18/3
61          s    1  100 22  23  45 0.48888889 0.7742861  s/1
62          s    1  100 25  18  43 0.58139535 0.8671574  s/1
63          s    1  100 19  20  39 0.48717949 0.7725762  s/1
64          s    1  100 22  19  41 0.53658537 0.8220163  s/1
65          s    1  100 18  18  36 0.50000000 0.7853982  s/1
66          s    1  100 23  18  41 0.56097561 0.8465259  s/1
67          s    1  100 23  20  43 0.53488372 0.8203102  s/1
68          s    1  100 24  21  45 0.53333333 0.8187562  s/1
69          s    1  100 21  18  39 0.53846154 0.8238977  s/1
70          s    1  100 25  22  47 0.53191489 0.8173348  s/1
71          s    2  100 20  24  44 0.45454545 0.7398808  s/2
72          s    2  100 18  19  37 0.48648649 0.7718830  s/2
73          s    2  100 20  18  38 0.52631579 0.8117261  s/2
74          s    2  100 19  11  30 0.63333333 0.9203646  s/2
75          s    2  100 20  23  43 0.46511628 0.7504861  s/2
76          s    2  100 23  22  45 0.51111111 0.7965102  s/2
77          s    2  100 23  24  47 0.48936170 0.7747591  s/2
78          s    2  100 24  18  42 0.57142857 0.8570719  s/2
79          s    2  100 20  17  37 0.54054054 0.8259833  s/2
80          s    2  100 23  20  43 0.53488372 0.8203102  s/2
81          s    3  100 19  21  40 0.47500000 0.7603877  s/3
82          s    3  100 17  18  35 0.48571429 0.7711105  s/3
83          s    3  100 10  19  29 0.34482759 0.6276203  s/3
84          s    3  100 17  21  38 0.44736842 0.7326689  s/3
85          s    3  100 20  22  42 0.47619048 0.7615796  s/3
86          s    3  100  8  17  25 0.32000000 0.6012642  s/3
87          s    3  100 21  12  33 0.63636364 0.9235115  s/3
88          s    3  100 17  22  39 0.43589744 0.7211187  s/3
89          s    3  100 18  21  39 0.46153846 0.7468986  s/3
90          s    3  100 21  22  43 0.48837209 0.7737692  s/3
91          l    1  100 21  20  41 0.51219512 0.7975945  l/1
92          l    1  100 21  20  41 0.51219512 0.7975945  l/1
93          l    1  100 15  18  33 0.45454545 0.7398808  l/1
94          l    1  100  4   8  12 0.33333333 0.6154797  l/1
95          l    1  100 11  10  21 0.52380952 0.8092167  l/1
96          l    1  100  5  18  23 0.21739130 0.4850498  l/1
97          l    1  100  9  18  27 0.33333333 0.6154797  l/1
98          l    1  100  6  18  24 0.25000000 0.5235988  l/1
99          l    1  100 14   1  15 0.93333333 1.3096389  l/1
100         l    1  100 15  26  41 0.36585366 0.6495880  l/1
101         l    2  100 21  20  41 0.51219512 0.7975945  l/2
102         l    2  100 21  21  42 0.50000000 0.7853982  l/2
103         l    2  100  8  12  20 0.40000000 0.6847192  l/2
104         l    2  100 14   9  23 0.60869565 0.8949687  l/2
105         l    2  100 14  12  26 0.53846154 0.8238977  l/2
106         l    2  100 27  23  50 0.54000000 0.8254410  l/2
107         l    2  100  7  16  23 0.30434783 0.5843739  l/2
108         l    2  100 13  23  36 0.36111111 0.6446581  l/2
109         l    2  100 24  25  49 0.48979592 0.7751934  l/2
110         l    2  100 26  24  50 0.52000000 0.8054035  l/2
111         l    3  100 23  22  45 0.51111111 0.7965102  l/3
112         l    3  100 23  25  48 0.47916667 0.7645588  l/3
113         l    3  100 21  23  44 0.47727273 0.7626631  l/3
114         l    3  100 26  21  47 0.55319149 0.8386905  l/3
115         l    3  100 22  16  38 0.57894737 0.8646773  l/3
116         l    3  100 22  22  44 0.50000000 0.7853982  l/3
117         l    3  100 25  20  45 0.55555556 0.8410687  l/3
118         l    3  100 29  26  55 0.52727273 0.8126844  l/3
119         l    3  100 26  20  46 0.56521739 0.8508019  l/3
120         l    3  100 24  22  46 0.52173913 0.8071441  l/3
121        25    1   50 20  18  38 0.52631579 0.8117261 25/1
122        25    1   50 19  19  38 0.50000000 0.7853982 25/1
123        25    1   50 16  23  39 0.41025641 0.6951656 25/1
124        25    1   50 20  25  45 0.44444444 0.7297277 25/1
125        25    1   50 17  23  40 0.42500000 0.7101140 25/1
126        25    1   50 20  20  40 0.50000000 0.7853982 25/1
127        25    1   50 19  21  40 0.47500000 0.7603877 25/1
128        25    1   50 21  26  47 0.44680851 0.7321058 25/1
129        25    1   50 18  20  38 0.47368421 0.7590702 25/1
130        25    1   50  8  22  30 0.26666667 0.5426391 25/1
131        25    2   50 17  24  41 0.41463415 0.6996120 25/2
132        25    2   50  3  19  22 0.13636364 0.3782282 25/2
133        25    2   50  8  14  22 0.36363636 0.6472848 25/2
134        25    2   50 19  22  41 0.46341463 0.7487801 25/2
135        25    2   50  3  24  27 0.11111111 0.3398369 25/2
136        25    2   50 15  22  37 0.40540541 0.6902300 25/2
137        25    2   50  2   9  11 0.18181818 0.4405107 25/2
138        25    2   50 16  19  35 0.45714286 0.7424884 25/2
139        25    2   50  1  23  24 0.04166667 0.2055689 25/2
140        25    2   50 18  16  34 0.52941176 0.8148269 25/2
141        25    3   50  0  17  17 0.00000000 0.0000000 25/3
142        25    3   50  6  20  26 0.23076923 0.5010930 25/3
143        25    3   50 12  25  37 0.32432432 0.6058911 25/3
144        25    3   50 12  21  33 0.36363636 0.6472848 25/3
145        25    3   50 13  22 145 0.84827586 1.1706883 25/3
146        25    3   50 14  22  36 0.38888889 0.6733516 25/3
147        25    3   50 17  25  42 0.40476190 0.6895746 25/3
148        25    3   50 15  23  38 0.39473684 0.6793415 25/3
149        25    3   50 14  25  39 0.35897436 0.6424324 25/3
150        25    3   50 23  24  47 0.48936170 0.7747591 25/3
151        18    1   50  9  21  30 0.30000000 0.5796397 18/1
152        18    1   50 18  19  37 0.48648649 0.7718830 18/1
153        18    1   50 15  25  40 0.37500000 0.6590580 18/1
154        18    1   50 25  23  48 0.52083333 0.8062375 18/1
155        18    1   50 19  22  41 0.46341463 0.7487801 18/1
156        18    1   50 18  25  43 0.41860465 0.7036390 18/1
157        18    1   50 18  21  39 0.46153846 0.7468986 18/1
158        18    1   50 20  21  41 0.48780488 0.7732018 18/1
159        18    1   50  8  22  30 0.26666667 0.5426391 18/1
160        18    1   50 14  25  39 0.35897436 0.6424324 18/1
161        18    2   50 11  21  32 0.34375000 0.6264863 18/2
162        18    2   50 22  21  43 0.51162791 0.7970271 18/2
163        18    2   50  4  16  20 0.20000000 0.4636476 18/2
164        18    2   50 20  23  43 0.46511628 0.7504861 18/2
165        18    2   50 21  22  43 0.48837209 0.7737692 18/2
166        18    2   50 18  20  38 0.47368421 0.7590702 18/2
167        18    2   50  9  17  26 0.34615385 0.6290148 18/2
168        18    2   50 20  24  44 0.45454545 0.7398808 18/2
169        18    2   50 13  20  33 0.39393939 0.6785256 18/2
170        18    2   50 20  21  41 0.48780488 0.7732018 18/2
171        18    3   50  6  14  20 0.30000000 0.5796397 18/3
172        18    3   50 19  25  44 0.43181818 0.7170032 18/3
173        18    3   50  7  21  28 0.25000000 0.5235988 18/3
174        18    3   50 19  24  43 0.44186047 0.7271268 18/3
175        18    3   50 21  23  44 0.47727273 0.7626631 18/3
176        18    3   50 16  20  36 0.44444444 0.7297277 18/3
177        18    3   50 23  26  49 0.46938776 0.7547668 18/3
178        18    3   50 22  20  42 0.52380952 0.8092167 18/3
179        18    3   50 13  20  33 0.39393939 0.6785256 18/3
180        18    3   50 18  24  42 0.42857143 0.7137244 18/3
181         s    1   50 14  21  35 0.40000000 0.6847192  s/1
182         s    1   50 16  21  37 0.43243243 0.7176232  s/1
183         s    1   50 18  18  36 0.50000000 0.7853982  s/1
184         s    1   50 12  16  28 0.42857143 0.7137244  s/1
185         s    1   50 15  17  32 0.46875000 0.7541278  s/1
186         s    1   50 17  22  39 0.43589744 0.7211187  s/1
187         s    1   50  3  20  23 0.13043478 0.3695089  s/1
188         s    1   50 18  20  38 0.47368421 0.7590702  s/1
189         s    1   50 18  23  41 0.43902439 0.7242704  s/1
190         s    1   50  9  19  28 0.32142857 0.6027946  s/1
191         s    2   50 16  24  40 0.40000000 0.6847192  s/2
192         s    2   50 20  22  42 0.47619048 0.7615796  s/2
193         s    2   50 18  20  38 0.47368421 0.7590702  s/2
194         s    2   50 22  22  44 0.50000000 0.7853982  s/2
195         s    2   50 19  23  42 0.45238095 0.7377068  s/2
196         s    2   50 13  15  28 0.46428571 0.7496534  s/2
197         s    2   50 13  15  28 0.46428571 0.7496534  s/2
198         s    2   50 18  20  38 0.47368421 0.7590702  s/2
199         s    2   50 12  26  38 0.31578947 0.5967431  s/2
200         s    2   50  7  21  28 0.25000000 0.5235988  s/2
201         s    3   50 13  22  35 0.37142857 0.6553659  s/3
202         s    3   50 16  21  37 0.43243243 0.7176232  s/3
203         s    3   50 12  17  29 0.41379310 0.6987583  s/3
204         s    3   50 17  10  27 0.62962963 0.9165257  s/3
205         s    3   50  7  18  25 0.28000000 0.5575988  s/3
206         s    3   50  7   9  16 0.43750000 0.7227342  s/3
207         s    3   50  8  20  28 0.28571429 0.5639426  s/3
208         s    3   50  5  15  20 0.25000000 0.5235988  s/3
209         s    3   50  9  20  29 0.31034483 0.5908728  s/3
210         s    3   50  6  15  21 0.28571429 0.5639426  s/3
211         l    1   50  4  18  22 0.18181818 0.4405107  l/1
212         l    1   50  7  16  23 0.30434783 0.5843739  l/1
213         l    1   50  4  20  24 0.16666667 0.4205343  l/1
214         l    1   50 21  24  45 0.46666667 0.7520401  l/1
215         l    1   50  7  24  31 0.22580645 0.4951811  l/1
216         l    1   50  9  19  28 0.32142857 0.6027946  l/1
217         l    1   50  2  13  15 0.13333333 0.3737922  l/1
218         l    1   50  5  24  29 0.17241379 0.4281928  l/1
219         l    1   50 23  21  44 0.52272727 0.8081333  l/1
220         l    1   50 16  19  35 0.45714286 0.7424884  l/1
221         l    2   50 20  16  36 0.55555556 0.8410687  l/2
222         l    2   50 12   8  20 0.60000000 0.8860771  l/2
223         l    2   50 15  23  38 0.39473684 0.6793415  l/2
224         l    2   50  3  18  21 0.14285714 0.3875967  l/2
225         l    2   50  8  16  24 0.33333333 0.6154797  l/2
226         l    2   50  9  19  28 0.32142857 0.6027946  l/2
227         l    2   50 22  22  44 0.50000000 0.7853982  l/2
228         l    2   50  9  10  19 0.47368421 0.7590702  l/2
229         l    2   50 13  23  36 0.36111111 0.6446581  l/2
230         l    2   50 15  20  35 0.42857143 0.7137244  l/2
231         l    3   50 20  21  41 0.48780488 0.7732018  l/3
232         l    3   50  9  18  27 0.33333333 0.6154797  l/3
233         l    3   50 18  18  36 0.50000000 0.7853982  l/3
234         l    3   50  9  16  25 0.36000000 0.6435011  l/3
235         l    3   50 22  26  48 0.45833333 0.7436831  l/3
236         l    3   50 21  17  38 0.55263158 0.8381274  l/3
237         l    3   50 19  23  42 0.45238095 0.7377068  l/3
238         l    3   50 19  20  39 0.48717949 0.7725762  l/3
239         l    3   50 18  21  39 0.46153846 0.7468986  l/3
240         l    3   50 21  22  43 0.48837209 0.7737692  l/3
241        25    1   25 19  23  42 0.45238095 0.7377068 25/1
242        25    1   25  0   7   7 0.00000000 0.0000000 25/1
243        25    1   25 14   9  23 0.60869565 0.8949687 25/1
244        25    1   25  0  14  14 0.00000000 0.0000000 25/1
245        25    1   25 14  22  36 0.38888889 0.6733516 25/1
246        25    1   25  0   3   3 0.00000000 0.0000000 25/1
247        25    1   25 15  23  38 0.39473684 0.6793415 25/1
248        25    1   25 14  20  34 0.41176471 0.6966984 25/1
249        25    1   25  7  13  20 0.35000000 0.6330518 25/1
250        25    1   25 15  20  35 0.42857143 0.7137244 25/1
251        25    2   25  0   9   9 0.00000000 0.0000000 25/2
252        25    2   25 16  23  39 0.41025641 0.6951656 25/2
253        25    2   25 15  25  40 0.37500000 0.6590580 25/2
254        25    2   25 17  19  36 0.47222222 0.7576061 25/2
255        25    2   25  1  10  11 0.09090909 0.3062774 25/2
256        25    2   25  2  20  22 0.09090909 0.3062774 25/2
257        25    2   25  7  15  22 0.31818182 0.5993139 25/2
258        25    2   25  1  18  19 0.05263158 0.2314774 25/2
259        25    2   25  3  22  25 0.12000000 0.3537416 25/2
260        25    2   25  9  21  30 0.30000000 0.5796397 25/2
261        25    3   25  2  23  25 0.08000000 0.2867566 25/3
262        25    3   25  1  19  20 0.05000000 0.2255134 25/3
263        25    3   25  8  21  29 0.27586207 0.5529804 25/3
264        25    3   25 10  20  30 0.33333333 0.6154797 25/3
265        25    3   25  6   6  12 0.50000000 0.7853982 25/3
266        25    3   25  0  15  15 0.00000000 0.0000000 25/3
267        25    3   25  1  17  18 0.05555556 0.2379411 25/3
268        25    3   25  3  24  27 0.11111111 0.3398369 25/3
269        25    3   25  7  19  26 0.26923077 0.5455338 25/3
270        25    3   25  4  22  26 0.15384615 0.4030571 25/3
271        18    1   25  6  18  24 0.25000000 0.5235988 18/1
272        18    1   25  0  14  14 0.00000000 0.0000000 18/1
273        18    1   25  7  19  26 0.26923077 0.5455338 18/1
274        18    1   25  5  22  27 0.18518519 0.4448600 18/1
275        18    1   25  3  10  13 0.23076923 0.5010930 18/1
276        18    1   25 14  24  38 0.36842105 0.6522512 18/1
277        18    1   25 12  21  33 0.36363636 0.6472848 18/1
278        18    1   25  0  23  23 0.00000000 0.0000000 18/1
279        18    1   25 14  17  31 0.45161290 0.7369352 18/1
280        18    1   25  2  12  14 0.14285714 0.3875967 18/1
281        18    2   25  8  19  27 0.29629630 0.5755915 18/2
282        18    2   25 12  20  32 0.37500000 0.6590580 18/2
283        18    2   25 10  18  28 0.35714286 0.6405223 18/2
284        18    2   25  0   6   6 0.00000000 0.0000000 18/2
285        18    2   25  8  16  24 0.33333333 0.6154797 18/2
286        18    2   25  8  21  29 0.27586207 0.5529804 18/2
287        18    2   25  2  18  20 0.10000000 0.3217506 18/2
288        18    2   25  5  17  22 0.22727273 0.4969325 18/2
289        18    2   25  3  20  23 0.13043478 0.3695089 18/2
290        18    2   25  7  17  24 0.29166667 0.5705104 18/2
291        18    3   25 11  20  31 0.35483871 0.6381162 18/3
292        18    3   25  8  19  27 0.29629630 0.5755915 18/3
293        18    3   25  6  14  20 0.30000000 0.5796397 18/3
294        18    3   25 19  19  38 0.50000000 0.7853982 18/3
295        18    3   25  8  21  29 0.27586207 0.5529804 18/3
296        18    3   25  3  21  24 0.12500000 0.3613671 18/3
297        18    3   25  4  22  26 0.15384615 0.4030571 18/3
298        18    3   25  5  18  23 0.21739130 0.4850498 18/3
299        18    3   25  6  17  23 0.26086957 0.5360615 18/3
300        18    3   25 19  22  41 0.46341463 0.7487801 18/3
301         s    1   25  9  19  28 0.32142857 0.6027946  s/1
302         s    1   25  2  17  19 0.10526316 0.3304226  s/1
303         s    1   25  9  22  31 0.29032258 0.5690309  s/1
304         s    1   25  9  19  28 0.32142857 0.6027946  s/1
305         s    1   25 12  19  31 0.38709677 0.6715128  s/1
306         s    1   25  5  19  24 0.20833333 0.4739849  s/1
307         s    1   25  2  15  17 0.11764706 0.3501058  s/1
308         s    1   25 12  22  34 0.35294118 0.6361321  s/1
309         s    1   25  0   8   8 0.00000000 0.0000000  s/1
310         s    1   25 15  23  38 0.39473684 0.6793415  s/1
311         s    2   25  9  15  24 0.37500000 0.6590580  s/2
312         s    2   25 17  19  36 0.47222222 0.7576061  s/2
313         s    2   25 17  17  34 0.50000000 0.7853982  s/2
314         s    2   25 12  16  28 0.42857143 0.7137244  s/2
315         s    2   25  6  21  27 0.22222222 0.4908827  s/2
316         s    2   25 13  27  40 0.32500000 0.6066126  s/2
317         s    2   25  7  16  23 0.30434783 0.5843739  s/2
318         s    2   25  0   9   9 0.00000000 0.0000000  s/2
319         s    2   25 11  18  29 0.37931034 0.6635047  s/2
320         s    2   25  5  19  24 0.20833333 0.4739849  s/2
321         s    3   25 11  18  29 0.37931034 0.6635047  s/3
322         s    3   25 12  16  28 0.42857143 0.7137244  s/3
323         s    3   25  2  15  17 0.11764706 0.3501058  s/3
324         s    3   25 12  16  28 0.42857143 0.7137244  s/3
325         s    3   25 13  20  33 0.39393939 0.6785256  s/3
326         s    3   25  9  23  32 0.28125000 0.5589899  s/3
327         s    3   25  2  18  20 0.10000000 0.3217506  s/3
328         s    3   25  0  11  11 0.00000000 0.0000000  s/3
329         s    3   25  1   5   6 0.16666667 0.4205343  s/3
330         s    3   25  6  19  25 0.24000000 0.5119727  s/3
331         l    1   25  1  16  17 0.05882353 0.2449787  l/1
332         l    1   25 16  17  33 0.48484848 0.7702443  l/1
333         l    1   25  1  14  15 0.06666667 0.2611574  l/1
334         l    1   25  4  21  25 0.16000000 0.4115168  l/1
335         l    1   25  5  20  25 0.20000000 0.4636476  l/1
336         l    1   25  4  20  24 0.16666667 0.4205343  l/1
337         l    1   25  4  14  18 0.22222222 0.4908827  l/1
338         l    1   25  1  15  16 0.06250000 0.2526803  l/1
339         l    1   25 12  22  34 0.35294118 0.6361321  l/1
340         l    1   25  4  20  24 0.16666667 0.4205343  l/1
341         l    2   25 19  24  43 0.44186047 0.7271268  l/2
342         l    2   25  4  22  26 0.15384615 0.4030571  l/2
343         l    2   25  3  18  21 0.14285714 0.3875967  l/2
344         l    2   25  1  17  18 0.05555556 0.2379411  l/2
345         l    2   25  1  16  17 0.05882353 0.2449787  l/2
346         l    2   25 19  20  39 0.48717949 0.7725762  l/2
347         l    2   25  0  16  16 0.00000000 0.0000000  l/2
348         l    2   25  1  10  11 0.09090909 0.3062774  l/2
349         l    2   25  0   4   4 0.00000000 0.0000000  l/2
350         l    2   25  8  19  27 0.29629630 0.5755915  l/2
351         l    3   25 11  16  27 0.40740741 0.6922680  l/3
352         l    3   25 10  15  25 0.40000000 0.6847192  l/3
353         l    3   25  6  12  18 0.33333333 0.6154797  l/3
354         l    3   25 16  18  34 0.47058824 0.7559694  l/3
355         l    3   25 14  21  35 0.40000000 0.6847192  l/3
356         l    3   25 14  20  34 0.41176471 0.6966984  l/3
357         l    3   25 18  21  39 0.46153846 0.7468986  l/3
358         l    3   25  4   8  12 0.33333333 0.6154797  l/3
359         l    3   25  7  18  25 0.28000000 0.5575988  l/3
360         l    3   25  9  19  28 0.32142857 0.6027946  l/3
361        25    1   10  3  16  19 0.15789474 0.4086379 25/1
362        25    1   10  7  11  18 0.38888889 0.6733516 25/1
363        25    1   10  4   0   4 1.00000000 1.5707963 25/1
364        25    1   10  0   5   5 0.00000000 0.0000000 25/1
365        25    1   10  4   4   8 0.50000000 0.7853982 25/1
366        25    1   10  3   1   4 0.75000000 1.0471976 25/1
367        25    1   10 10  12  22 0.45454545 0.7398808 25/1
368        25    1   10  3   0   3 1.00000000 1.5707963 25/1
369        25    1   10  9  14  23 0.39130435 0.6758276 25/1
370        25    1   10  5   6  11 0.45454545 0.7398808 25/1
371        25    2   10  0   2   2 0.00000000 0.0000000 25/2
372        25    2   10  2  13  15 0.13333333 0.3737922 25/2
373        25    2   10  4  16  20 0.20000000 0.4636476 25/2
374        25    2   10  9  11  20 0.45000000 0.7353145 25/2
375        25    2   10  0   4   4 0.00000000 0.0000000 25/2
376        25    2   10  1  20  21 0.04761905 0.2199880 25/2
377        25    2   10  8   7  15 0.53333333 0.8187562 25/2
378        25    2   10  2  17  19 0.10526316 0.3304226 25/2
379        25    2   10  0  14  14 0.00000000 0.0000000 25/2
380        25    2   10  8  12  20 0.40000000 0.6847192 25/2
381        25    3   10  0   6   6 0.00000000 0.0000000 25/3
382        25    3   10  3   8  11 0.27272727 0.5494672 25/3
383        25    3   10  2   6   8 0.25000000 0.5235988 25/3
384        25    3   10  3  17  20 0.15000000 0.3976994 25/3
385        25    3   10  7   5  12 0.58333333 0.8691222 25/3
386        25    3   10  9  15  24 0.37500000 0.6590580 25/3
387        25    3   10  4  19  23 0.17391304 0.4301739 25/3
388        25    3   10  4  20  24 0.16666667 0.4205343 25/3
389        18    1   10  5   7  12 0.41666667 0.7016741 18/1
390        18    1   10  4  17  21 0.19047619 0.4516334 18/1
391        18    1   10  1   6   7 0.14285714 0.3875967 18/1
392        18    1   10  9  22  31 0.29032258 0.5690309 18/1
393        18    1   10  1  11  12 0.08333333 0.2928428 18/1
394        18    1   10  5  16  21 0.23809524 0.5097397 18/1
395        18    1   10  9  20  29 0.31034483 0.5908728 18/1
396        18    1   10  6  21  27 0.22222222 0.4908827 18/1
397        18    1   10  2   8  10 0.20000000 0.4636476 18/1
398        18    1   10  1   5   6 0.16666667 0.4205343 18/1
399        18    2   10  0   3   3 0.00000000 0.0000000 18/2
400        18    2   10  4  19  23 0.17391304 0.4301739 18/2
401        18    2   10  8  18  26 0.30769231 0.5880026 18/2
402        18    2   10  8  16  24 0.33333333 0.6154797 18/2
403        18    2   10  3   3   6 0.50000000 0.7853982 18/2
404        18    2   10  8  13  21 0.38095238 0.6651961 18/2
405        18    2   10  0  15  15 0.00000000 0.0000000 18/2
406        18    2   10  9  11  20 0.45000000 0.7353145 18/2
407        18    2   10  2  13  15 0.13333333 0.3737922 18/2
408        18    3   10  1  13  14 0.07142857 0.2705498 18/3
409        18    3   10  2   3   5 0.40000000 0.6847192 18/3
410        18    3   10 12  22  34 0.35294118 0.6361321 18/3
411        18    3   10  5  23  28 0.17857143 0.4362869 18/3
412        18    3   10  4   7  11 0.36363636 0.6472848 18/3
413        18    3   10  5  11  16 0.31250000 0.5931998 18/3
414        18    3   10 11  17  28 0.39285714 0.6774179 18/3
415        18    3   10  7  12  19 0.36842105 0.6522512 18/3
416        18    3   10  6   7  13 0.46153846 0.7468986 18/3
417        18    3   10  4  16  20 0.20000000 0.4636476 18/3
418         s    1   10  0  14  14 0.00000000 0.0000000  s/1
419         s    1   10  2   9  11 0.18181818 0.4405107  s/1
420         s    1   10 10  14  24 0.41666667 0.7016741  s/1
421         s    1   10  8  22  30 0.26666667 0.5426391  s/1
422         s    1   10  5  24  29 0.17241379 0.4281928  s/1
423         s    1   10  6  18  24 0.25000000 0.5235988  s/1
424         s    1   10  4   4   8 0.50000000 0.7853982  s/1
425         s    1   10  6  21  27 0.22222222 0.4908827  s/1
426         s    1   10  5  14  19 0.26315789 0.5386635  s/1
427         s    1   10 15  16  31 0.48387097 0.7692663  s/1
428         s    2   10  7   9  16 0.43750000 0.7227342  s/2
429         s    2   10  5   5  10 0.50000000 0.7853982  s/2
430         s    2   10  0   5   5 0.00000000 0.0000000  s/2
431         s    2   10  8   4  12 0.66666667 0.9553166  s/2
432         s    2   10  8   1   9 0.88888889 1.2309594  s/2
433         s    2   10  3  22  25 0.12000000 0.3537416  s/2
434         s    2   10  5  21  26 0.19230769 0.4539613  s/2
435         s    2   10  6   4  10 0.60000000 0.8860771  s/2
436         s    2   10  6  11  17 0.35294118 0.6361321  s/2
437         s    3   10  3   4   7 0.42857143 0.7137244  s/3
438         s    3   10  5  14  19 0.26315789 0.5386635  s/3
439         s    3   10 10   4  14 0.71428571 1.0068537  s/3
440         s    3   10  3  16  19 0.15789474 0.4086379  s/3
441         s    3   10  5  14  19 0.26315789 0.5386635  s/3
442         s    3   10 14  18  32 0.43750000 0.7227342  s/3
443         s    3   10  0   6   6 0.00000000 0.0000000  s/3
444         s    3   10 10  16  26 0.38461538 0.6689641  s/3
445         s    3   10  7   9  16 0.43750000 0.7227342  s/3
446         l    1   10  0   2   2 0.00000000 0.0000000  l/1
447         l    1   10  0   4   4 0.00000000 0.0000000  l/1
448         l    1   10  2  19  21 0.09523810 0.3137279  l/1
449         l    1   10  2  14  16 0.12500000 0.3613671  l/1
450         l    1   10  0  17  17 0.00000000 0.0000000  l/1
451         l    1   10  9  13  22 0.40909091 0.6939806  l/1
452         l    1   10  4   8  12 0.33333333 0.6154797  l/1
453         l    1   10  3  13  16 0.18750000 0.4478324  l/1
454         l    1   10 10  16  26 0.38461538 0.6689641  l/1
455         l    1   10  3  11  14 0.21428571 0.4812754  l/1
456         l    2   10  6   7  13 0.46153846 0.7468986  l/2
457         l    2   10  1  11  12 0.08333333 0.2928428  l/2
458         l    2   10  1  15  16 0.06250000 0.2526803  l/2
459         l    2   10  2  17  19 0.10526316 0.3304226  l/2
460         l    2   10  2  15  17 0.11764706 0.3501058  l/2
461         l    2   10  2   2   4 0.50000000 0.7853982  l/2
462         l    2   10  5  14  19 0.26315789 0.5386635  l/2
463         l    2   10 17  14  31 0.54838710 0.8338611  l/2
464         l    2   10 10  11  21 0.47619048 0.7615796  l/2
465         l    2   10  9  14  23 0.39130435 0.6758276  l/2
466         l    3   10  4   5   9 0.44444444 0.7297277  l/3
467         l    3   10  1   3   4 0.25000000 0.5235988  l/3
468         l    3   10 13   9  22 0.59090909 0.8768157  l/3
469         l    3   10  3  20  23 0.13043478 0.3695089  l/3
470         l    3   10 12  13  25 0.48000000 0.7653928  l/3
471         l    3   10  0   7   7 0.00000000 0.0000000  l/3
472         l    3   10  6   7  13 0.46153846 0.7468986  l/3
473         l    3   10 10   6  16 0.62500000 0.9117383  l/3
474         l    3   10  1   1   2 0.50000000 0.7853982  l/3
475         l    3   10  3  10  13 0.23076923 0.5010930  l/3
 

=========================

Federico C.F. Calboli

Department of Biology
University College London
Room 327
Darwin Building
Gower Street
London
WClE 6BT

Tel: (+44) 020 7679 4395 
Fax (+44) 020 7679 7096
f.calboli at ucl.ac.uk



From andrejk at zrc-sazu.si  Tue May 13 17:31:04 2003
From: andrejk at zrc-sazu.si (Andrej Kveder)
Date: Tue, 13 May 2003 17:31:04 +0200
Subject: [R] NLME - multilevel model using binary outcome - logistic
	regression
In-Reply-To: <3EBEB658.23343.6C2184@localhost>
Message-ID: <FHEEJBDDCNPPNJEACDJAEEEDCNAA.andrejk@zrc-sazu.si>

I just want to followup on my earlier question. I tried fitting a nonlinear
regression using the NLS and specified a following model.

model.1<-nls(clinton ~ 1/(1 + exp(-(sex + educ + age))), data=elect)

The testing data set I'm using is on the US election polls. Clinton is a
binary outcome (1-vote, 0-no-vote).

However I get the following error message.

Error in match.call(definition, call, expand.dots) : .Primitive... is not a
function

What am I doing wrong?
I know that for the single level models R has better functions (e.g. lrm or
glm), I used them before with success. However in the final instance I want
to fit a multilevel model with a binary outcome variable as a simple binary
logistic model.

I would be thankfull for all the insights.

Andrej

_________
Andrej Kveder, M.A.
researcher
Institute of Medical Sciences SRS SASA; Novi trg 2, SI-1000 Ljubljana,
Slovenia
phone: +386 1 47 06 440   fax: +386 1 42 61 493



From deepayan at stat.wisc.edu  Tue May 13 17:39:26 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 13 May 2003 10:39:26 -0500
Subject: [R] Re[2]:  unfortunately, no such function, panel.segments
In-Reply-To: <11801.030513@eimb.ru>
References: <6rptmm9ahz.fsf@bates4.stat.wisc.edu> <11801.030513@eimb.ru>
Message-ID: <200305131039.26969.deepayan@stat.wisc.edu>

On Tuesday 13 May 2003 10:14, Wladimir Eremeev wrote:
> Dear Douglas,
>
> >> plot.panel=function(x,y,...){
> >>   panel.xyplot(x,y,...);
> >>   panel.lmline(x,y,...);
> >>   panel.lmline(x[1:9],y[1:9],...);
> >>   panel.lmline(x[10:23],y[10:23],...);
> >>   panel.grid(h=-1,v=-1,...);
> >> };
> >>
> >> then I draw plots:
> >>   xyplot(<blah-blah-blah>,panel=plot.panel,<...>)
> >>
> >>   This command draws graphics, but all regression lines on them are
> >>   drawn from the left side to the right side, i.e. over the whole x
> >>   range...
>
> DB> I think you will need to do the linear model fits to the data subsets
> DB> within the panel function then use panel.segments to add the lines.
>
> But I've found lsegments, llines, and others.

Right, those are exactly what you want.

Deepayan



From kwright at eskimo.com  Tue May 13 17:41:48 2003
From: kwright at eskimo.com (Kevin Wright)
Date: Tue, 13 May 2003 08:41:48 -0700 (PDT)
Subject: [R] How do I view hidden methods?
Message-ID: <200305131541.IAA09501@eskimo.com>


I'm using R 1.7.0 on Windows 2000.

I'm a long-time user of R, but am experiencing frustration because
I can't figure out how to view the function definition of a non-exported 
method.  (I know I can go view the source code or the code in the library directory
but I am trying to view the function inside the R environment.

In particular,

library(mva)
biplot.princomp
Error: Oject "biplot.princomp" not found.


Right now I don't like hidden methods, but maybe someone can explain
the value of hiding functions from the user?

Kevin Wright



From deepayan at stat.wisc.edu  Tue May 13 17:52:19 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 13 May 2003 10:52:19 -0500
Subject: [R] Barchart to make a graph like this??
In-Reply-To: <3614.24.205.101.9.1052812842.squirrel@Biodiversity>
References: <3614.24.205.101.9.1052812842.squirrel@Biodiversity>
Message-ID: <200305131052.19581.deepayan@stat.wisc.edu>

On Tuesday 13 May 2003 03:00, knussear at biodiversity.unr.edu wrote:
> Hi list,
>
> I'm trying to get R to make a graph like the one shown in this pdf, where
> males are white bars and females are black bars.
>
> http://www.brrc.unr.edu/~knussear/mmgraph.pdf
>
> I tried barchart, but I couldnt get the bars to share a common x axis.

I'm assuming by this you mean barchart in the lattice package.

> Do you have any suggestions?

Some information on the form of your data would have helped.

This is not the standard form of a barchart, so you need to fudge some things. 
First of all, make the values in one of the groups (the ones you want on the 
left) negative. Then barchart with groups (or use + in the formula, depending 
on the form of your data), stack=TRUE should give you what you want. Of 
course, the axis labels will be negative, you need to control those using 
scales.

HTH,

Deepayan



From tlumley at u.washington.edu  Tue May 13 18:03:18 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 13 May 2003 09:03:18 -0700 (PDT)
Subject: [R] How do I view hidden methods?
In-Reply-To: <200305131541.IAA09501@eskimo.com>
Message-ID: <Pine.A41.4.44.0305130900150.49176-100000@homer13.u.washington.edu>

On Tue, 13 May 2003, Kevin Wright wrote:

>
> I'm using R 1.7.0 on Windows 2000.
>
> I'm a long-time user of R, but am experiencing frustration because
> I can't figure out how to view the function definition of a non-exported
> method.  (I know I can go view the source code or the code in the library directory
> but I am trying to view the function inside the R environment.
>
> In particular,
>
> library(mva)
> biplot.princomp
> Error: Oject "biplot.princomp" not found.
>
>
> Right now I don't like hidden methods, but maybe someone can explain
> the value of hiding functions from the user?
>

So they can't be called directly, but only via UseMethod.
You can see the function with

getS3method("biplot","princomp")

	-thomas



From bates at stat.wisc.edu  Tue May 13 18:09:40 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 13 May 2003 16:09:40 -0000
Subject: [R] NLME - multilevel model using binary outcome - logistic
	regression
In-Reply-To: <FHEEJBDDCNPPNJEACDJAEEEDCNAA.andrejk@zrc-sazu.si>
References: <FHEEJBDDCNPPNJEACDJAEEEDCNAA.andrejk@zrc-sazu.si>
Message-ID: <6r65oe96bv.fsf@bates4.stat.wisc.edu>

"Andrej Kveder" <andrejk at zrc-sazu.si> writes:

> I just want to followup on my earlier question. I tried fitting a nonlinear
> regression using the NLS and specified a following model.
> 
> model.1<-nls(clinton ~ 1/(1 + exp(-(sex + educ + age))), data=elect)
> 
> The testing data set I'm using is on the US election polls. Clinton is a
> binary outcome (1-vote, 0-no-vote).
> 
> However I get the following error message.
> 
> Error in match.call(definition, call, expand.dots) : .Primitive... is not a
> function
> 
> What am I doing wrong?
> I know that for the single level models R has better functions (e.g. lrm or
> glm), I used them before with success. However in the final instance I want
> to fit a multilevel model with a binary outcome variable as a simple binary
> logistic model.
> 
> I would be thankfull for all the insights.

As I understand it you are trying to fit a generalized linear mixed
model.  For that you should use one of the functions for GLMMs.  I
would recommend glmmPQL from the MASS package.

Your problem with the call to nls is that you did not include all the
required arguments but, since you don't want to use nls to fit this
model, there is no purpose in following up on that.



From tblackw at umich.edu  Tue May 13 18:19:23 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Tue, 13 May 2003 12:19:23 -0400 (EDT)
Subject: [R] assessing the fit of a LME model
In-Reply-To: <3.0.6.32.20030513161711.02b957b8@pop-server.ucl.ac.uk>
Message-ID: <Pine.SOL.4.44.0305131203010.11940-100000@robotron.gpcc.itd.umich.edu>

Federico  -

I'm coming to this from outside the field, and I hope Doug Bates
will reply ... but I would question the use of normal theory linear
models with counted data.  Why not logistic regression (binomial)
or log-linear models (Poisson) ?

You see, coming to the question from outside, I'm still back at
the point of needing to answer *that* question for myself, before
I can think about the random-effects aspects of the problem.

I don't yet understand "vials within cages".  Are the vials open
or closed ?  What determines the total number per vial ?  (Thus,
is a binomial or a Poisson error model appropriate ?)  And, what
is "temperature" in the Bartlett test, and why does it make sense
to *cross* "cage" with "temperature" ?  Was every cage in fact
tested at multiple temperatures ?  (I would guess not, but I don't
fully understand the experimental setup.)

So ... in the end ... I offer you many questions and *zero* answers !

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Tue, 13 May 2003, Federico Calboli wrote:

> I would like to ask a couple of questions on a LME model.
>
> I tested 4 selection lines at 4 food concentrations against a standard
> competitor stock. I had 3 replicate cages per selection line. In each cage
> I have 10 vials. I counted the number of wild type flies and competitor
> stock emerging in each vial. My main question is: is there any difference
> between selection lines?
>
> I did fit the following model:
>
> mod1<-lme(wt~selection*food, random=~1|c1/food, competition)
>
> The quantile plot is straight, the plot of residuals looks good, the
> standardized residual plot seems ok... BUT if I do a bartlett test for
> homogeneity of variance (done by cage*temperature, 48 cages in all) the
> variance is NOT homogeneous. Is my model still accettable? if not, what
> could I do?
>
> The same model on asin(sqrt(wild type/total)) does not fit anywhere as well.
>
> my dataset (NB *wt* is the number of wild type flies in each vial; *spa* is
> the number of comepetitor stock flies in each vial, *p1* is
> asin(sqrt(competition$prop)), *c1* is the cage nested in selection using
> getGroups...):
>
>     selection cage food wt spa tot       prop        p1   c1
>
> (475 lines of data deleted)
>
> Federico C.F. Calboli
>
> Department of Biology
> University College London
> Room 327
> Darwin Building
> Gower Street
> London
> WClE 6BT
>
> Tel: (+44) 020 7679 4395
> Fax (+44) 020 7679 7096
> f.calboli at ucl.ac.uk



From Guangchun.Song at stjude.org  Tue May 13 18:24:15 2003
From: Guangchun.Song at stjude.org (Song, Guangchun)
Date: Tue, 13 May 2003 11:24:15 -0500
Subject: [R] How to retrieve data frame column names?
Message-ID: <A1DAD6685C12D511B20F0003472515138E698C@sjmemexc3.stjude.org>


Dear R-users/helpers,

Does anyone tell me how to retrieve the data frame column names?

I'm working on coxph model to analyze survival data of Affy DNA chips.

I get the coxph coef p-value for each probe and want output the probe name
with the p-value.  The probe names are the data frame column names.

How can I do this?

Thanks for your help.

Guangchun



From ripley at stats.ox.ac.uk  Tue May 13 18:30:11 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 13 May 2003 17:30:11 +0100 (BST)
Subject: [R] How to retrieve data frame column names?
In-Reply-To: <A1DAD6685C12D511B20F0003472515138E698C@sjmemexc3.stjude.org>
Message-ID: <Pine.LNX.4.44.0305131728390.10972-100000@gannet.stats>

On Tue, 13 May 2003, Song, Guangchun wrote:

> Does anyone tell me how to retrieve the data frame column names?
> 
> I'm working on coxph model to analyze survival data of Affy DNA chips.
> 
> I get the coxph coef p-value for each probe and want output the probe name
> with the p-value.  The probe names are the data frame column names.
> 
> How can I do this?

That is rather vague!  At a guess, you did

fit <- coxph(..., data=foo, ...)

and want to retrieve `foo'.  That's stored in fit$call$data.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From pgilbert at bank-banque-canada.ca  Tue May 13 18:51:30 2003
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Tue, 13 May 2003 12:51:30 -0400
Subject: [R] building R 1.7.0 with gcc 3.2.3 on Solaris
In-Reply-To: <x265ok83v5.fsf@biostat.ku.dk>
References: <Pine.LNX.4.44.0305091724080.23696-100000@gannet.stats>
	<x265ok83v5.fsf@biostat.ku.dk>
Message-ID: <3EC12292.8030501@bank-banque-canada.ca>

It turns out that this problem was caused by compiling gcc on SunOS 5.6 
and then trying to use it on SunOS 5.8. (Sys admins like to compile 
things on 5.6, as the apps then usually run on both 5.6 and 5.8.) With 
gcc compiled and used on SunOS 5.8,  R 1.7.0 compiles and everything 
runs fine. (So far I have only tried R as a 32 bit application.) I still 
need to set LDFLAGS or the C and Fortran don't mix.

Thanks,
Paul Gilbert

Peter Dalgaard BSA wrote:
> Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:
> 
>>On Fri, 9 May 2003, Paul Gilbert wrote:
>>
>>>With gcc 3.2.3 on SunOS 5.8 and R 1.7.0, configure fails for me unless I 
>>>set LDFLAGS ( LDFLAGS=-L/apps/asd/unix/gnu/gcc/3.2.3/SunOS5.8/lib ). 
>>
>>It works here with gcc installed in /usr/local/lib.  
> 
> >>With that set it appears that configure succeeds (i.e. no error messages
 >>>on the console), but config.log contains messages
 >>>
 >>>configure:4099: checking for gcc option to accept ANSI C
 >>>configure:4160: gcc  -c -g -O2 -I/usr/local/include conftest.c >&5
 >>>In file included from configure:4124:
 >>>/usr/include/sys/stat.h:258: syntax error before "blksize_t"
 >>>/usr/include/sys/stat.h:262: syntax error before '}' token
 >>>/usr/include/sys/stat.h:318: syntax error before "blksize_t"
 >>>/usr/include/sys/stat.h:319: conflicting types for `st_blocks'
 >>>/usr/include/sys/stat.h:259: previous declaration of `st_blocks'
 >>>/usr/include/sys/stat.h:322: syntax error before '}' token
 >>>configure:4163: $? = 1
 >>>configure: failed program was:
 >>>| #line 4106 "configure"
 >>>| /* confdefs.h.  */
 >>>|
 >>>| #define PACKAGE_NAME "R"
 >>>| #define PACKAGE_TARNAME "R"
 >>>| #define PACKAGE_VERSION "1.7.0"
 >>>| #define PACKAGE_STRING "R 1.7.0"

> A longshot: This sort of thing happens if you accidentally mix
> multiple versions of gcc. Are you sure you don't also need to put
> /apps/asd/unix/gnu/gcc/3.2.3/SunOS5.8/bin or so at the head of your
> PATH so as not to pick up another gcc?
>



From ripley at stats.ox.ac.uk  Tue May 13 19:04:00 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 13 May 2003 18:04:00 +0100 (BST)
Subject: [R] building R 1.7.0 with gcc 3.2.3 on Solaris
In-Reply-To: <3EC12292.8030501@bank-banque-canada.ca>
Message-ID: <Pine.LNX.4.44.0305131801030.11029-100000@gannet.stats>

On Tue, 13 May 2003, Paul Gilbert wrote:

> It turns out that this problem was caused by compiling gcc on SunOS 5.6 
> and then trying to use it on SunOS 5.8. (Sys admins like to compile 
> things on 5.6, as the apps then usually run on both 5.6 and 5.8.) With 

Not gcc: gcc compiled under Solaris 2.6 is wrong for 2.7 or 2.8.  
Compiled under 2.7 works on 2.8 though, although I would not recommend it.

There are quite a lot of other exceptions ....

> gcc compiled and used on SunOS 5.8,  R 1.7.0 compiles and everything 
> runs fine. (So far I have only tried R as a 32 bit application.) I still 
> need to set LDFLAGS or the C and Fortran don't mix.

Rather, Fortran should not run at all, so perhaps you are picking up the 
wrong copy of -lg2c?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From John.Marsland at CommerzbankIB.com  Tue May 13 19:16:34 2003
From: John.Marsland at CommerzbankIB.com (Marsland, John)
Date: Tue, 13 May 2003 18:16:34 +0100
Subject: [R] RMySQL crashes R
Message-ID: <8CBAA121CEB4D5118CB200508BB2BBEF0317E713@xmx8lonib.lonib.commerzbank.com>

I have justed upgraded R v1.7.0 on Windows NT 4 and have installed the
latest RMySQL (version 0.5-1)and DBI (version 0.1-5) packages.

When I issue the following commands (tactfully adjusted) R just crashes and
disappears, any ideas?

require(RMySQL)
m <- dbDriver("MySQL")
con <- dbConnect(m, dbname="xxx", user="xxx", password="xxx",
host="myserver.com")

I get the same result with mysqlNewConnection().

I've sucessfully used both previous versions of R and the MySQL package
together with no problems.

Regards, 

John Marsland


********************************************************************** 
This is a commercial communication from Commerzbank AG.\ \ This ... {{dropped}}



From clists at perrin.socsci.unc.edu  Tue May 13 19:20:59 2003
From: clists at perrin.socsci.unc.edu (Andrew Perrin)
Date: Tue, 13 May 2003 13:20:59 -0400 (EDT)
Subject: [R] barplot x axis labels
Message-ID: <Pine.LNX.4.53.0305131319090.4721@perrin.socsci.unc.edu>

I know this has got to be easy, but can't figure it out.

I've got a data frame that includes several numeric indices and a date for
each of 1100 records.  I'd like to plot a barplot of the mean of each of
these indices by date.  I've managed to do this:

> barplot(tapply(first.pro.auth.sum, dates(date), mean))

but even though I use the dates(date) function, the x axis displays
numeric labels, not dates. I'd like it to display the dates. Any advice?

Thanks.

----------------------------------------------------------------------
Andrew J Perrin - http://www.unc.edu/~aperrin
Assistant Professor of Sociology, U of North Carolina, Chapel Hill
clists at perrin.socsci.unc.edu * andrew_perrin (at) unc.edu



From pratap at itam.mx  Tue May 13 20:21:20 2003
From: pratap at itam.mx (Sangeeta Pratap)
Date: Tue, 13 May 2003 13:21:20 -0500 (CDT)
Subject: [R] Help on PLotting
Message-ID: <Pine.LNX.4.44.0305131318420.17126-100000@ciep.itam.mx>


We were wondering if there was a simple way to plot two series, say y and 
z, against a series x and have both series appear in the same plot. 

For example the function plot(x~y+z) generates two scatter plots, one with
y against x and the other with z against x. Is there any way to obtain
both on the same picture?  

Thanks for your help 

Sangeeta

-- 

______________________________________________________________________________
Sangeeta Pratap				  email:pratap at itam.mx
Centro de Investigaci?n Econ?mica	  phone:52 55 56284000 extn.2966
Instituto Tecnol?gico Aut?nomo de M?xico  fax:  52 55 56284058	
Av. Camino de Santa Teresa 930
10700, Mexico D.F



From jerome at hivnet.ubc.ca  Tue May 13 20:51:12 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Tue, 13 May 2003 11:51:12 -0700
Subject: [R] Help on PLotting
In-Reply-To: <Pine.LNX.4.44.0305131318420.17126-100000@ciep.itam.mx>
References: <Pine.LNX.4.44.0305131318420.17126-100000@ciep.itam.mx>
Message-ID: <200305131856.LAA06455@hivnet.ubc.ca>


See ?matplot.

On May 13, 2003 11:21 am, Sangeeta Pratap wrote:
> Content-Length: 800
> Status: R
> X-Status: N
>
>
> We were wondering if there was a simple way to plot two series, say y
> and z, against a series x and have both series appear in the same plot.
>
> For example the function plot(x~y+z) generates two scatter plots, one
> with y against x and the other with z against x. Is there any way to
> obtain both on the same picture?
>
> Thanks for your help
>
> Sangeeta



From deepayan at stat.wisc.edu  Tue May 13 20:59:42 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 13 May 2003 13:59:42 -0500
Subject: [R] Help on PLotting
In-Reply-To: <Pine.LNX.4.44.0305131318420.17126-100000@ciep.itam.mx>
References: <Pine.LNX.4.44.0305131318420.17126-100000@ciep.itam.mx>
Message-ID: <200305131359.42275.deepayan@stat.wisc.edu>


See ?matplot. Alternatively, using xyplot from the lattice package,

xyplot(y + z ~ x, allow.m = TRUE)

On Tuesday 13 May 2003 13:21, Sangeeta Pratap wrote:
> We were wondering if there was a simple way to plot two series, say y and
> z, against a series x and have both series appear in the same plot.
>
> For example the function plot(x~y+z) generates two scatter plots, one with
> y against x and the other with z against x. Is there any way to obtain
> both on the same picture?
>
> Thanks for your help
>
> Sangeeta



From bangham at neocera.com  Tue May 13 22:33:37 2003
From: bangham at neocera.com (Mike Bangham)
Date: Tue, 13 May 2003 16:33:37 -0400
Subject: [R] call nlm from a dll?
Message-ID: <E936146C7570D311B92D009027AC92995D6244@neoserver.neocera.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030513/d8dcfd4d/attachment.pl

From bates at stat.wisc.edu  Tue May 13 23:26:36 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 13 May 2003 21:26:36 -0000
Subject: [R] Robert Gentleman's talk to the Statis. Soc. of Canada
Message-ID: <6rel327d30.fsf@bates4.stat.wisc.edu>

Users of R may find the "Message from the President" in the latest issue
of Liaison, the newsletter of the Statistical Society of Canada, to be
of interest. (http://www.ssc.ca/documents/pubs/Liaison17.2.pdf).  In
this message Jim Ramsey, President of the SSC, describes his purpose
in inviting Robert Gentleman to give the President's Invited Address
at their annual general meeting.  Robert's topic will be "Modern
Statistical Computing".



From p.murrell at auckland.ac.nz  Tue May 13 23:31:12 2003
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Wed, 14 May 2003 09:31:12 +1200
Subject: [R] grid - deleting and erasing grobs?
References: <3EC02AFD.1010709@hppi.troitsk.ru>
Message-ID: <3EC16420.70505@stat.auckland.ac.nz>

Hi


M.Kondrin wrote:
> Hello!
> Don't quite understand how can I delete grobs and simultaneously erase 
> graphic output they produce. I first change grob's "vp" field to null 
> (grid.edit(gr,vp=NULL)) to erase it and then call rm(gr) (as grobs are 
> external pointers I'm not shure what this method actually frees 
> allocated memory).
> May be there is simpler method?
> Does garbage collector have any effect on grobs?
> Thank you in advance


You can't delete grobs interactively.
It is theoretically possible, but it has not been implemented (yet).
[more detail on a reply shifted to R-devel]

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz



From s.mcclatchie at niwa.co.nz  Tue May 13 23:35:26 2003
From: s.mcclatchie at niwa.co.nz (Sam McClatchie)
Date: Wed, 14 May 2003 09:35:26 +1200
Subject: [R] how to upgrade R/ linux/ mandrake/ readme suggestion
Message-ID: <3EC1651E.4030407@niwa.cri.nz>

System info:
Mandrake 9.0
R Version 1.7.0
ESS 5.1.21
Emacs 21.2.1
-------------------

Colleagues

The R-team has done a great job of making it easy to upgrade to current 
versions of the R-language using the rpms for linux. I have a minor 
suggestion for the readme file <Mandrake-Readme.txt> where the mandrake 
linux binaries reside <http://www.cran.r-project.org/>.

The readme at the moment focusses on "BUILDING AN R RPM FOR EARLIER 
VERSIONS OF MANDRAKE" (sorry about the capitals). It would be very 
helpful to have a one liner near the top of the file that says something 
like what follows (I've left the LaTex makup in there from my own notes).
------------------------

\subsection{Upgrading R}
First copy the /usr/lib/R/library/ somehwere safe! After
installing the new version of R, check to make sure you still
have any former user contributed packages you may have
installed. if not copy them over from the former library
directory before deleting it.

Download the
new rpm for the appropriate mandrake distribution.  Change to
root. Use the upgrade option for rpmi to install the rpm.
\begin{verbatim}
[root at smc R]# rpmi -U R-1.7.0-1mdk.i586.rpm
\end{verbatim}

--------------------
This may save some users from trying <rpmi -i R-1.7.0-1mdk.i586.rpm> and 
then wondering why they get a lot of messages about conflicting file 
versions from an earlier version of R.

Thanks for making upgade so easy.

Best fishes

Sam


-- 
Sam McClatchie, Research scientist (fisheries acoustics))))))))))
NIWA (National Institute of Water & Atmospheric Research Ltd)
PO Box 14 901, Kilbirnie, Wellington, New Zealand
s.mcclatchie at niwa.cri.nz
Research home page <http://www.smcc.150m.com/>
                       /\
            >><xX(&>
                    /// \\\
                   //// \\\\
                  ///  <%)Xx><<
                 /////  \\\\\\
           ><(((@>
     ><(((%>     ..>><xX(?>O<?)Xx><<



From mikalzet at libero.it  Wed May 14 00:35:52 2003
From: mikalzet at libero.it (mikalzet@libero.it)
Date: Wed, 14 May 2003 00:35:52 +0200 (CEST)
Subject: [R] Re: how to upgrade R/ linux/ mandrake/ readme suggestion
In-Reply-To: <3EC1651E.4030407@niwa.cri.nz>
References: <3EC1651E.4030407@niwa.cri.nz>
Message-ID: <Pine.LNX.4.50.0305140024100.2890-100000@macchinetta>

On Wed, 14 May 2003, Sam McClatchie wrote:

> It would be very 
> helpful to have a one liner near the top of the file that says something 
> like what follows 

<cut>

R 1.7.0 - for the first time - has "make check all" in the spec file and
this has brought to the light a few problems.

I must still upload RPM packages for Mandrake 8.0 (which I've managed to compile, 
but only  with --shlib disabled, because with --shlib enabled a package 
fails the check) and 8.1 (which just will not compile if make check all is 
done ... whether or not R is compiled as --shlib: one of the packages 
systematically fails on make check).

In any case, as soon as I have a little time I will examine the issue more 
closely and upload - hopefully - either working rpms or a bug report
on the relevant packages.

But before I do this I shall certainly upload a revised readme with your 
indications included. Thank you !

-- 
Michele Alzetta



From cschuste at nd.edu  Wed May 14 00:39:31 2003
From: cschuste at nd.edu (Christof Schuster)
Date: Tue, 13 May 2003 17:39:31 -0500 (EST)
Subject: [R] bug in promax?
Message-ID: <Pine.SOL.4.10.10305131736040.7849-100000@shakespeare.helios.nd.edu>


I was wondering whether the following inconsistency of the promax
rotation function with the results of a promax rotation using SAS
should be considered a bug in the promax function of R. Any comments
will be highly appreciated.

The following is a loading matrix obtained from a varimax rotation in SAS:
# Factor loadings after varimax rotation
x <- t(array(c(0.78107,         0.35573,
               0.85995,         0.07887,
               0.79376,         0.22499,
               0.26307,         0.85087,
               0.29449,         0.72966,
               0.06064,         0.68135), c(2,6)))

Clearly, the varimax function of R confirms this because

varimax(x)$rotmat
              [,1]         [,2]
[1,]  1.000000e+00 2.021128e-07
[2,] -2.021128e-07 1.000000e+00

yields the identity matrix.

SAS will return the following matrix after a promax rotation (for which
m=3 by default):

 0.75760         0.18383
 0.91956        -0.14061
 0.80720         0.03711
 0.05546         0.86360
 0.12295         0.72239
-0.11977         0.73116

However, using the promax function of R yields

promax(x, m=3)$loadings
            [,1]        [,2]
[1,]  0.74582399  0.20809487
[2,]  0.90713821 -0.11197901
[3,]  0.79547453  0.06260245
[4,]  0.05020993  0.86729962
[5,]  0.11747045  0.72788738
[6,] -0.12182636  0.72904497

Although the values are quite close to the SAS solution, there is
nevertheless a small mismatch. The following slightly edited function
of promax

mypromax <- function (x, m = 3) 
{
    if (ncol(x) < 2) 
        return(x)
    dn <- dimnames(x)
    xx <- varimax(x)
    x <- xx$loadings
    x1 <- diag(1/sqrt(diag(x %*% t(x)))) %*% x
    Q <- x1 * abs(x1)^(m - 1)
    U <- lm.fit(x, Q)$coefficients
    d <- diag(solve(t(U) %*% U))
    U <- U %*% diag(sqrt(d))
    dimnames(U) <- NULL
    z <- x %*% U
    U <- xx$rotmat %*% U
    dimnames(z) <- dn
    list(loadings = z, rotmat = U)
}

yields 

round(mypromax(x)$loadings, 5)
         [,1]     [,2]
[1,]  0.75760  0.18383
[2,]  0.91956 -0.14061
[3,]  0.80721  0.03711
[4,]  0.05546  0.86360
[5,]  0.12295  0.72238
[6,] -0.11977  0.73116

Clearly, these values are virtually identical to the loadings after
promax rotation from SAS. The only differences of the above mypromax
function to the original function is that the loadings after varimax
rotation are first normalized (see the line in which x1 is calculated)
before they are used to calculate the target matrix Q in the next
line.

Hendrickson & White (1964), BJSP, 17, 65-70 who originally suggested
PROMAX wrote about the target matrix, p. 66: "Each element of this
matrix [the target matrix Q] is, ..., the kth power of the
corresponding element in the row-column normalized orthogonal matrix."

Although I am not sure what Hendrickson and White meant with "row-column"
normalization it appears to me that the original promax function is
missing a normalization of the loadings after varimax rotation before the
target matrix is calculated. The normalization I have used (and that
appears to be used by SAS) ensures that diag(x1 x1')=I, where x1 denotes
the normalized loadings.

Which set of loadings are the correct promax loadings?

Christof Schuster

Christof Schuster
University of Notre Dame
Department of Psychology                       
103 Haggar Hall
Notre Dame, IN 46556

Tel: (574) 631-5473    email: cschuste at nd.edu
Fax: (574) 631-8883    www.nd.edu/~cschuste



From s195404 at student.uq.edu.au  Wed May 14 00:47:58 2003
From: s195404 at student.uq.edu.au (Andrew C. Ward)
Date: Tue, 13 May 2003 22:47:58 +0000
Subject: [R] Barchart to make a graph like this??
In-Reply-To: <200305131052.19581.deepayan@stat.wisc.edu>
References: <3614.24.205.101.9.1052812842.squirrel@Biodiversity>
	<200305131052.19581.deepayan@stat.wisc.edu>
Message-ID: <1052866078.3ec1761ec3149@my.uq.edu.au>

Ken, I actually asked about doing this on the list sometime ago
and received a number of very useful suggestions. If you search
the archives for "Christmas tree graphs" you'll discover all you
need to know (and more).

Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au


Quoting Deepayan Sarkar <deepayan at stat.wisc.edu>:

> On Tuesday 13 May 2003 03:00, knussear at biodiversity.unr.edu
> wrote:
> > Hi list,
> >
> > I'm trying to get R to make a graph like the one shown in
> this pdf, where
> > males are white bars and females are black bars.
> >
> > http://www.brrc.unr.edu/~knussear/mmgraph.pdf
> >
> > I tried barchart, but I couldnt get the bars to share a
> common x axis.
> 
> I'm assuming by this you mean barchart in the lattice package.
> 
> > Do you have any suggestions?
> 
> Some information on the form of your data would have helped.
> 
> This is not the standard form of a barchart, so you need to
> fudge some things. 
> First of all, make the values in one of the groups (the ones
> you want on the 
> left) negative. Then barchart with groups (or use + in the
> formula, depending 
> on the form of your data), stack=TRUE should give you what you
> want. Of 
> course, the axis labels will be negative, you need to control
> those using 
> scales.
> 
> HTH,
> 
> Deepayan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From ggrothendieck at volcanomail.com  Wed May 14 02:02:17 2003
From: ggrothendieck at volcanomail.com (Gabor Grothendieck)
Date: Tue, 13 May 2003 17:02:17 -0700 (PDT)
Subject: [R] Sorting a matrix in an odd way"
Message-ID: <20030514000217.B2E6AABB9@sitemail.everyone.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030513/a283d768/attachment.pl

From bates at stat.wisc.edu  Wed May 14 02:16:39 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 14 May 2003 00:16:39 -0000
Subject: [R] Some Programming Humor
Message-ID: <6rvfwe5qob.fsf@bates4.stat.wisc.edu>


From bates at stat.wisc.edu  Wed May 14 02:37:49 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 14 May 2003 00:37:49 -0000
Subject: [R] Some Programming Humor
In-Reply-To: <6rvfwe5qob.fsf@bates4.stat.wisc.edu>
References: <6rvfwe5qob.fsf@bates4.stat.wisc.edu>
Message-ID: <6rr8725pnw.fsf@bates4.stat.wisc.edu>

Douglas Bates <bates at cs.wisc.edu> writes:

> I checked and R is one of the 515 languages mentioned in the enclosed.

Hmm - the enclosure seems to have gone missing.  It was

 From: Tim Schaab <tim at madweb.org>
 Subject: [Madlug] Some Programming Humor
 To: MadLUG List <Madlug at madisonlinux.org>
 Date: Tue, 13 May 2003 19:00:13 -0500
 Organization: Madweb.org

 Taking a break from studying all things databases for an upcoming
 exam, I found this site that really amazed me.

 The recipe is simple.  

 1) Take the song "99 Bottles of Beer on the Wall"
 2) Write a program that will sing/display the song for all to see
 3) Repeat step 2 in a different language

 Currently, they have 515 languages covered.

 Once again proving some techie humor is not fit for the masses, but
 rather funny if you get it.

 Consume and enjoy!

 http://99-bottles-of-beer.ls-la.net/



From Tom.Mulholland at health.wa.gov.au  Wed May 14 06:19:06 2003
From: Tom.Mulholland at health.wa.gov.au (Mulholland, Tom)
Date: Wed, 14 May 2003 12:19:06 +0800
Subject: [R] Is there a simple method of changing text into 'Proper Case'
Message-ID: <74E242B6968AA0469B632C5A3EFC1EFD03D55BC3@nt207mesep.health.wa.gov.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030514/2e207ce4/attachment.pl

From spencer.graves at pdf.com  Wed May 14 06:50:54 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 13 May 2003 21:50:54 -0700
Subject: [R] Is there a simple method of changing text into 'Proper Case'
References: <74E242B6968AA0469B632C5A3EFC1EFD03D55BC3@nt207mesep.health.wa.gov.au>
Message-ID: <3EC1CB2E.6040704@pdf.com>

It's not obvious to me what you are asking, but I'm guessing that 
"casefold" might help.

hth.  spencer graves

Mulholland, Tom wrote:
> I am probably just looking in the wrong place. I am sure there are a number
> of ways to do this. If anyone could point me in the right direction it would
> be very much appreciated.
>  
> Thanks
>  
> _________________________________________________
>  
> Tom Mulholland
> Senior Policy Officer
> WA Country Health Service
> 189 Royal St, East Perth, WA, 6004
>  
> Tel: (08) 9222 4062
> e-mail: Tom.Mulholland at health.wa.gov.au
> <mailto:Tom.Mulholland at health.wa.gov.au> 
>  
> The contents of this e-mail transmission are confidential and may be
> protected by professional privilege. The contents are intended only for the
> named recipients of this e-mail. If you are not the intended recipient, you
> are hereby notified that any use, reproduction, disclosure or distribution
> of the information contained in this e-mail is prohibited. Please notify the
> sender immediately.
>  
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Tom.Mulholland at health.wa.gov.au  Wed May 14 07:24:31 2003
From: Tom.Mulholland at health.wa.gov.au (Mulholland, Tom)
Date: Wed, 14 May 2003 13:24:31 +0800
Subject: [R] Is there a simple method of changing text into 'Proper Ca se'
Message-ID: <74E242B6968AA0469B632C5A3EFC1EFD03D56F97@nt207mesep.health.wa.gov.au>

Yes and no. Given your response it appears that "Proper Case" is not a term
that everyone uses. In Excel there is a function "Proper" which in essence
changes "this line into something like this" into "This Line Into Something
Like This."

My look at casefold seesm to be that is is a wrapper of two functions to
change text into either Lower or Upper case.So my question is about how do
you just capitalise the first letter in each word.

Thanks for your response.

Tom

-----Original Message-----
From: Spencer Graves [mailto:spencer.graves at PDF.COM] 
Sent: Wednesday, 14 May 2003 12:51 PM
To: Mulholland, Tom
Cc: ' (r-help at stat.math.ethz.ch)'
Subject: Re: [R] Is there a simple method of changing text into 'Proper
Case'


It's not obvious to me what you are asking, but I'm guessing that 
"casefold" might help.

hth.  spencer graves

Mulholland, Tom wrote:
> I am probably just looking in the wrong place. I am sure there are a 
> number of ways to do this. If anyone could point me in the right 
> direction it would be very much appreciated.
>  
> Thanks
>  
> _________________________________________________
>  
> Tom Mulholland
> Senior Policy Officer
> WA Country Health Service
> 189 Royal St, East Perth, WA, 6004
>  
> Tel: (08) 9222 4062
> e-mail: Tom.Mulholland at health.wa.gov.au 
> <mailto:Tom.Mulholland at health.wa.gov.au>
>  
> The contents of this e-mail transmission are confidential and may be 
> protected by professional privilege. The contents are intended only 
> for the named recipients of this e-mail. If you are not the intended 
> recipient, you are hereby notified that any use, reproduction, 
> disclosure or distribution of the information contained in this e-mail 
> is prohibited. Please notify the sender immediately.
>  
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ligges at statistik.uni-dortmund.de  Wed May 14 08:40:27 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 14 May 2003 08:40:27 +0200
Subject: [R] Is there a simple method of changing text into 'Proper Ca se'
In-Reply-To: <74E242B6968AA0469B632C5A3EFC1EFD03D56F97@nt207mesep.health.wa.gov.au>
References: <74E242B6968AA0469B632C5A3EFC1EFD03D56F97@nt207mesep.health.wa.gov.au>
Message-ID: <3EC1E4DB.3060100@statistik.uni-dortmund.de>

Mulholland, Tom wrote:
> Yes and no. Given your response it appears that "Proper Case" is not a term
> that everyone uses. In Excel there is a function "Proper" which in essence
> changes "this line into something like this" into "This Line Into Something
> Like This."
> 
> My look at casefold seesm to be that is is a wrapper of two functions to
> change text into either Lower or Upper case.So my question is about how do
> you just capitalise the first letter in each word.

Perl experts might do it differently, but the "R way" seems to be

  substring(x, 1, 1) <- toupper(substring(x, 1, 1))
  substring(x, 2) <- tolower(substring(x, 2))

Uwe Ligges


> Thanks for your response.
> 
> Tom
> 
> -----Original Message-----
> From: Spencer Graves [mailto:spencer.graves at PDF.COM] 
> Sent: Wednesday, 14 May 2003 12:51 PM
> To: Mulholland, Tom
> Cc: ' (r-help at stat.math.ethz.ch)'
> Subject: Re: [R] Is there a simple method of changing text into 'Proper
> Case'
> 
> 
> It's not obvious to me what you are asking, but I'm guessing that 
> "casefold" might help.
> 
> hth.  spencer graves
> 
> Mulholland, Tom wrote:
> 
>>I am probably just looking in the wrong place. I am sure there are a 
>>number of ways to do this. If anyone could point me in the right 
>>direction it would be very much appreciated.
>> 
>>Thanks
>> 
>>_________________________________________________
>> 
>>Tom Mulholland
>>Senior Policy Officer
>>WA Country Health Service
>>189 Royal St, East Perth, WA, 6004
>> 
>>Tel: (08) 9222 4062
>>e-mail: Tom.Mulholland at health.wa.gov.au 
>><mailto:Tom.Mulholland at health.wa.gov.au>



From spencer.graves at pdf.com  Wed May 14 09:15:17 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 14 May 2003 00:15:17 -0700
Subject: [R] Is there a simple method of changing text into 'Proper Ca se'
References: <74E242B6968AA0469B632C5A3EFC1EFD03D56F97@nt207mesep.health.wa.gov.au>
	<3EC1E4DB.3060100@statistik.uni-dortmund.de>
Message-ID: <3EC1ED05.6030601@pdf.com>

Excellent.  Users concered about transportability to S-Plus would have 
to translate "toupper" and "tolower" into "casefold", however.

Spencer Graves

Uwe Ligges wrote:
> Mulholland, Tom wrote:
> 
>> Yes and no. Given your response it appears that "Proper Case" is not a 
>> term
>> that everyone uses. In Excel there is a function "Proper" which in 
>> essence
>> changes "this line into something like this" into "This Line Into 
>> Something
>> Like This."
>>
>> My look at casefold seesm to be that is is a wrapper of two functions to
>> change text into either Lower or Upper case.So my question is about 
>> how do
>> you just capitalise the first letter in each word.
> 
> 
> Perl experts might do it differently, but the "R way" seems to be
> 
>  substring(x, 1, 1) <- toupper(substring(x, 1, 1))
>  substring(x, 2) <- tolower(substring(x, 2))
> 
> Uwe Ligges
> 
> 
>> Thanks for your response.
>>
>> Tom
>>
>> -----Original Message-----
>> From: Spencer Graves [mailto:spencer.graves at PDF.COM] Sent: Wednesday, 
>> 14 May 2003 12:51 PM
>> To: Mulholland, Tom
>> Cc: ' (r-help at stat.math.ethz.ch)'
>> Subject: Re: [R] Is there a simple method of changing text into 'Proper
>> Case'
>>
>>
>> It's not obvious to me what you are asking, but I'm guessing that 
>> "casefold" might help.
>>
>> hth.  spencer graves
>>
>> Mulholland, Tom wrote:
>>
>>> I am probably just looking in the wrong place. I am sure there are a 
>>> number of ways to do this. If anyone could point me in the right 
>>> direction it would be very much appreciated.
>>>
>>> Thanks
>>>
>>> _________________________________________________
>>>
>>> Tom Mulholland
>>> Senior Policy Officer
>>> WA Country Health Service
>>> 189 Royal St, East Perth, WA, 6004
>>>
>>> Tel: (08) 9222 4062
>>> e-mail: Tom.Mulholland at health.wa.gov.au 
>>> <mailto:Tom.Mulholland at health.wa.gov.au>
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From pgrandeau at wanadoo.fr  Wed May 14 09:37:29 2003
From: pgrandeau at wanadoo.fr (Pascal Grandeau)
Date: Wed, 14 May 2003 09:37:29 +0200
Subject: [R] How to speed R with triangular matrix
Message-ID: <000001c319eb$ac71bd50$0100a8c0@MEDION24GHZ>

Dear r-help,

I want to solve an equation XR=B where R is a regular 10x10 upper
triangular matrix and B a 100x10 matrix. I do X=B%*%solve(R) which work
well but I need to do this operation a great number of time and this is
very long. With my pentium 2.4 GHz,  Windows XP and R 1.7.0, I do this
100000 times in 58 seconds (for comparaison Scilab take 22 seconds and
Matlab only 8 seconds to do the same thing). So, I try backsolve with
X=t(backsolve(R,t(B),transpose=TRUE)) or X=t(backsolve(t(R),t(B))) but
this is longer (more than 1 minute 10).

Is there a mean to to this more rapidly with R ? 

Thank you very much

P. Grandeau

---



From gb at stat.umu.se  Wed May 14 09:59:13 2003
From: gb at stat.umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Wed, 14 May 2003 09:59:13 +0200 (CEST)
Subject: [R] Two names of a function
Message-ID: <Pine.LNX.4.44.0305140952040.5919-100000@tal.stat.umu.se>


Is it possible to let a function be known under two names without having
two identical copies of the function body? 

---
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se



From kwan022 at stat.auckland.ac.nz  Wed May 14 09:57:25 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Wed, 14 May 2003 19:57:25 +1200 (NZST)
Subject: [R] Two names of a function
In-Reply-To: <Pine.LNX.4.44.0305140952040.5919-100000@tal.stat.umu.se>
Message-ID: <Pine.LNX.4.44.0305141957060.21508-100000@stat56.stat.auckland.ac.nz>

Do you mean something like:
> sq <- function(x) x^2
> sq(2)
[1] 4
> sq(9)
[1] 81
> sq1 <- sq
> sq1(9)
[1] 81


On Wed, 14 May 2003, G?ran Brostr?m wrote:

> Date: Wed, 14 May 2003 09:59:13 +0200 (CEST)
> From: G?ran Brostr?m <gb at stat.umu.se>
> To: R-help <r-help at stat.math.ethz.ch>
> Subject: [R] Two names of a function
> 
> 
> Is it possible to let a function be known under two names without having
> two identical copies of the function body? 
> 
> ---
>  G?ran Brostr?m                    tel: +46 90 786 5223
>  Department of Statistics          fax: +46 90 786 6614
>  Ume? University                   http://www.stat.umu.se/egna/gb/
>  SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)



From ripley at stats.ox.ac.uk  Wed May 14 10:04:40 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 14 May 2003 09:04:40 +0100 (BST)
Subject: [R] Two names of a function
In-Reply-To: <Pine.LNX.4.44.0305140952040.5919-100000@tal.stat.umu.se>
Message-ID: <Pine.LNX.4.44.0305140859110.23605-100000@gannet.stats>

On Wed, 14 May 2003, G?ran Brostr?m wrote:

> Is it possible to let a function be known under two names without having
> two identical copies of the function body? 

Well, that's what .Alias did (have one copy), and it has been removed.  
There's nothing to stop you writing a version of .Alias via .Call, except
there were good reasons to remove it.  Given that, perhaps you should ask
what how to do what you really want to do (the top-level task that
prompted this question).

I don't think you can even know if there are two copies of the function 
body: there can be potential copies of R objects which are shared until 
one is altered.  I would have to read the internal code very carefully to 
find out if e.g. body<- made an actual copy.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From gb at stat.umu.se  Wed May 14 10:20:36 2003
From: gb at stat.umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Wed, 14 May 2003 10:20:36 +0200 (CEST)
Subject: [R] Two names of a function
In-Reply-To: <Pine.LNX.4.44.0305141957060.21508-100000@stat56.stat.auckland.ac.nz>
Message-ID: <Pine.LNX.4.44.0305141011260.5951-100000@tal.stat.umu.se>

On Wed, 14 May 2003, Ko-Kang Kevin Wang wrote:

> Do you mean something like:
> > sq <- function(x) x^2
> > sq(2)
> [1] 4
> > sq(9)
> [1] 81
> > sq1 <- sq
> > sq1(9)
> [1] 81

No, you are taking a copy of the function. I'm thinking in the lines of

1. an 'alias' mechanism: sq1 <- function() alias(sq), or

2. sq1 calling sq: sq1 <- function(x) sq(x)

but 2. must be done more sophisticated. I foresee problems with 
environments and passing the argument list.

G?ran

> 
> 
> On Wed, 14 May 2003, G?ran Brostr?m wrote:
> 
> > Date: Wed, 14 May 2003 09:59:13 +0200 (CEST)
> > From: G?ran Brostr?m <gb at stat.umu.se>
> > To: R-help <r-help at stat.math.ethz.ch>
> > Subject: [R] Two names of a function
> > 
> > 
> > Is it possible to let a function be known under two names without having
> > two identical copies of the function body? 
> > 
> > ---
> >  G?ran Brostr?m                    tel: +46 90 786 5223
> >  Department of Statistics          fax: +46 90 786 6614
> >  Ume? University                   http://www.stat.umu.se/egna/gb/
> >  SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > 
> 
> 

-- 
---
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se



From gb at stat.umu.se  Wed May 14 10:29:15 2003
From: gb at stat.umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Wed, 14 May 2003 10:29:15 +0200 (CEST)
Subject: [R] Two names of a function
In-Reply-To: <Pine.LNX.4.44.0305140859110.23605-100000@gannet.stats>
Message-ID: <Pine.LNX.4.44.0305141022090.5951-100000@tal.stat.umu.se>

On Wed, 14 May 2003, Prof Brian Ripley wrote:

> On Wed, 14 May 2003, G?ran Brostr?m wrote:
> 
> > Is it possible to let a function be known under two names without having
> > two identical copies of the function body? 
> 
> Well, that's what .Alias did (have one copy), and it has been removed.  
> There's nothing to stop you writing a version of .Alias via .Call, except
> there were good reasons to remove it.  Given that, perhaps you should ask
> what how to do what you really want to do (the top-level task that
> prompted this question).

The reason is backward compability; I'm rewriting an R package, changing a 
few function names (for good reasons). I may better use the way 'optimise' 
and 'optimize' do it; two identical wrappers to a common function.

Thanks,

G?ran
 
> 
> I don't think you can even know if there are two copies of the function 
> body: there can be potential copies of R objects which are shared until 
> one is altered.  I would have to read the internal code very carefully to 
> find out if e.g. body<- made an actual copy.
> 
>



From B.Rowlingson at lancaster.ac.uk  Wed May 14 11:37:32 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 14 May 2003 10:37:32 +0100
Subject: [R] Some Programming Humor
In-Reply-To: <6rr8725pnw.fsf@bates4.stat.wisc.edu>
References: <6rvfwe5qob.fsf@bates4.stat.wisc.edu>
	<6rr8725pnw.fsf@bates4.stat.wisc.edu>
Message-ID: <3EC20E5C.5080201@lancaster.ac.uk>

Douglas Bates wrote:
> Douglas Bates <bates at cs.wisc.edu> writes:
> 
> 
>>I checked and R is one of the 515 languages mentioned in the enclosed.
> 

  Very nice. But where's the S version? :)

  On a similar note, has anyone written a quine in R? Its defined here:

  http://www.nyx.net/~gthompso/quine.htm

as a program that reproduces itself on an output device without 
inputting its source. There are examples in many languages, but I dont 
see R or S.

For R I think that would mean that:

   R --slave <quine.R >quined.R

  produces quined.R as an identical file to quine.R

  You could probably also have an R quine on a functional level, such that:

  quined <- quine()

  returns 'quined' as an identical function to 'quine'.

The rule about not inputting the source rules out the use of 'get' in R, 
as in:

 > quine <- function(){get("quine")}

  Which is a quine:

 > quine()
function(){get("quine")}
 > quine
function(){get("quine")}

  Anyone up for a challenge?

Baz



From dieter.menne at menne-biomed.de  Wed May 14 11:39:14 2003
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Wed, 14 May 2003 11:39:14 +0200
Subject: [R] Multiple comparison and lme (again, sorry)
Message-ID: <JLEPLGAANFCEAEDCAGJNEEBNCFAA.dieter.menne@menne-biomed.de>

Dear list,

As a reply to my recent mail:

> simint and TukeyHSD work for aov objects.
> Can someone point me to similar functions for lme objects?

Douglas Bates wrote

There aren't multiple comparison methods for lme objects because it is
not clear how to do multiple comparisons for these.  I don't think the
theory of multiple comparisons extends easily to lme models.  One
could use approximations but it is not clear how good the
approximations are.
--------

This should serve as a warning, but let's assume I can live with "only
approximations".

In another thread, Thorsten Hothorn suggested for glm (slightly edited)

library(multcomp)
set.seed(290875)
# a factor at three levels
group <- factor(c(rep(1,10), rep(2, 10), rep(3,10)))
# Williams contrasts
contrasts(group)<-zapsmall(mginv(contrMat(table(group), type="Will")))
# a binary response
z <- factor(rbinom(30, 1, 0.5))
# estimate the model
gmod <- glm( z ~ group, family=binomial(link = "logit"))
summary(gmod)
# exclude the intercept

# Should be the following, but does not work due to a confirmed
# bug in the CRAN-binary version 5.10
#summary(csimtest(coef(gmod)[2:3], vcov(gmod)[2:3,2:3],
#                 cmatrix=diag(2), df=27,asympt=T))
summary(csimtest(coef(gmod)[2:3], vcov(gmod)[2:3,2:3],
                 cmatrix=diag(2), df=27))

-------
This works and can be extended to to lme, but only gives TWO of the three
possible Tukey contrasts. Setting type="Tukey" does not work, as by
assigning to
contrasts(group) only two independent columns are copied (which makes
sense).

# Can someone help me out with the example below: I need P-T1, P-T2, T1-T2

library(nlme)
library(multcomp)
set.seed(701)
sub<-rnorm(50,0,2.0) # subjects random
vr<-0.2
response<-c(rnorm(50,0,vr)+sub,rnorm(50,2,vr)+sub,rnorm(50,3,vr)+sub)
treat<-factor(c(rep("P",50),rep("T1",50),rep("T2",50)))
subj<-factor(rep(1:50,3))
# The following only gives me 2 (instead of 3) contrasts
#contrasts(treat)<-zapsmall(mginv(contrMat(c(50,50,50), type="Tukey")))
example<-data.frame(response, treat, subj)
example.lme<-lme(response~treat, data=example, random=~1|subj)
summary(example.lme)

#summary(csimtest.....)



From i.wilson at maths.abdn.ac.uk  Wed May 14 12:39:37 2003
From: i.wilson at maths.abdn.ac.uk (Ian Wilson)
Date: Wed, 14 May 2003 11:39:37 +0100
Subject: [R] Some Programming Humor
In-Reply-To: <3EC20E5C.5080201@lancaster.ac.uk>
Message-ID: <HJEIKCALHCOJAGKCPKHBGEFFCBAA.i.wilson@maths.abdn.ac.uk>



Douglas Bates wrote:
> Douglas Bates <bates at cs.wisc.edu> writes:
> 
> 
>>I checked and R is one of the 515 languages mentioned in the enclosed.
> 

  Very nice. But where's the S version? :)

The "R" version used a loop - so it could not really be called S ;)

How about

cat(paste(n <- 99:1,a <- "bottles of beer",b <- "on the wall,\n"
,n,a,"take one down, pass it around,\n",n-1,a,b,"\n"))



From djw1005 at cam.ac.uk  Wed May 14 13:19:39 2003
From: djw1005 at cam.ac.uk (Damon Wischik)
Date: Wed, 14 May 2003 12:19:39 +0100 (BST)
Subject: [R] <-
In-Reply-To: <3EC1E4DB.3060100@statistik.uni-dortmund.de>
Message-ID: <Pine.SOL.3.96.1030514121147.18819A-100000@draco.cus.cam.ac.uk>


Uwe Ligges wrote:
> Perl experts might do it differently, but the "R way" seems to be
>   substring(x, 1, 1) <- toupper(substring(x, 1, 1))
>   substring(x, 2) <- tolower(substring(x, 2))

I hadn't come across this use of substring on the left hand side of <-
before. Now, of course, I see it explained on the help page for substr.

What other special functions can appear on the left hand side of <-? Is
there anywhere I can look to find a list? I've come across
  vector[vector of logicals] <- 
  vector[vector of integers] <- 
  data.frame[] <-

One thing I would find very handy is a shortcut for
  res <- myfunc()
  a <- res$val1
  b <- res$val2
Something along the lines of
  list(a=val1,b=val2) <- myfunc()
but I don't know what the right syntax would be or how I'd go about
programming it. Any suggestions?

Damon Wischik.



From Torsten.Hothorn at rzmail.uni-erlangen.de  Wed May 14 13:28:06 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Wed, 14 May 2003 13:28:06 +0200 (CEST)
Subject: [R] Multiple comparison and lme (again, sorry)
In-Reply-To: <200305141004.h4EA1L6w027408@hypatia.math.ethz.ch>
References: <200305141004.h4EA1L6w027408@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.51.0305141255320.26374@artemis.imbe.med.uni-erlangen.de>

> Message: 64
> Date: Wed, 14 May 2003 11:39:14 +0200
> From: "Dieter Menne" <dieter.menne at menne-biomed.de>
> Subject: [R] Multiple comparison and lme (again, sorry)
> To: "R-Help" <r-help at stat.math.ethz.ch>
> Message-ID:
> 	<JLEPLGAANFCEAEDCAGJNEEBNCFAA.dieter.menne at menne-biomed.de>
> Content-Type: text/plain;   charset="iso-8859-1"
>
> Dear list,
>
> As a reply to my recent mail:
>
> > simint and TukeyHSD work for aov objects.
> > Can someone point me to similar functions for lme objects?
>
> Douglas Bates wrote
>
> There aren't multiple comparison methods for lme objects because it is
> not clear how to do multiple comparisons for these.  I don't think the
> theory of multiple comparisons extends easily to lme models.  One
> could use approximations but it is not clear how good the
> approximations are.
> --------
>
> This should serve as a warning, but let's assume I can live with "only
> approximations".
>
> In another thread, Thorsten Hothorn suggested for glm (slightly edited)
>
> library(multcomp)
> set.seed(290875)
> # a factor at three levels
> group <- factor(c(rep(1,10), rep(2, 10), rep(3,10)))
> # Williams contrasts
> contrasts(group)<-zapsmall(mginv(contrMat(table(group), type="Will")))
> # a binary response
> z <- factor(rbinom(30, 1, 0.5))
> # estimate the model
> gmod <- glm( z ~ group, family=binomial(link = "logit"))
> summary(gmod)
> # exclude the intercept
>
> # Should be the following, but does not work due to a confirmed
> # bug in the CRAN-binary version 5.10
> #summary(csimtest(coef(gmod)[2:3], vcov(gmod)[2:3,2:3],
> #                 cmatrix=diag(2), df=27,asympt=T))
> summary(csimtest(coef(gmod)[2:3], vcov(gmod)[2:3,2:3],
>                  cmatrix=diag(2), df=27))

`asympt = TRUE' must be there for a logistic regression model and
it works with mvtnorm_0.5-12 (on CRAN).

>
> -------
> This works and can be extended to to lme, but only gives TWO of the three
> possible Tukey contrasts. Setting type="Tukey" does not work, as by
> assigning to
> contrasts(group) only two independent columns are copied (which makes
> sense).
>
> # Can someone help me out with the example below: I need P-T1, P-T2, T1-T2
>
> library(nlme)
> library(multcomp)
> set.seed(701)
> sub<-rnorm(50,0,2.0) # subjects random
> vr<-0.2
> response<-c(rnorm(50,0,vr)+sub,rnorm(50,2,vr)+sub,rnorm(50,3,vr)+sub)
> treat<-factor(c(rep("P",50),rep("T1",50),rep("T2",50)))
> subj<-factor(rep(1:50,3))
> # The following only gives me 2 (instead of 3) contrasts
> #contrasts(treat)<-zapsmall(mginv(contrMat(c(50,50,50), type="Tukey")))

you need to specify the `how.many' argument:

 ## need to specify how.many
R> contrasts(treat,how.many = 3) <- zapsmall(
                                    mginv(contrMat(table(treat),
                                                   type="Tukey")))

R> attr(treat, "contrasts")
         T1-P       T2-P      T2-T1
P  -0.3333333 -0.3333333  0.0000000
T1  0.3333333  0.0000000 -0.3333333
T2  0.0000000  0.3333333  0.3333333

 ## however, this will not work!
R> example.lme<-lme(response~treat, random=~1|subj)
Error in MEEM(object, conLin, control$niterEM) :
        Singularity in backsolve at level 0, block 1

The problem is a basic one: AFAIK, none of the `model.fit' functions deals
with singular design matrices without additional work (have a look at
TukeyHSD for what that means) as induced for example by Tukey contrasts
(I would be happy to be wrong here).

And that is the reason why we can't use `lm.fit' for parameter estimation
for arbitrary contrasts within `multcomp'. The `multcomp' package, as a
workaround, estimates the parameters of a linear model (!) via the
Moore-Penrose inverse.

For all other models, we currently only offer a low-level interface
(`csim{int,test}') which assumes that the
parameters / contrasts and their covariance matrix are there. As long as
those values can be computed via `coef' and `vcov', everything is fine
(and we are currently working on methods for `lm' and `glm' to the
`simint' and `simtest' generics). If not, as it is the case here, there
is no general solution (and I can't answer this particular question).


Best,

Torsten

> example<-data.frame(response, treat, subj)
> example.lme<-lme(response~treat, data=example, random=~1|subj)
> summary(example.lme)
>
> #summary(csimtest.....)
>
>
> ------------------------------
>
> _______________________________________________
> R-help at stat.math.ethz.ch mailing list  DIGESTED
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
> End of R-help Digest, Vol 3, Issue 14
> *************************************
>
>



From john_hendrickx at yahoo.com  Wed May 14 13:37:00 2003
From: john_hendrickx at yahoo.com (John Hendrickx)
Date: Wed, 14 May 2003 04:37:00 -0700 (PDT)
Subject: [R] mcl models, percentages
Message-ID: <20030514113700.51782.qmail@web14202.mail.yahoo.com>

I've put two packages for R on my home page at
http://www.xs4all.nl/~jhckx/R/. The "pcnt" package is for multiway
percentage tables. I've posted a first effort called "ctab" on this
group and a request for enhancing "ftable" with percentages on the
wishlist.

The "mcl" package is for estimating multinomial logistic models using
conditional logistic regression. This gives greater flexibility in
imposing restrictions on the dependent variable. One application is
to estimate loglinear models for sqaure tables (e.g.
quasi-independence, quasi-symmetry) with covariates. The mcl package
therefore contains a number of functions for models for square tables
as well.

A caveat is that "clogit" in R doesn't produce the same estimates as
"multilog", although the likelihood functions for both models are the
same. The maximum absolute difference is 0.0034, the mean absolute
difference is 0.00069. Stata's "clogit" and "mlogit" produce the same
estimates and match those of "multilog" to at least 6 decimal points
accuracy. See the notes in http://www.xs4all.nl/~jhckx/R/mcl.html Can
anyone shed any light on this?

John Hendrickx



From ripley at stats.ox.ac.uk  Wed May 14 13:38:15 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 14 May 2003 12:38:15 +0100 (BST)
Subject: [R] <-
In-Reply-To: <Pine.SOL.3.96.1030514121147.18819A-100000@draco.cus.cam.ac.uk>
Message-ID: <Pine.LNX.4.44.0305141228320.25531-100000@gannet.stats>

These are called `replacement functions', or sometimes `assignment
functions'.  Leaving aside S4 methods (set by setReplaceMethod), they all
end in "<-", as the first quoted example is actually evaluated as 
something very close to

x <- "substring<-"(x, 1, 1, toupper(substring(x, 1, 1)))

In the base package there are

> ls(NULL, patt="<-$")
 [1] "$<-"                "<-"                 "<<-"
 [4] "[<-"                "[[<-"               "attr<-"
 [7] "attributes<-"       "body<-"             "class<-"
[10] "codes<-"            "colnames<-"         "comment<-"
[13] "contrasts<-"        "diag<-"             "dim<-"
[16] "dimnames<-"         "environment<-"      "formals<-"
[19] "is.na<-"            "length<-"           "levels<-"
[22] "mode<-"             "mostattributes<-"   "names<-"
[25] "oldClass<-"         "parent.env<-"       "row.names<-"
[28] "rownames<-"         "split.data.frame<-" "split<-"
[31] "storage.mode<-"     "substr<-"           "substring<-"
[34] "tsp<-"

(and some methods; "split.data.frame<-" is a mistake and codes<- is 
deprecated in R-devel).

But users can write them as well, and there are some in the methods 
package.

On Wed, 14 May 2003, Damon Wischik wrote:

> 
> Uwe Ligges wrote:
> > Perl experts might do it differently, but the "R way" seems to be
> >   substring(x, 1, 1) <- toupper(substring(x, 1, 1))
> >   substring(x, 2) <- tolower(substring(x, 2))
> 
> I hadn't come across this use of substring on the left hand side of <-
> before. Now, of course, I see it explained on the help page for substr.
> 
> What other special functions can appear on the left hand side of <-? Is
> there anywhere I can look to find a list? I've come across
>   vector[vector of logicals] <- 
>   vector[vector of integers] <- 
>   data.frame[] <-
> 
> One thing I would find very handy is a shortcut for
>   res <- myfunc()
>   a <- res$val1
>   b <- res$val2
> Something along the lines of
>   list(a=val1,b=val2) <- myfunc()
> but I don't know what the right syntax would be or how I'd go about
> programming it. Any suggestions?
> 
> Damon Wischik.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From michael.seewald at vie.boehringer-ingelheim.com  Wed May 14 13:53:51 2003
From: michael.seewald at vie.boehringer-ingelheim.com (michael.seewald@vie.boehringer-ingelheim.com)
Date: Wed, 14 May 2003 13:53:51 +0200
Subject: [R] ROracle problem with Oracle9i on Red Hat 8.0
Message-ID: <AF7DB4C757D2D2119C080001FA7E56B205A2CAF4@VIEEXCH2.vie.at.bic>


Hi,

I have a problem executing "library(ROracle)" in R:

OS/Software:
Redhat 8.0, all available patches applied
Oracle 9i v9.2.0.1.0
R v1.7.0
ROracle v0.5-0
DBI v0.1-5

The compilation and installation of ROracle went fine. However when I try to
load ROracle I get the following:
>> library(ROracle)
>Error in dyn.load(x, as.logical(local), as.logical(now)) :
>        unable to load shared library
"/home/michael/software/R/R-1.7.0/library/ROracle/libs/ROracle.so":
>  /home/michael/software/R/R-1.7.0/library/ROracle/libs/ROracle.so:
undefined symbol: sqlca
>Error in library(ROracle) : .First.lib failed

The 2 solutions mentioned in ROracle/inst/INSTALL don't seem to help (1:
define $LD_LIBRARY_PATH, 2: compile statically).

Is there any solution to this? I would greatly appreciate any help!!

Best wishes,
Michael Seewald

---
Michael Seewald, PhD
Boehringer Ingelheim Austria
Dept NCE Lead Discovery - Bioinformatics
Dr. Boehringergasse 5-11
A-1121 Vienna, Austria
Tel.: ++43-1-80105-2786
Fax: ++43-1-80105-2683
email: Michael.Seewald at vie.boehringer-ingelheim.com



From dsjoerg at yahoo.com  Wed May 14 14:49:16 2003
From: dsjoerg at yahoo.com (David Joerg)
Date: Wed, 14 May 2003 08:49:16 -0400
Subject: [R] regression in batches?
Message-ID: <DB30501EDA9FE34CB686A124032C127EF61782@mxgbl1.twosigma.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030514/5dcda05b/attachment.pl

From dsjoerg at yahoo.com  Wed May 14 14:49:16 2003
From: dsjoerg at yahoo.com (David Joerg)
Date: Wed, 14 May 2003 08:49:16 -0400
Subject: [R] regression in batches?
Message-ID: <DB30501EDA9FE34CB686A124032C127E37715D@mxgbl1.twosigma.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030514/d76c9d4f/attachment.pl

From p.dalgaard at biostat.ku.dk  Wed May 14 14:59:36 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed, 14 May 2003 12:59:36 -0000
Subject: [R] Some Programming Humor
In-Reply-To: <HJEIKCALHCOJAGKCPKHBGEFFCBAA.i.wilson@maths.abdn.ac.uk>
References: <HJEIKCALHCOJAGKCPKHBGEFFCBAA.i.wilson@maths.abdn.ac.uk>
Message-ID: <x2smrhfzn0.fsf@biostat.ku.dk>

"Ian Wilson" <i.wilson at maths.abdn.ac.uk> writes:

> Douglas Bates wrote:
> > Douglas Bates <bates at cs.wisc.edu> writes:
> > 
> > 
> >>I checked and R is one of the 515 languages mentioned in the enclosed.
> > 
> 
>   Very nice. But where's the S version? :)
> 
> The "R" version used a loop - so it could not really be called S ;)
> 
> How about
> 
> cat(paste(n <- 99:1,a <- "bottles of beer",b <- "on the wall,\n"
> ,n,a,"take one down, pass it around,\n",n-1,a,b,"\n"))

Do we guarantee left-to-right evaluation?

Here's my old version:

f <- function(n) structure(c(paste(c(n,n,n-1),
     "bottles of beer",c("on the wall","")),
     "take one down, pass it around")[c(1,2,4,3)], class="verse")
print.verse <- function(x,...) cat(x, sep="\n")
lapply(99:1, f)

(It's an open question what to strive for in these examples. My tack
was that it should highlight features of the language, so I threw in
lapply, (S3) methods, and smart indexing...) 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From H.RINNER at tirol.gv.at  Wed May 14 15:01:58 2003
From: H.RINNER at tirol.gv.at (RINNER Heinrich)
Date: Wed, 14 May 2003 15:01:58 +0200
Subject: [R] number of patients in a hospital on a given date
Message-ID: <C4D44AB4CB62D311BA6500041202E886031EE204@xms1.tirol.gv.at>

Dear R-users!

I am using R 1.7.0, under Windows XP.

Having some hospital discharge data (admission date and discharge date for
each patient), I want to get the number of patients in the hospital on a
given date.

My data look like (simple example):
> x <- data.frame(patid=c("pat1", "pat2"), adm.date = c("15.03.2002",
"16.03.2002"),
       dis.date=c("18.03.2002", "17.03.2002"))

I can easily do a date-time conversion from the character objects: 
> x[,2:3] <- apply(x[,2:3], MARGIN=2, FUN=strptime, format="%d.%m.%Y")
> x
  patid   adm.date   dis.date
1  pat1 2002-03-15 2002-03-18
2  pat2 2002-03-16 2002-03-17

What I want in the end is something like a data.frame A like this:
A
date		no.of.patients
2002-03-14	0
2002-03-15	1
2002-03-16	2
2002-03-17	2
2002-03-18	1
2002-03-19	0

Or, alternatively, a data.frame B like this:
B
patid	date.in.hospital
pat1	2002-03-15
pat1	2002-03-16
pat1	2002-03-17
pat1	2002-03-18
pat2	2002-03-16
pat2	2002-03-17

>From this I could easily get A by using "table".
So the trick would be to get a data.frame with one line for each day of each
patient in the hospital - but how?

I'd be happy about any ideas,
Heinrich Rinner.



From roger at ysidro.econ.uiuc.edu  Wed May 14 15:09:57 2003
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Wed, 14 May 2003 08:09:57 -0500 (CDT)
Subject: [R] regression in batches?
In-Reply-To: <DB30501EDA9FE34CB686A124032C127EF61782@mxgbl1.twosigma.com>
Message-ID: <Pine.SOL.4.30.0305140808220.21180-100000@ysidro.econ.uiuc.edu>

You could try the non-CRAN package LM see: http://www.econ.uiuc.edu/~roger/research/rq/LM.html
which uses RMySQL...


url:	www.econ.uiuc.edu	Roger Koenker		Dept. of Economics UCL,
email	rkoenker at uiuc.edu	Department of Economics Drayton House,
vox: 	217-333-4558		University of Illinois	30 Gordon St,
fax:   	217-244-6678		Champaign, IL 61820	London,WC1H 0AX, UK
							vox:	020-7679-5838

On Wed, 14 May 2003, David Joerg wrote:

> Hello, I have a data set that's too large to load into memory all at
> once to do a simple linear regression on.  What would be a good way to
> do a piecewise (batch) regression on it in R?  I've started reading the
> docs and FAQs and haven't found anything yet that would suggest how to
> do this, aside from diving into the guts of lm().
>
> Thanks and regards--!
>
> David Joerg
>
> dsjoerg at yahoo.com
>
>
>
>
> 	[[alternate HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From dj at research.bell-labs.com  Wed May 14 15:09:59 2003
From: dj at research.bell-labs.com (David James)
Date: Wed, 14 May 2003 09:09:59 -0400
Subject: [R] ROracle problem with Oracle9i on Red Hat 8.0
In-Reply-To: <AF7DB4C757D2D2119C080001FA7E56B205A2CAF4@VIEEXCH2.vie.at.bic>;
	from michael.seewald@vie.boehringer-ingelheim.com on Wed, May 14,
	2003 at 01:53:51PM +0200
References: <AF7DB4C757D2D2119C080001FA7E56B205A2CAF4@VIEEXCH2.vie.at.bic>
Message-ID: <20030514090959.B10679@jessie.research.bell-labs.com>

Hmm. I don't have (easy) access to Oracle9i, but I'd try to find
out whether the client library is indeed in the $ORACLE_HOME/lib
directory.  (I think the file name is something like "libclntst9.xx"
where xx may be "so" or "a").  Don MacQueen reported a similar
problem on Mac OS X, and he posted a workaround on the r-sig-mac list
on 7 Feb 2003.  I'm including here the relevant part of his posting:


DM = Don MacQueen

DM> The first work around is this:
DM> 
DM> cp  $ORACLE_HOME/rdbms/lib/libclntst9.a $ORACLE_HOME/lib
DM> cd $ORACLE_HOME/lib
DM> ranlib -s libclntst9.a
DM> 
DM> (look in the file $ORACLE_HOME/precomp/lib/env_precomp.mk for 
DM> references to libclntst9.a)
DM> 
DM> The absence of libclntst9.a in $ORACLE_HOME/lib may represent an 
DM> error in the Oracle distribution, or it may represent a lack of 
DM> understanding on my part.
DM> 

--
David

michael.seewald at vie.boehringer-ingelheim.com wrote:
> 
> Hi,
> 
> I have a problem executing "library(ROracle)" in R:
> 
> OS/Software:
> Redhat 8.0, all available patches applied
> Oracle 9i v9.2.0.1.0
> R v1.7.0
> ROracle v0.5-0
> DBI v0.1-5
> 
> The compilation and installation of ROracle went fine. However when I try to
> load ROracle I get the following:
> >> library(ROracle)
> >Error in dyn.load(x, as.logical(local), as.logical(now)) :
> >        unable to load shared library
> "/home/michael/software/R/R-1.7.0/library/ROracle/libs/ROracle.so":
> >  /home/michael/software/R/R-1.7.0/library/ROracle/libs/ROracle.so:
> undefined symbol: sqlca
> >Error in library(ROracle) : .First.lib failed
> 
> The 2 solutions mentioned in ROracle/inst/INSTALL don't seem to help (1:
> define $LD_LIBRARY_PATH, 2: compile statically).
> 
> Is there any solution to this? I would greatly appreciate any help!!
> 
> Best wishes,
> Michael Seewald
> 
> ---
> Michael Seewald, PhD
> Boehringer Ingelheim Austria
> Dept NCE Lead Discovery - Bioinformatics
> Dr. Boehringergasse 5-11
> A-1121 Vienna, Austria
> Tel.: ++43-1-80105-2786
> Fax: ++43-1-80105-2683
> email: Michael.Seewald at vie.boehringer-ingelheim.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
David A. James
Statistics Research, Room 2C-253            Phone:  (908) 582-3082       
Bell Labs, Lucent Technologies              Fax:    (908) 582-3340
Murray Hill, NJ 09794-0636



From sandrine.mainard1 at etud.univ-ubs.fr  Wed May 14 15:28:45 2003
From: sandrine.mainard1 at etud.univ-ubs.fr (sandrine.mainard1@etud.univ-ubs.fr)
Date: Wed, 14 May 2003 15:28:45 +0200
Subject: [R] mt.plot
Message-ID: <1052918925.3ec2448d52fda@homae.univ-ubs.fr>

Hello,

One more time,i have a question about a function in multtest!
I'm wondering how change the xlim and ylim when i use the mt.plot. Because it 
doesn't work if i want to have the legend too.And i have another question about 
mt.plot:
- How do you explain the results of the mt.plot with the option "rvsa"? because 
i have calculate with a programm how many rejected hypotheses there are ,and i 
find the same results on graph if i say that is a cumulative distribution graph
(repartition).I don't know if that's right!
- How can i oblige R to make more tickmarks between the main tickmarks which 
have already drawn?
I'm apologize to annoy you nearly every day!!!!
Thanks a lot
Sandrine mainard




--------------------------------------------------------------------------------
Universit de Bretagne sud                               http://www.univ-ubs.fr/



From maechler at stat.math.ethz.ch  Wed May 14 15:39:10 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 14 May 2003 15:39:10 +0200
Subject: [R] expand.grid
In-Reply-To: <200305032348.49124.gmm@ds.unifi.it>
References: <200305032348.49124.gmm@ds.unifi.it>
Message-ID: <16066.18174.638928.790645@gargle.gargle.HOWL>

>>>>> "Giovanni" == Giovanni Marchetti <gmm at ds.unifi.it>
>>>>>     on Sat, 3 May 2003 23:48:48 +0000 writes:

    Giovanni> I recently posted a question concerning an
    Giovanni> inconsistency of expand.grid in defining the
    Giovanni> reference level of the factors.

    > > expand.grid(x = c("b", "a"), y = c(1, 2))$x
    > [1] b a b a
    > Levels: b a            # reference level is b
    > > expand.grid(x = c("b", "a"))$x
    > [1] b a
    > Levels: a b            # reference level is a

    Giovanni> Thank you very much for the ready explanations and
    Giovanni> comments.

    Giovanni> I found this inconsistency working with
    Giovanni> contingency tables and logistic models.

Ciao Giovanni,

I've forgotten to tell you (and the audience) that this has been
chnaged in R-patched (to be 1.7.1) where 
expand.grid(x1) and expand.grid(x1,x2) will be consistent.

Thank you for your posting!
Martin



From gerds at fdm.uni-freiburg.de  Wed May 14 16:18:36 2003
From: gerds at fdm.uni-freiburg.de (Thomas Gerds)
Date: Wed, 14 May 2003 16:18:36 +0200
Subject: [R] number of patients in a hospital on a given date
In-Reply-To: <C4D44AB4CB62D311BA6500041202E886031EE204@xms1.tirol.gv.at>
	(RINNER Heinrich's message of "Wed, 14 May 2003 15:01:58 +0200")
References: <C4D44AB4CB62D311BA6500041202E886031EE204@xms1.tirol.gv.at>
Message-ID: <7evfwd3937.fsf@rembrandt.fdm.uni-freiburg.de>

how about this:

x <- data.frame(patid=c("pat1", "pat2"), adm.date = c("15.03.2002","16.03.2002"),dis.date=c("18.03.2002", "17.03.2002"))
x[,2:3] <- apply(x[,2:3], MARGIN=2, FUN=strptime, format="%d.%m.%Y")
alldays <- c("2002-03-14","2002-03-15","2002-03-16","2002-03-17","2002-03-18","2002-03-19")
tmp <- table(unlist(apply(x,
                          1,
                          function(y){
                            beg <- match(y[2],alldays)
                            end <- match(y[3],alldays)
                            alldays[beg:end]})))
nulldays <- alldays[match(alldays,names(tmp),nomatch=0)==0]
out <- rbind(data.frame(days=c(names(tmp),nulldays),freq=c(as.numeric(tmp),rep(0,length(nulldays)))))
out[order(out$days),]

        days freq
5 2002-03-14    0
1 2002-03-15    1
2 2002-03-16    2
3 2002-03-17    2
4 2002-03-18    1
6 2002-03-19    0

tomy

RINNER Heinrich <H.RINNER at tirol.gv.at> writes:

> Dear R-users!
>
> I am using R 1.7.0, under Windows XP.
>
> Having some hospital discharge data (admission date and discharge date for
> each patient), I want to get the number of patients in the hospital on a
> given date.
>
> My data look like (simple example):
>> x <- data.frame(patid=c("pat1", "pat2"), adm.date = c("15.03.2002",
> "16.03.2002"),
>        dis.date=c("18.03.2002", "17.03.2002"))
>
> I can easily do a date-time conversion from the character objects: 
>> x[,2:3] <- apply(x[,2:3], MARGIN=2, FUN=strptime, format="%d.%m.%Y")
>> x
>   patid   adm.date   dis.date
> 1  pat1 2002-03-15 2002-03-18
> 2  pat2 2002-03-16 2002-03-17
>
> What I want in the end is something like a data.frame A like this:
> A
> date		no.of.patients
> 2002-03-14	0
> 2002-03-15	1
> 2002-03-16	2
> 2002-03-17	2
> 2002-03-18	1
> 2002-03-19	0
>
> Or, alternatively, a data.frame B like this:
> B
> patid	date.in.hospital
> pat1	2002-03-15
> pat1	2002-03-16
> pat1	2002-03-17
> pat1	2002-03-18
> pat2	2002-03-16
> pat2	2002-03-17
>
>>From this I could easily get A by using "table".
> So the trick would be to get a data.frame with one line for each day of each
> patient in the hospital - but how?
>
> I'd be happy about any ideas,
> Heinrich Rinner.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
no signature



From f.mattes at rfc.ucl.ac.uk  Wed May 14 16:25:57 2003
From: f.mattes at rfc.ucl.ac.uk (Frank Mattes)
Date: Wed, 14 May 2003 15:25:57 +0100
Subject: [R] building mean/median over subgroups
Message-ID: <p05200f00bae8001643f9@[128.40.218.142]>

Dear all,

I'm trying to solve the following problem, and hoping to get some 
advise here from the group

I have a dataframe in which the same sample was measured more than 
once on the same day. I would reorganize the dataframe to get a 
single value (mean /median) for one day

Patient	Day	Sample	Test
A	1	A	23
A	1	A	36
A	5	B	44
A	5	B	23
B	2	C	10
B	2	C	5


mean

Patient	Day	Sample	Test.mean
A	1	A	29.5
A	5	A	33.5
B	2	C	7.5


it would be great to get some help form the list.

Yours
Frank
-- 
Frank Mattes, MD			e-mail:	f.mattes at ucl.ac.uk



From spencer.graves at pdf.com  Wed May 14 17:00:59 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 14 May 2003 08:00:59 -0700
Subject: [R] building mean/median over subgroups
References: <p05200f00bae8001643f9@[128.40.218.142]>
Message-ID: <3EC25A2B.2030803@pdf.com>

Have you considered "sapply"?

hth.  spencer graves

Frank Mattes wrote:
> Dear all,
> 
> I'm trying to solve the following problem, and hoping to get some advise 
> here from the group
> 
> I have a dataframe in which the same sample was measured more than once 
> on the same day. I would reorganize the dataframe to get a single value 
> (mean /median) for one day
> 
> Patient    Day    Sample    Test
> A    1    A    23
> A    1    A    36
> A    5    B    44
> A    5    B    23
> B    2    C    10
> B    2    C    5
> 
> 
> mean
> 
> Patient    Day    Sample    Test.mean
> A    1    A    29.5
> A    5    A    33.5
> B    2    C    7.5
> 
> 
> it would be great to get some help form the list.
> 
> Yours
> Frank



From fharrell at virginia.edu  Wed May 14 17:05:27 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Wed, 14 May 2003 11:05:27 -0400
Subject: [R] building mean/median over subgroups
In-Reply-To: <p05200f00bae8001643f9@[128.40.218.142]>
References: <p05200f00bae8001643f9@[128.40.218.142]>
Message-ID: <20030514110527.70e2c85d.fharrell@virginia.edu>

On Wed, 14 May 2003 15:25:57 +0100
Frank Mattes <f.mattes at rfc.ucl.ac.uk> wrote:

> Dear all,
> 
> I'm trying to solve the following problem, and hoping to get some 
> advise here from the group
> 
> I have a dataframe in which the same sample was measured more than 
> once on the same day. I would reorganize the dataframe to get a 
> single value (mean /median) for one day
> 
> Patient	Day	Sample	Test
> A	1	A	23
> A	1	A	36
> A	5	B	44
> A	5	B	23
> B	2	C	10
> B	2	C	5
> 
> 
> mean
> 
> Patient	Day	Sample	Test.mean
> A	1	A	29.5
> A	5	A	33.5
> B	2	C	7.5
> 
> 
> it would be great to get some help form the list.
> 
> Yours
> Frank
> -- 
> Frank Mattes, MD			e-mail:	f.mattes at ucl.ac.uk
> 

There are examples like this in Section 4.2 of http://hesweb1.med.virginia.edu/biostat/s/doc/splus.pdf

---
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From dbeyer at u.washington.edu  Wed May 14 17:53:58 2003
From: dbeyer at u.washington.edu (Dick Beyer)
Date: Wed, 14 May 2003 08:53:58 -0700 (PDT)
Subject: [R] lme speedup question
Message-ID: <Pine.LNX.4.43.0305140853580.1293@hymn12.u.washington.edu>

I am hoping someone will be kind enough to have a look at the following piece of code and tell me if there is a way to run lme() so it is a lot faster. The inner loop, j in 1:15000, takes about 2 hrs on my 2.8GHz dual Xeon 4GB RAM machine.  The timings I have done show the dominant execution time is in lme.

options(contrasts=c("contr.sum", "contr.sum"))
getOption("contrasts")
vg  <- c(1,2,1,2,2,1,2,1,1,2,1,2,2,1,2,1,1,2,1,2,2,1,2,1)
ag  <- c(1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5,6,6,6,6)
dy  <- c(1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2)
rp  <- c(1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3)

for (perm in 1:216){
 vg <- vgAll[perm,]
 for(j in 1:15000){
  ge <- c(philmaanova.rloess$adjdata[j,1:24])
  dat <- data.frame(ge,vg=factor(vg),ag=factor(ag),dy=factor(dy),rp=factor(rp))
  dat$vgrp <- getGroups(dat, form = ~ 1|vg/rp, level = 2)
  ge.lme   <- lme(fixed=ge~vg+ag+dy, data=dat, random=~1|vgrp)
  cp1[j,1] <- philmaanova.rloess$cloneid[j]
  tmpInt   <- intervals(ge.lme,level=0.95,which="fixed")
  cp1[j,2] <- tmpInt$fixed[2,2]*2
  cp1[j,3] <- tmpInt$fixed[2,1]
  cp1[j,4] <- tmpInt$fixed[2,3]
}
}

An Aside: I am using lme for a mixed model with treating rp as random and nested in the fixed effect vg.  I am collecting the coefficients and se's so I can later calculate a modified t-test (like SAM does, Significance Analysis of Microarrays).

Thanks very much for any help,
Dick
*******************************************************************************
Richard P. Beyer, Ph.D.	University of Washington
Tel.:(206) 616 7378	Env. & Occ. Health Sci. , Box 354695
Fax: (206) 685 4696	4225 Roosevelt Way NE, # 100
			Seattle, WA 98105-6099



From tlumley at u.washington.edu  Wed May 14 18:22:16 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 14 May 2003 09:22:16 -0700 (PDT)
Subject: [R] mcl models, percentages
In-Reply-To: <20030514113700.51782.qmail@web14202.mail.yahoo.com>
Message-ID: <Pine.A41.4.44.0305140906180.144126-100000@homer39.u.washington.edu>

On Wed, 14 May 2003, John Hendrickx wrote:

>
> A caveat is that "clogit" in R doesn't produce the same estimates as
> "multilog", although the likelihood functions for both models are the
> same. The maximum absolute difference is 0.0034, the mean absolute
> difference is 0.00069. Stata's "clogit" and "mlogit" produce the same
> estimates and match those of "multilog" to at least 6 decimal points
> accuracy. See the notes in http://www.xs4all.nl/~jhckx/R/mcl.html Can
> anyone shed any light on this?
>


Two possibilities

1/ not having converged far enough: the convergence tolerance for coxph is
by default only 1e-4 (yes, I should change it)

2/ Weights. In one of your examples you have frequency weights passed to
clogit.  This doesn't work (at least, it isn't equivalent to passing in
the expanded data) because weighting doesn't make coxph compute the full
set of permutations that you need for the likelihood in a large stratum.


	-thomas



From mschwartz at medanalytics.com  Wed May 14 18:24:04 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 14 May 2003 11:24:04 -0500
Subject: [R] number of patients in a hospital on a given date
In-Reply-To: <C4D44AB4CB62D311BA6500041202E886031EE204@xms1.tirol.gv.at>
Message-ID: <00b901c31a35$3d5279b0$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of RINNER
Heinrich
>Sent: Wednesday, May 14, 2003 8:02 AM
>To: 'r-help at stat.math.ethz.ch'
>Subject: [R] number of patients in a hospital on a given date
>
>
>Dear R-users!
>
>I am using R 1.7.0, under Windows XP.
>
>Having some hospital discharge data (admission date and 
>discharge date for
>each patient), I want to get the number of patients in the 
>hospital on a
>given date.
>
>My data look like (simple example):
>> x <- data.frame(patid=c("pat1", "pat2"), adm.date = c("15.03.2002",
>"16.03.2002"),
>       dis.date=c("18.03.2002", "17.03.2002"))
>
>I can easily do a date-time conversion from the character objects: 
>> x[,2:3] <- apply(x[,2:3], MARGIN=2, FUN=strptime,
format="%d.%m.%Y")
>> x
>  patid   adm.date   dis.date
>1  pat1 2002-03-15 2002-03-18
>2  pat2 2002-03-16 2002-03-17
>
>What I want in the end is something like a data.frame A like this:
>A
>date		no.of.patients
>2002-03-14	0
>2002-03-15	1
>2002-03-16	2
>2002-03-17	2
>2002-03-18	1
>2002-03-19	0
>
>Or, alternatively, a data.frame B like this:
>B
>patid	date.in.hospital
>pat1	2002-03-15
>pat1	2002-03-16
>pat1	2002-03-17
>pat1	2002-03-18
>pat2	2002-03-16
>pat2	2002-03-17
>
>>From this I could easily get A by using "table".
>So the trick would be to get a data.frame with one line for 
>each day of each
>patient in the hospital - but how?
>
>I'd be happy about any ideas,
>Heinrich Rinner.


Heinrich,

How about something like this:

x <- data.frame(patid = c("pat1", "pat2"), 
                adm.date = c("15.03.2002", "16.03.2002"),
                dis.date = c("18.03.2002", "17.03.2002"))

x[,2:3] <- apply(x[,2:3], MARGIN = 2, FUN = strptime, format =
"%d.%m.%Y")

x is then:

> x
  patid   adm.date   dis.date
1  pat1 2002-03-15 2002-03-18
2  pat2 2002-03-16 2002-03-17

days <- NULL

# generate a combined sequence of days all patients are in the
hospital
# based upon the intervals from admit to discharge
for (i in 1:nrow(x))
{
    days <- c(days, 
                format(seq(from = x$adm.date[i], to = x$dis.date[i],
by = "day"), 
                "%Y-%m-%d"))
}

days is then:

> days
[1] "2002-03-15" "2002-03-16" "2002-03-17" "2002-03-18" "2002-03-16"
"2002-03-17"

# Now create a dataframe from the results of table(days)
days.table <- data.frame(table(days))

days.table is then:

> days.table
        days Freq
1 2002-03-15    1
2 2002-03-16    2
3 2002-03-17    2
4 2002-03-18    1


HTH,

Marc Schwartz



From Jeff.Enos at FMR.COM  Wed May 14 18:36:35 2003
From: Jeff.Enos at FMR.COM (Enos, Jeff)
Date: Wed, 14 May 2003 12:36:35 -0400
Subject: [R] RODBC and SQL Server
Message-ID: <BCDD553B066D624390A38989CA623A037A6007@MSGBOS681NTS.fmr.com>

All,

I have a set of users who are currently using RODBC on Solaris (2.6 and
up) to connect to SQL Server databases.  We use unixODBC for a driver
manager and Easysoft's ODBC-ODBC bridge underneath.  R 1.6.2 is our
standard R version.

While moving to Linux (RedHat 9) I have become eager to phase out our
use of Easysoft, but am tied to SQL Server for the time being.  

I am curious as to whether others have had experience using
alternative drivers for SQL Server, such as FreeTDS (which supposedly
works with unixODBC though it speaks TDS), sitting behind RODBC on
Linux/Solaris (R 1.6.2 and up).

Many thanks,

Jeff Enos



From pkleiber at honlab.nmfs.hawaii.edu  Wed May 14 19:37:39 2003
From: pkleiber at honlab.nmfs.hawaii.edu (Pierre Kleiber)
Date: Wed, 14 May 2003 07:37:39 -1000
Subject: [R] Some Programming Humor
References: <HJEIKCALHCOJAGKCPKHBGEFFCBAA.i.wilson@maths.abdn.ac.uk>
	<x2smrhfzn0.fsf@biostat.ku.dk>
Message-ID: <3EC27EE3.6030101@honlab.nmfs.hawaii.edu>

And here's a somewhat inebriated version of the beer bottle program

bottles <- function() {
    outstring <- function(b,s,x) {
      cat(b," ")
      for(i in s) cat(sample(c(i,letters,"",".",","),1,
                           prob=c(x,rep(1,29))))
      cat("\n")
    }
    s1 <- unlist(strsplit("bottle(s) of beer on the wall,",NULL))
    s2 <- unlist(strsplit("bottle(s) of beer.",NULL))
    s3 <- unlist(strsplit("Take one down, pass it around,",NULL))
    s4 <- unlist(strsplit("bottle(s) of beer on the wall.",NULL))
    for (b in 99:1){
      #inbf <- 50+b*9950/99
      #inbf <- 50+9950*exp(-(99-b))
      inbf <- 50+9950/(1+exp(-.1*(b-80)))
      outstring(b,s1,inbf)
      outstring(b,s2,inbf)
      outstring("  ",s3,inbf)
      outstring(b-1,s4,inbf)
      cat("\n")
    }
}

The inebriation function, by which the variable, inbf, is calculated, 
obviously should be adjusted to local cultural beer-drinking norms.
     Cheers, Pierre


Peter Dalgaard BSA wrote:
> "Ian Wilson" <i.wilson at maths.abdn.ac.uk> writes:
> 
> 
>>Douglas Bates wrote:
>>
>>>Douglas Bates <bates at cs.wisc.edu> writes:
>>>
>>>
>>>
>>>>I checked and R is one of the 515 languages mentioned in the enclosed.
>>>
>>  Very nice. But where's the S version? :)
>>
>>The "R" version used a loop - so it could not really be called S ;)
>>
>>How about
>>
>>cat(paste(n <- 99:1,a <- "bottles of beer",b <- "on the wall,\n"
>>,n,a,"take one down, pass it around,\n",n-1,a,b,"\n"))
> 
> 
> Do we guarantee left-to-right evaluation?
> 
> Here's my old version:
> 
> f <- function(n) structure(c(paste(c(n,n,n-1),
>      "bottles of beer",c("on the wall","")),
>      "take one down, pass it around")[c(1,2,4,3)], class="verse")
> print.verse <- function(x,...) cat(x, sep="\n")
> lapply(99:1, f)
> 
> (It's an open question what to strive for in these examples. My tack
> was that it should highlight features of the language, so I threw in
> lapply, (S3) methods, and smart indexing...) 
> 


-- 
-----------------------------------------------------------------
Pierre Kleiber             Email: pkleiber at honlab.nmfs.hawaii.edu
Fishery Biologist                     Tel: 808 983-5399/737-7544
NOAA FISHERIES - Honolulu Laboratory         Fax: 808 983-2902
2570 Dole St., Honolulu, HI 96822-2396
-----------------------------------------------------------------
  "God could have told Moses about galaxies and mitochondria and
   all.  But behold... It was good enough for government work."



From rprograming at yahoo.com.mx  Wed May 14 20:04:21 2003
From: rprograming at yahoo.com.mx (=?iso-8859-1?q?Proyecto=20R?=)
Date: Wed, 14 May 2003 13:04:21 -0500 (CDT)
Subject: [R] (sin asunto)
Message-ID: <20030514180421.71589.qmail@web20506.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030514/f982747b/attachment.pl

From ypeng at math.mun.ca  Wed May 14 20:29:53 2003
From: ypeng at math.mun.ca (Paul Y. Peng)
Date: Wed, 14 May 2003 15:59:53 -0230
Subject: [R] savehistory not working properly in R?
Message-ID: <3EC28B21.8785F3D5@math.mun.ca>

Dear R users,

I have a .RData which contains .Last object as follows:

	.Last <- function () 
	{
		savehistory(file = ".Rhistory")
	}

In this directory, if I issue the following command

	Rterm --save < mycmds.q

to execute commands in mycmds.q and to save results in .RData,
I got the following error message towards the end of the execution:

	Error in savehistory(file) : savehistory can only be used
	in Rgui and Rterm
	Execution halted

I lost the results of the commands too. The documentation of
"savehistory" says that it only works with Rgui and Rterm. Why
doesn't it work in this case? Is it because it is in a batch mode
rather than in an interactive mode? I did this in Windows98 with
the following R

	> version
	platform i386-pc-mingw32
	arch     i386           
	os       mingw32        
	system   i386, mingw32  
	status                  
	major    1              
	minor    6.2            
	year     2003           
	month    01             
	day      10             
	language R

I tested it in Linux with the same version R and the same problem
happened.

Is it possible to prevent savehistory from printing the error message
so that the session can be finished properly? I hope that I did not
miss anything obvious. Otherwise, please forgive me. Thanks.

Paul.



From B.Rowlingson at lancaster.ac.uk  Wed May 14 20:50:00 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 14 May 2003 19:50:00 +0100
Subject: [R] Some Programming Humor - Quine
In-Reply-To: <3EC20E5C.5080201@lancaster.ac.uk>
References: <6rvfwe5qob.fsf@bates4.stat.wisc.edu>	<6rr8725pnw.fsf@bates4.stat.wisc.edu>
	<3EC20E5C.5080201@lancaster.ac.uk>
Message-ID: <3EC28FD8.6000601@lancaster.ac.uk>


  Well I managed to modify a javascript quine on the quine web page to 
create this monster - simply stick it all on one line in a file - I've 
split it here for an attempt at clarity:

a=1:10;a[1]='a=1:10;';a[2]='[';a[3]=']';a[4]='\'';a[5]='\\';a[6]='=';a[7]='a';a[8]=';';a[9]='';

a[10]='for(i in 1:10)cat(ifelse(i==1,a[1],a[9])

,a[7],a[2],i,a[3],a[6],a[4],ifelse(i==4||i==5,a[5],a[9]),

a[i],a[4],a[8],ifelse(i==10,a[10],a[9]),sep=a[9])';for(i in 1:10)

cat(ifelse(i==1,a[1],a[9]),a[7],a[2],i,a[3],a[6],a[4],

ifelse(i==4||i==5,a[5],a[9]),a[i],a[4],a[8],ifelse(i==10,a[10],a[9]),sep=a[9])

  This passes the quine script test:

$ R --slave < q2.R >q2o.R
$ diff q2.R q2o.R
  <nothing!>
$

I'm sure if I understood it I could make it better...

Original javascript version by: Geoffrey A Swift (blimey at toke.com)
From: http://www.nyx.net/~gthompso/quine.htm

Baz



From Kosenkov.Kirill at nac.spb.ru  Wed May 14 22:18:24 2003
From: Kosenkov.Kirill at nac.spb.ru (Kosenkov Kirill)
Date: Thu, 15 May 2003 00:18:24 +0400
Subject: [R] how to include 'NA's in xtabs?
Message-ID: <3EC2A490.7070609@nac.spb.ru>

Hello!

I have a dataset with NA's in some variables (factors), for example:
$ P67 : Factor w/ 2 levels "-","+": NA 2 1 NA NA 2 1 1 2 NA ...

I need to use 'xtabs' like
xtabs(~x$P67)
It works well and produces something like this:
x$P67
    -    +
  779 1318
but i want to compute NA's too, like this:
x$P67
    -    +   NA
  779 1318  137

I am trying xtabs(~x$P67, exclude=NULL) but xtabs does not compute 
'NA's in this case too.

I do not want to transform my data (do not want to do any 
substitution on NA's).

How i can say 'xtabs' to compute NA-values?

and second question: how to use argument 'na.action' in 'xtabs'?
'xtabs' help page does not explain this.

Thanks!



From rinkusaha at hotmail.com  Wed May 14 22:46:29 2003
From: rinkusaha at hotmail.com (rinku saha)
Date: Thu, 15 May 2003 02:16:29 +0530
Subject: [R] (no subject)
Message-ID: <Law15-F67yp4O0b9kan000206f6@hotmail.com>

1)I installed R-1.7.0  in Sgi machine(irix6.5).I installed all the 
bioconductor packages too.
After that i did put all my >cel files under one directory and then move 
into that directory and Start  R.Then i gave library(affy) to load it.
Welcome to Bioconductor
  To view some introductory material.........
   Simply type.......
  Creating a new  generic function for "summary" in package
Biobase
{1} TRUE

My question is did it reall yy load the package affy.

2)When  i write data <-ReadAffy()
it gives these:

1: the condition has length > 1 and only the first element will be used in: 
if (dim(intensity(cel)) != dim.intensity) stop(paste("CEL file dimension 
mismatch !\n(file",

My question is how can i make it work to read my .cel file.
I am sending you an example .cel file
[CEL]
Version=3

[HEADER]
Cols=536
Rows=536
TotalX=536
TotalY=536
OffsetX=0
OffsetY=0
GridCornerUL=237 234
GridCornerUR=4492 243
GridCornerLR=4490 4508
GridCornerLL=235 4499
Axis-invertX=0
AxisInvertY=0
swapXY=0
DatHeader=[73..46225]  MG2000062256AA:CLS=4733 RWS=4733 XIN=3  YIN=3  VE=17  
       2.0 06/22/ 0 11:15:55      GridVerify=Success   Hu6800.1sq            
                6
Algorithm=Percentile
AlgorithmParameters=Percentile:75;CellMargin:2;OutlierHigh:1.500;OutlierLow:1.004

[INTENSITY]
NumberCells=287296
CellHeader=X	Y	MEAN	STDV	NPIXELS
  0	  0	1447.3	294.2	 36
  1	  0	34282.8	4017.5	 36
  2	  0	1528.0	244.9	 36
  3	  0	33889.3	4679.7	 36
  4	  0	1073.5	211.4	 36
  5	  0	1493.8	235.2	 36
  6	  0	26558.8	5903.9	 36
  7	  0	1557.5	259.3	 36
  8	  0	25951.8	3178.6	 30
  9	  0	1497.0	292.3	 36
10	  0	26122.8	3989.7	 36
11	  0	1577.3	271.9	 36
12	  0	25029.8	4386.5	 36
13	  0	1454.8	229.0	 36
14	  0	25128.5	5666.1	 36
15	  0	1602.0	242.9	 36
16	  0	26180.0	6859.9	 36
17	  0	1652.8	304.7	 36
18	  0	26311.8	7985.2	 36
19	  0	1655.0	295.9	 36
20



3)when i try to load tcl/tk  it says:
Loading required package: tcltk
Error in firstlib(which.lib.loc, package) :
        Tcl/Tk support is not available on this syError: syntax error
Please do help me out.

Thanks
RInku

_________________________________________________________________
Mega movies. Mega prizes. http://server1.msn.co.in/sp03/hallmark/index.asp 
Switch to Hallmark channel.



From sundar.dorai-raj at pdf.com  Wed May 14 22:49:38 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 14 May 2003 15:49:38 -0500
Subject: [R] how to include 'NA's in xtabs?
References: <3EC2A490.7070609@nac.spb.ru>
Message-ID: <3EC2ABE2.1090202@pdf.com>



Kosenkov Kirill wrote:
> Hello!
> 
> I have a dataset with NA's in some variables (factors), for example:
> $ P67 : Factor w/ 2 levels "-","+": NA 2 1 NA NA 2 1 1 2 NA ...
> 

The key is here. Should be 3 levels if you want NAs included.

> I need to use 'xtabs' like
> xtabs(~x$P67)
> It works well and produces something like this:
> x$P67
>    -    +
>  779 1318
> but i want to compute NA's too, like this:
> x$P67
>    -    +   NA
>  779 1318  137
> 
> I am trying xtabs(~x$P67, exclude=NULL) but xtabs does not compute 'NA's 
> in this case too.
> 
> I do not want to transform my data (do not want to do any substitution 
> on NA's).
> 
> How i can say 'xtabs' to compute NA-values?
> 
> and second question: how to use argument 'na.action' in 'xtabs'?
> 'xtabs' help page does not explain this.
> 
> Thanks!
> 


Try this:

x$P67 = factor(x$P67, exclude = NULL)
xtabs(~x$P67)


Here's an example:
R> x = factor(c(1:2, NA), exclude = NULL, labels = c("+", "-", "0"))
R> xtabs(~ x)
x
+ - 0
1 1 1

Sundar



From john_hendrickx at yahoo.com  Wed May 14 22:58:31 2003
From: john_hendrickx at yahoo.com (John Hendrickx)
Date: Wed, 14 May 2003 13:58:31 -0700 (PDT)
Subject: [R] mcl models, percentages
In-Reply-To: <Pine.A41.4.44.0305140906180.144126-100000@homer39.u.washington.edu>
Message-ID: <20030514205831.67672.qmail@web14202.mail.yahoo.com>


--- Thomas Lumley <tlumley at u.washington.edu> wrote:
> On Wed, 14 May 2003, John Hendrickx wrote:
> 
> >
> > A caveat is that "clogit" in R doesn't produce the same estimates
> as
> > "multilog", although the likelihood functions for both models are
> the
> > same. The maximum absolute difference is 0.0034, the mean
> absolute
> > difference is 0.00069. Stata's "clogit" and "mlogit" produce the
> same
> > estimates and match those of "multilog" to at least 6 decimal
> points
> > accuracy. See the notes in http://www.xs4all.nl/~jhckx/R/mcl.html
> Can
> > anyone shed any light on this?
> >
> 
> 
> Two possibilities
> 
> 1/ not having converged far enough: the convergence tolerance for
> coxph is
> by default only 1e-4 (yes, I should change it)
> 
> 2/ Weights. In one of your examples you have frequency weights
> passed to
> clogit.  This doesn't work (at least, it isn't equivalent to
> passing in
> the expanded data) because weighting doesn't make coxph compute the
> full
> set of permutations that you need for the likelihood in a large
> stratum.

It appears to be the convergence tolerance. It's not just the
weights, the problem occurs for the logan data as well. Specifying
"eps=1e-9" in  coxph produces the estimates found in other programs.
Could you specify a lower default value for eps? It would also be
useful to add options in "clogit" for eps and weights.

John Hendrickx



From gb at stat.umu.se  Thu May 15 00:17:46 2003
From: gb at stat.umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Thu, 15 May 2003 00:17:46 +0200 (CEST)
Subject: [R] mcl models, percentages
In-Reply-To: <Pine.A41.4.44.0305140906180.144126-100000@homer39.u.washington.edu>
Message-ID: <Pine.LNX.4.44.0305150011480.7120-100000@tal.stat.umu.se>

On Wed, 14 May 2003, Thomas Lumley wrote:

> On Wed, 14 May 2003, John Hendrickx wrote:
> 
> >
> > A caveat is that "clogit" in R doesn't produce the same estimates as
> > "multilog", although the likelihood functions for both models are the
> > same. The maximum absolute difference is 0.0034, the mean absolute
> > difference is 0.00069. Stata's "clogit" and "mlogit" produce the same
> > estimates and match those of "multilog" to at least 6 decimal points
> > accuracy. See the notes in http://www.xs4all.nl/~jhckx/R/mcl.html Can
> > anyone shed any light on this?
> >
> 
> 
> Two possibilities
> 
> 1/ not having converged far enough: the convergence tolerance for coxph is
> by default only 1e-4 (yes, I should change it)

I tried to change 'eps' to 1.e-8, found yet another way of crashing  R:
------------------------------------------------------------------------
> library(survival)
>  coxph(Surv(enter, exit, event) ~ x, data = tt, 
              control = list(eps = 1.e-8))

Program received signal SIGSEGV, Segmentation fault.
0x405526a0 in agfit3 (maxiter=0x0, nusedx=0x1, nvarx=0x1, start=0x8f267b8, 
    stop=0x8f26770, event=0x8f25f98, covar2=0x8f26728, offset=0x8f266e0, 
    weights=0x8f26698, nstrat=0x8ec4ab0, strata=0x8ec4a90, 
sort1=0x8f25f60, 
    sort2=0x8f25f28, means=0x8e7ed30, Rf_beta=0x8e7ed08, u=0x8e7ece0, 
    imat2=0x8e7ecb8, loglik=0x8f25ef0, flag=0x8ec4a70, work=0x8f249a0, 
    eps=0x8e7ec90, tol_chol=0x0, sctest=0x8e7ec68) at agfit3.c:263
263     agfit3.c: No such file or directory.
        in agfit3.c
-------------------------------------------------------------------------
It's of course my fault; 'control' should be a call to 'coxph.control'.
But should  R  crash...?

G?ran
[...]

---
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se



From dtudor at evhr.net  Thu May 15 00:27:26 2003
From: dtudor at evhr.net (David Tudor)
Date: Thu, 15 May 2003 00:27:26 +0200
Subject: [R] abrupt end to R
Message-ID: <5.2.0.9.0.20030515001955.00b33b58@pop3.evhr.net>


Dear All,

I haven't seen any further comments about the problem that John Marsland 
first noted and that I also have:

 > library(DBI)
 > library(RMySQL)
Warning message:
DLL attempted to change FPU control word from 8001f to 9001f
 > mgr <- dbDriver("MySQL")
 > con <- dbConnect(mgr, host="localhost", dbname="marketing")

upon which R dies...

Dr. Mingw says:

Rgui.exe caused an Access Violation at location 77c13730 in module 
msvcrt.dll Reading from location 00000000.

Registers:
eax=10e501a0 ebx=00000000 ecx=00000000 edx=10e51fe0 esi=00000000 edi=003e3d08
eip=77c13730 esp=0022d5ac ebp=0022d7f8 iopl=0         nv up ei pl zr na po nc
cs=001b  ss=0023  ds=0023  es=0023  fs=0038  gs=0000             efl=00000246

Call stack:
77C13730  msvcrt.dll:77C13730  strlen
004C799D  R.dll:004C799D  do_dotcall
004DA35F  R.dll:004DA35F  Rf_eval
004DC2D5  R.dll:004DC2D5  do_set
004DA3C8  R.dll:004DA3C8  Rf_eval
004DBA52  R.dll:004DBA52  do_begin
004DA3C8  R.dll:004DA3C8  Rf_eval
004DA6B5  R.dll:004DA6B5  Rf_applyClosure
004DA1D7  R.dll:004DA1D7  Rf_eval
004DA949  R.dll:004DA949  Rf_applyClosure
004DAC5A  R.dll:004DAC5A  R_execMethod
10DA2B43  methods.dll:10DA2B43  R_standardGeneric
0050C059  R.dll:0050C059  do_standardGeneric
004DA35F  R.dll:004DA35F  Rf_eval
004DA0F6  R.dll:004DA0F6  Rf_eval
004DA03E  R.dll:004DA03E  Rf_eval
004DA0F6  R.dll:004DA0F6  Rf_eval
004DA03E  R.dll:004DA03E  Rf_eval
004DA0F6  R.dll:004DA0F6  Rf_eval
004DA03E  R.dll:004DA03E  Rf_eval
004DC4BB  R.dll:004DC4BB  Rf_evalList
004DA2F0  R.dll:004DA2F0  Rf_eval
004DD2F3  R.dll:004DD2F3  Rf_DispatchOrEval
0056941B  R.dll:0056941B  do_subset2
004DA3C8  R.dll:004DA3C8  Rf_eval
004DA6B5  R.dll:004DA6B5  Rf_applyClosure
004DA1D7  R.dll:004DA1D7  Rf_eval
004DC2D5  R.dll:004DC2D5  do_set
004DA3C8  R.dll:004DA3C8  Rf_eval
004DBA52  R.dll:004DBA52  do_begin
004DA3C8  R.dll:004DA3C8  Rf_eval
004DA6B5  R.dll:004DA6B5  Rf_applyClosure
004DA1D7  R.dll:004DA1D7  Rf_eval
004DB0DC  R.dll:004DB0DC  do_if
004DA3C8  R.dll:004DA3C8  Rf_eval
004DB427  R.dll:004DB427  do_for
004DA3C8  R.dll:004DA3C8  Rf_eval
004DBA52  R.dll:004DBA52  do_begin
004DA3C8  R.dll:004DA3C8  Rf_eval
004DA3C8  R.dll:004DA3C8  Rf_eval
004DBA52  R.dll:004DBA52  do_begin
004DA3C8  R.dll:004DA3C8  Rf_eval
004DA6B5  R.dll:004DA6B5  Rf_applyClosure
004DA1D7  R.dll:004DA1D7  Rf_eval
004DA6B5  R.dll:004DA6B5  Rf_applyClosure
004DA1D7  R.dll:004DA1D7  Rf_eval
004DC2D5  R.dll:004DC2D5  do_set
004DA3C8  R.dll:004DA3C8  Rf_eval
004F996E  R.dll:004F996E  Rf_ReplIteration
004F9F72  R.dll:004F9F72  Rf_ReplIteration
004FAA76  R.dll:004FAA76  run_Rmainloop
004014D7  Rgui.exe:004014D7
0040141E  Rgui.exe:0040141E
00401603  Rgui.exe:00401603
00401165  Rgui.exe:00401165
00401013  Rgui.exe:00401013
77E5EB69  kernel32.dll:77E5EB69  CreateProcessInternalW


But then, again, I never did speak Chinese...

Thanks for your help.

David Tudor



-------------- next part --------------

---




From r_stuff_online at hotmail.com  Thu May 15 00:32:49 2003
From: r_stuff_online at hotmail.com (Neil Osborne)
Date: Wed, 14 May 2003 22:32:49 +0000
Subject: [R] Help in grouping time stamped data and general stats help
Message-ID: <Law12-F49DXgIDksUmU0001d73c@hotmail.com>

Hi,

I am a new comer to R. I want to carrying out some exploratory data analysis 
on some financial data which has been time stamped. The data is a Microsoft 
database and I can access it using the RODBC package. The data consists of a 
5 minute sampling of market prices. However, there are periods for which 
there is no data (these periods occur randomly), and is typically caused by 
a system crash. Consequently, the timestamps are not evenly spaced.

I would be most grateful if someone could show me how to do the following 
(using R):

1). Aggregate the data into time buckets (bins) of my choice for e.g. 0-1 
hr, 1hr-2hr etc
2). Carry out tests to check time of day effects


Thanks

_________________________________________________________________
Hotmail messages direct to your mobile phone http://www.msn.co.uk/msnmobile



From dbeyer at u.washington.edu  Thu May 15 01:17:39 2003
From: dbeyer at u.washington.edu (Dick Beyer)
Date: Wed, 14 May 2003 16:17:39 -0700 (PDT)
Subject: [R] lme speedup question
Message-ID: <Pine.LNX.4.43.0305141617390.18348@hymn02.u.washington.edu>

Thanks very much to the help I received on my lme speedup question.  Jake Bowers pointed out that memory fill might slow things down, so I will keep watch on that.  Renaud Lancelot pointed out using update instead of redoing lme in the inner loop (also to look at using gls as it might be faster).  That sped up things by about 9%.  Douglas Bates pointed out my unnecessary creation of structures in the inner loop, so I moved the creation of the data.frame to the outermost loop.  With these changes, I see about a 27% speedup, for which I am very grateful. 

My modified code 

for (perm in 1:216){
  vg <- vgAll[perm,]
  ge <- c(philmaanova.rloess$adjdata[1,1:24])
  dat <- data.frame(ge,vg=factor(vg),ag=factor(ag),dy=factor(dy),rp=factor(rp))
  dat$vgrp <- getGroups(dat, form = ~ 1|vg/rp, level = 2)
  ge.lme   <- lme(fixed=ge~vg+ag+dy, data=dat, random=~1|vgrp)

  for(j in 1:15000){
    dat$ge   <- c(philmaanova.rloess$adjdata[j,1:24])
    ge.lme   <- update(ge.lme, data=dat)
    cp1[j,1] <- philmaanova.rloess$cloneid[j]
    tmpInt   <- intervals(ge.lme,level=0.95,which="fixed")
    cp1[j,2] <- tmpInt$fixed[2,2]*2
    cp1[j,3] <- tmpInt$fixed[2,1]
    cp1[j,4] <- tmpInt$fixed[2,3]
  }
}

> I am hoping someone will be kind enough to have a look at the following piece
of code and tell me if there is a way to run lme() so it is a lot faster. The
inner loop, j in 1:15000, takes about 2 hrs on my 2.8GHz dual Xeon 4GB RAM
machine.  The timings I have done show the dominant execution time is in lme.
> 
> options(contrasts=c("contr.sum", "contr.sum"))
> getOption("contrasts")
> vg  <- c(1,2,1,2,2,1,2,1,1,2,1,2,2,1,2,1,1,2,1,2,2,1,2,1)
> ag  <- c(1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5,6,6,6,6)
> dy  <- c(1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2)
> rp  <- c(1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3)
> 
> for (perm in 1:216){
>  vg <- vgAll[perm,]
>  for(j in 1:15000){
>   ge <- c(philmaanova.rloess$adjdata[j,1:24])
>   dat <-
data.frame(ge,vg=factor(vg),ag=factor(ag),dy=factor(dy),rp=factor(rp))
>   dat$vgrp <- getGroups(dat, form = ~ 1|vg/rp, level = 2)
>   ge.lme   <- lme(fixed=ge~vg+ag+dy, data=dat, random=~1|vgrp)
>   cp1[j,1] <- philmaanova.rloess$cloneid[j]
>   tmpInt   <- intervals(ge.lme,level=0.95,which="fixed")
>   cp1[j,2] <- tmpInt$fixed[2,2]*2
>   cp1[j,3] <- tmpInt$fixed[2,1]
>   cp1[j,4] <- tmpInt$fixed[2,3]
> }
> }

Thanks for all your help,
Dick
*******************************************************************************
Richard P. Beyer, Ph.D.	University of Washington
Tel.:(206) 616 7378	Env. & Occ. Health Sci. , Box 354695
Fax: (206) 685 4696	4225 Roosevelt Way NE, # 100
			Seattle, WA 98105-6099



From glynn.clements at virgin.net  Thu May 15 01:38:56 2003
From: glynn.clements at virgin.net (Glynn Clements)
Date: Thu, 15 May 2003 00:38:56 +0100
Subject: [R] Re: [GRASSLIST:3] libpq-fe.h ???
In-Reply-To: <BAY2-F107GEm3EcPPzA0000dd9c@hotmail.com>
References: <BAY2-F107GEm3EcPPzA0000dd9c@hotmail.com>
Message-ID: <16066.54160.900577.317779@cerise.nosuchdomain.co.uk>


Miha STAUT wrote:

> The PostgreSQL_7.2.1 Users guide states: "Frontend programs that use libpq 
> must include the header file libpq-fe.h and must link with the libpq 
> library." Is Libpq a package that can be downloaded and how should I create 
> this header and make a link to it?
> 
> I use R 1.6.2.1 and PostgreSQL 7.2 with RedHat 7.3.

You need the appropriate -devel package. E.g for RedHat 6.2,
libpq-fe.h is in the "postgresql-devel" RPM.

-- 
Glynn Clements <glynn.clements at virgin.net>



From mail at fwr.on.ca  Thu May 15 04:52:33 2003
From: mail at fwr.on.ca (Nurnberg-LaZerte)
Date: Wed, 14 May 2003 22:52:33 -0400
Subject: [R] Manly's randomization analysis of multiple regression
Message-ID: <E19G8r9-0006ji-00@server.family>

My wife has been using a diagnostic from Manley (1991; "Randomization and MonteCarlo Methods in Biology") that compares a normal multiple regression's performance with that using random predicted variables. 

Is there something like this already available in R? 

If not, the "boot" package looks like a good place to start looking for methods, no?

Thanks in advance 
Bruce L.



From TOfarre1 at usc.edu.au  Thu May 15 07:05:52 2003
From: TOfarre1 at usc.edu.au (Trudi O'Farrell)
Date: Thu, 15 May 2003 15:05:52 +1000
Subject: [R] Importing S-Plus data sets into R
Message-ID: <sec3aee4.005@homer.usc.edu.au>

Dear All

I apologise for such a simplistic question.  However I am having immense trouble getting my S-Plus data set into R.  I have attempted data.dump/data.restore though I am unable to get it to work for me.  The error I am getting in R is :
Error in seek(s) : no applicable method for "seek"

Is this the best way to import S-Plus datasets or is there another suggestion that I could try?  My data set is 284 variables with 1461rows.

Thank-you for your help in advance,

Trudi



From Arnaud.Dowkiw at dpi.qld.gov.au  Thu May 15 07:16:14 2003
From: Arnaud.Dowkiw at dpi.qld.gov.au (Dowkiw, Arnaud)
Date: Thu, 15 May 2003 15:16:14 +1000
Subject: [R] Importing S-Plus data sets into R
Message-ID: <C2C6EA6C4DADB348BFDF58894B0390120127311C@kinsrv001.dpi.qld.gov.au>

3 steps :

under Splus:

> dput(data.frame,"data.frame.transfer")

then put "data.frame.transfer" in you working R Windows directory

under R :

>data.frame<-dget("data.frame.transfer")

Hope this helps.

Arnaud

-----Original Message-----
From: Trudi O'Farrell [mailto:TOfarre1 at usc.edu.au]
Sent: Thursday, 15 May 2003 3:06 PM
To: r-help at stat.math.ethz.ch
Cc: Trudi O'Farrell
Subject: [R] Importing S-Plus data sets into R


Dear All

I apologise for such a simplistic question.  However I am having immense
trouble getting my S-Plus data set into R.  I have attempted
data.dump/data.restore though I am unable to get it to work for me.  The
error I am getting in R is :
Error in seek(s) : no applicable method for "seek"

Is this the best way to import S-Plus datasets or is there another
suggestion that I could try?  My data set is 284 variables with
1461rows.

Thank-you for your help in advance,

Trudi

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help

********************************DISCLAIMER**********************... {{dropped}}



From Tom.Mulholland at health.wa.gov.au  Thu May 15 08:23:51 2003
From: Tom.Mulholland at health.wa.gov.au (Mulholland, Tom)
Date: Thu, 15 May 2003 14:23:51 +0800
Subject: [R] Is there a simple method of changing text into 'Proper Ca se'
Message-ID: <74E242B6968AA0469B632C5A3EFC1EFD03D56F99@nt207mesep.health.wa.gov.au>

Thank you for the help. As a result I have written two functions.

SentCase <- function(InputString){
 InputString <-
paste(toupper(substring(InputString,1,1)),tolower(substring(InputString,2)),
sep="")
}

ProperCase <- function(InputString){
sapply(lapply(strsplit(InputString," "), SentCase), paste, collapse=" ")
}

        > cat(SentCase("this little string"))
        This little string> 
        > cat(ProperCase("this little string"))
        This Little String> 

-----Original Message-----
From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de] 
Sent: Wednesday, 14 May 2003 2:40 PM
To: Mulholland, Tom
Cc: 'Spencer Graves'; (r-help at stat.math.ethz.ch)
Subject: Re: [R] Is there a simple method of changing text into 'Proper Ca
se'


Mulholland, Tom wrote:
> Yes and no. Given your response it appears that "Proper Case" is not a 
> term that everyone uses. In Excel there is a function "Proper" which 
> in essence changes "this line into something like this" into "This 
> Line Into Something Like This."
> 
> My look at casefold seesm to be that is is a wrapper of two functions 
> to change text into either Lower or Upper case.So my question is about 
> how do you just capitalise the first letter in each word.

Perl experts might do it differently, but the "R way" seems to be

  substring(x, 1, 1) <- toupper(substring(x, 1, 1))
  substring(x, 2) <- tolower(substring(x, 2))

Uwe Ligges


> Thanks for your response.
> 
> Tom
> 
> -----Original Message-----
> From: Spencer Graves [mailto:spencer.graves at PDF.COM]
> Sent: Wednesday, 14 May 2003 12:51 PM
> To: Mulholland, Tom
> Cc: ' (r-help at stat.math.ethz.ch)'
> Subject: Re: [R] Is there a simple method of changing text into 'Proper
> Case'
> 
> 
> It's not obvious to me what you are asking, but I'm guessing that
> "casefold" might help.
> 
> hth.  spencer graves
> 
> Mulholland, Tom wrote:
> 
>>I am probably just looking in the wrong place. I am sure there are a
>>number of ways to do this. If anyone could point me in the right 
>>direction it would be very much appreciated.
>> 
>>Thanks
>> 
>>_________________________________________________
>> 
>>Tom Mulholland
>>Senior Policy Officer
>>WA Country Health Service
>>189 Royal St, East Perth, WA, 6004
>> 
>>Tel: (08) 9222 4062
>>e-mail: Tom.Mulholland at health.wa.gov.au
>><mailto:Tom.Mulholland at health.wa.gov.au>



From ripley at stats.ox.ac.uk  Thu May 15 08:39:27 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 15 May 2003 07:39:27 +0100 (BST)
Subject: [R] savehistory not working properly in R?
In-Reply-To: <3EC28B21.8785F3D5@math.mun.ca>
Message-ID: <Pine.LNX.4.44.0305150732220.7760-100000@gannet.stats>

On Wed, 14 May 2003, Paul Y. Peng wrote:

> I have a .RData which contains .Last object as follows:
> 
> 	.Last <- function () 
> 	{
> 		savehistory(file = ".Rhistory")
> 	}
> 
> In this directory, if I issue the following command
> 
> 	Rterm --save < mycmds.q
> 
> to execute commands in mycmds.q and to save results in .RData,
> I got the following error message towards the end of the execution:
> 
> 	Error in savehistory(file) : savehistory can only be used
> 	in Rgui and Rterm
> 	Execution halted
> 
> I lost the results of the commands too. The documentation of
> "savehistory" says that it only works with Rgui and Rterm. Why
> doesn't it work in this case? Is it because it is in a batch mode
> rather than in an interactive mode? 

Yes.  The history is associated with the command-line editing: what you 
are doing is considered to be BATCH use.

> I did this in Windows98 with
> the following R
> 
> 	> version
> 	platform i386-pc-mingw32
> 	arch     i386           
> 	os       mingw32        
> 	system   i386, mingw32  
> 	status                  
> 	major    1              
> 	minor    6.2            
> 	year     2003           
> 	month    01             
> 	day      10             
> 	language R
> 
> I tested it in Linux with the same version R and the same problem
> happened.
> 
> Is it possible to prevent savehistory from printing the error message
> so that the session can be finished properly? I hope that I did not
> miss anything obvious. Otherwise, please forgive me. Thanks.

The real problem is in your .Last.  You could do

.Last <- function ()
{
    if(interactive()) savehistory(file = ".Rhistory")
}

or use try():  if you are worried about not saving .RData you really 
should protect the commands in .Last (see its help page for warnings).

I'll see if the documentation can be clarified.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu May 15 08:58:39 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 15 May 2003 07:58:39 +0100 (BST)
Subject: [R] installation problems with RMySQL (was abrupt end to R)
In-Reply-To: <5.2.0.9.0.20030515001955.00b33b58@pop3.evhr.net>
Message-ID: <Pine.LNX.4.44.0305150752590.7841-100000@gannet.stats>

Please do use an informative subject line.

The comment was that he was using code compiled against MySQL 4.0.x on
MySQL 3.2.x, and had not read the readmes.

A further comment is that you are asked *not* to report problems with 
pre-compiled packages on R-help, but to re-compile them yourself.
He had ignored that, and I suspect you have too.

On Thu, 15 May 2003, David Tudor wrote:

> I haven't seen any further comments about the problem that John Marsland 
> first noted and that I also have:
> 
>  > library(DBI)
>  > library(RMySQL)
> Warning message:
> DLL attempted to change FPU control word from 8001f to 9001f
>  > mgr <- dbDriver("MySQL")
>  > con <- dbConnect(mgr, host="localhost", dbname="marketing")
> 
> upon which R dies...

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From John.Marsland at CommerzbankIB.com  Thu May 15 09:37:32 2003
From: John.Marsland at CommerzbankIB.com (Marsland, John)
Date: Thu, 15 May 2003 08:37:32 +0100
Subject: [R] RMySQL crashes R
Message-ID: <8CBAA121CEB4D5118CB200508BB2BBEF0317E71B@xmx8lonib.lonib.commerzbank.com>


I received three responses to my previous question, all of them were off
list. So I am posting the dialogue for the benefit of other users.

Subsequent to this dialogue, I have installed MySQL4 and have tried to
compile the RMySQL package from source for both versions of MySQL. 

I have not been sucessful and have had to revert to using RMySQL version
0.4-6 for the time being - which works fine with R v1.7.0 despite being
built under R v1.5.1 and it works with MySQL versions 3.x and 4.x.

I would respectfully like to keep this question open - refiled as a question
regarding either the source code, the instructions or my inability to follow
them.

Regards, 

John Marsland

> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> Sent: 14 May 2003 10:51
> To: Marsland, John
> Subject: RE: [R] RMySQL crashes R
> 
> 
> On Wed, 14 May 2003, Marsland, John wrote:
> 
> > Thanks for the pointer, I am indeed using MySQL version 3.23.40. 
> > 
> > My mysql server is on a solaris server. So I have installed 
> the windows
> > version 3.23.56 which is described as "recent" by mysql.com.
> > 
> > I have tried to compile RMySQL from source but I have a 
> problem. In the
> > README.windows (in which you are credited), I am following 
> the instructions
> > to re-import the libmysql.dll library with reimp. But reimp 
> seems only to
> > produce libmysql.def and liblibmysql.a - no dll file. Reimp 
> is now part of
> > mingw-utils now - I don't know if this make a difference? I 
> am no expert on
> > these utilities...
> 
> You only need the .a
> 
> > 
> > When I try to compile the package, I get a number of 
> undefined references to
> > 'mysql_init' and 'mysql_options' - I presume it's trying to 
> find this
> > reimported dll for version 3.23.x.
> 
> They should be in the .a.
> 
> > I'd be grateful if you could give me a clue as to where I 
> am going wrong.
> > 
> > Regards,
> > 
> > John Marsland
> > 
> > PS I have received a number of off-list emails in response 
> to my posting
> > from users with similar problems.
> > 
> > > -----Original Message-----
> > > From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> > > Sent: 13 May 2003 18:56
> > > To: Marsland, John
> > > Subject: Re: [R] RMySQL crashes R
> > > 
> > > 
> > > You did compile this from the sources, didn't you, because
> > > 
> > > 1) You are asked *not* to send messages to R-help about the 
> > > pre-compiled 
> > > Windows packages and
> > > 
> > > 2) The pre-compiled package on CRAN requires RMySQL 4.0.x, as it 
> > > documentation states.
> > > 
> > > Your symptoms are consistent with negligence of these points.
> > > I hope not!
> > > 
> > > On Tue, 13 May 2003, Marsland, John wrote:
> > > 
> > > > I have justed upgraded R v1.7.0 on Windows NT 4 and have 
> > > installed the
> > > > latest RMySQL (version 0.5-1)and DBI (version 0.1-5) packages.
> > > > 
> > > > When I issue the following commands (tactfully adjusted) R 
> > > just crashes and
> > > > disappears, any ideas?
> > > > 
> > > > require(RMySQL)
> > > > m <- dbDriver("MySQL")
> > > > con <- dbConnect(m, dbname="xxx", user="xxx", password="xxx",
> > > > host="myserver.com")
> > > > 
> > > > I get the same result with mysqlNewConnection().
> > > > 
> > > > I've sucessfully used both previous versions of R and the 
> > > MySQL package
> > > > together with no problems.
> > > 
> > > 
> > > -- 
> > > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > > Professor of Applied Statistics,  
> http://www.stats.ox.ac.uk/~ripley/
> > > University of Oxford,             Tel:  +44 1865 272861 (self)
> > > 1 South Parks Road,                     +44 1865 272866 (PA)
> > > Oxford OX1 3TG, UK                Fax:  +44 1865 272595

> -----Original Message-----
> From: David Tudor [mailto:dtudor at evhr.net]
> Sent: 13 May 2003 19:50
> To: Marsland, John
> Subject: Re: [R] RMySQL crashes R
> 
> 
> 
> I've got the same problem...
> 
> Best regards,
> David Tudor
> 

> -----Original Message-----
> From: Adelchi Azzalini [mailto:azzalini at stat.unipd.it]
> Sent: 14 May 2003 09:22
> To: Marsland, John
> Subject: Re: [R] RMySQL crashes R
> 
> 
> On Tuesday 13 May 2003 19:16, you wrote:
> > I have justed upgraded R v1.7.0 on Windows NT 4 and have 
> installed the
> > latest RMySQL (version 0.5-1)and DBI (version 0.1-5) packages.
> >
> > When I issue the following commands (tactfully adjusted) R 
> just crashes and
> > disappears, any ideas?
> >
> > require(RMySQL)
> > m <- dbDriver("MySQL")
> > con <- dbConnect(m, dbname="xxx", user="xxx", password="xxx",
> > host="myserver.com")
> 
> Unfortunately,  I cannot help ...in fact I have  the same 
> problem myself!
> only on a different environment (R 1.6.1 on Linux).  I wrote 
> to the R-help list 
> some time ago  about this, but only got an anwser from the 
> author of RMySQL 
> stating that the case is unusual, check the libaries, etc...
> 
> If you sort out how to habdle the problem, I would be 
> interested in knowing
> about it
> 
> good luck
> 
> Adelchi Azzalini
> 
> -- 
> Adelchi Azzalini  <azzalini at stat.unipd.it>
> Dipart.Scienze Statistiche, Universit? di Padova, Italia
> http://azzalini.stat.unipd.it/
> 


********************************************************************** 
This is a commercial communication from Commerzbank AG.\ \ This ... {{dropped}}



From V.Khamenia at BioVisioN.de  Thu May 15 09:39:20 2003
From: V.Khamenia at BioVisioN.de (Khamenia, Valery)
Date: Thu, 15 May 2003 09:39:20 +0200
Subject: [R] error-prone feature?
Message-ID: <D15343265276D31197BC00A024A6C110774051@EXS_BDC>

Hi All,

  while looking why the cclust(cclust) doesn't work for 1-dimensional data,
  I've found unpleasant behavior in semantics of R. Indeed:

    is.matrix(matrix(cbind(c(1,2,3,4)),ncol=2)[1:2,])  == TRUE

  but:

    is.matrix(matrix(c(1,2))[1:2,]) == FALSE
  

kind regards,
Valery A.Khamenya
---------------------------------------------------------------------------
Bioinformatics Department
BioVisioN AG, Hannover



From ripley at stats.ox.ac.uk  Thu May 15 09:54:00 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 15 May 2003 08:54:00 +0100 (BST)
Subject: [R] Importing S-Plus data sets into R
In-Reply-To: <C2C6EA6C4DADB348BFDF58894B0390120127311C@kinsrv001.dpi.qld.gov.au>
Message-ID: <Pine.LNX.4.44.0305150850590.8191-100000@gannet.stats>

On Thu, 15 May 2003, Dowkiw, Arnaud wrote:

> 3 steps :
> 
> under Splus:
> 
> > dput(data.frame,"data.frame.transfer")
> 
> then put "data.frame.transfer" in you working R Windows directory
> 
> under R :
> 
> >data.frame<-dget("data.frame.transfer")

That would mask the system function data.frame!

It's easier to use dump and source to transfer in source format.  If using
a current version of S-PLUS (5.x or 6.x), do use oldStyle=T when dumping.



> 
> Hope this helps.
> 
> Arnaud
> 
> -----Original Message-----
> From: Trudi O'Farrell [mailto:TOfarre1 at usc.edu.au]
> Sent: Thursday, 15 May 2003 3:06 PM
> To: r-help at stat.math.ethz.ch
> Cc: Trudi O'Farrell
> Subject: [R] Importing S-Plus data sets into R
> 
> 
> Dear All
> 
> I apologise for such a simplistic question.  However I am having immense
> trouble getting my S-Plus data set into R.  I have attempted
> data.dump/data.restore though I am unable to get it to work for me.  The
> error I am getting in R is :
> Error in seek(s) : no applicable method for "seek"
> 
> Is this the best way to import S-Plus datasets or is there another
> suggestion that I could try?  My data set is 284 variables with
> 1461rows.
> 
> Thank-you for your help in advance,
> 
> Trudi
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ********************************DISCLAIMER**********************... {{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu May 15 10:01:04 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 15 May 2003 09:01:04 +0100 (BST)
Subject: [R] error-prone feature?
In-Reply-To: <D15343265276D31197BC00A024A6C110774051@EXS_BDC>
Message-ID: <Pine.LNX.4.44.0305150854160.8191-100000@gannet.stats>

Well, that is in all good texts on R, together with the 
solution: drop=FALSE.  See ?"[" for the on-line details.

`S Programming' says

  S programmers have often overlooked these rules, which can result
  in puzzling or incorrect behaviour when just one observation or
  variable meets some selection criterion.

I suggest you get yourself a copy and read it.


On Thu, 15 May 2003, Khamenia, Valery wrote:

>   while looking why the cclust(cclust) doesn't work for 1-dimensional data,
>   I've found unpleasant behavior in semantics of R. Indeed:
> 
>     is.matrix(matrix(cbind(c(1,2,3,4)),ncol=2)[1:2,])  == TRUE
> 
>   but:
> 
>     is.matrix(matrix(c(1,2))[1:2,]) == FALSE


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Kosenkov.Kirill at nac.spb.ru  Thu May 15 10:04:42 2003
From: Kosenkov.Kirill at nac.spb.ru (Kosenkov Kirill)
Date: Thu, 15 May 2003 12:04:42 +0400
Subject: [R] how to include 'NA's in xtabs?
In-Reply-To: <3EC2ABE2.1090202@pdf.com>
References: <3EC2A490.7070609@nac.spb.ru> <3EC2ABE2.1090202@pdf.com>
Message-ID: <3EC34A1A.30900@nac.spb.ru>

Thanks for your reply, but i dont want to transform my data
with 'factor' or anything else. I really need 'NA's as NA's
and i dont need them as levels of factor.

I just seeking possibility to compute count of 'NA's with
'xtabs' without transforming my data. Maybe 'na.action' argument
in 'xtabs' may help? But i dont know how to use it.

Any suggestions?

Sundar Dorai-Raj wrote:

> 
> 
> Kosenkov Kirill wrote:
> 
>> Hello!
>>
>> I have a dataset with NA's in some variables (factors), for example:
>> $ P67 : Factor w/ 2 levels "-","+": NA 2 1 NA NA 2 1 1 2 NA ...
>>
> 
> The key is here. Should be 3 levels if you want NAs included.
> 

>> I need to use 'xtabs' like
>> xtabs(~x$P67)
>> It works well and produces something like this:
>> x$P67
>>    -    +
>>  779 1318
>> but i want to compute NA's too, like this:
>> x$P67
>>    -    +   NA
>>  779 1318  137
>>
>> I am trying xtabs(~x$P67, exclude=NULL) but xtabs does not compute 
>> 'NA's in this case too.
>>
>> I do not want to transform my data (do not want to do any substitution 
>> on NA's).
>>
>> How i can say 'xtabs' to compute NA-values?
>>
>> and second question: how to use argument 'na.action' in 'xtabs'?
>> 'xtabs' help page does not explain this.
>>
>> Thanks!
>>
> 
> 
> Try this:
> 
> x$P67 = factor(x$P67, exclude = NULL)
> xtabs(~x$P67)
> 
> 
> Here's an example:
> R> x = factor(c(1:2, NA), exclude = NULL, labels = c("+", "-", "0"))
> R> xtabs(~ x)
> x
> + - 0
> 1 1 1
> 
> Sundar
> 
> 
> 
> .
>



From maechler at stat.math.ethz.ch  Thu May 15 10:13:22 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 15 May 2003 10:13:22 +0200
Subject: [R] lme() vs aov(y ~ A*B + Error(aa %in% A + bb %in% B)) --
	questions
Message-ID: <16067.19490.804356.575252@gargle.gargle.HOWL>

Here is a reproducible (when you're on-net) script for a
relatively simple real data (consulting) situation here.

The data analyst tried to use lme() rather than  aov( + Error()) 
and asked several questions that I couldn't easily answer and
thought to be interesting for a more general audience in any
case.

I attach the script as text/plain file that you should run
"everywhere".  The three questions are summarized at the
beginning of the file.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: lme-ex4.R
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030515/c43b2bd1/lme-ex4.pl

From V.Khamenia at BioVisioN.de  Thu May 15 10:24:51 2003
From: V.Khamenia at BioVisioN.de (Khamenia, Valery)
Date: Thu, 15 May 2003 10:24:51 +0200
Subject: AW: [R] error-prone feature?
Message-ID: <D15343265276D31197BC00A024A6C110774052@EXS_BDC>

> Well, that is in all good texts on R, together with the 
> solution: drop=FALSE.  See ?"[" for the on-line details.

OK. Thank you a lot. Now patched cclust and clustIndex 
work fine for 1D case. BTW, why not to apply the "drop=F" 
to these functions? I guess other users need 1D case as 
well.

kind regards,
Valery A.Khamenya
---------------------------------------------------------------------------
Bioinformatics Department
BioVisioN AG, Hannover



From ripley at stats.ox.ac.uk  Thu May 15 10:31:06 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 15 May 2003 09:31:06 +0100 (BST)
Subject: AW: [R] error-prone feature?
In-Reply-To: <D15343265276D31197BC00A024A6C110774052@EXS_BDC>
Message-ID: <Pine.LNX.4.44.0305150929030.8282-100000@gannet.stats>

On Thu, 15 May 2003, Khamenia, Valery wrote:

> > Well, that is in all good texts on R, together with the 
> > solution: drop=FALSE.  See ?"[" for the on-line details.
> 
> OK. Thank you a lot. Now patched cclust and clustIndex 
> work fine for 1D case. BTW, why not to apply the "drop=F" 
> to these functions? I guess other users need 1D case as 
> well.

Nothing to do with me: you should report problems with packages to the 
maintainers, rather than R-help or a member of R-core.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From V.Khamenia at BioVisioN.de  Thu May 15 10:42:38 2003
From: V.Khamenia at BioVisioN.de (Khamenia, Valery)
Date: Thu, 15 May 2003 10:42:38 +0200
Subject: AW: AW: [R] error-prone feature?
Message-ID: <D15343265276D31197BC00A024A6C110774054@EXS_BDC>

> Nothing to do with me: you should report problems with 
> packages to the 
> maintainers, rather than R-help or a member of R-core.

OK. 
I've sent a note about cclust patch to Evgenia Dimitriadou

Thank you for your valueable comments.

(No more reply needed in this thread)

kind regards,
Valery A.Khamenya
---------------------------------------------------------------------------
Bioinformatics Department
BioVisioN AG, Hannover



From petr.pikal at precheza.cz  Thu May 15 11:03:55 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Thu, 15 May 2003 11:03:55 +0200
Subject: [R] how to include 'NA's in xtabs?
In-Reply-To: <3EC2A490.7070609@nac.spb.ru>
Message-ID: <3EC3741B.2743.75CBBE@localhost>

Hi

On 15 May 2003 at 0:18, Kosenkov Kirill wrote:

> Hello!
> 
> I have a dataset with NA's in some variables (factors), for example: $
> P67 : Factor w/ 2 levels "-","+": NA 2 1 NA NA 2 1 1 2 NA ...
> 
> I need to use 'xtabs' like
> xtabs(~x$P67)
> It works well and produces something like this:
> x$P67
>     -    +
>   779 1318
> but i want to compute NA's too, like this:
> x$P67
>     -    +   NA
>   779 1318  137

what about using summary instead of xtabs

> summary(ostbet$delka)
 159  160 NA's 
   5   22    3 

> xtabs(~ostbet$delka)
ostbet$delka
159 160 
  5  22 




> 
> I am trying xtabs(~x$P67, exclude=NULL) but xtabs does not compute
> 'NA's in this case too.
> 
> I do not want to transform my data (do not want to do any 
> substitution on NA's).
> 
> How i can say 'xtabs' to compute NA-values?
> 
> and second question: how to use argument 'na.action' in 'xtabs'?
> 'xtabs' help page does not explain this.
> 
> Thanks!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

Cheers
Petr Pikal
petr.pikal at precheza.cz
p.pik at volny.cz



From d.orme at imperial.ac.uk  Thu May 15 11:13:53 2003
From: d.orme at imperial.ac.uk (David Orme)
Date: Thu, 15 May 2003 10:13:53 +0100
Subject: [R] Compile R-1.7.0 on Mac OS 10.2.6
Message-ID: <8C5B3F75-86B5-11D7-B569-000393DC1748@ic.ac.uk>

Hi,

I can't get R-1.7.0 to compile on my Mac. Can someone give me some 
pointers?

The machine is an 800MHz iBook running OS 10.2.6. I have installed the 
December 2002 Developers Tools and have installed g77, f2c and dlcompat 
via fink. I've checked the versions of g77 and gcc and they're both 
based on gcc version 3.1. I've got Apple's X11 (Beta 3). I've added 
/sw/bin to my path. I've read through R-admin.pdf, particularly the 
appendix on OS X.

The problem seems to be something to do with the fortran compiler. The 
final lines of the configure output are:

> checking how to get verbose linking output from g77... configure: 
> WARNING: compilation failed
>
> checking for Fortran 77 libraries...
> checking for dummy main to link with Fortran 77 libraries... none
> checking for Fortran 77 name-mangling scheme... configure: error: 
> cannot compile a simple Fortran program
> See `config.log' for more details.

Checking config.log, both the warning and error are associated with the 
following message:

> dyld: g77 version mismatch for library: /sw/lib/libiconv.2.dylib 
> (compatibility version of user: 4.0.0 greater than library's version: 
> 3.0.0)

Can anyone help?

Many thanks,
David
---------------------------------------
Dr. David Orme

Department of Biological Sciences
Imperial College London
Silwood Park Campus
Ascot, Berkshire SL5 7PY UK.

Tel: +44 (0)20 759 42358
Fax: +44 (0)20 759 42339
e-mail: d.orme at imperial.ac.uk



From Philippe.Hupe at curie.fr  Thu May 15 10:51:07 2003
From: Philippe.Hupe at curie.fr (=?ISO-8859-1?Q?Philippe_Hup=E9?=)
Date: Thu, 15 May 2003 10:51:07 +0200
Subject: [R] hclust function
In-Reply-To: <D15343265276D31197BC00A024A6C110774052@EXS_BDC>
References: <D15343265276D31197BC00A024A6C110774052@EXS_BDC>
Message-ID: <3EC354FB.1090902@curie.fr>


I am trying to use hclust function from mva package but I can't 
understand what the variable height stands for when I use the ward 
criterion. Here is a small example :

library(mva)
x <- c(1,2,3,4)
cluster <- hclust(dist(x), method="ward")
cluster$height

cluster$height = 1 1 3 but it is supposed to be 0.5 0.5 4

the distance between clusters is Ni*Nj/(Ni+Nj)*||Gi-Gj||^2 and 
cluster$height does not match with this distance.

Does someone has any idea ?

Thanks in advance.

Philippe Hup?

-- 

--------------------------------------------------

Philippe Hup?
Institut Curie - Equipe Bioinformatique
26, rue d'Ulm - 75005 PARIS France
+33 (0)1 42 34 65 29

Philippe.Hupe at curie.fr <mailto:Philippe.Hupe at curie.fr>



From alkatz at post.tau.ac.il  Thu May 15 10:56:33 2003
From: alkatz at post.tau.ac.il (alkatz@post.tau.ac.il)
Date: Thu, 15 May 2003 11:56:33 +0300 (IDT)
Subject: [R] A question
Message-ID: <1052988993.3ec35641405b2@webmail.tau.ac.il>

Hello everyone ,

I would like to know if there exists a possibility
to run R function without using R GUI. 

Is it possible to run my R script *.R 
from DOS command prompt without starting the GUI ?

Thanks for help,
Alex.



From ripley at stats.ox.ac.uk  Thu May 15 12:17:06 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 15 May 2003 11:17:06 +0100 (BST)
Subject: [R] A question
In-Reply-To: <1052988993.3ec35641405b2@webmail.tau.ac.il>
Message-ID: <Pine.LNX.4.44.0305151114060.19265-100000@gannet.stats>

On Thu, 15 May 2003 alkatz at post.tau.ac.il wrote:

> I would like to know if there exists a possibility
> to run R function without using R GUI. 
> 
> Is it possible to run my R script *.R 
> from DOS command prompt without starting the GUI ?

Under Windows, yes -- see the README.rw1070 file or rw-FAQ Q2.10.
Both files are in the top-level installation directory.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From kwan022 at stat.auckland.ac.nz  Thu May 15 12:20:50 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Thu, 15 May 2003 22:20:50 +1200 (NZST)
Subject: Running R in Batch Mode in Windows (was Re: [R] A question
In-Reply-To: <1052988993.3ec35641405b2@webmail.tau.ac.il>
Message-ID: <Pine.LNX.4.44.0305152220010.29657-100000@stat56.stat.auckland.ac.nz>

Hi,

Please read 2.10 of R for Windows FAQ

On Thu, 15 May 2003 alkatz at post.tau.ac.il wrote:

> Date: Thu, 15 May 2003 11:56:33 +0300 (IDT)
> From: alkatz at post.tau.ac.il
> To: r-help at stat.math.ethz.ch
> Subject: [R] A question
> 
> Hello everyone ,
> 
> I would like to know if there exists a possibility
> to run R function without using R GUI. 
> 
> Is it possible to run my R script *.R 
> from DOS command prompt without starting the GUI ?
> 
> Thanks for help,
> Alex.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)



From kurt.sys at UGent.be  Thu May 15 12:32:33 2003
From: kurt.sys at UGent.be (Kurt Sys)
Date: Thu, 15 May 2003 12:32:33 +0200
Subject: [R] kolmogorov-smirnov
Message-ID: <16067.27841.88275.963226@ksys.rug.ac.be>

Hello,

I got a rather simple question: Can I find somewhere in R the
significance values for a Kolmogorov distribution (I know the degrees
of freedom and I have already the maximum deviation). ks.test is not
really doing what I want. All I need is the values, like one can get
the values for a chi-squared distribution by 'qchisq(0.05, 375)'.

tnx,
Kurt.



From fharrell at virginia.edu  Thu May 15 12:38:10 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Thu, 15 May 2003 06:38:10 -0400
Subject: [R] Manly's randomization analysis of multiple regression
In-Reply-To: <E19G8r9-0006ji-00@server.family>
References: <E19G8r9-0006ji-00@server.family>
Message-ID: <20030515063810.07ff7acb.fharrell@virginia.edu>

On Wed, 14 May 2003 22:52:33 -0400
Nurnberg-LaZerte <mail at fwr.on.ca> wrote:

> My wife has been using a diagnostic from Manley (1991; "Randomization and MonteCarlo Methods in Biology") that compares a normal multiple regression's performance with that using random predicted variables. 
> 
> Is there something like this already available in R? 
> 
> If not, the "boot" package looks like a good place to start looking for methods, no?
> 
> Thanks in advance 
> Bruce L.

This is related to that: Look at the validate function in the Design package (http://hesweb1.med.virginia.edu/biostat/s/Design.html) which has a "randomize" option to get the apparent and validated performance of models fitted by randomly permuting the vector of response variable values.  This is not a high-precision way to estimate bias in your original R^2 etc. but rather is a teaching tool.  For efficient estimation of future model performance use the validation bootstrap option (the default for validate( )).
---
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From nielssteenkrogh at hotmail.com  Thu May 15 13:34:12 2003
From: nielssteenkrogh at hotmail.com (Niels Steen Krogh)
Date: Thu, 15 May 2003 13:34:12 +0200
Subject: [R] RMySQL crashes R
Message-ID: <BAY7-F58G8vGIFPOONG00021cdd@hotmail.com>

I havn't  tried your mysql-approach, but have with no problems used
a very different approach to connect R and mysql (and other
databases)

I use the folowing setup (everything opensource with no licensing
costs):

- Linux Redhat 8.0
- Zope 2.6.1  (www.zope.org)
- RSessionDA, RSOAP and rpy  (find via www.google.com)
- R1.6.2 with SESSION package (SESSION package is included in the RSESSIONDA 
download)
- Mysql 3.23.52 (included in Redhat 8.0 distr.)

In this setup R and Mysql are webservices connected via Zopes
python-based technology.
This approach makes it very easy to distribute the use of R and
mysql since the userinterface is the web.  And the approach also
makes it very easy to svitch from mysql to postgresql or Oracle as
the backend database.

I you want to try this solution before you start building please
send me a mail, and I shall open my router for a short while.

I also have a few screenshots showing integration to Excel from R
(via zope) here. The text is in danish, but the pictures should be
selfexplanatory: 
http://www.zug.dk/Members/Nielssteenkrogh/1049270051696377330/view

Regards
Niels

Cand. Polit.
Niels Steen Krogh
Solsortvej 44
2000 F.

Tlf: 3888 8613

ZiteLab / EmpoweR youR data

_________________________________________________________________
F Hotmail p mobilen http://www.msn.dk/mobile



From koller at isis.wu-wien.ac.at  Thu May 15 14:03:17 2003
From: koller at isis.wu-wien.ac.at (Wolfgang Koller)
Date: Thu, 15 May 2003 14:03:17 +0200
Subject: [R] Some Programming Humor - Quine
In-Reply-To: <3EC28FD8.6000601@lancaster.ac.uk>
References: <3EC20E5C.5080201@lancaster.ac.uk>
	<6rvfwe5qob.fsf@bates4.stat.wisc.edu>
	<6rr8725pnw.fsf@bates4.stat.wisc.edu>
	<3EC20E5C.5080201@lancaster.ac.uk>
Message-ID: <3.0.6.32.20030515140317.00909c00@isis.wu-wien.ac.at>

Hi Barry! Hi helplist!

What about this piece of code?

quc1 <- "function () { STR <- "
quc2 <-
"substr(deparse(paste)[1],start=24,stop=24); "
quc3 <- "recstr <-
function(str=character(1),pos=195) "
quc4 <-
"paste(substr(str,1,pos-1),"
quc5 <- "str,substr(str,pos,1000),sep=STR);
"
quc6 <- "eval(parse(text=recstr("
qucode <-
paste(quc1,quc2,quc3,quc4,quc5,quc6,sep="")
qucode <-
paste(qucode,paste(qucode,")))}",sep=""),")))}",sep="\"")
quine <-
eval(parse(text=qucode))

It passes the following quine-test:

> all(deparse(quine)==deparse(quine()))
[1] TRUE
> all(deparse(quine())==deparse(quine()()))
[1] TRUE

By the way, some questions that arose in this programming exercise:
a) is there a simpler way to do the assignment 
     STR <- "\""
   without using quotes?

b) what does this cryptic <environment: 034768AC> (or similar) mean that
does appear after the return value of quine() but not after the result of
quine?

c) is there a better way to check if two functions are identical than the
way suggested above?


Wolfgang


-------------------------------------------------
Wolfgang Koller,  wolfgang.koller at wu-wien.ac.at
Forschungsinstitut f?r Europafragen
Wirtschaftsuniversit?t Wien
Althanstra?e 39-45, 1090 Vienna, Austria
Tel: ++43/1/31336/4147  Fax: ++43/1/31336/758
http://fgr.wu-wien.ac.at/institut/ef/ief-home.htm



From ripley at stats.ox.ac.uk  Thu May 15 14:17:20 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 15 May 2003 13:17:20 +0100 (BST)
Subject: [R] Some Programming Humor - Quine
In-Reply-To: <3.0.6.32.20030515140317.00909c00@isis.wu-wien.ac.at>
Message-ID: <Pine.LNX.4.44.0305151311490.19596-100000@gannet.stats>

On Thu, 15 May 2003, Wolfgang Koller wrote:

> By the way, some questions that arose in this programming exercise:
> a) is there a simpler way to do the assignment 
>      STR <- "\""
>    without using quotes?

Not simpler, but '"' is probably easier to read.

> b) what does this cryptic <environment: 034768AC> (or similar) mean that
> does appear after the return value of quine() but not after the result of
> quine?

All R functions have environments.  This is not printed when the function
is printed if and only if the environment is the user's workspace.
The number is a Hex address of the environment, and you will see it when 
functions are defined or generated inside functions.

> c) is there a better way to check if two functions are identical than the
> way suggested above?

?identical

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From koller at isis.wu-wien.ac.at  Thu May 15 14:20:36 2003
From: koller at isis.wu-wien.ac.at (Wolfgang Koller)
Date: Thu, 15 May 2003 14:20:36 +0200
Subject: [R] Some Programming Humor - Quine
Message-ID: <3.0.6.32.20030515142036.008eee50@isis.wu-wien.ac.at>

Hi! 

It seems as if the email-program has spoiled the script, therefore a second
try (in case it is spoiled again I give a hint how to repair it: the
strings quc1, quc2, quc3, quc5 all end on a blank):

quc1<-"function () { STR <- "
quc2<-"substr(deparse(paste)[1],start=24,stop=24); "
quc3<-"recstr <- function(str=character(1),pos=195) "
quc4<-"paste(substr(str,1,pos-1),"
quc5<-"str,substr(str,pos,1000),sep=STR); "
quc6<-"eval(parse(text=recstr("
qucode<-paste(quc1,quc2,quc3,quc4,quc5,quc6,sep="")
qucode<-paste(qucode,paste(qucode,")))}",sep=""),")))}",sep="\"")
quine<-eval(parse(text=qucode))

Wolfgang




-------------------------------------------------
Wolfgang Koller,  wolfgang.koller at wu-wien.ac.at
Forschungsinstitut f?r Europafragen
Wirtschaftsuniversit?t Wien
Althanstra?e 39-45, 1090 Vienna, Austria
Tel: ++43/1/31336/4147  Fax: ++43/1/31336/758
http://fgr.wu-wien.ac.at/institut/ef/ief-home.htm



From koller at isis.wu-wien.ac.at  Thu May 15 14:43:00 2003
From: koller at isis.wu-wien.ac.at (Wolfgang Koller)
Date: Thu, 15 May 2003 14:43:00 +0200
Subject: [R] Some Programming Humor - Quine
In-Reply-To: <Pine.LNX.4.44.0305151311490.19596-100000@gannet.stats>
References: <3.0.6.32.20030515140317.00909c00@isis.wu-wien.ac.at>
Message-ID: <3.0.6.32.20030515144300.00908bc0@isis.wu-wien.ac.at>

At 13:17 15.05.03 +0100, Prof Brian Ripley wrote:
>On Thu, 15 May 2003, Wolfgang Koller wrote:
>
>> By the way, some questions that arose in this programming exercise:
>> a) is there a simpler way to do the assignment 
>>      STR <- "\""
>>    without using quotes?
>
>Not simpler, but '"' is probably easier to read.
This version still uses a quote --- the one in the middle. With "simpler" I
meant in comparison with the version I used in quine()-code, which is
admittedly ugly and depends on the source code of paste(), but does not use
quotes (nor double quotes or whatever ' and " are correctly named in English):
  STR <- substr(deparse(paste)[1],start=24,stop=24)

Maybe something analogous to letters[] would be a nice additional feature
in R? I have needed something like that on several occasions before.

>
>> b) what does this cryptic <environment: 034768AC> (or similar) mean that
>> does appear after the return value of quine() but not after the result of
>> quine?
>
>All R functions have environments.  This is not printed when the function
>is printed if and only if the environment is the user's workspace.
>The number is a Hex address of the environment, and you will see it when 
>functions are defined or generated inside functions.
>
>> c) is there a better way to check if two functions are identical than the
>> way suggested above?
>
>?identical

so my quine-version seems not to pass this test:
> identical(quine,quine())
[1] FALSE
> identical(quine(),quine()())
[1] FALSE
> 
has this to do with the environment somehow being part of the function? I
dont quite understand, since quine(), quine()(), quine()()() all look quite
identical to me, save the information about the environment that is added
after the return value.

Wolfgang
-------------------------------------------------
Wolfgang Koller,  wolfgang.koller at wu-wien.ac.at
Forschungsinstitut f?r Europafragen
Wirtschaftsuniversit?t Wien
Althanstra?e 39-45, 1090 Vienna, Austria
Tel: ++43/1/31336/4147  Fax: ++43/1/31336/758
http://fgr.wu-wien.ac.at/institut/ef/ief-home.htm



From dmurdoch at pair.com  Thu May 15 14:43:23 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu, 15 May 2003 08:43:23 -0400
Subject: [R] abrupt end to R
In-Reply-To: <5.2.0.9.0.20030515001955.00b33b58@pop3.evhr.net>
References: <5.2.0.9.0.20030515001955.00b33b58@pop3.evhr.net>
Message-ID: <sa27cvo904p00hl4aq6rcvpdpr2k7hmnnn@4ax.com>

On Thu, 15 May 2003 00:27:26 +0200, you wrote:

>
>Dear All,
>
>I haven't seen any further comments about the problem that John Marsland 
>first noted and that I also have:
>
> > library(DBI)
> > library(RMySQL)
>Warning message:
>DLL attempted to change FPU control word from 8001f to 9001f

It's a bad idea to ignore warnings!  This says that there's a problem
with the DLL that RMySQL is loading.  It is attempting to change the
rounding behaviour, and R is fighting back.  I don't know if that
would cause the error below, but it's a possibility.

> > mgr <- dbDriver("MySQL")
> > con <- dbConnect(mgr, host="localhost", dbname="marketing")
>
>upon which R dies...
>
>Dr. Mingw says:
>
>Rgui.exe caused an Access Violation at location 77c13730 in module 
>msvcrt.dll Reading from location 00000000.
>
>Registers:
>eax=10e501a0 ebx=00000000 ecx=00000000 edx=10e51fe0 esi=00000000 edi=003e3d08
>eip=77c13730 esp=0022d5ac ebp=0022d7f8 iopl=0         nv up ei pl zr na po nc
>cs=001b  ss=0023  ds=0023  es=0023  fs=0038  gs=0000             efl=00000246
>
>Call stack:
>77C13730  msvcrt.dll:77C13730  strlen
>004C799D  R.dll:004C799D  do_dotcall
 ...

I've cc'd this to the RMySQL maintainer David James; David J, if you
don't know what I'm talking about regarding rounding, I'd be happy to
expand on it.

Duncan Murdoch



From ripley at stats.ox.ac.uk  Thu May 15 15:07:17 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 15 May 2003 14:07:17 +0100 (BST)
Subject: [R] Some Programming Humor - Quine
In-Reply-To: <3.0.6.32.20030515144300.00908bc0@isis.wu-wien.ac.at>
Message-ID: <Pine.LNX.4.44.0305151405380.19746-100000@gannet.stats>

On Thu, 15 May 2003, Wolfgang Koller wrote:

> At 13:17 15.05.03 +0100, Prof Brian Ripley wrote:
> >On Thu, 15 May 2003, Wolfgang Koller wrote:
> >
> >> By the way, some questions that arose in this programming exercise:
> >> a) is there a simpler way to do the assignment 
> >>      STR <- "\""
> >>    without using quotes?
> >
> >Not simpler, but '"' is probably easier to read.
> This version still uses a quote --- the one in the middle. With "simpler" I
> meant in comparison with the version I used in quine()-code, which is
> admittedly ugly and depends on the source code of paste(), but does not use
> quotes (nor double quotes or whatever ' and " are correctly named in English):
>   STR <- substr(deparse(paste)[1],start=24,stop=24)
> 
> Maybe something analogous to letters[] would be a nice additional feature
> in R? I have needed something like that on several occasions before.

What analogue do you have in mind: remember the encoding is OS- and 
locale-dependent?  I've written CharToInt and IntToChar functions on 
occasion.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From spencer.graves at pdf.com  Thu May 15 15:19:18 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 15 May 2003 06:19:18 -0700
Subject: [R] kolmogorov-smirnov
References: <16067.27841.88275.963226@ksys.rug.ac.be>
Message-ID: <3EC393D6.3090408@pdf.com>

Have you considered the following:

 > ks.test(1:5, "pnorm")$p.value
[1] 0.001685888

hth.  spencer graves

Kurt Sys wrote:
> Hello,
> 
> I got a rather simple question: Can I find somewhere in R the
> significance values for a Kolmogorov distribution (I know the degrees
> of freedom and I have already the maximum deviation). ks.test is not
> really doing what I want. All I need is the values, like one can get
> the values for a chi-squared distribution by 'qchisq(0.05, 375)'.
> 
> tnx,
> Kurt.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From B.Rowlingson at lancaster.ac.uk  Thu May 15 15:43:37 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 15 May 2003 14:43:37 +0100
Subject: [R] Some Programming Humor - Quine
In-Reply-To: <3.0.6.32.20030515144300.00908bc0@isis.wu-wien.ac.at>
References: <3.0.6.32.20030515140317.00909c00@isis.wu-wien.ac.at>
	<3.0.6.32.20030515144300.00908bc0@isis.wu-wien.ac.at>
Message-ID: <3EC39989.3000809@lancaster.ac.uk>


> so my quine-version seems not to pass this test:
> 
>>identical(quine,quine())
> 
> [1] FALSE
> 
>>identical(quine(),quine()())
> 
> [1] FALSE
> 
> has this to do with the environment somehow being part of the function? I
> dont quite understand, since quine(), quine()(), quine()()() all look quite
> identical to me, save the information about the environment that is added
> after the return value.
> 

  Thats right. Even if the environment isn't printed, its still there, 
and so the quine fails the 'identical' test.

  If you can adjust your code to return an object with the same 
environment as itself then it will work

 > q2 <- quine()
 > identical(q2,quine)
[1] FALSE
 > environment(q2) <- environment(quine)
 > identical(q2,quine)
[1] TRUE

  In fact all you need to do is set the environment to globalenv(). I'm 
sure a minor adjustment to your script can fix this!


Baz



From pgilbert at bank-banque-canada.ca  Thu May 15 17:20:03 2003
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Thu, 15 May 2003 11:20:03 -0400
Subject: [R] R as 64 bit application
Message-ID: <3EC3B023.D3E52447@bank-banque-canada.ca>

In a package test I have a problem that needs over 4G of memory. This requires
that I use R compiled as a 64 bit application. Is there a way within R to test
if R has been compile as a 64 bit application? This would allow me to
automatically skip the test when I know it is going to fail.

Thanks,
Paul Gilbert



From brahm at alum.mit.edu  Thu May 15 17:32:44 2003
From: brahm at alum.mit.edu (David Brahm)
Date: Thu, 15 May 2003 11:32:44 -0400
Subject: [R] <-
References: <Pine.SOL.3.96.1030514121147.18819A-100000@draco.cus.cam.ac.uk>
Message-ID: <16067.45852.564108.66287@arbres1a.fmr.com>

Damon Wischik <djw1005 at cam.ac.uk> wrote:
> One thing I would find very handy is a shortcut for
>   res <- myfunc()
>   a <- res$val1
>   b <- res$val2
> Something along the lines of
>   list(a=val1,b=val2) <- myfunc()
> but I don't know what the right syntax would be or how I'd go about
> programming it. Any suggestions?

I agree this would be handy!  And appealing to Perl folks who are used to:
  Perl> ($arg1, $arg2) = @ARGV;
I couldn't figure out how to do it with replacement functions (see Prof Brian
Ripley's <ripley at stats.ox.ac.uk> reply), but here's another approach:

multi.assign <- function(x, ...) {
  mycall <- match.call()[-2]
  mycall[1] <- call("list")
  mylist <- eval(mycall, x)
  for (i in names(mylist)) assign(i, mylist[[i]], parent.frame())
}

Here's an example:
  R> myfunc <- function() list(val1=7, val2=c(5,5))
  R> multi.assign(myfunc(), a=val1, b=val2, d=val1+val2)
  R> a
     [1] 7
  R> b
     [1] 5 5
  R> d
     [1] 12 12
-- 
                              -- David Brahm (brahm at alum.mit.edu)



From kurt.sys at UGent.be  Thu May 15 17:52:53 2003
From: kurt.sys at UGent.be (Kurt Sys)
Date: Thu, 15 May 2003 17:52:53 +0200
Subject: [R] Re: kolmogorov-smirnov
In-Reply-To: <16067.27841.88275.963226@ksys.rug.ac.be>
References: <16067.27841.88275.963226@ksys.rug.ac.be>
Message-ID: <16067.47061.101470.448068@ksys.rug.ac.be>

OK... problem solved. The values can easily be calculated, as long as
there are 'enough' d.f. (for 0.05: 1.36/sqrt(d.f.))


Kurt.


--
Mail from Kurt Sys
sent on Thursday May 15 2003 at 12:32 (GMT+0200):

> Hello,
> 
> I got a rather simple question: Can I find somewhere in R the
> significance values for a Kolmogorov distribution (I know the
> degrees of freedom and I have already the maximum
> deviation). ks.test is not really doing what I want. All I need is
> the values, like one can get the values for a chi-squared
> distribution by 'qchisq(0.05, 375)'.
> 
> tnx, Kurt.

-- 
Prediction is very difficult, especially of the future.
		-- Niels Bohr



From azzalini at stat.unipd.it  Thu May 15 18:07:51 2003
From: azzalini at stat.unipd.it (Adelchi Azzalini)
Date: Thu, 15 May 2003 18:07:51 +0200
Subject: [R] abrupt end to R
In-Reply-To: <sa27cvo904p00hl4aq6rcvpdpr2k7hmnnn@4ax.com>
References: <5.2.0.9.0.20030515001955.00b33b58@pop3.evhr.net>
	<sa27cvo904p00hl4aq6rcvpdpr2k7hmnnn@4ax.com>
Message-ID: <20030515160752.1CA237CA824@tango.stat.unipd.it>

On Thursday 15 May 2003 14:43, Duncan Murdoch wrote:
> On Thu, 15 May 2003 00:27:26 +0200, you wrote:
> >Dear All,
> >
> >I haven't seen any further comments about the problem that John Marsland
> >
> >first noted and that I also have:
> > > library(DBI)
> > > library(RMySQL)
> >
> >Warning message:
> >DLL attempted to change FPU control word from 8001f to 9001f
>
> It's a bad idea to ignore warnings!  This says that there's a problem
>

In general, I agree ...of course.  However, I have a similar experience even
without warnings:

>  library(DBI)
> library(RMySQL)
>  handle<-dbDriver("MySQL")
> handle
<MySQLDriver:(958)> 
>  con<-dbConnect(handle, dbname="xxxx",  host="tango", user="aa")
Segmentation fault

The actual dbname has been replaced by "xxxx", but it does not matter
what I write there; the outcome is the same.  Also, changing the host="tango"
to host="localhost" or to the full computer name makes no difference. 

The environment is as follows:         _    
            
platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    6.1              
year     2002             
month    11               
day      01               
language R         

DBI version 0.1-4
RMySQL version 0.5-0

[tango:aa:~/SW] mysql --version
mysql  Ver 11.16 Distrib 3.23.49, for pc-linux-gnu (i686)

The fanny thing is that my students can connect to my computer and use 
the database from the computer lab (with R 1.6.1 for Windows) without problems!

Regards,

Adelchi Azzalini

-- 
Adelchi Azzalini  <azzalini at stat.unipd.it>
Dipart.Scienze Statistiche, Universit? di Padova, Italia
http://azzalini.stat.unipd.it/



From tlumley at u.washington.edu  Thu May 15 18:09:01 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 15 May 2003 09:09:01 -0700 (PDT)
Subject: [R] R as 64 bit application
In-Reply-To: <3EC3B023.D3E52447@bank-banque-canada.ca>
Message-ID: <Pine.A41.4.44.0305150902550.23588-100000@homer36.u.washington.edu>

On Thu, 15 May 2003, Paul Gilbert wrote:

> In a package test I have a problem that needs over 4G of memory. This
> requires that I use R compiled as a 64 bit application. Is there a way
> within R to test if R has been compile as a 64 bit application? This
> would allow me to automatically skip the test when I know it is going to
> fail.
>

I don't think so.  You could use a simple C function


  void is64bit (int *sizeptr){
	*sizeptr = sizeof sizeptr ==8;
	return;
	}


  is64bit<-function(){
	.C("is64bit",logical(1))[[1]]
	}


	-thomas



From ripley at stats.ox.ac.uk  Thu May 15 18:18:05 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 15 May 2003 17:18:05 +0100 (BST)
Subject: [R] R as 64 bit application
In-Reply-To: <Pine.A41.4.44.0305150902550.23588-100000@homer36.u.washington.edu>
Message-ID: <Pine.LNX.4.44.0305151712340.1110-100000@gannet.stats>

On Thu, 15 May 2003, Thomas Lumley wrote:

> On Thu, 15 May 2003, Paul Gilbert wrote:
> 
> > In a package test I have a problem that needs over 4G of memory. This
> > requires that I use R compiled as a 64 bit application. Is there a way
> > within R to test if R has been compile as a 64 bit application? This
> > would allow me to automatically skip the test when I know it is going to
> > fail.
> >
> 
> I don't think so.  You could use a simple C function
> 
> 
>   void is64bit (int *sizeptr){
> 	*sizeptr = sizeof sizeptr ==8;
> 	return;
> 	}
> 
> 
>   is64bit<-function(){
> 	.C("is64bit",logical(1))[[1]]
> 	}
> 

You could call object.size:

> object.size(numeric(0)) #32-bit
[1] 28
> object.size(numeric(0)) #64-bit
[1] 56

or you could look at the results of gc():

> foo <- gc()
> foo[1,4]/foo[1,3]*2^20
[1] 56.05374

and it's about 28 on a 32-bit system.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From klaus.thul at infineon.com  Thu May 15 19:04:24 2003
From: klaus.thul at infineon.com (klaus.thul@infineon.com)
Date: Thu, 15 May 2003 19:04:24 +0200
Subject: [R] Cumulated probability plot
Message-ID: <2B302C161738D611915300300530013F01734ED4@drsse109.drs.infineon.com>

Hello,

is there an easy possiblity in R to produce a plot of the cumulative
probability of a variable in R? (variable given as a sample vector)

Regards,
Klaus Thul



From ypeng at math.mun.ca  Thu May 15 19:21:45 2003
From: ypeng at math.mun.ca (Paul Y. Peng)
Date: Thu, 15 May 2003 14:51:45 -0230
Subject: [R] savehistory not working properly in R?
References: <Pine.LNX.4.44.0305150732220.7760-100000@gannet.stats>
Message-ID: <3EC3CCA9.D2E44FF8@math.mun.ca>

Prof Brian Ripley wrote:
> 
> On Wed, 14 May 2003, Paul Y. Peng wrote:
> 
> > I have a .RData which contains .Last object as follows:
> >
> >       .Last <- function ()
> >       {
> >               savehistory(file = ".Rhistory")
> >       }
> >
> > In this directory, if I issue the following command
> >
> >       Rterm --save < mycmds.q
> >
> > to execute commands in mycmds.q and to save results in .RData,
> > I got the following error message towards the end of the execution:
> >
> >       Error in savehistory(file) : savehistory can only be used
> >       in Rgui and Rterm
> >       Execution halted
> >
> > I lost the results of the commands too. The documentation of
> > "savehistory" says that it only works with Rgui and Rterm. Why
> > doesn't it work in this case? Is it because it is in a batch mode
> > rather than in an interactive mode?
> 
> Yes.  The history is associated with the command-line editing: what you
> are doing is considered to be BATCH use.
> >
> > Is it possible to prevent savehistory from printing the error message
> > so that the session can be finished properly? I hope that I did not
> > miss anything obvious. Otherwise, please forgive me. Thanks.
> 
> The real problem is in your .Last.  You could do
> 
> .Last <- function ()
> {
>     if(interactive()) savehistory(file = ".Rhistory")
> }

Many thanks. As always, your suggestion works. I should have thought
about interactive().

> or use try():  if you are worried about not saving .RData you really
> should protect the commands in .Last (see its help page for warnings).

I will give try() a real try. It seems to be quite useful.

> I'll see if the documentation can be clarified.

Why does R save its command history only when one saves the data
image of the session? Is this a feature? Even though .Last can do
this, would it be more convenient if R can do this automatically?
Logically, I feel the command history should be treated separately.

Paul.



From deepayan at stat.wisc.edu  Thu May 15 19:39:52 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 15 May 2003 12:39:52 -0500
Subject: [R] Cumulated probability plot
In-Reply-To: <2B302C161738D611915300300530013F01734ED4@drsse109.drs.infineon.com>
References: <2B302C161738D611915300300530013F01734ED4@drsse109.drs.infineon.com>
Message-ID: <200305151239.52627.deepayan@stat.wisc.edu>

On Thursday 15 May 2003 12:04, klaus.thul at infineon.com wrote:
> Hello,
>
> is there an easy possiblity in R to produce a plot of the cumulative
> probability of a variable in R? (variable given as a sample vector)

What do you mean by cumulative probability ? If you mean the Empirical 
Distribution Function, try

x <- rnorm(100)
library(stepfun)
plot(ecdf(x))

-Deepayan



From dnogues at ipe.csic.es  Thu May 15 19:41:00 2003
From: dnogues at ipe.csic.es (=?ISO-8859-1?Q?David_Nogu=E9s?=)
Date: Thu, 15 May 2003 19:41:00 +0200
Subject: [R] plot question
Message-ID: <3EC3D12C.1020306@ipe.csic.es>

Hello:

Im a novice user of R. I was triying develop graphs with plot.lm or 
plot(gam) but I dont obtain a desire result. I would like to create a 
plot from lm, glm and gam objects showing:

1- Fit curve
2- Raw data of predictor and response variables as points.
3- Confidence intervals (95%)

Anybody can help me?  

-- 
David Nogu?s Bravo

Functional Ecology and Biodiversity Department
Pyrenean Institute of Ecology
Spanish Research Council

Av. Monta?ana 1005
Zaragoza - CP 50059
976716030 - 976716019 (fax)



From macq at llnl.gov  Thu May 15 19:57:01 2003
From: macq at llnl.gov (Don MacQueen)
Date: Thu, 15 May 2003 10:57:01 -0700
Subject: [R] Cumulated probability plot
In-Reply-To: <2B302C161738D611915300300530013F01734ED4@drsse109.drs.infineon.com>
References: <2B302C161738D611915300300530013F01734ED4@drsse109.drs.infineon.com>
Message-ID: <p05210602bae98504b04c@[128.115.153.6]>

Yes it is possible.

Start your search for a solution with the quantile() function:

>  quantile(rnorm(100))
          0%         25%         50%         75%        100%
-2.73069396 -0.76456805  0.02988956  0.62436410  2.59762742

-Don

At 7:04 PM +0200 5/15/03, klaus.thul at infineon.com wrote:
>Hello,
>
>is there an easy possiblity in R to produce a plot of the cumulative
>probability of a variable in R? (variable given as a sample vector)
>
>Regards,
>Klaus Thul
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From mihastaut at hotmail.com  Thu May 15 19:57:12 2003
From: mihastaut at hotmail.com (Miha STAUT)
Date: Thu, 15 May 2003 17:57:12 +0000
Subject: [R] Re: list GRASSLIST: List Message Rejected
Message-ID: <BAY2-F7QJXs7k46ls7N00004781@hotmail.com>

I appologise sincerly, will not happen again.

mr. Ripley: Your suggestions were helpful, thanks. I figured I haven not 
installed the devel RPMS.


>From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
>To: listproc at baylor.edu
>CC: grass-request at baylor.edu, Miha STAUT <mihastaut at hotmail.com>
>Subject: Re: list GRASSLIST: List Message Rejected
>Date: Thu, 15 May 2003 07:50:19 +0100 (BST)
>
>Please ask your subscribers not to add your list to postings to open
>lists, to avoid annoying legitimate users of those lists.
>
>Mr Stout: please note the errors of your ways.
>
>On Wed, 14 May 2003 listproc at baylor.edu wrote:
>
> > Dear ripley at stats.ox.ac.uk:
> >
> > Your recent message to the GRASSLIST list has been
> > rejected for the following reason:
> >
> > Only list subscribers may send messages to this list.
> >
> > If you need assistance, please contact the list owner at
> > GRASSLIST-request at baylor.edu
> >
> > The text of your message follows:
> > ----------------------------------------------------------------------
> > Received: from FS-EXCHANGE1.baylor.edu (flopsy.baylor.edu 
>[129.62.3.249])
> > 	by ccis01.baylor.edu (8.9.3p2/8.9.1) with ESMTP id PAA1321941
> > 	for <GRASSLIST at listproc.baylor.edu>; Sun, 11 May 2003 15:34:02 -0500 
>(CDT)
> > Received: from waylon.baylor.edu ([129.62.3.228]) by 
>FS-EXCHANGE1.baylor.edu with Microsoft SMTPSVC(5.0.2195.4561);
> > 	 Sun, 11 May 2003 15:34:02 -0500
> > Received: from elron.baylor.edu ([129.62.3.143]) by waylon.baylor.edu 
>with Microsoft SMTPSVC(5.0.2195.4561);
> > 	 Sun, 11 May 2003 15:34:02 -0500
> > Received: from willie.baylor.edu (willie.baylor.edu [129.62.3.227])
> > 	by elron.baylor.edu (Switch-2.2.6/Switch-2.2.4) with SMTP id 
>V4BK1XMX18842
> > 	for <grasslist at baylor.edu>; Sun, 11 May 2003 15:33:58 -0500
> > Received: from toucan.stats.ox.ac.uk ([163.1.20.20])
> >  by willie.baylor.edu (NAVGW 2.5.1.13) with SMTP id M2003051115340102880
> >  for <grasslist at baylor.edu>; Sun, 11 May 2003 15:34:01 -0500
> > Received: from gannet.stats (gannet.stats [163.1.20.127])
> > 	by toucan.stats.ox.ac.uk (8.12.9/8.12.9) with ESMTP id h4BKY0UK006538;
> > 	Sun, 11 May 2003 21:34:00 +0100 (BST)
> > Date: Sun, 11 May 2003 21:33:59 +0100 (BST)
> > From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
> > X-X-Sender: ripley at gannet.stats
> > To: Miha STAUT <mihastaut at hotmail.com>
> > cc: grasslist at baylor.edu, <r-help at stat.math.ethz.ch>
> > Subject: Re: [R] libpq-fe.h ???
> > In-Reply-To: <BAY2-F107GEm3EcPPzA0000dd9c at hotmail.com>
> > Message-ID: <Pine.LNX.4.44.0305112121001.7212-100000 at gannet.stats>
> > MIME-Version: 1.0
> > Content-Type: TEXT/PLAIN; charset=US-ASCII
> > X-IMID: elron.baylor.edu
> > X-OriginalArrivalTime: 11 May 2003 20:34:02.0281 (UTC) 
>FILETIME=[A8823990:01C317FC]
> >
> > 1) What has this to do with GRASS?  It has very little to do with R,
> > either, appearing to be a PostgreSQL installation problem.
> >
> > 2) Did you install PostgreSQL from source, or install RPMS: if the 
>latter
> > did you install _all_ the RPMs?  I suspect you don't have the client 
>files
> > installed.  On my system (installed from the sources under RH7.3)
> > libpq-fe.h is in /usr/local/pgsql/include.
> >
> > 3) Rdbi/Rdbi.PgSQL are not on CRAN and appear not to be supported, but 
>in
> > any case you would do best to ask the author(s)/maintainer(s) about
> > packages, and especially non-CRAN packages.
> >
> > 4) There is no such thing as R 1.6.2.1, and reports have it that
> > Rdbi.PgSQL does not work with the current versions of R.  The only
> > currently supported R interface to PostgreSQL would appear to be RODBC.
> >
> > On Sun, 11 May 2003, Miha STAUT wrote:
> >
> > > I tried to install the Rdbi_0.1-2.tar.gz and Rdbi.PgSQL_0.1-2 package. 
>The
> > > Rdbi_0.1-2.tar.gz installed fine but the Rdbi.PgSQL_0.1-2 had some 
>problems.
> > > The compilation routine tried to  find a header called libpq-fe.h but 
>did
> > > not find it in the standard locations. I searched through the computer 
>but
> > > did not find a file called in this way either. What should I do to
> > > successuffly install this package? In the Netleters introduction to 
>R/GRASS
> > > interface there is  no mention about this problems.
> > >
> > > The PostgreSQL_7.2.1 Users guide states: "Frontend programs that use 
>libpq
> > > must include the header file libpq-fe.h and must link with the libpq
> > > library." Is Libpq a package that can be downloaded and how should I 
>create
> > > this header and make a link to it?
> >
> > [...]
> >
> >
> >
>
>--
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From spencer.graves at pdf.com  Thu May 15 20:15:38 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 15 May 2003 11:15:38 -0700
Subject: [R] plot question
References: <3EC3D12C.1020306@ipe.csic.es>
Message-ID: <3EC3D94A.8050700@pdf.com>

Have you considered "predict.lm"?  The documentation includes an example 
that will produce predicted lines plus both confidence and tolerance 
intervals.  Follow that with "points(x, y)" to add the data points.

hope this helps.  spencer graves

David Nogu?s wrote:
> Hello:
> 
> Im a novice user of R. I was triying develop graphs with plot.lm or 
> plot(gam) but I dont obtain a desire result. I would like to create a 
> plot from lm, glm and gam objects showing:
> 
> 1- Fit curve
> 2- Raw data of predictor and response variables as points.
> 3- Confidence intervals (95%)
> 
> Anybody can help me?



From mschwartz at medanalytics.com  Thu May 15 20:23:19 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Thu, 15 May 2003 13:23:19 -0500
Subject: [R] plot question
In-Reply-To: <3EC3D12C.1020306@ipe.csic.es>
Message-ID: <003b01c31b0f$12370180$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of David Nogu?s
>Sent: Thursday, May 15, 2003 12:41 PM
>To: R-help
>Subject: [R] plot question
>
>
>Hello:
>
>Im a novice user of R. I was triying develop graphs with plot.lm or 
>plot(gam) but I dont obtain a desire result. I would like to create a

>plot from lm, glm and gam objects showing:
>
>1- Fit curve
>2- Raw data of predictor and response variables as points.
>3- Confidence intervals (95%)
>
>Anybody can help me?  
>
>-- 
>David Nogu?s Bravo


Here is a link to a post of mine back in March which provides example
code for plot.lm():

https://www.stat.math.ethz.ch/pipermail/r-help/2003-March/030057.html

HTH,

Marc Schwartz



From Kosenkov.Kirill at nac.spb.ru  Thu May 15 20:34:53 2003
From: Kosenkov.Kirill at nac.spb.ru (Kosenkov Kirill)
Date: Thu, 15 May 2003 22:34:53 +0400
Subject: [R] how to include 'NA's in xtabs?
In-Reply-To: <3EC3741B.2743.75CBBE@localhost>
References: <3EC3741B.2743.75CBBE@localhost>
Message-ID: <3EC3DDCD.30101@nac.spb.ru>

That's ok if i do something like xtabs(~f1). Thanks.
What about xtabs(w~f1+f2)? If i need to do crosstabulation
and factor variables contains NA's?

I want to repeat my second question: how to use 'na.action'
argument in xtabs? Can anybody explain, how is it works?


Petr Pikal wrote:

> Hi
> 
> On 15 May 2003 at 0:18, Kosenkov Kirill wrote:
> 
> 
>>Hello!
>>
>>I have a dataset with NA's in some variables (factors), for example: $
>>P67 : Factor w/ 2 levels "-","+": NA 2 1 NA NA 2 1 1 2 NA ...
>>
>>I need to use 'xtabs' like
>>xtabs(~x$P67)
>>It works well and produces something like this:
>>x$P67
>>    -    +
>>  779 1318
>>but i want to compute NA's too, like this:
>>x$P67
>>    -    +   NA
>>  779 1318  137
> 
> 
> what about using summary instead of xtabs
> 
> 
>>summary(ostbet$delka)
> 
>  159  160 NA's 
>    5   22    3 
> 
> 
>>xtabs(~ostbet$delka)
> 
> ostbet$delka
> 159 160 
>   5  22 
> 
> 
> 
> 
> 
>>I am trying xtabs(~x$P67, exclude=NULL) but xtabs does not compute
>>'NA's in this case too.
>>
>>I do not want to transform my data (do not want to do any 
>>substitution on NA's).
>>
>>How i can say 'xtabs' to compute NA-values?
>>
>>and second question: how to use argument 'na.action' in 'xtabs'?
>>'xtabs' help page does not explain this.
>>
>>Thanks!
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 
> Cheers
> Petr Pikal
> petr.pikal at precheza.cz
> p.pik at volny.cz
> 
> 
> 
> 
> .
>



From ripley at stats.ox.ac.uk  Thu May 15 21:31:02 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 15 May 2003 20:31:02 +0100 (BST)
Subject: [R] savehistory not working properly in R?
In-Reply-To: <3EC3CCA9.D2E44FF8@math.mun.ca>
Message-ID: <Pine.LNX.4.44.0305152029010.1457-100000@gannet.stats>

On Thu, 15 May 2003, Paul Y. Peng wrote:

> Why does R save its command history only when one saves the data
> image of the session? Is this a feature? Even though .Last can do
> this, would it be more convenient if R can do this automatically?
> Logically, I feel the command history should be treated separately.

I don't know: it predates my involvement with R.  The Windows ports used
always to save it, but we changed to conform to the Unix version, since
being different confused too many people.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From pburns at pburns.seanet.com  Thu May 15 21:42:56 2003
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Thu, 15 May 2003 20:42:56 +0100
Subject: [R] <-
References: <Pine.SOL.3.96.1030514121147.18819A-100000@draco.cus.cam.ac.uk>
	<16067.45852.564108.66287@arbres1a.fmr.com>
Message-ID: <3EC3EDC0.3060207@pburns.seanet.com>

I rather object to this sort of solution.  One of the strong points of
the S language is lists which allow items that belong together to be
in a single object.  It's hard to believe that the results of a single call
to a function don't belong together.

R without an accent (or at least with my accent) would attach the list:

res <- myfunc()
attach(res)
summary(a)


Patrick Burns

Burns Statistics
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

David Brahm wrote:

>Damon Wischik <djw1005 at cam.ac.uk> wrote:
>  
>
>>One thing I would find very handy is a shortcut for
>>  res <- myfunc()
>>  a <- res$val1
>>  b <- res$val2
>>Something along the lines of
>>  list(a=val1,b=val2) <- myfunc()
>>but I don't know what the right syntax would be or how I'd go about
>>programming it. Any suggestions?
>>    
>>
>
>I agree this would be handy!  And appealing to Perl folks who are used to:
>  Perl> ($arg1, $arg2) = @ARGV;
>I couldn't figure out how to do it with replacement functions (see Prof Brian
>Ripley's <ripley at stats.ox.ac.uk> reply), but here's another approach:
>
>multi.assign <- function(x, ...) {
>  mycall <- match.call()[-2]
>  mycall[1] <- call("list")
>  mylist <- eval(mycall, x)
>  for (i in names(mylist)) assign(i, mylist[[i]], parent.frame())
>}
>
>Here's an example:
>  R> myfunc <- function() list(val1=7, val2=c(5,5))
>  R> multi.assign(myfunc(), a=val1, b=val2, d=val1+val2)
>  R> a
>     [1] 7
>  R> b
>     [1] 5 5
>  R> d
>     [1] 12 12
>  
>



From kjetil at entelnet.bo  Thu May 15 21:58:18 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Thu, 15 May 2003 15:58:18 -0400
Subject: [R] how to include 'NA's in xtabs?
In-Reply-To: <3EC3DDCD.30101@nac.spb.ru>
References: <3EC3741B.2743.75CBBE@localhost>
Message-ID: <3EC3B91A.25634.5545C5@localhost>

On 15 May 2003 at 22:34, Kosenkov Kirill wrote:

The problem with xtabs discussed in this thread is the same problem 
as was discussed for table in R1.6.2 time. The NEWS file for R1.7.0 
has:

 o	table() now allows exclude= with factor arguments (requested by
	Michael Friendly).

but (rw1070, windows XP):

> test <- c(1,2,3,1,2,3,NA,NA,1,2,3)
> test
 [1]  1  2  3  1  2  3 NA NA  1  2  3
> table(test)
test
1 2 3 
3 3 3 
> table(test, exclude=NULL)
test
   1    2    3 <NA> 
   3    3    3    2 
> test <- factor(test)
> table(test)
test
1 2 3 
3 3 3 
> table(test, exclude=NULL)
test
1 2 3 
3 3 3 

so the announced fix does'nt seem to work?

I thought the same fix could be applied to xtabs, but first rw1070
must live up to its NEWS file.

Kjetil Halvorsen

> That's ok if i do something like xtabs(~f1). Thanks.
> What about xtabs(w~f1+f2)? If i need to do crosstabulation
> and factor variables contains NA's?
> 
> I want to repeat my second question: how to use 'na.action'
> argument in xtabs? Can anybody explain, how is it works?
> 
> 
> Petr Pikal wrote:
> 
> > Hi
> > 
> > On 15 May 2003 at 0:18, Kosenkov Kirill wrote:
> > 
> > 
> >>Hello!
> >>
> >>I have a dataset with NA's in some variables (factors), for example: $
> >>P67 : Factor w/ 2 levels "-","+": NA 2 1 NA NA 2 1 1 2 NA ...
> >>
> >>I need to use 'xtabs' like
> >>xtabs(~x$P67)
> >>It works well and produces something like this:
> >>x$P67
> >>    -    +
> >>  779 1318
> >>but i want to compute NA's too, like this:
> >>x$P67
> >>    -    +   NA
> >>  779 1318  137
> > 
> > 
> > what about using summary instead of xtabs
> > 
> > 
> >>summary(ostbet$delka)
> > 
> >  159  160 NA's 
> >    5   22    3 
> > 
> > 
> >>xtabs(~ostbet$delka)
> > 
> > ostbet$delka
> > 159 160 
> >   5  22 
> > 
> > 
> > 
> > 
> > 
> >>I am trying xtabs(~x$P67, exclude=NULL) but xtabs does not compute
> >>'NA's in this case too.
> >>
> >>I do not want to transform my data (do not want to do any 
> >>substitution on NA's).
> >>
> >>How i can say 'xtabs' to compute NA-values?
> >>
> >>and second question: how to use argument 'na.action' in 'xtabs'?
> >>'xtabs' help page does not explain this.
> >>
> >>Thanks!
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > 
> > 
> > Cheers
> > Petr Pikal
> > petr.pikal at precheza.cz
> > p.pik at volny.cz
> > 
> > 
> > 
> > 
> > .
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From p.connolly at hortresearch.co.nz  Thu May 15 22:47:37 2003
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Fri, 16 May 2003 08:47:37 +1200
Subject: [R] savehistory not working properly in R?
In-Reply-To: <3EC3CCA9.D2E44FF8@math.mun.ca>
References: <Pine.LNX.4.44.0305150732220.7760-100000@gannet.stats>
	<3EC3CCA9.D2E44FF8@math.mun.ca>
Message-ID: <20030515204736.GL13579@hortresearch.co.nz>

On Thu, 15-May-2003 at 02:51PM -0230, Paul Y. Peng wrote:


|> Why does R save its command history only when one saves the data
|> image of the session? Is this a feature? Even though .Last can do
|> this, would it be more convenient if R can do this automatically?
|> Logically, I feel the command history should be treated separately.

I like it how it is.  I always have at least two R sessions active.
One I'm working on and the other I use for tinkering with ideas that
come up from reading this list.  I don't usually want to keep a
history of those tinkerings, so I quit the tinkering R session without
saving a data image.

best

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From mackenzi at usq.edu.au  Fri May 16 01:31:51 2003
From: mackenzi at usq.edu.au (Tony Mackenzie)
Date: Fri, 16 May 2003 09:31:51 +1000
Subject: [R] Unable to load lapack.dll when using RExcel add-in
Message-ID: <4CE94EAEAD60B744B9263A2C82A9C7924886A1@alpha.usq.edu.au>

I am having trouble using R routines from the RExcel add-in, that use lapack.dll. As an example if I start the R kernel from within Excel and execute
 
"x<-rbind(c(1,2),c(1,-1))
 z<-solve(x)", 
I get the following error:
 
"Error in solve.default(x): lapack routines could not be loaded.
In addition: Warning message:
unable to load shared library "C:\Program Files\R\rw1070/modules/lapack.dll";
Load library failure. The specified module could not be found."
 
I have the file lapack.dll in the correct directory. I am not sure why the forward slash "/" characters are not  back slash's "\" in this error message. However, I do not know if this is important.
 
I have installed R 1.7.0 on my system running windows 2000 and I have installed RExcel 1.0 with RDCOM server 1.2. Any help would be appreciated. I think the RExcel add-in is fantastic and I would like to be able to use the lapack.dll routines.
 
Regards,
Tony MacKenzie



From petr.pikal at precheza.cz  Fri May 16 01:36:04 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri, 16 May 2003 01:36:04 +0200
Subject: [R] strptime and non ISO date format
Message-ID: <3EC44084.14217.EBE451@localhost>

Dear all

I have a character vector of dates something like:

timevec<-c("15.5.2003 00:00", "15.5.2003 00:01", "15.5.2003 00:02", 
"15.5.2003 00:03","15.5.2003 00:04")

and I would like to transform it to some more convenient date class. Is there a 
way how to do it directly without previous reformating to ISO like structure and 
adding a seconds to it.

I tried direct transformation but it does not work as I expected (or as I 
understood from help pages :-).

> strptime(timevec,"%m.%d.%y %H:%M")
[1] NA NA NA NA NA

Thank you for any hint.

Best regards.

Petr Pikal
petr.pikal at precheza.cz
p.pik at volny.cz



From edd at debian.org  Fri May 16 02:24:54 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 15 May 2003 19:24:54 -0500
Subject: [R] strptime and non ISO date format
In-Reply-To: <3EC44084.14217.EBE451@localhost>
References: <3EC44084.14217.EBE451@localhost>
Message-ID: <20030516002454.GA13282@sonny.eddelbuettel.com>

On Fri, May 16, 2003 at 01:36:04AM +0200, Petr Pikal wrote:
> I have a character vector of dates something like:
> 
> timevec<-c("15.5.2003 00:00", "15.5.2003 00:01", "15.5.2003 00:02", 
> "15.5.2003 00:03","15.5.2003 00:04")
> 
> and I would like to transform it to some more convenient date class. Is there a 
> way how to do it directly without previous reformating to ISO like structure and 
> adding a seconds to it.
> 
> I tried direct transformation but it does not work as I expected (or as I 
> understood from help pages :-).
> 
> > strptime(timevec,"%m.%d.%y %H:%M")
> [1] NA NA NA NA NA

You have the month and day mixed up, and also asked for two-digit year when
you really have four digits. Correcting both of these does the trick:

edd at chibud:~> R --silent
> timevec<-c("15.5.2003 00:00", "15.5.2003 00:01", "15.5.2003 00:02",
+ "15.5.2003 00:03","15.5.2003 00:04")
> strptime(timevec,"%d.%m.%Y %H:%M")
[1] "2003-05-15 00:00:00" "2003-05-15 00:01:00" "2003-05-15 00:02:00"
[4] "2003-05-15 00:03:00" "2003-05-15 00:04:00"

Hth, Dirk

-- 
Don't drink and derive. Alcohol and algebra don't mix.



From petr.pikal at precheza.cz  Fri May 16 03:00:56 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri, 16 May 2003 03:00:56 +0200
Subject: [R] strptime and non ISO date format
In-Reply-To: <20030516002454.GA13282@sonny.eddelbuettel.com>
References: <3EC44084.14217.EBE451@localhost>
Message-ID: <3EC45468.30041.13995C6@localhost>

Thank to Dirk and Patrick. I need to read help pages more 
carefully next time.

On 15 May 2003 at 19:24, Dirk Eddelbuettel wrote:

> On Fri, May 16, 2003 at 01:36:04AM +0200, Petr Pikal wrote:
> > I have a character vector of dates something like:
> > 
> > timevec<-c("15.5.2003 00:00", "15.5.2003 00:01", "15.5.2003 00:02",
> > "15.5.2003 00:03","15.5.2003 00:04")
> > 
> > and I would like to transform it to some more convenient date class.
> > Is there a way how to do it directly without previous reformating to
> > ISO like structure and adding a seconds to it.
> > 
> > I tried direct transformation but it does not work as I expected (or
> > as I understood from help pages :-).
> > 
> > > strptime(timevec,"%m.%d.%y %H:%M")
> > [1] NA NA NA NA NA
> 
> You have the month and day mixed up, and also asked for two-digit year
> when you really have four digits. Correcting both of these does the
> trick:
> 
> edd at chibud:~> R --silent
> > timevec<-c("15.5.2003 00:00", "15.5.2003 00:01", "15.5.2003 00:02",
> + "15.5.2003 00:03","15.5.2003 00:04")
> > strptime(timevec,"%d.%m.%Y %H:%M")
> [1] "2003-05-15 00:00:00" "2003-05-15 00:01:00" "2003-05-15 00:02:00"
> [4] "2003-05-15 00:03:00" "2003-05-15 00:04:00"
> 
> Hth, Dirk
> 
> -- 
> Don't drink and derive. Alcohol and algebra don't mix.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

Petr
petr.pikal at precheza.cz
p.pik at volny.cz



From wettenhall at wehi.edu.au  Fri May 16 07:27:54 2003
From: wettenhall at wehi.edu.au (James Wettenhall)
Date: Fri, 16 May 2003 15:27:54 +1000 (EST)
Subject: [R] Reloading a shared library with dyn.load
Message-ID: <Pine.LNX.4.44.0305161458480.10979-100000@unix24.alpha.wehi.edu.au>

Hi,

I'm using dyn.load to load a shared library (compiled from C 
code) into R.  If I dyn.unload it and then dyn.load it again, I 
get an hourglass icon in Rgui (R 1.7.0, Win 2000), and it 
just sits there forever.  I can't press Escape to stop the 
current computation, but I can close Rgui without resorting to 
using the Task Manager.

Is it a problem with my use of R_alloc?  Do I need something 
like R_cleanup?  Or is it a problem with dyn.load?

I'll demonstrate how I compile a C file, HelloFromC.C into a 
shared library, HelloFromC.dll and then load it into R.

HelloFromC.c
------------
#include <R.h>
#include <Rinternals.h>
#include <R_ext/Rdynload.h>
#include <R_ext/Memory.h>
#include <R_ext/Applic.h>
#include <stdio.h>

void HelloFromC(char **result)
{
   *result = (char *) R_alloc(20,sizeof(char));
   sprintf(*result,"Hello from C!"); 
}

static const
R_CMethodDef CEntries[] = {
{"HelloFromC",(DL_FUNC) &HelloFromC,1},
{NULL,NULL,0}
};

void R_init_HelloFromC(DllInfo *info)
{
    R_registerRoutines(info,CEntries,NULL,NULL,NULL);
}

----------------------------------------------------------------
c:\james\HelloFromC> Rcmd SHLIB HelloFromC
making HelloFromC.d from HelloFromC.c
gcc   -IC:/JAMES/rw1070/src/include -Wall -O2   -c HelloFromC.c 
-o HelloFromC.o
ar cr HelloFromC.a *.o
ranlib HelloFromC.a
gcc  --shared -s  -o HelloFromC.dll HelloFromC.def HelloFromC.a  
-LC:/JAMES/rw1070/src/gnuwin32  -lg2c -lR
-----------------------------------------------------------------

Now in R 1.7.0...
-----------------

> dyn.load("HelloFromC")
> result <- ""
> .C("HelloFromC",result)[[1]]
[1] "Hello from C!"
> dyn.unload("HelloFromC")
> dyn.load("HelloFromC")

This is where it freezes.

Any suggestions?

Regards,
James



From Roger.Bivand at nhh.no  Fri May 16 08:51:40 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 16 May 2003 08:51:40 +0200 (CEST)
Subject: [R] Unable to load lapack.dll when using RExcel add-in
In-Reply-To: <4CE94EAEAD60B744B9263A2C82A9C7924886A1@alpha.usq.edu.au>
Message-ID: <Pine.LNX.4.44.0305160849300.32008-100000@reclus.nhh.no>

On Fri, 16 May 2003, Tony Mackenzie wrote:

> I am having trouble using R routines from the RExcel add-in, that use lapack.dll. As an example if I start the R kernel from within Excel and execute
>  
> "x<-rbind(c(1,2),c(1,-1))
>  z<-solve(x)", 
> I get the following error:
>  
> "Error in solve.default(x): lapack routines could not be loaded.
> In addition: Warning message:
> unable to load shared library "C:\Program Files\R\rw1070/modules/lapack.dll";
> Load library failure. The specified module could not be found."
>  
> I have the file lapack.dll in the correct directory. I am not sure why the forward slash "/" characters are not  back slash's "\" in this error message. However, I do not know if this is important.
>  
> I have installed R 1.7.0 on my system running windows 2000 and I have installed RExcel 1.0 with RDCOM server 1.2. Any help would be appreciated. I think the RExcel add-in is fantastic and I would like to be able to use the lapack.dll routines.
>  

For the time being, do: solve(..., LINPACK=TRUE)

This uses the older, built-in functions rather than lapack.dll. I believe 
a patch has been made to the R windows release, but we'll have to wait 
until 1.7.1, perhaps, for the path to work correctly.

This has been discussed several times on the "Rcom" special interest list, 
which is certainly worth joining for users of the software.

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From ripley at stats.ox.ac.uk  Fri May 16 08:54:13 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 16 May 2003 07:54:13 +0100 (BST)
Subject: [R] Reloading a shared library with dyn.load
In-Reply-To: <Pine.LNX.4.44.0305161458480.10979-100000@unix24.alpha.wehi.edu.au>
Message-ID: <Pine.LNX.4.44.0305160742380.9271-100000@gannet.stats>

As there is AFAIK no way to unregister entry points, you cannot safely
unload a DLL with registered entry points (which is what your code appears
to do).  So if you want to do this, don't register them,

Package tcltk does unload its DLL (so the Tcl/Tk dlls get released) if 
detached, and so was not modified to register.

Until un-registration is provided, I would not use the registration 
mechanisms during development.

On Fri, 16 May 2003, James Wettenhall wrote:

> Hi,
> 
> I'm using dyn.load to load a shared library (compiled from C 
> code) into R.  If I dyn.unload it and then dyn.load it again, I 
> get an hourglass icon in Rgui (R 1.7.0, Win 2000), and it 
> just sits there forever.  I can't press Escape to stop the 
> current computation, but I can close Rgui without resorting to 
> using the Task Manager.
> 
> Is it a problem with my use of R_alloc?  Do I need something 
> like R_cleanup?  Or is it a problem with dyn.load?
> 
> I'll demonstrate how I compile a C file, HelloFromC.C into a 
> shared library, HelloFromC.dll and then load it into R.
> 
> HelloFromC.c
> ------------
> #include <R.h>
> #include <Rinternals.h>
> #include <R_ext/Rdynload.h>
> #include <R_ext/Memory.h>
> #include <R_ext/Applic.h>
> #include <stdio.h>
> 
> void HelloFromC(char **result)
> {
>    *result = (char *) R_alloc(20,sizeof(char));
>    sprintf(*result,"Hello from C!"); 
> }
> 
> static const
> R_CMethodDef CEntries[] = {
> {"HelloFromC",(DL_FUNC) &HelloFromC,1},
> {NULL,NULL,0}
> };
> 
> void R_init_HelloFromC(DllInfo *info)
> {
>     R_registerRoutines(info,CEntries,NULL,NULL,NULL);
> }
> 
> ----------------------------------------------------------------
> c:\james\HelloFromC> Rcmd SHLIB HelloFromC
> making HelloFromC.d from HelloFromC.c
> gcc   -IC:/JAMES/rw1070/src/include -Wall -O2   -c HelloFromC.c 
> -o HelloFromC.o
> ar cr HelloFromC.a *.o
> ranlib HelloFromC.a
> gcc  --shared -s  -o HelloFromC.dll HelloFromC.def HelloFromC.a  
> -LC:/JAMES/rw1070/src/gnuwin32  -lg2c -lR
> -----------------------------------------------------------------
> 
> Now in R 1.7.0...
> -----------------
> 
> > dyn.load("HelloFromC")
> > result <- ""
> > .C("HelloFromC",result)[[1]]
> [1] "Hello from C!"
> > dyn.unload("HelloFromC")
> > dyn.load("HelloFromC")
> 
> This is where it freezes.
> 
> Any suggestions?
> 
> Regards,
> James
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From news_poc at yahoo.fr  Fri May 16 09:40:44 2003
From: news_poc at yahoo.fr (=?iso-8859-1?q?Chasset=20Pierre-Olivier?=)
Date: Fri, 16 May 2003 09:40:44 +0200 (CEST)
Subject: [R] anamorphosis
Message-ID: <20030516074044.63337.qmail@web20504.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030516/9d4c6737/attachment.pl

From p.pagel at gsf.de  Fri May 16 10:05:25 2003
From: p.pagel at gsf.de (Philipp Pagel)
Date: Fri, 16 May 2003 10:05:25 +0200
Subject: [R] Axis labels
Message-ID: <20030516080525.GA1887@porcupine.gsf.de>


	Hello R-experts!

When I produce a plot R takes avoids overlapping axis labels in order to
maintain readabilty which is great. But now I have written a little
custom plot function in which I set my own labels and label
positions after generating the actual plot:

axis(..., lables=c('A', 'B', 'F', 'G', 'M'), at=mypositions)

As you may have guessed: This is categorial data. But the labels (and
categories) are unevenly spaced. I need to make sure, that all labels
are printed. Is there a way to tell R not to care about overlapping
labels or even better automatically reduce font size or scale the plot
to make everything fit? In my actual example letters would'n really
overlap - just get pretty close, so simply switching off this "distance
check" would solve my problem. 

I have read ?axis and ?par but couldn't find anything that seems to help.

Thanks for any hints.

	Philipp

-- 
Dr. Philipp Pagel                                Tel.  +49-89-3187-3675
Institute for Bioinformatics / MIPS              Fax.  +49-89-3187-3585
GSF - National Research Center for Environment and Health
Ingolstaedter Landstrasse 1
85764 Neuherberg
Germany



From ripley at stats.ox.ac.uk  Fri May 16 10:33:27 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 16 May 2003 09:33:27 +0100 (BST)
Subject: [R] Axis labels
In-Reply-To: <20030516080525.GA1887@porcupine.gsf.de>
Message-ID: <Pine.LNX.4.44.0305160929450.9568-100000@gannet.stats>


On Fri, 16 May 2003, Philipp Pagel wrote:

> When I produce a plot R takes avoids overlapping axis labels in order to
> maintain readabilty which is great. But now I have written a little
> custom plot function in which I set my own labels and label
> positions after generating the actual plot:
> 
> axis(..., lables=c('A', 'B', 'F', 'G', 'M'), at=mypositions)
> 
> As you may have guessed: This is categorial data. But the labels (and
> categories) are unevenly spaced. I need to make sure, that all labels
> are printed. Is there a way to tell R not to care about overlapping
> labels or even better automatically reduce font size or scale the plot
> to make everything fit? In my actual example letters would'n really
> overlap - just get pretty close, so simply switching off this "distance
> check" would solve my problem. 
> 
> I have read ?axis and ?par but couldn't find anything that seems to help.
> 
> Thanks for any hints.

I think you would prefer to use text() (you'll need to make sure xpd is
set suitably) or even mtext() to label your axis.  AFAIR the overlap check
is deep in the axis C code.  You could also call axis() repeatedly, one 
label at a time.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dnogues at ipe.csic.es  Fri May 16 10:28:39 2003
From: dnogues at ipe.csic.es (=?ISO-8859-1?Q?David_Nogu=E9s?=)
Date: Fri, 16 May 2003 10:28:39 +0200
Subject: [R] glm and gam confidence intervals
Message-ID: <3EC4A137.3080004@ipe.csic.es>

How can I obtain the values of confidence intervals from gam anf glm 
objects?

Thanks in advance

-- 
David Nogu?s Bravo

Functional Ecology and Biodiversity Department
Pyrenean Institute of Ecology
Spanish Research Council

Av. Monta?ana 1005
Zaragoza - CP 50059
976716030 - 976716019 (fax)



From ripley at stats.ox.ac.uk  Fri May 16 10:45:00 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 16 May 2003 09:45:00 +0100 (BST)
Subject: [R] glm and gam confidence intervals
In-Reply-To: <3EC4A137.3080004@ipe.csic.es>
Message-ID: <Pine.LNX.4.44.0305160939420.9703-100000@gannet.stats>

On Fri, 16 May 2003, David Nogu?s wrote:

> How can I obtain the values of confidence intervals from gam anf glm 
> objects?

Confidence intervals of what?  (You do need to be more precise.)

For the coefficients of a glm, see profile.glm in MASS.
For predictions you can get asymptotic (normal-based) CIs from the 
predict(se=TRUE) results on link scale and transform.

For gams it is a lot trickier, as for example there may be multiple local 
maxima to the likelihood, and there may be non-interval confidence regions 
for predictions as a result.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From wl at eimb.ru  Fri May 16 12:15:59 2003
From: wl at eimb.ru (Wladimir Eremeev)
Date: Fri, 16 May 2003 14:15:59 +0400
Subject: [R] data.frame contents are not displayed
Message-ID: <12594.030516@eimb.ru>

Dear r-help,

I need to unite contents of two files with variables into one data
frame, produce some derivative variables from them and store them in
that data frame.

Here is the set of commands (processing first file for now)

data7902<-data.frame(year=NULL,lon=NULL,area=NULL,extent=NULL,area.std=NULL,extent.std=NULL,
                     area.norm=NULL,extent.norm=NULL);

area7902<-read.table("a7902-15.txt",
                     col.names=c("year","area","lon"),
                     header=FALSE,
                     comment.char='#');

data7902$year<-area7902$year;
data7902$area<-area7902$area;
data7902$lon<-area7902$lon;
  
Checking:
I type "area7902" in the R console and get

    year         area lon
1   1979  78164.77944   0
2   1979  65492.49919  20
3   1979  41491.50425  40
4   1979  15217.32476  60
....

Then I type "data7902" in the R console.

[1] year area lon
<0 rows> (or 0-length row.names)

For the same time typing "data7902$year" gives the list of years for
all rows in data frame.

Why contents of the newly created and filled data frame are not
displayed?

-- 
Best regards
Wladimir Eremeev                                     mailto:wl at eimb.ru



From simon at stats.gla.ac.uk  Fri May 16 12:21:53 2003
From: simon at stats.gla.ac.uk (Simon Wood)
Date: Fri, 16 May 2003 11:21:53 +0100 (BST)
Subject: [R] glm and gam confidence intervals
In-Reply-To: <3EC4A137.3080004@ipe.csic.es>
Message-ID: <Pine.SOL.3.96.1030516110939.14009A-100000@moon.stats.gla.ac.uk>

> How can I obtain the values of confidence intervals from gam anf glm 
> objects?
- Vp in the gam object is the covariance matrix of the posterior
distribution of the gam parameters under a certian Bayesian model of
smoothing, the mean of this distribution is the parameter estimates
(coefficients). In the large sample limit the distribution is normal
(exactly so for normal errors and identity link). 

- predict.gam() can give standard errors for any prediction that you ask
it to make (on the scale of the linear predictor these are exact and do
not, for example, rely on any approximations like the estimators of the
smooths being independent). CI's then obtainable from the large sample 
normal result.

- predict.gam() with the type="lpmatrix" will give you the matrix by which
the fitted gam coefficients must be multiplied in order to obtain the
vector of required predictions (on the scale of the linear predictor).
This can be used to obtain the covariance matrix for the predictions
directly from the covariance matrix of the parameters. 

- Confidence intervals for complicated quantities derived from a fitted
gam object can be obtained by simulating parameter sets from the
multivariate normal with mean given by the fitted coefficients and
covariance matrix Vp and re-computing the derived quantity from each. 

Simon

_____________________________________________________________________
> Simon Wood simon at stats.gla.ac.uk        www.stats.gla.ac.uk/~simon/
>>  Department of Statistics, University of Glasgow, Glasgow, G12 8QQ
>>>   Direct telephone: (0)141 330 4530          Fax: (0)141 330 4814



From duncan at research.bell-labs.com  Fri May 16 12:55:28 2003
From: duncan at research.bell-labs.com (Duncan Temple Lang)
Date: Fri, 16 May 2003 06:55:28 -0400
Subject: [R] Reloading a shared library with dyn.load
In-Reply-To: <Pine.LNX.4.44.0305160742380.9271-100000@gannet.stats>;
	from ripley@stats.ox.ac.uk on Fri, May 16, 2003 at 07:54:13AM
	+0100
References: <Pine.LNX.4.44.0305161458480.10979-100000@unix24.alpha.wehi.edu.au>
	<Pine.LNX.4.44.0305160742380.9271-100000@gannet.stats>
Message-ID: <20030516065528.A21287@jessie.research.bell-labs.com>

Prof Brian Ripley wrote:
> As there is AFAIK no way to unregister entry points, you cannot safely
> unload a DLL with registered entry points (which is what your code appears
> to do).  So if you want to do this, don't register them,

This is not true.  The unloading of a shared library automatically
unregisters the entry points (the routine Rf_freeDllInfo in
Rdynload.c). So using the registration is not a problem.

Checking this on both my Linux and Windows boxes running 1.7 patched
doesn't cause any problems.  Adding a static variable to the
HelloFromC routine and both incrementing it and adding its value to
the returned string in each call illustrates that when a second
dyn.load() call is made, a new version of the library comes in.

So I can't reproduce the problem directly from the commands.
Something that comes to mind is that another process has got a lock on
the file. But I don't see that as likely.


> 
> Package tcltk does unload its DLL (so the Tcl/Tk dlls get released) if 
> detached, and so was not modified to register.
> 
> Until un-registration is provided, I would not use the registration 
> mechanisms during development.

This is *NOT* a necessary precaution.  Registration has the potential
to improve this situation rather than diminishing it. So please don't
let this discourage people from using registration.

 D.


> 
> On Fri, 16 May 2003, James Wettenhall wrote:
> 
> > Hi,
> > 
> > I'm using dyn.load to load a shared library (compiled from C 
> > code) into R.  If I dyn.unload it and then dyn.load it again, I 
> > get an hourglass icon in Rgui (R 1.7.0, Win 2000), and it 
> > just sits there forever.  I can't press Escape to stop the 
> > current computation, but I can close Rgui without resorting to 
> > using the Task Manager.
> > 
> > Is it a problem with my use of R_alloc?  Do I need something 
> > like R_cleanup?  Or is it a problem with dyn.load?
> > 
> > I'll demonstrate how I compile a C file, HelloFromC.C into a 
> > shared library, HelloFromC.dll and then load it into R.
> > 
> > HelloFromC.c
> > ------------
> > #include <R.h>
> > #include <Rinternals.h>
> > #include <R_ext/Rdynload.h>
> > #include <R_ext/Memory.h>
> > #include <R_ext/Applic.h>
> > #include <stdio.h>
> > 
> > void HelloFromC(char **result)
> > {
> >    *result = (char *) R_alloc(20,sizeof(char));
> >    sprintf(*result,"Hello from C!"); 
> > }
> > 
> > static const
> > R_CMethodDef CEntries[] = {
> > {"HelloFromC",(DL_FUNC) &HelloFromC,1},
> > {NULL,NULL,0}
> > };
> > 
> > void R_init_HelloFromC(DllInfo *info)
> > {
> >     R_registerRoutines(info,CEntries,NULL,NULL,NULL);
> > }
> > 
> > ----------------------------------------------------------------
> > c:\james\HelloFromC> Rcmd SHLIB HelloFromC
> > making HelloFromC.d from HelloFromC.c
> > gcc   -IC:/JAMES/rw1070/src/include -Wall -O2   -c HelloFromC.c 
> > -o HelloFromC.o
> > ar cr HelloFromC.a *.o
> > ranlib HelloFromC.a
> > gcc  --shared -s  -o HelloFromC.dll HelloFromC.def HelloFromC.a  
> > -LC:/JAMES/rw1070/src/gnuwin32  -lg2c -lR
> > -----------------------------------------------------------------
> > 
> > Now in R 1.7.0...
> > -----------------
> > 
> > > dyn.load("HelloFromC")
> > > result <- ""
> > > .C("HelloFromC",result)[[1]]
> > [1] "Hello from C!"
> > > dyn.unload("HelloFromC")
> > > dyn.load("HelloFromC")
> > 
> > This is where it freezes.
> > 
> > Any suggestions?
> > 
> > Regards,
> > James
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
_______________________________________________________________

Duncan Temple Lang                duncan at research.bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-3217
700 Mountain Avenue, Room 2C-259  fax:    (908)582-3340
Murray Hill, NJ  07974-2070       
         http://cm.bell-labs.com/stat/duncan



From ripley at stats.ox.ac.uk  Fri May 16 12:59:43 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 16 May 2003 11:59:43 +0100 (BST)
Subject: [R] Reloading a shared library with dyn.load
In-Reply-To: <20030516065528.A21287@jessie.research.bell-labs.com>
Message-ID: <Pine.LNX.4.44.0305161158090.9906-100000@gannet.stats>

Thank you for the corrections -- my knowledge is clearly out of date, but 
I have been bitten by this in the past.

Apologies for misleading people.

On Fri, 16 May 2003, Duncan Temple Lang wrote:

> Prof Brian Ripley wrote:
> > As there is AFAIK no way to unregister entry points, you cannot safely
> > unload a DLL with registered entry points (which is what your code appears
> > to do).  So if you want to do this, don't register them,
> 
> This is not true.  The unloading of a shared library automatically
> unregisters the entry points (the routine Rf_freeDllInfo in
> Rdynload.c). So using the registration is not a problem.
> 
> Checking this on both my Linux and Windows boxes running 1.7 patched
> doesn't cause any problems.  Adding a static variable to the
> HelloFromC routine and both incrementing it and adding its value to
> the returned string in each call illustrates that when a second
> dyn.load() call is made, a new version of the library comes in.
> 
> So I can't reproduce the problem directly from the commands.
> Something that comes to mind is that another process has got a lock on
> the file. But I don't see that as likely.
> 
> 
> > 
> > Package tcltk does unload its DLL (so the Tcl/Tk dlls get released) if 
> > detached, and so was not modified to register.
> > 
> > Until un-registration is provided, I would not use the registration 
> > mechanisms during development.
> 
> This is *NOT* a necessary precaution.  Registration has the potential
> to improve this situation rather than diminishing it. So please don't
> let this discourage people from using registration.
> 
>  D.
> 
> 
> > 
> > On Fri, 16 May 2003, James Wettenhall wrote:
> > 
> > > Hi,
> > > 
> > > I'm using dyn.load to load a shared library (compiled from C 
> > > code) into R.  If I dyn.unload it and then dyn.load it again, I 
> > > get an hourglass icon in Rgui (R 1.7.0, Win 2000), and it 
> > > just sits there forever.  I can't press Escape to stop the 
> > > current computation, but I can close Rgui without resorting to 
> > > using the Task Manager.
> > > 
> > > Is it a problem with my use of R_alloc?  Do I need something 
> > > like R_cleanup?  Or is it a problem with dyn.load?
> > > 
> > > I'll demonstrate how I compile a C file, HelloFromC.C into a 
> > > shared library, HelloFromC.dll and then load it into R.
> > > 
> > > HelloFromC.c
> > > ------------
> > > #include <R.h>
> > > #include <Rinternals.h>
> > > #include <R_ext/Rdynload.h>
> > > #include <R_ext/Memory.h>
> > > #include <R_ext/Applic.h>
> > > #include <stdio.h>
> > > 
> > > void HelloFromC(char **result)
> > > {
> > >    *result = (char *) R_alloc(20,sizeof(char));
> > >    sprintf(*result,"Hello from C!"); 
> > > }
> > > 
> > > static const
> > > R_CMethodDef CEntries[] = {
> > > {"HelloFromC",(DL_FUNC) &HelloFromC,1},
> > > {NULL,NULL,0}
> > > };
> > > 
> > > void R_init_HelloFromC(DllInfo *info)
> > > {
> > >     R_registerRoutines(info,CEntries,NULL,NULL,NULL);
> > > }
> > > 
> > > ----------------------------------------------------------------
> > > c:\james\HelloFromC> Rcmd SHLIB HelloFromC
> > > making HelloFromC.d from HelloFromC.c
> > > gcc   -IC:/JAMES/rw1070/src/include -Wall -O2   -c HelloFromC.c 
> > > -o HelloFromC.o
> > > ar cr HelloFromC.a *.o
> > > ranlib HelloFromC.a
> > > gcc  --shared -s  -o HelloFromC.dll HelloFromC.def HelloFromC.a  
> > > -LC:/JAMES/rw1070/src/gnuwin32  -lg2c -lR
> > > -----------------------------------------------------------------
> > > 
> > > Now in R 1.7.0...
> > > -----------------
> > > 
> > > > dyn.load("HelloFromC")
> > > > result <- ""
> > > > .C("HelloFromC",result)[[1]]
> > > [1] "Hello from C!"
> > > > dyn.unload("HelloFromC")
> > > > dyn.load("HelloFromC")
> > > 
> > > This is where it freezes.
> > > 
> > > Any suggestions?
> > > 
> > > Regards,
> > > James
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > > 
> > 
> > -- 
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From wl at eimb.ru  Fri May 16 13:12:17 2003
From: wl at eimb.ru (Wladimir Eremeev)
Date: Fri, 16 May 2003 15:12:17 +0400
Subject: [R] substitute
Message-ID: <7633.030516@eimb.ru>

Dear r-help,

  I have troubles with 'substitute'.
  I have the data frame with vectors data$area.0, data$area.20, etc...
  Command
  
  substitute(data$area.lon,list(lon=20))

  returns

  data$area.lon

  but is expected to return data$area.20

  Where did I do mistakes?
-- 
Best regards
Wladimir Eremeev                                     mailto:wl at eimb.ru

==========================================================================
Research Scientist                                Leninsky Prospect 33,
Space Monitoring & Ecoinformation Systems Sector, Moscow, Russia, 119071,
Institute of Ecology,                             Phone: (095) 135-9972;
Russian Academy of Sciences                       Fax: (095) 954-5534



From ripley at stats.ox.ac.uk  Fri May 16 13:08:10 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 16 May 2003 12:08:10 +0100 (BST)
Subject: [R] data.frame contents are not displayed
In-Reply-To: <12594.030516@eimb.ru>
Message-ID: <Pine.LNX.4.44.0305161202530.9906-100000@gannet.stats>

$<- is not the right way to change the contents of a data frame.
You have updated the underlying list, but you haven't (for example) added 
any row names, and you have circumvented the checks that all columns 
should have the same length (and they do not).

If you had created a data frame of the right size, then $<- would have 
replaced the contents of the column -- that's the only safe way to use it.
If you used 

> data7902 <- data.frame(year=NULL, lon=NULL)
> data7902
NULL data frame with 0 rows
> names(data7902)
character(0)

you will see that you don't even have any columns.

On Fri, 16 May 2003, Wladimir Eremeev wrote:

> Dear r-help,
> 
> I need to unite contents of two files with variables into one data
> frame, produce some derivative variables from them and store them in
> that data frame.
> 
> Here is the set of commands (processing first file for now)
> 
> data7902<-data.frame(year=NULL,lon=NULL,area=NULL,extent=NULL,area.std=NULL,extent.std=NULL,
>                      area.norm=NULL,extent.norm=NULL);
> 
> area7902<-read.table("a7902-15.txt",
>                      col.names=c("year","area","lon"),
>                      header=FALSE,
>                      comment.char='#');
> 
> data7902$year<-area7902$year;
> data7902$area<-area7902$area;
> data7902$lon<-area7902$lon;
>   
> Checking:
> I type "area7902" in the R console and get
> 
>     year         area lon
> 1   1979  78164.77944   0
> 2   1979  65492.49919  20
> 3   1979  41491.50425  40
> 4   1979  15217.32476  60
> ....
> 
> Then I type "data7902" in the R console.
> 
> [1] year area lon
> <0 rows> (or 0-length row.names)
> 
> For the same time typing "data7902$year" gives the list of years for
> all rows in data frame.
> 
> Why contents of the newly created and filled data frame are not
> displayed?
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri May 16 13:12:18 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 16 May 2003 12:12:18 +0100 (BST)
Subject: [R] substitute
In-Reply-To: <7633.030516@eimb.ru>
Message-ID: <Pine.LNX.4.44.0305161208460.9906-100000@gannet.stats>

On Fri, 16 May 2003, Wladimir Eremeev wrote:

>   I have troubles with 'substitute'.
>   I have the data frame with vectors data$area.0, data$area.20, etc...
>   Command
>   
>   substitute(data$area.lon,list(lon=20))
> 
>   returns
> 
>   data$area.lon
> 
>   but is expected to return data$area.20
> 
>   Where did I do mistakes?

The symbol is area.lon, not lon.  substitute only work on whole symbols, 
and `.' is just part of the alphabet allowed in syntactic names.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From wl at eimb.ru  Fri May 16 13:33:49 2003
From: wl at eimb.ru (Wladimir Eremeev)
Date: Fri, 16 May 2003 15:33:49 +0400
Subject: [R] substitute
In-Reply-To: <Pine.LNX.4.44.0305161208460.9906-100000@gannet.stats>
References: <Pine.LNX.4.44.0305161208460.9906-100000@gannet.stats>
Message-ID: <13648.030516@eimb.ru>

Dear Prof,

Friday, May 16, 2003, 15:12:18, you wrote:

>>   but is expected to return data$area.20
>> 
>>   Where did I do mistakes?

PBR> The symbol is area.lon, not lon.  substitute only work on whole symbols, 
PBR> and `.' is just part of the alphabet allowed in syntactic names.


Thank you! Now I see...

Now I'm studying parse(). I think it can help me.

-- 
Best regards
Wladimir Eremeev                                     mailto:wl at eimb.ru

==========================================================================
Research Scientist                                Leninsky Prospect 33,
Space Monitoring & Ecoinformation Systems Sector, Moscow, Russia, 119071,
Institute of Ecology,                             Phone: (095) 135-9972;
Russian Academy of Sciences                       Fax: (095) 954-5534



From arv at ono.com  Fri May 16 13:24:52 2003
From: arv at ono.com (antonio rodriguez)
Date: Fri, 16 May 2003 13:24:52 +0200
Subject: [R] unable to install dse package
In-Reply-To: <20030516002454.GA13282@sonny.eddelbuettel.com>
Message-ID: <IPEFKICOHOECENGJBAGLMEHDCAAA.arv@ono.com>

Hi,

On WinXP, with R1.7.0 I've got the following messages when trying to install
(from CRAN or local file) the dse package:

Error in file(file, "r") : unable to open connection
In addition: Warning message:
cannot open file `dse/DESCRIPTION'

Thanks in advance


Antonio Rodriguez



From bitwrit at ozemail.com.au  Fri May 16 13:18:44 2003
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Fri, 16 May 2003 21:18:44 +1000
Subject: [R] Axis labels
In-Reply-To: <20030516080525.GA1887@porcupine.gsf.de>
References: <20030516080525.GA1887@porcupine.gsf.de>
Message-ID: <20030516115650.LLZD23569.mta07.mail.mel.aone.net.au@there>

Philipp Pagel wrote:
> Hello R-experts!
>
> When I produce a plot R takes avoids overlapping axis labels in order to
> maintain readabilty which is great. But now I have written a little
> custom plot function in which I set my own labels and label
> positions after generating the actual plot:
>
> axis(..., lables=c('A', 'B', 'F', 'G', 'M'), at=mypositions)
>
I realize that this isn't what you asked for, but there is a function for 
staggering long axis labels in "Kickstarting R" at:

http://cran.r-project.org

under Contributed Documentation. Might help.

Jim



From ma at ne.su.se  Fri May 16 14:09:41 2003
From: ma at ne.su.se (Mahmood ARAI)
Date: Fri, 16 May 2003 14:09:41 +0200
Subject: [R] glmmPQL, NA/NaN/Inf in foreign function call (arg 3)
Message-ID: <20030516120941.DC14E3B88D@mbox2.su.se>

Dear all, 

I try to fit a glmmPQL on a huge data with 384189 individuals id=1:384189:
working in 1520 establishments est:1:1516. The minimum number of individuals
in every establishment is 30. 

This works for a subsample excluding establishemnet cells smaller than 100,
but fail when we include smaller cells: 


R> summary(glmmPQL(count ~
+      I( age-ave(age,est) )* ave(age,est) +
+      I( wom-ave(wom,est) )* ave(age,est) +
+      I( age-ave(age,est) )* ave(wom,est) +
+      I( wom-ave(wom,est) )* ave(wom,est) ,
+              random = ~ I( age-ave(age,est) ) +
+                        I( wom-ave(wom,est) ) | est,
+                                          family=quasipoisson,
+                                         data=mydata
iteration 1
Error in logLik.reStruct(object, conLin) :
       NA/NaN/Inf in foreign function call (arg 3)
R> 

Which function call "NA/NaN/Inf in foreign function call (arg 3)" refers to? 

thanks
mahmood arai 

http://www.ne.su.se/~ma



From sway at tanox.com  Fri May 16 14:20:07 2003
From: sway at tanox.com (Shawn Way)
Date: Fri, 16 May 2003 07:20:07 -0500
Subject: [R] Images Import and Analysis
Message-ID: <2F3262756375D411B0CC00B0D049775DFD616E@westpark.tanox.net>


I'm starting a time study on an area.  To determine if an individual has
entered the area, we are having timed photographs taken of the area.  What I
want to do is import the image files (either one at a time or
simultaneously), convert it to a density image, take the density at multiple
points in the image and determine if they are over an area average
(indicating someone or something is in that area).

Any ideas on how to get started (importing the images) in R? (programming
tool of choice)


Shawn Way
Engineering Manager
Tanox, Inc.



From Vincent.Spiesser at univ-tlse1.fr  Fri May 16 15:15:21 2003
From: Vincent.Spiesser at univ-tlse1.fr (Vincent Spiesser)
Date: Fri, 16 May 2003 15:15:21 +0200
Subject: [R] Splus' "discr" function
Message-ID: <4.2.0.58.20030516151003.00a55d08@mail.univ-tlse1.fr>

Hi,
Does an equivalent of the Splus' "discr" function exist ?

Vincent Spiesser



From sundar.dorai-raj at pdf.com  Fri May 16 15:32:23 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Fri, 16 May 2003 08:32:23 -0500
Subject: [R] Splus' "discr" function
References: <4.2.0.58.20030516151003.00a55d08@mail.univ-tlse1.fr>
Message-ID: <3EC4E867.2050508@pdf.com>

?lda in package MASS.

This can be found by help.search("discriminant").

sd

Vincent Spiesser wrote:
> Hi,
> Does an equivalent of the Splus' "discr" function exist ?
> 
> Vincent Spiesser
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From hb at maths.lth.se  Fri May 16 15:58:06 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Fri, 16 May 2003 15:58:06 +0200
Subject: [R] unable to install dse package
In-Reply-To: <IPEFKICOHOECENGJBAGLMEHDCAAA.arv@ono.com>
Message-ID: <000101c31bb3$79e60700$e502eb82@alpha.wehi.edu.au>

This is a known bug in the R v1.7.0 release that occurs when using
install.packages()/update.packages() to install *bundles* and is
probably already fixed in the patch and the next version. Here is a work
around for now

 
source("http://www.maths.lth.se/help/R/patches/rw1070/install.packages.R
")

Cheers

Henrik Bengtsson
Lund University

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> antonio rodriguez
> Sent: den 16 maj 2003 13:25
> To: r-help at stat.math.ethz.ch
> Subject: [R] unable to install dse package
> 
> 
> Hi,
> 
> On WinXP, with R1.7.0 I've got the following messages when 
> trying to install (from CRAN or local file) the dse package:
> 
> Error in file(file, "r") : unable to open connection
> In addition: Warning message:
> cannot open file `dse/DESCRIPTION'
> 
> Thanks in advance
> 
> 
> Antonio Rodriguez
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> 
>



From hb at maths.lth.se  Fri May 16 16:05:53 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Fri, 16 May 2003 16:05:53 +0200
Subject: [R] Images Import and Analysis
In-Reply-To: <2F3262756375D411B0CC00B0D049775DFD616E@westpark.tanox.net>
Message-ID: <000201c31bb4$436b6200$e502eb82@alpha.wehi.edu.au>

Package 'pixmap' [ install.packages("pixmap") ] has support for "import,
export, plotting and other manipulations of bitmapped images". More
precisely, you can read and write Portable Anymap Images, i.e. ppm
(rgb), pgm (gray), pbm (monochrome). For tiff, png, jpg etc you first
have to convert your images to the above formats before importing them
into R. ImageMagick's (http://www.imagemagick.org/) command line
'convert' command available for many platforms is good for this. With
the right path settings, you can basically do this from within R by
using system(), e.g.

  system("convert foo.jpg foo.ppm")
  img <- read.pnm("foo.ppm")
  plot(img)

However, 'pixmap' do not contain much image analysis functions so those
you have to write yourself.

Henrik Bengtsson
Lund University

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Shawn Way
> Sent: den 16 maj 2003 14:20
> To: r-help at stat.math.ethz.ch
> Subject: [R] Images Import and Analysis
> 
> 
> 
> I'm starting a time study on an area.  To determine if an 
> individual has entered the area, we are having timed 
> photographs taken of the area.  What I want to do is import 
> the image files (either one at a time or simultaneously), 
> convert it to a density image, take the density at multiple 
> points in the image and determine if they are over an area 
> average (indicating someone or something is in that area).
> 
> Any ideas on how to get started (importing the images) in R? 
> (programming tool of choice)
> 
> 
> Shawn Way
> Engineering Manager
> Tanox, Inc.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> 
>



From ripley at stats.ox.ac.uk  Fri May 16 16:11:49 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 16 May 2003 15:11:49 +0100 (BST)
Subject: [R] unable to install dse package
In-Reply-To: <IPEFKICOHOECENGJBAGLMEHDCAAA.arv@ono.com>
Message-ID: <Pine.LNX.4.44.0305161509400.10147-100000@gannet.stats>

dse is a bundle, and rw1070 can't install bundles.  What you can do is 
download the file and unzip it into the library directory (using 
zip.unpack if you like).

On Fri, 16 May 2003, antonio rodriguez wrote:

> On WinXP, with R1.7.0 I've got the following messages when trying to install
> (from CRAN or local file) the dse package:
> 
> Error in file(file, "r") : unable to open connection
> In addition: Warning message:
> cannot open file `dse/DESCRIPTION'

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rossini at blindglobe.net  Fri May 16 16:15:59 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Fri, 16 May 2003 07:15:59 -0700
Subject: [R] Reloading a shared library with dyn.load
In-Reply-To: <20030516065528.A21287@jessie.research.bell-labs.com> (Duncan
	Temple Lang's message of "Fri, 16 May 2003 06:55:28 -0400")
References: <Pine.LNX.4.44.0305161458480.10979-100000@unix24.alpha.wehi.edu.au>
	<Pine.LNX.4.44.0305160742380.9271-100000@gannet.stats>
	<20030516065528.A21287@jessie.research.bell-labs.com>
Message-ID: <87issbnfj4.fsf@jeeves.blindglobe.net>

Duncan Temple Lang <duncan at research.bell-labs.com> writes:

> So I can't reproduce the problem directly from the commands.
> Something that comes to mind is that another process has got a lock on
> the file. But I don't see that as likely.

Possibly completely unrelated, but Windows does the strangest things
with file locks -- I've been having problems with this (working with
files cross-platform (from Linux and Windows vis 2k terminal servier
on the same fileserver), and finding unreleased locks every so often. 

best,
-tony

-- 
A.J. Rossini rossini at u.washington.edu http://software.biostat.washington.edu/ 
Biostatistics, U Washington and Fred Hutchinson Cancer Research Center

FHCRC:Tu: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email 
UW  : Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX 

CONFIDENTIALITY NOTICE: This e-mail message and any attachments ... {{dropped}}



From gregory_r_warnes at groton.pfizer.com  Fri May 16 18:07:52 2003
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Fri, 16 May 2003 12:07:52 -0400
Subject: [R] DNA
Message-ID: <D7A3CFD7825BD6119B880002A58F06C202F2C986@groexmb02.pfizer.com>

There are some tools for handling genetic data in the 'genetics' package on
CRAN.   These were motiviated by the need to process population genetic
data.

-G

> -----Original Message-----
> From: Daniel Edmund Davison [mailto:davison at midway.uchicago.edu]
> Sent: Monday, May 05, 2003 1:58 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] DNA
> 
> 
> 
> Hi, is anyone using R for DNA sequence analyses / population
> genetics?
> 
> Thanks,
> Dan
> 
> ______________________________________________________________
> __________________
> Daniel Davison
> 
> email: davison at uchicago.edu
> tel.: +1 312 665 7010
> fax:  +1 312 665 7754
> http://home.uchicago.edu/~davison/
> 
> Committee on Evolutionary Biology  &  Division of Birds
> University of Chicago                 Field Museum of Natural History
> 1025 E. 57th Street                   1400 S. Lake Shore Drive
> Culver Hall 402                       Chicago, IL 60605-2496
> Chicago, IL 60637                     U.S.A.
> U.S.A.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


LEGAL NOTICE\ Unless expressly stated otherwise, this message is... {{dropped}}



From rwatkins at cornerstonelp.com  Fri May 16 19:00:42 2003
From: rwatkins at cornerstonelp.com (rwatkins@cornerstonelp.com)
Date: Fri, 16 May 2003 12:00:42 -0500
Subject: [R] Newbie hung up with matrices
Message-ID: <NDEKIJPPGJCIKBNEDOKOEEALCCAA.rwatkins@cornerstonelp.com>

Hi all:
	Thanks in advance for your assistance.

	I just started learning R.  I'm trying to use the Help and the downloadable
manuals.  I am stuck on trying to multiply matrices.  Can anyone please
supply a couple of lines of code that I can plug into a fresh console to see
how  a double precision (1x3) matrix is multiplied by a double precision
(3x3) matrix?  I keep getting an error message,"Error in x%*%A: requires
numeric matrix/vector arguments".

	I have some VBA and VB experience (thus a little Object Oriented
programming experience), am I right in beliving that I am not "dimensioning"
correctly?  I have been trying the following example:
		A<-matrix
		A<-read.csv("test33.csv"), where the data is
				A,B,C
				1,4,7
				2,5,8
				3,6,9

		x<-c(4,5,6)
		x%*%A
			ERROR (as shown above)

	ALSO, I have downloaded the RExcel add-in, but have not found any reference
manual, etc that describes how to use it.  Any suggestions here are
appreciated, as I primarily do my work in Excel.

	Are there any good books available that will help me in my quest to become
a more adept user of R?  I know I am going to need this package for
multivariate regressions, etc.

	Again, thanks in advance for your time and consideration.



From MLakshmi at CNTUS.JNJ.COM  Fri May 16 19:32:32 2003
From: MLakshmi at CNTUS.JNJ.COM (Lakshminarayanan, Mani  [CNTUS])
Date: Fri, 16 May 2003 13:32:32 -0400
Subject: [R] Question on ldBands function in Hmisc package by Harrell
Message-ID: <E5382FD31214D6118FF40002A541DECE049E2314@CNTUSMAEXS4.na.jnj.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030516/920fa4af/attachment.pl

From s2112930 at student.rmit.edu.au  Fri May 16 19:41:19 2003
From: s2112930 at student.rmit.edu.au (Skanda Kallur; MEngg)
Date: Sat, 17 May 2003 03:41:19 +1000
Subject: [R] ARMA.predict?
Message-ID: <1053106879.90e8b560s2112930@student.rmit.edu.au>

Hi there,

Does anyone know how to predict ARMA? It doesn?t have either predict or forecast methods. I found couple of packages called fbasic and fseries at http://www.itp.phys.ethz.ch/econophysics/R/, which has ?arma.predict? in it, but it doesn?t seem to be working. Any help in this regard would be appreciated. Thanks in advance.

Regards


Skanda Kallur

"Prediction is very difficult, especially if it's about the future." 
--Niels Bohr



From raf1729 at hotmail.com  Fri May 16 20:16:04 2003
From: raf1729 at hotmail.com (R A F)
Date: Fri, 16 May 2003 18:16:04 +0000
Subject: [R] Efficient subsetting
Message-ID: <Law11-F77Bma4RCIlWr00028aba@hotmail.com>

Hi, I'm facing this problem quite a lot, so it seems worthwhile
to check to see what the most efficient solution is.

I've two vectors x (values ordered) and y.  I've ranges
x < x0, x0 <= x < x1, x1 <= x < x2, x2 <= x < x3, x > xn
and want to construct a subvector yprime of y which consists
of the first/last value of y whose x values are in the range.

For example,

x   y
1   2
1   3
2   3
3   4
4   5
5   6

and let's say the ranges are 1 <= x < 3 and 3 <= x < 5.  I
should produce yprime as c( 2, 4 ) (if I ask for the first value
of y whose x is in the range).  [If there're no x values within
a given range, output an NA.]

Obviously I can do a loop and use which, etc., but it seems
like there should be a better way.

Thanks very much.

A general solution would be nice, but if it helps to make the
algorithm efficient, I'm happy to assume

(a) x values are ordered
(b) the ranges are always evenly spaced:  for example, x in
0 to 10, 10 to 20, 20 to 30, etc.



From ripley at stats.ox.ac.uk  Fri May 16 20:29:37 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 16 May 2003 19:29:37 +0100 (BST)
Subject: [R] ARMA.predict?
In-Reply-To: <1053106879.90e8b560s2112930@student.rmit.edu.au>
Message-ID: <Pine.LNX.4.44.0305161927520.10533-100000@gannet.stats>

On Sat, 17 May 2003, Skanda Kallur; MEngg wrote:

> Hi there,
> 
> Does anyone know how to predict ARMA? It doesn???t have either predict
> or forecast methods. I found couple of packages called fbasic and
> fseries at http://www.itp.phys.ethz.ch/econophysics/R/, which has
> ???arma.predict??? in it, but it doesn???t seem to be working. Any help
> in this regard would be appreciated. Thanks in advance.

Well,  R comes with arima and arima0 functions, and both have predict 
methods.  What is ARMA and where did you get it from?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri May 16 20:32:18 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 16 May 2003 19:32:18 +0100 (BST)
Subject: [R] Newbie hung up with matrices
In-Reply-To: <NDEKIJPPGJCIKBNEDOKOEEALCCAA.rwatkins@cornerstonelp.com>
Message-ID: <Pine.LNX.4.44.0305161930330.10533-100000@gannet.stats>

On Fri, 16 May 2003 rwatkins at cornerstonelp.com wrote:

> 	I just started learning R.  I'm trying to use the Help and the downloadable
> manuals.  I am stuck on trying to multiply matrices.  Can anyone please
> supply a couple of lines of code that I can plug into a fresh console to see
> how  a double precision (1x3) matrix is multiplied by a double precision
> (3x3) matrix?  I keep getting an error message,"Error in x%*%A: requires
> numeric matrix/vector arguments".
> 
> 	I have some VBA and VB experience (thus a little Object Oriented
> programming experience), am I right in beliving that I am not "dimensioning"
> correctly?  I have been trying the following example:
> 		A<-matrix
> 		A<-read.csv("test33.csv"), where the data is
> 				A,B,C
> 				1,4,7
> 				2,5,8
> 				3,6,9

You've forgotten header=TRUE, if you don't want A,B,C to be part of your 
matrix.  R comes with a Data Import/Export Manual: please consult it.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ccleland at optonline.net  Fri May 16 20:32:43 2003
From: ccleland at optonline.net (Chuck Cleland)
Date: Fri, 16 May 2003 14:32:43 -0400
Subject: [R] Newbie hung up with matrices
In-Reply-To: <NDEKIJPPGJCIKBNEDOKOEEALCCAA.rwatkins@cornerstonelp.com>
References: <NDEKIJPPGJCIKBNEDOKOEEALCCAA.rwatkins@cornerstonelp.com>
Message-ID: <3EC52ECB.6040509@optonline.net>

rwatkins at cornerstonelp.com wrote:
> 	I just started learning R.  I'm trying to use the Help and the downloadable
> manuals.  I am stuck on trying to multiply matrices.  Can anyone please
> supply a couple of lines of code that I can plug into a fresh console to see
> how  a double precision (1x3) matrix is multiplied by a double precision
> (3x3) matrix?  I keep getting an error message,"Error in x%*%A: requires
> numeric matrix/vector arguments".

 > A <- matrix(c(1,4,7,2,5,8,3,6,9), ncol=3, byrow=TRUE)
 > x <- c(3,5,6)
 > x%*%A
      [,1] [,2] [,3]
[1,]   31   73  115

The result of read.csv is not a matrix, so try the following:

A <- as.matrix(A)
x%*%A

hope this helps,

Chuck Cleland



From feldesmanm at pdx.edu  Fri May 16 20:38:37 2003
From: feldesmanm at pdx.edu (Marc Feldesman)
Date: Fri, 16 May 2003 11:38:37 -0700
Subject: [R] Newbie hung up with matrices
In-Reply-To: <NDEKIJPPGJCIKBNEDOKOEEALCCAA.rwatkins@cornerstonelp.com>
References: <NDEKIJPPGJCIKBNEDOKOEEALCCAA.rwatkins@cornerstonelp.com>
Message-ID: <20030516113837.3a115ff5.feldesmanm@pdx.edu>

On Fri, 16 May 2003 12:00:42 -0500, an incredible array of electrons
randomly cascading around the Universe collided and turned into words
spewed forth by rwatkins at cornerstonelp.com:


rwatkins at cornerstonelp.com> Hi all:
rwatkins at cornerstonelp.com> 	Thanks in advance for your assistance.
rwatkins at cornerstonelp.com> 
rwatkins at cornerstonelp.com> 	I just started learning R.  I'm trying
to use the Help and the downloadable
rwatkins at cornerstonelp.com> manuals.  I am stuck on trying to multiply
matrices.  Can anyone please
rwatkins at cornerstonelp.com> supply a couple of lines of code that I
can plug into a fresh console to see
rwatkins at cornerstonelp.com> how  a double precision (1x3) matrix is
multiplied by a double precision
rwatkins at cornerstonelp.com> (3x3) matrix?  I keep getting an error
message,"Error in x%*%A: requires
rwatkins at cornerstonelp.com> numeric matrix/vector arguments".
rwatkins at cornerstonelp.com> 
rwatkins at cornerstonelp.com> 	I have some VBA and VB experience
(thus a little Object Oriented
rwatkins at cornerstonelp.com> programming experience), am I right in
beliving that I am not "dimensioning"
rwatkins at cornerstonelp.com> correctly?  I have been trying the
following example:
rwatkins at cornerstonelp.com> 		A<-matrix
rwatkins at cornerstonelp.com> 		A<-read.csv("test33.csv"), where the
data is
rwatkins at cornerstonelp.com> 				A,B,C
rwatkins at cornerstonelp.com> 				1,4,7
rwatkins at cornerstonelp.com> 				2,5,8
rwatkins at cornerstonelp.com> 				3,6,9
rwatkins at cornerstonelp.com> 
rwatkins at cornerstonelp.com> 		x<-c(4,5,6)
rwatkins at cornerstonelp.com> 		x%*%A
rwatkins at cornerstonelp.com> 			ERROR (as shown above)
rwatkins at cornerstonelp.com> 
rwatkins at cornerstonelp.com> 	ALSO, I have downloaded the RExcel
add-in, but have not found any reference
rwatkins at cornerstonelp.com> manual, etc that describes how to use it. 
Any suggestions here are
rwatkins at cornerstonelp.com> appreciated, as I primarily do my work in
Excel.
rwatkins at cornerstonelp.com> 
rwatkins at cornerstonelp.com> 	Are there any good books available
"that will help me in my quest to become
rwatkins at cornerstonelp.com> a more adept user of R?  I know I am going
to need this package for
rwatkins at cornerstonelp.com> multivariate regressions, etc.
rwatkins at cornerstonelp.com> 
rwatkins at cornerstonelp.com> 	Again, thanks in advance for your time
and consideration.
rwatkins at cornerstonelp.com> 
rwatkins at cornerstonelp.com>
______________________________________________


Couple of thoughts.

A<-matrix      # what's the purpose???

A<-read.csv("test33.csv", header=TRUE)

A  # just to list your data

and to make sure that A,B,C aren't stuck in there as rows.

Then your command should work (also assuming that you really have
a CSV file).  Try ?read.csv

Hope this helps.



From jerome at hivnet.ubc.ca  Fri May 16 20:41:16 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Fri, 16 May 2003 11:41:16 -0700
Subject: [R] Newbie hung up with matrices
In-Reply-To: <NDEKIJPPGJCIKBNEDOKOEEALCCAA.rwatkins@cornerstonelp.com>
References: <NDEKIJPPGJCIKBNEDOKOEEALCCAA.rwatkins@cornerstonelp.com>
Message-ID: <200305161847.LAA02615@hivnet.ubc.ca>


You need to convert your data frame as a matrix before your operation. Try 
this:
x %*% as.matrix(A)

Regarding a good book, I may not be the best person to answer you. I am 
aware of the online manuals available at http://www.r-project.org .
The manual "An Introduction to R" is my personal best bet.

HTH,
Jerome

On May 16, 2003 10:00 am, rwatkins at cornerstonelp.com wrote:
> Hi all:
> 	Thanks in advance for your assistance.
>
> 	I just started learning R.  I'm trying to use the Help and the
> downloadable manuals.  I am stuck on trying to multiply matrices.  Can
> anyone please supply a couple of lines of code that I can plug into a
> fresh console to see how  a double precision (1x3) matrix is multiplied
> by a double precision (3x3) matrix?  I keep getting an error
> message,"Error in x%*%A: requires numeric matrix/vector arguments".
>
> 	I have some VBA and VB experience (thus a little Object Oriented
> programming experience), am I right in beliving that I am not
> "dimensioning" correctly?  I have been trying the following example:
> 		A<-matrix
> 		A<-read.csv("test33.csv"), where the data is
> 				A,B,C
> 				1,4,7
> 				2,5,8
> 				3,6,9
>
> 		x<-c(4,5,6)
> 		x%*%A
> 			ERROR (as shown above)
>
> 	ALSO, I have downloaded the RExcel add-in, but have not found any
> reference manual, etc that describes how to use it.  Any suggestions
> here are appreciated, as I primarily do my work in Excel.
>
> 	Are there any good books available that will help me in my quest to
> become a more adept user of R?  I know I am going to need this package
> for multivariate regressions, etc.
>
> 	Again, thanks in advance for your time and consideration.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From fharrell at virginia.edu  Fri May 16 20:45:49 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Fri, 16 May 2003 14:45:49 -0400
Subject: [R] Question on ldBands function in Hmisc package by Harrell
In-Reply-To: <E5382FD31214D6118FF40002A541DECE049E2314@CNTUSMAEXS4.na.jnj.com>
References: <E5382FD31214D6118FF40002A541DECE049E2314@CNTUSMAEXS4.na.jnj.com>
Message-ID: <20030516144549.151c575f.fharrell@virginia.edu>

On Fri, 16 May 2003 13:32:32 -0400
"Lakshminarayanan, Mani  [CNTUS]" <MLakshmi at cntus.jnj.com> wrote:

> Has anyone tried to download Hmisc and used ldBands function for calculating
> Lan-Demets group sequential boundaries?  The write-up in F.Harrell's website
> indicates that, besides downloading the package Hmisc, one needs to copy the
> progra ld98 from the University of Wisconsin website.  As suggested, I did
> this but received another error message regarding the search path.  I think
> I have fixed this problem.  But, when I tried to run the program, it still
> opened up the MS-DOS Window and gave me another error message.
> 
> If you have tried this, please let me know how you did it.  Thanks in
> advance for your help.
> 
> Mani Lakshminarayanan, Ph.D
> Director of Statistics
> Centocor, Inc
> 

I have debugged ldBands only on Linux.  If a Windows user will debug it I'll make any needed changes for Windows.  -Frank
---
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From jerome at hivnet.ubc.ca  Fri May 16 21:20:36 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Fri, 16 May 2003 12:20:36 -0700
Subject: [R] Efficient subsetting
In-Reply-To: <Law11-F77Bma4RCIlWr00028aba@hotmail.com>
References: <Law11-F77Bma4RCIlWr00028aba@hotmail.com>
Message-ID: <200305161926.MAA04095@hivnet.ubc.ca>


Here I have a general solution. x need not be ordered and ranges need not 
be equally spaced.

x <- c(1,1,2,3,4,5)
y <- c(2,3,3,4,5,6)
xcut <- cut(x,breaks=c(1,3,5),right=F)

#If you want the FIRST value of y whose x are in the range
wh <- !duplicated(xcut) & !is.na(xcut)
y[wh]         #   [1] 2 4

#If you want the LAST value of y whose x are in the range
revxcut <- rev(xcut)
wh <- rev(!duplicated(revxcut) & !is.na(revxcut))
y[wh]         #   [1] 3 5

HTH,
Jerome

On May 16, 2003 11:16 am, R A F wrote:
> Content-Length: 1109
> Status: R
> X-Status: N
>
> Hi, I'm facing this problem quite a lot, so it seems worthwhile
> to check to see what the most efficient solution is.
>
> I've two vectors x (values ordered) and y.  I've ranges
> x < x0, x0 <= x < x1, x1 <= x < x2, x2 <= x < x3, x > xn
> and want to construct a subvector yprime of y which consists
> of the first/last value of y whose x values are in the range.
>
> For example,
>
> x   y
> 1   2
> 1   3
> 2   3
> 3   4
> 4   5
> 5   6
>
> and let's say the ranges are 1 <= x < 3 and 3 <= x < 5.  I
> should produce yprime as c( 2, 4 ) (if I ask for the first value
> of y whose x is in the range).  [If there're no x values within
> a given range, output an NA.]
>
> Obviously I can do a loop and use which, etc., but it seems
> like there should be a better way.
>
> Thanks very much.
>
> A general solution would be nice, but if it helps to make the
> algorithm efficient, I'm happy to assume
>
> (a) x values are ordered
> (b) the ranges are always evenly spaced:  for example, x in
> 0 to 10, 10 to 20, 20 to 30, etc.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 

Jerome Asselin (J?r?me), Statistical Analyst
British Columbia Centre for Excellence in HIV/AIDS
St. Paul's Hospital, 608 - 1081 Burrard Street
Vancouver, British Columbia, CANADA V6Z 1Y6
Email: jerome at hivnet.ubc.ca
Phone: 604 806-9112   Fax: 604 806-9044



From s2112930 at student.rmit.edu.au  Fri May 16 21:24:29 2003
From: s2112930 at student.rmit.edu.au (Skanda Kallur; MEngg)
Date: Sat, 17 May 2003 05:24:29 +1000
Subject: [R] arma.predict?
Message-ID: <1053113069.c61de720s2112930@student.rmit.edu.au>

Professor, thanks for the reply, I am using Auto Regression Moving Average arma()(sorry it wasnt ARMA) which comes under tseries package to fit my data and I am intending to predict with arma fitted data but couldnt find a method to do it. 

Interestingly, I found two packages at http://www.itp.phys.ethz.ch/econophysics/R/ which has packages called fbasic and fseries. fseries has arma.predict() but it threw some error, I wasnt able to install it. I would appreciate if you could have a look at it.

Regards

Skanda

-----Original Message-----
From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
To: "Skanda Kallur; MEngg" <s2112930 at student.rmit.edu.au>
Date: Fri, 16 May 2003 19:29:37 +0100 (BST)
Subject: Re: [R] ARMA.predict?

On Sat, 17 May 2003, Skanda Kallur; MEngg wrote:

> Hi there,
> 
> Does anyone know how to predict ARMA? It doesn???t have either predict
> or forecast methods. I found couple of packages called fbasic and
> fseries at http://www.itp.phys.ethz.ch/econophysics/R/, which has
> ???arma.predict??? in it, but it doesn???t seem to be working. Any help
> in this regard would be appreciated. Thanks in advance.

Well,  R comes with arima and arima0 functions, and both have predict 
methods.  What is ARMA and where did you get it from?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



Skanda Kallur

"Prediction is very difficult, especially if it's about the future." 
--Niels Bohr



From eje4 at cornell.edu  Fri May 16 21:38:07 2003
From: eje4 at cornell.edu (Eric Evans)
Date: Fri, 16 May 2003 15:38:07 -0400
Subject: [R] 1.7.0 installation problem
Message-ID: <5.1.0.14.2.20030516153334.00b68950@postoffice4.mail.cornell.edu>

Hello,

I'm having a problem trying to upgrade from R 1.6.0 to 1.7.0 on our 
Suns.  We're running Solaris 8 and we're using gcc 3.2.3.  The problem is 
that I get a bunch of error messages about a missing subroutine 
Rdconv::fill during the "make" of 1.7.0, although I didn't have this 
missing subroutine problem back when I installed 1.6.0.  Can anyone suggest 
how I can fix this problem and get 1.7.0 to compile on our systems?  Thanks 
very much.

Best wishes,
Eric Evans
Cornell Phonetics Lab
Ithaca, NY, USA



From ripley at stats.ox.ac.uk  Fri May 16 22:09:06 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 16 May 2003 21:09:06 +0100 (BST)
Subject: [R] 1.7.0 installation problem
In-Reply-To: <5.1.0.14.2.20030516153334.00b68950@postoffice4.mail.cornell.edu>
Message-ID: <Pine.LNX.4.44.0305162056080.10896-100000@gannet.stats>

On Fri, 16 May 2003, Eric Evans wrote:

> I'm having a problem trying to upgrade from R 1.6.0 to 1.7.0 on our 
> Suns.  We're running Solaris 8 and we're using gcc 3.2.3.  The problem is 
> that I get a bunch of error messages about a missing subroutine 
> Rdconv::fill during the "make" of 1.7.0, although I didn't have this 
> missing subroutine problem back when I installed 1.6.0.  Can anyone suggest 
> how I can fix this problem and get 1.7.0 to compile on our systems?  Thanks 
> very much.

This looks like a Perl problem.  fill is in Text::Wrap, so my guess is 
that there is a problem with your installation.  Could you please send us 
the output of perl --version and the exact error messages.  (We know the 
current Perl 5.8.0 works, so upgrading to that should solve the problem.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rwatkins at cornerstonelp.com  Fri May 16 23:32:19 2003
From: rwatkins at cornerstonelp.com (rwatkins@cornerstonelp.com)
Date: Fri, 16 May 2003 16:32:19 -0500
Subject: [R] 
	Newbie Matrix problem refined; Can't convert .csv data to matrix
Message-ID: <NDEKIJPPGJCIKBNEDOKOEEAOCCAA.rwatkins@cornerstonelp.com>

Thanks to all for your previous help.  I see now that my problem is
converting my .csv file of data into a matrix.  My example is a (3x3) matrix
with a "header" row (that doesn't contain numerics).

Thanks again for your time and gracious consideration.



From p.dalgaard at biostat.ku.dk  Sat May 17 00:34:37 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri, 16 May 2003 22:34:37 -0000
Subject: [R]  Newbie Matrix problem refined;
	Can't convert .csv data to matrix
In-Reply-To: <NDEKIJPPGJCIKBNEDOKOEEAOCCAA.rwatkins@cornerstonelp.com>
References: <NDEKIJPPGJCIKBNEDOKOEEAOCCAA.rwatkins@cornerstonelp.com>
Message-ID: <x2el2yikhh.fsf@biostat.ku.dk>

<rwatkins at cornerstonelp.com> writes:

> Thanks to all for your previous help.  I see now that my problem is
> converting my .csv file of data into a matrix.  My example is a (3x3) matrix
> with a "header" row (that doesn't contain numerics).
> 
> Thanks again for your time and gracious consideration.

I believe that was actually answered in at least one of the replies
you already got, but to reiterate: Use as.matrix to coerce the data
frame returned by read.csv to a matrix. As in:

> A <- as.matrix(read.csv(stdin()))
0: A,B,C
1: 1,2,3
2: 4,5,6
3: 7,8,9
4:
> A%*%A

      A   B   C
  1  30  36  42
  2  66  81  96
  3 102 126 150


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From mackenzi at usq.edu.au  Sat May 17 04:04:44 2003
From: mackenzi at usq.edu.au (Tony Mackenzie)
Date: Sat, 17 May 2003 12:04:44 +1000
Subject: [R] Unable to load lapack.dll when using RExcel add-in
Message-ID: <4CE94EAEAD60B744B9263A2C82A9C7924886A5@alpha.usq.edu.au>

Roger,
 
Thank you for your help. LINPACK will be fine for my use with RExcel. How do I join the the "Rcom" special interest list?
 
Regards,
Tony MacKenzie
 

	-----Original Message----- 
	From: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
	Sent: Fri 16/05/2003 4:51 PM 
	To: Tony Mackenzie 
	Cc: r-help at stat.math.ethz.ch 
	Subject: Re: [R] Unable to load lapack.dll when using RExcel add-in
	
	

	On Fri, 16 May 2003, Tony Mackenzie wrote:
	
	> I am having trouble using R routines from the RExcel add-in, that use lapack.dll. As an example if I start the R kernel from within Excel and execute
	> 
	> "x<-rbind(c(1,2),c(1,-1))
	>  z<-solve(x)",
	> I get the following error:
	> 
	> "Error in solve.default(x): lapack routines could not be loaded.
	> In addition: Warning message:
	> unable to load shared library "C:\Program Files\R\rw1070/modules/lapack.dll";
	> Load library failure. The specified module could not be found."
	> 
	> I have the file lapack.dll in the correct directory. I am not sure why the forward slash "/" characters are not  back slash's "\" in this error message. However, I do not know if this is important.
	> 
	> I have installed R 1.7.0 on my system running windows 2000 and I have installed RExcel 1.0 with RDCOM server 1.2. Any help would be appreciated. I think the RExcel add-in is fantastic and I would like to be able to use the lapack.dll routines.
	> 
	
	For the time being, do: solve(..., LINPACK=TRUE)
	
	This uses the older, built-in functions rather than lapack.dll. I believe
	a patch has been made to the R windows release, but we'll have to wait
	until 1.7.1, perhaps, for the path to work correctly.
	
	This has been discussed several times on the "Rcom" special interest list,
	which is certainly worth joining for users of the software.
	
	--
	Roger Bivand
	Economic Geography Section, Department of Economics, Norwegian School of
	Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
	Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
	e-mail: Roger.Bivand at nhh.no



From arv at ono.com  Sat May 17 08:40:56 2003
From: arv at ono.com (arv@ono.com)
Date: Sat, 17 May 2003 08:40:56 +0200
Subject: [R] unable to install dse package
Message-ID: <7e0fa103.a1037e0f@ono.com>

Dear All,

I remenber that with R1.6.2 I was able to install from CRAN this 
package. But is OK the solution gave by Dr. Ripley.

Thanks to everybody

Cheers

Antonio

----- Mensaje Original -----
Remitente: Robert Gentleman <rgentlem at jimmy.harvard.edu>
Fecha: Viernes, Mayo 16, 2003 2:36 pm
Asunto: Re: [R] unable to install dse package

> Hi Antonio,
>  There is a bug in the installation code for bundles. We are actively
>  sorting this out and you should expect to see a patch available from
>  Duncan Murdoch within the week,
>    Robert
>  ps if not let me know and I will supply it to you directly


----- Mensaje Original -----
Remitente: Prof Brian Ripley <ripley at stats.ox.ac.uk>
Fecha: Viernes, Mayo 16, 2003 4:11 pm
Asunto: Re: [R] unable to install dse package

> dse is a bundle, and rw1070 can't install bundles.  What you can 
> do is 
> download the file and unzip it into the library directory (using 
> zip.unpack if you like).
> 
> On Fri, 16 May 2003, antonio rodriguez wrote:
> 
> > On WinXP, with R1.7.0 I've got the following messages when 
> trying to install
> > (from CRAN or local file) the dse package:
> > 
> > Error in file(file, "r") : unable to open connection
> > In addition: Warning message:
> > cannot open file `dse/DESCRIPTION'
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From Roger.Bivand at nhh.no  Sat May 17 11:13:41 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 17 May 2003 11:13:41 +0200 (CEST)
Subject: [R] Unable to load lapack.dll when using RExcel add-in
In-Reply-To: <4CE94EAEAD60B744B9263A2C82A9C7924886A5@alpha.usq.edu.au>
Message-ID: <Pine.LNX.4.44.0305171111140.2384-100000@reclus.nhh.no>

On Sat, 17 May 2003, Tony Mackenzie wrote:

>  Thank you for your help. LINPACK will be fine for my use with RExcel.
> How do I join the the "Rcom" special interest list?

The link is from: http://cran.r-project.org/contrib/extra/dcom/ReadMe.txt

a long way down, to: 

http://mailman.csd.univie.ac.at/mailman/listinfo/rcom-l

Sorry, I should have added this to my reply.

Roger

>  
> Regards,
> Tony MacKenzie
>  
> 
> 	-----Original Message----- 
> 	From: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
> 	Sent: Fri 16/05/2003 4:51 PM 
> 	To: Tony Mackenzie 
> 	Cc: r-help at stat.math.ethz.ch 
> 	Subject: Re: [R] Unable to load lapack.dll when using RExcel add-in
> 	
> 	
> 
> 	On Fri, 16 May 2003, Tony Mackenzie wrote:
> 	
> 	> I am having trouble using R routines from the RExcel add-in, that use lapack.dll. As an example if I start the R kernel from within Excel and execute
> 	> 
> 	> "x<-rbind(c(1,2),c(1,-1))
> 	>  z<-solve(x)",
> 	> I get the following error:
> 	> 
> 	> "Error in solve.default(x): lapack routines could not be loaded.
> 	> In addition: Warning message:
> 	> unable to load shared library "C:\Program Files\R\rw1070/modules/lapack.dll";
> 	> Load library failure. The specified module could not be found."
> 	> 
> 	> I have the file lapack.dll in the correct directory. I am not sure why the forward slash "/" characters are not  back slash's "\" in this error message. However, I do not know if this is important.
> 	> 
> 	> I have installed R 1.7.0 on my system running windows 2000 and I have installed RExcel 1.0 with RDCOM server 1.2. Any help would be appreciated. I think the RExcel add-in is fantastic and I would like to be able to use the lapack.dll routines.
> 	> 
> 	
> 	For the time being, do: solve(..., LINPACK=TRUE)
> 	
> 	This uses the older, built-in functions rather than lapack.dll. I believe
> 	a patch has been made to the R windows release, but we'll have to wait
> 	until 1.7.1, perhaps, for the path to work correctly.
> 	
> 	This has been discussed several times on the "Rcom" special interest list,
> 	which is certainly worth joining for users of the software.
> 	
> 	--
> 	Roger Bivand
> 	Economic Geography Section, Department of Economics, Norwegian School of
> 	Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
> 	Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
> 	e-mail: Roger.Bivand at nhh.no
> 	
> 	
> 	
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From gb at stat.umu.se  Sat May 17 12:50:26 2003
From: gb at stat.umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Sat, 17 May 2003 12:50:26 +0200 (CEST)
Subject: [R] R indentation
Message-ID: <Pine.LNX.4.44.0305171242420.10584-100000@tal.stat.umu.se>

I use Gnu emacs 21, Linux RH9 and R-1.7.0. I have succeeded to get the 
recommended indentation of 4 in  C  thru customization as described in 
'R-exts', p.73, but I can't get it to work in  R  code. Can someone help, 
for instance by sending me the appropriate lines in '.emacs'?

Thanks!
---
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se



From magnolia at absolutok.net  Sat May 17 12:46:00 2003
From: magnolia at absolutok.net (ana kozomara)
Date: Sat, 17 May 2003 12:46:00 +0200
Subject: [R] Regression tree
Message-ID: <0039e0046101153SILJA@silja.absolutok.com>



  Hi everybody.
I'm a new R user and i've been searching a tool for construction of
regression tree...
I found function "tree()" written by a certain Mr. Ripley, and seems to be
just
what i'm looking for, but when i try to use it in R replies me:"Object not
found".
So I was wandering if I should include one special library or something
like that?
Thanks a lot,
ana



From kwan022 at stat.auckland.ac.nz  Sat May 17 12:54:44 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Sat, 17 May 2003 22:54:44 +1200 (NZST)
Subject: [R] Regression tree
In-Reply-To: <0039e0046101153SILJA@silja.absolutok.com>
Message-ID: <Pine.LNX.4.44.0305172253300.24276-100000@stat61.stat.auckland.ac.nz>

Hi,

  library(tree) 
would be what you want.

But I'd suggest you to use rpart() in library(rpart).  

On Sat, 17 May 2003, ana kozomara wrote:

> Date: Sat, 17 May 2003 12:46:00 +0200
> From: ana kozomara <magnolia at absolutok.net>
> To: r-help at stat.math.ethz.ch
> Subject: [R] Regression tree
> 
> 
> 
>   Hi everybody.
> I'm a new R user and i've been searching a tool for construction of
> regression tree...
> I found function "tree()" written by a certain Mr. Ripley, and seems to be
> just
> what i'm looking for, but when i try to use it in R replies me:"Object not
> found".
> So I was wandering if I should include one special library or something
> like that?
> Thanks a lot,
> ana
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)



From magnolia at absolutok.net  Sat May 17 12:59:43 2003
From: magnolia at absolutok.net (ana kozomara)
Date: Sat, 17 May 2003 12:59:43 +0200
Subject: [R] Regression tree
Message-ID: <002264359101153SILJA@silja.absolutok.com>

Hi...
wow that was quick!
Thanks.
Imfortunately, I tried library(tree), it doesn't work.
R answers that he dosn't find library tree...
So have any idea why...?
ana
----- Original Message -----
From: "Ko-Kang Kevin Wang" <kwan022 at stat.auckland.ac.nz>
To: "ana kozomara" <magnolia at absolutok.net>
Cc: <r-help at stat.math.ethz.ch>
Sent: Saturday, May 17, 2003 12:54 PM
Subject: Re: [R] Regression tree


> Hi,
>
>   library(tree)
> would be what you want.
>
> But I'd suggest you to use rpart() in library(rpart).
>
> On Sat, 17 May 2003, ana kozomara wrote:
>
> > Date: Sat, 17 May 2003 12:46:00 +0200
> > From: ana kozomara <magnolia at absolutok.net>
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] Regression tree
> >
> >
> >
> >   Hi everybody.
> > I'm a new R user and i've been searching a tool for construction of
> > regression tree...
> > I found function "tree()" written by a certain Mr. Ripley, and seems
to be
> > just
> > what i'm looking for, but when i try to use it in R replies me:"Object
not
> > found".
> > So I was wandering if I should include one special library or
something
> > like that?
> > Thanks a lot,
> > ana
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>
> --
> Cheers,
>
> Kevin
>
> ------------------------------------------------------------------------
------
> /* Time is the greatest teacher, unfortunately it kills its students */
>
> --
> Ko-Kang Kevin Wang
> Master of Science (MSc) Student
> SLC Tutor and Lab Demonstrator
> Department of Statistics
> University of Auckland
> New Zealand
> Homepage: http://www.stat.auckland.ac.nz/~kwan022
> Ph: 373-7599
>     x88475 (City)
>     x88480 (Tamaki)
>
>



From kwan022 at stat.auckland.ac.nz  Sat May 17 13:12:38 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Sat, 17 May 2003 23:12:38 +1200 (NZST)
Subject: [R] Regression tree
In-Reply-To: <002264359101153SILJA@silja.absolutok.com>
Message-ID: <Pine.LNX.4.44.0305172309510.24350-100000@stat61.stat.auckland.ac.nz>

Hi,

On Sat, 17 May 2003, ana kozomara wrote:

> Hi...
> wow that was quick!
> Thanks.
> Imfortunately, I tried library(tree), it doesn't work.
> R answers that he dosn't find library tree...
> So have any idea why...?

Yes.  Unlike rpart, tree is not a recommended package.  i.e. it does not 
come with R Installation.

You need to download it separately from CRAN.  Which one to download 
depending on your OS and version of R.


-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)



From Kosenkov.Kirill at nac.spb.ru  Sat May 17 14:15:20 2003
From: Kosenkov.Kirill at nac.spb.ru (Kosenkov Kirill)
Date: Sat, 17 May 2003 16:15:20 +0400
Subject: [R] how to handle 'multiresponse' variable?
Message-ID: <3EC627D8.1020309@nac.spb.ru>

Hello!

I have dataset where one variable is 'multiresponse', like this:
[1] "1 2" "1 2 3" "4" "1 4" "4 3" etc.
'responses' separated by space. observations in different 'rows' 
of data.frame.
I can do strsplit(data$var,' ') and make a list, where multiple 
responses are elements of character vectors, like this:
  $ P124               :List of 2956
   ..$ : chr  "2" "4"
   ..$ : chr  "1" "2"
   ..$ : chr "NA"
   ..$ : chr  "3" "4"
   ..$ : chr "3"

I need to compute crosstabulation on this variable, to make 
crosstabulation where this variable is a factor variable 
(responses of this variable are categories, in which i need to 
compute distributions of other variables). And i need to do 
crosstabulation with 'weights', like in xtabs(w~f1+f2).

Is any way exists to do such things with 'multiresponse' variables 
in R or i need to write my own functions to handle it?

Thanks!



From ripley at stats.ox.ac.uk  Sat May 17 14:59:04 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 17 May 2003 13:59:04 +0100 (BST)
Subject: [R] R indentation
In-Reply-To: <Pine.LNX.4.44.0305171242420.10584-100000@tal.stat.umu.se>
Message-ID: <Pine.LNX.4.44.0305171355030.21068-100000@gannet.stats>

On Sat, 17 May 2003, G?ran Brostr?m wrote:

> I use Gnu emacs 21, Linux RH9 and R-1.7.0. I have succeeded to get the 
> recommended indentation of 4 in  C  thru customization as described in 
> 'R-exts', p.73, but I can't get it to work in  R  code. Can someone help, 
> for instance by sending me the appropriate lines in '.emacs'?

;;;-- Implement "R core indentation style"--------------------------------
(setq ess-mode-hook
      '(lambda()
	 (ess-set-style 'C++ 'quiet)

	 (add-hook 'local-write-file-hooks
		   '(lambda()
		      (nuke-trailing-whitespace)
		      ))
	 ))

(add-hook 'perl-mode-hook
	  '(lambda() (setq perl-indent-level 4)))

works for me, *provided* I have set (via customization)

(custom-set-variables
  ;; custom-set-variables was added by Custom -- don't edit or cut/paste it!
  ;; Your init file should contain only one such instance.
 '(c-basic-offset 4)
 '(c-default-style "bsd"))


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From grosso at mail.ru  Sat May 17 18:04:43 2003
From: grosso at mail.ru (Pavel Stupin)
Date: Sun, 18 May 2003 00:04:43 +0800
Subject: [R] Influence Diagrams in R
Message-ID: <20030518000443.31cb4c4b.grosso@mail.ru>

Hello,

Is it possible to model and solve influence diagrams in R?

I would appreciate your help.
Pavel.



From parkhurs at ariel.ucs.indiana.edu  Sat May 17 18:28:45 2003
From: parkhurs at ariel.ucs.indiana.edu (David Parkhurst)
Date: Sat, 17 May 2003 11:28:45 -0500
Subject: [R] Changing default R window under XP
Message-ID: <000f01c31c91$692369b0$0a6cfea9@BLSPEAPARKHOM>

I?m working with R 1.7.0 under windows XP.  Whenever I start the program, it
comes up full screen, and I have to resize it to suit my preferences.   How
can I make it come up at a particular size (but not full screen) every time?



Thanks.

Dave Parkhurst



From ripley at stats.ox.ac.uk  Sat May 17 19:00:00 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 17 May 2003 18:00:00 +0100 (BST)
Subject: [R] Changing default R window under XP
In-Reply-To: <000f01c31c91$692369b0$0a6cfea9@BLSPEAPARKHOM>
Message-ID: <Pine.LNX.4.44.0305171752080.21525-100000@gannet.stats>

One possibility is to use SDI mode (e.g. --sdi)

On Sat, 17 May 2003, David Parkhurst wrote:

> I?m working with R 1.7.0 under windows XP.  Whenever I start the program, it
> comes up full screen, and I have to resize it to suit my preferences.   How
> can I make it come up at a particular size (but not full screen) every time?

If you are in MDI, it actually comes up maximized, not full screen (so
e.g. the taskbar is still shown). The initial size appears to be set in
line 728 of src/gnuwin32/rui.c, so you could change that and re-compile R.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From magnolia at absolutok.net  Sat May 17 19:19:49 2003
From: magnolia at absolutok.net (ANA KOZOMARA)
Date: Sat, 17 May 2003 19:19:49 +0200
Subject: [R] how to construct tree under R
Message-ID: <003184919171153SILJA@silja.absolutok.com>

Hello.
I have a hudge problem, don't know how to deal with it...
I'm supposed to implement a tree structure in R, without using
rpart library...
I don't have any clue about appropriate approach...
Anyway, I can't use pointers under R...so how to to it?
lists, vectors...
Anyway, does anybody knows how the regression tree in rpart was
implemented...
Someone please help!
Thanks,
ana



From feldesmanm at pdx.edu  Sat May 17 19:52:23 2003
From: feldesmanm at pdx.edu (Marc Feldesman)
Date: Sat, 17 May 2003 10:52:23 -0700
Subject: [R] how to construct tree under R
In-Reply-To: <003184919171153SILJA@silja.absolutok.com>
References: <003184919171153SILJA@silja.absolutok.com>
Message-ID: <20030517105223.5901091a.feldesmanm@pdx.edu>



On Sat, 17 May 2003 19:19:49 +0200, an incredible array of electrons
randomly cascading around the Universe collided and turned into words
spewed forth by ANA KOZOMARA:


ANA> Hello.
ANA> I have a hudge problem, don't know how to deal with it...
ANA> I'm supposed to implement a tree structure in R, without using
ANA> rpart library...
ANA> I don't have any clue about appropriate approach...
ANA> Anyway, I can't use pointers under R...so how to to it?
ANA> lists, vectors...
ANA> Anyway, does anybody knows how the regression tree in rpart was
ANA> implemented...
ANA> Someone please help!


You might look at the source code, which is available with the
library.  You could also look at the technical report available on
CRAN (package sources), which explains the way the program works.  If
all else fails, you could also look at Breiman et al, "Classification
and Regression Trees" which is the canonical source for this.

HTH



From parkhurs at ariel.ucs.indiana.edu  Sat May 17 20:25:46 2003
From: parkhurs at ariel.ucs.indiana.edu (David Parkhurst)
Date: Sat, 17 May 2003 13:25:46 -0500
Subject: [R] Changing default R window under XP
References: <Pine.LNX.4.44.0305171752080.21525-100000@gannet.stats>
Message-ID: <002d01c31ca1$d6059bb0$0a6cfea9@BLSPEAPARKHOM>

Thanks for the quick response.  I don't know the abbreviations SDI and MDI.
However, I have just recently installed R on a new hard drive, and by
default, it (R) does come up full screen.  That is, the middle button of the
three in the upper right corner of its window has an icon with two windows.
(When clicked, that puts the window in partial screen.)  If it were not full
screen, that button would show a single window.

Also, I tried right clicking on my R icon to set properties, where I thought
I could specify command-line options like "--sdi" to see what would happen,
but I don't see a way to do that in XP.  (I'm pretty sure I could do that in
earlier versions of the windows OS.)  Also, in the Rconsole file, I changed
the line"MDI = yes" to "MDI = no," but that didn't seem to make any
difference that I can see.

As for recompiling, I use Fortran (90), and don't have a C compiler.

Further help would be welcome.
Dave
----- Original Message ----- 
From: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
To: "David Parkhurst" <parkhurs at ariel.ucs.indiana.edu>
Cc: <r-help at stat.math.ethz.ch>
Sent: Saturday, May 17, 2003 12:00 PM
Subject: Re: [R] Changing default R window under XP


> One possibility is to use SDI mode (e.g. --sdi)
>
> On Sat, 17 May 2003, David Parkhurst wrote:
>
> > I'm working with R 1.7.0 under windows XP.  Whenever I start the
program, it
> > comes up full screen, and I have to resize it to suit my preferences.
How
> > can I make it come up at a particular size (but not full screen) every
time?
>
> If you are in MDI, it actually comes up maximized, not full screen (so
> e.g. the taskbar is still shown). The initial size appears to be set in
> line 728 of src/gnuwin32/rui.c, so you could change that and re-compile R.
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>
>



From magnolia at absolutok.net  Sat May 17 20:28:24 2003
From: magnolia at absolutok.net (ANA KOZOMARA)
Date: Sat, 17 May 2003 20:28:24 +0200
Subject: [R] how to construct tree under R
Message-ID: <0033e2428181153SILJA@silja.absolutok.com>


----- Original Message -----
From: "Marc Feldesman" <feldesmanm at pdx.edu>
To: <r-help at stat.math.ethz.ch>
Sent: Saturday, May 17, 2003 7:52 PM
Subject: Re: [R] how to construct tree under R


>
>
> On Sat, 17 May 2003 19:19:49 +0200, an incredible array of electrons
> randomly cascading around the Universe collided and turned into words
> spewed forth by ANA KOZOMARA:
>
>
> ANA> Hello.
> ANA> I have a hudge problem, don't know how to deal with it...
> ANA> I'm supposed to implement a tree structure in R, without using
> ANA> rpart library...
> ANA> I don't have any clue about appropriate approach...
> ANA> Anyway, I can't use pointers under R...so how to to it?
> ANA> lists, vectors...
> ANA> Anyway, does anybody knows how the regression tree in rpart was
> ANA> implemented...
> ANA> Someone please help!
>
>
> You might look at the source code, which is available with the
> library.  You could also look at the technical report available on
> CRAN (package sources), which explains the way the program works.  If
> all else fails, you could also look at Breiman et al, "Classification
> and Regression Trees" which is the canonical source for this.
>
> HTH
Thanks for your advices...but, but, but...the whole day i was trying to
understand the source code of the rpart function...
i mean, if it's what obtained by typing
>rpart in R-prompt...
sorry, if I pose stupid questions, but R is really new to me...
I don't even know what's
> also look at Breiman et al, "Classification
> and Regression Trees"
.a book...? I don't think that, here in France I could get it...:(...
So, my stupid question is, how do I get the source code of R functions...?
Well, thanks a lot again,
ana
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From perkinsm at bway.net  Sat May 17 20:40:09 2003
From: perkinsm at bway.net (Mark E. Perkins)
Date: Sat, 17 May 2003 14:40:09 -0400
Subject: [R] problem building dvi and pdf documentation on Darwin 10.2.6
Message-ID: <2147483647.1053182409@[192.168.187.8]>

I just installed R-1.7.0 on Darwin 6.6 (a.k.a. MacOS 10.2.6). 
'make' and 'make check' run without any problems. 'make info' 
builds with no complaints, but 'make dvi' and 'make pdf' fail. 
I get refman.dvi and refman.pdf OK (with some warnings from 
pdftex that some names are referenced that do not exist), but 
R-FAQ.{dvi,pdf} fails as shown below. Attempts to build the other 
R-{intro,admin,...}.{dvi,pdf} (manually via 'make xyzzy') fail 
similarly.

My last serious experience with TeX was some years ago, so I'm not 
sure if this a glitch in the input files, a borken TeX installation 
(mine is teTeX 2.0.2 built via fink), or some (other) Darwin-related 
problem.

If someone with a better understanding of these things can point 
me in the right direction, I'd appreciate it.

Thanks,
Mark Perkins
perkinsm at bway.net

---------------------------
Output from make:

TEXINPUTS=".:$TEXINPUTS" ../../bin/texi2dvi --texinfo="@set
UseExternalXrefs" R-FAQ.texi
This is TeX, Version 3.14159 (Web2C 7.4.5)
(/tmp/t2d10777/xtr/R-FAQ.texi (./texinfo.tex
Loading texinfo [version 2002-03-26.08]: Basics, pdf, fonts, page headings,
tables, conditionals, indexing, sectioning, toc, environments, defuns,
macros,
cross references, (/sw/share/texmf/tex/generic/misc/epsf.tex) localization,
and turning on texinfo input format.)
! Missing @endcsname inserted.
<to be read again> 
                   @let 
@parsearg #1->@let 
                   @next = #1 at begingroup @obeylines @futurelet @temp
@parsea...
<argument> UseExternalXrefs at settitle 
                                     R
@setzzz ...tzzz ->@expandafter @gdef @csname SET#1
                                                  @endcsname {#2}
@setyyy ... @empty @else @setzzz {#1}#2 at endsetzzz 
                                                  @fi @endgroup 
l.5 @set UseExternalXrefs at settitle R FAQ
                                        
? [I type <return> here]

(/sw/share/texmf/tex/texinfo/txi-en.tex) [1] [-1] Chapter 1 (./R-FAQ.tmp)
Cross reference values unknown; you must run TeX again. Chapter 2 [1] [2]
[3] (./R-FAQ.tmp) (./R-FAQ.tmp) [4] [5] (./R-FAQ.tmp) (./R-FAQ.tmp)
(./R-FAQ.tmp) (./R-FAQ.tmp) [6] (./R-FAQ.tmp) (./R-FAQ.tmp) (./R-FAQ.tmp)
(./R-FAQ.tmp) (./R-FAQ.tmp) [7] (./R-FAQ.tmp) [8] [9] Chapter 3 [10]
(./R-FAQ.tmp) (./R-FAQ.tmp) (./R-FAQ.tmp) (./R-FAQ.tmp) (./R-FAQ.tmp) [11]
(./R-FAQ.tmp) [12] [13] [14] [15] (./R-FAQ.tmp) [16] (./R-FAQ.tmp)
(./R-FAQ.tmp
) (./R-FAQ.tmp) Chapter 4 [17] (./R-FAQ.tmp) Chapter 5 [18] [19]
(./R-FAQ.tmp)
[20] (./R-FAQ.tmp) (./R-FAQ.tmp) [21] [22] [23] [24] [25] [26] [27]
(./R-FAQ.tmp) [28] (./R-FAQ.tmp) [29] (./R-FAQ.tmp) [30] (./R-FAQ.tmp)
(./R-FAQ.tmp) (./R-FAQ.tmp) [31] (./R-FAQ.tmp) (./R-FAQ.tmp) (./R-FAQ.tmp)
(./R-FAQ.tmp) (./R-FAQ.tmp) (./R-FAQ.tmp) (./R-FAQ.tmp) [32] [33] [34] [35]

WARNING: for users of Unix TeX 3.0!
This manual trips a bug in TeX version 3.0 (tex hangs).
If you are running another version of TeX, relax.
If you are running Unix TeX 3.0, kill this TeX process.
 Then upgrade your TeX installation if you can.
 (See ftp://ftp.gnu.org/pub/gnu/TeX.README.)
If you are stuck with version 3.0, run the
 script ``tex3patch'' from the Texinfo distribution
 to use a workaround.

Chapter 6 [36] (./R-FAQ.tmp) (./R-FAQ.tmp) (./R-FAQ.tmp) [37] Chapter 7
[38] [39] [40] [41] [42] [43] [44] [45] (./R-FAQ.tmp) Chapter 8 [46]
Chapter 9
[47] [48] Chapter 10 [49] [50] )
Output written on R-FAQ.dvi (52 pages, 156736 bytes).
Transcript written on R-FAQ.log.
../../bin/texi2dvi: tex exited with bad status, quitting.
../../bin/texi2dvi: see R-FAQ.log for errors.
make[2]: *** [R-FAQ.dvi] Error 1
make[1]: *** [dvi] Error 2
make: [dvi] Error 2 (ignored)



From ripley at stats.ox.ac.uk  Sat May 17 20:45:55 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Sat, 17 May 2003 19:45:55 +0100 (GMT Daylight Time)
Subject: [R] Changing default R window under XP
In-Reply-To: <002d01c31ca1$d6059bb0$0a6cfea9@BLSPEAPARKHOM>
Message-ID: <Pine.WNT.4.44.0305171934520.2784-100000@petrel>

On Sat, 17 May 2003, David Parkhurst wrote:

> Thanks for the quick response.  I don't know the abbreviations SDI and MDI.

So you've never read the R for Windows README, for example?  Surely it
is reasonable to expect people to be familiar with README when they ask how
to do things?  (They are standard Windows terms, BTW.)

> However, I have just recently installed R on a new hard drive, and by
> default, it (R) does come up full screen.  That is, the middle button of the
> three in the upper right corner of its window has an icon with two windows.
> (When clicked, that puts the window in partial screen.)  If it were not full
> screen, that button would show a single window.

Yes, that's what happens, and that is what *maximized* means.  Do look
those terms up in your Windows help, to help you understand those who use
them in the standard way.

> Also, I tried right clicking on my R icon to set properties, where I thought
> I could specify command-line options like "--sdi" to see what would happen,
> but I don't see a way to do that in XP.  (I'm pretty sure I could do that in
> earlier versions of the windows OS.)

I've never seen an XP where it did not work on a shortcut.

> Also, in the Rconsole file, I changed
> the line"MDI = yes" to "MDI = no," but that didn't seem to make any
> difference that I can see.

It's in the documentation: you add --sdi to the end of the target in the
properties of the shortcut.  Changing the right Rconsole file does work
....

> As for recompiling, I use Fortran (90), and don't have a C compiler.

They are free, and fully documented: again, please read the documentation.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ahmlatif at yahoo.com  Sat May 17 20:47:18 2003
From: ahmlatif at yahoo.com (Mahbub Latif)
Date: Sat, 17 May 2003 11:47:18 -0700 (PDT)
Subject: [R] max/summary
Message-ID: <20030517184718.89660.qmail@web41205.mail.yahoo.com>

Hi,

What is the reason for getting two different max of a
vector from two functions max() and summary()? Here is
an example,

> set.seed(2222)
> x <- sample(x=1:100000, size=10000, replace=T)
> max(x)
[1] 99992
> summary(x)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
      6   24510   49950   50020   75040   99990 

Which value is the correct one? I had this problem
while I was working with microarry data. 

Thanks.

Mahbub



From ripley at stats.ox.ac.uk  Sat May 17 20:59:39 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Sat, 17 May 2003 19:59:39 +0100 (GMT Daylight Time)
Subject: [R] max/summary
In-Reply-To: <20030517184718.89660.qmail@web41205.mail.yahoo.com>
Message-ID: <Pine.WNT.4.44.0305171956220.2784-100000@petrel>

They are the same value.  Lokking at ?summary will show you that the number
of significant values are different in the two cases (7 and 4).

You need to distinguish between the value and how it is printed.

On Sat, 17 May 2003, Mahbub Latif wrote:

> What is the reason for getting two different max of a
> vector from two functions max() and summary()? Here is
> an example,
>
> > set.seed(2222)
> > x <- sample(x=1:100000, size=10000, replace=T)
> > max(x)
> [1] 99992
> > summary(x)
>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>       6   24510   49950   50020   75040   99990
>
> Which value is the correct one? I had this problem
> while I was working with microarry data.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From magnolia at absolutok.net  Sat May 17 21:00:06 2003
From: magnolia at absolutok.net (ANA KOZOMARA)
Date: Sat, 17 May 2003 21:00:06 +0200
Subject: [R] how to construct tree under R
Message-ID: <003200600191153SILJA@silja.absolutok.com>

Sorry, didn't mean to make you mad...
unfortunately, at the moment i don't think i can afford it,
and in my university library there are no books concerning R...
Anyway, I'm sorry if I'm bugging you with the questions...
(actually, I even tried to install today one library which I think was
written
by you..."tree")...anyway it didn't work, so I suppose that speaks of my
niveau..Too bad there is no mailing list for a real R beginers...
I'm kidding,
best regard,
anyway, thaks for the answers,
ana
>
> Why not?  What is special about France?  The book in published in the
USA,
> so you could order it from there.
>
> > So, my stupid question is, how do I get the source code of R
functions...?
> > Well, thanks a lot again,
>
> In the R sources, which are on CRAN, as Marc said.
>
> You get with R the technical support you paid for: you might be better
off
> buying a commercial program and using its paid-for technical support.
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>



From edd at debian.org  Sat May 17 21:12:45 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 17 May 2003 14:12:45 -0500
Subject: [R] max/summary
In-Reply-To: <20030517184718.89660.qmail@web41205.mail.yahoo.com>
References: <20030517184718.89660.qmail@web41205.mail.yahoo.com>
Message-ID: <20030517191245.GA25200@sonny.eddelbuettel.com>

On Sat, May 17, 2003 at 11:47:18AM -0700, Mahbub Latif wrote:
> Hi,
> 
> What is the reason for getting two different max of a
> vector from two functions max() and summary()? Here is
> an example,
> 
> > set.seed(2222)
> > x <- sample(x=1:100000, size=10000, replace=T)
> > max(x)
> [1] 99992
> > summary(x)
>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
>       6   24510   49950   50020   75040   99990 
> 
> Which value is the correct one? I had this problem
> while I was working with microarry data. 

They are both the same, summary uses a display with 4 significant digits:

edd at chibud:~> R --silent --no-save --no-restore
> set.seed(2222)
> x <- sample(x=1:100000, size=10000, replace=T)
> max(x)
[1] 99992
> summary(x, digits=6)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
    6.0 24513.5 49954.5 50019.7 75038.8 99992.0
       
Hth, Dirk

-- 
Don't drink and derive. Alcohol and analysis don't mix.



From kwan022 at stat.auckland.ac.nz  Sat May 17 22:10:24 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Sun, 18 May 2003 08:10:24 +1200 (NZST)
Subject: [R] how to construct tree under R
In-Reply-To: <003184919171153SILJA@silja.absolutok.com>
Message-ID: <Pine.LNX.4.44.0305180803370.4759-100000@stat61.stat.auckland.ac.nz>

Hi,

On Sat, 17 May 2003, ANA KOZOMARA wrote:

> I have a hudge problem, don't know how to deal with it...
> I'm supposed to implement a tree structure in R, without using
> rpart library...

I'm not sure what exactly you want here.  If you want to write a function 
that uses some kind of algorithms on decision trees (e.g. CART) then you 
will have to consult some technical books.

If you are just working on a practical problem, i.e. you have got a data 
set and just want to get a tree from it, then the tree or rpart package 
are two of the packages you can use (and you can consult "Modern Applied 
Statistics with S" by Venables and Ripley, 2002).  I am not sure why you 
do not want to use the rpart package, but the tree package has some very 
good documentation which you can read and find out how to use it.  

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)



From p.dalgaard at biostat.ku.dk  Sat May 17 23:10:45 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Sat, 17 May 2003 21:10:45 -0000
Subject: [R] problem building dvi and pdf documentation on Darwin 10.2.6
In-Reply-To: <2147483647.1053182409@[192.168.187.8]>
References: <2147483647.1053182409@[192.168.187.8]>
Message-ID: <x24r3ti89j.fsf@biostat.ku.dk>

"Mark E. Perkins" <perkinsm at bway.net> writes:

> I just installed R-1.7.0 on Darwin 6.6 (a.k.a. MacOS 10.2.6). 
> 'make' and 'make check' run without any problems. 'make info' 
> builds with no complaints, but 'make dvi' and 'make pdf' fail. 
> I get refman.dvi and refman.pdf OK (with some warnings from 
> pdftex that some names are referenced that do not exist), but 
> R-FAQ.{dvi,pdf} fails as shown below. Attempts to build the other 
> R-{intro,admin,...}.{dvi,pdf} (manually via 'make xyzzy') fail 
> similarly.
> 
> My last serious experience with TeX was some years ago, so I'm not 
> sure if this a glitch in the input files, a borken TeX installation 
> (mine is teTeX 2.0.2 built via fink), or some (other) Darwin-related 
> problem.
> 
> If someone with a better understanding of these things can point 
> me in the right direction, I'd appreciate it.
> 
...
> TEXINPUTS=".:$TEXINPUTS" ../../bin/texi2dvi --texinfo="@set
> UseExternalXrefs" R-FAQ.texi
> This is TeX, Version 3.14159 (Web2C 7.4.5)
> (/tmp/t2d10777/xtr/R-FAQ.texi (./texinfo.tex
> Loading texinfo [version 2002-03-26.08]: Basics, pdf, fonts, page headings,
> tables, conditionals, indexing, sectioning, toc, environments, defuns,
> macros,
> cross references, (/sw/share/texmf/tex/generic/misc/epsf.tex) localization,
> and turning on texinfo input format.)
> ! Missing @endcsname inserted.
> <to be read again> 
>                    @let 
> @parsearg #1->@let 
>                    @next = #1 at begingroup @obeylines @futurelet @temp
> @parsea...
> <argument> UseExternalXrefs at settitle 
>                                      R
> @setzzz ...tzzz ->@expandafter @gdef @csname SET#1
>                                                   @endcsname {#2}
> @setyyy ... @empty @else @setzzz {#1}#2 at endsetzzz 
>                                                   @fi @endgroup 
> l.5 @set UseExternalXrefs at settitle R FAQ
>                                         
> ? [I type <return> here]
> 
> (/sw/share/texmf/tex/texinfo/txi-en.tex) [1] [-1] Chapter 1 (./R-FAQ.tmp)
> Cross reference values unknown; you must run TeX again. Chapter 2 [1] [2]
> [3] (./R-FAQ.tmp) (./R-FAQ.tmp) [4] [5] (./R-FAQ.tmp) (./R-FAQ.tmp)
> (./R-FAQ.tmp) (./R-FAQ.tmp) [6] (./R-FAQ.tmp) (./R-FAQ.tmp) (./R-FAQ.tmp)
> (./R-FAQ.tmp) (./R-FAQ.tmp) [7] (./R-FAQ.tmp) [8] [9] Chapter 3 [10]
> (./R-FAQ.tmp) (./R-FAQ.tmp) (./R-FAQ.tmp) (./R-FAQ.tmp) (./R-FAQ.tmp) [11]
> (./R-FAQ.tmp) [12] [13] [14] [15] (./R-FAQ.tmp) [16] (./R-FAQ.tmp)
> (./R-FAQ.tmp
> ) (./R-FAQ.tmp) Chapter 4 [17] (./R-FAQ.tmp) Chapter 5 [18] [19]
> (./R-FAQ.tmp)
> [20] (./R-FAQ.tmp) (./R-FAQ.tmp) [21] [22] [23] [24] [25] [26] [27]
> (./R-FAQ.tmp) [28] (./R-FAQ.tmp) [29] (./R-FAQ.tmp) [30] (./R-FAQ.tmp)
> (./R-FAQ.tmp) (./R-FAQ.tmp) [31] (./R-FAQ.tmp) (./R-FAQ.tmp) (./R-FAQ.tmp)
> (./R-FAQ.tmp) (./R-FAQ.tmp) (./R-FAQ.tmp) (./R-FAQ.tmp) [32] [33] [34] [35]
> 
> WARNING: for users of Unix TeX 3.0!
> This manual trips a bug in TeX version 3.0 (tex hangs).
> If you are running another version of TeX, relax.
> If you are running Unix TeX 3.0, kill this TeX process.
>  Then upgrade your TeX installation if you can.
>  (See ftp://ftp.gnu.org/pub/gnu/TeX.README.)
> If you are stuck with version 3.0, run the
>  script ``tex3patch'' from the Texinfo distribution
>  to use a workaround.
> 
> Chapter 6 [36] (./R-FAQ.tmp) (./R-FAQ.tmp) (./R-FAQ.tmp) [37] Chapter 7
> [38] [39] [40] [41] [42] [43] [44] [45] (./R-FAQ.tmp) Chapter 8 [46]
> Chapter 9
> [47] [48] Chapter 10 [49] [50] )
> Output written on R-FAQ.dvi (52 pages, 156736 bytes).
> Transcript written on R-FAQ.log.
> ../../bin/texi2dvi: tex exited with bad status, quitting.
> ../../bin/texi2dvi: see R-FAQ.log for errors.

It might be informative to take that hint since the log files are
somewhat more verbose about exactly what is going on. 

It's not your texinfo version -- mine is exactly the same. However,
there are probably very few people running teTeX 2.x so there could be
an obscure installation problem with that.

It looks like your troubles begin where TeX is supposed to be
processing R-FAQ.aux. It can happen that TeX gets wedged when there's a
problem with that so you could try deleting it.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From feldesmanm at pdx.edu  Sun May 18 01:15:02 2003
From: feldesmanm at pdx.edu (Marc Feldesman)
Date: Sat, 17 May 2003 16:15:02 -0700
Subject: [R] Windows binary corrupt
Message-ID: <5.1.1.2.2.20030517161010.00a8dae8@pop4.attglobal.net>

I've tried to download the Windows 1.7.0 binary from three different 
mirrors today.  Each time the binary comes down corrupt - MD 5 sums don't 
check and the installer reports that its own setup files are corrupt.

Since I've tried from different computers and different connections, I have 
to assume a problem downstream from me.

Has anyone else reported this problem?  Has the binary changed at all since 
it was posted back in April?

BTW, I haven't encountered this before when I've downloaded the 1.7.0 
Windows binary immediately following its release.






=====================
Dr. Marc R. Feldesman
Professor and Chairman
Anthropology Department
Portland State University
1721 SW Broadway
Portland, Oregon 97201
email:  feldesmanm at pdx.edu
phone:  503-725-3081
fax:    503-725-3905
http://web.pdx.edu/~h1mf
PGP Key Available On Request
======================

"Beyond every credibility gap lies a gullibility fill"

Powered by  Latochoerus and Windows 2000, SP1



From estatisticus at yahoo.com  Sun May 18 06:22:13 2003
From: estatisticus at yahoo.com (J S)
Date: Sat, 17 May 2003 21:22:13 -0700 (PDT)
Subject: [R] derivatives from loess (not locpoly)?
Message-ID: <20030518042213.21874.qmail@web9505.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030517/4ef56a66/attachment.pl

From ripley at stats.ox.ac.uk  Sun May 18 09:11:57 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 18 May 2003 08:11:57 +0100 (BST)
Subject: [R] derivatives from loess (not locpoly)?
In-Reply-To: <20030518042213.21874.qmail@web9505.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0305180808150.16083-100000@gannet.stats>

Not easily. Unlike locpoly (in KernSmooth, uncredited), loess uses a 
locally varying bandwidth and that would need to be taken into account in 
determining the derivative.  The underlying Fortran code does not have any 
support for this.

On Sat, 17 May 2003, J S wrote:

> is there a way of estimating derivative curves, similar to the ones we
> get from 'locpoly', from 'loess' estimation.

>  i am interested in estimation of 1st and 2nd derivatives...

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Sebastian.Weber at physik.tu-darmstadt.de  Sun May 18 11:28:06 2003
From: Sebastian.Weber at physik.tu-darmstadt.de (Sebastian Weber)
Date: Sun, 18 May 2003 11:28:06 +0200
Subject: [R] log scale y axis ticks control?
Message-ID: <20030518092806.GA27846@prp0.prp.physik.tu-darmstadt.de>

Hello R Users!

I'm using lattice to produce some graphs with logaritmic y-scales. I use
the command

xyplot(hits ~ c(1:1024), data=eichData, type="S", scales=list(y =
list(log=10)))

to create the plot. This is fine, except for the automatically choosen
tick marks. I'd like to have a major tick at the 10^n location and minor
ticks in between which correspond with the native variable. To get this
working I have to use at and label like

labl <- rep("", 30)
labl[1] <- "1"; labl[10] <- "10"; labl[19] <- "100"; labl[28] <- "1000";
nums <- c(1:10, seq(20,100, 10), seq(200, 1000, 100))
xyplot(hits ~ c(1:1024), data=eichData, type="S", scales=list(y =
list(log=10, at=nums, labels=labl)))

But this definitely extremly clumsy. There has to be an easier way to do
it which I haven't found yet.

Another nifty feature would be mixing these two axis styles. One axis
with linear ticks (10^0, 10^0.5, 10^1, ...) and the other axis with tick
marks as indicated above.

Thanks in advance,

Sebastian Weber



From Sebastian.Weber at physik.tu-darmstadt.de  Sun May 18 11:34:34 2003
From: Sebastian.Weber at physik.tu-darmstadt.de (Sebastian Weber)
Date: Sun, 18 May 2003 11:34:34 +0200
Subject: [R] mixing log scale and linear scale panels
Message-ID: <20030518093434.GA27904@prp0.prp.physik.tu-darmstadt.de>

Hello R Users!

I'm very often confronted with the problem to produce a linear and a log
scale view of a graph (hits counted by alpha-ray detector). I would like
to join these views within a multi-panel lattice graph. I have crawled
through the documentation, google and friends without success. 

Thank your for your help!

Sincerly,

Sebastian Weber



From xiao.gang.fan1 at libertysurf.fr  Sun May 18 12:08:08 2003
From: xiao.gang.fan1 at libertysurf.fr (Fan)
Date: Sun, 18 May 2003 11:08:08 +0100
Subject: [R] how to handle 'multiresponse' variable?
References: <3EC627D8.1020309@nac.spb.ru>
Message-ID: <3EC75B88.8030503@libertysurf.fr>

There were some discussions in the past on this subject.
AFAK, there're actually useful functions in Frank Harell's package
"hmisc", like mChoice() and summarize(). For the detail
go to the R search page

http://finzi.psych.upenn.edu/search.html

and search

"Frank Harrell type multi-valued variable".

--
Fan

Kosenkov Kirill wrote:
> Hello!
> 
> I have dataset where one variable is 'multiresponse', like this:
> [1] "1 2" "1 2 3" "4" "1 4" "4 3" etc.
> 'responses' separated by space. observations in different 'rows' of 
> data.frame.
> I can do strsplit(data$var,' ') and make a list, where multiple 
> responses are elements of character vectors, like this:
>  $ P124               :List of 2956
>   ..$ : chr  "2" "4"
>   ..$ : chr  "1" "2"
>   ..$ : chr "NA"
>   ..$ : chr  "3" "4"
>   ..$ : chr "3"
> 
> I need to compute crosstabulation on this variable, to make 
> crosstabulation where this variable is a factor variable (responses of 
> this variable are categories, in which i need to compute distributions 
> of other variables). And i need to do crosstabulation with 'weights', 
> like in xtabs(w~f1+f2).
> 
> Is any way exists to do such things with 'multiresponse' variables in R 
> or i need to write my own functions to handle it?
> 
> Thanks!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From smyth at wehi.edu.au  Sun May 18 13:12:32 2003
From: smyth at wehi.edu.au (Gordon Smyth)
Date: Sun, 18 May 2003 21:12:32 +1000
Subject: [R] how to build specific doc types in Windows
Message-ID: <5.2.0.9.1.20030518210214.00ad2470@imaphost.wehi.edu.au>

I am building R packages using R 1.7.0pat under Windows 2000 Professional. 
All works fine except that I haven't been able to figure out how to use the 
--docs=TYPE option. I would like to optionally turn off building chm help. 
I have tried build commands like

rcmd build --binary --docs=TYPE mypackagename

In place of "TYPE" I have tried things like "html", "text", "chm", "t", 
"h", "HTML" etc, etc, but all of these break the build entirely. What are 
the actual options for --docs=TYPE? I have tried all the documentation 
sources I know of, plus hacking the perl code, but can't see what the 
options are.

Thanks
Gordon

For easy reference, here is the help output from rcmd build:

Usage: Rcmd build [options] pkgdirs

Build R packages from package sources in the directories specified by
pkgdirs.

Options:
   -h, --help            print short help message and exit
   -v, --version         print version info and exit

   --force               force overwriting of (index) files
   --no-vignettes        do not rebuild package vignettes

   --binary              build pre-compiled binary packages, with options:
   --docs=TYPE           type(s) of documentation to build and install
   --auto-zip            select zipping of data and help based on size
   --use-zip-data        collect data files in zip archive
   --use-zip-help        collect help and examples into zip archives
   --use-zip             combine '--use-zip-data' and '--use-zip-help'



From adrian.trapletti at lmttrading.com  Sun May 18 13:41:18 2003
From: adrian.trapletti at lmttrading.com (Adrian Trapletti)
Date: Sun, 18 May 2003 13:41:18 +0200
Subject: [R] arma.predict?
References: <200305171001.h4HA1QNU005023@hypatia.math.ethz.ch>
Message-ID: <3EC7715D.CD99F28E@lmttrading.com>

> Subject: Re: Re: [R] arma.predict?
> Date: Sat, 17 May 2003 05:24:29 +1000
> From: "Skanda Kallur; MEngg" <s2112930 at student.rmit.edu.au>
> To: ripley at stats.ox.ac.uk
> CC: r-help at stat.math.ethz.ch
>
> Professor, thanks for the reply, I am using Auto Regression Moving Average arma()(sorry it wasnt ARMA) which comes under tseries package to fit my data and I am intending to predict with arma fitted data but couldnt find a method to do it.

Pls use arima from ts. arma from tseries is preliminary and will soonly be removed in the current form.

> Interestingly, I found two packages at http://www.itp.phys.ethz.ch/econophysics/R/ which has packages called fbasic and fseries. fseries has arma.predict() but it threw some error, I wasnt able to install it. I would appreciate if you could have a look at it.

As far as I know, those packages are still preliminary. So if you want to use them, maybe you contact the author Diethelm W?rtz wuertz at itp.phys.ethz.ch

best
Adrian

>
> Regards
>
> Skanda
>
> -----Original Message-----
> From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
> To: "Skanda Kallur; MEngg" <s2112930 at student.rmit.edu.au>
> Date: Fri, 16 May 2003 19:29:37 +0100 (BST)
> Subject: Re: [R] ARMA.predict?
>
> On Sat, 17 May 2003, Skanda Kallur; MEngg wrote:
>
> > Hi there,
> >
> > Does anyone know how to predict ARMA? It doesn??????t have either predict
> > or forecast methods. I found couple of packages called fbasic and
> > fseries at http://www.itp.phys.ethz.ch/econophysics/R/, which has
> > ??????arma.predict?????? in it, but it doesn??????t seem to be working. Any help
> > in this regard would be appreciated. Thanks in advance.
>
> Well,  R comes with arima and arima0 functions, and both have predict
> methods.  What is ARMA and where did you get it from?
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> Skanda Kallur
>
> "Prediction is very difficult, especially if it's about the future."
> --Niels Bohr

--
Dr. Adrian Trapletti             Phone :             +41 (0) 1 994 5631
Trapletti Statistical Computing  Mobile:             +41 (0)76 370 5631
Wildsbergstrasse 31              Fax   :             +41 (0) 1 994 5631
CH-8610 Uster                    Email :  mailto:a.trapletti at bluewin.ch
Switzerland                      WWW   : http://trapletti.homelinux.com



From ripley at stats.ox.ac.uk  Sun May 18 13:51:58 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 18 May 2003 12:51:58 +0100 (BST)
Subject: [R] how to build specific doc types in Windows
In-Reply-To: <5.2.0.9.1.20030518210214.00ad2470@imaphost.wehi.edu.au>
Message-ID: <Pine.LNX.4.44.0305181243520.25659-100000@gannet.stats>

That option is passed to INSTALL, and Rcmd INSTALL has help which tells 
you.  I think you want --docs=normal.

I would have thought INSTALL was the obvious place to look (especially
form the Perl code).  I normally build binary packages via Rcmd INSTALL
--build in the source tree: this ensures that help references get resolved
correctly, which Rcmd build --binary does not.

On Sun, 18 May 2003, Gordon Smyth wrote:

> I am building R packages using R 1.7.0pat under Windows 2000 Professional. 
> All works fine except that I haven't been able to figure out how to use the 
> --docs=TYPE option. I would like to optionally turn off building chm help. 
> I have tried build commands like
> 
> rcmd build --binary --docs=TYPE mypackagename
> 
> In place of "TYPE" I have tried things like "html", "text", "chm", "t", 
> "h", "HTML" etc, etc, but all of these break the build entirely. What are 
> the actual options for --docs=TYPE? I have tried all the documentation 
> sources I know of, plus hacking the perl code, but can't see what the 
> options are.
> 
> Thanks
> Gordon
> 
> For easy reference, here is the help output from rcmd build:
> 
> Usage: Rcmd build [options] pkgdirs
> 
> Build R packages from package sources in the directories specified by
> pkgdirs.
> 
> Options:
>    -h, --help            print short help message and exit
>    -v, --version         print version info and exit
> 
>    --force               force overwriting of (index) files
>    --no-vignettes        do not rebuild package vignettes
> 
>    --binary              build pre-compiled binary packages, with options:
>    --docs=TYPE           type(s) of documentation to build and install
>    --auto-zip            select zipping of data and help based on size
>    --use-zip-data        collect data files in zip archive
>    --use-zip-help        collect help and examples into zip archives
>    --use-zip             combine '--use-zip-data' and '--use-zip-help'
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From alkatz at post.tau.ac.il  Sun May 18 13:05:40 2003
From: alkatz at post.tau.ac.il (alkatz@post.tau.ac.il)
Date: Sun, 18 May 2003 14:05:40 +0300 (IDT)
Subject: [R] echo = FALSE does not work
Message-ID: <1053255940.3ec7690453c5d@webmail.tau.ac.il>

Hello, everybody,

I am running 
R BATCH --no-save myscript.R myscript.out

myscrypt.out contains the ouput I want to see there, along with 
all the commands executed by the script.

I found in the help files, that writing echo=FALSE in the beginning of
myscrypt.out should suppress printing of the commands,
but it does not.

Can you help me , please ?

Thank you,
Alex



From ripley at stats.ox.ac.uk  Sun May 18 14:42:33 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 18 May 2003 13:42:33 +0100 (BST)
Subject: [R] echo = FALSE does not work
In-Reply-To: <1053255940.3ec7690453c5d@webmail.tau.ac.il>
Message-ID: <Pine.LNX.4.44.0305181337150.26795-100000@gannet.stats>

On Sun, 18 May 2003 alkatz at post.tau.ac.il wrote:

> I am running 
> R BATCH --no-save myscript.R myscript.out
> 
> myscrypt.out contains the ouput I want to see there, along with 
> all the commands executed by the script.
> 
> I found in the help files, that writing echo=FALSE in the beginning of
> myscrypt.out should suppress printing of the commands,
> but it does not.

I can't find anything like that in `the help files', so please give us a
clue as to which of the 800 or so you found it in.

help(options) does say that writing *options(echo=FALSE)* at the beginning
of *myscript.R* would do this, and it does.  It also says you can use 
--slave.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ndey00 at yahoo.com  Sun May 18 16:37:56 2003
From: ndey00 at yahoo.com (N Dey)
Date: Sun, 18 May 2003 07:37:56 -0700 (PDT)
Subject: [R] Date along x axis
Message-ID: <20030518143756.12616.qmail@web41303.mail.yahoo.com>

Dear all,

I am plotting date on x axis and by doing following

mydata$idate <- strptime(x=as.character(mydata$date),
format = "%m-%d-%Y")

mydata$ldate <- as.POSIXlt(mydata$idate)
dts <- seq.dates("01/01/2000", "12/31/2000", by="day")
dts1<-as.POSIXlt(dts1)

plot(mydata$ldate,mydata$Number
,type="b",xlim=c(min(dts1),max(dts1)))

but it is not working.It is giving error. So if
anybody know how to solve this then pl. let me know.

Actually data is only for 5-6 months but i want whole
year along x axis so that easy to compare with other
years's data (where we have complete data).

This is to set xlim as whole year.

THanking you.

best regards,
N. Dey



From ggrothendieck at volcanomail.com  Sun May 18 18:57:06 2003
From: ggrothendieck at volcanomail.com (Gabor Grothendieck)
Date: Sun, 18 May 2003 09:57:06 -0700 (PDT)
Subject: [R] Efficient subsetting
Message-ID: <20030518165707.193F74891@sitemail.everyone.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030518/92342a5d/attachment.pl

From ivo.welch at yale.edu  Sun May 18 20:21:08 2003
From: ivo.welch at yale.edu (Welch, Ivo)
Date: Sun, 18 May 2003 14:21:08 -0400
Subject: [R] TS data frames
Message-ID: <3EC7CF14.4020501@yale.edu>


hi chaps:  apologies, more naive beginner's questions.  my data sets 
contain multiple time series and look like

date   x   y
196211   12   1
196212   4   2
196301   44   5

so dataset <- read.table("data.dat", header=T); works well enough.  
tsdataset<- ts(dataset, freq=12, start=c(1962,11))  also seems to work.  
summary(tsdataset) and print(tsdataset) show that this operation did 
what I intended. 

* Alas, tsdataset$x no longer works.  how do I specify data series 
inside tsdataset now?

* Is there a time-series equivalent of read.table(), preferably allowing 
me to specify that the data column is the appropriate data in yyyymm format?

* For arguments sake, let's assume I want to do something with every 
variable in my data set.  for example, I want to convert every single 
data series into a time series.  "for (a in names(dataset)) a<-ts(a)" of 
course does not do what I want, because the destination is a vector 
named a, not a vector named by the contents of a.  I need sort of an 
eval.  similarly "for (a in names(dataset)) a<- uppercase-name(a)".   
Generically, how do I do something with every single series in a data 
set, and then assign it back to replace the old series within the data set?

* unrelated:  are there a push, pop, shift functions for vectors, ala perl?

* unrelated:  summary(vector) gives information in a row.  
summary(dataset) gives information in blocks.  can it be instructed to 
give information in rows, too?  where would I find documentation on 
issues like this?


sorry for all these questions.  help appreciated.

regards,

an R novice



From edd at debian.org  Sun May 18 19:56:25 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 18 May 2003 12:56:25 -0500
Subject: [R] TS data frames
In-Reply-To: <3EC7CF14.4020501@yale.edu>
References: <3EC7CF14.4020501@yale.edu>
Message-ID: <20030518175625.GA1828@sonny.eddelbuettel.com>

On Sun, May 18, 2003 at 02:21:08PM -0400, Welch, Ivo wrote:
> 
> hi chaps:  apologies, more naive beginner's questions.  my data sets 
> contain multiple time series and look like
> 
> date   x   y
> 196211   12   1
> 196212   4   2
> 196301   44   5
> 
> so dataset <- read.table("data.dat", header=T); works well enough.  
> tsdataset<- ts(dataset, freq=12, start=c(1962,11))  also seems to work.  
> summary(tsdataset) and print(tsdataset) show that this operation did 
> what I intended. 
> 
> * Alas, tsdataset$x no longer works.  how do I specify data series 
> inside tsdataset now?

tsdataset[,"x"]

> * Is there a time-series equivalent of read.table(), preferably allowing 
> me to specify that the data column is the appropriate data in yyyymm format?

No, just write yourself a simple wrapper doing read.table() and then ts()
creation.

> * For arguments sake, let's assume I want to do something with every 
> variable in my data set.  for example, I want to convert every single 
> data series into a time series.  "for (a in names(dataset)) a<-ts(a)" of 
> course does not do what I want, because the destination is a vector 
> named a, not a vector named by the contents of a.  I need sort of an 
> eval.  similarly "for (a in names(dataset)) a<- uppercase-name(a)".   
> Generically, how do I do something with every single series in a data 
> set, and then assign it back to replace the old series within the data set?

I am sure there are more elegant ways to do it, I typically just assign to
list elements:

for (i in 1:length(names(dataset)))
  a[[i]] <- ts(dataset[i])

> * unrelated:  are there a push, pop, shift functions for vectors, ala perl?

AFAIK not in base, you could emulate it, though. I needed something similar
recently and just hid it inside a list, and in- and decremented a hidden
index counter.

> * unrelated:  summary(vector) gives information in a row.  
> summary(dataset) gives information in blocks.  can it be instructed to 
> give information in rows, too?  where would I find documentation on 
> issues like this?

How about the code?  Requires some familiarity with the S language, though.

> sorry for all these questions.  help appreciated.

My pleasure. Always nice to see other financial economists around here :)

Regards,  Dirk

-- 
Don't drink and derive. Alcohol and analysis don't mix.



From perkinsm at bway.net  Sun May 18 20:10:48 2003
From: perkinsm at bway.net (Mark E. Perkins)
Date: Sun, 18 May 2003 14:10:48 -0400
Subject: [R] problem building dvi and pdf documentation on Darwin 10.2.6
In-Reply-To: <x24r3ti89j.fsf@biostat.ku.dk>
References: <2147483647.1053182409@[192.168.187.8]>
	<x24r3ti89j.fsf@biostat.ku.dk>
Message-ID: <2147483647.1053267048@[192.168.187.8]>

--On Saturday, May 17, 2003 23:16 +0200 Peter Dalgaard BSA
<p.dalgaard at biostat.ku.dk> wrote:

> "Mark E. Perkins" <perkinsm at bway.net> writes:

<snip>

>> Transcript written on R-FAQ.log.
>> ../../bin/texi2dvi: tex exited with bad status, quitting.
>> ../../bin/texi2dvi: see R-FAQ.log for errors.
> 
> It might be informative to take that hint since the log files are
> somewhat more verbose about exactly what is going on. 
> 
> It's not your texinfo version -- mine is exactly the same. However,
> there are probably very few people running teTeX 2.x so there could be
> an obscure installation problem with that.
> 
> It looks like your troubles begin where TeX is supposed to be
> processing R-FAQ.aux. It can happen that TeX gets wedged when there's a
> problem with that so you could try deleting it.

I should have mentioned that I had looked at the log file, but that it
really hadn't helped me any in terms of understanding the problem....

I *have* discovered that there is a problem with the index files. Running,
for example, 'make R-FAQ.dvi' in ..../manuals fails as noted previously.
The Makefile basically runs texi2dvi (with one argument), so if I try to
accomplish the same thing by hand and run

        tex R-FAQ.texi && texindex R-FAQ.?? && tex R-FAQ.texi ...etc

I get R-FAQ.dvi with table of contents (but note that R-FAQ does not build
an index). OTOH, if I do the same thing for R-admin (or any of the others),
texindex complains:

        texindex: R-admin.cp: not a texinfo index file
        Segmentation fault

If I make R-admin.cp a zero-byte file, I see the same result, but complaint
is about R-admin.vr. So it appears (to my TeX-deficient brain) as if tex
may be doing something funny with to the intermediate index files. On the
off chance that teTeX 2.0.2 is the problem, I built TeX from the web2c
distribution. I get the same result, but both are, in fact the same version
of TeX, i.e., both report:

-> cd proper-directory && ./tex --version
TeX (Web2C 7.4.5) 3.14159
kpathsea version 3.4.5
etc

texindex from fink and texindex from the Darwin installation are both

-> cd proper-directory && ./texindex --version
texindex (GNU texinfo) 4.2
etc

Lastly, here is R-admin.cp in its entirety (which looks like TeX stuff to
my untrained eye, and R-admin.vr is similar):

\entry{Obtaining R}{1}{Obtaining R}
\entry{Sources for R}{1}{Sources for R}
\entry{Installing under Unix}{2}{Installing under Unix}
\entry{Linux}{2}{Linux}
\entry{MacOS X}{2}{MacOS X}
\entry{Help pages}{3}{Help pages}
\entry{Manuals}{3}{Manuals}
\entry{Installation}{3}{Installation}
\entry{Manuals, installing}{4}{Manuals, installing}
\entry{Installing under Windows}{5}{Installing under Windows}
\entry{Installing under MacOS}{6}{Installing under MacOS}
\entry{MacOS X}{6}{MacOS X}
\entry{Packages}{7}{Packages}
\entry{Packages, installing}{7}{Packages, installing}
\entry{Packages, updating}{8}{Packages, updating}
\entry{Packages, removing}{8}{Packages, removing}
\entry{BLAS library}{10}{BLAS library}
\entry{LAPACK library}{10}{LAPACK library}
\entry{FORTRAN}{13}{FORTRAN}
\entry{BLAS library}{14}{BLAS library}
\entry{MacOS X}{16}{MacOS X}
\entry{BLAS library}{16}{BLAS library}
\entry{LAPACK library}{16}{LAPACK library}
\entry{Solaris}{16}{Solaris}
\entry{BLAS library}{17}{BLAS library}
\entry{LAPACK library}{17}{LAPACK library}
\entry{HP-UX}{17}{HP-UX}
\entry{IRIS}{18}{IRIS}
\entry{AIX}{19}{AIX}


Once again, any pointers will be appreciated. I can't find older versions
of teTeX and web2c for Darwin to see if I can pinpoint the problem to my
"new" version of TeX.

Thanks,
Mark Perkins
perkinsm at bway.net



From pburns at pburns.seanet.com  Sun May 18 21:41:02 2003
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Sun, 18 May 2003 20:41:02 +0100
Subject: [R] POP Portfolio Optimizer
Message-ID: <3EC7E1CE.8090605@pburns.seanet.com>

Burns Statistics has just released its POP Portfolio Optimizer, which
is available for a license fee.  This has an interface designed to run
under either S-PLUS or R.

In addition to portfolio selection and asset allocation, there is 
functionality
to generate random portfolios, and to estimate statistical factor models.

The website includes a new working paper on the best approach to
using statistical factor models to optimize portfolios with a benchmark.

Details are on http://www.burns-stat.com/

Patrick Burns

Burns Statistics
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")



From deepayan at stat.wisc.edu  Sun May 18 23:49:25 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Sun, 18 May 2003 16:49:25 -0500
Subject: [R] log scale y axis ticks control?
In-Reply-To: <20030518092806.GA27846@prp0.prp.physik.tu-darmstadt.de>
References: <20030518092806.GA27846@prp0.prp.physik.tu-darmstadt.de>
Message-ID: <200305181649.25641.deepayan@stat.wisc.edu>

On Sunday 18 May 2003 04:28, Sebastian Weber wrote:
> Hello R Users!
>
> I'm using lattice to produce some graphs with logaritmic y-scales. I use
> the command
>
> xyplot(hits ~ c(1:1024), data=eichData, type="S", scales=list(y =
> list(log=10)))
>
> to create the plot. This is fine, except for the automatically choosen
> tick marks. I'd like to have a major tick at the 10^n location and minor
> ticks in between which correspond with the native variable. To get this
> working I have to use at and label like
>
> labl <- rep("", 30)
> labl[1] <- "1"; labl[10] <- "10"; labl[19] <- "100"; labl[28] <- "1000";
> nums <- c(1:10, seq(20,100, 10), seq(200, 1000, 100))
> xyplot(hits ~ c(1:1024), data=eichData, type="S", scales=list(y =
> list(log=10, at=nums, labels=labl)))
>
> But this definitely extremly clumsy. There has to be an easier way to do
> it which I haven't found yet.

No, there's no easier way (mainly because I couldn't think of an easy way to 
code this). If you can suggest a general algorithm I would be happy to 
incorporate it. 

> Another nifty feature would be mixing these two axis styles. One axis
> with linear ticks (10^0, 10^0.5, 10^1, ...) and the other axis with tick
> marks as indicated above.

You mean different ticks/labels on the left and right sides of the panel ? I'm 
afraid that would be difficult to implement under the current setup. One 
alternative would be to do this inside the panel, in which case you could 
code it as part of the panel function.

Deepayan



From r_stuff_online at hotmail.com  Mon May 19 00:11:11 2003
From: r_stuff_online at hotmail.com (Neil Osborne)
Date: Sun, 18 May 2003 22:11:11 +0000
Subject: [R] How to split a dataframe into smaller constituent dataframes
Message-ID: <Law12-F62gRzpPWywCP00029bf5@hotmail.com>

I have read a large dataset into a dataframe using RODBC, the rows of data 
in the dataframe are (integer) timestamped and I would like to divide the 
original dataframe into n smaller dataframes where dataframe 1 contains all 
rows that had timestamps falling in the period 0-x1 minutes, dataframe 2 
contains all rows that had timestamps falling between x1+1 and x2, etc.. 
Does anyone know how to do this?


Thanks

_________________________________________________________________
Overloaded with spam? With MSN 8, you can filter it out 
http://join.msn.com/?page=features/junkmail&pgmarket=en-gb&XAPID=32&DI=1059



From edd at debian.org  Mon May 19 00:27:41 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 18 May 2003 17:27:41 -0500
Subject: [R] How to split a dataframe into smaller constituent dataframes
In-Reply-To: <Law12-F62gRzpPWywCP00029bf5@hotmail.com>
References: <Law12-F62gRzpPWywCP00029bf5@hotmail.com>
Message-ID: <20030518222741.GA3923@sonny.eddelbuettel.com>

On Sun, May 18, 2003 at 10:11:11PM +0000, Neil Osborne wrote:
> I have read a large dataset into a dataframe using RODBC, the rows of data 
> in the dataframe are (integer) timestamped and I would like to divide the 
> original dataframe into n smaller dataframes where dataframe 1 contains all 
> rows that had timestamps falling in the period 0-x1 minutes, dataframe 2 
> contains all rows that had timestamps falling between x1+1 and x2, etc.. 
> Does anyone know how to do this?

I would convert all your dates to DateTimeClass (i.e. POSIXct or POSIXlt),
e.g. using strptime, and then loop over them doing your subsetting at each
grid step you specify.  R really has excellent facilities to compute on, or
compare, dates up to Unix timestamp precision.

Alternatively, if the data lives in a DBMS you could simply tailor your
queries to the desired grid sizes and retrieve individual chunks and store
those.

Hth, Dirk

-- 
Don't drink and derive. Alcohol and analysis don't mix.



From eairoldi at stat.cmu.edu  Mon May 19 00:43:38 2003
From: eairoldi at stat.cmu.edu (Edoardo M Airoldi)
Date: Sun, 18 May 2003 18:43:38 -0400 (EDT)
Subject: [R] Fisher LDA and prior=c(...) argument
Message-ID: <Pine.LNX.4.44.0305181835000.29981-100000@hydra8.stat.cmu.edu>

hello,
 I am using LDA and QDA function of MASS library.  I understand Fisher LDA 
is a method non-probabilistic in nature, so I wonder what happens when I 
try to predict my test set examples as in:

> fit <- lda(labels~., data=train.table, prior=c(.5,.5))
> pred <- predict(fit, data=test.table, prior=c(.5,.5))

 Specifically I ask this because in my problem there are 700 examples 
class A, and 50 in class B, and I'd be glad to use a way to weight the 
contribution of the examples in different classes.
 My guess is that the CODE above estimates the likelihood of of the Fisher 
scores for (example | class) and then implements the Bayes rule to return 
the maximum a-posteriori class.

 Is that correct?  Any pointer towards that direction is appreciated.  
Please cc to edo at stat.cmu.edu your reply.
Thanks

Edoardo M. Airoldi
http://www.stat.cmu.edu/~eairoldi
BH 232L  (412) 268.7829
PC Lab   (412) 268.8719



From eairoldi at stat.cmu.edu  Mon May 19 00:59:27 2003
From: eairoldi at stat.cmu.edu (Edoardo M Airoldi)
Date: Sun, 18 May 2003 18:59:27 -0400 (EDT)
Subject: Follow-up: [R] Fisher LDA and prior=c(...) argument
In-Reply-To: <Pine.LNX.4.44.0305181835000.29981-100000@hydra8.stat.cmu.edu>
Message-ID: <Pine.LNX.4.44.0305181853470.29981-100000@hydra8.stat.cmu.edu>

hello,
 a clarification.

  I am using LDA and QDA function of MASS library.  I understand Fisher
LDA is a method non-probabilistic in nature, so I wonder what happens when
I try to predict my test set examples as in:
 
> fit <- lda(labels~., data=train.table, prior=c(.5,.5))
> pred <- predict(fit, data=test.table, prior=c(.5,.5))
  
  Specifically I ask this because in my problem there are 700 examples
class A, and 50 in class B, and I'd be glad to use a way to weight the
contribution of the examples in different classes (in the prediction
stage for LDA I guess)

  My guess is that the CODE above estimates the likelihood of 'the
projection of the data onto the canonical variate' (only one with 2
classes) as in:  P(example | class=.)  and then implements the Bayes
rule to return the maximum a-posteriori class, using the estimated 
likelihood and the given prior=c(...)
  
  Is that correct?  Any pointer towards the understanding is appreciated.

  Further any pointer towards an example that uses the argument CV=TRUE is 
also appreciated, since i was not able (apparently) to get any change by 
setting it to TRUE  =:-)

Edoardo M. Airoldi
http://www.stat.cmu.edu/~eairoldi
BH 232L  (412) 268.7829
PC Lab   (412) 268.8719



From djbrown at montana.edu  Mon May 19 02:03:29 2003
From: djbrown at montana.edu (Brown, David)
Date: Sun, 18 May 2003 18:03:29 -0600
Subject: [R] Confidence intervals for gls models?
Message-ID: <95AC7052DE4A78488DCFB615F7A49EA407A236BF@jewels.msu.montana.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030518/898e2ef9/attachment.pl

From ivo.welch at yale.edu  Sun May 18 18:15:08 2003
From: ivo.welch at yale.edu (Welch, Ivo)
Date: Sun, 18 May 2003 12:15:08 -0400
Subject: [R] irregular ts plot?
Message-ID: <3EC7B18C.2060504@yale.edu>

hi guys:  sorry, one more.  I have irregularly spaced time series, often
with big gaps.  a good analogy is:

	tsvec <- ts(c(1,NA,2,NA,1, NA, 2),freq=12, start=c(1965,12))

Unfortunately, plot( tsvec ) does not plot the data.  is it possible to
convince plot to just ignore the NA items (either with points or lines)

help appreciated.

/iaw



From edgar at cs.uprm.edu  Mon May 19 03:16:33 2003
From: edgar at cs.uprm.edu (Edgar Acuna)
Date: Sun, 18 May 2003 21:16:33 -0400 (EDT)
Subject: Follow-up: [R] Fisher LDA and prior=c(...) argument
In-Reply-To: <Pine.LNX.4.44.0305181853470.29981-100000@hydra8.stat.cmu.edu>
Message-ID: <Pine.GSO.4.33.0305182106040.12916-100000@cs.uprm.edu>


Hello,

If you don not use the option prior in lda then the priors  are estimated
proportionally to the size of each class. If you do not use the option
prior in predict.lda then they are taken from the lda object. Otherwise
you can use any numbers in the vector of priors the only condition is that
they add up one.

The CV option of lda refers to the leave-out-out method. Several people
use n-fold CV. I wrote an R function to compute 10-fold CV for lda. Look
at :
math.uprm.edu/~edgar/CV10LDA.TXT

Regards,

Edgar Acuna

On Sun, 18 May 2003, Edoardo M Airoldi wrote:

> hello,
>  a clarification.
>
>   I am using LDA and QDA function of MASS library.  I understand Fisher
> LDA is a method non-probabilistic in nature, so I wonder what happens when
> I try to predict my test set examples as in:
>
> > fit <- lda(labels~., data=train.table, prior=c(.5,.5))
> > pred <- predict(fit, data=test.table, prior=c(.5,.5))
>
>   Specifically I ask this because in my problem there are 700 examples
> class A, and 50 in class B, and I'd be glad to use a way to weight the
> contribution of the examples in different classes (in the prediction
> stage for LDA I guess)
>
>   My guess is that the CODE above estimates the likelihood of 'the
> projection of the data onto the canonical variate' (only one with 2
> classes) as in:  P(example | class=.)  and then implements the Bayes
> rule to return the maximum a-posteriori class, using the estimated
> likelihood and the given prior=c(...)
>
>   Is that correct?  Any pointer towards the understanding is appreciated.
>
>   Further any pointer towards an example that uses the argument CV=TRUE is
> also appreciated, since i was not able (apparently) to get any change by
> setting it to TRUE  =:-)
>
> Edoardo M. Airoldi
> http://www.stat.cmu.edu/~eairoldi
> BH 232L  (412) 268.7829
> PC Lab   (412) 268.8719
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From spencer.graves at pdf.com  Mon May 19 05:09:00 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 18 May 2003 20:09:00 -0700
Subject: [R] Confidence intervals for gls models?
References: <95AC7052DE4A78488DCFB615F7A49EA407A236BF@jewels.msu.montana.edu>
Message-ID: <3EC84ACC.5060405@pdf.com>

What about the obvious:

tstDf <- data.frame(x=1:9, y=rnorm(9), w=1:9)
fit <- lm(y~x, tstDf, weights=w)
pred <- predict(fit, se.fit=T)
pred$fit + outer(pred$se.fit, c(-2, 2))

"predict.lm" might need weights for interval="prediction" with newdata, 
but not with interval="confidence" ... or am I missing something?

hth.  spencer graves

Brown, David wrote:
> Is there an easy way to compute confidence intervals (or prediction
> intervals) for gls models?
> 
> E.g. for standard linear models, with the predict.lm function, we can set
> interval="confidence" , level = 0.95 and type="response".
> 
> Thanks in advance!
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Mon May 19 08:28:28 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 19 May 2003 07:28:28 +0100 (BST)
Subject: Follow-up: [R] Fisher LDA and prior=c(...) argument
In-Reply-To: <Pine.LNX.4.44.0305181853470.29981-100000@hydra8.stat.cmu.edu>
Message-ID: <Pine.LNX.4.44.0305190722270.29532-100000@gannet.stats>

MASS the package provides suport for MASS the book.  See the latter for 
the details, also my book

Ripley, B. D. (1996) Pattern Recognition and Neural Networks. CUP

which explains leave-one-out CV and has the formulae.

Someone else mention n-fold CV.  That, including S code and examples, is 
in the MASS book and its scripts are in the MASS package.

Please do not ignore the DESCRIPTION files of a package:
library(help=MASS) says

Description:

Package: MASS
Description: The main library.
Title: Main Library of Venables and Ripley's MASS
...
BundleDescription: Various functions from the software of Venables and
        Ripley, `Modern Applied Statistics with S' (4th edition).



On Sun, 18 May 2003, Edoardo M Airoldi wrote:

> hello,
>  a clarification.
> 
>   I am using LDA and QDA function of MASS library.  I understand Fisher
> LDA is a method non-probabilistic in nature, so I wonder what happens when

Who mentioned Fisher LDA?  Fisher is not mentioned on the help page, and 
what is usually called LDA is not due to Fisher.

> I try to predict my test set examples as in:
>  
> > fit <- lda(labels~., data=train.table, prior=c(.5,.5))
> > pred <- predict(fit, data=test.table, prior=c(.5,.5))
>   
>   Specifically I ask this because in my problem there are 700 examples
> class A, and 50 in class B, and I'd be glad to use a way to weight the
> contribution of the examples in different classes (in the prediction
> stage for LDA I guess)
> 
>   My guess is that the CODE above estimates the likelihood of 'the
> projection of the data onto the canonical variate' (only one with 2
> classes) as in:  P(example | class=.)  and then implements the Bayes
> rule to return the maximum a-posteriori class, using the estimated 
> likelihood and the given prior=c(...)
>   
>   Is that correct?  Any pointer towards the understanding is appreciated.
> 
>   Further any pointer towards an example that uses the argument CV=TRUE is 
> also appreciated, since i was not able (apparently) to get any change by 
> setting it to TRUE  =:-)
> 
> Edoardo M. Airoldi
> http://www.stat.cmu.edu/~eairoldi
> BH 232L  (412) 268.7829
> PC Lab   (412) 268.8719
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon May 19 08:52:58 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 19 May 2003 07:52:58 +0100 (BST)
Subject: [R] irregular ts plot?
In-Reply-To: <3EC7B18C.2060504@yale.edu>
Message-ID: <Pine.LNX.4.44.0305190750030.29570-100000@gannet.stats>

On Sun, 18 May 2003, Welch, Ivo wrote:

> hi guys:  sorry, one more.  I have irregularly spaced time series, often
> with big gaps.  a good analogy is:
> 
> 	tsvec <- ts(c(1,NA,2,NA,1, NA, 2),freq=12, start=c(1965,12))
> 
> Unfortunately, plot( tsvec ) does not plot the data.  is it possible to
> convince plot to just ignore the NA items (either with points or lines)

It does with type="p" or type="b".  As every other point is missing in 
your example, there are no non-missing segments to plot with type="l" (the 
default).

If you don't want the missing points noticed, don't use ts() which is
designed for regular times series.  (I believe that package tseries has
the beginnings of support for irregular series in recent versions.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon May 19 08:58:07 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 19 May 2003 07:58:07 +0100 (BST)
Subject: [R] Confidence intervals for gls models?
In-Reply-To: <3EC84ACC.5060405@pdf.com>
Message-ID: <Pine.LNX.4.44.0305190753420.29570-100000@gannet.stats>

On Sun, 18 May 2003, Spencer Graves wrote:

> What about the obvious:
> 
> tstDf <- data.frame(x=1:9, y=rnorm(9), w=1:9)
> fit <- lm(y~x, tstDf, weights=w)
> pred <- predict(fit, se.fit=T)
> pred$fit + outer(pred$se.fit, c(-2, 2))
> 
> "predict.lm" might need weights for interval="prediction" with newdata, 
> but not with interval="confidence" ... or am I missing something?

That's weighted least squares, not generalized least squares.

predict.gls does not have an `se.fit' argument.

Howver, lm.gls in package MASS will do the trick at the existing data 
points.  (To predict at newdata you would need to have a model for the 
covariance matrix, and once you have that you are doing time series or 
kriging or ... and there are many other possibilities.)

> 
> hth.  spencer graves
> 
> Brown, David wrote:
> > Is there an easy way to compute confidence intervals (or prediction
> > intervals) for gls models?
> > 
> > E.g. for standard linear models, with the predict.lm function, we can set
> > interval="confidence" , level = 0.95 and type="response".

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mikael.niva at ebc.uu.se  Mon May 19 10:30:33 2003
From: mikael.niva at ebc.uu.se (Mikael Niva)
Date: Mon, 19 May 2003 10:30:33 +0200
Subject: [R] Syntax for random effect in glmmPQL
Message-ID: <000a01c31de0$e9ee6360$3d9aee82@uu.se.vaxtbio>

Dear R-listers

I wonder if someone can help me with the syntax for the random effect in
glmmPQL()? I have a data set with a response variable "y" (counts), two
dependent variables: "treat" (4 levels) and "site" (2 levels). The
latter, I want to use as a random variable. How do I specify this in the
function?

Is it like this: glmmPQL(y~treat,random=~1|site,family=poisson,
data=mydata)? What does the ~1 do?

Thanks in advance, Mikael Niva

********************************************
Mikael Niva
Avd. f?r V?xtekologi, Dept. of Plant Ecology 
EBC
Uppsala Universitet



From ripley at stats.ox.ac.uk  Mon May 19 11:23:59 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 19 May 2003 10:23:59 +0100 (BST)
Subject: [R] Syntax for random effect in glmmPQL
In-Reply-To: <000a01c31de0$e9ee6360$3d9aee82@uu.se.vaxtbio>
Message-ID: <Pine.LNX.4.44.0305191014560.29990-100000@gannet.stats>

It is the same syntax as for lme.

I think you meant two *independent* variables.  I don't see the point of
treating a factor with two levels as a random effect: you don't really
expect to estimate a population from just two samples, do you?  If (as I
suspect) the sites are blocking factors they should be treated as fixed
effects (just as randomized block designs are analysed), or if you are
interested in the population of sites you should get several more.

A pedagogical hint to R-help readers:

You don't just have a data set:  you have an experiment or an
observational study you want to analyse.  If you had described the latter,
we might have been able to do better than guess at what you meant.

On Mon, 19 May 2003, Mikael Niva wrote:

> Dear R-listers
> 
> I wonder if someone can help me with the syntax for the random effect in
> glmmPQL()? I have a data set with a response variable "y" (counts), two
> dependent variables: "treat" (4 levels) and "site" (2 levels). The
> latter, I want to use as a random variable. How do I specify this in the
> function?
> 
> Is it like this: glmmPQL(y~treat,random=~1|site,family=poisson,
> data=mydata)? What does the ~1 do?

That gives you a random intercept by site.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From kwan022 at stat.auckland.ac.nz  Mon May 19 11:31:27 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Mon, 19 May 2003 21:31:27 +1200 (NZST)
Subject: [R] To update() or not to update()?
Message-ID: <Pine.LNX.4.44.0305192126140.14853-100000@stat61.stat.auckland.ac.nz>

Hi,

Suppose I have:
  # Fit a base model
  d1.ph <- coxph(Surv(start, stop, event)~
               ejec + diavol + score + smoking +
               beta + surg.done,
               data = data.frame(foo))

  summary(update(d1.ph, . ~ . + td1))
  summary(update(d1.ph, . ~ . + td2)) 

As I have many columns in my data frame, foo, called td's.  e.g. td1, td2, 
td3, ....  And I'd like to add one column each time.  What is the 
recommended way to do this?  Whether I should do what I did above, or 
should I do something like:
  td1.ph <- coxph(Surv(start, stop, event)~
                ejec + diavol + score + smoking + 
                beta + surg.done + td1,
                data = data.frame(foo)) 

  td2.ph <- coxph(Surv(start, stop, event)~
                ejec + diavol + score + smoking + 
                beta + surg.done + td2,
                data = data.frame(foo))  

I've done a system.time() on it and update() doesn't seem to be much (if 
at all) faster.  Is there an advantage of using update() then (other than 
that the codes look neater)?


-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)



From Stefan.Strecker at iw.uni-karlsruhe.de  Mon May 19 11:42:09 2003
From: Stefan.Strecker at iw.uni-karlsruhe.de (Strecker, Stefan)
Date: Mon, 19 May 2003 11:42:09 +0200
Subject: [R] Line plots with different symbols on the same line
Message-ID: <D5F4FCB34ECBC041992A289145E3FD662F2139@ibwsrvp2.iw.uni-karlsruhe.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030519/6f4f7417/attachment.pl

From ripley at stats.ox.ac.uk  Mon May 19 11:44:33 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 19 May 2003 10:44:33 +0100 (BST)
Subject: [R] To update() or not to update()?
In-Reply-To: <Pine.LNX.4.44.0305192126140.14853-100000@stat61.stat.auckland.ac.nz>
Message-ID: <Pine.LNX.4.44.0305191042180.29990-100000@gannet.stats>

On Mon, 19 May 2003, Ko-Kang Kevin Wang wrote:

> Suppose I have:
>   # Fit a base model
>   d1.ph <- coxph(Surv(start, stop, event)~
>                ejec + diavol + score + smoking +
>                beta + surg.done,
>                data = data.frame(foo))
> 
>   summary(update(d1.ph, . ~ . + td1))
>   summary(update(d1.ph, . ~ . + td2)) 
> 
> As I have many columns in my data frame, foo, called td's.  e.g. td1, td2, 
> td3, ....  And I'd like to add one column each time.  What is the 
> recommended way to do this?  Whether I should do what I did above, or 
> should I do something like:
>   td1.ph <- coxph(Surv(start, stop, event)~
>                 ejec + diavol + score + smoking + 
>                 beta + surg.done + td1,
>                 data = data.frame(foo)) 
> 
>   td2.ph <- coxph(Surv(start, stop, event)~
>                 ejec + diavol + score + smoking + 
>                 beta + surg.done + td2,
>                 data = data.frame(foo))  
> 
> I've done a system.time() on it and update() doesn't seem to be much (if 
> at all) faster.  Is there an advantage of using update() then (other than 
> that the codes look neater)?

You are calling update.default on a coxph fit, so it is just neater.  It
need not be for other model-fitting classes.

BTW, addterm (MASS) would automate this for you, adding all the columns 
one at a time and collating the results.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Philippe.Hupe at curie.fr  Mon May 19 11:47:43 2003
From: Philippe.Hupe at curie.fr (=?ISO-8859-1?Q?Philippe_Hup=E9?=)
Date: Mon, 19 May 2003 11:47:43 +0200
Subject: [R] Line plots with different symbols on the same line
In-Reply-To: <D5F4FCB34ECBC041992A289145E3FD662F2139@ibwsrvp2.iw.uni-karlsruhe.de>
References: <D5F4FCB34ECBC041992A289145E3FD662F2139@ibwsrvp2.iw.uni-karlsruhe.de>
Message-ID: <3EC8A83F.7040800@curie.fr>

Strecker, Stefan a ?crit :

>Hello,
> 
>my data is an ordered list of observations where each observation is either of condition "efficient" (coded as 1) or "non-efficient" (0) as e.g.
> 
>No. Obs Condition
>1 1.1 0
>2 1.2 1
>3 1.4 1
>4 1.5 0
>5 2.5 1 
>etc.
> 
>My goal is to plot a single line with lty='o' but different symbols for either condition whenever condition is 1 or 0, i.e. on the x-axis the consecutive no. of observation is plotted with the obs on the y-axis as two different symbols (e.g. pch=1 and  pch=2). 
> 
>Is there any way to achieve this?
> 
>Thanks in advance
>Stefan
> 
> 
> 
> 
>
>	[[alternate HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>.
>
>  
>
plot(Obs, data=your_data_frame, pch=c("*","+")[as.factor(Condition)])
see pch for details of symbols available
hope this helps.

Philippe

-- 

--------------------------------------------------

Philippe Hup?
Institut Curie - Equipe Bioinformatique
26, rue d'Ulm - 75005 PARIS France
+33 (0)1 42 34 65 29

Philippe.Hupe at curie.fr <mailto:Philippe.Hupe at curie.fr>



From vito.muggeo at giustizia.it  Mon May 19 11:57:30 2003
From: vito.muggeo at giustizia.it (vito muggeo)
Date: Mon, 19 May 2003 11:57:30 +0200
Subject: [R] To update() or not to update()?
References: <Pine.LNX.4.44.0305192126140.14853-100000@stat61.stat.auckland.ac.nz>
Message-ID: <005801c31ded$14400360$5c13070a@it.giustizia.it>

Hi Kevin,
Here there is a possible solution

Extract from the base model the response, the design matrix, (possible)
strata,....Note: fit it with argument x=T and y=T
    o<-list()
    X0<-d1.ph $x
    Y<-d1.ph $y
stra<-d1.ph $strata
....
    for(i in ....){ #what are the positions of "td" variables in the
dataframe?
            X<-cbind(X0,X[,i])
            o[[length(o)+1]]<-
agreg.fit(X,Y,strata=stra,control=coxph.control(eps =
1e-04),init=rep(0,ncol(X)), method="efron",rownames=NULL))
                   }

o is a list with all the fitted models.
agreg.fit() is faster that coxph() (that uses agreg.fit). It is something
like glm() and glm.fit().

Hope this helps you.
best,
vito


----- Original Message -----
From: "Ko-Kang Kevin Wang" <kwan022 at stat.auckland.ac.nz>
To: "R Help" <r-help at stat.math.ethz.ch>
Sent: Monday, May 19, 2003 11:31 AM
Subject: [R] To update() or not to update()?


> Hi,
>
> Suppose I have:
>   # Fit a base model
>   d1.ph <- coxph(Surv(start, stop, event)~
>                ejec + diavol + score + smoking +
>                beta + surg.done,
>                data = data.frame(foo))
>
>   summary(update(d1.ph, . ~ . + td1))
>   summary(update(d1.ph, . ~ . + td2))
>
> As I have many columns in my data frame, foo, called td's.  e.g. td1, td2,
> td3, ....  And I'd like to add one column each time.  What is the
> recommended way to do this?  Whether I should do what I did above, or
> should I do something like:
>   td1.ph <- coxph(Surv(start, stop, event)~
>                 ejec + diavol + score + smoking +
>                 beta + surg.done + td1,
>                 data = data.frame(foo))
>
>   td2.ph <- coxph(Surv(start, stop, event)~
>                 ejec + diavol + score + smoking +
>                 beta + surg.done + td2,
>                 data = data.frame(foo))
>
> I've done a system.time() on it and update() doesn't seem to be much (if
> at all) faster.  Is there an advantage of using update() then (other than
> that the codes look neater)?
>
>
> --
> Cheers,
>
> Kevin
>
> --------------------------------------------------------------------------
----
> /* Time is the greatest teacher, unfortunately it kills its students */
>
> --
> Ko-Kang Kevin Wang
> Master of Science (MSc) Student
> SLC Tutor and Lab Demonstrator
> Department of Statistics
> University of Auckland
> New Zealand
> Homepage: http://www.stat.auckland.ac.nz/~kwan022
> Ph: 373-7599
>     x88475 (City)
>     x88480 (Tamaki)
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From laurent.faisnel at ariase.com  Mon May 19 12:43:02 2003
From: laurent.faisnel at ariase.com (Laurent Faisnel)
Date: Mon, 19 May 2003 12:43:02 +0200
Subject: [R] how to run R as a daemon
Message-ID: <3EC8B536.7040202@ariase.com>

Hi all,
Using R a as a real-time application called by Php for a website, I 
would like to run one R process only, which would manage user 
connections. For the time each user who asks for an analysis causes a 
new R process to start, which is not suitable in prevision of many 
users. R needs about 30 seconds to run the script which makes the 
analysis. The problem is that this waiting time is n times more 
important when n users ask for an analysis...
Thanks for any help.

Laurent



From John.Marsland at CommerzbankIB.com  Mon May 19 12:59:04 2003
From: John.Marsland at CommerzbankIB.com (Marsland, John)
Date: Mon, 19 May 2003 11:59:04 +0100
Subject: [R] how to run R as a daemon
Message-ID: <8CBAA121CEB4D5118CB200508BB2BBEF0317E75C@xmx8lonib.lonib.commerzbank.com>

Why not run R as a separate process using the RSOAP package.
You can then converse with R as a web service using the NuSOAP PHP class as
described in the case of the Amazon example below:
http://www.devshed.com/Server_Side/PHP/AmazonAPI/AmazonAPI1/page3.html

John Marsland

> -----Original Message-----
> From: Laurent Faisnel [mailto:laurent.faisnel at ariase.com]
> Sent: 19 May 2003 11:43
> To: r-help at stat.math.ethz.ch
> Subject: [R] how to run R as a daemon
> 
> 
> Hi all,
> Using R a as a real-time application called by Php for a website, I 
> would like to run one R process only, which would manage user 
> connections. For the time each user who asks for an analysis causes a 
> new R process to start, which is not suitable in prevision of many 
> users. R needs about 30 seconds to run the script which makes the 
> analysis. The problem is that this waiting time is n times more 
> important when n users ask for an analysis...
> Thanks for any help.
> 
> Laurent
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


********************************************************************** 
This is a commercial communication from Commerzbank AG.\ \ This ... {{dropped}}



From a_ahmed1 at starmedia.com  Mon May 19 12:59:36 2003
From: a_ahmed1 at starmedia.com (Aziz Ahmed)
Date: Mon, 19 May 2003 06:59:36 -0400
Subject: [R] confidencial
Message-ID: <20030519105932.1C2663BA798@smtp.latinmail.com>

Dear sir,

            Let me introduce myself , I am brother to Tariq Aziz , the deputy prime minister of Iraq , before the us led coalition war against my country. 
            I have been working for my brother for past 15 years. My brother have the sum of [46 million Dollars] with me ,which to be send to Europe which has been done 
already.
            I have decided to find somebody who can help me to
secure the money or establish the money in Europe.Actually my brother has more than that with me. 
            I don't want my identity to be exposed to outside the world, I am now hiding in Kuwait. 
            Please if you are interested in this deal or to be my partner please contact my lawyer through his E-mail address. 
            I know nothing goes for nothing we will be negotiating after 
you contact my lawyer This is my lawyer E-mail address.... mattarozzi_mirco at rediffmail.com

Thanks.
  
  Aziz.



_______________________________________________________________________________________________________
Obtn gratis tu cuenta de correo en StarMedia Email. Regstrate hoy mismo!. http://www.starmedia.com/email



From laurent.faisnel at ariase.com  Mon May 19 14:21:45 2003
From: laurent.faisnel at ariase.com (Laurent Faisnel)
Date: Mon, 19 May 2003 14:21:45 +0200
Subject: [R] how to run R as a daemon
References: <8CBAA121CEB4D5118CB200508BB2BBEF0317E75C@xmx8lonib.lonib.commerzbank.com>
Message-ID: <3EC8CC59.8010305@ariase.com>

I  just visited the link you gave me. One of the problems that could 
occur using NuSOAP is that I do not intend using Python. Thanks anyway. 
I would also like to ask more precise questions :
- is it possible to run R as a standalone service, which runs in 
background indefinitely, waiting for instructions ? This would be a 
great improvement for me, since each time it is launched R has to 
re-load a (constant) matrix generated thanks to a database connection 
(takes a very long while)
- my R script is object-oriented; I define classes and methods, but I'm 
not so sure about how methods should be declared; I usually write 
something like :

mymethod <- function(.Object) UseMethod("mymethod",.Object);

setMethod("mymethod","myclass",
        function(.Object)
        {
            # instructions
            return(.Object);
        }
        );

Perhaps is this not the best way to write methods ? Could this explain 
the following fact : when I run the script, R spends about 1/3 of its 
thinking time creating the generic functions linked with my methods. 
Isn't this wasted time ? The same script may be executed many times 
consecutively by different users, and each time R has to re-define the 
generic functions ! (are always the same)

I use R 1.6.2 on a Linux server (Red Hat - soon Debian)

Marsland, John wrote:

>Why not run R as a separate process using the RSOAP package.
>You can then converse with R as a web service using the NuSOAP PHP class as
>described in the case of the Amazon example below:
>http://www.devshed.com/Server_Side/PHP/AmazonAPI/AmazonAPI1/page3.html
>
>John Marsland
>
>  
>
>>-----Original Message-----
>>From: Laurent Faisnel [mailto:laurent.faisnel at ariase.com]
>>Sent: 19 May 2003 11:43
>>To: r-help at stat.math.ethz.ch
>>Subject: [R] how to run R as a daemon
>>
>>
>>Hi all,
>>Using R a as a real-time application called by Php for a website, I 
>>would like to run one R process only, which would manage user 
>>connections. For the time each user who asks for an analysis causes a 
>>new R process to start, which is not suitable in prevision of many 
>>users. R needs about 30 seconds to run the script which makes the 
>>analysis. The problem is that this waiting time is n times more 
>>important when n users ask for an analysis...
>>Thanks for any help.
>>
>>Laurent
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
>>    
>>
>
>
>********************************************************************** 
>This is a commercial communication from Commerzbank AG.
>
>This communication is confidential and is intended only for the person to
>whom it is addressed.  If you are not that person you are not permitted to
>make use of the information and you are requested to notify
><mailto:LONIB.Postmaster at commerzbankib.com> immediately that you have
>received it and then destroy the copy in your possession.
>
>Commerzbank AG may monitor outgoing and incoming e-mails. By replying to
>this e-mail you consent to such monitoring. This e-mail message and any
>attached files have been scanned for the presence of computer viruses.
>However, you are advised that you open attachments at your own risk.
>
>This email was sent either by Commerzbank AG, London Branch, or by
>Commerzbank Securities, a division of Commerzbank.  Commerzbank AG is a
>limited liability company incorporated in the Federal Republic of Germany.
>Registered Company Number in England BR001025. Our registered address in
>the UK is 23 Austin Friars, London, EC2P 2JD. We are regulated by the
>Financial Services Authority for the conduct of investment business in the
>UK and we appear on the FSA register under number 124920. 
>
>**********************************************************************
>
>
>  
>



From ripley at stats.ox.ac.uk  Mon May 19 14:48:15 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 19 May 2003 13:48:15 +0100 (BST)
Subject: [R] how to run R as a daemon
In-Reply-To: <3EC8CC59.8010305@ariase.com>
Message-ID: <Pine.LNX.4.44.0305191335050.30406-100000@gannet.stats>

On Mon, 19 May 2003, Laurent Faisnel wrote:

> I  just visited the link you gave me. One of the problems that could 
> occur using NuSOAP is that I do not intend using Python. Thanks anyway. 
> I would also like to ask more precise questions :

`more precise'?  At least some of the inefficiencies are emerging, but I
still have little picture of what you are actually trying to do.  It ought
to be possible to run a new R session in a well under a second (on a 1+GHz
machine):

gannet% time env R_DEFAULT_PACKAGES=NULL R --vanilla --slave < /dev/null
0.203u 0.039s 0:00.27 85.1%     0+0k 0+0io 1220pf+0w

for example (on a dual Athlon 2600, R 1.7.0).

> - is it possible to run R as a standalone service, which runs in 
> background indefinitely, waiting for instructions ? 

It is, but waiting for instructions from one place (stdin or on a socket).
There is some danger of different jobs sent leaving things behind that 
will cause interactions.

> This would be a 
> great improvement for me, since each time it is launched R has to 
> re-load a (constant) matrix generated thanks to a database connection 
> (takes a very long while)

You could just save and then load that matrix in your .RData

> - my R script is object-oriented; I define classes and methods, but I'm 
> not so sure about how methods should be declared; I usually write 
> something like :
> 
> mymethod <- function(.Object) UseMethod("mymethod",.Object);
> 
> setMethod("mymethod","myclass",
>         function(.Object)
>         {
>             # instructions
>             return(.Object);
>         }
>         );
> 
> Perhaps is this not the best way to write methods ? Could this explain 
> the following fact : when I run the script, R spends about 1/3 of its 
> thinking time creating the generic functions linked with my methods. 
> Isn't this wasted time ? The same script may be executed many times 
> consecutively by different users, and each time R has to re-define the 
> generic functions ! (are always the same)

Yes, but it is your usage that is the problem.  You are mixing S3 and S4
methods (where did you copy an example like that from?).  You should
dump your scripts if you use S4 methods (which I don't think you should be
doing in such simple examples, nor if you care about speed):  see the
examples of S4-using packages on CRAN (e.g. DBI, SparseM).

Also consider upgrading to R 1.7.0 and setting R_DEFAULT_PACKAGES to what 
you actually need (and omit methods if you don't need it)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Andre.Dos.Anjos at cern.ch  Mon May 19 14:58:07 2003
From: Andre.Dos.Anjos at cern.ch (Andre DOS ANJOS)
Date: Mon, 19 May 2003 14:58:07 +0200 (CEST)
Subject: [R] R doesn't support 3D histograms?
Message-ID: <Pine.LNX.4.44.0305191452450.18816-200000@pcatd37.cern.ch>

Hi,

	I've been using R since a while now to make 2D histograms. I have 
some data (appended) that would like to use to make a 3-D plot with x being 
the first variable in the file, y the second and the height, or z the third
variable. How can I do it in R? I would like to have 3-D visualization of 
this plot. Preferably as a lego plot, that is, a set of stacks that grow 
with respect to the value of z, which have their delta x and delta y lengths 
equivalent to the spacings between the values of x and y. Other people also 
call it a 3-D histogram.

	Regards, Andre.

-- 
Andre Rabello DOS ANJOS, M.Sc.
Signal Processing, Data Analysis and Computing
Office: 32-2-A06, Tel: (+ 41 22) 767 5022
Fax: (+ 41 22) 767 8420
CERN - EP/HC Division
CH-1211 Geneve 23 - Suisse/Switzerland
http://cern.ch/rabello
Public GPG key at http://www.keyserver.net
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: request-sizes.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030519/4702f38f/request-sizes.txt

From John.Marsland at CommerzbankIB.com  Mon May 19 15:29:53 2003
From: John.Marsland at CommerzbankIB.com (Marsland, John)
Date: Mon, 19 May 2003 14:29:53 +0100
Subject: [R] how to run R as a daemon
Message-ID: <8CBAA121CEB4D5118CB200508BB2BBEF0317E75E@xmx8lonib.lonib.commerzbank.com>

As far as I am aware NuSOAP is pure PHP and not based on Python.
The RSOAP server is based on Python. 
My understanding is that, if you want your R server to have some sort of
longevity and manage lots of competing incoming requests or possibly to keep
a session for one user over time, you will need to embed R into something
capable of doing this. It could be a queue of some description or a database
(there's an example using Postgres on the omegahat site) or a server of some
sort (RSOAP uses python here for the things R doesn't have). You could even
embed R in a PHP or an apache module, but as far as I am aware these don't
yet exist yet and would require a fair bit of programming.
R doesn't have an queue manager, but you could just leave R monitoring a
port or a stdin and just refuse requests while the R session is busy - you
run the risk of failing to satisfy some  of your web requests.

John Marsland

> -----Original Message-----
> From: Laurent Faisnel [mailto:laurent.faisnel at ariase.com]
> Sent: 19 May 2003 13:22
> To: Marsland, John
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] how to run R as a daemon
> 
> 
> I  just visited the link you gave me. One of the problems that could 
> occur using NuSOAP is that I do not intend using Python. 
> Thanks anyway. 
> I would also like to ask more precise questions :
> - is it possible to run R as a standalone service, which runs in 
> background indefinitely, waiting for instructions ? This would be a 
> great improvement for me, since each time it is launched R has to 
> re-load a (constant) matrix generated thanks to a database connection 
> (takes a very long while)
> - my R script is object-oriented; I define classes and 
> methods, but I'm 
> not so sure about how methods should be declared; I usually write 
> something like :
> 
> mymethod <- function(.Object) UseMethod("mymethod",.Object);
> 
> setMethod("mymethod","myclass",
>         function(.Object)
>         {
>             # instructions
>             return(.Object);
>         }
>         );
> 
> Perhaps is this not the best way to write methods ? Could 
> this explain 
> the following fact : when I run the script, R spends about 1/3 of its 
> thinking time creating the generic functions linked with my methods. 
> Isn't this wasted time ? The same script may be executed many times 
> consecutively by different users, and each time R has to 
> re-define the 
> generic functions ! (are always the same)
> 
> I use R 1.6.2 on a Linux server (Red Hat - soon Debian)
> 
> Marsland, John wrote:
> 
> >Why not run R as a separate process using the RSOAP package.
> >You can then converse with R as a web service using the 
> NuSOAP PHP class as
> >described in the case of the Amazon example below:
> >http://www.devshed.com/Server_Side/PHP/AmazonAPI/AmazonAPI1/page3.html
> >
> >John Marsland
> >
> >  
> >
> >>-----Original Message-----
> >>From: Laurent Faisnel [mailto:laurent.faisnel at ariase.com]
> >>Sent: 19 May 2003 11:43
> >>To: r-help at stat.math.ethz.ch
> >>Subject: [R] how to run R as a daemon
> >>
> >>
> >>Hi all,
> >>Using R a as a real-time application called by Php for a website, I 
> >>would like to run one R process only, which would manage user 
> >>connections. For the time each user who asks for an 
> analysis causes a 
> >>new R process to start, which is not suitable in prevision of many 
> >>users. R needs about 30 seconds to run the script which makes the 
> >>analysis. The problem is that this waiting time is n times more 
> >>important when n users ask for an analysis...
> >>Thanks for any help.
> >>
> >>Laurent
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >>
> >>    
> >>
> >
> >
> >*************************************************************
> ********* 
> >This is a commercial communication from Commerzbank AG.
> >
> >This communication is confidential and is intended only for 
> the person to
> >whom it is addressed.  If you are not that person you are 
> not permitted to
> >make use of the information and you are requested to notify
> ><mailto:LONIB.Postmaster at commerzbankib.com> immediately that you have
> >received it and then destroy the copy in your possession.
> >
> >Commerzbank AG may monitor outgoing and incoming e-mails. By 
> replying to
> >this e-mail you consent to such monitoring. This e-mail 
> message and any
> >attached files have been scanned for the presence of 
> computer viruses.
> >However, you are advised that you open attachments at your own risk.
> >
> >This email was sent either by Commerzbank AG, London Branch, or by
> >Commerzbank Securities, a division of Commerzbank.  
> Commerzbank AG is a
> >limited liability company incorporated in the Federal 
> Republic of Germany.
> >Registered Company Number in England BR001025. Our 
> registered address in
> >the UK is 23 Austin Friars, London, EC2P 2JD. We are regulated by the
> >Financial Services Authority for the conduct of investment 
> business in the
> >UK and we appear on the FSA register under number 124920. 
> >
> >*************************************************************
> *********
> >
> >
> >  
> >
> 
> 
> 


********************************************************************** 
This is a commercial communication from Commerzbank AG.\ \ This ... {{dropped}}



From ivo.welch at yale.edu  Mon May 19 16:10:20 2003
From: ivo.welch at yale.edu (Welch, Ivo)
Date: Mon, 19 May 2003 10:10:20 -0400
Subject: [R] irregular ts plot?
Message-ID: <3EC8E5CC.1050407@yale.edu>


hi brian:  first, thank you very much for your help.  very highly 
appreciated.

I have read/am reading the R and plot documentations, but it will take a 
while to absorb it all.  may I ask 2 more itsy queries, please?  I hope 
they are the 5 second type questions for someone in the know.

* if 2 time-series are plotted with one plot command, they are below one 
another.  if 6 are plotted, they are in a 2c*3r array.  which parameter 
allows me to control this behavior?

* is it possible to run a batch command that leaves the figure window 
where it is?  or, that waits for user input, so that my batch command 
can plot a figure, wait until I look at it, plot the next figure, etc.?  
("scan() in a BATCH command does not wait.")

incidentally, for gnuplot, I found it very helpful that people had 
posted sample sessions on the web that contain a variety of commands 
with output and comments on what did what.  google works quite well for 
searching over many such sample sessions to find something that does 
what one needs.   there are R examples here and there (and especially in 
the docs), and they are extremely useful;  but, it would be nicer if 
this was more random but searchable stuff.

regards,

/iaw



From laurent.faisnel at ariase.com  Mon May 19 16:12:47 2003
From: laurent.faisnel at ariase.com (Laurent Faisnel)
Date: Mon, 19 May 2003 16:12:47 +0200
Subject: [R] how to run R as a daemon
References: <Pine.LNX.4.44.0305191335050.30406-100000@gannet.stats>
Message-ID: <3EC8E65F.4070209@ariase.com>

Prof Brian Ripley wrote:

>On Mon, 19 May 2003, Laurent Faisnel wrote:
>
>  
>
>>I  just visited the link you gave me. One of the problems that could 
>>occur using NuSOAP is that I do not intend using Python. Thanks anyway. 
>>I would also like to ask more precise questions :
>>    
>>
>
>`more precise'?  At least some of the inefficiencies are emerging, but I
>still have little picture of what you are actually trying to do.  It ought
>to be possible to run a new R session in a well under a second (on a 1+GHz
>machine):
>
>gannet% time env R_DEFAULT_PACKAGES=NULL R --vanilla --slave < /dev/null
>0.203u 0.039s 0:00.27 85.1%     0+0k 0+0io 1220pf+0w
>

I don't understand how you made this test. What does "gannet%" mean? 
Anyway, when I launch R with these options (--vanilla and --slave), it 
is fast enough.

>
>for example (on a dual Athlon 2600, R 1.7.0).
>
>  
>
>>- is it possible to run R as a standalone service, which runs in 
>>background indefinitely, waiting for instructions ? 
>>    
>>
>
>It is, but waiting for instructions from one place (stdin or on a socket).
>
This is a good piece of news. But how ?

>There is some danger of different jobs sent leaving things behind that 
>will cause interactions.
>
I 'll make some tests about possible interactions if I successfully 
launch R in such a mode.

>>This would be a 
>>great improvement for me, since each time it is launched R has to 
>>re-load a (constant) matrix generated thanks to a database connection 
>>(takes a very long while)
>>    
>>
>
>You could just save and then load that matrix in your .RData
>  
>
Seems to be a good idea. I'm not used to edit my .RData but sure it 
would be an improvement. I had not even thought about it.

>>- my R script is object-oriented; I define classes and methods, but I'm 
>>not so sure about how methods should be declared; I usually write 
>>something like :
>>
>>mymethod <- function(.Object) UseMethod("mymethod",.Object);
>>
>>setMethod("mymethod","myclass",
>>        function(.Object)
>>        {
>>            # instructions
>>            return(.Object);
>>        }
>>        );
>>
>>Perhaps is this not the best way to write methods ? Could this explain 
>>the following fact : when I run the script, R spends about 1/3 of its 
>>thinking time creating the generic functions linked with my methods. 
>>Isn't this wasted time ? The same script may be executed many times 
>>consecutively by different users, and each time R has to re-define the 
>>generic functions ! (are always the same)
>>    
>>
>
>Yes, but it is your usage that is the problem.  You are mixing S3 and S4
>methods (where did you copy an example like that from?).  You should
>dump your scripts if you use S4 methods (which I don't think you should be
>doing in such simple examples, nor if you care about speed):  see the
>examples of S4-using packages on CRAN (e.g. DBI, SparseM).
>  
>
I clearly prefer using S3 classes & methods. I knew S4 classes would 
cause slowness problems. But I did not find a clear documentation about 
differences between S3 and S4. Neither did I find detailed tutorials 
about R programming. Which part of my code structure is S3-like and 
which one is S4-like ? Is the above-mentionned problem S4 classes' fault 
? You mean with clean S3 scripts I would have none of these drawbacks ?

>Also consider upgrading to R 1.7.0 and setting R_DEFAULT_PACKAGES to what 
>you actually need (and omit methods if you don't need it)
>
>  
>
I won't use R 1.7.0 for the time. First everything has to work fine with 
R 1.6.2. I think I have few things in R_DEFAULT_PACKAGES, and I cannot 
omit methods because I use them all !

Thank you for your answer.
Laurent



From ripley at stats.ox.ac.uk  Mon May 19 16:43:22 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 19 May 2003 15:43:22 +0100 (BST)
Subject: [R] how to run R as a daemon
In-Reply-To: <3EC8E65F.4070209@ariase.com>
Message-ID: <Pine.LNX.4.44.0305191539360.30550-100000@gannet.stats>

On Mon, 19 May 2003, Laurent Faisnel wrote:

> Prof Brian Ripley wrote:
> 
> >On Mon, 19 May 2003, Laurent Faisnel wrote:
> >
> >  
> >
> >>I  just visited the link you gave me. One of the problems that could 
> >>occur using NuSOAP is that I do not intend using Python. Thanks anyway. 
> >>I would also like to ask more precise questions :
> >>    
> >>
> >
> >`more precise'?  At least some of the inefficiencies are emerging, but I
> >still have little picture of what you are actually trying to do.  It ought
> >to be possible to run a new R session in a well under a second (on a 1+GHz
> >machine):
> >
> >gannet% time env R_DEFAULT_PACKAGES=NULL R --vanilla --slave < /dev/null
> >0.203u 0.039s 0:00.27 85.1%     0+0k 0+0io 1220pf+0w
> >
> 
> I don't understand how you made this test. What does "gannet%" mean? 

A totally standard Unix prompt: machine_name% is the default prompt in 
csh.

> Anyway, when I launch R with these options (--vanilla and --slave), it 
> is fast enough.
> 
> >
> >for example (on a dual Athlon 2600, R 1.7.0).
> >
> >  
> >
> >>- is it possible to run R as a standalone service, which runs in 
> >>background indefinitely, waiting for instructions ? 
> >>    
> >>
> >
> >It is, but waiting for instructions from one place (stdin or on a socket).
> >
> This is a good piece of news. But how ?
> 
> >There is some danger of different jobs sent leaving things behind that 
> >will cause interactions.
> >
> I 'll make some tests about possible interactions if I successfully 
> launch R in such a mode.
> 
> >>This would be a 
> >>great improvement for me, since each time it is launched R has to 
> >>re-load a (constant) matrix generated thanks to a database connection 
> >>(takes a very long while)
> >>    
> >>
> >
> >You could just save and then load that matrix in your .RData
> >  
> >
> Seems to be a good idea. I'm not used to edit my .RData but sure it 
> would be an improvement. I had not even thought about it.
> 
> >>- my R script is object-oriented; I define classes and methods, but I'm 
> >>not so sure about how methods should be declared; I usually write 
> >>something like :
> >>
> >>mymethod <- function(.Object) UseMethod("mymethod",.Object);
> >>
> >>setMethod("mymethod","myclass",
> >>        function(.Object)
> >>        {
> >>            # instructions
> >>            return(.Object);
> >>        }
> >>        );
> >>
> >>Perhaps is this not the best way to write methods ? Could this explain 
> >>the following fact : when I run the script, R spends about 1/3 of its 
> >>thinking time creating the generic functions linked with my methods. 
> >>Isn't this wasted time ? The same script may be executed many times 
> >>consecutively by different users, and each time R has to re-define the 
> >>generic functions ! (are always the same)
> >>    
> >>
> >
> >Yes, but it is your usage that is the problem.  You are mixing S3 and S4
> >methods (where did you copy an example like that from?).  You should
> >dump your scripts if you use S4 methods (which I don't think you should be
> >doing in such simple examples, nor if you care about speed):  see the
> >examples of S4-using packages on CRAN (e.g. DBI, SparseM).
> >  
> >
> I clearly prefer using S3 classes & methods. I knew S4 classes would 
> cause slowness problems. But I did not find a clear documentation about 
> differences between S3 and S4. Neither did I find detailed tutorials 
> about R programming. Which part of my code structure is S3-like and 
> which one is S4-like ? Is the above-mentionned problem S4 classes' fault 
> ? You mean with clean S3 scripts I would have none of these drawbacks ?

There's a book called `S Programming' that has all this crystal clear, and 
it is in the FAQ!

> >Also consider upgrading to R 1.7.0 and setting R_DEFAULT_PACKAGES to what 
> >you actually need (and omit methods if you don't need it)
> >
> >  
> >
> I won't use R 1.7.0 for the time. First everything has to work fine with 
> R 1.6.2. I think I have few things in R_DEFAULT_PACKAGES, and I cannot 
> omit methods because I use them all !

That's the `methods' package, only needed for S4 methods.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon May 19 16:53:57 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 19 May 2003 15:53:57 +0100 (BST)
Subject: [R] irregular ts plot?
In-Reply-To: <3EC8E5CC.1050407@yale.edu>
Message-ID: <Pine.LNX.4.44.0305191545550.30550-100000@gannet.stats>

On Mon, 19 May 2003, Welch, Ivo wrote:

> 
> hi brian:  first, thank you very much for your help.  very highly 
> appreciated.
> 
> I have read/am reading the R and plot documentations, but it will take a 
> while to absorb it all.  may I ask 2 more itsy queries, please?  I hope 
> they are the 5 second type questions for someone in the know.
> 
> * if 2 time-series are plotted with one plot command, they are below one 
> another.  if 6 are plotted, they are in a 2c*3r array.  which parameter 
> allows me to control this behavior?

It's apparently hardwired in plot.mts:

    nc <- if (nser > 4) 2 else 1

> * is it possible to run a batch command that leaves the figure window 
> where it is?  or, that waits for user input, so that my batch command 
> can plot a figure, wait until I look at it, plot the next figure, etc.?  
> ("scan() in a BATCH command does not wait.")

So you need something that does wait and not use stdin.  On Windows I use
a dialog box, and I've never needed it on Linux.

> incidentally, for gnuplot, I found it very helpful that people had 
> posted sample sessions on the web that contain a variety of commands 
> with output and comments on what did what.  google works quite well for 
> searching over many such sample sessions to find something that does 
> what one needs.   there are R examples here and there (and especially in 
> the docs), and they are extremely useful;  but, it would be nicer if 
> this was more random but searchable stuff.

There are books on S with *lots* of examples: see the FAQ.  Books even 
have indices.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mail at joeconway.com  Mon May 19 17:33:59 2003
From: mail at joeconway.com (Joe Conway)
Date: Mon, 19 May 2003 08:33:59 -0700
Subject: [R] how to run R as a daemon
In-Reply-To: <3EC8B536.7040202@ariase.com>
References: <3EC8B536.7040202@ariase.com>
Message-ID: <3EC8F967.50507@joeconway.com>

Laurent Faisnel wrote:
> Hi all,
> Using R a as a real-time application called by Php for a website, I 
> would like to run one R process only, which would manage user 
> connections. For the time each user who asks for an analysis causes a 
> new R process to start, which is not suitable in prevision of many 
> users. R needs about 30 seconds to run the script which makes the 
> analysis. The problem is that this waiting time is n times more 
> important when n users ask for an analysis...
> Thanks for any help.

I have been using R as the processing engine behind a PHP application 
(Intranet) by embedding it in PostgreSQL. In my case the data being 
analyzed all resides in the Postgres database, and I use PL/R functions 
to process and return data to PHP. Then in PHP I use JPGraph to generate 
the charts. Recently I also started to play with using a virtual frame 
buffer and R's own charting capability to create the charts as temporary 
files and then simply use PHP to display them.

Further, I preload and pre-initialize the embedded R engine on 
postmaster (Postgres) startup, which reduces the initial call in any 
given session from 2+ seconds to 10s of milliseconds on my hardware.

You can get a copy of PL/R here: http://www.joeconway.com

The preloading functionality is avaialable only in Postgres 7.4devel at 
this point, but I have a backpatched version 7.3.2 RPM available at the 
same place. If you use the RPM, it has PL/R in it already, but 
unfortunately it is not the latest (I'll get around to fixing that soon, 
probably after Postgres 7.3.3 is released, which should be this week).

Although I'm still calling it an "alpha" release (partly due to lack of 
feedback from others -- anyone have any?), it has worked pretty reliably 
for my purposes, and I've started using it in a limited way on a 
production application within the last few weeks.

Hope this helps,

Joe



From jonathan.williams at pharmacology.oxford.ac.uk  Mon May 19 17:54:32 2003
From: jonathan.williams at pharmacology.oxford.ac.uk (Jonathan Williams)
Date: Mon, 19 May 2003 16:54:32 +0100
Subject: [R] plotting a simple graph
Message-ID: <NGBBKJEMOMLJFCOIEGCEEECAJJAA.jonathan.williams@pharm.ox.ac.uk>

I am having great difficulty plotting what should be a simple graph.
I have measured 1 'y' and 5 'x' variables in each of two groups.
Linear regression shows significant differences in the slopes of the
regression for each 'x' variable between the two groups.

All that I want to do is to plot one graph that shows the scatterplot
for the three groups (each group represented by a different symbol),
overlaid by the fitted regression lines for each group's relation
between the 'x1' and 'y' variables, covarying the remaining four 'x'
variables and adjusting them to their mean values.

#All five of the grp*x interactions are significant in:
fit1=lm(log(y)~grp*(log(x1)+log(x2)+log(x3)+log(x4)+log(x5))
summary(fit1)

#However, to avoid sending all of the data, I create dummy data-sets
#that have distributions resembling the original variables (which are
#very skewed, hence the log-transformations).

grp<-c(rep(0,150),rep(1,200))
y<-(rnorm(n=350,mean=8,sd=5)^1.15)+5
x1<-((rnorm(n=350,mean=10,sd=5))+1)
for (i in 1:350) {if (x1[i]<1 | x1[i]>20) x1[i]<-18}
x2<-(rnorm(n=350,mean=20,sd=5)^2)
x3<-(rnorm(n=350,mean=10,sd=3)^1.5)+50
x4<-rnorm(n=350,mean=45,sd=2.5)
x5<-rnorm(n=350,mean=2.4,sd=0.15)

#So, what I want to do is to plot the regression lines of log(y) on
#log(x1) for the three different groups, covarying grp, log(x2)...
#log(x6)x6 and grp:log(x2)....grp:log(x6). This what I tried:-

plot(log(x1)[grp==0],log(y)[grp==0],
main='Differential relations between log(y) and log(x1) in 3 groups,
adjusted for x2-x5',
xlab='log(x1)', ylab='log(y)')
newdat=data.frame(x1=seq(min(x1),max(x1),(max(x1)-min(x1))/10))
points(log(x1)[grp==1],log(y)[grp==1],pch=3)
lines(predict(lm(log(y)~log(x2)+log(x3)+log(x4)+log(x5),subset=grp==0),newda
t),lty=1)
lines(predict(lm(log(y)~log(x2)+log(x3)+log(x4)+log(x5),subset=grp==1),newda
t),lty='dashed')

This plots regression lines which have corners (which I think must be
wrong!) and which
bear no resemblance to the real regression lines (the lines are not very
close to the points
for the original data set).

#if I specify the means of x variables x2 to x5, as follows:-
newdat=data.frame(x1=seq(min(x1),max(x1),(max(x1)-min(x1))/10),x2=mean(x2),x
3=mean(x3),x4=mean(x4),x5=mean(x5))
#then this gives 2 parallel horizontal regression lines, which is also
incorrect

Please could someone enlighten me on how to plot the regression lines?
Thanks,

Jonathan Williams
OPTIMA
Radcliffe Infirmary
Woodstock Road
OXFORD OX2 6HE
Tel +1865 (2)24356



From tmurph6 at po-box.mcgill.ca  Mon May 19 17:50:24 2003
From: tmurph6 at po-box.mcgill.ca (Tanya Murphy)
Date: Mon, 19 May 2003 11:50:24 -0400
Subject: [R] upData levels in Hmisc
Message-ID: <3ED66DD0@webmail.mcgill.ca>

Dear listserve members, especially Prof. Harrell:

I am trying to create a factor variable that has fewer levels than the 
original.

I have a factor:
>rosa$risk1
   [1] 2 2 5 1 ...
[1799] 3 3 1 3 1 6 3 3 1 5 3 5 3 3 3 0 3 3 3 1 1 3
Levels: 0 1 2 3 4 5 6 8

But when I do this:
rosa2 <- upData(rosa, 
levels=list(risk1=list(1='1',2='2',3='3',0=c('0','4','6','8'))))

I get:
Error: syntax error

But I am able to reproduce the dat2 <- upData(dat, etc...)  example in Prof. 
Harrell's Hmisc notes.

Thanks!

Tanya Murphy



From anna at ptolemy.arc.nasa.gov  Mon May 19 17:56:01 2003
From: anna at ptolemy.arc.nasa.gov (Anna  H. Pryor)
Date: Mon, 19 May 2003 08:56:01 -0700
Subject: [R] modulus operator?
Message-ID: <200305190856.01745.anna@ptolemy.arc.nasa.gov>


Is there a modulus operator in R?

Anna



From wolski at molgen.mpg.de  Mon May 19 18:07:20 2003
From: wolski at molgen.mpg.de (Wolski)
Date: Mon, 19 May 2003 18:07:20 +0200
Subject: [R] modulus operator?
In-Reply-To: <200305190856.01745.anna@ptolemy.arc.nasa.gov>
References: <200305190856.01745.anna@ptolemy.arc.nasa.gov>
Message-ID: <200305191807200144.0A2FD8D6@harry.molgen.mpg.de>

I havent found any.
I am using this.

mod<-function(x,m)
  {
    t1<-floor(x/m)
    return(x-t1*m)
  }

Eryk

*********** REPLY SEPARATOR  ***********

On 5/19/2003 at 8:56 AM Anna  H. Pryor wrote:

>Is there a modulus operator in R?
>
>Anna
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help



Dipl. bio-chem. Eryk Witold Wolski    @    MPI-MG Dep. Vertebrate Genomics   
Ihnestrasse 73 14195 Berlin          'v'    
tel: 0049-30-84131285               /   \    
mail: wolski at molgen.mpg.de        ---W-W----



From fharrell at virginia.edu  Mon May 19 18:12:58 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Mon, 19 May 2003 12:12:58 -0400
Subject: [R] upData levels in Hmisc
In-Reply-To: <3ED66DD0@webmail.mcgill.ca>
References: <3ED66DD0@webmail.mcgill.ca>
Message-ID: <20030519121258.50fddfaf.fharrell@virginia.edu>

On Mon, 19 May 2003 11:50:24 -0400
Tanya Murphy <tmurph6 at po-box.mcgill.ca> wrote:

> Dear listserve members, especially Prof. Harrell:
> 
> I am trying to create a factor variable that has fewer levels than the 
> original.
> 
> I have a factor:
> >rosa$risk1
>    [1] 2 2 5 1 ...
> [1799] 3 3 1 3 1 6 3 3 1 5 3 5 3 3 3 0 3 3 3 1 1 3
> Levels: 0 1 2 3 4 5 6 8
> 
> But when I do this:
> rosa2 <- upData(rosa, 
> levels=list(risk1=list(1='1',2='2',3='3',0=c('0','4','6','8'))))
> 
> I get:
> Error: syntax error
> 
> But I am able to reproduce the dat2 <- upData(dat, etc...)  example in Prof. 
> Harrell's Hmisc notes.
> 
> Thanks!
> 
> Tanya Murphy

In S you can avoid quoting names in vectors and lists when these are legal S names.  Legal names do not start with numbers.  Use e.g. '1'='1', ..., '0'=c('0','4','6','8').
---
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From Roger.Bivand at nhh.no  Mon May 19 18:12:02 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 19 May 2003 18:12:02 +0200 (CEST)
Subject: [R] modulus operator?
In-Reply-To: <200305190856.01745.anna@ptolemy.arc.nasa.gov>
Message-ID: <Pine.LNX.4.44.0305191810540.13071-100000@reclus.nhh.no>

On Mon, 19 May 2003, Anna  H. Pryor wrote:

> 
> Is there a modulus operator in R?
> 

%%

see ?"Arithmetic"

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From sundar.dorai-raj at pdf.com  Mon May 19 18:14:20 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Mon, 19 May 2003 11:14:20 -0500
Subject: [R] modulus operator?
References: <200305190856.01745.anna@ptolemy.arc.nasa.gov>
Message-ID: <3EC902DC.8070806@pdf.com>

help("%%")

Anna H. Pryor wrote:
> Is there a modulus operator in R?
> 
> Anna
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From John.Marsland at CommerzbankIB.com  Mon May 19 18:16:16 2003
From: John.Marsland at CommerzbankIB.com (Marsland, John)
Date: Mon, 19 May 2003 17:16:16 +0100
Subject: FW: [R] modulus operator?
Message-ID: <8CBAA121CEB4D5118CB200508BB2BBEF0317E761@xmx8lonib.lonib.commerzbank.com>

 try "%%" as the modulus operator and "%/%" for integer division
 eg 5%%2 equals 1
 
 John Marsland
 
> > -----Original Message-----
> > From: Anna H. Pryor [mailto:anna at ptolemy.arc.nasa.gov]
> > Sent: 19 May 2003 16:56
> > To: R Help
> > Subject: [R] modulus operator?
> > 
> > 
> > 
> > Is there a modulus operator in R?
> > 
> > Anna
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > 
> 


********************************************************************** 
This is a commercial communication from Commerzbank AG.\ \ This ... {{dropped}}



From paul at minervaplaats.cx  Mon May 19 18:15:24 2003
From: paul at minervaplaats.cx (Paul)
Date: Mon, 19 May 2003 18:15:24 +0200
Subject: [R] modulus operator?
Message-ID: <1980678.1053368124@[192.168.1.7]>

Hoi Wolski,

--On maandag 19 mei 2003 18:07 +0200 Wolski <wolski at molgen.mpg.de> wrote:

> I havent found any.
> I am using this.
>
> mod<-function(x,m)
>   {
>     t1<-floor(x/m)
>     return(x-t1*m)
>   }
>
Isn't that just simply "%%" (or if i'm mistaken, perhaps '%/%')?

regards,
Paul

-- 
Paul Lemmens
NICI, University of Nijmegen              ASCII Ribbon Campaign /"\
Montessorilaan 3 (B.01.03)                    Against HTML Mail \ /
NL-6525 HR Nijmegen                                              X
The Netherlands                                                 / \
Phonenumber    +31-24-3612648
Fax            +31-24-3616066



From tmurph6 at po-box.mcgill.ca  Mon May 19 18:25:52 2003
From: tmurph6 at po-box.mcgill.ca (Tanya Murphy)
Date: Mon, 19 May 2003 12:25:52 -0400
Subject: [R] upData levels in Hmisc
Message-ID: <3ED6A631@webmail.mcgill.ca>

Prof. Harrell,

Thanks for the speedy reply! It worked. And thank you, in general, for all 
your help documents/tutorials.

Sincerely,
Tanya Murphy



From mschwartz at medanalytics.com  Mon May 19 18:26:20 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Mon, 19 May 2003 11:26:20 -0500
Subject: [R] modulus operator?
In-Reply-To: <200305191807200144.0A2FD8D6@harry.molgen.mpg.de>
Message-ID: <003b01c31e23$6282e520$0201a8c0@MARC>

Use: %%

See the R Reference Manual, pages 33 - 34 or ?Arithmetic

x %% y = x mod y

HTH,

Marc Schwartz


>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Wolski
>Sent: Monday, May 19, 2003 11:07 AM
>To: Anna H. Pryor; R Help
>Subject: Re: [R] modulus operator?
>
>
>I havent found any.
>I am using this.
>
>mod<-function(x,m)
>  {
>    t1<-floor(x/m)
>    return(x-t1*m)
>  }
>
>Eryk
>
>*********** REPLY SEPARATOR  ***********
>
>On 5/19/2003 at 8:56 AM Anna  H. Pryor wrote:
>
>>Is there a modulus operator in R?
>>
>>Anna
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
>
>Dipl. bio-chem. Eryk Witold Wolski    @    MPI-MG Dep. 
>Vertebrate Genomics   
>Ihnestrasse 73 14195 Berlin          'v'    
>tel: 0049-30-84131285               /   \    
>mail: wolski at molgen.mpg.de        ---W-W----
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From spencer.graves at pdf.com  Mon May 19 18:34:21 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 19 May 2003 09:34:21 -0700
Subject: [R] modulus operator?
References: <200305190856.01745.anna@ptolemy.arc.nasa.gov>
	<200305191807200144.0A2FD8D6@harry.molgen.mpg.de>
Message-ID: <3EC9078D.4000102@pdf.com>

What do you mean by "modulus"?  Is that something like absolute value 
(as in the "maximum modulus theorem";  see 
"http://mathworld.wolfram.com/MaximumModulusPrinciple.html")?  Or do you 
mean something like remainder?  If the latter, what about "%%":

 > 3.5%%2
[1] 1.5

hth.  spencer graves

Wolski wrote:
> I havent found any.
> I am using this.
> 
> mod<-function(x,m)
>   {
>     t1<-floor(x/m)
>     return(x-t1*m)
>   }
> 
> Eryk
> 
> *********** REPLY SEPARATOR  ***********
> 
> On 5/19/2003 at 8:56 AM Anna  H. Pryor wrote:
> 
> 
>>Is there a modulus operator in R?
>>
>>Anna
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 
> 
> 
> Dipl. bio-chem. Eryk Witold Wolski    @    MPI-MG Dep. Vertebrate Genomics   
> Ihnestrasse 73 14195 Berlin          'v'    
> tel: 0049-30-84131285               /   \    
> mail: wolski at molgen.mpg.de        ---W-W----
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jeff_hamann at hamanndonald.com  Mon May 19 20:20:39 2003
From: jeff_hamann at hamanndonald.com (Jeff D. Hamann)
Date: Mon, 19 May 2003 11:20:39 -0700
Subject: [R] create groups from tallies
Message-ID: <003201c31e33$5a730a80$7c74c180@forestry.oregonstate.edu>

I'm trying to figure out a way of grouping data from simple tally data. For
example, I would like to turn the following table into the table at the
bottom. I would normally do this in sql statements, but I won't have control
over the data, so that's not an option...

Thanks,
Jeff.

dbh, tally
5 1
12 2
6 1
10 1
6 1
12 1
10 2
9 1
3 1
5 1
8 1
3 1
6 1
5 1
10 1
5 1
4 1
22 1
20 1
15 1
14 1
11 1
15 1
10 1
8 1
14 1
10 1
11 1
16 1
17 1
10 1
12 1
9 1
6 1
11 1
18 1
7 1
8 1
9 1
12 1
13 1
14 1
16 1
15 1
8 1
35 1
5 1
8 1
14 1
11 1
12 1
20 1
10 1
27 1
7 1
8 2
12 2
5 1
20 1
12 1
17 1
22 1
10 1
13 1
9 1
27 1
9 1
18 1
12 1
15 2
18 1
22 1
16 1
17 1
11 1
15 1
8 1
14 1
18 1
11 1
14 1
9 1
14 1
8 1
9 1
10 1
20 1
11 1
10 1
6 1
10 1
16 1
8 2
14 2
7 1
5 1
8 1
15 1
13 2
13 1
15 1
9 2
16 1
18 1
12 1
10 1
17 1
15 1
7 1
17 1
20 1
5 1
7 1
6 1
7 1
4 1
8 1
7 1
4 1
16 1
6 1
5 1
3 1
5 1
17 1
6 1
13 1
10 1
6 1
7 1
9 1
5 1
6 1
9 1
22 1
2 1
8 1
5 1
14 1
12 1
14 1
9 2
19 1
18 1
17 1
23 1
21 1
22 1
16 1
15 1
13 1
9 1
14 1
11 1
19 1
19 1
20 1
25 1
22 1
22 1
17 1
24 1
15 1
8 1
3 1
6 1
7 1
11 1
11 1
11 1
5 1
19 1
16 1
12 1
9 1
16 1
13 1
12 1
18 1
18 1
19 1
11 1
12 1
11 1
13 1
13 1
12 1
10 1
15 1
6 1
11 1
9 1
8 1
7 1
12 1
15 1
15 1
12 1
17 1
17 1
20 1
9 1
8 1
16 1
19 1
25 1
22 1
23 1
21 1
23 1
19 1
8 1
16 1
10 1
16 1
11 1
11 1
10 1
13 1
17 1
15 1
6 1
23 1
21 1
12 1
14 1
17 1
17 1
12 1
12 1
14 1
17 1
17 1
11 1
13 1
19 1
27 1
10 1
33 1
9 1
10 1
15 1
12 1
11 1
8 1
8 1
10 1
7 1
10 1
12 1
9 1
12 1
7 1
10 1
9 1
11 1
12 1
10 1
10 1
11 1
16 1
13 1
8 1
17 1
15 1
19 1
16 1
12 1
7 1
11 1
15 1
15 1
14 1
14 1
8 1
6 1
7 1
23 1
4 1
4 1
7 1
6 1
9 1
10 1
15 1
23 1
8 1
13 1
8 1
21 1
24 1
22 1
8 1
14 1
24 1
13 1
17 1
9 1
25 1
9 1
22 1
7 1
20 1
13 2
15 1
9 1
17 1
13 1
18 1
9 1
19 1
7 1
14 1
15 1
9 1
16 1
12 1
7 1
9 1
11 1
23 1
8 1
19 1
10 1
23 1
6 1
28 1
32 1
9 1
6 1
27 1
14 1
18 1
11 1
14 1
10 1
15 1
9 1
21 1
23 1
16 2
19 1
22 1
16 1
13 1
11 1
29 1


"dbh","SumOftally"
2,1.00
3,4.00
4,5.00
5,13.00
6,17.00
7,18.00
8,26.00
9,29.00
10,27.00
11,24.00
12,27.00
13,19.00
14,20.00
15,23.00
16,18.00
17,18.00
18,10.00
19,12.00
20,8.00
21,5.00
22,11.00
23,9.00
24,3.00
25,3.00
27,4.00
28,1.00
29,1.00
32,1.00
33,1.00
35,1.00



From ana.kozomara at 9online.fr  Mon May 19 08:21:55 2003
From: ana.kozomara at 9online.fr (Ana KOZOMARA)
Date: Mon, 19 May 2003 08:21:55 +0200
Subject: [R] how to construct tree under R
References: <003200600191153SILJA@silja.absolutok.com>
	<3EC756D4.205FCEB5@statistik.uni-dortmund.de>
Message-ID: <000e01c31dce$f4e93ae0$0200a8c0@jenesaispas>

Hey guys,
thanks a lot for your understanding and advices.
Anyway, I suceed to make something like tree-structure under R...list of
lists...
because my problem was not which algorithm to use to construct the
regression tree, but which data structure to choose....
Nevermind,
best wishes,
thanks a lot again,
ana
----- Original Message -----
From: "Uwe Ligges" <ligges at statistik.uni-dortmund.de>
To: "ANA KOZOMARA" <magnolia at absolutok.net>
Sent: Sunday, May 18, 2003 11:48 AM
Subject: Re: [R] how to construct tree under R


>
>
> ANA KOZOMARA wrote:
> >
> > Sorry, didn't mean to make you mad...
> > unfortunately, at the moment i don't think i can afford it,
> > and in my university library there are no books concerning R...
> > Anyway, I'm sorry if I'm bugging you with the questions...
> > (actually, I even tried to install today one library which I think was
> > written
> > by you..."tree")...anyway it didn't work, so I suppose that speaks of my
> > niveau..Too bad there is no mailing list for a real R beginers...
> > I'm kidding,
> > best regard,
> > anyway, thaks for the answers,
> > ana
>
> [not to R-Help - you already forwarded Brian's message to r-help which
> was private!]
>
> Ana,
>
> in your library are no books concerning R? The two books from Venables
> and Ripley are very famous and "Modern Applied Statistics with S" ist
> the best sold Springer book in Statistics, AFAIK. So it's your turn make
> a suggestion to the library people to buy it!
> The book
>   Breiman, Friedman, Olshen, and Stone (1984):
>   Classification and Regression Trees. Wadsworth.
> is THE book defining CART (and therefore the similar implementation of
> rpart, which was implemented by Terry M Therneau and Beth Atkinson at
> Mayo - there was a Technical Report on this, AFAIK).
>
> Anyway, there are some manuals coming with R, for a beginner: "An
> Introduction to R", "R Data Import/Export", ans "R Language Definition".
> Also, reading the FAQs is a good idea.
> Since all people answering mails on R-help are volunteers, they don't
> want to answer extremly basic questions that are obvious from reading
> the manuals.
>
> Your idea to type in rpart was OK. Better idea: Look in the package
> structure of the package sources and look for the relevant file *.R with
> R Code, and *.c, *.f for the C and Fortran sources that are the basic of
> the DLL which the R Code uses.
>
> Uwe Ligges



From spencer.graves at pdf.com  Mon May 19 20:47:50 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 19 May 2003 11:47:50 -0700
Subject: [R] create groups from tallies
References: <003201c31e33$5a730a80$7c74c180@forestry.oregonstate.edu>
Message-ID: <3EC926D6.3060002@pdf.com>

Have you considered "aggregate"?

hth.  spencer graves

Jeff D. Hamann wrote:
> I'm trying to figure out a way of grouping data from simple tally data. For
> example, I would like to turn the following table into the table at the
> bottom. I would normally do this in sql statements, but I won't have control
> over the data, so that's not an option...
> 
> Thanks,
> Jeff.
> 
> dbh, tally
> 5 1
> 12 2
> 6 1
> 10 1
> 6 1
> 12 1
> 10 2
> 9 1
> 3 1
> 5 1
> 8 1
> 3 1
> 6 1
> 5 1
> 10 1
> 5 1
> 4 1
> 22 1
> 20 1
> 15 1
> 14 1
> 11 1
> 15 1
> 10 1
> 8 1
> 14 1
> 10 1
> 11 1
> 16 1
> 17 1
> 10 1
> 12 1
> 9 1
> 6 1
> 11 1
> 18 1
> 7 1
> 8 1
> 9 1
> 12 1
> 13 1
> 14 1
> 16 1
> 15 1
> 8 1
> 35 1
> 5 1
> 8 1
> 14 1
> 11 1
> 12 1
> 20 1
> 10 1
> 27 1
> 7 1
> 8 2
> 12 2
> 5 1
> 20 1
> 12 1
> 17 1
> 22 1
> 10 1
> 13 1
> 9 1
> 27 1
> 9 1
> 18 1
> 12 1
> 15 2
> 18 1
> 22 1
> 16 1
> 17 1
> 11 1
> 15 1
> 8 1
> 14 1
> 18 1
> 11 1
> 14 1
> 9 1
> 14 1
> 8 1
> 9 1
> 10 1
> 20 1
> 11 1
> 10 1
> 6 1
> 10 1
> 16 1
> 8 2
> 14 2
> 7 1
> 5 1
> 8 1
> 15 1
> 13 2
> 13 1
> 15 1
> 9 2
> 16 1
> 18 1
> 12 1
> 10 1
> 17 1
> 15 1
> 7 1
> 17 1
> 20 1
> 5 1
> 7 1
> 6 1
> 7 1
> 4 1
> 8 1
> 7 1
> 4 1
> 16 1
> 6 1
> 5 1
> 3 1
> 5 1
> 17 1
> 6 1
> 13 1
> 10 1
> 6 1
> 7 1
> 9 1
> 5 1
> 6 1
> 9 1
> 22 1
> 2 1
> 8 1
> 5 1
> 14 1
> 12 1
> 14 1
> 9 2
> 19 1
> 18 1
> 17 1
> 23 1
> 21 1
> 22 1
> 16 1
> 15 1
> 13 1
> 9 1
> 14 1
> 11 1
> 19 1
> 19 1
> 20 1
> 25 1
> 22 1
> 22 1
> 17 1
> 24 1
> 15 1
> 8 1
> 3 1
> 6 1
> 7 1
> 11 1
> 11 1
> 11 1
> 5 1
> 19 1
> 16 1
> 12 1
> 9 1
> 16 1
> 13 1
> 12 1
> 18 1
> 18 1
> 19 1
> 11 1
> 12 1
> 11 1
> 13 1
> 13 1
> 12 1
> 10 1
> 15 1
> 6 1
> 11 1
> 9 1
> 8 1
> 7 1
> 12 1
> 15 1
> 15 1
> 12 1
> 17 1
> 17 1
> 20 1
> 9 1
> 8 1
> 16 1
> 19 1
> 25 1
> 22 1
> 23 1
> 21 1
> 23 1
> 19 1
> 8 1
> 16 1
> 10 1
> 16 1
> 11 1
> 11 1
> 10 1
> 13 1
> 17 1
> 15 1
> 6 1
> 23 1
> 21 1
> 12 1
> 14 1
> 17 1
> 17 1
> 12 1
> 12 1
> 14 1
> 17 1
> 17 1
> 11 1
> 13 1
> 19 1
> 27 1
> 10 1
> 33 1
> 9 1
> 10 1
> 15 1
> 12 1
> 11 1
> 8 1
> 8 1
> 10 1
> 7 1
> 10 1
> 12 1
> 9 1
> 12 1
> 7 1
> 10 1
> 9 1
> 11 1
> 12 1
> 10 1
> 10 1
> 11 1
> 16 1
> 13 1
> 8 1
> 17 1
> 15 1
> 19 1
> 16 1
> 12 1
> 7 1
> 11 1
> 15 1
> 15 1
> 14 1
> 14 1
> 8 1
> 6 1
> 7 1
> 23 1
> 4 1
> 4 1
> 7 1
> 6 1
> 9 1
> 10 1
> 15 1
> 23 1
> 8 1
> 13 1
> 8 1
> 21 1
> 24 1
> 22 1
> 8 1
> 14 1
> 24 1
> 13 1
> 17 1
> 9 1
> 25 1
> 9 1
> 22 1
> 7 1
> 20 1
> 13 2
> 15 1
> 9 1
> 17 1
> 13 1
> 18 1
> 9 1
> 19 1
> 7 1
> 14 1
> 15 1
> 9 1
> 16 1
> 12 1
> 7 1
> 9 1
> 11 1
> 23 1
> 8 1
> 19 1
> 10 1
> 23 1
> 6 1
> 28 1
> 32 1
> 9 1
> 6 1
> 27 1
> 14 1
> 18 1
> 11 1
> 14 1
> 10 1
> 15 1
> 9 1
> 21 1
> 23 1
> 16 2
> 19 1
> 22 1
> 16 1
> 13 1
> 11 1
> 29 1
> 
> 
> "dbh","SumOftally"
> 2,1.00
> 3,4.00
> 4,5.00
> 5,13.00
> 6,17.00
> 7,18.00
> 8,26.00
> 9,29.00
> 10,27.00
> 11,24.00
> 12,27.00
> 13,19.00
> 14,20.00
> 15,23.00
> 16,18.00
> 17,18.00
> 18,10.00
> 19,12.00
> 20,8.00
> 21,5.00
> 22,11.00
> 23,9.00
> 24,3.00
> 25,3.00
> 27,4.00
> 28,1.00
> 29,1.00
> 32,1.00
> 33,1.00
> 35,1.00
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From apjaworski at mmm.com  Mon May 19 20:51:19 2003
From: apjaworski at mmm.com (apjaworski@mmm.com)
Date: Mon, 19 May 2003 13:51:19 -0500
Subject: [R] updates of recommended packages
Message-ID: <OF6F985884.98BAFA3C-ON86256D2B.00635DE7@mmm.com>

I noticed recently that on my Linux install of 1.7.0 some of the
recommended packages got updated (through update.packages()) but on my
Win2000 machine they did not.  After some of them got updated for the
second time on the Linux box I become curious.  I went to the US CRAN
mirror and checked the 1.7 folder under contributed packages for Windows
systems and most of the recommended packages are not there at all!  I did
not check every one of them, but the missing ones are at least the ones
that got updated on my Linux machine.  They are class, cluster, nlme,
MASS/VR and spatial. Surprisingly, the foreign package is there, but its
version is 0.5-12 and the newest one is 0.5-13.

Is there a different method of updating recommended packages now?

Thanks in advance,

Andy

PS.  Additional info: (1) I am using the US CRAN mirror (Wisconsin
machine), but it looks like there is the same problem with the main CRAN
site. (2) On my Linux box the update.packages() works
from sources, but on the Windows box it wants precompiled packages (zip
files) unless.  I just updated nlme from nlme.tar.gz "by hand" but can this
be automated using update.packages() functionality.

__________________________________
Andy Jaworski
Engineering Systems Technology Center
3M Center, 518-1-01
St. Paul, MN 55144-1000
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122



From tblackw at umich.edu  Mon May 19 21:03:05 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Mon, 19 May 2003 15:03:05 -0400 (EDT)
Subject: [R] plotting a simple graph
In-Reply-To: <NGBBKJEMOMLJFCOIEGCEEECAJJAA.jonathan.williams@pharm.ox.ac.uk>
Message-ID: <Pine.SOL.4.44.0305191445360.15140-100000@rygar.gpcc.itd.umich.edu>

Jonathan  -

After  plot(...), points(...), newdat <- data.frame(...)
exactly as below, try

   lines(log(newdat$x1), predict(...), lty=1) .

and the same with  grp==1.  What I've done above is to pass the
x-coordinate explicitly to  lines()  since it is not present in
the return value from  predict().  Here's the logic:

Perhaps one difficulty is that the return value from  predict.lm()
is "a vector of predictions, or a matrix of predictions and bounds
... if 'interval' is set."  Quoting here from  help("predict.lm").

Thus,  lines(predict(...), lty=1)  never sees the contents of the
data frame  newdat  and so  lines()  does not know what x-coordinate
to use when plotting each entry of the vector returned by predict().
In this case,  lines()  uses its time-series methods and plots the
35 y-values given against the integers 1:35.  Is that what you see
on the screen ?

HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -


On Mon, 19 May 2003, Jonathan Williams wrote:

> I am having great difficulty plotting what should be a simple graph.
> I have measured 1 'y' and 5 'x' variables in each of two groups.
> Linear regression shows significant differences in the slopes of the
> regression for each 'x' variable between the two groups.
>
> All that I want to do is to plot one graph that shows the scatterplot
> for the three groups (each group represented by a different symbol),
> overlaid by the fitted regression lines for each group's relation
> between the 'x1' and 'y' variables, covarying the remaining four 'x'
> variables and adjusting them to their mean values.
>
> #All five of the grp*x interactions are significant in:
> fit1=lm(log(y)~grp*(log(x1)+log(x2)+log(x3)+log(x4)+log(x5))
> summary(fit1)
>
> #However, to avoid sending all of the data, I create dummy data-sets
> #that have distributions resembling the original variables (which are
> #very skewed, hence the log-transformations).
>
> grp<-c(rep(0,150),rep(1,200))
> y<-(rnorm(n=350,mean=8,sd=5)^1.15)+5
> x1<-((rnorm(n=350,mean=10,sd=5))+1)
> for (i in 1:350) {if (x1[i]<1 | x1[i]>20) x1[i]<-18}
> x2<-(rnorm(n=350,mean=20,sd=5)^2)
> x3<-(rnorm(n=350,mean=10,sd=3)^1.5)+50
> x4<-rnorm(n=350,mean=45,sd=2.5)
> x5<-rnorm(n=350,mean=2.4,sd=0.15)
>
> #So, what I want to do is to plot the regression lines of log(y) on
> #log(x1) for the three different groups, covarying grp, log(x2)...
> #log(x6)x6 and grp:log(x2)....grp:log(x6). This what I tried:-
>
> plot(log(x1)[grp==0],log(y)[grp==0],
> main='Differential relations between log(y) and log(x1) in 3 groups,
> adjusted for x2-x5',
> xlab='log(x1)', ylab='log(y)')
> newdat=data.frame(x1=seq(min(x1),max(x1),(max(x1)-min(x1))/10))
> points(log(x1)[grp==1],log(y)[grp==1],pch=3)
> lines(predict(lm(log(y)~log(x2)+log(x3)+log(x4)+log(x5),subset=grp==0),newda
> t),lty=1)
> lines(predict(lm(log(y)~log(x2)+log(x3)+log(x4)+log(x5),subset=grp==1),newda
> t),lty='dashed')
>
> This plots regression lines which have corners (which I think must be
> wrong!) and which
> bear no resemblance to the real regression lines (the lines are not very
> close to the points
> for the original data set).
>
> #if I specify the means of x variables x2 to x5, as follows:-
> newdat=data.frame(x1=seq(min(x1),max(x1),(max(x1)-min(x1))/10),x2=mean(x2),x
> 3=mean(x3),x4=mean(x4),x5=mean(x5))
> #then this gives 2 parallel horizontal regression lines, which is also
> incorrect
>
> Please could someone enlighten me on how to plot the regression lines?
> Thanks,
>
> Jonathan Williams
> OPTIMA
> Radcliffe Infirmary
> Woodstock Road
> OXFORD OX2 6HE
> Tel +1865 (2)24356
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From gc4 at duke.edu  Mon May 19 21:40:00 2003
From: gc4 at duke.edu (gc4@duke.edu)
Date: Mon, 19 May 2003 15:40:00 -0400 (EDT)
Subject: [R] survit function and cox model with frailty
Message-ID: <Pine.GSO.4.53.0305191538020.27821@godzilla2.acpub.duke.edu>

Hi:

I have a question about the use of the survfit function after the
estimation of a cox proportional hazard model with a frailty term. My goal
is to estimate expected survival probabilities while controlling for the
group-specific frailty term.

First, I estimate a model of the following form:


model1 <- coxph(Surv(t0, t, d) ~ x1 + x2 + frailty(id), na.action=na.exclude,
                data=My.data)


Then, I prepare a data frame:


temp <- data.frame(t0=c(0,365,730,1095,1460),
                   t=c(365,730,1095,1460,3000),
                   d=c(0,0,0,0,0),
                   x1=c(0,0,0,0,0),
                   x2=c(1.5,1.5,1.5,1.5,1.5))


I think I would need to enter a statement with respect to the frailty
term, but I don't know how.

Indeed, when I use the survit function with temp data frame, I get an
error message:

> fit2 <- survfit(model1, newdata=temp, individual=TRUE)
Error in model.frame(formula, rownames, variables, varnames, extras,
extranames,  :
        variable lengths differ


Thank you very much,
giacomo



From ligges at statistik.uni-dortmund.de  Mon May 19 22:05:41 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 19 May 2003 22:05:41 +0200
Subject: [R] R doesn't support 3D histograms?
References: <Pine.LNX.4.44.0305191452450.18816-200000@pcatd37.cern.ch>
Message-ID: <3EC93915.CC5AA817@statistik.uni-dortmund.de>

Andre DOS ANJOS wrote:
> 
> Hi,
> 
>         I've been using R since a while now to make 2D histograms. I have
> some data (appended) that would like to use to make a 3-D plot with x being
> the first variable in the file, y the second and the height, or z the third
> variable. How can I do it in R? I would like to have 3-D visualization of
> this plot. Preferably as a lego plot, that is, a set of stacks that grow
> with respect to the value of z, which have their delta x and delta y lengths
> equivalent to the spacings between the values of x and y. Other people also
> call it a 3-D histogram.
> 
>         Regards, Andre.

I don't know of such a function. You could try to "hack" you on function
around others, like cloud() in package lattice or scatterplot3d() in the
identically called package. Neither way will be easy or even very
promising.
As always, contributions are welcome, but if you are just going to
produce a few of these plots, I'd suggest to switch to another software
for that purpose.

Uwe Ligges



From umalvarez at fata.unam.mx  Mon May 19 21:19:12 2003
From: umalvarez at fata.unam.mx (Ulises Mora Alvarez)
Date: Mon, 19 May 2003 14:19:12 -0500 (CDT)
Subject: [R] Compile R-1.7.0 on Mac OS 10.2.6
In-Reply-To: <8C5B3F75-86B5-11D7-B569-000393DC1748@ic.ac.uk>
Message-ID: <Pine.LNX.4.44.0305191406490.1934-100000@fata.unam.mx>

Hi!

Your log file clearly indicates that  /sw/lib/libiconv.2.dylib is missing. 
You may want to verify with 'ls /sw/lib/libiconv.2.dylib'

If your library is missing I'll recommend to reinstall  again g77 and gcc. 
You may want to use the binaries instead of the sources to save some time. 
I'll also recommend to install finkcommander 
(finkcommander.sourceforge.net) 

Regards.


On Thu, 15 May 2003, David Orme wrote:

> Hi,
> 
> I can't get R-1.7.0 to compile on my Mac. Can someone give me some 
> pointers?
> 
> The machine is an 800MHz iBook running OS 10.2.6. I have installed the 
> December 2002 Developers Tools and have installed g77, f2c and dlcompat 
> via fink. I've checked the versions of g77 and gcc and they're both 
> based on gcc version 3.1. I've got Apple's X11 (Beta 3). I've added 
> /sw/bin to my path. I've read through R-admin.pdf, particularly the 
> appendix on OS X.
> 
> The problem seems to be something to do with the fortran compiler. The 
> final lines of the configure output are:
> 
> > checking how to get verbose linking output from g77... configure: 
> > WARNING: compilation failed
> >
> > checking for Fortran 77 libraries...
> > checking for dummy main to link with Fortran 77 libraries... none
> > checking for Fortran 77 name-mangling scheme... configure: error: 
> > cannot compile a simple Fortran program
> > See `config.log' for more details.
> 
> Checking config.log, both the warning and error are associated with the 
> following message:
> 
> > dyld: g77 version mismatch for library: /sw/lib/libiconv.2.dylib 
> > (compatibility version of user: 4.0.0 greater than library's version: 
> > 3.0.0)
> 
> Can anyone help?
> 
> Many thanks,
> David
> ---------------------------------------
> Dr. David Orme
> 
> Department of Biological Sciences
> Imperial College London
> Silwood Park Campus
> Ascot, Berkshire SL5 7PY UK.
> 
> Tel: +44 (0)20 759 42358
> Fax: +44 (0)20 759 42339
> e-mail: d.orme at imperial.ac.uk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Ulises M. Alvarez
LAB. DE ONDAS DE CHOQUE
FISICA APLICADA Y TECNOLOGIA AVANZADA
UNAM
umalvarez at fata.unam.mx



From dmurdoch at pair.com  Mon May 19 22:19:50 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon, 19 May 2003 16:19:50 -0400
Subject: [R] Windows binary corrupt
In-Reply-To: <5.1.1.2.2.20030517161010.00a8dae8@pop4.attglobal.net>
References: <5.1.1.2.2.20030517161010.00a8dae8@pop4.attglobal.net>
Message-ID: <9veicvol93i8j15smqfn9rdfa2tr3l2ckr@4ax.com>

On Sat, 17 May 2003 16:15:02 -0700, you wrote:

>I've tried to download the Windows 1.7.0 binary from three different 
>mirrors today.  Each time the binary comes down corrupt - MD 5 sums don't 
>check and the installer reports that its own setup files are corrupt.
>
>Since I've tried from different computers and different connections, I have 
>to assume a problem downstream from me.
>
>Has anyone else reported this problem?  Has the binary changed at all since 
>it was posted back in April?
>
>BTW, I haven't encountered this before when I've downloaded the 1.7.0 
>Windows binary immediately following its release.

I haven't changed the binary.  I've just downloaded a copy, and it was
fine.  I don't know what would be going wrong for you, but you might
want to try R-patched instead:  I've got a build on my web page,
<http://www.stats.uwo.ca/faculty/murdoch/software/r-devel>.  You want
rw1070pat.exe.  

Duncan Murdoch



From dmurdoch at pair.com  Mon May 19 22:20:05 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon, 19 May 2003 16:20:05 -0400
Subject: [R] R doesn't support 3D histograms?
In-Reply-To: <Pine.LNX.4.44.0305191452450.18816-200000@pcatd37.cern.ch>
References: <Pine.LNX.4.44.0305191452450.18816-200000@pcatd37.cern.ch>
Message-ID: <mpdicvc0kfk4ao6i840stkvpb7mnj5boqf@4ax.com>

On Mon, 19 May 2003 14:58:07 +0200 (CEST), you wrote:

>Hi,
>
>	I've been using R since a while now to make 2D histograms. I have 
>some data (appended) that would like to use to make a 3-D plot with x being 
>the first variable in the file, y the second and the height, or z the third
>variable. How can I do it in R? I would like to have 3-D visualization of 
>this plot. Preferably as a lego plot, that is, a set of stacks that grow 
>with respect to the value of z, which have their delta x and delta y lengths 
>equivalent to the spacings between the values of x and y. Other people also 
>call it a 3-D histogram.

There are some 3D contributed packages available.  Mine (djmrgl) has a
function called hist3d() that might do what you want.  It's available
for Windows only from my web page
<http://www.stats.uwo.ca/faculty/murdoch/software>  One of my projects
for the summer is to merge djmrgl with the other OpenGL project by
Daniel Adler; then (and possibly now) a cross-platform 3D histogram
will be available.

Duncan Murdoch



From Jesse.Whittington at pc.gc.ca  Mon May 19 23:52:14 2003
From: Jesse.Whittington at pc.gc.ca (Jesse.Whittington@pc.gc.ca)
Date: Mon, 19 May 2003 15:52:14 -0600
Subject: [R] multcomp and glm
Message-ID: <OFDC6514CA.095BAC24-ON87256D2B.00760E02@apca.gc.ca>

I have run the following logistic regression model:

options(contrasts=c("contr.treatment", "contr.poly"))
m <- glm(wolf.cross ~ null.cross + feature, family = "binomial")

where:
wolf.cross = likelihood of wolves crossing a linear feature
null.cross = proportion of random paths that crossed a linear feature
feature = CATEGORY of linear feature with 5 levels: high-use road, low-use
road, high-use trail, low-use trail, and railway line

I would like to determine whether wolves are more likely to cross some
features than others and am using csimtest in the package multcomp to do
so.

x <- coef(model)
var.cov <- vcov(model)
df <- model$df.residual
contrast.matrix <- contrMat(rep(2,length(x), type = "Tukey")
post.hoc <- csimtest(estpar = x, df=df, covm = var.cov, cmatrix =
contrast.matrix)
summary(post.hoc)

My questions are:
(1) Have I entered my parameters for the posthoc analysis correctly and
does it matter which categorical variable I use as my reference category?

(2) How do I omit the continuous variable "null.cross" from the list of
multiple comparisons?

I would be most grateful for any assistance you can give me,
Jesse Whittington


Jasper National Park
Box 10,
Jasper, Alberta
Canada
(780) 852-6187



From ross at biostat.ucsf.edu  Tue May 20 00:43:29 2003
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Mon, 19 May 2003 22:43:29 -0000
Subject: [R] R CMD check creates a syntax error
Message-ID: <1053384167.25496.69.camel@epibiosun115-4>

Using R Version 1.6.2  (2003-01-10) I did R CMD check.  The package I
was checking includes an .Rd file with an example.

My package test directory included a file foo-Ex.R whose first line was
WARNING: ignoring environment value of R_HOME

There are some problems with this:
1. R_HOME is not set.
2. The line is a syntax error, causing the test to fail.

Furthermore, I got this warning message a lot in my transcript while
check was running.

Could anyone explain what is going on, or how to get around this?

Thanks.

P.S. 
http://r-bugs.biostat.ku.dk/cgi-bin/R/feature%26FAQ?id=1284;expression=WARNING:%20ignoring%20environment%20value%20of%20R_HOME;user=guest#themesg
appears related, but it says the error message arises from having R_HOME
set when it shouldn't be.  I haven't set it, as far as I can tell. 
Could it be somehow set inside my default R environment?
-- 
Ross Boylan <ross at biostat.ucsf.edu>              wk: (415) 502-4031
University of California, San Francisco         fax: (415) 476-9856
Dept of Epidemiology and Biostatistics           hm: (415) 550-1062
530 Parnassus Avenue (Library) rm 115-4
San Francisco, CA 94143-0840



From tblackw at umich.edu  Tue May 20 02:40:01 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Mon, 19 May 2003 20:40:01 -0400 (EDT)
Subject: [R] survit function and cox model with frailty
In-Reply-To: <Pine.GSO.4.53.0305191538020.27821@godzilla2.acpub.duke.edu>
Message-ID: <Pine.SOL.4.44.0305192034270.11423-100000@millipede.gpcc.itd.umich.edu>

Giacomo  -

Here's just a guess, since I have no experience with this.
Try adding a sixth variable to the data frame "temp", a
variable named "id" with value c(1,1,1,1,1).  Maybe that
will do it ?   This is consistent with your intention in
setting individual=TRUE, and it will give the frailty()
term that's already in the model something to work with.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Mon, 19 May 2003 gc4 at duke.edu wrote:

> Hi:
>
> I have a question about the use of the survfit function after the
> estimation of a cox proportional hazard model with a frailty term. My goal
> is to estimate expected survival probabilities while controlling for the
> group-specific frailty term.
>
> First, I estimate a model of the following form:
>
> model1 <- coxph(Surv(t0, t, d) ~ x1 + x2 + frailty(id), na.action=na.exclude,
>                 data=My.data)
>
> Then, I prepare a data frame:
>
> temp <- data.frame(t0=c(0,365,730,1095,1460),
>                    t=c(365,730,1095,1460,3000),
>                    d=c(0,0,0,0,0),
>                    x1=c(0,0,0,0,0),
>                    x2=c(1.5,1.5,1.5,1.5,1.5))
>
> I think I would need to enter a statement with respect to the frailty
> term, but I don't know how.
>
> Indeed, when I use the survit function with temp data frame, I get an
> error message:
>
> > fit2 <- survfit(model1, newdata=temp, individual=TRUE)
> Error in model.frame(formula, rownames, variables, varnames, extras,
> extranames,  :
>         variable lengths differ
>
> Thank you very much,
> giacomo
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From gc4 at duke.edu  Tue May 20 03:55:06 2003
From: gc4 at duke.edu (gc4@duke.edu)
Date: Mon, 19 May 2003 21:55:06 -0400 (EDT)
Subject: [R] survit function and cox model with frailty
In-Reply-To: <Pine.SOL.4.44.0305192034270.11423-100000@millipede.gpcc.itd.umich.edu>
References: <Pine.SOL.4.44.0305192034270.11423-100000@millipede.gpcc.itd.umich.edu>
Message-ID: <Pine.GSO.4.53.0305192141320.4232@godzilla1.acpub.duke.edu>

Hi:

I have followed through Thomas' suggestions, but unfortunately, to no
avail. I added a statement identifying the id group variable to the temp
data frame which I feed into the survfit function.

temp <- data.frame(t0=c(0,365,730,1095,1460),
                   t=c(365,730,1095,1460,3000),
                   d=c(0,0,0,0,0),
                   x1=c(0,0,0,0,0),
                   x2=c(1.5,1.5,1.5,1.5,1.5),
                   id=c(1,1,1,1,1))

However, I obtain the following error message:

fit2 <- survfit(model1, newdata=temp, individual=TRUE)
Error in x2 %*% coef : non-conformable arguments

The survfit function seems to be looking for a coefficient for the frailty
term, which, of course, is not there given that:
  h(t)=h0(t)*a*exp(Xb), where a is the frailty term.

I also tried to add a "frail(id)"=c(1,1,1,1,1) line to the statement
that creates the temp data frame. But, again, I obtain the following error
message:

> fit2 <- survfit(model3, newdata=temp, individual=TRUE)
Error in model.frame(formula, rownames, variables, varnames, extras,
extranames,  :
        variable lengths differ

Thank you very much for any suggestions. Thanks, in particular, to Thomas.
giacomo

On Mon, 19 May 2003, Thomas W Blackwell wrote:

> Giacomo  -
>
> Here's just a guess, since I have no experience with this.
> Try adding a sixth variable to the data frame "temp", a
> variable named "id" with value c(1,1,1,1,1).  Maybe that
> will do it ?   This is consistent with your intention in
> setting individual=TRUE, and it will give the frailty()
> term that's already in the model something to work with.
>
> -  tom blackwell  -  u michigan medical school  -  ann arbor  -
>



From andy_liaw at merck.com  Tue May 20 06:56:32 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 20 May 2003 00:56:32 -0400
Subject: [R] derivatives from loess (not locpoly)?
Message-ID: <3A822319EB35174CA3714066D590DCD5C4FB28@usrymx25.merck.com>

A possible alternative is locfit(..., deriv=...) (in package `locfit'), as
described in Section 6.1 of Loader's "Local Regression and Likelihood".

Andy

> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> Sent: Sunday, May 18, 2003 3:12 AM
> To: J S
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] derivatives from loess (not locpoly)?
> 
> 
> Not easily. Unlike locpoly (in KernSmooth, uncredited), loess uses a 
> locally varying bandwidth and that would need to be taken 
> into account in 
> determining the derivative.  The underlying Fortran code does 
> not have any 
> support for this.
> 
> On Sat, 17 May 2003, J S wrote:
> 
> > is there a way of estimating derivative curves, similar to 
> the ones we
> > get from 'locpoly', from 'loess' estimation.
> 
> >  i am interested in estimation of 1st and 2nd derivatives...
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From Torsten.Hothorn at rzmail.uni-erlangen.de  Tue May 20 08:48:31 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Tue, 20 May 2003 08:48:31 +0200 (CEST)
Subject: [R] multcomp and glm
In-Reply-To: <OFDC6514CA.095BAC24-ON87256D2B.00760E02@apca.gc.ca>
References: <OFDC6514CA.095BAC24-ON87256D2B.00760E02@apca.gc.ca>
Message-ID: <Pine.LNX.4.51.0305200824040.14483@artemis.imbe.med.uni-erlangen.de>


> I have run the following logistic regression model:
>
> options(contrasts=c("contr.treatment", "contr.poly"))
> m <- glm(wolf.cross ~ null.cross + feature, family = "binomial")
>
> where:
> wolf.cross = likelihood of wolves crossing a linear feature
> null.cross = proportion of random paths that crossed a linear feature
> feature = CATEGORY of linear feature with 5 levels: high-use road, low-use
> road, high-use trail, low-use trail, and railway line
>
> I would like to determine whether wolves are more likely to cross some
> features than others and am using csimtest in the package multcomp to do
> so.
>
> x <- coef(model)
> var.cov <- vcov(model)
> df <- model$df.residual
> contrast.matrix <- contrMat(rep(2,length(x), type = "Tukey")
> post.hoc <- csimtest(estpar = x, df=df, covm = var.cov, cmatrix =
> contrast.matrix)
> summary(post.hoc)
>

0) you should use asympt = TRUE for a logistic regression model, that is
using the asymptotic join multivariate normal distribution of the
estimated parameters instead of the t-distribution. This will NOT work
with `csimtest' because of a bug that will be fixed in the next release
(but `csimint' will do).

> My questions are:
> (1) Have I entered my parameters for the posthoc analysis correctly and
> does it matter which categorical variable I use as my reference category?
>

I think there are some problems here.

> x <- coef(model)
> var.cov <- vcov(model)

will tell you about ALL estimated parameters, that is: intercept,
null.cross and the 4 treatment contrasts for factor feature.

> contrast.matrix <- contrMat(rep(2,length(x), type = "Tukey")

will compute the contrasts for ALL parameters and I guess you would like
to have it for the levels of `feature' only.

As I pointed out in the last email thread on "Multiple comparison and
lme (again, sorry)" (r-help, May 14th), I can't see any `high-level' way
to compute Tukey contrasts and the corresponding convariance matrix
except doing the (model dependent) calculations by `hand' because you
can't estimate all parameters due to a design matrix with reduced rank.

The basic problem is that the S `contrasts' function (and all
model.fit functions) implicitly assume that there are at most k-1
contrasts for a factor at k levels, something that does not
cover Tukey contrasts.

Anyway, Tukey contrasts would implement all-pair comparisons, that is
comparing every combination of levels of `feature'. Is this really your
question?

> (2) How do I omit the continuous variable "null.cross" from the list of
> multiple comparisons?
>

just omit it from x and var.cov (maybe you should omit the intercept,
too):

csimint(estpar = x[-(1:2)], covm = var.cov[-(1:2),-(1:2)], cmatrix =
        diag(4), asympt = TRUE)

will give you simultaneous CI's for the treatment contrasts of `feature'.

There will be high-level functions for those problems in the next
release with some examples (and I can send you the current state,
if you like).

Best,

Torsten

> I would be most grateful for any assistance you can give me,
> Jesse Whittington
>
>
> Jasper National Park
> Box 10,
> Jasper, Alberta
> Canada
> (780) 852-6187
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>



From mitsu5 at ruby.famille.ne.jp  Tue May 20 09:37:27 2003
From: mitsu5 at ruby.famille.ne.jp (Mitsuo Igarashi)
Date: Tue, 20 May 2003 16:37:27 +0900
Subject: [R] How to use pakcage SEM
Message-ID: <200305200737.h4K7bXqx003015@mp2.vectant.ne.jp>

Hi.

I have tried to use Package "SEM".

As a learning, I try to convert a program running well of EQS 
which is as follows to SEM:

###  EQS  ###
/SPECIFICATION
CAS=100; VAR=5 MAT=COR; ANA=COR;
/EQUATIONS
V1=*F1+E1; V2=*F1+E2; V3=*F1+*F2+E3; V4=**F1+*F2*E4;
V5=*F2+E5;
/VAR
E1 TO E5=*; F1*1.0; F2=1.0;
/COV
E1,E2=*; F1,F2=*:
/PRINT
FIT ALL;
/MATRIX ......
/END

This is the converted SEM program.
###
data.mh<-matrix(c(
1.00,0,0,0, 0,
0.38,1.00,0,0, 0,
0.52,0.28,1.00,0,0,
0.55,0.32,0.38,1.00,0,
0.36,0.40,0.48,0.31,1.00
),ncol=5,byrow=T)

model.mh<-matrix(c(
	'F1 -> V1', 'a1',NA,
	'F1 -> V3', 'a3',NA,
	'F1 -> V4', 'a4',NA,
	'F2 -> V2', 'b2',NA,
	'F2 -> V3', 'b3',NA,
	'F2 -> V4', 'b4',NA,
	'F2 -> V5', 'b5',NA,
	'V1 <-> V1','e1', 1,
	'V2 <-> V2','e2', 1,
	'V3 <-> V3','e3', 1,
	'V4 <-> V4','e4', 1,
	'V5 <-> V5','e5', 1,
	'F1 <-> F1','d1', 1,
	'F2 <-> F2','d2', 1,
	'F1 <-> F2','c12',NA,
	'V1 <-> V2','cv1', NA,
),ncol=3,byrow=T)
obs.vars.mh <- c('V1','V2','V3','V4','V5')
rownames(data.mh) <- colnames(data.mh) <- obs.vars.mh

sem.mh <- sem(model.mh, data.mh, 100)
###

At this stage, everything looks going well.
By debug mode of "sem()" it finishes with no error.
However,the process of "summary(sem.mh)" produces an error.

> summary(sem.mh)
Error in optim(0, function(lam) ((1 - conf.level)/2 - pchisq(chisq, df,  : 
        Function cannot be evaluated at initial parameters
In addition: Warning message: 
NaNs produced in: sqrt(diag(object$cov)) 

It seems to me that there is something wrong at the conversion of 
"E1 TO E5=*;"  to " 'V1 <-> V2','cv1', NA ".

Could anyone explain me how to manage this trouble?

Thanks.

--------========----------
Mitsuo Igarashi
mitsu5 at ruby.famille.ne.jp



From Ulf.Martin at student.uni-magdeburg.de  Tue May 20 09:43:59 2003
From: Ulf.Martin at student.uni-magdeburg.de (Ulf Martin)
Date: Tue, 20 May 2003 09:43:59 +0200
Subject: [R] surprising behaviour of "bgroup": sets all in greek letters
Message-ID: <1053416639.3ec9dcbfb9489@webmail.uni-magdeburg.de>

Dear R user community

I wanted to use "bgroup" for plotting a math formula with
a big "{" on the left, and nothing on the right.
i used

  text( 10, 10, pos=4, cex=1.8, expression(F(x) == bgroup("{", x, "")), ...)

on a 40 x 20 plot.
surprisingly,
bgroup sets "Phi(xi) = { xi" 
i.e. replaces alphabetic characters with greek letters in the entire formula.

I tried out other ending delimiters instead of "":
With " ", ":", ";", ",", R complains about an "invalid group delimiter",
With "." R produces greek letters again.

Is this a bug, or am I missing something?
How could I possibly accomplish my original task?
The idea is to have something like

          0 if x<0
 F(x) = {
          y otherwise

in the end.

Thanks in advance!
(and for the great tool anyway!)

(I am not currently subscribed to the r-help list,
so I would be gratful if anybody could answer me directly too, thanks!)

Bye
-- 
ulf martin
ulf.martin at gmx.net



From reid at ifom-firc.it  Tue May 20 09:44:14 2003
From: reid at ifom-firc.it (James F. Reid)
Date: Tue, 20 May 2003 09:44:14 +0200
Subject: [R] R-1.7.0 'make check' fails on reg-tests-1
Message-ID: <3EC9DCCE.3090008@ifom-firc.it>

Dear all,

I am trying to upgrade R-1.6.2 to R-1.7.0 on an SGI running IRIX6.5.

Everything compiles but I get an error in the testing phase:

[snip]
running regression tests
make[3]: Entering directory `/usr/local/src/R-1.7.0/tests'
running code in 'reg-tests-1.R' ...make[3]: *** [reg-tests-1.Rout] Error 1
make[3]: Leaving directory `/usr/local/src/R-1.7.0/tests'
make[2]: *** [test-Reg] Error 2
make[2]: Leaving directory `/usr/local/src/R-1.7.0/tests'
make[1]: *** [test-all-basics] Error 1
make[1]: Leaving directory `/usr/local/src/R-1.7.0/tests'
make: *** [check] Error 2

this is the part in reg-tests-1.Rout.fail which fails:

 > ## fft
 > set.seed(123)
 > eps <- 1e-11
 > for(N in 1:130) {
+     x <- rnorm(N)
+     if(N %% 5 == 0) {
+       m5 <- matrix(x,ncol=5)
+       stopifnot(apply(m5,2,fft) == mvfft(m5))
+     }
+     dd <- Mod(1 - (f2 <- fft(fft(x), inverse=TRUE)/(x*length(x))))
+     stopifnot(dd < eps)
+ }


Any help concerning this matter would be very much appreciated.

Best regards,
James Reid.



From ripley at stats.ox.ac.uk  Tue May 20 10:10:55 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 20 May 2003 09:10:55 +0100 (BST)
Subject: [R] R-1.7.0 'make check' fails on reg-tests-1
In-Reply-To: <3EC9DCCE.3090008@ifom-firc.it>
Message-ID: <Pine.LNX.4.44.0305200906480.2860-100000@gannet.stats>

You appear to have a problem with the accuracy of the arithmetic on that
machine. Please run the test by hand and tell us what N and max(dd) are
when the test fails (or is it the mvftt test?)

The test is not new, but the change in random-number generator will affect 
what values are tested.

On Tue, 20 May 2003, James F. Reid wrote:

> Dear all,
> 
> I am trying to upgrade R-1.6.2 to R-1.7.0 on an SGI running IRIX6.5.
> 
> Everything compiles but I get an error in the testing phase:
> 
> [snip]
> running regression tests
> make[3]: Entering directory `/usr/local/src/R-1.7.0/tests'
> running code in 'reg-tests-1.R' ...make[3]: *** [reg-tests-1.Rout] Error 1
> make[3]: Leaving directory `/usr/local/src/R-1.7.0/tests'
> make[2]: *** [test-Reg] Error 2
> make[2]: Leaving directory `/usr/local/src/R-1.7.0/tests'
> make[1]: *** [test-all-basics] Error 1
> make[1]: Leaving directory `/usr/local/src/R-1.7.0/tests'
> make: *** [check] Error 2
> 
> this is the part in reg-tests-1.Rout.fail which fails:
> 
>  > ## fft
>  > set.seed(123)
>  > eps <- 1e-11
>  > for(N in 1:130) {
> +     x <- rnorm(N)
> +     if(N %% 5 == 0) {
> +       m5 <- matrix(x,ncol=5)
> +       stopifnot(apply(m5,2,fft) == mvfft(m5))
> +     }
> +     dd <- Mod(1 - (f2 <- fft(fft(x), inverse=TRUE)/(x*length(x))))
> +     stopifnot(dd < eps)
> + }
> 
> 
> Any help concerning this matter would be very much appreciated.
> 
> Best regards,
> James Reid.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From reid at ifom-firc.it  Tue May 20 10:23:04 2003
From: reid at ifom-firc.it (James F. Reid)
Date: Tue, 20 May 2003 10:23:04 +0200
Subject: [R] R-1.7.0 'make check' fails on reg-tests-1
References: <Pine.LNX.4.44.0305200906480.2860-100000@gannet.stats>
Message-ID: <3EC9E5E8.2090806@ifom-firc.it>

Thank you very much for your prompt response.

This is what I get when I run the test by hand.

 >max(dd)
[1] 2.136917e-11
 > N
[1] 111

I don't think it's the mvftt because that loop goes through fine.

Regards,
James Reid.

Prof Brian Ripley wrote:
> You appear to have a problem with the accuracy of the arithmetic on that
> machine. Please run the test by hand and tell us what N and max(dd) are
> when the test fails (or is it the mvftt test?)
> 
> The test is not new, but the change in random-number generator will affect 
> what values are tested.
> 
> On Tue, 20 May 2003, James F. Reid wrote:
> 
> 
>>Dear all,
>>
>>I am trying to upgrade R-1.6.2 to R-1.7.0 on an SGI running IRIX6.5.
>>
>>Everything compiles but I get an error in the testing phase:
>>
>>[snip]
>>running regression tests
>>make[3]: Entering directory `/usr/local/src/R-1.7.0/tests'
>>running code in 'reg-tests-1.R' ...make[3]: *** [reg-tests-1.Rout] Error 1
>>make[3]: Leaving directory `/usr/local/src/R-1.7.0/tests'
>>make[2]: *** [test-Reg] Error 2
>>make[2]: Leaving directory `/usr/local/src/R-1.7.0/tests'
>>make[1]: *** [test-all-basics] Error 1
>>make[1]: Leaving directory `/usr/local/src/R-1.7.0/tests'
>>make: *** [check] Error 2
>>
>>this is the part in reg-tests-1.Rout.fail which fails:
>>
>> > ## fft
>> > set.seed(123)
>> > eps <- 1e-11
>> > for(N in 1:130) {
>>+     x <- rnorm(N)
>>+     if(N %% 5 == 0) {
>>+       m5 <- matrix(x,ncol=5)
>>+       stopifnot(apply(m5,2,fft) == mvfft(m5))
>>+     }
>>+     dd <- Mod(1 - (f2 <- fft(fft(x), inverse=TRUE)/(x*length(x))))
>>+     stopifnot(dd < eps)
>>+ }
>>
>>
>>Any help concerning this matter would be very much appreciated.
>>
>>Best regards,
>>James Reid.
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
> 
>



From marc.schroeder at iaew.rwth-aachen.de  Tue May 20 10:45:07 2003
From: marc.schroeder at iaew.rwth-aachen.de (Marc Schroeder)
Date: Tue, 20 May 2003 10:45:07 +0200
Subject: [R] modell time series with AR-Garch modell
Message-ID: <3EC9EB13.9070805@iaew.rwth-aachen.de>

 Hi R-community!

Is there a possibility in R to model a time series with a so called AR-GARCH
process? AR-GARCH is a composite modell consisting of an autoregressive
process with an GARCH error term.

Thanks in advance
Marc



From d.orme at imperial.ac.uk  Tue May 20 10:59:10 2003
From: d.orme at imperial.ac.uk (David Orme)
Date: Tue, 20 May 2003 09:59:10 +0100
Subject: [R] Compile R-1.7.0 on Mac OS 10.2.6
In-Reply-To: <Pine.LNX.4.44.0305191406490.1934-100000@fata.unam.mx>
Message-ID: <520FF7EC-8AA1-11D7-9965-000393DC1748@ic.ac.uk>

Hi,

Thanks for the suggestion but that isn't it. The library is there...

> [doibook:~] dorme% ls /sw/lib/libiconv.2.dylib
> /sw/lib/libiconv.2.dylib

... but something about the library version is wrong. My version of g77 
was freshly (last week) installed from source using finkcommander; I'm 
using the December 2002 Apple Developer Tools version of gcc.

David

On Monday, May 19, 2003, at 08:19  pm, Ulises Mora Alvarez wrote:

> Hi!
>
> Your log file clearly indicates that  /sw/lib/libiconv.2.dylib is 
> missing.
> You may want to verify with 'ls /sw/lib/libiconv.2.dylib'
>
> If your library is missing I'll recommend to reinstall  again g77 and 
> gcc.
> You may want to use the binaries instead of the sources to save some 
> time.
> I'll also recommend to install finkcommander
> (finkcommander.sourceforge.net)
>
> Regards.
>
>
> On Thu, 15 May 2003, David Orme wrote:
>
>> Hi,
>>
>> I can't get R-1.7.0 to compile on my Mac. Can someone give me some
>> pointers?
>>
>> The machine is an 800MHz iBook running OS 10.2.6. I have installed the
>> December 2002 Developers Tools and have installed g77, f2c and 
>> dlcompat
>> via fink. I've checked the versions of g77 and gcc and they're both
>> based on gcc version 3.1. I've got Apple's X11 (Beta 3). I've added
>> /sw/bin to my path. I've read through R-admin.pdf, particularly the
>> appendix on OS X.
>>
>> The problem seems to be something to do with the fortran compiler. The
>> final lines of the configure output are:
>>
>>> checking how to get verbose linking output from g77... configure:
>>> WARNING: compilation failed
>>>
>>> checking for Fortran 77 libraries...
>>> checking for dummy main to link with Fortran 77 libraries... none
>>> checking for Fortran 77 name-mangling scheme... configure: error:
>>> cannot compile a simple Fortran program
>>> See `config.log' for more details.
>>
>> Checking config.log, both the warning and error are associated with 
>> the
>> following message:
>>
>>> dyld: g77 version mismatch for library: /sw/lib/libiconv.2.dylib
>>> (compatibility version of user: 4.0.0 greater than library's version:
>>> 3.0.0)
>>
>> Can anyone help?
>>
>> Many thanks,
>> David
>> ---------------------------------------
>> Dr. David Orme
>>
>> Department of Biological Sciences
>> Imperial College London
>> Silwood Park Campus
>> Ascot, Berkshire SL5 7PY UK.
>>
>> Tel: +44 (0)20 759 42358
>> Fax: +44 (0)20 759 42339
>> e-mail: d.orme at imperial.ac.uk
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
>
> -- 
> Ulises M. Alvarez
> LAB. DE ONDAS DE CHOQUE
> FISICA APLICADA Y TECNOLOGIA AVANZADA
> UNAM
> umalvarez at fata.unam.mx
>



From petr.pikal at precheza.cz  Tue May 20 11:51:56 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue, 20 May 2003 11:51:56 +0200
Subject: [R] plot POSIX class and identify
Message-ID: <3ECA16DC.22046.EE922F@localhost>

Hallo all
just a small question I did not find an answer in help pages.

Is it possible to use identify() after plotting with plot.POSIX to 
label points and/or to find out some points?

Thanks a lot.
Best regards

Petr Pikal
petr.pikal at precheza.cz
p.pik at volny.cz



From ligges at statistik.uni-dortmund.de  Tue May 20 12:10:07 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 20 May 2003 12:10:07 +0200
Subject: [R] plot POSIX class and identify
In-Reply-To: <3ECA16DC.22046.EE922F@localhost>
References: <3ECA16DC.22046.EE922F@localhost>
Message-ID: <3EC9FEFF.7050401@statistik.uni-dortmund.de>

Petr Pikal wrote:
> Hallo all
> just a small question I did not find an answer in help pages.
> 
> Is it possible to use identify() after plotting with plot.POSIX to 

Hmmm. There is not method plot.POSIX, but there are plot.POSIXct and 
plot.POSIXlt.

> label points and/or to find out some points?

identify() works as expected, just use it. You need to convert POSIXlt 
objects to POSIXct objects before.

Uwe Ligges

> Thanks a lot.
> Best regards
> 
> Petr Pikal
> petr.pikal at precheza.cz
> p.pik at volny.cz



From ligges at statistik.uni-dortmund.de  Tue May 20 12:12:59 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 20 May 2003 12:12:59 +0200
Subject: [R] surprising behaviour of "bgroup": sets all in greek letters
In-Reply-To: <1053416639.3ec9dcbfb9489@webmail.uni-magdeburg.de>
References: <1053416639.3ec9dcbfb9489@webmail.uni-magdeburg.de>
Message-ID: <3EC9FFAB.5010800@statistik.uni-dortmund.de>

Ulf Martin wrote:
> Dear R user community
> 
> I wanted to use "bgroup" for plotting a math formula with
> a big "{" on the left, and nothing on the right.
> i used
> 
>   text( 10, 10, pos=4, cex=1.8, expression(F(x) == bgroup("{", x, "")), ...)
> 
> on a 40 x 20 plot.
> surprisingly,
> bgroup sets "Phi(xi) = { xi" 
> i.e. replaces alphabetic characters with greek letters in the entire formula.
> 
> I tried out other ending delimiters instead of "":
> With " ", ":", ";", ",", R complains about an "invalid group delimiter",
> With "." R produces greek letters again.
> 
> Is this a bug, or am I missing something?
> How could I possibly accomplish my original task?
> The idea is to have something like
> 
>           0 if x<0
>  F(x) = {
>           y otherwise
> 
> in the end.
> 
> Thanks in advance!
> (and for the great tool anyway!)
> 
> (I am not currently subscribed to the r-help list,
> so I would be gratful if anybody could answer me directly too, thanks!)
> 
> Bye

Looks like a bug. I'll investigate further within the next couple of 
days (except anyone else comes up with the right idea before).

Uwe Ligges



From sjtr at ceh.ac.uk  Tue May 20 12:21:15 2003
From: sjtr at ceh.ac.uk (Stephen Thackeray)
Date: Tue, 20 May 2003 11:21:15 +0100
Subject: [R] Sorting in data frames
Message-ID: <seca0fb8.019@wpo.nerc.ac.uk>

Hi, 

Is it possible to sort the rows within a data frame, with respect to
the values in one or more of the columns? For example, if I had measured
water temperatures at differenrt depths within a lake, on different
sampling dates and had a dataframe containing sampling dates (x),
sampling depths (y) and data for each day-depth combination (z), would
it be possible to rearrange the data frame so that it is sorted by day
and then by depth? 

Best wishes

Steve Thackeray



From ripley at stats.ox.ac.uk  Tue May 20 12:29:11 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 20 May 2003 11:29:11 +0100 (BST)
Subject: [R] plot POSIX class and identify
In-Reply-To: <3ECA16DC.22046.EE922F@localhost>
Message-ID: <Pine.LNX.4.44.0305201123060.9805-100000@gannet.stats>

On Tue, 20 May 2003, Petr Pikal wrote:

> just a small question I did not find an answer in help pages.
> 
> Is it possible to use identify() after plotting with plot.POSIX to 
> label points and/or to find out some points?

Yes.  Try it, it works!

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ida.scheel at nr.no  Tue May 20 12:31:01 2003
From: ida.scheel at nr.no (Ida Scheel)
Date: Tue, 20 May 2003 12:31:01 +0200
Subject: [R] Allocation problem
Message-ID: <3ECA03E5.7020702@nr.no>

Hi,

I have a problem when using R1.7.0. I have a very large dataset, but I 
also have access to 24GB RAM on a super-computer. Nevertheless, when 
using the "lme"-function  I get the error message

Error: cannot allocate vector of size 224295 Kb

As I understand it, the default is that there is no memory-limit in R 
other than machine resources, but somehow R does not get acces to the 
24GB of RAM I have available.

Does anyone have a tip? I have tried

Ida



From azzalini at stat.unipd.it  Tue May 20 12:43:31 2003
From: azzalini at stat.unipd.it (Adelchi Azzalini)
Date: Tue, 20 May 2003 12:43:31 +0200
Subject: [R] Output to connections
Message-ID: <20030520104331.7FFD27CA824@tango.stat.unipd.it>


In the document "R Data Import/Export", section "Output to connections",
there is the following portion of code:

  ## convert decimal point to comma in output, using a pipe (Unix)
  zz <- pipe(paste("sed s/\\./,/ >", "outfile"), "w")
  cat(format(round(rnorm(100), 4)), sep = "\n", file = zz)
  close(zz)
  ## now look at the output file:
  file.show(outfile, delete.file = TRUE)

Surely the last fine must be 
  file.show("outfile", delete.file = TRUE)
However this is not the problem, but the fact that I get something like
,1.6861
,0.1934
,0.5640
,0.5741
,0.1920
,0.1898
,1.4788
,0.1706
,0.9953
<..snipped..>

If I run from R:
  zz <- file("outfile", "w")
  cat(format(round(rnorm(10), 4)), sep = "\n", file = zz)
  close(zz)
and then from outside R:
  sed s/\\./,/ outfile 
then I get it right (of course), something like
-1,3612
-0,9772
 0,1524
 2,4046
 0,4741
 0,6659
-0,8277
 0,5071
 0,7190
 0,4088

This is fine, but it would be good to have it working in first form.
 
environment: R 1.7.0 on Debian linux.

regards,

Adelchi Azzalini

-- 
Adelchi Azzalini  <azzalini at stat.unipd.it>
Dipart.Scienze Statistiche, Universit? di Padova, Italia
http://azzalini.stat.unipd.it/



From gregory.lefebvre at univ-rouen.fr  Tue May 20 12:56:44 2003
From: gregory.lefebvre at univ-rouen.fr (gregory)
Date: Tue, 20 May 2003 12:56:44 +0200
Subject: [R] R_x11.so
Message-ID: <3ECA09EC.2010707@univ-rouen.fr>

Hi the list,

I just installed  the R-1.7.0-1mdk.i516.rpm package on a mdk 9.1. All 
looks fine until I try to launch some graphics functions as png() or 
even demo( graphics). I receive the following example message:

 > png()
Error in png() : R_X11 module cannot be loaded
In addition: Warning message:
unable to load shared library "/usr/lib/R/modules/R_X11.so":
  /usr/lib/R/modules/R_X11.so: undefined symbol: png_set_IHDR


Also I verified that this file exists and it is.
~/>updatedb
~/>locate "R_x11.so"
~/>/usr/lib/R/modules/R_X11.so

Which variables have to be configured ? How can I do since I installed 
an rpm ?


Is there somebody who could help me.
In advance thank you.

Greg



From ligges at statistik.uni-dortmund.de  Tue May 20 12:59:09 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 20 May 2003 12:59:09 +0200
Subject: [R] Sorting in data frames
In-Reply-To: <seca0fb8.019@wpo.nerc.ac.uk>
References: <seca0fb8.019@wpo.nerc.ac.uk>
Message-ID: <3ECA0A7D.7080906@statistik.uni-dortmund.de>

Stephen Thackeray wrote:
> Hi, 
> 
> Is it possible to sort the rows within a data frame, with respect to
> the values in one or more of the columns? For example, if I had measured
> water temperatures at differenrt depths within a lake, on different
> sampling dates and had a dataframe containing sampling dates (x),
> sampling depths (y) and data for each day-depth combination (z), would
> it be possible to rearrange the data frame so that it is sorted by day
> and then by depth? 

See ?order and the mailing list archives.

Uwe Ligges



From ida.scheel at nr.no  Tue May 20 12:59:11 2003
From: ida.scheel at nr.no (Ida Scheel)
Date: Tue, 20 May 2003 12:59:11 +0200
Subject: [R] [Fwd: Allocation problem]
Message-ID: <3ECA0A7F.8060200@nr.no>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030520/1b06f99b/attachment.pl

From ripley at stats.ox.ac.uk  Tue May 20 13:02:55 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 20 May 2003 12:02:55 +0100 (BST)
Subject: [R] Allocation problem
In-Reply-To: <3ECA03E5.7020702@nr.no>
Message-ID: <Pine.LNX.4.44.0305201156400.9925-100000@gannet.stats>

On Tue, 20 May 2003, Ida Scheel wrote:

> I have a problem when using R1.7.0. I have a very large dataset, but I 
> also have access to 24GB RAM on a super-computer. Nevertheless, when 
> using the "lme"-function  I get the error message
> 
> Error: cannot allocate vector of size 224295 Kb
> 
> As I understand it, the default is that there is no memory-limit in R 
> other than machine resources, but somehow R does not get acces to the 
> 24GB of RAM I have available.

How do you know?  That message just says that at that point 220Mb *more*
was not available.

`A super-computer' is extremely vague; please be a lot more specific about 
what you are doing and how R was configured and built.  My expectation is 
that you are being limited by machine resources.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From hb at maths.lth.se  Tue May 20 13:03:31 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Tue, 20 May 2003 13:03:31 +0200
Subject: [R] Output to connections
In-Reply-To: <20030520104331.7FFD27CA824@tango.stat.unipd.it>
Message-ID: <000401c31ebf$732e8040$e502eb82@alpha.wehi.edu.au>

In R '\' has to be escaped, i.e. '\\' which means '\\' has to be '\\\\'
(this was probably there before the help page was generated!?)

The following works

  ## convert decimal point to comma in output, using a pipe (Unix)
  zz <- pipe(paste("sed s/\\\\./,/ >", "outfile"), "w")
  cat(format(round(rnorm(100), 4)), sep = "\n", file = zz)
  close(zz)
  ## now look at the output file:
  file.show("outfile", delete.file = TRUE)

Henrik Bengtsson

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Adelchi Azzalini
> Sent: den 20 maj 2003 12:44
> To: r-help at stat.math.ethz.ch
> Subject: [R] Output to connections
> 
> 
> 
> In the document "R Data Import/Export", section "Output to 
> connections", there is the following portion of code:
> 
>   ## convert decimal point to comma in output, using a pipe (Unix)
>   zz <- pipe(paste("sed s/\\./,/ >", "outfile"), "w")
>   cat(format(round(rnorm(100), 4)), sep = "\n", file = zz)
>   close(zz)
>   ## now look at the output file:
>   file.show(outfile, delete.file = TRUE)
> 
> Surely the last fine must be 
>   file.show("outfile", delete.file = TRUE)
> However this is not the problem, but the fact that I get 
> something like ,1.6861 ,0.1934 ,0.5640 ,0.5741 ,0.1920 
> ,0.1898 ,1.4788 ,0.1706 ,0.9953 <..snipped..>
> 
> If I run from R:
>   zz <- file("outfile", "w")
>   cat(format(round(rnorm(10), 4)), sep = "\n", file = zz)
>   close(zz)
> and then from outside R:
>   sed s/\\./,/ outfile 
> then I get it right (of course), something like
> -1,3612
> -0,9772
>  0,1524
>  2,4046
>  0,4741
>  0,6659
> -0,8277
>  0,5071
>  0,7190
>  0,4088
> 
> This is fine, but it would be good to have it working in first form.
>  
> environment: R 1.7.0 on Debian linux.
> 
> regards,
> 
> Adelchi Azzalini
> 
> -- 
> Adelchi Azzalini  <azzalini at stat.unipd.it>
> Dipart.Scienze Statistiche, Universit? di Padova, Italia 
http://azzalini.stat.unipd.it/

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Tue May 20 13:09:34 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 20 May 2003 12:09:34 +0100 (BST)
Subject: [R] R_x11.so
In-Reply-To: <3ECA09EC.2010707@univ-rouen.fr>
Message-ID: <Pine.LNX.4.44.0305201204140.9925-100000@gannet.stats>

>From the NEWS file:

    o	The R_X11 module is no longer loaded until it is needed, so
	do test that x11() works in a new Unix-alike R installation.

There appears to be a mismatch between that rpm and your libpng:
please contact the rpm maintainer.

Why not build R from the sources yourself?

On Tue, 20 May 2003, gregory wrote:

> Hi the list,
> 
> I just installed  the R-1.7.0-1mdk.i516.rpm package on a mdk 9.1. All 
> looks fine until I try to launch some graphics functions as png() or 
> even demo( graphics). I receive the following example message:
> 
>  > png()
> Error in png() : R_X11 module cannot be loaded
> In addition: Warning message:
> unable to load shared library "/usr/lib/R/modules/R_X11.so":
>   /usr/lib/R/modules/R_X11.so: undefined symbol: png_set_IHDR
> 
> 
> Also I verified that this file exists and it is.
> ~/>updatedb
> ~/>locate "R_x11.so"
> ~/>/usr/lib/R/modules/R_X11.so
> 
> Which variables have to be configured ? How can I do since I installed 
> an rpm ?
> 
> 
> Is there somebody who could help me.
> In advance thank you.
> 
> Greg
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From perkinsm at bway.net  Tue May 20 13:10:01 2003
From: perkinsm at bway.net (Mark E. Perkins)
Date: Tue, 20 May 2003 07:10:01 -0400
Subject: [R] Compile R-1.7.0 on Mac OS 10.2.6
In-Reply-To: <520FF7EC-8AA1-11D7-9965-000393DC1748@ic.ac.uk>
References: <520FF7EC-8AA1-11D7-9965-000393DC1748@ic.ac.uk>
Message-ID: <2147483647.1053414601@[192.168.187.8]>

--On Tuesday, May 20, 2003 09:59 +0100 David Orme <d.orme at imperial.ac.uk>
wrote:

> Hi,
> 
> Thanks for the suggestion but that isn't it. The library is there...
> 
>> [doibook:~] dorme% ls /sw/lib/libiconv.2.dylib
>> /sw/lib/libiconv.2.dylib
> 
> ... but something about the library version is wrong. My version of g77
> was freshly (last week) installed from source using finkcommander; I'm
> using the December 2002 Apple Developer Tools version of gcc.
> 
> David

I don't *think* libiconv is installed with g77. It looks to me as if it's
installed with the fink distribution and base files.On my system,
libiconv.2.dylib is a symlink to /sw/lib/libiconv.2.0.4.dylib
Try this:
        cd /sw/lib && ls -lF libiconv*

Here's what I get:

-> cd /sw/lib && ls -lF libiconv*
-rw-r--r--  1 root  admin  897284 May 19 08:58 libiconv.2.0.4.dylib
lrwxr-xr-x  1 root  admin      20 May 19 09:07 libiconv.2.dylib@ ->
libiconv.2.0.4.dylib
lrwxr-xr-x  1 root  admin      20 May 19 09:07 libiconv.dylib@ ->
libiconv.2.0.4.dylib
-rw-r--r--  1 root  admin     710 May 19 08:58 libiconv.la

Note that these have date and time from yesterday morning, which is the
last time I updated fink. You might try updating fink (I don't use fink
commander, but run 'fink selfupdate-cvs' directly). If *that* doesn't fix
the problem, you might try 'fink update libiconv'.

If updating libiconv still doesn't help, you might try

        fink install r-base

I built R-1.7.0 just last week with no problems. I first installed R via
fink, but uninstalled and went to the CRAN distribution because I wanted
docs in info and other formats (fink r-base only installs the html
versions). I also tend to update fink before I install any new package.

HTH,
--
Mark Perkins
perkinsm at bway.net



From azzalini at stat.unipd.it  Tue May 20 13:27:25 2003
From: azzalini at stat.unipd.it (Adelchi Azzalini)
Date: Tue, 20 May 2003 13:27:25 +0200
Subject: [R] Output to connections
In-Reply-To: <000401c31ebf$732e8040$e502eb82@alpha.wehi.edu.au>
References: <000401c31ebf$732e8040$e502eb82@alpha.wehi.edu.au>
Message-ID: <20030520112726.205437CA824@tango.stat.unipd.it>

On Tuesday 20 May 2003 13:03, Henrik Bengtsson wrote:
> In R '\' has to be escaped, i.e. '\\' which means '\\' has to be '\\\\'
> (this was probably there before the help page was generated!?)
>
> The following works
>
> ? ## convert decimal point to comma in output, using a pipe (Unix)
> ? zz <- pipe(paste("sed s/\\\\./,/ >", "outfile"), "w")
> ? cat(format(round(rnorm(100), 4)), sep = "\n", file = zz)
> ? close(zz)
> ? ## now look at the output file:
> ? file.show("outfile", delete.file = TRUE)

Yes, it works, thanks

Adelchi

-- 
Adelchi Azzalini  <azzalini at stat.unipd.it>
Dipart.Scienze Statistiche, Universit? di Padova, Italia
http://azzalini.stat.unipd.it/



From Philippe.Hupe at curie.fr  Tue May 20 13:34:04 2003
From: Philippe.Hupe at curie.fr (=?ISO-8859-1?Q?Philippe_Hup=E9?=)
Date: Tue, 20 May 2003 13:34:04 +0200
Subject: [R] conversion of a list element to a vector
In-Reply-To: <000401c31ebf$732e8040$e502eb82@alpha.wehi.edu.au>
References: <000401c31ebf$732e8040$e502eb82@alpha.wehi.edu.au>
Message-ID: <3ECA12AC.2080303@curie.fr>

Hello,

I would like to extract unique elements of a variable which belongs to a 
list

liste <- list(V1=c(1,2,3,5,2), V2=c(1,2,3,4,5))
var <- "V1"
uni <- unique(liste[var]) #does not work

I know that liste[var]$V1 works but for my problem, the label variable 
"V1" is only know through the var variable.

I can I do

Thanks in advance.



From ripley at stats.ox.ac.uk  Tue May 20 13:37:48 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 20 May 2003 12:37:48 +0100 (BST)
Subject: [R] Output to connections
In-Reply-To: <20030520112726.205437CA824@tango.stat.unipd.it>
Message-ID: <Pine.LNX.4.44.0305201232250.10083-100000@gannet.stats>

On Tue, 20 May 2003, Adelchi Azzalini wrote:

> On Tuesday 20 May 2003 13:03, Henrik Bengtsson wrote:
> > In R '\' has to be escaped, i.e. '\\' which means '\\' has to be '\\\\'
> > (this was probably there before the help page was generated!?)

Um, that's not the problem.  If this is a Unix-alike, the shell invoked by
popen also (probably, depending on the shell) needs "\" escaped. So each
of

the help processing
R strings
the Unix shell (probably)

need \ doubled (probably), and it is the last one I forgot.

> >
> > The following works
> >
> > ? ## convert decimal point to comma in output, using a pipe (Unix)
> > ? zz <- pipe(paste("sed s/\\\\./,/ >", "outfile"), "w")
> > ? cat(format(round(rnorm(100), 4)), sep = "\n", file = zz)
> > ? close(zz)
> > ? ## now look at the output file:
> > ? file.show("outfile", delete.file = TRUE)
> 
> Yes, it works, thanks
> 
> Adelchi
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From sundar.dorai-raj at pdf.com  Tue May 20 13:47:15 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue, 20 May 2003 06:47:15 -0500
Subject: [R] conversion of a list element to a vector
References: <000401c31ebf$732e8040$e502eb82@alpha.wehi.edu.au>
	<3ECA12AC.2080303@curie.fr>
Message-ID: <3ECA15C3.4060504@pdf.com>



Philippe Hup? wrote:
> Hello,
> 
> I would like to extract unique elements of a variable which belongs to a 
> list
> 
> liste <- list(V1=c(1,2,3,5,2), V2=c(1,2,3,4,5))
> var <- "V1"
> uni <- unique(liste[var]) #does not work
> 

Need to use "[[" here. liste[var] is still a list. liste[[var]] is a 
vector. I would avoid using "var" as a variable name since it is also 
the function for computing the variance.

> I know that liste[var]$V1 works but for my problem, the label variable 
> "V1" is only know through the var variable.
> 
> I can I do
> 
> Thanks in advance.
> 

lapply(liste, unique) returns a list of length(liste) containing the 
unique values of each element in the list.

Regards,
Sundar



From ripley at stats.ox.ac.uk  Tue May 20 13:50:03 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 20 May 2003 12:50:03 +0100 (BST)
Subject: [R] conversion of a list element to a vector
In-Reply-To: <3ECA12AC.2080303@curie.fr>
Message-ID: <Pine.LNX.4.44.0305201249030.10209-100000@gannet.stats>

You meant [[var]] not [var].  liste[var] is a one-element list.

On Tue, 20 May 2003, Philippe Hup? wrote:

> Hello,
> 
> I would like to extract unique elements of a variable which belongs to a 
> list
> 
> liste <- list(V1=c(1,2,3,5,2), V2=c(1,2,3,4,5))
> var <- "V1"
> uni <- unique(liste[var]) #does not work
> 
> I know that liste[var]$V1 works but for my problem, the label variable 
> "V1" is only know through the var variable.
> 
> I can I do
> 
> Thanks in advance.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From petr.pikal at precheza.cz  Tue May 20 14:05:00 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue, 20 May 2003 14:05:00 +0200
Subject: [R] plot POSIX class and identify
In-Reply-To: <3EC9FEFF.7050401@statistik.uni-dortmund.de>
References: <3ECA16DC.22046.EE922F@localhost>
Message-ID: <3ECA360C.10193.16863B1@localhost>

Thank you

On 20 May 2003 at 12:10, Uwe Ligges wrote:

> Petr Pikal wrote:
> > Hallo all
> > just a small question I did not find an answer in help pages.
> > 
> > Is it possible to use identify() after plotting with plot.POSIX to 
> 
> Hmmm. There is not method plot.POSIX, but there are plot.POSIXct and
> plot.POSIXlt.
> 
> > label points and/or to find out some points?
> 
> identify() works as expected, just use it. You need to convert POSIXlt
> objects to POSIXct objects before.

That's it

> plot(cas,pokus$tspkkp)
> identify(cas,pokus$tspkkp)
Error in xy.coords(x, y) : x and y lengths differ
> identify(as.POSIXct(cas),pokus$tspkkp)
[1] 1919 5448

Thanks again

> 
> Uwe Ligges
> 
> > Thanks a lot.
> > Best regards
> > 
> > Petr Pikal
> > petr.pikal at precheza.cz
> > p.pik at volny.cz
> 

Petr Pikal
petr.pikal at precheza.cz
p.pik at volny.cz



From lamac_k at hotmail.com  Tue May 20 14:42:36 2003
From: lamac_k at hotmail.com (lamack lamack)
Date: Tue, 20 May 2003 12:42:36 +0000
Subject: [R] regression coefficients
Message-ID: <BAY7-F45LJ7x7uNEE8W0003bd84@hotmail.com>

dear all, How can I compare regression coefficients across three (or more) 
groups?

Thank you very much



From wolski at molgen.mpg.de  Tue May 20 14:46:22 2003
From: wolski at molgen.mpg.de (Wolski)
Date: Tue, 20 May 2003 14:46:22 +0200
Subject: [R] Background color in plots.
Message-ID: <200305201446220653.013F35DB@harry.molgen.mpg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030520/050e8c58/attachment.pl

From thadani at tkk.att.ne.jp  Tue May 20 14:59:52 2003
From: thadani at tkk.att.ne.jp (Dilip Thadani)
Date: Tue, 20 May 2003 21:59:52 +0900
Subject: [R] conversion of a list element to a vector
References: <000401c31ebf$732e8040$e502eb82@alpha.wehi.edu.au>
	<3ECA12AC.2080303@curie.fr>
Message-ID: <001101c31ecf$b6bfea00$6601a8c0@indefensible>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030520/062d505e/attachment.pl

From jfox at mcmaster.ca  Tue May 20 15:06:55 2003
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 20 May 2003 09:06:55 -0400
Subject: [R] How to use pakcage SEM
In-Reply-To: <200305200737.h4K7bXqx003015@mp2.vectant.ne.jp>
Message-ID: <5.1.0.14.2.20030520085158.01ea2cb0@mcmail.cis.mcmaster.ca>

Dear Mitsuo,

You appear to be trying to fit a confirmatory factor analysis model with 
five observed variables and two factors. Two of the five variables load on 
both factors. Two variables have correlated measurement errors. I haven't 
checked that the model that you intend to fit is identified but let's 
suppose that it is.

As you've described the model to sem, there are 16 free parameters, but 
there are only 5*6/2 = 15 observed covariances (counting the diagonal 
entries of the correlation matrix), so clearly there's a mistake in the 
specification -- the model has negative degrees of freedom (and sem should 
complain, but doesn't).

The problem is that you've not placed any constraints on the model to fix 
the scales of the factors. The simplest thing to do would be to fix the 
variances of the factors to 1, rather than specifying them as free 
parameters; as well, you don't have to start the measurement-error 
variances at 1 rather than using the start values that sem computes, though 
it doesn't hurt to do so:

 > model.mh<-matrix(c(
+         'F1 -> V1', 'a1',NA,
+         'F1 -> V3', 'a3',NA,
+         'F1 -> V4', 'a4',NA,
+         'F2 -> V2', 'b2',NA,
+         'F2 -> V3', 'b3',NA,
+         'F2 -> V4', 'b4',NA,
+         'F2 -> V5', 'b5',NA,
+         'V1 <-> V1','e1', NA,
+         'V2 <-> V2','e2', NA,
+         'V3 <-> V3','e3', NA,
+         'V4 <-> V4','e4', NA,
+         'V5 <-> V5','e5', NA,
+         'F1 <-> F1', NA, 1,
+         'F2 <-> F2', NA, 1,
+         'F1 <-> F2','c12',NA,
+         'V1 <-> V2','cv1', NA
+         ),ncol=3,byrow=T)
 > sem.mh <- sem(model.mh, data.mh, 100)
 > summary(sem.mh)

  Model Chisquare =  2.2805   Df =  1 Pr(>Chisq) = 0.13101
  Goodness-of-fit index =  0.99097
  Adjusted goodness-of-fit index =  0.8646
  RMSEA index =  0.11373   90 % CI: (0, 0.31712)
  BIC =  -3.9341

  Normalized Residuals
      Min.   1st Qu.    Median      Mean   3rd Qu.      Max.
-3.92e-01 -5.50e-02 -5.27e-06  3.27e-02  1.09e-01  7.98e-01

  Parameter Estimates
     Estimate Std Error z value   Pr(>|z|)
a1  0.970680  0.275852 3.51884 4.3343e-04 V1 <--- F1
a3  0.317133  0.198819 1.59509 1.1069e-01 V3 <--- F1
a4  0.437281  0.250375 1.74651 8.0723e-02 V4 <--- F1
b2  0.526620  0.116264 4.52951 5.9119e-06 V2 <--- F2
b3  0.452136  0.196716 2.29842 2.1538e-02 V3 <--- F2
b4  0.234373  0.247929 0.94532 3.4449e-01 V4 <--- F2
b5  0.759562  0.131164 5.79092 7.0001e-09 V5 <--- F2
e1  0.052702  0.512634 0.10281 9.1812e-01 V1 <--> V1
e2  0.722672  0.126106 5.73065 1.0004e-08 V2 <--> V2
e3  0.552314  0.103604 5.33101 9.7669e-08 V3 <--> V3
e4  0.651868  0.128687 5.06552 4.0728e-07 V4 <--> V4
e5  0.423067  0.163535 2.58702 9.6811e-03 V5 <--> V5
c12 0.497557  0.167763 2.96584 3.0186e-03 F2 <--> F1
cv1 0.108796  0.076515 1.42190 1.5506e-01 V2 <--> V1

  Iterations =  37
 >

How does that compare to your EQS output?

John

At 04:37 PM 5/20/2003 +0900, you wrote:
>Hi.
>
>I have tried to use Package "SEM".
>
>As a learning, I try to convert a program running well of EQS
>which is as follows to SEM:
>
>###  EQS  ###
>/SPECIFICATION
>CAS=100; VAR=5 MAT=COR; ANA=COR;
>/EQUATIONS
>V1=*F1+E1; V2=*F1+E2; V3=*F1+*F2+E3; V4=**F1+*F2*E4;
>V5=*F2+E5;
>/VAR
>E1 TO E5=*; F1*1.0; F2=1.0;
>/COV
>E1,E2=*; F1,F2=*:
>/PRINT
>FIT ALL;
>/MATRIX ......
>/END
>
>This is the converted SEM program.
>###
>data.mh<-matrix(c(
>1.00,0,0,0, 0,
>0.38,1.00,0,0, 0,
>0.52,0.28,1.00,0,0,
>0.55,0.32,0.38,1.00,0,
>0.36,0.40,0.48,0.31,1.00
>),ncol=5,byrow=T)
>
>model.mh<-matrix(c(
>         'F1 -> V1', 'a1',NA,
>         'F1 -> V3', 'a3',NA,
>         'F1 -> V4', 'a4',NA,
>         'F2 -> V2', 'b2',NA,
>         'F2 -> V3', 'b3',NA,
>         'F2 -> V4', 'b4',NA,
>         'F2 -> V5', 'b5',NA,
>         'V1 <-> V1','e1', 1,
>         'V2 <-> V2','e2', 1,
>         'V3 <-> V3','e3', 1,
>         'V4 <-> V4','e4', 1,
>         'V5 <-> V5','e5', 1,
>         'F1 <-> F1','d1', 1,
>         'F2 <-> F2','d2', 1,
>         'F1 <-> F2','c12',NA,
>         'V1 <-> V2','cv1', NA,
>),ncol=3,byrow=T)
>obs.vars.mh <- c('V1','V2','V3','V4','V5')
>rownames(data.mh) <- colnames(data.mh) <- obs.vars.mh
>
>sem.mh <- sem(model.mh, data.mh, 100)
>###
>
>At this stage, everything looks going well.
>By debug mode of "sem()" it finishes with no error.
>However,the process of "summary(sem.mh)" produces an error.
>
> > summary(sem.mh)
>Error in optim(0, function(lam) ((1 - conf.level)/2 - pchisq(chisq, df,  :
>         Function cannot be evaluated at initial parameters
>In addition: Warning message:
>NaNs produced in: sqrt(diag(object$cov))
>
>It seems to me that there is something wrong at the conversion of
>"E1 TO E5=*;"  to " 'V1 <-> V2','cv1', NA ".
>
>Could anyone explain me how to manage this trouble?
>
>Thanks.
>
>--------========----------
>Mitsuo Igarashi
>mitsu5 at ruby.famille.ne.jp
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From adrian at lmttrading.com  Tue May 20 15:19:27 2003
From: adrian at lmttrading.com (Adrian Trapletti)
Date: Tue, 20 May 2003 15:19:27 +0200
Subject: [R] modell time series with AR-Garch modell
References: <3EC9EB13.9070805@iaew.rwth-aachen.de>
Message-ID: <00ca01c31ed2$71212970$bb8dc5d4@LMT003>

----- Original Message -----
From: "Marc Schroeder" <marc.schroeder at iaew.rwth-aachen.de>
To: "R-help at lists.R-project.org" <R-help at stat.math.ethz.ch>
Sent: Tuesday, May 20, 2003 10:45 AM
Subject: [R] modell time series with AR-Garch modell


> Hi R-community!
>
> Is there a possibility in R to model a time series with a so called
AR-GARCH
> process?

Not in one step. What can be done is modelling the time series with the
function AR from ts in the first step and then modelling the residuals from
the first step with the function GARCH from tseries.

>AR-GARCH is a composite modell consisting of an autoregressive
> process with an GARCH error term.
>
> Thanks in advance
> Marc
>

best
Adrian



From mschwartz at medanalytics.com  Tue May 20 15:38:40 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 20 May 2003 08:38:40 -0500
Subject: [R] Background color in plots.
In-Reply-To: <200305201446220653.013F35DB@harry.molgen.mpg.de>
References: <200305201446220653.013F35DB@harry.molgen.mpg.de>
Message-ID: <3ECA2FE0.8060809@medanalytics.com>

Wolski wrote:
> How can i set the background color in a plot.
> Eg. Instead of having with i like to have a grey background.
> Eryk


For the full window background color you can set par(bg = "color") prior 
to plotting.  See ?par for more information.

If on the other hand you are referring to the plot region itself (ie. 
within the plot box), it is a little trickier, but you can get the 
coordinates of the plot area rectangle and color it by using:

rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = 
"color")

In barplot2() in the gregmisc package you can set this easily for 
barplots by using the 'prcol' argument.  However for most other plotting 
routines you would need to plot the initial graphic, color the plot 
region and then re-plot (actually add) the graphic components to the 
existing plot window.

A simple example using plot():

# Create the base plotting window
# type = "n" does not plot the points
# Set the background color to "yellow"
par(bg = "yellow")
plot(1:10, type = "n")

# Now set the plot region to grey
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = 
"grey")

# Now plot the points on the existing window
points(1:10)



In some of the plotting functions to do the plot region color, like 
boxplot(), you would have to plot the full graphic and then replot it 
after setting the plot region color. In this case, you would use the 
'add = TRUE' argument in boxplot() for the second call. You could 
feasibly get the information from boxplot.stats() and draw the boxes and 
lines, etc., but just calling boxplot() twice is easier I think.

A quick example for boxplot():

x <- rnorm(100)
par(bg = "thistle")
boxplot(x)
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = 
"grey")
boxplot(x, add = TRUE, col = "blue")



They are not pretty I know, but hopefully gets the points across.

You can use colors() to get a list of the available color names.

HTH,

Marc Schwartz



From tblackw at umich.edu  Tue May 20 15:52:56 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Tue, 20 May 2003 09:52:56 -0400 (EDT)
Subject: [R] survit function and cox model with frailty
In-Reply-To: <Pine.GSO.4.53.0305192141320.4232@godzilla1.acpub.duke.edu>
Message-ID: <Pine.SOL.4.44.0305200914220.28571-100000@mspacman.gpcc.itd.umich.edu>

Giacomo  -

I'm stumped.  Again, I have never had occasion to use the
survival package myself and I am just looking for syntax
irregularities in the code you show.  The new error message
"Error in x2 %*% coef" is suggestive.  Do take a look at
coef(model1) to see if there is something irregular there.
You might print temp out to the screen to see that x2 has
the exepcted value.  Could the original data's data frame
have changed between the time  model1  was created and the
time  survfit() is run on it ?

(I've had SO much difficulty in the past with alternating
commas and decimal points that I would have defined x2 as
  x2 = rep(1.5, 5).)

I reassure you that you CAN get to the bottom of this.
I think you're making progress.  One step going forward
might be to look at  help("model.frame"), since that's
what causes the initial error message, and think about
how the arguments get matched in  survfit().

Aaaah.  Here's one more thing you could try.  Give the
new data frame of dimensions 5 x 6 some other name than
"temp" and try again.  I see that the variable name "temp"
is already used in survfit() for something else.  Again,
this is just a guess.  Unfortunately, the package code
is very complex.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -


On Mon, 19 May 2003 gc4 at duke.edu wrote:

>
> ... However, I obtain the following error message:
>
> fit2 <- survfit(model1, newdata=temp, individual=TRUE)
> Error in x2 %*% coef : non-conformable arguments
>
> I also tried to add a "frail(id)"=c(1,1,1,1,1) line to the statement
> that creates the temp data frame. But, again, I obtain the following error
> message:
>
> > fit2 <- survfit(model3, newdata=temp, individual=TRUE)
> Error in model.frame(formula, rownames, variables, varnames, extras,
> extranames,  :
>         variable lengths differ
>
> On Mon, 19 May 2003, Thomas W Blackwell wrote:
>
> > Giacomo  -
> >
> > Here's just a guess, since I have no experience with this.
> > Try adding a sixth variable to the data frame "temp", a
> > variable named "id" with value c(1,1,1,1,1).  Maybe that
> > will do it ?   This is consistent with your intention in
> > setting individual=TRUE, and it will give the frailty()
> > term that's already in the model something to work with.
> >
> > -  tom blackwell  -  u michigan medical school  -  ann arbor  -



From myao at ou.edu  Tue May 20 15:57:11 2003
From: myao at ou.edu (Minghua Yao)
Date: Tue, 20 May 2003 08:57:11 -0500
Subject: [R] Several Basic Questions
Message-ID: <HDEPJCAKDEJMEEHKJOKEKEFBCBAA.myao@ou.edu>

Hello, everyone,

I am having several basic questions that I haven't found the answer to from
the manuals:

1. How to remove "[1]" when a single line message is printed?
2. How to print several variables (e.g., a character string and a numeric
variable) at the same line?
3. How to have the control of the accuracy of variables? e.g., in the
following,

> x<-1134567.1
> y<-0.19
> z<-x-y
> z
[1] 1134567
>

I want variable to have an accuracy of 2 digits behind the decimal point
instead of all the digits behind the point being cut off.

Thank you in advance for any help.

Minghua



From ripley at stats.ox.ac.uk  Tue May 20 16:12:07 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 20 May 2003 15:12:07 +0100 (BST)
Subject: [R] Several Basic Questions
In-Reply-To: <HDEPJCAKDEJMEEHKJOKEKEFBCBAA.myao@ou.edu>
Message-ID: <Pine.LNX.4.44.0305201506310.13704-100000@gannet.stats>

On Tue, 20 May 2003, Minghua Yao wrote:

> I am having several basic questions that I haven't found the answer to from
> the manuals:
> 
> 1. How to remove "[1]" when a single line message is printed?

Use cat()

> 2. How to print several variables (e.g., a character string and a numeric
> variable) at the same line?

Use cat()

> 3. How to have the control of the accuracy of variables? e.g., in the
> following,
> 
> > x<-1134567.1
> > y<-0.19
> > z<-x-y
> > z
> [1] 1134567
> >
> 
> I want variable to have an accuracy of 2 digits behind the decimal point
> instead of all the digits behind the point being cut off.

Use cat, round and format:

> cat(format(round(z, 2)), "\n")
1134566.91 


These may not be explicit in the R manuals, but they are in all good books 
on R (see the FAQ).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ivan.piffer at ismaa.it  Tue May 20 17:00:09 2003
From: ivan.piffer at ismaa.it (Ivan Piffer)
Date: Tue, 20 May 2003 17:00:09 +0200
Subject: [R] question about Tukey test
Message-ID: <000f01c31ee0$84ba3810$c914000a@intra.ismaa.it>

I'm using SAS for my statistical purpose and I'm triyng to jump in the R'
world.
How can i implement Tukey linear test in R?
In sas-code my lines are :
PROC GLM;
BY PARCELLA;
CLASS TESI;
MODEL PROD=TESI;
MEANS TESI/TUKEY lines;

IN R:
ab<-type.convert(a$tesi)
a<-cbind(a,ab)
cc<-anova(lm(prod~ab,data=a))
cc2<-aov(prod~ab,data=a)
tt<-TukeyHSD(cc2,ordered=TRUE)

but how can I put the option lines that i find in sas (MEANS TESI/TUKEY
lines) in R language?
My output in sas is this and I wanna have the same in R.
Thank you...
Ivan

                                                  General Linear Models
Procedure

                                      Tukey's Studentized Range (HSD) Test
for variable: PROD

                                    NOTE: This test controls the type I
experimentwise error rate, but generally has a higher type
                                          II error rate than REGWQ.

                                                 Alpha= 0.05  df= 98  MSE=
12.43238
                                             Critical Value of Studentized
Range= 4.486
                                               Minimum Significant
Difference= 4.5893
                                                 WARNING: Cell sizes are not
equal.
                                                 Harmonic Mean of cell
sizes= 11.88

                                    Means with the same letter are not
significantly different.

                                           Tukey Grouping              Mean
N  TESI

                                                        A            11.788
12  R_GALA_TENROY
                                                        A
                                                B       A             8.385
12  MONDIAL_GALA
                                                B       A
                                                B       A             8.124
12  R_GALA_TENFOR
                                                B
                                                B                     7.134
12  GALAXY
                                                B
                                                B       C             6.301
12  ROYAL_GALA
                                                B       C
                                                B       C   D         4.874
12  OBROGALA
                                                B       C   D
                                                B       C   D         3.864
11  BROOKFIELD
                                                        C   D
                                                        C   D         1.713
12  REDGALA95
                                                            D
                                                            D         1.238
12  SCHNIGA



From vito.muggeo at giustizia.it  Tue May 20 16:56:44 2003
From: vito.muggeo at giustizia.it (vito muggeo)
Date: Tue, 20 May 2003 16:56:44 +0200
Subject: [R] R in BATCH mode
Message-ID: <00a801c31ee0$0bb625a0$5c13070a@it.giustizia.it>

Dear all,
In R<=1.6.2 I usually used the following code (in DOS prompt) to run R in
batch mode

C:\documents> Rcmd BATCH myfile.R

and I could see the results (including warning messages) in the file
myfile.Rout

In R.1.7.0 I'm experiencing the followings:

(1) even if I type "Rcmd BATCH myfile.R myfile.Rout",
no file myfile.Rout is created, but just a "&1" file
(2)After typing  "Rcmd BATCH myfile.R" the following message appears
immediately in DOS prompt
ARGUMENT '2' __ignored__
(3) results are printed in file "&1", but the process is rather slow.
Am I missing anything?

I'm running R-1.7.0 on WinME,

Many thanks,
best,
vito



From mitsu5 at ruby.famille.ne.jp  Tue May 20 17:02:55 2003
From: mitsu5 at ruby.famille.ne.jp (Mitsuo Igarashi)
Date: Wed, 21 May 2003 00:02:55 +0900
Subject: [R] How to use pakcage SEM
In-Reply-To: <5.1.0.14.2.20030520085158.01ea2cb0@mcmail.cis.mcmaster.ca>
References: <5.1.0.14.2.20030520085158.01ea2cb0@mcmail.cis.mcmaster.ca>
Message-ID: <200305201503.h4KF30qx017842@mp2.vectant.ne.jp>

Hello, Dear John.

As you taught me, I obtained the result which I expect and is 
the same as that of EQS.
I have started to learn structural equation modeling. This 
pushes my understanding SEM. Thank you very much.

Would you permit me to ask a question?
This EQS program sets an error covariance between V1 and V2.
However,It seems to me that the package SEM does not have the 
method of error covariance. So I set a covariance between V1 and 
V2. What is the difference between these two settings of 
covariances?

Best regards.
--------========----------
Mitsuo Igarashi
mitsu5 at ruby.famille.ne.jp
---------------

John Fox <jfox at mcmaster.ca> wrote:

> Dear Mitsuo,
> 
> You appear to be trying to fit a confirmatory factor analysis model with 
> five observed variables and two factors. Two of the five variables load on 
> both factors. Two variables have correlated measurement errors. I haven't 
> checked that the model that you intend to fit is identified but let's 
> suppose that it is.
> 
> As you've described the model to sem, there are 16 free parameters, but 
> there are only 5*6/2 = 15 observed covariances (counting the diagonal 
> entries of the correlation matrix), so clearly there's a mistake in the 
> specification -- the model has negative degrees of freedom (and sem should 
> complain, but doesn't).
> 
> The problem is that you've not placed any constraints on the model to fix 
> the scales of the factors. The simplest thing to do would be to fix the 
> variances of the factors to 1, rather than specifying them as free 
> parameters; as well, you don't have to start the measurement-error 
> variances at 1 rather than using the start values that sem computes, though 
> it doesn't hurt to do so:
> 
>  > model.mh<-matrix(c(
> +         'F1 -> V1', 'a1',NA,
> +         'F1 -> V3', 'a3',NA,
> +         'F1 -> V4', 'a4',NA,
> +         'F2 -> V2', 'b2',NA,
> +         'F2 -> V3', 'b3',NA,
> +         'F2 -> V4', 'b4',NA,
> +         'F2 -> V5', 'b5',NA,
> +         'V1 <-> V1','e1', NA,
> +         'V2 <-> V2','e2', NA,
> +         'V3 <-> V3','e3', NA,
> +         'V4 <-> V4','e4', NA,
> +         'V5 <-> V5','e5', NA,
> +         'F1 <-> F1', NA, 1,
> +         'F2 <-> F2', NA, 1,
> +         'F1 <-> F2','c12',NA,
> +         'V1 <-> V2','cv1', NA
> +         ),ncol=3,byrow=T)
>  > sem.mh <- sem(model.mh, data.mh, 100)
>  > summary(sem.mh)
> 
>   Model Chisquare =  2.2805   Df =  1 Pr(>Chisq) = 0.13101
>   Goodness-of-fit index =  0.99097
>   Adjusted goodness-of-fit index =  0.8646
>   RMSEA index =  0.11373   90 % CI: (0, 0.31712)
>   BIC =  -3.9341
> 
>   Normalized Residuals
>       Min.   1st Qu.    Median      Mean   3rd Qu.      Max.
> -3.92e-01 -5.50e-02 -5.27e-06  3.27e-02  1.09e-01  7.98e-01
> 
>   Parameter Estimates
>      Estimate Std Error z value   Pr(>|z|)
> a1  0.970680  0.275852 3.51884 4.3343e-04 V1 <--- F1
> a3  0.317133  0.198819 1.59509 1.1069e-01 V3 <--- F1
> a4  0.437281  0.250375 1.74651 8.0723e-02 V4 <--- F1
> b2  0.526620  0.116264 4.52951 5.9119e-06 V2 <--- F2
> b3  0.452136  0.196716 2.29842 2.1538e-02 V3 <--- F2
> b4  0.234373  0.247929 0.94532 3.4449e-01 V4 <--- F2
> b5  0.759562  0.131164 5.79092 7.0001e-09 V5 <--- F2
> e1  0.052702  0.512634 0.10281 9.1812e-01 V1 <--> V1
> e2  0.722672  0.126106 5.73065 1.0004e-08 V2 <--> V2
> e3  0.552314  0.103604 5.33101 9.7669e-08 V3 <--> V3
> e4  0.651868  0.128687 5.06552 4.0728e-07 V4 <--> V4
> e5  0.423067  0.163535 2.58702 9.6811e-03 V5 <--> V5
> c12 0.497557  0.167763 2.96584 3.0186e-03 F2 <--> F1
> cv1 0.108796  0.076515 1.42190 1.5506e-01 V2 <--> V1
> 
>   Iterations =  37
>  >
> 
> How does that compare to your EQS output?
> 
> John
> 
> At 04:37 PM 5/20/2003 +0900, you wrote:
> >Hi.
> >
> >I have tried to use Package "SEM".
> >
> >As a learning, I try to convert a program running well of EQS
> >which is as follows to SEM:
> >
> >###  EQS  ###
> >/SPECIFICATION
> >CAS=100; VAR=5 MAT=COR; ANA=COR;
> >/EQUATIONS
> >V1=*F1+E1; V2=*F1+E2; V3=*F1+*F2+E3; V4=**F1+*F2*E4;
> >V5=*F2+E5;
> >/VAR
> >E1 TO E5=*; F1*1.0; F2=1.0;
> >/COV
> >E1,E2=*; F1,F2=*:
> >/PRINT
> >FIT ALL;
> >/MATRIX ......
> >/END
> >
> >This is the converted SEM program.
> >###
> >data.mh<-matrix(c(
> >1.00,0,0,0, 0,
> >0.38,1.00,0,0, 0,
> >0.52,0.28,1.00,0,0,
> >0.55,0.32,0.38,1.00,0,
> >0.36,0.40,0.48,0.31,1.00
> >),ncol=5,byrow=T)
> >
> >model.mh<-matrix(c(
> >         'F1 -> V1', 'a1',NA,
> >         'F1 -> V3', 'a3',NA,
> >         'F1 -> V4', 'a4',NA,
> >         'F2 -> V2', 'b2',NA,
> >         'F2 -> V3', 'b3',NA,
> >         'F2 -> V4', 'b4',NA,
> >         'F2 -> V5', 'b5',NA,
> >         'V1 <-> V1','e1', 1,
> >         'V2 <-> V2','e2', 1,
> >         'V3 <-> V3','e3', 1,
> >         'V4 <-> V4','e4', 1,
> >         'V5 <-> V5','e5', 1,
> >         'F1 <-> F1','d1', 1,
> >         'F2 <-> F2','d2', 1,
> >         'F1 <-> F2','c12',NA,
> >         'V1 <-> V2','cv1', NA,
> >),ncol=3,byrow=T)
> >obs.vars.mh <- c('V1','V2','V3','V4','V5')
> >rownames(data.mh) <- colnames(data.mh) <- obs.vars.mh
> >
> >sem.mh <- sem(model.mh, data.mh, 100)
> >###
> >
> >At this stage, everything looks going well.
> >By debug mode of "sem()" it finishes with no error.
> >However,the process of "summary(sem.mh)" produces an error.
> >
> > > summary(sem.mh)
> >Error in optim(0, function(lam) ((1 - conf.level)/2 - pchisq(chisq, df,  :
> >         Function cannot be evaluated at initial parameters
> >In addition: Warning message:
> >NaNs produced in: sqrt(diag(object$cov))
> >
> >It seems to me that there is something wrong at the conversion of
> >"E1 TO E5=*;"  to " 'V1 <-> V2','cv1', NA ".
> >
> >Could anyone explain me how to manage this trouble?
> >
> >Thanks.
> >
> >--------========----------
> >Mitsuo Igarashi
> >mitsu5 at ruby.famille.ne.jp
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> -----------------------------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario, Canada L8S 4M4
> email: jfox at mcmaster.ca
> phone: 905-525-9140x23604
> web: www.socsci.mcmaster.ca/jfox
> -----------------------------------------------------



From roland.goecke at rostock.igd.fhg.de  Tue May 20 17:10:41 2003
From: roland.goecke at rostock.igd.fhg.de (Roland Goecke)
Date: Tue, 20 May 2003 17:10:41 +0200
Subject: [R] A questiona about FDA package
Message-ID: <3ECA4571.2000307@rostock.igd.fhg.de>

Hi,

I am using Jim Ramsay's FDA package for R and I was wondering if anyone could help me with the following problem.

I have a bunch of curves (measurements over time) for a certain parameter. I make these into an FD object and then register them. As a result, I get a list of 3 FD objects. The first one are the registered curves. The second one (Wfd) are the warping functions determined to register the curves. It is those that I want to use.

Now, I would like to apply these warping functions to another set of curves for a different parameter (same dimension of measured data). How can I do that? I guess I will have to use function eval.fd but how do I extract the timing / sample point information from the Wfd object? How do I apply these? Has anyone done something like this before?

I'd appreciate any ideas you might have.

Cheers
Roland



From tlumley at u.washington.edu  Tue May 20 17:15:12 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 20 May 2003 08:15:12 -0700 (PDT)
Subject: [R] survit function and cox model with frailty
In-Reply-To: <Pine.SOL.4.44.0305200914220.28571-100000@mspacman.gpcc.itd.umich.edu>
Message-ID: <Pine.A41.4.44.0305200808140.171844-100000@homer07.u.washington.edu>

On Tue, 20 May 2003, Thomas W Blackwell wrote:

> I reassure you that you CAN get to the bottom of this.
> I think you're making progress.  One step going forward
> might be to look at  help("model.frame"), since that's
> what causes the initial error message, and think about
> how the arguments get matched in  survfit().
>

Actually I think one CAN'T get to the bottom of this.  I don't think
survfit works on models with frailties.

I don't actually understand what the intent is (and why the multiple time
periods with identical covariates), but it isn't going to be at all
straightforward to do a proper prediction for a single new case: the
survival curve should be the survival distribution with the frailty
integrated out, which is hard.

It should be possible to do a prediction setting the frailty to 1, but it
isn't.  Given that coxph will fit user-defined penalised likelihoods
survfit would have to be fairly clever to guess what it was supposed to do
in each circumstance.


	-thomas



From myao at ou.edu  Tue May 20 17:17:13 2003
From: myao at ou.edu (Minghua Yao)
Date: Tue, 20 May 2003 10:17:13 -0500
Subject: [R] Several Basic Questions
In-Reply-To: <Pine.LNX.4.44.0305201506310.13704-100000@gannet.stats>
Message-ID: <HDEPJCAKDEJMEEHKJOKECEFDCBAA.myao@ou.edu>

Dear Prof. Ripley,

Thank you for your reply. It works fine except for question 3. I got

> cat(format(round(z, 2)), "\n")
1134567

May variable z has been rounded to 0 digit behind the point at the very
beginning. How to avoid that?

Minghua

-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
Sent: Tuesday, May 20, 2003 9:12 AM
To: Minghua Yao
Cc: R Help
Subject: Re: [R] Several Basic Questions


On Tue, 20 May 2003, Minghua Yao wrote:

> I am having several basic questions that I haven't found the answer to
from
> the manuals:
>
> 1. How to remove "[1]" when a single line message is printed?

Use cat()

> 2. How to print several variables (e.g., a character string and a numeric
> variable) at the same line?

Use cat()

> 3. How to have the control of the accuracy of variables? e.g., in the
> following,
>
> > x<-1134567.1
> > y<-0.19
> > z<-x-y
> > z
> [1] 1134567
> >
>
> I want variable to have an accuracy of 2 digits behind the decimal point
> instead of all the digits behind the point being cut off.

Use cat, round and format:

> cat(format(round(z, 2)), "\n")
1134566.91


These may not be explicit in the R manuals, but they are in all good books
on R (see the FAQ).

--
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From spencer.graves at pdf.com  Tue May 20 17:19:40 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 20 May 2003 08:19:40 -0700
Subject: [R] regression coefficients
References: <BAY7-F45LJ7x7uNEE8W0003bd84@hotmail.com>
Message-ID: <3ECA478C.8070009@pdf.com>

	  I don't know of a simply function to do what you want, but I can give 
you part of the standard log(likelihood ratio) theory:

	  Suppose b[i]|s ~ N.r(b, s^2*W[i]), i = 1, ..., k.  Then the 
log(likelihood) is a sum of k terms of the following form:

	  l[i] = (-0.5)*(r*log(2*pi*s^2)+log|W[i]|
	      +(s^-2)*t(b[i]-b)%*%solve(W[i]%*%(b[i]-b)

By differentiating with respect to b and setting to 0, we get the 
maximum likelihood estimate for b as follows:

	  b.hat = solve(sum(solve(W[i]))%*%sum(solve(W[i])%*%b[i])

In words:  b.hat = weighted average with weights inversely proportional 
to the variances.  Then log(likelihood ratio) is as follows:

	  log.LR = sum((s^-2)*t(b[i]-b.hat)%*%solve(W[i])%*%(b[i]-b.hat))

This problem should be in most good books on multivariate analysis.  I 
would guess that log.LR probably has an F distribution with numerator 
degrees of freedom = r*(k-1) and with denominator degrees of freedom = 
degrees of freedom in the estimate of s.  However, I don't remember for 
sure.  It's vaguely possible that this is an "unsolved" problem.  In the 
latter case, you should have all the pieces here to generate a Monte 
Carlo.

hope this helps.  spencer graves

lamack lamack wrote:
> dear all, How can I compare regression coefficients across three (or 
> more) groups?
> 
> Thank you very much
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Tue May 20 17:20:43 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 20 May 2003 16:20:43 +0100 (BST)
Subject: [R] R in BATCH mode
In-Reply-To: <00a801c31ee0$0bb625a0$5c13070a@it.giustizia.it>
Message-ID: <Pine.LNX.4.44.0305201613010.27095-100000@gannet.stats>

On Tue, 20 May 2003, vito muggeo wrote:

> In R<=1.6.2 I usually used the following code (in DOS prompt) to run R in
> batch mode
> 
> C:\documents> Rcmd BATCH myfile.R
> 
> and I could see the results (including warning messages) in the file
> myfile.Rout
> 
> In R.1.7.0 I'm experiencing the followings:
> 
> (1) even if I type "Rcmd BATCH myfile.R myfile.Rout",
> no file myfile.Rout is created, but just a "&1" file
> (2)After typing  "Rcmd BATCH myfile.R" the following message appears
> immediately in DOS prompt
> ARGUMENT '2' __ignored__
> (3) results are printed in file "&1", but the process is rather slow.
> Am I missing anything?
> 
> I'm running R-1.7.0 on WinME,

Ah, so you really are at a DOS prompt.  R is designed to be run in
Windows, and this works in all versions of Windows available to me (XP and
2000, and WinME is obselete).  The problem is your so-called `shell',
command.com.

Solution 1 is to get a real shell (even a real OS).

Solution 2 is to edit the rw1070/bin/BATCH file and replace

system("Rterm.exe $R_opts < $infile > $outfile 2>&1");

by

system("Rterm.exe $R_opts < $infile > $outfile");

and realize that probably the warning and error messages will not get 
diverted to the file.

If anyone knows definitively how to do this in command.com, please let 
R-Windows at r-project.org now.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tirler at statistik.wu-wien.ac.at  Tue May 20 17:38:03 2003
From: tirler at statistik.wu-wien.ac.at (Guenter Tirler)
Date: Tue, 20 May 2003 17:38:03 +0200 (CEST)
Subject: [R] problems with hist()
Message-ID: <16074.19419.594372.899471@coredump.wu-wien.ac.at>

Hi,
I try to compute the counts of a histogram of random numbers. But I
get different results depending on the limits (-10,10) or (-1000,1000)
although all numbers are in the interval (-10,10).

Have I done somthing wrong? 


> x<-rnorm(1e6)
> s1<-hist(x, br =c(-1000,-1,-0.5,0,0.5,1,1000),plot=FALSE)[[2]]
> s2<-hist(x, br =c(-10,-1,-0.5,0,0.5,1,10),plot=FALSE)[[2]]
> sum(s1)
[1] 1000000
> sum(s2)
[1] 1000000
>  s1                                                        
[1] 159035 149461 192003 191478 149789 158234
> s2
[1] 159009 149452 192004 191464 149805 158266

Thanks
G?nter



From ripley at stats.ox.ac.uk  Tue May 20 17:38:36 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 20 May 2003 16:38:36 +0100 (BST)
Subject: [R] Several Basic Questions
In-Reply-To: <HDEPJCAKDEJMEEHKJOKECEFDCBAA.myao@ou.edu>
Message-ID: <Pine.LNX.4.44.0305201637080.27144-100000@gannet.stats>

On Tue, 20 May 2003, Minghua Yao wrote:

> Dear Prof. Ripley,
> 
> Thank you for your reply. It works fine except for question 3. I got
> 
> > cat(format(round(z, 2)), "\n")
> 1134567
> 
> May variable z has been rounded to 0 digit behind the point at the very
> beginning. How to avoid that?

Read the help on format (and print), especially its `digits' argument.
More generally, read the help pages on functions new to you!

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ivo.welch at yale.edu  Tue May 20 17:42:43 2003
From: ivo.welch at yale.edu (Welch, Ivo)
Date: Tue, 20 May 2003 11:42:43 -0400
Subject: [R] what.is(object)
Message-ID: <3ECA4CF3.7030508@yale.edu>


hi:  still experimenting.  is there a function that tells me what an S 
object is, or how it is constructed?

s <- cor.test ( x, y );

s$estimate$name = 'correlation' ;   <-  try to rename 'cor' to 
'correlation' fails.  obviously, name is not a part here.
s$newfield = c("another info field", 3.2 ) ;  <- this is not congruous

so

what.is(s)       #tells me that this is a class called htest
what.is(s$statistic)    # helps me

would allow me to see how things are constructed.   does S contain such 
a feature?

regards,

/iaw



From ripley at stats.ox.ac.uk  Tue May 20 17:51:18 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 20 May 2003 16:51:18 +0100 (BST)
Subject: [R] regression coefficients
In-Reply-To: <3ECA478C.8070009@pdf.com>
Message-ID: <Pine.LNX.4.44.0305201640060.27144-100000@gannet.stats>

Why is s assumed known and common to the k groups?  I doubt if that is 
what was meant (although it was too imprecise to be at all sure).

If `common' is a viable assumption, you can just fit a model with by-group
regressions vs one with a common regression (which seems to be what you
are testing) and use anova().

If not, the case k=2 encompasses the Welch t-test so exact distribution
theory is not going to be possible, but by fitting a common model and
three separate models and summing the -2log-lik for the latter you can
easily get the LT test and refer it to its `standard' (asymptotic)
Chi-squared distribution.

On Tue, 20 May 2003, Spencer Graves wrote:

> 	  I don't know of a simply function to do what you want, but I can give 
> you part of the standard log(likelihood ratio) theory:
> 
> 	  Suppose b[i]|s ~ N.r(b, s^2*W[i]), i = 1, ..., k.  Then the 
> log(likelihood) is a sum of k terms of the following form:
> 
> 	  l[i] = (-0.5)*(r*log(2*pi*s^2)+log|W[i]|
> 	      +(s^-2)*t(b[i]-b)%*%solve(W[i]%*%(b[i]-b)
> 
> By differentiating with respect to b and setting to 0, we get the 
> maximum likelihood estimate for b as follows:
> 
> 	  b.hat = solve(sum(solve(W[i]))%*%sum(solve(W[i])%*%b[i])
> 
> In words:  b.hat = weighted average with weights inversely proportional 
> to the variances.  Then log(likelihood ratio) is as follows:
> 
> 	  log.LR = sum((s^-2)*t(b[i]-b.hat)%*%solve(W[i])%*%(b[i]-b.hat))
> 
> This problem should be in most good books on multivariate analysis.  I 
> would guess that log.LR probably has an F distribution with numerator 
> degrees of freedom = r*(k-1) and with denominator degrees of freedom = 
> degrees of freedom in the estimate of s.  However, I don't remember for 
> sure.  It's vaguely possible that this is an "unsolved" problem.  In the 
> latter case, you should have all the pieces here to generate a Monte 
> Carlo.

You have assumed s is known, in which case it is a Chi-squared 
distribution.  If s is unknown, you need to maximize over it to get an LR 
test (separately under the null and the alternative).

> lamack lamack wrote:
> > dear all, How can I compare regression coefficients across three (or 
> > more) groups?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jfox at mcmaster.ca  Tue May 20 17:54:29 2003
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 20 May 2003 11:54:29 -0400
Subject: [R] How to use pakcage SEM
In-Reply-To: <200305201503.h4KF30qx017842@mp2.vectant.ne.jp>
References: <5.1.0.14.2.20030520085158.01ea2cb0@mcmail.cis.mcmaster.ca>
	<5.1.0.14.2.20030520085158.01ea2cb0@mcmail.cis.mcmaster.ca>
Message-ID: <5.1.0.14.2.20030520113922.01e97588@mcmail.cis.mcmaster.ca>

Dear Mitsuo,

At 12:02 AM 5/21/2003 +0900, Mitsuo Igarashi wrote:
>Hello, Dear John.
>
>As you taught me, I obtained the result which I expect and is
>the same as that of EQS.
>I have started to learn structural equation modeling. This
>pushes my understanding SEM. Thank you very much.
>
>Would you permit me to ask a question?
>This EQS program sets an error covariance between V1 and V2.
>However,It seems to me that the package SEM does not have the
>method of error covariance. So I set a covariance between V1 and
>V2. What is the difference between these two settings of
>covariances?

Unlike EQS, the sem function uses the "ram" form of a structural-equation 
model. Setting a covariance between endogenous variables V1 and V2 is 
interpreted in this form of the model as an error covariance. See 
<http://www.socsci.mcmaster.ca/jfox/Books/Companion/appendix-sems.pdf> for 
some more information.

John

>Best regards.
>--------========----------
>Mitsuo Igarashi
>mitsu5 at ruby.famille.ne.jp
>---------------
>
>John Fox <jfox at mcmaster.ca> wrote:
>
> > Dear Mitsuo,
> >
> > You appear to be trying to fit a confirmatory factor analysis model with
> > five observed variables and two factors. Two of the five variables load on
> > both factors. Two variables have correlated measurement errors. I haven't
> > checked that the model that you intend to fit is identified but let's
> > suppose that it is.
> >
> > As you've described the model to sem, there are 16 free parameters, but
> > there are only 5*6/2 = 15 observed covariances (counting the diagonal
> > entries of the correlation matrix), so clearly there's a mistake in the
> > specification -- the model has negative degrees of freedom (and sem should
> > complain, but doesn't).
> >
> > The problem is that you've not placed any constraints on the model to fix
> > the scales of the factors. The simplest thing to do would be to fix the
> > variances of the factors to 1, rather than specifying them as free
> > parameters; as well, you don't have to start the measurement-error
> > variances at 1 rather than using the start values that sem computes, 
> though
> > it doesn't hurt to do so:
> >
> >  > model.mh<-matrix(c(
> > +         'F1 -> V1', 'a1',NA,
> > +         'F1 -> V3', 'a3',NA,
> > +         'F1 -> V4', 'a4',NA,
> > +         'F2 -> V2', 'b2',NA,
> > +         'F2 -> V3', 'b3',NA,
> > +         'F2 -> V4', 'b4',NA,
> > +         'F2 -> V5', 'b5',NA,
> > +         'V1 <-> V1','e1', NA,
> > +         'V2 <-> V2','e2', NA,
> > +         'V3 <-> V3','e3', NA,
> > +         'V4 <-> V4','e4', NA,
> > +         'V5 <-> V5','e5', NA,
> > +         'F1 <-> F1', NA, 1,
> > +         'F2 <-> F2', NA, 1,
> > +         'F1 <-> F2','c12',NA,
> > +         'V1 <-> V2','cv1', NA
> > +         ),ncol=3,byrow=T)
> >  > sem.mh <- sem(model.mh, data.mh, 100)
> >  > summary(sem.mh)
> >
> >   Model Chisquare =  2.2805   Df =  1 Pr(>Chisq) = 0.13101
> >   Goodness-of-fit index =  0.99097
> >   Adjusted goodness-of-fit index =  0.8646
> >   RMSEA index =  0.11373   90 % CI: (0, 0.31712)
> >   BIC =  -3.9341
> >
> >   Normalized Residuals
> >       Min.   1st Qu.    Median      Mean   3rd Qu.      Max.
> > -3.92e-01 -5.50e-02 -5.27e-06  3.27e-02  1.09e-01  7.98e-01
> >
> >   Parameter Estimates
> >      Estimate Std Error z value   Pr(>|z|)
> > a1  0.970680  0.275852 3.51884 4.3343e-04 V1 <--- F1
> > a3  0.317133  0.198819 1.59509 1.1069e-01 V3 <--- F1
> > a4  0.437281  0.250375 1.74651 8.0723e-02 V4 <--- F1
> > b2  0.526620  0.116264 4.52951 5.9119e-06 V2 <--- F2
> > b3  0.452136  0.196716 2.29842 2.1538e-02 V3 <--- F2
> > b4  0.234373  0.247929 0.94532 3.4449e-01 V4 <--- F2
> > b5  0.759562  0.131164 5.79092 7.0001e-09 V5 <--- F2
> > e1  0.052702  0.512634 0.10281 9.1812e-01 V1 <--> V1
> > e2  0.722672  0.126106 5.73065 1.0004e-08 V2 <--> V2
> > e3  0.552314  0.103604 5.33101 9.7669e-08 V3 <--> V3
> > e4  0.651868  0.128687 5.06552 4.0728e-07 V4 <--> V4
> > e5  0.423067  0.163535 2.58702 9.6811e-03 V5 <--> V5
> > c12 0.497557  0.167763 2.96584 3.0186e-03 F2 <--> F1
> > cv1 0.108796  0.076515 1.42190 1.5506e-01 V2 <--> V1
> >
> >   Iterations =  37
> >  >
> >
> > How does that compare to your EQS output?
> >
> > John
> >
> > At 04:37 PM 5/20/2003 +0900, you wrote:
> > >Hi.
> > >
> > >I have tried to use Package "SEM".
> > >
> > >As a learning, I try to convert a program running well of EQS
> > >which is as follows to SEM:
> > >
> > >###  EQS  ###
> > >/SPECIFICATION
> > >CAS=100; VAR=5 MAT=COR; ANA=COR;
> > >/EQUATIONS
> > >V1=*F1+E1; V2=*F1+E2; V3=*F1+*F2+E3; V4=**F1+*F2*E4;
> > >V5=*F2+E5;
> > >/VAR
> > >E1 TO E5=*; F1*1.0; F2=1.0;
> > >/COV
> > >E1,E2=*; F1,F2=*:
> > >/PRINT
> > >FIT ALL;
> > >/MATRIX ......
> > >/END
> > >
> > >This is the converted SEM program.
> > >###
> > >data.mh<-matrix(c(
> > >1.00,0,0,0, 0,
> > >0.38,1.00,0,0, 0,
> > >0.52,0.28,1.00,0,0,
> > >0.55,0.32,0.38,1.00,0,
> > >0.36,0.40,0.48,0.31,1.00
> > >),ncol=5,byrow=T)
> > >
> > >model.mh<-matrix(c(
> > >         'F1 -> V1', 'a1',NA,
> > >         'F1 -> V3', 'a3',NA,
> > >         'F1 -> V4', 'a4',NA,
> > >         'F2 -> V2', 'b2',NA,
> > >         'F2 -> V3', 'b3',NA,
> > >         'F2 -> V4', 'b4',NA,
> > >         'F2 -> V5', 'b5',NA,
> > >         'V1 <-> V1','e1', 1,
> > >         'V2 <-> V2','e2', 1,
> > >         'V3 <-> V3','e3', 1,
> > >         'V4 <-> V4','e4', 1,
> > >         'V5 <-> V5','e5', 1,
> > >         'F1 <-> F1','d1', 1,
> > >         'F2 <-> F2','d2', 1,
> > >         'F1 <-> F2','c12',NA,
> > >         'V1 <-> V2','cv1', NA,
> > >),ncol=3,byrow=T)
> > >obs.vars.mh <- c('V1','V2','V3','V4','V5')
> > >rownames(data.mh) <- colnames(data.mh) <- obs.vars.mh
> > >
> > >sem.mh <- sem(model.mh, data.mh, 100)
> > >###
> > >
> > >At this stage, everything looks going well.
> > >By debug mode of "sem()" it finishes with no error.
> > >However,the process of "summary(sem.mh)" produces an error.
> > >
> > > > summary(sem.mh)
> > >Error in optim(0, function(lam) ((1 - conf.level)/2 - pchisq(chisq, df,  :
> > >         Function cannot be evaluated at initial parameters
> > >In addition: Warning message:
> > >NaNs produced in: sqrt(diag(object$cov))
> > >
> > >It seems to me that there is something wrong at the conversion of
> > >"E1 TO E5=*;"  to " 'V1 <-> V2','cv1', NA ".
> > >
> > >Could anyone explain me how to manage this trouble?
> > >
> > >Thanks.
> > >
> > >--------========----------
> > >Mitsuo Igarashi
> > >mitsu5 at ruby.famille.ne.jp
> > >
> > >______________________________________________
> > >R-help at stat.math.ethz.ch mailing list
> > >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> > -----------------------------------------------------
> > John Fox
> > Department of Sociology
> > McMaster University
> > Hamilton, Ontario, Canada L8S 4M4
> > email: jfox at mcmaster.ca
> > phone: 905-525-9140x23604
> > web: www.socsci.mcmaster.ca/jfox
> > -----------------------------------------------------

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From ripley at stats.ox.ac.uk  Tue May 20 17:55:01 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 20 May 2003 16:55:01 +0100 (BST)
Subject: [R] problems with hist()
In-Reply-To: <16074.19419.594372.899471@coredump.wu-wien.ac.at>
Message-ID: <Pine.LNX.4.44.0305201651490.27144-100000@gannet.stats>

As a last resort, try read the help page:

     A numerical tolerance of 1e-7 times the range of the breaks is
     applied when counting entries on the edges of bins. 

If you use a silly range, this will affect your results.


On Tue, 20 May 2003, Guenter Tirler wrote:

> Hi,
> I try to compute the counts of a histogram of random numbers. But I
> get different results depending on the limits (-10,10) or (-1000,1000)
> although all numbers are in the interval (-10,10).
> 
> Have I done somthing wrong? 
> 
> 
> > x<-rnorm(1e6)
> > s1<-hist(x, br =c(-1000,-1,-0.5,0,0.5,1,1000),plot=FALSE)[[2]]
> > s2<-hist(x, br =c(-10,-1,-0.5,0,0.5,1,10),plot=FALSE)[[2]]
> > sum(s1)
> [1] 1000000
> > sum(s2)
> [1] 1000000
> >  s1                                                        
> [1] 159035 149461 192003 191478 149789 158234
> > s2
> [1] 159009 149452 192004 191464 149805 158266

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From spencer.graves at pdf.com  Tue May 20 17:55:27 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 20 May 2003 08:55:27 -0700
Subject: [R] regression coefficients
References: <Pine.LNX.4.44.0305201640060.27144-100000@gannet.stats>
Message-ID: <3ECA4FEF.10401@pdf.com>

Dear Prof. Ripley:  Of course, you are correct on both counts.  Thanks 
for the correction and elaboration.  spencer graves

Prof Brian Ripley wrote:
> Why is s assumed known and common to the k groups?  I doubt if that is 
> what was meant (although it was too imprecise to be at all sure).
> 
> If `common' is a viable assumption, you can just fit a model with by-group
> regressions vs one with a common regression (which seems to be what you
> are testing) and use anova().
> 
> If not, the case k=2 encompasses the Welch t-test so exact distribution
> theory is not going to be possible, but by fitting a common model and
> three separate models and summing the -2log-lik for the latter you can
> easily get the LT test and refer it to its `standard' (asymptotic)
> Chi-squared distribution.
> 
> On Tue, 20 May 2003, Spencer Graves wrote:
> 
> 
>>	  I don't know of a simply function to do what you want, but I can give 
>>you part of the standard log(likelihood ratio) theory:
>>
>>	  Suppose b[i]|s ~ N.r(b, s^2*W[i]), i = 1, ..., k.  Then the 
>>log(likelihood) is a sum of k terms of the following form:
>>
>>	  l[i] = (-0.5)*(r*log(2*pi*s^2)+log|W[i]|
>>	      +(s^-2)*t(b[i]-b)%*%solve(W[i]%*%(b[i]-b)
>>
>>By differentiating with respect to b and setting to 0, we get the 
>>maximum likelihood estimate for b as follows:
>>
>>	  b.hat = solve(sum(solve(W[i]))%*%sum(solve(W[i])%*%b[i])
>>
>>In words:  b.hat = weighted average with weights inversely proportional 
>>to the variances.  Then log(likelihood ratio) is as follows:
>>
>>	  log.LR = sum((s^-2)*t(b[i]-b.hat)%*%solve(W[i])%*%(b[i]-b.hat))
>>
>>This problem should be in most good books on multivariate analysis.  I 
>>would guess that log.LR probably has an F distribution with numerator 
>>degrees of freedom = r*(k-1) and with denominator degrees of freedom = 
>>degrees of freedom in the estimate of s.  However, I don't remember for 
>>sure.  It's vaguely possible that this is an "unsolved" problem.  In the 
>>latter case, you should have all the pieces here to generate a Monte 
>>Carlo.
> 
> 
> You have assumed s is known, in which case it is a Chi-squared 
> distribution.  If s is unknown, you need to maximize over it to get an LR 
> test (separately under the null and the alternative).
> 
> 
>>lamack lamack wrote:
>>
>>>dear all, How can I compare regression coefficients across three (or 
>>>more) groups?
>>
>



From mschwartz at medanalytics.com  Tue May 20 18:00:44 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 20 May 2003 11:00:44 -0500
Subject: [R] what.is(object)
In-Reply-To: <3ECA4CF3.7030508@yale.edu>
Message-ID: <002101c31ee8$f8be4190$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Welch, Ivo
>Sent: Tuesday, May 20, 2003 10:43 AM
>To: r-help at stat.math.ethz.ch
>Subject: [R] what.is(object)
>
>
>
>hi:  still experimenting.  is there a function that tells me what an
S 
>object is, or how it is constructed?
>
>s <- cor.test ( x, y );
>
>s$estimate$name = 'correlation' ;   <-  try to rename 'cor' to 
>'correlation' fails.  obviously, name is not a part here.
>s$newfield = c("another info field", 3.2 ) ;  <- this is not
congruous
>
>so
>
>what.is(s)       #tells me that this is a class called htest
>what.is(s$statistic)    # helps me
>
>would allow me to see how things are constructed.   does S 
>contain such 
>a feature?
>
>regards,
>
>/iaw


You can use str(s) to get the internal components and values.

See ?str

Using example data from cor.test:

> x <- c(44.4, 45.9, 41.9, 53.3, 44.7, 44.1, 50.7, 45.2, 60.1)
> y <- c( 2.6,  3.1,  2.5,  5.0,  3.6,  4.0,  5.2,  2.8,  3.8)
> s <- cor.test(x, y)
> str(s)
List of 9
 $ statistic  : Named num 1.84
  ..- attr(*, "names")= chr "t"
 $ parameter  : Named num 7
  ..- attr(*, "names")= chr "df"
 $ p.value    : num 0.108
 $ estimate   : Named num 0.571
  ..- attr(*, "names")= chr "cor"
 $ null.value : Named num 0
  ..- attr(*, "names")= chr "correlation"
 $ alternative: chr "two.sided"
 $ method     : chr "Pearson's product-moment correlation"
 $ data.name  : chr "x and y"
 $ conf.int   : atomic [1:2] -0.150  0.896
  ..- attr(*, "conf.level")= num 0.95
 - attr(*, "class")= chr "htest"


HTH,

Marc Schwartz



From spencer.graves at pdf.com  Tue May 20 18:07:34 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 20 May 2003 09:07:34 -0700
Subject: [R] what.is(object)
References: <3ECA4CF3.7030508@yale.edu>
Message-ID: <3ECA52C6.2040604@pdf.com>

Have you considered "class", "data.classe", and "attributes"?

hth.  spencer graves

Welch, Ivo wrote:
> hi:  still experimenting.  is there a function that tells me what an S 
> object is, or how it is constructed?
> 
> s <- cor.test ( x, y );
> 
> s$estimate$name = 'correlation' ;   <-  try to rename 'cor' to 
> 'correlation' fails.  obviously, name is not a part here.
> s$newfield = c("another info field", 3.2 ) ;  <- this is not congruous
> 
> so
> 
> what.is(s)       #tells me that this is a class called htest
> what.is(s$statistic)    # helps me
> 
> would allow me to see how things are constructed.   does S contain such 
> a feature?
> 
> regards,
> 
> /iaw
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Bernhard.Pfaff at drkw.com  Tue May 20 18:08:36 2003
From: Bernhard.Pfaff at drkw.com (Pfaff, Bernhard)
Date: Tue, 20 May 2003 18:08:36 +0200
Subject: [R] regression coefficients
Message-ID: <18D602BD42B7E24EB810D6454A58DB90047303A1@ibfftce505.is.de.dresdnerkb.com>

beside ?anova(), you might also be interested in considering the j-test, a
quick google retrieved:

http://support.sas.com/rnd/app/examples/ets/spec/

for an elucidation of the test problem.

HTH,
Bernhard

-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
Sent: 20 May 2003 17:51
To: Spencer Graves
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] regression coefficients


Why is s assumed known and common to the k groups?  I doubt if that is 
what was meant (although it was too imprecise to be at all sure).

If `common' is a viable assumption, you can just fit a model with by-group
regressions vs one with a common regression (which seems to be what you
are testing) and use anova().

If not, the case k=2 encompasses the Welch t-test so exact distribution
theory is not going to be possible, but by fitting a common model and
three separate models and summing the -2log-lik for the latter you can
easily get the LT test and refer it to its `standard' (asymptotic)
Chi-squared distribution.

On Tue, 20 May 2003, Spencer Graves wrote:

> 	  I don't know of a simply function to do what you want, but I can
give 
> you part of the standard log(likelihood ratio) theory:
> 
> 	  Suppose b[i]|s ~ N.r(b, s^2*W[i]), i = 1, ..., k.  Then the 
> log(likelihood) is a sum of k terms of the following form:
> 
> 	  l[i] = (-0.5)*(r*log(2*pi*s^2)+log|W[i]|
> 	      +(s^-2)*t(b[i]-b)%*%solve(W[i]%*%(b[i]-b)
> 
> By differentiating with respect to b and setting to 0, we get the 
> maximum likelihood estimate for b as follows:
> 
> 	  b.hat = solve(sum(solve(W[i]))%*%sum(solve(W[i])%*%b[i])
> 
> In words:  b.hat = weighted average with weights inversely proportional 
> to the variances.  Then log(likelihood ratio) is as follows:
> 
> 	  log.LR = sum((s^-2)*t(b[i]-b.hat)%*%solve(W[i])%*%(b[i]-b.hat))
> 
> This problem should be in most good books on multivariate analysis.  I 
> would guess that log.LR probably has an F distribution with numerator 
> degrees of freedom = r*(k-1) and with denominator degrees of freedom = 
> degrees of freedom in the estimate of s.  However, I don't remember for 
> sure.  It's vaguely possible that this is an "unsolved" problem.  In the 
> latter case, you should have all the pieces here to generate a Monte 
> Carlo.

You have assumed s is known, in which case it is a Chi-squared 
distribution.  If s is unknown, you need to maximize over it to get an LR 
test (separately under the null and the alternative).

> lamack lamack wrote:
> > dear all, How can I compare regression coefficients across three (or 
> > more) groups?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


----------------------------------------------------------------------
If you have received this e-mail in error or wish to read our e-mail 
disclaimer statement and monitoring policy, please refer to 
http://www.drkw.com/disc/email/ or contact the sender.



From gc4 at duke.edu  Tue May 20 18:24:54 2003
From: gc4 at duke.edu (gc4@duke.edu)
Date: Tue, 20 May 2003 12:24:54 -0400 (EDT)
Subject: [R] survit function and cox model with frailty
In-Reply-To: <Pine.A41.4.44.0305200808140.171844-100000@homer07.u.washington.edu>
References: <Pine.A41.4.44.0305200808140.171844-100000@homer07.u.washington.edu>
Message-ID: <Pine.GSO.4.53.0305201218060.13815@godzilla6.acpub.duke.edu>

Hi:

Special thanks to Thomas B. and Thomas L.

The question that arises is whether it is statistically legitimate to
estimate survival probabilities after fitting a cox model with a frailty
term.

In this regard, I offer a brief clarification on what I'm attempting to
do.

The example I submitted is a simplified working example I am using to make
sure I am able to make the code work. My assumption is that if it does not
work on something simple, it will not work on something more complicated.

I am estimating a model measuring the survival of political leaders in
office in a sample of 1992 leaders from 166 countries from 1919 to 1999.
My interest in on the effect of victory and defeat in war on leaders'
survival in office. I include variables measuring economic conditions,
domestic political institutions, domestic unrest, leaders' age and
previous times in office, and war participation and war outcomes. I also
include a country-level frailty term on the assumption that my covariates
only partially capture the range of country-specific conditions affecting
leaders' political survival.

If I interpret a frailty term as a latent effect that enters
multiplicatively into the specification of the hazard function, I can
consider it as an additional covariate associated with a hidden
coefficient of 1. Then, for example, I would ask what the survival
probabilities are given a covariate path for a political leader in a high
frailty country or in a low frailty country.

And if this is statistically legitimate, can the survfit function
accommodate a frailty term?

Thanks again to you all.
giacomo


On Tue, 20 May 2003, Thomas Lumley wrote:

> I don't actually understand what the intent is (and why the multiple time
> periods with identical covariates), but it isn't going to be at all
> straightforward to do a proper prediction for a single new case: the
> survival curve should be the survival distribution with the frailty
> integrated out, which is hard.
>
> It should be possible to do a prediction setting the frailty to 1, but it
> isn't.  Given that coxph will fit user-defined penalised likelihoods
> survfit would have to be fairly clever to guess what it was supposed to do
> in each circumstance.
>
>
> 	-thomas
>
>



From chrysopa at insecta.ufv.br  Tue May 20 18:31:31 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Tue, 20 May 2003 13:31:31 -0300
Subject: [R] Problem on model simplification with glmmPQL
Message-ID: <20030520162914.M47249@insecta.ufv.br>

Hi all,

I try to make a split-plot with poisson errors using glmmPQL, but I
have some doubts about the model simplification.

Look my system:

Block = 3 blocks
Xvar1 = 2 levels
Xvar2 = 13 levels
Yvar = Count data Response 

I need know about the behaviour of Var1, Var2 and interaction
Var1:Var2.

Look the levels:
> levels(Xvar1)
[1] "A" "B"
> levels(Xvar2)
 [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j" "k" "l" "m"
> levels(Block)
[1] "B1" "B2" "B3"

My general model in aov is:

aov(Yvar~Xvar1*Xvar2+Error(Block/Xvar1/Xvar2))

In glmmPQL I make this:

create the nested high level variable:

> BlockXvar1 <- as.factor(paste(Block,Xvar1))
> levels(BlockXvar1)
[1] "B1 A" "B1 B" "B2 A" "B2 B" "B3 A" "B3 B"
 
Make the model

> m1 <- 
glmmPQL(Yvar~Xvar1*Xvar2+Block,random=~1|BlockXvar1/Xvar2,family=poisson)
iteration 1 
iteration 2 
iteration 3 
iteration 4 
iteration 5 
iteration 6 
iteration 7 
iteration 8 
iteration 9 
iteration 10 
> anova(m1)
            numDF denDF  F-value p-value
(Intercept)     1    48 697.7770  <.0001
Xvar1           1     2 127.1378  0.0078
Xvar2          12    48 330.5172  <.0001
Block           2     2  22.7960  0.0420
Xvar1:Xvar2    12    48 282.0917  <.0001
 
OK, all variables are significative, now I try to make the model
simplification, I try to amalgamate levels of Xvar2.

Looking the mean:

> tapply(Yvar,list(Xvar2,Xvar1),mean)
           A          B
a  1.6666667  1.6666667
...
h  0.3333333  0.6666667
...
j  0.3333333  0.6666667
...
m 11.0000000  5.6666667

Look that the mean of h and j are exactly the same in A and B,
therefore h and j maybe amalgamated.

Then, I create a new Xvar2 whith these levels in one.

> Xvar2.amalg <- recode(Xvar2,"c('h','j')='hj'")
> levels(Xvar2.amalg)
 [1] "a"  "b"  "c"  "d"  "e"  "f"  "g"  "hj" "i"  "k"  "l"  "m" 

Now I make a new model, in lme I need to fit the model with
method="ML" to make it comparable, but in glmmPQL I dont know.

> m2 <- 
glmmPQL(Yvar~Xvar1*Xvar2.amalg+Block,random=~1|BlockXvar1/Xvar2.amalg,family=poisson)
iteration 1 
iteration 2 
iteration 3 
iteration 4 
iteration 5 
iteration 6 
iteration 7 
iteration 8 
iteration 9 
iteration 10 

and make a model comparison:

> anova(m1,m2)
   Model df      AIC      BIC     logLik   Test  L.Ratio p-value
m1     1 31 164.5596 237.6176  -51.27982                        
m2     2 29 353.6201 421.9647 -147.81006 1 vs 2 193.0605  <.0001

look the high significance, I dont understand this, the behaviour of
this two levels are the same, in this case the models must be no
significance and I get the model more simple, in this case teh model
with levels h and j like one level hj.

I try to make it using lme, but the comparison are significant too.

Where is the error?

Thanks
INte
Ronaldo

--
|   //|\\   [*****************************]
|| ( ? ? )  [Ronaldo Reis J?nior          ]
|     V     [ESALQ/USP-Entomologia, CP-09 ]
||  / l \   [13418-900 Piracicaba - SP    ]
|  /(lin)\  [Fone: 19-429-4199 r.229      ]
||/(linux)\ [chrysopa at insecta.ufv.br      ]
|/ (linux) \[ICQ#: 5692561                ]
||  ( x )   [*****************************]
||| _/ \_ Powered by Gnu/Debian Woody
-----------------------------------
Insecta - Entomologia
Departamento de Biologia Animal
Universidade Federal de Vi?osa



From chrysopa at insecta.ufv.br  Tue May 20 18:33:46 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Tue, 20 May 2003 13:33:46 -0300
Subject: [R] problem to save workspace
Message-ID: <20030520163144.M41352@insecta.ufv.br>

Hi,

I have a problem to save my workspace when I change the variables names.

Look:

Save workspace image? [y/n/c]: y
Warning messages: 
1: namespaces may not be available when loading 
2: names in persistent strings are currently ignored 

When I reload R:
I get the error:

Error in get(x, envir, mode, inherits) : variable "biplot" was not found
Fatal error: unable to restore saved data in .RData

Thanks
Ronaldo
--
|   //|\\   [*****************************]
|| ( ? ? )  [Ronaldo Reis J?nior          ]
|     V     [ESALQ/USP-Entomologia, CP-09 ]
||  / l \   [13418-900 Piracicaba - SP    ]
|  /(lin)\  [Fone: 19-429-4199 r.229      ]
||/(linux)\ [chrysopa at insecta.ufv.br      ]
|/ (linux) \[ICQ#: 5692561                ]
||  ( x )   [*****************************]
||| _/ \_ Powered by Gnu/Debian Woody
-----------------------------------
Insecta - Entomologia
Departamento de Biologia Animal
Universidade Federal de Vi?osa



From alkatz at post.tau.ac.il  Tue May 20 17:29:41 2003
From: alkatz at post.tau.ac.il (alkatz@post.tau.ac.il)
Date: Tue, 20 May 2003 18:29:41 +0300 (IDT)
Subject: [R] Calling R in BATCH mode from C programm
Message-ID: <1053444581.3eca49e59d052@webmail.tau.ac.il>

Hello R-people,

I have the following problem :

In order to run R script from DOS prompt in BATCH mode and pass it some
parameters I do the following :


Rterm --slave --no-save --no-restore <args.R> args.out ARG1=1 ARG2=2

It works fine :
the result is that the script args.R is isexecuted. Sys.getenv() sees the 
arguments ARG1 and ARG2, and the R creates output file args.out


Now I want to be able to call the same command from C application :


#include <conio.h>
#include <process.h>
#include <string.h>


void main()
{
   char *args[10], prog[80];
   int ch;

   strcpy(prog, "C:\\Program Files\\R\\RBase\\bin\\Rterm.exe "); 

   /* Arguments to Rterm.exe */
   args[0] = "--slave";
   args[1] = "--no-save";
   args[2] = "--no-restore";
   args[3] = "<args.R>";
   args[4] = "args.out";
   args[5] = "ARG1=1"; 
   args[6] = "ARG2=2";
   args[7] = NULL;
   

   _execl( prog, args[0], args[1], args[2], args[3], args[4], args[5], args[6], 
NULL);
}


Rterm starts, but writes to output :

ARGUMENT '<args.R>' __ignored__
ARGUMENT 'args.out' __ignored__


Command Sys.getenv("ARG1") returns correct result => R sees the rest of the 
arguments.

I tryed to type args[3] = "args.R" - without <> it does not help.

Does enyone know what might be my problem ??

Thanks,
Alex.



From ripley at stats.ox.ac.uk  Tue May 20 19:30:18 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 20 May 2003 18:30:18 +0100 (BST)
Subject: [R] Calling R in BATCH mode from C programm
In-Reply-To: <1053444581.3eca49e59d052@webmail.tau.ac.il>
Message-ID: <Pine.LNX.4.44.0305201823570.27414-100000@gannet.stats>

>From C, that is not how you redirect stdin, stdout (and you have forgotten
to redirect stderr).  I'll leave you to fathom that out (but as you are on
Windows, the R sources should give you many useful clues).  (Note that you 
do actually need a stdin and stdout to redirect, and a Windows application 
does not necessarily have them set up.)


On Tue, 20 May 2003 alkatz at post.tau.ac.il wrote:

> Hello R-people,
> 
> I have the following problem :
> 
> In order to run R script from DOS prompt in BATCH mode and pass it some
> parameters I do the following :
> 
> 
> Rterm --slave --no-save --no-restore <args.R> args.out ARG1=1 ARG2=2

That is actually <args.R >args.out: whether your form works depends on the 
OS and shell.  The effect is to redirect stdin/stdout and is done either 
by the shell or by the C initialization code.


> It works fine :
> the result is that the script args.R is isexecuted. Sys.getenv() sees the 
> arguments ARG1 and ARG2, and the R creates output file args.out
> 
> 
> Now I want to be able to call the same command from C application :
> 
> 
> #include <conio.h>
> #include <process.h>
> #include <string.h>
> 
> 
> void main()
> {
>    char *args[10], prog[80];
>    int ch;
> 
>    strcpy(prog, "C:\\Program Files\\R\\RBase\\bin\\Rterm.exe "); 
> 
>    /* Arguments to Rterm.exe */
>    args[0] = "--slave";
>    args[1] = "--no-save";
>    args[2] = "--no-restore";
>    args[3] = "<args.R>";
>    args[4] = "args.out";
>    args[5] = "ARG1=1"; 
>    args[6] = "ARG2=2";
>    args[7] = NULL;
>    
> 
>    _execl( prog, args[0], args[1], args[2], args[3], args[4], args[5], args[6], 
> NULL);
> }
> 
> 
> Rterm starts, but writes to output :
> 
> ARGUMENT '<args.R>' __ignored__
> ARGUMENT 'args.out' __ignored__
> 
> 
> Command Sys.getenv("ARG1") returns correct result => R sees the rest of the 
> arguments.
> 
> I tryed to type args[3] = "args.R" - without <> it does not help.
> 
> Does enyone know what might be my problem ??
> 
> Thanks,
> Alex.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From clists at perrin.socsci.unc.edu  Tue May 20 19:55:19 2003
From: clists at perrin.socsci.unc.edu (Andrew Perrin)
Date: Tue, 20 May 2003 13:55:19 -0400 (EDT)
Subject: [R] Extracting elements from an reStruct
Message-ID: <Pine.LNX.4.53.0305201348270.29959@perrin.socsci.unc.edu>

Sorry if this is obvious, but my S skills aren't great and I haven't been
able to find it documented anywhere.

I want to write a new function for use with lme objects; the function will
simply calculate an ICC (aka "rho") for each level of a mixed-effects
model.  What I need for this is pretty simple:

(c(var1..varn, residual)) / sum(c(var1..varn, residual))

where var1..varn are the variances of the intercepts of each level's
equation, and residual is the residual variance.  The problem is getting
access to var1..varn (or, as R generally reports it, sd1..sdn)
programmatically.  I can get the residual standard deviation with:

print(model$sigma)

and I can view the standard deviations with:

summary(model$modelStruct$lmeStruct)

But I can't figure out how to get at the standard deviations without the
human-readable print format.

Thanks-
Andy Perrin

----------------------------------------------------------------------
Andrew J Perrin - http://www.unc.edu/~aperrin
Assistant Professor of Sociology, U of North Carolina, Chapel Hill
clists at perrin.socsci.unc.edu * andrew_perrin (at) unc.edu



From news at chasset.net  Tue May 20 20:28:23 2003
From: news at chasset.net (Pierre-Olivier Chasset)
Date: Tue, 20 May 2003 20:28:23 +0200
Subject: [R] Anamorphosis
Message-ID: <200305202028.23797.news@chasset.net>

Dear Helper,

i just would like to know if it is possible to draw anamorphosis under R.

Thanks,

Pierre-Olivier Chasset



From tlumley at u.washington.edu  Tue May 20 21:36:50 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 20 May 2003 12:36:50 -0700 (PDT)
Subject: [R] survit function and cox model with frailty
In-Reply-To: <Pine.GSO.4.53.0305201218060.13815@godzilla6.acpub.duke.edu>
Message-ID: <Pine.A41.4.44.0305201135330.194520-100000@homer12.u.washington.edu>

On Tue, 20 May 2003 gc4 at duke.edu wrote:
>
> In this regard, I offer a brief clarification on what I'm attempting to
> do.
>
> The example I submitted is a simplified working example I am using to make
> sure I am able to make the code work. My assumption is that if it does not
> work on something simple, it will not work on something more complicated.
>
> I am estimating a model measuring the survival of political leaders in
> office in a sample of 1992 leaders from 166 countries from 1919 to 1999.
> My interest in on the effect of victory and defeat in war on leaders'
> survival in office. I include variables measuring economic conditions,
> domestic political institutions, domestic unrest, leaders' age and
> previous times in office, and war participation and war outcomes. I also
> include a country-level frailty term on the assumption that my covariates
> only partially capture the range of country-specific conditions affecting
> leaders' political survival.
>
> If I interpret a frailty term as a latent effect that enters
> multiplicatively into the specification of the hazard function, I can
> consider it as an additional covariate associated with a hidden
> coefficient of 1. Then, for example, I would ask what the survival
> probabilities are given a covariate path for a political leader in a high
> frailty country or in a low frailty country.
>
> And if this is statistically legitimate, can the survfit function
> accommodate a frailty term?
>

Yes, it is statistically legitimate. No, survfit can't do it. You could do
it yourself by extracting the baseline cumulative hazard and multiplying
it by the coefficients


An example, using the data in example(frailty)
 data(kidney)
 kfit <- coxph(Surv(time, status)~ age + sex + disease + frailty(id),
kidney
)
 H<-basehaz(kfit,centered=FALSE)

 # three new data points
 temp <- kidney[1:3,c("age","sex","disease")]
 # model.matrix without intercept
 Mtemp <- model.matrix(~age+sex+disease,temp)[,-1]
 # fitted log hazard ratio
 logHR <- Mtemp%*%coef(kfit)[,1]
 # turn it into a vector, not matrix
 logHR <- drop(logHR)
 # Hazard ratio
 HR <- exp(logHR)

 # survival curves with frailty=1
 frail1 <- exp( -outer(H$hazard,HR))
 # survival curves with frailty=2
 frail2 <- exp( -outer(H$hazard,HR)*2)
 # survival curves with frailty=0.5
 frail.5 <- exp( -outer(H$hazard,HR)*0.5)




	-thomas



From chrysopa at insecta.ufv.br  Tue May 20 21:39:15 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Tue, 20 May 2003 16:39:15 -0300
Subject: [R] Problem on model simplification with glmmPQL
Message-ID: <20030520162914.M47249@insecta.ufv.br>

Hi all,

I try to make a split-plot with poisson errors using glmmPQL, but I
have some doubts about the model simplification.

Look my system:

Block = 3 blocks
Xvar1 = 2 levels
Xvar2 = 13 levels
Yvar = Count data Response 

I need know about the behaviour of Var1, Var2 and interaction
Var1:Var2.

Look the levels:
> levels(Xvar1)
[1] "A" "B"
> levels(Xvar2)
 [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j" "k" "l" "m"
> levels(Block)
[1] "B1" "B2" "B3"

My general model in aov is:

aov(Yvar~Xvar1*Xvar2+Error(Block/Xvar1/Xvar2))

In glmmPQL I make this:

create the nested high level variable:

> BlockXvar1 <- as.factor(paste(Block,Xvar1))
> levels(BlockXvar1)
[1] "B1 A" "B1 B" "B2 A" "B2 B" "B3 A" "B3 B"
 
Make the model

> m1 <- 
glmmPQL(Yvar~Xvar1*Xvar2+Block,random=~1|BlockXvar1/Xvar2,family=poisson)
iteration 1 
iteration 2 
iteration 3 
iteration 4 
iteration 5 
iteration 6 
iteration 7 
iteration 8 
iteration 9 
iteration 10 
> anova(m1)
            numDF denDF  F-value p-value
(Intercept)     1    48 697.7770  <.0001
Xvar1           1     2 127.1378  0.0078
Xvar2          12    48 330.5172  <.0001
Block           2     2  22.7960  0.0420
Xvar1:Xvar2    12    48 282.0917  <.0001
 
OK, all variables are significative, now I try to make the model
simplification, I try to amalgamate levels of Xvar2.

Looking the mean:

> tapply(Yvar,list(Xvar2,Xvar1),mean)
           A          B
a  1.6666667  1.6666667
...
h  0.3333333  0.6666667
...
j  0.3333333  0.6666667
...
m 11.0000000  5.6666667

Look that the mean of h and j are exactly the same in A and B,
therefore h and j maybe amalgamated.

Then, I create a new Xvar2 whith these levels in one.

> Xvar2.amalg <- recode(Xvar2,"c('h','j')='hj'")
> levels(Xvar2.amalg)
 [1] "a"  "b"  "c"  "d"  "e"  "f"  "g"  "hj" "i"  "k"  "l"  "m" 

Now I make a new model, in lme I need to fit the model with
method="ML" to make it comparable, but in glmmPQL I dont know.

> m2 <- 
glmmPQL(Yvar~Xvar1*Xvar2.amalg+Block,random=~1|BlockXvar1/Xvar2.amalg,family=poisson)
iteration 1 
iteration 2 
iteration 3 
iteration 4 
iteration 5 
iteration 6 
iteration 7 
iteration 8 
iteration 9 
iteration 10 

and make a model comparison:

> anova(m1,m2)
   Model df      AIC      BIC     logLik   Test  L.Ratio p-value
m1     1 31 164.5596 237.6176  -51.27982                        
m2     2 29 353.6201 421.9647 -147.81006 1 vs 2 193.0605  <.0001

look the high significance, I dont understand this, the behaviour of
this two levels are the same, in this case the models must be no
significance and I get the model more simple, in this case teh model
with levels h and j like one level hj.

I try to make it using lme, but the comparison are significant too.

Where is the error?

Thanks
INte
Ronaldo

--
|   //|\\   [*****************************]
|| ( ? ? )  [Ronaldo Reis J?nior          ]
|     V     [ESALQ/USP-Entomologia, CP-09 ]
||  / l \   [13418-900 Piracicaba - SP    ]
|  /(lin)\  [Fone: 19-429-4199 r.229      ]
||/(linux)\ [chrysopa at insecta.ufv.br      ]
|/ (linux) \[ICQ#: 5692561                ]
||  ( x )   [*****************************]
||| _/ \_ Powered by Gnu/Debian Woody
-----------------------------------
Insecta - Entomologia
Departamento de Biologia Animal
Universidade Federal de Vi?osa



From stormplot at hotmail.com  Tue May 20 21:55:27 2003
From: stormplot at hotmail.com (Jason Fisher)
Date: Tue, 20 May 2003 12:55:27 -0700
Subject: [R] Tcltk question for R people
Message-ID: <Law9-F124ziJypQP6pk00009d14@hotmail.com>

Hello...

Curious to know whether the TK extensions Tktable and Iwidgets will be 
included in future versions of R (full installation).  These are key 
components of GUI construction and would be very useful in my current 
R-tcltk endeavors.  I realize that I could just install a version of 
ActiveTcl, which includes the extensions; however, my goal is to eventually 
distribute my work keeping installation procedures at a minimum.

I do have one question for individuals working with R and Tcl/Tk on Windows 
XP.  Has anyone experienced corrupted GUIs (lost widgets) after invoking a 
tkpack command (e.g. missing buttons).  My web searches on the subject leave 
me wondering if its a Windo$e problem.  Any ideas?

Thank you,
Jason

PS: Inclusion of the Tcl/Tk within the R 1.7.0 installation has been greatly 
appreciated.


***************************************
Jason C. Fisher
UCLA Graduate Student
Civil & Environmental Engineering Dept.
5731 Boelter Hall
Box 951593
Los Angeles, CA 90095-1593
Email: stormplot at hotmail.com



From clists at perrin.socsci.unc.edu  Tue May 20 21:58:04 2003
From: clists at perrin.socsci.unc.edu (Andrew Perrin)
Date: Tue, 20 May 2003 15:58:04 -0400 (EDT)
Subject: [R] Extracting elements from an reStruct
In-Reply-To: <3ECA7402.7090008@sentoo.sn>
References: <Pine.LNX.4.53.0305201348270.29959@perrin.socsci.unc.edu>
	<3ECA7402.7090008@sentoo.sn>
Message-ID: <Pine.LNX.4.53.0305201557140.29959@perrin.socsci.unc.edu>

Thanks to Renaud Lancelot, here's a working solution:

icc<-function(x) {
	v<-as.numeric(VarCorr(x)[,2])
	v<-as.numeric(na.omit(v))
	v^2 / sum(v^2)
}


Best,
Andy


----------------------------------------------------------------------
Andrew J Perrin - http://www.unc.edu/~aperrin
Assistant Professor of Sociology, U of North Carolina, Chapel Hill
clists at perrin.socsci.unc.edu * andrew_perrin (at) unc.edu


On Tue, 20 May 2003, Renaud Lancelot wrote:

> Andrew Perrin wrote:
> > Sorry if this is obvious, but my S skills aren't great and I haven't been
> > able to find it documented anywhere.
> >
> > I want to write a new function for use with lme objects; the function will
> > simply calculate an ICC (aka "rho") for each level of a mixed-effects
> > model.  What I need for this is pretty simple:
> >
> > (c(var1..varn, residual)) / sum(c(var1..varn, residual))
> >
> > where var1..varn are the variances of the intercepts of each level's
> > equation, and residual is the residual variance.  The problem is getting
> > access to var1..varn (or, as R generally reports it, sd1..sdn)
> > programmatically.  I can get the residual standard deviation with:
> >
> > print(model$sigma)
> >
> > and I can view the standard deviations with:
> >
> > summary(model$modelStruct$lmeStruct)
> >
> > But I can't figure out how to get at the standard deviations without the
> > human-readable print format.
> >
> > Thanks-
> > Andy Perrin
> >
> > ----------------------------------------------------------------------
> > Andrew J Perrin - http://www.unc.edu/~aperrin
> > Assistant Professor of Sociology, U of North Carolina, Chapel Hill
> > clists at perrin.socsci.unc.edu * andrew_perrin (at) unc.edu
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>
> Here is an example:
>
>  > library(nlme)
>  > data(Orthodont)
>  > fm <- lme(distance ~ age + Sex, data = Orthodont, random = ~ 1)
>  > summary(fm)
> [...]
> Random effects:
>   Formula: ~1 | Subject
>          (Intercept) Residual
> StdDev:    1.807425 1.431592
> [...]
>
>  > ## std dev.
>  > fm$sigma
> [1] 1.431592
>
>  > ## var-cov
>  > VarCorr(fm)
> Subject = pdLogChol(1)
>              Variance StdDev
> (Intercept) 3.266784 1.807425
> Residual    2.049456 1.431592
>
>  > ## variance components
>  > v <- sqrt(as.numeric(VarCorr(fm)[,1]))
>  > v
> [1] 1.807425 1.431592
>  > v/sum(v)
> [1] 0.5580165 0.4419835
>
> Best,
>
> Renaud
>
> --
> Dr Renaud Lancelot, v?t?rinaire
> CIRAD, D?partement Elevage et M?decine V?t?rinaire (CIRAD-Emvt)
> Programme Productions Animales
> http://www.cirad.fr/fr/pg_recherche/page.php?id=14
>
> ISRA-LNERV                      tel    +221 832 49 02
> BP 2057 Dakar-Hann              fax    +221 821 18 79 (CIRAD)
> Senegal                         e-mail renaud.lancelot at cirad.fr
>
>



From arrayprofile at yahoo.com  Tue May 20 22:44:11 2003
From: arrayprofile at yahoo.com (array chip)
Date: Tue, 20 May 2003 13:44:11 -0700 (PDT)
Subject: [R] stepAIC
Message-ID: <20030520204411.50253.qmail@web41201.mail.yahoo.com>

Hi,

I tried to use stepAIC for a cox proportional model
(30 independent variables) built by coxph. I found
that no matter whether I used direction="forward" or
direction="backward" as an option in stepAIC, I
alweays got exactly the same output, i.e. it seems
only backward selection was performed (eliminate 1
variable at a time). why did it happen like this? or
for cox model, stepAIC can only perform backward
selection?

thanks

zander



From ripley at stats.ox.ac.uk  Tue May 20 22:58:31 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 20 May 2003 21:58:31 +0100 (BST)
Subject: [R] stepAIC
In-Reply-To: <20030520204411.50253.qmail@web41201.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0305202154020.28023-100000@gannet.stats>

stepAIC is support software for MASS4.  There is an example in the book of 
it doing what you claim it cannot do.  So do look it up and see what your 
mistake was.

On Tue, 20 May 2003, array chip wrote:

> I tried to use stepAIC for a cox proportional model
> (30 independent variables) built by coxph. I found
> that no matter whether I used direction="forward" or
> direction="backward" as an option in stepAIC, I
> alweays got exactly the same output, i.e. it seems
> only backward selection was performed (eliminate 1
> variable at a time). why did it happen like this? or
> for cox model, stepAIC can only perform backward
> selection?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue May 20 23:19:19 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 20 May 2003 22:19:19 +0100 (BST)
Subject: [R] Tcltk question for R people
In-Reply-To: <Law9-F124ziJypQP6pk00009d14@hotmail.com>
Message-ID: <Pine.LNX.4.44.0305202159190.28023-100000@gannet.stats>

On Tue, 20 May 2003, Jason Fisher wrote:

> Curious to know whether the TK extensions ?Tktable? and ?Iwidgets? will be 
> included in future versions of R (full installation).  These are key 

On Windows?  Only if that is an offer to take over the provision and
testing of R_Tcl.zip.

> components of GUI construction and would be very useful in my current 
> R-tcltk endeavors.  I realize that I could just install a version of 
> ActiveTcl, which includes the extensions; however, my goal is to eventually 
> distribute my work keeping installation procedures at a minimum.

Um, that sounds like a very lazy approach: `let me make work for the R 
volunteers to keep my own work to a minimum'.  You seem to misunderstand 
the R project.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From yanyu at cs.ucla.edu  Tue May 20 23:23:28 2003
From: yanyu at cs.ucla.edu (Yan Yu)
Date: Tue, 20 May 2003 14:23:28 -0700 (PDT)
Subject: [R] a quick Q about memory limit in R
Message-ID: <Pine.SOL.4.33.0305201420100.23320-100000@panther.cs.ucla.edu>

Hello, there,
   I got this error when i tried to run " data.kr <- surf.gls(2, expcov,
data, d=0.7);"

"Error: cannot allocate vector of size 382890 Kb
Execution halted"

My data is 100x100 grid.

the following is the summary of "data":
> summary(data);
       x                y                z
 Min.   :  1.00   Min.   :  1.00   Min.   :-1.0172
 1st Qu.: 26.00   1st Qu.: 25.75   1st Qu.: 0.6550
 Median : 51.00   Median : 50.50   Median : 0.9657
 Mean   : 50.99   Mean   : 50.50   Mean   : 1.0000
 3rd Qu.: 76.00   3rd Qu.: 75.25   3rd Qu.: 1.2817
 Max.   :100.00   Max.   :100.00   Max.   : 2.6501

I have 2 Qs:
(1). for a 100x100 grid, why R tried to allocate such a HUGE vector,
382890 Kb??

(2) what decides the memory limit in R, How can increase that?

Many thanks,
yan



From nelson.oliveira at ufba.br  Tue May 20 23:25:55 2003
From: nelson.oliveira at ufba.br (Nelson)
Date: Tue, 20 May 2003 21:25:55 -0000
Subject: [R] graphs with two different y-scales
Message-ID: <000901c31f16$597fdfc0$019311c8@im.ufba.br>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030520/89c8666e/attachment.pl

From jeff_hamann at hamanndonald.com  Tue May 20 23:27:11 2003
From: jeff_hamann at hamanndonald.com (Jeff D. Hamann)
Date: Tue, 20 May 2003 14:27:11 -0700
Subject: [R] building a Win32 DLL with R objects?
Message-ID: <000201c31f16$e6749f10$7c74c180@forestry.oregonstate.edu>

I've been attemping to create a test dll that contains R objects (actually I
simply copied the code from the "Writing R extensions") and got it to build
the dll using rcmd shlib main.c (okay, it's simple, but effective). Here's
the info so far:

this is the contents of the main.c file (not there's no WinMain()). Do we
put it in or does the script do it when we compile?

/* this is a test for the r package to access r objects from a c lib */

#include "R.h"
#include "Rdefines.h"

SEXP test_function( SEXP a, SEXP b )
{

   int     na;
   int     nb;
   int     nab;
   double  *xa;
   double  *xb;
   double  *xab;

   SEXP ab;

   PROTECT( a = AS_NUMERIC( a ) );
   PROTECT( b = AS_NUMERIC( b ) );

   warning( "you're now in test_function\n" );

   na = LENGTH( a );
   nb = LENGTH( b );
   nab = na + nb - 1;

   PROTECT( nab = AS_NUMERIC( nab ) );

   xa = NUMERIC_POINTER( a );
   xb = NUMERIC_POINTER( b );
   xab = NUMERIC_POINTER( ab );


   UNPROTECT( 3 );

   return ab;

}

I built the dll using the "rcmd shlib main.c" and a dll pops out in the end.
Yeah for me! Now, I tried to call my function using:

## this is a simple r program to demonstrate how to
## call openfvs functions....
dyn.load("c:/rdll_test/main.dll" )
x <- c( 1, 2.3568, 3.14159 )
y <- c( -568.89234, 4, 3234.23424 )
conv <- function( a, b ) .Call( "test_function", a, b )

and I'm not sure the DLL actually getting loaded? I've been able to step
through other DLL projects I call from R, but none that use the R libraries.
When I run the script from the terminal (using rterm.exe), R just sits there
as if stuck in a loop and nothing happens. I would like to be able to step
through this using the visual studio debugger but haven't been able to
figure out how to build R DLLs using something other than the RCMD SHLIB.

WHen I try to compile a project, similar to my other projects I've been
calling from R, I get the following linker errors:

Linking...
main.obj : error LNK2001: unresolved external symbol _Rf_unprotect
main.obj : error LNK2001: unresolved external symbol _REAL
main.obj : error LNK2001: unresolved external symbol _LENGTH
main.obj : error LNK2001: unresolved external symbol _Rf_warning
main.obj : error LNK2001: unresolved external symbol _Rf_protect
main.obj : error LNK2001: unresolved external symbol _Rf_coerceVector
Debug/rdll_test.dll : fatal error LNK1120: 6 unresolved externals
Error executing link.exe.

rdll_test.dll - 7 error(s), 6 warning(s)

And I can't find the lib file I should be including. Is there one or am I
barking up the wrong tree?

Jeff.



From ripley at stats.ox.ac.uk  Wed May 21 00:08:16 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 20 May 2003 23:08:16 +0100 (BST)
Subject: [R] building a Win32 DLL with R objects?
In-Reply-To: <000201c31f16$e6749f10$7c74c180@forestry.oregonstate.edu>
Message-ID: <Pine.LNX.4.44.0305202302420.28103-100000@gannet.stats>

On Tue, 20 May 2003, Jeff D. Hamann wrote:

> I've been attemping to create a test dll that contains R objects (actually I
> simply copied the code from the "Writing R extensions") and got it to build
> the dll using rcmd shlib main.c (okay, it's simple, but effective). Here's
> the info so far:
>
> this is the contents of the main.c file (not there's no WinMain()). Do we
> put it in or does the script do it when we compile?

The linker does what is needed to build a DLL and with gcc/ld there is no 
need of a user-supplied WinMain.

[...]

> WHen I try to compile a project, similar to my other projects I've been
> calling from R, I get the following linker errors:
> 
> Linking...
> main.obj : error LNK2001: unresolved external symbol _Rf_unprotect
> main.obj : error LNK2001: unresolved external symbol _REAL
> main.obj : error LNK2001: unresolved external symbol _LENGTH
> main.obj : error LNK2001: unresolved external symbol _Rf_warning
> main.obj : error LNK2001: unresolved external symbol _Rf_protect
> main.obj : error LNK2001: unresolved external symbol _Rf_coerceVector
> Debug/rdll_test.dll : fatal error LNK1120: 6 unresolved externals
> Error executing link.exe.
> 
> rdll_test.dll - 7 error(s), 6 warning(s)
> 
> And I can't find the lib file I should be including. Is there one or am I
> barking up the wrong tree?

Did you actually make R.lib?  The info is in readme.packages.  If you did, 
you haven't added it to your project.

Note that as an Open Source project we do not actually support VC++, but 
there is information there on how to use it.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jerome at hivnet.ubc.ca  Wed May 21 00:09:00 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Tue, 20 May 2003 15:09:00 -0700
Subject: [R] graphs with two different y-scales
In-Reply-To: <000901c31f16$597fdfc0$019311c8@im.ufba.br>
References: <000901c31f16$597fdfc0$019311c8@im.ufba.br>
Message-ID: <200305202214.PAA14256@hivnet.ubc.ca>


First, you have to choose a common scaling for both of your y-variates, so 
that you can use that scaling to plot your two variables. If you want to 
plot curves, then read ?curve.

Then, you can use the axis() function to define multiple (i.e. two) axes 
for your y-variates.

HTH,
Jerome


On July 25, 2003 01:49 pm, Nelson wrote:
> I am trying to put in the same graph two functions with different y
> scales. Can anyone help me on how to do it? Nelson
>
> 	[[alternate HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From stormplot at hotmail.com  Wed May 21 01:28:10 2003
From: stormplot at hotmail.com (Jason Fisher)
Date: Tue, 20 May 2003 16:28:10 -0700
Subject: [R] Tcltk question for R people
Message-ID: <Law9-F99fr4k8GoKY7m0003a45f@hotmail.com>

Hello...

In regards to Professor Ripley's comments, perhaps you misunderstand my 
intentions.  My belief is that R is an incredible programming language which 
has been created from an enormous amount of hard work from people like you.  
I've been working off and on with S+ for about three years and R for the 
last year.  Much of my work in the past six months has been on the 
development of a graphics tool (GWplot) for the analysis of groundwater flow 
and transport models.  The software relies heavily upon both the RODBC 
(MySQL) and tcltk packages, both of which are working incredibly stable on 
my Windows XP machine.  I know, you had enough of my praises for R, where's 
the goods you ask...  What have I given to the R community?  As of yet, I'm 
disappointed to say, almost nothing at all.  Due to the unpredictable nature 
of civil engineering coarse requirements, I've been unable to focus on a 
single R project for very long.  This has changed given that I'm solely 
working toward my dissertation at this point in time.  I can only assure you 
that all of my code and software will be submitted (with documentation) to 
the R community in the near future.  The number of hours I've put into this 
project has been enormous.

Furthermore, I accept your offer and would gladly take over the provision 
and testing of the R_Tcl.zip.  Im not sure if I'm the perfect one for the 
job; however, working with Tcl/Tk has been a real pleasure so far.

Thanks for your time,

Jason

>On Windows?  Only if that is an offer to take over the provision and
>testing of R_Tcl.zip.

>Um, that sounds like a very lazy approach: `let me make work for the R 
>volunteers to keep my own work to a minimum'.  You seem to misunderstand 
>the R project.




***************************************
Jason C. Fisher
UCLA Graduate Student
Civil & Environmental Engineering Dept.
5731 Boelter Hall
Box 951593
Los Angeles, CA 90095-1593
Email: stormplot at hotmail.com



From jerome at hivnet.ubc.ca  Wed May 21 01:52:30 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Tue, 20 May 2003 16:52:30 -0700
Subject: [R] legend() with option adj=1
Message-ID: <200305202358.QAA18847@hivnet.ubc.ca>


Hi there,

I want to justify to right the text of my legend. Consider this short 
reproducable example.

x <- 1:5
y1 <- 1/x
y2 <- 2/x
plot(rep(x,2),c(y1,y2),type="n",xlab="x",ylab="y")
lines(x,y1)
lines(x,y2,lty=2)
legend(5,2,c("1,000","1,000,000"),lty=1:2,xjust=1,yjust=1)
legend(5,1.5,c("1,000","1,000,000"),lty=1:2,xjust=1,yjust=1,adj=1)

Now, I would like to right-justify the text of the legend. As you can see, 
the option adj=1 does not give satisfactory results.

Is this a bug or is there an easy way that I'm missing?

Thanks,
Jerome

-- 

Jerome Asselin (J?r?me), Statistical Analyst
British Columbia Centre for Excellence in HIV/AIDS
St. Paul's Hospital, 608 - 1081 Burrard Street
Vancouver, British Columbia, CANADA V6Z 1Y6
Email: jerome at hivnet.ubc.ca
Phone: 604 806-9112   Fax: 604 806-9044



From mitsu5 at ruby.famille.ne.jp  Wed May 21 02:38:06 2003
From: mitsu5 at ruby.famille.ne.jp (Mitsuo Igarashi)
Date: Wed, 21 May 2003 09:38:06 +0900
Subject: [R] How to use pakcage SEM
In-Reply-To: <5.1.0.14.2.20030520113922.01e97588@mcmail.cis.mcmaster.ca>
References: <5.1.0.14.2.20030520113922.01e97588@mcmail.cis.mcmaster.ca>
Message-ID: <200305210038.h4L0cBqx005166@mp2.vectant.ne.jp>

Dear John:

I appreciate the teaching given by the author of the package SEM.

It is a nice paper "appendix-sems.pdf" for me.
And I have found a book "An R and S-PLUS Companion to Applied 
Regression by John Fox". I am going to learn more.

Thank you very much indeed.
Best Regards.
--------========----------
Mitsuo Igarashi
mitsu5 at ruby.famille.ne.jp
-----------

John Fox <jfox at mcmaster.ca> wrote:

> Dear Mitsuo,
> 
> At 12:02 AM 5/21/2003 +0900, Mitsuo Igarashi wrote:
> >Hello, Dear John.
> >
> >As you taught me, I obtained the result which I expect and is
> >the same as that of EQS.
> >I have started to learn structural equation modeling. This
> >pushes my understanding SEM. Thank you very much.
> >
> >Would you permit me to ask a question?
> >This EQS program sets an error covariance between V1 and V2.
> >However,It seems to me that the package SEM does not have the
> >method of error covariance. So I set a covariance between V1 and
> >V2. What is the difference between these two settings of
> >covariances?
> 
> Unlike EQS, the sem function uses the "ram" form of a structural-equation 
> model. Setting a covariance between endogenous variables V1 and V2 is 
> interpreted in this form of the model as an error covariance. See 
> <http://www.socsci.mcmaster.ca/jfox/Books/Companion/appendix-sems.pdf> for 
> some more information.
> 
> John



From jeff_hamann at hamanndonald.com  Wed May 21 02:47:35 2003
From: jeff_hamann at hamanndonald.com (Jeff D. Hamann)
Date: Tue, 20 May 2003 17:47:35 -0700
Subject: [R] moving onto returning a data.frame?
Message-ID: <000901c31f32$927a99c0$7c74c180@forestry.oregonstate.edu>

I've been studying some of the code and I'm still a little shakey on the
proper method for returning a data.frame from a C function (which is my
ultimate goal here). I've started some code that I've "stolen" from the
archives and I'm running into crashes, etc. I've been trying to gleen some
insight from the src/main/scan.c file and didn't find many comments in the
code that would benifit a newbie.

Does anyone have a good example (from some of the packages?) for returning a
data.frame. I'm trying to start my function so that it takes a data.frame as
an argument and returns a data.frame (post-hocus-pocus).

Here's my function so far...

SEXP testfunction3(
   SEXP m_in )
{

   int *mdims, n, p, i;
   double *mm;

   SEXP m_out;
   SEXP nms;

   if( !isMatrix( m_in ) )
   {
      error("m_in must be a matrix");
   }



   mdims = INTEGER( GET_DIM( m_in ) );
   n = mdims[0];
   p = mdims[1];
   PROTECT( m_out = NEW_NUMERIC( p ) );
   PROTECT( m_in = AS_NUMERIC( m_in ) );
   PROTECT( nms = GET_COLNAMES( GET_DIMNAMES( m_in ) ) );

    /* here you'll disect the incoming data.frame into the vectors you'll
pass into your simulation code */
    /* get the vectors based on the column names to make sure the sequence
isn't important */

    /* crunch, crunch, crunch */

    /* assign the results into the outgoing data.frame which will have the
same dimensions as the incoming frame */


    if( !isNull( nms ) )
   {
      namesgets( m_out, nms );
   }

   UNPROTECT( 3 );

   return m_out;
}


Thanks,
Jeff.



From stephenb at csd.net.au  Wed May 21 03:16:21 2003
From: stephenb at csd.net.au (Stephen Beale)
Date: Wed, 21 May 2003 11:16:21 +1000
Subject: [R] Code Help 
Message-ID: <NEBBLBOPGLKMLFHDIGPAGEHNCFAA.stephenb@csd.net.au>

I am trying to analyse some data and was given R code to do this with but
there seem to be errors in the code.  My level of knowledge is improving but
still limited.

The details are;

Data on clover lines; Lines.txt	attached.  Comma seperations

Code:

options(digits=3)

clover <- read.table("Lines.txt",header=T,sep=",")
vnames <- names(clover);nv <- length(vnames)
flevels <- levels(clover$Line)

par(oma=c(0,6,4,6),mfrow=c(2,1),mar=c(4,4,1,0))

clover$Y <- clover[,"LeafLmm"]
mn.tab <- tapply(clover$Y,list(clover$Line),mean)
sd.tab <- sqrt(tapply(clover$Y,list(clover$Line),var))

om <- order(mn.tab)
plot(mn.tab,sd.tab,las=1,xlab="mean",ylab="s.d.")
lines(lowess(mn.tab,sd.tab))


model.i <- glm(Y  ~ C(clover$Line,Cline),data=clover,family=gaussian),

Beta <- summary(model.i)$coefficients
new.order <- order(Beta[-1,1])  + 1
Obeta <- Beta[c(1,new.order),]

detect.diff <- quantile(Obeta,probs=seq(0.2,0.8,0.2))
std.dev <- (min(Obeta[-1,2]) + max(Obeta[-1,2]))/2*sqrt(5)
sink("ClovAttr.txt")
print(paste("_____________",vnames[(i+2)],"_____________"))
cat("__________ mean table _______ \n")
print(mn.tab[om])
cat("__________ s.d. table _______ \n")
print(sd.tab[om])
print(model.i$family)
print(Obeta)
print(detect.diff)
cat("_________________________________\n")
sink()

library(ctest)

stdev <- round(std.dev*c(1.25,1,0.75),2)
stderr <- round(stdev/sqrt(5),2)
samp.size <- 3:10
beta <- 0.8

ylab <- "detectable differences"
for (j in seq(along=stdev)){
   Delta <- numeric(0)
for(k in seq(along=samp.size)){
Power.calcs <- power.t.test(n=samp.size[k],delta=NULL,sd=stdev[j],
 sig.level=0.05,power=beta,type="one.sample",alternative="one.sided")

beta  <- Power.calcs$power
Delta <- c(Delta,Power.calcs$delta)
          }  #   end of the k loop
if(j==1){
max.Delta <- max(Delta)
plot(samp.size,Delta,type='l',xlab="n",ylab=ylab,las=1,
    ylim=c(0,max.Delta),xlim=c(3,10))
         }   #   end of if(j==1)
else lines(samp.size,Delta,lty=j)
         }   #   end of j loop
mtext(vnames[i],side=3,outer=T,cex=1.2)

legend(7,max.Delta,legend=paste("s.e",stderr),lty=1:length(stdev))
text(5,0.9*max.Delta,"power=0.8")

_________________________________
The issue is the number of leaves to be sampled.
As above I only needed to analyse as a linear model, Plot curves of
detectable difference @ 3 standard deviations etc.  All the code is there
but there seems to be errors.  model.i I don't know what Cline is supposed
to be (possibly clover$Line), the detect.diff line is incorrect, the looping
through J&K appears incorrect and I don't know what i in the vnames is
supposed to be.

Any help?  This is probably simple stuff for experienced people.

Stephen Beale

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Lines.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030521/20fd52eb/Lines.txt

From kwan022 at stat.auckland.ac.nz  Wed May 21 03:29:06 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Wed, 21 May 2003 13:29:06 +1200 (NZST)
Subject: [R] Code Help 
In-Reply-To: <NEBBLBOPGLKMLFHDIGPAGEHNCFAA.stephenb@csd.net.au>
Message-ID: <Pine.LNX.4.44.0305211327020.28074-100000@stat61.stat.auckland.ac.nz>

Hi,

On Wed, 21 May 2003, Stephen Beale wrote:

> Code:
> 
> options(digits=3)
> 
> clover <- read.table("Lines.txt",header=T,sep=",")
> vnames <- names(clover);nv <- length(vnames)
> flevels <- levels(clover$Line)
> 
> par(oma=c(0,6,4,6),mfrow=c(2,1),mar=c(4,4,1,0))
> 
> clover$Y <- clover[,"LeafLmm"]
> mn.tab <- tapply(clover$Y,list(clover$Line),mean)
> sd.tab <- sqrt(tapply(clover$Y,list(clover$Line),var))
> 
> om <- order(mn.tab)
> plot(mn.tab,sd.tab,las=1,xlab="mean",ylab="s.d.")
> lines(lowess(mn.tab,sd.tab))
> 
> 
> model.i <- glm(Y  ~ C(clover$Line,Cline),data=clover,family=gaussian),

Take a close look at this line.  For one thing you have got a comma at the 
end which produce a syntax error.

Secondly, what is Cline?  I did a:
> colnames(clover)
[1] "Line"          "repl"          "LeafLmm"       "LeafWmm"      
[5] "Stolonthickmm" "StolonLcm"     "StolonDens"    "LeafAmm"      
[9] "Y"  

and it showed no column with name Cline.


-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)



From mail at joeconway.com  Wed May 21 04:13:06 2003
From: mail at joeconway.com (Joe Conway)
Date: Tue, 20 May 2003 19:13:06 -0700
Subject: [R] moving onto returning a data.frame?
In-Reply-To: <000901c31f32$927a99c0$7c74c180@forestry.oregonstate.edu>
References: <000901c31f32$927a99c0$7c74c180@forestry.oregonstate.edu>
Message-ID: <3ECAE0B2.90409@joeconway.com>

Jeff D. Hamann wrote:
> Does anyone have a good example (from some of the packages?) for returning a
> data.frame. I'm trying to start my function so that it takes a data.frame as
> an argument and returns a data.frame (post-hocus-pocus).
> 

I found this to be quite the challenge also. See pg_tuple_get_r_frame() 
in the file pg_conversion.c from PL/R. You can grab a copy here:
http://www.joeconway.com/

If you have any questions after looking through that, contact me off 
list and I'll try to help. That said, there's no guarantee my code is 
correct, but at least it seems to work in all of my use-cases so far ;-)

HTH,

Joe



From ligges at statistik.uni-dortmund.de  Wed May 21 08:47:59 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 21 May 2003 08:47:59 +0200
Subject: [R] a quick Q about memory limit in R
In-Reply-To: <Pine.SOL.4.33.0305201420100.23320-100000@panther.cs.ucla.edu>
References: <Pine.SOL.4.33.0305201420100.23320-100000@panther.cs.ucla.edu>
Message-ID: <3ECB211F.70801@statistik.uni-dortmund.de>

Yan Yu wrote:
> Hello, there,
>    I got this error when i tried to run " data.kr <- surf.gls(2, expcov,
> data, d=0.7);"
> 
> "Error: cannot allocate vector of size 382890 Kb
> Execution halted"
> 
> My data is 100x100 grid.
> 
> the following is the summary of "data":
> 
>>summary(data);
> 
>        x                y                z
>  Min.   :  1.00   Min.   :  1.00   Min.   :-1.0172
>  1st Qu.: 26.00   1st Qu.: 25.75   1st Qu.: 0.6550
>  Median : 51.00   Median : 50.50   Median : 0.9657
>  Mean   : 50.99   Mean   : 50.50   Mean   : 1.0000
>  3rd Qu.: 76.00   3rd Qu.: 75.25   3rd Qu.: 1.2817
>  Max.   :100.00   Max.   :100.00   Max.   : 2.6501
> 
> I have 2 Qs:
> (1). for a 100x100 grid, why R tried to allocate such a HUGE vector,
> 382890 Kb??

Because you perform some calculations with the data which consumes more 
memory than the data itself, e.g. by generating some matrices, temporary 
objects and copies of the data.

> (2) what decides the memory limit in R, How can increase that?

a) See ?Memory and the R FAQ 7.1, for example. If you are on Windows 
also R fow Windows FAQ 2.7. These are obvious places to look, aren't they?

b) By buying some more memory for your machine.

Uwe Ligges

> Many thanks,
> yan



From ligges at statistik.uni-dortmund.de  Wed May 21 08:52:45 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 21 May 2003 08:52:45 +0200
Subject: [R] problem to save workspace
In-Reply-To: <20030520163144.M41352@insecta.ufv.br>
References: <20030520163144.M41352@insecta.ufv.br>
Message-ID: <3ECB223D.20106@statistik.uni-dortmund.de>

Ronaldo Reis Jr. wrote:
> Hi,
> 
> I have a problem to save my workspace when I change the variables names.

What does this mean? What is a variable and how do you change its name?


> Look:
> 
> Save workspace image? [y/n/c]: y
> Warning messages: 
> 1: namespaces may not be available when loading 
> 2: names in persistent strings are currently ignored 
> 
> When I reload R:
> I get the error:
> 
> Error in get(x, envir, mode, inherits) : variable "biplot" was not found
> Fatal error: unable to restore saved data in .RData
> 
> Thanks
> Ronaldo

Hard to reproduce given one knows nothing about what you did before.

Uwe Ligges



From s.su at qut.edu.au  Wed May 21 08:53:00 2003
From: s.su at qut.edu.au (Steve Su)
Date: Wed, 21 May 2003 16:53:00 +1000
Subject: [R] inspect now available?
Message-ID: <000e01c31f65$9e5563a0$2032b583@busaccb337f>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030521/97746fcd/attachment.pl

From ligges at statistik.uni-dortmund.de  Wed May 21 09:05:55 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 21 May 2003 09:05:55 +0200
Subject: [R] inspect now available?
In-Reply-To: <000e01c31f65$9e5563a0$2032b583@busaccb337f>
References: <000e01c31f65$9e5563a0$2032b583@busaccb337f>
Message-ID: <3ECB2553.7060507@statistik.uni-dortmund.de>

Steve Su wrote:
> Dear All,
> 
> I am wondering if R now has a similar function to inspect in Splus? Someone post this question in 1999 and the answer was no, and I am wondering if this function has been developed in 2003? 
> 
> Thanks for your attention. 
> 

There is not function called inspect(), but other debugging tools are 
evailable. See, e.g., ?debug, ?recover, ?debugger and all the other 
functions mentioned on that help pages.

Uwe Ligges


> **************************************************************************************
> 
>  Steve Su (s.su at qut.edu.au)    
>  PhD student.  
>



From ligges at statistik.uni-dortmund.de  Wed May 21 09:19:11 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 21 May 2003 09:19:11 +0200
Subject: [R] legend() with option adj=1
In-Reply-To: <200305202358.QAA18847@hivnet.ubc.ca>
References: <200305202358.QAA18847@hivnet.ubc.ca>
Message-ID: <3ECB286F.3010803@statistik.uni-dortmund.de>

Jerome Asselin wrote:
> Hi there,
> 
> I want to justify to right the text of my legend. Consider this short 
> reproducable example.
> 
> x <- 1:5
> y1 <- 1/x
> y2 <- 2/x
> plot(rep(x,2),c(y1,y2),type="n",xlab="x",ylab="y")
> lines(x,y1)
> lines(x,y2,lty=2)
> legend(5,2,c("1,000","1,000,000"),lty=1:2,xjust=1,yjust=1)
> legend(5,1.5,c("1,000","1,000,000"),lty=1:2,xjust=1,yjust=1,adj=1)
> 
> Now, I would like to right-justify the text of the legend. As you can see, 
> the option adj=1 does not give satisfactory results.
> 
> Is this a bug or is there an easy way that I'm missing?
> 
> Thanks,
> Jerome
> 

Works, e.g., with the following little trick:

  x <- 1:5
  y1 <- 1/x
  y2 <- 2/x
  plot(rep(x,2),c(y1,y2),type="n",xlab="x",ylab="y")
  lines(x,y1)
  lines(x,y2,lty=2)
  temp <- legend(5, 2, legend = c(" ", " "),
    text.width = strwidth("1,000,000"), lty = 1:2, xjust = 1, yjust = 1)
  text(temp$rect$left + temp$rect$w, temp$text$y,
     c("1,000", "1,000,000"), pos=2)

See ?legend for details, in particular the returned value.

Uwe Ligges



From Roger.Bivand at nhh.no  Wed May 21 10:38:52 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 21 May 2003 10:38:52 +0200 (CEST)
Subject: [R] a quick Q about memory limit in R
In-Reply-To: <Pine.SOL.4.33.0305201420100.23320-100000@panther.cs.ucla.edu>
Message-ID: <Pine.LNX.4.44.0305211021230.15864-100000@reclus.nhh.no>

On Tue, 20 May 2003, Yan Yu wrote:

> Hello, there,
>    I got this error when i tried to run " data.kr <- surf.gls(2, expcov,
> data, d=0.7);"
> 
> "Error: cannot allocate vector of size 382890 Kb
> Execution halted"
> 
> My data is 100x100 grid.
> 
This is, I think, where the problem is. You have n=10000 observations, and 
if you do debug(surf.gls) before running, you will probably find that it 
stops at:

    Z <- .C("VR_gls", as.double(x), as.double(y), as.double(z), 
        as.integer(n), as.integer(np), as.integer(npar), as.double(f), 
        l = double((n * (n + 1))/2), r = double((npar * (npar + 
            1))/2), beta = double(npar), wz = double(n), yy = double(n), 
        W = double(n), ifail = as.integer(0), l1f = double(n * 
            npar), PACKAGE = "spatial")

because (n * (n + 1))/2 in your case is 50,005,000, times 8 as a double,
so l is a very large object ("On output L contains the Cholesky factor of
the covariance matrix of the observations" - comment in spatial/src/kr.c).
Do you need to have so many observations? If so, perhaps you could
consider using other packages that permit the search area to be restricted
to close neighbours of your observations?


> the following is the summary of "data":
> > summary(data);
>        x                y                z
>  Min.   :  1.00   Min.   :  1.00   Min.   :-1.0172
>  1st Qu.: 26.00   1st Qu.: 25.75   1st Qu.: 0.6550
>  Median : 51.00   Median : 50.50   Median : 0.9657
>  Mean   : 50.99   Mean   : 50.50   Mean   : 1.0000
>  3rd Qu.: 76.00   3rd Qu.: 75.25   3rd Qu.: 1.2817
>  Max.   :100.00   Max.   :100.00   Max.   : 2.6501
> 
> I have 2 Qs:
> (1). for a 100x100 grid, why R tried to allocate such a HUGE vector,
> 382890 Kb??
> 
> (2) what decides the memory limit in R, How can increase that?
> 
> Many thanks,
> yan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From gb at stat.umu.se  Wed May 21 11:05:51 2003
From: gb at stat.umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Wed, 21 May 2003 11:05:51 +0200 (CEST)
Subject: [R] Truncation of text strings
Message-ID: <Pine.LNX.4.44.0305211102030.3768-100000@tal.stat.umu.se>

How do I print text strings to a given length, ie, if they are too long
I want them truncated (from the end)?

> format.char("123", width = 1)

does not do what I want, ie, "1".

---
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se



From Roger.Bivand at nhh.no  Wed May 21 11:18:02 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 21 May 2003 11:18:02 +0200 (CEST)
Subject: [R] Truncation of text strings
In-Reply-To: <Pine.LNX.4.44.0305211102030.3768-100000@tal.stat.umu.se>
Message-ID: <Pine.LNX.4.44.0305211115540.15864-100000@reclus.nhh.no>

On Wed, 21 May 2003, G?ran Brostr?m wrote:

> How do I print text strings to a given length, ie, if they are too long
> I want them truncated (from the end)?
> 
> > format.char("123", width = 1)

?substr

substr("123", 1, 1)

> 
> does not do what I want, ie, "1".
> 
> ---
>  G?ran Brostr?m                    tel: +46 90 786 5223
>  Department of Statistics          fax: +46 90 786 6614
>  Ume? University                   http://www.stat.umu.se/egna/gb/
>  SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From ligges at statistik.uni-dortmund.de  Wed May 21 11:31:15 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 21 May 2003 11:31:15 +0200
Subject: [R] Truncation of text strings
In-Reply-To: <Pine.LNX.4.44.0305211102030.3768-100000@tal.stat.umu.se>
References: <Pine.LNX.4.44.0305211102030.3768-100000@tal.stat.umu.se>
Message-ID: <3ECB4763.6030902@statistik.uni-dortmund.de>

G?ran Brostr?m wrote:
> How do I print text strings to a given length, ie, if they are too long
> I want them truncated (from the end)?
> 
> 
>>format.char("123", width = 1)
> 
> 
> does not do what I want, ie, "1".
> 
> ---
>  G?ran Brostr?m                    tel: +46 90 786 5223
>  Department of Statistics          fax: +46 90 786 6614
>  Ume? University                   http://www.stat.umu.se/egna/gb/
>  SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


See ?substring

Uwe Ligges



From helmut.schuetz at chello.at  Wed May 21 12:02:46 2003
From: helmut.schuetz at chello.at (Helmut =?iso-8859-1?Q?Sch=FCtz?=)
Date: Wed, 21 May 2003 12:02:46 +0200
Subject: [R] Publication/Reference
Message-ID: <3ECB4EC6.6FF8EC5B@chello.at>

Dear List,

this may be a little off-topic, but I failed to obtain the "mother of
R"-reference through a couple of library services...
Maybe someone can provide me with a PDF?

Ross Ihaka and Robert Gentleman.
R: A language for data analysis and graphics.
Journal of Computational and Graphical Statistics, 5(3):299-314, 1996

Helmut Schuetz
Biokinet GmbH
A-1170 Vienna
Tel +43(0)1 4856969-62
Fax +43(0)1 4856969-90



From laurent.buffat at it-omics.com  Wed May 21 12:03:33 2003
From: laurent.buffat at it-omics.com (laurent  buffat)
Date: Wed, 21 May 2003 12:03:33 +0200
Subject: [R] callNextMethod
Message-ID: <DGEIIIMDDGKLGHFCOPOFOEGLCCAA.laurent.buffat@it-omics.com>


Hi,

I don't understand why this code doesn't work (f(b2)):

/////////////////

setClass("B0", representation(b0 = "numeric"))
setClass("B1", representation("B0", b1 = "character"))
setClass("B2", representation("B1", b2 = "logical"))

f <- function(x) class(x)

setMethod("f", "B0", function(x) c(x at b0, callNextMethod()))
setMethod("f", "B1", function(x) c(x at b1,x at b0*x at b0,callNextMethod()))
setMethod("f", "B2", function(x) c(x at b2, callNextMethod()))

b0 <- new("B0", b0 = 3)
b1 <- new("B1", b1 = "deux", b0 = 2)
b2 <- new("B2", b2 = FALSE, b1 = "dix", b0 = 10)

f(b0)
f(b1)
f(b2)

///////////////////////////

> f(b0)
[1] "3"  "B0"
> f(b1)
[1] "deux" "4"    "2"    "B1"  
> f(b2)
Error in get(x, envir, mode, inherits) : variable ".Generic" was not found

//////////////////////////////

I'm using R Version 1.7.0, on a linux machine.

Thanks for your help.

Laurent B.



From gb at stat.umu.se  Wed May 21 12:11:45 2003
From: gb at stat.umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Wed, 21 May 2003 12:11:45 +0200 (CEST)
Subject: [R] Truncation of text strings
In-Reply-To: <3ECB4763.6030902@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.44.0305211210040.4160-100000@tal.stat.umu.se>

On Wed, 21 May 2003, Uwe Ligges wrote:

> G?ran Brostr?m wrote:
> > How do I print text strings to a given length, ie, if they are too long
> > I want them truncated (from the end)?
> > 
> > 
> >>format.char("123", width = 1)
> > 
> > 
> > does not do what I want, ie, "1".
> > 
> > ---
> >  G?ran Brostr?m                    tel: +46 90 786 5223
> >  Department of Statistics          fax: +46 90 786 6614
> >  Ume? University                   http://www.stat.umu.se/egna/gb/
> >  SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 
> See ?substring

Oh yes, thanks to all who responded!

G?ran



From maechler at stat.math.ethz.ch  Wed May 21 12:15:17 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 21 May 2003 12:15:17 +0200
Subject: [R] Publication/Reference
In-Reply-To: <3ECB4EC6.6FF8EC5B@chello.at>
References: <3ECB4EC6.6FF8EC5B@chello.at>
Message-ID: <16075.20917.384901.220362@gargle.gargle.HOWL>

>>>>> "Helmut" == Helmut Sch?tz <helmut.schuetz at chello.at>
>>>>>     on Wed, 21 May 2003 12:02:46 +0200 writes:

    Helmut> Dear List, this may be a little off-topic, but I
    Helmut> failed to obtain the "mother of R"-reference through
    Helmut> a couple of library services...  Maybe someone can
    Helmut> provide me with a PDF?

    HS> Ross Ihaka and Robert Gentleman.
    HS>   R: A language for data analysis and graphics.  
    HS>  Journal of Computational and Graphical Statistics, 5(3):299-314, 1996

    Helmut> Helmut Schuetz Biokinet GmbH A-1170 Vienna
    Helmut> Tel +43(0)1 4856969-62 Fax +43(0)1 4856969-90

Sorry not to solve your problem, but
it's hard to believe that no University library in Vienna has
a subscription of JCGS (the journal).  If that's true,
please complain with them!

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From alkatz at post.tau.ac.il  Wed May 21 11:15:36 2003
From: alkatz at post.tau.ac.il (alkatz@post.tau.ac.il)
Date: Wed, 21 May 2003 12:15:36 +0300 (IDT)
Subject: [R] Calling R in BATCH mode from C programm
In-Reply-To: <Pine.LNX.4.44.0305201823570.27414-100000@gannet.stats>
References: <Pine.LNX.4.44.0305201823570.27414-100000@gannet.stats>
Message-ID: <1053508536.3ecb43b8674ef@webmail.tau.ac.il>

Dear, Prof. Repley,

thank you for the help,
of course, you are right. 

Redirection of stdin, stdout, stderr does the job.

If R script saves and reloads apprpriate workspaces,
then this method may be used instead of calling R functions from
C/C++ directly, wich is currently a problem, as I understand.

Here is C code that calls R in BATCH mode with arguments.
Then R runs script args.R wich reads the input arguments with Sys.getenv()
function and prints output to args.out and err.out files.

May be someone will find it usefull :

#include <stdio.h>
#include <stdlib.h>
#include <string.h>


char emsg[] = "can't redirect %s to %s\n";

void main ()
{
	int result, i;
	char buf[5120];

	if (!freopen( "args.R", "r", stdin )) {
		fprintf( stderr, emsg, "stdin", "args.R" );
		exit( 1 );
	}
	if (!freopen( "args.out", "w", stdout )) {
		fprintf( stderr, emsg, "stdout", "args.out" );
		exit( 1 );
	}
	if (!freopen( "err.out", "a", stderr )) {
		fprintf( stderr, emsg, "stderr", "err.out" );
		exit( 1 );
	}

	strcpy( buf, "Rterm --slave --no-save --no-restore ARG1=1 ARG2=2" );

	if (result = system( buf ))
		fprintf( stderr, "exit code = %d, errno = %d\n", result, 
errno );
}





Quoting Prof Brian Ripley <ripley at stats.ox.ac.uk>:

> >From C, that is not how you redirect stdin, stdout (and you have
> forgotten
> to redirect stderr).  I'll leave you to fathom that out (but as you are
> on
> Windows, the R sources should give you many useful clues).  (Note that
> you 
> do actually need a stdin and stdout to redirect, and a Windows
> application 
> does not necessarily have them set up.)
> 
> 
> On Tue, 20 May 2003 alkatz at post.tau.ac.il wrote:
> 
> > Hello R-people,
> > 
> > I have the following problem :
> > 
> > In order to run R script from DOS prompt in BATCH mode and pass it
> some
> > parameters I do the following :
> > 
> > 
> > Rterm --slave --no-save --no-restore <args.R> args.out ARG1=1 ARG2=2
> 
> That is actually <args.R >args.out: whether your form works depends on
> the 
> OS and shell.  The effect is to redirect stdin/stdout and is done either
> 
> by the shell or by the C initialization code.
> 
> 
> > It works fine :
> > the result is that the script args.R is isexecuted. Sys.getenv() sees
> the 
> > arguments ARG1 and ARG2, and the R creates output file args.out
> > 
> > 
> > Now I want to be able to call the same command from C application :
> > 
> > 
> > #include <conio.h>
> > #include <process.h>
> > #include <string.h>
> > 
> > 
> > void main()
> > {
> >    char *args[10], prog[80];
> >    int ch;
> > 
> >    strcpy(prog, "C:\\Program Files\\R\\RBase\\bin\\Rterm.exe "); 
> > 
> >    /* Arguments to Rterm.exe */
> >    args[0] = "--slave";
> >    args[1] = "--no-save";
> >    args[2] = "--no-restore";
> >    args[3] = "<args.R>";
> >    args[4] = "args.out";
> >    args[5] = "ARG1=1"; 
> >    args[6] = "ARG2=2";
> >    args[7] = NULL;
> >    
> > 
> >    _execl( prog, args[0], args[1], args[2], args[3], args[4], args[5],
> args[6], 
> > NULL);
> > }
> > 
> > 
> > Rterm starts, but writes to output :
> > 
> > ARGUMENT '<args.R>' __ignored__
> > ARGUMENT 'args.out' __ignored__
> > 
> > 
> > Command Sys.getenv("ARG1") returns correct result => R sees the rest
> of the 
> > arguments.
> > 
> > I tryed to type args[3] = "args.R" - without <> it does not help.
> > 
> > Does enyone know what might be my problem ??
> > 
> > Thanks,
> > Alex.
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From Giles.Heywood at CommerzbankIB.com  Wed May 21 12:40:55 2003
From: Giles.Heywood at CommerzbankIB.com (Heywood, Giles)
Date: Wed, 21 May 2003 11:40:55 +0100
Subject: [R] "locked environment"
Message-ID: <8CBAA121CEB4D5118CB200508BB2BBEF540344@xmx8lonib.lonib.commerzbank.com>

I have a class defined as an extension to matrix:
fooCLASS <- setClass("foo",representation("matrix"))

and define a method for a generic function (no problem):
setMethod("diff",signature(x="foo"),diff.foo <- function(x){x})

but I get a different behaviour for another generic function:
setMethod("lag",signature(x="foo"),lag.foo <- function(x){x})

Error in assign(".packageName", pkg, env) : 
can't add bindings to a locked environment

I did not get this behaviour under 1.5.1, it ran fine - any pointers?

platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    7.0            
year     2003           
month    04             
day      16             
language R              


********************************************************************** 
This is a commercial communication from Commerzbank AG.\ \ This ... {{dropped}}



From hgoehlmann at gmx.de  Wed May 21 13:56:40 2003
From: hgoehlmann at gmx.de (hgoehlmann@gmx.de)
Date: Wed, 21 May 2003 13:56:40 +0200 (MEST)
Subject: [R] Functionality of pdf()
References: <8CBAA121CEB4D5118CB200508BB2BBEF540344@xmx8lonib.lonib.commerzbank.com>
Message-ID: <14995.1053518200@www6.gmx.net>

Hello,

this might be too much to ask, but just a thought...     There are some
efforts in the bioconductor area where people create functions to produce html
tables which include links to current information. Would there be any chance
that somebody can implement a similar functionality in the pdf device, so that
you can not only create a graph but can also create a "clickable" graph with
link to current information?

Cheers,
hinrich    d8-)



From B.Rowlingson at lancaster.ac.uk  Wed May 21 14:19:02 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 21 May 2003 13:19:02 +0100
Subject: [R] Functionality of pdf()
In-Reply-To: <14995.1053518200@www6.gmx.net>
References: <8CBAA121CEB4D5118CB200508BB2BBEF540344@xmx8lonib.lonib.commerzbank.com>
	<14995.1053518200@www6.gmx.net>
Message-ID: <3ECB6EB6.6020104@lancaster.ac.uk>

hgoehlmann at gmx.de wrote:
> Hello,
> 
> this might be too much to ask, but just a thought...     There are some
> efforts in the bioconductor area where people create functions to produce html
> tables which include links to current information. Would there be any chance
> that somebody can implement a similar functionality in the pdf device, so that
> you can not only create a graph but can also create a "clickable" graph with
> link to current information?
>

  On a related note, I've just finished some R code to produce HTML 
imagemaps. You do something like this:

  im <- imagemap("Test",height=400,width=400)

  plot(1:10,1:10)

  addRegion(im) <- imCircle(5,5,.3,href="Point5.html")

  createPage(im,file="Test.html")

  imClose(im)

This produces Test.html and Test.png. When Test.html is viewed, you see 
the plot and can click within 0.3 units of the fifth point to go to the 
given URL.

  You can add rectangular, circular and polygonal clickable regions. You 
can specify a default for a click anywhere else. You can even have 
clickable rotated text or expressions. You can use par(mfrow=...) and 
have several plots with clickable bits on each one.

  Instead of createPage() you can call createIM() which will produce 
HTML Imagemap code for including into a web page.

  There's some horribly tricksy stuff involved in getting the right 
coordinates in the PNG file, and some limitations. Currently it cant 
deal with log-axes, and you cant do dev.copy() to put stuff in the PNG. 
But what it can do is quite useful.

  The documentation is sparsish, but once I've written some more 
examples and .Rd files I'll announce it to the world.

Baz



From mhayashi_jp at yahoo.com  Wed May 21 14:40:33 2003
From: mhayashi_jp at yahoo.com (Masayoshi Hayashi)
Date: Wed, 21 May 2003 05:40:33 -0700 (PDT)
Subject: [R] Graphics device history recording problem (Previous and Next
	utilities) 
Message-ID: <20030521124033.94871.qmail@web10807.mail.yahoo.com>

I use 1.7.0 version under Windows XP.

Problem:
When graphics device history recording function turned
on, suppose I source a file containing lines:

plot(graph1)
plot(graph2)

I see the graph2 in the graphic device, assuming
graph2 is the last plot in the file. Now using
"Previous" under history menu, I get graph1 as
expected. But after that, using "Next" does not show
graph2. Is this a normal behavior? If so how do you
get back to graph2? I have observed the same behavior
in 1.6.2.

Thank you for your input.



From ripley at stats.ox.ac.uk  Wed May 21 14:54:00 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 21 May 2003 13:54:00 +0100 (BST)
Subject: [R] Graphics device history recording problem (Previous and Next
	utilities) 
In-Reply-To: <20030521124033.94871.qmail@web10807.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0305211352340.29156-100000@gannet.stats>

On Wed, 21 May 2003, Masayoshi Hayashi wrote:

> I use 1.7.0 version under Windows XP.
> 
> Problem:
> When graphics device history recording function turned
> on, suppose I source a file containing lines:
> 
> plot(graph1)
> plot(graph2)
> 
> I see the graph2 in the graphic device, assuming
> graph2 is the last plot in the file. Now using
> "Previous" under history menu, I get graph1 as
> expected. But after that, using "Next" does not show
> graph2. Is this a normal behavior? If so how do you
> get back to graph2? I have observed the same behavior
> in 1.6.2.

R does not know the plot is finished until you go on to the next one.
So you have to explicitly add the current state of the current plot to the 
history, when it will work.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Wed May 21 15:02:05 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 21 May 2003 14:02:05 +0100 (BST)
Subject: [R] "locked environment"
In-Reply-To: <8CBAA121CEB4D5118CB200508BB2BBEF540344@xmx8lonib.lonib.commerzbank.com>
Message-ID: <Pine.LNX.4.44.0305211357420.29156-100000@gannet.stats>

On Wed, 21 May 2003, Heywood, Giles wrote:

> I have a class defined as an extension to matrix:
> fooCLASS <- setClass("foo",representation("matrix"))
> 
> and define a method for a generic function (no problem):
> setMethod("diff",signature(x="foo"),diff.foo <- function(x){x})
> 
> but I get a different behaviour for another generic function:
> setMethod("lag",signature(x="foo"),lag.foo <- function(x){x})
> 
> Error in assign(".packageName", pkg, env) : 
> can't add bindings to a locked environment
> 
> I did not get this behaviour under 1.5.1, it ran fine - any pointers?

lag() is in package ts, which has a namespace these days.  Why are you
setting S4 methods on S3 generics?  You will be able to set S3 methods.

> lag
function (x, ...)
UseMethod("lag")
<environment: namespace:ts>
> diff
function (x, ...)
UseMethod("diff")
<environment: namespace:base>

(and BTW the base namespace is somewhat different and not locked).
The combination of S4 methods and namespaces is not supported, so if you 
need this you will need to define the S4 generic somewhere you own.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dmurdoch at pair.com  Wed May 21 15:15:40 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed, 21 May 2003 09:15:40 -0400
Subject: [R] Graphics device history recording problem (Previous and Next
	utilities) 
In-Reply-To: <20030521124033.94871.qmail@web10807.mail.yahoo.com>
References: <20030521124033.94871.qmail@web10807.mail.yahoo.com>
Message-ID: <jtumcvk7vqc3jv9ckq5ccsafs3aabti4gq@4ax.com>

On Wed, 21 May 2003 05:40:33 -0700 (PDT), you wrote:

>I use 1.7.0 version under Windows XP.
>
>Problem:
>When graphics device history recording function turned
>on, suppose I source a file containing lines:
>
>plot(graph1)
>plot(graph2)
>
>I see the graph2 in the graphic device, assuming
>graph2 is the last plot in the file. Now using
>"Previous" under history menu, I get graph1 as
>expected. But after that, using "Next" does not show
>graph2. Is this a normal behavior? If so how do you
>get back to graph2? I have observed the same behavior
>in 1.6.2.

I don't see this.  Could you post exactly what you did, in what order?
Are you using MDI (one big window holding smaller subwindows) or SDI
(all separate windows)?

Duncan Murdoch



From wolski at molgen.mpg.de  Wed May 21 15:21:05 2003
From: wolski at molgen.mpg.de (Wolski)
Date: Wed, 21 May 2003 15:21:05 +0200
Subject: [R] cluster- binary data.
Message-ID: <200305211521050246.01585CC3@harry.molgen.mpg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030521/aab4f933/attachment.pl

From midnightsun at blueyonder.co.uk  Wed May 21 15:31:28 2003
From: midnightsun at blueyonder.co.uk (Adam)
Date: Wed, 21 May 2003 14:31:28 +0100
Subject: [R] rts conversion to ts?
Message-ID: <AMEEIKBPDPIFIPFANMHGMEHGCAAA.midnightsun@blueyonder.co.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030521/046cdb3b/attachment.pl

From jonathan.williams at pharmacology.oxford.ac.uk  Wed May 21 16:10:18 2003
From: jonathan.williams at pharmacology.oxford.ac.uk (Jonathan Williams)
Date: Wed, 21 May 2003 15:10:18 +0100
Subject: [R] dev.copy(pdf) messes up legend box
Message-ID: <NGBBKJEMOMLJFCOIEGCEAECEJJAA.jonathan.williams@pharm.ox.ac.uk>

When I use dev.print(pdf) and dev.copy(pdf) to print the *same*
graph, the box around the legend is too small using dev.copy(pdf)
- it cuts off the last letter of the (7-letter) labels.

Jonathan Williams
OPTIMA
Radcliffe Infirmary
Woodstock Road
OXFORD OX2 6HE
Tel +1865 (2)24356



From ripley at stats.ox.ac.uk  Wed May 21 16:08:33 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 21 May 2003 15:08:33 +0100 (BST)
Subject: [R] dev.copy(pdf) messes up legend box
In-Reply-To: <NGBBKJEMOMLJFCOIEGCEAECEJJAA.jonathan.williams@pharm.ox.ac.uk>
Message-ID: <Pine.LNX.4.44.0305211502110.9939-100000@gannet.stats>

You need to match the pointsizes on the source and the destination
devices, relative to the width and height.  It is not the box which is too
small but the text which is too large.  (See the comment in MASS4 p.454.)

Alternatively, re-plot on the intended destination device.

On Wed, 21 May 2003, Jonathan Williams wrote:

> When I use dev.print(pdf) and dev.copy(pdf) to print the *same*
> graph, the box around the legend is too small using dev.copy(pdf)
> - it cuts off the last letter of the (7-letter) labels.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tlumley at u.washington.edu  Wed May 21 16:15:12 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 21 May 2003 07:15:12 -0700 (PDT)
Subject: [R] moving onto returning a data.frame?
In-Reply-To: <000901c31f32$927a99c0$7c74c180@forestry.oregonstate.edu>
Message-ID: <Pine.A41.4.44.0305210710140.155406-100000@homer07.u.washington.edu>

On Tue, 20 May 2003, Jeff D. Hamann wrote:
> Does anyone have a good example (from some of the packages?) for returning a
> data.frame. I'm trying to start my function so that it takes a data.frame as
> an argument and returns a data.frame (post-hocus-pocus).

read.dta in the foreign package springs to mind since I updated it
yesterday.  There are probably many others.

> Here's my function so far...
>
> SEXP testfunction3(
>    SEXP m_in )
> {
>
>    int *mdims, n, p, i;
>    double *mm;
>
>    SEXP m_out;
>    SEXP nms;
>
>    if( !isMatrix( m_in ) )
>    {
>       error("m_in must be a matrix");
>    }
>
>
>
>    mdims = INTEGER( GET_DIM( m_in ) );
>    n = mdims[0];
>    p = mdims[1];
>    PROTECT( m_out = NEW_NUMERIC( p ) );

You are creating a vector of p reals here, not a data frame. If you know
the input and output have the same sizes and types it might be easiest to
use
    m_out = duplicate(m_in)
though this is not maximally efficient.

>    PROTECT( m_in = AS_NUMERIC( m_in ) );
>    PROTECT( nms = GET_COLNAMES( GET_DIMNAMES( m_in ) ) );
>
>     /* here you'll disect the incoming data.frame into the vectors you'll
> pass into your simulation code */
>     /* get the vectors based on the column names to make sure the sequence
> isn't important */
>
>     /* crunch, crunch, crunch */
>
>     /* assign the results into the outgoing data.frame which will have the
> same dimensions as the incoming frame */
>
>
>     if( !isNull( nms ) )
>    {
>       namesgets( m_out, nms );
>    }
>
>    UNPROTECT( 3 );
>
>    return m_out;
> }
>

	-thomas

Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From meinhardploner at gmx.net  Wed May 21 16:17:40 2003
From: meinhardploner at gmx.net (Meinhard Ploner)
Date: Wed, 21 May 2003 16:17:40 +0200
Subject: [R] overlapping a plot with an external image
Message-ID: <FAF2D2B2-8B96-11D7-ADA9-0003930EA956@gmx.net>

It's possible to overlap an external image (jpg or pdf)
with a plot generated with R?

Specifying the image as the background
of the plot might not be possible...

any idea?

thanks
Meinhard Ploner



From ripley at stats.ox.ac.uk  Wed May 21 16:38:56 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 21 May 2003 15:38:56 +0100 (BST)
Subject: [R] overlapping a plot with an external image
In-Reply-To: <FAF2D2B2-8B96-11D7-ADA9-0003930EA956@gmx.net>
Message-ID: <Pine.LNX.4.44.0305211535180.32308-100000@gannet.stats>

On Wed, 21 May 2003, Meinhard Ploner wrote:

> It's possible to overlap an external image (jpg or pdf)
> with a plot generated with R?
> 
> Specifying the image as the background
> of the plot might not be possible...

Although this has been discussed, R graphics devices cannot as yet plot
bitmap images.  So all one can do is to plot a set of rectangles: for that 
the pixmap package might be helpful.

Although we might add the ability to plot a bitmap image, note that it is 
not straightforward, as R screen graphics devices can be dynamically 
resized.  What should be done with a plotted image then?  Interpolate on 
the fly?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From maechler at stat.math.ethz.ch  Wed May 21 17:03:27 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 21 May 2003 17:03:27 +0200
Subject: [R] cluster- binary data.
In-Reply-To: <200305211521050246.01585CC3@harry.molgen.mpg.de>
References: <200305211521050246.01585CC3@harry.molgen.mpg.de>
Message-ID: <16075.38207.135783.428293@gargle.gargle.HOWL>

>>>>> "Eryk" == Eryk Wolski <wolski at molgen.mpg.de>
>>>>>     on Wed, 21 May 2003 15:21:05 +0200 writes:

    Eryk> Hi!
    Eryk> I am trying to calculate a dissimilarity matrix using daisy.
    Eryk> The matrix vectver is binary as i test with:
    >> levels(as.factor(vectver))
    Eryk> [1] "0" "1"

    Eryk> But the call to daisy gives me the following error message.:

    >> dfl1 <- daisy(vectver, type = list(asymm = c(1:length(vectver[,1]))))
    Eryk> Error in daisy(vectver, type = list(asymm = c(1:length(vectver[, 1])))) :
    Eryk> at least one binary variable has more than 2 levels.

    Eryk> and the call to mona that.

    Eryk> levels(as.factor(vectver))
    Eryk> [1] "0" "1"
    >> r<-mona(vectver)
    Eryk> Error in mona(vectver) : All variables must be binary (factor with 2 levels).

Well, you really don't give enough information 
(about the exact structure of `vectver').

Please make use of str(.), summary(.), table(.) ..

E.g., the following works flawlessly for me:

> vectver <- matrix(as.numeric(runif(10000) < 0.1), 200, 50)# more 0 than 1
> dv <- daisy(vectver, type = list(asymm = 1:ncol(vectver)))
> ##                                       ^^^^^^^^^^^^^^  Note !
> mv <- mona(vectver)


    Eryk>
    Eryk>    <........Eryk. ............>
    Eryk>


    Eryk> [[alternate HTML version deleted]]

	  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
this means that you should really configure your e-mail "software"
such that you send plain text only; see also
http://www.r-project.org/mail.html

Regards,

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From meinhardploner at gmx.net  Wed May 21 17:05:04 2003
From: meinhardploner at gmx.net (Meinhard Ploner)
Date: Wed, 21 May 2003 17:05:04 +0200
Subject: [R] overlapping a plot with an external image
In-Reply-To: <Pine.LNX.4.44.0305211535180.32308-100000@gannet.stats>
Message-ID: <9A7DD04C-8B9D-11D7-ADA9-0003930EA956@gmx.net>

On Wednesday, May 21, 2003, at 04:38  PM, Prof Brian Ripley wrote:

> On Wed, 21 May 2003, Meinhard Ploner wrote:
>
>> It's possible to overlap an external image (jpg or pdf)
>> with a plot generated with R?
>>
>> Specifying the image as the background
>> of the plot might not be possible...
>
> Although this has been discussed, R graphics devices cannot as yet plot
> bitmap images.  So all one can do is to plot a set of rectangles: for 
> that
> the pixmap package might be helpful.
>
> Although we might add the ability to plot a bitmap image, note that it 
> is
> not straightforward, as R screen graphics devices can be dynamically
> resized.  What should be done with a plotted image then?  Interpolate 
> on
> the fly?

The plotted image should be a logo of the project / department and I
like to add it on every plot  - for esthetical and descriptive reasons 
;-)

MP

> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From Jim_Garrett at bd.com  Wed May 21 17:06:18 2003
From: Jim_Garrett at bd.com (Jim_Garrett@bd.com)
Date: Wed, 21 May 2003 11:06:18 -0400
Subject: [R] Re: Several Basic Questions
Message-ID: <OF707E7B10.F144B62B-ON85256D2D.0051F76C@bd.com>

I get the digest, so apologies if this has already been sorted out.

Perhaps there is some platform dependence to this?  Following Ripley's
suggestion, I still get what Mingua got:

> x <- 1134567.1
> y <- 0.19
> z <- x - y
> version
         _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    7.0
year     2003
month    04
day      16
language R
> win.version()
[1] "Windows 2000 Professional (build 2195) Service Pack 2.0"
> cat(format(round(z, 2)), "\n")
1134567


**********************************************************************
This message is intended only for the designated recipient(s).  ... {{dropped}}



From ripley at stats.ox.ac.uk  Wed May 21 17:29:22 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Wed, 21 May 2003 16:29:22 +0100 (GMT Daylight Time)
Subject: [R] Re: Several Basic Questions
In-Reply-To: <OF707E7B10.F144B62B-ON85256D2D.0051F76C@bd.com>
Message-ID: <Pine.WNT.4.44.0305211627110.3432-100000@gannet.stats.ox.ac.uk>

Garrett (as you seem to prefer to address people as if they are your servants)

?format tells you about `digits'.  RTFM.

And yes, it has been sorted out long ago.

Professor Ripley


On Wed, 21 May 2003 Jim_Garrett at bd.com wrote:

> I get the digest, so apologies if this has already been sorted out.
>
> Perhaps there is some platform dependence to this?  Following Ripley's
> suggestion, I still get what Mingua got:
>
> > x <- 1134567.1
> > y <- 0.19
> > z <- x - y
> > version
>          _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    7.0
> year     2003
> month    04
> day      16
> language R
> > win.version()
> [1] "Windows 2000 Professional (build 2195) Service Pack 2.0"
> > cat(format(round(z, 2)), "\n")
> 1134567
>
>
> **********************************************************************
> This message is intended only for the designated recipient(s).  ... {{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From saurav at sas.upenn.edu  Wed May 21 17:40:02 2003
From: saurav at sas.upenn.edu (Saurav Pathak)
Date: Wed, 21 May 2003 11:40:02 -0400
Subject: [R] pairs with label
Message-ID: <20030521154001.GA13840@mail2.sas.upenn.edu>

Hi,

I have not been able to figure out how to label points on a pairs
(scatter matrix) plot.  That is, I wish all points on a scatter
matrix to be labeled by a number.  I can do that for a simple plot
using the text() command:

plot(data.2d, type="n")
text(data.2d, labels=the.labels)

where,
the.labels <- seq(1,20)

How may i get the same labels for something like
pairs(data.4d)

I cannot use the text() command with pairs(), it seems.

Thanks,
Saurav



From feldesmanm at pdx.edu  Wed May 21 17:40:56 2003
From: feldesmanm at pdx.edu (Marc R. Feldesman)
Date: Wed, 21 May 2003 08:40:56 -0700
Subject: [R] Re: Several Basic Questions
In-Reply-To: <OF707E7B10.F144B62B-ON85256D2D.0051F76C@bd.com>
Message-ID: <5.2.0.9.2.20030521083919.01cd94e8@pop4.attglobal.net>

At 08:06 AM 5/21/2003, Jim_Garrett at bd.com wrote:
 >I get the digest, so apologies if this has already been sorted out.
 >
 >Perhaps there is some platform dependence to this?  Following Ripley's
 >suggestion, I still get what Mingua got:
 >
 >> x <- 1134567.1
 >> y <- 0.19
 >> z <- x - y
 >> version
 >         _


try:

 >options(digits=10)
 >z
 > 1134566.91

Windows XP, RH Linux 8, Windows 2000



From spencer.graves at pdf.com  Wed May 21 17:41:18 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 21 May 2003 08:41:18 -0700
Subject: [R] rts conversion to ts?
References: <AMEEIKBPDPIFIPFANMHGMEHGCAAA.midnightsun@blueyonder.co.uk>
Message-ID: <3ECB9E1E.5020902@pdf.com>

I don't know if this will help, but the "survReg" command is written as 
"survreg", not "survReg", in R.  I define "survReg <- survreg" first, 
and then my S-Plus scripts using "survReg" work in R.  Similarly, 
"singular.ok=TRUE" by default in "lm" in R, while "singular.ok=FALSE" by 
default in S-Plus.  If I need to change the default behavior, I make a 
local copy in my working directory and edit that so it does what I want. 
  After that, each time "lm" is called, it accesses the copy in my 
working directory and never gets to "lm" in the base language.  You can 
even make "pi <- 3", but I don't recommend that for much of anything 
except to illustrate possibilities.

I'm not familiar with either "rts" or S-Plus dumps, so I don't know if 
this will help.

Best Wishes,
Spencer Graves

Adam wrote:
> Hi
> 
> Not sure if this is going to the right place?
> 
> I am attempting to use a S-Plus workspace that has been saved via the dump
> facility. These include a number of commands not recognised by R, namely rts
> commands. Is there a way round this by changing these in some way for R?s ts
> commands? Any help much appreciated.
> 
> 
> Adam
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ligges at statistik.uni-dortmund.de  Wed May 21 18:17:52 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 21 May 2003 18:17:52 +0200
Subject: [R] pairs with label
In-Reply-To: <20030521154001.GA13840@mail2.sas.upenn.edu>
References: <20030521154001.GA13840@mail2.sas.upenn.edu>
Message-ID: <3ECBA6B0.20903@statistik.uni-dortmund.de>

Saurav Pathak wrote:
> Hi,
> 
> I have not been able to figure out how to label points on a pairs
> (scatter matrix) plot.  That is, I wish all points on a scatter
> matrix to be labeled by a number.  I can do that for a simple plot
> using the text() command:
> 
> plot(data.2d, type="n")
> text(data.2d, labels=the.labels)
> 
> where,
> the.labels <- seq(1,20)
> 
> How may i get the same labels for something like
> pairs(data.4d)
> 
> I cannot use the text() command with pairs(), it seems.
> 
> Thanks,
> Saurav
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


Define a panel function for pairs(), see ?pairs for details,
such as:

pairs(data.4d, panel = function(x,y) text(x,y, labels=the.labels)))

Uwe Ligges



From p.dalgaard at biostat.ku.dk  Wed May 21 18:35:20 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed, 21 May 2003 16:35:20 -0000
Subject: [R] Tcltk question for R people
In-Reply-To: <Law9-F124ziJypQP6pk00009d14@hotmail.com>
References: <Law9-F124ziJypQP6pk00009d14@hotmail.com>
Message-ID: <x2of1wfe1v.fsf@biostat.ku.dk>

"Jason Fisher" <stormplot at hotmail.com> writes:

> Hello...
> 
> Curious to know whether the TK extensions ?Tktable? and
> ?Iwidgets? will be included in future versions of R (full
> installation).  These are key components of GUI construction and would
> be very useful in my current R-tcltk endeavors.  I realize that I
> could just install a version of ActiveTcl, which includes the
> extensions; however, my goal is to eventually distribute my work
> keeping installation procedures at a minimum.
> 
> I do have one question for individuals working with R and Tcl/Tk on
> Windows XP.  Has anyone experienced corrupted GUI?s (lost widgets)
> after invoking a tkpack command (e.g. missing buttons).  My web
> searches on the subject leave me wondering if it?s a Windo$e problem.
> Any ideas?
> 
> Thank you,
> Jason
> 
> PS: Inclusion of the Tcl/Tk within the R 1.7.0 installation has been
> greatly appreciated.

This stuff is, well, "under consideration". I've been wanting to have
the Tktable package in there too (for one thing, it could give us an
alternative data editor in a page or two of code). However, I'm not
sure how far we want to follow the route of adding external libraries
to the R sources, so it might be better to add them in the form of R
packages.

Volunteers into figuring out how to do this in the  Windows DLL world
are welcome...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From chrysopa at insecta.ufv.br  Wed May 21 18:41:27 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Wed, 21 May 2003 13:41:27 -0300
Subject: [R] help on spatial data
Message-ID: <20030521163933.M40911@insecta.ufv.br>

Hi, 
 
I have a dataset with x and y coordinates and in each point I have an 
identity of point, in some cases I can have more then one identity by point. 
 
My dataset is something like this: 
 
> x <- rep(c(1:4),4) 
> y <- rep(c(1:4),c(4,4,4,4)) 
> area1 <- sample(factor(rep(c("a","b","c","d"),4))) 
> area2 <- 
as.factor(c(rep(c("a","b"),c(2,2)),rep(c("a","b"),c(2,2)),rep(c("c","d"),c(2,2)),rep(c("c","d"),c(2,2)))) 
 
to view the spatial grid: 
 
> plot(y~x,pch=levels(area1)[codes(area1)]) 
> plot(y~x,pch=levels(area2)[codes(area2)]) 
 
I have several areas with different distribution. 
 
I need to compute the distance and the diference between points. 
 
My hypothesis is that the diference between two points increase with the 
distance between these points. 
 
In this example, the fisrt area (area1) have a random distribution, and my 
hypothesis is false, in second area (area2) I have an aggregated distribution 
and my hypothesis is true. 
 
I real data I can have several levels of aggregation, I need testing these 
difference of aggregations. 
 
I try to use the Kfn from spatial package, but I dont succeed.  
 
R have any package to make this analyse? 
 
What I need to read for this?  
 
Thanks for all 
 
-- 
|   //|\\   [*****************************] 
|| ( ? ? )  [Ronaldo Reis J?nior          ] 
|     V     [ESALQ/USP-Entomologia, CP-09 ] 
||  / l \   [13418-900 Piracicaba - SP    ] 
|  /(lin)\  [Fone: 19-429-4199 r.229      ] 
||/(linux)\ [chrysopa at insecta.ufv.br      ] 
|/ (linux) \[ICQ#: 5692561                ] 
||  ( x )   [*****************************] 
||| _/ \_ Powered by Gnu/Debian Woody 
-----------------------------------
Insecta - Entomologia
Departamento de Biologia Animal
Universidade Federal de Vi?osa



From chrysopa at insecta.ufv.br  Wed May 21 18:41:26 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Wed, 21 May 2003 13:41:26 -0300
Subject: [R] help on spatial data
Message-ID: <20030521163933.M40911@insecta.ufv.br>

Hi, 
 
I have a dataset with x and y coordinates and in each point I have an 
identity of point, in some cases I can have more then one identity by point. 
 
My dataset is something like this: 
 
> x <- rep(c(1:4),4) 
> y <- rep(c(1:4),c(4,4,4,4)) 
> area1 <- sample(factor(rep(c("a","b","c","d"),4))) 
> area2 <- 
as.factor(c(rep(c("a","b"),c(2,2)),rep(c("a","b"),c(2,2)),rep(c("c","d"),c(2,2)),rep(c("c","d"),c(2,2)))) 
 
to view the spatial grid: 
 
> plot(y~x,pch=levels(area1)[codes(area1)]) 
> plot(y~x,pch=levels(area2)[codes(area2)]) 
 
I have several areas with different distribution. 
 
I need to compute the distance and the diference between points. 
 
My hypothesis is that the diference between two points increase with the 
distance between these points. 
 
In this example, the fisrt area (area1) have a random distribution, and my 
hypothesis is false, in second area (area2) I have an aggregated distribution 
and my hypothesis is true. 
 
I real data I can have several levels of aggregation, I need testing these 
difference of aggregations. 
 
I try to use the Kfn from spatial package, but I dont succeed.  
 
R have any package to make this analyse? 
 
What I need to read for this?  
 
Thanks for all 
 
-- 
|   //|\\   [*****************************] 
|| ( ? ? )  [Ronaldo Reis J?nior          ] 
|     V     [ESALQ/USP-Entomologia, CP-09 ] 
||  / l \   [13418-900 Piracicaba - SP    ] 
|  /(lin)\  [Fone: 19-429-4199 r.229      ] 
||/(linux)\ [chrysopa at insecta.ufv.br      ] 
|/ (linux) \[ICQ#: 5692561                ] 
||  ( x )   [*****************************] 
||| _/ \_ Powered by Gnu/Debian Woody 
-----------------------------------
Insecta - Entomologia
Departamento de Biologia Animal
Universidade Federal de Vi?osa



From pgilbert at bank-banque-canada.ca  Wed May 21 19:12:49 2003
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Wed, 21 May 2003 13:12:49 -0400
Subject: [R] a quick Q about memory limit in R
References: <Pine.SOL.4.33.0305201420100.23320-100000@panther.cs.ucla.edu>
Message-ID: <3ECBB391.8AAC7D8F@bank-banque-canada.ca>

Yan Yu wrote:
...
> 
> (2) what decides the memory limit in R, How can increase that?

In recent versions of R this is controlled by the operating system, unless you
start R with an option that sets a lower limit than the OS allows. In Linux and
Unix this is controlled by

1/ ulimit (or limit in some shells). This can typically be relaxed by a normal
user to the system limits. On Linux the default max memory is usually not
limited (by ulimit) but it is sometimes necessary to relax the default stack
size.

2/ A combination of the amount of memory and amount of swap space. Roughly, on
Linux, these are added together to give the limit. This has changed over the
years in Linux and may vary on different version of Unix, but typically swap
space increases the size of problem you can handle. Physical memory is faster,
but swap works. Given prices these days you might consider having these add to
around 4G if you want to work on large problems with R.

3/ The architecture of the processor (e.g. 32-bit vs 64-bit). A program cannot
exceed the address space of the architecture (2^32 = 4G bytes on a typical PC
32-bit processor, 2^64=a lot more on a 64-bit workstation). The OS itself needs
some of this, so I believe the practical limit on 32-bit Linux is around 3G. (In
any case, there is not much point in have more than 4G of swap+memory on a
32-bit machine.) On a 64-bit architecture with a 64-bit Unix (most workstations)
the application (R) must be compiled as a 64-bit application. Thus the fixing of
Solaris bugs in gcc 3.2.3 has meant that much larger problems can now be handled
with R on Solaris (I believe this was possible before with Sun compilers.) It
should also be possible to compile 64-bit R under (64-bit) Linux on Intel
Itanium and AMD Opteron processors. I have no experience with this (but would be
interested in hearing from anyone that does).

On Windows the situation is different and I am much less familiar with it (and
look forward to being corrected). I believe applications must fit into physical
memory on Windows, that is, they can be swapped out but not partly swapped out.
This means that it is necessary to buy more memory to run bigger R problems. (Of
course, with physical memory problems will run much faster, so you should
consider buying more memory even in Unix.) Windows itself demands some of the
memory, so I believe the practical limit for applications in Windows is 2G
bytes. I understand there is a 64-bit version of Windows under development, but
I don't think it has been released yet.

Paul Gilbert



From jmc at research.bell-labs.com  Thu May 22 00:02:19 2003
From: jmc at research.bell-labs.com (John Chambers)
Date: Wed, 21 May 2003 18:02:19 -0400
Subject: [R] callNextMethod
References: <DGEIIIMDDGKLGHFCOPOFOEGLCCAA.laurent.buffat@it-omics.com>
Message-ID: <3ECBF76B.B6972FD1@research.bell-labs.com>

laurent buffat wrote:
> 
> Hi,
> 
> I don't understand why this code doesn't work (f(b2)):

Indeed, it should work.  There were some problems in chaining multiple
callNextMethod()s.

A fix has been committed to the R-patched source, and will be in version
1.7.1, in a few weeks.

A good bug report; thanks.

John Chambers

> 
> /////////////////
> 
> setClass("B0", representation(b0 = "numeric"))
> setClass("B1", representation("B0", b1 = "character"))
> setClass("B2", representation("B1", b2 = "logical"))
> 
> f <- function(x) class(x)
> 
> setMethod("f", "B0", function(x) c(x at b0, callNextMethod()))
> setMethod("f", "B1", function(x) c(x at b1,x at b0*x at b0,callNextMethod()))
> setMethod("f", "B2", function(x) c(x at b2, callNextMethod()))
> 
> b0 <- new("B0", b0 = 3)
> b1 <- new("B1", b1 = "deux", b0 = 2)
> b2 <- new("B2", b2 = FALSE, b1 = "dix", b0 = 10)
> 
> f(b0)
> f(b1)
> f(b2)
> 
> ///////////////////////////
> 
> > f(b0)
> [1] "3"  "B0"
> > f(b1)
> [1] "deux" "4"    "2"    "B1"
> > f(b2)
> Error in get(x, envir, mode, inherits) : variable ".Generic" was not found
> 
> //////////////////////////////
> 
> I'm using R Version 1.7.0, on a linux machine.
> 
> Thanks for your help.
> 
> Laurent B.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
John M. Chambers                  jmc at bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc



From DivineSAAM at aol.com  Thu May 22 00:32:10 2003
From: DivineSAAM at aol.com (DivineSAAM@aol.com)
Date: Wed, 21 May 2003 18:32:10 -0400
Subject: [R] Access Object's Objects HELP
Message-ID: <5270F8FF.34AA887D.0B088159@aol.com>

Dear WizaRds,

A run of nls produces the following concise summary:

> summary(cs.wt)

Formula: 0 ~ wt.MM(conc, time, A1, a1, A2, a2)

Parameters:
    Estimate Std. Error t value Pr(>|t|)  
A1 4.814e+02  2.240e+01  21.495   0.0296 *
a1 7.401e-01  7.435e-02   9.956   0.0637 .
A2 1.613e+02  1.738e+01   9.280   0.0683 .
a2 1.770e-02  7.324e-03   2.417   0.2497  

------------------------------------------
I need to access the estimates of A1,a1,A2...

How can I do this?

Also, I need to add a column to Parameters: giving
the ratio of the Std. Error to Estimate. Is there a way to get summary to do this?
I can't find the summary implementation.

I am using R 1.7.0 on Windows XP

HELP! Please:-)

Kind Regards,

Oscar A. Linares
The Geriatrics Center,
University of Michigan



From sundar.dorai-raj at pdf.com  Thu May 22 00:50:41 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 21 May 2003 17:50:41 -0500
Subject: [R] Access Object's Objects HELP
References: <5270F8FF.34AA887D.0B088159@aol.com>
Message-ID: <3ECC02C1.8070708@pdf.com>



DivineSAAM at aol.com wrote:
> Dear WizaRds,
> 
> A run of nls produces the following concise summary:
> 
> 
>>summary(cs.wt)
> 
> 
> Formula: 0 ~ wt.MM(conc, time, A1, a1, A2, a2)
> 
> Parameters:
>     Estimate Std. Error t value Pr(>|t|)  
> A1 4.814e+02  2.240e+01  21.495   0.0296 *
> a1 7.401e-01  7.435e-02   9.956   0.0637 .
> A2 1.613e+02  1.738e+01   9.280   0.0683 .
> a2 1.770e-02  7.324e-03   2.417   0.2497  
> 
> ------------------------------------------
> I need to access the estimates of A1,a1,A2...
> 
> How can I do this?
> 
> Also, I need to add a column to Parameters: giving
> the ratio of the Std. Error to Estimate. Is there a way to get summary to do this?
> I can't find the summary implementation.
> 
> I am using R 1.7.0 on Windows XP
> 

Most of the time, you can assign the summary list to a variable and 
extract it that way. As in (using the example on ?nls):

R> x = summary( fm1DNase1 )
R> names(x)
[1] "formula"      "residuals"    "sigma"
[4] "df"           "cov.unscaled" "correlation"
[7] "parameters"
R> x$parameters
      Estimate Std. Error  t value     Pr(>|t|)
Asym 2.345180 0.07815395 30.00719 2.165503e-13
xmid 1.483090 0.08135322 18.23026 1.218535e-10
scal 1.041455 0.03227080 32.27236 8.506916e-14

sundar



From bates at stat.wisc.edu  Thu May 22 01:24:20 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 21 May 2003 23:24:20 -0000
Subject: [R] Access Object's Objects HELP
In-Reply-To: <5270F8FF.34AA887D.0B088159@aol.com>
References: <5270F8FF.34AA887D.0B088159@aol.com>
Message-ID: <6rk7cj7ukj.fsf@bates5.stat.wisc.edu>

DivineSAAM at aol.com writes:

> Dear WizaRds,
> 
> A run of nls produces the following concise summary:
> 
> > summary(cs.wt)
> 
> Formula: 0 ~ wt.MM(conc, time, A1, a1, A2, a2)
> 
> Parameters:
>     Estimate Std. Error t value Pr(>|t|)  
> A1 4.814e+02  2.240e+01  21.495   0.0296 *
> a1 7.401e-01  7.435e-02   9.956   0.0637 .
> A2 1.613e+02  1.738e+01   9.280   0.0683 .
> a2 1.770e-02  7.324e-03   2.417   0.2497  
> 
> ------------------------------------------
> I need to access the estimates of A1,a1,A2...
> 
> How can I do this?

Use the coef extractor function, as in
 coef(cs.wt)

In general the best way to get information on a fitted model is to use
the extractor function like coef(object) as opposed to trying to
decide which component in the object holds the information of
interest.  In the case of objects of the nls class you really do want
to use the extractor functions because these objects have an unusual
internal structure.

> Also, I need to add a column to Parameters: giving
> the ratio of the Std. Error to Estimate. Is there a way to get summary to do this?

The "t value" is the ratio "Estimate"/"Std. Error".  Do you really
want "Std. Error"/Estimate?

> I can't find the summary implementation.

The nls package now has a namespace so the S3 methods are hidden.
You need to use
 getS3method("summary", "nls")
to see the gory details.

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/



From DivineSAAM at aol.com  Thu May 22 03:45:04 2003
From: DivineSAAM at aol.com (DivineSAAM@aol.com)
Date: Wed, 21 May 2003 21:45:04 -0400
Subject: [R] Plot observed vs. fitted values (weighted nls)
Message-ID: <27ADDAFE.2BB5DC10.0B088159@aol.com>

Dear WizaRds,

Given the experimental data,

csdata<-data.frame(
time=c(0,1,3,9,20),
conc=c(638.697,395.69,199.00,141.58,112.16)
)

weighted nls is applied,

wt.MM<- function(resp, time,A1,a1,A2,a2)
{
    pred <- A1*exp(-a1*time)+A2*exp(-a2*time)
    (resp - pred) / sqrt(pred)
}
#
cs.wt <- nls( ~ wt.MM(conc, time,A1,a1,A2,a2), data=csdata,
              start=list(A1=700,a1=1,A2=100,a2=0.1),
             trace = TRUE)
             
x<-csdata$time
y<-csdata$conc

Now, I want a plot of the observed vs. fitted values. I used
# 1. 'seq' to generate series of values for x-axis
# 2. 'predict' to calculate the fitted values
# 3. 'lines' to overlay the smooth curve of the fitted values

smoothx<-seq(0,20,0.1)

smoothy<-predict(cs.wt,list(x=smoothx))


*Unfortunately, this did not work.

My goal was to use

plot(x,y)
lines(smoothx,smoothy)

Got--Error in xy.coords(x, y) : x and y lengths differ--

ANY SUGGESTIONS? PLEASE:-)

I noticed that

> smoothy<-predict(cs.wt,list(x=smoothx))
> smoothy
[1] -0.15787479  0.38479197 -0.43312824  0.29216236 -0.09731213

is not a correct prediction of the response based on the results. 

The following was obtained using S-PLUS (which I really do not want to be using)

> predict(cs.wt)
[1] 640.2268 390.9596 205.7743 136.1417 114.0573


Kindest Regards and Many Thanks in Advance

Oscar A. Linares
The Geriatrics Center
University of Michigan, Ann Arbor



From kwan022 at stat.auckland.ac.nz  Thu May 22 07:03:42 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Thu, 22 May 2003 17:03:42 +1200 (NZST)
Subject: [R] Getting the Bootstrap Error Rate of QDA
Message-ID: <Pine.LNX.4.44.0305221701400.5671-100000@stat61.stat.auckland.ac.nz>

Hi,

What does this mean when I have something like:
>  qda.boot <- boot(train, qda.bootstrap, R = 500)
 Error in qda.default(structure(data.matrix(x), class = "matrix"), ...) : 
	Rank deficiency in group M
with my qda.bootstrap() looks something like:
> qda.bootstrap <- function(data, index) {
+   boot.qda <- qda(x = data[index, 2:9], group = data[index, 1])
+   qda.pred <- predict(boot.qda)
+   boot.resub <- sum(qda.pred$class != data[, 1]) / nrow(data)
+   data.pred <- predict(boot.qda, data[, 2:9])
+   data.resub <- sum(data.pred$class != data[,1]) / nrow(data)
+   abs(data.resub - boot.resub)
+ }

If I run qda.boot <- boot(train, qda.bootstrap, R = 500) a couple of 
times, it sometimes work but other times just give me the error message 
above.  Is there a way to solve this?





-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)



From s.su at qut.edu.au  Thu May 22 07:16:31 2003
From: s.su at qut.edu.au (Steve Su)
Date: Thu, 22 May 2003 15:16:31 +1000
Subject: [R] Re: dates in chron package, split warning message
Message-ID: <008f01c32021$4ea34b80$2032b583@busaccb337f>

>
> > Dear All,
> >
> > I am currently using R for windows.
> >
> > I am wondering why the dates command in chron package does not work in
the
> > following situation:
> >
> > cut(dates(c(23,45,67),origin=c(1,1,2004)),"months")
> >
> > but will work for:
> >
> > cut(dates(c(23,45,67),origin=c(1,1,2004)),"days")
> > cut(dates(c(23,45,67),origin=c(1,1,2004)),"weeks")
> >
> > My second query is rather trivial but I am wondering why warning
messages
> > were given when using the split in this manner:
> >
> > split(matrix(1:12,nrow=4),c(1,1,2,3)) # Which does what I want it to do.
> >
> > and no warning messages were given in Splus6 for example?
> >
> >
> >
>
****************************************************************************
> > **********
> >
> >  Steve Su (s.su at qut.edu.au)
> >  PhD student.
> >
> >  School of Accountancy
> >  School of Mathematical Sciences
> >  Queensland University of Technology
> >
> >  Postal Address: Steve Su, School of Accountancy, QUT, PO Box 2434,
> > Brisbane,
> >  Queensland, Australia, 4000.
> >
> >
> >  Phone:  +61 7 3864 2017
> >  Fax:    +61 7 3864 1812
> >  Mobile: 0421  840  586
> >      .
> >    _--_|\
> >   /      QUT
> >   \_.--._/
> >         v
> >
> >
>
****************************************************************************
> > **********
> >
> >
>
****************************************************************************
> > **********
> >
> >  Steve Su (s.su at qut.edu.au)
> >  PhD student.
> >
> >  School of Accountancy
> >  School of Mathematical Sciences
> >  Queensland University of Technology
> >
> >  Postal Address: Steve Su, School of Accountancy, QUT, PO Box 2434,
> > Brisbane,
> >  Queensland, Australia, 4000.
> >
> >
> >  Phone:  +61 7 3864 2017
> >  Fax:    +61 7 3864 1812
> >  Mobile: 0421  840  586
> >      .
> >    _--_|\
> >   /      QUT
> >   \_.--._/
> >         v
> >
> >
>
****************************************************************************
> > **********
> >
>



From ripley at stats.ox.ac.uk  Thu May 22 08:29:26 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 22 May 2003 07:29:26 +0100 (BST)
Subject: [R] Getting the Bootstrap Error Rate of QDA
In-Reply-To: <Pine.LNX.4.44.0305221701400.5671-100000@stat61.stat.auckland.ac.nz>
Message-ID: <Pine.LNX.4.44.0305220723110.2083-100000@gannet.stats>

You need to investigate the validity of bootstrapping here.

Remember that to use QDA you need as any observations in each group as 
dimensions, and futhermore those observations need to like ones from a 
non-degenerate normal distribution.

Unless this is a balanced bootstrap you may end up with too few in each 
group, and even then the repeating of observations makes this nothing like 
the assumed distribution theory and you may well have enough observations 
but not enough distinct ones.


On Thu, 22 May 2003, Ko-Kang Kevin Wang wrote:

> Hi,
> 
> What does this mean when I have something like:
> >  qda.boot <- boot(train, qda.bootstrap, R = 500)
>  Error in qda.default(structure(data.matrix(x), class = "matrix"), ...) : 
> 	Rank deficiency in group M
> with my qda.bootstrap() looks something like:
> > qda.bootstrap <- function(data, index) {
> +   boot.qda <- qda(x = data[index, 2:9], group = data[index, 1])
> +   qda.pred <- predict(boot.qda)
> +   boot.resub <- sum(qda.pred$class != data[, 1]) / nrow(data)
> +   data.pred <- predict(boot.qda, data[, 2:9])
> +   data.resub <- sum(data.pred$class != data[,1]) / nrow(data)
> +   abs(data.resub - boot.resub)
> + }
> 
> If I run qda.boot <- boot(train, qda.bootstrap, R = 500) a couple of 
> times, it sometimes work but other times just give me the error message 
> above.  Is there a way to solve this?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu May 22 08:44:51 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 22 May 2003 07:44:51 +0100 (BST)
Subject: [R] Re: dates in chron package, split warning message
In-Reply-To: <008f01c32021$4ea34b80$2032b583@busaccb337f>
Message-ID: <Pine.LNX.4.44.0305220731530.2083-100000@gannet.stats>

On Thu, 22 May 2003, Steve Su wrote:

> > > I am currently using R for windows.
> > >
> > > I am wondering why the dates command in chron package does not work in
> the
> > > following situation:
> > >
> > > cut(dates(c(23,45,67),origin=c(1,1,2004)),"months")
> > >
> > > but will work for:
> > >
> > > cut(dates(c(23,45,67),origin=c(1,1,2004)),"days")
> > > cut(dates(c(23,45,67),origin=c(1,1,2004)),"weeks")

The dates function (not command) does work of course.  It's cut.dates
which fails.  The short answer to you is this is a great opportunity to
learn to debug R functions, and the hint is that the line

    from <- switch(by, days = from, 
	weeks = (from - day.of.week(mdy$m,mdy$d, mdy$y) + as.numeric(start.on.monday)), 
        months = chron(julian(mdy$m, 1, mdy$y, origin = orig)),
        years = chron(julian(1, 1,mdy$y, origin = orig)))

contains two bugs.

> > > My second query is rather trivial but I am wondering why warning
> messages
> > > were given when using the split in this manner:
> > >
> > > split(matrix(1:12,nrow=4),c(1,1,2,3)) # Which does what I want it to do.
> > >
> > > and no warning messages were given in Splus6 for example?

Try reading the help pages in each system.  They do not define split in 
the same way, and your usage is incorrect in R but not in S-PLUS 6.1.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Roger.Bivand at nhh.no  Thu May 22 10:31:32 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 22 May 2003 10:31:32 +0200 (CEST)
Subject: [R] help on spatial data
In-Reply-To: <20030521163933.M40911@insecta.ufv.br>
Message-ID: <Pine.LNX.4.44.0305221011300.17183-100000@reclus.nhh.no>

On Wed, 21 May 2003, Ronaldo Reis Jr. wrote:

> Hi, 
>  
> I have a dataset with x and y coordinates and in each point I have an 
> identity of point, in some cases I can have more then one identity by point. 
>  
> My dataset is something like this: 
>  
> > x <- rep(c(1:4),4) 
> > y <- rep(c(1:4),c(4,4,4,4)) 
> > area1 <- sample(factor(rep(c("a","b","c","d"),4))) 
> > area2 <- 
> as.factor(c(rep(c("a","b"),c(2,2)),rep(c("a","b"),c(2,2)),rep(c("c","d"),c(2,2)),rep(c("c","d"),c(2,2)))) 
>  
> to view the spatial grid: 
>  
> > plot(y~x,pch=levels(area1)[codes(area1)]) 
> > plot(y~x,pch=levels(area2)[codes(area2)]) 
>  
> I have several areas with different distribution. 
>  
> I need to compute the distance and the diference between points. 
>  
> My hypothesis is that the diference between two points increase with the 
> distance between these points. 
>  

It looks as though your points are fixed observation sites, and so the
spatial distribution of the points themselves is not what is being
observed. The observations are the categorical factor levels at the fixed
points, is that right? What does "the difference between two points" mean
- same category or different category? How can the difference "increase"? 

> In this example, the fisrt area (area1) have a random distribution, and my 
> hypothesis is false, in second area (area2) I have an aggregated distribution 
> and my hypothesis is true. 

If the points were not so "fixed", this might be approached as a marked 
point process, or if there were more points, through comparing Khat for 
the levels of the factor (spatstat, splancs). However, it feels perhaps 
more like a join count situation, counting similar/not similar neighbour 
points (spdep).

library(spdep)
xy.nb <- cell2nb(4,4)
joincount.test(area1, nb2listw(xy.nb, style="B"))
joincount.test(area2, nb2listw(xy.nb, style="B"))

(or joincount.mc() for a permutation test)

(see: Cliff, A. D., Ord, J. K. 1981 Spatial processes, Pion, p. 20.)

>  
> I real data I can have several levels of aggregation, I need testing these 
> difference of aggregations. 
>  
> I try to use the Kfn from spatial package, but I dont succeed.  
>  
> R have any package to make this analyse? 
>  
> What I need to read for this?  
>  
> Thanks for all 
>  
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From ggrothendieck at volcanomail.com  Thu May 22 13:27:21 2003
From: ggrothendieck at volcanomail.com (Gabor Grothendieck)
Date: Thu, 22 May 2003 04:27:21 -0700 (PDT)
Subject: [R] Re: dates in chron package, split warning message
Message-ID: <20030522112722.191583D51@sitemail.everyone.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030522/ec8c1285/attachment.pl

From uth at zhwin.ch  Thu May 22 13:57:41 2003
From: uth at zhwin.ch (=?iso-8859-1?Q?=22Untern=E4hrer_Thomas=2C_uth=22?=)
Date: Thu, 22 May 2003 13:57:41 +0200
Subject: [R] Tkrplot works not 
Message-ID: <6A4BCEF0FD65344A8F496D7E520DD8B9023E90AE@lobster.zhwin.ch>


Hi,

I've spent some time in programming R - tcl/tk. 
Today I've updated my R version from 1.6.2 to 1.7.0. 
My programm stops now with two error-messages: 
(How could it be, two errors? The command "stop" produces an error but does really stop
the programm after it, isn't it?)

> Loading required package: tcltk 
> Error in structure(.External("dotTcl", ..., PACKAGE = "tcltk"), class = "tclObj") : 
>         [tcl] couldn't load library "C:/Programme/R/library/tkrplot/libs/tkrplot.dll": 
> 		this library or a dependent library could not be found in library path.
> Error in library(tkrplot) : .First.lib failed

The library tkrplot is installed! I used it under version 1.6.2 several times.

In the "Windows-specific changes to R" on CRAN I've seen that:

"Tcl/Tk 8.4.1 is bundled in rw1070.exe.  You can still use your own
installation of Tcl/Tk: see the rw-FAQ."

So, I uninstall my tcl-version. But there are still the same errors.  

Why couldn't R load the tkrplot-library?


Thanks for your help and please don't look at my english (it's terrible)

Thomas



From joseandres at uvigo.es  Thu May 22 14:02:44 2003
From: joseandres at uvigo.es (Jose A. Andres)
Date: Thu, 22 May 2003 14:02:44 +0200
Subject: [R] basic question on getGroups for lme analyses
Message-ID: <00d801c3205a$10f67a80$742492c1@DROSOPHILA>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030522/1b45a1c7/attachment.pl

From bitwrit at ozemail.com.au  Thu May 22 12:54:26 2003
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Thu, 22 May 2003 20:54:26 +1000
Subject: [R] overlapping a plot with an external image
In-Reply-To: <FAF2D2B2-8B96-11D7-ADA9-0003930EA956@gmx.net>
References: <FAF2D2B2-8B96-11D7-ADA9-0003930EA956@gmx.net>
Message-ID: <20030522121224.IEQJ1341.mta04.mail.mel.aone.net.au@there>

Meinhard Ploner wrote:
> It's possible to overlap an external image (jpg or pdf)
> with a plot generated with R?
>
> Specifying the image as the background
> of the plot might not be possible...
>
If the plot is output using postscript(), the default background color is 
transparent. For instance, if you have a plot produced 
with postscript(...,onefile=FALSE,...) named Rplots.ps, you can insert the 
following lines in another Postscript file to get the plot overlaid on 
whatever image is in that file.

...
%%DocumentNeededFiles: /home/jim/analyses/Rplots.ps
...
gsave
x y translate
x y scale
(/home/jim/R/analyses/Rplots.ps) run
grestore
...

the "translate" and "scale" commands allow you to place the plot where you 
want it and get the correct size. It's not too hard, but it helps if you 
have had some experience with Postscript. Once you have gotten the 
translate and scale factors right (Ghostview is a great help) you can just 
keep plugging your plots in unless you want to change the image size.

Jim



From isaac.neuhaus at bms.com  Thu May 22 14:27:51 2003
From: isaac.neuhaus at bms.com (Isaac Neuhaus)
Date: Thu, 22 May 2003 08:27:51 -0400
Subject: [R] Experimental Design
Message-ID: <3ECCC247.9030706@bms.com>

I don't know if this is the best place to post this question but I will 
try anyway. I have two experiements for which I use one-way 
matched-randomized ANOVA for the analysis and I would like to compare 
different treatments in the two experiments. The only common group in 
the two experiments are the controls. Is there any  ANOVA design that 
allows me  to  make this comparison taking into consideration the 
confounding effect? Any help would be greatly appreciated.

Isaac

A representation of the experiments follows:

Experiment 1
           Control1     Treat1      Treat2
Blk1          s1          s2          s3
Blk2          s4          s5          s6
Blk3          s7          s8          s9


Experiment 2
           Control2     Treat3      Treat4
Blk1          s1a          s2a          s3a
Blk2          s4a          s5a          s6a
Blk3          s7a          s8a          s9a

Control1 and Control2 I are the same control cell line. I would like to 
compare Treat1 to Treat3 and Treat 4 and also I would like to compare 
Treat2 to Treat3 and Treat4. The fact that those experiments are done in 
two different blocks will confound the interpretation. Can I use the 
common control group to build a model? Should I include one of the 
treatments in future experiments to test my model?



From dmurdoch at pair.com  Thu May 22 14:38:34 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu, 22 May 2003 08:38:34 -0400
Subject: [R] Tkrplot works not 
In-Reply-To: <6A4BCEF0FD65344A8F496D7E520DD8B9023E90AE@lobster.zhwin.ch>
References: <6A4BCEF0FD65344A8F496D7E520DD8B9023E90AE@lobster.zhwin.ch>
Message-ID: <1vgpcvokv4jalqocmj2qglhhkf5g3dc490@4ax.com>

On Thu, 22 May 2003 13:57:41 +0200, you wrote:

>
>Hi,
>
>I've spent some time in programming R - tcl/tk. 
>Today I've updated my R version from 1.6.2 to 1.7.0. 
>My programm stops now with two error-messages: 
>(How could it be, two errors? The command "stop" produces an error but does really stop
>the programm after it, isn't it?)
>
>> Loading required package: tcltk 
>> Error in structure(.External("dotTcl", ..., PACKAGE = "tcltk"), class = "tclObj") : 
>>         [tcl] couldn't load library "C:/Programme/R/library/tkrplot/libs/tkrplot.dll": 
>> 		this library or a dependent library could not be found in library path.
>> Error in library(tkrplot) : .First.lib failed
>
>The library tkrplot is installed! I used it under version 1.6.2 several times.
>
>In the "Windows-specific changes to R" on CRAN I've seen that:
>
>"Tcl/Tk 8.4.1 is bundled in rw1070.exe.  You can still use your own
>installation of Tcl/Tk: see the rw-FAQ."
>
>So, I uninstall my tcl-version. But there are still the same errors.  
>
>Why couldn't R load the tkrplot-library?

Did you re-install it after the upgrade to 1.7.0?  It might be there
were some changes necessary.  I'd suggest reinstalling it from CRAN,
and you'll get the appropriate version.

I just tried this in the 1.7.0 patched version, and everything worked
fine.

Duncan Murdoch



From tblackw at umich.edu  Thu May 22 15:00:05 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Thu, 22 May 2003 09:00:05 -0400 (EDT)
Subject: [R] Plot observed vs. fitted values (weighted nls)
In-Reply-To: <27ADDAFE.2BB5DC10.0B088159@aol.com>
Message-ID: <Pine.SOL.4.44.0305220853580.16161-100000@timepilot.gpcc.itd.umich.edu>



On Wed, 21 May 2003 DivineSAAM at aol.com wrote:

> Dear WizaRds,
>
> Given the experimental data,
>
> csdata<-data.frame(
> time=c(0,1,3,9,20),
> conc=c(638.697,395.69,199.00,141.58,112.16)
> )
>
> weighted nls is applied,
>
> wt.MM<- function(resp, time,A1,a1,A2,a2)
> {
>     pred <- A1*exp(-a1*time)+A2*exp(-a2*time)
>     (resp - pred) / sqrt(pred)
> }
> #
> cs.wt <- nls( ~ wt.MM(conc, time,A1,a1,A2,a2), data=csdata,
>               start=list(A1=700,a1=1,A2=100,a2=0.1),
>              trace = TRUE)
>
> x<-csdata$time
> y<-csdata$conc
>
> Now, I want a plot of the observed vs. fitted values. I used
> # 1. 'seq' to generate series of values for x-axis
> # 2. 'predict' to calculate the fitted values
> # 3. 'lines' to overlay the smooth curve of the fitted values
>
> smoothx<-seq(0,20,0.1)
>
> smoothy<-predict(cs.wt,list(x=smoothx))

predict()  is looking for a variable called "time".
Try  predict(cs.wt, data.frame(time=seq(0,20,0.1)))

>
> *Unfortunately, this did not work.
>
> My goal was to use
>
> plot(x,y)
> lines(smoothx,smoothy)
>
> Oscar A. Linares
> The Geriatrics Center
> University of Michigan, Ann Arbor
>

-  tom blackwell  -  u michigan medical school  -  ann arbor  -



From fzagmutt at hotmail.com  Thu May 22 16:46:13 2003
From: fzagmutt at hotmail.com (Francisco J. Zagmutt Vergara)
Date: Thu, 22 May 2003 14:46:13 +0000
Subject: [R] basic question on getGroups for lme analyses
Message-ID: <Law15-F913Z4d5htAyD00040d41@hotmail.com>

As far as I know GetGroups is designed to extract grouping factors from an 
object, not to create them . To do so you can either specify your hierarchy 
in the random argument of your lme model .i.e. m1<-lme(distance~age, 
data=Orthodont, random = ~age|Subject)

or you can also create grouped data using groupedData.i.e:

groupedData( distance ~ age | Subject,
                   data = as.data.frame( Orthodont ),
                   FUN = mean,
                   outer = ~ Sex,
                   labels = list( x = "Age",
                     y = "Distance from pituitary to pterygomaxillary 
fissure" ),
                   units = list( x = "(yr)", y = "(mm)") )

     plot( Orth.new )         # trellis plot by Subject

     formula( Orth.new )      # extractor for the formula
     gsummary( Orth.new )     # apply summary by Subject
     fm1 <- lme( Orth.new )   # fixed and groups formulae extracted from 
object
     Orthodont2 <- update(Orthodont, FUN = mean)





>From: "Jose A. Andres" <joseandres at uvigo.es>
>To: <r-help at stat.math.ethz.ch>
>Subject: [R] basic question on getGroups for lme analyses
>Date: Thu, 22 May 2003 14:02:44 +0200
>
>Hi all!
>
>I am working on a nested lme model with one fixed effect ("treatment", 
>which 3 levels) and two random effects for "Individuals" (four of them) 
>within "treatment" and "replicate -2 levels-" within "individual" within 
>"treatment". For doing so, I?ve been trying to create a factor for 
>Individual%in%Treatment, say IT
>by
>
>Hongos$IT=getGroups(~1|Treatment/Individual, data=hongos1, level=4)
>
>but I got the following error:
>
>Error in getGroups(~1 | Treatment/Individual, data = hongos1, level = 4) :
>         no applicable method for "getGroups"
>
>I've been trying some other things but nothing seem to work, probably 
>because I cannot fully understand how o use the getGroups command. Any 
>suggestions?
>
>Thanks a lot!
>
>/Jose
>
>
>
>	[[alternate HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From tord.snall at ebc.uu.se  Thu May 22 16:55:41 2003
From: tord.snall at ebc.uu.se (Tord Snall)
Date: Thu, 22 May 2003 16:55:41 +0200
Subject: [R] extract half a matrix
Message-ID: <3.0.6.32.20030522165541.00d49160@mail.anst.uu.se>

Dear all,

I'm new to matrix operations in R. I couln't find a solution to the
following problem among earlier help mails or in An introd to R, I guess
because the question is really basic.

I want to extract all above the diagonal, i.e. from 

    1  2  3  4 
1   0 26 49 49 
2  26  0 44 40 
3  49 44  0 21 
4  49 40 21  0 

I want 

26
49
44
49
40
21


Thanks in advance!


Sincerely,
Tord

-----------------------------------------------------------------------
Tord Sn?ll
Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
Villav?gen 14			
SE-752 36 Uppsala, Sweden
Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
E-mail: Tord.Snall at ebc.uu.se
Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!



From joseandres at uvigo.es  Thu May 22 17:00:34 2003
From: joseandres at uvigo.es (Jose A. Andres)
Date: Thu, 22 May 2003 17:00:34 +0200
Subject: [R] getGroups, nested mixed model
Message-ID: <010101c32072$e5cbb8c0$742492c1@DROSOPHILA>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030522/f694827d/attachment.pl

From paradis at isem.univ-montp2.fr  Thu May 22 17:16:09 2003
From: paradis at isem.univ-montp2.fr (Emmanuel Paradis)
Date: Thu, 22 May 2003 17:16:09 +0200
Subject: [R] extract half a matrix
In-Reply-To: <3.0.6.32.20030522165541.00d49160@mail.anst.uu.se>
Message-ID: <4.2.0.58.20030522171104.00b6db90@162.38.183.200>

At 16:55 22/05/2003 +0200, vous avez ?crit:
>Dear all,
>
>I'm new to matrix operations in R. I couln't find a solution to the
>following problem among earlier help mails or in An introd to R, I guess
>because the question is really basic.
>
>I want to extract all above the diagonal, i.e. from
>
>     1  2  3  4
>1   0 26 49 49
>2  26  0 44 40
>3  49 44  0 21
>4  49 40 21  0
>
>I want
>
>26
>49
>44
>49
>40
>21

If your matrix is named M, this should do it:

M[row(M) < col(M)]


EP



>Thanks in advance!
>
>
>Sincerely,
>Tord



From roger at ysidro.econ.uiuc.edu  Thu May 22 17:24:31 2003
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Thu, 22 May 2003 10:24:31 -0500 (CDT)
Subject: [R] extract half a matrix
In-Reply-To: <3.0.6.32.20030522165541.00d49160@mail.anst.uu.se>
Message-ID: <Pine.SOL.4.30.0305221023550.8057-100000@ysidro.econ.uiuc.edu>

A[row(A)<col(A)]


url:	www.econ.uiuc.edu	Roger Koenker		Dept. of Economics UCL,
email	rkoenker at uiuc.edu	Department of Economics Drayton House,
vox: 	217-333-4558		University of Illinois	30 Gordon St,
fax:   	217-244-6678		Champaign, IL 61820	London,WC1H 0AX, UK
							vox:	020-7679-5838

On Thu, 22 May 2003, Tord Snall wrote:

> Dear all,
>
> I'm new to matrix operations in R. I couln't find a solution to the
> following problem among earlier help mails or in An introd to R, I guess
> because the question is really basic.
>
> I want to extract all above the diagonal, i.e. from
>
>     1  2  3  4
> 1   0 26 49 49
> 2  26  0 44 40
> 3  49 44  0 21
> 4  49 40 21  0
>
> I want
>
> 26
> 49
> 44
> 49
> 40
> 21
>
>
> Thanks in advance!
>
>
> Sincerely,
> Tord
>
> -----------------------------------------------------------------------
> Tord Snll
> Avd. f vxtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
> Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
> Villavgen 14
> SE-752 36 Uppsala, Sweden
> Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
> Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
> Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
> E-mail: Tord.Snall at ebc.uu.se
> Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From ligges at statistik.uni-dortmund.de  Thu May 22 17:22:18 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 22 May 2003 17:22:18 +0200
Subject: [R] extract half a matrix
In-Reply-To: <3.0.6.32.20030522165541.00d49160@mail.anst.uu.se>
References: <3.0.6.32.20030522165541.00d49160@mail.anst.uu.se>
Message-ID: <3ECCEB2A.8020308@statistik.uni-dortmund.de>

Tord Snall wrote:
> Dear all,
> 
> I'm new to matrix operations in R. I couln't find a solution to the
> following problem among earlier help mails or in An introd to R, I guess
> because the question is really basic.
> 
> I want to extract all above the diagonal, i.e. from 
> 
>     1  2  3  4 
> 1   0 26 49 49 
> 2  26  0 44 40 
> 3  49 44  0 21 
> 4  49 40 21  0 
> 
> I want 
> 
> 26
> 49
> 44
> 49
> 40
> 21
> 


   X[row(X) < col(X)]

Uwe Ligges



> Thanks in advance!
> 
> 
> Sincerely,
> Tord
> 
> -----------------------------------------------------------------------
> Tord Sn?ll
> Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
> Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
> Villav?gen 14			
> SE-752 36 Uppsala, Sweden
> Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
> Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
> Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
> E-mail: Tord.Snall at ebc.uu.se
> Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From spencer.graves at pdf.com  Thu May 22 17:32:17 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 22 May 2003 08:32:17 -0700
Subject: [R] extract half a matrix
References: <3.0.6.32.20030522165541.00d49160@mail.anst.uu.se>
Message-ID: <3ECCED81.405@pdf.com>

 > A <- array(1:12, dim=c(3,4))
 > A[col(A)>row(A)]
[1]  4  7  8 10 11 12

This is described in Modern Applied Statistics with S (p. 43 of the 3rd 
edition;  I'm pretty sure I've seen it in the 4th edition, but I don't 
have that handy just now.)

hth.  spencer graves

Tord Snall wrote:
> Dear all,
> 
> I'm new to matrix operations in R. I couln't find a solution to the
> following problem among earlier help mails or in An introd to R, I guess
> because the question is really basic.
> 
> I want to extract all above the diagonal, i.e. from 
> 
>     1  2  3  4 
> 1   0 26 49 49 
> 2  26  0 44 40 
> 3  49 44  0 21 
> 4  49 40 21  0 
> 
> I want 
> 
> 26
> 49
> 44
> 49
> 40
> 21
> 
> 
> Thanks in advance!
> 
> 
> Sincerely,
> Tord
> 
> -----------------------------------------------------------------------
> Tord Sn?ll
> Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
> Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
> Villav?gen 14			
> SE-752 36 Uppsala, Sweden
> Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
> Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
> Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
> E-mail: Tord.Snall at ebc.uu.se
> Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jfox at mcmaster.ca  Thu May 22 17:39:51 2003
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 22 May 2003 11:39:51 -0400
Subject: [R] extract half a matrix
In-Reply-To: <3.0.6.32.20030522165541.00d49160@mail.anst.uu.se>
Message-ID: <5.1.0.14.2.20030522113730.01e97440@mcmail.cis.mcmaster.ca>

Dear Tord,

At 04:55 PM 5/22/2003 +0200, Tord Snall wrote:

>I'm new to matrix operations in R. I couln't find a solution to the
>following problem among earlier help mails or in An introd to R, I guess
>because the question is really basic.
>
>I want to extract all above the diagonal, i.e. from
>
>     1  2  3  4
>1   0 26 49 49
>2  26  0 44 40
>3  49 44  0 21
>4  49 40 21  0
>
>I want
>
>26
>49
>44
>49
>40
>21
>

If you want the result as a one-column matrix, 
as.matrix(mat[upper.tri(mat)]) will do the trick.

John


-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From spencer.graves at pdf.com  Thu May 22 17:40:09 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 22 May 2003 08:40:09 -0700
Subject: [R] Experimental Design
References: <3ECCC247.9030706@bms.com>
Message-ID: <3ECCEF59.5030808@pdf.com>

	  It looks to me like you have two blocking variables with 1 control 
group and 4 treatment groups, with the control replicated between the 
"master blocking variable" = "experiment 1 vs. 2".  (The minor blocking 
variable occurs at 6 levels unless "Blk1" in Experiment 1 somehow 
relates to "Blk1" in Experiment 2.)  People who deal with this routinely 
could probably provide R code plus citations to the literature where 
this kind of analysis is discussed.  I would write an appropriate model 
and do the analysis.

	  And yes, I would want to confirm any encouraging results in a future 
experiment.

hth.  spencer graves

Isaac Neuhaus wrote:
> I don't know if this is the best place to post this question but I will 
> try anyway. I have two experiements for which I use one-way 
> matched-randomized ANOVA for the analysis and I would like to compare 
> different treatments in the two experiments. The only common group in 
> the two experiments are the controls. Is there any  ANOVA design that 
> allows me  to  make this comparison taking into consideration the 
> confounding effect? Any help would be greatly appreciated.
> 
> Isaac
> 
> A representation of the experiments follows:
> 
> Experiment 1
>           Control1     Treat1      Treat2
> Blk1          s1          s2          s3
> Blk2          s4          s5          s6
> Blk3          s7          s8          s9
> 
> 
> Experiment 2
>           Control2     Treat3      Treat4
> Blk1          s1a          s2a          s3a
> Blk2          s4a          s5a          s6a
> Blk3          s7a          s8a          s9a
> 
> Control1 and Control2 I are the same control cell line. I would like to 
> compare Treat1 to Treat3 and Treat 4 and also I would like to compare 
> Treat2 to Treat3 and Treat4. The fact that those experiments are done in 
> two different blocks will confound the interpretation. Can I use the 
> common control group to build a model? Should I include one of the 
> treatments in future experiments to test my model?
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From martinl at mathinfo.ens.univ-reims.fr  Thu May 22 16:25:58 2003
From: martinl at mathinfo.ens.univ-reims.fr (MARTIN Ludovic)
Date: Thu, 22 May 2003 16:25:58 +0200
Subject: [R] [R ] Query : problems with the arithmetic operator "^" with
	function "lme"
Message-ID: <200305221522.h4MFMKwR014036@tom.ens.univ-reims.fr>

Dear all,

I've got a problem in including square variables in lme function. I've 
tried to work on Dialyzer data of Pinheiro and Bates'book. 

We fit the heteroscedastic model with:

> data(Dialyzer)
> fm2Dial.lme<-lme(rate~(pressure+pressure^2+pressure^3+pressure^4)*QB,
+    Dialyzer,~pressure+pressure^2,weights=varPower(form=~pressure))

We Obtain

> fm2Dial.lme

Linear mixed-effects model fit by REML
  Data: Dialyzer 
  Log-restricted-likelihood: -488.4535
  Fixed: rate ~ (pressure + pressure^2 + pressure^3 + pressure^4) * QB 
   (Intercept)       pressure          QB300 pressure:QB300 
     39.362769       1.480331      -4.547449       7.515690 

Random effects:
 Formula: ~pressure + pressure^2 | Subject
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev     Corr  
(Intercept) 0.01102331 (Intr)
pressure    1.26972080 -0.823
Residual    8.79053329       

Variance function:
 Structure: Power of variance covariate
 Formula: ~pressure 
 Parameter estimates:
    power 
-1.025219 
Number of Observations: 140
Number of Groups: 20 

They are not coefficients associated with the "pressure^2, 
pressure^3, ..."
However, the model called is " rate ~ (pressure + pressure^2 + 
pressure^3 + pressure^4) * QB " . "^" is a problem !
So, we fit the model like this, including two matrices, for the fixed 
effects and the random effects:

>Dialyzer$PressureA<-cbind(Dialyzer$pressure,...,Dialyzer$pressure^4)
>Dialyzer$PressureB<-cbind(Dialyser$pressure,Dialyzer$pressure^2)

Now, we fit the same model like this:

>fm3Dial.lme<-lme(rate~(PressureA)*QB,
+    Dialyzer,~PressureB,weights=varPower(form=~pressure))

We obtain:

Linear mixed-effects model fit by REML
  Data: Dialyzer 
  Log-restricted-likelihood: -309.5058
  Fixed: rate ~ (PressureA) * QB 
   (Intercept)     PressureA1     PressureA2     PressureA3     
   -17.6805986     93.7145527    -49.1906874     12.2471222      
. . . 
Random effects:
 Formula: ~PressureB | Subject
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev   Corr         
(Intercept) 1.859195 (Intr) PrssB1
PressureB1  5.327444 -0.523       
PressureB2  1.648356  0.364 -0.954
Residual    1.261931              
. . .
 
Now, it's OK. The anova method returns
> anova(fm3Dial.lme)
             numDF denDF  F-value p-value
(Intercept)      1   112 551.5492  <.0001
PressureA        4   112 968.6231  <.0001
QB               1    18   4.7268  0.0433
PressureA:QB     4   112  20.9273  <.0001

However, the anova method is used to test the significanse of the terms 
in the order they were entered in the model. In Pinheiro and 
Bates'book, the result is

>anova(fm2Dial.lme)
 
                   numDF denDF  F-value p-value
      (Intercept)      1   112    552.9  <.0001
         pressure      1   112   2328.6  <.0001
    I(pressure^2)      1   112   1174.6  <.0001
           ...         ... ...     ...   ...
  I(pressure^2):QB     1   112      1.4  0.2477
  I(pressure^3):QB     1   112      2.2  0.1370
  I(pressure^4):QB     1   112      0.2  0.6840

The three large p-values suggest they are not needed in the model. They 
could be elimated from the model. It isn't indicated when we use 
matrices PressureA and PressureB ! So, how can we do? 
  
I would be grateful if anyone could help me.

Cordially,

Martin Ludovic.



From tlumley at u.washington.edu  Thu May 22 17:45:21 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 22 May 2003 08:45:21 -0700 (PDT)
Subject: [R] extract half a matrix
In-Reply-To: <3.0.6.32.20030522165541.00d49160@mail.anst.uu.se>
Message-ID: <Pine.A41.4.44.0305220844360.68840-100000@homer08.u.washington.edu>

On Thu, 22 May 2003, Tord Snall wrote:

> Dear all,
>
> I'm new to matrix operations in R. I couln't find a solution to the
> following problem among earlier help mails or in An introd to R, I guess
> because the question is really basic.
>
> I want to extract all above the diagonal, i.e. from
>
>     1  2  3  4
> 1   0 26 49 49
> 2  26  0 44 40
> 3  49 44  0 21
> 4  49 40 21  0
>

In addition to the solution suggested by other people there are built-in
functions upper.tri and lower.tri for doing this sort of thing, so

  x[upper.tri(x)]


	-thomas



From tord.snall at ebc.uu.se  Thu May 22 17:58:41 2003
From: tord.snall at ebc.uu.se (Tord Snall)
Date: Thu, 22 May 2003 17:58:41 +0200
Subject: [R] extract half a matrix
In-Reply-To: <Pine.A41.4.44.0305220844360.68840-100000@homer08.u.washing
	ton.edu>
References: <3.0.6.32.20030522165541.00d49160@mail.anst.uu.se>
Message-ID: <3.0.6.32.20030522175841.00d49160@mail.anst.uu.se>

Dear all,

Thanks for, as always the quick replies!

I have a suggestion: add the upper.tri() and lower.tri() under "See Also"
in the diag() help page. I searched for a such function there, and I can
see that diag() can be found unde "See also" for upper.tri().


Sincerely,
Tord




At 08:45 2003-05-22 -0700, Thomas Lumley wrote:
>On Thu, 22 May 2003, Tord Snall wrote:
>
>> Dear all,
>>
>> I'm new to matrix operations in R. I couln't find a solution to the
>> following problem among earlier help mails or in An introd to R, I guess
>> because the question is really basic.
>>
>> I want to extract all above the diagonal, i.e. from
>>
>>     1  2  3  4
>> 1   0 26 49 49
>> 2  26  0 44 40
>> 3  49 44  0 21
>> 4  49 40 21  0
>>
>
>In addition to the solution suggested by other people there are built-in
>functions upper.tri and lower.tri for doing this sort of thing, so
>
>  x[upper.tri(x)]
>
>
>	-thomas
>
>

-----------------------------------------------------------------------
Tord Sn?ll
Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
Villav?gen 14			
SE-752 36 Uppsala, Sweden
Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
E-mail: Tord.Snall at ebc.uu.se
Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!



From p.dalgaard at biostat.ku.dk  Thu May 22 18:05:52 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Thu, 22 May 2003 16:05:52 -0000
Subject: [R] [R ] Query : problems with the arithmetic operator "^" with
	function "lme"
In-Reply-To: <200305221522.h4MFMKwR014036@tom.ens.univ-reims.fr>
References: <200305221522.h4MFMKwR014036@tom.ens.univ-reims.fr>
Message-ID: <x2addf2c74.fsf@biostat.ku.dk>

"MARTIN ?Ludovic" <martinl at mathinfo.ens.univ-reims.fr> writes:

> > data(Dialyzer)
> > fm2Dial.lme<-lme(rate~(pressure+pressure^2+pressure^3+pressure^4)*QB,
> +    Dialyzer,~pressure+pressure^2,weights=varPower(form=~pressure))

You'll need I(pressure^2) in R. (FAQ 3.3.2)


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From hack at pedos.hr  Thu May 22 18:39:39 2003
From: hack at pedos.hr (Branimir K. Hackenberger)
Date: Thu, 22 May 2003 18:39:39 +0200
Subject: [R] (no subject)
Message-ID: <000001c32080$c02356b0$cecc35a1@BranimirHackenberger>

Dear R-helpers!

What it's means "Rank failure in Choleski decomposition" by using of
function surf.gls {spatial}?

Sincerely Yours

Branimir K. Hackenberger



From gxx4 at cwru.edu  Thu May 22 19:33:07 2003
From: gxx4 at cwru.edu (gxx4@cwru.edu)
Date: Thu, 22 May 2003 13:33:07 -0400
Subject: [R] help for calling a c program in the windows version R
Message-ID: <3fc4043f77b7.3f77b73fc404@cwru.edu>

Hi, all:

I want to call a c program in the windows version R, so I compiled it in VC to get the dll file and use the command ?dyn.load? to call it in R. There is no error appeared for this command, but when I use the command ? is.loaded? to check, it shows that dll file isn?t be loaded. Does anyone have same experience or know the correct way to do it?

Best wishes,
Guan Xing
5/22/03



From ligges at statistik.uni-dortmund.de  Thu May 22 20:11:39 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 22 May 2003 20:11:39 +0200
Subject: [R] help for calling a c program in the windows version R
References: <3fc4043f77b7.3f77b73fc404@cwru.edu>
Message-ID: <3ECD12DB.4658C58C@statistik.uni-dortmund.de>



gxx4 at cwru.edu wrote:
> 
> Hi, all:
> 
> I want to call a c program in the windows version R, so I compiled it in VC to get the dll file and use the command ?dyn.load? to call it in R. There is no error appeared for this command, but when I use the command ? is.loaded? to check, it shows that dll file isn?t be loaded. Does anyone have same experience or know the correct way to do it?
> 
> Best wishes,
> Guan Xing
> 5/22/03

I never used VC (Mingw's gcc is recommended), but I can tell you that
there is some information in .../src/gnuwin32/readme.packages and I
think also in Venables&Ripley (2000): S Programming, Springer (but not
sure about that, since the latter is in my office).

Uwe Ligges



From lsophir at wisemail.weizmann.ac.il  Thu May 22 22:22:19 2003
From: lsophir at wisemail.weizmann.ac.il (Ron Ophir)
Date: Thu, 22 May 2003 23:22:19 +0300
Subject: [R] download problem: configuration
Message-ID: <secd5bbd.067@wisemail.weizmann.ac.il>

Dear All,
I installed R on linux red-hat 7.3. I tried to run getBioC() script, which download R packages from bioconductor site, but I get the followin error message:

Error in getBioC() : Your R is not currently configured to allow HTTP
connections, which is required for getBioC to work properly.

How do I configure R correctly?

Thanks,
Ron



From duncan at research.bell-labs.com  Thu May 22 22:42:56 2003
From: duncan at research.bell-labs.com (Duncan Temple Lang)
Date: Thu, 22 May 2003 16:42:56 -0400
Subject: [R] 4 packages for Windows users
Message-ID: <20030522164255.E4468@jessie.research.bell-labs.com>

I have finally got around to putting 4 packages
on the Omegahat web site for use on Microsoft Windows.
The packages are:

RDCOMClient - interactive, dynamic access to arbitrary (D)COM objects
 from within R that allows one to create COM objects
 from R and call their methods and access their properties without 
 the need to compile any code specific to the COM object.


RDCOMServer - facility for defining COM classes entirely within
 R using functions and values as methods and properties. 
 This is a more general model than the one in S-Plus and the
 Thomas Baier's RDCOM facility.  It allows clients to see 
 S-COM objects as regular COM objects without needing to know
 the S language or create S commands.
 It also allows arbitrary S objects to be used as arguments in calls
 from the RDCOMClient package, and can be used to handle events from
 COM objects such as ActiveX controls, Excel.
  

SWinRegistry - facilities for accessing the Windows registry and its contents.
  One can read and write values, create keys, and navigate the hierarchy.

SWinTypeLibs - R interface to read Windows type libraries describing COM objects,
  C routines, etc.  This allows us to "compile" methods for accessing COM 
  objects from R more efficiently and with better local error-handling.



The packages are reasonably stable but could benefit from people using
them further.

The packages can be downloaded collectively from 

  http://www.omegahat.org/RDCOMBundle

or individually from

  http://www.omegahat.org/<package name>.


 Thanks

   Duncan.

-- 
_______________________________________________________________

Duncan Temple Lang                duncan at research.bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-3217
700 Mountain Avenue, Room 2C-259  fax:    (908)582-3340
Murray Hill, NJ  07974-2070       
         http://cm.bell-labs.com/stat/duncan



From myao at ou.edu  Thu May 22 22:44:09 2003
From: myao at ou.edu (Minghua Yao)
Date: Thu, 22 May 2003 15:44:09 -0500
Subject: [R] Question on dbHasCompleted(...)
Message-ID: <HDEPJCAKDEJMEEHKJOKEMEGFCBAA.myao@ou.edu>

All,

In the following, when I just enter R from UNIX and make a connection to
Oracle database, dbHasCompleted(rs) is TRUE. This shouldn't have happened
since I haven't fetched any thing. Help will be appreciated.

-MY

---------------------------------------------------------------------
MyUnixMachine% R

R : Copyright 2003, The R Development Core Team
Version 1.7.0  (2003-04-16)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type `license()' or `licence()' for distribution details.

R is a collaborative project with many contributors.
Type `contributors()' for more information.

Type `demo()' for some demos, `help()' for on-line help, or
`help.start()' for a HTML browser interface to help.
Type `q()' to quit R.

> library(ROracle)
> ora <- dbDriver("Oracle")
> channel <- dbConnect(ora, user = "scott", password="tiger",
dbname="myoracle")
> rs <- dbSendQuery(channel, "select * from USArrests")
> dbHasCompleted(rs)
[1] TRUE       # why ???????
>



From s.su at qut.edu.au  Fri May 23 04:49:55 2003
From: s.su at qut.edu.au (Steve Su)
Date: Fri, 23 May 2003 12:49:55 +1000
Subject: [R] Re: dates in chron package, split warning message
References: <Pine.LNX.4.44.0305220731530.2083-100000@gannet.stats>
Message-ID: <000901c320d5$fd9c2ee0$2032b583@busaccb337f>

Dear All,

Thank you Professor Ripley for your prompt and helpful reply.

I propose the answer to my question on cut.dates function is do the
following:

months = chron(julian(mdy$m,
1, mdy$y, origin = orig),origin=orig)-1, years = chron(julian(1, 1,
mdy$y, origin = orig),origin=orig)-1)

in the cut.dates function.

As to my second query, I modify the split function by adding the following
line in the split.default function:

if(is.matrix(x)){
return(.Internal(split(c(x),factor(rep(f,length=length(c(x)))))))

which works well for my needs.

Thank you for your attention.

Steve.





----- Original Message -----
From: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
To: "Steve Su" <s.su at qut.edu.au>
Cc: "R Help" <r-help at stat.math.ethz.ch>
Sent: Thursday, May 22, 2003 4:44 PM
Subject: Re: [R] Re: dates in chron package, split warning message


> On Thu, 22 May 2003, Steve Su wrote:
>
> > > > I am currently using R for windows.
> > > >
> > > > I am wondering why the dates command in chron package does not work
in
> > the
> > > > following situation:
> > > >
> > > > cut(dates(c(23,45,67),origin=c(1,1,2004)),"months")
> > > >
> > > > but will work for:
> > > >
> > > > cut(dates(c(23,45,67),origin=c(1,1,2004)),"days")
> > > > cut(dates(c(23,45,67),origin=c(1,1,2004)),"weeks")
>
> The dates function (not command) does work of course.  It's cut.dates
> which fails.  The short answer to you is this is a great opportunity to
> learn to debug R functions, and the hint is that the line
>
>     from <- switch(by, days = from,
> weeks = (from - day.of.week(mdy$m,mdy$d, mdy$y) +
as.numeric(start.on.monday)),
>         months = chron(julian(mdy$m, 1, mdy$y, origin = orig)),
>         years = chron(julian(1, 1,mdy$y, origin = orig)))
>
> contains two bugs.
>
> > > > My second query is rather trivial but I am wondering why warning
> > messages
> > > > were given when using the split in this manner:
> > > >
> > > > split(matrix(1:12,nrow=4),c(1,1,2,3)) # Which does what I want it to
do.
> > > >
> > > > and no warning messages were given in Splus6 for example?
>
> Try reading the help pages in each system.  They do not define split in
> the same way, and your usage is incorrect in R but not in S-PLUS 6.1.
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From dmurdoch at pair.com  Fri May 23 05:00:35 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu, 22 May 2003 23:00:35 -0400
Subject: [R] help for calling a c program in the windows version R
In-Reply-To: <3fc4043f77b7.3f77b73fc404@cwru.edu>
References: <3fc4043f77b7.3f77b73fc404@cwru.edu>
Message-ID: <cl2rcvkc9893n7cblpisrr0fe499ag6te9@4ax.com>

On Thu, 22 May 2003 13:33:07 -0400, you wrote:

>Hi, all:
>
>I want to call a c program in the windows version R, so I compiled it in VC to get the dll file and use the command ?dyn.load? to call it in R. There is no error appeared for this command, but when I use the command ? is.loaded? to check, it shows that dll file isn?t be loaded. Does anyone have same experience or know the correct way to do it?

"is.loaded" doesn't check for the DLL, it checks for a particular
entry point in the DLL.  Most likely VC is exporting the function
under a different name than you are searching for, or isn't exporting
it at all.

You can view all the exports in a DLL using the Quick View program
that is distributed with some versions of Windows, or using the
objdump program that's in the development tools put together by Brian
Ripley, or using some tool that probably comes with VC.  (With Borland
compilers the tool is called tdump.exe, but I don't know what
Microsoft calls it.)

More help on using DLLs is on my web page,
<http://www.stats.uwo.ca/faculty/murdoch/software/compilingDLLs> and
in the readme.packages file distributed with R.

Duncan Murdoch



From dmurdoch at pair.com  Fri May 23 04:28:26 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu, 22 May 2003 22:28:26 -0400
Subject: [R] extract half a matrix
In-Reply-To: <3.0.6.32.20030522175841.00d49160@mail.anst.uu.se>
References: <3.0.6.32.20030522165541.00d49160@mail.anst.uu.se>
	<Pine.A41.4.44.0305220844360.68840-100000@homer08.u.washing
	ton.edu> <3.0.6.32.20030522175841.00d49160@mail.anst.uu.se>
Message-ID: <gn1rcv8qsbffj41stovf0u5iab5n6f1irc@4ax.com>

On Thu, 22 May 2003 17:58:41 +0200, you wrote:

>Dear all,
>
>Thanks for, as always the quick replies!
>
>I have a suggestion: add the upper.tri() and lower.tri() under "See Also"
>in the diag() help page. I searched for a such function there, and I can
>see that diag() can be found unde "See also" for upper.tri().

Good suggestion.  I've put it into r-patched, so it should be in 1.7.1
(which should be released on June 16, according to current plans.

Duncan Murdoch



From dmurdoch at pair.com  Fri May 23 04:28:26 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu, 22 May 2003 22:28:26 -0400
Subject: [R] extract half a matrix
In-Reply-To: <3.0.6.32.20030522175841.00d49160@mail.anst.uu.se>
References: <3.0.6.32.20030522165541.00d49160@mail.anst.uu.se>
	<Pine.A41.4.44.0305220844360.68840-100000@homer08.u.washing
	ton.edu> <3.0.6.32.20030522175841.00d49160@mail.anst.uu.se>
Message-ID: <gn1rcv8qsbffj41stovf0u5iab5n6f1irc@4ax.com>

On Thu, 22 May 2003 17:58:41 +0200, you wrote:

>Dear all,
>
>Thanks for, as always the quick replies!
>
>I have a suggestion: add the upper.tri() and lower.tri() under "See Also"
>in the diag() help page. I searched for a such function there, and I can
>see that diag() can be found unde "See also" for upper.tri().

Good suggestion.  I've put it into r-patched, so it should be in 1.7.1
(which should be released on June 16, according to current plans.

Duncan Murdoch



From Roger.Bivand at nhh.no  Fri May 23 09:59:24 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 23 May 2003 09:59:24 +0200 (CEST)
Subject: [R] spatial: surf.gls() rank failure; was (no subject)
In-Reply-To: <000001c32080$c02356b0$cecc35a1@BranimirHackenberger>
Message-ID: <Pine.LNX.4.44.0305230939390.18827-100000@reclus.nhh.no>

Please always use an informative subject.

Please also recall that questions about contributed packages should first 
be addressed to their maintainers.

In the case of the spatial package, another source of information that 
should be consulted before contacting the maintainer, is the book that the 
software is wriiten to support.

Finally, consider that a prime benefit of open source software is that you 
can read the code, and identify where error messages are being generated.

On Thu, 22 May 2003, Branimir K. Hackenberger wrote:

> Dear R-helpers!
> 
> What it's means "Rank failure in Choleski decomposition" by using of
> function surf.gls {spatial}?
> 
In this case, reading the code of surf.gls shows that this message is 
displayed when the C function VR_gls() returns a non-zero value of ifail, 
which happens when cholcov() returns from chols(), the algorithm of which 
is given in: M.J.R. Healy (1968) Applied Statistics  pp. 195-197.

If that is too abstract, try:

data(topo)
topo <- rbind(topo, topo[50:52,])
topo.kr <- surf.gls(2, expcov, topo, d = 0.7)
Error in surf.gls(2, expcov, topo, d = 0.7) : 
        Rank failure in Choleski decomposition

that is, you seem to have duplicate point locations, leading to a 
covariance matrix not of full rank.  

> Sincerely Yours
> 
> Branimir K. Hackenberger
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From Alex.Randriamiharisoa at inst.hospvd.ch  Fri May 23 11:16:14 2003
From: Alex.Randriamiharisoa at inst.hospvd.ch (Alex Randriamiharisoa)
Date: Fri, 23 May 2003 11:16:14 +0200
Subject: [R] Fortran DLL
Message-ID: <5.1.0.14.2.20030523103432.026dee50@pop.hospvd.ch>

Dear R-users,
After the reading of "Writing R extensions", "readme.packages", "Using 
external compilers with
R", ...,  I have tried to create a DLL for my Fortran file using the command:

g77 --shared -o robeth.dll robeth.f

and failed with several messages as :
c:\temp/ccU8N5fb.o: ...  undefined reference to 'realpr_'
c:\temp/ccU8N5fb.o: ...  undefined reference to 'dblepr_'
c:\temp/ccU8N5fb.o: ...  undefined reference to 'intpr_'
c:\temp/ccU8N5fb.o: ...  undefined reference to 'rexit_'

What I have missed. If I insert #include <R.h> at the top of the file, the 
MinGW
g77 compiler exits immediately =>  "undefined or invalid # directives"

I've tested on  R Version 1.5.1 and 1.7.0, for windows. If a special 
library is needed,
someone could send it to me by mail.
Thanks for your help.
Alex R.



From Roger.Bivand at nhh.no  Fri May 23 11:56:32 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 23 May 2003 11:56:32 +0200 (CEST)
Subject: [R] Fortran DLL
In-Reply-To: <5.1.0.14.2.20030523103432.026dee50@pop.hospvd.ch>
Message-ID: <Pine.LNX.4.44.0305231147460.18827-100000@reclus.nhh.no>

On Fri, 23 May 2003, Alex Randriamiharisoa wrote:

> Dear R-users,
> After the reading of "Writing R extensions", "readme.packages", "Using 
> external compilers with
> R", ...,  I have tried to create a DLL for my Fortran file using the command:
> 
> g77 --shared -o robeth.dll robeth.f
> 
> and failed with several messages as :
> c:\temp/ccU8N5fb.o: ...  undefined reference to 'realpr_'
> c:\temp/ccU8N5fb.o: ...  undefined reference to 'dblepr_'
> c:\temp/ccU8N5fb.o: ...  undefined reference to 'intpr_'
> c:\temp/ccU8N5fb.o: ...  undefined reference to 'rexit_'
> 
> What I have missed. If I insert #include <R.h> at the top of the file, the 
> MinGW
> g77 compiler exits immediately =>  "undefined or invalid # directives"
> 

These are references to R.dll, which is not linked.

Perhaps try 

Rcmd SHLIB robeth.f

to use the build train that will link correctly. 

> I've tested on  R Version 1.5.1 and 1.7.0, for windows. If a special 
> library is needed,
> someone could send it to me by mail.
> Thanks for your help.
> Alex R.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From kurt.sys at UGent.be  Fri May 23 12:35:09 2003
From: kurt.sys at UGent.be (Kurt Sys)
Date: Fri, 23 May 2003 12:35:09 +0200
Subject: [R] building zip?
Message-ID: <16077.63838.37904.523629@ksys.rug.ac.be>

Hello,

I know this might sound stupid, but here's my problem. I try to build
packages, which gives absolutely no problem as long as I do this in
Linux. I get my .tar.gz-package. However, for windows, one needs
.zip-files (I guess), but for one reason or another, this seems not to
work.
I'm sorry about this question, but I'm not a windows-specialist (nor
Linux-guru). I don't see how to make 'zip'-packages in linux and
trying this in Windows ('Rcmd build <package>' at the DOS prompt),
tells me it can't find perl script 'c:\Progra~1\R/bin/build' (or
something like that).


tnx,
Kurt



-- 
You can destroy your now by worrying about tomorrow.
		-- Janis Joplin



From rwatkins at cornerstonelp.com  Fri May 23 13:10:21 2003
From: rwatkins at cornerstonelp.com (rwatkins@cornerstonelp.com)
Date: Fri, 23 May 2003 06:10:21 -0500
Subject: [R] Not getting all data to a text file via write.table
Message-ID: <NDEKIJPPGJCIKBNEDOKOKECGCCAA.rwatkins@cornerstonelp.com>

Hi all- Thanks in advance for your help.

	I have a 2275x1 table of residuals from an lm() regression.  I want to
analyze this further in Excel.  I tried using:

	df<-resid(object)
	write.table(df)

and this yields a nice looking output in R, but because of screen
constraints, I seem to loose data "out-the-top" of the Console -- which
doesn't bother me, as long as I can see it eventually.  But when i clicked
on the RGui tool bar File|Save to file|, etc., only what I could see in the
Console seemed to be saved to the text file.

	Obviiously, I am a newbie -- How can I get the entire output into this
textfile?

	Again, thanks!  Enjoy the Holiday weekend!



From Bernhard.Pfaff at drkw.com  Fri May 23 13:11:31 2003
From: Bernhard.Pfaff at drkw.com (Pfaff, Bernhard)
Date: Fri, 23 May 2003 13:11:31 +0200
Subject: [R] building zip?
Message-ID: <18D602BD42B7E24EB810D6454A58DB90047303B7@ibfftce505.is.de.dresdnerkb.com>

Hello Kurt,

you might consult the following two web-references:

1)
http://www.stats.ox.ac.uk/pub/Rtools/

2)
http://www.stat.auckland.ac.nz/~kwan022/pub/R/WinBook/WinBook.pdf

chapter 5, Build R Package. The software you need to have installed is
listed in chapter 4.1.

HTH,
Bernhard


-----Original Message-----
From: Kurt Sys [mailto:kurt.sys at UGent.be]
Sent: 23 May 2003 12:35
To: R list
Subject: [R] building zip?


Hello,

I know this might sound stupid, but here's my problem. I try to build
packages, which gives absolutely no problem as long as I do this in
Linux. I get my .tar.gz-package. However, for windows, one needs
.zip-files (I guess), but for one reason or another, this seems not to
work.
I'm sorry about this question, but I'm not a windows-specialist (nor
Linux-guru). I don't see how to make 'zip'-packages in linux and
trying this in Windows ('Rcmd build <package>' at the DOS prompt),
tells me it can't find perl script 'c:\Progra~1\R/bin/build' (or
something like that).


tnx,
Kurt



-- 
You can destroy your now by worrying about tomorrow.
		-- Janis Joplin

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


----------------------------------------------------------------------
If you have received this e-mail in error or wish to read our e-mail 
disclaimer statement and monitoring policy, please refer to 
http://www.drkw.com/disc/email/ or contact the sender.



From p.dalgaard at biostat.ku.dk  Fri May 23 13:23:22 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri, 23 May 2003 11:23:22 -0000
Subject: [R] building zip?
In-Reply-To: <16077.63838.37904.523629@ksys.rug.ac.be>
References: <16077.63838.37904.523629@ksys.rug.ac.be>
Message-ID: <x2addd3npv.fsf@biostat.ku.dk>

Kurt Sys <kurt.sys at UGent.be> writes:

> Hello,
> 
> I know this might sound stupid, but here's my problem. I try to build
> packages, which gives absolutely no problem as long as I do this in
> Linux. I get my .tar.gz-package. However, for windows, one needs
> .zip-files (I guess), but for one reason or another, this seems not to
> work.
> I'm sorry about this question, but I'm not a windows-specialist (nor
> Linux-guru). I don't see how to make 'zip'-packages in linux and
> trying this in Windows ('Rcmd build <package>' at the DOS prompt),
> tells me it can't find perl script 'c:\Progra~1\R/bin/build' (or
> something like that).

You can use tar.gz files on Windows too, you just need to have the 
toolchain installed (which most people don't). 

I suspect you need to install the source tools. There's a check box
for that when you install R (off by default; I actually thought I had
convinced Duncan to change it, but apparently not). If you do have
them installed, my best guess is that you need perl itself or that it
is not configured right. 

However, that won't end your troubles... You do need to read the
readme.packages file for what to do next. Basically, you have to
install the package from source and zip the resulting installed
package directory.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From stuart.leask at nottingham.ac.uk  Fri May 23 13:28:38 2003
From: stuart.leask at nottingham.ac.uk (Stuart Leask)
Date: Fri, 23 May 2003 12:28:38 +0100
Subject: [R] write.table only writes the first 256 variables/columns
References: <5.1.0.14.2.20030520085158.01ea2cb0@mcmail.cis.mcmaster.ca><5.1.0.14.2.20030520085158.01ea2cb0@mcmail.cis.mcmaster.ca>
	<5.1.0.14.2.20030520113922.01e97588@mcmail.cis.mcmaster.ca>
Message-ID: <00cf01c3211e$74b23f40$f2e1f380@OPENZAURUS>

Hi there.
Using read.spss I can read in a file 333 columns, 280 lines, but if I use
write.table to export it, I only get 256 columns x 280 lines. I can't find
this feature documented anywhere...

Stuart
Dr Stuart Leask MA MRCPsych, Clinical Lecturer in Psychiatry
University of Nottingham Dept of Psychiatry, Duncan Macmillan House
Porchester Road, Nottingham. NG3 6AA. UK
http://www.nottingham.ac.uk/psychiatry/staff/s_leask.html



From spencer.graves at pdf.com  Fri May 23 13:34:44 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 23 May 2003 04:34:44 -0700
Subject: [R] Not getting all data to a text file via write.table
References: <NDEKIJPPGJCIKBNEDOKOKECGCCAA.rwatkins@cornerstonelp.com>
Message-ID: <3ECE0754.5030705@pdf.com>

	  ?write.table reveals a second argument "file".  Have you considered 
"write.table(df, 'df.csv')"?  I've imported *.csv files produced by 
"write.table" into Excel many times, so I think this should work for you.

	  By the way, "df" is the density function for the F distribution.  It 
is also the degrees of freedom argument for Student's t distribution 
functions, etc.  It is therefore considered poor style to use "df" as 
the name of a data.frame or some other object.

hth.  spencer graves

rwatkins at cornerstonelp.com wrote:
> Hi all- Thanks in advance for your help.
> 
> 	I have a 2275x1 table of residuals from an lm() regression.  I want to
> analyze this further in Excel.  I tried using:
> 
> 	df<-resid(object)
> 	write.table(df)
> 
> and this yields a nice looking output in R, but because of screen
> constraints, I seem to loose data "out-the-top" of the Console -- which
> doesn't bother me, as long as I can see it eventually.  But when i clicked
> on the RGui tool bar File|Save to file|, etc., only what I could see in the
> Console seemed to be saved to the text file.
> 
> 	Obviiously, I am a newbie -- How can I get the entire output into this
> textfile?
> 
> 	Again, thanks!  Enjoy the Holiday weekend!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Roger.Bivand at nhh.no  Fri May 23 13:38:50 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 23 May 2003 13:38:50 +0200 (CEST)
Subject: [R] building zip?
In-Reply-To: <x2addd3npv.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0305231336230.18827-100000@reclus.nhh.no>

On 23 May 2003, Peter Dalgaard BSA wrote:

> Kurt Sys <kurt.sys at UGent.be> writes:
> 
> > Hello,
> > 
> > I know this might sound stupid, but here's my problem. I try to build
> > packages, which gives absolutely no problem as long as I do this in
> > Linux. I get my .tar.gz-package. However, for windows, one needs
> > .zip-files (I guess), but for one reason or another, this seems not to
> > work.
> > I'm sorry about this question, but I'm not a windows-specialist (nor
> > Linux-guru). I don't see how to make 'zip'-packages in linux and
> > trying this in Windows ('Rcmd build <package>' at the DOS prompt),
> > tells me it can't find perl script 'c:\Progra~1\R/bin/build' (or
> > something like that).
> 
> You can use tar.gz files on Windows too, you just need to have the 
> toolchain installed (which most people don't). 
> 
> I suspect you need to install the source tools. There's a check box
> for that when you install R (off by default; I actually thought I had
> convinced Duncan to change it, but apparently not). If you do have
> them installed, my best guess is that you need perl itself or that it
> is not configured right. 
> 
> However, that won't end your troubles... You do need to read the
> readme.packages file for what to do next. Basically, you have to
> install the package from source and zip the resulting installed
> package directory.
> 
Actually, Rcmd build --binary <pkg> does a great job of making the binary 
package *.zip automatically - if Rcmd check runs cleanly, building the 
binary will too.


> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From p.dalgaard at biostat.ku.dk  Fri May 23 14:01:13 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri, 23 May 2003 12:01:13 -0000
Subject: [R] Not getting all data to a text file via write.table
In-Reply-To: <NDEKIJPPGJCIKBNEDOKOKECGCCAA.rwatkins@cornerstonelp.com>
References: <NDEKIJPPGJCIKBNEDOKOKECGCCAA.rwatkins@cornerstonelp.com>
Message-ID: <x265o13lyt.fsf@biostat.ku.dk>

<rwatkins at cornerstonelp.com> writes:

> Hi all- Thanks in advance for your help.
> 
> 	I have a 2275x1 table of residuals from an lm() regression.  I want to
> analyze this further in Excel.  I tried using:
> 
> 	df<-resid(object)
> 	write.table(df)
> 
> and this yields a nice looking output in R, but because of screen
> constraints, I seem to loose data "out-the-top" of the Console -- which
> doesn't bother me, as long as I can see it eventually.  But when i clicked
> on the RGui tool bar File|Save to file|, etc., only what I could see in the
> Console seemed to be saved to the text file.
> 
> 	Obviiously, I am a newbie -- How can I get the entire output into this
> textfile?

There's a file= argument to write.table. 

That's the right way to do it, but you can increase the amount saved
in the console too, on the GUI Preferences menu I think.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From Jan_Svatos at eurotel.cz  Fri May 23 14:31:47 2003
From: Jan_Svatos at eurotel.cz (Jan_Svatos@eurotel.cz)
Date: Fri, 23 May 2003 14:31:47 +0200
Subject: [R] Not getting all data to a text file via write.table
Message-ID: <OF192FEA92.BFB70473-ONC1256D2F.00439658@eurotel.cz>


Hi,

look more deeply at

?write.table

>From wite.table help:

`write.table' prints its required argument `x' (after converting
it to a data frame if it is not one already) to `file'.  The
entries in each line (row) are separated by the value of `sep'.

Therefore,

>write.table(df, file=myfile.csv, sep=";")
gives the exact output independent on screen constraints.


Or try
>library(MASS)
>?write.matrix

BTW,
R as really excellent statistical software has MUCH better tools for
analysis of residuals than any spreadsheet calculator including Excel,
therefore I use R for such analysis. Try

>?lm.influence

HTH,
Jan



- - - Original message: - - -
From: r-help-bounces at stat.math.ethz.ch
Send: 23.5.2003 13:14:07
To: "R Help" <r-help at stat.math.ethz.ch>
Subject: [R] Not getting all data to a text file via write.table

Hi all- Thanks in advance for your help.

 I have a 2275x1 table of residuals from an lm() regression.
 I want to analyze this further in Excel.  I tried using:

 df<-resid(object)
 write.table(df)

and this yields a nice looking output in R, but because of screen
constraints, I seem to loose data "out-the-top" of the Console -- which
doesn't bother me, as long as I can see it eventually.  But when i clicked
on the RGui tool bar File|Save to file|, etc., only what I could see in the
Console seemed to be saved to the text file.

 Obviiously, I am a newbie -- How can I get the entire output into this
textfile?

 Again, thanks!  Enjoy the Holiday weekend!

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Laurens.Leerink at tudor.com  Fri May 23 15:32:44 2003
From: Laurens.Leerink at tudor.com (Laurens Leerink)
Date: Fri, 23 May 2003 09:32:44 -0400
Subject: [R] isSeekable returns F on seekable file
Message-ID: <C00E92D3970A4F41A95D70A813D544051089A9@tudor.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030523/ed10184d/attachment.pl

From tlumley at u.washington.edu  Fri May 23 15:50:00 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 23 May 2003 06:50:00 -0700 (PDT)
Subject: [R] write.table only writes the first 256 variables/columns
In-Reply-To: <00cf01c3211e$74b23f40$f2e1f380@OPENZAURUS>
Message-ID: <Pine.A41.4.44.0305230645150.25218-100000@homer32.u.washington.edu>

On Fri, 23 May 2003, Stuart Leask wrote:

> Hi there.
> Using read.spss I can read in a file 333 columns, 280 lines, but if I use
> write.table to export it, I only get 256 columns x 280 lines. I can't find
> this feature documented anywhere...
>

I can't replicate this:

> foo<-matrix(rnorm(333*280), ncol=333, nrow=280)
> foo<-as.data.frame(foo)
> write.table(foo,"foo.txt")
> bar<-read.table("foo.txt",header=TRUE)
> dim(bar)
[1] 280 333
> all.equal(foo,bar)
[1] TRUE

and I can't see why it would be true. Does this example work for you?
 The largest SPSS file I have lying around has only 212 columns, so I
can't test the read.spss aspect of it.

	-thomas



From laurent.buffat at it-omics.com  Fri May 23 16:00:55 2003
From: laurent.buffat at it-omics.com (laurent  buffat)
Date: Fri, 23 May 2003 16:00:55 +0200
Subject: [R] replaceMethod time and memory for very large object.
In-Reply-To: <C00E92D3970A4F41A95D70A813D544051089A9@tudor.com>
Message-ID: <DGEIIIMDDGKLGHFCOPOFOEIECCAA.laurent.buffat@it-omics.com>


Hi there,

First, please apologize, I?m not fluent in English.

I try to manipulate very large object with R, and I have some problems with
memory and time access, because of the ? by value mechanism ?.
I would like to ? encapsulate ? a large vector in a class and access to the
vector by method and replaceMethod, but where is a lot of ? implicit copy ?,
and so, a lot of memory and time consuming.

The data are very large, and come from micro array experiment (see
http://Biocondutor.org for more detail of what is a micro array ) , but a
 typical ? vector is a 20000 genes * 20 probes * 100 experiments * 2 (means
and variance)

The best way, in term of speed and memory is to try to emulate a ? by
reference ? mechanism, but it?s not very ? in the spirit of R ? and a little
? dangerous ? (see the example).

Could you give me some recommendations ?

Thanks for your help.

The code below is a little ? long ?, sorry.

Laurent B.

////////////////////////////

setClass("Foo", representation(v = "numeric"))

setMethod("initialize", signature("Foo"), function(.Object, v=vector()) {
		.Object at v <- v
		.Object
	   })


setGeneric("v", function(.Object) standardGeneric("v"))
setMethod("v", "Foo", function(.Object) .Object at v )

setGeneric("v<-",function(.Object,value) standardGeneric("v<-"))
setReplaceMethod("v", "Foo", function(.Object, value) {
	.Object at v <- value
         return(.Object)
         })

setMethod("[","Foo", function(x,i,j=NA,...,drop=FALSE) x at v[i] )

setReplaceMethod("[","Foo",function(x,i,j=NA,...,value) {
	x at v[i] <- value
	x
	})

n <- 2000 * 20 * 100 * 2

# in fact I would like to have
# 20000 genes * 20 mesures by genes (probes) * 100 experiences * 2 ( mean
and variance)
# but, it's to much memory for these example, so just try with 2000 "genes".

x <- rep(1,n)
# x, a non encapsuled vetor for the data "
y <- new("Foo",v=x)
# y, a encapsuled version".


x[1] <- 2
y at v[1] <- 2
v(y)[1] <- 2
y[1] <- 2

nt <- 10 # number of test

system.time(for(i in 1:nt) x[1] <- 2)
system.time(for(i in 1:nt) y at v[1] <- 2)
system.time(for(i in 1:nt) v(y)[1] <- 2)
system.time(for(i in 1:nt) y[1] <- 2)

[1] 0 0 0 0 0
[1]  7.80  3.17 10.97  0.00  0.00
[1] 10.19  5.39 15.60  0.00  0.00
[1]  9.00  4.54 13.55  0.00  0.00

x[1:2]
y[1:2]
v(y)[1:2]
y at v[1:2]

system.time(for(i in 1:nt) x[1:2])
system.time(for(i in 1:nt) y[1:2])
system.time(for(i in 1:nt) v(y)[1:2])
system.time(for(i in 1:nt) y at v[1:2])


[1] 0 0 0 0 0
[1] 0 0 0 0 0
[1] 0 0 0 0 0
[1] 0 0 0 0 0

# no problem for "acces method, only for replace method
# Class FooPtr,
# a way to try to by pass the "by value mecanizim of R" ...

setClass("FooPtr", representation(p = "environment"))

setMethod("initialize", signature("FooPtr"), function(.Object, v=vector()) {
		.Object at p <- new("environment")
		assign("v",v,envir=.Object at p)
		.Object
	   })

setMethod("v", "FooPtr", function(.Object) get("v",envir=.Object at p) )

setReplaceMethod("v", "FooPtr",
                   function(.Object, value) {
                   assign("v",value,envir=.Object at p)
                   return(.Object)
                 })

setMethod("[","FooPtr", function(x,i,j=NA,...,drop=FALSE)
get("v",envir=x at p)[i] )

# a first version of "[<-" for FooPtr :

setReplaceMethod("[","FooPtr",function(x,i,j=NA,...,value)
	{
	v<- get("v",envir=x at p)
	v[i] <- value
	assign("v",v,envir=x at p)
	x
	})

z <- new("FooPtr",v=x)

x[1] <- 2
v(z)[1] <- 2
z[1] <- 2


system.time(for(i in 1:nt) x[1] <- 2)
system.time(for(i in 1:nt) v(z)[1] <- 2)
system.time(for(i in 1:nt) z[1] <- 2)

[1] 0.01 0.00 0.01 0.00 0.00
[1] 0 0 0 0 0
[1] 1.63 1.18 2.81 0.00 0.00

# the v(z)[1] is "good", but not "[<-"
# a more creasy way to try "by reference"

setReplaceMethod("[","FooPtr",function(x,i,j=NA,...,value)
	{
	assign("i",i,envir=x at p)
	assign("value",value,envir=x at p)
	eval(expression(v[i] <- value), envir=x at p)
	rm("i","value",envir=x at p)
	x
	})

system.time(for(i in 1:nt) x[1] <- 2)
system.time(for(i in 1:nt) v(z)[1] <- 2)
system.time(for(i in 1:nt) z[1] <- 2)

[1] 0 0 0 0 0
[1] 0 0 0 0 0
[1] 0.14 0.12 0.26 0.00 0.00

# "[<-" is better, but v(z)[] is the best ... (why ???)


# ok, v(z)[i] is the "best" acess, but you need to know what you do :

v(z)[1] <- 12345
z1 <- z
v(z1)[1]

# z and z1 work with the same environment ...

//////////////////////

Thanks for your help.

Laurent



From p.dalgaard at biostat.ku.dk  Fri May 23 16:12:12 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri, 23 May 2003 14:12:12 -0000
Subject: [R] write.table only writes the first 256 variables/columns
In-Reply-To: <Pine.A41.4.44.0305230645150.25218-100000@homer32.u.washington.edu>
References: <Pine.A41.4.44.0305230645150.25218-100000@homer32.u.washington.edu>
Message-ID: <x2iss121c0.fsf@biostat.ku.dk>

Thomas Lumley <tlumley at u.washington.edu> writes:

>  The largest SPSS file I have lying around has only 212 columns, so I
> can't test the read.spss aspect of it.

I can:

> s95 <- as.data.frame(read.spss("~skm/public_html/fsvpage/sundby95.sav"))
> write.table(s95,"foo.txt")
> bar<-read.table("foo.txt",header=TRUE)
> dim(bar)
[1] 2742  323
> dim(s95)
[1] 2742  323

(all.equal() gives a few diffs but that's because factor levels are
in non-alphabetical order in s95)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From stuart.leask at nottingham.ac.uk  Fri May 23 16:43:49 2003
From: stuart.leask at nottingham.ac.uk (Stuart Leask)
Date: Fri, 23 May 2003 15:43:49 +0100
Subject: Fw: [R] write.table only writes the first 256 variables/columns
Message-ID: <012701c32139$b932ea00$f2e1f380@OPENZAURUS>

Thanks. I was "believing" an Excel import of the file - as you say, a
re-import
into R still has 333 columns. I shall look elsewhere for the cause of the
mysterious truncation.

Stuart

> ----- Original Message -----
> From: "Thomas Lumley" <tlumley at u.washington.edu>
> To: "Stuart Leask" <stuart.leask at nottingham.ac.uk>
> Cc: "R-Help" <r-help at stat.math.ethz.ch>
> Sent: Friday, May 23, 2003 2:50 PM
> Subject: Re: [R] write.table only writes the first 256 variables/columns
>
>
> > On Fri, 23 May 2003, Stuart Leask wrote:
> >
> > > Hi there.
> > > Using read.spss I can read in a file 333 columns, 280 lines, but if I
> use
> > > write.table to export it, I only get 256 columns x 280 lines. I can't
> find
> > > this feature documented anywhere...
> > >
> >
> > I can't replicate this:
> >
> > > foo<-matrix(rnorm(333*280), ncol=333, nrow=280)
> > > foo<-as.data.frame(foo)
> > > write.table(foo,"foo.txt")
> > > bar<-read.table("foo.txt",header=TRUE)
> > > dim(bar)
> > [1] 280 333
> > > all.equal(foo,bar)
> > [1] TRUE
> >
> > and I can't see why it would be true. Does this example work for you?
> >  The largest SPSS file I have lying around has only 212 columns, so I
> > can't test the read.spss aspect of it.
> >
> > -thomas
> >
>



From iwhite at staffmail.ed.ac.uk  Fri May 23 16:44:08 2003
From: iwhite at staffmail.ed.ac.uk (iwhite@staffmail.ed.ac.uk)
Date: Fri, 23 May 2003 15:44:08 +0100 (BST)
Subject: [R] predict.smooth.spline
Message-ID: <Pine.GSO.4.33.0305231543060.19395-100000@holyrood.ed.ac.uk>

I'm using R 1.7.0 on linux. With this version of R the package modreg is
automatically loaded at start of session. However attempting to use
predict.smooth.spline() produces Error: couldn't find function
predict.smooth.spline.

The function smooth.spline() is OK. What am I missing?

======================================
I.White
ICAPB, University of Edinburgh
Ashworth Laboratories, West Mains Road
Edinburgh EH9 3JT
Fax: 0131 650 6564  Tel: 0131 650 5490
E-mail: iwhite at staffmail.ed.ac.uk



From cp133 at york.ac.uk  Fri May 23 16:56:05 2003
From: cp133 at york.ac.uk (cp133)
Date: Fri, 23 May 2003 15:56:05 +0100
Subject: [R] plot output function
Message-ID: <3ECE3685.53A110D4@york.ac.uk>

Hi,

I have written my own function to estimate a local linear regression.
When I plot the output vector on the scatterplot of the data, the
function lines does not work and I get a rescaled regression line. 
When I plot the output vector alone, the graph looks right, but choosing
the type "line" instead of the default does not deliver a clear single
line.

Does somebody know why this is happening.

Thank you,

Chiara



From gti1x at vet.gla.ac.uk  Fri May 23 17:02:32 2003
From: gti1x at vet.gla.ac.uk (Giles Innocent)
Date: Fri, 23 May 2003 16:02:32 +0100
Subject: Fw: [R] write.table only writes the first 256 variables/columns
In-Reply-To: <012701c32139$b932ea00$f2e1f380@OPENZAURUS>;
	from stuart.leask@nottingham.ac.uk on Fri, May 23, 2003 at
	15:43:49 +0100
References: <012701c32139$b932ea00$f2e1f380@OPENZAURUS>
Message-ID: <20030523160232.A3580@leslie.vet.gla.ac.uk>

Excel only imports the first 256 columns as standard (not sure if you 
can increase this).  I had a similar problem importing a database 
recently - I just gave up using Excel, used R instead.

Giles

On 2003.05.23 15:43 Stuart Leask wrote:
> Thanks. I was "believing" an Excel import of the file - as you say, a
> re-import
> into R still has 333 columns. I shall look elsewhere for the cause of
> the
> mysterious truncation.
> 
> Stuart
> 
> > ----- Original Message -----
> > From: "Thomas Lumley" <tlumley at u.washington.edu>
> > To: "Stuart Leask" <stuart.leask at nottingham.ac.uk>
> > Cc: "R-Help" <r-help at stat.math.ethz.ch>
> > Sent: Friday, May 23, 2003 2:50 PM
> > Subject: Re: [R] write.table only writes the first 256
> variables/columns
> >
> >
> > > On Fri, 23 May 2003, Stuart Leask wrote:
> > >
> > > > Hi there.
> > > > Using read.spss I can read in a file 333 columns, 280 lines, but
> if I
> > use
> > > > write.table to export it, I only get 256 columns x 280 lines. I
> can't
> > find
> > > > this feature documented anywhere...
> > > >
> > >
> > > I can't replicate this:
> > >
> > > > foo<-matrix(rnorm(333*280), ncol=333, nrow=280)
> > > > foo<-as.data.frame(foo)
> > > > write.table(foo,"foo.txt")
> > > > bar<-read.table("foo.txt",header=TRUE)
> > > > dim(bar)
> > > [1] 280 333
> > > > all.equal(foo,bar)
> > > [1] TRUE
> > >
> > > and I can't see why it would be true. Does this example work for
> you?
> > >  The largest SPSS file I have lying around has only 212 columns,
> so I
> > > can't test the read.spss aspect of it.
> > >
> > > -thomas
> > >
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
>



From edd at debian.org  Fri May 23 17:03:06 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 23 May 2003 10:03:06 -0500
Subject: [R] Source code analysis for R ?
Message-ID: <20030523150306.GA29338@sonny.eddelbuettel.com>


A GUI-heavy R project of mine has mushroomed into well over 1000 lines of
code. It is getting to a point where I am wondering if someone had something
like a script to summarize which functions call which other etc.  

Note that I am not looking at profiling but rather a (static) analysis of
code interdepence.  Does anybody here have anything for this task?

Thanks for any pointers,  Dirk

-- 
Don't drink and derive. Alcohol and analysis don't mix.



From ligges at statistik.uni-dortmund.de  Fri May 23 17:19:46 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 23 May 2003 17:19:46 +0200
Subject: [R] predict.smooth.spline
In-Reply-To: <Pine.GSO.4.33.0305231543060.19395-100000@holyrood.ed.ac.uk>
References: <Pine.GSO.4.33.0305231543060.19395-100000@holyrood.ed.ac.uk>
Message-ID: <3ECE3C12.9000805@statistik.uni-dortmund.de>

iwhite at staffmail.ed.ac.uk wrote:
> I'm using R 1.7.0 on linux. With this version of R the package modreg is
> automatically loaded at start of session. However attempting to use
> predict.smooth.spline() produces Error: couldn't find function
> predict.smooth.spline.
> 
> The function smooth.spline() is OK. What am I missing?


Use the generic, predict().
predict.smooth.spline() is the method for class smooth.spline. Regularly 
you shoudn't call it directly.

Since modreg has a namespace, you don't see the method.
See, e.g., ?getS3method, if you are really going to get the method.

Uwe Ligges


> ======================================
> I.White
> ICAPB, University of Edinburgh
> Ashworth Laboratories, West Mains Road
> Edinburgh EH9 3JT
> Fax: 0131 650 6564  Tel: 0131 650 5490
> E-mail: iwhite at staffmail.ed.ac.uk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jfox at mcmaster.ca  Fri May 23 17:23:20 2003
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 23 May 2003 11:23:20 -0400
Subject: [R] predict.smooth.spline
In-Reply-To: <Pine.GSO.4.33.0305231543060.19395-100000@holyrood.ed.ac.uk
 >
Message-ID: <5.1.0.14.2.20030523112128.01ea52a8@mcmail.cis.mcmaster.ca>

Dear I. White,

The method function predict.smooth.spline isn't exported by the modreg 
package; you can use it via the generic predict() on an object of class 
smooth.spline.

I hope this helps,
  John

At 03:44 PM 5/23/2003 +0100, iwhite at staffmail.ed.ac.uk wrote:
>I'm using R 1.7.0 on linux. With this version of R the package modreg is
>automatically loaded at start of session. However attempting to use
>predict.smooth.spline() produces Error: couldn't find function
>predict.smooth.spline.
>
>The function smooth.spline() is OK. What am I missing?
>
>======================================
>I.White
>ICAPB, University of Edinburgh
>Ashworth Laboratories, West Mains Road
>Edinburgh EH9 3JT
>Fax: 0131 650 6564  Tel: 0131 650 5490
>E-mail: iwhite at staffmail.ed.ac.uk
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From ligges at statistik.uni-dortmund.de  Fri May 23 17:36:53 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 23 May 2003 17:36:53 +0200
Subject: [R] plot output function
In-Reply-To: <3ECE3685.53A110D4@york.ac.uk>
References: <3ECE3685.53A110D4@york.ac.uk>
Message-ID: <3ECE4015.1050701@statistik.uni-dortmund.de>

cp133 wrote:
> Hi,
> 
> I have written my own function to estimate a local linear regression.
> When I plot the output vector on the scatterplot of the data, the
> function lines does not work and I get a rescaled regression line. 
> When I plot the output vector alone, the graph looks right, but choosing
> the type "line" instead of the default does not deliver a clear single
> line.
> 
> Does somebody know why this is happening.
> 

Does abline() help?

If not, please be more specific in your question and tell us what you 
are exactly going to do.

Uwe Ligges



From heyer at mpimp-golm.mpg.de  Fri May 23 17:41:30 2003
From: heyer at mpimp-golm.mpg.de (Arnd G. Heyer)
Date: Fri, 23 May 2003 17:41:30 +0200
Subject: [R] Duncan's Multiple Range Test
Message-ID: <3ECE412A.40501@mpimp-golm.mpg.de>

Dear R Community,

I am desperately seeking a procedure for comparison of means other than 
TukeyHSD. Is anybody out there, who would be willing to implement 
Duncan's Multiple Range test or REGW into R?

With many thanks,
Arnd Heyer



From csillery at selway.umt.edu  Fri May 23 17:43:27 2003
From: csillery at selway.umt.edu (Katalin Csillery)
Date: Fri, 23 May 2003 09:43:27 -0600 (MDT)
Subject: [R] variance components
Message-ID: <Pine.OSF.4.21.0305230925000.1811-100000@selway.umt.edu>


Dear All,

I need to calculate the variance components in a mixed effect model (one
fixed and one random effect) with REML (maximizing the proportion of
the likelihood that does not depend on the fixed effects). In S+ there is
the varcomp function, but I would like to do it in R. Is there a way to do
that?

Thanks!
Katalin


___
Katalin Csillery
Division of Biological Sciences
University of Montana, Missoula MT 59801
Phone: 406 243 6106, E-mail: csillery at selway.umt.edu



From MSchwartz at medanalytics.com  Fri May 23 17:55:08 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 23 May 2003 15:55:08 -0000
Subject: Fw: [R] write.table only writes the first 256 variables/columns
In-Reply-To: <20030523160232.A3580@leslie.vet.gla.ac.uk>
References: <012701c32139$b932ea00$f2e1f380@OPENZAURUS>
	<20030523160232.A3580@leslie.vet.gla.ac.uk>
Message-ID: <1053705270.17055.91.camel@localhost>

You cannot increase the column/field limit in any of the MS Office
products.

At least for the desktop MS applications (and presumably for all ODBC
based driver interactions) there is a 255 column limit in the CREATE
TABLE SQL query as part of the ODBC limitations.

A reference is here:

http://msdn.microsoft.com/library/default.asp?url=/library/en-us/odbc/htm/odbcjetsdk_149.asp

The major changes in recent versions of Excel relative to sheet size was
to increase the number of rows, which in Excel XP (2002) is 65,536 rows
by 256 columns.

HTH,

Marc Schwartz


On Fri, 2003-05-23 at 10:02, Giles Innocent wrote:
> Excel only imports the first 256 columns as standard (not sure if you 
> can increase this).  I had a similar problem importing a database 
> recently - I just gave up using Excel, used R instead.
> 
> Giles
> 
> On 2003.05.23 15:43 Stuart Leask wrote:
> > Thanks. I was "believing" an Excel import of the file - as you say, a
> > re-import
> > into R still has 333 columns. I shall look elsewhere for the cause of
> > the
> > mysterious truncation.
> > 
> > Stuart
> > 
> > > ----- Original Message -----
> > > From: "Thomas Lumley" <tlumley at u.washington.edu>
> > > To: "Stuart Leask" <stuart.leask at nottingham.ac.uk>
> > > Cc: "R-Help" <r-help at stat.math.ethz.ch>
> > > Sent: Friday, May 23, 2003 2:50 PM
> > > Subject: Re: [R] write.table only writes the first 256
> > variables/columns
> > >
> > >
> > > > On Fri, 23 May 2003, Stuart Leask wrote:
> > > >
> > > > > Hi there.
> > > > > Using read.spss I can read in a file 333 columns, 280 lines, but
> > if I
> > > use
> > > > > write.table to export it, I only get 256 columns x 280 lines. I
> > can't
> > > find
> > > > > this feature documented anywhere...
> > > > >
> > > >
> > > > I can't replicate this:
> > > >
> > > > > foo<-matrix(rnorm(333*280), ncol=333, nrow=280)
> > > > > foo<-as.data.frame(foo)
> > > > > write.table(foo,"foo.txt")
> > > > > bar<-read.table("foo.txt",header=TRUE)
> > > > > dim(bar)
> > > > [1] 280 333
> > > > > all.equal(foo,bar)
> > > > [1] TRUE
> > > >
> > > > and I can't see why it would be true. Does this example work for
> > you?
> > > >  The largest SPSS file I have lying around has only 212 columns,
> > so I
> > > > can't test the read.spss aspect of it.
> > > >
> > > > -thomas
> > > >
> > >
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From tlumley at u.washington.edu  Fri May 23 17:56:29 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 23 May 2003 08:56:29 -0700 (PDT)
Subject: [R] Source code analysis for R ?
In-Reply-To: <20030523150306.GA29338@sonny.eddelbuettel.com>
Message-ID: <Pine.A41.4.44.0305230854270.17962-100000@homer26.u.washington.edu>

On Fri, 23 May 2003, Dirk Eddelbuettel wrote:

>
> A GUI-heavy R project of mine has mushroomed into well over 1000 lines of
> code. It is getting to a point where I am wondering if someone had something
> like a script to summarize which functions call which other etc.
>
> Note that I am not looking at profiling but rather a (static) analysis of
> code interdepence.  Does anybody here have anything for this task?
>

This seems to work as a starting point:
calls<-function(fn){
     if(length(fn)==1)
        return(character(0))
     else
        c(as.character(fn[[1]]),sapply(fn, calls),recursive=TRUE)
}

You use it like
 calls(body(update.formula))

             "{"             "<-"    "environment"     "as.formula"

            "<-"      ".Internal" "update.formula"     "as.formula"

    "as.formula"             "<-"        "formula"  "terms.formula"

            "<-"    "environment"         "return"

Unfortunately most of the calls are to <- in any given piece of code, but
it would be easy to trim these out.

Given the links you could then use GraphViz to draw the call graph.

	-thomas



From pfaffman at relaxpc.com  Fri May 23 17:58:33 2003
From: pfaffman at relaxpc.com (Jay Pfaffman)
Date: Fri, 23 May 2003 08:58:33 -0700
Subject: [R] Summary statistics & plots of repeated measures data
Message-ID: <200305231558.h4NFwXD28141@aaalab.stanford.edu>

I'm an R novice and my colleagues are about to convince me to get my
data into SPSS, which will presumably be easier for someone who
doesn't live in R to point and click his way into some kind of
analysis that might be meaningful.

I've got two groups of subjects (classkey in the table below).
They've each received several different treatments.  One measure is a
1-7 rating taken several times per treatment (about 1-14 times per
session).   studentkey, classkey, and treatment are factor()s.

The table looks something like this:

   ete classkey studentkey treatment
1    7        4        108       bp1
2    4        4        117       bp1
3    6        4        120       bp1
4    6        4        105       bp1
5    3        4        100       bp1
6    3        4        100       bp1
7    4        4        107       bp1
8    3        4        100       bp1
9    7        4        107       bp1
10   4        4        107       bp1

I'd like to see the effects of each of the treatments for this
within-subject comparison.  Repeated measures ANOVA seems like the
analysis I need.  The results of

summary(lme(ete ~ treatment, data=allitems, random=~1 | studentkey,
          subset=allitems$classkey==4))

follow, but I'm not quite sure what to make of them.  In particular,
I'm very confused about the meanings of the numbers in the Value
column, as they bear no relation to the group means of the data in
each of those treatments.

Linear mixed-effects model fit by REML
 Data: allitems 
  Subset: allitems$classkey == 4 
   AIC  BIC logLik
  2035 2065  -1011

Random effects:
 Formula: ~1 | studentkey
        (Intercept) Residual
StdDev:        1.39     1.58

Fixed effects: ete ~ treatment 
                Value Std.Error  DF t-value p-value
(Intercept)      5.44     0.322 493   16.90  <.0001
treatmentbp2    -0.80     0.204 493   -3.95   1e-04
treatmentbprog1 -1.84     0.214 493   -8.61  <.0001
treatmentbs1    -2.17     0.291 493   -7.44  <.0001
treatmentbs2    -1.31     0.221 493   -5.91  <.0001
 Correlation: 
                (Intr) trtmntbp2 trtmntbp1 trtmntbs1
treatmentbp2    -0.344                              
treatmentbprog1 -0.331  0.503                       
treatmentbs1    -0.239  0.385     0.342             
treatmentbs2    -0.327  0.514     0.467     0.352   

Standardized Within-Group Residuals:
   Min     Q1    Med     Q3    Max 
-2.888 -0.666  0.102  0.722  2.341 

Number of Observations: 521
Number of Groups: 24 
       
I'm clearly misunderstanding something.  This is very likely the type
of analysis I'll be doing for much of my career, I'd love to figure
out how to do it in R now.  (I've got  MASS3, & Dalgaard's Intro Stats
with R as well as various online documents.  Pointers to relevant
sections therein would also be appreciated.)

Thanks.

-- 
Jay Pfaffman                           pfaffman at relaxpc.com
+1-415-821-7507 (H)                    +1-415-812-5047 (M)



From cp133 at york.ac.uk  Fri May 23 18:03:35 2003
From: cp133 at york.ac.uk (cp133)
Date: Fri, 23 May 2003 17:03:35 +0100
Subject: [R] plot output function
References: <3ECE3685.53A110D4@york.ac.uk>
	<3ECE4015.1050701@statistik.uni-dortmund.de>
Message-ID: <3ECE4657.3A3B63F8@york.ac.uk>

no, I'm afraid abline does not help, it works only for straight lines.

The output of my function is a vector of fitted values (called fit).
I would like to superimpose the fitted regression line to the
scatterplot of the data. 
Therefore, I use the commands "plot(x,y)"to display the scatterplot;
then
"lines(x,fit)" to add the estimated regression line.
The graph displays the scatterplot correctly but not the fitted
regression line.
When I use the command "plot(x,fit)" I get the correct regression line
but the plot is very rough, it looks like that, instead of a single
clear line, I get several thin lines.

Hope this is clearer.

Thank you,

Chiara

Uwe Ligges wrote:
> 
> cp133 wrote:
> > Hi,
> >
> > I have written my own function to estimate a local linear regression.
> > When I plot the output vector on the scatterplot of the data, the
> > function lines does not work and I get a rescaled regression line.
> > When I plot the output vector alone, the graph looks right, but choosing
> > the type "line" instead of the default does not deliver a clear single
> > line.
> >
> > Does somebody know why this is happening.
> >
> 
> Does abline() help?
> 
> If not, please be more specific in your question and tell us what you
> are exactly going to do.
> 
> Uwe Ligges



From hb at maths.lth.se  Fri May 23 18:06:54 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Fri, 23 May 2003 18:06:54 +0200
Subject: [R] replaceMethod time and memory for very large object.
In-Reply-To: <DGEIIIMDDGKLGHFCOPOFOEIECCAA.laurent.buffat@it-omics.com>
Message-ID: <000801c32145$54652280$e502eb82@alpha.wehi.edu.au>

Hi Laurent, this is exactly the problem I had to when I was started to
work on microarray data. Your strategy works and it does indeed improve
the memory and time efficiency quite a bit. It is just a matter on what
granuality you want to emulate references, i.e. a matrix, a column of a
matrix or a single cell. I have stayed with a matrix and when I update
the matrix R (50000x20) in a quadruple of (R,G,Rb,Gb) it does help since
I do not have to pay the cost of having G, Rb and Gb coupled to the same
data structure.

FYI: Since 2001, I have developed the R.oo package
(http://www.maths.lth.se/help/R/R.classes/) based a similar idea to what
you are suggesting, i.e. use environments or similar functionalities to
emulate pointers and provide it in a reusable way. It implements some
extra features too, however not necessary in this context. Note also
that R.oo is more in the spirit of "a method belongs to a class" and not
"a method belongs to a generic function", which is the idea of R, but it
is not a restriction. At this moment R.oo is based on S4, but I intend
to upgrade to S4. My microarray package com.braju.sma is then making use
of R.oo wherever microarray structures are defined.

Best wishes

Henrik Bengtsson
Lund University

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of laurent buffat
> Sent: den 23 maj 2003 16:01
> To: r-help at stat.math.ethz.ch
> Subject: [R] replaceMethod time and memory for very large object.
> 
> 
> 
> Hi there,
> 
> First, please apologize, I'm not fluent in English.
> 
> I try to manipulate very large object with R, and I have some 
> problems with memory and time access, because of the < by 
> value mechanism >. I would like to < encapsulate > a large 
> vector in a class and access to the vector by method and 
> replaceMethod, but where is a lot of < implicit copy >, and 
> so, a lot of memory and time consuming.
> 
> The data are very large, and come from micro array experiment 
> (see http://Biocondutor.org for more detail of what is a 
> micro array ) , but a  typical > vector is a 20000 genes * 20 
> probes * 100 experiments * 2 (means and variance)
> 
> The best way, in term of speed and memory is to try to 
> emulate a < by reference > mechanism, but it's not very < in 
> the spirit of R > and a little < dangerous > (see the example).
> 
> Could you give me some recommendations ?
> 
> Thanks for your help.
> 
> The code below is a little < long >, sorry.
> 
> Laurent B.
> 
> ////////////////////////////
> 
> setClass("Foo", representation(v = "numeric"))
> 
> setMethod("initialize", signature("Foo"), function(.Object, 
> v=vector()) {
> 		.Object at v <- v
> 		.Object
> 	   })
> 
> 
> setGeneric("v", function(.Object) standardGeneric("v")) 
> setMethod("v", "Foo", function(.Object) .Object at v )
> 
> setGeneric("v<-",function(.Object,value) 
> standardGeneric("v<-")) setReplaceMethod("v", "Foo", 
> function(.Object, value) {
> 	.Object at v <- value
>          return(.Object)
>          })
> 
> setMethod("[","Foo", function(x,i,j=NA,...,drop=FALSE) x at v[i] )
> 
> setReplaceMethod("[","Foo",function(x,i,j=NA,...,value) {
> 	x at v[i] <- value
> 	x
> 	})
> 
> n <- 2000 * 20 * 100 * 2
> 
> # in fact I would like to have
> # 20000 genes * 20 mesures by genes (probes) * 100 
> experiences * 2 ( mean and variance) # but, it's to much 
> memory for these example, so just try with 2000 "genes".
> 
> x <- rep(1,n)
> # x, a non encapsuled vetor for the data "
> y <- new("Foo",v=x)
> # y, a encapsuled version".
> 
> 
> x[1] <- 2
> y at v[1] <- 2
> v(y)[1] <- 2
> y[1] <- 2
> 
> nt <- 10 # number of test
> 
> system.time(for(i in 1:nt) x[1] <- 2)
> system.time(for(i in 1:nt) y at v[1] <- 2)
> system.time(for(i in 1:nt) v(y)[1] <- 2)
> system.time(for(i in 1:nt) y[1] <- 2)
> 
> [1] 0 0 0 0 0
> [1]  7.80  3.17 10.97  0.00  0.00
> [1] 10.19  5.39 15.60  0.00  0.00
> [1]  9.00  4.54 13.55  0.00  0.00
> 
> x[1:2]
> y[1:2]
> v(y)[1:2]
> y at v[1:2]
> 
> system.time(for(i in 1:nt) x[1:2])
> system.time(for(i in 1:nt) y[1:2])
> system.time(for(i in 1:nt) v(y)[1:2])
> system.time(for(i in 1:nt) y at v[1:2])
> 
> 
> [1] 0 0 0 0 0
> [1] 0 0 0 0 0
> [1] 0 0 0 0 0
> [1] 0 0 0 0 0
> 
> # no problem for "acces method, only for replace method
> # Class FooPtr,
> # a way to try to by pass the "by value mecanizim of R" ...
> 
> setClass("FooPtr", representation(p = "environment"))
> 
> setMethod("initialize", signature("FooPtr"), 
> function(.Object, v=vector()) {
> 		.Object at p <- new("environment")
> 		assign("v",v,envir=.Object at p)
> 		.Object
> 	   })
> 
> setMethod("v", "FooPtr", function(.Object) get("v",envir=.Object at p) )
> 
> setReplaceMethod("v", "FooPtr",
>                    function(.Object, value) {
>                    assign("v",value,envir=.Object at p)
>                    return(.Object)
>                  })
> 
> setMethod("[","FooPtr", function(x,i,j=NA,...,drop=FALSE) 
> get("v",envir=x at p)[i] )
> 
> # a first version of "[<-" for FooPtr :
> 
> setReplaceMethod("[","FooPtr",function(x,i,j=NA,...,value)
> 	{
> 	v<- get("v",envir=x at p)
> 	v[i] <- value
> 	assign("v",v,envir=x at p)
> 	x
> 	})
> 
> z <- new("FooPtr",v=x)
> 
> x[1] <- 2
> v(z)[1] <- 2
> z[1] <- 2
> 
> 
> system.time(for(i in 1:nt) x[1] <- 2)
> system.time(for(i in 1:nt) v(z)[1] <- 2)
> system.time(for(i in 1:nt) z[1] <- 2)
> 
> [1] 0.01 0.00 0.01 0.00 0.00
> [1] 0 0 0 0 0
> [1] 1.63 1.18 2.81 0.00 0.00
> 
> # the v(z)[1] is "good", but not "[<-"
> # a more creasy way to try "by reference"
> 
> setReplaceMethod("[","FooPtr",function(x,i,j=NA,...,value)
> 	{
> 	assign("i",i,envir=x at p)
> 	assign("value",value,envir=x at p)
> 	eval(expression(v[i] <- value), envir=x at p)
> 	rm("i","value",envir=x at p)
> 	x
> 	})
> 
> system.time(for(i in 1:nt) x[1] <- 2)
> system.time(for(i in 1:nt) v(z)[1] <- 2)
> system.time(for(i in 1:nt) z[1] <- 2)
> 
> [1] 0 0 0 0 0
> [1] 0 0 0 0 0
> [1] 0.14 0.12 0.26 0.00 0.00
> 
> # "[<-" is better, but v(z)[] is the best ... (why ???)
> 
> 
> # ok, v(z)[i] is the "best" acess, but you need to know what you do :
> 
> v(z)[1] <- 12345
> z1 <- z
> v(z1)[1]
> 
> # z and z1 work with the same environment ...
> 
> //////////////////////
> 
> Thanks for your help.
> 
> Laurent
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> 
>



From spencer.graves at pdf.com  Fri May 23 18:15:05 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 23 May 2003 09:15:05 -0700
Subject: [R] variance components
References: <Pine.OSF.4.21.0305230925000.1811-100000@selway.umt.edu>
Message-ID: <3ECE4909.9060303@pdf.com>

Have you considered "lme" (documented especially in Pinhiero and Bates, 
Mixed Effects Models in S and S-Pus)?

hth.  spencer graves

Katalin Csillery wrote:
> Dear All,
> 
> I need to calculate the variance components in a mixed effect model (one
> fixed and one random effect) with REML (maximizing the proportion of
> the likelihood that does not depend on the fixed effects). In S+ there is
> the varcomp function, but I would like to do it in R. Is there a way to do
> that?
> 
> Thanks!
> Katalin
> 
> 
> ___
> Katalin Csillery
> Division of Biological Sciences
> University of Montana, Missoula MT 59801
> Phone: 406 243 6106, E-mail: csillery at selway.umt.edu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From maechler at stat.math.ethz.ch  Fri May 23 18:31:44 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 23 May 2003 18:31:44 +0200
Subject: [R] plot output function
In-Reply-To: <3ECE4657.3A3B63F8@york.ac.uk>
References: <3ECE3685.53A110D4@york.ac.uk>
	<3ECE4015.1050701@statistik.uni-dortmund.de>
	<3ECE4657.3A3B63F8@york.ac.uk>
Message-ID: <16078.19696.469243.498029@gargle.gargle.HOWL>

I guess you forgot that lines(x,y) , contrary to  plot(x,y)
needs  *increasing* (or decreasing) `x' to make sense in your
situation.

Hence use something like

plot(x,y)
fit <- yourcoolfunction(x,y, ...)
ix <- order(x)
lines(x[ix], fit[ix], col = 2)

HTH,
Martin

>>>>> "cp133" == cp133  <cp133 at york.ac.uk>
>>>>>     on Fri, 23 May 2003 17:03:35 +0100 writes:

    cp133> no, I'm afraid abline does not help, it works only
    cp133> for straight lines.  The output of my function is a
    cp133> vector of fitted values (called fit).  I would like
    cp133> to superimpose the fitted regression line to the
    cp133> scatterplot of the data.  Therefore, I use the
    cp133> commands "plot(x,y)"to display the scatterplot; then
    cp133> "lines(x,fit)" to add the estimated regression line.
    cp133> The graph displays the scatterplot correctly but not
    cp133> the fitted regression line.  When I use the command
    cp133> "plot(x,fit)" I get the correct regression line but
    cp133> the plot is very rough, it looks like that, instead
    cp133> of a single clear line, I get several thin lines.

    cp133> Hope this is clearer.

    cp133> Thank you,

    cp133> Chiara

    cp133> Uwe Ligges wrote:
    >>  cp133 wrote: > Hi,
    >> >
    >> > I have written my own function to estimate a local
    >> linear regression.  > When I plot the output vector on
    >> the scatterplot of the data, the > function lines does
    >> not work and I get a rescaled regression line.  > When I
    >> plot the output vector alone, the graph looks right, but
    >> choosing > the type "line" instead of the default does
    >> not deliver a clear single > line.
    >> >
    >> > Does somebody know why this is happening.
    >> >
    >> 
    >> Does abline() help?
    >> 
    >> If not, please be more specific in your question and tell
    >> us what you are exactly going to do.
    >> 
    >> Uwe Ligges



From Roger.Bivand at nhh.no  Fri May 23 18:32:46 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 23 May 2003 18:32:46 +0200 (CEST)
Subject: [R] plot output function
In-Reply-To: <3ECE4657.3A3B63F8@york.ac.uk>
Message-ID: <Pine.LNX.4.44.0305231830020.19270-100000@reclus.nhh.no>

On Fri, 23 May 2003, cp133 wrote:

> no, I'm afraid abline does not help, it works only for straight lines.
> 
> The output of my function is a vector of fitted values (called fit).
> I would like to superimpose the fitted regression line to the
> scatterplot of the data. 
> Therefore, I use the commands "plot(x,y)"to display the scatterplot;
> then
> "lines(x,fit)" to add the estimated regression line.
> The graph displays the scatterplot correctly but not the fitted
> regression line.
> When I use the command "plot(x,fit)" I get the correct regression line
> but the plot is very rough, it looks like that, instead of a single
> clear line, I get several thin lines.
> 

Please make sure the x are in increasing order, and the fit vector 
re-ordered to match, something like:

o <- order(x)
lines(x[o], fit[o])

I think the line is zigzagging backwards and forwards along the x vector.

> Hope this is clearer.
> 
> Thank you,
> 
> Chiara
> 
> Uwe Ligges wrote:
> > 
> > cp133 wrote:
> > > Hi,
> > >
> > > I have written my own function to estimate a local linear regression.
> > > When I plot the output vector on the scatterplot of the data, the
> > > function lines does not work and I get a rescaled regression line.
> > > When I plot the output vector alone, the graph looks right, but choosing
> > > the type "line" instead of the default does not deliver a clear single
> > > line.
> > >
> > > Does somebody know why this is happening.
> > >
> > 
> > Does abline() help?
> > 
> > If not, please be more specific in your question and tell us what you
> > are exactly going to do.
> > 
> > Uwe Ligges
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From anna at ptolemy.arc.nasa.gov  Fri May 23 19:41:57 2003
From: anna at ptolemy.arc.nasa.gov (Anna  H. Pryor)
Date: Fri, 23 May 2003 10:41:57 -0700
Subject: [R] calling files of commands in R
Message-ID: <200305231041.57785.anna@ptolemy.arc.nasa.gov>


Please excuse me if this is a very basic question and I am just 
misunderstanding the basic structure of R.

Right now, I am writing everything in a buffer (emacs) and then copying it 
into R when it is correct.  Is there a way to save a file of commands and 
then just type the file name or something in R and have the commands executed 
within R?

Anna



From jerome at hivnet.ubc.ca  Fri May 23 19:53:32 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Fri, 23 May 2003 10:53:32 -0700
Subject: [R] calling files of commands in R
In-Reply-To: <200305231041.57785.anna@ptolemy.arc.nasa.gov>
References: <200305231041.57785.anna@ptolemy.arc.nasa.gov>
Message-ID: <200305231759.KAA00577@hivnet.ubc.ca>


See ?source.

On May 23, 2003 10:41 am, Anna  H. Pryor wrote:
> Please excuse me if this is a very basic question and I am just
> misunderstanding the basic structure of R.
>
> Right now, I am writing everything in a buffer (emacs) and then copying
> it into R when it is correct.  Is there a way to save a file of commands
> and then just type the file name or something in R and have the commands
> executed within R?
>
> Anna
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From rossini at blindglobe.net  Fri May 23 19:54:28 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Fri, 23 May 2003 10:54:28 -0700
Subject: [R] calling files of commands in R
In-Reply-To: <200305231041.57785.anna@ptolemy.arc.nasa.gov> ("Anna  H.
	Pryor"'s message of "Fri, 23 May 2003 10:41:57 -0700")
References: <200305231041.57785.anna@ptolemy.arc.nasa.gov>
Message-ID: <87wugh1rcb.fsf@jeeves.blindglobe.net>

"Anna  H. Pryor" <anna at ptolemy.arc.nasa.gov> writes:

> Please excuse me if this is a very basic question and I am just 
> misunderstanding the basic structure of R.
>
> Right now, I am writing everything in a buffer (emacs) and then copying it 
> into R when it is correct.  Is there a way to save a file of commands and 
> then just type the file name or something in R and have the commands executed 
> within R?

source("filename")



-- 
A.J. Rossini rossini at u.washington.edu http://software.biostat.washington.edu/ 
Biostatistics, U Washington and Fred Hutchinson Cancer Research Center

FHCRC:Tu: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email 
UW  : Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX 

CONFIDENTIALITY NOTICE: This e-mail message and any attachments ... {{dropped}}



From dmurdoch at pair.com  Fri May 23 20:08:48 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Fri, 23 May 2003 14:08:48 -0400
Subject: [R] calling files of commands in R
In-Reply-To: <200305231759.KAA00577@hivnet.ubc.ca>
References: <200305231041.57785.anna@ptolemy.arc.nasa.gov>
	<200305231759.KAA00577@hivnet.ubc.ca>
Message-ID: <froscvcd1r74k1qmj11ad2eckbmree6enf@4ax.com>

On Fri, 23 May 2003 10:53:32 -0700, Jerome Asselin wrote:

>
>See ?source.

You'll also save typing if you use setwd() to get to the same working
directory as your source, first.

Duncan Murdoch



From p.dalgaard at biostat.ku.dk  Sat May 24 01:03:26 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri, 23 May 2003 23:03:26 -0000
Subject: [R] Summary statistics & plots of repeated measures data
In-Reply-To: <200305231558.h4NFwXD28141@aaalab.stanford.edu>
References: <200305231558.h4NFwXD28141@aaalab.stanford.edu>
Message-ID: <x2adddb6q0.fsf@biostat.ku.dk>

Jay Pfaffman <pfaffman at relaxpc.com> writes:

> I'd like to see the effects of each of the treatments for this
> within-subject comparison.  Repeated measures ANOVA seems like the
> analysis I need.  The results of
> 
> summary(lme(ete ~ treatment, data=allitems, random=~1 | studentkey,
>           subset=allitems$classkey==4))
> 
> follow, but I'm not quite sure what to make of them.  In particular,
> I'm very confused about the meanings of the numbers in the Value
> column, as they bear no relation to the group means of the data in
> each of those treatments.

They're not supposed to. Not in an unbalanced design. Mostly, if there
is a substantial variation between students, the results would be
closer to that obtained from an additive linear model treating student
effects as fixed (lm(ete ~ treatment+factor(studentkey), ...)). The
treatment means is what you get if you assume zero student variation,
and in general you get some sort of average between the two.

You'll bump into those issues whatever program you choose...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ozric at web.de  Sat May 24 01:21:22 2003
From: ozric at web.de (Christian Schulz)
Date: Sat, 24 May 2003 01:21:22 +0200
Subject: [R] calling files of commands in R
References: <200305231041.57785.anna@ptolemy.arc.nasa.gov>
Message-ID: <004401c32182$0668ea70$d200a8c0@pc>

When you using windows, imho
R-Winedt supports you very nice
to archive your code and  especially for
me - working with  "some line code snippets".

http://cran.r-project.org/contrib/extra/winedt/

christian


----- Original Message -----
From: "Anna H. Pryor" <anna at ptolemy.arc.nasa.gov>
To: <r-help at stat.math.ethz.ch>
Sent: Friday, May 23, 2003 7:41 PM
Subject: [R] calling files of commands in R


>
> Please excuse me if this is a very basic question and I am just
> misunderstanding the basic structure of R.
>
> Right now, I am writing everything in a buffer (emacs) and then copying it
> into R when it is correct.  Is there a way to save a file of commands and
> then just type the file name or something in R and have the commands
executed
> within R?
>
> Anna
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From pierremallard at yahoo.fr  Sat May 24 14:23:43 2003
From: pierremallard at yahoo.fr (=?iso-8859-1?q?Pierre=20Mallard?=)
Date: Sat, 24 May 2003 14:23:43 +0200 (CEST)
Subject: [R] ...listable functions...
Message-ID: <20030524122343.36892.qmail@web20301.mail.yahoo.com>

Hi R-helpers.
I have the following problem:
I would like to apply my function gain(df,X,A) to a
list of arguments.
df is a data frame
X,A are the varibales od data frame.
When I do
> gain(kyphosis,"Kyphosis",c("Start","Number"))
[1] "Start"  "Number"
I get the following error...
Error in unique.default(x) : unique() applies only to
vectors
I tried lapply and apply, it didn't seem to work...

Can anybody tell me how to apply my function gain to a
list of argument(in this case, my third argument
changes)...
Thanks in advance,
pierre



From ligges at statistik.uni-dortmund.de  Sat May 24 14:31:22 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 24 May 2003 14:31:22 +0200
Subject: [R] ...listable functions...
In-Reply-To: <20030524122343.36892.qmail@web20301.mail.yahoo.com>
References: <20030524122343.36892.qmail@web20301.mail.yahoo.com>
Message-ID: <3ECF661A.1050504@statistik.uni-dortmund.de>

Pierre Mallard wrote:
> Hi R-helpers.
> I have the following problem:
> I would like to apply my function gain(df,X,A) to a
> list of arguments.
> df is a data frame
> X,A are the varibales od data frame.
> When I do
> 
>>gain(kyphosis,"Kyphosis",c("Start","Number"))
> 
> [1] "Start"  "Number"
> I get the following error...
> Error in unique.default(x) : unique() applies only to
> vectors
> I tried lapply and apply, it didn't seem to work...
> 
> Can anybody tell me how to apply my function gain to a
> list of argument(in this case, my third argument
> changes)...
> Thanks in advance,
> pierre
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

  lapply(c("Start", "Number"), function(x) gain(kyphosis, "Kyphosis", x))

Uwe Ligges



From mitsu5 at ruby.famille.ne.jp  Sat May 24 15:53:38 2003
From: mitsu5 at ruby.famille.ne.jp (Mitsuo Igarashi)
Date: Sat, 24 May 2003 22:53:38 +0900
Subject: [R] Can Package SEM do mean structural analysis?
Message-ID: <200305241353.h4ODrik2014599@mp2.vectant.ne.jp>

Hi.

I am wondering whether Package SEM can do with intercepts and 
means in its structural analysis.

If it can not calculate, how can I make a supplemental function 
in R?

Many thanks in advance.

--------========----------
Mitsuo Igarashi
mitsu5 at ruby.famille.ne.jp



From jfox at mcmaster.ca  Sat May 24 16:42:20 2003
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 24 May 2003 10:42:20 -0400
Subject: [R] Can Package SEM do mean structural analysis?
In-Reply-To: <200305241353.h4ODrik2014599@mp2.vectant.ne.jp>
Message-ID: <5.1.0.14.2.20030524103328.01e9e310@mcmail.cis.mcmaster.ca>

Dear Mitsuo,

My intention in writing the sem package was to provide a basic 
structural-equation facility for R. I haven't made explicit provision for 
models with means, but it might be possible to fit such models by using the 
raw sums-of-squares-and-products matrix among the observed variables 
(perhaps divided by n) as input.  It might be necessary to make small 
modifications to degrees of freedom, etc.

I'm afraid that I don't have time now to figure out whether this will work 
and, if so, precisely how to do it, but you're welcome to try. If you get 
it to work, I'd be interested in the answer. If this approach doesn't work, 
then incorporating means would likely require major modifications to the 
program.

There are, by the way, several other things that dedicated 
structural-equation software does that the sem package does not -- e.g., 
analysis by groups and for ordinal observed variables. I may, at some 
point, extend the package in these directions, but I don't have plans at 
the moment to do so.

Good luck,
  John

At 10:53 PM 5/24/2003 +0900, you wrote:

>I am wondering whether Package SEM can do with intercepts and
>means in its structural analysis.
>
>If it can not calculate, how can I make a supplemental function
>in R?

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From ltorgo at liacc.up.pt  Sat May 24 18:48:57 2003
From: ltorgo at liacc.up.pt (Luis Torgo)
Date: Sat, 24 May 2003 16:48:57 +0000
Subject: [R] predicting fuzzy cluster membership
Message-ID: <200305241648.57524.ltorgo@liacc.up.pt>

Dear all,
I'm trying to obtain a fuzzy clustering with fanny from the cluster package, 
using a given set of data. That worked just fine.
I have another separate sample of data from the same problem. For each case in 
this new sample I would like to know their membership coefficients with 
respect to the clustering obtained with the first dataset. In effect I want 
to have a kind of prediction of the probability that each case in the new set 
belongs to each of the clusters formed with the first set of data. I do not 
want to add the second ssample to the first and build a new clustering 
because that would change the initial clustering.

I've looked in the help pages of the cluster package for some similar example 
with no success. I've also searched the R mailing list but didn't find any 
related question.

Is there any easy way of obtaining this matrix of cluster membership values 
for the new set of data?

Thank you in advance,
Luis

> R.version
         _                
platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    6.1              
year     2002             
month    11               
day      01               
language R      

-- 
Luis Torgo
    FEP/LIACC, University of Porto   Phone : (+351) 22 607 88 30
    Machine Learning Group           Fax   : (+351) 22 600 36 54
    R. Campo Alegre, 823             email : ltorgo at liacc.up.pt
    4150 PORTO   -  PORTUGAL         WWW   : http://www.liacc.up.pt/~ltorgo



From ripley at stats.ox.ac.uk  Sat May 24 18:08:14 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 24 May 2003 17:08:14 +0100 (BST)
Subject: [R] predicting fuzzy cluster membership
In-Reply-To: <200305241648.57524.ltorgo@liacc.up.pt>
Message-ID: <Pine.LNX.4.44.0305241651020.5351-100000@gannet.stats>

That's not how conventional clustering works: you need to understand the 
underlying principles (and for fanny, the main reference).  The goal is to 
place a given set of objects into clusters (overlapping clusters for 
fanny).  It is not to assign a future object to a cluster: that's a 
completely different, supervised, pattern recognition problem, and you 
should be using very different methods (given in different books, even).
Only for a few methods are there closely related prediction methods (e.g. 
1nn on cluster centres for k-means, mda for emclust).

On Sat, 24 May 2003, Luis Torgo wrote:

> I'm trying to obtain a fuzzy clustering with fanny from the cluster package, 
> using a given set of data. That worked just fine.
> I have another separate sample of data from the same problem. For each case in 
> this new sample I would like to know their membership coefficients with 
> respect to the clustering obtained with the first dataset. In effect I want 
> to have a kind of prediction of the probability that each case in the new set 
> belongs to each of the clusters formed with the first set of data. I do not 
> want to add the second ssample to the first and build a new clustering 
> because that would change the initial clustering.
> 
> I've looked in the help pages of the cluster package for some similar example 
> with no success. I've also searched the R mailing list but didn't find any 
> related question.

But it's a question on (lack of) understanding of statistics, and your 
best avenue is to seek expert local statistical help.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From pierremallard at yahoo.fr  Sat May 24 20:22:11 2003
From: pierremallard at yahoo.fr (=?iso-8859-1?q?Pierre=20Mallard?=)
Date: Sat, 24 May 2003 20:22:11 +0200 (CEST)
Subject: [R] ...listable functions...
In-Reply-To: <3ECF661A.1050504@statistik.uni-dortmund.de>
Message-ID: <20030524182211.13471.qmail@web20303.mail.yahoo.com>

 --- Uwe Ligges <ligges at statistik.uni-dortmund.de> a
?crit?: > Pierre Mallard wrote:
> > Hi R-helpers.
> > I have the following problem:
> > I would like to apply my function gain(df,X,A) to
> a
> > list of arguments.
> > df is a data frame
> > X,A are the varibales od data frame.
> > When I do
> > 
> >>gain(kyphosis,"Kyphosis",c("Start","Number"))
> > 
> > [1] "Start"  "Number"
> > I get the following error...
> > Error in unique.default(x) : unique() applies only
> to
> > vectors
> > I tried lapply and apply, it didn't seem to
> work...
> > 
> > Can anybody tell me how to apply my function gain
> to a
> > list of argument(in this case, my third argument
> > changes)...
> > Thanks in advance,
> > pierre
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> >
>
https://www.stat.math.ethz.ch/mailman/listinfo/r-help

Thanks a lot...it works now,
although I had to change it to
 lapply(list("Start", "Number"), function(x)
 gain(kyphosis, "Kyphosis", x))
because he was understanding as if it were the
isolated values...
best regards,
pierre
> 
>   lapply(c("Start", "Number"), function(x)
> gain(kyphosis, "Kyphosis", x))
> 
> Uwe Ligges
>



From pierremallard at yahoo.fr  Sat May 24 20:46:21 2003
From: pierremallard at yahoo.fr (=?iso-8859-1?q?Pierre=20Mallard?=)
Date: Sat, 24 May 2003 20:46:21 +0200 (CEST)
Subject: [R] ...listable functions...
In-Reply-To: <3ECF661A.1050504@statistik.uni-dortmund.de>
Message-ID: <20030524184621.47514.qmail@web20308.mail.yahoo.com>

 --- Uwe Ligges <ligges at statistik.uni-dortmund.de> a
?crit?: > Pierre Mallard wrote:
> > Hi R-helpers.
> > I have the following problem:
> > I would like to apply my function gain(df,X,A) to
> a
> > list of arguments.
> > df is a data frame
> > X,A are the varibales od data frame.
> > When I do
> > 
> >>gain(kyphosis,"Kyphosis",c("Start","Number"))
> > 
> > [1] "Start"  "Number"
> > I get the following error...
> > Error in unique.default(x) : unique() applies only
> to
> > vectors
> > I tried lapply and apply, it didn't seem to
> work...
> > 
> > Can anybody tell me how to apply my function gain
> to a
> > list of argument(in this case, my third argument
> > changes)...
> > Thanks in advance,
> > pierre
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> >
>
https://www.stat.math.ethz.ch/mailman/listinfo/r-help

Thanks a lot...it works now,
although I had to change it to
 lapply(list("Start", "Number"), function(x)
 gain(kyphosis, "Kyphosis", x))
because he was understanding as if it were the
isolated values...
best regards,
pierre
> 
>   lapply(c("Start", "Number"), function(x)
> gain(kyphosis, "Kyphosis", x))
> 
> Uwe Ligges
>



From Ted.Harding at nessie.mcc.ac.uk  Sat May 24 21:30:21 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sat, 24 May 2003 20:30:21 +0100 (BST)
Subject: [R] help output paged in separate window
Message-ID: <XFMail.030524203021.Ted.Harding@nessie.mcc.ac.uk>

Hi folks,

I use R in X windows on Linux.

Normally, I use 'less' as pager, which is fine for scanning through
'help' (or '?') output in the R window itself; the help session is
terminated by typing "q", as usual for 'less', and the R window then
reverts to the R command line interface.

Often, I would like to have the output from 'help' pop up in a separate
window so that I can continue to work in the R window while reading the
help. The "help" window could then be closed when interest in this
particular help dwindles.

What can I set $PAGER to, to achieve this? Or should it be done in a
different way (e.g. using some option to 'help' or to 'file.show')?

(I don't want to use 'help.start' because of the overhead of using
an HTML browser)

With thanks, and best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 24-May-03                                       Time: 20:30:21
------------------------------ XFMail ------------------------------



From chrysopa at insecta.ufv.br  Sat May 24 22:14:37 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Sat, 24 May 2003 17:14:37 -0300
Subject: [R] help with xyplot
Message-ID: <20030524201213.M24183@insecta.ufv.br>

Hi, 
 
I make a graphic using xyplot, it is very good. 
 
xyplot((ocorrencia/isca)~frag|especie) 
 
But I need to plot a curve for each especie's plot. 
 
I try to use panel.abline and others panel., but I dont succeed. 
 
I need to plot the function exp(a+b*x+c*x^2)/1+exp(a+b*x+c*x^2), a b and c 
are different for each especie.  
 
Normally I use the curve function to add a curve in a points graphics, but it 
dont work with xyplot. 
 
Anybody have any idea? 
 
Thanks 
Ronaldo 
 
-- 
|   //|\\   [*****************************] 
|| ( ? ? )  [Ronaldo Reis J?nior          ] 
|     V     [ESALQ/USP-Entomologia, CP-09 ] 
||  / l \   [13418-900 Piracicaba - SP    ] 
|  /(lin)\  [Fone: 19-429-4199 r.229      ] 
||/(linux)\ [chrysopa at insecta.ufv.br      ] 
|/ (linux) \[ICQ#: 5692561                ] 
||  ( x )   [*****************************] 
||| _/ \_ Powered by Gnu/Debian Woody 
-----------------------------------
Insecta - Entomologia
Departamento de Biologia Animal
Universidade Federal de Vi?osa



From deepayan at stat.wisc.edu  Sat May 24 22:58:56 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Sat, 24 May 2003 15:58:56 -0500
Subject: [R] help with xyplot
In-Reply-To: <20030524201213.M24183@insecta.ufv.br>
References: <20030524201213.M24183@insecta.ufv.br>
Message-ID: <200305241558.56431.deepayan@stat.wisc.edu>

On Saturday 24 May 2003 15:14, Ronaldo Reis Jr. wrote:
> Hi,
>
> I make a graphic using xyplot, it is very good.
>
> xyplot((ocorrencia/isca)~frag|especie)
>
> But I need to plot a curve for each especie's plot.
>
> I try to use panel.abline and others panel., but I dont succeed.
>
> I need to plot the function exp(a+b*x+c*x^2)/1+exp(a+b*x+c*x^2), a b and c
> are different for each especie.
>
> Normally I use the curve function to add a curve in a points graphics, but
> it dont work with xyplot.

Here's a version of curve modified to work with lattice:

lcurve <-
    function (expr, from, to, n = 101, curve.type = "l",
              col = add.line$col, lty = add.line$lty,
              lwd = add.line$lwd, type = NULL,
              ...)
{
    add.line <- trellis.par.get("add.line")
    sexpr <- substitute(expr)
    if (is.name(sexpr)) {
        fcall <- paste(sexpr, "(x)")
        expr <- parse(text = fcall)
    }
    else {
        if (!(is.call(sexpr) && match("x", all.vars(sexpr), nomatch = 0))) 
            stop("'expr' must be a function or an expression containing 'x'")
        expr <- sexpr
    }
    lims <- current.viewport()$xscale
    if (missing(from)) 
        from <- lims[1]
    if (missing(to)) 
        to <- lims[2]
    x <- seq(from, to, length = n)
    y <- eval(expr, envir = list(x = x), enclos = parent.frame())
    llines(x, y, type = curve.type, col = col, lty = lty, lwd = lwd, ...)
}


With this defined, you can do something like 


xyplot((ocorrencia/isca)~frag|especie, 
       panel = function(x, y, ...) {
           panel.xyplot(x, y, ...)
           ## calculate a, b, c based on x and y
           lcurve(exp(a+b*x+c*x^2)/1+exp(a+b*x+c*x^2), ...)
       })


I will add a lcurve() similar to this for the next release of lattice.

Deepayan



From pingzhao at waffle.cs.dal.ca  Sun May 25 03:03:51 2003
From: pingzhao at waffle.cs.dal.ca (pingzhao)
Date: Sat, 24 May 2003 22:03:51 -0300
Subject: [R] Problem in installing R add-on package(not from CRAN)
Message-ID: <3F121BF1@webmail.ucis.dal.ca>

Hi all,

I downloaded a R package (supclust, not from CRAN) in my directory, then type:

markov:/home/pingzhao> R CMD INSTALL supclust_1.1.tar.gz -l ~/lib

but met the following errors

* Installing *source* package 'supclust' ...
** libs
/usr/local/lib/R/bin/SHLIB: make: not found
ERROR: compilation failed for package 'supclust'


Does it mean the R has not properly installed? what are problems here???

Thanks,

Pingzhao



From edd at debian.org  Sun May 25 03:21:46 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 24 May 2003 20:21:46 -0500
Subject: [R] Problem in installing R add-on package(not from CRAN)
In-Reply-To: <3F121BF1@webmail.ucis.dal.ca>
References: <3F121BF1@webmail.ucis.dal.ca>
Message-ID: <20030525012145.GA4115@sonny.eddelbuettel.com>

On Sat, May 24, 2003 at 10:03:51PM -0300, pingzhao wrote:
> Hi all,
> 
> I downloaded a R package (supclust, not from CRAN) in my directory, then type:
> 
> markov:/home/pingzhao> R CMD INSTALL supclust_1.1.tar.gz -l ~/lib
> 
> but met the following errors
> 
> * Installing *source* package 'supclust' ...
> ** libs
> /usr/local/lib/R/bin/SHLIB: make: not found
                              ^^^^^^^^^^^^^^^
> ERROR: compilation failed for package 'supclust'
> 
> 
> Does it mean the R has not properly installed? what are problems here???

You don't have the required build tools, in this case make.

Did you build R on that machine, or was a pre-built binary installed?

Dirk

-- 
Don't drink and derive. Alcohol and analysis don't mix.



From dmurdoch at pair.com  Sun May 25 03:39:03 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sat, 24 May 2003 21:39:03 -0400
Subject: [R] Problem in installing R add-on package(not from CRAN)
In-Reply-To: <3F121BF1@webmail.ucis.dal.ca>
References: <3F121BF1@webmail.ucis.dal.ca>
Message-ID: <9k70dvs929l43mqq6tgd40co5chgfh1dq8@4ax.com>

On Sat, 24 May 2003 22:03:51 -0300, you wrote:

>Hi all,
>
>I downloaded a R package (supclust, not from CRAN) in my directory, then type:
>
>markov:/home/pingzhao> R CMD INSTALL supclust_1.1.tar.gz -l ~/lib
>
>but met the following errors
>
>* Installing *source* package 'supclust' ...
>** libs
>/usr/local/lib/R/bin/SHLIB: make: not found
>ERROR: compilation failed for package 'supclust'

It's saying that the "make" command was not found.  You need standard
development tools to install source packages.

Duncan Murdoch



From pingzhao at waffle.cs.dal.ca  Sun May 25 04:29:16 2003
From: pingzhao at waffle.cs.dal.ca (pingzhao)
Date: Sat, 24 May 2003 23:29:16 -0300
Subject: [R] Problem in installing R add-on package(not from CRAN)
Message-ID: <3F1233A7@webmail.ucis.dal.ca>

Hi all,
The R was installed by system adminstrator. Here
make is used to compile C code, right?, but the compile tools
C, C++,etc. are there. Could any one give me somes hints on
how to fix this problems?
Thanks!!!

>===== Original Message From 	Dirk Eddelbuettel <edd at debian.org> =====
>On Sat, May 24, 2003 at 10:03:51PM -0300, pingzhao wrote:
>> Hi all,
>>
>> I downloaded a R package (supclust, not from CRAN) in my directory, then 
type:
>>
>> markov:/home/pingzhao> R CMD INSTALL supclust_1.1.tar.gz -l ~/lib
>>
>> but met the following errors
>>
>> * Installing *source* package 'supclust' ...
>> ** libs
>> /usr/local/lib/R/bin/SHLIB: make: not found
>                              ^^^^^^^^^^^^^^^
>> ERROR: compilation failed for package 'supclust'
>>
>>
>> Does it mean the R has not properly installed? what are problems here???
>
>You don't have the required build tools, in this case make.
>
>Did you build R on that machine, or was a pre-built binary installed?
>
>Dirk
>
>--
>Don't drink and derive. Alcohol and analysis don't mix.



From mitsu5 at ruby.famille.ne.jp  Sun May 25 07:03:42 2003
From: mitsu5 at ruby.famille.ne.jp (Mitsuo Igarashi)
Date: Sun, 25 May 2003 14:03:42 +0900
Subject: [R] Can Package SEM do mean structural analysis?
In-Reply-To: <5.1.0.14.2.20030524103328.01e9e310@mcmail.cis.mcmaster.ca>
References: <5.1.0.14.2.20030524103328.01e9e310@mcmail.cis.mcmaster.ca>
Message-ID: <200305250503.h4P53lk2029203@mp2.vectant.ne.jp>

Dear John:

Thank you very much for your prompt explanation on the 
present possibilities of SEM.

I am not a statistician so that I can not figure out the raw sums-of-squares-and-products matrix.
And I will do with SEM in the area without mean structural 
equation.

I appreciate your good teaching at every time.
--------========----------
Mitsuo Igarashi
mitsu5 at ruby.famille.ne.jp
----------------

John Fox <jfox at mcmaster.ca> wrote:

> Dear Mitsuo,
> 
> My intention in writing the sem package was to provide a basic 
> structural-equation facility for R. I haven't made explicit provision for 
> models with means, but it might be possible to fit such models by using the 
> raw sums-of-squares-and-products matrix among the observed variables 
> (perhaps divided by n) as input.  It might be necessary to make small 
> modifications to degrees of freedom, etc.
> 
> I'm afraid that I don't have time now to figure out whether this will work 
> and, if so, precisely how to do it, but you're welcome to try. If you get 
> it to work, I'd be interested in the answer. If this approach doesn't work, 
> then incorporating means would likely require major modifications to the 
> program.
> 
> There are, by the way, several other things that dedicated 
> structural-equation software does that the sem package does not -- e.g., 
> analysis by groups and for ordinal observed variables. I may, at some 
> point, extend the package in these directions, but I don't have plans at 
> the moment to do so.
> 
> Good luck,
>   John
> 
> At 10:53 PM 5/24/2003 +0900, you wrote:
> 
> >I am wondering whether Package SEM can do with intercepts and
> >means in its structural analysis.
> >
> >If it can not calculate, how can I make a supplemental function
> >in R?



From eairoldi at stat.cmu.edu  Sun May 25 07:15:50 2003
From: eairoldi at stat.cmu.edu (Edoardo M Airoldi)
Date: Sun, 25 May 2003 01:15:50 -0400 (EDT)
Subject: [R] LDA once again
Message-ID: <Pine.LNX.4.44.0305250045550.7781-100000@hydra8.stat.cmu.edu>

hi there,
 i have one more question about LDA.  just to make surei understand,
suppose we have two classes, then if i specify a prior=c(.3,.7) in
lda(...) this will affect my between classes covariance matrix as in:

 SB = (.3*m1 - .7*m2) %*% inv(Sigma) %*% t(.3*m1 - .7*m2)

 [is Sigma affected ?] and the threshold to decide which class to assign
'test' data = log(.3/.7)

 if i specify a prior=c(.2,.8) in predict(...), but not in lda(...)  then
SB will not be affected, but and the threshold to decide which class to
assign to my 'test' data will be at log(.8/.2)


                        --- --- --- manual --- --- ---
Details:

     The function tries hard to detect if the within-class covariance
     matrix is singular. If any variable has within-group variance less
     than `tol^2' it will stop and report the variable as constant. 
     This could result from poor scaling of the problem, but is more
     likely to result from constant variables.

     Specifying the `prior' will affect the classification unless
     over-ridden in `predict.lda'. Unlike in most statistical packages,
     it will also affect the rotation of the linear discriminants
     within their space, as a weighted between-groups covariance matrix
     is used. Thus the first few linear discriminants emphasize the
     differences between groups with the weights given by the prior,
     which may differ from their prevalence in the dataset.



From blopes at email.unc.edu  Sun May 25 09:02:18 2003
From: blopes at email.unc.edu (Brian J. Lopes)
Date: Sun, 25 May 2003 03:02:18 -0400
Subject: [R] assign() won't work
Message-ID: <001001c3228b$ad6016a0$f34893ac@lopeylaptop>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030525/ab760bad/attachment.pl

From ripley at stats.ox.ac.uk  Sun May 25 09:38:14 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 25 May 2003 08:38:14 +0100 (BST)
Subject: [R] LDA once again
In-Reply-To: <Pine.LNX.4.44.0305250045550.7781-100000@hydra8.stat.cmu.edu>
Message-ID: <Pine.LNX.4.44.0305250825210.21383-100000@gannet.stats>

Do read the reference: MASS (the book), *and* the code.  Your question is 
addressed in the primary reference for the function, with references to 
the original papers.

On Sun, 25 May 2003, Edoardo M Airoldi wrote:

>  i have one more question about LDA.  just to make surei understand,
> suppose we have two classes, then if i specify a prior=c(.3,.7) in
> lda(...) this will affect my between classes covariance matrix as in:
> 
>  SB = (.3*m1 - .7*m2) %*% inv(Sigma) %*% t(.3*m1 - .7*m2)
> 
>  [is Sigma affected ?] and the threshold to decide which class to assign
> 'test' data = log(.3/.7)

Sigma is undefined!  That symbol is normally used to indicate the 
*population* within-class covariance matrix.  But no, you do not seem to 
understand, so please consult your local statistical experts (since you 
seem inexplicably loath to read our book).

Overview for well-informed readers:  the `Fisher' view of LDA has no
priors: the Rao and Bryan views do, and they differ.  In practice it only
matters if LDA is used when the within-class covariances are not common
but the conventional theory assumes the model is correct.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sun May 25 09:53:10 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 25 May 2003 08:53:10 +0100 (BST)
Subject: [R] Problem in installing R add-on package(not from CRAN)
In-Reply-To: <3F1233A7@webmail.ucis.dal.ca>
Message-ID: <Pine.LNX.4.44.0305250847050.21383-100000@gannet.stats>

On Sat, 24 May 2003, pingzhao wrote:

> The R was installed by system adminstrator. Here
> make is used to compile C code, right?, but the compile tools

It isn't: it controls the running of compilers, linkers etc.

> C, C++,etc. are there. Could any one give me somes hints on
> how to fix this problems?

Ask your system administator for help!  It's a problem with *your*
computing setup not R, and (s)he clearly knows how to use it (and you do
not).  You haven't even told us what platform you are using.  Here is one
guess:

On Solaris the standard development tools are in /usr/ccs/bin, and a 
standard account does not have that directory in the path.

[...]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From kwan022 at stat.auckland.ac.nz  Sun May 25 10:15:23 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Sun, 25 May 2003 20:15:23 +1200 (NZST)
Subject: [R] Example Data Set(s) for nnet, rpart
Message-ID: <Pine.LNX.4.44.0305252006250.31429-100000@stat61.stat.auckland.ac.nz>

Hi,

I'm doing a presentation on Neural Networks and Tree-Based Models in two 
weeks, at the moment I'm looking for a data set to use in the 
presentation.  What I would like to use is a good old data, like the Iris 
data, that is already known by every statisticians.

MASS4 uses the cpus data in Chapter 8.10 and the Cushing's syndrome in 
Chapter 12.4.  These two data sets plus the Iris data I have mentioned 
make three possible candidate data sets.  Does anyone has a good 
recommendation as to which data set is better?  

While I'm at it.  Is it technically correct to obtain (using residuals()) 
the residual sum of square from the nnet() and rpart() models.  Then say 
one is better than the other based on the statistic?



-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)



From wprijsin at cs.uu.nl  Sun May 25 10:15:37 2003
From: wprijsin at cs.uu.nl (Wouter van Rijsinge)
Date: Sun, 25 May 2003 10:15:37 +0200
Subject: [R] Fitting an ARIMA model to a time series
Message-ID: <5.2.0.9.0.20030525094310.019dd410@imaps.students.cs.uu.nl>

R 1.6.2 on windows XP (and windows 2000)

Dear Readers,

I have to fit an ARIMA model to a blood pressure series to make predictions 
with it. But since I don't have a blood pressure data set yet I have to 
work with self made data. So I have created an AR( 2 ) series with the 
following code:
series <- list()
series$series <- arima.sim(n=2100, model=list(ar = c(0.6, 0.1)), sd=1)  + 120
It is based upon the assumption that the blood pressure will be a value 
around a mean of 120 with only minor fluctuations. Only when something goes 
terribly wrong it will have a trend up or down.

I now try to predict new values every interval of size 20 with data from a 
sliding window of size 100 with the following code:
windowSize <- 100
lagSize <- 5
for(i in 1 : 100)
{
	index <- windowSize + ((i-1)*20)
	model <-  arima(series$series[ ( ( (index-windowSize) + 1) : index ) ], 
order = c(2, 1, 1), method = c("ML")  )
	predictions <- arima.sim(n=5, model = model)
}

The problem is that whatever order I use for the model estimation I always 
end up with the error: "ar part of model is not stationary". I have tried 
to fit totally different series with less random fluctuations and more 
trend etc. but it also doesn't work. I don't know any solution for this 
problem anymore. So I have the following questions:
1. Is there anybody who can tell me how to (automatically) fit an ARIMA 
model to the data and make predictions with it?  It of course has to work 
with future blood pressure series too. Even with blood pressure series with 
trend because in the future I will have to fit it to data from the 
Intensive Care.
2. Or is the model not compatible with the (simulated) blood pressure data 
and should I just stop trying?

I hope someone has a solution for this problem because I can't find one.

Greetings,

	Wouter



From ligges at statistik.uni-dortmund.de  Sun May 25 11:28:06 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 25 May 2003 11:28:06 +0200
Subject: [R] assign() won't work
References: <001001c3228b$ad6016a0$f34893ac@lopeylaptop>
Message-ID: <3ED08CA6.8445391E@statistik.uni-dortmund.de>



"Brian J. Lopes" wrote:
> 
> Hey everyone, I've been searching the mail lists, and I can't find a real discussion about my problem.  Here it is:
> 
> I have created a loop fitting various time series models to my data.  I labeled each one of the outputs by using the assign and paste statements, i.e. assign(paste("group","subgroup",i),arima(...)).  Works great, but here's what I need...
> 
> I want to create a tables by group, and refer to particular information from each arima fit, such as AIC value, loglikelihood value, etc.
> 
> My best guess is,
> assign(paste("group","subgroup"),get(paste("group",subgroup",i))$aic
> 
> This won't work, due to the restrictions of my the assign function.  If you can't understand this from the code, here it is verbally:
> 
> I've got a bunch of matrices to fill-in with information, all their names are part of this paste function (59 in total).  I want to fill in the rows of each matrix with the information from every analysis provided for each group.  (i.e. for ARMA(1,0) I want a row of the aic and loglikelihood values, but I want this for the ARMA(1,1) model I ran, and the ARMA(2,0) model I ran as well)  I have done many ARMA's for many different series, and want to make a table for each series.  There are too many of these to do this for each individual series.
> 
> Thanks for your help!
> Pura Vida,
> Brian

1) Please, tell your mailtool to wrap lines (and not to send in HTML
format which has been deleted anyway).

2) I don't get the point completely.

3) I guess you are going to use a list (of matrices or other appropriate
data structures) instead a huge number of single objects (in your case
matrices). Access to list elements should be much easier to handle.

Uwe Ligges



From p.dalgaard at biostat.ku.dk  Sun May 25 11:36:43 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Sun, 25 May 2003 09:36:43 -0000
Subject: [R] assign() won't work
In-Reply-To: <001001c3228b$ad6016a0$f34893ac@lopeylaptop>
References: <001001c3228b$ad6016a0$f34893ac@lopeylaptop>
Message-ID: <x2smr39xah.fsf@biostat.ku.dk>

"Brian J. Lopes" <blopes at email.unc.edu> writes:

> Hey everyone, I've been searching the mail lists, and I can't find a
> real discussion about my problem. Here it is:
> 
> I have created a loop fitting various time series models to my data.
> I labeled each one of the outputs by using the assign and paste
> statements, i.e. assign(paste("group","subgroup",i),arima(...)).
> Works great, but here's what I need...
> 
> I want to create a tables by group, and refer to particular
> information from each arima fit, such as AIC value, loglikelihood
> value, etc.
> 
> My best guess is,
> assign(paste("group","subgroup"),get(paste("group",subgroup",i))$aic
> 
> This won't work, due to the restrictions of my the assign function.
> If you can't understand this from the code, here it is verbally:
> 
> I've got a bunch of matrices to fill-in with information, all their
> names are part of this paste function (59 in total). I want to fill
> in the rows of each matrix with the information from every analysis
> provided for each group. (i.e. for ARMA(1,0) I want a row of the aic
> and loglikelihood values, but I want this for the ARMA(1,1) model I
> ran, and the ARMA(2,0) model I ran as well) I have done many ARMA's
> for many different series, and want to make a table for each series.
> There are too many of these to do this for each individual series.

(please wrap your lines...)

Every time someone asks the question "How do I assign to x1,x2,x3,..."
they get the answer that assign(paste("x",i,sep=""),...) will work,
but they'd probably be better off using lists. I suspect you're in the
process of finding out why: The R language works much better on data
structures than on string representations. 

I'm not going to try and sort out the full details of your problem,
but if you had a list of arima() results, the solution could be as
simple as

sapply(olist,function(o)unlist(o[c("loglik","aic")]))

Here's a simple example, continuing example(arima):

data(lh)
l <- list(c(1,0,0),c(3,0,0),c(1,0,0))
olist <- lapply(l,arima, x=lh)
names(olist) <- sapply(l,deparse) 
sapply(olist,function(o)unlist(o[c("loglik","aic")]))

There are a couple of variations: (a) You might want to transpose the
resulting matrix using t(..) and (b) there's a simpler form

sapply(olist,"[",c("loglik","aic"))

but notice that (since the unlist() is gone) that gives you a list
matrix, rather than a matrix of numbers so the formatting is
different. (Run str() on the output to see what I mean.)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From Ted.Harding at nessie.mcc.ac.uk  Sun May 25 11:42:27 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sun, 25 May 2003 10:42:27 +0100 (BST)
Subject: [R] help output paged in separate window
In-Reply-To: <XFMail.030524203021.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <XFMail.030525104227.Ted.Harding@nessie.mcc.ac.uk>

On 24-May-03 Ted Harding wrote:
> I use R in X windows on Linux.
> [...]
> Often, I would like to have the output from 'help' pop up in a separate
> window so that I can continue to work in the R window while reading the
> help. The "help" window could then be closed when interest in this
> particular help dwindles.
> [...]

Thanks to Jonathan Baron and Peter Dalgaard for private comments and help
on this question. Peter in particular pointed out that
  library(tcltk); options(pager=tkpager)
does the trick of detaching the pager from the R window exactly as
desired, with relatively small overhead (as opposed to an HTML browser
for 'help.start', or ESS: I put enough load on this 48MB laptop without
having a multimegabyte Fat Man sitting on my memory).

Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 25-May-03                                       Time: 10:42:27
------------------------------ XFMail ------------------------------



From ismdiego at est-econ.uc3m.es  Sun May 25 13:23:38 2003
From: ismdiego at est-econ.uc3m.es (ismdiego@est-econ.uc3m.es)
Date: Sun, 25 May 2003 13:23:38 +0200 (CEST)
Subject: [R] scroll keys
Message-ID: <7331175279ismdiego@est-econ.uc3m.es>


Hello:

I use R in X windows on Linux (SUSE 8.1)

I used to work with R1.6.1, and everything was ok. Recently I have 
installed R1.7.0 and the scroll keys do not work properly. Some 
suggestions?

Thanks in advanced.



From p.dalgaard at biostat.ku.dk  Sun May 25 13:33:21 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Sun, 25 May 2003 11:33:21 -0000
Subject: [R] scroll keys
In-Reply-To: <7331175279ismdiego@est-econ.uc3m.es>
References: <7331175279ismdiego@est-econ.uc3m.es>
Message-ID: <x2of1r9rvv.fsf@biostat.ku.dk>

<ismdiego at est-econ.uc3m.es> writes:

> Hello:
> 
> I use R in X windows on Linux (SUSE 8.1)
> 
> I used to work with R1.6.1, and everything was ok. Recently I have 
> installed R1.7.0 and the scroll keys do not work properly. Some 
> suggestions?
> 
> Thanks in advanced.

Both installed in the same way (from source or RPM)? Same SuSE version?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From fharrell at virginia.edu  Sun May 25 13:44:37 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Sun, 25 May 2003 07:44:37 -0400
Subject: [R] help output paged in separate window
In-Reply-To: <XFMail.030525104227.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.030524203021.Ted.Harding@nessie.mcc.ac.uk>
	<XFMail.030525104227.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <20030525074437.72a0d70e.fharrell@virginia.edu>

On Sun, 25 May 2003 10:42:27 +0100 (BST)
Ted.Harding at nessie.mcc.ac.uk wrote:

> On 24-May-03 Ted Harding wrote:
> > I use R in X windows on Linux.
> > [...]
> > Often, I would like to have the output from 'help' pop up in a separate
> > window so that I can continue to work in the R window while reading the
> > help. The "help" window could then be closed when interest in this
> > particular help dwindles.
> > [...]
> 
> Thanks to Jonathan Baron and Peter Dalgaard for private comments and help
> on this question. Peter in particular pointed out that
>   library(tcltk); options(pager=tkpager)
> does the trick of detaching the pager from the R window exactly as
> desired, with relatively small overhead (as opposed to an HTML browser
> for 'help.start', or ESS: I put enough load on this 48MB laptop without
> having a multimegabyte Fat Man sitting on my memory).

tkpager works well; I just wish it handled the "see also" links to other help files.

I wish that help.start() would work with the blazing fast html browser dillo (Linux/Unix).  dillo is a 240K executable written in C.

Frank
---
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From ozric at web.de  Sun May 25 14:00:41 2003
From: ozric at web.de (Christian Schulz)
Date: Sun, 25 May 2003 14:00:41 +0200
Subject: [R] Example Data Set(s) for nnet, rpart
References: <Pine.LNX.4.44.0305252006250.31429-100000@stat61.stat.auckland.ac.nz>
Message-ID: <001401c322b5$44ad0300$6900ebd9@pc>

...i  like the adult file, beacuse it is "real-life"
and have a lot of cases for good splitting
in train/test cases -  ok  you need more time, to train/test!

http://www.ics.uci.edu/~mlearn/MLSummary.html

Donated by Ron Kohavi
Predicting whether income exceeds $50K/yr based on census data
Documentation: On everything
48842 instances, 14 attributes (6 continuous and 8 nominal)
Missing attribute values
Originally listed as the "Census Income" Database. It was renamed because it
is cited as the "Adult" database

regards,christian


----- Original Message -----
From: "Ko-Kang Kevin Wang" <kwan022 at stat.auckland.ac.nz>
To: "R Help" <r-help at stat.math.ethz.ch>
Sent: Sunday, May 25, 2003 10:15 AM
Subject: [R] Example Data Set(s) for nnet, rpart


> Hi,
>
> I'm doing a presentation on Neural Networks and Tree-Based Models in two
> weeks, at the moment I'm looking for a data set to use in the
> presentation.  What I would like to use is a good old data, like the Iris
> data, that is already known by every statisticians.
>
> MASS4 uses the cpus data in Chapter 8.10 and the Cushing's syndrome in
> Chapter 12.4.  These two data sets plus the Iris data I have mentioned
> make three possible candidate data sets.  Does anyone has a good
> recommendation as to which data set is better?
>
> While I'm at it.  Is it technically correct to obtain (using residuals())
> the residual sum of square from the nnet() and rpart() models.  Then say
> one is better than the other based on the statistic?
>
>
>
> --
> Cheers,
>
> Kevin
>
> --------------------------------------------------------------------------
----
> /* Time is the greatest teacher, unfortunately it kills its students */
>
> --
> Ko-Kang Kevin Wang
> Master of Science (MSc) Student
> SLC Tutor and Lab Demonstrator
> Department of Statistics
> University of Auckland
> New Zealand
> Homepage: http://www.stat.auckland.ac.nz/~kwan022
> Ph: 373-7599
>     x88475 (City)
>     x88480 (Tamaki)
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Sun May 25 14:05:25 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 25 May 2003 13:05:25 +0100 (BST)
Subject: [R] help output paged in separate window
In-Reply-To: <20030525074437.72a0d70e.fharrell@virginia.edu>
Message-ID: <Pine.LNX.4.44.0305251251370.10966-100000@gannet.stats>

On Sun, 25 May 2003, Frank E Harrell Jr wrote:

> On Sun, 25 May 2003 10:42:27 +0100 (BST)
> Ted.Harding at nessie.mcc.ac.uk wrote:
> 
> > On 24-May-03 Ted Harding wrote:
> > > I use R in X windows on Linux.
> > > [...]
> > > Often, I would like to have the output from 'help' pop up in a separate
> > > window so that I can continue to work in the R window while reading the
> > > help. The "help" window could then be closed when interest in this
> > > particular help dwindles.
> > > [...]
> > 
> > Thanks to Jonathan Baron and Peter Dalgaard for private comments and help
> > on this question. Peter in particular pointed out that
> >   library(tcltk); options(pager=tkpager)
> > does the trick of detaching the pager from the R window exactly as
> > desired, with relatively small overhead (as opposed to an HTML browser
> > for 'help.start', or ESS: I put enough load on this 48MB laptop without
> > having a multimegabyte Fat Man sitting on my memory).

(BTW, if your Window Manager has a pager that will work at least as well 
as PAGER: e.g. CDE users can use dtpad and that is much lighter weight 
than the ca 2Mb needed loading up Tcl/Tk.  You can also make PAGER run 
less in another instance of your favourite terminal -- which as an 
additional instance should be cheap.)

> tkpager works well; I just wish it handled the "see also" links to other help files.
> 
> I wish that help.start() would work with the blazing fast html browser
> dillo (Linux/Unix).  dillo is a 240K executable written in C.

Presumably it doesn't work because `dillo' is not really a conforming HTML 
browser?   What actually are the symptoms?

help.start() does work with lynx last time I looked, and lynx really is
small, You can tell essentially nothing about the resident set size of the
running executable from the file size.  From a web page on gnu.org I found

  The 'dillo' Web browser is a very fast, extremely small browser. Source 
  is less than 365 KB, and the binary is around 265 KB. It is a graphical
  browser built upon GTK+, and it renders a good subset of HTML, excluding
  frames, JavaScript, and JVM support.

Note that it requires GTK+, and that is not at all small.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ismdiego at est-econ.uc3m.es  Sun May 25 14:59:27 2003
From: ismdiego at est-econ.uc3m.es (ismdiego@est-econ.uc3m.es)
Date: Sun, 25 May 2003 14:59:27 +0200 (CEST)
Subject: [R] scroll keys
Message-ID: <5329929531ismdiego@est-econ.uc3m.es>



> <ismdiego at est-econ.uc3m.es> writes:
> 
> > Hello:
> > 
> > I use R in X windows on Linux (SUSE 8.1)
> > 
> > I used to work with R1.6.1, and everything was ok. Recently I have 
> > installed R1.7.0 and the scroll keys do not work properly. Some 
> > suggestions?
> > 
> > Thanks in advanced.
> 
> Both installed in the same way (from source or RPM)? Same SuSE 
version?

Same SuSE version but R1.6.1 installed from source and R1.7.0 from RPM.

--
--
********************************
ismdiego



From ligges at statistik.uni-dortmund.de  Sun May 25 18:00:05 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 25 May 2003 18:00:05 +0200
Subject: [R] surprising behaviour of "bgroup": sets all in greek letters
In-Reply-To: <3EC9FFAB.5010800@statistik.uni-dortmund.de>
References: <1053416639.3ec9dcbfb9489@webmail.uni-magdeburg.de>
	<3EC9FFAB.5010800@statistik.uni-dortmund.de>
Message-ID: <3ED0E885.8000909@statistik.uni-dortmund.de>

Uwe Ligges wrote:
> Ulf Martin wrote:
> 
>> Dear R user community
>>
>> I wanted to use "bgroup" for plotting a math formula with
>> a big "{" on the left, and nothing on the right.
>> i used
>>
>>   text( 10, 10, pos=4, cex=1.8, expression(F(x) == bgroup("{", x, 
>> "")), ...)
>>
>> on a 40 x 20 plot.
>> surprisingly,
>> bgroup sets "Phi(xi) = { xi" i.e. replaces alphabetic characters with 
>> greek letters in the entire formula.
>>
>> I tried out other ending delimiters instead of "":
>> With " ", ":", ";", ",", R complains about an "invalid group delimiter",
>> With "." R produces greek letters again.
>>
>> Is this a bug, or am I missing something?
>> How could I possibly accomplish my original task?
>> The idea is to have something like
>>
>>           0 if x<0
>>  F(x) = {
>>           y otherwise
>>
>> in the end.
>>
>> Thanks in advance!
>> (and for the great tool anyway!)
>>
>> (I am not currently subscribed to the r-help list,
>> so I would be gratful if anybody could answer me directly too, thanks!)
>>
>> Bye
> 
> 
> Looks like a bug. I'll investigate further within the next couple of 
> days (except anyone else comes up with the right idea before).
> 
> Uwe Ligges

Yes, it is a bug.
I don't know whether I'm working only on the symptoms here, but the 
following patch to .../src/main/plotmath.c should fix it. I'll file it 
to R-Bugs at once.

Uwe Ligges

==========================
(diff'ed to R-1.7.0 patched (2003-05-25))
 >  diff -u ./plotmath.old ./r-patched/src/main/plotmath.c


--- ./plotmath.old     2003-05-25 17:47:23.000000000 +0200
+++ ./r-patched/src/main/plotmath.c     2003-05-25 17:49:38.000000000 +0200
@@ -2075,10 +2075,12 @@
      delim2 = DelimCode(expr, CADDDR(expr));
      bbox = RenderElement(CADDR(expr), 0);
      dist = max(bboxHeight(bbox) - axisHeight, bboxDepth(bbox) + 
axisHeight);
-    bbox = RenderDelim(delim1, dist + extra, draw);
+    if (delim1 != '.')
+        bbox = RenderDelim(delim1, dist + extra, draw);
      bbox = CombineBBoxes(bbox, RenderElement(CADDR(expr), draw));
      bbox = RenderItalicCorr(bbox, draw);
-    bbox = CombineBBoxes(bbox, RenderDelim(delim2, dist + extra, draw));
+    if (delim2 != '.')
+        bbox = CombineBBoxes(bbox,     RenderDelim(delim2, dist + 
extra, draw));
      return bbox;
  }



From jfox at mcmaster.ca  Sun May 25 21:54:36 2003
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 25 May 2003 15:54:36 -0400
Subject: [R] Can Package SEM do mean structural analysis?
In-Reply-To: <200305250503.h4P53lk2029203@mp2.vectant.ne.jp>
References: <5.1.0.14.2.20030524103328.01e9e310@mcmail.cis.mcmaster.ca>
	<5.1.0.14.2.20030524103328.01e9e310@mcmail.cis.mcmaster.ca>
Message-ID: <5.1.0.14.2.20030525155240.01e43220@mcmail.cis.mcmaster.ca>

Dear Mitsuo,

The raw sums of squares and products matrix contains the sums of squares 
and sums of cross-products for the variables without subtracting the means. 
You'd add an initial column one ones to represent the means. As I said, I 
don't have time now to work out in detail whether this will allow you to 
fit models with means.

John

At 02:03 PM 5/25/2003 +0900, Mitsuo Igarashi wrote:
>Dear John:
>
>Thank you very much for your prompt explanation on the
>present possibilities of SEM.
>
>I am not a statistician so that I can not figure out the raw 
>sums-of-squares-and-products matrix.
>And I will do with SEM in the area without mean structural
>equation.
>
>I appreciate your good teaching at every time.
>--------========----------
>Mitsuo Igarashi
>mitsu5 at ruby.famille.ne.jp
>----------------
>
>John Fox <jfox at mcmaster.ca> wrote:
>
> > Dear Mitsuo,
> >
> > My intention in writing the sem package was to provide a basic
> > structural-equation facility for R. I haven't made explicit provision for
> > models with means, but it might be possible to fit such models by using 
> the
> > raw sums-of-squares-and-products matrix among the observed variables
> > (perhaps divided by n) as input.  It might be necessary to make small
> > modifications to degrees of freedom, etc.
> >
> > I'm afraid that I don't have time now to figure out whether this will work
> > and, if so, precisely how to do it, but you're welcome to try. If you get
> > it to work, I'd be interested in the answer. If this approach doesn't 
> work,
> > then incorporating means would likely require major modifications to the
> > program.
> >
> > There are, by the way, several other things that dedicated
> > structural-equation software does that the sem package does not -- e.g.,
> > analysis by groups and for ordinal observed variables. I may, at some
> > point, extend the package in these directions, but I don't have plans at
> > the moment to do so.
> >
> > Good luck,
> >   John
> >
> > At 10:53 PM 5/24/2003 +0900, you wrote:
> >
> > >I am wondering whether Package SEM can do with intercepts and
> > >means in its structural analysis.
> > >
> > >If it can not calculate, how can I make a supplemental function
> > >in R?
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From shitao at hotmail.com  Mon May 26 01:53:59 2003
From: shitao at hotmail.com (Tao Shi)
Date: Sun, 25 May 2003 23:53:59 +0000
Subject: [R] segmentation fault when loading MASS library
Message-ID: <Sea2-F47TYP0KlixRXm0001dfbc@hotmail.com>

Hi, all:

There are two versions of R installed on our Linux cluster: 1.6.2 and 1.7.0 
and both of them have problems with the MASS library.

For the R 1.6.2, whenever I load MASS library by typing library(MASS), there 
is a "segmentation fault" and it automatically exit R.

For the R 1.7.0, for some reasons, there is no MASS library (there are also 
other libraries came with the R 1.7.0) are missing.  Since I know the MASS 
library should be part of the R 1.7 distribution package, I went to talk to 
the system administrator who installed R 1.7.  He told me that he didn't do 
anything special during the installation and he's also puzzled how this 
would happen.

Help...........

...Tao



From yakovp at earthlink.net  Mon May 26 03:09:06 2003
From: yakovp at earthlink.net (yakov peretz)
Date: Sun, 25 May 2003 21:09:06 -0400
Subject: [R] Problem with library
Message-ID: <3ED16932.E0734866@earthlink.net>

Hello.

I'm using R 1.7.0 on win98 ver2. I erased all my previous versions of R,
and install r 1.7.0. When I write "library()" I receive on a separate
pane all the lib in ver 1.7.0, and the following msg "Warning message:
library 'C:/Program Files/R/rw1051/library' contains no package in:
library()"
Where is this msg coming from?? How to remove it?

Thnx Yakov



From fharrell at virginia.edu  Mon May 26 03:15:01 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Sun, 25 May 2003 21:15:01 -0400
Subject: [R] help output paged in separate window
In-Reply-To: <Pine.LNX.4.44.0305251251370.10966-100000@gannet.stats>
References: <20030525074437.72a0d70e.fharrell@virginia.edu>
	<Pine.LNX.4.44.0305251251370.10966-100000@gannet.stats>
Message-ID: <20030525211501.7bcb8f03.fharrell@virginia.edu>

On Sun, 25 May 2003 13:05:25 +0100 (BST)
Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> On Sun, 25 May 2003, Frank E Harrell Jr wrote:
> 
> > On Sun, 25 May 2003 10:42:27 +0100 (BST)
> > Ted.Harding at nessie.mcc.ac.uk wrote:
> > 
> > > On 24-May-03 Ted Harding wrote:
> > > > I use R in X windows on Linux.
> > > > [...]
> > > > Often, I would like to have the output from 'help' pop up in a separate
> > > > window so that I can continue to work in the R window while reading the
> > > > help. The "help" window could then be closed when interest in this
> > > > particular help dwindles.
> > > > [...]
> > > 
> > > Thanks to Jonathan Baron and Peter Dalgaard for private comments and help
> > > on this question. Peter in particular pointed out that
> > >   library(tcltk); options(pager=tkpager)
> > > does the trick of detaching the pager from the R window exactly as
> > > desired, with relatively small overhead (as opposed to an HTML browser
> > > for 'help.start', or ESS: I put enough load on this 48MB laptop without
> > > having a multimegabyte Fat Man sitting on my memory).
> 
> (BTW, if your Window Manager has a pager that will work at least as well 
> as PAGER: e.g. CDE users can use dtpad and that is much lighter weight 
> than the ca 2Mb needed loading up Tcl/Tk.  You can also make PAGER run 
> less in another instance of your favourite terminal -- which as an 
> additional instance should be cheap.)
> 
> > tkpager works well; I just wish it handled the "see also" links to other help files.
> > 
> > I wish that help.start() would work with the blazing fast html browser
> > dillo (Linux/Unix).  dillo is a 240K executable written in C.
> 
> Presumably it doesn't work because `dillo' is not really a conforming HTML 
> browser?   What actually are the symptoms?

dillo is 'almost' conforming.  The main thing I miss is frames.  Before I responded I thought it would be good to update dillo to the latest version from rpmfind.net.  Now, using dillo 0.7.2, all is well with help.start() and with help(functionname).  The search engine is the only thing I've tested that doesn't work.  I highly recommend dillo for use with R in Linux/Unix.

> 
> help.start() does work with lynx last time I looked, and lynx really is
> small, You can tell essentially nothing about the resident set size of the
> running executable from the file size.  From a web page on gnu.org I found
> 
>   The 'dillo' Web browser is a very fast, extremely small browser. Source 
>   is less than 365 KB, and the binary is around 265 KB. It is a graphical
>   browser built upon GTK+, and it renders a good subset of HTML, excluding
>   frames, JavaScript, and JVM support.
> 
> Note that it requires GTK+, and that is not at all small.

My RedHat 8.0 had GTK+ already, so it didn't cost me.

Thanks,

Frank
------
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat



From dmurdoch at pair.com  Mon May 26 03:39:59 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sun, 25 May 2003 21:39:59 -0400
Subject: [R] Problem with library
In-Reply-To: <3ED16932.E0734866@earthlink.net>
References: <3ED16932.E0734866@earthlink.net>
Message-ID: <3ur2dvgug0ts35j8uvt8vv9ivu7tcteo4t@4ax.com>

On Sun, 25 May 2003 21:09:06 -0400, you wrote:

>Hello.
>
>I'm using R 1.7.0 on win98 ver2. I erased all my previous versions of R,
>and install r 1.7.0. When I write "library()" I receive on a separate
>pane all the lib in ver 1.7.0, and the following msg "Warning message:
>library 'C:/Program Files/R/rw1051/library' contains no package in:
>library()"
>Where is this msg coming from?? How to remove it?

You're somehow telling R to look in that directory for packages,
presumably because that was the right place to look when you used
1.5.1.

I'm not sure how you're telling it that, but a likely reason is that
you've got a .lib.loc variable that contains the old address, or your
.First function sets it, or something like that.

Duncan Murdoch



From yakovp at earthlink.net  Mon May 26 04:04:29 2003
From: yakovp at earthlink.net (yakov peretz)
Date: Sun, 25 May 2003 22:04:29 -0400
Subject: [R] Problem with library
References: <3ED16932.E0734866@earthlink.net>
Message-ID: <3ED1762D.5E706ADB@earthlink.net>

Hello,

I found te answer, Thanks.

Yakov

yakov peretz wrote:

> Hello.
>
> I'm using R 1.7.0 on win98 ver2. I erased all my previous versions of R,
> and install r 1.7.0. When I write "library()" I receive on a separate
> pane all the lib in ver 1.7.0, and the following msg "Warning message:
> library 'C:/Program Files/R/rw1051/library' contains no package in:
> library()"
> Where is this msg coming from?? How to remove it?
>
> Thnx Yakov
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Raimondas at vb.lt  Mon May 26 06:03:25 2003
From: Raimondas at vb.lt (Raimondas B.)
Date: Mon, 26 May 2003 07:03:25 +0300
Subject: [R] Need computing of Correlation Integral
Message-ID: <001c01c3233b$c17b9410$6e25b10a@berniunas>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030526/27d75ea4/attachment.pl

From edd at debian.org  Mon May 26 06:40:12 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 25 May 2003 23:40:12 -0500
Subject: [R] Need computing of Correlation Integral
In-Reply-To: <001c01c3233b$c17b9410$6e25b10a@berniunas>
References: <001c01c3233b$c17b9410$6e25b10a@berniunas>
Message-ID: <20030526044011.GA13955@sonny.eddelbuettel.com>

On Mon, May 26, 2003 at 07:03:25AM +0300, Raimondas B. wrote:
> Dear users,
> Maybe some of you has realized computing of Correlation Integral which is used in computing BSD statistic. 

If you want the BSD statistic, it is part of the tseries package. Try

    > help(bds.test, package=tseries)
    
though you may need to install the tseries package first.

Hth,  Dirk

-- 
Don't drink and derive. Alcohol and analysis don't mix.



From r.hankin at auckland.ac.nz  Mon May 26 06:50:20 2003
From: r.hankin at auckland.ac.nz (Robin Hankin)
Date: Mon, 26 May 2003 16:50:20 +1200
Subject: [R] vectorizing data.frame()
Message-ID: <200305260450.h4Q4oK6b005043@r.hankin.sges.auckland.ac.nz>

Hello everybody.

I have a dozen or so vectors (of different lengths) which I want to
coalesce into a dataframe, as in the following toy example.

R> foo <- c(1,2,3)
R> bar <- c(7,8)
R> data.frame(name =c(rep("foo",length(foo)),rep("bar",length(bar))),
              value=c(foo,bar))

  name value
1   foo     1
2   foo     2
3   foo     3
4   bar     7
5   bar     8

Is there a better (vectorized) way?


-- 

Robin Hankin, Lecturer,
School of Geography and Environmental Science
Tamaki Campus
Private Bag 92019 Auckland
New Zealand

r.hankin_AT_auckland.ac.nz
tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042



From kurt.sys at UGent.be  Mon May 26 08:44:01 2003
From: kurt.sys at UGent.be (Kurt Sys)
Date: Mon, 26 May 2003 08:44:01 +0200
Subject: [R] building zip?
In-Reply-To: <200305231201.h4NC1S1F025799@erdos.math.unb.ca>
References: <200305231201.h4NC1S1F025799@erdos.math.unb.ca>
Message-ID: <16081.47025.312398.309705@ksys.rug.ac.be>

Hello,

thanks, it's easy and it seems to work. There are not .dll's involved
yet...

tnx,
Kurt.


--
Mail from Rolf Turner
sent on Friday May 23 2003 at 09:01 (GMT-0300):

> 
> I had similar difficulties a while back, trying to build a package
> for Windoze under Solaris.  With Solaris, the answer turns out to be
> easy --- once you know how.  (But ``they'' never seem to tell you
> these things until you squeeze the information out of ``them''.)
> 
> That is, it's easy as long as there are no *.dll's involved.  If
> there are, then you have a more difficult problem, which I am
> currently unqualified to help with.
> 
> For what they're worth, here are my notes to myself on what to do
> (in Solaris).  (I was installing stuff for students on our local
> Novell network, so the notes are oriented that way.):
> 
> ===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
> To create a package to be installed by Windows is easy as long as
> there is no compilation (no C or Fortran code to be compiled into a
> dynamically loadable object or `dll''.)
> 
> Just install the package on the Unix box, go to where it's installed
> (e.g. .../Rlib) and then execute
> 
>         zip -r9l <pkge>.zip <pkge> e.g.:
>         zip -r9l ts.sup.zip ts.sup
> 
> The resulting *.zip file can then be transported to a windows system
> and installed there.
> 
> E.g. put ts.sup.zip in F:/rproject on the Novell network, start up R
> and execute
> 
>         > install.packages("F:/rproject/ts.sup.zip",
>                            lib="L:/statdata/Rlib",CRAN=NULL)
> 
> (Currently an error and some warnings occur, but they can be
> ignored!!!)
> ===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
> 
> The ``zip'' command is built into Solaris (solaris 2.9); on Linux I
> guess you'd have to get it off the web and install it.  E.g., (I
> think) http://www.info-zip.org/pub/infozip/.
> 
> Hope this helps.
> 
> 				cheers,
> 
> 					Rolf Turner rolf at math.unb.ca

-- 
A Linux machine! because a 486 is a terrible thing to waste!
		-- jjs at wintermute.ucr.edu, Joe Sloan



From ozric at web.de  Mon May 26 08:46:48 2003
From: ozric at web.de (Christian Schulz)
Date: Mon, 26 May 2003 08:46:48 +0200
Subject: [R] RWeka read.arff()
Message-ID: <002601c32352$9579be20$d200a8c0@pc>

Dear R-project and Weka users,

here is my first step to import 
Arff files from the Weka Machine Learning Package
 into R-project.

http://www.cs.waikato.ac.nz/ml/weka/

Further: Ko-Kang Kevin Wang
starts a webpage for RWeka

http://www.stat.auckland.ac.nz/~kwan022/RWeka/


Perhaps a regular expression crack,
know how it's possible - getting the second part of
three text-blocks, which tab or space separated
- so the the regular expression for labels could be better!?

many thanks & regards,christian


[1] "@ATTRIBUTE SEPALLENGTH REAL"
[2] "@ATTRIBUTE SEPALWIDTH REAL"
[3] "@ATTRIBUTE PETALLENGTH REAL"
[4] "@ATTRIBUTE PETALWIDTH REAL"
[5] "@ATTRIBUTE CLASS {IRIS-SETOSA,IRIS-VERSICOLOR,IRIS-VIRGINICA}"


read.arff <- function(file = "", header = TRUE, ...) {
x <- readLines(file)
y <- toupper(x)
s <- which(y == "@DATA")
data <- read.table(file = file, sep = ",", comment.char = "%",skip = s)
attr <- paste(y)
attr2 <- grep("^@ATTRIBUTE",value=T,attr)
labels <- sub("\([^ ]*\)","", attr2)
names(data) <- as.character(labels)
return(data)
}


[tests]
xyz <- read.arff("c:/project/Rweka/labor.arff")
str(xyz)
xyz <-  read.arff("c:/project/Rweka/labor.arff")
str(xyz)
xyz <-  read.arff("c:/project/Rweka/iris.arff")
str(xyz)
xyz <-  read.arff("c:/project/Rweka/labor.arff")
str(xyz)
xyz <-  read.arff("c:/project/Rweka/cpu.arff")
str(xyz)
xyz <-  read.arff("c:/project/Rweka/adult.arff")
str(xyz)



From ripley at stats.ox.ac.uk  Mon May 26 09:29:50 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 26 May 2003 08:29:50 +0100 (BST)
Subject: [R] vectorizing data.frame()
In-Reply-To: <200305260450.h4Q4oK6b005043@r.hankin.sges.auckland.ac.nz>
Message-ID: <Pine.LNX.4.44.0305260821050.6438-100000@gannet.stats>

That's a misleading title!

You want a single vector by concatenating vectors and recording their
origins.  There's no need for a data frame, and you are certainly not 
`vectorizing data.frame()'.  I presume you want to do this for a list of 
vectors.  How about

use <- c("foo", "bar")
names(use) <- use
xx <- unlist(lapply(use, get))
names(xx) <- sub("[0-9]+$", "", names(xx))
data.frame(names=names(xx), value=xx)

?

That will work with any character vector of names of vectors not ending in 
a digit.

On Mon, 26 May 2003, Robin Hankin wrote:

> Hello everybody.
> 
> I have a dozen or so vectors (of different lengths) which I want to
> coalesce into a dataframe, as in the following toy example.
> 
> R> foo <- c(1,2,3)
> R> bar <- c(7,8)
> R> data.frame(name =c(rep("foo",length(foo)),rep("bar",length(bar))),
>               value=c(foo,bar))
> 
>   name value
> 1   foo     1
> 2   foo     2
> 3   foo     3
> 4   bar     7
> 5   bar     8
> 
> Is there a better (vectorized) way?
> 
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon May 26 09:37:50 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 26 May 2003 08:37:50 +0100 (BST)
Subject: [R] segmentation fault when loading MASS library
In-Reply-To: <Sea2-F47TYP0KlixRXm0001dfbc@hotmail.com>
Message-ID: <Pine.LNX.4.44.0305260832040.6438-100000@gannet.stats>

On Sun, 25 May 2003, Tao Shi wrote:

> Hi, all:
> 
> There are two versions of R installed on our Linux cluster: 1.6.2 and 1.7.0 
> and both of them have problems with the MASS library.
> 
> For the R 1.6.2, whenever I load MASS library by typing library(MASS), there 
> is a "segmentation fault" and it automatically exit R.

Has this just started, or has it been happening for 5 months or so since 
1.6.2 came out?

> For the R 1.7.0, for some reasons, there is no MASS library (there are also 
> other libraries came with the R 1.7.0) are missing.  Since I know the MASS 
> library should be part of the R 1.7 distribution package, I went to talk to 
> the system administrator who installed R 1.7.  He told me that he didn't do 
> anything special during the installation and he's also puzzled how this 
> would happen.
> 
> Help...........

What do you expect *us* to do?  This does work on many, many other Linux 
systems.  Have you tried building and installing R yourself?  Or getting 
the current VR bundle sources from CRAN and installing them yourself?
Or (depending on the Linux version) installing an RPM from CRAN?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From laurent.buffat at it-omics.com  Mon May 26 09:57:50 2003
From: laurent.buffat at it-omics.com (laurent  buffat)
Date: Mon, 26 May 2003 09:57:50 +0200
Subject: [R] replaceMethod time and memory for very large object.
In-Reply-To: <000801c32145$54652280$e502eb82@alpha.wehi.edu.au>
Message-ID: <DGEIIIMDDGKLGHFCOPOFOEJBCCAA.laurent.buffat@it-omics.com>


Hi Henrik,

thanks a lot for your references (R.oo and com.braju.sma). It's a great
help.

Best regards,

laurent buffat

-----Message d'origine-----
De : Henrik Bengtsson [mailto:hb at maths.lth.se]
Envoye : vendredi 23 mai 2003 18:07
A : 'laurent buffat'; r-help at stat.math.ethz.ch
Objet : RE: [R] replaceMethod time and memory for very large object.


Hi Laurent, this is exactly the problem I had to when I was started to
work on microarray data. Your strategy works and it does indeed improve
the memory and time efficiency quite a bit. It is just a matter on what
granuality you want to emulate references, i.e. a matrix, a column of a
matrix or a single cell. I have stayed with a matrix and when I update
the matrix R (50000x20) in a quadruple of (R,G,Rb,Gb) it does help since
I do not have to pay the cost of having G, Rb and Gb coupled to the same
data structure.

FYI: Since 2001, I have developed the R.oo package
(http://www.maths.lth.se/help/R/R.classes/) based a similar idea to what
you are suggesting, i.e. use environments or similar functionalities to
emulate pointers and provide it in a reusable way. It implements some
extra features too, however not necessary in this context. Note also
that R.oo is more in the spirit of "a method belongs to a class" and not
"a method belongs to a generic function", which is the idea of R, but it
is not a restriction. At this moment R.oo is based on S4, but I intend
to upgrade to S4. My microarray package com.braju.sma is then making use
of R.oo wherever microarray structures are defined.

Best wishes

Henrik Bengtsson
Lund University

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of laurent buffat
> Sent: den 23 maj 2003 16:01
> To: r-help at stat.math.ethz.ch
> Subject: [R] replaceMethod time and memory for very large object.
>
>
>
> Hi there,
>
> First, please apologize, I'm not fluent in English.
>
> I try to manipulate very large object with R, and I have some
> problems with memory and time access, because of the < by
> value mechanism >. I would like to < encapsulate > a large
> vector in a class and access to the vector by method and
> replaceMethod, but where is a lot of < implicit copy >, and
> so, a lot of memory and time consuming.
>
> The data are very large, and come from micro array experiment
> (see http://Biocondutor.org for more detail of what is a
> micro array ) , but a  typical > vector is a 20000 genes * 20
> probes * 100 experiments * 2 (means and variance)
>
> The best way, in term of speed and memory is to try to
> emulate a < by reference > mechanism, but it's not very < in
> the spirit of R > and a little < dangerous > (see the example).
>
> Could you give me some recommendations ?
>
> Thanks for your help.
>
> The code below is a little < long >, sorry.
>
> Laurent B.
>
> ////////////////////////////
>
> setClass("Foo", representation(v = "numeric"))
>
> setMethod("initialize", signature("Foo"), function(.Object,
> v=vector()) {
> 		.Object at v <- v
> 		.Object
> 	   })
>
>
> setGeneric("v", function(.Object) standardGeneric("v"))
> setMethod("v", "Foo", function(.Object) .Object at v )
>
> setGeneric("v<-",function(.Object,value)
> standardGeneric("v<-")) setReplaceMethod("v", "Foo",
> function(.Object, value) {
> 	.Object at v <- value
>          return(.Object)
>          })
>
> setMethod("[","Foo", function(x,i,j=NA,...,drop=FALSE) x at v[i] )
>
> setReplaceMethod("[","Foo",function(x,i,j=NA,...,value) {
> 	x at v[i] <- value
> 	x
> 	})
>
> n <- 2000 * 20 * 100 * 2
>
> # in fact I would like to have
> # 20000 genes * 20 mesures by genes (probes) * 100
> experiences * 2 ( mean and variance) # but, it's to much
> memory for these example, so just try with 2000 "genes".
>
> x <- rep(1,n)
> # x, a non encapsuled vetor for the data "
> y <- new("Foo",v=x)
> # y, a encapsuled version".
>
>
> x[1] <- 2
> y at v[1] <- 2
> v(y)[1] <- 2
> y[1] <- 2
>
> nt <- 10 # number of test
>
> system.time(for(i in 1:nt) x[1] <- 2)
> system.time(for(i in 1:nt) y at v[1] <- 2)
> system.time(for(i in 1:nt) v(y)[1] <- 2)
> system.time(for(i in 1:nt) y[1] <- 2)
>
> [1] 0 0 0 0 0
> [1]  7.80  3.17 10.97  0.00  0.00
> [1] 10.19  5.39 15.60  0.00  0.00
> [1]  9.00  4.54 13.55  0.00  0.00
>
> x[1:2]
> y[1:2]
> v(y)[1:2]
> y at v[1:2]
>
> system.time(for(i in 1:nt) x[1:2])
> system.time(for(i in 1:nt) y[1:2])
> system.time(for(i in 1:nt) v(y)[1:2])
> system.time(for(i in 1:nt) y at v[1:2])
>
>
> [1] 0 0 0 0 0
> [1] 0 0 0 0 0
> [1] 0 0 0 0 0
> [1] 0 0 0 0 0
>
> # no problem for "acces method, only for replace method
> # Class FooPtr,
> # a way to try to by pass the "by value mecanizim of R" ...
>
> setClass("FooPtr", representation(p = "environment"))
>
> setMethod("initialize", signature("FooPtr"),
> function(.Object, v=vector()) {
> 		.Object at p <- new("environment")
> 		assign("v",v,envir=.Object at p)
> 		.Object
> 	   })
>
> setMethod("v", "FooPtr", function(.Object) get("v",envir=.Object at p) )
>
> setReplaceMethod("v", "FooPtr",
>                    function(.Object, value) {
>                    assign("v",value,envir=.Object at p)
>                    return(.Object)
>                  })
>
> setMethod("[","FooPtr", function(x,i,j=NA,...,drop=FALSE)
> get("v",envir=x at p)[i] )
>
> # a first version of "[<-" for FooPtr :
>
> setReplaceMethod("[","FooPtr",function(x,i,j=NA,...,value)
> 	{
> 	v<- get("v",envir=x at p)
> 	v[i] <- value
> 	assign("v",v,envir=x at p)
> 	x
> 	})
>
> z <- new("FooPtr",v=x)
>
> x[1] <- 2
> v(z)[1] <- 2
> z[1] <- 2
>
>
> system.time(for(i in 1:nt) x[1] <- 2)
> system.time(for(i in 1:nt) v(z)[1] <- 2)
> system.time(for(i in 1:nt) z[1] <- 2)
>
> [1] 0.01 0.00 0.01 0.00 0.00
> [1] 0 0 0 0 0
> [1] 1.63 1.18 2.81 0.00 0.00
>
> # the v(z)[1] is "good", but not "[<-"
> # a more creasy way to try "by reference"
>
> setReplaceMethod("[","FooPtr",function(x,i,j=NA,...,value)
> 	{
> 	assign("i",i,envir=x at p)
> 	assign("value",value,envir=x at p)
> 	eval(expression(v[i] <- value), envir=x at p)
> 	rm("i","value",envir=x at p)
> 	x
> 	})
>
> system.time(for(i in 1:nt) x[1] <- 2)
> system.time(for(i in 1:nt) v(z)[1] <- 2)
> system.time(for(i in 1:nt) z[1] <- 2)
>
> [1] 0 0 0 0 0
> [1] 0 0 0 0 0
> [1] 0.14 0.12 0.26 0.00 0.00
>
> # "[<-" is better, but v(z)[] is the best ... (why ???)
>
>
> # ok, v(z)[i] is the "best" acess, but you need to know what you do :
>
> v(z)[1] <- 12345
> z1 <- z
> v(z1)[1]
>
> # z and z1 work with the same environment ...
>
> //////////////////////
>
> Thanks for your help.
>
> Laurent
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
>
>



From tord.snall at ebc.uu.se  Mon May 26 10:28:28 2003
From: tord.snall at ebc.uu.se (Tord Snall)
Date: Mon, 26 May 2003 10:28:28 +0200
Subject: [R] knots fixed in gam(), library(mgcv)
Message-ID: <3.0.6.32.20030526102828.00db93b0@mail.anst.uu.se>

Dear all,

I have a problem with specifying the no. of knots in our function which
include gam(). I last worked with this in mid September but since then I
have reinstalled R and Simon Wood's library(mgcv), which he has changed
since then. The statistician (and good R-coder) with whom I co-operate is
now unfortunately overloaded with teaching, and I'm in the sprut of my
thesis.... I therefore would be really happy for help in solving this
problem. 

The problem is then the way we specify the no of knots in the gam, I think.

This is part of our function which worked fine in mid September: 

  require(mgcv)
  if(is.null(knots))
    fsp <- update.formula(formula, ~ . + s(d))
  else{
    fsp <- substitute(form+s(d,kn|f),list(kn=knots, form=formula))
    fsp <- as.formula(deparse(fsp))
  }
  fit <- gam(fsp, data = data, ...)
  ##

When I do not use the argument "knots" the function still works fine, but
when I do, I get the error message:

Error in (kinship ~ 1) + s(d, 10 | f) : non-numeric argument to binary
operator

I have tried changing the line with substitute() based on what is written
in ?gam but I mostly get the error message Error in terms.formula(gf,
specials = c("s")) 

Could someone please give a hint.

Thanks in advance!


Sincerely,
Tord Sn?ll



-----------------------------------------------------------------------
Tord Sn?ll
Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
Villav?gen 14			
SE-752 36 Uppsala, Sweden
Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
E-mail: Tord.Snall at ebc.uu.se
Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!



From tord.snall at ebc.uu.se  Mon May 26 11:12:48 2003
From: tord.snall at ebc.uu.se (Tord Snall)
Date: Mon, 26 May 2003 11:12:48 +0200
Subject: Solved: [R] knots fixed in gam(), library(mgcv)
Message-ID: <3.0.6.32.20030526111248.00db69a0@mail.anst.uu.se>

Dear all,

Berwin A Turlach kindly, quickly replied to my question. 

Solution:

>    else
>    fsp <- update.formula(formula, substitute( ~ . +s(d,kn|f),
list(kn=knots)))
>    fsp <- gam(fsp, data = data, ...)


cheers,
Tord


-----------------------------------------------------------------------
Tord Sn?ll
Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
Villav?gen 14			
SE-752 36 Uppsala, Sweden
Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
E-mail: Tord.Snall at ebc.uu.se
Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!



From kurt.sys at ugent.be  Mon May 26 11:21:47 2003
From: kurt.sys at ugent.be (Kurt Sys)
Date: Mon, 26 May 2003 11:21:47 +0200
Subject: [R] building zip?
In-Reply-To: <18D602BD42B7E24EB810D6454A58DB90047303B6@ibfftce505.is.de.dresdnerkb.com>
References: <18D602BD42B7E24EB810D6454A58DB90047303B6@ibfftce505.is.de.dresdnerkb.com>
Message-ID: <16081.56491.621733.9294@ksys.rug.ac.be>

Hello,

I guess I owe the R Windows maintainers an apology. Indeed, the
information of how building the zip-packages is in the file
'readme.packages'.

However, my story (if I'm allowed): I installed R for Windows quite
fast, just to test the packages. In standard installation, the
necessary software for building packages is not installed, and hence,
the file 'readme.packages' was not on the computer where I installed R
for Windows. I read all readme-files and the 'writing
extensions'... but the information was in the 'readme.packages', which
was not 'installed', because I just took standard installation (it was
just for testing, so I thought that the 'standard' installation would
have been ok, as it is for Linux).
I wonder, no offence to anyone, just a question, why the building
packages stuff is not in the standard Windows installation. It would
have saved me (and apparently some others) time, and all people on
this list another stupid question mail.


Kurt.



From p.dalgaard at biostat.ku.dk  Mon May 26 11:53:12 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon, 26 May 2003 09:53:12 -0000
Subject: [R] building zip?
In-Reply-To: <16081.56491.621733.9294@ksys.rug.ac.be>
References: <18D602BD42B7E24EB810D6454A58DB90047303B6@ibfftce505.is.de.dresdnerkb.com>
	<16081.56491.621733.9294@ksys.rug.ac.be>
Message-ID: <x24r3igh99.fsf@biostat.ku.dk>

Kurt Sys <kurt.sys at ugent.be> writes:

> I wonder, no offence to anyone, just a question, why the building
> packages stuff is not in the standard Windows installation. 

It's mostly historical. We used to have this in a separate zip file
which we'd not normally require people to install -- on the premise
that there's a bunch of other stuff you need for building packages
(perl, shell tools, C compiler) anyway. 

However, with the user-friendly installer, you select everythings up
front, and it has become much more difficult to add things to an
installation (why does "user-friendliness" always make something
harder?).

Since it is a tiny piece of extra baggage, I do agree that it would be
better to set it to install by default.


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From LEWIN_KOH_NICHOLAS_JOHN at lilly.com  Mon May 26 12:01:55 2003
From: LEWIN_KOH_NICHOLAS_JOHN at lilly.com (LEWIN_KOH_NICHOLAS_JOHN@lilly.com)
Date: Mon, 26 May 2003 18:01:55 +0800
Subject: [R] lme: cannot allocate vector
Message-ID: <OFDCD2036E.FE0948EF-ON48256D32.00363342@ap.lilly.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030526/7cecc7e5/attachment.pl

From ripley at stats.ox.ac.uk  Mon May 26 12:37:37 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 26 May 2003 11:37:37 +0100 (BST)
Subject: [R] lme: cannot allocate vector
In-Reply-To: <OFDCD2036E.FE0948EF-ON48256D32.00363342@ap.lilly.com>
Message-ID: <Pine.LNX.4.44.0305261134500.6838-100000@gannet.stats>

On Mon, 26 May 2003 LEWIN_KOH_NICHOLAS_JOHN at lilly.com wrote:

> Hi,
> I am trying to fit a linear mixed effects model (lme) with a variance 
> covariance matrix that has 148248^2 entries. I get the error message: 
> error: cannot allocate vector of size 2243241 kb
> 
> However, I am running this on a sun sparc (solaris 2.8) with 20GB of ram, 
> using R 1.7
> Is this a hard limit I am reaching or does this have to do with how sun 
> segments memory?

Did you build a 64-bit version of R (see the R-admin manual)?  If not, 
you are limited to 4Gb total, and that's the likely explanation.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dmurdoch at pair.com  Mon May 26 13:04:38 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon, 26 May 2003 07:04:38 -0400
Subject: [R] building zip?
In-Reply-To: <x24r3igh99.fsf@biostat.ku.dk>
References: <18D602BD42B7E24EB810D6454A58DB90047303B6@ibfftce505.is.de.dresdnerkb.com>
	<16081.56491.621733.9294@ksys.rug.ac.be>
	<x24r3igh99.fsf@biostat.ku.dk>
Message-ID: <qts3dv8g0dutt8u8pv63ee73c9r1dotl8m@4ax.com>

On 26 May 2003 12:00:02 +0200, you wrote:

>However, with the user-friendly installer, you select everythings up
>front, and it has become much more difficult to add things to an
>installation (why does "user-friendliness" always make something
>harder?).

It's not hard at all:  just re-install, changing the install options.
(It's harder to delete a component from an installation, but it always
has been.  To do that you need to uninstall before you re-install
everything.)  

Maybe instructions for this need to be added to the FAQ?

Duncan



From p.dalgaard at biostat.ku.dk  Mon May 26 13:22:49 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon, 26 May 2003 11:22:49 -0000
Subject: [R] building zip?
In-Reply-To: <qts3dv8g0dutt8u8pv63ee73c9r1dotl8m@4ax.com>
References: <18D602BD42B7E24EB810D6454A58DB90047303B6@ibfftce505.is.de.dresdnerkb.com>
	<16081.56491.621733.9294@ksys.rug.ac.be>
	<x24r3igh99.fsf@biostat.ku.dk>
	<qts3dv8g0dutt8u8pv63ee73c9r1dotl8m@4ax.com>
Message-ID: <x2r86meyka.fsf@biostat.ku.dk>

Duncan Murdoch <dmurdoch at pair.com> writes:

> On 26 May 2003 12:00:02 +0200, you wrote:
> 
> >However, with the user-friendly installer, you select everythings up
> >front, and it has become much more difficult to add things to an
> >installation (why does "user-friendliness" always make something
> >harder?).
> 
> It's not hard at all:  just re-install, changing the install options.
> (It's harder to delete a component from an installation, but it always
> has been.  To do that you need to uninstall before you re-install
> everything.)  

Yes, but you have to download again if you removed the rwXXXX.exe
file, and if you modified the installation in other ways, the
modifications may get overwritten. So users may spend some time
realising that this really is the way to do it...
 
> Maybe instructions for this need to be added to the FAQ?

Could well be.


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From tord.snall at ebc.uu.se  Mon May 26 13:54:07 2003
From: tord.snall at ebc.uu.se (Tord Snall)
Date: Mon, 26 May 2003 13:54:07 +0200
Subject: [R] as.matrix() problem in mantel.test()?
Message-ID: <3.0.6.32.20030526135407.00db69a0@mail.anst.uu.se>

Dear all,

I get an unexpected error when using the mantel.test function in
library(ape). Is there something wrong with my matrices?

> dmatr<- read.table("obt.Loiselle.kinship.intens02.DIST.matrix.txt",head=F)
> kmatr<-
read.table("obt.Loiselle.kinship.intens02.KINSHIP.matrix.txt",head=F)
> 
> mantel.test(as.matrix(kmatr), as.matrix(dmatr), nperm = 500, graph = T)
Error in var(x, na.rm = na.rm) : `x' is empty
> 
> is.matrix(as.matrix(dmatr))
[1] TRUE
> is.matrix(as.matrix(kmatr))
[1] TRUE
> 
> as.matrix(dmatr[1:5,1:5])
         V1        V2       V3       V4       V5
1        NA   39.9625 223.1820 258.3800 1085.030
2   39.9625        NA 191.3660 224.1090 1084.730
3  223.1820  191.3660       NA  41.8808  972.544
4  258.3800  224.1090  41.8808       NA  981.315
5 1085.0300 1084.7300 972.5440 981.3150       NA
> as.matrix(kmatr[1:5,1:5])
       V1      V2      V3      V4      V5
1      NA -0.0892 -0.3284 -0.0692  0.1895
2 -0.0892      NA  0.1404  0.2367 -0.1888
3 -0.3284  0.1404      NA -0.0025 -0.3629
4 -0.0692  0.2367 -0.0025      NA -0.1689
5  0.1895 -0.1888 -0.3629 -0.1689      NA


Thanks in advance!


Sincerely,
Tord

-----------------------------------------------------------------------
Tord Sn?ll
Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
Villav?gen 14			
SE-752 36 Uppsala, Sweden
Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
E-mail: Tord.Snall at ebc.uu.se
Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!



From bitwrit at ozemail.com.au  Mon May 26 14:17:33 2003
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Mon, 26 May 2003 22:17:33 +1000
Subject: [R] help output paged in separate window
In-Reply-To: <XFMail.030524203021.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.030524203021.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <20030526121920.IETJ16123.mta07.mail.mel.aone.net.au@there>

Ted Harding wrote:
> Hi folks,
>
> I use R in X windows on Linux.
>
> Normally, I use 'less' as pager, which is fine for scanning through
> 'help' (or '?') output in the R window itself; the help session is
> terminated by typing "q", as usual for 'less', and the R window then
> reverts to the R command line interface.
>
> Often, I would like to have the output from 'help' pop up in a separate
> window so that I can continue to work in the R window while reading the
> help. The "help" window could then be closed when interest in this
> particular help dwindles.
>
> What can I set $PAGER to, to achieve this? Or should it be done in a
> different way (e.g. using some option to 'help' or to 'file.show')?
>
> (I don't want to use 'help.start' because of the overhead of using
> an HTML browser)
>
Well, here is a little function derived from the help browser macro I 
wrote for NEdit that will fire up an xterm with less displaying the help 
for a function. I haven't accounted for operators, but it could be done, 
and I haven't extensively tested it, but I suppose I shouldn't expect to 
have all the fun...

Jim

helpless<-function(topic) {
 topic<-substitute(topic)
 sys.command<-paste("locate ",topic,sep="",collapse="")
 helpfilelist<-system(sys.command,TRUE)
 helpmatch<-paste("help/",topic,sep="",collapse="")
 # find the R text help file(s)
 helpfile<-helpfilelist[grep(helpmatch,helpfilelist)]
 # assume that the shortest name matching "topic" will be the one
 if(length(helpfile) > 1)
  helpfile<-helpfile[which.min(nchar(helpfile))]
 sys.command<-paste("xterm -e less ",helpfile,sep="",collapse="")
 system(sys.command)
}



From ida.scheel at nr.no  Mon May 26 15:13:30 2003
From: ida.scheel at nr.no (Ida Scheel)
Date: Mon, 26 May 2003 15:13:30 +0200
Subject: [R] Problem with a 64bit R on HP-UX]
Message-ID: <3ED212FA.5070703@nr.no>

  Greetings,

We are trying to compile a 64bit version of R (1.7.0) on HP-UX (11.11),
but are running into some problems.

The following relevant filesets are installed:

B3901BA B.11.11.04 HP C/ANSI C Developer's
Bundle for HP-UX 11.i (S800)
B3909DB B.11.11.60 HP Fortran 90 Compiler
and associated products (S800)
B3913DB C.03.33.01 HP aC++ Compiler (S800)

This is our configure step:

./configure --prefix=/site/R-1.7.0 CC="cc" CFLAGS="+O2 +DD64" \
CXX="aCC" CXXFLAGS="+O2 +DD64" \
FC="f90" F77="f90" FFLAGS="+O2 +DD64" \
LD="f90" LDFLAGS="+DD64" \
--without-jpeglib --without-libpng

This steps seems to end ok:

R is now configured for hppa2.0w-hp-hpux11.11

Source directory: .
Installation directory: /site/R-1.7.0

C compiler: cc +O2 +DD64
C++ compiler: aCC +O2 +DD64
Fortran compiler: f90 +O2 +DD64

Interfaces supported: X11
External libraries:
Additional capabilities: bzip2, PCRE
Options enabled:

Recommended packages: yes

configure: WARNING: I could not determine SHLIB_CXXLDFLAGS
configure: WARNING: you cannot build DVI versions of the R manuals
configure: WARNING: you cannot build info versions of the R manuals
configure: WARNING: you cannot build PDF versions of the R manuals


When trying to compile, I get this:

cc -Wp,-H16000 -I. -I../../../src/include -I../../../src/include
-I/local/X11R6/include -I/usr/local/include -DHAVE_CONFIG_H +Z +O2
+DD64 -c rbitmap.c -o rbitmap.lo
ld -b -Bsymbolic +DD64 -o R_X11.sl dataentry.lo devX11.lo
rotated.lo rbitmap.lo -lSM -lICE -L/local/X11R6/lib -lX11 -lnsl -ldl -lm
ld: Unrecognized argument: +DD64
Fatal error.
*** Error exit code 1

Using the f90 linker makes it link ok, but the generated R executable
does not run. How should we set the linker for the generation of 64bit
shared libraries (if that is the problem)?


Best Regards

Andreas



From eric.esposito at gazdefrance.com  Mon May 26 16:40:20 2003
From: eric.esposito at gazdefrance.com (Eric ESPOSITO)
Date: Mon, 26 May 2003 15:40:20 +0100
Subject: [R] xyplot with several pages
Message-ID: <OF7EFF2F93.945B633E-ON41256D32.004FBF96@notes.edfgdf.fr>

I'm sorry to ask such a stupid question, but I didn't find how to plot each
page with the function xyplot on a separate graphic device in order to have
all the pages opened after calling the function.
When doing:
> data(quakes)
> Depth <- equal.count(quakes$depth, number=8, overlap=.1)
> xyplot(lat ~ long | Depth, data = quakes, layout=c(2,2))
2 pages are drawn but the second page overwrites the first one, does
anybody know how to plot the graphs on 2 separate devices?

Eric Esposito



From jfox at mcmaster.ca  Mon May 26 16:27:53 2003
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 26 May 2003 10:27:53 -0400
Subject: [R] new cross-platform basic-statistics GUI
Message-ID: <5.1.0.14.2.20030526102510.01ea68e0@mcmail.cis.mcmaster.ca>

Dear R-announce list members,

I've submitted a new package to CRAN, Rcmdr, which provides a 
cross-platform basic-statistics GUI for R. Rcmdr is based on the tcltk 
package and uses only standard Tk widgets. It therefore runs under Windows 
if Tcl/Tk support is installed with R, although it requires the 
single-document interface (SDI). I've tested Rcmdr with Windows and Red Hat 
Linux; others have reported that it works on other Linux/Unix and Macintosh 
systems (the latter under X11).

The R-Commander GUI consists of a window containing several menus, buttons, 
and information fields. The Commander window also contains a log/script 
box. The R-Commander menus are easily configurable through a text file. The 
menu tree and additional information are available at 
<http://www.socsci.mcmaster.ca/jfox/Misc/Rcmdr/>.

The menus lead to simple dialog boxes, the general contents of which are 
more or less obvious from the names of the menu items. These boxes have a 
common structure, including a help button leading to the help page for a 
relevant function.

Commands generated via dialogs are posted to the R session window, along 
with printed output, and to the log window. Lines in the log window may be 
edited and (re)submitted for execution. Logs can be saved and reloaded.

My object in designing and implementing this GUI was to cover the content 
of a basic-statistics course. The target text was Moore's The Basic 
Practice of Statistics, Second Edition (Freeman, 2000), which is the text 
that I currently use for a two-semester introduction to statistics for 
undergraduate sociology majors. The R Commander implements the content of 
this text plus some additional material (e.g., linear and generalized 
linear models). As a result of several suggestions that I received, the 
coverage is now larger than originally envisaged, and I'm happy to 
entertain suggestions for further additions -- keeping in mind, however, 
the intended limited scope of the project.

Until the package appears on CRAN, you can download the package source and 
a Windows binary from my web site. The Rcmdr package mostly uses functions 
in the base and recommended packages; it also uses some functions in my car 
package.

John

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From baron at psych.upenn.edu  Mon May 26 17:55:41 2003
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Mon, 26 May 2003 11:55:41 -0400
Subject: [R] "Tcl/Tk support is not available on this system, " RH 9,
	R 1.7.0-1
Message-ID: <20030526155541.GA4598@mail1.sas.upenn.edu>

In trying to run John Fox's new Rcmdr package on Redhat Linux 9,
I got this error message.  The problem is in loading the tclck
library.  library(tcltk) produces the same error.  It has been
discussed before, e.g.,
http://finzi.psych.upenn.edu/R/Rhelp02/archive/11898.html but
with respect to earlier versions of Linux and R.
I tried updating to the latest RPMs of tcl and tk (8.3.5-89), but
that didn't help.  Otherwise I just have the standard RH9
installation.  Has anyone gotten tcltk to work on RH9?

Jon



From gb at stat.umu.se  Mon May 26 18:17:36 2003
From: gb at stat.umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Mon, 26 May 2003 18:17:36 +0200 (CEST)
Subject: [R] "Tcl/Tk support is not available on this system, " RH 9, R
	1.7.0-1
In-Reply-To: <20030526155541.GA4598@mail1.sas.upenn.edu>
Message-ID: <Pine.LNX.4.44.0305261817110.29701-100000@tal.stat.umu.se>

On Mon, 26 May 2003, Jonathan Baron wrote:

> In trying to run John Fox's new Rcmdr package on Redhat Linux 9,
> I got this error message.  The problem is in loading the tclck
> library.  library(tcltk) produces the same error.  It has been
> discussed before, e.g.,
> http://finzi.psych.upenn.edu/R/Rhelp02/archive/11898.html but
> with respect to earlier versions of Linux and R.
> I tried updating to the latest RPMs of tcl and tk (8.3.5-89), but
> that didn't help.  Otherwise I just have the standard RH9
> installation.  Has anyone gotten tcltk to work on RH9?

Yes.

> 
> Jon
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
---
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se



From ripley at stats.ox.ac.uk  Mon May 26 18:17:05 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 26 May 2003 17:17:05 +0100 (BST)
Subject: [R] "Tcl/Tk support is not available on this system, " RH 9, R
	1.7.0-1
In-Reply-To: <20030526155541.GA4598@mail1.sas.upenn.edu>
Message-ID: <Pine.LNX.4.44.0305261710370.7791-100000@gannet.stats>

How did you install R?  `R-1.7.0-1' suggests a binary RPM, but we
shouldn't have to guess.

Tcl/Tk has to be present when R was configured.  My guess is that was not 
so when your R was configured (I think RH8.0 and 9 by default don't have 
Tcl/Tk, and never have the current 8.4.1).  In that case you need to build 
R yourself: always a good idea.

It isn't clear to the rest of us what options the builders of binary RPMs 
include, and it would be helpful if the summary given at the end of 
configure was available on CRAN.

On Mon, 26 May 2003, Jonathan Baron wrote:

> In trying to run John Fox's new Rcmdr package on Redhat Linux 9,
> I got this error message.  The problem is in loading the tclck
> library.  library(tcltk) produces the same error.  It has been
> discussed before, e.g.,
> http://finzi.psych.upenn.edu/R/Rhelp02/archive/11898.html but
> with respect to earlier versions of Linux and R.
> I tried updating to the latest RPMs of tcl and tk (8.3.5-89), but
> that didn't help.  Otherwise I just have the standard RH9
> installation.  Has anyone gotten tcltk to work on RH9?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From laurent.buffat at it-omics.com  Mon May 26 18:31:37 2003
From: laurent.buffat at it-omics.com (laurent  buffat)
Date: Mon, 26 May 2003 18:31:37 +0200
Subject: [R] callNextMethod & initialize & explicit parameters
In-Reply-To: <20030526155541.GA4598@mail1.sas.upenn.edu>
Message-ID: <DGEIIIMDDGKLGHFCOPOFMEJFCCAA.laurent.buffat@it-omics.com>


Hello,

I know that in general, it is better to call callNextMethod without
arguments,
and so the call is done with the current arguments, but I want explicitly
change the value of
a given argument, how can I do ?

See the code. Why is doesn't work ?

Thanks for your help

Laurent Buffat

///////////////////////

setClass("A", representation(a = "numeric"))

setMethod("initialize", "A", function(.Object, a=1, ...)

		   cat("initialize in A\n")
               .Object at a <- a
                return(.Object)
              })

setClass("B", representation(b = "numeric"),contains=c("A"))

setMethod("initialize", "B", function(.Object, a=1,  b=2, ...)

	    {
	      a.init <- b*b # or something more complexe ...
	      .Object <- callNextMethod(.Object,a=a.init, ...)
	      .Object at b <- b
              return(.Object)
            })



x <-new("B")

/////////////////// error with new("B").
# The evaluation of "a=a.init" is done in the environment of initialize,A,
and a.init doesn't exist
# in this environment ...

initialize in A
Error in .local(.Object, ...) : Object "a.init" not found



From jfox at mcmaster.ca  Mon May 26 18:39:33 2003
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 26 May 2003 12:39:33 -0400
Subject: [R] "Tcl/Tk support is not available on this system, " RH
	9, R 1.7.0-1
In-Reply-To: <20030526155541.GA4598@mail1.sas.upenn.edu>
Message-ID: <5.0.2.1.0.20030526123628.00b08d38@mcmail.cis.mcmaster.ca>

Dear Jonathan,

To clarify, I have verified that the Rcmdr package works under Linux 7.0 
(after some updating). I'm an infrequent user of Linux, so have not 
upgraded my operating system.

I hope that someone else will have a solution, since it's my goal to have 
Rcmdr work as broadly as possible.

Thanks for the report,
  John

At 11:55 AM 5/26/2003 -0400, Jonathan Baron wrote:
>In trying to run John Fox's new Rcmdr package on Redhat Linux 9,
>I got this error message.  The problem is in loading the tclck
>library.  library(tcltk) produces the same error.  It has been
>discussed before, e.g.,
>http://finzi.psych.upenn.edu/R/Rhelp02/archive/11898.html but
>with respect to earlier versions of Linux and R.
>I tried updating to the latest RPMs of tcl and tk (8.3.5-89), but
>that didn't help.  Otherwise I just have the standard RH9
>installation.  Has anyone gotten tcltk to work on RH9?
>
>Jon
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help

____________________________
John Fox
Department of Sociology
McMaster University
email: jfox at mcmaster.ca
web: http://www.socsci.mcmaster.ca/jfox



From luke at stat.uiowa.edu  Mon May 26 19:27:48 2003
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Mon, 26 May 2003 12:27:48 -0500 (CDT)
Subject: [R] Problem with a 64bit R on HP-UX]
In-Reply-To: <3ED212FA.5070703@nr.no>
Message-ID: <Pine.LNX.4.44.0305261148090.5107-100000@itasca2.stat.uiowa.edu>

Quick and very dirty solution that seems to sort of work for me:
configure as you do, then

	gmake

until it fails, then

	gmake LDFLAGS=""

until that fails.  At this point you should have a working base R.
Linking with f90 or cc seems to need +DD64, but direct linking with ld
does not (ld seems to try 64 bit if any objects are 64 bit).

Now do

	env R_LD_LIBRARY_PATH=`pwd`/bin gmake LDFLAGS=""

This final step is needed because the bin/R shell script is not able
to install source packages with compiled code and so installing the
recommended packages fails.  The problem seems to be with setting of
SHLIB_PATH in bin/R: it sets the 64-bit locations, but this confuses
some part of the cc chain that is still 32-bit.

I also get the message

/usr/lib/pa20_64/dld.sl: Unable to find library '/usr/lib/nls/loc/pa20_64/locales.2/C'.

on startup; doesn't seem to be fatal though (but it does cause make
check to fail).

We need to clean this up, but as this is very much a minority platform
I'm not sure how soon anyone will get to it.  Help is of course
welcome...

luke

On Mon, 26 May 2003, Ida Scheel wrote:

>   Greetings,
> 
> We are trying to compile a 64bit version of R (1.7.0) on HP-UX (11.11),
> but are running into some problems.
> 
> The following relevant filesets are installed:
> 
> B3901BA B.11.11.04 HP C/ANSI C Developer's
> Bundle for HP-UX 11.i (S800)
> B3909DB B.11.11.60 HP Fortran 90 Compiler
> and associated products (S800)
> B3913DB C.03.33.01 HP aC++ Compiler (S800)
> 
> This is our configure step:
> 
> ./configure --prefix=/site/R-1.7.0 CC="cc" CFLAGS="+O2 +DD64" \
> CXX="aCC" CXXFLAGS="+O2 +DD64" \
> FC="f90" F77="f90" FFLAGS="+O2 +DD64" \
> LD="f90" LDFLAGS="+DD64" \
> --without-jpeglib --without-libpng
> 
> This steps seems to end ok:
> 
> R is now configured for hppa2.0w-hp-hpux11.11
> 
> Source directory: .
> Installation directory: /site/R-1.7.0
> 
> C compiler: cc +O2 +DD64
> C++ compiler: aCC +O2 +DD64
> Fortran compiler: f90 +O2 +DD64
> 
> Interfaces supported: X11
> External libraries:
> Additional capabilities: bzip2, PCRE
> Options enabled:
> 
> Recommended packages: yes
> 
> configure: WARNING: I could not determine SHLIB_CXXLDFLAGS
> configure: WARNING: you cannot build DVI versions of the R manuals
> configure: WARNING: you cannot build info versions of the R manuals
> configure: WARNING: you cannot build PDF versions of the R manuals
> 
> 
> When trying to compile, I get this:
> 
> cc -Wp,-H16000 -I. -I../../../src/include -I../../../src/include
> -I/local/X11R6/include -I/usr/local/include -DHAVE_CONFIG_H +Z +O2
> +DD64 -c rbitmap.c -o rbitmap.lo
> ld -b -Bsymbolic +DD64 -o R_X11.sl dataentry.lo devX11.lo
> rotated.lo rbitmap.lo -lSM -lICE -L/local/X11R6/lib -lX11 -lnsl -ldl -lm
> ld: Unrecognized argument: +DD64
> Fatal error.
> *** Error exit code 1
> 
> Using the f90 linker makes it link ok, but the generated R executable
> does not run. How should we set the linker for the generation of 64bit
> shared libraries (if that is the problem)?
> 
> 
> Best Regards
> 
> Andreas
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Luke Tierney
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
   Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu



From brising at louisville.edu  Mon May 26 19:39:23 2003
From: brising at louisville.edu (Bill Rising)
Date: Mon, 26 May 2003 13:39:23 -0400
Subject: [R] spinning and flipping arrays
Message-ID: <200305261739.h4QHdmMn012014@hypatia.math.ethz.ch>

Hello people,

Is there some simple way of spinning and/or flipping arrays in R? 
Here's what I mean.

Suppose that foo is a 2x3x4 array with the following contents: (I know 
this is different than typing 'foo' at and R prompt, but I'm so used to 
row major order from using APL, I have a hard time with R's output)

> foo[1,,]
     [,1] [,2] [,3] [,4]
[1,]    1    2    3    4
[2,]    5    6    7    8
[3,]    9   10   11   12

> foo[2,,]
     [,1] [,2] [,3] [,4]
[1,]   13   14   15   16
[2,]   17   18   19   20
[3,]   21   22   23   24

flipping foo around its last coordinate would be done via

> flipfoo <- foo[,,4:1]

> flipfoo[1,,]
     [,1] [,2] [,3] [,4]
[1,]    4    3    2    1
[2,]    8    7    6    5
[3,]   12   11   10    9
> flipfoo[2,,]
     [,1] [,2] [,3] [,4]
[1,]   16   15   14   13
[2,]   20   19   18   17
[3,]   24   23   22   21

(a more general method would allow specifying the axis around which to 
reverse the subscripts)

spinning corresponds to shifting the coordinates by possibly different 
amounts along one axis.

I need these to manipulate a dataset, and have been tearing my hair out 
for a day and a half trying to figure out how to do it in R. Matlab has a 
few user-written utilities. APL has it built in as an operator. R 
*should* be able to do it, but I'm too new to R to figure it out. It 
could be easily done in general by any number of ways if only I could 
figure out how to turn a string (like ",,4:1") into the argument for "[". 
Nothing I've tried or searched for works, but I suspect I'm being a bit 
obtuse.

Thanks for any and all hints.

Bill



From christoph.lehmann at gmx.ch  Mon May 26 19:50:11 2003
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Mon, 26 May 2003 17:50:11 -0000
Subject: [R] receiver operating characteristic (ROC)
Message-ID: <1053971272.1208.5.camel@christophl>

Hi dear R users

For assessing the quality of my discriminant analysis I am looking for a

    receiver operating characteristic (ROC) (from transmission theory)

curve, implemented in/with R.

Does anybody know, where I can find this?

Thanks a lot

Christoph
-- 
Christoph Lehmann <christoph.lehmann at gmx.ch>



From MSchwartz at medanalytics.com  Mon May 26 19:54:27 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Mon, 26 May 2003 17:54:27 -0000
Subject: [R] "Tcl/Tk support is not available on this system, " RH 9, R
	1.7.0-1
In-Reply-To: <Pine.LNX.4.44.0305261710370.7791-100000@gannet.stats>
References: <Pine.LNX.4.44.0305261710370.7791-100000@gannet.stats>
Message-ID: <1053971647.5856.84.camel@localhost>

Prof. Baron,

Run:

rpm -qa | grep tcl

and

rpm -qa | grep tk

in a console and look for the following from the first and second
outputs respectively:

tcl-8.3.5-88
tk-8.3.5-88

The above are the latest versions of tcl and tk "officially" released by
RH for 9, though if you installed new RPMs as you indicate below, you'll
get the versions reported from them.

Depending upon what type of install you did with RH 9, you may or may
not have had these prior to installing R.  As Prof. Ripley pointed out,
these need to be present when you installed the R 1.7.0 RPM.

I just installed Rcmdr on my RH 9 system and it works fine (albeit only
during a first look with no extensive testing), so my guess is that you
are or were missing the tcl/tk packages when you installed R. Be aware
that you also need the "car" package installed from CRAN for Rcmdr.

You may need to remove R 1.7.0 and reinstall it with the RH tcl/tk
packages present.

I am going to be at my computer somewhat infrequently today, but if I
can be of help, let me know.

HTH,

Marc Schwartz

P.S. to Prof. Fox: Unless I missed it, you may wish to consider having
an adjustment for the font size on the menus. When using
options(Rcmdr.fontsize = XX), it affected the log window size, but not
the menu fonts, which on my 1600 x 1200 lcd panel are on the smallish
side.


On Mon, 2003-05-26 at 11:17, Prof Brian Ripley wrote:
> How did you install R?  `R-1.7.0-1' suggests a binary RPM, but we
> shouldn't have to guess.
> 
> Tcl/Tk has to be present when R was configured.  My guess is that was not 
> so when your R was configured (I think RH8.0 and 9 by default don't have 
> Tcl/Tk, and never have the current 8.4.1).  In that case you need to build 
> R yourself: always a good idea.
> 
> It isn't clear to the rest of us what options the builders of binary RPMs 
> include, and it would be helpful if the summary given at the end of 
> configure was available on CRAN.
> 
> On Mon, 26 May 2003, Jonathan Baron wrote:
> 
> > In trying to run John Fox's new Rcmdr package on Redhat Linux 9,
> > I got this error message.  The problem is in loading the tclck
> > library.  library(tcltk) produces the same error.  It has been
> > discussed before, e.g.,
> > http://finzi.psych.upenn.edu/R/Rhelp02/archive/11898.html but
> > with respect to earlier versions of Linux and R.
> > I tried updating to the latest RPMs of tcl and tk (8.3.5-89), but
> > that didn't help.  Otherwise I just have the standard RH9
> > installation.  Has anyone gotten tcltk to work on RH9?



From f.mattes at rfc.ucl.ac.uk  Mon May 26 20:38:41 2003
From: f.mattes at rfc.ucl.ac.uk (Frank Mattes)
Date: Mon, 26 May 2003 19:38:41 +0100
Subject: [R] help with subset(), still original dataframe in tapply
Message-ID: <p05200f00baf80a888472@[128.40.218.142]>

Dear R-help reader,

it would be great if someone knows what I'm doing wrong.
I have (shorten) dataframe, which consists of  a group identification 
and a number

>ex
         UID   REL
1  R1.B8.31 0.000
2  R1.B8.31 0.000
3  R1.B8.31 0.000
4  R1.B8.31 0.000
5  R1.B8.38 0.010
6  R1.B8.38 0.060
7  R1.B8.38 0.006
8  R1.B8.38 0.010
9  R1.B8.48 0.080
10 R1.B8.48    NA
11 R1.B8.48 0.006

I'm creating now a subset missing the values 0 and "NA"
>  newex<-subset(ex,ex$REL>0)
>  newex
         UID   REL
5  R1.B8.38 0.010
6  R1.B8.38 0.060
7  R1.B8.38 0.006
8  R1.B8.38 0.010
9  R1.B8.48 0.080
11 R1.B8.48 0.006

and now would like to apply the mean to each group in (UID)

>  tapply(newex$REL,newex$UID,mean,rm.na=T)
R1.B8.31 R1.B8.38 R1.B8.48
       NA   0.0215   0.0430

to my surprise, I still have the mean for group R1.B8.31, which has 
been removed by the subset function before.

I can remove the NA by

  tapply(newex$REL,interaction(newex$UID,drop=T),mean,rm.na=T)

but I would like to know why the tapply still uses the original dataframe.

Many thanks for your help

Frank
-- 
Frank Mattes, 				e-mail:	f.mattes at ucl.ac.uk
Department of Virology			fax	0044(0)207 8302854
Royal Free Hospital and 			tel	0044(0)207 8302997
University College Medical School
London



From p.dalgaard at biostat.ku.dk  Mon May 26 20:53:44 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon, 26 May 2003 18:53:44 -0000
Subject: [R] help with subset(), still original dataframe in tapply
In-Reply-To: <p05200f00baf80a888472@[128.40.218.142]>
References: <p05200f00baf80a888472@[128.40.218.142]>
Message-ID: <x2wugda5yo.fsf@biostat.ku.dk>

Frank Mattes <f.mattes at rfc.ucl.ac.uk> writes:

> I'm creating now a subset missing the values 0 and "NA"
> >  newex<-subset(ex,ex$REL>0)
> >  newex
>          UID   REL
> 5  R1.B8.38 0.010
> 6  R1.B8.38 0.060
> 7  R1.B8.38 0.006
> 8  R1.B8.38 0.010
> 9  R1.B8.48 0.080
> 11 R1.B8.48 0.006
> 
> and now would like to apply the mean to each group in (UID)
> 
> >  tapply(newex$REL,newex$UID,mean,rm.na=T)
> R1.B8.31 R1.B8.38 R1.B8.48
>        NA   0.0215   0.0430
> 
> to my surprise, I still have the mean for group R1.B8.31, which has
> been removed by the subset function before.

A subset of a three-level factor is still a three-level factor. If you
want it to become a factor with only those levels that are present in
data, you need to say so, e.g. with

tapply(newex$REL,factor(newex$UID),mean)
 
> but I would like to know why the tapply still uses the original dataframe.

It doesn't.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From spencer.graves at pdf.com  Mon May 26 21:05:52 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 26 May 2003 12:05:52 -0700
Subject: [R] spinning and flipping arrays
References: <200305261739.h4QHdmMn012014@hypatia.math.ethz.ch>
Message-ID: <3ED26590.1080409@pdf.com>

	  I know of no single function to do this;  perhaps someone else does. 
  I don't have time to write and debug functions to do this myself, but 
it should be easy enough to write functions like the following:

flip3 <-
function(x){
   n3 <- dim(x)[3]
   x[,,n3:1]
}
spin3 <-
function(x, k=1){
   n3 <- dim(x)[3]
   x[,,1+(((1+k):(n3+k))%%n3)]
}

With a little more work, I could generate functions that would do this 
for any dimension of arrays with any number of dimensions.  To do that, 
I might have to compute S-Plus commands using "cmd <- paste(...)" and 
then execute them using "eval(parse(text=cmd))".

	  Perhaps someone else will reply with a more complete and elegant 
solution.  Until then, I hope this helps.

spencer graves

Bill Rising wrote:
> Hello people,
> 
> Is there some simple way of spinning and/or flipping arrays in R? 
> Here's what I mean.
> 
> Suppose that foo is a 2x3x4 array with the following contents: (I know 
> this is different than typing 'foo' at and R prompt, but I'm so used to 
> row major order from using APL, I have a hard time with R's output)
> 
> 
>>foo[1,,]
> 
>      [,1] [,2] [,3] [,4]
> [1,]    1    2    3    4
> [2,]    5    6    7    8
> [3,]    9   10   11   12
> 
> 
>>foo[2,,]
> 
>      [,1] [,2] [,3] [,4]
> [1,]   13   14   15   16
> [2,]   17   18   19   20
> [3,]   21   22   23   24
> 
> flipping foo around its last coordinate would be done via
> 
> 
>>flipfoo <- foo[,,4:1]
> 
> 
>>flipfoo[1,,]
> 
>      [,1] [,2] [,3] [,4]
> [1,]    4    3    2    1
> [2,]    8    7    6    5
> [3,]   12   11   10    9
> 
>>flipfoo[2,,]
> 
>      [,1] [,2] [,3] [,4]
> [1,]   16   15   14   13
> [2,]   20   19   18   17
> [3,]   24   23   22   21
> 
> (a more general method would allow specifying the axis around which to 
> reverse the subscripts)
> 
> spinning corresponds to shifting the coordinates by possibly different 
> amounts along one axis.
> 
> I need these to manipulate a dataset, and have been tearing my hair out 
> for a day and a half trying to figure out how to do it in R. Matlab has a 
> few user-written utilities. APL has it built in as an operator. R 
> *should* be able to do it, but I'm too new to R to figure it out. It 
> could be easily done in general by any number of ways if only I could 
> figure out how to turn a string (like ",,4:1") into the argument for "[". 
> Nothing I've tried or searched for works, but I suspect I'm being a bit 
> obtuse.
> 
> Thanks for any and all hints.
> 
> Bill
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From brising at louisville.edu  Mon May 26 21:13:01 2003
From: brising at louisville.edu (Bill Rising)
Date: Mon, 26 May 2003 15:13:01 -0400
Subject: [R] spinning and flipping arrays
Message-ID: <200305261913.h4QJDQMn002131@hypatia.math.ethz.ch>

On 5/26/2003 15:05, Spencer Graves wrote

>	  I know of no single function to do this;  perhaps someone else does. 
>  I don't have time to write and debug functions to do this myself, but 
>it should be easy enough to write functions like the following:
>
>flip3 <-
>function(x){
>   n3 <- dim(x)[3]
>   x[,,n3:1]
>}
>spin3 <-
>function(x, k=1){
>   n3 <- dim(x)[3]
>   x[,,1+(((1+k):(n3+k))%%n3)]
>}

These are pretty much what I'd figured out...

>
>With a little more work, I could generate functions that would do this 
>for any dimension of arrays with any number of dimensions.  To do that, 
>I might have to compute S-Plus commands using "cmd <- paste(...)" and 
>then execute them using "eval(parse(text=cmd))".

This last piece is what I think I needed. I had been trying to just put 
the 
/argument/ to the "[" command together, instead of putting together the 
entire command.

Thanks for the tip. I'll keep working on it.
Bill



From jmc at research.bell-labs.com  Mon May 26 21:55:20 2003
From: jmc at research.bell-labs.com (John Chambers)
Date: Mon, 26 May 2003 15:55:20 -0400
Subject: [R] callNextMethod & initialize & explicit parameters
References: <DGEIIIMDDGKLGHFCOPOFMEJFCCAA.laurent.buffat@it-omics.com>
Message-ID: <3ED27128.6909737E@research.bell-labs.com>

laurent buffat wrote:
> 
> Hello,
> 
> I know that in general, it is better to call callNextMethod without
> arguments,
> and so the call is done with the current arguments, but I want explicitly
> change the value of
> a given argument, how can I do ?
> 
> See the code. Why is doesn't work ?

You are combining two "nonstandard" mechanisms here that currently don't
quite manage to work together:

1- methods that have different formal argument lists from the generic
function (argument "a", for example).

2- callNextMethod with explicit arguments that use local variables
computed in the current method.

To implement mechanism 1, a local function is created during
setMethod(), and the actual method calls this local function.  The
callNextMethod code tries to take account of these local functions, but
in this case doesn't succeed.  We should be able to fix it.

Meanwhile, a workaround would be to insert the local information
explicitly, replacing callNextMethod(.Object,a=a.init, ...) in the
method for class "B" with two lines such as:
              .Object <- callNextMethod()
              .Object at a <- a.init

(Your example may be a bit exotic for R-help.  intialize() methods and
callNextMethod() are extensions to the "Programming with Data"
description.  Since the details are still being worked out, the R-devel
list might be a better forum.   Also, as a note on portability to
S-Plus:  it currently doesn't have them.)

> 
> Thanks for your help
> 
> Laurent Buffat
> 
> ///////////////////////
> 
> setClass("A", representation(a = "numeric"))
> 
> setMethod("initialize", "A", function(.Object, a=1, ...)
> 
>                    cat("initialize in A\n")
>                .Object at a <- a
>                 return(.Object)
>               })
> 
> setClass("B", representation(b = "numeric"),contains=c("A"))
> 
> setMethod("initialize", "B", function(.Object, a=1,  b=2, ...)
> 
>             {
>               a.init <- b*b # or something more complexe ...
>               .Object <- callNextMethod(.Object,a=a.init, ...)
>               .Object at b <- b
>               return(.Object)
>             })
> 
> x <-new("B")
> 
> /////////////////// error with new("B").
> # The evaluation of "a=a.init" is done in the environment of initialize,A,
> and a.init doesn't exist
> # in this environment ...
> 
> initialize in A
> Error in .local(.Object, ...) : Object "a.init" not found
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
John M. Chambers                  jmc at bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc



From Ted.Harding at nessie.mcc.ac.uk  Mon May 26 21:03:42 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Mon, 26 May 2003 20:03:42 +0100 (BST)
Subject: [R] help output paged in separate window
In-Reply-To: <20030526121920.IETJ16123.mta07.mail.mel.aone.net.au@there>
Message-ID: <XFMail.030526200341.Ted.Harding@nessie.mcc.ac.uk>

On 26-May-03 Jim Lemon wrote:
> Well, here is a little function derived from the help browser macro I 
> wrote for NEdit that will fire up an xterm with less displaying the
> help for a function.
> Jim
> 
> helpless<-function(topic) {
>  topic<-substitute(topic)
>  sys.command<-paste("locate ",topic,sep="",collapse="")
>  helpfilelist<-system(sys.command,TRUE)
>  helpmatch<-paste("help/",topic,sep="",collapse="")
>  # find the R text help file(s)
>  helpfile<-helpfilelist[grep(helpmatch,helpfilelist)]
>  # assume that the shortest name matching "topic" will be the one
>  if(length(helpfile) > 1)
>   helpfile<-helpfile[which.min(nchar(helpfile))]
>  sys.command<-paste("xterm -e less ",helpfile,sep="",collapse="")
>  system(sys.command)
> }

Well that's neat! I must study it and learn some of the tricks.
They look useful. The only thing I have against it is that it
doesn't detach from the R window, unlike tkpager which conveniently
does, so it's not possible to continue working in R while reading
help (leaving one as it were helpless ... ).

Thanks, and best wishes,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 26-May-03                                       Time: 20:03:41
------------------------------ XFMail ------------------------------



From spencer.graves at pdf.com  Mon May 26 22:19:27 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 26 May 2003 13:19:27 -0700
Subject: [R] spinning and flipping arrays
References: <200305261913.h4QJDQMn002131@hypatia.math.ethz.ch>
Message-ID: <3ED276CF.6080206@pdf.com>

You may also be interested in "aperm", which permutes the indices of an 
array.  Thus, t(x) is the same as aperm(x, 2:1).

spencer graves

Bill Rising wrote:
> On 5/26/2003 15:05, Spencer Graves wrote
> 
> 
>>	  I know of no single function to do this;  perhaps someone else does. 
>> I don't have time to write and debug functions to do this myself, but 
>>it should be easy enough to write functions like the following:
>>
>>flip3 <-
>>function(x){
>>  n3 <- dim(x)[3]
>>  x[,,n3:1]
>>}
>>spin3 <-
>>function(x, k=1){
>>  n3 <- dim(x)[3]
>>  x[,,1+(((1+k):(n3+k))%%n3)]
>>}
> 
> 
> These are pretty much what I'd figured out...
> 
> 
>>With a little more work, I could generate functions that would do this 
>>for any dimension of arrays with any number of dimensions.  To do that, 
>>I might have to compute S-Plus commands using "cmd <- paste(...)" and 
>>then execute them using "eval(parse(text=cmd))".
> 
> 
> This last piece is what I think I needed. I had been trying to just put 
> the 
> /argument/ to the "[" command together, instead of putting together the 
> entire command.
> 
> Thanks for the tip. I'll keep working on it.
> Bill
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From dcum007 at ec.auckland.ac.nz  Mon May 26 22:45:44 2003
From: dcum007 at ec.auckland.ac.nz (dcum007@ec.auckland.ac.nz)
Date: Tue, 27 May 2003 08:45:44 +1200
Subject: [R] Randomness
Message-ID: <1053981944.3ed27cf8445b0@webmail2.ec.auckland.ac.nz>

Hi,
I am very new to R and cannot seem to find how it generates random numbers. I 
am currently involved with a project that requires a random number generator 
and have developed one. I am, however, unsure of just how random it is and was 
wanting to compare my generator with that of R (as well as others). 
If anyone knows how the random numbers are generated or have any ideas on 
testing or where a true pseudo-random number generator can be found I would 
love to know.
David
dcum007 at ec.auckland.ac.nz



From jfox at mcmaster.ca  Mon May 26 21:56:34 2003
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 26 May 2003 15:56:34 -0400
Subject: [R] "Tcl/Tk support is not available on this system, " RH
	9, R 1.7.0-1
In-Reply-To: <1053971647.5856.84.camel@localhost>
References: <Pine.LNX.4.44.0305261710370.7791-100000@gannet.stats>
	<Pine.LNX.4.44.0305261710370.7791-100000@gannet.stats>
Message-ID: <5.0.2.1.0.20030526155115.00afa248@mcmail.cis.mcmaster.ca>

Dear Marc,

At 12:54 PM 5/26/2003 -0500, Marc Schwartz wrote:

. . .


>I just installed Rcmdr on my RH 9 system and it works fine (albeit only
>during a first look with no extensive testing), so my guess is that you
>are or were missing the tcl/tk packages when you installed R. Be aware
>that you also need the "car" package installed from CRAN for Rcmdr.
>

. . .

>P.S. to Prof. Fox: Unless I missed it, you may wish to consider having
>an adjustment for the font size on the menus. When using
>options(Rcmdr.fontsize = XX), it affected the log window size, but not
>the menu fonts, which on my 1600 x 1200 lcd panel are on the smallish
>side.

I'll take a look at how to handle that. How about text in dialog boxes? Is 
that too small as well? In addition to setting font sizes via options(), I 
could add a Preferences item to the File menu, although it might be worth 
considering first what other customization would be desirable.

I think that I'll wait until I receive more suggestions for modifications 
and additions before proceeding.

Thanks for the suggestion.
  John

____________________________
John Fox
Department of Sociology
McMaster University
email: jfox at mcmaster.ca
web: http://www.socsci.mcmaster.ca/jfox



From kjetil at entelnet.bo  Mon May 26 23:02:43 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Mon, 26 May 2003 17:02:43 -0400
Subject: [R] Randomness
In-Reply-To: <1053981944.3ed27cf8445b0@webmail2.ec.auckland.ac.nz>
Message-ID: <3ED248B3.4050.1118C03@localhost>

On 27 May 2003 at 8:45, dcum007 at ec.auckland.ac.nz wrote:


Try
?RNGkind

at the R prompt.

> Hi,
> I am very new to R and cannot seem to find how it generates random numbers. I 
> am currently involved with a project that requires a random number generator 
> and have developed one. I am, however, unsure of just how random it is and was 
> wanting to compare my generator with that of R (as well as others). 
> If anyone knows how the random numbers are generated or have any ideas on 
> testing or where a true pseudo-random number generator can be found I would 
> love to know.

What is a TRUE pseudo-random generator?

Kjetil Halvorsen

> David
> dcum007 at ec.auckland.ac.nz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From kwan022 at stat.auckland.ac.nz  Mon May 26 23:06:32 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Tue, 27 May 2003 09:06:32 +1200 (NZST)
Subject: [R] Randomness
In-Reply-To: <1053981944.3ed27cf8445b0@webmail2.ec.auckland.ac.nz>
Message-ID: <Pine.LNX.4.44.0305270904160.8991-100000@stat61.stat.auckland.ac.nz>

What kind of random numbers (what distributions) do you want?  You have a 
choice of specifying distributions of the random numbers.  For example: 
  rnorm() for Normal Random Numbers
  runif() for Uniform Random Numbers
etc

On Tue, 27 May 2003 dcum007 at ec.auckland.ac.nz wrote:

> Date: Tue, 27 May 2003 08:45:44 +1200
> From: dcum007 at ec.auckland.ac.nz
> To: "R-help at lists.R-project.org" <R-help at stat.math.ethz.ch>
> Subject: [R] Randomness
> 
> Hi,
> I am very new to R and cannot seem to find how it generates random numbers. I 
> am currently involved with a project that requires a random number generator 
> and have developed one. I am, however, unsure of just how random it is and was 
> wanting to compare my generator with that of R (as well as others). 
> If anyone knows how the random numbers are generated or have any ideas on 
> testing or where a true pseudo-random number generator can be found I would 
> love to know.
> David
> dcum007 at ec.auckland.ac.nz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
"On two occasions, I have been asked [by members of Parliament],
'Pray, Mr. Babbage, if you put into the machine wrong figures, will
the right answers come out?' I am not able to rightly apprehend the
kind of confusion of ideas that could provoke such a question."

-- Charles Babbage (1791-1871) 
---- From Computer Stupidities: http://rinkworks.com/stupid/

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)



From spencer.graves at pdf.com  Mon May 26 23:08:37 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 26 May 2003 14:08:37 -0700
Subject: [R] Randomness
References: <1053981944.3ed27cf8445b0@webmail2.ec.auckland.ac.nz>
Message-ID: <3ED28255.801@pdf.com>

	  "?.Random.seed" should answer your immediate questions about how the 
random numbers were generated.  Articles appeared in The American 
Statistician a few years ago on the accuracy of statistical computations 
in S-Plus that said that S-Plus was one bit away from the best known 
algorathm at that time.  I suspect that the R developers have fixed that 
minor problem.  This R help page cites several articles and provides 
alternative methods of random number generation, so it is probably among 
the best available.

	  There is a standard naming convention in R / S for functions 
associated with probability distributions.  An initial letter "r" = 
random numbers, "d" = density", "p" = cumulative probability 
distribution function (cdf), "q" = quantile function = inverse cdf. 
Succeeding letters specify the distribution, so "runif" = uniform, 
"rnorm" = normal, "rt" = Student's t, etc.

hth.  spencer graves

dcum007 at ec.auckland.ac.nz wrote:
> Hi,
> I am very new to R and cannot seem to find how it generates random numbers. I 
> am currently involved with a project that requires a random number generator 
> and have developed one. I am, however, unsure of just how random it is and was 
> wanting to compare my generator with that of R (as well as others). 
> If anyone knows how the random numbers are generated or have any ideas on 
> testing or where a true pseudo-random number generator can be found I would 
> love to know.
> David
> dcum007 at ec.auckland.ac.nz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Mon May 26 23:12:35 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 26 May 2003 22:12:35 +0100 (BST)
Subject: [R] Randomness
In-Reply-To: <1053981944.3ed27cf8445b0@webmail2.ec.auckland.ac.nz>
Message-ID: <Pine.LNX.4.44.0305262207170.8053-100000@gannet.stats>

?RNG comes with copious references, and the sources are in src/main/RNG.c.

On Tue, 27 May 2003 dcum007 at ec.auckland.ac.nz wrote:

> Hi,
> I am very new to R and cannot seem to find how it generates random numbers. I 
> am currently involved with a project that requires a random number generator 
> and have developed one. I am, however, unsure of just how random it is and was 
> wanting to compare my generator with that of R (as well as others). 
> If anyone knows how the random numbers are generated or have any ideas on 
> testing or where a true pseudo-random number generator can be found I would 
> love to know.

Well, there is a very extensive literature, and you don't give your 
background.  I would suggest starting with either my 1987 book `Stochastic 
Simulation' or Knuth's TAOCP.  The principles were worked out long ago, 
and the world is in no need of yet another PRNG.  (There are far too many 
that have been heavily promoted and a few years later discredited.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Mon May 26 23:14:31 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon, 26 May 2003 21:14:31 -0000
Subject: [R] spinning and flipping arrays
In-Reply-To: <200305261913.h4QJDQMn002131@hypatia.math.ethz.ch>
References: <200305261913.h4QJDQMn002131@hypatia.math.ethz.ch>
Message-ID: <x2smr19zg4.fsf@biostat.ku.dk>

Bill Rising <brising at louisville.edu> writes:

> On 5/26/2003 15:05, Spencer Graves wrote
> 
> >	  I know of no single function to do this;  perhaps someone else does. 
> >  I don't have time to write and debug functions to do this myself, but 
> >it should be easy enough to write functions like the following:
> >
> >flip3 <-
> >function(x){
> >   n3 <- dim(x)[3]
> >   x[,,n3:1]
> >}
> >spin3 <-
> >function(x, k=1){
> >   n3 <- dim(x)[3]
> >   x[,,1+(((1+k):(n3+k))%%n3)]
> >}
> 
> These are pretty much what I'd figured out...
> 
> >
> >With a little more work, I could generate functions that would do this 
> >for any dimension of arrays with any number of dimensions.  To do that, 
> >I might have to compute S-Plus commands using "cmd <- paste(...)" and 
> >then execute them using "eval(parse(text=cmd))".

> This last piece is what I think I needed. I had been trying to just put 
> the 
> /argument/ to the "[" command together, instead of putting together the 
> entire command.
> 
> Thanks for the tip. I'll keep working on it.

Relying on textual representation always looks dodgy to me. How about

spin <- function(x,amount=c(1,rep(0,length(dim(x))-1))) {
    indices <- mapply(function(n,k) (seq(length=n)+k-1)%%n + 1,
                      dim(x),amount, SIMPLIFY=FALSE)
    do.call("[", c(list(x), indices))
}

(Note: mapply() was introduced in 1.7.0). Notice that it is much
easier to use 1:n than to try to generate an empty index for "[".

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From jasonparcon at yahoo.com  Mon May 26 23:58:02 2003
From: jasonparcon at yahoo.com (Jason Parcon)
Date: Mon, 26 May 2003 14:58:02 -0700 (PDT)
Subject: [R] random numbers
Message-ID: <20030526215802.79046.qmail@web80505.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030526/ee74023b/attachment.pl

From zeileis at ci.tuwien.ac.at  Tue May 27 00:03:12 2003
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Tue, 27 May 2003 00:03:12 +0200
Subject: [R] random numbers
In-Reply-To: <20030526215802.79046.qmail@web80505.mail.yahoo.com>
References: <20030526215802.79046.qmail@web80505.mail.yahoo.com>
Message-ID: <200305262203.h4QM3CDC032055@thorin.ci.tuwien.ac.at>

On Monday 26 May 2003 23:58, Jason Parcon wrote:

> Is it possible to assign a seed number when generating, say, normal
> random numbers in rnorm for reproducibility purposes?

Yes, with the command set.seed() to the help page of which you are 
being pointed by both
  help(rnorm)
and
  help.search("random seed")


>
> ---------------------------------
>
>
> 	[[alternate HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From brising at louisville.edu  Tue May 27 03:44:27 2003
From: brising at louisville.edu (Bill Rising)
Date: Mon, 26 May 2003 21:44:27 -0400
Subject: [R] spinning and flipping arrays
Message-ID: <200305270144.h4R1irMn020143@hypatia.math.ethz.ch>

On 5/26/2003 17:21, Peter Dalgaard BSA wrote

>Bill Rising <brising at louisville.edu> writes:
>
>> On 5/26/2003 15:05, Spencer Graves wrote
>> 
[snip...]

This seems to work for the flipping (and it relies on textual 
representations, and is completely unreadable, and is inelegant):

fliparr <-
function(arr,dims=length(dim(arr))) {
 #defaults to flipping across last dimension, otherwise takes
 #  a vector of dimensions (which ignores dimesions which are out of 
bounds)
 # NO error checking yet
 # initialize a series of blank strings for the indices
  strarg <- vector("character",arrsize <- length(arrdim<-dim(arr)))
 # find which indices will be flipped (logical vector)
  which <-  apply(outer(1:arrsize,as.vector(dims),"=="),1,any)
 # use 1:dimension size for non-flipped dimensions
  strarg[!which] <- paste(NULL,arrdim[!which],sep="1:")
 # use dimension size:1 for flipped dimensions
  strarg[which] <- paste(arrdim[which],NULL,sep=":1")
 # paste all the text together and hope syntax never changes
  
eval(parse(text=paste("arr[",paste(strarg,collapse=","),"]",collapse="")))
}

>
>Relying on textual representation always looks dodgy to me. 

You've got a good point.

>How about
>
>spin <- function(x,amount=c(1,rep(0,length(dim(x))-1))) {
>    indices <- mapply(function(n,k) (seq(length=n)+k-1)%%n + 1,
>                      dim(x),amount, SIMPLIFY=FALSE)
>    do.call("[", c(list(x), indices))
>}

This works quite well for spinning an equal amount in each dimension. I 
think I can use this to work on the equivalent to APL which either uses a 
single number to spin a single dimension (like spin(foo,c(something,0,0)) 
) or an array with the dimensions of the original array minus the 
dimension around which items are spun, so that the items can be shifted 
differenent amounts.

>
>(Note: mapply() was introduced in 1.7.0). 

I'll check out mapply. thanks,

Bill



From Robert.Espesser at lpl.univ-aix.fr  Tue May 27 07:33:17 2003
From: Robert.Espesser at lpl.univ-aix.fr (Robert.Espesser@lpl.univ-aix.fr)
Date: Tue, 27 May 2003 07:33:17 +0200 (CEST)
Subject: [R] help output paged in separate window
In-Reply-To: <XFMail.030526200341.Ted.Harding@nessie.mcc.ac.uk>
References: <20030526121920.IETJ16123.mta07.mail.mel.aone.net.au@there>
	<XFMail.030526200341.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <33727.147.94.227.41.1054013597.squirrel@wperso.univ-mrs.fr>

You have to run the xterm in background , then you can go on with R
see  below the modification of helpless:
....
.....
sys.command<-paste("xterm -e less ",helpfile,sep="",collape="")
# append "&", to launch xterm -e helpfile in background
sys.command <- paste(sys.command, "  &",sep="",collape="")
system(sys.command)
}



> On 26-May-03 Jim Lemon wrote:
>> Well, here is a little function derived from the help browser macro I
>> wrote for NEdit that will fire up an xterm with less displaying the
>> help for a function.
>> Jim
>>
>> helpless<-function(topic) {
>>  topic<-substitute(topic)
>>  sys.command<-paste("locate ",topic,sep="",collapse="")
>>  helpfilelist<-system(sys.command,TRUE)
>>  helpmatch<-paste("help/",topic,sep="",collapse="")
>>  # find the R text help file(s)
>>  helpfile<-helpfilelist[grep(helpmatch,helpfilelist)]
>>  # assume that the shortest name matching "topic" will be the one
>>  if(length(helpfile) > 1)
>>   helpfile<-helpfile[which.min(nchar(helpfile))]
>>  sys.command<-paste("xterm -e less ",helpfile,sep="",collapse="")
>>  system(sys.command)
>> }
>
> Well that's neat! I must study it and learn some of the tricks.
> They look useful. The only thing I have against it is that it
> doesn't detach from the R window, unlike tkpager which conveniently
> does, so it's not possible to continue working in R while reading
> help (leaving one as it were helpless ... ).
>
> Thanks, and best wishes,
> Ted.
>
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 167 1972
> Date: 26-May-03                                       Time: 20:03:41
> ------------------------------ XFMail ------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From arv at ono.com  Tue May 27 09:10:40 2003
From: arv at ono.com (arv@ono.com)
Date: Tue, 27 May 2003 09:10:40 +0200
Subject: [R] Rcmdr on Debian
Message-ID: <54cc51cc.51cc54cc@ono.com>

Hi,

I've been able to run Rcmdr on Debian-Woody without too much problems,
just to load first the tcltk and car libraries. The issue is that after
leaving R I'm not able to see at the prompt any character like 'ls', but
the unix instructions are executed, don't know why the visualization of
the unix commands is cancelled.

Antonio Rodriguez



From wl at eimb.ru  Tue May 27 10:04:50 2003
From: wl at eimb.ru (Wladimir Eremeev)
Date: Tue, 27 May 2003 12:04:50 +0400
Subject: [R] R doesn't remove temporary dirs and about bugreport
Message-ID: <7503.030527@eimb.ru>

Dear r-help,

1.  I always find in TEMP directory subdirs named like Rtmp#####
  where ##### denote a number.

  Obviously, they are created by R and are not removed by it after
  finish.
  Why?

  I use R 1.7.0 and Windows NT Workstation 4.0, English. SP 6a.

2. Is it possible to get known whether my bug report was received?

  I've sent to r-bugs at biostat.ku.dk the following but it seemed to me
  there  were no any reaction. Also I had some troubles with mail
  server, and the letter could be lost.

====
the source code of the 'reshape' function contains the following

reshapeLong <- function(data, varying, v.names = NULL, timevar,
       idvar, ids = 1:NROW(date), times, drop = NULL, new.row.names =
NULL) {

I suspect the expression

ids=1:NROW(date)

is erroneous.
The 'date' variable doesn't appear anywhere else in this function.
Maybe, 'data' ?

====
-- 
Best regards
Wladimir Eremeev                                     mailto:wl at eimb.ru



From p.dalgaard at biostat.ku.dk  Tue May 27 09:59:15 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Tue, 27 May 2003 07:59:15 -0000
Subject: [R] Rcmdr on Debian
In-Reply-To: <54cc51cc.51cc54cc@ono.com>
References: <54cc51cc.51cc54cc@ono.com>
Message-ID: <x2n0h8aka0.fsf@biostat.ku.dk>

<arv at ono.com> writes:

> Hi,
> 
> I've been able to run Rcmdr on Debian-Woody without too much problems,
> just to load first the tcltk and car libraries. The issue is that after
> leaving R I'm not able to see at the prompt any character like 'ls', but
> the unix instructions are executed, don't know why the visualization of
> the unix commands is cancelled.

This can happen even without the tcltk stuff. Not quite sure why (most
likely, it is readline-related), but the way out is to type "stty
sane" at the shell prompt.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Tue May 27 10:13:17 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 27 May 2003 09:13:17 +0100 (BST)
Subject: [R] R doesn't remove temporary dirs and about bugreport
In-Reply-To: <7503.030527@eimb.ru>
Message-ID: <Pine.LNX.4.44.0305270905130.9164-100000@gannet.stats>

On Tue, 27 May 2003, Wladimir Eremeev wrote:

> Dear r-help,
> 
> 1.  I always find in TEMP directory subdirs named like Rtmp#####
>   where ##### denote a number.
> 
>   Obviously, they are created by R and are not removed by it after
>   finish.
>   Why?

Probably because a session crashed or Windows locked the file: an attempt 
is made to remove the file when R ends.

>   I use R 1.7.0 and Windows NT Workstation 4.0, English. SP 6a.
> 
> 2. Is it possible to get known whether my bug report was received?

Look on R-bugs.biostat.ku.dk to find out.

>   I've sent to r-bugs at biostat.ku.dk the following but it seemed to me
>   there  were no any reaction. Also I had some troubles with mail
>   server, and the letter could be lost.

I have seen a reply to you (Cc: to R-devel) on that one, and the bug has 
been fixed.

BTW, all my messages to you generated problem reports from your server: 
please do use a valid reply address on a machine which is properly 
registered in the global DNS.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Lsophir at wisemail.weizmann.ac.il  Tue May 27 10:43:58 2003
From: Lsophir at wisemail.weizmann.ac.il (Ron Ophir)
Date: Tue, 27 May 2003 11:43:58 +0300
Subject: [R] proxy
Message-ID: <sed34f8e.013@wisemail.weizmann.ac.il>

Dear all,
Where do I define the proxy in R on linux platform (something equivalent to --internet2 in windows)?
Thanks,
Ron



From Ted.Harding at nessie.mcc.ac.uk  Tue May 27 10:52:20 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue, 27 May 2003 09:52:20 +0100 (BST)
Subject: SOLVED: Re: [R] help output paged in separate window
In-Reply-To: <Pine.LNX.4.44.0305251251370.10966-100000@gannet.stats>
Message-ID: <XFMail.030527093605.Ted.Harding@nessie.mcc.ac.uk>

May I thank everyone who chipped in with suggestions and comments about
this question.

On one contribution: Robert Espresso suggested how to amend Jim Lemon's
function 'helpless' so as to put it in the background.
This works (as far as putting it in the background is concerned).
However, by experiment I found that Jim's function is limited because
of the way it looks for what to feed to 'less' and it sometimes succeeds
but in general will not succeed and so 'less' will get empty input.
E.g., with Robert's mod of Jim's function, compare the results of
"?library" (which works) with "?RNGkind" (which doesn't).

However, after a little reflection (which I could have done earlier ... )
I've found a very straightforward solution for Unix systems, outlined
below, which allows anything which would have been sent to R's pager to be
shown on a separate and fully-detached window using 'less'. The details
shown have been implemented in Linux, but the principles are applicable
on all Unix and the method should work either exactly as it is or with
minor modifcations.

1. Create a file in your $PATH with name "pgr" containg the lines

  #! /bin/bash
  export HLPFIL=`mktemp R_hlp.tmp.XXXXXX`
  cat > $HLPFIL
  xterm -e less $HLPFIL &

and make it executable ("chmod 755 pgr"). (You may want to change the
first line, depending on your shell, or you may well be able to omit it
altogether). The 'mktemp' function generates a filename which is unique
within its directory.

2. Give R the command

  options(page="pgr")

where "pgr" can be replaced by a full pathname if required.

That's it: Now try "?library", "help.search("random")", "help(RNGkind)"
or anything else!

If you use this a lot, you will find it handy to have a method of
automatically deleting all the "R_hlp.tmp.XXXXXX" files you've created
in a session.

Best wishes to all,
Ted.



From ripley at stats.ox.ac.uk  Tue May 27 11:22:32 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 27 May 2003 10:22:32 +0100 (BST)
Subject: [R] proxy
In-Reply-To: <sed34f8e.013@wisemail.weizmann.ac.il>
Message-ID: <Pine.LNX.4.44.0305271018560.9306-100000@gannet.stats>

It's documented in ?download.file, and it isn't equivalent to --internet2 
but to the standard internet support under Windows (which is more 
flexible).

Full text search on Windows or grepping the help files on Linux would have 
found this for you.

On Tue, 27 May 2003, Ron Ophir wrote:

> Where do I define the proxy in R on linux platform (something equivalent
> to --internet2 in windows)?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Roger.Bivand at nhh.no  Tue May 27 11:59:14 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 27 May 2003 11:59:14 +0200 (CEST)
Subject: SOLVED: Re: [R] help output paged in separate window
In-Reply-To: <XFMail.030527093605.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <Pine.LNX.4.44.0305271139360.31925-100000@reclus.nhh.no>

On Tue, 27 May 2003 Ted.Harding at nessie.mcc.ac.uk wrote:

> May I thank everyone who chipped in with suggestions and comments about
> this question.
> 
> On one contribution: Robert Espresso suggested how to amend Jim Lemon's
> function 'helpless' so as to put it in the background.
> This works (as far as putting it in the background is concerned).
> However, by experiment I found that Jim's function is limited because
> of the way it looks for what to feed to 'less' and it sometimes succeeds
> but in general will not succeed and so 'less' will get empty input.
> E.g., with Robert's mod of Jim's function, compare the results of
> "?library" (which works) with "?RNGkind" (which doesn't).
> 
> However, after a little reflection (which I could have done earlier ... )
> I've found a very straightforward solution for Unix systems, outlined
> below, which allows anything which would have been sent to R's pager to be
> shown on a separate and fully-detached window using 'less'. The details
> shown have been implemented in Linux, but the principles are applicable
> on all Unix and the method should work either exactly as it is or with
> minor modifcations.
> 
> 1. Create a file in your $PATH with name "pgr" containg the lines
> 
>   #! /bin/bash
>   export HLPFIL=`mktemp R_hlp.tmp.XXXXXX`
>   cat > $HLPFIL
>   xterm -e less $HLPFIL &
> 
> and make it executable ("chmod 755 pgr"). (You may want to change the
> first line, depending on your shell, or you may well be able to omit it
> altogether). The 'mktemp' function generates a filename which is unique
> within its directory.
> 
> 2. Give R the command
> 
>   options(page="pgr")
> 
> where "pgr" can be replaced by a full pathname if required.
> 
> That's it: Now try "?library", "help.search("random")", "help(RNGkind)"
> or anything else!
> 
> If you use this a lot, you will find it handy to have a method of
> automatically deleting all the "R_hlp.tmp.XXXXXX" files you've created
> in a session.

Or even use R to generate the shell script in a directory from tempdir():

.xthelp <- function() {
    tdir <- tempdir()
    pgr <- paste(tdir, "/pgr", sep="")
    con <- file(pgr, "w")
    cat("#! /bin/bash\n", file=con)
    cat("export HLPFIL=`mktemp ", tdir, "/R_hlp.XXXXXX`\n", sep="", file=con)
    cat("cat > $HLPFIL\nxterm -e less $HLPFIL &\n", file=con)
    close(con)
    system(paste("chmod 755 ", pgr, sep=""))
    options(pager=pgr)
}
.xthelp()

source() this; then the files go away when R quits. This still leaves the
function object in the global environment. The mode can also be 750 or
tighter since execute permissions for other users seem a bit unnecessary?

Roger

> 
> Best wishes to all,
> Ted.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From Ted.Harding at nessie.mcc.ac.uk  Tue May 27 12:23:52 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue, 27 May 2003 11:23:52 +0100 (BST)
Subject: SOLVED: Re: [R] help output paged in separate window
In-Reply-To: <XFMail.030527093605.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <XFMail.030527112352.Ted.Harding@nessie.mcc.ac.uk>

On 27-May-03 Ted Harding wrote:
> 1. Create a file in your $PATH with name "pgr" containg the lines
>   #! /bin/bash
>   export HLPFIL=`mktemp R_hlp.tmp.XXXXXX`
>   cat > $HLPFIL
>   xterm -e less $HLPFIL &
> 
> 2. Give R the command  options(page="pgr") where "pgr" can be replaced
>    by a full pathname if required.
> [...]
> If you use this a lot, you will find it handy to have a method of
> automatically deleting all the "R_hlp.tmp.XXXXXX" files you've created
> in a session.

For anyone who wants details of how to set all this up automatically, try
the following:

Edit your ~/.Rprofile to include (as well as anything else that's there):

  options(pager="~/pgr")
  .Last <- function() {
    system("rm R_hlp.tmp.*")
  }

and then this paging method will be set up at the start of every session,
and at the end of every session all of the temporary files will be
removed.

Best wishes to all,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 27-May-03                                       Time: 11:23:52
------------------------------ XFMail ------------------------------



From tore.wentzel-larsen at helse-bergen.no  Tue May 27 12:38:30 2003
From: tore.wentzel-larsen at helse-bergen.no (Tore Wentzel-Larsen)
Date: Tue, 27 May 2003 12:38:30 +0200
Subject: [R] Re: receiver operating characteristic (ROC)
Message-ID: <2BCE4822277DDF4A93570D7D01B0AAA82D3565@ted.ihelse.net>

Try the Bioconductor package ROC (see http://www.bioconductor.org/ ).
It is well suited for ROC curves in general.

sincerely,
Tore Wentzel-Larsen



From Ted.Harding at nessie.mcc.ac.uk  Tue May 27 12:51:44 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue, 27 May 2003 11:51:44 +0100 (BST)
Subject: SOLVED: Re: [R] help output paged in separate window
In-Reply-To: <Pine.LNX.4.44.0305271139360.31925-100000@reclus.nhh.no>
Message-ID: <XFMail.030527115144.Ted.Harding@nessie.mcc.ac.uk>

On 27-May-03 Roger Bivand wrote:
> Or even use R to generate the shell script in a directory from
> tempdir():
> 
> .xthelp <- function() {
>     tdir <- tempdir()
>     pgr <- paste(tdir, "/pgr", sep="")
>     con <- file(pgr, "w")
>     cat("#! /bin/bash\n", file=con)
>     cat("export HLPFIL=`mktemp ", tdir, "/R_hlp.XXXXXX`\n", sep="",
> file=con)
>     cat("cat > $HLPFIL\nxterm -e less $HLPFIL &\n", file=con)
>     close(con)
>     system(paste("chmod 755 ", pgr, sep=""))
>     options(pager=pgr)
> }
> .xthelp()
> 
> source() this; then the files go away when R quits. This still leaves
> the function object in the global environment. The mode can also be
> 750 or tighter since execute permissions for other users seem a bit
> unnecessary?

Thanks! I like this even better than my previous solution, since it is
completely clean (and as a bonus it has taught me more about R)! I've put
the above code into my ~/.Rprofile (also adding the line "rm(.xthelp)" at
the end) on the assumption that I'm going to need this once and for all
throughout a session, but of course people may want to keep their options
open.

Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 27-May-03                                       Time: 11:51:44
------------------------------ XFMail ------------------------------



From p.dalgaard at biostat.ku.dk  Tue May 27 13:54:25 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Tue, 27 May 2003 11:54:25 -0000
Subject: SOLVED: Re: [R] help output paged in separate window
In-Reply-To: <XFMail.030527115144.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.030527115144.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <x2wugczjiu.fsf@biostat.ku.dk>

(Ted Harding) <Ted.Harding at nessie.mcc.ac.uk> writes:

> Thanks! I like this even better than my previous solution, since it is
> completely clean (and as a bonus it has taught me more about R)! I've put
> the above code into my ~/.Rprofile (also adding the line "rm(.xthelp)" at
> the end) on the assumption that I'm going to need this once and for all
> throughout a session, but of course people may want to keep their options
> open.

Actually, none of this would be necessary if there was a workaround
for the misbehaviour of "more" when stdin is redirected. (It happily
gobbles up the rest of the input file...). If we could only use
standard %s substitution on the $PAGER variable, much would be easier.

There would seem to be some scope for doing things differently from
what we do now, so if anyone wants to volunteer...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From Raimondas at vb.lt  Tue May 27 13:52:31 2003
From: Raimondas at vb.lt (Raimondas B.)
Date: Tue, 27 May 2003 14:52:31 +0300
Subject: [R] Need computing of Correlation Integral
Message-ID: <002201c32446$7492bc30$6e25b10a@berniunas>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030527/8796ca13/attachment.pl

From glouis at dynamicro.on.ca  Tue May 27 13:47:01 2003
From: glouis at dynamicro.on.ca (Greg Louis)
Date: Tue, 27 May 2003 07:47:01 -0400
Subject: SOLVED: Re: [R] help output paged in separate window
In-Reply-To: <XFMail.030527112352.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.030527093605.Ted.Harding@nessie.mcc.ac.uk>
	<XFMail.030527112352.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <20030527114701.GA1244@athame.dynamicro.on.ca>

On 20030527 (Tue) at 1123:52 +0100, Ted Harding wrote:
> On 27-May-03 Ted Harding wrote:
> > 1. Create a file in your $PATH with name "pgr" containg the lines
> >   #! /bin/bash
> >   export HLPFIL=`mktemp R_hlp.tmp.XXXXXX`
> >   cat > $HLPFIL
> >   xterm -e less $HLPFIL &
> > 
> > 2. Give R the command  options(page="pgr") where "pgr" can be replaced
> >    by a full pathname if required.
> > [...]
> > If you use this a lot, you will find it handy to have a method of
> > automatically deleting all the "R_hlp.tmp.XXXXXX" files you've created
> > in a session.
> 
> For anyone who wants details of how to set all this up automatically, try
> the following:
> 
> Edit your ~/.Rprofile to include (as well as anything else that's there):
> 
>   options(pager="~/pgr")
>   .Last <- function() {
>     system("rm R_hlp.tmp.*")
>   }
> 
This also works on Linux, except it removes the temporary file when the
pager exits:
#! /bin/bash
export HLPFIL=`mktemp R_hlp.tmp.XXXXXX`
cat > $HLPFIL
xterm -e less $HLPFIL & lpid=$!
wait $lpid
/bin/rm $HLPFIL

-- 
| G r e g  L o u i s          | gpg public key: finger     |
|   http://www.bgl.nu/~glouis |   glouis at consultronics.com |



From vito.muggeo at giustizia.it  Tue May 27 14:15:57 2003
From: vito.muggeo at giustizia.it (vito muggeo)
Date: Tue, 27 May 2003 14:15:57 +0200
Subject: [R] saving warning messages
Message-ID: <007601c32449$bd879de0$5c13070a@it.giustizia.it>

Dear all,
is it possible to save warning messages in the object created by any
function causing the warning message itself?

For instance coxph() in survival package fits Cox regression model and
returns the fitted model with possible warning messages if some problems
occur in fitting. However sometimes the warning messages may be meaningless
and the fitted model to be valid at all.
Therefore I would like the warning msg to be attached in the returned
object, i.e. to have something like
obj<-coxph(.... #print warning message
is.null(obj$warning)
> FALSE

Using par(warn=2) causes the warnings messages to be considered as error and
it is not what I want.

many thanks for your time,

vito



From P.Lemmens at nici.kun.nl  Tue May 27 14:53:46 2003
From: P.Lemmens at nici.kun.nl (Paul Lemmens)
Date: Tue, 27 May 2003 14:53:46 +0200
Subject: [R] Numbers that look equal, should be equal,
 but if() doesn't see as equal
Message-ID: <23399093.1054047226@lemmens.socsci.kun.nl>

Hi!

After a lot of testing and debugging I'm falling silent in figuring out 
what goes wrong in the following.

I'm implementing the Vincentizing procedure that Ratcliff (1979) described. 
It's about calculating RT bins for any distribution of RT data. It boils 
down to rank ordering your data, replicating each data point as many times 
as you need bins and then splitting up the resulting distribution in equal 
bins.

The code that I've written is attached (and not included because it is 
considerable in length due to many comments). Ratcliff.r contains some 
basic functions and distribution.bins.r contains the problematic function 
bins.factor() (problem area marked with 'FAILING TEST'). The final attached 
file is the mock up distribution I made.

The failing test is the check if the mean of the mean RT's for each bin 
equals the mean of the original distribution. These should/are 
mathematically equivalent. Sometimes, however, the test fails. With the 
attached distribution most notably for 4, 7, 8, 9, and 13 bins. Since the 
means are mathematically equivalent IMHO it should not be an issue of this 
particular distribution. As a matter of fact, I also have tested some 
rnorm() distributions and my function also fails on those (albeit a little 
less often than with foobar.txt).

Problem description: if one calculates the bins or bin means by hand, the 
mean of the bin means is visually the same as the overall mean, even with 
options(digits=20), but *still* the test fails.

IMHO it's not my code and neither the distribution I use to test, but 
still, can you point out an obvious failure of my programming or is it 
indeed something of R that I don't yet grasp?

thank you for your help,
Paul


-- 
Paul Lemmens
NICI, University of Nijmegen              ASCII Ribbon Campaign /"\
Montessorilaan 3 (B.01.03)                    Against HTML Mail \ /
NL-6525 HR Nijmegen                                              X
The Netherlands                                                 / \
Phonenumber    +31-24-3612648
Fax            +31-24-3616066

-------------- next part --------------
"RT" "Cond"
"1"  1 "A"
"2"  1 "A"
"3"  1 "A"
"4"  2 "A"
"5"  2 "A"
"6"  3 "A"
"7"  3 "A"
"8"  3 "A"
"9"  3 "A"
"10"  3 "A"
"11"  4 "A"
"12"  4 "A"
"13"  4 "A"
"14"  4 "A"
"15"  5 "A"
"16"  5 "A"
"17"  5 "A"
"18"  5 "A"
"19"  5 "A"
"20"  5 "A"
"21"  5 "A"
"22"  6 "A"
"23"  6 "A"
"24"  6 "A"
"25"  6 "A"
"26"  6 "A"
"27"  6 "A"
"28"  6 "A"
"29"  6 "A"
"30"  6 "A"
"31"  7 "A"
"32"  7 "A"
"33"  7 "A"
"34"  7 "A"
"35"  8 "A"
"36"  8 "A"
"37"  8 "A"
"38"  9 "A"
"39"  9 "A"
"40" 10 "A"
"41"  2 "B"
"42"  2 "B"
"43"  2 "B"
"44"  4 "B"
"45"  4 "B"
"46"  6 "B"
"47"  6 "B"
"48"  6 "B"
"49"  6 "B"
"50"  6 "B"
"51"  8 "B"
"52"  8 "B"
"53"  8 "B"
"54"  8 "B"
"55" 10 "B"
"56" 10 "B"
"57" 10 "B"
"58" 10 "B"
"59" 10 "B"
"60" 10 "B"
"61" 10 "B"
"62" 12 "B"
"63" 12 "B"
"64" 12 "B"
"65" 12 "B"
"66" 12 "B"
"67" 12 "B"
"68" 12 "B"
"69" 12 "B"
"70" 12 "B"
"71" 14 "B"
"72" 14 "B"
"73" 14 "B"
"74" 14 "B"
"75" 16 "B"
"76" 16 "B"
"77" 16 "B"
"78" 18 "B"
"79" 18 "B"
"80" 20 "B"
"81"  3 "C"
"82"  3 "C"
"83"  3 "C"
"84"  6 "C"
"85"  6 "C"
"86"  9 "C"
"87"  9 "C"
"88"  9 "C"
"89"  9 "C"
"90"  9 "C"
"91" 12 "C"
"92" 12 "C"
"93" 12 "C"
"94" 12 "C"
"95" 15 "C"
"96" 15 "C"
"97" 15 "C"
"98" 15 "C"
"99" 15 "C"
"100" 15 "C"
"101" 15 "C"
"102" 18 "C"
"103" 18 "C"
"104" 18 "C"
"105" 18 "C"
"106" 18 "C"
"107" 18 "C"
"108" 18 "C"
"109" 18 "C"
"110" 18 "C"
"111" 21 "C"
"112" 21 "C"
"113" 21 "C"
"114" 21 "C"
"115" 24 "C"
"116" 24 "C"
"117" 24 "C"
"118" 27 "C"
"119" 27 "C"
"120" 30 "C"

From wl at eimb.ru  Tue May 27 15:13:49 2003
From: wl at eimb.ru (Wladimir Eremeev)
Date: Tue, 27 May 2003 17:13:49 +0400
Subject: [R] R doesn't remove temporary dirs and about bugreport
Message-ID: <0717.030527@eimb.ru>

Dear Prof Brian Ripley,

   Thank you for the answers.

> BTW, all my messages to you generated problem reports from your server:
> please do use a valid reply address on a machine which is properly 
> registered in the global DNS. 

My providers seem to have problems with their providers (up-link
company, so to say).
I am terribly sorry.

I communicated to my providers and was answered that they are unable
to change anything.

I've seen your reply only when looked in the web-page containing
mailing lists (http://maths.newcastle.edu.au/~rking/R/help/03a/index.html)

My reply address is valid one.

-- 
Best regards
Wladimir Eremeev                                     mailto:wl at eimb.ru

==========================================================================
Research Scientist                                Leninsky Prospect 33,
Space Monitoring & Ecoinformation Systems Sector, Moscow, Russia, 119071,
Institute of Ecology,                             Phone: (095) 135-9972;
Russian Academy of Sciences                       Fax: (095) 954-5534



From ripley at stats.ox.ac.uk  Tue May 27 15:12:49 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 27 May 2003 14:12:49 +0100 (BST)
Subject: [R] Numbers that look equal, should be equal, but if() doesn't
	see as equal
In-Reply-To: <23399093.1054047226@lemmens.socsci.kun.nl>
Message-ID: <Pine.LNX.4.44.0305271405510.21251-100000@gannet.stats>

?all.equal may help you.

In the absence of any of your code, there is not much we can do, except to
comment that if() (of your subject line) only knows about TRUE and FALSE,
so we can only guess at what you used to test equality.


On Tue, 27 May 2003, Paul Lemmens wrote:

> After a lot of testing and debugging I'm falling silent in figuring out 
> what goes wrong in the following.
> 
> I'm implementing the Vincentizing procedure that Ratcliff (1979) described. 
> It's about calculating RT bins for any distribution of RT data. It boils 
> down to rank ordering your data, replicating each data point as many times 
> as you need bins and then splitting up the resulting distribution in equal 
> bins.
> 
> The code that I've written is attached (and not included because it is 
> considerable in length due to many comments). 

No code arrived here.  What `attached (and not included' means is unclear 
to me, but only the dataset arrived.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From clists at perrin.socsci.unc.edu  Tue May 27 15:49:45 2003
From: clists at perrin.socsci.unc.edu (Andrew Perrin)
Date: Tue, 27 May 2003 09:49:45 -0400 (EDT)
Subject: [R] Help! R won't start
Message-ID: <Pine.LNX.4.53.0305270948430.26135@perrin.socsci.unc.edu>

Returning after the long weekend, I get the following:

aperrin at perrin:~/afshome/papers/microcultures/R$ R

R : Copyright 2003, The R Development Core Team
Version 1.7.0  (2003-04-16)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type `license()' or `licence()' for distribution details.

R is a collaborative project with many contributors.
Type `contributors()' for more information.

Type `demo()' for some demos, `help()' for on-line help, or
`help.start()' for a HTML browser interface to help.
Type `q()' to quit R.

Error in get(x, envir, mode, inherits) : variable "biplot" was not found
Fatal error: unable to restore saved data in .RData



Any advice? The partition is mounted read/write.  This is R 1.7.0 under
debian linux (kernel 2.4.20).

Thanks!

----------------------------------------------------------------------
Andrew J Perrin - http://www.unc.edu/~aperrin
Assistant Professor of Sociology, U of North Carolina, Chapel Hill
clists at perrin.socsci.unc.edu * andrew_perrin (at) unc.edu



From ripley at stats.ox.ac.uk  Tue May 27 15:58:53 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 27 May 2003 14:58:53 +0100 (BST)
Subject: [R] Help! R won't start
In-Reply-To: <Pine.LNX.4.53.0305270948430.26135@perrin.socsci.unc.edu>
Message-ID: <Pine.LNX.4.44.0305271455340.23893-100000@gannet.stats>

try R --vanilla

The likely story is that you have library(MASS) in the .Rprofile being 
found.  That does not work in 1.7.0 (and is not the recommended way to do 
this: see the help archives for solutions, one of which is to run 
update.packages() and get the current VR bundle).

On Tue, 27 May 2003, Andrew Perrin wrote:

> Returning after the long weekend, I get the following:
> 
> aperrin at perrin:~/afshome/papers/microcultures/R$ R
> 
> R : Copyright 2003, The R Development Core Team
> Version 1.7.0  (2003-04-16)
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type `license()' or `licence()' for distribution details.
> 
> R is a collaborative project with many contributors.
> Type `contributors()' for more information.
> 
> Type `demo()' for some demos, `help()' for on-line help, or
> `help.start()' for a HTML browser interface to help.
> Type `q()' to quit R.
> 
> Error in get(x, envir, mode, inherits) : variable "biplot" was not found
> Fatal error: unable to restore saved data in .RData
> 
> 
> 
> Any advice? The partition is mounted read/write.  This is R 1.7.0 under
> debian linux (kernel 2.4.20).
> 
> Thanks!
> 
> ----------------------------------------------------------------------
> Andrew J Perrin - http://www.unc.edu/~aperrin
> Assistant Professor of Sociology, U of North Carolina, Chapel Hill
> clists at perrin.socsci.unc.edu * andrew_perrin (at) unc.edu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From MSchwartz at medanalytics.com  Tue May 27 16:04:02 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 27 May 2003 14:04:02 -0000
Subject: [R] Help! R won't start
In-Reply-To: <Pine.LNX.4.53.0305270948430.26135@perrin.socsci.unc.edu>
References: <Pine.LNX.4.53.0305270948430.26135@perrin.socsci.unc.edu>
Message-ID: <1054044211.23826.46.camel@localhost>

On Tue, 2003-05-27 at 08:49, Andrew Perrin wrote:
> Returning after the long weekend, I get the following:
> 
> aperrin at perrin:~/afshome/papers/microcultures/R$ R
> 
> R : Copyright 2003, The R Development Core Team
> Version 1.7.0  (2003-04-16)
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type `license()' or `licence()' for distribution details.
> 
> R is a collaborative project with many contributors.
> Type `contributors()' for more information.
> 
> Type `demo()' for some demos, `help()' for on-line help, or
> `help.start()' for a HTML browser interface to help.
> Type `q()' to quit R.
> 
> Error in get(x, envir, mode, inherits) : variable "biplot" was not found
> Fatal error: unable to restore saved data in .RData
> 
> 
> 
> Any advice? The partition is mounted read/write.  This is R 1.7.0 under
> debian linux (kernel 2.4.20).
> 
> Thanks!


Andrew,

Do you by chance have library(MASS) in your .Rprofile?

If so, change it to:

options(defaultPackages=c(getOption("defaultPackages"), "MASS"))

Include any other packages that you are loading in the c(...) arguments
after MASS.

That will resolve the issue.

Regards,

Marc Schwartz



From tlumley at u.washington.edu  Tue May 27 16:04:47 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 27 May 2003 07:04:47 -0700 (PDT)
Subject: [R] spinning and flipping arrays
In-Reply-To: <200305261739.h4QHdmMn012014@hypatia.math.ethz.ch>
Message-ID: <Pine.A41.4.44.0305270659230.160994-100000@homer10.u.washington.edu>

On Mon, 26 May 2003, Bill Rising wrote:

> Hello people,
>
> Is there some simple way of spinning and/or flipping arrays in R?
> Here's what I mean.
>

I don't think there's a built-in solution.

I would try constructing the permutation of indices, probably using
aperm() to move the index of interest to first or last place, whichever is
easiest.

This sort of thing might well be worth coding at least partly in C.

	-thomas



From spencer.graves at pdf.com  Tue May 27 16:08:25 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 27 May 2003 07:08:25 -0700
Subject: [R] saving warning messages
References: <007601c32449$bd879de0$5c13070a@it.giustizia.it>
Message-ID: <3ED37159.9090601@pdf.com>

?warnings in R1.6.2 reveals that, "`warnings' prints the top-level 
variable `last.warning' in a pleasing form."

hth.  spencer graves

vito muggeo wrote:
> Dear all,
> is it possible to save warning messages in the object created by any
> function causing the warning message itself?
> 
> For instance coxph() in survival package fits Cox regression model and
> returns the fitted model with possible warning messages if some problems
> occur in fitting. However sometimes the warning messages may be meaningless
> and the fitted model to be valid at all.
> Therefore I would like the warning msg to be attached in the returned
> object, i.e. to have something like
> obj<-coxph(.... #print warning message
> is.null(obj$warning)
> 
>>FALSE
> 
> 
> Using par(warn=2) causes the warnings messages to be considered as error and
> it is not what I want.
> 
> many thanks for your time,
> 
> vito
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From tlumley at u.washington.edu  Tue May 27 16:09:35 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 27 May 2003 07:09:35 -0700 (PDT)
Subject: [R] Randomness
In-Reply-To: <1053981944.3ed27cf8445b0@webmail2.ec.auckland.ac.nz>
Message-ID: <Pine.A41.4.44.0305270706070.160994-100000@homer10.u.washington.edu>

On Tue, 27 May 2003 dcum007 at ec.auckland.ac.nz wrote:

> Hi,
> I am very new to R and cannot seem to find how it generates random numbers. I
> am currently involved with a project that requires a random number generator
> and have developed one. I am, however, unsure of just how random it is and was
> wanting to compare my generator with that of R (as well as others).

The one addition I would make to Brian Ripley's reply is that R does not
generate cryptographically secure random numbers.  If your project needs
random encryption keys or nonces or whatever, you should read something
from the computer security literature. In this situation the arguments
against making up your own generator are even stronger.


	-thomas



From tlumley at u.washington.edu  Tue May 27 16:20:24 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 27 May 2003 07:20:24 -0700 (PDT)
Subject: [R] Numbers that look equal, should be equal, but if() doesn't
	see as equal
In-Reply-To: <23399093.1054047226@lemmens.socsci.kun.nl>
Message-ID: <Pine.A41.4.44.0305270715490.160994-100000@homer10.u.washington.edu>

On Tue, 27 May 2003, Paul Lemmens wrote:
>
> Problem description: if one calculates the bins or bin means by hand, the
> mean of the bin means is visually the same as the overall mean, even with
> options(digits=20), but *still* the test fails.
>

It is possible at least on some systems for numbers to print the same but
not be ==.  It's very difficult to ensure that two different floating
point numbers are ==, so it is almost always better to check that the
difference is small, which is what all.equal() does.

To get floating point equality you need not just mathematical equivalence
but quite a lot of care in handling rounding -- and it can still be broken
quite easily by optimising compilers.  If you look at the R tests
directory you will see quite a lot of places where mathematically
identical quantities are compared with relatively wide tolerances for
exactly this reason.

Usually getting within 10^-10 or so is sufficient and easily achievable.

	-thomas



From clists at perrin.socsci.unc.edu  Tue May 27 16:23:41 2003
From: clists at perrin.socsci.unc.edu (Andrew Perrin)
Date: Tue, 27 May 2003 10:23:41 -0400 (EDT)
Subject: [R] Help! R won't start
In-Reply-To: <Pine.LNX.4.44.0305271455340.23893-100000@gannet.stats>
References: <Pine.LNX.4.44.0305271455340.23893-100000@gannet.stats>
Message-ID: <Pine.LNX.4.53.0305271021340.26135@perrin.socsci.unc.edu>

On Tue, 27 May 2003, Prof Brian Ripley wrote:

> try R --vanilla
>
> The likely story is that you have library(MASS) in the .Rprofile being
> found.  That does not work in 1.7.0 (and is not the recommended way to do
> this: see the help archives for solutions, one of which is to run
> update.packages() and get the current VR bundle).
>

Thanks for all the quick responses! However, I don't have library(MASS)
anywhere as far as I can tell - just the stock
/usr/lib/R/library/base/R/Rprofile which contains no such call.

Starting R from a different directory works fine. Furthermore, starting R
with --no-restore-data works fine, and I can then restore the data
manually using load(".RData").  That might provide a clue.

The data file is extremely large:

aperrin at perrin:~/afshome/papers/microcultures/R$ ls -l .RData
-rw-r--r--    1 aperrin  aperrin  104355299 May 27 10:20 .RData

which could be the problem too.

ap


----------------------------------------------------------------------
Andrew J Perrin - http://www.unc.edu/~aperrin
Assistant Professor of Sociology, U of North Carolina, Chapel Hill
clists at perrin.socsci.unc.edu * andrew_perrin (at) unc.edu



From clists at perrin.socsci.unc.edu  Tue May 27 16:24:26 2003
From: clists at perrin.socsci.unc.edu (Andrew Perrin)
Date: Tue, 27 May 2003 10:24:26 -0400 (EDT)
Subject: [R] Help! R won't start
In-Reply-To: <Pine.LNX.4.44.0305271455340.23893-100000@gannet.stats>
References: <Pine.LNX.4.44.0305271455340.23893-100000@gannet.stats>
Message-ID: <Pine.LNX.4.53.0305271024000.26135@perrin.socsci.unc.edu>

Oops - I forgot. I get this message when I try to quit and save the data:

> q()
Save workspace image? [y/n/c]: y
Warning messages:
1: namespaces may not be available when loading
2: names in persistent strings are currently ignored


----------------------------------------------------------------------
Andrew J Perrin - http://www.unc.edu/~aperrin
Assistant Professor of Sociology, U of North Carolina, Chapel Hill
clists at perrin.socsci.unc.edu * andrew_perrin (at) unc.edu



From ripley at stats.ox.ac.uk  Tue May 27 17:03:37 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 27 May 2003 16:03:37 +0100 (BST)
Subject: [R] Help! R won't start
In-Reply-To: <Pine.LNX.4.53.0305271024000.26135@perrin.socsci.unc.edu>
Message-ID: <Pine.LNX.4.44.0305271556390.24275-100000@gannet.stats>

Looks like you have saved an object with a namespace (the MASS namespace) 
as its environment.  There is not much documentation available about
such situations, but see

http://www.stat.uiowa.edu/~luke/R/namespaces/morenames.html

for a sketch.

I suspect you got that message last time you saved, and then you were 
surprised when you had forgotten the warning.

Have you got a modified version of a MASS function in there?

In any case, the advice still applies: the current MASS will load up mva
which is what is needed, so update.packages().

On Tue, 27 May 2003, Andrew Perrin wrote:

> Oops - I forgot. I get this message when I try to quit and save the data:
> 
> > q()
> Save workspace image? [y/n/c]: y
> Warning messages:
> 1: namespaces may not be available when loading
> 2: names in persistent strings are currently ignored


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From clists at perrin.socsci.unc.edu  Tue May 27 17:16:41 2003
From: clists at perrin.socsci.unc.edu (Andrew Perrin)
Date: Tue, 27 May 2003 11:16:41 -0400 (EDT)
Subject: [R] Help! R won't start
In-Reply-To: <Pine.LNX.4.44.0305271556390.24275-100000@gannet.stats>
References: <Pine.LNX.4.44.0305271556390.24275-100000@gannet.stats>
Message-ID: <Pine.LNX.4.53.0305271116350.26135@perrin.socsci.unc.edu>

Yes, that did it - thanks!

ap

----------------------------------------------------------------------
Andrew J Perrin - http://www.unc.edu/~aperrin
Assistant Professor of Sociology, U of North Carolina, Chapel Hill
clists at perrin.socsci.unc.edu * andrew_perrin (at) unc.edu


On Tue, 27 May 2003, Prof Brian Ripley wrote:

> Looks like you have saved an object with a namespace (the MASS namespace)
> as its environment.  There is not much documentation available about
> such situations, but see
>
> http://www.stat.uiowa.edu/~luke/R/namespaces/morenames.html
>
> for a sketch.
>
> I suspect you got that message last time you saved, and then you were
> surprised when you had forgotten the warning.
>
> Have you got a modified version of a MASS function in there?
>
> In any case, the advice still applies: the current MASS will load up mva
> which is what is needed, so update.packages().
>
> On Tue, 27 May 2003, Andrew Perrin wrote:
>
> > Oops - I forgot. I get this message when I try to quit and save the data:
> >
> > > q()
> > Save workspace image? [y/n/c]: y
> > Warning messages:
> > 1: namespaces may not be available when loading
> > 2: names in persistent strings are currently ignored
>
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From chrysopa at insecta.ufv.br  Tue May 27 18:27:15 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Tue, 27 May 2003 13:27:15 -0300
Subject: [R] proportional splitplot with glmmPQL
Message-ID: <20030527162324.M60345@insecta.ufv.br>

Hi ALL,

sorry by this repeated question, but I'm a student and I dont have
money to buy any book more for now and I dont find any answer in network.

I have a splitplot with binomial errors (proportion data).

I try to make a model with glmmPQL.

But my doubt are:

Exit any method to compare models made with glmmPQL?
How know about the variables significance and model significance?
How make a model simplification (variables simplification and levels
amalgamation)?

If it is not possible with glmmPQL, how is the best method for make this
analysis? Using lme with the data transformed in log(y/n-y), where y is the
observation and n is the total.

Thanks for ALL and sorry again.

Inte
Ronaldo

--
|   //|\\   [*****************************]
|| ( ? ? )  [Ronaldo Reis J?nior          ]
|     V     [ESALQ/USP-Entomologia, CP-09 ]
||  / l \   [13418-900 Piracicaba - SP    ]
|  /(lin)\  [Fone: 19-429-4199 r.229      ]
||/(linux)\ [chrysopa at insecta.ufv.br      ]
|/ (linux) \[ICQ#: 5692561                ]
||  ( x )   [*****************************]
||| _/ \_ Powered by Gnu/Debian Woody
-----------------------------------
Insecta - Entomologia
Departamento de Biologia Animal
Universidade Federal de Vi?osa



From rg117 at yahoo.co.uk  Tue May 27 21:33:05 2003
From: rg117 at yahoo.co.uk (=?iso-8859-1?q?Rishabh=20Gupta?=)
Date: Tue, 27 May 2003 20:33:05 +0100 (BST)
Subject: [R] 0 margin for creating eps files
Message-ID: <20030527193305.52325.qmail@web41101.mail.yahoo.com>

Dear all,

I am trying to create eps files of R plots (in Linux) so that I can import them into Word
(obviously in MS Windows). What I would like is for the files to be cropped so that there is no
margin around the actual plot, because I have no way of editing the files after they have been
created. I have tried using

par(mai=c(.75,.75,0,0))

in order to reduce the margin; it works fine when I create a plot on the screen, however when I
use

dev.copy2eps(file="FILENAME.eps")

to save to the eps file, the margin has returned. Could someone please tell what I am doing wrong,
should I be using different parameter to set the margins of the eps files.

Any help would be greatly appreciated.

Many Thanks

Rishabh

__________________________________________________
It's Samaritans' Week. Help Samaritans help others. 
Call 08709 000032 to give or donate online now at http://www.samaritans.org/support/donations.shtm



From umalvarez at fata.unam.mx  Tue May 27 21:02:00 2003
From: umalvarez at fata.unam.mx (Ulises Mora Alvarez)
Date: Tue, 27 May 2003 14:02:00 -0500 (CDT)
Subject: [R] 0 margin for creating eps files
In-Reply-To: <20030527193305.52325.qmail@web41101.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0305271400200.10078-100000@fata.unam.mx>

Hi!

You may try (from the R help):

dev.print(postscript, file = "some_name.eps", horizontal = FALSE, onefile 
= FALSE, paper = "special")





On Tue, 27 May 2003, Rishabh Gupta wrote:

> Dear all,
> 
> I am trying to create eps files of R plots (in Linux) so that I can import them into Word
> (obviously in MS Windows). What I would like is for the files to be cropped so that there is no
> margin around the actual plot, because I have no way of editing the files after they have been
> created. I have tried using
> 
> par(mai=c(.75,.75,0,0))
> 
> in order to reduce the margin; it works fine when I create a plot on the screen, however when I
> use
> 
> dev.copy2eps(file="FILENAME.eps")
> 
> to save to the eps file, the margin has returned. Could someone please tell what I am doing wrong,
> should I be using different parameter to set the margins of the eps files.
> 
> Any help would be greatly appreciated.
> 
> Many Thanks
> 
> Rishabh
> 
> __________________________________________________
> It's Samaritans' Week. Help Samaritans help others. 
> Call 08709 000032 to give or donate online now at http://www.samaritans.org/support/donations.shtm
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Ulises M. Alvarez
LAB. DE ONDAS DE CHOQUE
FISICA APLICADA Y TECNOLOGIA AVANZADA
UNAM
umalvarez at fata.unam.mx



From murdoch at stats.uwo.ca  Tue May 27 22:08:54 2003
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 27 May 2003 16:08:54 -0400
Subject: [R] 0 margin for creating eps files
In-Reply-To: <20030527193305.52325.qmail@web41101.mail.yahoo.com>
References: <20030527193305.52325.qmail@web41101.mail.yahoo.com>
Message-ID: <dah7dvolcdugthdbqo6nmedra63kvaf737@4ax.com>

On Tue, 27 May 2003 20:33:05 +0100 (BST), you wrote in message
<20030527193305.52325.qmail at web41101.mail.yahoo.com>:

>Dear all,
>
>I am trying to create eps files of R plots (in Linux) so that I can import them into Word
>(obviously in MS Windows). What I would like is for the files to be cropped so that there is no
>margin around the actual plot, because I have no way of editing the files after they have been
>created. I have tried using
>
>par(mai=c(.75,.75,0,0))
>
>in order to reduce the margin; it works fine when I create a plot on the screen, however when I
>use
>
>dev.copy2eps(file="FILENAME.eps")
>
>to save to the eps file, the margin has returned. Could someone please tell what I am doing wrong,
>should I be using different parameter to set the margins of the eps files.
>
>Any help would be greatly appreciated.

I think the easiest way to do this is to use Ghostview to "convert to
EPS", and have it recalculate the bounding box as it does so.  Since
it's working with a Postscript interpreter, it does the bounding box
calculation very accurately; playing around with margins is likely to
lead to inconsistencies depending on labels, etc.

Duncan Murdoch



From ripley at stats.ox.ac.uk  Tue May 27 23:06:01 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 27 May 2003 22:06:01 +0100 (BST)
Subject: [R] 0 margin for creating eps files
In-Reply-To: <dah7dvolcdugthdbqo6nmedra63kvaf737@4ax.com>
Message-ID: <Pine.LNX.4.44.0305272155180.9158-100000@gannet.stats>

On Tue, 27 May 2003, Duncan Murdoch wrote:

> On Tue, 27 May 2003 20:33:05 +0100 (BST), you wrote in message
> <20030527193305.52325.qmail at web41101.mail.yahoo.com>:
> 
> >Dear all,
> >
> >I am trying to create eps files of R plots (in Linux) so that I can import them into Word
> >(obviously in MS Windows). What I would like is for the files to be cropped so that there is no
> >margin around the actual plot, because I have no way of editing the files after they have been
> >created. I have tried using
> >
> >par(mai=c(.75,.75,0,0))
> >
> >in order to reduce the margin; it works fine when I create a plot on the screen, however when I
> >use
> >
> >dev.copy2eps(file="FILENAME.eps")
> >
> >to save to the eps file, the margin has returned. Could someone please tell what I am doing wrong,
> >should I be using different parameter to set the margins of the eps files.
> >
> >Any help would be greatly appreciated.
> 
> I think the easiest way to do this is to use Ghostview to "convert to
> EPS", and have it recalculate the bounding box as it does so.  Since
> it's working with a Postscript interpreter, it does the bounding box
> calculation very accurately; playing around with margins is likely to
> lead to inconsistencies depending on labels, etc.

I don't see any need for that in my examples: R did the calculation
right to the nearest bp (and that's the accuracy of bounding boxes).

I suspect you mean GSView (on Windows): ghostview (a Unix program) does 
not AFAIK have that option.

If you just want a tight bounding box, gs's bbox device will give it to 
you.  On Unix, 

gs -sDEVICE=bbox -dBATCH -dNOPAUSE -q file.eps

will do something like

%%BoundingBox: 0 0 278 283
%%HiResBoundingBox: 0.000000 0.000000 277.992018 282.023991

just copy the first one into the file.  That's how all the figures in my 
books are included, for example.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From chunlou at yahoo.com  Wed May 28 00:14:03 2003
From: chunlou at yahoo.com (Chunlou Yung)
Date: Tue, 27 May 2003 18:14:03 -0400
Subject: [R] plot to stdout in batch mode
Message-ID: <NCBBKDNFIKJKKCFELNNMOEILDGAA.chunlou@yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030527/8a7f2d09/attachment.pl

From gaoz at zgi.com  Wed May 28 01:01:42 2003
From: gaoz at zgi.com (ZRG (Zeren Gao))
Date: Tue, 27 May 2003 16:01:42 -0700
Subject: [R] write staff out
Message-ID: <E31FE8BA49FA6A40B40883D8F0EF04C8764C97@stampy.zgi.com>

Hi there, 
I need to output t.test result from R into regular text file, anyone has a suggestion what kind of function to use in what format? 
thanks a lot. 
Zeren Gao



From maj at stats.waikato.ac.nz  Wed May 28 01:15:36 2003
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Wed, 28 May 2003 11:15:36 +1200
Subject: [R] The Wrong Choice: Locked in by license restrictions
Message-ID: <3ED3F198.7040602@stats.waikato.ac.nz>

A colleague pointed me to this article advocating R as a Matlab 
substitute. Here is the link (deliberately on two lines:

http://searchenterpriselinux.techtarget.com/
originalContent/0,289142,sid39_gci902076,00.html

I'm not a Matlab user, but I understand that it provides a nice front 
end to the Linpack collection of numerical linear algebra routines. My 
friend and I wonder if R can really compete in that league. Does anyone 
know if there are published benchmark comparisons between R and other 
packages like Matlab with the focus on numerical stability rather than 
speed?

Cheers,

Murray

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From baron at psych.upenn.edu  Wed May 28 01:20:15 2003
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Tue, 27 May 2003 19:20:15 -0400
Subject: [R] write staff out
In-Reply-To: <E31FE8BA49FA6A40B40883D8F0EF04C8764C97@stampy.zgi.com>
References: <E31FE8BA49FA6A40B40883D8F0EF04C8764C97@stampy.zgi.com>
Message-ID: <20030527232015.GB11354@mail1.sas.upenn.edu>

On 05/27/03 16:01, ZRG (Zeren Gao) wrote:
>Hi there, 
>I need to output t.test result from R into regular text file, anyone has a 
>suggestion what kind of function to use in what format? 
>thanks a lot. 

The following function prints a t test result in LaTeX format, in
a way that elicits the fewest complaints from reviewers for
psychology journals.  This is for a one-sample test.

ttest  <- function (x)
{
tc <- t.test(x)
print(paste("($t_{",tc[[2]],"}=",formatC(tc[[1]],format="f",digits=2),
            "$, $p=",formatC(tc[[3]],format="f"),"$)",sep=""),quote=FALSE)
print(tc$estimate)
}

I don't know how you want to represent degrees of freedom in
"regular text," but you can probably figure out how to modify this.

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R page:               http://finzi.psych.upenn.edu/



From spencer.graves at pdf.com  Wed May 28 01:35:50 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 27 May 2003 16:35:50 -0700
Subject: [R] write staff out
References: <E31FE8BA49FA6A40B40883D8F0EF04C8764C97@stampy.zgi.com>
Message-ID: <3ED3F656.4060504@pdf.com>

Have you considered "sink"?

hth.  spencer graves

ZRG (Zeren Gao) wrote:
> Hi there, 
> I need to output t.test result from R into regular text file, anyone has a suggestion what kind of function to use in what format? 
> thanks a lot. 
> Zeren Gao
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From rpeng at stat.ucla.edu  Wed May 28 02:11:00 2003
From: rpeng at stat.ucla.edu (Roger D. Peng)
Date: Tue, 27 May 2003 17:11:00 -0700
Subject: [R] The Wrong Choice: Locked in by license restrictions
In-Reply-To: <3ED3F198.7040602@stats.waikato.ac.nz>
References: <3ED3F198.7040602@stats.waikato.ac.nz>
Message-ID: <3ED3FE94.3080103@stat.ucla.edu>

My experience with Matlab users is that they perfer Matlab because of 
the various toolkits that are available (image processing comes to 
mind).  With respect to standard linear algebra my guess is that Octave, 
Matlab, and R are comparable.  A guess, though....

-roger

Murray Jorgensen wrote:
> A colleague pointed me to this article advocating R as a Matlab 
> substitute. Here is the link (deliberately on two lines:
> 
> http://searchenterpriselinux.techtarget.com/
> originalContent/0,289142,sid39_gci902076,00.html
> 
> I'm not a Matlab user, but I understand that it provides a nice front 
> end to the Linpack collection of numerical linear algebra routines. My 
> friend and I wonder if R can really compete in that league. Does anyone 
> know if there are published benchmark comparisons between R and other 
> packages like Matlab with the focus on numerical stability rather than 
> speed?
> 
> Cheers,
> 
> Murray
>



From kjetil at entelnet.bo  Wed May 28 02:11:26 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Tue, 27 May 2003 20:11:26 -0400
Subject: [R] write staff out
In-Reply-To: <E31FE8BA49FA6A40B40883D8F0EF04C8764C97@stampy.zgi.com>
Message-ID: <3ED3C66E.1847.D60BA7@localhost>

On 27 May 2003 at 16:01, ZRG (Zeren Gao) wrote:

Maybe capture.output is what you need, new in R-1.7.0

an example:

 capture.output( t.test( rnorm(10), rnorm(10, 2) ) )
 [1] ""                                                              
 [2] "  Welch Two Sample t-test"                                     
 [3] ""                                                              
 [4] "data:  rnorm(10) and rnorm(10, 2) "                            
 [5] "t = -5.5629, df = 16.133, p-value = 4.157e-05"                 
 [6] "alternative hypothesis: true difference in means is not equal 
to 0 "
 [7] "95 percent confidence interval:"                               
 [8] " -2.897467 -1.299261 "                                         
 [9] "sample estimates:"                                             
[10] " mean of x  mean of y "                                        
[11] "-0.1485742  1.9497894 "                                        
[12] ""                            


This also has a file= argument.

Kjetil Halvorsen

> Hi there, 
> I need to output t.test result from R into regular text file, anyone has a suggestion what kind of function to use in what format? 
> thanks a lot. 
> Zeren Gao
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Simon.Blomberg at anu.edu.au  Wed May 28 02:13:12 2003
From: Simon.Blomberg at anu.edu.au (Simon Blomberg)
Date: Wed, 28 May 2003 10:13:12 +1000
Subject: [R] Bradley Terry model and glmmPQL
Message-ID: <7A3A13F416B40842BD2C1753E044B359B133A6@CASEVS02.cas.anu.edu.au>

Dear R-ers,

I am having trouble understanding why I am getting an error using glmmPQL (library MASS).

I am getting the following error:

iteration 1 
Error in MEEM(object, conLin, control$niterEM) : 
        Singularity in backsolve at level 0, block 1

The long story:

I have data from an experiment on pairwise comparisons between 3 treatments (a, b, c). So a typical run of an experiment involves a rater choosing between a versus b, b versus c, or a versus c. The response is either 0 (not chosen) or 1 (chosen) for each treatment. I am interested in using the Bradley-Terry model to analyse this data. The Bradley-Terry model is a reparameterization of an ordinary logistic regression, using dummy variables to represent the treatment contrasts (see e.g. Agresti 1996 or Agresti 1990). It allows you to rank the treatments in accordance to preference. So my data looks something like this:

    rater age  a  b  c success failure
1       a   1  1 -1  0       1       0
2       b   1 -1  0  1       0       1
3       c   1  0  1 -1       1       0
4       d   1  1 -1  0       1       0
5       e   1 -1  0  1       0       1
6       f   1  0  1 -1       0       1
7       g   1  1 -1  0       0       1
8       h   1 -1  0  1       0       1
9       i   1  0  1 -1       1       0
10      j   1  1 -1  0       1       0
11      a   1 -1  0  1       0       1
12      b   1  0  1 -1       0       1
13      c   1  1 -1  0       0       1
14      d   1 -1  0  1       1       0
15      e   1  0  1 -1       1       0
16      f   1  1 -1  0       1       0
17      g   1 -1  0  1       1       0
18      h   1  0  1 -1       0       1
19      i   1  1 -1  0       1       0
20      j   1 -1  0  1       1       0
...

This is simulated data, but it corresponds to what my real data look like. Note: There are 10 raters (a to j), they repeat the experiment at two ages (1 and 2). Each rater rates all 3 treatment combinations at least once (and in my simulations up to 10 times). So for case 1, this corresponds to a trial between treatments a and b. a was chosen, which corresponds to a success. Similarly, for case 2 which is a trial between c and a, a was chosen, which corresponds to a failure. There are no ties.

The Bradley-Terry model can be fit using glm:

fit <- glm(cbind(success, failure) ~ c + b + nb -1, family=binomial, data=dat)

which works fine. I can also include the age factor, which also seems to work ok:

fit2 <- glm(cbind(success, failure) ~ c + b + nb + as.factor(age) -1, family=binomial, data=dat)

Now, since each rater performs ratings on each of the 3 treatment combinations, I was interested in including rater as a random factor. My naive method was to use glmmPQL from library MASS:

fit3 <- glmmPQL(cbind(success, failure) ~ c + b + nb -1, random = ~1|rater, family=binomial, data=dat)

However, I get the following error:

iteration 1 
Error in MEEM(object, conLin, control$niterEM) : 
        Singularity in backsolve at level 0, block 1

Can someone interpret this error for me, and tell me where I have gone wrong? Is there an alternative approach? Or am I thinking about this problem in the wrong way?

Thanks in advance,

Simon.

Simon Blomberg
Depression & Anxiety Consumer Research Unit
Centre for Mental Health Research
Australian National University
http://www.anu.edu.au/cmhr/
Simon.Blomberg at anu.edu.au  +61 (2) 6125 3379



From Simon.Blomberg at anu.edu.au  Wed May 28 02:35:47 2003
From: Simon.Blomberg at anu.edu.au (Simon Blomberg)
Date: Wed, 28 May 2003 10:35:47 +1000
Subject: [R] Bradley Terry model and glmmPQL
Message-ID: <7A3A13F416B40842BD2C1753E044B359B098C6@CASEVS02.cas.anu.edu.au>

aargh. "nb" should be "a" for each of the model formulae. This is not the source of the error. sorry for any confusion.

Simon.

> 
> fit <- glm(cbind(success, failure) ~ c + b + nb -1, 
> family=binomial, data=dat)
> 
> which works fine. I can also include the age factor, which 
> also seems to work ok:
> 
> fit2 <- glm(cbind(success, failure) ~ c + b + nb + 
> as.factor(age) -1, family=binomial, data=dat)
> 
> Now, since each rater performs ratings on each of the 3 
> treatment combinations, I was interested in including rater 
> as a random factor. My naive method was to use glmmPQL from 
> library MASS:
> 
> fit3 <- glmmPQL(cbind(success, failure) ~ c + b + nb -1, 
> random = ~1|rater, family=binomial, data=dat)
> 
> However, I get the following error:
> 
> iteration 1 
> Error in MEEM(object, conLin, control$niterEM) : 
>         Singularity in backsolve at level 0, block 1



From wettenhall at wehi.edu.au  Wed May 28 04:14:21 2003
From: wettenhall at wehi.edu.au (James Wettenhall)
Date: Wed, 28 May 2003 12:14:21 +1000 (EST)
Subject: [R] R_GlobalEnv
Message-ID: <Pine.LNX.4.44.0305281206530.14479-100000@unix24.alpha.wehi.edu.au>

Hi,

I'm trying to access the current R global environment from 
within C, using R_GlobalEnv.

In the example below, Rgui (R 1.7.0. Win2K) crashes when I try 
to run assignValueToFooInR_GlobalEnv, but not when I run 
assignValueToFooInRhoEnv with Rho=.GlobalEnv.  Can anyone tell me why?

[ My motivation is that I want use defineVar to initialise a 
workingEnvironment (corresponding to Value below), so that event-handler 
functions for a specific C library (which must have a specific 
prototype) can call R functions by looking up workingEnvironment with 
findVar. Earlier, I tried a static global SEXP variable in C to 
keep track of the environment, but that's not reliable because 
of garbage collection. Maybe SEXPREC would work better? ]

Thanks in advance,
James


***** testR_GlobalEnv.c *****
#include <R.h>
#include <Rinternals.h>
#include <R_ext/Rdynload.h>
#include <R_ext/Memory.h>
#include <R_ext/Applic.h>

static SEXP assignValueToFooInRhoEnv(SEXP Value,SEXP Rho)
{
    defineVar(install("Foo"),Value,Rho);
    return Value;
}

static SEXP assignValueToFooInR_GlobalEnv(SEXP Value)
{
    defineVar(install("Foo"),Value,R_GlobalEnv);
    return Value;
}

static const
R_CallMethodDef CallEntries[] = {
{"assignValueToFooInRhoEnv",     
(DL_FUNC)&assignValueToFooInRhoEnv,2},
{"assignValueToFooInR_GlobalEnv", 
(DL_FUNC)&assignValueToFooInR_GlobalEnv,1},
{NULL,NULL,0}
};

void R_init_testR_GlobalEnv(DllInfo *info)
{
  R_registerRoutines(info,NULL,CallEntries,NULL,NULL);
}


***** In R *****
> dyn.load("testR_GlobalEnv")
> .Call("assignValueToFooInRhoEnv", 5, .GlobalEnv)
[1] 5
> Foo
[1] 5
> .Call("assignValueToFooInR_GlobalEnv", 5)

Then Rgui crashes!



From DivineSAAM at aol.com  Wed May 28 04:45:49 2003
From: DivineSAAM at aol.com (DivineSAAM@aol.com)
Date: Tue, 27 May 2003 22:45:49 -0400
Subject: [R] The Wrong Choice: Locked in by license restrictions
Message-ID: <268E647A.229C4113.0B088159@aol.com>

In a message dated 5/27/2003 7:11:00 PM Eastern Standard Time, rpeng at stat.ucla.edu writes:

> originalContent/0,289142,sid39_gci902076,00.html

I run MATLAB v6.5 Release 13. In my view, the benefit of Matlab over R depends on your objectives. I am now using R exclusively, except for solving differential and partial differential equations which R is weak in. If a comparable suite of DEQ solvers were available for R, then, in my opinion, R would be superior to MATLAB for many reasons (too numerous to list).

Both use LAPACK. Prof. Bates Matrix package is a useful complement based on LAPACK. From a computational statistics point of view, MATLAB cannot compare to R, R is much much better anf the support on r-news, well, there is nothing like it for MATLAB. So, unless you need to solve DEQs (IVPs and BVPs), PDEs, and now delay DEQs, use R.

I have tried to find the fortran versions of the MATLAB ODE suite but have not been successful. Also, looking at the MATLAB code has not been helpful because the solvers make extensive use of MATLAB built-ins. Don't get me wrong, MATLAB is an outstanding product...R is "simply the best" (Tina Turner)

The Serial Fortran Solvers for ODE Initial Value Problems by Alan C. Hindmarsh in Fortran (http://www.llnl.gov/CASC/odepack/) would be very nice to have in R for scientific computing.

There are benchmark comparisions of MATLAB vs. S-PLUS in the s-news archives.

Livin La Vida [R]oca (tranlation [R]ockin and [R]ollin)

oscar



From rg117 at yahoo.co.uk  Wed May 28 04:52:18 2003
From: rg117 at yahoo.co.uk (=?iso-8859-1?q?Rishabh=20Gupta?=)
Date: Wed, 28 May 2003 03:52:18 +0100 (BST)
Subject: [R] 0 margin for creating eps files
In-Reply-To: <20030527193305.52325.qmail@web41101.mail.yahoo.com>
Message-ID: <20030528025218.65130.qmail@web41110.mail.yahoo.com>

Hi,
 Thanks to everyone that replied. It seems that the solution was simpler than I thought. I was
using the wrong parameter. It should have been

	par( mar = c( .., .., .., ..) )

rather than

	par( mai = c( .., .., .., ..) )

After I changed that it works fine now.

Thanks

Rishabh

 --- Rishabh Gupta <rg117 at yahoo.co.uk> wrote: > Dear all,
> 
> I am trying to create eps files of R plots (in Linux) so that I can import them into Word
> (obviously in MS Windows). What I would like is for the files to be cropped so that there is no
> margin around the actual plot, because I have no way of editing the files after they have been
> created. I have tried using
> 
> par(mai=c(.75,.75,0,0))
> 
> in order to reduce the margin; it works fine when I create a plot on the screen, however when I
> use
> 
> dev.copy2eps(file="FILENAME.eps")
> 
> to save to the eps file, the margin has returned. Could someone please tell what I am doing
> wrong,
> should I be using different parameter to set the margins of the eps files.
> 
> Any help would be greatly appreciated.
> 
> Many Thanks
> 
> Rishabh
> 
> __________________________________________________
> It's Samaritans' Week. Help Samaritans help others. 
> Call 08709 000032 to give or donate online now at
> http://www.samaritans.org/support/donations.shtm
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help 

__________________________________________________

http://uk.promotions.yahoo.com/yplus/yoffer.html



From kjetil at entelnet.bo  Wed May 28 06:18:33 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Wed, 28 May 2003 00:18:33 -0400
Subject: [R] The Wrong Choice: Locked in by license restrictions
In-Reply-To: <268E647A.229C4113.0B088159@aol.com>
Message-ID: <3ED40059.2085.1B84B93@localhost>

On 27 May 2003 at 22:45, DivineSAAM at aol.com wrote:

> In a message dated 5/27/2003 7:11:00 PM Eastern Standard Time, rpeng at stat.ucla.edu writes:
> 
> > originalContent/0,289142,sid39_gci902076,00.html
> 
> I run MATLAB v6.5 Release 13. In my view, the benefit of Matlab over R depends on your objectives. I am now using R exclusively, except for solving differential and partial differential equations which R is weak in. If a comparable suite of DEQ solvers were available for R, then, in my opinion, 
R would be superior to MATLAB for many reasons (too numerous to list).
> 
> Both use LAPACK. Prof. Bates Matrix package is a useful complement based on LAPACK. From a computational statistics point of view, MATLAB cannot compare to R, R is much much better anf the support on r-news, well, there is nothing like it for MATLAB. So, unless you need to solve DEQs (IVPs and 
BVPs), PDEs, and now delay DEQs, use R.
> 
> I have tried to find the fortran versions of the MATLAB ODE suite but have not been successful. Also, looking at the MATLAB code has not been helpful because the solvers make extensive use of MATLAB built-ins. Don't get me wrong, MATLAB is an outstanding product...R is "simply the best" (Tina 
Turner)
> 
> The Serial Fortran Solvers for ODE Initial Value Problems by Alan C. Hindmarsh in Fortran (http://www.llnl.gov/CASC/odepack/) would be very nice to have in R for scientific computing.
> 


On CRAN there is the package odesolve. From library(help=odesolve):

Package: odesolve
Version: 0.5-8
Date: 2003/01/31
Title: Solvers for Ordinary Differential Equations
Author: R. Woodrow Setzer <setzer.woodrow at epa.gov>
Maintainer: R. Woodrow Setzer <setzer.woodrow at epa.gov>
Depends: R (>= 1.4.0)
Description: This package provides an interface for the ODE solver
        lsoda. ODEs are expressed as R functions or as compiled code.

Can you comment on the benefits of odepack versus lsoda?

Kjetil Halvorsen

> There are benchmark comparisions of MATLAB vs. S-PLUS in the s-news archives.
> 
> Livin La Vida [R]oca (tranlation [R]ockin and [R]ollin)
> 
> oscar
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From P.Lemmens at nici.kun.nl  Wed May 28 08:33:33 2003
From: P.Lemmens at nici.kun.nl (Paul Lemmens)
Date: Wed, 28 May 2003 08:33:33 +0200
Subject: [R] Numbers that look equal, should be equal, but if() doesn't see
	as equal (repost with code included)
Message-ID: <1081812.1054110813@lemmens.socsci.kun.nl>

Hi!

Apologies for sending the mail without any code. Apparently somewhere along 
the way the .R attachments got filtered out. I have included the code below 
as clean as possible. My original mail is below the code.

Thank you again for your time.
regards,
Paul

vincentize <- function(data, bins)
{
	if ( length(data) < 2 )
	{
		stop("The data is really short. Is that ok?");
	}

	if ( bins < 2 )
	{
		stop("A number of bins smaller than 2 just really isn't useful");
	}

	if ( bins > length(data) )
	{
		stop("This is really unusual, although perhaps possible. If your eally 
know what you're doing, maybe you should disable this check!?.");
	}
	
	ret <- c();
	for ( i in 1:length(data))
	{
		rt <- data[i];
		b <- 0;
		while ( b < bins )
		{
			ret <- c(ret, rt);
			b <- b+1;
		}
	}

	ret;
}


binify <- function(data, bins, n)
{
	if ( bins < 2 )
	{
		stop("Number of bins is smaller than 2. Nothing to split, exiting.");
	}

	if ( length(data) < 2 )
	{
		stop("The length of the data is really short. Is that ok?");
	}

	if ( bins * n != length(data) )
	{
		stop("Cannot construct bins of equal length.");
	}

	t(array(data, c(n,bins)));
}

mean.bins <- function(data)
{
	# For the vincentizing procedures in vincentize() and binify(),
 	# it made sense to check the data array/vector/matrix. Here,
	# we now just need to check that data is a matrix.
	if ( !is.matrix(data) )
	{
		stop("The data is not in matrix form.");
	}

	means <- c();
	bins <- dim(data)[1];
	for (i in 1:bins)
	{
		means <- c(means, mean(data[i,]));
	}

	# return a vector of means.
	means;
}

bins.factor <- function(data, bins)
{
	if ( !is.data.frame(data) )
	{
		stop("data is not a data frame.");
	}

	source('Ratcliff.r', local=TRUE);
	subject.bin.means <- c();

	attach(data);
	l <- levels(Cond);
	for ( i in 1:length(l) )
	{
		cat("Calculating bins for factor level ", l[i], ".\n", sep="");
		flush.console();

		data <- RT[Cond == l[i]];
		data <- sort(data);

		n <- length(data);
		data.vincent <- vincentize(data,bins);
		data.vincent.bins <- binify(data.vincent, bins, n);
		bin.means <- mean.bins(data.vincent.bins);

		# FAILING TEST.
		mean.orig <- mean(data);
		mean.b <- mean(bin.means);
		if ( mean.b != mean.orig )
		{
			#cat("mean.b\n", str(mean.b), "mean.orig\n", str(mean.orig)); 
flush.console;
			detach(data);
			stop("Something went wrong calculating the bins: means do not equal.");
		}		
		subject.bin.means <- c(subject.bin.means, bin.means);
	}
	detach(data);

	if ( !length(subject.bin.means) == bins*length(l) )
	{
		stop("Inappropriate number of means calculated.");
	}
	else
	{
		subject.bin.means
	}
}

---------- Forwarded Message ----------
Date: dinsdag 27 mei 2003 14:53 +0200
From: Paul Lemmens <P.Lemmens at nici.kun.nl>
To: r-help at stat.math.ethz.ch
Subject: [R] Numbers that look equal, should be equal, but if() doesn't see 
as equal

Hi!

After a lot of testing and debugging I'm falling silent in figuring out
what goes wrong in the following.

I'm implementing the Vincentizing procedure that Ratcliff (1979) described.
It's about calculating RT bins for any distribution of RT data. It boils
down to rank ordering your data, replicating each data point as many times
as you need bins and then splitting up the resulting distribution in equal
bins.

The code that I've written is attached (and not included because it is
considerable in length due to many comments). Ratcliff.r contains some
basic functions and distribution.bins.r contains the problematic function
bins.factor() (problem area marked with 'FAILING TEST'). The final attached
file is the mock up distribution I made.

The failing test is the check if the mean of the mean RT's for each bin
equals the mean of the original distribution. These should/are
mathematically equivalent. Sometimes, however, the test fails. With the
attached distribution most notably for 4, 7, 8, 9, and 13 bins. Since the
means are mathematically equivalent IMHO it should not be an issue of this
particular distribution. As a matter of fact, I also have tested some
rnorm() distributions and my function also fails on those (albeit a little
less often than with foobar.txt).

Problem description: if one calculates the bins or bin means by hand, the
mean of the bin means is visually the same as the overall mean, even with
options(digits=20), but *still* the test fails.

IMHO it's not my code and neither the distribution I use to test, but
still, can you point out an obvious failure of my programming or is it
indeed something of R that I don't yet grasp?

thank you for your help,
Paul


-- 
Paul Lemmens
NICI, University of Nijmegen              ASCII Ribbon Campaign /"\
Montessorilaan 3 (B.01.03)                    Against HTML Mail \ /
NL-6525 HR Nijmegen                                              X
The Netherlands                                                 / \
Phonenumber    +31-24-3612648
Fax            +31-24-3616066


---------- End Forwarded Message ----------




-- 
Paul Lemmens
NICI, University of Nijmegen              ASCII Ribbon Campaign /"\
Montessorilaan 3 (B.01.03)                    Against HTML Mail \ /
NL-6525 HR Nijmegen                                              X
The Netherlands                                                 / \
Phonenumber    +31-24-3612648
Fax            +31-24-3616066

-------------- next part --------------
Hi!

After a lot of testing and debugging I'm falling silent in figuring out 
what goes wrong in the following.

I'm implementing the Vincentizing procedure that Ratcliff (1979) described. 
It's about calculating RT bins for any distribution of RT data. It boils 
down to rank ordering your data, replicating each data point as many times 
as you need bins and then splitting up the resulting distribution in equal 
bins.

The code that I've written is attached (and not included because it is 
considerable in length due to many comments). Ratcliff.r contains some 
basic functions and distribution.bins.r contains the problematic function 
bins.factor() (problem area marked with 'FAILING TEST'). The final attached 
file is the mock up distribution I made.

The failing test is the check if the mean of the mean RT's for each bin 
equals the mean of the original distribution. These should/are 
mathematically equivalent. Sometimes, however, the test fails. With the 
attached distribution most notably for 4, 7, 8, 9, and 13 bins. Since the 
means are mathematically equivalent IMHO it should not be an issue of this 
particular distribution. As a matter of fact, I also have tested some 
rnorm() distributions and my function also fails on those (albeit a little 
less often than with foobar.txt).

Problem description: if one calculates the bins or bin means by hand, the 
mean of the bin means is visually the same as the overall mean, even with 
options(digits=20), but *still* the test fails.

IMHO it's not my code and neither the distribution I use to test, but 
still, can you point out an obvious failure of my programming or is it 
indeed something of R that I don't yet grasp?

thank you for your help,
Paul


-- 
Paul Lemmens
NICI, University of Nijmegen              ASCII Ribbon Campaign /"\
Montessorilaan 3 (B.01.03)                    Against HTML Mail \ /
NL-6525 HR Nijmegen                                              X
The Netherlands                                                 / \
Phonenumber    +31-24-3612648
Fax            +31-24-3616066

-------------- next part --------------
"RT" "Cond"
"1"  1 "A"
"2"  1 "A"
"3"  1 "A"
"4"  2 "A"
"5"  2 "A"
"6"  3 "A"
"7"  3 "A"
"8"  3 "A"
"9"  3 "A"
"10"  3 "A"
"11"  4 "A"
"12"  4 "A"
"13"  4 "A"
"14"  4 "A"
"15"  5 "A"
"16"  5 "A"
"17"  5 "A"
"18"  5 "A"
"19"  5 "A"
"20"  5 "A"
"21"  5 "A"
"22"  6 "A"
"23"  6 "A"
"24"  6 "A"
"25"  6 "A"
"26"  6 "A"
"27"  6 "A"
"28"  6 "A"
"29"  6 "A"
"30"  6 "A"
"31"  7 "A"
"32"  7 "A"
"33"  7 "A"
"34"  7 "A"
"35"  8 "A"
"36"  8 "A"
"37"  8 "A"
"38"  9 "A"
"39"  9 "A"
"40" 10 "A"
"41"  2 "B"
"42"  2 "B"
"43"  2 "B"
"44"  4 "B"
"45"  4 "B"
"46"  6 "B"
"47"  6 "B"
"48"  6 "B"
"49"  6 "B"
"50"  6 "B"
"51"  8 "B"
"52"  8 "B"
"53"  8 "B"
"54"  8 "B"
"55" 10 "B"
"56" 10 "B"
"57" 10 "B"
"58" 10 "B"
"59" 10 "B"
"60" 10 "B"
"61" 10 "B"
"62" 12 "B"
"63" 12 "B"
"64" 12 "B"
"65" 12 "B"
"66" 12 "B"
"67" 12 "B"
"68" 12 "B"
"69" 12 "B"
"70" 12 "B"
"71" 14 "B"
"72" 14 "B"
"73" 14 "B"
"74" 14 "B"
"75" 16 "B"
"76" 16 "B"
"77" 16 "B"
"78" 18 "B"
"79" 18 "B"
"80" 20 "B"
"81"  3 "C"
"82"  3 "C"
"83"  3 "C"
"84"  6 "C"
"85"  6 "C"
"86"  9 "C"
"87"  9 "C"
"88"  9 "C"
"89"  9 "C"
"90"  9 "C"
"91" 12 "C"
"92" 12 "C"
"93" 12 "C"
"94" 12 "C"
"95" 15 "C"
"96" 15 "C"
"97" 15 "C"
"98" 15 "C"
"99" 15 "C"
"100" 15 "C"
"101" 15 "C"
"102" 18 "C"
"103" 18 "C"
"104" 18 "C"
"105" 18 "C"
"106" 18 "C"
"107" 18 "C"
"108" 18 "C"
"109" 18 "C"
"110" 18 "C"
"111" 21 "C"
"112" 21 "C"
"113" 21 "C"
"114" 21 "C"
"115" 24 "C"
"116" 24 "C"
"117" 24 "C"
"118" 27 "C"
"119" 27 "C"
"120" 30 "C"
-------------- next part --------------
______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help

From brostaux.y at fsagx.ac.be  Wed May 28 10:29:34 2003
From: brostaux.y at fsagx.ac.be (Yves Brostaux)
Date: Wed, 28 May 2003 10:29:34 +0200
Subject: [R] Slow computation in for loop
Message-ID: <5.1.0.14.1.20030528101427.00b0e110@fusamail.fsagx.ac.be>

Dear members,

I'm using R to do some test computation on a set of parameters of a 
function. This function is included in three for() loops, first one for 
replications, and the remaining two cycling through possible parameters 
values, like this :

for (k in replicates) {
   data <- sampling from a population
   for (i in param1) {
     for (j in param2) {
        result <- function(i, j, data)
     }
   }
}

With the 'hardest' set of parameters, a single computation of the function 
take about 16s on an old Sun Sparc workstation with 64 Mb RAM and don't 
access a single time to disk.

But when I launch the for() loops (which generate 220 function calls), disk 
gets very sollicitated and the whole process takes as much as 8 to 10 
hours, instead of the expected 1 hour.

What's wrong here ? Is there a thing I don't know about for() loops, and a 
way to correct it ?



From Stefan.Strecker at iw.uni-karlsruhe.de  Wed May 28 11:17:43 2003
From: Stefan.Strecker at iw.uni-karlsruhe.de (Strecker, Stefan)
Date: Wed, 28 May 2003 11:17:43 +0200
Subject: [R] Test for trend?
Message-ID: <D5F4FCB34ECBC041992A289145E3FD662F214C@ibwsrvp2.iw.uni-karlsruhe.de>

Hello R community,

I would like to test for learning effects by subjects in my experiment. Each subject participates in six consecutive auction rounds of the same treatment.
The response variable is the efficiency of an auction outcome measured by a real number. Since the efficiency increases over the six rounds, I suppose that subjects learn about the rules of the auction institution, but I would like to test for that conjecture. 

The prop.trend.test does not seem to be right, because the treatment does not change between the rounds, i.e. the number of trials (n) is not available. A linear regression shows a positive slope and the 99%-confidence interval shows a significant deviation from a zero slope, but I am not able to compute the exact p-value. The Cox-Stuart test for trend detects a trend but gives a p-value of 1.

Isn't there a distribution-free, exact test for trend which operates on the rank-oder of the data instead of binary coded values?

Please apologize for asking a rather R-unspecific question.

Thanks in advance
Stefan
---
Stefan Strecker
Universitaet Karlsruhe (TH)
Department of Economics and Business Engineering
Chair for Information Management and Systems
Englerstrasse 14
D-76131 Karlsruhe, Germany
T: +49 721 608 8374
F: +49 721 608 8399
M: +49 179 69 29 746
http://www.iw.uni-karlsruhe.de
DH PGP Key available upon request



From p.dalgaard at biostat.ku.dk  Wed May 28 11:30:32 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed, 28 May 2003 09:30:32 -0000
Subject: [R] Slow computation in for loop
In-Reply-To: <5.1.0.14.1.20030528101427.00b0e110@fusamail.fsagx.ac.be>
References: <5.1.0.14.1.20030528101427.00b0e110@fusamail.fsagx.ac.be>
Message-ID: <x2vfvv2yzo.fsf@biostat.ku.dk>

Yves Brostaux <brostaux.y at fsagx.ac.be> writes:

> Dear members,
> 
> I'm using R to do some test computation on a set of parameters of a
> function. This function is included in three for() loops, first one
> for replications, and the remaining two cycling through possible
> parameters values, like this :
> 
> for (k in replicates) {
>    data <- sampling from a population
>    for (i in param1) {
>      for (j in param2) {
>         result <- function(i, j, data)
>      }
>    }
> }
> 
> With the 'hardest' set of parameters, a single computation of the
> function take about 16s on an old Sun Sparc workstation with 64 Mb RAM
> and don't access a single time to disk.
> 
> But when I launch the for() loops (which generate 220 function calls),
> disk gets very sollicitated and the whole process takes as much as 8
> to 10 hours, instead of the expected 1 hour.
> 
> What's wrong here ? Is there a thing I don't know about for() loops,
> and a way to correct it ?

The problem with pseudocode: You didn't really overwrite the "result"
every time did you? I bet you stored it somewhere.

Two common causes of inefficiency are (a) that the stored objects may
be large and (b) some naive ways of storing the results involve
copying all preceding results, e.g.

list.of.results <- list()
for (.....){
     result <- ...
     list.of.results <- c(list.of.results, result)
}

The fix for (a) is to extract what you need and discard the rest
and for (b) to allocate the list up front with the proper length and
assign to list.of.results[[i]].

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From christoph.lehmann at gmx.ch  Wed May 28 11:49:43 2003
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Wed, 28 May 2003 09:49:43 -0000
Subject: [R] plot() error-msg: "need finite xlim values"
Message-ID: <1054115337.2292.4.camel@christophl>

Hi
I try to plot a ROC curve, using the ROC library from bioonductor (using
the example in the help). Everything runs nicely except, that finally I
get the error: "Error in plot.window(xlim, ylim, log, asp, ...) :
        need finite xlim values"

---

> set.seed(123)
> state <- c(0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, + 1, 1,
1)
> markers <- c(1, 2, 1, 1, 2, 3, 3, 4, 2, 1, 1, 3, 2, 3, 2, 4, + 5, 2,
3, 4) + runif(20, -1, 1)
> roc1 <- rocdemo.sca(truth = state, data = markers, rule = dxrule.sca,
seqlen = 5)
> plot(roc1)
Error in plot.window(xlim, ylim, log, asp, ...) :
        need finite xlim values
In addition: Warning messages:
1: no finite arguments to min; returning Inf
2: no finite arguments to max; returning -Inf
3: no finite arguments to min; returning Inf
4: no finite arguments to max; returning -Inf


--
thanks for any help

christoph

-- 
Christoph Lehmann <christoph.lehmann at gmx.ch>



From brostaux.y at fsagx.ac.be  Wed May 28 12:02:54 2003
From: brostaux.y at fsagx.ac.be (Yves Brostaux)
Date: Wed, 28 May 2003 12:02:54 +0200
Subject: [R] Slow computation in for loop
In-Reply-To: <x2vfvv2yzo.fsf@biostat.ku.dk>
References: <5.1.0.14.1.20030528101427.00b0e110@fusamail.fsagx.ac.be>
	<5.1.0.14.1.20030528101427.00b0e110@fusamail.fsagx.ac.be>
Message-ID: <5.1.0.14.1.20030528113345.00b11a70@fusamail.fsagx.ac.be>

First of all, thank you for your response.

I actually have to refine my pseudocode. 'result' is a numerical vector of 
length 7, and is binded with whole results through an rbind() :

for (k in replicates) {
   data <- sampling from a population
   for (i in param1) {
     for (j in param2) {
        result <- function(i, j, data)
        all.results <- rbind(all.results, result)
     }
   }
}

all.result is at most a 220 rows and 7 columns data frame, which doesn't 
seem to be big enough to explain such a slow computation.

Moreover, previous computations with a sample size of 100, which took 
individually about 4 seconds at most, ran effectively in a little bit more 
than 15 minutes for the whole set.

The problem arise with a sample size of 500, increasing single function 
computation time normally, but not the whole process !?


At 11:37 28/05/03, you wrote:
>Yves Brostaux <brostaux.y at fsagx.ac.be> writes:
>
> > Dear members,
> >
> > I'm using R to do some test computation on a set of parameters of a
> > function. This function is included in three for() loops, first one
> > for replications, and the remaining two cycling through possible
> > parameters values, like this :
> >
> > for (k in replicates) {
> >    data <- sampling from a population
> >    for (i in param1) {
> >      for (j in param2) {
> >         result <- function(i, j, data)
> >      }
> >    }
> > }
> >
> > With the 'hardest' set of parameters, a single computation of the
> > function take about 16s on an old Sun Sparc workstation with 64 Mb RAM
> > and don't access a single time to disk.
> >
> > But when I launch the for() loops (which generate 220 function calls),
> > disk gets very sollicitated and the whole process takes as much as 8
> > to 10 hours, instead of the expected 1 hour.
> >
> > What's wrong here ? Is there a thing I don't know about for() loops,
> > and a way to correct it ?
>
>The problem with pseudocode: You didn't really overwrite the "result"
>every time did you? I bet you stored it somewhere.
>
>Two common causes of inefficiency are (a) that the stored objects may
>be large and (b) some naive ways of storing the results involve
>copying all preceding results, e.g.
>
>list.of.results <- list()
>for (.....){
>      result <- ...
>      list.of.results <- c(list.of.results, result)
>}
>
>The fix for (a) is to extract what you need and discard the rest
>and for (b) to allocate the list up front with the proper length and
>assign to list.of.results[[i]].
>
>--
>    O__  ---- Peter Dalgaard             Blegdamsvej 3
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
>~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From DivineSAAM at aol.com  Wed May 28 12:24:46 2003
From: DivineSAAM at aol.com (DivineSAAM@aol.com)
Date: Wed, 28 May 2003 06:24:46 -0400
Subject: [R] The Wrong Choice: Locked in by license restrictions
Message-ID: <4ACD6DD9.49FC254F.0B088159@aol.com>

In a message dated 5/27/2003 11:18:33 PM Eastern Standard Time, kjetil at entelnet.bo writes:

> Can you comment on the benefits of odepack versus lsoda?

The benefit of ODEPACK vs. LSODA is mainly that ODEPACK is a collection of solvers (A. C. Hindmarsh (1983) "ODEPACK: a systematized collection of ODE solvers"; in Scientific Computing, ed. R. S. Stepleman et al., North Holland, Amsterdam, pp. 55--64.) whereas LSODA is a solver. Some problems demand alternate approaches. ODEPACK sports the Petzold DASSL solver which is of proven utility for large chemical systems. LSODA however is excellent and quite useful.

/oal



From phgrosjean at sciviews.org  Wed May 28 13:10:18 2003
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Wed, 28 May 2003 13:10:18 +0200
Subject: [R] Slow computation in for loop
In-Reply-To: <5.1.0.14.1.20030528113345.00b11a70@fusamail.fsagx.ac.be>
Message-ID: <MABBLJDICACNFOLGIHJOCEMMDHAA.phgrosjean@sciviews.org>

I suspect that your problem comes from the rbind(). I have also noticed an
exponentially slower execution with the increase of the size of the data
frame that you rbind()s. It is much faster to rbind() several separated
temporary data frames (let's say, ten by ten loops), and then to rbind()
them all together.

An even better solution is to allocate a data frame or matrix with the final
size (it seems you can predict it in your example), and then use
df[n, ] <- result
where df is your allocated data frame and n is the iteration.

Best,

Philippe Grosjean

...........]<(({?<...............<?}))><...............................
 ) ) ) ) )
( ( ( ( (       Dr. Philippe Grosjean
 ) ) ) ) )
( ( ( ( (       LOV, UMR 7093
 ) ) ) ) )      Station Zoologique
( ( ( ( (       Observatoire Oceanologique
 ) ) ) ) )      BP 28
( ( ( ( (       06234 Villefranche sur mer cedex
 ) ) ) ) )      France
( ( ( ( (
 ) ) ) ) )      tel: +33.4.93.76.38.18, fax: +33.4.93.76.38.34
( ( ( ( (
 ) ) ) ) )      e-mail: phgrosjean at sciviews.org
( ( ( ( (       SciViews project coordinator (http://www.sciviews.org)
 ) ) ) ) )
.......................................................................



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Yves Brostaux
Sent: mercredi 28 mai 2003 12:03
To: r-help at stat.math.ethz.ch
Cc: Peter Dalgaard BSA; Patrick Burns
Subject: Re: [R] Slow computation in for loop


First of all, thank you for your response.

I actually have to refine my pseudocode. 'result' is a numerical vector of
length 7, and is binded with whole results through an rbind() :

for (k in replicates) {
   data <- sampling from a population
   for (i in param1) {
     for (j in param2) {
        result <- function(i, j, data)
        all.results <- rbind(all.results, result)
     }
   }
}

all.result is at most a 220 rows and 7 columns data frame, which doesn't
seem to be big enough to explain such a slow computation.

Moreover, previous computations with a sample size of 100, which took
individually about 4 seconds at most, ran effectively in a little bit more
than 15 minutes for the whole set.

The problem arise with a sample size of 500, increasing single function
computation time normally, but not the whole process !?


At 11:37 28/05/03, you wrote:
>Yves Brostaux <brostaux.y at fsagx.ac.be> writes:
>
> > Dear members,
> >
> > I'm using R to do some test computation on a set of parameters of a
> > function. This function is included in three for() loops, first one
> > for replications, and the remaining two cycling through possible
> > parameters values, like this :
> >
> > for (k in replicates) {
> >    data <- sampling from a population
> >    for (i in param1) {
> >      for (j in param2) {
> >         result <- function(i, j, data)
> >      }
> >    }
> > }
> >
> > With the 'hardest' set of parameters, a single computation of the
> > function take about 16s on an old Sun Sparc workstation with 64 Mb RAM
> > and don't access a single time to disk.
> >
> > But when I launch the for() loops (which generate 220 function calls),
> > disk gets very sollicitated and the whole process takes as much as 8
> > to 10 hours, instead of the expected 1 hour.
> >
> > What's wrong here ? Is there a thing I don't know about for() loops,
> > and a way to correct it ?
>
>The problem with pseudocode: You didn't really overwrite the "result"
>every time did you? I bet you stored it somewhere.
>
>Two common causes of inefficiency are (a) that the stored objects may
>be large and (b) some naive ways of storing the results involve
>copying all preceding results, e.g.
>
>list.of.results <- list()
>for (.....){
>      result <- ...
>      list.of.results <- c(list.of.results, result)
>}
>
>The fix for (a) is to extract what you need and discard the rest
>and for (b) to allocate the list up front with the proper length and
>assign to list.of.results[[i]].
>
>--
>    O__  ---- Peter Dalgaard             Blegdamsvej 3
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
>~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Wed May 28 13:43:19 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 28 May 2003 12:43:19 +0100 (BST)
Subject: [R] Slow computation in for loop
In-Reply-To: <MABBLJDICACNFOLGIHJOCEMMDHAA.phgrosjean@sciviews.org>
Message-ID: <Pine.LNX.4.44.0305281240160.14422-100000@gannet.stats>

On Wed, 28 May 2003, Philippe Grosjean wrote:

> I suspect that your problem comes from the rbind(). I have also noticed an
> exponentially slower execution with the increase of the size of the data
> frame that you rbind()s. It is much faster to rbind() several separated
> temporary data frames (let's say, ten by ten loops), and then to rbind()
> them all together.
> 
> An even better solution is to allocate a data frame or matrix with the final
> size (it seems you can predict it in your example), and then use
> df[n, ] <- result
> where df is your allocated data frame and n is the iteration.

Since we are told the results are all numeric, it would be even better to 
use a pre-computed numeric matrix to store them.  rbind.data.frame is 
about the worst possible choice in such circumstances.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From hennig at stat.math.ethz.ch  Wed May 28 13:53:51 2003
From: hennig at stat.math.ethz.ch (Christian Hennig)
Date: Wed, 28 May 2003 13:53:51 +0200 (CEST)
Subject: [R] Kernel density
Message-ID: <Pine.LNX.4.44.0305281346030.11581-100000@florence>

Hi,

I want to fit a kernel density estimator by bkde of library KernSmooth.
I need only the density value at the point 0. 
I do not understand the following behaviour:

> q <- rnorm(100) 
> bkq <- bkde(q, bandwidth=0.11, gridsize=1, range.x=c(0,0))
Error in 0:L : NA/NaN argument
> bkq <- bkde(q, bandwidth=0.11, gridsize=1, range.x=c(-1,1))
> bkq
$x
[1] -1

$y
[1] NA

> bkq <- bkde(q, bandwidth=0.11, gridsize=3, range.x=c(-1,1))
Warning message: 
longer object length
	is not a multiple of shorter object length in: kappa * gcounts 
> bkq
$x
[1] -1  0  1

$y
[1] NA NA NA

> bkq <- bkde(q, bandwidth=0.11, range.x=c(-1,1))
(works, I get 401 proper y-values)

Adding truncate=FALSE does not change anything.
Do I really need to generate 401 (default gridsize) y-fits to extract the
one value I am interested in? What's the problem with specifying gridsize?

Best,
Christian


-- 
***********************************************************************
Christian Hennig
Seminar fuer Statistik, ETH-Zentrum (LEO), CH-8092 Zuerich (currently)
and Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at stat.math.ethz.ch, http://stat.ethz.ch/~hennig/
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag.de



From ripley at stats.ox.ac.uk  Wed May 28 14:41:12 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 28 May 2003 13:41:12 +0100 (BST)
Subject: [R] Kernel density
In-Reply-To: <Pine.LNX.4.44.0305281346030.11581-100000@florence>
Message-ID: <Pine.LNX.4.44.0305281329530.17103-100000@gannet.stats>

On Wed, 28 May 2003, Christian Hennig wrote:

> I want to fit a kernel density estimator by bkde of library KernSmooth.
> I need only the density value at the point 0. 
> I do not understand the following behaviour:

It's not designed to do that.  And why use a linear-binning method for
just one point?

gridsize has to be at least 6, it seems.

> > q <- rnorm(100) 
> > bkq <- bkde(q, bandwidth=0.11, gridsize=1, range.x=c(0,0))
> Error in 0:L : NA/NaN argument
> > bkq <- bkde(q, bandwidth=0.11, gridsize=1, range.x=c(-1,1))
> > bkq
> $x
> [1] -1
> 
> $y
> [1] NA
> 
> > bkq <- bkde(q, bandwidth=0.11, gridsize=3, range.x=c(-1,1))
> Warning message: 
> longer object length
> 	is not a multiple of shorter object length in: kappa * gcounts 
> > bkq
> $x
> [1] -1  0  1
> 
> $y
> [1] NA NA NA
> 
> > bkq <- bkde(q, bandwidth=0.11, range.x=c(-1,1))
> (works, I get 401 proper y-values)
> 
> Adding truncate=FALSE does not change anything.
> Do I really need to generate 401 (default gridsize) y-fits to extract the
> one value I am interested in? What's the problem with specifying gridsize?

Do read and debug the code, but also consider if this is a useful 
thing to do compared to, say,

> density(q, bw=0.11, n=1, from=0, to=0)

Call:
        density(x = q, bw = 0.11, n = 1, from = 0, to = 0)

Data: q (100 obs.);     Bandwidth 'bw' = 0.11

       x                y
 Min.   :0        Min.   :0.3202
 1st Qu.:0        1st Qu.:0.3202
 Median :0        Median :0.3202
 Mean   :0        Mean   :0.3202
 3rd Qu.:0        3rd Qu.:0.3202
 Max.   :0        Max.   :0.3202


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From clists at perrin.socsci.unc.edu  Wed May 28 14:42:07 2003
From: clists at perrin.socsci.unc.edu (Andrew Perrin)
Date: Wed, 28 May 2003 08:42:07 -0400 (EDT)
Subject: [R] Test for trend?
In-Reply-To: <D5F4FCB34ECBC041992A289145E3FD662F214C@ibwsrvp2.iw.uni-karlsruhe.de>
References: <D5F4FCB34ECBC041992A289145E3FD662F214C@ibwsrvp2.iw.uni-karlsruhe.de>
Message-ID: <Pine.LNX.4.53.0305280838580.708@perrin.socsci.unc.edu>

I think this depends on what you mean by "trend." What I would mean is
"effect of successive trials that is very unlikely to be spurious," which
is a good lay definition of statistical significance.

Given that these are multiple trials on the same subjects over time, it
seems like a mixed-effects model might be in order. Take a look at the
nlme pacakge, as well as Pinheiro and Bates' excellent treatment:

http://cm.bell-labs.com/cm/ms/departments/sia/project/nlme/MEMSS/index.html

...and John Fox's different (but also excellent) discussion:

http://www.socsci.mcmaster.ca/jfox/Books/Companion/appendix-mixed-models.pdf

Best,
Andy Perrin

----------------------------------------------------------------------
Andrew J Perrin - http://www.unc.edu/~aperrin
Assistant Professor of Sociology, U of North Carolina, Chapel Hill
clists at perrin.socsci.unc.edu * andrew_perrin (at) unc.edu


On Wed, 28 May 2003, Strecker, Stefan wrote:

> Hello R community,
>
> I would like to test for learning effects by subjects in my experiment. Each subject participates in six consecutive auction rounds of the same treatment.
> The response variable is the efficiency of an auction outcome measured by a real number. Since the efficiency increases over the six rounds, I suppose that subjects learn about the rules of the auction institution, but I would like to test for that conjecture.
>
> The prop.trend.test does not seem to be right, because the treatment does not change between the rounds, i.e. the number of trials (n) is not available. A linear regression shows a positive slope and the 99%-confidence interval shows a significant deviation from a zero slope, but I am not able to compute the exact p-value. The Cox-Stuart test for trend detects a trend but gives a p-value of 1.
>
> Isn't there a distribution-free, exact test for trend which operates on the rank-oder of the data instead of binary coded values?
>
> Please apologize for asking a rather R-unspecific question.
>
> Thanks in advance
> Stefan
> ---
> Stefan Strecker
> Universitaet Karlsruhe (TH)
> Department of Economics and Business Engineering
> Chair for Information Management and Systems
> Englerstrasse 14
> D-76131 Karlsruhe, Germany
> T: +49 721 608 8374
> F: +49 721 608 8399
> M: +49 179 69 29 746
> http://www.iw.uni-karlsruhe.de
> DH PGP Key available upon request
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From tlumley at u.washington.edu  Wed May 28 16:16:53 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 28 May 2003 07:16:53 -0700 (PDT)
Subject: [R] Numbers that look equal, should be equal, but if() doesn't
	see as equal (repost with code included)
In-Reply-To: <1081812.1054110813@lemmens.socsci.kun.nl>
Message-ID: <Pine.A41.4.44.0305280713230.115070-100000@homer25.u.washington.edu>

On Wed, 28 May 2003, Paul Lemmens wrote:

> Hi!
>
> Apologies for sending the mail without any code. Apparently somewhere along
> the way the .R attachments got filtered out. I have included the code below
> as clean as possible. My original mail is below the code.

I still think you need not to be using ==.  You want something like

if ( abs(mean.b-mean.orig)/(epsilon+abs(mean.orig) < epsilon){

You are effectively using epsilon=0, but epsilon=10e-10 should be
adequate.

	-thomas



> Thank you again for your time.
> regards,
> Paul
>
> vincentize <- function(data, bins)
> {
> 	if ( length(data) < 2 )
> 	{
> 		stop("The data is really short. Is that ok?");
> 	}
>
> 	if ( bins < 2 )
> 	{
> 		stop("A number of bins smaller than 2 just really isn't useful");
> 	}
>
> 	if ( bins > length(data) )
> 	{
> 		stop("This is really unusual, although perhaps possible. If your eally
> know what you're doing, maybe you should disable this check!?.");
> 	}
>
> 	ret <- c();
> 	for ( i in 1:length(data))
> 	{
> 		rt <- data[i];
> 		b <- 0;
> 		while ( b < bins )
> 		{
> 			ret <- c(ret, rt);
> 			b <- b+1;
> 		}
> 	}
>
> 	ret;
> }
>
>
> binify <- function(data, bins, n)
> {
> 	if ( bins < 2 )
> 	{
> 		stop("Number of bins is smaller than 2. Nothing to split, exiting.");
> 	}
>
> 	if ( length(data) < 2 )
> 	{
> 		stop("The length of the data is really short. Is that ok?");
> 	}
>
> 	if ( bins * n != length(data) )
> 	{
> 		stop("Cannot construct bins of equal length.");
> 	}
>
> 	t(array(data, c(n,bins)));
> }
>
> mean.bins <- function(data)
> {
> 	# For the vincentizing procedures in vincentize() and binify(),
>  	# it made sense to check the data array/vector/matrix. Here,
> 	# we now just need to check that data is a matrix.
> 	if ( !is.matrix(data) )
> 	{
> 		stop("The data is not in matrix form.");
> 	}
>
> 	means <- c();
> 	bins <- dim(data)[1];
> 	for (i in 1:bins)
> 	{
> 		means <- c(means, mean(data[i,]));
> 	}
>
> 	# return a vector of means.
> 	means;
> }
>
> bins.factor <- function(data, bins)
> {
> 	if ( !is.data.frame(data) )
> 	{
> 		stop("data is not a data frame.");
> 	}
>
> 	source('Ratcliff.r', local=TRUE);
> 	subject.bin.means <- c();
>
> 	attach(data);
> 	l <- levels(Cond);
> 	for ( i in 1:length(l) )
> 	{
> 		cat("Calculating bins for factor level ", l[i], ".\n", sep="");
> 		flush.console();
>
> 		data <- RT[Cond == l[i]];
> 		data <- sort(data);
>
> 		n <- length(data);
> 		data.vincent <- vincentize(data,bins);
> 		data.vincent.bins <- binify(data.vincent, bins, n);
> 		bin.means <- mean.bins(data.vincent.bins);
>
> 		# FAILING TEST.
> 		mean.orig <- mean(data);
> 		mean.b <- mean(bin.means);
> 		if ( mean.b != mean.orig )
> 		{
> 			#cat("mean.b\n", str(mean.b), "mean.orig\n", str(mean.orig));
> flush.console;
> 			detach(data);
> 			stop("Something went wrong calculating the bins: means do not equal.");
> 		}
> 		subject.bin.means <- c(subject.bin.means, bin.means);
> 	}
> 	detach(data);
>
> 	if ( !length(subject.bin.means) == bins*length(l) )
> 	{
> 		stop("Inappropriate number of means calculated.");
> 	}
> 	else
> 	{
> 		subject.bin.means
> 	}
> }
>
> ---------- Forwarded Message ----------
> Date: dinsdag 27 mei 2003 14:53 +0200
> From: Paul Lemmens <P.Lemmens at nici.kun.nl>
> To: r-help at stat.math.ethz.ch
> Subject: [R] Numbers that look equal, should be equal, but if() doesn't see
> as equal
>
> Hi!
>
> After a lot of testing and debugging I'm falling silent in figuring out
> what goes wrong in the following.
>
> I'm implementing the Vincentizing procedure that Ratcliff (1979) described.
> It's about calculating RT bins for any distribution of RT data. It boils
> down to rank ordering your data, replicating each data point as many times
> as you need bins and then splitting up the resulting distribution in equal
> bins.
>
> The code that I've written is attached (and not included because it is
> considerable in length due to many comments). Ratcliff.r contains some
> basic functions and distribution.bins.r contains the problematic function
> bins.factor() (problem area marked with 'FAILING TEST'). The final attached
> file is the mock up distribution I made.
>
> The failing test is the check if the mean of the mean RT's for each bin
> equals the mean of the original distribution. These should/are
> mathematically equivalent. Sometimes, however, the test fails. With the
> attached distribution most notably for 4, 7, 8, 9, and 13 bins. Since the
> means are mathematically equivalent IMHO it should not be an issue of this
> particular distribution. As a matter of fact, I also have tested some
> rnorm() distributions and my function also fails on those (albeit a little
> less often than with foobar.txt).
>
> Problem description: if one calculates the bins or bin means by hand, the
> mean of the bin means is visually the same as the overall mean, even with
> options(digits=20), but *still* the test fails.
>
> IMHO it's not my code and neither the distribution I use to test, but
> still, can you point out an obvious failure of my programming or is it
> indeed something of R that I don't yet grasp?
>
> thank you for your help,
> Paul
>
>
> --
> Paul Lemmens
> NICI, University of Nijmegen              ASCII Ribbon Campaign /"\
> Montessorilaan 3 (B.01.03)                    Against HTML Mail \ /
> NL-6525 HR Nijmegen                                              X
> The Netherlands                                                 / \
> Phonenumber    +31-24-3612648
> Fax            +31-24-3616066
>
>
> ---------- End Forwarded Message ----------
>
>
>
>
> --
> Paul Lemmens
> NICI, University of Nijmegen              ASCII Ribbon Campaign /"\
> Montessorilaan 3 (B.01.03)                    Against HTML Mail \ /
> NL-6525 HR Nijmegen                                              X
> The Netherlands                                                 / \
> Phonenumber    +31-24-3612648
> Fax            +31-24-3616066
>
>

Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle
^^^^^^^^^^^^^^^^^^^^^^^^
- NOTE NEW EMAIL ADDRESS



From P.Lemmens at nici.kun.nl  Wed May 28 16:35:59 2003
From: P.Lemmens at nici.kun.nl (Paul Lemmens)
Date: Wed, 28 May 2003 16:35:59 +0200
Subject: [R] Numbers that look equal, should be equal, but if() doesn't
	see as equal (repost with code included)
In-Reply-To: <Pine.A41.4.44.0305280713230.115070-100000@homer25.u.washington.edu>
References: <Pine.A41.4.44.0305280713230.115070-100000@homer25.u.washington.
	edu>
Message-ID: <30034125.1054139759@lemmens.socsci.kun.nl>

Hoi Thomas,

--On woensdag 28 mei 2003 7:16 -0700 Thomas Lumley 
<tlumley at u.washington.edu> wrote:

> On Wed, 28 May 2003, Paul Lemmens wrote:
>
>> Hi!
>>
>> Apologies for sending the mail without any code. Apparently somewhere
>> along the way the .R attachments got filtered out. I have included the
>> code below as clean as possible. My original mail is below the code.
>
> I still think you need not to be using ==.  You want something like
>
> if ( abs(mean.b-mean.orig)/(epsilon+abs(mean.orig) < epsilon){
>
> You are effectively using epsilon=0, but epsilon=10e-10 should be
> adequate.
>
Based on all the hints and explanations I've changed the test to 
'identical(all.equal(mean.b, mean.orig, tolerance=.Machine$double.eps), 
FALSE)'.

I still need to look into the concept of finite precision, because I still 
don't grasp how sometimes (as an extreme example, probably) 0.25 != 1/4. 
That this will happen for a number with a lot of different decimals I can 
understand (by an accumulation of rounding errors).


thnx all 4 your help!



-- 
Paul Lemmens
NICI, University of Nijmegen              ASCII Ribbon Campaign /"\
Montessorilaan 3 (B.01.03)                    Against HTML Mail \ /
NL-6525 HR Nijmegen                                              X
The Netherlands                                                 / \
Phonenumber    +31-24-3612648
Fax            +31-24-3616066



From szhan at uoguelph.ca  Wed May 28 16:48:08 2003
From: szhan at uoguelph.ca (szhan@uoguelph.ca)
Date: Wed, 28 May 2003 10:48:08 -0400
Subject: [R] Zero is not zero
Message-ID: <1054133288.3ed4cc287af66@webmail.uoguelph.ca>

Hello, There:
I read data from tab-delimted text file(1888.txt) in C:/temp, which has 
thousands rows and 80 colulms, using read.delim("C:/temp/1888.txt"). when I 
retrieved the numeric coulum which has real zero values and applies R buid-in 
function such as mean( ), sum() and got a result of NA. It seems that R (R 
1.6.2 in windows) considers zero as missing value (NA). Thus my question is 
how to read the real zero as zero.
Thank in advance.

Joshua



From ripley at stats.ox.ac.uk  Wed May 28 16:59:45 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 28 May 2003 15:59:45 +0100 (BST)
Subject: [R] Numbers that look equal, should be equal, but if() doesn't
	see as equal (repost with code included)
In-Reply-To: <30034125.1054139759@lemmens.socsci.kun.nl>
Message-ID: <Pine.LNX.4.44.0305281549550.10329-100000@gannet.stats>

On Wed, 28 May 2003, Paul Lemmens wrote:

> Hoi Thomas,
> 
> --On woensdag 28 mei 2003 7:16 -0700 Thomas Lumley 
> <tlumley at u.washington.edu> wrote:
> 
> > On Wed, 28 May 2003, Paul Lemmens wrote:
> >
> >> Hi!
> >>
> >> Apologies for sending the mail without any code. Apparently somewhere
> >> along the way the .R attachments got filtered out. I have included the
> >> code below as clean as possible. My original mail is below the code.
> >
> > I still think you need not to be using ==.  You want something like
> >
> > if ( abs(mean.b-mean.orig)/(epsilon+abs(mean.orig) < epsilon){
> >
> > You are effectively using epsilon=0, but epsilon=10e-10 should be
> > adequate.
> >
> Based on all the hints and explanations I've changed the test to 
> 'identical(all.equal(mean.b, mean.orig, tolerance=.Machine$double.eps), 
> FALSE)'.
> 
> I still need to look into the concept of finite precision, because I still 
> don't grasp how sometimes (as an extreme example, probably) 0.25 != 1/4. 
> That this will happen for a number with a lot of different decimals I can 
> understand (by an accumulation of rounding errors).

How you you think 0.25 gets converted to an internal number?  It might be
0 + 2/10 + 5/100, and 2/10 and 5/100 cannot be represented exactly in 
binary arithmetic.  (R uses the system's strtod routine, so how it is done 
is system-dependent: on my systems it does end up with the same bit 
pattern as 1/4.)

As a real example

> (0.1 + 0.2) == 0.3
[1] FALSE

since

> print(c(0.1 + 0.2, 0.3), digits=20)
[1] 0.30000000000000004 0.29999999999999999

yet

> print(c(0.1, 0.2, 0.3), digits=20)
[1] 0.1 0.2 0.3


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From supratik at stat.ucc.ie  Wed May 28 17:18:18 2003
From: supratik at stat.ucc.ie (Roy, Supratik)
Date: Wed, 28 May 2003 16:18:18 +0100
Subject: [R] modules in RedHat
Message-ID: <F64493091FAC4D4DAC46261FEC1967995FDBA0@xch4.ucc.ie>


I am having problems when calling "supsmu" in R 1.6.2 installed
on RedHat 8.0. I used the rpm provided on the R site. "supsmu"
seems to have not been installed by default - (i.e., as part of
the modreg package). It also does not occur as part of any of the
contibuted packages - so there apparently is no question about 
installing it from contributed libraries. Can anyone help?

Supratik Roy



From adi at roda.ro  Wed May 28 17:35:18 2003
From: adi at roda.ro (Adrian Dusa)
Date: Wed, 28 May 2003 18:35:18 +0300
Subject: [R] missing values
Message-ID: <000001c3252e$bf100f90$c13afea9@RODAL>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030528/427533d6/attachment.pl

From Simon.Fear at synequanon.com  Wed May 28 17:39:53 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Wed, 28 May 2003 16:39:53 +0100
Subject: [R] Numbers that look equal, should be equal,
	but if() doesn'tsee as equal (repost with code included)
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572AC0CC2@synequanon01>

Try the following function (the name is supposed to be a joke, by the
way),
which will also do the right thing with NAs and characters. Use it as
if(equal.enough(x,y)) rather than if(x==y), e.g.

> equal.enough(0.1+0.2, 0.3)
[1] TRUE

My default of 15 significant figures may be overkill in many
applications; be
prepared to reduce this.

Simon Fear


"equal.enough" <- function(x, y, sig.figs=15, d.p.zero=-Inf) {
# set argument d.p.zero to a real but small number (e.g. 1e-15) to
overide
# the sig.figs setting in favour of decimal places for comparison of
extremely small numbers
# (if appropriate - which is not always the case)
	if (is.numeric(x)) {
	  if (is.numeric(y)) {
	    if (is.infinite(d.p.zero))
		ifelse(is.na(x), is.na(y),
		ifelse(is.na(y), F,
		abs(signif(x, sig.figs) - signif(y, sig.figs)) == 0))
	    else
		ifelse(is.na(x), is.na(y),
		ifelse(is.na(y), F,
		abs(signif(x, sig.figs) - signif(y, sig.figs)) <=
d.p.zero))
	  } 
	  else is.na(y)		# a vector of F as long as y
	} else x==y
}
 

Simon Fear
Senior Statistician
Syne qua non Ltd
Tel: +44 (0) 1379 644449
Fax: +44 (0) 1379 644445
email: Simon.Fear at synequanon.com
web: http://www.synequanon.com
 
Number of attachments included with this message: 0
 
This message (and any associated files) is confidential and 
contains information which may be legally privileged.  It is 
intended for the stated addressee(s) only.  Access to this 
email by anyone else is unauthorised.  If you are not the 
intended addressee, any action taken (or not taken) in 
reliance on it, or any disclosure or copying of the contents of 
it is unauthorised and unlawful.  If you are not the addressee, 
please inform the sender immediately and delete the email 
from your system.

This message and any associated attachments have been 
checked for viruses using an internationally recognised virus 
detection process.  However, Internet communications cannot 
be guaranteed to be secure or error-free as information could 
be intercepted, corrupted, lost, destroyed, arrive late or 
incomplete. Therefore, we do not accept responsibility for any 
errors or omissions that are present in this message, or any 
attachment, that have arisen as a result of e-mail transmission.  
If verification is required, please request a hard-copy version. 
Any views or opinions presented are solely those of the author 
and do not necessarily represent those of Syne qua non.



From plummer at iarc.fr  Wed May 28 17:40:43 2003
From: plummer at iarc.fr (Martyn Plummer)
Date: Wed, 28 May 2003 15:40:43 -0000
Subject: [R] modules in RedHat
In-Reply-To: <F64493091FAC4D4DAC46261FEC1967995FDBA0@xch4.ucc.ie>
References: <F64493091FAC4D4DAC46261FEC1967995FDBA0@xch4.ucc.ie>
Message-ID: <1054136632.965.10.camel@xena>

On Wed, 2003-05-28 at 17:18, Roy, Supratik wrote:
> 
> I am having problems when calling "supsmu" in R 1.6.2 installed
> on RedHat 8.0. I used the rpm provided on the R site. "supsmu"
> seems to have not been installed by default - (i.e., as part of
> the modreg package). It also does not occur as part of any of the
> contibuted packages - so there apparently is no question about 
> installing it from contributed libraries. Can anyone help?

I don't keep old RPMS, so I can't confirm this problem, but the
RPM for R 1.7.0 definitely has the modreg package, and includes
the supsmu function. Try upgrading.

Martyn



From spencer.graves at pdf.com  Wed May 28 17:46:28 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 28 May 2003 08:46:28 -0700
Subject: [R] missing values
References: <000001c3252e$bf100f90$c13afea9@RODAL>
Message-ID: <3ED4D9D4.9060701@pdf.com>

VAR1[c(11, 13, 14)] <- NA

Is this what you what?
hth.  spencer graves

Adrian Dusa wrote:
> Dear list members,
> 
>  
> 
> I'm relatively new to this list; can anyone tell me how to declare
> missing values once a dataset has been attached?
> 
> For example here:
> 
>  
> 
>    VAR1
> 
> 1     1
> 
> 2     2
> 
> 3     1
> 
> 4     3
> 
> 5     2
> 
> 6     1
> 
> 7     3
> 
> 8     3
> 
> 9     1
> 
> 10    2
> 
> 11   98
> 
> 12    2
> 
> 13   97
> 
> 14   99
> 
> 15   NA
> 
> 16    3
> 
>  
> 
> I would like values 97, 98 and 99 to be treated as missing values.
> 
> I read everything about is.na but I just can't figure out how to do it. 
> 
>  
> 
> Many thanks,
> 
> Adrian
> 
>  
> 
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> Adrian Dusa (adi at roda.ro)
> Romanian Social Data Archive (www.roda.ro)
> 1, Schitu Magureanu Bd.
> 76625 Bucharest sector 5
> Romania
> Tel./Fax: +40 (21) 312.66.18
> 
>  
> 
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From B.Rowlingson at lancaster.ac.uk  Wed May 28 18:03:03 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 28 May 2003 17:03:03 +0100
Subject: [R] Numbers that look equal, should be equal, but if() doesn'tsee
	as equal (repost with code included)
In-Reply-To: <6C8A8033ABC1E3468048ABC4F13CE572AC0CC2@synequanon01>
References: <6C8A8033ABC1E3468048ABC4F13CE572AC0CC2@synequanon01>
Message-ID: <3ED4DDB7.7020308@lancaster.ac.uk>

Simon Fear wrote:
> Try the following function (the name is supposed to be a joke, by the
> way),
> which will also do the right thing with NAs and characters. Use it as
> if(equal.enough(x,y)) rather than if(x==y), e.g.
> 
> 
>>equal.enough(0.1+0.2, 0.3)
> 

  Oh, why not just go one step further, and redefine the == operator!

  "==" <- function(x,y){equal.enough(x,y)}

before:
 > (.1+.2)==.3
[1] FALSE

after:
 > (.1+.2)==.3
[1] TRUE

  This requires a slight modification to equal.enough, which I will not 
list here, so that people dont _actually_ do this. It just ensures that 
equal.enough doesn't go all infinitely recursive on us.

  Next time on useless R tips: 1 + 1 = 3

Barry



From tlumley at u.washington.edu  Wed May 28 18:15:45 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 28 May 2003 09:15:45 -0700 (PDT)
Subject: [R] missing values
In-Reply-To: <000001c3252e$bf100f90$c13afea9@RODAL>
Message-ID: <Pine.A41.4.44.0305280915060.130750-100000@homer40.u.washington.edu>

On Wed, 28 May 2003, Adrian Dusa wrote:

>
>
> I would like values 97, 98 and 99 to be treated as missing values.
>

VAR1[VAR1 %in% c(97,98,99)]<-NA

	-thomas



From Simon.Fear at synequanon.com  Wed May 28 18:17:19 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Wed, 28 May 2003 17:17:19 +0100
Subject: [R] Numbers that look equal, should be equal,
	but if() doesn'tsee as equal (repost with code included)
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572AC0CC4@synequanon01>

No problem, equal.enough(1+1,3,d.p.zero=10) !

But seriously, this is WHY NOT do that substitution: it helps me
remember
that I am not in fact truly testing for numeric identity. 

S


-----Original Message-----
From: Barry Rowlingson [mailto:B.Rowlingson at lancaster.ac.uk]
Sent: 28 May 2003 17:03
To: Simon Fear
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Numbers that look equal, should be equal, but if()
doesn'tsee as equal (repost with code included)

  Next time on useless R tips: 1 + 1 = 3

Barry
 

Simon Fear
Senior Statistician
Syne qua non Ltd
Tel: +44 (0) 1379 644449
Fax: +44 (0) 1379 644445
email: Simon.Fear at synequanon.com
web: http://www.synequanon.com
 
Number of attachments included with this message: 0
 
This message (and any associated files) is confidential and 
contains information which may be legally privileged.  It is 
intended for the stated addressee(s) only.  Access to this 
email by anyone else is unauthorised.  If you are not the 
intended addressee, any action taken (or not taken) in 
reliance on it, or any disclosure or copying of the contents of 
it is unauthorised and unlawful.  If you are not the addressee, 
please inform the sender immediately and delete the email 
from your system.

This message and any associated attachments have been 
checked for viruses using an internationally recognised virus 
detection process.  However, Internet communications cannot 
be guaranteed to be secure or error-free as information could 
be intercepted, corrupted, lost, destroyed, arrive late or 
incomplete. Therefore, we do not accept responsibility for any 
errors or omissions that are present in this message, or any 
attachment, that have arisen as a result of e-mail transmission.  
If verification is required, please request a hard-copy version. 
Any views or opinions presented are solely those of the author 
and do not necessarily represent those of Syne qua non.



From Edmond.Ng at lshtm.ac.uk  Wed May 28 18:38:15 2003
From: Edmond.Ng at lshtm.ac.uk (Edmond Ng)
Date: Wed, 28 May 2003 17:38:15 +0100
Subject: [R] supplying the Hessian to "nlm"
Message-ID: <sed4f410.025@s-webmail.lshtm.ac.uk>

Dear all, 

I am trying to minimize a function with 3 parameters using nlm. I have worked out the 2nd derivatives (incl the cross-product terms) and would like to supply them to nlm for evaluation. What I am not sure about is how to set up the Hessian matrix for nlm. That is, 

attr(lhat, "hessian") <- c(???) 

Do I have to enter all 9 of the entries or just the lower triangle of the matrix? I have not been able to find the documentation in relationship to this. Many thanks for any tips in advance. 

Edmond



From f.mattes at rfc.ucl.ac.uk  Wed May 28 18:48:26 2003
From: f.mattes at rfc.ucl.ac.uk (Frank Mattes)
Date: Wed, 28 May 2003 17:48:26 +0100
Subject: [R] how to get a line plot before/after treatment
Message-ID: <p05200f01bafa974cd5c7@[128.40.218.142]>

Dear R help-list reader,

I would like to generate a plot which compares to states in a patient 
treatment, before and after. for this reason I have generated a vector
before<-c(1,30,23,40)
and
after<-c(20,10,20,60)
the first element in "before" corresponds to the first element in "after".
I would like and generate a dotplot with
before and after as x-scale, the elements of "before" and "after" on 
the y-scale and the corresponding elements connected with a line.

However, so far I couldn't figure out how to do this in R. If anyone 
as a suggestion, please let me know

Many thanks

Frank
-- 
Frank Mattes, MD			e-mail:	f.mattes at ucl.ac.uk
Department of Virology			fax	0044(0)207 8302854
Royal Free Hospital and 			tel	0044(0)207 8302997
University College Medical School
London



From adi at roda.ro  Wed May 28 19:20:43 2003
From: adi at roda.ro (Adrian Dusa)
Date: Wed, 28 May 2003 20:20:43 +0300
Subject: [R] thx
Message-ID: <000001c3253d$7c7c75b0$c13afea9@RODAL>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030528/39d34dd3/attachment.pl

From MSchwartz at medanalytics.com  Wed May 28 20:29:42 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 28 May 2003 18:29:42 -0000
Subject: [R] how to get a line plot before/after treatment
In-Reply-To: <p05200f01bafa974cd5c7@[128.40.218.142]>
References: <p05200f01bafa974cd5c7@[128.40.218.142]>
Message-ID: <1054146532.5141.128.camel@localhost>

On Wed, 2003-05-28 at 11:48, Frank Mattes wrote:
> Dear R help-list reader,
> 
> I would like to generate a plot which compares to states in a patient 
> treatment, before and after. for this reason I have generated a vector
> before<-c(1,30,23,40)
> and
> after<-c(20,10,20,60)
> the first element in "before" corresponds to the first element in "after".
> I would like and generate a dotplot with
> before and after as x-scale, the elements of "before" and "after" on 
> the y-scale and the corresponding elements connected with a line.
> 
> However, so far I couldn't figure out how to do this in R. If anyone 
> as a suggestion, please let me know
> 
> Many thanks
> 
> Frank


Dr. Mattes,

How about this, using interaction.plot() in package nlme (I am presuming
that each pair of measures is an independent pairing). It takes a bit to
get the data in the proper structure, but the plotting is then easy:


before <- c(1,30,23,40)
after <- c(20,10,20,60)

# Create a new dataframe with columns:
# 'score', 'when' and 'unit'
# 'when' and 'unit' are set to factors

before.new <- data.frame(score = before, when = "Before", 
                         unit = factor(1:4))

after.new <- data.frame(score = after, when = "After", 
                        unit = factor(1:4))

df.new <- rbind(before.new, after.new)

#display df.new to see the structure
df.new

# load nlme
library(nlme)

#attach the dataframe to call variables directly
attach(df.new)

#create plot
interaction.plot(when, unit, score, ylab = "Score", xlab = "When", 
                 col = rainbow(4))

# detach df.new to clean up
detach(df.new)



See ?interaction.plot for more information. This is a simple example of
the function which can handle repeated measures (the default y axis is
the means of scores) and multiple x-axis factors (for example if you had
before, 1 wk after and 2 wks after).

HTH,

Marc Schwartz



From tblackw at umich.edu  Wed May 28 20:47:04 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Wed, 28 May 2003 14:47:04 -0400 (EDT)
Subject: [R] how to get a line plot before/after treatment
In-Reply-To: <p05200f01bafa974cd5c7@[128.40.218.142]>
Message-ID: <Pine.SOL.4.44.0305281440420.17509-100000@zektor.gpcc.itd.umich.edu>

Frank  -

Roughly speaking:

matplot(c(0,10), rbind(before, after), type="l", axes=F, xlab="time",
         ylab="measurement")
axis(2)
axis(1, c(0,10), c("before","after"))

Should do the job, if I interpret correctly the plot you have in mind.
See help("matplot") : Details, and many pages of help("par") for ways
to modify and decorate the basic plot.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Wed, 28 May 2003, Frank Mattes wrote:

> Dear R help-list reader,
>
> I would like to generate a plot which compares to states in a patient
> treatment, before and after. for this reason I have generated a vector
> before<-c(1,30,23,40)
> and
> after<-c(20,10,20,60)
> the first element in "before" corresponds to the first element in "after".
> I would like and generate a dotplot with
> before and after as x-scale, the elements of "before" and "after" on
> the y-scale and the corresponding elements connected with a line.
>
> However, so far I couldn't figure out how to do this in R. If anyone
> as a suggestion, please let me know
>
> Many thanks
>
> Frank
> --
> Frank Mattes, MD			e-mail:	f.mattes at ucl.ac.uk
> Department of Virology			fax	0044(0)207 8302854
> Royal Free Hospital and 			tel	0044(0)207 8302997
> University College Medical School
> London
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From dmurdoch at pair.com  Wed May 28 20:58:35 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed, 28 May 2003 14:58:35 -0400
Subject: [R] Numbers that look equal, should be equal,
	but if() doesn't see as equal (repost with code included)
In-Reply-To: <Pine.LNX.4.44.0305281549550.10329-100000@gannet.stats>
References: <30034125.1054139759@lemmens.socsci.kun.nl>
	<Pine.LNX.4.44.0305281549550.10329-100000@gannet.stats>
Message-ID: <e91advkijbo0590ea7ldl2fh72l0igmi4v@4ax.com>

On Wed, 28 May 2003 15:59:45 +0100 (BST), Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:


>> print(c(0.1 + 0.2, 0.3), digits=20)
>[1] 0.30000000000000004 0.29999999999999999
>
>yet
>
>> print(c(0.1, 0.2, 0.3), digits=20)
>[1] 0.1 0.2 0.3

Is this the way things should work?  Why isn't 0.3 printed as
0.30000000000000000 the first time, or as 0.29999999999999999 the
second time?  Surely its value is the same in both print statements,
and the requested format is the same in both.  

Duncan Murdoch



From dmurdoch at pair.com  Wed May 28 21:02:25 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed, 28 May 2003 15:02:25 -0400
Subject: [R] Zero is not zero
In-Reply-To: <1054133288.3ed4cc287af66@webmail.uoguelph.ca>
References: <1054133288.3ed4cc287af66@webmail.uoguelph.ca>
Message-ID: <rn1adv016pvvvnavbpg583f1ku3dg8hten@4ax.com>

On Wed, 28 May 2003 10:48:08 -0400, you wrote:

>Hello, There:
>I read data from tab-delimted text file(1888.txt) in C:/temp, which has 
>thousands rows and 80 colulms, using read.delim("C:/temp/1888.txt"). when I 
>retrieved the numeric coulum which has real zero values and applies R buid-in 
>function such as mean( ), sum() and got a result of NA. It seems that R (R 
>1.6.2 in windows) considers zero as missing value (NA). Thus my question is 
>how to read the real zero as zero.

No, read.delim doesn't treat "0" as missing.  What is likely happening
is that some line of your file has a typo or other error in it, so it
doesn't look like a number, and the whole column is converted to
character mode.

To find where the error is, try as.numeric(x), where x is the column
containing your data, and it'll convert all the strings that don't
look like numbers to NA. 

Duncan Murdoch



From f.mattes at rfc.ucl.ac.uk  Wed May 28 21:09:09 2003
From: f.mattes at rfc.ucl.ac.uk (Frank Mattes)
Date: Wed, 28 May 2003 20:09:09 +0100
Subject: [R] ? building a database with a the great examples
Message-ID: <p05200f03bafab75c5986@[128.40.218.142]>

Dear R help reader,

I'm not an expert in R and are lerning a lot by reading the help 
digest, which is sometimes difficult because the huge amount of data 
posted. I have posted some questions before, and  are impressed how 
quick I got a solution for my problem. Sometimes with quite different 
suggestions. I was always wondering if my questions didn't come up 
before. On the other site, it wasn't easy to search the help archive, 
purely I didn't know how to formulate my problem.
I'm wondering if we could not collect all the answers / examples in a 
database -
sorted in topics, like the help document "Rtips".
I have no clue if this is possible to do nor how time consuming the 
maintaining would be.

This is just my view how the help list could be improved

Yours
Frank
-- 
Frank Mattes, MD			e-mail:	f.mattes at ucl.ac.uk
Department of Virology			fax	0044(0)207 8302854
Royal Free Hospital and 			tel	0044(0)207 8302997
University College Medical School
London



From baron at psych.upenn.edu  Wed May 28 21:29:29 2003
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Wed, 28 May 2003 15:29:29 -0400
Subject: [R] ? building a database with a the great examples
In-Reply-To: <p05200f03bafab75c5986@[128.40.218.142]>
References: <p05200f03bafab75c5986@[128.40.218.142]>
Message-ID: <20030528192929.GA14274@mail2.sas.upenn.edu>

On 05/28/03 20:09, Frank Mattes wrote:
On the other site, it wasn't easy to search the help archive, 
>purely I didn't know how to formulate my problem.
>I'm wondering if we could not collect all the answers / examples in a 
>database -
>sorted in topics, like the help document "Rtips".
>I have no clue if this is possible to do nor how time consuming the 
>maintaining would be.

As the maintainer of one of the sites you might search, I do
think that this would be time consuming and also somewhat
redundant with the many textbooks and introductory documents that
are available.  Also, it isn't clear to me how you would search
the "tips" except by using the same sort of search terms that you
can use now.  (But if someone can think of a way to solve these
problems, I don't want to stop him or her from implementing this
idea!)

I find the htdig interface that I use fairly powerful.  You can
use phrases and logic (AND, OR, etc.).  Often a fairly general
search turns up something that gives me a hint about what search
terms I should have used.

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R page:               http://finzi.psych.upenn.edu/



From andy_liaw at merck.com  Wed May 28 14:08:06 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 28 May 2003 08:08:06 -0400
Subject: [R] Slow computation in for loop
Message-ID: <3A822319EB35174CA3714066D590DCD5C4FB56@usrymx25.merck.com>

I don't know if this will help you or not, but might worth a try.  You can
replace the two inner for loops with nested calls to sapply().  For example:

> sapply(1:5, function(x) sapply(6:10, function(y) x+y))
     [,1] [,2] [,3] [,4] [,5]
[1,]    7    8    9   10   11
[2,]    8    9   10   11   12
[3,]    9   10   11   12   13
[4,]   10   11   12   13   14
[5,]   11   12   13   14   15

Using sapply() this way is a sneaky way of avoiding explicit for loops, but
whether it actually saves resources, you have to try and see.

HTH,
Andy


> -----Original Message-----
> From: Yves Brostaux [mailto:brostaux.y at fsagx.ac.be]
> Sent: Wednesday, May 28, 2003 4:30 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Slow computation in for loop
> 
> 
> Dear members,
> 
> I'm using R to do some test computation on a set of parameters of a 
> function. This function is included in three for() loops, 
> first one for 
> replications, and the remaining two cycling through possible 
> parameters 
> values, like this :
> 
> for (k in replicates) {
>    data <- sampling from a population
>    for (i in param1) {
>      for (j in param2) {
>         result <- function(i, j, data)
>      }
>    }
> }
> 
> With the 'hardest' set of parameters, a single computation of 
> the function 
> take about 16s on an old Sun Sparc workstation with 64 Mb RAM 
> and don't 
> access a single time to disk.
> 
> But when I launch the for() loops (which generate 220 
> function calls), disk 
> gets very sollicitated and the whole process takes as much as 8 to 10 
> hours, instead of the expected 1 hour.
> 
> What's wrong here ? Is there a thing I don't know about for() 
> loops, and a 
> way to correct it ?
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------
Notice: This e-mail message, together with any attachments, cont... {{dropped}}



From ihaka at stat.auckland.ac.nz  Wed May 28 22:57:05 2003
From: ihaka at stat.auckland.ac.nz (Ross Ihaka)
Date: Thu, 29 May 2003 08:57:05 +1200
Subject: [R] Slow computation in for loop
In-Reply-To: <MABBLJDICACNFOLGIHJOCEMMDHAA.phgrosjean@sciviews.org>
References: <MABBLJDICACNFOLGIHJOCEMMDHAA.phgrosjean@sciviews.org>
Message-ID: <3ED522A1.8090301@stat.auckland.ac.nz>

Philippe Grosjean wrote:
> I suspect that your problem comes from the rbind(). I have also noticed an
> exponentially slower execution with the increase of the size of the data
> frame that you rbind()s. It is much faster to rbind() several separated
> temporary data frames (let's say, ten by ten loops), and then to rbind()
> them all together.

Got it in one.  This is one place where Splus performance is much better 
than R.  Some simulations I did makes it look like Splus does not just 
enlarge objects one element at a time. Instead, the underlying memory is 
enlarged in larger increments and additions to the array use this hidden 
space.

I thought about adding this feature, but in the end decided that 
pre-allocating the result is a better solution (the Splus enlargement 
strategy doesn't work when elements are prepended).  At one one point 
there was a slot in the object header which could have served to hold 
the "true length" of objects, but I think that Luke Tierney has used it 
for other puposes.

-- 
Ross Ihaka                         Email:  ihaka at stat.auckland.ac.nz
Department of Statistics           Phone:  (64-9) 373-7599 x 85054
University of Auckland             Fax:    (64-9) 373-7018
Private Bag 92019, Auckland
New Zealand



From John.Fieberg at dnr.state.mn.us  Wed May 28 23:26:03 2003
From: John.Fieberg at dnr.state.mn.us (John Fieberg)
Date: Wed, 28 May 2003 16:26:03 -0500
Subject: [R] Ordinal data - Regression Trees  & Proportional Odds
Message-ID: <sed4e349.095@co5.dnr.state.mn.us>

I have a data set w/ an ordinal response taking on one of 10 categories.
 I am considering using polr to fit a cumulative logits model.  I
previously fit the model in SAS (using proc logistic) which provides a
test for the proportional odds assumption (p < 0.001 for the test).  Are
there simple diagnostic plots that can be used to look at the validity
of this assumption and possibly help w/ modifying the model as
appropriate?  Any references or examples of useful R code for addressing
the proportional odds assumption would be much appreciated!

I also used a regression tree approach to explore this data set.  In
doing so, I treated the response as numeric, using the rpart library.  I
am rather new to regression trees - and wondered about the validity of
this approach.  I used cross-validation to prune the tree - but plots of
the response clearly indicate that the data are non-normal and don't
have equal variance (the data are highly skewed towards larger response
categories - values of 8-10).  I have seen some people suggest that the
tree approach is essentially non-parametric - but then I have seen other
references suggesting examination of residual plots and potential
transformations of the response to ensure homogeneity of variance.  For
this data set, it will be difficult to find an appropriate
transformation, given the large number of responses near 10 (i.e., the
fact that the data are constrained to be less than or equal to 10
results in strange residual plots).

Any help is much appreciated!

John Fieberg, Ph.D.
Wildlife Biometrician, Minnesota DNR
5463-C W. Broadway
Forest Lake, MN 55434



From rwatkins at cornerstonelp.com  Wed May 28 23:45:27 2003
From: rwatkins at cornerstonelp.com (rwatkins@cornerstonelp.com)
Date: Wed, 28 May 2003 16:45:27 -0500
Subject: [R] Durbin-Watson Test
Message-ID: <NDEKIJPPGJCIKBNEDOKOMEDICCAA.rwatkins@cornerstonelp.com>

Is there a command to perform Durbin-Watson in R?  If not, what seems to be
the most efficient way to perform such tests?

Thanks in advance to all.



From jfox at mcmaster.ca  Thu May 29 00:53:17 2003
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 28 May 2003 18:53:17 -0400
Subject: [R] Durbin-Watson Test
In-Reply-To: <NDEKIJPPGJCIKBNEDOKOMEDICCAA.rwatkins@cornerstonelp.com>
Message-ID: <5.1.0.14.2.20030528185025.01f87df0@mcmail.cis.mcmaster.ca>

Dear rwatkins,

The car and lmtest packages both have functions for Durbin-Watson tests. 
More generally, doing a search at http://www.r-project.org/ will get you 
this kind of information.

I hope that this helps,
  John

At 04:45 PM 5/28/2003 -0500, rwatkins at cornerstonelp.com wrote:
>Is there a command to perform Durbin-Watson in R?  If not, what seems to be
>the most efficient way to perform such tests?

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From edd at debian.org  Thu May 29 01:43:31 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 28 May 2003 18:43:31 -0500
Subject: [R] (no subject)
Message-ID: <16085.18851.153307.525146@edd.debian.net>

Subject: [ANN] Quantian: A Knoppix remastering for Scientific Computing 
X-Mailer: VM 7.03 under 21.4 (patch 6) "Common Lisp" XEmacs Lucid
FCC: /home/edd/mail/out/mail
From: Dirk Eddelbuettel <edd at debian.org>
--text follows this line--

[ Apologies for cross-postings; however, this message is being sent only to 
  lists to which I am personally subscribed and overlap should be small. 
  Should your sense of netiquette be offended, please accept my apologies.
  That said, I would welcome pointers to other lists of interest for this
  posting and would encourage careful forwarding to related mailing lists. ]


	 Announcing the "Quantian Scientific Computing Environment"

		   A Knoppix / Debian variant tailored to
		     numerical and quantitative analysis

Quantian is a remastering of Knoppix, the self-configuring bootable cdrom
that turns any pc or laptop into a full-featured Linux workstation.  This
version is based on Knoppix 3.2 (2003-05-20), an earlier release based on
Knoppix 3.1 (2003-01-20) is still available; see below for URLs.

Quantian differs from Knoppix by adding a set of programs of interest to
applied or theoretical workers in quantitative or data-driven fields. The
added programs include

 o R, including several add-on packages (such as tseries, RODBC, coda,
   mcmcpack, gtkdevice, rgtk, rquantlib), out-of-the box support for the
   powerful ESS modes for Emacs as well as the Ggobi visualisation program
 o Octave with add-on packages octave-forge, octave-sp, octave-epstk,
   matwrap and Inline::Octave 
 o Maxima, including the x11 front-end and emacs support
 o the Gnu Scientific Library (GSL) incl example binaries
 o the Pari/GP, Gap, Ginac and Yacas computer algebra systems
 o the Quantlib quantitative finance library incl. the Python interface
 o the OpenDX and Mayavi data visualization systems
 o TeXmacs for wysiwyg (La)TeX editing
 o and various other programs such apcalc, aribas, autoclass, euler, evolver,
   freefem, gambit, geg, geomview, glpk, gnuplot, gperiodic, gmt, gretl, 
   lp-solve, mcl, multimix, rasmol, plotutils, pgapack, pspp, pdl, rcalc,
   yorick and xlispstat

while at the same time retaining programs and features already in Knoppix:

 o Auto-configuration of graphics, sound, disks, networking, auxiliary 
   devices which is second to none among computer installations
 o The current version 3.1 of the KDE desktop environment
 o The GNU compiler suite comprising gcc, g77, g++ compilers 
   in releases 2.95, 3.2 and 3.3 as well as gcj in version 3.2
 o Perl and Python with loads of add-ons, plus ruby, tcl, ...
 o The Emacs and Vim editors, as well as kate, joe, kate, nedit and zile
 o A complete teTeX TeX and LaTeX setup for scientific publishing
 o Gnumeric, Abiword, Koffice, ... office tools
 o a Swiss-army knife collection of networking tools allowing access
   to wired and wireless lans, covering ethernet, isdn or dial-up modems

In total, over 1200 Debian packages are included.

Quantian iso images are available at 

	http://software.biostat.washington.edu/edd/quantian/
	http://franz.stat.wisc.edu/~edd/quantian/

and a Quantian overview page, including a recent paper, is at

	http://dirk.eddelbuettel.com/quantian.html

Plans for future versions are not set in stone but may entail support for
OpenMosix clustering.  Comments, questions, feedback are more than welcome! 

 -- Dirk Eddelbuettel <edd at debian.org>  Wed, 28 May 2003 18:42:40 -0500

-- 
Don't drink and derive. Alcohol and analysis don't mix.



From Ted.Harding at nessie.mcc.ac.uk  Thu May 29 01:03:19 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Thu, 29 May 2003 00:03:19 +0100 (BST)
Subject: [R] Numbers that look equal, should be equal, but if() doesn
In-Reply-To: <3ED4DDB7.7020308@lancaster.ac.uk>
Message-ID: <XFMail.030529000319.Ted.Harding@nessie.mcc.ac.uk>

On 28-May-03 Barry Rowlingson wrote:
>   Oh, why not just go one step further, and redefine the == operator!
> 
>   "==" <- function(x,y){equal.enough(x,y)}
> 
> before:
>  > (.1+.2)==.3
> [1] FALSE
> 
> after:
>  > (.1+.2)==.3
> [1] TRUE
> 
>   This requires a slight modification to equal.enough, which I will not
> list here, so that people dont _actually_ do this. It just ensures that
> equal.enough doesn't go all infinitely recursive on us.
> 
>   Next time on useless R tips: 1 + 1 = 3

At which point I am unable to resist quoting:

  "2 plus 2 is never equal to 5 -- even for large values of 2".

Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 29-May-03                                       Time: 00:03:19
------------------------------ XFMail ------------------------------



From andy_liaw at merck.com  Thu May 29 14:07:16 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 29 May 2003 08:07:16 -0400
Subject: [R] Ordinal data - Regression Trees  & Proportional Odds
Message-ID: <3A822319EB35174CA3714066D590DCD5C4FB67@usrymx25.merck.com>

> From: John Fieberg [mailto:John.Fieberg at dnr.state.mn.us]
> 
> I have a data set w/ an ordinal response taking on one of 10 
> categories.
>  I am considering using polr to fit a cumulative logits model.  I
> previously fit the model in SAS (using proc logistic) which provides a
> test for the proportional odds assumption (p < 0.001 for the 
> test).  Are
> there simple diagnostic plots that can be used to look at the validity
> of this assumption and possibly help w/ modifying the model as
> appropriate?  Any references or examples of useful R code for 
> addressing
> the proportional odds assumption would be much appreciated!
> 
> I also used a regression tree approach to explore this data set.  In
> doing so, I treated the response as numeric, using the rpart 
> library.  I
> am rather new to regression trees - and wondered about the validity of
> this approach.  I used cross-validation to prune the tree - 
> but plots of
> the response clearly indicate that the data are non-normal and don't
> have equal variance (the data are highly skewed towards 
> larger response
> categories - values of 8-10).  I have seen some people 
> suggest that the
> tree approach is essentially non-parametric - but then I have 
> seen other
> references suggesting examination of residual plots and potential
> transformations of the response to ensure homogeneity of 
> variance.  For
> this data set, it will be difficult to find an appropriate
> transformation, given the large number of responses near 10 (i.e., the
> fact that the data are constrained to be less than or equal to 10
> results in strange residual plots).

I can't say anything about logistic models, but would like to say a few
things about trees.

AFAIK there's no implementation (or description) of tree algorithm that
handles ordinal response.  We have discussed this with Prof. Breiman some
time last year, and it is not straight forward at all (to us, at least).  

Regression trees are non-parametric models in the sense that the regression
functions they estimate can have arbitrary form.  However, the least squares
(or even least absolute value) splitting criterion implicitly assume
homoscedasticity.  As a matter of fact, the CART book (Breiman, Friedman,
Olshen & Stone, 1984) has discussion on the effect of heteroscedasticity on
regression trees.

HTH,
Andy
 
> Any help is much appreciated!
> 
> John Fieberg, Ph.D.
> Wildlife Biometrician, Minnesota DNR
> 5463-C W. Broadway
> Forest Lake, MN 55434
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From mitsu5 at ruby.famille.ne.jp  Thu May 29 14:07:40 2003
From: mitsu5 at ruby.famille.ne.jp (Mitsuo Igarashi)
Date: Thu, 29 May 2003 21:07:40 +0900
Subject: [R] Can Package SEM do mean structural analysis?
In-Reply-To: <5.1.0.14.2.20030524103328.01e9e310@mcmail.cis.mcmaster.ca>
References: <5.1.0.14.2.20030524103328.01e9e310@mcmail.cis.mcmaster.ca>
Message-ID: <200305291207.h4TC7kk2018832@mp2.vectant.ne.jp>

Dear John:

I can make it on your suggestion in mean structural analysis.

I appreciate so much and love your package sem.
I hope your package sem will be extended in near future.

John Fox <jfox at mcmaster.ca> wrote:

> Dear Mitsuo,
> 
> My intention in writing the sem package was to provide a basic 
> structural-equation facility for R. I haven't made explicit provision for 
> models with means, but it might be possible to fit such models by using the 
> raw sums-of-squares-and-products matrix among the observed variables 
> (perhaps divided by n) as input.  It might be necessary to make small 
> modifications to degrees of freedom, etc.
--------========----------
Mitsuo Igarashi
mitsu5 at ruby.famille.ne.jp



From gb at stat.umu.se  Thu May 29 16:01:24 2003
From: gb at stat.umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Thu, 29 May 2003 16:01:24 +0200 (CEST)
Subject: [R] install-packages
Message-ID: <Pine.LNX.4.44.0305291545380.5872-100000@tal.stat.umu.se>

When I try 'install-packages' (from menu) in R-1.7.0 (Windows), I get 

> install.packages(choose.files('',filters=Filters[c('zip','All'),]), 
.libPaths()[1], CRAN = NULL)
Error in file(file, "r") : unable to open connection
In addition: Warning message: 
cannot open file `eha060/DESCRIPTION' 
>
 but it works with R-1.6.2. It also works if I manually unzip 
'eha060.zip' in the right place.

'eha' is an R package written by myself, and since I intend to send it to 
CRAN soon, I'm worried that I have built it incorrectly. I usually work on 
Linux, and I built eha there. Then I copied the resulting .tar.gz file to
a Windows 2000 machine with Ripley's tools installed and installed it by
'Rcmd INSTALL ...'. So far, so good, everything works. Then I zipped the 
catalogue 'eha' to get 'eha060.zip', and this file doesn't work with
'install.packages', however with 'unzip'.

Is the error with me or with 1.7.0? I have seen the reports on failures 
with bundles, but 'eha' is not a bundle.

Thanks,

G?ran
---
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se



From Setzer.Woodrow at epamail.epa.gov  Thu May 29 15:58:30 2003
From: Setzer.Woodrow at epamail.epa.gov (Setzer.Woodrow@epamail.epa.gov)
Date: Thu, 29 May 2003 09:58:30 -0400
Subject: [R] ODE solvers in R (was:The Wrong Choice: Locked in by license
	restrictions)
Message-ID: <OFBF5CAF34.5AFB47A8-ON85256D35.004C632B@rtp.epa.gov>


I have plans to add dassl to odesolve.  However, I won't have time in
the immediate future.  If someone wanted to take this on, I'd be happy
to give advice and continue to manage the package ... .

R. Woodrow Setzer, Jr.                        Phone: (919) 541-0128
Experimental Toxicology Division             Fax:  (919) 541-4284
Pharmacokinetics Branch
NHEERL B143-05; US EPA; RTP, NC 27711



From DivineSAAM at aol.com  Thu May 29 16:39:16 2003
From: DivineSAAM at aol.com (DivineSAAM@aol.com)
Date: Thu, 29 May 2003 10:39:16 EDT
Subject: [R] ODE solvers in R (was:The Wrong Choice: Locked in by license
	restrict...
Message-ID: <1a4.151e6ecb.2c077594@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030529/1bf58a7d/attachment.pl

From jgentry at jimmy.harvard.edu  Thu May 29 16:58:28 2003
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Thu, 29 May 2003 10:58:28 -0400 (EDT)
Subject: [R] Bioconductor 1.2 Released
Message-ID: <Pine.SOL.4.20.0305291056410.27125-100000@santiam.dfci.harvard.edu>


The Bioconductor development team announces release 1.2 of the
Bioconductor packages for the analysis of genomic data. Bioconductor
is an open source bioinformatics software project based on the R language.

Version 1.2 features:
=====================

    * All packages from the 1.1 release are included.  All current bug
	fixes have been applied, and most have been upgraded and
	provide enhanced functionality.

    * affy: The affy package now provides for the automatic downloads 
	of necessary CDF packages. There is also a new function, 
	justRMA() which will use less system resources if one just
	wants RMA vs. using ReadAffy() and then rma/expresso - this 
	will solve some users' problem when they do not have enough 
	memory for working with the full method. The package's 
	implementation of MAS 5.0 now agrees better with Affymetrix's 
	then in previous releases, and now includes a function mas5() 
	to make it easier for a user to obtain these results.

    * affycomp: A new package that serves as a graphics toolbox for 
	the assessment of Affymetrix expression measures.

    * AnnBuilder: DB support is no longer required. ABPkgBuilder now 
	provides a signle API for building of data packages. Also, 
	data packages built with AnnBuilder will include an evidence 
	code and association information for GO ids.

    * Biobase: The exprs2excel method for the exprSet class has been 
	added, which will create an excel friendly file from the 
	expression component of an exprSet.

    * DynDoc: A new package that provides a set of functions to create 
	and interact with dynamic documents and vignettes

    * limma: A new package that provides functionality to handle
	linear models for microarray data.

    * makecdfenv: A package to create hash table environments from CDF 
	files, as well as functionality to create data packages out 
	of these environments.

    * RBGL: A new package that provides an interface to the Boost 
	libraries for graph manipulation.

    * Rgraphviz: A new package that provides an interface with
	Graphviz to plot graph objects in R.

    * Ruuid: A new package that provides Universally Unique ID values
	(UUIDs).

    * SAGElyzer: A new package that will store SAGE data in a database 
	and then provide functionality to locate genes that are
	similar to a given SAGE tag.

    * tkWidgets: The importWizard functionality was added, which 
	provides an Excel style interface for importing data into R. 
	Also the DPExplorer is new in 1.2 - allowing users to explore 
	a BioC data package. The argsWidget widget set will create a 
	GUI for accepting input dynamically.

    * vsn: vsn can now be used as a normalization method with the affy 
	package. The likelihood function optimization has been 
	streamlined and is faster. There is a new function to produce 
	a diagnostic plot for the variance-mean relationship of 
	microarray data, meanSdPlot. The data returned by vsn is now 
	an object of class "exprSet".

    * widgetTools: A new package that provides user friendly tools to 
	create Tcl/Tk widgets in R.

Software, documentation, and further details are available on the
Bioconductor WWW site:

      http://www.bioconductor.org/

HELP AND RESOURCES:
===================

Information on subscribing to the mailing list and viewing its archives
can be found at:

      http://www.stat.math.ethz.ch/mailman/listinfo/bioconductor

Please use that list to discuss Bioconductor specific issues, bugs,
and problems.  Note that every package has a vignette (a literate
program which provides an annotated example of the package's use) as
well as possibly some "HOWTO"s.  These document the tool's usage, and
are provided in the "doc" subdirectory of each package library.

WHO:
====

For the Bioconductor development team:

  Douglas Bates, University of Wisconsin, USA.
  Vince Carey, Harvard Medical School, USA.
  Marcel Dettling, Federal Inst. Technology, Switzerland.
  Sandrine Dudoit, Division of Biostatistics, University of
      California, Berkeley, USA.
  Byron Ellis, Harvard Department of Statistics, USA.
  Laurent Gautier, Technial University of Denmark, Denmark.
  Robert Gentleman, Harvard Medical School, USA.
  Jeff Gentry, Dana-Farber Cancer Institute, USA.
  Kurt Hornik, Technische Universitat Wien, Austria.
  Torsten Hothorn, Institut fuer Medizininformatik, Biometrie und
      Epidemiologie, Germany. 
  Wolfgang Huber, DKFZ Heidelberg, Molecular Genome Analysis,
      Germany. 
  Stefano Iacus, Italy
  Rafael Irizarry, Department of Biostatistics (JHU), USA.
  Friedrich Leisch, Technische Universitat Wien, Austria.
  Martin Maechler, Federal Inst. Technology, Switzerland.
  Anthony Rossini, University of Washington and the Fred Hutchinson
      Cancer Research Center, USA. 
  Gunther Sawitzki, Institute fur Angewandte Mathematik, Germany.
  Gordon Smythe, WEHI Bioinformatics Group, Australia
  Luke Tierney, University of Iowa, USA.
  Jean Yee Hwa Yang, University of California, San Francisco, USA. 
  Jianhua (John) Zhang, Dana-Farber Cancer Institute, USA



From partha_bagchi at hgsi.com  Thu May 29 17:05:06 2003
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Thu, 29 May 2003 11:05:06 -0400
Subject: [R] Odd behavior of strptime
Message-ID: <OF874A1816.8198BEE0-ON85256D35.00525004-85256D35.0052DD20@hgsi.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030529/fec9db93/attachment.pl

From dave at evocapital.com  Thu May 29 17:26:38 2003
From: dave at evocapital.com (David Khabie-Zeitoune)
Date: Thu, 29 May 2003 16:26:38 +0100
Subject: [R] Odd behavior of strptime
In-Reply-To: <OF874A1816.8198BEE0-ON85256D35.00525004-85256D35.0052DD20@hgsi.com>
Message-ID: <8D0F30FE2EB3314182D4A33F738BB19D012447@mail.internal.net>

The strptime object is a structured list object with 9 components. (Type
"names(z)" to see the names of the individual components). You may want
to convert the strptime object to a POSIXct object using

Z = as.POSIXct(z)

This is just a vector (of the expected length).

Cheers,
Dave




-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of
partha_bagchi at hgsi.com
Sent: 29 May 2003 16:05
To: r-help at stat.math.ethz.ch
Subject: [R] Odd behavior of strptime


The example from the help page for strptime has the following oddity:

>      dates <- c("02/27/92", "02/27/92", "01/14/92",
+                 "02/28/92", "02/01/92")
>      times <- c("23:03:20", "22:29:56", "01:03:30",
+                 "18:21:03", "16:56:26")
>      x <- paste(dates, times)
>      z <- strptime(x, "%m/%d/%y %H:%M:%S")
>      z
[1] "1992-02-27 23:03:20" "1992-02-27 22:29:56" "1992-01-14 01:03:30" 
"1992-02-28 18:21:03" "1992-02-01 16:56:26"
> 
> length(z)
[1] 9
>
The length is always denoted as 9.
Of course this implies that any replacement I want to do with dates etc.

always fails with the error:

Error in "[[<-.data.frame"(*tmp*, D[I], value = 
strptime(as.character(x[[D[I]]]),  : 
        replacement has 9 rows, data has 5970
>
> version
         _ 
platform i386-pc-mingw32
arch     i386 
os       mingw32 
system   i386, mingw32 
status 
major    1 
minor    7.0 
year     2003 
month    04 
day      16 
language R 
>
(platform Win2000 professional)

Has anyone else encountered this?

Thanks,
Partha.


	[[alternate HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From dowlingr at uoguelph.ca  Thu May 29 17:28:18 2003
From: dowlingr at uoguelph.ca (dowlingr@uoguelph.ca)
Date: Thu, 29 May 2003 11:28:18 -0400
Subject: [R] One question
Message-ID: <1054222098.3ed62712426b0@webmail.uoguelph.ca>

Hello everyone,
I am a new R software user.  I have been using the R package "com.braju.sma" in 
order to analyze microarray data.  I have one question regarding analysis using 
this package.  This type of analysis uses the expression ratio of red 
color/green color (R/G) and I was wondering if it was possible to switch this 
around so that the expression ratio was green color/red color (G/R).
Any help that you could give me would be greatly appreciated,
Thanks

Jimmy



From ligges at statistik.uni-dortmund.de  Thu May 29 17:34:17 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 29 May 2003 17:34:17 +0200
Subject: [R] Odd behavior of strptime
In-Reply-To: <OF874A1816.8198BEE0-ON85256D35.00525004-85256D35.0052DD20@hgsi.com>
References: <OF874A1816.8198BEE0-ON85256D35.00525004-85256D35.0052DD20@hgsi.com>
Message-ID: <3ED62879.7050804@statistik.uni-dortmund.de>

partha_bagchi at hgsi.com wrote:
> The example from the help page for strptime has the following oddity:
> 
> 
>>     dates <- c("02/27/92", "02/27/92", "01/14/92",
> 
> +                 "02/28/92", "02/01/92")
> 
>>     times <- c("23:03:20", "22:29:56", "01:03:30",
> 
> +                 "18:21:03", "16:56:26")
> 
>>     x <- paste(dates, times)
>>     z <- strptime(x, "%m/%d/%y %H:%M:%S")
>>     z
> 
> [1] "1992-02-27 23:03:20" "1992-02-27 22:29:56" "1992-01-14 01:03:30" 
> "1992-02-28 18:21:03" "1992-02-01 16:56:26"
> 
>>length(z)
> 
> [1] 9
> 
> The length is always denoted as 9.
> Of course this implies that any replacement I want to do with dates etc. 
> always fails with the error:
> 
> Error in "[[<-.data.frame"(*tmp*, D[I], value = 
> strptime(as.character(x[[D[I]]]),  : 
>         replacement has 9 rows, data has 5970
> 
>>version
> 
>          _ 
> platform i386-pc-mingw32
> arch     i386 
> os       mingw32 
> system   i386, mingw32 
> status 
> major    1 
> minor    7.0 
> year     2003 
> month    04 
> day      16 
> language R 
> 
> (platform Win2000 professional)
> 
> Has anyone else encountered this?
> 
> Thanks,
> Partha.


Hint, from ?POSIXlt:
"Class "POSIXlt" is a named list of [9] vectors representing ..."

Uwe Ligges



From ligges at statistik.uni-dortmund.de  Thu May 29 17:42:23 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 29 May 2003 17:42:23 +0200
Subject: [R] install-packages
In-Reply-To: <Pine.LNX.4.44.0305291545380.5872-100000@tal.stat.umu.se>
References: <Pine.LNX.4.44.0305291545380.5872-100000@tal.stat.umu.se>
Message-ID: <3ED62A5F.7060104@statistik.uni-dortmund.de>

G?ran Brostr?m wrote:
> When I try 'install-packages' (from menu) in R-1.7.0 (Windows), I get 
> 
> 
>>install.packages(choose.files('',filters=Filters[c('zip','All'),]), 
> 
> .libPaths()[1], CRAN = NULL)
> Error in file(file, "r") : unable to open connection
> In addition: Warning message: 
> cannot open file `eha060/DESCRIPTION' 


>  but it works with R-1.6.2. It also works if I manually unzip 
> 'eha060.zip' in the right place.
> 
> 'eha' is an R package written by myself, and since I intend to send it to 
> CRAN soon, I'm worried that I have built it incorrectly. I usually work on 
> Linux, and I built eha there. Then I copied the resulting .tar.gz file to
> a Windows 2000 machine with Ripley's tools installed and installed it by
> 'Rcmd INSTALL ...'. So far, so good, everything works. Then I zipped the 
> catalogue 'eha' to get 'eha060.zip',

That might be the problem: Zip it with the tools collection, most easily 
  using the (recommended) way described below.


 >  and this file doesn't work with
> 'install.packages', however with 'unzip'.
> 
> Is the error with me or with 1.7.0? I have seen the reports on failures 
> with bundles, but 'eha' is not a bundle.
> 
> Thanks,
> 
> G?ran


- Use  Rcmd INSTALL --build  ....  to create the Windows binary version 
of the package.

- Does the package pass R CMD check under Linux / Rcmd check under Windows?

- Be sure not to have loaded (an old version of) the package before 
trying install.packages(), because files may be locked.

- Follow readme.packages in .../src/gnuwin32 *exactly*.

Uwe



From partha_bagchi at hgsi.com  Thu May 29 17:47:16 2003
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Thu, 29 May 2003 11:47:16 -0400
Subject: [R] Odd behavior of strptime
Message-ID: <OF26193842.3F2AA734-ON85256D35.00569075-85256D35.0056B983@hgsi.com>

I guess I got confused by the fact that I didn't have to convert to 
POSIXct in 1.5.1 where I had tested the code I was using. Retesting in 
1.7.0 resulted in the error.

Thanks,
Partha.





"David Khabie-Zeitoune" <dave at evocapital.com>
Sent by: r-help-bounces at stat.math.ethz.ch
05/29/2003 11:26 AM
Please respond to dave

 
        To:     <partha_bagchi at hgsi.com>, <r-help at stat.math.ethz.ch>
        cc: 
        Subject:        RE: [R] Odd behavior of strptime


The strptime object is a structured list object with 9 components. (Type
"names(z)" to see the names of the individual components). You may want
to convert the strptime object to a POSIXct object using

Z = as.POSIXct(z)

This is just a vector (of the expected length).

Cheers,
Dave




-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of
partha_bagchi at hgsi.com
Sent: 29 May 2003 16:05
To: r-help at stat.math.ethz.ch
Subject: [R] Odd behavior of strptime


The example from the help page for strptime has the following oddity:

>      dates <- c("02/27/92", "02/27/92", "01/14/92",
+                 "02/28/92", "02/01/92")
>      times <- c("23:03:20", "22:29:56", "01:03:30",
+                 "18:21:03", "16:56:26")
>      x <- paste(dates, times)
>      z <- strptime(x, "%m/%d/%y %H:%M:%S")
>      z
[1] "1992-02-27 23:03:20" "1992-02-27 22:29:56" "1992-01-14 01:03:30"
"1992-02-28 18:21:03" "1992-02-01 16:56:26"
>
> length(z)
[1] 9
>
The length is always denoted as 9.
Of course this implies that any replacement I want to do with dates etc.

always fails with the error:

Error in "[[<-.data.frame"(*tmp*, D[I], value =
strptime(as.character(x[[D[I]]]),  :
replacement has 9 rows, data has 5970
>
> version
_
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    7.0
year     2003
month    04
day      16
language R
>
(platform Win2000 professional)

Has anyone else encountered this?

Thanks,
Partha.


[[alternate HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help

--
This message has been scanned for viruses and
dangerous content by MailScanner, and is
believed to be clean.



From jfox at mcmaster.ca  Thu May 29 18:11:04 2003
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 29 May 2003 12:11:04 -0400
Subject: [R] install-packages
In-Reply-To: <Pine.LNX.4.44.0305291545380.5872-100000@tal.stat.umu.se>
Message-ID: <5.1.0.14.2.20030529115357.01e46d18@mcmail.cis.mcmaster.ca>

Dear Goran,

I've noticed this problem with recent versions of R when I've zipped an R 
package for Windows using a zip utility different from the recommended 
Info-Zip. If you build the package under Windows with the --binary switch, 
then a usable zip file should be produced.

As an aside, I've noticed recently that packages that I build under Windows 
in this manner report wrong MD5 checksums for some files when they are 
installed, but seem to work fine.

I hope that this helps,
  John

At 04:01 PM 5/29/2003 +0200, G?ran Brostr?m wrote:
>When I try 'install-packages' (from menu) in R-1.7.0 (Windows), I get
>
> > install.packages(choose.files('',filters=Filters[c('zip','All'),]),
>.libPaths()[1], CRAN = NULL)
>Error in file(file, "r") : unable to open connection
>In addition: Warning message:
>cannot open file `eha060/DESCRIPTION'
> >
>  but it works with R-1.6.2. It also works if I manually unzip
>'eha060.zip' in the right place.
>
>'eha' is an R package written by myself, and since I intend to send it to
>CRAN soon, I'm worried that I have built it incorrectly. I usually work on
>Linux, and I built eha there. Then I copied the resulting .tar.gz file to
>a Windows 2000 machine with Ripley's tools installed and installed it by
>'Rcmd INSTALL ...'. So far, so good, everything works. Then I zipped the
>catalogue 'eha' to get 'eha060.zip', and this file doesn't work with
>'install.packages', however with 'unzip'.
>
>Is the error with me or with 1.7.0? I have seen the reports on failures
>with bundles, but 'eha' is not a bundle.

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From stephen at inf.ed.ac.uk  Thu May 29 18:59:32 2003
From: stephen at inf.ed.ac.uk (Stephen Eglen)
Date: Thu, 29 May 2003 17:59:32 +0100
Subject: [R] Postscript query: plotting long vectors
Message-ID: <16086.15476.115381.712265@bushmills.inf.ed.ac.uk>

Hi, 

I have a query about the maximum length of vector that can be plotted
in one go in a postscript driver.  Try the following code (in 1.7.0;
version details below):

t <- seq(from=0, to=4*pi, length=200000)
y <- sin(t)
postscript(file="o.ps")
plot(t, y, type="l")
dev.off()

If I view the postscript file o.ps in "gv", it takes many seconds
before eventually the axes appear, but then only one vertical line is
drawn within the plot area -- there is no sine curve.  (this is on a
fast dual processor linux machine with 2Gb RAM.)  This is clearly a
postscript problem, rather than a R problem, since reducing the length
of t down to something like 2000 solves the problem.  By looking at
the file o.ps it looks like the line is drawn by one "rlineto" call
per point, followed eventually by a "stroke" after the last point.
I'm guessing that the postscript interpreter simply cannot remember so
many points in the path before it gets to the stroke.

The example above is artificial, but this problem appeared with a real
data set this morning.  The fix was to replace the single call to
plot() with many calls to line(), breaking the t and y vectors into
more manageable chunks; in this way, each postscript path was
manageable and we got the plot.

I tried plotting the same long vectors in gnuplot by first writing
them from R:

write.table(cbind(t,y), sep="\t", file="eg.dat", row.names=F, col.names=F,
            quote=F)

and then in gnuplot:

set term postscript
set output "gnuplot.ps"
plot "eg.dat" wi lines

This came out fine; in gnuplot.ps every 400 lines during the plot it
outputs "currentpoint stroke M" (M is defined to moveto).  I had a
look at the gnuplot source (gnuplot-3.7.3/term/post.trm) and found
that it does keep count of the length of the current postscript path:
e.g. in the function PS_vector(x,y) we see (line 1122):

	if (ps_path_count >= 400) {
		fprintf(gpoutfile,"currentpoint stroke M\n");
		ps_path_count = 0;
	}

so every 400 points it draws the line so far and then continues.
(Matlab .ps files also seem to have regular "MP stroke".

I had a quick look in the corresponding R code src/main/devPS.c and
could not see any counter.  Would it be worth adding such a counter
and periodic line output to PS_Polyline?


> version
platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    7.0              
year     2003             
month    04               
day      16               
language R



From gb at stat.umu.se  Thu May 29 19:18:36 2003
From: gb at stat.umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Thu, 29 May 2003 19:18:36 +0200 (CEST)
Subject: [R] install-packages
In-Reply-To: <3ED62A5F.7060104@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.44.0305291912560.6094-100000@tal.stat.umu.se>

On Thu, 29 May 2003, Uwe Ligges wrote:

> G?ran Brostr?m wrote:
> > When I try 'install-packages' (from menu) in R-1.7.0 (Windows), I get 
> > 
> > 
> >>install.packages(choose.files('',filters=Filters[c('zip','All'),]), 
> > 
> > .libPaths()[1], CRAN = NULL)
> > Error in file(file, "r") : unable to open connection
> > In addition: Warning message: 
> > cannot open file `eha060/DESCRIPTION' 
> 
> 
> >  but it works with R-1.6.2. It also works if I manually unzip 
> > 'eha060.zip' in the right place.
> > 
> > 'eha' is an R package written by myself, and since I intend to send it to 
> > CRAN soon, I'm worried that I have built it incorrectly. I usually work on 
> > Linux, and I built eha there. Then I copied the resulting .tar.gz file to
> > a Windows 2000 machine with Ripley's tools installed and installed it by
> > 'Rcmd INSTALL ...'. So far, so good, everything works. Then I zipped the 
> > catalogue 'eha' to get 'eha060.zip',
> 
> That might be the problem: Zip it with the tools collection, most easily 
>   using the (recommended) way described below.

I used Brian's tools

> 
>  >  and this file doesn't work with
> > 'install.packages', however with 'unzip'.
> > 
> > Is the error with me or with 1.7.0? I have seen the reports on failures 
> > with bundles, but 'eha' is not a bundle.
> > 
> > Thanks,
> > 
> > G?ran
> 
> 
> - Use  Rcmd INSTALL --build  ....  to create the Windows binary version 
> of the package.

Thanks, that worked!

> - Does the package pass R CMD check under Linux / Rcmd check under Windows?

Yes / Yes
 
> - Be sure not to have loaded (an old version of) the package before 
> trying install.packages(), because files may be locked.
> 
> - Follow readme.packages in .../src/gnuwin32 *exactly*.

Actually, I couldn't find 'Rcmd INSTALL --build' there, so thank you for
enlightening me! (I usually follow instructions exactly, I learned that 
the hard way the first (and last :)) time I installed  R  from source on 
Windows!)

G?ran



From gb at stat.umu.se  Thu May 29 19:22:45 2003
From: gb at stat.umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Thu, 29 May 2003 19:22:45 +0200 (CEST)
Subject: [R] install-packages
In-Reply-To: <5.1.0.14.2.20030529115357.01e46d18@mcmail.cis.mcmaster.ca>
Message-ID: <Pine.LNX.4.44.0305291920080.6094-100000@tal.stat.umu.se>

On Thu, 29 May 2003, John Fox wrote:

> Dear Goran,
> 
> I've noticed this problem with recent versions of R when I've zipped an R 
> package for Windows using a zip utility different from the recommended 
> Info-Zip. If you build the package under Windows with the --binary switch, 
> then a usable zip file should be produced.

Thank you. As you saw from Uwe's answer, 'Rcmd INSTALL --build ...' also 
works. My excuse is that I am a novice on Windows.

G?ran



From rbonk at host.sk  Thu May 29 19:40:37 2003
From: rbonk at host.sk (Rado Bonk)
Date: Thu, 29 May 2003 17:40:37 -0000
Subject: [R] how to smooth a line in a graph
Message-ID: <1054252090.1356.10.camel@templar.fns.uniba.sk>

Hi R-users,

I have a line graph made by plot(). The line is very similar to
hyperbola, and consists of 5 points. How can I make it look smooth?

Thanks,

Rado 

-- 
Radoslav Bonk M.S.
Dept. of Physical Geography and Geoecology
Faculty of Sciences, Comenius University
Mlynska Dolina 842 15, Bratislava, SLOVAKIA
tel: +421 905 968 127 e-mail: rbonk at host.sk



From ripley at stats.ox.ac.uk  Thu May 29 19:43:14 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 29 May 2003 18:43:14 +0100 (BST)
Subject: [R] Postscript query: plotting long vectors
In-Reply-To: <16086.15476.115381.712265@bushmills.inf.ed.ac.uk>
Message-ID: <Pine.LNX.4.44.0305291822210.26237-100000@gannet.stats>

I don't think that's entirely correct: as far as I know doing that resets 
the line-type pattern (and I have just checked the PostScript Reference 
manual).

Level 1 Postscript interpreters often have a limit of about 1500 segments 
in a path, but level >=2 (all recent ones) are supposed to have no limit.

It seems that your suggested change would help a few PostScript 
interpreters but damage the output for the rest.  It is better that the 
end-user splits the polylines up.


On Thu, 29 May 2003, Stephen Eglen wrote:

> Hi, 
> 
> I have a query about the maximum length of vector that can be plotted
> in one go in a postscript driver.  Try the following code (in 1.7.0;
> version details below):
> 
> t <- seq(from=0, to=4*pi, length=200000)
> y <- sin(t)
> postscript(file="o.ps")
> plot(t, y, type="l")
> dev.off()
> 
> If I view the postscript file o.ps in "gv", it takes many seconds
> before eventually the axes appear, but then only one vertical line is
> drawn within the plot area -- there is no sine curve.  (this is on a
> fast dual processor linux machine with 2Gb RAM.)  This is clearly a
> postscript problem, rather than a R problem, since reducing the length
> of t down to something like 2000 solves the problem.  By looking at
> the file o.ps it looks like the line is drawn by one "rlineto" call
> per point, followed eventually by a "stroke" after the last point.
> I'm guessing that the postscript interpreter simply cannot remember so
> many points in the path before it gets to the stroke.
> 
> The example above is artificial, but this problem appeared with a real
> data set this morning.  The fix was to replace the single call to
> plot() with many calls to line(), breaking the t and y vectors into
> more manageable chunks; in this way, each postscript path was
> manageable and we got the plot.
> 
> I tried plotting the same long vectors in gnuplot by first writing
> them from R:
> 
> write.table(cbind(t,y), sep="\t", file="eg.dat", row.names=F, col.names=F,
>             quote=F)
> 
> and then in gnuplot:
> 
> set term postscript
> set output "gnuplot.ps"
> plot "eg.dat" wi lines
> 
> This came out fine; in gnuplot.ps every 400 lines during the plot it
> outputs "currentpoint stroke M" (M is defined to moveto).  I had a
> look at the gnuplot source (gnuplot-3.7.3/term/post.trm) and found
> that it does keep count of the length of the current postscript path:
> e.g. in the function PS_vector(x,y) we see (line 1122):
> 
> 	if (ps_path_count >= 400) {
> 		fprintf(gpoutfile,"currentpoint stroke M\n");
> 		ps_path_count = 0;
> 	}
> 
> so every 400 points it draws the line so far and then continues.
> (Matlab .ps files also seem to have regular "MP stroke".
> 
> I had a quick look in the corresponding R code src/main/devPS.c and
> could not see any counter.  Would it be worth adding such a counter
> and periodic line output to PS_Polyline?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From pavlicov at stat.ohio-state.edu  Thu May 29 19:55:48 2003
From: pavlicov at stat.ohio-state.edu (Martina Pavlicova)
Date: Thu, 29 May 2003 13:55:48 -0400 (EDT)
Subject: [R] how to smooth a line in a graph
In-Reply-To: <1054252090.1356.10.camel@templar.fns.uniba.sk>
Message-ID: <Pine.SOL.4.33.0305291353530.21902-100000@spatial.stat.ohio-state.edu>


> x <- c(1,2,3,4,5)
> y <- c(5,2,1,.5,.2)

> plot(x,y)
> lines(spline(x,y, 100))

See ?spline

Hope that helps.

Martina Pavlicova
--------------------------------------------------------------------------
Department of Statistics             Office Phone: (614) 292-1567
1958 Neil Avenue, 304E Cockins Hall  FAX: (614) 292-2096
The Ohio State University            E-mail: pavlicov at stat.ohio-state.edu
Columbus, OH 43210-1247              www.stat.ohio-state.edu/~pavlicov


On 29 May 2003, Rado Bonk wrote:

> Hi R-users,
>
> I have a line graph made by plot(). The line is very similar to
> hyperbola, and consists of 5 points. How can I make it look smooth?
>
> Thanks,
>
> Rado
>
> --
> Radoslav Bonk M.S.
> Dept. of Physical Geography and Geoecology
> Faculty of Sciences, Comenius University
> Mlynska Dolina 842 15, Bratislava, SLOVAKIA
> tel: +421 905 968 127 e-mail: rbonk at host.sk
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From Ted.Harding at nessie.mcc.ac.uk  Thu May 29 20:00:38 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Thu, 29 May 2003 19:00:38 +0100 (BST)
Subject: [R] Postscript query: plotting long vectors
In-Reply-To: <16086.15476.115381.712265@bushmills.inf.ed.ac.uk>
Message-ID: <XFMail.030529190038.Ted.Harding@nessie.mcc.ac.uk>

On 29-May-03 Stephen Eglen wrote:
> t <- seq(from=0, to=4*pi, length=200000)
> y <- sin(t)
> postscript(file="o.ps")
> plot(t, y, type="l")
> dev.off()
> 
> If I view the postscript file o.ps in "gv", it takes many seconds
> before eventually the axes appear, but then only one vertical line is
> drawn within the plot area -- there is no sine curve.  (this is on a
> fast dual processor linux machine with 2Gb RAM.)  This is clearly a
> postscript problem, rather than a R problem, since reducing the length
> of t down to something like 2000 solves the problem.  By looking at
> the file o.ps it looks like the line is drawn by one "rlineto" call
> per point, followed eventually by a "stroke" after the last point.
> I'm guessing that the postscript interpreter simply cannot remember so
> many points in the path before it gets to the stroke.

Absolutely no problem here: beautiful sine curve, axes and all (gv-3.5.8
of June 1997, R-1.6.2, medium-speed 733MHz single processor with 512MB RAM
running Linux; 15 seconds to draw the curve; 'gs' 5.5 took about 5 secs).
At a guess your 'gv' is not coping. It's not a PS problem as such.

Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 29-May-03                                       Time: 19:00:38
------------------------------ XFMail ------------------------------



From elvis at xlsolutions-corp.com  Thu May 29 20:27:26 2003
From: elvis at xlsolutions-corp.com (elvis@xlsolutions-corp.com)
Date: Thu, 29 May 2003 11:27:26 -0700
Subject: [R] Course***Advanced R/Splus Programming in Princeton,
	San Francisco, etc***June/July 2003 by XLsolutions Corp.
Message-ID: <APEHLKCMHHAKBGLAPKPCMEENCGAA.elvis@xlsolutions-corp.com>

XSolutions Corp (www.xlsolutions-corp.com) is proud to announce
a 2-day "Advanced R/Splus programming" taught by R Development
Core Team Guru!

*********Princeton, NJ ---------->  June 19-20, 2003
*********San Francisco ---------->  July 24-25, 2003

*********Boston, MA    ---------->  TBD
*********Washington DC ---------->  TBD


           Early-bird discount ends May 31!
           Reserve your seat Now  (payment due after the class)

Registration:


Email Sue Turner: sue at xlsolutions-corp.com
Phone: 206-686-1578

www.xlsolutions-corp.com/training.htm

With the following outline:

- Overview of R/S fundamentals: Syntax and Semantics
- Class and Inheritance in R/S-Plus
- Concepts, Construction and good use of language objects
- Coercion and efficiency
- Object-oriented programming in R and S-Plus
- Advanced manipulation tools: Parse, Deparse, Substitute, etc.
- How to fully take advantage of Vectorization
- Generic and Method Functions; S4 (S-Plus 6)
- Search path, databases and frames Visibility
- Working with large objects
- Handling Properly Recursion and iterative calculations
- Managing loops; For (S-Plus) and for() loops
- Consequences of Lazy Evaluation
- Efficient Code practices for large computations
- Memory management and Resource monitoring
- Writing R/S-Plus functions to call compiled code
- Writing and debugging compiled code for R/S-Plus system
- Connecting R/S-Plus to External Data Sources
- Understanding the structure of model fitting functions in R/S-Plus
- Designing and Packaging efficiently a new model function


Please email us for the full description of the course with fees and
information on trainers. For example, Early-bird group research fee is
$995!
It'll also deal with lots of S-Plus efficiency issues and any special topics
from participants is welcome.

Please let us know if you and your colleagues are interested in this class
to take advantage of group discount. Over half of the seats in both classes
are currently reserved.  Register now to secure your seat in this course!

Cheers,

Elvis Miller, PhD
Manager Training.
XLSolutions Corporation
206 686 1578
www.xlsolutions-corp.com



From rpeng at stat.ucla.edu  Thu May 29 20:25:00 2003
From: rpeng at stat.ucla.edu (Roger D. Peng)
Date: Thu, 29 May 2003 11:25:00 -0700
Subject: [R] how to smooth a line in a graph
In-Reply-To: <1054252090.1356.10.camel@templar.fns.uniba.sk>
References: <1054252090.1356.10.camel@templar.fns.uniba.sk>
Message-ID: <3ED6507C.4060007@stat.ucla.edu>

You may be interested in spline().  For example:

x <- 1:5
y <- c(1,3,4, 2.5,2)
plot(x, y)
sp <- spline(x, y, n = 50)
lines(sp)

-roger

Rado Bonk wrote:
> Hi R-users,
> 
> I have a line graph made by plot(). The line is very similar to
> hyperbola, and consists of 5 points. How can I make it look smooth?
> 
> Thanks,
> 
> Rado 
>



From lancelot at sentoo.sn  Thu May 29 21:12:14 2003
From: lancelot at sentoo.sn (Renaud Lancelot)
Date: Thu, 29 May 2003 19:12:14 +0000
Subject: [R] surfaces and digital terrain model
Message-ID: <3ED65B8E.7050703@sentoo.sn>

Dear all,

I have computed a digital terrain model from a set of points (x, y, z) 
using the function interp() in package akima. I want to predict flooded 
surfaces given target values of z. I can display the flooded surfaces 
with contour() or image(), but I don't know how to get the polygons 
delimiting the surfaces. Did anyone write a function for this purpose ?

Best regards,

Renaud

-- 
Dr Renaud Lancelot, v?t?rinaire
CIRAD, D?partement Elevage et M?decine V?t?rinaire (CIRAD-Emvt)
Programme Productions Animales
http://www.cirad.fr/presentation/programmes/prod-ani.shtml

ISRA-LNERV                      tel    (221) 832 49 02
BP 2057 Dakar-Hann              fax    (221) 821 18 79 (CIRAD)
Senegal                         e-mail renaud.lancelot at cirad.fr



From athyer at muohio.edu  Thu May 29 21:39:37 2003
From: athyer at muohio.edu (athyer@muohio.edu)
Date: Thu, 29 May 2003 15:39:37 -0400 (EDT)
Subject: [R] Citation
Message-ID: <1286.134.53.9.199.1054237177.squirrel@webmail.muohio.edu>

Hello!
Can anyone tell me the proper format for citing "R" in a publication?
Sincerely,

Erin Athy
Miami University
Oxford OH



From ligges at statistik.uni-dortmund.de  Thu May 29 21:49:23 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 29 May 2003 21:49:23 +0200
Subject: [R] Citation
References: <1286.134.53.9.199.1054237177.squirrel@webmail.muohio.edu>
Message-ID: <3ED66443.ADA2AAAF@statistik.uni-dortmund.de>



athyer at muohio.edu wrote:
> 
> Hello!
> Can anyone tell me the proper format for citing "R" in a publication?

Yes: the R FAQ in Section 2.8 ("Citing R").

Uwe Ligges


> Sincerely,
> 
> Erin Athy
> Miami University
> Oxford OH



From rwatkins at cornerstonelp.com  Thu May 29 21:56:58 2003
From: rwatkins at cornerstonelp.com (rwatkins@cornerstonelp.com)
Date: Thu, 29 May 2003 14:56:58 -0500
Subject: [R] Newbie trying to Lag Variables in a regression
Message-ID: <NDEKIJPPGJCIKBNEDOKOMEDPCCAA.rwatkins@cornerstonelp.com>

Perhaps I am making this too hard, but how does one regress y(t) on a
constant, x(t-1) and y(t-1)?  I've tried the manuals and until I get
Dalgaard's book (just ordered on Amazon), I am stuck!

Thanks to all in advance for your patience and consideration.



From lehmann at puk.unibe.ch  Thu May 29 22:07:21 2003
From: lehmann at puk.unibe.ch (Christoph Lehmann)
Date: Thu, 29 May 2003 20:07:21 -0000
Subject: [R] collinearity for relative data (percent values)
Message-ID: <1054238780.1261.15.camel@christophl>

sorry, maybe an all too trivial question. But we have power data from J
frequency spectra and to have the same range for the data of all our
subjects, we just transformed them into % values, pseudo-code:

power[i,j]=power[i,j]/sum(power[i,1:J])

of course, now we have perfect collinearity in our x design-matrix,
since all power-values for each subject sum up to 1.

How shall we solve this problem: just eliminate one column of x, or
introduce a restriction which says exactly that our power data sum up to
1 for each subject?

Thanks a lot

Christoph
-- 
Christoph Lehmann <lehmann at puk.unibe.ch>
University Hospital of Clinical Psychiatry



From r at difficulties.de  Fri May 30 00:55:40 2003
From: r at difficulties.de (Matthias Kirschner)
Date: Fri, 30 May 2003 00:55:40 +0200
Subject: [R] R summary
Message-ID: <20030529225540.GA20871@kb.mbwg.de>

Dear all
i use R only a few days and don't understand the difference between
fivenum(x) und summary(x).

> x
 [1] 20.77 22.56 22.71 22.99 26.39 27.08 27.32 27.33 27.57 27.81 28.69 29.36
[13] 30.25 31.89 32.88 33.23 33.28 33.40 33.52 33.83 33.95 34.82
> fivenum(x)
[1] 20.770 27.080 29.025 33.280 34.820
> summary(x)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  20.77   27.14   29.03   29.17   33.27   34.82 

And why is the 1st Qu. 27.14 although
qL=x(1/4*(n+1))=x(23/4)=x(5 3/4)
x(5)=26.39
x(6)=27.08
why is ql in summary between x(6) und x(7)??

I have learned that 1st Qu. = q(0.25)... so i am a little confused.

Thanks a lot
Matze



From r.hankin at auckland.ac.nz  Thu May 29 23:27:52 2003
From: r.hankin at auckland.ac.nz (Robin Hankin)
Date: Fri, 30 May 2003 09:27:52 +1200
Subject: [R] R CMD BATCH --vanilla --slave produces unwanted lines
Message-ID: <200305292127.h4TLRqdC001093@r.hankin.sges.auckland.ac.nz>

Hello list

(thanks for all the help on my data.frame() question, especially to
Professor R for a working script...I was pleased to see the solution
wasn't obvious!)

Anyway, now I'm trying to run R in batch mode, but I'm getting extra
output, which I don't want (RedHat 8.3, R-1.7.0):

r:~% cat test.R
options(echo=FALSE)
write(rnorm(4),"")

r:~% R CMD BATCH --vanilla --slave test.R
r:~% cat test.Rout 
> options(echo=FALSE)
0.1500393 0.1067567 0.2707306 -1.657154
[1] 1.82 0.07 1.87 0.00 0.00
r:~% 


I just want the four random variables, not the "options(echo=FALSE)"
line nor the final line which looks like the output of a proc.time()
call (how come this is called at all if I'm using the --vanilla flag?)

How do I arrange for test.Rout to contain just a single line of four
random variables?



-- 

Robin Hankin, Lecturer,
School of Geography and Environmental Science
Tamaki Campus
Private Bag 92019 Auckland
New Zealand

r.hankin at auckland.ac.nz
tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042



From p.dalgaard at biostat.ku.dk  Thu May 29 23:40:29 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Thu, 29 May 2003 21:40:29 -0000
Subject: [R] Newbie trying to Lag Variables in a regression
In-Reply-To: <NDEKIJPPGJCIKBNEDOKOMEDPCCAA.rwatkins@cornerstonelp.com>
References: <NDEKIJPPGJCIKBNEDOKOMEDPCCAA.rwatkins@cornerstonelp.com>
Message-ID: <x2add5bf2c.fsf@biostat.ku.dk>

<rwatkins at cornerstonelp.com> writes:

> Perhaps I am making this too hard, but how does one regress y(t) on a
> constant, x(t-1) and y(t-1)?  I've tried the manuals and until I get
> Dalgaard's book (just ordered on Amazon), I am stuck!

Not sure the book will unstick you...

However, the simple way is to create a new variable which shifts the
response, i.e. 

yshft <- c(y[-1], NA) # pad with missing
summary(lm(yshft ~ x + y))

Alternatively, lag the regressors:

N <- length(x)
xlag <- c(NA, x[1:(N-1)])
ylag <- c(NA, y[1:(N-1)])
summary(lm(y ~ xlag + ylag))


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From kmw at rockefeller.edu  Thu May 29 23:57:52 2003
From: kmw at rockefeller.edu (Knut M. Wittkowski)
Date: Thu, 29 May 2003 17:57:52 -0400
Subject: [R] R summary (and quantiles)
In-Reply-To: <20030529225540.GA20871@kb.mbwg.de>
Message-ID: <5.1.0.14.0.20030529174331.01e682a0@imap.rockefeller.edu>

Matthias

The function "fivenum", defines quantiles by assuming that the i-th order 
statistic is the

         (i-0.5)/(length(x))

quantile. Thus, it defines a 25% quantile by finding the cutoff point where 
25% are below and 75% above. In this example, this is the "center" of 
27.08, counting half of this measurement as "above" and half as "below". 
This makes a lot of sense, but problem with this definition is that the min 
is not the 0% quantile, but the 1/2n-quantile.

 > (order(x)-.5)/(length(x))
  [1] 0.02272727 0.06818182 0.11363636 0.15909091 0.20454545 0.25000000
  [7] 0.29545455 0.34090909 0.38636364 0.43181818 0.47727273 0.52272727
[13] 0.56818182 0.61363636 0.65909091 0.70454545 0.75000000 0.79545455
[19] 0.84090909 0.88636364 0.93181818 0.97727273

The function "summary" is based on a definition of quantiles that is biased 
to equate the min to the 0%-quantile and max to the 100%-quantile. "The 
algorithm linearly interpolates between order statistics of x, assuming 
that the ith order statistic is the

         (i-1)/(length(x)-1)

quantile."

The solution is simple: Never use

         quantile or
         summary

if you are interested in quantiles ;-)

At 00:55 2003-05-30 +0200, you wrote:
>Dear all
>i use R only a few days and don't understand the difference between
>fivenum(x) und summary(x).
>
> > x
>  [1] 20.77 22.56 22.71 22.99 26.39 27.08 27.32 27.33 27.57 27.81 28.69 29.36
>[13] 30.25 31.89 32.88 33.23 33.28 33.40 33.52 33.83 33.95 34.82
> > fivenum(x)
>[1] 20.770 27.080 29.025 33.280 34.820
> > summary(x)
>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>   20.77   27.14   29.03   29.17   33.27   34.82
>
>And why is the 1st Qu. 27.14 although
>qL=x(1/4*(n+1))=x(23/4)=x(5 3/4)
>x(5)=26.39
>x(6)=27.08
>why is ql in summary between x(6) und x(7)??
>
>I have learned that 1st Qu. = q(0.25)... so i am a little confused.
>
>Thanks a lot
>Matze
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help

Knut M. Wittkowski, PhD,DSc
------------------------------------------
The Rockefeller University, GCRC
1230 York Ave #121B, Box 322, NY,NY 10021
+1(212)327-7175, +1(212)327-8450 (Fax)
kmw at rockefeller.edu
http://www.rucares.org/statist/



From macq at llnl.gov  Fri May 30 01:02:29 2003
From: macq at llnl.gov (Don MacQueen)
Date: Thu, 29 May 2003 16:02:29 -0700
Subject: [R] Postscript query: plotting long vectors
In-Reply-To: <16086.15476.115381.712265@bushmills.inf.ed.ac.uk>
References: <16086.15476.115381.712265@bushmills.inf.ed.ac.uk>
Message-ID: <p05210603bafc20a62a36@[128.115.153.6]>

When I run the example in R 1.6.2, and view it with gs, I get a good plot.
When I run the example in R 1.7.0, and view it with gs, I get a bad plot.
(run on the same host)

My "bad plot" is as described by Stephen.

In the "good" postscript file, about 100 lines in, there is this:
%%EndProlog
%%Page: 1 1
bp
77.04 91.44 743.76 534.96 cl
0.0000 0.0000 0.0000 rgb
0.75 setlinewidth
[] 0 setdash
np
101.73 313.20 m
101.74 313.21 l
101.74 313.23 l
101.74 313.24 l
101.75 313.25 l
(followed by ~200000 lines of the same type, with slowly changing values)

In the "bad" postscript file, at about the same point in the file, is this:
%%EndProlog
%%Page: 1 1
bp
77.04 91.44 743.76 534.96 cl
0 0 0 rgb
0.75 setlinewidth
[] 0 setdash
np
101.73 313.20 m
0.00 0.01 l
0.00 0.01 l
0.00 0.01 l
0.00 0.01 l
0.00 0.01 l
(followed by ~200000 lines, including some like these)

0.00 0.00 l
0.00 0.00 l

0.00 -0.01 l
0.00 -0.01 l

0.00 -0.00 l
0.00 -0.00 l

Looks like it might be a formatting issue on how these lines were written.

My version information:

---- 1.6.2 ----
>  version
platform sparc-sun-solaris2.7
arch     sparc              
os       solaris2.7         
system   sparc, solaris2.7  
status                      
major    1                  
minor    6.2                
year     2003               
month    01                 
day      10                 
language R                  
>

---- 1.7.0 ----
>  version
          _                  
platform sparc-sun-solaris2.7
arch     sparc              
os       solaris2.7         
system   sparc, solaris2.7  
status                      
major    1                  
minor    7.0                
year     2003               
month    04                 
day      16                 
language R                  

[245]% gs --version
5.50

-Don

At 5:59 PM +0100 5/29/03, Stephen Eglen wrote:
>Hi,
>
>I have a query about the maximum length of vector that can be plotted
>in one go in a postscript driver.  Try the following code (in 1.7.0;
>version details below):
>
>t <- seq(from=0, to=4*pi, length=200000)
>y <- sin(t)
>postscript(file="o.ps")
>plot(t, y, type="l")
>dev.off()
>
>If I view the postscript file o.ps in "gv", it takes many seconds
>before eventually the axes appear, but then only one vertical line is
>drawn within the plot area -- there is no sine curve.  (this is on a
>fast dual processor linux machine with 2Gb RAM.)  This is clearly a
>postscript problem, rather than a R problem, since reducing the length
>of t down to something like 2000 solves the problem.  By looking at
>the file o.ps it looks like the line is drawn by one "rlineto" call
>per point, followed eventually by a "stroke" after the last point.
>I'm guessing that the postscript interpreter simply cannot remember so
>many points in the path before it gets to the stroke.
>
>The example above is artificial, but this problem appeared with a real
>data set this morning.  The fix was to replace the single call to
>plot() with many calls to line(), breaking the t and y vectors into
>more manageable chunks; in this way, each postscript path was
>manageable and we got the plot.
>
>I tried plotting the same long vectors in gnuplot by first writing
>them from R:
>
>write.table(cbind(t,y), sep="\t", file="eg.dat", row.names=F, col.names=F,
>             quote=F)
>
>and then in gnuplot:
>
>set term postscript
>set output "gnuplot.ps"
>plot "eg.dat" wi lines
>
>This came out fine; in gnuplot.ps every 400 lines during the plot it
>outputs "currentpoint stroke M" (M is defined to moveto).  I had a
>look at the gnuplot source (gnuplot-3.7.3/term/post.trm) and found
>that it does keep count of the length of the current postscript path:
>e.g. in the function PS_vector(x,y) we see (line 1122):
>
>	if (ps_path_count >= 400) {
>		fprintf(gpoutfile,"currentpoint stroke M\n");
>		ps_path_count = 0;
>	}
>
>so every 400 points it draws the line so far and then continues.
>(Matlab .ps files also seem to have regular "MP stroke".
>
>I had a quick look in the corresponding R code src/main/devPS.c and
>could not see any counter.  Would it be worth adding such a counter
>and periodic line output to PS_Polyline?
>
>
>>  version
>platform i686-pc-linux-gnu
>arch     i686            
>os       linux-gnu       
>system   i686, linux-gnu 
>status                   
>major    1               
>minor    7.0             
>year     2003            
>month    04              
>day      16              
>language R
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From mhoward at micron.com  Fri May 30 01:11:24 2003
From: mhoward at micron.com (mhoward@micron.com)
Date: Thu, 29 May 2003 17:11:24 -0600
Subject: [R] Comparison Operator
Message-ID: <363801FFD7B74240A329CEC3F7FE4CC409C83D@ntxboimbx07.micron.com>

Does R have a comparison operator similar to the Like function, for example:

a<-"Is a Fish"
b<-"Fish"

if(b in a){c<-TRUE}

Michael R Howard
Micron Technology Inc. Boise ID.
Fab C Engineering Software (FCES)
Software Engineer



From sundar.dorai-raj at pdf.com  Fri May 30 01:23:02 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 29 May 2003 16:23:02 -0700
Subject: [R] Comparison Operator
References: <363801FFD7B74240A329CEC3F7FE4CC409C83D@ntxboimbx07.micron.com>
Message-ID: <3ED69656.3020505@pdf.com>



mhoward at micron.com wrote:
> Does R have a comparison operator similar to the Like function, for example:
> 
> a<-"Is a Fish"
> b<-"Fish"
> 
> if(b in a){c<-TRUE}
> 

How about ?regexpr:

R> a="is a fish"
R> b="fish"
R> regexpr(b,a)
[1] 6
attr(,"match.length")
[1] 4
R> regexpr(b,a)>0
[1] TRUE
R> b="Fish"
R> regexpr(b,a)>0
[1] FALSE

Note
Regards,
Sundar



From spencer.graves at pdf.com  Fri May 30 01:24:48 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 29 May 2003 16:24:48 -0700
Subject: [R] Comparison Operator
References: <363801FFD7B74240A329CEC3F7FE4CC409C83D@ntxboimbx07.micron.com>
Message-ID: <3ED696C0.1060002@pdf.com>

Have you considered "regexpr"?

 > a<-"Is a Fish"
 > b<-"Fish"
 > regexpr(b, a)
[1] 6
attr(,"match.length")
[1] 4

hth.  spencer graves

mhoward at micron.com wrote:
> Does R have a comparison operator similar to the Like function, for example:
> 
> a<-"Is a Fish"
> b<-"Fish"
> 
> if(b in a){c<-TRUE}
> 
> Michael R Howard
> Micron Technology Inc. Boise ID.
> Fab C Engineering Software (FCES)
> Software Engineer
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From edd at debian.org  Fri May 30 01:24:56 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 29 May 2003 18:24:56 -0500
Subject: [R] Comparison Operator
In-Reply-To: <363801FFD7B74240A329CEC3F7FE4CC409C83D@ntxboimbx07.micron.com>
References: <363801FFD7B74240A329CEC3F7FE4CC409C83D@ntxboimbx07.micron.com>
Message-ID: <20030529232455.GA28990@sonny.eddelbuettel.com>

On Thu, May 29, 2003 at 05:11:24PM -0600, mhoward at micron.com wrote:
> Does R have a comparison operator similar to the Like function, for example:
> 
> a<-"Is a Fish"
> b<-"Fish"
> 
> if(b in a){c<-TRUE}

You probably want grep:

> a<-"Is a Fish"
> b<-"Fish"
> if (grep(b,a)) c<-TRUE
> c
[1] TRUE

Hth, Dirk 

-- 
Don't drink and derive. Alcohol and analysis don't mix.



From andy_liaw at merck.com  Fri May 30 03:21:31 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 29 May 2003 21:21:31 -0400
Subject: [R] R summary (and quantiles)
Message-ID: <3A822319EB35174CA3714066D590DCD5C4FB77@usrymx25.merck.com>

When all else fails, read the help page...

?fivenum says to look at ?boxplot.stats, and the "Details" section of
?boxplot.stats has, well, details.  Tukey had reasons to call those hinges
rather than quartiles.

Andy

> -----Original Message-----
> From: Knut M. Wittkowski [mailto:kmw at rockefeller.edu]
> Sent: Thursday, May 29, 2003 5:58 PM
> To: Matthias Kirschner
> Cc: R-help at stat.math.ethz.ch
> Subject: Re: [R] R summary (and quantiles)
> 
> 
> Matthias
> 
> The function "fivenum", defines quantiles by assuming that 
> the i-th order 
> statistic is the
> 
>          (i-0.5)/(length(x))
> 
> quantile. Thus, it defines a 25% quantile by finding the 
> cutoff point where 
> 25% are below and 75% above. In this example, this is the "center" of 
> 27.08, counting half of this measurement as "above" and half 
> as "below". 
> This makes a lot of sense, but problem with this definition 
> is that the min 
> is not the 0% quantile, but the 1/2n-quantile.
> 
>  > (order(x)-.5)/(length(x))
>   [1] 0.02272727 0.06818182 0.11363636 0.15909091 0.20454545 
> 0.25000000
>   [7] 0.29545455 0.34090909 0.38636364 0.43181818 0.47727273 
> 0.52272727
> [13] 0.56818182 0.61363636 0.65909091 0.70454545 0.75000000 0.79545455
> [19] 0.84090909 0.88636364 0.93181818 0.97727273
> 
> The function "summary" is based on a definition of quantiles 
> that is biased 
> to equate the min to the 0%-quantile and max to the 
> 100%-quantile. "The 
> algorithm linearly interpolates between order statistics of 
> x, assuming 
> that the ith order statistic is the
> 
>          (i-1)/(length(x)-1)
> 
> quantile."
> 
> The solution is simple: Never use
> 
>          quantile or
>          summary
> 
> if you are interested in quantiles ;-)
> 
> At 00:55 2003-05-30 +0200, you wrote:
> >Dear all
> >i use R only a few days and don't understand the difference between
> >fivenum(x) und summary(x).
> >
> > > x
> >  [1] 20.77 22.56 22.71 22.99 26.39 27.08 27.32 27.33 27.57 
> 27.81 28.69 29.36
> >[13] 30.25 31.89 32.88 33.23 33.28 33.40 33.52 33.83 33.95 34.82
> > > fivenum(x)
> >[1] 20.770 27.080 29.025 33.280 34.820
> > > summary(x)
> >    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
> >   20.77   27.14   29.03   29.17   33.27   34.82
> >
> >And why is the 1st Qu. 27.14 although
> >qL=x(1/4*(n+1))=x(23/4)=x(5 3/4)
> >x(5)=26.39
> >x(6)=27.08
> >why is ql in summary between x(6) und x(7)??
> >
> >I have learned that 1st Qu. = q(0.25)... so i am a little confused.
> >
> >Thanks a lot
> >Matze
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> Knut M. Wittkowski, PhD,DSc
> ------------------------------------------
> The Rockefeller University, GCRC
> 1230 York Ave #121B, Box 322, NY,NY 10021
> +1(212)327-7175, +1(212)327-8450 (Fax)
> kmw at rockefeller.edu
> http://www.rucares.org/statist/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------
Notice: This e-mail message, together with any attachments, cont... {{dropped}}



From p.connolly at hortresearch.co.nz  Fri May 30 05:04:39 2003
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Fri, 30 May 2003 15:04:39 +1200
Subject: [R] Postscript query: plotting long vectors
In-Reply-To: <p05210603bafc20a62a36@[128.115.153.6]>
References: <16086.15476.115381.712265@bushmills.inf.ed.ac.uk>
	<p05210603bafc20a62a36@[128.115.153.6]>
Message-ID: <20030530030439.GF8550@hortresearch.co.nz>

On Thu, 29-May-2003 at 04:02PM -0700, Don MacQueen wrote:

|> When I run the example in R 1.6.2, and view it with gs, I get a good plot.
|> When I run the example in R 1.7.0, and view it with gs, I get a bad plot.
|> (run on the same host)
|> 
|> My "bad plot" is as described by Stephen.


[ ... ]

|> 
|> 0.00 -0.00 l
|> 0.00 -0.00 l
|> 
|> Looks like it might be a formatting issue on how these lines were written.
|> 
|> My version information:
|> 
|> ---- 1.6.2 ----
|> > version
|> platform sparc-sun-solaris2.7
|> arch     sparc              
|> os       solaris2.7         
|> system   sparc, solaris2.7  
|> status                      
|> major    1                  
|> minor    6.2                
|> year     2003               
|> month    01                 
|> day      10                 
|> language R                  
|> >
|> 
|> ---- 1.7.0 ----
|> > version
|>          _                  
|> platform sparc-sun-solaris2.7
|> arch     sparc              
|> os       solaris2.7         
|> system   sparc, solaris2.7  
|> status                      
|> major    1                  
|> minor    7.0                
|> year     2003               
|> month    04                 
|> day      16                 
|> language R                  

I can confirm similar results using Redhat Linux 7.3 with the same two
R releases and gv 3.5.8.


best

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From temiz at deprem.gov.tr  Fri May 30 09:53:10 2003
From: temiz at deprem.gov.tr (orkun)
Date: Fri, 30 May 2003 10:53:10 +0300
Subject: [R] piping the results
Message-ID: <3ED70DE6.80100@deprem.gov.tr>

Hello

Could you explain how I can export (or pipe) statistics result to a text 
file.
When results are in large quantity. I cannot see all of them  in console


kind regards


Ahmet Temiz

TURKEY




______________________________________



______________________________________
The views and opinions expressed in this e-mail message are the ... {{dropped}}



From ligges at statistik.uni-dortmund.de  Fri May 30 09:59:12 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 30 May 2003 09:59:12 +0200
Subject: [R] piping the results
In-Reply-To: <3ED70DE6.80100@deprem.gov.tr>
References: <3ED70DE6.80100@deprem.gov.tr>
Message-ID: <3ED70F50.5030006@statistik.uni-dortmund.de>

orkun wrote:
> Hello
> 
> Could you explain how I can export (or pipe) statistics result to a text 
> file.
> When results are in large quantity. I cannot see all of them  in console
> 
> 
> kind regards
> 
> 
> Ahmet Temiz
> 
> TURKEY
> 

See ?sink and ?capture.output.

Uwe Ligges



From ripley at stats.ox.ac.uk  Fri May 30 09:59:50 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 30 May 2003 08:59:50 +0100 (BST)
Subject: [R] piping the results
In-Reply-To: <3ED70DE6.80100@deprem.gov.tr>
Message-ID: <Pine.LNX.4.44.0305300858340.27788-100000@gannet.stats>

See ?sink.   I doubt it you really mean it, but ?pipe tells you how to 
pipe things to a process (not a file).

On Fri, 30 May 2003, orkun wrote:

> Could you explain how I can export (or pipe) statistics result to a text 
> file.
> When results are in large quantity. I cannot see all of them  in console

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From phgrosjean at sciviews.org  Fri May 30 10:12:05 2003
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Fri, 30 May 2003 10:12:05 +0200
Subject: [R] Slow computation in for loop
In-Reply-To: <3ED522A1.8090301@stat.auckland.ac.nz>
Message-ID: <MABBLJDICACNFOLGIHJOEENMDHAA.phgrosjean@sciviews.org>

Philippe Grosjean wrote:
>> I suspect that your problem comes from the rbind(). I have also noticed
an
>> exponentially slower execution with the increase of the size of the data
>> frame that you rbind()s. It is much faster to rbind() several separated
>> temporary data frames (let's say, ten by ten loops), and then to rbind()
>> them all together.

Ross Ihaka answered:
>Got it in one.  This is one place where Splus performance is much better
>than R.  Some simulations I did makes it look like Splus does not just
>enlarge objects one element at a time. Instead, the underlying memory is
>enlarged in larger increments and additions to the array use this hidden
>space.

>I thought about adding this feature, but in the end decided that
>pre-allocating the result is a better solution (the Splus enlargement
>strategy doesn't work when elements are prepended).  At one one point
>there was a slot in the object header which could have served to hold
>the "true length" of objects, but I think that Luke Tierney has used it
>for other puposes.

Of course, we could dream of a faster rbind() in such circumstances (Prof.
Brian Ripley pointed also that using a data frame is much less efficient
than a matrix if all entries are numbers). However, if nobody has objections
on the programming style using a preallocated matrix, perhaps should it be
useful to add this tip somewhere in the documentation (FAQ, ...?):

# Solution using rbind()
all.results <- NULL
system.time(
for (i in 1:10000) {
	result <- rnorm(5)
	all.results <- rbind(all.results, result)
})

# Solution using a preallocated matrix
all.results <- matrix(nrow=10000, ncol=5)
system.time(
for (i in 1:10000) {
	result <- rnorm(5)
	all.results[i, ] <- result
})

On my P IV 1.6 Ghz, it took 11.74 sec using rbind() and 0.36 sec using the
preallocated matrix.
Best,

Philippe Grosjean

...........]<(({?<...............<?}))><...............................
 ) ) ) ) )
( ( ( ( (       Dr. Philippe Grosjean
 ) ) ) ) )
( ( ( ( (       LOV, UMR 7093
 ) ) ) ) )      Station Zoologique
( ( ( ( (       Observatoire Oceanologique
 ) ) ) ) )      BP 28
( ( ( ( (       06234 Villefranche sur mer cedex
 ) ) ) ) )      France
( ( ( ( (
 ) ) ) ) )      tel: +33.4.93.76.38.18, fax: +33.4.93.76.38.34
( ( ( ( (
 ) ) ) ) )      e-mail: phgrosjean at sciviews.org
( ( ( ( (       SciViews project coordinator (http://www.sciviews.org)
 ) ) ) ) )
.......................................................................



From Bernhard.Pfaff at drkw.com  Fri May 30 10:37:14 2003
From: Bernhard.Pfaff at drkw.com (Pfaff, Bernhard)
Date: Fri, 30 May 2003 10:37:14 +0200
Subject: [R] Newbie trying to Lag Variables in a regression
Message-ID: <18D602BD42B7E24EB810D6454A58DB90047303CC@ibfftce505.is.de.dresdnerkb.com>

<rwatkins at cornerstonelp.com> writes:

> Perhaps I am making this too hard, but how does one regress y(t) on a
> constant, x(t-1) and y(t-1)?  I've tried the manuals and until I get
> Dalgaard's book (just ordered on Amazon), I am stuck!

Not sure the book will unstick you...

However, the simple way is to create a new variable which shifts the
response, i.e. 

yshft <- c(y[-1], NA) # pad with missing
summary(lm(yshft ~ x + y))

Alternatively, lag the regressors:

N <- length(x)
xlag <- c(NA, x[1:(N-1)])
ylag <- c(NA, y[1:(N-1)])
summary(lm(y ~ xlag + ylag))


Hello rwatkins,

in case you have to cope oftenly with lagged exogenous and/or endogenous
variables the following function might be handy, in particular if you want
to create longer lagged series (this is controlled by setting the argument
'd' to the relevant integer of the lagged period):  

#
# Function: tslag (lagging a vector)
#
tslag <- 
function(x, d=1)
{
  x <- as.vector(x)
  n <- length(x)
  c(rep(NA,d),x)[1:n]
}

HTH,
Bernhard



-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


----------------------------------------------------------------------
If you have received this e-mail in error or wish to read our e-mail 
disclaimer statement and monitoring policy, please refer to 
http://www.drkw.com/disc/email/ or contact the sender.



From th.fischer at gmx.net  Fri May 30 10:44:55 2003
From: th.fischer at gmx.net (Thomas Fischer)
Date: Fri, 30 May 2003 10:44:55 +0200
Subject: [R] Coefficients: (20 not defined because of singularities)
Message-ID: <200305301044.55917.th.fischer@gmx.net>

Hello,

I am trying to run a linear regression analysis on my data set. For some 
reason most variables are removed due to singularities.

My linear regression looks this way (I am using only partial data, which 
is selected by flags):

fm<-lm(log(cplex6.time..sec..[flags]) ~ cplex6.cities[flags] + 
log(1/features.meanOver.frust[flags]) + 
log(1/features.meanOver.minDist[flags]) +
[...]
avg..steps.to.loc..Opt..norm..[flags] + NN.List.opt..tour.max.[flags])

As I am using inversion and logarithms I set all data to positiv values, 
before running lm():

cplex6.time..sec..[cplex6.time..sec..<=0.00001]=0.00001
features.meanOver.frust[features.meanOver.frust<=0.00001]=0.00001
features.meanOver.minDist[features.meanOver.minDist<=0.00001]=0.00001
[...]
features.varOver.varDist[features.varOver.varDist<=0.00001]=0.00001

Retrieving the summary of fm, I get the message, that some coefficients 
have been removed.

[...]
Coefficients: (20 not defined because of singularities)
                                                Estimate Std. Error t 
value
(Intercept)                                      87.2162    44.1148   
1.977
log(1/features.meanOver.frust[flags])            -2.5298     0.1515 
-16.702
log(1/features.meanOver.minDist[flags])         154.7170    11.3917  
13.582
log(1/features.meanOver.quant25Dist[flags])    -943.4625    71.3505 
-13.223
log(1/features.meanOver.quart1SpanDist[flags])  776.1049    60.0571  
12.923
log(1/features.meanOver.spanDist[flags])         -9.8069     0.1400 
-70.038
log(1/features.meanOver.varDist[flags])         -11.3211     0.6715 
-16.859
log(1/features.quant25Over.minDist[flags])      -46.9655     3.1438 
-14.939
avg..steps.to.loc..Opt..norm..[flags]             0.8324     1.0919   
0.762
                                               Pr(>|t|)
(Intercept)                                      0.0511 .
log(1/features.meanOver.frust[flags])            <2e-16 ***
log(1/features.meanOver.minDist[flags])          <2e-16 ***
log(1/features.meanOver.quant25Dist[flags])      <2e-16 ***
log(1/features.meanOver.quart1SpanDist[flags])   <2e-16 ***
log(1/features.meanOver.spanDist[flags])         <2e-16 ***
log(1/features.meanOver.varDist[flags])          <2e-16 ***
log(1/features.quant25Over.minDist[flags])       <2e-16 ***
avg..steps.to.loc..Opt..norm..[flags]            0.4478
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
[...]


The summary of one of the removed coefficients looks like this:

> summary(features.spanOver.quart1SpanDist[flags])
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
0.05584 0.05797 0.06366 0.06311 0.06674 0.07290
> summary(log(1/features.spanOver.quart1SpanDist[flags]))
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
  2.619   2.707   2.754   2.767   2.848   2.885

The summary of a coefficient that was kept looks this way:

> summary(features.quant25Over.minDist[flags])
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.
0.001030 0.001030 0.001030 0.001032 0.001030 0.001040
> summary(log(1/features.quant25Over.minDist[flags]))
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
  6.869   6.878   6.878   6.877   6.878   6.878

So, I don't see the difference. Why has the first coefficient been 
removed and the second one kept?
Please help me.

I'm using R 1.6.2 on a Linux x86 machine.

Greetings,
Thomas Fischer



From temiz at deprem.gov.tr  Fri May 30 10:57:44 2003
From: temiz at deprem.gov.tr (orkun)
Date: Fri, 30 May 2003 11:57:44 +0300
Subject: [R] cbind order
Message-ID: <3ED71D08.7010603@deprem.gov.tr>

Hello

I need to use this command:
cbind(ftable(xtabs(cnt~geo+slp+con+hey,data=dt3))
hey is in count of success /failure value
but cbind gives failure/success counts. I want to change the order of 
this cbind as  success /failure counts.
for instance:
I want cbind to give counts as 32-4552 rather than 4552-32


what should I do ?


thanks in advance

Ahmet
TURKEY


______________________________________



______________________________________
The views and opinions expressed in this e-mail message are the ... {{dropped}}



From ripley at stats.ox.ac.uk  Fri May 30 11:06:31 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 30 May 2003 10:06:31 +0100 (BST)
Subject: [R] Coefficients: (20 not defined because of singularities)
In-Reply-To: <200305301044.55917.th.fischer@gmx.net>
Message-ID: <Pine.LNX.4.44.0305301003570.31111-100000@gannet.stats>

It is the model matrix which is singular, *not* the variable.  You are 
trying to fit a collinear model.

Use alias() to see what is going on.

On Fri, 30 May 2003, Thomas Fischer wrote:

> Hello,
> 
> I am trying to run a linear regression analysis on my data set. For some 
> reason most variables are removed due to singularities.
> 
> My linear regression looks this way (I am using only partial data, which 
> is selected by flags):
> 
> fm<-lm(log(cplex6.time..sec..[flags]) ~ cplex6.cities[flags] + 
> log(1/features.meanOver.frust[flags]) + 
> log(1/features.meanOver.minDist[flags]) +
> [...]
> avg..steps.to.loc..Opt..norm..[flags] + NN.List.opt..tour.max.[flags])
> 
> As I am using inversion and logarithms I set all data to positiv values, 
> before running lm():
> 
> cplex6.time..sec..[cplex6.time..sec..<=0.00001]=0.00001
> features.meanOver.frust[features.meanOver.frust<=0.00001]=0.00001
> features.meanOver.minDist[features.meanOver.minDist<=0.00001]=0.00001
> [...]
> features.varOver.varDist[features.varOver.varDist<=0.00001]=0.00001
> 
> Retrieving the summary of fm, I get the message, that some coefficients 
> have been removed.

No, that they are nor defined, as it says.


> [...]
> Coefficients: (20 not defined because of singularities)
>                                                 Estimate Std. Error t 
> value
> (Intercept)                                      87.2162    44.1148   
> 1.977
> log(1/features.meanOver.frust[flags])            -2.5298     0.1515 
> -16.702
> log(1/features.meanOver.minDist[flags])         154.7170    11.3917  
> 13.582
> log(1/features.meanOver.quant25Dist[flags])    -943.4625    71.3505 
> -13.223
> log(1/features.meanOver.quart1SpanDist[flags])  776.1049    60.0571  
> 12.923
> log(1/features.meanOver.spanDist[flags])         -9.8069     0.1400 
> -70.038
> log(1/features.meanOver.varDist[flags])         -11.3211     0.6715 
> -16.859
> log(1/features.quant25Over.minDist[flags])      -46.9655     3.1438 
> -14.939
> avg..steps.to.loc..Opt..norm..[flags]             0.8324     1.0919   
> 0.762
>                                                Pr(>|t|)
> (Intercept)                                      0.0511 .
> log(1/features.meanOver.frust[flags])            <2e-16 ***
> log(1/features.meanOver.minDist[flags])          <2e-16 ***
> log(1/features.meanOver.quant25Dist[flags])      <2e-16 ***
> log(1/features.meanOver.quart1SpanDist[flags])   <2e-16 ***
> log(1/features.meanOver.spanDist[flags])         <2e-16 ***
> log(1/features.meanOver.varDist[flags])          <2e-16 ***
> log(1/features.quant25Over.minDist[flags])       <2e-16 ***
> avg..steps.to.loc..Opt..norm..[flags]            0.4478
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
> [...]
> 
> 
> The summary of one of the removed coefficients looks like this:

That's the summary of the variable, not the coefficient.

> > summary(features.spanOver.quart1SpanDist[flags])
>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
> 0.05584 0.05797 0.06366 0.06311 0.06674 0.07290
> > summary(log(1/features.spanOver.quart1SpanDist[flags]))
>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>   2.619   2.707   2.754   2.767   2.848   2.885
> 
> The summary of a coefficient that was kept looks this way:
> 
> > summary(features.quant25Over.minDist[flags])
>     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.
> 0.001030 0.001030 0.001030 0.001032 0.001030 0.001040
> > summary(log(1/features.quant25Over.minDist[flags]))
>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>   6.869   6.878   6.878   6.877   6.878   6.878
> 
> So, I don't see the difference. Why has the first coefficient been 
> removed and the second one kept?
> Please help me.
> 
> I'm using R 1.6.2 on a Linux x86 machine.
> 
> Greetings,
> Thomas Fischer
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From otoomet at econ.dk  Fri May 30 10:37:04 2003
From: otoomet at econ.dk (Ott Toomet)
Date: Fri, 30 May 2003 10:37:04 +0200
Subject: [R] Coefficients: (20 not defined because of singularities)
In-Reply-To: <200305301044.55917.th.fischer@gmx.net> (message from Thomas
	Fischer on Fri, 30 May 2003 10:44:55 +0200)
References: <200305301044.55917.th.fischer@gmx.net>
Message-ID: <200305300837.h4U8b4801858@punik.econ.au.dk>

Hi,

"singularity" in this case means that your X'X matrix is singular,
i.e. you have multicollinearity in your data.  A common reasons is
selecting observations with a particular binary feature (e.g. only
women) and then including a control variable for the same feature
(e.g. including child*women cross effect).  You seem to be working
with the continuous variables, so this may not be the case.

A way to check collinearity is using condition numbers (look
kappa() in R).  First, make the model matrix (you may use
model.matrix() but if you have only variables and no special effects,
you may use cbind() instead).  Then take a single column out of the
matrix and calculate the condition number (this is definitely 1).  Now
add the second column, and calculate again.  Print out condition
numbers, corresponding to the number of columns you used.  You should
see where the number explodes, it means corresponding variable is
collinear with some of the previous ones.

Perhaps it helps.

Ott

 | From: Thomas Fischer <th.fischer at gmx.net>
 | Date: Fri, 30 May 2003 10:44:55 +0200
 | 
 | Hello,
 | 
 | I am trying to run a linear regression analysis on my data set. For some 
 | reason most variables are removed due to singularities.
 | 
 | My linear regression looks this way (I am using only partial data, which 
 | is selected by flags):
 | 
 | fm<-lm(log(cplex6.time..sec..[flags]) ~ cplex6.cities[flags] + 
 | log(1/features.meanOver.frust[flags]) + 
 | log(1/features.meanOver.minDist[flags]) +

 | The summary of one of the removed coefficients looks like this:
 | 
 | > summary(features.spanOver.quart1SpanDist[flags])
 |    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
 | 0.05584 0.05797 0.06366 0.06311 0.06674 0.07290
 | > summary(log(1/features.spanOver.quart1SpanDist[flags]))
 |    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
 |   2.619   2.707   2.754   2.767   2.848   2.885
 | 
 | The summary of a coefficient that was kept looks this way:
 | 
 | > summary(features.quant25Over.minDist[flags])
 |     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.
 | 0.001030 0.001030 0.001030 0.001032 0.001030 0.001040
 | > summary(log(1/features.quant25Over.minDist[flags]))
 |    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
 |   6.869   6.878   6.878   6.877   6.878   6.878
 | 
 | So, I don't see the difference. Why has the first coefficient been 
 | removed and the second one kept?
 | Please help me.
 | 
 | I'm using R 1.6.2 on a Linux x86 machine.
 | 
 | Greetings,
 | Thomas Fischer



From arv at ono.com  Fri May 30 12:41:43 2003
From: arv at ono.com (antonio rodriguez)
Date: Fri, 30 May 2003 12:41:43 +0200
Subject: [R] Rcmdr on Debian
In-Reply-To: <x2n0h8aka0.fsf@biostat.ku.dk>
Message-ID: <IPEFKICOHOECENGJBAGLCEADCBAA.arv@ono.com>

Hi Peter,

Thanks it works fine now with this little trick

Cheers

Antonio

-----Mensaje original-----
De: Peter Dalgaard BSA [mailto:p.dalgaard at biostat.ku.dk]
Enviado el: martes, 27 de mayo de 2003 10:04
Para: arv at ono.com
CC: R Help
Asunto: Re: [R] Rcmdr on Debian


<arv at ono.com> writes:

> Hi,
> 
> I've been able to run Rcmdr on Debian-Woody without too much problems,
> just to load first the tcltk and car libraries. The issue is that after
> leaving R I'm not able to see at the prompt any character like 'ls', but
> the unix instructions are executed, don't know why the visualization of
> the unix commands is cancelled.

This can happen even without the tcltk stuff. Not quite sure why (most
likely, it is readline-related), but the way out is to type "stty
sane" at the shell prompt.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From p.dalgaard at biostat.ku.dk  Fri May 30 13:02:11 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri, 30 May 2003 11:02:11 -0000
Subject: [R] cbind order
In-Reply-To: <3ED71D08.7010603@deprem.gov.tr>
References: <3ED71D08.7010603@deprem.gov.tr>
Message-ID: <x23ciwadyd.fsf@biostat.ku.dk>

orkun <temiz at deprem.gov.tr> writes:

> Hello
> 
> I need to use this command:
> cbind(ftable(xtabs(cnt~geo+slp+con+hey,data=dt3))
> hey is in count of success /failure value
> but cbind gives failure/success counts. I want to change the order of
> this cbind as  success /failure counts.
> for instance:
> I want cbind to give counts as 32-4552 rather than 4552-32
> 
> 
> what should I do ?

Well, all cbind does in that context is to remove the embellishments
of the ftable structure, exposing the N x 2 internal matrix. Various
other matrix operations, including indexing, has the same effect, e.g.

data(Titanic)
ftable(Titanic, row.vars = 1:3)[,]    # same as using cbind()
ftable(Titanic, row.vars = 1:3)[,2:1] # what you want

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From tblackw at umich.edu  Fri May 30 13:51:32 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Fri, 30 May 2003 07:51:32 -0400 (EDT)
Subject: [R] R CMD BATCH --vanilla --slave produces unwanted lines
In-Reply-To: <200305292127.h4TLRqdC001093@r.hankin.sges.auckland.ac.nz>
Message-ID: <Pine.SOL.4.44.0305300745470.1269-100000@timepilot.gpcc.itd.umich.edu>

Supply a separate output file name explicitly to write().

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Fri, 30 May 2003, Robin Hankin wrote:

> Anyway, now I'm trying to run R in batch mode, but I'm getting extra
> output, which I don't want (RedHat 8.3, R-1.7.0):
>
> r:~% cat test.R
> options(echo=FALSE)
> write(rnorm(4),"")
>
> r:~% R CMD BATCH --vanilla --slave test.R
> r:~% cat test.Rout
> > options(echo=FALSE)
> 0.1500393 0.1067567 0.2707306 -1.657154
> [1] 1.82 0.07 1.87 0.00 0.00
> r:~%
>
> I just want the four random variables, not the "options(echo=FALSE)"
> line nor the final line which looks like the output of a proc.time()
> call (how come this is called at all if I'm using the --vanilla flag?)
>
> How do I arrange for test.Rout to contain just a single line of four
> random variables?
>
> Robin Hankin, Lecturer,
> School of Geography and Environmental Science
> Tamaki Campus
> Private Bag 92019 Auckland
> New Zealand
>
> r.hankin at auckland.ac.nz
> tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042
>



From tblackw at umich.edu  Fri May 30 14:35:16 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Fri, 30 May 2003 08:35:16 -0400 (EDT)
Subject: [R] surfaces and digital terrain model
In-Reply-To: <3ED65B8E.7050703@sentoo.sn>
Message-ID: <Pine.SOL.4.44.0305300814500.4891-100000@timepilot.gpcc.itd.umich.edu>

Renaud  -

help("contour") gives a reference to  filled.contour(), which might
do what you want by explicitly setting its "levels" argument to be
the single z value which corresponds to the water level.  I have not
experimented to see whether  filled.contour()  will accept arguments
new=FALSE, add=TRUE  which would allow it to add to an existing plot.
And, my information is relative to base R 1.6.1.  More recent versions
of R may have other function names, such as "levelplot".  Try the
help().

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Thu, 29 May 2003, Renaud Lancelot wrote:

> Dear all,
>
> I have computed a digital terrain model from a set of points (x, y, z)
> using the function interp() in package akima. I want to predict flooded
> surfaces given target values of z. I can display the flooded surfaces
> with contour() or image(), but I don't know how to get the polygons
> delimiting the surfaces. Did anyone write a function for this purpose ?
>
> Dr Renaud Lancelot, vtrinaire
> CIRAD, Dpartement Elevage et Mdecine Vtrinaire (CIRAD-Emvt)
> Programme Productions Animales
> http://www.cirad.fr/presentation/programmes/prod-ani.shtml
>
> ISRA-LNERV                      tel    (221) 832 49 02
> BP 2057 Dakar-Hann              fax    (221) 821 18 79 (CIRAD)
> Senegal                         e-mail renaud.lancelot at cirad.fr
>



From cp133 at york.ac.uk  Fri May 30 15:09:24 2003
From: cp133 at york.ac.uk (cp133)
Date: Fri, 30 May 2003 14:09:24 +0100
Subject: [R] bootstrapping data.frame and matrix
Message-ID: <3ED75804.972E40BE@york.ac.uk>

Dear All,

When bootstrapping a statistics based on more than one vector, from a
data.frame or a matrix object, it looks like I am not able to pass the
data to R. What am I doing wrong?
I use the library "bootstrap".
Here is an example with a data.frame called "data"


 "boot2_bootstrap(data, theta, nboot)

I get the following error message:

Error in inherits(x, "data.frame") : Argument "xdata" is missing, with
no default"


Please note that the same is happening when I create a matrix from the
data.frame with the function cbind
(i.e.  
names(data)
[1] "shortrate" "y1"        "y5"        "y10"       "y15"      
"y20"      
[7] "y25"      
xdata_cbind(data$y10,data$shortrate)
is.matrix(x.data)
TRUE)

Thanks in advance,

Chiara



From A.B.M.Crombach at exeter.ac.uk  Fri May 30 15:41:58 2003
From: A.B.M.Crombach at exeter.ac.uk (Anton Crombach)
Date: Fri, 30 May 2003 14:41:58 +0100
Subject: [R] Missing 'getGroupMembers()'
Message-ID: <3EDD4A8A@minerva.ex.ac.uk>

Hi,

I'm trying to write a method such that my own classes can be used with the 
groups like "Summary" and "Math", but when I tried to look for examples or 
just wanted to get an idea of which functions are the members of a group, I 
found out that the function "getGroupMembers" is not present... I couldn't 
find an alternative function, if there is one. Does anyone know a solution?

Anton



From Mike.Prager at noaa.gov  Fri May 30 16:17:45 2003
From: Mike.Prager at noaa.gov (Mike Prager)
Date: Fri, 30 May 2003 10:17:45 -0400
Subject: [R] Time for Usenet R Group?
Message-ID: <5.1.0.14.2.20030530101215.036286f0@hermes.nos.noaa.gov>

I probably shouldn't suggest this, because I can't volunteer to implement 
it.  However, I bring it up in the hopes that if (1) others agree and (2) 
the R core group think it a good idea that a suitable volunteer will come 
forward.

I am finding that the flood of R email messages is becoming difficult to 
deal with, even using filters, etc., in my email client.  Would we be 
better served by establishing a Usenet newsgroup?  Would that be practical 
or impractical?  Would it create problems for the maintainers of R?


-- 
Michael Prager      <Mike.Prager at noaa.gov>
NOAA Center for Coastal Fisheries and Habitat Research
Beaufort, North Carolina  28516  USA
http://shrimp.ccfhrb.noaa.gov/~mprager/

Standard Disclaimers:
* Opinions expressed here are personal and are not otherwise represented.
* Any use of tradenames does not constitute a NOAA or NMFS endorsement.



From rvaradha at jhsph.edu  Fri May 30 16:21:44 2003
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Fri, 30 May 2003 10:21:44 -0400
Subject: [R] Normal deviate generation - Marsaglia's ziggurat method
Message-ID: <59e9155a222e.5a222e59e915@jhsph.edu>

Hi:

I was wondering why Marsaglia's new ziggurat method for generating 
deviates from the standard normal distribution has not been implemented 
in the R base package. I know that it is available in SuppDists 
pacakage of Bob Wheeler, as "rziggurat". According my timing tests, it 
is about 6 to 7 times faster (on a Pentium 2.4 MHz) machine than the 
default Inversion method used in R base package. 

thanks,
Ravi.



From ripley at stats.ox.ac.uk  Fri May 30 16:30:58 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 30 May 2003 15:30:58 +0100 (BST)
Subject: [R] Missing 'getGroupMembers()'
In-Reply-To: <3EDD4A8A@minerva.ex.ac.uk>
Message-ID: <Pine.LNX.4.44.0305301522220.5831-100000@gannet.stats>

Do you want to write S3 or S4 methods for these groups?  Both systems have
groups with those names (and they are not the same). In either case, the
details are in ?.Methods (in current versions of R).


On Fri, 30 May 2003, Anton Crombach wrote:

> I'm trying to write a method such that my own classes can be used with the 
> groups like "Summary" and "Math", but when I tried to look for examples or 
> just wanted to get an idea of which functions are the members of a group, I 
> found out that the function "getGroupMembers" is not present... I couldn't 
> find an alternative function, if there is one. Does anyone know a solution?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From clists at perrin.socsci.unc.edu  Fri May 30 16:35:11 2003
From: clists at perrin.socsci.unc.edu (Andrew Perrin)
Date: Fri, 30 May 2003 10:35:11 -0400 (EDT)
Subject: [R] Error using glmmPQL
Message-ID: <Pine.LNX.4.53.0305301032200.11074@perrin.socsci.unc.edu>

Can anyone shed any light on this?

> doubt.demographic.pql<-glmmPQL(random = ~ 1 | groupid/participantid,
+                                fixed = r.info.doubt ~
+            realage + minority + female + education + income + scenario,
+                                data = fgdata.df[coded.resource,],
+                                na.action=na.omit,
+                                niter=50,
+                                family=binomial(link=probit))
iteration 1
iteration 2
iteration 3
iteration 4
iteration 5
iteration 6
iteration 7
iteration 8
Error in logLik.reStruct(object, conLin) :
        NA/NaN/Inf in foreign function call (arg 3)

The traceback() output is very long, so I won't post it, but you can see
it here:

http://www.unc.edu/~aperrin/stuff/diagnostics

Thanks,
Andy Perrin

----------------------------------------------------------------------
Andrew J Perrin - http://www.unc.edu/~aperrin
Assistant Professor of Sociology, U of North Carolina, Chapel Hill
clists at perrin.socsci.unc.edu * andrew_perrin (at) unc.edu



From hb at maths.lth.se  Fri May 30 16:40:23 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Fri, 30 May 2003 16:40:23 +0200
Subject: [R] How to check if a pipe was successfully opened or not?
Message-ID: <000501c326b9$67413dc0$e502eb82@alpha.wehi.edu.au>

Is there a way to detect if the opening of a connection to a pipe was
successful or not? Here are two examples

 # Works
 > con <- pipe("ls")
 > res <- open(con, open="r")
 > print(res)
 NULL

 # Does not work
 > con <- pipe("unknown_command")
 > res <- open(con, open="r")
 > 'unknown_command' is not recognized as an internal or external
command,
 operable program or batch file.
 > print(res)
 NULL

Can I make my script recognize/detect that the latter failed? try() will
not catch the error. The error message is not written to stdout so
sink() won't "catch" it either. Does anyone know of a (cross-platform)
way to test if "unknown_command" exists or not on the current system
before calling pipe()/open()? 

I'm running R v1.7.0 on WinXP.

Thanks

Henrik Bengtsson

Dept. of Mathematical Statistics @ Centre for Mathematical Sciences
Lund Institute of Technology/Lund University, Sweden 
(Sweden +2h UTC, Melbourne +10 UTC, Calif. -7h UTC)
+46 708 909208 (cell), +46 46 320 820 (home), 
+1 (508) 464 6644 (global fax),
+46 46 2229611 (off), +46 46 2224623 (dept. fax)
h b @ m a t h s . l t h . s e, http://www.maths.lth.se/~hb/



From A.B.M.Crombach at exeter.ac.uk  Fri May 30 16:37:41 2003
From: A.B.M.Crombach at exeter.ac.uk (Anton Crombach)
Date: Fri, 30 May 2003 15:37:41 +0100
Subject: [R] Missing 'getGroupMembers()'
Message-ID: <3EDD77EA@minerva.ex.ac.uk>

S4 methods, I'm using "Programming with data" (~ the green book) as my main 
reference for programming. Not everything is the same in R, usually that was 
not a problem, but using these groups I got a bit lost. I've been looking in 
the R docs of ?setGenerics, ?setGeneric and so on already.

>Do you want to write S3 or S4 methods for these groups?  Both systems have
>groups with those names (and they are not the same). In either case, the
>details are in ?.Methods (in current versions of R).
>
>
>On Fri, 30 May 2003, Anton Crombach wrote:
>
>> I'm trying to write a method such that my own classes can be used with the
>> groups like "Summary" and "Math", but when I tried to look for examples or
>> just wanted to get an idea of which functions are the members of a group, I
>> found out that the function "getGroupMembers" is not present... I couldn't
>> find an alternative function, if there is one. Does anyone know a solution?
>
>--
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From macq at llnl.gov  Fri May 30 16:47:53 2003
From: macq at llnl.gov (Don MacQueen)
Date: Fri, 30 May 2003 07:47:53 -0700
Subject: [R] Comparison Operator
In-Reply-To: <20030529232455.GA28990@sonny.eddelbuettel.com>
References: <363801FFD7B74240A329CEC3F7FE4CC409C83D@ntxboimbx07.micron.com>
	<20030529232455.GA28990@sonny.eddelbuettel.com>
Message-ID: <p05210600bafd1edd6aa0@[128.115.153.6]>

grep() by itself isn't quite right for this job:

>   a<-"Is a Fish"
>   b<-"aFish"
>   if (grep(b,a)) c<-TRUE
Error in if (grep(b, a)) c <- TRUE : argument is of length zero

-Don

At 6:24 PM -0500 5/29/03, Dirk Eddelbuettel wrote:
>On Thu, May 29, 2003 at 05:11:24PM -0600, mhoward at micron.com wrote:
>>  Does R have a comparison operator similar to the Like function, for example:
>>
>>  a<-"Is a Fish"
>>  b<-"Fish"
>>
>>  if(b in a){c<-TRUE}
>
>You probably want grep:
>
>  > a<-"Is a Fish"
>>  b<-"Fish"
>>  if (grep(b,a)) c<-TRUE
>  > c
>[1] TRUE
>
>Hth, Dirk
>
>--
>Don't drink and derive. Alcohol and analysis don't mix.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From ripley at stats.ox.ac.uk  Fri May 30 16:53:20 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 30 May 2003 15:53:20 +0100 (BST)
Subject: [R] Normal deviate generation - Marsaglia's ziggurat method
In-Reply-To: <59e9155a222e.5a222e59e915@jhsph.edu>
Message-ID: <Pine.LNX.4.44.0305301531390.5831-100000@gannet.stats>

Accuracy and reliability are more important than speed.

As you say, it is available elsewhere, but who actually needs a faster
method?  1 million normals take 0.55s on my machine (an Athlon 2600): 1
million uniforms take 0.16s, so there is not I think scope to be `6 to 7
times faster' at R level.  rziggurat takes 0.51s on the same machine,
despite saying

     This implementation running in R is approximately three times as
     fast as rnorm().

So I checked some other machines
		runif	rnorm	rziggurat
2.4Ghz P4	0.33	1.30	0.37
1GHz PIII	0.40	1.47	0.94
Athlon 2600	0.16	0.55	0.51

There's something rather strange about the P4 results relative to the
others, possibly due to cache sizes.  (Linux RH7.3 for the first two,
RH8.0 for the last, and the same compiled code running on each.)

My point remains: who wants 1 million random uniforms and wants to save 
fractions of a second?


Also, I was wondering why some people expect R to provide exactly what
they fancy, free of charge?


On Fri, 30 May 2003, Ravi Varadhan wrote:

> I was wondering why Marsaglia's new ziggurat method for generating 
> deviates from the standard normal distribution has not been implemented 
> in the R base package. I know that it is available in SuppDists 
> pacakage of Bob Wheeler, as "rziggurat". According my timing tests, it 
> is about 6 to 7 times faster (on a Pentium 2.4 MHz) machine than the 
> default Inversion method used in R base package. 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From feldesmanm at pdx.edu  Fri May 30 17:00:32 2003
From: feldesmanm at pdx.edu (Marc R. Feldesman)
Date: Fri, 30 May 2003 08:00:32 -0700
Subject: [R] Time for Usenet R Group?
In-Reply-To: <5.1.0.14.2.20030530101215.036286f0@hermes.nos.noaa.gov>
Message-ID: <5.2.0.9.2.20030530075203.01c3cfe8@pop4.attglobal.net>

At 07:17 AM 5/30/2003, Mike Prager wrote:
 >I probably shouldn't suggest this, because I can't volunteer to implement
 >it.  However, I bring it up in the hopes that if (1) others agree and (2)
 >the R core group think it a good idea that a suitable volunteer will come
 >forward.
 >
 >I am finding that the flood of R email messages is becoming difficult to
 >deal with, even using filters, etc., in my email client.  Would we be
 >better served by establishing a Usenet newsgroup?  Would that be practical
 >or impractical?  Would it create problems for the maintainers of R?
 >


I agree with you on the "flood" of messages lately.  Often this flood 
accompanies a new release, but this flood has continued unabated for longer 
than I would have imagined.  The good news is that R is becoming more 
popular and this (hopefully) attracts more developers, which results in 
more libraries, etc.  The bad news is that with more users come more questions.

The problem I see with a Usenet group is that unless it is moderated, the 
ratio of noise to signal is quite high and flame wars erupt, spam bots 
scour for new email addresses to plague and the war merely 
escalates.  There are two problems with moderation:  1) someone has to 
moderate the group; 2) someone has to inform users of inappropriate posts - 
maybe; and 3) the message delay would be intolerable to those accustomed to 
the near instant feedback we are privileged to get with the superb list we 
have now.  One alternative to a Usenet newsgroup would be something along 
the lines of SourceForge's discussion boards.  At least this requires the 
project to be registered and the group be accessible via a web-interface.

Personally, I don't find it a huge burden to go through and filter messages 
by topics that interest me at the moment.  I move all the other R related 
posts to my own archive and, if I need something not personally archived, I 
have other sources to get them from.

Have you considered getting the messages in digest form?



From mhoward at micron.com  Fri May 30 17:00:03 2003
From: mhoward at micron.com (mhoward@micron.com)
Date: Fri, 30 May 2003 09:00:03 -0600
Subject: [R] Comparison Operator
Message-ID: <363801FFD7B74240A329CEC3F7FE4CC409C83E@ntxboimbx07.micron.com>

OK, regexpr gets me what I needed, thanks to all..

One more thing, say I have a Table like:

0 RAW1 RAW2 RAW3 AVE1 AVE2 AVE3
1   1   2    5    2.3  1.2  4.5
2   0   3    6    1.7  2.2  3.5
3   3   1    6    0.1  3.9  1.6


and I want to create a sub table that only has the RAW columns.
Problem is I won't know what the column names will be, only that
they either contain "RAW" or "AVE" and they may not be grouped
together.

Mike


-----Original Message-----
From: Don MacQueen [mailto:macq at llnl.gov]
Sent: Friday, May 30, 2003 8:48 AM
To: Dirk Eddelbuettel; mhoward
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Comparison Operator


grep() by itself isn't quite right for this job:

>   a<-"Is a Fish"
>   b<-"aFish"
>   if (grep(b,a)) c<-TRUE
Error in if (grep(b, a)) c <- TRUE : argument is of length zero

-Don

At 6:24 PM -0500 5/29/03, Dirk Eddelbuettel wrote:
>On Thu, May 29, 2003 at 05:11:24PM -0600, mhoward at micron.com wrote:
>>  Does R have a comparison operator similar to the Like function, for example:
>>
>>  a<-"Is a Fish"
>>  b<-"Fish"
>>
>>  if(b in a){c<-TRUE}
>
>You probably want grep:
>
>  > a<-"Is a Fish"
>>  b<-"Fish"
>>  if (grep(b,a)) c<-TRUE
>  > c
>[1] TRUE
>
>Hth, Dirk
>
>--
>Don't drink and derive. Alcohol and analysis don't mix.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From ripley at stats.ox.ac.uk  Fri May 30 17:02:59 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 30 May 2003 16:02:59 +0100 (BST)
Subject: [R] Error using glmmPQL
In-Reply-To: <Pine.LNX.4.53.0305301032200.11074@perrin.socsci.unc.edu>
Message-ID: <Pine.LNX.4.44.0305301601470.5831-100000@gannet.stats>

lme does this (and that is from lme) sometimes -- often when the model 
does not fit well.

On Fri, 30 May 2003, Andrew Perrin wrote:

> Can anyone shed any light on this?
> 
> > doubt.demographic.pql<-glmmPQL(random = ~ 1 | groupid/participantid,
> +                                fixed = r.info.doubt ~
> +            realage + minority + female + education + income + scenario,
> +                                data = fgdata.df[coded.resource,],
> +                                na.action=na.omit,
> +                                niter=50,
> +                                family=binomial(link=probit))
> iteration 1
> iteration 2
> iteration 3
> iteration 4
> iteration 5
> iteration 6
> iteration 7
> iteration 8
> Error in logLik.reStruct(object, conLin) :
>         NA/NaN/Inf in foreign function call (arg 3)
> 
> The traceback() output is very long, so I won't post it, but you can see
> it here:
> 
> http://www.unc.edu/~aperrin/stuff/diagnostics

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From kamimura at carpa.ciagri.usp.br  Fri May 30 16:55:04 2003
From: kamimura at carpa.ciagri.usp.br (Danilo Tadashi Tagami Kamimura)
Date: Fri, 30 May 2003 11:55:04 -0300
Subject: [R] conversao para matriz
In-Reply-To: <mailman.0.1054304685.24066.r-help@stat.math.ethz.ch>
Message-ID: <200305301527.h4UFRtu9023012@hypatia.math.ethz.ch>

ol?,
estou tentando converter a vari?vel b (abaixo) em uma matriz com duas
colunas, sem muito sucesso, algu?m teria alguma sugest?o?

muito obrigado,

a<-outer(1:5,1:7,FUN="paste")
b<- sample(a,10)
 [1] "4 2" "5 7" "3 3" "4 1" "4 5" "3 5" "5 2" "2 1" "3 7" "1 4"

Matriz desejada:

 4   2
 5   7
 ......
 3  7
 1  4 

__________________________________
        Danilo Tadashi Tagami Kamimura
   Engenharia Agron?mica   ESALQ   USP
<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>



From ripley at stats.ox.ac.uk  Fri May 30 17:28:53 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 30 May 2003 16:28:53 +0100 (BST)
Subject: [R] How to check if a pipe was successfully opened or not?
In-Reply-To: <000501c326b9$67413dc0$e502eb82@alpha.wehi.edu.au>
Message-ID: <Pine.LNX.4.44.0305301613300.5956-100000@gannet.stats>

On Fri, 30 May 2003, Henrik Bengtsson wrote:

> Is there a way to detect if the opening of a connection to a pipe was
> successful or not? Here are two examples
> 
>  # Works
>  > con <- pipe("ls")
>  > res <- open(con, open="r")
>  > print(res)
>  NULL
> 
>  # Does not work
>  > con <- pipe("unknown_command")
>  > res <- open(con, open="r")
>  > 'unknown_command' is not recognized as an internal or external
> command,
>  operable program or batch file.
>  > print(res)
>  NULL

open() always returns NULL.

> Can I make my script recognize/detect that the latter failed? try() will
> not catch the error. The error message is not written to stdout so
> sink() won't "catch" it either. Does anyone know of a (cross-platform)
> way to test if "unknown_command" exists or not on the current system
> before calling pipe()/open()? 
> 
> I'm running R v1.7.0 on WinXP.

The C code called by open() has

    fp = popen(con->description, mode);
    if(!fp) {
	warning("cannot open cmd `%s'", con->description);
	return FALSE;
    }

so presumably your system's popen is returning a FILE stream even though 
the command cannot be opened.  Not much we can do about that.  Solaris 
says

    The popen() function returns a null pointer if files or
    processes cannot be created.

but I think the problem is that the `process' is that launching the shell, 
not that of the command.  I am not using Windows, so cannot check there.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mhoward at micron.com  Fri May 30 17:43:23 2003
From: mhoward at micron.com (mhoward@micron.com)
Date: Fri, 30 May 2003 09:43:23 -0600
Subject: [R] Comparison Operator
Message-ID: <363801FFD7B74240A329CEC3F7FE4CC409C83F@ntxboimbx07.micron.com>

Thanks Rolf and J.R. both of these solutions worked for me and
thanks to all the others for your suggestions, I was able to 
accomplish what I needed.


xx <- df[,grep('RAW',names(df))]
xxx <- df[,regexpr('RAW',names(df)) > 0]



Mike

-----Original Message-----
From: mhoward 
Sent: Friday, May 30, 2003 9:00 AM
To: 'Don MacQueen'; Dirk Eddelbuettel
Cc: r-help at stat.math.ethz.ch
Subject: RE: [R] Comparison Operator


OK, regexpr gets me what I needed, thanks to all..

One more thing, say I have a Table like:

0 RAW1 RAW2 RAW3 AVE1 AVE2 AVE3
1   1   2    5    2.3  1.2  4.5
2   0   3    6    1.7  2.2  3.5
3   3   1    6    0.1  3.9  1.6


and I want to create a sub table that only has the RAW columns.
Problem is I won't know what the column names will be, only that
they either contain "RAW" or "AVE" and they may not be grouped
together.

Mike


-----Original Message-----
From: Don MacQueen [mailto:macq at llnl.gov]
Sent: Friday, May 30, 2003 8:48 AM
To: Dirk Eddelbuettel; mhoward
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Comparison Operator


grep() by itself isn't quite right for this job:

>   a<-"Is a Fish"
>   b<-"aFish"
>   if (grep(b,a)) c<-TRUE
Error in if (grep(b, a)) c <- TRUE : argument is of length zero

-Don

At 6:24 PM -0500 5/29/03, Dirk Eddelbuettel wrote:
>On Thu, May 29, 2003 at 05:11:24PM -0600, mhoward at micron.com wrote:
>>  Does R have a comparison operator similar to the Like function, for example:
>>
>>  a<-"Is a Fish"
>>  b<-"Fish"
>>
>>  if(b in a){c<-TRUE}
>
>You probably want grep:
>
>  > a<-"Is a Fish"
>>  b<-"Fish"
>>  if (grep(b,a)) c<-TRUE
>  > c
>[1] TRUE
>
>Hth, Dirk
>
>--
>Don't drink and derive. Alcohol and analysis don't mix.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From spencer.graves at pdf.com  Fri May 30 17:51:03 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 30 May 2003 08:51:03 -0700
Subject: [R] conversao para matriz
References: <200305301527.h4UFRtu9023012@hypatia.math.ethz.ch>
Message-ID: <3ED77DE7.2030508@pdf.com>

Have you considered "regexpr" and "substr" or "substring"?

hth.  spencer graves

Danilo Tadashi Tagami Kamimura wrote:
> ol?,
> estou tentando converter a vari?vel b (abaixo) em uma matriz com duas
> colunas, sem muito sucesso, algu?m teria alguma sugest?o?
> 
> muito obrigado,
> 
> a<-outer(1:5,1:7,FUN="paste")
> b<- sample(a,10)
>  [1] "4 2" "5 7" "3 3" "4 1" "4 5" "3 5" "5 2" "2 1" "3 7" "1 4"
> 
> Matriz desejada:
> 
>  4   2
>  5   7
>  ......
>  3  7
>  1  4 
> 
> __________________________________
>         Danilo Tadashi Tagami Kamimura
>    Engenharia Agron?mica   ESALQ   USP
> <<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From mmarques at power.inescn.pt  Fri May 30 17:51:07 2003
From: mmarques at power.inescn.pt (Mark Marques)
Date: Fri, 30 May 2003 16:51:07 +0100
Subject: [R] How to remove a complete dataframe column
Message-ID: <114104136437.20030530165107@power.inescn.pt>


I am using dataframes and I and I want to delete (remove) a specific
column by name ...
the data frame has 14 columns with several names and only need some.
I tried to overwrite the columns with a single value but that in not very
clean as I need to export the data to file.
The rm command gives me a warning message stating :
< remove: variable "rtu$Ri." was not found >
or there is another method to remove parts of a dataframe?
thanks in advance
Mark Marques



From rossini at blindglobe.net  Fri May 30 17:22:20 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Fri, 30 May 2003 08:22:20 -0700
Subject: [R] Time for Usenet R Group?
In-Reply-To: <5.1.0.14.2.20030530101215.036286f0@hermes.nos.noaa.gov> (Mike
	Prager's message of "Fri, 30 May 2003 10:17:45 -0400")
References: <5.1.0.14.2.20030530101215.036286f0@hermes.nos.noaa.gov>
Message-ID: <87isrscvdf.fsf@jeeves.blindglobe.net>

"Mike Prager" <Mike.Prager at noaa.gov> writes:

> I am finding that the flood of R email messages is becoming difficult
> to deal with, even using filters, etc., in my email client.  Would we
> be better served by establishing a Usenet newsgroup?  Would that be
> practical or impractical?  Would it create problems for the
> maintainers of R?

everything is possible -- but you should ask whether the people you'd
like to be on the newsgroup would follow, and perhaps if it isn't just
a matter of modifying email client/usage of email work habits.  

For me, it's mostly a matter of permanently sorting/scoring on a few
key people (r-core and 7 others) and temporarily sorting/scoring on
interesting threads/topics, and that seems to take care of 95% of the
information I'm looking for (i.e. orders the mail to read, when I
want/need/etc to read), the rest ending up in an
end-of-the-day/week/month mailbox/folder to peruse later.  But your
needs might be different.

best,
-tony

-- 
A.J. Rossini  /  rossini at u.washington.edu  /  rossini at scharp.org
Biomedical/Health Informatics and Biostatistics, University of Washington.
Biostatistics, HVTN/SCHARP, Fred Hutchinson Cancer Research Center.
FHCRC: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email 

CONFIDENTIALITY NOTICE: This e-mail message and any attachments ... {{dropped}}



From ligges at statistik.uni-dortmund.de  Fri May 30 17:58:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 30 May 2003 17:58:03 +0200
Subject: [R] conversao para matriz
In-Reply-To: <200305301527.h4UFRtu9023012@hypatia.math.ethz.ch>
References: <200305301527.h4UFRtu9023012@hypatia.math.ethz.ch>
Message-ID: <3ED77F8B.7060606@statistik.uni-dortmund.de>

Danilo Tadashi Tagami Kamimura wrote:
> ol?,
> estou tentando converter a vari?vel b (abaixo) em uma matriz com duas
> colunas, sem muito sucesso, algu?m teria alguma sugest?o?
> 
> muito obrigado,
> 
> a<-outer(1:5,1:7,FUN="paste")
> b<- sample(a,10)
>  [1] "4 2" "5 7" "3 3" "4 1" "4 5" "3 5" "5 2" "2 1" "3 7" "1 4"
> 
> Matriz desejada:
> 
>  4   2
>  5   7
>  ......
>  3  7
>  1  4 
> 

On this list in english, please.
I guess you are going to do something like

   matrix(as.numeric(unlist(strsplit(b, " "))), ncol = 2, byrow = TRUE)

[I don't get the point why you use a character vector for those values.]

Uwe Ligges



From ripley at stats.ox.ac.uk  Fri May 30 18:10:15 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 30 May 2003 17:10:15 +0100 (BST)
Subject: [R] How to remove a complete dataframe column
In-Reply-To: <114104136437.20030530165107@power.inescn.pt>
Message-ID: <Pine.LNX.4.44.0305301706480.8311-100000@gannet.stats>

On Fri, 30 May 2003, Mark Marques wrote:

> I am using dataframes and I and I want to delete (remove) a specific
> column by name ...
> the data frame has 14 columns with several names and only need some.
> I tried to overwrite the columns with a single value but that in not very
> clean as I need to export the data to file.
> The rm command gives me a warning message stating :
> < remove: variable "rtu$Ri." was not found >
> or there is another method to remove parts of a dataframe?

You make a copy selecting the names you want, as in

rtu2 <- rtu[!(names(rtu) %in% c("Ri", "another I do not want"))]

or

rtu3 <- rtu[c("var2", "var7")]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From roebuck at odin.mdacc.tmc.edu  Fri May 30 18:30:48 2003
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Fri, 30 May 2003 11:30:48 -0500 (CDT)
Subject: [R] [Q] R equivalent for Splus get.message()
Message-ID: <Pine.OSF.4.33.0305301124320.97333-100000@odin.mdacc.tmc.edu>

I'm trying to get a translation of some Splus code going.
My problem is with the S-plus get.message() function not
existing in R. Is there a replacement or alternative?

ErrorHandler.func<-function()
{
    cat("app.terminated\n");
    cat(paste("err.fatal",get.message(),"\n",sep=""));
    dump.calls();
}
options(error=ErrorHandler.func)

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From mt at michaelltaylor.com  Fri May 30 18:34:48 2003
From: mt at michaelltaylor.com (michaell taylor)
Date: Fri, 30 May 2003 16:34:48 -0000
Subject: [R] How to remove a complete dataframe column
In-Reply-To: <114104136437.20030530165107@power.inescn.pt>
References: <114104136437.20030530165107@power.inescn.pt>
Message-ID: <1054312474.20808.41.camel@xeon>


or, if you no longer want the columns and don't want to create more
objects, you could:

rtu$Ri <- NULL

On Fri, 2003-05-30 at 11:51, Mark Marques wrote:
> 
> I am using dataframes and I and I want to delete (remove) a specific
> column by name ...
> the data frame has 14 columns with several names and only need some.
> I tried to overwrite the columns with a single value but that in not very
> clean as I need to export the data to file.
> The rm command gives me a warning message stating :
> < remove: variable "rtu$Ri." was not found >
> or there is another method to remove parts of a dataframe?
> thanks in advance
> Mark Marques
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From brahm at alum.mit.edu  Fri May 30 18:44:55 2003
From: brahm at alum.mit.edu (David Brahm)
Date: Fri, 30 May 2003 12:44:55 -0400
Subject: [R] R CMD BATCH --vanilla --slave produces unwanted lines
References: <200305292127.h4TLRqdC001093@r.hankin.sges.auckland.ac.nz>
Message-ID: <16087.35463.328197.92844@arbres1a.fmr.com>

Robin Hankin <r.hankin at auckland.ac.nz> wrote:

> Anyway, now I'm trying to run R in batch mode, but I'm getting extra
> output, which I don't want (RedHat 8.3, R-1.7.0):
...
> r:~% R CMD BATCH --vanilla --slave test.R

Why not just run:
unix> R --vanilla --slave < test.R > test.out

Then the "options(echo=FALSE)" line is unnecessary.  Note an explicit q()
at the end of the script eliminates a single blank line that occurs otherwise.
So the test.R script is just:

  write(rnorm(4),"")
  q()

-- 
                              -- David Brahm (brahm at alum.mit.edu)



From ripley at stats.ox.ac.uk  Fri May 30 18:51:39 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 30 May 2003 17:51:39 +0100 (BST)
Subject: [R] [Q] R equivalent for Splus get.message()
In-Reply-To: <Pine.OSF.4.33.0305301124320.97333-100000@odin.mdacc.tmc.edu>
Message-ID: <Pine.LNX.4.44.0305301747310.8509-100000@gannet.stats>

Are you looking for geterrmessage()?

I think an error handler should be writing to stderr(), BTW, but normally 
the R error message will already have been written there.

On Fri, 30 May 2003, Paul Roebuck wrote:

> I'm trying to get a translation of some Splus code going.
> My problem is with the S-plus get.message() function not
> existing in R. Is there a replacement or alternative?
> 
> ErrorHandler.func<-function()
> {
>     cat("app.terminated\n");
>     cat(paste("err.fatal",get.message(),"\n",sep=""));
>     dump.calls();
> }
> options(error=ErrorHandler.func)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rpeng at stat.ucla.edu  Fri May 30 19:10:10 2003
From: rpeng at stat.ucla.edu (Roger D. Peng)
Date: Fri, 30 May 2003 10:10:10 -0700
Subject: [R] bootstrapping data.frame and matrix
In-Reply-To: <3ED75804.972E40BE@york.ac.uk>
References: <3ED75804.972E40BE@york.ac.uk>
Message-ID: <3ED79072.1040708@stat.ucla.edu>

The help page for `bootstrap' says that to bootstrap more complex 
statistics (it gives an example for the correlation), you need to 
bootstrap the (row) indices of the data frame and not the data frame 
itself.  By the way, you appear to have the order of the arguments to 
bootstrap() incorrect but I guess this is a typo?

In general, I would suggest using the `boot' package from CRAN (along 
with the Davison & Hinckley book) instead of the `bootstrap' package. 
`boot' can work neatly on more general data structures and also uses the 
trick of bootstrapping the indices of the data rather than the data 
themselves.

Also, it appears you are using an old version of R because the the "_" 
operator is deprecated in the current version (1.7.0).

-roger

cp133 wrote:
> Dear All,
> 
> When bootstrapping a statistics based on more than one vector, from a
> data.frame or a matrix object, it looks like I am not able to pass the
> data to R. What am I doing wrong?
> I use the library "bootstrap".
> Here is an example with a data.frame called "data"
> 
> 
>  "boot2_bootstrap(data, theta, nboot)
> 
> I get the following error message:
> 
> Error in inherits(x, "data.frame") : Argument "xdata" is missing, with
> no default"
> 
> 
> Please note that the same is happening when I create a matrix from the
> data.frame with the function cbind
> (i.e.  
> names(data)
> [1] "shortrate" "y1"        "y5"        "y10"       "y15"      
> "y20"      
> [7] "y25"      
> xdata_cbind(data$y10,data$shortrate)
> is.matrix(x.data)
> TRUE)
> 
> Thanks in advance,
> 
> Chiara
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
>



From rpeng at stat.ucla.edu  Fri May 30 19:16:34 2003
From: rpeng at stat.ucla.edu (Roger D. Peng)
Date: Fri, 30 May 2003 10:16:34 -0700
Subject: [R] Normal deviate generation - Marsaglia's ziggurat method
In-Reply-To: <59e9155a222e.5a222e59e915@jhsph.edu>
References: <59e9155a222e.5a222e59e915@jhsph.edu>
Message-ID: <3ED791F2.4030503@stat.ucla.edu>

Since it is available in the `SuppDists' package, why do we need it in 
the `base' package?  There are perhaps hundreds of useful functions that 
exist in external packages that are not in `base'.  My understanding was 
that one goal was to keep `base' from getting too bloated.

-roger


Ravi Varadhan wrote:

> Hi:
> 
> I was wondering why Marsaglia's new ziggurat method for generating 
> deviates from the standard normal distribution has not been implemented 
> in the R base package. I know that it is available in SuppDists 
> pacakage of Bob Wheeler, as "rziggurat". According my timing tests, it 
> is about 6 to 7 times faster (on a Pentium 2.4 MHz) machine than the 
> default Inversion method used in R base package. 
> 
> thanks,
> Ravi.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
>



From cp133 at york.ac.uk  Fri May 30 19:28:26 2003
From: cp133 at york.ac.uk (chiara peroni)
Date: Fri, 30 May 2003 18:28:26 +0100
Subject: [R] bootstrapping data.frame and matrix
References: <3ED75804.972E40BE@york.ac.uk> <3ED79072.1040708@stat.ucla.edu>
Message-ID: <3ED794BA.D5047629@york.ac.uk>


Hi,

I use an old version of R (5.02). The reason I do not use the package
boot on the last version of R, is the clash of the package itself with
expressions contained in other packages, i.e. the"sm " library. I don't
know if you have the same problem.

Thank you!

Chiara

"Roger D. Peng" wrote:
> 
> The help page for `bootstrap' says that to bootstrap more complex
> statistics (it gives an example for the correlation), you need to
> bootstrap the (row) indices of the data frame and not the data frame
> itself.  By the way, you appear to have the order of the arguments to
> bootstrap() incorrect but I guess this is a typo?
> 
> In general, I would suggest using the `boot' package from CRAN (along
> with the Davison & Hinckley book) instead of the `bootstrap' package.
> `boot' can work neatly on more general data structures and also uses the
> trick of bootstrapping the indices of the data rather than the data
> themselves.
> 
> Also, it appears you are using an old version of R because the the "_"
> operator is deprecated in the current version (1.7.0).
> 
> -roger
> 
> cp133 wrote:
> > Dear All,
> >
> > When bootstrapping a statistics based on more than one vector, from a
> > data.frame or a matrix object, it looks like I am not able to pass the
> > data to R. What am I doing wrong?
> > I use the library "bootstrap".
> > Here is an example with a data.frame called "data"
> >
> >
> >  "boot2_bootstrap(data, theta, nboot)
> >
> > I get the following error message:
> >
> > Error in inherits(x, "data.frame") : Argument "xdata" is missing, with
> > no default"
> >
> >
> > Please note that the same is happening when I create a matrix from the
> > data.frame with the function cbind
> > (i.e.
> > names(data)
> > [1] "shortrate" "y1"        "y5"        "y10"       "y15"
> > "y20"
> > [7] "y25"
> > xdata_cbind(data$y10,data$shortrate)
> > is.matrix(x.data)
> > TRUE)
> >
> > Thanks in advance,
> >
> > Chiara
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> >



From ripley at stats.ox.ac.uk  Fri May 30 19:38:39 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 30 May 2003 18:38:39 +0100 (BST)
Subject: [R] bootstrapping data.frame and matrix
In-Reply-To: <3ED794BA.D5047629@york.ac.uk>
Message-ID: <Pine.LNX.4.44.0305301836280.8652-100000@gannet.stats>

On Fri, 30 May 2003, chiara peroni wrote:

> I use an old version of R (5.02). The reason I do not use the package
> boot on the last version of R, is the clash of the package itself with
> expressions contained in other packages, i.e. the"sm " library. I don't
> know if you have the same problem.

Hi Chiara,

I am the maintainer of both, and they have never clashed to my knowledge.
Please let me know (off the list) what problems you are finding.

Brian

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rpeng at stat.ucla.edu  Fri May 30 19:50:03 2003
From: rpeng at stat.ucla.edu (Roger D. Peng)
Date: Fri, 30 May 2003 10:50:03 -0700
Subject: [R] Time for Usenet R Group?
In-Reply-To: <5.2.0.9.2.20030530075203.01c3cfe8@pop4.attglobal.net>
References: <5.2.0.9.2.20030530075203.01c3cfe8@pop4.attglobal.net>
Message-ID: <3ED799CB.1090602@stat.ucla.edu>

Marc R. Feldesman wrote:

> I agree with you on the "flood" of messages lately.  Often this flood 
> accompanies a new release, but this flood has continued unabated for 
> longer than I would have imagined.  The good news is that R is becoming 
> more popular and this (hopefully) attracts more developers, which 
> results in more libraries, etc.  The bad news is that with more users 
> come more questions.

I don't consider that "bad news".  That's just "how it is".  As far as I 
can see, it's all good news :)

Personally, I prefer having the email list with the individual messages 
(rather than the digest) because I check email frequently and can catch 
things as they come in.  If the list moved to Usenet or a web forum, I 
doubt I would check the list as frequently, if ever.

-roger



From hdoran at nasdc.org  Fri May 30 19:55:14 2003
From: hdoran at nasdc.org (Harold Doran)
Date: Fri, 30 May 2003 13:55:14 -0400
Subject: [R] Sparse Matrix
Message-ID: <66578BFC0BA55348B5907A0F798EE93029E736@ernesto.NASDC.ORG>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030530/f0727cdc/attachment.pl

From Huiqin.Yang at noaa.gov  Fri May 30 20:48:59 2003
From: Huiqin.Yang at noaa.gov (Huiqin Yang)
Date: Fri, 30 May 2003 14:48:59 -0400
Subject: [R] how to install a package of my own functions
Message-ID: <3ED7A79B.A69E7AB3@noaa.gov>

Hi everyone,

  Does anyone know how to get the functions we've made to work as a package? 

> version
         _                   
platform sparc-sun-solaris2.9
arch     sparc               
os       solaris2.9          
system   sparc, solaris2.9   
status                       
major    1                   
minor    7.0                 
year     2003                
month    04                  
day      16                  
language R    

  Thanks a lot.

Helen



From rpeng at stat.ucla.edu  Fri May 30 21:05:00 2003
From: rpeng at stat.ucla.edu (Roger D. Peng)
Date: Fri, 30 May 2003 12:05:00 -0700
Subject: [R] how to install a package of my own functions
In-Reply-To: <3ED7A79B.A69E7AB3@noaa.gov>
References: <3ED7A79B.A69E7AB3@noaa.gov>
Message-ID: <3ED7AB5C.905@stat.ucla.edu>

See the PDF manual "Writing R Extensions" from the CRAN website.

-roger

Huiqin Yang wrote:

> Hi everyone,
> 
>   Does anyone know how to get the functions we've made to work as a package? 
> 
> 
>>version
> 
>          _                   
> platform sparc-sun-solaris2.9
> arch     sparc               
> os       solaris2.9          
> system   sparc, solaris2.9   
> status                       
> major    1                   
> minor    7.0                 
> year     2003                
> month    04                  
> day      16                  
> language R    
> 
>   Thanks a lot.
> 
> Helen
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
>



From clists at perrin.socsci.unc.edu  Fri May 30 21:28:49 2003
From: clists at perrin.socsci.unc.edu (Andrew Perrin)
Date: Fri, 30 May 2003 15:28:49 -0400 (EDT)
Subject: [R] Error using glmmPQL
In-Reply-To: <Pine.LNX.4.44.0305301601470.5831-100000@gannet.stats>
References: <Pine.LNX.4.44.0305301601470.5831-100000@gannet.stats>
Message-ID: <Pine.LNX.4.53.0305301528470.11074@perrin.socsci.unc.edu>

Thanks.

----------------------------------------------------------------------
Andrew J Perrin - http://www.unc.edu/~aperrin
Assistant Professor of Sociology, U of North Carolina, Chapel Hill
clists at perrin.socsci.unc.edu * andrew_perrin (at) unc.edu


On Fri, 30 May 2003, Prof Brian Ripley wrote:

> lme does this (and that is from lme) sometimes -- often when the model
> does not fit well.
>
> On Fri, 30 May 2003, Andrew Perrin wrote:
>
> > Can anyone shed any light on this?
> >
> > > doubt.demographic.pql<-glmmPQL(random = ~ 1 | groupid/participantid,
> > +                                fixed = r.info.doubt ~
> > +            realage + minority + female + education + income + scenario,
> > +                                data = fgdata.df[coded.resource,],
> > +                                na.action=na.omit,
> > +                                niter=50,
> > +                                family=binomial(link=probit))
> > iteration 1
> > iteration 2
> > iteration 3
> > iteration 4
> > iteration 5
> > iteration 6
> > iteration 7
> > iteration 8
> > Error in logLik.reStruct(object, conLin) :
> >         NA/NaN/Inf in foreign function call (arg 3)
> >
> > The traceback() output is very long, so I won't post it, but you can see
> > it here:
> >
> > http://www.unc.edu/~aperrin/stuff/diagnostics
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From jawegelin at ucdavis.edu  Fri May 30 21:37:29 2003
From: jawegelin at ucdavis.edu (Jacob Wegelin)
Date: Fri, 30 May 2003 12:37:29 -0700 (PDT)
Subject: [R] color in plot title: title(sub="something", col=4)
Message-ID: <Pine.GSO.4.44.0305301127490.24873-100000@vici.ucdavis.edu>


Is there a way to specify the color of the main title, the subtitle, or
the axis labels?  I mean, for instance, something like

title(main="cougar", col=2)

For me, the above command produces the color black; that is, the "col"
argument has no effect.

I'm on a Windows 2000 machine with

> version
         _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    5.0
year     2002
month    04
day      29
language R

Thanks for any advice

Jake

Jacob A. Wegelin, Ph.D.
Adjunct Assistant Professor
Epidemiology and Preventive Medicine, Univ. California
One Shields Ave, TB-168
Davis CA 95616-8638 USA
TEL 530.752.2793
FAX 530.752.3239
http://wegelin.ucdavis.edu/
jawegelin at ucdavis.edu



From Charles.White at NA.AMEDD.ARMY.MIL  Fri May 30 21:38:56 2003
From: Charles.White at NA.AMEDD.ARMY.MIL (White, Charles E WRAIR-Wash DC)
Date: Fri, 30 May 2003 15:38:56 -0400
Subject: [R] Extracting Vectors from Lists of Lists Produced by Functions
Message-ID: <12D0D00E1404D511A4820090274CA09C02FC059F@dasmtyjqf010.amedd.army.mil>

If you found my subject heading to be confusing then I'm sure you'll enjoy
the example I've included below. I find the apply type functions to be
wonderful for avoiding loops but when I use them with existing functions, I
end up using loops anyway to extract the vectors I want. I would appreciate
it if someone could show me how to avoid these loops. Thanks.

EXAMPLE: 
noise<-matrix(data = rnorm(15, mean=0, sd=1), nrow = 5, ncol = 3,
              byrow = FALSE, dimnames = NULL)
measure<-apply(noise,2,t.test)
measure
tval<-NULL
df<-NULL
pval<-NULL
for (i in 1:length(measure)){
  tval[i]<-measure[[i]][[1]]
  df[i]<-measure[[i]][[2]]
  pval[i]<-measure[[i]][[3]]}
data.frame(tval,df,pval)

Charles E. White, Biostatistician
Walter Reed Army Institute of Research
503 Robert Grant Ave., Room 1w102
Silver Spring, MD 20910-1557
301 319-9781
WRAIR Home Page: http://wrair-www.army.mil/



From sundar.dorai-raj at pdf.com  Fri May 30 21:53:46 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Fri, 30 May 2003 12:53:46 -0700
Subject: [R] Extracting Vectors from Lists of Lists Produced by Functions
References: <12D0D00E1404D511A4820090274CA09C02FC059F@dasmtyjqf010.amedd.army.mil>
Message-ID: <3ED7B6CA.4090200@pdf.com>



White, Charles E WRAIR-Wash DC wrote:
> If you found my subject heading to be confusing then I'm sure you'll enjoy
> the example I've included below. I find the apply type functions to be
> wonderful for avoiding loops but when I use them with existing functions, I
> end up using loops anyway to extract the vectors I want. I would appreciate
> it if someone could show me how to avoid these loops. Thanks.
> 
> EXAMPLE: 
> noise<-matrix(data = rnorm(15, mean=0, sd=1), nrow = 5, ncol = 3,
>               byrow = FALSE, dimnames = NULL)
> measure<-apply(noise,2,t.test)
> measure
> tval<-NULL
> df<-NULL
> pval<-NULL
> for (i in 1:length(measure)){
>   tval[i]<-measure[[i]][[1]]
>   df[i]<-measure[[i]][[2]]
>   pval[i]<-measure[[i]][[3]]}
> data.frame(tval,df,pval)
> 
> Charles E. White, Biostatistician
> Walter Reed Army Institute of Research
> 503 Robert Grant Ave., Room 1w102
> Silver Spring, MD 20910-1557
> 301 319-9781
> WRAIR Home Page: http://wrair-www.army.mil/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

Charles,

Use a data.frame and sapply instead.

sapply(as.data.frame(noise), function(x) t.test(x)[1:3])

Sundar



From sundar.dorai-raj at pdf.com  Fri May 30 21:55:23 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Fri, 30 May 2003 12:55:23 -0700
Subject: [R] color in plot title: title(sub="something", col=4)
References: <Pine.GSO.4.44.0305301127490.24873-100000@vici.ucdavis.edu>
Message-ID: <3ED7B72B.1000503@pdf.com>



Jacob Wegelin wrote:
> Is there a way to specify the color of the main title, the subtitle, or
> the axis labels?  I mean, for instance, something like
> 
> title(main="cougar", col=2)
> 
> For me, the above command produces the color black; that is, the "col"
> argument has no effect.
> 
> I'm on a Windows 2000 machine with
> 
> 
>>version
> 
>          _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    5.0
> year     2002
> month    04
> day      29
> language R
> 
> Thanks for any advice
> 
> Jake


See ?par. Specifically col.main, col.sub, and col.axis.

Regards,
Sundar



From lockwood at rand.org  Fri May 30 21:54:36 2003
From: lockwood at rand.org (J.R. Lockwood)
Date: Fri, 30 May 2003 15:54:36 -0400 (EDT)
Subject: [R] Extracting Vectors from Lists of Lists Produced by Functions
In-Reply-To: <12D0D00E1404D511A4820090274CA09C02FC059F@dasmtyjqf010.amedd.army.mil>
Message-ID: <Pine.LNX.4.33.0305301548230.17470-100000@penguin.rand.org>

Dear Charles,

Since you are extracting vectors of the same length from each element
of the list, you can use "sapply"

"sapply(measure,function(x){x[1:3]})"

after which you can transpose, rename, make into a dataframe as
desired.

In general you would use "lapply" to apply a function to each element
of a list, resulting in new list.

best,

J.R. Lockwood
412-683-2300 x4941
lockwood at rand.org
http://www.rand.org/methodology/stat/members/lockwood/


> If you found my subject heading to be confusing then I'm sure you'll enjoy
> the example I've included below. I find the apply type functions to be
> wonderful for avoiding loops but when I use them with existing functions, I
> end up using loops anyway to extract the vectors I want. I would appreciate
> it if someone could show me how to avoid these loops. Thanks.
> 
> EXAMPLE: 
> noise<-matrix(data = rnorm(15, mean=0, sd=1), nrow = 5, ncol = 3,
>               byrow = FALSE, dimnames = NULL)
> measure<-apply(noise,2,t.test)
> measure
> tval<-NULL
> df<-NULL
> pval<-NULL
> for (i in 1:length(measure)){
>   tval[i]<-measure[[i]][[1]]
>   df[i]<-measure[[i]][[2]]
>   pval[i]<-measure[[i]][[3]]}
> data.frame(tval,df,pval)
> 
> Charles E. White, Biostatistician
> Walter Reed Army Institute of Research
> 503 Robert Grant Ave., Room 1w102
> Silver Spring, MD 20910-1557
> 301 319-9781
> WRAIR Home Page: http://wrair-www.army.mil/
>



From ripley at stats.ox.ac.uk  Fri May 30 22:02:50 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 30 May 2003 21:02:50 +0100 (BST)
Subject: [R] color in plot title: title(sub="something", col=4)
In-Reply-To: <Pine.GSO.4.44.0305301127490.24873-100000@vici.ucdavis.edu>
Message-ID: <Pine.LNX.4.44.0305302101120.8952-100000@gannet.stats>

?title says

     ...: further graphical parameters from `par'.  Use e.g.,
          `col.main' or `cex.sub' instead of just `col' or `cex'.

And it is *really* time you upgraded your 13-month-old R, especially as it 
is a 1.x.0 release.

On Fri, 30 May 2003, Jacob Wegelin wrote:

> 
> Is there a way to specify the color of the main title, the subtitle, or
> the axis labels?  I mean, for instance, something like
> 
> title(main="cougar", col=2)
> 
> For me, the above command produces the color black; that is, the "col"
> argument has no effect.

So why not look up the help on title?

> I'm on a Windows 2000 machine with
> 
> > version
>          _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    5.0
> year     2002
> month    04
> day      29
> language R
> 
> Thanks for any advice
> 
> Jake
> 
> Jacob A. Wegelin, Ph.D.
> Adjunct Assistant Professor
> Epidemiology and Preventive Medicine, Univ. California
> One Shields Ave, TB-168
> Davis CA 95616-8638 USA
> TEL 530.752.2793
> FAX 530.752.3239
> http://wegelin.ucdavis.edu/
> jawegelin at ucdavis.edu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From lancelot at sentoo.sn  Fri May 30 22:36:15 2003
From: lancelot at sentoo.sn (Renaud Lancelot)
Date: Fri, 30 May 2003 20:36:15 +0000
Subject: Follow up: [R] surfaces and digital terrain model
In-Reply-To: <Pine.SOL.4.44.0305300814500.4891-100000@timepilot.gpcc.itd.umich.edu>
References: <Pine.SOL.4.44.0305300814500.4891-100000@timepilot.gpcc.itd.umich.edu>
Message-ID: <3ED7C0BF.4080702@sentoo.sn>

Yesterday, I posted the following:

>>I have computed a digital terrain model from a set of points (x, y, z)
>>using the function interp() in package akima. I want to predict flooded
>>surfaces given target values of z. I can display the flooded surfaces
>>with contour() or image(), but I don't know how to get the polygons
>>delimiting the surfaces. Did anyone write a function for this purpose ?

Many thanks to Roger Bivand, Paul Murrel, Deepayan Sarkar, Barry 
Rowlingson and Thomas W Blackwell for their replies and their help. Paul 
Murrel provided me with a function "clines", kindly ported to Windows by 
Duncan Murdoch. This function does exactly what I need, i.e. it returns 
a list of polygons corresponding to target value(s) of z.

I wrote a function to compute (hopefully !) what I want, i.e. predicted 
flooded surfaces given target values of z (managing the cases of several 
independent watered surfaces, possibly with islands). Provided that Paul 
Murrel agrees to share his function, I will be happy to send it to 
anyone wishing to use and improve it (and debug it ;-) ).

Best regards and thanks again,

Renaud

-- 
Dr Renaud Lancelot, v?t?rinaire
CIRAD, D?partement Elevage et M?decine V?t?rinaire (CIRAD-Emvt)
Programme Productions Animales
http://www.cirad.fr/fr/pg_recherche/page.php?id=14

ISRA-LNERV                      tel    +221 832 49 02
BP 2057 Dakar-Hann              fax    +221 821 18 79 (CIRAD)
Senegal                         e-mail renaud.lancelot at cirad.fr



From apjaworski at mmm.com  Fri May 30 23:29:49 2003
From: apjaworski at mmm.com (apjaworski@mmm.com)
Date: Fri, 30 May 2003 16:29:49 -0500
Subject: [R] Sparse Matrix
Message-ID: <OF2127006E.0997CAD0-ON86256D36.0075FEE6@mmm.com>


There is a contributed package called SparseM.  It looks like it will do
what you need.

Cheers,

Andy

__________________________________
Andy Jaworski
Engineering Systems Technology Center
3M Center, 518-1-01
St. Paul, MN 55144-1000
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122


|---------+-------------------------------->
|         |           "Harold Doran"       |
|         |           <hdoran at nasdc.org>   |
|         |           Sent by:             |
|         |           r-help-bounces at stat.m|
|         |           ath.ethz.ch          |
|         |                                |
|         |                                |
|         |           05/30/2003 12:55     |
|         |                                |
|---------+-------------------------------->
  >-----------------------------------------------------------------------------------------------------------------------------|
  |                                                                                                                             |
  |      To:       <r-help at stat.math.ethz.ch>                                                                                   |
  |      cc:                                                                                                                    |
  |      Subject:  [R] Sparse Matrix                                                                                            |
  >-----------------------------------------------------------------------------------------------------------------------------|




I am learning about sparse matrices and wonder if R can create them from a
full matrix. Can anyone tell me how I might be able to accomplish this.



------
Harold C. Doran
Director of Research and Evaluation
New American Schools
675 N. Washington Street, Suite 220
Alexandria, Virginia 22314
703.647.1628
 <http://www.edperform.net/>




             [[alternate HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From rwatkins at cornerstonelp.com  Sat May 31 00:21:11 2003
From: rwatkins at cornerstonelp.com (rwatkins@cornerstonelp.com)
Date: Fri, 30 May 2003 17:21:11 -0500
Subject: [R] Downloading packages from CRAN
Message-ID: <NDEKIJPPGJCIKBNEDOKOKEEGCCAA.rwatkins@cornerstonelp.com>

Hello-
	I am trying to download packages from CRAN to my Window-based system.  I
downloaded the most recent version of Perl, as instructed in the Install
Manual and the "car" package, just as a trial.
	Where should they "reside" within my computer:  the unzipped Perl I have
placed at ...R/rw1070; the "car" package I unzipped and placed at
...R/rw1070/library.  Is this correct?  I have tried calling various
commands via help(...) as a proxy to see if the commands / functions are
available [perhaps this is incorrect?] and get the message,"No documentation
for ... in specified packages and libraries"...
	I think my problems are related to the fact that I have mis-addressed or
mis-ordered something.  Am I right?
	I greatly appreciate all of the help I've receive to date -- thanks for
your continued patience.  A good weekend to all.

Rick



From markhall at gol.com  Sat May 31 00:44:51 2003
From: markhall at gol.com (Mark Hall)
Date: Sat, 31 May 2003 07:44:51 +0900
Subject: [R] Time for Usenet R Group?
In-Reply-To: <5.1.0.14.2.20030530101215.036286f0@hermes.nos.noaa.gov>
References: <5.1.0.14.2.20030530101215.036286f0@hermes.nos.noaa.gov>
Message-ID: <20030531063628.5523.MARKHALL@gol.com>

Actually, check the archives about a year ago when this was brought up and the associated
problems.  Ranging from spam harvesters, copyright and the like.

Best, MEH


-- 
 Mark Hall
Niigata Prefectural Museum of History

<>



From kwan022 at stat.auckland.ac.nz  Sat May 31 01:04:45 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Sat, 31 May 2003 11:04:45 +1200 (NZST)
Subject: [R] Downloading packages from CRAN
In-Reply-To: <NDEKIJPPGJCIKBNEDOKOKEEGCCAA.rwatkins@cornerstonelp.com>
Message-ID: <Pine.LNX.4.44.0305311056540.8205-100000@stat61.stat.auckland.ac.nz>

Hi,

On Fri, 30 May 2003 rwatkins at cornerstonelp.com wrote:

> Date: Fri, 30 May 2003 17:21:11 -0500
> From: rwatkins at cornerstonelp.com
> To: R Help <r-help at stat.math.ethz.ch>
> Subject: [R] Downloading packages from CRAN
> 
> Hello-
> 	I am trying to download packages from CRAN to my Window-based system.  I
> downloaded the most recent version of Perl, as instructed in the Install
> Manual and the "car" package, just as a trial.

I don't think you need Perl to download packages from CRAN, nor do you 
need to have Perl installed to to be able to install new package.

How did you download the packages?  The easiest way is probably to do it 
within Rgui.  In the menu bar go to Packages -> Install packages from 
CRAN..., and select the package(s) you want to install.  The installation 
is automatic and the package(s) will be unpacked to the correct place.

> 	Where should they "reside" within my computer:  the unzipped Perl I have
> placed at ...R/rw1070; the "car" package I unzipped and placed at
> ...R/rw1070/library.  Is this correct?  I have tried calling various
> commands via help(...) as a proxy to see if the commands / functions are
> available [perhaps this is incorrect?] and get the message,"No documentation
> for ... in specified packages and libraries"...

Provided you installed the package(s) properly, have you loaded it before 
calling the documentation?  Using the car package example:
  > library(car)
  > ?box.cox
seem to work fine.

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
"On two occasions, I have been asked [by members of Parliament],
'Pray, Mr. Babbage, if you put into the machine wrong figures, will
the right answers come out?' I am not able to rightly apprehend the
kind of confusion of ideas that could provoke such a question."

-- Charles Babbage (1791-1871) 
---- From Computer Stupidities: http://rinkworks.com/stupid/

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)



From tpopenfoose at earthlink.net  Sat May 31 01:14:36 2003
From: tpopenfoose at earthlink.net (Toby Popenfoose)
Date: Fri, 30 May 2003 18:14:36 -0500
Subject: [R] Need help installing qtoolbox
Message-ID: <000701c32701$3d736890$6501a8c0@poweramd>

I have windows version of R v1.6.2

I have downloaded the qtoolbox.zip from
 http://www.cmis.csiro.au/S-PLUS/qtoolbox/

My R command line is
> install.packages("C:/Program Files/R/qtoolbox.zip", .libPaths()[1], CRAN =
NULL)

and I get the following error message:
updating HTML package descriptions
Warning message:
error -1 in extracting from zip file
>

Is there another way to install this S-Plus based Package?  Is there another
control chart library for R that I should be trying instead?

Thank you,
toby popenfoose
tpopenfoose at earthlink.net



From arrayprofile at yahoo.com  Sat May 31 01:28:44 2003
From: arrayprofile at yahoo.com (array chip)
Date: Fri, 30 May 2003 16:28:44 -0700 (PDT)
Subject: [R] catch error/warning message in a loop
Message-ID: <20030530232844.41267.qmail@web41203.mail.yahoo.com>

Hi, I am running cox regreesion (coxph) on a large
number of independent variables, one variable at a
time, using loop. At some point of the loop, the cox
regression stopped due to some errors. How can I know
at which variable the cox regression stopped so that I
can pinpoint the variable that causes the problem? I
guess this is not unique to cox regression, it is the
problem of catching the error/warning message promptly
in a loop.

tahnks

__________________________________

Yahoo! Calendar - Free online calendar with sync to Outlook(TM).



From spencer.graves at pdf.com  Sat May 31 01:58:54 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 30 May 2003 16:58:54 -0700
Subject: [R] catch error/warning message in a loop
References: <20030530232844.41267.qmail@web41203.mail.yahoo.com>
Message-ID: <3ED7F03E.3070809@pdf.com>

	  With situations like this, I often include something like "cat(i, 
'')" in the loop (where "i" is the index of the loop).

	  If I'm writing a function to be used by others, I might use "try", as 
described, e.g. in Venables and Ripley (2000) S Programming (p. 48).

hth.  spencer graves

array chip wrote:
> Hi, I am running cox regreesion (coxph) on a large
> number of independent variables, one variable at a
> time, using loop. At some point of the loop, the cox
> regression stopped due to some errors. How can I know
> at which variable the cox regression stopped so that I
> can pinpoint the variable that causes the problem? I
> guess this is not unique to cox regression, it is the
> problem of catching the error/warning message promptly
> in a loop.
> 
> tahnks
> 
> __________________________________
> 
> Yahoo! Calendar - Free online calendar with sync to Outlook(TM).
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Sat May 31 09:39:54 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 31 May 2003 08:39:54 +0100 (BST)
Subject: [R] Need help installing qtoolbox
In-Reply-To: <000701c32701$3d736890$6501a8c0@poweramd>
Message-ID: <Pine.LNX.4.44.0305310834160.9829-100000@gannet.stats>

On Fri, 30 May 2003, Toby Popenfoose wrote:

> I have windows version of R v1.6.2
> 
> I have downloaded the qtoolbox.zip from
>  http://www.cmis.csiro.au/S-PLUS/qtoolbox/
> 
> My R command line is
> > install.packages("C:/Program Files/R/qtoolbox.zip", .libPaths()[1], CRAN =
> NULL)
> 
> and I get the following error message:
> updating HTML package descriptions
> Warning message:
> error -1 in extracting from zip file
> >
> 
> Is there another way to install this S-Plus based Package?  

I presume it is a S-PLUS library section for S-PLUS 4.x. You wouldn't try
to install, say, a MATLAB toolbox, so why do you think an S-PLUS one would
work?

It is sometimes possible to port the sources of an S-PLUS library section 
to sources for an R package, with considerable work.

> Is there another
> control chart library for R that I should be trying instead?

You seem to have `package' and `library' reversed in meaning.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jmc at research.bell-labs.com  Sat May 31 15:17:53 2003
From: jmc at research.bell-labs.com (John Chambers)
Date: Sat, 31 May 2003 09:17:53 -0400
Subject: [R] Missing 'getGroupMembers()'
References: <3EDD4A8A@minerva.ex.ac.uk>
Message-ID: <3ED8AB81.CFC90574@research.bell-labs.com>

Anton Crombach wrote:
> 
> Hi,
> 
> I'm trying to write a method such that my own classes can be used with the
> groups like "Summary" and "Math", but when I tried to look for examples or
> just wanted to get an idea of which functions are the members of a group, I
> found out that the function "getGroupMembers" is not present... I couldn't
> find an alternative function, if there is one. Does anyone know a solution?
> 

There isn't one currently, and the implementation is not quite as
straightforward in R.

Generic functions in R are objects, with the group they belong to as a
slot.  So, fundamentally, you have to examine some collection of objects
and select those that are generic functions with a particular group
name.

A second complication is that funtions such as "sum" and "+" are not
normally seen as generic functions (so people won't be annoyed by
inefficiency in calling those functions).  To find the groups
corresponding to those functions requires a bit of trickery using
knowledge of how R implements methods for them.

So you have to be a little careful that you are looking in the right set
of generic functions before getGroupMembers is well defined.

Having said all that, the following code implements what one is likely
to want in most cases (the argument recursive= to getGroupMembers is not
supported in this version).  Subject to comments, we can add a version
of it to the package.

------------------------------
getGroups <- function(what = c(getGenerics(), names(.BasicFunsList))) {
    g <-unlist(sapply(what,
          function(x){f <- getGeneric(x);  if(is(f,
"genericFunction"))f at group else NULL}))
    split(names(g), g)
}

getGroupMembers <- function(group, whatGenerics) {
    groups <- if(missing(whatGenerics)) getGroups() else
getGroups(whatGenerics)
    elNamed(groups, group)
}

------------------------------

With this definition, for example,
  
R> getGroupMembers("Math")
 [1] "cumprod" "sqrt"    "abs"     "acos"    "acosh"   "asin"   
"asinh"  
 [8] "atan"    "atanh"   "ceiling" "cos"     "cosh"    "cumsum" 
"exp"    
[15] "floor"   "sin"     "sinh"    "tan"     "tanh"    "trunc"  

Since you mention "Summary", we might as well note now that this group
does not exist in R, because currently the functions that would be its
members are not organized to take methods.

For example,

R> args(max)
function (..., na.rm = FALSE) 
NULL

So there is no first argument on which to attach methods.  If there is a
strong desire, the formal arguments could be changed, to function(x,
..., na.rm = FALSE).  But this needs some discussion (preferrably on
R-devel).

John Chambers

> Anton
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
John M. Chambers                  jmc at bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc



From pfleonard at hotmail.com  Sat May 31 17:35:46 2003
From: pfleonard at hotmail.com (peter leonard)
Date: Sat, 31 May 2003 08:35:46 -0700
Subject: [R] function to populate a matrix based on a lookup to another
	matrix ?
Message-ID: <Law11-F1233JkrKdMUP00061c0d@hotmail.com>

Hi,

This is a beginner R question.

I have a  4x4 matrix  named 'lookup' with the following values:

            1         2               3          4
1 0.000000 2.828427 5.656854 8.485281
2 2.828427 0.000000 2.828427 5.656854
3 5.656854 2.828427 0.000000 2.828427
4 8.485281 5.656854 2.828427 0.000000

I then create a new empty matrix named 'dd' with specfic row and col names :

   1   3   4   3    3   1
1 NA NA NA NA NA NA
2 NA NA NA NA NA NA
3 NA NA NA NA NA NA
4 NA NA NA NA NA NA
3 NA NA NA NA NA NA
2 NA NA NA NA NA NA
1 NA NA NA NA NA NA

I want to be able populate the cells in 'dd' using 'lookup' based on the 
specified rownames and colnames of 'dd'. For example, the cell in 'dd' where 
the rowname =2 and the colname = 1 should be assigned the value 2.828427 .

I've tried several ways of doing this with the apply function  but without 
success. I can do it with a for loop but I want to avoid that for efficiency 
reasons.

After running the function, as an example, the first column of 'dd' should 
look like this :

             1
1 0.000000000
2 2.828427125
3 5.656854249
4 8.485281374
3 5.656854249
2 2.828427125
1 0.000000000

Can anyone please help me identify the required function or an alternative 
way of achieving the same result? Hopefully this is simple and I'm just not 
seeing it.

Thanks
Peter



From ligges at statistik.uni-dortmund.de  Sat May 31 17:58:27 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 31 May 2003 17:58:27 +0200
Subject: [R] function to populate a matrix based on a lookup to another
	matrix ?
In-Reply-To: <Law11-F1233JkrKdMUP00061c0d@hotmail.com>
References: <Law11-F1233JkrKdMUP00061c0d@hotmail.com>
Message-ID: <3ED8D123.6070700@statistik.uni-dortmund.de>

peter leonard wrote:
> Hi,
> 
> This is a beginner R question.
> 
> I have a  4x4 matrix  named 'lookup' with the following values:
> 
>            1         2               3          4
> 1 0.000000 2.828427 5.656854 8.485281
> 2 2.828427 0.000000 2.828427 5.656854
> 3 5.656854 2.828427 0.000000 2.828427
> 4 8.485281 5.656854 2.828427 0.000000
> 
> I then create a new empty matrix named 'dd' with specfic row and col 
> names :
> 
>   1   3   4   3    3   1
> 1 NA NA NA NA NA NA
> 2 NA NA NA NA NA NA
> 3 NA NA NA NA NA NA
> 4 NA NA NA NA NA NA
> 3 NA NA NA NA NA NA
> 2 NA NA NA NA NA NA
> 1 NA NA NA NA NA NA
> 
> I want to be able populate the cells in 'dd' using 'lookup' based on the 
> specified rownames and colnames of 'dd'. For example, the cell in 'dd' 
> where the rowname =2 and the colname = 1 should be assigned the value 
> 2.828427 .
> 
> I've tried several ways of doing this with the apply function  but 
> without success. I can do it with a for loop but I want to avoid that 
> for efficiency reasons.
> 
> After running the function, as an example, the first column of 'dd' 
> should look like this :
> 
>             1
> 1 0.000000000
> 2 2.828427125
> 3 5.656854249
> 4 8.485281374
> 3 5.656854249
> 2 2.828427125
> 1 0.000000000
> 
> Can anyone please help me identify the required function or an 
> alternative way of achieving the same result? Hopefully this is simple 
> and I'm just not seeing it.
> 
> Thanks
> Peter
> 

  dd <- lookup[as.numeric(rownames(dd)), as.numeric(colnames(dd))]
and after that restoring dd's row- and colnames.

Anyway, I guess you don't need to create "dd". Just calculate those 
rownames (rn) and colnames (cn) as integers. Then the following works:

  dd <- lookup[rn, cn]

Uwe Ligges



From pauljohn at ku.edu  Sat May 31 18:57:15 2003
From: pauljohn at ku.edu (Paul E. Johnson)
Date: Sat, 31 May 2003 11:57:15 -0500
Subject: [R] parse on left hand side of R assignment
Message-ID: <3ED8DEEB.5090808@ku.edu>

I keep finding myself in a situation where I want to calculate a 
variable name and then use it on the left hand side of an assignment. 
For example

iteration <- 1
varName <- paste("run",iteration,sep="")
myList$parse(text=varName) <- aColumn

I want to take some existing variable  "aColumn" and use the name 
"varName" name for it and put it into a list "myList".  That use fails 
with this error:

Error: couldn't find function "(<-"

I've tried many variations on the theme.

If I could do this with a data frame, I would be just as happy. Right 
now I'm using a list rather than a data frame because not all columns 
are of the same length. But I can work around that.

-- 
Paul E. Johnson                       email: pauljohn at ukans.edu
Dept. of Political Science            http://lark.cc.ukans.edu/~pauljohn
University of Kansas                  Office: (785) 864-9086
Lawrence, Kansas 66045                FAX: (785) 864-5700



From ligges at statistik.uni-dortmund.de  Sat May 31 19:17:47 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 31 May 2003 19:17:47 +0200
Subject: [R] parse on left hand side of R assignment
In-Reply-To: <3ED8DEEB.5090808@ku.edu>
References: <3ED8DEEB.5090808@ku.edu>
Message-ID: <3ED8E3BB.5030401@statistik.uni-dortmund.de>

Paul E. Johnson wrote:
> I keep finding myself in a situation where I want to calculate a 
> variable name and then use it on the left hand side of an assignment. 
> For example
> 
> iteration <- 1
> varName <- paste("run",iteration,sep="")
> myList$parse(text=varName) <- aColumn
> 
> I want to take some existing variable  "aColumn" and use the name 
> "varName" name for it and put it into a list "myList".  That use fails 
> with this error:
> 
> Error: couldn't find function "(<-"
> 
> I've tried many variations on the theme.
> 
> If I could do this with a data frame, I would be just as happy. Right 
> now I'm using a list rather than a data frame because not all columns 
> are of the same length. But I can work around that.
> 

See ?assign.

Uwe Ligges



From spencer.graves at pdf.com  Sat May 31 19:25:40 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 31 May 2003 10:25:40 -0700
Subject: [R] parse on left hand side of R assignment
References: <3ED8DEEB.5090808@ku.edu>
Message-ID: <3ED8E594.3080100@pdf.com>

Have you considered the following:

 > myList <- list()
 > iteration <- 1
 > varName <- paste("run",iteration,sep="")
 > myList[[varName]] <- "aColumn"
 > myList
$run1
[1] "aColumn"

hth.  spencer graves

Paul E. Johnson wrote:
> I keep finding myself in a situation where I want to calculate a 
> variable name and then use it on the left hand side of an assignment. 
> For example
> 
> iteration <- 1
> varName <- paste("run",iteration,sep="")
> myList$parse(text=varName) <- aColumn
> 
> I want to take some existing variable  "aColumn" and use the name 
> "varName" name for it and put it into a list "myList".  That use fails 
> with this error:
> 
> Error: couldn't find function "(<-"
> 
> I've tried many variations on the theme.
> 
> If I could do this with a data frame, I would be just as happy. Right 
> now I'm using a list rather than a data frame because not all columns 
> are of the same length. But I can work around that.
>



From jfox at mcmaster.ca  Sat May 31 19:30:07 2003
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 31 May 2003 13:30:07 -0400
Subject: [R] parse on left hand side of R assignment
In-Reply-To: <3ED8DEEB.5090808@ku.edu>
Message-ID: <5.1.0.14.2.20030531132546.01e95498@mcmail.cis.mcmaster.ca>

At 11:57 AM 5/31/2003 -0500, Paul E. Johnson wrote:
>I keep finding myself in a situation where I want to calculate a variable 
>name and then use it on the left hand side of an assignment. For example
>
>iteration <- 1
>varName <- paste("run",iteration,sep="")
>myList$parse(text=varName) <- aColumn
>
>I want to take some existing variable  "aColumn" and use the name 
>"varName" name for it and put it into a list "myList".  That use fails 
>with this error:
>
>Error: couldn't find function "(<-"
>
>I've tried many variations on the theme.
>
>If I could do this with a data frame, I would be just as happy. Right now 
>I'm using a list rather than a data frame because not all columns are of 
>the same length. But I can work around that.

Dear Paul,

I don't think that assign() will work in this context, but I may be wrong.

One way to proceed is with eval() and parse(), assembling the command to be 
executed as a text string; for example,

eval(parse(text=paste("myList$", varName, " <- aColumn", sep=""))), though 
you do have to be careful about the environment in which the expression is 
evaluated -- see the envir argument to eval.

I hope that this helps,
  John


-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From ripley at stats.ox.ac.uk  Sat May 31 19:55:36 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 31 May 2003 18:55:36 +0100 (BST)
Subject: [R] parse on left hand side of R assignment
In-Reply-To: <3ED8DEEB.5090808@ku.edu>
Message-ID: <Pine.LNX.4.44.0305311855150.11211-100000@gannet.stats>

On Sat, 31 May 2003, Paul E. Johnson wrote:

> I keep finding myself in a situation where I want to calculate a 
> variable name and then use it on the left hand side of an assignment. 
> For example
> 
> iteration <- 1
> varName <- paste("run",iteration,sep="")
> myList$parse(text=varName) <- aColumn
> 
> I want to take some existing variable  "aColumn" and use the name 
> "varName" name for it and put it into a list "myList".  That use fails 
> with this error:
> 
> Error: couldn't find function "(<-"
> 
> I've tried many variations on the theme.
> 
> If I could do this with a data frame, I would be just as happy. Right 
> now I'm using a list rather than a data frame because not all columns 
> are of the same length. But I can work around that.

For a data frame you could use

mydf[paste("run",iteration,sep="")] <- aColumn

and for a list or a data frame

Robject[[paste("run",iteration,sep="")]] <- aColumn

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mail at joeconway.com  Sat May 31 22:18:00 2003
From: mail at joeconway.com (Joe Conway)
Date: Sat, 31 May 2003 13:18:00 -0700
Subject: [R] Need help installing qtoolbox
In-Reply-To: <000701c32701$3d736890$6501a8c0@poweramd>
References: <000701c32701$3d736890$6501a8c0@poweramd>
Message-ID: <3ED90DF8.8030400@joeconway.com>

Toby Popenfoose wrote:
> Is there another control chart library for R that I should be trying
> instead?
> 

I looked around and could not find an R package for Shewhart control 
charts. I'll post the function I wrote for my own needs, but note that I 
am not a statistician, nor am I particularly experienced with R -- so 
use at your own risk ;-)

It only does X-bar, R, and geometric moving average. I used the 
"traditional" calculations (i.e. use constants based on sample group 
size, and range, to calculate UCL/LCL) instead of a more rigorous approach.

Below is the function and an example of how to use it (if anyone has 
suggestions for improvement, I'd love to hear them).

HTH,

Joe

8<-------------------------

controlChart <- function(xdata, ssize, CLnumGroups = 0)
{
     if (!is.vector(xdata))
         stop("Data must be a vector")

     if (!is.numeric(xdata))
         stop("Data vector must be numeric")

     xdatalen <- length(xdata)
     xdataresid <- xdatalen %% ssize
     newxdatalen <- xdatalen - xdataresid
     if (xdataresid != 0)
         xdata <- xdata[1:newxdatalen]

     if (ssize < 1 | ssize > 10)
     {
         stop("Sample size must be in the range of 1 to 10")
     }
     else if (ssize > 1 & ssize < 11)
     {
         # Xbar/R factors
         ng <- c(2:10)
         D3 <- c(0,0,0,0,0,0.08,0.14,0.18,0.22)
         D4 <- c(3.27,2.57,2.28,2.11,2.00,1.92,1.86,1.82,1.78)
         A2 <- c(1.88,1.02,0.73,0.58,0.48,0.42,0.37,0.34,0.31)
         d2 <- c(1.13,1.69,2.06,2.33,2.53,2.70,2.85,2.97,3.08)
         v <- data.frame(ng, D3, D4, A2, d2)

         # put into sample groups
         m <- matrix(xdata, ncol = ssize, byrow = TRUE)

         # number of groups
         numgroups <- nrow(m)

         # Adjust number of points used to calculate control limits.
         if (numgroups < CLnumGroups | CLnumGroups == 0)
             CLnumGroups = numgroups

         # range for each group
         r <- apply(m, 1, range)
         r <- r[2,] - r[1,]

         # Rbar
         rb <- mean(r[1:CLnumGroups])
         rb <- rep(rb, numgroups)

         # R UCL and LCL
         rucl <- v$D4[match(ssize,v$ng) + 1] * rb
         rlcl <- v$D3[match(ssize,v$ng) + 1] * rb

         # Xbar
         xb <- apply(m, 1, mean)

         # Xbarbar
         xbb <- mean(xb[1:numgroups])
         xbb <- rep(xbb, numgroups)

         # X UCL and LCL
         xucl <- xbb + (v$A2[match(ssize,v$ng) + 1] * rb)
         xlcl <- xbb - (v$A2[match(ssize,v$ng) + 1] * rb)
     }
     else            #sample size is 1
     {
         m <- xdata

         # number of groups
         numgroups <- length(m)

         # Adjust number of points used to calculate control limits.
         if (numgroups < CLnumGroups | CLnumGroups == 0)
             CLnumGroups = numgroups

         # set range for each group to 0
         r <- rep(0, numgroups)

         # Rbar
         rb <- rep(0, numgroups)

         # R UCL and LCL
         rucl <- rep(0, numgroups)
         rlcl <- rep(0, numgroups)

         # Xbar is a copy of the individual data points
         xb <- m

         # Xbarbar is mean over the data
         xbb <- mean(xb[1:CLnumGroups])
         xbb <- rep(xbb, numgroups)

         # standard deviation over the data
         xsd <- sd(xb[1:CLnumGroups])

         # X UCL and LCL
         xucl <- xbb + 3 * xsd
         xlcl <- xbb - 3 * xsd
     }

     # geometric moving average
     if (numgroups > 1)
     {
         rg <- 0.25
         gma = c(xb[1])
         for(i in 2:numgroups)
             gma[i] = (rg * xb[i]) + ((1 - rg) * gma[i - 1])
     }
     else
     {
         gma <- rep(0, numgroups)
     }

     # create a single dataframe with all the plot data
     controlChartSummary <- data.frame(1:numgroups, xb, xbb, xucl, xlcl, 
r, rb, rucl, rlcl, gma)

     return(controlChartSummary)
}

# sample data
xdata <- 12 + 4 * rnorm(90)
# sample size
ssize <- 3
# get control chart data
cc <- controlChart(xdata, ssize)
# get number of sample groups
numgroups <- length(cc$xb)

# X Bar chart
plotxrange <- range(c(1:numgroups))
plotyrange <- range(cc$xb, cc$xucl, cc$xlcl)
plotyrange[1] <- plotyrange[1] - (plotyrange[2] - plotyrange[1]) * 0.1
plotyrange[2] <- plotyrange[2] + (plotyrange[2] - plotyrange[1]) * 0.1

plot(c(1:numgroups), xlim = plotxrange, ylim = plotyrange, cc$xb, type = 
"b", lty = 1)
lines(c(1:numgroups), cc$xbb, lty = 1)
lines(c(1:numgroups), cc$xucl, lty = 1)
lines(c(1:numgroups), cc$xlcl, lty = 1)

# R chart
plotxrange <- range(c(1:numgroups))
plotyrange <- range(cc$r, cc$rucl, cc$rlcl)
plotyrange[1] <- plotyrange[1] - (plotyrange[2] - plotyrange[1]) * 0.1
plotyrange[2] <- plotyrange[2] + (plotyrange[2] - plotyrange[1]) * 0.1

plot(c(1:numgroups), xlim = plotxrange, ylim = plotyrange, cc$r, type = 
"b", lty = 1)
lines(c(1:numgroups), cc$rb, lty = 1)
lines(c(1:numgroups), cc$rucl, lty = 1)
lines(c(1:numgroups), cc$rlcl, lty = 1)

# Geometric Moving Average chart
plotxrange <- range(c(1:numgroups))
plotyrange <- range(cc$gma)
plotyrange[1] <- plotyrange[1] - (plotyrange[2] - plotyrange[1]) * 0.1
plotyrange[2] <- plotyrange[2] + (plotyrange[2] - plotyrange[1]) * 0.1

plot(c(1:numgroups), xlim = plotxrange, ylim = plotyrange, cc$gma, type 
= "b", lty = 1)



