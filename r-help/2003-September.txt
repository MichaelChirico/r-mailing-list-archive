From sumslily at yahoo.com  Mon Sep  1 03:06:27 2003
From: sumslily at yahoo.com (Lily)
Date: Sun, 31 Aug 2003 18:06:27 -0700 (PDT)
Subject: [R] help for performing regressions based on combination of
	predictors
Message-ID: <20030901010627.42361.qmail@web41201.mail.yahoo.com>

Dear All,

I would like to perform linear regressions based on Y
and all of the combinations of the five predictors,
i.e.,(y,x1,x2),(y,x1,x3),....,(y,x1,x2,x4,x5),....,(y,x1,x2,x3,x4,x5).

Is there any quick way to do it instead of repeat
performing regressions for 31 times? Or, is there 
any method to manipulate the dataset into the 31
combinations?

Thanks for your help!



From ypeng at math.mun.ca  Mon Sep  1 03:58:53 2003
From: ypeng at math.mun.ca (Paul Y. Peng)
Date: Sun, 31 Aug 2003 23:28:53 -0230
Subject: [R] Shared library loading in Win R 1071 and previous
	Win	Rversions
References: <Pine.WNT.4.44.0308301659330.2808-100000@petrel>
	<3F510476.35381968@math.mun.ca>
	<3F51F1B3.4000706@statistik.uni-dortmund.de>
Message-ID: <3F52A7DD.DB24994@math.mun.ca>

Many thanks to Brian and Uwe for their replies. After some changes
and recompilation, my dll library now works with R1.7.1. I think
the problem was caused by the change in R1.7.1 on calling log1p C
function from users' C programs. The answer to my another question
is that the older binary versions than rw1070 for Windows are not
available in CRAN.

Paul.



From sumslily at yahoo.com  Mon Sep  1 03:57:09 2003
From: sumslily at yahoo.com (Lily)
Date: Sun, 31 Aug 2003 18:57:09 -0700 (PDT)
Subject: [R] help for performing regressions based on combination of
	predictors
In-Reply-To: <20030901013524.GM11971@hortresearch.co.nz>
Message-ID: <20030901015709.4025.qmail@web41206.mail.yahoo.com>

Thanks! However, what I mean is performing 31
regressions based on the combinations of the
predictors. I don't consider interaction in 
this case. So, the regressions are like
lm(y~x1+x2) or lm(Y~x1+x2+x3),or lm(y~x1+x2+x4)
...etc.

--- Patrick Connolly <p.connolly at hortresearch.co.nz>
wrote:
> On Sun, 31-Aug-2003 at 06:06PM -0700, Lily wrote:
> 
> |> Dear All,
> |> 
> |> I would like to perform linear regressions based
> on Y
> |> and all of the combinations of the five
> predictors,
> |>
>
i.e.,(y,x1,x2),(y,x1,x3),....,(y,x1,x2,x4,x5),....,(y,x1,x2,x3,x4,x5).
> |> 
> |> Is there any quick way to do it instead of repeat
> |> performing regressions for 31 times? Or, is there
> 
> |> any method to manipulate the dataset into the 31
> |> combinations?
> 
> Probably, but it's simpler to put them all in the
> formula:
> 
> lm(y ~ x1 * x2 * x3 * x4 *x5)
> 
> 
> -- 
> Patrick Connolly
> HortResearch
> Mt Albert
> Auckland
> New Zealand 
> Ph: +64-9 815 4200 x 7188
>
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
> I have the world`s largest collection of seashells.
> I keep it on all
> the beaches of the world ... Perhaps you`ve seen it.
>  ---Steven Wright 
>
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From kjetil at entelnet.bo  Mon Sep  1 04:10:27 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Sun, 31 Aug 2003 22:10:27 -0400
Subject: [R] help for performing regressions based on combination
	of	predictors
In-Reply-To: <20030901010627.42361.qmail@web41201.mail.yahoo.com>
Message-ID: <3F527253.19068.1179ED3@localhost>

On 31 Aug 2003 at 18:06, Lily wrote:


Have you tried 
library(leaps)
library(help=leaps)
?

Kjetil Halvorsen

> Dear All,
> 
> I would like to perform linear regressions based on Y
> and all of the combinations of the five predictors,
> i.e.,(y,x1,x2),(y,x1,x3),....,(y,x1,x2,x4,x5),....,(y,x1,x2,x3,x4,x5).
> 
> Is there any quick way to do it instead of repeat
> performing regressions for 31 times? Or, is there 
> any method to manipulate the dataset into the 31
> combinations?
> 
> Thanks for your help!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ok at cs.otago.ac.nz  Mon Sep  1 04:49:00 2003
From: ok at cs.otago.ac.nz (Richard A. O'Keefe)
Date: Mon, 1 Sep 2003 14:49:00 +1200 (NZST)
Subject: [R] difference between <- and =
Message-ID: <200309010249.h812n0p8244669@atlas.otago.ac.nz>

Levi Larkey <larkey at mail.utexas.edu> wrote:

a perfect illustration of why allowing "=" as an alternative
spelling for "<-" was always an obviously really bad idea.

	Is there any reason for using one operator over the other outside of 
	function definitions and calls?

You should never use "=" for assignment unless you are suffering such
severe "C" withdrawal symptoms that the doctor just had to give you a
shot to calm you down.  It is best to keep different symbols for
different purposes.  (I note that Ada uses ":=" for assignment and
"=>" for keyword arguments.)

Something that would be quite useful would be an option asking R to
warn you
    - if you have any assignment operator in a function argument
      (thanks to lazy evaluation this probably *won't* do what you
      expect)
    - if you have "=" anywhere except for binding a name to an argument.
Perhaps these could be two options.



From rab at nauticom.net  Mon Sep  1 07:12:32 2003
From: rab at nauticom.net (rab)
Date: Mon, 01 Sep 2003 01:12:32 -0400
Subject: [R] Illegal instruction - R 1.7.1 under RH 9 Intel
Message-ID: <3F52D540.6090000@nauticom.net>

I installed R 1.7.1 on my intel desktop (RH 9) without any problems.  I 
installed the same binary (R-1.7.1-1.i386.rpm) on my Toshiba Satellite 
2535cds (RH 9). R starts as usual all the way to how to quit then prints:

Illegal instruction

and exits to the shell prompt. I also had installed the patched readline 
rpm.

How can I fix this? I've never had a problem running R before on the laptop.

Rick B.



From ripley at stats.ox.ac.uk  Mon Sep  1 08:36:42 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 1 Sep 2003 07:36:42 +0100 (BST)
Subject: [R] Illegal instruction - R 1.7.1 under RH 9 Intel
In-Reply-To: <3F52D540.6090000@nauticom.net>
Message-ID: <Pine.LNX.4.44.0309010721290.31066-100000@gannet.stats>

We've seen things like this on RH, and it boiled down to the exact state
of the updates on different systems.  Indeed, we currently have a
situation that R compiled on server A will crash on one of servers B or C,
for any choice of A amongst the three servers.  (Fortunately R compiled on
D works on all of A B C.)  All the machines concerned are dual PIIIs.

We are in the process of ensuring that all our machines are patched with
exactly the same update rpms, but that is probably not the whole story as
we have encountered problems between single-processor P4 and
dual-processor PIII machines (obviously running different kernels, at the
same patch level).  (It's also a problem with 100 odd machines, many of 
which are dual-boot and rarely in Linux.)

I can only suggest you build R from the sources yourself on the laptop, 
unless Martyn has a better idea.

On Mon, 1 Sep 2003, rab wrote:

> I installed R 1.7.1 on my intel desktop (RH 9) without any problems.  I 
> installed the same binary (R-1.7.1-1.i386.rpm) on my Toshiba Satellite 
> 2535cds (RH 9). R starts as usual all the way to how to quit then prints:
> 
> Illegal instruction
> 
> and exits to the shell prompt. I also had installed the patched readline 
> rpm.
> 
> How can I fix this? I've never had a problem running R before on the laptop.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Mon Sep  1 09:04:54 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon, 01 Sep 2003 07:04:54 -0000
Subject: [R] Illegal instruction - R 1.7.1 under RH 9 Intel
In-Reply-To: <3F52D540.6090000@nauticom.net>
References: <3F52D540.6090000@nauticom.net>
Message-ID: <x2y8x90yzq.fsf@biostat.ku.dk>

rab <rab at nauticom.net> writes:

> I installed R 1.7.1 on my intel desktop (RH 9) without any problems.
> I installed the same binary (R-1.7.1-1.i386.rpm) on my Toshiba
> Satellite 2535cds (RH 9). R starts as usual all the way to how to quit
> then prints:
> 
> Illegal instruction
> 
> and exits to the shell prompt. I also had installed the patched
> readline rpm.
> 
> How can I fix this? I've never had a problem running R before on the laptop.

Couple of questions which might help us get closer to the source of
the trouble:

Does it happen if you turn off readline processing? (R --no-readline)
If so, and if you're not running the KDE konsole, you might want to
try downgrading readline to the original version. Apart from that,
could you try running under the debugger (R -d gdb) and tell us where
the crash is coming from?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From spencer.graves at pdf.com  Mon Sep  1 11:57:20 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 01 Sep 2003 02:57:20 -0700
Subject: [R] difference between <- and =
References: <200309010249.h812n0p8244669@atlas.otago.ac.nz>
Message-ID: <3F531800.1030705@pdf.com>

	  A common, punishing error for me, with DF being a data frame, is the 
following:

	  if(DF$a = 1) ...

	  where I intended to write "if(DF$a == 1)...".  This error first 
replaces column "a" of DF with the trivial vector 1 (of length 1), and 
then interprets that as a logical, which evaluates as TRUE.  Unless the 
"if" statement otherwise generates an error, I must restore column "a" 
from somewhere before I can continue.

	   In addition to specifying function arguments, I also use "=" to 
specify named components of a list or a vector.  That works fine for me. 
  It's only the accidental use of "=" when I mean "==" that creates 
problems.

Best Wishes,
Spencer Graves

Richard A. O'Keefe wrote:
> Levi Larkey <larkey at mail.utexas.edu> wrote:
> 
> a perfect illustration of why allowing "=" as an alternative
> spelling for "<-" was always an obviously really bad idea.
> 
> 	Is there any reason for using one operator over the other outside of 
> 	function definitions and calls?
> 
> You should never use "=" for assignment unless you are suffering such
> severe "C" withdrawal symptoms that the doctor just had to give you a
> shot to calm you down.  It is best to keep different symbols for
> different purposes.  (I note that Ada uses ":=" for assignment and
> "=>" for keyword arguments.)
> 
> Something that would be quite useful would be an option asking R to
> warn you
>     - if you have any assignment operator in a function argument
>       (thanks to lazy evaluation this probably *won't* do what you
>       expect)
>     - if you have "=" anywhere except for binding a name to an argument.
> Perhaps these could be two options.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From p.dalgaard at biostat.ku.dk  Mon Sep  1 12:23:32 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon, 01 Sep 2003 10:23:32 -0000
Subject: [R] difference between <- and =
In-Reply-To: <3F531800.1030705@pdf.com>
References: <200309010249.h812n0p8244669@atlas.otago.ac.nz>
	<3F531800.1030705@pdf.com>
Message-ID: <x2bru4iz71.fsf@biostat.ku.dk>

Spencer Graves <spencer.graves at pdf.com> writes:

> 	  A common, punishing error for me, with DF being a data
> frame, is the following:
> 
> 	  if(DF$a = 1) ...
> 
> 	  where I intended to write "if(DF$a == 1)...".  This error
> first replaces column "a" of DF with the trivial vector 1 (of length
> 1), and then interprets that as a logical, which evaluates as TRUE.
> Unless the "if" statement otherwise generates an error, I must restore
> column "a" from somewhere before I can continue.

Eh?

> a <- list(x=2)
> if (a$x = 1) 5
Error: syntax error

I think you're referring to another R-like language....

 
> 	   In addition to specifying function arguments, I also use
> "=" to specify named components of a list or a vector.  That works
> fine for me. It's only the accidental use of "=" when I mean "==" that
> creates problems.

(Actually, that's the same thing. list() and c() are function calls like
(almost) everything else.)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ucgamdo at ucl.ac.uk  Mon Sep  1 12:38:27 2003
From: ucgamdo at ucl.ac.uk (ucgamdo@ucl.ac.uk)
Date: Mon, 01 Sep 2003 11:38:27 +0100
Subject: [R] Re: Plotting bivariate normal distributions.
Message-ID: <3.0.5.32.20030901113827.007d4100@pop-server.ucl.ac.uk>

You'll find that it is a lot easier to do it in R:

# lets first simulate a bivariate normal sample
library(MASS)
bivn <- mvrnorm(1000, mu = c(0, 0), Sigma = matrix(c(1, .5, .5, 1), 2))

# now we do a kernel density estimate
bivn.kde <- kde2d(bivn[,1], bivn[,2], n = 50)

# now plot your results
contour(bivn.kde)
image(bivn.kde)
persp(bivn.kde, phi = 45, theta = 30)

# fancy contour with image
image(bivn.kde); contour(bivn.kde, add = T)

# fancy perspective
persp(bivn.kde, phi = 45, theta = 30, shade = .1, border = NA)

#########################################################################
Hi,

I've used the Mathematica to produce 3D graphics, contour plots of a
bivariate normal distribution

Now I want make these graphics in R, but i do not know how.
I would like to:
- Plot a 3D graph for some different variance matrix
- Plot the contour plots
- Find and try to plot (in the 3d graph ou contour plot) the (1-a)%
confidence region based in a chi-square(a) with the degrees of freedom
equal a 2 or bigger.

Below is the Mathematica Notebook that i've used until now


<< "Graphics`PlotField`"

NB[x_,y_]:=(1/((2 Pi)*Sqrt[a*b*(1-c^2)]))*Exp[(-1/(2*(1-c^2)))*( 
          ((x-u)/Sqrt[a])^2 + ((y-v)/Sqrt[b])^2 
			- 2*c(((x-u)/Sqrt[a])((y-v)/Sqrt[b]))
								)]

{{a,c}, {c,b}} = {{1,0}, {0,1}};  The covariance Matrix
{u,v} = {0,0};                    Mean vector
Plot3D[NB[x,y],{x,-1.5,1.5},{y,-1.5,1.5},
		AxesLabel->{x,y,z},
		BoxRatios->{1,1,1}];
ContourPlot[NB[x,y],{x,-1,1},{y,-1,1},
		Axes->True, 
		AxesLabel->{x,y}];

3d graph rotation
Do[
	Plot3D[NB[x,y],{x,-1.5,1.5},{y,-1.5,1.5},
		PlotPoints->20,
		Mesh ->False,
		SphericalRegion ->True,
		Axes ->None,
		Boxed ->False,
		ViewPoint->{2 Cos[t], 2 Sin[t], 1.3},
		BoxRatios->{1,1,1}
	],{t, 0, 2Pi-2Pi/36, 2Pi/36}]


Thanks, 
Rafael
-- 
  
  bertola at fastmail.fm

-- 

                          love email again



From spencer.graves at pdf.com  Mon Sep  1 12:37:48 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 01 Sep 2003 03:37:48 -0700
Subject: [R] difference between <- and =
References: <200309010249.h812n0p8244669@atlas.otago.ac.nz>	<3F531800.1030705@pdf.com>
	<x2bru4iz71.fsf@biostat.ku.dk>
Message-ID: <3F53217C.7080504@pdf.com>

Thank, Peter, for the clarification:  You are correct on both counts. 
For the moment, I'm stuck working in an organization with many users of 
"another R-like language", and I must use the same dialect as they do. 
Migration is on my long-term planning horizon but won't happen soon.

	  Thanks also for your many interesting and useful contributions to my 
education and that of many others.

Best Wishes,
Spencer Graves

Peter Dalgaard BSA wrote:
> Spencer Graves <spencer.graves at pdf.com> writes:
> 
> 
>>	  A common, punishing error for me, with DF being a data
>>frame, is the following:
>>
>>	  if(DF$a = 1) ...
>>
>>	  where I intended to write "if(DF$a == 1)...".  This error
>>first replaces column "a" of DF with the trivial vector 1 (of length
>>1), and then interprets that as a logical, which evaluates as TRUE.
>>Unless the "if" statement otherwise generates an error, I must restore
>>column "a" from somewhere before I can continue.
> 
> 
> Eh?
> 
> 
>>a <- list(x=2)
>>if (a$x = 1) 5
> 
> Error: syntax error
> 
> I think you're referring to another R-like language....
> 
>  
> 
>>	   In addition to specifying function arguments, I also use
>>"=" to specify named components of a list or a vector.  That works
>>fine for me. It's only the accidental use of "=" when I mean "==" that
>>creates problems.
> 
> 
> (Actually, that's the same thing. list() and c() are function calls like
> (almost) everything else.)
>



From gcendoya at balcarce.inta.gov.ar  Mon Sep  1 13:54:55 2003
From: gcendoya at balcarce.inta.gov.ar (CENDOYA, Gabriela)
Date: Mon, 1 Sep 2003 08:54:55 -0300
Subject: [R] Gram-Schmidt orthonormal factorization
Message-ID: <000801c3707f$dccebe40$6500fd0a@gcendoya.balcarce.inta.gov.ar>

Hi:

Does R have a function as gsorth is SAS, that perform a the Gram-Schmidt
orthonormal factorization of the m ?n matrix A, where m is greater than or
equal to n? That is, the GSORTH subroutine in SAS computes the
column-orthonormal m ?n matrix P and the upper triangular n ?n matrix T such
that A = P*T.

or any other version of Gram-Schmidt orthonormal factorization?

I search the help, but I didn?t find any thing about.

Thanks, Gabriela

PD: I am using R 1.7.1, for Windows 98.



From roger at ysidro.econ.uiuc.edu  Mon Sep  1 14:59:58 2003
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Mon, 1 Sep 2003 07:59:58 -0500 (CDT)
Subject: [R] Quantile Regression Packages    
Message-ID: <Pine.SOL.4.30.0308290732330.18111-100000@ysidro.econ.uiuc.edu>


I'd like to mention that there is a new quantile regression package
"nprq" on CRAN for additive nonparametric quantile regression estimation.
Models are structured similarly to the gss package of Gu and the mgcv
package of Wood.  Formulae like

	y ~ qss(z1) + qss(z2) +  X

are interpreted as a partially linear model in the covariates of X,
with nonparametric components defined as functions of z1 and z2.
Rather than estimating conditional mean functions, conditional
quantile functions are estimated using penalty methods.

When z1 is univariate fitting is based on the total variation
penalty methods described in Koenker, Ng and Portnoy (Biometrika, 1994).
When z2 is bivariate fitting is based on the  total variation penalty
(triogram) methods described in Koenker and Mizera (2003), available at
http://www.econ.uiuc.edu/~roger/research/goniolatry/gon.html and
forthcoming in JRSS(B).

There are options to constrain the qss components to be monotone and/or
convex/concave for univariate components, and to be convex/concave
for bivariate components.  Fitting is done by new sparse implementations
of the dense interior point (Frisch-Newton) algorithms already available
in the package quantreg.

The new package "nprq" thus supplements the existing packages
"quantreg" and "nlrq" that can be used for linear and nonlinear
parametric quantile regression fitting respectively.  In particular,
"nprq" provides general fitting functions for quantile regression
problems with sparse design matrices paralleling the functionality of
least squares function slm() in the SparseM package.

There has also been some recent updating of the quantreg package, which
now includes some functionality for resampling based inference methods.

The package "nprq" is joint work with Pin Ng of Northern Arizona University.

Comments and suggestions, as always,  would be most welcome.

url:	www.econ.uiuc.edu/~roger/my.html	Roger Koenker
email	rkoenker at uiuc.edu			Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820



From krcabrer at unalmed.edu.co  Mon Sep  1 15:08:10 2003
From: krcabrer at unalmed.edu.co (Kenneth Cabrera)
Date: Mon, 01 Sep 2003 08:08:10 -0500
Subject: [R] Gram-Schmidt orthonormal factorization
In-Reply-To: <000801c3707f$dccebe40$6500fd0a@gcendoya.balcarce.inta.gov.ar>
References: <000801c3707f$dccebe40$6500fd0a@gcendoya.balcarce.inta.gov.ar>
Message-ID: <oprutn3wdwfaouaq@200.24.8.4>

See ?qr
and
http://ikpe1101.ikp.kfa-juelich.de/briefbook_data_analysis/node224.html

Note the compact form of how QR decomposition in R works.

On Mon, 01 Sep 2003 08:54:55 -0300, CENDOYA, Gabriela 
<gcendoya at balcarce.inta.gov.ar> wrote:

> Hi:
>
> Does R have a function as gsorth is SAS, that perform a the Gram-Schmidt
> orthonormal factorization of the m ?n matrix A, where m is greater than 
> or
> equal to n? That is, the GSORTH subroutine in SAS computes the
> column-orthonormal m ?n matrix P and the upper triangular n ?n matrix T 
> such
> that A = P*T.
>
> or any other version of Gram-Schmidt orthonormal factorization?
>
> I search the help, but I didn?t find any thing about.
>
> Thanks, Gabriela
>
> PD: I am using R 1.7.1, for Windows 98.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



--



From Jan.Verbesselt at agr.kuleuven.ac.be  Mon Sep  1 16:00:27 2003
From: Jan.Verbesselt at agr.kuleuven.ac.be (Jan Verbesselt)
Date: Mon, 1 Sep 2003 16:00:27 +0200
Subject: [R] readcsvIts() to create irregular time series
Message-ID: <000001c37091$65c9d200$1145210a@agr.ad10.intern.kuleuven.ac.be>

Dear,

Thanks for the previous tips about 'its' for importing the following
data.
5/10/1998,7
5/11/1998,5
5/12/1998,2
5/14/1998,1
5/15/1998,1
5/19/1998,1
5/20/1998,1

1. When using the following command;
test<-readcsvIts('Fires98.csv',informat=its.format("%m/%d/%Y"),header=FA
LSE)

the function reads in the data from the csv file as;
           V2
05/10/1998  7
05/11/1998  5

When testing if it's a its object
is.its(test) 
the result is FALSE.
When do you use informat or outformat? 
What goes wrong?

2. When reading in the data as a table;
m1 <- read.table('Fires98.csv',header=FALSE, sep=",", dec=".")
          V1 V2
1  5/10/1998  7
2  5/11/1998  5
...
test2 <- its(m1,dates=as.POSIXct(x=strptime(dimnames(V1)[[1]]
format=its.format("%m/%d/%Y"))) )...Doesn't work! 

I have difficulties defining the first V1 column as its object.

Thanks in advance for helping me out,
Jan



________________________________________________________________________
__
Jan Verbesselt 
Research Associate 
Lab of Geomatics and Forest Engineering K.U. Leuven
Vital Decosterstraat 102. B-3000 Leuven Belgium 
Tel:+32-16-329750 
Fax: +32-16-329760
http://perswww.kuleuven.ac.be/~u0027178/VCard/mycard.php?name=janv
http://gloveg.kuleuven.ac.be/
________________________________________________________________________
__



From eric.esposito at gazdefrance.com  Mon Sep  1 17:03:55 2003
From: eric.esposito at gazdefrance.com (Eric ESPOSITO)
Date: Mon, 1 Sep 2003 16:03:55 +0100
Subject: [R] Arima with an external regressor
Message-ID: <OFC1554D9B.41C9E248-ON41256D94.00518FDF@notes.edfgdf.fr>

Hello,
Does anybody know if the function arima with an external regressor (xreg)
applies the auto correlation on the dependant variable or on the residuals.
In comparison with SAS (proc autoreg), it seems that the auto correlation
applies on the residuals but i'd like to have the confirmation.

I want to estimate:
Y[t] = a[1]*X[t] + a[2] + E[t]
with E[t]=b[1]*E[t-1]

Should I use :
arima(Y, xreg=X, order=c(1,0,0))          or rather              arima(Y,
xreg=X, order=c(0,0,1))
And what is the exact equation of the estimating model:
Y[t] = a[1]*X[t] + a[2] + E[t] + b[1]*E[t-1]     or       Y[t] = a[1]*X[t]
+ a[2] + b[1]*E[t-1]
where a[1], a[2] and b[1] are the coefficients returned by the arima
function

Thank you,
Eric Esposito



From ripley at stats.ox.ac.uk  Mon Sep  1 16:19:05 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 1 Sep 2003 15:19:05 +0100 (BST)
Subject: [R] Arima with an external regressor
In-Reply-To: <OFC1554D9B.41C9E248-ON41256D94.00518FDF@notes.edfgdf.fr>
Message-ID: <Pine.LNX.4.44.0309011516440.21892-100000@gannet.stats>

It's stated on the help page, and it is neither.

Maybe SAS does use `residuals' but `errors' as on the R page is the 
correct term.

What was the problem with doing ?arima?  Unlike SAS, you have the source 
code to read too.

On Mon, 1 Sep 2003, Eric ESPOSITO wrote:

> Does anybody know if the function arima with an external regressor (xreg)
> applies the auto correlation on the dependant variable or on the residuals.
> In comparison with SAS (proc autoreg), it seems that the auto correlation
> applies on the residuals but i'd like to have the confirmation.
> 
> I want to estimate:
> Y[t] = a[1]*X[t] + a[2] + E[t]
> with E[t]=b[1]*E[t-1]
> 
> Should I use :
> arima(Y, xreg=X, order=c(1,0,0))          or rather              arima(Y,
> xreg=X, order=c(0,0,1))
> And what is the exact equation of the estimating model:
> Y[t] = a[1]*X[t] + a[2] + E[t] + b[1]*E[t-1]     or       Y[t] = a[1]*X[t]
> + a[2] + b[1]*E[t-1]
> where a[1], a[2] and b[1] are the coefficients returned by the arima
> function

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Giles.Heywood at CommerzbankIB.com  Mon Sep  1 16:43:50 2003
From: Giles.Heywood at CommerzbankIB.com (Heywood, Giles)
Date: Mon, 1 Sep 2003 15:43:50 +0100 
Subject: [R] readcsvIts() to create irregular time series
Message-ID: <8CBAA121CEB4D5118CB200508BB2BBEF540481@xmx8lonib.lonib.commerzbank.com>

Jan

The function readcsvIts reads a csv file into a matrix.  To convert 
the matrix into an 'its', apply the its function to the matrix.

So for your example

its.format("%m/%d/%Y")
test? <- its(readcsvIts(filename))
is.its(test)

"TRUE"

The its documentation for readcsvIts states incorrectly that an 'its'
object is returned, so your confusion is understandable.  I will correct 
this in the next release.

Giles

> -----Original Message-----
> From: Jan Verbesselt [mailto:Jan.Verbesselt at agr.kuleuven.ac.be]
> Sent: 01 September 2003 15:00
> To: r-help at stat.math.ethz.ch
> Subject: [R] readcsvIts() to create irregular time series
> 
> 
> Dear,
> 
> Thanks for the previous tips about 'its' for importing the following
> data.
> 5/10/1998,7
> 5/11/1998,5
> 5/12/1998,2
> 5/14/1998,1
> 5/15/1998,1
> 5/19/1998,1
> 5/20/1998,1
> 
> 1. When using the following command;
> test<-readcsvIts('Fires98.csv',informat=its.format("%m/%d/%Y")
> ,header=FA
> LSE)
> 
> the function reads in the data from the csv file as;
>            V2
> 05/10/1998  7
> 05/11/1998  5
> 
> When testing if it's a its object
> is.its(test) 
> the result is FALSE.
> When do you use informat or outformat? 
> What goes wrong?
> 
> 2. When reading in the data as a table;
> m1 <- read.table('Fires98.csv',header=FALSE, sep=",", dec=".")
>           V1 V2
> 1  5/10/1998  7
> 2  5/11/1998  5
> ...
> test2 <- its(m1,dates=as.POSIXct(x=strptime(dimnames(V1)[[1]]
> format=its.format("%m/%d/%Y"))) )...Doesn't work! 
> 
> I have difficulties defining the first V1 column as its object.
> 
> Thanks in advance for helping me out,
> Jan
> 
> 
> 
> ______________________________________________________________
> __________
> __
> Jan Verbesselt 
> Research Associate 
> Lab of Geomatics and Forest Engineering K.U. Leuven
> Vital Decosterstraat 102. B-3000 Leuven Belgium 
> Tel:+32-16-329750 
> Fax: +32-16-329760
> http://perswww.kuleuven.ac.be/~u0027178/VCard/mycard.php?name=janv
> http://gloveg.kuleuven.ac.be/
> ______________________________________________________________
> __________
> __
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


********************************************************************** 
This is a commercial communication from Commerzbank AG.\ \ T...{{dropped}}



From solares at unsl.edu.ar  Mon Sep  1 16:42:30 2003
From: solares at unsl.edu.ar (solares@unsl.edu.ar)
Date: Mon, 1 Sep 2003 11:42:30 -0300 (ART)
Subject: [R] Axis color
Message-ID: <36322.170.210.173.216.1062427350.squirrel@inter14.unsl.edu.ar>

Hello, my question is if I have two axes in a graphics as I can put him a 
different color al axis and to the number of the scale. ? Thanks. Ruben



From Sofiane.Lariani at rdls.nestle.com  Mon Sep  1 17:43:37 2003
From: Sofiane.Lariani at rdls.nestle.com (Lariani,Sofiane,LAUSANNE,NRC/BAS)
Date: Mon, 1 Sep 2003 17:43:37 +0200 
Subject: [R] How to free memory used by R. 
Message-ID: <EF9E44B0F76FDB4396B9EF18A66545EDF5D2E6@CHLSNE01.nestle.com>

Hi,
I want to free memory used by R. The usage of rm and gc give no result. I'm
running  an algorithm consuming a huge memory and I need to recover the
memory used by R between 2 call of my algorithm.
Thank you in advance for your help.

e-mail: sofiane.lariani at rdls.nestle.com

Sofiane Lariani



From sumslily at yahoo.com  Mon Sep  1 18:05:18 2003
From: sumslily at yahoo.com (Lily)
Date: Mon, 1 Sep 2003 09:05:18 -0700 (PDT)
Subject: [R] help for performing regressions based on combination of
	predictors
In-Reply-To: <3F527253.19068.1179ED3@localhost>
Message-ID: <20030901160518.24681.qmail@web41206.mail.yahoo.com>

Thank you for your help. I just tried "leaps".
However, I still need to know the regression
coefficients for each regression. Seems leaps 
doesn't provided the coefficients.

Lily
--- kjetil brinchmann halvorsen <kjetil at entelnet.bo>
wrote:
> On 31 Aug 2003 at 18:06, Lily wrote:
> 
> 
> Have you tried 
> library(leaps)
> library(help=leaps)
> ?
> 
> Kjetil Halvorsen
> 
> > Dear All,
> > 
> > I would like to perform linear regressions based
> on Y
> > and all of the combinations of the five
> predictors,
> >
>
i.e.,(y,x1,x2),(y,x1,x3),....,(y,x1,x2,x4,x5),....,(y,x1,x2,x3,x4,x5).
> > 
> > Is there any quick way to do it instead of repeat
> > performing regressions for 31 times? Or, is there 
> > any method to manipulate the dataset into the 31
> > combinations?
> > 
> > Thanks for your help!
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> >
>
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
>



From Jan.Verbesselt at agr.kuleuven.ac.be  Mon Sep  1 18:59:23 2003
From: Jan.Verbesselt at agr.kuleuven.ac.be (Jan Verbesselt)
Date: Mon, 1 Sep 2003 18:59:23 +0200
Subject: [R] readcsvIts() to create irregular time series
In-Reply-To: <8CBAA121CEB4D5118CB200508BB2BBEF540481@xmx8lonib.lonib.commerzbank.com>
Message-ID: <000001c370aa$652c7730$1145210a@agr.ad10.intern.kuleuven.ac.be>

Thanks for the quick help,

It works now!

> Fire   <-
its(readcsvIts('Fires98_2002.csv',informat=its.format("%m/%d/%Y"),header
=TRUE))
> is.its(Fire)
[1] TRUE

BUT;
1. What can you do with informat and outformat? Is it the same as
its.format() before the its function?

2. Can the its be plotted onto a ts? And is a correlation analysis in
between the two objects possible?

 > Timeserie
Time Series:
Start = c(1998, 10) 
End = c(2001, 36) 
Frequency = 36 
              V2
  [1,] 0.8021540
  [2,] 0.7862612

plot(Timeserie, ylim=c(0.4, 7))
lines(Fire, col=2, type="S")
?

Thanks again for your help,
Jan


-----Original Message-----
From: Heywood, Giles [mailto:Giles.Heywood at CommerzbankIB.com] 
Sent: Monday, September 01, 2003 4:44 PM
To: 'r-help at stat.math.ethz.ch'
Cc: 'Jan Verbesselt'
Subject: RE: [R] readcsvIts() to create irregular time series

Jan

The function readcsvIts reads a csv file into a matrix.  To convert 
the matrix into an 'its', apply the its function to the matrix.

So for your example

its.format("%m/%d/%Y")
test- <- its(readcsvIts(filename))
is.its(test)

"TRUE"



From johannes.huesing at medizin.uni-essen.de  Mon Sep  1 19:02:49 2003
From: johannes.huesing at medizin.uni-essen.de (=?iso-8859-1?Q?=22H=FCsing=2C_Johannes=22?=)
Date: Mon, 1 Sep 2003 19:02:49 +0200
Subject: [R] error message in nlm()
Message-ID: <B3A80C9C13928B45B2FCE4C43656363A2DE5FC@mail-srv02.master.medizin.uni-essen.de>

Hi all,

I have been trying the nlm function but received an error message
which reads:

Error in nlm(intensities ~ f, c(epsilon.spec.start,
epsilon.unspec.start,  : 
	invalid function value in 'nlm' optimizer

The message is generated somewhere in the compiled part, apparently 
within the function 

static void fcn(int n, const double x[], double *f, function_info
		*state)

where a jump to a "badvalue" label is caused on different conditions:

- if the type of a value generated from the call from R is neither of 
  type INTSXP nor REALSXP,
- if the length of this value is not 1.

The error message is issued after the second call to the function that 
nlm minimizes over.

Could you give any suggestions on what I could be mishandling?

Best wishes


Johannes



From tblackw at umich.edu  Mon Sep  1 19:38:24 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Mon, 1 Sep 2003 13:38:24 -0400 (EDT)
Subject: [R] How to free memory used by R. 
In-Reply-To: <EF9E44B0F76FDB4396B9EF18A66545EDF5D2E6@CHLSNE01.nestle.com>
Message-ID: <Pine.SOL.4.44.0309011322500.3066-100000@rygar.gpcc.itd.umich.edu>

On Mon, 1 Sep 2003, Lariani,Sofiane,LAUSANNE,NRC/BAS wrote:

> I want to free memory used by R. The usage of rm and gc give no result. I'm
> running  an algorithm consuming a huge memory and I need to recover the
> memory used by R between 2 call of my algorithm.
> Thank you in advance for your help.
>
> e-mail: sofiane.lariani at rdls.nestle.com
>
> Sofiane Lariani

What operating system and what version of R, please ?

Other people will have a much better understanding of the
details here than I have, but here goes.

The fact that you ask this question suggests that you are
running the unnamed, memory intensive algorithm inside a loop.
It's my understanding that  gc()  is called automatically
every time control comes back to the command line prompt.
So, gc() is only an issue inside a loop.  You might TRY
writing a wrapper function:

my.algorithm <- function(...) {
   algorithm(...)
   gc()           }

and call the wrapper rather than  algorithm()  directly,
inside the loop.  Chances are this won't help, because
the loop will try to keep intermediate results.
(At least it used to do this in old Splus prior to 1990.)

If nothing else works, do as we all used to do prior to 1990.
Write a batch script which does one iteration of the algorithm
and saves just the intermediate results you want.  Then write
a shell script (I assume you're using a version of unix) that
simply runs  R BATCH scriptname logfile  again and again, one
call for each iteration of the loop.  This guarantees that
nothing is saved except what you specify.  (It's clunky, yes,
but this works when nothing else will.)  Alternatively, you
may have access to a machine with more memory.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -



From tlumley at u.washington.edu  Mon Sep  1 19:42:06 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 1 Sep 2003 10:42:06 -0700 (PDT)
Subject: [R] How to free memory used by R. 
In-Reply-To: <EF9E44B0F76FDB4396B9EF18A66545EDF5D2E6@CHLSNE01.nestle.com>
Message-ID: <Pine.A41.4.44.0309011038430.112236-100000@homer12.u.washington.edu>

On Mon, 1 Sep 2003, Lariani,Sofiane,LAUSANNE,NRC/BAS wrote:

> Hi,
> I want to free memory used by R. The usage of rm and gc give no result. I'm
> running  an algorithm consuming a huge memory and I need to recover the
> memory used by R between 2 call of my algorithm.
> Thank you in advance for your help.

There is no portable way (and often no way at all) for a program to return
memory to the operating system.

On the other hand, a competent virtual memory system will page unused
memory to disk fairly quickly, which has more or less the same effect
unless you are short of disk space.

	-thomas



From tblackw at umich.edu  Mon Sep  1 19:43:38 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Mon, 1 Sep 2003 13:43:38 -0400 (EDT)
Subject: [R] error message in nlm()
In-Reply-To: <B3A80C9C13928B45B2FCE4C43656363A2DE5FC@mail-srv02.master.medizin.uni-essen.de>
Message-ID: <Pine.SOL.4.44.0309011339220.3066-100000@rygar.gpcc.itd.umich.edu>

Johannes  -

There's something special about the way control parameters are
accepted by  nlm() and nlme().  Try searching very recent help
archives for nlme() or control.  Try duplicating exactly one of
the examples at the bottom of the help page  help("nlm").  My
recollection is that the parameter that you actually pass has
to be literally a function, maybe one with a specific name.
But that's jsut vague recollection.  Others will have better
information.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Mon, 1 Sep 2003, [iso-8859-1] "Hüsing, Johannes" wrote:

> I have been trying the nlm function but received an error message
> which reads:
>
> Error in nlm(intensities ~ f, c(epsilon.spec.start,
> epsilon.unspec.start,  :
> 	invalid function value in 'nlm' optimizer
>
> The error message is issued after the second call to the function that
> nlm minimizes over.
>
> Could you give any suggestions on what I could be mishandling?
> Johannes



From ripley at stats.ox.ac.uk  Mon Sep  1 19:50:24 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 1 Sep 2003 18:50:24 +0100 (BST)
Subject: [R] How to free memory used by R. 
In-Reply-To: <Pine.SOL.4.44.0309011322500.3066-100000@rygar.gpcc.itd.umich.edu>
Message-ID: <Pine.LNX.4.44.0309011843000.22462-100000@gannet.stats>

On Mon, 1 Sep 2003, Thomas W Blackwell wrote:

> On Mon, 1 Sep 2003, Lariani,Sofiane,LAUSANNE,NRC/BAS wrote:
> 
> > I want to free memory used by R. The usage of rm and gc give no result. I'm
> > running  an algorithm consuming a huge memory and I need to recover the
> > memory used by R between 2 call of my algorithm.

What was the exact error message behind this?

> > Thank you in advance for your help.
> >
> > e-mail: sofiane.lariani at rdls.nestle.com
> >
> > Sofiane Lariani
> 
> What operating system and what version of R, please ?

Yes, please?

> Other people will have a much better understanding of the
> details here than I have, but here goes.
> 
> The fact that you ask this question suggests that you are
> running the unnamed, memory intensive algorithm inside a loop.
> It's my understanding that  gc()  is called automatically
> every time control comes back to the command line prompt.
> So, gc() is only an issue inside a loop.  You might TRY
> writing a wrapper function:
> 
> my.algorithm <- function(...) {
>    algorithm(...)
>    gc()           }
> 
> and call the wrapper rather than  algorithm()  directly,
> inside the loop.  Chances are this won't help, because
> the loop will try to keep intermediate results.
> (At least it used to do this in old Splus prior to 1990.)

Not in R (and S-PLUS only existed went on sale in about 1988).
Unless there is a bug or a memory leak, gc() is called whenever a naive 
attempt to get memory fails.  There are various levels of gc(), and they 
are all tried.  So when R reports it is short of memory, it is unable to 
free up enough of the memory it has for the needed memory, and all objects 
not currently in use have been deleted.

If you want a lot of memory for a single object then it has to be 
contiguous.  R no longer compacts objects, so it can become increasingly 
hard to get large chunks of memory as the loop runs.

> If nothing else works, do as we all used to do prior to 1990.
> Write a batch script which does one iteration of the algorithm
> and saves just the intermediate results you want.  Then write
> a shell script (I assume you're using a version of unix) that
> simply runs  R BATCH scriptname logfile  again and again, one
> call for each iteration of the loop.  This guarantees that
> nothing is saved except what you specify.  (It's clunky, yes,
> but this works when nothing else will.)  

That's true of S, but not I think of R (or at least the memory reduction 
is very small).  We say For loops are not implemented in R because they 
are not needed, and For loops automate this.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Sep  1 19:54:17 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 1 Sep 2003 18:54:17 +0100 (BST)
Subject: [R] How to free memory used by R. 
In-Reply-To: <Pine.A41.4.44.0309011038430.112236-100000@homer12.u.washington.edu>
Message-ID: <Pine.LNX.4.44.0309011850300.22462-100000@gannet.stats>

On Mon, 1 Sep 2003, Thomas Lumley wrote:

> On Mon, 1 Sep 2003, Lariani,Sofiane,LAUSANNE,NRC/BAS wrote:
> 
> > Hi,
> > I want to free memory used by R. The usage of rm and gc give no result. I'm
> > running  an algorithm consuming a huge memory and I need to recover the
> > memory used by R between 2 call of my algorithm.
> > Thank you in advance for your help.
> 
> There is no portable way (and often no way at all) for a program to return
> memory to the operating system.
> 
> On the other hand, a competent virtual memory system will page unused
> memory to disk fairly quickly, which has more or less the same effect
> unless you are short of disk space.

Or short of address space.  This is an increasing issue for 32-bit 
machines: you can have 100Gb of disc space, but the per-process address 
space may only be 2-4Gb.  It's certainly the limit running R under 
Windows.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jimingyu at princeton.edu  Mon Sep  1 23:26:43 2003
From: jimingyu at princeton.edu (Jiming Yu)
Date: Mon, 1 Sep 2003 14:26:43 -0700
Subject: [R] File Reading Problem
Message-ID: <002701c370cf$bd850b20$46a2b48c@princeton2cze9>

Dear all,
    I am trying to read characters byte by byte(in their ASCII codes) from a
file(already transferred from text file to a file of ASCII codes, by C
language). I am using scan() function. But it seems that this is impossible.
    If I read data as 'character' type, data are read word by word,
separated by spaces(though in default setting, sep=""). e.g. if a file
contains "This is a book.", Then it reads "This", "is", "a", "book.", not
"T", "h", "i", "s", etc(as I wanted it to).
    If I read data as 'integer' type from the file which contains all ASCII
codes of the original file, e.g. if a file contains "This is a book.", Then
it reads "T", " ", "i", " ", "a", " " , "b", which are initials of all words
and all spaces, not "T", "h", "i", "s", etc(as I wanted it to).
    If anybody has a solution, please let me know. I'd really appreciate
your help. Thank you very much!
                Jiming



Jiming Yu
Information Sciences and Systems Group
Department of Electrical Engineering
Princeton University

Email:  jimingyu at princeton.edu
Office:  609-258-4634
Cell:     609-933-6850



From ripley at stats.ox.ac.uk  Mon Sep  1 20:47:48 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 1 Sep 2003 19:47:48 +0100 (BST)
Subject: [R] File Reading Problem
In-Reply-To: <002701c370cf$bd850b20$46a2b48c@princeton2cze9>
Message-ID: <Pine.LNX.4.44.0309011945470.22603-100000@gannet.stats>

?readBin  will do what you want.  If the file is really a set of lines, 
you could use readLines() followed by strsplit().

See also the R Data Import/Export manual.

On Mon, 1 Sep 2003, Jiming Yu wrote:

> Dear all,
>     I am trying to read characters byte by byte(in their ASCII codes) from a
> file(already transferred from text file to a file of ASCII codes, by C
> language). I am using scan() function. But it seems that this is impossible.
>     If I read data as 'character' type, data are read word by word,
> separated by spaces(though in default setting, sep=""). e.g. if a file
> contains "This is a book.", Then it reads "This", "is", "a", "book.", not
> "T", "h", "i", "s", etc(as I wanted it to).
>     If I read data as 'integer' type from the file which contains all ASCII
> codes of the original file, e.g. if a file contains "This is a book.", Then
> it reads "T", " ", "i", " ", "a", " " , "b", which are initials of all words
> and all spaces, not "T", "h", "i", "s", etc(as I wanted it to).
>     If anybody has a solution, please let me know. I'd really appreciate
> your help. Thank you very much!

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From den.duurs at lycos.com  Mon Sep  1 22:04:02 2003
From: den.duurs at lycos.com (Remko Duursma)
Date: Mon, 01 Sep 2003 13:04:02 -0700
Subject: [R] meta-analysis question
Message-ID: <AJJKCCLPKIKCMCAA@mailcity.com>

Dear R-helpers,

i have the following situation: i have a bunch of y=b0 + b1*x from different studies, and want to estimate a "general" y=f(x). I only have the b0,b1's and R-squareds. Should i weigh the separate equations by their R-squared? 

thanks

Remko


^'~,_,~'^'~,_,~'^'~,_,~'^'~,_,~'^'~,_,~'^'~,_,~'
Remko Duursma, Ph.D. student
Forest Biometrics Lab / Idaho Stable Isotope Lab
University of Idaho, Moscow, ID, U.S.A.



From kwan022 at stat.auckland.ac.nz  Mon Sep  1 22:16:49 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Tue, 2 Sep 2003 08:16:49 +1200 (NZST)
Subject: [R] Axis color
In-Reply-To: <36322.170.210.173.216.1062427350.squirrel@inter14.unsl.edu.ar>
Message-ID: <Pine.LNX.4.44.0309020815570.32667-100000@stat55.stat.auckland.ac.nz>

See ?axis

On Mon, 1 Sep 2003 solares at unsl.edu.ar wrote:

> Date: Mon, 1 Sep 2003 11:42:30 -0300 (ART)
> From: solares at unsl.edu.ar
> To: R-help at stat.math.ethz.ch
> Subject: [R] Axis color
> 
> Hello, my question is if I have two axes in a graphics as I can put him a 
> different color al axis and to the number of the scale. ? Thanks. Ruben
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
"On two occasions, I have been asked [by members of Parliament],
'Pray, Mr. Babbage, if you put into the machine wrong figures, will
the right answers come out?' I am not able to rightly apprehend the
kind of confusion of ideas that could provoke such a question."

-- Charles Babbage (1791-1871) 
---- From Computer Stupidities: http://rinkworks.com/stupid/

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)



From Kurt.Sys at UGent.be  Mon Sep  1 22:18:40 2003
From: Kurt.Sys at UGent.be (Kurt Sys)
Date: Mon,  1 Sep 2003 22:18:40 +0200
Subject: [R] help file extension
In-Reply-To: <B3A80C9C13928B45B2FCE4C43656363A2DE5FC@mail-srv02.master.medizin.uni-essen.de>
References: <B3A80C9C13928B45B2FCE4C43656363A2DE5FC@mail-srv02.master.medizin.uni-essen.de>
Message-ID: <1062447520.3f53a9a0651e8@mail.ugent.be>

Hi all,

I've been struggling with the following problem... Normally, if you build a 
package, the help files are created automatically (by 'converting' the Rd-files)
in pdf- and/or html-format. I have some additional information, about the 
general purpose and how-to-use of the package, actually, it's a scheme. This is 
made in LaTeX. Can anyone give me a clue of how to include this scheme (and some 
text) in the pdf- (and probably html-)help files while building the package?

tnx,
Kurt.



From dmurdoch at pair.com  Mon Sep  1 22:32:26 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon, 01 Sep 2003 16:32:26 -0400
Subject: [R] File Reading Problem
In-Reply-To: <002701c370cf$bd850b20$46a2b48c@princeton2cze9>
References: <002701c370cf$bd850b20$46a2b48c@princeton2cze9>
Message-ID: <9r47lv039hoacvfe5pkhc82m0kkdkl85jb@4ax.com>

On Mon, 1 Sep 2003 14:26:43 -0700, "Jiming Yu"
<jimingyu at princeton.edu> wrote:

>Dear all,
>    I am trying to read characters byte by byte(in their ASCII codes) from a
>file

I was going to suggest using readBin, but there seems to be a bug:

> con <- file('c:/test.txt','rb')
> readBin(con,'c',15,1)
stack imbalance in internal readBin, 9 then 8stack imbalance in
.Internal, 8 then 7
stack imbalance in {, 6 then 5
NULL
Error: unprotect(): stack imbalance

This was in today's r-devel build for Windows, but the bug also shows
up in 1.7.1.  I'll look into it.

Duncan Murdoch



From bates at stat.wisc.edu  Mon Sep  1 22:36:41 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 01 Sep 2003 20:36:41 -0000
Subject: [R] help file extension
In-Reply-To: <1062447520.3f53a9a0651e8@mail.ugent.be>
References: <B3A80C9C13928B45B2FCE4C43656363A2DE5FC@mail-srv02.master.medizin.uni-essen.de>
	<1062447520.3f53a9a0651e8@mail.ugent.be>
Message-ID: <6rd6ek1c00.fsf@bates4.stat.wisc.edu>

Perhaps you could make this a vignette?  See the section "Writing
package vignettes" in the manual "Writing R Extensions".

Kurt Sys <Kurt.Sys at ugent.be> writes:

> Hi all,
> 
> I've been struggling with the following problem... Normally, if you build a 
> package, the help files are created automatically (by 'converting' the Rd-files)
> in pdf- and/or html-format. I have some additional information, about the 
> general purpose and how-to-use of the package, actually, it's a scheme. This is 
> made in LaTeX. Can anyone give me a clue of how to include this scheme (and some 
> text) in the pdf- (and probably html-)help files while building the package?
> 
> tnx,
> Kurt.



From jimingyu at princeton.edu  Tue Sep  2 01:54:54 2003
From: jimingyu at princeton.edu (Jiming Yu)
Date: Mon, 1 Sep 2003 16:54:54 -0700
Subject: [R] File Reading Problem
References: <Pine.LNX.4.44.0309011945470.22603-100000@gannet.stats>
Message-ID: <001801c370e4$70e36130$46a2b48c@princeton2cze9>

    Thank you very much. I think it's working by using:

mytry<-readBin("Source.txt", n=2325120, size=1, what="int")

    where n is the maximum size of the text file. So there may be no big
bugs here.
    I'd really appreciate your help. Thanks.
                Jiming


----- Original Message -----
From: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
To: "Jiming Yu" <jimingyu at Princeton.EDU>
Cc: <r-help at stat.math.ethz.ch>; "Martin Maechler"
<maechler at stat.math.ethz.ch>
Sent: Monday, September 01, 2003 11:47 AM
Subject: Re: [R] File Reading Problem


> ?readBin  will do what you want.  If the file is really a set of lines,
> you could use readLines() followed by strsplit().
>
> See also the R Data Import/Export manual.
>
> On Mon, 1 Sep 2003, Jiming Yu wrote:
>
> > Dear all,
> >     I am trying to read characters byte by byte(in their ASCII codes)
from a
> > file(already transferred from text file to a file of ASCII codes, by C
> > language). I am using scan() function. But it seems that this is
impossible.
> >     If I read data as 'character' type, data are read word by word,
> > separated by spaces(though in default setting, sep=""). e.g. if a file
> > contains "This is a book.", Then it reads "This", "is", "a", "book.",
not
> > "T", "h", "i", "s", etc(as I wanted it to).
> >     If I read data as 'integer' type from the file which contains all
ASCII
> > codes of the original file, e.g. if a file contains "This is a book.",
Then
> > it reads "T", " ", "i", " ", "a", " " , "b", which are initials of all
words
> > and all spaces, not "T", "h", "i", "s", etc(as I wanted it to).
> >     If anybody has a solution, please let me know. I'd really appreciate
> > your help. Thank you very much!
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>



From spencer.graves at pdf.com  Mon Sep  1 22:50:04 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 01 Sep 2003 13:50:04 -0700
Subject: [R] meta-analysis question
References: <AJJKCCLPKIKCMCAA@mailcity.com>
Message-ID: <3F53B0FC.1040609@pdf.com>

	Can you get the covariance matrices of the vectors b = c(b0, b1)? 
There is a reasonable literature on meta-analysis with which I'm not 
very familiar.  However, a standard thing to do is to compute a weighted 
average with weights proportional to the inverse of the covariance 
matrices, while testing to evaluate whether the b's plausibly all 
estimate the same thing.

	  The theory is as follows:  Suppose b.i ~ N.k(mu, Sig.i), i = 1, 2, 
..., n.  If you have a covariance matrix for each vector b.i, then you 
have this set-up.  Assuming you do have (or can approximate) Sig.i, then

	  l.i = log(likelihood(b.i)) = 
(-0.5)*(k*log(2*pi)+log(det(Sig.i))+t(b.i-mu)%*%solve(Sig.i, (b.i-mu))).

The first derivative of l.i with respect to mu is as follows:

	  D.l.i = solve(Sig.i, (x.i-mu)).

	  The solution for mu of sum(D.l.i)=0 is as follows:

	  mu.hat = solve(sum(Sig.i), sum(solve(Sig.i, (x.i-mu)))).

	  One could also derive various statistics for evaluating whether it is 
plausible to believe that these b.i's all come from the same population. 
  I would assume that the literature on meta-analysis would deal with 
this, but I have not looked much at that literature, and I'll leave that 
question to others.

hope this helps.
spencer graves

Remko Duursma wrote:
> Dear R-helpers,
> 
> i have the following situation: i have a bunch of 
y=b0 + b1*x from different studies, and want to
estimate a "general" y=f(x). I only have the b0,b1's
and R-squareds. Should i weigh the separate equations
by their R-squared?
> 
> thanks
> 
> Remko
> 
> 
> ^'~,_,~'^'~,_,~'^'~,_,~'^'~,_,~'^'~,_,~'^'~,_,~'
> Remko Duursma, Ph.D. student
> Forest Biometrics Lab / Idaho Stable Isotope Lab
> University of Idaho, Moscow, ID, U.S.A.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From p.dalgaard at biostat.ku.dk  Mon Sep  1 22:55:13 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon, 01 Sep 2003 20:55:13 -0000
Subject: [R] File Reading Problem
In-Reply-To: <9r47lv039hoacvfe5pkhc82m0kkdkl85jb@4ax.com>
References: <002701c370cf$bd850b20$46a2b48c@princeton2cze9>
	<9r47lv039hoacvfe5pkhc82m0kkdkl85jb@4ax.com>
Message-ID: <x21xv0rzyf.fsf@biostat.ku.dk>

Duncan Murdoch <dmurdoch at pair.com> writes:

> On Mon, 1 Sep 2003 14:26:43 -0700, "Jiming Yu"
> <jimingyu at princeton.edu> wrote:
> 
> >Dear all,
> >    I am trying to read characters byte by byte(in their ASCII codes) from a
> >file
> 
> I was going to suggest using readBin, but there seems to be a bug:
> 
> > con <- file('c:/test.txt','rb')
> > readBin(con,'c',15,1)
> stack imbalance in internal readBin, 9 then 8stack imbalance in
> .Internal, 8 then 7
> stack imbalance in {, 6 then 5
> NULL
> Error: unprotect(): stack imbalance
> 
> This was in today's r-devel build for Windows, but the bug also shows
> up in 1.7.1.  I'll look into it.

It's not unique to windows:

> con <- file('FAQ','rb')
> readBin(con,'c',15,1)
stack imbalance in internal readBin, 9 then 8stack imbalance in
> .Internal, 8 then 7
stack imbalance in {, 6 then 5
NULL
Error: unprotect(): stack imbalance


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From kjetil at entelnet.bo  Mon Sep  1 23:07:42 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Mon, 01 Sep 2003 17:07:42 -0400
Subject: [R] meta-analysis question
In-Reply-To: <AJJKCCLPKIKCMCAA@mailcity.com>
Message-ID: <3F537CDE.6982.669B17@localhost>

On 1 Sep 2003 at 13:04, Remko Duursma wrote:

I guess NO. The R-squared's doesn? give information about the 
relative infoemation content in each study. 

Kjetil Halvorsen

> Dear R-helpers,
> 
> i have the following situation: i have a bunch of y=b0 + b1*x from different studies, and want to estimate a "general" y=f(x). I only have the b0,b1's and R-squareds. Should i weigh the separate equations by their R-squared? 
> 
> thanks
> 
> Remko
> 
> 
> ^'~,_,~'^'~,_,~'^'~,_,~'^'~,_,~'^'~,_,~'^'~,_,~'
> Remko Duursma, Ph.D. student
> Forest Biometrics Lab / Idaho Stable Isotope Lab
> University of Idaho, Moscow, ID, U.S.A.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From kjetil at entelnet.bo  Mon Sep  1 23:07:42 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Mon, 01 Sep 2003 17:07:42 -0400
Subject: [R] meta-analysis question
In-Reply-To: <AJJKCCLPKIKCMCAA@mailcity.com>
Message-ID: <3F537CDE.6982.669B17@localhost>

On 1 Sep 2003 at 13:04, Remko Duursma wrote:

I guess NO. The R-squared's doesn? give information about the 
relative infoemation content in each study. 

Kjetil Halvorsen

> Dear R-helpers,
> 
> i have the following situation: i have a bunch of y=b0 + b1*x from different studies, and want to estimate a "general" y=f(x). I only have the b0,b1's and R-squareds. Should i weigh the separate equations by their R-squared? 
> 
> thanks
> 
> Remko
> 
> 
> ^'~,_,~'^'~,_,~'^'~,_,~'^'~,_,~'^'~,_,~'^'~,_,~'
> Remko Duursma, Ph.D. student
> Forest Biometrics Lab / Idaho Stable Isotope Lab
> University of Idaho, Moscow, ID, U.S.A.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From dmurdoch at pair.com  Mon Sep  1 23:24:11 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon, 01 Sep 2003 17:24:11 -0400
Subject: [R] help file extension
In-Reply-To: <1062447520.3f53a9a0651e8@mail.ugent.be>
References: <B3A80C9C13928B45B2FCE4C43656363A2DE5FC@mail-srv02.master.medizin.uni-essen.de>
	<1062447520.3f53a9a0651e8@mail.ugent.be>
Message-ID: <o0e7lv8gedo0bu9lrn7ieg8mpegeptg8k1@4ax.com>

On Mon,  1 Sep 2003 22:18:40 +0200, you wrote:

>Hi all,
>
>I've been struggling with the following problem... Normally, if you build a 
>package, the help files are created automatically (by 'converting' the Rd-files)
>in pdf- and/or html-format. I have some additional information, about the 
>general purpose and how-to-use of the package, actually, it's a scheme. This is 
>made in LaTeX. Can anyone give me a clue of how to include this scheme (and some 
>text) in the pdf- (and probably html-)help files while building the package?

You can put additional documentation in a "doc" subdirectory, but it
won't be included in the automatically generated reference manual.  I
think the only way to do that is to put it in an Rd file.  Allowing
the user to easily include a general introduction at the start of that
file sounds like it would be a nice enhancement.

A somewhat commonly used convention is to put general package info
about package foo into foo.Rd, but in some cases (e.g. boot) this name
is already taken.

Duncan Murdoch



From p.silva at gmx.net  Mon Sep  1 22:47:40 2003
From: p.silva at gmx.net (Philip Silva)
Date: Mon, 01 Sep 2003 22:47:40 +0200
Subject: [R] Error in dyn.load
Message-ID: <3F53B06C.5010507@gmx.net>

Hi,

I've created a shared library from including this code (with g++ 
-I/usr/local/lib/R/include -I/usr/local/include -c Rtest.cpp; g++ 
-shared -L/usr/local/lib -o Rtest.so Rtest.cpp):
void check_data (SEXP data) {
	int l=length (data);
}

But when I try to load it in R I get this error message:
unable to load shared library ...
...
  undefined symbol: _Z9Rf_lengthP7SEXPREC

How can I solve this problem?

Philip



From dmurdoch at pair.com  Mon Sep  1 23:51:38 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon, 01 Sep 2003 17:51:38 -0400
Subject: [R] help file extension
In-Reply-To: <o0e7lv8gedo0bu9lrn7ieg8mpegeptg8k1@4ax.com>
References: <B3A80C9C13928B45B2FCE4C43656363A2DE5FC@mail-srv02.master.medizin.uni-essen.de>
	<1062447520.3f53a9a0651e8@mail.ugent.be>
	<o0e7lv8gedo0bu9lrn7ieg8mpegeptg8k1@4ax.com>
Message-ID: <tnf7lvooikqpo5f3e3rilu7i3j0hkp6m42@4ax.com>

On Mon, 01 Sep 2003 17:24:11 -0400, you wrote:


>You can put additional documentation in a "doc" subdirectory, 

That should be info/doc in the source...

>but it
>won't be included in the automatically generated reference manual. 

It will, however, be referenced in the HTML.  Doug Bates' pointer to
the vignettes section of the manual was very helpful!

Duncan Murdoch



From ripley at stats.ox.ac.uk  Mon Sep  1 23:57:07 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 1 Sep 2003 22:57:07 +0100 (BST)
Subject: [R] Error in dyn.load
In-Reply-To: <3F53B06C.5010507@gmx.net>
Message-ID: <Pine.LNX.4.44.0309012254350.23273-100000@gannet.stats>

Did you follow the instructions in Writing R Extensions?

You need to make sure you include the proper header files, as length
is a C and not C++ export from R.bin, and in any case it is remapped in R.

On Mon, 1 Sep 2003, Philip Silva wrote:

> Hi,
> 
> I've created a shared library from including this code (with g++ 
> -I/usr/local/lib/R/include -I/usr/local/include -c Rtest.cpp; g++ 
> -shared -L/usr/local/lib -o Rtest.so Rtest.cpp):
> void check_data (SEXP data) {
> 	int l=length (data);
> }
> 
> But when I try to load it in R I get this error message:
> unable to load shared library ...
> ...
>   undefined symbol: _Z9Rf_lengthP7SEXPREC
> 
> How can I solve this problem?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From bates at stat.wisc.edu  Tue Sep  2 00:16:52 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 01 Sep 2003 22:16:52 -0000
Subject: [R] help file extension
In-Reply-To: <tnf7lvooikqpo5f3e3rilu7i3j0hkp6m42@4ax.com>
References: <B3A80C9C13928B45B2FCE4C43656363A2DE5FC@mail-srv02.master.medizin.uni-essen.de>
	<1062447520.3f53a9a0651e8@mail.ugent.be>
	<o0e7lv8gedo0bu9lrn7ieg8mpegeptg8k1@4ax.com>
	<tnf7lvooikqpo5f3e3rilu7i3j0hkp6m42@4ax.com>
Message-ID: <6r7k4stapv.fsf@bates4.stat.wisc.edu>

Duncan Murdoch <dmurdoch at pair.com> writes:

> On Mon, 01 Sep 2003 17:24:11 -0400, you wrote:
> 
> 
> >You can put additional documentation in a "doc" subdirectory, 
> 
> That should be info/doc in the source...

I think you mean inst/doc



From tblackw at umich.edu  Tue Sep  2 00:20:12 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Mon, 1 Sep 2003 18:20:12 -0400 (EDT)
Subject: [R] Error in dyn.load
In-Reply-To: <3F53B06C.5010507@gmx.net>
Message-ID: <Pine.SOL.4.44.0309011807410.25175-100000@tetris.gpcc.itd.umich.edu>

Philip  -

Why not compile and load using the unix command line:

R CMD SHLIB <files>

rather than try to write your own compiler flags ?

See  help("SHLIB"),  help("COMPILE")  inside R.

You may have a good reason for NOT going the ordinary
route, but you need to tell us what it is.  And do try
the ordinary method for us, first, and please tell us
what difficulties you encounter there.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Mon, 1 Sep 2003, Philip Silva wrote:

> I've created a shared library from including this code
> (with g++ -I/usr/local/lib/R/include -I/usr/local/include -c Rtest.cpp;
> g++ -shared -L/usr/local/lib -o Rtest.so Rtest.cpp):
>
> void check_data (SEXP data) {
> 	int l=length (data);
> }
>
> But when I try to load it in R I get this error message:
> unable to load shared library ...
> ...
>   undefined symbol: _Z9Rf_lengthP7SEXPREC
>
> How can I solve this problem?
>
> Philip



From Matthew.Kelly at csiro.au  Tue Sep  2 00:28:09 2003
From: Matthew.Kelly at csiro.au (Matthew.Kelly@csiro.au)
Date: Tue, 2 Sep 2003 08:28:09 +1000
Subject: [R] RMySQL segmentation fault
Message-ID: <39B7E7009F2DD840AA747934AB551E69184776@exnsw1-arm.nsw.csiro.au>

Hello all,

Thanks to those who helped with my problem.

The problem posted to the list was as follows;

>I have been trying to use RMySQL but when I run the commands below I end up with a segmentation fault
> Note I can access the MySQL database as any MySQL user.  
> 
> If I and running after logging in as root then running R, the following works
> 
> > library(RMySQL)
> > m <- dbDriver("MySQL")
> > con <- dbConnect(m,host="acomputer",dbname="atable",user="au_ser",password="a_password")
> > rs <- dbSendQuery(con,statement="select * from flock")
> > data <- fetch(rs,n=-1)
> 
> If I run the same code as a normal user the following line fails with a segmentation fault
> con <- dbConnect(m,host="acomputer",dbname="atable",user="au_ser",password="a_password")
> 
> I have the following relevant software installed
> MySql 3.23.32 
> R-1.7.0
> RMySQL 0.5.2
> Redhat 7.0

The problem was fixed by upgrading Development and Client MySQL Packages to MySQL 4.0. (thanks to David James)

However the following fix was also suggested, and may be useful for people who cannot upgrade the mysql client.

I had the same problem and after running RMySQL with strace and playing around a bit, I found out, that - at least when using MySQL-client library 3.23.49 - RMySQL crashes, if there is a .my.cnf in your ~home, which contains more than just a plain [client]. The easiest workaround for me is just to rename or delete the .my.cnf. Seems to be a bug in the mysql-client library and not in the RMySQL package.(thanks to Holger Klein )



From den.duurs at lycos.com  Tue Sep  2 01:07:21 2003
From: den.duurs at lycos.com (Remko Duursma)
Date: Mon, 01 Sep 2003 16:07:21 -0700
Subject: [R] meta-analysis question
Message-ID: <AIOMAJLILIEDMCAA@mailcity.com>


This is really helpful, however: i do not have the covariance matrix for each study. In fact, i only have b0, b1, R-squared and the range of x's used for the fit.


Rekmo
--------- Original Message ---------

DATE: Mon, 01 Sep 2003 13:50:04
From: Spencer Graves <spencer.graves at pdf.com>
To: den.duurs at lycos.com
Cc: rhelp <r-help at r-project.org>

>	Can you get the covariance matrices of the vectors b = c(b0, b1)? 
>There is a reasonable literature on meta-analysis with which I'm not 
>very familiar.  However, a standard thing to do is to compute a weighted 
>average with weights proportional to the inverse of the covariance 
>matrices, while testing to evaluate whether the b's plausibly all 
>estimate the same thing.
>
>	  The theory is as follows:  Suppose b.i ~ N.k(mu, Sig.i), i = 1, 2, 
>..., n.  If you have a covariance matrix for each vector b.i, then you 
>have this set-up.  Assuming you do have (or can approximate) Sig.i, then
>
>	  l.i = log(likelihood(b.i)) = 
>(-0.5)*(k*log(2*pi)+log(det(Sig.i))+t(b.i-mu)%*%solve(Sig.i, (b.i-mu))).
>
>The first derivative of l.i with respect to mu is as follows:
>
>	  D.l.i = solve(Sig.i, (x.i-mu)).
>
>	  The solution for mu of sum(D.l.i)=0 is as follows:
>
>	  mu.hat = solve(sum(Sig.i), sum(solve(Sig.i, (x.i-mu)))).
>
>	  One could also derive various statistics for evaluating whether it is 
>plausible to believe that these b.i's all come from the same population. 
>  I would assume that the literature on meta-analysis would deal with 
>this, but I have not looked much at that literature, and I'll leave that 
>question to others.
>
>hope this helps.
>spencer graves
>
>Remko Duursma wrote:
>> Dear R-helpers,
>> 
>> i have the following situation: i have a bunch of 
>y=b0 + b1*x from different studies, and want to
>estimate a "general" y=f(x). I only have the b0,b1's
>and R-squareds. Should i weigh the separate equations
>by their R-squared?
>> 
>> thanks
>> 
>> Remko
>> 
>> 
>> ^'~,_,~'^'~,_,~'^'~,_,~'^'~,_,~'^'~,_,~'^'~,_,~'
>> Remko Duursma, Ph.D. student
>> Forest Biometrics Lab / Idaho Stable Isotope Lab
>> University of Idaho, Moscow, ID, U.S.A.
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From dmurdoch at pair.com  Tue Sep  2 01:09:34 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon, 01 Sep 2003 19:09:34 -0400
Subject: [R] help file extension
In-Reply-To: <6r7k4stapv.fsf@bates4.stat.wisc.edu>
References: <B3A80C9C13928B45B2FCE4C43656363A2DE5FC@mail-srv02.master.medizin.uni-essen.de>
	<1062447520.3f53a9a0651e8@mail.ugent.be>
	<o0e7lv8gedo0bu9lrn7ieg8mpegeptg8k1@4ax.com>
	<tnf7lvooikqpo5f3e3rilu7i3j0hkp6m42@4ax.com>
	<6r7k4stapv.fsf@bates4.stat.wisc.edu>
Message-ID: <gbk7lvo7skg2f1kopb2h9g4218b4dihk53@4ax.com>

On 01 Sep 2003 17:17:32 -0500, you wrote:

>Duncan Murdoch <dmurdoch at pair.com> writes:
>
>> On Mon, 01 Sep 2003 17:24:11 -0400, you wrote:
>> 
>> 
>> >You can put additional documentation in a "doc" subdirectory, 
>> 
>> That should be info/doc in the source...
>
>I think you mean inst/doc

Just not my day for accuracy, I guess!  Thanks.

Duncan



From ok at cs.otago.ac.nz  Tue Sep  2 01:18:43 2003
From: ok at cs.otago.ac.nz (Richard A. O'Keefe)
Date: Tue, 2 Sep 2003 11:18:43 +1200 (NZST)
Subject: [R] difference between <- and =
Message-ID: <200309012318.h81NIhl0255561@atlas.otago.ac.nz>

Spencer Graves <spencer.graves at PDF.COM> wrote:
	A common, punishing error for me, with DF being a data frame, is the 
	following:
	
		  if(DF$a = 1) ...
	
	 where I intended to write "if(DF$a == 1)...".

This is a syntax error in R.

    > d <- data.frame(a=2,b=3,c=4)
    > if (d$a=1) cat("foo!")
    Error: syntax error

If I've understood the R documentation correctly, "=" is only allowed
as a synonym for "<-" at "statement" level.

Of course, that's one more reason not to use "=" when you DO want
assignment; "<-" has no such restriction.



From spencer.graves at pdf.com  Tue Sep  2 01:55:05 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 01 Sep 2003 16:55:05 -0700
Subject: [R] meta-analysis question
References: <AIOMAJLILIEDMCAA@mailcity.com>
Message-ID: <3F53DC59.7040607@pdf.com>

	  Have you made normal probability plots and scatterplots of the b0's 
and b1's?  Especially if the numbers seem reasonably normally 
distributed, possibly with some outliers, I'd throw out the outliers, 
compute mean, standard deviation and correlation from what I had left, 
and hope that this all was adequate for the purpose at hand.

	  If this were really important and I didn't have anything else to work 
with, I might compute some kind of "Mahalinobis distance" of each point 
from the (trimmed?) mean relative to the (trimmed?) covariance, and then 
I might try to plot this Mahalinobis distance" vs. the x range and 
R-squared numbers.  However, I'm not certain what I would do with the 
result.

hope this helps.  spencer graves

Remko Duursma wrote:
> This is really helpful, however: i do not have the covariance 
matrix for each study. In fact, i only have b0, b1, R-squared
and the range of x's used for the fit.
> 
> 
> Rekmo
> --------- Original Message ---------
> 
> DATE: Mon, 01 Sep 2003 13:50:04
> From: Spencer Graves <spencer.graves at pdf.com>
> To: den.duurs at lycos.com
> Cc: rhelp <r-help at r-project.org>
> 
>>	Can you get the covariance matrices of the vectors b = c(b0, b1)? 
>>There is a reasonable literature on meta-analysis with which I'm not 
>>very familiar.  However, a standard thing to do is to compute a weighted 
>>average with weights proportional to the inverse of the covariance 
>>matrices, while testing to evaluate whether the b's plausibly all 
>>estimate the same thing.
>>
>>	  The theory is as follows:  Suppose b.i ~ N.k(mu, Sig.i), i = 1, 2, 
>>..., n.  If you have a covariance matrix for each vector b.i, then you 
>>have this set-up.  Assuming you do have (or can approximate) Sig.i, then
>>
>>	  l.i = log(likelihood(b.i)) = 
>>(-0.5)*(k*log(2*pi)+log(det(Sig.i))+t(b.i-mu)%*%solve(Sig.i, (b.i-mu))).
>>
>>The first derivative of l.i with respect to mu is as follows:
>>
>>	  D.l.i = solve(Sig.i, (x.i-mu)).
>>
>>	  The solution for mu of sum(D.l.i)=0 is as follows:
>>
>>	  mu.hat = solve(sum(Sig.i), sum(solve(Sig.i, (x.i-mu)))).
>>
>>	  One could also derive various statistics for evaluating whether it is 
>>plausible to believe that these b.i's all come from the same population. 
>> I would assume that the literature on meta-analysis would deal with 
>>this, but I have not looked much at that literature, and I'll leave that 
>>question to others.
>>
>>hope this helps.
>>spencer graves
>>
>>Remko Duursma wrote:
>>
>>>Dear R-helpers,
>>>
>>>i have the following situation: i have a bunch of 
>>
>>y=b0 + b1*x from different studies, and want to
>>estimate a "general" y=f(x). I only have the b0,b1's
>>and R-squareds. Should i weigh the separate equations
>>by their R-squared?
>>
>>>thanks
>>>
>>>Remko
>>>
>>>
>>>^'~,_,~'^'~,_,~'^'~,_,~'^'~,_,~'^'~,_,~'^'~,_,~'
>>>Remko Duursma, Ph.D. student
>>>Forest Biometrics Lab / Idaho Stable Isotope Lab
>>>University of Idaho, Moscow, ID, U.S.A.
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Yannong.Dong-1 at ou.edu  Tue Sep  2 03:20:49 2003
From: Yannong.Dong-1 at ou.edu (Yannong.Dong-1)
Date: Mon, 01 Sep 2003 20:20:49 -0500
Subject: [R] Strange problem.
Message-ID: <14cea91505d3.1505d314cea9@ou.edu>

Hi, everyone,
    I am a new user of R. Recently, I tried the following commands, but couldn't make them work. If any one of you has some ideas about it, please help me. The commands are

>std<-1000
>mean<-8000
>prior<-function(n){1/(sqrt(2*pi)*std)*exp(-1.0*(n-mean)^2/(2*std^2))}
>plot(prior,1,15000)
>post<-function(n){
+ if(n < 9543) 
+  0
+ else
+  prior(n)/n
+ }
>plot(post,1,15000)  # This command didn't work. The error message is " x and y lengths differ "

I was really confused about it because the first function "prior" can work well. I think I must make something wrong stupidly, but could not find it. If you can help me about it, it would be very helpful. Thanx a lot in advance.

   Rgds, 
   Yannong Dong



From spencer.graves at pdf.com  Tue Sep  2 03:54:06 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 01 Sep 2003 18:54:06 -0700
Subject: [R] Strange problem.
References: <14cea91505d3.1505d314cea9@ou.edu>
Message-ID: <3F53F83E.5070903@pdf.com>

	  Note also the warning:  "the condition has length > 1 and only the 
first element will be used in: if (n < 9543) 0 else prior(n)/n".  The 
problem is that "if" is not vectorized:  "if(n<9543)" is interpreted as 
"if(n[1]<9543)", which then produces a scalar output, 0, which 
presumably then generates the error message "x and y lengths differ".

	  Try "ifelse" instead, so "post" becomes:

post<-function(n){
  ifelse(n < 9543, 0, prior(n)/n)
  }

	  Then plot(post,1,15000) seemed to work fine for me.

hope this helps.  spencer graves

Yannong.Dong-1 wrote:
> Hi, everyone,
>     I am a new user of R. Recently, I tried the following commands, but couldn't make them work. If any one of you has some ideas about it, please help me. The commands are
> 
> 
>>std<-1000
>>mean<-8000
>>prior<-function(n){1/(sqrt(2*pi)*std)*exp(-1.0*(n-mean)^2/(2*std^2))}
>>plot(prior,1,15000)
>>post<-function(n){
> 
> + if(n < 9543) 
> +  0
> + else
> +  prior(n)/n
> + }
> 
>>plot(post,1,15000)  # This command didn't work. The error message is " x and y lengths differ "
> 
> 
> I was really confused about it because the first function "prior" can work well. I think I must make something wrong stupidly, but could not find it. If you can help me about it, it would be very helpful. Thanx a lot in advance.
> 
>    Rgds, 
>    Yannong Dong
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From kwan022 at stat.auckland.ac.nz  Tue Sep  2 03:58:44 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Tue, 2 Sep 2003 13:58:44 +1200 (NZST)
Subject: [R] Strange problem.
In-Reply-To: <14cea91505d3.1505d314cea9@ou.edu>
Message-ID: <Pine.LNX.4.44.0309021357090.1513-100000@stat55.stat.auckland.ac.nz>

On Mon, 1 Sep 2003, Yannong.Dong-1 wrote:

> >std<-1000
> >mean<-8000
> >prior<-function(n){1/(sqrt(2*pi)*std)*exp(-1.0*(n-mean)^2/(2*std^2))}
> >plot(prior,1,15000)
> >post<-function(n){
> + if(n < 9543) 
> +  0
> + else
> +  prior(n)/n
> + }
> >plot(post,1,15000)  # This command didn't work. The error message is " x and y lengths differ "

Try replacing the post() function with something like:
post<-function(n){
 ifelse(n < 9543, 0, prior(n) / n)
}

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
"On two occasions, I have been asked [by members of Parliament],
'Pray, Mr. Babbage, if you put into the machine wrong figures, will
the right answers come out?' I am not able to rightly apprehend the
kind of confusion of ideas that could provoke such a question."

-- Charles Babbage (1791-1871) 
---- From Computer Stupidities: http://rinkworks.com/stupid/

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)



From ok at cs.otago.ac.nz  Tue Sep  2 04:20:32 2003
From: ok at cs.otago.ac.nz (Richard A. O'Keefe)
Date: Tue, 2 Sep 2003 14:20:32 +1200 (NZST)
Subject: [R] Strange problem.
Message-ID: <200309020220.h822KWr1302119@atlas.otago.ac.nz>

Yannong.Dong-1 had a mysterious problem with plot() applied to a function.

I think the basic problem is not that 'if() else' isn't vectorised,
but that 'plot' *is*.  The R documentation is fairly clear if you
know where to look (like ?plot.function), and I know I've seen it
mentioned in one of the R tutorials.

Having a vectorised plot() makes a great deal of sense, but it can be
a surprise to people who aren't used to the vector way of thinking.

It looks as though mention of ?Normal might be useful too.



From ss4403 at mindspring.com  Tue Sep  2 05:25:59 2003
From: ss4403 at mindspring.com (Scott S.)
Date: Mon, 01 Sep 2003 22:25:59 -0500
Subject: [R] Error in making R-1.6.2.
Message-ID: <3F540DC7.4000108@mindspring.com>

Hi Rolf,

Saw your post back in March about a particular error message you were 
getting.  To refresh your memory here is the link:

https://stat.ethz.ch/pipermail/r-help/2003-March/029580.html

I'm getting the same error message when trying to compile CUPS (Common 
Unix Printing System).  Have been messing with this for days now and 
can't seem to understand what is going on here.  Have you resolved this 
for your particular case?  If so would you please be so kind as to shed 
some light on this for me.  Thanks in advance

Scott Slawin



From Arnaud.Dowkiw at dpi.qld.gov.au  Tue Sep  2 06:47:28 2003
From: Arnaud.Dowkiw at dpi.qld.gov.au (Dowkiw, Arnaud)
Date: Tue, 2 Sep 2003 14:47:28 +1000
Subject: [R] Strange problem.
Message-ID: <200309020447.h824lhP9008305@dpi-gw1.dpi.qld.gov.au>

Hi Dong,

The problem comes from the fact that you are trying to apply a function to a set of values. Prior works because it applies the same function to each component of that set. Post does not work because it applies a function which is defined by intervals. No if (bla bla bla) is allowed unless it applies to a given element of that set of values and not to the whole vector. This is why I suggest you do this :


> post<-function(n)
{
post<-c(rep(NA,length(n)))
for (i in 1:length(n))
	{
	if(n[i]<9543)
	post[i]<-0
	else
	post[i]<-prior(n[i])/n[i]
	}
post
}

>plot(post(9500:15000))

try this and tell me if it's what you want.

Good luck,

Arnaud
*************************
Arnaud DOWKIW
Department of Primary Industries
J. Bjelke-Petersen Research Station
KINGAROY, QLD 4610
Australia
T : + 61 7 41 600 700
T : + 61 7 41 600 728 (direct)
F : + 61 7 41 600 760
**************************



-----Original Message-----
From: Yannong.Dong-1 [mailto:Yannong.Dong-1 at ou.edu]
Sent: Tuesday, 2 September 2003 11:21 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Strange problem.


Hi, everyone,
    I am a new user of R. Recently, I tried the following commands, but couldn't make them work. If any one of you has some ideas about it, please help me. The commands are

>std<-1000
>mean<-8000
>prior<-function(n){1/(sqrt(2*pi)*std)*exp(-1.0*(n-mean)^2/(2*std^2))}
>plot(prior,1,15000)
>post<-function(n){
+ if(n < 9543) 
+  0
+ else
+  prior(n)/n
+ }
>plot(post,1,15000)  # This command didn't work. The error message is " x and y lengths differ "

I was really confused about it because the first function "prior" can work well. I think I must make something wrong stupidly, but could not find it. If you can help me about it, it would be very helpful. Thanx a lot in advance.

   Rgds, 
   Yannong Dong

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help 

********************************DISCLAIMER******************...{{dropped}}



From ok at cs.otago.ac.nz  Tue Sep  2 07:12:14 2003
From: ok at cs.otago.ac.nz (Richard A. O'Keefe)
Date: Tue, 2 Sep 2003 17:12:14 +1200 (NZST)
Subject: [R] I don't understand this
Message-ID: <200309020512.h825CEUU081571@atlas.otago.ac.nz>

For reasons which I'll spare you, I'm writing a program to analyse
R source code.  This has led me to probe some of the darker corners
of R syntax to find out what is supposed to happen.

Now, from reading the R documentation (and the New S book &c) I know
perfectly well that
    f(a, b, etc) <- x
is supposed to turn into
    a <- "f<-"(a, b, etc, value=x)

Except, what if f is not an identifier or string?
What, for example, should _this_ do?

> x <- NULL
> (if (TRUE) names else dim)(x) <- 27

I was expecting _either_ that I would be told that you can't
set names(NULL) to 27, _or_ that I would be told the whole thing
wasn't allowed.

In fact, it was allowed.

> x
[1] 27

This result has me completely baffled.

Is this behaviour intentional?
What rules does it follow from?
What _exactly_ are the rules for assignment supposed to be _in R_?

The emphasis on _in R_ is because I know the New S book spells out
a lot of detail, but (a) I've been searching for my copy for a couple
of weeks and (b) R is not _exactly_ the same as S.



From ripley at stats.ox.ac.uk  Tue Sep  2 07:15:10 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 2 Sep 2003 06:15:10 +0100 (BST)
Subject: [R] Error in making R-1.6.2.
In-Reply-To: <3F540DC7.4000108@mindspring.com>
Message-ID: <Pine.LNX.4.44.0309020612360.30233-100000@gannet.stats>

You sent that to R-help, not `Rolf'.  He was using Solaris 9, and
that sort of error message is normally a symptom of using a version of gcc 
compiled for a different version of Solaris.  gcc `fixes' the system 
header files, of the version it is compiled under.

So I suggest checking the compiler/OS match.

On Mon, 1 Sep 2003, Scott S. wrote:

> Hi Rolf,
> 
> Saw your post back in March about a particular error message you were 
> getting.  To refresh your memory here is the link:
> 
> https://stat.ethz.ch/pipermail/r-help/2003-March/029580.html
> 
> I'm getting the same error message when trying to compile CUPS (Common 
> Unix Printing System).  Have been messing with this for days now and 
> can't seem to understand what is going on here.  Have you resolved this 
> for your particular case?  If so would you please be so kind as to shed 
> some light on this for me.  Thanks in advance
> 
> Scott Slawin


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Sep  2 07:34:08 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 2 Sep 2003 06:34:08 +0100 (BST)
Subject: [R] I don't understand this
In-Reply-To: <200309020512.h825CEUU081571@atlas.otago.ac.nz>
Message-ID: <Pine.LNX.4.44.0309020623350.30349-100000@gannet.stats>

On Tue, 2 Sep 2003, Richard A. O'Keefe wrote:

> For reasons which I'll spare you, I'm writing a program to analyse
> R source code.  This has led me to probe some of the darker corners
> of R syntax to find out what is supposed to happen.
> 
> Now, from reading the R documentation (and the New S book &c) I know
> perfectly well that
>     f(a, b, etc) <- x
> is supposed to turn into
>     a <- "f<-"(a, b, etc, value=x)
> 
> Except, what if f is not an identifier or string?
> What, for example, should _this_ do?
> 
> > x <- NULL
> > (if (TRUE) names else dim)(x) <- 27
> 
> I was expecting _either_ that I would be told that you can't
> set names(NULL) to 27, _or_ that I would be told the whole thing
> wasn't allowed.

I get

Error: couldn't find function " <-"

!  (On some systems I get a set of non-printable chars in there.)

What I would have expected is that it tried to find "(<-" and failed, as 
in

> x <- 3
> (names(x)) <- 27
Error: couldn't find function "(<-"

(and S does essentially that in your example). 

> In fact, it was allowed.
> 
> > x
> [1] 27
>
> This result has me completely baffled.

Not reproducible, either.
 
> Is this behaviour intentional?
> What rules does it follow from?
> What _exactly_ are the rules for assignment supposed to be _in R_?
>
> The emphasis on _in R_ is because I know the New S book spells out
> a lot of detail, but (a) I've been searching for my copy for a couple
> of weeks and (b) R is not _exactly_ the same as S.

And for R you have the source code, and a `R Language Definition'.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ok at cs.otago.ac.nz  Tue Sep  2 08:21:43 2003
From: ok at cs.otago.ac.nz (Richard A. O'Keefe)
Date: Tue, 2 Sep 2003 18:21:43 +1200 (NZST)
Subject: [R] I don't understand this
Message-ID: <200309020621.h826LhZL284611@atlas.otago.ac.nz>

I asked what 
> x <- NULL
> (if (TRUE) names else dim)(x) <- 27
is *supposed* to do.

Professor Brian Ripley basically gave me the answer I wanted:
it isn't *supposed* to do anything.  However, he went on to say

	And for R you have the source code, and a `R Language Definition'.
	
My original message made it clear that I had read the R documentation.
I am very favourably impressed by it; compared with many commercial
systems it is *superb*.  However, the R Language Definition is not
finished yet and does not discuss assignment at length.  In fact,
remarks on assignment are scattered thinly throughout the text, at
least one appears to have "right" when it means "left".  That's OK;
it doesn't claim to be finished documentation, but it does mean that
some questions cannot as yet be answered by reading it.

As for the code (src/main/eval.c), it tells you want DOES happen (if you
are considerably more familiar with R internals than I am yet), but with
R's characteristic paucity of comments, it says nothing about what is
*supposed* to happen.

By the way, is anyone else worried about this code:

    static SEXP applydefine(SEXP call, SEXP op, SEXP args, SEXP rho)
    {
	...
=======>char buf[32];
	...
	while (isLanguage(CADR(expr))) {
===========>sprintf(buf, "%s<-", CHAR(PRINTNAME(CAR(expr))));
	    tmp = install(buf);

A similar buffer-overrun in Windows RTF boxes led to a security
vulnerability.

To put it another way, it was a serious question for a serious reason,
and I _had_ done my homework, but I have a really hard time reading the
R sources.



From Rob.Hyndman at buseco.monash.edu.au  Tue Sep  2 09:00:25 2003
From: Rob.Hyndman at buseco.monash.edu.au (Rob J Hyndman)
Date: Tue, 02 Sep 2003 17:00:25 +1000
Subject: [R] Blackman-Tukey spectral estimator
Message-ID: <3F544009.4000309@buseco.monash.edu.au>

Does anyone have code for computing the Blackman-Tukey estimate of the 
spectral density?

___________________________________________________
Rob J Hyndman
Associate Professor & Director of Consulting
Department of Econometrics & Business Statistics
Monash University, VIC 3800, Australia.
http://www-personal.buseco.monash.edu.au/~hyndman/



From aureliano_buendia_covaleda at gmx.net  Tue Sep  2 09:33:07 2003
From: aureliano_buendia_covaleda at gmx.net (Alfredo C. V.)
Date: Tue, 2 Sep 2003 02:33:07 -0500
Subject: [R] normal distribution
Message-ID: <200309020233.07519.aureliano_buendia_covaleda@gmx.net>

Hi Sirs and Madams.

My question is more statistical than related with the use of R software and I 
hope it will not seems so silly and elemental. I'm analyzing  a set of data 
of some soil organism collected in diferent landscapes, soils taxa, and 
depths. The sample was performed thinking in a factorial structure with four 
factors: Specie, Landscape, Soil and Depth. Because not all the species 
appear in each sample there are so many zeros in the matrix data.

Checking the normal distribution I'm not sure If I must check it in the 
original sample data (without zeros) or in the big matrix with zeros. In the 
first case there is a normal distribution (W = 0,85) but in the second  it is 
not (W = 0,45). In which data must I check distribution?, Can I proceed to 
perform a Parametric ANOVA?.

Thanks



From acovaleda at hotpop.com  Tue Sep  2 09:45:47 2003
From: acovaleda at hotpop.com (acovaleda@hotpop.com)
Date: Tue, 2 Sep 2003 02:45:47 -0500
Subject: [R] normal distribution
Message-ID: <200309020233.07519.aureliano_buendia_covaleda@gmx.net>

Hi Sirs and Madams.

My question is more statistical than related with the use of R software and I 
hope it will not seems so silly and elemental. I'm analyzing  a set of data 
of some soil organism collected in diferent landscapes, soils taxa, and 
depths. The sample was performed thinking in a factorial structure with four 
factors: Specie, Landscape, Soil and Depth. Because not all the species 
appear in each sample there are so many zeros in the matrix data.

Checking the normal distribution I'm not sure If I must check it in the 
original sample data (without zeros) or in the big matrix with zeros. In the 
first case there is a normal distribution (W = 0,85) but in the second  it is 
not (W = 0,45). In which data must I check distribution?, Can I proceed to 
perform a Parametric ANOVA?.

Thanks



From Friedrich.Leisch at ci.tuwien.ac.at  Tue Sep  2 08:37:42 2003
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Tue, 2 Sep 2003 08:37:42 +0200
Subject: [R] R News: Call for Papers
Message-ID: <16212.15030.153585.393504@celeborn.leisch.at>


R News (see http://CRAN.R-project.org/doc/Rnews/) is running low on
submissions lately. If you are the author of a package on CRAN or
Bioconductor and want to attract a larger audience to your software,
you should consider writing a short article introducing the
package. Another "typical" kind of R News article is to describe a
data analysis application using R (not necessarily using software you
have written).

We are looking forward to all contributions!

For the editorial board,
Fritz Leisch

-- 
-------------------------------------------------------------------
                        Friedrich  Leisch 
Institut f?r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit?t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra?e 8-10/1071      Friedrich.Leisch at ci.tuwien.ac.at
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch

_______________________________________________
R-announce at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-announce



From hodgess at gator.dt.uh.edu  Tue Sep  2 10:37:35 2003
From: hodgess at gator.dt.uh.edu (Erin Hodgess)
Date: Tue, 2 Sep 2003 03:37:35 -0500
Subject: [R] Histogram question
Message-ID: <200309020837.h828bZZ02693@gator.dt.uh.edu>

Dear R People:

When the "hist" command is used with the probability = T, the results
are such that the height x the width of each bar would represent
the relative frequency.

Is there a way to adjust the hist function such that the bars have the 
height of the relative frequency (without regard to width), please?

I was experimenting with the "truehist" function and changed the code
for the "est" value.  However, the y axis labels are not at the same levels
between the prob = T and prob = F when that change is made.

This is R 1.7.1 for Windows.

thanks in advance!!!!!

Sincerely,
Erin Hodgess
mailto: hodgess at gator.uhd.edu



From luke at stat.uiowa.edu  Tue Sep  2 10:40:04 2003
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Tue, 2 Sep 2003 03:40:04 -0500 (CDT)
Subject: [R] I don't understand this
In-Reply-To: <200309020621.h826LhZL284611@atlas.otago.ac.nz>
Message-ID: <Pine.LNX.4.44.0309020336110.12601-100000@itasca2.stat.uiowa.edu>

On Tue, 2 Sep 2003, Richard A. O'Keefe wrote:
> 
> By the way, is anyone else worried about this code:
> 
>     static SEXP applydefine(SEXP call, SEXP op, SEXP args, SEXP rho)
>     {
> 	...
> =======>char buf[32];
> 	...
> 	while (isLanguage(CADR(expr))) {
> ===========>sprintf(buf, "%s<-", CHAR(PRINTNAME(CAR(expr))));
> 	    tmp = install(buf);
> 

Yes -- Brian added code to check this and similar buffer overflows to
R-devel a while ago.

luke

-- 
Luke Tierney
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
   Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu



From luke at stat.uiowa.edu  Tue Sep  2 10:58:39 2003
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Tue, 2 Sep 2003 03:58:39 -0500 (CDT)
Subject: [R] I don't understand this
In-Reply-To: <200309020512.h825CEUU081571@atlas.otago.ac.nz>
Message-ID: <Pine.LNX.4.44.0309020340160.12601-100000@itasca2.stat.uiowa.edu>

On Tue, 2 Sep 2003, Richard A. O'Keefe wrote:

> For reasons which I'll spare you, I'm writing a program to analyse
> R source code.  This has led me to probe some of the darker corners
> of R syntax to find out what is supposed to happen.
> 
> Now, from reading the R documentation (and the New S book &c) I know
> perfectly well that
>     f(a, b, etc) <- x
> is supposed to turn into
>     a <- "f<-"(a, b, etc, value=x)
> 
> Except, what if f is not an identifier or string?
> What, for example, should _this_ do?
> 
> > x <- NULL
> > (if (TRUE) names else dim)(x) <- 27
> 
> I was expecting _either_ that I would be told that you can't
> set names(NULL) to 27, _or_ that I would be told the whole thing
> wasn't allowed.
> 
> In fact, it was allowed.
> 
> > x
> [1] 27
> 
> This result has me completely baffled.
> 
> Is this behaviour intentional?

No.  Using anything other than a symbol or string for the function in
a complex assignment is an error.  The internals assumed the function
would be a symbol (the parser deals with the string case) but did not
check for this; should be fixed shortly in R-devel.

Thanks for pointing this out.

luke

-- 
Luke Tierney
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
   Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu



From p.silva at gmx.net  Tue Sep  2 01:13:20 2003
From: p.silva at gmx.net (Philip Silva)
Date: Tue, 02 Sep 2003 01:13:20 +0200
Subject: [R] Error in dyn.load
In-Reply-To: <Pine.LNX.4.44.0309012254350.23273-100000@gannet.stats>
References: <Pine.LNX.4.44.0309012254350.23273-100000@gannet.stats>
Message-ID: <3F53D290.5090108@gmx.net>

Yes, but not exactly enough.. I didn't put the R-#includes in the extern 
"C"-part but know everything works fine. Thank you very much!

Prof Brian Ripley wrote:
> Did you follow the instructions in Writing R Extensions?
> 
> You need to make sure you include the proper header files, as length
> is a C and not C++ export from R.bin, and in any case it is remapped in R.
> 
> On Mon, 1 Sep 2003, Philip Silva wrote:
> 
> 
>>Hi,
>>
>>I've created a shared library from including this code (with g++ 
>>-I/usr/local/lib/R/include -I/usr/local/include -c Rtest.cpp; g++ 
>>-shared -L/usr/local/lib -o Rtest.so Rtest.cpp):
>>void check_data (SEXP data) {
>>	int l=length (data);
>>}
>>
>>But when I try to load it in R I get this error message:
>>unable to load shared library ...
>>...
>>  undefined symbol: _Z9Rf_lengthP7SEXPREC
>>
>>How can I solve this problem?
> 
>



From Giles.Heywood at CommerzbankIB.com  Tue Sep  2 13:21:54 2003
From: Giles.Heywood at CommerzbankIB.com (Heywood, Giles)
Date: Tue, 2 Sep 2003 12:21:54 +0100 
Subject: [R] readcsvIts() to create irregular time series
Message-ID: <8CBAA121CEB4D5118CB200508BB2BBEF540488@xmx8lonib.lonib.commerzbank.com>

> BUT;
> 1. What can you do with informat and outformat? Is it the same as
> its.format() before the its function?

its.format() sets the text representation format for the times, and 
once set, it persists within that R session.  It is often convenient
to set this format just once in a session, since in many circumstances
multiple date formats serve only to distract and confuse.  The arguments
informat and outformat in readcsvIts override the value set in 
its.format().

> 
> 2. Can the its be plotted onto a ts? And is a correlation analysis in
> between the two objects possible?
> 

All regular time-series can be represented as irregular time-series -
they are a special case.  If you want to use both, I suggest you convert
your regular time-series to irregular.  You might for example use
seq.POSIXt(start,end,by="month") to set up a monthly series of POSIX
dates, and its(matrix,seq.POSIXt(start,end,by="month")) will then provide
you with a reglar time-series reprented as an 'its'.

Having done this, you can plot multiple series, which may not have the 
same time-stamps, using for example:

xy <- unionIts(Fire,its(matrix,seq.POSIXt(start,end,by="month"))
plot(xy)

> 2. Can the its be plotted onto a ts? And is a correlation analysis in
> between the two objects possible?

A meaningful calculation of correlation normally requires the data to be 
aligned in time (I can't think of an exception to this).  So you need to 
ensure that you have at least some of the data 'aligned' to start off with.
For example, if you have an 'its' x with daily data, and a 'its' y with
monthly data, you could do the following:

cor(intersectIts(x,y))

It relies for success on at least some subset of the POSIX dates being 
equal, i.e. that the result of the intersect operation is not NULL.

Giles


********************************************************************** 
This is a commercial communication from Commerzbank AG.\ \ T...{{dropped}}



From spencer.graves at pdf.com  Tue Sep  2 13:59:40 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 02 Sep 2003 04:59:40 -0700
Subject: [R] normal distribution
References: <200309020233.07519.aureliano_buendia_covaleda@gmx.net>
Message-ID: <3F54862C.1050604@pdf.com>

	  I don't hear a distinction between response variable(s) and potential 
explanatory variable(s).  The standard linear regression and parametric 
ANOVA assumes that the response variable is a linear function of 
parameters to be estimated plus normally distributed noise.  I usually 
judge this by making normal probability plots (qqnorm) of my response 
variables.

	  Where are the 0's that concern you?  Are they in the response 
variable(s) or the potential explanatory variable(s)?  If the latter, 
it's not a problem.  If the former, it is.

hope this helps.  spencer graves

acovaleda at hotpop.com wrote:
> Hi Sirs and Madams.
> 
> My question is more statistical than related with the use of R software and I 
> hope it will not seems so silly and elemental. I'm analyzing  a set of data 
> of some soil organism collected in diferent landscapes, soils taxa, and 
> depths. The sample was performed thinking in a factorial structure with four 
> factors: Specie, Landscape, Soil and Depth. Because not all the species 
> appear in each sample there are so many zeros in the matrix data.
> 
> Checking the normal distribution I'm not sure If I must check it in the 
> original sample data (without zeros) or in the big matrix with zeros. In the 
> first case there is a normal distribution (W = 0,85) but in the second  it is 
> not (W = 0,45). In which data must I check distribution?, Can I proceed to 
> perform a Parametric ANOVA?.
> 
> Thanks
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From andy_liaw at merck.com  Tue Sep  2 14:35:54 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 02 Sep 2003 08:35:54 -0400
Subject: [R] Histogram question
Message-ID: <3A822319EB35174CA3714066D590DCD50205CA92@usrymx25.merck.com>

You can do it "by hand"; e.g.,

x <- rnorm(50)
x.hist <- hist(x, prob=TRUE, plot=FALSE)
x.prob <- x.hist$count / length(x)
## Alternatively:
x.prob <- diff(x.hist$breaks) * x.hist$density

You can then use barplot or whatever you like to plot x.prob.

HTH,
Andy

> -----Original Message-----
> From: Erin Hodgess [mailto:hodgess at gator.dt.uh.edu] 
> Sent: Tuesday, September 02, 2003 4:38 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Histogram question
> 
> 
> Dear R People:
> 
> When the "hist" command is used with the probability = T, the 
> results are such that the height x the width of each bar 
> would represent the relative frequency.
> 
> Is there a way to adjust the hist function such that the bars 
> have the 
> height of the relative frequency (without regard to width), please?
> 
> I was experimenting with the "truehist" function and changed 
> the code for the "est" value.  However, the y axis labels are 
> not at the same levels between the prob = T and prob = F when 
> that change is made.
> 
> This is R 1.7.1 for Windows.
> 
> thanks in advance!!!!!
> 
> Sincerely,
> Erin Hodgess
> mailto: hodgess at gator.uhd.edu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> 

------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From JonesW at kssg.com  Tue Sep  2 15:26:13 2003
From: JonesW at kssg.com (Wayne Jones)
Date: Tue, 2 Sep 2003 14:26:13 +0100 
Subject: [R]: Creating a Package with Windows XP.
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB021F0E3D@gimli.middleearth.kssg.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030902/fedbe9ea/attachment.pl

From Sofiane.Lariani at rdls.nestle.com  Tue Sep  2 15:39:28 2003
From: Sofiane.Lariani at rdls.nestle.com (Lariani,Sofiane,LAUSANNE,NRC/BAS)
Date: Tue, 2 Sep 2003 15:39:28 +0200 
Subject: [R] How to free memory used by R. 
Message-ID: <EF9E44B0F76FDB4396B9EF18A66545EDF5D2EB@CHLSNE01.nestle.com>

>>>>> I follow the memory used by R at each run. This memory increase
considerably at each run. >>>>> After three times  the message is no more
memory (or some thing like this). Even by >>>>> >>>>> deleting all objects
and using gc(), the memory dont decrease!!! the only solution is to >>>>>
kill R.

>>>>> Windows and R 1.7.1

>>>>  thank you
>>>>> ps: I dont think that R developper are aware about the importance of
this memory problem. 


-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
Sent: lundi, 1. septembre 2003 19:50
To: Thomas W Blackwell
Cc: Lariani,Sofiane,LAUSANNE,NRC/BAS; 'r-help at stat.math.ethz.ch'
Subject: Re: [R] How to free memory used by R. 


On Mon, 1 Sep 2003, Thomas W Blackwell wrote:

> On Mon, 1 Sep 2003, Lariani,Sofiane,LAUSANNE,NRC/BAS wrote:
> 
> > I want to free memory used by R. The usage of rm and gc give no result.
I'm
> > running  an algorithm consuming a huge memory and I need to recover the
> > memory used by R between 2 call of my algorithm.

What was the exact error message behind this?

>>>>> I follow the memory used by R at each run. This memory increase
considerably at each run. >>>>> After three times  the message is no more
memory (or some thing like this). Even by >>>>> >>>>> deleting all objects
and using gc(), the memory dont decrease!!! the only solution is to >>>>>
kill R.

> > Thank you in advance for your help.
> >
> > e-mail: sofiane.lariani at rdls.nestle.com
> >
> > Sofiane Lariani
> 
> What operating system and what version of R, please ?

Yes, please?

>>>>> Windows and R 1.7.1

> Other people will have a much better understanding of the
> details here than I have, but here goes.
> 
> The fact that you ask this question suggests that you are
> running the unnamed, memory intensive algorithm inside a loop.
> It's my understanding that  gc()  is called automatically
> every time control comes back to the command line prompt.
> So, gc() is only an issue inside a loop.  You might TRY
> writing a wrapper function:
> 
> my.algorithm <- function(...) {
>    algorithm(...)
>    gc()           }
> 
> and call the wrapper rather than  algorithm()  directly,
> inside the loop.  Chances are this won't help, because
> the loop will try to keep intermediate results.
> (At least it used to do this in old Splus prior to 1990.)

Not in R (and S-PLUS only existed went on sale in about 1988).
Unless there is a bug or a memory leak, gc() is called whenever a naive 
attempt to get memory fails.  There are various levels of gc(), and they 
are all tried.  So when R reports it is short of memory, it is unable to 
free up enough of the memory it has for the needed memory, and all objects 
not currently in use have been deleted.

If you want a lot of memory for a single object then it has to be 
contiguous.  R no longer compacts objects, so it can become increasingly 
hard to get large chunks of memory as the loop runs.

> If nothing else works, do as we all used to do prior to 1990.
> Write a batch script which does one iteration of the algorithm
> and saves just the intermediate results you want.  Then write
> a shell script (I assume you're using a version of unix) that
> simply runs  R BATCH scriptname logfile  again and again, one
> call for each iteration of the loop.  This guarantees that
> nothing is saved except what you specify.  (It's clunky, yes,
> but this works when nothing else will.)  

That's true of S, but not I think of R (or at least the memory reduction 
is very small).  We say For loops are not implemented in R because they 
are not needed, and For loops automate this.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From JonesW at kssg.com  Tue Sep  2 15:33:29 2003
From: JonesW at kssg.com (Wayne Jones)
Date: Tue, 2 Sep 2003 14:33:29 +0100 
Subject: [R] FW: Creating a Package with Windows XP.
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB021F0E3E@gimli.middleearth.kssg.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030902/8d738575/attachment.pl

From solares at unsl.edu.ar  Tue Sep  2 15:52:22 2003
From: solares at unsl.edu.ar (solares@unsl.edu.ar)
Date: Tue, 2 Sep 2003 10:52:22 -0300 (ART)
Subject: [R] Execute R without environment and multiple grid in multiple
	graphics
Message-ID: <59613.170.210.173.216.1062510742.squirrel@inter14.unsl.edu.ar>

hello, i like execute a script in R without having to execute the 
environment R, my scrip uses the package tcltk,
for ej :
global var
myfunction<-function(){
tt<-tktoplevel()
b<-tkbutton(...)
..}
I want that the interfaz is only seen, and that it shows objects of R, for 
example graphics without the environment
of R so much in windows (perhaps making click in ujn icon or executing one 
lines of commands) like in linux.
And another question is i cant work in multiple axis "y" with multiple 
grid, how i cant make this?
Thanks Ruben.



From ligges at statistik.uni-dortmund.de  Tue Sep  2 15:53:15 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 02 Sep 2003 15:53:15 +0200
Subject: [R] FW: Creating a Package with Windows XP.
In-Reply-To: <6B5A9304046AD411BD0200508BDFB6CB021F0E3E@gimli.middleearth.kssg.com>
References: <6B5A9304046AD411BD0200508BDFB6CB021F0E3E@gimli.middleearth.kssg.com>
Message-ID: <3F54A0CB.2080405@statistik.uni-dortmund.de>

Wayne Jones wrote:

>>Hi there fellow R-Users, 
>>
>>I am trying to use the "package.skeleton" to create my own package with
>>R.1.7.1 on Windows XP Professional.
>>I have followed the package.skeleton example and have downloaded the
>>necessary files found at http://www.stats.ox.ac.uk/pub/Rtools/tools.zip.
>>
>>and perl5, available via http://www.activestate.com/Products/ActivePerl/.
>>
>>When I run the command "Rcmd BUILD AnExample" I get the following output
>>and error message: 
>>
>>
>>C:\Program Files\R\rw1071\bin>Rcmd BUILD AnExample
>>* checking for file 'AnExample/DESCRIPTION' ... OK
>>* preparing 'AnExample':
>>* cleaning src
>>* checking whether 'INDEX' is up-to-date ... OK
>>* checking whether 'data/00Index' is up-to-date ... OK
>>* removing junk files
>>* building 'AnExample_1.0.tar.gz'
>>tar: Files/R/rw1071/bin/AnExample_1.0.tar: Cannot stat: No such file or
>>director
>>y
>>tar: Error exit delayed from previous errors
>>AnExample_1.0.tar: No such file or directory
>>

Do not use blanks in your paths ("Program Files").

Uwe Ligges


>>Whaen I run Rcmd check AnExample I get the following error message
>>
>>C:\Program Files\R\rw1071\bin>Rcmd check AnExample
>>* checking for working latex ...latex: not found
>> NO
>>* using log directory 'C:/Program Files/R/rw1071/bin/AnExample.Rcheck'
>>* checking for file 'AnExample/DESCRIPTION' ... OK
>>* checking if this is a source package ... ERROR
>>Only *source* packages can be checked.
>>
>>
>>What am I doing wrong??
>>Any help would be much appreciated, 
>>
>>Regards,
>>
>>Wayne
>>
>>
>>
>>
>>Dr Wayne R. Jones
>>Statistician / Research Analyst
>>KSS Group plc
>>St James's Buildings
>>79 Oxford Street
>>Manchester M1 6SS
>>Tel: +44(0)161 609 4084
>>Mob: +44(0)7810 523 713
>>
>>
> 
> 
> 
> KSS Ltd
> Seventh Floor  St James's Buildings  79 Oxford Street  Manchester  M1 6SS  England
> Company Registration Number 2800886
> Tel: +44 (0) 161 228 0040	Fax: +44 (0) 161 236 6305
> mailto:kssg at kssg.com		http://www.kssg.com
> 
> 
> The information in this Internet email is confidential and m...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From solares at unsl.edu.ar  Tue Sep  2 15:57:00 2003
From: solares at unsl.edu.ar (solares@unsl.edu.ar)
Date: Tue, 2 Sep 2003 10:57:00 -0300 (ART)
Subject: [R] Change the graphics parameters and refresh then plot region
Message-ID: <33330.170.210.173.216.1062511020.squirrel@inter14.unsl.edu.ar>

Hello, How I can change the parameters of a graphics after it fact and 
that  changes have be seen in the plot, exists a refresh in R?.  Thanks 
Ruben



From ligges at statistik.uni-dortmund.de  Tue Sep  2 16:05:21 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 02 Sep 2003 16:05:21 +0200
Subject: [R] Change the graphics parameters and refresh then plot region
In-Reply-To: <33330.170.210.173.216.1062511020.squirrel@inter14.unsl.edu.ar>
References: <33330.170.210.173.216.1062511020.squirrel@inter14.unsl.edu.ar>
Message-ID: <3F54A3A1.8030408@statistik.uni-dortmund.de>

solares at unsl.edu.ar wrote:

> Hello, How I can change the parameters of a graphics after it fact and 
> that  changes have be seen in the plot, exists a refresh in R?.  Thanks 
> Ruben

You need to re-plot it.

Uwe Ligges



From tlumley at u.washington.edu  Tue Sep  2 16:10:32 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 2 Sep 2003 07:10:32 -0700 (PDT)
Subject: [R] I don't understand this
In-Reply-To: <200309020621.h826LhZL284611@atlas.otago.ac.nz>
Message-ID: <Pine.A41.4.44.0309020653100.46986-100000@homer18.u.washington.edu>

On Tue, 2 Sep 2003, Richard A. O'Keefe wrote:

> I asked what
> > x <- NULL
> > (if (TRUE) names else dim)(x) <- 27
> is *supposed* to do.
>
> Professor Brian Ripley basically gave me the answer I wanted:
> it isn't *supposed* to do anything.  However, he went on to say
>
> 	And for R you have the source code, and a `R Language Definition'.
>
> My original message made it clear that I had read the R documentation.
> I am very favourably impressed by it; compared with many commercial
> systems it is *superb*.  However, the R Language Definition is not
> finished yet and does not discuss assignment at length.  In fact,
> remarks on assignment are scattered thinly throughout the text, at
> least one appears to have "right" when it means "left".  That's OK;
> it doesn't claim to be finished documentation, but it does mean that
> some questions cannot as yet be answered by reading it.

> As for the code (src/main/eval.c), it tells you want DOES happen (if you
> are considerably more familiar with R internals than I am yet), but with
> R's characteristic paucity of comments, it says nothing about what is
> *supposed* to happen.

Yes. Unfortunately these questions probably can't be answered any other
way, either.  If something isn't discussed in the language definition or
the FAQ there may simply be no facts about what the intended behaviour is.
The issue may never have been considered, especially in cases where the S
language definition is not clear.

In the particular case you suggested I am reminded of one of Steve
Summit's postings about undefined behaviour in comp.lang.c.
(http://www.eskimo.com/~scs/readings/undef.950321.html)

     Yet for most of the 15 years I've been programming in C, I
     simply could not have told you why i=i++ is undefined.
     It's an ugly expression; it's meaningless to me; I don't know what it
     does; I don't want to know what it does; I'd never write it; I
     don't  understand why anyone would write it; it's a mystery to me why
     anyone cares what it does; if I ever encountered it in code I was
     maintaining,  I'd rewrite it.


I would have said that the behavior of
   (if (cond) names else dim)(x) <- 10
is undefined in the S language, along with things like the order of
evaluation of the apply functions.

	-thomas



From wowen at richmond.edu  Tue Sep  2 16:15:51 2003
From: wowen at richmond.edu (Owen, Jason)
Date: Tue, 2 Sep 2003 10:15:51 -0400 
Subject: [R] ?hist
Message-ID: <C1F927C74082D311A25B00508B5BFF1703897909@urmail-oz.richmond.edu>

Hello R users,

When using the hist() function, by default the y-axis
displays the counts for each bin (assuming equal bin
sizes).  By adding 'probability = TRUE' or 'freq = FALSE,
the y-axis displays the density (relative freq. / bin size),
but the help file for hist() seems to suggest that this
argument will display the relative frequency:

freq: logical; if `TRUE', the histogram graphic is a representation
          of frequencies, the `counts' component of the result; if
          `FALSE', relative frequencies (``probabilities''),
          component`density', are plotted.   Defaults to `TRUE' iff
          `breaks' are equidistant (and `probability' is not
          specified).

I understand that displaying the density is important
when the bin sizes are not all equal, but I think the help
file is not clear with what this argument does.

Jason
--
Assistant Professor of Statistics
Mathematics and Computer Science Department
University of Richmond, Virginia 23173
(804) 289-8081   fax:(804) 287-6664
http://www.mathcs.richmond.edu/~wowen



From Lorenz.Gygax at fat.admin.ch  Tue Sep  2 16:16:25 2003
From: Lorenz.Gygax at fat.admin.ch (Lorenz.Gygax@fat.admin.ch)
Date: Tue, 2 Sep 2003 16:16:25 +0200 
Subject: [R] Hangup on save.image () / q ()
Message-ID: <210BCBFA22E42D4C9135491A294984DEB4F9B9@evd-s7013.evd.admin.ch>


Dear all,

I am doing some data handling and tabualtions and then I am using glmmPQL to
fit a binomial hierarchical model (which I assign to a new object). If I do
a save.image () or a q ('yes') after this, I get the following warning
messages:

Warning messages: 
1: namespaces may not be available when loading 
2: names in persistent strings are currently ignored 

Sometimes R seems to shut down properly, sometimes R hangs up during the
quit, in any case R cannot be restarted after this because the .RData seems
to be corrupt.

This is on R Version 1.7.0 (2003-04-16) on Windows and it happens both, if I
am using Emacs with ESS or the R-Gui.exe. .RData is about 200 KB before I do
the hierarchical model. After the hang up, the unusable file is about 1200
KB.

Any ideas what is happening or pointers where I should be looking (I tried
the R archives but did not seem to find the right key word)?

Many thanks, Lorenz
- 
Lorenz Gygax
Tel: +41 52 368 33 84 / lorenz.gygax at fat.admin.ch      
Center for proper housing of ruminants and pigs
Swiss Veterinary Office, FAT, CH-8356 T?nikon / Switzerland



From christian.ritter at shell.com  Tue Sep  2 16:18:06 2003
From: christian.ritter at shell.com (Ritter, Christian C MCIL-CTGAS)
Date: Tue, 2 Sep 2003 16:18:06 +0200
Subject: [R] R/Chemometrics/reading .spa files into R.
Message-ID: <156CDC8CCFD1894295D2907F16337A481FA910@bru-s-006.europe.shell.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030902/a60ebb2c/attachment.pl

From m.grum at cgiar.org  Tue Sep  2 16:00:49 2003
From: m.grum at cgiar.org (Grum, Mikkel [IPGRI-SSA-Nairobi])
Date: Tue, 02 Sep 2003 07:00:49 -0700
Subject: [R] Plotting dates
Message-ID: <FC788AB9771FD6118E6F0002A5AD7B8F019B7E4A@icrafnttrain.icraf.cgiar.org>

I'm trying to plot observations against observation dates and getting julian
dates along the x-axis:

library(date)
Week<-as.date(c("05/02/03","05/09/03","05/16/03","05/23/03","05/30/03","06/0
7/03","06/14/03"))
Leafminers<-c(0,2,5,10,4,6,5)
Diglyphus<-c(0,0,4,5,7,3,1)
LeafDig<-cbind(Week,Leafminers,Diglyphus)
plot(LeafDig,ylim=c(0,20),main="Leafminers",ylab="Observed
numbers",xlab="",adj=0,bty="l")
points(Diglyphus,pch=2)
lines(Diglyphus,lty=2)
legend(1,18,c("Leafminers","Diglyphus"),lty=c(1,2),pch=c(1,2))

How do I get some more intelligeble dates, like the dates below (but
preferably with 03, ie. 2May03) and spaced with the observations (every
seventh day) rather than the 10 days that seem to be default??

> Week
[1] 2May3  9May3  16May3 23May3 30May3 7Jun3  14Jun3

ALSO, why won't the three last lines of code in the top example show on the
graph?

cheers,
Mikkel



Mikkel Grum
International Plant Genetic Resources Institute (IPGRI)
Sub-Saharan Africa Group
***
PO Box 30677
00100 Nairobi, Kenya
Tel: +254 20 524505(direct)/524500(IPGRI)
Fax: +254 20 524501(IPGRI)/524001(ICRAF)
m.grum at cgiar.org
www.ipgri.org



From ernesto at ipimar.pt  Tue Sep  2 16:29:34 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Tue, 02 Sep 2003 15:29:34 +0100
Subject: [R] package xtable
Message-ID: <1062512973.9820.26.camel@gandalf.local>

Hi,

How can I avoid xtable of printing rownumbers when exporting a
data.frame ?

Are there more packages that deal with LaTeX besides xtable and Sweave ?

Thanks

EJ



From JonesW at kssg.com  Tue Sep  2 16:40:03 2003
From: JonesW at kssg.com (Wayne Jones)
Date: Tue, 2 Sep 2003 15:40:03 +0100 
Subject: [R] FW: Creating a Package with Windows XP.
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB021F0E3F@gimli.middleearth.kssg.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030902/97949622/attachment.pl

From ligges at statistik.uni-dortmund.de  Tue Sep  2 16:59:04 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 02 Sep 2003 16:59:04 +0200
Subject: [R] FW: Creating a Package with Windows XP.
In-Reply-To: <6B5A9304046AD411BD0200508BDFB6CB021F0E3F@gimli.middleearth.kssg.com>
References: <6B5A9304046AD411BD0200508BDFB6CB021F0E3F@gimli.middleearth.kssg.com>
Message-ID: <3F54B038.7050200@statistik.uni-dortmund.de>

Wayne Jones wrote:

> Thanks for that.
> 
> Ive moved everything into a new directory and the command: 
> 
> C:WayneTemp\rw1071\bin>Rcmd BUILD AnExample 
> 
> now works producing the file AnExample_1.0.tar.gz
> 
> However, the command C:WayneTemp\rw1071\bin>Rcmd check AnExample 
> still produces the following error message: 
> 
> C:\Program Files\R\rw1071\bin>Rcmd check AnExample
> * checking for working latex ...latex: not found
>  NO
> * using log directory 'C:/Program Files/R/rw1071/bin/AnExample.Rcheck'
> * checking for file 'AnExample/DESCRIPTION' ... OK
> * checking if this is a source package ... ERROR
> Only *source* packages can be checked.
> 
> 
> Any help would be much appreciated. 

So you have a "Built" field in your DESCRIPTION file? Remove it.

If not:
Do you have set up that directory using package.skeleton() and followed 
the instructions given in ?package.skeleton and the ReadMes within the 
directory structure exactly?

Uwe Ligges


> Regards
> Wayne
> 
> 
> 
> -----Original Message-----
> From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de]
> Sent: 02 September 2003 14:53
> To: Wayne Jones
> Cc: 'r-help at stat.math.ethz.ch'
> Subject: Re: [R] FW: Creating a Package with Windows XP.
> 
> 
> Wayne Jones wrote:
> 
> 
>>>Hi there fellow R-Users, 
>>>
>>>I am trying to use the "package.skeleton" to create my own package with
>>>R.1.7.1 on Windows XP Professional.
>>>I have followed the package.skeleton example and have downloaded the
>>>necessary files found at http://www.stats.ox.ac.uk/pub/Rtools/tools.zip.
>>>
>>>and perl5, available via http://www.activestate.com/Products/ActivePerl/.
>>>
>>>When I run the command "Rcmd BUILD AnExample" I get the following output
>>>and error message: 
>>>
>>>
>>>C:\Program Files\R\rw1071\bin>Rcmd BUILD AnExample
>>>* checking for file 'AnExample/DESCRIPTION' ... OK
>>>* preparing 'AnExample':
>>>* cleaning src
>>>* checking whether 'INDEX' is up-to-date ... OK
>>>* checking whether 'data/00Index' is up-to-date ... OK
>>>* removing junk files
>>>* building 'AnExample_1.0.tar.gz'
>>>tar: Files/R/rw1071/bin/AnExample_1.0.tar: Cannot stat: No such file or
>>>director
>>>y
>>>tar: Error exit delayed from previous errors
>>>AnExample_1.0.tar: No such file or directory
>>>
> 
> 
> Do not use blanks in your paths ("Program Files").
> 
> Uwe Ligges
> 
> 
> 
>>>Whaen I run Rcmd check AnExample I get the following error message
>>>
>>>C:\Program Files\R\rw1071\bin>Rcmd check AnExample
>>>* checking for working latex ...latex: not found
>>>NO
>>>* using log directory 'C:/Program Files/R/rw1071/bin/AnExample.Rcheck'
>>>* checking for file 'AnExample/DESCRIPTION' ... OK
>>>* checking if this is a source package ... ERROR
>>>Only *source* packages can be checked.
>>>
>>>
>>>What am I doing wrong??
>>>Any help would be much appreciated, 
>>>
>>>Regards,
>>>
>>>Wayne
>>>
>>>
>>>
>>>
>>>Dr Wayne R. Jones
>>>Statistician / Research Analyst
>>>KSS Group plc
>>>St James's Buildings
>>>79 Oxford Street
>>>Manchester M1 6SS
>>>Tel: +44(0)161 609 4084
>>>Mob: +44(0)7810 523 713
>>>
>>>
>>
>>
>>
>>KSS Ltd
>>Seventh Floor  St James's Buildings  79 Oxford Street  Manchester  M1 6SS
> 
> England
> 
>>Company Registration Number 2800886
>>Tel: +44 (0) 161 228 0040	Fax: +44 (0) 161 236 6305
>>mailto:kssg at kssg.com		http://www.kssg.com
>>
>>
>>The information in this Internet email is confidential and m...{{dropped}}
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 
>



From Giles.Heywood at CommerzbankIB.com  Tue Sep  2 16:58:42 2003
From: Giles.Heywood at CommerzbankIB.com (Heywood, Giles)
Date: Tue, 2 Sep 2003 15:58:42 +0100 
Subject: [R] Plotting dates
Message-ID: <8CBAA121CEB4D5118CB200508BB2BBEF54048A@xmx8lonib.lonib.commerzbank.com>


One solution is to use the Irregular Time-Series (its) package
on CRAN.

LeafDig <- cbind(Leafminers,Diglyphus)
dimnames(LeafDig)[[1]] <-
c("05/02/03","05/09/03","05/16/03","05/23/03","05/30/03","06/07/03","06/14/0
3")
require("its")
its.format("%m/%d/%y")
plot(its(LeafDig),format="%d %b %y")

You can select date format you require via the format parameter.

Giles

> -----Original Message-----
> From: Grum, Mikkel [IPGRI-SSA-Nairobi] [mailto:m.grum at cgiar.org]
> Sent: 02 September 2003 15:01
> To: r-help at stat.math.ethz.ch
> Subject: [R] Plotting dates
> 
> 
> I'm trying to plot observations against observation dates and 
> getting julian
> dates along the x-axis:
> 
> library(date)
> Week<-as.date(c("05/02/03","05/09/03","05/16/03","05/23/03","0
> 5/30/03","06/0
> 7/03","06/14/03"))
> Leafminers<-c(0,2,5,10,4,6,5)
> Diglyphus<-c(0,0,4,5,7,3,1)
> LeafDig<-cbind(Week,Leafminers,Diglyphus)
> plot(LeafDig,ylim=c(0,20),main="Leafminers",ylab="Observed
> numbers",xlab="",adj=0,bty="l")
> points(Diglyphus,pch=2)
> lines(Diglyphus,lty=2)
> legend(1,18,c("Leafminers","Diglyphus"),lty=c(1,2),pch=c(1,2))
> 
> How do I get some more intelligeble dates, like the dates below (but
> preferably with 03, ie. 2May03) and spaced with the 
> observations (every
> seventh day) rather than the 10 days that seem to be default??
> 
> > Week
> [1] 2May3  9May3  16May3 23May3 30May3 7Jun3  14Jun3
> 
> ALSO, why won't the three last lines of code in the top 
> example show on the
> graph?
> 
> cheers,
> Mikkel
> 
> 
> 
> Mikkel Grum
> International Plant Genetic Resources Institute (IPGRI)
> Sub-Saharan Africa Group
> ***
> PO Box 30677
> 00100 Nairobi, Kenya
> Tel: +254 20 524505(direct)/524500(IPGRI)
> Fax: +254 20 524501(IPGRI)/524001(ICRAF)
> m.grum at cgiar.org
> www.ipgri.org
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


********************************************************************** 
This is a commercial communication from Commerzbank AG.\ \ T...{{dropped}}



From Geert.Aarts at wur.nl  Tue Sep  2 17:06:49 2003
From: Geert.Aarts at wur.nl (Aarts, Geert)
Date: Tue, 2 Sep 2003 17:06:49 +0200
Subject: [R] convert character to POSIXct
Message-ID: <AF44D9769360274EACBCFC0473D436D00119C774@scomp0010>

Dear list-members,
I would like to calculate the difference between two points in time. To convert a 'time (GMT)'-character with the format "1/1/1999 01:01:01" into an object of class "POSIXct"', I first use the strptime() as suggested in the details help(as.POSIXct).
e.g.
starttime<-strptime("1/1/1999 01:01:01",format="%d/%m/%Y %H:%M:%S")
endtime<-strptime("1/8/1999 01:01:01",format="%d/%m/%Y %H:%M:%S")
> starttime
[1] "1999-01-01 01:01:01"
> endtime
[1] "1999-08-01 01:01:01"

If I substract these from each other, 
endtime-starttime
>Time difference of 211.9583 days
Which should mean that the default is in day light saving.
 
Next I convert these times into as.POSIXct and substract them
 as.POSIXct(starttime)
[1] "1999-01-01 01:01:01 GMT Standard Time"
as.POSIXct(endtime)
[1] "1999-08-01 01:01:01 GMT Standard Time"
as.POSIXct(endtime)-as.POSIXct(starttime)
Time difference of 211.9583 days

So although the calculation suggest time is in daylight saving, it actually states that it is in "GMT Standard Time"
Can somebody tell me whether my thoughts are correct and if not, tell me why this is happening?
 
PS.
> as.POSIXct(endtime, tz="GMT")-as.POSIXct(starttime, tz="GMT")
Time difference of 212 days
So this seems to work correctly.
 
Kinds regards, Geert (Windows, R-version 1.7.0)



From ripley at stats.ox.ac.uk  Tue Sep  2 17:21:10 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 2 Sep 2003 16:21:10 +0100 (BST)
Subject: [R] convert character to POSIXct
In-Reply-To: <AF44D9769360274EACBCFC0473D436D00119C774@scomp0010>
Message-ID: <Pine.LNX.4.44.0309021618400.11518-100000@gannet.stats>

You converted to POSIXct in your local time zone.  It has a tz argument: 
use it if you want GMT.

On Tue, 2 Sep 2003, Aarts, Geert wrote:

> I would like to calculate the difference between two points in time. To
> convert a 'time (GMT)'-character with the format "1/1/1999 01:01:01"
> into an object of class "POSIXct"', I first use the strptime() as
> suggested in the details help(as.POSIXct).

> e.g.
> starttime<-strptime("1/1/1999 01:01:01",format="%d/%m/%Y %H:%M:%S")
> endtime<-strptime("1/8/1999 01:01:01",format="%d/%m/%Y %H:%M:%S")
> > starttime
> [1] "1999-01-01 01:01:01"
> > endtime
> [1] "1999-08-01 01:01:01"
> 
> If I substract these from each other, 
> endtime-starttime
> >Time difference of 211.9583 days
> Which should mean that the default is in day light saving.

It's your local timezone, as the help page says.

> Next I convert these times into as.POSIXct and substract them
>  as.POSIXct(starttime)
> [1] "1999-01-01 01:01:01 GMT Standard Time"
> as.POSIXct(endtime)
> [1] "1999-08-01 01:01:01 GMT Standard Time"
> as.POSIXct(endtime)-as.POSIXct(starttime)
> Time difference of 211.9583 days
> 
> So although the calculation suggest time is in daylight saving, it
> actually states that it is in "GMT Standard Time" Can somebody tell me
> whether my thoughts are correct and if not, tell me why this is
> happening?

Because you asked for it to be done!

> PS.
> > as.POSIXct(endtime, tz="GMT")-as.POSIXct(starttime, tz="GMT")
> Time difference of 212 days
> So this seems to work correctly.

So does the rest of your code.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From junwen at astro.ocis.temple.edu  Tue Sep  2 17:40:55 2003
From: junwen at astro.ocis.temple.edu (Junwen wang)
Date: Tue, 2 Sep 2003 11:40:55 -0400 (EDT)
Subject: [R] normalize data
Message-ID: <Pine.OSF.4.53.0309021139440.650159@gs873ps>

Hi,
I have two set of data (not microarray data) and I want to compare
them, Is there any function in R can do this?

Thanks
Junwen



From p.dalgaard at biostat.ku.dk  Tue Sep  2 17:47:08 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Tue, 02 Sep 2003 15:47:08 -0000
Subject: [R] I don't understand this
In-Reply-To: <Pine.A41.4.44.0309020653100.46986-100000@homer18.u.washington.edu>
References: <Pine.A41.4.44.0309020653100.46986-100000@homer18.u.washington.edu>
Message-ID: <x2bru3chuj.fsf@biostat.ku.dk>

Thomas Lumley <tlumley at u.washington.edu> writes:

> I would have said that the behavior of
>    (if (cond) names else dim)(x) <- 10
> is undefined in the S language, along with things like the order of
> evaluation of the apply functions.

Actually, following Luke's analysis, I think it is pretty squarely an
error, which we just weren't quite good enough at detecting... 

BTW: If you ever actually need to do something like that, try

eval(substitute(foo(x)<-10,list(foo=as.name(if (cond) "names" else "dim")))) 


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From B.Rowlingson at lancaster.ac.uk  Tue Sep  2 18:00:35 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 02 Sep 2003 17:00:35 +0100
Subject: [R] I don't understand this
In-Reply-To: <x2bru3chuj.fsf@biostat.ku.dk>
References: <Pine.A41.4.44.0309020653100.46986-100000@homer18.u.washington.edu>
	<x2bru3chuj.fsf@biostat.ku.dk>
Message-ID: <3F54BEA3.3080501@lancaster.ac.uk>

Peter Dalgaard BSA wrote:

> BTW: If you ever actually need to do something like that, try
> 
> eval(substitute(foo(x)<-10,list(foo=as.name(if (cond) "names" else "dim")))) 
> 

please nooooo!!! What's wrong with:

  if(cond){
    names(x) <- 10
   } else {
    dim(x) <- 10
  }

  readable, obvious, maintainable, 'portable' for some value of 
'portable'....

  although I'd also want to add a comment explaining why you are 
conditionally setting either the names or the dimension of 'x' to 10....

Baz



From marie-agnes.coutellec at univ-rennes1.fr  Tue Sep  2 18:12:42 2003
From: marie-agnes.coutellec at univ-rennes1.fr (=?iso-8859-1?Q?Marie-Agn=E8s?= Coutellec)
Date: Tue, 02 Sep 2003 18:12:42 +0200
Subject: [R] bootstrap and sample size
Message-ID: <4.2.0.58.20030902180522.009edc30@mailhost.univ-rennes1.fr>

Hello,
I am trying to bootstrap the following statistic:
1- x/y
using different sample sizes for x and y (x and y are not paired data). 
Apparently, only one sample size can be handled, and the na.action 
(na.exclude) does not work with boot.
Could anyone help ?
thanks a lot


Marie-Agn?s Coutellec
UMR CNRS - Universit? 6553 ECOBIO
Universit? de Rennes 1
Campus de Beaulieu, Batiment 14
263 avenue du General Leclerc, CS 74205
35042 RENNES Cedex - FRANCE
Tel: 33-(0)223235036
marie-agnes.coutellec at univ-rennes1.fr
http://www.umr6553.univ-rennes1.fr



From Simon.Fear at synequanon.com  Tue Sep  2 18:18:31 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Tue, 2 Sep 2003 17:18:31 +0100
Subject: [R] I don't understand this
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572AC0DAA@synequanon01>

Please choose answer:
a) you beat me to it making a great point
b) it's got two too many pairs of braces in it, that's whats wrong with
it!

But seriously, I am sure Richard O'K had no intention of doing any such
thing.
The question was just about the syntax of R, no?

Isn't it the case that

(expr)(expr)

is incorrect syntax under any circumstances?

> -----Original Message-----
> From: Barry Rowlingson [mailto:B.Rowlingson at lancaster.ac.uk]
> please nooooo!!! What's wrong with:
> 
>   if(cond){
>     names(x) <- 10
>    } else {
>     dim(x) <- 10
>   }
>
 

Simon Fear
Senior Statistician
Syne qua non Ltd
Tel: +44 (0) 1379 644449
Fax: +44 (0) 1379 644445
email: Simon.Fear at synequanon.com
web: http://www.synequanon.com
 
Number of attachments included with this message: 0
 
This message (and any associated files) is confidential and\...{{dropped}}



From djw1005 at cam.ac.uk  Tue Sep  2 18:38:12 2003
From: djw1005 at cam.ac.uk (Damon Wischik)
Date: Tue, 2 Sep 2003 17:38:12 +0100 (BST)
Subject: [R] Hangup on save.image () / q ()
Message-ID: <Pine.SOL.3.96.1030902171116.12756A-100000@libra.cus.cam.ac.uk>


> I am doing some data handling and tabualtions and then I am using 
> glmmPQL to fit a binomial hierarchical model (which I assign to a
> new object). If I do a save.image () or a q ('yes') after this, I
> get the following warning messages: 
>   Warning messages: 
>   1: namespaces may not be available when loading 
>   2: names in persistent strings are currently ignored 
> Sometimes R seems to shut down properly, sometimes R hangs up during 
> the quit, in any case R cannot be restarted after this because the
> .RData seems to be corrupt.

I have trouble with closing R under ESS.  I have this trouble _every_time_
I plot any graphics at all. I've had the same trouble under several
Windows 2000 and Windows XP machines, under both Emacs and Xemacs. I don't
know why other people don't have the same trouble. I don't have any
trouble when I don't plot any graphics. (But then, I never do
save.image()). Do you plot any graphics in your R session? 

I posted messages to the r-help and ess-help mailing lists:
  http://maths.newcastle.edu.au/~rking/R/help/03a/2183.html
  https://www.stat.math.ethz.ch/pipermail/ess-help/2003-March/001363.html

>From r-help, I was told that it's a Windows/Emacs issue, and not a topic
for r-help. From ess-help, I was told that it's a Windows/Emacs issue, one
which "either R can fix or Emacs can fix", and not a topic for ess-help.
It's something to do with relinquishing file handles, and "it probably
won't get fixed anytime soon".

I assume we're in a minority. Otherwise, the R FAQ for all platforms
should give a warning rather than just saying
  6.2 Should I run R from within Emacs?
  Yes, _definitely_.
and the R FAQ for Windows would mention it.

The only question left is: how do you cope with it? I still use ESS, and I
close my sessions by switching off Emacs, which then has Windows do the
dirty business of shutting down R, because this way I don't have to put up
with unresponsive windows. Of course, this is no help to you, as you want
to save your data...

Damon Wischik.



From th50 at leicester.ac.uk  Tue Sep  2 18:40:58 2003
From: th50 at leicester.ac.uk (Hotz, T.)
Date: Tue, 2 Sep 2003 17:40:58 +0100
Subject: [R] I don't understand this
Message-ID: <1F2CE8D4B0195E488213E8B8CCF7148602501344@saffron.cfs.le.ac.uk>


> -----Original Message-----
> From: Simon Fear [mailto:Simon.Fear at synequanon.com]
> Sent: 02 September 2003 17:19
> To: Barry Rowlingson; Peter Dalgaard BSA
> Cc: r-help at r-project.org
> Subject: RE: [R] I don't understand this

> Isn't it the case that
> 
> (expr)(expr)
> 
> is incorrect syntax under any circumstances?

No, you could have a function definition on the left:

> (function(x)x^2)(2)
[1] 4

HTH

Thomas

---

Thomas Hotz
Research Associate in Medical Statistics
University of Leicester
United Kingdom

Department of Epidemiology and Public Health
22-28 Princess Road West
Leicester
LE1 6TP
Tel +44 116 252-5410
Fax +44 116 252-5423

Division of Medicine for the Elderly
Department of Medicine
The Glenfield Hospital
Leicester
LE3 9QP
Tel +44 116 256-3643
Fax +44 116 232-2976



From tzhou1 at students.uiuc.edu  Tue Sep  2 20:07:23 2003
From: tzhou1 at students.uiuc.edu (tzhou1)
Date: Tue, 2 Sep 2003 13:07:23 -0500
Subject: [R] weights in mixed model
Message-ID: <3F5B4BF0@webmail.uiuc.edu>

Hi,

I have a question about how to do case weight in mixed model using R. I read 
Pinhiero and Bates (2000) Mixed-Effects Models in S and S-Plus. The weight 
functions in there are not what I wanted. Can R do case weight, giving each 
observation my own weight? If so, could you give me some references and 
examples? I'm looking forward to hearing from you!

Tianyue



From tlumley at u.washington.edu  Tue Sep  2 20:27:00 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 2 Sep 2003 11:27:00 -0700 (PDT)
Subject: [R] I don't understand this
In-Reply-To: <6C8A8033ABC1E3468048ABC4F13CE572AC0DAA@synequanon01>
Message-ID: <Pine.A41.4.44.0309021120170.125676-100000@homer35.u.washington.edu>

On Tue, 2 Sep 2003, Simon Fear wrote:

> Please choose answer:
> a) you beat me to it making a great point
> b) it's got two too many pairs of braces in it, that's whats wrong with
> it!
>
> But seriously, I am sure Richard O'K had no intention of doing any such
> thing.
> The question was just about the syntax of R, no?
>
> Isn't it the case that
>
> (expr)(expr)
>
> is incorrect syntax under any circumstances?

Nope.

It's *usually* incorrect, but not always

  power<-function(lambda) function(x) x^lambda

  (power(3))(2)

is perfectly valid.

You could also define, say, %*% to be a composition operator on some group
of functions and write
  (f %*% g)(x)
quite sensibly.


It may be the case that (expr)(expr)<-  is always invalid.


	-thomas



From tlumley at u.washington.edu  Tue Sep  2 20:28:40 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 2 Sep 2003 11:28:40 -0700 (PDT)
Subject: [R] weights in mixed model
In-Reply-To: <3F5B4BF0@webmail.uiuc.edu>
Message-ID: <Pine.A41.4.44.0309021127130.125676-100000@homer35.u.washington.edu>

On Tue, 2 Sep 2003, tzhou1 wrote:

> Hi,
>
> I have a question about how to do case weight in mixed model using R. I read
> Pinhiero and Bates (2000) Mixed-Effects Models in S and S-Plus. The weight
> functions in there are not what I wanted. Can R do case weight, giving each
> observation my own weight? If so, could you give me some references and
> examples? I'm looking forward to hearing from you!
>

It depends on what you mean by weights.

The standard thing to mean in regression is weights that are inversely
proportional to variances, but lme() does this, so I assume you mean
something else.  What?


	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From p.dalgaard at biostat.ku.dk  Tue Sep  2 20:45:55 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Tue, 02 Sep 2003 18:45:55 -0000
Subject: [R] I don't understand this
In-Reply-To: <Pine.A41.4.44.0309021120170.125676-100000@homer35.u.washington.edu>
References: <Pine.A41.4.44.0309021120170.125676-100000@homer35.u.washington.edu>
Message-ID: <x27k4rc9kb.fsf@biostat.ku.dk>

Thomas Lumley <tlumley at u.washington.edu> writes:

> It may be the case that (expr)(expr)<-  is always invalid.

Semantically, maybe, but not syntactically. I.e. we can't catch it in
the parser, because "<-" is just another operator, and someone might
redefine it to something where that lhs makes sense (this is not quite
as crazy as it sounds; think about what is happening with other
operators inside model formulas).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From p.dalgaard at biostat.ku.dk  Tue Sep  2 20:56:24 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Tue, 02 Sep 2003 18:56:24 -0000
Subject: [R] I don't understand this
In-Reply-To: <3F54BEA3.3080501@lancaster.ac.uk>
References: <Pine.A41.4.44.0309020653100.46986-100000@homer18.u.washington.edu>
	<x2bru3chuj.fsf@biostat.ku.dk> <3F54BEA3.3080501@lancaster.ac.uk>
Message-ID: <x23cffc92q.fsf@biostat.ku.dk>

Barry Rowlingson <B.Rowlingson at lancaster.ac.uk> writes:

> Peter Dalgaard BSA wrote:
> 
> > BTW: If you ever actually need to do something like that, try
> > eval(substitute(foo(x)<-10,list(foo=as.name(if (cond) "names" else
> > "dim"))))
> 
> please nooooo!!! What's wrong with:
> 
>   if(cond){
>     names(x) <- 10
>    } else {
>     dim(x) <- 10
>   }
> 
>   readable, obvious, maintainable, 'portable' for some value of
> 'portable'....

Well, there's nothing nonportable with my suggestion either. I thought
that "ever actually need to" would suffice to indicate that I wasn't
suggesting it as good programming practice. 

Nothing wrong with your code, except perhaps generality; I was
thinking in terms of "function that specifies which replacement
function to use", which could involve a larger set of possible
functions than names()<- and dim()<-. 

However, I'd be hard pressed to come up with a case where this would
occur in practice.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From megk at ualberta.ca  Tue Sep  2 21:23:29 2003
From: megk at ualberta.ca (Meg Krawchuk)
Date: Tue, 2 Sep 2003 13:23:29 -0600
Subject: [R] roc for mixed models
Message-ID: <000801c37187$b0ce7570$369c8081@renr.ualberta.ca>

Hello. 
I'm looking for information on model assessment using ROC in a mixed
model environment accessible through R or SPLUS. I just found an article
in the Journal of Statistical Software (Liu & Wu. 2003. Estimating the
area under a receiver operating characteristic (ROC) curve for repeated
measures design. www.jstatsoft.org/v08/i12/roc.pdf) giving details of
new code for SAS. Does this exist in R? I didn't see any mention in my
searches thru roc/mixed/glmm/glmmPQL/repeated/lme, etc... on the
r-project site so thought I would take a stab at a general call for
help.

Thanks in advance,
Meg.


***************************************************************
Meg Krawchuk
Department of Renewable Resources
7-51 General Services Building
University of Alberta
Edmonton, Alberta
T6G 2H1
megk at ualberta.ca
http://www.ualberta.ca/~megk/web_page.html



From kjetil at entelnet.bo  Tue Sep  2 21:31:45 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Tue, 02 Sep 2003 15:31:45 -0400
Subject: [R] identify with image
Message-ID: <3F54B7E1.7714.1B4CD4@localhost>

Hola!

I will want to identify pixels in an image with the mouse, for 
so getting the image data from the matrix(es), for use in subsequent 
discriminant analysis. But the following bombs R:
(windows XP, rw1071)

> str(baboon)
 list()
 - attr(*, "size")= int [1:2] 512 512
 - attr(*, "cellres")= num [1:2] 1 1
 - attr(*, "bbox")= num [1:4] 0 0 512 512
 - attr(*, "channels")= chr "grey"
 - attr(*, "bbcent")= logi FALSE
 - attr(*, "class")= chr "pixmapGrey"
 - attr(*, "grey")= num [1:512, 1:512] 0.537 0.510 0.345 0.259 0.322 
...
> class(baboon)
[1] "pixmapGrey"
> library(pixmap)
> plot(baboon)
> identify(baboon, n=1)

... and then R bombs!

What to do?

Kjetil Halvorsen



From krcabrer at unalmed.edu.co  Tue Sep  2 22:37:52 2003
From: krcabrer at unalmed.edu.co (Kenneth Cabrera)
Date: Tue, 02 Sep 2003 15:37:52 -0500
Subject: [R] identify with image
In-Reply-To: <3F54B7E1.7714.1B4CD4@localhost>
References: <3F54B7E1.7714.1B4CD4@localhost>
Message-ID: <opruv3let2faouaq@200.24.8.4>

Hi, Dr Halvorsen

Try
identify(expand.grid(1:512,1:512))

But, be careful with the index of the matrix (image)



On Tue, 02 Sep 2003 15:31:45 -0400, kjetil brinchmann halvorsen 
<kjetil at entelnet.bo> wrote:

> Hola!
>
> I will want to identify pixels in an image with the mouse, for so getting 
> the image data from the matrix(es), for use in subsequent discriminant 
> analysis. But the following bombs R:
> (windows XP, rw1071)
>
>> str(baboon)
> list()
> - attr(*, "size")= int [1:2] 512 512
> - attr(*, "cellres")= num [1:2] 1 1
> - attr(*, "bbox")= num [1:4] 0 0 512 512
> - attr(*, "channels")= chr "grey"
> - attr(*, "bbcent")= logi FALSE
> - attr(*, "class")= chr "pixmapGrey"
> - attr(*, "grey")= num [1:512, 1:512] 0.537 0.510 0.345 0.259 0.322 ...
>> class(baboon)
> [1] "pixmapGrey"
>> library(pixmap)
>> plot(baboon)
>> identify(baboon, n=1)
>
> ... and then R bombs!
>
> What to do?
>
> Kjetil Halvorsen
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



--



From Roger.Bivand at nhh.no  Tue Sep  2 23:42:49 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 2 Sep 2003 23:42:49 +0200 (CEST)
Subject: [R] identify with image
In-Reply-To: <3F54B7E1.7714.1B4CD4@localhost>
Message-ID: <Pine.LNX.4.44.0309022313190.19967-100000@reclus.nhh.no>

On Tue, 2 Sep 2003, kjetil brinchmann halvorsen wrote:

> Hola!
> 
> I will want to identify pixels in an image with the mouse, for 
> so getting the image data from the matrix(es), for use in subsequent 
> discriminant analysis. But the following bombs R:
> (windows XP, rw1071)
> 
> > str(baboon)
>  list()
>  - attr(*, "size")= int [1:2] 512 512
>  - attr(*, "cellres")= num [1:2] 1 1
>  - attr(*, "bbox")= num [1:4] 0 0 512 512
>  - attr(*, "channels")= chr "grey"
>  - attr(*, "bbcent")= logi FALSE
>  - attr(*, "class")= chr "pixmapGrey"
>  - attr(*, "grey")= num [1:512, 1:512] 0.537 0.510 0.345 0.259 0.322 
> ...
> > class(baboon)
> [1] "pixmapGrey"
> > library(pixmap)
> > plot(baboon)
> > identify(baboon, n=1)
> 
> ... and then R bombs!
> 
> What to do?
> 

As Kenneth said, give identify() the expanded grid of points, but there is
something wrong here:

> library(pixmap)
> example(pixmap)
....
pixmap> plot(z[1:20, 10:40])
> identify(z, n=1)

Program received signal SIGSEGV, Segmentation fault.
do_set (call=0x869ce7c, op=0x8299648, args=0x869ce98, rho=0x8f2496c)
    at eval.c:1308
1308                switch (NAMED(s)) {


The identify.default() function is passing the pixmap object through to
xy.coords(), which returns two empty x and y vectors, which are checked
for length in the R code - xy.coords() treats the pixmap object as a list, 
does:

} else if (is.list(x)) {
    xlab <- paste(ylab, "$x", sep = "")
    ylab <- paste(ylab, "$y", sep = "")
    y <- x[["y"]]
    x <- x[["x"]]
} else {

and y and x are the same length, so returns to identify.default() with 
nothing, which is passed on to the .Internal() undetected. Two 
possibilities - an identify.pixmap() in pixmap, or a test for the 
(package, S4) pixmap class in xy.coords. But as it stands, it's a quick 
way to exit the program. xy.coords() seems to be trusting the user to have 
a list with x and y components, and here it has neither. The list is 
indeed empty, being an S4 class - it just has attributes.


> version
_                
platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    7.1              
year     2003             
month    06               
day      16               
language R        
Package: pixmap
Version: 0.3-2


> Kjetil Halvorsen
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From tzhou1 at students.uiuc.edu  Wed Sep  3 00:07:06 2003
From: tzhou1 at students.uiuc.edu (tzhou1)
Date: Tue, 2 Sep 2003 17:07:06 -0500
Subject: [R] weights in mixed model
Message-ID: <3F5E1954@webmail.uiuc.edu>

>It depends on what you mean by weights.
>
>The standard thing to mean in regression is weights that are inversely
>proportional to variances, but lme() does this, so I assume you mean
>something else.  What?


I want to use weights based on the residuals (not the usual residuals, refer
to Markatou, M. (1996), ??Robust statistical inference: weighted likelihoods
or usual M-estimation??? Communications in Statistics, Theory and Methods, 25,
2597-2613.). Basically, I want to calculate my own weights first, then use
them in the mixed model in R. Can R do this?

Thank you very much for your reply!

Tianyue



From Kurt.Sys at UGent.be  Wed Sep  3 00:13:29 2003
From: Kurt.Sys at UGent.be (Kurt Sys)
Date: Wed,  3 Sep 2003 00:13:29 +0200
Subject: [R] help file extension
In-Reply-To: <6r7k4stapv.fsf@bates4.stat.wisc.edu>
References: <B3A80C9C13928B45B2FCE4C43656363A2DE5FC@mail-srv02.master.medizin.uni-essen.de>
	<1062447520.3f53a9a0651e8@mail.ugent.be>
	<o0e7lv8gedo0bu9lrn7ieg8mpegeptg8k1@4ax.com>
	<tnf7lvooikqpo5f3e3rilu7i3j0hkp6m42@4ax.com>
	<6r7k4stapv.fsf@bates4.stat.wisc.edu>
Message-ID: <1062540809.3f55160954f91@mail.ugent.be>

OK, that's more or less what I want.
tnx,
Kurt.

Quoting Douglas Bates <bates at stat.wisc.edu>:

> Duncan Murdoch <dmurdoch at pair.com> writes:
> 
> > On Mon, 01 Sep 2003 17:24:11 -0400, you wrote:
> > 
> > 
> > >You can put additional documentation in a "doc" subdirectory, 
> > 
> > That should be info/doc in the source...
> 
> I think you mean inst/doc



From steve.dutky at thomson.com  Wed Sep  3 00:30:15 2003
From: steve.dutky at thomson.com (Dutky, Steve)
Date: Tue, 2 Sep 2003 18:30:15 -0400 
Subject: [R] How to avoid automatic coercion to factor?
Message-ID: <6EEA47532CD0D611887500B0D04943453FBA42@tfsmdmsg7.tfn.com>

I have a function that manipulates a list of numeric and character
components of equal length and wants to return a data.frame.

EG, 

f<-function() { 
	a<-list(Int1=1:5,Char1=letters[1:5],Char2=letters[6:10])
	b<-data.frame(a)
}

How can I get the columns Char1, Char2, (...CharN) returned coerced to
character and not factor?

It appears that I could coerce individual columns by
b$CharI<-as.character(b$CharI). Is there a less ugly way of doing this?

Thanks, Steve Dutky
301-545-4113 desk
301-325-8146 cell
steve.dutky at thomson.com
www.thomson.com/financial



From jasont at indigoindustrial.co.nz  Wed Sep  3 02:38:58 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Wed, 03 Sep 2003 12:38:58 +1200
Subject: [R] package xtable
In-Reply-To: <1062512973.9820.26.camel@gandalf.local>
References: <1062512973.9820.26.camel@gandalf.local>
Message-ID: <3F553822.1010400@indigoindustrial.co.nz>

Ernesto Jardim wrote:
> Hi,
> 
> How can I avoid xtable of printing rownumbers when exporting a
> data.frame ?
> 
> Are there more packages that deal with LaTeX besides xtable and Sweave ?

Check out Frank Harrell Jr's "Hmisc" and "Design" packages (on CRAN). 
He also published a great booklet, available at the URL below, that 
includes the full LaTeX/S code used to produce it.  Nice.

http://hesweb1.med.virginia.edu/biostat/s/doc/summary.pdf

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz



From ok at cs.otago.ac.nz  Wed Sep  3 04:14:19 2003
From: ok at cs.otago.ac.nz (Richard A. O'Keefe)
Date: Wed, 3 Sep 2003 14:14:19 +1200 (NZST)
Subject: [R] I don't understand this
Message-ID: <200309030214.h832EJ3l252275@atlas.otago.ac.nz>

Thomas Lumley <tlumley at u.washington.edu> wrote:
	I would have said that the behavior of
	   (if (cond) names else dim)(x) <- 10
	is undefined in the S language, along with things like the order of
	evaluation of the apply functions.
	
The thing is, it would make perfect sense for
    (if (cond) f else g)(x) <- e
to have the effect of
    (if (cond) f(x) <- e else g(x) <- e)	    

In fact, I've used two programming languages where the analogue of
this _did_ work, and a third where it didn't but using only published
interfaces could very easily be made to work.

Another assignment-related thing I'm not clear on is what
    f(x) <<- e
is supposed to do.
    f(x) <- e
is equivalent to
    x <- "f<-"(x, value=e)
and
    x <<- e
assigns to x in the next outer environment,
but a simple macro-expansion of
    f(x) <<- e
to
    x <<- "f<-"(x, value=e)
may have the nasty effect of writing to an outer x a value derived from
an inner one.

Now, that seems to be exactly what happens in R:

> x <- c(1,2,3)
> f <- function(x) x[2] <<- x
> f(77)
> x
[1] 77 77

While the documentation and source code _could_ tell me whether this
is intentional, as far as I can tell (and I have, needless to say,
looked) they _don't_.

Now, despite its misleading opening screen (which says that the
target of an assignment is "a variable name (possibly quoted)",
?"<<-" goes on to say that
        vvv
     In all the assignment operator expressions, `x' can be a name or
        ^^^
     an expression defining a part of an object to be replaced (e.g.,
     `z[[1]]').  The name does not need to be quoted, though it can be.
(the arrows are my emphasis.)  So it's explict that f(x) <<- e is
*supposed* to be allowed and I don't need to ask about that.

The question is, what is f(x) <<- e supposed to do when there is an
x in the current environment as well as one in an outer environment?
It doesn't make much sense to fetch from one variable and store into
the other, but that's what R actually does.  Is that really what's
*supposed* to happen?

It would be perfectly possible to make f(x) <<- e use the same
variable in both places, and since the form is accepted by R,
I expected it to work that way.

Perhaps the simplest alternative that would still allow this form
to be used in non-confusing cases would be to issue an error message
if x is defined in the local environment; if it isn't, the simple macro
expansion will work just fine.

> x <- c(1,2,3)
> f <- function(y) x[2] <<- y
> f(77)
> x
[1]  1 77  3

This example works as ?"<<-" might lead one to expect.



From ok at cs.otago.ac.nz  Wed Sep  3 04:34:51 2003
From: ok at cs.otago.ac.nz (Richard A. O'Keefe)
Date: Wed, 3 Sep 2003 14:34:51 +1200 (NZST)
Subject: [R] I don't understand this
Message-ID: <200309030234.h832Ypiv262754@atlas.otago.ac.nz>

"Simon Fear" <Simon.Fear at synequanon.com> wrote:
	But seriously, I am sure Richard O'K had no intention of doing
	any such thing.  The question was just about the syntax of R, no?
	
Exactly so.

	Isn't it the case that
	
	(expr)(expr)
	
	is incorrect syntax under any circumstances?
	
No.

Functions are values in R, just like they are in C and Scheme.
And R accepts expressions in function position, just as C and Scheme do.

> (sqrt)(4)
[1] 2

> f <- c(sin,cos)
> f[[1]](0)
[1] 0
> f[[2]](0)
[1] 1

Beware:  f[1] and f[2] are lists, not functions; they don't work.

> (if (TRUE) cos else sin)(0)
[1] 1
> (if (FALSE) cos else sin)(0)
[1] 0

Not only is this all allowed by R's parser, it works just fine.
Why _should_ it be a syntax error?

There's one difference between f(x) and (f)(x).
The first is basically
    get("f", mode="function")(x)
while the second is basically
    get("f", mode="any")(x).
A couple of times this has kept me out of trouble when I've
unwittingly used c as a local numeric variable AND as the
column constructor function.  I'm not entirely sure that I'm
grateful for this; I never _meant_ to do any such thing and
I'd rather have been told about my mistake.  But that interpretation
of f(x) is clearly described in the New S book.



From deepayan at stat.wisc.edu  Wed Sep  3 04:38:44 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 2 Sep 2003 21:38:44 -0500
Subject: [R] How to avoid automatic coercion to factor?
In-Reply-To: <6EEA47532CD0D611887500B0D04943453FBA42@tfsmdmsg7.tfn.com>
References: <6EEA47532CD0D611887500B0D04943453FBA42@tfsmdmsg7.tfn.com>
Message-ID: <200309022138.44221.deepayan@stat.wisc.edu>


>From ?data.frame:

     Character variables passed to 'data.frame' are converted
     to factor columns unless protected by 'I'. If a list or data frame
     or matrix is passed to 'data.frame' it is as if each column had
     been passed as a separate argument.

See the Examples section for an example.

On Tuesday 02 September 2003 17:30, Dutky, Steve wrote:
> I have a function that manipulates a list of numeric and character
> components of equal length and wants to return a data.frame.
>
> EG,
>
> f<-function() {
> 	a<-list(Int1=1:5,Char1=letters[1:5],Char2=letters[6:10])
> 	b<-data.frame(a)
> }
>
> How can I get the columns Char1, Char2, (...CharN) returned coerced to
> character and not factor?
>
> It appears that I could coerce individual columns by
> b$CharI<-as.character(b$CharI). Is there a less ugly way of doing this?



From ripley at stats.ox.ac.uk  Wed Sep  3 06:50:41 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 3 Sep 2003 05:50:41 +0100 (BST)
Subject: [R] How to avoid automatic coercion to factor?
In-Reply-To: <200309022138.44221.deepayan@stat.wisc.edu>
Message-ID: <Pine.LNX.4.44.0309030544350.26990-100000@gannet.stats>

Deepayan is correct, but note that I() creates a column of class "AsIs", 
not "character".  We should ask why you want character columns in a data 
frame?   (Certainly prior to 1.8.0 there is a fair chance that unless they 
are of class "AsIs" manipulations would turn them into factors.)

If you really want character columns, the way to do it is underhand:

f <- function() {
    a <- list(Int1=1:5,Char1=letters[1:5],Char2=letters[6:10])
    attr(a, "row.names") <- 1:5
    attr(a, "class") <- "data.frame"
    a
}

However, you might consider returning a list.


On Tue, 2 Sep 2003, Deepayan Sarkar wrote:

> 
> >From ?data.frame:
> 
>      Character variables passed to 'data.frame' are converted
>      to factor columns unless protected by 'I'. If a list or data frame
>      or matrix is passed to 'data.frame' it is as if each column had
>      been passed as a separate argument.
> 
> See the Examples section for an example.
> 
> On Tuesday 02 September 2003 17:30, Dutky, Steve wrote:
> > I have a function that manipulates a list of numeric and character
> > components of equal length and wants to return a data.frame.
> >
> > EG,
> >
> > f<-function() {
> > 	a<-list(Int1=1:5,Char1=letters[1:5],Char2=letters[6:10])
> > 	b<-data.frame(a)
> > }
> >
> > How can I get the columns Char1, Char2, (...CharN) returned coerced to
> > character and not factor?
> >
> > It appears that I could coerce individual columns by
> > b$CharI<-as.character(b$CharI). Is there a less ugly way of doing this?
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From gisar at nus.edu.sg  Wed Sep  3 07:10:48 2003
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Wed, 3 Sep 2003 13:10:48 +0800
Subject: [R] normalize data
Message-ID: <CDA8D2689259E444942B3CDED8DD912933FF46@MBXSRV03.stf.nus.edu.sg>

boxplot(), scale(), hist() ... But this largely depends on what ascpect
of the data you want to compare and why.

-----Original Message-----
From: Junwen wang [mailto:junwen at astro.ocis.temple.edu] 
Sent: Tuesday, September 02, 2003 11:41 PM
To: R-help at stat.math.ethz.ch
Subject: [R] normalize data


Hi,
I have two set of data (not microarray data) and I want to compare them,
Is there any function in R can do this?

Thanks
Junwen

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ok at cs.otago.ac.nz  Wed Sep  3 08:08:28 2003
From: ok at cs.otago.ac.nz (Richard A. O'Keefe)
Date: Wed, 3 Sep 2003 18:08:28 +1200 (NZST)
Subject: [R] Another R syntax question
Message-ID: <200309030608.h8368Sgl319178@atlas.otago.ac.nz>

The file src/library/base/R/print.R
contains this line:

    x0 <- xm[okP]==0 != (as.numeric(Cf[okP])==0)

I didn't know R allowed that, and I wonder if it is deliberate?
                                        
In mathematics, you would expect x = y not= z to mean
(x = y) and (y not= z).;
In R, it is parsed as (x == y) != z.

While I have to admit that the spacing around == and != in print.R's
example does actually convey the actual association, in a vaguely
Principia Mathematica-ish way, I have to wonder:

Is R really seriously intended to swallow x == y != z without complaint?

If the line

%left       GT GE LT LE EQ NE

in src/main/gram.y were changed to

%nonassoc   GT GE LT LE EQ NE

then the line

    x0 <- xm[okP]==0 != (as.numeric(Cf[okP])==0)

in src/library/base/R/print.R would have to be changed to

    x0 <- (xm[okP]==0) != (as.numeric(Cf[okP])==0)

and all things considered, surely that would be an improvement?



From Roger.Bivand at nhh.no  Wed Sep  3 08:47:58 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 3 Sep 2003 08:47:58 +0200 (CEST)
Subject: [R] identify with image
In-Reply-To: <Pine.LNX.4.44.0309022313190.19967-100000@reclus.nhh.no>
Message-ID: <Pine.LNX.4.44.0309030835010.20931-100000@reclus.nhh.no>

On Tue, 2 Sep 2003, Roger Bivand wrote:

The simplest case is:

> plot(1:10)
> xy <- list()
> identify(xy, n=1)
Segmentation fault

but 

> identify(xy)
Error in identify.default(xy) : invalid number of points in identify

I'm not sure, but adding a check against zero-length and/or NULL x and or 
y about line 3010 in src/main/plot.c should catch this.

Roger

> On Tue, 2 Sep 2003, kjetil brinchmann halvorsen wrote:
> 
> > Hola!
> > 
> > I will want to identify pixels in an image with the mouse, for 
> > so getting the image data from the matrix(es), for use in subsequent 
> > discriminant analysis. But the following bombs R:
> > (windows XP, rw1071)
> > 
> > > str(baboon)
> >  list()
> >  - attr(*, "size")= int [1:2] 512 512
> >  - attr(*, "cellres")= num [1:2] 1 1
> >  - attr(*, "bbox")= num [1:4] 0 0 512 512
> >  - attr(*, "channels")= chr "grey"
> >  - attr(*, "bbcent")= logi FALSE
> >  - attr(*, "class")= chr "pixmapGrey"
> >  - attr(*, "grey")= num [1:512, 1:512] 0.537 0.510 0.345 0.259 0.322 
> > ...
> > > class(baboon)
> > [1] "pixmapGrey"
> > > library(pixmap)
> > > plot(baboon)
> > > identify(baboon, n=1)
> > 
> > ... and then R bombs!
> > 
> > What to do?
> > 
> 
> As Kenneth said, give identify() the expanded grid of points, but there is
> something wrong here:
> 
> > library(pixmap)
> > example(pixmap)
> ....
> pixmap> plot(z[1:20, 10:40])
> > identify(z, n=1)
> 
> Program received signal SIGSEGV, Segmentation fault.
> do_set (call=0x869ce7c, op=0x8299648, args=0x869ce98, rho=0x8f2496c)
>     at eval.c:1308
> 1308                switch (NAMED(s)) {
> 
> 
> The identify.default() function is passing the pixmap object through to
> xy.coords(), which returns two empty x and y vectors, which are checked
> for length in the R code - xy.coords() treats the pixmap object as a list, 
> does:
> 
> } else if (is.list(x)) {
>     xlab <- paste(ylab, "$x", sep = "")
>     ylab <- paste(ylab, "$y", sep = "")
>     y <- x[["y"]]
>     x <- x[["x"]]
> } else {
> 
> and y and x are the same length, so returns to identify.default() with 
> nothing, which is passed on to the .Internal() undetected. Two 
> possibilities - an identify.pixmap() in pixmap, or a test for the 
> (package, S4) pixmap class in xy.coords. But as it stands, it's a quick 
> way to exit the program. xy.coords() seems to be trusting the user to have 
> a list with x and y components, and here it has neither. The list is 
> indeed empty, being an S4 class - it just has attributes.
> 
> 
> > version
> _                
> platform i686-pc-linux-gnu
> arch     i686             
> os       linux-gnu        
> system   i686, linux-gnu  
> status                    
> major    1                
> minor    7.1              
> year     2003             
> month    06               
> day      16               
> language R        
> Package: pixmap
> Version: 0.3-2
> 
> 
> > Kjetil Halvorsen
> > 
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From andrejk at zrc-sazu.si  Wed Sep  3 18:01:13 2003
From: andrejk at zrc-sazu.si (Andrej Kveder)
Date: Wed, 3 Sep 2003 09:01:13 -0700
Subject: [R] glmmPQL probelm
Message-ID: <NCBBKFHOJJKAABNINHHCCEGDEMAA.andrejk@zrc-sazu.si>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030903/2e161762/attachment.pl

From ripley at stats.ox.ac.uk  Wed Sep  3 09:12:22 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 3 Sep 2003 08:12:22 +0100 (BST)
Subject: [R] glmmPQL probelm
In-Reply-To: <NCBBKFHOJJKAABNINHHCCEGDEMAA.andrejk@zrc-sazu.si>
Message-ID: <Pine.LNX.4.44.0309030810140.27476-100000@gannet.stats>

Nothing to do with glmmPQL (as traceback() would have shown you).

I think you are looking for ?try.

On Wed, 3 Sep 2003, Andrej Kveder wrote:

> Dear listers,
> 
> First let me appologize if the same mail arrives multiple times. Recently I
> had some probelms sending my e-mails to the list.
> 
> I encountered a problem when running glmmPQL procuedure doing multilevel
> modeling with a dichotomous outcome.
> Those are the two error messages I usually get:
> 
> Error in logLik.reStruct(object, conLin) :
>         NA/NaN/Inf in foreign function call (arg 3)
> 
> Error in solve.default(pdMatrix(a, fact = TRUE)) :
>         Lapack routine dgesv: system is exactly singular
> 
> The trick is that the model is a part of a simualtion run, which uses the
> same starting variance covariance matrix as a source for a mutlivariate
> normal simulated 2 level dataset. So the variations in the data set are just
> a part of the stochastic process. In the majority of the cases the model
> runs fine, while in some cases I get either of the two error messages. The
> model obviously cannot be identified. Does anybody have an idea why?
> The second question would relate to the handling of the problem. I don't
> even mind that much to have some models unidentified (of cours I would
> rather not have them). I would like to detect the possible problem
> beforehand in order to instruct the simulation run not to specifiy it. What
> is most annoying is that when an error occurs, the program stops the
> simulation run and not just skips the model results. Does anybody have an
> idea what to do about it? Any suggestions would be most helpfull. I can also
> send the R program file if that would help.
> 
> Thanks
> 
> Andrej
> 
> _________
> Andrej Kveder, M.A.
> researcher
> Institute of Medical Sciences SRS SASA; Novi trg 2, SI-1000 Ljubljana,
> Slovenia
> phone: +386 1 47 06 440   fax: +386 1 42 61 493
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Karen.Richardson at insightful.com  Wed Sep  3 11:24:51 2003
From: Karen.Richardson at insightful.com (Karen Richardson)
Date: Wed, 3 Sep 2003 10:24:51 +0100
Subject: [R] Course 'Bootstrap methods and permutation tests' - 23 - 24
	October 
Message-ID: <B796B8C05975394DA24E457D1985BDB417B9B1@uk2kexch01.insightful.com>


 
Insightful are pleased to announce we are now taking bookings for our latest course on "Bootstrap methods and permutation tests" in the UK on 23rd - 24th October. 

This course will focus in particular on two resampling methods, bootstrapping and permutation tests, which have been applied successfully to areas of statistical modelling where "traditional" standard errors, confidence intervals and significance tests are unavailable or of doubtful accuracy.  Interest in these methods has risen dramatically over the past 10 years. 

The tutor for the course is Dr. Tim Hesterberg, of Insightful's R & D division in Seattle.  Tim is primary author of the "S+Resample" package for bootstrapping, permutation tests, jackknife, and other resampling procedures, and is lead author of "Bootstrap Methods and Permutation Tests" (2003), W. H. Freeman, and numerous technical articles on resampling.  See www.insightful.com/Hesterberg/

This course will be suitable for any statistician faced with inferential problems where the use of standard results may be questionable or not available. 

Further information on the course is available at:  http://www.insightful.com/services/training/bootstrap_UK.asp

To register for the course:  http://www.insightful.com/services/register_european.asp

If you need any further information please do not hesitate to contact me.

Regards,

Karen Richardson
Sales and Marketing Administrator
Insightful
krichardson at insightful.com
Direct Line: +44 (0) 1256 339 822
Fax Number: +44 (0) 1256 339 839
....................................................................................
Seats are now available for the S-PLUS Essentials Course November 10 - 13 2003 - in the Basingstoke office.
http://www.insightful.com/services/training/essentialsII_4.asp



From Simon.Fear at synequanon.com  Wed Sep  3 11:51:46 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Wed, 3 Sep 2003 10:51:46 +0100
Subject: [R] I don't understand this
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572AC0DAB@synequanon01>

Thanks to everyone for enlightening me about (f)(g). So I
suppose (f)(g)(h)... is OK as long as (f)(g) returns a function with
an argument (and so on)?

Meanwhile, back on Earth, in attempting a compromise between 
the clarity of Barry R's

if (cond) names(x) <- 10 else dim(x) <- 10

and the generality of Peter D's

eval(substitute(foo(x)<-10,list(foo=as.name(if (cond) "names" else
"dim"))))

I tried to set it up as a clearer two-liner:

foo <- if (cond) names else dim
foo(x) <- 10

> foo <- if (TRUE) names else dim
> foo
function (x) 
UseMethod("names")
<environment: namespace:base>

So far so good. But

> foo(x) <- 10
Error: couldn't find function "foo<-"

Shedding further light on the semantic problem with the construct
"f(x)<-";
it
will only work if "f<-" is already explicitly defined, in addition to
"f"
being defined. (Or if "<-" has had its default overwritten.)
Making "foo" equivalent to "names" does not make "foo<-" equivalent
to "names<-". You need an on-the-fly explicit eval(substitute(...)) 
to do that.

The same should hold for "(f)(x)<-" except that (f) might find a
non-function value; I would expect (and hope) for a crash if so.

Sorry if this is obvious to many people on the list. It has been a very
enlightening discussion for me. At least, I thought I was learning
something, until at the next prompt I experimented with

> (foo)(x) <- 10
Error: couldn't find function "H-?<-"

Now where did THAT error message come from??

(I am running R version 0.1 on a PDP 8. Same result with 1.7.0
under Win98)
 

Simon Fear
Senior Statistician
Syne qua non Ltd
Tel: +44 (0) 1379 644449
Fax: +44 (0) 1379 644445
email: Simon.Fear at synequanon.com
web: http://www.synequanon.com
 
Number of attachments included with this message: 0
 
This message (and any associated files) is confidential and\...{{dropped}}



From B.Rowlingson at lancaster.ac.uk  Wed Sep  3 12:04:11 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 03 Sep 2003 11:04:11 +0100
Subject: [R] I don't understand this
In-Reply-To: <6C8A8033ABC1E3468048ABC4F13CE572AC0DAB@synequanon01>
References: <6C8A8033ABC1E3468048ABC4F13CE572AC0DAB@synequanon01>
Message-ID: <3F55BC9B.4000104@lancaster.ac.uk>

Simon Fear wrote:

>>foo(x) <- 10
> 
> Error: couldn't find function "foo<-"

  this is because you defined 'foo', and not 'foo<-', which are two 
different functions.

  if instead (or as well) you did:

"foo<-" <- if (TRUE) get("names<-") else get("dim<-")

then it works.

Doesn't cure this one though:

 > (foo)(x) <- 10
Error: couldn't find function "@<-"

Where's the gurus?

Baz



From p.dalgaard at biostat.ku.dk  Wed Sep  3 12:37:17 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed, 03 Sep 2003 10:37:17 -0000
Subject: [R] I don't understand this
In-Reply-To: <200309030214.h832EJ3l252275@atlas.otago.ac.nz>
References: <200309030214.h832EJ3l252275@atlas.otago.ac.nz>
Message-ID: <x2ptiidunk.fsf@biostat.ku.dk>

"Richard A. O'Keefe" <ok at cs.otago.ac.nz> writes:

> Thomas Lumley <tlumley at u.washington.edu> wrote:
> 	I would have said that the behavior of
> 	   (if (cond) names else dim)(x) <- 10
> 	is undefined in the S language, along with things like the order of
> 	evaluation of the apply functions.
> 	
> The thing is, it would make perfect sense for
>     (if (cond) f else g)(x) <- e
> to have the effect of
>     (if (cond) f(x) <- e else g(x) <- e)	    
> 
> In fact, I've used two programming languages where the analogue of
> this _did_ work, and a third where it didn't but using only published
> interfaces could very easily be made to work.

Yes, and it could be made to work in R too with a simple semantic
change: The fundamental problem is that replacement functions are
bound to symbols in R, not to the actual functions. That is the reason
why we have

> x <- c(a=1)
> x
a
1
> (names)(x)
[1] "a"
> (names)(x) <- 1
Error: couldn't find function "PT<-"

(that's with the bug unfixed). The thing is that (names) is an unnamed
function so there's no way to know that "names<-" is the replacment
function. If names<- had been an attribute of names, then there would
be no problem. Usual story: Code that needs to go via the textual
representation of something is often subtly wrong.

Of course noone really need to do this, do they? So the incentive to
change is rather small.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From baresel at wzw.tum.de  Wed Sep  3 12:45:56 2003
From: baresel at wzw.tum.de (=?iso-8859-1?Q?J=F6rg_Peter_Baresel?=)
Date: Wed, 3 Sep 2003 12:45:56 +0200
Subject: [R] iinstallation R-grid-package
Message-ID: <003901c37208$8e2378a0$1a7f288d@AGRARINF>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030903/cde5b2ad/attachment.pl

From ucgamdo at ucl.ac.uk  Wed Sep  3 13:19:12 2003
From: ucgamdo at ucl.ac.uk (ucgamdo@ucl.ac.uk)
Date: Wed, 03 Sep 2003 12:19:12 +0100
Subject: [R] Re: normal distribution in samples of soil organisms.
Message-ID: <3.0.5.32.20030903121912.007d7d90@pop-server.ucl.ac.uk>

Hi, 

   You didn't specify the satistical model you are intereted in, I will
suppose it is something like:
#Organims ~ Landscape + Soil + Depth + Species

I suppose you have a table of with something like...

Spec	Lands	Soil	Depth	#Organisms
A	1	1	1	10
A	1	2	1	2
B	1	1	1	0
B	2	2	2	2

... etc,

Normally, the count of organisms in soil samples follows a posisson
distribution, not a normal one. You should effectively check for normality
in your final data table, including the zeroes. In fact, you can do an
anova and then do some diagnostics plots, in R you would do something like
(suppose your table is stored in an object called my data):

mydata.lm <- lm(Organisms ~ Spec + Lands + Soil + Depth, data = mydata) #
fit a linear model

anova(mydata.lm) # to print a nicely formatted anova table

plot(mydata.lm)  # to do some diagnostics plots

If your data follows a poisson distribution, the qq plot obtained above
will be strikingly deviated from a straight line. This plots are normally
more useful than just obtaining p-values for normality tests. If your data
is indeed deviated from normality, you should then apply a suitable
transformation and repeat the analysis. I strongly adivice you to have a
look at the book Biometry, by Robert R. Sokal and F. James Rohlf (1996),
there are quite good examples in there and where and what transformations
should be applied, specially trasnforming data from a poisson-like
distribution to a normal one.

Hope this helps.



acovaleda at hotpop.com wrote:
> Hi Sirs and Madams.
> 
> My question is more statistical than related with the use of R software
and I 
> hope it will not seems so silly and elemental. I'm analyzing  a set of data 
> of some soil organism collected in diferent landscapes, soils taxa, and 
> depths. The sample was performed thinking in a factorial structure with
four 
> factors: Specie, Landscape, Soil and Depth. Because not all the species 
> appear in each sample there are so many zeros in the matrix data.
> 
> Checking the normal distribution I'm not sure If I must check it in the 
> original sample data (without zeros) or in the big matrix with zeros. In
the 
> first case there is a normal distribution (W = 0,85) but in the second
it is 
> not (W = 0,45). In which data must I check distribution?, Can I proceed to 
> perform a Parametric ANOVA?.
> 
> Thanks
>



From d.orme at imperial.ac.uk  Wed Sep  3 14:00:37 2003
From: d.orme at imperial.ac.uk (David Orme)
Date: Wed, 3 Sep 2003 13:00:37 +0100
Subject: [R] Matrix problem - possibly use of 'outer'
Message-ID: <3B46B48A-DE06-11D7-AE17-000393DC1748@ic.ac.uk>

Hi,

I can't get my head around this - can someone give me a pointer:

I have a vector of values ('orig') representing areas and I want to 
calculate the amount contributed by each original vector values in a 
new vector ('new'). I find this hard to explain so here is a graphical 
explanation:

# CODE START
orig <- 10:1 #10 values with varying area
new <- rep(sum(orig)/6,6) #6 values with equal areas

plot(56:0, 56:0, type="n", xlim=c(56,0)) # suitable plot frame
abline(v=cumsum(c(0,new)), col="grey75") #  the original values
axis(1, at=cumsum(0:10), line=-5) # the 'breaks' for the new vector
# CODE STOP

The grey lines show how area from the vector 'orig' should fall into 
the vector 'new'. I want to represent this relationship as a 
transformation matrix (transf.mat) of dimensions length(new) x 
length(orig) such that each element in the matrix represents the shared 
areas between the vectors. colSums(transf.mat) therefore is identical 
to orig and rowSums is identical to new.

I've worked transf.mat out by hand for the example above but I need to 
find a way of computing it given the two vectors orig and new - my 
hunch is that there is some elegant way using outer but I can't work it 
out.

# CODE START
transf.mat <- matrix(c(9.167, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.833, 8.333, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0.666, 8, 0.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
6.5, 2.667, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3.333, 5, 0.833, 0, 0, 0, 0, 0, 
0, 0, 0, 0, 3.167, 3, 2, 1), ncol=10, byrow=T)
all.equal(colSums(transf.mat), orig)
all.equal(rowSums(transf.mat), new)
# CODE STOP

Hope this makes some sense.

David

---------------------------------------
Dr. David Orme

Department of Biological Sciences
Imperial College London
Silwood Park Campus
Ascot, Berkshire SL5 7PY UK.

Tel: +44 (0)20 759 42358
Fax: +44 (0)20 759 42339
e-mail: d.orme at imperial.ac.uk



From MSchwartz at medanalytics.com  Mon Sep  1 18:16:50 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Mon, 01 Sep 2003 11:16:50 -0500
Subject: [R] Axis color
In-Reply-To: <36322.170.210.173.216.1062427350.squirrel@inter14.unsl.edu.ar>
References: <36322.170.210.173.216.1062427350.squirrel@inter14.unsl.edu.ar>
Message-ID: <1062433010.16051.47.camel@localhost>

On Mon, 2003-09-01 at 09:42, solares at unsl.edu.ar wrote:
> Hello, my question is if I have two axes in a graphics as I can put him a 
> different color al axis and to the number of the scale. ? Thanks. Ruben


I am not entirely sure if you want the actual axis lines and tick marks
in different colors or simply the axis labels at the tick mark locations
in different colors or perhaps both.

So I will combine both approaches in a single example:

# Generate a simple plot
# Do not draw the axes or axis labels
plot(1:10, axes = FALSE, ann = FALSE)

# Now draw x axis in red, but do not draw the tick mark
# labels.
axis(1, labels = FALSE, col = "red")

# Now draw the labels in "blue"
# Use axTicks() to get default tick locations
at = axTicks(1)
mtext(side = 1, text = at, at = at, col = "blue", line = 1)

# Now draw x axis label
mtext(side = 1, text = "X Axis Label", line = 3)

# Now do the same for the Y axis, this time
# use 1:10 for the axis tick marks and labels
# and reverse the colors
at = 1:10
axis(2, labels = FALSE, at = at, col = "blue")
mtext(side = 2, text = at, at = at, col = "red", line = 1)
mtext(side = 2, text = "Y Axis Label", line = 3)


For more information see ?plot, ?plot.default, ?axis, ?mtext and
?axTicks.

Hope that helps,

Marc Schwartz



From MSchwartz at medanalytics.com  Wed Sep  3 01:21:05 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 02 Sep 2003 18:21:05 -0500
Subject: [R] How to avoid automatic coercion to factor?
In-Reply-To: <6EEA47532CD0D611887500B0D04943453FBA42@tfsmdmsg7.tfn.com>
References: <6EEA47532CD0D611887500B0D04943453FBA42@tfsmdmsg7.tfn.com>
Message-ID: <1062544865.4558.20.camel@localhost>

On Tue, 2003-09-02 at 17:30, Dutky, Steve wrote:
> I have a function that manipulates a list of numeric and character
> components of equal length and wants to return a data.frame.
> 
> EG, 
> 
> f<-function() { 
> 	a<-list(Int1=1:5,Char1=letters[1:5],Char2=letters[6:10])
> 	b<-data.frame(a)
> }
> 
> How can I get the columns Char1, Char2, (...CharN) returned coerced to
> character and not factor?
> 
> It appears that I could coerce individual columns by
> b$CharI<-as.character(b$CharI). Is there a less ugly way of doing this?
> 
> Thanks, Steve Dutky


Steve,

Try this:

f<-function() { 
   a <- list(Int1 = 1:5, Char1 = letters[1:5], Char2 = letters[6:10])
   b <- data.frame(I(a))
}

and note the use of I(a) to inhibit the conversion of character vectors
to factors.

I presume that you are doing more in your function than what you have
above...

See ?data.frame and ?I (AsIs) for additional information.

HTH,

Marc Schwartz



From rajarshi at presidency.com  Wed Sep  3 14:35:19 2003
From: rajarshi at presidency.com (Rajarshi Guha)
Date: Wed, 03 Sep 2003 12:35:19 -0000
Subject: [R] plotting a distribution curves
Message-ID: <1062447931.3165.3.camel@ra.chem.psu.edu>

Hi,
  is there a way to plot distribution curves (say normal or chi sq etc)
from within R?

For example I looked up the *chisq family of functions but I'm not sure
as to how I would use them to generate a plot of the chi sq distribution
(for arbitrary d.o.f).

Thanks,
 
-------------------------------------------------------------------
Rajarshi Guha <rajarshi at presidency.com> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
Did you hear that two rabbits escaped from the zoo and so far they have
only recaptured 116 of them?



From baresel at wzw.tum.de  Wed Sep  3 14:50:09 2003
From: baresel at wzw.tum.de (=?iso-8859-1?Q?J=F6rg_Peter_Baresel?=)
Date: Wed, 3 Sep 2003 14:50:09 +0200
Subject: [R] SNK-test
Message-ID: <001201c37219$e8bc28a0$1a7f288d@AGRARINF>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030903/314f473e/attachment.pl

From petr.pikal at precheza.cz  Wed Sep  3 14:56:35 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Wed, 03 Sep 2003 14:56:35 +0200
Subject: [R] plotting a distribution curves
In-Reply-To: <1062447931.3165.3.camel@ra.chem.psu.edu>
Message-ID: <3F560123.30012.10552ED@localhost>

Hallo

On 1 Sep 2003 at 16:25, Rajarshi Guha wrote:

> Hi,
>   is there a way to plot distribution curves (say normal or chi sq
>   etc)
> from within R?
> 
> For example I looked up the *chisq family of functions but I'm not
> sure as to how I would use them to generate a plot of the chi sq
> distribution (for arbitrary d.o.f).

Something like that

plot(seq(-3,3,.1),dnorm(seq(-3,3,.1)),type="l")
plot(seq(0,20,.1),dchisq(seq(0,20,.1),5),type="l")


> 
> Thanks,
> 
> -------------------------------------------------------------------
> Rajarshi Guha <rajarshi at presidency.com> <http://jijo.cjb.net> GPG
> Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
> -------------------------------------------------------------------
> Did you hear that two rabbits escaped from the zoo and so far they
> have only recaptured 116 of them?
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

Cheers
Petr Pikal
petr.pikal at precheza.cz



From baresel at wzw.tum.de  Wed Sep  3 15:12:17 2003
From: baresel at wzw.tum.de (=?iso-8859-1?Q?J=F6rg_Peter_Baresel?=)
Date: Wed, 3 Sep 2003 15:12:17 +0200
Subject: [R] variance components
Message-ID: <002401c3721c$ffebcc80$1a7f288d@AGRARINF>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030903/9b448f81/attachment.pl

From th50 at leicester.ac.uk  Wed Sep  3 15:11:00 2003
From: th50 at leicester.ac.uk (Hotz, T.)
Date: Wed, 3 Sep 2003 14:11:00 +0100
Subject: [R] plotting a distribution curves
Message-ID: <1F2CE8D4B0195E488213E8B8CCF714860250134A@saffron.cfs.le.ac.uk>


> -----Original Message-----
> From: Petr Pikal [mailto:petr.pikal at precheza.cz]
> Sent: 03 September 2003 13:57
> To: rajarshi at presidency.com
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] plotting a distribution curves
> 
> 
> Hallo
> 
> On 1 Sep 2003 at 16:25, Rajarshi Guha wrote:
> 
> > Hi,
> >   is there a way to plot distribution curves (say normal or chi sq
> >   etc)
> > from within R?
> > 
> > For example I looked up the *chisq family of functions but I'm not
> > sure as to how I would use them to generate a plot of the chi sq
> > distribution (for arbitrary d.o.f).
> 
> Something like that
> 
> plot(seq(-3,3,.1),dnorm(seq(-3,3,.1)),type="l")
> plot(seq(0,20,.1),dchisq(seq(0,20,.1),5),type="l")

Or using curve (see ?curve)

curve(dnorm(x,1,2),-4,6)
curve(dchisq(x,5),0,20)

HTH

Thomas

> 
> 
> > 
> > Thanks,
> > 
> > -------------------------------------------------------------------
> > Rajarshi Guha <rajarshi at presidency.com> <http://jijo.cjb.net> GPG
> > Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
> > -------------------------------------------------------------------
> > Did you hear that two rabbits escaped from the zoo and so far they
> > have only recaptured 116 of them?
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> Cheers
> Petr Pikal
> petr.pikal at precheza.cz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 



---

Thomas Hotz
Research Associate in Medical Statistics
University of Leicester
United Kingdom

Department of Epidemiology and Public Health
22-28 Princess Road West
Leicester
LE1 6TP
Tel +44 116 252-5410
Fax +44 116 252-5423

Division of Medicine for the Elderly
Department of Medicine
The Glenfield Hospital
Leicester
LE3 9QP
Tel +44 116 256-3643
Fax +44 116 232-2976



From bates at stat.wisc.edu  Wed Sep  3 15:38:30 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 03 Sep 2003 13:38:30 -0000
Subject: [R] plotting a distribution curves
In-Reply-To: <3F560123.30012.10552ED@localhost>
References: <3F560123.30012.10552ED@localhost>
Message-ID: <6r3cfeoutv.fsf@bates4.stat.wisc.edu>

"Petr Pikal" <petr.pikal at precheza.cz> writes:

> Hallo
> 
> On 1 Sep 2003 at 16:25, Rajarshi Guha wrote:
> 
> > Hi,
> >   is there a way to plot distribution curves (say normal or chi sq
> >   etc)
> > from within R?
> > 
> > For example I looked up the *chisq family of functions but I'm not
> > sure as to how I would use them to generate a plot of the chi sq
> > distribution (for arbitrary d.o.f).
> 
> Something like that
> 
> plot(seq(-3,3,.1),dnorm(seq(-3,3,.1)),type="l")
> plot(seq(0,20,.1),dchisq(seq(0,20,.1),5),type="l")

Perhaps it is easier to use 'curve'

curve(dnorm, from = -3, to = 3)
curve(dchisq(x,df=5), from = 0, to = 20)



From paulda at BATTELLE.ORG  Wed Sep  3 15:46:07 2003
From: paulda at BATTELLE.ORG (Paul, David  A)
Date: Wed, 03 Sep 2003 09:46:07 -0400
Subject: [R] variance components
Message-ID: <940250A9EB37A24CBE28D858EF07774967AAC1@ws-bco-mse3.milky-way.battelle.org>

Use the nlme( ) package:

>library(nlme)

The lme( ) and nlme( ) functions in this package are
designed to estimate mixed effects models.  An
outstanding reference is "Mixed Effects Models in S
and Splus", by Drs. Pinheiro and Bates.


Best,

  david paul

-----Original Message-----
From: J?rg Peter Baresel [mailto:baresel at wzw.tum.de] 
Sent: Wednesday, September 03, 2003 9:12 AM
To: r-help
Subject: [R] variance components


Which possibilities are there in "R" for estimation of Variance components?


J?rg Peter Baresel
Technische Universit?t M?nchen
Lehrstuhl f?r Pflanzenbau und Pflanzenz?chtung
D-85354 Freising
Lange Point 51


	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From tlumley at u.washington.edu  Wed Sep  3 15:56:26 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 3 Sep 2003 06:56:26 -0700 (PDT)
Subject: [R] I don't understand this
In-Reply-To: <6C8A8033ABC1E3468048ABC4F13CE572AC0DAB@synequanon01>
Message-ID: <Pine.A41.4.44.0309030651480.270078-100000@homer01.u.washington.edu>

On Wed, 3 Sep 2003, Simon Fear wrote:

> Thanks to everyone for enlightening me about (f)(g). So I
> suppose (f)(g)(h)... is OK as long as (f)(g) returns a function with
> an argument (and so on)?

Indeed.  As an example of what can be done

recurse <- function(f) {
              g<- function(h)
                  function(x)  f(h(h))(x)
	      g(g)
	}

is not only syntactically valid, but arguably useful (it gives a way of
writing anonymous recursive functions), so that
  recurse( function(self) function(n) if (n<2) 1 else n*self(n-1))
is an anonymous factorial function.

	-thomas



From lsilva at fc.up.pt  Wed Sep  3 15:57:10 2003
From: lsilva at fc.up.pt (Luis Miguel Almeida da Silva)
Date: Wed, 3 Sep 2003 14:57:10 +0100
Subject: [R] problem with HoltWinters
Message-ID: <D52F84A2AE107848949A8C7E45F02D699DEAD1@MAIL.fc.up.pt>

Dear helpers
 
I'm having a problem with function HoltWinters from package ts. I have a time series that I want to fit an Holt-Winters model and make predictions for the next values. I've already built an object of class ts to serve as input to HoltWinters. But then I get an error; I've used HoltWinters a lot of times and this never hapened
 
> data.HW<-HoltWinters(data.ts)
Error in model.frame(formula, rownames, variables, varnames, extras, extranames,  : 
        variable lengths differ
 
This is the data

> data.ts
         Jan     Feb     Mar     Apr     May     Jun     Jul     Aug     Sep
2001 1117001 1017287 1195142 1049729 1409147 1267002 1579907 1563127 1195597
2002 1228333 1062520 1080117 1171998 1383951 1141008 1604061 1446024 1276017
2003 1068221 1045052 1164273 1091765 1272330 1305676                        
         Oct     Nov     Dec
2001 1290688 1104137 1027022
2002 1262232 1048522 1174157
2003                        
 
Do you know what is happening?
 
Thank you
Luis



From tlumley at u.washington.edu  Wed Sep  3 16:10:44 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 3 Sep 2003 07:10:44 -0700 (PDT)
Subject: [R] Another R syntax question
In-Reply-To: <200309030608.h8368Sgl319178@atlas.otago.ac.nz>
Message-ID: <Pine.A41.4.44.0309030700570.270078-100000@homer01.u.washington.edu>

On Wed, 3 Sep 2003, Richard A. O'Keefe wrote:

> The file src/library/base/R/print.R
> contains this line:
>
>     x0 <- xm[okP]==0 != (as.numeric(Cf[okP])==0)
>
> I didn't know R allowed that, and I wonder if it is deliberate?

Well, I'm not surprised that it's syntactically valid, but I wouldn't know
off-hand which way it evaluated.

> In mathematics, you would expect x = y not= z to mean
> (x = y) and (y not= z).;
> In R, it is parsed as (x == y) != z.

I think it's clear that it will parse as either
(x==y) != z
or
x == (y!=z)
but not which.

> While I have to admit that the spacing around == and != in print.R's
> example does actually convey the actual association, in a vaguely
> Principia Mathematica-ish way, I have to wonder:
>
> Is R really seriously intended to swallow x == y != z without complaint?
>
> If the line
>
> %left       GT GE LT LE EQ NE
>
> in src/main/gram.y were changed to
>
> %nonassoc   GT GE LT LE EQ NE
>
> then the line
>
>     x0 <- xm[okP]==0 != (as.numeric(Cf[okP])==0)
>
> in src/library/base/R/print.R would have to be changed to
>
>     x0 <- (xm[okP]==0) != (as.numeric(Cf[okP])==0)
>
> and all things considered, surely that would be an improvement?


This is presumably S compatible (<checks: yes it is>) and so while
changing print.R would be an improvement, changing the grammar probably
wouldn't.

	-thomas



From Bodo.Ahrens at univie.ac.at  Wed Sep  3 16:09:23 2003
From: Bodo.Ahrens at univie.ac.at (Bodo Ahrens)
Date: Wed, 3 Sep 2003 16:09:23 +0200
Subject: [R] llines and NA
Message-ID: <200309031609.23490.Bodo.Ahrens@univie.ac.at>


Hallo helpers,

I tried to use "llines" of package lattice in e.g.

levelplot(z~x+y,xyz, at=c.at,region=T,col.regions=col.v,main =
paste("Test",sep=""),aspect = mapasp(xyz,x=xyz$x,y=xyz$y),
panel=function(x,y,subscripts,...){
panel.levelplot(x,y,subscripts,...);
lines(linex,liney)})

The problem is that there are NAs in linex and liney and thus I get strange
line segments to infinity.

The base function "lines" is able to handle this. Any ideas how to get a
similar behavior with "llines"?

Thanks,

Bodo





-- 
Bodo Ahrens
Institut fuer Meteorologie und Geophysik, Universitaet Wien
Althanstrasse 14, A-1090 Wien, Austria
Tel: +43-1-4277-51917, Fax: +43-1-4277-9519
E-mail: Bodo.Ahrens at univie.ac.at



From tlumley at u.washington.edu  Wed Sep  3 16:21:59 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 3 Sep 2003 07:21:59 -0700 (PDT)
Subject: [R] I don't understand this
In-Reply-To: <200309030214.h832EJ3l252275@atlas.otago.ac.nz>
Message-ID: <Pine.A41.4.44.0309030711000.270078-100000@homer01.u.washington.edu>

On Wed, 3 Sep 2003, Richard A. O'Keefe wrote:

> Another assignment-related thing I'm not clear on is what
>     f(x) <<- e
> is supposed to do.

Me neither.

>     f(x) <- e
> is equivalent to
>     x <- "f<-"(x, value=e)
> and
>     x <<- e
> assigns to x in the next outer environment,
> but a simple macro-expansion of
>     f(x) <<- e
> to
>     x <<- "f<-"(x, value=e)
> may have the nasty effect of writing to an outer x a value derived from
> an inner one.
>
> Now, that seems to be exactly what happens in R:
>
> > x <- c(1,2,3)
> > f <- function(x) x[2] <<- x
> > f(77)
> > x
> [1] 77 77
>
> While the documentation and source code _could_ tell me whether this
> is intentional, as far as I can tell (and I have, needless to say,
> looked) they _don't_.

I'm fairly confident that this is a case where there was no intention one
way or the other.

> Now, despite its misleading opening screen (which says that the
> target of an assignment is "a variable name (possibly quoted)",
> ?"<<-" goes on to say that
>         vvv
>      In all the assignment operator expressions, `x' can be a name or
>         ^^^
>      an expression defining a part of an object to be replaced (e.g.,
>      `z[[1]]').  The name does not need to be quoted, though it can be.
> (the arrows are my emphasis.)  So it's explict that f(x) <<- e is
> *supposed* to be allowed and I don't need to ask about that.

Well, it's possible that the documentation is wrong.

> The question is, what is f(x) <<- e supposed to do when there is an
> x in the current environment as well as one in an outer environment?
> It doesn't make much sense to fetch from one variable and store into
> the other, but that's what R actually does.  Is that really what's
> *supposed* to happen?

I don't think so.  <<- works as intended for subscripting of relatively
simple objects, but has the result you describe even for [.data.frame.

I think it's a bug.

	-thomas



From p.dalgaard at biostat.ku.dk  Wed Sep  3 16:31:33 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed, 03 Sep 2003 14:31:33 -0000
Subject: [R] Another R syntax question
In-Reply-To: <Pine.A41.4.44.0309030700570.270078-100000@homer01.u.washington.edu>
References: <Pine.A41.4.44.0309030700570.270078-100000@homer01.u.washington.edu>
Message-ID: <x2he3udjsb.fsf@biostat.ku.dk>

Thomas Lumley <tlumley at u.washington.edu> writes:

> I think it's clear that it will parse as either
> (x==y) != z
> or
> x == (y!=z)
> but not which.

The rule is that everything is left associative except assignment and
exponentiation (and IF, for some reason). If in doubt, just remember
that it is the opposite of assignment and that (x <- y) <- z doesn't
make sense... Of course, using parentheses is more expedient.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From fabio.rocha at click21.com.br  Wed Sep  3 16:42:44 2003
From: fabio.rocha at click21.com.br (fabio.rocha)
Date: Wed, 03 Sep 2003 14:42:44 -0000
Subject: [R] Call R function from C code
Message-ID: <20030903144317.1185.qmail@qmail-local.click21.com.br>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030903/5036f2de/attachment.pl

From s195404 at student.uq.edu.au  Wed Sep  3 16:56:49 2003
From: s195404 at student.uq.edu.au (Andrew C. Ward)
Date: Wed,  3 Sep 2003 14:56:49 +0000
Subject: [R] Call R function from C code
In-Reply-To: <20030903144317.1185.qmail@qmail-local.click21.com.br>
References: <20030903144317.1185.qmail@qmail-local.click21.com.br>
Message-ID: <1062601009.3f5601313110c@my.uq.edu.au>

Dear Fabio,

This question, or one very much like it, appears regularly
on the list. You may consider searching for it in the
archives before going much further. The search page can be
found at http://cran.r-project.org/search.html.

Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au


Quoting "fabio.rocha" <fabio.rocha at click21.com.br>:

> I am participating in a project in the university, and
> appeared a doubt: if can I call one function from R as
> "solve" from C code.
> The intention of the research is to create a DLL.
> Is it possible and where can I find an example?
> 
> Sorry for bad english!
> 
> 
> 
> 
____________________________________________________________
_______________________
> Acesse nosso portal www.click21.com.br
> 
> Porque internet gr?tis, nem a Embratel pode fazer mais
> barato. Mas pode fazer melhor.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From Jan.Verbesselt at agr.kuleuven.ac.be  Wed Sep  3 16:58:15 2003
From: Jan.Verbesselt at agr.kuleuven.ac.be (Jan Verbesselt)
Date: Wed, 3 Sep 2003 16:58:15 +0200
Subject: [R] Diagnostic tool for s.window in the STL method for Time series
	Analysis
Message-ID: <000001c3722b$cd9cee80$1145210a@agr.ad10.intern.kuleuven.ac.be>


Dear R-Help,

1. Does somebody know a diagnostic tool to determine the n(s), smoothing
parameter of the seasonal component in the STL method for Time Series?
 
s.window= n(s)= smoothing parameter
Is tsdiag the solution? If yes how can it be used? Should I use arima or
StructTS?

2. Also does the STL method take n(p), the number of observations in
each cycle of the seasonal component, automatically from the FREQUENCY
of the ts (Timeseries) object?

Thanks a lot,
Jan


________________________________________________________________________
__
Jan Verbesselt 
Research Associate 
Lab of Geomatics and Forest Engineering K.U. Leuven
Vital Decosterstraat 102. B-3000 Leuven Belgium 
Tel:+32-16-329750 
Fax: +32-16-329760
http://perswww.kuleuven.ac.be/~u0027178/VCard/mycard.php?name=janv
http://gloveg.kuleuven.ac.be/
________________________________________________________________________
__



From rbonk at host.sk  Wed Sep  3 23:31:41 2003
From: rbonk at host.sk (Rado Bonk)
Date: Wed, 03 Sep 2003 17:31:41 -0400
Subject: [R] value of hypsometric integral ( ecdf() )
Message-ID: <1062624701.14613.34.camel@templar.fns.uniba.sk>

Hi R-users,

How can I compute the area below the curve (so called "hypsometric
integral") plotted by:

plot(ecdf(volcano), do.points=F, verticals=T)

Thanks,

Rado


-- 
Radoslav Bonk M.S.
Dept. of Physical Geography and Geoecology
Faculty of Sciences, Comenius University
Mlynska Dolina 842 15, Bratislava, SLOVAKIA
tel: +421 905 968 127 e-mail: rbonk at host.sk



From solares at unsl.edu.ar  Wed Sep  3 17:39:26 2003
From: solares at unsl.edu.ar (solares@unsl.edu.ar)
Date: Wed, 3 Sep 2003 12:39:26 -0300 (ART)
Subject: [R] replot
Message-ID: <35714.170.210.173.216.1062603566.squirrel@inter14.unsl.edu.ar>

Hi, how i cant replot a graphics, te function replot() not exist in R for
win 1.7.1, how i cant without plot.new?



From spencer.graves at pdf.com  Wed Sep  3 17:58:35 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 03 Sep 2003 08:58:35 -0700
Subject: [R] SNK-test
References: <001201c37219$e8bc28a0$1a7f288d@AGRARINF>
Message-ID: <3F560FAB.80307@pdf.com>

Have you tried www.r-project.org -> search -> "R site search"?  I just 
got several hits for "multiple comparisons" and "Newman-Keuls".

hope this helps.  spencer graves

J?rg Peter Baresel wrote:
>  How can I perform a Student-Newman-Keuls-Test for multiple comparision of means in R?
> (I did not manage to find any specific function in the libraries)
> 
> 
> J?rg Peter Baresel
> Technische Universit?t M?nchen
> Institut f?r Ackerbau und INformatik im Pflanzenbau
> D-85354 Freising
> Lange Point 51
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From paul at datavore.com  Wed Sep  3 18:18:42 2003
From: paul at datavore.com (Paul Meagher)
Date: Wed, 3 Sep 2003 13:18:42 -0300
Subject: [R] Overlaying graphs
References: <Pine.A41.4.44.0309030711000.270078-100000@homer01.u.washington.edu>
Message-ID: <010a01c37237$0b4bf180$9141de18@computer>

I am wanting to construct a probability distribution for height and then,
hopefully, visually and analytically demonstrate that it is normally
distributed.

These are the commands I have developed so far:

fat   <- read.table("fat.dat", header=TRUE)
mu    <- mean(fat$height)
sdev  <- sd(fat$height)
hist(fat$height, br=20, freq=FALSE, xlab="Male Height in Inches")
curve(dnorm(x, mu, sdev), from=64, to=78)

I do not know how to overlay the curve graphic on top of hist graphic.

I am hoping to show visually that the normal curve overlays the obtained
probability distribution when plotted on the same graph.  Unfortunately, I
an not sure how to overlay them. Can anyone point me in the right direction
or show me the code.

The data set is here:

http://www.datavore.com/fat.dat

Regards,
Paul Meagher



From david.meyer at ci.tuwien.ac.at  Wed Sep  3 18:21:10 2003
From: david.meyer at ci.tuwien.ac.at (David Meyer)
Date: Wed, 3 Sep 2003 18:21:10 +0200
Subject: [R] problem with HoltWinters
In-Reply-To: <D52F84A2AE107848949A8C7E45F02D699DEAD1@MAIL.fc.up.pt>;
	from lsilva@fc.up.pt on Wed, Sep 03, 2003 at 15:57:10 +0200
References: <D52F84A2AE107848949A8C7E45F02D699DEAD1@MAIL.fc.up.pt>
Message-ID: <20030903162110.GG20461@boromir.ci.tuwien.ac.at>

How did you construct `data.ts'? Can you send me the file?

best,
David

On 2003.09.03 15:57, Luis Miguel Almeida da Silva wrote:
> Dear helpers
> 
> I'm having a problem with function HoltWinters from package ts. I have
> a time series that I want to fit an Holt-Winters model and make
> predictions for the next values. I've already built an object of class
> ts to serve as input to HoltWinters. But then I get an error; I've
> used HoltWinters a lot of times and this never hapened
> 
> > data.HW<-HoltWinters(data.ts)
> Error in model.frame(formula, rownames, variables, varnames, extras,
> extranames,  :
>         variable lengths differ
> 
> This is the data
> 
> > data.ts
>          Jan     Feb     Mar     Apr     May     Jun     Jul     Aug
>   Sep
> 2001 1117001 1017287 1195142 1049729 1409147 1267002 1579907 1563127
> 1195597
> 2002 1228333 1062520 1080117 1171998 1383951 1141008 1604061 1446024
> 1276017
> 2003 1068221 1045052 1164273 1091765 1272330 1305676
> 
>          Oct     Nov     Dec
> 2001 1290688 1104137 1027022
> 2002 1262232 1048522 1174157
> 2003
> 
> Do you know what is happening?
> 
> Thank you
> Luis
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
>



From p.dalgaard at biostat.ku.dk  Wed Sep  3 18:23:29 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed, 03 Sep 2003 16:23:29 -0000
Subject: [R] Overlaying graphs
In-Reply-To: <010a01c37237$0b4bf180$9141de18@computer>
References: <Pine.A41.4.44.0309030711000.270078-100000@homer01.u.washington.edu>
	<010a01c37237$0b4bf180$9141de18@computer>
Message-ID: <x2k78pdemo.fsf@biostat.ku.dk>

"Paul Meagher" <paul at datavore.com> writes:

> I am wanting to construct a probability distribution for height and then,
> hopefully, visually and analytically demonstrate that it is normally
> distributed.
> 
> These are the commands I have developed so far:
> 
> fat   <- read.table("fat.dat", header=TRUE)
> mu    <- mean(fat$height)
> sdev  <- sd(fat$height)
> hist(fat$height, br=20, freq=FALSE, xlab="Male Height in Inches")
> curve(dnorm(x, mu, sdev), from=64, to=78)
> 
> I do not know how to overlay the curve graphic on top of hist graphic.
> 
> I am hoping to show visually that the normal curve overlays the obtained
> probability distribution when plotted on the same graph.  Unfortunately, I
> an not sure how to overlay them. Can anyone point me in the right direction
> or show me the code.

Using the "add" argument to curve gets you most of the way, but
getting the y axis right is a little tricky. You could take a look at
the scripts in the ISwR package (sec.1.3), or the book itself...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From brahm at alum.mit.edu  Wed Sep  3 18:31:07 2003
From: brahm at alum.mit.edu (David Brahm)
Date: Wed, 3 Sep 2003 12:31:07 -0400
Subject: [R] How to avoid automatic coercion to factor?
References: <Pine.LNX.4.44.0309030544350.26990-100000@gannet.stats>
Message-ID: <16214.5963.79252.407104@arbres1a.fmr.com>

Steve Dutky <steve.dutky at thomson.com> wrote:
> I have a function that manipulates a list of numeric and character
> components of equal length and wants to return a data.frame.
> ...
> How can I get the columns Char1, Char2, (...CharN) returned coerced to
> character and not factor?

Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> ... We should ask why you want character columns in a data frame?...

I think Steve's situation is very common.  It points up a long-standing gap in
the S language, namely a class of objects for tabular data that is less
restrictive than data.frame or matrix.  Data frames are really designed for
statistics (thus their inclination towards factors and valid column names),
while matrices can only handle a single mode of data (numeric or character).

In my own world, I've "implemented" this "class" as lists of equal-length
vectors, and built many tools for it that mirror read.table, write.table,
merge, cbind, rbind, etc.  Except that I've done it sloppily, without using
real classes or constructors/validators/methods.

It would be nice to have a real class "table" (maybe data.frame would extend
it?).  But no, I'm not volunteering to build it. :-/
-- 
                              -- David Brahm (brahm at alum.mit.edu)



From lsilva at fc.up.pt  Wed Sep  3 18:32:19 2003
From: lsilva at fc.up.pt (Luis Miguel Almeida da Silva)
Date: Wed, 3 Sep 2003 17:32:19 +0100
Subject: [R] problem with HoltWinters
Message-ID: <D52F84A2AE107848949A8C7E45F02D699DEAD4@MAIL.fc.up.pt>

The data goes in attachment. I used ts to create data.ts
 
data.ts<-ts(data=data,start=c(2001,1),frequency=12)


	-----Original Message----- 
	From: David Meyer [mailto:david.meyer at ci.tuwien.ac.at] 
	Sent: Wed 03/09/2003 17:21 
	To: Luis Miguel Almeida da Silva 
	Cc: r-help at stat.math.ethz.ch 
	Subject: Re: [R] problem with HoltWinters
	
	

	How did you construct `data.ts'? Can you send me the file?
	
	best,
	David
	
	On 2003.09.03 15:57, Luis Miguel Almeida da Silva wrote:
	> Dear helpers
	>
	> I'm having a problem with function HoltWinters from package ts. I have
	> a time series that I want to fit an Holt-Winters model and make
	> predictions for the next values. I've already built an object of class
	> ts to serve as input to HoltWinters. But then I get an error; I've
	> used HoltWinters a lot of times and this never hapened
	>
	> > data.HW<-HoltWinters(data.ts)
	> Error in model.frame(formula, rownames, variables, varnames, extras,
	> extranames,  :
	>         variable lengths differ
	>
	> This is the data
	>
	> > data.ts
	>          Jan     Feb     Mar     Apr     May     Jun     Jul     Aug
	>   Sep
	> 2001 1117001 1017287 1195142 1049729 1409147 1267002 1579907 1563127
	> 1195597
	> 2002 1228333 1062520 1080117 1171998 1383951 1141008 1604061 1446024
	> 1276017
	> 2003 1068221 1045052 1164273 1091765 1272330 1305676
	>
	>          Oct     Nov     Dec
	> 2001 1290688 1104137 1027022
	> 2002 1262232 1048522 1174157
	> 2003
	>
	> Do you know what is happening?
	>
	> Thank you
	> Luis
	>
	> ______________________________________________
	> R-help at stat.math.ethz.ch mailing list
	> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
	>
	>
	

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: data.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030903/9dfa9419/data.txt

From MSchwartz at medanalytics.com  Wed Sep  3 18:33:57 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 03 Sep 2003 11:33:57 -0500
Subject: [R] replot
In-Reply-To: <35714.170.210.173.216.1062603566.squirrel@inter14.unsl.edu.ar>
References: <35714.170.210.173.216.1062603566.squirrel@inter14.unsl.edu.ar>
Message-ID: <1062606837.4558.80.camel@localhost>

On Wed, 2003-09-03 at 10:39, solares at unsl.edu.ar wrote:
> Hi, how i cant replot a graphics, te function replot() not exist in R
> for
> win 1.7.1, how i cant without plot.new?


In general, you need to simply re-execute the function or series of
functions (with any changes) to re-display a plot. There is no "refresh"
function per se. 

If you might be looking to add a plot to an existing plot, use:

par(new = TRUE)

prior to generating the second plot. This will enable you to overlay a
new plot on an existing one, without first clearing the old plot.

If you have a complicated series of calls to generate the plot, it is
best to save the R code in a separate file. Then you can edit it and
either copy and paste the code into the R console or use source() to
read the code into R.


HTH,

Marc Schwartz



From david.meyer at ci.tuwien.ac.at  Wed Sep  3 18:54:20 2003
From: david.meyer at ci.tuwien.ac.at (David Meyer)
Date: Wed, 3 Sep 2003 18:54:20 +0200
Subject: [R] problem with HoltWinters
In-Reply-To: <D52F84A2AE107848949A8C7E45F02D699DEAD4@MAIL.fc.up.pt>;
	from lsilva@fc.up.pt on Wed, Sep 03, 2003 at 18:32:19 +0200
References: <D52F84A2AE107848949A8C7E45F02D699DEAD4@MAIL.fc.up.pt>
Message-ID: <20030903165420.GK20461@boromir.ci.tuwien.ac.at>

HoltWinters() by default fits a seasonal model, and therefore needs 
three complete cycles for the starting values. But your third cycle is 
incomplete, so in short, you haven't got enough data to fit a seasonal 
model, unless you provide all starting values using l.start, b.start, 
and s.start. I will change the code to give a better error message in 
such cases.

Best,
David.

On 2003.09.03 18:32, Luis Miguel Almeida da Silva wrote:
> The data goes in attachment. I used ts to create data.ts
> 
> data.ts<-ts(data=data,start=c(2001,1),frequency=12)
> 
> 
> 	-----Original Message-----
> 	From: David Meyer [mailto:david.meyer at ci.tuwien.ac.at]
> 	Sent: Wed 03/09/2003 17:21
> 	To: Luis Miguel Almeida da Silva
> 	Cc: r-help at stat.math.ethz.ch
> 	Subject: Re: [R] problem with HoltWinters
> 	 
> 	 
> 
> 	How did you construct `data.ts'? Can you send me the file?
> 	 
> 	best,
> 	David
> 	 
> 	On 2003.09.03 15:57, Luis Miguel Almeida da Silva wrote:
> 	> Dear helpers
> 	>
> 	> I'm having a problem with function HoltWinters from package
> ts. I have
> 	> a time series that I want to fit an Holt-Winters model and
> make
> 	> predictions for the next values. I've already built an
> object of class
> 	> ts to serve as input to HoltWinters. But then I get an
> error; I've
> 	> used HoltWinters a lot of times and this never hapened
> 	>
> 	> > data.HW<-HoltWinters(data.ts)
> 	> Error in model.frame(formula, rownames, variables, varnames,
> extras,
> 	> extranames,  :
> 	>         variable lengths differ
> 	>
> 	> This is the data
> 	>
> 	> > data.ts
> 	>          Jan     Feb     Mar     Apr     May     Jun     Jul
>     Aug
> 	>   Sep
> 	> 2001 1117001 1017287 1195142 1049729 1409147 1267002 1579907
> 1563127
> 	> 1195597
> 	> 2002 1228333 1062520 1080117 1171998 1383951 1141008 1604061
> 1446024
> 	> 1276017
> 	> 2003 1068221 1045052 1164273 1091765 1272330 1305676
> 	>
> 	>          Oct     Nov     Dec
> 	> 2001 1290688 1104137 1027022
> 	> 2002 1262232 1048522 1174157
> 	> 2003
> 	>
> 	> Do you know what is happening?
> 	>
> 	> Thank you
> 	> Luis
> 	>
> 	> ______________________________________________
> 	> R-help at stat.math.ethz.ch mailing list
> 	> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 	>
> 	>
> 	 
> 
> 
> 1117001
> 1017287
> 1195142
> 1049729
> 1409147
> 1267002
> 1579907
> 1563127
> 1195597
> 1290688
> 1104137
> 1027022
> 1228333
> 1062520
> 1080117
> 1171998
> 1383951
> 1141008
> 1604061
> 1446024
> 1276017
> 1262232
> 1048522
> 1174157
> 1068221
> 1045052
> 1164273
> 1091765
> 1272330
> 1305676
>



From david.meyer at ci.tuwien.ac.at  Wed Sep  3 18:54:20 2003
From: david.meyer at ci.tuwien.ac.at (David Meyer)
Date: Wed, 3 Sep 2003 18:54:20 +0200
Subject: [R] problem with HoltWinters
In-Reply-To: <D52F84A2AE107848949A8C7E45F02D699DEAD4@MAIL.fc.up.pt>;
	from lsilva@fc.up.pt on Wed, Sep 03, 2003 at 18:32:19 +0200
References: <D52F84A2AE107848949A8C7E45F02D699DEAD4@MAIL.fc.up.pt>
Message-ID: <20030903165420.GK20461@boromir.ci.tuwien.ac.at>

HoltWinters() by default fits a seasonal model, and therefore needs 
three complete cycles for the starting values. But your third cycle is 
incomplete, so in short, you haven't got enough data to fit a seasonal 
model, unless you provide all starting values using l.start, b.start, 
and s.start. I will change the code to give a better error message in 
such cases.

Best,
David.

On 2003.09.03 18:32, Luis Miguel Almeida da Silva wrote:
> The data goes in attachment. I used ts to create data.ts
> 
> data.ts<-ts(data=data,start=c(2001,1),frequency=12)
> 
> 
> 	-----Original Message-----
> 	From: David Meyer [mailto:david.meyer at ci.tuwien.ac.at]
> 	Sent: Wed 03/09/2003 17:21
> 	To: Luis Miguel Almeida da Silva
> 	Cc: r-help at stat.math.ethz.ch
> 	Subject: Re: [R] problem with HoltWinters
> 	 
> 	 
> 
> 	How did you construct `data.ts'? Can you send me the file?
> 	 
> 	best,
> 	David
> 	 
> 	On 2003.09.03 15:57, Luis Miguel Almeida da Silva wrote:
> 	> Dear helpers
> 	>
> 	> I'm having a problem with function HoltWinters from package
> ts. I have
> 	> a time series that I want to fit an Holt-Winters model and
> make
> 	> predictions for the next values. I've already built an
> object of class
> 	> ts to serve as input to HoltWinters. But then I get an
> error; I've
> 	> used HoltWinters a lot of times and this never hapened
> 	>
> 	> > data.HW<-HoltWinters(data.ts)
> 	> Error in model.frame(formula, rownames, variables, varnames,
> extras,
> 	> extranames,  :
> 	>         variable lengths differ
> 	>
> 	> This is the data
> 	>
> 	> > data.ts
> 	>          Jan     Feb     Mar     Apr     May     Jun     Jul
>     Aug
> 	>   Sep
> 	> 2001 1117001 1017287 1195142 1049729 1409147 1267002 1579907
> 1563127
> 	> 1195597
> 	> 2002 1228333 1062520 1080117 1171998 1383951 1141008 1604061
> 1446024
> 	> 1276017
> 	> 2003 1068221 1045052 1164273 1091765 1272330 1305676
> 	>
> 	>          Oct     Nov     Dec
> 	> 2001 1290688 1104137 1027022
> 	> 2002 1262232 1048522 1174157
> 	> 2003
> 	>
> 	> Do you know what is happening?
> 	>
> 	> Thank you
> 	> Luis
> 	>
> 	> ______________________________________________
> 	> R-help at stat.math.ethz.ch mailing list
> 	> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 	>
> 	>
> 	 
> 
> 
> 1117001
> 1017287
> 1195142
> 1049729
> 1409147
> 1267002
> 1579907
> 1563127
> 1195597
> 1290688
> 1104137
> 1027022
> 1228333
> 1062520
> 1080117
> 1171998
> 1383951
> 1141008
> 1604061
> 1446024
> 1276017
> 1262232
> 1048522
> 1174157
> 1068221
> 1045052
> 1164273
> 1091765
> 1272330
> 1305676
>



From ernesto at ipimar.pt  Wed Sep  3 19:10:41 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Wed, 03 Sep 2003 18:10:41 +0100
Subject: [R] boot package
Message-ID: <1062609041.30924.10.camel@gandalf.local>

Hi,

I'm getting this error that I don't understand can someone give an hint
on this ?

Thanks

EJ

> boot.ci(blm01,type="bca",index=4)
Error in if (const(t, min(1e-08, mean(t)/1e+06))) { :
        missing value where TRUE/FALSE needed



From p.dobcsanyi at designtheory.org  Wed Sep  3 19:15:00 2003
From: p.dobcsanyi at designtheory.org (Peter Dobcsanyi)
Date: Wed, 3 Sep 2003 18:15:00 +0100
Subject: [R] ANN: An XML format for block designs
Message-ID: <20030903171500.GA6599@designtheory.org>


    A standard format for block designs and their properties
    ========================================================

         (A proposal and an invitation for public debate)


At DesignTheory.org we are developing a web-based Design Theory Resource
Server for combinatorial and statistical design theory.  These resources
will include an online database of designs, an Encyclopaedia of Design
Theory, and software packages for the generation and analysis of
designs.  We hope to address the needs of both researchers and
practitioners of design theory.

One critical element is our XML format to represent designs and their
properties in a standard platform-independent manner. This will allow
for the straightforward exchange of designs and their properties between
various computer systems, including databases and web servers, and
combinatorial, group theoretical and statistical packages. The XML
format will also be used for outside submissions to our design database
and to store designs in perpetuity.

Our initial development is in the area of block designs, and we invite
you to read and comment on our proposal for the External Representation
of Block Designs, available online at:

    http://designtheory.org/

Please send your comments (and follow-ups) exclusively to:

    developers at designtheory.org

This is a mailing list to which you are welcome, although not required,
to join. Alternatively, you can follow the discussions through the
public archives of the list.  For further details, please visit:

    http://designtheory.org/mailing.html

We will finalize the XML format for block designs after sufficient
public debate, after which we shall release GAP [1], R [2], and Python
[3] software for block designs.  We are committed to the open source
model and all products of our development will be released to the public
free of charge.

We shall also start developing a database of block designs, and look
forward to your contributions (in the XML format) to this database.

Please feel free to forward this announcement to anyone you think may be
interested.

References:

[1] GAP - Groups, Algorithms and Programming
    http://www.gap-system.org/

[2] The R Project for Statistical Computing
    http://www.r-project.org/

[3] The Python programming language
    http://www.python.org/



From spencer.graves at pdf.com  Wed Sep  3 19:19:21 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 03 Sep 2003 10:19:21 -0700
Subject: [R] Overlaying graphs
References: <Pine.A41.4.44.0309030711000.270078-100000@homer01.u.washington.edu>	<010a01c37237$0b4bf180$9141de18@computer>
	<x2k78pdemo.fsf@biostat.ku.dk>
Message-ID: <3F562299.5090506@pdf.com>

To "demonstrate that [a variable] is normally distributed", have you 
considered normal probability plots (e.g., via qqnorm)?  They are much 
more sensitive to departures from normality and much more informative on 
the nature of those departures, e.g., showing skewness, mixtures, 
outliers, ... .

hope this helps.  spencer graves

Peter Dalgaard BSA wrote:
> "Paul Meagher" <paul at datavore.com> writes:
> 
> 
>>I am wanting to construct a probability distribution for height and then,
>>hopefully, visually and analytically demonstrate that it is normally
>>distributed.
>>
>>These are the commands I have developed so far:
>>
>>fat   <- read.table("fat.dat", header=TRUE)
>>mu    <- mean(fat$height)
>>sdev  <- sd(fat$height)
>>hist(fat$height, br=20, freq=FALSE, xlab="Male Height in Inches")
>>curve(dnorm(x, mu, sdev), from=64, to=78)
>>
>>I do not know how to overlay the curve graphic on top of hist graphic.
>>
>>I am hoping to show visually that the normal curve overlays the obtained
>>probability distribution when plotted on the same graph.  Unfortunately, I
>>an not sure how to overlay them. Can anyone point me in the right direction
>>or show me the code.
> 
> 
> Using the "add" argument to curve gets you most of the way, but
> getting the y axis right is a little tricky. You could take a look at
> the scripts in the ISwR package (sec.1.3), or the book itself...
>



From rossini at blindglobe.net  Wed Sep  3 18:43:33 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Wed, 03 Sep 2003 09:43:33 -0700
Subject: [R] impact of R and S
Message-ID: <85u17tu8ju.fsf@blindglobe.net>


It is interesting how things have changed -- 5 weeks later, I review
materials collected at the JSM, and notice that Springer-Verlag's
glossy statistics catalog has 3 of 9 books on the front page directly
or indirectly related to R  (Peter D's intro book, MASS, and
Parmigiani et.al's book with a number of Bioconductor-related
chapters).

(one could argue that 8 of 9 could use it -- it would be interesting
if var der Laan / Robins had an associated software toolkit, but that
would be quite a project).

best,
-tony

-- 
A.J. Rossini     			
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW   :              FAX=206-543-3461 | moving soon to a permanent office
FHCRC: 206-667-7025 FAX=206-667-4812 | Voicemail is pretty sketchy/use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From deepayan at stat.wisc.edu  Wed Sep  3 19:52:22 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Wed, 3 Sep 2003 12:52:22 -0500
Subject: [R] llines and NA
In-Reply-To: <200309031609.23490.Bodo.Ahrens@univie.ac.at>
References: <200309031609.23490.Bodo.Ahrens@univie.ac.at>
Message-ID: <200309031252.22547.deepayan@stat.wisc.edu>


This is a bug in grid.lines. A possible workaround is to use your own function 
that handles this using grid.segments (or lsegments).

On Wednesday 03 September 2003 09:09 am, Bodo Ahrens wrote:
> Hallo helpers,
>
> I tried to use "llines" of package lattice in e.g.
>
> levelplot(z~x+y,xyz, at=c.at,region=T,col.regions=col.v,main =
> paste("Test",sep=""),aspect = mapasp(xyz,x=xyz$x,y=xyz$y),
> panel=function(x,y,subscripts,...){
> panel.levelplot(x,y,subscripts,...);
> lines(linex,liney)})
>
> The problem is that there are NAs in linex and liney and thus I get strange
> line segments to infinity.
>
> The base function "lines" is able to handle this. Any ideas how to get a
> similar behavior with "llines"?
>
> Thanks,
>
> Bodo



From fugate at lanl.gov  Wed Sep  3 20:12:14 2003
From: fugate at lanl.gov (Michael Fugate)
Date: Wed, 3 Sep 2003 12:12:14 -0600 (MDT)
Subject: [R] lme in R and Splus
Message-ID: <Pine.LNX.4.44.0309031148080.9025-100000@cptamerica.lanl.gov>

Good Day,

Included below is some code to generate data and to fit a mixed effects
model to this fake data.  The code works as expected when I call the
function "lme" in Splus but not in R.  

The error message from calling lme in R is: 
"Error in getGroups.data.frame(dataMix, groups) :
        Invalid formula for groups"

I installed the nlme package for R around 20 August 2003. 

Thanks in advance.

System information:

Splus:
Version 6.1.2 Release 2 for Sun SPARC, SunOS 5.6 : 2002

R:
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    1
minor    7.1
year     2003
month    06
day      16
language R



############## BEGINNING OF CODE ###########################
# a fake dataset to make the bumps with
nn <- 30  # of data points
mm <- 7   # number of support sites for x(s)
# create sites s
ss <- seq(1,10,length=nn)
# create the data y
e1 <- rnorm(nn,sd=0.1)
e2 <- cos(ss/10*2*pi*4)*.2
yy <- sin(ss/10*2*pi)+e2+e1
plot(ss,yy)

# locations of support points
ww <- seq(1-2,10+2,length=mm)
# width of kernel
sdkern <- 2

# create the matrix KK
KK <- matrix(NA,ncol=mm,nrow=nn)
for(ii in 1:mm){
KK[,ii] <- dnorm(ss,mean=ww[ii],sd=sdkern)
}

# create a dataframe to hold the data
df1 <- data.frame(y=yy,K=KK,sub=1)
df1$sub <- as.factor(df1$sub)

# now fit a mixed model using lme
a1 <- lme(fixed= y ~ 1,
          random= pdIdent(~KK-1),
          data=df1,na.action=na.omit)

# obtain and plot the fitted values
a1p <- as.vector(predict(a1,df1))
lines(ss,a1p,lty=1)

##################### END OF CODE ######################################3

-- 
*********************************************************************
| Michael Fugate                         Temp Phone: (505) 665-1817 |
| Statistical Sciences Group, D-1                                   |
| Los Alamos National Laboratory         email: fugate at lanl.gov     |
| Los Alamos, NM 87545                                              |
| Mail Stop: F600                                                   |



From monica.palaseanu-lovejoy at stud.man.ac.uk  Wed Sep  3 20:21:23 2003
From: monica.palaseanu-lovejoy at stud.man.ac.uk (Monica Palaseanu-Lovejoy)
Date: Wed, 3 Sep 2003 19:21:23 +0100
Subject: [R] plot only partial plots
Message-ID: <E19ucG4-000MvV-8u@probity.mcc.ac.uk>

Hi everybody,

I would like to plot only a part of a data frame, and identify the 
IDs for all the points with  values higher than a certain value. I 
will try to be more explicit: 

I did a qqnorm plot of my data. It is obvious from the plot that 
all the sample quantiles which are in Theoretical Quantiles = or > 
than 1 belong to another group. To be sure about that I plot the 
cooks.distance for the same data, and sure enough the data with 
the indices grater than 250 (x axis) have obvious higher Cook ?s 
distance than the majority of the data. The data indices on the 
Cook?s distance plot are different than my data ID (in my data 
table) which is ?character type?. How do I identify the IDs of the 
data I am interested into, and how I can plot only the data with 
Theoretical Quantiles equal or grater than 1? 

And, of course, how can I plot only the Cook?s distance for the 
data with indices higher than a certain number, or Cook?s 
distance higher than a certain number????

And, on the same line, how can I sort a tab-delimited table after 
the values from one column? I know how to assign one column 
to a vector and sort that vector, but what if I want to sort the 
whole table, like in Excel for example?

Thank you in advance for all your time and answers,

Monica


Monica Palaseanu-Lovejoy
University of Manchester
School of Geography
Mansfield Cooper Building 
Oxford Road, Manchester
M13 9PL, UK. 
email: monica.palaseanu-lovejoy at stud.man.ac.uk



From spencer.graves at pdf.com  Wed Sep  3 20:45:33 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 03 Sep 2003 11:45:33 -0700
Subject: [R] plot only partial plots
References: <E19ucG4-000MvV-8u@probity.mcc.ac.uk>
Message-ID: <3F5636CD.7070402@pdf.com>

I don't know about doing it all on the same line, but have you 
considered something like the following:

DF <- data.frame(x=1:9, y=1:9, z=rep(1:3, 3))
plot(DF$x, DF$y, type="n")
sel <- (DF$z>2)
text(DF$x[sel], DF$y[sel], letters[1:3])

hope this helps.  spencer graves

Monica Palaseanu-Lovejoy wrote:
> Hi everybody,
> 
> I would like to plot only a part of a data frame, and identify the 
> IDs for all the points with  values higher than a certain value. I 
> will try to be more explicit: 
> 
> I did a qqnorm plot of my data. It is obvious from the plot that 
> all the sample quantiles which are in Theoretical Quantiles = or > 
> than 1 belong to another group. To be sure about that I plot the 
> cooks.distance for the same data, and sure enough the data with 
> the indices grater than 250 (x axis) have obvious higher Cook ?s 
> distance than the majority of the data. The data indices on the 
> Cook?s distance plot are different than my data ID (in my data 
> table) which is ?character type?. How do I identify the IDs of the 
> data I am interested into, and how I can plot only the data with 
> Theoretical Quantiles equal or grater than 1? 
> 
> And, of course, how can I plot only the Cook?s distance for the 
> data with indices higher than a certain number, or Cook?s 
> distance higher than a certain number????
> 
> And, on the same line, how can I sort a tab-delimited table after 
> the values from one column? I know how to assign one column 
> to a vector and sort that vector, but what if I want to sort the 
> whole table, like in Excel for example?
> 
> Thank you in advance for all your time and answers,
> 
> Monica
> 
> 
> Monica Palaseanu-Lovejoy
> University of Manchester
> School of Geography
> Mansfield Cooper Building 
> Oxford Road, Manchester
> M13 9PL, UK. 
> email: monica.palaseanu-lovejoy at stud.man.ac.uk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From rpeng at jhsph.edu  Wed Sep  3 21:33:50 2003
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 03 Sep 2003 15:33:50 -0400
Subject: [R] boot package
In-Reply-To: <1062609041.30924.10.camel@gandalf.local>
References: <1062609041.30924.10.camel@gandalf.local>
Message-ID: <3F56421E.4000403@jhsph.edu>

It's hard to say, but I sometimes get this error when I either have a 
very small dataset or if I don't do enough resamples (i.e. R is too small).

-roger

Ernesto Jardim wrote:

>Hi,
>
>I'm getting this error that I don't understand can someone give an hint
>on this ?
>
>Thanks
>
>EJ
>
>  
>
>>boot.ci(blm01,type="bca",index=4)
>>    
>>
>Error in if (const(t, min(1e-08, mean(t)/1e+06))) { :
>        missing value where TRUE/FALSE needed
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>  
>



From bates at stat.wisc.edu  Wed Sep  3 21:37:58 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 03 Sep 2003 19:37:58 -0000
Subject: [R] lme in R and Splus
In-Reply-To: <Pine.LNX.4.44.0309031148080.9025-100000@cptamerica.lanl.gov>
References: <Pine.LNX.4.44.0309031148080.9025-100000@cptamerica.lanl.gov>
Message-ID: <6rwucpmzlw.fsf@bates4.stat.wisc.edu>

Michael Fugate <fugate at lanl.gov> writes:

> ############## BEGINNING OF CODE ###########################
> # a fake dataset to make the bumps with
> nn <- 30  # of data points
> mm <- 7   # number of support sites for x(s)
> # create sites s
> ss <- seq(1,10,length=nn)
> # create the data y
> e1 <- rnorm(nn,sd=0.1)
> e2 <- cos(ss/10*2*pi*4)*.2
> yy <- sin(ss/10*2*pi)+e2+e1
> plot(ss,yy)
> 
> # locations of support points
> ww <- seq(1-2,10+2,length=mm)
> # width of kernel
> sdkern <- 2
> 
> # create the matrix KK
> KK <- matrix(NA,ncol=mm,nrow=nn)
> for(ii in 1:mm){
> KK[,ii] <- dnorm(ss,mean=ww[ii],sd=sdkern)
> }
> 
> # create a dataframe to hold the data
> df1 <- data.frame(y=yy,K=KK,sub=1)
> df1$sub <- as.factor(df1$sub)
> 
> # now fit a mixed model using lme
> a1 <- lme(fixed= y ~ 1,
>           random= pdIdent(~KK-1),
>           data=df1,na.action=na.omit)

You don't have a grouping factor in the random specification and I
can't tell from the simulation what you would expect the groups to be.

> # obtain and plot the fitted values
> a1p <- as.vector(predict(a1,df1))
> lines(ss,a1p,lty=1)
> 
> ##################### END OF CODE ######################################3
> 
> -- 
> *********************************************************************
> | Michael Fugate                         Temp Phone: (505) 665-1817 |
> | Statistical Sciences Group, D-1                                   |
> | Los Alamos National Laboratory         email: fugate at lanl.gov     |
> | Los Alamos, NM 87545                                              |
> | Mail Stop: F600                                                   |
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/



From kjetil at entelnet.bo  Wed Sep  3 22:38:55 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Wed, 03 Sep 2003 16:38:55 -0400
Subject: [R] value of hypsometric integral ( ecdf() )
In-Reply-To: <1062624701.14613.34.camel@templar.fns.uniba.sk>
Message-ID: <3F56191F.24061.908F91@localhost>

On 3 Sep 2003 at 17:31, Rado Bonk wrote:

?
It is not really clear what you want, since what you call the 
"hypsometric" curve is really the cumulative distribution function, 
so its integral is infinite.

Does the following help?

> data(volcano)
> library(stepfun)
> plot(ecdf(volcano), do.points=F, verticals=T)
> test <- ecdf(volcano)
> str(test)
function (v)  
 - attr(*, "class")= chr [1:3] "ecdf" "stepfun" "function"
 - attr(*, "call")= language ecdf(volcano)
> test(120)
[1] 0.4586395
> args(integrate)
function (f, lower, upper, subdivisions = 100, rel.tol = 
.Machine$double.eps^0.25, 
    abs.tol = rel.tol, stop.on.error = TRUE, keep.xy = FALSE, 
    aux = NULL, ...) 
NULL
> test( 100:110)
 [1] 0.1066516 0.1221029 0.1371773 0.1535708 0.1727907 0.1929527 
0.2127379
 [8] 0.2317694 0.2534389 0.2726588 0.3060109
> integrate( test, 80, 200)
Error in integrate(test, 80, 200) : maximum number of subdivisions 
reached
> integrate( test, 80, 200, subdivisions=1000)
69.81223 with absolute error < 0.0033
> 

Kjetil Halvorsen



> Hi R-users,
> 
> How can I compute the area below the curve (so called "hypsometric
> integral") plotted by:
> 
> plot(ecdf(volcano), do.points=F, verticals=T)
> 
> Thanks,
> 
> Rado
> 
> 
> -- 
> Radoslav Bonk M.S.
> Dept. of Physical Geography and Geoecology
> Faculty of Sciences, Comenius University
> Mlynska Dolina 842 15, Bratislava, SLOVAKIA
> tel: +421 905 968 127 e-mail: rbonk at host.sk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From p.dalgaard at biostat.ku.dk  Wed Sep  3 22:49:40 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed, 03 Sep 2003 20:49:40 -0000
Subject: [R] lme in R and Splus
In-Reply-To: <Pine.LNX.4.44.0309031148080.9025-100000@cptamerica.lanl.gov>
References: <Pine.LNX.4.44.0309031148080.9025-100000@cptamerica.lanl.gov>
Message-ID: <x2znhlmw91.fsf@biostat.ku.dk>

Michael Fugate <fugate at lanl.gov> writes:

> ############## BEGINNING OF CODE ###########################
> # a fake dataset to make the bumps with
> nn <- 30  # of data points
> mm <- 7   # number of support sites for x(s)
> # create sites s
> ss <- seq(1,10,length=nn)
> # create the data y
> e1 <- rnorm(nn,sd=0.1)
> e2 <- cos(ss/10*2*pi*4)*.2
> yy <- sin(ss/10*2*pi)+e2+e1
> plot(ss,yy)
> 
> # locations of support points
> ww <- seq(1-2,10+2,length=mm)
> # width of kernel
> sdkern <- 2
> 
> # create the matrix KK
> KK <- matrix(NA,ncol=mm,nrow=nn)
> for(ii in 1:mm){
> KK[,ii] <- dnorm(ss,mean=ww[ii],sd=sdkern)
> }
> 
> # create a dataframe to hold the data
> df1 <- data.frame(y=yy,K=KK,sub=1)
> df1$sub <- as.factor(df1$sub)
> 
> # now fit a mixed model using lme
> a1 <- lme(fixed= y ~ 1,
>           random= pdIdent(~KK-1),
>           data=df1,na.action=na.omit)
> 
> # obtain and plot the fitted values
> a1p <- as.vector(predict(a1,df1))
> lines(ss,a1p,lty=1)

lme in S-PLUS is older than the one in R, and some things changed. I
think you want

df1 <- data.frame(y=yy,K=I(KK),sub=1)
a1 <- lme(fixed= y ~ 1,
          random= list(sub=pdIdent(~K-1)),
          data=df1,na.action=na.omit)
lines(ss,predict(a1,df1,1))

(Apparently you can't do a level-0 prediction in a model with only an
intercept, which looks like a bit of a bug. Of course, that is just
the intercept for all observations, but...)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From bbals at t-online.de  Wed Sep  3 23:13:30 2003
From: bbals at t-online.de (Bernhard Bals)
Date: Wed, 03 Sep 2003 23:13:30 +0200
Subject: [R] Calling functions of R from Perl?
Message-ID: <3F56597A.3050007@t-online.de>

Hi,

I've already asked this question, but unfortunately I've combined it 
with another question. So it was ignored in almost all cases. Thanks to 
those who have already given some hints.

Here again:

I don't want to use R interactively (issue commands after the prompt > 
..), but use some functionality of R from inside a Perl script.

Can I use methods of R from a Perl script: Is there an interface from
Perl (or at least from C/C++) to R (f.e. invoke R functions from Perl,
C, C++ or some other language)?
If so, can you please point me to the documentation on the Web or in
literature where this is decribed?

Do you have some trivial demo Perl script (or C/C++ program) that uses 
this technique, f.e. calls an R method like "mean" or "standard deviation"?

Any help is appreciated very much!


Regards
Bernhard
_________________

Dr. Bernhard Bals
Dollmannstr. 6
D-81541 M?nchen
+49-89-62509585
bbals at t-online.de



From vograno at evafunds.com  Wed Sep  3 23:29:25 2003
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Wed, 3 Sep 2003 14:29:25 -0700
Subject: [R] read.table: check.names arg - feature request
Message-ID: <6776E9D60411DD439AA7C8A20F67C51C1797F8@ehost060.intermedia.net>

Hi,

I thought it would be convenient if the check.names argument to read.table, which currently can only be TRUE/FALSE, could take a function value as well. If the function is supplied it should be used instead of the default make.names.

Here is an example where it can come in handy. I tend to keep my data in coma-separated files with a header line. The header line is prefixed with a comment sign '#' to simplify identification of these lines. Now when I read.table the files the '#' is converted to '.' while I want it to be discarded.

Thanks,
Vadim


P.S. I don't know if r-help is the right place for feature requests. If it's not please let me know where the right one is.



From mingliz2 at netscape.net  Thu Sep  4 00:41:16 2003
From: mingliz2 at netscape.net (Ming)
Date: Wed, 03 Sep 2003 18:41:16 -0400
Subject: [R] help.start( )
Message-ID: <52BB82FC.679C9736.00A174A8@netscape.net>

Dear R experts,

I installed R-1.7.1 on Linux (Red Hat 9.0) starting from R-1.7.1.tgz without a problem.  Then I fired up R and tried things and found that help.start( ) does not work.  I downloaded Sun Java j2re1.4.2, installed that and re-installed R-1.7.1 from scratch.  I tried help.start( ) again and the browser (Mozilla 1.2.1) crashed.

I read about copying libjavaplugin_oji.so into mozilla/plugins and installed R-1.7.1 (again from scratch).  Mozilla still crashed.  Can you tell me how to make help.start( ) work in R-1.7.1?

Thank you

Ming Chow

__________________________________________________________________
McAfee VirusScan Online from the Netscape Network.
Comprehensive protection for your entire computer. Get your free trial today!
http://channels.netscape.com/ns/computing/mcafee/index.jsp?promo=393397

Get AOL Instant Messenger 5.1 free of charge.  Download Now!



From steve.dutky at thomson.com  Thu Sep  4 01:09:51 2003
From: steve.dutky at thomson.com (Dutky, Steve)
Date: Wed, 3 Sep 2003 19:09:51 -0400 
Subject: [R] How to avoid automatic coercion to factor?
Message-ID: <6EEA47532CD0D611887500B0D04943453FBA4B@tfsmdmsg7.tfn.com>

Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>...
>If you really want character columns, the way to do it is underhand:
>
>f <- function() {
>    a <- list(Int1=1:5,Char1=letters[1:5],Char2=letters[6:10])
>    attr(a, "row.names") <- 1:5
>    attr(a, "class") <- "data.frame"
>    a
>}
>...
This certainly appears to me to be the least ugly of the suggested methods.
Is there a point at which "underhand" becomes "inadvisable"?

>...
>We should ask why you want character columns in a data frame? 

The short answer is that it is closer to how I get the original data.  The
remaining manipulations appear more convenient to me as character columns in
a data frame (e.g.. as arguments to functions for fix, string and regular
expressions) than either factors or lists.  In this particular application,
the character columns share the same domain of values, however more often
than not, as factors, the same values appear as distinct levels in different
columns.

I grant that my S programming occurs in a vacuum and exhibits all the bad
habits I acquired from a life spent in impoverished development
environments.  I certainly appreciate the generosity of your feedback and
the availability of 'r-help at stat.math.ethz.ch'

Thanks, Steve Dutky
-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
Sent: Wednesday, September 03, 2003 12:51 AM
To: Deepayan Sarkar
Cc: Dutky, Steve; 'r-help at stat.math.ethz.ch'
Subject: Re: [R] How to avoid automatic coercion to factor?


Deepayan is correct, but note that I() creates a column of class "AsIs", 
not "character".  We should ask why you want character columns in a data 
frame?   (Certainly prior to 1.8.0 there is a fair chance that unless they 
are of class "AsIs" manipulations would turn them into factors.)

If you really want character columns, the way to do it is underhand:

f <- function() {
    a <- list(Int1=1:5,Char1=letters[1:5],Char2=letters[6:10])
    attr(a, "row.names") <- 1:5
    attr(a, "class") <- "data.frame"
    a
}

However, you might consider returning a list.


On Tue, 2 Sep 2003, Deepayan Sarkar wrote:

> 
> >From ?data.frame:
> 
>      Character variables passed to 'data.frame' are converted
>      to factor columns unless protected by 'I'. If a list or data frame
>      or matrix is passed to 'data.frame' it is as if each column had
>      been passed as a separate argument.
> 
> See the Examples section for an example.
> 
> On Tuesday 02 September 2003 17:30, Dutky, Steve wrote:
> > I have a function that manipulates a list of numeric and character
> > components of equal length and wants to return a data.frame.
> >
> > EG,
> >
> > f<-function() {
> > 	a<-list(Int1=1:5,Char1=letters[1:5],Char2=letters[6:10])
> > 	b<-data.frame(a)
> > }
> >
> > How can I get the columns Char1, Char2, (...CharN) returned coerced to
> > character and not factor?
> >
> > It appears that I could coerce individual columns by
> > b$CharI<-as.character(b$CharI). Is there a less ugly way of doing this?
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jasont at indigoindustrial.co.nz  Thu Sep  4 01:21:13 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Thu, 04 Sep 2003 11:21:13 +1200
Subject: [R] Calling functions of R from Perl?
In-Reply-To: <3F56597A.3050007@t-online.de>
References: <3F56597A.3050007@t-online.de>
Message-ID: <3F567769.8090102@indigoindustrial.co.nz>

Bernhard Bals wrote:
> Hi,
> 
> I've already asked this question, but unfortunately I've combined it 
> with another question. So it was ignored in almost all cases. Thanks to 
> those who have already given some hints.
> 
> Here again:
> 
> I don't want to use R interactively (issue commands after the prompt > 
> ..), but use some functionality of R from inside a Perl script.
> 
> Can I use methods of R from a Perl script: Is there an interface from
> Perl (or at least from C/C++) to R (f.e. invoke R functions from Perl,
> C, C++ or some other language)?
> If so, can you please point me to the documentation on the Web or in
> literature where this is decribed?
> 
> Do you have some trivial demo Perl script (or C/C++ program) that uses 
> this technique, f.e. calls an R method like "mean" or "standard deviation"?
> 

Haven't used it myself, so I don't know how well it works, but this one 
might do what you want...

http://www.omegahat.org/RSPerl/index.html

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz



From edd at debian.org  Thu Sep  4 01:13:37 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 3 Sep 2003 18:13:37 -0500
Subject: [R] Calling functions of R from Perl?
In-Reply-To: <3F56597A.3050007@t-online.de>
References: <3F56597A.3050007@t-online.de>
Message-ID: <20030903231337.GA15736@sonny.eddelbuettel.com>

On Wed, Sep 03, 2003 at 11:13:30PM +0200, Bernhard Bals wrote:
> I don't want to use R interactively (issue commands after the prompt > 
> ..), but use some functionality of R from inside a Perl script.
> 
> Can I use methods of R from a Perl script: Is there an interface from
> Perl (or at least from C/C++) to R (f.e. invoke R functions from Perl,
> C, C++ or some other language)?

Sure. You can always use Perl to 'print' commands into a pipe to R. Or even
write them to a file, and then have Perl's backtick or system command
execute the file via R's batch mode.

There is a much higher-end interface available at www.omegahat.org, but it
sounds like you want something simple.

> If so, can you please point me to the documentation on the Web or in
> literature where this is decribed?

Google is your friend -- the 'call R from perl' query finds a total of
353,000 documents, including the aforementioned omegahat.org code as well as
prior discussions on this list.

http://www.google.com/search?hl=en&ie=UTF-8&oe=UTF-8&q=call+R+from+perl&btnG=Google+Search

Dirk


-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From jasont at indigoindustrial.co.nz  Thu Sep  4 01:32:26 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Thu, 04 Sep 2003 11:32:26 +1200
Subject: [R] help.start( )
In-Reply-To: <52BB82FC.679C9736.00A174A8@netscape.net>
References: <52BB82FC.679C9736.00A174A8@netscape.net>
Message-ID: <3F567A0A.3090507@indigoindustrial.co.nz>

Ming wrote:
> Dear R experts,
> 
> I installed R-1.7.1 on Linux (Red Hat 9.0) starting from R-1.7.1.tgz without a problem.  Then I fired up R and tried things and found that help.start( ) does not work.  I downloaded Sun Java j2re1.4.2, installed that and re-installed R-1.7.1 from scratch.  I tried help.start( ) again and the browser (Mozilla 1.2.1) crashed.
> 
> I read about copying libjavaplugin_oji.so into mozilla/plugins and installed R-1.7.1 (again from scratch).  Mozilla still crashed.  Can you tell me how to make help.start( ) work in R-1.7.1?
> 

It doesn't help much, but it works fine on my SuSE 8.2 box, using 
R-1.7.1 (patched) and Mozlla 1.2.1.  I've also used Konqueror (the KDE 
browser/file manager) using help.start(browser="konqueror").  Have you 
tried that (or Galleon, or Opera, or ...)?

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz



From jasjeet_sekhon at harvard.edu  Thu Sep  4 01:56:04 2003
From: jasjeet_sekhon at harvard.edu (Jasjeet S. Sekhon)
Date: Wed, 3 Sep 2003 19:56:04 -0400
Subject: [R] R on Linux/Opteron?
Message-ID: <200309031956.04328.jasjeet_sekhon@harvard.edu>

I use R on a dual Opteron running SuSE Enterprise version 8 (amd-64).
It compiles without complaint using gcc-3.3 (64bit)---all of the tests
are successful and my personal test code performs well.  The
performance is rather good.  I could NOT get R to compile using the
Portland Group compilers.

Doing realistic benchmarks is very hard.  But in production the
machine is *much* nicer to work with than any Intel machine I've
worked on (for a similar price---i.e., excluding Itaniums).  The
Opteron is made to be a server chip and this really shows in server
related tasks, such as multiple processes and process which require a
lot of RAM or do a lot of I/O.

Cheers,
Jas.

======================================
Jasjeet S. Sekhon
Assistant Professor
Harvard University
Center for Basic Research in the 
  Social Sciences
jsekhon at fas.harvard.edu
http://jsekhon.fas.harvard.edu/
Office: 617.496.2426 Fax: 617.496.5149
======================================

>Dear R-help:
>
>Has anyone tried using R on the the AMD Opteron in either 64- or 32-bit
>mode?  If so, any good/bad experiences, comments, etc?  We are considering
>getting this hardware, and would like to know if R can run smoothly on such
>a beast.  Any comment much appreciated.
>
>Best,
>Andy
>
>Andy Liaw, PhD
>Biometrics Research      PO Box 2000, RY33-300     
>Merck Research Labs           Rahway, NJ 07065
>mailto:andy_liaw at merck.com <mailto:andy_liaw at merck.com>         
>732-594-0820



From MSchwartz at medanalytics.com  Thu Sep  4 02:02:03 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 03 Sep 2003 19:02:03 -0500
Subject: [R] help.start( )
In-Reply-To: <52BB82FC.679C9736.00A174A8@netscape.net>
References: <52BB82FC.679C9736.00A174A8@netscape.net>
Message-ID: <1062633723.4200.47.camel@localhost>

On Wed, 2003-09-03 at 17:41, Ming wrote:
> Dear R experts,
> 
> I installed R-1.7.1 on Linux (Red Hat 9.0) starting from R-1.7.1.tgz
> without a problem.  Then I fired up R and tried things and found that
> help.start( ) does not work.  I downloaded Sun Java j2re1.4.2,
> installed that and re-installed R-1.7.1 from scratch.  I tried
> help.start( ) again and the browser (Mozilla 1.2.1) crashed.
> 
> I read about copying libjavaplugin_oji.so into mozilla/plugins and
> installed R-1.7.1 (again from scratch).  Mozilla still crashed.  Can
> you tell me how to make help.start( ) work in R-1.7.1?
> 
> Thank you
> 
> Ming Chow


You don't want to copy the file itself into the plug-in directory, but
create a 'symlink' to the file.

One of the things that you should consider (seriously) doing, is to
upgrade your mozilla version to 1.4. There have been notable (and
beneficial) updates to the browser since 1.2.x.

You will need to open a console window, su to root and change into the
mozilla/plugins folder, which should be something like:

/usr/lib/mozilla-1.4/plugins

Of course, adjust the 'mozilla-1.x' component to your actual path.

In that folder, in the console window as root, type:

ln -s /usr/path-to-java/plugin/i386/ns610-gcc32/libjavaplugin_oji.so

That will create the symlink for the java plug-in. Adjust the
'path-to-java' above for your installation of java. Be sure that you use
the 'ns610-gcc32' path and not the others that may be present. This is a
version of the plugin that was compiled with the version of gcc that
comes with RH 9.

Once you have created the symlink, then try help.start() in R. If things
are functioning properly and the initial main page comes up, after you
click on "Search Engine & Keywords", you should see "Applet SearchEngine
started" on the mozilla status line.

HTH,

Marc Schwartz



From ok at cs.otago.ac.nz  Thu Sep  4 05:06:02 2003
From: ok at cs.otago.ac.nz (Richard A. O'Keefe)
Date: Thu, 4 Sep 2003 15:06:02 +1200 (NZST)
Subject: [R] plotting a distribution curves
Message-ID: <200309040306.h84362rC297641@atlas.otago.ac.nz>

Rajarshi Guha <rajarshi at presidency.com> wrote:
	  is there a way to plot distribution curves (say normal or chi sq etc)
	from within R?
	
	For example I looked up the *chisq family of functions but I'm not sure
	as to how I would use them to generate a plot of the chi sq distribution
	(for arbitrary d.o.f).
	
Perhaps the most obvious way:
    x <- seq(0, 30, length=101)
    plot(x, dchisq(x, df=8))

Another way:
    curve(dchisq(x,df=8), from=0, to=30)

As someone has recently noted, code that depends on the textual
form of something is often subtly wrong, which is why I think that
"curve" and similar functions are best avoided.  A third way that
is better than "curve" is

    plot(function(x) dchisq(x,df=8), from=0, to=30)

in which the name of the argument x no longer matters.

This can of course be used with any function, not just a c* function.



From especiales at canaco.net  Thu Sep  4 05:06:57 2003
From: especiales at canaco.net (especiales | canaco.net)
Date: Wed, 3 Sep 2003 22:06:57 -0500
Subject: [R] Mantenga la Seguridad en el Trabajo ...
Message-ID: <1737063297-220039443657279@canaco.net>


   Para dejar de recibir especiales|canaco.net vaya al final del boletín
                    Mantenga la Seguridad en el Trabajo
                           y evite ser sancionado

                              Septiembre, 2003
       Manténgase al día y evite desembolsos o sanciones innecesarios
        garantice la seguridad en su Centro de Trabajo y conozca las
       alternativas que tiene como empresario para lograr un ambiente
       preventivo y sano. Obtenga el mejor rendimiento laboral de sus
     empleados a través de la Creación de las Comisiones Capacitación y
                Seguridad e Higiene en su empresa o negocio.
        Canaco Monterrey lo invita a participar en su próximo evento
                          SEGURIDAD EN EL TRABAJO
            Expositor:        Lic. Antonio Sarabia Cantú
                          Depto. de Inspección en el Trabajo
                       Secretaría del Trabajo y Previsión Social
    La cita es el viernes 9 de Septiembre de 2003 en el Edificio Canaco,
    ubicado en Ocampo 411 Pte., Centro, de 3:00 p.m. a 6:00 p.m., Costo
    para socios $1,250.00 + IVA Costo para no Socios $ 2,250.00 + I.V.A.
      Recuerde que usted puede asistir a este evento SIN ningún COSTO
   utilizando los beneficios que le brinda la propuesta de valor Peso que
                        no da Tres... ¿Para qué es?
    Para mayores informes y confirmaciones comuníquese a la Gerencia de
     Servicios Legales al Tel. 8400-2424 o vía correo electrónico a la
                       dirección: [1]legal at canaco.net
                        [2][USEMAP:down_der_a.jpg]
                        [3][USEMAP:down_der_ab.jpg]
                   [4]Envía este boletín a un amigo AHORA
         Usted recibe esta publicación por que está suscrito a las
                        publicaciones de canaco.net
   La dirección a que le enviamos el mensaje es r-help at stat.math.ethz.ch,
    para dejar de recibir Boletines Especiales|canaco.net [5]Click aquí
      Derechos Reservados © CANACO Monterrey, N.L., México 2000 - 2003

   [t.asp?S=2&ID=531&NL=8&N=565&Imp=True&SubscriberID=151453]

References

   1. mailto:legal at canaco.net?subject=Confirmaci%F3n al evento de Seguridad en el Trabajo ...
   2. LYNXIMGMAP:file://localhost/tmp/@8515.0.html#new
   3. LYNXIMGMAP:file://localhost/tmp/@8515.0.html#new1
   4. http://www.canaco.net/enewsletterpro/members.asp?Task=FF&SubscriberID=151453&Email=r%2Dhelp%40stat%2Emath%2Eethz%2Ech&S=2&N=565&Format=HTML
   5. http://www.canaco.net/enewsletterpro/members.asp?Task=OptOut&SubscriberID=151453&Email=r%2Dhelp%40stat%2Emath%2Eethz%2Ech&S=2


From zhuw at mail.smu.edu  Thu Sep  4 06:41:19 2003
From: zhuw at mail.smu.edu (zhu wang)
Date: Thu, 04 Sep 2003 04:41:19 -0000
Subject: [R] carma (package growth)
Message-ID: <1062650340.4587.12.camel@zwang.stat.smu.edu>

Dear helpers,

I am wondering if I can use the growth package to fit continuous ARMA
time series. To be specific,

y <- arima.sim(model=list(ar=c(1.7,-0.8)),n=100)

How do I use carma to fit y if possible? The package is for longitudinal
data but I suspect I can use it for my problem. I looked at the help
file without success.

Thanks for any ideas.


-- 
Zhu Wang

Statistical Science Department
Southern Methodist University
Phone: (214)768-2453
Fax: (214)768-4035
Email: zhuw at mail.smu.edu



From bido at mac.com  Thu Sep  4 07:50:28 2003
From: bido at mac.com (Francisco J. Bido)
Date: Thu, 4 Sep 2003 00:50:28 -0500
Subject: [R] Looking for R Equivalent of Gauss Statements
Message-ID: <B041336F-DE9B-11D7-AD7D-000393B90A0A@mac.com>

Hi,

I am translating some Gauss code to R.  Gauss has an interesting way of 
handling constraints.  Observe the following code snipplet:

e1 = x[.,23] .eq 0;  @ remove obs with Regular Hours = 0 @
e2 = x[.,12] .gt 1;   @ remove obs with non-regular work status @
e3 = x[.,4] .lt 15;    @ remove obs with agricultural and mining 
industry code (< 15)@
esum = e1 + e2 + e3;
e = esum .gt 0;      @ remove obs that fail all three of the above 
tests @
x = delif(x,e);

I'm hoping that the above is self explanatory.    Currently I am using 
the  "subset" command in R to compute e1, e2, e3 but the rest is 
tricky: the actual code has several additional constraints and I'm 
ending up with some very ugly buggy code.   Is there a straightforward 
way to do this in R?

Thanks,
-Francisco



From Marlene.Mueller at gmx.de  Thu Sep  4 09:37:58 2003
From: Marlene.Mueller at gmx.de (Marlene Mueller)
Date: Thu, 04 Sep 2003 09:37:58 +0200
Subject: [R] Looking for R Equivalent of Gauss Statements
In-Reply-To: <B041336F-DE9B-11D7-AD7D-000393B90A0A@mac.com>
References: <B041336F-DE9B-11D7-AD7D-000393B90A0A@mac.com>
Message-ID: <3F56EBD6.9030900@gmx.de>


R is very similar to Gauss for this kind of task.
Try:

   e1 <- x[,23] == 0
   e2 <- x[,12] > 1
   e3 <- x[,4] < 15
   e  <- e1 | e2 | e3   # e1 or e2 or e3
   x  <- x[!e,]         # keep if NOT e

Hope that helps,
Marlene



Francisco J. Bido wrote:
> Hi,
> 
> I am translating some Gauss code to R.  Gauss has an interesting way of 
> handling constraints.  Observe the following code snipplet:
> 
> e1 = x[.,23] .eq 0;  @ remove obs with Regular Hours = 0 @
> e2 = x[.,12] .gt 1;   @ remove obs with non-regular work status @
> e3 = x[.,4] .lt 15;    @ remove obs with agricultural and mining 
> industry code (< 15)@
> esum = e1 + e2 + e3;
> e = esum .gt 0;      @ remove obs that fail all three of the above tests @
> x = delif(x,e);
> 
> I'm hoping that the above is self explanatory.    Currently I am using 
> the  "subset" command in R to compute e1, e2, e3 but the rest is tricky: 
> the actual code has several additional constraints and I'm ending up 
> with some very ugly buggy code.   Is there a straightforward way to do 
> this in R?
> 
> Thanks,
> -Francisco
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 


-- 
PD Dr. Marlene M?ller
Fraunhofer ITWM Kaiserslautern, Abt. Finanzmathematik
mailto:Marlene.Mueller at itwm.fraunhofer.de, Tel/Fax: +49 631 205 4189/4139
http://www.itwm.fhg.de/index.php?abt=fm/employees/mueller&inc=mueller



From maechler at stat.math.ethz.ch  Thu Sep  4 10:28:02 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 4 Sep 2003 10:28:02 +0200
Subject: [R] read.table: check.names arg - feature request
In-Reply-To: <6776E9D60411DD439AA7C8A20F67C51C1797F8@ehost060.intermedia.net>
References: <6776E9D60411DD439AA7C8A20F67C51C1797F8@ehost060.intermedia.net>
Message-ID: <16214.63378.867051.496778@gargle.gargle.HOWL>

>>>>> "Vadim" == Vadim Ogranovich <vograno at evafunds.com>
>>>>>     on Wed, 3 Sep 2003 14:29:25 -0700 writes:

    Vadim> Hi, I thought it would be convenient if the
    Vadim> check.names argument to read.table, which currently
    Vadim> can only be TRUE/FALSE, could take a function value
    Vadim> as well. If the function is supplied it should be
    Vadim> used instead of the default make.names.

One could, but it's not necessary in your case (see below), and
it's a potential pit to fall in..  We want read.table() to
return valid  data frames.

    Vadim> Here is an example where it can come in handy. I tend
    Vadim> to keep my data in coma-separated files with a header
    Vadim> line. The header line is prefixed with a comment sign
    Vadim> '#' to simplify identification of these lines. Now
    Vadim> when I read.table the files the '#' is converted to
    Vadim> '.' while I want it to be discarded.

Hmm, are you using a very old version of R,
or haven't you seen the `comment.char = "#"' argument of
read.table()?

Reading "?read.table", also note the note about
`blank.lines.skip' , and then realize that the default for
blank.lines.skip is  ` !fill ' and that `fill = TRUE' for all
the read.csv* and read.delim* incantation of read.table().

In sum, it's very easy to use current read.table() for your
situation!

    Vadim> P.S. I don't know if r-help is the right place for
    Vadim> feature requests. If it's not please let me know
    Vadim> where the right one is.

Since your proposal can be interpreted as "How do I use
read.table() when my file has comment lines?",
r-help has been very appropriate.

Otherwise, and particularly if the proposal is more technical,
R-devel would be better suited.

Regards,
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From britta.lintfert at IMS.Uni-Stuttgart.DE  Thu Sep  4 11:18:40 2003
From: britta.lintfert at IMS.Uni-Stuttgart.DE (Britta Lintfert)
Date: Thu, 04 Sep 2003 11:18:40 +0200
Subject: [R] ANOVA/MANOVA
Message-ID: <3F57036F.1D8E5224@ims.uni-stuttgart.de>

Hello,

I have to do an  ANOVA (or is it a MANOVA) with 6 Variables (called HsL,
LsH, Hp, Lp, G, and) and  6 categories (OQ, Go, RC, AV, CC, Sk),  the
examples in the literature couldn't help me so far.  Who can help me??
Thank

Britta



From kwan022 at stat.auckland.ac.nz  Thu Sep  4 12:18:51 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Thu, 4 Sep 2003 22:18:51 +1200 (NZST)
Subject: [R] ANOVA/MANOVA
In-Reply-To: <3F57036F.1D8E5224@ims.uni-stuttgart.de>
Message-ID: <Pine.LNX.4.44.0309042217500.17286-100000@stat55.stat.auckland.ac.nz>

On Thu, 4 Sep 2003, Britta Lintfert wrote:

> I have to do an  ANOVA (or is it a MANOVA) with 6 Variables (called HsL,
> LsH, Hp, Lp, G, and) and  6 categories (OQ, Go, RC, AV, CC, Sk),  the
> examples in the literature couldn't help me so far.  Who can help me??

Perhaps the documentation of aov()?  Which part of it do you not 
understand?

Take a look at:
?aov

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
"On two occasions, I have been asked [by members of Parliament],
'Pray, Mr. Babbage, if you put into the machine wrong figures, will
the right answers come out?' I am not able to rightly apprehend the
kind of confusion of ideas that could provoke such a question."

-- Charles Babbage (1791-1871) 
---- From Computer Stupidities: http://rinkworks.com/stupid/

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)



From uleopold at science.uva.nl  Thu Sep  4 13:11:07 2003
From: uleopold at science.uva.nl (Ulrich Leopold)
Date: Thu, 04 Sep 2003 11:11:07 -0000
Subject: [R] subtract 2 columns in a data.frame
Message-ID: <1062673905.22020.41.camel@pc-fg6>

Dear list,

could someone point me to the right command to subtract 2 columns in a
data.frame. Might be a bit embarrassing question. But I cannot figure
out how to do this simple command in R.

Thanks, Ulrich
-- 
__________________________________________________

Ulrich Leopold MSc.

Department of Physical Geography
Institute for Biodiversity and Ecosystem Dynamics
Faculty of Science
University of Amsterdam
Nieuwe Achtergracht 166
NL-1018WV Amsterdam

Phone:	+31 20 525 7456 (7451 Secretary)
Fax:	+31 20 525 7431
Mobile:	+31 64 220 3028
Email:	uleopold at science.uva.nl
URL:	www.science.uva.nl/ibed/research/Research_Fields/fg/stafffg/index.html



From spencer.graves at pdf.com  Thu Sep  4 13:19:55 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 04 Sep 2003 04:19:55 -0700
Subject: [R] subtract 2 columns in a data.frame
References: <1062673905.22020.41.camel@pc-fg6>
Message-ID: <3F571FDB.1010401@pdf.com>

Is the following what you want?

 > DF <- data.frame(a=1:2, b=3:4)
 > DF$a-DF$b
[1] -2 -2
 > DF[,"a"]-DF[,"b"]
[1] -2 -2

hope this helps.  spencer graves

Ulrich Leopold wrote:
> Dear list,
> 
> could someone point me to the right command to subtract 2 columns in a
> data.frame. Might be a bit embarrassing question. But I cannot figure
> out how to do this simple command in R.
> 
> Thanks, Ulrich



From p.dalgaard at biostat.ku.dk  Thu Sep  4 13:20:42 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Thu, 04 Sep 2003 11:20:42 -0000
Subject: [R] subtract 2 columns in a data.frame
In-Reply-To: <1062673905.22020.41.camel@pc-fg6>
References: <1062673905.22020.41.camel@pc-fg6>
Message-ID: <x2smnchk7u.fsf@biostat.ku.dk>

Ulrich Leopold <uleopold at science.uva.nl> writes:

> Dear list,
> 
> could someone point me to the right command to subtract 2 columns in a
> data.frame. Might be a bit embarrassing question. But I cannot figure
> out how to do this simple command in R.

E.g.,

mydata$difference <- mydata$x - mydata$y

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ernesto at ipimar.pt  Thu Sep  4 13:44:01 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Thu, 04 Sep 2003 12:44:01 +0100
Subject: [R] boot with strata doubt
Message-ID: <1062675841.2751.24.camel@gandalf.local>

Hi,

I'm using the boot package to bootstrap a linear model. The boot command
is:

> blm01 <- boot(mat, boot.fishpower, 1000, strata=boot.strata)

I'm having several problems with the linear model so I decided to check
the stratification. The first thing I did was checking the number of
observations by strata, in particular strata with only 1 observation:

> vec1 <- unlist(lapply(split(boot.strata, boot.strata), length))
> table(vec1)
vec1
 1  2  3  4  5  6  7  8 10 11 12 13 15 21 23 43 56 60
19  3 11  5  4  2  1  1  3  2  1  2  1  2  1  1  1  2

So I have 19 strata with 1 observation. I decided to take a look at the
boot.array matrix to check how many observations where used in all
resamples, I was expecting at least 19. 

> mat2 <- boot.array(blm01)
> vec2 <- apply(mat2,2,FUN=function(x){length(x[x=="1"])})
> vec2[vec2=="1000"]
numeric(0)

This tells me that no observation was used in all resamples.

I am getting something wrong ?

Regards

EJ



From kwan022 at stat.auckland.ac.nz  Thu Sep  4 13:50:55 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Thu, 4 Sep 2003 23:50:55 +1200 (NZST)
Subject: [R] subtract 2 columns in a data.frame
In-Reply-To: <1062673905.22020.41.camel@pc-fg6>
Message-ID: <Pine.LNX.4.44.0309042350070.17286-100000@stat55.stat.auckland.ac.nz>

On 4 Sep 2003, Ulrich Leopold wrote:

> could someone point me to the right command to subtract 2 columns in a
> data.frame. Might be a bit embarrassing question. But I cannot figure
> out how to do this simple command in R.

Suppose your data frame is called foo, and you want the first column minus 
the second:
  foo[,1] - foo[,2]


-- 
Cheers,

Kevin

------------------------------------------------------------------------------
"On two occasions, I have been asked [by members of Parliament],
'Pray, Mr. Babbage, if you put into the machine wrong figures, will
the right answers come out?' I am not able to rightly apprehend the
kind of confusion of ideas that could provoke such a question."

-- Charles Babbage (1791-1871) 
---- From Computer Stupidities: http://rinkworks.com/stupid/

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)



From partha_bagchi at hgsi.com  Thu Sep  4 13:49:55 2003
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Thu, 4 Sep 2003 07:49:55 -0400
Subject: [R] help.start( )
Message-ID: <OF86F24016.5FFC78C1-ON85256D97.0040D999-85256D97.0040FF32@hgsi.com>

I think the Mozilla plugin site explicitly says that you cannot copy the 
Java plugin into the Mozilla plugin directory. You have to make a symbolic 
link to it in the plugin directory. Please try that.





Jason Turner <jasont at indigoindustrial.co.nz>
Sent by: r-help-bounces at stat.math.ethz.ch
09/03/2003 07:32 PM

 
        To:     Ming <mingliz2 at netscape.net>
        cc:     R-help at stat.math.ethz.ch
        Subject:        Re: [R] help.start( )


Ming wrote:
> Dear R experts,
>
> I installed R-1.7.1 on Linux (Red Hat 9.0) starting from R-1.7.1.tgz 
without a problem.  Then I fired up R and tried things and found that 
help.start( ) does not work.  I downloaded Sun Java j2re1.4.2, installed 
that and re-installed R-1.7.1 from scratch.  I tried help.start( ) again 
and the browser (Mozilla 1.2.1) crashed.
>
> I read about copying libjavaplugin_oji.so into mozilla/plugins and 
installed R-1.7.1 (again from scratch).  Mozilla still crashed.  Can you 
tell me how to make help.start( ) work in R-1.7.1?
>

It doesn't help much, but it works fine on my SuSE 8.2 box, using
R-1.7.1 (patched) and Mozlla 1.2.1.  I've also used Konqueror (the KDE
browser/file manager) using help.start(browser="konqueror").  Have you
tried that (or Galleon, or Opera, or ...)?

Cheers

Jason
--
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help

--
This message has been scanned for viruses and
dangerous content by MailScanner, and is
believed to be clean.



From D.R.J.Pleydell at pgr.salford.ac.uk  Thu Sep  4 14:07:55 2003
From: D.R.J.Pleydell at pgr.salford.ac.uk (David Richard John Pleydell)
Date: Thu, 04 Sep 2003 12:07:55 -0000
Subject: [R] AIC and significance tests
In-Reply-To: <200309041010.h84A1S1D025490@stat.math.ethz.ch>
Message-ID: <5.2.0.9.0.20030904125708.041e92e8@mail.salford.ac.uk>

Hi
I have two geostatistical models from geoR.  An ordinary kriging model with 
AIC=-148.6 and a universal kriging model with AIC=-156.7, there are 345 
data points.  The improvement shown by the AIC by adding a trend component 
to the model seems quite small given the number of data points, is there a 
test to see if the improvement to the model fit is significant?

Thanks
David



************************************************
David Pleydell
D 31 Peel Building
Telford Institute of Environmental Systems
School of Environment and Life Sciences
University of Salford
M5 4WT
phone: +44 161 2952094
fax:  +44 161 295 5015



From uleopold at science.uva.nl  Thu Sep  4 14:35:11 2003
From: uleopold at science.uva.nl (Ulrich Leopold)
Date: Thu, 04 Sep 2003 14:35:11 +0200
Subject: [R] subtract 2 columns in a data.frame
In-Reply-To: <x2smnchk7u.fsf@biostat.ku.dk>
References: <1062673905.22020.41.camel@pc-fg6> <x2smnchk7u.fsf@biostat.ku.dk>
Message-ID: <3F57317F.7060606@science.uva.nl>

> E.g.,
> 
> mydata$difference <- mydata$x - mydata$y
> 

That's what I thought, but I get the following message:

 > propLSK.STONE.Pox0t30$Pox0t30STONE-propLSK.STONE.Pox0t30$Pox0t30
numeric(0)

Does it mean the resulting vector is empty? If yes, what could be the reason 
for it? Both columns are available:

      UGreen    Pox0t30 Pox0t30Stone
1         0  37.150000    16.461500
2         0   6.833330     7.464404
3         0   9.750000    15.616870
4         0  15.050000    19.146500
5         0  13.266700    10.515750
6         0  34.300000    27.304840
7         0  45.800000    27.217171
8        NA  23.200000    16.844601
9         0  13.600000    28.051821
10        0  16.750000     6.021914
11        0  16.433300     3.832123
12        0  17.333300     3.905555


What am I missing?

Ulrich


-- 
__________________________________________________

Ulrich Leopold MSc.

Department of Physical Geography
Institute for Biodiversity and Ecosystem Dynamics
Faculty of Science
University of Amsterdam
Nieuwe Achtergracht 166
NL-1018WV Amsterdam

Phone:	+31 20 525 7456 (7451 Secretary)
Fax:	+31 20 525 7431
Mobile:	+31 64 220 3028
Email:	uleopold at science.uva.nl
URL:	www.science.uva.nl/ibed/research/Research_Fields/fg/stafffg/index.html



From uleopold at science.uva.nl  Thu Sep  4 14:41:41 2003
From: uleopold at science.uva.nl (Ulrich Leopold)
Date: Thu, 04 Sep 2003 14:41:41 +0200
Subject: [R] subtract 2 columns in a data.frame -- found the problem
In-Reply-To: <x2smnchk7u.fsf@biostat.ku.dk>
References: <1062673905.22020.41.camel@pc-fg6> <x2smnchk7u.fsf@biostat.ku.dk>
Message-ID: <3F573305.8080903@science.uva.nl>

Dear list,

sorry for having bothering you. I found the problem. It was the a stupid 
error made by me. R could not recognise the variable as it is of course case 
sensitive for names. So I specified the wrong variable name and R did 
complain about it with "numeric(0)".

Ulrich

Peter Dalgaard BSA wrote:
> Ulrich Leopold <uleopold at science.uva.nl> writes:
> 
> 
>>Dear list,
>>
>>could someone point me to the right command to subtract 2 columns in a
>>data.frame. Might be a bit embarrassing question. But I cannot figure
>>out how to do this simple command in R.
> 
> 
> E.g.,
> 
> mydata$difference <- mydata$x - mydata$y
> 

-- 
__________________________________________________

Ulrich Leopold MSc.

Department of Physical Geography
Institute for Biodiversity and Ecosystem Dynamics
Faculty of Science
University of Amsterdam
Nieuwe Achtergracht 166
NL-1018WV Amsterdam

Phone:	+31 20 525 7456 (7451 Secretary)
Fax:	+31 20 525 7431
Mobile:	+31 64 220 3028
Email:	uleopold at science.uva.nl
URL:	www.science.uva.nl/ibed/research/Research_Fields/fg/stafffg/index.html



From spencer.graves at pdf.com  Thu Sep  4 14:42:06 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 04 Sep 2003 05:42:06 -0700
Subject: [R] AIC and significance tests
References: <5.2.0.9.0.20030904125708.041e92e8@mail.salford.ac.uk>
Message-ID: <3F57331E.4080700@pdf.com>

	  2*log(likelihood ratio) is approximately chi-square for nested 
models.  AIC = (-2)*(log(likelihood)-k), where k = number of parameters 
in the model.

	  Thus, del(AIC) = 2*(log(likelihood ratio)-del(k)).  If the trend is 
strictly linear, then it involves only 1 parameter, so del(k) = 1.  Then 
log(likelihood ratio) = 1+0.5*(156.7-148.6) = 1+0.5*8.1 = 5.05.  From 
this, a significance probability (p value) can be obtained as follows:

 > pchisq(5.05, 1, lower.tail=FALSE)
[1] 0.02462594

	  For more information, see, e.g., Burnham and Anderson (2002) Model 
Selection and Multi-Model Inference, 2nd ed. (Springer) or Ripley (1996) 
Pattern Recognition and Neural Networks (Cambridge U. Pr.).  Also, 
www.r-project.org -> search -> "R site search" for "Burnham and Anderson".

hope this helps.  spencer graves

David Richard John Pleydell wrote:
> Hi
> I have two geostatistical models from geoR.  An ordinary kriging model 
> with AIC=-148.6 and a universal kriging model with AIC=-156.7, there are 
> 345 data points.  The improvement shown by the AIC by adding a trend 
> component to the model seems quite small given the number of data 
> points, is there a test to see if the improvement to the model fit is 
> significant?
> 
> Thanks
> David
> 
> 
> 
> ************************************************
> David Pleydell
> D 31 Peel Building
> Telford Institute of Environmental Systems
> School of Environment and Life Sciences
> University of Salford
> M5 4WT
> phone: +44 161 2952094
> fax:  +44 161 295 5015
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From p.dalgaard at biostat.ku.dk  Thu Sep  4 14:49:01 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Thu, 04 Sep 2003 12:49:01 -0000
Subject: [R] subtract 2 columns in a data.frame
In-Reply-To: <3F57317F.7060606@science.uva.nl>
References: <1062673905.22020.41.camel@pc-fg6> <x2smnchk7u.fsf@biostat.ku.dk>
	<3F57317F.7060606@science.uva.nl>
Message-ID: <x2fzjchg7p.fsf@biostat.ku.dk>

Ulrich Leopold <uleopold at science.uva.nl> writes:

> > E.g.,
> > mydata$difference <- mydata$x - mydata$y
> >
> 
> That's what I thought, but I get the following message:
> 
>  > propLSK.STONE.Pox0t30$Pox0t30STONE-propLSK.STONE.Pox0t30$Pox0t30
> numeric(0)
> 
> Does it mean the resulting vector is empty? If yes, what could be the
> reason for it? Both columns are available:
> 
>       UGreen    Pox0t30 Pox0t30Stone
> 1         0  37.150000    16.461500
> 2         0   6.833330     7.464404
> 3         0   9.750000    15.616870
> 4         0  15.050000    19.146500
> 5         0  13.266700    10.515750
> 6         0  34.300000    27.304840
> 7         0  45.800000    27.217171
> 8        NA  23.200000    16.844601
> 9         0  13.600000    28.051821
> 10        0  16.750000     6.021914
> 11        0  16.433300     3.832123
> 12        0  17.333300     3.905555
> 
> 
> What am I missing?

Case sensitivity, it seems...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From petr.pikal at precheza.cz  Thu Sep  4 14:52:12 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Thu, 04 Sep 2003 14:52:12 +0200
Subject: [R] subtract 2 columns in a data.frame
In-Reply-To: <3F57317F.7060606@science.uva.nl>
References: <x2smnchk7u.fsf@biostat.ku.dk>
Message-ID: <3F57519C.17429.15FDA95@localhost>


   Hi

   On 4 Sep 2003 at 14:35, Ulrich Leopold wrote:

   > > E.g.,

   > >

   > > mydata$difference <- mydata$x - mydata$y

   > >

   >

   > That's what I thought, but I get the following message:

   >

   >  > propLSK.STONE.Pox0t30$Pox0t30STONE-propLSK.STONE.Pox0t30$Pox0t30

   > numeric(0)

   Beware of case sensitivity

   propLSK.STONE.Pox0t30$Pox0t30stone-propLSK.STONE.Pox0t30$Pox0t30

   shall work as expected

   A little bit less complicated names of data frames and variables could
   be more readable and more error prone.

   Cheers

   Petr

   >

   > Does it mean the resulting vector is empty? If yes, what could be
   the

   > reason for it? Both columns are available:

   >

   >       UGreen    Pox0t30 Pox0t30Stone

   > 1         0  37.150000    16.461500

   > 2         0   6.833330     7.464404

   > 3         0   9.750000    15.616870

   > 4         0  15.050000    19.146500

   > 5         0  13.266700    10.515750

   > 6         0  34.300000    27.304840

   > 7         0  45.800000    27.217171

   > 8        NA  23.200000    16.844601

   > 9         0  13.600000    28.051821

   > 10        0  16.750000     6.021914

   > 11        0  16.433300     3.832123

   > 12        0  17.333300     3.905555

   >

   >

   > What am I missing?

   >

   > Ulrich

   >

   >

   > --

   > __________________________________________________

   >

   > Ulrich Leopold MSc.

   >

   > Department of Physical Geography

   > Institute for Biodiversity and Ecosystem Dynamics

   > Faculty of Science

   > University of Amsterdam

   > Nieuwe Achtergracht 166

   > NL-1018WV Amsterdam

   >

   > Phone:         +31 20 525 7456 (7451 Secretary)

   > Fax:  +31 20 525 7431

   > Mobile:        +31 64 220 3028

   > Email:          uleopold at science.uva.nl

   >
   URL:           www.science.uva.nl/ibed/research/Research_Fields/fg/sta
   fffg/index

   > .html

   >

   > ______________________________________________

   > R-help at stat.math.ethz.ch mailing list

   > https://www.stat.math.ethz.ch/mailman/listinfo/r-help

   Petr Pikal

   petr.pikal at precheza.cz


From roger at ysidro.econ.uiuc.edu  Thu Sep  4 15:24:42 2003
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Thu, 4 Sep 2003 08:24:42 -0500 (CDT)
Subject: [R] title expressions
Message-ID: <Pine.SOL.4.30.0309040810000.28208-100000@ysidro.econ.uiuc.edu>

The officially sanctioned way to put the expression "lambda_1 = x" in a title
is something like this:

	title(substitute(lambda[1] == lamb, list(lamb = x)))

but suppose I have two lambdas and would like something like

	"lambda_1 = x_1 , lambda_2 = x_2"

to appear.  What then?  Undoubtedly I'm missing something blindingly
obvious with lists, but having tried several versions unsuccessfully
I thought I would defer to the collective expertise of R-help.  Thanks
in advance.


url:	www.econ.uiuc.edu/~roger/my.html	Roger Koenker
email	rkoenker at uiuc.edu			Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820



From paul at datavore.com  Thu Sep  4 16:04:56 2003
From: paul at datavore.com (Paul Meagher)
Date: Thu, 4 Sep 2003 11:04:56 -0300
Subject: [R] Overlaying graphs
References: <200309040556.h845u0XI208492@atlas.otago.ac.nz>
Message-ID: <018501c372ed$85fa60e0$9141de18@computer>


----- Original Message ----- 
From: "Richard A. O'Keefe" <ok at cs.otago.ac.nz>
To: <paul at datavore.com>
Sent: Thursday, September 04, 2003 2:56 AM
Subject: Re: [R] Overlaying graphs


> I do not know how to overlay the curve graphic on top of hist graphic.
>
> Do you know about the "add=TRUE" option for plot()?
>
> I am hoping to show visually that the normal curve overlays the obtained
> probability distribution when plotted on the same graph.  Unfortunately, I
> an not sure how to overlay them. Can anyone point me in the right
direction
> or show me the code.
>
> This is a bad way to do it anyway.  What you want is a qqnorm plot.
> See ?qqnorm.
>
>



From paul at datavore.com  Thu Sep  4 16:10:49 2003
From: paul at datavore.com (Paul Meagher)
Date: Thu, 4 Sep 2003 11:10:49 -0300
Subject: [R] Overlaying graphs
References: <200309040556.h845u0XI208492@atlas.otago.ac.nz>
Message-ID: <018801c372ee$58e82e60$9141de18@computer>

My apologies for the last email that only contained the message and not my
reply.  Here is what I meant to send.

----- Original Message ----- 
From: "Richard A. O'Keefe" <ok at cs.otago.ac.nz>
To: <paul at datavore.com>
Sent: Thursday, September 04, 2003 2:56 AM
Subject: Re: [R] Overlaying graphs

> I do not know how to overlay the curve graphic on top of hist graphic.
>
> Do you know about the "add=TRUE" option for plot()?

I learned about it from one of the list members and it worked ok for me.
This is the recipe I finally came up with:

fat  <- read.table("fat.dat", header=TRUE)
mu   <- mean(fat$height)
sdev <- sd(fat$height)
par (fin=c(4,4))
hist(fat$height, br=20, freq=FALSE, col="lightblue",
     border="black", xlab="Male Height in Inches",
     main = paste("Histogram of" , "Male Height"))
curve(dnorm(x, mu, sdev), add=TRUE, from=64, to=78, col="red", lwd=5)

> I am hoping to show visually that the normal curve overlays the obtained
> probability distribution when plotted on the same graph.  Unfortunately, I
> an not sure how to overlay them. Can anyone point me in the right
direction
> or show me the code.
>
> This is a bad way to do it anyway.  What you want is a qqnorm plot.
> See ?qqnorm.

Yes qqnorm looks like a better tool for this particular job.  It does not
appear to be very general in the sense that you could visually inspect
whether poissson distributed data conforms to a theoretical poisson
distribution.

I guess this leads to two more questions:

1. Is the Anderson-Darling goodness-of-fit test the recommended analytic
test for determining whether a normal distribution conforms to a theoretical
normal distribution.

2. Does R have a suite of "best-fit" tools for finding the best
fitting-probability distribution for any observed probability distribution?

Regards,
Paul Meagher

>



From tlumley at u.washington.edu  Thu Sep  4 16:14:37 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 4 Sep 2003 07:14:37 -0700 (PDT)
Subject: [R] title expressions
In-Reply-To: <Pine.SOL.4.30.0309040810000.28208-100000@ysidro.econ.uiuc.edu>
Message-ID: <Pine.A41.4.44.0309040710140.131572-100000@homer34.u.washington.edu>

On Thu, 4 Sep 2003, Roger Koenker wrote:

> The officially sanctioned way to put the expression "lambda_1 = x" in a title
> is something like this:
>
> 	title(substitute(lambda[1] == lamb, list(lamb = x)))
>
> but suppose I have two lambdas and would like something like
>
> 	"lambda_1 = x_1 , lambda_2 = x_2"
>

Assuming x_1 and x_2 mean two values, not subscripted values

   title(substitute(lambda[1]==x1*", "*lambda[2]==x2, list(x1=x1,x2=x2)))

In 1.8 you will be able to do

   title(bquote(lambda[1]==.(x1)*", "*lambda[2]==.(x2)))


	-thomas



From pri at chu.com.au  Thu Sep  4 16:21:07 2003
From: pri at chu.com.au (Philip Rhoades)
Date: Fri, 5 Sep 2003 00:21:07 +1000
Subject: [R] Allelic Differentiation, sampling, unique(), duplicated()
Message-ID: <20030904142107.GA28841@phil>

Hi people,

I have made some progress trying to work out how to solve this problem  
but I have got a bit stuck - sorry if this turns out to be a simple  
exercise . .

Allelic Differentiation (AD) in genetics measures the number of  
different alleles between (say) two populations eg:

Organisms in Pop 1 have alleles: a, b, c, d, e

Organisms in Pop 2 have alleles: b, b, c, d, e

Different (unique) alleles (n) are: a

[unique() does not do what I want here for comparing these two vectors  
and I can't get combinations of unique() and duplicated() to work  
either.]

Total alleles = 10

Therefore AD = (2 * n) / 10 = 0.2

What I want to do is compare two populations of 200 organisms each but  
sampling for only 20 at a time.

So there are 200!/((200-20)! * 20!) possible combinations of samples in  
each population.

For all possible combinations of sample pop1 and sample pop2 I want to  
measure AD ie (200!/((200-20)! * 20!) * 200!/((200-20)! * 20!) )  
calculations.

As well as the unique allele problem, can someone suggest how I can do  
the sampling loops?

Thanks,

Phil.
--
Philip Rhoades

Pricom Pty Limited  (ACN 003 252 275  ABN 91 003 252 275)
GPO Box 3411
Sydney NSW	2001
Australia
Mobile:  +61:0411-185-652
Fax:  +61:2:8923-5363
E-mail:  pri at chu.com.au



From mailinglist.wegmann at gmx.net  Thu Sep  4 18:20:52 2003
From: mailinglist.wegmann at gmx.net (Martin Wegmann)
Date: Thu, 4 Sep 2003 16:20:52 +0000
Subject: [R] error in lm.fit
Message-ID: <200309041620.52218.mailinglist.wegmann@gmx.net>

Hello R user, 

I have several data frames with >100 columns and I did a linear regression 
over time of each column

df1.lm <- lapply(df1, function(x) lm(x~year)$coeff[2])

that worked fine and I get slope of each column oder time - until I divided 
df1 by df2 

df3 <- df1/df2

> df3.lm <- lapply(df3, function(x) lm(x~year)$coeff[2])
Error in lm.fit(x, y, offset = offset, ...) :
        0 (non-NA) cases

df3 has cases:
      X106      X107      X108
1  -2.200986 -2.128744 -2.126991
2  -2.201284 -2.179806 -1.998352
3  -2.201589 -2.051754 -1.918321
4  -2.207428 -2.024579 -2.160275
5  -2.088381 -2.084716 -2.033241
6  -2.313741 -1.905484 -2.024190
7  -2.232551 -2.118113 -2.123781
8  -2.096430 -1.787569 -2.309956
9  -2.029564 -1.650830 -2.038038
10 -1.805616 -1.936357 -1.827615
11 -2.427711 -2.260115 -2.192925
12 -2.255148 -1.624925 -2.075030
13 -2.040811 -1.928457 -1.985597
14 -2.131254 -2.126999 -2.079338
15 -2.407123 -2.193653 -2.162101
16 -2.024426 -2.168195 -2.078530
17 -2.224164 -1.853840 -2.150593
18 -2.067553 -2.140541 -1.907311
19 -2.142151 -2.176615 -2.015018
20 -2.125215 -2.051265 -1.848539

I did it with df1 and df2, both worked, the only difference I recognized so 
far were the negative values and the amount of decimal places, therefore I 
added 10 and multiplied it with 1000000 but both approaches didn't work. 

any idea what I might have done wrong?

(using R 1.7.0  Linux)

thanks, Martin



From jrogers at cantatapharm.com  Thu Sep  4 16:22:27 2003
From: jrogers at cantatapharm.com (Jim Rogers)
Date: Thu, 4 Sep 2003 10:22:27 -0400
Subject: [R] SNK-test
Message-ID: <99A12772DCDEEB458B996332957B0D53011844@mercury.cantatapharm.com>

Please note Student-Newman-Keuls is NOT a recommended multiple comparison procedure.

In the language of Hsu (1996), Student-Newman-Keuls is not even a "confident inequalities" method. In other words, it does not control the probability of making at least one incorrect assertion of inequality (which is the least you should expect of any multiple comparisons procedure). 

Tukey's HSD does protect the desired error rate, and gives you confidence intervals as well (not just assertions of inequality). 

Reference:

Hsu (1996). Multiple Comparisons, Theory and Methods. Chapman Hall.

J?rg Peter Baresel wrote:
>  How can I perform a Student-Newman-Keuls-Test for multiple 
> comparision of means in R? (I did not manage to find any specific 
> function in the libraries)
> 
> 
> J?rg Peter Baresel
> Technische Universit?t M?nchen
> Institut f?r Ackerbau und INformatik im Pflanzenbau
> D-85354 Freising
> Lange Point 51
> 

James A. Rogers, Ph.D. <rogers at cantatapharm.com>
Statistical Scientist
Cantata Pharmaceuticals
300 Technology Square, 5th floor
Cambridge, MA  02139
617.225.9009 x312
Fax 617.225.9010



From ahmlatif at yahoo.com  Thu Sep  4 16:26:54 2003
From: ahmlatif at yahoo.com (Mahbub Latif)
Date: Thu, 4 Sep 2003 07:26:54 -0700 (PDT)
Subject: [R] lattice question--- different ylim 
Message-ID: <20030904142654.14518.qmail@web41201.mail.yahoo.com>

Hi there,

I have four panels in a lattice bwplot. I want to have
two different ylim for the panels, for example panels
[1,1] and [1,2] with ylim=c(0,200) and panels [2,1]
and [2,2] with ylim=c(0,100). 

Thanks for help in advance.

Mahbub.



From llaghi at foodsci.unibo.it  Thu Sep  4 16:31:21 2003
From: llaghi at foodsci.unibo.it (Luca Laghi)
Date: Thu, 4 Sep 2003 16:31:21 +0200 (CEST)
Subject: [R] laplace transform
In-Reply-To: <mailman.31.1062685094.6569.r-help@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.21.0309041628180.4232-100000@carbon>

Dear users,
is anybody of you aware of a R command to perform laplace transform or
even its inversion?
Thank you very much.
Luca



From spencer.graves at pdf.com  Thu Sep  4 16:34:27 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 04 Sep 2003 07:34:27 -0700
Subject: [R] Overlaying graphs
References: <200309040556.h845u0XI208492@atlas.otago.ac.nz>
	<018801c372ee$58e82e60$9141de18@computer>
Message-ID: <3F574D73.3000607@pdf.com>

	  Your observation that qqnorm "does not appear to be very general" is 
rebutted by Venables and Ripley (2002) Modern Applied Statistics with S, 
4th ed. (Springer, p.108):  "One of the best ways to compare the 
distribution of a sample x with a distribution is to use a Q-Q plot. ... 
This idea can be applied quite generally.  For example, to test a sample 
against a t9 distribution, we might use

	  plot( qt(ppoints(x), 9), sort(x) )

	  Before I consider the "best-fitting probability distribution", I want 
to know something about the nature of the application and what the 
numbers claim to represent:  If they are discrete counts, I will not 
even consider a normal distribution except as an approximation.  If they 
are money or physical measurements like power or grams in applications 
where they should never be negative, then I may want to take logarithms 
first before I do anything else.  If lifetime data, I will consider 
lognormal and Weibull, and prepare a cumulative hazard plot before doing 
much else.  If a normal probability plot shows skewness, I will look for 
another distribution or a transformation that makes sense with the 
application.  If it shows discontinuities, I will consider mixtures.  By 
the time you start considering mixtures, the number of alternative 
distributional models becomes infinite.

hope this helps.  spencer graves

Paul Meagher wrote:
> My apologies for the last email that only contained the message and not my
> reply.  Here is what I meant to send.
> 
> ----- Original Message ----- 
> From: "Richard A. O'Keefe" <ok at cs.otago.ac.nz>
> To: <paul at datavore.com>
> Sent: Thursday, September 04, 2003 2:56 AM
> Subject: Re: [R] Overlaying graphs
> 
> 
>>I do not know how to overlay the curve graphic on top of hist graphic.
>>
>>Do you know about the "add=TRUE" option for plot()?
> 
> 
> I learned about it from one of the list members and it worked ok for me.
> This is the recipe I finally came up with:
> 
> fat  <- read.table("fat.dat", header=TRUE)
> mu   <- mean(fat$height)
> sdev <- sd(fat$height)
> par (fin=c(4,4))
> hist(fat$height, br=20, freq=FALSE, col="lightblue",
>      border="black", xlab="Male Height in Inches",
>      main = paste("Histogram of" , "Male Height"))
> curve(dnorm(x, mu, sdev), add=TRUE, from=64, to=78, col="red", lwd=5)
> 
> 
>>I am hoping to show visually that the normal curve overlays the obtained
>>probability distribution when plotted on the same graph.  Unfortunately, I
>>an not sure how to overlay them. Can anyone point me in the right
> 
> direction
> 
>>or show me the code.
>>
>>This is a bad way to do it anyway.  What you want is a qqnorm plot.
>>See ?qqnorm.
> 
> 
> Yes qqnorm looks like a better tool for this particular job.  It does not
> appear to be very general in the sense that you could visually inspect
> whether poissson distributed data conforms to a theoretical poisson
> distribution.
> 
> I guess this leads to two more questions:
> 
> 1. Is the Anderson-Darling goodness-of-fit test the recommended analytic
> test for determining whether a normal distribution conforms to a theoretical
> normal distribution.
> 
> 2. Does R have a suite of "best-fit" tools for finding the best
> fitting-probability distribution for any observed probability distribution?
> 
> Regards,
> Paul Meagher
> 
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From djw1005 at cam.ac.uk  Thu Sep  4 16:55:02 2003
From: djw1005 at cam.ac.uk (Damon Wischik)
Date: Thu, 4 Sep 2003 15:55:02 +0100 (BST)
Subject: [R] Overlaying graphs
In-Reply-To: <018801c372ee$58e82e60$9141de18@computer>
Message-ID: <Pine.SOL.3.96.1030904155009.27672A-100000@libra.cus.cam.ac.uk>


Paul Meagher wrote:
> 2. Does R have a suite of "best-fit" tools for finding the best
> fitting-probability distribution for any observed probability distribution?

I think that the best-fitting probability distribution for an observed
probability distribution is the empirical distribution of your
observations. 

(Perhaps you have some other criteria than just goodness of fit?)

Damon.



From mailinglist.wegmann at gmx.net  Thu Sep  4 19:01:09 2003
From: mailinglist.wegmann at gmx.net (Martin Wegmann)
Date: Thu, 4 Sep 2003 17:01:09 +0000
Subject: [R] error in lm.fit - solved
In-Reply-To: <200309041620.52218.mailinglist.wegmann@gmx.net>
References: <200309041620.52218.mailinglist.wegmann@gmx.net>
Message-ID: <200309041701.09018.mailinglist.wegmann@gmx.net>

Hi, 

I found the problem, now it is working fine. cheers Martin


On Thursday 04 September 2003 16:20, Martin Wegmann wrote:
> Hello R user,
>
> I have several data frames with >100 columns and I did a linear regression
> over time of each column
>
> df1.lm <- lapply(df1, function(x) lm(x~year)$coeff[2])
>
> that worked fine and I get slope of each column oder time - until I divided
> df1 by df2
>
> df3 <- df1/df2
>
> > df3.lm <- lapply(df3, function(x) lm(x~year)$coeff[2])
>
> Error in lm.fit(x, y, offset = offset, ...) :
>         0 (non-NA) cases
>
> df3 has cases:
>       X106      X107      X108
> 1  -2.200986 -2.128744 -2.126991
> 2  -2.201284 -2.179806 -1.998352
> 3  -2.201589 -2.051754 -1.918321
> 4  -2.207428 -2.024579 -2.160275
> 5  -2.088381 -2.084716 -2.033241
> 6  -2.313741 -1.905484 -2.024190
> 7  -2.232551 -2.118113 -2.123781
> 8  -2.096430 -1.787569 -2.309956
> 9  -2.029564 -1.650830 -2.038038
> 10 -1.805616 -1.936357 -1.827615
> 11 -2.427711 -2.260115 -2.192925
> 12 -2.255148 -1.624925 -2.075030
> 13 -2.040811 -1.928457 -1.985597
> 14 -2.131254 -2.126999 -2.079338
> 15 -2.407123 -2.193653 -2.162101
> 16 -2.024426 -2.168195 -2.078530
> 17 -2.224164 -1.853840 -2.150593
> 18 -2.067553 -2.140541 -1.907311
> 19 -2.142151 -2.176615 -2.015018
> 20 -2.125215 -2.051265 -1.848539
>
> I did it with df1 and df2, both worked, the only difference I recognized so
> far were the negative values and the amount of decimal places, therefore I
> added 10 and multiplied it with 1000000 but both approaches didn't work.
>
> any idea what I might have done wrong?
>
> (using R 1.7.0  Linux)
>
> thanks, Martin
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Thu Sep  4 17:05:52 2003
From: ripley at stats.ox.ac.uk (Brian D Ripley)
Date: Thu, 4 Sep 2003 16:05:52 +0100 (BST)
Subject: [R] How to avoid automatic coercion to factor?
In-Reply-To: <16214.5963.79252.407104@arbres1a.fmr.com>
References: <Pine.LNX.4.44.0309030544350.26990-100000@gannet.stats>
	<16214.5963.79252.407104@arbres1a.fmr.com>
Message-ID: <1138.147.162.216.107.1062687952.squirrel@webmail.stats.ox.ac.uk>

Yes, that is one scenario and for that we need a better class
(possibly a better data.frame class).

But there are other scenarios for which a special class for the
column is better.  Which is why I asked.

> Steve Dutky <steve.dutky at thomson.com> wrote:
>> I have a function that manipulates a list of numeric and character
>> components of equal length and wants to return a data.frame.
>> ...
>> How can I get the columns Char1, Char2, (...CharN) returned coerced to
>> character and not factor?
>
> Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>> ... We should ask why you want character columns in a data frame?...
>
> I think Steve's situation is very common.  It points up a long-standing
> gap in the S language, namely a class of objects for tabular data that
> is less restrictive than data.frame or matrix.  Data frames are really
> designed for statistics (thus their inclination towards factors and
> valid column names), while matrices can only handle a single mode of
> data (numeric or character).
>
> In my own world, I've "implemented" this "class" as lists of
> equal-length vectors, and built many tools for it that mirror
> read.table, write.table, merge, cbind, rbind, etc.  Except that I've
> done it sloppily, without using real classes or
> constructors/validators/methods.
>
> It would be nice to have a real class "table" (maybe data.frame would
> extend it?).  But no, I'm not volunteering to build it. :-/
> --
>                               -- David Brahm (brahm at alum.mit.edu)


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tlumley at u.washington.edu  Thu Sep  4 17:09:59 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 4 Sep 2003 08:09:59 -0700 (PDT)
Subject: [R] Allelic Differentiation, sampling, unique(), duplicated()
In-Reply-To: <20030904142107.GA28841@phil>
Message-ID: <Pine.A41.4.44.0309040801470.61662-100000@homer37.u.washington.edu>

On Fri, 5 Sep 2003, Philip Rhoades wrote:

> Hi people,
>
> I have made some progress trying to work out how to solve this problem
> but I have got a bit stuck - sorry if this turns out to be a simple
> exercise . .
>
> Allelic Differentiation (AD) in genetics measures the number of
> different alleles between (say) two populations eg:
>
> Organisms in Pop 1 have alleles: a, b, c, d, e
>
> Organisms in Pop 2 have alleles: b, b, c, d, e
>
> Different (unique) alleles (n) are: a
>
> [unique() does not do what I want here for comparing these two vectors
> and I can't get combinations of unique() and duplicated() to work
> either.]

YOu could do it with

union(setdiff(one,two), setdiff(two,one))

and there's probably a direct way to do it with match().  We should
probably have a setsymdiff() function to add to the others.


> Total alleles = 10
>
> Therefore AD = (2 * n) / 10 = 0.2
>
> What I want to do is compare two populations of 200 organisms each but
> sampling for only 20 at a time.
>
> So there are 200!/((200-20)! * 20!) possible combinations of samples in
> each population.
>
> For all possible combinations of sample pop1 and sample pop2 I want to
> measure AD ie (200!/((200-20)! * 20!) * 200!/((200-20)! * 20!) )
> calculations.

This is far too many calculations
R> choose(200,20)
[1] 1.613588e+27


> As well as the unique allele problem, can someone suggest how I can do
> the sampling loops?
>

You can't. 10^27 is a very large number.

I would suggest choosing pop1 and pop2 at random, a few thousand or
hundred thousand times (depending on the accuracy you need).


	-thomas



From JonesW at kssg.com  Thu Sep  4 17:10:12 2003
From: JonesW at kssg.com (Wayne Jones)
Date: Thu, 4 Sep 2003 16:10:12 +0100 
Subject: [R]: RODBC column length>255
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB021F0E42@gimli.middleearth.kssg.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030904/8761900e/attachment.pl

From bido at mac.com  Thu Sep  4 17:23:51 2003
From: bido at mac.com (Francisco J. Bido)
Date: Thu, 4 Sep 2003 10:23:51 -0500
Subject: [R] Looking for R Equivalent of Gauss Statements
In-Reply-To: <3F56EBD6.9030900@gmx.de>
Message-ID: <C9F6896A-DEEB-11D7-AD7D-000393B90A0A@mac.com>

Thanks Marlene, that's exactly what I was hoping for.

Best,
-Francisco


On Thursday, September 4, 2003, at 02:37 AM, Marlene Mueller wrote:

>
> R is very similar to Gauss for this kind of task.
> Try:
>
>   e1 <- x[,23] == 0
>   e2 <- x[,12] > 1
>   e3 <- x[,4] < 15
>   e  <- e1 | e2 | e3   # e1 or e2 or e3
>   x  <- x[!e,]         # keep if NOT e
>
> Hope that helps,
> Marlene
>
>
>
> Francisco J. Bido wrote:
>> Hi,
>> I am translating some Gauss code to R.  Gauss has an interesting way 
>> of handling constraints.  Observe the following code snipplet:
>> e1 = x[.,23] .eq 0;  @ remove obs with Regular Hours = 0 @
>> e2 = x[.,12] .gt 1;   @ remove obs with non-regular work status @
>> e3 = x[.,4] .lt 15;    @ remove obs with agricultural and mining 
>> industry code (< 15)@
>> esum = e1 + e2 + e3;
>> e = esum .gt 0;      @ remove obs that fail all three of the above 
>> tests @
>> x = delif(x,e);
>> I'm hoping that the above is self explanatory.    Currently I am 
>> using the  "subset" command in R to compute e1, e2, e3 but the rest 
>> is tricky: the actual code has several additional constraints and I'm 
>> ending up with some very ugly buggy code.   Is there a 
>> straightforward way to do this in R?
>> Thanks,
>> -Francisco
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
> -- 
> PD Dr. Marlene M?ller
> Fraunhofer ITWM Kaiserslautern, Abt. Finanzmathematik
> mailto:Marlene.Mueller at itwm.fraunhofer.de, Tel/Fax: +49 631 205 
> 4189/4139
> http://www.itwm.fhg.de/index.php?abt=fm/employees/mueller&inc=mueller
>



From HADASSA.BRUNSCHWIG at Roche.COM  Thu Sep  4 17:37:46 2003
From: HADASSA.BRUNSCHWIG at Roche.COM (Brunschwig, Hadassa {PDMM~Basel})
Date: Thu, 04 Sep 2003 17:37:46 +0200
Subject: [R] Dos() Command for R
Message-ID: <BC6A439CD6835749A9C7B8D8F041DFA88B11B2@rbamsem1.emea.roche.com>


Hello R-people

Is there an equivalent in R for the dos() command in S?

We are trying to write a function which will initiate the Metropolis algorithm run with BUGS. That means we have a file containing the commands for BUGS which we usually type in manually in the command prompt to run BUGS. It is also possible to run this list of commands by typing in backbugs (name of file with list of commands).cmd in the command prompt, this however is exactly what we try to automatise. We basically need a command in R which calls on the command prompt and executes backbugs ... there. We played with the function system() but still werent able to find out how this could work.

Thanks in advance for any comments.

Dassy



From paul at datavore.com  Thu Sep  4 17:45:50 2003
From: paul at datavore.com (Paul Meagher)
Date: Thu, 4 Sep 2003 12:45:50 -0300
Subject: [R] Overlaying graphs
References: <200309040556.h845u0XI208492@atlas.otago.ac.nz>
	<018801c372ee$58e82e60$9141de18@computer>
	<3F574D73.3000607@pdf.com>
Message-ID: <01a401c372fb$9eb49b60$9141de18@computer>

From: "Spencer Graves" <spencer.graves at PDF.COM>

>   Your observation that qqnorm "does not appear to be very general" is
> rebutted by Venables and Ripley (2002) Modern Applied Statistics with S,
> 4th ed. (Springer, p.108):  "One of the best ways to compare the
> distribution of a sample x with a distribution is to use a Q-Q plot. ...
> This idea can be applied quite generally.  For example, to test a sample
> against a t9 distribution, we might use
>
>   plot( qt(ppoints(x), 9), sort(x) )

Thanks for enlightening me on this issue.  I will look into the generaltiy
of the Q-Q plot further.  I only have a copy of MASS(1994) available.

>   Before I consider the "best-fitting probability distribution", I want
> to know something about the nature of the application and what the
> numbers claim to represent:  { lots of useful rules-of-thumb snipped }

As I am sure you are aware it is possible to buy canned software that is
supposed to find the best fitting theoretical distribution for your data.
My sense is that the "R Way", if there is one,  is to advocate a mixture of
exploratory data analysis, knowledge about the random variable being
studied, and various statistical tests to confirm hypothesis generated from
EDA and prior knowledge.   My hidden agenda was really to find out if people
on this list think that you can "can" the process of finding the best
fitting theoretical distribution for your data, and if so, what that
"canned" process consists of.

My limited experience with seeing Palisade's best-fit software was that it
suggested a gamma distribution as the best fit.  I thought that this
probabily isn't that helpful because the gamma distribution has so many
parameters that it would likely show up at the top of the list of best
candidates in most cases.  It probably is useful, however, to have a tool
that will generate estimates of your distribution parameters and do some
perfunctory goodness-of-fit testing to rule out certain probability
distributions as candidates.

Regards,
Paul Meagher

> hope this helps.  spencer graves
>
> Paul Meagher wrote:
> > My apologies for the last email that only contained the message and not
my
> > reply.  Here is what I meant to send.
> >
> > ----- Original Message ----- 
> > From: "Richard A. O'Keefe" <ok at cs.otago.ac.nz>
> > To: <paul at datavore.com>
> > Sent: Thursday, September 04, 2003 2:56 AM
> > Subject: Re: [R] Overlaying graphs
> >
> >
> >>I do not know how to overlay the curve graphic on top of hist graphic.
> >>
> >>Do you know about the "add=TRUE" option for plot()?
> >
> >
> > I learned about it from one of the list members and it worked ok for me.
> > This is the recipe I finally came up with:
> >
> > fat  <- read.table("fat.dat", header=TRUE)
> > mu   <- mean(fat$height)
> > sdev <- sd(fat$height)
> > par (fin=c(4,4))
> > hist(fat$height, br=20, freq=FALSE, col="lightblue",
> >      border="black", xlab="Male Height in Inches",
> >      main = paste("Histogram of" , "Male Height"))
> > curve(dnorm(x, mu, sdev), add=TRUE, from=64, to=78, col="red", lwd=5)
> >
> >
> >>I am hoping to show visually that the normal curve overlays the obtained
> >>probability distribution when plotted on the same graph.  Unfortunately,
I
> >>an not sure how to overlay them. Can anyone point me in the right
> >
> > direction
> >
> >>or show me the code.
> >>
> >>This is a bad way to do it anyway.  What you want is a qqnorm plot.
> >>See ?qqnorm.
> >
> >
> > Yes qqnorm looks like a better tool for this particular job.  It does
not
> > appear to be very general in the sense that you could visually inspect
> > whether poissson distributed data conforms to a theoretical poisson
> > distribution.
> >
> > I guess this leads to two more questions:
> >
> > 1. Is the Anderson-Darling goodness-of-fit test the recommended analytic
> > test for determining whether a normal distribution conforms to a
theoretical
> > normal distribution.
> >
> > 2. Does R have a suite of "best-fit" tools for finding the best
> > fitting-probability distribution for any observed probability
distribution?
> >
> > Regards,
> > Paul Meagher
> >
> >
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
>



From solares at unsl.edu.ar  Thu Sep  4 17:45:37 2003
From: solares at unsl.edu.ar (solares@unsl.edu.ar)
Date: Thu, 4 Sep 2003 12:45:37 -0300 (ART)
Subject: [R] R command
Message-ID: <53791.170.210.173.216.1062690337.squirrel@inter14.unsl.edu.ar>

Hi, ?How i cant exexute a script in R without the environment of R?, my
script uses the package tcltk, i like view only the interface without tehe 
environment of R 1.7.1
Ej

name script---> probe.R

tt<-tktoplevel()
but<-tkbutton()

and execute in win (icon or line command) probe.R and see the interface?
Thanks for all. Ruben



From maechler at stat.math.ethz.ch  Thu Sep  4 17:48:18 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 4 Sep 2003 17:48:18 +0200
Subject: [R] subtract 2 columns in a data.frame -- found the problem
In-Reply-To: <3F573305.8080903@science.uva.nl>
References: <1062673905.22020.41.camel@pc-fg6> <x2smnchk7u.fsf@biostat.ku.dk>
	<3F573305.8080903@science.uva.nl>
Message-ID: <16215.24258.102669.714013@gargle.gargle.HOWL>

>>>>> "Ulrich" == Ulrich Leopold <uleopold at science.uva.nl>
>>>>>     on Thu, 04 Sep 2003 14:41:41 +0200 writes:

    Ulrich> Dear list, sorry for having bothering you. I found
    Ulrich> the problem. It was the a stupid error made by me. R
    Ulrich> could not recognise the variable as it is of course
    Ulrich> case sensitive for names. So I specified the wrong
    Ulrich> variable name and R did complain about it with
    Ulrich> "numeric(0)".

    Ulrich> Ulrich

Exactly for reasons like these, S language teachers (not all AFAIK) have
recommended to use the slightly more cumbersome

 x[,"<varname>"]  instead of
 x $ <varname>

for things like these: 
With the [,".."] form, you immediately get an (intelligible)
error message when you mistype the variable name.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



    Ulrich> Peter Dalgaard BSA wrote:
    >> Ulrich Leopold <uleopold at science.uva.nl> writes:
    >> 
    >> 
    >>> Dear list,
    >>> 
    >>> could someone point me to the right command to subtract
    >>> 2 columns in a data.frame. Might be a bit embarrassing
    >>> question. But I cannot figure out how to do this simple
    >>> command in R.
    >> 
    >> 
    >> E.g.,
    >> 
    >> mydata$difference <- mydata$x - mydata$y
    >>



From mtolvieira at msn.com  Thu Sep  4 17:56:03 2003
From: mtolvieira at msn.com (Marcel Vieira)
Date: Thu, 04 Sep 2003 16:56:03 +0100
Subject: [R] function is too long to keep source
Message-ID: <BAY5-F30H8ZJaQPmRfQ00035eaf@hotmail.com>

Dear R users,

I am trying to minimise a function using "nlm".

I am getting the following error message: "Error: function is too long to 
keep source"

The function is really very long (about 100 A4 pages).

Is there anything I could do to solve this problem?

At the moment I am using "nlmin" in S-Plus with no problems but I'd prefer 
to use R.

Thank you very much in advance.

Regards.
Marcel

Marcel Vieira
Social Statistics
University of Southampton



From rbonk at host.sk  Fri Sep  5 00:21:51 2003
From: rbonk at host.sk (Rado Bonk)
Date: Thu, 04 Sep 2003 18:21:51 -0400
Subject: [R] documents for writing functions
Message-ID: <1062712607.18329.143.camel@templar.fns.uniba.sk>

Hi,

Does anybody know suitable documents (manuals) on writing user functions
(covering loops, conditions ...) in R? Other than the usually available
manuals.

Thanks,

Rado


-- 
Radoslav Bonk M.S.
Dept. of Physical Geography and Geoecology
Faculty of Sciences, Comenius University
Mlynska Dolina 842 15, Bratislava, SLOVAKIA
tel: +421 905 968 127 e-mail: rbonk at host.sk



From spencer.graves at pdf.com  Thu Sep  4 18:19:34 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 04 Sep 2003 09:19:34 -0700
Subject: [R] function is too long to keep source
References: <BAY5-F30H8ZJaQPmRfQ00035eaf@hotmail.com>
Message-ID: <3F576616.7040104@pdf.com>

	  Have you considered "optim" in library(MASS)?  "optim" will 
optionally output the hessian, which can be used to obtain confidence 
intervals in many cases.

hope this helps.  spencer graves

Marcel Vieira wrote:
> Dear R users,
> 
> I am trying to minimise a function using "nlm".
> 
> I am getting the following error message: "Error: function is too long 
> to keep source"
> 
> The function is really very long (about 100 A4 pages).
> 
> Is there anything I could do to solve this problem?
> 
> At the moment I am using "nlmin" in S-Plus with no problems but I'd 
> prefer to use R.
> 
> Thank you very much in advance.
> 
> Regards.
> Marcel
> 
> Marcel Vieira
> Social Statistics
> University of Southampton
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From spencer.graves at pdf.com  Thu Sep  4 18:21:46 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 04 Sep 2003 09:21:46 -0700
Subject: [R] documents for writing functions
References: <1062712607.18329.143.camel@templar.fns.uniba.sk>
Message-ID: <3F57669A.2050107@pdf.com>

Have you considered the two books by Venables and Ripley (2002) Modern 
Applied Statistics in S and (2000) S Programming (both Springer)?  If 
yes, I don't know what you mean by "the usually available manuals."

hope this helps.

Rado Bonk wrote:
> Hi,
> 
> Does anybody know suitable documents (manuals) on writing user functions
> (covering loops, conditions ...) in R? Other than the usually available
> manuals.
> 
> Thanks,
> 
> Rado
> 
>



From mtolvieira at msn.com  Thu Sep  4 18:35:21 2003
From: mtolvieira at msn.com (Marcel Vieira)
Date: Thu, 04 Sep 2003 17:35:21 +0100
Subject: [R] function is too long to keep source
Message-ID: <BAY5-F13bX0PyAv1YQc00054747@hotmail.com>

Thanks a lot for your help.

But I am getting that error message when I am trying to
load my function. Then I can't use anything to minimise it.

Is there anything I can do to increase R's
capacity for loading very long functions?

Many thanks.
Marcel


>Have you considered "optim" in library(MASS)?  "optim" will optionally 
>output the hessian, which can be used to obtain confidence intervals in 
>many cases.
>
>hope this helps.  spencer graves
>
>Marcel Vieira wrote:
>>Dear R users,
>>
>>I am trying to minimise a function using "nlm".
>>
>>I am getting the following error message: "Error: function is too long to 
>>keep source"
>>
>>The function is really very long (about 100 A4 pages).
>>
>>Is there anything I could do to solve this problem?
>>
>>At the moment I am using "nlmin" in S-Plus with no problems but I'd prefer 
>>to use R.
>>
>>Thank you very much in advance.
>>
>>Regards.
>>Marcel
>>
>>Marcel Vieira
>>Social Statistics
>>University of Southampton
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>

Marcel Vieira
Social Statistics
University of Southampton



From edd at debian.org  Thu Sep  4 18:39:35 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 4 Sep 2003 11:39:35 -0500
Subject: [R]: RODBC column length>255
In-Reply-To: <6B5A9304046AD411BD0200508BDFB6CB021F0E42@gimli.middleearth.kssg.com>
References: <6B5A9304046AD411BD0200508BDFB6CB021F0E42@gimli.middleearth.kssg.com>
Message-ID: <20030904163935.GA22988@sonny.eddelbuettel.com>

On Thu, Sep 04, 2003 at 04:10:12PM +0100, Wayne Jones wrote:
> I am using the RODBC functionality to query a database. I am trying to read
> in a columns of strings which have a character field lengths greater than
> 255. 
> The data.frame that I recieve back from the RODBC query only contains the
> first 255 characters (the rest having been truncated). 
> 
> Any help on how to solve this problem would be greatly appreciated.

You may get lucky by simply upgrading your RODBC package. I had the same
problem, wrote a crude patch, sent it to Brian Ripley who then replaced it
with something much better. As usual :)

That was around RODBC_1.0-1, current is 1.0-4. Give it a try. Works for me
with text of up to 8 or 9k stored in a single column.

Hth, Dirk

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From edd at debian.org  Thu Sep  4 18:41:38 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 4 Sep 2003 11:41:38 -0500
Subject: [R] Dos() Command for R
In-Reply-To: <BC6A439CD6835749A9C7B8D8F041DFA88B11B2@rbamsem1.emea.roche.com>
References: <BC6A439CD6835749A9C7B8D8F041DFA88B11B2@rbamsem1.emea.roche.com>
Message-ID: <20030904164138.GB22988@sonny.eddelbuettel.com>

On Thu, Sep 04, 2003 at 05:37:46PM +0200, Brunschwig, Hadassa {PDMM~Basel} wrote:
> Is there an equivalent in R for the dos() command in S?

help(system)

Hth, Dirk

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From spencer.graves at pdf.com  Thu Sep  4 18:52:48 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 04 Sep 2003 09:52:48 -0700
Subject: [R] function is too long to keep source
References: <BAY5-F13bX0PyAv1YQc00054747@hotmail.com>
Message-ID: <3F576DE0.80506@pdf.com>

	  I have a personal rule that any function I write that is longer than 
about one page should be modularized.  This rule pushes me to think 
carefully about how to structure the problem.  It also helps me debug my 
code and modify it as appropriate.  If I can develop appropriate 
"primatives", I get modules that I might be able to use in other 
applications.

	  This doesn't help with your immediate problem, but it might in the 
longer term.

spencer graves


Marcel Vieira wrote:
> Thanks a lot for your help.
> 
> But I am getting that error message when I am trying to
> load my function. Then I can't use anything to minimise it.
> 
> Is there anything I can do to increase R's
> capacity for loading very long functions?
> 
> Many thanks.
> Marcel
> 
> 
>> Have you considered "optim" in library(MASS)?  "optim" will optionally 
>> output the hessian, which can be used to obtain confidence intervals 
>> in many cases.
>>
>> hope this helps.  spencer graves
>>
>> Marcel Vieira wrote:
>>
>>> Dear R users,
>>>
>>> I am trying to minimise a function using "nlm".
>>>
>>> I am getting the following error message: "Error: function is too 
>>> long to keep source"
>>>
>>> The function is really very long (about 100 A4 pages).
>>>
>>> Is there anything I could do to solve this problem?
>>>
>>> At the moment I am using "nlmin" in S-Plus with no problems but I'd 
>>> prefer to use R.
>>>
>>> Thank you very much in advance.
>>>
>>> Regards.
>>> Marcel
>>>
>>> Marcel Vieira
>>> Social Statistics
>>> University of Southampton
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
>>
>>
> 
> Marcel Vieira
> Social Statistics
> University of Southampton
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Ted.Harding at nessie.mcc.ac.uk  Thu Sep  4 18:47:39 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Thu, 04 Sep 2003 17:47:39 +0100 (BST)
Subject: [R] Putting regression lines on SPLOM
Message-ID: <XFMail.030904174739.Ted.Harding@nessie.mcc.ac.uk>

Sorry Folks,
I'm sure I could suss out the answer myself but I need it
soon ... !

1. Given a set of 4 variables X,Y,Z,W in a dataframe DF, I make
   a scatter-plot matrix using splom(DF).

2. I do all regressions of U on V using lm(U~V), where U and V
   are all 12 different ordered pairs from X,Y,Z,W.

3. Now I would like to superpose the regression lines from (2)
   onto the corresponding panels from (1).

(By the way, the data used for the regressions are not quite
 the same as those used for the plots, since a few observations
 are omitted from the regressions but appear on  the plots,
 so (1) and (2) really are separate operations).

With thanks,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 04-Sep-03                                       Time: 17:47:39
------------------------------ XFMail ------------------------------



From B.Rowlingson at lancaster.ac.uk  Thu Sep  4 18:56:56 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 04 Sep 2003 17:56:56 +0100
Subject: [R] function is too long to keep source
In-Reply-To: <BAY5-F13bX0PyAv1YQc00054747@hotmail.com>
References: <BAY5-F13bX0PyAv1YQc00054747@hotmail.com>
Message-ID: <3F576ED8.8010301@lancaster.ac.uk>

Marcel Vieira wrote:
> Thanks a lot for your help.
> 
> But I am getting that error message when I am trying to
> load my function. Then I can't use anything to minimise it.
> 
> Is there anything I can do to increase R's
> capacity for loading very long functions?

I assume by 'load' you must be somehow using 'source' to read your file 
into R. help("source") says:

     If `options'("keep.source") is true (the default), the source of
      functions is keep so they can be listed exactly as input. This
      imposes a limit of 128K chars on the function size and a nesting
      limit of 265.  Use `option(keep.source = FALSE)' when these limits
      might take effect: if exceeded they generate an error.

Baz



From elvis at xlsolutions-corp.com  Thu Sep  4 18:57:27 2003
From: elvis at xlsolutions-corp.com (elvis@xlsolutions-corp.com)
Date: Thu,  4 Sep 2003 09:57:27 -0700
Subject: [R] Splus/R: Complementing and Extending Statistical Computing for
	SAS Users
Message-ID: <20030904165728.14540.qmail@webmail-2-1.secureserver.net>


   XLSolutions Corporation ([1]www.xlsolutions-corp.com) is pleased to
   announce a two-day course, "Splus/R: Complementing and Extending
   Statistical Computing for SAS Users"
   [2]www.xlsolutions-corp.com/Rsas.htm
   Dates/City: October 9-10, 2003 in Washington DC
               October 2-3, 2003  in Princeton, NJ
               October 2-3, 2003  in Boston, MA

Simply Register  by September 30th for Earlybird! (Payment is due AFTER class).

   This course is designed for SAS users who want to learn how to
   complement
   and extend statistical computing with Splus and/or R system.
   The course will give participants a strong foundation for becoming
   a versatile programmer.
   Course Description:
   This two-day course focuses on a broad spectrum of topics:
   *Data manipulations in S and R (data frame and matrix operations)
   and SAS (the data step) -- issues of importing, formatting,
   transformation,
   cataloging, exporting
   *Splus/R Functions vs macros in SAS for programming repetitive
   processes.
   *The iteration models of SAS vs whole-object modeling
   *Specific comparison: linear modeling, glms, gees, lmes.
   *etc
   Complete course description: [3]www.xlsolutions-corp.com/Rsas.htm
   Registration:
   Email Sue Turner: sue at xlsolutions-corp.com
   Phone: 206-686-1578 x221
   Ask for group discount!  (Payment is due AFTER class).
   Share Your Thoughts:
   Are there any additional topics you would like for this course to
   address?
   Would you like for this course to be offered in another city?
   Please let us know by contributing to our recommendation list:
   training at xlsolutions-corp.com.
   ======================================================================
   ==
   Pre-registration Form
   Please email the following details with the course code: R2SASBoston
   XLsolutions Corporation: For your Solutions needs, Consulting and
   Training.
   [4]www.xlsolutions-corp.com
   Title...... First Name ................. Last Name....................
   Organization..........................................................
   Mailing Address.......................................................
   ....................................................................
   ....................................................................
   Zip Code...................... Country.............................
   Telephone........................... Fax
   ...............................
   E-mail................................................................
   Payment will be made by: (1) check (2) invoice (3) credit card
   Elvis Miller, PhD
   Manager Training and Technical Support
   North American Division
   XLSolutions Corporation
   Email: elvis at xlsolutions-corp.com
   Phone: 206-686-1578
   Web: [5]www.xlsolutions-corp.com
   

References

   1. http://www.xlsolutions-corp.com/
   2. http://www.xlsolutions-corp.com/Rsas.htm
   3. http://www.xlsolutions-corp.com/Rsas.htm
   4. http://www.xlsolutions-corp.com/
   5. http://www.xlsolutions-corp.com/


From vograno at evafunds.com  Thu Sep  4 19:00:40 2003
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Thu, 4 Sep 2003 10:00:40 -0700
Subject: [R] read.table: check.names arg - feature request
Message-ID: <6776E9D60411DD439AA7C8A20F67C51C1797F9@ehost060.intermedia.net>

I admit I should have been more clear in my original posting. Let me try again (and I do know that by deafulat read.table discards everything after '#' which is why I use comment.char="", my bad not to mention this).


Here is a typical example of my data file:

#key	value
foo	1.2
boo	1.3

As you see the header line begins with '#' and then lists the column names, however make.names will convert the raw names  c("#key", "value") to c(".key", "value") while I need c("key", "value"), i.e. no dot before key. So I am asking to give us a hook to specify the function that will handle this situation.



I am not sure I understand how having this hook can result in an invalid data frame? It can return invalid names, but check.names=FALSE can too.

Thanks,
Vadim

-----Original Message-----
From: Martin Maechler [mailto:maechler at stat.math.ethz.ch]
Sent: Thursday, September 04, 2003 1:28 AM
To: Vadim Ogranovich
Cc: R-Help (E-mail)
Subject: Re: [R] read.table: check.names arg - feature request


>>>>> "Vadim" == Vadim Ogranovich <vograno at evafunds.com>
>>>>>     on Wed, 3 Sep 2003 14:29:25 -0700 writes:

    Vadim> Hi, I thought it would be convenient if the
    Vadim> check.names argument to read.table, which currently
    Vadim> can only be TRUE/FALSE, could take a function value
    Vadim> as well. If the function is supplied it should be
    Vadim> used instead of the default make.names.

One could, but it's not necessary in your case (see below), and
it's a potential pit to fall in..  We want read.table() to
return valid  data frames.

    Vadim> Here is an example where it can come in handy. I tend
    Vadim> to keep my data in coma-separated files with a header
    Vadim> line. The header line is prefixed with a comment sign
    Vadim> '#' to simplify identification of these lines. Now
    Vadim> when I read.table the files the '#' is converted to
    Vadim> '.' while I want it to be discarded.

Hmm, are you using a very old version of R,
or haven't you seen the `comment.char = "#"' argument of
read.table()?

Reading "?read.table", also note the note about
`blank.lines.skip' , and then realize that the default for
blank.lines.skip is  ` !fill ' and that `fill = TRUE' for all
the read.csv* and read.delim* incantation of read.table().

In sum, it's very easy to use current read.table() for your
situation!

    Vadim> P.S. I don't know if r-help is the right place for
    Vadim> feature requests. If it's not please let me know
    Vadim> where the right one is.

Since your proposal can be interpreted as "How do I use
read.table() when my file has comment lines?",
r-help has been very appropriate.

Otherwise, and particularly if the proposal is more technical,
R-devel would be better suited.

Regards,
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From pburns at pburns.seanet.com  Thu Sep  4 19:00:48 2003
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Thu, 04 Sep 2003 18:00:48 +0100
Subject: [R] documents for writing functions
References: <1062712607.18329.143.camel@templar.fns.uniba.sk>
Message-ID: <3F576FC0.4040208@pburns.seanet.com>

Would S Poetry be the sort of thing you are looking for?

Patrick Burns

Burns Statistics
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

Rado Bonk wrote:

>Hi,
>
>Does anybody know suitable documents (manuals) on writing user functions
>(covering loops, conditions ...) in R? Other than the usually available
>manuals.
>
>Thanks,
>
>Rado
>
>
>  
>



From tlumley at u.washington.edu  Thu Sep  4 19:21:10 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 4 Sep 2003 10:21:10 -0700 (PDT)
Subject: [R] function is too long to keep source
In-Reply-To: <BAY5-F30H8ZJaQPmRfQ00035eaf@hotmail.com>
Message-ID: <Pine.A41.4.44.0309041018580.61662-100000@homer37.u.washington.edu>

On Thu, 4 Sep 2003, Marcel Vieira wrote:

> Dear R users,
>
> I am trying to minimise a function using "nlm".
>
> I am getting the following error message: "Error: function is too long to
> keep source"
>
> The function is really very long (about 100 A4 pages).
>
> Is there anything I could do to solve this problem?

Assuming that the obvious solution (splitting up the function into pieces)
doesn't work you can use

   options(keep.source=FALSE)

to tell R not to store the source text in addition to the parsed code. The
only disadvantage of this is that when you list the function source inside
R there aren't any comments, but you don't want to do this with 100 pages
of code anyway.

	-thomas



From pgreen at umich.edu  Thu Sep  4 19:23:11 2003
From: pgreen at umich.edu (Paul Green)
Date: Thu, 04 Sep 2003 13:23:11 -0400
Subject: [R] counts for grouped data
Message-ID: <5.1.0.14.2.20030904131820.00b11e98@mailkardia.sph.umich.edu>

How does one get counts for grouped data
from ungrouped data. For example, how can
I get

         X1  X2  Count
         1     1      1
         1     2      2
         2     1      1
         2     2      1

from

         X1  X2
         A    A
         A    B
         B    B
         A    B
         B    A

Thanks in advance

Paul Green



From flom at ndri.org  Thu Sep  4 19:28:12 2003
From: flom at ndri.org (Peter Flom)
Date: Thu, 04 Sep 2003 13:28:12 -0400
Subject: [R] scatter.smooth error
Message-ID: <sf573dfd.047@MAIL.NDRI.ORG>

Hello

When I run 

scatter.smooth(jitter(weight), jitter(height2), span = .25, evaluation
= 50, pch = '.')

I get the type of graph I thought I would get, but also a warning.....

k-d tree limited by memory. ncmax= 528 


I always get concerned when there are warnings I don't understand. 
What's a k-d tree?  Is this something to be concerned about?

Thanks

Peter

Peter L. Flom, PhD
Assistant Director, Statistics and Data Analysis Core
Center for Drug Use and HIV Research
National Development and Research Institutes
71 W. 23rd St
www.peterflom.com
New York, NY 10010
(212) 845-4485 (voice)
(917) 438-0894 (fax)



From york at zipcon.net  Thu Sep  4 19:41:25 2003
From: york at zipcon.net (Anne York)
Date: Thu, 4 Sep 2003 10:41:25 -0700 (PDT)
Subject: [R] gnome gui question
Message-ID: <Pine.LNX.4.44.0309040956390.3502-100000@localhost.localdomain>

I have compiled R 1.7.1 with gnome and installed the gtkDevice on a Linux 
RH 8 system. This is my first use of this device and I have two 
questions about it.

1.  After running R --rui="gnome", the console comes up. To open a 
graphics window, I open the gtkDevice library [library(gtkDevice)], then 
start a gtk device [gtk()]. After the library command, I receive the 
message from R that the gtk function is masked from package:base. Did I do 
something incorrect in my installation to receive this message? The 
gtk device does open and appears to work, so maybe this is a "play on". 

2. In the "settings --> preferences"  menu section, I am able to change 
the look (fonts and colors) for the console and pager. However, the 
corresponding section for the graphics window has no visible options. Is 
this normal? 


Thank-you.

Anne



From tlumley at u.washington.edu  Thu Sep  4 19:47:09 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 4 Sep 2003 10:47:09 -0700 (PDT)
Subject: [R] counts for grouped data
In-Reply-To: <5.1.0.14.2.20030904131820.00b11e98@mailkardia.sph.umich.edu>
Message-ID: <Pine.A41.4.44.0309041046210.61662-100000@homer37.u.washington.edu>

On Thu, 4 Sep 2003, Paul Green wrote:

> How does one get counts for grouped data
> from ungrouped data. For example, how can
> I get
>
>          X1  X2  Count
>          1     1      1
>          1     2      2
>          2     1      1
>          2     2      1
>
> from
>
>          X1  X2
>          A    A
>          A    B
>          B    B
>          A    B
>          B    A
>

One possibility is

> df
  X1 X2
1  A  A
2  A  B
3  B  B
4  A  B
5  B  A
> aggregate(rep(1,nrow(df)), df, NROW)
  X1 X2 x
1  A  A 1
2  B  A 1
3  A  B 2
4  B  B 1


	-thomas



From tplate at blackmesacapital.com  Thu Sep  4 19:50:47 2003
From: tplate at blackmesacapital.com (Tony Plate)
Date: Thu, 04 Sep 2003 11:50:47 -0600
Subject: [R] read.table: check.names arg - feature request
In-Reply-To: <6776E9D60411DD439AA7C8A20F67C51C1797F9@ehost060.intermedia .net>
Message-ID: <5.2.1.1.2.20030904114018.04bc4d58@mailhost.blackmesacapital.com>

If you have a special need, it probably far more time effective on your 
part to write a special function rather than attempt to convince the very 
busy R developers that they should add a new feature to a very old function 
(is this a better use of their time than, say, fixing long identified bugs 
that have not yet been fixed for lack of time?).

You should be able to do something like:

my.read.table <- function(..., header=T, comment.char="", check.names=F) {
      x <- read.table(..., header=header, comment.char=comment.char, 
check.names=check.names)
      colnames(x)[1] <- gsub("#", "", colnames(x)[1])
      x
}

And with your example on my clipboard:

 > readLines("clipboard", -1)
[1] "#key    value" "foo     1.2"   "boo     1.3"
 > read.table("clipboard", header=T, comment.char="", check.names=F)
   #key value
1  foo   1.2
2  boo   1.3
 > my.read.table("clipboard")
   key value
1 foo   1.2
2 boo   1.3
 >

hope this helps,

Tony Plate

At Thursday 10:00 AM 9/4/2003 -0700, Vadim Ogranovich wrote:
>I admit I should have been more clear in my original posting. Let me try 
>again (and I do know that by deafulat read.table discards everything after 
>'#' which is why I use comment.char="", my bad not to mention this).
>
>
>Here is a typical example of my data file:
>
>#key    value
>foo     1.2
>boo     1.3
>
>As you see the header line begins with '#' and then lists the column 
>names, however make.names will convert the raw names  c("#key", "value") 
>to c(".key", "value") while I need c("key", "value"), i.e. no dot before 
>key. So I am asking to give us a hook to specify the function that will 
>handle this situation.
>
>
>
>I am not sure I understand how having this hook can result in an invalid 
>data frame? It can return invalid names, but check.names=FALSE can too.
>
>Thanks,
>Vadim
>
>-----Original Message-----
>From: Martin Maechler [mailto:maechler at stat.math.ethz.ch]
>Sent: Thursday, September 04, 2003 1:28 AM
>To: Vadim Ogranovich
>Cc: R-Help (E-mail)
>Subject: Re: [R] read.table: check.names arg - feature request
>
>
> >>>>> "Vadim" == Vadim Ogranovich <vograno at evafunds.com>
> >>>>>     on Wed, 3 Sep 2003 14:29:25 -0700 writes:
>
>     Vadim> Hi, I thought it would be convenient if the
>     Vadim> check.names argument to read.table, which currently
>     Vadim> can only be TRUE/FALSE, could take a function value
>     Vadim> as well. If the function is supplied it should be
>     Vadim> used instead of the default make.names.
>
>One could, but it's not necessary in your case (see below), and
>it's a potential pit to fall in..  We want read.table() to
>return valid  data frames.
>
>     Vadim> Here is an example where it can come in handy. I tend
>     Vadim> to keep my data in coma-separated files with a header
>     Vadim> line. The header line is prefixed with a comment sign
>     Vadim> '#' to simplify identification of these lines. Now
>     Vadim> when I read.table the files the '#' is converted to
>     Vadim> '.' while I want it to be discarded.
>
>Hmm, are you using a very old version of R,
>or haven't you seen the `comment.char = "#"' argument of
>read.table()?
>
>Reading "?read.table", also note the note about
>`blank.lines.skip' , and then realize that the default for
>blank.lines.skip is  ` !fill ' and that `fill = TRUE' for all
>the read.csv* and read.delim* incantation of read.table().
>
>In sum, it's very easy to use current read.table() for your
>situation!
>
>     Vadim> P.S. I don't know if r-help is the right place for
>     Vadim> feature requests. If it's not please let me know
>     Vadim> where the right one is.
>
>Since your proposal can be interpreted as "How do I use
>read.table() when my file has comment lines?",
>r-help has been very appropriate.
>
>Otherwise, and particularly if the proposal is more technical,
>R-devel would be better suited.
>
>Regards,
>Martin Maechler <maechler at stat.math.ethz.ch>    http://stat.ethz.ch/~maechler/
>Seminar fuer Statistik, ETH-Zentrum  LEO C16    Leonhardstr. 27
>ETH (Federal Inst. Technology)  8092 Zurich     SWITZERLAND
>phone: x-41-1-632-3408          fax: ...-1228                   <><
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From deepayan at stat.wisc.edu  Thu Sep  4 19:54:28 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 4 Sep 2003 12:54:28 -0500
Subject: [R] lattice question--- different ylim
In-Reply-To: <20030904142654.14518.qmail@web41201.mail.yahoo.com>
References: <20030904142654.14518.qmail@web41201.mail.yahoo.com>
Message-ID: <200309041254.28302.deepayan@stat.wisc.edu>


For example (variations are possible), 

y <- 100 * runif(400)
a <- gl(4, 100)
x <- gl(3, 7, 400)

library(lattice)
bwplot(y ~ x | a, scales = list(y = "free"), 
       ylim = list(c(0, 100), c(0, 200), c(0, 100), c(0, 200)))

(Assuming you have up to date versions of R and lattice).

On Thursday 04 September 2003 09:26 am, Mahbub Latif wrote:
> Hi there,
>
> I have four panels in a lattice bwplot. I want to have
> two different ylim for the panels, for example panels
> [1,1] and [1,2] with ylim=c(0,200) and panels [2,1]
> and [2,2] with ylim=c(0,100).
>
> Thanks for help in advance.
>
> Mahbub.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From spencer.graves at pdf.com  Thu Sep  4 19:59:54 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 04 Sep 2003 10:59:54 -0700
Subject: [R] counts for grouped data
References: <5.1.0.14.2.20030904131820.00b11e98@mailkardia.sph.umich.edu>
Message-ID: <3F577D9A.7050403@pdf.com>

Have you considered "table"?

spencer graves

Paul Green wrote:
> How does one get counts for grouped data
> from ungrouped data. For example, how can
> I get
> 
>         X1  X2  Count
>         1     1      1
>         1     2      2
>         2     1      1
>         2     2      1
> 
> from
> 
>         X1  X2
>         A    A
>         A    B
>         B    B
>         A    B
>         B    A
> 
> Thanks in advance
> 
> Paul Green
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From MSchwartz at medanalytics.com  Thu Sep  4 20:07:55 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Thu, 04 Sep 2003 13:07:55 -0500
Subject: [R] read.table: check.names arg - feature request
In-Reply-To: <6776E9D60411DD439AA7C8A20F67C51C1797F9@ehost060.intermedia.net>
References: <6776E9D60411DD439AA7C8A20F67C51C1797F9@ehost060.intermedia.net>
Message-ID: <1062698875.4219.66.camel@localhost>

On Thu, 2003-09-04 at 12:00, Vadim Ogranovich wrote:
> I admit I should have been more clear in my original posting. Let me
> try again (and I do know that by deafulat read.table discards
> everything after '#' which is why I use comment.char="", my bad not to
> mention this).
> 
> 
> Here is a typical example of my data file:
> 
> #key	value
> foo	1.2
> boo	1.3
> 
> As you see the header line begins with '#' and then lists the column
> names, however make.names will convert the raw names  c("#key",
> "value") to c(".key", "value") while I need c("key", "value"), i.e. no
> dot before key. So I am asking to give us a hook to specify the
> function that will handle this situation.
> 
> 
> 
> I am not sure I understand how having this hook can result in an
> invalid data frame? It can return invalid names, but check.names=FALSE
> can too.
> 
> Thanks,
> Vadim

SNIP 

What's wrong with changing the colnames after the import:

(This is under R 1.7.1 under RH 9, using defaults)

# Note the conversion of the '#' to 'X.'
make.names(c("#key", "value"))
[1] "X.key" "value"

# Presuming you have dataframe 'df' now imported:
colnames(df)
[1] "X.key" "value"

# Now change them
colnames(df) <- gsub("X\\.", "", colnames(df))

# Check names
colnames(df)
[1] "key"   "value"



Is there a reason that you could not do this after, rather than before
or during the import? You are asking R Core to make a substantive change
to a function, when an alternative already exists to resolve a rather
unique situation.

HTH,

Marc Schwartz



From deepayan at stat.wisc.edu  Thu Sep  4 20:14:31 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 4 Sep 2003 13:14:31 -0500
Subject: [R] Putting regression lines on SPLOM
In-Reply-To: <XFMail.030904174739.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.030904174739.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <200309041314.31769.deepayan@stat.wisc.edu>


You can't do it in that sequence, and whether you can do it at all depends on 
exactly what you mean when you say that the data used for the regressions are 
not the same as those used for the plots. The typical way would be to do 

splom(DF, 
      panel = function(x, y, ...) {
          panel.xyplot(x, y, ...)

          # modify x and y as appropriate (?)
          # whether that can be done depends on whether
          # you have all the information you need 
          # available inside the panel function

          fm <- lm(y ~ x) 
          panel.abline(fm)
      })

Can't think of anything else (other than using a custom superpanel function).

Deepayan

On Thursday 04 September 2003 11:47 am, Ted Harding wrote:
> Sorry Folks,
> I'm sure I could suss out the answer myself but I need it
> soon ... !
>
> 1. Given a set of 4 variables X,Y,Z,W in a dataframe DF, I make
>    a scatter-plot matrix using splom(DF).
>
> 2. I do all regressions of U on V using lm(U~V), where U and V
>    are all 12 different ordered pairs from X,Y,Z,W.
>
> 3. Now I would like to superpose the regression lines from (2)
>    onto the corresponding panels from (1).
>
> (By the way, the data used for the regressions are not quite
>  the same as those used for the plots, since a few observations
>  are omitted from the regressions but appear on  the plots,
>  so (1) and (2) really are separate operations).
>
> With thanks,
> Ted.
>
>
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 167 1972
> Date: 04-Sep-03                                       Time: 17:47:39
> ------------------------------ XFMail ------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From paulda at BATTELLE.ORG  Thu Sep  4 20:50:25 2003
From: paulda at BATTELLE.ORG (Paul, David  A)
Date: Thu, 04 Sep 2003 14:50:25 -0400
Subject: [R] Comparison of SAS & R/Splus
Message-ID: <940250A9EB37A24CBE28D858EF07774967AAD0@ws-bco-mse3.milky-way.battelle.org>

I am one of only 5 or 6 people in my organization making the
effort to include R/Splus as an analysis tool in everyday work -
the rest of my colleagues use SAS exclusively.

Today, one of them made the assertion that he believes the
numerical algorithms in SAS are superior to those in Splus
and R -- ie, optimization routines are faster in SAS, the SAS
Institute has teams of excellent numerical analysts that
ensure its superiority to anything freely available, PROC 
NLMIXED is more flexible than nlme( ) in the sense that it 
allows a much wider array of error structures than can be used 
in R/Splus, &etc.  

I obviously do not subscribe to these views and would like 
to refute them, but I am not a numerical analyst and am still 
a novice at R/Splus.  Do there exist refereed papers comparing the 
numerical capabilities of these platforms?  If not, are there 
other resources I might look up and pass along to my colleagues?



Much thanks in advance,
 
 david paul



From feh3k at spamcop.net  Thu Sep  4 15:34:26 2003
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Thu, 4 Sep 2003 15:34:26 +0200
Subject: [R] Comparison of SAS & R/Splus
In-Reply-To: <940250A9EB37A24CBE28D858EF07774967AAD0@ws-bco-mse3.milky-way.battelle.org>
References: <940250A9EB37A24CBE28D858EF07774967AAD0@ws-bco-mse3.milky-way.battelle.org>
Message-ID: <20030904153426.5ee09b96.feh3k@spamcop.net>

On Thu, 04 Sep 2003 14:50:25 -0400
"Paul, David  A" <paulda at BATTELLE.ORG> wrote:

> I am one of only 5 or 6 people in my organization making the
> effort to include R/Splus as an analysis tool in everyday work -
> the rest of my colleagues use SAS exclusively.
> 
> Today, one of them made the assertion that he believes the
> numerical algorithms in SAS are superior to those in Splus
> and R -- ie, optimization routines are faster in SAS, the SAS
> Institute has teams of excellent numerical analysts that
> ensure its superiority to anything freely available, PROC 
> NLMIXED is more flexible than nlme( ) in the sense that it 
> allows a much wider array of error structures than can be used 
> in R/Splus, &etc.  
> 
> I obviously do not subscribe to these views and would like 
> to refute them, but I am not a numerical analyst and am still 
> a novice at R/Splus.  Do there exist refereed papers comparing the 
> numerical capabilities of these platforms?  If not, are there 
> other resources I might look up and pass along to my colleagues?
> 
> 
> 
> Much thanks in advance,
>  
>  david paul

I don't have papers comparing the numerical capabilities but I say bunk to your colleagues.  The last time I looked, SAS still relies on the out of date Gauss-Jordan sweep operator in many key places, in place of the QR decomposition that R and S-Plus use in regression.  And SAS being closed source makes it impossible to see how it really does calculations in some cases.

See http://hesweb1.med.virginia.edu/biostat/s/doc/splus.pdf Section 1.6 for a comparison of S and SAS (though this doesn't address numerical reliability).  Overall, SAS is about 11 years behind R and S-Plus in statistical capabilities (last year it was about 10 years behind) in my estimation.

Frank Harrell
SAS User, 1969-1991
---
Frank E Harrell Jr    Professor and Chair            School of Medicine
                      Department of Biostatistics    Vanderbilt University



From haky at galton.uchicago.edu  Thu Sep  4 22:08:04 2003
From: haky at galton.uchicago.edu (Hae-Kyung Im)
Date: Thu, 4 Sep 2003 15:08:04 -0500 (CDT)
Subject: [R] error handling in R/ lapack routines
Message-ID: <Pine.LNX.4.44.0309041437550.26200-100000@pafnuty.uchicago.edu>


Does any of you know where I can find an explanation of lapack errors codes?
I get error code 17 when using optim().

Is there a way to handle errors in R such that depending on the type of 
error I can decide what to do next?

Thanks,
Haky



From MSchwartz at medanalytics.com  Thu Sep  4 22:12:55 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Thu, 04 Sep 2003 15:12:55 -0500
Subject: [R] Comparison of SAS & R/Splus
In-Reply-To: <20030904153426.5ee09b96.feh3k@spamcop.net>
References: <940250A9EB37A24CBE28D858EF07774967AAD0@ws-bco-mse3.milky-way.battelle.org>
	<20030904153426.5ee09b96.feh3k@spamcop.net>
Message-ID: <1062706375.4219.97.camel@localhost>

On Thu, 2003-09-04 at 08:34, Frank E Harrell Jr wrote:
> On Thu, 04 Sep 2003 14:50:25 -0400
> "Paul, David  A" <paulda at BATTELLE.ORG> wrote:
> 
> > I am one of only 5 or 6 people in my organization making the
> > effort to include R/Splus as an analysis tool in everyday work -
> > the rest of my colleagues use SAS exclusively.
> > 
> > Today, one of them made the assertion that he believes the
> > numerical algorithms in SAS are superior to those in Splus
> > and R -- ie, optimization routines are faster in SAS, the SAS
> > Institute has teams of excellent numerical analysts that
> > ensure its superiority to anything freely available, PROC 
> > NLMIXED is more flexible than nlme( ) in the sense that it 
> > allows a much wider array of error structures than can be used 
> > in R/Splus, &etc.  
> > 
> > I obviously do not subscribe to these views and would like 
> > to refute them, but I am not a numerical analyst and am still 
> > a novice at R/Splus.  Do there exist refereed papers comparing the 
> > numerical capabilities of these platforms?  If not, are there 
> > other resources I might look up and pass along to my colleagues?
> > 
> > 
> > 
> > Much thanks in advance,
> >  
> >  david paul
> 
> I don't have papers comparing the numerical capabilities but I say
> bunk to your colleagues.  The last time I looked, SAS still relies on
> the out of date Gauss-Jordan sweep operator in many key places, in
> place of the QR decomposition that R and S-Plus use in regression. 
> And SAS being closed source makes it impossible to see how it really
> does calculations in some cases.
> 
> See http://hesweb1.med.virginia.edu/biostat/s/doc/splus.pdf Section
> 1.6 for a comparison of S and SAS (though this doesn't address
> numerical reliability).  Overall, SAS is about 11 years behind R and
> S-Plus in statistical capabilities (last year it was about 10 years
> behind) in my estimation.
> 
> Frank Harrell
> SAS User, 1969-1991


In follow up to Frank's reply, allow me to point you to some additional
papers and articles on numerical accuracy issues. I have not reviewed
these in some time and they may be a bit dated relative to current
versions. These do not cover R specifically, but do address S-Plus and
SAS. This is not an exhaustive list by any means, but many of the papers
do have other references that may be of value.


1. http://www.stat.uni-muenchen.de/~knuesel/elv/accuracy.html

2. http://www.amstat.org/publications/tas/mccull-1.pdf

3. http://www.amstat.org/publications/tas/mccull.pdf

4. http://www.npl.co.uk/ssfm/download/documents/cmsc06_00.pdf


Another option is that NIST has reference datasets available for comparison at:

http://www.itl.nist.gov/div898/strd/

These would allow you to conduct your own comparisons if you desire.

HTH,

Marc Schwartz
(Also a former SAS user)



From kwan022 at stat.auckland.ac.nz  Thu Sep  4 22:12:51 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Fri, 5 Sep 2003 08:12:51 +1200 (NZST)
Subject: [R] documents for writing functions
In-Reply-To: <3F57669A.2050107@pdf.com>
Message-ID: <Pine.LNX.4.44.0309050810001.19662-100000@stat55.stat.auckland.ac.nz>

On Thu, 4 Sep 2003, Spencer Graves wrote:

> Have you considered the two books by Venables and Ripley (2002) Modern 
> Applied Statistics in S and (2000) S Programming (both Springer)?  If 
> yes, I don't know what you mean by "the usually available manuals."

In addition, John Chambers's "Programming with Data" (aka The Green Book) 
is a good source.
 
> hope this helps.
> 
> Rado Bonk wrote:
> > Hi,
> > 
> > Does anybody know suitable documents (manuals) on writing user functions
> > (covering loops, conditions ...) in R? Other than the usually available
> > manuals.

It all depends on how much programming experience you already have.  I'm 
giving a small workshop next week on these areas and my notes are 
available at http://www.stat.auckland.ac.nz/~kwan022/rinfo.php 

I'm planning on extend the notes into a book I'm writing -- which will be 
submitted to CRAN when it is completed.

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
"On two occasions, I have been asked [by members of Parliament],
'Pray, Mr. Babbage, if you put into the machine wrong figures, will
the right answers come out?' I am not able to rightly apprehend the
kind of confusion of ideas that could provoke such a question."

-- Charles Babbage (1791-1871) 
---- From Computer Stupidities: http://rinkworks.com/stupid/

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)



From kwan022 at stat.auckland.ac.nz  Thu Sep  4 22:19:46 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Fri, 5 Sep 2003 08:19:46 +1200 (NZST)
Subject: [R] Comparison of SAS & R/Splus
In-Reply-To: <940250A9EB37A24CBE28D858EF07774967AAD0@ws-bco-mse3.milky-way.battelle.org>
Message-ID: <Pine.LNX.4.44.0309050815070.19662-100000@stat55.stat.auckland.ac.nz>

On Thu, 4 Sep 2003, Paul, David  A wrote:

> I am one of only 5 or 6 people in my organization making the
> effort to include R/Splus as an analysis tool in everyday work -
> the rest of my colleagues use SAS exclusively.
> 
> Today, one of them made the assertion that he believes the
> numerical algorithms in SAS are superior to those in Splus
> and R -- ie, optimization routines are faster in SAS, the SAS

I can't say for the optimisation routines, but I have found this...

When I was doing my MSc thesis, using tree-based models and neural 
networks for classifications, I discovered something interesting.

Using SAS Enterprise Miner (SAS EM), its Tree Node is far more efficient 
than the rpart package.  Using the same (or very similar at least) parameter 
settings, SAS EM can produce a tree in about 1 minute while it would take 
rpart 5 ~ 6 minutes (same data, same machine....).  Having said that, I 
still prefer rpart as it can draw a beautiful tree, whereas it is very 
difficult to fit the graphical tree produced by SAS EM into one A4 page -- 
in the end I had to use the text tree.

However, the Neural Network node in SAS EM is less efficient than nnet.  
The time it takes to fit a neural network in R using nnet is much 
faster....



-- 
Cheers,

Kevin

------------------------------------------------------------------------------
"On two occasions, I have been asked [by members of Parliament],
'Pray, Mr. Babbage, if you put into the machine wrong figures, will
the right answers come out?' I am not able to rightly apprehend the
kind of confusion of ideas that could provoke such a question."

-- Charles Babbage (1791-1871) 
---- From Computer Stupidities: http://rinkworks.com/stupid/

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)



From p.dalgaard at biostat.ku.dk  Thu Sep  4 22:27:12 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Thu, 04 Sep 2003 20:27:12 -0000
Subject: [R] Dos() Command for R
In-Reply-To: <20030904164138.GB22988@sonny.eddelbuettel.com>
References: <BC6A439CD6835749A9C7B8D8F041DFA88B11B2@rbamsem1.emea.roche.com>
	<20030904164138.GB22988@sonny.eddelbuettel.com>
Message-ID: <x2n0dk70xo.fsf@biostat.ku.dk>

Dirk Eddelbuettel <edd at debian.org> writes:

> On Thu, Sep 04, 2003 at 05:37:46PM +0200, Brunschwig, Hadassa {PDMM~Basel} wrote:
> > Is there an equivalent in R for the dos() command in S?
> 
> help(system)

help(shell) on Windows, actually. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From spencer.graves at pdf.com  Thu Sep  4 22:33:02 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 04 Sep 2003 13:33:02 -0700
Subject: [R] error handling in R/ lapack routines
References: <Pine.LNX.4.44.0309041437550.26200-100000@pafnuty.uchicago.edu>
Message-ID: <3F57A17E.2060108@pdf.com>

	  I just did a Google search for "lapack error codes" and got several 
hits.  However, I don't know if a translation of "error code 17" would 
really help you.

	  Have you tried "fn" as a stand-alone function?  If yes, have you 
tried including a "cat" or "print" statement in it, so it prints the 
value (and maybe the arguments) before it actually returns it?  If optim 
is going to run more than a few seconds, I have "fn" print the value it 
returns.  If it returns NA. I see that, etc.

hope this helps.
spencer graves

Hae-Kyung Im wrote:
> Does any of you know where I can find an explanation of lapack errors codes?
> I get error code 17 when using optim().
> 
> Is there a way to handle errors in R such that depending on the type of 
> error I can decide what to do next?
> 
> Thanks,
> Haky
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Mike.Prager at noaa.gov  Thu Sep  4 22:47:43 2003
From: Mike.Prager at noaa.gov (Mike Prager)
Date: Thu, 04 Sep 2003 16:47:43 -0400
Subject: [R] Comparison of SAS & R/Splus
In-Reply-To: <940250A9EB37A24CBE28D858EF07774967AAD0@ws-bco-mse3.milky-way.battelle.org>
References: <940250A9EB37A24CBE28D858EF07774967AAD0@ws-bco-mse3.milky-way.battelle.org>
Message-ID: <3F57A4EF.1020301@noaa.gov>

Paul, David A wrote:

>I am one of only 5 or 6 people in my organization making the
>effort to include R/Splus as an analysis tool in everyday work -
>the rest of my colleagues use SAS exclusively.
>
>Today, one of them made the assertion that he believes the
>numerical algorithms in SAS are superior to those in Splus
>and R -- ie, optimization routines are faster in SAS, the SAS
>Institute has teams of excellent numerical analysts that
>ensure its superiority to anything freely available, PROC 
>NLMIXED is more flexible than nlme( ) in the sense that it 
>allows a much wider array of error structures than can be used 
>in R/Splus, &etc.  
>
>I obviously do not subscribe to these views and would like 
>to refute them, but I am not a numerical analyst and am still 
>a novice at R/Splus.  Do there exist refereed papers comparing the 
>numerical capabilities of these platforms?  If not, are there 
>other resources I might look up and pass along to my colleagues?
>  
>

I suspect it will be difficult to find the answer to your colleagues'
assertions without doing your own studies.  How important is it to you
to settle this disagreement?

One could always name the many leading statisticians who contribute to
R, but I don't think that name dropping settles anything.

Nonetheless, even if SAS were faster, that would be only part of the
issue.  As you know, R offers vastly better exploratory graphics, better
graphics overall, far more flexible programming, user extensibility, and
more natural programming access to the results of previous
computations.  So even if your colleagues were right in their
assertions, they would be overlooking many capabilities of the S
language that are not readily available in SAS.

IMO, SAS shines in its ability to read files in almost any format, to
handle gigantic data sets without burping, and to produce formatted
cross-tabulations and other highly structured text reports.  However, if
your colleagues work at all in data exploration, they are ignoring
important tools by not exploring R or S-Plus.

-- 
Michael Prager, Ph.D.
NOAA Center for Coastal Fisheries and Habitat Research
Beaufort, North Carolina  28516
http://shrimp.ccfhrb.noaa.gov/~mprager/
DISCLAIMER: Opinions expressed are personal, not official. N...{{dropped}}



From spencer.graves at pdf.com  Thu Sep  4 22:58:01 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 04 Sep 2003 13:58:01 -0700
Subject: [R] error handling in R/ lapack routines
References: <Pine.LNX.4.44.0309041545370.26559-100000@pafnuty.uchicago.edu>
Message-ID: <3F57A759.40209@pdf.com>

yes:  From "?optim", I get the following:

optim(par, fn, gr = NULL,
            method = c("Nelder-Mead", "BFGS", "CG", "L-BFGS-B", "SANN"),
            lower = -Inf, upper = Inf,
            control = list(), hessian = FALSE, ...)

By "fn", I meant the function you supply for that argument.

spencer graves

Hae-Kyung Im wrote:
> Hi,
> Thanks for your reply.
> 
> I did search in google but I couldn't really find a list of error codes. 
> Although you're right, that wouldn't probably help me much.
> 
> What do you mean by using "fn" as a stand-alone function? Do you mean the 
> function I'm maximizing?
> 
> Haky
> 
> 
> 
> On Thu, 4 Sep 2003, Spencer Graves wrote:
> 
> 
>>	  I just did a Google search for "lapack error codes" and got several 
>>hits.  However, I don't know if a translation of "error code 17" would 
>>really help you.
>>
>>	  Have you tried "fn" as a stand-alone function?  If yes, have you 
>>tried including a "cat" or "print" statement in it, so it prints the 
>>value (and maybe the arguments) before it actually returns it?  If optim 
>>is going to run more than a few seconds, I have "fn" print the value it 
>>returns.  If it returns NA. I see that, etc.
>>
>>hope this helps.
>>spencer graves
>>
>>Hae-Kyung Im wrote:
>>
>>>Does any of you know where I can find an explanation of lapack errors codes?
>>>I get error code 17 when using optim().
>>>
>>>Is there a way to handle errors in R such that depending on the type of 
>>>error I can decide what to do next?
>>>
>>>Thanks,
>>>Haky
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
>>
>



From bates at stat.wisc.edu  Thu Sep  4 23:35:08 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 04 Sep 2003 21:35:08 -0000
Subject: [R] Comparison of SAS & R/Splus
In-Reply-To: <940250A9EB37A24CBE28D858EF07774967AAD0@ws-bco-mse3.milky-way.battelle.org>
References: <940250A9EB37A24CBE28D858EF07774967AAD0@ws-bco-mse3.milky-way.battelle.org>
Message-ID: <6rr82wxmml.fsf@bates4.stat.wisc.edu>

"Paul, David  A" <paulda at BATTELLE.ORG> writes:

> I am one of only 5 or 6 people in my organization making the
> effort to include R/Splus as an analysis tool in everyday work -
> the rest of my colleagues use SAS exclusively.
> 
> Today, one of them made the assertion that he believes the
> numerical algorithms in SAS are superior to those in Splus
> and R -- ie, optimization routines are faster in SAS, the SAS
> Institute has teams of excellent numerical analysts that
> ensure its superiority to anything freely available, PROC 
> NLMIXED is more flexible than nlme( ) in the sense that it 
> allows a much wider array of error structures than can be used 
> in R/Splus, &etc.  
> 
> I obviously do not subscribe to these views and would like 
> to refute them, but I am not a numerical analyst and am still 
> a novice at R/Splus.  Do there exist refereed papers comparing the 
> numerical capabilities of these platforms?  If not, are there 
> other resources I might look up and pass along to my colleagues?

Although they are out of date, there are some comparisons of accuracy in

 McCullough, B. D. (1998), "Assessing the reliability of statistical
 software: Part I", The American Statistician, 52, 149-159.

 McCullough, B. D. (1999), "Assessing the reliability of statistical
 software: Part II", The American Statistician, 53, 358-366.

Regarding PROC NLMIXED versus nlme, there are a lot of differences
between them.  I don't think that PROC NLMIXED will handle nested
random effects while nlme does.  However, nlme assumes the underlying
noise is Gaussian while PROC NLMIXED allows Gaussian or binomial or
Poisson.  PROC NLMIXED uses adaptive Gaussian quadrature to evaluate
the marginal log-likelihood whereas nlme uses a less accurate
evaluation but better parameterizations of the variance of the random
effects.  I think it would be difficult to declare one to be superior
to the other.



From kwright at eskimo.com  Thu Sep  4 23:50:31 2003
From: kwright at eskimo.com (Kevin Wright)
Date: Thu, 4 Sep 2003 14:50:31 -0700 (PDT)
Subject: [R] PROC MIXED vs lme. Split-plot with heterogeneous variances. 
Message-ID: <200309042150.OAA16618@eskimo.com>

> A curious difference between SAS and R.  I wonder if anyone can explain it.
> 
> Basic idea: Split-plot design (Male = whole plot, Trt = Sub plot).  Rep is random, Rep*Male variance component is 0 and deleted.  Heterogeneous variances - each Trt has different variance.
> 
> The model with only Male and Trt as fixed effects is the same in SAS and R.  
> 
> When I add Male:Trt interaction, the results of the tests of fixed effects are no longer the same (comparing SAS and R) for Male, but are the same for Trt and Male:Trt.
> 
> Is my model specification incorrect?
> 
> Kevin Wright.  Details follow.
> 
> 
> Model with Male, Trt as fixed effects
> 
> proc mixed data=pollen ;
>   class Trt Rep Male;
>   model Yield = Male Trt;
>   random Rep;
>   repeated / group = Trt;
>   lsmeans Trt Male;
> run;
> 
>                                 Type 3 Tests of Fixed Effects
> 
>                                       Num     Den
>                         Effect         DF      DF    F Value    Pr > F
> 
>                         Male            1      47       3.64    0.0624
>                         Trt             9      47       3.80    0.0012
> 
> 
> 
> > pollen.hetero<-lme(Yield~Male+Trt,pollen,random=list(Rep=~1),
> +                    weights=varIdent(form=~1|Trt))
> > 
> > anova(pollen.hetero)
>             numDF denDF   F-value p-value
> (Intercept)     1    47 14.613222  0.0004
> Male            1    47  3.640521  0.0625
> Trt             9    47  3.797328  0.0012
> 
> 
> 
> Now add Male:Trt interaction as a fixed effect.
> 
> proc mixed data=pollen ;
>   class Trt Rep Male;
>   model Yield = Male Trt Male*Trt;
>   random Rep;
>   repeated / group = Trt;
>   lsmeans Trt Male;
> run;
> 
> 
>                                 Type 3 Tests of Fixed Effects
> 
>                                       Num     Den
>                         Effect         DF      DF    F Value    Pr > F
> 
>                         Male            1      38       0.39    0.5384
>                         Trt             9      38       8.40    <.0001
>                         Trt*Male        9      38       2.97    0.0090
> 
> > pollen.hetero<-lme(Yield~Male+Trt+Male:Trt,pollen,random=list(Rep=~1),
> +                    weights=varIdent(form=~1|Trt))
> > 
> > anova(pollen.hetero)
>             numDF denDF   F-value p-value
> (Intercept)     1    38 27.007016  <.0001
> Male            1    38  8.431796  0.0061
> Trt             9    38  8.396913  <.0001
> Male:Trt        9    38  2.964672  0.0090
> 
> 
>



From bates at stat.wisc.edu  Thu Sep  4 23:54:04 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 04 Sep 2003 21:54:04 -0000
Subject: [R] Comparison of SAS & R/Splus
In-Reply-To: <6rr82wxmml.fsf@bates4.stat.wisc.edu>
References: <940250A9EB37A24CBE28D858EF07774967AAD0@ws-bco-mse3.milky-way.battelle.org>
	<6rr82wxmml.fsf@bates4.stat.wisc.edu>
Message-ID: <6rhe3sxlrg.fsf@bates4.stat.wisc.edu>

Douglas Bates <bates at cs.wisc.edu> writes:

>  McCullough, B. D. (1998), "Assessing the reliability of statistical
>  software: Part I", The American Statistician, 52, 149-159.
> 
>  McCullough, B. D. (1999), "Assessing the reliability of statistical
>  software: Part II", The American Statistician, 53, 358-366.

In my cutting-and-pasting I got those page numbers backwards.  The 1998
article is on pages 358-366 and the 1999 one is on pages 149-159



From tlumley at u.washington.edu  Fri Sep  5 00:00:27 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 4 Sep 2003 15:00:27 -0700 (PDT)
Subject: [R] Comparison of SAS & R/Splus
In-Reply-To: <940250A9EB37A24CBE28D858EF07774967AAD0@ws-bco-mse3.milky-way.battelle.org>
Message-ID: <Pine.A41.4.44.0309041457390.61662-100000@homer37.u.washington.edu>

On Thu, 4 Sep 2003, Paul, David  A wrote:

> I am one of only 5 or 6 people in my organization making the
> effort to include R/Splus as an analysis tool in everyday work -
> the rest of my colleagues use SAS exclusively.
>
> Today, one of them made the assertion that he believes the
> numerical algorithms in SAS are superior to those in Splus
> and R -- ie, optimization routines are faster in SAS, the SAS
> Institute has teams of excellent numerical analysts that
> ensure its superiority to anything freely available, PROC
> NLMIXED is more flexible than nlme( ) in the sense that it
> allows a much wider array of error structures than can be used
> in R/Splus, &etc.


While I don't subscribe to the general theory, they have a point about
PROC NLMIXED.  It does more accurate calculations for generalised linear
mixed models than are currently available in R/S-PLUS, and for
logistic random effects models the difference can sometimes be large
enought to matter.


	-thomas



From paulda at BATTELLE.ORG  Fri Sep  5 01:06:02 2003
From: paulda at BATTELLE.ORG (Paul, David  A)
Date: Thu, 04 Sep 2003 19:06:02 -0400
Subject: SUMMARY: [R] Comparison of SAS & R/Splus
Message-ID: <940250A9EB37A24CBE28D858EF07774967AAD3@ws-bco-mse3.milky-way.battelle.org>

My thanks to Drs. Armstrong, Bates, Harrell, Liaw, Lumley, 
Prager, Schwartz, and Mr. Wang for their replies.  I have
pasted my original message and their replies below.

After viewing http://www.itl.nist.gov/div898/strd/ as suggested
by Dr. Schwartz, it occurred to me that it might be educational
to search for some data repositories on google. I was able to find 
some,though I'm sure many of the R listserv readers are already 
aware of them:

http://kdd.ics.uci.edu/
http://www.ics.uci.edu/~mlearn/MLOther.html
http://www.ldeo.columbia.edu/datarep/
http://data.geocomm.com/
http://libraries.mit.edu/gis/data/repository.html
http://nssdc.gsfc.nasa.gov/


  -david paul



-----Original Message-----
I am one of only 5 or 6 people in my organization making the 
effort to include R/Splus as an analysis tool in everyday 
work - the rest of my colleagues use SAS exclusively.

Today, one of them made the assertion that he believes the 
numerical algorithms in SAS are superior to those in Splus 
and R -- ie, optimization routines are faster in SAS, the 
SAS Institute has teams of excellent numerical analysts that 
ensure its superiority to anything freely available, PROC 
NLMIXED is more flexible than nlme( ) in the sense that it 
allows a much wider array of error structures than can be used 
in R/Splus, &etc.  

I obviously do not subscribe to these views and would like 
to refute them, but I am not a numerical analyst and am still 
a novice at R/Splus.  Do there exist refereed papers comparing the 
numerical capabilities of these platforms?  If not, are there 
other resources I might look up and pass along to my colleagues?
---------------------------

This link might give you some insight, but SAS is not one of the 
packages benchmarked here.

http://www.sciviews.org/other/benchmark.htm

   [Whit Armstrong]

---------------------------

I don't have papers comparing the numerical capabilities but I say 
bunk to your colleagues.  The last time I looked, SAS still relies 
on the out of date Gauss-Jordan sweep operator in many key places, 
in place of the QR decomposition that R and S-Plus use in regression.  
And SAS being closed source makes it impossible to see how it 
really does calculations in some cases.

See http://hesweb1.med.virginia.edu/biostat/s/doc/splus.pdf Section 
1.6 for a comparison of S and SAS (though this doesn't address 
numerical reliability).  Overall, SAS is about 11 years behind R 
and S-Plus in statistical capabilities (last year it was about 10 
years behind) in my estimation.

Frank Harrell
SAS User, 1969-1991
---
Frank E Harrell Jr    Professor and Chair            School of Medicine
                      Department of Biostatistics    Vanderbilt University

---------------------------

Too bad your colleagues weren't at the "State of Statistical 
Software" session at JSM.  I was there.  It was so packed that 
people ran out of standing room.  The three speakers are all R 
advocates (Jan De Leeuw, Luke Tierney and Duncan Temple Lang).  
The most interesting thing (to me) about the session is that the 
discussant is a person from SAS (first name Wolfgang).  I just 
had to hear what he'd say.

The SAS person essentially said that the numerical accuracy of 
R (probability functions, especially) is unmatched because the 
routines were written by authority figures in the area.  (That's 
one advantage he said R has, but also said that the fact that 
that code is open, even SAS is looking at the R source, and that, 
to him, is a disadvantage.  He obviously missed the point of 
open source.)  One of the criticisms he had for R, compared to 
SAS, is that R may not have undergone extensive QA tests.  He 
said that SAS now probably has only a handful of PROC developers 
(not exactly the "team" your colleague imagined), but 5-6 times 
more software testers.

I think hearing from the horse's mouth beats reading articles 
in the journal for this sort of things.  There was a recent article 
in American statistician bashing the numerical instability and bad 
quality of RNG in JMP (a SAS product).  SAS posted a "white paper" 
on their web site refuting some those claims (but they did changed 
the RNG to Mersenne Twister in JMP5), comparing JMP with Excel and 
SAS.  I must say that comparison isn't convincing, as neither Excel 
nor SAS can really be trusted as gold standard.

Andy [Liaw]

---------------------------

In follow up to Frank's reply, allow me to point you to some 
additional papers and articles on numerical accuracy issues. I 
have not reviewed these in some time and they may be a bit dated 
relative to current versions. These do not cover R specifically, 
but do address S-Plus and SAS. This is not an exhaustive list by 
any means, but many of the papers do have other references that 
may be of value.


1. http://www.stat.uni-muenchen.de/~knuesel/elv/accuracy.html

2. http://www.amstat.org/publications/tas/mccull-1.pdf

3. http://www.amstat.org/publications/tas/mccull.pdf

4. http://www.npl.co.uk/ssfm/download/documents/cmsc06_00.pdf


Another option is that NIST has reference datasets available for 
comparison at:

http://www.itl.nist.gov/div898/strd/

These would allow you to conduct your own comparisons if you desire.

HTH,

Marc Schwartz
(Also a former SAS user)

---------------------------

I can't say for the optimisation routines, but I have found this...

When I was doing my MSc thesis, using tree-based models and neural 
networks for classifications, I discovered something interesting.

Using SAS Enterprise Miner (SAS EM), its Tree Node is far more efficient 
than the rpart package.  Using the same (or very similar at least) parameter

settings, SAS EM can produce a tree in about 1 minute while it would take 
rpart 5 ~ 6 minutes (same data, same machine....).  Having said that, I 
still prefer rpart as it can draw a beautiful tree, whereas it is very 
difficult to fit the graphical tree produced by SAS EM into one A4 page -- 
in the end I had to use the text tree.

However, the Neural Network node in SAS EM is less efficient than nnet.  
The time it takes to fit a neural network in R using nnet is much 
faster....

Cheers,

  Kevin [Wang]

---------------------------

I suspect it will be difficult to find the answer to your colleagues' 
assertions without doing your own studies.  How important is it to you 
to settle this disagreement?

One could always name the many leading statisticians who contribute to 
R, but I don't think that name-dropping settles anything.

Nonetheless, even if SAS were faster, that would be only part of the 
issue.  As you know, R offers vastly better exploratory graphics, better 
graphics overall, far more flexible programming, user extensibility, and 
more natural programming access to the results of previous 
computations.  So even if your colleagues were right in their 
assertions, they would be overlooking many capabilities of the S 
language that are not readily available in SAS.

IMO, SAS shines in its ability to read files in almost any format, to 
handle gigantic data sets without burping, and to produce formatted 
cross-tabulations and other highly structured text reports.  However, if 
your colleagues work at all in data exploration, they are ignoring 
important tools by not exploring R or S-Plus.

 
Michael Prager, Ph.D.
NOAA Center for Coastal Fisheries and Habitat Research Beaufort, 
North Carolina  28516 http://shrimp.ccfhrb.noaa.gov/~mprager/
DISCLAIMER: Opinions expressed are personal, not official. No 
government endorsement of any commercial product is made or implied.

---------------------------

Although they are out of date, there are some comparisons of accuracy in

 McCullough, B. D. (1998), "Assessing the reliability of statistical
 software: Part I", The American Statistician, 52, 358-366.

 McCullough, B. D. (1999), "Assessing the reliability of statistical
 software: Part II", The American Statistician, 53, 149-159.

Regarding PROC NLMIXED versus nlme, there are a lot of differences 
between them.  I don't think that PROC NLMIXED will handle nested 
random effects while nlme does.  However, nlme assumes the underlying 
noise is Gaussian while PROC NLMIXED allows Gaussian or binomial or 
Poisson.  PROC NLMIXED uses adaptive Gaussian quadrature to evaluate the 
marginal log-likelihood whereas nlme uses a less accurate evaluation but 
better parameterizations of the variance of the random effects.  I think 
it would be difficult to declare one to be superior to the other.

   [Douglas Bates]

---------------------------

While I don't subscribe to the general theory, they have a point about 
PROC NLMIXED.  It does more accurate calculations for generalised linear 
mixed models than are currently available in R/S-PLUS, and for logistic 
random effects models the difference can sometimes be large enought to 
matter.


	-Thomas [Lumley]



From ggrothendieck at volcanomail.com  Fri Sep  5 02:36:21 2003
From: ggrothendieck at volcanomail.com (Gabor Grothendieck)
Date: Thu, 4 Sep 2003 17:36:21 -0700 (PDT)
Subject: [R] read.table: check.names arg - feature request
Message-ID: <20030905003621.6ED9E3BEC@sitemail.everyone.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030904/17f090cc/attachment.pl

From Ted.Harding at nessie.mcc.ac.uk  Fri Sep  5 02:52:31 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 05 Sep 2003 01:52:31 +0100 (BST)
Subject: [R] Putting regression lines on SPLOM
In-Reply-To: <200309041314.31769.deepayan@stat.wisc.edu>
Message-ID: <XFMail.030905015231.Ted.Harding@nessie.mcc.ac.uk>

Thanks, Deepayan!
However, for me this has deepened the mystery (I don't really
understand in detail how lattice graphics works anyway!).

To clarify: The variables X,Y,Z,W in DF have some zero values,
and otherwise are positive. For U,V in X,Y,Z,W I plot log(1+V)
against log(1+U) for all the points. But I regress log(V) on
log(U) using only those points where both U and V are positive
(for these data the difference between log(U) and log(1+U) is
small when U>0, and has little effect on the plot; but I want
the regression to be as stated). Can this be incorporated into
the framework you suggest below?

Thanks!
Ted.

On 04-Sep-03 Deepayan Sarkar wrote:
> You can't do it in that sequence, and whether you can do it at all
> depends on exactly what you mean when you say that the data used for
> the regressions are not the same as those used for the plots. The
> typical way would be to do 
> 
> splom(DF, 
>       panel = function(x, y, ...) {
>           panel.xyplot(x, y, ...)
> 
>           # modify x and y as appropriate (?)
>           # whether that can be done depends on whether
>           # you have all the information you need 
>           # available inside the panel function
> 
>           fm <- lm(y ~ x) 
>           panel.abline(fm)
>       })
> 
> Can't think of anything else (other than using a custom superpanel
> function).
> 
> Deepayan
> 
> On Thursday 04 September 2003 11:47 am, Ted Harding wrote:
>> Sorry Folks,
>> I'm sure I could suss out the answer myself but I need it
>> soon ... !
>>
>> 1. Given a set of 4 variables X,Y,Z,W in a dataframe DF, I make
>>    a scatter-plot matrix using splom(DF).
>>
>> 2. I do all regressions of U on V using lm(U~V), where U and V
>>    are all 12 different ordered pairs from X,Y,Z,W.
>>
>> 3. Now I would like to superpose the regression lines from (2)
>>    onto the corresponding panels from (1).
>>
>> (By the way, the data used for the regressions are not quite
>>  the same as those used for the plots, since a few observations
>>  are omitted from the regressions but appear on  the plots,
>>  so (1) and (2) really are separate operations).
>>
>> With thanks,
>> Ted.
>>
>>
>> --------------------------------------------------------------------
>> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
>> Fax-to-email: +44 (0)870 167 1972
>> Date: 04-Sep-03                                       Time: 17:47:39
>> ------------------------------ XFMail ------------------------------
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 05-Sep-03                                       Time: 01:52:31
------------------------------ XFMail ------------------------------



From Arnaud.Dowkiw at dpi.qld.gov.au  Fri Sep  5 03:37:41 2003
From: Arnaud.Dowkiw at dpi.qld.gov.au (Dowkiw, Arnaud)
Date: Fri, 5 Sep 2003 11:37:41 +1000
Subject: [R] Strange problem.
Message-ID: <200309050137.h851bmP9029243@dpi-gw1.dpi.qld.gov.au>

By the way, Dong,

you shouldn't use the term "mean" in Splus to designate the mean of your trait  (mean<-8000). "mean' is an Splus function, and by doing mean<-8000, you may experience problems when you'll need the argument "mean" to designate the original Splus function (as in the function model.tables.aov(object.aov,type="effects") for example). I tell you that because I had this problem today. Some of the function I had created and that worked before wouldn't work anymore and I realised this was because of that "mean" element that I had generated to help you solve your problem and that I forgot to erase.

Arnaud


-----Original Message-----
From: Yannong.Dong-1 [mailto:Yannong.Dong-1 at ou.edu]
Sent: Tuesday, 2 September 2003 11:21 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Strange problem.


Hi, everyone,
    I am a new user of R. Recently, I tried the following commands, but couldn't make them work. If any one of you has some ideas about it, please help me. The commands are

>std<-1000
>mean<-8000
>prior<-function(n){1/(sqrt(2*pi)*std)*exp(-1.0*(n-mean)^2/(2*std^2))}
>plot(prior,1,15000)
>post<-function(n){
+ if(n < 9543) 
+  0
+ else
+  prior(n)/n
+ }
>plot(post,1,15000)  # This command didn't work. The error message is " x and y lengths differ "

I was really confused about it because the first function "prior" can work well. I think I must make something wrong stupidly, but could not find it. If you can help me about it, it would be very helpful. Thanx a lot in advance.

   Rgds, 
   Yannong Dong

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help 

********************************DISCLAIMER******************...{{dropped}}



From ok at cs.otago.ac.nz  Fri Sep  5 03:54:53 2003
From: ok at cs.otago.ac.nz (Richard A. O'Keefe)
Date: Fri, 5 Sep 2003 13:54:53 +1200 (NZST)
Subject: [R] Finding periods, sort of.
Message-ID: <200309050154.h851srFx351205@atlas.otago.ac.nz>


A student of mine has 110 similarly structured multivariate time
series, and we're interested in methods that are practical for
thousands of them.

Basically each series describes a series of musical notes, and certain
properties of these notes are recorded.  The same set of properties
is recorded for each series.

The event times are irregular.  The number of events and the event
times are different for each series.

These are non-periodic series.  However, when you plot them, they
*look* repetitive.  That is, you have zig-zaggy bands going up and
down, and while they don't go up and down with a regular period,
the cycles do seem to have vaguely similar shapes, especially if
you smooth them.

R has been a *great* tool for exploring this stuff.  For example,
I concatenated a selection of the series and used
quantile(notes, c(0.34,0.66)) to find suitable cutoff points.
Then

library(vcd)

tern <- function (data, L = 65, U = 73, bw = 20) {
    f <- data$Note
    v <- data$Volume

    nf <- length(f)

    lo <- cumsum(v * (f < L))
    lo <- lo[(bw+1):nf] - lo[1:(nf-bw)]

    md <- cumsum(v * (f >= L & f <= U))
    md <- md[(bw+1):nf] - md[1:(nf-bw)]

    hi <- cumsum(v * (f > U))
    hi <- hi[(bw+1):nf] - hi[1:(nf-bw)]

    cv <- cumsum(v)
    cv <- cv[(bw+1):nf] - cv[1:(nf-bw)]

    ternaryplot(cbind(lo=lo/cv, md=md/cv, hi=hi/cv), lty=1)
}

produces different-looking ternary diagrams for different pieces,
which is good, because my student and I are looking for ways to
disriminate pieces.   Of course, these diagrams, by design, leave
out the time element entirely.

(I do hope that nobody has patented the idea of using ternary diagrams
to display the distribution of high, medium, and low notes in music.)

One thing we've done is to smooth fairly heavily and then (in effect)
count median-crossings to determine the number of (half-)"cycles".

But there has to be a better way to estimate the repetitiveness of
a time series than that.  I was wondering if maybe there was a way
to do a maximum likelihood estimate of seasonality using HoltWinters
as a building block, but I'm out of my depth.



From deepayan at stat.wisc.edu  Fri Sep  5 04:55:54 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 4 Sep 2003 21:55:54 -0500
Subject: [R] Putting regression lines on SPLOM
In-Reply-To: <XFMail.030905015231.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.030905015231.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <200309042155.54772.deepayan@stat.wisc.edu>


On Thursday 04 September 2003 19:52, Ted Harding wrote:
> Thanks, Deepayan!
> However, for me this has deepened the mystery (I don't really
> understand in detail how lattice graphics works anyway!).
>
> To clarify: The variables X,Y,Z,W in DF have some zero values,
> and otherwise are positive. For U,V in X,Y,Z,W I plot log(1+V)
> against log(1+U) for all the points. But I regress log(V) on
> log(U) using only those points where both U and V are positive
> (for these data the difference between log(U) and log(1+U) is
> small when U>0, and has little effect on the plot; but I want
> the regression to be as stated). Can this be incorporated into
> the framework you suggest below?

Sure. The only lattice/trellis 'style' issue relevant here is that the panel 
function is supposed to work with the x and y vectors supplied to it (and is 
not designed to easily access any extraneous information) --- other than 
that, it's as flexible as R allows you to be. 

In this case, things are slightly complicated by the fact that axis limits 
cannot be controlled in splom except as determined by the range of the data 
supplied. This means the data frame you supply has to be in the log(1+U) 
form, and the regression framed accordingly. So,

splom(log(1 + DF), 
      panel = function(x, y, ...) {
          panel.xyplot(x, y, ...)
          ok <- (x > 0) & (y > 0)
          fm <- lm(  log(exp(y[ok]) - 1) ~  log(exp(x[ok]) - 1) )
          panel.abline(fm, ...)
      }) 

Does this give you what you want ?

If it makes more sense, I can send you a modified panel.pairs which would 
allow something like

splom(DF, 
      prepanel.limits = function(x) extend.limits(range(log(1 + x))),
      panel = function(x, y, ...) {
          panel.xyplot(log(1 + x), log(1 + y), ...)
          ok <- (x > 0) & (y > 0)
          fm <- lm(  log(y[ok]) ~  log(x[ok]) )
          panel.abline(fm, ...)
      }) 

Deepayan


>
> Thanks!
> Ted.
>
> On 04-Sep-03 Deepayan Sarkar wrote:
> > You can't do it in that sequence, and whether you can do it at all
> > depends on exactly what you mean when you say that the data used for
> > the regressions are not the same as those used for the plots. The
> > typical way would be to do
> >
> > splom(DF,
> >       panel = function(x, y, ...) {
> >           panel.xyplot(x, y, ...)
> >
> >           # modify x and y as appropriate (?)
> >           # whether that can be done depends on whether
> >           # you have all the information you need
> >           # available inside the panel function
> >
> >           fm <- lm(y ~ x)
> >           panel.abline(fm)
> >       })
> >
> > Can't think of anything else (other than using a custom superpanel
> > function).
> >
> > Deepayan
> >
> > On Thursday 04 September 2003 11:47 am, Ted Harding wrote:
> >> Sorry Folks,
> >> I'm sure I could suss out the answer myself but I need it
> >> soon ... !
> >>
> >> 1. Given a set of 4 variables X,Y,Z,W in a dataframe DF, I make
> >>    a scatter-plot matrix using splom(DF).
> >>
> >> 2. I do all regressions of U on V using lm(U~V), where U and V
> >>    are all 12 different ordered pairs from X,Y,Z,W.
> >>
> >> 3. Now I would like to superpose the regression lines from (2)
> >>    onto the corresponding panels from (1).
> >>
> >> (By the way, the data used for the regressions are not quite
> >>  the same as those used for the plots, since a few observations
> >>  are omitted from the regressions but appear on  the plots,
> >>  so (1) and (2) really are separate operations).
> >>
> >> With thanks,
> >> Ted.



From wwang30 at jhmi.edu  Fri Sep  5 05:35:17 2003
From: wwang30 at jhmi.edu (Wenyi Wang)
Date: Thu, 04 Sep 2003 23:35:17 -0400
Subject: [R] Two questions about building R add-on package
Message-ID: <sf57cc43.005@cis27.hosts.jhmi.edu>

Hi, 

I am a new user of R and am building an R add-on package. I followed the
"Writing R Extension" manual from cran website but still met some
problems that I cannot solve. I build it under redhat linux 9.0 R1.7.0. 
Say foo is the name of the package.

First, after I wrote the Rd files for each function in the package, R
CMD check keep giving error message:
"*checking Rd files....OK
.....................
*checking foo-manual.tex....ERROR
Could not creat DVI version. 
This typically indicates Rd problems."

But if I use R CMD Rd2dvi with each Rd File (I have totally 8 Rd files
for 8 functions), the dvi files are created with no problem.  Even after
that, the R CMD check still give the same error message. I wonder if
anyone has met similar problem before and how you solved it.

Second, I was looking for a way to compile the package for Windows R.  I
tried two ways to compile it. 

    a.I used cygwin,mwing32 and perl as provided on
www.stats.ox.ac.uk/pub/Rtools, and compiled the package under windowsME
MS-DOS window with those tools installed.  The major problem was
incurred by .dll file.  As in the package, for the functions to work
properly, we need to call a C file, which in windows R has to be
converted to .dll file.  So even though foo.dll file was created by
cygwin, I cannot dyn.load it under winME R1.7.1. Interestingly, I CAN
dyn.load the same file under win2000 R1.5.1 and winXP R1.7.1.  But, as
we are concerned about the users with WinME installed on their computer,
we want to make the dll file work under winME as well.

   b. I also tried to cross-compile the package under linux, which was
said able to solve the dll problem.  I followed "Building Microsoft
Windows Versions of R and R packages under Intel Linux$)A!1 by Jun Yan and
A. J. Rossini and used their Makefile.  But it kept giving error
message:
" making DLL...
  console.c:22: config.h: No such file or directory
  make[4]: *** [console.o] Error 1
  make[3]: *** [libR] Error 2
  make[2]: *** [src/foo.dll] Error 2
  make[1]: *** [pkg-foo] Error 2
....."

If anyone knows about these problems, please give me a hand.  Your help
is very important to me.  Thank you very much.

Best Regards,
Wenyi



From s195404 at student.uq.edu.au  Fri Sep  5 07:03:51 2003
From: s195404 at student.uq.edu.au (Andrew C. Ward)
Date: Fri,  5 Sep 2003 05:03:51 +0000
Subject: [R] laplace transform
In-Reply-To: <Pine.LNX.4.21.0309041628180.4232-100000@carbon>
References: <Pine.LNX.4.21.0309041628180.4232-100000@carbon>
Message-ID: <1062738231.3f58193753495@my.uq.edu.au>

Dear Luca,

I don't think that R has a built-in function for doing
Laplace or inverse Laplace transforms. I remember having to
use an IMSL routine (INLP, I think) to do this many years
ago. When I looked at the article that the algorithm was
based on, I found that as an example the author showed how
well the method worked when inverting 1/s! Presumably, 
things have improved since then.

A Google search of (numerical "inverse laplace transform")
yields a number of references that should get you started.
If you write some R code to do this, think about submitting
it to CRAN. Even though a lot of R/S code is devoted to
statistical methods, there's no reason at all why all kinds
of other things can't be written.
 

Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au


Quoting Luca Laghi <llaghi at foodsci.unibo.it>:

> Dear users,
> is anybody of you aware of a R command to perform laplace
> transform or
> even its inversion?
> Thank you very much.
> Luca
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From lisa at infinito.it  Fri Sep  5 07:27:18 2003
From: lisa at infinito.it (Lisa)
Date: Fri, 5 Sep 2003 07:27:18 +0200
Subject: [R] Arima seasonal
Message-ID: <000801c3736e$60171c70$5dc07550@L>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030905/eb1e0666/attachment.pl

From ripley at stats.ox.ac.uk  Fri Sep  5 10:50:11 2003
From: ripley at stats.ox.ac.uk (Brian D Ripley)
Date: Fri, 5 Sep 2003 09:50:11 +0100 (BST)
Subject: [R] Two questions about building R add-on package
In-Reply-To: <sf57cc43.005@cis27.hosts.jhmi.edu>
References: <sf57cc43.005@cis27.hosts.jhmi.edu>
Message-ID: <1110.147.162.216.107.1062751811.squirrel@webmail.stats.ox.ac.uk>


> I am a new user of R and am building an R add-on package. I followed the
> "Writing R Extension" manual from cran website but still met some
> problems that I cannot solve. I build it under redhat linux 9.0 R1.7.0.
> Say foo is the name of the package.

Do read the instructions!

> First, after I wrote the Rd files for each function in the package, R
> CMD check keep giving error message:
> "*checking Rd files....OK
> .....................
> *checking foo-manual.tex....ERROR
> Could not creat DVI version.
> This typically indicates Rd problems."
>
> But if I use R CMD Rd2dvi with each Rd File (I have totally 8 Rd files
> for 8 functions), the dvi files are created with no problem.  Even after
> that, the R CMD check still give the same error message. I wonder if
> anyone has met similar problem before and how you solved it.
>
> Second, I was looking for a way to compile the package for Windows R.  I
> tried two ways to compile it.
>
>     a.I used cygwin,mwing32 and perl as provided on
> www.stats.ox.ac.uk/pub/Rtools, and compiled the package under windowsME
> MS-DOS window with those tools installed.  The major problem was
> incurred by .dll file.  As in the package, for the functions to work
> properly, we need to call a C file, which in windows R has to be
> converted to .dll file.  So even though foo.dll file was created by
> cygwin, I cannot dyn.load it under winME R1.7.1. Interestingly, I CAN
> dyn.load the same file under win2000 R1.5.1 and winXP R1.7.1.  But, as
> we are concerned about the users with WinME installed on their computer,
> we want to make the dll file work under winME as well.

We quite explicitly say Cygwin is not supported.

>    b. I also tried to cross-compile the package under linux, which was
> said able to solve the dll problem.  I followed "Building Microsoft
> Windows Versions of R and R packages under Intel Linux$)A!1 by Jun
> Yan and A. J. Rossini and used their Makefile.  But it kept giving error
> message:
> " making DLL...
>   console.c:22: config.h: No such file or directory
>   make[4]: *** [console.o] Error 1
>   make[3]: *** [libR] Error 2
>   make[2]: *** [src/foo.dll] Error 2
>   make[1]: *** [pkg-foo] Error 2
> ....."

We quite explicitly say you need to build R first.  If Yun-Rossini do not,
take this up with them.  In any case, I rather object: all the real work
was done by the R-Windows maintainers and supplied with the R sources.

> If anyone knows about these problems, please give me a hand.  Your help
> is very important to me.  Thank you very much.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri Sep  5 11:02:45 2003
From: ripley at stats.ox.ac.uk (Brian D Ripley)
Date: Fri, 5 Sep 2003 10:02:45 +0100 (BST)
Subject: [R] Comparison of SAS & R/Splus
In-Reply-To: <Pine.A41.4.44.0309041457390.61662-100000@homer37.u.washington.edu>
References: <940250A9EB37A24CBE28D858EF07774967AAD0@ws-bco-mse3.milky-way.battelle.org>
	<Pine.A41.4.44.0309041457390.61662-100000@homer37.u.washington.edu>
Message-ID: <1145.147.162.216.107.1062752565.squirrel@webmail.stats.ox.ac.uk>


> On Thu, 4 Sep 2003, Paul, David  A wrote:
>
>> I am one of only 5 or 6 people in my organization making the
>> effort to include R/Splus as an analysis tool in everyday work - the
>> rest of my colleagues use SAS exclusively.
>>
>> Today, one of them made the assertion that he believes the
>> numerical algorithms in SAS are superior to those in Splus
>> and R -- ie, optimization routines are faster in SAS, the SAS
>> Institute has teams of excellent numerical analysts that
>> ensure its superiority to anything freely available, PROC
>> NLMIXED is more flexible than nlme( ) in the sense that it
>> allows a much wider array of error structures than can be used
>> in R/Splus, &etc.
>
>
> While I don't subscribe to the general theory, they have a point about
> PROC NLMIXED.  It does more accurate calculations for generalised linear
> mixed models than are currently available in R/S-PLUS, and for
> logistic random effects models the difference can sometimes be large
> enought to matter.

Yes.  Except that I have access to several other codes for GLMM, and
not infrequently the answers from NLMIXED are out of line with
all of the others, and are sometimes just not credible.  So
'more accurate' is as far as I am concerned remains to be proved
for SAS.

In general I find such discussions irrelvant.  I bet those users
make far, far more errors then any of these packages do so.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Ted.Harding at nessie.mcc.ac.uk  Fri Sep  5 11:06:39 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 05 Sep 2003 10:06:39 +0100 (BST)
Subject: [R] Putting regression lines on SPLOM
In-Reply-To: <200309042155.54772.deepayan@stat.wisc.edu>
Message-ID: <XFMail.030905100639.Ted.Harding@nessie.mcc.ac.uk>

Thanks, Deepayan and Andy, for suggesting solutions.

Deepayan's solution seems to work beautifully, producing exactly
what is wanted, as it stands:

On 05-Sep-03 Deepayan Sarkar wrote:
> 
  splom(log(1 + DF),
        panel = function(x, y, ...) {
            panel.xyplot(x, y, ...)
            ok <- (x > 0) & (y > 0)
            fm <- lm(  log(exp(y[ok]) - 1) ~  log(exp(x[ok]) - 1) )
            panel.abline(fm, ...)
        }) 

However, there seems to be a problem with Andy Liaw's, applied to the
same data:

  df.trans <- lapply(DF, function(x) log(1+x))  ## Do the transformation.
  splom(df.trans, panel = function(x, y, ..) {
        panel.xyplot(x, y, ...)
        fit <- lm(log(exp(y)-1) ~ log(exp(x)-1), subset = x>0 & y>0)
                panel.abline(fit)
        })

  Error in panel(x = as.numeric(z[subscripts, j]),
                 y = as.numeric(z[subscripts,  : 
                     ... used in an incorrect context

(which is the same error as I got trying an earlier suggestion of
Deepayan's).

Anyway, much obliged for all the help!

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 05-Sep-03                                       Time: 10:06:39
------------------------------ XFMail ------------------------------



From maechler at stat.math.ethz.ch  Fri Sep  5 12:18:00 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 5 Sep 2003 12:18:00 +0200
Subject: [R] gnome gui question
In-Reply-To: <Pine.LNX.4.44.0309040956390.3502-100000@localhost.localdomain>
References: <Pine.LNX.4.44.0309040956390.3502-100000@localhost.localdomain>
Message-ID: <16216.25304.197161.414412@gargle.gargle.HOWL>

>>>>> "Anne" == Anne York <york at zipcon.net>
>>>>>     on Thu, 4 Sep 2003 10:41:25 -0700 (PDT) writes:

    Anne> I have compiled R 1.7.1 with gnome and installed the
    Anne> gtkDevice on a Linux RH 8 system. This is my first use
    Anne> of this device and I have two questions about it.

    Anne> 1.  After running R --rui="gnome", the console comes
    Anne> up. To open a graphics window, I open the gtkDevice
    Anne> library [library(gtkDevice)], then start a gtk device
          ~~~~~~~
it's called a "package" .. (sorry to be a pain..)

    Anne> [gtk()]. After the library command, I receive the
    Anne> message from R that the gtk function is masked from
    Anne> package:base. Did I do something incorrect in my
    Anne> installation to receive this message? The gtk device
    Anne> does open and appears to work, so maybe this is a
    Anne> "play on".

yes. I'm not aware of the exact plans, but the gtk() from the
gtkDevice package should become *the* version.

    Anne> 2. In the "settings --> preferences" menu section, I
    Anne> am able to change the look (fonts and colors) for the
    Anne> console and pager. However, the corresponding section
    Anne> for the graphics window has no visible options. Is
    Anne> this normal?

yes,  help(gtk) tells you that's it's just another version of x11().
What you might be really interested is the "RGtk" package
http://www.omegahat.org/RGtk/ from Omegahat,
and its tools ("widgets").
Maybe the first screen shot link in
   http://www.omegahat.org/RGtk/ScreenShots/devices.html
can wet your appetite and make you encouraging the RGtk & gtkDevice 
authors to expand their work ... ;-)

Regards, Martin



From s195404 at student.uq.edu.au  Fri Sep  5 12:29:37 2003
From: s195404 at student.uq.edu.au (Andrew C. Ward)
Date: Fri,  5 Sep 2003 10:29:37 +0000
Subject: [R] Putting regression lines on SPLOM
In-Reply-To: <XFMail.030905100639.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.030905100639.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <1062757777.3f586591d0ef7@my.uq.edu.au>

I wonder if it's as simple as the two dots ("..") in the
splom line rather than three?

Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au


Quoting Ted Harding <Ted.Harding at nessie.mcc.ac.uk>:

> Thanks, Deepayan and Andy, for suggesting solutions.
> 
> Deepayan's solution seems to work beautifully, producing
> exactly
> what is wanted, as it stands:
> 
> On 05-Sep-03 Deepayan Sarkar wrote:
> > 
>   splom(log(1 + DF),
>         panel = function(x, y, ...) {
>             panel.xyplot(x, y, ...)
>             ok <- (x > 0) & (y > 0)
>             fm <- lm(  log(exp(y[ok]) - 1) ~ 
> log(exp(x[ok]) - 1) )
>             panel.abline(fm, ...)
>         }) 
> 
> However, there seems to be a problem with Andy Liaw's,
> applied to the
> same data:
> 
>   df.trans <- lapply(DF, function(x) log(1+x))  ## Do the
> transformation.
>   splom(df.trans, panel = function(x, y, ..) {
>         panel.xyplot(x, y, ...)
>         fit <- lm(log(exp(y)-1) ~ log(exp(x)-1), subset =
> x>0 & y>0)
>                 panel.abline(fit)
>         })
> 
>   Error in panel(x = as.numeric(z[subscripts, j]),
>                  y = as.numeric(z[subscripts,  : 
>                      ... used in an incorrect context
> 
> (which is the same error as I got trying an earlier
> suggestion of
> Deepayan's).
> 
> Anyway, much obliged for all the help!
> 
> Best wishes,
> Ted.
> 
> 
> ----------------------------------------------------------
----------
> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 167 1972
> Date: 05-Sep-03                                      
> Time: 10:06:39
> ------------------------------ XFMail
> ------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From Ted.Harding at nessie.mcc.ac.uk  Fri Sep  5 12:49:06 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 05 Sep 2003 11:49:06 +0100 (BST)
Subject: [R] Putting regression lines on SPLOM
In-Reply-To: <1062757777.3f586591d0ef7@my.uq.edu.au>
Message-ID: <XFMail.030905114906.Ted.Harding@nessie.mcc.ac.uk>

Yes, that's it! Well spotted (and maybe new glasses for me ...).
Thanks! Andy's solution now also works beautifully.
Ted.

On 05-Sep-03 Andrew C. Ward wrote:
> I wonder if it's as simple as the two dots ("..") in the
> splom line rather than three?
> 
> Regards,
> 
> Andrew C. Ward


>> However, there seems to be a problem with Andy Liaw's,
>> applied to the same data:
>> 
>>   df.trans <- lapply(DF, function(x) log(1+x))  ## Do the
>> transformation.
>>   splom(df.trans, panel = function(x, y, ..) {
>>         panel.xyplot(x, y, ...)
>>         fit <- lm(log(exp(y)-1) ~ log(exp(x)-1), subset =
>> x>0 & y>0)
>>                 panel.abline(fit)
>>         })
>> 
>>   Error in panel(x = as.numeric(z[subscripts, j]),
>>                  y = as.numeric(z[subscripts,  : 
>>                      ... used in an incorrect context
>> 
>> (which is the same error as I got trying an earlier
>> suggestion of Deepayan's).

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 05-Sep-03                                       Time: 11:49:06
------------------------------ XFMail ------------------------------



From wettenhall at wehi.edu.au  Fri Sep  5 14:13:13 2003
From: wettenhall at wehi.edu.au (James Wettenhall)
Date: Fri, 5 Sep 2003 22:13:13 +1000 (EST)
Subject: [R] Installing R on Red Hat Linux, Tcl/Tk
Message-ID: <Pine.LNX.4.44.0309052141570.12867-100000@unix28.alpha.wehi.edu.au>

Hi,

I've been trying to install R on Red Hat Linux 9 for some
potential users of my R/TclTk application.  I tried using the 
rpm for R 1.7.1 for Red Hat Linux 9.  It told me that I needed:
libtcl8.3.so
so I looked for a binary release of Tcl 8.3.x on 
http://www.tcl.tk/software/tcltk/8.3.html
but found that the link to the Tcl 8.3.x binaries pointed to 
ActiveTcl 8.4.x . I couldn't see the old 8.3.x binaries 
anywhere.  ActiveTcl is a nice easy way to get the extensions 
like Tktable, but it seemed to be the wrong version.

I tried building tcl and tk 8.3 from source.  tcl was built 
succesfully and installed in /usr/local/lib/tcl8.3 but I wasn't 
able to build tk: errors like "foo has been defined previously"

Then I tried installing tcl and tk from the Red Hat CD
(using rpms).  Then when I installed R 1.7.1 from the rpm it 
seemed to work, except that:
> library(tcltk)
couldn't find a usable tk.tcl and it seemed to be 
looking in /usr/local/lib/tk8.3 whereas the rpms from the Red 
Hat CD were installed elsewhere (/usr/share/ I think) and 
rpm -i --prefix
didn't work.  (tk was "not relocatable".)

Things started to work better after I copied /usr/share/tk8.3 to 
/usr/local/lib/tk8.3/ (but I initially forgot to do the same 
with tcl so was probably using the version I built from source).

So now library(tcltk) seems to be working, but I'm getting 
segmentation faults if I try to use Tktable, after doing 
addTclPath("/usr/local/ActiveTcl/lib"). (Installing ActiveTcl 
seemed easier than building Tcl/Tk extensions from source.)

So maybe I need to build Tktable --with tcl8.3 and tk8.3.

I expect to be able to sort this out pretty soon, but I'm just 
wondering whether the R/Linux gurus out there have any general 
advice about whether it is better to use rpms or install from 
source and whether anyone has an rpm for R 1.7.x configured to 
work with libtcl8.4.so (available from ActiveTcl).   

Regards,
James



From paulda at BATTELLE.ORG  Fri Sep  5 15:03:30 2003
From: paulda at BATTELLE.ORG (Paul, David  A)
Date: Fri, 05 Sep 2003 09:03:30 -0400
Subject: [R] Comparison of SAS & R/Splus
Message-ID: <940250A9EB37A24CBE28D858EF07774967AAD5@ws-bco-mse3.milky-way.battelle.org>



 On Fri, 5 Sep 2003, Brian D. Ripley wrote:
> In general I find such discussions irrelvant.  
> I bet those users make far, far more errors then any 
> of these packages do so.

However, without having the discussions with my colleagues,
nothing will ever change.  The perception of SAS' "bestness"
flows, in my experience from several things:

a.  It was developed long before Splus and R so more people
are familiar with it, especially managers and other
decision-makers.

b.  The FDA requires SAS transport version 5 datasets, and it
is somewhat easier to use SAS throughout a clinical trial 
than to perform analyses in one package and convert data to
another at the end.

c.  Because SAS costs so much $$, it _must_ be good (dumb, but
people do think that)

d.  Because SAS is commercial software, a posteriori errors found in 
clinical trials analyses (and due to software issues) can be 
attributed by the NDA applicants to the SAS Institute.
Lawyers really like this.  Of course, Splus is also commercial 
and therefore does not suffer from criticism on these 
grounds.


It is a fact of life that building a better mousetrap does
not guarantee that the "world will beat a path to your door".
Marketing and perception are very important!  Part of my 
job involves defending choice of software, and since I'm 
swimming upstream by choosing to learn R, I need to have 
intelligent arguments to use when this choice is questioned.

Given the responses to my original post, I now do have 
those arguments in hand.  This merely confirms what is
already obvious: this is an amazing listserv!


Respectfully,

  david paul



From bido at mac.com  Fri Sep  5 15:31:59 2003
From: bido at mac.com (Francisco J. Bido)
Date: Fri, 5 Sep 2003 08:31:59 -0500
Subject: [R] Basic Dummy Variable Creation
Message-ID: <53664F83-DFA5-11D7-A3CB-000393B90A0A@mac.com>

Hi There,

While looking through the mailing list archive, I did not come across a 
simple minded example regarding the creation of dummy variables.  The 
Gauss language provides the command "y = dummydn(x,v,p)" for creating 
dummy variables.
Here:

x = Nx1 vector of data to be broken up into dummy variables.
v = Kx1 vector specifying the K-1 breakpoints
p = positive integer in the range [1,K], specifying which column should 
be dropped in the matrix of dummy variables.
y = Nx(K-1) matrix containing the K-1 dummy variables.

My recent mailing list archive inquiry has led me to examine R's 
"model.matrix" but it has so many options that I'm not seeing the 
forest because of the trees.  Is that really the easiest way? or is 
there something similar to the dummydn command described above?

To provide a concrete scenario, please consider the following.  Using 
the above notation, say, I had:

x <- c(1:10)      #data to be broken up into dummy variables
v <- c(3,5,7)     #breakpoints
p =  1                #drop this column to avoid dummy variable trap

How can I get a matrix "y" that has the associated dummy variables for 
columns?	
Thank You,
-Francisco



From MSchwartz at medanalytics.com  Fri Sep  5 15:35:48 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 05 Sep 2003 08:35:48 -0500
Subject: [R] Installing R on Red Hat Linux, Tcl/Tk
In-Reply-To: <Pine.LNX.4.44.0309052141570.12867-100000@unix28.alpha.wehi.edu.au>
References: <Pine.LNX.4.44.0309052141570.12867-100000@unix28.alpha.wehi.edu.au>
Message-ID: <1062768947.22138.41.camel@localhost>

On Fri, 2003-09-05 at 07:13, James Wettenhall wrote:
> Hi,
> 
> I've been trying to install R on Red Hat Linux 9 for some
> potential users of my R/TclTk application.  I tried using the 
> rpm for R 1.7.1 for Red Hat Linux 9.  It told me that I needed:
> libtcl8.3.so
> so I looked for a binary release of Tcl 8.3.x on 
> http://www.tcl.tk/software/tcltk/8.3.html
> but found that the link to the Tcl 8.3.x binaries pointed to 
> ActiveTcl 8.4.x . I couldn't see the old 8.3.x binaries 
> anywhere.  ActiveTcl is a nice easy way to get the extensions 
> like Tktable, but it seemed to be the wrong version.
> 
> I tried building tcl and tk 8.3 from source.  tcl was built 
> succesfully and installed in /usr/local/lib/tcl8.3 but I wasn't 
> able to build tk: errors like "foo has been defined previously"
> 
> Then I tried installing tcl and tk from the Red Hat CD
> (using rpms).  Then when I installed R 1.7.1 from the rpm it 
> seemed to work, except that:
> > library(tcltk)
> couldn't find a usable tk.tcl and it seemed to be 
> looking in /usr/local/lib/tk8.3 whereas the rpms from the Red 
> Hat CD were installed elsewhere (/usr/share/ I think) and 
> rpm -i --prefix
> didn't work.  (tk was "not relocatable".)
> 
> Things started to work better after I copied /usr/share/tk8.3 to 
> /usr/local/lib/tk8.3/ (but I initially forgot to do the same 
> with tcl so was probably using the version I built from source).
> 
> So now library(tcltk) seems to be working, but I'm getting 
> segmentation faults if I try to use Tktable, after doing 
> addTclPath("/usr/local/ActiveTcl/lib"). (Installing ActiveTcl 
> seemed easier than building Tcl/Tk extensions from source.)
> 
> So maybe I need to build Tktable --with tcl8.3 and tk8.3.
> 
> I expect to be able to sort this out pretty soon, but I'm just 
> wondering whether the R/Linux gurus out there have any general 
> advice about whether it is better to use rpms or install from 
> source and whether anyone has an rpm for R 1.7.x configured to 
> work with libtcl8.4.so (available from ActiveTcl).   
> 
> Regards,
> James


Martyn remedied an older problem with R 1.7.0 where there were some
issues with tcl/tk support and that "should not" be a problem with the 
1.7.1 RPM. He has posted the config log at:

http://cran.r-project.org/bin/linux/redhat/9/i386/configure.log

The log indicates that tcl/tk support is present in the RPMs he has
posted. Just for the sake of it, you might want to verify the MD5 hash
for the downloaded RPM to be sure that you a working with an intact
RPM.  Martyn has the values posted at:

http://cran.r-project.org/bin/linux/redhat/9/i386/md5sums

You may also be at risk for some version incompatibility related issues
given the multiple installs (RPM and source) and the copying of
particular files to non-default locations. A "mix and match"
installation could contribute to a host of problems. In addition it may
be possible that the RPM database for tcl/tk may now be compromised,
which could cause you update problems in the future, if for example, you
use RHN to secure updates from Red Hat. That may or may not be a
relevant issue for you.

Yet another problem is that if you installed any RPMS for tcl/tk that
were not specifically compiled for RH 9, you may have some problems due
to some idiosyncrasies that have been seen with the version of gcc that
comes with RH 9. 

My initial reaction would be to remove the versions (plural) of tcl/tk
that you have installed and then remove R. I would also be sure to
delete any individual files that you may have copied/moved and be sure
to remove any modifications that you may have made to any environment
variables.

Hopefully this should leave you with a clean system as far as tcl/tk is
concerned.

I would then install the RH version of tcl/tk for RH 9 which is 8.3,
verify the R 1.7.1 RPM and reinstall it. Be sure to install R after
installing tcl/tk.

An alternative, if you have a specific requirement for the 8.4 version
of tcl/tk, is to not install the RH 8.3 version at all but install the
8.4 version (either RPMS specifically for RH 9 or compile from source)
and then compile R from source (either the source tree or the source
RPM).

Others may have additional thoughts, but to go back and start with a
clean system would seem to be a reasonable requirement.

Marc Schwartz



From tlumley at u.washington.edu  Fri Sep  5 15:49:08 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 5 Sep 2003 06:49:08 -0700 (PDT)
Subject: [R] Comparison of SAS & R/Splus
In-Reply-To: <940250A9EB37A24CBE28D858EF07774967AAD5@ws-bco-mse3.milky-way.battelle.org>
Message-ID: <Pine.A41.4.44.0309050645360.136658-100000@homer05.u.washington.edu>

On Fri, 5 Sep 2003, Paul, David  A wrote:
>
> d.  Because SAS is commercial software, a posteriori errors found in
> clinical trials analyses (and due to software issues) can be
> attributed by the NDA applicants to the SAS Institute.
> Lawyers really like this.  Of course, Splus is also commercial
> and therefore does not suffer from criticism on these
> grounds.
>

Note, however, that one of the few specific pieces of guidance the FDA
gives on software is that it isn't sufficient to place your trust in
commercial off-the-shelf software (and of course this is reinforced by
the software licensing terms).


	-thomas



From paul at datavore.com  Fri Sep  5 16:31:07 2003
From: paul at datavore.com (Paul Meagher)
Date: Fri, 5 Sep 2003 11:31:07 -0300
Subject: [R] Overlaying graphs
References: <Pine.SOL.3.96.1030904155009.27672A-100000@libra.cus.cam.ac.uk>
Message-ID: <01f901c373ba$58e638e0$9141de18@computer>

From: "Damon Wischik" <djw1005 at cam.ac.uk>

> Paul Meagher wrote:
> > 2. Does R have a suite of "best-fit" tools for finding the best
> > fitting-probability distribution for any observed probability
distribution?
>
> I think that the best-fitting probability distribution for an observed
> probability distribution is the empirical distribution of your
> observations.
>
> (Perhaps you have some other criteria than just goodness of fit?)

You can certainly use the empirical distribution of observations to
construct your probability distribution and you are correct that, in some
sense, this would be the best fitting probability distribution.

Lately I have been asking myself why we bother in the first place to use
theoretical probability distributions to model our empirically
distributions.  Why not construct the probability distribution directly from
the data itself?  I think that in some cases, this is the correct route to
go.  Computers allow us to make inferences about the probability of certain
outcomes using these irregularly shaped distributions.  These inferences may
be more accurate than using any of the available theoretical probability
distributions.

The main reasons I can come up with for not using the empirical distribution
itself as your probability distribution are:

1. Over-fitting which limits your ability to generalize to new situations.
This, I think, is most important reason for engaging in the exercise of
fitting your data to a theoretical distribution.

2. It is easier to derive inferences about your random variable.  This is
the second most important reason.

3. Anyone who plays with numbers constitutionally tends towards platonism.

Regards,
Paul

> Damon.
>
>



From hmendes at ipimar.pt  Fri Sep  5 16:30:09 2003
From: hmendes at ipimar.pt (Hugo Vilela Mendes)
Date: Fri, 5 Sep 2003 15:30:09 +0100
Subject: [R] multivariate spec.ar
Message-ID: <002d01c373ba$356c7f00$85040a0a@HMendes>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030905/e32b0bdb/attachment.pl

From rpugh at mango-solutions.com  Fri Sep  5 16:33:44 2003
From: rpugh at mango-solutions.com (rpugh)
Date: Fri, 5 Sep 2003 15:33:44 +0100
Subject: [R] Comparison of SAS & R/Splus
In-Reply-To: <Pine.A41.4.44.0309050645360.136658-100000@homer05.u.washington.edu>
Message-ID: <000501c373ba$b8b58140$36968651@vsn.local>

Sorry - couldn't resist chipping in.

Firstly, this sort of conversation has been done over and over again on
the S-News list, and I'd look in the archives for more info.

My background: I was a SAS "statistical programmer" in the pharma
industry before I joined Insightful (S-PLUS guys).  I now work at Mango
Solutions (an independent consulting firm) so don't feel I'm
particularly biased to either S, R or SAS.

IN MY OPINION, the issue of "comparing" SAS to S/R is a strange one,
because the technologies had very different upbringings.  The tools are
also aimed at serving different jobs, and that can really sum up the
differences in one sentence: SAS is a data language, S/R are
analysis/visualization languages.

On your point about when the different softwares were "developed", I
believe both languages were developed in the 70s.  The real difference
is when the systems were "commercialized": SAS in the 70s, S-PLUS in the
90s.  That's where the difference in "time lines" occur.

As far as comparisons are concerned, I would go as far as saying that
you "CAN" do everything in S/R that you can do in SAS and vice-versa.
The important factor is often "how easy" it is to do those things.  For
example, you can create extremely complex graphics in SAS using things
like Proc Annotate, but I wouldn't recommend it.  This again comes back
to the different aims of SAS/S/R: in my experience, data manipulation
and basic reporting can be "easier" in SAS, while fitting stats
models/creating graphics is far better in S/R.

So, why is SAS so heavily used in (say) the pharma industry nowadays?
Firstly, ask yourself how long it would take to rewrite every SAS
macro/application your company uses today, or how much has been invested
in SAS training over the last 10-20 years.  Very often, issues such as
these can dominate discussions about transferring to S/R/Whatever.

Having said this, I do know a number of pharma companies who are looking
to move away from SAS.  The key here is to take it slowly.  There's no
way you can just decide to switch from SAS to S/R overnight.  The best
way of going from SAS to S/R is to look at replacing SAS modules
gradually.  For example, how about replacing SAS/GRAPH, SAS/STAT,
SAS/IML, SAS/ASSIST, SAS/Access and SAS/INSIGHT with S-PLUS or R?  In
most countries, this will save a good deal of money which can be spent
on training/consulting to ensure everyone can get up to speed with S/R.

As far as the FDA is concerned, they do not support any commercial
software, and I know that SAS and S-PLUS are used there.  As far as
providing transport files is concerned, that doesn't particularly
restrict the choice of package.  Plus, I can't see this standard lasting
- personally I believe that CDISC (or a version of it) will catch on.
www.cdisc.org for more info.

At the end of the day, SAS, S and R are all good technologies, and the
"best one" to use completely depends on what needs to be achieved.

Sorry for the long rambling email ... I'd happily chat more about this
with people "offline" ...

Cheers,
Rich.

Mango Solutions

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Thomas Lumley
Sent: 05 September 2003 14:49
To: Paul, David A
Cc: r-help at stat.math.ethz.ch
Subject: RE: [R] Comparison of SAS & R/Splus

On Fri, 5 Sep 2003, Paul, David  A wrote:
>
> d.  Because SAS is commercial software, a posteriori errors found in
> clinical trials analyses (and due to software issues) can be
> attributed by the NDA applicants to the SAS Institute.
> Lawyers really like this.  Of course, Splus is also commercial
> and therefore does not suffer from criticism on these
> grounds.
>

Note, however, that one of the few specific pieces of guidance the FDA
gives on software is that it isn't sufficient to place your trust in
commercial off-the-shelf software (and of course this is reinforced by
the software licensing terms).


	-thomas

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help

---
Incoming mail is certified Virus Free.



From maechler at stat.math.ethz.ch  Fri Sep  5 16:36:45 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 5 Sep 2003 16:36:45 +0200
Subject: [R] scatter.smooth warning "k-d tree" --> "loess bowels"
In-Reply-To: <sf573dfd.047@MAIL.NDRI.ORG>
References: <sf573dfd.047@MAIL.NDRI.ORG>
Message-ID: <16216.40829.226874.780682@gargle.gargle.HOWL>

>>>>> "Peter" == Peter Flom <flom at ndri.org>
>>>>>     on Thu, 04 Sep 2003 13:28:12 -0400 writes:

    Peter> Hello When I run

    Peter> scatter.smooth(jitter(weight), jitter(height2), span
    Peter>                = .25, evaluation = 50, pch = '.')

    Peter> I get the type of graph I thought I would get, but
    Peter> also a warning.....

 (and not an "error" as said in the original Subject)

    Peter> k-d tree limited by memory. ncmax= 528


    Peter> I always get concerned when there are warnings I
    Peter> don't understand.  What's a k-d tree?  Is this
    Peter> something to be concerned about?

scatter.smooth() builds on loess() and the reference in
help(loess) is chapter 8 of "the white book",

     W.S. Cleveland, E. Grosse and W.M. Shyu (1992) Local regression
     models. Chapter 8 of _Statistical Models in S_ eds J.M. Chambers
     and T.J. Hastie, Wadsworth & Brooks/Cole.

Specifically, Section 8.4.2, p.373-376 is what you need here.
You can learn that a k-d tree is the data structure used to
represent a particular kind of "rpart()"-like partitioning of
the predictor space.
(The fun part is in the subsection "Error Messages from the Bowels of Loess"
 where you learn why you can even get an error message  "Chernobyl! ...")

---

The warning means that the loess() approximation will be a bit
more rough than might be desired.,
since help(loess.control) has

  >> Usage:
  >> 
  >>      loess.control(surface = c("interpolate", "direct"),
  >>                    statistics = c("approximate", "exact"),
  >>                    trace.hat = c("exact", "approximate"),
  >>                    cell = 0.2, iterations = 4, ...)
  >> 
  >> Arguments:
  >> 
  >>  surface: should be fitted surface be computed exactly or via
  >>           interpolation from a kd tree?

By setting surface = "direct" you will certainly get rid of the
above warning, but probably pay a (too) big performance penalty.

Unfortunately the loess-underlying Fortran code is pretty messy
(with many dozens of subroutines called ehg125(), ehg126(), ....)
so that it's not obvious how to improve it to adapt memory usage
to the size of the k-d tree used.  I'm pretty sure that today's
computers would allow much larger trees than the loess()
algorithm was made to.

Regards,
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From solares at unsl.edu.ar  Fri Sep  5 16:39:18 2003
From: solares at unsl.edu.ar (solares@unsl.edu.ar)
Date: Fri, 5 Sep 2003 11:39:18 -0300 (ART)
Subject: [R] skins in R?
Message-ID: <53831.170.210.173.216.1062772758.squirrel@inter14.unsl.edu.ar>

Hello, it wanted to know if exists in R any package that carry out skins on 
the widget of tcl, rounded button style window XP.  Thanks Ruben



From rossini at blindglobe.net  Fri Sep  5 15:33:11 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Fri, 05 Sep 2003 06:33:11 -0700
Subject: [R] Two questions about building R add-on package
In-Reply-To: <1110.147.162.216.107.1062751811.squirrel@webmail.stats.ox.ac.uk>
	(Brian
	D. Ripley's message of "Fri, 5 Sep 2003 09:50:11 +0100 (BST)")
References: <sf57cc43.005@cis27.hosts.jhmi.edu>
	<1110.147.162.216.107.1062751811.squirrel@webmail.stats.ox.ac.uk>
Message-ID: <858yp38inc.fsf@blindglobe.net>

Brian D Ripley <ripley at stats.ox.ac.uk> writes:

> From <wwang30 at jhmi.edu>

> > Windows Versions of R and R packages under Intel Linux$)A!1 by Jun
> > Yan and A. J. Rossini and used their Makefile.  But it kept giving error

> We quite explicitly say you need to build R first.  If Yun-Rossini do not,

As far as I know, I've never seem a "Yun-Rossini" article. 

> take this up with them.

We (the Yan-Rossini article) do explicitly state this.

> In any case, I rather object: all the real work was done by the
> R-Windows maintainers and supplied with the R sources. 

And we simply automated the process a bit, as was claimed.  Why do you
"rather object"? 

If you put it that way, all the real work processing work was done by
the GCC team.  You simply automated the process a bit with a bit of
code for this thing called R.

best,
-tony

-- 
A.J. Rossini     			
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW   :              FAX=206-543-3461 | moving soon to a permanent office
FHCRC: 206-667-7025 FAX=206-667-4812 | Voicemail is pretty sketchy/use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From Arne.Muller at aventis.com  Fri Sep  5 17:07:59 2003
From: Arne.Muller at aventis.com (Arne.Muller@aventis.com)
Date: Fri, 5 Sep 2003 17:07:59 +0200
Subject: [R] all values from a data frame
Message-ID: <C80ECAFA2ACC1B45BE45D133ED660ADECDCAD0@crbsmxsusr04.pharma.aventis.com>

Hello,

I've a data frame with 15 colums and 6000 rows, and I need the data in a
single vector of size 90000 for ttest. Is there such a conversion function in
R, or would I have to write my own loop over the colums?

	thanks for your help + kind regards

	Arne



From Ted.Harding at nessie.mcc.ac.uk  Fri Sep  5 17:04:34 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 05 Sep 2003 16:04:34 +0100 (BST)
Subject: [R] Putting regression lines on SPLOM
In-Reply-To: <XFMail.030904174739.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <XFMail.030905160434.Ted.Harding@nessie.mcc.ac.uk>

Another query:

I'm now trying to have the x- and y-axes all on the same scale
(0:15) in every panel, whereas the default behaviour of splom
is to scale them according to the ranges of the individual
variables in each panel.

So I tried (emulating the responses to my earlier query):

  splom(log(1+DF), panel = function(x, y, ... ) {
        panel.xyplot(x, y, xlim=c(0,15),ylim=c(0,15))
       })

And it appears that the 'xlim' and 'ylim' specifications are
ignored (i.e. the behaviour is exactly the same as

  splom(log(1+DF)).

?panel.xyplot refers you to ?xyplot for "further arguments",
and ?xyplot certainly specifies the above form for specifying
x- and y-limits. I think ...

With thanks as always for any help,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 05-Sep-03                                       Time: 16:04:34
------------------------------ XFMail ------------------------------



From Simon.Fear at synequanon.com  Fri Sep  5 17:18:37 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Fri, 5 Sep 2003 16:18:37 +0100
Subject: [R] all values from a data frame
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572D273D0@synequanon01>

Use unlist.

In any case, don't write an explicit "loop over 
the columns". See ?lapply instead.

> -----Original Message-----
> From: Arne.Muller at aventis.com [mailto:Arne.Muller at aventis.com]
> Sent: 05 September 2003 16:08
> To: r-help at stat.math.ethz.ch
> Subject: [R] all values from a data frame
> 
> 
> Security Warning:
> If you are not sure an attachment is safe to open please contact 
> Andy on x234. There are 0 attachments with this message.
> ________________________________________________________________
> 
> Hello,
> 
> I've a data frame with 15 colums and 6000 rows, and I need 
> the data in a
> single vector of size 90000 for ttest. Is there such a conversion
> function in
> R, or would I have to write my own loop over the colums?
> 
> 	thanks for your help + kind regards
> 
> 	Arne
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
 

Simon Fear
Senior Statistician
Syne qua non Ltd
Tel: +44 (0) 1379 644449
Fax: +44 (0) 1379 644445
email: Simon.Fear at synequanon.com
web: http://www.synequanon.com
 
Number of attachments included with this message: 0
 
This message (and any associated files) is confidential and\...{{dropped}}



From jfox at mcmaster.ca  Fri Sep  5 17:39:26 2003
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 05 Sep 2003 11:39:26 -0400
Subject: [R] all values from a data frame
In-Reply-To: <C80ECAFA2ACC1B45BE45D133ED660ADECDCAD0@crbsmxsusr04.pharma
	.aventis.com>
Message-ID: <5.1.0.14.2.20030905113830.01f8a420@127.0.0.1>

Dear Arne,

At 05:07 PM 9/5/2003 +0200, Arne.Muller at aventis.com wrote:
>Hello,
>
>I've a data frame with 15 colums and 6000 rows, and I need the data in a
>single vector of size 90000 for ttest. Is there such a conversion function in
>R, or would I have to write my own loop over the colums?
>
>         thanks for your help + kind regards

unlist() should do what you want.

I hope that this helps,
  John

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From partha_bagchi at hgsi.com  Fri Sep  5 17:25:11 2003
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Fri, 5 Sep 2003 11:25:11 -0400
Subject: [R] all values from a data frame
Message-ID: <OFACC9A294.2349665B-ON85256D98.005460E9-85256D98.0054B494@hgsi.com>

If I understand you correctly, you want to stack the 15 columns on top of 
one another? I assuming all the data is numeric?

In this case, convert the data.frame to a matrix and set the dim of the 
matrix to NULL.

If df is the data.frame,
df1 <- as.matrix(df)
dim(df1) <- NULL






<Arne.Muller at aventis.com>
Sent by: r-help-bounces at stat.math.ethz.ch
09/05/2003 11:07 AM

 
        To:     <r-help at stat.math.ethz.ch>
        cc: 
        Subject:        [R] all values from a data frame


Hello,

I've a data frame with 15 colums and 6000 rows, and I need the data in a
single vector of size 90000 for ttest. Is there such a conversion function 
in
R, or would I have to write my own loop over the colums?

thanks for your help + kind regards

Arne

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help

--
This message has been scanned for viruses and
dangerous content by MailScanner, and is
believed to be clean.



From jfox at mcmaster.ca  Fri Sep  5 17:50:59 2003
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 05 Sep 2003 11:50:59 -0400
Subject: [R] Basic Dummy Variable Creation
In-Reply-To: <53664F83-DFA5-11D7-A3CB-000393B90A0A@mac.com>
Message-ID: <5.1.0.14.2.20030905113940.01ff5c00@127.0.0.1>

Dear Francisco,

At 08:31 AM 9/5/2003 -0500, Francisco J. Bido wrote:
>Hi There,
>
>While looking through the mailing list archive, I did not come across a 
>simple minded example regarding the creation of dummy variables.  The 
>Gauss language provides the command "y = dummydn(x,v,p)" for creating 
>dummy variables.
>Here:
>
>x = Nx1 vector of data to be broken up into dummy variables.
>v = Kx1 vector specifying the K-1 breakpoints
>p = positive integer in the range [1,K], specifying which column should be 
>dropped in the matrix of dummy variables.
>y = Nx(K-1) matrix containing the K-1 dummy variables.
>
>My recent mailing list archive inquiry has led me to examine R's 
>"model.matrix" but it has so many options that I'm not seeing the forest 
>because of the trees.  Is that really the easiest way? or is there 
>something similar to the dummydn command described above?
>
>To provide a concrete scenario, please consider the following.  Using the 
>above notation, say, I had:
>
>x <- c(1:10)      #data to be broken up into dummy variables
>v <- c(3,5,7)     #breakpoints
>p =  1                #drop this column to avoid dummy variable trap
>
>How can I get a matrix "y" that has the associated dummy variables for 
>columns?
>Thank You,
>-Francisco

My initial question would be why do you want to do this? Statistical-model 
formulas in R implicitly generate dummy variables (and other contrasts) 
directly from factors, so if this is the context that you had in mind, 
there's no need to generate the dummy variables explicitly.

If you really do want the matrix of dummy regressors, say for a factor 
named "factor," then you can use model.matrix() to get them. Because the 
default contrast type for unordered factors is "contr.treatment", which 
corresponds to 0/1 dummy regressors, you can get the dummy variables as 
model.matrix(~factor)[,-1]. Here I've removed the initial column of ones 
returned by model matrix. Alternatively, model.matrix(~ factor - 1) gives 
you a complete set of dummy regressors; you could then drop whichever 
column you wanted to.

More generally, if you haven't already done so you might see how 
linear-model formulas are implemented in R. All of the introductions to R 
cover this topic. I think that this is one of the strengths of the S 
language, by the way.

I hope that this helps,
  John
-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From pete at sprint.net  Fri Sep  5 17:50:44 2003
From: pete at sprint.net (Peter Whiting)
Date: Fri, 5 Sep 2003 10:50:44 -0500
Subject: [R] eliminating a large subset of data from a frame
Message-ID: <20030905155044.GA5440@sprint.net>

I have a data frame with 155,000 rows. One of the columns
represents the user id (of which about 10,000 are unique).  I am
able to isolate 1000 of these user ids (stored in a list) that
I want to eliminate from the data set, but I don't know of an
efficient way to do this. Certainly this would be slow:

newdf<-df
for(i in listofbadusers) {
 newdf<-subset(tmp,uid!=i)
}

is there a better approach?

I guess I could use the opposite logic and use a list of
good users and add their data to the new frame...

thanks,
pete



From chrysopa at insecta.ufv.br  Fri Sep  5 15:35:30 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Fri, 5 Sep 2003 10:35:30 -0300
Subject: [R] [Off] Ecological Modelling's Book Suggestion.
Message-ID: <200309051035.31005.chrysopa@insecta.ufv.br>

Hi,

Anybody can suggest a good Ecological Modelling's Book.

Thanks
Ronaldo
-- 
O c?u sueco.
                -- pal?ndromo
--
|>   // | \\   [***********************************]
|   ( ?   ? )  [Ronaldo Reis J?nior                ]
|>      V      [UFV/DBA-Entomologia                ]
|    /     \   [36571-000 Vi?osa - MG              ]
|>  /(.''`.)\  [Fone: 31-3899-2532                 ]
|  /(: :'  :)\ [chrysopa at insecta.ufv.br            ]
|>/ (`. `'` ) \[ICQ#: 5692561 | LinuxUser#: 205366 ]
|    ( `-  )   [***********************************]
|>>  _/   \_Powered by GNU/Debian Woody/Sarge



From Simon.Fear at synequanon.com  Fri Sep  5 18:02:28 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Fri, 5 Sep 2003 17:02:28 +0100
Subject: [R] eliminating a large subset of data from a frame
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572AC0DB6@synequanon01>

I can't see what would be wrong with

newdf <- subset(df, uid %in% listofgoodusers)
or
newdf <- subset(df, !(uid %in% listofbadusers))

Is this what you want? Please note the code you supplied will
not run at all, let alone slowly, so it is not easy to know exactly
what you are trying to achieve

> -----Original Message-----
> newdf<-df
> for(i in listofbadusers) {
>  newdf<-subset(tmp,uid!=i)
> }
 

Simon Fear
Senior Statistician
Syne qua non Ltd
Tel: +44 (0) 1379 644449
Fax: +44 (0) 1379 644445
email: Simon.Fear at synequanon.com
web: http://www.synequanon.com
 
Number of attachments included with this message: 0
 
This message (and any associated files) is confidential and\...{{dropped}}



From bates at stat.wisc.edu  Fri Sep  5 18:12:27 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 05 Sep 2003 16:12:27 -0000
Subject: [R] Basic Dummy Variable Creation
In-Reply-To: <53664F83-DFA5-11D7-A3CB-000393B90A0A@mac.com>
References: <53664F83-DFA5-11D7-A3CB-000393B90A0A@mac.com>
Message-ID: <6rwucnxlh9.fsf@bates4.stat.wisc.edu>

"Francisco J. Bido" <bido at mac.com> writes:

> Hi There,
> 
> While looking through the mailing list archive, I did not come across
> a simple minded example regarding the creation of dummy variables.
> The Gauss language provides the command "y = dummydn(x,v,p)" for
> creating dummy variables.
> 
> Here:
> 
> x = Nx1 vector of data to be broken up into dummy variables.
> v = Kx1 vector specifying the K-1 breakpoints
> p = positive integer in the range [1,K], specifying which column
> should be dropped in the matrix of dummy variables.
> 
> y = Nx(K-1) matrix containing the K-1 dummy variables.
> 
> My recent mailing list archive inquiry has led me to examine R's
> "model.matrix" but it has so many options that I'm not seeing the
> forest because of the trees.  Is that really the easiest way? or is
> there something similar to the dummydn command described above?
> 
> 
> To provide a concrete scenario, please consider the following.  Using
> the above notation, say, I had:
> 
> 
> x <- c(1:10)      #data to be broken up into dummy variables
> v <- c(3,5,7)     #breakpoints
> p =  1                #drop this column to avoid dummy variable trap
> 
> How can I get a matrix "y" that has the associated dummy variables for
> columns?

Don't.

Consider why you want the dummy variables.  You probably want to use
them in the specification of a statistical model and R's model
specification language automatically expands a factor variable into a
set of contrasts.

Try

data(PlantGrowth)
fm = lm(weight ~ group, data = PlantGrowth)
summary(fm)

and you will see that the `group' factor has been expanded to two of
the three indicator variables (if you use the default setting for
contrasts - other possibilities exist).

You can check explicitly how the model matrix is created with

model.matrix(fm)

The model specification facilities in R are much more flexible than
most other languages and you almost never need to create indicators
explicitly.



From ligges at statistik.uni-dortmund.de  Fri Sep  5 18:16:20 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 05 Sep 2003 18:16:20 +0200
Subject: [R] eliminating a large subset of data from a frame
In-Reply-To: <20030905155044.GA5440@sprint.net>
References: <20030905155044.GA5440@sprint.net>
Message-ID: <3F58B6D4.2050606@statistik.uni-dortmund.de>

Peter Whiting wrote:

> I have a data frame with 155,000 rows. One of the columns
> represents the user id (of which about 10,000 are unique).  I am
> able to isolate 1000 of these user ids (stored in a list) that
> I want to eliminate from the data set, but I don't know of an
> efficient way to do this. Certainly this would be slow:
> 
> newdf<-df
> for(i in listofbadusers) {
>  newdf<-subset(tmp,uid!=i)
> }

What about subsetting? See help("[").

One solution (not saying it is the optimal one):

  newdf <- df[!(df$uid %in% listofbadusers), ]

Uwe Ligges

> is there a better approach?
> 
> I guess I could use the opposite logic and use a list of
> good users and add their data to the new frame...
> 
> thanks,
> pete
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From p.dalgaard at biostat.ku.dk  Fri Sep  5 18:31:34 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri, 05 Sep 2003 16:31:34 -0000
Subject: [R] Basic Dummy Variable Creation
In-Reply-To: <6rwucnxlh9.fsf@bates4.stat.wisc.edu>
References: <53664F83-DFA5-11D7-A3CB-000393B90A0A@mac.com>
	<6rwucnxlh9.fsf@bates4.stat.wisc.edu>
Message-ID: <x265k7qjpc.fsf@biostat.ku.dk>

Douglas Bates <bates at stat.wisc.edu> writes:

> > x <- c(1:10)      #data to be broken up into dummy variables
> > v <- c(3,5,7)     #breakpoints
> > p =  1                #drop this column to avoid dummy variable trap
> > 
> > How can I get a matrix "y" that has the associated dummy variables for
> > columns?
> 
> Don't.
> 
> Consider why you want the dummy variables.  You probably want to use
> them in the specification of a statistical model and R's model
> specification language automatically expands a factor variable into a
> set of contrasts.

... However, if you insist on seeing what goes on behind the scenes,
try

 x <- c(1:10)
 vv <- c(-Inf,v,Inf)
 f <- cut(x,vv)
 model.matrix(~f)
 model.matrix(~f)[,-1]
 model.matrix(~f-1)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From bido at mac.com  Fri Sep  5 18:34:21 2003
From: bido at mac.com (Francisco J. Bido)
Date: Fri, 5 Sep 2003 11:34:21 -0500
Subject: [R] Basic Dummy Variable Creation
In-Reply-To: <6rwucnxlh9.fsf@bates4.stat.wisc.edu>
Message-ID: <CD618494-DFBE-11D7-A3CB-000393B90A0A@mac.com>

Thanks Douglas,

I see what your saying.  One of the reasons that I ask this question 
(besides being a complete R rookie) is to obtain good form and habits.  
R seems to be extremely capable and flexible (and of course also pretty 
dense) thank God for the mailing list.  Your example and the feedback 
provided by others on the list provide very good guidance.  I got this 
one down.  Thanks again!

-Francisco



On Friday, September 5, 2003, at 11:12 AM, Douglas Bates wrote:

> "Francisco J. Bido" <bido at mac.com> writes:
>
>> Hi There,
>>
>> While looking through the mailing list archive, I did not come across
>> a simple minded example regarding the creation of dummy variables.
>> The Gauss language provides the command "y = dummydn(x,v,p)" for
>> creating dummy variables.
>>
>> Here:
>>
>> x = Nx1 vector of data to be broken up into dummy variables.
>> v = Kx1 vector specifying the K-1 breakpoints
>> p = positive integer in the range [1,K], specifying which column
>> should be dropped in the matrix of dummy variables.
>>
>> y = Nx(K-1) matrix containing the K-1 dummy variables.
>>
>> My recent mailing list archive inquiry has led me to examine R's
>> "model.matrix" but it has so many options that I'm not seeing the
>> forest because of the trees.  Is that really the easiest way? or is
>> there something similar to the dummydn command described above?
>>
>>
>> To provide a concrete scenario, please consider the following.  Using
>> the above notation, say, I had:
>>
>>
>> x <- c(1:10)      #data to be broken up into dummy variables
>> v <- c(3,5,7)     #breakpoints
>> p =  1                #drop this column to avoid dummy variable trap
>>
>> How can I get a matrix "y" that has the associated dummy variables for
>> columns?
>
> Don't.
>
> Consider why you want the dummy variables.  You probably want to use
> them in the specification of a statistical model and R's model
> specification language automatically expands a factor variable into a
> set of contrasts.
>
> Try
>
> data(PlantGrowth)
> fm = lm(weight ~ group, data = PlantGrowth)
> summary(fm)
>
> and you will see that the `group' factor has been expanded to two of
> the three indicator variables (if you use the default setting for
> contrasts - other possibilities exist).
>
> You can check explicitly how the model matrix is created with
>
> model.matrix(fm)
>
> The model specification facilities in R are much more flexible than
> most other languages and you almost never need to create indicators
> explicitly.
>



From bido at mac.com  Fri Sep  5 18:52:20 2003
From: bido at mac.com (Francisco J. Bido)
Date: Fri, 5 Sep 2003 11:52:20 -0500
Subject: [R] R Documentation with Emphasis on Econometrics
In-Reply-To: <858yp38inc.fsf@blindglobe.net>
Message-ID: <5079125D-DFC1-11D7-A3CB-000393B90A0A@mac.com>

Hi Everyone,

There's a lot of good documentation out there but I haven't come across 
one that makes econometrics it's primary focus.  Do any of
you know of any?

Thanks,
-Francisco



From kjetil at entelnet.bo  Fri Sep  5 18:54:21 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Fri, 05 Sep 2003 12:54:21 -0400
Subject: [R] Basic Dummy Variable Creation
In-Reply-To: <53664F83-DFA5-11D7-A3CB-000393B90A0A@mac.com>
Message-ID: <3F58877D.18407.707CA1@localhost>

On 5 Sep 2003 at 8:31, Francisco J. Bido wrote:

Yes, model matrix is the answer, and if it has many arguments, it 
also has many reasonable defaults.  When I am trying out a new 
function, I just accept the dafaults for a starter.

> 
> x <- c(1:10)      #data to be broken up into dummy variables
> v <- c(3,5,7)     #breakpoints
> p =  1                #drop this column to avoid dummy variable trap
> 

What about 
f <- cut(x, breaks=c(0,3,5,7,10)
y <- model.matrix( ~ f)

(model matrix will drop the first column for you), and make a column 
for the intercept)
If you want all the columns, and no intercept, replace with

y <- model.matrix( ~ y - 1)
or even 
y <- model.matrix( ~y + 0)

Kjetil Halvorsen


> How can I get a matrix "y" that has the associated dummy variables for 
> columns?	
> Thank You,
> -Francisco
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From bbenthul at ppacg.org  Fri Sep  5 19:29:14 2003
From: bbenthul at ppacg.org (Bart Benthul)
Date: Fri, 5 Sep 2003 11:29:14 -0600
Subject: [R] R Documentation with Emphasis on Econometrics
In-Reply-To: <5079125D-DFC1-11D7-A3CB-000393B90A0A@mac.com>
Message-ID: <NAEILMBIIHLJMHEBBLPEEEOPDEAA.bbenthul@ppacg.org>

Short and basic:

http://www.buseco.monash.edu.au/depts/ebs/pubs/wpapers/2001/10-01.php

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Francisco J. Bido
Sent: Friday, September 05, 2003 10:52 AM
To: r-help at stat.math.ethz.ch
Subject: [R] R Documentation with Emphasis on Econometrics


Hi Everyone,

There's a lot of good documentation out there but I haven't come across 
one that makes econometrics it's primary focus.  Do any of
you know of any?

Thanks,
-Francisco

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From deepayan at stat.wisc.edu  Fri Sep  5 19:45:54 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri, 5 Sep 2003 12:45:54 -0500
Subject: [R] Putting regression lines on SPLOM
In-Reply-To: <XFMail.030905160434.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.030905160434.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <200309051245.54052.deepayan@stat.wisc.edu>

On Friday 05 September 2003 10:04 am, Ted Harding wrote:
> Another query:
>
> I'm now trying to have the x- and y-axes all on the same scale
> (0:15) in every panel, whereas the default behaviour of splom
> is to scale them according to the ranges of the individual
> variables in each panel.
>
> So I tried (emulating the responses to my earlier query):
>
>   splom(log(1+DF), panel = function(x, y, ... ) {
>         panel.xyplot(x, y, xlim=c(0,15),ylim=c(0,15))
>        })
>
> And it appears that the 'xlim' and 'ylim' specifications are
> ignored (i.e. the behaviour is exactly the same as
>   splom(log(1+DF)).
>

Yes, this is what I briefly mentioned in my earlier message. 

panel.xyplot does not accept arguments called xlim and ylim (see below), so 
it's not surprising that this didn't work. The panel function is responsible 
for doing the plotting only; the plotting area, along with appropriate scales 
and axes, have to be set up beforehand.

Unfortunately, the current implementation of splom (in particular the 
panel.pairs function) does not allow you to do what you want in any other way 
either (however, read on for a solution).

The usual control of axis limits in xyplot-like functions can be done in two 
ways. One, via the prepanel function, which conceptually has access to all 
the data the panel function has, and can use that to decide what the 
appropriate limits should be. The other way is explicit specification via the 
scales argument (for which xlim and ylim are a shorthand).

The prepanel function returns separate limits for x and y axes. This does not 
translate to splom, since each limit is used on both the x and y axes. 
However, it is natural to add a new optional argument, which would be a  
function that would decide on the limits for each variable in the data frame, 
to be used as both x and y limits. This feature was missing till now, but I 
have added something for the next release (source() the attached file to use 
it), which will allow you to do:

splom(log(1+DF),
      prepanel.limits = function(x) c(0, 15),
      panel = function(x, y, ... ) {
          panel.xyplot(x, y, ...)
      })

Another natural thing to do would be to extend the scales$limits option to the 
pscales argument in splom. I'll look into it.


> ?panel.xyplot refers you to ?xyplot for "further arguments",
> and ?xyplot certainly specifies the above form for specifying
> x- and y-limits. I think ...

Where exactly does it do that ? xyplot is in the "See Also" section, but how 
does that imply that arguments accepted by xyplot can be given to 
panel.xyplot ? And I don't see the phrase "further arguments" anywhere in the 
help page for panel.xyplot.

If there's anything in the documentation that even suggests that xlim and ylim 
can be passed to panel functions, that's definitely misleading, and I would 
appreciate it if you could point out any such confusing statements.

Deepayan



From deepayan at stat.wisc.edu  Fri Sep  5 19:51:13 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri, 5 Sep 2003 12:51:13 -0500
Subject: [R] Putting regression lines on SPLOM
In-Reply-To: <200309051245.54052.deepayan@stat.wisc.edu>
References: <XFMail.030905160434.Ted.Harding@nessie.mcc.ac.uk>
	<200309051245.54052.deepayan@stat.wisc.edu>
Message-ID: <200309051251.13932.deepayan@stat.wisc.edu>


Oops, forgot the attachment.

On Friday 05 September 2003 12:45 pm, Deepayan Sarkar wrote:

> The prepanel function returns separate limits for x and y axes. This does
> not translate to splom, since each limit is used on both the x and y axes.
> However, it is natural to add a new optional argument, which would be a
> function that would decide on the limits for each variable in the data
> frame, to be used as both x and y limits. This feature was missing till
> now, but I have added something for the next release (source() the attached
> file to use it), which will allow you to do:
>
> splom(log(1+DF),
>       prepanel.limits = function(x) c(0, 15),
>       panel = function(x, y, ... ) {
>           panel.xyplot(x, y, ...)
>       })
-------------- next part --------------



panel.pairs <-
    function(z, panel = "panel.splom", groups = NULL,
             panel.subscripts,
             subscripts,
             pscales = 5,
             panel.number = 0,  ## should always be supplied
             prepanel.limits = function(x) extend.limits(range(as.numeric(x), na.rm = TRUE)),
             ...)
{
    panel <- 
        if (is.function(panel)) panel 
        else if (is.character(panel)) get(panel)
        else eval(panel)

    axis.line <- trellis.par.get("axis.line")
    axis.text <- trellis.par.get("axis.text")
    n.var <- ncol(z)

    if(n.var>0) {
        ## there must be a better way to do the foll:
        lim <- list(1:n.var)
        for(i in 1:n.var) {
            lim[[i]] <- prepanel.limits(z[,i])
        }
        ## should be further complicated by allowing for customization by
        ## prepanel functions --- prepanel(z[i], z[j]) etc
    }
    ## maybe (ideally) this should be affected by scales

    draw <- is.list(pscales) || (is.numeric(pscales) && pscales!=0) # whether axes to be drawn

    splom.layout <- grid.layout(nrow=n.var, ncol=n.var)

    if (n.var > 0 && any(subscripts)) {

        push.viewport(viewport(layout=splom.layout))

        for(i in 1:n.var)
            for(j in 1:n.var)
            {
                push.viewport(viewport(layout.pos.row = n.var-i+1,
                                       layout.pos.col = j,
                                       clip = TRUE,
                                       ##gp = gpar(fontsize = fontsize.small),
                                       xscale = lim[[j]],
                                       yscale = lim[[i]]))

                if(i == j)
                {
                    if (!is.null(colnames(z)))
                        grid.text(colnames(z)[i])
                    ##gp = gpar(fontsize = 10))
                    if (draw) {
                        ## plot axes

                        if (is.factor(z[,i])) {
                            axls <- 1:nlevels(z[,i])
                            nal <- length(axls)/2+.5

                            for(tt in seq(along=axls)) {
                                if(tt <= nal) {
                                    
                                    grid.lines(y = unit(rep(axls[tt],2), "native"),
                                               x = unit(c(1,1),"npc") - unit(c(0,.25), "lines"),
                                               gp = gpar(col = axis.line$col))
                                    
                                    grid.text(label = levels(z[,i])[tt],
                                              x = unit(1,"npc") - unit(.5, "lines"),
                                              y = unit(axls[tt], "native"),
                                              just = c("right", "centre"))
                                    
                                    grid.lines(x = unit(rep(axls[tt],2), "native"),
                                               y = unit(c(0,.25), "lines"),
                                               gp = gpar(col = axis.line$col))
                                    
                                    grid.text(label = levels(z[,i])[tt],
                                              rot = 90,
                                              y = unit(0.5, "lines"),
                                              x = unit(axls[tt], "native"),
                                              just = c("left", "centre"))
                                    
                                }
                                if(tt >=nal) {
                                    
                                    grid.lines(y = unit(rep(axls[tt],2), "native"),
                                               x = unit(c(0,0.25), "lines"),
                                               gp = gpar(col = axis.line$col))
                                    
                                    grid.text(label = levels(z[,i])[tt],
                                              x = unit(0.5, "lines"),
                                              y = unit(axls[tt], "native"),
                                              just = c("left", "centre"))
                                    
                                    grid.lines(x = unit(rep(axls[tt],2), "native"),
                                               y = unit(c(1,1),"npc") - unit(c(0,.25), "lines"),
                                               gp = gpar(col = axis.line$col))
                                    
                                    grid.text(label = levels(z[,i])[tt], rot = 90,
                                              y = unit(1,"npc") - unit(.5, "lines"),
                                              x = unit(axls[tt], "native"),
                                              just = c("right", "centre"))
                                    
                                }
                                
                            }
                            
                        }
                        else {
                        
                            axls <-
                                if (is.list(pscales) && !is.null(pscales[[i]]$at))
                                    pscales[[i]]$at
                                else
                                    lpretty(lim[[i]], n = pscales)

                            labels <-
                                if (is.list(pscales) && !is.null(pscales[[i]]$lab))
                                    pscales[[i]]$lab
                            ## should be rendered like factors ?
                                else
                                    as.character(axls)

                            axid <- axls>lim[[i]][1] & axls <lim[[i]][2]
                            axls <- axls[axid]
                            labels <- labels[axid]
                            nal <- length(axls)/2+.5

                            for(tt in seq(along=axls)) {
                                if(tt <= nal) {
                                    
                                    grid.lines(y = unit(rep(axls[tt],2), "native"),
                                               x = unit(c(1,1),"npc") - unit(c(0,.25), "lines"),
                                               gp = gpar(col = axis.line$col))
                                    
                                    grid.text(label = labels[tt],
                                              x = unit(1,"npc") - unit(.5, "lines"),
                                              y = unit(axls[tt], "native"),
                                              just = c("right", "centre"))
                                    
                                    grid.lines(x = unit(rep(axls[tt],2), "native"),
                                               y = unit(c(0,.25), "lines"),
                                               gp = gpar(col = axis.line$col))
                                    
                                    grid.text(label = labels[tt],
                                              y = unit(0.5, "lines"),
                                              x = unit(axls[tt], "native"),
                                              just = c("centre", "bottom"))
                                    
                                }
                                if(tt >=nal) {
                                    
                                    grid.lines(y = unit(rep(axls[tt],2), "native"),
                                               x = unit(c(0,0.25), "lines"),
                                               gp = gpar(col = axis.line$col))
                                    
                                    grid.text(label = labels[tt],
                                              x = unit(0.5, "lines"),
                                              y = unit(axls[tt], "native"),
                                              just = c("left", "centre"))
                                    
                                    grid.lines(x = unit(rep(axls[tt],2), "native"),
                                               y = unit(c(1,1),"npc") - unit(c(0,.25), "lines"),
                                               gp = gpar(col = axis.line$col))
                                    
                                    grid.text(label = labels[tt],
                                              y = unit(1,"npc") - unit(.5, "lines"),
                                              x = unit(axls[tt], "native"),
                                              just = c("centre", "top"))
                                    
                                }
                                
                            }
                        }    
                    }

                    grid.rect()

                }
                else
                {
                    pargs <-
                        if (!panel.subscripts)
                            c(list(x = as.numeric(z[subscripts, j]),
                                   y = as.numeric(z[subscripts, i]),
                                   panel.number = panel.number),
                              list(...))
                        else
                            c(list(x = as.numeric(z[subscripts, j]),
                                   y = as.numeric(z[subscripts, i]),
                                   groups = groups,
                                   subscripts = subscripts,
                                   panel.number = panel.number),
                              list(...))

                    if (!("..." %in% names(formals(panel))))
                        pargs <- pargs[names(formals(panel))]
                    do.call("panel", pargs)

                    grid.rect()
                }
                pop.viewport()
            }
        pop.viewport()
    }
}


From rolf at math.unb.ca  Fri Sep  5 20:09:17 2003
From: rolf at math.unb.ca (Rolf Turner)
Date: Fri, 5 Sep 2003 15:09:17 -0300 (ADT)
Subject: [R] Basic Dummy Variable Creation
Message-ID: <200309051809.h85I9Hmp015697@erdos.math.unb.ca>


In response to a question from Francisco J. Bido, about how to create
dummy variables, Doug Bates and others essentially said ``Don't.''
Which is good advice, but ....

Recently I encountered a problem involving a linear model with a
three level factor (levels low, medium, and high) crossed with linear
and quadratic terms in a continuous variate.  The client wanted (for
some reason --- perhaps I should have discouraged him more
forcefully) to compare the full model with a model in which there
were linear and quadratic terms for the high level of the factor, but
only linear terms for the low and medium levels.

The only way I could see of specifying the reduced model was through
using dummy variables explicitly.  I.e. I could see no way of
specifying such a model in the standard general linear model syntax.
(The client was actually working in SAS, but the same considerations
apply whether one is speaking SAS or R/Splus, it seems to me.)

Did I miss something obvious (or even not-so-obvious)?

				cheers,

					Rolf Turner
					rolf at math.unb.ca



From Ted.Harding at nessie.mcc.ac.uk  Fri Sep  5 20:18:31 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 05 Sep 2003 19:18:31 +0100 (BST)
Subject: [R] Putting regression lines on SPLOM
In-Reply-To: <200309051245.54052.deepayan@stat.wisc.edu>
Message-ID: <XFMail.030905191831.Ted.Harding@nessie.mcc.ac.uk>

Hi Deepayan,
Thanks again, especially for the careful explanation. Some comments
(in snipped context) below:

On 05-Sep-03 Deepayan Sarkar wrote:
> On Friday 05 September 2003 10:04 am, Ted Harding wrote:
>> Another query:
>>
>> I'm now trying to have the x- and y-axes all on the same scale
>> (0:15) in every panel, whereas the default behaviour of splom
>> is to scale them according to the ranges of the individual
>> variables in each panel.
>> [...]
> [...]
> Unfortunately, the current implementation of splom (in particular the 
> panel.pairs function) does not allow you to do what you want in any
> other way either (however, read on for a solution).
> [...]
> ... This feature was missing till now, but I have added something for
> the next release (source() the attached file to use it), which will
allow you to do:
> 
> splom(log(1+DF),
>       prepanel.limits = function(x) c(0, 15),
>       panel = function(x, y, ... ) {
>           panel.xyplot(x, y, ...)
>       })

*** No file was attached  :((

> [...]
>> ?panel.xyplot refers you to ?xyplot for "further arguments",
>> and ?xyplot certainly specifies the above form for specifying
>> x- and y-limits. I think ...
> 
> Where exactly does it do that ? xyplot is in the "See Also" section,
> but how does that imply that arguments accepted by xyplot can be
> given to panel.xyplot ? And I don't see the phrase "further
> arguments" anywhere in the help page for panel.xyplot.
> 
> If there's anything in the documentation that even suggests that xlim
> and ylim can be passed to panel functions, that's definitely
> misleading, and I would appreciate it if you could point out any such
> confusing statements.

Quite possible I was not reading sufficiently between the lines,
but the indications that led me down that path come from the following
citations:

  ?splom -> ?panel.xyplot ->

  panel.xyplot      package:lattice      R Documentation
  Default Panel Function for xyplot
  Description:
       This is the default panel function for `xyplot'.
  Usage:
       panel.xyplot(x, y, type="p",
       [..] 
       lwd = plot.line$lwd, ...)
  [...]
       ...: other arguments, e.g., arguments to pass to `panel.loess'.
  [...]
  See Also:
       `panel.superpose', `xyplot', `splom',`qqmath'

and of course ?xyplot leads to the 'xlim' and 'ylim' parameters.

I guess the expectation was that "e.g." in the "other arguments" line
permitted the hypothesis that since controlling axis scales would 
probably be a common need and so there might be a mechanism for it
(but not mentioned so far down the path), the natural next direction
to try was the suggested "see xyplot" where what looks like a mechanism
can be found.

I agree, though, that the above does not logically imply that this is
indeed such a mechanism: it merely creates an expectation (albeit in
my case quite a strong one) that it would be; and some resulting
surpise that it did not work! So I guess this falls within your
"even suggests", even though it's not overtly misleading.

Anyway, many thanks again for the elucidations, and I look forward
to receiving the file to try the new feature!

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 05-Sep-03                                       Time: 19:18:31
------------------------------ XFMail ------------------------------



From flom at ndri.org  Fri Sep  5 20:30:11 2003
From: flom at ndri.org (Peter Flom)
Date: Fri, 05 Sep 2003 14:30:11 -0400
Subject: [R] Dotchart question
Message-ID: <sf589dfa.021@MAIL.NDRI.ORG>

Sorry to keep asking elementary questions......I appreciate the help.

I am trying to create a dotchart with the rows sorted according to the
values, rather than the labels.  When I try

prof <- c('Accountant', 'Administrative assistant', 'Garment worker',
'Cook',
  'Dentist', 'General practictioner', 'Graduate student', 'High level
manager',
  'Low level manager', 'Mechanical engineer', 'Mechanic',
'Minister/priest/rabbi',
  'Nurse', 'Professor', 'Sales clerk', 'Server', 'Taxi driver')
mol <- c(34, 29, 27, 36, 20, 40, 35, 32, 30, 31, 30, 32, 37, 37, 27,
28, 36)

dotchart(mol, labels = prof, main = 'Dot chart', xlab = 'Meaning of
life score')

I get a dot chart sorted by the values of prof; what I'd like is one
sorted by values of mol.

I looked at the help file for dotchart, but did not see anything.

Thanks again in advance

Peter L. Flom, PhD
Assistant Director, Statistics and Data Analysis Core
Center for Drug Use and HIV Research
National Development and Research Institutes
71 W. 23rd St
www.peterflom.com
New York, NY 10010
(212) 845-4485 (voice)
(917) 438-0894 (fax)



From spencer.graves at pdf.com  Fri Sep  5 20:49:31 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 05 Sep 2003 11:49:31 -0700
Subject: [R] Basic Dummy Variable Creation
References: <200309051809.h85I9Hmp015697@erdos.math.unb.ca>
Message-ID: <3F58DABB.3030801@pdf.com>

	  One must estimate 2 coefficients for a 3-level factor.  I therefore 
prefer to look for a plausible order between the 3 levels so I can code 
them as -1, 0, +1 and then estimate linear and quadratic coefficients. 
Then for interactions, I look first for interactions between the linear 
effect of this factor and others, especially if the data do not support 
reasonable estimation of both interaction terms.  This sounds to me to 
be pretty close to what your client was requesting.

hope this helps.
spencer graves

Rolf Turner wrote:
> In response to a question from Francisco J. Bido, about how to create
> dummy variables, Doug Bates and others essentially said ``Don't.''
> Which is good advice, but ....
> 
> Recently I encountered a problem involving a linear model with a
> three level factor (levels low, medium, and high) crossed with linear
> and quadratic terms in a continuous variate.  The client wanted (for
> some reason --- perhaps I should have discouraged him more
> forcefully) to compare the full model with a model in which there
> were linear and quadratic terms for the high level of the factor, but
> only linear terms for the low and medium levels.
> 
> The only way I could see of specifying the reduced model was through
> using dummy variables explicitly.  I.e. I could see no way of
> specifying such a model in the standard general linear model syntax.
> (The client was actually working in SAS, but the same considerations
> apply whether one is speaking SAS or R/Splus, it seems to me.)
> 
> Did I miss something obvious (or even not-so-obvious)?
> 
> 				cheers,
> 
> 					Rolf Turner
> 					rolf at math.unb.ca
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Ted.Harding at nessie.mcc.ac.uk  Fri Sep  5 20:57:54 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 05 Sep 2003 19:57:54 +0100 (BST)
Subject: [R] Putting regression lines on SPLOM
In-Reply-To: <200309051251.13932.deepayan@stat.wisc.edu>
Message-ID: <XFMail.030905195754.Ted.Harding@nessie.mcc.ac.uk>

On 05-Sep-03 Deepayan Sarkar wrote:
> 
> Oops, forgot the attachment.
> 
> On Friday 05 September 2003 12:45 pm, Deepayan Sarkar wrote:
>> The prepanel function returns separate limits for x and y axes. This
>> does not translate to splom, since each limit is used on both the x
>> and y axes.
>> However, it is natural to add a new optional argument, which would be
>> a function that would decide on the limits for each variable in the
>> data frame, to be used as both x and y limits. This feature was
>> missing till now, but I have added something for the next release
>> (source() the attached file to use it), which will allow you to do:
>>
>> splom(log(1+DF),
>>       prepanel.limits = function(x) c(0, 15),
>>       panel = function(x, y, ... ) {
>>           panel.xyplot(x, y, ...)
>>       })

Thanks again, Deepayan -- it works a treat!

I guess it would be OK to insert the contents of your file
"panel.limits.R" into the R code file of the "lattice" package, so that
it is loaded every time?

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 05-Sep-03                                       Time: 19:57:54
------------------------------ XFMail ------------------------------



From rvaradha at jhsph.edu  Fri Sep  5 21:24:02 2003
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Fri, 05 Sep 2003 15:24:02 -0400
Subject: [R] laplace transform
Message-ID: <43a203f0f3.3f0f343a20@jhsph.edu>

Hi:

I have written a Fortran program based on the Gaver-Stehfest algorithm, 
which uses only real numbers (as opposed to the more powerful methods 
using complex numbers). However, this can't be used in R since the 
function specifying the inverse of the Laplace transform must also be 
written in Fortran.  I would be interested in learning how to define 
the function in R and then calling the Fortran subroutines to do the 
inverse computations. Can anyone tell me how to do this?

thanks,
Ravi.

----- Original Message -----
From: "Andrew C. Ward" <s195404 at student.uq.edu.au>
Date: Friday, September 5, 2003 1:03 am
Subject: Re: [R] laplace transform

> Dear Luca,
> 
> I don't think that R has a built-in function for doing
> Laplace or inverse Laplace transforms. I remember having to
> use an IMSL routine (INLP, I think) to do this many years
> ago. When I looked at the article that the algorithm was
> based on, I found that as an example the author showed how
> well the method worked when inverting 1/s! Presumably, 
> things have improved since then.
> 
> A Google search of (numerical "inverse laplace transform")
> yields a number of references that should get you started.
> If you write some R code to do this, think about submitting
> it to CRAN. Even though a lot of R/S code is devoted to
> statistical methods, there's no reason at all why all kinds
> of other things can't be written.
> 
> 
> Regards,
> 
> Andrew C. Ward
> 
> CAPE Centre
> Department of Chemical Engineering
> The University of Queensland
> Brisbane Qld 4072 Australia
> andreww at cheque.uq.edu.au
> 
> 
> Quoting Luca Laghi <llaghi at foodsci.unibo.it>:
> 
> > Dear users,
> > is anybody of you aware of a R command to perform laplace
> > transform or
> > even its inversion?
> > Thank you very much.
> > Luca
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From Luis.Tito-de-Morais at ird.sn  Fri Sep  5 21:30:05 2003
From: Luis.Tito-de-Morais at ird.sn (Tito de Morais Luis)
Date: Fri, 05 Sep 2003 19:30:05 -0000
Subject: [R] Dotchart question
In-Reply-To: <sf589dfa.021@MAIL.NDRI.ORG>
References: <sf589dfa.021@MAIL.NDRI.ORG>
Message-ID: <1062788708.8614.110.camel@rap06.ird.sn>

This one is ugly, but works...

molprof<-data.frame(mol,prof)
molprof <- molprof[with(molprof,order(mol)), ]
dotchart(molprof$mol, labels = as.character(molprof$prof), main = 'Dot
chart', xlab = 'Meaning of life score')

HTH

Tito


Le ven 05/09/2003 ? 18:30, Peter Flom a ?crit :
> Sorry to keep asking elementary questions......I appreciate the help.
> 
> I am trying to create a dotchart with the rows sorted according to the
> values, rather than the labels.  When I try
> 
> prof <- c('Accountant', 'Administrative assistant', 'Garment worker',
> 'Cook',
>   'Dentist', 'General practictioner', 'Graduate student', 'High level
> manager',
>   'Low level manager', 'Mechanical engineer', 'Mechanic',
> 'Minister/priest/rabbi',
>   'Nurse', 'Professor', 'Sales clerk', 'Server', 'Taxi driver')
> mol <- c(34, 29, 27, 36, 20, 40, 35, 32, 30, 31, 30, 32, 37, 37, 27,
> 28, 36)
> 
> dotchart(mol, labels = prof, main = 'Dot chart', xlab = 'Meaning of
> life score')
> 
> I get a dot chart sorted by the values of prof; what I'd like is one
> sorted by values of mol.
> 
> I looked at the help file for dotchart, but did not see anything.
> 
> Thanks again in advance
> 
> Peter L. Flom, PhD
> Assistant Director, Statistics and Data Analysis Core
> Center for Drug Use and HIV Research
> National Development and Research Institutes
> 71 W. 23rd St
> www.peterflom.com
> New York, NY 10010
> (212) 845-4485 (voice)
> (917) 438-0894 (fax)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
-- 
L. Tito de Morais
      UR RAP
   IRD de Dakar
      BP 1386
       Dakar
      S?n?gal

T?l.: + 221 849 33 31
Fax: +221 832 16 75
Courriel: tito at ird.sn



From noble at gs.washington.edu  Fri Sep  5 21:40:42 2003
From: noble at gs.washington.edu (William Noble)
Date: Fri, 05 Sep 2003 12:40:42 -0700
Subject: [R] stack overflow
Message-ID: <200309051940.h85JegqA013780@adenine.gs.washington.edu>


Hello,

I am trying to do an ANOVA on a microarray data set consisting of
22690 elements.  The ANOVA is fine, but when I try to put the data in
a frame in order to exporting it, I get a stack overflow.  I have
found documentation on dynamic memory in R, but not on how to increase
the stack size.  The code I'm using is below.  If anyone has any
suggestions for a workaround here, I'd appreciate it.

Thank you.
Bill Noble

------------
R : Copyright 2003, The R Development Core Team
Version 1.7.1  (2003-06-16)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type `license()' or `licence()' for distribution details.

R is a collaborative project with many contributors.
Type `contributors()' for more information.

Type `demo()' for some demos, `help()' for on-line help, or
`help.start()' for a HTML browser interface to help.
Type `q()' to quit R.

> invisible(options(echo = TRUE))
> sdata <- read.table("../../data/02-09-03/data.mtx", header=T, row.names=1)
> infection <- gl(2,8,16, label=c("no infection", "infection"))
> labor <- gl(2,4,16, label=c("no labor", "labor"))
> aof <- function(x) {
+   m <- data.frame(infection, labor, x);
+   anova(aov(x ~ infection + labor + infection*labor, m))
+ }
> anovaresults <- apply(sdata, 1, aof)
> pvalues <- data.frame(lapply(anovaresults, function(x) { x["Pr(>F)"][1:3,] }))
Error: protect(): stack overflow
> anovaresults[[1]]
Analysis of Variance Table

Response: x
                Df Sum Sq Mean Sq F value  Pr(>F)  
infection        1   9082    9082  0.2315 0.63907  
labor            1  98722   98722  2.5164 0.13865  
infection:labor  1 143262  143262  3.6517 0.08019 .
Residuals       12 470776   39231                  
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 
> temp <- lapply(anovaresults, function(x) { x["Pr(>F)"][1:3,] })
> length(temp)
[1] 22690
> temp[1]
$"AFFX-BioB-5_at"
         1          2          3 
0.63906707 0.13865289 0.08018914 
> gc(verbose=TRUE)
Garbage collection 62 = 23+6+33 (level 2) ... 
1430471 cons cells free (28%)
17.4 Mbytes of heap free (32%)
          used (Mb) gc trigger  (Mb)
Ncells 3249183 86.8    4953636 132.3
Vcells 4749443 36.3    7025348  53.6
> pvalues <- data.frame(temp)
Error: protect(): stack overflow
> gc(verbose=TRUE)
Garbage collection 63 = 23+6+34 (level 2) ... 
1636368 cons cells free (33%)
19.5 Mbytes of heap free (34%)
          used (Mb) gc trigger  (Mb)
Ncells 3317268 88.6    4953636 132.3
Vcells 4794917 36.6    7353029  56.1



From tblackw at umich.edu  Fri Sep  5 22:34:12 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Fri, 5 Sep 2003 16:34:12 -0400 (EDT)
Subject: [R] stack overflow
In-Reply-To: <200309051940.h85JegqA013780@adenine.gs.washington.edu>
Message-ID: <Pine.SOL.4.44.0309051618160.12350-100000@tetris.gpcc.itd.umich.edu>

Bill  -

Here's what I would do, starting after your display of  anovaresults[[1]].

temp.1 <- unlist(lapply(anovaresults, function(x) { x["Pr(>F)"][1:3],] }))
temp.2 <- matrix(temp.1, length(anovaresults), 3, byrow=T)
dimnames(temp.2) <- list(names(anovaresults),
	 	 	 dimnames(anovaresults[[1]])[[1]][1:3])
rm("anovaresults")
pvalues <- data.frame(temp.2)

Another suggestion is to do the subscripting that extracts the
single column of p-values inside your function  aof().  Then the
list returned by  apply()  will be much smaller and have a simpler
structure.

HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Fri, 5 Sep 2003, William Noble wrote:

> I am trying to do an ANOVA on a microarray data set consisting of
> 22690 elements.  The ANOVA is fine, but when I try to put the data in
> a frame in order to exporting it, I get a stack overflow.  I have
> found documentation on dynamic memory in R, but not on how to increase
> the stack size.  The code I'm using is below.  If anyone has any
> suggestions for a workaround here, I'd appreciate it.
>
> Thank you.
> Bill Noble
> ------------
>
> > invisible(options(echo = TRUE))
> > sdata <- read.table("../../data/02-09-03/data.mtx", header=T, row.names=1)
> > infection <- gl(2,8,16, label=c("no infection", "infection"))
> > labor <- gl(2,4,16, label=c("no labor", "labor"))
> > aof <- function(x) {
> +   m <- data.frame(infection, labor, x);
> +   anova(aov(x ~ infection + labor + infection*labor, m))
> + }
> > anovaresults <- apply(sdata, 1, aof)
> > pvalues <- data.frame(lapply(anovaresults, function(x) { x["Pr(>F)"][1:3,] }))
> Error: protect(): stack overflow
> >
> > anovaresults[[1]]
> Analysis of Variance Table
>
> Response: x
>                 Df Sum Sq Mean Sq F value  Pr(>F)
> infection        1   9082    9082  0.2315 0.63907
> labor            1  98722   98722  2.5164 0.13865
> infection:labor  1 143262  143262  3.6517 0.08019 .
> Residuals       12 470776   39231
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
> >
> > temp <- lapply(anovaresults, function(x) { x["Pr(>F)"][1:3,] })
> > length(temp)
> [1] 22690
> > temp[1]
> $"AFFX-BioB-5_at"
>          1          2          3
> 0.63906707 0.13865289 0.08018914
> > gc(verbose=TRUE)
> Garbage collection 62 = 23+6+33 (level 2) ...
> 1430471 cons cells free (28%)
> 17.4 Mbytes of heap free (32%)
>           used (Mb) gc trigger  (Mb)
> Ncells 3249183 86.8    4953636 132.3
> Vcells 4749443 36.3    7025348  53.6
> > pvalues <- data.frame(temp)
> Error: protect(): stack overflow
> > gc(verbose=TRUE)
> Garbage collection 63 = 23+6+34 (level 2) ...
> 1636368 cons cells free (33%)
> 19.5 Mbytes of heap free (34%)
>           used (Mb) gc trigger  (Mb)
> Ncells 3317268 88.6    4953636 132.3
> Vcells 4794917 36.6    7353029  56.1
>



From h.wickham at auckland.ac.nz  Fri Sep  5 23:02:31 2003
From: h.wickham at auckland.ac.nz (h.wickham@auckland.ac.nz)
Date: Sat,  6 Sep 2003 09:02:31 +1200
Subject: [R] Dotchart question
In-Reply-To: <sf589dfa.021@MAIL.NDRI.ORG>
References: <sf589dfa.021@MAIL.NDRI.ORG>
Message-ID: <1062795751.3f58f9e7d8067@medmail.auckland.ac.nz>

Hi Peter,

Dotchart plots the points in the order that it receives them - to plot them in
order of increasing mol, you need to sort mol first.  To make sure you keep the
right prof associated to the right mol, I'd use names to connect the two first
(this also means you don't need to provide an explicit labels vectors to dotchart)

eg.
names(mol) <- prof
dotchart(sort(mol))

HTH,

Hadley

-------------------------------------------------
This mail sent through IMP: http://horde.org/imp/



From tzhou1 at students.uiuc.edu  Fri Sep  5 23:20:21 2003
From: tzhou1 at students.uiuc.edu (tzhou1)
Date: Fri, 5 Sep 2003 16:20:21 -0500
Subject: [R] fit data with skew t distribution
Message-ID: <3F7BAD6F@webmail.uiuc.edu>

Hi,

Is there a function in R that I can use to fit the data with skew t 
distribution? Speaking in detail, I first used the kernel density estimation 
to fit my data, then I drew the skew t using my specified location, scale, 
shape, and df to make it close to the kernel density. Now I want to get the 
parameter estimations of the skew t which give me the closet density to the 
kernel density. Which functions in R can do this? Any suggestions are 
welcome!!

Thanks!

Tianyue



From p.dalgaard at biostat.ku.dk  Fri Sep  5 23:19:50 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri, 05 Sep 2003 21:19:50 -0000
Subject: [R] stack overflow
In-Reply-To: <200309051940.h85JegqA013780@adenine.gs.washington.edu>
References: <200309051940.h85JegqA013780@adenine.gs.washington.edu>
Message-ID: <x2r82vylr4.fsf@biostat.ku.dk>

William Noble <noble at gs.washington.edu> writes:

> Hello,
> 
> I am trying to do an ANOVA on a microarray data set consisting of
> 22690 elements.  The ANOVA is fine, but when I try to put the data in
> a frame in order to exporting it, I get a stack overflow.  I have
> found documentation on dynamic memory in R, but not on how to increase
> the stack size.  The code I'm using is below.  If anyone has any
> suggestions for a workaround here, I'd appreciate it.

You might want to consider turning it into a matrix instead (just use
sapply()). 

However, this looks like a bug and it has even got worse in r-devel.
So thanks for drawing attention to it.

To paraphrase the situation, just take a long list of short vectors
and turn it into a data frame:

> tmp <- lapply(1:22690,function(i)rnorm(3))
> xx <- data.frame(tmp)
Segmentation fault

The problem comes from within the error handler itself. 

Program received signal SIGSEGV, Segmentation fault.
Rf_errorcall (call=0x81dadb0, format=0x817c598 "protect(): stack
overflow")
    at ../../../R/src/main/errors.c:481
481         vsignalError(call, format, ap);

The traceback indicates that Rf_protect() goes into infinite
recursion. (Luke?) 


Deep  down in the stack we have 

#760082 0x08073e48 in Rf_substituteList (el=0x8d47a9c, rho=0x81dadb0)
    at ../../../R/src/main/coerce.c:1811
1811            PROTECT(h = substitute(CAR(el), rho));
(gdb) down
#760081 0x080bf717 in Rf_protect (s=0x978a050)
    at ../../../R/src/main/memory.c:1999
1999            errorcall(R_NilValue, "protect(): stack overflow");

and below that we have

#760082 0x08073e48 in Rf_substituteList (el=0x8d47a9c, rho=0x81dadb0)
    at ../../../R/src/main/coerce.c:1811
1811            PROTECT(h = substitute(CAR(el), rho));
(gdb)
#760083 0x08073e54 in Rf_substituteList (el=0x8d47ab8, rho=0x81dadb0)
    at ../../../R/src/main/coerce.c:1812
1812            PROTECT(t = substituteList(CDR(el), rho));
(gdb)
#760084 0x08073e54 in Rf_substituteList (el=0x8d47ad4, rho=0x81dadb0)
    at ../../../R/src/main/coerce.c:1812
1812            PROTECT(t = substituteList(CDR(el), rho));
(gdb)
#760085 0x08073e54 in Rf_substituteList (el=0x8d47af0, rho=0x81dadb0)
    at ../../../R/src/main/coerce.c:1812
1812            PROTECT(t = substituteList(CDR(el), rho));

So the original problem is that substituteList() is not happy with
long lists. I'm not really sure but my gut feeling is that the tail
should be computed before the head (i.e. reverse lines 1811 and 1812)
so that you don't end up with a pile of heads computed before the
recursion ends.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From laboissiere at psy.mpg.de  Sat Sep  6 00:10:18 2003
From: laboissiere at psy.mpg.de (Rafael Laboissiere)
Date: Sat, 6 Sep 2003 00:10:18 +0200
Subject: [R] Right formula for a mixed-design anova
Message-ID: <20030905221018.GF25179@laboiss0>

Hi,

I am having some trouble to find the correct syntax in R for analysing my
results.  I am running a experiment in which we measure the force exerted by
the subjects (the independent variable) under two different fixed factors.
Each factor has two levels, so that each subject participated to several
repetitions of those four kinds of trials.  I think that I should consider
the subjects here as a random effect.

My specific problem is that we are interested on investigating the effect of
an end-state in each trial (say, the controlled point on the screen ended to
the right or to the left) on the exerted force.  I think that this later
factor should also be considered as a random effect, but I am not sure.

My question is how do I specify this model using aov() in R.  I am not very
used to statitics, and perhaps my question has a trivial answer.  If this is
the case, please give the pointers where I can find more information on this
problem.

Thank you in advance for any help,

-- 
Rafael Laboissiere



From kjetil at entelnet.bo  Sat Sep  6 00:51:22 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Fri, 05 Sep 2003 18:51:22 -0400
Subject: [R] Dotchart question
In-Reply-To: <sf589dfa.021@MAIL.NDRI.ORG>
Message-ID: <3F58DB2A.18497.1B756E2@localhost>

On 5 Sep 2003 at 14:30, Peter Flom wrote:

prof <- c('Accountant', 'Administrative assistant', 'Garment worker',
 'Cook',
   'Dentist', 'General practictioner', 'Graduate student', 
'High level manager',
   'Low level manager', 'Mechanical engineer', 'Mechanic',
 'Minister/priest/rabbi',
   'Nurse', 'Professor', 'Sales clerk', 'Server', 'Taxi driver')

mol <- c(34, 29, 27, 36, 20, 40, 35, 32, 30, 31, 30, 32, 37, 37, 27,
    28, 36)

o <- order(mol)
mol <- mol[o]
prof <- prof[o]

dotchart(mol, labels = prof, main = 'Dot chart', 
        xlab = 'Meaning of life score')

Works for me.

Kjetil Halvorsen



> Sorry to keep asking elementary questions......I appreciate the help.
> 
> I am trying to create a dotchart with the rows sorted according to the
> values, rather than the labels.  When I try
> 
> prof <- c('Accountant', 'Administrative assistant', 'Garment worker',
> 'Cook',
>   'Dentist', 'General practictioner', 'Graduate student', 'High level
> manager',
>   'Low level manager', 'Mechanical engineer', 'Mechanic',
> 'Minister/priest/rabbi',
>   'Nurse', 'Professor', 'Sales clerk', 'Server', 'Taxi driver')
> mol <- c(34, 29, 27, 36, 20, 40, 35, 32, 30, 31, 30, 32, 37, 37, 27,
> 28, 36)
> 
> dotchart(mol, labels = prof, main = 'Dot chart', xlab = 'Meaning of
> life score')
> 
> I get a dot chart sorted by the values of prof; what I'd like is one
> sorted by values of mol.
> 
> I looked at the help file for dotchart, but did not see anything.
> 
> Thanks again in advance
> 
> Peter L. Flom, PhD
> Assistant Director, Statistics and Data Analysis Core
> Center for Drug Use and HIV Research
> National Development and Research Institutes
> 71 W. 23rd St
> www.peterflom.com
> New York, NY 10010
> (212) 845-4485 (voice)
> (917) 438-0894 (fax)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From kjetil at entelnet.bo  Sat Sep  6 00:51:22 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Fri, 05 Sep 2003 18:51:22 -0400
Subject: [R] fit data with skew t distribution
In-Reply-To: <3F7BAD6F@webmail.uiuc.edu>
Message-ID: <3F58DB2A.22608.1B75675@localhost>

On 5 Sep 2003 at 16:20, tzhou1 wrote:

I don't know what a skew t distribution is, but 
help.search("skew t")
gives

dmst(sn)                Multivariate skew-t distribution
dst(sn)                 Skew-t Distribution
dst2.plot(sn)           Plot of Bivariate Skew-t Density Function
msn.affine(sn)          Affine transformation a multivariate
                        skew-normal or skew-t variable
mst.fit(sn)             Fitting multivariate skew-t distributions

so you shoukd probably install package sn from CRAN.

Kjetil Halvorsen

> Hi,
> 
> Is there a function in R that I can use to fit the data with skew t 
> distribution? Speaking in detail, I first used the kernel density estimation 
> to fit my data, then I drew the skew t using my specified location, scale, 
> shape, and df to make it close to the kernel density. Now I want to get the 
> parameter estimations of the skew t which give me the closet density to the 
> kernel density. Which functions in R can do this? Any suggestions are 
> welcome!!
> 
> Thanks!
> 
> Tianyue
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From lenvi10 at yahoo.com  Sat Sep  6 01:18:16 2003
From: lenvi10 at yahoo.com (len vir)
Date: Fri, 5 Sep 2003 19:18:16 -0400 (EDT)
Subject: [R] R Documentation with Emphasis on Econometrics
In-Reply-To: <NAEILMBIIHLJMHEBBLPEEEOPDEAA.bbenthul@ppacg.org>
Message-ID: <20030905231816.46150.qmail@web14806.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030905/e10874c4/attachment.pl

From gblevins at mn.rr.com  Sat Sep  6 05:28:59 2003
From: gblevins at mn.rr.com (Greg Blevins)
Date: Fri, 5 Sep 2003 20:28:59 -0700
Subject: [R] Using subset with describe in Hmisc
Message-ID: <000a01c37427$037c2500$1c361d41@glblpyirxqz5lp>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030905/11d4092c/attachment.pl

From edd at debian.org  Sat Sep  6 04:37:00 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 5 Sep 2003 21:37:00 -0500
Subject: [R] Installing R on Red Hat Linux, Tcl/Tk
In-Reply-To: <1062768947.22138.41.camel@localhost>
References: <Pine.LNX.4.44.0309052141570.12867-100000@unix28.alpha.wehi.edu.au>
	<1062768947.22138.41.camel@localhost>
Message-ID: <20030906023700.GA5355@sonny.eddelbuettel.com>

On Fri, 2003-09-05 at 07:13, James Wettenhall wrote:
> I've been trying to install R on Red Hat Linux 9 for some
> potential users of my R/TclTk application.  I tried using the 
> rpm for R 1.7.1 for Red Hat Linux 9.  It told me that I needed:
> libtcl8.3.so
> so I looked for a binary release of Tcl 8.3.x on 
> http://www.tcl.tk/software/tcltk/8.3.html
> but found that the link to the Tcl 8.3.x binaries pointed to 
> ActiveTcl 8.4.x . I couldn't see the old 8.3.x binaries 
> anywhere.  ActiveTcl is a nice easy way to get the extensions 
> like Tktable, but it seemed to be the wrong version.
[....]

I cannot resist pointing that after

	$ apt-get install tktable

everything just works under Debian, in this case the "testing" flavour that
will eventually morph into  the next Debian stable release:

	$ R --slave
	> library(tcltk)
	> tt <- tktoplevel()
	> tclRequire("Tktable")
	<Tcl> 2.8 
	> table1 <- tkwidget(tt,"table")
	> tkpack(table1)
	<Tcl>  

Same with bwidget, iwidgets and a few other tcl/tk extensions. All available
straight from the Debian mirrors.

Hth,  Dirk

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From MSchwartz at medanalytics.com  Sat Sep  6 05:18:02 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 05 Sep 2003 22:18:02 -0500
Subject: [R] Installing R on Red Hat Linux, Tcl/Tk
In-Reply-To: <20030906023700.GA5355@sonny.eddelbuettel.com>
References: <Pine.LNX.4.44.0309052141570.12867-100000@unix28.alpha.wehi.edu.au>
	<1062768947.22138.41.camel@localhost>
	<20030906023700.GA5355@sonny.eddelbuettel.com>
Message-ID: <1062818281.22138.229.camel@localhost>

On Fri, 2003-09-05 at 21:37, Dirk Eddelbuettel wrote:
> On Fri, 2003-09-05 at 07:13, James Wettenhall wrote:
> > I've been trying to install R on Red Hat Linux 9 for some
> > potential users of my R/TclTk application.  I tried using the 
> > rpm for R 1.7.1 for Red Hat Linux 9.  It told me that I needed:
> > libtcl8.3.so
> > so I looked for a binary release of Tcl 8.3.x on 
> > http://www.tcl.tk/software/tcltk/8.3.html
> > but found that the link to the Tcl 8.3.x binaries pointed to 
> > ActiveTcl 8.4.x . I couldn't see the old 8.3.x binaries 
> > anywhere.  ActiveTcl is a nice easy way to get the extensions 
> > like Tktable, but it seemed to be the wrong version.
> [....]
> 
> I cannot resist pointing that after
> 
> 	$ apt-get install tktable
> 
> everything just works under Debian, in this case the "testing" flavour that
> will eventually morph into  the next Debian stable release:
> 
> 	$ R --slave
> 	> library(tcltk)
> 	> tt <- tktoplevel()
> 	> tclRequire("Tktable")
> 	<Tcl> 2.8 
> 	> table1 <- tkwidget(tt,"table")
> 	> tkpack(table1)
> 	<Tcl>  
> 
> Same with bwidget, iwidgets and a few other tcl/tk extensions. All available
> straight from the Debian mirrors.
> 
> Hth,  Dirk



While I don't use apt-get, I did just download the TkTable 2.8 tarball
from sourceforge:

http://sourceforge.net/project/showfiles.php?group_id=11464

did the ./configure, make, make install process (about 2 minutes) and I
get the same output as Dirk above (including the nice table widget)
under RH 9 using the default RH installation of tcl/tk (8.3). So the
ActiveTcl version 8.4 is not required.

I suspect this gives further support to the likely key issue being the
resultant mix of tcl/tk versions that James is dealing with.

HTH,

Marc



From feh3k at spamcop.net  Sat Sep  6 06:54:41 2003
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Sat, 6 Sep 2003 06:54:41 +0200
Subject: [R] Using subset with describe in Hmisc
In-Reply-To: <000a01c37427$037c2500$1c361d41@glblpyirxqz5lp>
References: <000a01c37427$037c2500$1c361d41@glblpyirxqz5lp>
Message-ID: <20030906065441.5ce670e9.feh3k@spamcop.net>

On Fri, 5 Sep 2003 20:28:59 -0700
"Greg Blevins" <gblevins at mn.rr.com> wrote:

> Hello,
> 
> This is an embarassingly simple question, but I cannot get subset to work with describe.
> 
> dataframe is attached and called Ph
> 
> >describe(q1, subset=qs3a==1)
> 
> qs3a is numeric.
> 
> This runs, but no subset takes place.
> 
> Thanks in advance.
> 
> Greg Blevins
> The Market Solutions Group
> 	[[alternative HTML version deleted]]

If you type ?describe you won't see a subset argument for describe when the first argument is not a formula.  Use describe(~ q1, subset=....).  

---
Frank E Harrell Jr    Professor and Chair            School of Medicine
                      Department of Biostatistics    Vanderbilt University



From s195404 at student.uq.edu.au  Sat Sep  6 13:32:41 2003
From: s195404 at student.uq.edu.au (Andrew C. Ward)
Date: Sat,  6 Sep 2003 11:32:41 +0000
Subject: [R] laplace transform
In-Reply-To: <43a203f0f3.3f0f343a20@jhsph.edu>
References: <43a203f0f3.3f0f343a20@jhsph.edu>
Message-ID: <1062847961.3f59c5d9cf4e8@my.uq.edu.au>

Dear Ravi,

R calls many functions that are written in FORTRAN. As a
start on how to do this, perhaps look at the cluster
package.


Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au


Quoting Ravi Varadhan <rvaradha at jhsph.edu>:

> Hi:
> 
> I have written a Fortran program based on the
> Gaver-Stehfest algorithm, 
> which uses only real numbers (as opposed to the more
> powerful methods 
> using complex numbers). However, this can't be used in R
> since the 
> function specifying the inverse of the Laplace transform
> must also be 
> written in Fortran.  I would be interested in learning
> how to define 
> the function in R and then calling the Fortran
> subroutines to do the 
> inverse computations. Can anyone tell me how to do this?
> 
> thanks,
> Ravi.
> 
> ----- Original Message -----
> From: "Andrew C. Ward" <s195404 at student.uq.edu.au>
> Date: Friday, September 5, 2003 1:03 am
> Subject: Re: [R] laplace transform
> 
> > Dear Luca,
> > 
> > I don't think that R has a built-in function for doing
> > Laplace or inverse Laplace transforms. I remember
> having to
> > use an IMSL routine (INLP, I think) to do this many
> years
> > ago. When I looked at the article that the algorithm
> was
> > based on, I found that as an example the author showed
> how
> > well the method worked when inverting 1/s! Presumably,
> 
> > things have improved since then.
> > 
> > A Google search of (numerical "inverse laplace
> transform")
> > yields a number of references that should get you
> started.
> > If you write some R code to do this, think about
> submitting
> > it to CRAN. Even though a lot of R/S code is devoted
> to
> > statistical methods, there's no reason at all why all
> kinds
> > of other things can't be written.
> > 
> > 
> > Regards,
> > 
> > Andrew C. Ward
> > 
> > CAPE Centre
> > Department of Chemical Engineering
> > The University of Queensland
> > Brisbane Qld 4072 Australia
> > andreww at cheque.uq.edu.au
> > 
> > 
> > Quoting Luca Laghi <llaghi at foodsci.unibo.it>:
> > 
> > > Dear users,
> > > is anybody of you aware of a R command to perform
> laplace
> > > transform or
> > > even its inversion?
> > > Thank you very much.
> > > Luca
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > >
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > >
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > 
> 
>



From uth at zhwin.ch  Sat Sep  6 16:28:49 2003
From: uth at zhwin.ch (=?utf-8?Q?=22Untern=C3=A4hrer_Thomas=2C_uth=22?=)
Date: Sat, 6 Sep 2003 16:28:49 +0200
Subject: [R] split.screen problem and segments in figure margin
Message-ID: <53A181E56FB0694ABFD212F8AEDA7F6F1AB867@langouste.zhwin.ch>

hi,
 
two questions...
 
1. what happens with points()?
    after the split.screen function points() start not at x = 1 (at x = - something)

graphics.off()
x11()
split.screen(c(3, 1))
split.screen(c(2, 1), 1)

screen(3)
plot(dat, type = "n")
screen(4)
plot(dat, type = "n")
screen(2)
plot(dat, type = "n")

dat <- rnorm(1000)

for (i in 1:length(dat)){
  screen(3)
  points(i, dat[i])
  screen(4)
  points(i, dat[i])
  screen(2)
  points(i, dat[i])
}

close.screen(all = TRUE)

I was searching the mail-archives and found the same question but no answers.
Can somebody help me?
 
 
2. Can I draw segments() in the figure margin (not in the plot region).... or can I split my axis(2,...) in 3 with a gap between them? 
 
 
thanks for any help
 
Thomas



From ligges at statistik.uni-dortmund.de  Sat Sep  6 17:01:31 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 06 Sep 2003 17:01:31 +0200
Subject: [R] split.screen problem and segments in figure margin
In-Reply-To: <53A181E56FB0694ABFD212F8AEDA7F6F1AB867@langouste.zhwin.ch>
References: <53A181E56FB0694ABFD212F8AEDA7F6F1AB867@langouste.zhwin.ch>
Message-ID: <3F59F6CB.7040300@statistik.uni-dortmund.de>

Untern?hrer Thomas, uth wrote:
> hi,
>  
> two questions...
>  
> 1. what happens with points()?
>     after the split.screen function points() start not at x = 1 (at x = - something)
> 
> graphics.off()
> x11()
> split.screen(c(3, 1))
> split.screen(c(2, 1), 1)
> 
> screen(3)
> plot(dat, type = "n")
> screen(4)
> plot(dat, type = "n")
> screen(2)
> plot(dat, type = "n")
> 
> dat <- rnorm(1000)
> 
> for (i in 1:length(dat)){
>   screen(3)
>   points(i, dat[i])
>   screen(4)
>   points(i, dat[i])
>   screen(2)
>   points(i, dat[i])
> }
> 
> close.screen(all = TRUE)
> 
> I was searching the mail-archives and found the same question but no answers.
> Can somebody help me?

This is a bug, already submitted as bug report PR#2069.
There are a couple of other unfixed bugs related to split.screen(), so 
I'd recommend to use layout() or par(mfrow = ..) in your case, or even 
better: consider to contribute a bugfix.

>  
> 2. Can I draw segments() in the figure margin (not in the plot region).... or can I split my axis(2,...) in 3 with a gap between them? 

You can by setting par(xpd = TRUE). See ?par for details.

Uwe Ligges

>  
> thanks for any help
>  
> Thomas
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From paul_divi at yahoo.gr  Sat Sep  6 17:06:44 2003
From: paul_divi at yahoo.gr (=?iso-8859-7?q?Paul=20Divid?=)
Date: Sat, 6 Sep 2003 16:06:44 +0100 (BST)
Subject: [R] Fitting t-Student(mu, sigma, nu)
Message-ID: <20030906150644.14202.qmail@web12903.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030906/382e852f/attachment.pl

From MSchwartz at medanalytics.com  Sat Sep  6 18:35:16 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Sat, 06 Sep 2003 11:35:16 -0500
Subject: [R] split.screen problem and segments in figure margin
In-Reply-To: <3F59F6CB.7040300@statistik.uni-dortmund.de>
References: <53A181E56FB0694ABFD212F8AEDA7F6F1AB867@langouste.zhwin.ch>
	<3F59F6CB.7040300@statistik.uni-dortmund.de>
Message-ID: <1062866116.22138.393.camel@localhost>

On Sat, 2003-09-06 at 10:01, Uwe Ligges wrote:
> Untern?hrer Thomas, uth wrote:
> > hi,
> >  
> > two questions...
> >  
> > 1. what happens with points()?
> >     after the split.screen function points() start not at x = 1 (at x = - something)
> > 
> > graphics.off()
> > x11()
> > split.screen(c(3, 1))
> > split.screen(c(2, 1), 1)
> > 
> > screen(3)
> > plot(dat, type = "n")
> > screen(4)
> > plot(dat, type = "n")
> > screen(2)
> > plot(dat, type = "n")
> > 
> > dat <- rnorm(1000)
> > 
> > for (i in 1:length(dat)){
> >   screen(3)
> >   points(i, dat[i])
> >   screen(4)
> >   points(i, dat[i])
> >   screen(2)
> >   points(i, dat[i])
> > }
> > 
> > close.screen(all = TRUE)
> > 
> > I was searching the mail-archives and found the same question but no answers.
> > Can somebody help me?
> 
> This is a bug, already submitted as bug report PR#2069.
> There are a couple of other unfixed bugs related to split.screen(), so 
> I'd recommend to use layout() or par(mfrow = ..) in your case, or even 
> better: consider to contribute a bugfix.


I may be missing something here, but in follow up to Uwe's reply, unless
you are specifically trying to demonstrate the bug, you are calling
plot(dat, ...) in each of the initial screens BEFORE 'dat' is defined in
your code.

At least the first time you run the code, you should get:

> screen(3)
> plot(dat, type = "n")
Error in plot(dat, type = "n") : Object "dat" not found

> screen(4)
> plot(dat, type = "n")
Error in plot(dat, type = "n") : Object "dat" not found

> screen(2)
> plot(dat, type = "n")
Error in plot(dat, type = "n") : Object "dat" not found


Of course, on each subsequent run of the code sequence, 'dat' is then
defined prior to the initial plot() calls if you don't rm(dat) each
time.

If you modify the code to:


graphics.off()
x11()
split.screen(c(3, 1))
split.screen(c(2, 1), 1)

# Define 'dat' here!
dat <- rnorm(1000)
x <- 1:1000

screen(3)
plot(dat, type = "n")
par("usr")

screen(4)
plot(dat, type = "n")
par("usr")

screen(2)
plot(dat, type = "n")
par("usr")

screen(3)
par("usr")
points(x, dat)

screen(4)
par("usr")
points(x, dat)

screen(2)
par("usr")
points(x, dat)

close.screen(all = TRUE)

It seems to run fine.

Note you do not require a for() loop for the calls to points() and that
for each of the par("usr") calls I get:

[1]  -38.960000 1039.960000   -3.116957    3.958396

This is using R 1.7.1 under RH 9.


To lengthen the reply a bit, I also tried the following using different
vectors for 'dat' to be sure that there was not a residual problem with
par("usr"), given that all three original plots are using the same data:

graphics.off()
x11()
split.screen(c(3, 1))
split.screen(c(2, 1), 1)

dat4 <- rnorm(1000)
x <- 1:1000

dat2 <- dat4 * 2

dat3 <- dat4 * 3

screen(3)
plot(dat3, type = "n")
par("usr")
[1]  -38.96000 1039.96000  -11.51162   10.63908

screen(4)
plot(dat4, type = "n")
par("usr")
[1]  -38.960000 1039.960000   -3.837208    3.546360

screen(2)
plot(dat2, type = "n")
par("usr")
[1]  -38.960000 1039.960000   -7.674416    7.092720

screen(3)
par("usr")
[1]  -38.96000 1039.96000  -11.51162   10.63908
points(x, dat3)

screen(4)
par("usr")
[1]  -38.960000 1039.960000   -3.837208    3.546360
points(x, dat4)

screen(2)
par("usr")
[1]  -38.960000 1039.960000   -7.674416    7.092720
points(x, dat2)

close.screen(all = TRUE)

HTH,

Marc Schwartz



From tzhou1 at students.uiuc.edu  Sat Sep  6 18:42:41 2003
From: tzhou1 at students.uiuc.edu (tzhou1)
Date: Sat, 6 Sep 2003 11:42:41 -0500
Subject: [R] fit data with skew t distribution
Message-ID: <3F7ED209@webmail.uiuc.edu>

Hi, Kjetil,

Thank you very much for your help! I tried mst.fit and mst.mle. They both did 
a good job for solving my problem.

Tianyue

>===== Original Message From "kjetil brinchmann halvorsen" 
<kjetil at entelnet.bo> =====
>On 5 Sep 2003 at 16:20, tzhou1 wrote:
>
>I don't know what a skew t distribution is, but
>help.search("skew t")
>gives
>
>dmst(sn)                Multivariate skew-t distribution
>dst(sn)                 Skew-t Distribution
>dst2.plot(sn)           Plot of Bivariate Skew-t Density Function
>msn.affine(sn)          Affine transformation a multivariate
>                        skew-normal or skew-t variable
>mst.fit(sn)             Fitting multivariate skew-t distributions
>
>so you shoukd probably install package sn from CRAN.
>
>Kjetil Halvorsen
>
>> Hi,
>>
>> Is there a function in R that I can use to fit the data with skew t
>> distribution? Speaking in detail, I first used the kernel density 
estimation
>> to fit my data, then I drew the skew t using my specified location, scale,
>> shape, and df to make it close to the kernel density. Now I want to get the
>> parameter estimations of the skew t which give me the closet density to the
>> kernel density. Which functions in R can do this? Any suggestions are
>> welcome!!
>>
>> Thanks!
>>
>> Tianyue
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From cati_andrej at yahoo.com  Sat Sep  6 18:49:35 2003
From: cati_andrej at yahoo.com (Andrej Kveder)
Date: Sat, 6 Sep 2003 09:49:35 -0700 (PDT)
Subject: [R] automatic model specification
Message-ID: <20030906164935.90047.qmail@web11105.mail.yahoo.com>

Dear listers,


I must first say that all the suggestions and help I
got from the list so far was of great help to my work.

I approach you with another question. Is it possible
to generate an automatic specification of the formula
for lme (or other models in R)? Let me clarify. I'm
using models in a simulation run and can have variable
number of variables in the data. I would like to
generate the formula as a string automaticaly
depending on the data structure. I had something like
this in mind:

my.formula<-"y~x1+x2+x3"
my.ran<-"~ x1"
d<-groupedData(my.formula | inter, data=d.n.data)
model<-lme(my.formula, data=d, random=my.ran | group)

I know this doesn't work. The error reports wrong type
for the formula. Is there a way to do this? 

Thanks for all the help and suggestions

Andrej

_________
Andrej Kveder, M.A.
researcher
Institute of Medical Sciences SRS SASA; Novi trg 2,
SI-1000 Ljubljana, Slovenia
phone: +386 1 47 06 440   fax: +386 1 42 61 493



From maechler at stat.math.ethz.ch  Sat Sep  6 19:27:59 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 6 Sep 2003 19:27:59 +0200
Subject: [R] laplace transform
In-Reply-To: <1062847961.3f59c5d9cf4e8@my.uq.edu.au>
References: <43a203f0f3.3f0f343a20@jhsph.edu>
	<1062847961.3f59c5d9cf4e8@my.uq.edu.au>
Message-ID: <16218.6431.844101.896829@gargle.gargle.HOWL>

>>>>> "Andrew" == Andrew C Ward <s195404 at student.uq.edu.au>
>>>>>     on Sat,  6 Sep 2003 11:32:41 +0000 writes:

    Andrew> Dear Ravi, R calls many functions that are written
    Andrew> in FORTRAN. As a start on how to do this, perhaps
    Andrew> look at the cluster package.

But that doesn't help Ravi.
He needs to learn how to call R functions from compiled code,
since one wants the laplace transform of an R function.

1) you can do this only from C, not from Fortran
2) This is not a big problem, since it will be the C code that
   both calls into Fortran and into R.

In some sense, this problem is very much similar ``in spirit''
to solving differential equations: 
You have functions as input and functions as output.
And you are lucky: The "odesolve" CRAN package has the same
basic setup as you: It uses a Fortran algorithm to solve
differential equations specified by R functions.

So download odesolve (source, not "install package"), study its
code and learn :-)  You definitely should also (first) learn
from reading in the "Writing R Extensions" manual, particularly
the chapter "System and foreign language interfaces".

Regards,
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><

    Andrew> Quoting Ravi Varadhan <rvaradha at jhsph.edu>:

    >> Hi:
    >> 
    >> I have written a Fortran program based on the
    >> Gaver-Stehfest algorithm, which uses only real numbers
    >> (as opposed to the more powerful methods using complex
    >> numbers). However, this can't be used in R since the
    >> function specifying the inverse of the Laplace transform
    >> must also be written in Fortran.  I would be interested
    >> in learning how to define the function in R and then
    >> calling the Fortran subroutines to do the inverse
    >> computations. Can anyone tell me how to do this?
    >> 
    >> thanks, Ravi.
    >> 
    >> ----- Original Message ----- From: "Andrew C. Ward"
    >> <s195404 at student.uq.edu.au> Date: Friday, September 5,
    >> 2003 1:03 am Subject: Re: [R] laplace transform
    >> 
    >> > Dear Luca,
    >> > 
    >> > I don't think that R has a built-in function for doing
    >> > Laplace or inverse Laplace transforms. I remember
    >> having to > use an IMSL routine (INLP, I think) to do
    >> this many years > ago. When I looked at the article that
    >> the algorithm was > based on, I found that as an example
    >> the author showed how > well the method worked when
    >> inverting 1/s! Presumably,
    >> 
    >> > things have improved since then.
    >> > 
    >> > A Google search of (numerical "inverse laplace
    >> transform") > yields a number of references that should
    >> get you started.  > If you write some R code to do this,
    >> think about submitting > it to CRAN. Even though a lot of
    >> R/S code is devoted to > statistical methods, there's no
    >> reason at all why all kinds > of other things can't be
    >> written.
    >> > 
    >> > 
    >> > Regards,
    >> > 
    >> > Andrew C. Ward
    >> > 
    >> > CAPE Centre > Department of Chemical Engineering > The
    >> University of Queensland > Brisbane Qld 4072 Australia >
    >> andreww at cheque.uq.edu.au
    >> > 
    >> > 
    >> > Quoting Luca Laghi <llaghi at foodsci.unibo.it>:
    >> > 
    >> > > Dear users, > > is anybody of you aware of a R
    >> command to perform laplace > > transform or > > even its
    >> inversion?  > > Thank you very much.  > > Luca
    >> > >



From kjetil at entelnet.bo  Sat Sep  6 19:49:34 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Sat, 06 Sep 2003 13:49:34 -0400
Subject: [R] Fitting t-Student(mu, sigma, nu)
In-Reply-To: <20030906150644.14202.qmail@web12903.mail.yahoo.com>
Message-ID: <3F59E5EE.1746.7EBE59@localhost>

On 6 Sep 2003 at 16:06, Paul Divid wrote:

?fitdistr
will give you the answers. 

Something like:

> library(MASS)
> test <- rt(100, df=8)
> fitdistr( test, "t", df=30 )
       m            s     
  0.04966923   1.17588480 
 (0.12130013) (0.08745488)
> fitdistr( test, "t", df=8 )
       m            s     
  0.04895709   1.07989354 
 (0.11957624) (0.08891004)

If you want to estimate df too, see the help page. 

Kjetil Halvorsen


> Dear R users:
>  
> 1. Is there a function which fits to the data the t-student distribution 
> with parameters mu, sigma, nu.
>  
> Is the function fitdistr of MASS
> with the syntax fitdistr(x, "t")
> appropriate for this?
>  
>  
> 2. Is there a function which can fit the exponential power distribution?
>  
> Thanks.
>  
> 
> 
> 
> ---------------------------------
> 
> ????????? ??? ?????? ???@yahoo.gr
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From andrejk at zrc-sazu.si  Sat Sep  6 21:19:52 2003
From: andrejk at zrc-sazu.si (Andrej Kveder)
Date: Sat, 6 Sep 2003 21:19:52 +0200
Subject: [R] automatic model specification
In-Reply-To: <3F5A2EDF.1010504@pburns.seanet.com>
Message-ID: <FHEEJBDDCNPPNJEACDJAKECKDCAA.andrejk@zrc-sazu.si>

Thanks it did the trick.

Andrej



-----Original Message-----
From: Patrick Burns [mailto:pburns at pburns.seanet.com]
Sent: Saturday, September 06, 2003 9:01 PM
To: andrejk at zrc-sazu.si
Subject: Re: [R] automatic model specification


Does doing

as.formula(my.formula)

etc. solve your problem?

Patrick Burns

Burns Statistics
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

Andrej Kveder wrote:

>Dear listers,
>
>
>I must first say that all the suggestions and help I
>got from the list so far was of great help to my work.
>
>I approach you with another question. Is it possible
>to generate an automatic specification of the formula
>for lme (or other models in R)? Let me clarify. I'm
>using models in a simulation run and can have variable
>number of variables in the data. I would like to
>generate the formula as a string automaticaly
>depending on the data structure. I had something like
>this in mind:
>
>my.formula<-"y~x1+x2+x3"
>my.ran<-"~ x1"
>d<-groupedData(my.formula | inter, data=d.n.data)
>model<-lme(my.formula, data=d, random=my.ran | group)
>
>I know this doesn't work. The error reports wrong type
>for the formula. Is there a way to do this? 
>
>Thanks for all the help and suggestions
>
>Andrej
>
>_________
>Andrej Kveder, M.A.
>researcher
>Institute of Medical Sciences SRS SASA; Novi trg 2,
>SI-1000 Ljubljana, Slovenia
>phone: +386 1 47 06 440   fax: +386 1 42 61 493
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
>  
>



From quesadaj at psych.colorado.edu  Sun Sep  7 00:52:33 2003
From: quesadaj at psych.colorado.edu (Jose Quesada)
Date: Sat, 06 Sep 2003 16:52:33 -0600
Subject: [R] X11 not available
Message-ID: <opru3ohvdlx8hwns@localhost>

Hi All,

After compiling R-1.7.1 on a P4 running a default install of redHat 9 
(which of course has X11), I get the following error:
> x11()
Error in x11() : X11 is not available

This is surprising, because in ./configure I gave:

./configure \
--enable-R-shlib \
--with-x \
--with-lapack \
--with-gnome

Any idea why this is happening? It also occurs if i install the rpm from 
CRAN...
Thanks a lot in advance,
-Jose

-- 
Jose Quesada, PhD.

quesadaj at psych.colorado.edu             Research associate
http://lsa.colorado.edu/~quesadaj       Institute of Cognitive Science
					University of Colorado (Boulder)

Muenzinger psychology building          Phone:303 492 1522
office D447A						Fax:  303 492 7177
Campus Box 344
University of Colorado at Boulder
Boulder, CO 80309-0344



From MSchwartz at medanalytics.com  Sun Sep  7 03:44:25 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Sat, 06 Sep 2003 20:44:25 -0500
Subject: [R] X11 not available
In-Reply-To: <opru3ohvdlx8hwns@localhost>
References: <opru3ohvdlx8hwns@localhost>
Message-ID: <1062899064.22138.637.camel@localhost>

On Sat, 2003-09-06 at 17:52, Jose Quesada wrote:
> Hi All,
> 
> After compiling R-1.7.1 on a P4 running a default install of redHat 9 
> (which of course has X11), I get the following error:
> > x11()
> Error in x11() : X11 is not available
> 
> This is surprising, because in ./configure I gave:
> 
> ./configure \
> --enable-R-shlib \
> --with-x \
> --with-lapack \
> --with-gnome
> 
> Any idea why this is happening? It also occurs if i install the rpm from 
> CRAN...
> Thanks a lot in advance,
> -Jose


Jose,

Make sure that you have installed the XFree86 Development RPM from the
RH CDs.

Open a console and type:

rpm -qa | grep XFree86-devel

You should get:

XFree86-devel-4.3.0-2

If you do not, you will need to install the XFree86 development RPM from
the RH CD's or remove the version of R you compiled and re-install using
the pre-compiled RPM that Martyn has on CRAN.

In order to compile the application from source, you need the 'devel'
libraries and headers installed on your system.

HTH,

Marc Schwartz



From MSchwartz at medanalytics.com  Sun Sep  7 05:06:37 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Sat, 06 Sep 2003 22:06:37 -0500
Subject: [R] split.screen problem and segments in figure margin
In-Reply-To: <1062866116.22138.393.camel@localhost>
References: <53A181E56FB0694ABFD212F8AEDA7F6F1AB867@langouste.zhwin.ch>
	<3F59F6CB.7040300@statistik.uni-dortmund.de>
	<1062866116.22138.393.camel@localhost>
Message-ID: <1062903997.22138.737.camel@localhost>


Many thanks to Uwe and Thomas for their off-list clarifications.

To quote my daughter, who recently said with a slip of the tongue: "Dad,
you are not being very observative". 

I apologize for my oversight on this one.

As a result of focusing on the initial function sequence that Thomas
posted, where 'dat' was assigned after the call to plot(dat, ...) and
then reviewing the bug report, I was led to focus on any changes in
certain graphic parameters as per my reply. I however missed the now
obvious error in the way that the points are being plotted outside of
the expected ranges.

I suppose that this is a good example of "Be careful of what ye seek..."

That all being said, I have spent much of the day trying to track this
one down, albeit without definitive success at this point.

After reviewing the code for split.screen, screen and erase.screen, I
have noted that there is a probability that at least part of the problem
is embedded in how the device parameters for each individual screen are
being saved and restored as one changes from screen to screen. There is
an explicit list of parameters (defined in split.screen) that are being
saved and manipulated in the Global Environment and my suspicion at this
point is that there is a mis-match of some sort in that process.

The particular pars that are being saved and restored are:

c("adj", "bty", "cex", "col", "crt", "err", "font", "lab", "las", "lty",
"lwd", "mar", "mex", "mfg", "mgp", "pch", "pty", "smo", "srt", "tck",
"usr", "xaxp", "xaxs", "xaxt", "xpd", "yaxp", "yaxs", "yaxt", "fig")


One can run the following code with proper results:

graphics.off()
x11()
split.screen(c(3, 1))
split.screen(c(2, 1), 1)

dat <- rnorm(1000)

screen(3)
plot(dat, type = "n")
par3 <- par(no.readonly = TRUE)

screen(4)
plot(dat, type = "n")
par4 <- par(no.readonly = TRUE)

screen(2)
plot(dat, type = "n")
par2 <- par(no.readonly = TRUE)

# In lieu of screen(3)
par(fig = par3$fig)
par(usr = par3$usr)
points(dat)

# In lieu of screen(4)
par(xpd = TRUE)
par(fig = par4$fig)
par(usr = par4$usr)
points(dat)

# In lieu of screen(2)
par(xpd = FALSE)
par(fig = par2$fig)
par(usr = par2$usr)
points(dat)

close.screen(all = TRUE)


Note that I explicitly save the non-readonly pars after each plot() call
so that I can restore specific pars prior to calling points().

Rather than using screen() to select the screen to place the set of
points, I am explicitly setting par("fig") and par("usr"), which
essentially accomplishes the same thing as screen(), although there is a
lot of additional code and other pars that get saved and restored, in
that function of course.

What is curious however, is the need to set par(xpd = TRUE) for the
second call to points(). If I do not, then no points are drawn after the
first set. Note that I have to re-set par(xpd = FALSE) for the third set
of points, or they do not plot. This gets curiouser and curiouser...

What is also interesting, is that the default arguments to screen() not
only include the screen number, but 'new' which is set to TRUE by
default. The effect of this argument is to call erase.screen(). However,
the default background color is 'transparent'. Thus if one calls
screen() as Thomas did in the original code, there is no visible screen
clearing effect. If one however sets par(bg = "white") before calling
the screen() calls, the individual screens are indeed cleared. This
behavior is referenced in the help 'warning' section for these screen
related functions.. 

Thus, in the situation Thomas is trying to get to work (go back to a
plot and add to it), in reality each call to screen should be of the
form screen(n, new = FALSE).

Now, with that in place, using the following section of code in place of
the second series of calls above:

screen(3, new = FALSE)
points(dat)

screen(4, new = FALSE)
points(dat)

screen(2, new = FALSE)
points(dat)

close.screen(all = TRUE)


One actually gets the first set of points properly plotted. However the
second and third sets do not. This brings us back to par("xpd"), yet
with a curious result. If I try to take the approach that I did above:

screen(3, new = FALSE)
points(dat)

screen(4, new = FALSE)
par(xpd = TRUE)
points(dat)

screen(2, new = FALSE)
par(xpd = FALSE)
points(dat)

close.screen(all = TRUE)

This results in a proper first set of points in the lower screen, but
the other two, which have a proper x axis range, are improperly plotted
on the y axis.

At this point, after looking at the code, I am losing my
"observativeness" and cannot seem to identify what is causing the
problems as Thomas first noted today.  Perhaps someone with a clear set
of eyes can see something here. I hope that this may be of help in
providing some sense of direction here. If there is something obvious, I
am just not seeing it at this point, but then again, my eyes are pretty
glazed over...

Marc



From han at math.sc.edu  Sun Sep  7 06:08:51 2003
From: han at math.sc.edu (Jun Han)
Date: Sun, 7 Sep 2003 00:08:51 -0400
Subject: [R] help on R
Message-ID: <NHBBLEPGJBPCLMGLBJPIAENICBAA.han@math.sc.edu>

Hi, there,

Is there a R routine which can fit multinomial logistic regression for
nominal outcomes?
Not the multinom() of log-linear model, neither the polr() for ordinal
outcomes.
Thanks.

Jun Han



From pri at chu.com.au  Sun Sep  7 12:23:31 2003
From: pri at chu.com.au (Philip Rhoades)
Date: Sun, 7 Sep 2003 20:23:31 +1000
Subject: [R] Centring ticks on hists
Message-ID: <20030907102331.GA15623@phil>

Hi people,

With:

	hist(rnorm(200, 10, 3), breaks=20)

- how do I centre the ticks below each hist rectangle?

Thanks,

Phil.
--
Philip Rhoades

Pricom Pty Limited  (ACN 003 252 275  ABN 91 003 252 275)
GPO Box 3411
Sydney NSW	2001
Australia
Mobile:  +61:0411-185-652
Fax:  +61:2:8923-5363
E-mail:  pri at chu.com.au



From p.dalgaard at biostat.ku.dk  Sun Sep  7 12:27:12 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Sun, 07 Sep 2003 10:27:12 -0000
Subject: [R] X11 not available
In-Reply-To: <1062899064.22138.637.camel@localhost>
References: <opru3ohvdlx8hwns@localhost> <1062899064.22138.637.camel@localhost>
Message-ID: <x24qzozycw.fsf@biostat.ku.dk>

Marc Schwartz <MSchwartz at medanalytics.com> writes:

> Open a console and type:
> 
> rpm -qa | grep XFree86-devel
> 
> You should get:
> 
> XFree86-devel-4.3.0-2

Correct, but it's a very slow way of doing

rpm -q XFree86-devel

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From MSchwartz at medanalytics.com  Sun Sep  7 15:57:13 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Sun, 07 Sep 2003 08:57:13 -0500
Subject: [R] Centring ticks on hists
In-Reply-To: <20030907102331.GA15623@phil>
References: <20030907102331.GA15623@phil>
Message-ID: <1062943033.22138.742.camel@localhost>

On Sun, 2003-09-07 at 05:23, Philip Rhoades wrote:
> Hi people,
> 
> With:
> 
> 	hist(rnorm(200, 10, 3), breaks=20)
> 
> - how do I centre the ticks below each hist rectangle?
> 
> Thanks,
> 
> Phil.
> --
> Philip Rhoades


hist() returns a list of elements, one of which is 'mids', which are the
cell centers. Thus, use something like:

hist.data <- hist(rnorm(200, 10, 3), breaks=20, axes = FALSE)
axis(1, at = hist.data$mids)
axis(2)

See ?hist for more information.

HTH,

Marc Schwartz



From MSchwartz at medanalytics.com  Sun Sep  7 16:04:07 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Sun, 07 Sep 2003 09:04:07 -0500
Subject: [R] X11 not available
In-Reply-To: <x24qzozycw.fsf@biostat.ku.dk>
References: <opru3ohvdlx8hwns@localhost>
	<1062899064.22138.637.camel@localhost> <x24qzozycw.fsf@biostat.ku.dk>
Message-ID: <1062943446.22138.750.camel@localhost>

On Sun, 2003-09-07 at 05:28, Peter Dalgaard BSA wrote:
> Marc Schwartz <MSchwartz at medanalytics.com> writes:
> 
> > Open a console and type:
> > 
> > rpm -qa | grep XFree86-devel
> > 
> > You should get:
> > 
> > XFree86-devel-4.3.0-2
> 
> Correct, but it's a very slow way of doing
> 
> rpm -q XFree86-devel


Quite true:

$ time rpm -q XFree86-devel
XFree86-devel-4.3.0-2
 
real    0m0.054s
user    0m0.040s
sys     0m0.010s

$ time rpm -qa | grep XFree86-devel
XFree86-devel-4.3.0-2
 
real    0m15.021s
user    0m13.880s
sys     0m0.230s


Thanks for pointing that out Peter.

Marc



From jfox at mcmaster.ca  Sun Sep  7 16:08:08 2003
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 07 Sep 2003 10:08:08 -0400
Subject: [R] help on R
In-Reply-To: <NHBBLEPGJBPCLMGLBJPIAENICBAA.han@math.sc.edu>
Message-ID: <5.1.0.14.2.20030907100509.01f8af20@127.0.0.1>

Dear Jun Han,

The multinom function in the nnet package does fit what's usually called 
the multinomial logistic regression model. How does the model that you want 
to fit differ?

John

At 12:08 AM 9/7/2003 -0400, Jun Han wrote:
>Hi, there,
>
>Is there a R routine which can fit multinomial logistic regression for
>nominal outcomes?
>Not the multinom() of log-linear model, neither the polr() for ordinal
>outcomes.
>Thanks.
>
>Jun Han

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From hornbeck1 at adelphia.net  Sun Sep  7 19:28:02 2003
From: hornbeck1 at adelphia.net (Peter Hornbeck)
Date: Sun, 7 Sep 2003 13:28:02 -0400
Subject: [R] Need help with cluster analysis of amino acid sequences
Message-ID: <000201c37565$66e387c0$6401a8c0@PVHXP>

I am just starting to use R and am wanting to use the cluster algorithm for
analyzing sequences of amino acids for similarities.  The input will be
lists of short sequences of 8-15 amino acids.

Let me give you a feel for the sort of data I am interested in.

 Amino acids can be classified by a number of different parameters: e.g.,
charge and hydrophobicity.  Each of these qualities could be described by a
numerical assignment: charge (perhaps as either 0 or 1), and hydrophobicity
(perhaps as a continuum from 0 to 1).  The point of the analysis is to
cluster those sequences that have similar properties at different positions
along the sequence.

My question is: is there a user group of biologists that may be able to
provide tips about how to proceed, or perhaps who already have developed
algorithms that can be applied/modified to the sort of analysis I need?

Or does anyone have suggestions of other on-line resources that might be
helpful?

Thanks, Peter

Peter Hornbeck
Magnolia, MA
01930
(978) 5264867



From deepayan at stat.wisc.edu  Sun Sep  7 20:02:06 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Sun, 7 Sep 2003 13:02:06 -0500
Subject: [R] Need help with cluster analysis of amino acid sequences
In-Reply-To: <000201c37565$66e387c0$6401a8c0@PVHXP>
References: <000201c37565$66e387c0$6401a8c0@PVHXP>
Message-ID: <200309071302.06375.deepayan@stat.wisc.edu>


The bioconductor project [1] might be of interest to you, and its mailing list 
[2] is probably more appropriate for your question.

[1] http://www.bioconductor.org
[2] https://www.stat.math.ethz.ch/mailman/listinfo/bioconductor

HTH,

Deepayan

On Sunday 07 September 2003 12:28, Peter Hornbeck wrote:
> I am just starting to use R and am wanting to use the cluster algorithm for
> analyzing sequences of amino acids for similarities.  The input will be
> lists of short sequences of 8-15 amino acids.
>
> Let me give you a feel for the sort of data I am interested in.
>
>  Amino acids can be classified by a number of different parameters: e.g.,
> charge and hydrophobicity.  Each of these qualities could be described by a
> numerical assignment: charge (perhaps as either 0 or 1), and hydrophobicity
> (perhaps as a continuum from 0 to 1).  The point of the analysis is to
> cluster those sequences that have similar properties at different positions
> along the sequence.
>
> My question is: is there a user group of biologists that may be able to
> provide tips about how to proceed, or perhaps who already have developed
> algorithms that can be applied/modified to the sort of analysis I need?
>
> Or does anyone have suggestions of other on-line resources that might be
> helpful?
>
> Thanks, Peter
>
> Peter Hornbeck
> Magnolia, MA
> 01930
> (978) 5264867
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From abunn at montana.edu  Sun Sep  7 20:31:44 2003
From: abunn at montana.edu (Andy Bunn)
Date: Sun, 7 Sep 2003 12:31:44 -0600
Subject: [R] extracting monthly temperature data
Message-ID: <000b01c3756e$5bf12ad0$78f05a99@msu.montana.edu>

I know that R is very advanced when it comes to DateTime handling. I am
not quite as advanced as R however.

I just downloaded a stupendously ugly dataset of hourly air temperature
from 1985 to 2003. It has a great many NAs. I want to extract mean,
median, max, and min monthly values.

So far I have read it in as object. Date and Time are factors and Temp
is an int.

> summary(temp.dat)
         Date             Time             Temp         
 01/01/1986:    24   03:00  :  6457   Min.   :  -22.00  
 01/01/1987:    24   04:00  :  6457   1st Qu.:   23.00  
 01/01/1988:    24   05:00  :  6457   Median :   34.00  
 01/01/1989:    24   06:00  :  6457   Mean   :   34.35  
 01/01/1990:    24   10:00  :  6457   3rd Qu.:   45.00  
 01/01/1992:    24   11:00  :  6457   Max.   :   89.00  
 (Other)   :154794   (Other):116196   NA's   :52178.00  

I then made a POSIXt object for the dates and times.

> date.time <- strptime(paste(temp.dat$Date, temp.dat$Time), "%m/%d/%Y
%H:")
> class(date.time)
[1] "POSIXt"  "POSIXlt"
> date.time[1]
[1] "1985-10-01 01:00:00"


Now I'm stuck.

Questions: 

What's the best class for reuniting the temperature data with the dates?
A time series? A list?

Depending on the answer, what's the best way to extract, say, the mean
temperatures for Sepetmber?

Thanks in advance, Andy



From spencer.graves at pdf.com  Sun Sep  7 21:01:42 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 07 Sep 2003 12:01:42 -0700
Subject: [R] extracting monthly temperature data
References: <000b01c3756e$5bf12ad0$78f05a99@msu.montana.edu>
Message-ID: <3F5B8096.3000302@pdf.com>

	  What is "class(temp.dat)"?  Have you considered "?data.frame"?  If 
"temp.dat" is a data.frame, you can recombine date.time with Temp via

	  temp.dat$date.time <- date.time.

	  Then you can "rm(date.time)", because the above command makes a copy 
as a column of the data.frame temp.dat.

	  I have not been working with POSIXt, so I can't answer your question 
about how to get monthly means, other than to ask if you know about 
subscripting with a logical vector, "aggregate" and "tapply"?

hope this helps.  spencer graves

Andy Bunn wrote:
> I know that R is very advanced when it comes to DateTime handling. I am
> not quite as advanced as R however.
> 
> I just downloaded a stupendously ugly dataset of hourly air temperature
> from 1985 to 2003. It has a great many NAs. I want to extract mean,
> median, max, and min monthly values.
> 
> So far I have read it in as object. Date and Time are factors and Temp
> is an int.
> 
> 
>>summary(temp.dat)
> 
>          Date             Time             Temp         
>  01/01/1986:    24   03:00  :  6457   Min.   :  -22.00  
>  01/01/1987:    24   04:00  :  6457   1st Qu.:   23.00  
>  01/01/1988:    24   05:00  :  6457   Median :   34.00  
>  01/01/1989:    24   06:00  :  6457   Mean   :   34.35  
>  01/01/1990:    24   10:00  :  6457   3rd Qu.:   45.00  
>  01/01/1992:    24   11:00  :  6457   Max.   :   89.00  
>  (Other)   :154794   (Other):116196   NA's   :52178.00  
> 
> I then made a POSIXt object for the dates and times.
> 
> 
>>date.time <- strptime(paste(temp.dat$Date, temp.dat$Time), "%m/%d/%Y
> 
> %H:")
> 
>>class(date.time)
> 
> [1] "POSIXt"  "POSIXlt"
> 
>>date.time[1]
> 
> [1] "1985-10-01 01:00:00"
> 
> 
> Now I'm stuck.
> 
> Questions: 
> 
> What's the best class for reuniting the temperature data with the dates?
> A time series? A list?
> 
> Depending on the answer, what's the best way to extract, say, the mean
> temperatures for Sepetmber?
> 
> Thanks in advance, Andy
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From abunn at montana.edu  Sun Sep  7 21:30:11 2003
From: abunn at montana.edu (Andy Bunn)
Date: Sun, 7 Sep 2003 13:30:11 -0600
Subject: [R] extracting monthly temperature data
In-Reply-To: <3F5B8096.3000302@pdf.com>
Message-ID: <000c01c37576$86801ec0$78f05a99@msu.montana.edu>

I can make a data.frame out of the data with the POSIXt objects in it
with the temp data. It's the syntax of the aggregate command that is
eluding me if aggregate and a data frame is the right way to go.


# remake a data frame
temp.dat <- data.frame(date.time, temp.dat$Temp)
colnames(temp.dat) <- c("date", "temp")

> summary(temp.dat)
      date                          temp         
 Min.   :1985-10-01 01:00:00   Min.   :  -22.00  
 1st Qu.:1990-05-02 03:15:00   1st Qu.:   23.00  
 Median :1994-11-01 06:30:00   Median :   34.00  
 Mean   :1994-10-19 13:07:38   Mean   :   34.35  
 3rd Qu.:1999-04-05 17:45:00   3rd Qu.:   45.00  
 Max.   :2003-09-05 16:00:00   Max.   :   89.00  
                               NA's   :52178.00  

aggregate(temp.dat$temp, list(temp.dat$date$mon == 9), mean)


Thx, A



From rpietro at duke.edu  Sun Sep  7 21:32:41 2003
From: rpietro at duke.edu (Ricardo Pietrobon)
Date: Sun, 7 Sep 2003 15:32:41 -0400 (EDT)
Subject: [R] data manipulation
Message-ID: <Pine.GSO.4.56.0309071501010.22900@teer9.acpub.duke.edu>

Hi,


I am new to R, coming from a few years using Stata. I've been twisting my
brain and checking several R and S references over the last few days to
try to solve this data management problem: I have a data set with a unique
patient identifier that is repeated along multiple rows, a variable with
month of patient encounter, and a continous variable for cost of
individual encounters. The data looks like this:

ID	date		cost
1	"2001-01"	200.00
1	"2001-01"	123.94
1	"2001-03"	100.23
1	"2001-04"	150.34
2	"2001-03"	296.34
2	"2002-05"	156.36


I would like to obtain the median costs and boxplots for the sum of
encounters happening in the first six months after the index encounter
(first patient encounter) for each patient, then the mean and median costs
for the costs happening from 6 to 12 months after the index encounter, and
so on. Notice that the first ID has two encounters during the index date,
making it more difficult to define a single row with the index encounter.

Any help would be appreciated,


Ricardo


Ricardo Pietrobon, MD
Assistant Professor of Surgery
Duke University Medical Center
Durham, NC 27710 US



From p.dalgaard at biostat.ku.dk  Sun Sep  7 22:34:18 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Sun, 07 Sep 2003 20:34:18 -0000
Subject: [R] data manipulation
In-Reply-To: <Pine.GSO.4.56.0309071501010.22900@teer9.acpub.duke.edu>
References: <Pine.GSO.4.56.0309071501010.22900@teer9.acpub.duke.edu>
Message-ID: <x2r82sxrnd.fsf@biostat.ku.dk>

Ricardo Pietrobon <rpietro at duke.edu> writes:

> ID	date		cost
> 1	"2001-01"	200.00
> 1	"2001-01"	123.94
> 1	"2001-03"	100.23
> 1	"2001-04"	150.34
> 2	"2001-03"	296.34
> 2	"2002-05"	156.36
> 
> 
> I would like to obtain the median costs and boxplots for the sum of
> encounters happening in the first six months after the index encounter
> (first patient encounter) for each patient, then the mean and median costs
> for the costs happening from 6 to 12 months after the index encounter, and
> so on. Notice that the first ID has two encounters during the index date,
> making it more difficult to define a single row with the index encounter.
> 
> Any help would be appreciated,

Let's see... You're going to need a bit of slight ugliness to convert
the date to a numeric month number. Something like (NB: That's a code
that means "I didn't actually try this"...)

attach(yourdata)
monthnum <- sapply(strsplit(date,"-"),function(x)sum(as.numeric(x)*c(12,1)))

Then we need a table of the index dates for each person

tbl <- tapply(monthnum, ID, min)

Now subtract the index date from monthnum

months.post.index <- monthnum - tbl[ID]

then you probably want to look at the subset of your original data
frame and do the sums

total.cost.6mo <- with(subset(yourdata,months.post.index < 6), 
                       tapply(cost,ID,sum))

and finally

boxplot(total.cost.6mo)
median(total.cost.6mo)

(You could elaborate by converting months.post.index with cut() and
use lapply(names(period),.....) to give you a list of tables, which
boxplot() might actually know how to plot directly.)
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From quesadaj at psych.colorado.edu  Mon Sep  8 03:11:41 2003
From: quesadaj at psych.colorado.edu (Jose Quesada)
Date: Sun, 07 Sep 2003 19:11:41 -0600
Subject: [R] png support
Message-ID: <opru5plrlyx8hwns@localhost>

Hi all,

It's me again with compiling questions :)

Even though I have libpng and zlib:
rpm -q libpng
libpng-1.2.2-8

and
rpm -q zlib
zlib-1.1.4-8.8x

my newly-compiled R doesn't support png.
> No png support in this version of R

Anyone knows why?

Thanks,
-Jose

-- 
Jose Quesada, PhD.

quesadaj at psych.colorado.edu             Research associate
http://lsa.colorado.edu/~quesadaj       Institute of Cognitive Science
					University of Colorado (Boulder)

Muenzinger psychology building          Phone:303 492 1522
office D447A						Fax:  303 492 7177
Campus Box 344
University of Colorado at Boulder
Boulder, CO 80309-0344



From quesadaj at psych.colorado.edu  Mon Sep  8 03:18:47 2003
From: quesadaj at psych.colorado.edu (Jose Quesada)
Date: Sun, 07 Sep 2003 19:18:47 -0600
Subject: [R] X11 not available
In-Reply-To: <1062899064.22138.637.camel@localhost>
References: <opru3ohvdlx8hwns@localhost> <1062899064.22138.637.camel@localhost>
Message-ID: <opru5pxlrvx8hwns@localhost>

On Sat, 06 Sep 2003 20:44:25 -0500, Marc Schwartz 
<MSchwartz at MedAnalytics.com> wrote:



> On Sat, 2003-09-06 at 17:52, Jose Quesada wrote:
>> Hi All,
>>
>> After compiling R-1.7.1 on a P4 running a default install of redHat 9
>> (which of course has X11), I get the following error:
>> > x11()
>> Error in x11() : X11 is not available
>>
>> This is surprising, because in ./configure I gave:
>>
>> ./configure \
>> --enable-R-shlib \
>> --with-x \
>> --with-lapack \
>> --with-gnome
>>
>> Any idea why this is happening? It also occurs if i install the rpm from
>> CRAN...
>> Thanks a lot in advance,
>> -Jose
>
>
> Jose,
>
> Make sure that you have installed the XFree86 Development RPM from the
> RH CDs.
>
> Open a console and type:
>
> rpm -qa | grep XFree86-devel
>
> You should get:
>
> XFree86-devel-4.3.0-2
>
> If you do not, you will need to install the XFree86 development RPM from
> the RH CD's or remove the version of R you compiled and re-install using
> the pre-compiled RPM that Martyn has on CRAN.
>
> In order to compile the application from source, you need the 'devel'
> libraries and headers installed on your system.
>
> HTH,
>
> Marc Schwartz
>
>

Thanks Marc,

That worked fine. A bunch of dependencies were detected when trying to 
install XFree86-devel-4.3.0-2. I tried to solve them, and installed some 
newer versions exisiting libraries, concretely:
XFree86-devel-4.3.0-25.i386.rpm
XFree86-libs-4.3-5mdk.i586.rpm
XFree86-libs-4.3.0-2.i386.rpm
XFree86-libs-4.3.0-25.i386.rpm
XFree86-libs-data-4.3.0
fontconfig-2.2.1-6mdk.i586.rpm
fontconfig-devel-2.2.1-4.i386.rpm
freetype-2.1.4-4.1.i386.rpm
freetype-devel-2.1.4-4.1.i386.rpm

Some dependencies were recursive (A needed B installed, B needed A to be 
installed), so I had to run rpm --nodeps (which is not a good practice). 
After an uninstall and reinstall fest, I have R working with Xwindows... 
but no other program can find X anymore :|. I still prefer that to having 
R with no X11, but if you have any advice to reinstall the newer XFree 
+ devel libraries in a clean way, without breaking dependencies, please 
let me know!

Thanks a lot again,
-Jose

-- 
Jose Quesada, PhD.

quesadaj at psych.colorado.edu             Research associate
http://lsa.colorado.edu/~quesadaj       Institute of Cognitive Science
					University of Colorado (Boulder)
Muenzinger psychology building          Phone:303 492 1522
office D447A						Fax:  303 492 7177
Campus Box 344
University of Colorado at Boulder
Boulder, CO 80309-0344



From rpeng at jhsph.edu  Mon Sep  8 03:47:52 2003
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Sun, 07 Sep 2003 21:47:52 -0400
Subject: [R] png support
In-Reply-To: <opru5plrlyx8hwns@localhost>
References: <opru5plrlyx8hwns@localhost>
Message-ID: <3F5BDFC8.8060605@jhsph.edu>

You need the devel versions of those libraries.  I think (not sure, 
though) that they are libpng-devel-*.rpm and zlib-devel-*.rpm where * is 
the version number.

-roger

Jose Quesada wrote:

> Hi all,
> 
> It's me again with compiling questions :)
> 
> Even though I have libpng and zlib:
> rpm -q libpng
> libpng-1.2.2-8
> 
> and
> rpm -q zlib
> zlib-1.1.4-8.8x
> 
> my newly-compiled R doesn't support png.
> 
>> No png support in this version of R
> 
> 
> Anyone knows why?
> 
> Thanks,
> -Jose
> 

-- 
Together, we can stop attaching Word documents
http://www.fsf.org/philosophy/no-word-attachments.html



From search-awareness at word-of-mouth-connection.com  Mon Sep  8 05:07:19 2003
From: search-awareness at word-of-mouth-connection.com (search-awareness@word-of-mouth-connection.com)
Date: Sun, 07 Sep 2003 22:07:19 -0500
Subject: [R] Someone just searched for word-of-mouth information about:
	r-help@lists.r-project.org
Message-ID: <E19wCN5-000393-IK@peter.wordofmouthconnections.info>


WordofMouthConnection.com Search Awareness System

This email is a website-generated message, but it is not spam.

An acquaintance of yours recently conducted a search on your email address in our online community, WordofMouthConnection.com. It could be a friend, a family member, co-worker, business associate, or someone else who's interested in learning more about you.

Why are we sending you this email?

When people find out others are talking about them -- whether it is good or bad -- they want to know. At WordofMouthConnection.com, we feel responsible to alert people so they have an opportunity to find out what is being said. 

Click here to view all "Word-of-Mouth Connections" in our system regarding this email address:

http://womc.net/pass.php?a=search&b=5&c=r-help at lists.r-project.org

How did we find you?

When your acquaintance searched for connections at our website he/she provided us with your email address.

What can you do?

First, we'd like to invite you to visit our website at www.WordofMouthConnection.com and learn about our service.  Registration is free. Not only can you find out if any WordofMouthConnection.com Connections have been submitted about you, but you can connect to others as well to research word-of-mouth information about your friends, co-workers, family, etc.

We are solely interested in fostering a community of willing people to promote information exchange. If you decide you're not interested, you can choose to block future emails from us. 

To add your email address to our Do Not Email List use the following link:

http://womc.net/pass.php?a=donotemail&b=r-help at lists.r-project.org&c=true

*Important - "Word-of-Mouth Connections" are only for the purpose of identifying the connection subject.  What you see is what you get, in terms of search results.  WordofMouthConnection.com is an online community that helps connect people so that they can talk at greater length and in greater detail. None of the information that is exchanged resides within the website itself.

If you have any questions or comments please email us at:

http://womc.net/pass.php?a=contact

Sincerely,
WordofMouthConnection.com



From MSchwartz at medanalytics.com  Mon Sep  8 05:37:50 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Sun, 07 Sep 2003 22:37:50 -0500
Subject: [R] X11 not available
In-Reply-To: <opru5pxlrvx8hwns@localhost>
References: <opru3ohvdlx8hwns@localhost>
	<1062899064.22138.637.camel@localhost>  <opru5pxlrvx8hwns@localhost>
Message-ID: <1062992270.22138.1106.camel@localhost>

On Sun, 2003-09-07 at 20:18, Jose Quesada wrote:

SNIP

> Thanks Marc,
> 
> That worked fine. A bunch of dependencies were detected when trying to 
> install XFree86-devel-4.3.0-2. I tried to solve them, and installed some 
> newer versions exisiting libraries, concretely:
> XFree86-devel-4.3.0-25.i386.rpm
> XFree86-libs-4.3-5mdk.i586.rpm
> XFree86-libs-4.3.0-2.i386.rpm
> XFree86-libs-4.3.0-25.i386.rpm
> XFree86-libs-data-4.3.0
> fontconfig-2.2.1-6mdk.i586.rpm
> fontconfig-devel-2.2.1-4.i386.rpm
> freetype-2.1.4-4.1.i386.rpm
> freetype-devel-2.1.4-4.1.i386.rpm
> 
> Some dependencies were recursive (A needed B installed, B needed A to be 
> installed), so I had to run rpm --nodeps (which is not a good practice). 
> After an uninstall and reinstall fest, I have R working with Xwindows... 
> but no other program can find X anymore :|. I still prefer that to having 
> R with no X11, but if you have any advice to reinstall the newer XFree 
> + devel libraries in a clean way, without breaking dependencies, please 
> let me know!
> 
> Thanks a lot again,
> -Jose


Jose,

The RPMs that have 'mdk' in them are for the Mandrake distribution and
not for Red Hat. I presume that you may have downloaded those from
RPMFind or RPMSeek? You now likely have a mix of conflicting RPMs on
your system, which is problematic as you are finding.

You will need to uninstall those RPMs and perhaps the others that you
installed (using rpm -e RPMName) and install the Red Hat versions. These
should be on your Red Hat install CD's.  If you get dependency issues
during the removal, use rpm -e RPMName1 RPMName2 ..., where you list
multiple RPMs as part of the same command. That will enable the RPM
manager to handle the dependencies during removal.

If X is still intact and running after the uninstall process, an easy
way of doing the install step for the devel packages is to go to the
Main Red Hat menu, then to System Settings, then to Add/Remove
Applications.  This will then prompt you for the root password.

Once this is up, it will bring you to the Package Management menu. In
that menu will be a category of Development. Select Development Tools,
Kernel Development, X Software Development and Gnome Software
Development (also KDE if you use that). Once you have selected these,
then click on update. This will install the requested RPMs while taking
care of the various dependencies. You will need to have your Red Hat
installation CD's for this process.

If this proceeds successfully, you will have the development packages
installed for the key system components, which will enable you to
compile applications from source or source RPMs.

The particular X related RPMS that you should have, out of the list
above are:

XFree86-4.3.0-2
XFree86-libs-4.3.0-2
XFree86-libs-data-4.3.0-2
XFree86-devel-4.3.0-2
fontconfig-devel-2.1-9
fontconfig-2.1-9
freetype-2.1.3-6
freetype-devel-2.1.3-6

These are the most recent Red Hat released versions of these RPMs.

As you noted, it is bad to use --nodeps, as this can result in a variety
of problems and compromise the integrity of the RPM database, which can
lead to future problems with updates and related operations. Typically
if there are multiple RPMs that are co-dependent, you can put them into
a common directory and use 'rpm -Uvh *rpm' without the quotes. Then the
RPM manager will handle the various dependencies during the install.

Depending upon the state of your system after uninstalling the
conflicting RPMS, you may or may not be able to run X. If not, you may
have to resort to restarting your system in console mode and
re-installing the RPMs. If things get really bad, you may need to
re-boot to a rescue disk (should have been created during the initial
install) or to the original boot CD to be able to get to a console so
that you can login as root to reinstall the compromised RPMs.

Until you get there, it may be difficult to know what steps you might
have to take to get back to a stable system.

Drop a line back with any updates.

HTH,

Marc



From search-awareness at word-of-mouth-connection.com  Mon Sep  8 08:21:19 2003
From: search-awareness at word-of-mouth-connection.com (search-awareness@word-of-mouth-connection.com)
Date: Mon, 08 Sep 2003 02:21:19 -0400
Subject: [R] Someone just searched for word-of-mouth information about:
	r-help@lists.r-project.org
Message-ID: <E19wFOp-0004EF-AA@peter.word-of-mouth-connection.com>


WordofMouthConnection.com Search Awareness System

This email is a website-generated message, but it is not spam.

An acquaintance of yours recently conducted a search on your email address in our online community, WordofMouthConnection.com. It could be a friend, a family member, co-worker, business associate, or someone else who's interested in learning more about you.

Why are we sending you this email?

When people find out others are talking about them -- whether it is good or bad -- they want to know. At WordofMouthConnection.com, we feel responsible to alert people so they have an opportunity to find out what is being said. 

Click here to view all "Word-of-Mouth Connections" in our system regarding this email address:

https://womc.net/pass.php?a=search&b=5&c=r-help at lists.r-project.org

How did we find you?

When your acquaintance searched for connections at our website he/she provided us with your email address.

What can you do?

First, we'd like to invite you to visit our website at www.WordofMouthConnection.com and learn about our service.  Registration is free. Not only can you find out if any WordofMouthConnection.com Connections have been submitted about you, but you can connect to others as well to research word-of-mouth information about your friends, co-workers, family, etc.

We are solely interested in fostering a community of willing people to promote information exchange. If you decide you're not interested, you can choose to block future emails from us. 

To add your email address to our Do Not Email List use the following link:

http://womc.net/pass.php?a=donotemail&b=&c=true

*Important - "Word-of-Mouth Connections" are only for the purpose of identifying the connection subject.  What you see is what you get, in terms of search results.  WordofMouthConnection.com is an online community that helps connect people so that they can talk at greater length and in greater detail. None of the information that is exchanged resides within the website itself.

If you have any questions or comments please email us at:

http://womc.net/pass.php?a=contact

Sincerely,
WordofMouthConnection.com



From hwood at iprimus.com.au  Mon Sep  8 08:21:23 2003
From: hwood at iprimus.com.au (hwood@iprimus.com.au)
Date: Mon, 8 Sep 2003 16:21:23 +1000
Subject: [R] cannot allocate vector of size...
Message-ID: <3F5379FD0000302F@cpms02.int.iprimus.net.au>

Hi,

I know that this question has been asked several times before but I haven't
been able to find an answer.

I'm running R on a P3 933 with 384 MB of RAM. The system is running Windows
XP Home. 

I'm trying to read a 1054 row by 30303 column matrix from a tab delimited
text file ("file.txt") into R using the following command:
   m <- matrix(scan(file ="file.txt"), nrow = 1054, ncol = 30303, byrow =
TRUE)
When I use this command I get the following output:
   Read 31939362 items
   Error: cannot allocate vector of size 249526Kb

I have recently increased the amount of RAM in my system. Prior to this
I got only the 'Error...' message and not the 'Read ... items' message.

I have increased the space available to R at startup to 1G by modifying the
startup properties.

I would love any assistance/ideas anyone can give me with this problem.

Thanks!

Hannah



From JonesW at kssg.com  Mon Sep  8 09:58:50 2003
From: JonesW at kssg.com (Wayne Jones)
Date: Mon, 8 Sep 2003 08:58:50 +0100 
Subject: [R]: RODBC column length>255
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB021F0E45@gimli.middleearth.kssg.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030908/d52ce384/attachment.pl

From anne.piotet at urbanet.ch  Mon Sep  8 10:57:02 2003
From: anne.piotet at urbanet.ch (anne)
Date: Mon, 08 Sep 2003 10:57:02 +0200
Subject: [R] Error message in non linear regression model
Message-ID: <3F5C445E.4020104@urbanet.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030908/6fde3120/attachment.pl

From martinol at ensam.inra.fr  Mon Sep  8 12:56:50 2003
From: martinol at ensam.inra.fr (Martin Olivier)
Date: Mon, 08 Sep 2003 10:56:50 +0000
Subject: [R] graphic of hierachical clustering
Message-ID: <3F5C6072.7020802@ensam.inra.fr>

Hi all,

I would like to save the dendrogram of a hierarchical clustering.
Let reshc the result of the fucntion hclust(). To save the dendrogram,
I can use the function postscript:

postscript(file="hc605.ps")
plot(as.dendrogram(reshc),horiz=T,ylab="",main=" ")
dev.off()

Using the functions plot and as.dendrogram, it is possible to obtain an 
horizontal tree with option horiz=T.
The problem is there is a box around the tree...this box looks like the 
result of the function box() and it is possible
 to delete it with box(col="white"). But when I convert the postscript 
file in gif or tiff file, this box  is not deleted.

Could you explain me why this box appear after the conversion of my 
postscript file and a solution
to delete this box in a gif or tiff format? (I know I can use 
plot(reshc) but the tree is vertical   in this case)

Regards,
Olivier.

-- 

-------------------------------------------------------------
Martin Olivier
INRA - Unit? prot?omique           LIRMM - IFA/MAB
2, Place Viala                     161, rue Ada
F-34060 Montpellier C?dex 1        34392 Montpellier C?dex 5	

Tel : 04 99 61 26 02               Tel : O4 67 41 86 71
martinol at ensam.inra.fr



From hb at maths.lth.se  Mon Sep  8 11:20:39 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Mon, 8 Sep 2003 11:20:39 +0200
Subject: [R] cannot allocate vector of size...
In-Reply-To: <3F5379FD0000302F@cpms02.int.iprimus.net.au>
Message-ID: <000101c375ea$7af01fa0$e502eb82@maths.lth.se>

Hi, it seems that you can do

 s <- scan(file ="file.txt")

but that you do not have memory left to do

  m <- matrix(s, nrow = 1054, ncol = 30303, byrow = TRUE)

which requires twice the amount of memory. Could this be the case? 

First, try to read your matrix using read.matrix() that you'll find in
library(tseries). Second, what data type does you file contain? Is it
real numbers or integers? If you have integers I believe you could save
some memory. Try for instance,

i <- 1:10
d <- as.double(i)
object.size(i) # gives 68 bytes
object.size(d) # gives 108 bytes

You can help scan() by specifying what data type you are using. See
argument 'what' in ?scan. Of course, if you have mixed column types and
30303 columns this might need some work.

Henrik Bengtsson
Lund University

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> hwood at iprimus.com.au
> Sent: den 8 september 2003 08:21
> To: r-help at stat.math.ethz.ch
> Subject: [R] cannot allocate vector of size...
> 
> 
> Hi,
> 
> I know that this question has been asked several times before 
> but I haven't been able to find an answer.
> 
> I'm running R on a P3 933 with 384 MB of RAM. The system is 
> running Windows XP Home. 
> 
> I'm trying to read a 1054 row by 30303 column matrix from a 
> tab delimited text file ("file.txt") into R using the 
> following command:
>    m <- matrix(scan(file ="file.txt"), nrow = 1054, ncol = 
> 30303, byrow =
> TRUE)
> When I use this command I get the following output:
>    Read 31939362 items
>    Error: cannot allocate vector of size 249526Kb
> 
> I have recently increased the amount of RAM in my system. 
> Prior to this I got only the 'Error...' message and not the 
> 'Read ... items' message.
> 
> I have increased the space available to R at startup to 1G by 
> modifying the startup properties.
> 
> I would love any assistance/ideas anyone can give me with 
> this problem.
> 
> Thanks!
> 
> Hannah
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> 
>



From dave at evocapital.com  Mon Sep  8 11:30:47 2003
From: dave at evocapital.com (David Khabie-Zeitoune)
Date: Mon, 8 Sep 2003 10:30:47 +0100
Subject: [R] R video
Message-ID: <8D0F30FE2EB3314182D4A33F738BB19D064009@sqlsrvr.evocapital.com>

Hi

Does anybody know of any R packages under Windows to produce video files
from a sequence of R graphs -- e.g. in .wmv or avi format?

Thanks

David



From gavin.simpson at ucl.ac.uk  Mon Sep  8 11:33:29 2003
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Mon, 08 Sep 2003 10:33:29 +0100
Subject: [R] graphic of hierachical clustering
In-Reply-To: <3F5C6072.7020802@ensam.inra.fr>
References: <3F5C6072.7020802@ensam.inra.fr>
Message-ID: <3F5C4CE9.8000700@ucl.ac.uk>

Hi Martin,

try ?plot.default

which states:

frame.plot: a logical indicating whether a box should be drawn around
           the plot.

So the following:

postscript(file = "hc605.ps")
plot(as.dendrogram(reshc), horiz = TRUE, ylab = "", main = " ",
	frame.plot = FALSE)
dev.off()

should get you what you want.

plot.dendrogram doesn't explicitly mention frame.plot, but the ... 
allows you to pass plotting parameters to other methods:

..., xlab, ylab: graphical parameters, or arguments for other methods.

As for the postscript -> gif - I'm not qualified to explain this, except 
that it must have something to do with the fact that by doing 
box(col="white") you aren't actually *deleting* the box, you are just 
overplotting on it.

HTH

Gav

Martin Olivier wrote:

> Hi all,
> 
> I would like to save the dendrogram of a hierarchical clustering.
> Let reshc the result of the fucntion hclust(). To save the dendrogram,
> I can use the function postscript:
> 
> postscript(file="hc605.ps")
> plot(as.dendrogram(reshc),horiz=T,ylab="",main=" ")
> dev.off()
> 
> Using the functions plot and as.dendrogram, it is possible to obtain an 
> horizontal tree with option horiz=T.
> The problem is there is a box around the tree...this box looks like the 
> result of the function box() and it is possible
> to delete it with box(col="white"). But when I convert the postscript 
> file in gif or tiff file, this box  is not deleted.
> 
> Could you explain me why this box appear after the conversion of my 
> postscript file and a solution
> to delete this box in a gif or tiff format? (I know I can use 
> plot(reshc) but the tree is vertical   in this case)
> 
> Regards,
> Olivier.
> 

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpson at ucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From s195404 at student.uq.edu.au  Mon Sep  8 12:15:25 2003
From: s195404 at student.uq.edu.au (Andrew C. Ward)
Date: Mon,  8 Sep 2003 10:15:25 +0000
Subject: [R] cannot allocate vector of size...
In-Reply-To: <3F5379FD0000302F@cpms02.int.iprimus.net.au>
References: <3F5379FD0000302F@cpms02.int.iprimus.net.au>
Message-ID: <1063016125.3f5c56bd8e4c1@my.uq.edu.au>

Dear Hannah,

My usual replies to this question are:
  1. Read in just a subset (or a few random subsets) of
     your data and do some analysis on each of these
  2. Write some C code (either standalone or as something)
     that can be called from R
  3. Get even more RAM


Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au


Quoting hwood at iprimus.com.au:

> Hi,
> 
> I know that this question has been asked several times
> before but I haven't
> been able to find an answer.
> 
> I'm running R on a P3 933 with 384 MB of RAM. The system
> is running Windows
> XP Home. 
> 
> I'm trying to read a 1054 row by 30303 column matrix from
> a tab delimited
> text file ("file.txt") into R using the following
> command:
>    m <- matrix(scan(file ="file.txt"), nrow = 1054, ncol
> = 30303, byrow =
> TRUE)
> When I use this command I get the following output:
>    Read 31939362 items
>    Error: cannot allocate vector of size 249526Kb
> 
> I have recently increased the amount of RAM in my system.
> Prior to this
> I got only the 'Error...' message and not the 'Read ...
> items' message.
> 
> I have increased the space available to R at startup to
> 1G by modifying the
> startup properties.
> 
> I would love any assistance/ideas anyone can give me with
> this problem.
> 
> Thanks!
> 
> Hannah
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From turner at uvs.is  Mon Sep  8 12:24:59 2003
From: turner at uvs.is (turner@uvs.is)
Date: Mon, 8 Sep 2003 10:24:59 +0000
Subject: [R] No joy installing R with shared libs.
Message-ID: <OF10787443.B6514339-ON00256D9B.00384778@uvs.is>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030908/323403ca/attachment.pl

From s195404 at student.uq.edu.au  Mon Sep  8 12:22:22 2003
From: s195404 at student.uq.edu.au (Andrew C. Ward)
Date: Mon,  8 Sep 2003 10:22:22 +0000
Subject: [R]: RODBC column length>255
In-Reply-To: <6B5A9304046AD411BD0200508BDFB6CB021F0E45@gimli.middleearth.kssg.com>
References: <6B5A9304046AD411BD0200508BDFB6CB021F0E45@gimli.middleearth.kssg.com>
Message-ID: <1063016542.3f5c585ec73b0@my.uq.edu.au>

Dear Wayne,

This could be related to the ODBC specification, and so you
won't be able to change it. If it's hard-coded into RODBC, 
you will be able to modify the code and recompile the 
package yourself.

Alternatively, there may be another package that reads your
data without going through ODBC. I believe there are some
for Oracle, MySQL and others.


Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au


Quoting Wayne Jones <JonesW at kssg.com>:

> Hello there fellow R-users, 
> 
> I am using the RODBC functionality to query a database. I
> am trying to read
> in a columns of strings which have a character field
> lengths greater than
> 255. 
> The data.frame that I recieve back from the RODBC query
> only contains the
> first 255 characters (the rest having been truncated). 
> 
> Any help on how to solve this problem would be greatly
> appreciated.
> 
> Reagrds
> Wayne
> 
> 
> Dr Wayne R. Jones
> Statistician / Research Analyst
> KSS Group plc
> St James's Buildings
> 79 Oxford Street
> Manchester M1 6SS
> Tel: +44(0)161 609 4084
> Mob: +44(0)7810 523 713
> 
> 
> 
> 
> KSS Ltd
> Seventh Floor  St James's Buildings  79 Oxford Street 
> Manchester  M1 6SS  England
> Company Registration Number 2800886
> Tel: +44 (0) 161 228 0040	Fax: +44 (0) 161 236 6305
> mailto:kssg at kssg.com		http://www.kssg.com
> 
> 
> The information in this Internet email is confidential
> and m...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From jccorrea at unalmed.edu.co  Mon Sep  8 13:03:44 2003
From: jccorrea at unalmed.edu.co (Juan Carlos Correa Morales)
Date: Mon, 08 Sep 2003 06:03:44 -0500 (GMT)
Subject: [R] fit data with skew t distribution
In-Reply-To: <3F7BAD6F@webmail.uiuc.edu>
Message-ID: <Pine.GSO.4.44.0309080601061.7135-100000@eris.unalmed.edu.co>

Hi:
Prpfessor Azalini?s library 'sn' contains the function to fit the skew
normal and the skew t distributions.

Juan

On Fri, 5 Sep 2003, tzhou1 wrote:

> Hi,
>
> Is there a function in R that I can use to fit the data with skew t
> distribution? Speaking in detail, I first used the kernel density estimation
> to fit my data, then I drew the skew t using my specified location, scale,
> shape, and df to make it close to the kernel density. Now I want to get the
> parameter estimations of the skew t which give me the closet density to the
> kernel density. Which functions in R can do this? Any suggestions are
> welcome!!
>
> Thanks!
>
> Tianyue
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From ucgamdo at ucl.ac.uk  Mon Sep  8 14:13:09 2003
From: ucgamdo at ucl.ac.uk (ucgamdo@ucl.ac.uk)
Date: Mon, 08 Sep 2003 13:13:09 +0100
Subject: [R] Re: clustering polypeptide sequences
Message-ID: <3.0.5.32.20030908131309.007d7790@pop-server.ucl.ac.uk>


Hi Peter,

   You didn't give a very specific example, but it seems to me that what
you wish to do is not really complicated. I suppose you have created a
table of sequences vs. say hyprophobicity, charge, etc..., something like...

seq	hydroph	arom
b0001 	0.104762 	0.000000
b0002 	0.035122 	0.065854
b0003 	0.024193 	0.070968
b0004 	-0.096729 	0.084112
b0005 	-0.973469 	0.091837
b0006 	-0.402713 	0.108527
b0007 	0.680672 	0.123950
b0008 	-0.209779 	0.072555
b0009 	-0.013334 	0.046154
b0010 	0.952128 	0.143617

suppose you have these data into a data frame called myseqs [see the R
documentation in how to upload these data, you can try       > myseqs <-
edit(read.table()) ]

# you need to load the necessary libraries

library(mva)      # basic clustering
library(cluster)  # more clustering algorithms

# then you need to calculate the 'distances' between sequences

myseqs.d <- dist(myseqs)  # this creates the euclidean distance matrix, try
help(dist) for more info

# then we perform a hierarchical cluster

myseqs.clus <- hclust(myseqs.d)

# now checkout your results

plot(myseqs.clus) # hey! you see how easy it is?

# the documentation for hlcust contains much more info
# other fancy clustering algorithms

myseqs.pam <- pam(myseqs, k = 2)
plot(myseqs.pam)

I hope this is of any help.



From arinbasu at softhome.net  Mon Sep  8 14:36:40 2003
From: arinbasu at softhome.net (arinbasu@softhome.net)
Date: Mon, 08 Sep 2003 06:36:40 -0600
Subject: [R] problems with categorical variables
In-Reply-To: <200309081005.h88A2A0t011817@stat.math.ethz.ch> 
References: <200309081005.h88A2A0t011817@stat.math.ethz.ch>
Message-ID: <courier.3F5C77D8.00006E6D@softhome.net>

Hi All: 

I am working on a dataset of a study on healthcare workers. One of the 
variables I am studying is a categorical variable (variable name:EDUC, 
indicates educational achievement, with 6 levels: "illiterate", "primary", 
"junior high school", "high school completed", "undergraduate", and 
"postgraduate"). 

I want to collapse the 6 levels to a 4-level categorical variable (let's 
call it "educrec", with the following levels: "postgraduate", 
"undergraduate", "some schooling" and "illiterate"). 

I initially tried the following code: 

x <- table(EDUC)
educrec <- c(x[1], x[2], (x[3]+x[4]+x[5]), x[6])) 

table(educrec) gives me the tally count just fine, but I cannot use educrec 
in any cross tabulation. 

Would greatly appreciate if you can advise on the correct way to recode 
categorical variables to categorical variables in R.
I use Windows XP (Home), R-version 1.7.1
I looked for solutions in the "introduction to R" and the archives, but 
wasn't successful. 

 -Arin Basu



From solares at unsl.edu.ar  Mon Sep  8 14:38:59 2003
From: solares at unsl.edu.ar (solares@unsl.edu.ar)
Date: Mon, 8 Sep 2003 09:38:59 -0300 (ART)
Subject: [R] add checkbutton and the variable(wrong length of vector "b")
Message-ID: <57013.170.210.173.216.1063024739.squirrel@inter14.unsl.edu.ar>

Hello it wanted to add a boton of checkup in a menu, ?How I do to create so 
many variables as  checkbutton?  I try with the code that continues, use a 
vector that is charged dynamicamente while I open files but the component 
of vector "b" is associates with a Tcl variable  and load 3 components 
(environment, value and pointer) I wanted alone to charge the value (0 done 
not select and 1 selected), and the length its wrong.  Good, here are the 
script so that they see it.  Thanks Ruben

library(tcltk)
vectPath<-c()
b<-c()
archivos<-function(){
          f<-tkcmd("tk_getOpenFile")
          temparch<-tclvalue(f)
          assign("vectPath",c(vectPath,temparch),.GlobalEnv)
          temp<-0
          assign("b",c(b,temp),.GlobalEnv) #charge the variable for the 
checkbutton
          cant<-length(vectPath)
          j<-vectPath[cant]                  
          tkadd(m, "check", label=j, variable=b[cant]) #add the variable
}

ver<-function(){
     i<-1 
     while (i<=length(b)) { #the length of b is wrong!!
     print(tclvalue(b[i]))
     i<-i+1
     }
}

borra<-function(){
	 assign("vectPath",c(),.GlobalEnv)
	 assign("b",c(),.GlobalEnv)	 
     tkdelete(m,"0","end")
}
tt <- tktoplevel()
tkpack(mb <- tkmenubutton(tt, text="Datos"))
m <- tkmenu(mb,tearoff=FALSE) 
tkconfigure(mb,menu=m)
b<-tkbutton(tt,text="abrir",command=function()archivos())
tkpack(b)
b3<-tkbutton(tt,text="ver",command=function()ver())
tkpack(b3)
b4<-tkbutton(tt,text="Borrar",command=function()borra())
tkpack(b4)



From solares at unsl.edu.ar  Mon Sep  8 14:39:42 2003
From: solares at unsl.edu.ar (solares@unsl.edu.ar)
Date: Mon, 8 Sep 2003 09:39:42 -0300 (ART)
Subject: [R] add checkbutton and the variable(wrong length of vector "b")
Message-ID: <57170.170.210.173.216.1063024782.squirrel@inter14.unsl.edu.ar>

Hello it wanted to add a boton of checkup in a menu, ?How I do to create so 
many variables as  checkbutton?  I try with the code that continues, use a 
vector that is charged dynamicamente while I open files but the component 
of vector "b" is associates with a Tcl variable  and load 3 components 
(environment, value and pointer) I wanted alone to charge the value (0 done 
not select and 1 selected), and the length its wrong.  Good, here are the 
script so that they see it.  Thanks Ruben

library(tcltk)
vectPath<-c()
b<-c()
archivos<-function(){
          f<-tkcmd("tk_getOpenFile")
          temparch<-tclvalue(f)
          assign("vectPath",c(vectPath,temparch),.GlobalEnv)
          temp<-0
          assign("b",c(b,temp),.GlobalEnv) #charge the variable for the 
checkbutton
          cant<-length(vectPath)
          j<-vectPath[cant]                  
          tkadd(m, "check", label=j, variable=b[cant]) #add the variable
}

ver<-function(){
     i<-1 
     while (i<=length(b)) { #the length of b is wrong!!
     print(tclvalue(b[i]))
     i<-i+1
     }
}

borra<-function(){
	 assign("vectPath",c(),.GlobalEnv)
	 assign("b",c(),.GlobalEnv)	 
     tkdelete(m,"0","end")
}
tt <- tktoplevel()
tkpack(mb <- tkmenubutton(tt, text="Datos"))
m <- tkmenu(mb,tearoff=FALSE) 
tkconfigure(mb,menu=m)
b<-tkbutton(tt,text="abrir",command=function()archivos())
tkpack(b)
b3<-tkbutton(tt,text="ver",command=function()ver())
tkpack(b3)
b4<-tkbutton(tt,text="Borrar",command=function()borra())
tkpack(b4)



From solares at unsl.edu.ar  Mon Sep  8 14:56:59 2003
From: solares at unsl.edu.ar (solares@unsl.edu.ar)
Date: Mon, 8 Sep 2003 09:56:59 -0300 (ART)
Subject: [R] limits of read.table
Message-ID: <59837.170.210.173.216.1063025819.squirrel@inter14.unsl.edu.ar>

Hi, ?How many lines support read.table, i have a file .txt of 20000 lines 
and 12 columns, ?Which are the limits?Ruben



From p.dalgaard at biostat.ku.dk  Mon Sep  8 14:58:06 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon, 08 Sep 2003 12:58:06 -0000
Subject: [R] problems with categorical variables
In-Reply-To: <courier.3F5C77D8.00006E6D@softhome.net>
References: <200309081005.h88A2A0t011817@stat.math.ethz.ch>
	<courier.3F5C77D8.00006E6D@softhome.net>
Message-ID: <x23cf7a111.fsf@biostat.ku.dk>

arinbasu at softhome.net writes:

> Hi All: I am working on a dataset of a study on healthcare workers.
> One of the variables I am studying is a categorical variable (variable
> name:EDUC, indicates educational achievement, with 6 levels:
> "illiterate", "primary", "junior high school", "high school
> completed", "undergraduate", and "postgraduate"). I want to collapse
> the 6 levels to a 4-level categorical variable (let's call it
> "educrec", with the following levels: "postgraduate", "undergraduate",
> "some schooling" and "illiterate"). I initially tried the following
> code: x <- table(EDUC)
> educrec <- c(x[1], x[2], (x[3]+x[4]+x[5]), x[6])) table(educrec) gives
> me the tally count just fine, but I cannot use educrec in any cross
> tabulation. Would greatly appreciate if you can advise on the correct
> way to recode categorical variables to categorical variables in R.
> I use Windows XP (Home), R-version 1.7.1
> I looked for solutions in the "introduction to R" and the archives,
> but wasn't successful. -Arin Basu

EDUC2 <- EDUC
levels(EDUC2) <- c("postgraduate", 
                   "undergraduate",
                   "some schooling", 
                   "some schooling", 
                   "some schooling", 
                   "illiterate")

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From vincent.stoliaroff at sgcib.com  Mon Sep  8 15:00:30 2003
From: vincent.stoliaroff at sgcib.com (vincent.stoliaroff@sgcib.com)
Date: Mon, 8 Sep 2003 15:00:30 +0200
Subject: [R] Hierarchical clustering : analysis of the cluster
Message-ID: <OFCF447EBF.0F1F1765-ONC1256D9B.004674FB@ges.marc.societe-generale.fr>

Hi R lovers!

I am using the agnes function of the package cluster to compute a
hierarchical clustering.
I'd like to know if somebody has ever developped a function which could
give the names/label of the individuals merged together with respect to the
number of cluster the user eventually wants to keep.
Namely, If I have the dendogram and I choose to cut it to get , say 5
cluster, how can I get the names of the individuals in each of the 5
clusters?

I am looking for an algorithm that could do that.
I have tried to find one using the $merge component of the agnes.object or
the $order.lab component but with no result.

If by chance it exists already...
Thank you very much.





******************************************************************
The sender's email address has changed to 
firstname.lastname@ sgcib.com. You may want to update your 
personal address book. Please see http://www.sgcib.com for more 
information.
                               **
This message and any attachments (the "message") are confide...{{dropped}}



From solares at unsl.edu.ar  Mon Sep  8 15:03:19 2003
From: solares at unsl.edu.ar (solares@unsl.edu.ar)
Date: Mon, 8 Sep 2003 10:03:19 -0300 (ART)
Subject: [R] two tables with read.table?
Message-ID: <32862.170.210.173.216.1063026199.squirrel@inter14.unsl.edu.ar>

Hi, How i cant split with the function read.table a file with many tables 
in your inner, for example

file probe.txt
---------------
text1
text2
 colA colB
1 5   6
2 7   8
text3
text4
 colC colD
1 9   10
2 11  12
----------------
i like two tables:

table1<--colA and Col B 
and
table2<--colC and Col D

Have use a Regular Expression? Thanks



From solares at unsl.edu.ar  Mon Sep  8 15:05:11 2003
From: solares at unsl.edu.ar (solares@unsl.edu.ar)
Date: Mon, 8 Sep 2003 10:05:11 -0300 (ART)
Subject: [R] exist "as.time"
Message-ID: <33231.170.210.173.216.1063026311.squirrel@inter14.unsl.edu.ar>

Hi, ?Exist somewhere as.Time in R, how i cant convert hours in number
for example:
v<-08:00:01
x<-as.Time(v) and x is a integer.Thanks



From christoph.lehmann at gmx.ch  Mon Sep  8 14:42:38 2003
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Mon, 08 Sep 2003 14:42:38 +0200
Subject: [R] Rgobi installation failed, thanks for help
Message-ID: <1063024957.7712.46.camel@christophl>

I coudn't install Rgobi: Details:
my system: Redhat 9.0

platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    1
minor    7.0
year     2003
month    04
day      16
language R

--what I did:

downloaded ggobi /ggobi_0.99-10.tar.gz
./configure
make

to run: /usr/local/src/ggobi/bin/ggobi
runs fine

installed Rggobi (as recommended at
http://www.ggobi.org/INSTALL.html
):
as non-root:
bash-2.05b$ R_HOME=/usr/lib/R
bash-2.05b$ export R_HOME
bash-2.05b$ GGOBI_ROOT=/usr/local/src/ggobi
bash-2.05b$ export GGOBI_ROOT
bash-2.05b$ R_LIBS=/usr/lib/R/library
bash-2.05b$ export R_LIBS

as su:
ln -s $GGOBI_ROOT/lib/libggobi.so /usr/lib/
ln -s $GGOBI_ROOT/lib/libgtkext.so /usr/lib/
R CMD INSTALL Rggobi_0.53-0.tar.gz
Error in "class<-"(*tmp*, value = Class) :
        couldn't find function "objWithClass"
Warning message:
package methods in options("defaultPackages") was not found
Error in "class<-"(*tmp*, value = Class) :
        couldn't find function "objWithClass"
Error in library("methods") : .First.lib failed
Execution halted
/usr/local/lib/R/bin/INSTALL: line 1: 11697 Broken pipe             cat
"${R_PACKAGE_DIR}/R/${pkg}"
ERROR: execution of package source for 'Rggobi' failed

--
many thanks for your help

Christoph
-- 
Christoph Lehmann <christoph.lehmann at gmx.ch>



From bates at stat.wisc.edu  Mon Sep  8 15:33:13 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 08 Sep 2003 13:33:13 -0000
Subject: [R] Error message in non linear regression model
In-Reply-To: <3F5C445E.4020104@urbanet.ch>
References: <3F5C445E.4020104@urbanet.ch>
Message-ID: <6r8yozv1z1.fsf@bates4.stat.wisc.edu>

anne <anne.piotet at urbanet.ch> writes:

> Hello!
> 
> Trying to fit a non linear regression model
> 
>  modF<-nlsModel(kf~3*alpha*epsilon^P, dat, list(alpha=ALPHA))

You should use nls, not nlsModel.

Also, if P is fixed then this is a linear regression model.  Why use
nonlinear regression.



From petr.pikal at precheza.cz  Mon Sep  8 16:15:51 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Mon, 08 Sep 2003 16:15:51 +0200
Subject: [R] exist "as.time"
In-Reply-To: <33231.170.210.173.216.1063026311.squirrel@inter14.unsl.edu.ar>
Message-ID: <3F5CAB37.23580.152C5D4@localhost>

Hallo

On 8 Sep 2003 at 10:05, solares at unsl.edu.ar wrote:

> Hi, ?Exist somewhere as.Time in R, how i cant convert hours in number
> for example: v<-08:00:01 x<-as.Time(v) and x is a integer.Thanks

If you use POSIX format for date and time

v$hour 

will give you hour

If v is a character vector some subsetting function
?substr

can be probably used.


> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

Cheers
Petr Pikal
petr.pikal at precheza.cz



From thpe at hhbio.wasser.tu-dresden.de  Mon Sep  8 16:34:38 2003
From: thpe at hhbio.wasser.tu-dresden.de (Thomas Petzoldt)
Date: Mon, 08 Sep 2003 16:34:38 +0200
Subject: [R] [Off] Ecological Modelling's Book Suggestion.
In-Reply-To: <200309051035.31005.chrysopa@insecta.ufv.br>
References: <200309051035.31005.chrysopa@insecta.ufv.br>
Message-ID: <3F5C937E.9040400@hhbio.wasser.tu-dresden.de>

Ronaldo Reis Jr. Wrote:

> Hi,
> 
> Anybody can suggest a good Ecological Modelling's Book.

Hello,

there is an increasing number of interesting books published recently 
and it is a matter of taste, which to read first. For a comprehensive 
understanding you probably should read more than one book. Below you 
find three exciting volumes of very different style.

To return to R-Help: I think it would be a nice idea to port some of the 
examples of Roughgarden's book to R.


Thomas P.


@BOOK{Hastings1996,
   author = {Hastings, Alan},
   year = 1996,
   title = {Population Biology. Concepts and Models},
   pages = {1--220},
   publisher = {Springer},
   address = {New York},
   language = {english}
}

@BOOK{Gurney1998,
   author = {Gurney, W. S. C. and Nisbet, R. M.},
   year = 1998,
   title = {Ecological Dynamics},
   pages = {1--335},
   publisher = {Oxford University Press},
   address = {New York, Oxford},
   language = {english}
}

@BOOK{Roughgarden1998,
   author = {Roughgarden, Joan},
   year = 1998,
   title = {Primer of Ecological Theory},
   pages = {1--456},
   publisher = {Prentice Hall},
   language = {english}
}



From berthold.kramm at epost.de  Mon Sep  8 17:39:06 2003
From: berthold.kramm at epost.de (Berthold Kramm)
Date: Mon, 08 Sep 2003 17:39:06 +0200
Subject: [R] Problem with contour plot
Message-ID: <3F5CA29A.3060000@epost.de>

Using the code below (based on 'Modern Applied Statistics with S (4th 
Edition)from Venables,Ripley) for a 2*2 contour (plus color) plot, the 
top left contour plot is distorted in the sense that the contour plot is 
compressed in x-direction, while the axis and the contour plot in 
y-direction display correctly.
Any idea how to fix this anomaly ?

Best wishes,
Berthold

...
par(mfrow = c(2,2), pty ="s")

topo.ls <- surf.ls(3,RALV,RARV,PP)
trsurf <- trmat(topo.ls,80,160,80,160,100)
eqscplot(trsurf,xlab="RALV",ylab="RARV",type="n")
image(trsurf,col=terrain.colors(100),add=T)
contour(trsurf, lty="solid", add=TRUE)
points(RALV,RARV)
title("PP")

topo.ls <- (replication of the same block as above 3 times with 
different variables) ...



From Mark.Lamias at grizzard.com  Mon Sep  8 17:48:01 2003
From: Mark.Lamias at grizzard.com (Mark Lamias)
Date: Mon, 8 Sep 2003 11:48:01 -0400 
Subject: [R] Persp Plot
Message-ID: <BF3C804D59EE4C40BF5376A0FABA4AA62F650F@atl_mail.griz-main.com>

I am trying to graph two planes on the same graph using persp().  I can only
get one plane to plot at a time.  Can someone explain how I can graph two
planes on the same graph using persp?  I've looked throught the
documentation, but cannot find any references to appending a persp plot.

Thanks.

Sincerely yours,

Mark J. Lamias
Statistical Consultant



From ernesto at ipimar.pt  Mon Sep  8 17:53:20 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Mon, 08 Sep 2003 16:53:20 +0100
Subject: [R] New highlighting for NEdit 5.3
Message-ID: <1063036400.12470.40.camel@gandalf.local>

Hi,

I've just put together a new R syntax highlighting file for Nedit 5.3.

I've borrow the "base" functions of Jedit (thanks to Tobias Elze and Zed
A. Shaw) so now NEdit highlights a little more than before :)

You can download the file here: 

http://ernesto.freezope.org/cmf/starthere/r/R-5.3.pats

Just import it into NEdit with 

> nedit -import R-5.3.pats

and save your preferences when leaving the editor.

If you want to use NEdit as your default editor inside R do

> options(editor="nedit -lm R")

I usually change NEdit fonts to lucida-mono 12 so if you use other fonts
it may look uglier (or pretier) ...

Hope you enjoy it and, as usual, all comments are welcome.

Best regards

EJ

ps: please can somenone change the file in R-GUI page ?
-- 
Ernesto Jardim <ernesto at ipimar.pt>
Bi?logo Marinho/Marine Biologist
IPIMAR - Instituto Nacional de Investiga??o Agr?ria e das Pescas
IPIMAR - National Research Institute for Agriculture and Fisheries
Av. Brasilia, 1400-006
Lisboa, Portugal
Tel: +351 213 027 000
Fax: +351 213 015 948
http://ernesto.freezope.org



From jgentry at jimmy.harvard.edu  Mon Sep  8 18:51:21 2003
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Mon, 8 Sep 2003 12:51:21 -0400 (EDT)
Subject: [R] Stifling REprintf() output
Message-ID: <Pine.SOL.4.20.0309081246400.6125-100000@santiam.dfci.harvard.edu>


In some code that I have written, use of url() is generating the output
line:
"cannot open: HTTP status was `404 Not Found`"

The problem is that I do not want R to be outputting any error messages -
I have 'internet.info' set to 3, show.error.messages set to FALSE and the
url() wrapped in a try().  When the URL is not found I am already handling
it in a manner consistent with the rest of the package and the 'cannot
open' line is confusing some users.

The problem is that I can not figure out how to turn it off, the comment
in printutils says that REprintf writes to stderr and is not redirected by
sink().  The call in question appears to be coming from in_R_HTTPOpen, in
that if the HTTP return code is != 200 the REprintf is called.

Is there any way within R to keep this output from appearing?

Thanks
-J



From ggrothendieck at volcanomail.com  Mon Sep  8 18:52:57 2003
From: ggrothendieck at volcanomail.com (Gabor Grothendieck)
Date: Mon, 8 Sep 2003 09:52:57 -0700 (PDT)
Subject: [R] data manipulation
Message-ID: <20030908165259.369A57269@sitemail.everyone.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030908/3023bce2/attachment.pl

From sfalcon at fhcrc.org  Mon Sep  8 18:54:36 2003
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Mon, 8 Sep 2003 09:54:36 -0700
Subject: [R] No joy installing R with shared libs.
In-Reply-To: <OF10787443.B6514339-ON00256D9B.00384778@uvs.is>
References: <OF10787443.B6514339-ON00256D9B.00384778@uvs.is>
Message-ID: <20030908165434.GC27613@queenbee.fhcrc.org>

On Mon, Sep 08, 2003 at 10:24:59AM +0000, turner at uvs.is wrote:
> Can some kind soul please give me a fool proof recipe for building R and 
> RSPython so that it actually works?

I don't have a recipe, but one thought to help debug the process:  Try
installing RPy [1].  RPy also provides access to R via Python and uses
the libR.so library.  If you can install and "import rpy" without
problem then it must be an issue with RSPython.  


[1] http://rpy.sourceforge.net/


+ seth



From deepayan at stat.wisc.edu  Mon Sep  8 18:57:41 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Mon, 8 Sep 2003 11:57:41 -0500
Subject: [R] Persp Plot
In-Reply-To: <BF3C804D59EE4C40BF5376A0FABA4AA62F650F@atl_mail.griz-main.com>
References: <BF3C804D59EE4C40BF5376A0FABA4AA62F650F@atl_mail.griz-main.com>
Message-ID: <200309081157.41279.deepayan@stat.wisc.edu>


If they are non-intersecting planes, wireframe() from the lattice package 
_may_ help you. See example(wireframe). [Warning: the algorithm is quite 
crude (and slow) and doesn't always work.]

On Monday 08 September 2003 10:48, Mark Lamias wrote:
> I am trying to graph two planes on the same graph using persp().  I can
> only get one plane to plot at a time.  Can someone explain how I can graph
> two planes on the same graph using persp?  I've looked throught the
> documentation, but cannot find any references to appending a persp plot.
>
> Thanks.
>
> Sincerely yours,
>
> Mark J. Lamias
> Statistical Consultant
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ggrothendieck at volcanomail.com  Mon Sep  8 19:08:37 2003
From: ggrothendieck at volcanomail.com (Gabor Grothendieck)
Date: Mon, 8 Sep 2003 10:08:37 -0700 (PDT)
Subject: [R] data manipulation
Message-ID: <20030908170838.38CFD4967@sitemail.everyone.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030908/c24aef3e/attachment.pl

From Mark.Lamias at grizzard.com  Mon Sep  8 19:12:26 2003
From: Mark.Lamias at grizzard.com (Mark Lamias)
Date: Mon, 8 Sep 2003 13:12:26 -0400 
Subject: [R] Persp Plot
Message-ID: <BF3C804D59EE4C40BF5376A0FABA4AA62F6512@atl_mail.griz-main.com>

Any suggestions if they are intersecting?  

Thanks.

Sincerely yours,

Mark J. Lamias

-----Original Message-----
From: Deepayan Sarkar [mailto:deepayan at stat.wisc.edu]
Sent: Monday, September 08, 2003 12:58 PM
To: Mark Lamias; 'r-help at lists.r-project.org'
Subject: Re: [R] Persp Plot



If they are non-intersecting planes, wireframe() from the lattice package 
_may_ help you. See example(wireframe). [Warning: the algorithm is quite 
crude (and slow) and doesn't always work.]

On Monday 08 September 2003 10:48, Mark Lamias wrote:
> I am trying to graph two planes on the same graph using persp().  I can
> only get one plane to plot at a time.  Can someone explain how I can graph
> two planes on the same graph using persp?  I've looked throught the
> documentation, but cannot find any references to appending a persp plot.
>
> Thanks.
>
> Sincerely yours,
>
> Mark J. Lamias
> Statistical Consultant
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jc at or.psychology.dal.ca  Mon Sep  8 19:22:19 2003
From: jc at or.psychology.dal.ca (John Christie)
Date: Mon, 8 Sep 2003 14:22:19 -0300
Subject: [R] P-P probability plots?
Message-ID: <002C6F31-E221-11D7-81B8-000A9566473A@or.psychology.dal.ca>

Hi,
	I see that there is a standard function for Q-Q normal plots in R but 
couldn't find anything for normal probability plots.  To my eyeballs 
the latter are easier to interpret.  Is there a function in some 
library or is there a standard way to use qqnorm to get them?



From anne.piotet at urbanet.ch  Mon Sep  8 17:57:32 2003
From: anne.piotet at urbanet.ch (anne)
Date: Mon, 08 Sep 2003 17:57:32 +0200
Subject: [R] multiple selection syntax
Message-ID: <3F5CA6EB.6050208@urbanet.ch>

Hello

This is a very newbie question on R syntax, but I do not find the answer....

I want to make a selection on an interval say choose Xint in the 
interval of temperatures 390-399

I tried this syntax
Xint<- X[t>=390 && t< 400] 
typing >XintI get the answer numeric(0)

it did not select any object! 'though I verified that there indeed are 
occrencies of X in this interval


Any idea?

thanks

Anne



From ligges at statistik.uni-dortmund.de  Mon Sep  8 19:43:34 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 08 Sep 2003 19:43:34 +0200
Subject: [R] multiple selection syntax
In-Reply-To: <3F5CA6EB.6050208@urbanet.ch>
References: <3F5CA6EB.6050208@urbanet.ch>
Message-ID: <3F5CBFC6.10208@statistik.uni-dortmund.de>

anne wrote:

> Hello
> 
> This is a very newbie question on R syntax, but I do not find the 
> answer....
> 
> I want to make a selection on an interval say choose Xint in the 
> interval of temperatures 390-399
> 
> I tried this syntax
> Xint<- X[t>=390 && t< 400] typing >XintI get the answer numeric(0)
> 
> it did not select any object! 'though I verified that there indeed are 
> occrencies of X in this interval
> 
> 
> Any idea?
> 
> thanks
> 
> Anne

The idea is to read help("&&"). It tells you:

"& and && indicate logical AND and | and || indicate logical OR. The 
shorter form performs elementwise comparisons in much the same way as 
arithmetic operators. The longer form evaluates left to right examining 
only the first element of each vector. Evaluation proceeds only until 
the result is determined. The longer form is appropriate for programming 
control-flow and typically preferred in if clauses."

So I guess you want
  Xint <- X[(t >= 390) & (t < 400)]

Uwe Ligges



From bates at stat.wisc.edu  Mon Sep  8 19:49:21 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 08 Sep 2003 17:49:21 -0000
Subject: [R] multiple selection syntax
In-Reply-To: <3F5CA6EB.6050208@urbanet.ch>
References: <3F5CA6EB.6050208@urbanet.ch>
Message-ID: <6rn0dff9vr.fsf@bates4.stat.wisc.edu>

anne <anne.piotet at urbanet.ch> writes:

> Hello
> 
> This is a very newbie question on R syntax, but I do not find the answer....
> 
> I want to make a selection on an interval say choose Xint in the
> interval of temperatures 390-399
> 
> 
> I tried this syntax
> Xint<- X[t>=390 && t< 400] typing >XintI get the answer numeric(0)

Use &, not &&



From cmoffet at nwrc.ars.usda.gov  Mon Sep  8 19:55:32 2003
From: cmoffet at nwrc.ars.usda.gov (Corey Moffet)
Date: Mon, 08 Sep 2003 11:55:32 -0600
Subject: [R] multiple selection syntax
In-Reply-To: <3F5CA6EB.6050208@urbanet.ch>
Message-ID: <3.0.6.32.20030908115532.00f66ca8@nwrc.ars.usda.gov>

I think you just want &, not &&.

  
try:
 x <- 1:10
 xint <- x[x>=4 & x < 7]
 xint


At 05:57 PM 9/8/2003 +0200, anne wrote:
>Hello
>
>This is a very newbie question on R syntax, but I do not find the answer....
>
>I want to make a selection on an interval say choose Xint in the 
>interval of temperatures 390-399
>
>I tried this syntax
>Xint<- X[t>=390 && t< 400] 
>typing >XintI get the answer numeric(0)
>
>it did not select any object! 'though I verified that there indeed are 
>occrencies of X in this interval
>
>
>Any idea?
>
>thanks
>
>Anne
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
With best wishes and kind regards I am

Sincerely,

Corey A. Moffet, Ph.D.
Support Scientist

University of Idaho
Northwest Watershed Research Center
800 Park Blvd, Plaza IV, Suite 105
Boise, ID 83712-7716

Voice: (208) 422-0718
FAX:   (208) 334-1502



From arrayprofile at yahoo.com  Mon Sep  8 20:07:10 2003
From: arrayprofile at yahoo.com (array chip)
Date: Mon, 8 Sep 2003 11:07:10 -0700 (PDT)
Subject: [R] memory problem in exporting data frame
Message-ID: <20030908180710.11362.qmail@web41210.mail.yahoo.com>

Hi,

I am having trouble of exporting a large data frame
out of R to be used in other purpose. The data frame
is numeric with size 17000x400. It takes a quite some
time to start R as well. my computer has 1GB RAM. I
used the following command to write the data frame to
a text file and got the error message below:

> write.table(xxx, "C:\\xxx", sep="\t",
row.names=FALSE,col.names=FALSE,quote=FALSE)

Error: cannot allocate vector of size 55750 Kb
In addition: Warning message: 
Reached total allocation of 1023Mb: see
help(memory.size) 

I tried to increase the memory size by
memory.size(size=), but it seems running the above
command takes forever.

what can I do with this error message to get the data
out? 

Thanks



From pburns at pburns.seanet.com  Mon Sep  8 20:30:33 2003
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Mon, 08 Sep 2003 19:30:33 +0100
Subject: [R] memory problem in exporting data frame
References: <20030908180710.11362.qmail@web41210.mail.yahoo.com>
Message-ID: <3F5CCAC9.2050703@pburns.seanet.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030908/9cbb57ed/attachment.pl

From d.scofield at umiami.edu  Mon Sep  8 20:55:09 2003
From: d.scofield at umiami.edu (Douglas G. Scofield)
Date: Mon, 8 Sep 2003 14:55:09 -0400
Subject: [R] 1.7.1 console unresponsive following "paste into"
Message-ID: <003901c3763a$bd2d9e10$aacdab81@genetics5>

Dear R Help,

I've just installed 1.7.1 and have found that the console now exhibits
odd behavior when I paste commands into it.  I'm on a PC running Windows
XP Professional.

I use Word as my script editor, and then paste commands into the R
console using the standard Windows "copy" within Word then "paste"
within Rgui.  This worked without a hitch in 1.7.0, but now in 1.7.1 the
Rgui is unresponsive to keyboard input following the paste.  I can paste
again and the R Console responds to the newly pasted commands, but still
not to the keyboard.  Try it with the following commands:

   t <- 22/7
   t * t

The odd thing is, if I iconify R Console within RGui, then restore it, I
can then use the keyboard.  If I maximize R Console, then restore it, it
works *sometimes*.  And this is not particular to Word, as I just pasted
the above lines from this Outlook window and the same problem occurred.

Sincerely,

Douglas Scofield                 Department of Biology 
d.scofield at umiami.edu            University of Miami
off: (305) 284-3778              P.O. Box 249118
fax: (305) 284-3039              Coral Gables, FL  33124-0421



From THoffman at nasdc.org  Mon Sep  8 22:33:30 2003
From: THoffman at nasdc.org (Tamara Hoffman)
Date: Mon, 8 Sep 2003 16:33:30 -0400
Subject: [R] lmList with NAs
Message-ID: <66578BFC0BA55348B5907A0F798EE93014BCDD@ernesto.NASDC.ORG>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030908/42515f9e/attachment.pl

From keele at email.unc.edu  Mon Sep  8 22:35:20 2003
From: keele at email.unc.edu (Luke Keele)
Date: Mon, 8 Sep 2003 16:35:20 -0400 (Eastern Daylight Time)
Subject: [R] Probit and optim in R
Message-ID: <200309082035.h88KZKhn018672@smtp.unc.edu>


I have had some weird results using the optim() function.  I wrote a
probit likelihood and wanted to run it with optim() with simulated
data.  I did not include a gradient at first and found that optim()
would not even iterate using BFGS and would only occasionally work
using SANN.  I programmed in the gradient and it iterates fine but the
estimates it returns are wrong.  The simulated data work fine when I
use them in the glm function in R.  And even stranger the function
seems to work fine with real data.  There must be some programming
quirk that I have overlooked.  My code is attached if anyone wants to
take a look.  I'd like to be able to make it work without the gradient
if possible.  Any help would be greatly appreciated as I am completely
stumped at this point.

Luke Keele
Dept of Political Science
UNC-Chapel Hill
-------------- next part --------------
## Probit Code For Simulation

#Define empty matrix 

na <- matrix(NA,10,3)

#Set counter and start loop

j <- 1

while (j < 11){

#Simulate Data

x1 <- rnorm(1000) 
x2 <- rnorm(1000)
latentz <- 1.0 + 2.0 * x1 - 3.0 * x2 + rnorm(1000)
y <- latentz
y[latentz < 1] <- 0
y[latentz >=1] <- 1

#Option export of data to check estimates in STATA
#SimProbit <- data.frame(y, x1, x2)
#write.table(SimProbit, 'a:/SimProbit')

x <- cbind(1, x1 ,x2)

#Define Likelihood
llik.probit<-function(par, X, Y){

Y <- as.matrix(y)
X <- as.matrix(x)
K <- ncol(X)
b <-as.matrix(par[1:K])

 
  phi<-pnorm(X%*%b, mean=0, sd=1, lower.tail = TRUE, log.p = FALSE)
  sum(Y*log(phi)+(1-Y)*log(1-phi))
}

grad <-function(par,X,Y){

Y <- as.matrix(y)
X <- as.matrix(x)
K <- ncol(X)
b <-as.matrix(par[1:K])
phi <- as.vector(pnorm(X%*%b))
     apply((phi*x), 2, sum)
}

#Fit Model
values.start <- lm(y ~ x1 + x2)$coef
result<-optim(values.start, llik.probit, gr=grad, Y=Y, X=X, method="BFGS",
                       control=list(maxit=2000, fnscale=-1, trace), hessian=T)

na[j,] <-result$par

j <- j+1
}


## Probit with Real Data

#Define Data

data<-read.table("c:/mydocu~1/harvar~1/snct.dat", header=T)
y <- data$MIL
x <- cbind(rep(1, length(y)), data$COOP, data$TARGET, data$COST, data$RELAT)

#Form Likelihood
llik.probit<-function(par, X, Y){

Y <- as.matrix(y)
X <- as.matrix(x)
K <- ncol(X)
b <- as.matrix(par[1:K])

  phi<-pnorm(X%*%b)
  sum(Y*log(phi)+(1-Y)*log(1-phi))
}

#Fit Model

values.start <- lm(MIL ~ COOP + TARGET + COST + RELAT, data=data)$coef
result<-optim(values.start, llik.probit, Y=y, X=x, method="BFGS",
                       control=list(fnscale=-1), hessian=T)

result$par

#This works too

data <- data.frame(y, x1, x2)
Y <-data$y
X <- cbind(rep(1,length(y)), data$x1, data$x2)

test <- glm(y ~ x1 + x2, family=binomial(probit), data=data)

From flom at ndri.org  Mon Sep  8 23:07:49 2003
From: flom at ndri.org (Peter Flom)
Date: Mon, 08 Sep 2003 17:07:49 -0400
Subject: [R] Yet another beginner question
Message-ID: <sf5cb784.033@MAIL.NDRI.ORG>

Thanks for all the help on my earlier questions.....


How do you plot a simple time series with unequal intervals?  I have
the following

dateofpoll <- as.ts(c("6/1/02", "7/1/02", "10/1/02", "1/4/03",
"1/25/03",
"6/7/03", "7/16/03", "8/17/03", "9/4/03"))
reelect <- c(51, 47, 49, 51, 49, 49, 46, 45, 40)
new <-     c(28, 32, 35, 36, 41, 38, 47, 48, 52)

what I'd like is to plot reelect and new  (maybe with smoothing) on a
time scale, with the x axis labeled for date.....

But I can't figure out how, despite looking at ?ts and various things
there


Thanks in advance





Peter L. Flom, PhD
Assistant Director, Statistics and Data Analysis Core
Center for Drug Use and HIV Research
National Development and Research Institutes
71 W. 23rd St
www.peterflom.com
New York, NY 10010
(212) 845-4485 (voice)
(917) 438-0894 (fax)



From sundar.dorai-raj at pdf.com  Mon Sep  8 23:10:01 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Mon, 08 Sep 2003 16:10:01 -0500
Subject: [R] Probit and optim in R
In-Reply-To: <200309082035.h88KZKhn018672@smtp.unc.edu>
References: <200309082035.h88KZKhn018672@smtp.unc.edu>
Message-ID: <3F5CF029.40102@pdf.com>



Luke Keele wrote:
> I have had some weird results using the optim() function.  I wrote a
> probit likelihood and wanted to run it with optim() with simulated
> data.  I did not include a gradient at first and found that optim()
> would not even iterate using BFGS and would only occasionally work
> using SANN.  I programmed in the gradient and it iterates fine but the
> estimates it returns are wrong.  The simulated data work fine when I
> use them in the glm function in R.  And even stranger the function
> seems to work fine with real data.  There must be some programming
> quirk that I have overlooked.  My code is attached if anyone wants to
> take a look.  I'd like to be able to make it work without the gradient
> if possible.  Any help would be greatly appreciated as I am completely
> stumped at this point.
> 
> Luke Keele
> Dept of Political Science
> UNC-Chapel Hill
> 

When I tried this, I was getting NaN for the likelihood because phi came 
out to be 1 or 0 probability in some cases. Thus log(phi) or log(1-phi) 
returns a value optim doesn't like. To avoid this problem, use 
pnorm(..., log.p = TRUE) to get the log of the probability (which is 
what you need anyway) in your likelihood function:


   #Define Likelihood
   llik.probit <- function(par, X, Y){
     Y <- as.matrix(y)
     X <- as.matrix(x)
     phi <- pnorm(ifelse(Y == 0, -1, 1) * X%*%par, log.p = TRUE)
     -sum(phi)
   }

-sd



From spencer.graves at pdf.com  Mon Sep  8 23:36:11 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 08 Sep 2003 14:36:11 -0700
Subject: [R] P-P probability plots?
References: <002C6F31-E221-11D7-81B8-000A9566473A@or.psychology.dal.ca>
Message-ID: <3F5CF64B.8090507@pdf.com>

What is it about qqnorm that does not meed your needs?  Have you 
considered the option "datax=TRUE"?  You can store the results of qqnorm 
using "plot.it=FALSE" and then plot using "plot( ..., axes=FALSE)". 
Then add "axis" manually to label points with probability rather than or 
in addition to standard deviations.

hope this helps.  spencer graves

John Christie wrote:
> Hi,
>     I see that there is a standard function for Q-Q normal plots in R 
> but couldn't find anything for normal probability plots.  To my eyeballs 
> the latter are easier to interpret.  Is there a function in some library 
> or is there a standard way to use qqnorm to get them?
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From arrayprofile at yahoo.com  Mon Sep  8 23:57:50 2003
From: arrayprofile at yahoo.com (array chip)
Date: Mon, 8 Sep 2003 14:57:50 -0700 (PDT)
Subject: [R] memory problem in exporting data frame
In-Reply-To: <3F5CCAC9.2050703@pburns.seanet.com>
Message-ID: <20030908215750.76039.qmail@web41202.mail.yahoo.com>

Patrick,

Thanks for the suggestion. do you mean you need to
change each row of the data frame into a text string
using something like "paste(data[1,],collapse='\t')"
and then output the resulting character vector into a
file using writeLines?

It seems not working with my data mainly because my
data is in a data frame, not in a matrix. even a
single operation like "data[1,]" takes tremendous time
to complete (I think it will be much easier and faster
if my data is in a matrix).

If anyone has suggestions, I would appreciate letting
me know.

Thanks anyway.


--- Patrick Burns <pburns at pburns.seanet.com> wrote:
> I had a similar problem not long ago.  My solution
> was to
> look at the definition of "write.table" and
> essentially do it
> by hand.  The key steps are to create a matrix of
> characters
> that includes the dimnames (if desired), and then
> use
> "writeLines" to put that into a file.
> 
> My machine has 1G as well and my problem was a
> numeric
> matrix that was 5000 square.  So you should have no
> problem.
> 
> Patrick Burns
> 
> Burns Statistics
> patrick at burns-stat.com
> +44 (0)20 8525 0696
> http://www.burns-stat.com
> (home of S Poetry and "A Guide for the Unwilling S
> User")
> 
> array chip wrote:
> 
> >Hi,
> >
> >I am having trouble of exporting a large data frame
> >out of R to be used in other purpose. The data
> frame
> >is numeric with size 17000x400. It takes a quite
> some
> >time to start R as well. my computer has 1GB RAM. I
> >used the following command to write the data frame
> to
> >a text file and got the error message below:
> >
> >  
> >
> >>write.table(xxx, "C:\\xxx", sep="\t",
> >>    
> >>
> >row.names=FALSE,col.names=FALSE,quote=FALSE)
> >
> >Error: cannot allocate vector of size 55750 Kb
> >In addition: Warning message: 
> >Reached total allocation of 1023Mb: see
> >help(memory.size) 
> >
> >I tried to increase the memory size by
> >memory.size(size=), but it seems running the above
> >command takes forever.
> >
> >what can I do with this error message to get the
> data
> >out? 
> >
> >Thanks
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
>
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> >
> >  
> >
> 
>



From maj at stats.waikato.ac.nz  Tue Sep  9 00:15:55 2003
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Tue, 09 Sep 2003 10:15:55 +1200
Subject: [R] How do I coerce numeric factor columns of data frame to vector?
Message-ID: <3F5CFF9B.2070401@stats.waikato.ac.nz>

I have just noticed that quite a few columns of a data frame that I am 
working on are numeric factors. For summary() purposes I want them to be 
vectors. I tried, for example

 > indx <- c(1:18,21:37,40,41)
 > i <- 0
 > i <- i+1
 > summary(as.vector(sflows1[indx[i]]))
            Length Class  Mode
min.pkt.sz 3000   factor numeric

but this does not give the five-number summary that I want. I know that 
I can go back and modify read.table() to change the class of the 
columns, but I want to change the frame without re-reading it.

Murray

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From pburns at pburns.seanet.com  Tue Sep  9 00:32:50 2003
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Mon, 08 Sep 2003 23:32:50 +0100
Subject: [R] memory problem in exporting data frame
References: <20030908215750.76039.qmail@web41202.mail.yahoo.com>
Message-ID: <3F5D0392.1060300@pburns.seanet.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030908/0fe62f60/attachment.pl

From mmiller3 at iupui.edu  Tue Sep  9 01:06:56 2003
From: mmiller3 at iupui.edu (Michael A. Miller)
Date: Mon, 08 Sep 2003 18:06:56 -0500
Subject: [R] How do I coerce numeric factor columns of data frame to
	vector?
In-Reply-To: <3F5CFF9B.2070401@stats.waikato.ac.nz> (Murray Jorgensen's
	message of "Tue, 09 Sep 2003 10:15:55 +1200")
References: <3F5CFF9B.2070401@stats.waikato.ac.nz>
Message-ID: <873cf6x4kv.fsf@lumen.indyrad.iupui.edu>

>>>>> "Murray" == Murray Jorgensen <maj at stats.waikato.ac.nz> writes:

    > I have just noticed that quite a few columns of a data
    > frame that I am working on are numeric factors. For
    > summary() purposes I want them to be vectors.

Do you want them to be vectors or do you want numeric values?  If
the later, try as.numeric instead of as.vector:

> as.vector(factor(rep(seq(4),3)))
 [1] "1" "2" "3" "4" "1" "2" "3" "4" "1" "2" "3" "4"
> as.numeric(factor(rep(seq(4),3)))
 [1] 1 2 3 4 1 2 3 4 1 2 3 4
> summary(as.vector(factor(rep(seq(4),3))))
   Length     Class      Mode 
       12 character character 
> summary(as.numeric(factor(rep(seq(4),3))))
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   1.00    1.75    2.50    2.50    3.25    4.00 


Mike



From tblackw at umich.edu  Tue Sep  9 01:13:00 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Mon, 8 Sep 2003 19:13:00 -0400 (EDT)
Subject: [R] How do I coerce numeric factor columns of data frame to
	vector?
In-Reply-To: <3F5CFF9B.2070401@stats.waikato.ac.nz>
Message-ID: <Pine.SOL.4.44.0309081901170.19004-100000@tetris.gpcc.itd.umich.edu>

Murray  -

Suppose your data frame is called  mydata.  If ALL of the columns were
factors with numeric levels, you could do:

newdata <- as.data.frame(lapply(mydata, function(x) as.numeric(as.character(x))))

(Sorry about the nested functions.  I didn't invent these complications.)
When only the columns listed in  indx  need to be converted, make a
complementary vector  indy <- c(19,20,38,39,42:60)  (say), then do

newdata <- as.data.frame(lapply(mydata[indx],
                     function(x) as.numeric(as.character(x))))
alldata <- c(mydata[indy], newdata)[ sort.list(c(indy, indx)) ]

Again, it's just a trick to get the columns back in the original order,
but I think my code above will do it.  Best luck.  Others will probably
have more elegant solutions.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Tue, 9 Sep 2003, Murray Jorgensen wrote:

> I have just noticed that quite a few columns of a data frame that I am
> working on are numeric factors. For summary() purposes I want them to be
> vectors. I tried, for example
>
>  > indx <- c(1:18,21:37,40,41)
>  > i <- 0
>  > i <- i+1
>  > summary(as.vector(sflows1[indx[i]]))
>             Length Class  Mode
> min.pkt.sz 3000   factor numeric
>
> but this does not give the five-number summary that I want. I know that
> I can go back and modify read.table() to change the class of the
> columns, but I want to change the frame without re-reading it.
>
> Murray
>
> --
> Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
> Department of Statistics, University of Waikato, Hamilton, New Zealand
> Email: maj at waikato.ac.nz                                Fax 7 838 4155
> Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From tblackw at umich.edu  Tue Sep  9 01:22:04 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Mon, 8 Sep 2003 19:22:04 -0400 (EDT)
Subject: [R] How do I coerce numeric factor columns of data frame to
	vector?
In-Reply-To: <873cf6x4kv.fsf@lumen.indyrad.iupui.edu>
Message-ID: <Pine.SOL.4.44.0309081913500.19004-100000@tetris.gpcc.itd.umich.edu>

Michael  -

Because these columns are factors to begin with, using  as.numeric()
alone will have unexpected results.  See the section "Warning:" in
help("factor").

However, it is worth Murray asking himself WHY these columns are
factors to start with, rather than the expected numeric values.
One frequent source of this is using  read.table()  on a file
which contains column headers without setting  header=T.  Then,
the character string in the first row of each column prevents
numeric conversion of all of the other rows.  Another possible
difficulty is an unusual missing value code, or commas in place
of decimal points, or anything else, somewhere in the file that
does not convert automatically to numeric.  Maybe it's worth
editing the original data file before Murray reads it in.

Hmmm.  I think I ought to have offered these many cents worth
with my earlier reply.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Mon, 8 Sep 2003, Michael A. Miller wrote:

> >>>>> "Murray" == Murray Jorgensen <maj at stats.waikato.ac.nz> writes:
>
>     > I have just noticed that quite a few columns of a data
>     > frame that I am working on are numeric factors. For
>     > summary() purposes I want them to be vectors.
>
> Do you want them to be vectors or do you want numeric values?  If
> the later, try as.numeric instead of as.vector:
>
> > as.vector(factor(rep(seq(4),3)))
>  [1] "1" "2" "3" "4" "1" "2" "3" "4" "1" "2" "3" "4"
> > as.numeric(factor(rep(seq(4),3)))
>  [1] 1 2 3 4 1 2 3 4 1 2 3 4
> > summary(as.vector(factor(rep(seq(4),3))))
>    Length     Class      Mode
>        12 character character
> > summary(as.numeric(factor(rep(seq(4),3))))
>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>    1.00    1.75    2.50    2.50    3.25    4.00
>
> Mike



From naumov at buffalo.edu  Tue Sep  9 01:24:24 2003
From: naumov at buffalo.edu (Aleksey Naumov)
Date: Mon, 8 Sep 2003 19:24:24 -0400 (EDT)
Subject: [R] No joy installing R with shared libs.
In-Reply-To: <OF10787443.B6514339-ON00256D9B.00384778@uvs.is>
Message-ID: <Pine.GSO.4.05.10309081919190.6686-100000@callisto.acsu.buffalo.edu>

Douglas,

I don't use RSPython, but I had the same problem with RPy: segfault in
python the moment I try to load RPy: 'import rpy'.
The problem happened in R 1.7.0 and was fixed by upgrading to R 1.7.1, I
think it was traced to conflicting regex functions in libc and R (see
http://rpy.sourceforge.net). So I'd try to install R 1.7.1 if you don't
have it...

Best,
Aleksey

On Mon, 8 Sep 2003 turner at uvs.is wrote:

> Hello,
> 
> My platform is SuSE 8.1.  After downloading and unpacking R version 1.7 I 
> tried building with shared libs enabled. (./configure --enabl-R-shlib). My 
> goal is to use RSPython but I am now in my own private segmentation fault 
> hell.
> 
> The R build worked fine: make, make check, make install cool.
> The RSPython build worked fine.
> 
> Thinking I'm good to go, I run python. But when I import RS python rolls 
> over and dies with a segmentation fault. 
> It has been two days of futzing with recompiles, environment variable 
> diddling and whatnot. 
> 
> Can some kind soul please give me a fool proof recipe for building R and 
> RSPython so that it actually works?
> 
> Thanks,
> Douglass Turner
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
>



From tblackw at umich.edu  Tue Sep  9 01:27:31 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Mon, 8 Sep 2003 19:27:31 -0400 (EDT)
Subject: [R] memory problem in exporting data frame
In-Reply-To: <20030908180710.11362.qmail@web41210.mail.yahoo.com>
Message-ID: <Pine.SOL.4.44.0309081922330.19004-100000@tetris.gpcc.itd.umich.edu>


Simplest is to save your workspace using  save.image(),
then delete a bunch of large objects other than the data
frame that you want to export, and run  write.table()
again, now that you've made space for it.  A quick calc
shows  17000 x 400 x 8 = 55 Mb, and that's just the size
of the object that chokes R below.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Mon, 8 Sep 2003, array chip wrote:

> I am having trouble of exporting a large data frame
> out of R to be used in other purpose. The data frame
> is numeric with size 17000x400. It takes a quite some
> time to start R as well. my computer has 1GB RAM. I
> used the following command to write the data frame to
> a text file and got the error message below:
>
> > write.table(xxx, "C:\\xxx", sep="\t",
> row.names=FALSE,col.names=FALSE,quote=FALSE)
>
> Error: cannot allocate vector of size 55750 Kb
> In addition: Warning message:
> Reached total allocation of 1023Mb: see
> help(memory.size)
>
> I tried to increase the memory size by
> memory.size(size=), but it seems running the above
> command takes forever.
>
> what can I do with this error message to get the data
> out?
>
> Thanks



From maj at stats.waikato.ac.nz  Tue Sep  9 03:25:27 2003
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Tue, 09 Sep 2003 13:25:27 +1200
Subject: [R] How do I coerce numeric factor columns of data frame to
	vector?
In-Reply-To: <Pine.SOL.4.44.0309081913500.19004-100000@tetris.gpcc.itd.umich.edu>
References: <Pine.SOL.4.44.0309081913500.19004-100000@tetris.gpcc.itd.umich.edu>
Message-ID: <3F5D2C07.4050502@stats.waikato.ac.nz>

Hi Thomas et al,

checking the code that read the frame, I see that the problem was indeed 
caused by missing value codes at the read.table() stage. However I did 
not want to re-visit the reading stages again with these frames. (To 
show why not I include the code that read them, which you may recognise 
from an earlier thread in which I got some help from Andy Liaw.)

Murray

nam.vec 
<-c(?min.pkt.sz?,?pkt.count?,?bytes?,?duration?,?m1.psz?,?m1.count?,?m2.psz?,?m2.count?,?m3.psz?,?m3.count?,?iat.min?,?iat.max?,?m1.iat?,?m1.iat.count?,?m2.iat?,?m2.iat.count?,?m3.iat?,?m3.iat.count?,?port?,?ip.address?,?min.pkt.sz2?,?pkt.count2?,?bytes2?,
?m1.psz2?,?m1.count2?,?m2.psz2?,?m2.count2?,?m3.psz2?,?m3.count2?,?iat.min2?,?iat.max2?,?m1.iat2?,?m1.iat.count2?,?m2.iat2?,?m2.iat.count2?,?m3.iat2?,?m3.iat.count2?,?port2?,?ip.address2?,?diff.min.psz?,?diff.max.psz?)

flines <- 107165
slines <- 3000
sel6 <- sample(flines,3000*6)
selected1 <- sort(sel6[1:3000])
selected2 <- sort(sel6[3001:6000])
selected3 <- sort(sel6[6001:9000])
selected4 <- sort(sel6[9001:12000])
selected5 <- sort(sel6[12001:15000])
selected6 <- sort(sel6[15001:18000])

select.frame <- function(selected) {
strvec <- rep("",slines)
selected <- sort(sample(flines, slines))
skip <- c(0, diff(selected) - 1)
fcon <- file("c:/data/perry/data.csv", open="r")
for (i in 1:length(skip)) {
     ## skip to the selected line
     readLines(fcon, n=skip[i])
     strvec[i] <- readLines(fcon, n=1)
}
close(fcon)
sel.flows <- read.table(textConnection(strvec), header=FALSE, sep=",")
names(sel.flows) <- nam.vec
sel.flows
}


Thomas W Blackwell wrote:

> Michael  -
> 
> Because these columns are factors to begin with, using  as.numeric()
> alone will have unexpected results.  See the section "Warning:" in
> help("factor").
> 
> However, it is worth Murray asking himself WHY these columns are
> factors to start with, rather than the expected numeric values.
> One frequent source of this is using  read.table()  on a file
> which contains column headers without setting  header=T.  Then,
> the character string in the first row of each column prevents
> numeric conversion of all of the other rows.  Another possible
> difficulty is an unusual missing value code, or commas in place
> of decimal points, or anything else, somewhere in the file that
> does not convert automatically to numeric.  Maybe it's worth
> editing the original data file before Murray reads it in.
> 
> Hmmm.  I think I ought to have offered these many cents worth
> with my earlier reply.
> 
> -  tom blackwell  -  u michigan medical school  -  ann arbor  -
> 
> On Mon, 8 Sep 2003, Michael A. Miller wrote:
> 
> 
>>>>>>>"Murray" == Murray Jorgensen <maj at stats.waikato.ac.nz> writes:
>>
>>    > I have just noticed that quite a few columns of a data
>>    > frame that I am working on are numeric factors. For
>>    > summary() purposes I want them to be vectors.
>>
>>Do you want them to be vectors or do you want numeric values?  If
>>the later, try as.numeric instead of as.vector:
>>
>>
>>>as.vector(factor(rep(seq(4),3)))
>>
>> [1] "1" "2" "3" "4" "1" "2" "3" "4" "1" "2" "3" "4"
>>
>>>as.numeric(factor(rep(seq(4),3)))
>>
>> [1] 1 2 3 4 1 2 3 4 1 2 3 4
>>
>>>summary(as.vector(factor(rep(seq(4),3))))
>>
>>   Length     Class      Mode
>>       12 character character
>>
>>>summary(as.numeric(factor(rep(seq(4),3))))
>>
>>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>>   1.00    1.75    2.50    2.50    3.25    4.00
>>
>>Mike
> 
> 
> 

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From ayalahec at msu.edu  Tue Sep  9 06:11:26 2003
From: ayalahec at msu.edu (Hector L. Ayala-del-Rio)
Date: Tue, 09 Sep 2003 00:11:26 -0400
Subject: [R] Matrix resampling (bootstraps)
Message-ID: <5.2.1.1.0.20030908235330.02282ff0@mail.msu.edu>

Dear all,
    I am trying to generate bootstrap replicate matrixes (rows=samples, 
column=species, sampling with replacement) from a matrix dataset, but I do 
not know how to do it in R.  I have tried boot() and bootstrap(), but they 
require an statistic, which in my case is cluster analysis (generating 
bootstrap values for a cluster analysis is a topic that has been mentioned 
previously in this list).  I have been trying to use sample() and matrix() 
to generate the replicate matrix but they seem to generate a single vector 
rather than the entire matrix.  What I want is to resample the entire 
matrix, but by resampling different columns (species).  In that way, the 
bootstrap values will give me an idea of how similar the samples are.  Any 
ideas will be very very helpful.  An example of that data matrix is below.

Thanks

Hector

   X36C X40C X58C X60C X62C X66C X77C X92C X95C X96C X107C X109C X116C
26Y        0    0    0   59  919  351  128    0  104  214     0     0     0
C-0        0    0    0  368 1343 1826  211    0  253  352     0     0     0
C-50       0    0    0  211 1032 1701   50    0   54   56     0     0     0
C-90      64    0   65  260  769  876    0    0   87    0     0    91    96
C-127-1    0    0  127  149  364 3990    0    0    0    0     0     0     0
C-164      0    0    0   68  179 2373    0    0  105    0     0     0     0
C-198      0    0    0   89  327 1458  314    0  209  298     0     0     0
C-226      0    0    0    0  206  858    0    0  363  304     0     0     0
C-268      0    0    0   75  270  629    0    0  107    0     0     0     0
C-294-C   54    0    0  112  379  753    0  220  823  325     0     0     0
C-310      0    0    0    0  116  305    0  396 1049  355     0     0     0
C-357-2   96    0    0  445  201  405    0  114 2265    0   178    99   125
C-375     90    0   56  231  385  817    0  211 2776    0    57    79   106
C-399    110    0   50  563 1060 1244    0  414 2933    0    54   107   123
C-414     64    0    0  197  408  825    0  111 1875    0     0    82   104
C-428     63    0    0   80  100  695    0  162 2374    0   481   132   369
C-434      0    0    0  269  261 1689    0 2923 3496    0     0     0     0
C-454     77    0    0  257  170  963    0  377 3984    0     0    90    96
C-465      0    0    0  234  406  860    0  428 1601    0     0     0     0
C-479    111    0    0  349  297 1538   51  494 3753    0    75   102    95



From p.connolly at hortresearch.co.nz  Tue Sep  9 06:36:20 2003
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Tue, 9 Sep 2003 16:36:20 +1200
Subject: [R] How limits are set in a scales list
Message-ID: <20030909043620.GS25050@hortresearch.co.nz>

I have a lattice plot that has 4 pages with 4 columns and 8 rows per
page.  I wish to have the rows use a separate x-axis since their
ranges are quite different, but I wish to have those same limits used
on each page.

By setting an element of the scales list to something like x = list(limits = 
                       lim.list$CFU, lim.list$CFU, lim.list$CFU, lim.list$CFU,
                       lim.list$TU, lim.list$TU, lim.list$TU, lim.list$TU, 
                       etc, etc) ,
                       relation = "sliced")

where lim.list is a list of the limits I wish to use, Only the first
four panels (but on each page) are drawn using the limits I wish to
use.  Thereafter, they're all the same, but not in accordance with any
other values in lim.list.

The help page does not make it clear to me just how I should be
specifying the list.  There was recently something like this but I
didn't manage to find it in the archives to check if it covered what I
require.

Ideas welcome.

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From ggrothendieck at volcanomail.com  Tue Sep  9 07:41:39 2003
From: ggrothendieck at volcanomail.com (Gabor Grothendieck)
Date: Mon, 8 Sep 2003 22:41:39 -0700 (PDT)
Subject: [R] data manipulation
Message-ID: <20030909054139.78E9B499C@sitemail.everyone.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030908/b3e82238/attachment.pl

From deepayan at stat.wisc.edu  Tue Sep  9 08:40:02 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 9 Sep 2003 01:40:02 -0500
Subject: [R] How limits are set in a scales list
In-Reply-To: <20030909043620.GS25050@hortresearch.co.nz>
References: <20030909043620.GS25050@hortresearch.co.nz>
Message-ID: <200309090140.02262.deepayan@stat.wisc.edu>

On Monday 08 September 2003 23:36, Patrick Connolly wrote:
> I have a lattice plot that has 4 pages with 4 columns and 8 rows per
> page.  I wish to have the rows use a separate x-axis since their
> ranges are quite different, but I wish to have those same limits used
> on each page.
>
> By setting an element of the scales list to something like x = list(limits
> = lim.list$CFU, lim.list$CFU, lim.list$CFU, lim.list$CFU, lim.list$TU,
> lim.list$TU, lim.list$TU, lim.list$TU, etc, etc) ,
>                        relation = "sliced")
>
> where lim.list is a list of the limits I wish to use, Only the first
> four panels (but on each page) are drawn using the limits I wish to
> use.  Thereafter, they're all the same, but not in accordance with any
> other values in lim.list.

Could you specify your call more precisely ? I'm assuming limits was something 
like 

limits = list(lim.list$CFU, lim.list$CFU, ...
         ^^^^

What were the values of lim.list$CFU and lim.list$TU ? If you are explicitly 
specifying the limits, why do you have relation="sliced" and not 
relation="free" ? If lim.list$CFU and lim.list$TU don't have the same diff(), 
the limits will be modified to honour the relation="sliced" setting. Is that 
what you want ? I would guess from the reported behaviour that 
diff(lim.list$TU) is less than diff(lim.list$CFU).


> The help page does not make it clear to me just how I should be
> specifying the list.  There was recently something like this but I
> didn't manage to find it in the archives to check if it covered what I
> require.

Yes, the help page doesn't seem to mention this at all. I have updated this, 
and the relevant new portions are:

In \item{scales}

    relation : determines limits of the axis. Possible values are "same"
    (default), "free" and "sliced". For relation="same", the same limits
    (determined by \code{xlim, ylim, scales$limits} etc) are used for
    all the panels. For relation="free", limits for each panel is
    determined by the points in that panel (via the \code{prepanel}
    function). Behaviour for relation = "sliced" is similar, except that
    the length (max - min) of the scales are constrained to remain the
    same across panels (limits specified as character vectors, if any,
    are ignored in these computations). If relation is not "same", the
    value of \code{xlim/ ylim/ scales$limits} is normally ignored,
    except when the latter is a list, when it is treated as if its 
    components were the limit values obtained from the prepanel 
    calculations for each panel.

\item{xlim} 

    Normally a numeric vector of length 2 (possibly a
    DateTime object) giving minimum and maximum for the x-axis, or, a
    character vector, expected to denote the levels of \code{x}. The
    latter form is interpreted as a range containing c(1, length(xlim)),
    with the character vector determining labels at tick positions
    \code{1:length(xlim)}

    \code{xlim} could also be a list, with as many components as the
    number of panels (recycled if necessary), with each component as
    described above. This is meaningul only when
    \code{scales$x$relation} is "free" or "sliced", in which case these
    are treated as if they were the corresponding limit components
    returned by prepanel calculations.


Deepayan



From ligges at statistik.uni-dortmund.de  Tue Sep  9 08:41:31 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 09 Sep 2003 08:41:31 +0200
Subject: [R] 1.7.1 console unresponsive following "paste into"
In-Reply-To: <003901c3763a$bd2d9e10$aacdab81@genetics5>
References: <003901c3763a$bd2d9e10$aacdab81@genetics5>
Message-ID: <3F5D761B.4090600@statistik.uni-dortmund.de>

Douglas G. Scofield wrote:

> Dear R Help,
> 
> I've just installed 1.7.1 and have found that the console now exhibits
> odd behavior when I paste commands into it.  I'm on a PC running Windows
> XP Professional.
> 
> I use Word as my script editor, and then paste commands into the R
> console using the standard Windows "copy" within Word then "paste"
> within Rgui.  This worked without a hitch in 1.7.0, but now in 1.7.1 the
> Rgui is unresponsive to keyboard input following the paste.  I can paste
> again and the R Console responds to the newly pasted commands, but still
> not to the keyboard.  Try it with the following commands:
> 
>    t <- 22/7
>    t * t
> 
> The odd thing is, if I iconify R Console within RGui, then restore it, I
> can then use the keyboard.  If I maximize R Console, then restore it, it
> works *sometimes*.  And this is not particular to Word, as I just pasted
> the above lines from this Outlook window and the same problem occurred.
> 
> Sincerely,
> 
> Douglas Scofield                 Department of Biology 
> d.scofield at umiami.edu            University of Miami
> off: (305) 284-3778              P.O. Box 249118
> fax: (305) 284-3039              Coral Gables, FL  33124-0421
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


This is a known bug of the "paste"-button that is only visible in Rgui 
in its mdi-mode and is fixed in the fortcoming R-1.8.0 (in development). 
Instead, you might want to use Ctrl+v or the menu.

Uwe Ligges



From Giles.Heywood at CommerzbankIB.com  Tue Sep  9 08:55:44 2003
From: Giles.Heywood at CommerzbankIB.com (Heywood, Giles)
Date: Tue, 9 Sep 2003 07:55:44 +0100 
Subject: [R] Yet another beginner question
Message-ID: <8CBAA121CEB4D5118CB200508BB2BBEF54049C@xmx8lonib.lonib.commerzbank.com>

The Irregular Time-Series ('its') class could be helpful to you.
The following does the basics of what you have asked.

require(its)
its.format("%m/%d/%y")
myits <-
its(cbind(reelect,new),dates=as.POSIXct(x=strptime(dateofpoll,format=its.for
mat())))
plot(myits,type="b")

You may want to customise the graphical parameters using par(), 
or passing extra parameters to plot() which will pass them through,
to axis.POSIXct, for example to control the number of x-axis ticks, 
which in this example defaults to 1.

On the smoothing issue, I can't really help.

The its package is to be found on CRAN.

Giles
> -----Original Message-----
> From: Peter Flom [mailto:flom at ndri.org]
> Sent: 08 September 2003 22:08
> To: r-help at stat.math.ethz.ch
> Subject: [R] Yet another beginner question
> 
> 
> Thanks for all the help on my earlier questions.....
> 
> 
> How do you plot a simple time series with unequal intervals?  I have
> the following
> 
> dateofpoll <- as.ts(c("6/1/02", "7/1/02", "10/1/02", "1/4/03",
> "1/25/03",
> "6/7/03", "7/16/03", "8/17/03", "9/4/03"))
> reelect <- c(51, 47, 49, 51, 49, 49, 46, 45, 40)
> new <-     c(28, 32, 35, 36, 41, 38, 47, 48, 52)
> 
> what I'd like is to plot reelect and new  (maybe with smoothing) on a
> time scale, with the x axis labeled for date.....
> 
> But I can't figure out how, despite looking at ?ts and various things
> there
> 
> 
> Thanks in advance
> 
> 
> 
> 
> 
> Peter L. Flom, PhD
> Assistant Director, Statistics and Data Analysis Core
> Center for Drug Use and HIV Research
> National Development and Research Institutes
> 71 W. 23rd St
> www.peterflom.com
> New York, NY 10010
> (212) 845-4485 (voice)
> (917) 438-0894 (fax)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


********************************************************************** 
This is a commercial communication from Commerzbank AG.\ \ T...{{dropped}}



From ligges at statistik.uni-dortmund.de  Tue Sep  9 08:57:38 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 09 Sep 2003 08:57:38 +0200
Subject: [R] Yet another beginner question
In-Reply-To: <sf5cb784.033@MAIL.NDRI.ORG>
References: <sf5cb784.033@MAIL.NDRI.ORG>
Message-ID: <3F5D79E2.2040904@statistik.uni-dortmund.de>

Peter Flom wrote:

> Thanks for all the help on my earlier questions.....
> 
> 
> How do you plot a simple time series with unequal intervals?  I have
> the following
> 
> dateofpoll <- as.ts(c("6/1/02", "7/1/02", "10/1/02", "1/4/03",
> "1/25/03",
> "6/7/03", "7/16/03", "8/17/03", "9/4/03"))
> reelect <- c(51, 47, 49, 51, 49, 49, 46, 45, 40)
> new <-     c(28, 32, 35, 36, 41, 38, 47, 48, 52)
> 
> what I'd like is to plot reelect and new  (maybe with smoothing) on a
> time scale, with the x axis labeled for date.....
> 
> But I can't figure out how, despite looking at ?ts and various things
> there
> 
> 
> Thanks in advance

You can do it by converting to POSIX format, but a more convinient way 
is provided by the new contributed package "its" (Irregular Spaced 
Time-Series, on CRAN) by Giles Heywood (I have not tested it, though),
see the announcement: 
https://www.stat.math.ethz.ch/pipermail/r-announce/2003/000768.html

Uwe Ligges



> Peter L. Flom, PhD
> Assistant Director, Statistics and Data Analysis Core
> Center for Drug Use and HIV Research
> National Development and Research Institutes
> 71 W. 23rd St
> www.peterflom.com
> New York, NY 10010
> (212) 845-4485 (voice)
> (917) 438-0894 (fax)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From hb at maths.lth.se  Tue Sep  9 09:45:34 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Tue, 9 Sep 2003 09:45:34 +0200
Subject: [R] memory problem in exporting data frame
In-Reply-To: <Pine.SOL.4.44.0309081922330.19004-100000@tetris.gpcc.itd.umich.edu>
Message-ID: <003501c376a6$5a16d3c0$e502eb82@maths.lth.se>

Hi, I replied to a related question yesterday (Mon Sept 8, 2003) with
subject "RE: [R] cannot allocate vector of size...". That was as also
about running low of memory, but about *reading* data from file and not
writing. However, the problem is likely to be due to the same thing.

You pass a large object to a function via an argument, an argument which
is then changed inside the function (in your case write.table() is doing
x <- as.matrix(x)). As long as the argument is only read, R is clever
not to create a copy of it (pass by reference if read-only), but as soon
as you change it, it is creating a local copy of it (pass by value).
Hence, now you have your original 'xxx' object plus a local copy
"inside" the function. This is likely to be your problem. 

You can do the work around that Patrick Burns suggest and improve it
slightly, if can you do not need the 'xxx' variable anymore, you can do
'xxx <- as.matrix(xxx)'. A better approach, as you suggest yourself,
except from doing it row by row, is to write your dataframe block by
block with a reasonable block size. This can of course be done using a
for loop and write.table(), but you will do better if you look at the
code in write.table() and avoid the doing the same overhead work in each
step.

Finally and FYI, you might be able to shrink your original data frame by
considering the following

i <- as.integer(1:1000)
d <- as.double(i)
df1 <- data.frame(i=i, d=d)
df2 <- data.frame(i=i, d=i)
object.size(df1)  # 24392 bytes
object.size(df2)  # 20392 bytes

However, note that when doing x <- as.matrix(x) (as write.table() does),
will coerce the data into *one* data type (because it is a matrix). In
other words, the only thing you will gain is a smaller 'xxx' object.

Best wishes

Henrik Bengtsson
Lund University

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Thomas 
> W Blackwell
> Sent: den 9 september 2003 01:28
> To: array chip
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] memory problem in exporting data frame
> 
> 
> 
> Simplest is to save your workspace using  save.image(),
> then delete a bunch of large objects other than the data
> frame that you want to export, and run  write.table()
> again, now that you've made space for it.  A quick calc
> shows  17000 x 400 x 8 = 55 Mb, and that's just the size
> of the object that chokes R below.
> 
> -  tom blackwell  -  u michigan medical school  -  ann arbor  -
> 
> On Mon, 8 Sep 2003, array chip wrote:
> 
> > I am having trouble of exporting a large data frame
> > out of R to be used in other purpose. The data frame
> > is numeric with size 17000x400. It takes a quite some
> > time to start R as well. my computer has 1GB RAM. I
> > used the following command to write the data frame to
> > a text file and got the error message below:
> >
> > > write.table(xxx, "C:\\xxx", sep="\t",
> > row.names=FALSE,col.names=FALSE,quote=FALSE)
> >
> > Error: cannot allocate vector of size 55750 Kb
> > In addition: Warning message:
> > Reached total allocation of 1023Mb: see
> > help(memory.size)
> >
> > I tried to increase the memory size by
> > memory.size(size=), but it seems running the above
> > command takes forever.
> >
> > what can I do with this error message to get the data
> > out?
> >
> > Thanks
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> 
>



From petzoldt at rcs.urz.tu-dresden.de  Tue Sep  9 10:23:55 2003
From: petzoldt at rcs.urz.tu-dresden.de (Thomas Petzoldt)
Date: Tue, 09 Sep 2003 10:23:55 +0200
Subject: [R] R video
In-Reply-To: <8D0F30FE2EB3314182D4A33F738BB19D064009@sqlsrvr.evocapital.com>
References: <8D0F30FE2EB3314182D4A33F738BB19D064009@sqlsrvr.evocapital.com>
Message-ID: <3F5D8E1B.8090805@rcs.urz.tu-dresden.de>

David Khabie-Zeitoune schrieb:

> Hi
> 
> Does anybody know of any R packages under Windows to produce video files
> from a sequence of R graphs -- e.g. in .wmv or avi format?

Hello,

some times ago I've testet several methods and found the following to be 
useful and effective:

1.) Create a numbered sequence of bitmap images on the harddisk:

for(i in 1:nruns) {
   bmp(filename=paste("pp", i+1000, ".bmp", sep=""))
   plot(.........) # some plotting commands
   .........
   dev.off()
}

2.) Convert the bitmaps to a color depth of 16.7 Mio colors. For this 
purpose I use the freeware program IrfanView (http://www.irfanview.com).
Hint: File - Batch Conversion - Button "Set Advanced Options", Change 
Color Depth, 16.7 Million. Then select the files to convert, the 
destination path and the output format (.bmp), press the Start button 
and relax.

3.) Get the program "bmp2avi" (search the web for it) and convert the 
.bmp images to a video (avi) file.

4.) If the video is too large, use a video compression utility (e.g. the 
GPL licensed VirtualDub) to compress it.

5.) There are some alternative ways of creating animations using 
non-free software or tools to make animated Gifs.


Thomas



-- 
Thomas Petzoldt
Dresden University of Technology
Institute for Hydrobiology         petzoldt at rcs.urz.tu-dresden.de
01062 Dresden                      http://www.tu-dresden.de/fghhihb/



From britta.lintfert at IMS.Uni-Stuttgart.DE  Tue Sep  9 10:57:28 2003
From: britta.lintfert at IMS.Uni-Stuttgart.DE (Britta Lintfert)
Date: Tue, 09 Sep 2003 10:57:28 +0200
Subject: [R] ANOVA
Message-ID: <3F5D95F8.5AD69D91@ims.uni-stuttgart.de>

I have Data like this:

  Tone     OQtil4   OQ0     GOtil4    GO0    SKrhsJ   SK0    RCrhsJ
RC0
1  HsLG -9.1347877 -2.97  -7.409590  -6.40  9.389357 20.60 10.688854
24.40
2  HsLG -7.9270569 -2.03  -7.861541  -6.90 10.165324 26.40 10.640183
23.10
3  HsLG -7.0394106 -1.26  -7.509566  -6.53 12.033194 30.87  9.401959
20.37
4  HsLG -6.8625610 -1.03  -7.645118  -6.68 10.372605 24.22  9.378803
17.82
5  HsLG -3.4338120  0.09  -3.500840  -1.78 10.099846 21.02 12.616201
27.0
30 LsHG -4.9901811 -3.07  -7.277441  -6.92  3.720834  4.38  5.881904
12.38
31 LsHG -4.8716366 -3.09  -9.519955  -9.19  3.448722  3.11  6.209417
10.61
32 LsHG -4.9816874 -3.18 -10.213482  -9.88  3.800335  4.52  6.123314
9.62
33 LsHG -5.2910151 -3.45  -9.932184  -9.58  3.977211  3.82  6.607025
11.32
34  LpG -3.8409134 -1.73  -3.860474  -3.41  5.684152  9.39  6.836872
10.39
35  LpG  0.6961129  1.74  -6.001874  -5.82  4.579058  7.48  5.443493
8.38
36  LpG -1.7564074 -0.59   1.418013   1.92  7.995624 18.88  8.777576
19.33
37  LpG -1.1411241  0.06  -1.874103  -1.64  5.705399 11.19  7.445697
15.74
38  LpG -3.4338120  0.09  -3.500840  -1.78 10.099846 21.02 12.616201
27.02
39  LpG -3.1127062 -1.28  -5.409113  -5.07  8.406529 23.93  8.815908
24.43


now I want to know, if there are significant differents in the variables
OQ, GO, SK, RC depending on Tone. This I can do with an ANOVA , or??

But when I start aov in R I get the following message:

anova1 <- aov(Tone ~  OQtil4*OQ0*GOtil4*GO0*SKrhsJ*SK0*RCrhsJ*RC0,
data=gesamt)
Warning message:
"-" not meaningful for factors in: Ops.factor(y, z$residuals)

What's wrong with my Data?


Thanks for helping me

Britta



--
Britta.Lintfert at IMS.Uni-Stuttgart.de
Institut f?r Maschinelle Sprachverarbeitung
http://www.ims.uni-stuttgart.de
der Universit?t Stuttgart               Tel.: 0049/711/121-1372
Azenbergstr. 12, D-70174 Stuttgart      Fax.: 0049/711/121-1366



From erich.neuwirth at univie.ac.at  Tue Sep  9 10:52:59 2003
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Tue, 09 Sep 2003 10:52:59 +0200
Subject: [R] R video
In-Reply-To: <3F5D8E1B.8090805@rcs.urz.tu-dresden.de>
References: <8D0F30FE2EB3314182D4A33F738BB19D064009@sqlsrvr.evocapital.com>
	<3F5D8E1B.8090805@rcs.urz.tu-dresden.de>
Message-ID: <3F5D94EB.7070306@univie.ac.at>

Quicktime also can convert sequences of images into
quicktime and avi movies.
It accepts quite a lot of different image formats.





Thomas Petzoldt wrote:

> David Khabie-Zeitoune schrieb:
> 
>> Hi
>>
>> Does anybody know of any R packages under Windows to produce video files
>> from a sequence of R graphs -- e.g. in .wmv or avi format?
> 

Erich Neuwirth



From theis at statistik.uni-dortmund.de  Tue Sep  9 11:35:12 2003
From: theis at statistik.uni-dortmund.de (Winfried Theis)
Date: Tue, 09 Sep 2003 09:35:12 -0000
Subject: [R] ANOVA
In-Reply-To: <3F5D95F8.5AD69D91@ims.uni-stuttgart.de>
References: <3F5D95F8.5AD69D91@ims.uni-stuttgart.de>
Message-ID: <1063101098.1299.10.camel@malepartus>

Hi Britta!


On Tue, 2003-09-09 at 10:57, Britta Lintfert wrote:
[snip]
> 
> 
> now I want to know, if there are significant differents in the variables
> OQ, GO, SK, RC depending on Tone. This I can do with an ANOVA , or??
Yes, this is correct.
> 
> But when I start aov in R I get the following message:
> 
> anova1 <- aov(Tone ~  OQtil4*OQ0*GOtil4*GO0*SKrhsJ*SK0*RCrhsJ*RC0,
> data=gesamt)
> Warning message:
> "-" not meaningful for factors in: Ops.factor(y, z$residuals)
> 
> What's wrong with my Data?
Nothing. It is your call to aov that is wrong. Formulas in R are
formulated as "Dependent variable" ~ "influences". So what you are
trying to do is to explain Tone by all your other variables and their
interactions. If your variables are independent you may simply go ahead
and use aov on each of them. Look first for a book on multivariate
linear models...

> 
> 
> Thanks for helping me
You're welcome.

Winfried
> 
> Britta
> 
> 
> 
> --
> Britta.Lintfert at IMS.Uni-Stuttgart.de
> Institut f?r Maschinelle Sprachverarbeitung
> http://www.ims.uni-stuttgart.de
> der Universit?t Stuttgart               Tel.: 0049/711/121-1372
> Azenbergstr. 12, D-70174 Stuttgart      Fax.: 0049/711/121-1366
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
-- 
---------------------------------------------------------------------
Dipl.-Math. Winfried Theis
SFB 475, Fachbereich Statistik, Universit"at Dortmund, 44221 Dortmund
Tel.: +49-231-755-5903 FAX: +49-231-755-4387



From M.Mamin at intershop.de  Tue Sep  9 11:49:08 2003
From: M.Mamin at intershop.de (Marc Mamin)
Date: Tue, 9 Sep 2003 11:49:08 +0200 
Subject: [R] lattice.xyplot: adding grid lines
Message-ID: <770E451830D96B4D84747B54665DA1B202DAF0D8@jena03.net.j.ad.intershop.net>


Hallo,

I'd like to add grid lines to a lattice graph having 2 series of Y data.

See these 2 examples:



data(iris)

[1]
xyplot(Sepal.Length + Sepal.Width ~ Petal.Length ,
            data = iris, allow.multiple = TRUE, scales = "same",type="l",
)


[2]
xyplot(Sepal.Length + Sepal.Width ~ Petal.Length ,
            data = iris, allow.multiple = TRUE, scales = "same",type="l",
panel = function(x, y) {
  panel.grid(h=2, v= 3)
   panel.xyplot(x, y)
  }
)


Question:  is it possible to keep all the formats of example [1] (colors,
type="l", ...), and just add the grids appearing in example 2.
Moreover I'd like to choose the color of the grid...

Thanks for you help,

Marc Mamin



From ernesto at ipimar.pt  Tue Sep  9 11:49:07 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Tue, 09 Sep 2003 10:49:07 +0100
Subject: [R] Matrix resampling (bootstraps)
In-Reply-To: <5.2.1.1.0.20030908235330.02282ff0@mail.msu.edu>
References: <5.2.1.1.0.20030908235330.02282ff0@mail.msu.edu>
Message-ID: <1063100946.2735.17.camel@gandalf.local>

On Tue, 2003-09-09 at 05:11, Hector L. Ayala-del-Rio wrote:
> Dear all,
>     I am trying to generate bootstrap replicate matrixes (rows=samples, 
> column=species, sampling with replacement) from a matrix dataset, but I do 
> not know how to do it in R.  I have tried boot() and bootstrap(), but they 
> require an statistic, which in my case is cluster analysis (generating 
> bootstrap values for a cluster analysis is a topic that has been mentioned 
> previously in this list).  I have been trying to use sample() and matrix() 
> to generate the replicate matrix but they seem to generate a single vector 
> rather than the entire matrix.  What I want is to resample the entire 
> matrix, but by resampling different columns (species).  In that way, the 
> bootstrap values will give me an idea of how similar the samples are.  Any 
> ideas will be very very helpful.  An example of that data matrix is below.
> 
> Thanks
> 
> Hector
> 
>    X36C X40C X58C X60C X62C X66C X77C X92C X95C X96C X107C X109C X116C
> 26Y        0    0    0   59  919  351  128    0  104  214     0     0     0
> C-0        0    0    0  368 1343 1826  211    0  253  352     0     0     0
> C-50       0    0    0  211 1032 1701   50    0   54   56     0     0     0
> C-90      64    0   65  260  769  876    0    0   87    0     0    91    96
> C-127-1    0    0  127  149  364 3990    0    0    0    0     0     0     0
> C-164      0    0    0   68  179 2373    0    0  105    0     0     0     0
> C-198      0    0    0   89  327 1458  314    0  209  298     0     0     0
> C-226      0    0    0    0  206  858    0    0  363  304     0     0     0
> C-268      0    0    0   75  270  629    0    0  107    0     0     0     0
> C-294-C   54    0    0  112  379  753    0  220  823  325     0     0     0
> C-310      0    0    0    0  116  305    0  396 1049  355     0     0     0
> C-357-2   96    0    0  445  201  405    0  114 2265    0   178    99   125
> C-375     90    0   56  231  385  817    0  211 2776    0    57    79   106
> C-399    110    0   50  563 1060 1244    0  414 2933    0    54   107   123
> C-414     64    0    0  197  408  825    0  111 1875    0     0    82   104
> C-428     63    0    0   80  100  695    0  162 2374    0   481   132   369
> C-434      0    0    0  269  261 1689    0 2923 3496    0     0     0     0
> C-454     77    0    0  257  170  963    0  377 3984    0     0    90    96
> C-465      0    0    0  234  406  860    0  428 1601    0     0     0     0
> C-479    111    0    0  349  297 1538   51  494 3753    0    75   102    95
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

Hi Hector,

I'm not sure I've understood your problem, you should describe your data
for people fully understand your problem.

I think your should try to use the boot function. It has a lot of
analysis allready programed that are extremely usefull. Your statistic
must be the result of a R function applied to your dataset, just be
carefull to assure that the result of your function allways have the
same dimension, otherwise boot will fale. Regarding the species issue,
what I understant is that you want to bootstrap the observations of each
species independently and than compute the statistic. You can do that by
using the "strata" argument in boot. Change the matrix to a dataframe
with columns for species, samples and observations and tell boot that
species is the strata.

Hope this helps

EJ
-- 
Ernesto Jardim <ernesto at ipimar.pt>
Bi?logo Marinho/Marine Biologist
IPIMAR - Instituto Nacional de Investiga??o Agr?ria e das Pescas
IPIMAR - National Research Institute for Agriculture and Fisheries
Av. Brasilia, 1400-006
Lisboa, Portugal
Tel: +351 213 027 000
Fax: +351 213 015 948
http://ernesto.freezope.org



From ahmlatif at yahoo.com  Tue Sep  9 11:54:29 2003
From: ahmlatif at yahoo.com (Mahbub Latif)
Date: Tue, 9 Sep 2003 02:54:29 -0700 (PDT)
Subject: [R] lattice plot - portrait / landscape
Message-ID: <20030909095429.56442.qmail@web41215.mail.yahoo.com>

Hi,

How can I use portrait/landscape option in lattice
bwplot? Is there any option in trellis.device where I
can define this?

Thanks in advance,

Mahbub.



From christoph.lehmann at gmx.ch  Tue Sep  9 11:08:36 2003
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Tue, 09 Sep 2003 11:08:36 +0200
Subject: [R] logistic regression for a data set with perfect separation
Message-ID: <1063098516.1488.19.camel@christophl>

Dear R experts

I have the follwoing data
          V1 V2
1 -5.8000000  0
2 -4.8000000  0
3 -2.8666667  0
4 -0.8666667  0
5 -0.7333333  0
6 -1.6666667  0
7 -0.1333333  1
8  1.2000000  1
9  1.3333333  1

and I want to know, whether V1 can predict V2: of course it can, since
there is a perfect separation between cases 1..6 and 7..9

How can I test, whether this conclusion (being able to assign an
observation i to class j, only knowing its value on Variable V1)  holds
also for the population, our data were drawn from? 

Means, which inference procedure is recommended? Logistic regression
doesn't work, since the ML algorithm does not converge

1: Algorithm did not converge in: (if (is.empty.model(mt)) glm.fit.null else glm
.fit)(x = X, y = Y,
2: fitted probabilities numerically 0 or 1 occurred in: (if (is.empty.model(mt))
 glm.fit.null else glm.fit)(x = X, y = Y,

Many thanks for your help

Christoph
-- 
Christoph Lehmann <christoph.lehmann at gmx.ch>



From spencer.graves at pdf.com  Tue Sep  9 12:23:51 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 09 Sep 2003 03:23:51 -0700
Subject: [R] ANOVA
References: <3F5D95F8.5AD69D91@ims.uni-stuttgart.de>
	<1063101098.1299.10.camel@malepartus>
Message-ID: <3F5DAA37.4020708@pdf.com>

To expand on Winfried's comments, you may wish to try the following 
before considering multivariate:

	  anova(lm(OQtil4 ~ Tone, data=gesamt))

and similarly for your other response variables.  There are ways of 
putting this kind of thing in a loop, storing only the p values or 
whatever you want.  However, unless you need a routine to do this many 
times, it's probably best to just do it like this and be done with it.

hope this helps.  spencer graves

Winfried Theis wrote:
> Hi Britta!
> 
> 
> On Tue, 2003-09-09 at 10:57, Britta Lintfert wrote:
> [snip]
> 
>>
>>now I want to know, if there are significant differents in the variables
>>OQ, GO, SK, RC depending on Tone. This I can do with an ANOVA , or??
> 
> Yes, this is correct.
> 
>>But when I start aov in R I get the following message:
>>
>>anova1 <- aov(Tone ~  OQtil4*OQ0*GOtil4*GO0*SKrhsJ*SK0*RCrhsJ*RC0,
>>data=gesamt)
>>Warning message:
>>"-" not meaningful for factors in: Ops.factor(y, z$residuals)
>>
>>What's wrong with my Data?
> 
> Nothing. It is your call to aov that is wrong. Formulas in R are
> formulated as "Dependent variable" ~ "influences". So what you are
> trying to do is to explain Tone by all your other variables and their
> interactions. If your variables are independent you may simply go ahead
> and use aov on each of them. Look first for a book on multivariate
> linear models...
> 
> 
>>
>>Thanks for helping me
> 
> You're welcome.
> 
> Winfried
> 
>>Britta
>>
>>
>>
>>--
>>Britta.Lintfert at IMS.Uni-Stuttgart.de
>>Institut f?r Maschinelle Sprachverarbeitung
>>http://www.ims.uni-stuttgart.de
>>der Universit?t Stuttgart               Tel.: 0049/711/121-1372
>>Azenbergstr. 12, D-70174 Stuttgart      Fax.: 0049/711/121-1366
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From laurent.faisnel at ariase.com  Tue Sep  9 12:47:32 2003
From: laurent.faisnel at ariase.com (Laurent Faisnel)
Date: Tue, 09 Sep 2003 12:47:32 +0200
Subject: [R] No joy installing R with shared libs
Message-ID: <3F5DAFC4.4030707@ariase.com>

 >> Can some kind soul please give me a fool proof recipe for building R 
 >> and RSPython so that it actually works?


 > I don't have a recipe, but one thought to help debug the process:  Try
 > installing RPy [1].  RPy also provides access to R via Python and uses
 > the libR.so library.  If you can install and "import rpy" without
 > problem then it must be an issue with RSPython.

Hi,

I had problems of the same kind recently and finally gave up.
I tried to install Rpy without success, errors with undetected libraries 
occured while I was making the "import rpy" from python (especially with 
libblas).
Since I was not sure R was correctly configured I downloaded the latest 
version R-1.7.1 and tried to install it with R-enable-shared option. I 
could not get out of numerous errors.
Please tell me whether the problem you had calling RSPython is solved 
after installing RPy (if it was possible to install it).
Good luck.

Laurent



From laurent.faisnel at ariase.com  Tue Sep  9 12:49:57 2003
From: laurent.faisnel at ariase.com (Laurent Faisnel)
Date: Tue, 09 Sep 2003 12:49:57 +0200
Subject: [R] problem trying to use a superclass on R-1.7.1
Message-ID: <3F5DB055.5040001@ariase.com>

  Hi dear helpers,

I have been using for quite a long time a script where a class extends 
another one (without trouble). But I now have problems of that kind 
while trying to run the script :

Error in insertMethod(methods, sig, args, def, TRUE) :
         inserting method corresponding to empty signature

I think this may be because the way I wrote the scripts could be 
deprecated. Indeed I recently downloaded R-1.7.1 (binary version).

This is how my classes look like :

#-----------------------------------------------------
# CLASS    Person
#-----------------------------------------------------

setClass("Person",representation(name="character"));

# CONSTRUCTOR

setMethod("initialize","Person",
           function(.Object)
           {
               .Object at name <- "Unknown"; # default name
               return(.Object);
           }
);

#-----------------------------------------------------
# CLASS    Employee           (extends Person)
#-----------------------------------------------------

setClass("Employee",representation("Person", service="character", 
con="MySQLConnection"));

# con : connection to be established with MySQL database

# constructor
setMethod("initialize","Employee",
           function(.Object)
           {
               .Object <- callNextMethod();  # calls the superclass 
constructor
             .Object at con <- dbConnect("MySQL");
             .Object at service <- "unknown service";
             return(.Object);
           }
);

The script just creates a new Employee and the error occurs when it 
comes to callNextMethod()

Thanks for any help.
Laurent

PS : I've read there's something related to this in R-1.7.1's new 
features, but it does not seem to match the problem exactly (problems 
that used to wait until new() is called to appear are now caught 
properly). Is the initialize() function deprecated ? Should I use 
prototype instead ?



From s195404 at student.uq.edu.au  Tue Sep  9 12:48:23 2003
From: s195404 at student.uq.edu.au (Andrew C. Ward)
Date: Tue,  9 Sep 2003 10:48:23 +0000
Subject: [R] lattice plot - portrait / landscape
In-Reply-To: <20030909095429.56442.qmail@web41215.mail.yahoo.com>
References: <20030909095429.56442.qmail@web41215.mail.yahoo.com>
Message-ID: <1063104503.3f5daff7b3131@my.uq.edu.au>

Dear Manbub,

I assume that you mean you want the boxes to be vertical
rather than horizontal (which is the default). Compare the
following two uses of bwplot:
   data(singer)
   bwplot(voice.part ~ height, data=singer, xlab="Height 
(inches)")
   bwplot(height ~ voice.part, data=singer, ylab="Height 
(inches)", horizontal=FALSE)

If by some chance you wish to change the orientation of a
saved graph, you'll find that the postscript device has an
argument horizontal that affects the orientation of the 
printed image. See ?postscript for all the glorious details.

If you mean something else entirely, perhaps you'd better
rephrase the question :)


Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au


Quoting Mahbub Latif <ahmlatif at yahoo.com>:

> Hi,
> 
> How can I use portrait/landscape option in lattice
> bwplot? Is there any option in trellis.device where I
> can define this?
> 
> Thanks in advance,
> 
> Mahbub.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From simon_gibbon at ici.com  Tue Sep  9 13:15:34 2003
From: simon_gibbon at ici.com (simon_gibbon@ici.com)
Date: Tue, 9 Sep 2003 12:15:34 +0100
Subject: [R]: RODBC column length>255
Message-ID: <OFEBCEDF20.F6E8BA35-ON80256D9C.003CF35C@unauthorised.ici.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030909/0a19caec/attachment.pl

From one_ming at yahoo.com  Tue Sep  9 13:17:25 2003
From: one_ming at yahoo.com (Yiming Zhou)
Date: Tue, 9 Sep 2003 04:17:25 -0700 (PDT)
Subject: [R] How to convert a Rd file into multi html files?
Message-ID: <20030909111726.30352.qmail@web21210.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030909/fcaa884c/attachment.pl

From ligges at statistik.uni-dortmund.de  Tue Sep  9 13:42:46 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 09 Sep 2003 13:42:46 +0200
Subject: [R] How to convert a Rd file into multi html files?
In-Reply-To: <20030909111726.30352.qmail@web21210.mail.yahoo.com>
References: <20030909111726.30352.qmail@web21210.mail.yahoo.com>
Message-ID: <3F5DBCB6.8070807@statistik.uni-dortmund.de>

Yiming Zhou wrote:

> Hi,
> I wrote all documents for each objects in my package in one .Rd file. Now I can't convert the .Rd file into multi html files such that a html file corresponds a object in package. 
> The command I used was ' R CMD Rdconv -t html foo.Rd'. It just converted the document of first object in .Rd into html format.
>  
> I had to write a perl script to satisfy myself. But is there a more direct and simple way to do it?
>  
> Thank you very much.
>  
> your sincerely,
>  
> Yiming Zhou

The idea is to have one Rd file for each function -- with some 
exceptions, hence this is not supported.

Why don't you build a package? With the right \alias{} entries, you will 
get that help page for any help() call of an aliased topic.

Uwe Ligges



From ucgamdo at ucl.ac.uk  Tue Sep  9 13:50:14 2003
From: ucgamdo at ucl.ac.uk (ucgamdo@ucl.ac.uk)
Date: Tue, 09 Sep 2003 12:50:14 +0100
Subject: [R] Re: Hierarchical clustering
Message-ID: <3.0.5.32.20030909125014.007d5100@pop-server.ucl.ac.uk>

I think are looking for the function 'cutree' from package mva

checkout its documentation:

> require(mva)
> ?cutree

pleanty of examples to do what you want.


#############################################################################
Hi R lovers!

I am using the agnes function of the package cluster to compute a
hierarchical clustering.
I'd like to know if somebody has ever developped a function which could
give the names/label of the individuals merged together with respect to the
number of cluster the user eventually wants to keep.
Namely, If I have the dendogram and I choose to cut it to get , say 5
cluster, how can I get the names of the individuals in each of the 5
clusters?

I am looking for an algorithm that could do that.
I have tried to find one using the $merge component of the agnes.object or
the $order.lab component but with no result.

If by chance it exists already...
Thank you very much.



From p.pagel at gsf.de  Tue Sep  9 14:04:38 2003
From: p.pagel at gsf.de (Philipp Pagel)
Date: Tue, 9 Sep 2003 14:04:38 +0200
Subject: [R] How to convert a Rd file into multi html files?
In-Reply-To: <20030909111726.30352.qmail@web21210.mail.yahoo.com>
References: <20030909111726.30352.qmail@web21210.mail.yahoo.com>
Message-ID: <20030909120437.GA4249@porcupine.gsf.de>


	Hi!

On Tue, Sep 09, 2003 at 04:17:25AM -0700, Yiming Zhou wrote:
> The command I used was ' R
> CMD Rdconv -t html foo.Rd'. It just converted the document of first
> object in .Rd into html format.

I'm not exactly an expert in writing R documentation but while playing
arround with package building I initially had the same problem. By
looking at other peoples *.Rd files I discovered that you need to
separate individual sections of documentation by \eof. "Writing R
Extensions" doesn't seem to mention this, though.

hope it helps
	Philipp

-- 
Dr. Philipp Pagel                                Tel.  +49-89-3187-3675
Institute for Bioinformatics / MIPS              Fax.  +49-89-3187-3585
GSF - National Research Center for Environment and Health
Ingolstaedter Landstrasse 1
85764 Neuherberg, Germany



From Arne.Muller at aventis.com  Tue Sep  9 14:10:28 2003
From: Arne.Muller at aventis.com (Arne.Muller@aventis.com)
Date: Tue, 9 Sep 2003 14:10:28 +0200
Subject: [R] No joy installing R with shared libs
Message-ID: <C80ECAFA2ACC1B45BE45D133ED660ADECDCADF@crbsmxsusr04.pharma.aventis.com>

Hi,

I've experienced similar failures with the RSperl installation. So I'd be
interested if someone sorts out the library misery ... ;-)

	Arne

> -----Original Message-----
> From: Laurent Faisnel [mailto:laurent.faisnel at ariase.com]
> Sent: 09 September 2003 12:48
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] No joy installing R with shared libs
> 
> 
>  >> Can some kind soul please give me a fool proof recipe for 
> building R 
>  >> and RSPython so that it actually works?
> 
> 
>  > I don't have a recipe, but one thought to help debug the 
> process:  Try
>  > installing RPy [1].  RPy also provides access to R via 
> Python and uses
>  > the libR.so library.  If you can install and "import rpy" without
>  > problem then it must be an issue with RSPython.
> 
> Hi,
> 
> I had problems of the same kind recently and finally gave up.
> I tried to install Rpy without success, errors with 
> undetected libraries 
> occured while I was making the "import rpy" from python 
> (especially with 
> libblas).
> Since I was not sure R was correctly configured I downloaded 
> the latest 
> version R-1.7.1 and tried to install it with R-enable-shared 
> option. I 
> could not get out of numerous errors.
> Please tell me whether the problem you had calling RSPython is solved 
> after installing RPy (if it was possible to install it).
> Good luck.
> 
> Laurent
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From gattuso at obs-vlfr.fr  Tue Sep  9 14:39:53 2003
From: gattuso at obs-vlfr.fr (Gattuso, Jean-Pierre)
Date: Tue, 9 Sep 2003 14:39:53 +0200
Subject: [R] Making R packages
Message-ID: <p06002012bb837666df81@[193.49.112.222]>

Hi:

I am posting this message for a colleague who has 
a lot of trouble to build an R package on 
Windows. He did not find a solution to his 
problems on the R-help archives and hopes that 
one of the R gurus will be able to help.

He has a directory "CO2" which should contain all 
the required files and directories:
	DATA:
	DESCRIPTION
	MAN:
	R:
	README
	SRC:

The following command is run in a windows console:
	C:\Program Files\R\rw1071\bin\rcmd INSTALL D:\CO2

Then he gets the following error (approximate 
translation of a French message) :
	"Perl is not recognized as an internal or 
external command, an executable file or a command 
file"

Perl has of course been installed on the PC and 
my colleague has the "Tools" file. He does not 
know what is wrong although he suspects that 
environment variables (which ones?) must be 
changed.

Any help would be appreciated.

jp
-- 

Jean-Pierre Gattuso | mailto:gattuso at obs-vlfr.fr 
| http://www.obs-vlfr.fr/~gattuso



From Sean.Davis at dcb.cit.nih.gov  Tue Sep  9 14:51:27 2003
From: Sean.Davis at dcb.cit.nih.gov (Sean Davis)
Date: Tue, 9 Sep 2003 08:51:27 -0400 (EDT)
Subject: [R] Building XML package for MacOS X
Message-ID: <Pine.GSO.4.50.0309090845440.3952-100000@argo.cit.nih.gov>

I am working to build the XML package for R on MacOS X.  I have installed
libxml2-2.5.9 into /usr/local.  I set the
LIBXML_INCDIR=/usr/local/include/libxml2.  I use R INSTALL, I get the
following:

R INSTALL -c -l /usr/local/R/library XML_0.94-1.tar.gz
  :
  :
  :
gcc -bundle -flat_namespace -undefined suppress -L/sw/lib -L/usr/local/lib
-o XML.so DocParse.o EventParse.o ExpatParse.o HTMLParse.o RSDTD.o
RUtils.o Utils.o XMLEventParse.o XMLTree.o -lz  -lxml2
ld: multiple definitions of symbol _xmlParserError
Utils.o definition of _xmlParserError in section (__TEXT,__text)
/usr/local/lib/libxml2.dylib(libxml2.2.5.9.dylib-master.o) definition of
_xmlParserError
make: *** [XML.so] Error 1
ERROR: compilation failed for package 'XML'

How can I fix the problem?  I have tried compiling straight source that
has other problems.  I think that I need to modify the "makefile" to let
the compiler to use only the first definition of _xmlParserError, but I
don't know how to do this when using R INSTALL.

Thanks,
Sean



From thpe at hhbio.wasser.tu-dresden.de  Tue Sep  9 14:49:13 2003
From: thpe at hhbio.wasser.tu-dresden.de (Thomas Petzoldt)
Date: Tue, 09 Sep 2003 14:49:13 +0200
Subject: [R] Making R packages
In-Reply-To: <p06002012bb837666df81@[193.49.112.222]>
References: <p06002012bb837666df81@[193.49.112.222]>
Message-ID: <3F5DCC49.9050907@hhbio.wasser.tu-dresden.de>

Gattuso, Jean-Pierre wrote:


> The following command is run in a windows console:
>     C:\Program Files\R\rw1071\bin\rcmd INSTALL D:\CO2
> 
> Then he gets the following error (approximate translation of a French 
> message) :
>     "Perl is not recognized as an internal or external command, an 
> executable file or a command file"

You (or he) has to set the appropriate PATH to contain the tools, the 
Perl\bin  the Mingw\bin and the Html-Workshop directories. You should 
respect capitalization of the path names and avoid spaces within the 
names. For the latter you can use the abbreviated directory name, e.g. 
C:\PROGRA~1\Perl\bin (or whatever) instead of C:\Program Files\Perl\bin

Thomas



From pols1oh at bestweb.net  Tue Sep  9 14:55:18 2003
From: pols1oh at bestweb.net (michaell taylor)
Date: Tue, 09 Sep 2003 12:55:18 -0000
Subject: [R] Hardware oddity - linux/windows
Message-ID: <1063112130.25704.58.camel@xeon>


Hi,

I am trying to figure out why a new machine is running my R script so
slowly.  

The script was developed on a Linux , dual 2.8 xeon processor machine
with 4GB ram.  On this machine, the script runs in about an hour (it
creates lots of multilevel simulations). While running, 100% of a single
processor (50% of dual processor) is used consistently during the entire
run, about 800 MB of ram is utilized.  Xeon hyperthread condition
(on/off) seems not to matter to performance.  While the script runs, I
am using the "other" processor for miscellaneous emailing, editing, etc.

Moving the script to a windows XP machine with nearly identical hardware
configuration (2.8 dual xeon, 4.5 GB ram) the script takes nearly 2
hours.  Oddly, the maximum cpu load on this machine is 50% of a single
processor (25% of dual processor) during the run - which seems
consistent with the doubling of total processing time. While running
this script, this machine does no other tasks whatsoever. 

Both machines have at least double the memory required for the task,
both utilize fast scsi drives and all data is stored locally on the
drive (no data on network drives).  Moreover, being a simulated problem,
very little data is read/written to drives during the process.

Anyone have ideas as to why the Windows machine is so slow?

Thanks in advance.

Michaell Taylor



From dmurdoch at pair.com  Tue Sep  9 14:55:45 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue, 09 Sep 2003 08:55:45 -0400
Subject: [R] Making R packages
In-Reply-To: <p06002012bb837666df81@[193.49.112.222]>
References: <p06002012bb837666df81@[193.49.112.222]>
Message-ID: <8bjrlv8aq5hoqt76uh306ukkqj8vtsecoa@4ax.com>

On Tue, 9 Sep 2003 14:39:53 +0200, you wrote:

>Then he gets the following error (approximate 
>translation of a French message) :
>	"Perl is not recognized as an internal or 
>external command, an executable file or a command 
>file"
>
>Perl has of course been installed on the PC and 
>my colleague has the "Tools" file. He does not 
>know what is wrong although he suspects that 
>environment variables (which ones?) must be 
>changed.
>
>Any help would be appreciated.

Sounds as though his PATH is missing the Perl directory.  Quoting the
INSTALL file:

>Check your path
>---------------
>
>You need the following in your path (with the first two first):
>.
>our toolset
>mingw\bin
>Perl\bin
>the latex bin directory
>zip.exe, unzip.exe, hhc.exe

Duncan Murdoch



From ligges at statistik.uni-dortmund.de  Tue Sep  9 15:01:34 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 09 Sep 2003 15:01:34 +0200
Subject: [R] Making R packages
In-Reply-To: <p06002012bb837666df81@[193.49.112.222]>
References: <p06002012bb837666df81@[193.49.112.222]>
Message-ID: <3F5DCF2E.1060507@statistik.uni-dortmund.de>

Gattuso, Jean-Pierre wrote:

> Hi:
> 
> I am posting this message for a colleague who has a lot of trouble to 
> build an R package on Windows. He did not find a solution to his 
> problems on the R-help archives and hopes that one of the R gurus will 
> be able to help.
> 
> He has a directory "CO2" which should contain all the required files and 
> directories:
>     DATA:
>     DESCRIPTION
>     MAN:
>     R:
>     README
>     SRC:
> 
> The following command is run in a windows console:
>     C:\Program Files\R\rw1071\bin\rcmd INSTALL D:\CO2
> 
> Then he gets the following error (approximate translation of a French 
> message) :
>     "Perl is not recognized as an internal or external command, an 
> executable file or a command file"
> 
> Perl has of course been installed on the PC and my colleague has the 
> "Tools" file. He does not know what is wrong although he suspects that 
> environment variables (which ones?) must be changed.
> 
> Any help would be appreciated.
> 
> jp

You have to add perl to your environment variable "path".
It's a good idea to add your R directory too, so you can do:

d:\> Rcmd INSTALL CO2

If you have some C or Fortran sources, you will need the compiler as 
well, see ...\rw1071\src\gnuwin32\readme.packages for details.

Uwe Ligges
Uwe Ligges



From ernesto at ipimar.pt  Tue Sep  9 15:01:21 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Tue, 09 Sep 2003 14:01:21 +0100
Subject: [R] Making R packages
In-Reply-To: <p06002012bb837666df81@[193.49.112.222]>
References: <p06002012bb837666df81@[193.49.112.222]>
Message-ID: <1063112480.3178.1.camel@gandalf.local>

On Tue, 2003-09-09 at 13:39, Gattuso, Jean-Pierre wrote:
> Hi:
> 
> I am posting this message for a colleague who has 
> a lot of trouble to build an R package on 
> Windows. He did not find a solution to his 
> problems on the R-help archives and hopes that 
> one of the R gurus will be able to help.
> 
> He has a directory "CO2" which should contain all 
> the required files and directories:
> 	DATA:
> 	DESCRIPTION
> 	MAN:
> 	R:
> 	README
> 	SRC:
> 
> The following command is run in a windows console:
> 	C:\Program Files\R\rw1071\bin\rcmd INSTALL D:\CO2
> 
> Then he gets the following error (approximate 
> translation of a French message) :
> 	"Perl is not recognized as an internal or 
> external command, an executable file or a command 
> file"
> 
> Perl has of course been installed on the PC and 
> my colleague has the "Tools" file. He does not 
> know what is wrong although he suspects that 
> environment variables (which ones?) must be 
> changed.
> 
> Any help would be appreciated.
> 
> jp

Hi JP,

Depending on your OS version you can change the PATH variable. In NT
version is under "system" I believe (I don't have a M$ system here to
check).

Hope this helps.

Regards

EJ



From deepayan at stat.wisc.edu  Tue Sep  9 15:03:06 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 9 Sep 2003 08:03:06 -0500
Subject: [R] lattice.xyplot: adding grid lines
In-Reply-To: <770E451830D96B4D84747B54665DA1B202DAF0D8@jena03.net.j.ad.intershop.net>
References: <770E451830D96B4D84747B54665DA1B202DAF0D8@jena03.net.j.ad.intershop.net>
Message-ID: <200309090803.06587.deepayan@stat.wisc.edu>

On Tuesday 09 September 2003 04:49, Marc Mamin wrote:
> Hallo,
>
> I'd like to add grid lines to a lattice graph having 2 series of Y data.
>
> See these 2 examples:
>
>
>
> data(iris)
>
> [1]
> xyplot(Sepal.Length + Sepal.Width ~ Petal.Length ,
>             data = iris, allow.multiple = TRUE, scales = "same",type="l",
> )
>
>
> [2]
> xyplot(Sepal.Length + Sepal.Width ~ Petal.Length ,
>             data = iris, allow.multiple = TRUE, scales = "same",type="l",
> panel = function(x, y) {
>   panel.grid(h=2, v= 3)
>    panel.xyplot(x, y)
>   }
> )
>
>
> Question:  is it possible to keep all the formats of example [1] (colors,
> type="l", ...), and just add the grids appearing in example 2.
> Moreover I'd like to choose the color of the grid...

Something like this should work:

xyplot(Sepal.Length + Sepal.Width ~ Petal.Length ,
       data = iris, allow.multiple = TRUE, scales = "same",type="l",
       panel = function(...) {
           panel.grid(h=2, v= 3, col="blue")
           panel.xyplot(...)
       }
)

Deepayan



From JonesW at kssg.com  Tue Sep  9 14:55:19 2003
From: JonesW at kssg.com (Wayne Jones)
Date: Tue, 9 Sep 2003 13:55:19 +0100 
Subject: [R] Making R packages
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB021F0E4A@gimli.middleearth.kssg.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030909/94646e11/attachment.pl

From JonesW at kssg.com  Tue Sep  9 15:02:08 2003
From: JonesW at kssg.com (Wayne Jones)
Date: Tue, 9 Sep 2003 14:02:08 +0100 
Subject: [R] Making R packages
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB021F0E4B@gimli.middleearth.kssg.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030909/57c8326a/attachment.pl

From jmacdon at med.umich.edu  Tue Sep  9 15:10:37 2003
From: jmacdon at med.umich.edu (James MacDonald)
Date: Tue, 09 Sep 2003 09:10:37 -0400
Subject: [R] Matrix resampling (bootstraps)
Message-ID: <sf5d9927.072@mail-01.med.umich.edu>

Putting aside the issue of whether you should be using boot() or not,
you can resample your matrix by doing something like this.

> a <- matrix(1:10, nrow=10, ncol=10, byrow=TRUE)
> a
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
 [1,]    1    2    3    4    5    6    7    8    9    10
 [2,]    1    2    3    4    5    6    7    8    9    10
 [3,]    1    2    3    4    5    6    7    8    9    10
 [4,]    1    2    3    4    5    6    7    8    9    10
 [5,]    1    2    3    4    5    6    7    8    9    10
 [6,]    1    2    3    4    5    6    7    8    9    10
 [7,]    1    2    3    4    5    6    7    8    9    10
 [8,]    1    2    3    4    5    6    7    8    9    10
 [9,]    1    2    3    4    5    6    7    8    9    10
[10,]    1    2    3    4    5    6    7    8    9    10
> b <- sample(1:10, replace=TRUE)
> b
 [1]  2 10  7 10  5  1  4  5  9  5
> d <- a[,b]
> d
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
 [1,]    2   10    7   10    5    1    4    5    9     5
 [2,]    2   10    7   10    5    1    4    5    9     5
 [3,]    2   10    7   10    5    1    4    5    9     5
 [4,]    2   10    7   10    5    1    4    5    9     5
 [5,]    2   10    7   10    5    1    4    5    9     5
 [6,]    2   10    7   10    5    1    4    5    9     5
 [7,]    2   10    7   10    5    1    4    5    9     5
 [8,]    2   10    7   10    5    1    4    5    9     5
 [9,]    2   10    7   10    5    1    4    5    9     5
[10,]    2   10    7   10    5    1    4    5    9     5

HTH,

Jim


James W. MacDonald
Affymetrix and cDNA Microarray Core
University of Michigan Cancer Center
1500 E. Medical Center Drive
7410 CCGC
Ann Arbor MI 48109
734-647-5623

>>> "Hector L. Ayala-del-Rio" <ayalahec at msu.edu> 09/09/03 12:11AM >>>
Dear all,
    I am trying to generate bootstrap replicate matrixes (rows=samples,

column=species, sampling with replacement) from a matrix dataset, but I
do 
not know how to do it in R.  I have tried boot() and bootstrap(), but
they 
require an statistic, which in my case is cluster analysis (generating

bootstrap values for a cluster analysis is a topic that has been
mentioned 
previously in this list).  I have been trying to use sample() and
matrix() 
to generate the replicate matrix but they seem to generate a single
vector 
rather than the entire matrix.  What I want is to resample the entire 
matrix, but by resampling different columns (species).  In that way,
the 
bootstrap values will give me an idea of how similar the samples are. 
Any 
ideas will be very very helpful.  An example of that data matrix is
below.

Thanks

Hector

   X36C X40C X58C X60C X62C X66C X77C X92C X95C X96C X107C X109C X116C
26Y        0    0    0   59  919  351  128    0  104  214     0     0  
  0
C-0        0    0    0  368 1343 1826  211    0  253  352     0     0  
  0
C-50       0    0    0  211 1032 1701   50    0   54   56     0     0  
  0
C-90      64    0   65  260  769  876    0    0   87    0     0    91  
 96
C-127-1    0    0  127  149  364 3990    0    0    0    0     0     0  
  0
C-164      0    0    0   68  179 2373    0    0  105    0     0     0  
  0
C-198      0    0    0   89  327 1458  314    0  209  298     0     0  
  0
C-226      0    0    0    0  206  858    0    0  363  304     0     0  
  0
C-268      0    0    0   75  270  629    0    0  107    0     0     0  
  0
C-294-C   54    0    0  112  379  753    0  220  823  325     0     0  
  0
C-310      0    0    0    0  116  305    0  396 1049  355     0     0  
  0
C-357-2   96    0    0  445  201  405    0  114 2265    0   178    99  
125
C-375     90    0   56  231  385  817    0  211 2776    0    57    79  
106
C-399    110    0   50  563 1060 1244    0  414 2933    0    54   107  
123
C-414     64    0    0  197  408  825    0  111 1875    0     0    82  
104
C-428     63    0    0   80  100  695    0  162 2374    0   481   132  
369
C-434      0    0    0  269  261 1689    0 2923 3496    0     0     0  
  0
C-454     77    0    0  257  170  963    0  377 3984    0     0    90  
 96
C-465      0    0    0  234  406  860    0  428 1601    0     0     0  
  0
C-479    111    0    0  349  297 1538   51  494 3753    0    75   102  
 95

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From deepayan at stat.wisc.edu  Tue Sep  9 15:13:22 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 9 Sep 2003 08:13:22 -0500
Subject: [R] lattice plot - portrait / landscape
In-Reply-To: <1063104503.3f5daff7b3131@my.uq.edu.au>
References: <20030909095429.56442.qmail@web41215.mail.yahoo.com>
	<1063104503.3f5daff7b3131@my.uq.edu.au>
Message-ID: <200309090813.22648.deepayan@stat.wisc.edu>

On Tuesday 09 September 2003 05:48, Andrew C. Ward wrote:
> Dear Manbub,
>
> I assume that you mean you want the boxes to be vertical
> rather than horizontal (which is the default). Compare the
> following two uses of bwplot:
>    data(singer)
>    bwplot(voice.part ~ height, data=singer, xlab="Height
> (inches)")
>    bwplot(height ~ voice.part, data=singer, ylab="Height
> (inches)", horizontal=FALSE)


One small additional comment: you shouldn't need to use the horizontal 
argument in this case, or whenever exactly one of the arguments is a factor. 
horizontal "defaults" to TRUE only when both are numeric or both are factors 
(ideally neither should happen).


> If by some chance you wish to change the orientation of a
> saved graph, you'll find that the postscript device has an
> argument horizontal that affects the orientation of the
> printed image. See ?postscript for all the glorious details.
>
> If you mean something else entirely, perhaps you'd better
> rephrase the question :)
>
>
> Regards,
>
> Andrew C. Ward
>
> CAPE Centre
> Department of Chemical Engineering
> The University of Queensland
> Brisbane Qld 4072 Australia
> andreww at cheque.uq.edu.au
>
> Quoting Mahbub Latif <ahmlatif at yahoo.com>:
> > Hi,
> >
> > How can I use portrait/landscape option in lattice
> > bwplot? Is there any option in trellis.device where I
> > can define this?
> >
> > Thanks in advance,
> >
> > Mahbub.
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From M.Mamin at intershop.de  Tue Sep  9 15:19:18 2003
From: M.Mamin at intershop.de (Marc Mamin)
Date: Tue, 9 Sep 2003 15:19:18 +0200 
Subject: [R] lattice.xyplot: adding grid lines
Message-ID: <770E451830D96B4D84747B54665DA1B202DAF0DC@jena03.net.j.ad.intershop.net>

Hallo, thank you for your answer,

there is still one problem in your solution:

Sepal.Length + Sepal.Width are considerd as a single serie of data...

Marc Mamin




-----Original Message-----
From: Deepayan Sarkar [mailto:deepayan at stat.wisc.edu]
Sent: Tuesday, September 09, 2003 3:03 PM
To: Marc Mamin; R-help
Subject: Re: [R] lattice.xyplot: adding grid lines


On Tuesday 09 September 2003 04:49, Marc Mamin wrote:
> Hallo,
>
> I'd like to add grid lines to a lattice graph having 2 series of Y data.
>
> See these 2 examples:
>
>
>
> data(iris)
>
> [1]
> xyplot(Sepal.Length + Sepal.Width ~ Petal.Length ,
>             data = iris, allow.multiple = TRUE, scales = "same",type="l",
> )
>
>
> [2]
> xyplot(Sepal.Length + Sepal.Width ~ Petal.Length ,
>             data = iris, allow.multiple = TRUE, scales = "same",type="l",
> panel = function(x, y) {
>   panel.grid(h=2, v= 3)
>    panel.xyplot(x, y)
>   }
> )
>
>
> Question:  is it possible to keep all the formats of example [1] (colors,
> type="l", ...), and just add the grids appearing in example 2.
> Moreover I'd like to choose the color of the grid...

Something like this should work:

xyplot(Sepal.Length + Sepal.Width ~ Petal.Length ,
       data = iris, allow.multiple = TRUE, scales = "same",type="l",
       panel = function(...) {
           panel.grid(h=2, v= 3, col="blue")
           panel.xyplot(...)
       }
)

Deepayan



From seancarmody at yahoo.com  Tue Sep  9 15:26:18 2003
From: seancarmody at yahoo.com (=?iso-8859-1?q?Sean=20Carmody?=)
Date: Tue, 9 Sep 2003 23:26:18 +1000 (EST)
Subject: [R] Changing Tick Marks for Date Plots
Message-ID: <20030909132618.88868.qmail@web13509.mail.yahoo.com>

I have been experimenting with various approaches to
plotting (irregular) time-series with reasonable
success. One thing I have been able to do is change
the number of tick marks on the axis. Consider the
following simple example:

> x <- as.data.frame(matrix(ncol=2,nrow=500))
> names(x) <- c("dates","values")
> x$dates <- as.POSIXct(Sys.time()+1:500*86400)
> x$values <- cumsum(rnorm(500))))
> plot(x$dates,x$values,type="l")

The resulting plot only has two tick-marks: 2004 and
2005 (depending on today's date!). I have the same
problem when I use the "its" library:

> library(its)
> plot(as.its(x),format="%b-%Y")

Any suggestions would be greatly appreciated.

Regards,
Sean.



http://search.yahoo.com.au - Yahoo! Search
- Looking for more? Try the new Yahoo! Search



From ripley at stats.ox.ac.uk  Tue Sep  9 15:28:07 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 9 Sep 2003 14:28:07 +0100 (BST)
Subject: [R] Building XML package for MacOS X
In-Reply-To: <Pine.GSO.4.50.0309090845440.3952-100000@argo.cit.nih.gov>
Message-ID: <Pine.LNX.4.44.0309091426570.23724-100000@gannet.stats>

The simplest way is probably to edit the libxml2 library and remove
the module containing xmlParserError.  That's what the Windows maintainer 
has to do.

On Tue, 9 Sep 2003, Sean Davis wrote:

> I am working to build the XML package for R on MacOS X.  I have installed
> libxml2-2.5.9 into /usr/local.  I set the
> LIBXML_INCDIR=/usr/local/include/libxml2.  I use R INSTALL, I get the
> following:
> 
> R INSTALL -c -l /usr/local/R/library XML_0.94-1.tar.gz
>   :
>   :
>   :
> gcc -bundle -flat_namespace -undefined suppress -L/sw/lib -L/usr/local/lib
> -o XML.so DocParse.o EventParse.o ExpatParse.o HTMLParse.o RSDTD.o
> RUtils.o Utils.o XMLEventParse.o XMLTree.o -lz  -lxml2
> ld: multiple definitions of symbol _xmlParserError
> Utils.o definition of _xmlParserError in section (__TEXT,__text)
> /usr/local/lib/libxml2.dylib(libxml2.2.5.9.dylib-master.o) definition of
> _xmlParserError
> make: *** [XML.so] Error 1
> ERROR: compilation failed for package 'XML'
> 
> How can I fix the problem?  I have tried compiling straight source that
> has other problems.  I think that I need to modify the "makefile" to let
> the compiler to use only the first definition of _xmlParserError, but I
> don't know how to do this when using R INSTALL.
> 
> Thanks,
> Sean
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Sep  9 15:29:36 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 9 Sep 2003 14:29:36 +0100 (BST)
Subject: [R] Hardware oddity - linux/windows
In-Reply-To: <1063112130.25704.58.camel@xeon>
Message-ID: <Pine.LNX.4.44.0309091428390.23724-100000@gannet.stats>

Do you have an anti-virus software running?  That's about what I see when 
Sophos is switched on.

On 9 Sep 2003, michaell taylor wrote:

> 
> Hi,
> 
> I am trying to figure out why a new machine is running my R script so
> slowly.  
> 
> The script was developed on a Linux , dual 2.8 xeon processor machine
> with 4GB ram.  On this machine, the script runs in about an hour (it
> creates lots of multilevel simulations). While running, 100% of a single
> processor (50% of dual processor) is used consistently during the entire
> run, about 800 MB of ram is utilized.  Xeon hyperthread condition
> (on/off) seems not to matter to performance.  While the script runs, I
> am using the "other" processor for miscellaneous emailing, editing, etc.
> 
> Moving the script to a windows XP machine with nearly identical hardware
> configuration (2.8 dual xeon, 4.5 GB ram) the script takes nearly 2
> hours.  Oddly, the maximum cpu load on this machine is 50% of a single
> processor (25% of dual processor) during the run - which seems
> consistent with the doubling of total processing time. While running
> this script, this machine does no other tasks whatsoever. 

The last is very, very unlikely.

> Both machines have at least double the memory required for the task,
> both utilize fast scsi drives and all data is stored locally on the
> drive (no data on network drives).  Moreover, being a simulated problem,
> very little data is read/written to drives during the process.
> 
> Anyone have ideas as to why the Windows machine is so slow?
> 
> Thanks in advance.
> 
> Michaell Taylor
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tord.snall at ebc.uu.se  Tue Sep  9 15:38:32 2003
From: tord.snall at ebc.uu.se (Tord Snall)
Date: Tue, 09 Sep 2003 15:38:32 +0200
Subject: [R] tree mortality risk model using glm()
Message-ID: <3.0.6.32.20030909153832.00f6f660@mail.anst.uu.se>

Dear all,

I've used glm(family=binomial(link="logit")) several times, but now I think
that a log link is more appropriate. 

I want to fit a model for probability of tree fall (TF)), with tree
diameter (dbh) and soil moisure (soil) as predictors. A large number of
trees have been checked every second year whether they stand up (0) or have
fallen (1).

I assume that the tree fall probability is predicted by

TF = 1 - exp(-(dbh + soil))
log(1 - TF) = -(dbh + soil)

I thought the following call would fit the model, but I get an error message.
test<- glm(1-TF ~ dbh +soil , data = extdat, family = quasibinomial(link =
"log"))
Error: no valid set of coefficients has been found:please supply starting
values
In addition: Warning message: 
NaNs produced in: log(x) 

Could someone give a clue on what is wrong. Is there another way to fit
this model? 

People have asked about exponential models before but they have dealt with
continuous responses.


Thanks in advance!

Yours sincerely,
Tord



-----------------------------------------------------------------------
Tord Sn?ll
Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
Villav?gen 14			
SE-752 36 Uppsala, Sweden
Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
E-mail: Tord.Snall at ebc.uu.se
Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!



From deepayan at stat.wisc.edu  Tue Sep  9 15:33:31 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 9 Sep 2003 08:33:31 -0500
Subject: [R] lattice.xyplot: adding grid lines
In-Reply-To: <770E451830D96B4D84747B54665DA1B202DAF0DC@jena03.net.j.ad.intershop.net>
References: <770E451830D96B4D84747B54665DA1B202DAF0DC@jena03.net.j.ad.intershop.net>
Message-ID: <200309090833.31481.deepayan@stat.wisc.edu>


Sorry, that's what you get when you don't run your code before sending it. 
Should be panel.superpose instead of panel.xyplot, since you want a grouped 
display. e.g.,

xyplot(Sepal.Length + Sepal.Width ~ Petal.Length ,
       data = iris, allow.multiple = TRUE, scales = "same",type="l",
       panel = function(...) {
           panel.grid(h=2, v= 3, col="blue")
           panel.superpose(...)
       }
)

Deepayan


On Tuesday 09 September 2003 08:19, Marc Mamin wrote:
> Hallo, thank you for your answer,
>
> there is still one problem in your solution:
>
> Sepal.Length + Sepal.Width are considerd as a single serie of data...
>
> Marc Mamin



From pgilbert at bank-banque-canada.ca  Tue Sep  9 16:12:55 2003
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Tue, 09 Sep 2003 10:12:55 -0400
Subject: [R] How to convert a Rd file into multi html files?
In-Reply-To: <20030909111726.30352.qmail@web21210.mail.yahoo.com>
References: <20030909111726.30352.qmail@web21210.mail.yahoo.com>
Message-ID: <3F5DDFE7.6060502@bank-banque-canada.ca>

The R packaging programs expect one .Rd file for each function, all in 
the man directory. Installing the package converts each .Rd file into an 
html file as well as other documentation formats.

There was once some discussion of allowing multiple functions to be 
documented in a single file, but I believe that has never been done. 
Maintaining a number of packages I find it somewhat inconvenient to deal 
with the very large number of source files this system implies, so I 
have another directory I call mansrc, which does not get included in 
packages. This directory has one file I call  whatever.help, where 
"whatever"  corresponds to  a code file R/whatever.R that contains code 
for multiple functions. I then process this through a perl script to 
produce man/*.Rd files that are included in packages.  I would be happy 
to supply the perl script, but it sounds like you have already written 
your own. I doubt that my system is worth the extra complexity unless 
you are documenting a large number of functions.

Paul Gilbert

Yiming Zhou wrote:

>Hi,
>I wrote all documents for each objects in my package in one .Rd file. Now I can't convert the .Rd file into multi html files such that a html file corresponds a object in package. 
>The command I used was ' R CMD Rdconv -t html foo.Rd'. It just converted the document of first object in .Rd into html format.
> 
>I had to write a perl script to satisfy myself. But is there a more direct and simple way to do it?
> 
>Thank you very much.
> 
>your sincerely,
> 
>Yiming Zhou
>  
>



From ernesto at ipimar.pt  Tue Sep  9 16:36:35 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Tue, 09 Sep 2003 15:36:35 +0100
Subject: [R] ploting 2 variables in a lattice xyplot
Message-ID: <1063118194.3177.27.camel@gandalf.local>

Hi,

I want to plot 2 variables (confidence intervals) in a single xyplot. I
have a dataframe with variables Yup, Ylo, X and Z and I want to have a
xyplot with both variables ploted. I'm trying with 

xyplot(Yup~X|Z, panel=function(x){...})

but this way I'm not able to pass variable Ylo into the function...

How can I do this ?

Thanks

EJ



From mmiller3 at iupui.edu  Tue Sep  9 17:01:58 2003
From: mmiller3 at iupui.edu (Michael A. Miller)
Date: Tue, 09 Sep 2003 10:01:58 -0500
Subject: [R] How do I coerce numeric factor columns of data frame to
	vector?
In-Reply-To: <Pine.SOL.4.44.0309081913500.19004-100000@tetris.gpcc.itd.umich.edu>
	(Thomas
	W. Blackwell's message of "Mon, 8 Sep 2003 19:22:04 -0400 (EDT)")
References: <Pine.SOL.4.44.0309081913500.19004-100000@tetris.gpcc.itd.umich.edu>
Message-ID: <87vfs22eft.fsf@lumen.indyrad.iupui.edu>

>>>>> "Thomas" == Thomas W Blackwell <tblackw at umich.edu> writes:

    > Michael - Because these columns are factors to begin with,
    > using as.numeric() alone will have unexpected results.  See
    > the section "Warning:" in help("factor").

Ah, thanks for pointing that out.  When I've used as.numeric on
factors, it is usually because I've explicitly made a numeric
variable a factor.  I can see where something that I think aught
to be numeric would be interpreted as a factor, say due to an
error in formatting an input file.  If I do something like this:

x <- some numeric array
f <- factor(x)
y <- as.numeric(x)

is there a possibility of y not equalling x?  If x really is
numeric that is.

Regards, Mike

-- 
Michael A. Miller                               mmiller3 at iupui.edu
  Imaging Sciences, Department of Radiology, IU School of Medicine



From Giles.Heywood at CommerzbankIB.com  Tue Sep  9 17:06:52 2003
From: Giles.Heywood at CommerzbankIB.com (Heywood, Giles)
Date: Tue, 9 Sep 2003 16:06:52 +0100 
Subject: [R] Changing Tick Marks for Date Plots
Message-ID: <8CBAA121CEB4D5118CB200508BB2BBEF54049D@xmx8lonib.lonib.commerzbank.com>

The way to control number of tickmarks in plot is via par(lab)

par(lab=c(5,5,7)) #the default
plot(rnorm(20),rnorm(20))
par(lab=3*c(5,5,7))
plot(rnorm(20),rnorm(20))

However this does not work for axis.POSIXct, which the function
called by the plot method for 'its'.  I am not sure why this is.

The parameter that controls the location of tickmarks and labels
in axis.POSIXct is 'at'.  You could use this, thus:

plot(x$dates,x$values,type="l",xaxt = "n")
axis.POSIXct(x = x$dates, side = 1,
at=x$dates[seq(1,500,100)],format="%b-%Y")

At present, the plot method for 'its' class does not pass the 'at'
parameter through to axis.POSIXct.  It could, and probably will, 
in the next version.  You could easily do the fix.

Giles

> -----Original Message-----
> From: Sean Carmody [mailto:seancarmody at yahoo.com]
> Sent: 09 September 2003 14:26
> To: r-help at stat.math.ethz.ch
> Subject: [R] Changing Tick Marks for Date Plots
> 
> 
> I have been experimenting with various approaches to
> plotting (irregular) time-series with reasonable
> success. One thing I have been able to do is change
> the number of tick marks on the axis. Consider the
> following simple example:
> 
> > x <- as.data.frame(matrix(ncol=2,nrow=500))
> > names(x) <- c("dates","values")
> > x$dates <- as.POSIXct(Sys.time()+1:500*86400)
> > x$values <- cumsum(rnorm(500))))
> > plot(x$dates,x$values,type="l")
> 
> The resulting plot only has two tick-marks: 2004 and
> 2005 (depending on today's date!). I have the same
> problem when I use the "its" library:
> 
> > library(its)
> > plot(as.its(x),format="%b-%Y")
> 
> Any suggestions would be greatly appreciated.
> 
> Regards,
> Sean.
> 
> 
> 
> http://search.yahoo.com.au - Yahoo! Search
> - Looking for more? Try the new Yahoo! Search
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


********************************************************************** 
This is a commercial communication from Commerzbank AG.\ \ T...{{dropped}}



From solares at unsl.edu.ar  Tue Sep  9 17:10:06 2003
From: solares at unsl.edu.ar (solares@unsl.edu.ar)
Date: Tue, 9 Sep 2003 12:10:06 -0300 (ART)
Subject: [R] charge a vector with variables and to use as variable in a
	checkbutton?
Message-ID: <54559.170.210.173.216.1063120206.squirrel@inter14.unsl.edu.ar>

hello, how i cant to charge in form dynamic a checkbutton, try to do it 
with a vector be charged automaticamente but not
works, for example

library(tcltk)
tt<-tktoplevel()
f<-tkframe(tt)
tkpack(f)
i<-2
if (i==1) {b1<-tkcheckbutton
(f,text="b1",variable="b1",relief="raised");tkpack(b1);print(tclvalue
("b1"))}else if (i==2) {b1<-tkcheckbutton
(f,text="b1",variable="b1",relief="raised");tkpack(b1);print(tclvalue
("b1"));b2<-tkcheckbutton(f,text="b2",variable="b2",relief="raised");tkpack
(b2);print(tclvalue("b2"))}else if (i==3) {b1<-tkcheckbutton
(f,text="b1",variable="b1",relief="raised");tkpack(b1);print(tclvalue
("b1"));b2<-tkcheckbutton(f,text="b2",variable="b2",relief="raised");tkpack
(b2);print(tclvalue("b2"));b3<-tkcheckbutton
(f,text="b3",variable="b3",relief="raised");tkpack(b3);print(tclvalue
("b3"))}

i<-3
switch(i,{b1<-tkcheckbutton
(f,text="b1",variable="b1",relief="raised");tkpack(b1)},
{b1<-tkcheckbutton(f,text="b1",variable="b1",relief="raised");tkpack
(b1);b2<-tkcheckbutton(f,text="b2",variable="b2",relief="raised");tkpack
(b2)},
{b1<-tkcheckbutton(f,text="b1",variable="b1",relief="raised");tkpack
(b1);b2<-tkcheckbutton(f,text="b2",variable="b2",relief="raised");tkpack
(b2);;b3<-tkcheckbutton(f,text="b3",variable="b3",relief="raised");tkpack
(b3)})

as seeing I should charge in form estatic each checkbutton at to say the 
value "i" because I cannot do somewhere as:
b1<-0;b2<-0;b3<-0
b<-c(b1,b2,b3) #vector b contain three variables
j<-3;i<-1
while (i<=j){ 
 b[i]<-tkcheckbutton(f,text="b[i]",variable="b[i]",relief="raised")
#how b[i] is the same "variable" all the time for checkbutton
 tkpack(b[i])
 i<-i+1
}

Thanks Ruben



From nali at biostat.umn.edu  Tue Sep  9 17:15:22 2003
From: nali at biostat.umn.edu (Na Li)
Date: Tue, 09 Sep 2003 10:15:22 -0500
Subject: [R] How do I coerce numeric factor columns of data frame to
	vector?
In-Reply-To: <87vfs22eft.fsf@lumen.indyrad.iupui.edu> (Michael A. Miller's
	message of "Tue, 09 Sep 2003 10:01:58 -0500")
References: <Pine.SOL.4.44.0309081913500.19004-100000@tetris.gpcc.itd.umich.edu>
	<87vfs22eft.fsf@lumen.indyrad.iupui.edu>
Message-ID: <kofzj6uh6d.fsf@qiuranke.phony.umn.edu>

On 9 Sep 2003, Michael A. Miller outgrape:

> > > > > >  "Thomas" == Thomas W Blackwell <tblackw at umich.edu> writes:
>  
> >  Michael - Because these columns are factors to begin with,
> >  using as.numeric() alone will have unexpected results.  See
> >  the section "Warning:" in help("factor").
>  
>  Ah, thanks for pointing that out.  When I've used as.numeric on
>  factors, it is usually because I've explicitly made a numeric
>  variable a factor.  I can see where something that I think aught
>  to be numeric would be interpreted as a factor, say due to an
>  error in formatting an input file.  If I do something like this:
>  
>  x <- some numeric array
>  f <- factor(x)
>  y <- as.numeric(x)
>  
>  is there a possibility of y not equalling x?  If x really is
>  numeric that is.

> x <- c(1, 3, 1)
> y <- factor (x)
> y
[1] 1 3 1
Levels: 1 3
> as.numeric (y)
[1] 1 2 1

I don't know a good way to convert it back however, except 

> as.numeric (levels (y)[as.numeric (y)])
[1] 1 3 1

which is a bit awkward.

Michael



From tlumley at u.washington.edu  Tue Sep  9 17:31:44 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 9 Sep 2003 08:31:44 -0700 (PDT)
Subject: [R] tree mortality risk model using glm()
In-Reply-To: <3.0.6.32.20030909153832.00f6f660@mail.anst.uu.se>
Message-ID: <Pine.A41.4.44.0309090824180.197476-100000@homer07.u.washington.edu>

On Tue, 9 Sep 2003, Tord Snall wrote:

> Dear all,
>
> I've used glm(family=binomial(link="logit")) several times, but now I think
> that a log link is more appropriate.
>
> I want to fit a model for probability of tree fall (TF)), with tree
> diameter (dbh) and soil moisure (soil) as predictors. A large number of
> trees have been checked every second year whether they stand up (0) or have
> fallen (1).
>
> I assume that the tree fall probability is predicted by
>
> TF = 1 - exp(-(dbh + soil))
> log(1 - TF) = -(dbh + soil)
>
> I thought the following call would fit the model, but I get an error message.
> test<- glm(1-TF ~ dbh +soil , data = extdat, family = quasibinomial(link =
> "log"))
> Error: no valid set of coefficients has been found:please supply starting
> values
> In addition: Warning message:
> NaNs produced in: log(x)

Although glm() usually doesn't need starting values, it can run into
problems when you have a restricted parameter space as you do here.  You
may need to supply starting values, as the error message suggests.

	-thomas



From bates at stat.wisc.edu  Tue Sep  9 17:35:18 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 09 Sep 2003 15:35:18 -0000
Subject: [R] ploting 2 variables in a lattice xyplot
In-Reply-To: <1063118194.3177.27.camel@gandalf.local>
References: <1063118194.3177.27.camel@gandalf.local>
Message-ID: <6rbrtuj7ol.fsf@bates4.stat.wisc.edu>

Ernesto Jardim <ernesto at ipimar.pt> writes:

> Hi,
> 
> I want to plot 2 variables (confidence intervals) in a single xyplot. I
> have a dataframe with variables Yup, Ylo, X and Z and I want to have a
> xyplot with both variables ploted. I'm trying with 
> 
> xyplot(Yup~X|Z, panel=function(x){...})
> 
> but this way I'm not able to pass variable Ylo into the function...
> 
> How can I do this ?

According to the "formula" description on the manual page for xyplot
you can use

xyplot(Ylo+Yup~X|Z, allow.multiple=TRUE)

Did you try that?



From maechler at stat.math.ethz.ch  Tue Sep  9 17:37:22 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 9 Sep 2003 17:37:22 +0200
Subject: [R] How do I coerce numeric factor columns of data frame to
	vector?
In-Reply-To: <kofzj6uh6d.fsf@qiuranke.phony.umn.edu>
References: <Pine.SOL.4.44.0309081913500.19004-100000@tetris.gpcc.itd.umich.edu>
	<87vfs22eft.fsf@lumen.indyrad.iupui.edu>
	<kofzj6uh6d.fsf@qiuranke.phony.umn.edu>
Message-ID: <16221.62386.563593.295649@gargle.gargle.HOWL>

>>>>> "NaLi" == Na Li <nali at biostat.umn.edu>
>>>>>     on Tue, 09 Sep 2003 10:15:22 -0500 writes:

    NaLi> On 9 Sep 2003, Michael A. Miller outgrape:
    >> > > > > >  "Thomas" == Thomas W Blackwell <tblackw at umich.edu> writes:
    >> 
    >> >  Michael - Because these columns are factors to begin with,
    >> >  using as.numeric() alone will have unexpected results.  See
    >> >  the section "Warning:" in help("factor").
    >> 
    >> Ah, thanks for pointing that out.  When I've used as.numeric on
    >> factors, it is usually because I've explicitly made a numeric
    >> variable a factor.  I can see where something that I think aught
    >> to be numeric would be interpreted as a factor, say due to an
    >> error in formatting an input file.  If I do something like this:
    >> 
    >> x <- some numeric array
    >> f <- factor(x)
    >> y <- as.numeric(x)
    >> 
    >> is there a possibility of y not equalling x?  If x really is
    >> numeric that is.

    >> x <- c(1, 3, 1)
    >> y <- factor (x)
    >> y
    NaLi> [1] 1 3 1
    NaLi> Levels: 1 3
    >> as.numeric (y)
    NaLi> [1] 1 2 1

    NaLi> I don't know a good way to convert it back however, 

this is almost a FAQ,
but I'm astonished that the answer isn't even in  help(factor).
I'll put it there for R 1.8.0

    NaLi> except

    >> as.numeric (levels (y)[as.numeric (y)])
    NaLi> [1] 1 3 1

    NaLi> which is a bit awkward.

    NaLi> Michael

as.numeric(as.character(y)) !

{in some cases you might consider using as.integer() instead of as.numeric()}



From tlumley at u.washington.edu  Tue Sep  9 17:37:45 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 9 Sep 2003 08:37:45 -0700 (PDT)
Subject: [R] Stifling REprintf() output
In-Reply-To: <Pine.SOL.4.20.0309081246400.6125-100000@santiam.dfci.harvard.edu>
Message-ID: <Pine.A41.4.44.0309090833470.197476-100000@homer07.u.washington.edu>

On Mon, 8 Sep 2003, Jeff Gentry wrote:

>
> In some code that I have written, use of url() is generating the output
> line:
> "cannot open: HTTP status was `404 Not Found`"
>

My fault.  This used to use error(), but as you will recall, the result
was that the connection wasn't freed and getBioC() leaked a lot of
connections.

Presumably it should test for options(internet.info) before printing. I'll
have a look when I get back to Seattle.

	-thomas



From edd at debian.org  Tue Sep  9 17:44:20 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 9 Sep 2003 10:44:20 -0500
Subject: [R] charge a vector with variables and to use as variable in a
	checkbutton?
In-Reply-To: <54559.170.210.173.216.1063120206.squirrel@inter14.unsl.edu.ar>
References: <54559.170.210.173.216.1063120206.squirrel@inter14.unsl.edu.ar>
Message-ID: <20030909154420.GA9052@sonny.eddelbuettel.com>

On Tue, Sep 09, 2003 at 12:10:06PM -0300, solares at unsl.edu.ar wrote:
> hello, how i cant to charge in form dynamic a checkbutton, try to do it 
> with a vector be charged automaticamente but not
> works, for example
[...]
> while (i<=j){ 
>  b[i]<-tkcheckbutton(f,text="b[i]",variable="b[i]",relief="raised")
> #how b[i] is the same "variable" all the time for checkbutton
>  tkpack(b[i])
>  i<-i+1
> }

You may want to re-read some of the available code examples. What you did is
fundamentally broken -- you do not pass strings with variables names inside.

You need to define some variables via the tclVar() function, and you can
access the values of those variables in non-tcltk expressions with tclvalue().

What you want it probably close to this -- it uses menubuttons rather than
checkbuttons but is the closest example I had hanging around here:


    color <- tclVar("blue")
    long.color <- tclVar(paste("Status is", tclvalue(color)))
    for (i in c("red", "green", "blue"))
      tkadd(m, "radio", label=i, variable=color, value=i,
            command=function(){
              cat("Background is", tclvalue(color), "\n")
              tclvalue(long.color) <- paste("Status is", tclvalue(color))
            })
			  
Hth, Dirk

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From Sean.Davis at dcb.cit.nih.gov  Tue Sep  9 18:13:10 2003
From: Sean.Davis at dcb.cit.nih.gov (Sean Davis)
Date: Tue, 9 Sep 2003 12:13:10 -0400 (EDT)
Subject: [R] Building XML package for MacOS X
In-Reply-To: <Pine.LNX.4.44.0309091426570.23724-100000@gannet.stats>
References: <Pine.LNX.4.44.0309091426570.23724-100000@gannet.stats>
Message-ID: <Pine.GSO.4.50.0309091210520.3952-100000@argo.cit.nih.gov>

I know this is not entirely on-topic, but assuming that several users
have had to do this, could someone give me some specifics?  If it is
off-topic, feel free to reply directly rather than to the group.

Thanks

> The simplest way is probably to edit the libxml2 library and remove
> the module containing xmlParserError.  That's what the Windows maintainer
> has to do.
>
> On Tue, 9 Sep 2003, Sean Davis wrote:
>
> > I am working to build the XML package for R on MacOS X.  I have installed
> > libxml2-2.5.9 into /usr/local.  I set the
> > LIBXML_INCDIR=/usr/local/include/libxml2.  I use R INSTALL, I get the
> > following:
> >
> > R INSTALL -c -l /usr/local/R/library XML_0.94-1.tar.gz
> >   :
> >   :
> >   :
> > gcc -bundle -flat_namespace -undefined suppress -L/sw/lib -L/usr/local/lib
> > -o XML.so DocParse.o EventParse.o ExpatParse.o HTMLParse.o RSDTD.o
> > RUtils.o Utils.o XMLEventParse.o XMLTree.o -lz  -lxml2
> > ld: multiple definitions of symbol _xmlParserError
> > Utils.o definition of _xmlParserError in section (__TEXT,__text)
> > /usr/local/lib/libxml2.dylib(libxml2.2.5.9.dylib-master.o) definition of
> > _xmlParserError
> > make: *** [XML.so] Error 1
> > ERROR: compilation failed for package 'XML'
> >
> > How can I fix the problem?  I have tried compiling straight source that
> > has other problems.  I think that I need to modify the "makefile" to let
> > the compiler to use only the first definition of _xmlParserError, but I
> > don't know how to do this when using R INSTALL.
> >
> > Thanks,
> > Sean
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> >
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From jortiz at kent.edu  Tue Sep  9 18:13:37 2003
From: jortiz at kent.edu (Joseph Ortiz)
Date: Tue, 9 Sep 2003 12:13:37 -0400
Subject: [R] Cross-platform compatibility with R?
Message-ID: <9182C431-E2E0-11D7-8269-000A95840136@kent.edu>

Dear All,

I'm a newbie to R having just switched from S-Plus.

I was able to port my files from S-Plus for Linux to R for OSX using 
the S-Plus "data.dump", and the R "data.restore" commands. I've decided 
that I like R enough to install it on my Linux box, but I can't figure 
out an easy way to get multiple files from my OSX macintosh R 
environment to a Linux install of R, as there does not appear to be a 
"data.dump" command in R.

I tried to use tar to archive my directories and binary .Rdata files 
and simply extract them to a new machine. This works fine going from 
one OSX machine to another, but does not work going from OSX to Linux, 
presumably due to binary file or directory incompatibilities.

Does anyone have any suggestions for a work around to this problem?

Thanks,
Joe
______________________________________________

Dr. Joseph D. Ortiz
Assistant Professor - Geology
Kent State University
336 McGilvrey Hall
P.O. Box 5190
Kent, OH 44242-0001
Phone: 330-672-2225
FAX: 330-672-7949
email: jortiz at kent.edu
Web: http://www.personal.kent.edu/~jortiz/home/



From p.dalgaard at biostat.ku.dk  Tue Sep  9 18:16:50 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Tue, 09 Sep 2003 16:16:50 -0000
Subject: [R] How do I coerce numeric factor columns of data frame to
	vector?
In-Reply-To: <16221.62386.563593.295649@gargle.gargle.HOWL>
References: <Pine.SOL.4.44.0309081913500.19004-100000@tetris.gpcc.itd.umich.edu>
	<87vfs22eft.fsf@lumen.indyrad.iupui.edu>
	<kofzj6uh6d.fsf@qiuranke.phony.umn.edu>
	<16221.62386.563593.295649@gargle.gargle.HOWL>
Message-ID: <x2r82qj5qx.fsf@biostat.ku.dk>

Martin Maechler <maechler at stat.math.ethz.ch> writes:

>     >> as.numeric (levels (y)[as.numeric (y)])
>     NaLi> [1] 1 3 1
> 
>     NaLi> which is a bit awkward.

> as.numeric(as.character(y)) !
> 
> {in some cases you might consider using as.integer() instead of as.numeric()}

Better to convert first and then index:

as.numeric(levels(y))[y] 

The speed gain is only going to be visible on huge vectors, though.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From gattuso at obs-vlfr.fr  Tue Sep  9 18:25:22 2003
From: gattuso at obs-vlfr.fr (Gattuso, Jean-Pierre)
Date: Tue, 9 Sep 2003 18:25:22 +0200
Subject: [R] Making R packages (Unix)
Message-ID: <p0600202bbb83abff6f40@[193.49.112.222]>

Hi:

I have have taken over from a colleague who 
prepared an R package and failed to build it on 
Windows. I am doing this with unix as I am a mac 
user. Below is the output I get when I use the 
build command:

[gattuso:unix/R/CO2.Rcheck] gattuso% R CMD build CO2
* checking for file 'CO2/DESCRIPTION' ... OK
* preparing 'CO2':
* checking whether 'INDEX' is up-to-date ... NO
* use '--force' to overwrite the existing 'INDEX'
* removing junk files
* building 'CO2_1.0.tar.gz'
tar: Unable to access 
/Users/gattuso/documents/unix/R/CO2.Rcheck/CO2_1.0.tar 
<No such file or directory>
tar: WARNING! These file names were not selected:
/Users/gattuso/documents/unix/R/CO2.Rcheck/CO2_1.0.tar
CO2_1.0.tar: No such file or directory


I have read the R-exts.pdf document but did not 
find what I do wrong. In fact, there is little 
information on the use of R CMD build, both in 
the R-exts.pdf document and the man (R CMD build 
--help) pages.

Do I need to make the CO2_1.0.tar file myself?

Your help would be much appreciated!

jp
-- 

Jean-Pierre Gattuso | mailto:gattuso at obs-vlfr.fr 
| http://www.obs-vlfr.fr/~gattuso



From ligges at statistik.uni-dortmund.de  Tue Sep  9 18:28:43 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 09 Sep 2003 18:28:43 +0200
Subject: [R] Cross-platform compatibility with R?
In-Reply-To: <9182C431-E2E0-11D7-8269-000A95840136@kent.edu>
References: <9182C431-E2E0-11D7-8269-000A95840136@kent.edu>
Message-ID: <3F5DFFBB.20908@statistik.uni-dortmund.de>

Joseph Ortiz wrote:

> Dear All,
> 
> I'm a newbie to R having just switched from S-Plus.
> 
> I was able to port my files from S-Plus for Linux to R for OSX using the 
> S-Plus "data.dump", and the R "data.restore" commands. I've decided that 
> I like R enough to install it on my Linux box, but I can't figure out an 
> easy way to get multiple files from my OSX macintosh R environment to a 
> Linux install of R, as there does not appear to be a "data.dump" command 
> in R.
> 
> I tried to use tar to archive my directories and binary .Rdata files and 
> simply extract them to a new machine. This works fine going from one OSX 
> machine to another, but does not work going from OSX to Linux, 
> presumably due to binary file or directory incompatibilities.
> 
> Does anyone have any suggestions for a work around to this problem?
> 
> Thanks,
> Joe
> ______________________________________________
> 
> Dr. Joseph D. Ortiz
> Assistant Professor - Geology
> Kent State University
> 336 McGilvrey Hall
> P.O. Box 5190
> Kent, OH 44242-0001
> Phone: 330-672-2225
> FAX: 330-672-7949
> email: jortiz at kent.edu
> Web: http://www.personal.kent.edu/~jortiz/home/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


See ?dump and ?save, the latter has an argument ASCII for portability 
reasons.

Uwe Ligges



From p.dalgaard at biostat.ku.dk  Tue Sep  9 18:31:13 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Tue, 09 Sep 2003 16:31:13 -0000
Subject: [R] Cross-platform compatibility with R?
In-Reply-To: <9182C431-E2E0-11D7-8269-000A95840136@kent.edu>
References: <9182C431-E2E0-11D7-8269-000A95840136@kent.edu>
Message-ID: <x2n0ddkjl1.fsf@biostat.ku.dk>

Joseph Ortiz <jortiz at kent.edu> writes:

> I tried to use tar to archive my directories and binary .Rdata files
> and simply extract them to a new machine. This works fine going from
> one OSX machine to another, but does not work going from OSX to Linux,
> presumably due to binary file or directory incompatibilities.
> 
> Does anyone have any suggestions for a work around to this problem?

It should work to move .Rdata files (the format is platform
independent), just watch out that the R versions are compatible (or
read the documentation for save() to see how to generate
back-compatible files).

This could be a bug, but what are the precise symptoms then?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From bates at stat.wisc.edu  Tue Sep  9 18:33:30 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 09 Sep 2003 16:33:30 -0000
Subject: [R] Cross-platform compatibility with R?
In-Reply-To: <9182C431-E2E0-11D7-8269-000A95840136@kent.edu>
References: <9182C431-E2E0-11D7-8269-000A95840136@kent.edu>
Message-ID: <6rd6e9j4zf.fsf@bates4.stat.wisc.edu>

Joseph Ortiz <jortiz at kent.edu> writes:

> Dear All,
> 
> I'm a newbie to R having just switched from S-Plus.
> 
> I was able to port my files from S-Plus for Linux to R for OSX using
> the S-Plus "data.dump", and the R "data.restore" commands. I've
> decided that I like R enough to install it on my Linux box, but I
> can't figure out an easy way to get multiple files from my OSX
> macintosh R environment to a Linux install of R, as there does not
> appear to be a "data.dump" command in R.
> 
> 
> I tried to use tar to archive my directories and binary .Rdata files
> and simply extract them to a new machine. This works fine going from
> one OSX machine to another, but does not work going from OSX to Linux,
> presumably due to binary file or directory incompatibilities.
> 
> 
> Does anyone have any suggestions for a work around to this problem?

Use save and load. Files generated by save() can be read by load()
on any platform.



From ernesto at ipimar.pt  Tue Sep  9 18:50:19 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Tue, 09 Sep 2003 17:50:19 +0100
Subject: [R] ploting 2 variables in a lattice xyplot
In-Reply-To: <6rbrtuj7ol.fsf@bates4.stat.wisc.edu>
References: <1063118194.3177.27.camel@gandalf.local>
	<6rbrtuj7ol.fsf@bates4.stat.wisc.edu>
Message-ID: <1063126218.3177.30.camel@gandalf.local>

On Tue, 2003-09-09 at 16:35, Douglas Bates wrote:
> Ernesto Jardim <ernesto at ipimar.pt> writes:
> 
> > Hi,
> > 
> > I want to plot 2 variables (confidence intervals) in a single xyplot. I
> > have a dataframe with variables Yup, Ylo, X and Z and I want to have a
> > xyplot with both variables ploted. I'm trying with 
> > 
> > xyplot(Yup~X|Z, panel=function(x){...})
> > 
> > but this way I'm not able to pass variable Ylo into the function...
> > 
> > How can I do this ?
> 
> According to the "formula" description on the manual page for xyplot
> you can use
> 
> xyplot(Ylo+Yup~X|Z, allow.multiple=TRUE)
> 
> Did you try that?

No, I allways forget formula as two sides :)

I'll try it.

Thanks 

EJ



From arrayprofile at yahoo.com  Tue Sep  9 19:03:56 2003
From: arrayprofile at yahoo.com (array chip)
Date: Tue, 9 Sep 2003 10:03:56 -0700 (PDT)
Subject: [R] memory problem in exporting data frame
In-Reply-To: <003501c376a6$5a16d3c0$e502eb82@maths.lth.se>
Message-ID: <20030909170356.85918.qmail@web41202.mail.yahoo.com>

Hi all,

Thanks for all the suggestions. I was able to get the
data frame out by first deleting some other large
objects in the directory, and then changing the data
frame into matrix by as.matrix(), splitting the matrix
into 4 blocks and finally using write.table() to write
the matrix into 4 files to be combined later.

Thanks again

--- Henrik Bengtsson <hb at maths.lth.se> wrote:
> Hi, I replied to a related question yesterday (Mon
> Sept 8, 2003) with
> subject "RE: [R] cannot allocate vector of size...".
> That was as also
> about running low of memory, but about *reading*
> data from file and not
> writing. However, the problem is likely to be due to
> the same thing.
> 
> You pass a large object to a function via an
> argument, an argument which
> is then changed inside the function (in your case
> write.table() is doing
> x <- as.matrix(x)). As long as the argument is only
> read, R is clever
> not to create a copy of it (pass by reference if
> read-only), but as soon
> as you change it, it is creating a local copy of it
> (pass by value).
> Hence, now you have your original 'xxx' object plus
> a local copy
> "inside" the function. This is likely to be your
> problem. 
> 
> You can do the work around that Patrick Burns
> suggest and improve it
> slightly, if can you do not need the 'xxx' variable
> anymore, you can do
> 'xxx <- as.matrix(xxx)'. A better approach, as you
> suggest yourself,
> except from doing it row by row, is to write your
> dataframe block by
> block with a reasonable block size. This can of
> course be done using a
> for loop and write.table(), but you will do better
> if you look at the
> code in write.table() and avoid the doing the same
> overhead work in each
> step.
> 
> Finally and FYI, you might be able to shrink your
> original data frame by
> considering the following
> 
> i <- as.integer(1:1000)
> d <- as.double(i)
> df1 <- data.frame(i=i, d=d)
> df2 <- data.frame(i=i, d=i)
> object.size(df1)  # 24392 bytes
> object.size(df2)  # 20392 bytes
> 
> However, note that when doing x <- as.matrix(x) (as
> write.table() does),
> will coerce the data into *one* data type (because
> it is a matrix). In
> other words, the only thing you will gain is a
> smaller 'xxx' object.
> 
> Best wishes
> 
> Henrik Bengtsson
> Lund University
> 
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch 
> > [mailto:r-help-bounces at stat.math.ethz.ch] On
> Behalf Of Thomas 
> > W Blackwell
> > Sent: den 9 september 2003 01:28
> > To: array chip
> > Cc: r-help at stat.math.ethz.ch
> > Subject: Re: [R] memory problem in exporting data
> frame
> > 
> > 
> > 
> > Simplest is to save your workspace using 
> save.image(),
> > then delete a bunch of large objects other than
> the data
> > frame that you want to export, and run 
> write.table()
> > again, now that you've made space for it.  A quick
> calc
> > shows  17000 x 400 x 8 = 55 Mb, and that's just
> the size
> > of the object that chokes R below.
> > 
> > -  tom blackwell  -  u michigan medical school  - 
> ann arbor  -
> > 
> > On Mon, 8 Sep 2003, array chip wrote:
> > 
> > > I am having trouble of exporting a large data
> frame
> > > out of R to be used in other purpose. The data
> frame
> > > is numeric with size 17000x400. It takes a quite
> some
> > > time to start R as well. my computer has 1GB
> RAM. I
> > > used the following command to write the data
> frame to
> > > a text file and got the error message below:
> > >
> > > > write.table(xxx, "C:\\xxx", sep="\t",
> > > row.names=FALSE,col.names=FALSE,quote=FALSE)
> > >
> > > Error: cannot allocate vector of size 55750 Kb
> > > In addition: Warning message:
> > > Reached total allocation of 1023Mb: see
> > > help(memory.size)
> > >
> > > I tried to increase the memory size by
> > > memory.size(size=), but it seems running the
> above
> > > command takes forever.
> > >
> > > what can I do with this error message to get the
> data
> > > out?
> > >
> > > Thanks
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list 
> > https://www.stat.math.ethz.ch/mailman/listinfo>
> /r-help
> > 
> > 
>



From p.dalgaard at biostat.ku.dk  Tue Sep  9 19:14:33 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Tue, 09 Sep 2003 17:14:33 -0000
Subject: [R] memory problem in exporting data frame
In-Reply-To: <20030909170356.85918.qmail@web41202.mail.yahoo.com>
References: <20030909170356.85918.qmail@web41202.mail.yahoo.com>
Message-ID: <x2iso1khku.fsf@biostat.ku.dk>

array chip <arrayprofile at yahoo.com> writes:

> Hi all,
> 
> Thanks for all the suggestions. I was able to get the
> data frame out by first deleting some other large
> objects in the directory, and then changing the data
> frame into matrix by as.matrix(), splitting the matrix
> into 4 blocks and finally using write.table() to write
> the matrix into 4 files to be combined later.

A bit late, but also note that it is possible to write out a single
large object with save() and then read it into a "clean" R session for
postprocessing. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From pgilbert at bank-banque-canada.ca  Tue Sep  9 19:19:10 2003
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Tue, 09 Sep 2003 13:19:10 -0400
Subject: [R] How to convert a Rd file into multi html files?
In-Reply-To: <3F5DDFE7.6060502@bank-banque-canada.ca>
References: <20030909111726.30352.qmail@web21210.mail.yahoo.com>
	<3F5DDFE7.6060502@bank-banque-canada.ca>
Message-ID: <3F5E0B8E.8070909@bank-banque-canada.ca>

Paul Gilbert wrote:

> The R packaging programs expect one .Rd file for each function, ...

Sorry, this was not exactly correct. It expects one .Rd file for each 
documentation item (man page) indicated by \name{}, but that can 
document more than one function.

Paul Gilbert



From mmiller3 at iupui.edu  Tue Sep  9 19:25:46 2003
From: mmiller3 at iupui.edu (Michael A. Miller)
Date: Tue, 09 Sep 2003 12:25:46 -0500
Subject: [R] How do I coerce numeric factor columns of data frame to
	vector?
In-Reply-To: <kofzj6uh6d.fsf@qiuranke.phony.umn.edu> (Na Li's message of
	"Tue, 09 Sep 2003 10:15:22 -0500")
References: <Pine.SOL.4.44.0309081913500.19004-100000@tetris.gpcc.itd.umich.edu>
	<87vfs22eft.fsf@lumen.indyrad.iupui.edu>
	<kofzj6uh6d.fsf@qiuranke.phony.umn.edu>
Message-ID: <87k78h3mcl.fsf@lumen.indyrad.iupui.edu>

>>>>> "Na" == Na Li <nali at biostat.umn.edu> writes:

    > x <- c(1, 3, 1) 
    > y <- factor (x) 
    > y
    > [1] 1 3 1 
    > Levels: 1 3
    > as.numeric (y)
    > [1] 1 2 1

Ah, now I get it - thanks!

Mike



From deepayan at stat.wisc.edu  Tue Sep  9 19:58:32 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 9 Sep 2003 12:58:32 -0500
Subject: [R] ploting 2 variables in a lattice xyplot
In-Reply-To: <6rbrtuj7ol.fsf@bates4.stat.wisc.edu>
References: <1063118194.3177.27.camel@gandalf.local>
	<6rbrtuj7ol.fsf@bates4.stat.wisc.edu>
Message-ID: <200309091258.32229.deepayan@stat.wisc.edu>

On Tuesday 09 September 2003 10:35 am, Douglas Bates wrote:
> Ernesto Jardim <ernesto at ipimar.pt> writes:
> > Hi,
> >
> > I want to plot 2 variables (confidence intervals) in a single xyplot. I
> > have a dataframe with variables Yup, Ylo, X and Z and I want to have a
> > xyplot with both variables ploted. I'm trying with
> >
> > xyplot(Yup~X|Z, panel=function(x){...})
> >
> > but this way I'm not able to pass variable Ylo into the function...
> >
> > How can I do this ?
>
> According to the "formula" description on the manual page for xyplot
> you can use
>
> xyplot(Ylo+Yup~X|Z, allow.multiple=TRUE)
>
> Did you try that?

Yes, this seems to work with the following panel function:

panel = function(x, y, groups, subscripts, ...) {
    groups <- as.numeric(groups)
    lsegments(x[groups[subscripts] == 1], y[ groups[subscripts] == 1],
              x[groups[subscripts] == 2], y[ groups[subscripts] == 2], ...)
}

Deepayan



From hb at maths.lth.se  Tue Sep  9 19:59:32 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Tue, 9 Sep 2003 19:59:32 +0200
Subject: [R] memory problem in exporting data frame
In-Reply-To: <20030909170356.85918.qmail@web41202.mail.yahoo.com>
Message-ID: <006801c376fc$1f611c80$e502eb82@maths.lth.se>

> -----Original Message-----
> From: array chip [mailto:arrayprofile at yahoo.com] 
> Sent: den 9 september 2003 19:04
> To: Henrik Bengtsson; 'Thomas W Blackwell'; Patrick Burns
> Cc: r-help at stat.math.ethz.ch
> Subject: RE: [R] memory problem in exporting data frame
> 
> 
> Hi all,
> 
> Thanks for all the suggestions. I was able to get the
> data frame out by first deleting some other large
> objects in the directory, and then changing the data
> frame into matrix by as.matrix(), splitting the matrix
> into 4 blocks and finally using write.table() to write
> the matrix into 4 files to be combined later.

write.table() has an 'append' argument, which means that you do not have
to write your matrix into seperate files, but you can append each block
to the same file 
as you go. Make sure that you turn of the column names (col.names=FALSE)
when you append and that you control or turn off the row names
(row.names=FALSE).

Henrik

> Thanks again
> 
> --- Henrik Bengtsson <hb at maths.lth.se> wrote:
> > Hi, I replied to a related question yesterday (Mon
> > Sept 8, 2003) with
> > subject "RE: [R] cannot allocate vector of size...".
> > That was as also
> > about running low of memory, but about *reading*
> > data from file and not
> > writing. However, the problem is likely to be due to
> > the same thing.
> > 
> > You pass a large object to a function via an
> > argument, an argument which
> > is then changed inside the function (in your case
> > write.table() is doing
> > x <- as.matrix(x)). As long as the argument is only
> > read, R is clever
> > not to create a copy of it (pass by reference if
> > read-only), but as soon
> > as you change it, it is creating a local copy of it
> > (pass by value).
> > Hence, now you have your original 'xxx' object plus
> > a local copy
> > "inside" the function. This is likely to be your
> > problem.
> > 
> > You can do the work around that Patrick Burns
> > suggest and improve it
> > slightly, if can you do not need the 'xxx' variable
> > anymore, you can do
> > 'xxx <- as.matrix(xxx)'. A better approach, as you
> > suggest yourself,
> > except from doing it row by row, is to write your
> > dataframe block by
> > block with a reasonable block size. This can of
> > course be done using a
> > for loop and write.table(), but you will do better
> > if you look at the
> > code in write.table() and avoid the doing the same
> > overhead work in each
> > step.
> > 
> > Finally and FYI, you might be able to shrink your
> > original data frame by
> > considering the following
> > 
> > i <- as.integer(1:1000)
> > d <- as.double(i)
> > df1 <- data.frame(i=i, d=d)
> > df2 <- data.frame(i=i, d=i)
> > object.size(df1)  # 24392 bytes
> > object.size(df2)  # 20392 bytes
> > 
> > However, note that when doing x <- as.matrix(x) (as
> > write.table() does),
> > will coerce the data into *one* data type (because
> > it is a matrix). In
> > other words, the only thing you will gain is a
> > smaller 'xxx' object.
> > 
> > Best wishes
> > 
> > Henrik Bengtsson
> > Lund University
> > 
> > > -----Original Message-----
> > > From: r-help-bounces at stat.math.ethz.ch
> > > [mailto:r-help-bounces at stat.math.ethz.ch] On
> > Behalf Of Thomas
> > > W Blackwell
> > > Sent: den 9 september 2003 01:28
> > > To: array chip
> > > Cc: r-help at stat.math.ethz.ch
> > > Subject: Re: [R] memory problem in exporting data
> > frame
> > > 
> > > 
> > > 
> > > Simplest is to save your workspace using
> > save.image(),
> > > then delete a bunch of large objects other than
> > the data
> > > frame that you want to export, and run
> > write.table()
> > > again, now that you've made space for it.  A quick
> > calc
> > > shows  17000 x 400 x 8 = 55 Mb, and that's just
> > the size
> > > of the object that chokes R below.
> > > 
> > > -  tom blackwell  -  u michigan medical school  -
> > ann arbor  -
> > > 
> > > On Mon, 8 Sep 2003, array chip wrote:
> > > 
> > > > I am having trouble of exporting a large data
> > frame
> > > > out of R to be used in other purpose. The data
> > frame
> > > > is numeric with size 17000x400. It takes a quite
> > some
> > > > time to start R as well. my computer has 1GB
> > RAM. I
> > > > used the following command to write the data
> > frame to
> > > > a text file and got the error message below:
> > > >
> > > > > write.table(xxx, "C:\\xxx", sep="\t",
> > > > row.names=FALSE,col.names=FALSE,quote=FALSE)
> > > >
> > > > Error: cannot allocate vector of size 55750 Kb
> > > > In addition: Warning message:
> > > > Reached total allocation of 1023Mb: see
> > > > help(memory.size)
> > > >
> > > > I tried to increase the memory size by 
> memory.size(size=), but it 
> > > > seems running the
> > above
> > > > command takes forever.
> > > >
> > > > what can I do with this error message to get the
> > data
> > > > out?
> > > >
> > > > Thanks
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo>
> > /r-help
> > > 
> > > 
> > 
> 
> 
> __________________________________
> Do you Yahoo!?

> software http://sitebuilder.yahoo.com
> 
>



From kvanhorn at ksvanhorn.com  Tue Sep  9 22:38:58 2003
From: kvanhorn at ksvanhorn.com (Kevin S. Van Horn)
Date: Tue, 09 Sep 2003 14:38:58 -0600
Subject: [R] Computing a CDF or many quantiles
Message-ID: <3F5E3A62.4090607@ksvanhorn.com>

Given f, a pdf over a finite interval, is there any existing R function that 
can efficiently tabulate the cumulative distribution function for f, or 
produce all N+1 quantiles of the form i/N?  "Efficiently" here means better 
than doing repeated integrations for each point.



From jerome at hivnet.ubc.ca  Tue Sep  9 22:43:33 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Tue, 9 Sep 2003 13:43:33 -0700
Subject: [R] Computing a CDF or many quantiles
In-Reply-To: <3F5E3A62.4090607@ksvanhorn.com>
References: <3F5E3A62.4090607@ksvanhorn.com>
Message-ID: <200309092042.NAA09989@hivnet.ubc.ca>


Perhaps approx() or approxfun() can help you create an efficient CDF.

HTH,
Jerome

On September 9, 2003 01:38 pm, Kevin S. Van Horn wrote:
> Content-Length: 417
> Status: R
> X-Status: N
>
> Given f, a pdf over a finite interval, is there any existing R function
> that can efficiently tabulate the cumulative distribution function for
> f, or produce all N+1 quantiles of the form i/N?  "Efficiently" here
> means better than doing repeated integrations for each point.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From cmprobst at terra.com.br  Tue Sep  9 21:09:26 2003
From: cmprobst at terra.com.br (=?iso-8859-1?Q?cmprobst?=)
Date: Tue,  9 Sep 2003 16:09:26 -0300
Subject: [R] Newbie question about plotting density objects
Message-ID: <HKYNVQ$694E3789C7BB55DB16C396856B583DE8@terra.com.br>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030909/47efe6a2/attachment.pl

From Ted.Harding at nessie.mcc.ac.uk  Wed Sep 10 00:28:53 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue, 09 Sep 2003 23:28:53 +0100 (BST)
Subject: [R] Computing a CDF or many quantiles
In-Reply-To: <3F5E3A62.4090607@ksvanhorn.com>
Message-ID: <XFMail.030909232853.Ted.Harding@nessie.mcc.ac.uk>

On 09-Sep-03 Kevin S. Van Horn wrote:
> Given f, a pdf over a finite interval, is there any existing R function
> that 
> can efficiently tabulate the cumulative distribution function for f, or
> produce all N+1 quantiles of the form i/N?  "Efficiently" here means
> better than doing repeated integrations for each point.

If that's all you want to do, then a very straightfoward approach should
be OK. I illustrate with a truncated normal distribution on [-1,1]:

  x <- (-1)+(0.001*(0:2000));pdf<-dnorm(x); pdf<-pdf/(sum(pdf)*0.001)
  CDF<-cumsum(pdf)*0.001
  plot(x,pdf,ylim=c(0,1),type="l");lines(x,CDF)

Quantiles:
  N=10;e<-CDF[1];
  for(i in (0:10)){
      j<-max(which(CDF<=i/N+e));print(c(x[j],CDF[j]))
  }
  [1] -1.0000000000  0.0003543119
  [1] -0.75000000    0.09992753
  [1] -0.5390000     0.1999932
  [1] -0.3500000     0.2999169
  [1] -0.1720000     0.4003052
  [1]  0.0000000     0.5002921
  [1]  0.1720000     0.6002703
  [1]  0.3490000     0.7000831
  [1]  0.5380000     0.8000068
  [1]  0.7490000     0.9000725
  [1]  1             1
(a bit approximate here owing to not adopting a slightly more subtle
 approach to the first step).

Tabulation should be extremely straightforward.

Is this what you mean?

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 09-Sep-03                                       Time: 23:28:53
------------------------------ XFMail ------------------------------



From ross at biostat.ucsf.edu  Wed Sep 10 02:33:06 2003
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Tue, 9 Sep 2003 17:33:06 -0700
Subject: [R] recording and taking mean of a set of matrices
Message-ID: <20030910003306.GD12620@wheat.boylan.org>

I'm looking for a good form in which to store matrix results of a
simulation.

I am doing a simulation study.  Each simulation generates some data
and then analyzes it.  I want to record the results of many
simulations and analyze them.  Say r has the results of one
simulation, and I care about r$coefficients, a vector of coefficients,
and r$var, the estimated covariance matrix.

I'll do lots of simulations and then look at the results, computing
the mean of each value.

I'm looking for a good way to save and then analyze the results.  The
coefficients seem to fit well into a data frame, but I'm looking for a
good way to handle the matrix.

The only structure I've discovered that can even handle a set of
matrices is a list.  It also occurs to me the results could go to a 3
dimensional array; I suppose it would be good to make the last index
vary with the simulation.

Neither of these approaches seems ideal, because I would need to
handle the matrix separately from the other data I want to store.  I'm
hoping to do something like simresults <- rbind(simresults, r$coeff,
r$var).

The result also needs to be amenable to calculations.  If m1 and m2
are matrices (same dimension for each) mean(list(m1, m2)) doesn't
work, so even though list will record the data it isn't a great form
for analysis.  (But I suppose some apply variant would work with 3d
arrays). 

Any suggestions for good ways to approach this?  Again, the ideal
solution would have
* consistent handling of matrices and other data
* easy computation of (e.g.) means for the results.

Thanks.

P.S. I'm also aware I could accumulate means as I go, but I'm looking
for a more general solution.



From spencer.graves at pdf.com  Wed Sep 10 03:57:18 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 09 Sep 2003 18:57:18 -0700
Subject: [R] recording and taking mean of a set of matrices
References: <20030910003306.GD12620@wheat.boylan.org>
Message-ID: <3F5E84FE.4070005@pdf.com>

	  In simulation like you describe, it is best to avoid using rbind in a 
loop, as that has more overhead than creating objects of the size 
required to store the results before you start the loop.  Also, if all 
your results are numbers, it may be better to avoid data.frames as they 
require more overhead than simple arrays.  See, e.g., Venables and 
Ripley (2002) Modern Applied Statistics with S, 4th ed. (Springer) or 
Venables and Ripley (2000) S Programming (Springer).

	  If I wanted to save all the coefficients and all the covariance 
matrices, I might create separate arrays for coefficients and for the 
covariance matrices, like the following,

N <- 2 # number of simulates
k <- 3 # number of coefficients
Coef <- array(NA, dim=c(N, k))
dimnames(Coef) <- list(NULL, letters[1:k])
Var <- array(NA, dim=c(N, k, k))
dimnames(Var) <- list(NULL, letters[1:k], letters[1:k])

## Each iteration would include something like the following:
i <- 1
Coef1 <- 1:3
Var1 <- array(1:9, dim=c(3,3))
Var1 <- (Var1+t(Var1))
Coef[1,] <- Coef1
Var[1, , ] <- Var1

##
## If I did not want to store two copies of all the covariances,
## I might do something like the following

# Set up
Results <- array(NA, dim=c(N, 2*k + choose(k, 2)))

## In each interation:
Results[1,1:k] <- Coef1
Results[1, -(1:k)] <- Var1[!lower.tri(Var1)]

hope this helps.
spencer graves

Ross Boylan wrote:
> I'm looking for a good form in which to store matrix results of a
> simulation.
> 
> I am doing a simulation study.  Each simulation generates some data
> and then analyzes it.  I want to record the results of many
> simulations and analyze them.  Say r has the results of one
> simulation, and I care about r$coefficients, a vector of coefficients,
> and r$var, the estimated covariance matrix.
> 
> I'll do lots of simulations and then look at the results, computing
> the mean of each value.
> 
> I'm looking for a good way to save and then analyze the results.  The
> coefficients seem to fit well into a data frame, but I'm looking for a
> good way to handle the matrix.
> 
> The only structure I've discovered that can even handle a set of
> matrices is a list.  It also occurs to me the results could go to a 3
> dimensional array; I suppose it would be good to make the last index
> vary with the simulation.
> 
> Neither of these approaches seems ideal, because I would need to
> handle the matrix separately from the other data I want to store.  I'm
> hoping to do something like simresults <- rbind(simresults, r$coeff,
> r$var).
> 
> The result also needs to be amenable to calculations.  If m1 and m2
> are matrices (same dimension for each) mean(list(m1, m2)) doesn't
> work, so even though list will record the data it isn't a great form
> for analysis.  (But I suppose some apply variant would work with 3d
> arrays). 
> 
> Any suggestions for good ways to approach this?  Again, the ideal
> solution would have
> * consistent handling of matrices and other data
> * easy computation of (e.g.) means for the results.
> 
> Thanks.
> 
> P.S. I'm also aware I could accumulate means as I go, but I'm looking
> for a more general solution.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ramasamya at gis.a-star.edu.sg  Wed Sep 10 04:03:05 2003
From: ramasamya at gis.a-star.edu.sg (Adaikalavan RAMASAMY)
Date: Wed, 10 Sep 2003 10:03:05 +0800
Subject: [R] recording and taking mean of a set of matrices
Message-ID: <6D9E9B9DF347EF4385F6271C64FB8D56075F67@BIONIC.biopolis.one-north.com>

" mean(list(m1, m2)) " will not work. 

mylist <- list(m1, m2)

sapply( mylist, FUN=mean ) gives will give you the mean of m1 and m2

sapply( mylist, FUN= function(x) apply(x, 2, mean) ) will give you the
column means of m1 and m2 in a matrix format. Double check the resulting
dimension.


Here are two ways to store results (say calculating quadratic of a
series) after each iteration : -

for(x in 1:100){

	# Option 1
	tmp[ ,x] <- x^2
	cat(x, "\t", tmp[ ,x], "\n", sep="", file="out.txt",
append=TRUE)

	# Option 2
	save(tmp, file="out.rda", compress=T)

Regards, Adai.




-----Original Message-----
From: Ross Boylan [mailto:ross at biostat.ucsf.edu] 
Sent: Wednesday, September 10, 2003 8:33 AM
To: R-help at stat.math.ethz.ch
Subject: [R] recording and taking mean of a set of matrices

I'm looking for a good form in which to store matrix results of a
simulation.

I am doing a simulation study.  Each simulation generates some data
and then analyzes it.  I want to record the results of many
simulations and analyze them.  Say r has the results of one
simulation, and I care about r$coefficients, a vector of coefficients,
and r$var, the estimated covariance matrix.

I'll do lots of simulations and then look at the results, computing
the mean of each value.

I'm looking for a good way to save and then analyze the results.  The
coefficients seem to fit well into a data frame, but I'm looking for a
good way to handle the matrix.

The only structure I've discovered that can even handle a set of
matrices is a list.  It also occurs to me the results could go to a 3
dimensional array; I suppose it would be good to make the last index
vary with the simulation.

Neither of these approaches seems ideal, because I would need to
handle the matrix separately from the other data I want to store.  I'm
hoping to do something like simresults <- rbind(simresults, r$coeff,
r$var).

The result also needs to be amenable to calculations.  If m1 and m2
are matrices (same dimension for each) mean(list(m1, m2)) doesn't
work, so even though list will record the data it isn't a great form
for analysis.  (But I suppose some apply variant would work with 3d
arrays). 

Any suggestions for good ways to approach this?  Again, the ideal
solution would have
* consistent handling of matrices and other data
* easy computation of (e.g.) means for the results.

Thanks.

P.S. I'm also aware I could accumulate means as I go, but I'm looking
for a more general solution.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ggrothendieck at volcanomail.com  Wed Sep 10 04:31:55 2003
From: ggrothendieck at volcanomail.com (Gabor Grothendieck)
Date: Tue, 9 Sep 2003 19:31:55 -0700 (PDT)
Subject: [R] recording and taking mean of a set of matrices
Message-ID: <20030910023155.7CEEA49E3@sitemail.everyone.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030909/2b0a0d06/attachment.pl

From jasont at indigoindustrial.co.nz  Wed Sep 10 04:48:23 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Wed, 10 Sep 2003 14:48:23 +1200
Subject: [R] Newbie question about plotting density objects
In-Reply-To: <HKYNVQ$694E3789C7BB55DB16C396856B583DE8@terra.com.br>
References: <HKYNVQ$694E3789C7BB55DB16C396856B583DE8@terra.com.br>
Message-ID: <3F5E90F7.4090302@indigoindustrial.co.nz>

cmprobst wrote:
> Dear List,
> 
> I have an array of 6400 x 56 elements. I want to calculate the density function for each column and plot all 56 density functions in one plot.
> 
> I have tried several procedures, but they all failed.
> 
> What can I do?

56 lines could even confuse a spider, so you might want to re-think your 
plotting approach.  However....

## untested code!
## get a density object for each column.
den.list <- apply(zz,2,density)

## set up your plot window
all.x <- sapply(den.list,function(d,...) {d$x})
all.y <- sapply(den.list,function(d,...) {d$y})
plot(all.x,all.y,type="n")

## now plot each one on that graph
## this will make each line the same colour; for
## different line types or colours, you'll probably
## have to use a for() loop.

lapply(den.list,function(d,...) {lines(d$x,d$y)})

There's probably a much, much cleaner way to do that, though.  I think 
the sm library has the sm.density function that takes an "add" argument 
to its plots...  too busy to check that out on this box, however.

Cheers

Jason

-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
64-21-343-545
jasont at indigoindustrial.co.nz



From spencer.graves at pdf.com  Wed Sep 10 04:40:22 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 09 Sep 2003 19:40:22 -0700
Subject: [R] recording and taking mean of a set of matrices
References: <6D9E9B9DF347EF4385F6271C64FB8D56075F67@BIONIC.biopolis.one-north.com>
Message-ID: <3F5E8F16.1020203@pdf.com>

	  If all you want are the means of the statistics, then you may not 
need to store all the individual simulation results.  What about the 
following:

N <- 9 # number of simulations
k <- 3 # number of coefficients
CoefSum <- rep(0, k)
names(CoefSum) <- letters[1:k]
VarSum <- array(0, dim=c(k, k))
dimnames(VarSum) <- list(letters[1:k], letters[1:k])

for(i in 1:N){
	c.i <- rnorm(k)
	v.i <- var(array(rnorm(k^2), dim=c(k,k)))
	CoefSum <- (CoefSum+c.i)
	VarSum <- (VarSum+v.i)
}
CoefSum/N
VarSum/N

hope this helps.  spencer graves

Adaikalavan RAMASAMY wrote:
> " mean(list(m1, m2)) " will not work. 
> 
> mylist <- list(m1, m2)
> 
> sapply( mylist, FUN=mean ) gives will give you the mean of m1 and m2
> 
> sapply( mylist, FUN= function(x) apply(x, 2, mean) ) will give you the
> column means of m1 and m2 in a matrix format. Double check the resulting
> dimension.
> 
> 
> Here are two ways to store results (say calculating quadratic of a
> series) after each iteration : -
> 
> for(x in 1:100){
> 
> 	# Option 1
> 	tmp[ ,x] <- x^2
> 	cat(x, "\t", tmp[ ,x], "\n", sep="", file="out.txt",
> append=TRUE)
> 
> 	# Option 2
> 	save(tmp, file="out.rda", compress=T)
> 
> Regards, Adai.
> 
> 
> 
> 
> -----Original Message-----
> From: Ross Boylan [mailto:ross at biostat.ucsf.edu] 
> Sent: Wednesday, September 10, 2003 8:33 AM
> To: R-help at stat.math.ethz.ch
> Subject: [R] recording and taking mean of a set of matrices
> 
> I'm looking for a good form in which to store matrix results of a
> simulation.
> 
> I am doing a simulation study.  Each simulation generates some data
> and then analyzes it.  I want to record the results of many
> simulations and analyze them.  Say r has the results of one
> simulation, and I care about r$coefficients, a vector of coefficients,
> and r$var, the estimated covariance matrix.
> 
> I'll do lots of simulations and then look at the results, computing
> the mean of each value.
> 
> I'm looking for a good way to save and then analyze the results.  The
> coefficients seem to fit well into a data frame, but I'm looking for a
> good way to handle the matrix.
> 
> The only structure I've discovered that can even handle a set of
> matrices is a list.  It also occurs to me the results could go to a 3
> dimensional array; I suppose it would be good to make the last index
> vary with the simulation.
> 
> Neither of these approaches seems ideal, because I would need to
> handle the matrix separately from the other data I want to store.  I'm
> hoping to do something like simresults <- rbind(simresults, r$coeff,
> r$var).
> 
> The result also needs to be amenable to calculations.  If m1 and m2
> are matrices (same dimension for each) mean(list(m1, m2)) doesn't
> work, so even though list will record the data it isn't a great form
> for analysis.  (But I suppose some apply variant would work with 3d
> arrays). 
> 
> Any suggestions for good ways to approach this?  Again, the ideal
> solution would have
> * consistent handling of matrices and other data
> * easy computation of (e.g.) means for the results.
> 
> Thanks.
> 
> P.S. I'm also aware I could accumulate means as I go, but I'm looking
> for a more general solution.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ok at cs.otago.ac.nz  Wed Sep 10 07:18:54 2003
From: ok at cs.otago.ac.nz (Richard A. O'Keefe)
Date: Wed, 10 Sep 2003 17:18:54 +1200 (NZST)
Subject: [R] recording and taking mean of a set of matrices
Message-ID: <200309100518.h8A5Isc3382295@atlas.otago.ac.nz>

If there are a _lot_ of results, and they are not needed until after
the simulations have all run, it's always possible to write them out
to a file or files and then use scan() or read.table() or something like
that to read them back in.



From m.mader at gsf.de  Wed Sep 10 08:02:12 2003
From: m.mader at gsf.de (Michael Mader)
Date: Wed, 10 Sep 2003 08:02:12 +0200
Subject: [R] Making R packages (Unix)
References: <p0600202bbb83abff6f40@[193.49.112.222]>
Message-ID: <3F5EBE64.27A98F30@gsf.de>

"Gattuso, Jean-Pierre" wrote:
> 
> Hi:
> 
> I have have taken over from a colleague who
> prepared an R package and failed to build it on
> Windows. I am doing this with unix as I am a mac
> user. Below is the output I get when I use the
> build command:
> 
> [gattuso:unix/R/CO2.Rcheck] gattuso% R CMD build CO2
> * checking for file 'CO2/DESCRIPTION' ... OK
> * preparing 'CO2':
> * checking whether 'INDEX' is up-to-date ... NO
> * use '--force' to overwrite the existing 'INDEX'
> * removing junk files
> * building 'CO2_1.0.tar.gz'
> tar: Unable to access
> /Users/gattuso/documents/unix/R/CO2.Rcheck/CO2_1.0.tar
> <No such file or directory>
> tar: WARNING! These file names were not selected:
> /Users/gattuso/documents/unix/R/CO2.Rcheck/CO2_1.0.tar
> CO2_1.0.tar: No such file or directory
> 
Looks like R_HOME is set to an invalid directory.

Regards 

Michael

-- 
Michael T. Mader
Institute for Bioinformatics/MIPS, GSF
Ingolstaedter Landstrasse 1
D-80937 Neuherberg
0049-89-3187-3576
 
In statistics, some people worry about not seeing the forest for the
trees.
I like to look at the bark. (C. R. Blyth, 1967)



From WeiQiang.Li at seagate.com  Wed Sep 10 11:58:09 2003
From: WeiQiang.Li at seagate.com (WeiQiang.Li@seagate.com)
Date: Wed, 10 Sep 2003 17:58:09 +0800
Subject: [R] Need your help-SOS
Message-ID: <OF4327119C.BFCC8FD7-ON48256D9D.00351AAA-48256D9D.0036BE56@notes.seagate.com>

Hello,

      I am a newbie in R project and trying to call prcomp(x) of R function
using (D)COM server communicate with R in ASP, and encountering the error
"Runtime error -2147221493(8004000b). Automation Error, Object is static,
operation not allowed."

      Source code is shown as below:
      <%
      Set StatConn=Server.CreateObject("StatConnectorSrv.StatConnector")
      StatConn.Init ("R")
      Result=StatConn.Evaluate("x<-matrix(c(1,2,3,4,5,6,7,8,9),3)")
      Result=StatConn.Evaluate("y<-prcomp(x)")
      StatConn.Close
      %>

      I have another problem when displaying dimension variable
"Result(1,1)" on client, there will be a "Type mismatch: 'Result'" error.
      Source code is shown as below:
      <%
      Set StatConn=Server.CreateObject("StatConnectorSrv.StatConnector")
      StatConn.Init ("R")
      Result=StatConn.Evaluate("x<-matrix(c(1,2,3,4,5,6,7,8,9),3)")
      Response.write Result(1,1)
      StatConn.Close
      %>

      You are very appreciated if you help me on above issue.
      Thanks Again!

Regards,
WeiQiang Li
IT-Factory Information Systems
Tel: 6485-2439



From orasi at stat.unibo.it  Wed Sep 10 13:42:35 2003
From: orasi at stat.unibo.it (orasi@stat.unibo.it)
Date: Wed, 10 Sep 2003 13:42:35 +0200
Subject: [R] C code for KalmnaLike
Message-ID: <1063194155.3f5f0e2ba5036@canne.stat.unibo.it>



Hi
it is possible to see the C code for the KalmanLike and Kalmansmooth functions 
with R?
Otherwise, without using R, how can I get the code?
Thank 
arianna



From dave.nys at agr.kuleuven.ac.be  Wed Sep 10 14:48:25 2003
From: dave.nys at agr.kuleuven.ac.be (Dave Nys)
Date: Wed, 10 Sep 2003 14:48:25 +0200
Subject: [R] geoR variogram problem
Message-ID: <EFEHKIJALLCFMLIEKDNACEMCCAAA.dave.nys@agr.kuleuven.ac.be>

Dear GeoR-er,

If I use the variog function in the latest release of geoR, the first lag is
always ignored.
For instance, if you read in geodata, calculates the variogram using the
variog function and give in a uvec like uvec=seq(0,max,by=2.44), it only
starts giving results from distance=4.88 and ignores 2.44!
This wasn't the case in former versions of geoR.  Is this done on purpose?
Why?

Tnx for your help,
Dave Nys
K.U.Leuven
Laboratory for Forest, Nature and Landscape Research
Vital De Costerstraat 102  B-3000 Leuven
Tel. +32 (0)16 329751  Fax. +32 (0)16 329760
email: Dave.Nys at agr.kuleuven.ac.be



From Raimondas at vb.lt  Wed Sep 10 14:52:40 2003
From: Raimondas at vb.lt (Raimondas B.)
Date: Wed, 10 Sep 2003 15:52:40 +0300
Subject: [R] Need your help with SJava package on W2K
References: <OF4327119C.BFCC8FD7-ON48256D9D.00351AAA-48256D9D.0036BE56@notes.seagate.com>
Message-ID: <000a01c3779a$6b555810$6e25b10a@berniunas>

Dear R expert,

I have the problems with running R from Java on Windows 2000.
This is my what i get when i run the program:
Loading RInterpreter library

java.lang.UnsatisfiedLinkError: no RInterpreter in java.library.path

I set all variable (environment). I'd like to notice,that Java from R works
fine, initialization was without any problems.

Please help me to solve me this problem.
Raimondas



From tblackw at umich.edu  Wed Sep 10 14:52:10 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Wed, 10 Sep 2003 08:52:10 -0400 (EDT)
Subject: [R] Need your help-SOS
In-Reply-To: <OF4327119C.BFCC8FD7-ON48256D9D.00351AAA-48256D9D.0036BE56@notes.seagate.com>
Message-ID: <Pine.SOL.4.44.0309100845400.8161-100000@timepilot.gpcc.itd.umich.edu>

WeiQiang  -

As I read it, both difficulties arise on the DCOM side,
not in the R syntax.  Problem 1, and I'm just guessing,
could arise if you are not allowed to overwrite the
value of "Result" in the DCOM environment.  Try again,
using two different variable names in the two successive
lines.

Problem 2 would seem to have something to do with the
DCOM syntax for subscripting an array.  Inside R, the
syntax would be to use square brackets for subscripting x,
thus,  x[1,1] would return the upper left corner element.

I have no knowledge of DCOM, so I don't know how the
command  Response.write Result(1,1)  gets interpreted.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Wed, 10 Sep 2003 WeiQiang.Li at seagate.com wrote:

> Hello,
>
>       I am a newbie in R project and trying to call prcomp(x) of R function
> using (D)COM server communicate with R in ASP, and encountering the error
> "Runtime error -2147221493(8004000b). Automation Error, Object is static,
> operation not allowed."
>
>       Source code is shown as below:
>       <%
>       Set StatConn=Server.CreateObject("StatConnectorSrv.StatConnector")
>       StatConn.Init ("R")
>       Result=StatConn.Evaluate("x<-matrix(c(1,2,3,4,5,6,7,8,9),3)")
>       Result=StatConn.Evaluate("y<-prcomp(x)")
>       StatConn.Close
>       %>
>
>       I have another problem when displaying dimension variable
> "Result(1,1)" on client, there will be a "Type mismatch: 'Result'" error.
>       Source code is shown as below:
>       <%
>       Set StatConn=Server.CreateObject("StatConnectorSrv.StatConnector")
>       StatConn.Init ("R")
>       Result=StatConn.Evaluate("x<-matrix(c(1,2,3,4,5,6,7,8,9),3)")
>       Response.write Result(1,1)
>       StatConn.Close
>       %>
>
>       You are very appreciated if you help me on above issue.
>       Thanks Again!
>
> Regards,
> WeiQiang Li
> IT-Factory Information Systems
> Tel: 6485-2439
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From gregory_r_warnes at groton.pfizer.com  Wed Sep 10 14:37:28 2003
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Wed, 10 Sep 2003 08:37:28 -0400
Subject: [R] Off Topic:  Good reference for sample size calculations
Message-ID: <D7A3CFD7825BD6119B880002A58F06C20680A75F@groexmb02.pfizer.com>


Hi All,

This is off topic, but we're drawing a blank here..

> In a presentation I'll be giving next week, I want to include a reference
> to a good general text on computing sample sizes for standard experiments.
> Can anyone recommend a good book to use for this purpose?
> 
> Thanks,
> 
> -Greg


LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}



From hdoran at nasdc.org  Wed Sep 10 15:19:19 2003
From: hdoran at nasdc.org (Harold Doran)
Date: Wed, 10 Sep 2003 09:19:19 -0400
Subject: [R] Off Topic:  Good reference for sample size calculations
Message-ID: <66578BFC0BA55348B5907A0F798EE930663153@ernesto.NASDC.ORG>

Jacob Cohen's book "Statistical Power Analysis for the Behavioral Sciences" is one.



 
------
Harold C. Doran
Director of Research and Evaluation
New American Schools
675 N. Washington Street, Suite 220
Alexandria, Virginia 22314
703.647.1628
<http://www.edperform.net>  
 
 


-----Original Message-----
From: Warnes, Gregory R [mailto:gregory_r_warnes at groton.pfizer.com]
Sent: Wednesday, September 10, 2003 8:37 AM
To: 'r-help at stat.math.ethz.ch'
Subject: [R] Off Topic: Good reference for sample size calculations



Hi All,

This is off topic, but we're drawing a blank here..

> In a presentation I'll be giving next week, I want to include a reference
> to a good general text on computing sample sizes for standard experiments.
> Can anyone recommend a good book to use for this purpose?
> 
> Thanks,
> 
> -Greg


LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From MSchwartz at medanalytics.com  Wed Sep 10 15:24:33 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 10 Sep 2003 08:24:33 -0500
Subject: [R] Off Topic:  Good reference for sample size calculations
In-Reply-To: <D7A3CFD7825BD6119B880002A58F06C20680A75F@groexmb02.pfizer.com>
References: <D7A3CFD7825BD6119B880002A58F06C20680A75F@groexmb02.pfizer.com>
Message-ID: <1063200272.23355.4.camel@localhost>

On Wed, 2003-09-10 at 07:37, Warnes, Gregory R wrote:
> Hi All,
> 
> This is off topic, but we're drawing a blank here..
> 
> > In a presentation I'll be giving next week, I want to include a reference
> > to a good general text on computing sample sizes for standard experiments.
> > Can anyone recommend a good book to use for this purpose?
> > 
> > Thanks,
> > 
> > -Greg


Greg,

How about:

Design and Analysis of Clinical Trials
Concepts and Methodologies
Shein-Chung Chow and Jen-pei Liu
Wiley, 1998 

Chapter 10: Sample Size Determination
Pages 424 - 482

Amazon.com link:

http://www.amazon.com/exec/obidos/tg/detail/-/047113404X/

HTH,

Marc Schwartz



From spencer.graves at pdf.com  Wed Sep 10 15:45:27 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 10 Sep 2003 06:45:27 -0700
Subject: [R] C code for KalmnaLike
References: <1063194155.3f5f0e2ba5036@canne.stat.unibo.it>
Message-ID: <3F5F2AF7.8070208@pdf.com>

	  Did you try www.r-project.org -> "Download CRAN" -> {select a local 
mirror} -> "Source code for all platforms"?

	  From what I hear, your prayers should be answered there (though I 
have no personnally built links to compiled code since S-Plus 3.3).

hope this helps.  spencer graves

orasi at stat.unibo.it wrote:
> 
> Hi
> it is possible to see the C code for the KalmanLike and Kalmansmooth functions 
> with R?
> Otherwise, without using R, how can I get the code?
> Thank 
> arianna
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From pgilbert at bank-banque-canada.ca  Wed Sep 10 16:34:57 2003
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Wed, 10 Sep 2003 10:34:57 -0400
Subject: [R] C code for KalmnaLike
In-Reply-To: <1063194155.3f5f0e2ba5036@canne.stat.unibo.it>
References: <1063194155.3f5f0e2ba5036@canne.stat.unibo.it>
Message-ID: <3F5F3691.5030804@bank-banque-canada.ca>

orasi at stat.unibo.it wrote:

>Hi
>it is possible to see the C code for the KalmanLike and Kalmansmooth functions with R?
>
It is possible to see all the code distributed with R and the R packages 
on CRAN. (This is why it is sometimes called an open source project.) 
Kalman smoothing and Kalman filtering, on which the likelihood 
calculation is usually based,  are not part of base R, but are in 
packages.  I am not sure about other packages, but the versions in the 
dse package are not written in C. There is a fortran version and an 
equivalent R version. There is a C version which is translated with f2c, 
but that is not the place to look if you are trying to understand the 
algorithm. The easiest code to read is the R version, but the fortran it 
the one that is used (by default) for reason of speed.

>Otherwise, without using R, how can I get the code?
>
You can download the source from CRAN and examine it without using R. 
However, if you actually want to use the code, then I strongly suggest 
you use R too. The R code makes a call to fortran in order to speed the 
iterative part of the calculation, but the likelihood calculation from 
the residuals, all the error checking, plotting, and "nice to use" 
features are in the R code. If you want to use dse, then start by 
reading the dse user's guide distributed with the package bundle (in 
dse1/inst/doc/dse-guide.pdf) and getting familiar with R.  (When I have 
been asked questions like your's before, the next question has usually 
be something like: please give me a tutorial on the internal details of  
your code, because I want to pull it  apart and use it somewhere else.  
I am not very interested in the effort required for me to do that.)

Paul Gilbert

>Thank 
>arianna
>



From partha_bagchi at hgsi.com  Wed Sep 10 16:38:56 2003
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Wed, 10 Sep 2003 10:38:56 -0400
Subject: [R] Off Topic:  Good reference for sample size calculations
Message-ID: <OF8239BA56.F0DFA8B9-ON85256D9D.004F8ACD-85256D9D.00507859@hgsi.com>

Following should help: 

1. "Sample Size Methodology (Statistical Modeling and Decision Science)" 
        by Raghavarao and Desu (1990)
         Academic Press.

2. Russell Lenth's monograph - Some Practical Guide to Effective Sample 
Size
        http://www.stat.uiowa.edu/techrep/tr303.pdf 

3. Introduction to Sample Size determination and Power Analysis for 
Clinical Trials
        John Lachin, Controlled Clinical Trials, 2, 93-113 (1981)

4. Evaluation of Sample Size and Power for Analyses of Survival with 
Allowance for Nonuniform Patient Entry, Losses to Follow-up, 
Noncompliance, and Stratification
        John Lachin & Mary Foulkes, Biometrics, 42, 507-519, September 
1986

Partha





"Warnes, Gregory R" <gregory_r_warnes at groton.pfizer.com>
Sent by: r-help-bounces at stat.math.ethz.ch
09/10/2003 08:37 AM

 
        To:     "'r-help at stat.math.ethz.ch'" <r-help at stat.math.ethz.ch>
        cc: 
        Subject:        [R] Off Topic:  Good reference for sample size calculations



Hi All,

This is off topic, but we're drawing a blank here..

> In a presentation I'll be giving next week, I want to include a 
reference
> to a good general text on computing sample sizes for standard 
experiments.
> Can anyone recommend a good book to use for this purpose?
>
> Thanks,
>
> -Greg


LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help

--
This message has been scanned for viruses and
dangerous content by MailScanner, and is
believed to be clean.



From TyagiAnupam at aol.com  Wed Sep 10 16:46:16 2003
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Wed, 10 Sep 2003 10:46:16 EDT
Subject: [R] Plot survey data
Message-ID: <ba.462c2f6a.2c909338@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030910/1a0c9c81/attachment.pl

From pgreen at umich.edu  Wed Sep 10 16:50:10 2003
From: pgreen at umich.edu (Paul Green)
Date: Wed, 10 Sep 2003 10:50:10 -0400
Subject: [R] sort a matrix on just one column
Message-ID: <5.1.0.14.2.20030910104631.00b12300@mailkardia.sph.umich.edu>

How can I sort(decreasing) a matrix on just the first column?
For example, I can I get

   8  2
   7  5
   4  1

from

   7  5
   4  1
   8  2

Thanks



From tlumley at u.washington.edu  Wed Sep 10 16:52:40 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 10 Sep 2003 07:52:40 -0700 (PDT)
Subject: [R] Making R packages (Unix)
In-Reply-To: <p0600202bbb83abff6f40@[193.49.112.222]>
Message-ID: <Pine.A41.4.44.0309100748510.195750-100000@homer04.u.washington.edu>

On Tue, 9 Sep 2003, Gattuso, Jean-Pierre wrote:

> Hi:
>
> I have have taken over from a colleague who
> prepared an R package and failed to build it on
> Windows. I am doing this with unix as I am a mac
> user. Below is the output I get when I use the
> build command:

This looks like what happens under Mac OS X, where tar doesn't recognise
the -X flag for eXcluding files [it's used for something else].

You can confirm by checking man tar.  I don't know if this will get fixed
for 1.8.0, but a work-around is to get GNU tar.

	-thomas

> [gattuso:unix/R/CO2.Rcheck] gattuso% R CMD build CO2
> * checking for file 'CO2/DESCRIPTION' ... OK
> * preparing 'CO2':
> * checking whether 'INDEX' is up-to-date ... NO
> * use '--force' to overwrite the existing 'INDEX'
> * removing junk files
> * building 'CO2_1.0.tar.gz'
> tar: Unable to access
> /Users/gattuso/documents/unix/R/CO2.Rcheck/CO2_1.0.tar
> <No such file or directory>
> tar: WARNING! These file names were not selected:
> /Users/gattuso/documents/unix/R/CO2.Rcheck/CO2_1.0.tar
> CO2_1.0.tar: No such file or directory
>
>
> I have read the R-exts.pdf document but did not
> find what I do wrong. In fact, there is little
> information on the use of R CMD build, both in
> the R-exts.pdf document and the man (R CMD build
> --help) pages.
>
> Do I need to make the CO2_1.0.tar file myself?
>
> Your help would be much appreciated!
>
> jp
> --
> 
> Jean-Pierre Gattuso | mailto:gattuso at obs-vlfr.fr
> | http://www.obs-vlfr.fr/~gattuso
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From paulojus at est.ufpr.br  Wed Sep 10 16:59:15 2003
From: paulojus at est.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Wed, 10 Sep 2003 11:59:15 -0300 (BRT)
Subject: [R] geoR variogram problem
In-Reply-To: <EFEHKIJALLCFMLIEKDNACEMCCAAA.dave.nys@agr.kuleuven.ac.be>
References: <EFEHKIJALLCFMLIEKDNACEMCCAAA.dave.nys@agr.kuleuven.ac.be>
Message-ID: <Pine.LNX.4.56.0309101158390.13725@gauss.est.ufpr.br>

Dave

GHard to tell withoiut see your data.
Pleas send me and example code (and data if necessary) and I will chack

P.J.


On Wed, 10 Sep 2003, Dave Nys wrote:

> Dear GeoR-er,
>
> If I use the variog function in the latest release of geoR, the first lag is
> always ignored.
> For instance, if you read in geodata, calculates the variogram using the
> variog function and give in a uvec like uvec=seq(0,max,by=2.44), it only
> starts giving results from distance=4.88 and ignores 2.44!
> This wasn't the case in former versions of geoR.  Is this done on purpose?
> Why?
>
> Tnx for your help,
> Dave Nys
> K.U.Leuven
> Laboratory for Forest, Nature and Landscape Research
> Vital De Costerstraat 102  B-3000 Leuven
> Tel. +32 (0)16 329751  Fax. +32 (0)16 329760
> email: Dave.Nys at agr.kuleuven.ac.be
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>

Paulo Justiniano Ribeiro Jr
Departamento de Estat?stica
Universidade Federal do Paran?
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 361 3471
Fax: (+55) 41 361 3141
e-mail: pj at est.ufpr.br
http://www.est.ufpr.br/~paulojus



From petr.pikal at precheza.cz  Wed Sep 10 17:11:18 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Wed, 10 Sep 2003 17:11:18 +0200
Subject: [R] sort a matrix on just one column
In-Reply-To: <5.1.0.14.2.20030910104631.00b12300@mailkardia.sph.umich.edu>
Message-ID: <3F5F5B36.16273.20F940F@localhost>

Hi

On 10 Sep 2003 at 10:50, Paul Green wrote:

> How can I sort(decreasing) a matrix on just the first column?
> For example, I can I get
> 
>    8  2
>    7  5
>    4  1
> 
> from
> 
>    7  5
>    4  1
>    8  2

I am sure in help pages for sort() is a link to order()

> mat
     x y
[1,] 7 5
[2,] 4 1
[3,] 8 2

> o<-order(mat[,1],decreasing=T)

> mat[o,]
     x y
[1,] 8 2
[2,] 7 5
[3,] 4 1


> 
> Thanks
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

CheersPetr Pikal
petr.pikal at precheza.cz



From rtmoore at fas.harvard.edu  Wed Sep 10 17:24:43 2003
From: rtmoore at fas.harvard.edu (Ryan Thomas Moore)
Date: Wed, 10 Sep 2003 11:24:43 -0400 (EDT)
Subject: [R] dataframe subsetting
Message-ID: <Pine.LNX.4.44.0309101117330.886-100000@ice1.fas.harvard.edu>


I can create a small dataset, "x" below, and subset out rows based on 
values of a certain variable.  However, on the dataset I'm working on now, 
"latdata" below, I get a subscript error.  Any advice is appreciated!

Ryan


Successful:

> is.data.frame(x)
[1] TRUE
> x
  X1 X2 X3
1  1  3  5
2  2  4  6
> x[x$X2 %in% c(3),]
  X1 X2 X3
1  1  3  5

Unsuccessful:

> is.data.frame(latdata)
[1] TRUE
> is.numeric(latdata$intent)
[1] TRUE
> table(latdata$intent)

  1   2   3   4   5   6 
 34  23  67 179 996   2 
> unlikely <- latdata[latdata$intent %in% c(1,2,3,4),]
Error in x[[j]] : subscript out of bounds


------------------------------------------
Ryan T. Moore ~ Government & Social Policy
Ph.D. Candidate ~ Harvard University



From jfox at mcmaster.ca  Wed Sep 10 17:32:34 2003
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 10 Sep 2003 11:32:34 -0400
Subject: [R] Plot survey data
In-Reply-To: <ba.462c2f6a.2c909338@aol.com>
Message-ID: <5.1.0.14.2.20030910112842.01fdf788@127.0.0.1>

Dear Anupam,

I may be wrong, but I don't think that there's any standard method to use 
in plotting with case weights. I can think of two approaches, however: (1) 
If you have a large sample, and if the range of the weights isn't too 
large, you could sample your observations with probability of inclusion in 
the plot proportional to the case weights. (2) You could plot the points 
with "size" proportional to the square root of the case weights (i.e., area 
proportional to the weights).

I hope that this helps,
  John

At 10:46 AM 9/10/2003 -0400, TyagiAnupam at aol.com wrote:
>I am trying to make plots that take into account survey weights. This a
>survey of the US population.  To start with I want to explore the data 
>using pairs,
>plot, coplots and lattice. Are there specialized methods that handle survey
>weights for plotting? Any pointers?
>Anupam.

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From solares at unsl.edu.ar  Wed Sep 10 17:37:19 2003
From: solares at unsl.edu.ar (solares@unsl.edu.ar)
Date: Wed, 10 Sep 2003 12:37:19 -0300 (ART)
Subject: [R] what is set.fit in function predict.lm
Message-ID: <45964.170.210.173.216.1063208239.squirrel@inter14.unsl.edu.ar>

Hi, what es the parameter set.fit in function predict.lm, is set.fit True
then i need the standard error How i cant calculate it?. It is the different
what? i see the code of predict.lm How i cant see the matemathics formula 
for the calculation of standard error.



From ripley at stats.ox.ac.uk  Wed Sep 10 17:51:44 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 10 Sep 2003 16:51:44 +0100 (BST)
Subject: [R] what is set.fit in function predict.lm
In-Reply-To: <45964.170.210.173.216.1063208239.squirrel@inter14.unsl.edu.ar>
Message-ID: <Pine.LNX.4.44.0309101648140.20235-100000@gannet.stats>

On Wed, 10 Sep 2003 solares at unsl.edu.ar wrote:

> Hi, what es the parameter set.fit in function predict.lm, is set.fit True
> then i need the standard error How i cant calculate it?. It is the different
> what? i see the code of predict.lm How i cant see the matemathics formula 
> for the calculation of standard error.

> args(predict.lm)
function (object, newdata, se.fit = FALSE, scale = NULL, df = Inf,
    interval = c("none", "confidence", "prediction"), level = 0.95,
    type = c("response", "terms"), terms = NULL, na.action = na.pass,
    ...)

so I guess you meant `se.fit'.  That argument is documented on the help
page: if true it returns standard errors (estimated standard deviations)
for the predictions, without your calculating anything.

The formulae are in any good book on regression, although R is more
careful than most books in dealing with e.g. rank-deficient cases.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From pgilbert at bank-banque-canada.ca  Wed Sep 10 17:52:58 2003
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Wed, 10 Sep 2003 11:52:58 -0400
Subject: [R] C code for KalmnaLike
In-Reply-To: <3F5F3691.5030804@bank-banque-canada.ca>
References: <1063194155.3f5f0e2ba5036@canne.stat.unibo.it>
	<3F5F3691.5030804@bank-banque-canada.ca>
Message-ID: <3F5F48DA.3070006@bank-banque-canada.ca>

My apologies. I now realize this question was more specifically about 
the KalmanLike and KalmanSmooth functions distributed in package ts with 
base, and not generally about code for calculating the Kalman smoother 
or likelihood from the Kalman filter. Of course, the sources for these 
functions are available and appear to be written in C.

Paul Gilbert

Paul Gilbert wrote:

> orasi at stat.unibo.it wrote:
>
>> Hi
>> it is possible to see the C code for the KalmanLike and Kalmansmooth 
>> functions with R?
>>
> It is possible to see all the code distributed with R and the R 
> packages on CRAN. (This is why it is sometimes called an open source 
> project.) Kalman smoothing and Kalman filtering, on which the 
> likelihood calculation is usually based,  are not part of base R, but 
> are in packages.  I am not sure about other packages, but the versions 
> in the dse package are not written in C. There is a fortran version 
> and an equivalent R version. There is a C version which is translated 
> with f2c, but that is not the place to look if you are trying to 
> understand the algorithm. The easiest code to read is the R version, 
> but the fortran it the one that is used (by default) for reason of speed.
>
>> Otherwise, without using R, how can I get the code?
>>
> You can download the source from CRAN and examine it without using R. 
> However, if you actually want to use the code, then I strongly suggest 
> you use R too. The R code makes a call to fortran in order to speed 
> the iterative part of the calculation, but the likelihood calculation 
> from the residuals, all the error checking, plotting, and "nice to 
> use" features are in the R code. If you want to use dse, then start by 
> reading the dse user's guide distributed with the package bundle (in 
> dse1/inst/doc/dse-guide.pdf) and getting familiar with R.  (When I 
> have been asked questions like your's before, the next question has 
> usually be something like: please give me a tutorial on the internal 
> details of  your code, because I want to pull it  apart and use it 
> somewhere else.  I am not very interested in the effort required for 
> me to do that.)
>
> Paul Gilbert
>
>> Thank arianna
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From KINLEY_ROBERT at lilly.com  Wed Sep 10 17:54:38 2003
From: KINLEY_ROBERT at lilly.com (KINLEY_ROBERT@lilly.com)
Date: Wed, 10 Sep 2003 16:54:38 +0100
Subject: [R] Industrial Statistician Job (Basingstoke UK)
Message-ID: <OFB8B8CE13.4FA45D01-ON80256D9D.005406FA@ema.lilly.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030910/cb7c14dc/attachment.pl

From dave at evocapital.com  Wed Sep 10 18:03:44 2003
From: dave at evocapital.com (David Khabie-Zeitoune)
Date: Wed, 10 Sep 2003 17:03:44 +0100
Subject: [R] Multivariate Kalman filter with time-varying coefficients
Message-ID: <8D0F30FE2EB3314182D4A33F738BB19D0BA76A@sqlsrvr.evocapital.com>

Hi

Does anyone know of any R code for estimating a *multivariate* state
space model using a Kalman filter where the output matrix H(t) is
time-varying but predictable (i.e. measurable w.r.t information at time
t-1) in the observation equation 

y(t) = H(t) z(t) + R w(t)? 

[Here y(t) are the observations, z(t) is the state variable, w(t) the
observation error and R R' the observation error covariance]

Cheers,
David



From tblackw at umich.edu  Wed Sep 10 18:13:00 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Wed, 10 Sep 2003 12:13:00 -0400 (EDT)
Subject: [R] dataframe subsetting
In-Reply-To: <Pine.LNX.4.44.0309101117330.886-100000@ice1.fas.harvard.edu>
Message-ID: <Pine.SOL.4.44.0309101204270.8161-100000@timepilot.gpcc.itd.umich.edu>

Ryan  -

Puzzling.  My best guess is a misspelling or a truncation
in the column name "intent" within latdata in the context of

> unlikely <- latdata[latdata$intent %in% c(1,2,3,4),]

but I do not see any such misspelling in your email.  Could
you try again, using some other way to specify the column on
which you wish to subset ?  Such as: figure out what number
the column is (say it's the fifth column in latdata) and use

> unlikely <- latdata[latdata[[5]] %in% c(1,2,3,4),]

Otherwise, your R syntax looks fine to me.  Try also asking

> is.factor(latdata$intent)

but I don't think that would have caused the error message
you see.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Wed, 10 Sep 2003, Ryan Thomas Moore wrote:

> I can create a small dataset, "x" below, and subset out rows based on
> values of a certain variable.  However, on the dataset I'm working on now,
> "latdata" below, I get a subscript error.  Any advice is appreciated!
>
> Ryan
>
> Successful:
>
> > is.data.frame(x)
> [1] TRUE
> > x
>   X1 X2 X3
> 1  1  3  5
> 2  2  4  6
> > x[x$X2 %in% c(3),]
>   X1 X2 X3
> 1  1  3  5
>
> Unsuccessful:
>
> > is.data.frame(latdata)
> [1] TRUE
> > is.numeric(latdata$intent)
> [1] TRUE
> > table(latdata$intent)
>
>   1   2   3   4   5   6
>  34  23  67 179 996   2
> > unlikely <- latdata[latdata$intent %in% c(1,2,3,4),]
> Error in x[[j]] : subscript out of bounds
> ------------------------------------------
> Ryan T. Moore ~ Government & Social Policy
> Ph.D. Candidate ~ Harvard University



From spencer.graves at pdf.com  Wed Sep 10 18:15:26 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 10 Sep 2003 09:15:26 -0700
Subject: [R] dataframe subsetting
References: <Pine.LNX.4.44.0309101117330.886-100000@ice1.fas.harvard.edu>
Message-ID: <3F5F4E1E.4020203@pdf.com>

Can you cut the data.frame down to just 2 rows and 2 columns that 
display the error?  You might find the error in the process of doing 
that.  If not, you should be able to distribute your same question with 
an example so anyone else can reproduce the problem.

This doesn't answer your question, but this technique can be used to 
resolve many difficult problems.

spencer graves

Ryan Thomas Moore wrote:
> I can create a small dataset, "x" below, and subset out rows based on 
> values of a certain variable.  However, on the dataset I'm working on now, 
> "latdata" below, I get a subscript error.  Any advice is appreciated!
> 
> Ryan
> 
> 
> Successful:
> 
> 
>>is.data.frame(x)
> 
> [1] TRUE
> 
>>x
> 
>   X1 X2 X3
> 1  1  3  5
> 2  2  4  6
> 
>>x[x$X2 %in% c(3),]
> 
>   X1 X2 X3
> 1  1  3  5
> 
> Unsuccessful:
> 
> 
>>is.data.frame(latdata)
> 
> [1] TRUE
> 
>>is.numeric(latdata$intent)
> 
> [1] TRUE
> 
>>table(latdata$intent)
> 
> 
>   1   2   3   4   5   6 
>  34  23  67 179 996   2 
> 
>>unlikely <- latdata[latdata$intent %in% c(1,2,3,4),]
> 
> Error in x[[j]] : subscript out of bounds
> 
> 
> ------------------------------------------
> Ryan T. Moore ~ Government & Social Policy
> Ph.D. Candidate ~ Harvard University
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From elsawy at ysbl.york.ac.uk  Wed Sep 10 19:12:00 2003
From: elsawy at ysbl.york.ac.uk (Karim Elsawy)
Date: Wed, 10 Sep 2003 18:12:00 +0100
Subject: [R] insert eps into microsft word
Message-ID: <3F5F5B60.4E3ABEF@ysbl.york.ac.uk>

it seems that word can not read encapsupalted postscripts generated by R
I used this command

postscript("output.eps",horizontal=F,onefile=TRUE)
since onefile=TRUE produces an encapsualted postscript

actually what I'm trying to do is to insert the postsript file into a
word document
since other formats like jpeg and bmp do not reproduce the same quality
like postscript
formats


any suggestions are very much appreciated
Karim



From ben at zoo.ufl.edu  Wed Sep 10 19:27:34 2003
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Wed, 10 Sep 2003 13:27:34 -0400 (EDT)
Subject: [R] insert eps into microsft word
In-Reply-To: <3F5F5B60.4E3ABEF@ysbl.york.ac.uk>
Message-ID: <Pine.LNX.4.44.0309101326580.3601-100000@bolker.zoo.ufl.edu>


  If you're working in windows, the WMF (windows metafile) format is 
probably your best bet; it's a vector format like PostScript.

On Wed, 10 Sep 2003, Karim Elsawy wrote:

> it seems that word can not read encapsupalted postscripts generated by R
> I used this command
> 
> postscript("output.eps",horizontal=F,onefile=TRUE)
> since onefile=TRUE produces an encapsualted postscript
> 
> actually what I'm trying to do is to insert the postsript file into a
> word document
> since other formats like jpeg and bmp do not reproduce the same quality
> like postscript
> formats
> 
> 
> any suggestions are very much appreciated
> Karim
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From dave at evocapital.com  Wed Sep 10 19:21:22 2003
From: dave at evocapital.com (David Khabie-Zeitoune)
Date: Wed, 10 Sep 2003 18:21:22 +0100
Subject: [R] insert eps into microsft word
Message-ID: <8D0F30FE2EB3314182D4A33F738BB19D0BA76F@sqlsrvr.evocapital.com>

Have you tried win.metafile (I'm assuming you are using Windows)?
E.g.

win.metafile(file = "c:/test.wmf")
plot(rnorm(100))
dev.off()

WMF is a vectorised format (unlike jpeg or bmp) so should produce nice
scalable graphs.

-----Original Message-----
From: Karim Elsawy [mailto:elsawy at ysbl.york.ac.uk] 
Sent: 10 September 2003 18:12
To: r-help at stat.math.ethz.ch
Subject: [R] insert eps into microsft word


it seems that word can not read encapsupalted postscripts generated by R
I used this command

postscript("output.eps",horizontal=F,onefile=TRUE)
since onefile=TRUE produces an encapsualted postscript

actually what I'm trying to do is to insert the postsript file into a
word document since other formats like jpeg and bmp do not reproduce the
same quality like postscript formats


any suggestions are very much appreciated
Karim

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From MSchwartz at medanalytics.com  Wed Sep 10 19:22:24 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 10 Sep 2003 12:22:24 -0500
Subject: [R] insert eps into microsft word
In-Reply-To: <3F5F5B60.4E3ABEF@ysbl.york.ac.uk>
References: <3F5F5B60.4E3ABEF@ysbl.york.ac.uk>
Message-ID: <1063214543.32608.3.camel@localhost>

On Wed, 2003-09-10 at 12:12, Karim Elsawy wrote:
> it seems that word can not read encapsupalted postscripts generated by R
> I used this command
> 
> postscript("output.eps",horizontal=F,onefile=TRUE)
> since onefile=TRUE produces an encapsualted postscript
> 
> actually what I'm trying to do is to insert the postsript file into a
> word document
> since other formats like jpeg and bmp do not reproduce the same quality
> like postscript
> formats
> 
> 
> any suggestions are very much appreciated
> Karim


Try this syntax:

postscript("output.eps", horizontal = FALSE, onefile = FALSE, 
           paper = "special")

Take note of the instructions in the Details section of ?postscript and
also re-read the description of 'onefile' ('**' are my add):

"logical: if true (the default) allow multiple figures in one file. **If
false**, generate a file name containing the page number and use an EPSF
header and no DocumentMedia comment."

HTH,

Marc Schwartz



From Paul.Bayer at gleichsam.de  Wed Sep 10 19:27:08 2003
From: Paul.Bayer at gleichsam.de (Paul Bayer)
Date: Wed, 10 Sep 2003 19:27:08 +0200
Subject: [R] scan() problem
Message-ID: <012878AB-E3B4-11D7-99CA-0003936979C0@gleichsam.de>

Dear R-helpers,

I have to read some large csv-files into R (30 - 100MB).
Since reading with read.csv leads to "memory exhausted", I tried
with scan(), skipping not needed columns by NULL-elements in
"what".

When these skipped elements are quoted strings with commata inside,
R interprets each such quoted comma as element separator
leading to wrong records in the rest of the line.

A little test will show what I mean. I have the following "test.csv":

"col.A","col.B","col.C","col.D"
1,"quoted string","again, again again",123
2,"nice quotes, isnt it","you got it",456

First I read all elements:

 > tst <- scan("test.csv", what=list(a=0,b="",c="",d=0), sep=",", skip=1)
Read 2 records
 > tst
$a
[1] 1 2

$b
[1] "quoted string"        "nice quotes, isnt it"

$c
[1] "again, again again" "you got it"

$d
[1] 123 456

Everything is fine. Then I try to skip the 2nd column by giving b=NULL:

 > tst <- scan("test.csv", what=list(a=0,b=NULL,c="",d=0), sep=",", 
skip=1)
Read 2 records
Warning message:
number of items read is not a multiple of the number of columns
 > tst
$a
[1] 1 2

$b
NULL

$c
[1] "again, again again"            " isnt it,you got it,456\n\n\n"

$d
[1] 123  NA

 >

I got garbage.
Isn't this a bug?
Or did I something wrong?
Is there a workaround?

Thank you all,

Paul Bayer,
Feldafing, Germany



From christoph.lehmann at gmx.ch  Wed Sep 10 19:40:38 2003
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Wed, 10 Sep 2003 17:40:38 -0000
Subject: [R] PLS LDA
Message-ID: <1063215509.1159.3.camel@christophl>

Dear R experts
I saw and downloaded the fresh pls package for R. Is there any way of
using this pls package for PLS discriminant analysis? If not, is there
any other package available.

I need a way of classifying objects into e.g. two groups, where
nbr_observations << nbr_variables

many thanks for your kind help

Christoph
-- 
Christoph Lehmann <christoph.lehmann at gmx.ch>



From emb7 at st-andrews.ac.uk  Wed Sep 10 19:43:36 2003
From: emb7 at st-andrews.ac.uk (Martin Biuw)
Date: Wed, 10 Sep 2003 18:43:36 +0100
Subject: [R] insert eps into microsft word
In-Reply-To: <3F5F5B60.4E3ABEF@ysbl.york.ac.uk>
References: <3F5F5B60.4E3ABEF@ysbl.york.ac.uk>
Message-ID: <oprvaouy0e8xmvrg@gatty.st-and.ac.uk>

You can also add a Windows metafile preview to your eps image using for 
instance Ghostscript.

Martin

On Wed, 10 Sep 2003 18:12:00 +0100, Karim Elsawy <elsawy at ysbl.york.ac.uk> 
wrote:

> it seems that word can not read encapsupalted postscripts generated by R
> I used this command
>
> postscript("output.eps",horizontal=F,onefile=TRUE)
> since onefile=TRUE produces an encapsualted postscript
>
> actually what I'm trying to do is to insert the postsript file into a
> word document
> since other formats like jpeg and bmp do not reproduce the same quality
> like postscript
> formats
>
>
> any suggestions are very much appreciated
> Karim
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>



-- 
Martin Biuw
Sea Mammal Research Unit
Gatty Marine Laboratory, University of St Andrews
St Andrews, Fife KY16 8PA
Scotland
Ph: +44-(0)1334-462637
Fax: +44-(0)1334-462632
Web: http://smub.st.and.ac.uk



From ririzarr at jhsph.edu  Wed Sep 10 19:53:56 2003
From: ririzarr at jhsph.edu (Rafael A. Irizarry)
Date: Wed, 10 Sep 2003 13:53:56 -0400 (EDT)
Subject: [R] insert eps into microsft word
In-Reply-To: <3F5F5B60.4E3ABEF@ysbl.york.ac.uk>
Message-ID: <Pine.GSO.4.10.10309101350460.1369-100000@athena.biostat.jhsph.edu>

for word documents submitted to picky journals i usually use seomthing
like this:

bitmap("plot_1.png",width=6,height=6,res=600,pointsize=12,family="Times")

on my computer this resutls in quality  just as good (to mu eye) as with
postscript. you can also use adobe acrobat to convert postsctipt to
something else.

On Wed, 10 Sep 2003, Karim Elsawy wrote:

> it seems that word can not read encapsupalted postscripts generated by R
> I used this command
> 
> postscript("output.eps",horizontal=F,onefile=TRUE)
> since onefile=TRUE produces an encapsualted postscript
> 
> actually what I'm trying to do is to insert the postsript file into a
> word document
> since other formats like jpeg and bmp do not reproduce the same quality
> like postscript
> formats
> 
> 
> any suggestions are very much appreciated
> Karim
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From christoph.lehmann at gmx.ch  Wed Sep 10 19:52:31 2003
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Wed, 10 Sep 2003 17:52:31 -0000
Subject: [R] logistic regression for a data set with perfect separation
Message-ID: <1063216216.1159.11.camel@christophl>

Dear R experts

I have the follwoing data
          V1 V2
1 -5.8000000  0
2 -4.8000000  0
3 -2.8666667  0
4 -0.8666667  0
5 -0.7333333  0
6 -1.6666667  0
7 -0.1333333  1
8  1.2000000  1
9  1.3333333  1

and I want to know, whether V1 can predict V2: of course it can, since
there is a perfect separation between cases 1..6 and 7..9

How can I test, whether this conclusion (being able to assign an
observation i to class j, only knowing its value on Variable V1)  holds
also for the population, our data were drawn from? 

Means, which inference procedure is recommended? Logistic regression,
for obvious reasons makes no sense.

Many thanks for your help

Christoph
-- 
Christoph Lehmann <christoph.lehmann at gmx.ch>



From jccorrea at unalmed.edu.co  Wed Sep 10 20:19:29 2003
From: jccorrea at unalmed.edu.co (Juan Carlos Correa Morales)
Date: Wed, 10 Sep 2003 13:19:29 -0500 (GMT)
Subject: [R] logistic regression for a data set with perfect separation
In-Reply-To: <1063216216.1159.11.camel@christophl>
Message-ID: <Pine.GSO.4.44.0309101319180.11245-100000@eris.unalmed.edu.co>

Hi:
Look at

Rousseeuw, P. J. and Christmann, A. (2003) Robustness against separations
and outliers in logistic regression, Computational Statistics & Data
Analysis, Vol. 43, pp. 315-332

Juan Carlos Correa, Ph.D.
Escuela de Estadistica
Universidad Nacional- Sede Medellin
Medellin COLOMBIA


On Wed, 10 Sep 2003, Christoph Lehmann wrote:

> Dear R experts
>
> I have the follwoing data
>           V1 V2
> 1 -5.8000000  0
> 2 -4.8000000  0
> 3 -2.8666667  0
> 4 -0.8666667  0
> 5 -0.7333333  0
> 6 -1.6666667  0
> 7 -0.1333333  1
> 8  1.2000000  1
> 9  1.3333333  1
>
> and I want to know, whether V1 can predict V2: of course it can, since
> there is a perfect separation between cases 1..6 and 7..9
>
> How can I test, whether this conclusion (being able to assign an
> observation i to class j, only knowing its value on Variable V1)  holds
> also for the population, our data were drawn from?
>
> Means, which inference procedure is recommended? Logistic regression,
> for obvious reasons makes no sense.
>
> Many thanks for your help
>
> Christoph
> --
> Christoph Lehmann <christoph.lehmann at gmx.ch>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From david.firth at nuffield.oxford.ac.uk  Wed Sep 10 20:39:39 2003
From: david.firth at nuffield.oxford.ac.uk (David Firth)
Date: Wed, 10 Sep 2003 19:39:39 +0100
Subject: [R] logistic regression for a data set with perfect separation
In-Reply-To: <1063216216.1159.11.camel@christophl>
Message-ID: <22AE29C5-E3BE-11D7-B4CE-0050E4C03977@nuffield.oxford.ac.uk>

On Wednesday, Sep 10, 2003, at 18:50 Europe/London, Christoph Lehmann 
wrote:

> Dear R experts
>
> I have the follwoing data
>           V1 V2
> 1 -5.8000000  0
> 2 -4.8000000  0
> 3 -2.8666667  0
> 4 -0.8666667  0
> 5 -0.7333333  0
> 6 -1.6666667  0
> 7 -0.1333333  1
> 8  1.2000000  1
> 9  1.3333333  1
>
> and I want to know, whether V1 can predict V2: of course it can, since
> there is a perfect separation between cases 1..6 and 7..9
>
> How can I test, whether this conclusion (being able to assign an
> observation i to class j, only knowing its value on Variable V1)  holds
> also for the population, our data were drawn from?

For this you really need more data.  The only way you'll ever be able 
to reject that hypothesis is by finding an instance of 010 or 101 in 
the (ordered by V1) sample.  And if you find such then you can reject 
with certainty.

>
> Means, which inference procedure is recommended? Logistic regression,
> for obvious reasons makes no sense.

Not so obvious to me!  Logistic regression still makes sense, but care 
is needed in the method of estimation/inference.  The maximum 
likelihood solution in the above case is a model which says V2 is 1 
with certainty at some values of V1, and is zero with certainty at 
other values; and that seems an unwarranted inference with so little 
data.  That's a criticism of maximum likelihood, rather than a 
criticism of logistic regression.  (Think about the more extreme 
situation of tossing a coin once: if a head is observed, the ML 
solution is that the coin lands heads with certainty, ie that there no 
chance of tails.)

There are alternative (Bayesian and pseudo-Bayesian) methods of 
inference which can yield more sensible answers in general.  [One such 
is implemented in package brlr ("bias reduced logistic regression") on 
CRAN.]  To "test" the hypothesis described above, though, with the data 
you have, would seem to require a fully Bayesian analysis whose 
conclusions would depend strongly on the prior probability attached to 
the hypothesis.  ie you need more data...

I hope that helps in some way!

Regards,
David


>
> Many thanks for your help
>
> Christoph
> -- 
> Christoph Lehmann <christoph.lehmann at gmx.ch>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From szhan at uoguelph.ca  Wed Sep 10 20:48:12 2003
From: szhan at uoguelph.ca (szhan@uoguelph.ca)
Date: Wed, 10 Sep 2003 14:48:12 -0400
Subject: [R] how to calculate Spearman correlation with missing values
Message-ID: <1063219692.3f5f71ec2175a@webmail.uoguelph.ca>

Hello, there:
I got data matix with missing values. I want to calculate any possible 
pairwise Spearman correlation rho for each column. Is there a function just 
like cor(x, y, use="complete.obs") for Pearson correlation?
Thanks in advance!

Josh



From hothorn at ci.tuwien.ac.at  Wed Sep 10 21:01:23 2003
From: hothorn at ci.tuwien.ac.at (Torsten Hothorn)
Date: Wed, 10 Sep 2003 21:01:23 +0200 (CEST)
Subject: [R] how to calculate Spearman correlation with missing values
In-Reply-To: <1063219692.3f5f71ec2175a@webmail.uoguelph.ca>
Message-ID: <Pine.LNX.3.96.1030910210049.5174J-100000@thorin.ci.tuwien.ac.at>

On Wed, 10 Sep 2003 szhan at uoguelph.ca wrote:

> Hello, there:
> I got data matix with missing values. I want to calculate any possible 
> pairwise Spearman correlation rho for each column. Is there a function just 
> like cor(x, y, use="complete.obs") for Pearson correlation?
> Thanks in advance!
> 

?cor.test
                                                                            

> Josh
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
>



From gavin.simpson at ucl.ac.uk  Wed Sep 10 21:26:00 2003
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Wed, 10 Sep 2003 20:26:00 +0100
Subject: [R] insert eps into microsft word
In-Reply-To: <3F5F5B60.4E3ABEF@ysbl.york.ac.uk>
References: <3F5F5B60.4E3ABEF@ysbl.york.ac.uk>
Message-ID: <3F5F7AC8.4060700@ucl.ac.uk>

Depending on your version of Word that simply is *not* true!

I can't test this here (I now have Word XP/2002) but my colleagues have 
Word 97 on their college-supplied service (yes, really!) and despite not 
being able to see a preview, they can quite happily import eps files I 
have produced during the course of my work. Admitedly a blank box in 
word is not the most user-friendly thing to work with, but this old 
version of Word will happily deal with the postscript produced.

Having used Word 2000 and XP during the course of writing a PhD thesis 
that used R-generated plots extensively, I know first hand how easy it 
is to deal with eps files from R in Word.

My setup involves using Ghostscript/GSView on Windows XP to view the eps 
plots I produce in R and then import them into Word XP (the eps filter 
now seems to add a preview for you), but if you have an earlier word 
version, GSView can easily add a preview for you.

Also, onefile = TRUE does *not* produce eps files.

I quote from ?postscript :

  onefile: logical: if true (the default) allow multiple figures in one
           file.  If false, generate a file name containing the page
           number and use an EPSF header and no `DocumentMedia' comment.

It is a bit confusing, but onefile = TRUE is for producing multi-page 
postscript documents, i.e. put all the plots to follow into a single 
postscript doc with (possibly) more than a single page.

I know a number of people have suggested using a windows metafile. 
Whilst this might offer a solution to your problem, unless you are using 
a very-out-of-date version of Word I cannot see the advantages of using 
metafiles over postscript.

HTH

Gavin

Karim Elsawy wrote:

> it seems that word can not read encapsupalted postscripts generated by R
> I used this command
> 
> postscript("output.eps",horizontal=F,onefile=TRUE)
> since onefile=TRUE produces an encapsualted postscript
> 
> actually what I'm trying to do is to insert the postsript file into a
> word document
> since other formats like jpeg and bmp do not reproduce the same quality
> like postscript
> formats
> 
> 
> any suggestions are very much appreciated
> Karim
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpson at ucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From p.dalgaard at biostat.ku.dk  Wed Sep 10 21:29:43 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed, 10 Sep 2003 19:29:43 -0000
Subject: [R] insert eps into microsft word
In-Reply-To: <Pine.GSO.4.10.10309101350460.1369-100000@athena.biostat.jhsph.edu>
References: <Pine.GSO.4.10.10309101350460.1369-100000@athena.biostat.jhsph.edu>
Message-ID: <x2ad9cjv7p.fsf@biostat.ku.dk>

"Rafael A. Irizarry" <ririzarr at jhsph.edu> writes:

> for word documents submitted to picky journals i usually use seomthing
> like this:
> 
> bitmap("plot_1.png",width=6,height=6,res=600,pointsize=12,family="Times")
> 
> on my computer this resutls in quality  just as good (to mu eye) as with
> postscript. you can also use adobe acrobat to convert postsctipt to
> something else.

Word seems generally unhappy with PostScript, not just the files R
makes. One option that I have seen come out rather nicely is to have
the plots as PDF and use Adobe Distiller as the backend so that the
whole thing becomes a PDF file.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From Ted.Harding at nessie.mcc.ac.uk  Wed Sep 10 21:24:06 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Wed, 10 Sep 2003 20:24:06 +0100 (BST)
Subject: [R] logistic regression for a data set with perfect separati
In-Reply-To: <1063216216.1159.11.camel@christophl>
Message-ID: <XFMail.030910202406.Ted.Harding@nessie.mcc.ac.uk>

On 10-Sep-03 Christoph Lehmann wrote:
> I have the follwoing data
>           V1 V2
> 1 -5.8000000  0
> 2 -4.8000000  0
> 3 -2.8666667  0
> 4 -0.8666667  0
> 5 -0.7333333  0
> 6 -1.6666667  0
> 7 -0.1333333  1
> 8  1.2000000  1
> 9  1.3333333  1
> 
> and I want to know, whether V1 can predict V2: of course it can, since
> there is a perfect separation between cases 1..6 and 7..9
> 
> How can I test, whether this conclusion (being able to assign an
> observation i to class j, only knowing its value on Variable V1)  holds
> also for the population, our data were drawn from? 
> 
> Means, which inference procedure is recommended? Logistic regression,
> for obvious reasons makes no sense.

This is not so much an R question, nor really a "which procedure"
question, since standard procedures are not usually equipped to deal
with such situations (beyond telling you in some way that the situation
is "out of bounds").

However, you can certainly investigate it by writing little R programs
to look at it from various points of view.

Let 'm' denote the location parameter for the CDF which models the
probability, and 's' the scale parameter (e.g. a logistic function).

For a start, clearly the maximum of the likelihood is 1, achieved when
s=0 and m is any value between -0.7333.. and -0.1333..

You can investigate the variation of the likelihood as m and s vary
by evaluating expressions like

m<-(-.07);s<-1.0;L<-plogis((V1-m)/s);2*sum(V2*log(L)+(1-V2)*log(1-L))

For instance, for any value of s>0, find the value of m which maximises
this. Then you can get an indication about your question by looking
for the value of s such that this maximised value (with sign changed)
is just on (say) the 5% point of a chisq[df=1]; my gropings suggest
that s=0.8, m=(-0.1) (approx). This gives you a pair (m,s) which is
just consistent with your data by this criterion. What, for instance,
is the probability for any value of V1 that V2=1/0?

E.g. for m=-0.1,s=0.8, consider the range -2 <= x <=2 (step=0.1):
 m<-(-0.10);s<-0.8;x<-0.1*(-20:20);L<-plogis((x-m)/s);L
 [1] 0.08509905 0.09534946 0.10669059 0.11920292 0.13296424 0.14804720
 [7] 0.16451646 0.18242552 0.20181322 0.22270014 0.24508501 0.26894142
[13] 0.29421497 0.32082130 0.34864514 0.37754067 0.40733340 0.43782350
[19] 0.46879063 0.50000000 0.53120937 0.56217650 0.59266660 0.62245933
[25] 0.65135486 0.67917870 0.70578503 0.73105858 0.75491499 0.77729986
[31] 0.79818678 0.81757448 0.83548354 0.85195280 0.86703576 0.88079708
[37] 0.89330941 0.90465054 0.91490095 0.92414182 0.93245331

so that P(V2=1) can be substantial (>0.1) for V1 as low as -1.8,
and P(V2=0) likewise for V2 as high as +1.6; yet this (m,s) is not
"rejected" on likelihood grounds. So, in answer to your substantive
question, it would seem that your data do not support the generalisation
you are asking about.

And so on; you can plot things out, etc. You can do a simulation study:
for a given (m,s), say the pair above, and a set of V1 values like those
which you have, what is the probability that you get a set of results
(V2) which show "perfect separation"?:-- find what proportion of
simulations satisfy

  max(which(V1[V2==0])) < min(which(V1[V2==1]))

Explore a grid of (m,s) values and estimate this proportion; smooth the
estimates and plot a contour diagram ... and so on!

Use R as a tool for questions like this, and do not necessarily expect to
find a procedure which is tailor-made for (e.g.) this particular question!

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 10-Sep-03                                       Time: 20:24:06
------------------------------ XFMail ------------------------------



From bamelbourne at ucdavis.edu  Wed Sep 10 21:36:21 2003
From: bamelbourne at ucdavis.edu (Brett Melbourne)
Date: Wed, 10 Sep 2003 12:36:21 -0700
Subject: [R] insert eps into microsft word
References: <3F5F5B60.4E3ABEF@ysbl.york.ac.uk> <3F5F7AC8.4060700@ucl.ac.uk>
Message-ID: <015101c377d2$d0299750$af3eeda9@des.ucdavis.edu>

Your problem may also be that you can't get the figure to print from Word?

To get Word to print anything other than a blank box for the eps, you will
need to install and use a postscript printer driver for your printer.

cheers
Brett

Brett Melbourne, Postdoctoral Fellow
Biological Invasions IGERT www.cpb.ucdavis.edu/bioinv
Center for Population Biology, Storer Hall
University of California Davis CA 95616


----- Original Message ----- 
From: "Gavin Simpson" <gavin.simpson at ucl.ac.uk>
To: "Karim Elsawy" <elsawy at ysbl.york.ac.uk>
Cc: <r-help at stat.math.ethz.ch>
Sent: Wednesday, September 10, 2003 12:26 PM
Subject: Re: [R] insert eps into microsft word


> Depending on your version of Word that simply is *not* true!
>
> I can't test this here (I now have Word XP/2002) but my colleagues have
> Word 97 on their college-supplied service (yes, really!) and despite not
> being able to see a preview, they can quite happily import eps files I
> have produced during the course of my work. Admitedly a blank box in
> word is not the most user-friendly thing to work with, but this old
> version of Word will happily deal with the postscript produced.
>
> Having used Word 2000 and XP during the course of writing a PhD thesis
> that used R-generated plots extensively, I know first hand how easy it
> is to deal with eps files from R in Word.
>
> My setup involves using Ghostscript/GSView on Windows XP to view the eps
> plots I produce in R and then import them into Word XP (the eps filter
> now seems to add a preview for you), but if you have an earlier word
> version, GSView can easily add a preview for you.
>
> Also, onefile = TRUE does *not* produce eps files.
>
> I quote from ?postscript :
>
>   onefile: logical: if true (the default) allow multiple figures in one
>            file.  If false, generate a file name containing the page
>            number and use an EPSF header and no `DocumentMedia' comment.
>
> It is a bit confusing, but onefile = TRUE is for producing multi-page
> postscript documents, i.e. put all the plots to follow into a single
> postscript doc with (possibly) more than a single page.
>
> I know a number of people have suggested using a windows metafile.
> Whilst this might offer a solution to your problem, unless you are using
> a very-out-of-date version of Word I cannot see the advantages of using
> metafiles over postscript.
>
> HTH
>
> Gavin
>
> Karim Elsawy wrote:
>
> > it seems that word can not read encapsupalted postscripts generated by R
> > I used this command
> >
> > postscript("output.eps",horizontal=F,onefile=TRUE)
> > since onefile=TRUE produces an encapsualted postscript
> >
> > actually what I'm trying to do is to insert the postsript file into a
> > word document
> > since other formats like jpeg and bmp do not reproduce the same quality
> > like postscript
> > formats
> >
> >
> > any suggestions are very much appreciated
> > Karim
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> >
>
> -- 
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> Gavin Simpson                     [T] +44 (0)20 7679 5522
> ENSIS Research Fellow             [F] +44 (0)20 7679 7565
> ENSIS Ltd. & ECRC                 [E] gavin.simpson at ucl.ac.uk
> UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
> 26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
> London.  WC1H 0AP.
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From andy_liaw at merck.com  Wed Sep 10 21:50:42 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 10 Sep 2003 15:50:42 -0400
Subject: [R] PLS LDA
Message-ID: <3A822319EB35174CA3714066D590DCD50205CAF0@usrymx25.merck.com>

Do you mean the pls.pcr package by Prof. Wehrens?  This is what I do:

o  Code the two groups as 0s and 1s (numeric, not factor).

o  Run PLS as usual.  Cases with predicted values > 0.5 get 
   classified as 1s, otherwise as 0s.

o  Note that you need to modify the code inside the mvr() 
   function a bit if you want to use the built-in selection
   of number of LVs:  It selects the number that gives the
   best MSE, but what you really want is the number that
   gives the best error rate.  One trick is to discretize
   the predictions in {0, 1}, then the "MSE" will be error
   rate.

There are better ways to do this, but this works fairly well.

HTH,
Andy 

> -----Original Message-----
> From: Christoph Lehmann [mailto:christoph.lehmann at gmx.ch] 
> Sent: Wednesday, September 10, 2003 1:38 PM
> To: R-help at stat.math.ethz.ch
> Subject: [R] PLS LDA
> 
> 
> Dear R experts
> I saw and downloaded the fresh pls package for R. Is there 
> any way of using this pls package for PLS discriminant 
> analysis? If not, is there any other package available.
> 
> I need a way of classifying objects into e.g. two groups, 
> where nbr_observations << nbr_variables
> 
> many thanks for your kind help
> 
> Christoph
> -- 
> Christoph Lehmann <christoph.lehmann at gmx.ch>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> 

------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From christoph.lehmann at gmx.ch  Wed Sep 10 22:10:15 2003
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Wed, 10 Sep 2003 20:10:15 -0000
Subject: [R] PLS LDA
In-Reply-To: <3A822319EB35174CA3714066D590DCD50205CAF0@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD50205CAF0@usrymx25.merck.com>
Message-ID: <1063224483.2706.6.camel@christophl>

Hi Andy

Great and thanks a lot! Yes, it is the package from Prof. Wehrens. So I
just run the PLS like a Logistic Regression, coding the endogenous
variable as binary. 
So no need of specifying a binary-link function (as we have to when
using glm)?
And yes of course: I need the LVs which give the best error rate. What
do you mean by "discretize the predictions in {0, 1}"? Does this mean I
assign a prediction either a 0 (if predicted values <=0.5) or a 1 if the
predicted value is >0.5?
I need to dive into the package tomorrow, so that I better understand
the material, but is there any way of calculating e.g. a leaving-one-out
cross-validation error?

Thanks and best regards

Christoph

On Wed, 2003-09-10 at 21:50, Liaw, Andy wrote:
> Do you mean the pls.pcr package by Prof. Wehrens?  This is what I do:
> 
> o  Code the two groups as 0s and 1s (numeric, not factor).
> 
> o  Run PLS as usual.  Cases with predicted values > 0.5 get 
>    classified as 1s, otherwise as 0s.
> 
> o  Note that you need to modify the code inside the mvr() 
>    function a bit if you want to use the built-in selection
>    of number of LVs:  It selects the number that gives the
>    best MSE, but what you really want is the number that
>    gives the best error rate.  One trick is to discretize
>    the predictions in {0, 1}, then the "MSE" will be error
>    rate.
> 
> There are better ways to do this, but this works fairly well.
> 
> HTH,
> Andy 
> 
> > -----Original Message-----
> > From: Christoph Lehmann [mailto:christoph.lehmann at gmx.ch] 
> > Sent: Wednesday, September 10, 2003 1:38 PM
> > To: R-help at stat.math.ethz.ch
> > Subject: [R] PLS LDA
> > 
> > 
> > Dear R experts
> > I saw and downloaded the fresh pls package for R. Is there 
> > any way of using this pls package for PLS discriminant 
> > analysis? If not, is there any other package available.
> > 
> > I need a way of classifying objects into e.g. two groups, 
> > where nbr_observations << nbr_variables
> > 
> > many thanks for your kind help
> > 
> > Christoph
> > -- 
> > Christoph Lehmann <christoph.lehmann at gmx.ch>
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list 
> > https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> > 
> 
> ------------------------------------------------------------------------------
> Notice:  This e-mail message, together with any attachments,...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
-- 
Christoph Lehmann <christoph.lehmann at gmx.ch>



From jeaneid at chass.utoronto.ca  Wed Sep 10 22:28:25 2003
From: jeaneid at chass.utoronto.ca (Jean Eid)
Date: Wed, 10 Sep 2003 16:28:25 -0400
Subject: [R] coef names in lm 
Message-ID: <Pine.SGI.4.40.0309101616050.532605-100000@origin.chass.utoronto.ca>

Dear all,
I am interested in finding out how to change the names of coefficients in
the lm function. I have a design matrix which I called "design" where each
variate has its own name. However when I issue the command:

lm.1<-lm(response~design-1, weights=some.weights)

and follow it with:

summary(lm.1)

it seems to paste as a character the names of the variates
with design i.e I have something like:

designAge
designPlace
designOccupation
...
as names of coefficients and instead I just wanted to be
it seems to do
Age
Place
Occupation.

P.S.. the reason I need this is because I am using the xtable library to
turn output into latex tables and do not want to manually delete each and
every single "design" word in the coefficients name vector.

Thank you so much for any feedback,

Jean Eid



From andy_liaw at merck.com  Wed Sep 10 22:28:45 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 10 Sep 2003 16:28:45 -0400
Subject: [R] coef names in lm
Message-ID: <3A822319EB35174CA3714066D590DCD50205CAF2@usrymx25.merck.com>

If you coerce "design" into a data frame and then do

lm.1 <- lm(response ~ . - 1, data=design, ...)

that should work.

Andy

> -----Original Message-----
> From: Jean Eid [mailto:jeaneid at chass.utoronto.ca] 
> Sent: Wednesday, September 10, 2003 4:28 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] coef names in lm
> 
> 
> Dear all,
> I am interested in finding out how to change the names of 
> coefficients in the lm function. I have a design matrix which 
> I called "design" where each variate has its own name. 
> However when I issue the command:
> 
> lm.1<-lm(response~design-1, weights=some.weights)
> 
> and follow it with:
> 
> summary(lm.1)
> 
> it seems to paste as a character the names of the variates
> with design i.e I have something like:
> 
> designAge
> designPlace
> designOccupation
> ...
> as names of coefficients and instead I just wanted to be
> it seems to do
> Age
> Place
> Occupation.
> 
> P.S.. the reason I need this is because I am using the xtable 
> library to turn output into latex tables and do not want to 
> manually delete each and every single "design" word in the 
> coefficients name vector.
> 
> Thank you so much for any feedback,
> 
> Jean Eid
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> 

------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From rpeng at jhsph.edu  Wed Sep 10 22:30:51 2003
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 10 Sep 2003 16:30:51 -0400
Subject: [R] coef names in lm
In-Reply-To: <Pine.SGI.4.40.0309101616050.532605-100000@origin.chass.utoronto.ca>
References: <Pine.SGI.4.40.0309101616050.532605-100000@origin.chass.utoronto.ca>
Message-ID: <3F5F89FB.1080607@jhsph.edu>

Maybe this will work for you:

df <- as.data.frame(design)
lm.2 <- lm(response ~ ., df)

-roger

Jean Eid wrote:

>Dear all,
>I am interested in finding out how to change the names of coefficients in
>the lm function. I have a design matrix which I called "design" where each
>variate has its own name. However when I issue the command:
>
>lm.1<-lm(response~design-1, weights=some.weights)
>
>and follow it with:
>
>summary(lm.1)
>
>it seems to paste as a character the names of the variates
>with design i.e I have something like:
>
>designAge
>designPlace
>designOccupation
>...
>as names of coefficients and instead I just wanted to be
>it seems to do
>Age
>Place
>Occupation.
>
>P.S.. the reason I need this is because I am using the xtable library to
>turn output into latex tables and do not want to manually delete each and
>every single "design" word in the coefficients name vector.
>
>Thank you so much for any feedback,
>
>Jean Eid
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>  
>

-- 
Together, we can stop attaching Word documents
http://www.fsf.org/philosophy/no-word-attachments.html



From paulda at BATTELLE.ORG  Wed Sep 10 23:11:57 2003
From: paulda at BATTELLE.ORG (Paul, David  A)
Date: Wed, 10 Sep 2003 17:11:57 -0400
Subject: [R] regression questions
Message-ID: <940250A9EB37A24CBE28D858EF07774967AAF7@ws-bco-mse3.milky-way.battelle.org>

I have been puzzling over how to fit some fixed effects models
to a set of data.  My response function is

response <- function(a, b, c, alpha1, alpha2, indicator, t, t2)
{
	z = a + 
		b * (t) * exp(-alpha1 * t) +
		indicator *c * (t2) * exp(-alpha2 * t2)
}

where t2 = t - 4 and "indicator" is a 0-1 vector denoting
when t > 4.  Each test subject receives equal doses at t = 0 and 
t = 4.  The dose can vary from subject to subject.

Also note the following:
1.  Var(e[it]) = sigma1^2 for t<=4; Var(e[it]) = sigma2^2 for t>4.
	This is motivated by my data exploration.  
2.  b,c > 0 for biological interpretability
3.  t varies over {0,2,4,6,8,10}.  
4.  For a variety of reasons, "a", "alpha1", and "alpha2" must
	be held constant over all of the test subjects.

The function nlsList( ) is not appropriate because it assumes
that all of the parameters are allowed to vary with each level of
a specified grouping variable (in this case, "subject.id").  
I have been able to fit nls( ) models using the following 
syntax:

model.nls1 <- 
nls(y ~ response(10, b[subject.id], c[subject.id], alpha1, alpha2, 
			    indicator, t, t2),
			 data = foo.frame, 
			 start = list(b = rep(25,12), c = rep(100,12), 
					    alpha1 = 0.5, alpha2 = 0.5), 
			 trace = T)

The start values were motivated by some data exploration, and
the results appear to be stable.  The value "a=10" was fixed also
as a result of the initial data exploration, and appears necessary
in order for the model to be stable.

Unfortunately, the estimated b- and c-values for several subjects are
negative.  Also, nls( ) does not allow a "weights = " statement
like gnls( ) does.  When I try

model.nls1 <- 
gnls(y ~ response(10, b[subject.id], c[subject.id], alpha1, alpha2, 
			    indicator, t, t2),
			 data = foo.frame, 
			 start = list(b = rep(25,12), c = rep(100,12), 
					    alpha1 = 0.5, alpha2 = 0.5), 
			 trace = T)

I get the message "Error in eval(expr, envir, enclos) : Object "b" not
found"
This surprises me, since my understanding is that gnls( ) is essentially
nls( ) but with "weights = " and "correlation = " options.  I suppose
that separate fixed effects for each subject could be estimated from
gnls( ) if I created a separate indicator variable for each subject and
added them to the data frame (I have not yet done this); however, this 
does not address the need for the b,c parameters to be constrained
greater than zero.


I would gratefully welcome suggestions.


Much thanks in advance,
   david paul



From kvanhorn at ksvanhorn.com  Thu Sep 11 01:03:51 2003
From: kvanhorn at ksvanhorn.com (Kevin S. Van Horn)
Date: Wed, 10 Sep 2003 17:03:51 -0600
Subject: [R] Computing a CDF or many quantiles
In-Reply-To: <XFMail.030909232853.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.030909232853.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <3F5FADD7.8030404@ksvanhorn.com>

Your method looks like a naive reimplementation of integration, and 
won't work so well for distributions that have the great majority of the 
probability mass concentrated in a small fraction of the sample space. 
 I was hoping for something that would retain the adaptability of 
integrate().

(Ted Harding) wrote:

>If that's all you want to do, then a very straightfoward approach should
>be OK. I illustrate with a truncated normal distribution on [-1,1]:
>
>  x <- (-1)+(0.001*(0:2000));pdf<-dnorm(x); pdf<-pdf/(sum(pdf)*0.001)
>  CDF<-cumsum(pdf)*0.001
>  plot(x,pdf,ylim=c(0,1),type="l");lines(x,CDF)
>
>Quantiles:
>  N=10;e<-CDF[1];
>  for(i in (0:10)){
>      j<-max(which(CDF<=i/N+e));print(c(x[j],CDF[j]))
>  }
>  
>



From jerome at hivnet.ubc.ca  Thu Sep 11 01:24:34 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Wed, 10 Sep 2003 16:24:34 -0700
Subject: [R] Computing a CDF or many quantiles
In-Reply-To: <3F5FADD7.8030404@ksvanhorn.com>
References: <XFMail.030909232853.Ted.Harding@nessie.mcc.ac.uk>
	<3F5FADD7.8030404@ksvanhorn.com>
Message-ID: <200309102323.QAA03906@hivnet.ubc.ca>

On September 10, 2003 04:03 pm, Kevin S. Van Horn wrote:
>
> Your method looks like a naive reimplementation of integration, and
> won't work so well for distributions that have the great majority of the
> probability mass concentrated in a small fraction of the sample space.
>  I was hoping for something that would retain the adaptability of
> integrate().

Yesterday, I've suggested to use approxfun(). Did you consider my 
suggestion? Below is an example.

N <- 500
x <- rexp(N)
y <- rank(x)/(N+1)
empCDF <- approxfun(x,y)
xvals <- seq(0,4,.01)
plot(xvals,empCDF(xvals),type="l",
xlab="Quantile",ylab="Cumulative Distribution Function")
lines(xvals,pexp(xvals),lty=2)
legend(2,.4,c("Empirical CDF","Exact CDF"),lty=1:2)


It's possible to tune in some parameters in approxfun() to better match 
your personal preferences. Have a look at help(approxfun) for details.

HTH,
Jerome Asselin



From jerome at hivnet.ubc.ca  Thu Sep 11 01:40:22 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Wed, 10 Sep 2003 16:40:22 -0700
Subject: [R] Computing a CDF or many quantiles
In-Reply-To: <200309102323.QAA03906@hivnet.ubc.ca>
References: <XFMail.030909232853.Ted.Harding@nessie.mcc.ac.uk>
	<3F5FADD7.8030404@ksvanhorn.com>
	<200309102323.QAA03906@hivnet.ubc.ca>
Message-ID: <200309102339.QAA04503@hivnet.ubc.ca>


Also look at ecdf() from package "stepfun".

HTH,
Jerome Asselin



From Alexander.Herr at csiro.au  Thu Sep 11 02:23:53 2003
From: Alexander.Herr at csiro.au (Alexander.Herr@csiro.au)
Date: Thu, 11 Sep 2003 10:23:53 +1000
Subject: [R] Customised legend in lattice
Message-ID: <2FE6D3D02CCDD211B80600902745F56C01E2772E@exchange-tv.tvl.qld.csiro.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030911/9888f2fa/attachment.pl

From ggrothendieck at volcanomail.com  Thu Sep 11 03:24:11 2003
From: ggrothendieck at volcanomail.com (Gabor Grothendieck)
Date: Wed, 10 Sep 2003 18:24:11 -0700 (PDT)
Subject: [R] scan() problem
Message-ID: <20030911012411.3FB1042DF@sitemail.everyone.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030910/ae671698/attachment.pl

From Philippe.Hupe at curie.fr  Thu Sep 11 09:54:32 2003
From: Philippe.Hupe at curie.fr (=?ISO-8859-1?Q?Philippe_Hup=E9?=)
Date: Thu, 11 Sep 2003 09:54:32 +0200
Subject: [R] how to insert a double quote with the paste function?
Message-ID: <3F602A38.4050501@curie.fr>

Hello,

I would like to write in a variable the following string :

Hello "World"

If I do cat("Hello ","\"World\""), I have the good result on the screen 
but it can not be affected to a variable. If I do the same thing with 
paste paste("Hello ","\"World\"") it does not work since \" seems to be 
not recognized. So what is the trick to do that.

Thanks,

Philippe
-- 

--------------------------------------------------

Philippe Hup?
Institut Curie - Equipe Bioinformatique
26, rue d'Ulm - 75005 PARIS France
+33 (0)1 44 32 42 75

Philippe.Hupe at curie.fr <mailto:Philippe.Hupe at curie.fr>



From dave at evocapital.com  Thu Sep 11 10:04:19 2003
From: dave at evocapital.com (David Khabie-Zeitoune)
Date: Thu, 11 Sep 2003 09:04:19 +0100
Subject: [R] Flipping a heatmap
Message-ID: <8D0F30FE2EB3314182D4A33F738BB19D0BA775@sqlsrvr.evocapital.com>

Hi

I am using the heatmap function in package mva to look at large
correlation matrices visually.
Is there any way to "flip" the output of heatmap plot left-right so
that, if presented with a correlation matrix, it plots the unity
elements in the correlation matrix along a diagonal from top left to
bottom right?

For example:

library(mva)
x = matrix(rnorm(1000), ncol=10)
z = cor(x)
heatmap(z)

Heatmap calls image, and I've found ways to do it with image e.g:

image(z[1:10,10:1]) 

will plot things the "right" way round, but

heatmap(z[1:10,10:1]) 

does not.

Any help much appreciated.
Cheers,
Dave



From glaziou at pasteur-kh.org  Thu Sep 11 10:10:21 2003
From: glaziou at pasteur-kh.org (Philippe Glaziou)
Date: Thu, 11 Sep 2003 15:10:21 +0700
Subject: [R] how to insert a double quote with the paste function?
In-Reply-To: <3F602A38.4050501@curie.fr>
References: <3F602A38.4050501@curie.fr>
Message-ID: <20030911081021.GB654@pasteur-kh.org>

Philippe Hup? <Philippe.Hupe at curie.fr> wrote:
> I would like to write in a variable the following string :
> 
> Hello "World"
> 
> If I do cat("Hello ","\"World\""), I have the good result on the screen 
> but it can not be affected to a variable. If I do the same thing with 
> paste paste("Hello ","\"World\"") it does not work since \" seems to be 
> not recognized. So what is the trick to do that.


How about:

> h<-'hello "World"'
> h
[1] "hello \"World\""
> cat(h, "\n")
hello "World"
> 

-- 
Philippe Glaziou
Institut Pasteur du Cambodge



From dave at evocapital.com  Thu Sep 11 10:15:07 2003
From: dave at evocapital.com (David Khabie-Zeitoune)
Date: Thu, 11 Sep 2003 09:15:07 +0100
Subject: [R] how to insert a double quote with the paste function?
Message-ID: <8D0F30FE2EB3314182D4A33F738BB19D0BA777@sqlsrvr.evocapital.com>

Philippe

You seem to have the right answer already, unless I misunderstand...

If I define:

> x = "Hello \"World\""
Then the default print method for this character string will give the rather ugly looking:

> x
[1] "Hello \"World\""

But this is just R telling us that it does recognise the escape sequence \". If we pass this variable to a more output-friendly function like cat, we get:

> cat(x)
Hello "World"

So the variable x really does contain  'Hello "World"', it's just that R's default print method will show the escape characters used in a string. 




-----Original Message-----
From: Philippe Hup? [mailto:Philippe.Hupe at curie.fr] 
Sent: 11 September 2003 08:55
To: 'r-help at stat.math.ethz.ch'
Subject: [R] how to insert a double quote with the paste function?


Hello,

I would like to write in a variable the following string :

Hello "World"

If I do cat("Hello ","\"World\""), I have the good result on the screen 
but it can not be affected to a variable. If I do the same thing with 
paste paste("Hello ","\"World\"") it does not work since \" seems to be 
not recognized. So what is the trick to do that.

Thanks,

Philippe
-- 

--------------------------------------------------

Philippe Hup?
Institut Curie - Equipe Bioinformatique
26, rue d'Ulm - 75005 PARIS France
+33 (0)1 44 32 42 75

Philippe.Hupe at curie.fr <mailto:Philippe.Hupe at curie.fr>

______________________________________________
R-help at stat.math.ethz.ch mailing list https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Thu Sep 11 10:18:31 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 11 Sep 2003 09:18:31 +0100 (BST)
Subject: [R] how to insert a double quote with the paste function?
In-Reply-To: <3F602A38.4050501@curie.fr>
Message-ID: <Pine.LNX.4.44.0309110916040.27926-100000@gannet.stats>

On Thu, 11 Sep 2003, Philippe Hup? wrote:

> I would like to write in a variable the following string :
> 
> Hello "World"
> 
> If I do cat("Hello ","\"World\""), I have the good result on the screen 
> but it can not be affected to a variable. If I do the same thing with 
> paste paste("Hello ","\"World\"") it does not work since \" seems to be 
> not recognized. So what is the trick to do that.

It is recognized:

> xx <- paste("Hello ","\"World\"") 
> print(xx)
[1] "Hello  \"World\""
> cat(xx, "\n")
Hello  "World" 
> print(xx, quote=FALSE)
[1] Hello  "World"

It's likely that it is the behaviour of print() you did not understand: 
the quote appears by itself in the character string but is escaped when 
printed within quotes.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From pburns at pburns.seanet.com  Thu Sep 11 10:24:53 2003
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Thu, 11 Sep 2003 09:24:53 +0100
Subject: [R] how to insert a double quote with the paste function?
References: <3F602A38.4050501@curie.fr>
Message-ID: <3F603155.9090702@pburns.seanet.com>

The paste is doing the right thing -- it is how it is displayed
that matters:

 > jj <- paste("hello", "\"world\"")
 > jj
[1] "hello \"world\""
 > cat(jj)
hello "world"> print(jj, quote=FALSE)
[1] hello "world"

Patrick Burns

Burns Statistics
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

Philippe Hup? wrote:

> Hello,
>
> I would like to write in a variable the following string :
>
> Hello "World"
>
> If I do cat("Hello ","\"World\""), I have the good result on the 
> screen but it can not be affected to a variable. If I do the same 
> thing with paste paste("Hello ","\"World\"") it does not work since \" 
> seems to be not recognized. So what is the trick to do that.
>
> Thanks,
>
> Philippe



From peter.adorjan at epigenomics.com  Thu Sep 11 11:08:33 2003
From: peter.adorjan at epigenomics.com (Peter Adorjan)
Date: Thu, 11 Sep 2003 11:08:33 +0200
Subject: [R] Job opening: Biostatistician
Message-ID: <3F603B91.3040306@epigenomics.com>

I hope this this could be of interest for some of you,
Thanks,
Peter Adorjan


      Biostatistics Expert (Berlin, Germany)

     You will develop and apply statistical techniques for the analysis, 
visualization and quality control of high-dimensional and complex 
biomedical data sets (mainly DNA microarray data). You will support 
clinical study design in diagnostics and pharmaceutical research. You 
will develop new methods and implement algorithms for statistical data 
analysis. You will analyze data from scientific studies and clinical 
trials in close cooperation with life scientists and external partners. 
You will document and present results internally and externally.

You hold a university degree (MS, PhD) in statistics, computer science 
or a related field. You have good knowledge and working experience with 
multivariate statistical methods. Experience in medical or 
pharmaceutical research and experience analyzing DNA microarray data is 
a strong plus. Solid analytical skills are essential and experience with 
machine learning methods is ideal. You master R/S-Plus or another 
statistical language; you have good software development skills (C++ or 
Java, databases). You can efficiently turn ideas into practical 
solutions. You are an independent, creative scientist with excellent 
communication skills. You are able to plan and supervise research and 
also provide effective solutions within a constrained time. You know how 
to work in an international environment (working language English) at an 
interdisciplinary nodal position between the life sciences and 
statistics. Ideally, you have experience in project- and/or team-management.

Position is available immediately.

Epigenomics` offices are attractively located in downtown Berlin and we 
offer positions with a high degree of responsibility in an exciting and 
dynamic work atmosphere. We offer a competitive compensation package.
Human Resources Dept.
Kleine Pr?sidentenstr. 1
D-10178 Berlin, Germany
http://www.epigenomics.com
Email: careers at epigenomics.com



From davidD at qimr.edu.au  Thu Sep 11 02:25:45 2003
From: davidD at qimr.edu.au (David Duffy)
Date: Thu, 11 Sep 2003 10:25:45 +1000 (EST)
Subject: [R] Re: logistic regression {R-help Digest ..}
In-Reply-To: <200309101017.h8AAAbA5014324@stat.math.ethz.ch>
References: <200309101017.h8AAAbA5014324@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.50.0309111021520.26594-100000@orpheus.qimr.edu.au>

On Tue, 9 Sep 2003 Christoph Lehmann <christoph.lehmann at gmx.ch> wrote:
> I have the following data
>           V1 V2
> 1 -5.8000000  0
> 2 -4.8000000  0
> 3 -2.8666667  0
> 4 -0.8666667  0
> 5 -0.7333333  0
> 6 -1.6666667  0
> 7 -0.1333333  1
> 8  1.2000000  1
> 9  1.3333333  1
> 
> and I want to know, whether V1 can predict V2: of course it can, since
> there is a perfect separation between cases 1..6 and 7..9
> 
> How can I test, whether this conclusion (being able to assign an
> observation i to class j, only knowing its value on Variable V1)  holds
> also for the population, our data were drawn from? 

The brlr package does this:

summary(brlr(V2 ~ V1))

brlr(formula = V2 ~ V1)
 
Coefficients:
            Value  Std. Error t value
(Intercept) 0.2620 1.0624     0.2466
V1          1.4014 1.0077     1.3908
 
Deviance: 3.5078
Penalized deviance: 3.528
Residual df: 7


-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From andy_liaw at merck.com  Thu Sep 11 13:46:16 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 11 Sep 2003 07:46:16 -0400
Subject: [R] Flipping a heatmap
Message-ID: <3A822319EB35174CA3714066D590DCD50205CAFB@usrymx25.merck.com>

My feeling is that heatmap is not the right thing to use on a correlation
matrix.  The heatmap function expects a data matrix, and does a two-way
clustering of cases and variables.  It tries to rearrange the rows and
columns so that similar colors are closer together.  This obviously will not
work for a correlation matrix.  (The rearrangement is one of several
enhancements that Robert/Martin added to my original attempt.)

If you really want to do it, you may try to find my original naive version
of the heatmap function, which I posted to the Bioconductor mailing list
earlier this year.  That does not do any rearragement.

HTH,
Andy

> -----Original Message-----
> From: David Khabie-Zeitoune [mailto:dave at evocapital.com] 
> Sent: Thursday, September 11, 2003 4:04 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Flipping a heatmap
> 
> 
> Hi
> 
> I am using the heatmap function in package mva to look at 
> large correlation matrices visually. Is there any way to 
> "flip" the output of heatmap plot left-right so that, if 
> presented with a correlation matrix, it plots the unity 
> elements in the correlation matrix along a diagonal from top 
> left to bottom right?
> 
> For example:
> 
> library(mva)
> x = matrix(rnorm(1000), ncol=10)
> z = cor(x)
> heatmap(z)
> 
> Heatmap calls image, and I've found ways to do it with image e.g:
> 
> image(z[1:10,10:1]) 
> 
> will plot things the "right" way round, but
> 
> heatmap(z[1:10,10:1]) 
> 
> does not.
> 
> Any help much appreciated.
> Cheers,
> Dave
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> 

------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From nandi at statlab.uni-heidelberg.de  Thu Sep 11 13:46:18 2003
From: nandi at statlab.uni-heidelberg.de (Swagata Nandi)
Date: Thu, 11 Sep 2003 13:46:18 +0200
Subject: [R] Problem in installing quantreg package
Message-ID: <3F60608A.9060508@statlab.uni-heidelberg.de>

I was trying to install package "quantreg" in an R session, but I got 
the follwing error message:

ERROR: cannot write to or create directory '/usr/lib/R/library'.

Can anyone suggest what I need to do to fix it up?

Swagata Nandi



From nandi at statlab.uni-heidelberg.de  Thu Sep 11 13:48:20 2003
From: nandi at statlab.uni-heidelberg.de (Swagata Nandi)
Date: Thu, 11 Sep 2003 13:48:20 +0200 (CEST)
Subject: [R] Problem in installing "quantreg" package
Message-ID: <Pine.LNX.4.44.0309111346440.16493-100000@taper.statlab.uni-heidelberg.de>


Hi,

I was trying to install "quantreg" package in an R session, but got the
following error message:

ERROR: cannot write to or create directory '/usr/lib/R/library'

Can anyone suggest what I need to do?

Swagata Nandi



From maechler at stat.math.ethz.ch  Thu Sep 11 14:43:21 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 11 Sep 2003 14:43:21 +0200
Subject: [R] Flipping a heatmap
In-Reply-To: <3A822319EB35174CA3714066D590DCD50205CAFB@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD50205CAFB@usrymx25.merck.com>
Message-ID: <16224.28137.257081.372173@gargle.gargle.HOWL>

>>>>> "AndyL" == Liaw, Andy <andy_liaw at merck.com>
>>>>>     on Thu, 11 Sep 2003 07:46:16 -0400 writes:

    AndyL> My feeling is that heatmap is not the right thing to
    AndyL> use on a correlation matrix.  
definitely.

    AndyL> The heatmap function expects a data matrix, and does
    AndyL> a two-way clustering of cases and variables.  It
    AndyL> tries to rearrange the rows and columns so that
    AndyL> similar colors are closer together.  This obviously
    AndyL> will not work for a correlation matrix.  (The
    AndyL> rearrangement is one of several enhancements that
    AndyL> Robert/Martin added to my original attempt.)

    AndyL> If you really want to do it, you may try to find my
    AndyL> original naive version of the heatmap function, which
    AndyL> I posted to the Bioconductor mailing list earlier
    AndyL> this year.  That does not do any rearragement.

Thank you, Andy.  
Further note that the upcoming version of R will also allow the
option of *not* doing any reordering. 

But even then, heatmap() is not quite appropriate for
correlation matrices.

    AndyL> HTH,
    AndyL> Andy

    >> -----Original Message-----
    >> From: David Khabie-Zeitoune [mailto:dave at evocapital.com] 
    >> Sent: Thursday, September 11, 2003 4:04 AM
    >> To: r-help at stat.math.ethz.ch
    >> Subject: [R] Flipping a heatmap
    >> 
    >> 
    >> Hi
    >> 
    >> I am using the heatmap function in package mva to look at 
    >> large correlation matrices visually. Is there any way to 
    >> "flip" the output of heatmap plot left-right so that, if 
    >> presented with a correlation matrix, it plots the unity 
    >> elements in the correlation matrix along a diagonal from top 
    >> left to bottom right?
    >> 
    >> For example:
    >> 
    >> library(mva)
    >> x = matrix(rnorm(1000), ncol=10)
    >> z = cor(x)
    >> heatmap(z)
    >> 
    >> Heatmap calls image, and I've found ways to do it with image e.g:
    >> 
    >> image(z[1:10,10:1]) 
    >> 
    >> will plot things the "right" way round, but
    >> 
    >> heatmap(z[1:10,10:1]) 
    >> 
    >> does not.
    >> 
    >> Any help much appreciated.
    >> Cheers,
    >> Dave



From ripley at stats.ox.ac.uk  Thu Sep 11 14:46:54 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 11 Sep 2003 13:46:54 +0100 (BST)
Subject: [R] Problem in installing quantreg package
In-Reply-To: <3F60608A.9060508@statlab.uni-heidelberg.de>
Message-ID: <Pine.LNX.4.44.0309111345380.3144-100000@gannet.stats>

On Thu, 11 Sep 2003, Swagata Nandi wrote:

> I was trying to install package "quantreg" in an R session, but I got 
> the follwing error message:
> 
> ERROR: cannot write to or create directory '/usr/lib/R/library'.
> 
> Can anyone suggest what I need to do to fix it up?

Use the account you used to install R, or install to another library tree
whihc you do own: install.packages (which I presume you used) has a `lib'
argument.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dmurdoch at pair.com  Thu Sep 11 14:53:03 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu, 11 Sep 2003 08:53:03 -0400
Subject: [R] Flipping a heatmap
In-Reply-To: <3A822319EB35174CA3714066D590DCD50205CAFB@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD50205CAFB@usrymx25.merck.com>
Message-ID: <r0s0mvkul1uo4g2q6uuamp1kturge06d97@4ax.com>

On Thu, 11 Sep 2003 07:46:16 -0400, you wrote:

>My feeling is that heatmap is not the right thing to use on a correlation
>matrix.  The heatmap function expects a data matrix, and does a two-way
>clustering of cases and variables.  It tries to rearrange the rows and
>columns so that similar colors are closer together.  This obviously will not
>work for a correlation matrix.  

There are several different ways you might organize the rows and
columns of a correlation matrix, but rearranging it to put equal
correlations together sounds like one sensible idea.  You'd probably
want row and column labels rather than the dendrogram heatmap() puts
on, but other than that, it seems like a nice idea to me.

Duncan Murdoch



From rpeng at jhsph.edu  Thu Sep 11 15:04:00 2003
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu, 11 Sep 2003 09:04:00 -0400
Subject: [R] Problem in installing "quantreg" package
In-Reply-To: <Pine.LNX.4.44.0309111346440.16493-100000@taper.statlab.uni-heidelberg.de>
References: <Pine.LNX.4.44.0309111346440.16493-100000@taper.statlab.uni-heidelberg.de>
Message-ID: <3F6072C0.7040900@jhsph.edu>

You probably do not have permission to write to that directory (and you 
need write permission to install a package).  I assume you are on Unix?  
Either ask your system administrator to install it for you or install it 
into a directory where you have permission.  For example, I make a 
subdirectory called "R-local" in my home directory for installing my own 
packages.  Look at ?Startup to see how you can get R to recognize your 
local package directory.

-roger

Swagata Nandi wrote:

>Hi,
>
>I was trying to install "quantreg" package in an R session, but got the
>following error message:
>
>ERROR: cannot write to or create directory '/usr/lib/R/library'
>
>Can anyone suggest what I need to do?
>
>Swagata Nandi
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>  
>

-- 
Together, we can stop attaching Word documents
http://www.fsf.org/philosophy/no-word-attachments.html



From laurent.faisnel at ariase.com  Thu Sep 11 15:13:45 2003
From: laurent.faisnel at ariase.com (Laurent Faisnel)
Date: Thu, 11 Sep 2003 15:13:45 +0200
Subject: [R] Problem in installing "quantreg" package
References: <Pine.LNX.4.44.0309111346440.16493-100000@taper.statlab.uni-heidelberg.de>
Message-ID: <3F607509.909@ariase.com>

Swagata Nandi wrote:
> Hi,
> 
> I was trying to install "quantreg" package in an R session, but got the
> following error message:
> 
> ERROR: cannot write to or create directory '/usr/lib/R/library'
> 
> Can anyone suggest what I need to do?
> 
> Swagata Nandi
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

You probably have not the right to write in that directory. You should 
either ask your system's administrator to grant you the needed 
privileges or find another directory in which you can write an then read 
the package's doc to find out any configuration option to specify the 
installation directory).

Hope this helps,
Laurent



From nandi at statlab.uni-heidelberg.de  Thu Sep 11 14:33:21 2003
From: nandi at statlab.uni-heidelberg.de (Swagata Nandi)
Date: Thu, 11 Sep 2003 14:33:21 +0200 (CEST)
Subject: [R] Problem in installing "quantreg" package
In-Reply-To: <3F6072C0.7040900@jhsph.edu>
Message-ID: <Pine.LNX.4.44.0309111432420.16493-100000@taper.statlab.uni-heidelberg.de>


Thanks, I could install it as superuser.

Swagata.

On Thu, 11 Sep 2003, Roger D. Peng wrote:

> You probably do not have permission to write to that directory (and you
> need write permission to install a package).  I assume you are on Unix?
> Either ask your system administrator to install it for you or install it
> into a directory where you have permission.  For example, I make a
> subdirectory called "R-local" in my home directory for installing my own
> packages.  Look at ?Startup to see how you can get R to recognize your
> local package directory.
>
> -roger
>
> Swagata Nandi wrote:
>
> >Hi,
> >
> >I was trying to install "quantreg" package in an R session, but got the
> >following error message:
> >
> >ERROR: cannot write to or create directory '/usr/lib/R/library'
> >
> >Can anyone suggest what I need to do?
> >
> >Swagata Nandi
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> >
> >
>
> --
> Together, we can stop attaching Word documents
> http://www.fsf.org/philosophy/no-word-attachments.html
>
>
>



From dave at evocapital.com  Thu Sep 11 16:57:23 2003
From: dave at evocapital.com (David Khabie-Zeitoune)
Date: Thu, 11 Sep 2003 15:57:23 +0100
Subject: [R] Flipping a heatmap
Message-ID: <8D0F30FE2EB3314182D4A33F738BB19D0BA784@sqlsrvr.evocapital.com>

Thanks to everyone who replied on this subject. Clearly, two rows of the
correlation matrix which have similar numerical entries represent two
variables which have similar correlations with the other variables.
Therefore clustering using a distance metric (e.g. dist) defined on the
rows (or equivalently columns) of the correlation matrix produces an
ordering which lumps together correlated variables. This had been my
original thinking (if a little fuzzy), but I've decided now to do the
clustering on the data matrix directly and just do an image plot of the
resulting re-ordered correlation matrix.

If any one else has good ideas about how to visualise correlation
structures in large correlation matrices, I'd love to hear them, on- or
off-line.

-----Original Message-----
From: Duncan Murdoch [mailto:dmurdoch at pair.com] 
Sent: 11 September 2003 13:53
To: r-help at stat.math.ethz.ch
Subject: Re: [R] Flipping a heatmap


On Thu, 11 Sep 2003 07:46:16 -0400, you wrote:

>My feeling is that heatmap is not the right thing to use on a 
>correlation matrix.  The heatmap function expects a data matrix, and 
>does a two-way clustering of cases and variables.  It tries to 
>rearrange the rows and columns so that similar colors are closer 
>together.  This obviously will not work for a correlation matrix.

There are several different ways you might organize the rows and columns
of a correlation matrix, but rearranging it to put equal correlations
together sounds like one sensible idea.  You'd probably want row and
column labels rather than the dendrogram heatmap() puts on, but other
than that, it seems like a nice idea to me.

Duncan Murdoch

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From maechler at stat.math.ethz.ch  Thu Sep 11 17:33:03 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 11 Sep 2003 17:33:03 +0200
Subject: [R] Flipping a heatmap
In-Reply-To: <16224.28137.257081.372173@gargle.gargle.HOWL>
References: <3A822319EB35174CA3714066D590DCD50205CAFB@usrymx25.merck.com>
	<16224.28137.257081.372173@gargle.gargle.HOWL>
Message-ID: <16224.38319.306281.869474@gargle.gargle.HOWL>

After some off-line discussion I want to correct my earlier
post:
It's clear (even to me ;-) that the idea of reordering columns
(and rows simultaneously for symmetric matrices) and then
image()ing is very appropriate for correlation matrices.
BTW, this has been quite an old idea, going back to
Bertin (1983) and probably much longer.

What I rather meant to say was that currently heatmap() isn't
setup to support this use very well.  But even there I wasn't
quite correct, since you can achieve quite a bit by using the
`Rowv' and `Colv' arguments.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><


>>>>> "MM" == Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Thu, 11 Sep 2003 14:43:21 +0200 writes:

>>>>> "AndyL" == Liaw, Andy <andy_liaw at merck.com>
>>>>>     on Thu, 11 Sep 2003 07:46:16 -0400 writes:

    AndyL> My feeling is that heatmap is not the right thing to
    AndyL> use on a correlation matrix.  
    MM> definitely.

    AndyL> The heatmap function expects a data matrix, and does
    AndyL> a two-way clustering of cases and variables.  It
    AndyL> tries to rearrange the rows and columns so that
    AndyL> similar colors are closer together.  This obviously
    AndyL> will not work for a correlation matrix.  (The
    AndyL> rearrangement is one of several enhancements that
    AndyL> Robert/Martin added to my original attempt.)

    AndyL> If you really want to do it, you may try to find my
    AndyL> original naive version of the heatmap function, which
    AndyL> I posted to the Bioconductor mailing list earlier
    AndyL> this year.  That does not do any rearragement.

    MM> Thank you, Andy.  
    MM> Further note that the upcoming version of R will also allow the
    MM> option of *not* doing any reordering. 

    MM> But even then, heatmap() is not quite appropriate for
    MM> correlation matrices.

    AndyL> HTH,
    AndyL> Andy

    >>> -----Original Message-----
    >>> From: David Khabie-Zeitoune [mailto:dave at evocapital.com] 
    >>> Sent: Thursday, September 11, 2003 4:04 AM
    >>> To: r-help at stat.math.ethz.ch
    >>> Subject: [R] Flipping a heatmap
    >>> 
    >>> 
    >>> Hi
    >>> 
    >>> I am using the heatmap function in package mva to look at 
    >>> large correlation matrices visually. Is there any way to 
    >>> "flip" the output of heatmap plot left-right so that, if 
    >>> presented with a correlation matrix, it plots the unity 
    >>> elements in the correlation matrix along a diagonal from top 
    >>> left to bottom right?
    >>> 
    >>> For example:
    >>> 
    >>> library(mva)
    >>> x = matrix(rnorm(1000), ncol=10)
    >>> z = cor(x)
    >>> heatmap(z)
    >>> 
    >>> Heatmap calls image, and I've found ways to do it with image e.g:
    >>> 
    >>> image(z[1:10,10:1]) 
    >>> 
    >>> will plot things the "right" way round, but
    >>> 
    >>> heatmap(z[1:10,10:1]) 
    >>> 
    >>> does not.
    >>> 
    >>> Any help much appreciated.
    >>> Cheers,
    >>> Dave



From Arne.Muller at aventis.com  Thu Sep 11 17:09:38 2003
From: Arne.Muller at aventis.com (Arne.Muller@aventis.com)
Date: Thu, 11 Sep 2003 17:09:38 +0200
Subject: [R] R book
Message-ID: <C80ECAFA2ACC1B45BE45D133ED660ADECDCAF5@crbsmxsusr04.pharma.aventis.com>

Hi All,

I'd be interested in your opinions of the book

"Introductory Statistics with R" by Peter Dalgaard 

Does it well describe the R object concept, the language itself and
statistical aspects (I am not a statistician)?

	thanks for your opinion,

	Arne



From peter.schlattmann at medizin.fu-berlin.de  Thu Sep 11 17:46:09 2003
From: peter.schlattmann at medizin.fu-berlin.de (Dr. Peter Schlattmann)
Date: Thu, 11 Sep 2003 17:46:09 +0200 (CEST)
Subject: [R] predict and nlem
Message-ID: <33298.160.45.195.78.1063295169.squirrel@www.medizin.fu-berlin.de>

Dear all,

I want to predict a new observation with nlme using fixed and random
effects estimates from a previous fit. How can I do this? (My problem is
different from the Loblolly example)

Thanks a lot!
Peter



From diriano at rz.uni-potsdam.de  Thu Sep 11 18:08:35 2003
From: diriano at rz.uni-potsdam.de (diriano@rz.uni-potsdam.de)
Date: Thu, 11 Sep 2003 18:08:35 +0200
Subject: [R] Loading Distance matrices and PCA
Message-ID: <1063296515.3f609e0349fac@mail.uni-potsdam.de>

Hi All

I am really new into R, and I would like to know if it is possible to load a
distance file matrix (lower-triangular) into R and then do a PCA or
Multidimensional Scaling over that matrix.

I would apreciate any help,
Thanks

Diego Riano

-- 

Diego Mauricio Riano Pachon
Biologist
Institute of Biology and Biochemistry
University of Potsdam
Karl-Liebknecht-Str. 24-25
Haus 20
14476 Golm
Germany
Tel:0331/977-2809
http://bioinf.ibun.unal.edu.co/~gotem
http://www.geocities.com/dmrp.geo/



From ripley at stats.ox.ac.uk  Thu Sep 11 18:33:12 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 11 Sep 2003 17:33:12 +0100 (BST)
Subject: [R] Loading Distance matrices and PCA
In-Reply-To: <1063296515.3f609e0349fac@mail.uni-potsdam.de>
Message-ID: <Pine.LNX.4.44.0309111731390.3800-100000@gannet.stats>

On Thu, 11 Sep 2003 diriano at rz.uni-potsdam.de wrote:

> I am really new into R, and I would like to know if it is possible to load a
> distance file matrix (lower-triangular) into R and then do a PCA or
> Multidimensional Scaling over that matrix.

No, yes, as PCA is not defined for a distance matrix but MDS is.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From f.mercier at fr.fournierpharma.com  Thu Sep 11 19:06:53 2003
From: f.mercier at fr.fournierpharma.com (f.mercier@fr.fournierpharma.com)
Date: Thu, 11 Sep 2003 19:06:53 +0200
Subject: =?iso-8859-1?Q?R=E9f=2E_=3A_[R]_Loading_Distance_matrices_and_PCA?=
Message-ID: <OFB1C39D97.F4AB6B8E-ONC1256D9E.005DEBC8@fournier.fr>


Hi Diego,
I think that some function from the package "ade4" can do this.
F





                                                                                                                                            
                      diriano at rz.uni-potsda                                                                                                 
                      m.de                          Pour :   r-help at stat.math.ethz.ch                                                       
                      Envoy? par :                  cc :                                                                                    
                      r-help-bounces at stat.m         Objet :  [R] Loading Distance matrices and PCA                                          
                      ath.ethz.ch                                                                                                           
                                                                                                                                            
                                                                                                                                            
                      11/09/03 18:08                                                                                                        
                                                                                                                                            
                                                                                                                                            




Hi All

I am really new into R, and I would like to know if it is possible to load
a
distance file matrix (lower-triangular) into R and then do a PCA or
Multidimensional Scaling over that matrix.

I would apreciate any help,
Thanks

Diego Riano

--

Diego Mauricio Riano Pachon
Biologist
Institute of Biology and Biochemistry
University of Potsdam
Karl-Liebknecht-Str. 24-25
Haus 20
14476 Golm
Germany
Tel:0331/977-2809
http://bioinf.ibun.unal.edu.co/~gotem
http://www.geocities.com/dmrp.geo/

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jortiz at kent.edu  Thu Sep 11 19:14:43 2003
From: jortiz at kent.edu (Joseph Ortiz)
Date: Thu, 11 Sep 2003 13:14:43 -0400
Subject: [R] Cross-platform compatibility with R?
Message-ID: <6F8FD1B3-E47B-11D7-BD75-000A95840136@kent.edu>

Dear All,

Thanks to all of the individuals who responded to my question regarding 
cross-platform compatibility with R.
My problem turned out to be incompatible versions of R on two machines. 
I was able to upgrade to consistent
versions of R on my linux and OSX boxes and transfer files and 
directories directly from one machine to another
using compressed tar archives.

To summarize the responses, the following methods can be used to 
transfer files  by ftp or physical media between
R installs on different machines and OS systems:

1. tar and compress files
2. Use the R dump and source commands
3. Use the R save and load commands

Cheers,
Joe
______________________________________________

Dr. Joseph D. Ortiz
Assistant Professor - Geology
Kent State University
336 McGilvrey Hall
P.O. Box 5190
Kent, OH 44242-0001
Phone: 330-672-2225
FAX: 330-672-7949
email: jortiz at kent.edu
Web: http://www.personal.kent.edu/~jortiz/home/



From jasont at indigoindustrial.co.nz  Thu Sep 11 20:37:39 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Thu, 11 Sep 2003 18:37:39 -0000
Subject: [R] R book
In-Reply-To: <C80ECAFA2ACC1B45BE45D133ED660ADECDCAF5@crbsmxsusr04.pharma.aventis.com>
References: <C80ECAFA2ACC1B45BE45D133ED660ADECDCAF5@crbsmxsusr04.pharma.aventis.com>
Message-ID: <1063305960.4445.8.camel@kryten.indigoindustrial.co.nz>

On Fri, 2003-09-12 at 03:09, Arne.Muller at aventis.com wrote:
> Hi All,
> 
> I'd be interested in your opinions of the book
> 
> "Introductory Statistics with R" by Peter Dalgaard 
> 
> Does it well describe the R object concept, the language itself and
> statistical aspects (I am not a statistician)?


The title of the book is accurate.  It's concerned mostly with
introducing statistics gently, and is very kind to non-statisticians. 
It teaches enough R to perform the statistics it teaches (table of
contents should be available online from your favorite online
bookstore), but doesn't get deeply into the language itself.  

I find it a good book for a gentle introduction; once you're past the
stage of needing it, it's a good "loaner" to coleagues who don't yet use
R.  "Here, borrow this for a week, and if you find it helps, buy a
copy". 

After graduating from this book, the next sensible purchase is "Modern
Applied Statistics with S" (Venables and Ripley).

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
+64-(0)21-343-545



From dyang at nrcan.gc.ca  Thu Sep 11 21:11:09 2003
From: dyang at nrcan.gc.ca (Yang, Richard)
Date: Thu, 11 Sep 2003 15:11:09 -0400
Subject: [R] Rgui access violation
Message-ID: <F0E0B899CB43D5118D220002A55113CF02F927CB@s2-edm-r1.nofc.cfs.nrcan.gc.ca>

Dear All;

	While using EMclust() in the mclust package, I frequently
encountered a program error. A message window popped up with the message "
Rgui.exe has generated errors and will be closed by Windows. You will need
to restart the program. An error log is be created."
	



> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    7.1            
year     2003           
month    06             
day      16             
language R



From dyang at nrcan.gc.ca  Thu Sep 11 21:20:06 2003
From: dyang at nrcan.gc.ca (Yang, Richard)
Date: Thu, 11 Sep 2003 15:20:06 -0400
Subject: [R] Rgui access violation
Message-ID: <F0E0B899CB43D5118D220002A55113CF02F927CC@s2-edm-r1.nofc.cfs.nrcan.gc.ca>

I apologize for accidentally sent the incompleted message. The crash
relating to memory size. By increasing the memory limit to 512 MB seems to
solve the problem.

Richard

> 
> Dear All;
> 
> 	While using EMclust() in the mclust package, I frequently
> encountered a program error. A message window popped up with 
> the message "
> Rgui.exe has generated errors and will be closed by Windows. 
> You will need
> to restart the program. An error log is be created."
> 	
> 
> 
> 
> > version
>          _              
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    1              
> minor    7.1            
> year     2003           
> month    06             
> day      16             
> language R
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From ligges at statistik.uni-dortmund.de  Thu Sep 11 21:37:05 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 11 Sep 2003 21:37:05 +0200
Subject: [R] Rgui access violation
References: <F0E0B899CB43D5118D220002A55113CF02F927CC@s2-edm-r1.nofc.cfs.nrcan.gc.ca>
Message-ID: <3F60CEE1.CC5A9498@statistik.uni-dortmund.de>


"Yang, Richard" wrote:
> 
> I apologize for accidentally sent the incompleted message. The crash
> relating to memory size. By increasing the memory limit to 512 MB seems to
> solve the problem.
> 
> Richard
> 
> >
> > Dear All;
> >
> >       While using EMclust() in the mclust package, I frequently
> > encountered a program error. A message window popped up with
> > the message "
> > Rgui.exe has generated errors and will be closed by Windows.
> > You will need
> > to restart the program. An error log is be created."

Since most probably the mclust package causes the crash, you might want
to ask its maintainer, Ron Wehrens <rwehrens at sci.kun.nl>.

Uwe Ligges


> >
> >
> >
> > > version
> >          _
> > platform i386-pc-mingw32
> > arch     i386
> > os       mingw32
> > system   i386, mingw32
> > status
> > major    1
> > minor    7.1
> > year     2003
> > month    06
> > day      16
> > language R
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From dmurdoch at pair.com  Thu Sep 11 21:50:53 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu, 11 Sep 2003 15:50:53 -0400
Subject: [R] Rgui access violation
In-Reply-To: <F0E0B899CB43D5118D220002A55113CF02F927CB@s2-edm-r1.nofc.cfs.nrcan.gc.ca>
References: <F0E0B899CB43D5118D220002A55113CF02F927CB@s2-edm-r1.nofc.cfs.nrcan.gc.ca>
Message-ID: <dck1mvsqacq9c1t2i5jbshsj8k8n5at12a@4ax.com>

On Thu, 11 Sep 2003 15:11:09 -0400, "Yang, Richard"
<dyang at nrcan.gc.ca> wrote :

>Dear All;
>
>	While using EMclust() in the mclust package, I frequently
>encountered a program error. A message window popped up with the message "
>Rgui.exe has generated errors and will be closed by Windows. You will need
>to restart the program. An error log is be created."

mclust is a contributed package; the maintainer is Ron Wehrens
<rwehrens at sci.kun.nl>.  Could you try to work with him to figure out
what's going wrong?  

Duncan Murdoch



From dautran at ira.cinvestav.mx  Thu Sep 11 21:48:44 2003
From: dautran at ira.cinvestav.mx (Daphne Autran)
Date: Thu, 11 Sep 2003 14:48:44 -0500
Subject: [R] Using R for microarrays datas analysis by Mixed model ANOVA. lme
	function.
Message-ID: <BB863BCC.281%dautran@ira.cinvestav.mx>

Hi, 
We are using R to analyse microarrays datas by ANOVA.
We would like to set up Mixed Model analysis, using the "lme" function
within the nmle package.
However, we have problem in understanding and getting the right formula to
build a "groupedData" object which appear to be required for lme to work.
I ve read all the available nmle package s Users guides and manuals, but
explications are scarce.

Does anybody have an experience in using this function for microarrays datas
analysis and could send me informations or, if possible, a resolved exemple
(input table of datas, formula of the model, ouput...) ?

Maybe other R functions are usefull and easier to implement Mixed Models
ANOVA for microarrays analysis, any suggestions ?

I thank you in advance for your reply.
Sincerely 

Daphne Autran 


    

    Dr Daphne Autran

    Laboratory of Reproductive Development and Apomixis
    Department of Genetic Ingeniering
    CINVESTAV - Unidad Irapuato
    Km 9,6 Libramiento Norte
    A.P.629 
    C.P. 36500 Irapuato Guanajuato
    MEXICO 
    
    Tel : (0052) 462 623 9600 ext.404
    Fax : (0052) 462 624 5849
    Email : dautran at ira.cinvestav.mx



From spencer.graves at pdf.com  Thu Sep 11 22:05:31 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 11 Sep 2003 13:05:31 -0700
Subject: [R] Using R for microarrays datas analysis by Mixed model ANOVA.
	lme	function.
References: <BB863BCC.281%dautran@ira.cinvestav.mx>
Message-ID: <3F60D58B.3040109@pdf.com>

1.  Have you consulted Pinhiero and Bates (2000) Mixed-Effects Models in 
S and S-Plus (Springer)?  This is the standard (almost indispensible) 
reference on "lme".

2.  Are you familiar with the Bioconductor project 
(www.bioconductor.org)?  The have a substantial library of software for 
analyzing microarray data.

hope this helps.  spencer graves

Daphne Autran wrote:
> Hi, 
> We are using R to analyse microarrays datas by ANOVA.
> We would like to set up Mixed Model analysis, using the "lme" function
> within the nmle package.
> However, we have problem in understanding and getting the right formula to
> build a "groupedData" object which appear to be required for lme to work.
> I ve read all the available nmle package s Users guides and manuals, but
> explications are scarce.
> 
> Does anybody have an experience in using this function for microarrays datas
> analysis and could send me informations or, if possible, a resolved exemple
> (input table of datas, formula of the model, ouput...) ?
> 
> Maybe other R functions are usefull and easier to implement Mixed Models
> ANOVA for microarrays analysis, any suggestions ?
> 
> I thank you in advance for your reply.
> Sincerely 
> 
> Daphne Autran 
> 
> 
>     
> 
>     Dr Daphne Autran
> 
>     Laboratory of Reproductive Development and Apomixis
>     Department of Genetic Ingeniering
>     CINVESTAV - Unidad Irapuato
>     Km 9,6 Libramiento Norte
>     A.P.629 
>     C.P. 36500 Irapuato Guanajuato
>     MEXICO 
>     
>     Tel : (0052) 462 623 9600 ext.404
>     Fax : (0052) 462 624 5849
>     Email : dautran at ira.cinvestav.mx
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From nj7w at virginia.edu  Thu Sep 11 22:22:09 2003
From: nj7w at virginia.edu (Nitin Jain)
Date: Thu, 11 Sep 2003 16:22:09 -0400 (EDT)
Subject: [R] S+DOX eqivalent in R?
In-Reply-To: <mailman.721.1063311305.6569.r-help@stat.math.ethz.ch>
Message-ID: <Pine.A41.4.32.0309111616470.16788-100000@node6.unix.Virginia.EDU>

Dear List,

I am looking for a function `Pseudo standard error' (PSE), which is
available in S+ DOX (design of experiemnt) module - Is there a similar
function available in R?

Reference for PSE function is in the paper:
'Quick and easy analysis of unreplicated factorials' by Russell V. Lenth,
Technometrics, 1989, 31, 4, 469-473.

Thanks.
-Nitin



From deepayan at stat.wisc.edu  Thu Sep 11 23:12:15 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 11 Sep 2003 16:12:15 -0500
Subject: [R] Customised legend in lattice
In-Reply-To: <2FE6D3D02CCDD211B80600902745F56C01E2772E@exchange-tv.tvl.qld.csiro.au>
References: <2FE6D3D02CCDD211B80600902745F56C01E2772E@exchange-tv.tvl.qld.csiro.au>
Message-ID: <200309111612.15517.deepayan@stat.wisc.edu>


On Wednesday 10 September 2003 19:23, Alexander.Herr at csiro.au wrote:

> ######------- Not working part------------------XXXXXXXXXXXXXXXXXXXXXXX
> update(plot4, key = list(corner=c(0,1), x=0.65, y=0.35,
>                           lines=list(c(1:2),col="black",lwd=1,lty=c(1:2)),
>                             text=list(c("category 1","category 2")),
>                           points=list(c(1:5),col=colo[1:5],pch=19),
>                             text=list(leg.txt),
>                      )
>        )

This does work as it was intended to, though the documentation is not very 
clear. However, what you were trying to do seems very reasonable, so I've 
modified (though not thoroughly tested yet) the appropriate function to allow 
a new (logical) component 'rep' in the key list. After you source() the 
attached file, something like


leg.txt<-c("Rating 1","Rating 2","Rating 3","Rating 4","Rating 5")
colo<-rep(c("black","red","darkgreen","navyblue","rosybrown"),2)

xyplot(1 ~ 1,
       key =
       list(corner=c(0,1),
            x=0.65, y=0.35,
            text=list(c("category 1","category 2")),
            lines=list(col="black", lwd = 1, lty=c(1:2)),
            points=list(col=colo[1:5],pch=19),
            text=list(leg.txt)))

should continue to give the current behaviour, but

xyplot(1 ~ 1,
       key =
       list(corner=c(0,1),
            x=0.65, y=0.35,
            rep = FALSE,
            text=list(c("category 1","category 2")),
            lines=list(col="black", lwd = 1, lty=c(1:2)),
            points=list(col=colo[1:5],pch=19),
            text=list(leg.txt)))

should give you what you want.

Deepayan


-------------- next part --------------

draw.key <- function(key, draw = FALSE, vp = NULL)
{
    if (!is.list(key)) stop("key must be a list")
    
    max.length <- 0
    ## maximum of the `row-lengths' of the above
    ## components. There is some scope for confusion
    ## here, e.g., if col is specified in key as a
    ## length 6 vector, and then lines=list(lty=1:3),
    ## what should be the length of that lines column ?
    ## If 3, what happens if lines=list() ?
    ## (Strangely enough, S+ accepts lines=list()
    ## if col (etc) is NOT specified outside, but not
    ## if it is)
    
    process.key <-
        function(between = 2,
                 align = TRUE,
                 title = NULL,
                 rep = TRUE,
                 background = trellis.par.get("background")$col,
                 border = FALSE,
                 transparent = FALSE, 
                 columns = 1,
                 divide = 3,
                 between.columns = 3,
                 cex = 1,
                 cex.title = 1.5 * max(cex),
                 col = "black", 
                 lty = 1,
                 lwd = 1,
                 font = 1, 
                 pch = 8,
                 adj = 0,
                 type = "l", 
                 size = 5, 
                 angle = 0, 
                 density = -1,
                 ...)
        {
            list(between = between,
                 align = align,
                 title = title,
                 rep = rep,
                 background = background,
                 border = border,
                 transparent = transparent, 
                 columns = columns,
                 divide = divide,
                 between.columns = between.columns,
                 cex = cex,
                 cex.title = cex.title,
                 col = col,
                 lty = lty,
                 lwd = lwd,
                 font = font, 
                 pch = pch,
                 adj = adj,
                 type = type, 
                 size = size, 
                 angle = angle, 
                 density = density,
                 ...)
        }

    default.fontsize <- trellis.par.get("fontsize")$default

    key <- do.call("process.key", key)

    key.length <- length(key)
    key.names <- names(key)    # Need to update
    if (is.logical(key$border)) 
        key$border <-
            if (key$border) "black"
            else "transparent"

    components <- list()

    for(i in 1:key.length) {

        curname <- pmatch(key.names[i], c("text", "rectangles", "lines", "points"))

        if (is.na(curname)) {
            ;## do nothing
        }
        else if (curname == 1) { # "text"
            if (!(is.characterOrExpression(key[[i]][[1]])))
                stop("first component of text has to be vector of labels")
            pars <- list(labels = key[[i]][[1]],
                         col = key$col,
                         adj = key$adj,
                         cex = key$cex,
                         font = key$font)
            key[[i]][[1]] <- NULL
            pars[names(key[[i]])] <- key[[i]]

            tmplen <- length(pars$labels)
            for (j in 1:length(pars))
                if (is.character(pars))
                    pars[[j]] <- rep(pars[[j]], length = tmplen)

            max.length <- max(max.length, tmplen)
            components[[length(components)+1]] <-
                list(type = "text", pars = pars, length = tmplen)

        }
        else if (curname == 2) { # "rectangles"

            pars <- list(col = key$col,
                         size = key$size,
                         angle = key$angle,
                         density = key$density)
            
            pars[names(key[[i]])] <- key[[i]]

            tmplen <- max(unlist(lapply(pars,length)))
            max.length <- max(max.length, tmplen)
            components[[length(components)+1]] <-
                list(type = "rectangles", pars = pars, length = tmplen)
            
        }
        else if (curname == 3) { # "lines"

            pars <- list(col = key$col,
                         size = key$size,
                         lty = key$lty,
                         cex = key$cex,
                         lwd = key$lwd,
                         type = key$type)

            pars[names(key[[i]])] <- key[[i]]

            tmplen <- max(unlist(lapply(pars,length)))
            max.length <- max(max.length, tmplen)
            components[[length(components)+1]] <-
                list(type = "lines", pars = pars, length = tmplen)
            
        }
        else if (curname == 4) { # "points"

            pars <- list(col = key$col,
                         cex = key$cex,
                         pch = key$pch)
                         
            pars[names(key[[i]])] <- key[[i]]

            tmplen <- max(unlist(lapply(pars,length)))
            max.length <- max(max.length, tmplen)
            components[[length(components)+1]] <-
                list(type = "points", pars = pars, length = tmplen)

        }
    }


    
    number.of.components <- length(components)
    ## number of components named one of "text",
    ## "lines", "rectangles" or "points"
    if (number.of.components == 0)
        stop("Invalid key, need at least one component named lines, text, rect or points")

    ## The next part makes sure all components have same length,
    ## except text, which should be as long as the number of labels

    ## Update (9/11/2003): but that doesn't always make sense --- Re:
    ## r-help message from Alexander.Herr at csiro.au (though it seems
    ## that's S+ behaviour on Linux at least). Each component should
    ## be allowed to have its own length (that's what the lattice docs
    ## suggest too, don't know why). Anyway, I'm adding a rep = TRUE
    ## argument to the key list, which controls whether each column
    ## will be repeated as necessary to have the same length.

    
    for (i in 1:number.of.components)
        if (components[[i]]$type != "text") {
            components[[i]]$pars <-
                lapply(components[[i]]$pars, rep,
                       length = if (key$rep) max.length
                       else components[[i]]$length)
            if (key$rep) components[[i]]$length <- max.length
        }
        else{
            ## NB: rep doesn't work with expressions of length > 1
            components[[i]]$pars <-
                c(components[[i]]$pars[1],
                  lapply(components[[i]]$pars[-1], rep,
                         length = components[[i]]$length))
        }

    column.blocks <- key$columns
    rows.per.block <- ceiling(max.length/column.blocks)

    if (column.blocks > max.length) warning("not enough rows for columns")
    
    key$between <- rep(key$between, length = number.of.components)

    
    if (key$align) {

        ## Setting up the layout


	## The problem of allocating space for text (character strings
	## or expressions) is dealt with as follows: 

	## Each row and column will take exactly as much space as
	## necessary. As steps in the construction, a matrix
	## textMatrix (of same dimensions as the layout) will contain
	## either 0, meaning that entry is not text, or n > 0, meaning
	## that entry has the text given by textList[[n]], where
	## textList is a list consisting of character strings or
	## expressions.



        n.row <- rows.per.block + 1
        n.col <- column.blocks * (1 + 3 * number.of.components) - 1

	textMatrix <- matrix(0, n.row, n.col)
	textList <- list()
	textCex <- numeric(0)

        heights.x <- rep(1, n.row)
        heights.units <- rep("lines", n.row)
        heights.data <- as.list(1:n.row)

        if (key$title != "" && is.characterOrExpression(key$title)) {
            heights.x[1] <- 1.2 * key$cex.title
            heights.units[1] <- "strheight"
            heights.data[[1]] <- key$title
        }
        else heights.x[1] <- 0


        widths.x <- rep(key$between.column, n.col)
        widths.units <- rep("strwidth", n.col)
        widths.data <- as.list(rep("o", n.col))



        for (i in 1:column.blocks) {
            widths.x[(1:number.of.components-1)*3+1 +
                     (i-1)*3*number.of.components + i-1] <-
                         key$between/2
            
            widths.x[(1:number.of.components-1)*3+1 +
                     (i-1)*3*number.of.components + i+1] <-
                         key$between/2
        }
    
        
	index <- 1

        for (i in 1:number.of.components) {

            cur <- components[[i]]

            id <- (1:column.blocks - 1) *
                (number.of.components * 3 + 1) + i * 3 - 1

            if (cur$type == "text") {

                for (j in 1:cur$length) {

                    colblck <- ceiling(j / rows.per.block)

                    xx <- (colblck - 1) *
                        (number.of.components * 3 + 1) + i * 3 - 1

                    yy <- j %% rows.per.block + 1
                    if (yy == 1) yy <- rows.per.block + 1

		    textMatrix[yy, xx] <- index
		    textList <- c(textList, list(cur$pars$labels[j]) )
		    textCex <- c(textCex, cur$pars$cex[j])
  		    index <- index + 1

		}


            } ## FIXME: do the same as above for those below
            else if (cur$type == "rectangles") {
                widths.x[id] <- max(cur$pars$size)
            }
            else if (cur$type == "lines") {
                widths.x[id] <- max(cur$pars$size)
            }
            else if (cur$type == "points") {
                widths.x[id] <- max(cur$pars$cex)
            }
        }


        ## Need to adjust the heights and widths 
        
        ## adjusting heights
        heights.insertlist.position <- 0
        heights.insertlist.unit <- unit(1, "null")

        for (i in 1:n.row) {
            textLocations <- textMatrix[i,]
            textLocations <- textLocations[textLocations>0]
            if (any(textLocations)) {

                strbar <- textList[textLocations]
                heights.insertlist.position <- c(heights.insertlist.position, i)
                heights.insertlist.unit <-
                    unit.c(heights.insertlist.unit,
                           unit(.2, "lines") + max(unit(textCex[textLocations], "strheight", strbar)))
            }
        }


        layout.heights <- unit(heights.x, heights.units, data=heights.data)
        if (length(heights.insertlist.position)>1)
            for (indx in 2:length(heights.insertlist.position))
                layout.heights <-
                    rearrangeUnit(layout.heights, heights.insertlist.position[indx],
                                  heights.insertlist.unit[indx])





        ## adjusting widths
        widths.insertlist.position <- 0
        widths.insertlist.unit <- unit(1, "null")




        for (i in 1:n.col) {
            textLocations <- textMatrix[,i]
            textLocations <- textLocations[textLocations>0]
            if (any(textLocations)) {

                strbar <- textList[textLocations]
                widths.insertlist.position <- c(widths.insertlist.position, i)
                widths.insertlist.unit <-
                    unit.c(widths.insertlist.unit,
                           max(unit(textCex[textLocations], "strwidth", strbar)))
            }
        }


        layout.widths <- unit(widths.x, widths.units, data=widths.data)
        if (length(widths.insertlist.position)>1)
            for (indx in 2:length(widths.insertlist.position))
                layout.widths <-
                    rearrangeUnit(layout.widths, widths.insertlist.position[indx],
                                  widths.insertlist.unit[indx])


        key.layout <- grid.layout(nrow = n.row, ncol = n.col,
                                  widths = layout.widths,
                                  heights = layout.heights,
                                  respect = FALSE)

        ## OK, layout set up, now to draw the key - no

        
        key.gf <- grid.frame(layout = key.layout, vp = vp,
                             gp = gpar(fontsize = default.fontsize),
                             draw = FALSE)

        if (!key$transparent) {
            grid.place(key.gf,
                       grid.rect(gp=gpar(fill = key$background, col = key$border),
                                 draw = FALSE),
                       draw = FALSE, row = NULL, col = NULL)
        }
        else
            grid.place(key.gf,
                       grid.rect(gp=gpar(col=key$border), draw = FALSE),
                       draw = FALSE, row = NULL, col = NULL)

        ## Title
        if (!is.null(key$title))
            grid.place(key.gf, 
                       grid.text(label = key$title, draw = FALSE,
                                 gp = gpar(fontsize = default.fontsize * key$cex.title)),
                       row=1, col = NULL, draw = FALSE)
        

        
        for (i in 1:number.of.components) {

            cur <- components[[i]]

            for (j in 1:cur$length) {

                colblck <- ceiling(j / rows.per.block)

                xx <- (colblck - 1) *
                    (number.of.components*3 + 1) + i*3 - 1

                yy <- j %% rows.per.block + 1
                if (yy == 1) yy <- rows.per.block + 1

                if (cur$type == "text") {
                    
                    grid.place(key.gf, 
                               grid.text(x = cur$pars$adj[j],
                                         just = c(
                                         if (cur$pars$adj[j] == 1) "right"
                                         else if (cur$pars$adj[j] == 0) "left"
                                         else "center",
                                         "center"),
                                         label = cur$pars$labels[j],
                                         gp = gpar(col = cur$pars$col[j],
                                         font = cur$pars$font[j],
                                         fontsize = default.fontsize * cur$pars$cex[j]),
                                         draw = FALSE),
                               row = yy, col = xx, draw = FALSE)
                    
                }
                else if (cur$type == "rectangles") {
                    grid.place(key.gf, 
                              grid.rect(width = cur$pars$size[j]/max(cur$pars$size),
                                        ## centred, unlike Trellis, due to aesthetic reasons !
                                        gp = gpar(fill = cur$pars$col[j]), 
                                        draw = FALSE),
                              row = yy, col = xx, draw = FALSE)
                    
                    ## Need to make changes to support angle/density
                }
                else if (cur$type == "lines") {
                    if (cur$pars$type[j] == "l") {
                        grid.place(key.gf,
                                  grid.lines(x = c(0,1) * cur$pars$size[j]/max(cur$pars$size),
                                             ## ^^ this should be centered as well, but since the
                                             ## chances that someone would actually use this feature
                                             ## are astronomical, I'm leaving that for later.
                                             y = c(.5, .5),
                                             gp = gpar(col = cur$pars$col[j],
                                             lty = cur$pars$lty[j],
                                             lwd = cur$pars$lwd[j]),
                                             draw = FALSE),
                                  row = yy, col = xx, draw = FALSE)
                    }
                    else if (cur$pars$type[j] == "p") {
                        grid.place(key.gf,
                                   grid.points(x=.5, y=.5, 
                                               gp = gpar(col = cur$pars$col[j]),
                                               size = unit(cur$pars$cex[j] * 2.5, "mm"),
                                               pch = cur$pars$pch[j],
                                               draw = FALSE),
                                   row = yy, col = xx, draw = FALSE)
                    }
                    else { # if (cur$pars$type[j] == "b" or "o") -- not differentiating
                        grid.place(key.gf, 
                                  grid.lines(x = c(0,1) * cur$pars$size[j]/max(cur$pars$size),
                                             ## ^^ this should be centered as well, but since the
                                             ## chances that someone would actually use this feature
                                             ## are astronomical, I'm leaving that for later.
                                             y = c(.5, .5),
                                             gp = gpar(col = cur$pars$col[j],
                                             lty = cur$pars$lty[j],
                                             lwd = cur$pars$lwd[j]),
                                             draw = FALSE),
                                  row = yy, col = xx, draw = FALSE)

                        grid.place(key.gf, 
                                   grid.points(x = (1:key$divide-1)/(key$divide-1),
                                               y = rep(.5, key$divide),
                                               gp = gpar(col = cur$pars$col[j]),
                                               size = unit(cur$pars$cex[j] * 2.5, "mm"),
                                               pch = cur$pars$pch[j],
                                               draw = FALSE),
                                   row = yy, col = xx, draw = FALSE)
                    }
                }
                else if (cur$type == "points") {
                    if (is.character(cur$pars$pch[j]))
                        grid.place(key.gf, 
                                  grid.text(lab = cur$pars$pch[j], x=.5, y=.5, 
                                            gp = gpar(col = cur$pars$col[j],
                                            fontsize = cur$pars$cex[j] * 10),
                                            draw = FALSE),
                                  row = yy, col = xx, draw = FALSE)
                    else {
                        grid.place(key.gf,
                                  grid.points(x=.5, y=.5, 
                                              gp = gpar(col = cur$pars$col[j]),
                                              size = unit(cur$pars$cex[j] * 2.5, "mm"),
                                              pch = cur$pars$pch[j],
                                              draw = FALSE),
                                  row = yy, col = xx, draw = FALSE)
                    }
                }

            }

        }

    }
    else stop("sorry, align=F not supported (yet ?)")


    if (draw)
        grid.draw(key.gf)

    key.gf
}











From AHill at wyeth.com  Thu Sep 11 23:16:30 2003
From: AHill at wyeth.com (Andrew Hill)
Date: Thu, 11 Sep 2003 17:16:30 -0400
Subject: [R] discrepancy between R and Splus lm.influence() functions for
	family=Gamma(link=identity)
Message-ID: <sf60adf7.099@gwsmtp.genetics.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030911/d68c54f4/attachment.pl

From MZodet at ahrq.gov  Fri Sep 12 00:45:49 2003
From: MZodet at ahrq.gov (MZodet@ahrq.gov)
Date: Thu, 11 Sep 2003 18:45:49 -0400
Subject: [R] Sorting
Message-ID: <3598558AD728D41183350008C7CF291C0A5CD334@exchange1.ahrq.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030911/c2277ca4/attachment.pl

From sfalcon at fhcrc.org  Fri Sep 12 00:55:36 2003
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Thu, 11 Sep 2003 15:55:36 -0700
Subject: [R] Sorting
In-Reply-To: <3598558AD728D41183350008C7CF291C0A5CD334@exchange1.ahrq.gov>
References: <3598558AD728D41183350008C7CF291C0A5CD334@exchange1.ahrq.gov>
Message-ID: <20030911225533.GO27613@queenbee.fhcrc.org>

See ?order.

On Thu, Sep 11, 2003 at 06:45:49PM -0400, MZodet at ahrq.gov wrote:
> What is the best way to sort a dataframe?



From kwan022 at stat.auckland.ac.nz  Fri Sep 12 01:05:08 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Fri, 12 Sep 2003 11:05:08 +1200 (NZST)
Subject: [R] Sorting
In-Reply-To: <3598558AD728D41183350008C7CF291C0A5CD334@exchange1.ahrq.gov>
Message-ID: <Pine.LNX.4.44.0309121104330.5711-100000@stat55.stat.auckland.ac.nz>

Hi,

On Thu, 11 Sep 2003 MZodet at ahrq.gov wrote:

> What is the best way to sort a dataframe?
> 
> For example, how would I go about sorting a dataframe (with variables V1-V5)
> by ascending V1, V2 and descending V3 while retaining V4 and V5.

?sort

> Also, is there a relatively easy way by which to re-order my columns?

?order or ?sort

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
"On two occasions, I have been asked [by members of Parliament],
'Pray, Mr. Babbage, if you put into the machine wrong figures, will
the right answers come out?' I am not able to rightly apprehend the
kind of confusion of ideas that could provoke such a question."

-- Charles Babbage (1791-1871) 
---- From Computer Stupidities: http://rinkworks.com/stupid/

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)



From ross at biostat.ucsf.edu  Fri Sep 12 01:33:53 2003
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Thu, 11 Sep 2003 16:33:53 -0700
Subject: [R] (structured) programming style
Message-ID: <1063323233.1905.18.camel@iron.libaux.ucsf.edu>

I find that because R functions are call by value, and because there are
no pointer or reference types (a la C++), I am making fairly heavy use
of lexical scoping to modify variables.  E.g.
outer <- function() {
  m <- matrix(0, 2, 2)
  inner <- function() {
    m[2,2] <<- 3
   ...
   }
}

I am not too pleased with this, as it violates basic rules of structured
programming, namely that it is not obvious what variables inner is
reading or writing.  It's not as totally out of control as the use of
global variables, but it's still bothersome.  In practice, I have many
variables and several levels of nesting that come into play.

A slightly subtler problem is that some of the variables in outer are
just for use by outer, while others are used for communication down the
line.  One can't tell by quick inspection what's what.

I am trying to compensate by commenting the code heavily, but I'd rather
not use a style that makes that necessary.

I recognize that I could pass m as an argument to inner and return a
modified version of it.  Assuming more than one variable was involved
(as would usually be the case) I'd need to put the "new" m in a list
returned from inner, and then unpack the list in the outer function. 
This is not only rather ugly, but I imagine it also raises some
performance issues.

All of which has me wondering if there are some more natural ways to use
the language to the same general ends.  Can anyone comment?

Thanks.
-- 
Ross Boylan                                      wk:  (415) 502-4031
530 Parnassus Avenue (Library) rm 115-4          ross at biostat.ucsf.edu
Dept of Epidemiology and Biostatistics           fax: (415) 476-9856
University of California, San Francisco
San Francisco, CA 94143-0840                     hm:  (415) 550-1062



From tlumley at u.washington.edu  Fri Sep 12 02:40:47 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 11 Sep 2003 17:40:47 -0700 (PDT)
Subject: [R] (structured) programming style
In-Reply-To: <1063323233.1905.18.camel@iron.libaux.ucsf.edu>
Message-ID: <Pine.A41.4.44.0309111709500.69974-100000@homer33.u.washington.edu>

On Thu, 11 Sep 2003, Ross Boylan wrote:

> I find that because R functions are call by value, and because there are
> no pointer or reference types (a la C++), I am making fairly heavy use
> of lexical scoping to modify variables.  E.g.
> outer <- function() {
>   m <- matrix(0, 2, 2)
>   inner <- function() {
>     m[2,2] <<- 3
>    ...
>    }
> }
>
> I am not too pleased with this, as it violates basic rules of structured
> programming, namely that it is not obvious what variables inner is
> reading or writing.  It's not as totally out of control as the use of
> global variables, but it's still bothersome.  In practice, I have many
> variables and several levels of nesting that come into play.
>
> A slightly subtler problem is that some of the variables in outer are
> just for use by outer, while others are used for communication down the
> line.  One can't tell by quick inspection what's what.
>
> I am trying to compensate by commenting the code heavily, but I'd rather
> not use a style that makes that necessary.
>
> I recognize that I could pass m as an argument to inner and return a
> modified version of it.  Assuming more than one variable was involved
> (as would usually be the case) I'd need to put the "new" m in a list
> returned from inner, and then unpack the list in the outer function.
> This is not only rather ugly, but I imagine it also raises some
> performance issues.
>


My personal preference is to use lexical scope only downwards (with a few
exceptions). Passing a variable into a function implicitly seems harmless,
but passing it out implicitly is, as you note, confusing.  In this context
I note that Python 2.1 has lexical closures that only allow variables to
be passed in and not out, and that most people seem happy with this.

I would typically pass out a list, but often wouldn't bother to unpack it
[One could make a case for multiple value return to be added to R, but
it's never been a high enough priority for the effort it would take]

There isn't necessarily better performance with the way you are doing it
(though for matrices there probably will be). Copying generally happens
when an object is modified, not when a name is bound.

For example, if you do

>  a<-list(m=rnorm(1e6))
> gc()
          used (Mb) gc trigger (Mb)
Ncells  369126  9.9     667722 17.9
Vcells 1087453  8.3    1471520 11.3
> b<-a$m
> gc()
          used (Mb) gc trigger (Mb)
Ncells  369103  9.9     667722 17.9
Vcells 1087396  8.3    1584906 12.1
> b[1]<-2
> gc()
          used (Mb) gc trigger (Mb)
Ncells  369108  9.9     667722 17.9
Vcells 2087397 16.0    2471462 18.9

you see that unpacking b from a didn't result in a copy, and that b must
just be a reference to a$m.  When b is modified it must be copied, but
this is true whether or not it is in a list. What matters is whether there
is another reference to it somewhere [actually, whether R thinks there
*might* be another reference: we try to be a bit conservative about this].


Now, it is certainly possible that you could have a situation where
assigning with <<- was really faster than passing back a list, by enough
to matter.  I think this situation is unusual enough that there may not be
a firm idea of `good R style', since it assumes that the objects are small
enough to fit easily in memory but large enough that it's worth going to
some effort to reduce copying. You might get more useful input from the
Bioconductor list, where people tend to spend a lot of time doing
computationally expensive things to medium-sized data sets.


	-thomas



From ross at biostat.ucsf.edu  Fri Sep 12 02:58:03 2003
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Thu, 11 Sep 2003 17:58:03 -0700
Subject: [R] (structured) programming style
In-Reply-To: <Pine.A41.4.44.0309111709500.69974-100000@homer33.u.washington.edu>
References: <Pine.A41.4.44.0309111709500.69974-100000@homer33.u.washington.edu>
Message-ID: <1063328283.1905.31.camel@iron.libaux.ucsf.edu>

Thanks for your response.  Is good to know that copying is lazy, but I
don't think that fully solves my problems.  See below.

On Thu, 2003-09-11 at 17:40, Thomas Lumley wrote:
.....
> 
> you see that unpacking b from a didn't result in a copy, and that b must
> just be a reference to a$m.  When b is modified it must be copied, but
> this is true whether or not it is in a list. What matters is whether there
> is another reference to it somewhere [actually, whether R thinks there
> *might* be another reference: we try to be a bit conservative about this].
> 

I'm thinking of a situation like
a <- array(0, dim=c(10000, 10))
and then I modify a one row at a time.
a[34,] <- newrow
So if I write directly to a, I just overwrite the row.
But if I make a copy, even a lazy one, when I change the row I have to
make a copy of the whole array (unless the laziness is really clever,
and your figures suggest that a single write causes the whole thing to
be copied).

Hmm, now that I think of it I suppose I could just return newrow from
the inner function... except I have inner functions that produce several
rows, with inner inner functions that do single rows...

> 
> Now, it is certainly possible that you could have a situation where
> assigning with <<- was really faster than passing back a list, by enough
> to matter.  I think this situation is unusual enough that there may not be
> a firm idea of `good R style', since it assumes that the objects are small
> enough to fit easily in memory but large enough that it's worth going to
> some effort to reduce copying. You might get more useful input from the
> Bioconductor list, where people tend to spend a lot of time doing
> computationally expensive things to medium-sized data sets.

Where and what is the Bioconductor list?

I suppose optimization is one traditional reason to break style
guidelines.



From spencer.graves at pdf.com  Fri Sep 12 03:03:04 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 11 Sep 2003 18:03:04 -0700
Subject: [R] (structured) programming style
References: <Pine.A41.4.44.0309111709500.69974-100000@homer33.u.washington.edu>
	<1063328283.1905.31.camel@iron.libaux.ucsf.edu>
Message-ID: <3F611B48.8060206@pdf.com>

You asked, "Where and what is Bioconductor... ."  See:  www.bioconductor.org

spencer graves

Ross Boylan wrote:
> Thanks for your response.  Is good to know that copying is lazy, but I
> don't think that fully solves my problems.  See below.
> 
> On Thu, 2003-09-11 at 17:40, Thomas Lumley wrote:
> .....
> 
>>you see that unpacking b from a didn't result in a copy, and that b must
>>just be a reference to a$m.  When b is modified it must be copied, but
>>this is true whether or not it is in a list. What matters is whether there
>>is another reference to it somewhere [actually, whether R thinks there
>>*might* be another reference: we try to be a bit conservative about this].
>>
> 
> 
> I'm thinking of a situation like
> a <- array(0, dim=c(10000, 10))
> and then I modify a one row at a time.
> a[34,] <- newrow
> So if I write directly to a, I just overwrite the row.
> But if I make a copy, even a lazy one, when I change the row I have to
> make a copy of the whole array (unless the laziness is really clever,
> and your figures suggest that a single write causes the whole thing to
> be copied).
> 
> Hmm, now that I think of it I suppose I could just return newrow from
> the inner function... except I have inner functions that produce several
> rows, with inner inner functions that do single rows...
> 
> 
>>Now, it is certainly possible that you could have a situation where
>>assigning with <<- was really faster than passing back a list, by enough
>>to matter.  I think this situation is unusual enough that there may not be
>>a firm idea of `good R style', since it assumes that the objects are small
>>enough to fit easily in memory but large enough that it's worth going to
>>some effort to reduce copying. You might get more useful input from the
>>Bioconductor list, where people tend to spend a lot of time doing
>>computationally expensive things to medium-sized data sets.
> 
> 
> Where and what is the Bioconductor list?
> 
> I suppose optimization is one traditional reason to break style
> guidelines.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From WeiQiang.Li at seagate.com  Fri Sep 12 03:19:06 2003
From: WeiQiang.Li at seagate.com (WeiQiang.Li@seagate.com)
Date: Fri, 12 Sep 2003 09:19:06 +0800
Subject: [R] help - "Object is static, operation not allowed" Error
Message-ID: <OF8300A359.5BC742D3-ON48256D9E.0053E0DF-48256D9F.000739F4@notes.seagate.com>

Hello,

      I am a newbie in R project and trying to call prcomp(x) of R function
using (D)COM server communicate with R in ASP, and encountering the error
"Runtime error -2147221493(8004000b). Automation Error, Object is static,
operation not allowed." at line Result=StatConn.Evaluate("y<-prcomp(x)"). E
ven I have added the line StatConn.EvaluateNoReturn("library (mva)"), it
still does not help me after I saw Wijk, H.J. van der's post mentioned that
have to load library
      My environment is shown as below:
            OS:         Win2000 Server
            R version:  1.7.1
            DCOM version:     1.2


      Source code is shown as below:
      <%
      Set StatConn=Server.CreateObject("StatConnectorSrv.StatConnector")
      StatConn.Init ("R")
      StatConn.EvaluateNoReturn("x<-matrix(c(1,2,3,4,5,6,7,8,9),3)")
      StatConn.EvaluateNoReturn("library (mva)")
      Result=StatConn.Evaluate("y<-prcomp(x)")
      StatConn.Close
      %>

      I have another problem when displaying dimension variable
"Result(1,1)" on client, there will be a "Type mismatch: 'Result'" error.
      Source code is shown as below:
      <%
      Set StatConn=Server.CreateObject("StatConnectorSrv.StatConnector")
      StatConn.Init ("R")
      Result=StatConn.Evaluate("x<-matrix(c(1,2,3,4,5,6,7,8,9),3)")
      Response.write Result(1,1)
      StatConn.Close
      %>

      You are very appreciated if you help me on above issue.
      Thanks Again!

Regards,
WeiQiang Li



From matthew_wiener at merck.com  Fri Sep 12 04:12:56 2003
From: matthew_wiener at merck.com (Wiener, Matthew)
Date: Thu, 11 Sep 2003 22:12:56 -0400
Subject: [R] Getting 2 kinds of quotes inside a pasted string
Message-ID: <AEBD81486231A343B1813FE62D3352250369A29D@usrymx15.merck.com>

Hi, all.

I would like to use "pipe" to run a file through an awk program before
scanning (to reduce the amount of data I'll be taking in).  I would like to
construct the awk program in R, and also to be able to set the awk variable
FS, to accommodate different field separators in different files.

My problem is that I keep getting the quotes escaped in the string that
comes out, and that sets the field separator to something different.

What I'd like to end up with is something like: 
	awk 'BEGIN{FS=";"}'  
If I can get this, I can put the rest of the awk program together.  What I
actually keep getting is 
awk 'BEGIN{FS=\";\"}'.  
That is, the quote characters are escaped.

I can print this with quote = FALSE, and get the string I'm looking for.
But when I paste that into the larger awk program, the quotes are
nonetheless escaped (presumably because the print, quote = FALSE affects
only display and not the internal structure).

I've also tried sprintf, but run into the same problem.  I'd very much
appreciate it if someone could show me how to create the string I'm looking
for, or tell me a better way to go about filtering the file in the first
place.  I'd prefer not to scan in everything and do the subsetting in R; the
files I'm using are very large, and the whole point is not to have to load
the whole file into memory.

Thanks very much,

Matthew Wiener
RY84-202
Applied Computer Science & Mathematics Dept.
Merck Research Labs
126 E. Lincoln Ave.
Rahway, NJ 07065
732-594-5303 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From edd at debian.org  Fri Sep 12 04:14:19 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 11 Sep 2003 21:14:19 -0500
Subject: [R] help - "Object is static, operation not allowed" Error
In-Reply-To: <OF8300A359.5BC742D3-ON48256D9E.0053E0DF-48256D9F.000739F4@notes.seagate.com>
References: <OF8300A359.5BC742D3-ON48256D9E.0053E0DF-48256D9F.000739F4@notes.seagate.com>
Message-ID: <20030912021419.GA1997@sonny.eddelbuettel.com>

On Fri, Sep 12, 2003 at 09:19:06AM +0800, WeiQiang.Li at seagate.com wrote:
>       I am a newbie in R project and trying to call prcomp(x) of R function
> using (D)COM server communicate with R in ASP, and encountering the error

As a general rule, I found it helpful to disentangle matters:

i)  make sure you really do have working R code, e.g. by actually running
    that code in the Gui
    
ii) make sure you really do talk back and forth between your controlling
    app and R; so send some data over the wire, alter it and see if you 
    it back --- also make sure that you cover the data type you intend to 
    send in i)
    
Hope this helps, Dirk    

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From yshen004 at temple.edu  Fri Sep 12 04:28:38 2003
From: yshen004 at temple.edu (yshen004@temple.edu)
Date: Thu, 11 Sep 2003 22:28:38 -0400
Subject: [R] about package e1071
Message-ID: <ac1cb090.c1f67acb.816e000@po-a.temple.edu>

Hi,

This is Yan from Temple University. I recently read a paper 
about SVM and tried to apply it with some dataset in R. I 
downloaded a zip file e1071_1.3-12.zip from CRAN and used R 
menu to install it. It seemed that the package was installed 
successfully. But I failed to load the package and a error 
message 'Error in parse(file, n, text, prompt) : syntax error 
on line 1930' showed up. Could you help me solve this 
problem? Thanks in advance.


Best,



Yan Shen
Temple University
Department of Statistics



From edd at debian.org  Fri Sep 12 04:37:36 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 11 Sep 2003 21:37:36 -0500
Subject: [R] Getting 2 kinds of quotes inside a pasted string
In-Reply-To: <AEBD81486231A343B1813FE62D3352250369A29D@usrymx15.merck.com>
References: <AEBD81486231A343B1813FE62D3352250369A29D@usrymx15.merck.com>
Message-ID: <20030912023736.GA2148@sonny.eddelbuettel.com>

On Thu, Sep 11, 2003 at 10:12:56PM -0400, Wiener, Matthew wrote:
> My problem is that I keep getting the quotes escaped in the string that
> comes out, and that sets the field separator to something different.
> 
> What I'd like to end up with is something like: 
> 	awk 'BEGIN{FS=";"}'  
> If I can get this, I can put the rest of the awk program together.  What I
> actually keep getting is 
> awk 'BEGIN{FS=\";\"}'.  
> That is, the quote characters are escaped.

This prints what you want:

	> print("awk \'BEGIN\{FS=\";\"\}\'")
	[1] "awk 'BEGIN{FS=\";\"}'"
      
and I can pipe it into tee(1) which logs to its first argument:

	> con<-pipe("tee /tmp/matt.log","w")
	> cat("awk \'BEGIN\{FS=\";\"\}\'\n", file=con)
	> awk 'BEGIN{FS=";"}'		     	     # this line echoes by tee
						     # pressed RETURN
	> close(con)

and it all looks fine:

	edd at chibud:~> cat /tmp/matt.log 
	awk 'BEGIN{FS=";"}'
	edd at chibud:~> 

Hth, Dirk

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From WeiQiang.Li at seagate.com  Fri Sep 12 04:41:18 2003
From: WeiQiang.Li at seagate.com (WeiQiang.Li@seagate.com)
Date: Fri, 12 Sep 2003 10:41:18 +0800
Subject: [R] help - "Object is static, operation not allowed" Error
In-Reply-To: <20030912021419.GA1997@sonny.eddelbuettel.com>
Message-ID: <OF2E0F9FCF.5988FB36-ON48256D9F.000CE48C-48256D9F.000EC09A@notes.seagate.com>


Hello Dirk,
      Thanks for your quick reply.
      They are simple R codes and working well in RGUI. DCOM is also
communicating well with R, the lineStr=StatConn.Evaluate("x
<-matrix(c(1,2,3,4,5,6,7,8,9),3)") return back return correctly. Only
seldom R codes called failed, and I suspect that the static library loaded
failed even there is no error return after call the line
StatConn.EvaluateNoReturn("library (mva)") . I need this problem fixed
urgently. I hope someone may help me.

      Thanks again!

Regards,
WeiQiang Li
IT-Factory Information Systems
Tel: 6485-2439



                                                                                                                                       
                      Dirk Eddelbuettel                                                                                                
                      <edd at debian.org>         To:       WeiQiang.Li at seagate.com                                                       
                      No Phone Info            cc:       r-help at stat.math.ethz.ch                                                      
                      Available                Subject:  Re: [R] help - "Object is static, operation not allowed" Error                
                                                                                                                                       
                      09/12/2003 10:14                                                                                                 
                      AM                                                                                                               
                                                                                                                                       




On Fri, Sep 12, 2003 at 09:19:06AM +0800, WeiQiang.Li at seagate.com wrote:
>       I am a newbie in R project and trying to call prcomp(x) of R
function
> using (D)COM server communicate with R in ASP, and encountering the error

As a general rule, I found it helpful to disentangle matters:

i)  make sure you really do have working R code, e.g. by actually running
    that code in the Gui

ii) make sure you really do talk back and forth between your controlling
    app and R; so send some data over the wire, alter it and see if you
    it back --- also make sure that you cover the data type you intend to
    send in i)

Hope this helps, Dirk

--
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From Raimondas at vb.lt  Fri Sep 12 06:33:07 2003
From: Raimondas at vb.lt (Raimondas B.)
Date: Fri, 12 Sep 2003 07:33:07 +0300
Subject: [R] Need your help with SJava package on W2K
Message-ID: <001d01c378e6$f7095120$6e25b10a@berniunas>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030912/7d5ec14a/attachment.pl

From ligges at statistik.uni-dortmund.de  Fri Sep 12 08:25:51 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 12 Sep 2003 08:25:51 +0200
Subject: [R] about package e1071
In-Reply-To: <ac1cb090.c1f67acb.816e000@po-a.temple.edu>
References: <ac1cb090.c1f67acb.816e000@po-a.temple.edu>
Message-ID: <3F6166EF.6020601@statistik.uni-dortmund.de>

yshen004 at temple.edu wrote:
> Hi,
> 
> This is Yan from Temple University. I recently read a paper 
> about SVM and tried to apply it with some dataset in R. I 
> downloaded a zip file e1071_1.3-12.zip from CRAN and used R 
> menu to install it. It seemed that the package was installed 
> successfully. But I failed to load the package and a error 
> message 'Error in parse(file, n, text, prompt) : syntax error 
> on line 1930' showed up. Could you help me solve this 
> problem? Thanks in advance.

Given your R version is R-1.7.x, this is the right file that works for 
me. Please try to download again and reinstall.

Uwe Ligges


> 
> Best,
> 
> 
> 
> Yan Shen
> Temple University
> Department of Statistics
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ligges at statistik.uni-dortmund.de  Fri Sep 12 08:29:29 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 12 Sep 2003 08:29:29 +0200
Subject: [R] help - "Object is static, operation not allowed" Error
In-Reply-To: <OF2E0F9FCF.5988FB36-ON48256D9F.000CE48C-48256D9F.000EC09A@notes.seagate.com>
References: <OF2E0F9FCF.5988FB36-ON48256D9F.000CE48C-48256D9F.000EC09A@notes.seagate.com>
Message-ID: <3F6167C9.3060205@statistik.uni-dortmund.de>

WeiQiang.Li at seagate.com wrote:

> Hello Dirk,
>       Thanks for your quick reply.
>       They are simple R codes and working well in RGUI. DCOM is also
> communicating well with R, the lineStr=StatConn.Evaluate("x
> <-matrix(c(1,2,3,4,5,6,7,8,9),3)") return back return correctly. Only
> seldom R codes called failed, and I suspect that the static library loaded
> failed even there is no error return after call the line
> StatConn.EvaluateNoReturn("library (mva)") . I need this problem fixed
> urgently. I hope someone may help me.

As I already told you in a private message: Please ask the package 
maintainer.

Uwe Ligges



>       Thanks again!
> 
> Regards,
> WeiQiang Li
> IT-Factory Information Systems
> Tel: 6485-2439
> 
> 
> 
>                                                                                                                                        
>                       Dirk Eddelbuettel                                                                                                
>                       <edd at debian.org>         To:       WeiQiang.Li at seagate.com                                                       
>                       No Phone Info            cc:       r-help at stat.math.ethz.ch                                                      
>                       Available                Subject:  Re: [R] help - "Object is static, operation not allowed" Error                
>                                                                                                                                        
>                       09/12/2003 10:14                                                                                                 
>                       AM                                                                                                               
>                                                                                                                                        
> 
> 
> 
> 
> On Fri, Sep 12, 2003 at 09:19:06AM +0800, WeiQiang.Li at seagate.com wrote:
> 
>>      I am a newbie in R project and trying to call prcomp(x) of R
> 
> function
> 
>>using (D)COM server communicate with R in ASP, and encountering the error
> 
> 
> As a general rule, I found it helpful to disentangle matters:
> 
> i)  make sure you really do have working R code, e.g. by actually running
>     that code in the Gui
> 
> ii) make sure you really do talk back and forth between your controlling
>     app and R; so send some data over the wire, alter it and see if you
>     it back --- also make sure that you cover the data type you intend to
>     send in i)
> 
> Hope this helps, Dirk
> 
> --
> Those are my principles, and if you don't like them... well, I have others.
>                                                 -- Groucho Marx
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Bodo.Ahrens at univie.ac.at  Fri Sep 12 08:34:06 2003
From: Bodo.Ahrens at univie.ac.at (Bodo Ahrens)
Date: Fri, 12 Sep 2003 08:34:06 +0200
Subject: [R] levelplot
Message-ID: <200309120834.07507.Bodo.Ahrens@univie.ac.at>

Dear helpers,

I have strange results with levelplot: The following lines of code produce a 
figure with a strange gray horizontal line. Changing n to 9 the line vanishes 
almost - it stays in the colorbar. Any ideas? The pixel geometry of the lower 
half of the figure is wrong?

##############################
n<-8
xyz<-expand.grid(x=seq(1,n),y=seq(1,n))
z<-matrix(0,n,n)
z[,(n/2-1):(n/2+1)]<-1
xyz$z<-as.vector(t(z))

library("lattice")
levelplot(z~x+y,xyz)
################################

Versions of lattice and grid etc are actual.

Thank you,

Bodo


-- 
Dr. Bodo Ahrens
Institut fuer Meteorologie und Geophysik, Universitaet Wien
Althanstrasse 14, A-1090 Wien, Austria
Tel: +43-1-4277-51917, Fax: +43-1-4277-9519
E-mail: Bodo.Ahrens at univie.ac.at



From Bodo.Ahrens at univie.ac.at  Fri Sep 12 08:51:24 2003
From: Bodo.Ahrens at univie.ac.at (Bodo Ahrens)
Date: Fri, 12 Sep 2003 08:51:24 +0200
Subject: [R] levelplot
Message-ID: <200309120851.24379.Bodo.Ahrens@univie.ac.at>


Dear helpers,

I have strange results with levelplot: The following lines of code produce a
figure with a strange gray horizontal line. Changing n to 9 the line vanishes
almost - it stays in the colorbar. Any ideas? The pixel geometry of the lower
half of the figure is wrong?

##############################
n<-8
xyz<-expand.grid(x=seq(1,n),y=seq(1,n))
z<-matrix(0,n,n)
z[,(n/2-1):(n/2+1)]<-1
xyz$z<-as.vector(t(z))

library("lattice")
levelplot(z~x+y,xyz)
################################

Versions of lattice and grid etc are actual.

Thank you,

Bodo


--
Dr. Bodo Ahrens
Institut fuer Meteorologie und Geophysik, Universitaet Wien
Althanstrasse 14, A-1090 Wien, Austria
Tel: +43-1-4277-51917, Fax: +43-1-4277-9519
E-mail: Bodo.Ahrens at univie.ac.at



From paul.delmar at wanadoo.fr  Fri Sep 12 08:57:15 2003
From: paul.delmar at wanadoo.fr (Paul Delmar)
Date: Fri, 12 Sep 2003 08:57:15 +0200
Subject: [R] Getting greek letters in plot  labels and title
Message-ID: <001101c378fb$19d4d990$0100a8c0@paul>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030912/7e467023/attachment.pl

From ligges at statistik.uni-dortmund.de  Fri Sep 12 09:10:17 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 12 Sep 2003 09:10:17 +0200
Subject: [R] Getting greek letters in plot  labels and title
In-Reply-To: <001101c378fb$19d4d990$0100a8c0@paul>
References: <001101c378fb$19d4d990$0100a8c0@paul>
Message-ID: <3F617159.8020402@statistik.uni-dortmund.de>

Paul Delmar wrote:

> Hi, 
>  
> Does any one knows how to include greek letters in plot labels and plot
> titles ?
>  
> Thanks a lot
>  
> paul

Yes, several people do know. See ?plotmath.

Uwe Ligges



From maechler at stat.math.ethz.ch  Fri Sep 12 09:16:49 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 12 Sep 2003 09:16:49 +0200
Subject: [R] discrepancy between R & Splus lm.influence() for family=Gamma
In-Reply-To: <sf60adf7.099@gwsmtp.genetics.com>
References: <sf60adf7.099@gwsmtp.genetics.com>
Message-ID: <16225.29409.828103.844410@gargle.gargle.HOWL>

>>>>> "Andrew" == Andrew Hill <AHill at wyeth.com>
>>>>>     on Thu, 11 Sep 2003 17:16:30 -0400 writes:

    Andrew> Hello, I am looking for an explanation and/or fix
    Andrew> for a discrepancy in the behaviour of the R
    Andrew> lm.influence() function [ version R 1.5.0
    Andrew> (2002-04-29) ] and the same function in Splus [
    Andrew> Splus version 5.1 release 1, running on SGI IRIX
    Andrew> 6.2].  The discrepancy is of concern because I am
    Andrew> migrating some Splus scripts to R and need to ensure
    Andrew> consistency of results.

Before reading on: 
Do you really mean R 1.5.0?  
If yes, you should definitely upgrade to R 1.7.1 !

There were considerable improvements (for R 1.7.0) for these
functions, mostly thanks to John Fox, and the recommended way in
R is to use influence() which is a generic function that has both an "lm"
and (important for you!) a "glm" method.

I.e., you use  influence(mylmfit, ...) and the method
 influence.glm(mylmfit, ...) will be called.  
This should do the correct calculations for all kind of glm models.

Regards,
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><


    Andrew> Specifically, when I fit a glm() model to a test
    Andrew> dataset using the family = Gamma(link=identity), and
    Andrew> then call lm.influence on the fitted glm object, the
    Andrew> resulting lm.influence()$coefficients and
    Andrew> lm.influence()$sigma values are different between R
    Andrew> and Splus versions.  The lm.influence()$hat vector
    Andrew> does agree between the two programs.  Also, the
    Andrew> glm() function does return the same model
    Andrew> coefficient in both R and Splus.

    Andrew> In contrast, if I use the default glm
    Andrew> family=Gaussian(link=identity), all output of
    Andrew> lm.influence() for both R and Splus does agree fully
    Andrew> for my dataset.

    Andrew> I have read the R help function for lm.influence()
    Andrew> and I understand that R returns the difference
    Andrew> between the model coefficients and the drop-one
    Andrew> coefficients, while Splus returns the drop-one
    Andrew> coefficients.  But this does not account for the
    Andrew> discrepancy that I see in the
    Andrew> lm.influence$coefficients, nor the difference in
    Andrew> lm.influence$sigma, at least to my understanding.

    Andrew> Pasted below is output, first from R, and second
    Andrew> from Splus, which illustates the issue.
    Andrew> Discrepancies between the R and Splus $sigma values
    Andrew> look like ~ 2-6%.  Hopefully I have not overlooked
    Andrew> an obvious statistical explanation for the
    Andrew> difference.

    Andrew> Thanks, Andrew.



From petzoldt at rcs.urz.tu-dresden.de  Fri Sep 12 09:23:11 2003
From: petzoldt at rcs.urz.tu-dresden.de (Thomas Petzoldt)
Date: Fri, 12 Sep 2003 09:23:11 +0200
Subject: [R] Getting greek letters in plot  labels and title
In-Reply-To: <001101c378fb$19d4d990$0100a8c0@paul>
References: <001101c378fb$19d4d990$0100a8c0@paul>
Message-ID: <3F61745F.9090606@rcs.urz.tu-dresden.de>

Paul Delmar schrieb:

> Hi, 
>  
> Does any one knows how to include greek letters in plot labels and plot
> titles ?

See ?plotmath and the demo in the base package

demo(plotmath)

(or demo(graphics) in some older versions)

A small example:

plot(pnorm(seq(-3,3,.1)), xlab="x",
            ylab=expression(Phi),
            main=expression(Phi==f(x)))


Thomas


-- 
Thomas Petzoldt
Dresden University of Technology
Institute for Hydrobiology         petzoldt at rcs.urz.tu-dresden.de
01062 Dresden                      http://www.tu-dresden.de/fghhihb/



From opal7313 at yahoo.fr  Fri Sep 12 09:30:13 2003
From: opal7313 at yahoo.fr (=?iso-8859-1?q?N=20L?=)
Date: Fri, 12 Sep 2003 09:30:13 +0200 (CEST)
Subject: [R] R update
Message-ID: <20030912073013.19742.qmail@web60209.mail.yahoo.com>

Hello,

 I used "fink" to install R but its version
 is the 1.7.0 and I want to install and update
bioconductor packages with getBioC.R ; this 
script requires R1.7.1; Is there a way to just update
it on my
Mac osx?  
Thanks in advance 
Line



From anne.piotet at urbanet.ch  Fri Sep 12 10:00:40 2003
From: anne.piotet at urbanet.ch (anne.piotet@urbanet.ch)
Date: Fri, 12 Sep 2003 10:00:40 +0200 (CEST)
Subject: [R] factor creation
Message-ID: <1063353640.3f617d2824915@webmail.urbanet.ch>

Another newbie question....
  I want to create a factor (say cT)from a numerical variable (sy temp) by 
regrouping the values in classes (say cT <390, [390,400[,[400,409[...>=550)

Is there a simple way of doing that using the factor function?

AND I do not find how to manipulate strings (I want to concatenete characters 
strings ("abkdas","chjw") into something like ("abkdas;chjw")what operators are 
available for strings manipulation and where do I find help??

Thanks a lot to you all

Anne 

Anne Piotet
av Jomini 1
1004 lausanne

t?l: +41 21 646 41 32



From arv at ono.com  Fri Sep 12 10:05:26 2003
From: arv at ono.com (antonio rodriguez)
Date: Fri, 12 Sep 2003 10:05:26 +0200
Subject: [R] eof and svd calculus with NA's
Message-ID: <IPEFKICOHOECENGJBAGLAEPLCCAA.arv@ono.com>

Hi,

Im currently dealing with large datasets of some climatic parameters and I'm
performing some EOF analysis on them. The problem is that for one of the
datasets, the continents are labelled as NA's (since the data was gathered
over the oceans). I don't know to which extent the dropping of those NA's
from the matrix will affect the future calculus, and how to maintain the
geographic entity of the EOF's

Thanks in advance

Antonio Rodriguez
---



From ripley at stats.ox.ac.uk  Fri Sep 12 10:13:58 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 12 Sep 2003 09:13:58 +0100 (BST)
Subject: [R] factor creation
In-Reply-To: <1063353640.3f617d2824915@webmail.urbanet.ch>
Message-ID: <Pine.LNX.4.44.0309120911270.8233-100000@gannet.stats>

On Fri, 12 Sep 2003 anne.piotet at urbanet.ch wrote:

> Another newbie question....
>   I want to create a factor (say cT)from a numerical variable (sy temp) by 
> regrouping the values in classes (say cT <390, [390,400[,[400,409[...>=550)
> 
> Is there a simple way of doing that using the factor function?

No, but see ?cut.

> AND I do not find how to manipulate strings (I want to concatenete characters 
> strings ("abkdas","chjw") into something like ("abkdas;chjw")what operators are 
> available for strings manipulation and where do I find help??

See ?paste.  This is in `An Introduction to R', and all good books on S/R
will give you more details.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From laurent.faisnel at ariase.com  Fri Sep 12 10:16:37 2003
From: laurent.faisnel at ariase.com (Laurent Faisnel)
Date: Fri, 12 Sep 2003 10:16:37 +0200
Subject: [R] factor creation
References: <1063353640.3f617d2824915@webmail.urbanet.ch>
Message-ID: <3F6180E5.7050205@ariase.com>

anne.piotet at urbanet.ch wrote:
> I do not find how to manipulate strings (I want to concatenete characters 
> strings ("abkdas","chjw") into something like ("abkdas;chjw")what operators are 
> available for strings manipulation and where do I find help??

Use the paste operator with specification of separator :

e.g. paste("abkdas","chjw",sep=";") will return string "abkdas;chjw"

Laurent



From Ted.Harding at nessie.mcc.ac.uk  Fri Sep 12 10:25:40 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 12 Sep 2003 09:25:40 +0100 (BST)
Subject: [R] eof and svd calculus with NA's
In-Reply-To: <IPEFKICOHOECENGJBAGLAEPLCCAA.arv@ono.com>
Message-ID: <XFMail.030912092138.Ted.Harding@nessie.mcc.ac.uk>

On 12-Sep-03 antonio rodriguez wrote:
> Im currently dealing with large datasets of some climatic parameters
> and I'm performing some EOF analysis on them. The problem is that for
> one of the datasets, the continents are labelled as NA's (since the
> data was gathered over the oceans). I don't know to which extent the
> dropping of those NA's from the matrix will affect the future
> calculus, and how to maintain the geographic entity of the EOF's

Surely you can sidestep any potential problems of dropping data by
a global editing of this dataset so that all "NA" continents become,
say, "Ocean"?

Not much more informative than "NA" perhaps, but still more meaningful
and will avoid the problem you raise.

Best wishes,
Ted.



From rdiaz at cnio.es  Fri Sep 12 11:12:14 2003
From: rdiaz at cnio.es (Ramon Diaz-Uriarte)
Date: Fri, 12 Sep 2003 11:12:14 +0200
Subject: [R] Using R for microarrays datas analysis by Mixed model ANOVA.
	=?iso-8859-1?q?lme=09function=2E?=
In-Reply-To: <3F60D58B.3040109@pdf.com>
References: <BB863BCC.281%dautran@ira.cinvestav.mx> <3F60D58B.3040109@pdf.com>
Message-ID: <200309121112.14280.rdiaz@cnio.es>

Dear Daphne,

A couple of further comments:

On Thursday 11 September 2003 22:05, Spencer Graves wrote:
> 1.  Have you consulted Pinhiero and Bates (2000) Mixed-Effects Models in
> S and S-Plus (Springer)?  This is the standard (almost indispensible)
> reference on "lme".
>
> 2.  Are you familiar with the Bioconductor project
> (www.bioconductor.org)?  The have a substantial library of software for
> analyzing microarray data.
>
> hope this helps.  spencer graves
>
> Daphne Autran wrote:
> > Hi,
> > We are using R to analyse microarrays datas by ANOVA.
> > We would like to set up Mixed Model analysis, using the "lme" function
> > within the nmle package.
> > However, we have problem in understanding and getting the right formula
> > to build a "groupedData" object which appear to be required for lme to
> > work. 

No, not really. You can use lme without a groupedData object. For instance:

library(nlme)
y <- rnorm(20)
x <- rnorm(20)
u <- factor(c(rep("a", 10), rep("b", 10)))

lme(y ~ x, random = ~ 1|u)


A simple minded approach is to call lme repeatedly using apply over your array 
of genes*subjects. Suppose you have:

microarray.data <- matrix(rnorm(200), ncol = 20) ## genes in rows

## using x and u as defined above
apply(microarray.data, 1, function(z) lme(z ~ x, random = ~1|u))


The above, of course, gives you a lot of output, in a not particularly 
organized form. You can access the components of the lme fitted object, or 
its summary, or whatever, and get only what you want, and place it in, say, a 
matrix:

f1 <- function(z) {
    summary(lme(z ~ x, random = ~1|u))$t[2, ]
}

gene.t.tables <- t(apply(microarray.data, 1, function(z) f1(z)))

etc...


As Spencer said, you probably want a copy of Pinheiro and Bates. Venables & 
Ripleys's MASS also discusses lme.

> >
> > Does anybody have an experience in using this function for microarrays
> > datas analysis and could send me informations or, if possible, a resolved
> > exemple (input table of datas, formula of the model, ouput...) ?
> >
> > Maybe other R functions are usefull and easier to implement Mixed Models
> > ANOVA for microarrays analysis, any suggestions ?

The package limma, in bioconductor, is ideal for fitting linear models. It 
does not include mixed effects models, though. 

Hope this helps,

Ram?n

-- 
Ram?n D?az-Uriarte
Bioinformatics Unit
Centro Nacional de Investigaciones Oncol?gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern?ndez Almagro, 3
28029 Madrid (Spain)
Fax: +-34-91-224-6972
Phone: +-34-91-224-6900

http://bioinfo.cnio.es/~rdiaz



From Simon.Fear at synequanon.com  Fri Sep 12 12:21:25 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Fri, 12 Sep 2003 11:21:25 +0100
Subject: [R] (structured) programming style
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572AC0DC6@synequanon01>

Ross, it seems to me that a "non-R-like" part of your code is hinted
at in

> I'm thinking of a situation like
> a <- array(0, dim=c(10000, 10))
> and then I modify a one row at a time.
> a[34,] <- newrow
> So if I write directly to a, I just overwrite the row.

My guess is you could be doing better with an apply()
to modify all the rows at once. Just one new copy of a.

I don't think there's a perfect answer to your main question, about 
controlling where the assignments are made. I like to use 
assign() with an explicit environment argument in this context, 
rather than <<-. Makes me feel that I'm in control. To be absolutely 
sure, you can combine this with get()
(otherwise in assign(x, fn(x), pos=1) it's the most local x
that gets used in calculating fn(x). x <<- fn(x) has the same potential
problem, as recently discussed on this list.)

In fact, in such unusual circumstances I use global variables without
any
sense of shame, and I name them global.x (etc) - names I would 
never use except when deliberately overriding normal lexical
scope. This is much easier and less error prone than clever
manipulation of the sys.frames() stack.  I'd rather have
clear code with global variables than "beautiful" code that I 
don't have the skill to maintain...
 

Simon Fear
Senior Statistician
Syne qua non Ltd
Tel: +44 (0) 1379 644449
Fax: +44 (0) 1379 644445
email: Simon.Fear at synequanon.com
web: http://www.synequanon.com
 
Number of attachments included with this message: 0
 
This message (and any associated files) is confidential and\...{{dropped}}



From laurent at cbs.dtu.dk  Fri Sep 12 13:21:46 2003
From: laurent at cbs.dtu.dk (Laurent Gautier)
Date: Fri, 12 Sep 2003 13:21:46 +0200
Subject: [R] Using R for microarrays datas analysis by Mixed model ANOVA.
	lme	function.
In-Reply-To: <200309121112.14280.rdiaz@cnio.es>
References: <BB863BCC.281%dautran@ira.cinvestav.mx> <3F60D58B.3040109@pdf.com>
	<200309121112.14280.rdiaz@cnio.es>
Message-ID: <20030912112146.GA69380650@genome.cbs.dtu.dk>

Just a note about linear model fitting in Bioconductor. Biobase
(in the devel section) has a feature to cast an exprSet to
a data.frame. Althought this cannot compare with the very nice 'user-friendly' 
features in the pack 'limma', it lets one with experience and habits with data.frames
 (use of formulae and all the goodies in nlme) remain on known
ground.

L.

PS: Biobase-devel needs R-devel since a recent time. The following
R code does the cast (just copy/paste it). 

as.data.frame.exprSet <- function(x, row.names=NA, optional=NA) {
  nc.eset <- ncol(exprs(x))
  nr.eset <- nrow(exprs(x))
  gn.eset <- geneNames(x)

  if (is.null(gn.eset))
    gn.eset <- rep(NA, nr.eset)
  i.pdata <- rep(seq(1, nc.eset), rep(nr.eset, nc.eset))

  pexp <- c(exprs(x))
  
  
  rv <- do.call("data.frame", c(list(exprs=pexp, genenames=rep(gn.eset, nc.eset)),
                                lapply(pData(x), function(y, i.pdata) y[i.pdata], i.pdata))
                )
  
  return(rv)
}

 

-- 
--------------------------------------------------------------
Laurent Gautier			CBS, Building 208, DTU
PhD. Student			DK-2800 Lyngby,Denmark	
tel: +45 45 25 24 89		http://www.cbs.dtu.dk/laurent



From smithq15 at yahoo.com  Fri Sep 12 13:35:15 2003
From: smithq15 at yahoo.com (Suzy Smith)
Date: Fri, 12 Sep 2003 04:35:15 -0700 (PDT)
Subject: [R] Using the system command
Message-ID: <20030912113515.59627.qmail@web14611.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030912/819c1a52/attachment.pl

From B.Rowlingson at lancaster.ac.uk  Fri Sep 12 13:48:45 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 12 Sep 2003 12:48:45 +0100
Subject: [R] Using the system command
In-Reply-To: <20030912113515.59627.qmail@web14611.mail.yahoo.com>
References: <20030912113515.59627.qmail@web14611.mail.yahoo.com>
Message-ID: <3F61B29D.80607@lancaster.ac.uk>

Suzy Smith wrote:
> Hello, I am currently taking a statistics course and we are to do a project producing a graph using multiple input files.
>  
> In R, I'm trying to build a filelist based on a pattern.  For some reason, if I do the command interactively and not assign it to an array variable I get what I thought I should, but if I do this inside my R program it chops off some file names and thinks there are two.
>  
> I looked on the R website and found that there is an 8,096 character limit when using a character array but mine chops at 119.
>  
> Here is the command:
> filelist <- system(paste("ls ", INPUTFILES, sep=""),intern=T)
>  
> Any help would be much appreciated.
>  

  I dont know why that doesn't work - it might be specific to the files 
on your system. However, R has some functions for finding files, such as 
list.files():

 > filelist <- list.files(pattern=".dat$")
 > filelist
[1] "jobacct.dat" "winmail.dat"
 >

  Get more info by typing ?list.files

  The following functions may also be useful:

file.access(base)       Ascertain File Accessibility
file.choose(base)       Choose a File Interactively
file.info(base)         Extract File Information
file.path(base)         Construct Path to File
file.show(base)         Display One or More Files

Baz



From ripley at stats.ox.ac.uk  Fri Sep 12 14:11:30 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 12 Sep 2003 13:11:30 +0100 (BST)
Subject: [R] Using the system command
In-Reply-To: <3F61B29D.80607@lancaster.ac.uk>
Message-ID: <Pine.LNX.4.44.0309121308250.28861-100000@gannet.stats>

On Fri, 12 Sep 2003, Barry Rowlingson wrote:

> Suzy Smith wrote:
> > Hello, I am currently taking a statistics course and we are to do a project producing a graph using multiple input files.
> >  
> > In R, I'm trying to build a filelist based on a pattern.  For some reason, if I do the command interactively and not assign it to an array variable I get what I thought I should, but if I do this inside my R program it chops off some file names and thinks there are two.
> >  
> > I looked on the R website and found that there is an 8,096 character limit when using a character array but mine chops at 119.
> >  
> > Here is the command:
> > filelist <- system(paste("ls ", INPUTFILES, sep=""),intern=T)
> >  
> > Any help would be much appreciated.
> >  
> 
>   I dont know why that doesn't work - it might be specific to the files 
> on your system. However, R has some functions for finding files, such as 
> list.files():

It was an undocumented limit on R < 1.6.2, so this is probably a long 
obselete version of R.

> 
>  > filelist <- list.files(pattern=".dat$")
>  > filelist
> [1] "jobacct.dat" "winmail.dat"
>  >
> 
>   Get more info by typing ?list.files
> 
>   The following functions may also be useful:
> 
> file.access(base)       Ascertain File Accessibility
> file.choose(base)       Choose a File Interactively
> file.info(base)         Extract File Information
> file.path(base)         Construct Path to File
> file.show(base)         Display One or More Files

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From emkiba at gmx.de  Fri Sep 12 14:29:13 2003
From: emkiba at gmx.de (Michael Kirschbaum)
Date: Fri, 12 Sep 2003 14:29:13 +0200
Subject: [R] convert a Character-string to a number
Message-ID: <000d01c37929$7da71db0$0b01a8c0@tvpaxter>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030912/8ebd5085/attachment.pl

From bolker at zoo.ufl.edu  Fri Sep 12 14:42:48 2003
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Fri, 12 Sep 2003 08:42:48 -0400 (EDT)
Subject: [R] convert a Character-string to a number
In-Reply-To: <000d01c37929$7da71db0$0b01a8c0@tvpaxter>
Message-ID: <Pine.LNX.4.44.0309120842430.6475-100000@bolker.zoo.ufl.edu>


  ?as.numeric

On Fri, 12 Sep 2003, Michael Kirschbaum wrote:

> Hi Everyone.
> 
> I have a simple problem but don't know, how to get along.
> 
> how can I convert the vector
> 
> a<-c("0,01","1,00")
> in a vector 
> b<-c(0.01,1.00)
> 
> Thank you for suggestions
> 
> M.Kirschbaum
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From zeileis at ci.tuwien.ac.at  Fri Sep 12 14:35:03 2003
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Fri, 12 Sep 2003 14:35:03 +0200
Subject: [R] convert a Character-string to a number
In-Reply-To: <000d01c37929$7da71db0$0b01a8c0@tvpaxter>
References: <000d01c37929$7da71db0$0b01a8c0@tvpaxter>
Message-ID: <200309121235.h8CCZ3Vl023952@thorin.ci.tuwien.ac.at>

On Friday 12 September 2003 14:29, Michael Kirschbaum wrote:

> Hi Everyone.
>
> I have a simple problem but don't know, how to get along.
>
> how can I convert the vector
>
> a<-c("0,01","1,00")
> in a vector
> b<-c(0.01,1.00)

You can use as.numeric(), but you need to change the decimal delimiter 
to ".", e.g.

R> as.numeric(gsub(",", ".", a))
[1] 0.01 1.00

hth,
Z

> Thank you for suggestions
>
> M.Kirschbaum
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From p.dalgaard at biostat.ku.dk  Fri Sep 12 14:36:28 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri, 12 Sep 2003 12:36:28 -0000
Subject: [R] convert a Character-string to a number
In-Reply-To: <000d01c37929$7da71db0$0b01a8c0@tvpaxter>
References: <000d01c37929$7da71db0$0b01a8c0@tvpaxter>
Message-ID: <x2wuce6v0v.fsf@biostat.ku.dk>

"Michael Kirschbaum" <emkiba at gmx.de> writes:

> Hi Everyone.
> 
> I have a simple problem but don't know, how to get along.
> 
> how can I convert the vector
> 
> a<-c("0,01","1,00")
> in a vector 
> b<-c(0.01,1.00)
> 
> Thank you for suggestions

[Expect about 10 people to chime in...]

as.numeric(sub(",", ".", a))

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From laurent.faisnel at ariase.com  Fri Sep 12 14:44:31 2003
From: laurent.faisnel at ariase.com (Laurent Faisnel)
Date: Fri, 12 Sep 2003 14:44:31 +0200
Subject: [R] convert a Character-string to a number
References: <000d01c37929$7da71db0$0b01a8c0@tvpaxter>
Message-ID: <3F61BFAF.5080500@ariase.com>

Michael Kirschbaum wrote:

> how can I convert the vector
> 
> a<-c("0,01","1,00")
> in a vector 
> b<-c(0.01,1.00)

What is your decimal delimiter ? '.' or ',' ?
If it is ',' you should change it into '.' and then as.numeric() works 
just fine.
If it is '.' it won't work.

HTH,
Laurent



From Simon.Fear at synequanon.com  Fri Sep 12 14:40:38 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Fri, 12 Sep 2003 13:40:38 +0100
Subject: [R] convert a Character-string to a number
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572D273F5@synequanon01>

as.numeric(gsub(",", ".", a))

works if the locale is such that decimal points are used instead of
commas, but you might seek a more generic solution and have
R use a comma for decimal separation - see ?localeconv.

> -----Original Message-----
> From: Michael Kirschbaum [mailto:emkiba at gmx.de]
> Sent: 12 September 2003 13:29
> To: R-Help
> Subject: [R] convert a Character-string to a number
> 
> 
> Security Warning:
> If you are not sure an attachment is safe to open please contact 
> Andy on x234. There are 0 attachments with this message.
> ________________________________________________________________
> 
> Hi Everyone.
> 
> I have a simple problem but don't know, how to get along.
> 
> how can I convert the vector
> 
> a<-c("0,01","1,00")
> in a vector 
> b<-c(0.01,1.00)
> 
> Thank you for suggestions
> 
> M.Kirschbaum
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
 

Simon Fear
Senior Statistician
Syne qua non Ltd
Tel: +44 (0) 1379 644449
Fax: +44 (0) 1379 644445
email: Simon.Fear at synequanon.com
web: http://www.synequanon.com
 
Number of attachments included with this message: 0
 
This message (and any associated files) is confidential and\...{{dropped}}



From petzoldt at rcs.urz.tu-dresden.de  Fri Sep 12 14:38:43 2003
From: petzoldt at rcs.urz.tu-dresden.de (Thomas Petzoldt)
Date: Fri, 12 Sep 2003 14:38:43 +0200
Subject: [R] convert a Character-string to a number
In-Reply-To: <000d01c37929$7da71db0$0b01a8c0@tvpaxter>
References: <000d01c37929$7da71db0$0b01a8c0@tvpaxter>
Message-ID: <3F61BE53.4080009@rcs.urz.tu-dresden.de>

Michael Kirschbaum schrieb:

> Hi Everyone.
> 
> I have a simple problem but don't know, how to get along.
> 
> how can I convert the vector
> 
> a<-c("0,01","1,00")
> in a vector 
> b<-c(0.01,1.00)
> 
> Thank you for suggestions

Ah, it seems to be a common German problem. My solution is:

as.numeric(sub(",",".",a))

Thomas



From krcabrer at unalmed.edu.co  Fri Sep 12 14:56:34 2003
From: krcabrer at unalmed.edu.co (Kenneth Cabrera)
Date: Fri, 12 Sep 2003 07:56:34 -0500
Subject: [R] convert a Character-string to a number
In-Reply-To: <000d01c37929$7da71db0$0b01a8c0@tvpaxter>
References: <000d01c37929$7da71db0$0b01a8c0@tvpaxter>
Message-ID: <oprvd0wkr7faouaq@200.24.8.4>

Try

as.numeric(gsub(",",".",a))


Hope it helps!!


Best regards

Kenneth

On Fri, 12 Sep 2003 14:29:13 +0200, Michael Kirschbaum <emkiba at gmx.de> 
wrote:

> Hi Everyone.
>
> I have a simple problem but don't know, how to get along.
>
> how can I convert the vector
>
> a<-c("0,01","1,00")
> in a vector b<-c(0.01,1.00)
>
> Thank you for suggestions
>
> M.Kirschbaum
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



--



From peter.schlattmann at medizin.fu-berlin.de  Fri Sep 12 15:00:43 2003
From: peter.schlattmann at medizin.fu-berlin.de (Dr. Peter Schlattmann)
Date: Fri, 12 Sep 2003 15:00:43 +0200 (CEST)
Subject: [R] nlme and simulation 
Message-ID: <32931.160.45.172.237.1063371643.squirrel@www.medizin.fu-berlin.de>

Dear all,

I would like to simulate data from a nlme model using  fixed effects and the
variances of the random effects distribution.

I scanned the help files and the mailing lists with no succes. Thanks for
your help!

Peter



From Christophe.Bouget at nogent.cemagref.fr  Fri Sep 12 15:19:14 2003
From: Christophe.Bouget at nogent.cemagref.fr (Bouget Christophe)
Date: Fri, 12 Sep 2003 15:19:14 +0200
Subject: [R] partial mantel
Message-ID: <31CFB6E0A456D511917700C04F10997CEB5BB8@orme.nogent.cemagref.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030912/156fb16c/attachment.pl

From tlumley at u.washington.edu  Fri Sep 12 15:43:32 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 12 Sep 2003 06:43:32 -0700 (PDT)
Subject: [R] (structured) programming style
In-Reply-To: <1063328283.1905.31.camel@iron.libaux.ucsf.edu>
Message-ID: <Pine.A41.4.44.0309120642390.166296-100000@homer08.u.washington.edu>

On Thu, 11 Sep 2003, Ross Boylan wrote:
> Where and what is the Bioconductor list?
>

See http://www.bioconductor.org.   It's an open-source bioinformatics
project using R.

	-thomas



From friendly at yorku.ca  Fri Sep 12 15:45:36 2003
From: friendly at yorku.ca (Michael Friendly)
Date: Fri, 12 Sep 2003 09:45:36 -0400
Subject: [R] Flipping a heatmap
In-Reply-To: <200309121000.h8CA0h9e013765@stat.math.ethz.ch>
References: <200309121000.h8CA0h9e013765@stat.math.ethz.ch>
Message-ID: <3F61CE00.5090106@yorku.ca>

On Thu, 11 Sep 2003 07:46:16 -0400, Duncan Murdoch wrote

>>>My feeling is that heatmap is not the right thing to use on a correlation
>>>matrix.  The heatmap function expects a data matrix, and does a two-way
>>>clustering of cases and variables.  It tries to rearrange the rows and
>>>columns so that similar colors are closer together.  This obviously will not
>>>work for a correlation matrix.  
>
>
>There are several different ways you might organize the rows and
>columns of a correlation matrix, but rearranging it to put equal
>correlations together sounds like one sensible idea.  You'd probably
>want row and column labels rather than the dendrogram heatmap() puts
>on, but other than that, it seems like a nice idea to me.
>
>Duncan Murdoch
>

My American Statistician paper,
@Article{Friendly:02:corrgram,
  author =       "M. Friendly",
  year =         "2002",
  journal = TAS,
  volume = 56,
  number = 4,
  pages = "316--324",
  title =        "Corrgrams: Exploratory displays for correlation matrices",
  url =          "http://www.math.yorku.ca/SCS/Papers/corrgram.pdf",
}


defines a simple scheme for reordering a correlation matrix 
(or R^-1, for conditional independence) based
on angles of the first two eigenvectors.  A variety
of rendering schemes is also described. 
There's a SAS macro at

  *     Doc: http://www.math.yorku.ca/SCS/sasmac/corrgram.html   *



-- 
Michael Friendly     Email: friendly at yorku.ca 
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA



From spencer.graves at pdf.com  Fri Sep 12 16:11:08 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 12 Sep 2003 07:11:08 -0700
Subject: [R] nlme and simulation
References: <32931.160.45.172.237.1063371643.squirrel@www.medizin.fu-berlin.de>
Message-ID: <3F61D3FC.6090900@pdf.com>

Have you looked at Pinhiero and Bates (2000) Mixed-Effects Models for S 
and S-Plus (Springer)?  They describe the use of simulation to evaluate 
the sampling distribution when a parameter is at a boundary.  For the 
cases they consider, they find that a mixture of chi-squares with 
different numbers of degrees of freedom (being number of parameters 
estimated with and without the parameter potentially at the boundary) 
works quite well.  I don't have the book here so can't give you a page 
citation, but it's in a methodology chapter (3?), and they have 
beautiful plot to illustrate the results.

hope this helps.
spencer graves

Dr. Peter Schlattmann wrote:
> Dear all,
> 
> I would like to simulate data from a nlme model using  fixed effects and the
> variances of the random effects distribution.
> 
> I scanned the help files and the mailing lists with no succes. Thanks for
> your help!
> 
> Peter
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From abunn at mymail.msu.montana.edu  Fri Sep 12 16:21:43 2003
From: abunn at mymail.msu.montana.edu (abunn@mymail.msu.montana.edu)
Date: Fri, 12 Sep 2003 08:21:43 -0600
Subject: [R] partial mantel
Message-ID: <6cc7e440d74c40f99f10994dd7819c24.abunn@mymail.msu.montana.edu>

Dean Urban at Duke University has an S+ library that will do full and partial Mantel Tests. I know that it has been ported to R sucessfully.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~`
EcoDist 

EcoDist is a library of functions for S-plus, to perform a variety of analyses based on ecolgical distance or dissimilarity, written primarily by Sarah Goslee. This is not yet ready for release, but if you're interested in trying a preliminary version, contact deanu at duke.edu. 




----- Original Message -----
From: Bouget Christophe
Sent: 9/12/2003 7:19:14 AM
To: r-help at stat.math.ethz.ch
Subject: [R] partial mantel

> Dear all,
> Has anyone written R code for partial Mantel Tests- as described for
> instance in Legtendre & Legendre (1998) ?
> In other words, in a community ecology analysis, I would like to calculate
> the correlation between two dissimilarity matrices, controlling for a third
> distance matrix representing geographical distances between sites.
> Thanks! 
> 
> Christophe Bouget
> Biodiversité et gestion des forêts de plaine - Ecosylv
> Ecosystèmes forestiers et paysages
> Institut de recherches pour l'ingénierie de l'agriculture et de
> l'environnement - CEMAGREF
> Domaine des Barres
> F-45 290 Nogent-sur-Vernisson
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
>



From solares at unsl.edu.ar  Fri Sep 12 16:43:43 2003
From: solares at unsl.edu.ar (solares@unsl.edu.ar)
Date: Fri, 12 Sep 2003 11:43:43 -0300 (ART)
Subject: [R] save object interactively
Message-ID: <39999.170.210.173.216.1063377823.squirrel@inter14.unsl.edu.ar>

Hello, it wanted to know as I can keep to save a object of R in interactive 
form, in which I can put the name of the file in a window of I talk, and 
not to have to create it, a badly serious example:

 x<-c(1,2,3,4)
> nbre<-"x.Rdata"
> f<-file.choose()
Error in file.choose() : file choice cancelled
> f
Error: Object "f" not found
> file.create(nbre)
[1] TRUE
> f<-file.choose()
> save(nbre,file=f)

But I should create the file before electing it, there is not form of 
opening a window of I talk and to keep with a name that I can put in that 
window?  Does not something exist as 
file.choose.save?  . Thanks Ruben



From opal7313 at yahoo.fr  Fri Sep 12 17:21:49 2003
From: opal7313 at yahoo.fr (=?iso-8859-1?q?N=20L?=)
Date: Fri, 12 Sep 2003 17:21:49 +0200 (CEST)
Subject: [R] libraries of Rgraphviz and rhdf5
Message-ID: <20030912152149.25992.qmail@web60203.mail.yahoo.com>

I just installed bioconductor via getBioC.R but there
is 3 problems: apparently some libraries are missing
and I don't know which one, and even the XML package
add a error message like : 
1:Installation of package Rgraphviz had non-zero exit
status in: installPkg(fileName, pkg, pkgVer, type,
lib, repEntry, versForce)
2:Installation of package rhdf5 had non-zero exit
status in: installPkg(fileName, pkg, pkgVer, type,
lib, repEntry, versForce)
3:Installation of package XML had non-zero exit status
in: installPkg(fileName, pkg, pkgVer, type, lib,
repEntry, versForce)
What can I do?

Thanks in advance!

Line



From emkiba at gmx.de  Fri Sep 12 17:28:45 2003
From: emkiba at gmx.de (Michael Kirschbaum)
Date: Fri, 12 Sep 2003 17:28:45 +0200
Subject: [R] Sorting a vector by date 
Message-ID: <005c01c37942$8e46e880$0b01a8c0@tvpaxter>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030912/414a30b5/attachment.pl

From ripley at stats.ox.ac.uk  Fri Sep 12 17:50:10 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 12 Sep 2003 16:50:10 +0100 (BST)
Subject: [R] Sorting a vector by date 
In-Reply-To: <005c01c37942$8e46e880$0b01a8c0@tvpaxter>
Message-ID: <Pine.LNX.4.44.0309121647570.29430-100000@gannet.stats>

On Fri, 12 Sep 2003, Michael Kirschbaum wrote:

> Hello out there....
> 
> Again I have a problem and I stuck...
> 
> How can  I sort a vector of dates?
> 
> For example I have the vector
> 
> a<-ISOdate(2001, 1, 1) + 70*86400*runif(10)

> How can this vector be sorted chronological?

a[sort.list(a)]


> And what's the function I should work with to handle  these entries?
> (in sense of:  which(a>2001-01-04) or somehting like that)

No function, just make sure you use *dates*, as in

which(a > as.POSIXct("2001-01-04"))


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From laurent.faisnel at ariase.com  Fri Sep 12 17:57:45 2003
From: laurent.faisnel at ariase.com (Laurent Faisnel)
Date: Fri, 12 Sep 2003 17:57:45 +0200
Subject: [R] Sorting a vector by date
References: <005c01c37942$8e46e880$0b01a8c0@tvpaxter>
Message-ID: <3F61ECF9.30909@ariase.com>

Michael Kirschbaum wrote:
> Hello out there....
> 
> Again I have a problem and I stuck...
> 
> How can  I sort a vector of dates?

A look at ?sort could help...

> 
> For example I have the vector
> 
> a<-ISOdate(2001, 1, 1) + 70*86400*runif(10)
> 
> How can this vector be sorted chronological?

  a is :
  [1] "2001-03-05 10:48:42 CET" "2001-01-30 09:29:32 CET"
  [3] "2001-02-12 11:15:02 CET" "2001-03-07 23:58:43 CET"
  [5] "2001-01-16 08:02:11 CET" "2001-02-25 00:52:20 CET"
  [7] "2001-01-04 21:34:45 CET" "2001-01-30 09:37:40 CET"
  [9] "2001-02-05 19:10:17 CET" "2001-01-09 17:41:49 CET"

sort(a) does just what you wanted without any option - I still advise 
you to have a close look at ?sort


> And what's the function I should work with to handle  these entries?
> (in sense of:  which(a>2001-01-04) or somehting like that)

You have to convert with ISOdate the date you want to compare with the 
ones in the vector. For example,

d<-ISOdate(2001,2,1)

then you can do things like :

aa<-a[a<d]

See ?ISOdate

> 
> Thank you for helping
> 
> M.Kirschbaum
> 
> 	[[alternative HTML version deleted]]

If you haven't been told yet : you should post text-only messages.

> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
>



From Alvaro.Antonio.Novo at bportugal.pt  Fri Sep 12 18:55:02 2003
From: Alvaro.Antonio.Novo at bportugal.pt (Alvaro.Antonio.Novo@bportugal.pt)
Date: Fri, 12 Sep 2003 17:55:02 +0100
Subject: [R] Converting character to function argument
Message-ID: <OFF0E04CE7.332A1B64-ON80256D9F.005B8410-80256D9F.005CEE34@exterior.bportugal.pt>

How can one transform a character string into an argument of a function
(which is not or I don't want it to be a character string)?

Example:

> expand.grid(c(1,0),c(1,0)) ## OK
  Var1 Var2
1    1    1
2    0    1
3    1    0
4    0    0


> paste(rep("c(0,1)",2),collapse=',') ## to be used below
[1] "c(0,1),c(0,1)"
> ## string is the input I want, but it needs to be coerced to the correct
format

> expand.grid(paste(rep("c(0,1)",2),collapse=',')) ## does not get me there
           Var1
1 c(0,1),c(0,1)

***************************************************************************
 AVISO DE CONFIDENCIALIDADE: Esta mensagem, assim como os ficheiros
eventualmente anexos, ? confidencial e reservada apenas ao conhecimento
da(s) pessoa(s) nela indicada(s) como destinat?ria(s). Se n?o ? o seu
destinat?rio, solicitamos que n?o fa?a qualquer uso do respectivo conte?do
e proceda ? sua destrui??o, notificando o remetente.
 LIMITA??O DE RESPONSABILIDADE: A seguran?a da transmiss?o de informa??o
por via electr?nica n?o pode ser garantida pelo remetente, o qual, em
consequ?ncia, n?o se responsabiliza por qualquer facto suscept?vel de
afectar a sua integridade.

 CONFIDENTIALITY NOTICE: This message, as well as existing attached files,
is confidential and intended exclusively for the individual(s) named as
addressees. If you are not the intended recipient, you are kindly requested
not to make any use whatsoever of its contents and to proceed to the
destruction of the message, thereby notifying the sender.
 DISCLAIMER: The sender of this message can not ensure the security of its
electronical transmission and consequently does not accept liability for
any fact which may interfere with the integrity of its content.



From MBock at arcadis-us.com  Fri Sep 12 19:01:46 2003
From: MBock at arcadis-us.com (Bock, Michael)
Date: Fri, 12 Sep 2003 11:01:46 -0600
Subject: [R] converting dataframe columns to vector and missing values
Message-ID: <DECFA52780A9724B81782C71B45AD02B060AFA@corpexch4.arcadis-us.com>

I am relatively new to R, but very pleased with what I can do with it so
far.
I am embarrassed to ask what seems like a simple question but I am at my
wits end. Basically I have written a function to calculate a bootstrapped
statistic on a list of values. The function works perfectly if I can feed it
the right data. I am exporting data into R as a dataframe and then assigning
each column to the list and running the function use a for loop. The problem
is what is the best way to convert the columns to a list. The column names
and the number of columns will vary depending on the dataset. I am currently
converting the dataframe to a matrix and the assigning each column of the
matrix to the list in turn:

#InputData is the dataframe
RunTests <- function (InputData) 
	{
	n <- length(InputData)
	Chem <- colnames(InputData)
	for (i in 1:n){
		print (Chem[i])
		Data <- data.matrix(InputData)
		x <- Data[,n]
		na.omit(x)
		#print(x)
		UCL <- HallBoot(x)
		print (UCL)
		}

	} 
Although this works some of the time, missing values are not removed. This
is a huge problem as the number of observation is each column is quite
variable. Obviously the na.omit is not working the way I expect. Any help
would be appreciated, including a whole new approach to sending the data to
the HallBoot function.

Michael J. Bock, PhD.
ARCADIS
24 Preble St. Suite 100
Portland, ME 04101
207.828.0046
fax 207.828.0062



From dmurdoch at pair.com  Fri Sep 12 19:09:57 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Fri, 12 Sep 2003 13:09:57 -0400
Subject: [R] save object interactively
In-Reply-To: <39999.170.210.173.216.1063377823.squirrel@inter14.unsl.edu.ar>
References: <39999.170.210.173.216.1063377823.squirrel@inter14.unsl.edu.ar>
Message-ID: <rdv3mv45ssno8i2iitm73r9h4nes44h2k0@4ax.com>

On Fri, 12 Sep 2003 11:43:43 -0300 (ART), <solares at unsl.edu.ar> wrote 
>> f<-file.choose()
>> save(nbre,file=f)
>
>But I should create the file before electing it, there is not form of 
>opening a window of I talk and to keep with a name that I can put in that 
>window?  Does not something exist as 
>file.choose.save?  . Thanks Ruben

The argument to the save function can be the result of a calculation,
so you could have

 save(nbre, file=file.choose())

Duncan Murdoch



From spencer.graves at pdf.com  Fri Sep 12 19:19:52 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 12 Sep 2003 10:19:52 -0700
Subject: [R] converting dataframe columns to vector and missing values
References: <DECFA52780A9724B81782C71B45AD02B060AFA@corpexch4.arcadis-us.com>
Message-ID: <3F620038.3060507@pdf.com>

Have you considered:

	  x <- Data[!is.na(Data[,n]), n]

Does this do what you want?  Vectors, arrays, and data.frame can be 
indexed by number or by a logical vector -- and by names if such are 
supplied.  In this case, "!is.na(Data[,n])" is a logical vector of 
length = number of rows of Data.

hope this helps.  spencer graves

Bock, Michael wrote:
> I am relatively new to R, but very pleased with what I can do with it so
> far.
> I am embarrassed to ask what seems like a simple question but I am at my
> wits end. Basically I have written a function to calculate a bootstrapped
> statistic on a list of values. The function works perfectly if I can feed it
> the right data. I am exporting data into R as a dataframe and then assigning
> each column to the list and running the function use a for loop. The problem
> is what is the best way to convert the columns to a list. The column names
> and the number of columns will vary depending on the dataset. I am currently
> converting the dataframe to a matrix and the assigning each column of the
> matrix to the list in turn:
> 
> #InputData is the dataframe
> RunTests <- function (InputData) 
> 	{
> 	n <- length(InputData)
> 	Chem <- colnames(InputData)
> 	for (i in 1:n){
> 		print (Chem[i])
> 		Data <- data.matrix(InputData)
> 		x <- Data[,n]
> 		na.omit(x)
> 		#print(x)
> 		UCL <- HallBoot(x)
> 		print (UCL)
> 		}
> 
> 	} 
> Although this works some of the time, missing values are not removed. This
> is a huge problem as the number of observation is each column is quite
> variable. Obviously the na.omit is not working the way I expect. Any help
> would be appreciated, including a whole new approach to sending the data to
> the HallBoot function.
> 
> Michael J. Bock, PhD.
> ARCADIS
> 24 Preble St. Suite 100
> Portland, ME 04101
> 207.828.0046
> fax 207.828.0062
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From spencer.graves at pdf.com  Fri Sep 12 19:21:44 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 12 Sep 2003 10:21:44 -0700
Subject: [R] Converting character to function argument
References: <OFF0E04CE7.332A1B64-ON80256D9F.005B8410-80256D9F.005CEE34@exterior.bportugal.pt>
Message-ID: <3F6200A8.1080101@pdf.com>

Have you considered

	 eval(parse(text="expand.grid(c(1,0),c(1,0))"))

There are other ways to get what you want, but this should work.

hope this helps.  spencer graves

Alvaro.Antonio.Novo at bportugal.pt wrote:
> How can one transform a character string into an argument of a function
> (which is not or I don't want it to be a character string)?
> 
> Example:
> 
> 
>>expand.grid(c(1,0),c(1,0)) ## OK
> 
>   Var1 Var2
> 1    1    1
> 2    0    1
> 3    1    0
> 4    0    0
> 
> 
> 
>>paste(rep("c(0,1)",2),collapse=',') ## to be used below
> 
> [1] "c(0,1),c(0,1)"
> 
>>## string is the input I want, but it needs to be coerced to the correct
> 
> format
> 
> 
>>expand.grid(paste(rep("c(0,1)",2),collapse=',')) ## does not get me there
> 
>            Var1
> 1 c(0,1),c(0,1)
> 
> ***************************************************************************
>  AVISO DE CONFIDENCIALIDADE: Esta mensagem, assim como os ficheiros
> eventualmente anexos, ? confidencial e reservada apenas ao conhecimento
> da(s) pessoa(s) nela indicada(s) como destinat?ria(s). Se n?o ? o seu
> destinat?rio, solicitamos que n?o fa?a qualquer uso do respectivo conte?do
> e proceda ? sua destrui??o, notificando o remetente.
>  LIMITA??O DE RESPONSABILIDADE: A seguran?a da transmiss?o de informa??o
> por via electr?nica n?o pode ser garantida pelo remetente, o qual, em
> consequ?ncia, n?o se responsabiliza por qualquer facto suscept?vel de
> afectar a sua integridade.
> 
>  CONFIDENTIALITY NOTICE: This message, as well as existing attached files,
> is confidential and intended exclusively for the individual(s) named as
> addressees. If you are not the intended recipient, you are kindly requested
> not to make any use whatsoever of its contents and to proceed to the
> destruction of the message, thereby notifying the sender.
>  DISCLAIMER: The sender of this message can not ensure the security of its
> electronical transmission and consequently does not accept liability for
> any fact which may interfere with the integrity of its content.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From hb at maths.lth.se  Fri Sep 12 19:32:13 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Fri, 12 Sep 2003 19:32:13 +0200
Subject: [R] Converting character to function argument
In-Reply-To: <OFF0E04CE7.332A1B64-ON80256D9F.005B8410-80256D9F.005CEE34@exterior.bportugal.pt>
Message-ID: <000d01c37953$d0c34350$2e0040d5@maths.lth.se>

eval() and parse() are you friends here. Possibly also substitute().
Example:

 eval(parse(text="expand.grid(c(1,0),c(1,0))"))

However, I would like to reply with a question to you. Why do you end up
with a string that you need to convert in the first place? Maybe you are
more interested in a solution like the following one:

N <- 2
l <- lapply(1:N, FUN=function(x) c(0,1))
expand.grid(l)

Henrik Bengtsson
Lund University

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Alvaro.Antonio.Novo at bportugal.pt
> Sent: den 12 september 2003 18:55
> To: r-help at stat.math.ethz.ch
> Subject: [R] Converting character to function argument
> 
> 
> How can one transform a character string into an argument of 
> a function (which is not or I don't want it to be a character string)?
> 
> Example:
> 
> > expand.grid(c(1,0),c(1,0)) ## OK
>   Var1 Var2
> 1    1    1
> 2    0    1
> 3    1    0
> 4    0    0
> 
> 
> > paste(rep("c(0,1)",2),collapse=',') ## to be used below
> [1] "c(0,1),c(0,1)"
> > ## string is the input I want, but it needs to be coerced to the 
> > correct
> format
> 
> > expand.grid(paste(rep("c(0,1)",2),collapse=',')) ## does not get me 
> > there
>            Var1
> 1 c(0,1),c(0,1)
> 
> **************************************************************
> *************
>  AVISO DE CONFIDENCIALIDADE: Esta mensagem, assim como os 
> ficheiros eventualmente anexos, ? confidencial e reservada 
> apenas ao conhecimento
> da(s) pessoa(s) nela indicada(s) como destinat?ria(s). Se n?o 
> ? o seu destinat?rio, solicitamos que n?o fa?a qualquer uso 
> do respectivo conte?do e proceda ? sua destrui??o, 
> notificando o remetente.  LIMITA??O DE RESPONSABILIDADE: A 
> seguran?a da transmiss?o de informa??o por via electr?nica 
> n?o pode ser garantida pelo remetente, o qual, em 
> consequ?ncia, n?o se responsabiliza por qualquer facto 
> suscept?vel de afectar a sua integridade.
> 
>  CONFIDENTIALITY NOTICE: This message, as well as existing 
> attached files, is confidential and intended exclusively for 
> the individual(s) named as addressees. If you are not the 
> intended recipient, you are kindly requested not to make any 
> use whatsoever of its contents and to proceed to the 
> destruction of the message, thereby notifying the sender.
>  DISCLAIMER: The sender of this message can not ensure the 
> security of its electronical transmission and consequently 
> does not accept liability for any fact which may interfere 
> with the integrity of its content.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> 
>



From ligges at statistik.uni-dortmund.de  Fri Sep 12 19:47:06 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 12 Sep 2003 19:47:06 +0200
Subject: [R] Converting character to function argument
In-Reply-To: <000d01c37953$d0c34350$2e0040d5@maths.lth.se>
References: <000d01c37953$d0c34350$2e0040d5@maths.lth.se>
Message-ID: <3F62069A.2090708@statistik.uni-dortmund.de>

Henrik Bengtsson wrote:

> eval() and parse() are you friends here. Possibly also substitute().
> Example:
> 
>  eval(parse(text="expand.grid(c(1,0),c(1,0))"))
> 
> However, I would like to reply with a question to you. Why do you end up
> with a string that you need to convert in the first place? 

That's the question, indeed!


 > Maybe you are
> more interested in a solution like the following one:
> 
> N <- 2
> l <- lapply(1:N, FUN=function(x) c(0,1))
> expand.grid(l)
 >
> Henrik Bengtsson
> Lund University



Or, if you are really going to work completely on characters (hence you 
have to be more specific!):

  do.call("expand.grid", rep(list(eval(parse(text = "c(1, 0)"))), 2))

Uwe Ligges


> 
>>-----Original Message-----
>>From: r-help-bounces at stat.math.ethz.ch 
>>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
>>Alvaro.Antonio.Novo at bportugal.pt
>>Sent: den 12 september 2003 18:55
>>To: r-help at stat.math.ethz.ch
>>Subject: [R] Converting character to function argument
>>
>>
>>How can one transform a character string into an argument of 
>>a function (which is not or I don't want it to be a character string)?
>>
>>Example:
>>
>>
>>>expand.grid(c(1,0),c(1,0)) ## OK
>>
>>  Var1 Var2
>>1    1    1
>>2    0    1
>>3    1    0
>>4    0    0
>>
>>
>>
>>>paste(rep("c(0,1)",2),collapse=',') ## to be used below
>>
>>[1] "c(0,1),c(0,1)"
>>
>>>## string is the input I want, but it needs to be coerced to the 
>>>correct
>>
>>format
>>
>>
>>>expand.grid(paste(rep("c(0,1)",2),collapse=',')) ## does not get me 
>>>there
>>
>>           Var1
>>1 c(0,1),c(0,1)
>>



From TyagiAnupam at aol.com  Fri Sep 12 20:24:01 2003
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Fri, 12 Sep 2003 14:24:01 EDT
Subject: [R] factor creation
Message-ID: <69.3bff8111.2c936941@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030912/818d3290/attachment.pl

From tblackw at umich.edu  Fri Sep 12 23:59:19 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Fri, 12 Sep 2003 17:59:19 -0400 (EDT)
Subject: [R] converting dataframe columns to vector and missing values
In-Reply-To: <3F620038.3060507@pdf.com>
Message-ID: <Pine.SOL.4.44.0309121741590.23443-100000@rygar.gpcc.itd.umich.edu>

On Fri, 12 Sep 2003, Spencer Graves wrote:

> Have you considered:
>
> 	  x <- Data[!is.na(Data[,n]), n]
>
> Does this do what you want?  Vectors, arrays, and data.frame can be
> indexed by number or by a logical vector -- and by names if such are
> supplied.  In this case, "!is.na(Data[,n])" is a logical vector of
> length = number of rows of Data.
>
> hope this helps.  spencer graves

Tom Blackwell adds ... Or even do the whole thing in one line as:

UCL.all <- lapply(InputData, function(x) HallBoot(na.omit(x)))
UCL.all      #  displays the result

Now the object  UCL.all  is a named list whose names are the names of
the columns in InputData, in order, and whose values are the output
from  HallBoot().  Spencer is protecting you from having to learn all
the intricacies of R list structure.

I think the example given in  help("na.omit")  is just a bit misleading.
It shows  na.omit()  used alone on a very small data frame named x.
It demonstrates that the return value of  na.omit(x)  omits the entire
third row, because that row has an NA in the second column, and it does
this by using  autoprint()  to display the result.  Nothing makes it
clear that the command  na.omit(x)  has not changed the object x at all.

But that is a common paradigm in R.  The arguments to a function are
passed by value, not by reference, and they ALWAYS remain unchanged by
having been used, unless they are explicitly overwritten.  (There must
be a few exceptions to this, but I can't think of them.)

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

> Bock, Michael wrote:
> > I am relatively new to R, but very pleased with what I can do with it so
> > far.
> > I am embarrassed to ask what seems like a simple question but I am at my
> > wits end. Basically I have written a function to calculate a bootstrapped
> > statistic on a list of values. The function works perfectly if I can feed it
> > the right data. I am exporting data into R as a dataframe and then assigning
> > each column to the list and running the function use a for loop. The problem
> > is what is the best way to convert the columns to a list. The column names
> > and the number of columns will vary depending on the dataset. I am currently
> > converting the dataframe to a matrix and the assigning each column of the
> > matrix to the list in turn:
> >
> > #InputData is the dataframe
> > RunTests <- function (InputData)
> > 	{
> > 	n <- length(InputData)
> > 	Chem <- colnames(InputData)
> > 	for (i in 1:n){
> > 		print (Chem[i])
> > 		Data <- data.matrix(InputData)
> > 		x <- Data[,n]
> > 		na.omit(x)
> > 		#print(x)
> > 		UCL <- HallBoot(x)
> > 		print (UCL)
> > 		}
> >
> > 	}
> > Although this works some of the time, missing values are not removed. This
> > is a huge problem as the number of observation is each column is quite
> > variable. Obviously the na.omit is not working the way I expect. Any help
> > would be appreciated, including a whole new approach to sending the data to
> > the HallBoot function.
> >
> > Michael J. Bock, PhD.
> > ARCADIS
> > 24 Preble St. Suite 100
> > Portland, ME 04101
> > 207.828.0046
> > fax 207.828.0062



From ross at biostat.ucsf.edu  Sat Sep 13 00:47:18 2003
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Fri, 12 Sep 2003 15:47:18 -0700
Subject: [R] Playing with formulae
Message-ID: <1063406838.1905.96.camel@iron.libaux.ucsf.edu>

First, thanks to everyone for their responses to my programming style
question.  Second, I have some questions about some obscure corners of
the language.

Let
f <- y~x+z
t <- terms(f).

I want to do some manipulations of the formula that require getting the
names of variables as character strings (e.g., for indexing into a
dataset).  However, t, or even attr(t, "variables"), does not provide
character strings.

1. Does all.vars(f) reliably produce the same ordering as t?

2. Can objects of class name (which I notice appear in places in t) be
used the same way as character strings (e.g., indexing columns in a data
set, arguments to match)?  (This would matter if I could pull t apart
reliably.  I can't.  See 3b for more on that problem.)

3. t's response attribute is said to be an index of the response
variable in variables (I presume this means the variables attribute).
  a) Will all.vars(f)[attr(t, "response")] reliably get me the character
     string for the name of the response variable?
  b) How can I get the response variable out of the "variables"
     attribute?  In my example,
     response is 1, but attr(t, "variables")[1] is list().
     Possible answer: attr(t, "variables")[[response+1]] looks right,
     and is of class name.  Hence the interest in question 2.

4. Is the actual number of coefficients the model will need
length(attr(t,"term.labels"))+attr(t, "intercept"),
regardless of interactions or I() terms?
(My interest is primarily in detecting the wrong number of terms, for
example if someone specifies an interaction).

5. The documentation for terms.formula appears to imply that if there is
a simple formula without interactions I will get coefficient estimates
in the same order that the original formula specified textually.  Right?
I'm concerned about this because I'm having a vector of simulation
coefficients passed in along with the formula, and I need to be sure
they line up with the model terms.

I know that's a lot of pretty detailed questions, but if you can offer
any help that would be great.  I've tried some simple tests that seem to
work, but of course those don't prove that the assumptions always hold. 
And the documentation does not seem to resolve the issues either.

I'm using R 1.7.1, but ideally my code will not be version-specific.



From lenvi10 at yahoo.com  Sat Sep 13 00:53:50 2003
From: lenvi10 at yahoo.com (len vir)
Date: Fri, 12 Sep 2003 15:53:50 -0700 (PDT)
Subject: [R] No Comment?
Message-ID: <20030912225350.91713.qmail@web14804.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030912/324e7450/attachment.pl

From tlumley at u.washington.edu  Sat Sep 13 01:12:39 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 12 Sep 2003 16:12:39 -0700 (PDT)
Subject: [R] Playing with formulae
In-Reply-To: <1063406838.1905.96.camel@iron.libaux.ucsf.edu>
Message-ID: <Pine.A41.4.44.0309121553270.25502-100000@homer29.u.washington.edu>

On Fri, 12 Sep 2003, Ross Boylan wrote:

> First, thanks to everyone for their responses to my programming style
> question.  Second, I have some questions about some obscure corners of
> the language.
>
> Let
> f <- y~x+z
> t <- terms(f).
>
> I want to do some manipulations of the formula that require getting the
> names of variables as character strings (e.g., for indexing into a
> dataset).  However, t, or even attr(t, "variables"), does not provide
> character strings.
>
> 1. Does all.vars(f) reliably produce the same ordering as t?

It doesn't even produce the same set: consider

y~I(x+z)+w

> 2. Can objects of class name (which I notice appear in places in t) be
> used the same way as character strings (e.g., indexing columns in a data
> set, arguments to match)?  (This would matter if I could pull t apart
> reliably.  I can't.  See 3b for more on that problem.)

No, but as.character will convert them to strings.

> 3. t's response attribute is said to be an index of the response
> variable in variables (I presume this means the variables attribute).
>   a) Will all.vars(f)[attr(t, "response")] reliably get me the character
>      string for the name of the response variable?

No.  consider
Surv(t,s)~x+z

>   b) How can I get the response variable out of the "variables"
>      attribute?  In my example,
>      response is 1, but attr(t, "variables")[1] is list().
>      Possible answer: attr(t, "variables")[[response+1]] looks right,
>      and is of class name.  Hence the interest in question 2.

The "factors" attribute has row names corresponding to variables and
column names corresponding to terms.

> 4. Is the actual number of coefficients the model will need
> length(attr(t,"term.labels"))+attr(t, "intercept"),
> regardless of interactions or I() terms?

No. A term can create multiple columns of the design matrix, eg factors,
polynomials, splines.  You won't know how many until you call
model.matrix.

> 5. The documentation for terms.formula appears to imply that if there is
> a simple formula without interactions I will get coefficient estimates
> in the same order that the original formula specified textually.  Right?
> I'm concerned about this because I'm having a vector of simulation
> coefficients passed in along with the formula, and I need to be sure
> they line up with the model terms.

Yes.

It might be useful to have names on the coefficients,  though.  Then you
could match on the names and not worry


An example of the sort of thing you're trying to do is in
untangle.specials() in the survival package, which is used to locate terms
and variables for strata() and cluster() in coxph().  It uses the dimnames
of the "factors" attribute as keys.

	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From ross at biostat.ucsf.edu  Sat Sep 13 02:22:18 2003
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Fri, 12 Sep 2003 17:22:18 -0700
Subject: [R] Playing with formulae
In-Reply-To: <Pine.A41.4.44.0309121553270.25502-100000@homer29.u.washington.edu>
References: <Pine.A41.4.44.0309121553270.25502-100000@homer29.u.washington.edu>
Message-ID: <1063412538.1904.114.camel@iron.libaux.ucsf.edu>

Thanks.  Not what I was hoping to hear, but it's good to know.  Back to
the drawing board(:  Perhaps since I really don't want to allow
interactions and other exotica, I should just have the names of the
covariates passed in, and then construct the formula from that (with
paste and as.formula?).

A couple of follow up questions.
On Fri, 2003-09-12 at 16:12, Thomas Lumley wrote:
> On Fri, 12 Sep 2003, Ross Boylan wrote:
.....
> 
> >   b) How can I get the response variable out of the "variables"
> >      attribute?  In my example,
> >      response is 1, but attr(t, "variables")[1] is list().
> >      Possible answer: attr(t, "variables")[[response+1]] looks right,
> >      and is of class name.  Hence the interest in question 2.
> 

Is attr(t, "variables")[[response+1]] always the right term, though it
may not be of class name if the response is an expression?

> The "factors" attribute has row names corresponding to variables and
> column names corresponding to terms.
> 
Is the first row name always the response (though it may not be a simple
variable name)?

....
> 
> An example of the sort of thing you're trying to do is in
> untangle.specials() in the survival package, which is used to locate terms
> and variables for strata() and cluster() in coxph().  It uses the dimnames
> of the "factors" attribute as keys.
> 

I'm working on a modified version of those routines, so I'll have
another look.  The strata term was one of the reasons I was mucking
around.

By the way, do you or anyone know what's special about specials?  The
only thing the documentation mentioned (that I saw) was that terms that
were special were flagged as such.


> 	-thomas
> 
> Thomas Lumley			Assoc. Professor, Biostatistics
> tlumley at u.washington.edu	University of Washington, Seattle



From tlumley at u.washington.edu  Sat Sep 13 04:01:26 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 12 Sep 2003 19:01:26 -0700 (PDT)
Subject: [R] Playing with formulae
In-Reply-To: <1063412538.1904.114.camel@iron.libaux.ucsf.edu>
Message-ID: <Pine.A41.4.44.0309121859130.42134-100000@homer29.u.washington.edu>

On Fri, 12 Sep 2003, Ross Boylan wrote:
>
> Is attr(t, "variables")[[response+1]] always the right term, though it
> may not be of class name if the response is an expression?

Yes

> > The "factors" attribute has row names corresponding to variables and
> > column names corresponding to terms.
> >
> Is the first row name always the response (though it may not be a simple
> variable name)?

Yes.  In fact it's the attr(,"response")th rowname, but this always is
first.

>
> By the way, do you or anyone know what's special about specials?  The
> only thing the documentation mentioned (that I saw) was that terms that
> were special were flagged as such.

That *is* all that's special.  terms() has an option for you to specify
terms as special, and those terms are then flagged as special.

So coxph uses terms(formulas, specials=c("strata","cluster")) to mark
strata() and cluster() terms as special.


	-thomas



From kjetil at entelnet.bo  Sat Sep 13 05:59:27 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Fri, 12 Sep 2003 23:59:27 -0400
Subject: [R] No Comment?
In-Reply-To: <20030912225350.91713.qmail@web14804.mail.yahoo.com>
Message-ID: <3F625DDF.11866.CBA3D@localhost>

On 12 Sep 2003 at 15:53, len vir wrote:

> Hi!
>  
> Why is there no 'multiple-line comment code' in R, 

?Because the developers use ess and so see no need?

Kjetil Halvorsen

> like 
> /* 
> in C++
> or in
> GAUSS
>  */   
>  
> for example ?
>  
> Just wondering!
>  
> len
> 
> 
> ---------------------------------
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ripley at stats.ox.ac.uk  Sat Sep 13 09:09:04 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 13 Sep 2003 08:09:04 +0100 (BST)
Subject: [R] No Comment?
In-Reply-To: <3F625DDF.11866.CBA3D@localhost>
Message-ID: <Pine.LNX.4.44.0309130803080.25290-100000@gannet.stats>

On Fri, 12 Sep 2003, kjetil brinchmann halvorsen wrote:

> On 12 Sep 2003 at 15:53, len vir wrote:
> 
> > Why is there no 'multiple-line comment code' in R, 
> 
> ?Because the developers use ess and so see no need?

Mainly because S does not, and S preceded ESS and it's progenitor S-mode.

You'll find the comments in S/R are often one line and rarely more
than three.  If you want to annotate code, use a system like Sweave or 
noweb.

> Kjetil Halvorsen
> 
> > like 
> > /* 
> > in C++
> > or in
> > GAUSS
> >  */   
> >  
> > for example ?

AFAIK C++ prefers // (and /* */ is a hangover from C), and many other
languages (e.g. Fortran, Perl) have no multi-line comment device.

Many editors will allow commenting a selected block of lines, and you can
also use

if(FALSE) {
}

to comment out parts of your code.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From pburns at pburns.seanet.com  Sat Sep 13 11:54:03 2003
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Sat, 13 Sep 2003 10:54:03 +0100
Subject: [R] No Comment?
References: <3F625DDF.11866.CBA3D@localhost>
Message-ID: <3F62E93B.1090803@pburns.seanet.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030913/9d392585/attachment.pl

From pburns at pburns.seanet.com  Sat Sep 13 12:07:38 2003
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Sat, 13 Sep 2003 11:07:38 +0100
Subject: [R] No Comment?
References: <3F625DDF.11866.CBA3D@localhost>
	<3F62E93B.1090803@pburns.seanet.com>
Message-ID: <3F62EC6A.7030502@pburns.seanet.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030913/e34d46b7/attachment.pl

From junwen at astro.ocis.temple.edu  Sat Sep 13 18:51:57 2003
From: junwen at astro.ocis.temple.edu (Junwen wang)
Date: Sat, 13 Sep 2003 12:51:57 -0400 (EDT)
Subject: [R] post-doc position needed
Message-ID: <Pine.OSF.4.53.0309131251100.1017783@gs873ps>

Dear colleagues,
I am looking for a post-doc (or scientific programmer) position in
computational biology/bioinformatics. If you or your colleagues happen to
have opening and need a self-motivated person to do the job, please feel
free to call me at 215-204-5058 or email me. I have strong
background in biology, statistics and programming. I am interested in
doing research on protein structure prediction, protein interaction,
alignment algorithm development, population genetic theory/modeling or
microarray data analysis.

Please see my resume at:
http://astro.temple.edu/~junwen/resume/

regards
John



From szhan at uoguelph.ca  Sat Sep 13 20:45:47 2003
From: szhan at uoguelph.ca (szhan@uoguelph.ca)
Date: Sat, 13 Sep 2003 14:45:47 -0400
Subject: [R] what does this error mean?
Message-ID: <1063478747.3f6365dba222a@webmail.uoguelph.ca>

Dear R-users:
I am runing R 1.6.2 with Windows XP. I try to calculate Pearson correlation 
and Spearman correlation of any pairwise columns of 8000 x 80 data matrix with 
missing values and randomize the matix 1000 times and calculate this two 
correlations again. The code bellow for Pearson is working fine but for 
Spearman got the error bellow for randomized data matrix and R console is stop 
working: 

cor (raw2[,i], raw2[,j], use="complete.obs")
cor.test (raw2[,i], raw2[,j],  method="spearman", na.action = "na.omit")
$estimate

Error in cor.test.default(raw2[, i], raw2[, j], method = "spearman", na.action 
= "na.omit") : 
        not enough finite observations
In addition: There were 50 or more warnings (use warnings() to see the first 
50)

What does the Error mean? How to fix it?
Any suggestion are highly appreciated?
Josh



From kjetil at entelnet.bo  Sat Sep 13 21:41:47 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Sat, 13 Sep 2003 15:41:47 -0400
Subject: [R] INDEX file as shown by library(help= ...)
Message-ID: <3F633ABB.16921.D60F8F@localhost>

Hola!

I thought that  one main purpose of the INDEX file as shown by
library(help = ...) was to give further pointers to use to search for 
help. But some pacakges have items in the index file with NONE help 
page, and further, non items in the index with help page. As an 
example I use 
> library(RColorBrewer)
> library(help=RColorBrewer)
# but this is not about RColorBrewer in particular, it is general
>From the help I naturally gives
> ?ColorBrewer
Error in help("ColorBrewer") : No documentation for `ColorBrewer' in 
specified packages and libraries:
  you could try `help.search("ColorBrewer")'
which is not very helpful. To find out which objects there are in the 
package, I do
> ls(pos=2)
[1] "brewer.pal"         "display.brewer.pal"

and there are indeed help for this items. Should there be a rule that 
there should be help pages for the items in INDEX, maybe inforced by
Rcmd check
?

Kjetil Halvorsen



From ripley at stats.ox.ac.uk  Sat Sep 13 21:42:01 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 13 Sep 2003 20:42:01 +0100 (BST)
Subject: [R] what does this error mean?
In-Reply-To: <1063478747.3f6365dba222a@webmail.uoguelph.ca>
Message-ID: <Pine.LNX.4.44.0309132029360.2495-100000@gannet.stats>

cor.test does not have an na.action argument unless used with the formula
interface, when it is better to use na.action=na.omit, not "na.omit".

The error message occurs if less than 2 rows are completely non-missing.
So take a closer look at your data.

BTW, I would compare the different methods of cor.test, not cor.test with 
cor, to check I really had this right.


On Sat, 13 Sep 2003 szhan at uoguelph.ca wrote:

> Dear R-users:
> I am runing R 1.6.2 with Windows XP. I try to calculate Pearson correlation 

That's long obselete, as you know.

> and Spearman correlation of any pairwise columns of 8000 x 80 data
> matrix with missing values and randomize the matix 1000 times and
> calculate this two correlations again. The code bellow for Pearson is
> working fine but for Spearman got the error bellow for randomized data
> matrix and R console is stop working:

And what does that last phrase mean?  (And `bellow' is not something you
should do on a public list.)

> cor (raw2[,i], raw2[,j], use="complete.obs")
> cor.test (raw2[,i], raw2[,j],  method="spearman", na.action = "na.omit")
> $estimate
> 
> Error in cor.test.default(raw2[, i], raw2[, j], method = "spearman", na.action 
> = "na.omit") : 
>         not enough finite observations
> In addition: There were 50 or more warnings (use warnings() to see the first 
> 50)
> 
> What does the Error mean? How to fix it?
> Any suggestion are highly appreciated?
> Josh


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tblackw at umich.edu  Sat Sep 13 21:52:06 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Sat, 13 Sep 2003 15:52:06 -0400 (EDT)
Subject: [R] what does this error mean?
In-Reply-To: <1063478747.3f6365dba222a@webmail.uoguelph.ca>
References: <1063478747.3f6365dba222a@webmail.uoguelph.ca>
Message-ID: <Pine.SOL.4.58.0309131545270.5318@timepilot.gpcc.itd.umich.edu>

Josh  -

See the example "run a simulation" in  help("try").

This won't be able to tell you the Spearman correlation
when there are fewer than two pairs of non-missing values,
but it will allow the loop to keep running.  Caution: the
return value from  try()  will be a string with the error
message, when  cor.test()  fails, so whatever variable
you accumulate the simulation results in must be able
to tolerate string values.  That suggests using a list.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Sat, 13 Sep 2003 szhan at uoguelph.ca wrote:

> Dear R-users:
> I am runing R 1.6.2 with Windows XP. I try to calculate Pearson correlation
> and Spearman correlation of any pairwise columns of 8000 x 80 data matrix with
> missing values and randomize the matix 1000 times and calculate this two
> correlations again. The code bellow for Pearson is working fine but for
> Spearman got the error bellow for randomized data matrix and R console is stop
> working:
>
> cor (raw2[,i], raw2[,j], use="complete.obs")
> cor.test (raw2[,i], raw2[,j],  method="spearman", na.action = "na.omit")
> $estimate
>
> Error in cor.test.default(raw2[, i], raw2[, j], method = "spearman",
> na.action = "na.omit") :
>         not enough finite observations
> In addition: There were 50 or more warnings (use warnings() to see
> the first  50)
>
> What does the Error mean? How to fix it?
> Any suggestion are highly appreciated?
> Josh



From schnitzlerj at gmx.de  Sun Sep 14 01:43:07 2003
From: schnitzlerj at gmx.de (Johannes Schnitzler)
Date: Sun, 14 Sep 2003 01:43:07 +0200 (MEST)
Subject: [R] (no subject)
Message-ID: <6281.1063496587@www61.gmx.net>

Dear all,

for an interactive web application i need to produce a lot of graphics (up
to 50) on demand.
In the moment i'm using the png format.

The png()
...using png(file="Rplot%03d.png", ...); 'plots' ; dev.off()... 
produces very good graphics. The problem is it takes too long to produce the
png files.
The bitmap()
...using bitmap(file="Rplot%03d.png", type="type = "png256",...); 'plots';
dev.off()...
works really fast. But on my system the quality is poor compared with png()
even with a higher resolution than 72.

I'm using R 1.7.0 on Windows NT ; Ghostscript 8.00

1) Is there a possibility to speed up the png() 
    or to improve the quality of the png produced by bitmap()

2) How is it possible to give "names" to the png files (if producing more
than one plot) instead of Name+serial number like Rplot%03d.png 

Any help would be appreciated

Johannes 

schnitzlerj at gmx.de



From tlumley at u.washington.edu  Sun Sep 14 04:24:57 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sat, 13 Sep 2003 19:24:57 -0700 (PDT)
Subject: [R] INDEX file as shown by library(help= ...)
In-Reply-To: <3F633ABB.16921.D60F8F@localhost>
Message-ID: <Pine.A41.4.44.0309131922200.136484-100000@homer35.u.washington.edu>

On Sat, 13 Sep 2003, kjetil brinchmann halvorsen wrote:

> and there are indeed help for this items. Should there be a rule that
> there should be help pages for the items in INDEX, maybe inforced by
> Rcmd check

The problem with enforcing it by Rcmd check is that INDEX need not be in
any easily parsed form.  A number of packages contain extra information
for the user in INDEX, which is a Good Thing, but makes it hard for
automated checking.

	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From TyagiAnupam at aol.com  Sun Sep 14 06:07:47 2003
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Sun, 14 Sep 2003 00:07:47 EDT
Subject: [R] Plot survey data
Message-ID: <bc.3d61c1d9.2c954393@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030914/59e531ed/attachment.pl

From hastie at stanford.edu  Sun Sep 14 06:42:56 2003
From: hastie at stanford.edu (Trevor Hastie)
Date: Sat, 13 Sep 2003 21:42:56 -0700
Subject: [R] Re: Logistic Regression
Message-ID: <003201c37a7a$ab393e00$d3bb42ab@yacht>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030913/3af1f126/attachment.pl

From ripley at stats.ox.ac.uk  Sun Sep 14 09:17:20 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 14 Sep 2003 08:17:20 +0100 (BST)
Subject: [R] Re: Logistic Regression
In-Reply-To: <003201c37a7a$ab393e00$d3bb42ab@yacht>
Message-ID: <Pine.LNX.4.44.0309140816050.10868-100000@gannet.stats>

On Sat, 13 Sep 2003, Trevor Hastie wrote:

> Christoph Lehman had problems with seperated data in two-class logistic
> regression.
> 
> One useful little trick is to penalize the logistic regression using a
> quadratic penalty on the coefficients. I am sure there are functions in
> the R contributed libraries to do this; 

Using nnet/multinom with weight decay does exactly this.

> otherwise it is easy to achieve via IRLS using ridge regressions. Then
> even though the data are separated, the penalized log-likelihood has a
> unique maximum. One intriguing feature is that as the penalty parameter
> goes to zero, the solution converges to the SVM solution - i.e. the
> optimal separating hyperplane see
> http://www-stat.stanford.edu/~hastie/Papers/margmax1.ps


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sun Sep 14 09:59:01 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 14 Sep 2003 08:59:01 +0100 (BST)
Subject: [R] Questions about png() on Windows
In-Reply-To: <6281.1063496587@www61.gmx.net>
Message-ID: <Pine.LNX.4.44.0309140850160.10967-100000@gannet.stats>

*PLEASE* always use a subject line!

On Sun, 14 Sep 2003, Johannes Schnitzler wrote:

> for an interactive web application i need to produce a lot of graphics (up
> to 50) on demand.
> In the moment i'm using the png format.
> 
> The png()
> ...using png(file="Rplot%03d.png", ...); 'plots' ; dev.off()... 
> produces very good graphics. The problem is it takes too long to produce the
> png files.
> The bitmap()
> ...using bitmap(file="Rplot%03d.png", type="type = "png256",...); 'plots';
> dev.off()...
> works really fast. But on my system the quality is poor compared with png()
> even with a higher resolution than 72.
> 
> I'm using R 1.7.0 on Windows NT ; Ghostscript 8.00
> 
> 1) Is there a possibility to speed up the png() 
>     or to improve the quality of the png produced by bitmap()

There is a possibility.  You have the source code, and we would be happy 
for you to optimize it and submit a faster version.  It looks up pixel 
values one at a time, and the use of block operations should speed it up.


> 2) How is it possible to give "names" to the png files (if producing more
> than one plot) instead of Name+serial number like Rplot%03d.png 

Just start a new device for each plot!

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From seniorr at aracnet.com  Sun Sep 14 11:03:12 2003
From: seniorr at aracnet.com (Russell Senior)
Date: Sun, 14 Sep 2003 09:03:12 -0000
Subject: [R] estimating quantiles from binned data
Message-ID: <86wucbpx2g.fsf@coulee.tdb.com>


Suppose I have a set of binned data, counts exceeding a series of
arbitrary thresholds, a total N, a minimum and maximum, those sorts of
things.  Is there a "standard" method for estimating arbitrary
quantiles from this?

My initial thought is that the counts and min/max give me solutions at
various points along the empirical cdf.  As the data are roughly
log-normal, I thought maybe I could use piece-wise log-normal
distributions between these points to estimate the arbitrary quantiles
I am interested in.

Are there "better thought out" methods than this?

Thanks!

-- 
Russell Senior         ``shtal latta wos ba padre u prett tu nashtonfi
seniorr at aracnet.com      mrlosh''  -- Bashgali Kafir for ``If you have
                         had diarrhoea many days you will surely die.''



From huan.huang at bnpparibas.com  Sun Sep 14 11:11:52 2003
From: huan.huang at bnpparibas.com (huan.huang@bnpparibas.com)
Date: Sun, 14 Sep 2003 10:11:52 +0100
Subject: [R] (no subject)
Message-ID: <OFD702E381.63FF0DEF-ON80256DA1.003286AC@bnpparibas.com>


I was using png() last week and also found it was very slow. But if you
try:

win.metafile('C:/temp/filename.png', width = 9, height = 10)
plot(rnorm(100))
dev.off()


It will speed up quite a lot. But one thing I don't understand is I always get truncated graph (I lost a bit at the right end of the plot). I make up
a very long title for the graph and then I get an entire graph. I guess I must miss something here.

Hope this helps.

Huan




Internet
schnitzlerj at gmx.de@stat.math.ethz.ch - 09/14/2003 12:43 AM


Sent by:    r-help-bounces at stat.math.ethz.ch

To:    r-help

cc:


Subject:    [R] (no subject)


Dear all,

for an interactive web application i need to produce a lot of graphics (up
to 50) on demand.
In the moment i'm using the png format.

The png()
...using png(file="Rplot%03d.png", ...); 'plots' ; dev.off()...
produces very good graphics. The problem is it takes too long to produce
the
png files.
The bitmap()
...using bitmap(file="Rplot%03d.png", type="type = "png256",...); 'plots';
dev.off()...
works really fast. But on my system the quality is poor compared with png()
even with a higher resolution than 72.

I'm using R 1.7.0 on Windows NT ; Ghostscript 8.00

1) Is there a possibility to speed up the png()
    or to improve the quality of the png produced by bitmap()

2) How is it possible to give "names" to the png files (if producing more
than one plot) instead of Name+serial number like Rplot%03d.png

Any help would be appreciated

Johannes

schnitzlerj at gmx.de

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help






This message and any attachments (the "message") is\ intende...{{dropped}}



From ripley at stats.ox.ac.uk  Sun Sep 14 11:34:54 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 14 Sep 2003 10:34:54 +0100 (BST)
Subject: [R] (no subject)
In-Reply-To: <OFD702E381.63FF0DEF-ON80256DA1.003286AC@bnpparibas.com>
Message-ID: <Pine.LNX.4.44.0309141019300.11233-100000@gannet.stats>

On Sun, 14 Sep 2003 huan.huang at bnpparibas.com wrote:

> I was using png() last week and also found it was very slow. But if you

If it is `very slow', there is a problem with your hardware.  On my very 
modest laptop

> system.time({png();plot(rnorm(100));dev.off()})
[1] 0.24 1.99 2.39   NA   NA
> system.time({bitmap("foo.png");plot(rnorm(100));dev.off()})
[1] 1.18 4.31 6.42   NA   NA

so I am puzzled by the original claim, too.

> try:
> 
> win.metafile('C:/temp/filename.png', width = 9, height = 10)
> plot(rnorm(100))
> dev.off()
> 
> 
> It will speed up quite a lot. But one thing I don't understand is I

It will not be a png plot, though, so what is the point of that?
You cannot open it in a real Web browser and I can only presume that you 
did not try to do so.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From spencer.graves at pdf.com  Sun Sep 14 12:33:48 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 14 Sep 2003 03:33:48 -0700
Subject: [R] estimating quantiles from binned data
References: <86wucbpx2g.fsf@coulee.tdb.com>
Message-ID: <3F64440C.2060904@pdf.com>

Have you considered making a normal probability plot?  This should help 
you evaluate the appropriatness of interpolating a log-normal.  The 
image of a mixture of lognormals would suggest limits on the accuracy of 
such interpolation.

hope this helps.
spencer graves

Russell Senior wrote:
> Suppose I have a set of binned data, counts exceeding a series of
> arbitrary thresholds, a total N, a minimum and maximum, those sorts of
> things.  Is there a "standard" method for estimating arbitrary
> quantiles from this?
> 
> My initial thought is that the counts and min/max give me solutions at
> various points along the empirical cdf.  As the data are roughly
> log-normal, I thought maybe I could use piece-wise log-normal
> distributions between these points to estimate the arbitrary quantiles
> I am interested in.
> 
> Are there "better thought out" methods than this?
> 
> Thanks!
>



From schnitzlerj at gmx.de  Sun Sep 14 13:22:43 2003
From: schnitzlerj at gmx.de (Johannes Schnitzler)
Date: Sun, 14 Sep 2003 13:22:43 +0200 (MEST)
Subject: [R] Questions about png() on Windows
References: <Pine.LNX.4.44.0309140850160.10967-100000@gannet.stats>
Message-ID: <16342.1063538563@www67.gmx.net>

Thank you for the reply,
it is not essential that the format is png. Every format that can be
displayed in a web browser would be fine.

> > for an interactive web application i need to produce a lot of graphics
> (up
> > to 50) on demand.
> > In the moment i'm using the png format.
> > 
> > The png()
> > ...using png(file="Rplot%03d.png", ...); 'plots' ; dev.off()... 
> > produces very good graphics. The problem is it takes too long to produce
> the
> > png files.
> > The bitmap()
> > ...using bitmap(file="Rplot%03d.png", type="type = "png256",...);
> 'plots';
> > dev.off()...
> > works really fast. But on my system the quality is poor compared with
> png()
> > even with a higher resolution than 72.
> > 
> > I'm using R 1.7.0 on Windows NT ; Ghostscript 8.00
> > 
> > 1) Is there a possibility to speed up the png() 
> >     or to improve the quality of the png produced by bitmap()
> 
> There is a possibility.  You have the source code, and we would be happy 
> for you to optimize it and submit a faster version.  It looks up pixel 
> values one at a time, and the use of block operations should speed it up.

I don't think i have the ability (in the moment) to do so - but i will have
a try....
Meanwhile: has somebody experience in improving the quality by setting
different parameters?

> > 2) How is it possible to give "names" to the png files (if producing
> more
> > than one plot) instead of Name+serial number like Rplot%03d.png 
> 
> Just start a new device for each plot!

To open a new device every time slows it down again.
On my sytem:
system.time({
for(i in
1:50){xy<-paste(i,".png",sep="");bitmap(xy);plot(rnorm(100));dev.off()}
})
[1]  4.40  5.62 42.70    NA    NA

system.time({
bitmap("%03d.png");for(i in 1:50){plot(rnorm(100))};dev.off()
})
[1] 0.62 0.16 1.49   NA   NA

Thank you in advance

Johannes



From jfox at mcmaster.ca  Sun Sep 14 14:31:20 2003
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 14 Sep 2003 08:31:20 -0400
Subject: [R] Plot survey data
In-Reply-To: <bc.3d61c1d9.2c954393@aol.com>
Message-ID: <5.1.0.14.2.20030914081151.01f9f008@127.0.0.1>

Dear Anupam,

At 12:07 AM 9/14/2003 -0400, TyagiAnupam at aol.com wrote:
>Hi John,
>thanks for the suggestion.  What would one consider as large range?

If the largest case weight corresponds to a probability of inclusion of 1, 
then the probability of inclusion for other cases is weight/max.weight, and 
the expected number of cases in the plot is n*average.weight/max.weight. 
You don't want this number to be too small. In your case, the ratio of the 
average to maximum weight is 0.013; assuming about 200,000 valid 
observations, you'd have about 2600 points in the plot, which seems 
reasonable (but see below).

> > summary(finalwt)
>    Min. 1st Qu.  Median    Mean          3rd Qu.             Max.
>     1.8   192.1   462.7      872.8          1018.0          67150.0
>The sample is large: about 250,000.
>How large a sample should one draw from the sample? There are also plenty of
>missing values.

Since you can't plot the missing values, the effective n is the number of 
valid cases. Making a scatterplot with a very large number of points is 
almost surely going to be uninformative (irrespective of the issue of 
weighting), and I'd consider an alternative, such as a bivariate 
nonparametric density estimate, possibly showing outlying points 
individually. (My second suggestion should produce a similar result.)

If you want to sample, I'd proceed by trial and error, adjusting both the 
sample size and point size. For example, you can decrease the sample size 
by scaling the weights down. A rule for how many points to include would be 
hard to come by, because a reasonable answer depends upon the configuration 
of the data, but I suspect that several tens of thousands of points would 
generally be too many.

Perhaps someone else will have better ideas.

Regards,
John


>In a message dated 9/12/03 10:48:06 PM Pacific Daylight Time,
>jfox at mcmaster.ca writes:
>
> > Dear Anupam,
> >
> > I may be wrong, but I don't think that there's any standard method to use
> > in plotting with case weights. I can think of two approaches, however: (1)
> > If you have a large sample, and if the range of the weights isn't too
> > large, you could sample your observations with probability of inclusion in
> > the plot proportional to the case weights. (2) You could plot the points
> > with "size" proportional to the square root of the case weights (i.e., 
> area
> > proportional to the weights).
> >
> > I hope that this helps,
> >  John
> >
>         [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From feh3k at spamcop.net  Sun Sep 14 09:35:29 2003
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Sun, 14 Sep 2003 09:35:29 +0200
Subject: [R] Re: Logistic Regression
In-Reply-To: <Pine.LNX.4.44.0309140816050.10868-100000@gannet.stats>
References: <003201c37a7a$ab393e00$d3bb42ab@yacht>
	<Pine.LNX.4.44.0309140816050.10868-100000@gannet.stats>
Message-ID: <20030914093529.001ab6b7.feh3k@spamcop.net>

On Sun, 14 Sep 2003 08:17:20 +0100 (BST)
Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> On Sat, 13 Sep 2003, Trevor Hastie wrote:
> 
> > Christoph Lehman had problems with seperated data in two-class logistic
> > regression.
> > 
> > One useful little trick is to penalize the logistic regression using a
> > quadratic penalty on the coefficients. I am sure there are functions in
> > the R contributed libraries to do this; 
> 
> Using nnet/multinom with weight decay does exactly this.

Also the lrm function in the Design package will do quadratic penalization.

Frank Harrell
> 
> > otherwise it is easy to achieve via IRLS using ridge regressions. Then
> > even though the data are separated, the penalized log-likelihood has a
> > unique maximum. One intriguing feature is that as the penalty parameter
> > goes to zero, the solution converges to the SVM solution - i.e. the
> > optimal separating hyperplane see
> > http://www-stat.stanford.edu/~hastie/Papers/margmax1.ps
> 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


---
Frank E Harrell Jr    Professor and Chair            School of Medicine
                      Department of Biostatistics    Vanderbilt University



From rajarshi at presidency.com  Sun Sep 14 19:13:49 2003
From: rajarshi at presidency.com (Rajarshi Guha)
Date: Sun, 14 Sep 2003 17:13:49 -0000
Subject: [R] title for plot contain 4 subplots
Message-ID: <1063559923.30438.16.camel@ra.chem.psu.edu>

Hi,
  I'm plotting 4 graphs on one page (2x2 matrix) but I cant seem to get
the title for the whole page right.

I'm doing:

op <- par(mfrow = c(2,2), pty="s")
hist(var$V2, breaks="FD",main="Euclidean Metric", xlab="Sum of 3NN ...
hist(var$V2, breaks="FD",main="Manhattan Metric", xlab="Sum of 3NN ...
hist(var$V2, breaks="FD",main="Euclidean Metric", xlab="Sum of 3NN ...
hist(var$V2, breaks="FD",main="Manhattan Metric", xlab="Sum of 3NN ...

At this point I would like to place a title at the head of the page
(like in the P-P plot example on the Chisquare help page. I'm doing:

mtext("Sum of 3NN Distances (per molecule) for Varying Distance
Metrics")

but it places this title as the title of the last plot and not the whole
page. The mtext help page says that I can use it to write text to the
outer margins of the device region but I cant seem to work out how I can
acheive this.

Thanks
-------------------------------------------------------------------
Rajarshi Guha <rajarshi at presidency.com> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
Q: What do you get when you put a spinning flywheel in a casket and
turn a corner?
A: A funeral precession.



From rajarshi at presidency.com  Sun Sep 14 20:18:56 2003
From: rajarshi at presidency.com (Rajarshi Guha)
Date: Sun, 14 Sep 2003 18:18:56 -0000
Subject: [R] title for plot contain 4 subplots
In-Reply-To: <1063559923.30438.16.camel@ra.chem.psu.edu>
References: <1063559923.30438.16.camel@ra.chem.psu.edu>
Message-ID: <1063563846.30438.25.camel@ra.chem.psu.edu>

On Sun, 2003-09-14 at 13:18, Rajarshi Guha wrote:
> Hi,
>   I'm plotting 4 graphs on one page (2x2 matrix) but I cant seem to get
> the title for the whole page right.
> 
> I'm doing:
> 
> op <- par(mfrow = c(2,2), pty="s")
> hist(var$V2, breaks="FD",main="Euclidean Metric", xlab="Sum of 3NN ...
> hist(var$V2, breaks="FD",main="Manhattan Metric", xlab="Sum of 3NN ...
> hist(var$V2, breaks="FD",main="Euclidean Metric", xlab="Sum of 3NN ...
> hist(var$V2, breaks="FD",main="Manhattan Metric", xlab="Sum of 3NN ...
> 
> At this point I would like to place a title at the head of the page
> (like in the P-P plot example on the Chisquare help page. I'm doing:

Thanks for the solution to the above problem. I am facing another
problem which seems to stem from the one above. After getting my plot on
screen I do 
dev.copy(png, file="out.png") 
dev.off()

The resultant PNG file shows the plots ok, but the ends of the overall
title get cut off. I tried changing the values in the oma vector tp par,
but it does'nt change anything.

Has anybody faced this?

Thanks,

-------------------------------------------------------------------
Rajarshi Guha <rajarshi at presidency.com> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
Science kind of takes the fun out of the portent business.
-Hobbes



From ripley at stats.ox.ac.uk  Sun Sep 14 20:50:00 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 14 Sep 2003 19:50:00 +0100 (BST)
Subject: [R] title for plot contain 4 subplots
In-Reply-To: <1063563846.30438.25.camel@ra.chem.psu.edu>
Message-ID: <Pine.LNX.4.44.0309141947090.12138-100000@gannet.stats>

On 14 Sep 2003, Rajarshi Guha wrote:

> On Sun, 2003-09-14 at 13:18, Rajarshi Guha wrote:
> > Hi,
> >   I'm plotting 4 graphs on one page (2x2 matrix) but I cant seem to get
> > the title for the whole page right.
> > 
> > I'm doing:
> > 
> > op <- par(mfrow = c(2,2), pty="s")
> > hist(var$V2, breaks="FD",main="Euclidean Metric", xlab="Sum of 3NN ...
> > hist(var$V2, breaks="FD",main="Manhattan Metric", xlab="Sum of 3NN ...
> > hist(var$V2, breaks="FD",main="Euclidean Metric", xlab="Sum of 3NN ...
> > hist(var$V2, breaks="FD",main="Manhattan Metric", xlab="Sum of 3NN ...
> > 
> > At this point I would like to place a title at the head of the page
> > (like in the P-P plot example on the Chisquare help page. I'm doing:
> 
> Thanks for the solution to the above problem. I am facing another
> problem which seems to stem from the one above. After getting my plot on
> screen I do 
> dev.copy(png, file="out.png") 
> dev.off()
> 
> The resultant PNG file shows the plots ok, but the ends of the overall
> title get cut off. I tried changing the values in the oma vector tp par,
> but it does'nt change anything.
> 
> Has anybody faced this?

Yes. It's even mentioned in several places, including on the dev.copy help
page (under some of the wrappers).  dev.copy assumes proportionate
pointsizes on the two devices, and that is unlikely to be true.  Either
replot on the png device or adjust pointsize on the target in your
dev.copy call.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From siewlengteng at yahoo.com  Sun Sep 14 20:57:18 2003
From: siewlengteng at yahoo.com (Siew Leng TENG)
Date: Sun, 14 Sep 2003 11:57:18 -0700 (PDT)
Subject: [R] reading in a file with multiple data types
Message-ID: <20030914185718.36541.qmail@web14916.mail.yahoo.com>

Hi,

I have a data file which contains multiple data types
(char and numeric) alongside with line spaces, tabs
and spaces. I hope to extract out the numeric blocks
of the data, probably as matrices or dataframes where
each line in the data block is a corresponding row in
the dataframe/ matrix.

I have tried using many R read functions but they do
not seem to yield the appropriate structure that
allows the extraction of the numeric blocks correctly
(due to the line spaces, tabs and spaces).

I gratefully appreciate any advice and suggestion on
how to obtain the desired data matrices/ dataframes
from this data file in R.

Thank you,
Siew-Leng
*Using R1.7.1. on windows ME, and on Unix.

------------------------------------
My data file contains data in the following block
structure :

1) block of a summary (char)
2) line spaces
3) text line
4) Data : stored as : 
number \t number (spc) number (spc) number (spc) ...
and so on.
[the number of numeric values stored at this line is
not fixed]
5) same structure from 2 - 4

An example of my data (in exact format) is given below
:


Final results
Final value 75.162993 
First case value 11
First case value 10
Case indices 
3 4 1 5 6 7 8 9 10 11 

Estimates : 
8.875350 
3.894280 
7.972684 
4.934348 
0.012406 
0.002134 
-0.024216 
0.072946 
-0.000468 
0.042769 
-0.126641 

Final components :
3 	 0 2 2 

4 	 0 1 

1 	 

5 	 0 0 0 1 2 

6 	 1 1 1 1 1 1 

7 	 1 1 1 1 1 

8 	 1 1 1 1 

9 	 0 0 0 0 1 1 2 

10 	 2 2 

11 	 0 2



From ripley at stats.ox.ac.uk  Sun Sep 14 21:11:40 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 14 Sep 2003 20:11:40 +0100 (BST)
Subject: [R] reading in a file with multiple data types
In-Reply-To: <20030914185718.36541.qmail@web14916.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0309142010260.12262-100000@gannet.stats>

You need to use connections to read block by block.

On Sun, 14 Sep 2003, Siew Leng TENG wrote:

> Hi,
> 
> I have a data file which contains multiple data types
> (char and numeric) alongside with line spaces, tabs
> and spaces. I hope to extract out the numeric blocks
> of the data, probably as matrices or dataframes where
> each line in the data block is a corresponding row in
> the dataframe/ matrix.
> 
> I have tried using many R read functions but they do
> not seem to yield the appropriate structure that
> allows the extraction of the numeric blocks correctly
> (due to the line spaces, tabs and spaces).
> 
> I gratefully appreciate any advice and suggestion on
> how to obtain the desired data matrices/ dataframes
> from this data file in R.
> 
> Thank you,
> Siew-Leng
> *Using R1.7.1. on windows ME, and on Unix.
> 
> ------------------------------------
> My data file contains data in the following block
> structure :
> 
> 1) block of a summary (char)
> 2) line spaces
> 3) text line
> 4) Data : stored as : 
> number \t number (spc) number (spc) number (spc) ...
> and so on.
> [the number of numeric values stored at this line is
> not fixed]
> 5) same structure from 2 - 4
> 
> An example of my data (in exact format) is given below
> :
> 
> 
> Final results
> Final value 75.162993 
> First case value 11
> First case value 10
> Case indices 
> 3 4 1 5 6 7 8 9 10 11 
> 
> Estimates : 
> 8.875350 
> 3.894280 
> 7.972684 
> 4.934348 
> 0.012406 
> 0.002134 
> -0.024216 
> 0.072946 
> -0.000468 
> 0.042769 
> -0.126641 
> 
> Final components :
> 3 	 0 2 2 
> 
> 4 	 0 1 
> 
> 1 	 
> 
> 5 	 0 0 0 1 2 
> 
> 6 	 1 1 1 1 1 1 
> 
> 7 	 1 1 1 1 1 
> 
> 8 	 1 1 1 1 
> 
> 9 	 0 0 0 0 1 1 2 
> 
> 10 	 2 2 
> 
> 11 	 0 2
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From roger at ysidro.econ.uiuc.edu  Sun Sep 14 22:00:22 2003
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Sun, 14 Sep 2003 15:00:22 -0500 (CDT)
Subject: [R] macosx install problem
Message-ID: <Pine.SOL.4.30.0309141455080.11749-100000@ysidro.econ.uiuc.edu>

I'm trying to install the current R-devel on a G4 powerbook.  I'm using

./configure --enable-R-shlib --with-blas='-framework vecLib' --with-lapack

with


rudjer: gcc -v
Reading specs from /usr/libexec/gcc/darwin/ppc/3.1/specs
Thread model: posix
Apple Computer, Inc. GCC version 1175, based on gcc version 3.1 20020420 (prerelease)
rudjer: g77 -v
Reading specs from /sw/lib/gcc-lib/powerpc-apple-darwin6.5/3.1/specs
Configured with: ../gcc3/configure --prefix=/sw --enable-languages=f77 --infodir=${prefix}/share/info
Thread model: single
Apple Computer, Inc. GCC version 1151, based on gcc version 3.1 20020420 (prerelease)

The configure, make and make install seem to go fine, but

rudjer: R
dyld: /usr/local/lib/R/bin/R.bin malformed library: /usr/local/lib/R/bin/Help (not a Mach-O file, bad magic number)
Trace/BPT trap
rudjer:

Any suggestions would be most welcome.

Roger


url:	www.econ.uiuc.edu/~roger/my.html	Roger Koenker
email	rkoenker at uiuc.edu			Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820



From seniorr at aracnet.com  Sun Sep 14 22:13:42 2003
From: seniorr at aracnet.com (Russell Senior)
Date: Sun, 14 Sep 2003 20:13:42 -0000
Subject: [R] estimating quantiles from binned data
In-Reply-To: <3F64440C.2060904@pdf.com>
References: <86wucbpx2g.fsf@coulee.tdb.com> <3F64440C.2060904@pdf.com>
Message-ID: <86brtnnn4u.fsf@coulee.tdb.com>

>>>>> "Spencer" == Spencer Graves <spencer.graves at pdf.com> writes:

Russell> Suppose I have a set of binned data, counts exceeding a
Russell> series of arbitrary thresholds, a total N, a minimum and
Russell> maximum, those sorts of things.  Is there a "standard" method
Russell> for estimating arbitrary quantiles from this?  My initial
Russell> thought is that the counts and min/max give me solutions at
Russell> various points along the empirical cdf.  As the data are
Russell> roughly log-normal, I thought maybe I could use piece-wise
Russell> log-normal distributions between these points to estimate the
Russell> arbitrary quantiles I am interested in.  Are there "better
Russell> thought out" methods than this?  Thanks!

Spencer> Have you considered making a normal probability plot?  

This is probably not practical, given I have on the order of 7000 sets
of binned data to evaluate.  I have prior knowledge of the data
involved (i.e. when we have an actual sample rather than just bin
counts), and though it isn't perfect, log normal usually isn't too bad
particularly in comparison to a standard normal distribution.  I also
want to match at the points where we "know" the quantiles precisely
(i.e. at bin boundaries).

Spencer> The image of a mixture of lognormals would suggest limits on
Spencer> the accuracy of such interpolation.

Oh, there are "limits", no doubt.  I guess the main point of my query
is to evaluate whether there are better, more theoretically sound
methods than the one I extracted from my hat.

-- 
Russell Senior         ``shtal latta wos ba padre u prett tu nashtonfi
seniorr at aracnet.com      mrlosh''  -- Bashgali Kafir for ``If you have
                         had diarrhoea many days you will surely die.''



From paul.delmar at wanadoo.fr  Sun Sep 14 22:17:08 2003
From: paul.delmar at wanadoo.fr (Paul Delmar)
Date: Sun, 14 Sep 2003 22:17:08 +0200
Subject: [R] Convert decimal to binary data
Message-ID: <000001c37afd$2c920ef0$0100a8c0@paul>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030914/fdc1b7ac/attachment.pl

From ripley at stats.ox.ac.uk  Sun Sep 14 22:39:57 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 14 Sep 2003 21:39:57 +0100 (BST)
Subject: [R] estimating quantiles from binned data
In-Reply-To: <86brtnnn4u.fsf@coulee.tdb.com>
Message-ID: <Pine.LNX.4.44.0309142137310.12337-100000@gannet.stats>

On 14 Sep 2003, Russell Senior wrote:

> >>>>> "Spencer" == Spencer Graves <spencer.graves at pdf.com> writes:
> 
> Russell> Suppose I have a set of binned data, counts exceeding a
> Russell> series of arbitrary thresholds, a total N, a minimum and
> Russell> maximum, those sorts of things.  Is there a "standard" method
> Russell> for estimating arbitrary quantiles from this?  My initial
> Russell> thought is that the counts and min/max give me solutions at
> Russell> various points along the empirical cdf.  As the data are
> Russell> roughly log-normal, I thought maybe I could use piece-wise
> Russell> log-normal distributions between these points to estimate the
> Russell> arbitrary quantiles I am interested in.  Are there "better
> Russell> thought out" methods than this?  Thanks!
> 
> Spencer> Have you considered making a normal probability plot?  
> 
> This is probably not practical, given I have on the order of 7000 sets
> of binned data to evaluate.  I have prior knowledge of the data
> involved (i.e. when we have an actual sample rather than just bin
> counts), and though it isn't perfect, log normal usually isn't too bad
> particularly in comparison to a standard normal distribution.  I also
> want to match at the points where we "know" the quantiles precisely
> (i.e. at bin boundaries).
> 
> Spencer> The image of a mixture of lognormals would suggest limits on
> Spencer> the accuracy of such interpolation.
> 
> Oh, there are "limits", no doubt.  I guess the main point of my query
> is to evaluate whether there are better, more theoretically sound
> methods than the one I extracted from my hat.

The normal procedure is to linearly interpolate the ecdf, and unless
the intervals are widely spaced, that seems as good as anything else.
An intermediate position is to use a cubic spline interplation, 
constrained to be monotonic (not sure you can do that in R via canned 
procedures).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From roger at ysidro.econ.uiuc.edu  Sun Sep 14 22:51:39 2003
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Sun, 14 Sep 2003 15:51:39 -0500 (CDT)
Subject: [R] macosx install problem
In-Reply-To: <Pine.SOL.4.30.0309141455080.11749-100000@ysidro.econ.uiuc.edu>
Message-ID: <Pine.SOL.4.30.0309141549220.11814-100000@ysidro.econ.uiuc.edu>

This was resolved by simply doing:

	cd /usr/local/lib
	rm -r R
	cd /usr/local/R/R-devel
	make install


url:	www.econ.uiuc.edu/~roger/my.html	Roger Koenker
email	rkoenker at uiuc.edu			Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820

On Sun, 14 Sep 2003, Roger Koenker wrote:

> I'm trying to install the current R-devel on a G4 powerbook.  I'm using
>
> ./configure --enable-R-shlib --with-blas='-framework vecLib' --with-lapack
>
> with
>
>
> rudjer: gcc -v
> Reading specs from /usr/libexec/gcc/darwin/ppc/3.1/specs
> Thread model: posix
> Apple Computer, Inc. GCC version 1175, based on gcc version 3.1 20020420 (prerelease)
> rudjer: g77 -v
> Reading specs from /sw/lib/gcc-lib/powerpc-apple-darwin6.5/3.1/specs
> Configured with: ../gcc3/configure --prefix=/sw --enable-languages=f77 --infodir=${prefix}/share/info
> Thread model: single
> Apple Computer, Inc. GCC version 1151, based on gcc version 3.1 20020420 (prerelease)
>
> The configure, make and make install seem to go fine, but
>
> rudjer: R
> dyld: /usr/local/lib/R/bin/R.bin malformed library: /usr/local/lib/R/bin/Help (not a Mach-O file, bad magic number)
> Trace/BPT trap
> rudjer:
>
> Any suggestions would be most welcome.
>
> Roger
>
>
> url:	www.econ.uiuc.edu/~roger/my.html	Roger Koenker
> email	rkoenker at uiuc.edu			Department of Economics
> vox: 	217-333-4558				University of Illinois
> fax:   	217-244-6678				Champaign, IL 61820
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From spencer.graves at pdf.com  Mon Sep 15 02:25:42 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 14 Sep 2003 17:25:42 -0700
Subject: [R] Integers in S-Plus and R
Message-ID: <3F650706.4070508@pdf.com>

	  I wish to comment on interesting and inconsistent behavior of both 
S-Plus and R with integers.

	  In R 1.7.1 for Windows, is.integer(2) is FALSE, though 
is.integer(1:2) and is.integer(max(1:2)) are both TRUE.  S-Plus 6.1 
produces TRUE for all three cases.

	  Meanwhile, as.integer(1e111) produces NA in R 1.7.1 and 2147483647 in 
S-Plus 6.1.  This behavior is consistent with the documentation in both 
cases:  R says, "The answer will be `NA' unless the coercion succeeds." 
  S-Plus says, "The numbers are truncated (moved to the closest integer 
...)."

	   Just one more thing to consider when trying to produce transportable 
scripts.

Spencer Graves



From spencer.graves at pdf.com  Mon Sep 15 02:27:38 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 14 Sep 2003 17:27:38 -0700
Subject: [R] Convert decimal to binary data
References: <000001c37afd$2c920ef0$0100a8c0@paul>
Message-ID: <3F65077A.6020000@pdf.com>

	  www.r-project.org -> search -> "R site search" for "conver to binary" 
reveals a function "ra2ba" in library bindata.  Have you considered this?

	  If your "decimal" is an integer, then the following might serve:

integer.base.b <-
function(x, b=2){
	xi <- as.integer(x)
	if(any(is.na(xi) | ((x-xi)!=0)))
		print(list(ERROR="x not integer", x=x))
	N <- length(x)
	xMax <- max(x)	
	ndigits <- (floor(logb(xMax, base=2))+1)
	Base.b <- array(NA, dim=c(N, ndigits))
	for(i in 1:ndigits){#i <- 1
		Base.b[, ndigits-i+1] <- (x %% b)
		x <- (x %/% b)
	}
	if(N ==1) Base.b[1, ] else Base.b
}

 > integer.base.b(x=1:9)
       [,1] [,2] [,3] [,4]
  [1,]    0    0    0    1
  [2,]    0    0    1    0
  [3,]    0    0    1    1
  [4,]    0    1    0    0
  [5,]    0    1    0    1
  [6,]    0    1    1    0
  [7,]    0    1    1    1
  [8,]    1    0    0    0
  [9,]    1    0    0    1
 > integer.base.b(123)
[1] 1 1 1 1 0 1 1

(in S-Plus 6.1 and R 1.7.1).
hope this helps.
spencer graves

Paul Delmar wrote:
> Hi,
>  
> I would like to convert a decimal into a binary number, for instance :
> 2->(1,0)
>  
> Any one knows how to do that ?
>  
> Thanks a lot 
>  
> paul
> 
> ---
> 
> 
> 
>  
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From zitan at mediasculpt.net  Tue Sep 16 01:03:48 2003
From: zitan at mediasculpt.net (Zitan Broth)
Date: Mon, 15 Sep 2003 16:03:48 -0700
Subject: [R] Command line R / PHP? - Thanks
References: <030601c36716$11fd24d0$3201a8c0@zitan>
Message-ID: <020601c37bdd$9f6c0030$bf3d00ca@zitan>

Greetings All,

I just wanted to say, somewhat belatedly, a huge thank you to all those who
answered my question.  I hope I have got all of you::

Thanks to Ruud, Jonathan, James, Martin, Andrew and Dennis.

Basically the solution and noted by these helpful people is to use infile
thereby creating an infile with php (using simple file io) calling R from
the command line with infile and writing the results to and output file
which can then be opened by PHP later.

The batch file call would be something like (from Ruud)::
     path_to_R\bin\Rterm.exe --no-restore --no-save < %1 > %1.out 2>&1

And away I go.

Again thank you all :-)

Z.


----- Original Message -----

> Greetings All,
>
> Just a quick query about calling R.  Looking through the manual you start
R
> with $ R, and then start calling R functions e.g plot whatever.  Sounds
> pretty funky, and R looks to be *the* open source maths package.  Awesome
> ...  I would like to call R from my favourite glue language PHP (rather
than
> call perl which calls R) if possible.  To call R from the command line is
> all this would require and this also seems quite possible ::
>
>     Batch use: At its simplest, Rterm.exe can be used in a batch mode by
> commands like
>         Rterm.exe --no-restore --no-save < infile > outfile
>
> And there is more information on this in section B.1 Invoking R under UNIX
> cool.
>
> However what I can't find is how to specify what function I want to run on
> my infile, say calculate standard deviation or means or linear regression
> and getting probabilities translations for t-statistics.  Have I missed
this
> in the docs?
>
> Any suggestions are greatly appreciated.   Awesome and a big thanks.
>
> Z.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>



From ripley at stats.ox.ac.uk  Mon Sep 15 09:25:39 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 15 Sep 2003 08:25:39 +0100 (BST)
Subject: [R] Integers in S-Plus and R
In-Reply-To: <3F650706.4070508@pdf.com>
Message-ID: <Pine.LNX.4.44.0309150820330.13009-100000@gannet.stats>

On Sun, 14 Sep 2003, Spencer Graves wrote:

> 	  I wish to comment on interesting and inconsistent behavior of both 
> S-Plus and R with integers.

I think both are consistent: they are just different from each other.

> 	  In R 1.7.1 for Windows, is.integer(2) is FALSE, though 
> is.integer(1:2) and is.integer(max(1:2)) are both TRUE.  S-Plus 6.1 
> produces TRUE for all three cases.

Yes, that's as documented.  Note that `2' was not integer in S-PLUS 1.x to 
4.x (including 2000), so this is rather an inconsistency in S-PLUS 
versions.

> 	  Meanwhile, as.integer(1e111) produces NA in R 1.7.1 and 2147483647 in 
> S-Plus 6.1.  This behavior is consistent with the documentation in both 
> cases:  R says, "The answer will be `NA' unless the coercion succeeds." 
>   S-Plus says, "The numbers are truncated (moved to the closest integer 
> ...)."
> 
> 	   Just one more thing to consider when trying to produce transportable 
> scripts.

Not that in porting code (both ways) I have ever found either to be a 
problem.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From opal7313 at yahoo.fr  Mon Sep 15 10:08:04 2003
From: opal7313 at yahoo.fr (=?iso-8859-1?q?N=20L?=)
Date: Mon, 15 Sep 2003 10:08:04 +0200 (CEST)
Subject: [R] Rgraphviz, rhdf5
Message-ID: <20030915080804.31938.qmail@web60205.mail.yahoo.com>

>I just installed bioconductor via getBioC.R but there
>is 3 problems: apparently some libraries are missing
>and I don't know which one, and even the XML package
>add a error message like : 
>1:Installation of package Rgraphviz had non-zero exit
>status in: installPkg(fileName, pkg, pkgVer, type,
>lib, repEntry, versForce)
>2:Installation of package rhdf5 had non-zero exit
>status in: installPkg(fileName, pkg, pkgVer, type,
>lib, repEntry, versForce)
>3:Installation of package XML had non-zero exit
>status
>in: installPkg(fileName, pkg, pkgVer, type, lib,
>repEntry, versForce)
>What can I do?

>Thanks in advance!

>Line
Hello,

As some people asked me I installed R-1.7.1 on a G4
Macosx 10.2.6 (Darwin).

Thanks again

Line



From s-plus at wiwi.uni-bielefeld.de  Mon Sep 15 11:23:48 2003
From: s-plus at wiwi.uni-bielefeld.de (Peter Wolf)
Date: Mon, 15 Sep 2003 11:23:48 +0200
Subject: [R] Convert decimal to binary data
References: <000001c37afd$2c920ef0$0100a8c0@paul>
Message-ID: <3F658524.6070102@wiwi.uni-bielefeld.de>

Paul Delmar wrote:

>Hi,
> 
>I would like to convert a decimal into a binary number, for instance :
>2->(1,0)
> 
>Any one knows how to do that ?
> 
>Thanks a lot 
> 
>paul
>  
>
see chcode or encode that are defined in:

http://www.wiwi.uni-bielefeld.de/~wolf/software/R-wtools/decodeencode/decodeencode.rev

peter



From ucgamdo at ucl.ac.uk  Mon Sep 15 11:51:41 2003
From: ucgamdo at ucl.ac.uk (ucgamdo@ucl.ac.uk)
Date: Mon, 15 Sep 2003 10:51:41 +0100
Subject: [R] Unable to plot dataframes
Message-ID: <3.0.5.32.20030915105141.007d9370@pop-server.ucl.ac.uk>

I moved recently from R in windows to R in linux, and have found out that I
cannot plot data frames. I think is an error related to the X server,
however, I haven't got the slighliest clue of what to do. To be more
specific this is a typical example of what happens to me:

> x <- data.frame(cbind(rnorm(50), rnorm(50), rnorm(50)))

> plot(x)

Error in text.default(x, y, cex = cex, font = font)
	X11 font of size 16 could not be loaded

# well, the actual details of the error might be slightly different
# a new graphics display appears on the screen and only one empty square is
drawn in the upper left corner
# of the graphics window.

Does anyone know what is the source of this problem or how to fix it?

Thanks,
M.



From MSchwartz at medanalytics.com  Mon Sep 15 14:39:06 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Mon, 15 Sep 2003 07:39:06 -0500
Subject: [R] Unable to plot dataframes
In-Reply-To: <3.0.5.32.20030915105141.007d9370@pop-server.ucl.ac.uk>
References: <3.0.5.32.20030915105141.007d9370@pop-server.ucl.ac.uk>
Message-ID: <1063629546.8571.13.camel@localhost>

On Mon, 2003-09-15 at 04:51, ucgamdo at ucl.ac.uk wrote:
> I moved recently from R in windows to R in linux, and have found out that I
> cannot plot data frames. I think is an error related to the X server,
> however, I haven't got the slighliest clue of what to do. To be more
> specific this is a typical example of what happens to me:
> 
> > x <- data.frame(cbind(rnorm(50), rnorm(50), rnorm(50)))
> 
> > plot(x)
> 
> Error in text.default(x, y, cex = cex, font = font)
> 	X11 font of size 16 could not be loaded
> 
> # well, the actual details of the error might be slightly different
> # a new graphics display appears on the screen and only one empty square is
> drawn in the upper left corner
> # of the graphics window.
> 
> Does anyone know what is the source of this problem or how to fix it?
> 
> Thanks,
> M.


See this post from earlier this year:

https://stat.ethz.ch/pipermail/r-help/2003-March/030101.html

HTH,

Marc Schwartz



From marcelino-cruz at bio.etsia.upm.es  Mon Sep 15 14:49:53 2003
From: marcelino-cruz at bio.etsia.upm.es (Marcelino de la Cruz)
Date: Mon, 15 Sep 2003 14:49:53 +0200
Subject: [R] partial mantel
Message-ID: <5.1.1.6.1.20030915142642.00a60ce0@galileo.ccupm.upm.es>

----- Original Message -----
From: Bouget Christophe
Sent: 9/12/2003 7:19:14 AM
To: r-help at stat.math.ethz.ch
Subject: [R] partial mantel
 > Dear all,
 > Has anyone written R code for partial Mantel Tests- as described for
 > instance in Legtendre & Legendre (1998) ?
 > In other words, in a community ecology analysis, I would like to calculate
 > the correlation between two dissimilarity matrices, controlling for a third
 > distance matrix representing geographical distances between sites.
 > Thanks!
 >
 > Christophe Bouget
 > Biodiversit? et gestion des for?ts de plaine - Ecosylv
 > Ecosyst?mes forestiers et paysages
 > Institut de recherches pour l'ing?nierie de l'agriculture et de
 > l'environnement - CEMAGREF
 > Domaine des Barres
 > F-45 290 Nogent-sur-Vernisson
 >

Some time ago I wrote the following naive function to implement the method 
2 of Legendre in  J. Statist. Comput. Simul. , 2000, Vol. 67, pp. 37 ? 73 
(permutation of residuals of null model).
Acording to Legendre, it can always be used, except when highly skewed data 
are combined with small  sample size (n < 20, or n < 50 in the presence of 
outliers). I have also R code for methods 1 and 3 available.
I hope it can help.

***********************************************************************************************
PARTIAL MANTEL TEST
METHOD 2
************************************************************************************************************
#a,b,c are distance matrix (from dist())
#nsim are required simulations
************************************************************************************************************
partial.mantel2<-function(a,b,c,nsim=100){
library(mva)
library(cluster)
m<- matrix(0,(dim(as.matrix(a))[1]),dim(as.matrix(a))[1])
m[lower.tri(m)] <- residuals(lm(as.vector(a)~as.vector(c)))
resA.C<-as.dist (m)
a.sd<-((a-mean(a))/sqrt(var(a)))  #estandarizaci?n de las matrices de 
distancias
b.sd<-((b-mean(b))/sqrt(var(b)))
c.sd<-((c-mean(c))/sqrt(var(c)))
n<- length(a)-1
rmAB<-drop(crossprod(a.sd,b.sd)/n)
rmAC<-drop(crossprod(a.sd,c.sd)/n)
rmBC<-drop(crossprod(b.sd,c.sd)/n)
rmAB.C<-(rmAB-(rmAC*rmBC))/(sqrt(1-rmAC^2)*sqrt(1-rmBC^2))
distribucion<-rep(-999,nsim)
resA.C.m<-as.matrix(resA.C)
resA.C.m.sim<-as.matrix(resA.C)

for (h in 1:nsim){
     x<-sample(1:dim(as.matrix(a.sd))[1]) # permutaci?n de la matriz a 
?nsim? veces
     for (i in 1:length(x)){
        for (j in 1:length (x)){
         resA.C.m.sim[i,j]<-resA.C.m[x[i],x[j]]
         }
     }
    rmRB<-drop(crossprod(as.dist(resA.C.m.sim),b.sd)/n)
    rmRC<- drop(crossprod(as.dist(resA.C.m.sim),c.sd)/n)
    distribucion[h]<-(rmRB-(rmRC*rmBC))/(sqrt(1-rmRC^2)*sqrt(1-rmBC^2))
}
distribucion<-c(rmAB.C,distribucion)

if(rmAB.C>0) 
p<-length(which(sort(distribucion)>=rmAB.C))/length(distribucion) else p<- 
length(which(sort(distribucion)<=rmAB.C))/length(distribucion)


print(c(?rMab.c:?,rmAB.C))
if(rmAB.C>0) print(c("prop rM < r*M:",p)) else print(c("prop rM > r*M:", p))
}


*****************************************************************************************************************************








***************************************
Marcelino de la Cruz Rot
Depto. Biolog?a Vegetal
ETS Ingenieros Agr?nomos
Universidad Polit?cnica de Madrid
28040-Madrid

Tel: 91.336.56.63.



From solares at unsl.edu.ar  Mon Sep 15 15:08:01 2003
From: solares at unsl.edu.ar (solares@unsl.edu.ar)
Date: Mon, 15 Sep 2003 10:08:01 -0300 (ART)
Subject: [R] locator in  multiple graphics
Message-ID: <36309.170.210.173.216.1063631281.squirrel@inter14.unsl.edu.ar>

hello, how i cant with function locator() know the coordinates of two 
function graphicated in the same graphical area, the return coordinates 
which are they , of one function or the another function:

|    f
|   /(click here)  locator(1), return (x,y) of f or g function?
|  /
| / 
|/~~~~~g
|________________



From ligges at statistik.uni-dortmund.de  Mon Sep 15 15:27:45 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 15 Sep 2003 15:27:45 +0200
Subject: [R] locator in  multiple graphics
In-Reply-To: <36309.170.210.173.216.1063631281.squirrel@inter14.unsl.edu.ar>
References: <36309.170.210.173.216.1063631281.squirrel@inter14.unsl.edu.ar>
Message-ID: <3F65BE51.7020606@statistik.uni-dortmund.de>

solares at unsl.edu.ar wrote:

> hello, how i cant with function locator() know the coordinates of two 
> function graphicated in the same graphical area, the return coordinates 
> which are they , of one function or the another function:
> 
> |    f
> |   /(click here)  locator(1), return (x,y) of f or g function?
> |  /
> | / 
> |/~~~~~g
> |________________
> 

Might be neither!
It returns a value specified in user coordinates of the plotting region 
at the time locator() was called. ?locator could be a bit more specific 
here ...


Try

  plot(1:10)
  locator()
  par("usr" = c(101,110,101,100))
  locator()

as an example


Uwe Ligges



From wimajo at yahoo.com  Mon Sep 15 15:39:12 2003
From: wimajo at yahoo.com (Joanne Dawson)
Date: Mon, 15 Sep 2003 06:39:12 -0700 (PDT)
Subject: [R] Deploying R Routines
Message-ID: <20030915133912.81863.qmail@web41805.mail.yahoo.com>

For those of you developing routines in R and S-Plus
(or know others in your organization who do) who are
looking for a fast and efficient way to share these
algorithms across your organization without building
and maintaining complete stand-alone, software
applications, the new Spotfire Advantage Solution for
R is worth a look. To find out more about this new
capability, and to apply for the "R to Application
Challenge" go to www.spotfire.com/rinfo and see for
yourself.



From tlumley at u.washington.edu  Mon Sep 15 15:51:46 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 15 Sep 2003 06:51:46 -0700 (PDT)
Subject: [R] Rgraphviz, rhdf5
In-Reply-To: <20030915080804.31938.qmail@web60205.mail.yahoo.com>
Message-ID: <Pine.A41.4.44.0309150643180.88530-100000@homer12.u.washington.edu>

On Mon, 15 Sep 2003, [iso-8859-1] N L wrote:

> >I just installed bioconductor via getBioC.R but there
> >is 3 problems: apparently some libraries are missing
> >and I don't know which one, and even the XML package
> >add a error message like :
> >1:Installation of package Rgraphviz had non-zero exit
> >status in: installPkg(fileName, pkg, pkgVer, type,
> >lib, repEntry, versForce)
> >2:Installation of package rhdf5 had non-zero exit
> >status in: installPkg(fileName, pkg, pkgVer, type,
> >lib, repEntry, versForce)
> >3:Installation of package XML had non-zero exit
> >status
> >in: installPkg(fileName, pkg, pkgVer, type, lib,
> >repEntry, versForce)
> >What can I do?
>
> >Thanks in advance!
>
> >Line
> Hello,
>
> As some people asked me I installed R-1.7.1 on a G4
> Macosx 10.2.6 (Darwin).
>

That is a very important piece of information.

The problem is that you are missing various necessary add-ons.
For Rgraphviz you need GraphViz (http://www.graphviz.org).
For Ruuid I think you need glib (http://www.gnu.org/directory/glib.html)

	-thomas



From emma042 at yahoo.com  Mon Sep 15 15:55:43 2003
From: emma042 at yahoo.com (=?iso-8859-1?q?Emma=20Tan?=)
Date: Mon, 15 Sep 2003 14:55:43 +0100 (BST)
Subject: [R] Gibbs sampling
Message-ID: <20030915135543.96338.qmail@web14206.mail.yahoo.com>

Hi,

I am trying to use the glmm() function in the
GLMMGibbs package to fit a crossed random effects
model.  I want to include two random effects and I'm
not sure how to go about doing this.  Do I include two
Ra() functions for the two random effects I wish to
include?  I did try this, adding both random
components to the glmm() function but only seemed to
get an estimate of one random error component and not
both.

Thanks for any help you can give!

Emma



From rossini at blindglobe.net  Mon Sep 15 17:11:04 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Mon, 15 Sep 2003 08:11:04 -0700
Subject: [R] Rgraphviz, rhdf5
In-Reply-To: <Pine.A41.4.44.0309150643180.88530-100000@homer12.u.washington.edu>
	(Thomas
	Lumley's message of "Mon, 15 Sep 2003 06:51:46 -0700 (PDT)")
References: <Pine.A41.4.44.0309150643180.88530-100000@homer12.u.washington.edu>
Message-ID: <85he3e3x4n.fsf@blindglobe.net>

Thomas Lumley <tlumley at u.washington.edu> writes:

> For Ruuid I think you need glib (http://www.gnu.org/directory/glib.html)

No, you can get away with one of the other libuuid packages; link
escapes me now, but Google might help.

best,
-tony

-- 
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From mmarques at power.inescn.pt  Mon Sep 15 18:01:47 2003
From: mmarques at power.inescn.pt (Mark Marques)
Date: Mon, 15 Sep 2003 17:01:47 +0100
Subject: [R] Persp and color
Message-ID: <17125721656.20030915170147@power.inescn.pt>



How can I control de "wrap-around" color behaviour in the persp
function ?
I am using something like :
persp(bb[1:100,2:97], col= rainbow(8,start=0.1, end=0.8)))

Depending on the rainbow length value I get several "wrap-around" blocks of
the selected color range...something that I wanted to avoid...
My idea is to use the color in order to make a separation from a
certain "height" .
Where can I find how are the colors ordered ? or can I control the
color order ?

THanks in advance
Marco Marques



 From 
 Mark
 mailto:mmarques at power.inescn.pt



From tring at gvdnet.dk  Mon Sep 15 19:26:26 2003
From: tring at gvdnet.dk (Troels Ring)
Date: Mon, 15 Sep 2003 19:26:26 +0200
Subject: [R] POSIX and identify
Message-ID: <5.2.0.9.0.20030915191816.03259020@mail.gvdnet.dk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030915/42f446b6/attachment.pl

From rajarshi at presidency.com  Mon Sep 15 19:24:49 2003
From: rajarshi at presidency.com (Rajarshi Guha)
Date: Mon, 15 Sep 2003 17:24:49 -0000
Subject: [R] question regarding ks.test()
Message-ID: <1063646976.1067.4.camel@ra.chem.psu.edu>

Hi,
  I'm using the ks.test() on two vectors. I looked up the reference and
also coded up a version of the two sample Smirnov test. My question is
that how can I decide from the output of R that the two vectors x & y
come from the same distribution?

Am I correct in assuming that smaller D values indicate that they come
from the same distribution? In addition how can I use the p value that
is supplied in the output?

In my code I decided (as described by Conover) by calculating the
1-alpha quantile and if D was greater than this value, the H_0 is
rejected. However I dont calculate a P value.  Is this method
significantly different from the method used in R? 

Since I get the same value of D in both methods is there any reason to
prefer one over the other?

Thanks,

-------------------------------------------------------------------
Rajarshi Guha <rajarshi at presidency.com> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
After a number of decimal places, nobody gives a damn.



From ripley at stats.ox.ac.uk  Mon Sep 15 19:43:40 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 15 Sep 2003 18:43:40 +0100 (BST)
Subject: [R] POSIX and identify
In-Reply-To: <5.2.0.9.0.20030915191816.03259020@mail.gvdnet.dk>
Message-ID: <Pine.LNX.4.44.0309151840410.18347-100000@gannet.stats>

You need to convert to POSIXct before using Dato in identify().
This will work as you expected in R 1.8.0.

On Mon, 15 Sep 2003, Troels Ring wrote:

> Dear Friends, I'm using winXP and R 1.7.1 and plotting some data using 
> dates on the x-axis, and wanted to use identify to show some points but was 
> told by identify that the x and y vectors producing a fine graph with 84 
> points were not equal in length. Below are the Dato for date - and 
> length(Dato) finds 9 but str finds 84 as known. Will identify not work in 
> this context ?
> Best wishes
> Troels Ring
> Aalborg, Denmark
>  > Dato
>   [1] "2000-01-04" "2000-01-07" "2000-01-10" "2000-01-13" "2000-01-17"
>   .......
> [81] "2003-04-23" "2003-05-14" "2003-07-30" "2003-08-14"
>  > length(Dato)
> [1] 9
>  > str(Dato)
> `POSIXlt', format: chr [1:84] "2000-01-04" "2000-01-07" "2000-01-10" 
> "2000-01-13" ...

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From andy_liaw at merck.com  Mon Sep 15 19:51:16 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 15 Sep 2003 13:51:16 -0400
Subject: [R] S+DOX eqivalent in R?
Message-ID: <3A822319EB35174CA3714066D590DCD50205CB1A@usrymx25.merck.com>

Lenth's PSE is "quick and easy".  Why not just roll your own?

Andy

> -----Original Message-----
> From: Nitin Jain [mailto:nj7w at virginia.edu] 
> Sent: Thursday, September 11, 2003 4:22 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] S+DOX eqivalent in R?
> 
> 
> Dear List,
> 
> I am looking for a function `Pseudo standard error' (PSE), 
> which is available in S+ DOX (design of experiemnt) module - 
> Is there a similar function available in R?
> 
> Reference for PSE function is in the paper:
> 'Quick and easy analysis of unreplicated factorials' by 
> Russell V. Lenth, Technometrics, 1989, 31, 4, 469-473.
> 
> Thanks.
> -Nitin
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> 

------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From tring at gvdnet.dk  Mon Sep 15 20:09:09 2003
From: tring at gvdnet.dk (Troels Ring)
Date: Mon, 15 Sep 2003 20:09:09 +0200
Subject: [R] POSIX and identify
In-Reply-To: <Pine.LNX.4.44.0309151840410.18347-100000@gannet.stats>
References: <5.2.0.9.0.20030915191816.03259020@mail.gvdnet.dk>
Message-ID: <5.2.0.9.0.20030915200206.03263d10@mail.gvdnet.dk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030915/86ee772c/attachment.pl

From ligges at statistik.uni-dortmund.de  Mon Sep 15 21:44:39 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 15 Sep 2003 21:44:39 +0200
Subject: [R] question regarding ks.test()
References: <1063646976.1067.4.camel@ra.chem.psu.edu>
Message-ID: <3F6616A7.95CA96D8@statistik.uni-dortmund.de>

Rajarshi Guha wrote:
> 
> Hi,
>   I'm using the ks.test() on two vectors. I looked up the reference and
> also coded up a version of the two sample Smirnov test. My question is
> that how can I decide from the output of R that the two vectors x & y
> come from the same distribution?

Strictly speaking, you cannot. You are testing H0: "same distribution"
against H1: "different distribution" in case "two.sided",
so you can only "decide" the alternative is true with probability
1-alpha, if p < alpha.


> Am I correct in assuming that smaller D values indicate that they come
> from the same distribution? 

Right. For D=0 the ecdfs are equal to each other under the two.sided
hypothesis.


> In addition how can I use the p value that is supplied in the output?

As all other p values? You can reject if p < alpha. Before going further
on, you should consider to read a book about statistical hypothesis
testing, see the help page for notes on the accuracy of the p-value.


> In my code I decided (as described by Conover) by calculating the
> 1-alpha quantile and if D was greater than this value, the H_0 is
> rejected. However I dont calculate a P value.  Is this method
> significantly different from the method used in R?

The 1-alpha/2 quantile for the two sided test, I think. 
That's equivalent to a decision by p-values.

 
> Since I get the same value of D in both methods is there any reason to
> prefer one over the other?

No.

Uwe Ligges
 

> Thanks,
> 
> -------------------------------------------------------------------
> Rajarshi Guha <rajarshi at presidency.com> <http://jijo.cjb.net>
> GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
> -------------------------------------------------------------------
> After a number of decimal places, nobody gives a damn.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From willemse at astro.uni-bonn.de  Mon Sep 15 22:10:35 2003
From: willemse at astro.uni-bonn.de (Philip Willemsen)
Date: Mon, 15 Sep 2003 22:10:35 +0200 (CEST)
Subject: [R] Multiple Gaussians
Message-ID: <Pine.LNX.4.55.0309152205470.18512@aibn35.astro.uni-bonn.de>

Dear R users,

I would like to know wether there exists a package or routine within the R
environment which allows to test for multiple Gaussians in a given
distribution: I have a histogram of some variable which seems to be tri -
or at least bimodal, so I would like to test if this is significant to
some level and/or estimate the underlying possible distributions.

Thank you very much,

Yours sincerely
Philip



From sundar.dorai-raj at pdf.com  Mon Sep 15 22:20:11 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Mon, 15 Sep 2003 15:20:11 -0500
Subject: [R] Multiple Gaussians
In-Reply-To: <Pine.LNX.4.55.0309152205470.18512@aibn35.astro.uni-bonn.de>
References: <Pine.LNX.4.55.0309152205470.18512@aibn35.astro.uni-bonn.de>
Message-ID: <3F661EFB.2050002@pdf.com>

You might take a look at mclust downloadable from CRAN.

Philip Willemsen wrote:

> Dear R users,
> 
> I would like to know wether there exists a package or routine within the R
> environment which allows to test for multiple Gaussians in a given
> distribution: I have a histogram of some variable which seems to be tri -
> or at least bimodal, so I would like to test if this is significant to
> some level and/or estimate the underlying possible distributions.
> 
> Thank you very much,
> 
> Yours sincerely
> Philip
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From kasia at darwin.epbi.cwru.edu  Mon Sep 15 22:54:19 2003
From: kasia at darwin.epbi.cwru.edu (Catherine Stein)
Date: Mon, 15 Sep 2003 16:54:19 -0400 (EDT)
Subject: [R] path analysis
Message-ID: <Pine.OSF.4.30.0309151652510.161054-100000@darwin.epbi.cwru.edu>


Can anyone help me find a R script that does path analysis with family
data (like a Beta model)?  A script that takes the variance-covariance
matrix in as input would be ideal.

Thanks!  Please email me with any ideas!
Cathy Stein
cmstein at cwru.edu



From Weiming.Zhang at uchsc.edu  Mon Sep 15 22:55:48 2003
From: Weiming.Zhang at uchsc.edu (Weiming Zhang)
Date: Mon, 15 Sep 2003 20:55:48 -0000
Subject: [R] how to print a plot
Message-ID: <1063659392.21254.9.camel@molecule.uchsc.edu>

Hi,

I am using R-1.7.1 on Linux. I integrated XEMACS with R. Could anybody
tell me how to print a plot? I used plot function to make some graphs
and then I wanted to print them or to save them to files. But I could
not find out how to do it.

Thank you very much.

Weiming Zhang



From yao6889 at msmailhub.oulan.ou.edu  Mon Sep 15 23:12:41 2003
From: yao6889 at msmailhub.oulan.ou.edu (Yao, Minghua)
Date: Mon, 15 Sep 2003 16:12:41 -0500
Subject: [R] How to Write Message into a File?
Message-ID: <FC0CEBD77311DA499A67ADB355A24FA20396ADB9@mail4.oulan.ou.edu>


Could any body please tell me how to write the message generated by, say,
t.test() into a file?

Thanks in advance.

Minghua



From spencer.graves at pdf.com  Mon Sep 15 23:24:56 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 15 Sep 2003 14:24:56 -0700
Subject: [R] How to Write Message into a File?
References: <FC0CEBD77311DA499A67ADB355A24FA20396ADB9@mail4.oulan.ou.edu>
Message-ID: <3F662E28.5060701@pdf.com>

Have you considered "?sink"?

hope this helps.  spencer graves

Yao, Minghua wrote:
> Could any body please tell me how to write the message generated by, say,
> t.test() into a file?
> 
> Thanks in advance.
> 
> Minghua
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jasont at indigoindustrial.co.nz  Mon Sep 15 23:58:02 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Mon, 15 Sep 2003 21:58:02 -0000
Subject: [R] how to print a plot
In-Reply-To: <1063659392.21254.9.camel@molecule.uchsc.edu>
References: <1063659392.21254.9.camel@molecule.uchsc.edu>
Message-ID: <1063663568.8437.5.camel@kryten.indigoindustrial.co.nz>

On Tue, 2003-09-16 at 08:56, Weiming Zhang wrote:
> Hi,
> 
> I am using R-1.7.1 on Linux. I integrated XEMACS with R. Could anybody
> tell me how to print a plot? I used plot function to make some graphs
> and then I wanted to print them or to save them to files. But I could
> not find out how to do it.

Have you tried:
help(Devices) 
help(pdf)

What I do:

pdf(file="myplots.pdf")
plot(...)
dev.off()

Use Acrobat or gv to view the pdf files.  Postscript is also good, but
not as universally understood; I have many coleagues who work in very
standard Windows environments, where ghostscript is unknown.  PDF is a
very sensible choice for e-mailing graphs.


-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
+64-(0)21-343-545



From brahm at alum.mit.edu  Tue Sep 16 00:28:57 2003
From: brahm at alum.mit.edu (David Brahm)
Date: Mon, 15 Sep 2003 18:28:57 -0400
Subject: [R] Re: [Rd] R 1.8.0 alpha
References: <x2pti8wr83.fsf@biostat.ku.dk>
Message-ID: <16230.15657.839828.262501@arbres1a.fmr.com>

Our Sun Ultra-80 running Solaris 2.8 (platform = sparc-sun-solaris2.8) failed
to "make" R-1.8.0alpha_2003-09-15.tar.gz.  The tail end of the output follows.
Note that we have gcc version 2.95.3, as a recent attempt to upgrade failed
miserably.  Any ideas?
                              -- David Brahm (brahm at alum.mit.edu)


/res/local/bin/gcc -I../../src/extra/zlib  -I../../src/extra/pcre -I. -I../../src/include -I../../src/include -IRB/local/include -DHAVE_CONFIG_H   -g -O2 -c registration.c -o registration.o
g77   -g -O2 -c xxxpr.f -o xxxpr.o
/res/local/bin/gcc  -LRB/local/lib -o R.bin  CConverters.o Rdynload.o RNG.o apply.o arithmetic.o apse.o array.o attrib.o base.o bind.o builtin.o character.o coerce.o colors.o complex.o connections.o context.o cov.o cum.o dcf.o datetime.o debug.o devPS.o devPicTeX.o deparse.o deriv.o devices.o dotcode.o dounzip.o dstruct.o duplicate.o engine.o envir.o errors.o eval.o format.o fourier.o gram.o gram-ex.o graphics.o identical.o internet.o iosupport.o lapack.o list.o logic.o main.o mapply.o match.o memory.o model.o names.o objects.o optim.o optimize.o options.o par.o paste.o pcre.o platform.o plot.o plot3d.o plotmath.o print.o printarray.o printvector.o printutils.o qsort.o random.o regex.o relop.o saveload.o scan.o seq.o serialize.o size.o sort.o source.o split.o sprintf.o subassign.o subscript.o subset.o summary.o unique.o util.o version.o vfonts.o registration.o xxxpr.o ../unix/libunix.a ../appl/libappl.a ../nmath/libnmath.a   -L/usr/ccs/lib -L/usr/lib -LRB/local/lib -L/res/local.0903/lib/gcc-lib/sparc-sun-solaris2.8/2.95.3 -L/usr/ccs/bin -L/res/local.0903/lib -lg2c -lm  ../extra/zlib/libz.a  ../extra/pcre/libpcre.a -lbz2 -lnsl -lsocket -lreadline -ldl -ltermcap -lm
Undefined                       first referenced
 symbol                             in file
BZ2_bzWriteClose                    connections.o
BZ2_bzReadOpen                      connections.o
BZ2_bzReadClose                     connections.o
BZ2_bzWriteOpen                     connections.o
BZ2_bzWrite                         connections.o
BZ2_bzRead                          connections.o
ld: fatal: Symbol referencing errors. No output written to R.bin
collect2: ld returned 1 exit status
make[3]: *** [R.bin] Error 1
make[3]: Leaving directory `/res/R/R-1.8.0/src/main'
make[2]: *** [R] Error 2
make[2]: Leaving directory `/res/R/R-1.8.0/src/main'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/res/R/R-1.8.0/src'
make: *** [R] Error 1
mica|R-1.8.0>



From Weiming.Zhang at uchsc.edu  Tue Sep 16 01:16:49 2003
From: Weiming.Zhang at uchsc.edu (Weiming Zhang)
Date: Mon, 15 Sep 2003 23:16:49 -0000
Subject: [R] how to print a plot
In-Reply-To: <1063663568.8437.5.camel@kryten.indigoindustrial.co.nz>
References: <1063659392.21254.9.camel@molecule.uchsc.edu> 
	<1063663568.8437.5.camel@kryten.indigoindustrial.co.nz>
Message-ID: <1063667847.21254.72.camel@molecule.uchsc.edu>

Hi, Thank both of you.

I tried everything. pdf(file="out.pdf") gave me a damaged pdf file. ps()
did not print. ps("out.ps") gave me a ps file with badly drawn graph and
could not be printed. I am using RH linux 7.2.

Thanks again.

weiming Zhang


On Mon, 2003-09-15 at 16:06, Jason Turner wrote:
> On Tue, 2003-09-16 at 08:56, Weiming Zhang wrote:
> > Hi,
> > 
> > I am using R-1.7.1 on Linux. I integrated XEMACS with R. Could anybody
> > tell me how to print a plot? I used plot function to make some graphs
> > and then I wanted to print them or to save them to files. But I could
> > not find out how to do it.
> 
> Have you tried:
> help(Devices) 
> help(pdf)
> 
> What I do:
> 
> pdf(file="myplots.pdf")
> plot(...)
> dev.off()
> 
> Use Acrobat or gv to view the pdf files.  Postscript is also good, but
> not as universally understood; I have many coleagues who work in very
> standard Windows environments, where ghostscript is unknown.  PDF is a
> very sensible choice for e-mailing graphs.
> 
> 
> -- 
> Indigo Industrial Controls Ltd.
> http://www.indigoindustrial.co.nz
> +64-(0)21-343-545
> 
> 
> 
>



From p.dalgaard at biostat.ku.dk  Tue Sep 16 01:30:31 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon, 15 Sep 2003 23:30:31 -0000
Subject: [R] Re: [Rd] R 1.8.0 alpha
In-Reply-To: <16230.15657.839828.262501@arbres1a.fmr.com>
References: <x2pti8wr83.fsf@biostat.ku.dk>
	<16230.15657.839828.262501@arbres1a.fmr.com>
Message-ID: <x2fzixd3u6.fsf@biostat.ku.dk>

David Brahm  <brahm at alum.mit.edu> writes:

> Our Sun Ultra-80 running Solaris 2.8 (platform = sparc-sun-solaris2.8) failed
> to "make" R-1.8.0alpha_2003-09-15.tar.gz.  The tail end of the output follows.
> Note that we have gcc version 2.95.3, as a recent attempt to upgrade failed
> miserably.  Any ideas?

Hmm, works for me on Solaris 9 with that compiler (Man! is Perl slow
on those machines)... The error you get looks rather like a missing or
out of date libbz2, so you might want to check that or try

"configure --without-libbz"  

> BZ2_bzReadOpen                      connections.o
> BZ2_bzReadClose                     connections.o
> BZ2_bzWriteOpen                     connections.o
> BZ2_bzWrite                         connections.o
> BZ2_bzRead                          connections.o
> ld: fatal: Symbol referencing errors. No output written to R.bin
> collect2: ld returned 1 exit status
> make[3]: *** [R.bin] Error 1
> make[3]: Leaving directory `/res/R/R-1.8.0/src/main'
> make[2]: *** [R] Error 2
> make[2]: Leaving directory `/res/R/R-1.8.0/src/main'
> make[1]: *** [R] Error 1
> make[1]: Leaving directory `/res/R/R-1.8.0/src'
> make: *** [R] Error 1
> mica|R-1.8.0> 
> 
> 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From Anne.Olga.Piotet at omsv.vd.ch  Tue Sep 16 08:33:45 2003
From: Anne.Olga.Piotet at omsv.vd.ch (Anne Piotet)
Date: Tue, 16 Sep 2003 08:33:45 +0200
Subject: [R] Interfacing C++ , MysQL and R
Message-ID: <002201c37c1c$7adf7820$83dad10a@RENOVA4>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030916/d44f1802/attachment.pl

From ripley at stats.ox.ac.uk  Tue Sep 16 08:38:56 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 16 Sep 2003 07:38:56 +0100 (BST)
Subject: [R] how to print a plot
In-Reply-To: <1063667847.21254.72.camel@molecule.uchsc.edu>
Message-ID: <Pine.LNX.4.44.0309160734080.19291-100000@gannet.stats>

You did use dev.off() to finish the plots before trying to look at them?
The symptoms you report are what happens if you did not.

There is no ps() function in R: the postscript device is postscript() not 
ps().

If you want to print a plot, try dev.print.  If you want to copy to a 
file, try dev.copy2eps.  (You are on Linux, where EPS is more widely 
acceptable than PDF.)

On 15 Sep 2003, Weiming Zhang wrote:

> Hi, Thank both of you.
> 
> I tried everything. pdf(file="out.pdf") gave me a damaged pdf file. ps()
> did not print. ps("out.ps") gave me a ps file with badly drawn graph and
> could not be printed. I am using RH linux 7.2.
> 
> Thanks again.
> 
> weiming Zhang
> 
> 
> On Mon, 2003-09-15 at 16:06, Jason Turner wrote:
> > On Tue, 2003-09-16 at 08:56, Weiming Zhang wrote:
> > > Hi,
> > > 
> > > I am using R-1.7.1 on Linux. I integrated XEMACS with R. Could anybody
> > > tell me how to print a plot? I used plot function to make some graphs
> > > and then I wanted to print them or to save them to files. But I could
> > > not find out how to do it.
> > 
> > Have you tried:
> > help(Devices) 
> > help(pdf)
> > 
> > What I do:
> > 
> > pdf(file="myplots.pdf")
> > plot(...)
> > dev.off()
> > 
> > Use Acrobat or gv to view the pdf files.  Postscript is also good, but
> > not as universally understood; I have many coleagues who work in very
> > standard Windows environments, where ghostscript is unknown.  PDF is a
> > very sensible choice for e-mailing graphs.
> > 
> > 
> > -- 
> > Indigo Industrial Controls Ltd.
> > http://www.indigoindustrial.co.nz
> > +64-(0)21-343-545
> > 
> > 
> > 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From maechler at stat.math.ethz.ch  Mon Sep 15 17:07:09 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 15 Sep 2003 17:07:09 +0200
Subject: [R] Fourth R Mailing List : "R-packages"
Message-ID: <16229.54685.100766.810816@gargle.gargle.HOWL>

We (mainly the R core team) have been discussing the creation of another
R mailing list, with the goal to fill the gap between

   R-help	 very high volume, with its great merits, but....

and 

   R-announce	 only for R important announcements (mostly R-core)
		 hence __MODERATED__ and *very* low volume, and hence 
		 highly recommended for almost all users of R.
		 *** all messages are forwarded to R-help ***

In the past, several CRAN package authors have rightly felt that
they would like the announcement of a major update of a package
be a bit more prominent than the flood of messages on R-help but
(most of the time) they still weren't supposed nor granted to
use R-announce for this. This has been one main motivation for
this new mailing list:

  R-packages  	o  all messages forwarded to R-help
  	        o  moderated (i.e. not accepting posts by anyone),
                   but CRAN package authors (and others,
		   similarly qualified) can freely post without
		   moderator interaction {unless there's abuse}.

The corresponding (new) web page,
    http://www.stat.math.ethz.ch/mailman/listinfo/r-packages/
now has

  TITLE:	     R Packages & Extensions Announcements

  DESCRIPTION :

     A moderated board for announcements about contributed R packages
     and similar R project extensions.

     All messages are forwarded to R-help automatically, so please do
     not subscribe to this list if you are subscribed to R-help.

     For major announcements on the R project, see the R-announce
     mailing list, instead.

And R-project.org's "Mailing Lists" web page will describe it
from tomorrow as

>> R-packages
>> 
>>     This list is for announcements as well, usually on the
>>     availability of new or enhanced contributed packages (on CRAN, typically).
>> 
>>     Note that the list is moderated. However, CRAN package
>>     authors (and others, similarly qualified) can freely post.
>> 
>>     As with R-announce, all messages to R-packages are
>>     automatically forwarded to the main R-help mailing list;
>>     hence you should only subscribe to R-packages if you do not
>>     to R-help.
>> 
>>     Use the web interface for information, subscription, archives, etc.

Amount of mail to expect:  Of course, we don't know yet, but
       I'd expect to see only a few messages per week.

Finally, just re-iterating the obvious: 

 o	This is *NOT* a list for discussion, just announcements of extensions to R.

 o	Do only subscribe if you are *NOT* subscribed to R-help,
	(but then, strongly consider doing it)!
 
For more info, subscription, etc, please use the URL above

Your R mailing list maintainer,
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><

_______________________________________________
R-announce at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-announce



From glaziou at pasteur-kh.org  Tue Sep 16 10:16:16 2003
From: glaziou at pasteur-kh.org (Philippe Glaziou)
Date: Tue, 16 Sep 2003 15:16:16 +0700
Subject: [R] Interfacing C++ , MysQL and R
In-Reply-To: <002201c37c1c$7adf7820$83dad10a@RENOVA4>
References: <002201c37c1c$7adf7820$83dad10a@RENOVA4>
Message-ID: <20030916081616.GF653@pasteur-kh.org>

Anne Piotet <Anne.Olga.Piotet at omsv.vd.ch> wrote:
> After a presentation of some statistical analysis of
> process datas, (where the few R possibilities I was able
> to show made quite a big impression), I was asked if it
> was possible to program a statistical application which
> could be used directly by the end user.
> 
> Such an application would include a userfriendly interface
> (developped in C++), a db , a core statistical program,
> standard output; the necessary queries and statistical
> procedures would be interactively generated from the user
> input by the C++ program.  As I do not intend to reprogram
> the necessary statistical functions if I can help it, I'm
> interested to know if

> a) it is possible to integrate R in such a way?


I have on one of my institution's Linux servers R tightly
integrated with a fairly large PostgreSQL database accessed
from our LAN through a web interface (mostly php scripts),
with buttons to create monthly and annual reports generated
by R through RPgSQL. 

The output is a pdf file that goes to the email address that
the user provides, it takes 5 to 15 minutes to get the file,
depending on the CPU load. There is no C++ code there
because I do not see any need for it. It works well, and
users are very satisfied. Reports look good because they are
compiled with LaTeX. It would be fairly easy to let the user
create specific reports with his own particular queries. I am
very happy with that system, because I get very few requests
for help, and all the reports are timely sent to the MoH.

I am sure that many other members of this list have set up
much more sophisticated systems integrating R and
databases. 



> b) naturally as I would sell the end product, what the
> royalties arrangements are

I let this to the GPL experts.

-- 
Philippe Glaziou
Pasteur Institute of Cambodia



From petr.pikal at precheza.cz  Tue Sep 16 10:37:04 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue, 16 Sep 2003 10:37:04 +0200
Subject: [R] POSIX and identify
In-Reply-To: <5.2.0.9.0.20030915200206.03263d10@mail.gvdnet.dk>
References: <Pine.LNX.4.44.0309151840410.18347-100000@gannet.stats>
Message-ID: <3F66E7D0.23688.1A887B@localhost>

Hi

On 15 Sep 2003 at 20:09, Troels Ring wrote:

> Thanks a lot, but something else may be awry ? - at least
> as.POSIXct(Dato) although now of length 84 still elicits a report of
> different argument lengths even though length now is 84 for both
> arguments.

try
plot(as.POSIXct(Dato),Crea))

and
then

identify(as.POSIXct(Dato),Crea))

>  > identify(as.POSIXct(Dato),Crea,5,plot=TRUE)
> Error in identify(x, y, as.character(labels), n, plot, offset) :
>          different argument lengths
>  > length(as.POSIXct(Dato))
> [1] 84
>  > length(Crea)
> [1] 84
>  > length(Dato)
> [1] 9
> 
> Best wishes
> Troels Ring
> Aalborg
> 
> At 18:43 9/15/03, you wrote:
> >You need to convert to POSIXct before using Dato in identify().
> >This will work as you expected in R 1.8.0.
> >
> >On Mon, 15 Sep 2003, Troels Ring wrote:
> >
> > > Dear Friends, I'm using winXP and R 1.7.1 and plotting some data
> > > using dates on the x-axis, and wanted to use identify to show some
> > > points but 
> > was
> > > told by identify that the x and y vectors producing a fine graph
> > > with 84 points were not equal in length. Below are the Dato for
> > > date - and length(Dato) finds 9 but str finds 84 as known. Will
> > > identify not work in this context ? Best wishes Troels Ring
> > > Aalborg, Denmark
> > >  > Dato
> > >   [1] "2000-01-04" "2000-01-07" "2000-01-10" "2000-01-13"
> > >   "2000-01-17" .......
> > > [81] "2003-04-23" "2003-05-14" "2003-07-30" "2003-08-14"
> > >  > length(Dato)
> > > [1] 9
> > >  > str(Dato)
> > > `POSIXlt', format: chr [1:84] "2000-01-04" "2000-01-07"
> > > "2000-01-10" "2000-01-13" ...
> >
> >--
> >Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> >University of Oxford,             Tel:  +44 1865 272861 (self) 1
> >South Parks Road,                     +44 1865 272866 (PA) Oxford OX1
> >3TG, UK                Fax:  +44 1865 272595
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
>  [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

Cheers
Petr Pikal
petr.pikal at precheza.cz



From rdiaz at cnio.es  Tue Sep 16 11:44:21 2003
From: rdiaz at cnio.es (Ramon Diaz-Uriarte)
Date: Tue, 16 Sep 2003 11:44:21 +0200
Subject: [R] simplifying randomForest(s)
Message-ID: <200309161144.21535.rdiaz@cnio.es>

Dear All,

I have been using the randomForest package for a couple of difficult 
prediction problems (which also share p >> n). The performance is good, but 
since all the variables in the data set are used, interpretation of what is 
going on is not easy, even after looking at variable importance as produced 
by the randomForest run.

I have tried a simple "variable selection" scheme, and it does seem to perform 
well (as judged by leave-one-out) but I am not sure if it makes any sense.  
The idea is, in a kind of backwards elimination,  to eliminate one by one the 
variables with smallest importance (or all the ones with negative importance 
in one go) until the out-of-bag estimate of classification error becames 
larger than that of the previous model (or of the initial model). So nothing 
really new. But I haven't been able to find any comments in the literature 
about "simplification" of random forests. 

Any suggestions/comments?

Best,

Ram?n

-- 
Ram?n D?az-Uriarte
Bioinformatics Unit
Centro Nacional de Investigaciones Oncol?gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern?ndez Almagro, 3
28029 Madrid (Spain)
Fax: +-34-91-224-6972
Phone: +-34-91-224-6900

http://bioinfo.cnio.es/~rdiaz



From ucgamdo at ucl.ac.uk  Tue Sep 16 12:46:18 2003
From: ucgamdo at ucl.ac.uk (ucgamdo@ucl.ac.uk)
Date: Tue, 16 Sep 2003 11:46:18 +0100
Subject: [R] Persp and color
Message-ID: <3.0.5.32.20030916114618.007da890@pop-server.ucl.ac.uk>

Hi, 

If you run the demo for persp (I have R 1.7), you will see that there is a
good example of 'coluring' a volcano according to different heights, just try

> demo(persp)

and check out the code. You probably will find it too complicated as I did,
I was trying to do the same and honestly I wasn't able to. However, there
is a way around and it is to use the function wireframe from the lattice
package

> library(lattice)
> ?wireframe

If you run through the help examples you'll see that it is a lot easier to
colour the surfaces the way you want using this function. However,
wireframe is extreMELY slow, so, if you have a big matrix it might be a
pain in the behind. Also, the way you feed the data to wireframe is
different to the way you do it with the persp function. I hope this is of
any help.

M.



From vito.muggeo at giustizia.it  Tue Sep 16 13:16:53 2003
From: vito.muggeo at giustizia.it (Vito Muggeo)
Date: Tue, 16 Sep 2003 13:16:53 +0200
Subject: [R] package documentation
Message-ID: <008f01c37c44$0c933460$5c13070a@GIUSTIZIA.IT>

Dear all,
I writing my first package and everything seems to work (at least up to now)

However when I try to build documentation (.dvi or .pdf), using
Rcmd Rd2dvi.sh --pdf mypack.Rd
I get a mypack.pdf whose title is
"R documentation of mypack.Rd" instead of
"The mypack package"
as it should be, is it right?
Also Version, Title, ....License,  namely info from the DESCRIPTION file,
are missing on the first page.

Where is the problem?
Many thanks,
vito



From ripley at stats.ox.ac.uk  Tue Sep 16 13:44:21 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 16 Sep 2003 12:44:21 +0100 (BST)
Subject: [R] package documentation
In-Reply-To: <008f01c37c44$0c933460$5c13070a@GIUSTIZIA.IT>
Message-ID: <Pine.LNX.4.44.0309161239280.22571-100000@gannet.stats>

On Tue, 16 Sep 2003, Vito Muggeo wrote:

> I writing my first package and everything seems to work (at least up to now)
> 
> However when I try to build documentation (.dvi or .pdf), using
> Rcmd Rd2dvi.sh --pdf mypack.Rd
> I get a mypack.pdf whose title is
> "R documentation of mypack.Rd" instead of
> "The mypack package"
> as it should be, is it right?

It is right, rather than you: it did as you asked and not as you wanted.

> Also Version, Title, ....License,  namely info from the DESCRIPTION file,
> are missing on the first page.
> 
> Where is the problem?

  gannet% R CMD Rd2dvi --help
  Usage: R CMD Rd2dvi [options] files

  Generate DVI (or PDF) output from the Rd sources specified by files, by
  either giving the paths to the files, or the path to a directory with
  the sources of a package.

You haven't called this with the option to give what you expected.  Note 
what follows the `or'.  That will give Package 'mypack' as the title.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From andy_liaw at merck.com  Tue Sep 16 14:14:45 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 16 Sep 2003 08:14:45 -0400
Subject: [R] simplifying randomForest(s)
Message-ID: <3A822319EB35174CA3714066D590DCD50205CB23@usrymx25.merck.com>

Ramon,

> From: Ramon Diaz-Uriarte [mailto:rdiaz at cnio.es] 
> 
> Dear All,
> 
> I have been using the randomForest package for a couple of difficult 
> prediction problems (which also share p >> n). The 
> performance is good, but 
> since all the variables in the data set are used, 
> interpretation of what is 
> going on is not easy, even after looking at variable 
> importance as produced 
> by the randomForest run.
> 
> I have tried a simple "variable selection" scheme, and it 
> does seem to perform 
> well (as judged by leave-one-out) but I am not sure if it 
> makes any sense.  
> The idea is, in a kind of backwards elimination,  to 
> eliminate one by one the 
> variables with smallest importance (or all the ones with 
> negative importance 
> in one go) until the out-of-bag estimate of classification 
> error becames 
> larger than that of the previous model (or of the initial 
> model). So nothing 
> really new. But I haven't been able to find any comments in 
> the literature 
> about "simplification" of random forests. 

This is quite a hazardous game.  We've been burned by this ourselves.  I'll
send you a paper we submitted on variable selection for random forest
off-line.  (Those who are interested, let me know.)

The basic problem is that when you select important variables by RF and then
re-run RF with those variables, the OOB error rate become biased downward.
As you iterate more times, the "overfitting" becomes more and more severe
(in the sense that, the OOB error rate will keep decreasing while error rate
on an independent test set will be flat or increases).  I was na?ve enough
to ask Breiman about this, and his reply was something like "any competent
statistician would know that you need something like cross-validation to do
that"...

In the upcoming version 5 of Breiman's Fortran code, he offers an option to
run RF twice, first time with all variables, and the second with the k
(selected by user) most important variables from the 1st run.  The OOB error
rate from the 2nd run is no longer unbiased, but the bias is probably not
too severe with only one iteration.

Best,
Andy
 
> Any suggestions/comments?
> 
> Best,
> 
> Ram?n
> 
> -- 
> Ram?n D?az-Uriarte
> Bioinformatics Unit
> Centro Nacional de Investigaciones Oncol?gicas (CNIO)
> (Spanish National Cancer Center)
> Melchor Fern?ndez Almagro, 3
> 28029 Madrid (Spain)
> Fax: +-34-91-224-6972
> Phone: +-34-91-224-6900
> 
http://bioinfo.cnio.es/~rdiaz

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ms99_2000 at yahoo.de  Tue Sep 16 14:16:10 2003
From: ms99_2000 at yahoo.de (=?iso-8859-1?q?michael=20schmitt?=)
Date: Tue, 16 Sep 2003 14:16:10 +0200 (CEST)
Subject: [R] RSPython crashes (using R 1.7.1 under Solaris 5.9)
Message-ID: <20030916121610.98581.qmail@web40511.mail.yahoo.com>

Hello.
I tried to install RSPython on Solaris 5.9.

After compiling R with --enable-R-shlib, I try to
install RSPython using "R INSTALL --clean RSPython".
This led to an error complaining about missing
"libutil", wich seems not to exist on Solaris.
Therefore I just removed the "-lutil" entry in
"configure" and tried to install again. The
installation worked without problems, but after
calling python and importing "RS" the python
interpreter immediately crashes with a segmentation
fault.

Thanks for any hints.
Michael



From andy_liaw at merck.com  Tue Sep 16 14:26:37 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 16 Sep 2003 08:26:37 -0400
Subject: [R] Interfacing C++ , MysQL and R
Message-ID: <3A822319EB35174CA3714066D590DCD50205CB24@usrymx25.merck.com>

> From: Anne Piotet [mailto:Anne.Olga.Piotet at omsv.vd.ch] 
> 
> Hello!
> 
>     After a presentation of some statistical analysis of 
> process datas, (where the few  R possibilities I was able to 
> show made quite a big impression), I was asked if it was 
> possible to program a statistical  application which could be 
> used directly by the end user.
> 
> Such an application would include a userfriendly interface 
> (developped in C++), a db , a core statistical program, 
> standard output; the necessary queries and statistical 
> procedures would be interactively generated from the user 
> input by the C++ program.  As I do not intend to reprogram 
> the necessary statistical functions if I can help it, I'm 
> interested to know if
> a) it is possible to integrate R in such a way?
> b) naturally as I would sell the end product, what the 
> royalties arrangements are

Others will know more about this, but that never stopped me from tossing in
my $0.02...

As R is licensed as GPL, if you distribute (e.g., sell) your code, it will
have to be GPL'ed as well.  I believe that means while you can sell it for
money,

1. You have to make it clear to whomever get the code that it's GPL'ed.
2. You have to distribute the source code, or allow a way for people to get
source code.
3. You can not restrict further distribution of the code, free or otherwise.

My understanding of how RedHat deals with this (at least in their enterprise
server product) is by tacking on GPL a term that whoever installed their
software agrees to purchase service/support contract from them.  Another
company that has a software linked to R does similar thing, by not selling
the "software", but the "service" (installation and training).

HTH,
Andy

> c) has anybody in the list experience with such a project?
> 
> Thanks for the help!
> 
> Anne
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> 

------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From mmarques at power.inescn.pt  Tue Sep 16 15:36:16 2003
From: mmarques at power.inescn.pt (Mark Marques)
Date: Tue, 16 Sep 2003 14:36:16 +0100
Subject: [R] Persp and color and adding a color vector
In-Reply-To: <16231.1285.16665.836076@gargle.gargle.HOWL>
References: <3.0.5.32.20030916114618.007da890@pop-server.ucl.ac.uk>
	<16231.1285.16665.836076@gargle.gargle.HOWL>
Message-ID: <96103384484.20030916143616@power.inescn.pt>


Followin Prof. Uwes idea and after checking up some docs I was able to
build a color vector with the correct colors and then "call" it from
using persp col = option ...
Nevertheless I still have a small problem...
using something like :
colorvect <- rainbow(length(mat3),start=0.1,end=0.8)
persp(mat3,col=colorvect, box= FALSE, theta=30)
works something like I need...
But ...
if I try to visualize a specific part like mat3[1:900,2:78] ...
persp(mat3[1:900,2:78,col=colorvect, box= FALSE, theta=30)
What I get is bleach result with only part of the colors...
I know that I were specting this but how can I avoid it with making
the colorvect vector each time I call persp ?

The other idea is making an equivalent matrix with each cell with the
color info...
but how can I automate that kind of procedure ?

THanks
Mark Marques



From mailinglist.wegmann at gmx.net  Tue Sep 16 15:47:16 2003
From: mailinglist.wegmann at gmx.net (Martin Wegmann)
Date: Tue, 16 Sep 2003 15:47:16 +0200
Subject: [R] gam and concurvity
Message-ID: <200309161547.16883.mailinglist.wegmann@gmx.net>

Hello, 

in the paper "Avoiding the effects of concurvity in GAM's .." of Figueiras et 
al. (2003) it is mentioned that in GLM collinearity is taken into account in 
the calc of se but not in GAM (-> results in confidence interval too narrow, 
p-value understated,  GAM S-Plus version). I haven't found any references to 
GAM and concurvity or collinearity on the R page. And I wonder if the R 
version of Gam differ in this point.
Another question would be, what the best manual way of a variable selection 
is, due to the lack of a stepwise procedure for GAM. Including the first 
variables, add var1, if GCV improves (what would be considered as 
improvement?) or P-value signif., keep it, otherwise drop it - add var 2, and 
so on?

thanks in advance, cheers Martin



From ucgamdo at ucl.ac.uk  Tue Sep 16 16:00:38 2003
From: ucgamdo at ucl.ac.uk (ucgamdo@ucl.ac.uk)
Date: Tue, 16 Sep 2003 15:00:38 +0100
Subject: [R] Persp and color
In-Reply-To: <16231.1285.16665.836076@gargle.gargle.HOWL>
References: <3.0.5.32.20030916114618.007da890@pop-server.ucl.ac.uk>
	<3.0.5.32.20030916114618.007da890@pop-server.ucl.ac.uk>
Message-ID: <3.0.5.32.20030916150038.007dbbf0@pop-server.ucl.ac.uk>

Hi, first of all I would like to say that honestly the persp demo is quite
impresive, I won't take that away from you. The only problem I had, was
that the code that actually builds the matrix of topo-colours that are used
in the demo, is quite complicated (at least for me), and that code is
poorly commented. So I was left with a series of help's() to try to see
what each function would do, etc, etc..., while I was in that proccess I
rembered about the wireframe function, and after checking its
documentation, I found out that it has 'built-in' the ability to creaty
this topo colors, that, I think is a great advantage. Maybe a good idea
would be to insert the procedure you used to create the colors into the
persp function itself, so humble neophyte users can easily plot striking
volcano surfaces.

This is actually the bit of code I couldn't work out, I know I would if I
just could invest more of my precious time to it:

> fcol <- fill

> zi <- volcano[-1, -1] + volcano[-1, -61] + volcano[-87, 
    -1] + volcano[-87, -61]

> fcol[-i1, -i2] <- terrain.colors(20)[cut(zi, quantile(zi, 
    seq(0, 1, len = 21)), include.lowest = TRUE)]

> persp(x, y, 2 * z, theta = 110, phi = 40, col = fcol, 
    scale = FALSE, ltheta = -120, shade = 0.4, border = NA, box = FALSE)


just another thing, I have realised that the demo runs from beginning to
end without stopping (not always), that is not very nice because the plots
are displayed too quickly to appreciate, so the user is left to 'run' de
demo manualy, i.e. copying and pasting each bit of code in order to see
each plot in detail. I am aware that R is the product of the cooperation of
many people, contributing part of their work-time into making it better, I
think your demo is fine, and perhaps you won't have time to improve on it,
don't worry about that (no bad feelings).

You correctly pointed out that a better way around was to go ask R-help
directly. Certainly, that is what I intended to do with my own problem, but
first I wanted to write my code properly. Tomorrow, I will post a thread
about making persp representations of fractals in R, and maybe, you will be
able to help me in showing how to correctly apply the colours to the
surface. Maybe you will find this interested, and who knows, you will
perhaps put it in your demo!

By the way, I did also check help(persp), and how the colours are asigned
to the surface facets is not well specified, not even on the examples (as I
am aware of).

Thanks,
Mario.





At 14:41 16/09/03 +0200, you wrote:
>>>>>> "ucgamdo" == ucgamdo  <ucgamdo at ucl.ac.uk>
>>>>>>     on Tue, 16 Sep 2003 11:46:18 +0100 writes:
>
>    ucgamdo> Hi, If you run the demo for persp (I have R 1.7),
>    ucgamdo> you will see that there is a good example of
>    ucgamdo> 'coluring' a volcano according to different
>    ucgamdo> heights, just try
>
>    >> demo(persp)
>
>    ucgamdo> and check out the code. You probably will find it
>    ucgamdo> too complicated as I did, I was trying to do the
>    ucgamdo> same and honestly I wasn't able to. 
>
>Thank you for you honesty.  As a main author of the part of
>demo(persp) I'm quite interested to find out what the problem
>was.  I assume you also have looked at  help(persp) ?
>
>    ucgamdo> However, there is a way around 
>
>[ another way around would be to ask on R-help or ask  someone who
>  knows R better ... ... ]
>
>    ucgamdo> and it is to use the
>    ucgamdo> function wireframe from the lattice package
>
>    >> library(lattice) ?wireframe
>
>    ucgamdo> If you run through the help examples you'll see
>    ucgamdo> that it is a lot easier to colour the surfaces the
>    ucgamdo> way you want using this function. However,
>    ucgamdo> wireframe is extreMELY slow, so, if you have a big
>    ucgamdo> matrix it might be a pain in the behind. Also, the
>    ucgamdo> way you feed the data to wireframe is different to
>    ucgamdo> the way you do it with the persp function. I hope
>    ucgamdo> this is of any help.
>
>    ucgamdo> M.
>
>    ucgamdo> ______________________________________________
>    ucgamdo> R-help at stat.math.ethz.ch mailing list
>    ucgamdo> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>



From ligges at statistik.uni-dortmund.de  Tue Sep 16 16:07:44 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 16 Sep 2003 16:07:44 +0200
Subject: [R] Persp and color and adding a color vector
In-Reply-To: <96103384484.20030916143616@power.inescn.pt>
References: <3.0.5.32.20030916114618.007da890@pop-server.ucl.ac.uk>	<16231.1285.16665.836076@gargle.gargle.HOWL>
	<96103384484.20030916143616@power.inescn.pt>
Message-ID: <3F671930.9000509@statistik.uni-dortmund.de>

Mark Marques wrote:

> Followin Prof. Uwes 

Who's that? If you mean me, I am not a Professor ...


 > idea and after checking up some docs I was able to
> build a color vector with the correct colors and then "call" it from
> using persp col = option ...
> Nevertheless I still have a small problem...
> using something like :
> colorvect <- rainbow(length(mat3),start=0.1,end=0.8)

Attention: ?persp tells you there are (nx-1)(ny-1) facets given you have 
a matrix of dimension nx x ny.
Additionally, this was not my idea, at least you have to select the 
colors by height, if I understood your question correctly.


> persp(mat3,col=colorvect, box= FALSE, theta=30)
> works something like I need...
> But ...
> if I try to visualize a specific part like mat3[1:900,2:78] ...
> persp(mat3[1:900,2:78,col=colorvect, box= FALSE, theta=30)
> What I get is bleach result with only part of the colors...

What about writing a little function along the lines of

  foo <- function(M){
	colvect <- ...(M)...
	persp(M, .....)
  }
and calling it with
  foo(mat3[1:900,2:78])


> I know that I were specting this but how can I avoid it with making
> the colorvect vector each time I call persp ?

As already mentioned, generate some colors and then take one color for a 
certain range of values of your matrix.

Anyway, wireframe() in package lattice might have some features that are 
much more convenient to perform your task, as mentioned by someone else 
(too lazy to look into the archives).

Uwe Ligges


> The other idea is making an equivalent matrix with each cell with the
> color info...
> but how can I automate that kind of procedure ?
> 
> THanks
> Mark Marques
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From huan.huang at bnpparibas.com  Tue Sep 16 16:13:42 2003
From: huan.huang at bnpparibas.com (huan.huang@bnpparibas.com)
Date: Tue, 16 Sep 2003 15:13:42 +0100
Subject: [R] Retrieve ... argument values
Message-ID: <OF70A8C40F.5C2DB61B-ON80256DA3.004E28CA@bnpparibas.com>


Dear R users,

I want to retrieve "..." argument values within a function. Here is a small
exmaple:

myfunc <- function(x, ...)
{
      if (hasArg(ylim))  a <- ylim
      plot(x, ...)
}

x <- rnorm(100)
myfunc(x, ylim=c(-0.5, 0.5))
Error in myfunc(x, ylim = c(-0.5, 0.5)) : Object "ylim" not found
>

I need to retrieve values of "ylim" (if it is defined when function is called) for later use in the function. Can anybody give me some hint?

Thanks a lot.

Huan




This message and any attachments (the "message") is\ intende...{{dropped}}



From vito.muggeo at giustizia.it  Tue Sep 16 16:28:37 2003
From: vito.muggeo at giustizia.it (Vito Muggeo)
Date: Tue, 16 Sep 2003 16:28:37 +0200
Subject: R: [R] gam and concurvity
References: <200309161547.16883.mailinglist.wegmann@gmx.net>
Message-ID: <00fe01c37c5e$d4671000$5c13070a@GIUSTIZIA.IT>

As someone (Simon Wood, for instance) could explain much better and as it is
stressed in the help files of the mgcv pakage (the package  including the
gam() function)
gam in R is not a clone of gam in S+.
S+ uses backfitting while R uses penalized splines (see the references
inside gam() function). The approaches are quite different and can lead to
substantial differences in particular cases, for instance with concurvity.

best,
vito

PS Can you point out the exact reference for "Figueiras et al. (2003)"?


----- Original Message -----
From: Martin Wegmann <mailinglist.wegmann at gmx.net>
To: R-list <r-help at stat.math.ethz.ch>
Sent: Tuesday, September 16, 2003 3:47 PM
Subject: [R] gam and concurvity


> Hello,
>
> in the paper "Avoiding the effects of concurvity in GAM's .." of Figueiras
et
> al. (2003) it is mentioned that in GLM collinearity is taken into account
in
> the calc of se but not in GAM (-> results in confidence interval too
narrow,
> p-value understated,  GAM S-Plus version). I haven't found any references
to
> GAM and concurvity or collinearity on the R page. And I wonder if the R
> version of Gam differ in this point.
> Another question would be, what the best manual way of a variable
selection
> is, due to the lack of a stepwise procedure for GAM. Including the first
> variables, add var1, if GCV improves (what would be considered as
> improvement?) or P-value signif., keep it, otherwise drop it - add var 2,
and
> so on?
>
> thanks in advance, cheers Martin
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From tlumley at u.washington.edu  Tue Sep 16 16:27:38 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 16 Sep 2003 07:27:38 -0700 (PDT)
Subject: [R] Persp and color
In-Reply-To: <3.0.5.32.20030916150038.007dbbf0@pop-server.ucl.ac.uk>
Message-ID: <Pine.A41.4.44.0309160726430.223948-100000@homer07.u.washington.edu>

On Tue, 16 Sep 2003 ucgamdo at ucl.ac.uk wrote:

> just another thing, I have realised that the demo runs from beginning to
> end without stopping (not always), that is not very nice because the plots
> are displayed too quickly to appreciate, so the user is left to 'run' de
> demo manualy, i.e. copying and pasting each bit of code in order to see
> each plot in detail. I am aware that R is the product of the cooperation of
> many people, contributing part of their work-time into making it better, I
> think your demo is fine, and perhaps you won't have time to improve on it,
> don't worry about that (no bad feelings).
>

If you type
  par(ask=TRUE)

you will always be prompted before a new graph is drawn.

	-thomas



From ligges at statistik.uni-dortmund.de  Tue Sep 16 16:32:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 16 Sep 2003 16:32:03 +0200
Subject: [R] Persp and color
In-Reply-To: <3.0.5.32.20030916150038.007dbbf0@pop-server.ucl.ac.uk>
References: <3.0.5.32.20030916114618.007da890@pop-server.ucl.ac.uk>	<3.0.5.32.20030916114618.007da890@pop-server.ucl.ac.uk>
	<3.0.5.32.20030916150038.007dbbf0@pop-server.ucl.ac.uk>
Message-ID: <3F671EE3.1070000@statistik.uni-dortmund.de>

ucgamdo at ucl.ac.uk wrote:

> Hi, first of all I would like to say that honestly the persp demo is quite
> impresive, I won't take that away from you. The only problem I had, was
> that the code that actually builds the matrix of topo-colours that are used
> in the demo, is quite complicated (at least for me), and that code is
> poorly commented. So I was left with a series of help's() to try to see
> what each function would do, etc, etc..., while I was in that proccess I
> rembered about the wireframe function, and after checking its
> documentation, I found out that it has 'built-in' the ability to creaty
> this topo colors, that, I think is a great advantage. Maybe a good idea
> would be to insert the procedure you used to create the colors into the
> persp function itself, so humble neophyte users can easily plot striking
> volcano surfaces.
> 
> This is actually the bit of code I couldn't work out, I know I would if I
> just could invest more of my precious time to it:
> 
> 
>>fcol <- fill
> 
> 
>>zi <- volcano[-1, -1] + volcano[-1, -61] + volcano[-87, 
> 
>     -1] + volcano[-87, -61]

Since

  dim(volcano)
  [1] 87 61

you have to throw away some points of the margins, because you need 
(nx-1)*(ny-1) facets' colors. And you want the color to be specified for 
the middle of the facets, not one of the 4 corners, so you average the 
matrices of those 4 corners.



>>fcol[-i1, -i2] <- terrain.colors(20)[cut(zi, quantile(zi, 
> 
>     seq(0, 1, len = 21)), include.lowest = TRUE)]


You use 20 different colors, choosen (indexed) by quantiles of the 
matrix calculated above. That's the obvious idea (nice implemented here, 
though).


>>persp(x, y, 2 * z, theta = 110, phi = 40, col = fcol, 
> 
>     scale = FALSE, ltheta = -120, shade = 0.4, border = NA, box = FALSE)
> 
> 
> just another thing, I have realised that the demo runs from beginning to
> end without stopping (not always), that is not very nice because the plots
> are displayed too quickly to appreciate, so the user is left to 'run' de
> demo manualy, i.e. copying and pasting each bit of code in order to see
> each plot in detail. I am aware that R is the product of the cooperation of
> many people, contributing part of their work-time into making it better, I
> think your demo is fine, and perhaps you won't have time to improve on it,
> don't worry about that (no bad feelings).


The improvement seems to be:

  par(ask = TRUE)
  demo(persp)

Uwe Ligges



> You correctly pointed out that a better way around was to go ask R-help
> directly. Certainly, that is what I intended to do with my own problem, but
> first I wanted to write my code properly. Tomorrow, I will post a thread
> about making persp representations of fractals in R, and maybe, you will be
> able to help me in showing how to correctly apply the colours to the
> surface. Maybe you will find this interested, and who knows, you will
> perhaps put it in your demo!
> 
> By the way, I did also check help(persp), and how the colours are asigned
> to the surface facets is not well specified, not even on the examples (as I
> am aware of).
> 
> Thanks,
> Mario.
> 
> 
> 
> 
> 
> At 14:41 16/09/03 +0200, you wrote:
> 
>>>>>>>"ucgamdo" == ucgamdo  <ucgamdo at ucl.ac.uk>
>>>>>>>    on Tue, 16 Sep 2003 11:46:18 +0100 writes:
>>
>>   ucgamdo> Hi, If you run the demo for persp (I have R 1.7),
>>   ucgamdo> you will see that there is a good example of
>>   ucgamdo> 'coluring' a volcano according to different
>>   ucgamdo> heights, just try
>>
>>   >> demo(persp)
>>
>>   ucgamdo> and check out the code. You probably will find it
>>   ucgamdo> too complicated as I did, I was trying to do the
>>   ucgamdo> same and honestly I wasn't able to. 
>>
>>Thank you for you honesty.  As a main author of the part of
>>demo(persp) I'm quite interested to find out what the problem
>>was.  I assume you also have looked at  help(persp) ?
>>
>>   ucgamdo> However, there is a way around 
>>
>>[ another way around would be to ask on R-help or ask  someone who
>> knows R better ... ... ]
>>
>>   ucgamdo> and it is to use the
>>   ucgamdo> function wireframe from the lattice package
>>
>>   >> library(lattice) ?wireframe
>>
>>   ucgamdo> If you run through the help examples you'll see
>>   ucgamdo> that it is a lot easier to colour the surfaces the
>>   ucgamdo> way you want using this function. However,
>>   ucgamdo> wireframe is extreMELY slow, so, if you have a big
>>   ucgamdo> matrix it might be a pain in the behind. Also, the
>>   ucgamdo> way you feed the data to wireframe is different to
>>   ucgamdo> the way you do it with the persp function. I hope
>>   ucgamdo> this is of any help.
>>
>>   ucgamdo> M.
>>
>>   ucgamdo> ______________________________________________
>>   ucgamdo> R-help at stat.math.ethz.ch mailing list
>>   ucgamdo> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From rdiaz at cnio.es  Tue Sep 16 16:31:19 2003
From: rdiaz at cnio.es (Ramon Diaz-Uriarte)
Date: Tue, 16 Sep 2003 16:31:19 +0200
Subject: [R] simplifying randomForest(s)
In-Reply-To: <3A822319EB35174CA3714066D590DCD50205CB23@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD50205CB23@usrymx25.merck.com>
Message-ID: <200309161631.19948.rdiaz@cnio.es>

Dear Andy,

Thanks a lot for your message.

> This is quite a hazardous game.  We've been burned by this ourselves.  I'll
> send you a paper we submitted on variable selection for random forest
> off-line.  (Those who are interested, let me know.)

Thanks!

>
> The basic problem is that when you select important variables by RF and
> then re-run RF with those variables, the OOB error rate become biased
> downward. As you iterate more times, the "overfitting" becomes more and
> more severe (in the sense that, the OOB error rate will keep decreasing
> while error rate on an independent test set will be flat or increases).  I
> was na?ve enough to ask Breiman about this, and his reply was something
> like "any competent statistician would know that you need something like
> cross-validation to do that"...

Yes, I understand the points you are making. However, I have tried to achieve 
protection against this problem by assessing the leave-one-out 
cross-validation error (LOOCVE) of the complete selection process. And the 
LOOCVE suggests this is working. Within the variable selection routine the 
OOB error rate is biased, but I guess that does not concern me that much, 
because I only use it to guide the selection. However, my final estimate of 
error comes from the LOOCVE.

This is the esqueleton of the alorithm:

n <- length(y)

for(i in 1:n) {
	the.simple.rf <- simplify.the.rf(data = data[-i, ])
	prediction[i] <- predict(the.simple.rf, newdata = data[i, ])
}
loocve <- sum(y != prediction) / n

Thus, the LOOCVE is computed with observations that were never used for the 
simplification of the tree that is predicting them.

[I'll be glad to send my code to anyone interested].

And, the interesting thing with the data set I have tried is that it seems to 
perform reasonably (actually, the LOOCVE of a tree with the reduced set of 
variables is smaller than the LOOCVE of the original tree).

(This is a first shot. I have a small sample size (29) so LOOCV is not that 
bad in terms of computation, although I am aware it can have high variance. I 
guess I could try the .632+ bootstrap method).



Best,

Ram?n



>
> Best,
> Andy
>
> > Any suggestions/comments?
> >
> > Best,
> >
> > Ram?n
> >
> > --
> > Ram?n D?az-Uriarte
> > Bioinformatics Unit
> > Centro Nacional de Investigaciones Oncol?gicas (CNIO)
> > (Spanish National Cancer Center)
> > Melchor Fern?ndez Almagro, 3
> > 28029 Madrid (Spain)
> > Fax: +-34-91-224-6972
> > Phone: +-34-91-224-6900
>
> http://bioinfo.cnio.es/~rdiaz
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
> ---------------------------------------------------------------------------
>--- Notice:  This e-mail message, together with any attachments, contains
> information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA),
> and/or its affiliates (which may be known outside the United States as
> Merck Frosst, Merck Sharp & Dohme or MSD) that may be confidential,
> proprietary copyrighted and/or legally privileged, and is intended solely
> for the use of the individual or entity named on this message.  If you are
> not the intended recipient, and have received this message in error, please
> immediately return this by e-mail and then delete it.
> ---------------------------------------------------------------------------
>---

-- 
Ram?n D?az-Uriarte
Bioinformatics Unit
Centro Nacional de Investigaciones Oncol?gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern?ndez Almagro, 3
28029 Madrid (Spain)
Fax: +-34-91-224-6972
Phone: +-34-91-224-6900

http://bioinfo.cnio.es/~rdiaz



From tlumley at u.washington.edu  Tue Sep 16 16:38:19 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 16 Sep 2003 07:38:19 -0700 (PDT)
Subject: [R] gam and concurvity
In-Reply-To: <200309161547.16883.mailinglist.wegmann@gmx.net>
Message-ID: <Pine.A41.4.44.0309160727590.223948-100000@homer07.u.washington.edu>

On Tue, 16 Sep 2003, Martin Wegmann wrote:

> Hello,
>
> in the paper "Avoiding the effects of concurvity in GAM's .." of Figueiras et
> al. (2003) it is mentioned that in GLM collinearity is taken into account in
> the calc of se but not in GAM (-> results in confidence interval too narrow,
> p-value understated,  GAM S-Plus version). I haven't found any references to
> GAM and concurvity or collinearity on the R page. And I wonder if the R
> version of Gam differ in this point.

They do.

R gam() uses penalised splines, resulting in an easily managed design
matrix.  S-PLUS gam() uses smoothing splines, and (until recently) there
wasn't any known feasible formula for the standard errors.

However:

1/ `Concurvity' is a serious problem only for a few extreme uses of gam.
Even in the air pollution time series studies that provoked the recent
fuss, there impact is really important only in studies that very
aggressively removed seasonal patterns or in data with huge seasonal
variations (eg inland Canada).

2/  These two cases are precisely the cases where the results are
sensitive to the choice of time scale at which seasonal variation
confounds the association, a choice that is not identifiable from the
data.

3/  Neither S-PLUS or R gam() standard errors incorporate the uncertainty
in an automatically chosen smoothing parameter.

4/ Trevor Hastie and colleagues have written software for calculating
correct standard errors for S-PLUS gam.

	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From tlumley at u.washington.edu  Tue Sep 16 16:40:45 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 16 Sep 2003 07:40:45 -0700 (PDT)
Subject: [R] Retrieve ... argument values
In-Reply-To: <OF70A8C40F.5C2DB61B-ON80256DA3.004E28CA@bnpparibas.com>
Message-ID: <Pine.A41.4.44.0309160738490.223948-100000@homer07.u.washington.edu>

On Tue, 16 Sep 2003 huan.huang at bnpparibas.com wrote:

>
> Dear R users,
>
> I want to retrieve "..." argument values within a function. Here is a small
> exmaple:
>
> myfunc <- function(x, ...)
> {
>       if (hasArg(ylim))  a <- ylim
>       plot(x, ...)
> }
>

One solution is
    dots<-substitute(list(...))
    a<-dots$ylim

which sets a to NULL if there is no ylim argument and to the ylim argument
if it exists

	-thomas



From p.dalgaard at biostat.ku.dk  Tue Sep 16 16:48:38 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Tue, 16 Sep 2003 14:48:38 -0000
Subject: [R] Retrieve ... argument values
In-Reply-To: <OF70A8C40F.5C2DB61B-ON80256DA3.004E28CA@bnpparibas.com>
References: <OF70A8C40F.5C2DB61B-ON80256DA3.004E28CA@bnpparibas.com>
Message-ID: <x2pti03hyw.fsf@biostat.ku.dk>

huan.huang at bnpparibas.com writes:

> Dear R users,
> 
> I want to retrieve "..." argument values within a function. Here is a small
> exmaple:
> 
> myfunc <- function(x, ...)
> {
>       if (hasArg(ylim))  a <- ylim
>       plot(x, ...)
> }
> 
> x <- rnorm(100)
> myfunc(x, ylim=c(-0.5, 0.5))
> Error in myfunc(x, ylim = c(-0.5, 0.5)) : Object "ylim" not found
> >
> 
> I need to retrieve values of "ylim" (if it is defined when function
> is called) for later use in the function. Can anybody give me some
> hint?

Yes, several:

"ylim" %in% names(match.call(expand.dots=FALSE)$...)

or

"ylim" %in% names(list(...)

(Use the former if it is somehow important not to evaluate the
arguments).

Or even

a <- list(...)$ylim

and then check for is.null(a).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From Simon.Fear at synequanon.com  Tue Sep 16 16:47:55 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Tue, 16 Sep 2003 15:47:55 +0100
Subject: [R] Retrieve ... argument values
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572AC0DD2@synequanon01>

For most purposes a more useful technique is to write the
function with a default NULL argument

myfunc <- function(x, ylim=NULL)

so that it can be called as myfunc(x) or myfunc(x,y). Inside
the function you test for !is.null(ylim) and take appropriate
action.

Alternatively, and maybe more commonly, you give ylim a 
sensible default so the caller has to be explicit about 
setting ylim to NULL if required.

As it happens, in your specific case you can write as you did except
for the pseudo-line(hasArg(ylim)), because all arguments will get
passed to plot, which will itself recognise and test for
an argument called ylim, within its own "...".

HTH

> -----Original Message-----
> From: huan.huang at bnpparibas.com [mailto:huan.huang at bnpparibas.com]
> Sent: 16 September 2003 15:14
> To: r-help at stat.math.ethz.ch
> Subject: [R] Retrieve ... argument values
> 
> 
> Security Warning:
> If you are not sure an attachment is safe to open please contact 
> Andy on x234. There are 0 attachments with this message.
> ________________________________________________________________
> 
> 
> Dear R users,
> 
> I want to retrieve "..." argument values within a function. Here is a
> small
> exmaple:
> 
> myfunc <- function(x, ...)
> {
>       if (hasArg(ylim))  a <- ylim
>       plot(x, ...)
> }
> 
> x <- rnorm(100)
> myfunc(x, ylim=c(-0.5, 0.5))
> Error in myfunc(x, ylim = c(-0.5, 0.5)) : Object "ylim" not found
> >
> 
> I need to retrieve values of "ylim" (if it is defined when function is
> called) for later use in the function. Can anybody give me some hint?
> 
> Thanks a lot.
> 
> Huan
> 
> 
> 
> 
> This message and any attachments (the "message") is\
> intende...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
 

Simon Fear
Senior Statistician
Syne qua non Ltd
Tel: +44 (0) 1379 644449
Fax: +44 (0) 1379 644445
email: Simon.Fear at synequanon.com
web: http://www.synequanon.com
 
Number of attachments included with this message: 0
 
This message (and any associated files) is confidential and\...{{dropped}}



From tblackw at umich.edu  Tue Sep 16 16:50:24 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Tue, 16 Sep 2003 10:50:24 -0400 (EDT)
Subject: [R] Retrieve ... argument values
In-Reply-To: <OF70A8C40F.5C2DB61B-ON80256DA3.004E28CA@bnpparibas.com>
References: <OF70A8C40F.5C2DB61B-ON80256DA3.004E28CA@bnpparibas.com>
Message-ID: <Pine.SOL.4.58.0309161044330.28414@robotron.gpcc.itd.umich.edu>

Huan  -

Look at the function code for  order().  To show the function
definition, type just order at the command line (no quotes,
no parentheses).  This example is what I found most useful
when I had a similar question.  The green book is also useful.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Tue, 16 Sep 2003 huan.huang at bnpparibas.com wrote:

> Dear R users,
>
> I want to retrieve "..." argument values within a function.
> Here is a small exmaple:
>
> myfunc <- function(x, ...)
> {
>       if (hasArg(ylim))  a <- ylim
>       plot(x, ...)
> }
>
> I need to retrieve values of "ylim" (if it is defined when
> function is called) for later use in the function. Can anybody
> give me some hint?  Thanks a lot.
> Huan



From andy_liaw at merck.com  Tue Sep 16 16:54:39 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 16 Sep 2003 10:54:39 -0400
Subject: [R] Retrieve ... argument values
Message-ID: <3A822319EB35174CA3714066D590DCD50205CB2C@usrymx25.merck.com>

Try:

 myfunc <- function(x, ...)
 {
       if (hasArg(ylim))  a <- ...$ylim
       plot(x, ...)
 }

HTH,
Andy

> -----Original Message-----
> From: huan.huang at bnpparibas.com [mailto:huan.huang at bnpparibas.com] 
> Sent: Tuesday, September 16, 2003 10:14 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Retrieve ... argument values
> 
> 
> 
> Dear R users,
> 
> I want to retrieve "..." argument values within a function. 
> Here is a small
> exmaple:
> 
> myfunc <- function(x, ...)
> {
>       if (hasArg(ylim))  a <- ylim
>       plot(x, ...)
> }
> 
> x <- rnorm(100)
> myfunc(x, ylim=c(-0.5, 0.5))
> Error in myfunc(x, ylim = c(-0.5, 0.5)) : Object "ylim" not found
> >
> 
> I need to retrieve values of "ylim" (if it is defined when 
> function is called) for later use in the function. Can 
> anybody give me some hint?
> 
> Thanks a lot.
> 
> Huan
> 
> 
> 
> 
> This message and any attachments (the "message") is\ 
> intende...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> 

------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From mailinglist.wegmann at gmx.net  Tue Sep 16 17:04:11 2003
From: mailinglist.wegmann at gmx.net (Martin Wegmann)
Date: Tue, 16 Sep 2003 17:04:11 +0200
Subject: R: [R] gam and concurvity
In-Reply-To: <00fe01c37c5e$d4671000$5c13070a@GIUSTIZIA.IT>
References: <200309161547.16883.mailinglist.wegmann@gmx.net>
	<00fe01c37c5e$d4671000$5c13070a@GIUSTIZIA.IT>
Message-ID: <200309161704.11512.mailinglist.wegmann@gmx.net>

On Tuesday 16 September 2003 16:28, Vito Muggeo wrote:
> As someone (Simon Wood, for instance) could explain much better and as it
> is stressed in the help files of the mgcv pakage (the package  including
> the gam() function)
> gam in R is not a clone of gam in S+.
> S+ uses backfitting while R uses penalized splines (see the references
> inside gam() function). The approaches are quite different and can lead to
> substantial differences in particular cases, for instance with concurvity.
>
> best,
> vito
>
> PS Can you point out the exact reference for "Figueiras et al. (2003)"?

I haven't found a journal name but the *.pdf download is 
http://isi-eh.usc.es/trabajos/110_70_fullpaper.pdf 


> ----- Original Message -----
> From: Martin Wegmann <mailinglist.wegmann at gmx.net>
> To: R-list <r-help at stat.math.ethz.ch>
> Sent: Tuesday, September 16, 2003 3:47 PM
> Subject: [R] gam and concurvity
>
> > Hello,
> >
> > in the paper "Avoiding the effects of concurvity in GAM's .." of
> > Figueiras
>
> et
>
> > al. (2003) it is mentioned that in GLM collinearity is taken into account
>
> in
>
> > the calc of se but not in GAM (-> results in confidence interval too
>
> narrow,
>
> > p-value understated,  GAM S-Plus version). I haven't found any references
>
> to
>
> > GAM and concurvity or collinearity on the R page. And I wonder if the R
> > version of Gam differ in this point.
> > Another question would be, what the best manual way of a variable
>
> selection
>
> > is, due to the lack of a stepwise procedure for GAM. Including the first
> > variables, add var1, if GCV improves (what would be considered as
> > improvement?) or P-value signif., keep it, otherwise drop it - add var 2,
>
> and
>
> > so on?
> >
> > thanks in advance, cheers Martin
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Ted.Harding at nessie.mcc.ac.uk  Tue Sep 16 16:54:16 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue, 16 Sep 2003 15:54:16 +0100 (BST)
Subject: [R] "Old" libraries with new R?
Message-ID: <XFMail.030916155416.Ted.Harding@nessie.mcc.ac.uk>

Hi Folks,

I'm currently installing R-1.7.1 off CRAN.

As it happens, I have a CD (kindly made for me by Linux
Emporium) containing all the libraries which were on CRAN
early this year when I installed R-1.6.1. This is highly
convenient, since the alternative would be several hours
on-line.

While a recent library will on installation announce the
fact should it need a newer version of R than the one which
is installed, presumably this is not likely to be the case
for an old library if a newer version of R is incompatible
with it.

So is there a way of finding out whether a library dating
from some time back is compatible with a recent R, other than
simply trying it out to see if it works OK?

With thanks, and best wishes to all,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 16-Sep-03                                       Time: 15:54:16
------------------------------ XFMail ------------------------------



From bolker at zoo.ufl.edu  Tue Sep 16 17:17:36 2003
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Tue, 16 Sep 2003 11:17:36 -0400 (EDT)
Subject: [R] Retrieve ... argument values
In-Reply-To: <6C8A8033ABC1E3468048ABC4F13CE572AC0DD2@synequanon01>
Message-ID: <Pine.LNX.4.44.0309161116020.20066-100000@bolker.zoo.ufl.edu>

  
  Yes, although this becomes tedious if (e.g.) you have a function that 
calls two different functions, each of which has many arguments (e.g. 
plot() and barplot(); then you have to set up a whole lot of arguments 
that default to NULL and, more annoyingly, you have to document them all 
in any .Rd file you create -- rather than just having a ... argument which 
you can say should contain arguments for either of the subfunctions (as 
long as the arguments don't overlap, of course)

  Ben


On Tue, 16 Sep 2003, Simon Fear wrote:

> For most purposes a more useful technique is to write the
> function with a default NULL argument
> 
> myfunc <- function(x, ylim=NULL)
> 
> so that it can be called as myfunc(x) or myfunc(x,y). Inside
> the function you test for !is.null(ylim) and take appropriate
> action.
> 
> Alternatively, and maybe more commonly, you give ylim a 
> sensible default so the caller has to be explicit about 
> setting ylim to NULL if required.
> 
> As it happens, in your specific case you can write as you did except
> for the pseudo-line(hasArg(ylim)), because all arguments will get
> passed to plot, which will itself recognise and test for
> an argument called ylim, within its own "...".
> 
> HTH
> 
> > -----Original Message-----
> > From: huan.huang at bnpparibas.com [mailto:huan.huang at bnpparibas.com]
> > Sent: 16 September 2003 15:14
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] Retrieve ... argument values
> > 
> > 
> > Security Warning:
> > If you are not sure an attachment is safe to open please contact 
> > Andy on x234. There are 0 attachments with this message.
> > ________________________________________________________________
> > 
> > 
> > Dear R users,
> > 
> > I want to retrieve "..." argument values within a function. Here is a
> > small
> > exmaple:
> > 
> > myfunc <- function(x, ...)
> > {
> >       if (hasArg(ylim))  a <- ylim
> >       plot(x, ...)
> > }
> > 
> > x <- rnorm(100)
> > myfunc(x, ylim=c(-0.5, 0.5))
> > Error in myfunc(x, ylim = c(-0.5, 0.5)) : Object "ylim" not found
> > >
> > 
> > I need to retrieve values of "ylim" (if it is defined when function is
> > called) for later use in the function. Can anybody give me some hint?
> > 
> > Thanks a lot.
> > 
> > Huan
> > 
> > 
> > 
> > 
> > This message and any attachments (the "message") is\
> > intende...{{dropped}}
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>  
> 
> Simon Fear
> Senior Statistician
> Syne qua non Ltd
> Tel: +44 (0) 1379 644449
> Fax: +44 (0) 1379 644445
> email: Simon.Fear at synequanon.com
> web: http://www.synequanon.com
>  
> Number of attachments included with this message: 0
>  
> This message (and any associated files) is confidential and\...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From paulda at BATTELLE.ORG  Tue Sep 16 17:19:11 2003
From: paulda at BATTELLE.ORG (Paul, David  A)
Date: Tue, 16 Sep 2003 11:19:11 -0400
Subject: [R] gnls( ) question
Message-ID: <940250A9EB37A24CBE28D858EF07774967AB08@ws-bco-mse3.milky-way.battelle.org>

Last week (Wed 9/10/2003, "regression questions") I posted 
a question regarding the use of gnls( ) and its dissimilarity 
to the syntax that nls( ) will accept.  No one replied, so 
I partly answered my own question by constructing indicator 
variables for use in gnls( ).  The code I used to construct 
the indicators is at the end of this email.
 
I do have a nagging, unanswered question:

What exactly does "Warning message: Step halving factor 
reduced below minimum in NLS step in: gnls(model = y ~ 5 + ...)"
mean?  I have tried to address this by specifying "control = 
list(maxIter = 1000, pnlsMaxIter = 200, msMaxIter = 1000, 
tolerance = 1e-06, pnlsTol = 1e-04, msTol = 1e-07, minScale = 
1e-10, returnObject = TRUE)" in my model calls, but this
does not entirely eliminate the problem (I am running gnls( )
24 separate times on separate data sets).

 
Much thanks in advance,
  david paul



#Constructing Indicator Variables
indicator <- paste( "foo$X <- sapply(foo$subject.id, 
	FUN = function(x) if(x == X) 1 else 0)" )
indicator <- parse( text = indicator )[[1]]
subjectID.foo <- as.factor(as.character(unique(foo$animal.id)))

for(i in subjectID.foo)
{
	INDICATOR <-  do.call("substitute", 
			list(indicator, list(i = i, 
				X = as.character(subjectID.foo[i]))))
	eval(INDICATOR)
}

foo$Overall.Effect <- rep(1,length(foo$dose.group))



From jose.pinheiro at pharma.novartis.com  Tue Sep 16 17:24:27 2003
From: jose.pinheiro at pharma.novartis.com (jose.pinheiro@pharma.novartis.com)
Date: Tue, 16 Sep 2003 11:24:27 -0400
Subject: [R] ASA Stat. Computing and Stat. Graphics 2004 Student Paper
	competition
Message-ID: <OF7208141F.856D8FF7-ON85256DA3.00546937-85256DA3.005488F6@EU.novartis.net>

The Statistical Computing and Statistical Graphics Sections of the ASA
are co-sponsoring a student paper competition on the topics of
Statistical Computing and Statistical Graphics.  Students are
encouraged to submit a paper in one of these areas, which might be
original methodological research, some novel computing or graphical
application in statistics, or any other suitable contribution (for
example, a software-related project).  The selected winners will
present their papers in a topic-contributed session at the 2004 Joint
Statistical Meetings.  The Sections will pay registration fees for the
winners as well as a substantial allowance for transportation to the
meetings and lodging. Enclosed below is the full text of the award 
announcement.
More details can be found at the Stat. Computing Section website at
http://www.statcomputing.org. 



Best Regards,

--Jos? Pinheiro

Awards Chair
ASA Statistical Computing Section
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: StudentPaper2004.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030916/1cf5e49a/StudentPaper2004.txt

From Simon.Fear at synequanon.com  Tue Sep 16 17:25:32 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Tue, 16 Sep 2003 16:25:32 +0100
Subject: [R] Retrieve ... argument values
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572AC0DD3@synequanon01>

Yes, and I was wrong to say ylim=NULL was "more useful", I should 
have said "much easier to understand and much easier to read,
debug and maintain". Of course for certain applications it IS worth
getting to grips with "...", and other people's posts have
been extremely useful in that regard.

> -----Original Message-----
> From: Ben Bolker [mailto:bolker at zoo.ufl.edu]
> Sent: 16 September 2003 16:18
> To: Simon Fear
> Cc: huan.huang at bnpparibas.com; R help list
> Subject: RE: [R] Retrieve ... argument values
> 
> 
> Security Warning:
> If you are not sure an attachment is safe to open please contact 
> Andy on x234. There are 0 attachments with this message.
> ________________________________________________________________
> 
>   
>   Yes, although this becomes tedious if (e.g.) you have a 
> function that 
> calls two different functions, each of which has many arguments (e.g. 
> plot() and barplot(); then you have to set up a whole lot of 
> arguments 
> that default to NULL and, more annoyingly, you have to 
> document them all
> in any .Rd file you create -- rather than just having a ... argument
> which 
> you can say should contain arguments for either of the 
> subfunctions (as 
> long as the arguments don't overlap, of course)
> 
>   Ben
> 
>
 

Simon Fear
Senior Statistician
Syne qua non Ltd
Tel: +44 (0) 1379 644449
Fax: +44 (0) 1379 644445
email: Simon.Fear at synequanon.com
web: http://www.synequanon.com
 
Number of attachments included with this message: 0
 
This message (and any associated files) is confidential and\...{{dropped}}



From ligges at statistik.uni-dortmund.de  Tue Sep 16 17:48:17 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 16 Sep 2003 17:48:17 +0200
Subject: [R] "Old" libraries with new R?
In-Reply-To: <XFMail.030916155416.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.030916155416.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <3F6730C1.1010908@statistik.uni-dortmund.de>

(Ted Harding) wrote:

> Hi Folks,
> 
> I'm currently installing R-1.7.1 off CRAN.
> 
> As it happens, I have a CD (kindly made for me by Linux
> Emporium) containing all the libraries which were on CRAN
> early this year when I installed R-1.6.1. This is highly
> convenient, since the alternative would be several hours
> on-line.
> 
> While a recent library will on installation announce the
> fact should it need a newer version of R than the one which
> is installed, presumably this is not likely to be the case
> for an old library if a newer version of R is incompatible
> with it.
> 
> So is there a way of finding out whether a library dating
> from some time back is compatible with a recent R, other than
> simply trying it out to see if it works OK?
> 
> With thanks, and best wishes to all,
> Ted.
> 
> 

There is a dependency field in a package's DESCRIPTION file. Here the 
package author *might* give information on dependency for a minimal 
required R version. But this is not checked, and the author not always 
knows about dependencies, because he/she is probably developing on 
recent versions.

Uwe Ligges



From Weiming.Zhang at uchsc.edu  Tue Sep 16 17:52:47 2003
From: Weiming.Zhang at uchsc.edu (Weiming Zhang)
Date: Tue, 16 Sep 2003 15:52:47 -0000
Subject: [R] how to print a plot
In-Reply-To: <Pine.LNX.4.44.0309160734080.19291-100000@gannet.stats>
References: <Pine.LNX.4.44.0309160734080.19291-100000@gannet.stats>
Message-ID: <1063727479.26828.12.camel@molecule.uchsc.edu>

Thank you all very much!

I did forget to use dev.off(). Everything works great now.

Many thanks.

Weiming zhang

On Tue, 2003-09-16 at 00:38, Prof Brian Ripley wrote:
> You did use dev.off() to finish the plots before trying to look at them?
> The symptoms you report are what happens if you did not.
> 
> There is no ps() function in R: the postscript device is postscript() not 
> ps().
> 
> If you want to print a plot, try dev.print.  If you want to copy to a 
> file, try dev.copy2eps.  (You are on Linux, where EPS is more widely 
> acceptable than PDF.)
> 
> On 15 Sep 2003, Weiming Zhang wrote:
> 
> > Hi, Thank both of you.
> > 
> > I tried everything. pdf(file="out.pdf") gave me a damaged pdf file. ps()
> > did not print. ps("out.ps") gave me a ps file with badly drawn graph and
> > could not be printed. I am using RH linux 7.2.
> > 
> > Thanks again.
> > 
> > weiming Zhang
> > 
> > 
> > On Mon, 2003-09-15 at 16:06, Jason Turner wrote:
> > > On Tue, 2003-09-16 at 08:56, Weiming Zhang wrote:
> > > > Hi,
> > > > 
> > > > I am using R-1.7.1 on Linux. I integrated XEMACS with R. Could anybody
> > > > tell me how to print a plot? I used plot function to make some graphs
> > > > and then I wanted to print them or to save them to files. But I could
> > > > not find out how to do it.
> > > 
> > > Have you tried:
> > > help(Devices) 
> > > help(pdf)
> > > 
> > > What I do:
> > > 
> > > pdf(file="myplots.pdf")
> > > plot(...)
> > > dev.off()
> > > 
> > > Use Acrobat or gv to view the pdf files.  Postscript is also good, but
> > > not as universally understood; I have many coleagues who work in very
> > > standard Windows environments, where ghostscript is unknown.  PDF is a
> > > very sensible choice for e-mailing graphs.
> > > 
> > > 
> > > -- 
> > > Indigo Industrial Controls Ltd.
> > > http://www.indigoindustrial.co.nz
> > > +64-(0)21-343-545
> > > 
> > > 
> > > 
> > >
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > 
> > 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From yao6889 at msmailhub.oulan.ou.edu  Tue Sep 16 18:09:53 2003
From: yao6889 at msmailhub.oulan.ou.edu (Yao, Minghua)
Date: Tue, 16 Sep 2003 11:09:53 -0500
Subject: [R] Question in Using sink function
Message-ID: <FC0CEBD77311DA499A67ADB355A24FA20396ADBA@mail4.oulan.ou.edu>


Could anyone please explain to me why the following writes nothing into
"all.Rout"
file? If the "for" loop is removed, t.test output can be written into
"all.out".

Thanks in advance. 

Minghua Yao

 ......
  zz <- file("all.Rout", open="wt")
  sink(zz)
   
  for(i in 1:n)
  {	  
    Cy3<-X[,2*i-1];
    Cy5<-X[,2*i];
	
    t.test(Cy3, Cy5)
  }


  sink()
  close(zz)
......



From s195404 at student.uq.edu.au  Tue Sep 16 18:27:29 2003
From: s195404 at student.uq.edu.au (Andrew C. Ward)
Date: Tue, 16 Sep 2003 16:27:29 +0000
Subject: [R] Question in Using sink function
In-Reply-To: <FC0CEBD77311DA499A67ADB355A24FA20396ADBA@mail4.oulan.ou.edu>
References: <FC0CEBD77311DA499A67ADB355A24FA20396ADBA@mail4.oulan.ou.edu>
Message-ID: <1063729649.3f6739f1d9b4f@my.uq.edu.au>

Dear Minghua Yao,

If you throw in a print() or two you'll get some output in
your file. You could try print(t.test(Cy3, Cy5)) or whatever
you actually want.


Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au


Quoting "Yao, Minghua" <yao6889 at msmailhub.oulan.ou.edu>:

> 
> Could anyone please explain to me why the following
> writes nothing into
> "all.Rout"
> file? If the "for" loop is removed, t.test output can be
> written into
> "all.out".
> 
> Thanks in advance. 
> 
> Minghua Yao
> 
>  ......
>   zz <- file("all.Rout", open="wt")
>   sink(zz)
>    
>   for(i in 1:n)
>   {	  
>     Cy3<-X[,2*i-1];
>     Cy5<-X[,2*i];
> 	
>     t.test(Cy3, Cy5)
>   }
> 
> 
>   sink()
>   close(zz)
> ......
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From ripley at stats.ox.ac.uk  Tue Sep 16 18:35:12 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 16 Sep 2003 17:35:12 +0100 (BST)
Subject: [R] Question in Using sink function
In-Reply-To: <FC0CEBD77311DA499A67ADB355A24FA20396ADBA@mail4.oulan.ou.edu>
Message-ID: <Pine.LNX.4.44.0309161730001.1938-100000@gannet.stats>

Autoprinting does not work inside a for() {} loop, and you did not print 
anything.

Try

for(i in 1:10) {i}

Did you try your problem without sink()?

On Tue, 16 Sep 2003, Yao, Minghua wrote:

> 
> Could anyone please explain to me why the following writes nothing into
> "all.Rout"
> file? If the "for" loop is removed, t.test output can be written into
> "all.out".
> 
> Thanks in advance. 
> 
> Minghua Yao
> 
>  ......
>   zz <- file("all.Rout", open="wt")
>   sink(zz)
>    
>   for(i in 1:n)
>   {	  
>     Cy3<-X[,2*i-1];
>     Cy5<-X[,2*i];
> 	
>     t.test(Cy3, Cy5)
>   }
> 
> 
>   sink()
>   close(zz)
> ......
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From yao6889 at msmailhub.oulan.ou.edu  Tue Sep 16 18:31:41 2003
From: yao6889 at msmailhub.oulan.ou.edu (Yao, Minghua)
Date: Tue, 16 Sep 2003 11:31:41 -0500
Subject: [R] Question in Using sink function
Message-ID: <FC0CEBD77311DA499A67ADB355A24FA20396ADBB@mail4.oulan.ou.edu>


Thanks, Prof. Ripley.

Right. I saw nothing, either, when I tried without "for" loop.
Does anywhere in the documents mention that Autoprinting does not work
inside a for() {} loop?

Minghua 

-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
Sent: Tuesday, September 16, 2003 11:35 AM
To: Yao, Minghua
Cc: R Help (E-mail)
Subject: Re: [R] Question in Using sink function


Autoprinting does not work inside a for() {} loop, and you did not print 
anything.

Try

for(i in 1:10) {i}

Did you try your problem without sink()?

On Tue, 16 Sep 2003, Yao, Minghua wrote:

> 
> Could anyone please explain to me why the following writes nothing into
> "all.Rout"
> file? If the "for" loop is removed, t.test output can be written into
> "all.out".
> 
> Thanks in advance. 
> 
> Minghua Yao
> 
>  ......
>   zz <- file("all.Rout", open="wt")
>   sink(zz)
>    
>   for(i in 1:n)
>   {	  
>     Cy3<-X[,2*i-1];
>     Cy5<-X[,2*i];
> 	
>     t.test(Cy3, Cy5)
>   }
> 
> 
>   sink()
>   close(zz)
> ......
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Sep 16 18:40:43 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 16 Sep 2003 17:40:43 +0100 (BST)
Subject: [R] "Old" libraries with new R?
In-Reply-To: <3F6730C1.1010908@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.44.0309161736150.1938-100000@gannet.stats>

On Tue, 16 Sep 2003, Uwe Ligges wrote:

> (Ted Harding) wrote:
> 
> > Hi Folks,
> > 
> > I'm currently installing R-1.7.1 off CRAN.
> > 
> > As it happens, I have a CD (kindly made for me by Linux
> > Emporium) containing all the libraries which were on CRAN
> > early this year when I installed R-1.6.1. This is highly
> > convenient, since the alternative would be several hours
> > on-line.
> > 
> > While a recent library will on installation announce the
> > fact should it need a newer version of R than the one which
> > is installed, presumably this is not likely to be the case
> > for an old library if a newer version of R is incompatible
> > with it.
> > 
> > So is there a way of finding out whether a library dating
> > from some time back is compatible with a recent R, other than
> > simply trying it out to see if it works OK?
> > 
> > With thanks, and best wishes to all,
> > Ted.
> > 
> > 
> 
> There is a dependency field in a package's DESCRIPTION file. Here the 
> package author *might* give information on dependency for a minimal 
> required R version. But this is not checked, and the author not always 
> knows about dependencies, because he/she is probably developing on 
> recent versions.

I think Ted wants the reverse: will an old package source work with
current R?  That would need prescience beyond most package authors to know 
at the time the package was bundled.

The best think to do I believe is to first check if the version you have
is the same as that on CRAN, and if not try R CMD check on the old
package.  (If yes, you could check 
http://cran.r-project.org/src/contrib/checkSummary.html to see if it works 
on the CRAN machines.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From pete at sprint.net  Tue Sep 16 18:44:02 2003
From: pete at sprint.net (Peter Whiting)
Date: Tue, 16 Sep 2003 11:44:02 -0500
Subject: [R] can predict ignore rows with insufficient info
Message-ID: <20030916164402.GA15590@sprint.net>

I need predict to ignore rows that contain levels not in the
model.

Consider a data frame, "const", that has columns for the number of
days required to construct a site and the city and state the site
was constructed in.

g<-lm(days~city,data=const)

Some of the sites in const have not yet been completed, and therefore
they have days==NA. I want to predict how many days these sites
will take to complete (I've simplified the above discussion to
remove many of the other factors involved.)

nconst<-subset(const,is.na(const$days))
x<-predict(g,nconst)
Error in model.frame.default(object, data, xlev = xlev) :
        factor city has new level(s) ALBANY

This is because we haven't yet completed a site in Albany.
If I just had one to worry about I could easily fix it (choose
a nearby market with similar characteristic) but I am dealing
with a several hundred cities. Instead, for the cities not
modeled by g I'd simply like to use the state, even though I
don't expect it to be as good:

g<-lm(days~state,data=const)
x<-predict(g,nconst)

I'm not sure how to identify the cities in nconst that are not
modeled by g (my actual model has many more predictors in the
formula) Is there a way to instruct predict to only predict the
rows for which it has enough information and not complain about
the others?

g<-lm(days~city,data=const)
x<-predict(g,nconst) ## the rows of x with city=ALBANY will be NA
g<-lm(days~state,data=const)
y<-predict(g,nconst)
x[is.na(x)]<-y[is.na(x)]

thanks,
pete



From tblackw at umich.edu  Tue Sep 16 19:08:27 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Tue, 16 Sep 2003 13:08:27 -0400 (EDT)
Subject: [R] help("print") seems truncated
Message-ID: <Pine.SOL.4.58.0309161302470.28414@robotron.gpcc.itd.umich.edu>

Dear r-help  -

I just noticed that in my R-1.7.1 on i386-pc-linux-gnu,
the page displayed by  help("print")  ends with the line

"     ## Printing of factors illustrated for ex"

and then no more.  It looks as though something got truncated
here.  I think this is an R that I compiled from source off of
CRAN, but I can't quite remember.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -



From ripley at stats.ox.ac.uk  Tue Sep 16 19:09:11 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 16 Sep 2003 18:09:11 +0100 (BST)
Subject: [R] Question in Using sink function
In-Reply-To: <FC0CEBD77311DA499A67ADB355A24FA20396ADBB@mail4.oulan.ou.edu>
Message-ID: <Pine.LNX.4.44.0309161803090.2004-100000@gannet.stats>

On Tue, 16 Sep 2003, Yao, Minghua wrote:

> 
> Thanks, Prof. Ripley.
> 
> Right. I saw nothing, either, when I tried without "for" loop.
> Does anywhere in the documents mention that Autoprinting does not work
> inside a for() {} loop?

It is in `An Introduction to R', albeit in a rather sophisticated way,
and of course in all good books on R/S.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tlumley at u.washington.edu  Tue Sep 16 19:33:14 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 16 Sep 2003 10:33:14 -0700 (PDT)
Subject: [R] Question in Using sink function
In-Reply-To: <FC0CEBD77311DA499A67ADB355A24FA20396ADBB@mail4.oulan.ou.edu>
Message-ID: <Pine.A41.4.44.0309161033010.210154-100000@homer06.u.washington.edu>

On Tue, 16 Sep 2003, Yao, Minghua wrote:

>
> Thanks, Prof. Ripley.
>
> Right. I saw nothing, either, when I tried without "for" loop.
> Does anywhere in the documents mention that Autoprinting does not work
> inside a for() {} loop?
>

It's a FAQ.

	-thomas



From ligges at statistik.uni-dortmund.de  Tue Sep 16 19:40:38 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 16 Sep 2003 19:40:38 +0200
Subject: [R] help("print") seems truncated
In-Reply-To: <Pine.SOL.4.58.0309161302470.28414@robotron.gpcc.itd.umich.edu>
References: <Pine.SOL.4.58.0309161302470.28414@robotron.gpcc.itd.umich.edu>
Message-ID: <3F674B16.2070009@statistik.uni-dortmund.de>

Thomas W Blackwell wrote:

> Dear r-help  -
> 
> I just noticed that in my R-1.7.1 on i386-pc-linux-gnu,
> the page displayed by  help("print")  ends with the line
> 
> "     ## Printing of factors illustrated for ex"
> 
> and then no more.  It looks as though something got truncated
> here.  I think this is an R that I compiled from source off of
> CRAN, but I can't quite remember.
> 
> -  tom blackwell  -  u michigan medical school  -  ann arbor  -

It's still in the R-1.8.0 alpha sources from yesterday and has been 
introduced between R-1.5.1 and R-1.6.2. Might be fixed before this 
message come through, hence not as a bug report ...

Uwe Ligges



From hennig at stat.math.ethz.ch  Tue Sep 16 19:53:56 2003
From: hennig at stat.math.ethz.ch (Christian Hennig)
Date: Tue, 16 Sep 2003 19:53:56 +0200 (CEST)
Subject: [R] path analysis
In-Reply-To: <Pine.OSF.4.30.0309151652510.161054-100000@darwin.epbi.cwru.edu>
Message-ID: <Pine.LNX.4.44.0309161953040.1731-100000@florence>

There is a library sem for structural equation models.

Best,
Christian Hennig

On Mon, 15 Sep 2003, Catherine Stein wrote:

> 
> Can anyone help me find a R script that does path analysis with family
> data (like a Beta model)?  A script that takes the variance-covariance
> matrix in as input would be ideal.
> 
> Thanks!  Please email me with any ideas!
> Cathy Stein
> cmstein at cwru.edu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
***********************************************************************
Christian Hennig
Seminar fuer Statistik, ETH-Zentrum (LEO), CH-8092 Zuerich (currently)
and Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at stat.math.ethz.ch, http://stat.ethz.ch/~hennig/
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag-online.de



From pete at sprint.net  Tue Sep 16 21:15:34 2003
From: pete at sprint.net (Peter Whiting)
Date: Tue, 16 Sep 2003 14:15:34 -0500
Subject: [R] can predict ignore rows with insufficient info
In-Reply-To: <20030916164402.GA15590@sprint.net>
References: <20030916164402.GA15590@sprint.net>
Message-ID: <20030916191534.GA16304@sprint.net>

On Tue, Sep 16, 2003 at 11:44:02AM -0500, Peter Whiting wrote:
> 
> I'm not sure how to identify the cities in nconst that are not
> modeled by g (my actual model has many more predictors in the
> formula)

I guess I could use some form of
subset(const,const$city%in%g$xlevels$city) 
over and over again for each factor...

as usual, there has to be a better way.

pete




> Is there a way to instruct predict to only predict the
> rows for which it has enough information and not complain about
> the others?
> 
> g<-lm(days~city,data=const)
> x<-predict(g,nconst) ## the rows of x with city=ALBANY will be NA
> g<-lm(days~state,data=const)
> y<-predict(g,nconst)
> x[is.na(x)]<-y[is.na(x)]
> 
> thanks,
> pete
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From tblackw at umich.edu  Tue Sep 16 22:17:59 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Tue, 16 Sep 2003 16:17:59 -0400 (EDT)
Subject: [R] can predict ignore rows with insufficient info
In-Reply-To: <20030916164402.GA15590@sprint.net>
References: <20030916164402.GA15590@sprint.net>
Message-ID: <Pine.SOL.4.58.0309161540070.28414@robotron.gpcc.itd.umich.edu>

Peter  -

Your subsequent email seems just right.  You have to determine
ahead of time which rows can be estimated.  Here's a strategy,
and possibly some code to implement it.

Let  supported(i,y,d)  be a user-written function which returns
a logical vector indicating rows which should be omitted from
the prediction on account of a non-covered covariate in column i
of data frame d with outcome variable y.  Apply this function to
all columns in your data frame using  lapply().  Then do the "or"
of all the logical vectors by calculating the row sums of the
numeric (0 or 1) equivalents.  Last, convert back to logical,
and subscript your data frame with this in the call to  predict().

Here's some rough code:

supported <- function(i,y,d)  {
   result <- rep(F, dim(d)[1])      # default return value when
   if (is.factor(d[[i]]))           #  d[[i]] is not a factor.
     result <- d[[i]] %in% unique(d[[i]][ !is.na(d[[y]]) ])
   result  }

tmp.1 <- lapply(seq(along=const), supported, "days", const)
tmp.2 <- matrix(unlist(tmp.1[ names(const) != "days" ]), nrow=dim(const)[1])
tmp.3 <- as.logical(as.vector(tmp.2 %*% rep(1, dim(tmp.2)[2])))

x <- predict(g, const[ is.na(const$days) & !tmp.3, ])

This code uses a few arcane maneuvers.  Look at help pages for
the relevant functions to dope out what it is doing.  Particularly
for  lapply(), seq(), rep(), unlist(), unique(), "%*%", "%in%".
(The last two must be quoted in order to see the help).

However, the code might work for you right out of the box !

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Tue, 16 Sep 2003, Peter Whiting wrote:

> I need predict to ignore rows that contain levels not in the
> model.
>
> Consider a data frame, "const", that has columns for the number of
> days required to construct a site and the city and state the site
> was constructed in.
>
> g<-lm(days~city,data=const)
>
> Some of the sites in const have not yet been completed, and therefore
> they have days==NA. I want to predict how many days these sites
> will take to complete (I've simplified the above discussion to
> remove many of the other factors involved.)
>
> nconst<-subset(const,is.na(const$days))
> x<-predict(g,nconst)
> Error in model.frame.default(object, data, xlev = xlev) :
>         factor city has new level(s) ALBANY
>
> This is because we haven't yet completed a site in Albany.
> If I just had one to worry about I could easily fix it (choose
> a nearby market with similar characteristic) but I am dealing
> with a several hundred cities. Instead, for the cities not
> modeled by g I'd simply like to use the state, even though I
> don't expect it to be as good:
>
> g<-lm(days~state,data=const)
> x<-predict(g,nconst)
>
> I'm not sure how to identify the cities in nconst that are not
> modeled by g (my actual model has many more predictors in the
> formula) Is there a way to instruct predict to only predict the
> rows for which it has enough information and not complain about
> the others?
>
> g<-lm(days~city,data=const)
> x<-predict(g,nconst) ## the rows of x with city=ALBANY will be NA
> g<-lm(days~state,data=const)
> y<-predict(g,nconst)
> x[is.na(x)]<-y[is.na(x)]
>
> thanks,
> pete
>



From tblackw at umich.edu  Tue Sep 16 22:31:29 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Tue, 16 Sep 2003 16:31:29 -0400 (EDT)
Subject: [R] can predict ignore rows with insufficient info
In-Reply-To: <Pine.SOL.4.58.0309161540070.28414@robotron.gpcc.itd.umich.edu>
References: <20030916164402.GA15590@sprint.net>
	<Pine.SOL.4.58.0309161540070.28414@robotron.gpcc.itd.umich.edu>
Message-ID: <Pine.SOL.4.58.0309161626540.28414@robotron.gpcc.itd.umich.edu>

Peter  -

Error !!
I forgot a "not" in the third line inside the function supported().
And, my mail editor doesn't balance parentheses, so I don't guarantee
that my code is even syntatically correct.

Corrected and re-named version of function:

unsupported <- function(i,y,d)  {
   result <- rep(F, dim(d)[1])      # default return value when
   if (is.factor(d[[i]]))           #  d[[i]] is not a factor.
     result <- !(d[[i]] %in% unique(d[[i]][ !is.na(d[[y]]) ]))
   result  }

tmp.1 <- lapply(seq(along=const), unsupported, "days", const)
tmp.2 <- matrix(unlist(tmp.1[ names(const) != "days" ]), nrow=dim(const)[1])
tmp.3 <- as.logical(as.vector(tmp.2 %*% rep(1, dim(tmp.2)[2])))

x <- predict(g, const[ is.na(const$days) & !tmp.3, ])

-  tom blackwell  -  u michigan medical school  -  ann arbor  -



From maechler at stat.math.ethz.ch  Tue Sep 16 22:45:24 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 16 Sep 2003 22:45:24 +0200
Subject: [R] Re: Number of R users
Message-ID: <16231.30308.453726.726409@gargle.gargle.HOWL>

I have been asked again about the numbers of R users.
The following is part of my answer, probably of some interest to some.

    >> In preparing some notes, I'd like to give some
    >> approximate baseline estimate of how many people are
    >> using R nowdays.

of course a very interesting question.  It came up on R-help
in June 2000, with a small "heated" debate :
start at   ---> http://www.r-project.org/nocvs/mail/r-help/2000/1493.html
but first, read on.

    >> perhaps the size of the R-help list would be a decent
    >> starting point. Any chance you could give me the
    >> approximate number of users?

Well, as with practical statistics, at first it's trivial, but
if you start thinking it becomes quite "interesting"..
At the moment, 
o  R-help      has	2005 unique e-mail addresses subscribed
o  All R-lists have     2659 for "R-*" alone, i.e. w/o bioconductor
o  ALL R-lists have	3189 unique (all "R-*" lists + "bioconductor"
				     combined, then "uniqued") addresses,

But from the mailman logs, for R-help e.g., this noon,  
	 1023 got r-help directly
	  780 got r-help as digest
which leaves about 200 (~ 10%) who seem to have mail delivery
disabled for some reason {explicitly, by bouncing, delivery
not-disabled but not successful on first try, ..?..} 

Then I also guess (from the address) that some groups deliver
R-help to an `internal mailing list' ((something we pretty
strongly discourage, particularly since it complicates unsubscription)).

Now you should probably read the R-help discussion thread from
two years ago (URL above). Quite interesting.
People's guesses wildly varied then from about 10'000 to 400'000 --
based on about the third of mailing list subscribers.
The multiplication factor `f' in    R_users = f * R-help_readers
was conservatively estimated in the range of 10-20 (rather the latter).
This would lead to a guess of about 50'000 users (with a wildly estimated
[logarithmic] standard error of "factor 2").  I think most would
agree that this would *not* count students who only use R during
their classes. 

(Please before you comment on this, do read the "June 2000" thread ..)

-- 
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From maechler at stat.math.ethz.ch  Tue Sep 16 22:53:12 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 16 Sep 2003 22:53:12 +0200
Subject: [R] path analysis
In-Reply-To: <Pine.LNX.4.44.0309161953040.1731-100000@florence>
References: <Pine.OSF.4.30.0309151652510.161054-100000@darwin.epbi.cwru.edu>
	<Pine.LNX.4.44.0309161953040.1731-100000@florence>
Message-ID: <16231.30776.288764.507879@gargle.gargle.HOWL>

>>>>> "ChrisH" == Christian Hennig <hennig at stat.math.ethz.ch>
>>>>>     on Tue, 16 Sep 2003 19:53:56 +0200 (CEST) writes:

    ChrisH> There is a library sem for structural equation
    ChrisH> models.  Best, Christian Hennig

"package", bitte,  NICHT "library" !!!



From pete at sprint.net  Tue Sep 16 23:09:00 2003
From: pete at sprint.net (Peter Whiting)
Date: Tue, 16 Sep 2003 16:09:00 -0500
Subject: [R] can predict ignore rows with insufficient info
In-Reply-To: <Pine.SOL.4.58.0309161540070.28414@robotron.gpcc.itd.umich.edu>
References: <20030916164402.GA15590@sprint.net>
	<Pine.SOL.4.58.0309161540070.28414@robotron.gpcc.itd.umich.edu>
Message-ID: <20030916210900.GB16661@sprint.net>

On Tue, Sep 16, 2003 at 04:17:59PM -0400, Thomas W Blackwell wrote:
> Peter  -
> 
> Your subsequent email seems just right.  You have to determine
> ahead of time which rows can be estimated.

It seems that predict removes rows with insufficient information
(ie, if I replace "ALBANY" with NA and refactor everything works)
- I wonder why it doesn't exhibit the same behavior when it
encounters a new level - just eliminate the row and go on...

Somewhat related: I had been assuming (incorrectly)
that length(x) would equal length(const$days) after
x<-predict(g,const) - this isn't the case if any of the rows of
const don't contain enough info for the model.  Those rows are
eliminated - I'd have expected them to just be NAs in the result.
I'll go back and look through the documents to see if there is a
straight forward way to convert:

> x
  1   3   4
1.5 1.5 1.5

to
> x
  1  2  3   4  5
1.5 NA 1.5 1.5 NA

slowly learning,
pete





  Here's a strategy,
> and possibly some code to implement it.
> 
> Let  supported(i,y,d)  be a user-written function which returns
> a logical vector indicating rows which should be omitted from
> the prediction on account of a non-covered covariate in column i
> of data frame d with outcome variable y.  Apply this function to
> all columns in your data frame using  lapply().  Then do the "or"
> of all the logical vectors by calculating the row sums of the
> numeric (0 or 1) equivalents.  Last, convert back to logical,
> and subscript your data frame with this in the call to  predict().
> 
> Here's some rough code:
> 
> supported <- function(i,y,d)  {
>    result <- rep(F, dim(d)[1])      # default return value when
>    if (is.factor(d[[i]]))           #  d[[i]] is not a factor.
>      result <- d[[i]] %in% unique(d[[i]][ !is.na(d[[y]]) ])
>    result  }
> 
> tmp.1 <- lapply(seq(along=const), supported, "days", const)
> tmp.2 <- matrix(unlist(tmp.1[ names(const) != "days" ]), nrow=dim(const)[1])
> tmp.3 <- as.logical(as.vector(tmp.2 %*% rep(1, dim(tmp.2)[2])))
> 
> x <- predict(g, const[ is.na(const$days) & !tmp.3, ])
> 
> This code uses a few arcane maneuvers.  Look at help pages for
> the relevant functions to dope out what it is doing.  Particularly
> for  lapply(), seq(), rep(), unlist(), unique(), "%*%", "%in%".
> (The last two must be quoted in order to see the help).
> 
> However, the code might work for you right out of the box !
> 
> -  tom blackwell  -  u michigan medical school  -  ann arbor  -
> 
> On Tue, 16 Sep 2003, Peter Whiting wrote:
> 
> > I need predict to ignore rows that contain levels not in the
> > model.
> >
> > Consider a data frame, "const", that has columns for the number of
> > days required to construct a site and the city and state the site
> > was constructed in.
> >
> > g<-lm(days~city,data=const)
> >
> > Some of the sites in const have not yet been completed, and therefore
> > they have days==NA. I want to predict how many days these sites
> > will take to complete (I've simplified the above discussion to
> > remove many of the other factors involved.)
> >
> > nconst<-subset(const,is.na(const$days))
> > x<-predict(g,nconst)
> > Error in model.frame.default(object, data, xlev = xlev) :
> >         factor city has new level(s) ALBANY
> >
> > This is because we haven't yet completed a site in Albany.
> > If I just had one to worry about I could easily fix it (choose
> > a nearby market with similar characteristic) but I am dealing
> > with a several hundred cities. Instead, for the cities not
> > modeled by g I'd simply like to use the state, even though I
> > don't expect it to be as good:
> >
> > g<-lm(days~state,data=const)
> > x<-predict(g,nconst)
> >
> > I'm not sure how to identify the cities in nconst that are not
> > modeled by g (my actual model has many more predictors in the
> > formula) Is there a way to instruct predict to only predict the
> > rows for which it has enough information and not complain about
> > the others?
> >
> > g<-lm(days~city,data=const)
> > x<-predict(g,nconst) ## the rows of x with city=ALBANY will be NA
> > g<-lm(days~state,data=const)
> > y<-predict(g,nconst)
> > x[is.na(x)]<-y[is.na(x)]
> >
> > thanks,
> > pete
> >



From maechler at stat.math.ethz.ch  Tue Sep 16 23:43:27 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 16 Sep 2003 23:43:27 +0200
Subject: [R] Re: Number of R users
In-Reply-To: <16231.30308.453726.726409@gargle.gargle.HOWL>
References: <16231.30308.453726.726409@gargle.gargle.HOWL>
Message-ID: <16231.33791.174231.93505@gargle.gargle.HOWL>

>>>>> "MM" == Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Tue, 16 Sep 2003 22:45:24 +0200 writes:
			      ^^^^^
			      (too late in the evening !)
	  <..........>

    MM> Well, as with practical statistics, at first it's trivial, but
    MM> if you start thinking it becomes quite "interesting"..
    MM> At the moment, 
    MM> o  R-help      has	2005 unique e-mail addresses subscribed
    MM> o  All R-lists have     2659 for "R-*" alone, i.e. w/o bioconductor
    MM> o  ALL R-lists have	3189 unique (all "R-*" lists + "bioconductor"
    MM> combined, then "uniqued") addresses,

As Jeff Gentry has noted (from the size of bioconductor) this
seems pretty (too!) astonishing.
I have checked, and from the 530 bioconductor subscribers, 112
are on R-help as well.  The bug in the above counting: I got the
last number manually -- with a mistake -- where the 2659 comes
from a reliable perl script.
"3189" must be corrected down to "3055".

(as it says "Never trust a statistic, unless ...." :-)
 okay, definitely getting late today..)

Martin



From rajarshi at presidency.com  Tue Sep 16 23:58:53 2003
From: rajarshi at presidency.com (Rajarshi Guha)
Date: Tue, 16 Sep 2003 21:58:53 -0000
Subject: [R] calculation of the p value in ks.test()
Message-ID: <1063749706.16925.12.camel@ra.chem.psu.edu>

Hi,
  I'm working with the ks.test() function and I have also implemented
the test using Conover as the reference. My D value matches that
produced by R. However to calculate the p value I am using the code
described in Numerical Recipes in C++ (2nd Ed.) pg 631.

The p value produced by the NRC code is generally larger than that
produced by R by a factor of 10. Currently I am not in a position to
download the R source and look at it - lack of space :(

has anybody used the NRC code? The text mentions that it calculates the
sum

Q(L) = 2 \sum^{-\infty}_{j=1} (-1)^(j-1) \exp^{-2 j^2 L^2}

and the value of L is given by

[ sqrt(n) + 0.12 + 0.11 / sqrt(n) ] * D

where n = n1*n2/(n1+n2) .. n1, n2 are lengths of the vectors
and D is the calculated statistic.

Is this the same definition as used in R?

Thanks,

-------------------------------------------------------------------
Rajarshi Guha <rajarshi at presidency.com> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
All great ideas are controversial, or have been at one time.



From tblackw at umich.edu  Tue Sep 16 23:57:39 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Tue, 16 Sep 2003 17:57:39 -0400 (EDT)
Subject: [R] can predict ignore rows with insufficient info
In-Reply-To: <20030916210900.GB16661@sprint.net>
References: <20030916164402.GA15590@sprint.net>
	<Pine.SOL.4.58.0309161540070.28414@robotron.gpcc.itd.umich.edu>
	<20030916210900.GB16661@sprint.net>
Message-ID: <Pine.SOL.4.58.0309161747160.24265@robotron.gpcc.itd.umich.edu>



On Tue, 16 Sep 2003, Peter Whiting wrote:

> It seems that predict removes rows with insufficient information
> (ie, if I replace "ALBANY" with NA and refactor everything works)
> - I wonder why it doesn't exhibit the same behavior when it
> encounters a new level - just eliminate the row and go on...
>
> Somewhat related: I had been assuming (incorrectly)
> that length(x) would equal length(const$days) after
> x<-predict(g,const) - this isn't the case if any of the rows of
> const don't contain enough info for the model.  Those rows are
> eliminated - I'd have expected them to just be NAs in the result.
> I'll go back and look through the documents to see if there is a
> straight forward way to convert:
>
> > x
>   1   3   4
> 1.5 1.5 1.5
>
> to
> > x
>   1  2  3   4  5
> 1.5 NA 1.5 1.5 NA
>
> slowly learning,
> pete

Before running  predict(...),  do  options(na.action="na.exclude").
this will give the equal length behavior that you may want ... as
long as you have replaced unsupported factor levels with NA.  See
help("na.omit")  and  help("options")  to see what this is doing.
(It won't have any effect of course, if you subscript the newdata
argument to predict() using my strategy.)

And, DO use a simple strategy that you cooked up yourself, in
preference to anything canned.  It's much easier to maintain.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -



From pete at sprint.net  Wed Sep 17 00:54:56 2003
From: pete at sprint.net (Peter Whiting)
Date: Tue, 16 Sep 2003 17:54:56 -0500
Subject: [R] can predict ignore rows with insufficient info
In-Reply-To: <Pine.SOL.4.58.0309161626540.28414@robotron.gpcc.itd.umich.edu>
References: <20030916164402.GA15590@sprint.net>
	<Pine.SOL.4.58.0309161540070.28414@robotron.gpcc.itd.umich.edu>
	<Pine.SOL.4.58.0309161626540.28414@robotron.gpcc.itd.umich.edu>
Message-ID: <20030916225456.GB17414@sprint.net>

On Tue, Sep 16, 2003 at 04:31:29PM -0400, Thomas W Blackwell wrote:
> Peter  -
> 
> Error !!
> I forgot a "not" in the third line inside the function supported().
> And, my mail editor doesn't balance parentheses, so I don't guarantee
> that my code is even syntatically correct.
> 
> Corrected and re-named version of function:
> 
> unsupported <- function(i,y,d)  {
>    result <- rep(F, dim(d)[1])      # default return value when
>    if (is.factor(d[[i]]))           #  d[[i]] is not a factor.
>      result <- !(d[[i]] %in% unique(d[[i]][ !is.na(d[[y]]) ]))
>    result  }
> 
> tmp.1 <- lapply(seq(along=const), unsupported, "days", const)
> tmp.2 <- matrix(unlist(tmp.1[ names(const) != "days" ]), nrow=dim(const)[1])
> tmp.3 <- as.logical(as.vector(tmp.2 %*% rep(1, dim(tmp.2)[2])))
> 
> x <- predict(g, const[ is.na(const$days) & !tmp.3, ])

this still suffers from the fact that the factor for city
still has "ALBANY" in it (even though it doesn't occur in the
subset).  It can be fixed by creating yet another tmp variable
and refactoring... Kinda painful with multiple predictors in
addition to city, but it is workable. 

> const
  state city days
1    s1   c1    1
2    s1   c1   NA
3    s2   c2    1
4    s2   c2    1
5    s1   c3   NA
> tmp.1 <- lapply(seq(along=const), unsupported, "days", const)
> tmp.2 <- matrix(unlist(tmp.1[ names(const) != "days" ]), nrow=dim(const)[1])
> tmp.3 <- as.logical(as.vector(tmp.2 %*% rep(1, dim(tmp.2)[2])))
> x <- predict(g, const[ is.na(const$days) & !tmp.3, ])
Error in model.frame.default(object, data, xlev = xlev) :
        factor city has new level(s) c3
> tmp.4 <- subset(const,is.na(const$days) & !tmp.3)
> x <- predict(g, tmp.4)
Error in model.frame.default(object, data, xlev = xlev) :
        factor city has new level(s) c3
> tmp.4$city=factor(tmp.4$city)
> x <- predict(g, tmp.4)
> 

pete



From pete at sprint.net  Wed Sep 17 01:48:24 2003
From: pete at sprint.net (Peter Whiting)
Date: Tue, 16 Sep 2003 18:48:24 -0500
Subject: [R] can predict ignore rows with insufficient info
In-Reply-To: <Pine.SOL.4.58.0309161626540.28414@robotron.gpcc.itd.umich.edu>
References: <20030916164402.GA15590@sprint.net>
	<Pine.SOL.4.58.0309161540070.28414@robotron.gpcc.itd.umich.edu>
	<Pine.SOL.4.58.0309161626540.28414@robotron.gpcc.itd.umich.edu>
Message-ID: <20030916234824.GA18385@sprint.net>

On Tue, Sep 16, 2003 at 04:31:29PM -0400, Thomas W Blackwell wrote:
> Corrected and re-named version of function:
> 
> unsupported <- function(i,y,d)  {
>    result <- rep(F, dim(d)[1])      # default return value when
>    if (is.factor(d[[i]]))           #  d[[i]] is not a factor.
>      result <- !(d[[i]] %in% unique(d[[i]][ !is.na(d[[y]]) ]))
>    result  }
> 
> tmp.1 <- lapply(seq(along=const), unsupported, "days", const)
> tmp.2 <- matrix(unlist(tmp.1[ names(const) != "days" ]), nrow=dim(const)[1])
> tmp.3 <- as.logical(as.vector(tmp.2 %*% rep(1, dim(tmp.2)[2])))
> 
> x <- predict(g, const[ is.na(const$days) & !tmp.3, ])

Here is an approach I came up with that appears to work:

predict2 <- function(g,data,...)  
{
  for(nm in names(g$xlevels)) { 
    cat(paste(nm,"\n"))
    data[[nm]]<- factor(data[[nm]],levels=g$xlevels[[nm]])
  }
  predict(g,data,...)
}

It bases its operation on refactoring each predictor using the
factor's "levels=" argument. Any element having a level not in
g$xlevels ends up as an NA, which predict correctly handles.

I'm not sure why predict doesn't do something like this by
default, but I am just a newbee.

pete



From maj at stats.waikato.ac.nz  Wed Sep 17 04:17:00 2003
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Wed, 17 Sep 2003 14:17:00 +1200
Subject: [R] Quit asking me if I want to save the workspace!
Message-ID: <3F67C41C.4080209@stats.waikato.ac.nz>

How do you stop R from putting up a dialog box when you quit Rgui?
(I use Windows and I never save workspaces that way)

Murray
-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From ririzarr at jhsph.edu  Wed Sep 17 04:23:21 2003
From: ririzarr at jhsph.edu (Rafael A. Irizarry)
Date: Tue, 16 Sep 2003 22:23:21 -0400 (EDT)
Subject: [R] Quit asking me if I want to save the workspace!
In-Reply-To: <3F67C41C.4080209@stats.waikato.ac.nz>
Message-ID: <Pine.GSO.4.10.10309162222370.24939-100000@athena.biostat.jhsph.edu>

you can type this:

q("no")

see the help file for q


On Wed, 17 Sep 2003, Murray Jorgensen wrote:

> How do you stop R from putting up a dialog box when you quit Rgui?
> (I use Windows and I never save workspaces that way)
> 
> Murray
> -- 
> Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
> Department of Statistics, University of Waikato, Hamilton, New Zealand
> Email: maj at waikato.ac.nz                                Fax 7 838 4155
> Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From maj at stats.waikato.ac.nz  Wed Sep 17 04:26:44 2003
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Wed, 17 Sep 2003 14:26:44 +1200
Subject: [R] Quit asking me if I want to save the workspace!
In-Reply-To: <Pine.GSO.4.10.10309162222370.24939-100000@athena.biostat.jhsph.edu>
References: <Pine.GSO.4.10.10309162222370.24939-100000@athena.biostat.jhsph.edu>
Message-ID: <3F67C664.8050109@stats.waikato.ac.nz>

Rafael A. Irizarry wrote:
> you can type this:
> 
> q("no")
> 
> see the help file for q

Still more work than two mouse clicks.

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From spencer.graves at pdf.com  Wed Sep 17 04:54:22 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 16 Sep 2003 19:54:22 -0700
Subject: [R] Quit asking me if I want to save the workspace!
In-Reply-To: <Pine.GSO.4.10.10309162222370.24939-100000@athena.biostat.jhsph.edu>
References: <Pine.GSO.4.10.10309162222370.24939-100000@athena.biostat.jhsph.edu>
Message-ID: <3F67CCDE.3080901@pdf.com>

Consider

Q <- function(x)q("no")

With R 1.7.1 under Windows, "Q()" caused R to close without asking for 
confirmation.  This does not solve the whole problem, but it might 
provide a piece of the puzzle. 

hope this helps.  spencer graves

Rafael A. Irizarry wrote:

>you can type this:
>
>q("no")
>
>see the help file for q
>
>
>On Wed, 17 Sep 2003, Murray Jorgensen wrote:
>
>  
>
>>How do you stop R from putting up a dialog box when you quit Rgui?
>>(I use Windows and I never save workspaces that way)
>>
>>Murray
>>-- 
>>Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
>>Department of Statistics, University of Waikato, Hamilton, New Zealand
>>Email: maj at waikato.ac.nz                                Fax 7 838 4155
>>Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
>>    
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From deepayan at stat.wisc.edu  Wed Sep 17 04:52:54 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 16 Sep 2003 21:52:54 -0500
Subject: [R] Quit asking me if I want to save the workspace!
In-Reply-To: <3F67C664.8050109@stats.waikato.ac.nz>
References: <Pine.GSO.4.10.10309162222370.24939-100000@athena.biostat.jhsph.edu>
	<3F67C664.8050109@stats.waikato.ac.nz>
Message-ID: <200309162152.54283.deepayan@stat.wisc.edu>

On Tuesday 16 September 2003 21:26, Murray Jorgensen wrote:
> Rafael A. Irizarry wrote:
> > you can type this:
> >
> > q("no")
> >
> > see the help file for q
>
> Still more work than two mouse clicks.

Start R with --no-save (not sure how/whether this will work on Windows).



From franklin at polisci.wisc.edu  Wed Sep 17 05:00:10 2003
From: franklin at polisci.wisc.edu (Charles H. Franklin)
Date: Tue, 16 Sep 2003 22:00:10 -0500
Subject: [R] Date on x-axis of xyplot
Message-ID: <PDEMINECFJGAIJGDGKGOIEHNEGAA.franklin@polisci.wisc.edu>

xyplot doesn't seem to want to label my x-axis with dates but instead puts
the day-number for each date.

begdate is the number of days since January 1, 1960 and was initially
created by

library(date)

...

polls$begdate<-mdy.date(begmm,begdd,begyy)

I create a new dataframe (pollstack) which includes begdate. In the process
begdate seems to lose its date attribute so I redo it as:

> pollstack$begdate<-as.date(pollstack$begdate)

after which

> attach(pollstack)
> summary(pollstack)
   begdate               pct              names
 First :15Nov2002   Min.   : 0.000   Clark   : 54
 Last  :10Sep2003   1st Qu.: 2.000   Dean    : 54
                    Median : 5.000   Edwards : 54
                    Mean   : 6.991   Gephardt: 54
                    3rd Qu.:12.000   Graham  : 54
                    Max.   :29.000   Kerry   : 54
                                     (Other) :216
>

And all seems well.

But xyplot continues to use day number on the x-axis. My plots are created
by

 print(xyplot(pct ~ begdate | names, pch=2, cex=.2,
   prepanel = function(x, y) prepanel.loess(x, y, span = 1),
   main="2004 Democratic Primary Race",
   xlab = "Date of Survey",
   ylab = "Percent Support",
   panel = function(x, y) {
       panel.grid(h=-1, v= -1)
       panel.xyplot(x, y, pch=1,col=2,cex=.7)
       panel.loess(x,y, span=.65, lwd=2,col=4)
      }, ) )

What am I missing?

Thanks!

Charles



/******************************************
** Charles H. Franklin
** Professor, Political Science
** University of Wisconsin, Madison
** 1050 Bascom Mall
** Madison, WI 53706
** 608-263-2022 Office
** 608-265-2663 Fax
** mailto:franklin at polisci.wisc.edu (best)
** mailto:chfrankl at facstaff.wisc.edu (alt)
** http://www.polisci.wisc.edu/~franklin
******************************************/



From jasont at indigoindustrial.co.nz  Wed Sep 17 05:01:04 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Wed, 17 Sep 2003 03:01:04 -0000
Subject: [R] Quit asking me if I want to save the workspace!
In-Reply-To: <3F67C664.8050109@stats.waikato.ac.nz>
References: <Pine.GSO.4.10.10309162222370.24939-100000@athena.biostat.jhsph.edu>
	<3F67C664.8050109@stats.waikato.ac.nz>
Message-ID: <1063768161.22655.10.camel@kryten.indigoindustrial.co.nz>

On Wed, 2003-09-17 at 14:26, Murray Jorgensen wrote:
> Rafael A. Irizarry wrote:
> > you can type this:
> > 
> > q("no")
> > 
> > see the help file for q
> 
> Still more work than two mouse clicks.

Two clicks!  How awful!   ;)

Actually, it bugs me too, so my desktop shortcut (under Win XP) has this
for "Target".
###
"C:\Program Files\R\rw1071\bin\Rgui.exe" --no-save
###
 
(my mail client might've line-wrapped that by the time you see it. 
Everything between the ### marks is one line.  *Include* the quotes. 
There is a space between Rgui.exe" and --no-save)

See Appendix B of "An Introduction to R" if you need more info.

Hope that helps.

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
+64-(0)21-343-545



From maj at stats.waikato.ac.nz  Wed Sep 17 05:15:12 2003
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Wed, 17 Sep 2003 15:15:12 +1200
Subject: [R] Quit asking me if I want to save the workspace!
In-Reply-To: <1063768161.22655.10.camel@kryten.indigoindustrial.co.nz>
References: <Pine.GSO.4.10.10309162222370.24939-100000@athena.biostat.jhsph.edu>	
	<3F67C664.8050109@stats.waikato.ac.nz>
	<1063768161.22655.10.camel@kryten.indigoindustrial.co.nz>
Message-ID: <3F67D1C0.5080400@stats.waikato.ac.nz>

Ah! now that tells me what I want to know. I was trying to type

"C:\Program Files\R\rw1071\bin\Rgui.exe --no-save"

instead of

"C:\Program Files\R\rw1071\bin\Rgui.exe" --no-save

into the "Target" box.  Silly me!

Jason Turner wrote:

> On Wed, 2003-09-17 at 14:26, Murray Jorgensen wrote:
> 
>>Rafael A. Irizarry wrote:
>>
>>>you can type this:
>>>
>>>q("no")
>>>
>>>see the help file for q
>>
>>Still more work than two mouse clicks.
> 
> 
> Two clicks!  How awful!   ;)
> 
> Actually, it bugs me too, so my desktop shortcut (under Win XP) has this
> for "Target".
> ###
> "C:\Program Files\R\rw1071\bin\Rgui.exe" --no-save
> ###
>  
> (my mail client might've line-wrapped that by the time you see it. 
> Everything between the ### marks is one line.  *Include* the quotes. 
> There is a space between Rgui.exe" and --no-save)
> 
> See Appendix B of "An Introduction to R" if you need more info.
> 
> Hope that helps.
> 
> Jason

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From TyagiAnupam at aol.com  Wed Sep 17 05:27:32 2003
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Tue, 16 Sep 2003 23:27:32 EDT
Subject: [R] Quit asking me if I want to save the workspace!
Message-ID: <17e.20386eab.2c992ea4@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030916/31c560a1/attachment.pl

From nathoo at cs.sfu.ca  Wed Sep 17 06:13:44 2003
From: nathoo at cs.sfu.ca (Farouk Nathoo)
Date: Tue, 16 Sep 2003 21:13:44 -0700 (PDT)
Subject: [R] Help with glmmML package 
Message-ID: <Pine.GSO.4.10.10309162112560.15122-100000@stawlmihq>

Dear R users,

I have been using the package glmmML to fit a logistic-normal mixed model
to clustered binary data. Along with parameter estimates I would also like
to obtain estimates of the random effects. I have noticed that a fitted
"glmmML" object contains a component called "frail", a vector, which looks
to be an estimate of the random effects. Can anyone confirm this? And if
so, how are these estimates obtained from the fitted model? Are they the
empirical Bayes estimates? Any reference would also be great.

Thanks very much for your help.

Farouk



From deepayan at stat.wisc.edu  Wed Sep 17 06:31:06 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 16 Sep 2003 23:31:06 -0500
Subject: [R] Date on x-axis of xyplot
In-Reply-To: <PDEMINECFJGAIJGDGKGOIEHNEGAA.franklin@polisci.wisc.edu>
References: <PDEMINECFJGAIJGDGKGOIEHNEGAA.franklin@polisci.wisc.edu>
Message-ID: <200309162331.06832.deepayan@stat.wisc.edu>

On Tuesday 16 September 2003 22:00, Charles H. Franklin wrote:
> xyplot doesn't seem to want to label my x-axis with dates but instead puts
> the day-number for each date.
>
> begdate is the number of days since January 1, 1960 and was initially
> created by
>
> library(date)
>
> ...
>
> polls$begdate<-mdy.date(begmm,begdd,begyy)
>
> I create a new dataframe (pollstack) which includes begdate. In the process
>
> begdate seems to lose its date attribute so I redo it as:
> > pollstack$begdate<-as.date(pollstack$begdate)
>
> after which
>
> > attach(pollstack)
> > summary(pollstack)
>
>    begdate               pct              names
>  First :15Nov2002   Min.   : 0.000   Clark   : 54
>  Last  :10Sep2003   1st Qu.: 2.000   Dean    : 54
>                     Median : 5.000   Edwards : 54
>                     Mean   : 6.991   Gephardt: 54
>                     3rd Qu.:12.000   Graham  : 54
>                     Max.   :29.000   Kerry   : 54
>                                      (Other) :216
>
>
> And all seems well.
>
> But xyplot continues to use day number on the x-axis. My plots are created
> by
>
>  print(xyplot(pct ~ begdate | names, pch=2, cex=.2,
>    prepanel = function(x, y) prepanel.loess(x, y, span = 1),
>    main="2004 Democratic Primary Race",
>    xlab = "Date of Survey",
>    ylab = "Percent Support",
>    panel = function(x, y) {
>        panel.grid(h=-1, v= -1)
>        panel.xyplot(x, y, pch=1,col=2,cex=.7)
>        panel.loess(x,y, span=.65, lwd=2,col=4)
>       }, ) )
>
> What am I missing?

The fact that xyplot doesn't know anything about the "date" class. I'm not 
familiar with the date package, but the docs and a few experiments seem to 
indicate that an object of class "date" is simply a numeric/integer vector 
with the class attribute set to "date". xyplot interprets it as plain numeric 
data.

You may be able to get what you want by 

print(xyplot(pct ~ factor(as.character(begdate)) | names, pch=2, cex=.2,
      prepanel = function(x, y) prepanel.loess(x, y, span = 1),
      ...


(but this will try to label all unique dates, which may not be good).


Is the date class standard enough to warrant including a check for it in 
lattice ?

Deepayan



From jasont at indigoindustrial.co.nz  Wed Sep 17 06:42:42 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Wed, 17 Sep 2003 04:42:42 -0000
Subject: [R] Date on x-axis of xyplot
In-Reply-To: <200309162331.06832.deepayan@stat.wisc.edu>
References: <PDEMINECFJGAIJGDGKGOIEHNEGAA.franklin@polisci.wisc.edu>
	<200309162331.06832.deepayan@stat.wisc.edu>
Message-ID: <1063774261.23711.11.camel@kryten.indigoindustrial.co.nz>

On Wed, 2003-09-17 at 16:31, Deepayan Sarkar wrote:
...
> Is the date class standard enough to warrant including a check for it in 
> lattice ?
> 

I've never used it myself, but the lack of POSIXct support in the
lattice graphics axes has often caused me to think up new ways around
the plot.  Unless I'm missing an obvious way to apply that...

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
+64-(0)21-343-545



From franklin at polisci.wisc.edu  Wed Sep 17 06:43:59 2003
From: franklin at polisci.wisc.edu (Charles H. Franklin)
Date: Tue, 16 Sep 2003 23:43:59 -0500
Subject: [R] Date on x-axis of xyplot
In-Reply-To: <200309162331.06832.deepayan@stat.wisc.edu>
Message-ID: <PDEMINECFJGAIJGDGKGOKEIBEGAA.franklin@polisci.wisc.edu>

>On Tuesday 16 September 2003 22:00, Charles H. Franklin wrote:
>> xyplot doesn't seem to want to label my x-axis with dates but instead
puts
>> the day-number for each date.
>>
>>...
>>
>> What am I missing?


Deepayan Sarkar replies:

>The fact that xyplot doesn't know anything about the "date" class. I'm not
>familiar with the date package, but the docs and a few experiments seem to
>indicate that an object of class "date" is simply a numeric/integer vector
>with the class attribute set to "date". xyplot interprets it as plain
numeric
>data.
>
>You may be able to get what you want by
>
>print(xyplot(pct ~ factor(as.character(begdate)) | names, pch=2, cex=.2,
>      prepanel = function(x, y) prepanel.loess(x, y, span = 1),
>      ...
>
>
>(but this will try to label all unique dates, which may not be good).
>
>
>Is the date class standard enough to warrant including a check for it in
>lattice ?
>
>Deepayan


OK. I was afraid of that.

I'm not sure how standard the date class is. Or if there is an alternative
that is better. But I DO think that being able to label dates in some way on
the x-axis would be a common enough problem to be worth solving. This is
especially an issue when data are irregularly spaced and so time series
plots are not appropriate. As it stands, my graphs are labeled 15650 to
15950, which is surely not intuitive to anyone!

Many thanks to Deepayan for the Lattice package and his support of it. It is
so great that I just want one more thing...!

Charles



From deepayan at stat.wisc.edu  Wed Sep 17 07:29:48 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Wed, 17 Sep 2003 00:29:48 -0500
Subject: [R] Date on x-axis of xyplot
In-Reply-To: <1063774261.23711.11.camel@kryten.indigoindustrial.co.nz>
References: <PDEMINECFJGAIJGDGKGOIEHNEGAA.franklin@polisci.wisc.edu>
	<200309162331.06832.deepayan@stat.wisc.edu>
	<1063774261.23711.11.camel@kryten.indigoindustrial.co.nz>
Message-ID: <200309170029.48934.deepayan@stat.wisc.edu>

On Tuesday 16 September 2003 23:51, Jason Turner wrote:
> On Wed, 2003-09-17 at 16:31, Deepayan Sarkar wrote:
> ...
>
> > Is the date class standard enough to warrant including a check for it in
> > lattice ?
>
> I've never used it myself, but the lack of POSIXct support in the
> lattice graphics axes has often caused me to think up new ways around
> the plot.  Unless I'm missing an obvious way to apply that...

Actually, lattice does support POSIXct for some time now, although the quality 
of that support (in terms of control over tick locations and labels) is not 
very good. But it might not be too difficult to add support for "date" 
objects as well. 

Deepayan



From ok at cs.otago.ac.nz  Wed Sep 17 07:58:00 2003
From: ok at cs.otago.ac.nz (Richard A. O'Keefe)
Date: Wed, 17 Sep 2003 17:58:00 +1200 (NZST)
Subject: [R] Retrieve ... argument values
Message-ID: <200309170558.h8H5w0LK458637@atlas.otago.ac.nz>

Ben Bolker <bolker at zoo.ufl.edu> wrote:
	  Yes, although this becomes tedious if (e.g.) you have a function that 
	calls two different functions, each of which has many arguments (e.g. 
	plot() and barplot(); then you have to set up a whole lot of arguments 
	that default to NULL and, more annoyingly, you have to document them all 
	in any .Rd file you create -- rather than just having a ... argument which 
	you can say should contain arguments for either of the subfunctions (as 
	long as the arguments don't overlap, of course)
	
Could I suggest a very simple alternative, which extends gracefully to
any number of arguments, and doesn't require you to know anything much
about ... except that you can pass it to another function?

> f <- function(...) {
+     has.ylim <- function(..., ylim) return(!missing(ylim))
+   
+     if (has.ylim(...)) "yes" else "no"
+ } 
> f(xlim=1)
[1] "no"
> f(ylim=2)
[1] "yes"

For each parameter XXX that you want to test the presence of, write
    has.XXX <- function(..., XXX) return(!missing(XXX))
and then use
    has.XXX(...)
in the body of the main function.



From ripley at stats.ox.ac.uk  Wed Sep 17 07:58:48 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 17 Sep 2003 06:58:48 +0100 (BST)
Subject: [R] Date on x-axis of xyplot
In-Reply-To: <200309162331.06832.deepayan@stat.wisc.edu>
Message-ID: <Pine.LNX.4.44.0309170655470.2844-100000@gannet.stats>

On Tue, 16 Sep 2003, Deepayan Sarkar wrote:

> Is the date class standard enough to warrant including a check for it in 
> lattice ?

I don't think so.  The POSIX*t classes in R are the most standard, 
followed by the chron package and only then the date package.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jasont at indigoindustrial.co.nz  Wed Sep 17 08:02:12 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Wed, 17 Sep 2003 06:02:12 -0000
Subject: [R] Date on x-axis of xyplot
In-Reply-To: <200309170029.48934.deepayan@stat.wisc.edu>
References: <PDEMINECFJGAIJGDGKGOIEHNEGAA.franklin@polisci.wisc.edu>
	<200309162331.06832.deepayan@stat.wisc.edu>
	<1063774261.23711.11.camel@kryten.indigoindustrial.co.nz>
	<200309170029.48934.deepayan@stat.wisc.edu>
Message-ID: <1063779028.24576.14.camel@kryten.indigoindustrial.co.nz>

On Wed, 2003-09-17 at 17:29, Deepayan Sarkar wrote:
> On Tuesday 16 September 2003 23:51, Jason Turner wrote:
> > ... the lack of POSIXct support in the
> > lattice graphics axes has often caused me to think up new ways around
> > the plot.  Unless I'm missing an obvious way to apply that...
> 
> Actually, lattice does support POSIXct for some time now, 

My bad.  Will check this further.

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
+64-(0)21-343-545



From ripley at stats.ox.ac.uk  Wed Sep 17 08:29:12 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 17 Sep 2003 07:29:12 +0100 (BST)
Subject: [R] can predict ignore rows with insufficient info
In-Reply-To: <20030916210900.GB16661@sprint.net>
Message-ID: <Pine.LNX.4.44.0309170727030.2924-100000@gannet.stats>

On Tue, 16 Sep 2003, Peter Whiting wrote:

> On Tue, Sep 16, 2003 at 04:17:59PM -0400, Thomas W Blackwell wrote:
> > Peter  -
> > 
> > Your subsequent email seems just right.  You have to determine
> > ahead of time which rows can be estimated.
> 
> It seems that predict removes rows with insufficient information
> (ie, if I replace "ALBANY" with NA and refactor everything works)
> - I wonder why it doesn't exhibit the same behavior when it
> encounters a new level - just eliminate the row and go on...
> 
> Somewhat related: I had been assuming (incorrectly)
> that length(x) would equal length(const$days) after
> x<-predict(g,const) - this isn't the case if any of the rows of
> const don't contain enough info for the model.  Those rows are
> eliminated - I'd have expected them to just be NAs in the result.

That depends on the setting of option na.action: the factory-fresh default 
is na.omit, which is what you are seeing.  As from R 1.8.0 it will use a 
default of na.pass for predict.lm.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Wed Sep 17 08:24:22 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 17 Sep 2003 07:24:22 +0100 (BST)
Subject: [R] can predict ignore rows with insufficient info
In-Reply-To: <20030916234824.GA18385@sprint.net>
Message-ID: <Pine.LNX.4.44.0309170717340.2924-100000@gannet.stats>

On Tue, 16 Sep 2003, Peter Whiting wrote:

> On Tue, Sep 16, 2003 at 04:31:29PM -0400, Thomas W Blackwell wrote:
> > Corrected and re-named version of function:
> > 
> > unsupported <- function(i,y,d)  {
> >    result <- rep(F, dim(d)[1])      # default return value when
> >    if (is.factor(d[[i]]))           #  d[[i]] is not a factor.
> >      result <- !(d[[i]] %in% unique(d[[i]][ !is.na(d[[y]]) ]))
> >    result  }
> > 
> > tmp.1 <- lapply(seq(along=const), unsupported, "days", const)
> > tmp.2 <- matrix(unlist(tmp.1[ names(const) != "days" ]), nrow=dim(const)[1])
> > tmp.3 <- as.logical(as.vector(tmp.2 %*% rep(1, dim(tmp.2)[2])))
> > 
> > x <- predict(g, const[ is.na(const$days) & !tmp.3, ])
> 
> Here is an approach I came up with that appears to work:

(One I sent privately to Peter.)

> predict2 <- function(g,data,...)  
> {
>   for(nm in names(g$xlevels)) { 
>     cat(paste(nm,"\n"))
>     data[[nm]]<- factor(data[[nm]],levels=g$xlevels[[nm]])
>   }
>   predict(g,data,...)
> }
> 
> It bases its operation on refactoring each predictor using the
> factor's "levels=" argument. Any element having a level not in
> g$xlevels ends up as an NA, which predict correctly handles.
> 
> I'm not sure why predict doesn't do something like this by
> default, but I am just a newbee.

Because it is thought more common for additional levels to be a mistake 
that the user would want to be alerted to.  Note also that here you are
talking about the "lm" method of predict(), and by no means all methods do 
handle NAs in the model matrix (and for those that do it is rather 
recent).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From maechler at stat.math.ethz.ch  Wed Sep 17 08:36:19 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 17 Sep 2003 08:36:19 +0200
Subject: [R] Quiz {was "Quit asking me .."}
In-Reply-To: <3F67CCDE.3080901@pdf.com>
References: <Pine.GSO.4.10.10309162222370.24939-100000@athena.biostat.jhsph.edu>
	<3F67CCDE.3080901@pdf.com>
Message-ID: <16232.227.360586.936442@gargle.gargle.HOWL>

>>>>> "Spencer" == Spencer Graves <spencer.graves at pdf.com>
>>>>>     on Tue, 16 Sep 2003 19:54:22 -0700 writes:

    Spencer> Consider
    Spencer>  Q <- function(x)q("no")

    Spencer> With R 1.7.1 under Windows, "Q()" caused R to close
    Spencer> without asking for confirmation.  This does not
    Spencer> solve the whole problem, but it might provide a
    Spencer> piece of the puzzle.

Apropos, this reminds me of the old quiz (from the S-plus times):

How can you write (quite short!) R code such that
typing
	"Q"   

-- without any  "()" -- will quit R (without asking about saving).

[But you shouldn't really keep that code active in your standard R session
 because it would be too easy to accidentally shut down R !]

For the advanced ones: 
My shortest solution uses 51 characters of R code, can you beat that?

-- 
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From ligges at statistik.uni-dortmund.de  Wed Sep 17 08:58:39 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 17 Sep 2003 08:58:39 +0200
Subject: [R] calculation of the p value in ks.test()
In-Reply-To: <1063749706.16925.12.camel@ra.chem.psu.edu>
References: <1063749706.16925.12.camel@ra.chem.psu.edu>
Message-ID: <3F68061F.6000704@statistik.uni-dortmund.de>

Rajarshi Guha wrote:

> Hi,
>   I'm working with the ks.test() function and I have also implemented
> the test using Conover as the reference. My D value matches that
> produced by R. However to calculate the p value I am using the code
> described in Numerical Recipes in C++ (2nd Ed.) pg 631.
> 
> The p value produced by the NRC code is generally larger than that
> produced by R by a factor of 10. Currently I am not in a position to
> download the R source and look at it - lack of space :(

Cannot believe: Lack of *_space_*???


> has anybody used the NRC code? The text mentions that it calculates the
> sum
> 
> Q(L) = 2 \sum^{-\infty}_{j=1} (-1)^(j-1) \exp^{-2 j^2 L^2}
> 
> and the value of L is given by
> 
> [ sqrt(n) + 0.12 + 0.11 / sqrt(n) ] * D
> 
> where n = n1*n2/(n1+n2) .. n1, n2 are lengths of the vectors
> and D is the calculated statistic.
> 
> Is this the same definition as used in R?


No. Since you have a working copy of R (obviously a binary version?), 
you only need the file ks.c. If that 3kB file won't flood your harddisk, 
I'll send it in a private message.

Uwe Ligges



From maechler at stat.math.ethz.ch  Wed Sep 17 09:03:42 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 17 Sep 2003 09:03:42 +0200
Subject: [R] Using POSIX?t rather than "chron" or "date" 
In-Reply-To: <Pine.LNX.4.44.0309170655470.2844-100000@gannet.stats>
References: <200309162331.06832.deepayan@stat.wisc.edu>
	<Pine.LNX.4.44.0309170655470.2844-100000@gannet.stats>
Message-ID: <16232.1870.806378.52010@gargle.gargle.HOWL>

>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>     on Wed, 17 Sep 2003 06:58:48 +0100 (BST) writes:

    BDR> On Tue, 16 Sep 2003, Deepayan Sarkar wrote:
    >> Is the date class standard enough to warrant including a
    >> check for it in lattice ?

    BDR> I don't think so.  The POSIX*t classes in R are the
    BDR> most standard, followed by the chron package and only
    BDR> then the date package.

Definitely.  And I think we should encourage people to
upgrade to POSIX.t from "chron" (let alone "date") more
strongly {Note that there have been  as.POSIXct() methods for
these classes since the beginning of the POSIX.t classes.

Could "chron" and "date" users be heard about what
functionality they are missing in POSIX.t ?

On the other hand, the recommended package "survival" has
a(nother?) class "date" and that package is based on S(plus) code
and may hence not be convertible sensibly ?

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From ligges at statistik.uni-dortmund.de  Wed Sep 17 09:16:00 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 17 Sep 2003 09:16:00 +0200
Subject: [R] Quiz {was "Quit asking me .."}
In-Reply-To: <16232.227.360586.936442@gargle.gargle.HOWL>
References: <Pine.GSO.4.10.10309162222370.24939-100000@athena.biostat.jhsph.edu>	<3F67CCDE.3080901@pdf.com>
	<16232.227.360586.936442@gargle.gargle.HOWL>
Message-ID: <3F680A30.3060104@statistik.uni-dortmund.de>

Martin Maechler wrote:

>>>>>>"Spencer" == Spencer Graves <spencer.graves at pdf.com>
>>>>>>    on Tue, 16 Sep 2003 19:54:22 -0700 writes:
> 
> 
>     Spencer> Consider
>     Spencer>  Q <- function(x)q("no")
> 
>     Spencer> With R 1.7.1 under Windows, "Q()" caused R to close
>     Spencer> without asking for confirmation.  This does not
>     Spencer> solve the whole problem, but it might provide a
>     Spencer> piece of the puzzle.
> 
> Apropos, this reminds me of the old quiz (from the S-plus times):
> 
> How can you write (quite short!) R code such that
> typing
> 	"Q"   
> 
> -- without any  "()" -- will quit R (without asking about saving).
> 
> [But you shouldn't really keep that code active in your standard R session
>  because it would be too easy to accidentally shut down R !]
> 
> For the advanced ones: 
> My shortest solution uses 51 characters of R code, can you beat that?
> 

Less than 51 is not that hard, Martin: 46 (counting line breaks as 
characters):

Q<-1
class(Q)<-"Q"
print.Q<-function(x)q("no")

Uwe



From deepayan at stat.wisc.edu  Wed Sep 17 09:17:24 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Wed, 17 Sep 2003 02:17:24 -0500
Subject: [R] Quiz {was "Quit asking me .."}
In-Reply-To: <16232.227.360586.936442@gargle.gargle.HOWL>
References: <Pine.GSO.4.10.10309162222370.24939-100000@athena.biostat.jhsph.edu>
	<3F67CCDE.3080901@pdf.com>
	<16232.227.360586.936442@gargle.gargle.HOWL>
Message-ID: <200309170217.24278.deepayan@stat.wisc.edu>

On Wednesday 17 September 2003 01:36, Martin Maechler wrote:

> How can you write (quite short!) R code such that
> typing
> 	"Q"
>
> -- without any  "()" -- will quit R (without asking about saving).
>
> [But you shouldn't really keep that code active in your standard R session
>  because it would be too easy to accidentally shut down R !]
>
> For the advanced ones:
> My shortest solution uses 51 characters of R code, can you beat that?

Barely, 46 removing all spaces:

print.q<-function(x)q("no");Q<-1;class(Q)<-"q"

We can also replace <- by = in recent (and _ in older) versions of R to 
decrease this further.



From maechler at stat.math.ethz.ch  Wed Sep 17 09:24:05 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 17 Sep 2003 09:24:05 +0200
Subject: [R] Quiz {was "Quit asking me .."}
In-Reply-To: <16232.227.360586.936442@gargle.gargle.HOWL>
References: <Pine.GSO.4.10.10309162222370.24939-100000@athena.biostat.jhsph.edu>
	<3F67CCDE.3080901@pdf.com>
	<16232.227.360586.936442@gargle.gargle.HOWL>
Message-ID: <16232.3093.17341.952417@gargle.gargle.HOWL>

>>>>> "MM" == Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Wed, 17 Sep 2003 08:36:19 +0200 writes:

>>>>> "Spencer" == Spencer Graves <spencer.graves at pdf.com>
>>>>>     on Tue, 16 Sep 2003 19:54:22 -0700 writes:

    Spencer> Consider
    Spencer> Q <- function(x)q("no")

    Spencer> With R 1.7.1 under Windows, "Q()" caused R to close
    Spencer> without asking for confirmation.  This does not
    Spencer> solve the whole problem, but it might provide a
    Spencer> piece of the puzzle.

    MM> Apropos, this reminds me of the old quiz (from the S-plus times):

    MM> How can you write (quite short!) R code such that
    MM> typing
    MM>		"Q"   
    MM> -- without any  "()" -- will quit R (without asking about saving).

    MM> [But you shouldn't really keep that code active in your
    MM> standard R session because it would be too easy to
    MM> accidentally shut down R !]

    MM> For the advanced ones: My shortest solution uses 51
    MM> characters of R code, can you beat that?

I had overlooked something: Uwe Ligges and Deepayan Sarkar beat it
almost simultaneously with a solution of 43 characters
(when using "=" for assignment).

Martin



From hb at maths.lth.se  Wed Sep 17 10:18:06 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Wed, 17 Sep 2003 10:18:06 +0200
Subject: [R] Quiz {was "Quit asking me .."}
In-Reply-To: <200309170217.24278.deepayan@stat.wisc.edu>
Message-ID: <002501c37cf4$3a8f4c40$3a0040d5@maths.lth.se>

First, 42 characters...

Q="no";class(Q)=Q;print.no=function(x)q(Q)

Interestingly, the following works too (41 chars)

Q="";class(Q)=Q;print.=function(x)q("no")

Is it legal though to have empty class names?

And finally, the beautiful one with 28 characters

Q="no";class(Q)=Q;print.no=q

Have nice day!

Henrik Bengtsson
Lund University

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Deepayan Sarkar
> Sent: den 17 september 2003 09:17
> To: Martin Maechler; R-help at stat.math.ethz.ch
> Subject: Re: [R] Quiz {was "Quit asking me .."}
> 
> 
> On Wednesday 17 September 2003 01:36, Martin Maechler wrote:
> 
> > How can you write (quite short!) R code such that
> > typing
> > 	"Q"
> >
> > -- without any  "()" -- will quit R (without asking about saving).
> >
> > [But you shouldn't really keep that code active in your standard R 
> > session  because it would be too easy to accidentally shut down R !]
> >
> > For the advanced ones:
> > My shortest solution uses 51 characters of R code, can you 
> beat that?
> 
> Barely, 46 removing all spaces:
> 
> print.q<-function(x)q("no");Q<-1;class(Q)<-"q"
> 
> We can also replace <- by = in recent (and _ in older) 
> versions of R to 
> decrease this further.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> 
>



From B.Rowlingson at lancaster.ac.uk  Wed Sep 17 10:31:29 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 17 Sep 2003 09:31:29 +0100
Subject: [R] R-Golf {was Quiz {was "Quit asking me .."}}
In-Reply-To: <200309170217.24278.deepayan@stat.wisc.edu>
References: <Pine.GSO.4.10.10309162222370.24939-100000@athena.biostat.jhsph.edu>	<3F67CCDE.3080901@pdf.com>	<16232.227.360586.936442@gargle.gargle.HOWL>
	<200309170217.24278.deepayan@stat.wisc.edu>
Message-ID: <3F681BE1.7000808@lancaster.ac.uk>

Deepayan Sarkar wrote:

> Barely, 46 removing all spaces:
> 
> print.q<-function(x)q("no");Q<-1;class(Q)<-"q"
> 
> We can also replace <- by = in recent (and _ in older) versions of R to 
> decrease this further.
> 

  This is 'R-golf'. Perl golf competitions are quite common and usually 
result in seriously obfuscated code.

  Perhaps someone would like to run an R-golf contest for the 
R-newsletter (crossword fans: solution to the crossword I set in the 
last one is coming in the next R-newsletter)? Perl golf contests are run 
from here [http://perlgolf.sourceforge.net] if you want inspiration.

Baz



From hb at maths.lth.se  Wed Sep 17 10:37:01 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Wed, 17 Sep 2003 10:37:01 +0200
Subject: [R] Quiz {was "Quit asking me .."}
In-Reply-To: <002501c37cf4$3a8f4c40$3a0040d5@maths.lth.se>
Message-ID: <002601c37cf6$de756360$3a0040d5@maths.lth.se>

Sorry for bugging you AGAIN, but I went to get a coffee and I realized
you can get down to 26 characters:

class(Q)=Q="no";print.no=q

That is a good question to put up on an R/parsing/S3/UseMethod quiz,
ehe?! 

Henrik

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Henrik 
> Bengtsson
> Sent: den 17 september 2003 10:18
> To: 'Deepayan Sarkar'; 'Martin Maechler'; R-help at stat.math.ethz.ch
> Cc: ligges at statistik.uni-dortmund.de
> Subject: RE: [R] Quiz {was "Quit asking me .."}
> 
> 
> First, 42 characters...
> 
> Q="no";class(Q)=Q;print.no=function(x)q(Q)
> 
> Interestingly, the following works too (41 chars)
> 
> Q="";class(Q)=Q;print.=function(x)q("no")
> 
> Is it legal though to have empty class names?
> 
> And finally, the beautiful one with 28 characters
> 
> Q="no";class(Q)=Q;print.no=q
> 
> Have nice day!
> 
> Henrik Bengtsson
> Lund University
> 
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Deepayan Sarkar
> > Sent: den 17 september 2003 09:17
> > To: Martin Maechler; R-help at stat.math.ethz.ch
> > Subject: Re: [R] Quiz {was "Quit asking me .."}
> > 
> > 
> > On Wednesday 17 September 2003 01:36, Martin Maechler wrote:
> > 
> > > How can you write (quite short!) R code such that
> > > typing
> > > 	"Q"
> > >
> > > -- without any  "()" -- will quit R (without asking about saving).
> > >
> > > [But you shouldn't really keep that code active in your standard R
> > > session  because it would be too easy to accidentally 
> shut down R !]
> > >
> > > For the advanced ones:
> > > My shortest solution uses 51 characters of R code, can you
> > beat that?
> > 
> > Barely, 46 removing all spaces:
> > 
> > print.q<-function(x)q("no");Q<-1;class(Q)<-"q"
> > 
> > We can also replace <- by = in recent (and _ in older)
> > versions of R to 
> > decrease this further.
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> > 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> 
>



From keef9490 at uidaho.edu  Wed Sep 17 10:39:02 2003
From: keef9490 at uidaho.edu (Robert Keefe)
Date: Wed, 17 Sep 2003 01:39:02 -0700 (PDT)
Subject: [R] Quiz {was "Quit asking me .."}
In-Reply-To: <002501c37cf4$3a8f4c40$3a0040d5@maths.lth.se>
References: <002501c37cf4$3a8f4c40$3a0040d5@maths.lth.se>
Message-ID: <Pine.GSO.4.51.0309170137030.10730@cyclone.csrv.uidaho.edu>


Henrik,

Gotcha, with 25:

Q=noquote(quote(q("no")))

Cheers,

Rob

_____________________________________________________

Rob Keefe                        Lab: (208) 885-5165
M.S. student                    Home: (208) 882-9749
Forest Biometrics Lab
University of Idaho
_____________________________________________________

On Wed, 17 Sep 2003, Henrik Bengtsson wrote:

> First, 42 characters...
>
> Q="no";class(Q)=Q;print.no=function(x)q(Q)
>
> Interestingly, the following works too (41 chars)
>
> Q="";class(Q)=Q;print.=function(x)q("no")
>
> Is it legal though to have empty class names?
>
> And finally, the beautiful one with 28 characters
>
> Q="no";class(Q)=Q;print.no=q
>
> Have nice day!
>
> Henrik Bengtsson
> Lund University
>
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Deepayan Sarkar
> > Sent: den 17 september 2003 09:17
> > To: Martin Maechler; R-help at stat.math.ethz.ch
> > Subject: Re: [R] Quiz {was "Quit asking me .."}
> >
> >
> > On Wednesday 17 September 2003 01:36, Martin Maechler wrote:
> >
> > > How can you write (quite short!) R code such that
> > > typing
> > > 	"Q"
> > >
> > > -- without any  "()" -- will quit R (without asking about saving).
> > >
> > > [But you shouldn't really keep that code active in your standard R
> > > session  because it would be too easy to accidentally shut down R !]
> > >
> > > For the advanced ones:
> > > My shortest solution uses 51 characters of R code, can you
> > beat that?
> >
> > Barely, 46 removing all spaces:
> >
> > print.q<-function(x)q("no");Q<-1;class(Q)<-"q"
> >
> > We can also replace <- by = in recent (and _ in older)
> > versions of R to
> > decrease this further.
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> >
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From gb at stat.umu.se  Wed Sep 17 11:20:43 2003
From: gb at stat.umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Wed, 17 Sep 2003 11:20:43 +0200 (CEST)
Subject: [R] Help with glmmML package 
In-Reply-To: <Pine.GSO.4.10.10309162112560.15122-100000@stawlmihq>
References: <Pine.GSO.4.10.10309162112560.15122-100000@stawlmihq>
Message-ID: <Pine.LNX.4.56.0309171104080.4384@tal.stat.umu.se>

On Tue, 16 Sep 2003, Farouk Nathoo wrote:

> Dear R users,
>
> I have been using the package glmmML to fit a logistic-normal mixed model
> to clustered binary data. Along with parameter estimates I would also like
> to obtain estimates of the random effects. I have noticed that a fitted
> "glmmML" object contains a component called "frail", a vector, which looks
> to be an estimate of the random effects. Can anyone confirm this?

I can.

> And if
> so, how are these estimates obtained from the fitted model?

They are the conditional expectations of the random effects, given "data",
calculated at the parameter values given by the fitted model.

> Are they the empirical Bayes estimates?

I guess one could call them that.

I apologize for the bad documentation of glmmML. Hopefully I will be able
to deliver improvements during this fall. Until then, read the source
code. :-)

 ---
 G?ran Brostr?m                    tel: +46 90 786 5223
 Department of Statistics          fax: +46 90 786 6614
 Ume? University                   http://www.stat.umu.se/egna/gb/
 SE-90187 Ume?, Sweden             e-mail: gb at stat.umu.se



From maechler at stat.math.ethz.ch  Wed Sep 17 11:40:20 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 17 Sep 2003 11:40:20 +0200
Subject: [R] Quiz {was "Quit asking me .."}
In-Reply-To: <Pine.GSO.4.51.0309170137030.10730@cyclone.csrv.uidaho.edu>
References: <002501c37cf4$3a8f4c40$3a0040d5@maths.lth.se>
	<Pine.GSO.4.51.0309170137030.10730@cyclone.csrv.uidaho.edu>
Message-ID: <16232.11268.571391.777979@gargle.gargle.HOWL>

>>>>> "Rob" == Robert Keefe <keef9490 at uidaho.edu>
>>>>>     on Wed, 17 Sep 2003 01:39:02 -0700 (PDT) writes:

    Rob> Henrik,

    Rob> Gotcha, with 25:

    Rob> Q=noquote(quote(q("no")))

which is beaten with 16:

         Q=delay(q("no"))

*BUT* that's really not a nice one (and if I had thought
about it in advance I hadn't asked about a minimal length solution). 

The purpose of the quiz was to demonstrate autoprinting and
print methods for S3 classes, and I'd judge Henrik clearly won
the first price (for now) with the 28-letter 
       Q="no";class(Q)=Q;print.no=q
which combines shortness and beauty.

I think this issue with of an [empty name]-class is something to
be considered further -- probably rather on R-devel.

Martin Maechler



From a.letertre at invs.sante.fr  Wed Sep 17 12:08:59 2003
From: a.letertre at invs.sante.fr (LE TERTRE Alain)
Date: Wed, 17 Sep 2003 12:08:59 +0200
Subject: [R] attributing names in predicted type="terms" gam object
Message-ID: <E205E1E28C581B4AB24D569AC43F2FE727F36F@exchange.invs>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030917/839a5949/attachment.pl

From Simon.Fear at synequanon.com  Wed Sep 17 12:19:50 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Wed, 17 Sep 2003 11:19:50 +0100
Subject: Just don't do it, surely? (was RE: [R] Retrieve ... argument values)
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572AC0DD4@synequanon01>

There have been various elegant solutions to test for the presence
of a particular named parameter within a ... argument, such as

if (!is.null(list(...)$ylim))
if ("ylim" %in% names(list(...)))

I think I'd have to comment these lines pretty clearly if I wanted
to easily follow the code in 6 months time. 

But I'm still not convinced it is ever a good idea to use this 
technique in preference to using explicit named arguments. If
there is something special about "ylim", why insist that it be 
passed within  "..." in the first place? Surely it's better
to define the function as function(x,ylim=default,...) within which
you do your special ylim stuff, then call plot(x, ylim=ylim,...))??

Can anyone come up with a good reason not to follow
that principle? I think my earlier post may have been
misconstrued: I'm not saying "never write functions that use ...", 
I'm just saying "never write functions that depend on a particular 
argument being passed via ...".
 

Simon Fear
Senior Statistician
Syne qua non Ltd
Tel: +44 (0) 1379 644449
Fax: +44 (0) 1379 644445
email: Simon.Fear at synequanon.com
web: http://www.synequanon.com
 
Number of attachments included with this message: 0
 
This message (and any associated files) is confidential and\...{{dropped}}



From ripley at stats.ox.ac.uk  Wed Sep 17 12:26:15 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 17 Sep 2003 11:26:15 +0100 (BST)
Subject: [R] Using POSIX?t rather than "chron" or "date" 
In-Reply-To: <16232.1870.806378.52010@gargle.gargle.HOWL>
Message-ID: <Pine.LNX.4.44.0309171124120.3457-100000@gannet.stats>

On Wed, 17 Sep 2003, Martin Maechler wrote:

> >>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk>
> >>>>>     on Wed, 17 Sep 2003 06:58:48 +0100 (BST) writes:
> 
>     BDR> On Tue, 16 Sep 2003, Deepayan Sarkar wrote:
>     >> Is the date class standard enough to warrant including a
>     >> check for it in lattice ?
> 
>     BDR> I don't think so.  The POSIX*t classes in R are the
>     BDR> most standard, followed by the chron package and only
>     BDR> then the date package.
> 
> Definitely.  And I think we should encourage people to
> upgrade to POSIX.t from "chron" (let alone "date") more
> strongly {Note that there have been  as.POSIXct() methods for
> these classes since the beginning of the POSIX.t classes.
> 
> Could "chron" and "date" users be heard about what
> functionality they are missing in POSIX.t ?
> 
> On the other hand, the recommended package "survival" has
> a(nother?) class "date" and that package is based on S(plus) code
> and may hence not be convertible sensibly ?

survival has the parts of date it needs included (same class, same
original author).  It has rate tables which as I understand it are in date
format and so need to accessed by date objects.  I could well understand
Thomas not wanting to do a conversion.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From phil.saunders at premierbet.com  Wed Sep 17 12:32:57 2003
From: phil.saunders at premierbet.com (Phil Saunders)
Date: Wed, 17 Sep 2003 11:32:57 +0100
Subject: [R] Text Vector Printing And Storage
Message-ID: <A5B74A99C30DBB46B9A819C3BD4A65F1435C2F@blsvr-2.bluelizard.org.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030917/f1b35e04/attachment.pl

From ugulumbe at yahoo.co.uk  Wed Sep 17 12:45:42 2003
From: ugulumbe at yahoo.co.uk (=?iso-8859-1?q?Usman=20Shehu?=)
Date: Wed, 17 Sep 2003 11:45:42 +0100 (BST)
Subject: [R] arma.roots
In-Reply-To: <200309171019.h8HA1lAK020978@stat.math.ethz.ch>
Message-ID: <20030917104542.56091.qmail@web10905.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030917/db3941b9/attachment.pl

From glaziou at pasteur-kh.org  Wed Sep 17 12:47:35 2003
From: glaziou at pasteur-kh.org (Philippe Glaziou)
Date: Wed, 17 Sep 2003 17:47:35 +0700
Subject: [R] Using POSIX?t rather than "chron" or "date"
In-Reply-To: <16232.1870.806378.52010@gargle.gargle.HOWL>
References: <200309162331.06832.deepayan@stat.wisc.edu>
	<Pine.LNX.4.44.0309170655470.2844-100000@gannet.stats>
	<16232.1870.806378.52010@gargle.gargle.HOWL>
Message-ID: <20030917104735.GA654@pasteur-kh.org>

Martin Maechler <maechler at stat.math.ethz.ch> wrote:
> Could "chron" and "date" users be heard about what
> functionality they are missing in POSIX.t ?


As a chron user, I suppose none. But I find chron more
friendly and it saves some typing.

In my opinion, as.POSIXct and most related functions have
rather complicated names to type, which make them prone to
typos. Typos slow down the thinking.

-- 
Philippe Glaziou
Pasteur Institute of Cambodia



From ripley at stats.ox.ac.uk  Wed Sep 17 13:19:50 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 17 Sep 2003 12:19:50 +0100 (BST)
Subject: Just don't do it, surely? (was RE: [R] Retrieve ... argument
	values)
In-Reply-To: <6C8A8033ABC1E3468048ABC4F13CE572AC0DD4@synequanon01>
Message-ID: <Pine.LNX.4.44.0309171127100.3457-100000@gannet.stats>

On Wed, 17 Sep 2003, Simon Fear wrote:

> There have been various elegant solutions to test for the presence
> of a particular named parameter within a ... argument, such as
> 
> if (!is.null(list(...)$ylim))
> if ("ylim" %in% names(list(...)))
> 
> I think I'd have to comment these lines pretty clearly if I wanted
> to easily follow the code in 6 months time. 

Well, take a look at the R sources, as

dots <- list(...)
haveYlim <- "ylim" %in% names(dots)

is the sort of thing we still understand 5 years later.

> But I'm still not convinced it is ever a good idea to use this 
> technique in preference to using explicit named arguments. If
> there is something special about "ylim", why insist that it be 
> passed within  "..." in the first place? Surely it's better
> to define the function as function(x,ylim=default,...) within which
> you do your special ylim stuff, then call plot(x, ylim=ylim,...))??
> 
> Can anyone come up with a good reason not to follow
> that principle? 

Inadvertent partial matching for one.  If you must do this, put ylim after 
... or anything you try to pass through ... starting y, yl or yli will
be matched to ylim, as in

> foo <- function(x, ylim=NULL, ...) match.call()
> foo(y=1)
foo(ylim = 1)
> foo <- function(x, ..., ylim=NULL) match.call()
> foo(y=1)
foo(y = 1)

Were you aware of that?  (It's not clear to me that a lot of authors of R 
code have considered it carefully. It is in `S Programming'.)

> I think my earlier post may have been
> misconstrued: I'm not saying "never write functions that use ...", 
> I'm just saying "never write functions that depend on a particular 
> argument being passed via ...".

It is also conceptually simpler for groups of arguments, such as graphical 
parameters, to be treated consistently, possibly between groups of 
functions.  See plot.POSIXct for one of the possible elegant workarounds.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ucgamdo at ucl.ac.uk  Wed Sep 17 13:42:48 2003
From: ucgamdo at ucl.ac.uk (ucgamdo@ucl.ac.uk)
Date: Wed, 17 Sep 2003 12:42:48 +0100
Subject: [R] Persp and color (again)
Message-ID: <3.0.5.32.20030917124248.007dea30@pop-server.ucl.ac.uk>

Hi guys,

  After all the discussion yesterday about persp and color, I decided to
have a more closer look at demo(persp), and decided to write a function to
generate 'topo-like' colours to plot perspectives (Thanks a lot to Uwe
Ligges for his enlightning comments regarding the code in the demo).

Here it goes, I believe that this function will be pretty useful to a lot
of people:

###########################################################################
# Function to generate a matrix of colors to be used in perspective plots
# (based on demo(persp) and the comments of U. Ligges
###########################################################################

surf.colors <- function(x, col = terrain.colors(20)) {

  # First we drop the 'borders' and average the facet corners
  # we need (nx - 1)(ny - 1) facet colours!
  x.avg <- (x[-1, -1] + x[-1, -(ncol(x) - 1)] +
             x[-(nrow(x) -1), -1] + x[-(nrow(x) -1), -(ncol(x) - 1)]) / 4

  # Now we construct the actual colours matrix
  colors = col[cut(x.avg, breaks = length(col), include.lowest = T)]

  return(colors)
}

# Now lets look at an example of using it:

# first lets build some random surface
library(MASS)
x <- cbind(rnorm(100), rnorm(100))
x <- kde2d(x[,1], x[,2], n = 100)$z

# now lets plot it!
par(bg = "gray")

persp(x, col = surf.colors(x), phi = 30, theta = 225, box = F, border = NA,
shade = .4)

persp(x, col = surf.colors(x, col = heat.colors(40)), phi = 30, theta =
225, box = F, border = NA, shade = .4)

persp(x, col = surf.colors(x, col = topo.colors(40)), phi = 30, theta =
225, box = F, border = NA, shade = .4)

persp(x, col = surf.colors(x, col = gray(seq(0, 1, len = 40))), phi = 30,
theta = 225, box = F, border = NA, shade = .4)

# etc, etc, etc. I hope this will give you plenty of ideas, perhaps, the
writer of persp would like to
# add this as a subroutine so it can be called directly from within the
persp function, say
# persp(x, col = heat.colors(20), topo = TRUE, ...)



From ucgamdo at ucl.ac.uk  Wed Sep 17 13:45:51 2003
From: ucgamdo at ucl.ac.uk (ucgamdo@ucl.ac.uk)
Date: Wed, 17 Sep 2003 12:45:51 +0100
Subject: [R] Fractals in R and having fun! (and more persp and color)
Message-ID: <3.0.5.32.20030917124551.007aaab0@pop-server.ucl.ac.uk>

Well, I started playing with fractals in R, and wrote a function to
generate de Mandelbrot set, which might
be of interest to some people

###########################################################################
# Mandelbrot set
###########################################################################

mandelbrot <- function(x = c(-3.0, 1.0),   # x coordinates
                       y = c(-1.8, 1.8),   # y coordinates
                       b = .05,            # by 'steps'
                       iter = 20)          # maximum number of iterations
{
  m = NULL  # will store the results, this is the 'image' matrix
  
  for(i in seq(x[1], x[2], by = b)) {

    r = NULL # stores part of the iteration results

    for(j in seq(y[1], y[2], by = b)) {

      it = iter # will hold iteration at which point (i, j) breaks off

      c = c(i, j)  # initial point
      z = c(i, j)  # i: real part; j: imaginary part

      for(k in 1:iter) {

        # the Mandelbrot iteration formulae: z -> z*z + c
        z =  c(z[1]^2 - z[2]^2, 2 * z[1]*z[2]) + c

        # tests if point breaks off
        if((z[1] + z[2])^2 > 4) { it = k; break }
      }

      r = c(r, it) # stores iteration results
    }
    # constructs the 'image' matrix
    m = rbind(m, r)
  }

  # the output fractal object
  fractal = list(x = seq(x[1], x[2], by = b), # x coordinates
    y = seq(y[1], y[2], by = b),              # y coordinates
    z = m)                                    # it matrix
}

######################################################################
# here goes how it works
######################################################################

frac <- mandelbrot()
image(frac)  # perhaps not very nice!

# more resolution, beware, this might take some time to calculate

frac <- mandelbrot(b = .01)
image(frac)

# now here comes the fun, lets do a persp plot of the set!

persp(log(frac$z), border = NA, theta = 225, phi = 45, col = "gray", shade
= .4)

###END###

Well, here comes what would have been my question. How to put some nice
colors to the above perspective plot? I wanted to post this question some
weeks ago, but it was answered yesterday after all the discussion on persp
and colors. If you see my previous post, you'll the definition of
surf.colors used below:

persp(log(frac$z), border = NA, theta = 225, phi = 45, col =
surf.colors(frac$z, col = c(gray(seq(0.5, 1, len = 39)), "black")), shade =
.4)

that was what I always wanted to do, and this was the source of my
confusion when checking the code in persp demo.

But now some new question arises, which I'll leave to the interested hacker:

Any C programmer who volunteers to write and link c code to R to calculate de
Mandelbrot set faster?

Does anyone have any idea on how to 'smooth' the valleys and ridges that
rise towards the set?, i.e. to avoid the stairs like appearence of the plot?

I hope you can have some fun with this!



From Bernhard.Pfaff at drkw.com  Wed Sep 17 13:51:15 2003
From: Bernhard.Pfaff at drkw.com (Pfaff, Bernhard)
Date: Wed, 17 Sep 2003 13:51:15 +0200
Subject: [R] Text Vector Printing And Storage
Message-ID: <18D602BD42B7E24EB810D6454A58DB90047305BA@ibfftce505.is.de.dresdnerkb.com>

how about: ?write

something like:

your.text <- c(date(), "insert name of your R object", "==== end ====")
write(your.text, "your-text.txt", append=TRUE)

date() and "==== end ====" should help you to separate your daily changing
character vectors.

HTH,
Bernhard

> I am using R 1.7.1 on Windows, running a program on a daily 
> basis which produces a vector of text results, where the 
> length of the vector may be different each day.
> 
> While I can display this vector in the R console using a cat 
> instruction, I am presently unable to either print it out on 
> a printer (item 2.9 in the R for Windows FAQ says I need to 
> use 'File | Print' but I've failed to find any function 
> listed under that name), 

File | Print works fine for me; have you checked your printer
settings?

> or to store this vector in a 
> textfile alongside previous days' results because they are 
> not all of the same length and cannot therefore be 
> collectively handled as a matrix or dataframe.
> 
how about: ?write

something like:

your.text <- c(date(), "insert name of your R object", "==== end ====")
write(your.text, "your-text.txt", append=TRUE)

date() and "==== end ====" should help you to separate your daily changing
character vectors.

HTH,
Bernhard


> Any help with regard to either of these problems would be 
> greatly appreciated!
> 
> Phil
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


----------------------------------------------------------------------
If you have received this e-mail in error or wish to read our e-mail 
disclaimer statement and monitoring policy, please refer to 
http://www.drkw.com/disc/email/ or contact the sender.



From Simon.Fear at synequanon.com  Wed Sep 17 13:52:01 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Wed, 17 Sep 2003 12:52:01 +0100
Subject: Just don't do it,
	surely? (was RE: [R] Retrieve ... argument values)
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572AC0DD7@synequanon01>

Thanks for the insight.

> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
<snip>
> dots <- list(...)
> haveYlim <- "ylim" %in% names(dots)
> 
> is the sort of thing we still understand 5 years later.
> 
I didn't say "understand", I said "easily follow". Obviously how
"easily" is subjective and depends to some extent on 
frequency of use of this idiom.

<snip>
> Inadvertent partial matching for one. 

Ah yes! It is true that I often forget about this, mostly because
partial argument matching offends me greatly, and I never, 
knowingly, use it. Of course as a major contributor to the
R project (and that's an understatement, I know), you do have
to worry about this - users of your routines may like to use
partial matching. But I hope most of us don't.

Worse news is that my posted formulation would suffer the same 
problem if I had an explicit argument "ylimit" and called with 
a "ylim" in "..." intended for "par". That's just too horrible to 
contemplate.
 

Simon Fear
Senior Statistician
Syne qua non Ltd
Tel: +44 (0) 1379 644449
Fax: +44 (0) 1379 644445
email: Simon.Fear at synequanon.com
web: http://www.synequanon.com
 
Number of attachments included with this message: 0
 
This message (and any associated files) is confidential and\...{{dropped}}



From lperepol at necessity.org  Wed Sep 17 14:22:29 2003
From: lperepol at necessity.org (Lawrence Perepolkin)
Date: Wed, 17 Sep 2003 05:22:29 -0700
Subject: [R] Is calculating a Lake Ratio possible with R?
Message-ID: <000401c37d16$5d238fb0$0a01a8c0@Reskit.com>



If I display a line chart, with peaks and valleys, and visualize rain
falling on a mountain range, filling in all the valleys. This produces a
series of lakes between peaks. In case the highest peak s not at the right
most edge,  erect a dam on the right to back up the water to the highest
peak, at the far right to collect all the water from the previous high point
in a final, artificial lake. 

Now calculate the total volume and the volume of the land mass.

If we divide the total volume of water by the volume of the earth below it,
we have the Lake Ratio. 

If someone has done something similar to this please let me know.

Thanks 

Lawrence



From simon at stats.gla.ac.uk  Wed Sep 17 15:02:48 2003
From: simon at stats.gla.ac.uk (Simon Wood)
Date: Wed, 17 Sep 2003 14:02:48 +0100 (BST)
Subject: [R]gam and concurvity 
In-Reply-To: <003201c37a7a$ab393e00$d3bb42ab@yacht>
Message-ID: <Pine.SOL.3.96.1030917134420.28530G-100000@moon.stats.gla.ac.uk>

> in the paper "Avoiding the effects of concurvity in GAM's .." of
> Figueiras et al. (2003) it is mentioned that in GLM collinearity is taken 
> into account in the calc of se but not in GAM (-> results in confidence 
> interval too narrow, p-value understated,  GAM S-Plus version). I haven't 
> found any references to GAM and concurvity or collinearity on the R page. 
> And I wonder if the R  version of Gam differ in this point.

- the penalized regression spline representation means that it's easy to
calculate the `correct' s.e.'s and this is what is done. The covariance
matrix used is based on a Bayesian model of smoothing, generalized from
Silverman (1985), JRSSB (and less closely, Wahba, 1983, JRSSB), so the
s.e.'s are generally a little larger than you'd get if you just pretended
that the GAM was an un-penalized GLM (this widening generally improves CI
performance). 

As Thomas Lumley pointed out, the s.e.'s don't take into account smoothing
parameter estimation uncertainty. In simulation studies this
uncertainty seems to have very little effect on the realized coverage
probabilities of Confidence Interval's that are in some sense `whole
model' intervals, but the performance of CI's for component functions of
the GAM can be quite a long way from nominal. There's a simple
`not-very-computer-intensive' fix for this which removes the conditioning
on the smoothing parameters and greatly improves component-wise coverage
probabilities.... implementation is on my `to-do' list (might wait to see
what the referees say though!)

Simon 

ps. mgcv 0.9 out now! (changes list linked to my www page)
_____________________________________________________________________
> Simon Wood simon at stats.gla.ac.uk        www.stats.gla.ac.uk/~simon/
>>  Department of Statistics, University of Glasgow, Glasgow, G12 8QQ
>>>   Direct telephone: (0)141 330 4530          Fax: (0)141 330 4814



From MZodet at ahrq.gov  Wed Sep 17 15:14:12 2003
From: MZodet at ahrq.gov (MZodet@ahrq.gov)
Date: Wed, 17 Sep 2003 09:14:12 -0400
Subject: [R] 3D plot/surface rotation
Message-ID: <3598558AD728D41183350008C7CF291C0A5CD344@exchange1.ahrq.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030917/3812a016/attachment.pl

From mmarques at power.inescn.pt  Wed Sep 17 15:32:09 2003
From: mmarques at power.inescn.pt (Mark Marques)
Date: Wed, 17 Sep 2003 14:32:09 +0100
Subject: [R] 3D plot/surface rotation
In-Reply-To: <3598558AD728D41183350008C7CF291C0A5CD344@exchange1.ahrq.gov>
References: <3598558AD728D41183350008C7CF291C0A5CD344@exchange1.ahrq.gov>
Message-ID: <118189537765.20030917143209@power.inescn.pt>

Hello MZodet,

Wednesday, September 17, 2003, 2:14:12 PM, you wrote:

Mag> How do I rotate 3D plots/surfaces generated by either cloud or wireframe?



wireframe has the screen parameter which reads a list to rotate ...
something in this kind:

wireframe(object, screen = list( x = 5, y = 5 , z= 10))

Same with cloud function...



From mailinglist.wegmann at gmx.net  Wed Sep 17 15:41:05 2003
From: mailinglist.wegmann at gmx.net (Martin Wegmann)
Date: Wed, 17 Sep 2003 15:41:05 +0200
Subject: [R] mgcv 0.9 install
In-Reply-To: <Pine.SOL.3.96.1030917134420.28530G-100000@moon.stats.gla.ac.uk>
References: <Pine.SOL.3.96.1030917134420.28530G-100000@moon.stats.gla.ac.uk>
Message-ID: <200309171541.05541.mailinglist.wegmann@gmx.net>

> ps. mgcv 0.9 out now! (changes list linked to my www page)
Hello, 

I tried to update mgcv but it doesn't work

update.packages()
mgcv :
 Version 0.8-9 in /usr/lib/R/library
 Version 0.9-2 on CRAN
Update (y/N)?  y
trying URL `http://cran.r-project.org/src/contrib/mgcv_0.9-2
.tar.gz'
Content type `application/x-tar' length 180772 bytes
opened URL
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ..........
.......... .......... ......
downloaded 176Kb

* Installing *source* package 'mgcv' ...
** libs
gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp -Wa
ll -pedantic  -fPIC  -g -O2 -c gcv.c -o gcv.o
gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp -Wa
ll -pedantic  -fPIC  -g -O2 -c magic.c -o magic.o
gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp -Wa
ll -pedantic  -fPIC  -g -O2 -c mat.c -o mat.o
gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp -Wa
ll -pedantic  -fPIC  -g -O2 -c matrix.c -o matrix.o
gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp -Wa
ll -pedantic  -fPIC  -g -O2 -c mgcv.c -o mgcv.o
gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp -Wa                                       
ll -pedantic  -fPIC  -g -O2 -c qp.c -o qp.o
gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp -Wa                                       
ll -pedantic  -fPIC  -g -O2 -c tprs.c -o tprs.o
gcc -shared  -o mgcv.so gcv.o magic.o mat.o matrix.o mgcv.o                                        
qp.o tprs.o -L/usr/lib/R/bin -lRlapack -lf77blas -latlas -L/                                       
usr/lib/gcc-lib/i386-linux/3.3 -L/usr/lib/gcc-lib/i386-linux                                       
/3.3/../../.. -lfrtbegin -lg2c-pic -lm -lgcc_s  -L/usr/lib/R                                       
/bin -lR
/usr/bin/ld: cannot find -lf77blas
collect2: ld returned 1 exit status
make: *** [mgcv.so] Fehler 1
ERROR: compilation failed for package 'mgcv'

Delete downloaded files (y/N)? y

Warning message:
Installation of package mgcv had non-zero exit status in: in                                       
stall.packages(update[, "Package"], instlib, contriburl = co                                       
ntriburl,
>

 Martin



From laurent.faisnel at ariase.com  Wed Sep 17 15:40:35 2003
From: laurent.faisnel at ariase.com (Laurent Faisnel)
Date: Wed, 17 Sep 2003 15:40:35 +0200
Subject: [R] 3D plot/surface rotation
References: <3598558AD728D41183350008C7CF291C0A5CD344@exchange1.ahrq.gov>
Message-ID: <3F686453.8030803@ariase.com>

MZodet at ahrq.gov wrote:
> How do I rotate 3D plots/surfaces generated by either cloud or wireframe?

wireframe - I think you have to set the screen parameter, see the 
example from ?wireframe, it seems to me you can rotate the surface as 
you like.

I believe it's the same thing for cloud, but I did not test it.

I don't know if it's possible for you but persp is also good for 3D 
surfaces. Then you just have to set the theta and phi parameters.

Hope this helps,
Laurent



From ernesto at ipimar.pt  Wed Sep 17 15:41:29 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Wed, 17 Sep 2003 14:41:29 +0100
Subject: [R] problems making R 1.7.1
Message-ID: <1063806089.4843.15.camel@gandalf.local>

Hi,

I'm building R 1.7.1 in a SuSE 8.2 box with the updated compiler from
SuSE (gcc 3.1.1-16) and I'm getting this error:



making dataentry.d from dataentry.c
In file included from /usr/X11R6/include/X11/keysym.h:73,
                 from dataentry.c:36:
/usr/X11R6/include/X11/keysymdef.h:1181:2: invalid preprocessing
directive #d
making devX11.d from devX11.c
making rotated.d from rotated.c
making rbitmap.d from rbitmap.c
make[4]: Leaving directory
`/usr/local/src/compile/R-1.7.1/src/modules/X11'
make[4]: Entering directory
`/usr/local/src/compile/R-1.7.1/src/modules/X11'
gcc -I. -I../../../src/include -I../../../src/include
-I/usr/X11R6/include -I/usr/local/include -DHAVE_CONFIG_H
-D__NO_MATH_INLINES -mieee-fp -fPIC  -g -O2 -c dataentry.c -o
dataentry.lo
In file included from /usr/X11R6/include/X11/keysym.h:73,
                 from dataentry.c:36:
/usr/X11R6/include/X11/keysymdef.h:1181:2: invalid preprocessing
directive #d
make[4]: *** [dataentry.lo] Error 1
make[4]: Leaving directory
`/usr/local/src/compile/R-1.7.1/src/modules/X11'
make[3]: *** [R] Error 2
make[3]: Leaving directory
`/usr/local/src/compile/R-1.7.1/src/modules/X11'
make[2]: *** [R] Error 1
make[2]: Leaving directory `/usr/local/src/compile/R-1.7.1/src/modules'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/usr/local/src/compile/R-1.7.1/src'
make: *** [R] Error 1


Can someone help me on this ?

Thanks

EJ



From dj at research.bell-labs.com  Wed Sep 17 15:51:37 2003
From: dj at research.bell-labs.com (David James)
Date: Wed, 17 Sep 2003 09:51:37 -0400
Subject: [R] Date on x-axis of xyplot
In-Reply-To: <Pine.LNX.4.44.0309170655470.2844-100000@gannet.stats>;
	from ripley@stats.ox.ac.uk on Wed, Sep 17, 2003 at 06:58:48AM
	+0100
References: <200309162331.06832.deepayan@stat.wisc.edu>
	<Pine.LNX.4.44.0309170655470.2844-100000@gannet.stats>
Message-ID: <20030917095137.A16054@jessie.research.bell-labs.com>

Prof Brian Ripley wrote:
> On Tue, 16 Sep 2003, Deepayan Sarkar wrote:
> 
> > Is the date class standard enough to warrant including a check for it in 
> > lattice ?
> 
> I don't think so.  The POSIX*t classes in R are the most standard, 
> followed by the chron package and only then the date package.

If it is not overly complicated to implement, could I timidly suggest
*not* checking for specific classes inside lattice, but rather use
some other kind of mechanism (perhaps invoking helper functions,
or use specific methods, etc.) to render axes?

A common rule-of-thumb among object-oriented programmers (Mark
Lutz in "Programming Python" comes to mind) is to avoid code that
switches explicitly among classes/types of objects -- such code tends
to be hard to extend when new classes of objects are introduced 
(and extremely hard in R, if package bindings are ever locked,
as namespaces may allow already or in the future).

> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
David A. James
Statistics Research, Room 2C-253            Phone:  (908) 582-3082       
Bell Labs, Lucent Technologies              Fax:    (908) 582-3340
Murray Hill, NJ 09794-0636



From mustafa.bas at uni-bielefeld.de  Wed Sep 17 15:53:55 2003
From: mustafa.bas at uni-bielefeld.de (Mustafa Bas)
Date: Wed, 17 Sep 2003 15:53:55 +0200
Subject: [R] mstree
Message-ID: <3F686773.8070702@uni-bielefeld.de>

hello,

i have some problems with mstree!
there are no similar function in R like in S-Plus!
Is there somebody who has a code in R ????

Thanks



From tlumley at u.washington.edu  Wed Sep 17 16:14:58 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 17 Sep 2003 07:14:58 -0700 (PDT)
Subject: [R] Quiz {was "Quit asking me .."}
In-Reply-To: <16232.227.360586.936442@gargle.gargle.HOWL>
Message-ID: <Pine.A41.4.44.0309170714300.115572-100000@homer36.u.washington.edu>

On Wed, 17 Sep 2003, Martin Maechler wrote:

>
> How can you write (quite short!) R code such that
> typing
> 	"Q"
>
> -- without any  "()" -- will quit R (without asking about saving).
>
> [But you shouldn't really keep that code active in your standard R session
>  because it would be too easy to accidentally shut down R !]
>
> For the advanced ones:
> My shortest solution uses 51 characters of R code, can you beat that?
>

Easily

Q<-delay(q("yes"))

	-thomas



From alessandro.valli at AMD.com  Wed Sep 17 16:15:02 2003
From: alessandro.valli at AMD.com (alessandro.valli@AMD.com)
Date: Wed, 17 Sep 2003 16:15:02 +0200
Subject: [R] Very long console input lines
Message-ID: <D1B7EDF38A7CD311A68C0008C72825DF090409E1@deexmta5.amd.com>

Hallo all,

I got a problem executing R in batch-mode via a perl-script (under Win2000) : 
	system ("Rterm.exe --slave --no-save --no-restore \<Rfile.r \>NUL");
The R execution is aborting with syntax error due to very-long lines.
My solution is converting
a <- c("very long string")
to
a <- paste("short string 1",\n
                "short string 2",\n
                      ...,\n
                "short string n")
It is not very elegant ...
Does anybody know a better solution ?

Thank you in advance,
Alessandro Valli



From Torsten.Hothorn at rzmail.uni-erlangen.de  Wed Sep 17 16:20:49 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Wed, 17 Sep 2003 16:20:49 +0200 (CEST)
Subject: [R] R courses in germany
Message-ID: <Pine.LNX.4.51.0309171619090.22601@artemis.imbe.med.uni-erlangen.de>


Starting in November, a short series of R courses will take place
at the University of Hanover. The topics will include

* Introduction to Data Analysis with R
  (T. Hothorn, U. Ligges, A. Zeileis)

* Programming with R
  (K. Hornik, F. Leisch)

* Mixed Models in S
  (J. Pinheiro)

More details are given at

        http://www.bioinf.uni-hannover.de/R-Kurse/

Best,

Torsten

 _______________________________________________________________________
|                                                                       |
|       Dr. rer. nat. Torsten Hothorn                                   |
|       Institut fuer Medizininformatik, Biometrie und Epidemiologie    |
|       Waldstrasse 6, D-91054 Erlangen, Deutschland                    |
|       Tel: ++49-9131-85-22707                                         |
|       Fax: ++49-9131-85-25740                                         |
|       Email: Torsten.Hothorn at rzmail.uni-erlangen.de                   |
|       Web: http://www.imbe.med.uni-erlangen.de/~hothorn               |
|_______________________________________________________________________|



From k_leiderman at hotmail.com  Wed Sep 17 16:22:15 2003
From: k_leiderman at hotmail.com (Karin Leiderman)
Date: Wed, 17 Sep 2003 08:22:15 -0600
Subject: [R]Bivariate Ripley K function
Message-ID: <Law14-F44OMyQlmLFQG00003667@hotmail.com>

Hello,
I have used the univariate Ripley K function in R, but does anyone know if 
there is a bivariate function built in? I have two species that I am dealing 
with.
Also, how might I add error bars into the graphs (univariate and/or 
bivariate)?

Thank you,

Karin Leiderman
k_leiderman at hotmail.com
Graduate Student/Research Assistant
Department of Mathematics
Univesity of New Mexico

_________________________________________________________________
Get 10MB of e-mail storage! Sign up for Hotmail Extra Storage.



From Jesus.Frias at dit.ie  Wed Sep 17 16:35:01 2003
From: Jesus.Frias at dit.ie (Jesus Frias)
Date: Wed, 17 Sep 2003 15:35:01 +0100
Subject: [R] gnls( ) question
In-Reply-To: <940250A9EB37A24CBE28D858EF07774967AB08@ws-bco-mse3.milky-way.battelle.org>
Message-ID: <LGECJJCANFBOOHCMGPJEEEJPCKAA.Jesus.Frias@dit.ie>

Hi Paul,
	The message has to do with the gauss-newton algorithm and it announces that
there will be a failure in convergence. An old version of the algorithm is
in Bates and Watts "Nonlinear regression and its applications" (one of the
appendix).

	When I get that kind of messages, it can mean two things:

1.-The initial estimates that I have provided are not good enough. You can
try to get some good estimates using optim().

2.-The model that I am trying to fit is not appropriate to describe the
data. No straight-forward solution goes for this.

	If you want to fiddle around with the parameters of gnls and try to see if
you reach convergence from your model and starting points, have a look at
the gnls page and the gnlsControl help pages. I think you need to specify
inside your gnls() call

control =gnlsControl(maxIter = 1000, pnlsMaxIter = 200, msMaxIter = 1000,
tolerance = 1e-06, pnlsTol = 1e-04, msTol = 1e-07, minScale = 1e-10,
returnObject = TRUE)


best regards,

IOsu

P.S.: That gnls function is a superb addition to the nonlinear regression
facilities R had before!.

--------------------------------------------------------------
Jes?s Mar?a Fr?as Celayeta
School of Food Sci. and Env. Health.
Faculty of Tourism and Food
Dublin Institute of Technology
Cathal Brugha St., Dublin 1. Ireland
Phone: +353 1 4024459 Fax: +353 1 4024495
http://www.dit.ie/DIT/tourismfood/science/staff/frias.html
--------------------------------------------------------------

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Paul, David A
> Sent: 16 September 2003 16:19
> To: 'r-help at stat.math.ethz.ch'
> Subject: [R] gnls( ) question
>
>
> Last week (Wed 9/10/2003, "regression questions") I posted
> a question regarding the use of gnls( ) and its dissimilarity
> to the syntax that nls( ) will accept.  No one replied, so
> I partly answered my own question by constructing indicator
> variables for use in gnls( ).  The code I used to construct
> the indicators is at the end of this email.
>
> I do have a nagging, unanswered question:
>
> What exactly does "Warning message: Step halving factor
> reduced below minimum in NLS step in: gnls(model = y ~ 5 + ...)"
> mean?  I have tried to address this by specifying "control =
> list(maxIter = 1000, pnlsMaxIter = 200, msMaxIter = 1000,
> tolerance = 1e-06, pnlsTol = 1e-04, msTol = 1e-07, minScale =
> 1e-10, returnObject = TRUE)" in my model calls, but this
> does not entirely eliminate the problem (I am running gnls( )
> 24 separate times on separate data sets).
>
>
> Much thanks in advance,
>   david paul
>
>
>
> #Constructing Indicator Variables
> indicator <- paste( "foo$X <- sapply(foo$subject.id,
> 	FUN = function(x) if(x == X) 1 else 0)" )
> indicator <- parse( text = indicator )[[1]]
> subjectID.foo <- as.factor(as.character(unique(foo$animal.id)))
>
> for(i in subjectID.foo)
> {
> 	INDICATOR <-  do.call("substitute",
> 			list(indicator, list(i = i,
> 				X = as.character(subjectID.foo[i]))))
> 	eval(INDICATOR)
> }
>
> foo$Overall.Effect <- rep(1,length(foo$dose.group))
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
> --
> This message has been scanned for content and
> viruses by the DIT ICT Services MailScanner Service,
> and is believed to be clean.
> http://www.dit.ie
>


-- 
This message has been scanned for content and 
viruses by the DIT ICT Services MailScanner Service, 
and is believed to be clean.
http://www.dit.ie



From tblackw at umich.edu  Wed Sep 17 16:41:13 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Wed, 17 Sep 2003 10:41:13 -0400 (EDT)
Subject: [R] 3D plot/surface rotation
In-Reply-To: <118189537765.20030917143209@power.inescn.pt>
References: <3598558AD728D41183350008C7CF291C0A5CD344@exchange1.ahrq.gov>
	<118189537765.20030917143209@power.inescn.pt>
Message-ID: <Pine.SOL.4.58.0309171033420.3730@rygar.gpcc.itd.umich.edu>

Perhaps MZodet wants the interactive, mouse controlled rotation
capability offered by ggobi <www.ggobi.org> ?  Designed for linux
but advertises "better portability to Microsoft Windows".
I have no experience myself either installing or using this.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

> > Wednesday, September 17, 2003, 2:14:12 PM, MZodet wrote:

> > How do I rotate 3D plots/surfaces generated by either cloud or wireframe?
>
> On Wed, 17 Sep 2003, Mark Marques wrote:
>
> wireframe has the screen parameter which reads a list to rotate ...
> something in this kind:
>
> wireframe(object, screen = list( x = 5, y = 5 , z= 10))
>
> Same with cloud function...
>



From simon at stats.gla.ac.uk  Wed Sep 17 16:49:16 2003
From: simon at stats.gla.ac.uk (Simon Wood)
Date: Wed, 17 Sep 2003 15:49:16 +0100 (BST)
Subject: [R] Re: mgcv 0.9 install
In-Reply-To: <200309171541.05541.mailinglist.wegmann@gmx.net>
Message-ID: <Pine.SOL.3.96.1030917153635.28530K-100000@moon.stats.gla.ac.uk>

> /usr/bin/ld: cannot find -lf77blas
- this is the problem, the linker can't find the basic linear algebra
system library on your machine (I'm surprised R can be built without
this). I think you may need to install the atlas package, but am not sure:
hopefully someone else will know...

Simon



From lamac_k at hotmail.com  Wed Sep 17 16:52:34 2003
From: lamac_k at hotmail.com (lamack lamack)
Date: Wed, 17 Sep 2003 14:52:34 +0000
Subject: [R] all possible samples
Message-ID: <BAY7-F69dbUu2o8q3p9000051ba@hotmail.com>

Dear all, there is an R function that return all possible samples of size n, 
with replacement,  from a vector of length N ?

Best regards



From paulda at BATTELLE.ORG  Wed Sep 17 17:02:21 2003
From: paulda at BATTELLE.ORG (Paul, David  A)
Date: Wed, 17 Sep 2003 11:02:21 -0400
Subject: [R] gnls( ) question
Message-ID: <940250A9EB37A24CBE28D858EF07774967AB0F@ws-bco-mse3.milky-way.battelle.org>

Thank you!  Using "control = gnlsControl(...)" has made
a difference in several of my model calls [no other change
needed, except that gnlsControl(...) does not accept
pnlsTol or pnlsMaxIter options].  For several other model
calls, fiddling with the intial parameter estimates helped.

Best,
  david paul


-----Original Message-----
From: Jesus Frias [mailto:Jesus.Frias at dit.ie] 
Sent: Wednesday, September 17, 2003 10:35 AM
To: Paul, David A; R help
Subject: RE: [R] gnls( ) question


Hi Paul,
	The message has to do with the gauss-newton algorithm and it
announces that there will be a failure in convergence. An old version of the
algorithm is in Bates and Watts "Nonlinear regression and its applications"
(one of the appendix).

	When I get that kind of messages, it can mean two things:

1.-The initial estimates that I have provided are not good enough. You can
try to get some good estimates using optim().

2.-The model that I am trying to fit is not appropriate to describe the
data. No straight-forward solution goes for this.

	If you want to fiddle around with the parameters of gnls and try to
see if you reach convergence from your model and starting points, have a
look at the gnls page and the gnlsControl help pages. I think you need to
specify inside your gnls() call

control =gnlsControl(maxIter = 1000, pnlsMaxIter = 200, msMaxIter = 1000,
tolerance = 1e-06, pnlsTol = 1e-04, msTol = 1e-07, minScale = 1e-10,
returnObject = TRUE)


best regards,

IOsu

P.S.: That gnls function is a superb addition to the nonlinear regression
facilities R had before!.

--------------------------------------------------------------
Jes?s Mar?a Fr?as Celayeta
School of Food Sci. and Env. Health.
Faculty of Tourism and Food
Dublin Institute of Technology
Cathal Brugha St., Dublin 1. Ireland
Phone: +353 1 4024459 Fax: +353 1 4024495
http://www.dit.ie/DIT/tourismfood/science/staff/frias.html
--------------------------------------------------------------

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Paul, David A
> Sent: 16 September 2003 16:19
> To: 'r-help at stat.math.ethz.ch'
> Subject: [R] gnls( ) question
>
>
> Last week (Wed 9/10/2003, "regression questions") I posted
> a question regarding the use of gnls( ) and its dissimilarity to the 
> syntax that nls( ) will accept.  No one replied, so I partly answered 
> my own question by constructing indicator variables for use in gnls( 
> ).  The code I used to construct the indicators is at the end of this 
> email.
>
> I do have a nagging, unanswered question:
>
> What exactly does "Warning message: Step halving factor reduced below 
> minimum in NLS step in: gnls(model = y ~ 5 + ...)" mean?  I have tried 
> to address this by specifying "control = list(maxIter = 1000, 
> pnlsMaxIter = 200, msMaxIter = 1000, tolerance = 1e-06, pnlsTol = 
> 1e-04, msTol = 1e-07, minScale = 1e-10, returnObject = TRUE)" in my 
> model calls, but this does not entirely eliminate the problem (I am 
> running gnls( ) 24 separate times on separate data sets).
>
>
> Much thanks in advance,
>   david paul
>
>
>
> #Constructing Indicator Variables
> indicator <- paste( "foo$X <- sapply(foo$subject.id,
> 	FUN = function(x) if(x == X) 1 else 0)" )
> indicator <- parse( text = indicator )[[1]]
> subjectID.foo <- as.factor(as.character(unique(foo$animal.id)))
>
> for(i in subjectID.foo)
> {
> 	INDICATOR <-  do.call("substitute",
> 			list(indicator, list(i = i,
> 				X = as.character(subjectID.foo[i]))))
> 	eval(INDICATOR)
> }
>
> foo$Overall.Effect <- rep(1,length(foo$dose.group))
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
> --
> This message has been scanned for content and
> viruses by the DIT ICT Services MailScanner Service,
> and is believed to be clean.
> http://www.dit.ie
>


-- 
This message has been scanned for content and 
viruses by the DIT ICT Services MailScanner Service, 
and is believed to be clean.
http://www.dit.ie



From rpeng at jhsph.edu  Wed Sep 17 17:03:36 2003
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 17 Sep 2003 11:03:36 -0400
Subject: [R]Bivariate Ripley K function
In-Reply-To: <Law14-F44OMyQlmLFQG00003667@hotmail.com>
References: <Law14-F44OMyQlmLFQG00003667@hotmail.com>
Message-ID: <3F6877C8.2050307@jhsph.edu>

I believe the `splancs' package from CRAN has a bivariate K function.  
For error bars you'll probably have to use Monte Carlo methods.  
`splancs' has some tools for that.

-roger

Karin Leiderman wrote:

> Hello,
> I have used the univariate Ripley K function in R, but does anyone 
> know if there is a bivariate function built in? I have two species 
> that I am dealing with.
> Also, how might I add error bars into the graphs (univariate and/or 
> bivariate)?
>
> Thank you,
>
> Karin Leiderman
> k_leiderman at hotmail.com
> Graduate Student/Research Assistant
> Department of Mathematics
> Univesity of New Mexico
>
> _________________________________________________________________
> Get 10MB of e-mail storage! Sign up for Hotmail Extra Storage.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Together, we can stop attaching Word documents
http://www.fsf.org/philosophy/no-word-attachments.html



From ripley at stats.ox.ac.uk  Wed Sep 17 17:11:44 2003
From: ripley at stats.ox.ac.uk (Brian D Ripley)
Date: Wed, 17 Sep 2003 16:11:44 +0100 (BST)
Subject: [R] 3D plot/surface rotation
In-Reply-To: <Pine.SOL.4.58.0309171033420.3730@rygar.gpcc.itd.umich.edu>
Message-ID: <Pine.GSO.4.31.0309171607290.17360-100000@markov.stats>

On Wed, 17 Sep 2003, Thomas W Blackwell wrote:

> Perhaps MZodet wants the interactive, mouse controlled rotation
> capability offered by ggobi <www.ggobi.org> ?  Designed for linux
> but advertises "better portability to Microsoft Windows".
> I have no experience myself either installing or using this.

It doesn't cover surfaces AFAIK.  There are R-GL packages which do allow
user-controlled rotations of surfaces (and more).  Another possibility is
to write some widget (e.g. in Tcl/Tk) to control the screen argument, and
replot when the argument is changed (as the tkdensity demo does).  Under
Windows, the latter works a lot better in 1.8.0 alpha which has buffering.

>
> -  tom blackwell  -  u michigan medical school  -  ann arbor  -
>
> > > Wednesday, September 17, 2003, 2:14:12 PM, MZodet wrote:
>
> > > How do I rotate 3D plots/surfaces generated by either cloud or wireframe?
> >
> > On Wed, 17 Sep 2003, Mark Marques wrote:
> >
> > wireframe has the screen parameter which reads a list to rotate ...
> > something in this kind:
> >
> > wireframe(object, screen = list( x = 5, y = 5 , z= 10))
> >
> > Same with cloud function...
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From ligges at statistik.uni-dortmund.de  Wed Sep 17 17:12:48 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 17 Sep 2003 17:12:48 +0200
Subject: [R] 3D plot/surface rotation
In-Reply-To: <Pine.SOL.4.58.0309171033420.3730@rygar.gpcc.itd.umich.edu>
References: <3598558AD728D41183350008C7CF291C0A5CD344@exchange1.ahrq.gov>	<118189537765.20030917143209@power.inescn.pt>
	<Pine.SOL.4.58.0309171033420.3730@rygar.gpcc.itd.umich.edu>
Message-ID: <3F6879F0.7000103@statistik.uni-dortmund.de>

Thomas W Blackwell wrote:

> Perhaps MZodet wants the interactive, mouse controlled rotation
> capability offered by ggobi <www.ggobi.org> ?  Designed for linux
> but advertises "better portability to Microsoft Windows".
> I have no experience myself either installing or using this.

In that case we might want to point MZodet to the packages
"djmrgl" (only on Windows, by Duncan Murdoch, 
http://www.stats.uwo.ca/faculty/murdoch/software/default.htm) and "rgl" 
(don't know its current state of development, by D. Adler and O. 
Nenadic, http://wsopuppenkiste.wiso.uni-goettingen.de/~dadler/rgl/) as well.

Uwe Ligges


> -  tom blackwell  -  u michigan medical school  -  ann arbor  -
> 
> 
>>>Wednesday, September 17, 2003, 2:14:12 PM, MZodet wrote:
> 
> 
>>>How do I rotate 3D plots/surfaces generated by either cloud or wireframe?
>>
>>On Wed, 17 Sep 2003, Mark Marques wrote:
>>
>>wireframe has the screen parameter which reads a list to rotate ...
>>something in this kind:
>>
>>wireframe(object, screen = list( x = 5, y = 5 , z= 10))
>>
>>Same with cloud function...
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From cathey.tommy at epa.gov  Wed Sep 17 17:21:54 2003
From: cathey.tommy at epa.gov (Tommy E. Cathey)
Date: Wed, 17 Sep 2003 11:21:54 -0400
Subject: [R] size of text when using vfont option
Message-ID: <3F687C12.D004CEEC@epa.gov>

How can I determine the size of a text string when using
the vfont option?

For example:
text(6, 6, "My Text String",vfont=c("sans serif", "plain"))


--
Tommy E. Cathey, Senior Scientific Application Consultant
High Performance Computing & Scientific Visualization
SAIC, Supporting the EPA
Research Triangle Park, NC
919-541-1500 EMail: cathey.tommy at epa.gov
My e-mail does not reflect the opinion of SAIC or the EPA.

Federal Contact - John B. Smith
919-541-1087    - smith.johnb at epa.gov



From bkrith at conrel.sice.umkc.edu  Wed Sep 17 17:40:52 2003
From: bkrith at conrel.sice.umkc.edu (Balaji Krithikaivasan)
Date: Wed, 17 Sep 2003 10:40:52 -0500 (CDT)
Subject: [R] A question on seasonal time series - R package
Message-ID: <Pine.LNX.4.33.0309171038370.29267-100000@Net_Server>

Hi there,
  I am using the "ts" class of the "R" package. I have a data file 
containing a time series of 1152 entries. It is actually 4 days data 
cascaded together where the time interval of data collected is 5 minutes. 
Thus, I have 288 values per day.

   When I am trying to fit this data using a period of 288 with a 
seasonal model, using the 
arima(...) function, I am getting error message "Error: makeARIMA(...): 
negative length vectors are not allowed". I am not sure what is the 
problem. I really appreciate some help on this. Thanks in advance.

-Balaji. 
-- 
"Two roads diverged in a wood and I took the one less traveled by and,
			that has made all the difference" -- Robert Frost

Balaji Krithikaivasan (PhD Student),
[Co]mputer [N]etworking [Re]search [L]ab (CoNReL)



From abunn at mymail.msu.montana.edu  Wed Sep 17 18:00:19 2003
From: abunn at mymail.msu.montana.edu (abunn@mymail.msu.montana.edu)
Date: Wed, 17 Sep 2003 10:00:19 -0600
Subject: [R] Generating a point pattern
Message-ID: <6762620884dd4a44919d2166882f2c8b.abunn@mymail.msu.montana.edu>

 
I have a stem map of trees that are different from CSR at distances of 10-15 meters on a hectare plot. There are about 100 stems per ha.

I want to generate a point pattern that replicates this for a model. So, about 100 trees in a 100 x 100 space that are clustered at distances from 10-15 meters.

Is this possible in R? Is there something similar to make.pattern in S+? I've been messing with splancs but since I don't want a cluster process (at least I don't think I do), I'm a bit lost.



From tplate at blackmesacapital.com  Wed Sep 17 18:07:35 2003
From: tplate at blackmesacapital.com (Tony Plate)
Date: Wed, 17 Sep 2003 10:07:35 -0600
Subject: Just don't do it, surely? (was RE: [R] Retrieve ...
	argument values)
In-Reply-To: <6C8A8033ABC1E3468048ABC4F13CE572AC0DD4@synequanon01>
Message-ID: <5.2.1.1.2.20030917095712.049ea108@mailhost.blackmesacapital.com>

At Wednesday 11:19 AM 9/17/2003 +0100, Simon Fear wrote:
>There have been various elegant solutions to test for the presence
>of a particular named parameter within a ... argument, such as
>
>if (!is.null(list(...)$ylim))
>if ("ylim" %in% names(list(...)))
>
>I think I'd have to comment these lines pretty clearly if I wanted
>to easily follow the code in 6 months time.
>
>But I'm still not convinced it is ever a good idea to use this
>technique in preference to using explicit named arguments. If
>there is something special about "ylim", why insist that it be
>passed within  "..." in the first place? Surely it's better
>to define the function as function(x,ylim=default,...) within which
>you do your special ylim stuff, then call plot(x, ylim=ylim,...))??
>
>Can anyone come up with a good reason not to follow
>that principle? I think my earlier post may have been
>misconstrued: I'm not saying "never write functions that use ...",
>I'm just saying "never write functions that depend on a particular
>argument being passed via ...".

Several reasons for not following that principle involve proliferation of 
defaults -- if the lower level functions have defaults, then those defaults 
must be repeated at the higher levels.  This is a good reason for not 
following that principle, because it makes software maintenance more 
difficult.  Another reason for not following that principle is that tf you 
have several lower level functions with different default values for an 
argument of the same name, it becomes impossible to get the lower-level 
default behavior.

-- Tony Plate



From Junk.Mail.Trap at NOT.real.COM  Wed Sep 17 18:08:23 2003
From: Junk.Mail.Trap at NOT.real.COM (Simon Lin)
Date: Wed, 17 Sep 2003 12:08:23 -0400
Subject: [R] R compiled on IBM p690?
Message-ID: <BAY2-DAV42whnCxsAE000005952@hotmail.com>

Hello,

We had all kinds of trouble of compiling/running R correctly on IBM p690.

Anybody have successfully experience and would like to share with us?

Please reply me personally (see my email address below), since I am not
subscribing this mailing list.

Thanks a lot!

Simon


=================================================
  Simon M. Lin, M.D.
  Assistant Research Professor of Biostatistics and Bioinformatics
  and Manager of Duke Bioinformatics Shared Resource
  Box 3958, Duke University Medical Center
  Durham, NC 27710
  Ph: (919) 681-9646 FAX: (919) 681-8028
  Lin00025 (at) mc.duke.edu
  http://dbsr.duke.edu



From apjaworski at mmm.com  Wed Sep 17 18:15:05 2003
From: apjaworski at mmm.com (apjaworski@mmm.com)
Date: Wed, 17 Sep 2003 11:15:05 -0500
Subject: [R] all possible samples
Message-ID: <OF3676EDAD.38B1CC8D-ON86256DA4.00558F87-86256DA4.005945C1@mmm.com>


I am not sure if this is the easiest way, but you can do something like
this:

library(gregmisc)
combinations(N, n, x, repeats=TRUE)

where x is an atomic vector of size N.  The only restriction is that the x
vector has to have N unique elements.  The combinations function will
return a matrix with n columns containing the combinations.

The combinations function is defined recursively.  Even for moderate values
of N and n it will either take a long time or bomb out with the "evaluation
is nested too deeply" error.  For example, on my modest machine (PIII 1GHz
with 1/5 Gbyte of memory) it takes almost a minute to evaluate

combinations(30, 6, repeats=TRUE)   (1623160 combinations)

and

combinations(44, 2, repeats=TRUE)   (only 990 combinations)

bombs out.

If you need to work with larger numbers you will probably need a sequential
code.

Hope this helps,

Andy


__________________________________
Andy Jaworski
Engineering Systems Technology Center
3M Center, 518-1-01
St. Paul, MN 55144-1000
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122


|---------+-------------------------------->
|         |           "lamack lamack"      |
|         |           <lamac_k at hotmail.com>|
|         |           Sent by:             |
|         |           r-help-bounces at stat.m|
|         |           ath.ethz.ch          |
|         |                                |
|         |                                |
|         |           09/17/2003 09:52     |
|         |                                |
|---------+-------------------------------->
  >-----------------------------------------------------------------------------------------------------------------------------|
  |                                                                                                                             |
  |      To:       R-help at stat.math.ethz.ch                                                                                     |
  |      cc:                                                                                                                    |
  |      Subject:  [R] all possible samples                                                                                     |
  >-----------------------------------------------------------------------------------------------------------------------------|




Dear all, there is an R function that return all possible samples of size
n,
with replacement,  from a vector of length N ?

Best regards

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Simon.Fear at synequanon.com  Wed Sep 17 18:25:55 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Wed, 17 Sep 2003 17:25:55 +0100
Subject: Just don't do it,
	surely? (was RE: [R] Retrieve ...  argument values)
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572AC0DDA@synequanon01>

Tony, I don't understand what you mean. Could you give
an example?

> -----Original Message-----
> From: Tony Plate [mailto:tplate at blackmesacapital.com]
> > ... I'm not saying "never write functions that use ...",
> >I'm just saying "never write functions that depend on a particular
> >argument being passed via ...".
> 
> Several reasons for not following that principle involve proliferation
> of 
> defaults -- if the lower level functions have defaults, then those
> defaults 
> must be repeated at the higher levels.  
> This is a good reason for not 
> following that principle, because it makes software maintenance more 
> difficult.  

I don't think I agree with that (though maybe I just didn't
get it). I prefer to know what arguments a function is going
to use.

> Another reason for not following that principle is that tf
> you 
> have several lower level functions with different default 
> values for an 
> argument of the same name, it becomes impossible to get the 
> lower-level 
> default behavior.

I'm lost there. When I choose which function to call it has
its own default??

I often call a function of mine called timepoints.summary for which I
want
to pass graphical parameters to boxplots, matplots and confidence
interval plots. So I name the arguments cex.boxplot, col.boxplot etc
and then within the function I call boxplot(x, cex=boxplot.cex) and so
on. I wouldn't expect a single argument "cex" to magically work out
whether it was being used in a boxplot or matplot and change
to a different default??
 

Simon Fear
Senior Statistician
Syne qua non Ltd
Tel: +44 (0) 1379 644449
Fax: +44 (0) 1379 644445
email: Simon.Fear at synequanon.com
web: http://www.synequanon.com
 
Number of attachments included with this message: 0
 
This message (and any associated files) is confidential and\...{{dropped}}



From hodgess at gator.dt.uh.edu  Wed Sep 17 18:31:40 2003
From: hodgess at gator.dt.uh.edu (Erin Hodgess)
Date: Wed, 17 Sep 2003 11:31:40 -0500
Subject: [R] mandelbrot set
Message-ID: <200309171631.h8HGVeL20718@gator.dt.uh.edu>

The mandelbrot set is totally cool!

Thanks to the generator (couldn't find his/her names!)

Sincerely,
Erin
mailto: hodgess at gator.uhd.edu



From josep.perarnau at upc.es  Wed Sep 17 18:36:38 2003
From: josep.perarnau at upc.es (Josep Perarnau)
Date: Wed, 17 Sep 2003 18:36:38 +0200
Subject: [R] plotting in the same figure
Message-ID: <000f01c37d39$ddb96af0$01000001@BAETULO>

Hello,

Do you know if it's possible to create a plot as in matlab with the
options hold on and hold off? 
For example I want to plot in the same figure the theoric cdf of the
normal distribution and the empiric cdf from the raw data.

Thank you,
Josep.



From andy_liaw at merck.com  Wed Sep 17 18:42:03 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 17 Sep 2003 12:42:03 -0400
Subject: [R] plotting in the same figure
Message-ID: <3A822319EB35174CA3714066D590DCD50205CB48@usrymx25.merck.com>

Look at the argument "new" under ?par.

Probably better way is to use the following sequence:

plot(...)   # whatever your first plot is.
lines(...)  # add line to the existing plot.
points(...) # add points to the existing plot.

There are many other functions that add to the existing plot.

HTH,
Andy

> -----Original Message-----
> From: Josep Perarnau [mailto:josep.perarnau at upc.es] 
> Sent: Wednesday, September 17, 2003 12:37 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] plotting in the same figure
> 
> 
> Hello,
> 
> Do you know if it's possible to create a plot as in matlab 
> with the options hold on and hold off? 
> For example I want to plot in the same figure the theoric cdf 
> of the normal distribution and the empiric cdf from the raw data.
> 
> Thank you,
> Josep.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
>



From spencer.graves at pdf.com  Wed Sep 17 18:45:30 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 17 Sep 2003 09:45:30 -0700
Subject: [R] Very long console input lines
In-Reply-To: <D1B7EDF38A7CD311A68C0008C72825DF090409E1@deexmta5.amd.com>
References: <D1B7EDF38A7CD311A68C0008C72825DF090409E1@deexmta5.amd.com>
Message-ID: <3F688FAA.8070608@pdf.com>

Have you considered enclosing the "very long string" in parentheses?  
Then R will know that it is not syntactically correct until it reaches 
the end.  To avoid that kind of thing, I routinely include "(" just to 
the right of "<-" in virtually any statement that might otherwise get 
split onto two lines in a way that the first might be evaluated without 
the second. 

hope this helps.  spencer graves
p.s.  I got this from Venables and Ripley, but I can't remember which 
book or which page. 

alessandro.valli at AMD.com wrote:

>Hallo all,
>
>I got a problem executing R in batch-mode via a perl-script (under Win2000) : 
>	system ("Rterm.exe --slave --no-save --no-restore \<Rfile.r \>NUL");
>The R execution is aborting with syntax error due to very-long lines.
>My solution is converting
>a <- c("very long string")
>to
>a <- paste("short string 1",\n
>                "short string 2",\n
>                      ...,\n
>                "short string n")
>It is not very elegant ...
>Does anybody know a better solution ?
>
>Thank you in advance,
>Alessandro Valli
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From tplate at blackmesacapital.com  Wed Sep 17 18:59:43 2003
From: tplate at blackmesacapital.com (Tony Plate)
Date: Wed, 17 Sep 2003 10:59:43 -0600
Subject: Just don't do it, surely? (was RE: [R] Retrieve ... 
	argument values)
In-Reply-To: <6C8A8033ABC1E3468048ABC4F13CE572AC0DDA@synequanon01>
Message-ID: <5.2.1.1.2.20030917104934.04a3db38@mailhost.blackmesacapital.com>

Simon, I agree, for some (maybe most) arguments it is good to know what 
defaults are being used.  But there are some for which I really don't want 
to know.  An example of the latter is arguments that control interaction 
with a database.  Suppose I have a low-level interaction function that 
takes an argument 'db.mode', where this specifies a way of interacting with 
the database.  Now, if I also have a higher level function that gets data 
from the database I might write:

db.get.high.level.data <- function(what, ...) {
      processed.what <- do something to 'what'
      db.get.low.level.data(processed.what, ...)
}

db.get.low.level.data(what, db.mode=2) {
      # fetch the data
}

By using ... arguments I can specify a db.mode argument to the higher level 
function, or just get the default provided in the lower level function.  If 
I then change the lower level function to provide a better mode of 
interaction I can make that mode the default in the lower level function, 
and be confident it will be used everywhere.  But if I specify the defaults 
in both places, then changing defaults becomes a big task.

As for the second point regarding different functions having different 
defaults for an argument of the same name, it can certainly be handled as 
you describe by making different argument names in the higher level function.

-- Tony Plate

At Wednesday 05:25 PM 9/17/2003 +0100, Simon Fear wrote:
>Tony, I don't understand what you mean. Could you give
>an example?
>
> > -----Original Message-----
> > From: Tony Plate [mailto:tplate at blackmesacapital.com]
> > > ... I'm not saying "never write functions that use ...",
> > >I'm just saying "never write functions that depend on a particular
> > >argument being passed via ...".
> >
> > Several reasons for not following that principle involve proliferation
> > of
> > defaults -- if the lower level functions have defaults, then those
> > defaults
> > must be repeated at the higher levels.
> > This is a good reason for not
> > following that principle, because it makes software maintenance more
> > difficult.
>
>I don't think I agree with that (though maybe I just didn't
>get it). I prefer to know what arguments a function is going
>to use.
>
> > Another reason for not following that principle is that tf
> > you
> > have several lower level functions with different default
> > values for an
> > argument of the same name, it becomes impossible to get the
> > lower-level
> > default behavior.
>
>I'm lost there. When I choose which function to call it has
>its own default??
>
>I often call a function of mine called timepoints.summary for which I
>want
>to pass graphical parameters to boxplots, matplots and confidence
>interval plots. So I name the arguments cex.boxplot, col.boxplot etc
>and then within the function I call boxplot(x, cex=boxplot.cex) and so
>on. I wouldn't expect a single argument "cex" to magically work out
>whether it was being used in a boxplot or matplot and change
>to a different default??
>
>
>Simon Fear
>Senior Statistician
>Syne qua non Ltd
>Tel: +44 (0) 1379 644449
>Fax: +44 (0) 1379 644445
>email: Simon.Fear at synequanon.com
>web: http://www.synequanon.com
>
>Number of attachments included with this message: 0
>
>This message (and any associated files) is confidential and
>contains information which may be legally privileged.  It is
>intended for the stated addressee(s) only.  Access to this
>email by anyone else is unauthorised.  If you are not the
>intended addressee, any action taken (or not taken) in
>reliance on it, or any disclosure or copying of the contents of
>it is unauthorised and unlawful.  If you are not the addressee,
>please inform the sender immediately and delete the email
>from your system.
>
>This message and any associated attachments have been
>checked for viruses using an internationally recognised virus
>detection process.  However, Internet communications cannot
>be guaranteed to be secure or error-free as information could
>be intercepted, corrupted, lost, destroyed, arrive late or
>incomplete. Therefore, we do not accept responsibility for any
>errors or omissions that are present in this message, or any
>attachment, that have arisen as a result of e-mail transmission.
>If verification is required, please request a hard-copy version.
>Any views or opinions presented are solely those of the author
>and do not necessarily represent those of Syne qua non.



From pingping.zheng at lancaster.ac.uk  Wed Sep 17 19:12:27 2003
From: pingping.zheng at lancaster.ac.uk (Pingping Zheng)
Date: Wed, 17 Sep 2003 18:12:27 +0100
Subject: [R] Re: mgcv 0.9 install
In-Reply-To: <Pine.SOL.3.96.1030917153635.28530K-100000@moon.stats.gla.ac.uk>
References: <Pine.SOL.3.96.1030917153635.28530K-100000@moon.stats.gla.ac.uk>
Message-ID: <3F6895FB.5010507@lancs.ac.uk>

It works for me. The last link command is:
gcc -shared -L/usr/local/lib -o mgcv.so gcv.o magic.o mat.o matrix.o
mgcv.o qp.o tprs.o -llapack -lblas ...
I have NOT got libf77blas in my linux system either but I have got
libblas.a and libblas.so and
the linker find the right library libblas to link.

Pingping


Simon Wood wrote:
>>/usr/bin/ld: cannot find -lf77blas
> 
> - this is the problem, the linker can't find the basic linear algebra
> system library on your machine (I'm surprised R can be built without
> this). I think you may need to install the atlas package, but am not sure:
> hopefully someone else will know...
> 
> Simon
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From bolker at zoo.ufl.edu  Wed Sep 17 19:40:55 2003
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Wed, 17 Sep 2003 13:40:55 -0400 (EDT)
Subject: [R] 3D plot/surface rotation
In-Reply-To: <Pine.GSO.4.31.0309171607290.17360-100000@markov.stats>
Message-ID: <Pine.LNX.4.44.0309171338470.22202-100000@bolker.zoo.ufl.edu>


  Another possibility (to plug my own stuff) is to use the "LG3d" package 
in my bbmisc package (http://www.zoo.ufl.edu/bolker/R/src for source, 
http://www.zoo.ufl.edu/bolker/R/windows/ for precompiled windows package), 
which uses the Live3D java applet to display (rotatable etc.) graphics in 
a web browser.  Not as good as x/ggobi for interaction with data, but 
possibly OK for display.

  Ben Bolker

On Wed, 17 Sep 2003, Brian D Ripley wrote:

> On Wed, 17 Sep 2003, Thomas W Blackwell wrote:
> 
> > Perhaps MZodet wants the interactive, mouse controlled rotation
> > capability offered by ggobi <www.ggobi.org> ?  Designed for linux
> > but advertises "better portability to Microsoft Windows".
> > I have no experience myself either installing or using this.
> 
> It doesn't cover surfaces AFAIK.  There are R-GL packages which do allow
> user-controlled rotations of surfaces (and more).  Another possibility is
> to write some widget (e.g. in Tcl/Tk) to control the screen argument, and
> replot when the argument is changed (as the tkdensity demo does).  Under
> Windows, the latter works a lot better in 1.8.0 alpha which has buffering.
> 
> >
> > -  tom blackwell  -  u michigan medical school  -  ann arbor  -
> >
> > > > Wednesday, September 17, 2003, 2:14:12 PM, MZodet wrote:
> >
> > > > How do I rotate 3D plots/surfaces generated by either cloud or wireframe?
> > >
> > > On Wed, 17 Sep 2003, Mark Marques wrote:
> > >
> > > wireframe has the screen parameter which reads a list to rotate ...
> > > something in this kind:
> > >
> > > wireframe(object, screen = list( x = 5, y = 5 , z= 10))
> > >
> > > Same with cloud function...
> > >
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From coate111956 at yahoo.com  Wed Sep 17 19:30:07 2003
From: coate111956 at yahoo.com (Bruce Coate)
Date: Wed, 17 Sep 2003 10:30:07 -0700 (PDT)
Subject: [R] Transpose Data Frame Question
Message-ID: <20030917173007.55507.qmail@web80601.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030917/83f556ce/attachment.pl

From B.Rowlingson at lancaster.ac.uk  Wed Sep 17 19:36:37 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 17 Sep 2003 18:36:37 +0100
Subject: [R]Bivariate Ripley K function
In-Reply-To: <3F6877C8.2050307@jhsph.edu>
References: <Law14-F44OMyQlmLFQG00003667@hotmail.com>
	<3F6877C8.2050307@jhsph.edu>
Message-ID: <3F689BA5.3050408@lancaster.ac.uk>

Roger D. Peng wrote:
> I believe the `splancs' package from CRAN has a bivariate K function.  
> For error bars you'll probably have to use Monte Carlo methods.  
> `splancs' has some tools for that.

  See also 'spatstat' for Kmulti and Kcross.

  Since R doesn't have a univariate K-function in the base or 
recommended packages I'm wondering which package the original poster got 
univariate K-function from. I suspect their friendly sysop installed 
splancs or spatstat.

Baz



From apjaworski at mmm.com  Wed Sep 17 19:49:00 2003
From: apjaworski at mmm.com (apjaworski@mmm.com)
Date: Wed, 17 Sep 2003 12:49:00 -0500
Subject: [R] Transpose Data Frame Question
Message-ID: <OF79E4EC7D.171AD836-ON86256DA4.00618409-86256DA4.0061DF04@mmm.com>


Here is a brute force way:

mm <- NULL
for(i in unique(ID)){
   zz <- data.frame[ID==i, 3]
   mm <- rbind(mm, c(i, zz))
}

It will work as long as you have the same number of tests for each ID.  If
not, you would need to pad shorter zz vectors with NAs.

Cheers,

Andy

__________________________________
Andy Jaworski
Engineering Systems Technology Center
3M Center, 518-1-01
St. Paul, MN 55144-1000
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122


|---------+-------------------------------->
|         |           Bruce Coate          |
|         |           <coate111956 at yahoo.co|
|         |           m>                   |
|         |           Sent by:             |
|         |           r-help-bounces at stat.m|
|         |           ath.ethz.ch          |
|         |                                |
|         |                                |
|         |           09/17/2003 12:30     |
|         |                                |
|---------+-------------------------------->
  >-----------------------------------------------------------------------------------------------------------------------------|
  |                                                                                                                             |
  |      To:       r-help at stat.math.ethz.ch                                                                                     |
  |      cc:                                                                                                                    |
  |      Subject:  [R] Transpose Data Frame Question                                                                            |
  >-----------------------------------------------------------------------------------------------------------------------------|




Hi,

I have a data.frame that has 3 columns (ID, Test, Result) and looks like
this

1, Test1, 120
1, Test2, 34
2, Test1, 132
2, Test2, 28
etc

I would like to turn it around so that it looks like this

1, 120, 34
2, 132, 28
etc

I have played around some with t and reshape, but with no success.
Any suggestions or hints would be greatly appreciated.
Thanks,
Bruce


---------------------------------


             [[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From bih at ornl.gov  Wed Sep 17 20:02:58 2003
From: bih at ornl.gov (Bing Zhang)
Date: Wed, 17 Sep 2003 14:02:58 -0400
Subject: [R] using matrix data for function
Message-ID: <3F652F2B@webmail1>

Hi All,

I have a function, f(x,y)
I have a matrix of data, m,  with the 1st column is x and the 2nd column is y
What's the best way to get f(x,y) for each row of the matrix?
I tried 
result<-f(m[,1],m[,2]) but it doesn't work.

Thanks!

Bing

---------------------------------
1060 Commerce Park
Oak Ridge National Laboratory
P.O. Box 2008, MS 6480
Oak Ridge, TN 37831-6480
Phone: 865-241-0761
Email: zhangb at ornl.gov



From andy_liaw at merck.com  Wed Sep 17 20:08:05 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 17 Sep 2003 14:08:05 -0400
Subject: [R] Transpose Data Frame Question
Message-ID: <3A822319EB35174CA3714066D590DCD50205CB4A@usrymx25.merck.com>

Isn't this what you want?

> x <- data.frame(id=rep(1:2, each=2), test = rep(c("test1","test2"), 2), 
+                 score = c(120, 34, 132, 28))
> x
  id  test score
1  1 test1   120
2  1 test2    34
3  2 test1   132
4  2 test2    28
> reshape(x, timevar="test", direction="wide")
  id score.test1 score.test2
1  1         120          34
3  2         132          28


HTH,
Andy 

> -----Original Message-----
> From: Bruce Coate [mailto:coate111956 at yahoo.com] 
> Sent: Wednesday, September 17, 2003 1:30 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Transpose Data Frame Question
> 
> 
> Hi,
>  
> I have a data.frame that has 3 columns (ID, Test, Result) and 
> looks like this
>  
> 1, Test1, 120
> 1, Test2, 34
> 2, Test1, 132
> 2, Test2, 28
> etc
>  
> I would like to turn it around so that it looks like this
>  
> 1, 120, 34
> 2, 132, 28
> etc
>  
> I have played around some with t and reshape, but with no success. 
> Any suggestions or hints would be greatly appreciated.
> Thanks,
> Bruce
> 
> 
> ---------------------------------
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
>



From uth at zhwin.ch  Wed Sep 17 20:16:24 2003
From: uth at zhwin.ch (=?utf-8?Q?=22Untern=C3=A4hrer_Thomas=2C_uth=22?=)
Date: Wed, 17 Sep 2003 20:16:24 +0200
Subject: AW: [R] using matrix data for function
Message-ID: <53A181E56FB0694ABFD212F8AEDA7F6F1AB882@langouste.zhwin.ch>

I'm not sure if that's the best way
 
apply(MAT, 1, FUN)
 
 

	-----Urspr?ngliche Nachricht----- 
	Von: Bing Zhang [mailto:bih at ornl.gov] 
	Gesendet: Mi 17.09.2003 20:02 
	An: r-help 
	Cc: 
	Betreff: [R] using matrix data for function
	
	

	Hi All,
	
	I have a function, f(x,y)
	I have a matrix of data, m,  with the 1st column is x and the 2nd column is y
	What's the best way to get f(x,y) for each row of the matrix?
	I tried
	result<-f(m[,1],m[,2]) but it doesn't work.
	
	Thanks!
	
	Bing
	
	---------------------------------
	1060 Commerce Park
	Oak Ridge National Laboratory
	P.O. Box 2008, MS 6480
	Oak Ridge, TN 37831-6480
	Phone: 865-241-0761
	Email: zhangb at ornl.gov
	
	______________________________________________
	R-help at stat.math.ethz.ch mailing list
	https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From juli at ceam.es  Wed Sep 17 20:27:49 2003
From: juli at ceam.es (juli g. pausas)
Date: Wed, 17 Sep 2003 20:27:49 +0200
Subject: [R] the name of a variable in a function
Message-ID: <3F68A7A5.6030203@ceam.es>

Dear collegues,
How can I get the name of a variable (and not the variable) within a 
function ?
For instance, in the following function, I'd like to create a variable 
in the dataframe df with the same name to the variable passed in var:


prova <- function( var )
{
  df <- as.data.frame(matrix(nr=20,nc=0))
  df[["here"]] <- seq(min(var), max(var), le= 20)   #
  df
}

for instance,

a <- 1:50
prova(a)

should give a dataframe with a variable called a (df$a)
Thanks in advance

Juli



From bih at ornl.gov  Wed Sep 17 20:41:25 2003
From: bih at ornl.gov (Bing Zhang)
Date: Wed, 17 Sep 2003 14:41:25 -0400
Subject: [R] using matrix data for function
Message-ID: <3F653AD7@webmail1>

Thanks. How about I have a third parameter for the function, which is a fixed 
object? i.e. the function is f(o,x,y)

Bing

>===== Original Message From james.holtman at convergys.com =====
>Assuming that f(x,y) is not vectorize, try
>
>apply(your.matrix, 1, function(x) f(x[1], x[2]))
>
>as in:
>
>> x.1 <- matrix(1:12,ncol=2)
>> x.1
>     [,1] [,2]
>[1,]    1    7
>[2,]    2    8
>[3,]    3    9
>[4,]    4   10
>[5,]    5   11
>[6,]    6   12
>> x.f <- function(x,y) x+y
>> apply(x.1, 1, function(x) x.f(x[1], x[2]))
>[1]  8 10 12 14 16 18
>>
>__________________________________________________________
>James Holtman        "What is the problem you are trying to solve?"
>Executive Consultant  --  Office of Technology, Convergys
>james.holtman at convergys.com
>(513) 723-2929
>
>
>
>                      Bing Zhang
>                      <bih at ornl.gov>               To:       r-help 
<r-help at stat.math.ethz.ch>
>                      Sent by:                     cc:
>                      r-help-bounces at stat.m        Subject:  [R] using matrix 
data for function
>                      ath.ethz.ch
>
>
>                      09/17/2003 14:02
>
>
>
>
>
>
>Hi All,
>
>I have a function, f(x,y)
>I have a matrix of data, m,  with the 1st column is x and the 2nd column is
>y
>What's the best way to get f(x,y) for each row of the matrix?
>I tried
>result<-f(m[,1],m[,2]) but it doesn't work.
>
>Thanks!
>
>Bing
>
>---------------------------------
>1060 Commerce Park
>Oak Ridge National Laboratory
>P.O. Box 2008, MS 6480
>Oak Ridge, TN 37831-6480
>Phone: 865-241-0761
>Email: zhangb at ornl.gov
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
>
>
>--
>"NOTICE:  The information contained in this electronic mail transmission is
>intended by Convergys Corporation for the use of the named individual or
>entity to which it is directed and may contain information that is
>privileged or otherwise confidential.  If you have received this electronic
>mail transmission in error, please delete it from your system without
>copying or forwarding it, and notify the sender of the error by reply email
>or by telephone (collect), so that the sender's address records can be
>corrected."

---------------------------------
1060 Commerce Park
Oak Ridge National Laboratory
P.O. Box 2008, MS 6480
Oak Ridge, TN 37831-6480
Phone: 865-241-0761
Email: zhangb at ornl.gov



From andy_liaw at merck.com  Wed Sep 17 20:46:33 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 17 Sep 2003 14:46:33 -0400
Subject: [R] using matrix data for function
Message-ID: <3A822319EB35174CA3714066D590DCD50205CB4B@usrymx25.merck.com>

Don't think this is "best", but here's one way:

> mat <- matrix(1:12, 6)
> mat
     [,1] [,2]
[1,]    1    7
[2,]    2    8
[3,]    3    9
[4,]    4   10
[5,]    5   11
[6,]    6   12
> f <- function(x, y) x + y
> apply(mat, 1, function(x) do.call("f", as.list(x)))
[1]  8 10 12 14 16 18

Note that apply(mat, 1, f) won't work, because both values are passed to f
in a single vector.

Perhaps better alternatives are:

1. Re-write f so that it takes a single vector of two elements, or write a
wrapper fw <- function(x) f(x[1], x[2]), then use fw in apply().

2. Re-write f so that it's vectorized, so that f(mat[,1], fmat[,2]) works.

HTH,
Andy


> -----Original Message-----
> From: Bing Zhang [mailto:bih at ornl.gov] 
> Sent: Wednesday, September 17, 2003 2:03 PM
> To: r-help
> Subject: [R] using matrix data for function
> 
> 
> Hi All,
> 
> I have a function, f(x,y)
> I have a matrix of data, m,  with the 1st column is x and the 
> 2nd column is y What's the best way to get f(x,y) for each 
> row of the matrix? I tried 
> result<-f(m[,1],m[,2]) but it doesn't work.
> 
> Thanks!
> 
> Bing
> 
> ---------------------------------
> 1060 Commerce Park
> Oak Ridge National Laboratory
> P.O. Box 2008, MS 6480
> Oak Ridge, TN 37831-6480
> Phone: 865-241-0761
> Email: zhangb at ornl.gov
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
>



From bates at stat.wisc.edu  Wed Sep 17 20:54:16 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 17 Sep 2003 18:54:16 -0000
Subject: [R] the name of a variable in a function
In-Reply-To: <3F68A7A5.6030203@ceam.es>
References: <3F68A7A5.6030203@ceam.es>
Message-ID: <6rr82f455v.fsf@bates4.stat.wisc.edu>

Well you don't know that the actual argument to a function is a name -
it could be a more complex expression.  In any case, you can get the expression
that was the actual argument with the substitute function, then you
need to deparse it.  Your function could be written

> prova <- function( var )
+ {
+     df <- data.frame(seq(min(var), max(var), len = 20))
+     names(df) <- deparse(substitute(var))
+     df
+ }
> prova(a)
           a
1   1.000000
2   3.578947
3   6.157895
4   8.736842
5  11.315789
6  13.894737
7  16.473684
8  19.052632
9  21.631579
10 24.210526
11 26.789474
12 29.368421
13 31.947368
14 34.526316
15 37.105263
16 39.684211
17 42.263158
18 44.842105
19 47.421053
20 50.000000

"juli g. pausas" <juli at ceam.es> writes:

> Dear collegues,
> How can I get the name of a variable (and not the variable) within a
> function ?
> 
> For instance, in the following function, I'd like to create a variable
> in the dataframe df with the same name to the variable passed in var:
> 
> 
> 
> prova <- function( var )
> {
>   df <- as.data.frame(matrix(nr=20,nc=0))
>   df[["here"]] <- seq(min(var), max(var), le= 20)   #
>   df
> }
> 
> for instance,
> 
> a <- 1:50
> prova(a)
> 
> should give a dataframe with a variable called a (df$a)
> Thanks in advance
> 
> Juli
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/



From thorntonr at maf.govt.nz  Wed Sep 17 21:50:55 2003
From: thorntonr at maf.govt.nz (Ron Thornton)
Date: Thu, 18 Sep 2003 07:50:55 +1200
Subject: [R] CART analysis
Message-ID: <sf696401.056@mafmsp1.maf.govt.nz>

Greetings,
Does anyone know of an R code for classification and regression tree
analysis (CART)?

Thank you
Ron

Ron Thornton BVSc, PhD, MACVSc (pathology, epidemiology)
Programme Co-ordinator, Active Surveillance
Animal Biosecurity
MAF Biosecurity Authority
P O Box 2526
Wellington, New Zealand
phone: 64-4-4744156
027 223 7582
fax: 64-4-474-4133
e-mail: ron.thornton at maf.govt.nz
http://www.maf.govt.nz



From kutinskyv at obninsk.com  Wed Sep 17 22:18:25 2003
From: kutinskyv at obninsk.com (Vladimir N. Kutinsky)
Date: Thu, 18 Sep 2003 00:18:25 +0400
Subject: [R] CART analysis
In-Reply-To: <sf696401.056@mafmsp1.maf.govt.nz>
Message-ID: <KFENLPKGENECNKICCNMBGEEJCHAA.kutinskyv@obninsk.com>

Ron,

> Does anyone know of an R code for classification and regression tree
> analysis (CART)?
>
If I got you right, you need a "tree" package. It implemets the CART method.
If you go further, you will like "randomForest" package.

Regards,
Vladimir



From ggrothendieck at volcanomail.com  Wed Sep 17 09:03:42 2003
From: ggrothendieck at volcanomail.com (Gabor Grothendieck)
Date: Wed, 17 Sep 2003 09:03:42 +0200
Subject: [R] Using POSIX?t rather than "chron" or "date"
Message-ID: <20030917201638.AF1383A77@sitemail.everyone.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030917/bde6be0e/attachment.pl

From paulda at BATTELLE.ORG  Wed Sep 17 22:22:23 2003
From: paulda at BATTELLE.ORG (Paul, David  A)
Date: Wed, 17 Sep 2003 16:22:23 -0400
Subject: [R] CART analysis
Message-ID: <940250A9EB37A24CBE28D858EF07774967AB12@ws-bco-mse3.milky-way.battelle.org>

> library(tree)
> ?tree

should work.  If you don't have the "tree" library,
you can download it off of CRAN at 

http://cran.r-project.org/bin/windows/contrib

if you're using Windows, or go to 

http://cran.r-project.org/src/contrib/PACKAGES.html

for the source code directly as gzipped .tar files.
I'm not all that familiar with Linux or the RPM files
that are used to install R on the various Linux flavors...
having said that, my understanding is that you would 
compile the packages from their source code directly 
if you are using R on a Linux operating system.

Best wishes,
  david paul


-----Original Message-----
From: Ron Thornton [mailto:thorntonr at maf.govt.nz] 
Sent: Wednesday, September 17, 2003 3:51 PM
To: r-help at stat.math.ethz.ch
Subject: [R] CART analysis


Greetings,
Does anyone know of an R code for classification and regression tree
analysis (CART)?

Thank you
Ron

Ron Thornton BVSc, PhD, MACVSc (pathology, epidemiology) Programme
Co-ordinator, Active Surveillance Animal Biosecurity MAF Biosecurity
Authority P O Box 2526 Wellington, New Zealand
phone: 64-4-4744156
027 223 7582
fax: 64-4-474-4133
e-mail: ron.thornton at maf.govt.nz
http://www.maf.govt.nz

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From kwan022 at stat.auckland.ac.nz  Wed Sep 17 22:27:18 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Thu, 18 Sep 2003 08:27:18 +1200 (NZST)
Subject: [R] CART analysis
In-Reply-To: <KFENLPKGENECNKICCNMBGEEJCHAA.kutinskyv@obninsk.com>
Message-ID: <Pine.LNX.4.44.0309180827100.8657-100000@stat61.stat.auckland.ac.nz>

Or, I think, the rpart package.

On Thu, 18 Sep 2003, Vladimir N. Kutinsky wrote:

> Date: Thu, 18 Sep 2003 00:18:25 +0400
> From: Vladimir N. Kutinsky <kutinskyv at obninsk.com>
> To: r-help at stat.math.ethz.ch
> Subject: RE: [R] CART analysis
> 
> Ron,
> 
> > Does anyone know of an R code for classification and regression tree
> > analysis (CART)?
> >
> If I got you right, you need a "tree" package. It implemets the CART method.
> If you go further, you will like "randomForest" package.
> 
> Regards,
> Vladimir
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
"On two occasions, I have been asked [by members of Parliament],
'Pray, Mr. Babbage, if you put into the machine wrong figures, will
the right answers come out?' I am not able to rightly apprehend the
kind of confusion of ideas that could provoke such a question."

-- Charles Babbage (1791-1871) 
---- From Computer Stupidities: http://rinkworks.com/stupid/

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)



From jasont at indigoindustrial.co.nz  Wed Sep 17 22:46:46 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Wed, 17 Sep 2003 20:46:46 -0000
Subject: [R] using matrix data for function
In-Reply-To: <3F652F2B@webmail1>
References: <3F652F2B@webmail1>
Message-ID: <1063832109.28964.8.camel@kryten.indigoindustrial.co.nz>

On Thu, 2003-09-18 at 06:02, Bing Zhang wrote:
> Hi All,
> 
> I have a function, f(x,y)
> I have a matrix of data, m,  with the 1st column is x and the 2nd column is y
> What's the best way to get f(x,y) for each row of the matrix?
> I tried 
> result<-f(m[,1],m[,2]) but it doesn't work.

That is the best way, provided your function handles vectors nicely. 
Apparently, yours doesn't.

Next best is something like apply(m,2,f)

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
+64-(0)21-343-545



From jasont at indigoindustrial.co.nz  Wed Sep 17 22:50:22 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Wed, 17 Sep 2003 20:50:22 -0000
Subject: [R] using matrix data for function
In-Reply-To: <3F653AD7@webmail1>
References: <3F653AD7@webmail1>
Message-ID: <1063832324.28942.12.camel@kryten.indigoindustrial.co.nz>

On Thu, 2003-09-18 at 06:41, Bing Zhang wrote:
> Thanks. How about I have a third parameter for the function, which is a fixed 
> object? i.e. the function is f(o,x,y)

1) My earlier reply had a typo. Should've been apply(m,1,f).

2) Luckily, the answer to this question, and any more you're likely to
have about apply(), are documented quite nicly.  help(apply) 

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
+64-(0)21-343-545



From Benjamin.STABLER at odot.state.or.us  Wed Sep 17 22:51:31 2003
From: Benjamin.STABLER at odot.state.or.us (Benjamin.STABLER@odot.state.or.us)
Date: Wed, 17 Sep 2003 13:51:31 -0700
Subject: [R] Building and loading a DLL on Windows NT
Message-ID: <76A000A82289D411952F001083F9DD06047FE26D@exsalem4-bu.odot.state.or.us>

I am trying to build a simple dll with Rcmd SHLIB to link into R.  The
results of the build are below.  From my limited knowledge of building DLLs,
it looks like it worked (I didn't get any errors).

F:\R\dlls> Rcmd SHLIB add.C
making add.d from add.C
g++   -IC:/PROGRA~1/R/src/include -Wall -O2   -c add.C -o add.o
ar cr add.a *.o
ranlib add.a
g++  --shared -s  -o add.dll add.def add.a  -LC:/PROGRA~1/R/src/gnuwin32
-lg2c -lR

Then I tried to load the DLL into R with:

dyn.load("F:\\R\\dlls\\add.dll")

which returned nothing (which I assumes means there were no errors).  But,

> is.loaded(symbol.C("add"))
[1] FALSE

returns false.  add is the name of the function in the source file.  I know
I can dynamically load other DLLs.  I've read quite a bit of documentation
and I am still stumped.  I have all the proper tools for building R under
Windows and I know they work since I have built Windows package binaries.
Any ideas on what I am doing wrong would be greatly appreciated.  Thanks.

Ben Stabler



From jasont at indigoindustrial.co.nz  Wed Sep 17 22:55:27 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Wed, 17 Sep 2003 20:55:27 -0000
Subject: [R] Using POSIX?t rather than "chron" or "date"
In-Reply-To: <20030917201638.AF1383A77@sitemail.everyone.net>
References: <20030917201638.AF1383A77@sitemail.everyone.net>
Message-ID: <1063832627.28943.17.camel@kryten.indigoindustrial.co.nz>

On Wed, 2003-09-17 at 19:03, Gabor Grothendieck wrote:
> The problem with POSIXt is that you must consider timezones 
> and daylight vs.  standard time issues even if you don't want 
> to.  
...
> I had previously suggested that we either put chron into the base 
> or create a new timezone-less version of POSIXt to complement what 
> is already in the base.  See:

When I don't want to be bothered with time zones, DST, etc, I set all
time zones to UTC.  Works fine for me.  I'd love to say I thought of it
myself, but it's an old trick frequently used in industrial real-time
control systems that have daylight savings features when they're not
welcome.

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
+64-(0)21-343-545



From ggrothendieck at volcanomail.com  Wed Sep 17 23:10:44 2003
From: ggrothendieck at volcanomail.com (Gabor Grothendieck)
Date: Wed, 17 Sep 2003 21:10:44 -0000
Subject: [R] Using POSIX?t rather than "chron" or "date"
Message-ID: <20030917211122.0B958475E@sitemail.everyone.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030917/78f51fa7/attachment.pl

From Benjamin.STABLER at odot.state.or.us  Wed Sep 17 23:14:45 2003
From: Benjamin.STABLER at odot.state.or.us (Benjamin.STABLER@odot.state.or.us)
Date: Wed, 17 Sep 2003 14:14:45 -0700
Subject: [R] Building and loading a DLL on Windows NT
Message-ID: <76A000A82289D411952F001083F9DD06047FE26E@exsalem4-bu.odot.state.or.us>

Thanks.  I didn't try the Borland utility but your response reminded me of a
way to view the DLL info in Windows.  Right click a DLL and then "quick
view" and Windows outputs some file information, including the Export table
which lists the names of the symbols in the DLL.  The name of the add
function is "_Z3addPdS_".  So it works now.  Thanks for your help.

Ben Stabler
Oregon Department of Transportation

>-----Original Message-----
>From: Whit Armstrong [mailto:Whit.Armstrong at tudor.com]
>Sent: Wednesday, September 17, 2003 1:56 PM
>To: STABLER Benjamin
>Subject: RE: [R] Building and loading a DLL on Windows NT
>
>
>There's a free utility from borland (I think it's called tdump 
>or dump) that
>will show you all the exports from a dll.  You could run that 
>on the dll you
>made to see what name the function is being exported under 
>(sorry, but I
>don't have the link).  Other than that, it looks like you're doing
>everything right.  I've never built a DLL using SHLIB, so I 
>can't help you
>there.
>
>Good luck,
>Whit
>
>-----Original Message-----
>From: Benjamin.STABLER at odot.state.or.us
>[mailto:Benjamin.STABLER at odot.state.or.us] 
>Sent: Wednesday, September 17, 2003 4:52 PM
>To: r-help at stat.math.ethz.ch
>Subject: [R] Building and loading a DLL on Windows NT
>
>
>I am trying to build a simple dll with Rcmd SHLIB to link into R.  The
>results of the build are below.  From my limited knowledge of 
>building DLLs,
>it looks like it worked (I didn't get any errors).
>
>F:\R\dlls> Rcmd SHLIB add.C
>making add.d from add.C
>g++   -IC:/PROGRA~1/R/src/include -Wall -O2   -c add.C -o add.o
>ar cr add.a *.o
>ranlib add.a
>g++  --shared -s  -o add.dll add.def add.a  
>-LC:/PROGRA~1/R/src/gnuwin32
>-lg2c -lR
>
>Then I tried to load the DLL into R with:
>
>dyn.load("F:\\R\\dlls\\add.dll")
>
>which returned nothing (which I assumes means there were no 
>errors).  But,
>
>> is.loaded(symbol.C("add"))
>[1] FALSE
>
>returns false.  add is the name of the function in the source 
>file.  I know
>I can dynamically load other DLLs.  I've read quite a bit of 
>documentation
>and I am still stumped.  I have all the proper tools for 
>building R under
>Windows and I know they work since I have built Windows 
>package binaries.
>Any ideas on what I am doing wrong would be greatly 
>appreciated.  Thanks.
>
>Ben Stabler
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From Sean.Davis at dcb.cit.nih.gov  Wed Sep 17 23:33:30 2003
From: Sean.Davis at dcb.cit.nih.gov (Sean Davis)
Date: Wed, 17 Sep 2003 17:33:30 -0400 (EDT)
Subject: [R] Building XML library on MacOS X
Message-ID: <Pine.GSO.4.50.0309171729550.29278-100000@argo.cit.nih.gov>

This is not a strictly R question, but I am trying to build the XML
package on MacOS X and have not been successful.  I have tried using
expat, libxml, and libxml2 without success in building.  Has someone
successfully done this that could enlighten me with the process
(especially as it relates to installing a libxml version and then
completing the XML package installation, specifying the correct
environment variables, etc.)?

Thanks in advance,
Sean



From Ted.Harding at nessie.mcc.ac.uk  Wed Sep 17 21:21:32 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Wed, 17 Sep 2003 20:21:32 +0100 (BST)
Subject: [R] all possible samples
In-Reply-To: <BAY7-F69dbUu2o8q3p9000051ba@hotmail.com>
Message-ID: <XFMail.030917202132.Ted.Harding@nessie.mcc.ac.uk>

On 17-Sep-03 lamack lamack wrote:
> Dear all, there is an R function that return all possible samples of
> size n, 
> with replacement,  from a vector of length N ?

Without delving into R to see if such a thing exists already, I can
suggest the following (based on an algorithm to be found in Nijenhuis
and Wilf, "Combinatorial Algortithms", Academic Press 1978). I once
implemented it in octave and it worked well. I'll use their notation
rather than yours so that I don't confuse my fingers ...

To select all subsets of size k out of n (in "lexicographic order"):

The n-set is {1,2,3,...,n}.
A selected subset is {a[1],a[2],...,a[k]}.

Repeatedly apply the following algorithm for "next subset":

(A) If first time (first subset): m<-0; h<-k; go to (D)
(B) If not first time: if( m>=n-h ) go to (C); else h<-0;
(C) h<-(h+1); m<-a[k+1-h];
(D) for(j in (1:h)) {a[k+j-h]<-(m+j)};
    if( a[1]==(n-k+1)) final_exit (all done);
    else nonfinal_exit (some left);

For 3 out of 5 this gives {1,2,3},(1,2,4},{1,2,5},{1,3,4},{1,3,5},
{1,4,5},{2,3,4},{2,3,5},{2,4,5},{3,4,5}.

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 17-Sep-03                                       Time: 20:21:32
------------------------------ XFMail ------------------------------



From dmurphy at cc.UManitoba.CA  Thu Sep 18 01:13:40 2003
From: dmurphy at cc.UManitoba.CA (Dennis J. Murphy)
Date: Wed, 17 Sep 2003 18:13:40 -0500
Subject: [R] RE: all possible samples
Message-ID: <20030917231340.GC5293@cc.umanitoba.ca>

Hi,

Another possibility is to use the combinations function in the gregmisc
package, which has an option repeats.allowed.

Sorry for not including the original post, but I had deleted it from my 
mailbox earlier in the day.

HTH,
Dennis



From ross at biostat.ucsf.edu  Thu Sep 18 01:52:49 2003
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Wed, 17 Sep 2003 16:52:49 -0700
Subject: [R] subsetting matrix replacement oddities
Message-ID: <1063842769.1019.49.camel@iron.libaux.ucsf.edu>

When assigning a dataframe to a subset of a matrix I got a very odd
result.  Am I missing something, or is this a bug?  Details are below.

Also, if m is defined outside of the current function, is
m[...] <<- foo
necessary to update it, or does regular replacement
m[....] <- foo
work (that is, does it update the "global" rather than creating a
"local" that conceals it)?  I got conflicting results, which were
tangled up with the oddity below.
--------------------------------------------------------

Browse[1]> covs
    epilepsy other.cancer
680        0            0
681        0            0
682        0            0
683        0            1
684        0            0
Browse[1]> m <- matrix(NA, 5,2)
Browse[1]> m[,1:2] <- covs
Browse[1]> m
[[1]]
[1] 0 0 0 0 0

[[2]]
[1] 0 0 0 1 0

[[3]]
[1] 0 0 0 0 0

[[4]]
[1] 0 0 0 1 0

[[5]]
[1] 0 0 0 0 0

[[6]]
[1] 0 0 0 1 0

[[7]]
[1] 0 0 0 0 0

[[8]]
[1] 0 0 0 1 0

[[9]]
[1] 0 0 0 0 0

[[10]]
[1] 0 0 0 1 0

Browse[1]> dim(covs)
[1] 5 2
Browse[1]> class(covs)
[1] "data.frame"
Browse[1]> class(m)
[1] "list"
Browse[1]> length(m)
[1] 10

Fortunately, the following seems to work as expected:
Browse[1]> m[,1:2] <- as.matrix(covs)


Ross Boylan                                      wk:  (415) 502-4031
530 Parnassus Avenue (Library) rm 115-4          ross at biostat.ucsf.edu
Dept of Epidemiology and Biostatistics           fax: (415) 476-9856
University of California, San Francisco
San Francisco, CA 94143-0840                     hm:  (415) 550-1062



From spencer.graves at pdf.com  Thu Sep 18 02:41:09 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 17 Sep 2003 17:41:09 -0700
Subject: [R] subsetting matrix replacement oddities
In-Reply-To: <1063842769.1019.49.camel@iron.libaux.ucsf.edu>
References: <1063842769.1019.49.camel@iron.libaux.ucsf.edu>
Message-ID: <3F68FF25.1090804@pdf.com>

A subset of a data.frame is still a data.frame.  A data.frame is 
actually a list with additional attributes.  As far as I know, your 
solution, "as.matrix", is an appropriate tool to convert a data.frame to 
a matrix.  Caution may be appropropriate, however, because if the 
data.frame includes anything not numeric, the result may not be numeric, 
and the result is inconsistent between S-Plus 6.1 and R 1.7.1.  Consider 
the following: 

S-PLUS 6.1: 

 > DF <- data.frame(a = 1:2, b = letters[1:2])
 > DF2 <- data.frame(c = TRUE)
 > DF3 <- data.frame(c = TRUE, d = 2)
 > sapply(DF, class)
         a        b
 "integer" "factor"
 > as.matrix(DF)
    a   b
1 "1" "a"
2 "2" "b"
 > as.matrix(DF2)
  c
1 T
 > as.matrix(DF3)
  c d
1 1 2

##################
R 1.7.1: 

 > DF <- data.frame(a=1:2, b=letters[1:2])
 > DF2 <- data.frame(c=TRUE)
 > DF3 <- data.frame(c=TRUE, d=2)
 > sapply(DF, class)
        a         b
"integer"  "factor"
 > as.matrix(DF)
  a   b 
1 "1" "a"
2 "2" "b"
 > as.matrix(DF2)
  c    
1 "TRUE"
 > as.matrix(DF3)
  c      d 
1 "TRUE" "2"
#####################
Hope this helps.  spencer graves

Ross Boylan wrote:

>When assigning a dataframe to a subset of a matrix I got a very odd
>result.  Am I missing something, or is this a bug?  Details are below.
>
>Also, if m is defined outside of the current function, is
>m[...] <<- foo
>necessary to update it, or does regular replacement
>m[....] <- foo
>work (that is, does it update the "global" rather than creating a
>"local" that conceals it)?  I got conflicting results, which were
>tangled up with the oddity below.
>--------------------------------------------------------
>
>Browse[1]> covs
>    epilepsy other.cancer
>680        0            0
>681        0            0
>682        0            0
>683        0            1
>684        0            0
>Browse[1]> m <- matrix(NA, 5,2)
>Browse[1]> m[,1:2] <- covs
>Browse[1]> m
>[[1]]
>[1] 0 0 0 0 0
>
>[[2]]
>[1] 0 0 0 1 0
>
>[[3]]
>[1] 0 0 0 0 0
>
>[[4]]
>[1] 0 0 0 1 0
>
>[[5]]
>[1] 0 0 0 0 0
>
>[[6]]
>[1] 0 0 0 1 0
>
>[[7]]
>[1] 0 0 0 0 0
>
>[[8]]
>[1] 0 0 0 1 0
>
>[[9]]
>[1] 0 0 0 0 0
>
>[[10]]
>[1] 0 0 0 1 0
>
>Browse[1]> dim(covs)
>[1] 5 2
>Browse[1]> class(covs)
>[1] "data.frame"
>Browse[1]> class(m)
>[1] "list"
>Browse[1]> length(m)
>[1] 10
>
>Fortunately, the following seems to work as expected:
>Browse[1]> m[,1:2] <- as.matrix(covs)
>
>
>Ross Boylan                                      wk:  (415) 502-4031
>530 Parnassus Avenue (Library) rm 115-4          ross at biostat.ucsf.edu
>Dept of Epidemiology and Biostatistics           fax: (415) 476-9856
>University of California, San Francisco
>San Francisco, CA 94143-0840                     hm:  (415) 550-1062
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From maj at stats.waikato.ac.nz  Thu Sep 18 02:55:03 2003
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Thu, 18 Sep 2003 12:55:03 +1200
Subject: [R] Suming logical vectors
Message-ID: <3F690267.5050008@stats.waikato.ac.nz>

Can anyone explain the following?  [R 1.6.0 Windows XP, yes I will 
upgrade soon.]

Murray

 > sort(IATmedian)[0:50]==0
  [1]  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE 
FALSE
[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
[25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
[37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
[49] FALSE FALSE
 > sum(sort(IATmedian)[0:50]==0)
[1] 2
 > sum(sort(IATmedian)==0)
[1] 2
 > sum(IATmedian==0)
[1] NA

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From ross at biostat.ucsf.edu  Thu Sep 18 03:13:54 2003
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Wed, 17 Sep 2003 18:13:54 -0700
Subject: [R] subsetting matrix replacement oddities
In-Reply-To: <3F68FF25.1090804@pdf.com>
References: <1063842769.1019.49.camel@iron.libaux.ucsf.edu>
	<3F68FF25.1090804@pdf.com>
Message-ID: <20030918011354.GR12620@wheat.boylan.org>

On Wed, Sep 17, 2003 at 05:41:09PM -0700, Spencer Graves wrote:
> A subset of a data.frame is still a data.frame.  A data.frame is 
> actually a list with additional attributes.  As far as I know, your 
> solution, "as.matrix", is an appropriate tool to convert a data.frame to 
> a matrix.  Caution may be appropropriate, however, because if the 

That helps explain where the list assignment is coming from, but it
still seems very odd that assignment to a subset of a matrix should
change the class of the object, so that it is no longer a matrix.



From deepayan at stat.wisc.edu  Thu Sep 18 03:53:30 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Wed, 17 Sep 2003 20:53:30 -0500 (CDT)
Subject: [R] Suming logical vectors
In-Reply-To: <3F690267.5050008@stats.waikato.ac.nz>
References: <3F690267.5050008@stats.waikato.ac.nz>
Message-ID: <Pine.LNX.4.58.0309172052100.20594@gstat305.stat.wisc.edu>


Your IATmedian has some NAs (which are removed by sort) ?

On Thu, 18 Sep 2003, Murray Jorgensen wrote:

> Can anyone explain the following?  [R 1.6.0 Windows XP, yes I will
> upgrade soon.]
>
> Murray
>
>  > sort(IATmedian)[0:50]==0
>   [1]  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> FALSE
> [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> [25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> [37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> [49] FALSE FALSE
>  > sum(sort(IATmedian)[0:50]==0)
> [1] 2
>  > sum(sort(IATmedian)==0)
> [1] 2
>  > sum(IATmedian==0)
> [1] NA
>
> --
> Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
> Department of Statistics, University of Waikato, Hamilton, New Zealand
> Email: maj at waikato.ac.nz                                Fax 7 838 4155
> Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From maj at stats.waikato.ac.nz  Thu Sep 18 04:05:01 2003
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Thu, 18 Sep 2003 14:05:01 +1200
Subject: [R] Suming logical vectors
In-Reply-To: <Pine.LNX.4.58.0309172052100.20594@gstat305.stat.wisc.edu>
References: <3F690267.5050008@stats.waikato.ac.nz>
	<Pine.LNX.4.58.0309172052100.20594@gstat305.stat.wisc.edu>
Message-ID: <3F6912CD.3040106@stats.waikato.ac.nz>

Blush!  Not too hard to explain at all!

Deepayan Sarkar wrote:

> Your IATmedian has some NAs (which are removed by sort) ?
> 
> On Thu, 18 Sep 2003, Murray Jorgensen wrote:
> 
> 
>>Can anyone explain the following?  [R 1.6.0 Windows XP, yes I will
>>upgrade soon.]
>>
>>Murray
>>
>> > sort(IATmedian)[0:50]==0
>>  [1]  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
>>FALSE
>>[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
>>[25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
>>[37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
>>[49] FALSE FALSE
>> > sum(sort(IATmedian)[0:50]==0)
>>[1] 2
>> > sum(sort(IATmedian)==0)
>>[1] 2
>> > sum(IATmedian==0)
>>[1] NA
>>
>>--
>>Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
>>Department of Statistics, University of Waikato, Hamilton, New Zealand
>>Email: maj at waikato.ac.nz                                Fax 7 838 4155
>>Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
> 
> 
> 

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From deepayan at stat.wisc.edu  Thu Sep 18 04:13:16 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Wed, 17 Sep 2003 21:13:16 -0500 (CDT)
Subject: [R] Date on x-axis of xyplot
In-Reply-To: <20030917095137.A16054@jessie.research.bell-labs.com>
References: <200309162331.06832.deepayan@stat.wisc.edu>
	<Pine.LNX.4.44.0309170655470.2844-100000@gannet.stats>
	<20030917095137.A16054@jessie.research.bell-labs.com>
Message-ID: <Pine.LNX.4.58.0309172109130.20594@gstat305.stat.wisc.edu>


[Due to problems with my mail client, this message may
eventually reach the list twice. Sorry about that.]

On Wednesday 17 September 2003 08:51, David James wrote:
> Prof Brian Ripley wrote:
> > On Tue, 16 Sep 2003, Deepayan Sarkar wrote:
> > > Is the date class standard enough to warrant including a check for
> > > it in lattice ?
> >
> > I don't think so.  The POSIX*t classes in R are the most standard,
> > followed by the chron package and only then the date package.
>
> If it is not overly complicated to implement, could I timidly suggest
> *not* checking for specific classes inside lattice, but rather use
> some other kind of mechanism (perhaps invoking helper functions,
> or use specific methods, etc.) to render axes?

This is definitely a good idea generally, and lattice tries to do that as
much as possible (exceptions being splom, cloud, wireframe). However, at
some point the tick locations and labels need to be calculated by some
variation of pretty and format, which loses the class attribute and has to
be processed case by case.

In fact for POSIXct, pretty doesn't return sensible values, and that case
has to be handled completely separately. The base plot functions seem to
handle this via axis.POSIXct, which is not directly usable and so is
essentially repeated in lattice. It might be a good idea to eventually
separate the common part out as something similar to pretty.

I also just dicovered that POSIXct handling in lattice is broken, except
when scales$relation = "free" or "sliced". I'll fix this ASAP.

Deepayan



From atuya at xd5.so-net.ne.jp  Thu Sep 18 04:56:16 2003
From: atuya at xd5.so-net.ne.jp (Atsuya Fujito)
Date: Wed, 17 Sep 2003 21:56:16 -0500
Subject: [R] print graph
Message-ID: <ABD76206-E983-11D7-8C56-003065F9618A@xd5.so-net.ne.jp>

Hello.

I am using R 1.7.1 on Mac OSX10.2.6 and XDarwin86 4.3.
I made barplot graph by barplot2.
I can get good graph on x11() device.
But when change the device to potscript(), the graph changed to 
incomplete.
For example, absence of label or err bar or ...
I would like to print out this graph.
Can anyone suggest how to print out graph?

Hope this help,
Thank you,

atuya



From MSchwartz at medanalytics.com  Thu Sep 18 06:16:43 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 17 Sep 2003 23:16:43 -0500
Subject: [R] print graph
In-Reply-To: <ABD76206-E983-11D7-8C56-003065F9618A@xd5.so-net.ne.jp>
References: <ABD76206-E983-11D7-8C56-003065F9618A@xd5.so-net.ne.jp>
Message-ID: <1063858603.5029.5.camel@localhost>

On Wed, 2003-09-17 at 21:56, Atsuya Fujito wrote:
> Hello.
> 
> I am using R 1.7.1 on Mac OSX10.2.6 and XDarwin86 4.3.
> I made barplot graph by barplot2.
> I can get good graph on x11() device.
> But when change the device to potscript(), the graph changed to 
> incomplete.
> For example, absence of label or err bar or ...
> I would like to print out this graph.
> Can anyone suggest how to print out graph?
> 
> Hope this help,
> Thank you,
> 
> atuya


Did you remember to use:

dev.off()

after completing the plot?

For example:

postscript("barplot2.ps")
barplot2(1:10)
dev.off()

HTH,

Marc Schwartz



From XkP9Ivaj13o at getithereandfast.com  Thu Sep 18 17:40:05 2003
From: XkP9Ivaj13o at getithereandfast.com (XkP9Ivaj13o)
Date: Thu, 18 Sep 2003 15:40:05 +0000
Subject: [R] R-help, Buy Generic and Save 60%  KDXhDE
In-Reply-To: <D5C54EAC28D008D2@stat.math.ethz.ch>
References: <D5C54EAC28D008D2@stat.math.ethz.ch>
Message-ID: <BF6833204A789146@getithereandfast.com>


   [1][gv3.jpg]
   tEC2FxLHJKF7 

References

   1. http://systemgreats.com/host/default.asp?ID=002


From maechler at stat.math.ethz.ch  Thu Sep 18 12:25:13 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 18 Sep 2003 12:25:13 +0200
Subject: [R] CART analysis
In-Reply-To: <940250A9EB37A24CBE28D858EF07774967AB12@ws-bco-mse3.milky-way.battelle.org>
References: <940250A9EB37A24CBE28D858EF07774967AB12@ws-bco-mse3.milky-way.battelle.org>
Message-ID: <16233.34825.455616.395591@gargle.gargle.HOWL>

>>>>> "PaulDA" == Paul, David A <paulda at battelle.org>
>>>>>     on Wed, 17 Sep 2003 16:22:23 -0400 writes:

    >> library(tree)
    >> ?tree

    PaulDA> should work.

Yes,  however,  "rpart" is a recommended package, hence
available in all R installations,
and the fact that it is recommended (and "tree" is not) should
really tell you that you should (at least try) using it first.

    PaulDA> If you don't have the "tree" library,

It's called ``package'', not "library" --- please take note (sigh...)

    PaulDA> you can download it off of CRAN ....

    PaulDA> <...............>



From Simon.Fear at synequanon.com  Thu Sep 18 12:40:30 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Thu, 18 Sep 2003 11:40:30 +0100
Subject: [R] packages and libraries
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572AC0DDD@synequanon01>

Martin Maechler writes

> It's called ``package'', not "library" --- please take note (sigh...)

Why not make the library() function deprecated and replace
it with package() or load.package()?

I'm afraid as long as the function to load these things is 
called library, I'm in danger of calling packages libraries. Think 
I have done on this list, in fact, even though I do know better. Too
much Splus.
 

Simon Fear
Senior Statistician
Syne qua non Ltd
Tel: +44 (0) 1379 644449
Fax: +44 (0) 1379 644445
email: Simon.Fear at synequanon.com
web: http://www.synequanon.com
 
Number of attachments included with this message: 0
 
This message (and any associated files) is confidential and\...{{dropped}}



From Simon.Fear at synequanon.com  Thu Sep 18 13:04:35 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Thu, 18 Sep 2003 12:04:35 +0100
Subject: [R] using matrix data for function
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572AC0DDE@synequanon01>

I think you will find the "new" (1.7.0) function

mapply(sum, mat[,1], mat[,2])

is an excellent generic approach (though in the particular
example, rowsum() would do the job).

I'd been waiting years for mapply(), love it!


> -----Original Message-----
> From: Liaw, Andy [mailto:andy_liaw at merck.com]
> Sent: 17 September 2003 19:47
> To: 'Bing Zhang'; r-help
> Subject: RE: [R] using matrix data for function
> 
> 
> Security Warning:
> If you are not sure an attachment is safe to open please contact 
> Andy on x234. There are 0 attachments with this message.
> ________________________________________________________________
> 
> Don't think this is "best", but here's one way:
> 
> > mat <- matrix(1:12, 6)
> > mat
>      [,1] [,2]
> [1,]    1    7
> [2,]    2    8
> [3,]    3    9
> [4,]    4   10
> [5,]    5   11
> [6,]    6   12
> > f <- function(x, y) x + y
> > apply(mat, 1, function(x) do.call("f", as.list(x)))
> [1]  8 10 12 14 16 18
> 
> Note that apply(mat, 1, f) won't work, because both values 
> are passed to
> f
> in a single vector.
> 
> Perhaps better alternatives are:
> 
> 1. Re-write f so that it takes a single vector of two 
> elements, or write
> a
> wrapper fw <- function(x) f(x[1], x[2]), then use fw in apply().
> 
> 2. Re-write f so that it's vectorized, so that f(mat[,1], fmat[,2])
> works.
> 
> HTH,
> Andy
> 
> 
> > -----Original Message-----
> > From: Bing Zhang [mailto:bih at ornl.gov] 
> > Sent: Wednesday, September 17, 2003 2:03 PM
> > To: r-help
> > Subject: [R] using matrix data for function
> > 
> > 
> > Hi All,
> > 
> > I have a function, f(x,y)
> > I have a matrix of data, m,  with the 1st column is x and the 
> > 2nd column is y What's the best way to get f(x,y) for each 
> > row of the matrix? I tried 
> > result<-f(m[,1],m[,2]) but it doesn't work.
> > 
> > Thanks!
> > 
> > Bing
> > 
> > ---------------------------------
> > 1060 Commerce Park
> > Oak Ridge National Laboratory
> > P.O. Box 2008, MS 6480
> > Oak Ridge, TN 37831-6480
> > Phone: 865-241-0761
> > Email: zhangb at ornl.gov
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list 
> > https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
 

Simon Fear
Senior Statistician
Syne qua non Ltd
Tel: +44 (0) 1379 644449
Fax: +44 (0) 1379 644445
email: Simon.Fear at synequanon.com
web: http://www.synequanon.com
 
Number of attachments included with this message: 0
 
This message (and any associated files) is confidential and\...{{dropped}}



From Ted.Harding at nessie.mcc.ac.uk  Thu Sep 18 13:58:45 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Thu, 18 Sep 2003 12:58:45 +0100 (BST)
Subject: [R] Installing from RPM on Red Hat 9
Message-ID: <XFMail.030918125845.Ted.Harding@nessie.mcc.ac.uk>

Hi Folks,
Sorry to bring up this kind of issue (though any discussion may help
some other people).

I've just installed Red Hat 9 Linux (opting for GNOME) and now want
to install R.
I downloaded the RPM for Red Hat 9 from CRAN (as well as the patched
readline).

Attempting to install ( rpm -i R-1.7.1-1.i386.rpm ) I get, pretty
quickly, the following:

warning: R-1.7.1-1.i386.rpm: V3 DSA signature: NOKEY, key ID 97d3544e
error: Failed dependencies:
        libtk8.3.so is needed by R-1.7.1-1

I guess the "warning" can be ignored, but I'm bothered by the failed
dependency.

A: There are libtcl8.3.so and libtcl.so under /usr/lib;
B: There's various "libgtk" under /usr/lib;
C: There's no "libtk"
D: I can't find any explicit reference to "libtk" in the installation
   GUI when the installation CDs are being used. So, even if libtk is
   in there somewhere, I can't find where to look for it. (I don't
   want to install everything in sight, because of restricted disk
   space).

I suspect that "libgtk" is a GNOMEified version of libtk ... ? Usually,
in my Linux experience, tcltk is a unified bunch of stuff which installs
everthing for both Tcl and Tk; Red Hat 9 seems to be different (and it's
my first experience of this version).

ANYWAY: Has anyone encountered this problem and solved it? Or am I
overlooking something simple?

Comments (and especially solutions) will be most welcome.
With thanks,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 18-Sep-03                                       Time: 12:58:45
------------------------------ XFMail ------------------------------



From ozric at web.de  Thu Sep 18 14:04:16 2003
From: ozric at web.de (Christian Schulz)
Date: Thu, 18 Sep 2003 14:04:16 +0200
Subject: [R] 2 time dependend states and probability transition matrix
Message-ID: <002101c37ddd$00150d90$d200a8c0@pc>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030918/e307f1f5/attachment.pl

From gareth.hughes-2 at stud.man.ac.uk  Thu Sep 18 14:07:16 2003
From: gareth.hughes-2 at stud.man.ac.uk (Gareth Hughes)
Date: Thu, 18 Sep 2003 13:07:16 +0100
Subject: [R] Score residuals
Message-ID: <E19zxZZ-0000Oq-Ip@serenity.mcc.ac.uk>

Hi-
Is it possible to obtain the score residuals after fitting a Weibull 
model using Surv( ).
Thanks in advance.



From baron at psych.upenn.edu  Thu Sep 18 14:19:08 2003
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Thu, 18 Sep 2003 08:19:08 -0400
Subject: [R] Installing from RPM on Red Hat 9
In-Reply-To: <XFMail.030918125845.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.030918125845.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <20030918121908.GA27571@mail1.sas.upenn.edu>

On 09/18/03 12:58, Ted Harding wrote:
>Hi Folks,
>Sorry to bring up this kind of issue (though any discussion may help
>some other people).
>
>I've just installed Red Hat 9 Linux (opting for GNOME) and now want
>to install R.
>I downloaded the RPM for Red Hat 9 from CRAN (as well as the patched
>readline).
>
>Attempting to install ( rpm -i R-1.7.1-1.i386.rpm ) I get, pretty
>quickly, the following:
>
>warning: R-1.7.1-1.i386.rpm: V3 DSA signature: NOKEY, key ID 97d3544e
>error: Failed dependencies:
>        libtk8.3.so is needed by R-1.7.1-1
>
>I guess the "warning" can be ignored, but I'm bothered by the failed
>dependency.
>
>A: There are libtcl8.3.so and libtcl.so under /usr/lib;
>B: There's various "libgtk" under /usr/lib;
>C: There's no "libtk"
>D: I can't find any explicit reference to "libtk" in the installation
>   GUI when the installation CDs are being used. So, even if libtk is
>   in there somewhere, I can't find where to look for it. (I don't
>   want to install everything in sight, because of restricted disk
>   space).
>
>I suspect that "libgtk" is a GNOMEified version of libtk ... ? Usually,
>in my Linux experience, tcltk is a unified bunch of stuff which installs
>everthing for both Tcl and Tk; Red Hat 9 seems to be different (and it's
>my first experience of this version).
>
>ANYWAY: Has anyone encountered this problem and solved it? Or am I
>overlooking something simple?
>
>Comments (and especially solutions) will be most welcome.
>With thanks,
>Ted.

You can find what something is by searching for it in
http://rpmfind.net/linux/RPM/
Turns out that libtk8.3.so is part of the tk rpm.  So you could
install that.  (I can also find it with 
 rpm -q --whatprovides libtk8.3.so
because I already have it.  But that won't help you.)

I vaguely recall that the requirement for tk and tcl was not
originally part of the RPM, but Martyn Plummer changed it because
people (like me) were complaining that Rcmdr (and perhaps other
packages) would not install without them.  He also started
including "configure.log" so that you would know how he had made
the RPM.

In the meantime, I had installed R from source, after making sure
that I had tcl and tk.  This was quite easy (although it took a
while for everything to finish).  So, I suggest that, if you do
not want to install tk, then you try installing from source.  The
installation instructions come with the source code.

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R page:               http://finzi.psych.upenn.edu/



From Gordon.Morrison at CommerzbankIB.com  Thu Sep 18 14:37:29 2003
From: Gordon.Morrison at CommerzbankIB.com (Morrison, Gordon)
Date: Thu, 18 Sep 2003 13:37:29 +0100
Subject: [R] Place a graphic into an R-plot
Message-ID: <FAD50FCCDDD5D511865200508BB2CDA502D6C184@xmx2lonib.lonib.commerzbank.com>

I have a graphic image in a file (say a *.jpeg or *.png file) and want to
put it into a plot. I have segmented the plot area by means of the layout
function and successfully plotted my data in the appropriate segments. I
cannot find how to put my graphic image onto the same plot. Searching the
archives has shed little light on my challenge.
 
Many thanks in anticipation.
 
Gordon

> version

platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    7.1            
year     2003           
month    06             
day      16             
language R        


********************************************************************** 
This is a commercial communication from Commerzbank AG.\ \ T...{{dropped}}



From maechler at stat.math.ethz.ch  Thu Sep 18 14:48:26 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 18 Sep 2003 14:48:26 +0200
Subject: [R] Fractals in R and having fun! (and more persp and color)
In-Reply-To: <3.0.5.32.20030917124551.007aaab0@pop-server.ucl.ac.uk>
References: <3.0.5.32.20030917124551.007aaab0@pop-server.ucl.ac.uk>
Message-ID: <16233.43418.5576.412630@gargle.gargle.HOWL>

>>>>> "Mario" == Mario ??? <ucgamdo at ucl.ac.uk>
>>>>>     on Wed, 17 Sep 2003 12:45:51 +0100 writes:


    Mario> Well, I started playing with fractals in R, and wrote
    Mario> a function to generate de Mandelbrot set, which might
    Mario> be of interest to some people

    Mario> ###################################################################
    Mario> # Mandelbrot set
    Mario> ###################################################################

    Mario> mandelbrot <- function(x = c(-3.0, 1.0),   # x coordinates
    Mario>                        y = c(-1.8, 1.8),   # y coordinates
    Mario>                        b = .05,            # by 'steps'
    Mario>                        iter = 20)          # maximum number of iterations

    Mario>     <..................>
    Mario>     <..................>
    Mario>     <..................>

Well, only a bit more than year ago I had posted my version of
mandelbrot() and a drawing function, see

   http://finzi.psych.upenn.edu/R/Rhelp02a/archive/5898.html

   [ I have a slightly updated version of the R code, that is now
     available as ftp://stat.ethz.ch/U/maechler/R/Mandelbrot.R
   ]

which is an order of magnitude more efficient than yours (22 x
faster for your "b = 0.01", *1), *2)
and with an iterImage() function for drawing its result in
several (simple) color schemes.
I agree that the proper solution would *definitely* use C code!

Your idea of using persp() -- while seen frequently in fractal books,
is new ``for R'' however, and nice!  Thank you.


Regards,
Martin

*1) mainly because I only have the iteration loop
    and do the rest vectorized, but also because I have a check
    for symmetry and make use of it when appropriate

*2) For speed comparison, note that I use 10 x more iterations
    and a much higher resolution by default

*3) When I do the comparison, I see that your function's result
    slightly differs from mine -- not for the Mandelbrot set
    itself, but for the very ``outer points'' (the dark orange
    ones in the image plot). Your result is
    asymmetric and hence can't be quite correct.



From maechler at stat.math.ethz.ch  Thu Sep 18 14:56:28 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 18 Sep 2003 14:56:28 +0200
Subject: [R] subsetting matrix replacement oddities
In-Reply-To: <3F68FF25.1090804@pdf.com>
References: <1063842769.1019.49.camel@iron.libaux.ucsf.edu>
	<3F68FF25.1090804@pdf.com>
Message-ID: <16233.43900.965749.634067@gargle.gargle.HOWL>

>>>>> "Spencer" == Spencer Graves <spencer.graves at pdf.com>
>>>>>     on Wed, 17 Sep 2003 17:41:09 -0700 writes:

    Spencer> A subset of a data.frame is still a data.frame.  A
    Spencer> data.frame is actually a list with additional
    Spencer> attributes.  As far as I know, your solution,
    Spencer> "as.matrix", is an appropriate tool to convert a
    Spencer> data.frame to a matrix.  Caution may be
    Spencer> appropropriate, however, because if the data.frame
    Spencer> includes anything not numeric, the result may not
    Spencer> be numeric, and the result is inconsistent between
    Spencer> S-Plus 6.1 and R 1.7.1.  

Yes, using  "as.matrix" is typically not the best, but rather
data.matrix() 
------------  is what you should apply usually to data frames.

(and which is a bit more consistent between R and S-plus).



From anielsen at math.ku.dk  Thu Sep 18 15:03:24 2003
From: anielsen at math.ku.dk (Anders Nielsen)
Date: Thu, 18 Sep 2003 15:03:24 +0200 (CEST)
Subject: [R] Place a graphic into an R-plot
In-Reply-To: <FAD50FCCDDD5D511865200508BB2CDA502D6C184@xmx2lonib.lonib.commerzbank.com>
Message-ID: <Pine.LNX.4.40.0309181500240.23618-100000@shannon.math.ku.dk>


Hi,

You need to install the pixmap package to do that. After that
is installed the following lines illustrate how to use it.


> library(pixmap)
>  x <- read.pnm(system.file("pictures/logo.ppm", package = "pixmap")[1])
> layout(matrix(c(1,1,2,3),2,2))
> plot(rnorm(100))
> plot(rnorm(100))
> plot(x)
>

Cheers,

Anders.


On Thu, 18 Sep 2003, Morrison, Gordon wrote:

> I have a graphic image in a file (say a *.jpeg or *.png file) and want to
> put it into a plot. I have segmented the plot area by means of the layout
> function and successfully plotted my data in the appropriate segments. I
> cannot find how to put my graphic image onto the same plot. Searching the
> archives has shed little light on my challenge.
>
> Many thanks in anticipation.
>
> Gordon
>
> > version
>
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    7.1
> year     2003
> month    06
> day      16
> language R
>
>
> **********************************************************************
> This is a commercial communication from Commerzbank AG.\ \ T...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>



From Roger.Bivand at nhh.no  Thu Sep 18 15:24:32 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 18 Sep 2003 15:24:32 +0200 (CEST)
Subject: [R] Place a graphic into an R-plot
Message-ID: <Pine.LNX.4.44.0309181519300.18503-100000@reclus.nhh.no>

Gordon:

This is a copy of an off-list reply from May 2003, which may give some 
assistance - not quite the same, because here the image was inserted into 
an existing plot. It is based on using the pixmap package to import a 
ppm or pnm file, then rescaling to fit the designated space.

Roger Bivand

---------- Forwarded message ----------
Date: Mon, 26 May 2003 11:26:21 +0200 (CEST)
From: Roger Bivand <Roger.Bivand at nhh.no>
To: meinhardploner at gmx.net
Cc: 
Subject: Re: [R] overlapping a plot with an external image

> On Wednesday, May 21, 2003, at 04:38  PM, Prof Brian Ripley wrote:

>> On Wed, 21 May 2003, Meinhard Ploner wrote:
>
>>> It's possible to overlap an external image (jpg or pdf)
>>> with a plot generated with R?
>>
>>> Specifying the image as the background
>>> of the plot might not be possible...
>
>> Although this has been discussed, R graphics devices cannot as yet plot
>> bitmap images.  So all one can do is to plot a set of rectangles: for
>> that the pixmap package might be helpful.
>
>> Although we might add the ability to plot a bitmap image, note that it
>> is not straightforward, as R screen graphics devices can be dynamically
>> resized.  What should be done with a plotted image then?  Interpolate
>> on the fly?

> The plotted image should be a logo of the project / department and I
> like to add it on every plot  - for esthetical and descriptive reasons 

Here is a very rough addlogo() using pixmap:

"addlogo" <- function(x, y, pixmap) {
    if (is.list(x)) {
        y <- x$y
        x <- x$x
    }
    else if (missing(y)) 
        stop("missing y")
    if (!is.numeric(x) || !is.numeric(y)) 
        stop("non-numeric coordinates")
    if ((nx <- length(x)) <= 1 || nx != length(y) || nx > 2) 
        stop("invalid coordinate lengths")
    pixmap at bbox[1] <- x[1]
    pixmap at bbox[2] <- y[1]
    pixmap at bbox[3] <- x[2]
    pixmap at bbox[4] <- y[2]
    pixmap at cellres[1] <- (pixmap at bbox[3] - pixmap at bbox[1]) / pixmap at size[2]
    pixmap at cellres[2] <- (pixmap at bbox[4] - pixmap at bbox[2]) / pixmap at size[1]
    plot(pixmap, add=TRUE)
    invisible(pixmap)
}

which will work with locator() too. To maintain aspect, it shouldn't alter 
the relative cell resolutions, and should just use the new x or y, bur 
this is the general case. The handling of the location of the logo is 
copied & pasted from legend().

Roger

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From tlumley at u.washington.edu  Thu Sep 18 16:16:51 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 18 Sep 2003 07:16:51 -0700 (PDT)
Subject: [R] Score residuals
In-Reply-To: <E19zxZZ-0000Oq-Ip@serenity.mcc.ac.uk>
References: <E19zxZZ-0000Oq-Ip@serenity.mcc.ac.uk>
Message-ID: <Pine.A41.4.58.0309180715100.102422@homer39.u.washington.edu>

On Thu, 18 Sep 2003, Gareth Hughes wrote:

> Hi-
> Is it possible to obtain the score residuals after fitting a Weibull
> model using Surv( ).

I'm not sure which score residuals you want, but resid(,type="matrix")
gives information that you can probably construct them from.

	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From mustafa.bas at uni-bielefeld.de  Thu Sep 18 16:20:00 2003
From: mustafa.bas at uni-bielefeld.de (Mustafa Bas)
Date: Thu, 18 Sep 2003 16:20:00 +0200
Subject: [R] mstree
Message-ID: <3F69BF10.3000105@uni-bielefeld.de>

hello!

i'm searching for R-code: MSTREE (like in S-Plus)


thanks!

Mustafa Bas



From spencer.graves at pdf.com  Thu Sep 18 16:25:21 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 18 Sep 2003 07:25:21 -0700
Subject: [R] 2 time dependend states and probability transition matrix
In-Reply-To: <002101c37ddd$00150d90$d200a8c0@pc>
References: <002101c37ddd$00150d90$d200a8c0@pc>
Message-ID: <3F69C051.3090709@pdf.com>

I don't know if I understand what you want, but I wonder if the 
following might help: 

 > Ptrans <- data.frame(Jan=LETTERS[rep(1:2, 5)],
+ June=LETTERS[rep(1:2, each=5)])
 > (table(Ptrans$Jan, Ptrans$June)/dim(Ptrans)[1])
  
      A    B 
  A 0.3 0.2
  B 0.2 0.3

hope this helps.  spencer graves

Christian Schulz wrote:

>Hi,
>
>have got anybody experience or a starting
>point for me, how i can program a function 
>which calculate me a probability transition matrix with a data.frame and two states.
>
>I have some independend variable and  a class variable 
>for two states - in example one from Jan2003 and the same variables from June2003.
>
>Now i  would like to calculate the probability that PERSON X change 
>from classA to classB  between this time-period dependend from
>the independend variables.
>
>Until now i think about an "easy" function  what use the Bayes-Theorem, but it's too bad that i'm
>not a mathematican.
>
>Thanks for any starting point, idea, link or paper!
>
>P.S.
>I now the msm package, but think it's complex for my intention!?
>
>
>Regards,Christian
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From lisas at salford-systems.com  Thu Sep 18 16:27:22 2003
From: lisas at salford-systems.com (Lisa Solomon)
Date: Thu, 18 Sep 2003 07:27:22 -0700
Subject: [R] MART and Random Forests
In-Reply-To: <3F69BF10.3000105@uni-bielefeld.de>
References: <3F69BF10.3000105@uni-bielefeld.de>
Message-ID: <3F69C0CA.9060802@salford-systems.com>

I am looking for people who have used MART and Random Forests.
I am trying to get a sense of potential applications. I would appreciate 
it if you would respond to me at
lisas at salford-systems.com <mailto:lisas at salford-systems.com>

Sincerely,
Lisa Solomon
619-543-8880 x21



From M.Mamin at intershop.de  Thu Sep 18 16:41:34 2003
From: M.Mamin at intershop.de (Marc Mamin)
Date: Thu, 18 Sep 2003 16:41:34 +0200
Subject: [R] 
	lattice, trellis.device, dev.off()  within a condition  (seems t
	o be a bug)
Message-ID: <770E451830D96B4D84747B54665DA1B202DAF102@jena03.net.j.ad.intershop.net>

Hi,

I have a strange issue under W2K;
consider these two code extracts:

1)

	if(condition a){
	trellis.device(png,filename = filename_a,...
	xyplot(...
	dev.off()	
	}

2) 

	if(condition a){
	trellis.device(png,filename = filename_a,...
	xyplot(...
	}
	dev.off()	



In 1), The png file is generated, but empty; in 2), where I've taken the
dev.off clause out of the condition block, my plot is fine

I've also tried following without success:

	if(condition a){
	trellis.device(png,filename = filename_a,...
	xyplot(...
	}
	if(condition a){
	dev.off()	
	}

Is there a way to get a list of all open devices in order to close them
outsid the condition blocks ??

Thanks for your help,

Marc Mamin



From deepayan at stat.wisc.edu  Wed Sep 17 19:17:37 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Wed, 17 Sep 2003 12:17:37 -0500
Subject: [R] Date on x-axis of xyplot
In-Reply-To: <20030917095137.A16054@jessie.research.bell-labs.com>
References: <200309162331.06832.deepayan@stat.wisc.edu>
	<Pine.LNX.4.44.0309170655470.2844-100000@gannet.stats>
	<20030917095137.A16054@jessie.research.bell-labs.com>
Message-ID: <200309171217.37197.deepayan@stat.wisc.edu>

On Wednesday 17 September 2003 08:51, David James wrote:
> Prof Brian Ripley wrote:
> > On Tue, 16 Sep 2003, Deepayan Sarkar wrote:
> > > Is the date class standard enough to warrant including a check for it
> > > in lattice ?
> >
> > I don't think so.  The POSIX*t classes in R are the most standard,
> > followed by the chron package and only then the date package.
>
> If it is not overly complicated to implement, could I timidly suggest
> *not* checking for specific classes inside lattice, but rather use
> some other kind of mechanism (perhaps invoking helper functions,
> or use specific methods, etc.) to render axes?

This is definitely a good idea generally, and lattice tries to do that as much 
as possible (exceptions being splom, cloud, wireframe). However, at some 
point the tick locations and labels need to be calculated by some variation 
of pretty and format, which loses the class attribute and has to be processed 
case by case. 

In fact for POSIXct, pretty doesn't return sensible values, and that case has 
to be handled completely separately. The base plot functions seem to handle 
this via axis.POSIXct, which is not directly reusable and so is essentially 
repeated in lattice. It might be a good idea to eventually separate the 
common part out as something similar to pretty.

I also just dicovered that POSIXct handling in lattice is broken, except when 
scales$relation = "free" or "sliced". I'll fix this ASAP.

Deepayan



From sundar.dorai-raj at pdf.com  Thu Sep 18 17:08:14 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 18 Sep 2003 10:08:14 -0500
Subject: [R] 	lattice, trellis.device, dev.off()  within a condition 
	(seems t	o be a bug)
In-Reply-To: <770E451830D96B4D84747B54665DA1B202DAF102@jena03.net.j.ad.intershop.net>
References: <770E451830D96B4D84747B54665DA1B202DAF102@jena03.net.j.ad.intershop.net>
Message-ID: <3F69CA5E.9010804@pdf.com>



Marc Mamin wrote:

> Hi,
> 
> I have a strange issue under W2K;
> consider these two code extracts:
> 
> 1)
> 
> 	if(condition a){
> 	trellis.device(png,filename = filename_a,...
> 	xyplot(...
> 	dev.off()	
> 	}
> 
> 2) 
> 
> 	if(condition a){
> 	trellis.device(png,filename = filename_a,...
> 	xyplot(...
> 	}
> 	dev.off()	
> 
> 
> 
> In 1), The png file is generated, but empty; in 2), where I've taken the
> dev.off clause out of the condition block, my plot is fine
> 
> I've also tried following without success:
> 
> 	if(condition a){
> 	trellis.device(png,filename = filename_a,...
> 	xyplot(...
> 	}
> 	if(condition a){
> 	dev.off()	
> 	}
> 
> Is there a way to get a list of all open devices in order to close them
> outsid the condition blocks ??
> 

Try wrapping the xyplot call in a print() call.

e.g.

if(condition a) {
   trellis.device(...)
   print(xyplot(...))
   dev.off()
}

This is FAQ 7.24.

-sd



From cathey.tommy at epa.gov  Thu Sep 18 17:12:39 2003
From: cathey.tommy at epa.gov (Tommy E. Cathey)
Date: Thu, 18 Sep 2003 11:12:39 -0400
Subject: [R] size of text
Message-ID: <3F69CB67.AD0CB6CA@epa.gov>

How can I determine the size of a text string when using
the vfont option?

For example:
text(6, 6, "My Text String",vfont=c("sans serif", "plain"))

--
Tommy E. Cathey, Senior Scientific Application Consultant
High Performance Computing & Scientific Visualization
SAIC, Supporting the EPA
Research Triangle Park, NC
919-541-1500 EMail: cathey.tommy at epa.gov
My e-mail does not reflect the opinion of SAIC or the EPA.

Federal Contact - John B. Smith
919-541-1087    - smith.johnb at epa.gov



From Ted.Harding at nessie.mcc.ac.uk  Thu Sep 18 17:05:55 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Thu, 18 Sep 2003 16:05:55 +0100 (BST)
Subject: [R] Installing from RPM on Red Hat 9
In-Reply-To: <1063888154.10875.17.camel@biol102145.oulu.fi>
Message-ID: <XFMail.030918160555.Ted.Harding@nessie.mcc.ac.uk>

Many thanks to Jari Oksanen and Jonathan Baron for very helpful comments
on my enquiry about installing R from RPM in Red Hat 9, and the ensuing
libtk problem. It does seem to be a slightly strange situation, and I
have added some comments below in case they may be useful to others.

On 18-Sep-03 Jari Oksanen wrote:
> libtk is a `Tk' library associated with `Tcl', and known collectively
> as `Tcl/Tk' [...]. It is not installed automatically in RH, unless you
> select kernel sources(!), neither can it be easily found with the
> modern ``user-friendly'' interface. So you need to find the `tk'
> package in your CD.

I mounted each of the 3 CDs and finally found tk-8.3.5-88.i386.rpm on
CD number 3! It's very true that the GUI does not easily reveal this,
and indeed it only showed up under "kernel sources". This is bizarre,
since Tcl/Tk is such a generally useful item.

> Python, perl etc. have Tk-bindings for GUI building. So it is
> surprising that RH does not install this automatically.

Indeed! Next saga down the line: having found it, I opened up the RPM
installer on it ( rpm -i /mnt/cdrom/tk-8.3.5-88.i386.rpm ) on it, only
to find that 'rpm' went to sleep -- although there was now apparently a
libtk library in /usr/lib, rpm did not finish off its job.

So I opted for using the GUI interface accepting that the only way to
install this rather small library via that route was to install the
kernel sources as well; acceptable since this also gives you the kernel
header files which can be needed if you're compiling other software.
This worked!

On 18-Sep-03 Jonathan Baron wrote:
[...]
> I vaguely recall that the requirement for tk and tcl was not
> originally part of the RPM, but Martyn Plummer changed it because
> people (like me) were complaining that Rcmdr (and perhaps other
> packages) would not install without them.  He also started
> including "configure.log" so that you would know how he had made
> the RPM.
> 
> In the meantime, I had installed R from source, after making sure
> that I had tcl and tk.  This was quite easy (although it took a
> while for everything to finish).  So, I suggest that, if you do
> not want to install tk, then you try installing from source.  The
> installation instructions come with the source code.

I was thinking of going down that road, but in view of your commments,
Jonathan, about Rcmdr etc. it may have been a good thing to make sure
there would be no problems on that front.

Anyway, after all that, R has now been installed and seems to be working
well.

Thanks!
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 18-Sep-03                                       Time: 16:05:55
------------------------------ XFMail ------------------------------



From anne.piotet at m-td.com  Thu Sep 18 17:31:50 2003
From: anne.piotet at m-td.com (Anne Piotet)
Date: Thu, 18 Sep 2003 17:31:50 +0200
Subject: [R] lattice boxplot graphical parameters
Message-ID: <001801c37df9$faf736e0$6c00a8c0@mtd4>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030918/06f55c9a/attachment.pl

From ozric at web.de  Thu Sep 18 17:34:11 2003
From: ozric at web.de (Christian Schulz)
Date: Thu, 18 Sep 2003 17:34:11 +0200
Subject: [R] 2 time dependend states and probability transition matrix
References: <002101c37ddd$00150d90$d200a8c0@pc> <3F69C051.3090709@pdf.com>
Message-ID: <002501c37dfa$4fcd81b0$d200a8c0@pc>

Thanks, yes a good and simple starting point, how  to
integrate Bayes  should my own challenge.

christian


----- Original Message -----
From: "Spencer Graves" <spencer.graves at pdf.com>
To: "Christian Schulz" <ozric at web.de>
Cc: <r-help at stat.math.ethz.ch>
Sent: Thursday, September 18, 2003 4:25 PM
Subject: Re: [R] 2 time dependend states and probability transition matrix


> I don't know if I understand what you want, but I wonder if the
> following might help:
>
>  > Ptrans <- data.frame(Jan=LETTERS[rep(1:2, 5)],
> + June=LETTERS[rep(1:2, each=5)])
>  > (table(Ptrans$Jan, Ptrans$June)/dim(Ptrans)[1])
>
>       A    B
>   A 0.3 0.2
>   B 0.2 0.3
>
> hope this helps.  spencer graves
>
> Christian Schulz wrote:
>
> >Hi,
> >
> >have got anybody experience or a starting
> >point for me, how i can program a function
> >which calculate me a probability transition matrix with a data.frame and
two states.
> >
> >I have some independend variable and  a class variable
> >for two states - in example one from Jan2003 and the same variables from
June2003.
> >
> >Now i  would like to calculate the probability that PERSON X change
> >from classA to classB  between this time-period dependend from
> >the independend variables.
> >
> >Until now i think about an "easy" function  what use the Bayes-Theorem,
but it's too bad that i'm
> >not a mathematican.
> >
> >Thanks for any starting point, idea, link or paper!
> >
> >P.S.
> >I now the msm package, but think it's complex for my intention!?
> >
> >
> >Regards,Christian
> >
> >
> >
> > [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From solares at unsl.edu.ar  Thu Sep 18 17:34:12 2003
From: solares at unsl.edu.ar (solares@unsl.edu.ar)
Date: Thu, 18 Sep 2003 12:34:12 -0300 (ART)
Subject: [R] Save object R with tkgetSaveFile
Message-ID: <47311.170.210.173.216.1063899252.squirrel@inter14.unsl.edu.ar>

HI, my question is about the function tkgetSavefile not save any file, for 
example the next script run OK but
not save the file who i like to save, how i cant to save and object R with 
tkgetSaveFile, how i use the
function save(objet, file="foo.R") with tkgetSaveFile ?What is the error?. 
I'm work with R 1.7.1

library(tcltk)
x<-1
filetypes <- list("{Texto {.txt}} {Word {.doc}} {Pdf {.pdf}} {Postscript 
{.ps}} {fuente C{.C}} {Eps {.eps}} {Latex {.tex}} {Todos 
*}")                 
fileD <- tkgetSaveFile
(filetypes=filetypes,initialdir="c:\\temp",defaultextension=".txt")
save(x,file="foo.R") #how i cant merge tkgetSaveFile with function "save" 
for to save the object "x"?
thanks Ruben



From ucgamdo at ucl.ac.uk  Thu Sep 18 18:28:59 2003
From: ucgamdo at ucl.ac.uk (ucgamdo@ucl.ac.uk)
Date: Thu, 18 Sep 2003 17:28:59 +0100
Subject: [R] Fractals in R and having fun! (and more persp and color)
In-Reply-To: <16233.27375.199834.532442@gargle.gargle.HOWL>
References: <3.0.5.32.20030917124551.007aaab0@pop-server.ucl.ac.uk>
	<3.0.5.32.20030917124551.007aaab0@pop-server.ucl.ac.uk>
Message-ID: <3.0.5.32.20030918172859.007ab1c0@pop-server.ucl.ac.uk>

Hi Martin,

   Thanks a lot for pointing your function out to me. I tried it, and
indeed it is very fast. I will have a close look at the asymmetry problem
in my own code, although this sounds pretty bizarre to me, I mean, I
realised that there was some asymmetry but I didn't really payed attention
to that. I think that the high number of iterations that can be achieved
with your function will be the solution to obtaining 'smoother' slopes in
the perspective plot (i.e. the outer regions that rise progressively
towards the set). If you come with any ideas on how to improve that
perspective let me know. I think I'll have a go to the c code.

Thanks,
Mario.

At 10:21 18/09/03 +0200, you wrote:
>
>    Mario> Well, I started playing with fractals in R, and wrote
>    Mario> a function to generate de Mandelbrot set, which might
>    Mario> be of interest to some people
>
>    Mario>
###################################################################
>    Mario> # Mandelbrot set
>    Mario>
###################################################################
>
>    Mario> mandelbrot <- function(x = c(-3.0, 1.0),   # x coordinates
>    Mario>                        y = c(-1.8, 1.8),   # y coordinates
>    Mario>                        b = .05,            # by 'steps'
>    Mario>                        iter = 20)          # maximum number of
iterations
>
>    <..................>
>    <..................>
>    <..................>
>
>Well, only a bit more than year ago I had posted my version of
>mandelbrot() and a drawing function, see
>
>   http://finzi.psych.upenn.edu/R/Rhelp02a/archive/5898.html
>
>   [ I have a slightly updated version of the R code, that is now
>     available as ftp://stat.ethz.ch/U/maechler/R/Mandelbrot.R
>   ]
>
>which is an order of magnitude more efficient than yours (22 x
>faster for your "b = 0.01", *1), *2)
>and with an iterImage() function for drawing its result in
>several (simple) color schemes.
>I agree that the proper solution would *definitely* use C code!
>
>Your idea of using persp() -- while seen frequently in fractal books,
>is new ``for R'' however, and nice!  Thank you.
>
>
>Regards,
>Martin
>
>*1) mainly because I only have the iteration loop
>    and do the rest vectorized, but also because I have a check
>    for symmetry and make use of it when appropriate
>
>*2) For speed comparison, note that I use 10 x more iterations
>    and a much higher resolution by default
>
>*3) When I do the comparison, I see that your function's result
>    slightly differs from mine -- not for the Mandelbrot set
>    itself, but for the very ``outer points'' (the dark orange
>    ones in the image plot). Your result is
>    asymmetric and hence can't be quite correct.
>
>



From uth at zhwin.ch  Thu Sep 18 18:42:15 2003
From: uth at zhwin.ch (=?iso-8859-1?Q?=22Untern=E4hrer_Thomas=2C_uth=22?=)
Date: Thu, 18 Sep 2003 18:42:15 +0200
Subject: AW: [R] lattice boxplot graphical parameters
Message-ID: <53A181E56FB0694ABFD212F8AEDA7F6F2589D3@langouste.zhwin.ch>


See panel.bwplot

bwplot(x ~ f1 | f2, pch = -1)



Thomas



-----Urspr?ngliche Nachricht-----
Von: Anne Piotet [mailto:anne.piotet at m-td.com] 
Gesendet: Donnerstag, 18. September 2003 17:32
An: 'r-help at lists.R-project.org'
Betreff: [R] lattice boxplot graphical parameters


Hello!
I'm trying my hand at lattice representations; I would like to represent a continuous varaiable as function of 2 factors and therefore use the following: bwplot(x ~f1| f2) which works fine except that it plots black points at the value of the median. How can I remove them? 



Thanks 

Anne

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From naumov at buffalo.edu  Thu Sep 18 18:55:17 2003
From: naumov at buffalo.edu (Aleksey Naumov)
Date: Thu, 18 Sep 2003 12:55:17 -0400 (EDT)
Subject: [R] Using POSIX?t rather than "chron" or "date"
In-Reply-To: <20030917201638.AF1383A77@sitemail.everyone.net>
Message-ID: <Pine.GSO.4.05.10309181231430.254-100000@joxer.acsu.buffalo.edu>

I agree with this. I am also in a situation where I need only dates (no
need for timezones or daylight saving time), and times actually get in a
way, complicating code and creating a mess. I've had occasions when
seq.POSIXt() did not work for me (could not generate a simple daily
sequence) due to the time component, which I don't need and never
specified. Even just the display of time component ("2002-10-20 08:00:00
EDT" vs. "2002-10-20") makes dates bulky and hard to track.

I also converted one of my date related function to chron and see much
improvement in code readability and reliability. On the one hand, I'd like
to stay with R base and not introduce another library dependency, however
chron provides the level of clarity beyond POSIXt classes (this
goes for function naming as well: chron(), dates(), times() are easier to
remember then strftime(), strptime() ...)

Don't have a remedy to offer, I'll leave this to more experienced users.
Just my 2c .

Best regards,
Aleksey


On Wed, 17 Sep 2003, Gabor Grothendieck wrote:

> 
> The problem with POSIXt is that you must consider timezones 
> and daylight vs.  standard time issues even if you don't want 
> to.  This violates modularity (viz. your routines becomes coupled 
> to unrelated information) and leads to subtle errors where different 
> routines are assuming different time zones.
> 
> The problem is that the time, date, day of the week, month, etc. 
> of a date depend on its time zone so even if you are just concerned 
> with daily data in a fixed time zone, say, you are still dragged 
> into time zone and standard vs. daylight considerations.
> 
> I recently converted a program using POSIXt to chron and it allowed 
> me to eliminate all the tz parameters that I was passing around and 
> even better it meant I did not even have to THINK about time zones 
> and all the associated headaches they were giving me.
> 
> I had previously suggested that we either put chron into the base 
> or create a new timezone-less version of POSIXt to complement what 
> is already in the base.  See:
> 
> https://stat.ethz.ch/pipermail/r-devel/2003-August/027269.html
> 
> 
> 
> 
> --- Martin Maechler <maechler at stat.math.ethz.ch> wrote:
> >>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk>
> >>>>>     on Wed, 17 Sep 2003 06:58:48 +0100 (BST) writes:
> 
>     BDR> On Tue, 16 Sep 2003, Deepayan Sarkar wrote:
>     >> Is the date class standard enough to warrant including a
>     >> check for it in lattice ?
> 
>     BDR> I don't think so.  The POSIX*t classes in R are the
>     BDR> most standard, followed by the chron package and only
>     BDR> then the date package.
> 
> Definitely.  And I think we should encourage people to
> upgrade to POSIX.t from "chron" (let alone "date") more
> strongly {Note that there have been  as.POSIXct() methods for
> these classes since the beginning of the POSIX.t classes.
> 
> Could "chron" and "date" users be heard about what
> functionality they are missing in POSIX.t ?
> 
> On the other hand, the recommended package "survival" has
> a(nother?) class "date" and that package is based on S(plus) code
> and may hence not be convertible sensibly ?
> 
> Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
> Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
> ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
> phone: x-41-1-632-3408		fax: ...-1228			<><
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
>



From Benjamin.STABLER at odot.state.or.us  Thu Sep 18 19:32:05 2003
From: Benjamin.STABLER at odot.state.or.us (Benjamin.STABLER@odot.state.or.us)
Date: Thu, 18 Sep 2003 10:32:05 -0700
Subject: [R] Building and loading a DLL on Windows NT
Message-ID: <76A000A82289D411952F001083F9DD06047FE274@exsalem4-bu.odot.state.or.us>

It was the case sensitive issue.  I changed the file from .C to .c and I got
the gcc compiler instead of the g++ compiler, which resulted in the function
name staying the same.  Thanks for your help.  Also, I can't seem to find
the Borland tdump utility (everything I can find on the Internet says it
comes with Borland C++ Builder). 

All the best,
Ben Stabler

>-----Original Message-----
>From: Whit Armstrong [mailto:Whit.Armstrong at tudor.com]
>Sent: Thursday, September 18, 2003 6:01 AM
>To: 'Roger.Bivand at nhh.no'; STABLER Benjamin
>Subject: RE: [R] Building and loading a DLL on Windows NT
>
>
>One way I've used to get rid of the name mangling is to surround the
>function prototypes (or the functions themselves, if you don't 
>use a header
>file) in an export brace:
>
>export "C" {
>	int myFunc(int, int)
>	...
>}
>
>I'm surprised that SHLIB generates name mangled code.  I 
>thought one of the
>advantages of using it was that it produced a clean interface, 
>especially
>since you're using a .c file not a .cpp file.  I know that gcc uses
>different compilers based on the extension of the file.  I 
>wonder if it's
>case sensitive.  That is, if you changed the extension to .c 
>rather than .C
>would g++ use the c compiler rather than a cpp compiler.
>
>Good luck,
>Whit



From gareth.hughes-2 at stud.man.ac.uk  Thu Sep 18 19:35:36 2003
From: gareth.hughes-2 at stud.man.ac.uk (Gareth Hughes)
Date: Thu, 18 Sep 2003 18:35:36 +0100
Subject: [R] ldcase residuals
Message-ID: <E1A02gw-0000yt-7l@serenity.mcc.ac.uk>

Another Surv question:
According to the reference given in R help(Escobar and Meeker), 
'ldcase' approximates the change in minus twice the maximised 
log-likelihood on omission of each observation in turn. The 
maximum such residual is 1.26, but the actual likelihood 
displacement on omitting the correspondong observation is 7.37. 
Am I missing something?
Thanks



From deepayan at stat.wisc.edu  Thu Sep 18 19:43:05 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 18 Sep 2003 12:43:05 -0500
Subject: [R] lattice boxplot graphical parameters
In-Reply-To: <001801c37df9$faf736e0$6c00a8c0@mtd4>
References: <001801c37df9$faf736e0$6c00a8c0@mtd4>
Message-ID: <200309181243.05143.deepayan@stat.wisc.edu>

On Thursday 18 September 2003 10:31 am, Anne Piotet wrote:
> Hello!
> I'm trying my hand at lattice representations; I would like to represent a
> continuous varaiable as function of 2 factors and therefore use the
> following: bwplot(x ~f1| f2) which works fine except that it plots black
> points at the value of the median. How can I remove them?

See help(panel.bwplot). 

(These parameters can be given in the high-level bwplot call directly)

Deepayan



From Benjamin.STABLER at odot.state.or.us  Thu Sep 18 19:59:14 2003
From: Benjamin.STABLER at odot.state.or.us (Benjamin.STABLER@odot.state.or.us)
Date: Thu, 18 Sep 2003 10:59:14 -0700
Subject: [R] Building and loading a DLL on Windows NT
Message-ID: <76A000A82289D411952F001083F9DD06047FE276@exsalem4-bu.odot.state.or.us>

Thanks for the link.  Turns out I already had pedump though.  Ripley's tools
for building R for Windows zip file contains a copy of pedump.  He also
notes it in the readme.  I forgot to look at the readme for the R tools when
I was debugging my problem.  Thanks again to the R community for all its
help.

Ben Stabler

>-----Original Message-----
>From: Liaw, Andy [mailto:andy_liaw at merck.com]
>Sent: Thursday, September 18, 2003 10:40 AM
>To: STABLER Benjamin
>Subject: RE: [R] Building and loading a DLL on Windows NT
>
>
>Here's a link to pedump, which BDR has suggested for checking exported
>symbols.  http://www.simtel.net/product.php?url_fb_product_page=28111.
>
>HTH,
>Andy
>
>> -----Original Message-----
>> From: Benjamin.STABLER at odot.state.or.us 
>> [mailto:Benjamin.STABLER at odot.state.or.us] 
>> Sent: Thursday, September 18, 2003 1:32 PM
>> To: Whit.Armstrong at tudor.com; Roger.Bivand at nhh.no
>> Cc: r-help at stat.math.ethz.ch
>> Subject: RE: [R] Building and loading a DLL on Windows NT
>> 
>> 
>> It was the case sensitive issue.  I changed the file from .C 
>> to .c and I got the gcc compiler instead of the g++ compiler, 
>> which resulted in the function name staying the same.  Thanks 
>> for your help.  Also, I can't seem to find the Borland tdump 
>> utility (everything I can find on the Internet says it comes 
>> with Borland C++ Builder). 
>> 
>> All the best,
>> Ben Stabler
>> 
>> >-----Original Message-----
>> >From: Whit Armstrong [mailto:Whit.Armstrong at tudor.com]
>> >Sent: Thursday, September 18, 2003 6:01 AM
>> >To: 'Roger.Bivand at nhh.no'; STABLER Benjamin
>> >Subject: RE: [R] Building and loading a DLL on Windows NT
>> >
>> >
>> >One way I've used to get rid of the name mangling is to 
>surround the 
>> >function prototypes (or the functions themselves, if you 
>don't use a 
>> >header
>> >file) in an export brace:
>> >
>> >export "C" {
>> >	int myFunc(int, int)
>> >	...
>> >}
>> >
>> >I'm surprised that SHLIB generates name mangled code.  I
>> >thought one of the
>> >advantages of using it was that it produced a clean interface, 
>> >especially
>> >since you're using a .c file not a .cpp file.  I know that gcc uses
>> >different compilers based on the extension of the file.  I 
>> >wonder if it's
>> >case sensitive.  That is, if you changed the extension to .c 
>> >rather than .C
>> >would g++ use the c compiler rather than a cpp compiler.
>> >
>> >Good luck,
>> >Whit
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list 
>> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
>> 
>



From Ted.Harding at nessie.mcc.ac.uk  Thu Sep 18 22:18:51 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Thu, 18 Sep 2003 21:18:51 +0100 (BST)
Subject: [R] xgobi vs ggobi
Message-ID: <XFMail.030918211851.Ted.Harding@nessie.mcc.ac.uk>

Hi Folks,

I'm at the point where I'd normally install xgobi (which I've
used and found very useful), but there is the alternative of
ggobi (now at version 0.9).

Would anyone with experience of both care to indicate the
merits of either relative to the other?

The other thing I can't make out too clearly from the ggobu
website is quite what's involved in choosing between the
various options. I gather you have to install ggobi itself
(presumably the "standalone"), and then Rggobi; but there are
options for ggobi:

#  stand-alone,
# stand-alone with XML support,
# stand-alone and embeddable ggobi library,
  (this implies an embeddable ggobi library is created.)
# stand-alone and embeddable ggobi library with XML support,
# R interface (allowing ggobi to be controlled from R)
# Python interface (allowing ggobi to be controlled from Python)
# Perl interface (allowing ggobi to be controlled from Perl)

I'm not a Perl fan, so won't be strongly tempted by that option.
I might find a use for Python, however, and clearly I need the
R interface. I'm more at a loss about the first four:

# With/without XML support, with/without embeddable ggobi library

Is there likely to be much advantage, for normal use, in XML?
Are there serious implications in the footprint with this option?
[I'm not generously endowed with RAM here, and would like to keep
 as much as possible for real things, i.e. analysing data]

What are the merits of the embeddable library?

With thanks,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 18-Sep-03                                       Time: 21:18:51
------------------------------ XFMail ------------------------------



From nathanwands at hotmail.com  Thu Sep 18 22:43:45 2003
From: nathanwands at hotmail.com (Nathan Cooper)
Date: Thu, 18 Sep 2003 16:43:45 -0400
Subject: [R] Sampling With R
Message-ID: <Law11-F6rSClxnp3yd600009d79@hotmail.com>

Hello,

I'm going to use R to analyze some point count data and I need to use the 
sample function. Let's say that I have a data set like below with each row 
being a visit to a site and the numbers in the rows individual distances. 
The real data set will of course have many more rows.

>a
[[1]]
[1]  1 10  2 32 43 54 65 NA

[[2]]
[1]  2  1 32  6  5 44  3  2

[[3]]
[1]  3  3 22 56  7 NA NA NA

[[4]]
[1]  4 23  4 33 NA NA NA NA

[[5]]
[1]  5 22 12  2  2  2 32 NA

[[6]]
[1]  6 22 32 43 23  5 NA NA

I'm going to analyze how density changes with number of visits. So I will 
sample 1 visit (row) x number of times and export the distances to the 
program DISTANCE. I know that I can do the sampling part using:

sample(a,x,replace=TRUE,prob=NULL) This works fine. But I also need to 
sample 2 visits (rows) out of visits 1-3 and then 2 visits out of visits 
4-6, and so on x number of times. Any ideas?

Thanks much,

Nathan Cooper
Utah Division of Wildlife Resources
nathanwands at hotmail.com

_________________________________________________________________
Use custom emotions -- try MSN Messenger 6.0! 
http://www.msnmessenger-download.com/tracking/reach_emoticon



From arnima at u.washington.edu  Thu Sep 18 23:12:51 2003
From: arnima at u.washington.edu (Arni Magnusson)
Date: Thu, 18 Sep 2003 14:12:51 -0700 (PDT)
Subject: [R] Reverse axis in xyplot()
Message-ID: <Pine.A41.4.58.0309181344430.10556@dante60.u.washington.edu>

Creating a plot with reverse Y axis is easy enough with traditional
graphics:
> x <- 1:3
> y <- 1:3
> plot(y~x, ylim=c(3,1))
  +-----------+
1 | o         |
  |           |
2 |     o     |
  |           |
3 |         o |
  +-----------+
    1   2   3

But xyplot doesn't grasp my idea:
> xyplot(y~x, ylim=c(3,1))
  +-----------+
3 |         o |
  |           |
2 |     o     |
  |           |
1 | o         |
  +-----------+
    1   2   3

Does anyone know how the reverse Y axis can be rendered with xyplot(),
perhaps using a customized panel function? I have tried post-processing
the trellis object elements, but with no luck. I have also tried the
xyplot(-y~x) workaround, but I don't know how to display the customized
labels.

Finally, I'm aware of the y<-ordered(y,rev(y)) workaround, but a solution
for the continuous case would be preferred.

Thanks in advance,
Arni



From Rong_Wang at dfci.harvard.edu  Thu Sep 18 23:43:48 2003
From: Rong_Wang at dfci.harvard.edu (Wang, Rong)
Date: Thu, 18 Sep 2003 17:43:48 -0400
Subject: [R] R-1.7.1 package installation problem
Message-ID: <9DC0C1B584EDD511B09000508BF93F9F0A1B12@PHSEXCH24.mgh.harvard.edu>

Hi there,
   I am a bioinformatician working in DFCI. I am new to R. Yesterday I installed
the R-1.7.1 to my Linux (since I am not able to find R-1.8 on the webpage). But
I have some package installation problems ...

1. install.packages2() function isn't  available. If I type at R prompt:
>install.packages2("Biobase")
Error: couldn't find function "install.packages2"
*****************************************************

2. If I try this:
>install.packages("Biobase")
trying URL `http://cran.us.r-project.org/src/contrib/PACKAGES'
Content type `text/plain' length 127126 bytes
opened URL
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ..........
.......... .......... ....
downloaded 124Kb

Warning message: 
No package "Biobase" on CRAN. in: download.packages(pkgs, destdir = tmpd,
available = available, 
****************************************************************
I did go to http://cran.us.r-project.org/src/contrib/PACKAGES to check the
packages available there, there are quite few ... Many packages, such as
Biobase, annotate and genefilter, are not included.

Could you please give me some clue? I do appreciate!

Sincerely,
Rong



From roger at ysidro.econ.uiuc.edu  Fri Sep 19 00:11:01 2003
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Thu, 18 Sep 2003 17:11:01 -0500 (CDT)
Subject: [R] Reverse axis in xyplot()
In-Reply-To: <Pine.A41.4.58.0309181344430.10556@dante60.u.washington.edu>
Message-ID: <Pine.SOL.4.30.0309181709290.23341-100000@ysidro.econ.uiuc.edu>

I had this question a while back in trying to do image plots of sparse
matrices and ended up using this:

	image(x=1:p,y=-(n:1),t(z),axes=FALSE, col=col,xlab=xlab,ylab=ylab)
        axis(1,pretty(1:p))
        axis(2,pretty(-(n:1)),labels=rev(pretty(1:n)))


url:	www.econ.uiuc.edu/~roger/my.html	Roger Koenker
email	rkoenker at uiuc.edu			Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820

On Thu, 18 Sep 2003, Arni Magnusson wrote:

> Creating a plot with reverse Y axis is easy enough with traditional
> graphics:
> > x <- 1:3
> > y <- 1:3
> > plot(y~x, ylim=c(3,1))
>   +-----------+
> 1 | o         |
>   |           |
> 2 |     o     |
>   |           |
> 3 |         o |
>   +-----------+
>     1   2   3
>
> But xyplot doesn't grasp my idea:
> > xyplot(y~x, ylim=c(3,1))
>   +-----------+
> 3 |         o |
>   |           |
> 2 |     o     |
>   |           |
> 1 | o         |
>   +-----------+
>     1   2   3
>
> Does anyone know how the reverse Y axis can be rendered with xyplot(),
> perhaps using a customized panel function? I have tried post-processing
> the trellis object elements, but with no luck. I have also tried the
> xyplot(-y~x) workaround, but I don't know how to display the customized
> labels.
>
> Finally, I'm aware of the y<-ordered(y,rev(y)) workaround, but a solution
> for the continuous case would be preferred.
>
> Thanks in advance,
> Arni
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From tblackw at umich.edu  Fri Sep 19 00:10:08 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Thu, 18 Sep 2003 18:10:08 -0400 (EDT)
Subject: [R] R-1.7.1 package installation problem
In-Reply-To: <9DC0C1B584EDD511B09000508BF93F9F0A1B12@PHSEXCH24.mgh.harvard.edu>
References: <9DC0C1B584EDD511B09000508BF93F9F0A1B12@PHSEXCH24.mgh.harvard.edu>
Message-ID: <Pine.SOL.4.58.0309181808580.24183@rygar.gpcc.itd.umich.edu>

Rong  -

I think you want the  www.bioconductor.org  site.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -



From arnima at u.washington.edu  Fri Sep 19 00:22:45 2003
From: arnima at u.washington.edu (Arni Magnusson)
Date: Thu, 18 Sep 2003 15:22:45 -0700 (PDT)
Subject: [R] Reverse axis in xyplot()
In-Reply-To: <Pine.SOL.4.30.0309181709290.23341-100000@ysidro.econ.uiuc.edu>
References: <Pine.SOL.4.30.0309181709290.23341-100000@ysidro.econ.uiuc.edu>
Message-ID: <Pine.A41.4.58.0309181510030.103932@dante24.u.washington.edu>

Thanks Roger, for pointing out the pretty() function. It's not
cross-referenced much in the documentation... Your example is not a
trellis one, but following the same approach:

xyplot(-y~x, scales=list(y=list(at=pretty(-y),
 labels=rev(format(pretty(y))))))

With the pretty() function this workaround does the job, and all the
braces look pretty as well :)

Arni




On Thu, 18 Sep 2003, Roger Koenker wrote:

> I had this question a while back in trying to do image plots of sparse
> matrices and ended up using this:
>
> 	image(x=1:p,y=-(n:1),t(z),axes=FALSE, col=col,xlab=xlab,ylab=ylab)
>         axis(1,pretty(1:p))
>         axis(2,pretty(-(n:1)),labels=rev(pretty(1:n)))
>
>
> Roger Koenker
>



From deepayan at stat.wisc.edu  Fri Sep 19 00:39:12 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 18 Sep 2003 17:39:12 -0500
Subject: [R] Reverse axis in xyplot()
In-Reply-To: <Pine.A41.4.58.0309181510030.103932@dante24.u.washington.edu>
References: <Pine.SOL.4.30.0309181709290.23341-100000@ysidro.econ.uiuc.edu>
	<Pine.A41.4.58.0309181510030.103932@dante24.u.washington.edu>
Message-ID: <200309181739.12823.deepayan@stat.wisc.edu>

On Thursday 18 September 2003 17:22, Arni Magnusson wrote:
> Thanks Roger, for pointing out the pretty() function. It's not
> cross-referenced much in the documentation... Your example is not a
> trellis one, but following the same approach:
>
> xyplot(-y~x, scales=list(y=list(at=pretty(-y),
>  labels=rev(format(pretty(y))))))
>
> With the pretty() function this workaround does the job, and all the
> braces look pretty as well :)

This does seem to be the best workaround for now. I'll try to fix this in the 
next lattice release. 

Deepayan

> Arni
>
> On Thu, 18 Sep 2003, Roger Koenker wrote:
> > I had this question a while back in trying to do image plots of sparse
> > matrices and ended up using this:
> >
> > 	image(x=1:p,y=-(n:1),t(z),axes=FALSE, col=col,xlab=xlab,ylab=ylab)
> >         axis(1,pretty(1:p))
> >         axis(2,pretty(-(n:1)),labels=rev(pretty(1:n)))
> >
> >
> > Roger Koenker
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ok at cs.otago.ac.nz  Fri Sep 19 07:40:38 2003
From: ok at cs.otago.ac.nz (Richard A. O'Keefe)
Date: Fri, 19 Sep 2003 17:40:38 +1200 (NZST)
Subject: [R] 3D plotting in R
Message-ID: <200309190540.h8J5ecUB488449@atlas.otago.ac.nz>

A student is trying to cluster some data.  Tree-building things seem to
be pretty hopeless (we've tried most of the ones in R, I think).
Multi-dimensional scaling produces somewhat tantalising results:
things do clump together somewhat, but the clusters overlap a lot.
I was wondering if these was an artefact of squeezing it down to 2D,
and whether 3D might be better.  So
loc <- cmdscale(dist(scale(log(data))), k=3)
plot(loc)
_but_ I still get a 2D plot.

I know about persp(), and a bunch of other things in R that give me
a 3d view of a 2d field (plots of a function of 2 arguments, in other
words).  But I want to plot a bunch of 3D points and label them.

If the worst comes to the worst, I'll dump them out in a file and use
XLispStat to view them.

I've asked previously whether there's a spinning plot in R, and have been
told that there isn't and why.  I've been given one anyway, but it calls
Tcl/Tk, and for some reason that doesn't work in my setup.



From hodgess at gator.dt.uh.edu  Fri Sep 19 08:06:04 2003
From: hodgess at gator.dt.uh.edu (Erin Hodgess)
Date: Fri, 19 Sep 2003 01:06:04 -0500
Subject: [R] Sampling rows from a list
Message-ID: <200309190606.h8J664C03475@gator.dt.uh.edu>

Dear R People:

Here is a function that someone asked for today.

This is getting the sample from different rows from a list.

Hope this helps!

Sincerely,
Erin
> oe1

function(n) {

        a1 <- n%%3

        n1 <- seq(from=2,to=(n-1+a1),by=3)

        n2 <- c(1:n)[-n1]

        if(a1 == 1)n2 <- c(n2,n2[length(n2)])

        if(a1 == 2)n2 <- c(n2,n1[length(n1)])

        n3 <- length(n2)

        y <- rep(NA,n3)

        i <- 1

        while(i <= n3) {

                a4 <- n2[i]:n2[(i+1)]

                if(length(a4)==1)a4 <- c(a4,a4)

                y[i:(i+1)] <- sample(a4,replace=T,2)

                i <- i+2

        }

        return(y)

}

>



From ligges at statistik.uni-dortmund.de  Fri Sep 19 08:30:24 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 19 Sep 2003 08:30:24 +0200
Subject: [R] 3D plotting in R
In-Reply-To: <200309190540.h8J5ecUB488449@atlas.otago.ac.nz>
References: <200309190540.h8J5ecUB488449@atlas.otago.ac.nz>
Message-ID: <3F6AA280.9000502@statistik.uni-dortmund.de>

Richard A. O'Keefe wrote:

> A student is trying to cluster some data.  Tree-building things seem to
> be pretty hopeless (we've tried most of the ones in R, I think).
> Multi-dimensional scaling produces somewhat tantalising results:
> things do clump together somewhat, but the clusters overlap a lot.
> I was wondering if these was an artefact of squeezing it down to 2D,
> and whether 3D might be better.  So
> loc <- cmdscale(dist(scale(log(data))), k=3)
> plot(loc)
> _but_ I still get a 2D plot.
> 
> I know about persp(), and a bunch of other things in R that give me
> a 3d view of a 2d field (plots of a function of 2 arguments, in other
> words).  But I want to plot a bunch of 3D points and label them.

Try cloud() in package lattice or scatterplot3d() in package scatterplot3d.



> If the worst comes to the worst, I'll dump them out in a file and use
> XLispStat to view them.
> 
> I've asked previously whether there's a spinning plot in R, and have been
> told that there isn't and why.  I've been given one anyway, but it calls
> Tcl/Tk, and for some reason that doesn't work in my setup.

There are the packages "rgl" and "djmrgl" (the latter on Windows only) 
for spinning.

Uwe Ligges



From ligges at statistik.uni-dortmund.de  Fri Sep 19 08:34:10 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 19 Sep 2003 08:34:10 +0200
Subject: [R] R-1.7.1 package installation problem
In-Reply-To: <9DC0C1B584EDD511B09000508BF93F9F0A1B12@PHSEXCH24.mgh.harvard.edu>
References: <9DC0C1B584EDD511B09000508BF93F9F0A1B12@PHSEXCH24.mgh.harvard.edu>
Message-ID: <3F6AA362.1020009@statistik.uni-dortmund.de>

Wang, Rong wrote:

> Hi there,
>    I am a bioinformatician working in DFCI. I am new to R. Yesterday I installed
> the R-1.7.1 to my Linux (since I am not able to find R-1.8 on the webpage). But
> I have some package installation problems ...

R-1.8.0 is still in development (alpha releases available).

> 1. install.packages2() function isn't  available. If I type at R prompt:
> 
>>install.packages2("Biobase")
> 
> Error: couldn't find function "install.packages2"
> *****************************************************
> 
> 2. If I try this:
> 
>>install.packages("Biobase")

It's a Bioconductor package:

  install.packages("Biobase", CRAN = getOption("BIOC"))



> trying URL `http://cran.us.r-project.org/src/contrib/PACKAGES'
> Content type `text/plain' length 127126 bytes
> opened URL
> .......... .......... .......... .......... ..........
> .......... .......... .......... .......... ..........
> .......... .......... ....
> downloaded 124Kb
> 
> Warning message: 
> No package "Biobase" on CRAN. in: download.packages(pkgs, destdir = tmpd,
> available = available, 
> ****************************************************************
> I did go to http://cran.us.r-project.org/src/contrib/PACKAGES to check the
> packages available there, there are quite few ... Many packages, such as
> Biobase, annotate and genefilter, are not included.
> 
> Could you please give me some clue? I do appreciate!
> 
> Sincerely,
> Rong
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Isabelle.ZABALZA-MEZGHANI at ifp.fr  Fri Sep 19 08:43:55 2003
From: Isabelle.ZABALZA-MEZGHANI at ifp.fr (ZABALZA-MEZGHANI Isabelle)
Date: Fri, 19 Sep 2003 08:43:55 +0200
Subject: [R] Extracting objects from a list of matrix
Message-ID: <488C02265C6AD611BF200002A542182F03F2A6F3@irnts22.ifp.fr>

Hello,

I would like to have an advise about how to extract objects from a list of
matrixs
I have fitted models (stored in an object called "model") using a matrix
response and the same formula and data. I get back, from summary.lm, as many
sumarries as I have responses.
Thus I have extract the coefficient matrix for each model with the following
command :

coefficients(summary(model))

My goal is only to get the "t values" for each model. Generally to extract a
colum from a matrix I do [,"t value"], and to apply a function to a list I
use lapply. But here, I can not manage to extract the columns, since the
"[]" function, is not really a function with arguments ...

Can someone give me a solution ? (in avoiding to make a loop around my list
components).

Thanks in advance,

Isabelle.


Isabelle Zabalza-Mezghani
IFP - Reservoir Engineering Department
Rueil-Malmaison - France



From Simon.Blomberg at anu.edu.au  Fri Sep 19 09:00:38 2003
From: Simon.Blomberg at anu.edu.au (Simon Blomberg)
Date: Fri, 19 Sep 2003 17:00:38 +1000
Subject: [R] 3D plotting in R
Message-ID: <7A3A13F416B40842BD2C1753E044B359B13426@CASEVS02.cas.anu.edu.au>

I can reccommend ggobi.

http://www.ggobi.org/

Install the binary standalone, and the Rggobi package for R (both are from the above site). Works fine for me on Windows 2000, R 1.7.1.

Cheers,

Simon.

Simon Blomberg, PhD
Depression & Anxiety Consumer Research Unit
Centre for Mental Health Research
Australian National University
http://www.anu.edu.au/cmhr/
Simon.Blomberg at anu.edu.au  +61 (2) 6125 3379


> -----Original Message-----
> From: Richard A. O'Keefe [mailto:ok at cs.otago.ac.nz]
> Sent: Friday, 19 September 2003 3:41 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] 3D plotting in R
> 
> 
> A student is trying to cluster some data.  Tree-building 
> things seem to
> be pretty hopeless (we've tried most of the ones in R, I think).
> Multi-dimensional scaling produces somewhat tantalising results:
> things do clump together somewhat, but the clusters overlap a lot.
> I was wondering if these was an artefact of squeezing it down to 2D,
> and whether 3D might be better.  So
> loc <- cmdscale(dist(scale(log(data))), k=3)
> plot(loc)
> _but_ I still get a 2D plot.
> 
> I know about persp(), and a bunch of other things in R that give me
> a 3d view of a 2d field (plots of a function of 2 arguments, in other
> words).  But I want to plot a bunch of 3D points and label them.
> 
> If the worst comes to the worst, I'll dump them out in a file and use
> XLispStat to view them.
> 
> I've asked previously whether there's a spinning plot in R, 
> and have been
> told that there isn't and why.  I've been given one anyway, 
> but it calls
> Tcl/Tk, and for some reason that doesn't work in my setup.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From ligges at statistik.uni-dortmund.de  Fri Sep 19 09:08:00 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 19 Sep 2003 09:08:00 +0200
Subject: [R] Extracting objects from a list of matrix
In-Reply-To: <488C02265C6AD611BF200002A542182F03F2A6F3@irnts22.ifp.fr>
References: <488C02265C6AD611BF200002A542182F03F2A6F3@irnts22.ifp.fr>
Message-ID: <3F6AAB50.8090100@statistik.uni-dortmund.de>

ZABALZA-MEZGHANI Isabelle wrote:

> Hello,
> 
> I would like to have an advise about how to extract objects from a list of
> matrixs
> I have fitted models (stored in an object called "model") using a matrix
> response and the same formula and data. I get back, from summary.lm, as many
> sumarries as I have responses.
> Thus I have extract the coefficient matrix for each model with the following
> command :
> 
> coefficients(summary(model))
> 
> My goal is only to get the "t values" for each model. Generally to extract a
> colum from a matrix I do [,"t value"], and to apply a function to a list I
> use lapply. But here, I can not manage to extract the columns, since the
> "[]" function, is not really a function with arguments ...

Why not? Try e.g.:

X <- matrix(1:4, 2)
"["(X,,2)

So in order to solve your problem try:

  lapply(YourList, "[", , "t-value")

or use an anonymous function:

  lapply(YourList, function(x) x[, "t-value"])


Uwe Ligges



> Can someone give me a solution ? (in avoiding to make a loop around my list
> components).
> 
> Thanks in advance,
> 
> Isabelle.
> 
> 
> Isabelle Zabalza-Mezghani
> IFP - Reservoir Engineering Department
> Rueil-Malmaison - France
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



lapply(....., function(x) x[,"t value"])



From M.Mamin at intershop.de  Fri Sep 19 11:37:16 2003
From: M.Mamin at intershop.de (Marc Mamin)
Date: Fri, 19 Sep 2003 11:37:16 +0200
Subject: [R] extracting the levels of a subset of data
Message-ID: <770E451830D96B4D84747B54665DA1B202DAF105@jena03.net.j.ad.intershop.net>


Hi,


> tmpdata<-subset(myd, TYPE=="A")
> levels(tmpdata$TYPE)
> [1] "A" "B" "C"

I'd like to get only "A" as output...


Thanks for your help

Marc



From s-plus at wiwi.uni-bielefeld.de  Fri Sep 19 11:42:53 2003
From: s-plus at wiwi.uni-bielefeld.de (Peter Wolf)
Date: Fri, 19 Sep 2003 11:42:53 +0200
Subject: [R] Save object R with tkgetSaveFile
References: <47311.170.210.173.216.1063899252.squirrel@inter14.unsl.edu.ar>
Message-ID: <3F6ACF9D.2050301@wiwi.uni-bielefeld.de>

solares at unsl.edu.ar wrote:

>HI, my question is about the function tkgetSavefile not save any file, for 
>example the next script run OK but
>not save the file who i like to save, how i cant to save and object R with 
>tkgetSaveFile, how i use the
>function save(objet, file="foo.R") with tkgetSaveFile ?What is the error?. 
>I'm work with R 1.7.1
>
>library(tcltk)
>x<-1
>filetypes <- list("{Texto {.txt}} {Word {.doc}} {Pdf {.pdf}} {Postscript 
>{.ps}} {fuente C{.C}} {Eps {.eps}} {Latex {.tex}} {Todos 
>*}")                 
>fileD <- tkgetSaveFile
>(filetypes=filetypes,initialdir="c:\\temp",defaultextension=".txt")
>save(x,file="foo.R") #how i cant merge tkgetSaveFile with function "save" 
>for to save the object "x"?
>thanks Ruben
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>
Try:

 x<-1:3
a<-tkgetSaveFile()
if(0<length(a)) save(x,file=as.character(a))

Peter Wolf



From arv at ono.com  Fri Sep 19 11:58:16 2003
From: arv at ono.com (antonio rodriguez)
Date: Fri, 19 Sep 2003 11:58:16 +0200
Subject: [R] extracting columns with NA's
Message-ID: <IPEFKICOHOECENGJBAGLIEGPCDAA.arv@ono.com>

Hi All,

How do I can delete from a matrix (or array) only those columns which have
all their values set to NA?

Cheers

Antonio Rodriguez
---



From socrates at mis.tutkie.tut.ac.jp  Fri Sep 19 12:03:44 2003
From: socrates at mis.tutkie.tut.ac.jp (Sokratis Alikhanidi)
Date: Fri, 19 Sep 2003 19:03:44 +0900
Subject: [R] About PLS analysis
Message-ID: <1436556515.20030919190344@mis.tutkie.tut.ac.jp>

   Dear colleagues,

May you point me out to the PLS module in R system?
I could not find it at all using "PLS" or "partial" as the search keywords.

Thank you.
Sokratis.

----------------------------------
Sokratis ALIKHANIDI, Ph.D.
Department of Knowledge-based Information Engineering
Toyohashi University of Technology
1-1 Hibarigaoka, Tempaku-cho, Toyohashi 441, JAPAN
TEL: 0532-44-6892
FAX: 0532-44-6873
mailto:socrates at mis.tutkie.tut.ac.jp



From one_ming at yahoo.com  Fri Sep 19 12:11:50 2003
From: one_ming at yahoo.com (Yiming Zhou)
Date: Fri, 19 Sep 2003 03:11:50 -0700 (PDT)
Subject: [R] what is mechanism of help(foo)?
Message-ID: <20030919101151.25916.qmail@web21209.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030919/622cc334/attachment.pl

From s-plus at wiwi.uni-bielefeld.de  Fri Sep 19 12:22:51 2003
From: s-plus at wiwi.uni-bielefeld.de (Peter Wolf)
Date: Fri, 19 Sep 2003 12:22:51 +0200
Subject: [R] extracting columns with NA's
References: <IPEFKICOHOECENGJBAGLIEGPCDAA.arv@ono.com>
Message-ID: <3F6AD8FB.2030803@wiwi.uni-bielefeld.de>

antonio rodriguez wrote:

>Hi All,
>
>How do I can delete from a matrix (or array) only those columns which have
>all their values set to NA?
>
>Cheers
>
>Antonio Rodriguez
>---
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>
Try:

 > x<-matrix(1:16,4,4)
 > x[col(x)>=row(x)]<-NA
 > x[,! apply(x,2,function(x) all(is.na(x))) ]
     [,1] [,2] [,3]
[1,]   NA   NA   NA
[2,]    2   NA   NA
[3,]    3    7   NA
[4,]    4    8   12

Peter Wolf



From p.pagel at gsf.de  Fri Sep 19 12:21:09 2003
From: p.pagel at gsf.de (Philipp Pagel)
Date: Fri, 19 Sep 2003 12:21:09 +0200
Subject: [R] extracting the levels of a subset of data
In-Reply-To: <770E451830D96B4D84747B54665DA1B202DAF105@jena03.net.j.ad.intershop.net>
References: <770E451830D96B4D84747B54665DA1B202DAF105@jena03.net.j.ad.intershop.net>
Message-ID: <20030919102108.GA4807@porcupine.gsf.de>

	Hi!

> > tmpdata<-subset(myd, TYPE=="A")
> > levels(tmpdata$TYPE)
> > [1] "A" "B" "C"
> 
> I'd like to get only "A" as output...

rebuild the factor after subsetting:

tmpdata$TYPE <- factor(tmp$TYPE)

If you want the levels of all factors in your data frame to be
adjusted you could also use:

tmpdata <- data.frame(as.matrix( subset(myd, TYPE=='A') ))

cu
	Philipp

-- 
Dr. Philipp Pagel                                Tel.  +49-89-3187-3675
Institute for Bioinformatics / MIPS              Fax.  +49-89-3187-3585
GSF - National Research Center for Environment and Health
Ingolstaedter Landstrasse 1
85764 Neuherberg, Germany



From B.Rowlingson at lancaster.ac.uk  Fri Sep 19 12:33:25 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 19 Sep 2003 11:33:25 +0100
Subject: [R] extracting columns with NA's
In-Reply-To: <IPEFKICOHOECENGJBAGLIEGPCDAA.arv@ono.com>
References: <IPEFKICOHOECENGJBAGLIEGPCDAA.arv@ono.com>
Message-ID: <3F6ADB75.1090203@lancaster.ac.uk>

antonio rodriguez wrote:
> Hi All,
> 
> How do I can delete from a matrix (or array) only those columns which have
> all their values set to NA?

  use 'apply' to sweep through columns using a little function that sees 
if all values in a column are NA:

eg: x:
 > x
           [,1]      [,2] [,3]      [,4] [,5]       [,6]      [,7]
[1,] 0.8548990        NA   NA 0.5548089   NA 0.63123175 0.1101337
[2,] 0.9593472 0.7681048   NA 0.3365029   NA 0.04580849        NA

 > x[,apply(x,2,function(col){!all(is.na(col))})]

           [,1]      [,2]      [,3]       [,4]      [,5]
[1,] 0.8548990        NA 0.5548089 0.63123175 0.1101337
[2,] 0.9593472 0.7681048 0.3365029 0.04580849        NA

I imagine solutions requiring fewer and fewer keystrokes will appear in 
R-help presently!

Baz



From vito.muggeo at giustizia.it  Fri Sep 19 12:39:21 2003
From: vito.muggeo at giustizia.it (Vito Muggeo)
Date: Fri, 19 Sep 2003 12:39:21 +0200
Subject: R: [R] extracting columns with NA's
References: <IPEFKICOHOECENGJBAGLIEGPCDAA.arv@ono.com>
Message-ID: <00d101c37e9a$4c3dfca0$5c13070a@GIUSTIZIA.IT>

If I have understood what you mean, you can use the (surely non-optimal)
code:

#build a matrix ....
A<-matrix(1:20,nrow=5)
A[2,4]<-NA
A[,3]<-rep(NA,nrow(A))

#count the missing value in each column
fi<-apply(A,2,function(x)sum(is.na(x)))

#exclude column(s) having a number of NA equal to nrow(A). Of course you can
modify the "==" as well as "nrow(A)"
A1<-A[!which(fi==nrow(A)),]


Hope this help you
best,
vito

----- Original Message -----
From: antonio rodriguez <arv at ono.com>
To: R-help <r-help at stat.math.ethz.ch>
Sent: Friday, September 19, 2003 11:58 AM
Subject: [R] extracting columns with NA's


> Hi All,
>
> How do I can delete from a matrix (or array) only those columns which have
> all their values set to NA?
>
> Cheers
>
> Antonio Rodriguez
> ---
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ligges at statistik.uni-dortmund.de  Fri Sep 19 12:51:35 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 19 Sep 2003 12:51:35 +0200
Subject: [R] what is mechanism of help(foo)?
In-Reply-To: <20030919101151.25916.qmail@web21209.mail.yahoo.com>
References: <20030919101151.25916.qmail@web21209.mail.yahoo.com>
Message-ID: <3F6ADFB7.6020607@statistik.uni-dortmund.de>

Yiming Zhou wrote:

> I wrote a R package, and installed it. But I don't understand how R can find right help content for object "foo" when calling "help(foo)". Who can give me underlying details or any reference regarding "help(foo)"?
>  
> In fact, after installing my package "pkg_foo" and calling library(pkg_foo), I can correcttly use any function and data in "pkg_foo". But I can't get help content when I type "?function_foo". My package included the files "CONTENTS", "DESCRIPTION", "INDEX", "TITLE" and subdirectories "DATA", "MAN", "HELP", "R". 
>  
> I built it in linux system, and install it in windows system. I tried to build it in windows system using "Rcmd build package_foo". System complained: "can't found 'sh', can't found 'tar' and 'gzip'.
>  
> I appreciate for any advises.

So you haven't installed it on Windows, I guess. You would have seen the 
same complaints during the installation process. So the help files have 
not been build from your Rd files (you have created those files, I presume).

Please read ...\rw1071\src\gnuwin32\readme.packages. It tells you which 
additional tools are required to build binary packages and install 
source packages.

Uwe Ligges




> Many thanks.
>  
> Best wishes,
>  
> Yiming Zhou
>  
>  
> 
> 
> ---------------------------------
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From arv at ono.com  Fri Sep 19 12:51:42 2003
From: arv at ono.com (antonio rodriguez)
Date: Fri, 19 Sep 2003 12:51:42 +0200
Subject: [R] solved: extracting columns with NA's
Message-ID: <IPEFKICOHOECENGJBAGLAEHBCDAA.arv@ono.com>

Many, many thanks to everybody. It helped a lot

Cheers

Antonio
---



From ligges at statistik.uni-dortmund.de  Fri Sep 19 12:52:24 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 19 Sep 2003 12:52:24 +0200
Subject: [R] what is mechanism of help(foo)?
In-Reply-To: <3F6ADFB7.6020607@statistik.uni-dortmund.de>
References: <20030919101151.25916.qmail@web21209.mail.yahoo.com>
	<3F6ADFB7.6020607@statistik.uni-dortmund.de>
Message-ID: <3F6ADFE8.2010900@statistik.uni-dortmund.de>

Uwe Ligges wrote:

> Yiming Zhou wrote:
> 
>> I wrote a R package, and installed it. But I don't understand how R 
>> can find right help content for object "foo" when calling "help(foo)". 
>> Who can give me underlying details or any reference regarding 
>> "help(foo)"?
>>  
>> In fact, after installing my package "pkg_foo" and calling 
>> library(pkg_foo), I can correcttly use any function and data in 
>> "pkg_foo". But I can't get help content when I type "?function_foo". 
>> My package included the files "CONTENTS", "DESCRIPTION", "INDEX", 
>> "TITLE" and subdirectories "DATA", "MAN", "HELP", "R".  
>> I built it in linux system, and install it in windows system. I tried 
>> to build it in windows system using "Rcmd build package_foo". System 
>> complained: "can't found 'sh', can't found 'tar' and 'gzip'.
>>  
>> I appreciate for any advises.
> 
> 
> So you haven't installed it on Windows, I guess. You would have seen the 
> same complaints during the installation process. So the help files have 
> not been build from your Rd files (you have created those files, I 
> presume).
> 
> Please read ...\rw1071\src\gnuwin32\readme.packages. It tells you which 
> additional tools are required to build binary packages and install 
> source packages.
> 
> Uwe Ligges

Let me add: Please read the manual "Writing R Extensions" as well!

Uwe Ligges



From wettenhall at wehi.edu.au  Fri Sep 19 12:55:43 2003
From: wettenhall at wehi.edu.au (James Wettenhall)
Date: Fri, 19 Sep 2003 20:55:43 +1000 (EST)
Subject: [R] Installing from RPM on Red Hat 9
In-Reply-To: <200309191025.h8JAFAAC008156@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.44.0309192044040.15351-100000@unix28.alpha.wehi.edu.au>

Ted,

If you are missing a shared library (libtk8.3.so) then you could 
just find the appropriate rpm on the RedHat9 CDs, perhaps 
tk-8.3.5-88.i386.rpm in /RedHat/RPMS on the second CD, and install 
it with sudo rpm -i.

BUT, there are some known bugs in the Tcl/Tk that comes with 
Redhat 9 (which don't exist in previous Redhat distributions) :

https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=89098
https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=101678
https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=100793
http://www.interlink.com.au/anthony/tech/rh9-tcltk/

What I did recently on Redhat 9 is install Tcl/Tk 8.4 from 
source (configure;make;make install; for Tcl, then for Tk) and 
then install R from source (configure;make;make install).  You 
can get Tcl/Tk source from www.tcl.tk and to build them you need 
the X11 developer's kit which can be installed from rpm off the 
Redhat9 CDs : Install XFree86-devel-4.3.0-2.i386.rpm which requires 
fontconfig-devel-2.1-9.i386.rpm and freetype-2.1.3-6.i386.rpm.

Installing R from source will put it (by default) in 
/usr/local/bin/R rather than /usr/bin/R

HTH,
James



From ramasamya at gis.a-star.edu.sg  Fri Sep 19 13:00:01 2003
From: ramasamya at gis.a-star.edu.sg (Adaikalavan RAMASAMY)
Date: Fri, 19 Sep 2003 19:00:01 +0800
Subject: [R] extracting columns with NA's
Message-ID: <6D9E9B9DF347EF4385F6271C64FB8D560A006E@BIONIC.biopolis.one-north.com>

out <- which( colMeans( is.na( xxx ) ) == 1 )
newdata <- xxx[ , -out ]



From Isabelle.ZABALZA-MEZGHANI at ifp.fr  Fri Sep 19 13:16:55 2003
From: Isabelle.ZABALZA-MEZGHANI at ifp.fr (ZABALZA-MEZGHANI Isabelle)
Date: Fri, 19 Sep 2003 13:16:55 +0200
Subject: [R] predict for mlm does not work properly
Message-ID: <488C02265C6AD611BF200002A542182F03F2A6F8@irnts22.ifp.fr>

Hello,

I've just fitted a model with multi-responses, and I get an object of class
"lm" "mlm".
My problem is that as soon as I invoke the predict method for a dataframe
"newdata", the methods runs and give me back prediction at the fitting
points but not for newdata.

Does someone has an explanation for this behavior, and some ideas to make
predict.mlm work efficiently.

Thanks in advance

Isabelle Zabalza-Mezghani
IFP-Reservoir Engineering Department
Rueil-Malmaison - France



From Jesus.Frias at dit.ie  Fri Sep 19 13:16:07 2003
From: Jesus.Frias at dit.ie (Jesus Frias)
Date: Fri, 19 Sep 2003 12:16:07 +0100
Subject: [R] extracting the levels of a subset of data
In-Reply-To: <770E451830D96B4D84747B54665DA1B202DAF105@jena03.net.j.ad.intershop.net>
Message-ID: <LGECJJCANFBOOHCMGPJEOEMKCKAA.Jesus.Frias@dit.ie>

Hiya

> I'd like to get only "A" as output...

two solutions:
1.-use unique()

	unique(tempdata$TYPE)

to get your answer


2.-or call factor again to reduce the levels:
> tmpd <- subset(myd,clas=="A")
> levels(tmpd$clas)
[1] "A" "B" "C"
> tmpd$clas <- factor(tmpd$clas)
> levels(tmpd$clas)
[1] "A"


regards,

IOsu

 

-- 
This message has been scanned for content and 
viruses by the DIT ICT Services MailScanner Service,  
and is believed to be clean.
http://www.dit.ie



From g.p.nason at bristol.ac.uk  Fri Sep 19 13:25:43 2003
From: g.p.nason at bristol.ac.uk (Guy Nason)
Date: Fri, 19 Sep 2003 12:25:43 +0100
Subject: [R] Weird problem with my code....
Message-ID: <3F6AE7B7.8010800@bristol.ac.uk>

Dear all,

Somebody kindly pointed out a problem in my WaveThresh3 code.

I can't figure out what is wrong.

I have whittled down the code quite a bit into an example case which 
repeats the problem.

There is one R function called "ScalingFunction" and one C function 
called "CScalFn.c".

The idea is that the R function calls the C routine repeatedly to 
compute a wavelet scaling function.

It *seems* that after some iterations of the C routine later on in the 
code some NAs mysteriously enter into some of the vectors (e.g. v) which 
then gets rejected by the next call to the C routine.

I have no idea where these ghostly NAs have arrived from.

I feel as though I've done something stupid but I cannot see what it is.

Code below. I would appreciate some R brainbox letting me know where 
I've gone wrong. (I already looked at the FAQ, the mailing lists and the 
bug lists [a bit]).

My setup: R1.7.0 on RedHat Linux (2.4.18-14smp)
gcc version 3.2 20020903 (Red Hat Linux 8.0 3.2-7)

Although the problem was reported to me on R1.6.2 in Linux 7.1

Here is the C code (save as CScalFn.c and compiled using R CMD SHLIB, 
then dyn.load("CScalFn.so")   )

Many thanks,
Guy

----------------------
#include <R.h>

#define MAX(a,b)        ( (a) < (b) ? (b) : (a))
#define MIN(a,b)        ( (a) < (b) ? (a) : (b))

void CScalFn(Sfloat *v, Sfloat *ans, Sint *res, Sfloat *H, Sint *lengthH)
{
int k,n;
Sfloat sum;
Sint b,e;

for(n=0; n< *res; ++n)     {
        sum = 0.0;
        b = MAX(0, (n+1- *lengthH)/2);
        e = MIN(*res, n/2);
        /* if (n < 100) Rprintf("%d %d\n", b,e); */
        for(k=b; k<= e; ++k)    {
                sum += *(H+n-2*k) * *(v+k);
                }
        *(ans+n) = sum;
        /*
        if (sum > 0.0)
                Rprintf("sum %lf\n", sum);*/
        }
}
---------------------------------------------------------

Here is the R function (I've inserted various "cat" statements to count 
the number of NA, nan and Infs at various stages)


---------------------------------------------------------

"ScalingFunction" <-
function(resolution = 4096, itlevels = 50)
{
    res <- 4 * resolution    #
#
# Select filter and work out some fixed constants
#
    H <- c(-1/sqrt(2), 1/sqrt(2))
    lengthH <- length(H)
    ll <- lengthH
    v <- rep(0, res)    #
#
# Set initial coefficient to 1 in 2nd position on 1st level
#
    v[2] <- 1    #
#
# Now iterate the successive filtering operations to build up the scaling
# function. The actual filtering is carried out by the C routine CScalFn.
#
    for(it in 1:itlevels) {
        ans <- rep(0, res)
        cat("Before: ", sum(is.na(v)), " ", sum(is.nan(v)), " ", 
sum(is.infinite(v)),"\n")
        z <- .C("CScalFn",
            v = as.double(v),
            ans = as.double(ans),
            res = as.integer(res),
            H = as.double(H),
            lengthH = as.integer(lengthH))    #

        cat("After: ", sum(is.na(v)), " ", sum(is.nan(v)), " ", 
sum(is.infinite(v)),"\n")
#
#        We only ever take the first half of the result
#
        v <- z$ans[1:(res/2)]    #

        cat("After taking first half: ", sum(is.na(v)), " ", 
sum(is.nan(v)), " ", sum(is.infinite(v)),"\n")
#
#        Set all other coefficients equal to zero. (This is because
#        rounding errors sometimes cause small values to appear).
#
        v[ - ((2^it + 1):(2^it + ll))] <- 0   
        cat("After Setting all other coefficients equal to zero: ", 
sum(is.na(v)), " ", sum(is.nan(v)), " ", sum(is.infinite(v)),"\n")
        v <- sqrt(2) * v
        cat("After mult by root 2: ", sum(is.na(v)), " ", 
sum(is.nan(v)), " ", sum(is.infinite(v)),"\n")
        llbef <- ll
        vbef <- v    #
#
#        Check to see if the next iteration would send the number
#        of coefficients over the resolution that we can have.
#        Exit the loop if it does.
#
        if(2^(it + 1) + lengthH + ll * 2 - 2 > res/2) {
            cit <- it
            cat("Breaking : ", sum(is.na(v)), " ", sum(is.nan(v)), " ", 
sum(is.infinite(v)),"\n")
            break
        }
#
#
#        ll is the number of coefficients that are nonzero in
#        any particular run. This formula updates ll for next time
#        round.
#
        ll <- lengthH + ll * 2 - 2    #
#
#        Add some zeroes to v to make it the right length.
#
        v <- c(v, rep(0, res - length(v)))
        cat("After adding some zeros : ", sum(is.na(v)), " ", 
sum(is.nan(v)), " ", sum(is.infinite(v)),"\n")
    }
    list(x = seq(from = 0, to = 1, length = llbef), y
         = vbef[(2^cit + 1):(2^cit + llbef)])
}



From andy_liaw at merck.com  Fri Sep 19 14:06:09 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 19 Sep 2003 08:06:09 -0400
Subject: [R] predict for mlm does not work properly
Message-ID: <3A822319EB35174CA3714066D590DCD50205CB60@usrymx25.merck.com>

> From: ZABALZA-MEZGHANI Isabelle 
> 
> Hello,
> 
> I've just fitted a model with multi-responses, and I get an 
> object of class "lm" "mlm". My problem is that as soon as I 
> invoke the predict method for a dataframe "newdata", the 
> methods runs and give me back prediction at the fitting 
> points but not for newdata.

What version of R and on what platform are you doing this?  What were the
commands that you tried?

In R-1.7.1 on WinXPPro, I get:

> df <- data.frame(y1=rnorm(10), y2=rnorm(10), x1=rnorm(10),x2=rnorm(10))
> df2 <- data.frame(y1=rnorm(10), y2=rnorm(10), x1=rnorm(10),x2=rnorm(10))
> try.mlm <- lm(cbind(y1,y2) ~ x1+x2, data=df)
> predict(try.mlm)
            y1          y2
1  -0.84974045 -0.19779627
2  -1.08128909  0.17851648
3   0.23572795  0.23167228
4  -0.65118764  0.09273186
5  -0.06741819  0.10396708
6  -0.88852774 -0.05386359
7  -0.21007585  0.07839343
8  -0.07061706  0.01714900
9  -0.67554077  0.07551119
10 -1.36196165  0.33502943
> predict(try.mlm, df2)
    
              y1            y2
  1  -0.66079093  2.772385e-02
  2  -1.25399169  1.344038e-01
  3  -0.64321234  3.044455e-02
  4   0.29611924 -9.523683e-02
  5  -1.01594522  1.557392e-01
  6  -0.04513806 -1.529740e-01
  7  -0.38954683 -2.780412e-03
  8  -1.21828379 -2.460862e-01
  9  -0.38511937  6.092239e-02
  10 -0.34979146 -9.909837e-05

Seems fine to me.

Andy

 
> Does someone has an explanation for this behavior, and some 
> ideas to make predict.mlm work efficiently.
> 
> Thanks in advance
> 
> Isabelle Zabalza-Mezghani
> IFP-Reservoir Engineering Department
> Rueil-Malmaison - France
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
>



From wolski at molgen.mpg.de  Fri Sep 19 14:12:39 2003
From: wolski at molgen.mpg.de (Wolski)
Date: Fri, 19 Sep 2003 14:12:39 +0200
Subject: [R] list subsets & passing parameters question.
Message-ID: <200309191412390829.03895C19@harry.molgen.mpg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030919/4b1fa3f2/attachment.pl

From cg.pettersson at evp.slu.se  Fri Sep 19 14:23:54 2003
From: cg.pettersson at evp.slu.se (CG Pettersson)
Date: Fri, 19 Sep 2003 14:23:54 +0200
Subject: [R] Evaluating outer observations in an lme object.
Message-ID: <200309191223.OAA24760@mail1.slu.se>

Hello everybody!
I?m working with a dataset from twelve fertilizer trials, where the
technical fertilizer product and application method, but not the
intensity of fertilization, is varied. (I?m using R1.7.1 and W2000.)

The call:

ejna1t4b.lme <- lme( Yield ~ TrCode, data = ejna1t4,
+                       random = ~ 1 | Trial/Block)

works as far as I can understand well, the Block structure of the
trials is used efficiently and everything looks nice according to
plots of the object.

Now I want to evaluate the influence of observations from the
different experimental places (for example soil analyses or rainfall)
- Could I do that without skipping the Trial/Block structure, or do I
have to start from scratch again? The observed values will naturally
only have one level for each Trial, so the term Trial/Block will host
the effects of all observed (and unobserved) phenomena in each trial.
Now I want to know where the effects come from.

I?ve been looking for a text on this, both in MASS and Pinheiro &
Bates, without finding any. Any hints of where to look?

Thanks
/CG

CG Pettersson, MSci, PhD Stud.
Swedish University of Agricultural Sciences
Dep. of Ecology and Crop Production. Box 7043
SE-750 07 Uppsala



From bates at stat.wisc.edu  Fri Sep 19 14:49:24 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 19 Sep 2003 12:49:24 -0000
Subject: [R] extracting the levels of a subset of data
In-Reply-To: <LGECJJCANFBOOHCMGPJEOEMKCKAA.Jesus.Frias@dit.ie>
References: <LGECJJCANFBOOHCMGPJEOEMKCKAA.Jesus.Frias@dit.ie>
Message-ID: <6rpthx9c3s.fsf@bates4.stat.wisc.edu>

Another alternative to trim the levels of a factor is to use drop =
TRUE.

> mydata = data.frame(TYPE=factor(rep(LETTERS[1:3], 8:6)),y=rnorm(21))
> tmpdata = subset(mydata, TYPE=="A")
> levels(tmpdata$TYPE)
[1] "A" "B" "C"
> tmpdata$TYPE = tmpdata$TYPE[, drop = TRUE]
> levels(tmpdata$TYPE)
[1] "A"


Jesus Frias <Jesus.Frias at dit.ie> writes:

> Hiya
> 
> > I'd like to get only "A" as output...
> 
> two solutions:
> 1.-use unique()
> 
> 	unique(tempdata$TYPE)
> 
> to get your answer
> 
> 
> 2.-or call factor again to reduce the levels:
> > tmpd <- subset(myd,clas=="A")
> > levels(tmpd$clas)
> [1] "A" "B" "C"
> > tmpd$clas <- factor(tmpd$clas)
> > levels(tmpd$clas)
> [1] "A"
> 
> 
> regards,
> 
> IOsu
> 
>  
> 
> -- 
> This message has been scanned for content and 
> viruses by the DIT ICT Services MailScanner Service,  
> and is believed to be clean.
> http://www.dit.ie
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/



From ucgamdo at ucl.ac.uk  Fri Sep 19 14:57:28 2003
From: ucgamdo at ucl.ac.uk (ucgamdo@ucl.ac.uk)
Date: Fri, 19 Sep 2003 13:57:28 +0100
Subject: [R] 3D plotting in R
Message-ID: <3.0.5.32.20030919135728.007dc100@pop-server.ucl.ac.uk>

For plotting 3D points, you might want to check the function 'cloud' in the
'lattice' package (some good examples in the help file), you can feed the 3
most important factors to the function and see a 3d rep of your data. A
perhaps, a better 3D representation comes from the function 'sm.density' in
the 'sm' package, follow the examples for the 3d case in help(sm.density).
If the data aggregates itself visually in obvious clusters, you can use the
functions 'pam' (for small datasets) or 'clara' (for larger ones) in the
package 'cluster' to identify which elements belong to each cluster. In
this case you should first determine visually, how many cluster are
present, and them, feed this value into these functions, say 

clara('data', k = 4)

where 'data' would, for example, be a 3 columns matrix representing some
sort of Principal Component Analysis, etc. and 4 is the number of groups
you suspect are present in your data.

Alternatevely, you can try independent component analysis on your data. I
think is more powerful analysis that goes beyond the classic principal
components stuff. Check package 'fastICA' in CRAN for details.

Hope this is useful.



From axel.benz at iao.fhg.de  Fri Sep 19 14:56:55 2003
From: axel.benz at iao.fhg.de (Axel Benz)
Date: Fri, 19 Sep 2003 14:56:55 +0200
Subject: [R] newby problem - concatenate lists
Message-ID: <87F1BE4E9ED108429DB4C9B983835621A093@samos.mlab.iao.fhg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030919/51079bdc/attachment.pl

From matthew_wiener at merck.com  Fri Sep 19 15:02:06 2003
From: matthew_wiener at merck.com (Wiener, Matthew)
Date: Fri, 19 Sep 2003 09:02:06 -0400
Subject: [R] newby problem - concatenate lists
Message-ID: <AEBD81486231A343B1813FE62D3352250369A2E6@usrymx15.merck.com>

c(x,y) will do it.
Hope this helps -Matt

-----Original Message-----
From: Axel Benz [mailto:axel.benz at iao.fhg.de] 
Sent: Friday, September 19, 2003 8:57 AM
To: r-help at stat.math.ethz.ch
Subject: [R] newby problem - concatenate lists


Hi,
a very basic question:
What ist the easiest way in R to concatenate two lists of vectors?
E.g, I have
x<-list(c(1,2))
y<-list(c(3,4))
and I want to receive
list(c(1,2),c(3,4))

thank you!

Axel
________________________________________
Fraunhofer Institut fuer
Arbeitswirtschaft und Organisation (IAO)
Dipl. Inf. Axel Benz
Nobelstr. 12
D-70569 Stuttgart
Germany
Tel. +49(0)7119702289
Fax. +49(0)7119702192
mail: mailto:axel.benz at iao.fhg.de
www: http://www.vis.iao.fhg.de
________________________________________


	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From g.p.nason at bristol.ac.uk  Fri Sep 19 15:03:18 2003
From: g.p.nason at bristol.ac.uk (Guy Nason)
Date: Fri, 19 Sep 2003 14:03:18 +0100
Subject: [R] Weird problem with my code....
Message-ID: <3F6AFE96.2070509@bristol.ac.uk>

Hi,

Thanks to Barry Rawlinson and Sundar Dorai-Raj the problem was solved.

The problem was that I was doing integer division when I should have 
been doing float division followed by ceil or floor.

Sorry about that and many thanks to those who took the time to look at this.

Best,
Guy



From andy_liaw at merck.com  Fri Sep 19 15:03:06 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 19 Sep 2003 09:03:06 -0400
Subject: [R] newby problem - concatenate lists
Message-ID: <3A822319EB35174CA3714066D590DCD50205CB63@usrymx25.merck.com>

Lists are just like vectors:

> x<-list(c(1,2))
> y<-list(c(3,4))
> c(x,y)
[[1]]
[1] 1 2

[[2]]
[1] 3 4

HTH,
Andy

> -----Original Message-----
> From: Axel Benz [mailto:axel.benz at iao.fhg.de] 
> Sent: Friday, September 19, 2003 8:57 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] newby problem - concatenate lists
> 
> 
> Hi,
> a very basic question:
> What ist the easiest way in R to concatenate two lists of 
> vectors? E.g, I have
> x<-list(c(1,2))
> y<-list(c(3,4))
> and I want to receive
> list(c(1,2),c(3,4))
> 
> thank you!
> 
> Axel
> ________________________________________
> Fraunhofer Institut fuer
> Arbeitswirtschaft und Organisation (IAO)
> Dipl. Inf. Axel Benz
> Nobelstr. 12
> D-70569 Stuttgart
> Germany
> Tel. +49(0)7119702289
> Fax. +49(0)7119702192
> mail: mailto:axel.benz at iao.fhg.de
> www: http://www.vis.iao.fhg.de 
> ________________________________________
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
>



From ligges at statistik.uni-dortmund.de  Fri Sep 19 15:16:55 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 19 Sep 2003 15:16:55 +0200
Subject: [R] newby problem - concatenate lists
In-Reply-To: <87F1BE4E9ED108429DB4C9B983835621A093@samos.mlab.iao.fhg.de>
References: <87F1BE4E9ED108429DB4C9B983835621A093@samos.mlab.iao.fhg.de>
Message-ID: <3F6B01C7.9030909@statistik.uni-dortmund.de>

Axel Benz wrote:

> Hi,
> a very basic question:
> What ist the easiest way in R to concatenate two lists of vectors?
> E.g, I have
> x<-list(c(1,2))
> y<-list(c(3,4))
> and I want to receive
> list(c(1,2),c(3,4))

What about c(x, y) ???

Uwe Ligges



> thank you!
> 
> Axel
> ________________________________________
> Fraunhofer Institut fuer
> Arbeitswirtschaft und Organisation (IAO)
> Dipl. Inf. Axel Benz
> Nobelstr. 12
> D-70569 Stuttgart
> Germany
> Tel. +49(0)7119702289
> Fax. +49(0)7119702192
> mail: mailto:axel.benz at iao.fhg.de
> www: http://www.vis.iao.fhg.de
> ________________________________________
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From tblackw at umich.edu  Fri Sep 19 15:27:31 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Fri, 19 Sep 2003 09:27:31 -0400 (EDT)
Subject: [R] list subsets & passing parameters question.
In-Reply-To: <200309191412390829.03895C19@harry.molgen.mpg.de>
References: <200309191412390829.03895C19@harry.molgen.mpg.de>
Message-ID: <Pine.SOL.4.58.0309190914040.24183@rygar.gpcc.itd.umich.edu>

Eryk  -

Question 1:  Square brackets work, just the same as for
vectors, and return a (smaller or larger) list object.
The new thing with lists, not available (or needed) with
vectors, is double square brackets, which return one list
element as itself, not enclosed in a list.
See  help("Subscript").

Question 2:  No, I don't think there's a way to pass a
whole string of parameters without some kind of complicated
 eval(parse(...)) syntax (which I've never tried to use myself).

I will comment that the REASON I have never tried to use
this is that I am running R inside of emacs, so it's much
easier to edit the buffer and modify and re-run a command
than it would be to figure out some fancy syntactic way of
doing it.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Fri, 19 Sep 2003, Wolski wrote:

> Hi!
>
> Is there a way to get a subset of a list?
> I looking for some function like the function available for arrays and dataframe.
>
> x<-1:10
> x[-c(1,2)] for arrays
>
> or
> x<-data.frame(a=1,b=2)
> subset(x,select=-a)
>
> But one for a list
> x<-list(a=1,a=2)
> subset(x,select=-a)
>
> The second problem i have are that i want to store parmeters to the plot.default function in a list. eg.: pars<-list(xlim=c(0,100),xlab="irrelevant" , ylab="incredible important").
> and call the plot.default function with this list as parameters.
>
> I know that there are the way with eval(parse(text = paste("plot.default",........
>
> Is there a different one?
>
> Eryk
>
> Dipl. bio-chem. Eryk Witold Wolski    @    MPI-MG Dep. Vertebrate Genomics
> Ihnestrasse 73 14195 Berlin          'v'
> tel: 0049-30-84131285               /   \
> mail: wolski at molgen.mpg.de        ---W-W----



From rstrobl at ibe.med.uni-muenchen.de  Fri Sep 19 15:54:03 2003
From: rstrobl at ibe.med.uni-muenchen.de (Ralf Strobl)
Date: Fri, 19 Sep 2003 15:54:03 +0200
Subject: [R] Hall-Wellner-Bands
Message-ID: <200309191554.03352.rstrobl@ibe.med.uni-muenchen.de>

Hi,
does there exists a R-function computing Hall-Wellner-Confidence-Bands?
Thanks,
Ralf Strobl



From spencer.graves at pdf.com  Fri Sep 19 15:57:18 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 19 Sep 2003 06:57:18 -0700
Subject: [R] Evaluating outer observations in an lme object.
In-Reply-To: <200309191223.OAA24760@mail1.slu.se>
References: <200309191223.OAA24760@mail1.slu.se>
Message-ID: <3F6B0B3E.5090009@pdf.com>

Might "update" help?  spencer graves

CG Pettersson wrote:

>Hello everybody!
>I?m working with a dataset from twelve fertilizer trials, where the
>technical fertilizer product and application method, but not the
>intensity of fertilization, is varied. (I?m using R1.7.1 and W2000.)
>
>The call:
>
>ejna1t4b.lme <- lme( Yield ~ TrCode, data = ejna1t4,
>+                       random = ~ 1 | Trial/Block)
>
>works as far as I can understand well, the Block structure of the
>trials is used efficiently and everything looks nice according to
>plots of the object.
>
>Now I want to evaluate the influence of observations from the
>different experimental places (for example soil analyses or rainfall)
>- Could I do that without skipping the Trial/Block structure, or do I
>have to start from scratch again? The observed values will naturally
>only have one level for each Trial, so the term Trial/Block will host
>the effects of all observed (and unobserved) phenomena in each trial.
>Now I want to know where the effects come from.
>
>I?ve been looking for a text on this, both in MASS and Pinheiro &
>Bates, without finding any. Any hints of where to look?
>
>Thanks
>/CG
>
>CG Pettersson, MSci, PhD Stud.
>Swedish University of Agricultural Sciences
>Dep. of Ecology and Crop Production. Box 7043
>SE-750 07 Uppsala
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From tlumley at u.washington.edu  Fri Sep 19 15:56:48 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 19 Sep 2003 06:56:48 -0700 (PDT)
Subject: [R] 3D plotting in R
In-Reply-To: <200309190540.h8J5ecUB488449@atlas.otago.ac.nz>
References: <200309190540.h8J5ecUB488449@atlas.otago.ac.nz>
Message-ID: <Pine.A41.4.58.0309190656230.85540@homer39.u.washington.edu>

On Fri, 19 Sep 2003, Richard A. O'Keefe wrote:
> I know about persp(), and a bunch of other things in R that give me
> a 3d view of a 2d field (plots of a function of 2 arguments, in other
> words).  But I want to plot a bunch of 3D points and label them.
>

I would try {g,x}gobi.

	-thomas



From spencer.graves at pdf.com  Fri Sep 19 16:04:22 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 19 Sep 2003 07:04:22 -0700
Subject: [R] About PLS analysis
In-Reply-To: <1436556515.20030919190344@mis.tutkie.tut.ac.jp>
References: <1436556515.20030919190344@mis.tutkie.tut.ac.jp>
Message-ID: <3F6B0CE6.4060109@pdf.com>

Where did you search?  From "www.r-project.org" -> search -> "R site 
search", I just got 84 matches for "pls" and 63 for "partial least 
squares".  A generalization of PLS is "structural equations", for which 
I got 53 matches.  The third match for "pls" mentioned package 
"pls.pcr", which presumably is still available.  I have not used this, 
so I can't say if this is still available and if it is whether something 
else might be better.  Have you tried this? 

hope this helps. 
spencer graves

Sokratis Alikhanidi wrote:

>   Dear colleagues,
>
>May you point me out to the PLS module in R system?
>I could not find it at all using "PLS" or "partial" as the search keywords.
>
>Thank you.
>Sokratis.
>
>----------------------------------
>Sokratis ALIKHANIDI, Ph.D.
>Department of Knowledge-based Information Engineering
>Toyohashi University of Technology
>1-1 Hibarigaoka, Tempaku-cho, Toyohashi 441, JAPAN
>TEL: 0532-44-6892
>FAX: 0532-44-6873
>mailto:socrates at mis.tutkie.tut.ac.jp
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From tlumley at u.washington.edu  Fri Sep 19 16:03:02 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 19 Sep 2003 07:03:02 -0700 (PDT)
Subject: [R] newby problem - concatenate lists
In-Reply-To: <87F1BE4E9ED108429DB4C9B983835621A093@samos.mlab.iao.fhg.de>
References: <87F1BE4E9ED108429DB4C9B983835621A093@samos.mlab.iao.fhg.de>
Message-ID: <Pine.A41.4.58.0309190702500.85540@homer39.u.washington.edu>

On Fri, 19 Sep 2003, Axel Benz wrote:

> Hi,
> a very basic question:
> What ist the easiest way in R to concatenate two lists of vectors?
> E.g, I have
> x<-list(c(1,2))
> y<-list(c(3,4))
> and I want to receive
> list(c(1,2),c(3,4))

c(x,y)

	-thomas



From tlumley at u.washington.edu  Fri Sep 19 16:05:47 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 19 Sep 2003 07:05:47 -0700 (PDT)
Subject: [R] list subsets & passing parameters question.
In-Reply-To: <200309191412390829.03895C19@harry.molgen.mpg.de>
References: <200309191412390829.03895C19@harry.molgen.mpg.de>
Message-ID: <Pine.A41.4.58.0309190704440.85540@homer39.u.washington.edu>

On Fri, 19 Sep 2003, Wolski wrote:
>
> The second problem i have are that i want to store parmeters to the plot.default function in a list. eg.: pars<-list(xlim=c(0,100),xlab="irrelevant" , ylab="incredible important").
> and call the plot.default function with this list as parameters.
>
> I know that there are the way with eval(parse(text = paste("plot.default",........
>

do.call("f",list(a,b,c))

calls f(a,b,c)

which I think is what you want.

	-thomas



From alessandro.valli at amd.com  Fri Sep 19 16:16:23 2003
From: alessandro.valli at amd.com (alessandro.valli@amd.com)
Date: Fri, 19 Sep 2003 16:16:23 +0200
Subject: [R] Very long console input lines
Message-ID: <D1B7EDF38A7CD311A68C0008C72825DF090409F4@deexmta5.amd.com>

Thank you Spencer,
but it seems not to work with strings :

myquery <- c("select ..... very long string 		=> gives syntax error
myquery <- {c("select ..... very long string		=> gives syntax error

It seems that the closing " is required in any case.

Thank you in any case,
Alessandro Valli


-----Original Message-----
From: Spencer Graves [mailto:spencer.graves at pdf.com]
Sent: Mittwoch, 17. September 2003 18:46
To: Valli, Alessandro
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Very long console input lines


Have you considered enclosing the "very long string" in parentheses?  
Then R will know that it is not syntactically correct until it reaches 
the end.  To avoid that kind of thing, I routinely include "(" just to 
the right of "<-" in virtually any statement that might otherwise get 
split onto two lines in a way that the first might be evaluated without 
the second. 

hope this helps.  spencer graves
p.s.  I got this from Venables and Ripley, but I can't remember which 
book or which page. 

alessandro.valli at AMD.com wrote:

>Hallo all,
>
>I got a problem executing R in batch-mode via a perl-script (under Win2000) : 
>	system ("Rterm.exe --slave --no-save --no-restore \<Rfile.r \>NUL");
>The R execution is aborting with syntax error due to very-long lines.
>My solution is converting
>a <- c("very long string")
>to
>a <- paste("short string 1",\n
>                "short string 2",\n
>                      ...,\n
>                "short string n")
>It is not very elegant ...
>Does anybody know a better solution ?
>
>Thank you in advance,
>Alessandro Valli
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From solares at unsl.edu.ar  Fri Sep 19 16:19:43 2003
From: solares at unsl.edu.ar (solares@unsl.edu.ar)
Date: Fri, 19 Sep 2003 11:19:43 -0300 (ART)
Subject: [R] Saving with tkgetSaveFile
Message-ID: <35642.170.210.173.216.1063981183.squirrel@inter14.unsl.edu.ar>

HI, i'm trying to save a data frame with the next script:
x<-c(1,2,3)#suposse here the data frame
a<-tkgetSaveFile()
a<-tkgetSaveFile()
save(x,file=as.character(a))

but i obtain the next warning message:
Warning messages: 
1: the condition has length > 1 and only the first element will be used in: 
if (file == "") stop("`file' must be non-empty string") 
2: only first element of `description' argument used

and nothing file is saved, ?What is the error? Thanks Ruben



From tblackw at umich.edu  Fri Sep 19 17:00:00 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Fri, 19 Sep 2003 11:00:00 -0400 (EDT)
Subject: [R] Saving with tkgetSaveFile
In-Reply-To: <35642.170.210.173.216.1063981183.squirrel@inter14.unsl.edu.ar>
References: <35642.170.210.173.216.1063981183.squirrel@inter14.unsl.edu.ar>
Message-ID: <Pine.SOL.4.58.0309191056320.28303@asteroids.gpcc.itd.umich.edu>

Ruben  -

Why not simply   save(x, file="new.file.name")  ?

See  help("save"), help("files").  The file name must be
quoted, and it must be passed as a named argument to save().

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Fri, 19 Sep 2003 solares at unsl.edu.ar wrote:

> HI, i'm trying to save a data frame with the next script:
> x<-c(1,2,3)#suposse here the data frame
> a<-tkgetSaveFile()
> a<-tkgetSaveFile()
> save(x,file=as.character(a))
>
> but i obtain the next warning message:
> Warning messages:
> 1: the condition has length > 1 and only the first element will be used in:
> if (file == "") stop("`file' must be non-empty string")
> 2: only first element of `description' argument used
>
> and nothing file is saved, ?What is the error? Thanks Ruben



From enzmann at kfn.uni-hannover.de  Fri Sep 19 17:02:32 2003
From: enzmann at kfn.uni-hannover.de (Dirk Enzmann)
Date: Fri, 19 Sep 2003 17:02:32 +0200
Subject: [R] Job Announcement
Message-ID: <3F6B1A88.1030105@kfn.uni-hannover.de>

The Criminological Research Institute of Lower Saxony (KFN) in Germany 
(Hannover) seeks a quantitative methodologist (Psychologist/Sociologist) 
to work in a research project on the developmental consequences of 
incarceration of juvenile delinquents.

For more detailed information see:

http://www.kfn.de/KFN_180903.pdf

Application deadline is October 12, 2003, but applications will be
accepted until the position is filled.

More information about the Institute is available at our home page 
http://www.kfn.de


*************************************************
Dr. Dirk Enzmann
Criminological Research Institute of Lower Saxony
Luetzerodestr. 9
D-30161 Hannover
Germany

phone: +49-511-348.36.32
fax:   +49-511-348.36.10
email: ENZMANN at KFN.uni-hannover.de

http://www.kfn.de



From tlumley at u.washington.edu  Fri Sep 19 17:33:09 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 19 Sep 2003 08:33:09 -0700 (PDT)
Subject: [R] Very long console input lines
In-Reply-To: <D1B7EDF38A7CD311A68C0008C72825DF090409F4@deexmta5.amd.com>
References: <D1B7EDF38A7CD311A68C0008C72825DF090409F4@deexmta5.amd.com>
Message-ID: <Pine.A41.4.58.0309190830280.202332@homer06.u.washington.edu>

On Fri, 19 Sep 2003 alessandro.valli at amd.com wrote:

> Thank you Spencer,
> but it seems not to work with strings :
>
> myquery <- c("select ..... very long string 		=> gives syntax error
> myquery <- {c("select ..... very long string		=> gives syntax error
>

I think you will have to rewrite this somehow.  If you have a known  upper
limit on line length you could modify the limit in the R source, but it's
probably easier to put the
  "select .... very long string
into a separate file and use readLines() on it, bypassing the limit in the
parser.

	-thomas



From jps at sanger.ac.uk  Fri Sep 19 17:59:22 2003
From: jps at sanger.ac.uk (Jason Skelton)
Date: Fri, 19 Sep 2003 16:59:22 +0100
Subject: [R] Updating R
Message-ID: <3F6B27DA.5010602@sanger.ac.uk>


Could anyone advise me on the easist way of upgrading R from 1.6.2 to 
1.7.1 ? is there a script like the bioconductor update.packages ?
or do I have to download the tar file and build it again ?
apologies for the trivial questions from a biologist


many thanks

Jason
-- 
--------------------------------
Jason Skelton
Pathogen Microarrays
Wellcome Trust Sanger Institute
Hinxton
Cambridge
CB10 1SA

Tel +44(0)1223 834244 Ext 7123
Fax +44(0)1223 494919



From Ted.Harding at nessie.mcc.ac.uk  Fri Sep 19 17:20:50 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 19 Sep 2003 16:20:50 +0100 (BST)
Subject: [R] Installing from RPM on Red Hat 9
In-Reply-To: <Pine.LNX.4.44.0309192044040.15351-100000@unix28.alpha.wehi.edu.au>
Message-ID: <XFMail.030919151831.Ted.Harding@nessie.mcc.ac.uk>

On 19-Sep-03 James Wettenhall wrote:
> 
> BUT, there are some known bugs in the Tcl/Tk that comes with 
> Redhat 9 (which don't exist in previous Redhat distributions) :
> 
> https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=89098
> https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=101678
> https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=100793
> http://www.interlink.com.au/anthony/tech/rh9-tcltk/

Thanks, James! Most revealing and worth being made aware of. I've
downloaded the rebuilt Tcl and Tk RPMs from the last-named website,
had no problems with 'rpm -U ... ' on them, and will see if all is
now well. (If not, I'll roll up my sleeves, adopt your practice,
and rebuild from source).

Best wishes,
Ted.



From ligges at statistik.uni-dortmund.de  Fri Sep 19 18:17:24 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 19 Sep 2003 18:17:24 +0200
Subject: [R] Updating R
In-Reply-To: <3F6B27DA.5010602@sanger.ac.uk>
References: <3F6B27DA.5010602@sanger.ac.uk>
Message-ID: <3F6B2C14.7070403@statistik.uni-dortmund.de>

Jason Skelton wrote:

> 
> Could anyone advise me on the easist way of upgrading R from 1.6.2 to 
> 1.7.1 ? is there a script like the bioconductor update.packages ?
> or do I have to download the tar file and build it again ?
> apologies for the trivial questions from a biologist

The latter.

Uwe Ligges

> 
> many thanks
> 
> Jason



From petr.pikal at precheza.cz  Fri Sep 19 18:19:47 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri, 19 Sep 2003 18:19:47 +0200
Subject: [R] angle and distance between sets of vectors
Message-ID: <3F6B48C3.22860.23E8C69@localhost>

Dear all

I want to find a distance between two points in three dimensional space and an 
angle between two vectors from [0,0,0] to specified points. I searched archives 
and found some solution using dist but I am not sure how to use it if I have 
several sets of such points.

Here is some example

#Four points

y <- c(1,0,0)
z <- c(1,1,0)
x <- 2*z
v <- 2*x

# two sets

mata<-rbind(y,x)

> mata
  [,1] [,2] [,3]
y    1    0    0
x    2    2    0

matb<-rbind(z,v)

> matb
  [,1] [,2] [,3]
z    1    1    0
v    4    4    0

# I want a distances and angles

> dist(rbind(y,z))
[1] 1
> dist(rbind(y/sum(y),z/sum(z)))
[1] 0.7071068


> dist(rbind(x,v))
[1] 2.828427
> dist(rbind(x/sum(x),v/sum(v)))
[1] 0


# they are actually here but they are a little bit hidden
 
> dist(rbind(mata,matb))
         y        x        z
x 2.236068                  
z 1.000000 1.414214         
v 5.000000 2.828427 4.242641

> dist(rbind(mata/rowSums(mata),matb/rowSums(matb)))
          y x z
x 0.7071068    
z 0.7071068 0  
v 0.7071068 0 0

Before I start programming a for loop (something like that)

for (i in 1:length(mata)) result<-dist(rbind(mata[i,],matb[i,]))

I would like to ask some more experienced if there is a way how to get a vector 
of distances and angles directly?

Something like
some.experienced.use.of.dist(mata,matb) resulting in matrix or dataframe or 2 
vectors or whatever

           distance        angle
1         1,                 .7071068
2         2.828427,     0

will be greatly appreciated.
Thanks

Petr Pikal
Petr Pikal
petr.pikal at precheza.cz



From Brian.J.GREGOR at odot.state.or.us  Fri Sep 19 19:13:36 2003
From: Brian.J.GREGOR at odot.state.or.us (Brian.J.GREGOR@odot.state.or.us)
Date: Fri, 19 Sep 2003 10:13:36 -0700
Subject: [R] using matrix data for function
Message-ID: <372EFF9FE4E42E419C978E7A305DC5FE0379AA81@exsalem5.odot.state.or.us>

It seems to me that the simplest approach is as follows. Say you have a
function as follows:
dosomething <- function(x,y) 0.523*x^2 + 0.34*y
Then you just use apply as follows to get your result (assuming that the
first column of matrix m contains the x values and the second column
contains the y values:
apply(m, 1, function(x) dosomething(x[1], x[2]))

Brian Gregor, P.E.
Transportation Planning Analysis Unit
Oregon Department of Transportation
Brian.J.GREGOR at odot.state.or.us
(503) 986-4120


-----Original Message-----
> From: Bing Zhang [mailto:bih at ornl.gov] 
> Sent: Wednesday, September 17, 2003 2:03 PM
> To: r-help
> Subject: [R] using matrix data for function
> 
> 
> Hi All,
> 
> I have a function, f(x,y)
> I have a matrix of data, m,  with the 1st column is x and the 
> 2nd column is y What's the best way to get f(x,y) for each 
> row of the matrix? I tried 
> result<-f(m[,1],m[,2]) but it doesn't work.
> 
> Thanks!
> 
> Bing



From olau at fas.harvard.edu  Fri Sep 19 19:37:05 2003
From: olau at fas.harvard.edu (Olivia Lau)
Date: Fri, 19 Sep 2003 13:37:05 -0400
Subject: [R] survreg distributions
Message-ID: <000f01c37ed4$a7b8ab90$4e02a8c0@olau>

Hi,

I need to find out if the exponential, weibull, and log-normal
distributions in the survreg package use the same
parameterizations as in the functions rexp, rweibull, and
rlnorm.  I have looked at the R-help and Venables & Ripley
(2002), and they have different functional forms for the
Weibull, for example.

If the parameterizations are different, is there an easy way to
use the link function to take random draws from the survreg
distributions?

In addition, does anyone know what the functional form for the
lognormal is, with respect to the survreg package?  I looked in
VR (p. 353), but I can't seem to map that parameterization (in
terms of tau and lambda) onto the standard lognormal
parameterization.

Any advice is greatly appreciated.

Yours,

Olivia Lau.



From cg.pettersson at evp.slu.se  Fri Sep 19 19:51:35 2003
From: cg.pettersson at evp.slu.se (CG Pettersson)
Date: Fri, 19 Sep 2003 19:51:35 +0200
Subject: [R] Evaluating outer observations in an lme object.
In-Reply-To: <3F6B0B3E.5090009@pdf.com>
Message-ID: <200309191751.TAA14184@mail1.slu.se>

Oh, the question might have been more precisely formulated I guess...

"update" surely helps a lot in the practical work at the computer. But
that is not my problem. The problem is where and how to introduce the
variables in the command.

I?ve tried things like:     random = ~ P.AL | Trial/Block 
as the random call, looking for some sort of direct effect from the
soil analysis P.AL. That results in a worse model than without the
term, possibly becouse the effect of the soil already is,
implicitlely, inside the term Trial.
What I am looking for is a way of evaluating several factors that have
just one observation for each Trial, still having the the nice
Trial/Block structure present in the model. 

Or am I just stupid?

/CG

-------------------
> Might "update" help?  spencer graves
> 
> CG Pettersson wrote:
> 
> >Hello everybody!
> >I?m working with a dataset from twelve fertilizer trials, where the
> >technical fertilizer product and application method, but not the
> >intensity of fertilization, is varied. (I?m using R1.7.1 and
W2000.)
> >
> >The call:
> >
> >ejna1t4b.lme <- lme( Yield ~ TrCode, data = ejna1t4,
> >+                       random = ~ 1 | Trial/Block)
> >
> >works as far as I can understand well, the Block structure of the
> >trials is used efficiently and everything looks nice according to
> >plots of the object.
> >
> >Now I want to evaluate the influence of observations from the
> >different experimental places (for example soil analyses or
rainfall)
> >- Could I do that without skipping the Trial/Block structure, or do
I
> >have to start from scratch again? The observed values will
naturally
> >only have one level for each Trial, so the term Trial/Block will
host
> >the effects of all observed (and unobserved) phenomena in each
trial.
> >Now I want to know where the effects come from.
> >
> >I?ve been looking for a text on this, both in MASS and Pinheiro &
> >Bates, without finding any. Any hints of where to look?
> >
> >Thanks
> >/CG
> >
> >CG Pettersson, MSci, PhD Stud.
> >Swedish University of Agricultural Sciences
> >Dep. of Ecology and Crop Production. Box 7043
> >SE-750 07 Uppsala
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >  
> >
> 
> 
CG Pettersson, MSci, PhD Stud.
Swedish University of Agricultural Sciences
Dep. of Ecology and Crop Production. Box 7043
SE-750 07 Uppsala



From anna at email.arc.nasa.gov  Fri Sep 19 19:53:22 2003
From: anna at email.arc.nasa.gov (Anna Pryor)
Date: Fri, 19 Sep 2003 10:53:22 -0700
Subject: [R] What is wrong with m?
Message-ID: <200309191053.22400.anna@email.arc.nasa.gov>


I've been programming in one directory and recently switched to another 
directory.  It appears that in doing so I've uncovered a problem.  My 
environment was saving something so that my code would work and now I don't 
know how to fix it.  I have the following bit of code:

  for(i in 1:index){
    indexList = lst[i]
	for(j in 2:jobs-1){
           indexList = c(indexList,lst[i+index*j])
        }
   saveList[i,] = indexList

   }


   for (i in 1:index){
	m[i] = median(saveList[i,])

}
m

In my new directory, I am getting the complaint that "object m is not found."  
Does anyone know what that means?

Anna



From spencer.graves at pdf.com  Fri Sep 19 20:10:35 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 19 Sep 2003 11:10:35 -0700
Subject: [R] What is wrong with m?
In-Reply-To: <200309191053.22400.anna@email.arc.nasa.gov>
References: <200309191053.22400.anna@email.arc.nasa.gov>
Message-ID: <3F6B469B.9000105@pdf.com>

For "m[1] <- ..." to work, "m" must already be defined.  To fix this, 
execute "m <- rep(NA, index)" before your second "for" loop, and it 
should work. 

hope this helps. 
spencer graves

Anna Pryor wrote:

>I've been programming in one directory and recently switched to another 
>directory.  It appears that in doing so I've uncovered a problem.  My 
>environment was saving something so that my code would work and now I don't 
>know how to fix it.  I have the following bit of code:
>
>  for(i in 1:index){
>    indexList = lst[i]
>	for(j in 2:jobs-1){
>           indexList = c(indexList,lst[i+index*j])
>        }
>   saveList[i,] = indexList
>
>   }
>
>
>   for (i in 1:index){
>	m[i] = median(saveList[i,])
>
>}
>m
>
>In my new directory, I am getting the complaint that "object m is not found."  
>Does anyone know what that means?
>
>Anna
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From cafa at ime.unicamp.br  Fri Sep 19 20:15:50 2003
From: cafa at ime.unicamp.br (Cezar Augusto de Freitas Anselmo)
Date: Fri, 19 Sep 2003 15:15:50 -0300 (BRT)
Subject: [R] Locate first index
In-Reply-To: <200309191026.h8JAFAAG008156@stat.math.ethz.ch>
Message-ID: <Pine.GSO.4.05.10309191507020.18607-100000@athenas.ime.unicamp.br>

Hi, all. I'd like to know if exists a manner to get the first index where
a condition is attained in a vector. For example,

There is a better solution than 

first.index <- table(subject[corretor==27])[1]

(give me the subject for the first time that corretor is 27)?

Thanks,

========================================
Cezar Freitas (ICQ 109128967)
IMECC - UNICAMP
Campinas, SP - Brasil



From spencer.graves at pdf.com  Fri Sep 19 20:29:48 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 19 Sep 2003 11:29:48 -0700
Subject: [R] Locate first index
In-Reply-To: <Pine.GSO.4.05.10309191507020.18607-100000@athenas.ime.unicamp.br>
References: <Pine.GSO.4.05.10309191507020.18607-100000@athenas.ime.unicamp.br>
Message-ID: <3F6B4B1C.4060503@pdf.com>

Have you considered "which", as in the following: 
 > a <- rep(1:2, 2)
 > a
[1] 1 2 1 2
 > which(a==1)
[1] 1 3
 > which(a==1)[1]
[1] 1

hope this helps.  spencer graves

Cezar Augusto de Freitas Anselmo wrote:

>Hi, all. I'd like to know if exists a manner to get the first index where
>a condition is attained in a vector. For example,
>
>There is a better solution than 
>
>first.index <- table(subject[corretor==27])[1]
>
>(give me the subject for the first time that corretor is 27)?
>
>Thanks,
>
>========================================
>Cezar Freitas (ICQ 109128967)
>IMECC - UNICAMP
>Campinas, SP - Brasil
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From bates at stat.wisc.edu  Fri Sep 19 20:28:08 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 19 Sep 2003 18:28:08 -0000
Subject: [R] What is wrong with m?
In-Reply-To: <3F6B469B.9000105@pdf.com>
References: <200309191053.22400.anna@email.arc.nasa.gov>
	<3F6B469B.9000105@pdf.com>
Message-ID: <6rr82cbpjz.fsf@bates4.stat.wisc.edu>

Spencer Graves <spencer.graves at pdf.com> writes:

> For "m[1] <- ..." to work, "m" must already be defined.  To fix this,
> execute "m <- rep(NA, index)" before your second "for" loop, and it
> should work. hope this helps. spencer graves

If saveList is actually a list, it would be more effective to use

 m = sapply(saveList, median)

That way there is no need to generate m and then change each element
of m in a loop.

One neglected aspect of the S language is the ability to apply
functions to structures instead of iterating over the components of a
structure.  Phil Spector's book "An Introduction to S and S-PLUS"
emphasizes this.

> Anna Pryor wrote:
> 
> > I've been programming in one directory and recently switched to
> > another directory.  It appears that in doing so I've uncovered a
> > problem.  My environment was saving something so that my code would
> > work and now I don't know how to fix it.  I have the following bit
> > of code:
> 
> >
> >  for(i in 1:index){
> >    indexList = lst[i]
> >	for(j in 2:jobs-1){
> >           indexList = c(indexList,lst[i+index*j])
> >        }
> >   saveList[i,] = indexList
> >
> >   }
> >
> >
> >   for (i in 1:index){
> >	m[i] = median(saveList[i,])
> >
> >}
> >m
> >
> > In my new directory, I am getting the complaint that "object m is
> > not found."  Does anyone know what that means?
> 
> >
> >Anna
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/



From GPetris at uark.edu  Fri Sep 19 20:36:20 2003
From: GPetris at uark.edu (Giovanni Petris)
Date: Fri, 19 Sep 2003 13:36:20 -0500 (CDT)
Subject: [R] Locate first index
In-Reply-To: <Pine.GSO.4.05.10309191507020.18607-100000@athenas.ime.unicamp.br>
	(message from Cezar Augusto de Freitas Anselmo on Fri, 19 Sep 2003
	15:15:50 -0300 (BRT))
References: <Pine.GSO.4.05.10309191507020.18607-100000@athenas.ime.unicamp.br>
Message-ID: <200309191836.h8JIaKbc001148@definetti.uark.edu>


((1:length(corretor))[corretor==27])[1]

should also work, and avoids computing table. 

Giovanni Petris

> Date: Fri, 19 Sep 2003 15:15:50 -0300 (BRT)
> From: Cezar Augusto de Freitas Anselmo <cafa at ime.unicamp.br>
> Sender: r-help-bounces at stat.math.ethz.ch
> Precedence: list
> 
> Hi, all. I'd like to know if exists a manner to get the first index where
> a condition is attained in a vector. For example,
> 
> There is a better solution than 
> 
> first.index <- table(subject[corretor==27])[1]
> 
> (give me the subject for the first time that corretor is 27)?
> 
> Thanks,
> 
> ========================================
> Cezar Freitas (ICQ 109128967)
> IMECC - UNICAMP
> Campinas, SP - Brasil
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
>



From MSchwartz at medanalytics.com  Fri Sep 19 20:40:48 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 19 Sep 2003 13:40:48 -0500
Subject: [R] Locate first index
In-Reply-To: <Pine.GSO.4.05.10309191507020.18607-100000@athenas.ime.unicamp.br>
References: <Pine.GSO.4.05.10309191507020.18607-100000@athenas.ime.unicamp.br>
Message-ID: <1063996848.4208.41.camel@localhost>

On Fri, 2003-09-19 at 13:15, Cezar Augusto de Freitas Anselmo wrote:
> Hi, all. I'd like to know if exists a manner to get the first index where
> a condition is attained in a vector. For example,
> 
> There is a better solution than 
> 
> first.index <- table(subject[corretor==27])[1]
> 
> (give me the subject for the first time that corretor is 27)?
> 
> Thanks,


first.index <- min(which(corretor == 27))

For example:

corretor <- c(15, 23, 27, 34, 25, 27, 26)

which(corretor == 27)
[1] 3 6

min(which(corretor == 27))
[1] 3

See ?which

HTH,

Marc Schwartz



From bates at stat.wisc.edu  Fri Sep 19 22:56:37 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 19 Sep 2003 20:56:37 -0000
Subject: [R] Locate first index
In-Reply-To: <1063996848.4208.41.camel@localhost>
References: <Pine.GSO.4.05.10309191507020.18607-100000@athenas.ime.unicamp.br>
	<1063996848.4208.41.camel@localhost>
Message-ID: <6rd6dwbioc.fsf@bates4.stat.wisc.edu>

It may be easier to use the match function which is defined to return
the index of the first match.

> corretor <- c(15, 23, 27, 34, 25, 27, 26)
> match(27, corretor)
[1] 3

Marc Schwartz <MSchwartz at medanalytics.com> writes:

> On Fri, 2003-09-19 at 13:15, Cezar Augusto de Freitas Anselmo wrote:
> > Hi, all. I'd like to know if exists a manner to get the first index where
> > a condition is attained in a vector. For example,
> > 
> > There is a better solution than 
> > 
> > first.index <- table(subject[corretor==27])[1]
> > 
> > (give me the subject for the first time that corretor is 27)?
> > 
> > Thanks,
> 
> 
> first.index <- min(which(corretor == 27))
> 
> For example:
> 
> corretor <- c(15, 23, 27, 34, 25, 27, 26)
> 
> which(corretor == 27)
> [1] 3 6
> 
> min(which(corretor == 27))
> [1] 3
> 
> See ?which



From MSchwartz at medanalytics.com  Fri Sep 19 23:26:12 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 19 Sep 2003 16:26:12 -0500
Subject: [R] Locate first index
In-Reply-To: <6rd6dwbioc.fsf@bates4.stat.wisc.edu>
References: <Pine.GSO.4.05.10309191507020.18607-100000@athenas.ime.unicamp.br>
	<1063996848.4208.41.camel@localhost>
	<6rd6dwbioc.fsf@bates4.stat.wisc.edu>
Message-ID: <1064006772.4208.56.camel@localhost>

On Fri, 2003-09-19 at 15:57, Douglas Bates wrote:
> It may be easier to use the match function which is defined to return
> the index of the first match.
> 
> > corretor <- c(15, 23, 27, 34, 25, 27, 26)
> > match(27, corretor)
> [1] 3


True and presumably much faster as the size of the search vector and the
offset of the first match increases. If this is being done repeatedly,
timing would become important.

Thanks for pointing that out.

Marc



From uruguay2002 at tiscali.es  Fri Sep 19 17:54:10 2003
From: uruguay2002 at tiscali.es (Veronica)
Date: Fri, 19 Sep 2003 15:54:10 GMT
Subject: [R] Saludos desde Madrid
Message-ID: <pbdm1stpo828kcj.190920031754@oemcomputer>

Hola amig@:
Me llamo Ver?nica. Te escribo desde Madrid, Espa?a y formo parte de un equipo del Movimiento Humanista.

Hoy son ya millones de personas las que experimentan c?mo la sociedad en que vivimos se deshumaniza d?a a d?a. El ser humano ha perdido todo valor, el mundo se mueve en torno al dinero y en base al ego?smo, mientras las personas van quedando cada vez m?s desamparadas. De este modo, mientras cada uno est?  preocupado de sus propios problemas, todos vivimos cada vez peor.

Sin embargo los humanistas sabemos que el absurdo de la globalizaci?n dirigida, pensada s?lo en t?rminos econ?micos por los grandes bancos y multinacionales, no va a triunfar. Existe otro proceso de mundializaci?n donde el ser humano ha crecido internamente y se encamina a la formaci?n de una Naci?n Humana Universal. Hay una nueva sensibilidad en el ser humano que experimenta que cualquier cosa que pase en cualquier punto del planeta termina por afectarle a uno mismo. Este es un proceso hist?rico irreversible y as? lo sienten ya en su coraz?n millones de personas.

Todo ser humano tiene derecho a una vida digna por el simple hecho de haber nacido. Y en el interior de todo ser humano hay algo muy grande que est? buscando expresarse en el mundo.

Nuestro proyecto consiste en conectar y organizar a esos millones de personas de sensibilidad humanista.

Si est?s interesado en saber m?s de nuestra propuesta, por favor sigue estos pasos:
1- Abre un mensaje nuevo
2- Escribe en el asunto la palabra SI
3- Env?alo a la direcci?n: veronica2003 at tiscali.es

Esperamos tu mensaje.

Un saludo afectuoso.
Ver?nica

======================================
Este mensaje se env?a una ?nica vez, por tanto no es
necesario que te des de baja de ninguna lista. Si su
contenido no es de tu inter?s, disculpanos.

No obstante, si conoces a otras personas a quienes
pueda interesar nuestra propuesta, te pedimos que
les reenvies este mensaje. Gracias de antemano.



From TyagiAnupam at aol.com  Sat Sep 20 03:55:13 2003
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Fri, 19 Sep 2003 21:55:13 EDT
Subject: [R] using aggregate with survey-design and survey functions
Message-ID: <6c.31b80388.2c9d0d81@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030919/60407318/attachment.pl

From TyagiAnupam at aol.com  Sat Sep 20 04:39:00 2003
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Fri, 19 Sep 2003 22:39:00 EDT
Subject: [R] modelling open source software
Message-ID: <17a.204580b5.2c9d17c4@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030919/d47f5991/attachment.pl

From spencer.graves at pdf.com  Sat Sep 20 04:47:38 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 19 Sep 2003 19:47:38 -0700
Subject: [R] using aggregate with survey-design and survey functions
In-Reply-To: <6c.31b80388.2c9d0d81@aol.com>
References: <6c.31b80388.2c9d0d81@aol.com>
Message-ID: <3F6BBFCA.1010907@pdf.com>

What do you get from the following: 

      is.element("income", objects())

spencer graves

TyagiAnupam at aol.com wrote:

>Hi R users,
>
>I am trying to use the aggregate function with a survey design object and 
>survey functions, but get the following error. I think I am incorrectly using the 
>syntax somehow, and it may not be possible to access variables directly by 
>name in a survey-design object. Am I right? How do I fix this problem? I have 
>used aggregate with "mean" and "weighted.mean", and that works fine. I am trying 
>to find out where the difference is. What would be an efficient alternative 
>to aggregate for a large dataset?
>
>  
>
>>s <- aggregate(income,list(age,sex),function(x) (svymean(~x,design=d.na)))
>>    
>>
>Error in aggregate(income, list(age, sex), function(x) (svymean(~x,  : 
>    Object "income" not found
> 
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From TyagiAnupam at aol.com  Sat Sep 20 04:52:21 2003
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Fri, 19 Sep 2003 22:52:21 EDT
Subject: [R] using aggregate with survey-design and survey functions
Message-ID: <33.3e15e4c3.2c9d1ae5@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030919/b7ba8386/attachment.pl

From kjetil at entelnet.bo  Sat Sep 20 08:10:01 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Sat, 20 Sep 2003 02:10:01 -0400
Subject: [R] mstree
In-Reply-To: <3F686773.8070702@uni-bielefeld.de>
Message-ID: <3F6BB6F9.31201.D28C25@localhost>

On 17 Sep 2003 at 15:53, Mustafa Bas wrote:

Is mstree minimum spanning tree? Then try 
mst in package ape (on CRAN).

Kjetil Halvorsen

> hello,
> 
> i have some problems with mstree!
> there are no similar function in R like in S-Plus!
> Is there somebody who has a code in R ????
> 
> Thanks
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From maechler at stat.math.ethz.ch  Sat Sep 20 10:15:10 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 20 Sep 2003 10:15:10 +0200
Subject: [R] Locate first index
In-Reply-To: <1064006772.4208.56.camel@localhost>
References: <Pine.GSO.4.05.10309191507020.18607-100000@athenas.ime.unicamp.br>
	<1063996848.4208.41.camel@localhost>
	<6rd6dwbioc.fsf@bates4.stat.wisc.edu>
	<1064006772.4208.56.camel@localhost>
Message-ID: <16236.3214.495033.795640@gargle.gargle.HOWL>

>>>>> "Marc" == Marc Schwartz <MSchwartz at medanalytics.com>
>>>>>     on Fri, 19 Sep 2003 16:26:12 -0500 writes:

    Marc> On Fri, 2003-09-19 at 15:57, Douglas Bates wrote:

    DB> It may be easier to use the match function which is
    DB> defined to return the index of the first match.
    DB> 
    DB> > corretor <- c(15, 23, 27, 34, 25, 27, 26) 
    DB> > match(27, corretor)
    DB>  [1]

indeed!

    Marc> True and presumably much faster as the size of the
    Marc> search vector and the offset of the first match
    Marc> increases. If this is being done repeatedly, timing
    Marc> would become important.

yes, and match() is much more readable too.

Since I'm sure that I have seen the not-so-good  min(which(a == x)) or
which(a == x)[1] several times before, I've added a note about
this (in the SEE ALSO section) of help(which) --- still in the
optimistic assumption that people read help pages... ;-)

Martin



From Ted.Harding at nessie.mcc.ac.uk  Sat Sep 20 10:37:02 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sat, 20 Sep 2003 09:37:02 +0100 (BST)
Subject: [R] modelling open source software
In-Reply-To: <17a.204580b5.2c9d17c4@aol.com>
Message-ID: <XFMail.030920093702.Ted.Harding@nessie.mcc.ac.uk>

On 20-Sep-03 TyagiAnupam at aol.com wrote:
> The following paper may be of interest to some. The author is generous
> about sharing a recently revised version.
> <A
> HREF="http://papers.ssrn.com/sol3/papers.cfm?abstract_id=259648">http://
> papers.ssrn.com/sol3/papers.cfm?abstract_id=259648</A>

Thanks for this pointer,

  http://papers.ssrn.com/sol3/papers.cfm?abstract_id=259648

An interesting paper, though I don't feel at home in the economic
territory that Jennifer Kuan inhabits, and I'm not at all sure about
her statistics. However, I have noticed a tiny and possibly significant
detail.

In the equations she uses indicators "H" and "L" to denote "high types"
and "low types" of "consumers" of closed source and open source software
(and according to her, "high" closed-source consumers are rich, while
"high" open-source consumers are competent).

In her economic model for the closed-source market, the "H" and "L" are
subscripts. In the model for open-source, they are superscripts. Is this
a subtly encoded signal of where she stands?

Best wishes to all,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 20-Sep-03                                       Time: 09:37:02
------------------------------ XFMail ------------------------------



From spencer.graves at pdf.com  Sat Sep 20 11:42:26 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 20 Sep 2003 02:42:26 -0700
Subject: [R] using aggregate with survey-design and survey functions
In-Reply-To: <33.3e15e4c3.2c9d1ae5@aol.com>
References: <33.3e15e4c3.2c9d1ae5@aol.com>
Message-ID: <3F6C2102.9000805@pdf.com>

In the following command: 

    s <- aggregate(income,list(age,sex),function(x) 
(svymean(~x,design=d.na)))

Since 'is.element("income", objects())' was FALSE, it was not in the 
search path, which it must be for "aggregate" to find it.  I suggest you 
read or reread something like "An Introduction to R", downloadable from 
"www.r-project.org" -> "Manuals". 

hope this helps. 
spencer graves

TyagiAnupam at aol.com wrote:

>In a message dated 9/19/03 7:46:07 PM Pacific Daylight Time, 
>spencer.graves at pdf.com writes:
>
>  
>
>>What do you get from the following: 
>>
>>   is.element("income", objects())
>>
>>spencer graves
>>
>>    
>>
>
>  
>
>>is.element("income", objects())
>>    
>>
>[1] FALSE
>
>The following may give further info about why I am getting this. Design 
>object is "d.na"
>
>  
>
>>attributes(d.na)
>>    
>>
>$names
>[1] "cluster"   "strata"    "prob"      "allprob"   "call"      "variables"
>[7] "nPSU"     
>
>$class
>[1] "survey.design"
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From djw1005 at cam.ac.uk  Sat Sep 20 11:58:02 2003
From: djw1005 at cam.ac.uk (Damon Wischik)
Date: Sat, 20 Sep 2003 10:58:02 +0100 (BST)
Subject: [R] Locate first index
In-Reply-To: <16236.3214.495033.795640@gargle.gargle.HOWL>
Message-ID: <Pine.SOL.3.96.1030920104638.26890A-100000@virgo.cus.cam.ac.uk>


> Since I'm sure that I have seen the not-so-good  min(which(a == x)) or
> which(a == x)[1] several times before, I've added a note about
> this (in the SEE ALSO section) of help(which) --- still in the
> optimistic assumption that people read help pages... ;-)

I had noticed the remark on the help page, but it had never occurred to me
to apply it to boolean vectors. It says "for the index of the minimum or
maximum", so I think it is to be used for numeric vectors, without it
occurring to me that booleans can be typecast into numerics. (I can never
remember which way round the typecasting goes, so I always use explicit
constructions like "ifelse(x,1,0)").

I have generally avoided which.min, because it looks (to me) as if it is
finding the location of the minima of a numerical vector. This is on the
grounds that "which" returns a vector of locations, so I expect
"which.min" to do the same, i.e. to behave like which(x==min(x)). I know
(from reading the help pages) that this is not what it does.  However, I
don't like putting "which.min" into my code for this purpose, because it
makes it harder for me to read.

If, on the other hand, there was a command "first" or maybe
"first.which" which was aliased to which.min, I would happily write
  first.which(x==3)

Damon.



From Chrhanck at aol.com  Sat Sep 20 13:44:07 2003
From: Chrhanck at aol.com (Chrhanck@aol.com)
Date: Sat, 20 Sep 2003 07:44:07 -0400
Subject: [R] Logit and Probit for Panel data
Message-ID: <1B466FAB.7E330AF0.006F5466@aol.com>

Dear R users/experts, 

I've heard it's possible to estimate the above kinds of models in R. However, after (an admittedly brief) survey of the packages, I haven't found an obvious candidate. Can you offer any help? (Yes I'm a newby.)

Yours sincerely

Christoph Hanck
Studentische Hilkskraft
Lehrstuhl f?r Empirische Wirtschaftsforschung, Prof. Dr. Wilfling
http://www.wiwi.uni-muenster.de/~05/
WWU Muenster
Tel.: +49-251-83 25045
eMail: chrhanck at aol.com



From ceciliashiraiwa at ig.com.br  Sat Sep 20 14:27:17 2003
From: ceciliashiraiwa at ig.com.br (=?iso-8859-1?Q?Cec=EDlia_Shiraiwa?=)
Date: Sat, 20 Sep 2003 09:27:17 -0300
Subject: [R] factorial design
Message-ID: <001c01c37f72$8c1bd760$59bc64c8@shiraiwa>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030920/bc358364/attachment.pl

From sundar.dorai-raj at pdf.com  Sat Sep 20 14:49:56 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Sat, 20 Sep 2003 07:49:56 -0500
Subject: [R] Logit and Probit for Panel data
In-Reply-To: <1B466FAB.7E330AF0.006F5466@aol.com>
References: <1B466FAB.7E330AF0.006F5466@aol.com>
Message-ID: <3F6C4CF4.1000603@pdf.com>

See ?glm and ?binomial.

-sundar


Chrhanck at aol.com wrote:
> Dear R users/experts, 
> 
> I've heard it's possible to estimate the above kinds of models in R. However, after (an admittedly brief) survey of the packages, I haven't found an obvious candidate. Can you offer any help? (Yes I'm a newby.)
> 
> Yours sincerely
> 
> Christoph Hanck
> Studentische Hilkskraft
> Lehrstuhl f?r Empirische Wirtschaftsforschung, Prof. Dr. Wilfling
> http://www.wiwi.uni-muenster.de/~05/
> WWU Muenster
> Tel.: +49-251-83 25045
> eMail: chrhanck at aol.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jfox at mcmaster.ca  Sat Sep 20 15:55:02 2003
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 20 Sep 2003 09:55:02 -0400
Subject: [R] Logit and Probit for Panel data
In-Reply-To: <3F6C4CF4.1000603@pdf.com>
References: <1B466FAB.7E330AF0.006F5466@aol.com>
	<1B466FAB.7E330AF0.006F5466@aol.com>
Message-ID: <5.1.0.14.2.20030920094433.01ff2768@127.0.0.1>

Dear Sundar and Christoph,

The glmmPQL function in the MASS package will fit generalised linear mixed 
models (appropriate, e.g., for longitudinal data), as will the GLMM 
function in the lme4 package. I believe that there are some other 
facilities for doing so as well, but they don't come to mind.

I hope that this helps,
  John

At 07:49 AM 9/20/2003 -0500, Sundar Dorai-Raj wrote:
>See ?glm and ?binomial.
>
>-sundar
>
>
>Chrhanck at aol.com wrote:
>>Dear R users/experts,
>>I've heard it's possible to estimate the above kinds of models in R. 
>>However, after (an admittedly brief) survey of the packages, I haven't 
>>found an obvious candidate. Can you offer any help? (Yes I'm a newby.)
>>Yours sincerely
>>Christoph Hanck
>>Studentische Hilkskraft
>>Lehrstuhl f?r Empirische Wirtschaftsforschung, Prof. Dr. Wilfling

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From kjetil at entelnet.bo  Sat Sep 20 16:11:04 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Sat, 20 Sep 2003 10:11:04 -0400
Subject: [R] Extracting objects from a list of matrix
In-Reply-To: <488C02265C6AD611BF200002A542182F03F2A6F3@irnts22.ifp.fr>
Message-ID: <3F6C27B8.29290.4308C4@localhost>

On 19 Sep 2003 at 8:43, ZABALZA-MEZGHANI Isabelle wrote:

[
is a function:

> test <- list(a=1, b=2, c=3)
> "["(test,2)
$b
[1] 2


Kjetil Halvorsen

> Hello,
> 
> I would like to have an advise about how to extract objects from a list of
> matrixs
> I have fitted models (stored in an object called "model") using a matrix
> response and the same formula and data. I get back, from summary.lm, as many
> sumarries as I have responses.
> Thus I have extract the coefficient matrix for each model with the following
> command :
> 
> coefficients(summary(model))
> 
> My goal is only to get the "t values" for each model. Generally to extract a
> colum from a matrix I do [,"t value"], and to apply a function to a list I
> use lapply. But here, I can not manage to extract the columns, since the
> "[]" function, is not really a function with arguments ...
> 
> Can someone give me a solution ? (in avoiding to make a loop around my list
> components).
> 
> Thanks in advance,
> 
> Isabelle.
> 
> 
> Isabelle Zabalza-Mezghani
> IFP - Reservoir Engineering Department
> Rueil-Malmaison - France
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Ted.Harding at nessie.mcc.ac.uk  Sat Sep 20 16:07:59 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sat, 20 Sep 2003 15:07:59 +0100 (BST)
Subject: [R] conditional function definition?
Message-ID: <XFMail.030920150759.Ted.Harding@nessie.mcc.ac.uk>

Hi Folks,

What is the best way to avoid a function being read in
anew (and masking an exiting function) when a definition
of it has already been established in R?

Reason: Fernando Tusell and I are working up Schafer's 'CAT'
for R (basically done now, just needs some cosmetic tidying up).

This uses a function 'slice.index', present in S but not in
the versions of R we were working with at the time. So we put
in a definition (copied from R-help ... ).

However, it seems that slice.index is now in "base" in latest
versions of R. So it would seem a bit silly to read it in anew.
Nevertheless, probably we should keep it in for the sake of people
still using older versions of R who would not have it.

So what's the best method to do

if( some test for function slice.index absent ) {
  slice.index<-function(....){....}
}

??

Thanks,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 20-Sep-03                                       Time: 15:07:59
------------------------------ XFMail ------------------------------



From lamac_k at hotmail.com  Sat Sep 20 16:26:30 2003
From: lamac_k at hotmail.com (lamack lamack)
Date: Sat, 20 Sep 2003 14:26:30 +0000
Subject: [R] permutations function
Message-ID: <BAY7-F1083GOe6hLT2R00008c46@hotmail.com>

Dear all

If I consider

d<- c(1,2,3,4)
N<- 4
n<- 2
out1<- matrix(0,N^n,n)
z<-1

for(i in 1:N)
{
for(j in 1:N)
{
   out1[z,1] = d[i]
   out1[z,2] = d[j]
   z<- z+1
}
}

library(gregmisc)
out2<- permutations(N,n,d,T,T)

I have that out1==out2. Ok

Now, if I consider

d<- c(1,2,3,4)
N<- 4
n<- 3
out1<- matrix(0,N^n,n)
z<-1

for(i in 1:N)
{
for(j in 1:N)
{
  for(k in 1:N)
  {
    out1[z,1] = d[i]
    out1[z,2] = d[j]
    out1[z,3] = d[k]
   z<- z+1
  }
}
}

out2<- permutations(N,n,d,T,T)

I have that out1 is not equal out1.

My question is: Why out1 is not equal out2 ?

Best regards



From kjetil at entelnet.bo  Sat Sep 20 16:38:22 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Sat, 20 Sep 2003 10:38:22 -0400
Subject: [R] About PLS analysis
In-Reply-To: <1436556515.20030919190344@mis.tutkie.tut.ac.jp>
Message-ID: <3F6C2E1E.9609.5C0669@localhost>

On 19 Sep 2003 at 19:03, Sokratis Alikhanidi wrote:

pls.pcr on CRAN

Kjetil Halvorsen

>    Dear colleagues,
> 
> May you point me out to the PLS module in R system?
> I could not find it at all using "PLS" or "partial" as the search keywords.
> 
> Thank you.
> Sokratis.
> 
> ----------------------------------
> Sokratis ALIKHANIDI, Ph.D.
> Department of Knowledge-based Information Engineering
> Toyohashi University of Technology
> 1-1 Hibarigaoka, Tempaku-cho, Toyohashi 441, JAPAN
> TEL: 0532-44-6892
> FAX: 0532-44-6873
> mailto:socrates at mis.tutkie.tut.ac.jp
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From spencer.graves at pdf.com  Sat Sep 20 16:57:07 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 20 Sep 2003 07:57:07 -0700
Subject: [R] factorial design
In-Reply-To: <001c01c37f72$8c1bd760$59bc64c8@shiraiwa>
References: <001c01c37f72$8c1bd760$59bc64c8@shiraiwa>
Message-ID: <3F6C6AC3.20302@pdf.com>

The first model includes C and interactions with C, which are combined 
with the residuals in the other two models.  The first model has 3, 3, 
3, 3, and 32 degrees of freedom for C, A:C, B:C, A:B:C, and residuals, 
respectively.  The other two models combine these two into a single 
residual term with 44 = 3 + 3 + 3 + 3 + 32 degrees of freedom. 

hope this helps.  spencer graves

Cec?lia Shiraiwa wrote:

>    Hello all,
>    I?m trying to study a factorial design, but I can?t understand why did Df, Sum Sq and Mean Sq of residuals alter when I Split the interaction? I think that Split the interaction must not alter the residuals. Am I doing something wrong?
>    Could anyone help me?
>    My data and functions I tried are:
> 
>Y<-c(196,213,183,
>        192,253,199,
>        251,331,276,
>        128,220,196,
>        272,275,227,
>        204,305,185,
>        135,322,276,
>        262,284,250,
>        272,275,227,
>        204,305,185,
>        135,322,276,
>        262,284,250,
>        296,369,344,
>        325,396,403,
>        370,323,319,
>        341,418,318)
>A<-factor(rep(c(0,1),c(24,24)))
>B<-factor(rep(c(0,1,0,1),c(12,12,12,12)))
>C<-factor(rep(c(rep(0:3,each=3)),times=4))
>av <- aov(Y ~ A + B + A*B + C + A*C + B*C + A*B*C )
>summary(av)
>avAB <- aov(Y ~ A/B)
>summary (avAB, split=list("A:B"=list(A1=1, A2=2)))
>avBA <- aov(Y ~ B/A)
>summary (avBA, split=list("B:A"=list(B1=1, B2=2)))
>
>
>Thanks
>Cecilia
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From spencer.graves at pdf.com  Sat Sep 20 17:12:52 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 20 Sep 2003 08:12:52 -0700
Subject: [R] conditional function definition?
In-Reply-To: <XFMail.030920150759.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.030920150759.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <3F6C6E74.8080402@pdf.com>

Have you considered: 

 > exists("slice.index")
[1] TRUE

       In other circumstances, I've tested various components of 
"version". 

hope this helps. 
spencer graves

(Ted Harding) wrote:

>Hi Folks,
>
>What is the best way to avoid a function being read in
>anew (and masking an exiting function) when a definition
>of it has already been established in R?
>
>Reason: Fernando Tusell and I are working up Schafer's 'CAT'
>for R (basically done now, just needs some cosmetic tidying up).
>
>This uses a function 'slice.index', present in S but not in
>the versions of R we were working with at the time. So we put
>in a definition (copied from R-help ... ).
>
>However, it seems that slice.index is now in "base" in latest
>versions of R. So it would seem a bit silly to read it in anew.
>Nevertheless, probably we should keep it in for the sake of people
>still using older versions of R who would not have it.
>
>So what's the best method to do
>
>if( some test for function slice.index absent ) {
>  slice.index<-function(....){....}
>}
>
>??
>
>Thanks,
>Ted.
>
>
>--------------------------------------------------------------------
>E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
>Fax-to-email: +44 (0)870 167 1972
>Date: 20-Sep-03                                       Time: 15:07:59
>------------------------------ XFMail ------------------------------
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From kjetil at entelnet.bo  Sat Sep 20 17:30:31 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Sat, 20 Sep 2003 11:30:31 -0400
Subject: [R] conditional function definition?
In-Reply-To: <XFMail.030920150759.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <3F6C3A57.30552.8BC714@localhost>

On 20 Sep 2003 at 15:07, Ted Harding wrote:

What about 

> exists("slice.index")
[1] TRUE

Kjetil Halvorsen

> Hi Folks,
> 
> What is the best way to avoid a function being read in
> anew (and masking an exiting function) when a definition
> of it has already been established in R?
> 
> Reason: Fernando Tusell and I are working up Schafer's 'CAT'
> for R (basically done now, just needs some cosmetic tidying up).
> 
> This uses a function 'slice.index', present in S but not in
> the versions of R we were working with at the time. So we put
> in a definition (copied from R-help ... ).
> 
> However, it seems that slice.index is now in "base" in latest
> versions of R. So it would seem a bit silly to read it in anew.
> Nevertheless, probably we should keep it in for the sake of people
> still using older versions of R who would not have it.
> 
> So what's the best method to do
> 
> if( some test for function slice.index absent ) {
>   slice.index<-function(....){....}
> }
> 
> ??
> 
> Thanks,
> Ted.
> 
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 167 1972
> Date: 20-Sep-03                                       Time: 15:07:59
> ------------------------------ XFMail ------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From mario at unir.br  Sat Sep 20 17:41:23 2003
From: mario at unir.br (Mario Alberto Cozzuol)
Date: Sat, 20 Sep 2003 11:41:23 -0400
Subject: [R] persp graphs
Message-ID: <1064072483.3f6c7523a21d0@www.unir.br>

Hi,
I am doing my way on R, with much experimenting. So, I am trying to plot a 3d 
graphic ussing "persp" and entering a data set (attached) of UTM coordinates 
as x,y and a pH values as z. However when I try an error message comes out 
telling that increasing x and y values are expected. Jus ordering the first 
vector does not help, and, of course, order the first two independently makes 
no sense since they are geographic coordinates. So, what I am doing wrong?
Thank you all very much for the help,

Mario
-- 
Dr. Mario A. Cozzuol
Laborat?rio de Biologia Evolutiva
Universidade Federal de Rond?nia
BR 364, Km 9,5
78900-000 Porto Velho, RO
Brasil
Tel./Fax 55 69 217-8593 
E-mail mario at unir.br



From ligges at statistik.uni-dortmund.de  Sat Sep 20 17:53:48 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 20 Sep 2003 17:53:48 +0200
Subject: [R] conditional function definition?
References: <XFMail.030920150759.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <3F6C780C.C6AD1ADB@statistik.uni-dortmund.de>

"(Ted Harding)" wrote:
> 
> Hi Folks,
> 
> What is the best way to avoid a function being read in
> anew (and masking an exiting function) when a definition
> of it has already been established in R?
> 
> Reason: Fernando Tusell and I are working up Schafer's 'CAT'
> for R (basically done now, just needs some cosmetic tidying up).
> 
> This uses a function 'slice.index', present in S but not in
> the versions of R we were working with at the time. So we put
> in a definition (copied from R-help ... ).
> 
> However, it seems that slice.index is now in "base" in latest
> versions of R. So it would seem a bit silly to read it in anew.
> Nevertheless, probably we should keep it in for the sake of people
> still using older versions of R who would not have it.
> 
> So what's the best method to do
> 
> if( some test for function slice.index absent ) {
>   slice.index<-function(....){....}
> }
> 
> ??
> 
> Thanks,
> Ted.
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 167 1972
> Date: 20-Sep-03                                       Time: 15:07:59
> ------------------------------ XFMail ------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


Beside the other answers (mentioning exists()), I'd like to point out
that R has Namespace support these days.
It would not help for users of outdated versions of R, though.

Uwe Ligges



From ligges at statistik.uni-dortmund.de  Sat Sep 20 18:12:51 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 20 Sep 2003 18:12:51 +0200
Subject: [R] permutations function
References: <BAY7-F1083GOe6hLT2R00008c46@hotmail.com>
Message-ID: <3F6C7C83.C046375A@statistik.uni-dortmund.de>



lamack lamack wrote:
> 
> Dear all
> 
> If I consider
> 
> d<- c(1,2,3,4)
> N<- 4
> n<- 2
> out1<- matrix(0,N^n,n)
> z<-1
> 
> for(i in 1:N)
> {
> for(j in 1:N)
> {
>    out1[z,1] = d[i]
>    out1[z,2] = d[j]
>    z<- z+1
> }
> }
> 
> library(gregmisc)
> out2<- permutations(N,n,d,T,T)
> 
> I have that out1==out2. Ok
> 
> Now, if I consider
> 
> d<- c(1,2,3,4)
> N<- 4
> n<- 3
> out1<- matrix(0,N^n,n)
> z<-1
> 
> for(i in 1:N)
> {
> for(j in 1:N)
> {
>   for(k in 1:N)
>   {
>     out1[z,1] = d[i]
>     out1[z,2] = d[j]
>     out1[z,3] = d[k]
>    z<- z+1
>   }
> }
> }
> 
> out2<- permutations(N,n,d,T,T)
> 
> I have that out1 is not equal out1.
> 
> My question is: Why out1 is not equal out2 ?


Because the "gregmisc" implementation of permutations() seems to be
buggy (CC'ing to Greg).

Uwe Ligges



> Best regards
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ligges at statistik.uni-dortmund.de  Sat Sep 20 18:18:37 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 20 Sep 2003 18:18:37 +0200
Subject: [R] persp graphs
References: <1064072483.3f6c7523a21d0@www.unir.br>
Message-ID: <3F6C7DDD.AB4617A6@statistik.uni-dortmund.de>



Mario Alberto Cozzuol wrote:
> 
> Hi,
> I am doing my way on R, with much experimenting. So, I am trying to plot a 3d
> graphic ussing "persp" and entering a data set (attached) of UTM coordinates
> as x,y and a pH values as z. However when I try an error message comes out
> telling that increasing x and y values are expected. Jus ordering the first
> vector does not help, and, of course, order the first two independently makes
> no sense since they are geographic coordinates. So, what I am doing wrong?
> Thank you all very much for the help,


So you are not going to plot a surface, but "just" a set of points? In
that case persp() is inadequate. For example you can use cloud() in
package lattice, scatterplot3d() in package "scatterplot3d", the
packages djmrgl and rgl, or xgobi or ggobi as external software.

Uwe Ligges


> Mario
> --
> Dr. Mario A. Cozzuol
> Laborat?rio de Biologia Evolutiva
> Universidade Federal de Rond?nia
> BR 364, Km 9,5
> 78900-000 Porto Velho, RO
> Brasil
> Tel./Fax 55 69 217-8593
> E-mail mario at unir.br
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From tlumley at u.washington.edu  Sat Sep 20 18:19:52 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sat, 20 Sep 2003 09:19:52 -0700 (PDT)
Subject: [R] using aggregate with survey-design and survey functions
In-Reply-To: <6c.31b80388.2c9d0d81@aol.com>
References: <6c.31b80388.2c9d0d81@aol.com>
Message-ID: <Pine.A41.4.58.0309200906490.146902@homer10.u.washington.edu>

On Fri, 19 Sep 2003 TyagiAnupam at aol.com wrote:

> Hi R users,
>
> I am trying to use the aggregate function with a survey design object and
> survey functions, but get the following error. I think I am incorrectly using the
> syntax somehow, and it may not be possible to access variables directly by
> name in a survey-design object. Am I right? How do I fix this problem? I have
> used aggregate with "mean" and "weighted.mean", and that works fine. I am trying
> to find out where the difference is. What would be an efficient alternative
> to aggregate for a large dataset?
>
> > s <- aggregate(income,list(age,sex),function(x) (svymean(~x,design=d.na)))
> Error in aggregate(income, list(age, sex), function(x) (svymean(~x,  :
>     Object "income" not found

This isn't going to work.

svymean needs the survey metadata to get the right mean, and aggregate
doesn't give it enough information.  aggregate would need a separate
method for svydesign objects.


	-thomas



From tlumley at u.washington.edu  Sat Sep 20 18:23:58 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sat, 20 Sep 2003 09:23:58 -0700 (PDT)
Subject: [R] Logit and Probit for Panel data
In-Reply-To: <5.1.0.14.2.20030920094433.01ff2768@127.0.0.1>
References: <1B466FAB.7E330AF0.006F5466@aol.com>
	<1B466FAB.7E330AF0.006F5466@aol.com>
	<5.1.0.14.2.20030920094433.01ff2768@127.0.0.1>
Message-ID: <Pine.A41.4.58.0309200921210.146902@homer10.u.washington.edu>

On Sat, 20 Sep 2003, John Fox wrote:

> Dear Sundar and Christoph,
>
> The glmmPQL function in the MASS package will fit generalised linear mixed
> models (appropriate, e.g., for longitudinal data), as will the GLMM
> function in the lme4 package. I believe that there are some other
> facilities for doing so as well, but they don't come to mind.
>

You can also fit marginal logit and probit models to panel data with the
gee or geepack packages.

One of Jim Lindsey's packages will fit (at least) a random intercept
model.

	-thomas



From edd at debian.org  Sat Sep 20 18:39:07 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 20 Sep 2003 11:39:07 -0500
Subject: For all par(xpd) settings,
	plot is clipped (Was: [R] Place a graphic into an R-plot)
In-Reply-To: <Pine.LNX.4.44.0309181519300.18503-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0309181519300.18503-100000@reclus.nhh.no>
Message-ID: <20030920163907.GA464@sonny.eddelbuettel.com>


Using Roger's rather useful addlogo() function (still included below), I am
unable to plot a pixmap anywhere but in the core plot region. 

In other words, when using the following code, and placing one coordinate
inside and one coordinate outside the plot region,

> library(pixmap)
> logo<-read.pnm(system.file("pictures/logo.ppm", package="pixmap"))
> source("/tmp/addlogo.R")
> par(xpd=NA); plot(1:10); addlogo(x=c(2,4),y=c(9,11), pixmap=logo)
> par(xpd=FALSE); plot(1:10); addlogo(x=c(2,4),y=c(9,11), pixmap=logo)
> par(xpd=TRUE); plot(1:10); addlogo(x=c(2,4),y=c(9,11), pixmap=logo)

all attempts result in a partial clipped pixmap (given the 1:10,1:10 plot
region). Setting xpd inside addlogo()'s plot() made no difference. This was
using this morning's alpha release of 1.8.0, and on Linux -- but it behaved
the same on win2k with an older version of R.

Am I misunderstanding something (which is most likely, given the still
mysterious ways of ?par), or is this a bug in pixmap's plot method?

Thanks, Dirk


On Thu, Sep 18, 2003 at 03:24:32PM +0200, Roger Bivand wrote:
> Gordon:
> 
> This is a copy of an off-list reply from May 2003, which may give some 
> assistance - not quite the same, because here the image was inserted into 
> an existing plot. It is based on using the pixmap package to import a 
> ppm or pnm file, then rescaling to fit the designated space.
> 
> Roger Bivand
> 
> ---------- Forwarded message ----------
> Date: Mon, 26 May 2003 11:26:21 +0200 (CEST)
> From: Roger Bivand <Roger.Bivand at nhh.no>
> To: meinhardploner at gmx.net
> Cc: 
> Subject: Re: [R] overlapping a plot with an external image
> 
> > On Wednesday, May 21, 2003, at 04:38  PM, Prof Brian Ripley wrote:
> 
> >> On Wed, 21 May 2003, Meinhard Ploner wrote:
> >
> >>> It's possible to overlap an external image (jpg or pdf)
> >>> with a plot generated with R?
> >>
> >>> Specifying the image as the background
> >>> of the plot might not be possible...
> >
> >> Although this has been discussed, R graphics devices cannot as yet plot
> >> bitmap images.  So all one can do is to plot a set of rectangles: for
> >> that the pixmap package might be helpful.
> >
> >> Although we might add the ability to plot a bitmap image, note that it
> >> is not straightforward, as R screen graphics devices can be dynamically
> >> resized.  What should be done with a plotted image then?  Interpolate
> >> on the fly?
> 
> > The plotted image should be a logo of the project / department and I
> > like to add it on every plot  - for esthetical and descriptive reasons 
> 
> Here is a very rough addlogo() using pixmap:
> 
> "addlogo" <- function(x, y, pixmap) {
>     if (is.list(x)) {
>         y <- x$y
>         x <- x$x
>     }
>     else if (missing(y)) 
>         stop("missing y")
>     if (!is.numeric(x) || !is.numeric(y)) 
>         stop("non-numeric coordinates")
>     if ((nx <- length(x)) <= 1 || nx != length(y) || nx > 2) 
>         stop("invalid coordinate lengths")
>     pixmap at bbox[1] <- x[1]
>     pixmap at bbox[2] <- y[1]
>     pixmap at bbox[3] <- x[2]
>     pixmap at bbox[4] <- y[2]
>     pixmap at cellres[1] <- (pixmap at bbox[3] - pixmap at bbox[1]) / pixmap at size[2]
>     pixmap at cellres[2] <- (pixmap at bbox[4] - pixmap at bbox[2]) / pixmap at size[1]
>     plot(pixmap, add=TRUE)
>     invisible(pixmap)
> }
> 
> which will work with locator() too. To maintain aspect, it shouldn't alter 
> the relative cell resolutions, and should just use the new x or y, bur 
> this is the general case. The handling of the location of the logo is 
> copied & pasted from legend().
> 
> Roger
> 
> -- 
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
> e-mail: Roger.Bivand at nhh.no
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From maechler at stat.math.ethz.ch  Sat Sep 20 18:45:57 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 20 Sep 2003 18:45:57 +0200
Subject: [R] Locate first index
In-Reply-To: <Pine.SOL.3.96.1030920104638.26890A-100000@virgo.cus.cam.ac.uk>
References: <16236.3214.495033.795640@gargle.gargle.HOWL>
	<Pine.SOL.3.96.1030920104638.26890A-100000@virgo.cus.cam.ac.uk>
Message-ID: <16236.33861.445667.695291@gargle.gargle.HOWL>

>>>>> "Damon" == Damon Wischik <djw1005 at cam.ac.uk>
>>>>>     on Sat, 20 Sep 2003 10:58:02 +0100 (BST) writes:

    MM> Since I'm sure that I have seen the not-so-good
    MM> min(which(a == x)) or which(a == x)[1] several times
    MM> before, I've added a note about this (in the SEE ALSO
    MM> section) of help(which) --- still in the optimistic
    MM> assumption that people read help pages... ;-)

    Damon> I had noticed the remark on the help page, 

eehm, hardly possible, since I've only added it today to the
development sources...

You seem to be talking about something else, but related..

    Damon> but it had never occurred to me to apply it to
    Damon> boolean vectors. It says "for the index of the
    Damon> minimum or maximum", so I think it is to be used for
    Damon> numeric vectors, without it occurring to me that
    Damon> booleans can be typecast into numerics. (I can never
    Damon> remember which way round the typecasting goes, so I
    Damon> always use explicit constructions like "ifelse(x,1,0)").

    Damon> I have generally avoided which.min, because it looks
    Damon> (to me) as if it is finding the location of the
    Damon> minima of a numerical vector.
Yes, almost: It gives the location (index) of the  (first)
minimum of a numerical vector -- where the "(first)" part is
only needed in case of multiple minima.

    Damon> This is on the grounds that "which" returns a vector
    Damon> of locations, so I expect "which.min" to do the same,
    Damon> i.e. to behave like which(x==min(x)). I know (from
    Damon> reading the help pages) that this is not what it does.
but almost, since it *does* give which(x==min(x))[1]
and this is often what is wanted {in the cases where you are
sure that there's only one minimum, or in those where you only
need the location of one of the minima anyways}.

    Damon> However, I don't like putting "which.min" into
    Damon> my code for this purpose, because it makes it harder
    Damon> for me to read.

Are you confusing  which.min() and "min.which" (which does not exist)?
The non existing "min.which" is really the subject here, and
it's the one where  match(a,x) can be used instead of
min(which(a == x)).

which.min(x) on the other hand is something very different (as
you indicate too), and really *is* the same (but more
efficiently) as  which(min(x) == x)[1], i.e. in the case of a unique
minimum, it is the same as which(min(x) == x)

    Damon> If, on the other hand, there was a command "first" or
    Damon> maybe "first.which" which was aliased to which.min, I
    Damon> would happily write first.which(x==3)

as Doug Bates said, and we tried to emphasize, you should use
   match(3,x)
for the above.



From maechler at stat.math.ethz.ch  Sat Sep 20 18:54:26 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 20 Sep 2003 18:54:26 +0200
Subject: [R] conditional function definition?
In-Reply-To: <3F6C6E74.8080402@pdf.com>
References: <XFMail.030920150759.Ted.Harding@nessie.mcc.ac.uk>
	<3F6C6E74.8080402@pdf.com>
Message-ID: <16236.34370.171635.7784@gargle.gargle.HOWL>

>>>>> "Spencer" == Spencer Graves <spencer.graves at pdf.com>
>>>>>     on Sat, 20 Sep 2003 08:12:52 -0700 writes:

    Spencer> Have you considered:
    >> exists("slice.index")
    Spencer> [1] TRUE

    Spencer>        In other circumstances, I've tested various
    Spencer> components of "version".

I'd recommend the latter, since there could be "slice.index"
lying around somewhere else.

I have the following in the cluster package's  R/zzz.R  file:
--------------------------------------------------------------------------------
    ## for R versions < 1.7:
    if(paste(R.version$major, R.version$minor, sep=".") < 1.7) {

	force <- function(x) x

	## for R versions < 1.6:
	if(paste(R.version$major, R.version$minor, sep=".") < 1.6) {
	    stop <- function (..., call. = TRUE)
		.Internal(stop(if (nargs() > 0) paste(..., sep = "")))

	    ## for R versions < 1.5
	    if(paste(R.version$major, R.version$minor, sep=".") < 1.5)
		## cheap substitute, used in silhouette.default()
		colSums <- function(x) apply(x, 2, sum)

    ### NOTE: From cluster 1.7.0, we require at least R 1.4

	}# versions < 1.6

    }# versions < 1.7
--------------------------------------------------------------------------------

    Spencer> hope this helps.  spencer graves

    Spencer> (Ted Harding) wrote:

    >> Hi Folks,
    >> 
    >> What is the best way to avoid a function being read in
    >> anew (and masking an exiting function) when a definition
    >> of it has already been established in R?
    >> 
    >> Reason: Fernando Tusell and I are working up Schafer's
    >> 'CAT' for R (basically done now, just needs some cosmetic
    >> tidying up).
    >> 
    >> This uses a function 'slice.index', present in S but not
    >> in the versions of R we were working with at the time. So
    >> we put in a definition (copied from R-help ... ).
    >> 
    >> However, it seems that slice.index is now in "base" in
    >> latest versions of R. So it would seem a bit silly to
    >> read it in anew.  Nevertheless, probably we should keep
    >> it in for the sake of people still using older versions
    >> of R who would not have it.
    >> 
    >> So what's the best method to do
    >> 
    >> if( some test for function slice.index absent ) {
    >> slice.index<-function(....){....}  }
    >> 
    >> ??
    >> 
    >> Thanks, Ted.
    >> 
    >> 
    >> --------------------------------------------------------------------
    >> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
    >> Fax-to-email: +44 (0)870 167 1972 Date: 20-Sep-03 Time:
    >> 15:07:59 ------------------------------ XFMail
    >> ------------------------------
    >> 
    >> ______________________________________________
    >> R-help at stat.math.ethz.ch mailing list
    >> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
    >> 
    >> 

    Spencer> ______________________________________________
    Spencer> R-help at stat.math.ethz.ch mailing list
    Spencer> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Roger.Bivand at nhh.no  Sat Sep 20 19:30:07 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 20 Sep 2003 19:30:07 +0200 (CEST)
Subject: For all par(xpd) settings, plot is clipped (Was: [R] Place a
	graphic into an R-plot)
In-Reply-To: <20030920163907.GA464@sonny.eddelbuettel.com>
Message-ID: <Pine.LNX.4.44.0309201926340.2754-100000@reclus.nhh.no>

On Sat, 20 Sep 2003, Dirk Eddelbuettel wrote:

> 
> Using Roger's rather useful addlogo() function (still included below), I am
> unable to plot a pixmap anywhere but in the core plot region. 
> 
> In other words, when using the following code, and placing one coordinate
> inside and one coordinate outside the plot region,
> 
> > library(pixmap)
> > logo<-read.pnm(system.file("pictures/logo.ppm", package="pixmap"))
> > source("/tmp/addlogo.R")
> > par(xpd=NA); plot(1:10); addlogo(x=c(2,4),y=c(9,11), pixmap=logo)
> > par(xpd=FALSE); plot(1:10); addlogo(x=c(2,4),y=c(9,11), pixmap=logo)
> > par(xpd=TRUE); plot(1:10); addlogo(x=c(2,4),y=c(9,11), pixmap=logo)
> 
> all attempts result in a partial clipped pixmap (given the 1:10,1:10 plot
> region). Setting xpd inside addlogo()'s plot() made no difference. This was
> using this morning's alpha release of 1.8.0, and on Linux -- but it behaved
> the same on win2k with an older version of R.
> 
> Am I misunderstanding something (which is most likely, given the still
> mysterious ways of ?par), or is this a bug in pixmap's plot method?

No, it seems to be a design choice in do_image() in plot3d.c, near line 
1924:

    /* override par("xpd") and force clipping to plot region */

which is a fine example of well commented code!

Roger

> 
> Thanks, Dirk
> 
> 
> On Thu, Sep 18, 2003 at 03:24:32PM +0200, Roger Bivand wrote:
> > Gordon:
> > 
> > This is a copy of an off-list reply from May 2003, which may give some 
> > assistance - not quite the same, because here the image was inserted into 
> > an existing plot. It is based on using the pixmap package to import a 
> > ppm or pnm file, then rescaling to fit the designated space.
> > 
> > Roger Bivand
> > 
> > ---------- Forwarded message ----------
> > Date: Mon, 26 May 2003 11:26:21 +0200 (CEST)
> > From: Roger Bivand <Roger.Bivand at nhh.no>
> > To: meinhardploner at gmx.net
> > Cc: 
> > Subject: Re: [R] overlapping a plot with an external image
> > 
> > > On Wednesday, May 21, 2003, at 04:38  PM, Prof Brian Ripley wrote:
> > 
> > >> On Wed, 21 May 2003, Meinhard Ploner wrote:
> > >
> > >>> It's possible to overlap an external image (jpg or pdf)
> > >>> with a plot generated with R?
> > >>
> > >>> Specifying the image as the background
> > >>> of the plot might not be possible...
> > >
> > >> Although this has been discussed, R graphics devices cannot as yet plot
> > >> bitmap images.  So all one can do is to plot a set of rectangles: for
> > >> that the pixmap package might be helpful.
> > >
> > >> Although we might add the ability to plot a bitmap image, note that it
> > >> is not straightforward, as R screen graphics devices can be dynamically
> > >> resized.  What should be done with a plotted image then?  Interpolate
> > >> on the fly?
> > 
> > > The plotted image should be a logo of the project / department and I
> > > like to add it on every plot  - for esthetical and descriptive reasons 
> > 
> > Here is a very rough addlogo() using pixmap:
> > 
> > "addlogo" <- function(x, y, pixmap) {
> >     if (is.list(x)) {
> >         y <- x$y
> >         x <- x$x
> >     }
> >     else if (missing(y)) 
> >         stop("missing y")
> >     if (!is.numeric(x) || !is.numeric(y)) 
> >         stop("non-numeric coordinates")
> >     if ((nx <- length(x)) <= 1 || nx != length(y) || nx > 2) 
> >         stop("invalid coordinate lengths")
> >     pixmap at bbox[1] <- x[1]
> >     pixmap at bbox[2] <- y[1]
> >     pixmap at bbox[3] <- x[2]
> >     pixmap at bbox[4] <- y[2]
> >     pixmap at cellres[1] <- (pixmap at bbox[3] - pixmap at bbox[1]) / pixmap at size[2]
> >     pixmap at cellres[2] <- (pixmap at bbox[4] - pixmap at bbox[2]) / pixmap at size[1]
> >     plot(pixmap, add=TRUE)
> >     invisible(pixmap)
> > }
> > 
> > which will work with locator() too. To maintain aspect, it shouldn't alter 
> > the relative cell resolutions, and should just use the new x or y, bur 
> > this is the general case. The handling of the location of the logo is 
> > copied & pasted from legend().
> > 
> > Roger
> > 
> > -- 
> > Roger Bivand
> > Economic Geography Section, Department of Economics, Norwegian School of
> > Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
> > Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
> > e-mail: Roger.Bivand at nhh.no
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > 
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From TyagiAnupam at aol.com  Sat Sep 20 19:56:35 2003
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Sat, 20 Sep 2003 13:56:35 EDT
Subject: [R] using aggregate with survey-design and survey functions
Message-ID: <191.1f4b6d83.2c9deed3@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030920/5e4defb3/attachment.pl

From spencer.graves at pdf.com  Sat Sep 20 21:30:25 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 20 Sep 2003 12:30:25 -0700
Subject: [R] persp graphs
In-Reply-To: <3F6C7DDD.AB4617A6@statistik.uni-dortmund.de>
References: <1064072483.3f6c7523a21d0@www.unir.br>
	<3F6C7DDD.AB4617A6@statistik.uni-dortmund.de>
Message-ID: <3F6CAAD1.1060906@pdf.com>

It depends on what he wants:  For certain circumstances, persp on the 
output of interp or loess is appropriate (Venables and Ripley 2002, 
Modern Applied Statistics with S, 4th ed., p. 76). 

hope this helps.  spencer graves
Uwe Ligges wrote:

>Mario Alberto Cozzuol wrote:
>  
>
>>Hi,
>>I am doing my way on R, with much experimenting. So, I am trying to plot a 3d
>>graphic ussing "persp" and entering a data set (attached) of UTM coordinates
>>as x,y and a pH values as z. However when I try an error message comes out
>>telling that increasing x and y values are expected. Jus ordering the first
>>vector does not help, and, of course, order the first two independently makes
>>no sense since they are geographic coordinates. So, what I am doing wrong?
>>Thank you all very much for the help,
>>    
>>
>
>
>So you are not going to plot a surface, but "just" a set of points? In
>that case persp() is inadequate. For example you can use cloud() in
>package lattice, scatterplot3d() in package "scatterplot3d", the
>packages djmrgl and rgl, or xgobi or ggobi as external software.
>
>Uwe Ligges
>
>
>  
>
>>Mario
>>--
>>Dr. Mario A. Cozzuol
>>Laborat?rio de Biologia Evolutiva
>>Universidade Federal de Rond?nia
>>BR 364, Km 9,5
>>78900-000 Porto Velho, RO
>>Brasil
>>Tel./Fax 55 69 217-8593
>>E-mail mario at unir.br
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>    
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From spencer.graves at pdf.com  Sat Sep 20 21:41:30 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 20 Sep 2003 12:41:30 -0700
Subject: [R] using aggregate with survey-design and survey functions
In-Reply-To: <191.1f4b6d83.2c9deed3@aol.com>
References: <191.1f4b6d83.2c9deed3@aol.com>
Message-ID: <3F6CAD6A.5070803@pdf.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030920/83a0e26e/attachment.pl

From gxx4 at cwru.edu  Sat Sep 20 22:09:38 2003
From: gxx4 at cwru.edu (gxx4@cwru.edu)
Date: Sat, 20 Sep 2003 16:09:38 -0400
Subject: [R] Errors in making a DLL file
Message-ID: <14760a147c4c.147c4c14760a@cwru.edu>

Hi, all:
 
I want to call a c program in the windows version R, so I installed ActivePerl and
MinGw, wrote the code below in command prompt:

Rcmd SHLIB filename.c

and I got the error message as follows:

Error: c:/R/rw1071/src/gnuwin32/MakeDLL 16: common syntax error.
.....
There are errors on line 16 18 20 22 25 28 43 44 45 47 49 50 51 52 53 79 80 81 83. 

Has any one met the same problem before? Do I need other tools installed?

Best Wishes,
Guan Xing
9/20/03



From mario at unir.br  Sun Sep 21 00:46:58 2003
From: mario at unir.br (Mario Alberto Cozzuol)
Date: Sat, 20 Sep 2003 18:46:58 -0400
Subject: [R] persp graphs
In-Reply-To: <3F6C7DDD.AB4617A6@statistik.uni-dortmund.de>
References: <1064072483.3f6c7523a21d0@www.unir.br>
	<3F6C7DDD.AB4617A6@statistik.uni-dortmund.de>
Message-ID: <200309201846.59000.mario@unir.br>

On Saturday 20 September 2003 12:18, Uwe Ligges wrote:
> So you are not going to plot a surface, but "just" a set of points? In
> that case persp() is inadequate. For example you can use cloud() in
> package lattice, scatterplot3d() in package "scatterplot3d", the
> packages djmrgl and rgl, or xgobi or ggobi as external software.

Actually I want to plot a surface, a geographic surface just like the volcano 
in the example, this is because does not make sense to order x and y. In my 
case the z values are the pH value for the soil at each poit.
I am missing something?

Thanks,

Mario

-- 
Dr. Mario A. Cozzuol
Laborat?rio de Biologia Evolutiva
Universidade Federal de Rond?nia
BR 364, Km 9,5
78900-000 Porto Velho, RO
Brasil
Tel./Fax 55 69 217-8593 
E-mail mario at unir.br



From djw1005 at cam.ac.uk  Sun Sep 21 01:52:16 2003
From: djw1005 at cam.ac.uk (Damon Wischik)
Date: Sun, 21 Sep 2003 00:52:16 +0100 (BST)
Subject: [R] Locate first index
In-Reply-To: <16236.33861.445667.695291@gargle.gargle.HOWL>
Message-ID: <Pine.SOL.3.96.1030921004025.1608B-100000@libra.cus.cam.ac.uk>


>> I had noticed the remark on the help page, 
> 
> eehm, hardly possible, since I've only added it today to the
> development sources...
> You seem to be talking about something else, but related..

Indeed, I've been confusing myself thoroughly. I thought you were
referring to the remark that is there at the moment in R 1.7.0. And I
was confusing which.min and which.max too -- I was thinking of something
like
  x <- c(3,4,1,1,2,8,5)
  which.max(x>2.5)
which returns the first index where the condition is true. (This is a bad,
though: it returns 1 when the condition is never true.)

> Are you confusing  which.min() and "min.which" (which does not exist)?
> The non existing "min.which" is really the subject here, and
> it's the one where  match(a,x) can be used instead of
> min(which(a == x)).

Yes, I was confusing them -- via which.max. Sorry for confusing the issue!

Damon.



From ligges at statistik.uni-dortmund.de  Sun Sep 21 11:13:33 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 21 Sep 2003 11:13:33 +0200
Subject: [R] persp graphs
References: <1064072483.3f6c7523a21d0@www.unir.br>
	<3F6C7DDD.AB4617A6@statistik.uni-dortmund.de>
	<200309201846.59000.mario@unir.br>
Message-ID: <3F6D6BBD.9AECD400@statistik.uni-dortmund.de>



Mario Alberto Cozzuol wrote:
> 
> On Saturday 20 September 2003 12:18, Uwe Ligges wrote:
> > So you are not going to plot a surface, but "just" a set of points? In
> > that case persp() is inadequate. For example you can use cloud() in
> > package lattice, scatterplot3d() in package "scatterplot3d", the
> > packages djmrgl and rgl, or xgobi or ggobi as external software.
> 
> Actually I want to plot a surface, a geographic surface just like the volcano
> in the example, this is because does not make sense to order x and y. In my
> case the z values are the pH value for the soil at each poit.
> I am missing something?

My guess was wrong. But your question can be easily be answered by
reading ?persp:

"x, y: locations of grid lines at which the values in `z' are measured."

So you need a vector x of length n, a vector y of length m and a matrix
z of dimension n x m.
You do NOT need a value of x and y for each point, but only for each
grid line. There is not difficulty to order them, when you already got a
matrix for z.

Uwe


> Thanks,
> 
> Mario
> 
> --
> Dr. Mario A. Cozzuol
> Laborat?rio de Biologia Evolutiva
> Universidade Federal de Rond?nia
> BR 364, Km 9,5
> 78900-000 Porto Velho, RO
> Brasil
> Tel./Fax 55 69 217-8593
> E-mail mario at unir.br
>



From ligges at statistik.uni-dortmund.de  Sun Sep 21 11:30:17 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 21 Sep 2003 11:30:17 +0200
Subject: [R] Errors in making a DLL file
References: <14760a147c4c.147c4c14760a@cwru.edu>
Message-ID: <3F6D6FA9.840AA755@statistik.uni-dortmund.de>



gxx4 at cwru.edu wrote:
> 
> Hi, all:
> 
> I want to call a c program in the windows version R, so I installed ActivePerl and
> MinGw, wrote the code below in command prompt:
> 
> Rcmd SHLIB filename.c
> 
> and I got the error message as follows:
> 
> Error: c:/R/rw1071/src/gnuwin32/MakeDLL 16: common syntax error.
> .....
> There are errors on line 16 18 20 22 25 28 43 44 45 47 49 50 51 52 53 79 80 81 83.
> 
> Has any one met the same problem before? Do I need other tools installed?
> 
> Best Wishes,
> Guan Xing
> 9/20/03
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

I've never seen this error, but for sure you haven't followed the
instructions in c:/R/rw1071/src/gnuwin32/readme.packages and the
"Writing R Extensions" manual closely enough (Are all the paths set? Do
you have the tool collection provided on Brians Ripley's page?).

Uwe Ligges



From monica.palaseanu-lovejoy at stud.man.ac.uk  Sun Sep 21 14:57:56 2003
From: monica.palaseanu-lovejoy at stud.man.ac.uk (Monica Palaseanu-Lovejoy)
Date: Sun, 21 Sep 2003 13:57:56 +0100
Subject: [R] aov and data behind plots
In-Reply-To: <200309061003.h86A1116008282@stat.math.ethz.ch>
Message-ID: <E1A13mz-000CR1-6O@probity.mcc.ac.uk>

Hi y'all,

First of all many thanks to Christian, Petr and Spencer for their 
replies. Your answers helped me to learn few more triks since then 
;-)

Now i have a question relating "aov". When i use aov i end up with 
4 plots. How do i "see" the data behind those plots? I know about 
summary - but this gives me only some statistical info. Also, if i 
want to identify which of my set of values gives a certain segment 
of the plot - how do i identify these values? 

Thanks a lot,

Monica


Monica Palaseanu-Lovejoy
University of Manchester
School of Geography
Mansfield Cooper Building 
Oxford Road, Manchester
M13 9PL, UK. 
email: monica.palaseanu-lovejoy at stud.man.ac.uk



From monica.palaseanu-lovejoy at stud.man.ac.uk  Sun Sep 21 15:05:28 2003
From: monica.palaseanu-lovejoy at stud.man.ac.uk (Monica Palaseanu-Lovejoy)
Date: Sun, 21 Sep 2003 14:05:28 +0100
Subject: [R] Z aware interpolation
In-Reply-To: <200309181008.h8IA2QA3018972@stat.math.ethz.ch>
Message-ID: <E1A13uG-000Cbi-6k@probity.mcc.ac.uk>

Hello again,

There is any package which does Z aware (real 3D) interpolations? 
It can be any method (IDW, kriging or spline) but it should take into 
consideration not only x and y coordinates for interpolation, but 
also z coordinate. I looked into different packages but it seems i 
didn't find the right one.

The ultimate goal is to import the output into a GIS (Geographical 
Information System) for further analysis.

Alternatively, maybe you know a source for codes for normal IDW 
(Inverse Distance Weight) interpolation (i mean the one which 
takes into consideration only x and y coordinates) so i can try to 
modify it to take into consideration z values as well. I am not sure 
it will work, or i can do it - but it worth a try - of course if this is not 
already done. 

Thanks,

Monica


Monica Palaseanu-Lovejoy
University of Manchester
School of Geography
Mansfield Cooper Building 
Oxford Road, Manchester
M13 9PL, UK. 
email: monica.palaseanu-lovejoy at stud.man.ac.uk



From Roger.Bivand at nhh.no  Sun Sep 21 15:50:49 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 21 Sep 2003 15:50:49 +0200 (CEST)
Subject: [R] Z aware interpolation
In-Reply-To: <E1A13uG-000Cbi-6k@probity.mcc.ac.uk>
Message-ID: <Pine.LNX.4.44.0309211545001.12846-100000@reclus.nhh.no>

On Sun, 21 Sep 2003, Monica Palaseanu-Lovejoy wrote:

> Hello again,
> 
> There is any package which does Z aware (real 3D) interpolations? 
> It can be any method (IDW, kriging or spline) but it should take into 
> consideration not only x and y coordinates for interpolation, but 
> also z coordinate. I looked into different packages but it seems i 
> didn't find the right one.

Assuming that you have points with x and y coordinates, and a z attribute 
that you want to interpolate to a grid, then the akima package provides 
spline interpolation as interp(). See Chapter 15 in Venables and Ripley 
(2002) Modern Applied Statistics with S for more ideas.

> 
> The ultimate goal is to import the output into a GIS (Geographical 
> Information System) for further analysis.
> 
> Alternatively, maybe you know a source for codes for normal IDW 
> (Inverse Distance Weight) interpolation (i mean the one which 
> takes into consideration only x and y coordinates) so i can try to 
> modify it to take into consideration z values as well. I am not sure 
> it will work, or i can do it - but it worth a try - of course if this is not 
> already done. 
> 
> Thanks,
> 
> Monica
> 
> 
> Monica Palaseanu-Lovejoy
> University of Manchester
> School of Geography
> Mansfield Cooper Building 
> Oxford Road, Manchester
> M13 9PL, UK. 
> email: monica.palaseanu-lovejoy at stud.man.ac.uk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From enzmann at kfn.uni-hannover.de  Sun Sep 21 16:29:53 2003
From: enzmann at kfn.uni-hannover.de (Dirk Enzmann)
Date: Sun, 21 Sep 2003 16:29:53 +0200
Subject: [R] Zero inflated count models
Message-ID: <3F6DB5E1.5080301@kfn.uni-hannover.de>

Can someone show me how to specify zero inflated poisson and zero 
inflated negative poisson models in R? I would like to replicate the 
example given in Long (1997: Regression Models for Categorical and 
Limited Dependent Variables) in Chapter 8.5 (pp. 242-247).

TIA
Dirk

*************************************************
Dr. Dirk Enzmann
Criminological Research Institute of Lower Saxony
Luetzerodestr. 9
D-30161 Hannover
Germany

phone: +49-511-348.36.32
fax:   +49-511-348.36.10
email: ENZMANN at KFN.uni-hannover.de

http://www.kfn.de



From enzmann at kfn.uni-hannover.de  Sun Sep 21 16:39:09 2003
From: enzmann at kfn.uni-hannover.de (Dirk Enzmann)
Date: Sun, 21 Sep 2003 16:39:09 +0200
Subject: [R] Zero inflated count models (2)
Message-ID: <3F6DB80D.3080302@kfn.uni-hannover.de>

In my previous mail, meant to say "negative binomial regression" (not 
"negative poisson), of course.

Dirk

*************************************************
Dr. Dirk Enzmann
Criminological Research Institute of Lower Saxony
Luetzerodestr. 9
D-30161 Hannover
Germany

phone: +49-511-348.36.32
fax:   +49-511-348.36.10
email: ENZMANN at KFN.uni-hannover.de

http://www.kfn.de



From gramarga at carpa.ciagri.usp.br  Sun Sep 21 16:53:24 2003
From: gramarga at carpa.ciagri.usp.br (Gabriel Rodrigues Alves Margarido)
Date: Sun, 21 Sep 2003 11:53:24 -0300
Subject: [R] 3 basic questions
Message-ID: <200309211441.h8LEfQ9e026767@stat.math.ethz.ch>

I have 3 basic questions (sorry, but R is a bit new to me)

First)

The following code will work on C, but something happens with R:

> x<-c(0,1,1,0,0,1,0,0,1)
> dim(x)<-c(3,3)
> types<-numeric(3)
> for (i in 1:3) {
+ j<-1
+ while (x[i,j]!=1) j<-j+1
+ if (j==4) types[i]<-0
+ else types[i]<-1
+ }
Error: subscript out of bounds

Any ideas about what is wrong?

Second)

I have a data file like this:
*data1 HHHHHHHHAAAAAABBBBBB...
*data2 HHHHHHHAAAAAABBBBBBB...
When I use read.table, all the characters are read as one variable.
How can I put each of them into a different column? Besides, I want to
discard the labels *data1 and *data2.

Third)

If the same file is like this:
*data1 HHHHHHHHAAAA
       AABBBBB...
*data2 HHHHHHHAAAAA
       ABBBBBB...
Can I read it like the one on question 2 (each data represented by a
line)?

Thank you in advance

Gabriel Margarido



From ggrothendieck at volcanomail.com  Sun Sep 21 17:25:32 2003
From: ggrothendieck at volcanomail.com (Gabor Grothendieck)
Date: Sun, 21 Sep 2003 08:25:32 -0700 (PDT)
Subject: [R] 3 basic questions
Message-ID: <20030921152532.630474072@sitemail.everyone.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030921/a78996a3/attachment.pl

From jasont at indigoindustrial.co.nz  Sun Sep 21 18:28:25 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Sun, 21 Sep 2003 16:28:25 -0000
Subject: [R] aov and data behind plots
In-Reply-To: <E1A13mz-000CR1-6O@probity.mcc.ac.uk>
References: <E1A13mz-000CR1-6O@probity.mcc.ac.uk>
Message-ID: <1064162242.11705.18.camel@kryten.akl.indigoindustrial.co.nz>

On Mon, 2003-09-22 at 00:57, Monica Palaseanu-Lovejoy wrote:

> Now i have a question relating "aov". When i use aov i end up with 
> 4 plots. How do i "see" the data behind those plots? I know about 
> summary - but this gives me only some statistical info. 

There's more than one (very different) answer to that question; it
depends what you mean by "the data behind those points".

The functions fitted(), resid(), cooks.distance(), and qqnorm() are all
handy functions, used by those plots.  coef() is also quite useful, as
is dummy.coef().

Failing that, have you tried str(your.aov.object)?  This gives a
detailed summary of each object element.  str(summary(your.aov.object))
might also be helpful.  Be careful about picking out object components
directly, however; if a nice, pre-packaged generic function exists to do
the job you want, it's much better to use that, rather than depend on
the internal object structure never changing.

> Also, if i 
> want to identify which of my set of values gives a certain segment 
> of the plot - how do i identify these values? 

See the help pages for locator() and identify().  The tricky bit for you
is making the four plots appear separately.  plot.lm() is the function
that makes those four plots; pick through it to find what you want.

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
+64-(0)21-343-545



From sundar.dorai-raj at pdf.com  Sun Sep 21 18:26:24 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Sun, 21 Sep 2003 11:26:24 -0500
Subject: [R] Zero inflated count models
In-Reply-To: <3F6DB5E1.5080301@kfn.uni-hannover.de>
References: <3F6DB5E1.5080301@kfn.uni-hannover.de>
Message-ID: <3F6DD130.2020907@pdf.com>


Dirk Enzmann wrote:

> Can someone show me how to specify zero inflated poisson and zero 
> inflated negative poisson models in R? I would like to replicate the 
> example given in Long (1997: Regression Models for Categorical and 
> Limited Dependent Variables) in Chapter 8.5 (pp. 242-247).
> 
> TIA
> Dirk
> 

Dirk,

I believe this can be done with Jim Lindsey's fmr function in the gnlm 
package. The help page has an example of both ZIP and ZINB model fits.

The gnlm package can be downloaded from

http://alpha.luc.ac.be/~jlindsey/rcode.html

-sundar



From monica.palaseanu-lovejoy at stud.man.ac.uk  Sun Sep 21 20:33:21 2003
From: monica.palaseanu-lovejoy at stud.man.ac.uk (Monica Palaseanu-Lovejoy)
Date: Sun, 21 Sep 2003 19:33:21 +0100
Subject: [R] Z aware interpolation - clarification
In-Reply-To: <Pine.LNX.4.44.0309211545001.12846-100000@reclus.nhh.no>
References: <E1A13uG-000Cbi-6k@probity.mcc.ac.uk>
Message-ID: <E1A191Y-000P54-Ga@probity.mcc.ac.uk>

Date sent:      	Sun, 21 Sep 2003 15:50:49 +0200 (CEST)
From:           	Roger Bivand <Roger.Bivand at nhh.no>
Send reply to:  	Roger.Bivand at nhh.no
To:             	Monica Palaseanu-Lovejoy <monica.palaseanu-lovejoy at stud.man.ac.uk>
Copies to:      	r-help at stat.math.ethz.ch
Subject:        	Re: [R] Z aware interpolation

Hi,

Well, i guess i was not very clear. My points have x, y, z 
coordinates, and PAH concentration values. I need to do my 
interpolation for PAH taking into consideration all my x, y, z 
coordinates. Otherwise my data seems not to behave - which could 
be normal since the data points are not in the same plan. Besides, 
if i project the points into a XY plan ... the distance between points 
will change, points quite far apart in an xyz coordinate system can 
be very close into a projected XY system. So i need to work with 
"real" distances taking into consideration z values as well. Maybe 
there is an other way to do it in which z can be translated as a kind 
of "weight" for distance .... if i work only in a XY system. I don't 
know yet .... so i hope somebody will give me a clue.

Thanks again,

Monica

On Sun, 21 Sep 2003, Monica Palaseanu-Lovejoy wrote:

> Hello again,
> 
> There is any package which does Z aware (real 3D) interpolations? 
> It can be any method (IDW, kriging or spline) but it should take into 
> consideration not only x and y coordinates for interpolation, but 
> also z coordinate. I looked into different packages but it seems i 
> didn't find the right one.

Assuming that you have points with x and y coordinates, and a z attribute 
that you want to interpolate to a grid, then the akima package provides 
spline interpolation as interp(). See Chapter 15 in Venables and Ripley 
(2002) Modern Applied Statistics with S for more ideas.

> 
> The ultimate goal is to import the output into a GIS (Geographical 
> Information System) for further analysis.
> 
> Alternatively, maybe you know a source for codes for normal IDW 
> (Inverse Distance Weight) interpolation (i mean the one which 
> takes into consideration only x and y coordinates) so i can try to 
> modify it to take into consideration z values as well. I am not sure 
> it will work, or i can do it - but it worth a try - of course if this is not 
> already done. 
> 
> Thanks,
> 
> Monica
> 
> 
> Monica Palaseanu-Lovejoy
> University of Manchester
> School of Geography
> Mansfield Cooper Building 
> Oxford Road, Manchester
> M13 9PL, UK. 
> email: monica.palaseanu-lovejoy at stud.man.ac.uk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no

Monica Palaseanu-Lovejoy
University of Manchester
School of Geography
Mansfield Cooper Building 
Oxford Road, Manchester
M13 9PL, UK. 
email: monica.palaseanu-lovejoy at stud.man.ac.uk



From tlumley at u.washington.edu  Sun Sep 21 22:39:03 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sun, 21 Sep 2003 13:39:03 -0700 (PDT)
Subject: [R] using aggregate with survey-design and survey functions
In-Reply-To: <191.1f4b6d83.2c9deed3@aol.com>
References: <191.1f4b6d83.2c9deed3@aol.com>
Message-ID: <Pine.A41.4.58.0309211338140.149456@homer07.u.washington.edu>

On Sat, 20 Sep 2003 TyagiAnupam at aol.com wrote:

> In a message dated 9/20/03 9:19:57 AM Pacific Daylight Time,
> tlumley at u.washington.edu writes:
>
> > svymean needs the survey metadata to get the right mean, and aggregate
> > doesn't give it enough information.  aggregate would need a separate
> > method for svydesign objects.
>
> Thanks for the info. I tried looking at source code of aggregate, but it only
> points to UseMethod("aggregate"). How can I find the source of this method?

methods("aggregate") will tell you where to look: aggregate.data.frame or
aggregate.default.


	-thomas



From rajiv.prasad at charter.net  Tue Sep 23 06:20:23 2003
From: rajiv.prasad at charter.net (Rajiv Prasad)
Date: Mon, 22 Sep 2003 21:20:23 -0700
Subject: [R] warning message from save.image()
Message-ID: <auto-000167631262@remt20.cluster1.charter.net>

Hi folks:

What does this warning message mean?

> save.image()
Warning messages:
1: namespaces may not be available when loading
2: names in persistent strings are currently ignored
> version
         _
platform alphapca56-unknown-linux-gnu
arch     alphapca56
os       linux-gnu
system   alphapca56, linux-gnu
status
major    1
minor    7.0
year     2003
month    04
day      16
language R

Thanks in advance.

Rajiv



From petr.pikal at precheza.cz  Mon Sep 22 08:39:02 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Mon, 22 Sep 2003 08:39:02 +0200
Subject: [R] persp graphs
In-Reply-To: <1064072483.3f6c7523a21d0@www.unir.br>
Message-ID: <3F6EB526.10824.25B61D@localhost>

Hallo

If you have data set not appropriate for persp plotting directly, 
maybe you can find some help in interp() function from akima 
package.

Cheers
Petr Pikal


On 20 Sep 2003 at 11:41, Mario Alberto Cozzuol wrote:

> Hi,
> I am doing my way on R, with much experimenting. So, I am trying to
> plot a 3d graphic ussing "persp" and entering a data set (attached) of
> UTM coordinates as x,y and a pH values as z. However when I try an
> error message comes out telling that increasing x and y values are
> expected. Jus ordering the first vector does not help, and, of course,
> order the first two independently makes no sense since they are
> geographic coordinates. So, what I am doing wrong? Thank you all very
> much for the help,
> 
> Mario
> -- 
> Dr. Mario A. Cozzuol
> Laborat?rio de Biologia Evolutiva
> Universidade Federal de Rond?nia
> BR 364, Km 9,5
> 78900-000 Porto Velho, RO
> Brasil
> Tel./Fax 55 69 217-8593 
> E-mail mario at unir.br
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

Petr Pikal
petr.pikal at precheza.cz



From e.pebesma at geog.uu.nl  Mon Sep 22 09:14:09 2003
From: e.pebesma at geog.uu.nl (Edzer J. Pebesma)
Date: Mon, 22 Sep 2003 09:14:09 +0200
Subject: [R] Z aware interpolation - clarification
Message-ID: <3F6EA141.4050600@geog.uu.nl>

Monica,

gstat has interpolation facilities for real 3D data: IDW, as
well as variogram modelling & kriging prediction and simulation.

Try:

library(gstat)
demo(gstat3D)

gstat exists as an R package, as well as a stand alone binary.
The package is at CRAN, the rest at www.gstat.org

best regards,
--
Edzer



From hwood at iprimus.com.au  Mon Sep 22 10:13:24 2003
From: hwood at iprimus.com.au (Hannah Wood)
Date: Mon, 22 Sep 2003 18:13:24 +1000
Subject: [R] Neural Network Question
Message-ID: <002f01c380e1$65761420$538886cb@hannah>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030922/e910fd27/attachment.pl

From jefferis at stanford.edu  Mon Sep 22 11:15:14 2003
From: jefferis at stanford.edu (Gregory Jefferis)
Date: Mon, 22 Sep 2003 02:15:14 -0700
Subject: [R] Data frame from list of lists
Message-ID: <BB940BB2.58DC%jefferis@stanford.edu>

This seems to be a simple problem, and I feel that there ought to be a
simple answer, but I can't seem to find it.

I have a function that returns a number of values as a heterogeneous list -
always the same length and same names(), but a number of different data
types, including character.  I want to apply it to many inputs, resulting in
a list of lists.

I would like to turn this list of lists into a single data frame in which
each row corresponds to one of the original sublists.

Here is a toy example:

myfunc=function(x) return(list(A=x,L=letters[x],T=Sys.time()))
ListOfLists=lapply(1:4,myfunc)
ListOfDataFrames=lapply(ListOfLists,as.data.frame)
df=do.call("rbind",ListOfDataFrames)

df

Which gives:

   A L                   T
1  1 a 2003-09-22 02:08:44
11 2 b 2003-09-22 02:08:44
12 3 c 2003-09-22 02:08:44
13 4 d 2003-09-22 02:08:44

Which is what I want (bar the rownames).  The problem is that this can be
very slow, particularly the last rbind step, when I have a large data set
(e.g. 5000 rows x20 cols).

I thought that one improvement might be to preassign the data frame since I
know how big it should be and then make assignments row by row.  But it
turns out that I can't then assign rows to the data frame one at a time - I
get errors because factor levels don't exist e.g.:

df[5:10,]=df[4,] 
for (i in 5:10){   
    df[i,]=as.data.frame(myfunc(i))
}

I presume that rbind.data.frame normally looks after adding extra levels to
factors as they appear in the new rows being appended to the data frame. If
anyone has a solution that is quick (and/or elegant), I would be extremely
grateful,

Greg Jefferis.

__________________________________________________________________________
Greg Jefferis,                          Lab Address: Liqun Luo, Herrin 144
Neurosciences PhD Programme &                e-mail: jefferis at stanford.edu
Dept Biological Sciences,                       Lab: (650) 725 5809
Gilbert Biology Building,                       Fax: (650) 723 0589
371 Serra Mall,
Stanford, CA 94305-5020.                       Home: (650) 326 9597



From r.basile at isae.it  Mon Sep 22 12:44:09 2003
From: r.basile at isae.it (Roberto Basile)
Date: Mon, 22 Sep 2003 12:44:09 +0200
Subject: [R] (no subject)
Message-ID: <000e01c380f6$74422d30$0d64a8c0@isae.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030922/aca690dc/attachment.pl

From bmjesus at fc.ul.pt  Mon Sep 22 13:36:09 2003
From: bmjesus at fc.ul.pt (Bruno Jesus)
Date: Mon, 22 Sep 2003 12:36:09 +0100
Subject: [R] how to use jEdit instead of notepad
Message-ID: <ECEKIJOACMKGBEBEFLBEAEMHCAAA.bmjesus@fc.ul.pt>

Dear all,

I've changed the Rprofile file so that jedit would start instead of notepad
whenever I use the fix() command, however nothing get saved when I close the
editor. Any hints on how to use jEdit in a similar fashion to the winedt?

many thanks in advance,
bruno

--------------------------------------------
Bruno Jesus
Instituto de Oceanografia
Faculdade de Ci?ncias de Lisboa
Campo Grande, 1749-016, Lisboa
Portugal



From hennig at stat.math.ethz.ch  Mon Sep 22 13:45:04 2003
From: hennig at stat.math.ethz.ch (Christian Hennig)
Date: Mon, 22 Sep 2003 13:45:04 +0200 (CEST)
Subject: [R] xgobi vs ggobi
In-Reply-To: <XFMail.030918211851.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <Pine.LNX.4.44.0309221340260.1729-100000@florence>

Hi Ted,

here is something rather imprecise. I have both xgobi and ggobi on my
computer. Up to now, I used almost always xgobi, because it contains the
features that I need. Some of these are not in ggobi (e.g. mean/sd and med/mad
standardization). ggobi has also some instabilties (no details now, because
it's some time ago that I encountered them). In general, ggobi looks more
user friedly, is supposed to communicate better with R and does also
some standardization and other things which are not in xgobi.
 
So my advice is to take them both.

Best,
Christian

On Thu, 18 Sep 2003 Ted.Harding at nessie.mcc.ac.uk wrote:

> Hi Folks,
> 
> I'm at the point where I'd normally install xgobi (which I've
> used and found very useful), but there is the alternative of
> ggobi (now at version 0.9).
> 
> Would anyone with experience of both care to indicate the
> merits of either relative to the other?
> 
> The other thing I can't make out too clearly from the ggobu
> website is quite what's involved in choosing between the
> various options. I gather you have to install ggobi itself
> (presumably the "standalone"), and then Rggobi; but there are
> options for ggobi:
> 
> #  stand-alone,
> # stand-alone with XML support,
> # stand-alone and embeddable ggobi library,
>   (this implies an embeddable ggobi library is created.)
> # stand-alone and embeddable ggobi library with XML support,
> # R interface (allowing ggobi to be controlled from R)
> # Python interface (allowing ggobi to be controlled from Python)
> # Perl interface (allowing ggobi to be controlled from Perl)
> 
> I'm not a Perl fan, so won't be strongly tempted by that option.
> I might find a use for Python, however, and clearly I need the
> R interface. I'm more at a loss about the first four:
> 
> # With/without XML support, with/without embeddable ggobi library
> 
> Is there likely to be much advantage, for normal use, in XML?
> Are there serious implications in the footprint with this option?
> [I'm not generously endowed with RAM here, and would like to keep
>  as much as possible for real things, i.e. analysing data]
> 
> What are the merits of the embeddable library?
> 
> With thanks,
> Ted.
> 
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 167 1972
> Date: 18-Sep-03                                       Time: 21:18:51
> ------------------------------ XFMail ------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
***********************************************************************
Christian Hennig
Seminar fuer Statistik, ETH-Zentrum (LEO), CH-8092 Zuerich (currently)
and Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at stat.math.ethz.ch, http://stat.ethz.ch/~hennig/
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag-online.de



From susanabird at yahoo.com.au  Mon Sep 22 13:45:20 2003
From: susanabird at yahoo.com.au (=?iso-8859-1?q?Susana=20Bird?=)
Date: Mon, 22 Sep 2003 21:45:20 +1000 (EST)
Subject: [R] weighting the OLS regression by the inverse of the number of
	observations
Message-ID: <20030922114520.38234.qmail@web20512.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030922/fcadf57a/attachment.pl

From christoph.lehmann at gmx.ch  Mon Sep 22 13:56:44 2003
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Mon, 22 Sep 2003 13:56:44 +0200
Subject: [R] anybody running Rggobi on a redhat 9.0 system?
Message-ID: <1064231803.1162.19.camel@christophl>

Hi
my installation of ggobi (!) was successful, but when I try to install
Rggobi as described on http://www.ggobi.org/INSTALL.html:

as non-su:
R_HOME=/usr/lib/R
export R_HOME
GGOBI_ROOT=/usr/local/src/ggobi
export GGOBI_ROOT
R_LIBS=/usr/lib/R/library
export R_LIBS

as: su
ln -s $GGOBI_ROOT/lib/libggobi.so /usr/lib/.
ln -s $GGOBI_ROOT/lib/libgtkext.so /usr/lib/.
R CMD INSTALL Rggobi_0.53-0.tar.gz

I get:
** R
** inst
** save image
Error in "class<-"(*tmp*, value = Class) :
        couldn't find function "objWithClass"
Warning message:
package methods in options("defaultPackages") was not found
Error in "class<-"(*tmp*, value = Class) :
        couldn't find function "objWithClass"
Error in library("methods") : .First.lib failed
Execution halted
/usr/local/lib/R/bin/INSTALL: line 1: 14240 Broken pipe             cat
"${R_PACKAGE_DIR}/R/${pkg}"
ERROR: execution of package source for 'Rggobi' failed


many thanks for your help
Christoph
-- 
Christoph Lehmann <christoph.lehmann at gmx.ch>



From kwan022 at stat.auckland.ac.nz  Mon Sep 22 14:11:14 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Tue, 23 Sep 2003 00:11:14 +1200 (NZST)
Subject: [R] xgobi vs ggobi
In-Reply-To: <Pine.LNX.4.44.0309221340260.1729-100000@florence>
Message-ID: <Pine.LNX.4.44.0309230004430.22830-100000@stat61.stat.auckland.ac.nz>

Hi,

On Mon, 22 Sep 2003, Christian Hennig wrote:

> Hi Ted,
> 
> here is something rather imprecise. I have both xgobi and ggobi on my
> computer. Up to now, I used almost always xgobi, because it contains the
> features that I need. Some of these are not in ggobi (e.g. mean/sd and med/mad
> standardization). ggobi has also some instabilties (no details now, because
> it's some time ago that I encountered them). In general, ggobi looks more
> user friedly, is supposed to communicate better with R and does also
> some standardization and other things which are not in xgobi.

I think GGobi is also *supposed to be* more "Windows"-friendly, as it does 
not need an X Server running -- whereas you need to have an X Server 
running on Windows in order to use XGobi.

The installation process of GGobi is also easier.  If my memory serves me 
right, I think the XGobi development has sort of stopped and the 
developers are now concentrating on GGobi?  I could be wrong though...

The other thing, I think, is that GGobi supports XML data format and XGobi 
doesn't (or not very well?).

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
"On two occasions, I have been asked [by members of Parliament],
'Pray, Mr. Babbage, if you put into the machine wrong figures, will
the right answers come out?' I am not able to rightly apprehend the
kind of confusion of ideas that could provoke such a question."

-- Charles Babbage (1791-1871) 
---- From Computer Stupidities: http://rinkworks.com/stupid/

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)



From ligges at statistik.uni-dortmund.de  Mon Sep 22 14:13:26 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 22 Sep 2003 14:13:26 +0200
Subject: [R] anybody running Rggobi on a redhat 9.0 system?
In-Reply-To: <1064231803.1162.19.camel@christophl>
References: <1064231803.1162.19.camel@christophl>
Message-ID: <3F6EE766.3030409@statistik.uni-dortmund.de>

Christoph Lehmann wrote:

> Hi
> my installation of ggobi (!) was successful, but when I try to install
> Rggobi as described on http://www.ggobi.org/INSTALL.html:
> 
> as non-su:
> R_HOME=/usr/lib/R
> export R_HOME
> GGOBI_ROOT=/usr/local/src/ggobi
> export GGOBI_ROOT
> R_LIBS=/usr/lib/R/library
> export R_LIBS
> 
> as: su
> ln -s $GGOBI_ROOT/lib/libggobi.so /usr/lib/.
> ln -s $GGOBI_ROOT/lib/libgtkext.so /usr/lib/.
> R CMD INSTALL Rggobi_0.53-0.tar.gz
> 
> I get:
> ** R
> ** inst
> ** save image
> Error in "class<-"(*tmp*, value = Class) :
>         couldn't find function "objWithClass"
> Warning message:
> package methods in options("defaultPackages") was not found
> Error in "class<-"(*tmp*, value = Class) :
>         couldn't find function "objWithClass"
> Error in library("methods") : .First.lib failed
> Execution halted
> /usr/local/lib/R/bin/INSTALL: line 1: 14240 Broken pipe             cat
> "${R_PACKAGE_DIR}/R/${pkg}"
> ERROR: execution of package source for 'Rggobi' failed
> 
> 
> many thanks for your help
> Christoph

Looks like your R installation is broken (package "methods" is not 
available). Try to reinstall R and look out for error messages.


Uwe Ligges



From jps at sanger.ac.uk  Mon Sep 22 14:36:07 2003
From: jps at sanger.ac.uk (Jason Skelton)
Date: Mon, 22 Sep 2003 13:36:07 +0100
Subject: [R] R installation
Message-ID: <3F6EECB7.1010501@sanger.ac.uk>


Hi

further to my upgrade question
thanks for pointing me in the right direction any ideas how I get round 
the following problem:

I'm trying to install on a Tru64 alpha


ecs1h[jps]69: make
`Makedeps' is up to date.
`libappl.a' is up to date.
`Makedeps' is up to date.
`libnmath.a' is up to date.
`Makedeps' is up to date.
`libunix.a' is up to date.
`Makedeps' is up to date.
`libbz2.a' is up to date.
`Makedeps' is up to date.
`libpcre.a' is up to date.
`Makedeps' is up to date.
`R.bin' is up to date.
`Makedeps' is up to date.
`R_X11.so' is up to date.
`Makedeps' is up to date.
`internet.so' is up to date.
`Makedeps' is up to date.
`libRlapack.so' is up to date.
../../../bin/libRlapack.so is unchanged
`lapack.so' is up to date.
`Makedeps' is up to date.
`vfonts.so' is up to date.
building system startup profile
building package 'base'
../../../library/base/R/base is unchanged
../../../library/base/man/base.Rd is unchanged
building package 'ctest'
../../../library/ctest/R/ctest is unchanged
../../../library/ctest/man/ctest.Rd is unchanged
Make: Cannot open ../../../../share/make/../../../../etc/Makeconf.  Stop.
*** Exit 1
Stop.
*** Exit 1
Stop.
*** Exit 1
Stop.
*** Exit 1
Stop.


there is a Makeconf file in the directory I'm trying to install from

/OSF1/R-1.7.1
ecs1h[jps]71: ls
AUTHORS        ChangeLog      Makefile       NEWS           VERSION 
    bin            configure.ac   include        share
BUGS           FAQ            Makefile.in    ONEWS          Y2K 
    config.log     date-stamp     library        so_locations
COPYING        INSTALL        Makefrag.cc    README         acinclude.m4 
   config.site    debian         libtool        src
COPYING.LIB    Makeconf       Makefrag.cxx   RESOURCES      aclocal.m4 
    config.status  doc            m4             tests
COPYRIGHTS     Makeconf.in    Makefrag.f77   THANKS         afm 
    configure      etc            modules        tools


thanks

J.

--------------------------------
Jason Skelton
Pathogen Microarrays
Wellcome Trust Sanger Institute
Hinxton
Cambridge
CB10 1SA

Tel +44(0)1223 834244 Ext 7123
Fax +44(0)1223 494919



From ligges at statistik.uni-dortmund.de  Mon Sep 22 14:44:39 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 22 Sep 2003 14:44:39 +0200
Subject: [R] indexing, subsets, or: not willing to read a manual; was:
	(no subject)
In-Reply-To: <000e01c380f6$74422d30$0d64a8c0@isae.it>
References: <000e01c380f6$74422d30$0d64a8c0@isae.it>
Message-ID: <3F6EEEB7.1020503@statistik.uni-dortmund.de>

Roberto Basile wrote:
> Hi, I have a problem to understand the use of subsets of data while running a regression model.

So, why don't you read a manual or some help pages?
Since you already talked about subsets, I would have taken a look at 
?subset which points you also to ?"["

Please use a sensible subject when posting to a list.

> In particular, I am using sm.regression with these commands 
> 
> plot(lndip96,gdip,col=1,type= "n")
> sm.regression(add=T,lndip96,gdip)

BTW: Strange ordered arguments, here.

> and I must run this model for two subsets of the data; in particular for lndip<=2.7 and for lndip>2.7.

What about indexing with, e.g.
  YourVector[lndip <= 2.7]

Uwe Ligges

> Thank you in advance for your help
> 
> Roberto Basile
> ISAE (Istituto di Studi e Analisi Economica)
> Piazza Indipendenza, 4 
> Roma
> Tel. 06-44482874
> Cell. 3286165588
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From andy_liaw at merck.com  Mon Sep 22 14:44:19 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 22 Sep 2003 08:44:19 -0400
Subject: [R] Data frame from list of lists
Message-ID: <3A822319EB35174CA3714066D590DCD50205CB6F@usrymx25.merck.com>

Don't know if this will be any faster, and it doesn't give you a data frame,
but the final conversion to data frame is probably fairly easy:

> xx <- do.call("rbind", lapply(ListOfLists, function(x) do.call("cbind",
x)))
> xx
     A   L   T           
[1,] "1" "a" "1064233098"
[2,] "2" "b" "1064233098"
[3,] "3" "c" "1064233098"
[4,] "4" "d" "1064233098"

This gives you a character matrix.  The tricky part (for me) is how to get
that last column back to POSIXct.  I have not dealt with date/time in R
before.

HTH,
Andy


> -----Original Message-----
> From: Gregory Jefferis [mailto:jefferis at stanford.edu] 
> Sent: Monday, September 22, 2003 5:15 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Data frame from list of lists
> 
> 
> This seems to be a simple problem, and I feel that there 
> ought to be a simple answer, but I can't seem to find it.
> 
> I have a function that returns a number of values as a 
> heterogeneous list - always the same length and same names(), 
> but a number of different data types, including character.  I 
> want to apply it to many inputs, resulting in a list of lists.
> 
> I would like to turn this list of lists into a single data 
> frame in which each row corresponds to one of the original sublists.
> 
> Here is a toy example:
> 
> myfunc=function(x) return(list(A=x,L=letters[x],T=Sys.time()))
> ListOfLists=lapply(1:4,myfunc)
> ListOfDataFrames=lapply(ListOfLists,as.data.frame)
> df=do.call("rbind",ListOfDataFrames)
> 
> df
> 
> Which gives:
> 
>    A L                   T
> 1  1 a 2003-09-22 02:08:44
> 11 2 b 2003-09-22 02:08:44
> 12 3 c 2003-09-22 02:08:44
> 13 4 d 2003-09-22 02:08:44
> 
> Which is what I want (bar the rownames).  The problem is that 
> this can be very slow, particularly the last rbind step, when 
> I have a large data set (e.g. 5000 rows x20 cols).
> 
> I thought that one improvement might be to preassign the data 
> frame since I know how big it should be and then make 
> assignments row by row.  But it turns out that I can't then 
> assign rows to the data frame one at a time - I get errors 
> because factor levels don't exist e.g.:
> 
> df[5:10,]=df[4,] 
> for (i in 5:10){   
>     df[i,]=as.data.frame(myfunc(i))
> }
> 
> I presume that rbind.data.frame normally looks after adding 
> extra levels to factors as they appear in the new rows being 
> appended to the data frame. If anyone has a solution that is 
> quick (and/or elegant), I would be extremely grateful,
> 
> Greg Jefferis.
> 
> ______________________________________________________________
> ____________
> Greg Jefferis,                          Lab Address: Liqun 
> Luo, Herrin 144
> Neurosciences PhD Programme &                e-mail: 
> jefferis at stanford.edu
> Dept Biological Sciences,                       Lab: (650) 725 5809
> Gilbert Biology Building,                       Fax: (650) 723 0589
> 371 Serra Mall,
> Stanford, CA 94305-5020.                       Home: (650) 326 9597
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
>



From D.R.J.Pleydell at pgr.salford.ac.uk  Mon Sep 22 15:03:54 2003
From: D.R.J.Pleydell at pgr.salford.ac.uk (David Richard John Pleydell)
Date: Mon, 22 Sep 2003 13:03:54 -0000
Subject: [R] Z aware interpolation
In-Reply-To: <200309221013.h8MA2s4F020947@stat.math.ethz.ch>
Message-ID: <5.2.0.9.0.20030922134354.03d21680@mail.salford.ac.uk>

Hi Monica

geoR enables you to do universal kriging, kriging where the mean is 
modelled on one or more Z variables, you can do this by specifying the 
trend component (your Z variable) with the likfit function (if you are 
using maximum liklihood based methods), or with variog function which is 
used with variofit for least squares based methods.

As Edzer pointed out there is also gstat, you may like to look at 
co-kriging which enables spatial information in your Z variable to be 
included in you interpolation. With co-kriging you end up using 3 variogram 
models compared to 1 used in universal kriging, but it may (or may not) 
give a more meaningful prediction depending on your problem.

Then with some cunning wizardry and a little luck you can then export to 
your GIS package.

Hope this helps
Dave


>Hello again,
>
>There is any package which does Z aware (real 3D) interpolations?
>It can be any method (IDW, kriging or spline) but it should take into
>consideration not only x and y coordinates for interpolation, but
>also z coordinate. I looked into different packages but it seems i
>didn't find the right one.
>
>The ultimate goal is to import the output into a GIS (Geographical
>Information System) for further analysis.



From ucgamdo at ucl.ac.uk  Mon Sep 22 15:19:43 2003
From: ucgamdo at ucl.ac.uk (Mario DOS REIS)
Date: Mon, 22 Sep 2003 14:19:43 +0100 (BST)
Subject: [R] RE: persp and soil PH data.
In-Reply-To: <200309221008.h8MA2s44020947@stat.math.ethz.ch>
Message-ID: <Pine.SOL.4.33.0309221415000.17055-100000@socrates-a.ucl.ac.uk>

Hi,

  What you want to do, i.e. plot a surface representig PH values vs. geographical coordinates is not trivial enough as to be
easily explained here. Your set of points x, y, and pH are not good enough to feed them straight into persp as many people
have already pointed out. You must fit a 'surface' to your data, and them, you can use persp or contour on that surface to plot what
you want. Someone already pointed this out, but I will insist on it again: run to your nearest library and get the book on
modern applied statistics with S and S-plus written by Venables and Ripley, there is a chapter on spatial statistics, that
explains in great detail how to do exactly what you want. In fact, if I remember very well (but I'm not 100% sure) there are
some examples of some soil data, etc. Hope this helps. If after reading that chapter you still have problems, send me a
sample of your data and I will try to reproduce a surface for you.

Hope this helps.
Mario.



From SchnitzlerJ at rki.de  Mon Sep 22 16:23:52 2003
From: SchnitzlerJ at rki.de (Schnitzler, Johannes)
Date: Mon, 22 Sep 2003 16:23:52 +0200
Subject: [R] weighted standard deviation
Message-ID: <3DDCC4D685EE744B9FB47706995CFCD10224CA1B@SEMAIL01.RKI.IVBB.BUND.DE>

Dear all,

is there an implemented function to compute a
weighted standard deviation (-like weighted.mean-) in R ?


Thank's a lot in advance


Johannes Schnitzler



From ligges at statistik.uni-dortmund.de  Mon Sep 22 17:12:07 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 22 Sep 2003 17:12:07 +0200
Subject: [R] weighted standard deviation
In-Reply-To: <3DDCC4D685EE744B9FB47706995CFCD10224CA1B@SEMAIL01.RKI.IVBB.BUND.DE>
References: <3DDCC4D685EE744B9FB47706995CFCD10224CA1B@SEMAIL01.RKI.IVBB.BUND.DE>
Message-ID: <3F6F1147.3070206@statistik.uni-dortmund.de>

Schnitzler, Johannes wrote:

> Dear all,
> 
> is there an implemented function to compute a
> weighted standard deviation (-like weighted.mean-) in R ?

No, AFAIK. In particular, I'm interested in your definition of a 
weighted standard deviation (incl. a reference to that definition).

Uwe Ligges


> 
> Thank's a lot in advance
> 
> 
> Johannes Schnitzler



From sundar.dorai-raj at pdf.com  Mon Sep 22 17:15:34 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Mon, 22 Sep 2003 10:15:34 -0500
Subject: [R] weighted standard deviation
In-Reply-To: <3DDCC4D685EE744B9FB47706995CFCD10224CA1B@SEMAIL01.RKI.IVBB.BUND.DE>
References: <3DDCC4D685EE744B9FB47706995CFCD10224CA1B@SEMAIL01.RKI.IVBB.BUND.DE>
Message-ID: <3F6F1216.2020108@pdf.com>

Perhaps "cov.wt" will do what you want?

Schnitzler, Johannes wrote:
> Dear all,
> 
> is there an implemented function to compute a
> weighted standard deviation (-like weighted.mean-) in R ?
> 
> 
> Thank's a lot in advance
> 
> 
> Johannes Schnitzler
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From paul at datavore.com  Mon Sep 22 17:26:34 2003
From: paul at datavore.com (Paul Meagher)
Date: Mon, 22 Sep 2003 12:26:34 -0300
Subject: [R] Updating a linear model
References: <Pine.LNX.4.44.0309230004430.22830-100000@stat61.stat.auckland.ac.nz>
Message-ID: <015201c3811d$e8ddf1c0$f07afea9@computer>

Say I have collected data and used it to construct a linear model.

I now have a new observation and want to use it to update my linear model.

Is there a more efficient way to update the model than recomputing the
linear model from the complete data set?

In other words, can I incrementally update a linear model as new
observations come in without recomputing the linear model from the full data
set?   I've looked at the help for the lm package but can't see anything
obvious that answers my question.

I am trying to use a set of regressors to predict what the next observation
will be.  I would like my coeeficient and intercept estimates to improve as
the data comes in - it will need to work well under limited information at
first (or not at all if there is some lower bound of information quantity
that is required).  If the next data point comes in, I will have (binary or
quantitative) information about whether the prediction was successful or
not.  Not sure if the option to use feedback would dictate a different
approach than the one I am thinking of.   Not sure if a backprop neural
network can be used to estimate the coefficients in a dynamically evolving
multiple linear regression equation.

If anyone has any pointers to packages I might want to look at, suggestions,
etc... I would appreciate it.

Regards,

Paul Meagher

Datavore Productions
50 Wood Grove Drive
Truro, Nova Scotia
B2N-6Y4
1.902.895.9671
www.datavore.com



From p.dalgaard at biostat.ku.dk  Mon Sep 22 18:42:00 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon, 22 Sep 2003 16:42:00 -0000
Subject: [R] Saving with tkgetSaveFile
In-Reply-To: <Pine.SOL.4.58.0309191056320.28303@asteroids.gpcc.itd.umich.edu>
References: <35642.170.210.173.216.1063981183.squirrel@inter14.unsl.edu.ar>
	<Pine.SOL.4.58.0309191056320.28303@asteroids.gpcc.itd.umich.edu>
Message-ID: <x2r828srec.fsf@biostat.ku.dk>

Thomas W Blackwell <tblackw at umich.edu> writes:

> Ruben  -
> 
> Why not simply   save(x, file="new.file.name")  ?
> 
> See  help("save"), help("files").  The file name must be
> quoted, and it must be passed as a named argument to save().

That's not the issue. tclvalue(a) instead of as.character(a) should be
the solution if there are spaces in the filename. Tcl internals are to
blame... 

        -p

> -  tom blackwell  -  u michigan medical school  -  ann arbor  -
> 
> On Fri, 19 Sep 2003 solares at unsl.edu.ar wrote:
> 
> > HI, i'm trying to save a data frame with the next script:
> > x<-c(1,2,3)#suposse here the data frame
> > a<-tkgetSaveFile()
> > a<-tkgetSaveFile()
> > save(x,file=as.character(a))
> >
> > but i obtain the next warning message:
> > Warning messages:
> > 1: the condition has length > 1 and only the first element will be used in:
> > if (file == "") stop("`file' must be non-empty string")
> > 2: only first element of `description' argument used
> >
> > and nothing file is saved, ?What is the error? Thanks Ruben
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From rxg218 at psu.edu  Mon Sep 22 18:48:04 2003
From: rxg218 at psu.edu (Rajarshi Guha)
Date: Mon, 22 Sep 2003 16:48:04 -0000
Subject: [R] a question about the pls.pcr package
Message-ID: <1064249564.4119.9.camel@ra.chem.psu.edu>

Hi,
  I downloaded the pls.pcr package and was experimenting with some of my
data. I have two files: the first contains the obervation matrix, each
line consisting of the parameters for one observation. The other file
contains the dependant variable (one value per line).

The steps I do to do a PLS are:

x <- read.table("obs")
y <- read.table("res")
o <- mvr(x,y,method="SIMPLS")

This appears to work. However when I do 

o <- mvr(x,y,method="SIMPLS",validation="CV")

I get

Error in crossprod(x, y) : requires numeric matrix/vector arguments

Does anybody have any idea why this should occur?

Thanks,

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
C Code.
C Code Run.
Run, Code, RUN!
PLEASE!!!!



From gregciresi at acedsl.com  Mon Sep 22 18:53:51 2003
From: gregciresi at acedsl.com (gregciresi@acedsl.com)
Date: Mon, 22 Sep 2003 12:53:51 -0400
Subject: [R] setting up different project directories in R
Message-ID: <1064249631.3f6f291f1d23d@www.acedsl.com>

I am a novice R user looking to set up different project directories.

In my S+ shortcuts, in the Target field, I use
    Splus.exe S_PROJ=D:\MYWORK
    Splus.exe S_PROJ=D:\MYWORK2
       etc.
Is there a similar way to set up the shortcuts in R?

Would it make sense in R to use multiple shortcuts with different 
settings in the target line?

Thanks,
Greg



From edd at debian.org  Mon Sep 22 19:52:56 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 22 Sep 2003 12:52:56 -0500
Subject: [R] weighted standard deviation
In-Reply-To: <3F6F1147.3070206@statistik.uni-dortmund.de>
References: <3DDCC4D685EE744B9FB47706995CFCD10224CA1B@SEMAIL01.RKI.IVBB.BUND.DE>
	<3F6F1147.3070206@statistik.uni-dortmund.de>
Message-ID: <20030922175256.GA25978@sonny.eddelbuettel.com>

On Mon, Sep 22, 2003 at 05:12:07PM +0200, Uwe Ligges wrote:
> Schnitzler, Johannes wrote:
> 
> >Dear all,
> >
> >is there an implemented function to compute a
> >weighted standard deviation (-like weighted.mean-) in R ?
> 
> No, AFAIK. In particular, I'm interested in your definition of a 
> weighted standard deviation (incl. a reference to that definition).

Frank Harrell's Hmisc has this, and more:

wtd.mean, wtd.var, wtd.quantile, wtd.ecdf, wtd.table, wtd.rank,
wtd.loess.noiter, num.denom.setup
                Set of function for obtaining weighted estimates
		
Hth, Dirk		

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From tlumley at u.washington.edu  Mon Sep 22 20:20:18 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 22 Sep 2003 11:20:18 -0700 (PDT)
Subject: [R] Updating a linear model
In-Reply-To: <015201c3811d$e8ddf1c0$f07afea9@computer>
References: <Pine.LNX.4.44.0309230004430.22830-100000@stat61.stat.auckland.ac.nz>
	<015201c3811d$e8ddf1c0$f07afea9@computer>
Message-ID: <Pine.A41.4.58.0309221117500.183774@homer08.u.washington.edu>

On Mon, 22 Sep 2003, Paul Meagher wrote:

> Say I have collected data and used it to construct a linear model.
>
> I now have a new observation and want to use it to update my linear model.
>
> Is there a more efficient way to update the model than recomputing the
> linear model from the complete data set?
>

Not implemented.  While in principle there are much more efficient things
to do, in practice there is enough overhead in lm() that it probably isn't
worth doing them.


	-thomas



From tlumley at u.washington.edu  Mon Sep 22 20:22:20 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 22 Sep 2003 11:22:20 -0700 (PDT)
Subject: [R] setting up different project directories in R
In-Reply-To: <1064249631.3f6f291f1d23d@www.acedsl.com>
References: <1064249631.3f6f291f1d23d@www.acedsl.com>
Message-ID: <Pine.A41.4.58.0309221120480.183774@homer08.u.washington.edu>

On Mon, 22 Sep 2003 gregciresi at acedsl.com wrote:

> I am a novice R user looking to set up different project directories.
>
> In my S+ shortcuts, in the Target field, I use
>     Splus.exe S_PROJ=D:\MYWORK
>     Splus.exe S_PROJ=D:\MYWORK2
>        etc.
> Is there a similar way to set up the shortcuts in R?
>

Just change the `Start in' field in the shortcut to the directory where
you want to start.

	-thomas



From rbonk at host.sk  Tue Sep 23 02:48:09 2003
From: rbonk at host.sk (Rado Bonk)
Date: Mon, 22 Sep 2003 20:48:09 -0400
Subject: [R] number of distinct values in a dataframe
Message-ID: <1064278088.5039.15.camel@templar.fns.uniba.sk>

Hi R-users,

How can I found the number of a distinct values in a data frame
(occurrence of distinct values)? The dataframe consists of several
thousands integer numbers.

Thanks,

Rado

-- 
Radoslav Bonk M.S.
Dept. of Physical Geography and Geoecology
Faculty of Sciences, Comenius University
Mlynska Dolina 842 15, Bratislava, SLOVAKIA
tel: +421 905 968 127 e-mail: rbonk at host.sk



From paul at datavore.com  Mon Sep 22 21:02:56 2003
From: paul at datavore.com (Paul Meagher)
Date: Mon, 22 Sep 2003 16:02:56 -0300
Subject: [R] Updating a linear model
References: <200309221836.h8MIaWxU014434@erdos.math.unb.ca>
Message-ID: <018d01c3813c$247e8c80$f07afea9@computer>

My google search for Plackett's Algorithm didn't return too much except that
Plackett's algorithm appears to be useful in Control Theory - it is
elaborated as "Plackett's algorithm for on-line recursive least squares
estimation".  Sounds something like what I want.

I am looking at developing a user modelling type app (new data points coming
in and wanting to dynamically update regression co-efficients for each user)
which could be viewed as a type of control problem.

Regards,
Paul

----- Original Message ----- 
From: "Rolf Turner" <rolf at math.unb.ca>
To: <paul at datavore.com>
Sent: Monday, September 22, 2003 3:36 PM
Subject: Re: [R] Updating a linear model


>
> As Thomas Lumley just said, there's nothing implemented in R.  The
> updating procedure is well-known and worked out; it is (in my
> experience) referred to as ``Plackett's Algorithm''.
>
> The reference I have to hand for this --- should you wish to roll
> your own --- is:
>
> Rao, C. Radhakrishna, Linear Statistical Inference and Its
> Applications, John Wiley \& Sons, New York, 1968,  page 29,
> Exercise 2.8
>
> There are --- almost surely --- better references, but I don't
> know them.
> cheers,
>
> Rolf Turner
> rolf at math.unb.ca
>



From bates at stat.wisc.edu  Mon Sep 22 21:12:23 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 22 Sep 2003 19:12:23 -0000
Subject: [R] number of distinct values in a dataframe
In-Reply-To: <1064278088.5039.15.camel@templar.fns.uniba.sk>
References: <1064278088.5039.15.camel@templar.fns.uniba.sk>
Message-ID: <6r4qz47i2p.fsf@bates4.stat.wisc.edu>

Rado Bonk <rbonk at host.sk> writes:

> How can I found the number of a distinct values in a data frame
> (occurrence of distinct values)? The dataframe consists of several
> thousands integer numbers.

It is not clear if you are asking about the number of unique values in
a column in a data frame or the number of unique rows in a data frame.
If there is more than one column these answers could be different.

The first is question is the easier one. Just use

 length(unique(mydataframe$columnOfInterest))



From jefferis at stanford.edu  Mon Sep 22 21:33:13 2003
From: jefferis at stanford.edu (Gregory Jefferis)
Date: Mon, 22 Sep 2003 12:33:13 -0700
Subject: [R] Data frame from list of lists (Quick Summary)
In-Reply-To: <3A822319EB35174CA3714066D590DCD50205CB6F@usrymx25.merck.com>
Message-ID: <BB949C89.58F1%jefferis@stanford.edu>

Here is a quick summary, since I always like it when people post the useful
answers they get (thanks very much to the three respondents).  What I learnt
was (and apologies to those list members for whom these are not exactly
revelations):

1) When making dataframes, work column-wise not row-wise when possible.
This is likely to be much faster (e.g. cbind not rbind) and friendlier
(data.frame(ListOfColumns) is a one liner, whereas data.frame(ListOfRows)
doesn't work).

2) To prevent complex classes like POSIXct (a date) from being unclassed:
    do.call("c",lapply(list,FUN)) is better than sapply(list,FUN)

Code:
#------------------------------------------------------------------------
# The input data was:
myfunc=function(x) return(list(A=x,L=letters[x],T=Sys.time()))
ToyListOfLists=lapply(1:4,myfunc)

# My Solution was:
#------------------------------------------------------------------------
FirstSubList=ToyListOfLists[[1]]
getCol=function(n) do.call( "c",lapply(ToyListOfLists,function(x) x[[n]]) )
ListOfCols=lapply(seq(FirstSubList),getCol)
df=data.frame(ListOfCols)
names(df)=names(FirstSubList)

# Damon Wischik's solution
# this is essentially the same but better, since:
# 1) it will also work if the list returned by myfunc() includes a factor
# 2) the protection against NAs in the list _may_ be useful
#------------------------------------------------------------------------
transpose.list(ToyListOfLists)

transpose.list <- function(lst) {
  typicalrow <- lst[[1]]
# GJ However, I am not sure that protection against NAs in
# the next 6 lines is necessary
  if (length(lst)>1) for (i in 2:length(lst)) {
    if (!any(is.na(typicalrow))) break
    better <- (is.na(typicalrow) & !is.na(lst[[i]]))
    for (j in which(better))
      typicalrow[[j]] <- lst[[i]][[j]]
  }
  getfield <- function(i) {
    v <- lapply(lst, function(row) row[[i]] )
    vv <- do.call("c",v)
    typicalitem <- typicalrow[[i]]
    if (is.factor(typicalitem))
      {
      vvf <- rep(typicalitem,length(vv))
      codes(vvf) <- vv
      vvf
      }
    else
      vv
    }
  cols <- lapply(1:length(typicalrow), function(i) getfield(i))
  names(cols) <- names(typicalrow)
# I think the next 2 lines could be replaced by:
# data.frame(cols) 
  df <- do.call("data.frame",cols)
  df
}


On 9/22/03 5:44, "Liaw, Andy" <andy_liaw at merck.com> wrote:

> Don't know if this will be any faster, and it doesn't give you a data frame,
> but the final conversion to data frame is probably fairly easy:
> 
>> xx <- do.call("rbind", lapply(ListOfLists, function(x) do.call("cbind",
> x)))
>> xx
>    A   L   T     
> [1,] "1" "a" "1064233098"
> [2,] "2" "b" "1064233098"
> [3,] "3" "c" "1064233098"
> [4,] "4" "d" "1064233098"
> 
> This gives you a character matrix.  The tricky part (for me) is how to get
> that last column back to POSIXct.  I have not dealt with date/time in R
> before.
> 
> HTH,
> Andy
> 
> 
>> -----Original Message-----
>> From: Gregory Jefferis [mailto:jefferis at stanford.edu]
>> Sent: Monday, September 22, 2003 5:15 AM
>> To: r-help at stat.math.ethz.ch
>> Subject: [R] Data frame from list of lists
>> 
>> 
>> This seems to be a simple problem, and I feel that there
>> ought to be a simple answer, but I can't seem to find it.
>> 
>> I have a function that returns a number of values as a
>> heterogeneous list - always the same length and same names(),
>> but a number of different data types, including character.  I
>> want to apply it to many inputs, resulting in a list of lists.
>> 
>> I would like to turn this list of lists into a single data
>> frame in which each row corresponds to one of the original sublists.
>> 
>> Here is a toy example:
>> 
>> myfunc=function(x) return(list(A=x,L=letters[x],T=Sys.time()))
>> ListOfLists=lapply(1:4,myfunc)
>> ListOfDataFrames=lapply(ListOfLists,as.data.frame)
>> df=do.call("rbind",ListOfDataFrames)
>> 
>> df
>> 
>> Which gives:
>> 
>>    A L                   T
>> 1  1 a 2003-09-22 02:08:44
>> 11 2 b 2003-09-22 02:08:44
>> 12 3 c 2003-09-22 02:08:44
>> 13 4 d 2003-09-22 02:08:44
>> 
>> Which is what I want (bar the rownames).  The problem is that
>> this can be very slow, particularly the last rbind step, when
>> I have a large data set (e.g. 5000 rows x20 cols).
>> 
>> I thought that one improvement might be to preassign the data
>> frame since I know how big it should be and then make
>> assignments row by row.  But it turns out that I can't then
>> assign rows to the data frame one at a time - I get errors
>> because factor levels don't exist e.g.:
>> 
>> df[5:10,]=df[4,]
>> for (i in 5:10){
>>     df[i,]=as.data.frame(myfunc(i))
>> }
>> 
>> I presume that rbind.data.frame normally looks after adding
>> extra levels to factors as they appear in the new rows being
>> appended to the data frame. If anyone has a solution that is
>> quick (and/or elegant), I would be extremely grateful,
>> 
>> Greg Jefferis.
>> 
>> ______________________________________________________________
>> ____________
>> Greg Jefferis,                          Lab Address: Liqun
>> Luo, Herrin 144
>> Neurosciences PhD Programme &                e-mail:
>> jefferis at stanford.edu
>> Dept Biological Sciences,                       Lab: (650) 725 5809
>> Gilbert Biology Building,                       Fax: (650) 723 0589
>> 371 Serra Mall,
>> Stanford, CA 94305-5020.                       Home: (650) 326 9597
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
>> 
> 

__________________________________________________________________________
Greg Jefferis,                          Lab Address: Liqun Luo, Herrin 144
Neurosciences PhD Programme &                e-mail: jefferis at stanford.edu
Dept Biological Sciences,                       Lab: (650) 725 5809
Gilbert Biology Building,                       Fax: (650) 723 0589
371 Serra Mall,
Stanford, CA 94305-5020.                       Home: (650) 326 9597



From abunn at mymail.msu.montana.edu  Mon Sep 22 22:41:28 2003
From: abunn at mymail.msu.montana.edu (abunn@mymail.msu.montana.edu)
Date: Mon, 22 Sep 2003 14:41:28 -0600
Subject: [R] Managing a list with a list
Message-ID: <2c75b4b60ad74a8ab7506f059427eef4.abunn@mymail.msu.montana.edu>

OK. Another amateur question.

I have a list with attributes on pine trees, like the stem's location, a logical value set to T if it's alive, some parameters for growth, diameter, etc. The tree list has another list in it which is a new data type for me. 

I want to make a new list that retains all the live trees. 
That is where Living == T.

Here's the summary of the list:

> summary(tf)
       Length Class  Mode   
id     10     -none- numeric
x      10     -none- numeric
y      10     -none- numeric
A      10     -none- numeric
NegB   10     -none- numeric
K      10     -none- numeric
Age    10     -none- numeric
DBH    10     -none- numeric
Living 10     -none- logical
pSeed  10     -none- list   
TCI    10     -none- numeric
STA    10     -none- numeric

Here are the living trees.

> tf$Living
 [1] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE

So, here are the ids of the trees I want to retain.

> tf$id[tf$Living == T]
[1]  2  3  4  5  6  7  9 10

Same with the easting coordinates.

> tf$x[tf$Living == T] #tf[[2]][tf$Living == T]
[1] 28 35 18 34 36 92  3 47
> 

But when I try to keep the whole list minus the dead trees it returns a list with all the trees living and dead (as I'm sure it is supposed to):

tf[tf$Living == T]

What am I doing wrong? I'm happy to RTFM, but if the manual in question is section 3.4 of R-lang then I'm still going to need help. I can break it all apart and then concatonate a new list but that seems heavy handed.

Thanks, Andy



From tlumley at u.washington.edu  Mon Sep 22 22:44:07 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 22 Sep 2003 13:44:07 -0700 (PDT)
Subject: [R] number of distinct values in a dataframe
In-Reply-To: <6r4qz47i2p.fsf@bates4.stat.wisc.edu>
References: <1064278088.5039.15.camel@templar.fns.uniba.sk>
	<6r4qz47i2p.fsf@bates4.stat.wisc.edu>
Message-ID: <Pine.A41.4.58.0309221326060.75096@homer41.u.washington.edu>

On Mon, 22 Sep 2003, Douglas Bates wrote:

> Rado Bonk <rbonk at host.sk> writes:
>
> > How can I found the number of a distinct values in a data frame
> > (occurrence of distinct values)? The dataframe consists of several
> > thousands integer numbers.
>
> It is not clear if you are asking about the number of unique values in
> a column in a data frame or the number of unique rows in a data frame.
> If there is more than one column these answers could be different.
>
> The first is question is the easier one. Just use
>
>  length(unique(mydataframe$columnOfInterest))
>

The same works for the second question

	length(unique(mydataframe))


	-thomas



From jasont at indigoindustrial.co.nz  Mon Sep 22 23:03:59 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Mon, 22 Sep 2003 21:03:59 -0000
Subject: [R] Updating a linear model
In-Reply-To: <018d01c3813c$247e8c80$f07afea9@computer>
References: <200309221836.h8MIaWxU014434@erdos.math.unb.ca>
	<018d01c3813c$247e8c80$f07afea9@computer>
Message-ID: <1064265105.22913.12.camel@kryten.akl.indigoindustrial.co.nz>

On Tue, 2003-09-23 at 07:02, Paul Meagher wrote:
> My google search for Plackett's Algorithm didn't return too much except that
> Plackett's algorithm appears to be useful in Control Theory - it is
> elaborated as "Plackett's algorithm for on-line recursive least squares
> estimation".  Sounds something like what I want.

Recursive least squares is touched upon in Ogata, pp 861-863.

@Book{Ogata1987,
  author =	 {Katsuhiko Ogata},
  title = 	 {Discrete-Time Control Systems},
  publisher = 	 {Prentice-Hall},
  year = 	 1987,
  address =	 {Englewood Cliffs, New Jersey}
}

These algorithms are built for speed, not robustness.  They are written
for online real-time systems that might have to solve many of these
identification problems in under a second.  As such, you won't get the
nice features of things like a trimmed least squares (though weighting
is covered in Ogata).

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
+64-(0)21-343-545



From jfox at mcmaster.ca  Mon Sep 22 21:54:47 2003
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 22 Sep 2003 15:54:47 -0400
Subject: [R] number of distinct values in a dataframe
In-Reply-To: <6r4qz47i2p.fsf@bates4.stat.wisc.edu>
References: <1064278088.5039.15.camel@templar.fns.uniba.sk>
	<1064278088.5039.15.camel@templar.fns.uniba.sk>
Message-ID: <5.0.2.1.0.20030922154922.023f6ea0@127.0.0.1>

Dear Rado and Doug,

At 02:13 PM 9/22/2003 -0500, Douglas Bates wrote:
>Rado Bonk <rbonk at host.sk> writes:
>
> > How can I found the number of a distinct values in a data frame
> > (occurrence of distinct values)? The dataframe consists of several
> > thousands integer numbers.
>
>It is not clear if you are asking about the number of unique values in
>a column in a data frame or the number of unique rows in a data frame.
>If there is more than one column these answers could be different.
>
>The first is question is the easier one. Just use
>
>  length(unique(mydataframe$columnOfInterest))

Since the data frame consists entirely of numeric values, finding the 
number of unique values in the data frame as a whole isn't much harder:

length(unique(as.vector(as.matrix(mydataframe))))

Regards,
  John


____________________________
John Fox
Department of Sociology
McMaster University
email: jfox at mcmaster.ca
web: http://www.socsci.mcmaster.ca/jfox



From garvin at cs.rice.edu  Tue Sep 23 00:52:36 2003
From: garvin at cs.rice.edu (John Garvin)
Date: Mon, 22 Sep 2003 17:52:36 -0500 (CDT)
Subject: [R] Compiling shared library on Alpha/OSF1
Message-ID: <Pine.LNX.4.44.0309221747140.3970-100000@hpc3.cs.rice.edu>

I'm having trouble compiling and installing R as a shared library on 
Alpha/OSF1. I used

./configure --enable-R-shlib SHLIB_CXXLDFLAGS=-L/lib/cmplrs/cxx

(Using configure with --enable-R-shlib alone generated "Could not
determine SHLIB_CXXLDFLAGS" errors.) make and everything else were done 
as specified in the documentation.

It compiled everything without visible problems, but on linking libR.so I 
got the following message:

/sbin/loader: Fatal Error: Cannot map library libR.so

Has anyone heard of this happening?

John Garvin



From jeaneid at chass.utoronto.ca  Tue Sep 23 01:07:47 2003
From: jeaneid at chass.utoronto.ca (Jean Eid)
Date: Mon, 22 Sep 2003 19:07:47 -0400
Subject: [R] ksmooth in  SPLUS vs R 
Message-ID: <Pine.SGI.4.40.0309221854030.1315265-100000@origin.chass.utoronto.ca>

I am working with a model that I have to estimate a nonparametric
function. The model is partial linear i.e.

Y=X$\beta$ + f(z) + $\epsilon$

I am using the ' double residual methods' Robinson (1988) Speckman (1988)
where I estimate a nonparametric function for each of the parametric
variables in terms of the nonparametric one i.e.

X[,i]=g(Z)+ u

this is done because I need the $E( X[,i]\vert Z)$ for each position j in
the vectors.

the problem is that when I use the ksmooth() function in R it estimates
the function at different points and not those that consist of the Z
vector.

the ksmooth() function in Splus on the other hand evaluates the points at
the corresponding Z vector. both codes are given below


d<-ksmooth(lprice,XX[,i],kernel="box")
unique(lprice-d$x)

in SPLUS will generate 0 while in R it generates a vector of different
values.



My second question is regarding the sm library:

d<-sm.regression(lprice, XX[,i], h=sd(lprice), display="none")
will only generate 50 point estimates while  NROW(XX[,i]) = 3897
and when I do
d<-sm.regression(lprice, XX[,i], h=sd(lprice), display="none",
ngrid=NROW(lprice))

I get the right dimension of the estimated points but again they are not
estimated at the points in lprice.


Any help is greatly appreciated.

P.S. I have Bowman and Azzalini book but unfortunately it does not clarify
the procedures in sm.regression()

Jean,



From bkrith at conrel.sice.umkc.edu  Tue Sep 23 01:29:55 2003
From: bkrith at conrel.sice.umkc.edu (Balaji Krithikaivasan)
Date: Mon, 22 Sep 2003 18:29:55 -0500 (CDT)
Subject: [R] Help on Time series seasonal Models in R package
Message-ID: <Pine.LNX.4.33.0309221829030.23245-100000@Net_Server>

Hi there, 
  I am a graduate student using "R" for time series modeling. I have a 
weeks data with 96 data per day. I am trying to use a seasonal model 
with period of 96 (the size of the total data is 480) to 
fit the data after deriving the order information from ACF 
and PACF plots. But, I am getting the 
following error message
  "Error in optim(init[mask] ...) : non-finite finite difference.
when i try to use arima(...).

   I would appreciate any help on this regard.

-Balaji.
-- 
"Two roads diverged in a wood and I took the one less traveled by and,
			that has made all the difference" -- Robert Frost

Balaji Krithikaivasan (PhD Student),
[Co]mputer [N]etworking [Re]search [L]ab (CoNReL)



From tlumley at u.washington.edu  Tue Sep 23 01:45:07 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 22 Sep 2003 16:45:07 -0700 (PDT)
Subject: [R] ksmooth in  SPLUS vs R 
In-Reply-To: <Pine.SGI.4.40.0309221854030.1315265-100000@origin.chass.utoronto.ca>
References: <Pine.SGI.4.40.0309221854030.1315265-100000@origin.chass.utoronto.ca>
Message-ID: <Pine.A41.4.58.0309221639350.27044@homer31.u.washington.edu>

On Mon, 22 Sep 2003, Jean Eid wrote:

>
> the problem is that when I use the ksmooth() function in R it estimates
> the function at different points and not those that consist of the Z
> vector.

The help page for ksmooth tells you how to estimate at whatever points you
like

	-thomas



From jeaneid at chass.utoronto.ca  Tue Sep 23 02:23:32 2003
From: jeaneid at chass.utoronto.ca (Jean Eid)
Date: Mon, 22 Sep 2003 20:23:32 -0400
Subject: [R] ksmooth in  SPLUS vs R 
In-Reply-To: <Pine.SGI.4.40.0309221854030.1315265-100000@origin.chass.utoronto.ca>
Message-ID: <Pine.SGI.4.40.0309222023260.1820056-100000@origin.chass.utoronto.ca>

Please do forget my questions as they are really trivial and I do not kno
what I was thinking of.

Thank you thomas for clarifying my cloudy head today.

jean,


On Mon, 22 Sep 2003, Jean Eid wrote:

> I am working with a model that I have to estimate a nonparametric
> function. The model is partial linear i.e.
>
> Y=X$\beta$ + f(z) + $\epsilon$
>
> I am using the ' double residual methods' Robinson (1988) Speckman (1988)
> where I estimate a nonparametric function for each of the parametric
> variables in terms of the nonparametric one i.e.
>
> X[,i]=g(Z)+ u
>
> this is done because I need the $E( X[,i]\vert Z)$ for each position j in
> the vectors.
>
> the problem is that when I use the ksmooth() function in R it estimates
> the function at different points and not those that consist of the Z
> vector.
>
> the ksmooth() function in Splus on the other hand evaluates the points at
> the corresponding Z vector. both codes are given below
>
>
> d<-ksmooth(lprice,XX[,i],kernel="box")
> unique(lprice-d$x)
>
> in SPLUS will generate 0 while in R it generates a vector of different
> values.
>
>
>
> My second question is regarding the sm library:
>
> d<-sm.regression(lprice, XX[,i], h=sd(lprice), display="none")
> will only generate 50 point estimates while  NROW(XX[,i]) = 3897
> and when I do
> d<-sm.regression(lprice, XX[,i], h=sd(lprice), display="none",
> ngrid=NROW(lprice))
>
> I get the right dimension of the estimated points but again they are not
> estimated at the points in lprice.
>
>
> Any help is greatly appreciated.
>
> P.S. I have Bowman and Azzalini book but unfortunately it does not clarify
> the procedures in sm.regression()
>
> Jean,
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From den.duurs at lycos.com  Tue Sep 23 02:44:45 2003
From: den.duurs at lycos.com (Remko Duursma)
Date: Mon, 22 Sep 2003 17:44:45 -0700
Subject: [R] Very small estimated random effect variance (lme)
Message-ID: <CKGFCKJHCOLKCDAA@mailcity.com>

Dear R-helpers,

i get some strange results using a linear mixed-effects model (lme), of the type:

lme1 <- lme(y ~ x, random=~x|group, ...)

For some datasets, i obtain very small standard deviations of the random effects. I compared these to standard deviations of the slope and intercept using a lmList approach. Of course, the SD from the lme is always smaller (shrinkage estimator), but in some cases (the problem cases) the SD from the lme seems way too small. E.g.: SD of intercept = 0.14, SD of slope = 0.0004, SD residual=0.11. An lmList gives a slope SD of 0.07.

I have about n=6 observations per group, and about 20-100 groups depending on the dataset.

thank you for any suggestions,

Remko



^'~,_,~'^'~,_,~'^'~,_,~'^'~,_,~'^'~,_,~'^'~,_,~'
Remko Duursma, Ph.D. student
Forest Biometrics Lab / Idaho Stable Isotope Lab
University of Idaho, Moscow, ID, U.S.A.



____________________________________________________________
Diabetics: Click here for a Free Glucose Meter from Access Diabetic.
http://r.hotbot.com/r/lmt_ad/http://mocda4.com/1/c/563632/102938/302214/302214
This offer applies to U.S. Residents Only



From olau at fas.harvard.edu  Tue Sep 23 02:51:18 2003
From: olau at fas.harvard.edu (Olivia Lau)
Date: Mon, 22 Sep 2003 20:51:18 -0400
Subject: [R] searching R-help within a function
Message-ID: <001001c3816c$cfc633b0$4e02a8c0@olau>

Hi,

I am working on a package which requires separate documentation
(tutorial documentation, really, with a lot of beautifully
latexed equations), and does not use R-help.  I am trying to
make it so that my help function will automatically search
R-help if the help topic isn't found in my documentation.

The function looks something like this:

help.pkg <- function(topic) {            # where the topic is a
character string
    url <- NULL
    if(is.character(topic)) {
        .....   # assignments for the URL given the topic
       }
    if (is.null(url)) {
        topic <- as.name(topic)
        help(topic)
   }
}

In the last line, help(topic) returns that there is no help for
"topic".  I have also tried various permutations of
substitute(help(topic)) and eval() to no avail.

Any suggestions are greatly appreciated.  Thanks,

Olivia Lau.



From fzagmutt at hotmail.com  Tue Sep 23 03:19:26 2003
From: fzagmutt at hotmail.com (Francisco J. Zagmutt Vergara)
Date: Tue, 23 Sep 2003 01:19:26 +0000
Subject: [R] ANOVA(L, Terms...)
Message-ID: <Law15-F62pyT1MQyJdp0002f958@hotmail.com>

Hi There

I have a lm object with 4 parameters and I want to test wether 2 parameters 
are equal using a Wald test (basically b1=b2 or b1-b2 =0).  In the help file 
from R it says that under ANOVA the optional arguments " Terms" or "L" test 
whether a linear combination is equal to 0.  I tried;

>anova(m1, Terms = Beta1-Beta2=0) but I get the error:
Object " Beta1" must be assigned locally before replacement.

I also tried

>anova (m1, Terms = 1-2 = 0) and I get:

Invalid assginment: No object name : 1-2 = 0

What am I doing wrong?

Thanks for your help!!






>From: Jean Eid <jeaneid at chass.utoronto.ca>
>To: r-help at stat.math.ethz.ch
>Subject: Re: [R] ksmooth in  SPLUS vs R Date: Mon, 22 Sep 2003 20:23:32 
>-0400
>
>Please do forget my questions as they are really trivial and I do not kno
>what I was thinking of.
>
>Thank you thomas for clarifying my cloudy head today.
>
>jean,
>
>
>On Mon, 22 Sep 2003, Jean Eid wrote:
>
> > I am working with a model that I have to estimate a nonparametric
> > function. The model is partial linear i.e.
> >
> > Y=X$\beta$ + f(z) + $\epsilon$
> >
> > I am using the ' double residual methods' Robinson (1988) Speckman 
>(1988)
> > where I estimate a nonparametric function for each of the parametric
> > variables in terms of the nonparametric one i.e.
> >
> > X[,i]=g(Z)+ u
> >
> > this is done because I need the $E( X[,i]\vert Z)$ for each position j 
>in
> > the vectors.
> >
> > the problem is that when I use the ksmooth() function in R it estimates
> > the function at different points and not those that consist of the Z
> > vector.
> >
> > the ksmooth() function in Splus on the other hand evaluates the points 
>at
> > the corresponding Z vector. both codes are given below
> >
> >
> > d<-ksmooth(lprice,XX[,i],kernel="box")
> > unique(lprice-d$x)
> >
> > in SPLUS will generate 0 while in R it generates a vector of different
> > values.
> >
> >
> >
> > My second question is regarding the sm library:
> >
> > d<-sm.regression(lprice, XX[,i], h=sd(lprice), display="none")
> > will only generate 50 point estimates while  NROW(XX[,i]) = 3897
> > and when I do
> > d<-sm.regression(lprice, XX[,i], h=sd(lprice), display="none",
> > ngrid=NROW(lprice))
> >
> > I get the right dimension of the estimated points but again they are not
> > estimated at the points in lprice.
> >
> >
> > Any help is greatly appreciated.
> >
> > P.S. I have Bowman and Azzalini book but unfortunately it does not 
>clarify
> > the procedures in sm.regression()
> >
> > Jean,
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help

_________________________________________________________________
?Est?s buscando un auto nuevo?  http://www.yupimsn.com/autos/



From comm at 263.net  Tue Sep 23 04:41:34 2003
From: comm at 263.net (Jean Sun)
Date: Tue, 23 Sep 2003 10:41:34 +0800
Subject: [R] what does the sum of square of Gaussian RVs with different
	variance obey?
Message-ID: <20030923024119.5EF1B33FA5@smtp.263.net>

>From basic statistics principle,we know,given several i.i.d Gaussian RVs with zero or nonzero mean,the sum of square of them is a central or noncentral Chi-distributed RV.However if these Gaussian RVs have different variances,what does the sum of square of them obey? 

Thanks in advance.



From zitan at mediasculpt.net  Wed Sep 24 00:57:12 2003
From: zitan at mediasculpt.net (Zitan Broth)
Date: Tue, 23 Sep 2003 15:57:12 -0700
Subject: [R] R Production Performance
Message-ID: <060f01c38226$0689ad00$3201a8c0@zitan>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030923/188025cb/attachment.pl

From maj at stats.waikato.ac.nz  Tue Sep 23 06:29:00 2003
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Tue, 23 Sep 2003 16:29:00 +1200
Subject: [R] R-project  [.com?] [.net?]
Message-ID: <3F6FCC0C.5060002@stats.waikato.ac.nz>

I got a shock a few days ago when I accidentally visited 
www.r-project.com . I thought that the r-project site had been hacked 
until I realised my mistake. There is also a site www.r-project.net. 
Both of these sites appear to be Japanese. Does anyone know anything 
about them? I suppose that it is not unusual for names close to those of 
popular sites to be used. It is good that they use a different language 
or there might well be confusion.

Murray

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862



From Simon.Blomberg at anu.edu.au  Tue Sep 23 06:58:41 2003
From: Simon.Blomberg at anu.edu.au (Simon Blomberg)
Date: Tue, 23 Sep 2003 14:58:41 +1000
Subject: [R] R-project  [.com?] [.net?]
Message-ID: <7A3A13F416B40842BD2C1753E044B359B1342A@CASEVS02.cas.anu.edu.au>

To add to the confusion, there is some statistical software for multivariate and spatial analysis called "the R package".

http://www.fas.umontreal.ca/biol/casgrain/en/labo/R/index.html

Although this link appears to be broken at the moment.

Simon.

Simon Blomberg, PhD
Depression & Anxiety Consumer Research Unit
Centre for Mental Health Research
Australian National University
http://www.anu.edu.au/cmhr/
Simon.Blomberg at anu.edu.au  +61 (2) 6125 3379


> -----Original Message-----
> From: Murray Jorgensen [mailto:maj at stats.waikato.ac.nz]
> Sent: Tuesday, 23 September 2003 2:29 PM
> To: R-help
> Subject: [R] R-project [.com?] [.net?]
> 
> 
> I got a shock a few days ago when I accidentally visited 
> www.r-project.com . I thought that the r-project site had been hacked 
> until I realised my mistake. There is also a site www.r-project.net. 
> Both of these sites appear to be Japanese. Does anyone know anything 
> about them? I suppose that it is not unusual for names close 
> to those of 
> popular sites to be used. It is good that they use a 
> different language 
> or there might well be confusion.
> 
> Murray
> 
> -- 
> Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
> Department of Statistics, University of Waikato, Hamilton, New Zealand
> Email: maj at waikato.ac.nz                                Fax 7 838 4155
> Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From ligges at statistik.uni-dortmund.de  Tue Sep 23 08:30:48 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 23 Sep 2003 08:30:48 +0200
Subject: [R] searching R-help within a function
In-Reply-To: <001001c3816c$cfc633b0$4e02a8c0@olau>
References: <001001c3816c$cfc633b0$4e02a8c0@olau>
Message-ID: <3F6FE898.2000603@statistik.uni-dortmund.de>

Olivia Lau wrote:
> Hi,
> 
> I am working on a package which requires separate documentation
> (tutorial documentation, really, with a lot of beautifully
> latexed equations), and does not use R-help.  I am trying to
> make it so that my help function will automatically search
> R-help if the help topic isn't found in my documentation.
> 
> The function looks something like this:
> 
> help.pkg <- function(topic) {            # where the topic is a
> character string
>     url <- NULL
>     if(is.character(topic)) {
>         .....   # assignments for the URL given the topic
>        }
>     if (is.null(url)) {
>         topic <- as.name(topic)
>         help(topic)
>    }
> }
> 
> In the last line, help(topic) returns that there is no help for
> "topic".  I have also tried various permutations of
> substitute(help(topic)) and eval() to no avail.

     do.call("help", list(topic))

Uwe Ligges

> Any suggestions are greatly appreciated.  Thanks,
> 
> Olivia Lau.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ligges at statistik.uni-dortmund.de  Tue Sep 23 08:36:31 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 23 Sep 2003 08:36:31 +0200
Subject: [R] Managing a list with a list
In-Reply-To: <2c75b4b60ad74a8ab7506f059427eef4.abunn@mymail.msu.montana.edu>
References: <2c75b4b60ad74a8ab7506f059427eef4.abunn@mymail.msu.montana.edu>
Message-ID: <3F6FE9EF.1080205@statistik.uni-dortmund.de>

abunn at mymail.msu.montana.edu wrote:

> OK. Another amateur question.
> 
> I have a list with attributes on pine trees, like the stem's location, a logical value set to T if it's alive, some parameters for growth, diameter, etc. The tree list has another list in it which is a new data type for me. 
> 
> I want to make a new list that retains all the live trees. 
> That is where Living == T.
> 
> Here's the summary of the list:
> 
> 
>>summary(tf)
> 
>        Length Class  Mode   
> id     10     -none- numeric
> x      10     -none- numeric
> y      10     -none- numeric
> A      10     -none- numeric
> NegB   10     -none- numeric
> K      10     -none- numeric
> Age    10     -none- numeric
> DBH    10     -none- numeric
> Living 10     -none- logical
> pSeed  10     -none- list   
> TCI    10     -none- numeric
> STA    10     -none- numeric
> 
> Here are the living trees.
> 
> 
>>tf$Living
> 
>  [1] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE
> 
> So, here are the ids of the trees I want to retain.
> 
> 
>>tf$id[tf$Living == T]



  lapply(tf, "[", tf$Living)

selects (by indexing with []) those elements from each element of tf, 
where tf$Living is TRUE.

Uwe Ligges



> [1]  2  3  4  5  6  7  9 10
> 
> Same with the easting coordinates.
> 
> 
>>tf$x[tf$Living == T] #tf[[2]][tf$Living == T]
> 
> [1] 28 35 18 34 36 92  3 47
> 
> 
> But when I try to keep the whole list minus the dead trees it returns a list with all the trees living and dead (as I'm sure it is supposed to):
> 
> tf[tf$Living == T]
> 
> What am I doing wrong? I'm happy to RTFM, but if the manual in question is section 3.4 of R-lang then I'm still going to need help. I can break it all apart and then concatonate a new list but that seems heavy handed.
> 
> Thanks, Andy
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From p.dalgaard at biostat.ku.dk  Tue Sep 23 09:46:07 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Tue, 23 Sep 2003 07:46:07 -0000
Subject: [R] Very small estimated random effect variance (lme)
In-Reply-To: <CKGFCKJHCOLKCDAA@mailcity.com>
References: <CKGFCKJHCOLKCDAA@mailcity.com>
Message-ID: <x2fzio6j7c.fsf@biostat.ku.dk>

"Remko Duursma" <den.duurs at lycos.com> writes:

> Dear R-helpers,
> 
> i get some strange results using a linear mixed-effects model (lme), of the type:
> 
> lme1 <- lme(y ~ x, random=~x|group, ...)
> 
> For some datasets, i obtain very small standard deviations of the random effects. I compared these to standard deviations of the slope and intercept using a lmList approach. Of course, the SD from the lme is always smaller (shrinkage estimator), but in some cases (the problem cases) the SD from the lme seems way too small. E.g.: SD of intercept = 0.14, SD of slope = 0.0004, SD residual=0.11. An lmList gives a slope SD of 0.07.
> 
> I have about n=6 observations per group, and about 20-100 groups depending on the dataset.
> 
> thank you for any suggestions,

It's not a shrinkage estimator it is a "subtraction estimator",
measuring the excess variance of the empirical slopes over what would
be expected from their s.e. if all (true) slopes were identical. This
can even be negative, although the parametrizations in lme() will
enforce a zero or very small variance in that case.

(There are occasional cases where a negative variance can be
interpreted, e.g. plants competing for the same growth medium, but
you're generally in trouble if the design is unbalanced.)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From laurent.faisnel at ariase.com  Tue Sep 23 10:10:31 2003
From: laurent.faisnel at ariase.com (Laurent Faisnel)
Date: Tue, 23 Sep 2003 10:10:31 +0200
Subject: [R] R Production Performance
References: <060f01c38226$0689ad00$3201a8c0@zitan>
Message-ID: <3F6FFFF7.6040406@ariase.com>

Zitan Broth wrote:
> Greetings All,
> 
> Been playing with R and it is very easy to get going with the UI or infile batch commands :-)
> 
> What I am wondering is how scalable and fast R is for running as part of a web service.  I believe R is written in C which is a great start, but what are peoples general thoughts on this?
> 
> Thanks greatly,
> Z.
> 

I use R in such a way. R is called by dynamic pages written in PHP, 
performs a calculation and writes results in a XML file. Results are 
then read by other pages. Performances still could be better but I 
haven't tried every solution yet (RSOAP seems very interesting). MySQL 
database access is made thanks to RMySQL.
Anyway, R is not incompatible with such projects.



From Melissa_Kuang at jltgroup.com  Tue Sep 23 11:04:00 2003
From: Melissa_Kuang at jltgroup.com (Melissa_Kuang@jltgroup.com)
Date: Tue, 23 Sep 2003 10:04:00 +0100
Subject: [R] Plotting of the lm
Message-ID: <DD42E3F5AF15D211BDA60008C7A49834050E045A@EMAIL03>

Hi,

I would like to enquire if by typing plot (lm(y~x)) would this show me the
plot of the fitted line? I tried this function previously but I was only
able to get the last 4 plots starting with Residuals vs fitted. 

Thank You.

Melissa


************************************************************
JLT Risk Solutions Ltd
6 Crutched Friars, London EC3N 2PH. Co Reg No 1536540
Tel: (44) (0)20 7528 4000   Fax: (44) (0)20 7528 4500
http://www.jltgroup.com
Lloyd's Broker.  Regulated by the General Insurance
Standards Council
------------------------------------------------------------
The content of this e-mail (including any attachments) as 
received may not be the same as sent. If you consider that 
the content is material to the formation or performance of 
a contract or you are otherwise relying upon its accuracy, 
you should consider requesting a copy be sent by facsimile 
or normal mail.  The information in this e-mail is 
confidential and may be legally privileged. If you are not 
the intended recipient, please notify the sender immediately 
and then delete this e-mail entirely - you must not retain, 
copy, distribute or use this e-mail for any purpose or 
disclose any of its content to others.

Opinions, conclusions and other information in this e-mail 
that do not relate to the official business of JLT Risk 
Solutions Ltd shall be understood as neither given nor 
endorsed by it.  Please note we intercept and monitor 
incoming / outgoing e-mail and therefore you should neither 
expect nor intend any e-mail to be private in nature.

We have checked this e-mail for viruses and other harmful 
components and believe but not guarantee it virus-free prior 
to leaving our computer system.  However, you should satisfy 
yourself that it is free from harmful components, as we do 
not accept responsibility for any loss or damage it may 
cause to your computer systems.



From kleinn at iac.umnw.ethz.ch  Tue Sep 23 11:14:15 2003
From: kleinn at iac.umnw.ethz.ch (Jan Kleinn)
Date: Tue, 23 Sep 2003 11:14:15 +0200
Subject: [R] filled.contour without box
Message-ID: <3F700EE7.6030203@iac.umnw.ethz.ch>

Dear all,

I would like to make a filled contour plot without the box R is 
generating by default around the plotting area, i.e. I'm looking for an 
option in filled.contour similar to 'axes=F' in 'contour' or in 'plot'. 
I couldn't find any option to get rid of the box, any help is welcome.

Thanks, Jan:-)



From ligges at statistik.uni-dortmund.de  Tue Sep 23 11:23:23 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 23 Sep 2003 11:23:23 +0200
Subject: [R] Plotting of the lm
In-Reply-To: <DD42E3F5AF15D211BDA60008C7A49834050E045A@EMAIL03>
References: <DD42E3F5AF15D211BDA60008C7A49834050E045A@EMAIL03>
Message-ID: <3F70110B.1020802@statistik.uni-dortmund.de>

Melissa_Kuang at jltgroup.com wrote:

> Hi,
> 
> I would like to enquire if by typing plot (lm(y~x)) would this show me the
> plot of the fitted line? I tried this function previously but I was only
> able to get the last 4 plots starting with Residuals vs fitted. 

No, it shows plots for analyses of the residuals.

Try

  plot(x, y)
  abline(lm(y~x))

in order to see the fitted line.

Uwe Ligges



> Thank You.
> 
> Melissa
> 
> 
> ************************************************************
> JLT Risk Solutions Ltd
> 6 Crutched Friars, London EC3N 2PH. Co Reg No 1536540
> Tel: (44) (0)20 7528 4000   Fax: (44) (0)20 7528 4500
> http://www.jltgroup.com
> Lloyd's Broker.  Regulated by the General Insurance
> Standards Council
> ------------------------------------------------------------
> The content of this e-mail (including any attachments) as 
> received may not be the same as sent. If you consider that 
> the content is material to the formation or performance of 
> a contract or you are otherwise relying upon its accuracy, 
> you should consider requesting a copy be sent by facsimile 
> or normal mail.  The information in this e-mail is 
> confidential and may be legally privileged. If you are not 
> the intended recipient, please notify the sender immediately 
> and then delete this e-mail entirely - you must not retain, 
> copy, distribute or use this e-mail for any purpose or 
> disclose any of its content to others.
> 
> Opinions, conclusions and other information in this e-mail 
> that do not relate to the official business of JLT Risk 
> Solutions Ltd shall be understood as neither given nor 
> endorsed by it.  Please note we intercept and monitor 
> incoming / outgoing e-mail and therefore you should neither 
> expect nor intend any e-mail to be private in nature.
> 
> We have checked this e-mail for viruses and other harmful 
> components and believe but not guarantee it virus-free prior 
> to leaving our computer system.  However, you should satisfy 
> yourself that it is free from harmful components, as we do 
> not accept responsibility for any loss or damage it may 
> cause to your computer systems.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ligges at statistik.uni-dortmund.de  Tue Sep 23 11:30:02 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 23 Sep 2003 11:30:02 +0200
Subject: [R] filled.contour without box
In-Reply-To: <3F700EE7.6030203@iac.umnw.ethz.ch>
References: <3F700EE7.6030203@iac.umnw.ethz.ch>
Message-ID: <3F70129A.30600@statistik.uni-dortmund.de>

Jan Kleinn wrote:

> Dear all,
> 
> I would like to make a filled contour plot without the box R is 
> generating by default around the plotting area, i.e. I'm looking for an 
> option in filled.contour similar to 'axes=F' in 'contour' or in 'plot'. 
> I couldn't find any option to get rid of the box, any help is welcome.
> 
> Thanks, Jan:-)

Easy to add a corresponding feature:

  fix(filled.contour)

Now, remove the two lines including "box()".
Or even better, add an argument to turn plotting of the box on or off.

Uwe Ligges



From gavin.simpson at ucl.ac.uk  Tue Sep 23 11:41:35 2003
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Tue, 23 Sep 2003 10:41:35 +0100
Subject: [R] Plotting of the lm
In-Reply-To: <DD42E3F5AF15D211BDA60008C7A49834050E045A@EMAIL03>
References: <DD42E3F5AF15D211BDA60008C7A49834050E045A@EMAIL03>
Message-ID: <3F70154F.1020204@ucl.ac.uk>

Try this:

plot(x, y)
abline(lm(y ~ x)) #plots the fitted line

or this if you need the model results elsewhere:

mod.lm <- lm(y ~ x)   # store the model
plot(x, y)            # plot the data
abline(mod.lm)        # plot the fitted line

see ?plot.lm and ?abline

HTH

Gav

Melissa_Kuang at jltgroup.com wrote:

> Hi,
> 
> I would like to enquire if by typing plot (lm(y~x)) would this show me the
> plot of the fitted line? I tried this function previously but I was only
> able to get the last 4 plots starting with Residuals vs fitted. 
> 
> Thank You.
> 
> Melissa
> 
> 
> ************************************************************
> JLT Risk Solutions Ltd
> 6 Crutched Friars, London EC3N 2PH. Co Reg No 1536540
> Tel: (44) (0)20 7528 4000   Fax: (44) (0)20 7528 4500
> http://www.jltgroup.com
> Lloyd's Broker.  Regulated by the General Insurance
> Standards Council
> ------------------------------------------------------------
> The content of this e-mail (including any attachments) as 
> received may not be the same as sent. If you consider that 
> the content is material to the formation or performance of 
> a contract or you are otherwise relying upon its accuracy, 
> you should consider requesting a copy be sent by facsimile 
> or normal mail.  The information in this e-mail is 
> confidential and may be legally privileged. If you are not 
> the intended recipient, please notify the sender immediately 
> and then delete this e-mail entirely - you must not retain, 
> copy, distribute or use this e-mail for any purpose or 
> disclose any of its content to others.
> 
> Opinions, conclusions and other information in this e-mail 
> that do not relate to the official business of JLT Risk 
> Solutions Ltd shall be understood as neither given nor 
> endorsed by it.  Please note we intercept and monitor 
> incoming / outgoing e-mail and therefore you should neither 
> expect nor intend any e-mail to be private in nature.
> 
> We have checked this e-mail for viruses and other harmful 
> components and believe but not guarantee it virus-free prior 
> to leaving our computer system.  However, you should satisfy 
> yourself that it is free from harmful components, as we do 
> not accept responsibility for any loss or damage it may 
> cause to your computer systems.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpson at ucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From f.calboli at ucl.ac.uk  Tue Sep 23 12:47:57 2003
From: f.calboli at ucl.ac.uk (Federico Calboli)
Date: Tue, 23 Sep 2003 10:47:57 -0000
Subject: [R] problems installing Design and Hmisc libs
Message-ID: <1064314041.2739.18.camel@monkey>

Dear All,

when I try to:

install.packages("Design"); install.packages("Hmisc") 

I get the following error messages:

* Installing *source* package 'Design' ...
** libs
g77 -mieee-fp  -O2 -fomit-frame-pointer -pipe -march=i586
-mcpu=pentiumpro  -O2 -fomit-frame-pointer -pipe -march=i586
-mcpu=pentiumpro -c lrmfit.f -o lrmfit.o
make: g77: Command not found
make: *** [lrmfit.o] Error 127
ERROR: compilation failed for package 'Design'

* Installing *source* package 'Hmisc' ...
** libs
g77 -mieee-fp  -O2 -fomit-frame-pointer -pipe -march=i586
-mcpu=pentiumpro  -O2 -fomit-frame-pointer -pipe -march=i586
-mcpu=pentiumpro -c cidxcn.f -o cidxcn.o
make: g77: Command not found
make: *** [cidxcn.o] Error 127
ERROR: compilation failed for package 'Hmisc'

The connection to CRAN and the download are fine though.

I am using R 1.7.1 under Mandrake Linux 9.1. My C compiler is gcc 3.2.2.

Any idea how to install the packages?

Regads,

Federico

-- 



=================================

Federico C. F. Calboli

Department of Biology
University College London
Darwin Building 
Gower Street
London
WC1E 6BT

tel: 020 7679 4395
fax: 020 7679 7096

f.calboli at ucl.ac.uk



From ligges at statistik.uni-dortmund.de  Tue Sep 23 13:08:43 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 23 Sep 2003 13:08:43 +0200
Subject: [R] problems installing Design and Hmisc libs
In-Reply-To: <1064314041.2739.18.camel@monkey>
References: <1064314041.2739.18.camel@monkey>
Message-ID: <3F7029BB.2010409@statistik.uni-dortmund.de>

Federico Calboli wrote:

> Dear All,
> 
> when I try to:
> 
> install.packages("Design"); install.packages("Hmisc") 
> 
> I get the following error messages:
> 
> * Installing *source* package 'Design' ...
> ** libs
> g77 -mieee-fp  -O2 -fomit-frame-pointer -pipe -march=i586
> -mcpu=pentiumpro  -O2 -fomit-frame-pointer -pipe -march=i586
> -mcpu=pentiumpro -c lrmfit.f -o lrmfit.o
> make: g77: Command not found
> make: *** [lrmfit.o] Error 127
> ERROR: compilation failed for package 'Design'
> 
> * Installing *source* package 'Hmisc' ...
> ** libs
> g77 -mieee-fp  -O2 -fomit-frame-pointer -pipe -march=i586
> -mcpu=pentiumpro  -O2 -fomit-frame-pointer -pipe -march=i586
> -mcpu=pentiumpro -c cidxcn.f -o cidxcn.o
> make: g77: Command not found
> make: *** [cidxcn.o] Error 127
> ERROR: compilation failed for package 'Hmisc'
> 
> The connection to CRAN and the download are fine though.
> 
> I am using R 1.7.1 under Mandrake Linux 9.1. My C compiler is gcc 3.2.2.

You need the Fortran compiler (g77) as well (as indicated by the error 
message).  Is it installed? Is it in your path?

Uwe Ligges


> Any idea how to install the packages?
> 
> Regads,
> 
> Federico
>



From Giles.Heywood at CommerzbankIB.com  Tue Sep 23 13:15:45 2003
From: Giles.Heywood at CommerzbankIB.com (Heywood, Giles)
Date: Tue, 23 Sep 2003 12:15:45 +0100
Subject: [R] Date on x-axis of xyplot
Message-ID: <8CBAA121CEB4D5118CB200508BB2BBEF5404A9@xmx8lonib.lonib.commerzbank.com>

One thing you could do is to use the 'its' (irregular time-series) 
package on CRAN.

e.g. using a trivial dataset

require(its)
its.format("%Y-%m-%d") #defines text format of dates in dimnames
df <- data.frame(1:3,(1:3)^2)
dimnames(df) <- list(c("2003-01-03","2003-01-06","2003-01-07"),letters[1:2])
plot(its(as.matrix(df)),type="p")

or more simply

mat <-
structure(1:6,dim=c(3,2),dimnames=list(c("2003-01-03","2003-01-06","2003-01-
07"),letters[1:2]))
plot(its(mat),type="p")

Clearly plot does not provide the same functionality as the 
beautifully crafted xyplot of lattice, but dates do get handled
as an abcissa. Incidentally the implementation of 'its' uses the 
POSIXct class, but this is largely encapsulated.

Giles

> -----Original Message-----
> From: Charles H. Franklin [mailto:franklin at polisci.wisc.edu]
> Sent: 17 September 2003 04:00
> To: r-help at stat.math.ethz.ch
> Subject: [R] Date on x-axis of xyplot
> 
> 
> xyplot doesn't seem to want to label my x-axis with dates but 
> instead puts
> the day-number for each date.
> 
> begdate is the number of days since January 1, 1960 and was initially
> created by
> 
> library(date)
> 
> ...
> 
> polls$begdate<-mdy.date(begmm,begdd,begyy)
> 
> I create a new dataframe (pollstack) which includes begdate. 
> In the process
> begdate seems to lose its date attribute so I redo it as:
> 
> > pollstack$begdate<-as.date(pollstack$begdate)
> 
> after which
> 
> > attach(pollstack)
> > summary(pollstack)
>    begdate               pct              names
>  First :15Nov2002   Min.   : 0.000   Clark   : 54
>  Last  :10Sep2003   1st Qu.: 2.000   Dean    : 54
>                     Median : 5.000   Edwards : 54
>                     Mean   : 6.991   Gephardt: 54
>                     3rd Qu.:12.000   Graham  : 54
>                     Max.   :29.000   Kerry   : 54
>                                      (Other) :216
> >
> 
> And all seems well.
> 
> But xyplot continues to use day number on the x-axis. My 
> plots are created
> by
> 
>  print(xyplot(pct ~ begdate | names, pch=2, cex=.2,
>    prepanel = function(x, y) prepanel.loess(x, y, span = 1),
>    main="2004 Democratic Primary Race",
>    xlab = "Date of Survey",
>    ylab = "Percent Support",
>    panel = function(x, y) {
>        panel.grid(h=-1, v= -1)
>        panel.xyplot(x, y, pch=1,col=2,cex=.7)
>        panel.loess(x,y, span=.65, lwd=2,col=4)
>       }, ) )
> 
> What am I missing?
> 
> Thanks!
> 
> Charles
> 
> 
> 
> /******************************************
> ** Charles H. Franklin
> ** Professor, Political Science
> ** University of Wisconsin, Madison
> ** 1050 Bascom Mall
> ** Madison, WI 53706
> ** 608-263-2022 Office
> ** 608-265-2663 Fax
> ** mailto:franklin at polisci.wisc.edu (best)
> ** mailto:chfrankl at facstaff.wisc.edu (alt)
> ** http://www.polisci.wisc.edu/~franklin
> ******************************************/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


********************************************************************** 
This is a commercial communication from Commerzbank AG.\ \ T...{{dropped}}



From f.calboli at ucl.ac.uk  Tue Sep 23 13:28:37 2003
From: f.calboli at ucl.ac.uk (Federico Calboli)
Date: Tue, 23 Sep 2003 11:28:37 -0000
Subject: [R] problems installing Design and Hmisc libs
In-Reply-To: <3F7029BB.2010409@statistik.uni-dortmund.de>
References: <1064314041.2739.18.camel@monkey>
	<3F7029BB.2010409@statistik.uni-dortmund.de>
Message-ID: <1064316561.2739.21.camel@monkey>


> You need the Fortran compiler (g77) as well (as indicated by the error 
> message).  Is it installed? Is it in your path?
> 
> Uwe Ligges
> 
It was not installed. Now everything works.

Cheers,
Federico

-- 



=================================

Federico C. F. Calboli

Department of Biology
University College London
Darwin Building 
Gower Street
London
WC1E 6BT

tel: 020 7679 4395
fax: 020 7679 7096

f.calboli at ucl.ac.uk



From jdb33 at hermes.cam.ac.uk  Tue Sep 23 13:50:43 2003
From: jdb33 at hermes.cam.ac.uk (James Brown)
Date: Tue, 23 Sep 2003 12:50:43 +0100 (BST)
Subject: [R] Rank and extract data from a series
In-Reply-To: <200309102323.QAA03906@hivnet.ubc.ca>
Message-ID: <Pine.SOL.4.44.0309231233080.12972-100000@red.csi.cam.ac.uk>


I would like to rank a time-series of data, extract the top ten data items
from this series, determine the corresponding row numbers for each value
in the sample, and take a mean of these *row numbers* (not the data).

I would like to do this in R, rather than pre-process the data on the
UNIX command line if possible, as I need to calculate other statistics
for the series.

I understand that I can use 'sort' to order the data, but I am not aware
of a function in R that would allow me to extract a given number of these
data and then determine their positions within the original time series.

e.g.

Time series:

1.0 (row 1)
4.5 (row 2)
2.3 (row 3)
1.0 (row 4)
7.3 (row 5)

Sort would give me:

1.0
1.0
2.3
4.5
7.3

I would then like to extract the top two data items:

4.5
7.3

and determine their positions within the original (unsorted) time series:

4.5 = row 2
7.3 = row 5

then take a mean:

2 and 5 = 3.5

Thanks in advance.

James Brown

___________________________________________

James Brown

Cambridge Coastal Research Unit (CCRU)
Department of Geography
University of Cambridge
Downing Place
Cambridge
CB2 3EN, UK

Telephone: +44 (0)1223 339776
Mobile: 07929 817546
Fax: +44 (0)1223 355674

E-mail: jdb33 at cam.ac.uk
E-mail: james_510 at hotmail.com

http://www.geog.cam.ac.uk/ccru/CCRU.html
___________________________________________






On Wed, 10 Sep 2003, Jerome Asselin wrote:

> On September 10, 2003 04:03 pm, Kevin S. Van Horn wrote:
> >
> > Your method looks like a naive reimplementation of integration, and
> > won't work so well for distributions that have the great majority of the
> > probability mass concentrated in a small fraction of the sample space.
> >  I was hoping for something that would retain the adaptability of
> > integrate().
>
> Yesterday, I've suggested to use approxfun(). Did you consider my
> suggestion? Below is an example.
>
> N <- 500
> x <- rexp(N)
> y <- rank(x)/(N+1)
> empCDF <- approxfun(x,y)
> xvals <- seq(0,4,.01)
> plot(xvals,empCDF(xvals),type="l",
> xlab="Quantile",ylab="Cumulative Distribution Function")
> lines(xvals,pexp(xvals),lty=2)
> legend(2,.4,c("Empirical CDF","Exact CDF"),lty=1:2)
>
>
> It's possible to tune in some parameters in approxfun() to better match
> your personal preferences. Have a look at help(approxfun) for details.
>
> HTH,
> Jerome Asselin
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From andy_liaw at merck.com  Tue Sep 23 14:09:07 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 23 Sep 2003 08:09:07 -0400
Subject: [R] R-project  [.com?] [.net?]
Message-ID: <3A822319EB35174CA3714066D590DCD50205CB7E@usrymx25.merck.com>

> From: Murray Jorgensen [mailto:maj at stats.waikato.ac.nz] 
> 
> I got a shock a few days ago when I accidentally visited 
> www.r-project.com . I thought that the r-project site had been hacked 

This one seems to be about some sort of city revival projects in Japan.
(The introduction starts with "Recycle, Redesign, Rethink, Refine, Restore,
Recreation...".  I can't read Japanese, but just guessing from the Chinese
characters that were sprinkled in the text.

> until I realised my mistake. There is also a site www.r-project.net. 

No indication what this is about.  Seems to say the site is still under
construction.

Andy

> Both of these sites appear to be Japanese. Does anyone know anything 
> about them? I suppose that it is not unusual for names close 
> to those of 
> popular sites to be used. It is good that they use a 
> different language 
> or there might well be confusion.
> 
> Murray
> 
> -- 
> Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
> Department of Statistics, University of Waikato, Hamilton, New Zealand
> Email: maj at waikato.ac.nz                                Fax 7 838 4155
> Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
>



From andy_liaw at merck.com  Tue Sep 23 14:13:59 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 23 Sep 2003 08:13:59 -0400
Subject: [R] Rank and extract data from a series
Message-ID: <3A822319EB35174CA3714066D590DCD50205CB7F@usrymx25.merck.com>

Here's one way.  Suppose your "time series" is in a vector called "x".

top10 <- sort(x, decreasing=TRUE)[1:10]
mean.index <- mean(which(x %in% top10))

HTH,
Andy

> -----Original Message-----
> From: James Brown [mailto:jdb33 at hermes.cam.ac.uk] 
> Sent: Tuesday, September 23, 2003 7:51 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Rank and extract data from a series
> 
> 
> 
> I would like to rank a time-series of data, extract the top 
> ten data items from this series, determine the corresponding 
> row numbers for each value in the sample, and take a mean of 
> these *row numbers* (not the data).
> 
> I would like to do this in R, rather than pre-process the 
> data on the UNIX command line if possible, as I need to 
> calculate other statistics for the series.
> 
> I understand that I can use 'sort' to order the data, but I 
> am not aware of a function in R that would allow me to 
> extract a given number of these data and then determine their 
> positions within the original time series.
> 
> e.g.
> 
> Time series:
> 
> 1.0 (row 1)
> 4.5 (row 2)
> 2.3 (row 3)
> 1.0 (row 4)
> 7.3 (row 5)
> 
> Sort would give me:
> 
> 1.0
> 1.0
> 2.3
> 4.5
> 7.3
> 
> I would then like to extract the top two data items:
> 
> 4.5
> 7.3
> 
> and determine their positions within the original (unsorted) 
> time series:
> 
> 4.5 = row 2
> 7.3 = row 5
> 
> then take a mean:
> 
> 2 and 5 = 3.5
> 
> Thanks in advance.
> 
> James Brown
> 
> ___________________________________________
> 
> James Brown
> 
> Cambridge Coastal Research Unit (CCRU)
> Department of Geography
> University of Cambridge
> Downing Place
> Cambridge
> CB2 3EN, UK
> 
> Telephone: +44 (0)1223 339776
> Mobile: 07929 817546
> Fax: +44 (0)1223 355674
> 
> E-mail: jdb33 at cam.ac.uk
> E-mail: james_510 at hotmail.com
> 
> http://www.geog.cam.ac.uk/ccru/CCRU.html
> ___________________________________________
> 
> 
> 
> 
> 
> 
> On Wed, 10 Sep 2003, Jerome Asselin wrote:
> 
> > On September 10, 2003 04:03 pm, Kevin S. Van Horn wrote:
> > >
> > > Your method looks like a naive reimplementation of 
> integration, and 
> > > won't work so well for distributions that have the great 
> majority of 
> > > the probability mass concentrated in a small fraction of 
> the sample 
> > > space.  I was hoping for something that would retain the 
> > > adaptability of integrate().
> >
> > Yesterday, I've suggested to use approxfun(). Did you consider my 
> > suggestion? Below is an example.
> >
> > N <- 500
> > x <- rexp(N)
> > y <- rank(x)/(N+1)
> > empCDF <- approxfun(x,y)
> > xvals <- seq(0,4,.01)
> > plot(xvals,empCDF(xvals),type="l",
> > xlab="Quantile",ylab="Cumulative Distribution Function")
> > lines(xvals,pexp(xvals),lty=2)
> > legend(2,.4,c("Empirical CDF","Exact CDF"),lty=1:2)
> >
> >
> > It's possible to tune in some parameters in approxfun() to better 
> > match your personal preferences. Have a look at help(approxfun) for 
> > details.
> >
> > HTH,
> > Jerome Asselin
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list 
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
>



From uth at zhwin.ch  Tue Sep 23 14:23:48 2003
From: uth at zhwin.ch (=?iso-8859-1?Q?=22Untern=E4hrer_Thomas=2C_uth=22?=)
Date: Tue, 23 Sep 2003 14:23:48 +0200
Subject: AW: [R] Rank and extract data from a series
Message-ID: <53A181E56FB0694ABFD212F8AEDA7F6F1AB88D@langouste.zhwin.ch>


Hi,



>I would like to rank a time-series of data, extract the top ten data items from this series, determine the 
>corresponding row numbers for each value in the sample, and take a mean of these *row numbers* (not the data).

>I would like to do this in R, rather than pre-process the data on the UNIX command line if possible, as I need to >calculate other statistics for the series.

>I understand that I can use 'sort' to order the data, but I am not aware of a function in R that would allow me 
>to extract a given number of these data and then determine their positions within the original time series.

>e.g.

>Time series:

>1.0 (row 1)
>4.5 (row 2)
>2.3 (row 3)
>1.0 (row 4)
>7.3 (row 5)

>Sort would give me:

>1.0
>1.0
>2.3
>4.5
>7.3

>I would then like to extract the top two data items:

>4.5
>7.3

>and determine their positions within the original (unsorted) time series:

>4.5 = row 2
>7.3 = row 5

>then take a mean:

>2 and 5 = 3.5

>Thanks in advance.

>James Brown

X <- c(1, 4.5, 2.3, 1, 7.3)
X1 <- sort(X, decreasing=TRUE)[1:2]
X2 <- match(X1, X)
mean(X2)



Hope this helps

Thomas


___________________________________________

James Brown

Cambridge Coastal Research Unit (CCRU)
Department of Geography
University of Cambridge
Downing Place
Cambridge
CB2 3EN, UK

Telephone: +44 (0)1223 339776
Mobile: 07929 817546
Fax: +44 (0)1223 355674

E-mail: jdb33 at cam.ac.uk
E-mail: james_510 at hotmail.com

http://www.geog.cam.ac.uk/ccru/CCRU.html
___________________________________________






On Wed, 10 Sep 2003, Jerome Asselin wrote:

> On September 10, 2003 04:03 pm, Kevin S. Van Horn wrote:
> >
> > Your method looks like a naive reimplementation of integration, and 
> > won't work so well for distributions that have the great majority of 
> > the probability mass concentrated in a small fraction of the sample 
> > space.  I was hoping for something that would retain the 
> > adaptability of integrate().
>
> Yesterday, I've suggested to use approxfun(). Did you consider my 
> suggestion? Below is an example.
>
> N <- 500
> x <- rexp(N)
> y <- rank(x)/(N+1)
> empCDF <- approxfun(x,y)
> xvals <- seq(0,4,.01)
> plot(xvals,empCDF(xvals),type="l",
> xlab="Quantile",ylab="Cumulative Distribution Function")
> lines(xvals,pexp(xvals),lty=2)
> legend(2,.4,c("Empirical CDF","Exact CDF"),lty=1:2)
>
>
> It's possible to tune in some parameters in approxfun() to better 
> match your personal preferences. Have a look at help(approxfun) for 
> details.
>
> HTH,
> Jerome Asselin
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

______________________________________________
R-help at stat.math.ethz.ch mailing list https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From scott1917 at yahoo.com  Tue Sep 23 15:22:19 2003
From: scott1917 at yahoo.com (scott1917@yahoo.com)
Date: Tue, 23 Sep 2003 06:22:19 -0700 (PDT)
Subject: [R] Marginal Means with the lme()
Message-ID: <20030923132219.83171.qmail@web40508.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030923/22f7e995/attachment.pl

From rpeng at jhsph.edu  Tue Sep 23 15:37:45 2003
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Tue, 23 Sep 2003 09:37:45 -0400
Subject: [R] filled.contour without box
In-Reply-To: <3F70129A.30600@statistik.uni-dortmund.de>
References: <3F700EE7.6030203@iac.umnw.ethz.ch>
	<3F70129A.30600@statistik.uni-dortmund.de>
Message-ID: <3F704CA9.6080909@jhsph.edu>

If you just want to get rid of the axes, you can do

filled.contour(x, plot.axes = { })

-roger

Uwe Ligges wrote:

> Jan Kleinn wrote:
>
>> Dear all,
>>
>> I would like to make a filled contour plot without the box R is 
>> generating by default around the plotting area, i.e. I'm looking for 
>> an option in filled.contour similar to 'axes=F' in 'contour' or in 
>> 'plot'. I couldn't find any option to get rid of the box, any help is 
>> welcome.
>>
>> Thanks, Jan:-)
>
>
> Easy to add a corresponding feature:
>
>  fix(filled.contour)
>
> Now, remove the two lines including "box()".
> Or even better, add an argument to turn plotting of the box on or off.
>
> Uwe Ligges
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From tlumley at u.washington.edu  Tue Sep 23 16:07:09 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 23 Sep 2003 07:07:09 -0700 (PDT)
Subject: [R] what does the sum of square of Gaussian RVs with different
	variance obey?
In-Reply-To: <20030923024119.5EF1B33FA5@smtp.263.net>
References: <20030923024119.5EF1B33FA5@smtp.263.net>
Message-ID: <Pine.A41.4.58.0309230705500.156122@homer11.u.washington.edu>

On Tue, 23 Sep 2003, Jean Sun wrote:

> >From basic statistics principle,we know,given several i.i.d Gaussian
> >RVs with zero or nonzero mean,the sum of square of them is a central or
> >noncentral Chi-distributed RV.However if these Gaussian RVs have
> >different variances,what does the sum of square of them obey?
>

Nothing very useful.  It's a mixture of chisquare(1) variables. One
standard approach is to approximate it by a multiple of a chisquared
distribution that has the correct mean and variance.

	-thomas



From tlumley at u.washington.edu  Tue Sep 23 16:11:43 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 23 Sep 2003 07:11:43 -0700 (PDT)
Subject: [R] problems installing Design and Hmisc libs
In-Reply-To: <1064314041.2739.18.camel@monkey>
References: <1064314041.2739.18.camel@monkey>
Message-ID: <Pine.A41.4.58.0309230710200.156122@homer11.u.washington.edu>

On Tue, 23 Sep 2003, Federico Calboli wrote:

> Dear All,
>
> when I try to:
>
> install.packages("Design"); install.packages("Hmisc")
>
> I get the following error messages:
>
> * Installing *source* package 'Design' ...
> ** libs
> g77 -mieee-fp  -O2 -fomit-frame-pointer -pipe -march=i586
> -mcpu=pentiumpro  -O2 -fomit-frame-pointer -pipe -march=i586
> -mcpu=pentiumpro -c lrmfit.f -o lrmfit.o
> make: g77: Command not found
> make: *** [lrmfit.o] Error 127
> ERROR: compilation failed for package 'Design'
>
> * Installing *source* package 'Hmisc' ...
> ** libs
> g77 -mieee-fp  -O2 -fomit-frame-pointer -pipe -march=i586
> -mcpu=pentiumpro  -O2 -fomit-frame-pointer -pipe -march=i586
> -mcpu=pentiumpro -c cidxcn.f -o cidxcn.o
> make: g77: Command not found
> make: *** [cidxcn.o] Error 127
> ERROR: compilation failed for package 'Hmisc'
>
> The connection to CRAN and the download are fine though.
>
> I am using R 1.7.1 under Mandrake Linux 9.1. My C compiler is gcc 3.2.2.
>
> Any idea how to install the packages?


You need a Fortran compiler, such as g77.

If you have g77 then it looks like it has moved since you compiled R.  If
you don't, then you presumably installed R binaries, and you need g77.


	-thomas



From shott at csbs.csbs.uni.edu  Tue Sep 23 16:38:16 2003
From: shott at csbs.csbs.uni.edu (Michael Shott)
Date: Tue, 23 Sep 2003 09:38:16 -0500
Subject: [R] (Fwd) Re: goodfit macro
Message-ID: <3F701487.15450.55AA5CD@localhost>

Dear R-Help:

As you can see, Prof. Friendly refers me to your site for an 
executable version of vcd.  I don't mean to be obtuse, but 15 minutes 
spent exploring your site failed to locate a downloadable version of the 
vcd package to which he referred.

I know plainly what this application can do.  What I need to know is 
how to obtain the application itself.

My thanks in advance for any help you can provide.

MS



------- Forwarded message follows -------
Date sent:      	Tue, 23 Sep 2003 09:14:28 -0400
From:           	Michael Friendly <friendly at yorku.ca>
Subject:        	Re: goodfit macro
To:             	shott at csbs.csbs.uni.edu
Send reply to:  	friendly at yorku.ca
Organization:   	York University

You can also carry out goodness of fit tests using the function goodfit 
in the vcd package
for R (a free version of S/Splus),
http://www.r-project.org

-Michael

Michael Shott wrote:

>Dear Michael:
>
>Recently I searched the web for guidance in gauging the goodness-of-
>fit of frequency data to statistical models.  Your website came up in 
>virtually every combination of keywords searched in Google.  The site 
>describes the goodfit.sas macro, which seems to do exactly what I'd 
>like.  But it seems to be available only as a .sas file.  Do you have 
>some application file that can be downloaded and used?
>
>I ask because I'd like to analyze some archaeological data.  They are 
>frequency distributions of the number of a particular artifact type by 
>site.  That is, x sites may have 1 occurrence, y sites may have 2 
>occurrences, z sites 3 occurrences and so on.  Your goodfit macro 
>seems to do the job, but I can't execute it from the .sas version that 
>appears on your website's ftp link.
>
>Thanks for any help that you can provide.
>
>Best,
>
>Mike Shott
>
>Michael J. Shott
>Professor
>Dept. of Sociology, Anthropology & Criminology
>University of Northern Iowa
>Cedar Falls, IA 50614-0513
>319/273-7337
>  
>


-- 
Michael Friendly     Email: friendly at yorku.ca 
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA


------- End of forwarded message -------
Michael J. Shott
Professor
Dept. of Sociology, Anthropology & Criminology
University of Northern Iowa
Cedar Falls, IA 50614-0513
319/273-7337



From jlopez0 at unalmed.edu.co  Tue Sep 23 16:37:44 2003
From: jlopez0 at unalmed.edu.co (Jaime Lopez Carvajal)
Date: Tue, 23 Sep 2003 09:37:44 -0500
Subject: [R] discretization method
Message-ID: <439a443bf1.43bf1439a4@unalmed.edu.co>

Hi R users

I need to apply discretization  to my continuous data.
Is there a method in R to do this?

Thanks in advance,

Jaime

From bolker at zoo.ufl.edu  Tue Sep 23 16:53:06 2003
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Tue, 23 Sep 2003 10:53:06 -0400 (EDT)
Subject: [R] discretization method
In-Reply-To: <439a443bf1.43bf1439a4@unalmed.edu.co>
Message-ID: <Pine.LNX.4.44.0309231052410.20538-100000@bolker.zoo.ufl.edu>


Consider:

 ?cut
 ?round

  With more detail we might be able to help more ...

On Tue, 23 Sep 2003, Jaime Lopez Carvajal wrote:

> Hi R users
> 
> I need to apply discretization  to my continuous data.
> Is there a method in R to do this?
> 
> Thanks in advance,
> 
> Jaime
> 

-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From tblackw at umich.edu  Tue Sep 23 16:47:22 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Tue, 23 Sep 2003 10:47:22 -0400 (EDT)
Subject: [R] discretization method
In-Reply-To: <439a443bf1.43bf1439a4@unalmed.edu.co>
References: <439a443bf1.43bf1439a4@unalmed.edu.co>
Message-ID: <Pine.SOL.4.58.0309231046150.15284@rygar.gpcc.itd.umich.edu>

On Tue, 23 Sep 2003, Jaime Lopez Carvajal wrote:

> I need to apply discretization  to my continuous data.
> Is there a method in R to do this?

See  help("cut").

-  tom blackwell  -  u michigan medical school  -  ann arbor  -



From Giovanni_Millo at generali.com  Tue Sep 23 17:06:12 2003
From: Giovanni_Millo at generali.com (Millo Giovanni)
Date: Tue, 23 Sep 2003 17:06:12 +0200
Subject: [R] loops in Sweave
Message-ID: <74F2D4ED68558643B63A6CC21746040D01A07302@BEMAILEXTS1.ad.generali.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030923/9048f251/attachment.pl

From SchnitzlerJ at rki.de  Tue Sep 23 17:10:46 2003
From: SchnitzlerJ at rki.de (Schnitzler, Johannes)
Date: Tue, 23 Sep 2003 17:10:46 +0200
Subject: AW: [R] weighted standard deviation
Message-ID: <3DDCC4D685EE744B9FB47706995CFCD1037C23BD@SEMAIL01.RKI.IVBB.BUND.DE>

Thank you all for the reply,

the Hmisc library is exactly what i was looking for.

Johannes



From RBaskin at ahrq.gov  Tue Sep 23 17:07:55 2003
From: RBaskin at ahrq.gov (RBaskin@ahrq.gov)
Date: Tue, 23 Sep 2003 11:07:55 -0400
Subject: [R] what does the sum of square of Gaussian RVs with differen
	t variance obey?
Message-ID: <3598558AD728D41183350008C7CF291C0F16B938@exchange1.ahrq.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030923/9e6e188b/attachment.pl

From zeileis at ci.tuwien.ac.at  Tue Sep 23 17:26:28 2003
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Tue, 23 Sep 2003 17:26:28 +0200
Subject: [R] (Fwd) Re: goodfit macro
In-Reply-To: <3F701487.15450.55AA5CD@localhost>
References: <3F701487.15450.55AA5CD@localhost>
Message-ID: <200309231526.h8NFQSIX026309@thorin.ci.tuwien.ac.at>

On Tuesday 23 September 2003 16:38, Michael Shott wrote:

> Dear R-Help:
>
> As you can see, Prof. Friendly refers me to your site for an
> executable version of vcd.  I don't mean to be obtuse, but 15
> minutes spent exploring your site failed to locate a downloadable
> version of the vcd package to which he referred.
>
> I know plainly what this application can do.  What I need to know is
> how to obtain the application itself.

Michael,

you need to install the R system first and then the add-on package vcd.
If you look at 
  http://www.R-project.org/
there are some manuals and the FAQ which will tell you how to obtain 
and install R on your operating system. Having done that you can 
install the package "vcd" which is also covered in the documentation I 
mentioned above.
Both R itself and the vcd package can be downloaded from
  http://CRAN.R-project.org/

HTH,
Z

> My thanks in advance for any help you can provide.
>
> MS
>
>
>
> ------- Forwarded message follows -------
> Date sent:      	Tue, 23 Sep 2003 09:14:28 -0400
> From:           	Michael Friendly <friendly at yorku.ca>
> Subject:        	Re: goodfit macro
> To:             	shott at csbs.csbs.uni.edu
> Send reply to:  	friendly at yorku.ca
> Organization:   	York University
>
> You can also carry out goodness of fit tests using the function
> goodfit in the vcd package
> for R (a free version of S/Splus),
> http://www.r-project.org
>
> -Michael
>
> Michael Shott wrote:
> >Dear Michael:
> >
> >Recently I searched the web for guidance in gauging the
> > goodness-of- fit of frequency data to statistical models.  Your
> > website came up in virtually every combination of keywords
> > searched in Google.  The site describes the goodfit.sas macro,
> > which seems to do exactly what I'd like.  But it seems to be
> > available only as a .sas file.  Do you have some application file
> > that can be downloaded and used?
> >
> >I ask because I'd like to analyze some archaeological data.  They
> > are frequency distributions of the number of a particular artifact
> > type by site.  That is, x sites may have 1 occurrence, y sites may
> > have 2 occurrences, z sites 3 occurrences and so on.  Your goodfit
> > macro seems to do the job, but I can't execute it from the .sas
> > version that appears on your website's ftp link.
> >
> >Thanks for any help that you can provide.
> >
> >Best,
> >
> >Mike Shott
> >
> >Michael J. Shott
> >Professor
> >Dept. of Sociology, Anthropology & Criminology
> >University of Northern Iowa
> >Cedar Falls, IA 50614-0513
> >319/273-7337



From ligges at statistik.uni-dortmund.de  Tue Sep 23 17:29:42 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 23 Sep 2003 17:29:42 +0200
Subject: [R] (Fwd) Re: goodfit macro
In-Reply-To: <3F701487.15450.55AA5CD@localhost>
References: <3F701487.15450.55AA5CD@localhost>
Message-ID: <3F7066E6.3050706@statistik.uni-dortmund.de>

Michael Shott wrote:

> Dear R-Help:
> 
> As you can see, Prof. Friendly refers me to your site for an 
> executable version of vcd.  I don't mean to be obtuse, but 15 minutes 
> spent exploring your site failed to locate a downloadable version of the 
> vcd package to which he referred.
> 
> I know plainly what this application can do.  What I need to know is 
> how to obtain the application itself.
> 
> My thanks in advance for any help you can provide.
> 
> MS


Well, vcd is a contributed package, not a stand-alone executable.
At first, you need to intstall R, after that, just type
   install.packages("vcd")
if you are connected to the internet, and the package will be installed.
Then, you can use the function:
   library(vcd)
   goodfit(.....)

But you will need to learn some basics of R at first, e.g. from "An 
Introduction to R" (a manual that comes with R), in order to import your 
data etc.

Uwe Ligges



> 
> 
> ------- Forwarded message follows -------
> Date sent:      	Tue, 23 Sep 2003 09:14:28 -0400
> From:           	Michael Friendly <friendly at yorku.ca>
> Subject:        	Re: goodfit macro
> To:             	shott at csbs.csbs.uni.edu
> Send reply to:  	friendly at yorku.ca
> Organization:   	York University
> 
> You can also carry out goodness of fit tests using the function goodfit 
> in the vcd package
> for R (a free version of S/Splus),
> http://www.r-project.org
> 
> -Michael
> 
> Michael Shott wrote:
> 
> 
>>Dear Michael:
>>
>>Recently I searched the web for guidance in gauging the goodness-of-
>>fit of frequency data to statistical models.  Your website came up in 
>>virtually every combination of keywords searched in Google.  The site 
>>describes the goodfit.sas macro, which seems to do exactly what I'd 
>>like.  But it seems to be available only as a .sas file.  Do you have 
>>some application file that can be downloaded and used?
>>
>>I ask because I'd like to analyze some archaeological data.  They are 
>>frequency distributions of the number of a particular artifact type by 
>>site.  That is, x sites may have 1 occurrence, y sites may have 2 
>>occurrences, z sites 3 occurrences and so on.  Your goodfit macro 
>>seems to do the job, but I can't execute it from the .sas version that 
>>appears on your website's ftp link.
>>
>>Thanks for any help that you can provide.
>>
>>Best,
>>
>>Mike Shott
>>
>>Michael J. Shott
>>Professor
>>Dept. of Sociology, Anthropology & Criminology
>>University of Northern Iowa
>>Cedar Falls, IA 50614-0513
>>319/273-7337
>> 
>>
> 
> 
>



From maechler at stat.math.ethz.ch  Tue Sep 23 18:01:17 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 23 Sep 2003 18:01:17 +0200
Subject: [R] filled.contour without box
In-Reply-To: <3F70129A.30600@statistik.uni-dortmund.de>
References: <3F700EE7.6030203@iac.umnw.ethz.ch>
	<3F70129A.30600@statistik.uni-dortmund.de>
Message-ID: <16240.28237.513687.643051@gargle.gargle.HOWL>

>>>>> "UweL" == Uwe Ligges <ligges at statistik.uni-dortmund.de>
>>>>>     on Tue, 23 Sep 2003 11:30:02 +0200 writes:

    UweL> Jan Kleinn wrote:
    >> Dear all,
    >> 
    >> I would like to make a filled contour plot without the
    >> box R is generating by default around the plotting area,
    >> i.e. I'm looking for an option in filled.contour similar
    >> to 'axes=F' in 'contour' or in 'plot'.  I couldn't find
    >> any option to get rid of the box, any help is welcome.
    >> 
    >> Thanks, Jan:-)

[ filled.contour()  does have an `axes = FALSE' option but that
  eliminates axes both on the image _and_ on the key/legend.

  As Roger Peng has just noted you can get rid of the axes of
  the image alone, using  `plot.axes = {}',
  however as you say, it's the box, not the axes you want to get
  rid of
]
  
    UweL> Easy to add a corresponding feature:

    UweL>   fix(filled.contour)

    UweL> Now, remove the two lines including "box()".  Or even
    UweL> better, add an argument to turn plotting of the box on
    UweL> or off.

R-1.8.0  will also have an argument  'frame.plot'
which can be set to FALSE to eliminate the box around the plot.
Note that it does not eliminate the box around the legend.
Since I think this is hardly desired this is still not an option
of the future filled.contour().

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From Melissa_Kuang at jltgroup.com  Tue Sep 23 18:17:31 2003
From: Melissa_Kuang at jltgroup.com (Melissa_Kuang@jltgroup.com)
Date: Tue, 23 Sep 2003 17:17:31 +0100
Subject: [R] How to extract data from Excel
Message-ID: <DD42E3F5AF15D211BDA60008C7A49834050E0460@EMAIL03>

Hi,

I would like to know how to extract the data from Excel Spreadsheet.

Thank you very much.

Melissa


************************************************************
JLT Risk Solutions Ltd
6 Crutched Friars, London EC3N 2PH. Co Reg No 1536540
Tel: (44) (0)20 7528 4000   Fax: (44) (0)20 7528 4500
http://www.jltgroup.com
Lloyd's Broker.  Regulated by the General Insurance
Standards Council
------------------------------------------------------------
The content of this e-mail (including any attachments) as\ r...{{dropped}}



From ligges at statistik.uni-dortmund.de  Tue Sep 23 18:42:34 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 23 Sep 2003 18:42:34 +0200
Subject: [R] How to extract data from Excel
In-Reply-To: <DD42E3F5AF15D211BDA60008C7A49834050E0460@EMAIL03>
References: <DD42E3F5AF15D211BDA60008C7A49834050E0460@EMAIL03>
Message-ID: <3F7077FA.6080607@statistik.uni-dortmund.de>

Melissa_Kuang at jltgroup.com wrote:

> Hi,
> 
> I would like to know how to extract the data from Excel Spreadsheet.

I would like to know whether you have read the manual "R Data 
Import/Export" before having posted the question. It tells about you 
more than one way.

Uwe Ligges


> Thank you very much.
> 
> Melissa



From edgar at cs.uprm.edu  Tue Sep 23 18:25:02 2003
From: edgar at cs.uprm.edu (Edgar Acuna)
Date: Tue, 23 Sep 2003 12:25:02 -0400 (EDT)
Subject: [R] discretization method
In-Reply-To: <439a443bf1.43bf1439a4@unalmed.edu.co>
Message-ID: <Pine.GSO.4.33.0309231223230.20643-100000@cs.uprm.edu>

there are plenty of discretization methods, which one are you looking for?
(In Spanish
hay bastantes metodos de discretizacion cual de ellos estas busacando?
Regards (saludos)
Edgar Acuna

On Tue, 23 Sep 2003, Jaime Lopez Carvajal wrote:

> Hi R users
>
> I need to apply discretization  to my continuous data.
> Is there a method in R to do this?
>
> Thanks in advance,
>
> Jaime
>



From tplate at blackmesacapital.com  Tue Sep 23 19:44:09 2003
From: tplate at blackmesacapital.com (Tony Plate)
Date: Tue, 23 Sep 2003 11:44:09 -0600
Subject: AW: [R] Rank and extract data from a series
In-Reply-To: <53A181E56FB0694ABFD212F8AEDA7F6F1AB88D@langouste.zhwin.ch>
Message-ID: <5.2.1.1.2.20030923111802.044548f8@mailhost.blackmesacapital.com>

Using Thomas Untern?hrer's handy example, one could also do:

 > X <- c(1, 4.5, 2.3, 1, 7.3)
 > mean(order(X, decreasing=TRUE)[1:2])
[1] 3.5
 >

I think this will give the same results as Thomas Untern?hrer's suggested 
code in almost all cases, but it is perhaps more concise and direct 
(provided that you don't actually need the values of the top items).

(of course you have to change the 1:2 to 1:10 for your needs).

Note that this question gets tricky if there are ties such that there is no 
unique set of row numbers that identify N "top" items.

For example, consider the following data:

 > X <- c(1,3,2,3,4)

Taking "top two", should the answer be 3.5 (avg of row numbers 2 and 5), 
4.5 (avg of row numbers 4 and 5), or 3.666667 (avg of row numbers 2,4 and 5)?

 > mean(order(X, decreasing=TRUE)[1:2])
[1] 3.5
 > order(X, decreasing=TRUE)[1:2]
[1] 5 2
 > # Andy Liaw's suggestion:
 > mean(which(X %in% sort(X, decreasing=TRUE)[1:2]))
[1] 3.666667
 > which(X %in% sort(X, decreasing=TRUE)[1:2])
[1] 2 4 5
 > # Thomas Untern?hrer's suggestion:
 > mean(match(sort(X, decreasing=TRUE)[1:2], X))
[1] 3.5
 > match(sort(X, decreasing=TRUE)[1:2], X)
[1] 5 2
 >

hope this helps,

Tony Plate

At Tuesday 02:23 PM 9/23/2003 +0200, Untern?hrer Thomas, uth wrote:

>Hi,
>
> >I would like to rank a time-series of data, extract the top ten data 
> items from this series, determine the
> >corresponding row numbers for each value in the sample, and take a mean 
> of these *row numbers* (not the data).
>
> >I would like to do this in R, rather than pre-process the data on the 
> UNIX command line if possible, as I need to >calculate other statistics 
> for the series.
>
> >I understand that I can use 'sort' to order the data, but I am not aware 
> of a function in R that would allow me
> >to extract a given number of these data and then determine their 
> positions within the original time series.
>
> >e.g.
>
> >Time series:
>
> >1.0 (row 1)
> >4.5 (row 2)
> >2.3 (row 3)
> >1.0 (row 4)
> >7.3 (row 5)
>
> >Sort would give me:
>
> >1.0
> >1.0
> >2.3
> >4.5
> >7.3
>
> >I would then like to extract the top two data items:
>
> >4.5
> >7.3
>
> >and determine their positions within the original (unsorted) time series:
>
> >4.5 = row 2
> >7.3 = row 5
>
> >then take a mean:
>
> >2 and 5 = 3.5
>
> >Thanks in advance.
>
> >James Brown
>
>X <- c(1, 4.5, 2.3, 1, 7.3)
>X1 <- sort(X, decreasing=TRUE)[1:2]
>X2 <- match(X1, X)
>mean(X2)
>
>
>
>Hope this helps
>
>Thomas
>
>
>___________________________________________
>
>James Brown
>
>Cambridge Coastal Research Unit (CCRU)
>Department of Geography
>University of Cambridge
>Downing Place
>Cambridge
>CB2 3EN, UK
>
>Telephone: +44 (0)1223 339776
>Mobile: 07929 817546
>Fax: +44 (0)1223 355674
>
>E-mail: jdb33 at cam.ac.uk
>E-mail: james_510 at hotmail.com
>
>http://www.geog.cam.ac.uk/ccru/CCRU.html
>___________________________________________
>
>
>
>
>
>
>On Wed, 10 Sep 2003, Jerome Asselin wrote:
>
> > On September 10, 2003 04:03 pm, Kevin S. Van Horn wrote:
> > >
> > > Your method looks like a naive reimplementation of integration, and
> > > won't work so well for distributions that have the great majority of
> > > the probability mass concentrated in a small fraction of the sample
> > > space.  I was hoping for something that would retain the
> > > adaptability of integrate().
> >
> > Yesterday, I've suggested to use approxfun(). Did you consider my
> > suggestion? Below is an example.
> >
> > N <- 500
> > x <- rexp(N)
> > y <- rank(x)/(N+1)
> > empCDF <- approxfun(x,y)
> > xvals <- seq(0,4,.01)
> > plot(xvals,empCDF(xvals),type="l",
> > xlab="Quantile",ylab="Cumulative Distribution Function")
> > lines(xvals,pexp(xvals),lty=2)
> > legend(2,.4,c("Empirical CDF","Exact CDF"),lty=1:2)
> >
> >
> > It's possible to tune in some parameters in approxfun() to better
> > match your personal preferences. Have a look at help(approxfun) for
> > details.
> >
> > HTH,
> > Jerome Asselin
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list 
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help

Tony Plate   tplate at acm.org



From bolker at zoo.ufl.edu  Tue Sep 23 19:59:50 2003
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Tue, 23 Sep 2003 13:59:50 -0400 (EDT)
Subject: [R] How to extract data from Excel
In-Reply-To: <DD42E3F5AF15D211BDA60008C7A49834050E0460@EMAIL03>
Message-ID: <Pine.LNX.4.44.0309231359170.20976-100000@bolker.zoo.ufl.edu>


  Your best bet is saving as a comma-separated value file (.csv) and using 
read.csv to get the data into R.

  Ben

On Tue, 23 Sep 2003 Melissa_Kuang at jltgroup.com wrote:

> Hi,
> 
> I would like to know how to extract the data from Excel Spreadsheet.
> 
> Thank you very much.
> 
> Melissa
> 
> 
> ************************************************************
> JLT Risk Solutions Ltd
> 6 Crutched Friars, London EC3N 2PH. Co Reg No 1536540
> Tel: (44) (0)20 7528 4000   Fax: (44) (0)20 7528 4500
> http://www.jltgroup.com
> Lloyd's Broker.  Regulated by the General Insurance
> Standards Council
> ------------------------------------------------------------
> The content of this e-mail (including any attachments) as\ r...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From skanesk at hotmail.com  Tue Sep 23 20:19:57 2003
From: skanesk at hotmail.com (K Skanes)
Date: Tue, 23 Sep 2003 15:49:57 -0230
Subject: [R] Plotting multiple lines
Message-ID: <Law9-F114yTkjKJIix10002e0d6@hotmail.com>

Hi,

I have a data set with 7 years worth of data, and 2 different values (a real 
value and a model value) of interest in each year for different lengths.  I 
would like a plot with the year on the y axis and an animal length along the 
x axis.  For each year I would like to see two lines, one representing real 
data and one representing model data.  I would like either the model or real 
line to be red.

I have no idea how to start this.  Can anybody help me??  If I didn't 
explain it well enough, I can try to explain it better...

Thank you,
Kay



From baron at psych.upenn.edu  Tue Sep 23 20:35:50 2003
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Tue, 23 Sep 2003 14:35:50 -0400
Subject: [R] Plotting multiple lines
In-Reply-To: <Law9-F114yTkjKJIix10002e0d6@hotmail.com>
References: <Law9-F114yTkjKJIix10002e0d6@hotmail.com>
Message-ID: <20030923183550.GA10709@mail2.sas.upenn.edu>

On 09/23/03 15:49, K Skanes wrote:
>Hi,
>
>I have a data set with 7 years worth of data, and 2 different values (a real 
>value and a model value) of interest in each year for different lengths.  I 
>would like a plot with the year on the y axis and an animal length along the 
>x axis.  For each year I would like to see two lines, one representing real 
>data and one representing model data.  I would like either the model or real 
>line to be red.

One way to do it is with barplot.  You would put your data in a
matrix m1 in which the columns were animals and the rows were
real/model.  (I might have it backward about rows/columns).  The
something like barplot(m1,beside=T) and lots of other options for
labels, colors, line thickness, line spacing, etc., although red
just might turn out to be the default.  Look at the help for
barplot.

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R page:               http://finzi.psych.upenn.edu/



From apjaworski at mmm.com  Tue Sep 23 20:59:04 2003
From: apjaworski at mmm.com (apjaworski@mmm.com)
Date: Tue, 23 Sep 2003 13:59:04 -0500
Subject: [R] bug in stack?
Message-ID: <OFBC48EF64.00DEC493-ON86256DAA.00675BB5-86256DAA.0068492F@mmm.com>

I am posting it here because I am not sure if the behavior described below
is actually a bug.

If I do something like this:

> x1 <- 1:3
> x2 <- 5:9
> x3 <- 21:27
> ll <- list(x1, x2, x3)
> stack(x1,x2,x3)

I get the following error:

Error in rep.int(names(x), lapply(x, length)) :
        invalid number of copies in "rep"

The problem seems to be that the generic list ll is lacking the names
attribute.

The stack.default function (in frametools.R) looks like this:

> stack.default
function (x, ...)
{
    x <- as.list(x)
    x <- x[unlist(lapply(x, is.vector))]
    data.frame(values = unlist(unname(x)), ind = factor(rep.int(names(x),
        lapply(x, length))))
}

and the last statement generates an error if names(x) evaluates to NULL.
If we add the following line of code before the last statement

if(is.null(names(x))) names(x) <- seq(along=x)

the stack function will work fine even for "nameless" lists.


Andy

__________________________________
Andy Jaworski
Engineering Systems Technology Center
3M Center, 518-1-01
St. Paul, MN 55144-1000
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122



From mahustonor at comcast.net  Tue Sep 23 22:28:20 2003
From: mahustonor at comcast.net (mahustonor@comcast.net)
Date: Tue, 23 Sep 2003 20:28:20 +0000
Subject: [R] Typical R installation problem
Message-ID: <200309232027.h8NKRLDd001955@stat.math.ethz.ch>

Dear Peter, 

	I don't know if this is the proper way to ask for help installing R, but if
not, I presume you can pass this on to the appropriate place.  

	I'm trying to install the latest binary on Redhat 9, and keep getting the same
error message no matter what I try.  

[root at localhost mhu]# rpm -i R-1.7.1-1.i386.rpm
warning: R-1.7.1-1.i386.rpm: V3 DSA signature: NOKEY, key ID 97d3544e
error: Failed dependencies:
        libtcl8.3.so is needed by R-1.7.1-1
        libtk8.3.so is needed by R-1.7.1-1
[root at localhost mhu]# exit

I actually found these two files in an obscure location on my computer, and
copied them to /usr/lib/ I also set my path to include the obscure location.  SO
they are actually available.  At least when I enter libtcl8.3.so it is
apparently read and a segmentation fault occurs.  

So, do you have any suggestions about how to get around this problem.  I don't
know what else to do to make these routines available to the R install.  

Any help would be greatly appreciated.  I had no problem installing R on my MAC
OS 10.1.5.

	Thank you very much, 

				Michael Huston
				Oak Ridge, Tennessee



From hodgess at gator.dt.uh.edu  Tue Sep 23 23:16:38 2003
From: hodgess at gator.dt.uh.edu (Erin Hodgess)
Date: Tue, 23 Sep 2003 16:16:38 -0500
Subject: [R] install problem with R Windows
Message-ID: <200309232116.h8NLGcO03267@gator.dt.uh.edu>

Dear R People:

I'm trying to install R 1.7.1 for Windows from Source.

The error that I get is:
previous declarion of 'ssize_t'
MAKE[2]: ***[internet.o]Error 1
MAKE[1]: ***[all]Error 1
MAKE: *** [rmodules] Error 2

Any ideas on how to proceed, please?

thanks in advance!

Sincerely,
Erin Hodgess
mailto: hodgess at gator.uhd.edu



From jasont at indigoindustrial.co.nz  Tue Sep 23 23:12:14 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Tue, 23 Sep 2003 21:12:14 -0000
Subject: [R] loops in Sweave
In-Reply-To: <74F2D4ED68558643B63A6CC21746040D01A07302@BEMAILEXTS1.ad.generali.com>
References: <74F2D4ED68558643B63A6CC21746040D01A07302@BEMAILEXTS1.ad.generali.com>
Message-ID: <1064352050.56.18.camel@kryten.indigoindustrial.co.nz>

On Wed, 2003-09-24 at 03:06, Millo Giovanni wrote:
> Dear all,
> 
> I was wondering whether there is a way to make loops in Sweave, i.e. for example to:
> 1) calculate a parameter, say, a=length(b)
> 2) according to that, add #a# chapters to the document, each including some repetitive analysis, each time done on a particular subset of the data indexed by the elements of 1:a.
> This would be of great help for repeating exploratory data analyses on, say, questionaries when the number of questions changes without having to change the Sweave .snw file.

Two possible ways, off the top of my head:

1) Within LaTeX, use \Sexpr{a} to get the length, then loop within
LaTeX.  I believe Lamport includes an example of looping within LaTeX,
but I haven't got the book handy.

2) Within the R chunk, generate the table using xtable() (package
"xtable") or Latex (package "Hmisc") and print directly within R.  I
haven't tried it, but something like
<<echo=FALSE,results=tex>>=
## build your table in R
tt <- xtable(foo)
print(tt)

@

might do the trick.  I'd been meaning to look at this anyway; you
question prompted me ;)

Check the Sweave manual at Herr Dr Leisch's site.
http://www.ci.tuwein.ac.at/~leisch/Sweave
This has the R chunk options required to produce the above, if my
untested example is not correct.

Cheers

Jason

-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
+64-(0)21-343-545



From hodgess at gator.dt.uh.edu  Tue Sep 23 23:52:18 2003
From: hodgess at gator.dt.uh.edu (Erin Hodgess)
Date: Tue, 23 Sep 2003 16:52:18 -0500
Subject: [R] install R for Windows problem
Message-ID: <200309232152.h8NLqIq07537@gator.dt.uh.edu>

Here are all of the messages:

In file included from internet.c:858:
sock.h.27:conflicting types for 'ssize_t'
c:/mingw/include/sys/types.h:119: previous declaration of 'ssize_t'
MAKE[2]: ***[internet.o] Error 1
MAKE[1]: ***[all] Error 1
MAKE:  ***[rmodules] Error 2



From zitan at mediasculpt.net  Wed Sep 24 19:46:41 2003
From: zitan at mediasculpt.net (Zitan Broth)
Date: Wed, 24 Sep 2003 10:46:41 -0700
Subject: [R] R Production Performance
References: <OF8F028250.C58EE9BB-ON85256DAA.00422BB2@convergys.com>
Message-ID: <00d401c382c3$d0b4a880$3201a8c0@zitan>

Hi James,

Thanks for your response :-)

----- Original Message -----
> It is like anything else that you want to run as part of web services:
what
> do you want it to do?  Yes, it is fast in doing computations, but what
will
> you have it do?  It is probably as fast as anything else that you will
find
> out there that is fairly general purpose.

I just want to use R for mathematical computations, and will call it via PHP
from the commandline with infile. We'll need to obviously test this
ourselves, but I just thought I'd raise the question :-))

> Are you going to be creating a lot of graphics that have to be displayed
> back on the screen?  How is the user going to input data (flat files, XML,
> Excel worksheets, Oracle database, ...)?  Will you be invoking a unique
> process each time a user calls, or will you be using a 'daemon' that will
> communicate with DCOM and such?  How many people will be trying to access
> it once and what is the mix of transactions that they will use?

Well for sure the rest of the app needs to scale as well and be fast,
failsafe etc..., but I am just asking about R.

I was imagining using a unique process call each time I access R, which is
how the apache/php/*nix environment works best (although keeping processes
in memory is achievable as well).  My experience to date on integration with
C packages deploying to *nix is that this works quite effectively although
certain packages require process management that are not multiprocess (to
ensure that R for example only executes one computation at a time), but this
is no problem. There are ways to call c packages directly with PHP (swig)
and I am investigating this at present.

> You can probably get a real good feel by enclosing the operations that you
> want to do in a "system.time" function to see how long it will take.  This
> really depends on what you are trying to do.  I can definitely say that it
> is faster than trying to code the algorithm in PERL or another scripting
> language.

Makes sense because R is written in C, where PERL and PHP are also written
in C, so R is a "layer deep" so to speak :-)

Thanks again,
Z.

> Greetings All,
>
> Been playing with R and it is very easy to get going with the UI or infile
> batch commands :-)
>
> What I am wondering is how scalable and fast R is for running as part of a
> web service.  I believe R is written in C which is a great start, but what
> are peoples general thoughts on this?
>
> Thanks greatly,
> Z.
>
>              [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
>
>
> --
> "NOTICE:  The information contained in this electronic mail transmission
is
> intended by Convergys Corporation for the use of the named individual or
> entity to which it is directed and may contain information that is
> privileged or otherwise confidential.  If you have received this
electronic
> mail transmission in error, please delete it from your system without
> copying or forwarding it, and notify the sender of the error by reply
email
> or by telephone (collect), so that the sender's address records can be
> corrected."
>
>
>



From MSchwartz at medanalytics.com  Wed Sep 24 00:43:59 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 23 Sep 2003 17:43:59 -0500
Subject: [R] Typical R installation problem
In-Reply-To: <200309232027.h8NKRLDd001955@stat.math.ethz.ch>
References: <200309232027.h8NKRLDd001955@stat.math.ethz.ch>
Message-ID: <1064357035.4102.59.camel@localhost>

On Tue, 2003-09-23 at 15:28, mahustonor at comcast.net wrote:
> Dear Peter, 
> 
> 	I don't know if this is the proper way to ask for help installing R, but if
> not, I presume you can pass this on to the appropriate place.  
> 
> 	I'm trying to install the latest binary on Redhat 9, and keep getting the same
> error message no matter what I try.  
> 
> [root at localhost mhu]# rpm -i R-1.7.1-1.i386.rpm
> warning: R-1.7.1-1.i386.rpm: V3 DSA signature: NOKEY, key ID 97d3544e
> error: Failed dependencies:
>         libtcl8.3.so is needed by R-1.7.1-1
>         libtk8.3.so is needed by R-1.7.1-1
> [root at localhost mhu]# exit
> 
> I actually found these two files in an obscure location on my computer, and
> copied them to /usr/lib/ I also set my path to include the obscure location.  SO
> they are actually available.  At least when I enter libtcl8.3.so it is
> apparently read and a segmentation fault occurs.  
> 
> So, do you have any suggestions about how to get around this problem.  I don't
> know what else to do to make these routines available to the R install.  
> 
> Any help would be greatly appreciated.  I had no problem installing R on my MAC
> OS 10.1.5.
> 
> 	Thank you very much, 
> 
> 				Michael Huston
> 				Oak Ridge, Tennessee


First, you have posted to r-help, which is an international e-mail list
and the primary source of assistance with R.

Since I now typically compile from source, I decided to remove my
present installation of R and freshly install the RPM that Martyn has
created on CRAN.  I run RH 9 and have a clean and fully updated
installation. The aforementioned tcl/tk files are in /usr/lib on my
system.

I installed the RPM without problem and then installed John Fox's Rcmdr
to test the tcltk functionality. It works without problem. I also tested
a tcl/tk function that I wrote and it works fine as well.

If your above listed files were not in /usr/lib to start with, that may
be (probably is) an indication that something is amiss in your tcl/tk
installation. You may need to remove and reinstall tcl/tk. 

Also, I am unsure as to what you mean by "At least when I enter
libtcl8.3.so it is apparently read and a segmentation fault occurs." Are
you trying to execute it directly from the command line? .so files are
shared libraries (akin to .DLLs in Windows).

HTH,

Marc Schwartz



From cfridell at macalester.edu  Wed Sep 24 01:04:51 2003
From: cfridell at macalester.edu (Carmen Fridell)
Date: Tue, 23 Sep 2003 18:04:51 -0500
Subject: [R] least squares regression line
Message-ID: <535732813.1064340291@MACID20264.geol.macalester.edu>

I can't seem to find the command to find the least squares regression line 
for my bivariate data set. Can you please help? ~Carmen



From rossini at blindglobe.net  Wed Sep 24 01:08:51 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Tue, 23 Sep 2003 16:08:51 -0700
Subject: [R] confusion about what to expect?
Message-ID: <85k77z9k70.fsf@blindglobe.net>


In playing around with data.frames (and wanting a simple, cheap way to
use the variable and case names in plots; but I've solved that with
some hacks, yech), I noticed the following behavior with subsetting. 


testdata <- data.frame(matrix(1:20,nrow=4,ncol=5))
names(testdata) ## expect labels, get them
names(testdata[2,]) ## expect labels, get them
names(testdata[,2]) ## expect labels, but NOT --  STRIPPED OFF??
testdata[,2]  ## would have expect a name (X2) in the front? NOT EXPECTED
testdata[2,]  ## get what I expect
testdata[2,2]  ## just a number, not a sub-data.frame? unexpected
testdata[2,2:3] ## this is a data.frame
testdata[2:3,2:3] ## and this is, too.

> version
         _                
platform i386-pc-linux-gnu
arch     i386             
os       linux-gnu        
system   i386, linux-gnu  
status   alpha            
major    1                
minor    8.0              
year     2003             
month    09               
day      20               
language R                
> 

I don't have 1.7.1 handy at this location to test, but I would've
expected a data.frame-like object upon subsetting; should I have
expected otherwise?  (granted, a data.frame with just a single
variable could be thought of as silly, but it does have some extra
information that might be worthwhile, on occassion?)

I'm not sure that it is a bug, but I was caught by suprise.  If it
isn't a bug, and someone has a concise way to think through this, for
my future reference, I'd appreciate hearing about it.

best,
-tony

-- 
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From p.connolly at hortresearch.co.nz  Wed Sep 24 01:32:26 2003
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Wed, 24 Sep 2003 11:32:26 +1200
Subject: [R] Omitting blank lines with read.table
Message-ID: <20030923233226.GE26762@hortresearch.co.nz>

Say we have a tab delimited file called bug.txt

Part	Rep	Cage	Hb pupae
1	1	S	32
	1	M	34
		L	42
			  
			  
	2	S	36
		M	28
		L	36

read.delim("bug.txt")

  Part Rep Cage Hb.pupae
1    1   1    S       32
2   NA   1    M       34
3   NA  NA    L       42
4   NA  NA            NA
5   NA  NA            NA
6   NA   2    S       36
7   NA  NA    M       28
8   NA  NA    L       36
>

Variations on read.table give the same result.

When I first used read.table in Splus, I liked the way it ignored rows
that were empty (at least when using sep = "\t").  A line was
considerend empty if it contained only tab characters, so the rows of
NAs or ""s are omitted, so that rows 4 and 5 above would be deleted.

R's read.table differs in this respect (and a number of really neat
ones).  I probably know enough Perl to be able to write a short script
that could delete such lines, and it's not difficult to remove the
rows from the dataframe afterwards; but maybe there's something simple
I've misunderstood in the use of R's read.table.

I can't use na.omit since the other NAs in the data can be dealt with
so I don't want them removed.  Other suggestions welcome.

Thanks

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From davidD at qimr.edu.au  Wed Sep 24 01:48:44 2003
From: davidD at qimr.edu.au (David Duffy)
Date: Wed, 24 Sep 2003 09:48:44 +1000 (EST)
Subject: [R] Updating least squares
In-Reply-To: <200309231013.h8NA2OE6010334@stat.math.ethz.ch>
References: <200309231013.h8NA2OE6010334@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.58.0309240941280.4089@orpheus.qimr.edu.au>

Paul Meagher <paul at datavore.com> wrote:
>
> I am looking at developing a user modelling type app (new data points coming
> in and wanting to dynamically update regression co-efficients for each user)
> which could be viewed as a type of control problem.
>

Alan Miller's AS274 (in C, f77 or f90) does this -- see statlib or his
home page (there are several similar routines eg AS164).  It would be
straightforward to write an R interface.

David Duffy



From tplate at blackmesacapital.com  Wed Sep 24 01:57:46 2003
From: tplate at blackmesacapital.com (Tony Plate)
Date: Tue, 23 Sep 2003 17:57:46 -0600
Subject: [R] confusion about what to expect?
In-Reply-To: <85k77z9k70.fsf@blindglobe.net>
Message-ID: <5.2.1.1.2.20030923174154.0461e160@mailhost.blackmesacapital.com>

Have you investigated the drop= argument to "["? (as in the expression 
testdata[,2,drop=F], which will return a dataframe).

"[.data.frame" has somewhat different behavior from "[" on matrices with 
respect to the drop argument: If the result would be a dataframe with a 
single column, the default behavior of "[.data.frame" is to return a vector 
(return a dataframe always if drop=F), but if the result would be a 
dataframe with a single row, the default behavior is to return a dataframe 
(return a list if drop=T).

E.g.:
 > class(data.frame(a=1:3,b=4:6)[,1])
[1] "integer"
 > class(data.frame(a=1:3,b=4:6)[,1,drop=F])
[1] "data.frame"
 > class(data.frame(a=1:3,b=4:6)[1,])
[1] "data.frame"
 > class(data.frame(a=1:3,b=4:6)[1,,drop=T])
[1] "list"
 >

The default behavior is often what you want, but when it isn't it can be 
confusing, especially it's not that easy to find documentation for this (at 
least not in a quick look through the FAQ, ?"[", and "An Introduction to R" 
-- please excuse me if I overlooked something.)

The thing you have going on with names(testdata[...]) is merely a 
consequence of whether or not the result of the subsetting operation is a 
dataframe or a vector.

hope this helps,

Tony Plate


At Tuesday 04:08 PM 9/23/2003 -0700, you wrote:

>In playing around with data.frames (and wanting a simple, cheap way to
>use the variable and case names in plots; but I've solved that with
>some hacks, yech), I noticed the following behavior with subsetting.
>
>
>testdata <- data.frame(matrix(1:20,nrow=4,ncol=5))
>names(testdata) ## expect labels, get them
>names(testdata[2,]) ## expect labels, get them
>names(testdata[,2]) ## expect labels, but NOT --  STRIPPED OFF??
>testdata[,2]  ## would have expect a name (X2) in the front? NOT EXPECTED
>testdata[2,]  ## get what I expect
>testdata[2,2]  ## just a number, not a sub-data.frame? unexpected
>testdata[2,2:3] ## this is a data.frame
>testdata[2:3,2:3] ## and this is, too.
>
> > version
>          _
>platform i386-pc-linux-gnu
>arch     i386
>os       linux-gnu
>system   i386, linux-gnu
>status   alpha
>major    1
>minor    8.0
>year     2003
>month    09
>day      20
>language R
> >
>
>I don't have 1.7.1 handy at this location to test, but I would've
>expected a data.frame-like object upon subsetting; should I have
>expected otherwise?  (granted, a data.frame with just a single
>variable could be thought of as silly, but it does have some extra
>information that might be worthwhile, on occassion?)
>
>I'm not sure that it is a bug, but I was caught by suprise.  If it
>isn't a bug, and someone has a concise way to think through this, for
>my future reference, I'd appreciate hearing about it.
>
>best,
>-tony
>
>--
>rossini at u.washington.edu            http://www.analytics.washington.edu/
>Biomedical and Health Informatics   University of Washington
>Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
>UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
>FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email
>
>CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From MSchwartz at medanalytics.com  Wed Sep 24 02:02:07 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 23 Sep 2003 19:02:07 -0500
Subject: [R] confusion about what to expect?
In-Reply-To: <85k77z9k70.fsf@blindglobe.net>
References: <85k77z9k70.fsf@blindglobe.net>
Message-ID: <1064361727.4102.92.camel@localhost>

On Tue, 2003-09-23 at 18:08, A.J. Rossini wrote:
> In playing around with data.frames (and wanting a simple, cheap way to
> use the variable and case names in plots; but I've solved that with
> some hacks, yech), I noticed the following behavior with subsetting. 
> 
> 
> testdata <- data.frame(matrix(1:20,nrow=4,ncol=5))
> names(testdata) ## expect labels, get them
> names(testdata[2,]) ## expect labels, get them
> names(testdata[,2]) ## expect labels, but NOT --  STRIPPED OFF??
> testdata[,2]  ## would have expect a name (X2) in the front? NOT EXPECTED
> testdata[2,]  ## get what I expect
> testdata[2,2]  ## just a number, not a sub-data.frame? unexpected
> testdata[2,2:3] ## this is a data.frame
> testdata[2:3,2:3] ## and this is, too.
> 
> > version
>          _                
> platform i386-pc-linux-gnu
> arch     i386             
> os       linux-gnu        
> system   i386, linux-gnu  
> status   alpha            
> major    1                
> minor    8.0              
> year     2003             
> month    09               
> day      20               
> language R                
> > 
> 
> I don't have 1.7.1 handy at this location to test, but I would've
> expected a data.frame-like object upon subsetting; should I have
> expected otherwise?  (granted, a data.frame with just a single
> variable could be thought of as silly, but it does have some extra
> information that might be worthwhile, on occassion?)
> 
> I'm not sure that it is a bug, but I was caught by suprise.  If it
> isn't a bug, and someone has a concise way to think through this, for
> my future reference, I'd appreciate hearing about it.
> 
> best,
> -tony


Tony,

A quick review of what is returned when you subset the data.frame
testdata:

> str(testdata[,2])
 int [1:4] 5 6 7 8

> str(testdata[2,])
`data.frame':   1 obs. of  5 variables:
 $ X1: int 2
 $ X2: int 6
 $ X3: int 10
 $ X4: int 14
 $ X5: int 18

> dim(testdata[,2])
NULL

> dim(testdata[2,])
[1] 1 5


Quoting from ?Extract:

"When [.data.frame is used for subsetting rows of a data.frame, it
returns a data frame with unique (and non-missing)row names, if
necessary transforming the names using make.names( * , unique = TRUE)"

What is unstated, but covered by R FAQ 7.7 ("Why do my matrices lose
dimensions?"), a single column in a data.frame resulting from the subset
operation is by default turned into a vector. Hence, no names.

HTH,

Marc Schwartz



From dmurdoch at pair.com  Wed Sep 24 02:05:37 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue, 23 Sep 2003 20:05:37 -0400
Subject: [R] install problem with R Windows
In-Reply-To: <200309232116.h8NLGcO03267@gator.dt.uh.edu>
References: <200309232116.h8NLGcO03267@gator.dt.uh.edu>
Message-ID: <hrn1nvcgfj49ish73slariuog6a51gtk0f@4ax.com>

On Tue, 23 Sep 2003 16:16:38 -0500, you wrote:

>Dear R People:
>
>I'm trying to install R 1.7.1 for Windows from Source.
>
>The error that I get is:
>previous declarion of 'ssize_t'
>MAKE[2]: ***[internet.o]Error 1
>MAKE[1]: ***[all]Error 1
>MAKE: *** [rmodules] Error 2
>
>Any ideas on how to proceed, please?

Can you describe your setup?  Have you installed the tools as
described in src/gnuwin32/INSTALL, or are you using others?  

Duncan Murdoch



From jasont at indigoindustrial.co.nz  Wed Sep 24 02:12:50 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Wed, 24 Sep 2003 00:12:50 -0000
Subject: [R] least squares regression line
In-Reply-To: <535732813.1064340291@MACID20264.geol.macalester.edu>
References: <535732813.1064340291@MACID20264.geol.macalester.edu>
Message-ID: <1064362774.916.6.camel@kryten.indigoindustrial.co.nz>

On Wed, 2003-09-24 at 11:04, Carmen Fridell wrote:
> I can't seem to find the command to find the least squares regression line 
> for my bivariate data set. Can you please help? ~Carmen

Any time you're lost in R, you can type "help.start()".  This will start
a web browser, which loads the starting help page.  Click on "Keyword
Search".  Once the new page loads, type in some of the words you're
looking for.  "regression" is a good place to start.  That will lead to
a list of potential matches by subject.  Hint - you're looking for a
function to estimate a *linear* model.

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
+64-(0)21-343-545



From paul at datavore.com  Wed Sep 24 04:24:02 2003
From: paul at datavore.com (Paul Meagher)
Date: Tue, 23 Sep 2003 23:24:02 -0300
Subject: [R] R Production Performance
References: <OF8F028250.C58EE9BB-ON85256DAA.00422BB2@convergys.com>
	<00d401c382c3$d0b4a880$3201a8c0@zitan>
Message-ID: <005301c38242$eba7c900$f07afea9@computer>

Hi Zitan,

Below is the test I ran awhile back on invoking R as a system call.  It
might be faster if you had a c-extension to R but before I went that route I
would want to know 1) roughly how fast Python and Perl are in returning
results with their c-bindings/embedded stuff/dcom stuff, 2) whether R can be
run as a daemon process so you don't incur start up costs, and 3) whether R
can act as a math server in the sense that it will fork children or threads
as multiple users establish sessions with it.  I agree it would be nice to
have a better interface to R than via a system call.

Regards,
Paul Meagher

=====================

I just timed how long it took to pipe a file containing 2 lines below into R
(via a PHP script executed from my browser):

input.R
--------------
x = cbind(4,5,3,2,3,4)
x


<?php
// timer.php

function getmicrotime(){
  list($usec, $sec) = explode(" ",microtime());
  return ((float)$usec + (float)$sec);
}

$time_start = getmicrotime();

$Input  = "./input.R";
$Output = "./output.R";
$RPath = "/usr/local/bin/R";
system("$RPath --no-save < $Input > $Output");
$fp = fopen("$Output", "r");
while (!feof($fp)) {
  $line = fgets($fp,4096);
  echo $line ."<br>";
}
fclose($fp);

$time_end = getmicrotime();
$time = $time_end - $time_start;
echo "<p>Time To Execute: $time seconds</p>";
?>

The time to execute this script was 3.1081320047379 seconds (if I execute
the script a few times this around what I get).

I then removed the line that calls R only.  There was something in the
output.R file so, in essense, the only difference between the original
script and modified script is the removal of the system call to R.

The time to execute was 0.0010089874267578 seconds

By subtractive logic, this means the call to R incurs an overhead of around
3 seconds on a average web server box using the php-apache module.

============================================






----- Original Message ----- 
From: "Zitan Broth" <zitan at mediasculpt.net>
To: <james.holtman at convergys.com>
Cc: <r-help at stat.math.ethz.ch>
Sent: Wednesday, September 24, 2003 2:46 PM
Subject: Re: [R] R Production Performance


> Hi James,
>
> Thanks for your response :-)
>
> ----- Original Message -----
> > It is like anything else that you want to run as part of web services:
> what
> > do you want it to do?  Yes, it is fast in doing computations, but what
> will
> > you have it do?  It is probably as fast as anything else that you will
> find
> > out there that is fairly general purpose.
>
> I just want to use R for mathematical computations, and will call it via
PHP
> from the commandline with infile. We'll need to obviously test this
> ourselves, but I just thought I'd raise the question :-))
>
> > Are you going to be creating a lot of graphics that have to be displayed
> > back on the screen?  How is the user going to input data (flat files,
XML,
> > Excel worksheets, Oracle database, ...)?  Will you be invoking a unique
> > process each time a user calls, or will you be using a 'daemon' that
will
> > communicate with DCOM and such?  How many people will be trying to
access
> > it once and what is the mix of transactions that they will use?
>
> Well for sure the rest of the app needs to scale as well and be fast,
> failsafe etc..., but I am just asking about R.
>
> I was imagining using a unique process call each time I access R, which is
> how the apache/php/*nix environment works best (although keeping processes
> in memory is achievable as well).  My experience to date on integration
with
> C packages deploying to *nix is that this works quite effectively although
> certain packages require process management that are not multiprocess (to
> ensure that R for example only executes one computation at a time), but
this
> is no problem. There are ways to call c packages directly with PHP (swig)
> and I am investigating this at present.
>
> > You can probably get a real good feel by enclosing the operations that
you
> > want to do in a "system.time" function to see how long it will take.
This
> > really depends on what you are trying to do.  I can definitely say that
it
> > is faster than trying to code the algorithm in PERL or another scripting
> > language.
>
> Makes sense because R is written in C, where PERL and PHP are also written
> in C, so R is a "layer deep" so to speak :-)
>
> Thanks again,
> Z.
>
> > Greetings All,
> >
> > Been playing with R and it is very easy to get going with the UI or
infile
> > batch commands :-)
> >
> > What I am wondering is how scalable and fast R is for running as part of
a
> > web service.  I believe R is written in C which is a great start, but
what
> > are peoples general thoughts on this?
> >
> > Thanks greatly,
> > Z.
> >
> >              [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> >
> >
> >
> > --
> > "NOTICE:  The information contained in this electronic mail transmission
> is
> > intended by Convergys Corporation for the use of the named individual or
> > entity to which it is directed and may contain information that is
> > privileged or otherwise confidential.  If you have received this
> electronic
> > mail transmission in error, please delete it from your system without
> > copying or forwarding it, and notify the sender of the error by reply
> email
> > or by telephone (collect), so that the sender's address records can be
> > corrected."
> >
> >
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From rossini at blindglobe.net  Wed Sep 24 04:40:55 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Tue, 23 Sep 2003 19:40:55 -0700
Subject: [R] confusion about what to expect?
In-Reply-To: <1064361727.4102.92.camel@localhost> (Marc Schwartz's message
	of "Tue, 23 Sep 2003 19:02:07 -0500")
References: <85k77z9k70.fsf@blindglobe.net>
	<1064361727.4102.92.camel@localhost>
Message-ID: <85fzim9adk.fsf@blindglobe.net>

Marc Schwartz <MSchwartz at MedAnalytics.com> writes:

> On Tue, 2003-09-23 at 18:08, A.J. Rossini wrote:

  <-- about confusion -->

Anyway, the mnemonic to use seems to be to remember that complex data
structures get simplified whenever possible.  Thanks to Doug G. and
Patrick C. for that!

I'll plead an excess of Lisp, Python, and C++ recently, but that isn't
a real excuse.

best,
-tony

-- 
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From fjmolina at ams.ucsc.edu  Wed Sep 24 04:59:03 2003
From: fjmolina at ams.ucsc.edu (Francisco J Molina)
Date: Tue, 23 Sep 2003 19:59:03 -0700
Subject: [R] weird behaviour when calling c++
Message-ID: <16241.2167.91875.429287@dhcp-63-193.cse.ucsc.edu>


I am using 1.7.1 in a PC ( redhat 9, linux )

I created a subroutine in C++, mySubrutine, to be used in R. To debug this
subroutine I have a main routine in C++ that calls mySubrutine. The only thing main () does is to provide mySubrutine with its
arguments 
(this is the easiest way for me to debug subroutines written in
C++ and intended to be used in R ).

I also have a version of the same program in R: an R script that provides
mySubrutine with its arguments. 

When I run the C++ version in gdb I do not have any problem, every time I
run it I get the result ( the same result ). 

The R script calls mySubrutine through .( ) C. Sometimes it gives me the 
same result I get in the C++ version; sometimes it freezes. This even
happens if I execute the script several times in a row ( I use C-c when it
freezes )
Any idea?

I am using  new and delete in mySubrutine, but I guess this should not be
any problem.

P.S: The first thing the R script executes is rm ( list = ls ( )).
     To use dyn.unload does not make any difference.
     
Thank you.



From kjetil at entelnet.bo  Wed Sep 24 05:22:46 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Tue, 23 Sep 2003 23:22:46 -0400
Subject: [R] Omitting blank lines with read.table
In-Reply-To: <20030923233226.GE26762@hortresearch.co.nz>
Message-ID: <3F70D5C6.16188.369A64@localhost>

On 24 Sep 2003 at 11:32, Patrick Connolly wrote:

read.table has an argument blank.lines.skip, which is true by 
default, at least in read.table. You can try to give that to 
read.delim?

Kjetil Halvorsen

> Say we have a tab delimited file called bug.txt
> 
> Part	Rep	Cage	Hb pupae
> 1	1	S	32
> 	1	M	34
> 		L	42
> 			  
> 			  
> 	2	S	36
> 		M	28
> 		L	36
> 
> read.delim("bug.txt")
> 
>   Part Rep Cage Hb.pupae
> 1    1   1    S       32
> 2   NA   1    M       34
> 3   NA  NA    L       42
> 4   NA  NA            NA
> 5   NA  NA            NA
> 6   NA   2    S       36
> 7   NA  NA    M       28
> 8   NA  NA    L       36
> >
> 
> Variations on read.table give the same result.
> 
> When I first used read.table in Splus, I liked the way it ignored rows
> that were empty (at least when using sep = "\t").  A line was
> considerend empty if it contained only tab characters, so the rows of
> NAs or ""s are omitted, so that rows 4 and 5 above would be deleted.
> 
> R's read.table differs in this respect (and a number of really neat
> ones).  I probably know enough Perl to be able to write a short script
> that could delete such lines, and it's not difficult to remove the
> rows from the dataframe afterwards; but maybe there's something simple
> I've misunderstood in the use of R's read.table.
> 
> I can't use na.omit since the other NAs in the data can be dealt with
> so I don't want them removed.  Other suggestions welcome.
> 
> Thanks
> 
> -- 
> Patrick Connolly
> HortResearch
> Mt Albert
> Auckland
> New Zealand 
> Ph: +64-9 815 4200 x 7188
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
> I have the world`s largest collection of seashells. I keep it on all
> the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From mail at joeconway.com  Wed Sep 24 06:47:42 2003
From: mail at joeconway.com (Joe Conway)
Date: Tue, 23 Sep 2003 21:47:42 -0700
Subject: [R] R Production Performance
In-Reply-To: <005301c38242$eba7c900$f07afea9@computer>
References: <OF8F028250.C58EE9BB-ON85256DAA.00422BB2@convergys.com>	<00d401c382c3$d0b4a880$3201a8c0@zitan>
	<005301c38242$eba7c900$f07afea9@computer>
Message-ID: <3F7121EE.6070603@joeconway.com>

Paul Meagher wrote:
> Below is the test I ran awhile back on invoking R as a system call.  It
> might be faster if you had a c-extension to R but before I went that route I
> would want to know 1) roughly how fast Python and Perl are in returning
> results with their c-bindings/embedded stuff/dcom stuff, 2) whether R can be
> run as a daemon process so you don't incur start up costs, and 3) whether R
> can act as a math server in the sense that it will fork children or threads
> as multiple users establish sessions with it.  I agree it would be nice to
> have a better interface to R than via a system call.
> 

I'm doing something similar using PL/R (an R procedural language handler 
extension to Postgres that I wrote) with Postgres, R, and PHP. In 
Postgres 7.4 (currently at beta3) or with a back-patched copy of 7.3, 
you can preload the R interpreter when the Postgres postmaster first 
starts. This means that essentially R is running as part of the Postgres 
daemon. Whenever a connection is made to the database, the forked 
process already has an initialized copy of R running inside it. The 
startup savings I see are similar to what you did (2.2 seconds versus 
0.009 seconds):

------------------------------------------------------------------
Function -- intentionally very simple:
--------------------------------------
create or replace function echo(text) returns text as 'print(arg1)' 
language 'plr';

Without preloading (first function call):
-----------------------------------------
regression=# explain analyze select echo('hello');
  Total runtime: 2195.35 msec

Without preloading (second function call):
-----------------------------------------
regression=# explain analyze select echo('hello');
  Total runtime: 0.55 msec

With preloading (first function call):
-----------------------------------------
regression=# explain analyze select echo('hello');
  Total runtime: 9.74 msec

With preloading (second function call):
-----------------------------------------
regression=# explain analyze select echo('hello');
  Total runtime: 0.59 msec
------------------------------------------------------------------


In both cases the second (and subsequent) function calls are even faster 
because the PL/R function itself has been precompiled and cached.

I call the PL/R function from PHP to read my data directly from the 
database, process it, and generate whatever charts I need. Here's a very 
simple example:


The PL/R function:
------------------------------------------------------------------
create type histtup as
(
   break float8,
   count int
);

create or replace function hist(text, text)
returns setof histtup as '
  sql <- paste("select id_val from sample_numeric_data ",
               "where ia_id=''", arg1, "''", sep="")
  rs <- pg.spi.exec(sql)

  if (!is.na(arg2)) {
     x11(display=":5")
     jpeg(file=arg2, width = 480, height = 480,
          pointsize = 12, quality = 75)
     par(ask = FALSE, bg = "#F8F8F8")
     sql <- paste("select ia_attname as val from atts ",
                  "where ia_id=''", arg1, "''", sep="")
     attname <- pg.spi.exec(sql)
     h <- hist(rs[,1], col = "blue",
               main = paste("Histogram of", attname$val),
               xlab = attname$val);
     dev.off()
     system(paste("chmod 666 ", arg2, sep=""),
            intern = FALSE, ignore.stderr = TRUE)
   }
   else
     h <- hist(rs[,1], plot = FALSE);

   result = data.frame(breaks = h$breaks[1:length(h$breaks)-1],
            count = h$counts);

   return(result)
' language 'plr';
------------------------------------------------------------------

The PHP page:
------------------------------------------------------------------
<HTML><BODY>
<?PHP
echo "
<FORM ACTION='$PHP_SELF' METHOD='post' NAME='proto_form'>
<TABLE WIDTH='482' CELLSPACING='0' CELLPADDING='1' BORDER='0'>
   <TR>
     <TD>Data</TD>
     <TD><INPUT TYPE='text' NAME='userdata' value='' size='80'></TD>
   </TR>
   <TR>
     <TD colspan='2'>
       <INPUT TYPE='submit' NAME='submit' value='Submit'>
     </TD>
   </TR>
</TABLE>
</FORM>
";

if ($_POST['submit'] == "Submit")
{
   $tmpfilename = 'charts/hist1.jpg';
   $conn = pg_connect("dbname=oscon user=postgres");
   $sql = "select * from hist('" . $_POST['userdata'] . "','" .
          "/tmp/" . $tmpfilename . "')";
   $rs = pg_query($conn,$sql);
   echo "<img src='$tmpfilename' border=0>";
}
?>
</BODY></HTML>
------------------------------------------------------------------


Hopefully this gives you some ideas about what is possible. If you're 
interested in PL/R, you can grab a copy (along with a patched 7.3.4 
source RPM for Postgres) here: http://www.joeconway.com/

HTH,

Joe



From ozric at web.de  Wed Sep 24 07:42:06 2003
From: ozric at web.de (Christian Schulz)
Date: Wed, 24 Sep 2003 07:42:06 +0200
Subject: [R] data.frame with duplicated id's
Message-ID: <001801c3825e$9739a520$db03ebd9@pc>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030924/93b97224/attachment.pl

From ahayen at nswcc.org.au  Wed Sep 24 07:56:00 2003
From: ahayen at nswcc.org.au (Andrew Hayen)
Date: Wed, 24 Sep 2003 15:56:00 +1000
Subject: [R] data.frame with duplicated id's
Message-ID: <2A23A3B738DB3E47BD676EDC51C064D1012034B0@iris.nswcc.org.au>

Try ?reshape

A


-----Original Message-----
From: Christian Schulz [mailto:ozric at web.de]
Sent: Wednesday, 24 September 2003 3:42 PM
To: r-help at stat.math.ethz.ch
Subject: [R] data.frame with duplicated id's


Hi,

is there a exstisting function (..i found nothing until now.) 
what makes it possible transfrom a dataset:

ID AGE V.MAI V.JUNE    
11 20   100   120
12 30   200   90

into 

ID    AGE    V
11    20       100 
11    20       120
12    30        200
12    30        90

,or have i to programm ths my self?

Thanks for any comment, help and/or starting point.

regards,christian






	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From comm at 263.net  Wed Sep 24 08:25:00 2003
From: comm at 263.net (Jean Sun)
Date: Wed, 24 Sep 2003 06:25:00 -0000
Subject: [R] what does the sum of square of Gaussian RVs with
	differentvariance obey?
Message-ID: <20030924062438.CA4B72F880@smtp.263.net>

Thanks a lot.
It does work. The fitted data match the simulated ones well. Even no need the shifted or scaled version of Chi-squared pdf. Also, I have tested the case of non-independent RVs,generated by linear combining of independent Gaussian RVs,the result is satisfactory too.

Regards,
J.Sun
	

2003-09-23 07:07:00 Thomas Lumley wrote£º

>On Tue, 23 Sep 2003, Jean Sun wrote:
>
>> >From basic statistics principle,we know,given several i.i.d Gaussian
>> >RVs with zero or nonzero mean,the sum of square of them is a central or
>> >noncentral Chi-distributed RV.However if these Gaussian RVs have
>> >different variances,what does the sum of square of them obey?
>>
>
>Nothing very useful.  It's a mixture of chisquare(1) variables. One
>standard approach is to approximate it by a multiple of a chisquared
>distribution that has the correct mean and variance.
>
>	-thomas



From vito.muggeo at giustizia.it  Wed Sep 24 09:31:46 2003
From: vito.muggeo at giustizia.it (Vito Muggeo)
Date: Wed, 24 Sep 2003 09:31:46 +0200
Subject: [R] models with I(1) errors
References: <2A23A3B738DB3E47BD676EDC51C064D1012034B0@iris.nswcc.org.au>
Message-ID: <005f01c3826d$ecfaa040$5c13070a@GIUSTIZIA.IT>

Dear all,
I'm interested in fitting time-series linear models with I(1) errors. Namely
given
y_t=a+b*t+u_t
the random term u_t are such that
u_t-u_{t-1}=e_t~iid N(0,\sigma)

Please, could anyone suggest me any reference (book, article, R functions)
dealing with such models?

Many thanks in advance,
regards,
vito



From p.pagel at gsf.de  Wed Sep 24 09:05:08 2003
From: p.pagel at gsf.de (Philipp Pagel)
Date: Wed, 24 Sep 2003 09:05:08 +0200
Subject: [R] data.frame with duplicated id's
In-Reply-To: <001801c3825e$9739a520$db03ebd9@pc>
References: <001801c3825e$9739a520$db03ebd9@pc>
Message-ID: <20030924070508.GA1480@porcupine.gsf.de>

	Hi!

> is there a exstisting function (..i found nothing until now.) 
> what makes it possible transfrom a dataset:
> 
> ID AGE V.MAI V.JUNE    
> 11 20   100   120
> 12 30   200   90
> 
> into 
> 
> ID    AGE    V
> 11    20       100 
> 11    20       120
> 12    30        200
> 12    30        90

I think reshape() will do what you want.

cu
	Philipp

-- 
Dr. Philipp Pagel                                Tel.  +49-89-3187-3675
Institute for Bioinformatics / MIPS              Fax.  +49-89-3187-3585
GSF - National Research Center for Environment and Health
Ingolstaedter Landstrasse 1
85764 Neuherberg, Germany



From sebastien.dejean at math.ups-tlse.fr  Wed Sep 24 10:15:51 2003
From: sebastien.dejean at math.ups-tlse.fr (sebastien.dejean@math.ups-tlse.fr)
Date: Wed, 24 Sep 2003 10:15:51 +0200
Subject: [R] Problem using C random generator called from R
Message-ID: <5.2.0.9.0.20030924095631.00ad7f30@mail.cict.fr>

Hello

I'm trying to use C random generator function drand48() which return 
floating-point values, uniformly distributed over [0,1], 
(http://www.opengroup.org/onlinepubs/007908799/xsh/drand48.html). When 
values are returned to R, they are not in [0,1]. A simple C program using 
drand48() gives values in [0,1] so I suppose there is a problem (type 
definition ?) between C and R. Here are R and C function and an example.

# R function
simulC <- function(n)
   {
dyn.load("test.so")
simR <- runif(n)
simC <- .C("test",
        as.integer(n),
        res=double(n))$res
out <- list(simR=simR,simC=simC)
out
}

// C function
void test(int *n,double *res)
{
   int i;
   for(i=0;i<*n;i++) {res[i] = drand48();}
}

# Result of x <- simulC(5)
 > x
$simR
  [1] 0.398567942 0.866053345 0.332070718 0.535814830 0.473418784
$simC
  [1] -1222291199   211182456  1007036963  1254056690  -646279915


Any help will be greatly appreciated,
S?bastien



--
S?bastien D?jean ~~~~~~~~~~~
http://www.lsp.ups-tlse.fr/Fp/Dejean



From Soren.Hojsgaard at agrsci.dk  Wed Sep 24 10:14:43 2003
From: Soren.Hojsgaard at agrsci.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Wed, 24 Sep 2003 10:14:43 +0200
Subject: [R] How to detect which function is used for e.g. printing an
	object of a given class
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC6BFAAD@DJFPOST01.djf.agrsci.dk>

Dear all,
I take a an object of class loglm and specialize it into class c("hllm", "loglm"). I would like to define print.hllm such that it prints some special information for the hllm object but ALSO prints the loglm-information using the print method for loglm. There is no print.loglm method (available), but if I look in the src for the MASS library, the function is there. 

Is there a way of seeing exactly which method (function) is used for say printing an object of a given class?

To acomplish what I describe above I define
print.hllm <- function(x, dots){
  < do something special >
  class(x) <- "loglm"
  print(x)
}

Is there an alternative way of "dispatching" the printing, such that the usual print method for loglm is used after doing what is special for hllm?

Thanks in advance
S?ren H?jsgaard


==========================================
S?ren H?jsgaard,  PhD, Senior Scientist
Biometry Research Unit
Danish Institute of Agricultural Sciences
Research Centre Foulum, DK-8830 Tjele, Denmark
Phone: +45 8999 1703
E-mail : sorenh at agrsci.dk
Homepage : http://www.jbs.agrsci.dk/~sorenh/



From martinol at ensam.inra.fr  Wed Sep 24 14:47:21 2003
From: martinol at ensam.inra.fr (Martin Olivier)
Date: Wed, 24 Sep 2003 14:47:21 +0200
Subject: [R] heatmap and hclust
Message-ID: <3F719259.2070005@ensam.inra.fr>

Hi all,

The function heatmap uses the functions dist and hclust with default 
parameters.
How to change these parameters? For example, i want to use the ward 
criterion for hierarchical
clustering with  binary distance.

Best regards,
Olivier.



From zeileis at ci.tuwien.ac.at  Wed Sep 24 11:01:39 2003
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Wed, 24 Sep 2003 11:01:39 +0200
Subject: [R] How to detect which function is used for e.g. printing an
	object of a given class
In-Reply-To: <C83C5E3DEEE97E498B74729A33F6EAEC6BFAAD@DJFPOST01.djf.agrsci.dk>
References: <C83C5E3DEEE97E498B74729A33F6EAEC6BFAAD@DJFPOST01.djf.agrsci.dk>
Message-ID: <200309240901.h8O91doN018881@thorin.ci.tuwien.ac.at>

S?ren:

> I take a an object of class loglm and specialize it into class
> c("hllm", "loglm"). I would like to define print.hllm such that it
> prints some special information for the hllm object but ALSO prints
> the loglm-information using the print method for loglm. There is no
> print.loglm method (available), but if I look in the src for the
> MASS library, the function is there.

MASS has got a namespace, so you can get the S3 method by

R> getS3method("print", "loglm")
function (x, ...) 
{
    cat("Call:\n")
    print(x$call)
    ts.array <- rbind(c(x$lrt, x$df, if (x$df > 0) 1 - pchisq(x$lrt, 
        x$df) else 1), c(x$pearson, x$df, if (x$df > 0) 1 - 
pchisq(x$pearson, 
        x$df) else 1))
    dimnames(ts.array) <- list(c("Likelihood Ratio", "Pearson"), 
        c("X^2", "df", "P(> X^2)"))
    cat("\nStatistics:\n")
    print(ts.array)
    invisible(x)
}
<environment: namespace:MASS>


> Is there a way of seeing exactly which method (function) is used for
> say printing an object of a given class?

If your object is of class "loglm" the method dispatch looks for 
print.loglm first and if that does not exist, it uses print.default. 
Correspondingly, if your object is of class c("hllm", "loglm") it 
looks first for print.hllm, then print.loglm etc.

> To acomplish what I describe above I define
> print.hllm <- function(x, dots){
>   < do something special >
>   class(x) <- "loglm"
>   print(x)
> }
>
> Is there an alternative way of "dispatching" the printing, such that
> the usual print method for loglm is used after doing what is special
> for hllm?

After having dispatched on the first element of class(x) you could 
also do recursively
  class(x) <- class(x)[-1]
but for the special case that you described above this is of course 
equivalent with your code.

Best,
Achim



From laurent at cbs.dtu.dk  Wed Sep 24 11:11:14 2003
From: laurent at cbs.dtu.dk (Laurent Gautier)
Date: Wed, 24 Sep 2003 11:11:14 +0200
Subject: [R] heatmap and hclust
In-Reply-To: <3F719259.2070005@ensam.inra.fr>
References: <3F719259.2070005@ensam.inra.fr>
Message-ID: <20030924091114.GA491330@genome.cbs.dtu.dk>

On Wed, Sep 24, 2003 at 02:47:21PM +0200, Martin Olivier wrote:
> Hi all,
> 
> The function heatmap uses the functions dist and hclust with default 
> parameters.
> How to change these parameters? For example, i want to use the ward 
> criterion for hierarchical
> clustering with  binary distance.
> 
> Best regards,
> Olivier.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


Specify what you want through the parameters "distfun" and "hclustfun".
Ex:
my.dist <- function(x) dist(x, method="binary")
my.hclust <- function(d) hclust(d, method="ward")

hm <- heatmap(blablabla, distfun=my.dist, hclustfun=my.hclust)


Hopin' it helps,



L.


-- 
--------------------------------------------------------------
Laurent Gautier			CBS, Building 208, DTU
PhD. Student			DK-2800 Lyngby,Denmark	
tel: +45 45 25 24 89		http://www.cbs.dtu.dk/laurent



From jean-marie.jungblut at mzes.uni-mannheim.de  Wed Sep 24 12:16:23 2003
From: jean-marie.jungblut at mzes.uni-mannheim.de (Jean-Marie Jungblut)
Date: Wed, 24 Sep 2003 12:16:23 +0200
Subject: [R] Graph window is not available any more
Message-ID: <DPEAKKPFDPBJKCLCOADIEENCCCAA.jean-marie.jungblut@mzes.uni-mannheim.de>

Hi all,

I have currently been using the book Modern Applied Statistics with S from
Venables and Ripley. At chapter 6 on Linear Statistical models I wanted to
produce the plot as shown by "Figure 6.1" using Whiteside's data. xyplot
command seems not to work on my version of "R"(version 1.7.0) running on
different environments (Win XP, Win 98 and Win 2000). I then used the
scripts for "R" provided with the package MASS pasting the following lines
into the R console:

library(MASS)
library(lattice)
options(echo = T,width=65, digits=5, height=9999)
trellis.device(postscript, file="ch06.ps", width=8, height=6, pointsize=9)
options(contrasts = c("contr.helmert", "contr.poly"))
xyplot(Gas ~ Temp | Insul, whiteside, panel =
  function(x, y, ...) {
    panel.xyplot(x, y, ...)
    panel.lmline(x, y, ...)
  }, xlab = "Average external temperature (deg. C)",
  ylab = "Gas consumption  (1000 cubic feet)", aspect = "xy",
  strip = function(...) strip.default(..., style = 1))

After this no graph shows up, no error message is displayed and other siple
commands like hist(x) or plot(y,x) do not produce any graphs. The Graph
window seems to be disabled until I close the session without saving the
workspace image.

Thank you very much for any reply or comments.

Jean-Marie Jungblut.

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-
Jean-Marie Jungblut
Wissenschaftlicher Mitarbeiter
Mannheimer Zentrum f?r Europ?ische Sozialforschung
Abt. A & Forschungsarchiv EURODATA

Universit?t Mannheim, MZES
D-68131 Mannheim

Fon: +49/(0)621 181 2830
Fax: +49/(0)621 181 2834
jean-marie at jungblut@mzes.uni-mannheim.de



From alessandro.semeria at cramont.it  Wed Sep 24 13:05:59 2003
From: alessandro.semeria at cramont.it (alessandro.semeria@cramont.it)
Date: Wed, 24 Sep 2003 13:05:59 +0200
Subject: [R] Graph window is not available any more
Message-ID: <OFB09B27F3.9585BFE3-ONC1256DAB.003C65DE-C1256DAB.003CE745@tomware.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030924/c9aae976/attachment.pl

From brostaux.y at fsagx.ac.be  Wed Sep 24 13:07:44 2003
From: brostaux.y at fsagx.ac.be (Yves Brostaux)
Date: Wed, 24 Sep 2003 13:07:44 +0200
Subject: [R] Matching colors with lattice auto.key
Message-ID: <5.1.0.14.1.20030924130115.04a89470@fusamail.fsagx.ac.be>

Hello !

I try to plot some data with lattice function xyplot. These data are 
separated in two groups by a factor. If I let the default color and symbol 
settings, I get the right legent with auto.key. But if I change them by col 
and pch arguments, the plot is right but the legend still reflects default 
settings. Isn't the auto-key feature normally taking its arguments from the 
internal parameters of the plot ?

Here some example :

 > x <- rnorm(20)
 > y <- rnorm(20)
 > z <- rep(1:2, each=10)
 > xyplot(y~x, groups=z, pch=16, col=c("red", "blue"), auto.key=T)

Is it a bug or am I missing something ?

Thanks in advance.



From david.meyer at ci.tuwien.ac.at  Wed Sep 24 13:13:39 2003
From: david.meyer at ci.tuwien.ac.at (David Meyer)
Date: Wed, 24 Sep 2003 13:13:39 +0200
Subject: [R] How to detect which function is used for e.g. printing an
	object of a given class
In-Reply-To: <200309240901.h8O91doN018881@thorin.ci.tuwien.ac.at>;
	from zeileis@ci.tuwien.ac.at on Wed, Sep 24, 2003 at 11:01:39
	+0200
References: <C83C5E3DEEE97E498B74729A33F6EAEC6BFAAD@DJFPOST01.djf.agrsci.dk>
	<200309240901.h8O91doN018881@thorin.ci.tuwien.ac.at>
Message-ID: <20030924111339.GA9749@boromir.ci.tuwien.ac.at>

> > Is there an alternative way of "dispatching" the printing, such that
> > the usual print method for loglm is used after doing what is special
> > for hllm?

You might want to have a look at `NextMethod()'

Best,
David



From david.meyer at ci.tuwien.ac.at  Wed Sep 24 13:13:39 2003
From: david.meyer at ci.tuwien.ac.at (David Meyer)
Date: Wed, 24 Sep 2003 13:13:39 +0200
Subject: [R] How to detect which function is used for e.g. printing an
	object of a given class
In-Reply-To: <200309240901.h8O91doN018881@thorin.ci.tuwien.ac.at>;
	from zeileis@ci.tuwien.ac.at on Wed, Sep 24, 2003 at 11:01:39
	+0200
References: <C83C5E3DEEE97E498B74729A33F6EAEC6BFAAD@DJFPOST01.djf.agrsci.dk>
	<200309240901.h8O91doN018881@thorin.ci.tuwien.ac.at>
Message-ID: <20030924111339.GA9749@boromir.ci.tuwien.ac.at>

> > Is there an alternative way of "dispatching" the printing, such that
> > the usual print method for loglm is used after doing what is special
> > for hllm?

You might want to have a look at `NextMethod()'

Best,
David



From p.dalgaard at biostat.ku.dk  Wed Sep 24 13:29:38 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed, 24 Sep 2003 11:29:38 -0000
Subject: [R] Typical R installation problem
In-Reply-To: <200309232027.h8NKRLDd001955@stat.math.ethz.ch>
References: <200309232027.h8NKRLDd001955@stat.math.ethz.ch>
Message-ID: <x2n0cumnjw.fsf@biostat.ku.dk>

mahustonor at comcast.net writes:

> Dear Peter, 
> 
> 	I don't know if this is the proper way to ask for help installing R, but if
> not, I presume you can pass this on to the appropriate place.  
> 
> 	I'm trying to install the latest binary on Redhat 9, and keep getting the same
> error message no matter what I try.  
> 
> [root at localhost mhu]# rpm -i R-1.7.1-1.i386.rpm
> warning: R-1.7.1-1.i386.rpm: V3 DSA signature: NOKEY, key ID 97d3544e
> error: Failed dependencies:
>         libtcl8.3.so is needed by R-1.7.1-1
>         libtk8.3.so is needed by R-1.7.1-1
> [root at localhost mhu]# exit
> 
> I actually found these two files in an obscure location on my computer, and
> copied them to /usr/lib/ I also set my path to include the obscure location.  SO
> they are actually available.  At least when I enter libtcl8.3.so it is
> apparently read and a segmentation fault occurs.  
> 
> So, do you have any suggestions about how to get around this problem.  I don't
> know what else to do to make these routines available to the R install.  
> 
> Any help would be greatly appreciated.  I had no problem installing R on my MAC
> OS 10.1.5.

Shuffling files about without telling RPM about it is not going to
change anything.

You need to *install the RPMs* that contain those files:

[pd at fritz pd]$ rpm -qf /usr/lib/libtcl8.3.so
tcl-8.3.5-88
[pd at fritz pd]$ rpm -qf /usr/lib/libtk8.3.so
tk-8.3.5-88

Granted, that's easier to figure out when you have a system where they
have alredy been installed, but it shouldn't be massively hard to
guess that libtcl comes from tcl and libtk from tk... [When push comes
to shove, go to your installation RPM directory and do something like
"rpm -qlip *.rpm | less", search for the file name and flip back to
the package description]


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ernesto at ipimar.pt  Wed Sep 24 13:46:21 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Wed, 24 Sep 2003 12:46:21 +0100
Subject: [R] plot.ts
Message-ID: <1064403981.9440.27.camel@gandalf.local>

Hi,

How can I force a plot.ts to draw a 2x2 plot matrix instead of 4x1 ?

Regards

EJ



From p.dalgaard at biostat.ku.dk  Wed Sep 24 13:46:39 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed, 24 Sep 2003 11:46:39 -0000
Subject: [R] what does the sum of square of Gaussian RVs with differen t
	variance obey?
In-Reply-To: <3598558AD728D41183350008C7CF291C0F16B938@exchange1.ahrq.gov>
References: <3598558AD728D41183350008C7CF291C0F16B938@exchange1.ahrq.gov>
Message-ID: <x2isnimmrh.fsf@biostat.ku.dk>

RBaskin at ahrq.gov writes:

> This is a relatively recent article that is somewhat accessible.
> Jensen, D. R., and Solomon, Herbert (1994), "Approximations to joint
> distributions of definite quadratic forms", Journal of the American
> Statistical Association, 89 , 480-486
> It has references to previous work.
> 
> I also have an old paper that is so old I can't tell what journal it came
> out of:(
> Grad, Arthur and Solomon, Herbert "Distribution of Quadratic Forms and Some
> Applications" probably published in 55 or 56 but I can't tell.  The paper by
> Grad and Solomon uses the moment generating function to give the exact
> distribution and various approximations to produce a table for a sum of 2 or
> 3 variates.

Looks like this one (courtesy of JSTOR):

    Distribution of Quadratic Forms and Some Applications

        Arthur Grad; Herbert Solomon

        The Annals of Mathematical Statistics, Vol. 26, No. 3. (Sep.,
        1955), pp. 464-477.



-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From Isabelle.ZABALZA-MEZGHANI at ifp.fr  Wed Sep 24 13:53:31 2003
From: Isabelle.ZABALZA-MEZGHANI at ifp.fr (ZABALZA-MEZGHANI Isabelle)
Date: Wed, 24 Sep 2003 13:53:31 +0200
Subject: [R] R binary version for 1.6.2
Message-ID: <488C02265C6AD611BF200002A542182F03F2A729@irnts22.ifp.fr>

Hello,

I would like to know where I can find a Windows binary version of R 1.6.2,
since I want to test the last SJava library (which has been built under
1.6.2) which does not work on R 1.7.1
I've already search on the CRAN web site but on the r1070 page, if I click
on 'old', I get an error.

Thanks in advance,

Isabelle

Isabelle Zabalza-Mezghani
IFP - Reservoir Engineering Department
Rueil-Malmaison, France



From uth at zhwin.ch  Wed Sep 24 14:14:13 2003
From: uth at zhwin.ch (=?iso-8859-1?Q?=22Untern=E4hrer_Thomas=2C_uth=22?=)
Date: Wed, 24 Sep 2003 14:14:13 +0200
Subject: AW: [R] plot.ts
Message-ID: <53A181E56FB0694ABFD212F8AEDA7F6F1AB892@langouste.zhwin.ch>



Maybe like this:

X.ts <- matrix(rnorm(4000),1000,4)
par(mfrow=c(2,2))

apply(X.ts, 2, plot.ts, plot.type=c("single"))

or

apply(X.ts, 2, ts.plot)



HTH


Thomas




>Hi,

>How can I force a plot.ts to draw a 2x2 plot matrix instead of 4x1 ?

>Regards

>EJ

______________________________________________
R-help at stat.math.ethz.ch mailing list https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From andy_liaw at merck.com  Wed Sep 24 14:15:05 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 24 Sep 2003 08:15:05 -0400
Subject: [R] weird behaviour when calling c++
Message-ID: <3A822319EB35174CA3714066D590DCD50205CB8E@usrymx25.merck.com>

This is sort of like calling up an auto mechanic and ask "My car just won't
start.  Can you fix it?"  The answer is almost surely "yes", but not without
looking at the car (or at least get answers on quite a few questions)!
Showing us the code would be a start.

Since you can use gdb to debug the code when run as stand-alone, why not try
running R under gdb and see if you can figure out the problem?

Andy

> -----Original Message-----
> From: Francisco J Molina [mailto:fjmolina at ams.ucsc.edu] 
> Sent: Tuesday, September 23, 2003 10:59 PM
> To: r-help
> Subject: [R] weird behaviour when calling c++
> 
> 
> 
> I am using 1.7.1 in a PC ( redhat 9, linux )
> 
> I created a subroutine in C++, mySubrutine, to be used in R. 
> To debug this subroutine I have a main routine in C++ that 
> calls mySubrutine. The only thing main () does is to provide 
> mySubrutine with its arguments 
> (this is the easiest way for me to debug subroutines written in
> C++ and intended to be used in R ).
> 
> I also have a version of the same program in R: an R script 
> that provides mySubrutine with its arguments. 
> 
> When I run the C++ version in gdb I do not have any problem, 
> every time I run it I get the result ( the same result ). 
> 
> The R script calls mySubrutine through .( ) C. Sometimes it 
> gives me the 
> same result I get in the C++ version; sometimes it freezes. 
> This even happens if I execute the script several times in a 
> row ( I use C-c when it freezes ) Any idea?
> 
> I am using  new and delete in mySubrutine, but I guess this 
> should not be any problem.
> 
> P.S: The first thing the R script executes is rm ( list = ls ( )).
>      To use dyn.unload does not make any difference.
>      
> Thank you.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
>



From Joerg.Schaber at uv.es  Wed Sep 24 14:43:11 2003
From: Joerg.Schaber at uv.es (Joerg Schaber)
Date: Wed, 24 Sep 2003 14:43:11 +0200
Subject: [R] 64-bit Oracle interface
Message-ID: <3F71915F.8010207@uv.es>

Hi,

I am running the 64bit version of R on a AIX RS6000 cluster on which is 
also running the ' SQL*Plus: Release 9.2.0.2.0' in the 
'ORACLE-environment Version 64 bit AIX 5.1'.
I have problems setting up an Oralce database connection.

I can instantiate a driver using  drv <- Oracle(). But when I try to 
connect to my database using dbConnect (dbConnect(drv, dbname="xxx", 
username="xxx", password="xxx")) I get the message:
Error in oraNewConnection(drv, ...) : RS-DBI driver: (ORA-12154: 
TNS:could not resolve service name)

When I use oraNewConnection (oraNewConnection(drv,username="xxx", 
password="xxx")) I get the message:
Error in oraNewConnection(drv, username = "pheno", password = "pheno") :
        RS-DBI driver: (ORA-12541: TNS:no listener)

However, sqlplus works well and the listener is also running.

Any idea what could be the problem here?

joerg



From ahmlatif at yahoo.com  Wed Sep 24 14:45:09 2003
From: ahmlatif at yahoo.com (Mahbub Latif)
Date: Wed, 24 Sep 2003 05:45:09 -0700 (PDT)
Subject: [R] lattice (qqmath) question
Message-ID: <20030924124509.38531.qmail@web41209.mail.yahoo.com>

Hi,

In lattice, is it possible to get qqplot for t
distribution in different panels with different dfs.
For example,

# in panel 1
qqmath(~x, distribution=function(p) qt(p, df=3))

# in panel 2
qqmath(~x, distribution=function(p) qt(p, df=5))

etc...

Thanks,

Mahbub.



From ligges at statistik.uni-dortmund.de  Wed Sep 24 14:56:38 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 24 Sep 2003 14:56:38 +0200
Subject: [R] R binary version for 1.6.2
In-Reply-To: <488C02265C6AD611BF200002A542182F03F2A729@irnts22.ifp.fr>
References: <488C02265C6AD611BF200002A542182F03F2A729@irnts22.ifp.fr>
Message-ID: <3F719486.40601@statistik.uni-dortmund.de>

ZABALZA-MEZGHANI Isabelle wrote:

> Hello,
> 
> I would like to know where I can find a Windows binary version of R 1.6.2,
> since I want to test the last SJava library (which has been built under
> 1.6.2) which does not work on R 1.7.1
> I've already search on the CRAN web site but on the r1070 page, if I click
> on 'old', I get an error.
 >
> Thanks in advance,
> 
> Isabelle


The Windows binary version of R-1.6.2 is no longer available on CRAN.
Nevertheless, http://cran.r-project.org/bin/windows/contrib/1.7/ReadMe 
tells us:

"The packages
   SJava, XML, netCDF, and xgobi
do not build out of the box. Nevertheless these are available at
   http://www.stats.ox.ac.uk/pub/RWin
kindly provided by Professor Brian D. Ripley."

So you *can* get a binary version of the SJava *package* for R-1.7.x.

Uwe Ligges



From m.mader at gsf.de  Wed Sep 24 14:59:24 2003
From: m.mader at gsf.de (Michael Mader)
Date: Wed, 24 Sep 2003 14:59:24 +0200
Subject: [R] 64-bit Oracle interface
References: <3F71915F.8010207@uv.es>
Message-ID: <3F71952C.909B3496@gsf.de>

Hi,

this is clearly not a problem of ROracle but very likely one of the
client configuration/connection stuff.

Is TNS on the client configured correctly (looks like the client cannot
map the server and, hence, does not find the listener; very common
Oracle mistake)?

Regards

Michael
Joerg Schaber wrote:
> 
[...]
> I can instantiate a driver using  drv <- Oracle(). But when I try to
> connect to my database using dbConnect (dbConnect(drv, dbname="xxx",
> username="xxx", password="xxx")) I get the message:
> Error in oraNewConnection(drv, ...) : RS-DBI driver: (ORA-12154:
> TNS:could not resolve service name)
> 
> When I use oraNewConnection (oraNewConnection(drv,username="xxx",
> password="xxx")) I get the message:
> Error in oraNewConnection(drv, username = "pheno", password = "pheno") :
>         RS-DBI driver: (ORA-12541: TNS:no listener)
> 


-- 
Michael T. Mader
Institute for Bioinformatics/MIPS, GSF
Ingolstaedter Landstrasse 1
D-80937 Neuherberg
0049-89-3187-3576
 
In statistics, some people worry about not seeing the forest for the
trees.
I like to look at the bark. (C. R. Blyth, 1967)



From ernesto at ipimar.pt  Wed Sep 24 15:40:36 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Wed, 24 Sep 2003 14:40:36 +0100
Subject: [R] plot.ts doubt
Message-ID: <1064410836.9439.41.camel@gandalf.local>

Hi,

I'm ploting a multivariate time series but I want to change the y
labels. I've tried with ylab but I get an error

> plot(hke.ts,ylab=letters[1:5])
Error in plot.ts(x[, i], axes = FALSE, xlab = "", ylab = "", log = log, 
:
        formal argument "ylab" matched by multiple actual arguments

I've tried to use xy.labels but I also get an error

> plot(hke.ts,xy.labels=letters[1:5])
Warning messages:
1: parameter "xy.labels" couldn't be set in high-level plot() function
2: parameter "xy.labels" couldn't be set in high-level plot() function
3: parameter "xy.labels" couldn't be set in high-level plot() function
4: parameter "xy.labels" couldn't be set in high-level plot() function
5: parameter "xy.labels" couldn't be set in high-level plot() function
6: parameter "xy.labels" couldn't be set in high-level plot() function
7: parameter "xy.labels" couldn't be set in high-level plot() function

What am I missing here ?

Regards

EJ



From Isabelle.ZABALZA-MEZGHANI at ifp.fr  Wed Sep 24 17:27:00 2003
From: Isabelle.ZABALZA-MEZGHANI at ifp.fr (ZABALZA-MEZGHANI Isabelle)
Date: Wed, 24 Sep 2003 17:27:00 +0200
Subject: [R] Problem with memory for large datasets
Message-ID: <488C02265C6AD611BF200002A542182F03F2A731@irnts22.ifp.fr>

Hello,

I would like to know if there is a possibility to "clean" the R memory
during a R session. In fact, I realize a lot of instruction with large
objects (matrix of 500*5000), and I can not manage to achieve the end of my
script due to memory lack. Of course, I've tried to remove all "temporary
object" during the script execution and to perform a garbage collector ...
But it seems to have no effect ...

Any idea to solve this problem without an exit from R ?

Regards

Isabelle

Isabelle Zabalza-Mezghani
IFP - Reservoir Engineering Department
Rueil Malmaison - France



From ligges at statistik.uni-dortmund.de  Wed Sep 24 17:53:13 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 24 Sep 2003 17:53:13 +0200
Subject: [R] Problem with memory for large datasets
In-Reply-To: <488C02265C6AD611BF200002A542182F03F2A731@irnts22.ifp.fr>
References: <488C02265C6AD611BF200002A542182F03F2A731@irnts22.ifp.fr>
Message-ID: <3F71BDE9.40304@statistik.uni-dortmund.de>

ZABALZA-MEZGHANI Isabelle wrote:

> Hello,
> 
> I would like to know if there is a possibility to "clean" the R memory
> during a R session. In fact, I realize a lot of instruction with large
> objects (matrix of 500*5000), and I can not manage to achieve the end of my
> script due to memory lack. Of course, I've tried to remove all "temporary
> object" during the script execution and to perform a garbage collector ...
> But it seems to have no effect ...
> 
> Any idea to solve this problem without an exit from R ?
> 
> Regards
> 
> Isabelle

After you have removed unnecessary objects, the only thing you can do is 
to increase the memory limit R uses (given you are on Windows). See 
?memory.limit for details.
Attention: raising it will cause your system to begin swapping heavily.

The best solution is to buy some more memory and/or optimize your code 
(given that's possible).

Uwe Ligges



From spencer.graves at pdf.com  Wed Sep 24 17:54:40 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 24 Sep 2003 10:54:40 -0500
Subject: [R] Problem with memory for large datasets
In-Reply-To: <488C02265C6AD611BF200002A542182F03F2A731@irnts22.ifp.fr>
References: <488C02265C6AD611BF200002A542182F03F2A731@irnts22.ifp.fr>
Message-ID: <3F71BE40.8020800@pdf.com>

What have you done to remove "temporary objects"?  Does this include 
"rm(list='ls()')"  or "remove(list=objects())"? 

hope this helps.  spencer graves

ZABALZA-MEZGHANI Isabelle wrote:

>Hello,
>
>I would like to know if there is a possibility to "clean" the R memory
>during a R session. In fact, I realize a lot of instruction with large
>objects (matrix of 500*5000), and I can not manage to achieve the end of my
>script due to memory lack. Of course, I've tried to remove all "temporary
>object" during the script execution and to perform a garbage collector ...
>But it seems to have no effect ...
>
>Any idea to solve this problem without an exit from R ?
>
>Regards
>
>Isabelle
>
>Isabelle Zabalza-Mezghani
>IFP - Reservoir Engineering Department
>Rueil Malmaison - France
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From kutinskyv at obninsk.com  Wed Sep 24 18:24:07 2003
From: kutinskyv at obninsk.com (Vladimir N. Kutinsky)
Date: Wed, 24 Sep 2003 20:24:07 +0400
Subject: [R] Problem with memory for large datasets
In-Reply-To: <488C02265C6AD611BF200002A542182F03F2A731@irnts22.ifp.fr>
Message-ID: <KFENLPKGENECNKICCNMBGEIECHAA.kutinskyv@obninsk.com>

Hi,

running gc() helped me a lot

Regards,
Vladimir


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of
> ZABALZA-MEZGHANI Isabelle
> Sent: Wednesday, September 24, 2003 7:27 PM
> To: help R (E-mail)
> Subject: [R] Problem with memory for large datasets
>
>
> Hello,
>
> I would like to know if there is a possibility to "clean" the R memory
> during a R session. In fact, I realize a lot of instruction with large
> objects (matrix of 500*5000), and I can not manage to achieve the
> end of my
> script due to memory lack. Of course, I've tried to remove all "temporary
> object" during the script execution and to perform a garbage collector ...
> But it seems to have no effect ...
>
> Any idea to solve this problem without an exit from R ?
>
> Regards
>
> Isabelle
>
> Isabelle Zabalza-Mezghani
> IFP - Reservoir Engineering Department
> Rueil Malmaison - France
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>



From bates at stat.wisc.edu  Wed Sep 24 18:27:48 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 24 Sep 2003 16:27:48 -0000
Subject: [R] Problem using C random generator called from R
In-Reply-To: <5.2.0.9.0.20030924095631.00ad7f30@mail.cict.fr>
References: <5.2.0.9.0.20030924095631.00ad7f30@mail.cict.fr>
Message-ID: <6r4qz2cfrj.fsf@bates4.stat.wisc.edu>

You need to declare the drand48 function within your C source file.
Either 

#include <stdlib.h>

or

extern double drand48(void);


sebastien.dejean at math.ups-tlse.fr writes:

> Hello
> 
> I'm trying to use C random generator function drand48() which return
> floating-point values, uniformly distributed over [0,1],
> (http://www.opengroup.org/onlinepubs/007908799/xsh/drand48.html). When
> values are returned to R, they are not in [0,1]. A simple C program
> using drand48() gives values in [0,1] so I suppose there is a problem
> (type definition ?) between C and R. Here are R and C function and an
> example.
> 
> 
> # R function
> simulC <- function(n)
>    {
> dyn.load("test.so")
> simR <- runif(n)
> simC <- .C("test",
>         as.integer(n),
>         res=double(n))$res
> out <- list(simR=simR,simC=simC)
> out
> }
> 
> // C function
> void test(int *n,double *res)
> {
>    int i;
>    for(i=0;i<*n;i++) {res[i] = drand48();}
> }
> 
> # Result of x <- simulC(5)
>  > x
> $simR
>   [1] 0.398567942 0.866053345 0.332070718 0.535814830 0.473418784
> $simC
>   [1] -1222291199   211182456  1007036963  1254056690  -646279915
> 
> 
> Any help will be greatly appreciated,
> S?bastien
> 
> 
> 
> --
> S?bastien D?jean ~~~~~~~~~~~
> http://www.lsp.ups-tlse.fr/Fp/Dejean
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/



From Subramanian_Karthikeyan at hc-sc.gc.ca  Wed Sep 24 19:04:04 2003
From: Subramanian_Karthikeyan at hc-sc.gc.ca (Subramanian Karthikeyan)
Date: Wed, 24 Sep 2003 13:04:04 -0400
Subject: [R] splitting clusters
Message-ID: <OFFC4D14A4.85CBB82F-ON85256DAB.005D85A1@hc-sc.gc.ca>

Hi All:

I am clustering 500 genes using hclust of R.  Visualizing cluster
membership becomes difficult with so many genes in each cluster...Is there
a way of printing the dendrogram in multiple pages so that I can clearly
see what is in each cluster?

Thanks in advance.

Karthi.



From Weiming.Zhang at uchsc.edu  Wed Sep 24 19:15:50 2003
From: Weiming.Zhang at uchsc.edu (Weiming Zhang)
Date: Wed, 24 Sep 2003 17:15:50 -0000
Subject: [R] SJava help
Message-ID: <1064423776.32366.10.camel@molecule.uchsc.edu>

Hi,

I installed SJava 0.66-1 on my linux RH 7.2 machine. I am using R-1.7.1.
I set LD_LIBRARY_PATH up then called library(SJava) and it was fine. But
when I called .JavaInit(),  I got weird error that states it could not
find java/lang/Hashtable. The session is below and shows my java
configuration. I am using j2sdk1.4.2_01 from Sun.

Thank you very much.

Weiming Zhang

> .javaConfig
$classPath
[1] "/usr/lib/R/library/SJava/org/omegahat/Jars/Environment.jar"
[2] "/usr/lib/R/library/SJava/org/.."                           
[3] "/usr/lib/R/library/SJava/org/omegahat/Jars/antlr.jar"      
[4] "/usr/lib/R/library/SJava/org/omegahat/Jars/jas.jar"        
[5] "/usr/lib/R/library/SJava/org/omegahat/Jars/jhall.jar"      

$properties
                                                                
EmbeddedInR 
                                                                     
"true" 
                                                      
InterfaceManagerClass 
            
"org/omegahat/Interfaces/NativeInterface/OmegaInterfaceManager" 
                                                  
ForeignReferenceBaseClass 
                                    
"org/omegahat/R/Java/RForeignReference" 
                                                              
java.compiler 
                                                                     
"NONE" 
                                                                 
OMEGA_HOME 
                                    
"/usr/lib/R/library/SJava/org/omegahat" 
                                                         
OmegahatSearchPath 
".,${OMEGA_HOME}/Environment/Scripts/Run,${OMEGA_HOME}/Jars/Environment.jar" 
                                                          
java.library.path 
                                            
"/usr/lib/R/library/SJava/libs" 

$libraryPath
[1] "/usr/lib/R/library/SJava/libs"

$args
character(0)

> .JavaInit()
[1] error initializing manager class can't find class
java/lang/Hashtable
Error in .JavaInit() : Couldn't start Java Virtual Machine: can't find
class java/lang/Hashtable
> 

The output from installation is here and 
I used R INSTALL -c SJavaPackageName:

* Installing *source* package 'SJava' ...
creating cache ./config.cache
checking for java... /opt/lang/java/j2sdk1.4.2_01/bin/java
Java VM /opt/lang/java/j2sdk1.4.2_01/bin/java
checking for javah... /opt/lang/java/j2sdk1.4.2_01/bin/javah
checking for c++... c++
checking whether the C++ compiler (c++  ) works... yes
checking whether the C++ compiler (c++  ) is a cross-compiler... no
checking whether we are using GNU C++... yes
checking whether c++ accepts -g... yes
checking for gcc... gcc
checking whether the C compiler (gcc  ) works... yes
checking whether the C compiler (gcc  ) is a cross-compiler... no
checking whether we are using GNU C... yes
checking whether gcc accepts -g... yes
checking for Rf_initEmbeddedR in -lR... no
No R shared library found
updating cache ./config.cache
creating ./config.status
creating Makevars
creating src/Makevars
creating src/RSJava/Makefile
creating Makefile_rules
creating inst/scripts/RJava.bsh
creating inst/scripts/RJava.csh
creating R/zzz.R
creating cleanup
creating inst/scripts/RJava
Copying the cleanup script to the scripts/ directory
Building libRSNativeJava.so in /tmp/R.INSTALL.30363/SJava/src/RSJava
if  test ! -d /usr/lib/R/library/SJava/libs ; then \
    mkdir /usr/lib/R/library/SJava/libs ; \
fi
gcc -g -O2 -D_R_ -I/usr/lib/R/include -I/usr/lib/R/include/R_ext
-I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I.
-I/tmp/R.INSTALL.30363/SJava/inst/include 
-I/opt/lang/java/j2sdk1.4.2_01/include
-I/opt/lang/java/j2sdk1.4.2_01/include/linux  -c CtoJava.c
gcc -g -O2 -D_R_ -I/usr/lib/R/include -I/usr/lib/R/include/R_ext
-I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I.
-I/tmp/R.INSTALL.30363/SJava/inst/include 
-I/opt/lang/java/j2sdk1.4.2_01/include
-I/opt/lang/java/j2sdk1.4.2_01/include/linux  -c ErrorHandling.c
gcc -g -O2 -D_R_ -I/usr/lib/R/include -I/usr/lib/R/include/R_ext
-I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I.
-I/tmp/R.INSTALL.30363/SJava/inst/include 
-I/opt/lang/java/j2sdk1.4.2_01/include
-I/opt/lang/java/j2sdk1.4.2_01/include/linux  -c ManagerInterfaceUtils.c
gcc -g -O2 -D_R_ -I/usr/lib/R/include -I/usr/lib/R/include/R_ext
-I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I.
-I/tmp/R.INSTALL.30363/SJava/inst/include 
-I/opt/lang/java/j2sdk1.4.2_01/include
-I/opt/lang/java/j2sdk1.4.2_01/include/linux  -c References.c
gcc -g -O2 -D_R_ -I/usr/lib/R/include -I/usr/lib/R/include/R_ext
-I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I.
-I/tmp/R.INSTALL.30363/SJava/inst/include 
-I/opt/lang/java/j2sdk1.4.2_01/include
-I/opt/lang/java/j2sdk1.4.2_01/include/linux  -c JNIUtils.c
gcc -shared  -o libRSNativeJava.so CtoJava.o ErrorHandling.o
ManagerInterfaceUtils.o References.o JNIUtils.o
-L/opt/lang/java/j2sdk1.4.2_01/jre/lib/i386/client
-L/opt/lang/java/j2sdk1.4.2_01/jre/lib/i386
-L/opt/lang/java/j2sdk1.4.2_01/jre/../lib/i386 -ljvm
-L/tmp/R.INSTALL.30363/SJava/inst/libs
-L/opt/lang/java/j2sdk1.4.2_01/jre/lib/i386/client
-L/opt/lang/java/j2sdk1.4.2_01/jre/lib/i386
-L/opt/lang/java/j2sdk1.4.2_01/jre/../lib/i386
-L/usr/lib/R/library/SJava/libs 
if test -n "CtoJava.h ErrorHandling.h JNIUtils.h ManagerInterfaceUtils.h
References.h" ; then cp CtoJava.h ErrorHandling.h JNIUtils.h
ManagerInterfaceUtils.h References.h
/tmp/R.INSTALL.30363/SJava/inst/include ; fi
mv libRSNativeJava.so /tmp/R.INSTALL.30363/SJava/inst/libs
Generating JNI header files from Java classes.
   RForeignReference, RManualFunctionActionListener,
ROmegahatInterpreter & REvaluator
*************
Warning:
    At present, to use the library you must set the 
    LD_LIBRARY_PATH environment variable
    to
     
/usr/lib/R/library/SJava/libs:/opt/lang/java/j2sdk1.4.2_01/jre/lib/i386/client:/opt/lang/java/j2sdk1.4.2_01/jre/lib/i386:/opt/lang/java/j2sdk1.4.2_01/jre/../lib/i386:
    or use one of the RJava.bsh or RJava.csh scripts
*************
** libs
gcc -I/usr/lib/R/include -D_R_ -I/usr/lib/R/include
-I/usr/lib/R/include/R_ext -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I.
-I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava
-I/opt/lang/java/j2sdk1.4.2_01/include
-I/opt/lang/java/j2sdk1.4.2_01/include/linux -I/usr/local/include
-D__NO_MATH_INLINES -mieee-fp  -fPIC  -O2 -m486 -fno-strength-reduce -g
-c ConverterExamples.c -o ConverterExamples.o
gcc -I/usr/lib/R/include -D_R_ -I/usr/lib/R/include
-I/usr/lib/R/include/R_ext -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I.
-I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava
-I/opt/lang/java/j2sdk1.4.2_01/include
-I/opt/lang/java/j2sdk1.4.2_01/include/linux -I/usr/local/include
-D__NO_MATH_INLINES -mieee-fp  -fPIC  -O2 -m486 -fno-strength-reduce -g
-c Converters.c -o Converters.o
gcc -I/usr/lib/R/include -D_R_ -I/usr/lib/R/include
-I/usr/lib/R/include/R_ext -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I.
-I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava
-I/opt/lang/java/j2sdk1.4.2_01/include
-I/opt/lang/java/j2sdk1.4.2_01/include/linux -I/usr/local/include
-D__NO_MATH_INLINES -mieee-fp  -fPIC  -O2 -m486 -fno-strength-reduce -g
-c Reflectance.c -o Reflectance.o
gcc -I/usr/lib/R/include -D_R_ -I/usr/lib/R/include
-I/usr/lib/R/include/R_ext -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I.
-I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava
-I/opt/lang/java/j2sdk1.4.2_01/include
-I/opt/lang/java/j2sdk1.4.2_01/include/linux -I/usr/local/include
-D__NO_MATH_INLINES -mieee-fp  -fPIC  -O2 -m486 -fno-strength-reduce -g
-c REmbed.c -o REmbed.o
gcc -I/usr/lib/R/include -D_R_ -I/usr/lib/R/include
-I/usr/lib/R/include/R_ext -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I.
-I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava
-I/opt/lang/java/j2sdk1.4.2_01/include
-I/opt/lang/java/j2sdk1.4.2_01/include/linux -I/usr/local/include
-D__NO_MATH_INLINES -mieee-fp  -fPIC  -O2 -m486 -fno-strength-reduce -g
-c REmbedWin.c -o REmbedWin.o
gcc -I/usr/lib/R/include -D_R_ -I/usr/lib/R/include
-I/usr/lib/R/include/R_ext -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I.
-I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava
-I/opt/lang/java/j2sdk1.4.2_01/include
-I/opt/lang/java/j2sdk1.4.2_01/include/linux -I/usr/local/include
-D__NO_MATH_INLINES -mieee-fp  -fPIC  -O2 -m486 -fno-strength-reduce -g
-c REval.c -o REval.o
gcc -I/usr/lib/R/include -D_R_ -I/usr/lib/R/include
-I/usr/lib/R/include/R_ext -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I.
-I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava
-I/opt/lang/java/j2sdk1.4.2_01/include
-I/opt/lang/java/j2sdk1.4.2_01/include/linux -I/usr/local/include
-D__NO_MATH_INLINES -mieee-fp  -fPIC  -O2 -m486 -fno-strength-reduce -g
-c RFunctionListener.c -o RFunctionListener.o
gcc -I/usr/lib/R/include -D_R_ -I/usr/lib/R/include
-I/usr/lib/R/include/R_ext -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I.
-I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava
-I/opt/lang/java/j2sdk1.4.2_01/include
-I/opt/lang/java/j2sdk1.4.2_01/include/linux -I/usr/local/include
-D__NO_MATH_INLINES -mieee-fp  -fPIC  -O2 -m486 -fno-strength-reduce -g
-c RReferenceCall.c -o RReferenceCall.o
gcc -I/usr/lib/R/include -D_R_ -I/usr/lib/R/include
-I/usr/lib/R/include/R_ext -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I.
-I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava
-I/opt/lang/java/j2sdk1.4.2_01/include
-I/opt/lang/java/j2sdk1.4.2_01/include/linux -I/usr/local/include
-D__NO_MATH_INLINES -mieee-fp  -fPIC  -O2 -m486 -fno-strength-reduce -g
-c RStoJava.c -o RStoJava.o
gcc -I/usr/lib/R/include -D_R_ -I/usr/lib/R/include
-I/usr/lib/R/include/R_ext -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I.
-I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava
-I/opt/lang/java/j2sdk1.4.2_01/include
-I/opt/lang/java/j2sdk1.4.2_01/include/linux -I/usr/local/include
-D__NO_MATH_INLINES -mieee-fp  -fPIC  -O2 -m486 -fno-strength-reduce -g
-c RtoJava.c -o RtoJava.o
gcc -shared -L/usr/local/lib -o SJava.so ConverterExamples.o
Converters.o Reflectance.o REmbed.o REmbedWin.o REval.o
RFunctionListener.o RReferenceCall.o RStoJava.o RtoJava.o
-L/tmp/R.INSTALL.30363/SJava/inst/libs
-L/opt/lang/java/j2sdk1.4.2_01/jre/lib/i386/client
-L/opt/lang/java/j2sdk1.4.2_01/jre/lib/i386
-L/opt/lang/java/j2sdk1.4.2_01/jre/../lib/i386
-L/usr/lib/R/library/SJava/libs -lRSNativeJava -ljvm    
** R
** inst
** help
 >>> Building/Updating help pages for package 'SJava'
     Formats: text html latex example 
  Array                             text    html    latex   example
  Dollar                            text    html    latex   example
  DotJavaSigs                       text    html    latex
  DotjavaConfig                     text    html    latex
  JClass                            text    html    latex   example
  Java                              text    html    latex   example
  JavaConstructor                   text    html    latex   example
  JavaInit                          text    html    latex   example
  JavaTerminate                     text    html    latex   example
  OmegahatExpression                text    html    latex   example
  RSJava.symbol                     text    html    latex   example
  RtoJavaSig                        text    html    latex   example
  expandClassName                   text    html    latex   example
  foreignReference                  text    html    latex   example
  getForeignReferences              text    html    latex   example
  getJavaConverterDescriptions      text    html    latex   example
  getJavaHandler                    text    html    latex   example
  getMethods                        text    html    latex   example
  getNumJavaConverters              text    html    latex   example
  interfaceGenerator                text    html    latex   example
  isJavaInitialized                 text    html    latex   example
  javaConfig                        text    html    latex   example
  javaHandlerGenerator              text    html    latex   example
  javaIs                            text    html    latex   example
  javaMatchFunctions                text    html    latex
  javaSig                           text    html    latex   example
  jdynamicCompile                   text    html    latex   example
  mergePath                         text    html    latex   example
  mergeProperties                   text    html    latex   example
  omegahatReference                 text    html    latex   example
  removeJavaConverter               text    html    latex   example
  setConvertible                    text    html    latex   example
  setJavaConverter                  text    html    latex   example
  setJavaFunctionConverter          text    html    latex   example
  setJavaHandler                    text    html    latex   example
     missing link(s):  javaHandlerGenerator()
Creating the symbolic link for libSJava.so in
/usr/lib/R/library/SJava/libs/
* DONE (SJava)

* DONE (INSTALL)



From christoph.lehmann at gmx.ch  Wed Sep 24 19:34:11 2003
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Wed, 24 Sep 2003 19:34:11 +0200
Subject: [R] storing objects (lm results) in an array
Message-ID: <1064424850.2620.28.camel@christophl>

Hi

I have calculated lots (>1000) of linear models and would like to store
each single result as an element of a 3D matrix or a similar storage:
something like

glm[i][j][k] = lm(...)

Since I read that results are lists: Is it possible to define a matrix
of type list? 

Or what do you recommend?

Many thanks

Christoph
-- 
Christoph Lehmann <christoph.lehmann at gmx.ch>



From jasont at indigoindustrial.co.nz  Wed Sep 24 19:50:20 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Wed, 24 Sep 2003 17:50:20 -0000
Subject: [R] storing objects (lm results) in an array
In-Reply-To: <1064424850.2620.28.camel@christophl>
References: <1064424850.2620.28.camel@christophl>
Message-ID: <1064426304.5435.23.camel@kryten.akl.indigoindustrial.co.nz>

On Thu, 2003-09-25 at 05:34, Christoph Lehmann wrote:
> Hi
> 
> I have calculated lots (>1000) of linear models and would like to store
> each single result as an element of a 3D matrix or a similar storage:
> something like
> 
> glm[i][j][k] = lm(...)
> 
> Since I read that results are lists: Is it possible to define a matrix
> of type list? 
> 
> Or what do you recommend?

1) glm is already a function name in R.  I'd suggest a different name.

2) I don't recommend a matrix.  Matricies require contiguous memory
chunks - it's possible to not have a long enough "block" of memory
available, even when the total free memory is sufficient, when storing
large matricies.

What's wrong with nested lists?  Something like my.lms[[i]][[j]][[k]] <-
lm(...)

This can "scatter" its storage across discontinuous chunks of memory.

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
+64-(0)21-343-545



From spencer.graves at pdf.com  Wed Sep 24 20:27:38 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 24 Sep 2003 13:27:38 -0500
Subject: [R] storing objects (lm results) in an array
In-Reply-To: <1064426304.5435.23.camel@kryten.akl.indigoindustrial.co.nz>
References: <1064424850.2620.28.camel@christophl>
	<1064426304.5435.23.camel@kryten.akl.indigoindustrial.co.nz>
Message-ID: <3F71E21A.4090304@pdf.com>

As you noted, the output of, e.g., "lm" is a list.  When I've done many 
fits like this, I've usely been interested in only a few components of 
the list.  In that case, I first construct a matrix or higher 
dimensional array and then store what I want in that array.  Example: 

 > DF0 <- data.frame(y1=rnorm(9), y2=rnorm(9))
 > coefs <- array(NA, dim=c(2, 1))
 > for(i in 1:2){
+ mdl <- paste("y", i, " ~ 1", sep="")
+ fit <- lm(formula(mdl), DF0)
+ coefs[i,] <- fit$coefficients
+ }
 > coefs
           [,1]
[1,]  0.5439368
[2,] -0.1862047

hope this helps.  spencer graves

Jason Turner wrote:

>On Thu, 2003-09-25 at 05:34, Christoph Lehmann wrote:
>  
>
>>Hi
>>
>>I have calculated lots (>1000) of linear models and would like to store
>>each single result as an element of a 3D matrix or a similar storage:
>>something like
>>
>>glm[i][j][k] = lm(...)
>>
>>Since I read that results are lists: Is it possible to define a matrix
>>of type list? 
>>
>>Or what do you recommend?
>>    
>>
>
>1) glm is already a function name in R.  I'd suggest a different name.
>
>2) I don't recommend a matrix.  Matricies require contiguous memory
>chunks - it's possible to not have a long enough "block" of memory
>available, even when the total free memory is sufficient, when storing
>large matricies.
>
>What's wrong with nested lists?  Something like my.lms[[i]][[j]][[k]] <-
>lm(...)
>
>This can "scatter" its storage across discontinuous chunks of memory.
>
>Cheers
>
>Jason
>  
>



From jasont at indigoindustrial.co.nz  Wed Sep 24 20:28:50 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Wed, 24 Sep 2003 18:28:50 -0000
Subject: [R] models with I(1) errors
In-Reply-To: <005f01c3826d$ecfaa040$5c13070a@GIUSTIZIA.IT>
References: <2A23A3B738DB3E47BD676EDC51C064D1012034B0@iris.nswcc.org.au>
	<005f01c3826d$ecfaa040$5c13070a@GIUSTIZIA.IT>
Message-ID: <1064428667.5444.55.camel@kryten.akl.indigoindustrial.co.nz>

On Wed, 2003-09-24 at 19:31, Vito Muggeo wrote:
> Dear all,
> I'm interested in fitting time-series linear models with I(1) errors. Namely
> given
> y_t=a+b*t+u_t
> the random term u_t are such that
> u_t-u_{t-1}=e_t~iid N(0,\sigma)
> 

library(nlme)
help(lme)  #note the optional correlation argument
help(corClasses)

You can specify AR(1) (among other) correlation structures in the error
term with lme().

The cannonical reference for the nlme library is

@Book{
  PinheiroBates2000,
  author =	 {Jos\'e C. Pinheiro and Douglas M. Bates},
  title =	 {Mixed-Effects Models in S and S-PLUS},
  publisher =	 {Springer-Verlag},
  year =	 {2000},
  address =	 {New York}
}

Cheers

Jason


-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
+64-(0)21-343-545



From hb at maths.lth.se  Wed Sep 24 20:42:56 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Wed, 24 Sep 2003 20:42:56 +0200
Subject: [R] SJava help
In-Reply-To: <1064423776.32366.10.camel@molecule.uchsc.edu>
Message-ID: <000c01c382cb$acaee1a0$800040d5@maths.lth.se>

Hi, I do not have Linux myself but looking at your error message

> > .JavaInit()
> [1] error initializing manager class can't find class 
> java/lang/Hashtable Error in .JavaInit() : Couldn't start 
> Java Virtual Machine: can't find class java/lang/Hashtable
> > 

it looks like you have not set the JAVA_HOME variable correctly. On a
Windows XP machine you will get the error (together with a popup
dialog):

> library(SJava)
using JAVA_HOME = /c/Program Files/Java/j2sdk1.4.0_02
Error in dyn.load(x, as.logical(local), as.logical(now)) :
        unable to load shared library
"c:/PROGRA~1/R/rw1071/library/SJava/libs/S
Java.dll":
  LoadLibrary failure:  The specified module could not be found.
Error in library(SJava) : .First.lib failed
>

See help(.Renviron) how to set the JAVA_HOME environment variable. 

***Note*** on Windows XP (and maybe on other systems too) you have to
set JAVA_HOME differently if you have i) Java Runtime Edition or the ii)
Java SDK. For Java SDK, which you have, you have to set

  JAVA_HOME=C:/Program Files/Java/j2sdk1.4.0_02/jre/

and not to

  JAVA_HOME=C:/Program Files/Java/j2sdk1.4.0_02/

as one would guess. But with Java Runtime Edition you should do

  JAVA_HOME=C:/Program Files/Java/j2re1.4.1_02/

If you use ~/.Renviron it won't mess with your other settings. 

Again, I'm not sure if this applies to Linux, but it's worth a try.

Cheers

Henrik Bengtsson


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Weiming Zhang
> Sent: den 24 september 2003 19:16
> To: R-help at stat.math.ethz.ch
> Subject: [R] SJava help
> 
> 
> Hi,
> 
> I installed SJava 0.66-1 on my linux RH 7.2 machine. I am 
> using R-1.7.1. I set LD_LIBRARY_PATH up then called 
> library(SJava) and it was fine. But when I called 
> .JavaInit(),  I got weird error that states it could not find 
> java/lang/Hashtable. The session is below and shows my java 
> configuration. I am using j2sdk1.4.2_01 from Sun.
> 
> Thank you very much.
> 
> Weiming Zhang
> 
> > .javaConfig
> $classPath
> [1] "/usr/lib/R/library/SJava/org/omegahat/Jars/Environment.jar"
> [2] "/usr/lib/R/library/SJava/org/.."                           
> [3] "/usr/lib/R/library/SJava/org/omegahat/Jars/antlr.jar"      
> [4] "/usr/lib/R/library/SJava/org/omegahat/Jars/jas.jar"        
> [5] "/usr/lib/R/library/SJava/org/omegahat/Jars/jhall.jar"      
> 
> $properties
>                                                                 
> EmbeddedInR 
>                                                                      
> "true" 
>                                                       
> InterfaceManagerClass 
>             
> "org/omegahat/Interfaces/NativeInterface/OmegaInterfaceManager" 
>                                                   
> ForeignReferenceBaseClass 
>                                     
> "org/omegahat/R/Java/RForeignReference" 
>                                                               
> java.compiler 
>                                                                      
> "NONE" 
>                                                                  
> OMEGA_HOME 
>                                     
> "/usr/lib/R/library/SJava/org/omegahat" 
>                                                          
> OmegahatSearchPath 
> ".,${OMEGA_HOME}/Environment/Scripts/Run,${OMEGA_HOME}/Jars/En
> vironment.jar" 
>                                                           
> java.library.path 
>                                             
> "/usr/lib/R/library/SJava/libs" 
> 
> $libraryPath
> [1] "/usr/lib/R/library/SJava/libs"
> 
> $args
> character(0)
> 
> > .JavaInit()
> [1] error initializing manager class can't find class 
> java/lang/Hashtable Error in .JavaInit() : Couldn't start 
> Java Virtual Machine: can't find class java/lang/Hashtable
> > 
> 
> The output from installation is here and 
> I used R INSTALL -c SJavaPackageName:
> 
> * Installing *source* package 'SJava' ...
> creating cache ./config.cache
> checking for java... /opt/lang/java/j2sdk1.4.2_01/bin/java
> Java VM /opt/lang/java/j2sdk1.4.2_01/bin/java
> checking for javah... /opt/lang/java/j2sdk1.4.2_01/bin/javah
> checking for c++... c++
> checking whether the C++ compiler (c++  ) works... yes
> checking whether the C++ compiler (c++  ) is a 
> cross-compiler... no checking whether we are using GNU C++... 
> yes checking whether c++ accepts -g... yes checking for 
> gcc... gcc checking whether the C compiler (gcc  ) works... 
> yes checking whether the C compiler (gcc  ) is a 
> cross-compiler... no checking whether we are using GNU C... 
> yes checking whether gcc accepts -g... yes checking for 
> Rf_initEmbeddedR in -lR... no No R shared library found 
> updating cache ./config.cache creating ./config.status 
> creating Makevars creating src/Makevars creating 
> src/RSJava/Makefile creating Makefile_rules creating 
> inst/scripts/RJava.bsh creating inst/scripts/RJava.csh 
> creating R/zzz.R creating cleanup creating inst/scripts/RJava 
> Copying the cleanup script to the scripts/ directory Building 
> libRSNativeJava.so in /tmp/R.INSTALL.30363/SJava/src/RSJava
> if  test ! -d /usr/lib/R/library/SJava/libs ; then \
>     mkdir /usr/lib/R/library/SJava/libs ; \
> fi
> gcc -g -O2 -D_R_ -I/usr/lib/R/include 
> -I/usr/lib/R/include/R_ext 
> -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> -I/tmp/R.INSTALL.30363/SJava/inst/include 
> -I/opt/lang/java/j2sdk1.4.2_01/include
> -I/opt/lang/java/j2sdk1.4.2_01/include/linux  -c CtoJava.c
> gcc -g -O2 -D_R_ -I/usr/lib/R/include 
> -I/usr/lib/R/include/R_ext 
> -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> -I/tmp/R.INSTALL.30363/SJava/inst/include 
> -I/opt/lang/java/j2sdk1.4.2_01/include
> -I/opt/lang/java/j2sdk1.4.2_01/include/linux  -c 
> ErrorHandling.c gcc -g -O2 -D_R_ -I/usr/lib/R/include 
> -I/usr/lib/R/include/R_ext 
> -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> -I/tmp/R.INSTALL.30363/SJava/inst/include 
> -I/opt/lang/java/j2sdk1.4.2_01/include
> -I/opt/lang/java/j2sdk1.4.2_01/include/linux  -c 
> ManagerInterfaceUtils.c gcc -g -O2 -D_R_ -I/usr/lib/R/include 
> -I/usr/lib/R/include/R_ext 
> -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> -I/tmp/R.INSTALL.30363/SJava/inst/include 
> -I/opt/lang/java/j2sdk1.4.2_01/include
> -I/opt/lang/java/j2sdk1.4.2_01/include/linux  -c References.c 
> gcc -g -O2 -D_R_ -I/usr/lib/R/include 
> -I/usr/lib/R/include/R_ext 
> -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> -I/tmp/R.INSTALL.30363/SJava/inst/include 
> -I/opt/lang/java/j2sdk1.4.2_01/include
> -I/opt/lang/java/j2sdk1.4.2_01/include/linux  -c JNIUtils.c
> gcc -shared  -o libRSNativeJava.so CtoJava.o ErrorHandling.o 
> ManagerInterfaceUtils.o References.o JNIUtils.o 
> -L/opt/lang/java/j2sdk1.4.2_01/jre/lib/i386/client
> -L/opt/lang/java/j2sdk1.4.2_01/jre/lib/i386
> -L/opt/lang/java/j2sdk1.4.2_01/jre/../lib/i386 -ljvm 
> -L/tmp/R.INSTALL.30363/SJava/inst/libs
> -L/opt/lang/java/j2sdk1.4.2_01/jre/lib/i386/client
> -L/opt/lang/java/j2sdk1.4.2_01/jre/lib/i386
> -L/opt/lang/java/j2sdk1.4.2_01/jre/../lib/i386
> -L/usr/lib/R/library/SJava/libs 
> if test -n "CtoJava.h ErrorHandling.h JNIUtils.h 
> ManagerInterfaceUtils.h References.h" ; then cp CtoJava.h 
> ErrorHandling.h JNIUtils.h ManagerInterfaceUtils.h 
> References.h /tmp/R.INSTALL.30363/SJava/inst/include ; fi mv 
> libRSNativeJava.so /tmp/R.INSTALL.30363/SJava/inst/libs
> Generating JNI header files from Java classes.
>    RForeignReference, RManualFunctionActionListener, 
> ROmegahatInterpreter & REvaluator
> *************
> Warning:
>     At present, to use the library you must set the 
>     LD_LIBRARY_PATH environment variable
>     to
>      
> /usr/lib/R/library/SJava/libs:/opt/lang/java/j2sdk1.4.2_01/jre
/lib/i386/client:/opt/lang/java/j2sdk1.4.2_>
01/jre/lib/i386:/opt/lang/java/j2sdk1.4.2_01/jre/../lib/i386:
>     or use one of the RJava.bsh or RJava.csh scripts
> *************
> ** libs
> gcc -I/usr/lib/R/include -D_R_ -I/usr/lib/R/include 
> -I/usr/lib/R/include/R_ext 
> -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> -I/opt/lang/java/j2sdk1.4.2_01/include
> -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> -O2 -m486 -fno-strength-reduce -g -c ConverterExamples.c -o 
> ConverterExamples.o gcc -I/usr/lib/R/include -D_R_ 
> -I/usr/lib/R/include -I/usr/lib/R/include/R_ext 
> -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> -I/opt/lang/java/j2sdk1.4.2_01/include
> -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> -O2 -m486 -fno-strength-reduce -g -c Converters.c -o 
> Converters.o gcc -I/usr/lib/R/include -D_R_ 
> -I/usr/lib/R/include -I/usr/lib/R/include/R_ext 
> -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> -I/opt/lang/java/j2sdk1.4.2_01/include
> -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> -O2 -m486 -fno-strength-reduce -g -c Reflectance.c -o 
> Reflectance.o gcc -I/usr/lib/R/include -D_R_ 
> -I/usr/lib/R/include -I/usr/lib/R/include/R_ext 
> -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> -I/opt/lang/java/j2sdk1.4.2_01/include
> -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> -O2 -m486 -fno-strength-reduce -g -c REmbed.c -o REmbed.o gcc 
> -I/usr/lib/R/include -D_R_ -I/usr/lib/R/include 
> -I/usr/lib/R/include/R_ext 
> -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> -I/opt/lang/java/j2sdk1.4.2_01/include
> -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> -O2 -m486 -fno-strength-reduce -g -c REmbedWin.c -o 
> REmbedWin.o gcc -I/usr/lib/R/include -D_R_ 
> -I/usr/lib/R/include -I/usr/lib/R/include/R_ext 
> -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> -I/opt/lang/java/j2sdk1.4.2_01/include
> -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> -O2 -m486 -fno-strength-reduce -g -c REval.c -o REval.o gcc 
> -I/usr/lib/R/include -D_R_ -I/usr/lib/R/include 
> -I/usr/lib/R/include/R_ext 
> -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> -I/opt/lang/java/j2sdk1.4.2_01/include
> -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> -O2 -m486 -fno-strength-reduce -g -c RFunctionListener.c -o 
> RFunctionListener.o gcc -I/usr/lib/R/include -D_R_ 
> -I/usr/lib/R/include -I/usr/lib/R/include/R_ext 
> -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> -I/opt/lang/java/j2sdk1.4.2_01/include
> -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> -O2 -m486 -fno-strength-reduce -g -c RReferenceCall.c -o 
> RReferenceCall.o gcc -I/usr/lib/R/include -D_R_ 
> -I/usr/lib/R/include -I/usr/lib/R/include/R_ext 
> -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> -I/opt/lang/java/j2sdk1.4.2_01/include
> -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> -O2 -m486 -fno-strength-reduce -g -c RStoJava.c -o RStoJava.o 
> gcc -I/usr/lib/R/include -D_R_ -I/usr/lib/R/include 
> -I/usr/lib/R/include/R_ext 
> -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> -I/opt/lang/java/j2sdk1.4.2_01/include
> -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> -O2 -m486 -fno-strength-reduce -g -c RtoJava.c -o RtoJava.o 
> gcc -shared -L/usr/local/lib -o SJava.so ConverterExamples.o 
> Converters.o Reflectance.o REmbed.o REmbedWin.o REval.o 
> RFunctionListener.o RReferenceCall.o RStoJava.o RtoJava.o 
> -L/tmp/R.INSTALL.30363/SJava/inst/libs
> -L/opt/lang/java/j2sdk1.4.2_01/jre/lib/i386/client
> -L/opt/lang/java/j2sdk1.4.2_01/jre/lib/i386
> -L/opt/lang/java/j2sdk1.4.2_01/jre/../lib/i386
> -L/usr/lib/R/library/SJava/libs -lRSNativeJava -ljvm    
> ** R
> ** inst
> ** help
>  >>> Building/Updating help pages for package 'SJava'
>      Formats: text html latex example 
>   Array                             text    html    latex   example
>   Dollar                            text    html    latex   example
>   DotJavaSigs                       text    html    latex
>   DotjavaConfig                     text    html    latex
>   JClass                            text    html    latex   example
>   Java                              text    html    latex   example
>   JavaConstructor                   text    html    latex   example
>   JavaInit                          text    html    latex   example
>   JavaTerminate                     text    html    latex   example
>   OmegahatExpression                text    html    latex   example
>   RSJava.symbol                     text    html    latex   example
>   RtoJavaSig                        text    html    latex   example
>   expandClassName                   text    html    latex   example
>   foreignReference                  text    html    latex   example
>   getForeignReferences              text    html    latex   example
>   getJavaConverterDescriptions      text    html    latex   example
>   getJavaHandler                    text    html    latex   example
>   getMethods                        text    html    latex   example
>   getNumJavaConverters              text    html    latex   example
>   interfaceGenerator                text    html    latex   example
>   isJavaInitialized                 text    html    latex   example
>   javaConfig                        text    html    latex   example
>   javaHandlerGenerator              text    html    latex   example
>   javaIs                            text    html    latex   example
>   javaMatchFunctions                text    html    latex
>   javaSig                           text    html    latex   example
>   jdynamicCompile                   text    html    latex   example
>   mergePath                         text    html    latex   example
>   mergeProperties                   text    html    latex   example
>   omegahatReference                 text    html    latex   example
>   removeJavaConverter               text    html    latex   example
>   setConvertible                    text    html    latex   example
>   setJavaConverter                  text    html    latex   example
>   setJavaFunctionConverter          text    html    latex   example
>   setJavaHandler                    text    html    latex   example
>      missing link(s):  javaHandlerGenerator()
> Creating the symbolic link for libSJava.so in 
> /usr/lib/R/library/SJava/libs/
> * DONE (SJava)
> 
> * DONE (INSTALL)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> 
>



From Weiming.Zhang at uchsc.edu  Wed Sep 24 20:54:43 2003
From: Weiming.Zhang at uchsc.edu (Weiming Zhang)
Date: Wed, 24 Sep 2003 18:54:43 -0000
Subject: [R] SJava help
In-Reply-To: <000c01c382cb$acaee1a0$800040d5@maths.lth.se>
References: <000c01c382cb$acaee1a0$800040d5@maths.lth.se>
Message-ID: <1064429705.32366.17.camel@molecule.uchsc.edu>

Hi, Henrik,

Thank you very much for replying.

I actually have the JAVA_HOME environment variable set in a linux shell
script .bash_profile which set up all of my development environment
before I install this SJava package and it points to the current java
cdk I am using. So it is weird that R could not find the common java
libraries. Do you think I need to use .Renviron instead of
.bash_profile?

Weiming
 
On Wed, 2003-09-24 at 12:42, Henrik Bengtsson wrote:
> Hi, I do not have Linux myself but looking at your error message
> 
> > > .JavaInit()
> > [1] error initializing manager class can't find class 
> > java/lang/Hashtable Error in .JavaInit() : Couldn't start 
> > Java Virtual Machine: can't find class java/lang/Hashtable
> > > 
> 
> it looks like you have not set the JAVA_HOME variable correctly. On a
> Windows XP machine you will get the error (together with a popup
> dialog):
> 
> > library(SJava)
> using JAVA_HOME = /c/Program Files/Java/j2sdk1.4.0_02
> Error in dyn.load(x, as.logical(local), as.logical(now)) :
>         unable to load shared library
> "c:/PROGRA~1/R/rw1071/library/SJava/libs/S
> Java.dll":
>   LoadLibrary failure:  The specified module could not be found.
> Error in library(SJava) : .First.lib failed
> >
> 
> See help(.Renviron) how to set the JAVA_HOME environment variable. 
> 
> ***Note*** on Windows XP (and maybe on other systems too) you have to
> set JAVA_HOME differently if you have i) Java Runtime Edition or the ii)
> Java SDK. For Java SDK, which you have, you have to set
> 
>   JAVA_HOME=C:/Program Files/Java/j2sdk1.4.0_02/jre/
> 
> and not to
> 
>   JAVA_HOME=C:/Program Files/Java/j2sdk1.4.0_02/
> 
> as one would guess. But with Java Runtime Edition you should do
> 
>   JAVA_HOME=C:/Program Files/Java/j2re1.4.1_02/
> 
> If you use ~/.Renviron it won't mess with your other settings. 
> 
> Again, I'm not sure if this applies to Linux, but it's worth a try.
> 
> Cheers
> 
> Henrik Bengtsson
> 
> 
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch 
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Weiming Zhang
> > Sent: den 24 september 2003 19:16
> > To: R-help at stat.math.ethz.ch
> > Subject: [R] SJava help
> > 
> > 
> > Hi,
> > 
> > I installed SJava 0.66-1 on my linux RH 7.2 machine. I am 
> > using R-1.7.1. I set LD_LIBRARY_PATH up then called 
> > library(SJava) and it was fine. But when I called 
> > .JavaInit(),  I got weird error that states it could not find 
> > java/lang/Hashtable. The session is below and shows my java 
> > configuration. I am using j2sdk1.4.2_01 from Sun.
> > 
> > Thank you very much.
> > 
> > Weiming Zhang
> > 
> > > .javaConfig
> > $classPath
> > [1] "/usr/lib/R/library/SJava/org/omegahat/Jars/Environment.jar"
> > [2] "/usr/lib/R/library/SJava/org/.."                           
> > [3] "/usr/lib/R/library/SJava/org/omegahat/Jars/antlr.jar"      
> > [4] "/usr/lib/R/library/SJava/org/omegahat/Jars/jas.jar"        
> > [5] "/usr/lib/R/library/SJava/org/omegahat/Jars/jhall.jar"      
> > 
> > $properties
> >                                                                 
> > EmbeddedInR 
> >                                                                      
> > "true" 
> >                                                       
> > InterfaceManagerClass 
> >             
> > "org/omegahat/Interfaces/NativeInterface/OmegaInterfaceManager" 
> >                                                   
> > ForeignReferenceBaseClass 
> >                                     
> > "org/omegahat/R/Java/RForeignReference" 
> >                                                               
> > java.compiler 
> >                                                                      
> > "NONE" 
> >                                                                  
> > OMEGA_HOME 
> >                                     
> > "/usr/lib/R/library/SJava/org/omegahat" 
> >                                                          
> > OmegahatSearchPath 
> > ".,${OMEGA_HOME}/Environment/Scripts/Run,${OMEGA_HOME}/Jars/En
> > vironment.jar" 
> >                                                           
> > java.library.path 
> >                                             
> > "/usr/lib/R/library/SJava/libs" 
> > 
> > $libraryPath
> > [1] "/usr/lib/R/library/SJava/libs"
> > 
> > $args
> > character(0)
> > 
> > > .JavaInit()
> > [1] error initializing manager class can't find class 
> > java/lang/Hashtable Error in .JavaInit() : Couldn't start 
> > Java Virtual Machine: can't find class java/lang/Hashtable
> > > 
> > 
> > The output from installation is here and 
> > I used R INSTALL -c SJavaPackageName:
> > 
> > * Installing *source* package 'SJava' ...
> > creating cache ./config.cache
> > checking for java... /opt/lang/java/j2sdk1.4.2_01/bin/java
> > Java VM /opt/lang/java/j2sdk1.4.2_01/bin/java
> > checking for javah... /opt/lang/java/j2sdk1.4.2_01/bin/javah
> > checking for c++... c++
> > checking whether the C++ compiler (c++  ) works... yes
> > checking whether the C++ compiler (c++  ) is a 
> > cross-compiler... no checking whether we are using GNU C++... 
> > yes checking whether c++ accepts -g... yes checking for 
> > gcc... gcc checking whether the C compiler (gcc  ) works... 
> > yes checking whether the C compiler (gcc  ) is a 
> > cross-compiler... no checking whether we are using GNU C... 
> > yes checking whether gcc accepts -g... yes checking for 
> > Rf_initEmbeddedR in -lR... no No R shared library found 
> > updating cache ./config.cache creating ./config.status 
> > creating Makevars creating src/Makevars creating 
> > src/RSJava/Makefile creating Makefile_rules creating 
> > inst/scripts/RJava.bsh creating inst/scripts/RJava.csh 
> > creating R/zzz.R creating cleanup creating inst/scripts/RJava 
> > Copying the cleanup script to the scripts/ directory Building 
> > libRSNativeJava.so in /tmp/R.INSTALL.30363/SJava/src/RSJava
> > if  test ! -d /usr/lib/R/library/SJava/libs ; then \
> >     mkdir /usr/lib/R/library/SJava/libs ; \
> > fi
> > gcc -g -O2 -D_R_ -I/usr/lib/R/include 
> > -I/usr/lib/R/include/R_ext 
> > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > -I/tmp/R.INSTALL.30363/SJava/inst/include 
> > -I/opt/lang/java/j2sdk1.4.2_01/include
> > -I/opt/lang/java/j2sdk1.4.2_01/include/linux  -c CtoJava.c
> > gcc -g -O2 -D_R_ -I/usr/lib/R/include 
> > -I/usr/lib/R/include/R_ext 
> > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > -I/tmp/R.INSTALL.30363/SJava/inst/include 
> > -I/opt/lang/java/j2sdk1.4.2_01/include
> > -I/opt/lang/java/j2sdk1.4.2_01/include/linux  -c 
> > ErrorHandling.c gcc -g -O2 -D_R_ -I/usr/lib/R/include 
> > -I/usr/lib/R/include/R_ext 
> > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > -I/tmp/R.INSTALL.30363/SJava/inst/include 
> > -I/opt/lang/java/j2sdk1.4.2_01/include
> > -I/opt/lang/java/j2sdk1.4.2_01/include/linux  -c 
> > ManagerInterfaceUtils.c gcc -g -O2 -D_R_ -I/usr/lib/R/include 
> > -I/usr/lib/R/include/R_ext 
> > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > -I/tmp/R.INSTALL.30363/SJava/inst/include 
> > -I/opt/lang/java/j2sdk1.4.2_01/include
> > -I/opt/lang/java/j2sdk1.4.2_01/include/linux  -c References.c 
> > gcc -g -O2 -D_R_ -I/usr/lib/R/include 
> > -I/usr/lib/R/include/R_ext 
> > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > -I/tmp/R.INSTALL.30363/SJava/inst/include 
> > -I/opt/lang/java/j2sdk1.4.2_01/include
> > -I/opt/lang/java/j2sdk1.4.2_01/include/linux  -c JNIUtils.c
> > gcc -shared  -o libRSNativeJava.so CtoJava.o ErrorHandling.o 
> > ManagerInterfaceUtils.o References.o JNIUtils.o 
> > -L/opt/lang/java/j2sdk1.4.2_01/jre/lib/i386/client
> > -L/opt/lang/java/j2sdk1.4.2_01/jre/lib/i386
> > -L/opt/lang/java/j2sdk1.4.2_01/jre/../lib/i386 -ljvm 
> > -L/tmp/R.INSTALL.30363/SJava/inst/libs
> > -L/opt/lang/java/j2sdk1.4.2_01/jre/lib/i386/client
> > -L/opt/lang/java/j2sdk1.4.2_01/jre/lib/i386
> > -L/opt/lang/java/j2sdk1.4.2_01/jre/../lib/i386
> > -L/usr/lib/R/library/SJava/libs 
> > if test -n "CtoJava.h ErrorHandling.h JNIUtils.h 
> > ManagerInterfaceUtils.h References.h" ; then cp CtoJava.h 
> > ErrorHandling.h JNIUtils.h ManagerInterfaceUtils.h 
> > References.h /tmp/R.INSTALL.30363/SJava/inst/include ; fi mv 
> > libRSNativeJava.so /tmp/R.INSTALL.30363/SJava/inst/libs
> > Generating JNI header files from Java classes.
> >    RForeignReference, RManualFunctionActionListener, 
> > ROmegahatInterpreter & REvaluator
> > *************
> > Warning:
> >     At present, to use the library you must set the 
> >     LD_LIBRARY_PATH environment variable
> >     to
> >      
> > /usr/lib/R/library/SJava/libs:/opt/lang/java/j2sdk1.4.2_01/jre
> /lib/i386/client:/opt/lang/java/j2sdk1.4.2_>
> 01/jre/lib/i386:/opt/lang/java/j2sdk1.4.2_01/jre/../lib/i386:
> >     or use one of the RJava.bsh or RJava.csh scripts
> > *************
> > ** libs
> > gcc -I/usr/lib/R/include -D_R_ -I/usr/lib/R/include 
> > -I/usr/lib/R/include/R_ext 
> > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> > -I/opt/lang/java/j2sdk1.4.2_01/include
> > -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> > -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> > -O2 -m486 -fno-strength-reduce -g -c ConverterExamples.c -o 
> > ConverterExamples.o gcc -I/usr/lib/R/include -D_R_ 
> > -I/usr/lib/R/include -I/usr/lib/R/include/R_ext 
> > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> > -I/opt/lang/java/j2sdk1.4.2_01/include
> > -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> > -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> > -O2 -m486 -fno-strength-reduce -g -c Converters.c -o 
> > Converters.o gcc -I/usr/lib/R/include -D_R_ 
> > -I/usr/lib/R/include -I/usr/lib/R/include/R_ext 
> > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> > -I/opt/lang/java/j2sdk1.4.2_01/include
> > -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> > -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> > -O2 -m486 -fno-strength-reduce -g -c Reflectance.c -o 
> > Reflectance.o gcc -I/usr/lib/R/include -D_R_ 
> > -I/usr/lib/R/include -I/usr/lib/R/include/R_ext 
> > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> > -I/opt/lang/java/j2sdk1.4.2_01/include
> > -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> > -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> > -O2 -m486 -fno-strength-reduce -g -c REmbed.c -o REmbed.o gcc 
> > -I/usr/lib/R/include -D_R_ -I/usr/lib/R/include 
> > -I/usr/lib/R/include/R_ext 
> > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> > -I/opt/lang/java/j2sdk1.4.2_01/include
> > -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> > -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> > -O2 -m486 -fno-strength-reduce -g -c REmbedWin.c -o 
> > REmbedWin.o gcc -I/usr/lib/R/include -D_R_ 
> > -I/usr/lib/R/include -I/usr/lib/R/include/R_ext 
> > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> > -I/opt/lang/java/j2sdk1.4.2_01/include
> > -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> > -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> > -O2 -m486 -fno-strength-reduce -g -c REval.c -o REval.o gcc 
> > -I/usr/lib/R/include -D_R_ -I/usr/lib/R/include 
> > -I/usr/lib/R/include/R_ext 
> > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> > -I/opt/lang/java/j2sdk1.4.2_01/include
> > -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> > -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> > -O2 -m486 -fno-strength-reduce -g -c RFunctionListener.c -o 
> > RFunctionListener.o gcc -I/usr/lib/R/include -D_R_ 
> > -I/usr/lib/R/include -I/usr/lib/R/include/R_ext 
> > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> > -I/opt/lang/java/j2sdk1.4.2_01/include
> > -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> > -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> > -O2 -m486 -fno-strength-reduce -g -c RReferenceCall.c -o 
> > RReferenceCall.o gcc -I/usr/lib/R/include -D_R_ 
> > -I/usr/lib/R/include -I/usr/lib/R/include/R_ext 
> > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> > -I/opt/lang/java/j2sdk1.4.2_01/include
> > -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> > -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> > -O2 -m486 -fno-strength-reduce -g -c RStoJava.c -o RStoJava.o 
> > gcc -I/usr/lib/R/include -D_R_ -I/usr/lib/R/include 
> > -I/usr/lib/R/include/R_ext 
> > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> > -I/opt/lang/java/j2sdk1.4.2_01/include
> > -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> > -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> > -O2 -m486 -fno-strength-reduce -g -c RtoJava.c -o RtoJava.o 
> > gcc -shared -L/usr/local/lib -o SJava.so ConverterExamples.o 
> > Converters.o Reflectance.o REmbed.o REmbedWin.o REval.o 
> > RFunctionListener.o RReferenceCall.o RStoJava.o RtoJava.o 
> > -L/tmp/R.INSTALL.30363/SJava/inst/libs
> > -L/opt/lang/java/j2sdk1.4.2_01/jre/lib/i386/client
> > -L/opt/lang/java/j2sdk1.4.2_01/jre/lib/i386
> > -L/opt/lang/java/j2sdk1.4.2_01/jre/../lib/i386
> > -L/usr/lib/R/library/SJava/libs -lRSNativeJava -ljvm    
> > ** R
> > ** inst
> > ** help
> >  >>> Building/Updating help pages for package 'SJava'
> >      Formats: text html latex example 
> >   Array                             text    html    latex   example
> >   Dollar                            text    html    latex   example
> >   DotJavaSigs                       text    html    latex
> >   DotjavaConfig                     text    html    latex
> >   JClass                            text    html    latex   example
> >   Java                              text    html    latex   example
> >   JavaConstructor                   text    html    latex   example
> >   JavaInit                          text    html    latex   example
> >   JavaTerminate                     text    html    latex   example
> >   OmegahatExpression                text    html    latex   example
> >   RSJava.symbol                     text    html    latex   example
> >   RtoJavaSig                        text    html    latex   example
> >   expandClassName                   text    html    latex   example
> >   foreignReference                  text    html    latex   example
> >   getForeignReferences              text    html    latex   example
> >   getJavaConverterDescriptions      text    html    latex   example
> >   getJavaHandler                    text    html    latex   example
> >   getMethods                        text    html    latex   example
> >   getNumJavaConverters              text    html    latex   example
> >   interfaceGenerator                text    html    latex   example
> >   isJavaInitialized                 text    html    latex   example
> >   javaConfig                        text    html    latex   example
> >   javaHandlerGenerator              text    html    latex   example
> >   javaIs                            text    html    latex   example
> >   javaMatchFunctions                text    html    latex
> >   javaSig                           text    html    latex   example
> >   jdynamicCompile                   text    html    latex   example
> >   mergePath                         text    html    latex   example
> >   mergeProperties                   text    html    latex   example
> >   omegahatReference                 text    html    latex   example
> >   removeJavaConverter               text    html    latex   example
> >   setConvertible                    text    html    latex   example
> >   setJavaConverter                  text    html    latex   example
> >   setJavaFunctionConverter          text    html    latex   example
> >   setJavaHandler                    text    html    latex   example
> >      missing link(s):  javaHandlerGenerator()
> > Creating the symbolic link for libSJava.so in 
> > /usr/lib/R/library/SJava/libs/
> > * DONE (SJava)
> > 
> > * DONE (INSTALL)
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list 
> > https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> > 
> > 
>



From JACQUELINE.LAW at ROCHE.COM  Wed Sep 24 21:13:21 2003
From: JACQUELINE.LAW at ROCHE.COM (Law, Jacqueline {Regu~Pleasanton})
Date: Wed, 24 Sep 2003 12:13:21 -0700
Subject: [R] probit analysis for correlated binary data
Message-ID: <DBD6A2244E770D49953244DB15B3131E269399@rpbmsem01.ple.roche.com>

Dear all,

I have a question on the dose-response estimation with clustered/ correlated binary data.
I would like to estimate the hit rate for a certain test at various concentration levels. The test is used
on 5 subjects, and each subject is tested 20 times. If we assume that the 100 samples are 
independent, the hit rate estimate is unbiased, but the variance is under-estimated. The other
estimate of interest is the concentration that will give a 95% sensitivity of the test. I suppose the
same problem would occur if a probit model is fitted to the data and assume all the samples are
independent. Does anyone have any suggestions on how to analyze this kind of data? 

Thanks a lot in advance.

- Jacqueline



From duncan at research.bell-labs.com  Wed Sep 24 21:59:56 2003
From: duncan at research.bell-labs.com (Duncan Temple Lang)
Date: Wed, 24 Sep 2003 15:59:56 -0400
Subject: [R] SJava help
In-Reply-To: <1064429705.32366.17.camel@molecule.uchsc.edu>;
	from Weiming.Zhang@uchsc.edu on Wed, Sep 24, 2003 at 12:55:05PM
	-0600
References: <000c01c382cb$acaee1a0$800040d5@maths.lth.se>
	<1064429705.32366.17.camel@molecule.uchsc.edu>
Message-ID: <20030924155956.A22367@jessie.research.bell-labs.com>


Hi.

 Over the past few weeks, I have spent some time enhancing the
SJava package and ironing out some issues (syncrhonization
and locking of the R evaluator, etc.). Along the way, 
I did encounter the problem you mention about java.lang.Hashtable.
I can't quite remember what the problem was, but I think it
may have been a typo in one part of the code.

I will make a new version of the package available in the next
day or so and hopefully your problem and others will be 
resolved.

 D.



Weiming Zhang wrote:
> Hi, Henrik,
> 
> Thank you very much for replying.
> 
> I actually have the JAVA_HOME environment variable set in a linux shell
> script .bash_profile which set up all of my development environment
> before I install this SJava package and it points to the current java
> cdk I am using. So it is weird that R could not find the common java
> libraries. Do you think I need to use .Renviron instead of
> .bash_profile?
> 
> Weiming
>  
> On Wed, 2003-09-24 at 12:42, Henrik Bengtsson wrote:
> > Hi, I do not have Linux myself but looking at your error message
> > 
> > > > .JavaInit()
> > > [1] error initializing manager class can't find class 
> > > java/lang/Hashtable Error in .JavaInit() : Couldn't start 
> > > Java Virtual Machine: can't find class java/lang/Hashtable
> > > > 
> > 
> > it looks like you have not set the JAVA_HOME variable correctly. On a
> > Windows XP machine you will get the error (together with a popup
> > dialog):
> > 
> > > library(SJava)
> > using JAVA_HOME = /c/Program Files/Java/j2sdk1.4.0_02
> > Error in dyn.load(x, as.logical(local), as.logical(now)) :
> >         unable to load shared library
> > "c:/PROGRA~1/R/rw1071/library/SJava/libs/S
> > Java.dll":
> >   LoadLibrary failure:  The specified module could not be found.
> > Error in library(SJava) : .First.lib failed
> > >
> > 
> > See help(.Renviron) how to set the JAVA_HOME environment variable. 
> > 
> > ***Note*** on Windows XP (and maybe on other systems too) you have to
> > set JAVA_HOME differently if you have i) Java Runtime Edition or the ii)
> > Java SDK. For Java SDK, which you have, you have to set
> > 
> >   JAVA_HOME=C:/Program Files/Java/j2sdk1.4.0_02/jre/
> > 
> > and not to
> > 
> >   JAVA_HOME=C:/Program Files/Java/j2sdk1.4.0_02/
> > 
> > as one would guess. But with Java Runtime Edition you should do
> > 
> >   JAVA_HOME=C:/Program Files/Java/j2re1.4.1_02/
> > 
> > If you use ~/.Renviron it won't mess with your other settings. 
> > 
> > Again, I'm not sure if this applies to Linux, but it's worth a try.
> > 
> > Cheers
> > 
> > Henrik Bengtsson
> > 
> > 
> > > -----Original Message-----
> > > From: r-help-bounces at stat.math.ethz.ch 
> > > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Weiming Zhang
> > > Sent: den 24 september 2003 19:16
> > > To: R-help at stat.math.ethz.ch
> > > Subject: [R] SJava help
> > > 
> > > 
> > > Hi,
> > > 
> > > I installed SJava 0.66-1 on my linux RH 7.2 machine. I am 
> > > using R-1.7.1. I set LD_LIBRARY_PATH up then called 
> > > library(SJava) and it was fine. But when I called 
> > > .JavaInit(),  I got weird error that states it could not find 
> > > java/lang/Hashtable. The session is below and shows my java 
> > > configuration. I am using j2sdk1.4.2_01 from Sun.
> > > 
> > > Thank you very much.
> > > 
> > > Weiming Zhang
> > > 
> > > > .javaConfig
> > > $classPath
> > > [1] "/usr/lib/R/library/SJava/org/omegahat/Jars/Environment.jar"
> > > [2] "/usr/lib/R/library/SJava/org/.."                           
> > > [3] "/usr/lib/R/library/SJava/org/omegahat/Jars/antlr.jar"      
> > > [4] "/usr/lib/R/library/SJava/org/omegahat/Jars/jas.jar"        
> > > [5] "/usr/lib/R/library/SJava/org/omegahat/Jars/jhall.jar"      
> > > 
> > > $properties
> > >                                                                 
> > > EmbeddedInR 
> > >                                                                      
> > > "true" 
> > >                                                       
> > > InterfaceManagerClass 
> > >             
> > > "org/omegahat/Interfaces/NativeInterface/OmegaInterfaceManager" 
> > >                                                   
> > > ForeignReferenceBaseClass 
> > >                                     
> > > "org/omegahat/R/Java/RForeignReference" 
> > >                                                               
> > > java.compiler 
> > >                                                                      
> > > "NONE" 
> > >                                                                  
> > > OMEGA_HOME 
> > >                                     
> > > "/usr/lib/R/library/SJava/org/omegahat" 
> > >                                                          
> > > OmegahatSearchPath 
> > > ".,${OMEGA_HOME}/Environment/Scripts/Run,${OMEGA_HOME}/Jars/En
> > > vironment.jar" 
> > >                                                           
> > > java.library.path 
> > >                                             
> > > "/usr/lib/R/library/SJava/libs" 
> > > 
> > > $libraryPath
> > > [1] "/usr/lib/R/library/SJava/libs"
> > > 
> > > $args
> > > character(0)
> > > 
> > > > .JavaInit()
> > > [1] error initializing manager class can't find class 
> > > java/lang/Hashtable Error in .JavaInit() : Couldn't start 
> > > Java Virtual Machine: can't find class java/lang/Hashtable
> > > > 
> > > 
> > > The output from installation is here and 
> > > I used R INSTALL -c SJavaPackageName:
> > > 
> > > * Installing *source* package 'SJava' ...
> > > creating cache ./config.cache
> > > checking for java... /opt/lang/java/j2sdk1.4.2_01/bin/java
> > > Java VM /opt/lang/java/j2sdk1.4.2_01/bin/java
> > > checking for javah... /opt/lang/java/j2sdk1.4.2_01/bin/javah
> > > checking for c++... c++
> > > checking whether the C++ compiler (c++  ) works... yes
> > > checking whether the C++ compiler (c++  ) is a 
> > > cross-compiler... no checking whether we are using GNU C++... 
> > > yes checking whether c++ accepts -g... yes checking for 
> > > gcc... gcc checking whether the C compiler (gcc  ) works... 
> > > yes checking whether the C compiler (gcc  ) is a 
> > > cross-compiler... no checking whether we are using GNU C... 
> > > yes checking whether gcc accepts -g... yes checking for 
> > > Rf_initEmbeddedR in -lR... no No R shared library found 
> > > updating cache ./config.cache creating ./config.status 
> > > creating Makevars creating src/Makevars creating 
> > > src/RSJava/Makefile creating Makefile_rules creating 
> > > inst/scripts/RJava.bsh creating inst/scripts/RJava.csh 
> > > creating R/zzz.R creating cleanup creating inst/scripts/RJava 
> > > Copying the cleanup script to the scripts/ directory Building 
> > > libRSNativeJava.so in /tmp/R.INSTALL.30363/SJava/src/RSJava
> > > if  test ! -d /usr/lib/R/library/SJava/libs ; then \
> > >     mkdir /usr/lib/R/library/SJava/libs ; \
> > > fi
> > > gcc -g -O2 -D_R_ -I/usr/lib/R/include 
> > > -I/usr/lib/R/include/R_ext 
> > > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > > -I/tmp/R.INSTALL.30363/SJava/inst/include 
> > > -I/opt/lang/java/j2sdk1.4.2_01/include
> > > -I/opt/lang/java/j2sdk1.4.2_01/include/linux  -c CtoJava.c
> > > gcc -g -O2 -D_R_ -I/usr/lib/R/include 
> > > -I/usr/lib/R/include/R_ext 
> > > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > > -I/tmp/R.INSTALL.30363/SJava/inst/include 
> > > -I/opt/lang/java/j2sdk1.4.2_01/include
> > > -I/opt/lang/java/j2sdk1.4.2_01/include/linux  -c 
> > > ErrorHandling.c gcc -g -O2 -D_R_ -I/usr/lib/R/include 
> > > -I/usr/lib/R/include/R_ext 
> > > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > > -I/tmp/R.INSTALL.30363/SJava/inst/include 
> > > -I/opt/lang/java/j2sdk1.4.2_01/include
> > > -I/opt/lang/java/j2sdk1.4.2_01/include/linux  -c 
> > > ManagerInterfaceUtils.c gcc -g -O2 -D_R_ -I/usr/lib/R/include 
> > > -I/usr/lib/R/include/R_ext 
> > > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > > -I/tmp/R.INSTALL.30363/SJava/inst/include 
> > > -I/opt/lang/java/j2sdk1.4.2_01/include
> > > -I/opt/lang/java/j2sdk1.4.2_01/include/linux  -c References.c 
> > > gcc -g -O2 -D_R_ -I/usr/lib/R/include 
> > > -I/usr/lib/R/include/R_ext 
> > > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > > -I/tmp/R.INSTALL.30363/SJava/inst/include 
> > > -I/opt/lang/java/j2sdk1.4.2_01/include
> > > -I/opt/lang/java/j2sdk1.4.2_01/include/linux  -c JNIUtils.c
> > > gcc -shared  -o libRSNativeJava.so CtoJava.o ErrorHandling.o 
> > > ManagerInterfaceUtils.o References.o JNIUtils.o 
> > > -L/opt/lang/java/j2sdk1.4.2_01/jre/lib/i386/client
> > > -L/opt/lang/java/j2sdk1.4.2_01/jre/lib/i386
> > > -L/opt/lang/java/j2sdk1.4.2_01/jre/../lib/i386 -ljvm 
> > > -L/tmp/R.INSTALL.30363/SJava/inst/libs
> > > -L/opt/lang/java/j2sdk1.4.2_01/jre/lib/i386/client
> > > -L/opt/lang/java/j2sdk1.4.2_01/jre/lib/i386
> > > -L/opt/lang/java/j2sdk1.4.2_01/jre/../lib/i386
> > > -L/usr/lib/R/library/SJava/libs 
> > > if test -n "CtoJava.h ErrorHandling.h JNIUtils.h 
> > > ManagerInterfaceUtils.h References.h" ; then cp CtoJava.h 
> > > ErrorHandling.h JNIUtils.h ManagerInterfaceUtils.h 
> > > References.h /tmp/R.INSTALL.30363/SJava/inst/include ; fi mv 
> > > libRSNativeJava.so /tmp/R.INSTALL.30363/SJava/inst/libs
> > > Generating JNI header files from Java classes.
> > >    RForeignReference, RManualFunctionActionListener, 
> > > ROmegahatInterpreter & REvaluator
> > > *************
> > > Warning:
> > >     At present, to use the library you must set the 
> > >     LD_LIBRARY_PATH environment variable
> > >     to
> > >      
> > > /usr/lib/R/library/SJava/libs:/opt/lang/java/j2sdk1.4.2_01/jre
> > /lib/i386/client:/opt/lang/java/j2sdk1.4.2_>
> > 01/jre/lib/i386:/opt/lang/java/j2sdk1.4.2_01/jre/../lib/i386:
> > >     or use one of the RJava.bsh or RJava.csh scripts
> > > *************
> > > ** libs
> > > gcc -I/usr/lib/R/include -D_R_ -I/usr/lib/R/include 
> > > -I/usr/lib/R/include/R_ext 
> > > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > > -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> > > -I/opt/lang/java/j2sdk1.4.2_01/include
> > > -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> > > -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> > > -O2 -m486 -fno-strength-reduce -g -c ConverterExamples.c -o 
> > > ConverterExamples.o gcc -I/usr/lib/R/include -D_R_ 
> > > -I/usr/lib/R/include -I/usr/lib/R/include/R_ext 
> > > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > > -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> > > -I/opt/lang/java/j2sdk1.4.2_01/include
> > > -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> > > -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> > > -O2 -m486 -fno-strength-reduce -g -c Converters.c -o 
> > > Converters.o gcc -I/usr/lib/R/include -D_R_ 
> > > -I/usr/lib/R/include -I/usr/lib/R/include/R_ext 
> > > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > > -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> > > -I/opt/lang/java/j2sdk1.4.2_01/include
> > > -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> > > -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> > > -O2 -m486 -fno-strength-reduce -g -c Reflectance.c -o 
> > > Reflectance.o gcc -I/usr/lib/R/include -D_R_ 
> > > -I/usr/lib/R/include -I/usr/lib/R/include/R_ext 
> > > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > > -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> > > -I/opt/lang/java/j2sdk1.4.2_01/include
> > > -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> > > -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> > > -O2 -m486 -fno-strength-reduce -g -c REmbed.c -o REmbed.o gcc 
> > > -I/usr/lib/R/include -D_R_ -I/usr/lib/R/include 
> > > -I/usr/lib/R/include/R_ext 
> > > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > > -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> > > -I/opt/lang/java/j2sdk1.4.2_01/include
> > > -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> > > -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> > > -O2 -m486 -fno-strength-reduce -g -c REmbedWin.c -o 
> > > REmbedWin.o gcc -I/usr/lib/R/include -D_R_ 
> > > -I/usr/lib/R/include -I/usr/lib/R/include/R_ext 
> > > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > > -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> > > -I/opt/lang/java/j2sdk1.4.2_01/include
> > > -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> > > -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> > > -O2 -m486 -fno-strength-reduce -g -c REval.c -o REval.o gcc 
> > > -I/usr/lib/R/include -D_R_ -I/usr/lib/R/include 
> > > -I/usr/lib/R/include/R_ext 
> > > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > > -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> > > -I/opt/lang/java/j2sdk1.4.2_01/include
> > > -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> > > -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> > > -O2 -m486 -fno-strength-reduce -g -c RFunctionListener.c -o 
> > > RFunctionListener.o gcc -I/usr/lib/R/include -D_R_ 
> > > -I/usr/lib/R/include -I/usr/lib/R/include/R_ext 
> > > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > > -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> > > -I/opt/lang/java/j2sdk1.4.2_01/include
> > > -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> > > -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> > > -O2 -m486 -fno-strength-reduce -g -c RReferenceCall.c -o 
> > > RReferenceCall.o gcc -I/usr/lib/R/include -D_R_ 
> > > -I/usr/lib/R/include -I/usr/lib/R/include/R_ext 
> > > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > > -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> > > -I/opt/lang/java/j2sdk1.4.2_01/include
> > > -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> > > -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> > > -O2 -m486 -fno-strength-reduce -g -c RStoJava.c -o RStoJava.o 
> > > gcc -I/usr/lib/R/include -D_R_ -I/usr/lib/R/include 
> > > -I/usr/lib/R/include/R_ext 
> > > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > > -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> > > -I/opt/lang/java/j2sdk1.4.2_01/include
> > > -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> > > -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> > > -O2 -m486 -fno-strength-reduce -g -c RtoJava.c -o RtoJava.o 
> > > gcc -shared -L/usr/local/lib -o SJava.so ConverterExamples.o 
> > > Converters.o Reflectance.o REmbed.o REmbedWin.o REval.o 
> > > RFunctionListener.o RReferenceCall.o RStoJava.o RtoJava.o 
> > > -L/tmp/R.INSTALL.30363/SJava/inst/libs
> > > -L/opt/lang/java/j2sdk1.4.2_01/jre/lib/i386/client
> > > -L/opt/lang/java/j2sdk1.4.2_01/jre/lib/i386
> > > -L/opt/lang/java/j2sdk1.4.2_01/jre/../lib/i386
> > > -L/usr/lib/R/library/SJava/libs -lRSNativeJava -ljvm    
> > > ** R
> > > ** inst
> > > ** help
> > >  >>> Building/Updating help pages for package 'SJava'
> > >      Formats: text html latex example 
> > >   Array                             text    html    latex   example
> > >   Dollar                            text    html    latex   example
> > >   DotJavaSigs                       text    html    latex
> > >   DotjavaConfig                     text    html    latex
> > >   JClass                            text    html    latex   example
> > >   Java                              text    html    latex   example
> > >   JavaConstructor                   text    html    latex   example
> > >   JavaInit                          text    html    latex   example
> > >   JavaTerminate                     text    html    latex   example
> > >   OmegahatExpression                text    html    latex   example
> > >   RSJava.symbol                     text    html    latex   example
> > >   RtoJavaSig                        text    html    latex   example
> > >   expandClassName                   text    html    latex   example
> > >   foreignReference                  text    html    latex   example
> > >   getForeignReferences              text    html    latex   example
> > >   getJavaConverterDescriptions      text    html    latex   example
> > >   getJavaHandler                    text    html    latex   example
> > >   getMethods                        text    html    latex   example
> > >   getNumJavaConverters              text    html    latex   example
> > >   interfaceGenerator                text    html    latex   example
> > >   isJavaInitialized                 text    html    latex   example
> > >   javaConfig                        text    html    latex   example
> > >   javaHandlerGenerator              text    html    latex   example
> > >   javaIs                            text    html    latex   example
> > >   javaMatchFunctions                text    html    latex
> > >   javaSig                           text    html    latex   example
> > >   jdynamicCompile                   text    html    latex   example
> > >   mergePath                         text    html    latex   example
> > >   mergeProperties                   text    html    latex   example
> > >   omegahatReference                 text    html    latex   example
> > >   removeJavaConverter               text    html    latex   example
> > >   setConvertible                    text    html    latex   example
> > >   setJavaConverter                  text    html    latex   example
> > >   setJavaFunctionConverter          text    html    latex   example
> > >   setJavaHandler                    text    html    latex   example
> > >      missing link(s):  javaHandlerGenerator()
> > > Creating the symbolic link for libSJava.so in 
> > > /usr/lib/R/library/SJava/libs/
> > > * DONE (SJava)
> > > 
> > > * DONE (INSTALL)
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list 
> > > https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> > > 
> > > 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
_______________________________________________________________

Duncan Temple Lang                duncan at research.bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-3217
700 Mountain Avenue, Room 2C-259  fax:    (908)582-3340
Murray Hill, NJ  07974-2070       
         http://cm.bell-labs.com/stat/duncan



From Weiming.Zhang at uchsc.edu  Wed Sep 24 22:15:39 2003
From: Weiming.Zhang at uchsc.edu (Weiming Zhang)
Date: Wed, 24 Sep 2003 20:15:39 -0000
Subject: [R] SJava help
In-Reply-To: <20030924155956.A22367@jessie.research.bell-labs.com>
References: <000c01c382cb$acaee1a0$800040d5@maths.lth.se>
	<1064429705.32366.17.camel@molecule.uchsc.edu>
	<20030924155956.A22367@jessie.research.bell-labs.com>
Message-ID: <1064434570.1963.3.camel@molecule.uchsc.edu>

Hi,

That would be great! I will wait.

Thanks.

Weiming
On Wed, 2003-09-24 at 13:59, Duncan Temple Lang wrote:
> 
> Hi.
> 
>  Over the past few weeks, I have spent some time enhancing the
> SJava package and ironing out some issues (syncrhonization
> and locking of the R evaluator, etc.). Along the way, 
> I did encounter the problem you mention about java.lang.Hashtable.
> I can't quite remember what the problem was, but I think it
> may have been a typo in one part of the code.
> 
> I will make a new version of the package available in the next
> day or so and hopefully your problem and others will be 
> resolved.
> 
>  D.
> 
> 
> 
> Weiming Zhang wrote:
> > Hi, Henrik,
> > 
> > Thank you very much for replying.
> > 
> > I actually have the JAVA_HOME environment variable set in a linux shell
> > script .bash_profile which set up all of my development environment
> > before I install this SJava package and it points to the current java
> > cdk I am using. So it is weird that R could not find the common java
> > libraries. Do you think I need to use .Renviron instead of
> > .bash_profile?
> > 
> > Weiming
> >  
> > On Wed, 2003-09-24 at 12:42, Henrik Bengtsson wrote:
> > > Hi, I do not have Linux myself but looking at your error message
> > > 
> > > > > .JavaInit()
> > > > [1] error initializing manager class can't find class 
> > > > java/lang/Hashtable Error in .JavaInit() : Couldn't start 
> > > > Java Virtual Machine: can't find class java/lang/Hashtable
> > > > > 
> > > 
> > > it looks like you have not set the JAVA_HOME variable correctly. On a
> > > Windows XP machine you will get the error (together with a popup
> > > dialog):
> > > 
> > > > library(SJava)
> > > using JAVA_HOME = /c/Program Files/Java/j2sdk1.4.0_02
> > > Error in dyn.load(x, as.logical(local), as.logical(now)) :
> > >         unable to load shared library
> > > "c:/PROGRA~1/R/rw1071/library/SJava/libs/S
> > > Java.dll":
> > >   LoadLibrary failure:  The specified module could not be found.
> > > Error in library(SJava) : .First.lib failed
> > > >
> > > 
> > > See help(.Renviron) how to set the JAVA_HOME environment variable. 
> > > 
> > > ***Note*** on Windows XP (and maybe on other systems too) you have to
> > > set JAVA_HOME differently if you have i) Java Runtime Edition or the ii)
> > > Java SDK. For Java SDK, which you have, you have to set
> > > 
> > >   JAVA_HOME=C:/Program Files/Java/j2sdk1.4.0_02/jre/
> > > 
> > > and not to
> > > 
> > >   JAVA_HOME=C:/Program Files/Java/j2sdk1.4.0_02/
> > > 
> > > as one would guess. But with Java Runtime Edition you should do
> > > 
> > >   JAVA_HOME=C:/Program Files/Java/j2re1.4.1_02/
> > > 
> > > If you use ~/.Renviron it won't mess with your other settings. 
> > > 
> > > Again, I'm not sure if this applies to Linux, but it's worth a try.
> > > 
> > > Cheers
> > > 
> > > Henrik Bengtsson
> > > 
> > > 
> > > > -----Original Message-----
> > > > From: r-help-bounces at stat.math.ethz.ch 
> > > > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Weiming Zhang
> > > > Sent: den 24 september 2003 19:16
> > > > To: R-help at stat.math.ethz.ch
> > > > Subject: [R] SJava help
> > > > 
> > > > 
> > > > Hi,
> > > > 
> > > > I installed SJava 0.66-1 on my linux RH 7.2 machine. I am 
> > > > using R-1.7.1. I set LD_LIBRARY_PATH up then called 
> > > > library(SJava) and it was fine. But when I called 
> > > > .JavaInit(),  I got weird error that states it could not find 
> > > > java/lang/Hashtable. The session is below and shows my java 
> > > > configuration. I am using j2sdk1.4.2_01 from Sun.
> > > > 
> > > > Thank you very much.
> > > > 
> > > > Weiming Zhang
> > > > 
> > > > > .javaConfig
> > > > $classPath
> > > > [1] "/usr/lib/R/library/SJava/org/omegahat/Jars/Environment.jar"
> > > > [2] "/usr/lib/R/library/SJava/org/.."                           
> > > > [3] "/usr/lib/R/library/SJava/org/omegahat/Jars/antlr.jar"      
> > > > [4] "/usr/lib/R/library/SJava/org/omegahat/Jars/jas.jar"        
> > > > [5] "/usr/lib/R/library/SJava/org/omegahat/Jars/jhall.jar"      
> > > > 
> > > > $properties
> > > >                                                                 
> > > > EmbeddedInR 
> > > >                                                                      
> > > > "true" 
> > > >                                                       
> > > > InterfaceManagerClass 
> > > >             
> > > > "org/omegahat/Interfaces/NativeInterface/OmegaInterfaceManager" 
> > > >                                                   
> > > > ForeignReferenceBaseClass 
> > > >                                     
> > > > "org/omegahat/R/Java/RForeignReference" 
> > > >                                                               
> > > > java.compiler 
> > > >                                                                      
> > > > "NONE" 
> > > >                                                                  
> > > > OMEGA_HOME 
> > > >                                     
> > > > "/usr/lib/R/library/SJava/org/omegahat" 
> > > >                                                          
> > > > OmegahatSearchPath 
> > > > ".,${OMEGA_HOME}/Environment/Scripts/Run,${OMEGA_HOME}/Jars/En
> > > > vironment.jar" 
> > > >                                                           
> > > > java.library.path 
> > > >                                             
> > > > "/usr/lib/R/library/SJava/libs" 
> > > > 
> > > > $libraryPath
> > > > [1] "/usr/lib/R/library/SJava/libs"
> > > > 
> > > > $args
> > > > character(0)
> > > > 
> > > > > .JavaInit()
> > > > [1] error initializing manager class can't find class 
> > > > java/lang/Hashtable Error in .JavaInit() : Couldn't start 
> > > > Java Virtual Machine: can't find class java/lang/Hashtable
> > > > > 
> > > > 
> > > > The output from installation is here and 
> > > > I used R INSTALL -c SJavaPackageName:
> > > > 
> > > > * Installing *source* package 'SJava' ...
> > > > creating cache ./config.cache
> > > > checking for java... /opt/lang/java/j2sdk1.4.2_01/bin/java
> > > > Java VM /opt/lang/java/j2sdk1.4.2_01/bin/java
> > > > checking for javah... /opt/lang/java/j2sdk1.4.2_01/bin/javah
> > > > checking for c++... c++
> > > > checking whether the C++ compiler (c++  ) works... yes
> > > > checking whether the C++ compiler (c++  ) is a 
> > > > cross-compiler... no checking whether we are using GNU C++... 
> > > > yes checking whether c++ accepts -g... yes checking for 
> > > > gcc... gcc checking whether the C compiler (gcc  ) works... 
> > > > yes checking whether the C compiler (gcc  ) is a 
> > > > cross-compiler... no checking whether we are using GNU C... 
> > > > yes checking whether gcc accepts -g... yes checking for 
> > > > Rf_initEmbeddedR in -lR... no No R shared library found 
> > > > updating cache ./config.cache creating ./config.status 
> > > > creating Makevars creating src/Makevars creating 
> > > > src/RSJava/Makefile creating Makefile_rules creating 
> > > > inst/scripts/RJava.bsh creating inst/scripts/RJava.csh 
> > > > creating R/zzz.R creating cleanup creating inst/scripts/RJava 
> > > > Copying the cleanup script to the scripts/ directory Building 
> > > > libRSNativeJava.so in /tmp/R.INSTALL.30363/SJava/src/RSJava
> > > > if  test ! -d /usr/lib/R/library/SJava/libs ; then \
> > > >     mkdir /usr/lib/R/library/SJava/libs ; \
> > > > fi
> > > > gcc -g -O2 -D_R_ -I/usr/lib/R/include 
> > > > -I/usr/lib/R/include/R_ext 
> > > > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > > > -I/tmp/R.INSTALL.30363/SJava/inst/include 
> > > > -I/opt/lang/java/j2sdk1.4.2_01/include
> > > > -I/opt/lang/java/j2sdk1.4.2_01/include/linux  -c CtoJava.c
> > > > gcc -g -O2 -D_R_ -I/usr/lib/R/include 
> > > > -I/usr/lib/R/include/R_ext 
> > > > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > > > -I/tmp/R.INSTALL.30363/SJava/inst/include 
> > > > -I/opt/lang/java/j2sdk1.4.2_01/include
> > > > -I/opt/lang/java/j2sdk1.4.2_01/include/linux  -c 
> > > > ErrorHandling.c gcc -g -O2 -D_R_ -I/usr/lib/R/include 
> > > > -I/usr/lib/R/include/R_ext 
> > > > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > > > -I/tmp/R.INSTALL.30363/SJava/inst/include 
> > > > -I/opt/lang/java/j2sdk1.4.2_01/include
> > > > -I/opt/lang/java/j2sdk1.4.2_01/include/linux  -c 
> > > > ManagerInterfaceUtils.c gcc -g -O2 -D_R_ -I/usr/lib/R/include 
> > > > -I/usr/lib/R/include/R_ext 
> > > > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > > > -I/tmp/R.INSTALL.30363/SJava/inst/include 
> > > > -I/opt/lang/java/j2sdk1.4.2_01/include
> > > > -I/opt/lang/java/j2sdk1.4.2_01/include/linux  -c References.c 
> > > > gcc -g -O2 -D_R_ -I/usr/lib/R/include 
> > > > -I/usr/lib/R/include/R_ext 
> > > > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > > > -I/tmp/R.INSTALL.30363/SJava/inst/include 
> > > > -I/opt/lang/java/j2sdk1.4.2_01/include
> > > > -I/opt/lang/java/j2sdk1.4.2_01/include/linux  -c JNIUtils.c
> > > > gcc -shared  -o libRSNativeJava.so CtoJava.o ErrorHandling.o 
> > > > ManagerInterfaceUtils.o References.o JNIUtils.o 
> > > > -L/opt/lang/java/j2sdk1.4.2_01/jre/lib/i386/client
> > > > -L/opt/lang/java/j2sdk1.4.2_01/jre/lib/i386
> > > > -L/opt/lang/java/j2sdk1.4.2_01/jre/../lib/i386 -ljvm 
> > > > -L/tmp/R.INSTALL.30363/SJava/inst/libs
> > > > -L/opt/lang/java/j2sdk1.4.2_01/jre/lib/i386/client
> > > > -L/opt/lang/java/j2sdk1.4.2_01/jre/lib/i386
> > > > -L/opt/lang/java/j2sdk1.4.2_01/jre/../lib/i386
> > > > -L/usr/lib/R/library/SJava/libs 
> > > > if test -n "CtoJava.h ErrorHandling.h JNIUtils.h 
> > > > ManagerInterfaceUtils.h References.h" ; then cp CtoJava.h 
> > > > ErrorHandling.h JNIUtils.h ManagerInterfaceUtils.h 
> > > > References.h /tmp/R.INSTALL.30363/SJava/inst/include ; fi mv 
> > > > libRSNativeJava.so /tmp/R.INSTALL.30363/SJava/inst/libs
> > > > Generating JNI header files from Java classes.
> > > >    RForeignReference, RManualFunctionActionListener, 
> > > > ROmegahatInterpreter & REvaluator
> > > > *************
> > > > Warning:
> > > >     At present, to use the library you must set the 
> > > >     LD_LIBRARY_PATH environment variable
> > > >     to
> > > >      
> > > > /usr/lib/R/library/SJava/libs:/opt/lang/java/j2sdk1.4.2_01/jre
> > > /lib/i386/client:/opt/lang/java/j2sdk1.4.2_>
> > > 01/jre/lib/i386:/opt/lang/java/j2sdk1.4.2_01/jre/../lib/i386:
> > > >     or use one of the RJava.bsh or RJava.csh scripts
> > > > *************
> > > > ** libs
> > > > gcc -I/usr/lib/R/include -D_R_ -I/usr/lib/R/include 
> > > > -I/usr/lib/R/include/R_ext 
> > > > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > > > -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> > > > -I/opt/lang/java/j2sdk1.4.2_01/include
> > > > -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> > > > -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> > > > -O2 -m486 -fno-strength-reduce -g -c ConverterExamples.c -o 
> > > > ConverterExamples.o gcc -I/usr/lib/R/include -D_R_ 
> > > > -I/usr/lib/R/include -I/usr/lib/R/include/R_ext 
> > > > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > > > -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> > > > -I/opt/lang/java/j2sdk1.4.2_01/include
> > > > -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> > > > -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> > > > -O2 -m486 -fno-strength-reduce -g -c Converters.c -o 
> > > > Converters.o gcc -I/usr/lib/R/include -D_R_ 
> > > > -I/usr/lib/R/include -I/usr/lib/R/include/R_ext 
> > > > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > > > -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> > > > -I/opt/lang/java/j2sdk1.4.2_01/include
> > > > -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> > > > -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> > > > -O2 -m486 -fno-strength-reduce -g -c Reflectance.c -o 
> > > > Reflectance.o gcc -I/usr/lib/R/include -D_R_ 
> > > > -I/usr/lib/R/include -I/usr/lib/R/include/R_ext 
> > > > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > > > -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> > > > -I/opt/lang/java/j2sdk1.4.2_01/include
> > > > -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> > > > -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> > > > -O2 -m486 -fno-strength-reduce -g -c REmbed.c -o REmbed.o gcc 
> > > > -I/usr/lib/R/include -D_R_ -I/usr/lib/R/include 
> > > > -I/usr/lib/R/include/R_ext 
> > > > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > > > -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> > > > -I/opt/lang/java/j2sdk1.4.2_01/include
> > > > -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> > > > -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> > > > -O2 -m486 -fno-strength-reduce -g -c REmbedWin.c -o 
> > > > REmbedWin.o gcc -I/usr/lib/R/include -D_R_ 
> > > > -I/usr/lib/R/include -I/usr/lib/R/include/R_ext 
> > > > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > > > -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> > > > -I/opt/lang/java/j2sdk1.4.2_01/include
> > > > -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> > > > -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> > > > -O2 -m486 -fno-strength-reduce -g -c REval.c -o REval.o gcc 
> > > > -I/usr/lib/R/include -D_R_ -I/usr/lib/R/include 
> > > > -I/usr/lib/R/include/R_ext 
> > > > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > > > -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> > > > -I/opt/lang/java/j2sdk1.4.2_01/include
> > > > -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> > > > -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> > > > -O2 -m486 -fno-strength-reduce -g -c RFunctionListener.c -o 
> > > > RFunctionListener.o gcc -I/usr/lib/R/include -D_R_ 
> > > > -I/usr/lib/R/include -I/usr/lib/R/include/R_ext 
> > > > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > > > -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> > > > -I/opt/lang/java/j2sdk1.4.2_01/include
> > > > -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> > > > -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> > > > -O2 -m486 -fno-strength-reduce -g -c RReferenceCall.c -o 
> > > > RReferenceCall.o gcc -I/usr/lib/R/include -D_R_ 
> > > > -I/usr/lib/R/include -I/usr/lib/R/include/R_ext 
> > > > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > > > -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> > > > -I/opt/lang/java/j2sdk1.4.2_01/include
> > > > -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> > > > -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> > > > -O2 -m486 -fno-strength-reduce -g -c RStoJava.c -o RStoJava.o 
> > > > gcc -I/usr/lib/R/include -D_R_ -I/usr/lib/R/include 
> > > > -I/usr/lib/R/include/R_ext 
> > > > -I/tmp/R.INSTALL.30363/SJava/src/RSJava  -I. 
> > > > -I/tmp/R.INSTALL.30363/SJava/inst/include  -IRSJava 
> > > > -I/opt/lang/java/j2sdk1.4.2_01/include
> > > > -I/opt/lang/java/j2sdk1.4.2_01/include/linux 
> > > > -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  
> > > > -O2 -m486 -fno-strength-reduce -g -c RtoJava.c -o RtoJava.o 
> > > > gcc -shared -L/usr/local/lib -o SJava.so ConverterExamples.o 
> > > > Converters.o Reflectance.o REmbed.o REmbedWin.o REval.o 
> > > > RFunctionListener.o RReferenceCall.o RStoJava.o RtoJava.o 
> > > > -L/tmp/R.INSTALL.30363/SJava/inst/libs
> > > > -L/opt/lang/java/j2sdk1.4.2_01/jre/lib/i386/client
> > > > -L/opt/lang/java/j2sdk1.4.2_01/jre/lib/i386
> > > > -L/opt/lang/java/j2sdk1.4.2_01/jre/../lib/i386
> > > > -L/usr/lib/R/library/SJava/libs -lRSNativeJava -ljvm    
> > > > ** R
> > > > ** inst
> > > > ** help
> > > >  >>> Building/Updating help pages for package 'SJava'
> > > >      Formats: text html latex example 
> > > >   Array                             text    html    latex   example
> > > >   Dollar                            text    html    latex   example
> > > >   DotJavaSigs                       text    html    latex
> > > >   DotjavaConfig                     text    html    latex
> > > >   JClass                            text    html    latex   example
> > > >   Java                              text    html    latex   example
> > > >   JavaConstructor                   text    html    latex   example
> > > >   JavaInit                          text    html    latex   example
> > > >   JavaTerminate                     text    html    latex   example
> > > >   OmegahatExpression                text    html    latex   example
> > > >   RSJava.symbol                     text    html    latex   example
> > > >   RtoJavaSig                        text    html    latex   example
> > > >   expandClassName                   text    html    latex   example
> > > >   foreignReference                  text    html    latex   example
> > > >   getForeignReferences              text    html    latex   example
> > > >   getJavaConverterDescriptions      text    html    latex   example
> > > >   getJavaHandler                    text    html    latex   example
> > > >   getMethods                        text    html    latex   example
> > > >   getNumJavaConverters              text    html    latex   example
> > > >   interfaceGenerator                text    html    latex   example
> > > >   isJavaInitialized                 text    html    latex   example
> > > >   javaConfig                        text    html    latex   example
> > > >   javaHandlerGenerator              text    html    latex   example
> > > >   javaIs                            text    html    latex   example
> > > >   javaMatchFunctions                text    html    latex
> > > >   javaSig                           text    html    latex   example
> > > >   jdynamicCompile                   text    html    latex   example
> > > >   mergePath                         text    html    latex   example
> > > >   mergeProperties                   text    html    latex   example
> > > >   omegahatReference                 text    html    latex   example
> > > >   removeJavaConverter               text    html    latex   example
> > > >   setConvertible                    text    html    latex   example
> > > >   setJavaConverter                  text    html    latex   example
> > > >   setJavaFunctionConverter          text    html    latex   example
> > > >   setJavaHandler                    text    html    latex   example
> > > >      missing link(s):  javaHandlerGenerator()
> > > > Creating the symbolic link for libSJava.so in 
> > > > /usr/lib/R/library/SJava/libs/
> > > > * DONE (SJava)
> > > > 
> > > > * DONE (INSTALL)
> > > > 
> > > > ______________________________________________
> > > > R-help at stat.math.ethz.ch mailing list 
> > > > https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> > > > 
> > > > 
> > >
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> -- 
> _______________________________________________________________
> 
> Duncan Temple Lang                duncan at research.bell-labs.com
> Bell Labs, Lucent Technologies    office: (908)582-3217
> 700 Mountain Avenue, Room 2C-259  fax:    (908)582-3340
> Murray Hill, NJ  07974-2070       
>          http://cm.bell-labs.com/stat/duncan



From p.dalgaard at biostat.ku.dk  Wed Sep 24 22:27:27 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Wed, 24 Sep 2003 20:27:27 -0000
Subject: [R] storing objects (lm results) in an array
In-Reply-To: <1064426304.5435.23.camel@kryten.akl.indigoindustrial.co.nz>
References: <1064424850.2620.28.camel@christophl>
	<1064426304.5435.23.camel@kryten.akl.indigoindustrial.co.nz>
Message-ID: <x2llseq6dt.fsf@biostat.ku.dk>

Jason Turner <jasont at indigoindustrial.co.nz> writes:

> On Thu, 2003-09-25 at 05:34, Christoph Lehmann wrote:
> > Hi
> > 
> > I have calculated lots (>1000) of linear models and would like to store
> > each single result as an element of a 3D matrix or a similar storage:
> > something like
> > 
> > glm[i][j][k] = lm(...)
> > 
> > Since I read that results are lists: Is it possible to define a matrix
> > of type list? 
> > 
> > Or what do you recommend?
> 
> 1) glm is already a function name in R.  I'd suggest a different name.
> 
> 2) I don't recommend a matrix.  Matricies require contiguous memory
> chunks - it's possible to not have a long enough "block" of memory
> available, even when the total free memory is sufficient, when storing
> large matricies.

Lists can have dimensions, so 

lmarray <- array(list(),c(I,J,K))

works fine. E.g.

> array(list(),c(2,5))
     [,1] [,2] [,3] [,4] [,5]
[1,] NULL NULL NULL NULL NULL
[2,] NULL NULL NULL NULL NULL

Notice that this is not a matrix, though. At least not in the S4
sense, where the elements need to be of a base type for an object of
class "matrix".  

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From Charles.Annis at statisticalengineering.com  Wed Sep 24 22:54:16 2003
From: Charles.Annis at statisticalengineering.com (Charles Annis, P.E.)
Date: Wed, 24 Sep 2003 16:54:16 -0400
Subject: [R] information matrix test in r/s
Message-ID: <008901c382de$079a9e30$2802a8c0@DHT0TL11>

Greetings, Fellow R-ians:

I'm working with a few different quasi-likelihood formulations for some data
I'm analyzing.  I'd like to implement the Information Matrix Test (see,
e.g., White, 1982, or Lancaster, 1984) for each of them to determine which
of the models is more likely.  Since the null distribution of the test
statistic is chi-squared, I envision calculating the ordinate of the sample
value to give P(data|model) and using those values (and a discrete uniform
prior on the model-space) to calculate Bayes Factors.

Is there any pre-existing package which performs this test in R?

Halbert White, "Maximum Likelihood Estimation of Misspecified Models,"
Econometrica Vol. 50, No. 1, (Jan., 1982) pp.1-26

Tony Lancaster, "The Covariance Matrix of the Information Matrix Test,"
Econometrica, Vol 52, No.4, (July, 1984), pp.1051-1054

I would be grateful for any suggestions.

Many Thanks.

Charles Annis, P.E.

Charles.Annis at StatisticalEngineering.com
phone: 561-352-9699
eFAX: 503-217-5849
http://www.StatisticalEngineering.com



From mdalphin at amgen.com  Wed Sep 24 18:57:29 2003
From: mdalphin at amgen.com (Mark Dalphin)
Date: Wed, 24 Sep 2003 09:57:29 -0700
Subject: [R] Core dump using DBI/ROracle
Message-ID: <200309240957.29888.mdalphin@amgen.com>

Hi,

Has anyone seen this problem before, and does anyone have a solution?

When I query a database using DBI and ROracle to retrieve a date in a format 
other than the system default, I get a core dump.

System: Redhat Linux 7.3
uname: Linux 2.4.20-20.7smp #1 SMP Mon Aug 18 14:46:14 EDT 2003 i686
Oracle version 8i
R --version: R 1.7.1 (2003-06-16).
DBI_0.1-6, ROracle_0.5-0

Start up R, load libraries and create a connection to DB:
> library(DBI)
> library(ROracle)
> conn <- dbConnect("Oracle", dbname='EPIMS', user='XXX', pass='XXX')

Here is an example of a query that works:
> d <- dbGetQuery(conn,
	'SELECT HybridDate FROM Hybridization WHERE ExperimentID=2717')
> str(d)
`data.frame':   54 obs. of  1 variable:
 $ HYBRIDDATE: chr  "22-MAY-2003 00:00:00" "22-MAY-2003 00:00:00" "17-JUL-2003 
00:00:00" "17-JUL-2003 00:00:00" ...

Here is a query which dumps core (the sql is all on one line):
> d <- dbGetQuery(conn,
	"SELECT TO_CHAR(HybridDate, 'YYYY-MM-DD') FROM Hybridization WHERE 
ExperimentID=2717")
Segmentation fault (core dumped)

My current work around is to accept the Oracle default date format and then 
use R's strpdate to convert to a date format that I want. I don't like coding 
this way, however, as it relies on the Oracle date format remaining static; I 
prefer to code more 'defensively'.

I assume this is a bug in DBI/ROracle processing of functions in the selected 
variables, but I don't know. Any suggestions are welcome.

Thanks,
Mark

-- 
Mark Dalphin                          email: mdalphin at amgen.com
Mail Stop: 29-2-A                     phone: +1-805-447-4951 (work)
One Amgen Center Drive                       +1-805-375-0680 (home)
Thousand Oaks, CA 91320                 fax: +1-805-499-9955 (work)



From ross at biostat.ucsf.edu  Wed Sep 24 23:36:15 2003
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Wed, 24 Sep 2003 14:36:15 -0700
Subject: [R] density() integrates to 1?
Message-ID: <1064439375.1091.59.camel@iron.libaux.ucsf.edu>

Visual inspection of the plot of a density() function vs a normal with
the same mean and variance suggests the area under the density curve is
bigger than under the normal curve.  The two curves are very close over
most of the domain.  Assuming the normal curve does integrate to 1, this
implies the area under density() is > 1.

Is there any assurance that the density kernel smoother produces
something that integrates to 1?  Or am I seeing things?

I suppose an additional complexity is that density() produces discrete
output, but then I'm looking at the continuous curve plot produced.



From abunn at mymail.msu.montana.edu  Thu Sep 25 00:06:55 2003
From: abunn at mymail.msu.montana.edu (abunn@mymail.msu.montana.edu)
Date: Wed, 24 Sep 2003 16:06:55 -0600
Subject: [R] using assign on save?
Message-ID: <eb2a4b723bd940e796c65dc0180cc603.abunn@mymail.msu.montana.edu>

I have an object which I want to save into an external file, using save, on a time step in loop. In the loop I have an if statment that will save when the appropraite time, t, is reached.

I want to change the object and the name of the saved object to reflect which time step is being written. I can do the file name in save using paste but cannot rename the object. 

For example, I want to save object foo at time t = 50 in file "Run.50.Rdata." Furthermore, I want the object in that file to be "foo50."

This is what I'm doing now:

    save(foo, file = paste("Run", t, "Rdata",sep="."))

which creates the right file name but obviously doesn't rename the object.

So, I tried assigning the object in the save function.

  save(assign(paste("foo", t, sep = ""), foo),
       file = paste("Run", t, "Rdata",sep="."))

This crashes. It would also leave a copy of foo50 in the workspace which is messy. 

The logic of how to rename the object at a time step, reference it in the save statement and then remove it is eluding me.

Any thoughts on how to proceed?

-Andy



From Ted.Harding at nessie.mcc.ac.uk  Thu Sep 25 00:15:15 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Wed, 24 Sep 2003 23:15:15 +0100 (BST)
Subject: [R] density() integrates to 1?
In-Reply-To: <1064439375.1091.59.camel@iron.libaux.ucsf.edu>
Message-ID: <XFMail.030924231515.Ted.Harding@nessie.mcc.ac.uk>

On 24-Sep-03 Ross Boylan wrote:
> Visual inspection of the plot of a density() function vs a normal with
> the same mean and variance suggests the area under the density curve is
> bigger than under the normal curve.  The two curves are very close over
> most of the domain.  Assuming the normal curve does integrate to 1,
> this
> implies the area under density() is > 1.
> 
> Is there any assurance that the density kernel smoother produces
> something that integrates to 1?  Or am I seeing things?
> 
> I suppose an additional complexity is that density() produces discrete
> output, but then I'm looking at the continuous curve plot produced.

It should integrate to 1 (see help for density), and sum to something
very close to 1 depending on the number of points ("n=...") at which
density is evaluated.

Example:
> X<-rnorm(1000)
> Y<-density(X)   # n = 512 (default)
> x<-Y$x; y<-Y$y;
> k<-length(x);d<-min(x[2:k]-x[1:k-1]);
> sum(y*d)
[1] 1.000975
> Y<-density(X,n=2000)
> x<-Y$x; y<-Y$y;
> k<-length(x);d<-min(x[2:k]-x[1:k-1]);
> sum(y*d)
[1] 1.000240
> Y<-density(X,n=100000)
> x<-Y$x; y<-Y$y;
> k<-length(x);d<-min(x[2:k]-x[1:k-1]);
> sum(y*d)
[1] 0.9999996

Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 24-Sep-03                                       Time: 23:15:15
------------------------------ XFMail ------------------------------



From feferraz at ime.usp.br  Thu Sep 25 01:20:34 2003
From: feferraz at ime.usp.br (Fernando Henrique Ferraz)
Date: Wed, 24 Sep 2003 20:20:34 -0300
Subject: [R] Sweave \Sexpr() issue
Message-ID: <20030924232034.GA16337@gmx.de>


   Hi, I'm having a little issue with \Sexpr{bla} relating to the number of digits it is using to print its output. I understand that what \Sexpr{bla} does is parsing 'bla' inside R and then returns it coerced into a character string. The problem I'm having is that I'm losing control over the number of digits it's using to print it's output.
   For example, let's take:
   > ex <- c(10,2,3,4,24)
   > options(digits=2)
   > sd(ex)
   [1] 9.2
   > options(digits=22)
   > sd(ex)
   [1] 9.154233993076646

  When I do a \Sexpr{sd(ex)} what it does is as.character(sd(ex)), which doesn't care about the "options(digits=n)" setting. So in my .tex output instead of getting something like 9.2 I always get a representation in 20 digits or so, as in   [1] 9.154233993076646.
  
  I have tried using \Sexpr{options(digits=2),sd(ex)}, but to no effect. Apparently 'options(digits)'  has no effect on the output of 'as.character', which is used in the \Sexpr implementation.
 
 > options(digits=2)
 > as.character(sd(ex))
 [1] "9.15423399307665"

 What I tried then was:
 > options(digits=2)
 > as.character(print(sd(ex)))
 [1] 9.2

 Which works inside R, but when I to that inside an \Sexpr (\Sexpr{options(digits=2);print(sd(ex))} it prints the full [1] "9.15423399307665".

 Anyone has any ideas?

Thank you,



From jasont at indigoindustrial.co.nz  Thu Sep 25 01:31:20 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Wed, 24 Sep 2003 23:31:20 -0000
Subject: [R] Sweave \Sexpr() issue
In-Reply-To: <20030924232034.GA16337@gmx.de>
References: <20030924232034.GA16337@gmx.de>
Message-ID: <1064446744.7718.1.camel@kryten.akl.indigoindustrial.co.nz>

On Thu, 2003-09-25 at 11:20, Fernando Henrique Ferraz wrote:
>    Hi, I'm having a little issue with \Sexpr{bla} relating to the number of digits it is using to print its output.

Try \Sexpr{format(bla,digits=3)}

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
+64-(0)21-343-545



From tblackw at umich.edu  Thu Sep 25 01:48:49 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Wed, 24 Sep 2003 19:48:49 -0400 (EDT)
Subject: [R] using assign on save?
In-Reply-To: <eb2a4b723bd940e796c65dc0180cc603.abunn@mymail.msu.montana.edu>
References: <eb2a4b723bd940e796c65dc0180cc603.abunn@mymail.msu.montana.edu>
Message-ID: <Pine.SOL.4.58.0309241940220.3755@timepilot.gpcc.itd.umich.edu>

Andy  -

help("assign")  says:

"Value:  This function is invoked for its side effect, which is
assigning `value' to the variable `x'.  ..."

Gosh.  The help page isn't very specific about what the return
value of  assign()  IS, but it's not a named object.  Your basic
strategy of assigning, writing, then removing sounds like a good
one, but perhaps these have to be three separate lines inside the
loop.  If that's so, then it's worth making a temporary character
string variable with the result of  paste(), so you can use it
three times.  Think also about where the assignment is going to
take place.

Warning: I haven't tried out any of the suggestions I am making.

HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Wed, 24 Sep 2003, Andy Bunn wrote:

> I have an object which I want to save into an external file, using save, on a time step in loop. In the loop I have an if statment that will save when the appropraite time, t, is reached.
>
> I want to change the object and the name of the saved object to reflect which time step is being written. I can do the file name in save using paste but cannot rename the object.
>
> For example, I want to save object foo at time t = 50 in file "Run.50.Rdata." Furthermore, I want the object in that file to be "foo50."
>
> This is what I'm doing now:
>
>     save(foo, file = paste("Run", t, "Rdata",sep="."))
>
> which creates the right file name but obviously doesn't rename the object.
>
> So, I tried assigning the object in the save function.
>
>   save(assign(paste("foo", t, sep = ""), foo),
>        file = paste("Run", t, "Rdata",sep="."))
>
> This crashes. It would also leave a copy of foo50 in the workspace which is messy.
>
> The logic of how to rename the object at a time step, reference it in the save statement and then remove it is eluding me.
>
> Any thoughts on how to proceed?
>
> -Andy



From andy_liaw at merck.com  Thu Sep 25 03:36:38 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 24 Sep 2003 21:36:38 -0400
Subject: [R] density() integrates to 1?
Message-ID: <3A822319EB35174CA3714066D590DCD50205CBA4@usrymx25.merck.com>

There was a related thread on R-help, probably last year.  The question was
getting density() to numerically integrate to 1.  The answer is, "yes".  If
you do fine enough partitions, you will see that it integrates to one.  And
yes, a kernel density estimate is theoretically a true density (assuming the
kernel used is a pdf), because it is just a n-component mixture of the
kernel.

Andy

> -----Original Message-----
> From: Ross Boylan [mailto:ross at biostat.ucsf.edu] 
> Sent: Wednesday, September 24, 2003 5:36 PM
> To: r-help
> Subject: [R] density() integrates to 1?
> 
> 
> Visual inspection of the plot of a density() function vs a 
> normal with the same mean and variance suggests the area 
> under the density curve is bigger than under the normal 
> curve.  The two curves are very close over most of the 
> domain.  Assuming the normal curve does integrate to 1, this 
> implies the area under density() is > 1.
> 
> Is there any assurance that the density kernel smoother 
> produces something that integrates to 1?  Or am I seeing things?
> 
> I suppose an additional complexity is that density() produces 
> discrete output, but then I'm looking at the continuous curve 
> plot produced.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
>



From zitan at mediasculpt.net  Thu Sep 25 23:07:17 2003
From: zitan at mediasculpt.net (Zitan Broth)
Date: Thu, 25 Sep 2003 14:07:17 -0700
Subject: [R] R Production Performance
References: <OF8F028250.C58EE9BB-ON85256DAA.00422BB2@convergys.com>
	<00d401c382c3$d0b4a880$3201a8c0@zitan>
	<005301c38242$eba7c900$f07afea9@computer>
Message-ID: <010f01c383a9$009b8650$414c4fcb@zitan>

Hi Paul,

Thanks greatly for your message.

----- Original Message -----
> Below is the test I ran awhile back on invoking R as a system call.  It
> might be faster if you had a c-extension to R but before I went that route
I
> would want to know 1) roughly how fast Python and Perl are in returning
> results with their c-bindings/embedded stuff/dcom stuff, 2) whether R can
be
> run as a daemon process so you don't incur start up costs, and 3) whether
R
> can act as a math server in the sense that it will fork children or
threads
> as multiple users establish sessions with it.  I agree it would be nice to
> have a better interface to R than via a system call.

Yeah I agree with what you are saying here for sure.  I would like to run R
as a daemon and perhaps 'process manage' it to ensure that only one request
is passed at a time.  If you are incur even a couple fo seconds from using
file IO then for the enterprise a different approach needs to be taken.
Perhaps using swig or directly from a database.

Awesome,
Z.

> Regards,
> Paul Meagher
>
> =====================
>
> I just timed how long it took to pipe a file containing 2 lines below into
R
> (via a PHP script executed from my browser):
>
> input.R
> --------------
> x = cbind(4,5,3,2,3,4)
> x
>
>
> <?php
> // timer.php
>
> function getmicrotime(){
>   list($usec, $sec) = explode(" ",microtime());
>   return ((float)$usec + (float)$sec);
> }
>
> $time_start = getmicrotime();
>
> $Input  = "./input.R";
> $Output = "./output.R";
> $RPath = "/usr/local/bin/R";
> system("$RPath --no-save < $Input > $Output");
> $fp = fopen("$Output", "r");
> while (!feof($fp)) {
>   $line = fgets($fp,4096);
>   echo $line ."<br>";
> }
> fclose($fp);
>
> $time_end = getmicrotime();
> $time = $time_end - $time_start;
> echo "<p>Time To Execute: $time seconds</p>";
> ?>
>
> The time to execute this script was 3.1081320047379 seconds (if I execute
> the script a few times this around what I get).
>
> I then removed the line that calls R only.  There was something in the
> output.R file so, in essense, the only difference between the original
> script and modified script is the removal of the system call to R.
>
> The time to execute was 0.0010089874267578 seconds
>
> By subtractive logic, this means the call to R incurs an overhead of
around
> 3 seconds on a average web server box using the php-apache module.
>
> ============================================
>
>
>
>
>
>
> ----- Original Message -----
> From: "Zitan Broth" <zitan at mediasculpt.net>
> To: <james.holtman at convergys.com>
> Cc: <r-help at stat.math.ethz.ch>
> Sent: Wednesday, September 24, 2003 2:46 PM
> Subject: Re: [R] R Production Performance
>
>
> > Hi James,
> >
> > Thanks for your response :-)
> >
> > ----- Original Message -----
> > > It is like anything else that you want to run as part of web services:
> > what
> > > do you want it to do?  Yes, it is fast in doing computations, but what
> > will
> > > you have it do?  It is probably as fast as anything else that you will
> > find
> > > out there that is fairly general purpose.
> >
> > I just want to use R for mathematical computations, and will call it via
> PHP
> > from the commandline with infile. We'll need to obviously test this
> > ourselves, but I just thought I'd raise the question :-))
> >
> > > Are you going to be creating a lot of graphics that have to be
displayed
> > > back on the screen?  How is the user going to input data (flat files,
> XML,
> > > Excel worksheets, Oracle database, ...)?  Will you be invoking a
unique
> > > process each time a user calls, or will you be using a 'daemon' that
> will
> > > communicate with DCOM and such?  How many people will be trying to
> access
> > > it once and what is the mix of transactions that they will use?
> >
> > Well for sure the rest of the app needs to scale as well and be fast,
> > failsafe etc..., but I am just asking about R.
> >
> > I was imagining using a unique process call each time I access R, which
is
> > how the apache/php/*nix environment works best (although keeping
processes
> > in memory is achievable as well).  My experience to date on integration
> with
> > C packages deploying to *nix is that this works quite effectively
although
> > certain packages require process management that are not multiprocess
(to
> > ensure that R for example only executes one computation at a time), but
> this
> > is no problem. There are ways to call c packages directly with PHP
(swig)
> > and I am investigating this at present.
> >
> > > You can probably get a real good feel by enclosing the operations that
> you
> > > want to do in a "system.time" function to see how long it will take.
> This
> > > really depends on what you are trying to do.  I can definitely say
that
> it
> > > is faster than trying to code the algorithm in PERL or another
scripting
> > > language.
> >
> > Makes sense because R is written in C, where PERL and PHP are also
written
> > in C, so R is a "layer deep" so to speak :-)
> >
> > Thanks again,
> > Z.
> >
> > > Greetings All,
> > >
> > > Been playing with R and it is very easy to get going with the UI or
> infile
> > > batch commands :-)
> > >
> > > What I am wondering is how scalable and fast R is for running as part
of
> a
> > > web service.  I believe R is written in C which is a great start, but
> what
> > > are peoples general thoughts on this?
> > >
> > > Thanks greatly,
> > > Z.
> > >
> > >              [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > >
> > >
> > >
> > >
> > > --
> > > "NOTICE:  The information contained in this electronic mail
transmission
> > is
> > > intended by Convergys Corporation for the use of the named individual
or
> > > entity to which it is directed and may contain information that is
> > > privileged or otherwise confidential.  If you have received this
> > electronic
> > > mail transmission in error, please delete it from your system without
> > > copying or forwarding it, and notify the sender of the error by reply
> > email
> > > or by telephone (collect), so that the sender's address records can be
> > > corrected."
> > >
> > >
> > >
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>
>



From ross at biostat.ucsf.edu  Thu Sep 25 04:16:13 2003
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Wed, 24 Sep 2003 19:16:13 -0700
Subject: [R] density() integrates to 1?
In-Reply-To: <3A822319EB35174CA3714066D590DCD50205CBA4@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD50205CBA4@usrymx25.merck.com>
Message-ID: <1064456173.1091.99.camel@iron.libaux.ucsf.edu>

On Wed, 2003-09-24 at 18:36, Liaw, Andy wrote:
> There was a related thread on R-help, probably last year.  The question was
> getting density() to numerically integrate to 1.  The answer is, "yes".  If
> you do fine enough partitions, you will see that it integrates to one.  And
> yes, a kernel density estimate is theoretically a true density (assuming the
> kernel used is a pdf), because it is just a n-component mixture of the
> kernel.
> 
> Andy

With this advice, and on reinspection, I think it's possible I was
fooled in my visual integration.  There is an area where the density()
is under the normal.  Vertically, it's actually quite a bit under, even
though the two curves are horizontally very close.  So perhaps that area
is bigger than I thought, enough to account for the discrepancy.

The other possibility is that even though the points on density are OK,
the curve created by plot putting a line through them really is not OK
(in the sense of integrating to 1).  The issue for this is not the
behavior of density when one increases the number of partitions, but the
behavior at a fixed partition (the default 512 in my case).  Or rather,
that behavior plus that of plot's line.



From zitan at mediasculpt.net  Thu Sep 25 23:20:35 2003
From: zitan at mediasculpt.net (Zitan Broth)
Date: Thu, 25 Sep 2003 14:20:35 -0700
Subject: [R] R Production Performance
References: <OF8F028250.C58EE9BB-ON85256DAA.00422BB2@convergys.com>
	<00d401c382c3$d0b4a880$3201a8c0@zitan>
	<005301c38242$eba7c900$f07afea9@computer>
	<3F7121EE.6070603@joeconway.com>
Message-ID: <011901c383aa$dc7d6430$414c4fcb@zitan>

Hi Joe,

Thanks for your message,

> I'm doing something similar using PL/R (an R procedural language handler
> extension to Postgres that I wrote) with Postgres, R, and PHP. In
> Postgres 7.4 (currently at beta3) or with a back-patched copy of 7.3,
> you can preload the R interpreter when the Postgres postmaster first
> starts. This means that essentially R is running as part of the Postgres
> daemon. Whenever a connection is made to the database, the forked
> process already has an initialized copy of R running inside it. The
> startup savings I see are similar to what you did (2.2 seconds versus
> 0.009 seconds):

That sounds cool, it also avoids the file IO.  I'm an R newbie, but could I
achieve something similar with pure PHP.  I was considering trying to use
SWIG for accessing R ( and another package OOQP ).  I am currently working
with MySQL for a demo project, but we have always been considered Postgres
as a more robust database (it actually has stored procedure languages for
example).  I think I may have to give your PL/R a serious look (although I
can't access you site just now).

Are you 'process managing' your calls to R to ensure that it is thread safe
or have you found this unnecessary with the php/postgres/R combo?

Awesome, Z.

> ------------------------------------------------------------------
> Function -- intentionally very simple:
> --------------------------------------
> create or replace function echo(text) returns text as 'print(arg1)'
> language 'plr';
>
> Without preloading (first function call):
> -----------------------------------------
> regression=# explain analyze select echo('hello');
>   Total runtime: 2195.35 msec
>
> Without preloading (second function call):
> -----------------------------------------
> regression=# explain analyze select echo('hello');
>   Total runtime: 0.55 msec
>
> With preloading (first function call):
> -----------------------------------------
> regression=# explain analyze select echo('hello');
>   Total runtime: 9.74 msec
>
> With preloading (second function call):
> -----------------------------------------
> regression=# explain analyze select echo('hello');
>   Total runtime: 0.59 msec
> ------------------------------------------------------------------
>
>
> In both cases the second (and subsequent) function calls are even faster
> because the PL/R function itself has been precompiled and cached.
>
> I call the PL/R function from PHP to read my data directly from the
> database, process it, and generate whatever charts I need. Here's a very
> simple example:
>
>
> The PL/R function:
> ------------------------------------------------------------------
> create type histtup as
> (
>    break float8,
>    count int
> );
>
> create or replace function hist(text, text)
> returns setof histtup as '
>   sql <- paste("select id_val from sample_numeric_data ",
>                "where ia_id=''", arg1, "''", sep="")
>   rs <- pg.spi.exec(sql)
>
>   if (!is.na(arg2)) {
>      x11(display=":5")
>      jpeg(file=arg2, width = 480, height = 480,
>           pointsize = 12, quality = 75)
>      par(ask = FALSE, bg = "#F8F8F8")
>      sql <- paste("select ia_attname as val from atts ",
>                   "where ia_id=''", arg1, "''", sep="")
>      attname <- pg.spi.exec(sql)
>      h <- hist(rs[,1], col = "blue",
>                main = paste("Histogram of", attname$val),
>                xlab = attname$val);
>      dev.off()
>      system(paste("chmod 666 ", arg2, sep=""),
>             intern = FALSE, ignore.stderr = TRUE)
>    }
>    else
>      h <- hist(rs[,1], plot = FALSE);
>
>    result = data.frame(breaks = h$breaks[1:length(h$breaks)-1],
>             count = h$counts);
>
>    return(result)
> ' language 'plr';
> ------------------------------------------------------------------
>
> The PHP page:
> ------------------------------------------------------------------
> <HTML><BODY>
> <?PHP
> echo "
> <FORM ACTION='$PHP_SELF' METHOD='post' NAME='proto_form'>
> <TABLE WIDTH='482' CELLSPACING='0' CELLPADDING='1' BORDER='0'>
>    <TR>
>      <TD>Data</TD>
>      <TD><INPUT TYPE='text' NAME='userdata' value='' size='80'></TD>
>    </TR>
>    <TR>
>      <TD colspan='2'>
>        <INPUT TYPE='submit' NAME='submit' value='Submit'>
>      </TD>
>    </TR>
> </TABLE>
> </FORM>
> ";
>
> if ($_POST['submit'] == "Submit")
> {
>    $tmpfilename = 'charts/hist1.jpg';
>    $conn = pg_connect("dbname=oscon user=postgres");
>    $sql = "select * from hist('" . $_POST['userdata'] . "','" .
>           "/tmp/" . $tmpfilename . "')";
>    $rs = pg_query($conn,$sql);
>    echo "<img src='$tmpfilename' border=0>";
> }
> ?>
> </BODY></HTML>
> ------------------------------------------------------------------
>
>
> Hopefully this gives you some ideas about what is possible. If you're
> interested in PL/R, you can grab a copy (along with a patched 7.3.4
> source RPM for Postgres) here: http://www.joeconway.com/
>
> HTH,
>
> Joe
>
>
>



From zitan at mediasculpt.net  Thu Sep 25 23:23:47 2003
From: zitan at mediasculpt.net (Zitan Broth)
Date: Thu, 25 Sep 2003 14:23:47 -0700
Subject: [R] R Production Performance
References: <OF8F028250.C58EE9BB-ON85256DAA.00422BB2@convergys.com>
	<00d401c382c3$d0b4a880$3201a8c0@zitan>
	<005301c38242$eba7c900$f07afea9@computer>
	<010f01c383a9$009b8650$414c4fcb@zitan>
Message-ID: <012901c383ab$4efcea30$414c4fcb@zitan>

Opps I meant "incur a couple of seconds overhead for starting R" rather than
file IO.

It would be nice to be able to preload the R interpreter like Joe is doing
with Postgres thereby running it as a daemon .....

Z.

----- Original Message -----
> Yeah I agree with what you are saying here for sure.  I would like to run
R
> as a daemon and perhaps 'process manage' it to ensure that only one
request
> is passed at a time.  If you are incur even a couple fo seconds from using
> file IO then for the enterprise a different approach needs to be taken.
> Perhaps using swig or directly from a database.



From Simon.Blomberg at anu.edu.au  Thu Sep 25 06:44:26 2003
From: Simon.Blomberg at anu.edu.au (Simon Blomberg)
Date: Thu, 25 Sep 2003 14:44:26 +1000
Subject: [R] mixing nested and crossed factors using lme
Message-ID: <7A3A13F416B40842BD2C1753E044B359B1342B@CASEVS02.cas.anu.edu.au>

Hi all,

I have an experiment where 5 raters assessed the quality of 24 web sites. (each rater rated each site once). I want to come up with a measure of reliability of the ratings for the web sites ie to what extent does each rater give the same (or similar) rating to each web site. My idea was to fit a random effects model using lme and from that, calculate the intraclass correlation as a measure of rater reliability. So I analysed it using a two-factor, unreplicated random effects model, with sitenumber and rater as crossed random effects. The call to lme was:

fit <- lme(score ~ 1, random=list(level=pdBlocked(list(pdIdent(~sitenumber-1), pdIdent(~rater-1)))),data=scores)

which makes sense, and I then calculated the intraclass correlation using the within sitenumber (ie among raters) variance, the within rater variance and the residual variance (using VarCorr(fit)): 
rho = var_among/(var_among + var_within + var_resid)

Now, the raters can be divided into two groups. I would like to include group as a fixed factor, to test whether there is a difference in scores between groups (I know the number of raters is too small. This is a pilot study and I am really just trying to get the analysis right in case we want to expand the study). raters therefore are nested within group. My initial guess was:

fit2 <- lme(score ~ group, random=list(level=pdBlocked(list(pdIdent(~sitenumber-1), pdIdent(~rater-1)))),data=scores)

but this fit implies (I think) that sitenumber AND rater are nested within group (sitenumber is not nested within group), and results in the wrong denominator degrees of freedom for the test of group (118). I then tried a slightly different approach:

fit3 <- lme(score ~ group, random=list(level=pdIdent(~sitenumber-1), rater=pdIdent(~group-1)),data=scores)

which gives the correct denominator degrees of freedom for the group effect (3). But it implies that rater is nested within level. Given that level is a dummy factor with only one level, I don't think this matters and I can "pretend" that it is really a crossed design. Is that correct? Or am I way off beam here? Can anyone suggest a more appropriate lme call? The more I think about it the more confused I get.

Thanks in advance,

Simon.

Simon Blomberg, PhD
Depression & Anxiety Consumer Research Unit
Centre for Mental Health Research
Australian National University
http://www.anu.edu.au/cmhr/
Simon.Blomberg at anu.edu.au  +61 (2) 6125 3379



From mail at joeconway.com  Thu Sep 25 07:00:44 2003
From: mail at joeconway.com (Joe Conway)
Date: Wed, 24 Sep 2003 22:00:44 -0700
Subject: [R] R Production Performance
In-Reply-To: <011901c383aa$dc7d6430$414c4fcb@zitan>
References: <OF8F028250.C58EE9BB-ON85256DAA.00422BB2@convergys.com>
	<00d401c382c3$d0b4a880$3201a8c0@zitan>
	<005301c38242$eba7c900$f07afea9@computer>
	<3F7121EE.6070603@joeconway.com>
	<011901c383aa$dc7d6430$414c4fcb@zitan>
Message-ID: <3F72767C.6080509@joeconway.com>

Zitan Broth wrote:
> That sounds cool, it also avoids the file IO.  I'm an R newbie, but could I
> achieve something similar with pure PHP.

I don't know of a way to achieve it with pure PHP short of writing your 
own C extension to PHP. I had considered that at one point, but have 
found it unnecessary since my data is already in Postgres and PL/R lets 
me do what I need.

> I am currently working with MySQL for a demo project,
> but we have always been considered Postgres as a more robust
> database (it actually has stored procedure languages for example).

Yes, in fact that is exactly what PL/R is -- a handler that allows your 
stored procedures to be written in R.

> I think I may have to give your PL/R a serious look (although I
> can't access you site just now).

Sorry about that. I've been having hardware problems with my server 
lately. It's back up now, and hopefully will stay up until I have a 
chance to replace a bad drive this coming weekend.

> Are you 'process managing' your calls to R to ensure that it is thread safe
> or have you found this unnecessary with the php/postgres/R combo?

There are no thread safety issues because Postgres is multi-process, not 
multi-threaded. Each database connection gets its own private copy of R, 
and only does one thing at a time.

There may be some considerations if you do connection pooling or use 
persistent connections though. I haven't needed that so far, so I can't 
say I've thought much about it yet.

Joe



From braver at pobox.com  Thu Sep 25 07:26:51 2003
From: braver at pobox.com (Alexy Khrabrov)
Date: Thu, 25 Sep 2003 01:26:51 -0400
Subject: [R] data lost in cv.tree?
Message-ID: <20030925052649.GA25435%alexy.khrabrov@setup.org>


Greetings -- I'm programming a data mining system
in R for protein structural data.  As a seasoned
Perl and Python and Ada and ML, et al., programmer,
I am severely befuddled by the environment problem,
where data is not found in a 3rd level nested
function.  I did peruse the parent frame not on the
search path idea, and came up with a hack which
kinda works, also below with the code which should
work but doesn't.  However, until I fully understand
the issue, I cannot trust my model, which is serious.
So here's a toy example I extracted from my code,
reproducing the problem:


##################################################################


where.is.X <- function() {
  nx <- 3
  ny <- 4
  y <- as.factor(c(1,0,1,1))
  X <- data.frame(matrix(c(1:(nx*ny)), nrow = ny, ncol = nx,
                         dimnames=list(c(),paste("x",1:nx,sep=""))))

  btr <- best.tree.lost(y~., X)
  print(summary(btr))
}


best.tree.lost <- function (fmla, X) {
  tr <- tree(fmla, X)
  print(summary(tr))
  cvtr <- cv.tree(tr, envir=parent.frame())
  size <- cvtr$size[order(cvtr$dev)[1]]
  print(size)
  btr <- prune.tree(tr, best=size)
  btr
}


##################################################################


here.is.X <- function() {
  nx <- 3
  ny <- 4
  y <- as.factor(c(1,0,1,1))
  X <- data.frame(matrix(c(1:(nx*ny)), nrow = ny, ncol = nx,
                         dimnames=list(c(),paste("x",1:nx,sep=""))))

  btr <- best.tree.found(y~., X)
  print(summary(btr))
}


best.tree.found <- function (fmla, X) {

  assign(".fmla", fmla, sys.frame(0))
  assign(".X", X, sys.frame(0))

  assign(".tr", tree(.fmla, .X), sys.frame(0))
  print(summary(.tr))
  cvtr <- cv.tree(.tr)
  size <- cvtr$size[order(cvtr$dev)[1]]
  print(size)
  btr <- prune.tree(.tr, best=size)
  btr
}

Now, if you ask
> where.is.X()
you get:
> Error in model.frame.default(formula = fmla, data = X, subset = c("1",  : 
	Object "X" not found

and if you say
> here.is.X()

you get a normal error :)  (as the toy tree is a singleton, if you know
of an easy way to generate a meaningful X for it, please show me).

At this point, I went looking for ways to achieve the effect of .found
in .lost without the global assignment.  To my horror, I found that
you can supply environments, local=list(...), try to assign frames,
say something like data=parent.frame(); that formuli have frames somewhere
associated with them; that I am never longer sure, for y~., what y and .
actually are at a point in space and time; that model.frame(tr) magically
finds out that I supplied data=X, even though I didn't name X in 
tree(fmla, X); that cv.tree can't find X even though it's not a parameter,
and if tr needs to know it, it sort of should make sure it knows where it
took it from in the first place!

Horrors!  Please enlighten me where formuli and models keep their training
data sets, how can I verify they are what they should have been, or I will
never trust R models.  As a pro I can quickly hack anything with globals,
but copying stuff around is not the answer.  I need the R model.frame 
enlightenment!

Same problem arises in stepAIC, and global assignment to frame 0 solves
it, but there should be (a) a better way and (b) a clear general understanding
as to where formuli and data frames are associated and found!

For dessert, I want to run R under cygwin; Windows distro is stand-alone,
quits in cygwin; is there a cygwin-ready distro?  Compiling with mingw
howtos seem to be for the stand-aloner also...  And just by itself, it
doesn't compile easily (?)...

Cheers,
Alexy



From braver at pobox.com  Thu Sep 25 08:02:57 2003
From: braver at pobox.com (Alexy Khrabrov)
Date: Thu, 25 Sep 2003 02:02:57 -0400
Subject: [R] data lost in cv.tree?
In-Reply-To: <20030925052649.GA25435%alexy.khrabrov@setup.org>
References: <20030925052649.GA25435%alexy.khrabrov@setup.org>
Message-ID: <20030925060255.GA25590%alexy.khrabrov@setup.org>

Oh, disregard the second argument to cv.tree, it's one of my
gazillion attempts to make the .lost work by saying silly
things a la local=list(X=X) or some such, all to no avail...

Cheers,
Alexy



From ok at cs.otago.ac.nz  Thu Sep 25 08:26:35 2003
From: ok at cs.otago.ac.nz (Richard A. O'Keefe)
Date: Thu, 25 Sep 2003 18:26:35 +1200 (NZST)
Subject: [R] Diamond graphs, again.
Message-ID: <200309250626.h8P6QZlP065169@atlas.otago.ac.nz>


Some time ago I was allowed to discuss "Diamond Graphs", and whether
they would be useful in R, in this mailing list.
The August 2003 issue of The American Statistician has finally arrived
here and I have been able to read the article.  A number of points of
interest arise.

1.  The article is
    "A Diamond-Shaped Equiponderant Graphical Display of the
    Effects of Two Categorical Predictors on Continuous Outcomes"
    by Xiuhong Li, Jennier M. Buechner, Patrike M. Tarwater,
    and Alvaro M\~unoz.
    The American Statistician, August 2003, pages 193-199.

    (All of the family names are displayed in small caps except for
    Xiuhong Li's.  Does anyone know why?)

2.  There are three examples in the paper.

    a.  Figures 2 and 3 display likelihood of developing AIDS
        as the thing to be explained, with plasma HIV-RNA level
        (measured in copies per ml) and degree of immune deficiency
        (measured in count of CD4+ T-lymphocyte cells per cubic mm)
        as the explanatory variables.

        The explanatory variables are continuous, not categorical.
        If the raw data were used, it would be possible to estimate
        a 2d probability density and display that.  The variables have
        been made categorical by cutting to 5 levels each.

	I managed to get a copy of the article this is based on.  It
	certainly isn't clear from the diamond graph that the viral load
	categories were approximately quartiles, with the bottom
	quartile split in two.  So two of the viral load categories have
	less data than the other three.  Much the same happened with the
	CD4+ levels, which is also not apparent.

        Using a diamond graph instead of a density plot with rugs on the
        margins hides the amount of data available for estimating the
        cells (6 of the 25 cells are empty because there is missing data).

	Viral load and CD4+ count were respectively the best and second	
	best predictor out of five predictors (seven are listed at one
	point; I guess this means that CD3+ and CD8+ levels weren't useful
	at all).  I have skimmed the article a couple of times, and cannot
	figure out why just two predictors were chosen.  It would be of
	interest to see graphs for one predictor, two predictors, and
	three predictors.  I have not yet seen any diamond graphs with
	three explanatory variables...

    b.  Figures 4-6 display (age-adjusted rate of end-stage renal
        disease due to any cause per 100,000 person-years) as the thing
        to be explained, with systolic blood pressure (measured in mm Hg)
        and diastolic pressure (measured in mm Hg) as the explanatory
        variables.

	Once again the explanatory variables are continuous, not
	categorical.  They are cut to 6 levels each.  With the raw data,
	one could perhaps get a contour plot of fitted disease rate
	and a scatterplot of the explanatory variables on the same graph.
        4 of the 36 cells are empty, but in this case the values in the
        cells basically _are_ counts, so we are _not_ left wondering
        how much data each cell is based on.

        I have not yet seen the article this was based on.

    c.  Figure 7 has two graphs.  On the left it's relative risk of
        breast cancer as the thing to be explained, with adult weight
        change (measured in kg; why not as a proportion of starting weight?)
        and hormone use (never, past, current) as the explanatory variables.
        On the right excess risk is to be explained, with the same
        explanatory variables.

	One of the explanatory variables is continuous.  (Although it is
	not obvious to me that a weight change of 10 kg in a 55kg woman
	should have the same significance as a weight change of 10kg in
	a 75kg woman.)

	It strikes me that the other explanatory variable may well be
	an approximation to a continuous predictor also (some kind of
	exponentially weighted dose, perhaps).

	I have not yet seen the article this was based on.  I have seen
	the abstract, though, which draws a conclusion somewhat at odds
	with the apparent significance of these graphs.  I expect that
	this shows that the diamond graphs _are_ useful.

        Like "a", we get no idea of how much data each cell is based on.

    In no case were there really two categorical predictors to start with.

3.  I finally pinned down what these graphs remind me of:  the two-way
    plots described in Tukey's 1977 book "Exploratory Data Analysis",
    which is not cited in the article.  Tukey's basic idea goes like this:
    (1) Fit an additive model to the data (median polish, whatever).
    (2) Tilt and spread the axes so that the vertical dimension is the
        fitted values.
    (3) Draw lines, not boxes, so that the fitted value for X=m Y=n
        is the level at the intersection of the lines for X=m and Y=n.
    (4) Now that you can see what the fitted values are from the
        intersections, plot the residuals, either as sticks from the
        intersection to the true value, or as variously sized/shaped
        blobs to show the relative magnitudes of the residuals.

    Once I realised this, I realised what really bothered me about these
    graphs.  They simply summarise the raw data (crudely).  There is no
    "data = fit + residuals".  I found myself _itching_ for the raw data
    so that I could see what was really going on.

4.  The paper compares a diamond graph (figure 5) with a trellis graph,
    or rather, a pair of trellis graphs (figure 6) for the same data.
    I felt much more comfortable with the trellis graph, largely because
    the numbers (in the range 0..200ish) were well spread out.  The
    trellis graph was, however, much bigger, and is less immediately
    accessible; the diamond graph conveys an impression of understanding
    without needing a lot of explanation.

5.  My analysis of perceptual issues was right in some respects and wrong
    in others.  The hexagons have been very carefully designed so that
    - the area is proportional to p
    - one length is proportional to p
    - the difference of two other lengths is proportional to p
    where p is the value in the interval [0,1] which is to be presented.
    I must say that for me the visually most salient length is one which
    is _not_ proportional to p (it's (1+p)/2).

6.  The article neither presents nor cites any experimental data to show
    that any task can be completed faster or more accurately using
    diamond graphs than some other kind of display.  As yet, it's a
    matter of opinion.

7.  It is unfortunate that the name "diamond graph" was chosen;
    "diamond graph" is an established technical term in mathematics.


You could get much the same effect by plotting discs of varying sizes,
or sectors of varying width, or little thermometers, or practically
anything varying in area, on a standard horizontal & vertical table,
and then rotating the paper by hand.  You won't be able to estimate
sizes accurately, but thanks to the cramped range available you aren't
going to estimate sizes accurately from a diamond graph anyway
(unless you can read the number displayed in the centre, which in my
photocopy of the article I can't).

In short, diamond graphs offer a reasonably clear way to summarise some
kinds of data, particularly for non-statisticians, but neither express
nor lead to any kind of analysis.

Since R is a statistics package rather than a "business presentation
graphics" package, perhaps Tukey-style two-way plots (are they already
available somewhere?)  would be more useful than diamond graphs.



From maechler at stat.math.ethz.ch  Thu Sep 25 09:56:27 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 25 Sep 2003 09:56:27 +0200
Subject: [R] splitting clusters
In-Reply-To: <OFFC4D14A4.85CBB82F-ON85256DAB.005D85A1@hc-sc.gc.ca>
References: <OFFC4D14A4.85CBB82F-ON85256DAB.005D85A1@hc-sc.gc.ca>
Message-ID: <16242.40875.639185.181702@gargle.gargle.HOWL>

>>>>> "KarthiS" == Subramanian Karthikeyan <Subramanian_Karthikeyan at hc-sc.gc.ca>
>>>>>     on Wed, 24 Sep 2003 13:04:04 -0400 writes:

    KarthiS> Hi All: I am clustering 500 genes using hclust of
    KarthiS> R.  Visualizing cluster membership becomes
    KarthiS> difficult with so many genes in each cluster...Is
    KarthiS> there a way of printing the dendrogram in multiple
    KarthiS> pages so that I can clearly see what is in each
    KarthiS> cluster?

- Use dd <- as.dendrogram(hc) on your hclust result `hc',
  then dd[1] gives the first branch, dd[1][2] the 2nd sub-branch of
  the first branch, etc., see the examples on
  ?dendrogram.

- The package "maptree" has also tools for this,
  particularly  prune.clust()

    KarthiS> Thanks in advance.

you're welcome.
-- 
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From maechler at stat.math.ethz.ch  Thu Sep 25 10:13:54 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 25 Sep 2003 10:13:54 +0200
Subject: [R] Sweave \Sexpr() issue
In-Reply-To: <1064446744.7718.1.camel@kryten.akl.indigoindustrial.co.nz>
References: <20030924232034.GA16337@gmx.de>
	<1064446744.7718.1.camel@kryten.akl.indigoindustrial.co.nz>
Message-ID: <16242.41922.192625.532375@gargle.gargle.HOWL>

>>>>> "Jason" == Jason Turner <jasont at indigoindustrial.co.nz>
>>>>>     on 25 Sep 2003 11:39:05 +1200 writes:

    Jason> On Thu, 2003-09-25 at 11:20, Fernando Henrique Ferraz
    Jason> wrote:
    >> Hi, I'm having a little issue with \Sexpr{bla} relating
    >> to the number of digits it is using to print its output.

    Jason> Try \Sexpr{format(bla,digits=3)}

Yes, definitely use  format() { or formatC() }!

format() actually  *does* use  `options(digits)' .
So you could set the option and then call format() several times
without setting digits.  
{ formatC() main purpose has been for text in graphics, and
  hence does not use options(digits),  but by default uses only
  a few digits}

Martin



From plummer at iarc.fr  Thu Sep 25 11:22:57 2003
From: plummer at iarc.fr (Martyn Plummer)
Date: Thu, 25 Sep 2003 09:22:57 -0000
Subject: [R] Red Hat 9 RPM requirements
Message-ID: <1064481971.992.105.camel@xena>

I've just added this section to the ReadMe file that accompanies the Red
Hat 9 RPMS. I hope this will save people some trouble in the future.
Martyn

Requirements
------------

Some people have experienced problems satisfying the dependencies
of the R RPM.  Here is a complete list of requirements, the RPMS
that provide them and where to find them on the 3-disk install set.

Requirement       RPM                  Disk Classification
-----------       ---                  ---- --------------
Perl              perl-5.8.0-88         1   Development/Languages
libICE.so.6       XFree86-libs-4.3.0-2  1   System Environment/Libraries
libSM.so.6        XFree86-libs-4.3.0-2      "
libX11.so.6       XFree86-libs-4.3.0-2      "
libblas.so.3      blas-3.0-20           2   Development/Libraries
libc.so.6         glibc-2.3.2-11.9      1   System Environment/Libraries
libdl.so.2        glibc-2.3.2-11.9          "
libm.so.6         glibc-2.3.2-11.9          "
libg2c.so.0       libf2c-3.2.2-5        2   System Environment/Libraries
libgcc_s.so.1     libgcc-3.2.2-5        1   System Environment/Libraries
libjpeg.so.62     libjpeg-6b-26         1   System Environment/Libraries
libncurses.so.5   ncurses-5.3-4         1   System Environment/Libraries
libpng12.so.0     libpng-1.2.2-16       1   System Environment/Libraries
libreadline.so.4  readline-4.3-5        1   System Environment/Libraries
libtcl8.3.so      tcl-8.3.5-88          1   Development/Languages
libtk8.3.so       tk-8.3.5-88           3   Development/Languages
libz.so.1         zlib-1.1.4-8          1   System Environment/Libraries

Don't use the graphical interface provided by Red Hat to install
packages. It is quite useless compared to "gnorpm" which was used in
previous releases of Red Hat Linux. The new GUI provides a dumbed down
interface for beginners without any extra functionality for power users.
For example, you won't find any packages that are classified under
"System Environment/Libraries", presumably because Red Hat don't want
you to try and uninstall them. The package tk is found under "Kernel
development", which is not where you would think to look, simply because
there is a tk GUI to configure the kernel.

You may also notice that the library "libg2c.so.0" is provided by the
package "libf2c", which doesn't seem like the best naming convention.
Especially as there is a program called f2c that has nothing to do with
it.



From lutz.thieme at amd.com  Thu Sep 25 11:31:01 2003
From: lutz.thieme at amd.com (lutz.thieme@amd.com)
Date: Thu, 25 Sep 2003 11:31:01 +0200
Subject: [R] multiple plot layout and filled contour
Message-ID: <E540DF203FFED21182EB0008C728756014A874DC@deexmta4.amd.com>

Hello everybody,

Could anybody give me a hint how I can use "layout" and "filled.contour"  (or  "image"
plot with a color legend) together, please?
What I want to do is something like the following example (Two or more plots with a 
legend for each at one page):

data(volcano)
layout(matrix(1:2, 1, 2, byrow = TRUE))
for (i in 1:2) {
	filled.contour(i*volcano, color = terrain.colors, asp = 1)
}

Thank you in advance.


	Kind regards,

	Lutz


	Lutz Thieme
	Product Engineering
	AMD Saxony Limited Liability Company & Co. KG
	M/S E22-PE, Wilschdorfer Landstr. 101
	D-01109 Dresden, Gemany
	phone:	+ 49-351-277 -  4269
	fax:		+ 49-351-277-9-4269



From ramasamya at gis.a-star.edu.sg  Thu Sep 25 13:01:28 2003
From: ramasamya at gis.a-star.edu.sg (Adaikalavan RAMASAMY)
Date: Thu, 25 Sep 2003 19:01:28 +0800
Subject: [R] density() integrates to 1?
Message-ID: <6D9E9B9DF347EF4385F6271C64FB8D56075F7D@BIONIC.biopolis.one-north.com>

We can try a to approximate the area under the curve using Trapezoidal rule on the plotting coordinates that density() produces. 


nbin <- 1024                   # number of bin

d <- density( rnorm(50000), n=nbin)

totalArea <- 0
 
for(i in 1:(nbin-1) ){

  xxx <- d$x[i+1] - d$x[i]     # width of bin
  yyy <- (d$y[i+1] + d$y[i])/2 # average height of bin

  binArea <- xxx*yyy
  totalArea <- totalArea + binArea
}

print(totalArea)               

We can see that the total area under the curve is close to 1 and the approximation gets better as nbin is increased (but this is always an overestimate due to the concavity of the normal curve).



From claus at ekstroem.dk  Thu Sep 25 13:33:00 2003
From: claus at ekstroem.dk (Claus Ekstroem)
Date: Thu, 25 Sep 2003 13:33:00 +0200
Subject: [R] Labels and tick mark sizes for persp
Message-ID: <20030925113300.GA23555@dina.kvl.dk>

Hi,

I think I'm missing something obvious here but I can't seem to be able 
to scale tick marks and labels individually in persp.

For example:

x <- matrix(rnorm(100), 10)
par(mfrow=c(2, 2))
persp(x, phi=35, theta=35, ticktype="detailed")
persp(x, phi=35, theta=35, ticktype="detailed", cex=2)
persp(x, phi=35, theta=35, ticktype="detailed", cex.lab=2)
persp(x, phi=35, theta=35, ticktype="detailed", cex.axis=2)

What am I doing wrong (or is persp only accounting for cex)? Setting the 
plotting options with par before each call produces the same result as 
above

Cheers,

Claus

-- 
*****************************************
Claus Thorn Ekstr?m <ekstrom at dina.kvl.dk>
Dept of Mathematics and Physics, KVL
Thorvaldsensvej 40
DK-1871 Frederiksberg C
Denmark
Phone:[+45] 3528 2341
Fax:  [+45] 3528 2350



From christoph.lehmann at gmx.ch  Thu Sep 25 13:31:38 2003
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Thu, 25 Sep 2003 13:31:38 +0200
Subject: [R] Error from gls call (package nlme)
Message-ID: <1064489498.1151.32.camel@christophl>

Hi
I have a huge array with series of data. For each cell in the array I
fit a linear model, either using lm() or gls()

with lm() there is no problem, but with gls() I get an error:

	Error in glsEstimate(glsSt, control = glsEstControl) :
        	computed gls fit is singular, rank 2

as soon as there are data like this:
	> y1 <- c(0,0,0,0)
	> x1 <- c(0,1,1.3,0)
	> gls(y1~x1)
	Error in glsEstimate(glsSt, control = glsEstControl) :
	        computed gls fit is singular, rank 2

of course, this is not a problem for lm()

	> lm(y1~x1)
 
	Call:
	lm(formula = y1 ~ x1)
	 
	Coefficients:
	(Intercept)           x1
	          0            0

I know, that such data does not make "sense" but it is possible, that
something like this occurs in my data-set. Since I call gls() for every
cell of my array in a loop, I don't want such errors to occur, since
this breaks my loop.

what is the problem here? What are potential solutions?

Many thanks

Christoph
-- 
Christoph Lehmann <christoph.lehmann at gmx.ch>



From Simon.Fear at synequanon.com  Thu Sep 25 13:49:59 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Thu, 25 Sep 2003 12:49:59 +0100
Subject: [R] Error from gls call (package nlme)
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572AC0DEB@synequanon01>

For a quick fix see ?try, in particular the last example there.

Afraid I am no expert in gls (which, you might mention, is in
package nlme) to explain the real cause of the problem.


> -----Original Message-----
> From: Christoph Lehmann [mailto:christoph.lehmann at gmx.ch]
> Sent: 25 September 2003 12:32
> To: r-help at stat.math.ethz.ch
> Subject: [R] Error from gls call (package nlme)
> 
> 
> Security Warning:
> If you are not sure an attachment is safe to open please contact 
> Andy on x234. There are 0 attachments with this message.
> ________________________________________________________________
> 
> Hi
> I have a huge array with series of data. For each cell in the array I
> fit a linear model, either using lm() or gls()
> 
> with lm() there is no problem, but with gls() I get an error:
> 
> 	Error in glsEstimate(glsSt, control = glsEstControl) :
>         	computed gls fit is singular, rank 2
> 
> as soon as there are data like this:
> 	> y1 <- c(0,0,0,0)
> 	> x1 <- c(0,1,1.3,0)
> 	> gls(y1~x1)
> 	Error in glsEstimate(glsSt, control = glsEstControl) :
> 	        computed gls fit is singular, rank 2
> 
> of course, this is not a problem for lm()
> 
> 	> lm(y1~x1)
>  
> 	Call:
> 	lm(formula = y1 ~ x1)
> 	 
> 	Coefficients:
> 	(Intercept)           x1
> 	          0            0
> 
> I know, that such data does not make "sense" but it is possible, that
> something like this occurs in my data-set. Since I call gls() 
> for every
> cell of my array in a loop, I don't want such errors to occur, since
> this breaks my loop.
> 
> what is the problem here? What are potential solutions?
> 
> Many thanks
> 
> Christoph
> -- 
> Christoph Lehmann <christoph.lehmann at gmx.ch>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
 

Simon Fear
Senior Statistician
Syne qua non Ltd
Tel: +44 (0) 1379 644449
Fax: +44 (0) 1379 644445
email: Simon.Fear at synequanon.com
web: http://www.synequanon.com
 
Number of attachments included with this message: 0
 
This message (and any associated files) is confidential and\...{{dropped}}



From Charles.White at NA.AMEDD.ARMY.MIL  Thu Sep 25 14:05:59 2003
From: Charles.White at NA.AMEDD.ARMY.MIL (White, Charles E WRAIR-Wash DC)
Date: Thu, 25 Sep 2003 08:05:59 -0400
Subject: [R] probit analysis for correlated binary data
Message-ID: <12D0D00E1404D511A4820090274CA09C03FBA47C@dasmtyjqf010.amedd.army.mil>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030925/ab802560/attachment.pl

From elsawy at ysbl.york.ac.uk  Thu Sep 25 14:18:14 2003
From: elsawy at ysbl.york.ac.uk (Karim Elsawy)
Date: Thu, 25 Sep 2003 13:18:14 +0100
Subject: [R] 3d contours
Message-ID: <3F72DD06.8CEE8387@ysbl.york.ac.uk>

Hi,
I wonder if there is any R package or function which produces the
coordinates of a 3d contours (isosurface) 
from a 3d data array.
any suggestions are very much appreciated
best regards
karim



From spencer.graves at pdf.com  Thu Sep 25 14:56:57 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 25 Sep 2003 07:56:57 -0500
Subject: [R] 3d contours
In-Reply-To: <3F72DD06.8CEE8387@ysbl.york.ac.uk>
References: <3F72DD06.8CEE8387@ysbl.york.ac.uk>
Message-ID: <3F72E619.9080301@pdf.com>

Have you cosidered (a) "contour" or (b) "image" possibly followed by 
"contour(..., add=TRUE)", possibly preceeded by "interp"?  If you have, 
then you must want to plot contours in three dimensions where a fourth 
is constant ... ? 

hope this helps.  spencer graves

Karim Elsawy wrote:

>Hi,
>I wonder if there is any R package or function which produces the
>coordinates of a 3d contours (isosurface) 
>from a 3d data array.
>any suggestions are very much appreciated
>best regards
>karim
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From rpeng at jhsph.edu  Thu Sep 25 14:54:45 2003
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu, 25 Sep 2003 08:54:45 -0400
Subject: [R] multiple plot layout and filled contour
In-Reply-To: <E540DF203FFED21182EB0008C728756014A874DC@deexmta4.amd.com>
References: <E540DF203FFED21182EB0008C728756014A874DC@deexmta4.amd.com>
Message-ID: <3F72E595.5080608@jhsph.edu>

As far as I know, you can't use layout() with filled.contour() because 
filled.contour() itself uses layout().  You might be able to use 
levelplot() in the 'lattice' package.

-roger

lutz.thieme at amd.com wrote:

>Hello everybody,
>
>Could anybody give me a hint how I can use "layout" and "filled.contour"  (or  "image"
>plot with a color legend) together, please?
>What I want to do is something like the following example (Two or more plots with a 
>legend for each at one page):
>
>data(volcano)
>layout(matrix(1:2, 1, 2, byrow = TRUE))
>for (i in 1:2) {
>	filled.contour(i*volcano, color = terrain.colors, asp = 1)
>}
>
>Thank you in advance.
>
>
>	Kind regards,
>
>	Lutz
>
>
>	Lutz Thieme
>	Product Engineering
>	AMD Saxony Limited Liability Company & Co. KG
>	M/S E22-PE, Wilschdorfer Landstr. 101
>	D-01109 Dresden, Gemany
>	phone:	+ 49-351-277 -  4269
>	fax:		+ 49-351-277-9-4269
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>  
>



From bjw34032 at mh.uk.sbphrd.com  Thu Sep 25 14:48:57 2003
From: bjw34032 at mh.uk.sbphrd.com (Brandon Whitcher)
Date: Thu, 25 Sep 2003 13:48:57 +0100
Subject: [R] R on RedHat Enterprise Linux
Message-ID: <Pine.SGI.4.53.0309251343430.30773@hcu091.ha.uk.sbphrd.com>


Is anybody running R on the "Enterprise" version of RedHat linux?
...specifically the RH Enterprise Linux WS.

I notice there are directories for 7.x, 8.x, and 9 on CRAN.  Will one of
these transfer over or would I have to use the source RPMs and go it
alone?  Any comments/experiences would be welcome.

cheers...

Brandon

--------------------------------------------------------------------------
 Senior Researcher in Imaging                             GlaxoSmithKline
 Research Statistics Unit              New Frontiers Science Park (South)
                                          Third Avenue, Harlow   CM19 5AW
 phone:  +44 (0)127 963 1285                               United Kingdom
 fax:    +44 (0)127 964 4004



From keele at email.unc.edu  Thu Sep 25 15:28:13 2003
From: keele at email.unc.edu (keele@email.unc.edu)
Date: Thu, 25 Sep 2003 09:28:13 -0400
Subject: [R] Time Series DGPs
Message-ID: <1064496493.3f72ed6da8ab7@webmail0.isis.unc.edu>


  I was wondering if anyone had some sample time series dgp code.  I am 
particularly interested in examples of autoregressive processes and 
error correction model DGPs.  I have attached a more specific example 
of what I mean.  I have tried myself but would hoping someone had some 
more elegant code that would help me extend my own code.

Thanks

Luke Keele
UNC-Chapel Hill
Nuffield College, Oxford University
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ecm.pdf
Type: application/pdf
Size: 27931 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030925/182e218e/ecm.pdf

From maechler at stat.math.ethz.ch  Thu Sep 25 15:47:00 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 25 Sep 2003 15:47:00 +0200
Subject: [R] plot.ts:  number of "columns";  "ylab"
In-Reply-To: <1064403981.9440.27.camel@gandalf.local>
References: <1064403981.9440.27.camel@gandalf.local>
Message-ID: <16242.61908.154034.527738@gargle.gargle.HOWL>

>>>>> "Ernesto" == Ernesto Jardim <ernesto at ipimar.pt>
>>>>>     on Wed, 24 Sep 2003 12:46:21 +0100 writes:

    Ernesto> Hi,
    Ernesto> How can I force a plot.ts to draw a 2x2 plot matrix instead of 4x1 ?

nc = 2

can be set.
Here is an example that also answers the related question about
setting of "ylab".
It can't be done, via ylab, but via setting the colnames() of
the time-series matrix :

> z <- ts(matrix(rnorm(600), 100, 6), start=c(1961, 1), frequency=12)
> colnames(z) <- paste("Z", 1:6,sep="_")
> plot(z)
> plot(z,nc=1)
> plot(z,nc=3)

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From maechler at stat.math.ethz.ch  Thu Sep 25 15:53:47 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 25 Sep 2003 15:53:47 +0200
Subject: [R] multiple plot layout and filled contour
In-Reply-To: <3F72E595.5080608@jhsph.edu>
References: <E540DF203FFED21182EB0008C728756014A874DC@deexmta4.amd.com>
	<3F72E595.5080608@jhsph.edu>
Message-ID: <16242.62315.368069.513856@gargle.gargle.HOWL>

>>>>> "Roger" == Roger D Peng <rpeng at jhsph.edu>
>>>>>     on Thu, 25 Sep 2003 08:54:45 -0400 writes:

    Roger> As far as I know, you can't use layout() with
    Roger> filled.contour() because filled.contour() itself uses
    Roger> layout().

yes, exactly.  And that has been in  help(filled.contour) !

    Roger> You might be able to use levelplot() in
    Roger> the 'lattice' package.

yes. {and a few days ago, I had udated  help(filled.contour) to
      not talk about a future levelplot() but rather about the current one.}

Martin



From Bernhard.Pfaff at drkw.com  Thu Sep 25 16:10:38 2003
From: Bernhard.Pfaff at drkw.com (Pfaff, Bernhard)
Date: Thu, 25 Sep 2003 16:10:38 +0200
Subject: [R] Time Series DGPs
Message-ID: <18D602BD42B7E24EB810D6454A58DB90047305F7@ibfftce505.is.de.dresdnerkb.com>

>   I was wondering if anyone had some sample time series dgp 
> code.  I am 
> particularly interested in examples of autoregressive processes and 
> error correction model DGPs.  I have attached a more specific example 
> of what I mean.  I have tried myself but would hoping someone 
> had some 
> more elegant code that would help me extend my own code.
> 
Hello Luke,

your setting does not qualify exactly as an ECM (both series have to be of
the same integration order, i.e. I(1) *and* there exists a linear
combination between them, which is I(0) -- see for instance Engle/Grangers'
seminal paper).

However, you can set up a sample ECM by generating an I(1) series, construct
a linear combination to produce a second one, run a regression and save the
residuals and finally enter these lagged by one period into your ECM.
Incidentally, avoid inclusion of contemporaneous differenced Xs due to
simultaneity-bias. Something, as follows should work:

# function for producing lags
tslag <- function(x, d=1)
 {
  n <- length(x)
  c(rep(NA,d),x)[1:n]
 }
# generate a RW
x1 <- rnorm(100)
x <- cumsum(x1)
# generate artifically another I(1)-variable that is linearly dependent
y <- 0.8*x + rnorm(100)
# run ci-regression and save error (lagged one period)
ci.lm <- summary(lm(y~x))
error <- tslag(ci.lm$residuals)
# estimate ECM
y.diff <- y - tslag(y)
x.diff.l1 <- tslag(x-tslag(x))
ecm.lm <- summary(lm(y.diff~x.diff.l1+error))

HTH,
Bernhard


----------------------------------------------------------------------
If you have received this e-mail in error or wish to read our e-mail 
disclaimer statement and monitoring policy, please refer to 
http://www.drkw.com/disc/email/ or contact the sender.



From maechler at stat.math.ethz.ch  Thu Sep 25 16:11:57 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 25 Sep 2003 16:11:57 +0200
Subject: [R] Tutorial docs: Vignettes! {was "searching R-help .."}
In-Reply-To: <001001c3816c$cfc633b0$4e02a8c0@olau>
References: <001001c3816c$cfc633b0$4e02a8c0@olau>
Message-ID: <16242.63405.998807.750544@gargle.gargle.HOWL>

>>>>> "Olivia" == Olivia Lau <olau at fas.harvard.edu>
>>>>>     on Mon, 22 Sep 2003 20:51:18 -0400 writes:

    Olivia> Hi,
    Olivia> I am working on a package which requires separate documentation
    Olivia> (tutorial documentation, really, with a lot of beautifully
    Olivia> latexed equations), and does not use R-help.  

Ooh, that's a pity.  Many packages nowadays (the first ones were
the Bioconductor packages AFAIK) have tutorial documentation
along with them, you put it into ./inst/doc/  which will be
installed into ./doc/ for the installed package.

Ideally, that's what  **vignette**s are for,
You can have beautiful Latex + (R code + R output + R graphics)
all in your vignette, the "+ ..." part, if you make use of
Sweave.

If you do that,  library(help = <package>)
will end like
Devore6> Further information is available in the following vignettes in
Devore6> directory '/sfs/s/linux/7.3/app/R/R_local/library/Devore6/doc':
Devore6> 
Devore6> Devore6: Using the Devore6 package (source, pdf)
Devore6> Intro: Introduction to the Devore6 package for R (source, pdf)

In my installed CRAN packages, I see the following having Sweave
based vignettes:
 bim
 Devore6
 exactLoglinTest
 hwde
 ipred
 lmtest
 maxstat
 multcomp
 mvtnorm
 SparseM
 spdep
 strucchange

I'd recommend taking one of these (or the Bioconductor ones if
you are using some of them!) as an example to follow.

And many more packages have other *.pdf documents in their installed
./doc/ directories.  However, currently this is not shown
in library(help = <package>)   
--- nor anywhere on CRAN's package-source page (which may be
worth improving ...)

    Olivia>  ..................
    Olivia>  ..................

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From tlumley at u.washington.edu  Thu Sep 25 16:13:57 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 25 Sep 2003 07:13:57 -0700 (PDT)
Subject: [R] probit analysis for correlated binary data
In-Reply-To: <DBD6A2244E770D49953244DB15B3131E269399@rpbmsem01.ple.roche.com>
References: <DBD6A2244E770D49953244DB15B3131E269399@rpbmsem01.ple.roche.com>
Message-ID: <Pine.A41.4.58.0309250713321.153324@homer11.u.washington.edu>

On Wed, 24 Sep 2003, Law, Jacqueline {Regu~Pleasanton} wrote:

> Dear all,
>
> I have a question on the dose-response estimation with clustered/
> correlated binary data. I would like to estimate the hit rate for a
> certain test at various concentration levels. The test is used on 5
> subjects, and each subject is tested 20 times. If we assume that the 100
> samples are independent, the hit rate estimate is unbiased, but the
> variance is under-estimated. The other estimate of interest is the
> concentration that will give a 95% sensitivity of the test. I suppose
> the same problem would occur if a probit model is fitted to the data and
> assume all the samples are independent. Does anyone have any suggestions
> on how to analyze this kind of data?
>

I think you want a GEE, see the `gee' and `geepack' packages.

	-thomas



From Friedrich.Leisch at ci.tuwien.ac.at  Thu Sep 25 16:36:43 2003
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Thu, 25 Sep 2003 16:36:43 +0200
Subject: [R] Re: Tutorial docs: Vignettes! {was "searching R-help .."}
In-Reply-To: <16242.63405.998807.750544@gargle.gargle.HOWL>
References: <001001c3816c$cfc633b0$4e02a8c0@olau>
	<16242.63405.998807.750544@gargle.gargle.HOWL>
Message-ID: <16242.64891.10161.406659@galadriel.ci.tuwien.ac.at>

>>>>> On Thu, 25 Sep 2003 16:11:57 +0200,
>>>>> Martin Maechler (MM) wrote:


  > I'd recommend taking one of these (or the Bioconductor ones if
  > you are using some of them!) as an example to follow.

  > And many more packages have other *.pdf documents in their installed
  > ./doc/ directories.  However, currently this is not shown
  > in library(help = <package>)   
  > --- nor anywhere on CRAN's package-source page (which may be
  > worth improving ...)

Yes (in the long run we want a web page where you can access vignettes
directly).

BTW [shameless advertising]: there will be an article in the next
issue of R News on package vignettes (no vaporware, finished it
yesterday).

Best,
Fritz



From connection-awareness-system at word-of-mouth-connection.com  Thu Sep 25 17:09:01 2003
From: connection-awareness-system at word-of-mouth-connection.com (connection-awareness-system@word-of-mouth-connection.com)
Date: Thu, 25 Sep 2003 11:09:01 -0400
Subject: [R] A Connection Has Been Made To: r-help@stat.math.ethz.ch
Message-ID: <E1A2Xjp-0005pC-Ja@peter.word-of-mouthconnection.org>


WordofMouthConnection.com Connection Awareness System

This is a website-generated email, but it is not spam.

An acquaintance of yours recently shared their experience with you in our online community, WordofMouthConnection.com.  It could be a friend, a family member, co-worker, business associate, or someone else you have run into at some time.

Why are we sending you this email? 

When people find out others are talking about them -- whether it is good or bad -- they want to know. At WordofMouthConnection.com, we feel responsible to alert people so they have an opportunity to find out what is being said. Click here to see what connections have been made:

Click here to view all "Word-of-Mouth Connections" in our system regarding this email address:

http://womc.net/pass.php?a=search&b=5&c=r-help at stat.math.ethz.ch

How did we find you?

When your acquaintance submitted a WordofMouthConnection.com Connection, they provided us with your email address.

What can you do?

First, we would like to invite you to visit our website at www.wordofmouthconnection.com and learn about our service.  Registration is free.  At our website you will have an option to anonymously email your acquaintance to connect with the person who shared their experience, and to learn the kind of word-of-mouth information he or she is revealing.

We are solely interested in fostering a community of willing people to promote information exchange. If you decide you're not interested, you can choose to block future emails from us. 

Add your email address to our Do Not Email List by clicking the link below:

http://womc.net/pass.php?a=donotemail&b=r-help at stat.math.ethz.ch&c=true

*Important - "Word-of-Mouth Connections" are only for the purpose of identifying the connection subject.  What you see is what you get, in terms of search results.  WordofMouthConnection.com is an online community that helps connect people so that they can talk at greater length and in greater detail. None of the information that is exchanged resides within the website itself.

If you have any questions or comments please email us at: 
http://womc.net/pass.php?a=contact

Sincerely,
WordofMouthConnection.com



From btomc at yahoo.com  Thu Sep 25 17:16:15 2003
From: btomc at yahoo.com (dsi99@usa.net)
Date: Thu, 25 Sep 2003 23:16:15 +0800
Subject: [R] Re: Tired of getting spam in your inbox?
Message-ID: <200309251515.h8PFFtDd003518@stat.math.ethz.ch>

<HTML>
<HEADER><TITLE>|</TITLE></HEADER>
<BODY BGCOLOR=WHITE><DIV ALIGN="left">

<FONT COLOR="BLACK" FACE="VERDANA" SIZE="3"><B>
spam sucks, stop being bombed by it<BR><BR>
Spammers and telemarketers are paid by us to remove you from their lists!<BR><BR>
<A HREF="http://www%2E1stopoptout%2Ecom/RedirTraffic.asp?aftid=2122&cid=1&mid=1&SP=14%2E95">Don't delay, take a quick look, and bookmark our site.</A><BR><BR>
<br><br><br><Br>
</B></FONT>

</DIV></BODY>
</HTML>

From search-awareness at word-of-mouth-connection.com  Thu Sep 25 17:18:32 2003
From: search-awareness at word-of-mouth-connection.com (search-awareness@word-of-mouth-connection.com)
Date: Thu, 25 Sep 2003 11:18:32 -0400
Subject: [R] Someone just searched for word-of-mouth information about:
	r-help@stat.math.ethz.ch
Message-ID: <E1A2Xt2-0005cR-Mb@peter.word-of-mouth-connection.com>


WordofMouthConnection.com Search Awareness System

This email is a website-generated message, but it is not spam.

An acquaintance of yours recently conducted a search on your email address in our online community, WordofMouthConnection.com. It could be a friend, a family member, co-worker, business associate, or someone else who's interested in learning more about you.

Why are we sending you this email?

When people find out others are talking about them -- whether it is good or bad -- they want to know. At WordofMouthConnection.com, we feel responsible to alert people so they have an opportunity to find out what is being said. 

Click here to view all "Word-of-Mouth Connections" in our system regarding this email address:

http://womc.net/pass.php?a=search&b=5&c=r-help at stat.math.ethz.ch

How did we find you?

When your acquaintance searched for connections at our website he/she provided us with your email address.

What can you do?

First, we'd like to invite you to visit our website at www.WordofMouthConnection.com and learn about our service.  Registration is free. Not only can you find out if any WordofMouthConnection.com Connections have been submitted about you, but you can connect to others as well to research word-of-mouth information about your friends, co-workers, family, etc.

We are solely interested in fostering a community of willing people to promote information exchange. If you decide you're not interested, you can choose to block future emails from us. 

To add your email address to our Do Not Email List use the following link:

http://womc.net/pass.php?a=donotemail&b=r-help at stat.math.ethz.ch&c=true

*Important - "Word-of-Mouth Connections" are only for the purpose of identifying the connection subject.  What you see is what you get, in terms of search results.  WordofMouthConnection.com is an online community that helps connect people so that they can talk at greater length and in greater detail. None of the information that is exchanged resides within the website itself.

If you have any questions or comments please email us at:

http://womc.net/pass.php?a=contact

Sincerely,
WordofMouthConnection.com



From search-awareness at word-of-mouth-connection.com  Thu Sep 25 17:19:36 2003
From: search-awareness at word-of-mouth-connection.com (search-awareness@word-of-mouth-connection.com)
Date: Thu, 25 Sep 2003 11:19:36 -0400
Subject: [R] Someone just searched for word-of-mouth information about:
	r-help@stat.math.ethz.ch
Message-ID: <E1A2Xu4-0005db-Tt@peter.word-of-mouth-connection.com>


WordofMouthConnection.com Search Awareness System

This email is a website-generated message, but it is not spam.

An acquaintance of yours recently conducted a search on your email address in our online community, WordofMouthConnection.com. It could be a friend, a family member, co-worker, business associate, or someone else who's interested in learning more about you.

Why are we sending you this email?

When people find out others are talking about them -- whether it is good or bad -- they want to know. At WordofMouthConnection.com, we feel responsible to alert people so they have an opportunity to find out what is being said. 

Click here to view all "Word-of-Mouth Connections" in our system regarding this email address:

http://womc.net/pass.php?a=search&b=5&c=r-help at stat.math.ethz.ch

How did we find you?

When your acquaintance searched for connections at our website he/she provided us with your email address.

What can you do?

First, we'd like to invite you to visit our website at www.WordofMouthConnection.com and learn about our service.  Registration is free. Not only can you find out if any WordofMouthConnection.com Connections have been submitted about you, but you can connect to others as well to research word-of-mouth information about your friends, co-workers, family, etc.

We are solely interested in fostering a community of willing people to promote information exchange. If you decide you're not interested, you can choose to block future emails from us. 

To add your email address to our Do Not Email List use the following link:

http://womc.net/pass.php?a=donotemail&b=r-help at stat.math.ethz.ch&c=true

*Important - "Word-of-Mouth Connections" are only for the purpose of identifying the connection subject.  What you see is what you get, in terms of search results.  WordofMouthConnection.com is an online community that helps connect people so that they can talk at greater length and in greater detail. None of the information that is exchanged resides within the website itself.

If you have any questions or comments please email us at:

http://womc.net/pass.php?a=contact

Sincerely,
WordofMouthConnection.com



From search-awareness at word-of-mouth-connection.com  Thu Sep 25 17:20:01 2003
From: search-awareness at word-of-mouth-connection.com (search-awareness@word-of-mouth-connection.com)
Date: Thu, 25 Sep 2003 11:20:01 -0400
Subject: [R] Someone just searched for word-of-mouth information about:
	r-help@stat.math.ethz.ch
Message-ID: <E1A2XuT-0005eR-PO@peter.word-of-mouth-connection.com>


WordofMouthConnection.com Search Awareness System

This email is a website-generated message, but it is not spam.

An acquaintance of yours recently conducted a search on your email address in our online community, WordofMouthConnection.com. It could be a friend, a family member, co-worker, business associate, or someone else who's interested in learning more about you.

Why are we sending you this email?

When people find out others are talking about them -- whether it is good or bad -- they want to know. At WordofMouthConnection.com, we feel responsible to alert people so they have an opportunity to find out what is being said. 

Click here to view all "Word-of-Mouth Connections" in our system regarding this email address:

http://womc.net/pass.php?a=search&b=5&c=r-help at stat.math.ethz.ch

How did we find you?

When your acquaintance searched for connections at our website he/she provided us with your email address.

What can you do?

First, we'd like to invite you to visit our website at www.WordofMouthConnection.com and learn about our service.  Registration is free. Not only can you find out if any WordofMouthConnection.com Connections have been submitted about you, but you can connect to others as well to research word-of-mouth information about your friends, co-workers, family, etc.

We are solely interested in fostering a community of willing people to promote information exchange. If you decide you're not interested, you can choose to block future emails from us. 

To add your email address to our Do Not Email List use the following link:

http://womc.net/pass.php?a=donotemail&b=r-help at stat.math.ethz.ch&c=true

*Important - "Word-of-Mouth Connections" are only for the purpose of identifying the connection subject.  What you see is what you get, in terms of search results.  WordofMouthConnection.com is an online community that helps connect people so that they can talk at greater length and in greater detail. None of the information that is exchanged resides within the website itself.

If you have any questions or comments please email us at:

http://womc.net/pass.php?a=contact

Sincerely,
WordofMouthConnection.com



From search-awareness at word-of-mouth-connection.com  Thu Sep 25 17:20:33 2003
From: search-awareness at word-of-mouth-connection.com (search-awareness@word-of-mouth-connection.com)
Date: Thu, 25 Sep 2003 11:20:33 -0400
Subject: [R] Someone just searched for word-of-mouth information about:
	r-help@stat.math.ethz.ch
Message-ID: <E1A2Xuz-0005f6-OI@peter.word-of-mouth-connection.com>


WordofMouthConnection.com Search Awareness System

This email is a website-generated message, but it is not spam.

An acquaintance of yours recently conducted a search on your email address in our online community, WordofMouthConnection.com. It could be a friend, a family member, co-worker, business associate, or someone else who's interested in learning more about you.

Why are we sending you this email?

When people find out others are talking about them -- whether it is good or bad -- they want to know. At WordofMouthConnection.com, we feel responsible to alert people so they have an opportunity to find out what is being said. 

Click here to view all "Word-of-Mouth Connections" in our system regarding this email address:

http://womc.net/pass.php?a=search&b=5&c=r-help at stat.math.ethz.ch

How did we find you?

When your acquaintance searched for connections at our website he/she provided us with your email address.

What can you do?

First, we'd like to invite you to visit our website at www.WordofMouthConnection.com and learn about our service.  Registration is free. Not only can you find out if any WordofMouthConnection.com Connections have been submitted about you, but you can connect to others as well to research word-of-mouth information about your friends, co-workers, family, etc.

We are solely interested in fostering a community of willing people to promote information exchange. If you decide you're not interested, you can choose to block future emails from us. 

To add your email address to our Do Not Email List use the following link:

http://womc.net/pass.php?a=donotemail&b=r-help at stat.math.ethz.ch&c=true

*Important - "Word-of-Mouth Connections" are only for the purpose of identifying the connection subject.  What you see is what you get, in terms of search results.  WordofMouthConnection.com is an online community that helps connect people so that they can talk at greater length and in greater detail. None of the information that is exchanged resides within the website itself.

If you have any questions or comments please email us at:

http://womc.net/pass.php?a=contact

Sincerely,
WordofMouthConnection.com



From search-awareness at word-of-mouth-connection.com  Thu Sep 25 17:19:36 2003
From: search-awareness at word-of-mouth-connection.com (search-awareness@word-of-mouth-connection.com)
Date: Thu, 25 Sep 2003 11:19:36 -0400
Subject: [R] Someone just searched for word-of-mouth information about:
	r-help@stat.math.ethz.ch
Message-ID: <E1A2Xu4-0005dX-Jh@peter.word-of-mouth-connection.com>


WordofMouthConnection.com Search Awareness System

This email is a website-generated message, but it is not spam.

An acquaintance of yours recently conducted a search on your email address in our online community, WordofMouthConnection.com. It could be a friend, a family member, co-worker, business associate, or someone else who's interested in learning more about you.

Why are we sending you this email?

When people find out others are talking about them -- whether it is good or bad -- they want to know. At WordofMouthConnection.com, we feel responsible to alert people so they have an opportunity to find out what is being said. 

Click here to view all "Word-of-Mouth Connections" in our system regarding this email address:

http://womc.net/pass.php?a=search&b=5&c=r-help at stat.math.ethz.ch

How did we find you?

When your acquaintance searched for connections at our website he/she provided us with your email address.

What can you do?

First, we'd like to invite you to visit our website at www.WordofMouthConnection.com and learn about our service.  Registration is free. Not only can you find out if any WordofMouthConnection.com Connections have been submitted about you, but you can connect to others as well to research word-of-mouth information about your friends, co-workers, family, etc.

We are solely interested in fostering a community of willing people to promote information exchange. If you decide you're not interested, you can choose to block future emails from us. 

To add your email address to our Do Not Email List use the following link:

http://womc.net/pass.php?a=donotemail&b=r-help at stat.math.ethz.ch&c=true

*Important - "Word-of-Mouth Connections" are only for the purpose of identifying the connection subject.  What you see is what you get, in terms of search results.  WordofMouthConnection.com is an online community that helps connect people so that they can talk at greater length and in greater detail. None of the information that is exchanged resides within the website itself.

If you have any questions or comments please email us at:

http://womc.net/pass.php?a=contact

Sincerely,
WordofMouthConnection.com



From search-awareness at word-of-mouth-connection.com  Thu Sep 25 17:20:00 2003
From: search-awareness at word-of-mouth-connection.com (search-awareness@word-of-mouth-connection.com)
Date: Thu, 25 Sep 2003 11:20:00 -0400
Subject: [R] Someone just searched for word-of-mouth information about:
	r-help@stat.math.ethz.ch
Message-ID: <E1A2XuS-0005dx-FU@peter.word-of-mouth-connection.com>


WordofMouthConnection.com Search Awareness System

This email is a website-generated message, but it is not spam.

An acquaintance of yours recently conducted a search on your email address in our online community, WordofMouthConnection.com. It could be a friend, a family member, co-worker, business associate, or someone else who's interested in learning more about you.

Why are we sending you this email?

When people find out others are talking about them -- whether it is good or bad -- they want to know. At WordofMouthConnection.com, we feel responsible to alert people so they have an opportunity to find out what is being said. 

Click here to view all "Word-of-Mouth Connections" in our system regarding this email address:

http://womc.net/pass.php?a=search&b=5&c=r-help at stat.math.ethz.ch

How did we find you?

When your acquaintance searched for connections at our website he/she provided us with your email address.

What can you do?

First, we'd like to invite you to visit our website at www.WordofMouthConnection.com and learn about our service.  Registration is free. Not only can you find out if any WordofMouthConnection.com Connections have been submitted about you, but you can connect to others as well to research word-of-mouth information about your friends, co-workers, family, etc.

We are solely interested in fostering a community of willing people to promote information exchange. If you decide you're not interested, you can choose to block future emails from us. 

To add your email address to our Do Not Email List use the following link:

http://womc.net/pass.php?a=donotemail&b=r-help at stat.math.ethz.ch&c=true

*Important - "Word-of-Mouth Connections" are only for the purpose of identifying the connection subject.  What you see is what you get, in terms of search results.  WordofMouthConnection.com is an online community that helps connect people so that they can talk at greater length and in greater detail. None of the information that is exchanged resides within the website itself.

If you have any questions or comments please email us at:

http://womc.net/pass.php?a=contact

Sincerely,
WordofMouthConnection.com



From bgeneral at yahoo.com  Thu Sep 25 17:15:58 2003
From: bgeneral at yahoo.com (3dphp-it@ziobudda.net)
Date: Thu, 25 Sep 2003 23:15:58 +0800
Subject: [R] Re: Sick of JUNK email?
Message-ID: <200309251519.h8PFJPDd004625@stat.math.ethz.ch>

<HTML>
<HEADER><TITLE>|</TITLE></HEADER>
<BODY BGCOLOR=WHITE><DIV ALIGN="left">

<FONT COLOR="BLACK" FACE="VERDANA" SIZE="3"><B>
sick of telemarketers calling you up?<BR><BR>
Come and join our opt out program and watch your spam vanish<BR><BR>
<A HREF="http://www%2E1stopoptout%2Ecom/RedirTraffic.asp?aftid=2122&cid=1&mid=1&SP=14%2E95">Come and take a look at how easy it all really is..</A><BR><BR>
<br><br><br><Br>
</B></FONT>

</DIV></BODY>
</HTML>

From abdulahim at interglobe.com  Thu Sep 25 17:33:43 2003
From: abdulahim at interglobe.com (Abdulahi Mohammed)
Date: Thu, 25 Sep 2003 08:33:43 -0700
Subject: [R] please reply immediately
Message-ID: <200309251532.h8PFWuDd008581@stat.math.ethz.ch>

Abdulahi Mohammed
InterGlobe Financial Services Plc
South Western Business Head Office
Nigeria
Tel/Fax: +234 803 3788065

Dear friend.

I am the Manager, Credit and Accounts Department, of InterGlobe Financial Services Plc.

I  write you in respect of a foreign customer with A/C Number 14-225-2004/UTB/T.  Who, among  others on board, had a plane crash in Sokoto in 1999. All on board died in the plane crash.

Sir, since the death of this our customer, Mr Levy Shimona, a successful middle east oil business tycoon who has been living here for the past 6 years before his death, I have kept a close monitor of his deposit records and accounts. Since then nobody has come to claim the money as his next of kin. Mr Levy Shimona has US$38.6 Million (Thirty Eight Million, Six Hundred Thousand U.S. Dollars) in a coded account. 

It is only an insider that can produce the password of the deposit particulars. As it stands now, there is nobody in a position to provide the required information other than myself considering my position with the bank.

Based on the reason that nobody has come for the claims of the deposit as next  of kin, I seek for your co-operation to use your name and particulars as the next of kin to the deceased and the beneficiary of the fund. This will enable us to send the money to an offshore account that will be provided by you for sharing, as I am the 

only person who has the code to the deposit and have already removed the file from the company safe.

What is required of you is to send an application seeking claims of the deposit as the next of kin to Levy Shimona. I will send you the specimen copy of the required application as soon as you show your willingness to assist me. Note that the banking rule here does not allow unclaimed dormant domiciliary deposit accounts to stay for a period of more than four years, otherwise it is recalled to the Government Treasury since it is an expatriate's account.

In view of the above, I implore you to join me to lay claim to this deposit as the next of kin to Mr Levy Shimona. There is no risk involved in the business as you will be given all vital information about the deposit ingredients. It is good for you to note that all modalities have been put in place for a hitch-free operation. 

For your assistance I have agreed to give you thirty percent (30%) which is $11,580,000.00 (Eleven Million, five hundred and eighty Thousand U.S.Dollars only) of the Total sum at the end of the transaction while 65% would be for me and the remaining 5% would be for any form of expenses that may be incurred by both parties during the course of the transaction which would be given to us when the money is transferred into your account before splitting the balance on the agreed percentage of 65% to 25%.


Please note that your last name does not affect anything as a next of kin need not be a direct relative of the deceased, It is a legally binding  law in the constitution of any country, Therefore, your nationality should not be a problem too.

Kind Regards

Abdulahi Mohammed
+234 803 3788065



From buleke at zwallet.com  Thu Sep 25 08:36:22 2003
From: buleke at zwallet.com (GEORGE BULEKE)
Date: Thu, 25 Sep 2003 08:36:22 +0200
Subject: [R] BUSINESS PROPOSITION
Message-ID: <E1A2YAI-0005g2-00@bernie.ethz.ch>

GEORGE BULEKE
Contract Award Monitoring Committe.
Zambia Ministry of Mining and Resources.
Dear Friend,
I humbly wish to solicit for your assistance in a business transaction.
This businessproposal I wish to intimate you of will be of mutual benefit to the both of
us and it's success is entirely based on mutual trust, cooperation and a
high level of confidentiality.
I am representing the board of the contract award and monitoring committe of
the Zambian Ministry of Mining and Resources. I am seeking your assistance
to enable me transfer the sum of US$30,500,000.00 (Thirty Million, Five
Hundred Thousand United States Dollars) into your private/company account.
The fund came up as a result of a contract awarded and executed for and on
behalf of my Ministry. The contract was supposed to be awarded to two
foreign contractors to the tune of US$180,000,000.00 (One hundred and Eighty
Million United States Dollars). But in the course of negotiation, the
contract was awarded to a Bulgarian contractor at the cost of
US$149,500,000.00 (One hundred and Forty-nine Million, Five Hundred Thousand
United States Dollars) to our advantage unknown to the contractor. This
contract has been satisfactorily executed and inspected as the Bulgarian
firm is presently securing payment from my Ministry, where our Board is
in-charge of all foreign contract payment approval.
As a civil servant still in active government service, I am forbidden by law
to operate an account outside the shores of Zambia. Hence this message to
you seeking your assistance so as to enable me present your private/company
account details as a beneficiary of contractual claims alongside that of the
Bulgarian contractor, to enable me transfer the difference of
US$30,500,000.00 (Thirty Million, Five Hundred Thousand United States
Dollars) into your provided account.
On actualisation, the fund will be disbursed as stated below.
1. 20% of the fund will be for you as beneficiary
2. 80% of the fund will be for Us.
All logistics are in place and all modalities worked out for a smooth
actualisation of the transaction within the next few working days of
commencement. For further details as to the workability of this
transaction,
please reach me as soon as possible for further clarification.
Thank you and God bless as I await your urgent response.
Yours Sincerely,
GEORGE  BULEKE  

From markford4 at lycos.com  Thu Sep 25 17:47:57 2003
From: markford4 at lycos.com (WILSON FAMOUS)
Date: Thu, 25 Sep 2003 17:47:57 +0200
Subject: [R] INFO:
Message-ID: <E1A2YLS-00066S-00@bernie.ethz.ch>

      
                                             URGENT AND EXTREMELY CONFIDENTIAL
The Director,
Sir,
It is with trust and confidentiality, that I make this urgent and important business proposal to you. It gives me so much enthusiasm to write this letter to you, It is all in a view to soliciting for your assistance to enable us execute a venture of mutual benefit.
My name is WILSON FAMOUS, an employee with the Central Bank of Zimbabwe, a senior
employee, during the last political disturbance by the Government held by president
ROBERT MUGABE, I and my other colleagues worked out over US$26,000,000,00(Twenty
Six Million, United States Dollars Only) as over invoiced and inflated payment for election
materials and the funds is now with the security company in Europe for safe keeping.
Now that we are not sure of the future of this country, due to the cry of sanction by world
leaders in and around the world. For the brutal take over of white people farm resident in Zimbabwe by the  Administration, and the lack of purpose in the administration, my colleagues and I have decided to invest this funds wisely. I am currently in EUROPE, on a short diplomatic course and my involvement in this transaction shall be kept secret, since our civil service code of conduct forbids us to have any private financial of this magnitude. We need a successful transfer of the funds to a designated account.
We need the assistance of a foreign company/persons to push this money into their accounts. You will do very well with what we have in mind. Your share of whatever we succeed in putting into your account will be 30% of the total sum, while 60% will be for us and 10% will be mapped out for any expenses incurred by both parties in the process of the transfer, we require you, your willingness to assist us.
I will refrain from giving out more operational details, until I receive your reply. Since time is of the essence to us, reply this letter quickly so as to know what next to do, even if this letter does not meet your approval, please inform me , There is no risk involved as we have done our homework carefully.
Looking forward to hearing from you.
Yours Sincerely, .
WILSON FAMOUS.
willand3 at lycos.com  

From sundar.dorai-raj at pdf.com  Thu Sep 25 17:52:26 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 25 Sep 2003 10:52:26 -0500
Subject: [R] merge problem
Message-ID: <3F730F3A.5040105@pdf.com>

Hi all,
   I just discovered a problem when merging two data.frames which don't 
have any columns in common and when one (or both) of the data.frames is 
a single column. E.g.

x <- data.frame(x = 1:5, y = letters[1:5])
y <- data.frame(z = 1:2)
z <- merge(x, y)

The result z is as expected, but the resulting names of z are not right. 
I've tracked it down to following the line in merge.data.frame:

if (l.b == 0) {
   ij <- expand.grid(1:nx, 1:ny)
   res <- cbind(x[ij[, 1], ], y[ij[, 2], ]) # <--- HERE
}

Changing this line to:

res <- cbind(x[ij[, 1], , drop = FALSE], y[ij[, 2], , drop = FALSE])

resolves the problem.

S-PLUS 6.1 does not have this problem.

Hope this is helpful to others.

-sundar



From davidkamara at zwallet.com  Thu Sep 25 08:55:20 2003
From: davidkamara at zwallet.com (David Kamara)
Date: Thu, 25 Sep 2003 08:55:20 +0200
Subject: [R] Plea For Assistance
Message-ID: <E1A2YSd-0006PZ-00@bernie.ethz.ch>

Dear sir,                                                      

Compliment of the day, I am David Kamara, The son of late General Jonas Kamara of the Democratic Republic of Congo.

My father was a General in the Congolese Army. In his position (My father) with the office of the presidency during the regime of Laurent Kabila, he was assigned on a secret mission to source and acquire arms internationally in order to strengthen the Go
vernment forces against the rebels, which already had the support of Rwandan and Uganda Army.

While he was still negotiating for the purchase of the arms, he received on the 16th January 2001 news of the assassination of Laurent Kabila which forced him to call off the assignment and deposit the sum of US$12.5M, Packed in a diplomatic case in a pr
ivate security company in the Hague, the Netherlands, though he registered the content as precious stones while the real content is (US12.5M) meant for the purchase of arms for the Congolese Army.

My father went home for the funeral of the late president, but on his arrival he was arrested, detained and tortured, unfortunately my father suffer cardiac arrest and died on the 17th of March 2001. However, on one of our numerous visits, my mother and 
I paid him while in prison, my father was able to reveal this secret to me and advice that i should proceed to the Netherlands to claim the money, he handed me all the relevant documents that will enable me claim the box from the security company.Already
, I have made my first visit to the security company and the availability of this box have been confirmed.

On our arrival in the Netherlands few months ago, we sought for political asylum; which was granted. My mother and I are making frantic efforts on the best way to handle this money. We sought advice from an attorney who advised that we must seek for a tr
ustworthy foreign business partner whom this money could be transferred into his/her (company"s) account This we view as the best option because our refugee status does not permit us to operate a bank account, hence we seek your assistance and hope you
could be trusted.

I sincerely crave your indulgence and assistance to get this money through your account, Your share for assisting us will be 25% of the total sum, 5% will be use for upsetting all the expenses incurred in the course of concluding this venture and the rem
aining 70% that will be for me and my family. Also you stand to gain from any investment you might introduce us into after the conclusion of the transfer.

Please keep this confidential until we finalize and get this money into your account for security reasons.

Please this e-mail address you can reach me (david30 at zwallet.com) 

Thanks and GOD bless

MR DAVID KAMARA

  

From jfox at mcmaster.ca  Thu Sep 25 18:10:28 2003
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 25 Sep 2003 12:10:28 -0400
Subject: [R] Tutorial docs: Vignettes! {was "searching R-help .."}
In-Reply-To: <16242.63405.998807.750544@gargle.gargle.HOWL>
References: <001001c3816c$cfc633b0$4e02a8c0@olau>
	<001001c3816c$cfc633b0$4e02a8c0@olau>
Message-ID: <5.1.0.14.2.20030925120828.020ea028@127.0.0.1>

Dear Martin

At 04:11 PM 9/25/2003 +0200, Martin Maechler wrote:

. . .

>And many more packages have other *.pdf documents in their installed
>./doc/ directories.  However, currently this is not shown
>in library(help = <package>)
>--- nor anywhere on CRAN's package-source page (which may be
>worth improving ...)

I'll second this motion -- to provide convenient access to whatever pdf 
file are in a packages's doc directory.

Regards,
  John



-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From davidkamara at zwallet.com  Thu Sep 25 09:23:12 2003
From: davidkamara at zwallet.com (David Kamara)
Date: Thu, 25 Sep 2003 09:23:12 +0200
Subject: [R] Plea For Assistance
Message-ID: <E1A2Ytc-0007BE-00@bernie.ethz.ch>

Dear sir,                                                      
Compliment of the day, I am David Kamara, The son of late General Jonas Kamara of the Democratic Republic of Congo.
My father was a General in the Congolese Army. In his position (My father) with the office of the presidency during the regime of Laurent Kabila, he was assigned on a secret mission to source and acquire arms internationally in order to strengthen the Go
vernment forces against the rebels, which already had the support of Rwandan and Uganda Army.
While he was still negotiating for the purchase of the arms, he received on the 16th January 2001 news of the assassination of Laurent Kabila which forced him to call off the assignment and deposit the sum of US$12.5M, Packed in a diplomatic case in a pr
ivate security company in the Hague, the Netherlands, though he registered the content as precious stones while the real content is (US12.5M) meant for the purchase of arms for the Congolese Army.
My father went home for the funeral of the late president, but on his arrival he was arrested, detained and tortured, unfortunately my father suffer cardiac arrest and died on the 17th of March 2001. However, on one of our numerous visits, my mother and 
I paid him while in prison, my father was able to reveal this secret to me and advice that i should proceed to the Netherlands to claim the money, he handed me all the relevant documents that will enable me claim the box from the security company.Already
, I have made my first visit to the security company and the availability of this box have been confirmed.
On our arrival in the Netherlands few months ago, we sought for political asylum; which was granted. My mother and I are making frantic efforts on the best way to handle this money. We sought advice from an attorney who advised that we must seek for a tr
ustworthy foreign business partner whom this money could be transferred into his/her (company"s) account This we view as the best option because our refugee status does not permit us to operate a bank account, hence we seek your assistance and hope you
could be trusted.
I sincerely crave your indulgence and assistance to get this money through your account, Your share for assisting us will be 25% of the total sum, 5% will be use for upsetting all the expenses incurred in the course of concluding this venture and the rem
aining 70% that will be for me and my family. Also you stand to gain from any investment you might introduce us into after the conclusion of the transfer.
Please keep this confidential until we finalize and get this money into your account for security reasons.
Please this e-mail address you can reach me (david30 at zwallet.com) 
Thanks and GOD bless
MR DAVID KAMARA  

From sbarry at jhsph.edu  Thu Sep 25 18:41:15 2003
From: sbarry at jhsph.edu (Sarah Barry)
Date: Thu, 25 Sep 2003 12:41:15 -0400
Subject: [R] LME problem
Message-ID: <000701c38383$d6767df0$5e58140a@SBARRY>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030925/fb5f51ab/attachment.pl

From bih at ornl.gov  Thu Sep 25 19:04:21 2003
From: bih at ornl.gov (Bing Zhang)
Date: Thu, 25 Sep 2003 13:04:21 -0400
Subject: [R] allShortestPath function in e1071 package
Message-ID: <3F6BC0CC@webmail1>

Hi All,

I am using the allShortestPath function based on Floyd's algorithm in e1071 
package. It runs great when I have less than 5000 nodes. But when I tried to 
work on more than 5000 nodes, I ran into memory problem. The problem I really 
want to solve has 10000-15000 nodes.

Does anybody know how to deal with this problem? Are there any other packages 
in R that can handle this problem? Thanks!

Bing

---------------------------------
1060 Commerce Park
Oak Ridge National Laboratory
P.O. Box 2008, MS 6480
Oak Ridge, TN 37831-6480
Phone: 865-241-0761
Email: zhangb at ornl.gov



From Subramanian_Karthikeyan at hc-sc.gc.ca  Thu Sep 25 19:10:18 2003
From: Subramanian_Karthikeyan at hc-sc.gc.ca (Subramanian Karthikeyan)
Date: Thu, 25 Sep 2003 13:10:18 -0400
Subject: [R] splitting clusters
Message-ID: <OF87B6AAD4.01A56F7D-ON85256DAC.005C33A1@hc-sc.gc.ca>


Thanks Martin,

Cutting the dendrogram as you suggested solved the problem.   I have
another question along the same lines... If samples x1, x2, y4,y5, z6 are
clustered together, is there a way of extracting this information (i.e.
name of the samples clustered together) and saving it in a file?

Thanks again,
Karthi.






                                                                                                                                       
                      Martin Maechler                                                                                                  
                      <maechler at stat.ma        To:       "Subramanian Karthikeyan" <Subramanian_Karthikeyan at hc-sc.gc.ca>               
                      th.ethz.ch>              cc:       r-help at stat.math.ethz.ch                                                      
                                               Subject:  Re: [R] splitting clusters                                                    
                      2003-09-25 03:56                                                                                                 
                      AM                                                                                                               
                      Please respond to                                                                                                
                      Martin Maechler                                                                                                  
                                                                                                                                       
                                                                                                                                       




>>>>> "KarthiS" == Subramanian Karthikeyan
<Subramanian_Karthikeyan at hc-sc.gc.ca>
>>>>>     on Wed, 24 Sep 2003 13:04:04 -0400 writes:

    KarthiS> Hi All: I am clustering 500 genes using hclust of
    KarthiS> R.  Visualizing cluster membership becomes
    KarthiS> difficult with so many genes in each cluster...Is
    KarthiS> there a way of printing the dendrogram in multiple
    KarthiS> pages so that I can clearly see what is in each
    KarthiS> cluster?

- Use dd <- as.dendrogram(hc) on your hclust result `hc',
  then dd[1] gives the first branch, dd[1][2] the 2nd sub-branch of
  the first branch, etc., see the examples on
  ?dendrogram.

- The package "maptree" has also tools for this,
  particularly  prune.clust()

    KarthiS> Thanks in advance.

you're welcome.
--
Martin Maechler <maechler at stat.math.ethz.ch>
http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16    Leonhardstr. 27
ETH (Federal Inst. Technology)      8092 Zurich SWITZERLAND
phone: x-41-1-632-3408        fax: ...-1228                 <><



From friendly at yorku.ca  Thu Sep 25 19:14:06 2003
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 25 Sep 2003 13:14:06 -0400
Subject: [R] ungrouping grouped data
Message-ID: <3F73225E.5080808@yorku.ca>

I'm sure this is probably simple, but I can't find an answer...
I have a data frame (Galton's data on heights of parents and children), 
in grouped form,

parent child frequency
73.5 72.2 1
73.5 73.2 3
72.5 68.2 1
72.5 69.2 2
72.5 70.2 1
72.5 71.2 2
72.5 72.2 7
72.5 73.2 2
72.5 74.2 4
71.5 65.2 1
71.5 66.2 3
71.5 67.2 4
71.5 68.2 3
71.5 69.2 5
71.5 70.2 10
...

and need the ungrouped equivalent, where each input observation
appears the number of times represented by its frequency.  In SAS
this would be

data galton2;
    set galton;
    do i=1 to frequency;
       output;
    end;

I can replicate this in R, but surely there must be an easier way.
(In APL2 it would be frequency\[1]galton)

thanks,
-Michael

-- 
Michael Friendly     Email: friendly at yorku.ca 
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA



From dmurdoch at pair.com  Thu Sep 25 19:49:14 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu, 25 Sep 2003 13:49:14 -0400
Subject: [R] Tutorial docs: Vignettes! {was "searching R-help .."}
In-Reply-To: <5.1.0.14.2.20030925120828.020ea028@127.0.0.1>
References: <001001c3816c$cfc633b0$4e02a8c0@olau>
	<001001c3816c$cfc633b0$4e02a8c0@olau>
	<16242.63405.998807.750544@gargle.gargle.HOWL>
	<5.1.0.14.2.20030925120828.020ea028@127.0.0.1>
Message-ID: <nfa6nvodtgsgb7hlkk6hbhb8iom107g68t@4ax.com>

On Thu, 25 Sep 2003 12:10:28 -0400, John Fox <jfox at mcmaster.ca> wrote
:

>Dear Martin
>
>At 04:11 PM 9/25/2003 +0200, Martin Maechler wrote:
>
>. . .
>
>>And many more packages have other *.pdf documents in their installed
>>./doc/ directories.  However, currently this is not shown
>>in library(help = <package>)
>>--- nor anywhere on CRAN's package-source page (which may be
>>worth improving ...)
>
>I'll second this motion -- to provide convenient access to whatever pdf 
>file are in a packages's doc directory.

These do get links in the HTML help, saying (at the top of the listing
for the package)

*Accompanying documentation* is available in the subdirectory "doc" of
the installed package.  

The hyperlink (marked with asterisks) takes me to a directory listing
in a case I'm looking at now.

Duncan Murdoch



From bih at ornl.gov  Thu Sep 25 19:52:25 2003
From: bih at ornl.gov (Bing Zhang)
Date: Thu, 25 Sep 2003 13:52:25 -0400
Subject: [R] allShortestPath function in e1071 package
Message-ID: <3F6BCDC4@webmail1>

Hi Richard,

Yes, I do need the path length and shortest path itself.

Bing

>===== Original Message From "Remington, Richard" <rnews at kernstat.com> =====
>Bing
>
>Sounds like you want path length, but....
>
>If minimum distance between any two points in a plane is equivalent in
>your application, then try something like
>
>x <- runif(10)
>y <- runif(10)
>require(mva)
>min(dist(c(x,y)))
>
>When this runs out of RAM, I call a C function to do the same.  Finds
>minimum distance for 100,000 points in 1 minute on 2GHz processor, 1Gb
>RAM machine.
>
>regards,
>Richard
>
>Richard E. Remington III
>Statistician
>KERN Statistical Services, Inc.
>PO Box 1046
>Boise, ID 83701
>Tel: 208.426.0113
>KernStat.com
>
>Bing Zhang wrote:
>
>>Hi All,
>>
>>I am using the allShortestPath function based on Floyd's algorithm in e1071
>>package. It runs great when I have less than 5000 nodes. But when I tried to
>>work on more than 5000 nodes, I ran into memory problem. The problem I 
really
>>want to solve has 10000-15000 nodes.
>>
>>Does anybody know how to deal with this problem? Are there any other 
packages
>>in R that can handle this problem? Thanks!
>>
>>Bing
>>
>>---------------------------------
>>1060 Commerce Park
>>Oak Ridge National Laboratory
>>P.O. Box 2008, MS 6480
>>Oak Ridge, TN 37831-6480
>>Phone: 865-241-0761
>>Email: zhangb at ornl.gov
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
>>
>>

---------------------------------
1060 Commerce Park
Oak Ridge National Laboratory
P.O. Box 2008, MS 6480
Oak Ridge, TN 37831-6480
Phone: 865-241-0761
Email: zhangb at ornl.gov



From faro at canaco.net  Thu Sep 25 19:07:21 2003
From: faro at canaco.net (Faro)
Date: Thu, 25 Sep 2003 12:07:21 -0500
Subject: [R] No hay condiciones para aprobar la reforma fiscal . . .
Message-ID: <132766195-22003942517721187@canaco.net>


   Hola r-help at stat.math.ethz.ch, tu boletín electrónico

         25 / Sept. / 2003
    [1][button_edc_100903.gif] 

     [2][button_yturria.gif] 

   [3][button_microsoft_xp.gif] 

       [4][button_dhl.gif] 

       [5][button_att.gif] 

        [6][button_P3.gif] 




   CANACO INFORMA           
                  INVITACION
   Acompáñenos en Diálogo de Líderes
   XXV Diálogo de Líderes con el Lic. Natividad González, Gobernador
   electo del Estado, y el tema: La Integración de América del Norte.
   XXIV Diálogo de Líderes con el Lic. Fernando Canales, Secretario de
   Economía, y el tema: La investigación Tecnológica en el Desarrollo
   Económico.
   Ambos eventos se llevarán a cabo mañana viernes 26 de septiembre en el
   Hotel Crowne Plaza. Confirme su asistencia a los Tels.8400-2424 ext.
   134 y 108 o vía e-mail a: [7]dialogo at canaco.net CUPO LIMITADO
   [logo_canaco120.jpg]

   TURISMO      
           LOCAL
   El boom de inversiones benefició al turismo en NL
   Para Omar Mohammed, la administración estatal panista reivindicó al
   turismo como un sector capaz de generar empleos y derrama económica
   para otras actividades.El subsecretario de Turismo cita una cifra: el
   gobernador anterior ejerció 100 mil pesos en su último año, mientras
   que este gobierno terminará el sexenio con 113 millones de pesos
   aplicados en infraestructura pública turística más 132 millones en las
   campañas de promoción.
   [8][cola_caballo.jpg] 

                                MILENIO.COM

   GOBIERNO         
            NACIONAL
   Lanza gobierno nueva estrategia antipobreza
   El 16 de octubre, al celebrarse el Día Mundial de la Alimentación, el
   gobierno federal presentará un nuevo programa, tentativamente llamado
   "Pa que te nutras", que reemplazaría a "Pa que te alcance", que nunca
   entró en operación.
   [9][mujer_nino.jpg] 

                              UNIVERSAL ONLINE

   LEGISLATIVO         
               NACIONAL
   No hay condiciones para aprobar la reforma fiscal: senadores
   Los trabajos de la mesa de análisis para la reforma fiscal sólo
   podrían arrojar cambios a las reglas de algunos impuestos con
   potencial desaprovechado que podrían incrementar los ingresos
   públicos.
   [10][hacienda_edificio.jpg] 

                                MILENIO.COM

   EMPRESARIAL         
               NACIONAL
   Los banqueros quieren limpiar su imagen
   La Asociación de Banqueros de México lanzará este jueves una campaña
   publicitaria para mejorar su imagen ante el público y ofrecer de nuevo
   sus productos a los clientes. La estrategia contempla una inversión de
   80 millones de pesos e incluirá spots en televisión, radio, cine y
   anuncios en periódicos.
   [11][bancos.jpg] 

                                MILENIO.COM

                                indicadores

                           Índices de las Bolsas

                                 BMV  7,788

   DW  9,425

                                                                   NASDAQ

    1,843

                                   Dólar

                               COMPRA  $10.61

   VENTA  $10.87

                               Interbancario

    $10.79

                                                   [12][indicadores.jpg] 

   [header_back_down_bott.jpg]

                                 suscribase

                                                                  nombre:

   ________________

                                                                  e-mail:

   ________________
   [_]   Faro [_]   Especiales|canaco.net
     [html]
   enviar
   [header_back_down_bott.jpg]

                                [dot_2.jpg]

                              [canaco_120.jpg]
                  [13]Envía este boletín a un amigo AHORA
   Usted recibe faro como parte de su suscripción a las publicaciones de
                                 canaco.net
              La dirección a la que le enviamos el mensaje es
                         r-help at stat.math.ethz.ch,
             para dejar de recibir este boletín [14]Oprima Aquí
                              [canaco_net.jpg]

      Derechos Reservados © CANACO Monterrey, N.L., México 2000 - 2003


   [t.asp?S=2&ID=575&NL=5&N=617&Imp=True&SubscriberID=151453]

References

   Visible links
   1. http://www.canaco.net/enewsletterpro/t.asp?S=2&ID=575&NL=5&N=617&SubscriberID=151453&URL=http%3A%2F%2Fwww%2Ecanaco%2Enet%2F%5Freportes%5Fespeciales%2Feducacionydesarrollo%5F02%2Ehtm
   2. http://www.canaco.net/enewsletterpro/t.asp?S=2&ID=575&NL=5&N=617&SubscriberID=151453&URL=http%3A%2F%2Fwww%2Eyturria%2Ecom%2Emx%2F
   3. http://www.canaco.net/enewsletterpro/t.asp?S=2&ID=575&NL=5&N=617&SubscriberID=151453&URL=http%3A%2F%2Fwww%2Emicrosoft%2Ecom%2Fmexico%2Fpromociones%2Fdomina%2F
   4. http://www.canaco.net/enewsletterpro/t.asp?S=2&ID=575&NL=5&N=617&SubscriberID=151453&URL=http%3A%2F%2Fwww%2Edhl%2Ecom%2F
   5. http://www.canaco.net/enewsletterpro/t.asp?S=2&ID=575&NL=5&N=617&SubscriberID=151453&URL=http%3A%2F%2Fcanaco%2Enet%2Faliados%2Fatt%2Fpromocion%2Ehtml
   6. http://www.canaco.net/enewsletterpro/t.asp?S=2&ID=575&NL=5&N=617&SubscriberID=151453&URL=http%3A%2F%2Fwww%2Ecanaco%2Enet%2Fcampana%5Fp3%2F
   7. mailto:dialogo at canaco.net
   8. http://www.canaco.net/enewsletterpro/t.asp?S=2&ID=575&NL=5&N=617&SubscriberID=151453&URL=http%3A%2F%2Fwww%2Emilenio%2Ecom%2Fnota%2Easp%3Fid%3D97320
   9. http://www.canaco.net/enewsletterpro/t.asp?S=2&ID=575&NL=5&N=617&SubscriberID=151453&URL=http%3A%2F%2Fwww%2Eeluniversal%2Ecom%2Emx%2Fpls%2Fimpreso%2Fnoticia%2Ehtml%3Fid%5Fnota%3D173185%26tabla%3Dnotas
  10. http://www.canaco.net/enewsletterpro/t.asp?S=2&ID=575&NL=5&N=617&SubscriberID=151453&URL=http%3A%2F%2Fwww%2Emilenio%2Ecom%2Fnota%2Easp%3Fid%3D97338
  11. http://www.canaco.net/enewsletterpro/t.asp?S=2&ID=575&NL=5&N=617&SubscriberID=151453&URL=http%3A%2F%2Fwww%2Emilenio%2Ecom%2Fnota%2Easp%3Fid%3D97337
  12. http://www.canaco.net/enewsletterpro/t.asp?S=2&ID=575&NL=5&N=617&SubscriberID=151453&URL=http%3A%2F%2Fwww%2Ecanaco%2Enet%2Findicadores%2F
  13. http://www.canaco.net/enewsletterpro/members.asp?Task=FF&SubscriberID=151453&Email=r%2Dhelp%40stat%2Emath%2Eethz%2Ech&S=2&N=617&Format=HTML
  14. http://www.canaco.net/enewsletterpro/members.asp?Task=OptOut&SubscriberID=151453&Email=r%2Dhelp%40stat%2Emath%2Eethz%2Ech&S=2

   Hidden links:
  15. http://www.canaco.net/enewsletterpro/t.asp?S=2&ID=575&NL=5&N=617&SubscriberID=151453&URL=http%3A%2F%2Fwww%2Emadisa%2Ecom
  16. http://www.canaco.net/enewsletterpro/t.asp?S=2&ID=575&NL=5&N=617&SubscriberID=151453&URL=http%3A%2F%2Fwww%2Ehotelesmilenium%2Ecom%2F


From tblackw at umich.edu  Thu Sep 25 20:00:58 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Thu, 25 Sep 2003 14:00:58 -0400 (EDT)
Subject: [R] ungrouping grouped data
In-Reply-To: <3F73225E.5080808@yorku.ca>
References: <3F73225E.5080808@yorku.ca>
Message-ID: <Pine.SOL.4.58.0309251350320.12019@mspacman.gpcc.itd.umich.edu>

Michael  -

 new <- as.data.frame(lapply(data, function(x,p) rep(x,p), data[["frequency"]]))

This should do it.  The first paragraph under "Details" in  help("rep")
says what  rep(x,p)  is doing above.  The rest is just hardware to apply
that to every column in your existing data frame, and turn the result
back into a data frame again.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Thu, 25 Sep 2003, Michael Friendly wrote:

> I'm sure this is probably simple, but I can't find an answer...
> I have a data frame (Galton's data on heights of parents and children),
> in grouped form,
>
> parent child frequency
> 73.5 72.2 1
> 73.5 73.2 3
> 72.5 68.2 1
> 72.5 69.2 2
> 72.5 70.2 1
> 72.5 71.2 2
> 72.5 72.2 7
> 72.5 73.2 2
> 72.5 74.2 4
> 71.5 65.2 1
> 71.5 66.2 3
> 71.5 67.2 4
> 71.5 68.2 3
> 71.5 69.2 5
> 71.5 70.2 10
> ...
>
> and need the ungrouped equivalent, where each input observation
> appears the number of times represented by its frequency.  In SAS
> this would be
>
> data galton2;
>     set galton;
>     do i=1 to frequency;
>        output;
>     end;
>
> I can replicate this in R, but surely there must be an easier way.
> (In APL2 it would be frequency\[1]galton)
>
> thanks,
> -Michael
> --
> Michael Friendly     Email: friendly at yorku.ca
> Professor, Psychology Dept.
> York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
> 4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
> Toronto, ONT  M3J 1P3 CANADA
>



From uth at zhwin.ch  Thu Sep 25 20:01:10 2003
From: uth at zhwin.ch (=?utf-8?Q?=22Untern=C3=A4hrer_Thomas=2C_uth=22?=)
Date: Thu, 25 Sep 2003 20:01:10 +0200
Subject: AW: [R] ungrouping grouped data
Message-ID: <53A181E56FB0694ABFD212F8AEDA7F6F1AB895@langouste.zhwin.ch>

Hi,

You can so something like this

XX <- data.frame(x=1:10,y=rbinom(10,3,0.5))

sapply(XX,rep,XX[,2])

HTH (if this do what you really want)
 
Thomas

	-----Urspr?ngliche Nachricht----- 
	Von: Michael Friendly [mailto:friendly at yorku.ca] 
	Gesendet: Do 25.09.2003 19:14 
	An: r-help 
	Cc: 
	Betreff: [R] ungrouping grouped data
	
	

	I'm sure this is probably simple, but I can't find an answer...
	I have a data frame (Galton's data on heights of parents and children),
	in grouped form,
	
	parent child frequency
	73.5 72.2 1
	73.5 73.2 3
	72.5 68.2 1
	72.5 69.2 2
	72.5 70.2 1
	72.5 71.2 2
	72.5 72.2 7
	72.5 73.2 2
	72.5 74.2 4
	71.5 65.2 1
	71.5 66.2 3
	71.5 67.2 4
	71.5 68.2 3
	71.5 69.2 5
	71.5 70.2 10
	...
	
	and need the ungrouped equivalent, where each input observation
	appears the number of times represented by its frequency.  In SAS
	this would be
	
	data galton2;
	    set galton;
	    do i=1 to frequency;
	       output;
	    end;
	
	I can replicate this in R, but surely there must be an easier way.
	(In APL2 it would be frequency\[1]galton)
	
	thanks,
	-Michael
	
	--
	Michael Friendly     Email: friendly at yorku.ca
	Professor, Psychology Dept.
	York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
	4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
	Toronto, ONT  M3J 1P3 CANADA
	
	______________________________________________
	R-help at stat.math.ethz.ch mailing list
	https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From bates at stat.wisc.edu  Thu Sep 25 20:07:14 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 25 Sep 2003 18:07:14 -0000
Subject: [R] ungrouping grouped data
In-Reply-To: <3F73225E.5080808@yorku.ca>
References: <3F73225E.5080808@yorku.ca>
Message-ID: <6rsmmkeo71.fsf@bates4.stat.wisc.edu>

Michael Friendly <friendly at yorku.ca> writes:

> I'm sure this is probably simple, but I can't find an answer...
> I have a data frame (Galton's data on heights of parents and
> children), in grouped form,
> 
> 
> parent child frequency
> 73.5 72.2 1
> 73.5 73.2 3
> 72.5 68.2 1
> 72.5 69.2 2
> 72.5 70.2 1
> 72.5 71.2 2
> 72.5 72.2 7
> 72.5 73.2 2
> 72.5 74.2 4
> 71.5 65.2 1
> 71.5 66.2 3
> 71.5 67.2 4
> 71.5 68.2 3
> 71.5 69.2 5
> 71.5 70.2 10
> ...
> 
> and need the ungrouped equivalent, where each input observation
> appears the number of times represented by its frequency.

If df is the name of the data frame you want

df[rep(1:nrow(df), df$frequency), 1:2]



From Benjamin.STABLER at odot.state.or.us  Thu Sep 25 20:19:07 2003
From: Benjamin.STABLER at odot.state.or.us (Benjamin.STABLER@odot.state.or.us)
Date: Thu, 25 Sep 2003 11:19:07 -0700
Subject: [R] apply on a 4D array
Message-ID: <76A000A82289D411952F001083F9DD06047FE294@exsalem4-bu.odot.state.or.us>

I am trying to multiply a 3D array of 4x4x4 by the 4 3D arrays of a 4D array
with dimensions 4x4x4x4 (the last dimension being the one that I want to
split by).  

(4x4x4 array)
> hiaAry
, , a1

          i1       i2      i3        i4
h1 9.5936098 6.001040 0.08772 0.3138600
h2 1.2003500 1.454570 2.79248 0.0000000
h3 0.1346500 0.201220 0.39256 0.5464000
h4 0.0109000 0.012270 0.16417 0.2766900

, , a2

          i1          i2       i3       i4
h1 195.08275 74.23508453 39.23165 14.89689
h2   1.80127  7.41649055  6.97972  2.77784
h3   0.00000  0.27444002  0.77353  6.10322
h4   0.01554  0.01232000  0.40669  3.69832

, , a3

         i1          i2      i3      i4
h1 25.81161 13.57603931 6.40551 1.38103
h2  2.61562  2.26407003 2.13906 1.41652
h3  0.05780  0.30406001 1.15228 0.00000
h4  0.00000  0.04258000 0.22346 0.43209

, , a4

         i1       i2         i3      i4
h1 59.47618 16.54495 0.00000000 0.00000
h2  1.50265  2.76623 0.00000000 0.08917
h3  0.00000  0.42722 0.00000000 1.29230
h4  0.00000  0.00000 0.07564002 0.34235


(4x4x4x4 array)
dim "wX" is the dimension that I want to split the array by.
> probAry
, , a1, w1

          i1         i2         i3          i4
h1 0.3784811 0.17321659 0.11236581 0.157227931
h2 0.2569944 0.08635110 0.03812272 0.036192191
h3 0.1659365 0.04928920 0.01856106 0.015686506
h4 0.0939886 0.02551057 0.00846568 0.006614069

, , a2, w1

          i1         i2          i3          i4
h1 0.3227855 0.14088002 0.090150394 0.127416178
h2 0.2181195 0.07210281 0.032273293 0.031203848
h3 0.1409469 0.04170138 0.015971840 0.013690984
h4 0.0804619 0.02189455 0.007375192 0.005817293

, , a3, w1

          i1        i2         i3        i4
h1 0.7558389 0.5157448 0.39155036 0.4867531
h2 0.6611814 0.3640772 0.20821663 0.2126003
h3 0.5494104 0.2540337 0.11997469 0.1092745
h4 0.4100844 0.1566448 0.06143343 0.0507088

, , a4, w1

          i1        i2        i3        i4
h1 0.9445381 0.8542088 0.7797483 0.8391612
h2 0.9234338 0.7957714 0.6755850 0.7172834
h3 0.8941212 0.7257939 0.5631331 0.5815922
h4 0.8487089 0.6284291 0.4226977 0.4107244

, , a1, w2................................

I thought it would be something along the lines of apply(4Darray, c(1,2,3),
function(x) x*3Darray).  But this returns the results in the form of 64rows
by dim1 by dim2 by dim3.

, , i4, a4
                h1           h2           h3           h4
 [1,]   8.05058486 6.881337e+00 5.579569e+00  3.940329195
 [2,]   0.19306289 2.185652e-01 2.347175e-01  0.219540239
 .
 .
 .
[63,]   0.00000000 1.300468e-01 2.430320e-01  0.395577205
[64,]   0.00000000 0.000000e+00 1.191559e-02  0.034329350

It looks like the rows are all the combinations of the 4th dimension with
the other dimensions.  So then I thought I could array it back to the
dimensions I want and maybe use aperm if I needed to.  But there must be a
better way to do this.  I can of course just multiple the 3D array by each
3D cube of the 4D array with a loop...but that would be inefficient.  

I thought maybe sweep(4Darray, 4, 3Darray, "*"), but that returns different
results than multiplying each 3D array by each 3D cube of the 4D array.  I
guess what I am asking is for some clarification on apply and sweep.  I have
read the manuals and searched the list, but I can't seem to find much about
operations with 3 or more dimensions.  Thanks.

Ben Stabler



From tblackw at umich.edu  Thu Sep 25 20:39:59 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Thu, 25 Sep 2003 14:39:59 -0400 (EDT)
Subject: [R] apply on a 4D array
In-Reply-To: <76A000A82289D411952F001083F9DD06047FE294@exsalem4-bu.odot.state.or.us>
References: <76A000A82289D411952F001083F9DD06047FE294@exsalem4-bu.odot.state.or.us>
Message-ID: <Pine.SOL.4.58.0309251436340.2630@mspacman.gpcc.itd.umich.edu>

Ben  -

I think you want something like

new <- array(prod(hiaAry, probAry[,,,1], probAry[,,,2],
           probAry[,,,3], probAry[,,,4]), dim(hiaAry))

But I'm just guessing.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Thu, 25 Sep 2003 Benjamin.STABLER at odot.state.or.us wrote:

> I am trying to multiply a 3D array of 4x4x4 by the 4 3D arrays of a 4D array
> with dimensions 4x4x4x4 (the last dimension being the one that I want to
> split by).
>
> (4x4x4 array)
> > hiaAry
> , , a1
>
>           i1       i2      i3        i4
> h1 9.5936098 6.001040 0.08772 0.3138600
> h2 1.2003500 1.454570 2.79248 0.0000000
> h3 0.1346500 0.201220 0.39256 0.5464000
> h4 0.0109000 0.012270 0.16417 0.2766900
>
> , , a2
>
>           i1          i2       i3       i4
> h1 195.08275 74.23508453 39.23165 14.89689
> h2   1.80127  7.41649055  6.97972  2.77784
> h3   0.00000  0.27444002  0.77353  6.10322
> h4   0.01554  0.01232000  0.40669  3.69832
>
> , , a3
>
>          i1          i2      i3      i4
> h1 25.81161 13.57603931 6.40551 1.38103
> h2  2.61562  2.26407003 2.13906 1.41652
> h3  0.05780  0.30406001 1.15228 0.00000
> h4  0.00000  0.04258000 0.22346 0.43209
>
> , , a4
>
>          i1       i2         i3      i4
> h1 59.47618 16.54495 0.00000000 0.00000
> h2  1.50265  2.76623 0.00000000 0.08917
> h3  0.00000  0.42722 0.00000000 1.29230
> h4  0.00000  0.00000 0.07564002 0.34235
>
>
> (4x4x4x4 array)
> dim "wX" is the dimension that I want to split the array by.
> > probAry
> , , a1, w1
>
>           i1         i2         i3          i4
> h1 0.3784811 0.17321659 0.11236581 0.157227931
> h2 0.2569944 0.08635110 0.03812272 0.036192191
> h3 0.1659365 0.04928920 0.01856106 0.015686506
> h4 0.0939886 0.02551057 0.00846568 0.006614069
>
> , , a2, w1
>
>           i1         i2          i3          i4
> h1 0.3227855 0.14088002 0.090150394 0.127416178
> h2 0.2181195 0.07210281 0.032273293 0.031203848
> h3 0.1409469 0.04170138 0.015971840 0.013690984
> h4 0.0804619 0.02189455 0.007375192 0.005817293
>
> , , a3, w1
>
>           i1        i2         i3        i4
> h1 0.7558389 0.5157448 0.39155036 0.4867531
> h2 0.6611814 0.3640772 0.20821663 0.2126003
> h3 0.5494104 0.2540337 0.11997469 0.1092745
> h4 0.4100844 0.1566448 0.06143343 0.0507088
>
> , , a4, w1
>
>           i1        i2        i3        i4
> h1 0.9445381 0.8542088 0.7797483 0.8391612
> h2 0.9234338 0.7957714 0.6755850 0.7172834
> h3 0.8941212 0.7257939 0.5631331 0.5815922
> h4 0.8487089 0.6284291 0.4226977 0.4107244
>
> , , a1, w2................................
>
> I thought it would be something along the lines of apply(4Darray, c(1,2,3),
> function(x) x*3Darray).  But this returns the results in the form of 64rows
> by dim1 by dim2 by dim3.
>
> , , i4, a4
>                 h1           h2           h3           h4
>  [1,]   8.05058486 6.881337e+00 5.579569e+00  3.940329195
>  [2,]   0.19306289 2.185652e-01 2.347175e-01  0.219540239
>  .
>  .
>  .
> [63,]   0.00000000 1.300468e-01 2.430320e-01  0.395577205
> [64,]   0.00000000 0.000000e+00 1.191559e-02  0.034329350
>
> It looks like the rows are all the combinations of the 4th dimension with
> the other dimensions.  So then I thought I could array it back to the
> dimensions I want and maybe use aperm if I needed to.  But there must be a
> better way to do this.  I can of course just multiple the 3D array by each
> 3D cube of the 4D array with a loop...but that would be inefficient.
>
> I thought maybe sweep(4Darray, 4, 3Darray, "*"), but that returns different
> results than multiplying each 3D array by each 3D cube of the 4D array.  I
> guess what I am asking is for some clarification on apply and sweep.  I have
> read the manuals and searched the list, but I can't seem to find much about
> operations with 3 or more dimensions.  Thanks.
>
> Ben Stabler
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From cdeclercq at nordnet.fr  Thu Sep 25 20:44:30 2003
From: cdeclercq at nordnet.fr (Christophe Declercq)
Date: Thu, 25 Sep 2003 20:44:30 +0200
Subject: [R] ungrouping grouped data
References: <3F73225E.5080808@yorku.ca>
Message-ID: <008301c38395$253b12a0$549df9c1@Alfred>

Something like that?

> galton2<-galton[rep(1:nrow(galton), galton$frequency), 1:2]

Christophe

----- Original Message ----- 
From: "Michael Friendly" <friendly at yorku.ca>
To: "r-help" <r-help at stat.math.ethz.ch>
Sent: Thursday, September 25, 2003 7:14 PM
Subject: [R] ungrouping grouped data


> I'm sure this is probably simple, but I can't find an answer...
> I have a data frame (Galton's data on heights of parents and children), 
> in grouped form,
> 
> parent child frequency
> 73.5 72.2 1
> 73.5 73.2 3
> 72.5 68.2 1
> 72.5 69.2 2
> 72.5 70.2 1
> 72.5 71.2 2
> 72.5 72.2 7
> 72.5 73.2 2
> 72.5 74.2 4
> 71.5 65.2 1
> 71.5 66.2 3
> 71.5 67.2 4
> 71.5 68.2 3
> 71.5 69.2 5
> 71.5 70.2 10
> ...
> 
> and need the ungrouped equivalent, where each input observation
> appears the number of times represented by its frequency.  In SAS
> this would be
> 
> data galton2;
>     set galton;
>     do i=1 to frequency;
>        output;
>     end;
> 
> I can replicate this in R, but surely there must be an easier way.
> (In APL2 it would be frequency\[1]galton)
> 
> thanks,
> -Michael
> 
> -- 
> Michael Friendly     Email: friendly at yorku.ca 
> Professor, Psychology Dept.
> York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
> 4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
> Toronto, ONT  M3J 1P3 CANADA
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
>



From jfox at mcmaster.ca  Thu Sep 25 20:59:17 2003
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 25 Sep 2003 14:59:17 -0400
Subject: [R] Tutorial docs: Vignettes! {was "searching R-help .."}
In-Reply-To: <nfa6nvodtgsgb7hlkk6hbhb8iom107g68t@4ax.com>
References: <5.1.0.14.2.20030925120828.020ea028@127.0.0.1>
	<001001c3816c$cfc633b0$4e02a8c0@olau>
	<001001c3816c$cfc633b0$4e02a8c0@olau>
	<16242.63405.998807.750544@gargle.gargle.HOWL>
	<5.1.0.14.2.20030925120828.020ea028@127.0.0.1>
Message-ID: <5.1.0.14.2.20030925145626.02000128@127.0.0.1>

Dear Duncan,

Thanks for pointing this out -- I wasn't aware of it.

I wonder whether it wouldn't be helpful in addition to make the links to 
such documents available through library(help=<package>) and 
help(package=<package>) as well, but I guess that how this should be done 
requires more thought.

Regards,
  John

At 01:49 PM 9/25/2003 -0400, Duncan Murdoch wrote:
>On Thu, 25 Sep 2003 12:10:28 -0400, John Fox <jfox at mcmaster.ca> wrote
>:
>
> >Dear Martin
> >
> >At 04:11 PM 9/25/2003 +0200, Martin Maechler wrote:
> >
> >. . .
> >
> >>And many more packages have other *.pdf documents in their installed
> >>./doc/ directories.  However, currently this is not shown
> >>in library(help = <package>)
> >>--- nor anywhere on CRAN's package-source page (which may be
> >>worth improving ...)
> >
> >I'll second this motion -- to provide convenient access to whatever pdf
> >file are in a packages's doc directory.
>
>These do get links in the HTML help, saying (at the top of the listing
>for the package)
>
>*Accompanying documentation* is available in the subdirectory "doc" of
>the installed package.
>
>The hyperlink (marked with asterisks) takes me to a directory listing
>in a case I'm looking at now.
>
>Duncan Murdoch

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From philkabi65 at netscape.net  Thu Sep 25 20:59:06 2003
From: philkabi65 at netscape.net (Philip Kabila)
Date: Thu, 25 Sep 2003 20:59:06 +0200
Subject: [R] PRIVATE AND CONFIDENTIAL.
Message-ID: <200309251859.h8PIx8Df002783@stat.math.ethz.ch>

FROM: PHILIP KABILA.
EMAIL: philkabi75 at netscape.net


                                           PRIVATE AND CONFIDENTIAL.
Dear Sir,

You may be surprise to receive this Email from me since you do not know me personally. However, I would like to introduce myself. I am Mr.Philip Kalusha  Kabila Jr,  the son of Dr. Stephen Kalusha Kabila who was murdered few months ago in Zimbabwe as a  result of land dispute. Before the death of my father (Dr. Kabila), he had taken me to AMSTERDAM to
deposit the sum of Twenty Two Million United States dollars (US$22,000,000) in a security company, as he foresaw the looming danger in Zimbabwe. The money in question was deposited in a box as Gemstones to avoid  much demurrage from the security company.

The proposed amount was meant for  the purchase of new machines and chemicals for the farms and establishment of  new farms on Swaziland. As you may be aware this land problem came into force when Zimbabwe president Mr. Robert Mugabe Introduced the Land Reformed Act of which my father rich farmers and some black farmers where affected. This resulted
to the killing and Mob action by Zimbabwe war veterans and some lunatics in the society, infact, a lot of people were killed because of this Land Reformed act of which my dad was one of the victims. It is against this background that my family and I who are currently staying in Amsterdam, I decided to transfer my father money to a foreign account. Since the
Dutch  law prohibit a refugee (asylum seeker) to open any account or be involved in any financial transaction. As the eldest son of my father, I am saddled with  the responsibility of seeking a genuine foreign account where the money could be transferred . I am faced with the dilemma of investing this amount of money in Holland for the fear of going through
the same experience in future since both countries have similar history. Moreover, The Netherlands foreign exchange policy does not allow such investment from asylum seekers. As a businessman, whom I have entrusted my future and my family in his hands , I must let you know that this transaction is risk free. If you accept to assist  me and my family, all I need you to do for me is to make arrangement and come to AMSTERDAM ,THE NETHERLANDS, so that we can open the non-resident account which will aid us in transferring the money into any account you will nominate overseas. This money I intend using for investment. I have options to offer you, first you can choose to have certain percentage of the money for nominating your account for the transaction, or you can go into partnership for a proper profitable investment of the money in your country.

Which ever option you choose, feel free to notify me. I have mapped out 5% of this money for all expenses incurred in processing the transaction. If for some reasons you do not prefer a partnership, I am willing to give you 25% of  the money while the remaining 70% that is
meant for me, will be for the  investment in your country. Please, contact me on the  Email so we can discuss further and a chance for you to ask me any question you may have in mind, while you maintain the absolute secrecy required in the transaction.

I wait to hear from you as soon as possible.

Best Regards,

PHILIP KABILA.



  

From mhough at itsa.ucsf.edu  Thu Sep 25 21:37:03 2003
From: mhough at itsa.ucsf.edu (Morgan Hough)
Date: Thu, 25 Sep 2003 12:37:03 -0700 (PDT)
Subject: [R] rpmbuild of src.rpm error
Message-ID: <Pine.GSO.4.53.0309251231380.10239@itsa.ucsf.edu>

I received an error trying to build R-1.7.1-src.rpm on RH9.0.93 (Severn)
and I was wondering if anybody could tell me what is going on with the
manual error.

+ cp -pr 'doc/manual/R-*.pdf' /var/tmp/R-root/usr/share/doc/R-1.7.1
cp: cannot stat `doc/manual/R-*.pdf': No such file or directory
error: Bad exit status from /var/tmp/rpm-tmp.78384 (%doc)
Processing files: R-debuginfo-1.7.1-1
+ cp -pr 'doc/manual/R-*.pdf' /var/tmp/R-root/usr/share/doc/R-1.7.1
cp: cannot stat `doc/manual/R-*.pdf': No such file or directory
error: Bad exit status from /var/tmp/rpm-tmp.78384 (%doc)
Processing files: R-debuginfo-1.7.1-1
Provides: KernSmooth.so.debug MASS.so.debug R_X11.so.debug class.so.debug
cluster.so.debug ctest.so.debug eda.so.debug foreign.so.debug
grid.so.debug internet.so.debug lapack.so.debug lattice.so.debug
libRlapack.so.debug lqs.so.debug methods.so.debug mgcv.so.debug
modreg.so.debug mva.so.debug nlme.so.debug nls.so.debug nnet.so.debug
rpart.so.debug spatial.so.debug splines.so.debug survival.so.debug
tools.so.debug ts.so.debug vfonts.so.debug
Requires(rpmlib): rpmlib(CompressedFileNames) <= 3.0.4-1
rpmlib(PayloadFilesHavePrefix) <= 4.0-1


RPM build errors:
    user martyn does not exist - using root
    user martyn does not exist - using root
    user martyn does not exist - using root
    Bad exit status from /var/tmp/rpm-tmp.78384 (%doc)

Thanks in advance.

Take care.

-Morgan



From Subramanian_Karthikeyan at hc-sc.gc.ca  Thu Sep 25 22:15:21 2003
From: Subramanian_Karthikeyan at hc-sc.gc.ca (Subramanian Karthikeyan)
Date: Thu, 25 Sep 2003 16:15:21 -0400
Subject: [R] splitting clusters
Message-ID: <OF31B1BAC8.71291EFE-ON85256DAC.006EDCC0@hc-sc.gc.ca>


I am really wondering if there is a way of exporting the names of the
samples/variables clustered within a dendrogram object into a TEXT file.
Any ideas?

Thanks,
Karthi.




                                                                                                                                       
                      "Liaw, Andy"                                                                                                     
                      <andy_liaw at merck.        To:       "'Subramanian Karthikeyan'" <Subramanian_Karthikeyan at hc-sc.gc.ca>             
                      com>                     cc:                                                                                     
                                               Subject:  RE: [R] splitting clusters                                                    
                      2003-09-25 03:10                                                                                                 
                      PM                                                                                                               
                                                                                                                                       
                                                                                                                                       




As Robert Gentleman pointed out to you on the BioC list, cutree() gives you
the cluster membership.

Andy

> -----Original Message-----
> From: Subramanian Karthikeyan
> [mailto:Subramanian_Karthikeyan at hc-sc.gc.ca]
> Sent: Thursday, September 25, 2003 1:10 PM
> To: Martin Maechler; r-help at stat.math.ethz.ch
> Subject: Re: [R] splitting clusters
>
>
>
> Thanks Martin,
>
> Cutting the dendrogram as you suggested solved the problem.   I have
> another question along the same lines... If samples x1, x2,
> y4,y5, z6 are clustered together, is there a way of
> extracting this information (i.e. name of the samples
> clustered together) and saving it in a file?
>
> Thanks again,
> Karthi.
>
>
>
>
>
>
>
>
>
>                       Martin Maechler
>
>
>                       <maechler at stat.ma        To:
> "Subramanian Karthikeyan"
> <Subramanian_Karthikeyan at hc-sc.gc.ca>
>                       th.ethz.ch>              cc:
> r-help at stat.math.ethz.ch
>
>                                                Subject:  Re:
> [R] splitting clusters
>
>                       2003-09-25 03:56
>
>
>                       AM
>
>
>                       Please respond to
>
>
>                       Martin Maechler
>
>
>
>
>
>
>
>
>
>
>
>
> >>>>> "KarthiS" == Subramanian Karthikeyan
> <Subramanian_Karthikeyan at hc-sc.gc.ca>
> >>>>>     on Wed, 24 Sep 2003 13:04:04 -0400 writes:
>
>     KarthiS> Hi All: I am clustering 500 genes using hclust of
>     KarthiS> R.  Visualizing cluster membership becomes
>     KarthiS> difficult with so many genes in each cluster...Is
>     KarthiS> there a way of printing the dendrogram in multiple
>     KarthiS> pages so that I can clearly see what is in each
>     KarthiS> cluster?
>
> - Use dd <- as.dendrogram(hc) on your hclust result `hc',
>   then dd[1] gives the first branch, dd[1][2] the 2nd sub-branch of
>   the first branch, etc., see the examples on
>   ?dendrogram.
>
> - The package "maptree" has also tools for this,
>   particularly  prune.clust()
>
>     KarthiS> Thanks in advance.
>
> you're welcome.
> --
> Martin Maechler <maechler at stat.math.ethz.ch>
> http://stat.ethz.ch/~maechler/
> Seminar fuer Statistik,
> ETH-Zentrum  LEO C16    Leonhardstr. 27
> ETH (Federal Inst. Technology)      8092 Zurich SWITZERLAND
> phone: x-41-1-632-3408        fax: ...-1228                 <><
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
>



From especiales at canaco.net  Thu Sep 25 22:07:01 2003
From: especiales at canaco.net (CART | canaco.net)
Date: Thu, 25 Sep 2003 15:07:01 -0500
Subject: [R] Vive al limite la Serie Cart ...
Message-ID: <1098262778-2200394252071420@canaco.net>


                             [1][USEMAP:03.jpg]
                   [2]Envía este boletín a un amigo AHORA
         Usted recibe esta publicación por que está suscrito a las
                        publicaciones de canaco.net
   La dirección a que le enviamos el mensaje es r-help at stat.math.ethz.ch,
    para dejar de recibir Boletines Especiales canaco.net [3]Click aquí
      Derechos Reservados © CANACO Monterrey, N.L., México 2000 - 2003

   [t.asp?S=2&ID=577&NL=8&N=619&Imp=True&SubscriberID=151453]

References

   1. LYNXIMGMAP:file://localhost/tmp/tmpVV9oqW.html#3
   2. http://www.canaco.net/enewsletterpro/members.asp?Task=FF&SubscriberID=151453&Email=r%2Dhelp%40stat%2Emath%2Eethz%2Ech&S=2&N=619&Format=HTML
   3. http://www.canaco.net/enewsletterpro/members.asp?Task=OptOut&SubscriberID=151453&Email=r%2Dhelp%40stat%2Emath%2Eethz%2Ech&S=2


From 239553 at yahoo.com  Fri Sep 26 13:14:50 2003
From: 239553 at yahoo.com (239553@yahoo.com)
Date: Fri, 26 Sep 2003 05:14:50 -0600
Subject: [R] ADD 3 INCHES IN LENGTH!       239553
Message-ID: <200309252112.h8PLCoDd005184@stat.math.ethz.ch>


                                The Facts...

        Before continuing, lets take a look at these sad, but true facts:
   The average erect penis size is just 6.16". Over 90 percent of all men
   posses this size. 85 percent of all men cannot have intercourse longer
   than 3 minutes, before ejaculating due to an underdeveloped and weak
   PC Muscle. 30 Million men in the USA alone suffer from Erectile
   Dysfunction (Impotence) The majority of men have very poor blood
   circulation to the penis. By age 29, 96 percent of men cannot gain
   erections 1/5 as much as when they were 20. Over 98 percent of men
   would increase the size of their penis if they knew how. 93 percent of
   Women have never achieved an orgasm during intercourse, and 76 percent
   admit that they are dissatisfied with their partners sexual
   performance.

             NO.1 Penis Enlargement Pill On The Market! 239553
                  * Gain 3+ Full Inches In Length 57393507
            * Expand Your Penis Up To 20 percent Thicker 239553
                  * Stop Premature Ejaculation! 274907948
                    * Produce Stronger Erections 239553
         * 100 percent Safe To Take, With No Side Effects 536326523
                    * Fast Distribution Worldwide 239553
                * Sold Over 1.2 Million Bottles! 1503380896
                * No Pumps! No Surgery! No Exercises! 239553
                        [1]Continue... -> 188805441
         [2]R'e'm'o'v'e' 'm'e' 'f'r'o'm' 't'h'i's 'l'i's't' 239553

   1304764598 1E5B4309-47391476-13271DED-38C93514-D946F2E 239553

References

   1. http://www.get-bigger.biz/eraser/vp/
   2. http://www.get-bigger.biz/eraser/out.html


From p.dalgaard at biostat.ku.dk  Thu Sep 25 23:16:02 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Thu, 25 Sep 2003 21:16:02 -0000
Subject: [R] rpmbuild of src.rpm error
In-Reply-To: <Pine.GSO.4.53.0309251231380.10239@itsa.ucsf.edu>
References: <Pine.GSO.4.53.0309251231380.10239@itsa.ucsf.edu>
Message-ID: <x28yoclgal.fsf@biostat.ku.dk>

Morgan Hough <mhough at itsa.ucsf.edu> writes:

> I received an error trying to build R-1.7.1-src.rpm on RH9.0.93 (Severn)
> and I was wondering if anybody could tell me what is going on with the
> manual error.

I'd look further up the log for an indication of whether the PDF
manuals got built at all. You do have all the TeX tools in place?
 
> + cp -pr 'doc/manual/R-*.pdf' /var/tmp/R-root/usr/share/doc/R-1.7.1
> cp: cannot stat `doc/manual/R-*.pdf': No such file or directory
> error: Bad exit status from /var/tmp/rpm-tmp.78384 (%doc)
> Processing files: R-debuginfo-1.7.1-1
> + cp -pr 'doc/manual/R-*.pdf' /var/tmp/R-root/usr/share/doc/R-1.7.1
> cp: cannot stat `doc/manual/R-*.pdf': No such file or directory
> error: Bad exit status from /var/tmp/rpm-tmp.78384 (%doc)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From garvin at cs.rice.edu  Thu Sep 25 23:37:57 2003
From: garvin at cs.rice.edu (John Garvin)
Date: Thu, 25 Sep 2003 16:37:57 -0500 (CDT)
Subject: [R] Re: Compiling shared library on Alpha/OSF1
In-Reply-To: <Pine.LNX.4.44.0309221747140.3970-100000@hpc3.cs.rice.edu>
Message-ID: <Pine.LNX.4.44.0309251637220.6384-100000@hpc3.cs.rice.edu>

Never mind my previous message. The problem turned out to be an unrelated 
misconfiguration.

Thank you!

John



From mrgoldgood at yahoo.com  Fri Sep 26 01:58:07 2003
From: mrgoldgood at yahoo.com (Dr.Muhammad Khalil)
Date: Thu, 25 Sep 2003 16:58:07 -0700 (PDT)
Subject: [R] Your message
Message-ID: <20030925235807.34294.qmail@web20702.mail.yahoo.com>

Dear Sir, 

Before I introduce myself, I wish to inform 
you that this letter is not a hoax mail and 
I urge you to treat it serious. We want to 
transfer to overseas account ($35,000.000.00 USD)
(Thirty Five Million United States Dollars) 
from a Standard Trust Bank Ltd here in Nigeria,
I want to ask you, If you are not capable to 
quietly look for a reliable and honest person who 
will be capable and fit to provide either an 
existing bank account or to set up a new Bank a/c
immediately to receive this money, even an 
empty a/c can serve to receive this money, as long 
as you will remain honest to me till the end for 
this important business trusting in you and 
believing in God that you will never let me down
either now or in future.  

I am Dr. Muhammad Khalil Hasan, the Auditor General 
of Standard Trust Bank Ltd here in Nigeria.  During
the course of our auditing, I discovered a floating 
fund in an account opened in the bank in 1996 and
since 1998 nobody has operated on this account
again,after going through some old files in the 
records I discovered that the owner of the account
died without a [Heir/WILL] hence the money is floating
and if I do not remit this money out urgently it will
be forfeited for nothing. The owner of this account 
is Mr. Robert Chapman a Canadia and great
industrialist.  He was African Area Director of SIL
International, who unfortunately died in the plane
crash of Kenya Airways Flight 431 in Abidjan, Ivory
Coast, January 30 2000. 
You will read more stories about the crash on 
visiting this website,
news.airwise.com/airlines/archive/2 000/kenya2000.html
and also in this 
website, www.sil.org/sil/news/2000/chapman1.html 
where Chapman's company talked about his death in 
the Kenya crash. You shall as well find the pictures
of Chapman and his wife there.   

No other person knows about this account or any thing
concerning it, the account has no other beneficiary
and my investigation proved to me as well that until 
his death he has a Gold/Diamond Consulting firm. 
I also found out that their only surviving daughter
died last year. 

The total amount involve is ($35,000.000.00 USD) 
(Thirty Five Million United States Dollars) and we
wish to transfer this money into a safe foreigners
account abroad. But I don't know any foreigner, 
I am only contacting you as a foreigner because this
money can not be approved to a local person here, but
to a foreigner who has information about the account,
which I shall give to you upon your positive response.

I am revealing this to you with believe in God that
you will never let me down in this business, you are
the first and the only person that I am contacting for
this business, so please reply urgently so that I will
inform you the next step to take urgently.  
 
I need your strong assurance that you will never let
us down, me and a key bank official who is deeply
involved with me in this business.  I guarantee 
that this transaction will be executed under a
legitimate arrangement that will protect you from any
breach of the law.  The bank official Will destroy 
all documents of transaction immediately we receive
this money leaving no trace to any place.  I will use
my position and influence to obtain all legal 
approvals for onward transfer of this money to your
account with appropriate clearance from the relevant
ministries and foreign exchange departments.

At the conclusion of this business, you will be given
40% of the total amount, 60% will be for us, I look
forward to your earliest reply. 
 
PLEASE, TREAT THIS PROPOSAL AS TOP SECRET. 

Find in the attachment my INTERNATIONAL PASSPORT, to
proof 
who I am.

Best Regards 

Dr. Muhammad Khalil Hasan.



From johnaku_1 at hknetmail.com  Thu Sep 25 14:06:45 2003
From: johnaku_1 at hknetmail.com (JOHN AKU)
Date: Thu, 25 Sep 2003 13:06:45 +0100
Subject: [R] NEXT OF KIN
Message-ID: <200309260003.h8Q03SDd010183@stat.math.ethz.ch>

I am a Nigerian, 26years in possession of my dad's properties.I lost him in 
a plane crash.He was the Minister for sport here in Nigeria
before he died .Since then I have been in charge of his business and I have 
got no problem with that since I have been doing that before
his death.I received a letter from his bank notifying me of his account in 
one of the FINANACE HOUSE IN EUROPE that worth 47.5 Million dollars which he got from
 Shell petroleum development company(SPDC)and chevron oil company operating
 in our locality for the compensation of youth sport and community development.
As a result of this notification I  have wrote a letter through my Lawyer 
to the bank that i want to tranfer the money to OVERSEA for investment, in which I have successfully 
carried out in the last two month. Since I am his next of kin ,it was so easy for
me in writing this letter  without the knowledge of my family members .I want to try as much
as possible to transfer this money out from  the bank to any faithfull man or woman account in ABROAD.
I know that this issue is a very sensitive one and it should not be discuss 
on the net. Why dont you send me your phone # and your Fax # ? so that, I will  get
in touch with you .This deal is a risk free one and your gain shall be 30% of this
money provided you co-operate with me .Remember not to tell anybody about this deal
because my daddy happens to be very popular person, even after his death.
What i need from you is your honest and your nominated account and the money will be transfer to your account from the bank
without leaving your country, but i need God fear person, who can keep the money for me and invest it.

Take care of yourself.
JOHN  AKU



From PRSC2_36.Xunta at xunta.es  Fri Sep 26 02:09:11 2003
From: PRSC2_36.Xunta at xunta.es (PRSC2_36.Xunta@xunta.es)
Date: Fri, 26 Sep 2003 02:09:11 +0200
Subject: [R] Informar al destinatario
Message-ID: <OF65A8A953.086F772B-ONC1256DAD.0000D782@xunta.es>

Informaci?n de incidente:-
Originador: r-help-bounces at stat.math.ethz.ch
Destinatarios:    r-help at stat.math.ethz.ch
Asunto:     [R] Your message

El mensaje de r-help-bounces at stat.math.ethz.ch se ha puesto en cuarentena
porque incluye contenido prohibido.



From lawanda.lewishn at criticalpath.net  Fri Sep 26 17:34:36 2003
From: lawanda.lewishn at criticalpath.net (Lawanda Lewis)
Date: Fri, 26 Sep 2003 15:34:36 +0000
Subject: [R] SPY on ANYONE by simply sending an E-Greeting Card! k
	ox2u7l1c7w3
Message-ID: <15cb01c38443$56685b49$b1f5d8e6@thb99t3>


                              Spy on Anyone by
                    sending them an Email-Greeting Card!

   Spy Software records their emails, Hotmail, Yahoo, Outlook, ACTUAL
   Computer Passwords, Chats, Keystrokes, PLUS MORE..

                Check up on your SPOUSE, KIDS, or EMPLOYEES!
                      [1]Follow This Link To Begin...

                   [2]Cease all future prommo material..

References

   1. http://www.goohle.us/index.php?afil=1025
   2. http://www.goohle.us/lsgone.php


From feh3k at spamcop.net  Thu Sep 25 13:48:31 2003
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Thu, 25 Sep 2003 13:48:31 +0200
Subject: [R] PlotMoth Refusing to Draw xlab
Message-ID: <20030925134831.689c2873.feh3k@spamcop.net>

Occasionally I have had plotmath refuse to draw x-axis labels.  This has happened when the label, created using expression(paste( ) ) as below, could be drawn easily in the available space.  I have not reproduced that, but the following example with a clearly overly long label results in no xlab at all.  I hoped that at least a truncated label would be plotted.  This is probably related to my original problem.


plot(0,0,xlab=expression(paste('1234567890abcdefghijklmnopqrstuvwzyz abcdefghijklmnopqrstuvwxyz ABCDEFGHIJKLMNOPARSTUVWXYZ')))

platform i386-pc-linux-gnu
arch     i386             
os       linux-gnu        
system   i386, linux-gnu  
status                    
major    1                
minor    7.1              
year     2003             
month    06               
day      16               
language R                

Thanks for any assistance  -Frank
---
Frank E Harrell Jr    Professor and Chair            School of Medicine
                      Department of Biostatistics    Vanderbilt University



From chiratoi at yahoo.ca  Fri Sep 26 01:58:14 2003
From: chiratoi at yahoo.ca (emelina payne)
Date: Fri, 26 Sep 2003 00:58:14 +0100
Subject: [R] Lucrative Career Opportunity
Message-ID: <20b101c383c0$e1db21e0$31d82498@anmrdhtq>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030926/7d352835/attachment.pl

From ihaka at stat.auckland.ac.nz  Fri Sep 26 05:23:42 2003
From: ihaka at stat.auckland.ac.nz (Ross Ihaka)
Date: Fri, 26 Sep 2003 15:23:42 +1200
Subject: [R] PlotMoth Refusing to Draw xlab
References: <20030925134831.689c2873.feh3k@spamcop.net>
Message-ID: <3F73B13E.1050001@stat.auckland.ac.nz>

Frank E Harrell Jr wrote:
> Occasionally I have had plotmath refuse to draw x-axis labels.  This has happened when the label, created using expression(paste( ) ) as below, could be drawn easily in the available space.  I have not reproduced that, but the following example with a clearly overly long label results in no xlab at all.  I hoped that at least a truncated label would be plotted.  This is probably related to my original problem.
> 
> 
> plot(0,0,xlab=expression(paste('1234567890abcdefghijklmnopqrstuvwzyz abcdefghijklmnopqrstuvwxyz ABCDEFGHIJKLMNOPARSTUVWXYZ')))
> 
> platform i386-pc-linux-gnu
> arch     i386             
> os       linux-gnu        
> system   i386, linux-gnu  
> status                    
> major    1                
> minor    7.1              
> year     2003             
> month    06               
> day      16               
> language R                
> 
> Thanks for any assistance  -Frank

I believe this is a clipping problem.  Strings placed outside the device 
area are clipped (this is to nasty avoid problems with some devices).
This means discarding the entire string.  Plain text strings and
expressions are handled differently in this regard, but there will be
a unification of this in the near future and that may be the time to
address it.

The only work around I can suggest is using larger margins.


-- 
Ross Ihaka                         Email:  ihaka at stat.auckland.ac.nz
Department of Statistics           Phone:  (64-9) 373-7599 x 85054
University of Auckland             Fax:    (64-9) 373-7018
Private Bag 92019, Auckland
New Zealand



From dr_j_s_eddy1 at tiscali.co.uk  Fri Sep 26 14:39:29 2003
From: dr_j_s_eddy1 at tiscali.co.uk (DR  JOSEPH  EDWARD)
Date: Fri, 26 Sep 2003 05:39:29 -0700
Subject: [R] MY SINCERE REQUEST!!
Message-ID: <E1A2kTI-0002hN-00@bernie.ethz.ch>

DR  JOSEPH  EDWARD,

BRANCH MANAGER,
UNITED BANK FOR AFRICA PLC,
ILUPEJU BRANCH,
LAGOS NIGERIA .
ATTN: PRESIDENT/C.E.O.
               
I am pleased to get across to you for a very urgent and profitable business proposal, though I don't know you neither have I seen you before but my confidence was reposed on you when the Chief Executive of Lagos State chamber of Commerce and Industry handed me your contact for a confidential business.

 I am the manager of United Bank for Africa Plc (UBA),Ilupeju branch,  Lagos Nigeria.The intended business is thus; We had a customer, a Foreigner (a Turkish) resident in Nigeria, he was a Contractor with one of the Government Parastatals.He has in his Account in my branch the sum of US 38.6  Million
(Thirty Eight Million, Six Hundred Thousand U.S. Dollars). Unfortunately, the man died four years ago until today non-of his next of kin has come forward to claim the money. Having noticed this, I in collaboration  with two other top Officials of the bank have covered up the account all this while.

Now we want you (being a foreigner) to be fronted as one of his next of  kin and forward your account and other relevant documents to be advised to  you by us to attest to the Claim.  We will use our positions to get all  internal documentations to back up the claims .The whole procedures will last  only five working days to get the fund retrieved successfully without t! race even now or in future. Your response is only what we are waiting for as we have arranged all  necessary things. As soon as this message comes to you kindly get back to me indicating your interest,  then I will furnish you with the whole procedures to ensure that the deal is successfully concluded. 

 For your assistance we have agreed to give you twenty five percent  (25%) ofthe Total sum at the end of the transaction while 65% would be for my colleagues and I and the remaining 10% would be for any form of expenses that may be incurred during the course of the transaction which would  be given to us when the money is transferred into your account before  splitting the balance on the agreed percentage of 65% to 25%. 
I await your earliest response.  
Thanks, 
Yours Sincerely
DR  JOSEPH  EDWARD.

N.B. Please if you are interested indicate your telephone, fax numbers and your contact address for easy communication in this mutual transaction.



From ok at cs.otago.ac.nz  Fri Sep 26 08:30:00 2003
From: ok at cs.otago.ac.nz (Richard A. O'Keefe)
Date: Fri, 26 Sep 2003 18:30:00 +1200 (NZST)
Subject: [R] Diamond graphs, again.
Message-ID: <200309260630.h8Q6U0aJ494811@atlas.otago.ac.nz>

I have now obtained copies of all three medical papers that
the "Diamond Graphs" article based its examples on.

Figures 4 and 5: "Blood Pressure and End-Stage Renal Disease in Men".

    The two predictor variables (systolic and disastolic blood pressure)
    are not only continuous, they are correlated.  Recoding as some kind
    of "size" (c1.diastolic + c2.systolic) and "shape" (maybe
    log(systolic/diastolic) might have been interesting.
    
    The real summary that I think anyone reading that paper would rely
    on is not the 3d bar chart (figure 2) but a table (table 3) which
    relates blood pressure category (optimal, normal, high-normal,
    stage 1/2/3/4 hypertension) to adjusted relative risk (with 95%
    confidence interval).

    Reading the article, other (listed) factors also affected relative
    risk, and it could have been useful to present some kind of multi-
    dimensional table.

    Comparing the original 3d bar plot and table with the diamond graph,
    two things stand out:
    (a) the higher the bar (= the bigger the hexagon), the *less* the
        amount of data it is based on.  This can be seen very clearly
        in the table; it cannot be seen at all in either the bar plot
        or the diamond graph.  If I'm reading the article correctly
        (hard, because the table and 3d bar plot don't use exactly the
        same categories), the lowest bar is based on 40 times as muh
        data as the highest bar (and the relative risk has a suitably
        wide confidence interval).
    (b) one would expect the risk to increase monotonically with
        each predictor.  It doesn't.  This stands out very clearly
        in the 3d bar plot.  It is very hard to see at all in the
        diamond graph.  Once I saw it in the 3d plot, I could (just)
        detect it in the diamond graph, but the diamond graph would
        never have called my attention to it.

    In fairness to both the 3d bar plot and the diamond graph, they
    _could_ be made to show an equivalent of error bars.  Let the
    bar (or hexagon) be coloured black from 0 to the lower end-point
    of the confidence interval, then red (if colour is desired) or
    grey (if it is not) from the lower end-point of the confidence
    interval to the upper end-point, with a "black belt" at the nominal
    value.

    [Oh DRAT!  I could have patented that extension to diamond graphs!
     Tsk tsk.  I'll never get rich, I'll always be 'ard up.]

Figure 7:  "Dual Effects of Weight and Weight Gain on Breast Cancer Risk".

    In my previous message, I commented that I found it hard to believe
    that weight *change* should be considered alone.  It wasn't.  In fact,
    that's part of the point of the article.

    I also commented that it seemed to me that the one categorical
    predictor was probably a surrogate for a continuous variable.
    Imagine me slapping my head and saying "but I _knew_ that!"

    The explanation is in the editor's comment, not cited in the Diamond
    Graphs paper, so here it is:
	Editorial, "Weight and Risk for Breast Cancer",
	Jennifer L. Kelsey & John Baron,
	JAMA, November 5, 19997--Vol 278, No.17
    The point is that weight and hormone treatment are *both* surrogates
    for "lifetime estrogen dose profile".  In post-menopausal women,
    female hormones _are_ still produced, in fat (which is an active
    tissue).  I _knew_ that.  So in fact there is a _single_ explanatory
    variable (some kind of weighted cumulative exposure) which both
    hormone therapy and body mass index affect.  This raises the obvious
    point that adding a third predictor (typical hormone levels during
    years of fertility) might well be very informative.  But how would
    diamond graphs cope with that?

    But wait:  the abstract says "Higher [body mass index] was associated
    with LOWER breast cancer incidence before menopause" but a "positive
    relationship was seen among postmenopausal women who had never used
    hormone replacement".  It also says "Weight gain after the age of 18
    years was UNRELATED to breast cancer incidence before menopause but
    was POSITIVELY associated with indicence after menopause".  The
    editorial cited above makes this point also.

    That is, in order to see the results of that study, you need a
    display which
	- shows weight
	- shows weight change
	- shows hormone therapy use
	- distinguishes between breast cancer before menopause
	  and breast cancer after menopause.

    The first sentence in the body of the paper is "The relation of
    body weight to breast cancer is complex."

    If there is an easy way to produce an "equiponderant display" with
    three predictors on a two-dimensional piece of paper, I do not know
    what it may be.  It's certain that diamond graphs, as described in
    the TAS article, cannot do justice to the data from this study.

    In contrast, the tables in the paper made the difference between    
    pre- and post-menopausal outcomes clear, and above all, included
    confidence intervals.  Why do the confidence intervals matter?
    Well, table 2 of the paper shows that the "multivariate-adjusted
    relative risk" confidence intervals for premenopausal women all
    contain 1 (with a fairly high p for trend), so there _might_ not,
    on this evidence, be any effect at all, while the relative risk
    confidence intervals for postmenopausal women all contain 1 except
    for gains of 20kg or more (where the relative risk could be as low
    as 1.2).  Since the study was based on 1000 premenopausal women and
    1517 postmenopausal ones, while the effect is biologically plausible,
    it doesn't appear to be anywhere near as strong as one might fear.

    Once again, BOTH 3d bar plots AND diamond graphs are at fault for
    not giving any indication of variability/noise/error bars/...,
    and BOTH could be fiddled with to improve this.  In this case,
    it is quite impossible to see from the diamond graphs in figure
    7 of the TAS article what is quite clear from the tables in the
    original source.


My background is AI, not medicine, so I came to these articles with a
"machine learning" bias.  I was expecting to see models trained on a
subset of the data and evaluated on another subset (cross-validation).
None of them did.  One of the many things to like about R that R makes
it comparatively easy to do cross-validation.

What have we seen as common themes?

1.  The so-called "categorical" variables were (in 5 out of 6 cases)
    measured as continuous variables and then cut to quartiles or
    quintiles or the like.

2.  More explanatory variables than 2 were considered in the sources,
    and in each case more than 2 were actually important or at least useful.

3.  Presenting information without "error bars" can be seriously misleading.

How does R help?

1.  R lets us do scatter plots, smoothing, density estimation, &c.

2.  R gives us "lattice" plots, amongst others.

3.  We can construct graphs with error bars in R.

The big challenge seems to be graphical presentation of higher-
dimensional data, things like spinning plots, grand tours, &c.
And for that, there's Rgobi.



From maechler at stat.math.ethz.ch  Fri Sep 26 08:50:23 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 26 Sep 2003 08:50:23 +0200
Subject: [R] Spam-Filter @stat.math.ethz.ch: was dead for about 15 hours
Message-ID: <16243.57775.113817.50225@gargle.gargle.HOWL>

As many of you have probably realized, the spam filtering
at @stat.math.ethz.ch  has been dead for since yesterday (09-25)
~16:50 till today ~08:30.

The sudden death may have been caused by unrelated installation
of some perl modules (spamassassin *is* running on perl) by our
IT staff.
We are very sorry for this event.

On the bright side: You have been able to get a glimpse of what
you are usually protected from... :-)

Regards,
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From Friedrich.Leisch at ci.tuwien.ac.at  Fri Sep 26 09:42:49 2003
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Fri, 26 Sep 2003 09:42:49 +0200
Subject: [R] allShortestPath function in e1071 package
In-Reply-To: <3F6BC0CC@webmail1>
References: <3F6BC0CC@webmail1>
Message-ID: <16243.60921.78478.210173@galadriel.ci.tuwien.ac.at>

>>>>> On Thu, 25 Sep 2003 13:04:21 -0400,
>>>>> Bing Zhang (BZ) wrote:

  > Hi All,
  > I am using the allShortestPath function based on Floyd's algorithm in e1071 
  > package. It runs great when I have less than 5000 nodes. But when I tried to 
  > work on more than 5000 nodes, I ran into memory problem. The problem I really 
  > want to solve has 10000-15000 nodes.

  > Does anybody know how to deal with this problem? Are there any other packages 
  > in R that can handle this problem? Thanks!

The e1071 implementation uses NxN matrices (where N is the number of
nodes), hence it does not scale well with the number of nodes as
memory consumption is N^2.

>From Bioconductor you get package graph which represent the graph
using lists of nedges and edges, and needs much fewer memeory if the
graphs is sparsely connected. Package RBGL (also from Bioconductor)
has shortest paths for such graph objects.

.f



From lehmann at puk.unibe.ch  Fri Sep 26 10:32:05 2003
From: lehmann at puk.unibe.ch (Christoph Lehmann)
Date: Fri, 26 Sep 2003 10:32:05 +0200
Subject: [R] overlay two pixmap
Message-ID: <1064565125.1123.9.camel@christophl>

Hi

I need to overlay two pixmaps (library (pixmap)). One, a pixmapGrey, is
the basis, and on this I need to overlay a pixmapIndexed, BUT: the
pixmapIndexed has set only some of its "pixels" to an indexed color,
many of its pixels should not cover the basis pixmapGrey pixel, means,
for this "in pixmapIndexed not defined pixels" it should be transparent.

What would you recommend me to do? Should I go for another solution than
pixmap?

Many thanks

Cheers

Christoph

-- 
Christoph Lehmann <lehmann at puk.unibe.ch>
University Hospital of Clinical Psychiatry



From christoph.lehmann at gmx.ch  Fri Sep 26 10:32:21 2003
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Fri, 26 Sep 2003 10:32:21 +0200
Subject: [R] overlay two pixmap
Message-ID: <1064565140.1123.12.camel@christophl>

Hi

I need to overlay two pixmaps (library (pixmap)). One, a pixmapGrey, is
the basis, and on this I need to overlay a pixmapIndexed, BUT: the
pixmapIndexed has set only some of its "pixels" to an indexed color,
many of its pixels should not cover the basis pixmapGrey pixel, means,
for this "in pixmapIndexed not defined pixels" it should be transparent.

What would you recommend me to do? Should I go for another solution than
pixmap?

Many thanks

Cheers

Christoph

-- 
Christoph Lehmann <lehmann at puk.unibe.ch>
University Hospital of Clinical Psychiatry
-- 
Christoph Lehmann <christoph.lehmann at gmx.ch>



From ernesto at ipimar.pt  Fri Sep 26 11:16:00 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Fri, 26 Sep 2003 10:16:00 +0100
Subject: [R] Spam-Filter @stat.math.ethz.ch: was dead for about 15 hours
In-Reply-To: <16243.57775.113817.50225@gargle.gargle.HOWL>
References: <16243.57775.113817.50225@gargle.gargle.HOWL>
Message-ID: <1064567760.18005.1.camel@gandalf.local>

On Fri, 2003-09-26 at 07:50, Martin Maechler wrote:
> As many of you have probably realized, the spam filtering
> at @stat.math.ethz.ch  has been dead for since yesterday (09-25)
> ~16:50 till today ~08:30.
> 
> The sudden death may have been caused by unrelated installation
> of some perl modules (spamassassin *is* running on perl) by our
> IT staff.
> We are very sorry for this event.
> 
> On the bright side: You have been able to get a glimpse of what
> you are usually protected from... :-)
> 
> Regards,
> Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
> Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
> ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
> phone: x-41-1-632-3408		fax: ...-1228			<><
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

Hi,

I've never imagined this was so bad ....

Thanks for protecting the Mailing List.

Regards

EJ



From laurent.faisnel at ariase.com  Fri Sep 26 12:04:41 2003
From: laurent.faisnel at ariase.com (Laurent Faisnel)
Date: Fri, 26 Sep 2003 12:04:41 +0200
Subject: [R] installation : make fails (R-1.7.1 on RedHat 8.0)
Message-ID: <3F740F39.7010904@ariase.com>

Hi,

I'm trying to compile R-1.7.1 from source (on a RedHat 8.0) instead of 
using the binary version, as it has often been advised.
However I don't manage to find a solution to the following error which 
occurs during the make procedure :

/!\-------------------------------------------/!\

building package 'ctest'
mkdir -p -- ../../../library/ctest/R
mkdir -p -- ../../../library/ctest/man
make[4]: Entre dans le r?pertoire `/usr/local/R-1.7.1/src/library/ctest/src'
making ansari.d from ansari.c
gcc: /usr/include/mysql: fichier d'entr?e d'?dition de liens n'est pas 
utilis? parce l'?dition de lien n'a pas ?t? faite
making chisqsim.d from chisqsim.c
gcc: /usr/include/mysql: fichier d'entr?e d'?dition de liens n'est pas 
utilis? parce l'?dition de lien n'a pas ?t? faite
making d2x2xk.d from d2x2xk.c
gcc: /usr/include/mysql: fichier d'entr?e d'?dition de liens n'est pas 
utilis? parce l'?dition de lien n'a pas ?t? faite
making fexact.d from fexact.c
gcc: /usr/include/mysql: fichier d'entr?e d'?dition de liens n'est pas 
utilis? parce l'?dition de lien n'a pas ?t? faite
making kendall.d from kendall.c
gcc: /usr/include/mysql: fichier d'entr?e d'?dition de liens n'est pas 
utilis? parce l'?dition de lien n'a pas ?t? faite
making ks.d from ks.c
gcc: /usr/include/mysql: fichier d'entr?e d'?dition de liens n'est pas 
utilis? parce l'?dition de lien n'a pas ?t? faite
making prho.d from prho.c
gcc: /usr/include/mysql: fichier d'entr?e d'?dition de liens n'est pas 
utilis? parce l'?dition de lien n'a pas ?t? faite
making swilk.d from swilk.c
gcc: /usr/include/mysql: fichier d'entr?e d'?dition de liens n'est pas 
utilis? parce l'?dition de lien n'a pas ?t? faite
making init.d from init.c
gcc: /usr/include/mysql: fichier d'entr?e d'?dition de liens n'est pas 
utilis? parce l'?dition de lien n'a pas ?t? faite
make[5]: Entre dans le r?pertoire `/usr/local/R-1.7.1/src/library/ctest/src'
make[5]: `Makedeps' est ? jour.
make[5]: Quitte le r?pertoire `/usr/local/R-1.7.1/src/library/ctest/src'
make[5]: Entre dans le r?pertoire `/usr/local/R-1.7.1/src/library/ctest/src'
gcc -I../../../../include /usr/include/mysql  -D__NO_MATH_INLINES 
-mieee-fp  -fPIC  -g -O2 -c ansari.c -o ansari.o
gcc: ne peut sp?cifier -o avec -c ou -S et de multiples compilations
make[5]: *** [ansari.o] Erreur 1
make[5]: Quitte le r?pertoire `/usr/local/R-1.7.1/src/library/ctest/src'
make[4]: *** [all] Erreur 2
make[4]: Quitte le r?pertoire `/usr/local/R-1.7.1/src/library/ctest/src'
make[3]: *** [all] Erreur 1
make[3]: Quitte le r?pertoire `/usr/local/R-1.7.1/src/library/ctest'
make[2]: *** [R] Erreur 1
make[2]: Quitte le r?pertoire `/usr/local/R-1.7.1/src/library'
make[1]: *** [R] Erreur 1
make[1]: Quitte le r?pertoire `/usr/local/R-1.7.1/src'
make: *** [R] Erreur 1

--------------------------

The problem seems to be related to package ctest (see also problem to 
make ansari.d from ansari.c). There also seems to be trouble with mysql, 
as if links should have been created (or are there paths to specify at 
that step ?).

Any help on this would be greatly appreciated.

Regards,
Laurent



From harald.bartel at prozentor.de  Fri Sep 26 12:06:15 2003
From: harald.bartel at prozentor.de (Harald Bartel)
Date: Fri, 26 Sep 2003 12:06:15 +0200
Subject: [R] least squares regression using (inequality) restrictions
Message-ID: <3F740F97.9090305@prozentor.de>

Dear R Users,

I would like to make a lesast squares regression similar to that what is 
done by the command "lm". But additionally, I would like to impose some 
restrictions:
1) The sum of all regression coefficients should be equal to 1.
2) Each coefficient should assume a value between 0 and 1. (inequality 
restrictions)

Which command is the best to use in order to solve this problem in a 
computationally efficient way?

Thank you in advance for your help,
Harald Bartel

-- 
------------------------------------------------------
PROZENTOR GmbH
Financial Content Provider
Bergstr. 67
10115 Berlin

Fon: +49 (0) 30 28 44 59-42
Fax: +49 (0) 30 28 44 59-59

email: harald.bartel at prozentor.de

PROZENTOR GmbH: http://www.prozentor.de
kostenlose Aktienprognosen: http://www.happyYuppie.com



From elsawy at ysbl.york.ac.uk  Fri Sep 26 12:16:14 2003
From: elsawy at ysbl.york.ac.uk (Karim Elsawy)
Date: Fri, 26 Sep 2003 11:16:14 +0100
Subject: [R] 3d contours
Message-ID: <3F7411EE.8A98D702@ysbl.york.ac.uk>

Hi,
I wonder if there is any R package or function which produces the
coordinates of a 3d contour (isosurface) 
from a 3d data array.
any suggestions are very much appreciated
best regards
karim



From Roger.Bivand at nhh.no  Fri Sep 26 12:44:35 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 26 Sep 2003 12:44:35 +0200 (CEST)
Subject: [R] overlay two pixmap
Message-ID: <Pine.LNX.4.44.0309261231300.24559-100000@reclus.nhh.no>

Christoph Lehmann wrote:

> I need to overlay two pixmaps (library (pixmap)). One, a pixmapGrey, is
> the basis, and on this I need to overlay a pixmapIndexed, BUT: the
> pixmapIndexed has set only some of its "pixels" to an indexed color,
> many of its pixels should not cover the basis pixmapGrey pixel, means,
> for this "in pixmapIndexed not defined pixels" it should be transparent.

> What would you recommend me to do? Should I go for another solution than
> pixmap?

Determine which of the indexed colours in the pixmapIndexed object are to 
be transparent, and change them to NA - you access them in say:

library(pixmap)
x <- read.pnm(system.file("pictures/logo.ppm", package = "pixmap")[1])
x
plot(x)
xx <- as(x, "pixmapIndexed")
xx
plot(xx)
example(pixmap)
z <- pixmapRGB(c(z1, z2, z3), 100, 100, bbox = c(0, 0, 100, 100))
plot(z)
xx at col[1:20]
xx at col[1] <- NA
plot(xx, add=T)

Here xx at col[1] was "white" aka "#FFFFFF", you could use col2rgb() to help 
set thresholds. Admittedly, this is messy if you don't know your 
threshold.

Roger

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From simon at stats.gla.ac.uk  Fri Sep 26 12:51:12 2003
From: simon at stats.gla.ac.uk (Simon Wood)
Date: Fri, 26 Sep 2003 11:51:12 +0100 (BST)
Subject: [R] least squares regression using (inequality) restrictions
In-Reply-To: <3F740F97.9090305@prozentor.de>
References: <3F740F97.9090305@prozentor.de>
Message-ID: <Pine.SOL.4.58.0309261146250.7428@moon.stats.gla.ac.uk>

> I would like to make a lesast squares regression similar to that what
is
> done by the command "lm". But additionally, I would like to impose some
> restrictions:
> 1) The sum of all regression coefficients should be equal to 1.
> 2) Each coefficient should assume a value between 0 and 1. (inequality
> restrictions)
>
> Which command is the best to use in order to solve this problem in a
> computationally efficient way?
- I don't know if it's the best way, but pcls() in package mgcv will do
this for you. It solves penalized least squares problems subject to linear
equality and inequality constraints by  quadratic programming (uses a
least squares specific method rather than a general QP method). It's
less easy to use than lm, but not too bad --- see the first example in
?pcls.

Simon
_____________________________________________________________________
> Simon Wood simon at stats.gla.ac.uk        www.stats.gla.ac.uk/~simon/
>>  Department of Statistics, University of Glasgow, Glasgow, G12 8QQ
>>>   Direct telephone: (0)141 330 4530          Fax: (0)141 330 4814



From Friedrich.Leisch at ci.tuwien.ac.at  Fri Sep 26 13:32:32 2003
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Fri, 26 Sep 2003 13:32:32 +0200
Subject: [R] overlay two pixmap
In-Reply-To: <1064565140.1123.12.camel@christophl>
References: <1064565140.1123.12.camel@christophl>
Message-ID: <16244.9168.557624.164278@galadriel.ci.tuwien.ac.at>

>>>>> On Fri, 26 Sep 2003 10:32:21 +0200,
>>>>> Christoph Lehmann (CL) wrote:

  > Hi
  > I need to overlay two pixmaps (library (pixmap)). One, a pixmapGrey, is
  > the basis, and on this I need to overlay a pixmapIndexed, BUT: the
  > pixmapIndexed has set only some of its "pixels" to an indexed color,
  > many of its pixels should not cover the basis pixmapGrey pixel, means,
  > for this "in pixmapIndexed not defined pixels" it should be transparent.

  > What would you recommend me to do? Should I go for another solution than
  > pixmap?

There is no method for doing this in pixmap yet ... but if you write
one (shouldn't be too much code) I'd be happy to include it in the
package such that others can use it in the future.

-- 
-------------------------------------------------------------------
                        Friedrich Leisch 
Institut f?r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit?t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra?e 8-10/1071      Friedrich.Leisch at ci.tuwien.ac.at
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch



From p.dalgaard at biostat.ku.dk  Fri Sep 26 13:32:31 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri, 26 Sep 2003 11:32:31 -0000
Subject: [R] installation : make fails (R-1.7.1 on RedHat 8.0)
In-Reply-To: <3F740F39.7010904@ariase.com>
References: <3F740F39.7010904@ariase.com>
Message-ID: <x2u16zrdhi.fsf@biostat.ku.dk>

Laurent Faisnel <laurent.faisnel at ariase.com> writes:

> Hi,
> 
> I'm trying to compile R-1.7.1 from source (on a RedHat 8.0) instead of
> using the binary version, as it has often been advised.
> However I don't manage to find a solution to the following error which
> occurs during the make procedure :


> gcc -I../../../../include /usr/include/mysql  -D__NO_MATH_INLINES
                            ******************
> -mieee-fp  -fPIC  -g -O2 -c ansari.c -o ansari.o


The stars indicate the problem. This wants to -I/usr/include/mysql if
anything, otherwise gcc will believe that there are two files to
compile and complain about the -o. I suspect that you entered the
wrong thing during configuration.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From egert at inf.uni-konstanz.de  Fri Sep 26 14:26:07 2003
From: egert at inf.uni-konstanz.de (Bjoern Egert)
Date: Fri, 26 Sep 2003 14:26:07 +0200
Subject: [R] Gaussian mixture models, modelNames: EEV, VEV mclust2002
Message-ID: <000401c38429$5c9c7970$1400a8c0@sam>

Hello,

I am using the parameterized EM- Algorithm in clustering context.
I use generated datasets, containing 5000 points in 20 dimensions with 5
clusters.
The following poses a problem for me:



   emEst<-me(modelName="EEV",data=data[,1:numDimensions],z=unmap(x))    
   emEst<-me(modelName="VEV",data=data[,1:numDimensions],z=unmap(x))  
   coordProj(main="Model
EEV",data,dimens=c(1,2),type="classification",ask=F,mu=emEst$mu,sigma=em
Est$sigma,z=emEst$z)      
   coordProj(main="Model
EEV",data,dimens=c(1,2),type="classification",ask=F,mu=emEst$mu,sigma=em
Est$sigma,z=emEst$z) 



For these two Models, neither the constraint "E" f?r equal shape, nor
the constraint "E" for equal Volume seems to have any impact on the
model. In contrast, for all other models, the constraints apply fine...


How is this to be explained ?

Thanks a lot
Best regards
Bjoern



From laurent.faisnel at ariase.com  Fri Sep 26 14:51:09 2003
From: laurent.faisnel at ariase.com (Laurent Faisnel)
Date: Fri, 26 Sep 2003 14:51:09 +0200
Subject: [R] installation : make fails (R-1.7.1 on RedHat 8.0)
References: <3F740F39.7010904@ariase.com> <x2u16zrdhi.fsf@biostat.ku.dk>
Message-ID: <3F74363D.40807@ariase.com>

Peter Dalgaard BSA wrote:
> Laurent Faisnel <laurent.faisnel at ariase.com> writes:
> 
> 
>>Hi,
>>
>>I'm trying to compile R-1.7.1 from source (on a RedHat 8.0) instead of
>>using the binary version, as it has often been advised.
>>However I don't manage to find a solution to the following error which
>>occurs during the make procedure :
> 
> 
> 
>>gcc -I../../../../include /usr/include/mysql  -D__NO_MATH_INLINES
> 
>                             ******************
> 
>>-mieee-fp  -fPIC  -g -O2 -c ansari.c -o ansari.o
> 
> 
> 
> The stars indicate the problem. This wants to -I/usr/include/mysql if
> anything, otherwise gcc will believe that there are two files to
> compile and complain about the -o. I suspect that you entered the
> wrong thing during configuration.
> 

Peter,
Thanks for your answer, but everything is not clear to me. This 
installation was made with the default ./configure without any 
additional option (so if I made something wrong, it is to forget an 
option). I checked out ./configure --help.
What should I add ? I don't believe there are headers or libraries in 
unusual places on my disk. Moreover, why does the script search for 
mysql now ? I'm interested by mysql, but this comes later with RMySQL !
Anyway, mysql headers *are* in /usr/include/mysql.

Regards,
Laurent



From p.dalgaard at biostat.ku.dk  Fri Sep 26 14:57:00 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Fri, 26 Sep 2003 12:57:00 -0000
Subject: [R] installation : make fails (R-1.7.1 on RedHat 8.0)
In-Reply-To: <3F74363D.40807@ariase.com>
References: <3F740F39.7010904@ariase.com> <x2u16zrdhi.fsf@biostat.ku.dk>
	<3F74363D.40807@ariase.com>
Message-ID: <x2llsbr9k7.fsf@biostat.ku.dk>

Laurent Faisnel <laurent.faisnel at ariase.com> writes:

> Peter Dalgaard BSA wrote:
> > Laurent Faisnel <laurent.faisnel at ariase.com> writes:
> >
> >>Hi,
> >>
> >>I'm trying to compile R-1.7.1 from source (on a RedHat 8.0) instead of
> >>using the binary version, as it has often been advised.
> >>However I don't manage to find a solution to the following error which
> >>occurs during the make procedure :
> >
> >>gcc -I../../../../include /usr/include/mysql  -D__NO_MATH_INLINES
> >                             ******************
> >
> >>-mieee-fp  -fPIC  -g -O2 -c ansari.c -o ansari.o
> > The stars indicate the problem. This wants to -I/usr/include/mysql if
> > anything, otherwise gcc will believe that there are two files to
> > compile and complain about the -o. I suspect that you entered the
> > wrong thing during configuration.
> >
> 
> Peter,
> Thanks for your answer, but everything is not clear to me. This
> installation was made with the default ./configure without any
> additional option (so if I made something wrong, it is to forget an
> option). I checked out ./configure --help.
> What should I add ? I don't believe there are headers or libraries in
> unusual places on my disk. Moreover, why does the script search for
> mysql now ? I'm interested by mysql, but this comes later with RMySQL !
> Anyway, mysql headers *are* in /usr/include/mysql.

That's not the problem. The problem is that the "/usr/include/mysql"
sneaked into your configuration files somehow. This can happen by
other means than configure options:. environment variables or
configuration files (~/.Rconf) are the two that I can recall just now.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From Olivier.Eterradossi at ema.fr  Fri Sep 26 15:22:38 2003
From: Olivier.Eterradossi at ema.fr (Olivier ETERRADOSSI)
Date: Fri, 26 Sep 2003 15:22:38 +0200
Subject: [R] polar plotting of complex quantities
Message-ID: <3F743D9E.9000606@ema.fr>

Hello to everybody,
... and sorry if the question has already been answered.

I am dealing with complex numbers and need a way of plotting them on 
angular plots (2D and 3D). Is there a package that already manage this, 
or can somebody in this R-world who could help me with his skill ?

Thanks to all. Have a nice week-end !

Olivier Eterradossi
Ph.D., "PsychoSensory Properties of Materials" Team
Research Center on Materials - Al?s School of Mines
H?lioparc, 2 av. P. Angot, F-64053 PAU CEDEX 9 - France



From spencer.graves at pdf.com  Fri Sep 26 16:04:56 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 26 Sep 2003 09:04:56 -0500
Subject: [R] 3d contours
In-Reply-To: <3F7411EE.8A98D702@ysbl.york.ac.uk>
References: <3F7411EE.8A98D702@ysbl.york.ac.uk>
Message-ID: <3F744788.6070801@pdf.com>

      I recieved and replied to this same post yesterday.  Did you 
receive my reply? 

      Also, have you searched www.r-project.org -> Search -> "R site 
search"? 

      hope this helps.  spencer graves

Karim Elsawy wrote:

>Hi,
>I wonder if there is any R package or function which produces the
>coordinates of a 3d contour (isosurface) 
>from a 3d data array.
>any suggestions are very much appreciated
>best regards
>karim
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From laurent.faisnel at ariase.com  Fri Sep 26 16:12:57 2003
From: laurent.faisnel at ariase.com (Laurent Faisnel)
Date: Fri, 26 Sep 2003 16:12:57 +0200
Subject: [R] installation : make fails (R-1.7.1 on RedHat 8.0)
References: <3F740F39.7010904@ariase.com>
	<x2u16zrdhi.fsf@biostat.ku.dk>	<3F74363D.40807@ariase.com>
	<x2llsbr9k7.fsf@biostat.ku.dk>
Message-ID: <3F744969.8070904@ariase.com>

Peter Dalgaard BSA wrote:
> Laurent Faisnel <laurent.faisnel at ariase.com> writes:
> 
> 
>>Peter Dalgaard BSA wrote:
>>
>>>Laurent Faisnel <laurent.faisnel at ariase.com> writes:
>>>
>>>
>>>>Hi,
>>>>
>>>>I'm trying to compile R-1.7.1 from source (on a RedHat 8.0) instead of
>>>>using the binary version, as it has often been advised.
>>>>However I don't manage to find a solution to the following error which
>>>>occurs during the make procedure :
>>>
>>>>gcc -I../../../../include /usr/include/mysql  -D__NO_MATH_INLINES
>>>
>>>                            ******************
>>>
>>>
>>>>-mieee-fp  -fPIC  -g -O2 -c ansari.c -o ansari.o
>>>
>>>The stars indicate the problem. This wants to -I/usr/include/mysql if
>>>anything, otherwise gcc will believe that there are two files to
>>>compile and complain about the -o. I suspect that you entered the
>>>wrong thing during configuration.
>>>
>>
>>Peter,
>>Thanks for your answer, but everything is not clear to me. This
>>installation was made with the default ./configure without any
>>additional option (so if I made something wrong, it is to forget an
>>option). I checked out ./configure --help.
>>What should I add ? I don't believe there are headers or libraries in
>>unusual places on my disk. Moreover, why does the script search for
>>mysql now ? I'm interested by mysql, but this comes later with RMySQL !
>>Anyway, mysql headers *are* in /usr/include/mysql.
> 
> 
> That's not the problem. The problem is that the "/usr/include/mysql"
> sneaked into your configuration files somehow. This can happen by
> other means than configure options:. environment variables or
> configuration files (~/.Rconf) are the two that I can recall just now.
> 

I fixed the problem. You gave me the decisive clue : it was a problem 
with environment variables.

I had the two following definitions :

PKG_CPPFLAGS=/usr/include/mysql   and   PKG_CPPLIBS=/usr/lib/mysql

I set both variables to "" and now make works fine.
Thanks again.



From spencer.graves at pdf.com  Fri Sep 26 16:12:55 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 26 Sep 2003 09:12:55 -0500
Subject: [R] polar plotting of complex quantities
In-Reply-To: <3F743D9E.9000606@ema.fr>
References: <3F743D9E.9000606@ema.fr>
Message-ID: <3F744967.4030900@pdf.com>

I'm not certain what you want, but have you considered the following: 

tst <- (rnorm(5)+1i*rnorm(5))
plot(Re(tst), Im(tst))
plot(Mod(tst), Arg(tst))

hope this helps.  spencer graves

Olivier ETERRADOSSI wrote:

> Hello to everybody,
> ... and sorry if the question has already been answered.
>
> I am dealing with complex numbers and need a way of plotting them on 
> angular plots (2D and 3D). Is there a package that already manage 
> this, or can somebody in this R-world who could help me with his skill ?
>
> Thanks to all. Have a nice week-end !
>
> Olivier Eterradossi
> Ph.D., "PsychoSensory Properties of Materials" Team
> Research Center on Materials - Al?s School of Mines
> H?lioparc, 2 av. P. Angot, F-64053 PAU CEDEX 9 - France
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From kjetil at entelnet.bo  Fri Sep 26 16:16:09 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Fri, 26 Sep 2003 10:16:09 -0400
Subject: [R] polar plotting of complex quantities
In-Reply-To: <3F743D9E.9000606@ema.fr>
Message-ID: <3F7411E9.8706.6CF3E8@localhost>

On 26 Sep 2003 at 15:22, Olivier ETERRADOSSI wrote:

This is really in "An introduction to R". 
Does the following help?

> test <- rnorm(100) + 1i*rnorm(100)
> summary(test)
 Length   Class    Mode 
    100 complex complex 
> plot(test)
# gives a plot of real versus imaginary parts.

Kjetil Halvorsen

> Hello to everybody,
> ... and sorry if the question has already been answered.
> 
> I am dealing with complex numbers and need a way of plotting them on 
> angular plots (2D and 3D). Is there a package that already manage this, 
> or can somebody in this R-world who could help me with his skill ?
> 
> Thanks to all. Have a nice week-end !
> 
> Olivier Eterradossi
> Ph.D., "PsychoSensory Properties of Materials" Team
> Research Center on Materials - Al?s School of Mines
> H?lioparc, 2 av. P. Angot, F-64053 PAU CEDEX 9 - France
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From mkondrin at hppi.troitsk.ru  Sat Sep 27 03:33:46 2003
From: mkondrin at hppi.troitsk.ru (M.Kondrin)
Date: Fri, 26 Sep 2003 18:33:46 -0700
Subject: [R] CRAN mirror - howto?
Message-ID: <3F74E8FA.7000104@hppi.troitsk.ru>

Hello!
There is a group of administartors of Russian internet site 
www.linuxportal.ru (this is mainly a forum for linux-users) who are 
intended to host on this site mirrors of linux distributions and open 
source software with http and ftp access. I have proposed to them to 
open there a CRAN mirror, making a point what this site would be a first 
R mirror in .ru domain, and they seems to accept the idea.
Wouldn't you explain what is the procedure of opening of "official" CRAN 
mirror (i.e. site listed among CRAN mirrors on cran.r-project.org page) 
or whom I should contact with. I can not find this information on main R 
site.



From ahenningsen at email.uni-kiel.de  Fri Sep 26 17:03:02 2003
From: ahenningsen at email.uni-kiel.de (Arne Henningsen)
Date: Fri, 26 Sep 2003 17:03:02 +0200
Subject: [R] checking generic/method consistency
Message-ID: <200309261703.02344.ahenningsen@email.uni-kiel.de>

Hi,

I wrote a package for linear programming and want to submit it to CRAN. 
Since the package 'quadprog' has a function with the name 'solve.QP' to 
perform Quadratic Programming, I named my (main) function 'solve.LP'. 
However 'R CMD check' gives one warning:

* checking generic/method consistency ... WARNING
solve:
  function(a, b, ...)
solve.LP:
  function(cvec, bvec, Amat, maximum, maxiter, verbose)

while 'R CMD check' gives no warnings when the function has the name 
'solve.QP'.

What do you recommend me to do?
1) Ignore the warning and upload the package to CRAN as it is?
2) Rename the function? (any suggestions?)
3) Change something that avoids this problem without renaming the functions?

I would prefer the third point, but I don't know how.

Thank you for your answers,

Arne

-- 
Arne Henningsen
Department of Agricultural Economics
Christian-Albrechts-University Kiel
24098 Kiel, Germany
Tel: +49-431-880-4445
Fax: +49-431-880-1397 
ahenningsen at email.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen.html



From s319642 at stud.uni-goettingen.de  Fri Sep 26 17:04:52 2003
From: s319642 at stud.uni-goettingen.de (Andreas Cordes)
Date: Fri, 26 Sep 2003 17:04:52 +0200
Subject: [R] empty postscript output of figures
Message-ID: <000101c3843f$8982c280$b5a40a0a@stoch22>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030926/48036dcf/attachment.pl

From axel.benz at iao.fhg.de  Fri Sep 26 17:34:47 2003
From: axel.benz at iao.fhg.de (Axel Benz)
Date: Fri, 26 Sep 2003 17:34:47 +0200
Subject: [R] performance question
Message-ID: <87F1BE4E9ED108429DB4C9B9838356219B01@samos.mlab.iao.fhg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030926/f077e558/attachment.pl

From hb at maths.lth.se  Fri Sep 26 17:43:00 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Fri, 26 Sep 2003 17:43:00 +0200
Subject: [R] checking generic/method consistency
In-Reply-To: <200309261703.02344.ahenningsen@email.uni-kiel.de>
Message-ID: <000f01c38444$e0d9ab70$3b0040d5@maths.lth.se>

Hi, it looks from the names of your argument that your function is a
"plain function", i.e. it is not a function specific to a class. If this
is true, I would avoid the period and rename your function to

  solveLP <- function(cvec, bvec, Amat, maximum, maxiter, verbose) ...

Under the S3 style of programming with classes methods coupled to
classes are written in the format

  method.class <- function(object, arg1, arg2, ...

That is, the part before the period is the name of a generic function
and the part after is the name of the class. This is why R CMD check
believe your that you have written a method 'solve' for class 'LP'. All
methods named 'solve' should have a argument signature that match the
generic function 'solve' and your solve.LP doesn't. I do not think this
was your intention, correct? See help.start() -> "R Language Definition"
-> "Object-oriented programming:" for more details about the S3 style. 

To avoid problems like these I am working on a R Coding Conventions
(RCC), http://www.maths.lth.se/help/R/RCC/ (see Naming Conventions). It
is an early version and not everyone agrees with it, but the intention
is to find a style that avoid problems like yours, where it says that
you should avoid periods in function names except if you use it for S3
class methods. Feedback is appreciated.

Cheers

Henrik Bengtsson
Lund University



> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Arne Henningsen
> Sent: den 26 september 2003 17:03
> To: r-help at stat.math.ethz.ch
> Subject: [R] checking generic/method consistency
> 
> 
> Hi,
> 
> I wrote a package for linear programming and want to submit 
> it to CRAN. 
> Since the package 'quadprog' has a function with the name 
> 'solve.QP' to 
> perform Quadratic Programming, I named my (main) function 'solve.LP'. 
> However 'R CMD check' gives one warning:
> 
> * checking generic/method consistency ... WARNING
> solve:
>   function(a, b, ...)
> solve.LP:
>   function(cvec, bvec, Amat, maximum, maxiter, verbose)
> 
> while 'R CMD check' gives no warnings when the function has the name 
> 'solve.QP'.
> 
> What do you recommend me to do?
> 1) Ignore the warning and upload the package to CRAN as it is?
> 2) Rename the function? (any suggestions?)
> 3) Change something that avoids this problem without renaming 
> the functions?
> 
> I would prefer the third point, but I don't know how.
> 
> Thank you for your answers,
> 
> Arne
> 
> -- 
> Arne Henningsen
> Department of Agricultural Economics 
> Christian-Albrechts-University Kiel 24098 Kiel, Germany
> Tel: +49-431-880-4445
> Fax: +49-431-880-1397 
> ahenningsen at email.uni-kiel.de 
> http://www.uni-> kiel.de/agrarpol/ahenningsen.html
> 
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> 
>



From tblackw at umich.edu  Fri Sep 26 17:45:31 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Fri, 26 Sep 2003 11:45:31 -0400 (EDT)
Subject: [R] empty postscript output of figures
In-Reply-To: <000101c3843f$8982c280$b5a40a0a@stoch22>
References: <000101c3843f$8982c280$b5a40a0a@stoch22>
Message-ID: <Pine.SOL.4.58.0309261139040.7970@mspacman.gpcc.itd.umich.edu>

Andreas  -

help("postscript") says:

"Arguments: file: ... For use with 'onefile=FALSE'
   give a 'printf' format such as `"Rplot%03d.ps"'
   (the default in that case)."

The "%03d" will be replaced with a three digit number
in the actual file name.  This allows  postscript() to
generate a distinct file name for each plot.  Try this
and see if it helps.  Do read the help.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Fri, 26 Sep 2003, Andreas Cordes wrote:

> I have a puzzeling problem. I want to export graphics from R to TeX via
> postscript(). This works fine for some graphs, but for others, the eps
> remain empty when viewed with GSView. When such an empty eps is imported
> to TeX, the figure appears upside down and very small, irrespective of
> TeX width and height commands. If I transform the eps to pdf, the
> graphic shows up, but turned aqround 90°. It appears that, when printing
> the figures to the gaphics window in R, the background is grey, while it
> is white for those graphics that are properly printed to file. All
> postscript commands are followed by a dev.off() command after the
> plotting commands. I have R running under WinXP .
>
> Here an example of malfunctioning code.
>
> postscript("ex6_pic1.eps", width =6, height = 9,
> horizontal = F, onefile = FALSE, paper = "special")
> par(mfrow=c(2,1));
> par(mfg=c(1,1));
> plot(bidia,weight,xlab="birthweight",ylab="head diameter");
> abline(birth.lm1$coefficients);
> par(mfg=c(2,1));
> plot(abdcir,weight,xlab="birthweight",ylab="abdomnial circumference");
> abline(birth.lm2$coefficients);
> dev.off()
>
> Hope you can help me.
> Best
> Andreas



From tblackw at umich.edu  Fri Sep 26 17:52:17 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Fri, 26 Sep 2003 11:52:17 -0400 (EDT)
Subject: [R] performance question
In-Reply-To: <87F1BE4E9ED108429DB4C9B9838356219B01@samos.mlab.iao.fhg.de>
References: <87F1BE4E9ED108429DB4C9B9838356219B01@samos.mlab.iao.fhg.de>
Message-ID: <Pine.SOL.4.58.0309261147030.7970@mspacman.gpcc.itd.umich.edu>

Axel  -

I believe that a function argument is not literally copied
until the first time it is modified within the function.
See email exchanges on this list from/to Ross Boylan within
the month of September for a more authoritative answer to
this question.  (Do you know about the R-help archives at
three sites listed on  http://cran.R-project.org/search.html ?)

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Fri, 26 Sep 2003, Axel Benz wrote:

> I am about to write functions for multivariate kernel densitiy estimation
> with mixed categorical and continuous date (accoring to Jeff Racine and Qi
> Li), and the leave-one-out window esitmation needs a lot of computation.
> I am now optimizing the code performance and therefore fhe following
> questions:
>
> As R uses call-by-value for functions, is it computational expensive to pass
> large matrices in function arguments?
>
> (i.e. are they really copied and does this need much computing time?) Is it
> maybe better to work with locally visible variables and nested functions in
> the optimized code?
>
> I have already used Rprof (and I could speed up the code a lot by the
> information from Rprof), but it does not tell me about that.
>
> Thank you for your hints!
>
> Axel
> ________________________________________
> Fraunhofer Institut fuer
> Arbeitswirtschaft und Organisation (IAO)
> Dipl. Inf. Axel Benz
> Nobelstr. 12
> D-70569 Stuttgart
> Germany
> Tel. +49(0)7119702289
> Fax. +49(0)7119702192
> mail: mailto:axel.benz at iao.fhg.de
> www: http://www.vis.iao.fhg.de
> ________________________________________



From tlumley at u.washington.edu  Fri Sep 26 18:00:53 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 26 Sep 2003 09:00:53 -0700 (PDT)
Subject: [R] performance question
In-Reply-To: <87F1BE4E9ED108429DB4C9B9838356219B01@samos.mlab.iao.fhg.de>
References: <87F1BE4E9ED108429DB4C9B9838356219B01@samos.mlab.iao.fhg.de>
Message-ID: <Pine.A41.4.58.0309260852530.136644@homer40.u.washington.edu>

On Fri, 26 Sep 2003, Axel Benz wrote:

> Hi,
> I am about to write functions for multivariate kernel densitiy estimation
> with mixed categorical and continuous date (accoring to Jeff Racine and Qi
> Li), and the leave-one-out window esitmation needs a lot of computation.
> I am now optimizing the code performance and therefore fhe following
> questions:
>
> As R uses call-by-value for functions, is it computational expensive to pass
> large matrices in function arguments?

No, as long as they are not modified. R doesn't make actual copies if it
knows they aren't needed, it just creates a reference to the original
object.

> (i.e. are they really copied and does this need much computing time?) Is it
> maybe better to work with locally visible variables and nested functions in
> the optimized code?

It probably won't make a detectable difference.  Looking up a variable is
microscopically quicker if it is local (eg passed as a parameter), but you
need fairly extreme cases for this to be noticeable.


	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From Roger.Bivand at nhh.no  Fri Sep 26 09:02:28 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 26 Sep 2003 09:02:28 +0200 (CEST)
Subject: [R] [R-pkgs] R spatial projects mailing list and web site
Message-ID: <Pine.LNX.4.44.0309260856170.24413-100000@reclus.nhh.no>

A mailing list has been opened, and a collection of web pages assembled,
to provide a joint forum for R spatial projects, where spatial data is
understood mostly as geographical data.

The mailing list is for discussing the development and use of R functions
and packages for handling and analysis of spatial, and particularly
geographical, data. The list also covers mapping and cartographic issues,
and interfaces between R and geographical information systems. It can
be accessed directly at:

https://www.stat.math.ethz.ch/mailman/listinfo/r-sig-geo

or through the R spatial projects web site:

http://sal.agecon.uiuc.edu/csiss/Rgeo/index.html

hosted by the Spatial Analysis Laboratory in the Department of
Agricultural and Consumer Economics at the University of Illinois,
Urbana-Champaign.

I would be very grateful for comments on, and corrections and
contributions to the web pages, in particular from authors and maintainers
of packages that should be described in and linked to the site.

Roger Bivand

Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://www.stat.math.ethz.ch/mailman/listinfo/r-packages



From Simon.Fear at synequanon.com  Fri Sep 26 18:24:18 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Fri, 26 Sep 2003 17:24:18 +0100
Subject: [R] checking generic/method consistency
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572AC0DF2@synequanon01>

> -----Original Message-----
> From: Henrik Bengtsson [mailto:hb at maths.lth.se]
> Sent: 26 September 2003 16:43

<snip>
> ... the intention
> is to find a style that avoid problems like yours, where it says that
> you should avoid periods in function names except if you use it for S3
> class methods. Feedback is appreciated.

One possible argument against this is the fact that 851 of the 1655
objects in base use a period in their name.

OK, well, not really that many because this list includes a lot of bona
fide S3 class methods - but it also includes sys.*, unix.*, win.* and
that's
not
to mention data.frame (which is of course NOT a method of the 
function data). And help.start. Then there is read.* which is to some 
extent S3-class-like in that the read method is set by .* but it is 
called explicitly, rather than according to the class of the first 
argument.

So, I don't see universal support for  your .* proposal ... and I'm
certainly
not going to rewrite my old code...

simon.fear at synequanon.com (nice  S4 class syntax)
 

Simon Fear
Senior Statistician
Syne qua non Ltd
Tel: +44 (0) 1379 644449
Fax: +44 (0) 1379 644445
email: Simon.Fear at synequanon.com
web: http://www.synequanon.com
 
Number of attachments included with this message: 0
 
This message (and any associated files) is confidential and\...{{dropped}}



From pgilbert at bank-banque-canada.ca  Fri Sep 26 19:07:45 2003
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Fri, 26 Sep 2003 13:07:45 -0400
Subject: [R] checking generic/method consistency
In-Reply-To: <6C8A8033ABC1E3468048ABC4F13CE572AC0DF2@synequanon01>
References: <6C8A8033ABC1E3468048ABC4F13CE572AC0DF2@synequanon01>
Message-ID: <3F747261.6070006@bankofcanada.ca>

Simon Fear wrote:

>>From: Henrik Bengtsson [mailto:hb at maths.lth.se]
>><snip>
>>    
>>
>>... the intention
>>is to find a style that avoid problems like yours, where it says that
>>you should avoid periods in function names except if you use it for S3
>>class methods. Feedback is appreciated.
>>    
>>
<snip>

>So, I don't see universal support for  your .* proposal ... and I'm
>certainly not going to rewrite my old code...
>
Being a recent convert to this dot-less naming convention let me say 
that, initially it might be best to think of it as very good advice for 
new code. However,  having just rewritten my old code for exactly this 
reason, it seems to be worthwhile and not as difficult as you might think.

Paul Gilbert



From tlumley at u.washington.edu  Fri Sep 26 19:10:18 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 26 Sep 2003 10:10:18 -0700 (PDT)
Subject: [R] checking generic/method consistency
In-Reply-To: <6C8A8033ABC1E3468048ABC4F13CE572AC0DF2@synequanon01>
References: <6C8A8033ABC1E3468048ABC4F13CE572AC0DF2@synequanon01>
Message-ID: <Pine.A41.4.58.0309260957160.136644@homer40.u.washington.edu>

On Fri, 26 Sep 2003, Simon Fear wrote:

> > -----Original Message-----
> > From: Henrik Bengtsson [mailto:hb at maths.lth.se]
> > Sent: 26 September 2003 16:43
>
> <snip>
> > ... the intention
> > is to find a style that avoid problems like yours, where it says that
> > you should avoid periods in function names except if you use it for S3
> > class methods. Feedback is appreciated.
>
> One possible argument against this is the fact that 851 of the 1655
> objects in base use a period in their name.
>
> OK, well, not really that many because this list includes a lot of bona
> fide S3 class methods - but it also includes sys.*, unix.*, win.* and
> that's
> not
> to mention data.frame (which is of course NOT a method of the
> function data). And help.start. Then there is read.* which is to some
> extent S3-class-like in that the read method is set by .* but it is
> called explicitly, rather than according to the class of the first
> argument.
>
> So, I don't see universal support for  your .* proposal ... and I'm
> certainly
> not going to rewrite my old code...
>

Old code is precisely the issue.

Newly added functions in base typically don't have . in their name, so we
have eg

socketSelect
constrOptim
textConnection
tryCatch
summaryRprof
compareVersion
extractAIC

and in R1.8.0 print.coefmat is being removed and replaced by printCoefmat
(though some people obivously never learn, since capture.output() was
added as recently as 1.7.0)

The problem is that many of the functions in base are either widely used
or part of the S language definition or both, and so can't be removed.
read.table, data.frame and the sys.* functions are good examples.

On the other hand, with either S4 methods or namespaces you have to
declare which functions are methods, so the scope for confusion is
getting smaller.   Also, in the near future we will have the underscore
back as an ordinary character and can use it as a word separator in
function names.


	-thomas



From andyj at splash.princeton.edu  Fri Sep 26 20:05:40 2003
From: andyj at splash.princeton.edu (Andy Jacobson)
Date: Fri, 26 Sep 2003 14:05:40 -0400
Subject: [R] reproducing an error in dumped frames
Message-ID: <f2kad8rfmrv.fsf@splash.princeton.edu>

Greetings,

        I am doing many iterations of simple optimizations using the
        L-BFGS-B method of optim() in R-1.6.2.  Very rarely (about 1
        in every 100,000 trials), a process will encounter some
        problem in optim that triggers the error message "non-finite
        value supplied by optim".  From the C code, it appears that
        this message could be emitted in several different places.

        I have tried to capture the exact conditions that cause this
        error via setting options(error) to call dump.frames().  I've
        gotten a frame dump or two now, and so I believe I have a few
        sets of guilty function arguments.  However, when I call
        optim() with these arguments, I cannot make it crash.  Am I
        wrong to have expected to be able to reproduce the problem in
        this manner?  Any suggestions would be much appreciated!

        Thanks,
                Andy

-- 
Andy Jacobson

andyj at splash.princeton.edu

Program in Atmospheric and Oceanic Sciences
Sayre Hall, Forrestal Campus
Princeton University
PO Box CN710 Princeton, NJ 08544-0710 USA

Tel: 609/258-5260  Fax: 609/258-2850



From mhough at itsa.ucsf.edu  Fri Sep 26 20:15:50 2003
From: mhough at itsa.ucsf.edu (Morgan Hough)
Date: Fri, 26 Sep 2003 11:15:50 -0700 (PDT)
Subject: [R] rpmbuild of src.rpm error
In-Reply-To: <x28yoclgal.fsf@biostat.ku.dk>
References: <Pine.GSO.4.53.0309251231380.10239@itsa.ucsf.edu>
	<x28yoclgal.fsf@biostat.ku.dk>
Message-ID: <Pine.GSO.4.53.0309261110460.24597@itsa.ucsf.edu>

Peter,

I had tetex installed but not all the additional packages. I installed the
missing packages and the R.src.rpm built just fine on the first Fedora
Core test release (RHL 9.0.93 codenamed Severn). Thanks for the help.

Take care.

-Morgan

On Thu, 25 Sep 2003, Peter Dalgaard BSA wrote:

> Morgan Hough <mhough at itsa.ucsf.edu> writes:
>
> > I received an error trying to build R-1.7.1-src.rpm on RH9.0.93 (Severn)
> > and I was wondering if anybody could tell me what is going on with the
> > manual error.
>
> I'd look further up the log for an indication of whether the PDF
> manuals got built at all. You do have all the TeX tools in place?
>
> > + cp -pr 'doc/manual/R-*.pdf' /var/tmp/R-root/usr/share/doc/R-1.7.1
> > cp: cannot stat `doc/manual/R-*.pdf': No such file or directory
> > error: Bad exit status from /var/tmp/rpm-tmp.78384 (%doc)
> > Processing files: R-debuginfo-1.7.1-1
> > + cp -pr 'doc/manual/R-*.pdf' /var/tmp/R-root/usr/share/doc/R-1.7.1
> > cp: cannot stat `doc/manual/R-*.pdf': No such file or directory
> > error: Bad exit status from /var/tmp/rpm-tmp.78384 (%doc)
>
> --
>    O__  ---- Peter Dalgaard             Blegdamsvej 3
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
>



From yao6889 at msmailhub.oulan.ou.edu  Fri Sep 26 23:10:36 2003
From: yao6889 at msmailhub.oulan.ou.edu (Yao, Minghua)
Date: Fri, 26 Sep 2003 16:10:36 -0500
Subject: [R] Std. errors of intercept and slope
Message-ID: <FC0CEBD77311DA499A67ADB355A24FA20396ADC2@mail4.oulan.ou.edu>

Dear all,

I have the following output generated by linear regression. Since there is
only one regression intercept and one slope for one set of data, what is the

meaning of std. error for intercept and that of slope? Thanks in advance.

Sincerely,

Minghua


> data(thuesen)
> attach(thuesen)
> lm(short.velocity~blood.glucose)

Call:
lm(formula = short.velocity ~ blood.glucose)

Coefficients:
  (Intercept)  blood.glucose  
      1.09781        0.02196  

> summary(lm(short.velocity~blood.glucose))

Call:
lm(formula = short.velocity ~ blood.glucose)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.40141 -0.14760 -0.02202  0.03001  0.43490 

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept)    1.09781    0.11748   9.345 6.26e-09 ***
blood.glucose  0.02196    0.01045   2.101   0.0479 *  
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 

Residual standard error: 0.2167 on 21 degrees of freedom
Multiple R-Squared: 0.1737,     Adjusted R-squared: 0.1343 
F-statistic: 4.414 on 1 and 21 DF,  p-value: 0.0479 

>



From bolker at zoo.ufl.edu  Fri Sep 26 23:33:53 2003
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Fri, 26 Sep 2003 17:33:53 -0400 (EDT)
Subject: [R] Std. errors of intercept and slope
In-Reply-To: <FC0CEBD77311DA499A67ADB355A24FA20396ADC2@mail4.oulan.ou.edu>
Message-ID: <Pine.LNX.4.44.0309261732380.3595-100000@bolker.zoo.ufl.edu>


  Since the intercept and slope are estimated parameters, they have 
sampling distributions described by their means and standard deviations.  
The s.d. tells you the size of the uncertainty in intercept & in slope.

  This is a pretty basic stats question -- you need to refer to a standard 
textbook or reference material ...

  Ben Bolker

On Fri, 26 Sep 2003, Yao, Minghua wrote:

> Dear all,
> 
> I have the following output generated by linear regression. Since there is
> only one regression intercept and one slope for one set of data, what is the
> 
> meaning of std. error for intercept and that of slope? Thanks in advance.
> 
> Sincerely,
> 
> Minghua
> 
> 
> > data(thuesen)
> > attach(thuesen)
> > lm(short.velocity~blood.glucose)
> 
> Call:
> lm(formula = short.velocity ~ blood.glucose)
> 
> Coefficients:
>   (Intercept)  blood.glucose  
>       1.09781        0.02196  
> 
> > summary(lm(short.velocity~blood.glucose))
> 
> Call:
> lm(formula = short.velocity ~ blood.glucose)
> 
> Residuals:
>      Min       1Q   Median       3Q      Max 
> -0.40141 -0.14760 -0.02202  0.03001  0.43490 
> 
> Coefficients:
>               Estimate Std. Error t value Pr(>|t|)    
> (Intercept)    1.09781    0.11748   9.345 6.26e-09 ***
> blood.glucose  0.02196    0.01045   2.101   0.0479 *  
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 
> 
> Residual standard error: 0.2167 on 21 degrees of freedom
> Multiple R-Squared: 0.1737,     Adjusted R-squared: 0.1343 
> F-statistic: 4.414 on 1 and 21 DF,  p-value: 0.0479 
> 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From yao6889 at msmailhub.oulan.ou.edu  Fri Sep 26 23:49:59 2003
From: yao6889 at msmailhub.oulan.ou.edu (Yao, Minghua)
Date: Fri, 26 Sep 2003 16:49:59 -0500
Subject: [R] Std. errors of intercept and slope
Message-ID: <FC0CEBD77311DA499A67ADB355A24FA20396ADC3@mail4.oulan.ou.edu>

Thanks, Ben.

Could you tell me the formula for calculating this sd., given (x_i, y_i)
(i=1,2,...,N)?
We only have one intercept and slope for them.

-Minghua

-----Original Message-----
From: Ben Bolker [mailto:bolker at zoo.ufl.edu]
Sent: Friday, September 26, 2003 4:34 PM
To: Yao, Minghua
Cc: R Help (E-mail)
Subject: Re: [R] Std. errors of intercept and slope



  Since the intercept and slope are estimated parameters, they have 
sampling distributions described by their means and standard deviations.  
The s.d. tells you the size of the uncertainty in intercept & in slope.

  This is a pretty basic stats question -- you need to refer to a standard 
textbook or reference material ...

  Ben Bolker

On Fri, 26 Sep 2003, Yao, Minghua wrote:

> Dear all,
> 
> I have the following output generated by linear regression. Since there is
> only one regression intercept and one slope for one set of data, what is
the
> 
> meaning of std. error for intercept and that of slope? Thanks in advance.
> 
> Sincerely,
> 
> Minghua
> 
> 
> > data(thuesen)
> > attach(thuesen)
> > lm(short.velocity~blood.glucose)
> 
> Call:
> lm(formula = short.velocity ~ blood.glucose)
> 
> Coefficients:
>   (Intercept)  blood.glucose  
>       1.09781        0.02196  
> 
> > summary(lm(short.velocity~blood.glucose))
> 
> Call:
> lm(formula = short.velocity ~ blood.glucose)
> 
> Residuals:
>      Min       1Q   Median       3Q      Max 
> -0.40141 -0.14760 -0.02202  0.03001  0.43490 
> 
> Coefficients:
>               Estimate Std. Error t value Pr(>|t|)    
> (Intercept)    1.09781    0.11748   9.345 6.26e-09 ***
> blood.glucose  0.02196    0.01045   2.101   0.0479 *  
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 
> 
> Residual standard error: 0.2167 on 21 degrees of freedom
> Multiple R-Squared: 0.1737,     Adjusted R-squared: 0.1343 
> F-statistic: 4.414 on 1 and 21 DF,  p-value: 0.0479 
> 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From petra at icsi.berkeley.edu  Sat Sep 27 00:06:59 2003
From: petra at icsi.berkeley.edu (Petra Steiner)
Date: Fri, 26 Sep 2003 15:06:59 -0700
Subject: [R] a. crossing branches with hclust, b. plot.dendrogram
Message-ID: <3F74B883.4346F756@icsi.berkeley.edu>

Hello,

a. when I use hclust with the methods media, centroid, and mcquitty,
and plot the results,  the dendrograms have lines that are crossing each
other. Is this ok?

b. My next question refers to plot.dendrogram: How can I use parameters
as "hang" or "cex" here? E.g. for

st <- as.dendrogram(subtreeshc[[x]])

I would like to have something like this, where cex and hang would work:

plot(st, frame.plot=F, cex = 0.4, hang = 0, sub = "", xlab = "",
ylab="", main = paste("Distance: ", me, " - Clustering Method: ",
mecl, " - Subtree ", x, collapse="", sep=""))

Thanks and best regards,
Petra

--

  Petra Steiner
  International Computer Science Institute (ICSI)
  1947 Center Street, Berkeley, CA, 94704-1198, USA
  http://www.ICSI.berkeley.edu/~petra



From braver at pobox.com  Sat Sep 27 00:54:48 2003
From: braver at pobox.com (Alexy Khrabrov)
Date: Fri, 26 Sep 2003 18:54:48 -0400
Subject: [R] data lost in cv.tree?
In-Reply-To: <20030925060255.GA25590%alexy.khrabrov@setup.org>
References: <20030925052649.GA25435%alexy.khrabrov@setup.org>
	<20030925060255.GA25590%alexy.khrabrov@setup.org>
Message-ID: <20030926225448.GA31235%alexy.khrabrov@setup.org>


OK, since this flew without a sound, let me rephrase it,
and omit dramatics.  Before I bother Brian, who wrote the
original cv.tree, I hope somebody will clue me in!

So, we have a nested call tree:

Abel calls Cain; Cain calls cv.tree.

Abel defines X, and fmla <- y~., and calls Cain(y~.,X).

Cain begats a tr <- tree(fmla, X), and then passes it along
to cv.tree(tr).

cv.tree complains, via its mouthpiece model.frame.default,
that it can't find X.

How can one supply X in that case?  It's a natural call sequence,
and putting X into the global frame is unnatural, and I'm not
sure that R's kinky search path is teh culprit here, it's how
formula and tree know which data they refer to, isn't it?

Cheers,
Alexy



From jmacdon at med.umich.edu  Sat Sep 27 01:59:00 2003
From: jmacdon at med.umich.edu (James MacDonald)
Date: Fri, 26 Sep 2003 19:59:00 -0400
Subject: [R] Spam-Filter @stat.math.ethz.ch: was dead for about 15
	hours
Message-ID: <sf749a94.059@med-gwia-01a.med.umich.edu>

On the bright side, I will soon be a bazillionaire due to the
opportunities afforded by numerous unfortunate deaths in west central
Africa. ;-D

Jim



James W. MacDonald
Affymetrix and cDNA Microarray Core
University of Michigan Cancer Center
1500 E. Medical Center Drive
7410 CCGC
Ann Arbor MI 48109
734-647-5623

>>> Martin Maechler <maechler at stat.math.ethz.ch> 09/26/03 02:50AM >>>
As many of you have probably realized, the spam filtering
at @stat.math.ethz.ch  has been dead for since yesterday (09-25)
~16:50 till today ~08:30.

The sudden death may have been caused by unrelated installation
of some perl modules (spamassassin *is* running on perl) by our
IT staff.
We are very sorry for this event.

On the bright side: You have been able to get a glimpse of what
you are usually protected from... :-)

Regards,
Martin Maechler
<maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/

Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From bolker at zoo.ufl.edu  Sat Sep 27 03:59:55 2003
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Fri, 26 Sep 2003 21:59:55 -0400 (EDT)
Subject: [R] Std. errors of intercept and slope
In-Reply-To: <FC0CEBD77311DA499A67ADB355A24FA20396ADC3@mail4.oulan.ou.edu>
Message-ID: <Pine.LNX.4.44.0309262159020.5289-100000@bolker.zoo.ufl.edu>


  I'm afraid you're going to have to look it up in a basic statistics 
textbook.

  Ben Bolker


On Fri, 26 Sep 2003, Yao, Minghua wrote:

> Thanks, Ben.
> 
> Could you tell me the formula for calculating this sd., given (x_i, y_i)
> (i=1,2,...,N)?
> We only have one intercept and slope for them.
> 
> -Minghua
> 
> -----Original Message-----
> From: Ben Bolker [mailto:bolker at zoo.ufl.edu]
> Sent: Friday, September 26, 2003 4:34 PM
> To: Yao, Minghua
> Cc: R Help (E-mail)
> Subject: Re: [R] Std. errors of intercept and slope
> 
> 
> 
>   Since the intercept and slope are estimated parameters, they have 
> sampling distributions described by their means and standard deviations.  
> The s.d. tells you the size of the uncertainty in intercept & in slope.
> 
>   This is a pretty basic stats question -- you need to refer to a standard 
> textbook or reference material ...
> 
>   Ben Bolker
> 
> On Fri, 26 Sep 2003, Yao, Minghua wrote:
> 
> > Dear all,
> > 
> > I have the following output generated by linear regression. Since there is
> > only one regression intercept and one slope for one set of data, what is
> the
> > 
> > meaning of std. error for intercept and that of slope? Thanks in advance.
> > 
> > Sincerely,
> > 
> > Minghua
> > 
> > 
> > > data(thuesen)
> > > attach(thuesen)
> > > lm(short.velocity~blood.glucose)
> > 
> > Call:
> > lm(formula = short.velocity ~ blood.glucose)
> > 
> > Coefficients:
> >   (Intercept)  blood.glucose  
> >       1.09781        0.02196  
> > 
> > > summary(lm(short.velocity~blood.glucose))
> > 
> > Call:
> > lm(formula = short.velocity ~ blood.glucose)
> > 
> > Residuals:
> >      Min       1Q   Median       3Q      Max 
> > -0.40141 -0.14760 -0.02202  0.03001  0.43490 
> > 
> > Coefficients:
> >               Estimate Std. Error t value Pr(>|t|)    
> > (Intercept)    1.09781    0.11748   9.345 6.26e-09 ***
> > blood.glucose  0.02196    0.01045   2.101   0.0479 *  
> > ---
> > Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 
> > 
> > Residual standard error: 0.2167 on 21 degrees of freedom
> > Multiple R-Squared: 0.1737,     Adjusted R-squared: 0.1343 
> > F-statistic: 4.414 on 1 and 21 DF,  p-value: 0.0479 
> > 
> > >
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > 
> 
> 

-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From nathanwands at hotmail.com  Sat Sep 27 04:28:09 2003
From: nathanwands at hotmail.com (Nathan Cooper)
Date: Fri, 26 Sep 2003 22:28:09 -0400
Subject: [R] A re-sampling problem
Message-ID: <Law11-F7912Phgloi9s0002705b@hotmail.com>

I plan on analyzing some bird point count data. I need to develop a 
re-sampling regime for data like this.

I used scan(file="Sample.txt",what=list(0,0,0,0,0,0),sep="\t")

[[1]]
[1] 1 2 3 4 5

[[2]]
[1]  6  7  8  9 NA

[[3]]
[1] 10 11 12 13 NA

[[4]]
[1] 14 15 16 NA NA

[[5]]
[1] 17 18 19 20 21

Each row represents one site and the numbers (1-21) are visits to that site. 
I'm going to be figuring out how many visits to each site is optimal so I 
will need to compare 1 visit to 2 visits to 3 visits etc. Therefore I need 
to somehow sample 1,2,3,4,or 5 visits with replacement from a random (with 
replacement) row 1000 times. Any ideas? I'm relatively familiar with the 
sample() functoin but not sure how to make it do this. I'm open to importing 
the data in a different way if that would make it easier. Thanks,

Nathan

_________________________________________________________________
Share your photos without swamping your Inbox.  Get Hotmail Extra Storage 
today! http://join.msn.com/?PAGE=features/es



From setsuko at mbj.ocn.ne.jp  Sat Sep 27 06:30:23 2003
From: setsuko at mbj.ocn.ne.jp (Setsuko Kinoshita)
Date: Sat, 27 Sep 2003 13:30:23 +0900
Subject: [R] Enquiry about Hierarchical Clustering
Message-ID: <200309270430.AA00845@setsuko.mbj.ocn.ne.jp>

Dear Sir,

This is Ms. Setsuko Kinoshita writing from Japan.

I have a question about " missing value" in Hierarchical Clustering.
Hierarchical Clustering was not available the data with missing value for earlier version of "R".
I used Euclidean distance and complete linkage method for "plot(hclust(dist()),hang=-1)".

How are missing values treated for Hierarchical Clustering in the latest "R 1.7.1" program?
e.g. : Is an average replaced ?

Yours Sincerely,

-----
Setsuko Kinoshita

Social?and Environmental Medicine,?
Graduate School of Comprehensive Human Sciences,
University of Tsukuba
1-1-1, Tennoudai, Tsukuba,
Ibaraki, 305-8575, Japan
Tel&Fax: +81-29-853-3489
E-mail:setsuko at epidemiology.md.tsukuba.ac.jp(office)
E-mail:setsuko at mbj.ocn.ne.jp(private)



From socrates at mis.tutkie.tut.ac.jp  Sat Sep 27 08:09:50 2003
From: socrates at mis.tutkie.tut.ac.jp (Sokratis Alikhanidi)
Date: Sat, 27 Sep 2003 15:09:50 +0900
Subject: [R] data.frame -> matrix
Message-ID: <3015877718.20030927150950@mis.tutkie.tut.ac.jp>

   Dear colleagues,

I am beginner, so the primitive questions:
in pls.pcr package in the function mvr I need to indicate a matrix of observations and a vector of responses.
But read.table function returns the data.frame object.

What is the way for conversion of the data.frame object into matrix and vector objects?

And what is the way for writing the results down into file?

Thank you very much.

Sokratis.



From kjetil at entelnet.bo  Sat Sep 27 08:16:29 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Sat, 27 Sep 2003 02:16:29 -0400
Subject: [R] Enquiry about Hierarchical Clustering
In-Reply-To: <200309270430.AA00845@setsuko.mbj.ocn.ne.jp>
Message-ID: <3F74F2FD.15966.212EC71@localhost>

On 27 Sep 2003 at 13:30, Setsuko Kinoshita wrote:

Try package cluster:

library(cluster)
?daisy # computes dissimilarity matrix with missing data
?agnes # aglomerative nesting

Kjetil Halvorsen

> Dear Sir,
> 
> This is Ms. Setsuko Kinoshita writing from Japan.
> 
> I have a question about " missing value" in Hierarchical Clustering.
> Hierarchical Clustering was not available the data with missing value for earlier version of "R".
> I used Euclidean distance and complete linkage method for "plot(hclust(dist()),hang=-1)".
> 
> How are missing values treated for Hierarchical Clustering in the latest "R 1.7.1" program?
> e.g. : Is an average replaced ?
> 
> Yours Sincerely,
> 
> -----
> Setsuko Kinoshita
> 
> Social $B!! (Band Environmental Medicine, $B!! (B
> Graduate School of Comprehensive Human Sciences,
> University of Tsukuba
> 1-1-1, Tennoudai, Tsukuba,
> Ibaraki, 305-8575, Japan
> Tel&Fax: +81-29-853-3489
> E-mail:setsuko at epidemiology.md.tsukuba.ac.jp(office)
> E-mail:setsuko at mbj.ocn.ne.jp(private)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ramasamya at gis.a-star.edu.sg  Sat Sep 27 11:05:43 2003
From: ramasamya at gis.a-star.edu.sg (Adaikalavan RAMASAMY)
Date: Sat, 27 Sep 2003 17:05:43 +0800
Subject: [R] Enquiry about Hierarchical Clustering
Message-ID: <6D9E9B9DF347EF4385F6271C64FB8D56075F81@BIONIC.biopolis.one-north.com>

Hclust is unable to handle missing values in dist().

There will be missing values in dist() function if 
1. all elements in a row are missing
2. all pairs between any two rows have at least one missing values.

In the former case, it is better to remove the row with all missing as
it is completely uninformative. The latter is harder to detect and I am
not sure how to deal with this.

Here is how dist() calculates its output for the following data:

   NA    3    5
    2    4    6

dist( rbind( c(NA, 3, 5) , c(2,4,6) ) ) = 1.732051 
= sqrt( [ (6-5)^2 + (4-3)^2  ] x 3/2 )

The factor 3/2 scales up the sum of squares of difference to account for
the missing pair.

Hope this helps.

--
Adaikalavan Ramasamy 



> Dear Sir,
> 
> This is Ms. Setsuko Kinoshita writing from Japan.
> 
> I have a question about " missing value" in Hierarchical Clustering. 
> Hierarchical Clustering was not available the data with missing value 
> for earlier version of "R". I used Euclidean distance and complete 
> linkage method for "plot(hclust(dist()),hang=-1)".
> 
> How are missing values treated for Hierarchical Clustering in the 
> latest "R 1.7.1" program? e.g. : Is an average replaced ?
> 
> Yours Sincerely,
> 
> -----
> Setsuko Kinoshita
> 
> Social $B!! (Band Environmental Medicine, $B!! (B
> Graduate School of Comprehensive Human Sciences,
> University of Tsukuba
> 1-1-1, Tennoudai, Tsukuba,
> Ibaraki, 305-8575, Japan
> Tel&Fax: +81-29-853-3489
> E-mail:setsuko at epidemiology.md.tsukuba.ac.jp(office)
> E-mail:setsuko at mbj.ocn.ne.jp(private)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From pburns at pburns.seanet.com  Sat Sep 27 12:07:59 2003
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Sat, 27 Sep 2003 11:07:59 +0100
Subject: [R] data.frame -> matrix
References: <3015877718.20030927150950@mis.tutkie.tut.ac.jp>
Message-ID: <3F75617F.9060505@pburns.seanet.com>

One place to start is "A Guide for the Unwilling S User".

Patrick Burns

Burns Statistics
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")


Sokratis Alikhanidi wrote:

>   Dear colleagues,
>
>I am beginner, so the primitive questions:
>in pls.pcr package in the function mvr I need to indicate a matrix of observations and a vector of responses.
>But read.table function returns the data.frame object.
>
>What is the way for conversion of the data.frame object into matrix and vector objects?
>
>And what is the way for writing the results down into file?
>
>Thank you very much.
>
>Sokratis.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
>  
>



From tring at gvdnet.dk  Sat Sep 27 13:25:57 2003
From: tring at gvdnet.dk (Troels Ring)
Date: Sat, 27 Sep 2003 13:25:57 +0200
Subject: [R] CI on median
Message-ID: <5.2.0.9.0.20030927132138.032bd4c0@mail.gvdnet.dk>


Dear friends, I'm probably wrong but is there anything better than 
bootstrap to get a confidence interval of the median from a population with 
unspecified distribution ?
Best wishes
Troels Ring, Aalborg, Denmark



From feh3k at spamcop.net  Sat Sep 27 08:39:40 2003
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Sat, 27 Sep 2003 08:39:40 +0200
Subject: [R] CI on median
In-Reply-To: <5.2.0.9.0.20030927132138.032bd4c0@mail.gvdnet.dk>
References: <5.2.0.9.0.20030927132138.032bd4c0@mail.gvdnet.dk>
Message-ID: <20030927083940.701a1a69.feh3k@spamcop.net>

On Sat, 27 Sep 2003 13:25:57 +0200
Troels Ring <tring at gvdnet.dk> wrote:

> 
> Dear friends, I'm probably wrong but is there anything better than 
> bootstrap to get a confidence interval of the median from a population with 
> unspecified distribution ?
> Best wishes
> Troels Ring, Aalborg, Denmark

The bootstrap doesn't work perfectly for the median.  Standard nonparametric statistics texts provide a distribution-free CI for the median, like:

medianCI <- function(y) {
    y <- sort(y[!is.na(y)])
    n <- length(y)
    if(n < 4) return(c(NA,NA))
    r <- pmin(qbinom(c(.025,.975), n, .5) + 1, n)  ## Exact 0.95 C.L.
    c(y[r[1]],y[r[2]])
}

In an upcoming release of the Hmisc package you can also get the Harrell-Davis distribution-free estimator of the median which is slightly more efficient than the traditional estimator, for small samples.  A new hdquantile function provides an estimate of the standard error for this estimator.

---
Frank E Harrell Jr    Professor and Chair            School of Medicine
                      Department of Biostatistics    Vanderbilt University



From spencer.graves at pdf.com  Sat Sep 27 15:33:57 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 27 Sep 2003 08:33:57 -0500
Subject: [R] Std. errors of intercept and slope
In-Reply-To: <Pine.LNX.4.44.0309262159020.5289-100000@bolker.zoo.ufl.edu>
References: <Pine.LNX.4.44.0309262159020.5289-100000@bolker.zoo.ufl.edu>
Message-ID: <3F7591C5.9010705@pdf.com>

See especially any discussion of "the matrix formulation of 
regression".  I'm sure this is in many books.  I'm not familiar with the 
recent literature, but I know it is in Draper and Smith, Applied 
Regression Analysis and Box, Hunter and Hunter, Statistics for 
Experimenters. 

Briefly, suppose we write the regression model as y = X b + e, where y 
and e are N x 1 vectors, X is an N x k matrix, and e is a vector of 
normal, independent errors with standard deviation s.e.  Then the least 
squares and maximum likelihood estimate of b is

      b.hat = (inverse(X' X))*(X'y),

and the covariance matrix for b.hat is

      var(b.hat) = s.e^2 * inverse(X'X). 

I apologize if this is too terse for you;  if so, please see any good 
book on regress. 

hope this helps.  spencer graves

Ben Bolker wrote:

>  I'm afraid you're going to have to look it up in a basic statistics 
>textbook.
>
>  Ben Bolker
>
>
>On Fri, 26 Sep 2003, Yao, Minghua wrote:
>
>  
>
>>Thanks, Ben.
>>
>>Could you tell me the formula for calculating this sd., given (x_i, y_i)
>>(i=1,2,...,N)?
>>We only have one intercept and slope for them.
>>
>>-Minghua
>>
>>-----Original Message-----
>>From: Ben Bolker [mailto:bolker at zoo.ufl.edu]
>>Sent: Friday, September 26, 2003 4:34 PM
>>To: Yao, Minghua
>>Cc: R Help (E-mail)
>>Subject: Re: [R] Std. errors of intercept and slope
>>
>>
>>
>>  Since the intercept and slope are estimated parameters, they have 
>>sampling distributions described by their means and standard deviations.  
>>The s.d. tells you the size of the uncertainty in intercept & in slope.
>>
>>  This is a pretty basic stats question -- you need to refer to a standard 
>>textbook or reference material ...
>>
>>  Ben Bolker
>>
>>On Fri, 26 Sep 2003, Yao, Minghua wrote:
>>
>>    
>>
>>>Dear all,
>>>
>>>I have the following output generated by linear regression. Since there is
>>>only one regression intercept and one slope for one set of data, what is
>>>      
>>>
>>the
>>    
>>
>>>meaning of std. error for intercept and that of slope? Thanks in advance.
>>>
>>>Sincerely,
>>>
>>>Minghua
>>>
>>>
>>>      
>>>
>>>>data(thuesen)
>>>>attach(thuesen)
>>>>lm(short.velocity~blood.glucose)
>>>>        
>>>>
>>>Call:
>>>lm(formula = short.velocity ~ blood.glucose)
>>>
>>>Coefficients:
>>>  (Intercept)  blood.glucose  
>>>      1.09781        0.02196  
>>>
>>>      
>>>
>>>>summary(lm(short.velocity~blood.glucose))
>>>>        
>>>>
>>>Call:
>>>lm(formula = short.velocity ~ blood.glucose)
>>>
>>>Residuals:
>>>     Min       1Q   Median       3Q      Max 
>>>-0.40141 -0.14760 -0.02202  0.03001  0.43490 
>>>
>>>Coefficients:
>>>              Estimate Std. Error t value Pr(>|t|)    
>>>(Intercept)    1.09781    0.11748   9.345 6.26e-09 ***
>>>blood.glucose  0.02196    0.01045   2.101   0.0479 *  
>>>---
>>>Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 
>>>
>>>Residual standard error: 0.2167 on 21 degrees of freedom
>>>Multiple R-Squared: 0.1737,     Adjusted R-squared: 0.1343 
>>>F-statistic: 4.414 on 1 and 21 DF,  p-value: 0.0479 
>>>
>>>      
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>
>>>      
>>>
>>    
>>
>
>  
>



From spencer.graves at pdf.com  Sat Sep 27 15:40:08 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 27 Sep 2003 08:40:08 -0500
Subject: [R] A re-sampling problem
In-Reply-To: <Law11-F7912Phgloi9s0002705b@hotmail.com>
References: <Law11-F7912Phgloi9s0002705b@hotmail.com>
Message-ID: <3F759338.9010208@pdf.com>

Have you looked at the discussion of bootstrapping in, e.g., Venables 
and Ripley (2002) Modern Applied Statistics with S, 4th ed. (Springer)? 

hope this helps.  spencer graves

Nathan Cooper wrote:

> I plan on analyzing some bird point count data. I need to develop a 
> re-sampling regime for data like this.
>
> I used scan(file="Sample.txt",what=list(0,0,0,0,0,0),sep="\t")
>
> [[1]]
> [1] 1 2 3 4 5
>
> [[2]]
> [1]  6  7  8  9 NA
>
> [[3]]
> [1] 10 11 12 13 NA
>
> [[4]]
> [1] 14 15 16 NA NA
>
> [[5]]
> [1] 17 18 19 20 21
>
> Each row represents one site and the numbers (1-21) are visits to that 
> site. I'm going to be figuring out how many visits to each site is 
> optimal so I will need to compare 1 visit to 2 visits to 3 visits etc. 
> Therefore I need to somehow sample 1,2,3,4,or 5 visits with 
> replacement from a random (with replacement) row 1000 times. Any 
> ideas? I'm relatively familiar with the sample() functoin but not sure 
> how to make it do this. I'm open to importing the data in a different 
> way if that would make it easier. Thanks,
>
> Nathan
>
> _________________________________________________________________
> Share your photos without swamping your Inbox.  Get Hotmail Extra 
> Storage today! http://join.msn.com/?PAGE=features/es
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From e.hagen at biologie.hu-berlin.de  Sat Sep 27 15:49:12 2003
From: e.hagen at biologie.hu-berlin.de (Ed Hagen)
Date: Sat, 27 Sep 2003 15:49:12 +0200
Subject: [R] frustration with ave()
Message-ID: <3F759558.6060406@biologie.hu-berlin.de>


Dear All,

I'm confused why I'm getting NA's in the output from ave() (at the end). Any 
help would be greatly appreciated.  I'm including the data in case that is where 
the problem lies:


 > f <- factor(FAMILYID)
 > bodyfat <- na.omit(data.frame(loessBODYFAT, f))
 > bodyfat$loessBODYFAT
   [1] -8.950153e-01 -9.175285e-01  3.174061e-01 -2.101260e-01  2.534174e-02
   [6]  1.846599e-01  8.322865e-01  1.348331e+00  1.241318e+00  1.634000e+00
  [11]  1.611048e+00  6.824926e-01  2.346168e+00  2.924673e-01  6.919381e-01
  [16]  3.142321e-01 -5.615214e-01  9.196103e-01 -1.290328e+00 -1.798727e+00
  [21] -1.011590e-01  7.051146e-01 -1.254440e+00  1.189397e+00 -7.017545e-01
  [26]  2.290020e-02 -1.451774e+00 -6.124868e-01 -4.780954e-01  3.237365e+00
  [31]  1.595977e+00  5.950309e-01 -4.699706e-01 -2.153001e-01 -3.248170e-01
  [36] -5.295042e-01  2.780444e-01 -5.878282e-01 -3.325859e-01 -7.690049e-02
  [41]  4.991054e-01 -4.410101e-01  9.133328e-01  1.429758e+00 -8.484772e-01
  [46] -1.004829e-01  1.769479e-01  3.892871e-01  7.209969e-01  3.759455e-01
  [51]  3.982560e-02 -1.702333e-01 -3.622422e-01 -2.893234e-01 -9.769459e-01
  [56] -1.935057e+00 -3.881132e-01 -1.037270e-02  2.561803e-01  3.884395e+00
  [61] -2.234557e-01 -6.893120e-01  3.531379e-01 -1.726464e+00  7.136614e-02
  [66] -4.278400e-01 -3.756271e-01  5.494344e-02  6.545344e-01  4.999740e-01
  [71]  4.911730e-01 -1.296921e-05  3.166220e+00  2.715371e-01 -6.104207e-01
  [76]  1.893740e+00  1.031131e+00 -5.917449e-01 -7.442768e-01  2.503388e+00
  [81] -4.087622e-01  4.399654e-01 -8.355297e-01  3.964619e-01  2.672100e-01
  [86] -3.927630e-01 -1.295004e+00 -1.874215e-01 -9.548985e-01 -1.366311e-01
  [91] -1.352021e+00 -9.658552e-01 -1.190914e+00 -1.910233e+00 -7.595405e-02
  [96] -1.648916e-01 -1.743877e-01 -1.234058e-01 -1.723277e+00 -7.316183e-01
[101] -8.062482e-01 -8.386729e-02  3.672521e-01 -7.525477e-01 -7.851946e-01
[106] -5.464147e-01 -1.454035e-01 -2.447245e-01 -4.732026e-01 -5.131587e-02
[111] -4.651404e-01  9.230189e-02  9.773851e-01  1.293947e-01 -3.261368e-01
[116] -1.671177e+00 -2.615938e-01  8.152311e-01  1.757506e-01  4.018943e-01
[121] -6.631180e-01 -1.839677e-01
 > bodyfat$f
   [1] 1  1  1  1  1  2  3  3  3  3  3  3  3  3  3  3  4  5  6  6  6  7  7
  [24] 7  7  8  9  9  9  9  9  9  9  9  9  9  9  10 10 10 11 11 11 11 12 12
  [47] 12 12 13 13 13 14 14 14 15 15 15 15 15 16 16 16 16 16 16 16 16 18 18
  [70] 18 18 20 21 21 22 22 22 23 23 23 23 23 25 25 25 30 30 30 31 31 31 31
  [93] 35 35 35 35 35 35 37 37 39 39 39 39 39 39 39 39 40 40 44 44 45 45 45
[116] 47 47 47 47 50 50 50
50 Levels: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 ... 50
 > ave(bodyfat$loessBODYFAT, bodyfat$f)
   [1] -3.359844e-01 -3.359844e-01 -3.359844e-01 -3.359844e-01 -3.359844e-01
   [6]  1.846599e-01  1.099428e+00  1.099428e+00  1.099428e+00  1.099428e+00
  [11]  1.099428e+00  1.099428e+00  1.099428e+00  1.099428e+00  1.099428e+00
  [16]  1.099428e+00 -5.615214e-01  9.196103e-01 -1.063405e+00 -1.063405e+00
  [21] -1.063405e+00 -1.542074e-02 -1.542074e-02 -1.542074e-02 -1.542074e-02
  [26]  2.290020e-02  1.476790e-01  1.476790e-01  1.476790e-01  1.476790e-01
  [31]  1.476790e-01  1.476790e-01  1.476790e-01  1.476790e-01  1.476790e-01
  [36]  1.476790e-01  1.476790e-01 -3.324382e-01 -3.324382e-01 -3.324382e-01
  [41]  6.002965e-01  6.002965e-01  6.002965e-01  6.002965e-01 -9.568124e-02
  [46] -9.568124e-02 -9.568124e-02 -9.568124e-02  3.789227e-01  3.789227e-01
  [51]  3.789227e-01 -2.739330e-01 -2.739330e-01 -2.739330e-01 -6.108618e-01
  [56] -6.108618e-01 -6.108618e-01 -6.108618e-01 -6.108618e-01  1.082750e-01
  [61]  1.082750e-01  1.082750e-01  1.082750e-01  1.082750e-01  1.082750e-01
  [66]  1.082750e-01  1.082750e-01 -1.296921e-05 -1.296921e-05 -1.296921e-05
  [71] -1.296921e-05  7.714833e-01  2.397139e-01  2.397139e-01 -5.728595e-02
  [76] -5.728595e-02 -5.728595e-02 -6.250627e-01 -6.250627e-01 -6.250627e-01
  [81] -6.250627e-01 -6.250627e-01 -6.066309e-01 -6.066309e-01 -6.066309e-01
  [86]  2.602143e-01  2.602143e-01  2.602143e-01 -2.354473e-01 -2.354473e-01
  [91] -2.354473e-01 -2.354473e-01            NA            NA            NA
  [96]            NA            NA            NA            NA            NA
[101]            NA            NA            NA            NA            NA
[106]            NA            NA            NA            NA            NA
[111]            NA            NA            NA            NA            NA
[116]            NA            NA            NA            NA            NA
[121]            NA            NA
 >

Thanks in advance,

Edward H. Hagen                  Institute for Theoretical Biology
phone: +49/30 2093-8649             Humboldt-Universit?t zu Berlin
fax:   +49/30 2093-8801                         Invalidenstra?e 43
http://itb.biologie.hu-berlin.de/~hagen      10115 Berlin, Germany



From spencer.graves at pdf.com  Sat Sep 27 16:02:24 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 27 Sep 2003 09:02:24 -0500
Subject: [R] Accessing coordinates of plotted contour lines (was "3d contours")
In-Reply-To: <3F7411EE.8A98D702@ysbl.york.ac.uk>
References: <3F7411EE.8A98D702@ysbl.york.ac.uk>
Message-ID: <3F759870.1040804@pdf.com>

	  I just listed "contour".  Unfortunately, the work is done by a call 
to ".Internal(contour(...)...)", and this call returns nothing.  It 
clearly computes what you want but does not return it.

	  Someone who knew what they were doing could get the source code for 
the internal contour function and modify it so it returned a list 
containing the lines plotted, and also modify contour.default so it 
returned the output of the internal contour function.  However, I don't 
know how to do that.

	  With luck, someone else will respond.

hope this helps.
Spencer Graves

#######################
Karim Elsawy wrote:

 >thanks a lot I recieved your reply
 >I sent this e-mail  just by mistake
 >what I'm realy looking for is the coordinates of the 3d isosurfaces I do
 >not want
 >just to plot them.
 >
 >thanks again
 >
 >Spencer Graves wrote:
 >
      I recieved and replied to this same post yesterday.  Did you
receive my reply?

      Also, have you searched www.r-project.org -> Search -> "R site
search"?

      hope this helps.  spencer graves

Karim Elsawy wrote:

>Hi,
>I wonder if there is any R package or function which produces the
>coordinates of a 3d contour (isosurface) 
>from a 3d data array.
>any suggestions are very much appreciated
>best regards
>karim
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From maechler at stat.math.ethz.ch  Sat Sep 27 18:56:17 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 27 Sep 2003 18:56:17 +0200
Subject: [R] CRAN mirror - howto?
In-Reply-To: <3F74E8FA.7000104@hppi.troitsk.ru>
References: <3F74E8FA.7000104@hppi.troitsk.ru>
Message-ID: <16245.49457.607981.434621@gargle.gargle.HOWL>

>>>>> "M" == M Kondrin <mkondrin at hppi.troitsk.ru>
>>>>>     on Fri, 26 Sep 2003 18:33:46 -0700 writes:

    M> Hello!  There is a group of administartors of Russian
    M> internet site www.linuxportal.ru (this is mainly a forum
    M> for linux-users) who are intended to host on this site
    M> mirrors of linux distributions and open source software
    M> with http and ftp access. I have proposed to them to open
    M> there a CRAN mirror, making a point what this site would
    M> be a first R mirror in .ru domain, and they seems to
    M> accept the idea.  Wouldn't you explain what is the
    M> procedure of opening of "official" CRAN mirror (i.e. site
    M> listed among CRAN mirrors on cran.r-project.org page) or
    M> whom I should contact with. I can not find this
    M> information on main R site.

Well, just make sure they *do* mirror CRAN to somewhere
(using rsync most easily), let's assume to  http://www.cran.linuxportal.ru/
Now they can ask cran at r-project.org to be added to the list of
mirrors and get a map 
http://cran.ru.r-project.org/ --> http://www.cran.linuxportal.ru/

Please ask (me or cran at ..) offline (and not earlier than Monday)
about the exact rsync command we ("CRAN.ch") are using for CRAN
mirroring.



From maechler at stat.math.ethz.ch  Sat Sep 27 19:11:14 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 27 Sep 2003 19:11:14 +0200
Subject: [R] Enquiry about Hierarchical Clustering
In-Reply-To: <6D9E9B9DF347EF4385F6271C64FB8D56075F81@BIONIC.biopolis.one-north.com>
References: <6D9E9B9DF347EF4385F6271C64FB8D56075F81@BIONIC.biopolis.one-north.com>
Message-ID: <16245.50354.270142.262991@gargle.gargle.HOWL>

>>>>> "Adaikalavan" == Adaikalavan RAMASAMY <ramasamya at gis.a-star.edu.sg>
>>>>>     on Sat, 27 Sep 2003 17:05:43 +0800 writes:

    Adaikalavan> Hclust is unable to handle missing values in
    Adaikalavan> dist().  There will be missing values in dist()
    Adaikalavan> function if 1. all elements in a row are
    Adaikalavan> missing 2. all pairs between any two rows have
    Adaikalavan> at least one missing values.

As Kjetial Halvorsen said,  use  daisy() from the cluster
package instead of dist().
The daisy() function has two advantages over dist():
1. Handling of missing values
2. Handling of data with continuous *and* categorical variables.

[Btw, this has not really anything to do with the clustering
 method used *after* the distance has been computed.
 You can use hclust() on a daisy result if you want]

Regards,
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From rpeng at jhsph.edu  Sat Sep 27 16:43:47 2003
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Sat, 27 Sep 2003 10:43:47 -0400
Subject: [R] data.frame -> matrix
In-Reply-To: <3015877718.20030927150950@mis.tutkie.tut.ac.jp>
References: <3015877718.20030927150950@mis.tutkie.tut.ac.jp>
Message-ID: <3F75A223.2090303@jhsph.edu>

I think data.matrix() is what you want.

-roger

Sokratis Alikhanidi wrote:
>    Dear colleagues,
> 
> I am beginner, so the primitive questions:
> in pls.pcr package in the function mvr I need to indicate a matrix of observations and a vector of responses.
> But read.table function returns the data.frame object.
> 
> What is the way for conversion of the data.frame object into matrix and vector objects?
> 
> And what is the way for writing the results down into file?
> 
> Thank you very much.
> 
> Sokratis.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From xma at arcturusag.com  Sat Sep 27 20:56:22 2003
From: xma at arcturusag.com (Xiao-Jun Ma)
Date: Sat, 27 Sep 2003 11:56:22 -0700
Subject: [R] coloring dendrgram in heatmap?
Message-ID: <BBAF0DEC119BD41193C100B0D0788DFE3FCEB7@GENOME>

Using the heatmap function in mva, it seems to be hard to use different
colors in the edges leading to different groups of objects, as commonly done
in many heatmaps in the microarray graphics. Any suggestions? Thanks.

max



From kjetil at entelnet.bo  Sat Sep 27 22:24:45 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Sat, 27 Sep 2003 16:24:45 -0400
Subject: [R] coloring dendrgram in heatmap?
In-Reply-To: <BBAF0DEC119BD41193C100B0D0788DFE3FCEB7@GENOME>
Message-ID: <3F75B9CD.16156.179BEC2@localhost>

On 27 Sep 2003 at 11:56, Xiao-Jun Ma wrote:

What about trying RColorBrewer, as mentioned in the docs of
heatmap. I had good results with that!

Kjetil Halvorsen

> Using the heatmap function in mva, it seems to be hard to use different
> colors in the edges leading to different groups of objects, as commonly done
> in many heatmaps in the microarray graphics. Any suggestions? Thanks.
> 
> max
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From xma at arcturusag.com  Sat Sep 27 23:45:30 2003
From: xma at arcturusag.com (Xiao-Jun Ma)
Date: Sat, 27 Sep 2003 14:45:30 -0700
Subject: [R] coloring dendrgram in heatmap?
Message-ID: <BBAF0DEC119BD41193C100B0D0788DFE3FCEB8@GENOME>

 No, I meant coloring the edges of the dendrogram on the left or top of the
image plot.


-----Original Message-----
From: kjetil brinchmann halvorsen
To: 'R-help at stat.math.ethz.ch '; 'Martin Maechler '
Sent: 9/27/03 1:24 PM
Subject: Re: [R] coloring dendrgram in heatmap?

On 27 Sep 2003 at 11:56, Xiao-Jun Ma wrote:

What about trying RColorBrewer, as mentioned in the docs of
heatmap. I had good results with that!

Kjetil Halvorsen

> Using the heatmap function in mva, it seems to be hard to use
different
> colors in the edges leading to different groups of objects, as
commonly done
> in many heatmaps in the microarray graphics. Any suggestions? Thanks.
> 
> max
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Yaqing.Gu-1 at ou.edu  Sun Sep 28 03:10:35 2003
From: Yaqing.Gu-1 at ou.edu (Yaqing Gu)
Date: Sat, 27 Sep 2003 20:10:35 -0500
Subject: [R] geodata conversion
Message-ID: <000e01c3855d$521fe2e0$cb730f81@coe.ou.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030927/d53002a5/attachment.pl

From j.baxter at ru.ac.za  Sun Sep 28 14:00:38 2003
From: j.baxter at ru.ac.za (Jeremy Baxter)
Date: Sun, 28 Sep 2003 14:00:38 +0200
Subject: [R] SA/ZA mirror
Message-ID: <200309281400.38382.j.baxter@ru.ac.za>

Hi all

Just to report that the South African mirror of CRAN should be back up on 
Monday (29/09/03). Our Information Tech dept have no idea who "broke" the 
process but assure me that it will be corrected by Monday.  Some of the files 
have finished downloading all ready. 

Sorry for the inconvenience caused!

Jeremy 
_______________________________________________
Jeremy Baxter, Statistics Department, Rhodes University, South Africa.
Views expressed above, no matter how badly spelt, are my own... I think?



From arc at arcriswell.com  Sun Sep 28 17:06:16 2003
From: arc at arcriswell.com (Andrew Criswell)
Date: Sun, 28 Sep 2003 22:06:16 +0700
Subject: [R] Logit reality check
Message-ID: <3F76F8E8.4020406@arcriswell.com>

Hello all:

I've been given the following data and have been asked to run a logit 
model using glm().  The variable, Y, is a proportion ranging from 0 to 
1, X is a covariate.  Without a base number of observations from which Y 
is computed as a proportion, I believe there is not sufficient information.

If I try the model below, R seems to grumble with a complaint.

glm(cbind(Y,1-Y) ~ X, family = binomial)

non-integer counts in a binomial glm! in: eval(expr, envir, enclos)

Am I correct to believe that more information is required?

Thanks,
ANDREW

             Y         X
 [1,]      0.40      41
 [2,]      0.19      69
 [3,]      0.20      60
 [4,]      0.29      85
 [5,]      0.14      48
 [6,]      0.20      32
 [7,]      0.11      69
 [8,]      0.28      17
 [9,]      0.35     115
[10,]     0.03      15
[11,]     0.14      11
[12,]     0.12      25



From tlumley at u.washington.edu  Sun Sep 28 17:36:48 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sun, 28 Sep 2003 08:36:48 -0700 (PDT)
Subject: [R] Logit reality check
In-Reply-To: <3F76F8E8.4020406@arcriswell.com>
References: <3F76F8E8.4020406@arcriswell.com>
Message-ID: <Pine.A41.4.58.0309280833150.92018@homer23.u.washington.edu>

On Sun, 28 Sep 2003, Andrew Criswell wrote:

> Hello all:
>
> I've been given the following data and have been asked to run a logit
> model using glm().  The variable, Y, is a proportion ranging from 0 to
> 1, X is a covariate.  Without a base number of observations from which Y
> is computed as a proportion, I believe there is not sufficient information.
>
> If I try the model below, R seems to grumble with a complaint.
>
> glm(cbind(Y,1-Y) ~ X, family = binomial)
>
> non-integer counts in a binomial glm! in: eval(expr, envir, enclos)
>
> Am I correct to believe that more information is required?

Yes, probably.

If they are proportions without a well-defined denominator you may be able
to model them using family=quasi() and specifying the link and variance
function for a logistic regression model.  You'd need to look at what the
variance function actually is, though.

McCullagh & Nelder's book has an example using proportions of leaf damage
that's a bit like this, although they end up using (mu(1-mu))^2 as the
variance function.

	-thomas



From larry.selby at worldnet.att.net  Sun Sep 28 06:00:16 2003
From: larry.selby at worldnet.att.net (Larry Selby)
Date: Sat, 27 Sep 2003 21:00:16 -0700
Subject: [R] Help
Message-ID: <000601c38575$0830f580$d285520c@pavilion>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030927/ace7bb49/attachment.pl

From jean.vidal at freesurf.fr  Sun Sep 28 18:08:21 2003
From: jean.vidal at freesurf.fr (Jean Vidal)
Date: Sun, 28 Sep 2003 18:08:21 +0200
Subject: [R] Problem with sas.get function in Hmisc library
Message-ID: <oprv7wf7z0x0obw2@mail.freesurf.fr>


I tried to use for the first time the Frank Harell's sas.get function (in 
Hmisc library)
and cannot manage to import my sas datas.

When I use the sas.get(library,member, ...) method, I get the following 
error :
> sas.get("pme","Edfv1_a")->test.import.sas
Error in sas.get("pme", "Edfv1_a") : library, "pme", is not a Unix 
directory
In addition: Warning message: pme/formats.sc? or formats.sas7bcat  not 
found. Formatting ignored. in: sas.get("pme", "Edfv1_a") 'rm' n'est pas 
reconnu en tant que commande interne
ou externe, un programme ex?cutable ou un fichier de commandes.

Is it supposed to work only on a Unix machine ?

So, let's try the second approach : running the sas_get macro and then 
importing
the 4 files with sas.get(sasout...

> mydata <-sas.get(sasout=c('dict','data','formats','specmiss'),id='ident')
Error in sas.get(sasout = c("dict", "data", "formats", "specmiss"), id = 
"ident") : unused argument(s) (sasout ...)

And effetively, there seems to be no 'sasout' argument in the function call 
:
"function (library, member, variables = character(0), ifs = character(0), 
format.library = library, id, dates. = c("sas", "yymmdd", "yearfrac", 
"yearfrac2"), keep.log = TRUE, log.file = "_temp_.log", macro = 
sas.get.macro, data.frame.out = existsFunction("data.frame"), clean.up = 
TRUE, quiet = FALSE, temp = tempfile("SaS"), formats = TRUE, recode = 
formats, special.miss = FALSE, sasprog = "sas", as.is = 0.5, 
check.unique.id = TRUE, force.single = FALSE, where, uncompress = FALSE) "

Am I missing something ?

Using :
Package: Hmisc
Version: 2.0-0
Date: 2003-07-10
Title: Harrell Miscellaneous

> version
         _              platform i386-pc-mingw32
arch     i386           os       mingw32        system   i386, mingw32  
status                  major    1              minor    7.1            
year     2003           month    06             day      16             
language R



From meyer at ci.tuwien.ac.at  Sun Sep 28 18:17:20 2003
From: meyer at ci.tuwien.ac.at (David Meyer)
Date: Sun, 28 Sep 2003 18:17:20 +0200 (CEST)
Subject: [R] Logit reality check
In-Reply-To: <Pine.A41.4.58.0309280833150.92018@homer23.u.washington.edu>
Message-ID: <Pine.LNX.4.21.0309281815140.25749-100000@boromir.ci.tuwien.ac.at>

> > If I try the model below, R seems to grumble with a complaint.
> >
> > glm(cbind(Y,1-Y) ~ X, family = binomial)
> >
> > non-integer counts in a binomial glm! in: eval(expr, envir, enclos)
> >

For binomial models (as described in the help page), the response must be
either a factor or a n x 2 matrix with the numbers of successes of
failures, not the proportions.

g.,
David



From fredrik.karlsson at ling.umu.se  Sun Sep 28 20:43:45 2003
From: fredrik.karlsson at ling.umu.se (Fredrik Karlsson)
Date: Sun, 28 Sep 2003 20:43:45 +0200
Subject: [R] Help regarding repeated measures needed.
Message-ID: <20030928184345.GA5249@ling.umu.se>

Dear list, 

I feel that I have to contact you for help with the data set I
collected. It concerns longitudinal data from acoustic measurements
conducted at monthly invervals during the development of a group of
children. In the synchronic perspective, I have found that it is highly
unlikely that the data is normally distributed. Furthermore, other
studies have shown a decreasing variance with increasing age.

So, what I want to ask you is: 

1) What do I do with this data. Is it possible to do statistical
analysis on this?

2) What approach do you recommend? What are the potential draw-backs?

3) Do you have some litterature suggestions for me?

4) If there is something that I can do, is it implemented in R? 


I'm sure that you can tell that I would be happy for any help I could
get on this issue.

/Fredrik Karlsson



From baud-bovy.gabriel at hsr.it  Sun Sep 28 21:45:20 2003
From: baud-bovy.gabriel at hsr.it (Gabriel Baud-Bovy)
Date: Sun, 28 Sep 2003 21:45:20 +0200
Subject: [R] Turtle world
Message-ID: <5.2.1.1.1.20030928174948.00b66f18@mail.hsr.it>

Dear all,

I am trying to do a "loose" implementation in R of the Turtle World (LOGO) and
need some advices on graphical issues.

In its current very simple implementation, the user can give order to the 
the turtle to
move through the console. The current position and movements are displayed
graphically (see below).  In the future, I would like to permit the turtle 
to interact
with objects (walls, light source, another turtle, etc.) in the world.

Right now, I am using the windows device and standard plotting functions:

- plot.new() and plot.window() for setting up and clearing the world
- segments() to plot a line representing the displacement of the turtle
- polygone(x,y,border) to plot the turtle

Before the turtle is moved, I "erased" it by calling polygon with 
border="#FFFFFF" before
redrawing it with another call to polygon with border=1. The problem with 
this approach
is that it "erases" also any line already drawn under the turtle.  To solve 
this problem, I
have considered the following approaches:

- redraw the world each time the turtles moves (this would mean that I have 
acess to the
display list or that I manage one). I believe that this might be possible 
with the grid package
but I am not sure if this is the best option.
- if I could have access to the internal buffer that corresponds to the 
window, I could store (or XrOR) the
section of the buffer when I draw the turtle to restore it when the turtle 
moves.

Ideally, the approach should be take into account possible development of 
the turtle world. For
example, if the  turtle world is represented by a matrix (bitmap), I could 
use image() (or the
package  pixmap)  do display it but it is quite slow to draw the entire 
world each time the
world changes (e.g., the turtle move). I would also need to define a new 
"line" function that would
draw the displacement of the turtle in the world.

Alternatively, objects and turtle's movements could be represented by 
display lists. But I
would have to define functions to do the rendering as well as to find out 
when the turtle
"intersect" with the object.

Is there any R package (tcl/tk, grid, RGL) that can be adapted to my needs? 
Is there R a package
that does 2D graphics? If I need to do some programming in C, is there 
anything I could use as a
starting point? Any idea, comment would be most welcome.

Gabriel Baud-Bovy



From tblackw at umich.edu  Sun Sep 28 22:05:43 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Sun, 28 Sep 2003 16:05:43 -0400 (EDT)
Subject: [R] frustration with ave()
In-Reply-To: <3F759558.6060406@biologie.hu-berlin.de>
References: <3F759558.6060406@biologie.hu-berlin.de>
Message-ID: <Pine.SOL.4.58.0309281545440.26147@millipede.gpcc.itd.umich.edu>

Ed  -

You seem to have encountered a bug.  I can reproduce Ed's difficulty
in a completely artificial example in which there are unused levels :

tmp <- factor(rep(seq(10), seq(10)))     #  length(tmp) # [1] 55
ave(seq(50), tmp[-seq(5)])               #  gives NA in rows 32-50

I would consider this to be incorrect behavior for the function
ave().  For the base package maintainers, I would suggest modifying
the definition of  ave()  so that the line involving  as.factor()
reads :

         l[[i]] <- li <- as.factor(l[[i]][,drop=T]) .

However, I have not thought through whether  ave()  could ever
be called with a grouping variable of dimension greater than 1,
or what consequence that would have for the proposed fix.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Sat, 27 Sep 2003, Ed Hagen wrote:

> I'm confused why I'm getting NA's in the output from ave() (at the end). Any
> help would be greatly appreciated.  I'm including the data in case that is where
> the problem lies:
>
>  > f <- factor(FAMILYID)
>  > bodyfat <- na.omit(data.frame(loessBODYFAT, f))
>  > bodyfat$loessBODYFAT
>      ...
>  > bodyfat$f
>    [1] 1  1  1  1  1  2  3  3  3  3  3  3  3  3  3  3  4  5  6  6  6  7  7
>   [24] 7  7  8  9  9  9  9  9  9  9  9  9  9  9  10 10 10 11 11 11 11 12 12
>   [47] 12 12 13 13 13 14 14 14 15 15 15 15 15 16 16 16 16 16 16 16 16 18 18
>   [70] 18 18 20 21 21 22 22 22 23 23 23 23 23 25 25 25 30 30 30 31 31 31 31
>   [93] 35 35 35 35 35 35 37 37 39 39 39 39 39 39 39 39 40 40 44 44 45 45 45
> [116] 47 47 47 47 50 50 50
> 50 Levels: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 ... 50
>  > ave(bodyfat$loessBODYFAT, bodyfat$f)
>      ...
>   [81] -6.250627e-01 -6.250627e-01 -6.066309e-01 -6.066309e-01 -6.066309e-01
>   [86]  2.602143e-01  2.602143e-01  2.602143e-01 -2.354473e-01 -2.354473e-01
>   [91] -2.354473e-01 -2.354473e-01            NA            NA            NA
>   [96]            NA            NA            NA            NA            NA
> [101]            NA            NA            NA            NA            NA
> [106]            NA            NA            NA            NA            NA
> [111]            NA            NA            NA            NA            NA
> [116]            NA            NA            NA            NA            NA
> [121]            NA            NA
>
> Thanks in advance,
>
> Edward H. Hagen                  Institute for Theoretical Biology
> phone: +49/30 2093-8649             Humboldt-Universit?t zu Berlin
> fax:   +49/30 2093-8801                         Invalidenstra?e 43
> http://itb.biologie.hu-berlin.de/~hagen      10115 Berlin, Germany



From tblackw at umich.edu  Sun Sep 28 22:23:41 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Sun, 28 Sep 2003 16:23:41 -0400 (EDT)
Subject: [R] frustration with ave()
In-Reply-To: <3F759558.6060406@biologie.hu-berlin.de>
References: <3F759558.6060406@biologie.hu-berlin.de>
Message-ID: <Pine.SOL.4.58.0309281622190.2045@millipede.gpcc.itd.umich.edu>

Maintainers  -  I should have said I am running R 1.7-1 on
RedHat Linux 8.0.  -  tom blackwell  -  u michigan medical school  -



From p.dalgaard at biostat.ku.dk  Sun Sep 28 22:28:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Sun, 28 Sep 2003 20:28:03 -0000
Subject: [R] frustration with ave()
In-Reply-To: <Pine.SOL.4.58.0309281545440.26147@millipede.gpcc.itd.umich.edu>
References: <3F759558.6060406@biologie.hu-berlin.de>
	<Pine.SOL.4.58.0309281545440.26147@millipede.gpcc.itd.umich.edu>
Message-ID: <x24qyw8xo6.fsf@biostat.ku.dk>

Thomas W Blackwell <tblackw at umich.edu> writes:

> Ed  -
> 
> You seem to have encountered a bug.  I can reproduce Ed's difficulty
> in a completely artificial example in which there are unused levels :
> 
> tmp <- factor(rep(seq(10), seq(10)))     #  length(tmp) # [1] 55
> ave(seq(50), tmp[-seq(5)])               #  gives NA in rows 32-50
> 
> I would consider this to be incorrect behavior for the function
> ave().  For the base package maintainers, I would suggest modifying
> the definition of  ave()  so that the line involving  as.factor()
> reads :
> 
>          l[[i]] <- li <- as.factor(l[[i]][,drop=T]) .

A minimal version of the same effect would be

> ave(1:2,factor(2:3,levels=1:3))
[1]  2 NA

Your fix looks sensible to me, but it might be better with simply

>          l[[i]] <- li <- factor(l[[i]]) 


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From jasont at indigoindustrial.co.nz  Sun Sep 28 22:31:10 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Sun, 28 Sep 2003 20:31:10 -0000
Subject: [R] geodata conversion
In-Reply-To: <000e01c3855d$521fe2e0$cb730f81@coe.ou.edu>
References: <000e01c3855d$521fe2e0$cb730f81@coe.ou.edu>
Message-ID: <1064781593.12752.75.camel@kryten.akl.indigoindustrial.co.nz>

On Sun, 2003-09-28 at 13:10, Yaqing Gu wrote:
> Hey,
> I have a data set of 1.20MB. I used read.table( ) to read in the data and then 
> tried to convert it to geodata type. But it failed and I got 
> "Error in vector("double", length) : cannot allocate vector of length 1351974000" message.
> All the commands I used were:
> 
>     rawdata<-read.table(file=" ")
>    datag<-as.geodata(rawdata)
> 
> BTW, what is the biggest origin data size as.geodata( ) can convert? 

Depends how much memory R can give it.

Check

help(Memory)

and read the FAQs.  You'll find them under "Miscelaneous Items", in the
browser, after you use the command "help.start()"

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
+64-(0)21-343-545



From hu at mshri.on.ca  Mon Sep 29 05:57:04 2003
From: hu at mshri.on.ca (Pingzhao Hu)
Date: Sun, 28 Sep 2003 23:57:04 -0400
Subject: [R] problem in integrating C routine with R on windows XP
Message-ID: <490D0AFAF3D2D3119F6C00508B6FDF15026CE84F@ex.mshri.on.ca>

Hi All,
I a C function code, which has been successed in integrating
with Splus on Unix. Now I want to move it on windows.
So I want to integrate this C function with R on windows XP.

I download tools.zip and saved it in c:\bin  directory,
download  MinGW and saved it in c:\MinGw directory,
download Perl and saved it in c:\Perl directory.

My path is set as:

 
C:\bin;C:\MinGW\bin;C:\Perl\bin;%SystemRoot%\system32;%SystemRoot%;%SystemRo
ot%\System32\Wbem;C:\Program Files\Common Files\Adaptec
Shared\System;c:\matlab6p5\bin\win32;

When I input the following command:

c:\rw1071\bin>   Rcmd SHLIB -o simu.dll simu.c

I met the following problem:

'make' is not recognized as an internal or external command,
operable program or batch file.

Could any one tell me the problem here? which steps I have lost or the path
has not been correctly set???

Thank you for your help in advance!

Ping



From p.dalgaard at biostat.ku.dk  Mon Sep 29 08:55:52 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: Mon, 29 Sep 2003 06:55:52 -0000
Subject: [R] problem in integrating C routine with R on windows XP
In-Reply-To: <490D0AFAF3D2D3119F6C00508B6FDF15026CE84F@ex.mshri.on.ca>
References: <490D0AFAF3D2D3119F6C00508B6FDF15026CE84F@ex.mshri.on.ca>
Message-ID: <x2vfrc6q0h.fsf@biostat.ku.dk>

Pingzhao Hu <hu at mshri.on.ca> writes:

> Hi All,
> I a C function code, which has been successed in integrating
> with Splus on Unix. Now I want to move it on windows.
> So I want to integrate this C function with R on windows XP.
> 
> I download tools.zip and saved it in c:\bin  directory,
> download  MinGW and saved it in c:\MinGw directory,
> download Perl and saved it in c:\Perl directory.
> 
> My path is set as:
> 
>  
> C:\bin;C:\MinGW\bin;C:\Perl\bin;%SystemRoot%\system32;%SystemRoot%;%SystemRo
> ot%\System32\Wbem;C:\Program Files\Common Files\Adaptec
> Shared\System;c:\matlab6p5\bin\win32;
> 
> When I input the following command:
> 
> c:\rw1071\bin>   Rcmd SHLIB -o simu.dll simu.c
> 
> I met the following problem:
> 
> 'make' is not recognized as an internal or external command,
> operable program or batch file.
> 
> Could any one tell me the problem here? which steps I have lost or the path
> has not been correctly set???

Did you unpack tools.zip correctly? You should end up having a
make.exe in C:\bin, and with the path above that should work. 

Another trap to fall in is that setting the path (via GUI) on XP sets
the path for *subsequent* shells, not those that are open at the time. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From maechler at stat.math.ethz.ch  Mon Sep 29 09:24:35 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 29 Sep 2003 09:24:35 +0200
Subject: [R] a. crossing branches with hclust, b. plot.dendrogram
In-Reply-To: <3F74B883.4346F756@icsi.berkeley.edu>
References: <3F74B883.4346F756@icsi.berkeley.edu>
Message-ID: <16247.56883.63784.219987@gargle.gargle.HOWL>

>>>>> "Petra" == Petra Steiner <petra at icsi.berkeley.edu>
>>>>>     on Fri, 26 Sep 2003 15:06:59 -0700 writes:

    Petra> Hello, a. when I use hclust with the methods media,
"median"
    Petra> centroid, and mcquitty, and plot the results, the
    Petra> dendrograms have lines that are crossing each
    Petra> other. Is this ok?

yes.  It is known in the litterature that only some methods
(those that are `monotone') are guaranteed to produce
dendrograms without "reversal"s or "inversion"s.   I don't have
the complete theory handy, but I know that "centroid" is known
*not* to fulfill the property and "single", "complete" and
"average" linkage *are*.

    Petra> b. My next question refers to plot.dendrogram: How
    Petra> can I use parameters as "hang" or "cex" here?
    Petra> E.g. for

    Petra> st <- as.dendrogram(subtreeshc[[x]])

The vertical position of nodes is part of the dendrogram
definition,
hence use
   st <- as.dendrogram(subtreeshc[[x]],  hang = ...)

Where as "cex" can be specified using `nodePar', see the
examples on help(plot.dendrogram).

    Petra> I would like to have something like this, where cex
    Petra> and hang would work:

    Petra> plot(st, frame.plot=F, cex = 0.4, hang = 0, sub = "",
    Petra> xlab = "", ylab="", main = paste("Distance: ", me, "
    Petra> - Clustering Method: ", mecl, " - Subtree ", x,
    Petra> collapse="", sep=""))

    Petra> Thanks and best regards, Petra

You're welcome.
-- 
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From ligges at statistik.uni-dortmund.de  Mon Sep 29 08:33:34 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 29 Sep 2003 08:33:34 +0200
Subject: [R] problem in integrating C routine with R on windows XP
In-Reply-To: <490D0AFAF3D2D3119F6C00508B6FDF15026CE84F@ex.mshri.on.ca>
References: <490D0AFAF3D2D3119F6C00508B6FDF15026CE84F@ex.mshri.on.ca>
Message-ID: <3F77D23E.4010607@statistik.uni-dortmund.de>

Pingzhao Hu wrote:

> Hi All,
> I a C function code, which has been successed in integrating
> with Splus on Unix. Now I want to move it on windows.
> So I want to integrate this C function with R on windows XP.
> 
> I download tools.zip and saved it in c:\bin  directory,
> download  MinGW and saved it in c:\MinGw directory,
> download Perl and saved it in c:\Perl directory.
> 
> My path is set as:
> 
>  
> C:\bin;C:\MinGW\bin;C:\Perl\bin;%SystemRoot%\system32;%SystemRoot%;%SystemRo
> ot%\System32\Wbem;C:\Program Files\Common Files\Adaptec
> Shared\System;c:\matlab6p5\bin\win32;


Leave out the last semicolon.



> When I input the following command:
> 
> c:\rw1071\bin>   Rcmd SHLIB -o simu.dll simu.c
> 
> I met the following problem:
> 
> 'make' is not recognized as an internal or external command,
> operable program or batch file.
> 
> Could any one tell me the problem here? which steps I have lost or the path
> has not been correctly set???
> 
> Thank you for your help in advance!
> 
> Ping
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


You might also want to read ...\src\gnuwin32\install to set up an 
environment for compiling R completely (e.g. LaTeX for generating help 
files, manuals, vignettes, etc.). That's sufficient for compiling 
packages (you won't need everything, but it doesn't hurt having too much 
installed).

Uwe Ligges



From Simon.Fear at synequanon.com  Mon Sep 29 11:12:41 2003
From: Simon.Fear at synequanon.com (Simon Fear)
Date: Mon, 29 Sep 2003 10:12:41 +0100
Subject: [R] CI on median
Message-ID: <6C8A8033ABC1E3468048ABC4F13CE572AC0DF5@synequanon01>

You can also get CIs for medians as a side effect of boxplot.

If for some reason you need to get the same result as you
would get from SAS, you could use the following (non-optimised
but hopefully intelligible) instead.

HTH

###############################################
# 95% confidence interval function for the median
# prints out CI, returns invisible list of median.hat, lowlim, highlim
# matches the output of SAS proc FREQ CIPCTLDF option
###############################################
#
"ci.median.sas" <- function(x, do.print=TRUE)
{
x <- x[!is.na(x)]
median.hat <- median(x)
nobs <- length(x)
x.ranked <- sort(x)
if (nobs < 2 ) {
  if (do.print) print(paste(median.hat, " (---, ---)", sep = ""))
  invisible(return(median.hat, lowlim=NA, highlim=NA))
}
# in general, rank of low cutoff point is the position of q in 0:nobs,
so add
one
# to give the position in 1:nobs
lowrank <- qbinom(0.025, nobs, 0.5) + 1
# but make sure that this choice does not use up too much probability,
making
a
# 95% interval impossible (except for very small samples, low will
always be
one):
plow <- pbinom(lowrank-1, nobs, 0.5) 
if (plow > 0.05 && lowrank > 1) {
  lowrank <- lowrank - 1
  plow <- pbinom(lowrank-1, nobs, 0.5)
}
# then find the corresponding high cutoff giving (better than) 95%
coverage
overall:
# nb for very small samples plow will still exceed 0.05, so we use
min(1,p)
to
# prevent potential eror
highrank <- qbinom(min(1, 0.95+plow), nobs, 0.5) + 1
# again +1 for index in 1:nobs rather than 0:nobs
lowlim <- x.ranked[lowrank]
highlim <- x.ranked[min(highrank, nobs)]
if (do.print) print(paste(median.hat, " (", lowlim, ", ", highlim, ")",
sep =
""))
invisible(return(median.hat, lowlim, highlim))
}
 

Simon Fear
Senior Statistician
Syne qua non Ltd
Tel: +44 (0) 1379 644449
Fax: +44 (0) 1379 644445
email: Simon.Fear at synequanon.com
web: http://www.synequanon.com
 
Number of attachments included with this message: 0
 
This message (and any associated files) is confidential and\...{{dropped}}



From elsawy at ysbl.york.ac.uk  Mon Sep 29 12:03:00 2003
From: elsawy at ysbl.york.ac.uk (Karim Elsawy)
Date: Mon, 29 Sep 2003 11:03:00 +0100
Subject: [R] rgl crashes R
References: <3.0.5.32.20030908131309.007d7790@pop-server.ucl.ac.uk>
Message-ID: <3F780354.2746F52A@ysbl.york.ac.uk>

I was using rgl library and it was going well, all of a sudden it
started to crash 
which leads R to quit giving this error message

X Error of failed request:  BadValue (integer parameter out of range for
operation)
  Major opcode of failed request:  142 (XFree86-DRI)
  Minor opcode of failed request:  13 ()
  Value in failed request:  0x2e00067
  Serial number of failed request:  705
  Current serial number in output stream:  705

what is intriguing is that when I re-run R it works only for the first
time and fails
again every second time

this almost the same script I used:
step.x<-20;step.y<-20;step.z<-15
xseq <- seq(-300,300,step.x)
yseq<-  seq(-300,300,step.y)
zseq <- seq(-105,105,step.z)
library(rgl)
       rgl.open() 
      
rgl.bbox(xseq,yseq,zseq,xlab=xseq,ylab=yseq,zlab=zseq,color="yellow")
min.tmp<-c(2.2,4.5,9.3)
rgl.spheres(min.tmp[1],min.tmp[2],min.tmp[3],radius=10)

and I'm using R 1.7.1 under linux red hat

any ideas what is going wrong
best regards
karim



From laurent.faisnel at ariase.com  Mon Sep 29 12:46:32 2003
From: laurent.faisnel at ariase.com (Laurent Faisnel)
Date: Mon, 29 Sep 2003 12:46:32 +0200
Subject: [R] problems trying to extend a class
Message-ID: <3F780D88.9090800@ariase.com>

Hi all,

I have been using for quite a long time a script where a class extends 
another one (without trouble). But I now have problems of that kind 
while trying to run the script :

Error in insertMethod(methods, sig, args, def, TRUE) :
         inserting method corresponding to empty signature

I think this may be because the way I wrote the scripts could be 
deprecated. Indeed I recently upgraded to R-1.7.1 (I compiled it from 
source). I use R on a RedHat 8.0 system.

This is how my classes look like :

#-----------------------------------------------------
# CLASS    Person
#-----------------------------------------------------

setClass("Person",representation(name="character"));

# CONSTRUCTOR

setMethod("initialize","Person",
           function(.Object)
           {
               .Object at name <- "Unknown"; # default name
               return(.Object);
           }
);

#-----------------------------------------------------
# CLASS    Employee           (extends Person)
#-----------------------------------------------------

setClass("Employee",representation("Person", service="character", 
con="MySQLConnection"));

# con : connection to be established with MySQL database

# constructor
setMethod("initialize","Employee",
           function(.Object)
           {
               .Object <- callNextMethod();  # calls the superclass 
constructor
             .Object at con <- dbConnect("MySQL");
             .Object at service <- "unknown service";
             return(.Object);
           }
);

The script just creates a new Employee and the error occurs when it 
comes to callNextMethod() :

 > library(RMySQL)
 > new("Person")
An object of class "Person"
Slot "name":
[1] "Unknown"
 >
 > new("Employee")
Error in insertMethod(methods, sig, args, def, TRUE) :
         inserting method corresponding to empty signature

Any help would be greatly appreciated.
Laurent

PS : I've read there's something related to this in R-1.7.1's new 
features, but it does not seem to match the problem exactly ("problems 
that used to wait until new() is called to appear are now caught 
properly"). Is the initialize() function deprecated ? Should I use 
prototype instead ?



From debrc.stage1 at bch.ap-hop-paris.fr  Mon Sep 29 14:14:42 2003
From: debrc.stage1 at bch.ap-hop-paris.fr (=?iso-8859-1?Q?xavi=E8re_panhard?=)
Date: Mon, 29 Sep 2003 14:14:42 +0200
Subject: [R] Integrating R functions in C routines
Message-ID: <000c01c38683$43ad3b50$ed2101a4@biostat8>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030929/655a7982/attachment.pl

From vtas at uosis.mif.vu.lt  Mon Sep 29 14:24:30 2003
From: vtas at uosis.mif.vu.lt (vtas@uosis.mif.vu.lt)
Date: Mon, 29 Sep 2003 15:24:30 +0300 (EEST)
Subject: [R] parametric surfaces
Message-ID: <1445.193.219.42.106.1064838270.squirrel@kedras.mif.vu.lt>

Hi,
does anyone know how to plot 3D parametric surface,e.g ellipsoid:
x=a*cos(s)*cos(t),
y=b*sin(s)*cos(t),
z=sin(t);
s in [0,2*pi],
t in [-pi,pi].

Vytautas Maniusis,
Vilnius University, Lithuania



From andy_liaw at merck.com  Mon Sep 29 14:28:03 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 29 Sep 2003 08:28:03 -0400
Subject: [R] coloring dendrgram in heatmap?
Message-ID: <3A822319EB35174CA3714066D590DCD50205CBB5@usrymx25.merck.com>

> From: Xiao-Jun Ma [mailto:xma at arcturusag.com] 
> 
>  No, I meant coloring the edges of the dendrogram on the left 
> or top of the image plot.
 
I'm not sure if this can be done with the current plot.dendrogram() (which
heatmap() calls to draw the trees).  You may want to experiment with the
edgePar argument and see if that can give you trees with different colors in
the branches.  If not, you'll need to hack into plot.dendrogram() and DIY.
(Martin would know this for sure...)

Best,
Andy
 
> -----Original Message-----
> From: kjetil brinchmann halvorsen
> To: 'R-help at stat.math.ethz.ch '; 'Martin Maechler '
> Sent: 9/27/03 1:24 PM
> Subject: Re: [R] coloring dendrgram in heatmap?
> 
> On 27 Sep 2003 at 11:56, Xiao-Jun Ma wrote:
> 
> What about trying RColorBrewer, as mentioned in the docs of 
> heatmap. I had good results with that!
> 
> Kjetil Halvorsen
> 
> > Using the heatmap function in mva, it seems to be hard to use
> different
> > colors in the edges leading to different groups of objects, as
> commonly done
> > in many heatmaps in the microarray graphics. Any 
> suggestions? Thanks.
> > 
> > max
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list 
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> 
> 
> ______________________________________________
> 
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
>



From spencer.graves at pdf.com  Mon Sep 29 14:41:40 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 29 Sep 2003 07:41:40 -0500
Subject: [R] parametric surfaces
In-Reply-To: <1445.193.219.42.106.1064838270.squirrel@kedras.mif.vu.lt>
References: <1445.193.219.42.106.1064838270.squirrel@kedras.mif.vu.lt>
Message-ID: <3F782884.6050502@pdf.com>

Have you looked at "contour" and "persp" (plue "outer")?  Venables and 
Ripley (2002) Mondern Applied Statistics with S (Springer) provide 
useful examples. 

hope this helps.  spencer graves

vtas at uosis.mif.vu.lt wrote:

>Hi,
>does anyone know how to plot 3D parametric surface,e.g ellipsoid:
>x=a*cos(s)*cos(t),
>y=b*sin(s)*cos(t),
>z=sin(t);
>s in [0,2*pi],
>t in [-pi,pi].
>
>Vytautas Maniusis,
>Vilnius University, Lithuania
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From hdoran at nasdc.org  Mon Sep 29 15:11:54 2003
From: hdoran at nasdc.org (Harold Doran)
Date: Mon, 29 Sep 2003 09:11:54 -0400
Subject: [R] Downloading LME4?
Message-ID: <66578BFC0BA55348B5907A0F798EE93013A099@ernesto.NASDC.ORG>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030929/82ce3410/attachment.pl

From jmacdon at med.umich.edu  Mon Sep 29 15:21:17 2003
From: jmacdon at med.umich.edu (James MacDonald)
Date: Mon, 29 Sep 2003 09:21:17 -0400
Subject: [R] Downloading LME4?
Message-ID: <sf77f9a9.090@med-gwia-02a.med.umich.edu>

I don't think there is a compiled version of this library, so you will
have to compile and install yourself. See question 3.1 of the R for
Windows FAQ.

In addition, the fact that there is not a compiled version on CRAN may
indicate a problem with this package on Windows.

HTH,

Jim

James W. MacDonald
Affymetrix and cDNA Microarray Core
University of Michigan Cancer Center
1500 E. Medical Center Drive
7410 CCGC
Ann Arbor MI 48109
734-647-5623

>>> "Harold Doran" <hdoran at nasdc.org> 09/29/03 09:11AM >>>
Dear R:
 
Am I having trouble downloading the LME4 library. I am using Windows
and am using ver 1.7 I have tried the following:
 
1) Install package from CRAN, but LME4 is not listed
 
2) Downloaded LME4 from http://cran.us.r-project.org/, however, I
cannot open the file when I try install from local drive. I get the
following error:
 
Error in file(file, "r") : unable to open connection
In addition: Warning messages: 
1: error 1 in extracting from zip file 
2: cannot open file `lme4_0.3-7.tar.gz/DESCRIPTION' 
 
Any help is appreciated.
 
 
 
------
Harold C. Doran
Director of Research and Evaluation
New American Schools
675 N. Washington Street, Suite 220
Alexandria, Virginia 22314
703.647.1628
 <http://www.edperform.net/>  
 
 
 

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From bates at stat.wisc.edu  Mon Sep 29 15:33:09 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 29 Sep 2003 13:33:09 -0000
Subject: [R] Downloading LME4?
In-Reply-To: <66578BFC0BA55348B5907A0F798EE93013A099@ernesto.NASDC.ORG>
References: <66578BFC0BA55348B5907A0F798EE93013A099@ernesto.NASDC.ORG>
Message-ID: <6rwubrlnwf.fsf@bates4.stat.wisc.edu>

"Harold Doran" <hdoran at nasdc.org> writes:

> Am I having trouble downloading the LME4 library. I am using Windows
> and am using ver 1.7 I have tried the following:
>  
> 1) Install package from CRAN, but LME4 is not listed

There is no precompiled version of lme4 for Windows because the last
version I uploaded caused an error under R-1.7.1.  I used a function
that will be available in R-1.8.0 but not in R-1.7.1

I have another version that does install successfully under R-1.7.1
but does not install under R-1.8.0 (beta).  I'm going to try to
isolate the problem later today.  Even if I am not successful in
getting it to load under 1.8.0 I will upload it for 1.7.1 and work on
the 1.8.0 problem before the release of 1.8.0.

Short reply: There should be a Windows version on CRAN within 3
days.

> 2) Downloaded LME4 from http://cran.us.r-project.org/, however, I cannot open the file when I try install from local drive. I get the following error:
>  
> Error in file(file, "r") : unable to open connection
> In addition: Warning messages: 
> 1: error 1 in extracting from zip file 
> 2: cannot open file `lme4_0.3-7.tar.gz/DESCRIPTION' 

It looks like you were trying to load the source package as if it was
a binary package.



From ozric at web.de  Mon Sep 29 15:30:59 2003
From: ozric at web.de (ozric@web.de)
Date: Mon, 29 Sep 2003 15:30:59 +0200
Subject: [R] ROracle - Windows? 
Message-ID: <200309291330.h8TDUxQ26110@mailgate5.cinetic.de>

[snip start]

-----Original Message----- 
From: Fan [mailto:xiao.gang.fan1 at libertysurf.fr] 
Sent: Thursday, January 17, 2002 4:03 PM 
To: Ernesto Jardim 
Cc: r-help at stat.math.ethz.ch 
Subject: Re: [R] R for large data sets 

AFAK, ROracle works only for R unix. 

[snip   end]


Is it until today true?
,because i get errors with RODBC & ORACLE.

info <- odbcGetInfo(cho)
>>info
[1] "Oracle8 version 08.01.6300. Driver ODBC version 03.51"
>>sqlSave(cho,probabilities)
Error in sqlSave(cho, probabilities) : [RODBC] ERROR: Could not SQLExecute

The same trial with another channel and db works fine for
sqlSave(channel,probabilities)
>>info <- odbcGetInfo(channel)
>>info
[1] "MySQL version 4.1.0-alpha-max-nt. Driver ODBC version 03.51"


Many thanks for any help or comment,
christian



From yao6889 at msmailhub.oulan.ou.edu  Mon Sep 29 15:38:02 2003
From: yao6889 at msmailhub.oulan.ou.edu (Yao, Minghua)
Date: Mon, 29 Sep 2003 08:38:02 -0500
Subject: [R] Std. errors of intercept and slope
Message-ID: <FC0CEBD77311DA499A67ADB355A24FA20396ADC4@mail4.oulan.ou.edu>

Thanks, Mr. Graves.

This is exactly what I need.

-MY

-----Original Message-----
From: Spencer Graves [mailto:spencer.graves at pdf.com]
Sent: Saturday, September 27, 2003 8:34 AM
To: bolker at zoo.ufl.edu
Cc: Yao, Minghua; R Help (E-mail)
Subject: Re: [R] Std. errors of intercept and slope


See especially any discussion of "the matrix formulation of 
regression".  I'm sure this is in many books.  I'm not familiar with the 
recent literature, but I know it is in Draper and Smith, Applied 
Regression Analysis and Box, Hunter and Hunter, Statistics for 
Experimenters. 

Briefly, suppose we write the regression model as y = X b + e, where y 
and e are N x 1 vectors, X is an N x k matrix, and e is a vector of 
normal, independent errors with standard deviation s.e.  Then the least 
squares and maximum likelihood estimate of b is

      b.hat = (inverse(X' X))*(X'y),

and the covariance matrix for b.hat is

      var(b.hat) = s.e^2 * inverse(X'X). 

I apologize if this is too terse for you;  if so, please see any good 
book on regress. 

hope this helps.  spencer graves

Ben Bolker wrote:

>  I'm afraid you're going to have to look it up in a basic statistics 
>textbook.
>
>  Ben Bolker
>
>
>On Fri, 26 Sep 2003, Yao, Minghua wrote:
>
>  
>
>>Thanks, Ben.
>>
>>Could you tell me the formula for calculating this sd., given (x_i, y_i)
>>(i=1,2,...,N)?
>>We only have one intercept and slope for them.
>>
>>-Minghua
>>
>>-----Original Message-----
>>From: Ben Bolker [mailto:bolker at zoo.ufl.edu]
>>Sent: Friday, September 26, 2003 4:34 PM
>>To: Yao, Minghua
>>Cc: R Help (E-mail)
>>Subject: Re: [R] Std. errors of intercept and slope
>>
>>
>>
>>  Since the intercept and slope are estimated parameters, they have 
>>sampling distributions described by their means and standard deviations.  
>>The s.d. tells you the size of the uncertainty in intercept & in slope.
>>
>>  This is a pretty basic stats question -- you need to refer to a standard

>>textbook or reference material ...
>>
>>  Ben Bolker
>>
>>On Fri, 26 Sep 2003, Yao, Minghua wrote:
>>
>>    
>>
>>>Dear all,
>>>
>>>I have the following output generated by linear regression. Since there
is
>>>only one regression intercept and one slope for one set of data, what is
>>>      
>>>
>>the
>>    
>>
>>>meaning of std. error for intercept and that of slope? Thanks in advance.
>>>
>>>Sincerely,
>>>
>>>Minghua
>>>
>>>
>>>      
>>>
>>>>data(thuesen)
>>>>attach(thuesen)
>>>>lm(short.velocity~blood.glucose)
>>>>        
>>>>
>>>Call:
>>>lm(formula = short.velocity ~ blood.glucose)
>>>
>>>Coefficients:
>>>  (Intercept)  blood.glucose  
>>>      1.09781        0.02196  
>>>
>>>      
>>>
>>>>summary(lm(short.velocity~blood.glucose))
>>>>        
>>>>
>>>Call:
>>>lm(formula = short.velocity ~ blood.glucose)
>>>
>>>Residuals:
>>>     Min       1Q   Median       3Q      Max 
>>>-0.40141 -0.14760 -0.02202  0.03001  0.43490 
>>>
>>>Coefficients:
>>>              Estimate Std. Error t value Pr(>|t|)    
>>>(Intercept)    1.09781    0.11748   9.345 6.26e-09 ***
>>>blood.glucose  0.02196    0.01045   2.101   0.0479 *  
>>>---
>>>Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 
>>>
>>>Residual standard error: 0.2167 on 21 degrees of freedom
>>>Multiple R-Squared: 0.1737,     Adjusted R-squared: 0.1343 
>>>F-statistic: 4.414 on 1 and 21 DF,  p-value: 0.0479 
>>>
>>>      
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>>
>>>      
>>>
>>    
>>
>
>  
>



From ligges at statistik.uni-dortmund.de  Mon Sep 29 15:47:22 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 29 Sep 2003 15:47:22 +0200
Subject: [R] Downloading LME4?
In-Reply-To: <66578BFC0BA55348B5907A0F798EE93013A099@ernesto.NASDC.ORG>
References: <66578BFC0BA55348B5907A0F798EE93013A099@ernesto.NASDC.ORG>
Message-ID: <3F7837EA.1050901@statistik.uni-dortmund.de>

Harold Doran wrote:

> Dear R:
>  
> Am I having trouble downloading the LME4 library. I am using Windows and am using ver 1.7 I have tried the following:
>  
> 1) Install package from CRAN, but LME4 is not listed

 From http://cran.us.r-project.org/bin/windows/contrib/1.7/ReadMe:
"Some new packages are already prepared for R-1.8.x and do no longer
pass Rcmd check. The last working versions of these packages can be
found in subdirectory ./last"

And indeed, you will find a file
http://cran.us.r-project.org/bin/windows/contrib/1.7/last/lme4_0.3-6.zip

	

> 2) Downloaded LME4 from http://cran.us.r-project.org/, however, I cannot open the file when I try install from local drive. I get the following error:
>  
> Error in file(file, "r") : unable to open connection
> In addition: Warning messages: 
> 1: error 1 in extracting from zip file 
> 2: cannot open file `lme4_0.3-7.tar.gz/DESCRIPTION' 

You have downloaded the source version of the package, not the binary 
version for Windows. You have to compile source packages before using 
them...

Uwe Ligges


> Any help is appreciated.
>  
>  
>  
> ------
> Harold C. Doran
> Director of Research and Evaluation
> New American Schools
> 675 N. Washington Street, Suite 220
> Alexandria, Virginia 22314
> 703.647.1628
>  <http://www.edperform.net/>  
>  
>  
>  
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ligges at statistik.uni-dortmund.de  Mon Sep 29 15:55:42 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 29 Sep 2003 15:55:42 +0200
Subject: [R] ROracle - Windows?
In-Reply-To: <200309291330.h8TDUxQ26110@mailgate5.cinetic.de>
References: <200309291330.h8TDUxQ26110@mailgate5.cinetic.de>
Message-ID: <3F7839DE.9060809@statistik.uni-dortmund.de>

ozric at web.de wrote:

> [snip start]
> 
> -----Original Message----- 
> From: Fan [mailto:xiao.gang.fan1 at libertysurf.fr] 
> Sent: Thursday, January 17, 2002 4:03 PM 
> To: Ernesto Jardim 
> Cc: r-help at stat.math.ethz.ch 
> Subject: Re: [R] R for large data sets 
> 
> AFAK, ROracle works only for R unix. 
> 
> [snip   end]
> 
> 
> Is it until today true?
> ,because i get errors with RODBC & ORACLE.

 From http://cran.r-project.org/bin/windows/contrib/1.7/ReadMe:

"Although the packages
   RMySQL, ROracle, and snow
pass make check, it seems to be dangerous to distribute them:
I do not have the software available these packages depend on."

So just try it out: Compile it yourself and see what happens.

Uwe Ligges



> info <- odbcGetInfo(cho)
> 
>>>info
> 
> [1] "Oracle8 version 08.01.6300. Driver ODBC version 03.51"
> 
>>>sqlSave(cho,probabilities)
> 
> Error in sqlSave(cho, probabilities) : [RODBC] ERROR: Could not SQLExecute
> 
> The same trial with another channel and db works fine for
> sqlSave(channel,probabilities)
> 
>>>info <- odbcGetInfo(channel)
>>>info
> 
> [1] "MySQL version 4.1.0-alpha-max-nt. Driver ODBC version 03.51"
> 
> 
> Many thanks for any help or comment,
> christian
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From jrogers at cantatapharm.com  Mon Sep 29 16:17:10 2003
From: jrogers at cantatapharm.com (Jim Rogers)
Date: Mon, 29 Sep 2003 10:17:10 -0400
Subject: [R] Statistician position, R lovers encouraged
Message-ID: <99A12772DCDEEB458B996332957B0D5301185A@mercury.cantatapharm.com>

Come help us do pioneering work on a novel biochemical profiling
platform! 

     Cantata Pharmaceuticals, a small biotechnology company located in
Cambridge, MA is seeking a Ph.D. statistician to work on its biomarker
discovery projects and clinical diagnostic applications.
Responsibilities include development and implementation of supervised
learning methods, exploratory data analysis, experimental design, and
presentation of results and statistical methods to scientists and
investors. Must be creative and have strong, broad foundation in
statistical theory, but must also be willing to spend time on data flow
automation and quality control. Demonstrated facility with either S (S+
or R) or Matlab is required. Management supportive of open source
development. Experience working with genomic and post-genomic
technologies is highly desirable. 

Email CV and cover letter to jobs at cantatapharm.com , to the attention of
Jim Rogers. 


James A. Rogers, Ph.D. <rogers at cantatapharm.com>
Statistical Scientist
Cantata Pharmaceuticals
300 Technology Square, 5th floor
Cambridge, MA  02139
617.225.9009 x312
Fax 617.225.9010



From Michael.Hecht at dillinger.biz  Mon Sep 29 16:20:47 2003
From: Michael.Hecht at dillinger.biz (Hecht Michael, F+E/ST)
Date: Mon, 29 Sep 2003 16:20:47 +0200
Subject: [R] data.frame subsetting
Message-ID: <98BC0F9CF5A9D511964100005A478F39087AA031@nt03.dillinger.de>

Hi,
 
I think I have the same problem. The following works
 
> aa<-data.frame(1:10)
> ab<-data.frame(1:12)
> ba<-data.frame(1:14)
> bb<-data.frame(1:16)
> xa<-data.frame()
> xa$aa<-aa
> xa$ab<-ab
> xb<-data.frame()
> xb$ba<-ba
> xb$bb<-bb
> xx<-data.frame()
> xx$xa<-xa
> xx$xb<-xb
> summary(xx)
 xa.aa.X1.10      xa.ab.X1.12     xb.ba.X1.14      xb.bb.X1.16    
 Min.   : 1.00    Min.   : 1.00   Min.   : 1.00    Min.   : 1.00  
 1st Qu.: 3.25    1st Qu.: 3.75   1st Qu.: 4.25    1st Qu.: 4.75  
 Median : 5.50    Median : 6.50   Median : 7.50    Median : 8.50  
 Mean   : 5.50    Mean   : 6.50   Mean   : 7.50    Mean   : 8.50  
 3rd Qu.: 7.75    3rd Qu.: 9.25   3rd Qu.:10.75    3rd Qu.:12.25  
 Max.   :10.00    Max.   :12.00   Max.   :14.00    Max.   :16.00  
> is.data.frame(xx)
[1] TRUE
> is.data.frame(xx$xa)
[1] TRUE
> is.data.frame(xx$xb)
[1] TRUE
> is.data.frame(xx$xa$aa)
[1] TRUE

this works not:
 
> ya<-data.frame()
> ya[["aa"]]<-aa
Error in "[[<-.data.frame"(*tmp*, "aa", value = aa) : 
        replacement has 10 rows, data has 0
 
So I also would like produce a sub-data.frame, maybe by this way
 
> subframename<-"subset 1"
> mydataframe[[subframename]] <- mysubframe1
> subframename<-"subset 2"
> mydataframe[[subframename]] <- mysubframe2
> ...
 
is this possible?? Normally I would like to use a loop to do this!!



From anne.piotet at m-td.com  Mon Sep 29 16:22:37 2003
From: anne.piotet at m-td.com (Anne Piotet)
Date: Mon, 29 Sep 2003 16:22:37 +0200
Subject: [R] getting documentation on packages
Message-ID: <005801c38695$23bd6650$6c00a8c0@mtd4>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030929/ed16f0be/attachment.pl

From wong_jerry at hotmail.com  Mon Sep 29 16:41:59 2003
From: wong_jerry at hotmail.com (Wong Jerry)
Date: Mon, 29 Sep 2003 22:41:59 +0800
Subject: [R] Solving nonlinear system equation
Message-ID: <BAY8-F92WAE1EHApwbW0002209e@hotmail.com>

Hi all,

I would like to ask that is there any function in R which can solve 
nonlinear system equations with  several variables. Thats mean some 
functions similar to the 'fsolve' or 'fzero' in matlab.

Thanks you

Jerry

_________________________________________________________________
Get 10Mb extra storage for MSN Hotmail. Subscribe Now!



From Rau at demogr.mpg.de  Mon Sep 29 16:47:29 2003
From: Rau at demogr.mpg.de (Rau, Roland)
Date: Mon, 29 Sep 2003 16:47:29 +0200
Subject: [R] getting documentation on packages
Message-ID: <3699CDBC4ED5D511BE6400306E1C0D8114CD0C@hermes.demogr.mpg.de>

Hi!

If you use R under Windows, I would suggest you click on "Help" in the main
tool bar. Then you choose "Html help". This should open your web-browser
displaying a page with various entries. If you click on "Packages" in the
Manuals section, you should discover what you are looking for.

Hope this helps,
Roland

> -----Original Message-----
> From:	Anne Piotet [SMTP:anne.piotet at m-td.com]
> Sent:	Monday, September 29, 2003 4:23 PM
> To:	r-help at stat.math.ethz.ch
> Subject:	[R] getting documentation on packages
> 
> hello!
>  Is there a general documentation on packages, like a list of available
> packagages, their general goal and a list of functions they contain? 
> Thanks 
> Anne
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


+++++
This mail has been sent through the MPI for Demographic Research.  Should you receive a mail that is apparently from a MPI user without this text displayed, then the address has most likely been faked.   If you are uncertain about the validity of this message, please check the mail header or ask your system administrator for assistance.



From dmurdoch at pair.com  Mon Sep 29 16:52:40 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon, 29 Sep 2003 10:52:40 -0400
Subject: [R] rgl crashes R
In-Reply-To: <3F780354.2746F52A@ysbl.york.ac.uk>
References: <3.0.5.32.20030908131309.007d7790@pop-server.ucl.ac.uk>
	<3F780354.2746F52A@ysbl.york.ac.uk>
Message-ID: <0nhgnv4km94vl0qqfg66ccsec0ukh7ofdm@4ax.com>

On Mon, 29 Sep 2003 11:03:00 +0100, Karim Elsawy
<elsawy at ysbl.york.ac.uk> wrote :

>I was using rgl library and it was going well, all of a sudden it
>started to crash 
>which leads R to quit giving this error message

Generally speaking you'll get the best help on contributed packages by
writing to the maintainer, in this case  Daniel Adler
<dadler at gwdg.de>.

Duncan Murdoch



From spencer.graves at pdf.com  Mon Sep 29 16:59:10 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 29 Sep 2003 09:59:10 -0500
Subject: [R] Solving nonlinear system equation
In-Reply-To: <BAY8-F92WAE1EHApwbW0002209e@hotmail.com>
References: <BAY8-F92WAE1EHApwbW0002209e@hotmail.com>
Message-ID: <3F7848BE.6000006@pdf.com>

Have you considered "optim" in the MASS library? 

Also, have you tried www.r-project.org -> search -> R site search?

hope this helps.  spencer graves

Wong Jerry wrote:

> Hi all,
>
> I would like to ask that is there any function in R which can solve 
> nonlinear system equations with  several variables. Thats mean some 
> functions similar to the 'fsolve' or 'fzero' in matlab.
>
> Thanks you
>
> Jerry
>
> _________________________________________________________________
> Get 10Mb extra storage for MSN Hotmail. Subscribe Now!
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From maechler at stat.math.ethz.ch  Mon Sep 29 17:12:33 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 29 Sep 2003 17:12:33 +0200
Subject: [R] coloring dendrgram in heatmap?
In-Reply-To: <3A822319EB35174CA3714066D590DCD50205CBB5@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD50205CBB5@usrymx25.merck.com>
Message-ID: <16248.19425.799604.409673@gargle.gargle.HOWL>

>>>>> "AndyL" == Liaw, Andy <andy_liaw at merck.com>
>>>>>     on Mon, 29 Sep 2003 08:28:03 -0400 writes:

    >> From: Xiao-Jun Ma [mailto:xma at arcturusag.com]
    >> 
    >> No, I meant coloring the edges of the dendrogram on the
    >> left or top of the image plot.
 
    AndyL> I'm not sure if this can be done with the current
    AndyL> plot.dendrogram() (which heatmap() calls to draw the
    AndyL> trees).  You may want to experiment with the edgePar
    AndyL> argument and see if that can give you trees with
    AndyL> different colors in the branches.  If not, you'll
    AndyL> need to hack into plot.dendrogram() and DIY.  (Martin
    AndyL> would know this for sure...)

yes, you are completely right, Andy.
To make this work with  heatmap() :

1) give a *dendrogram* object as `Rowv' and `Colv' argument to heatmap()

2) When constructing these 2 dendrograms, make sure that every
   node to which a non-standard edge should be drawn
   has an "edgePar" attribute, a list such as list(col = "green").

I agree that "2)" is somewhat tedious at the moment, but
unfortunately we are past feature freeze for R 1.8.0
{I had quite a few more proposed additional features that didn't
 make it...}

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><

    >> -----Original Message----- From: kjetil brinchmann
    >> halvorsen To: 'R-help at stat.math.ethz.ch '; 'Martin
    >> Maechler ' Sent: 9/27/03 1:24 PM Subject: Re: [R]
    >> coloring dendrgram in heatmap?
    >> 
    >> On 27 Sep 2003 at 11:56, Xiao-Jun Ma wrote:
    >> 
    >> What about trying RColorBrewer, as mentioned in the docs
    >> of heatmap. I had good results with that!
    >> 
    >> Kjetil Halvorsen
    >> 
    >> > Using the heatmap function in mva, it seems to be hard
    >> to use different > colors in the edges leading to
    >> different groups of objects, as commonly done > in many
    >> heatmaps in the microarray graphics. Any suggestions?
    >> Thanks.
    >> > 
    >> > max
    >> >



From andy_liaw at merck.com  Mon Sep 29 17:38:39 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 29 Sep 2003 11:38:39 -0400
Subject: [R] can I have a matrix of factors, please?
Message-ID: <3A822319EB35174CA3714066D590DCD50205CBC9@usrymx25.merck.com>

Dear R-help,

Is it a violation of the S language to have a matrix of factors?  What I
would like to have is just a factor object that has dim attribute, and can
be printed (and subsetted) like a matrix; i.e., all columns/rows have the
identical levels.  However, I can't get it to work:

> x <- factor(sample(2, 10, replace=TRUE))
> dim(x)<- c(5,2)
> x
 [1] 1 2 2 1 2 1 1 1 2 1
Levels: 1 2
> str(x)
 int [1:5, 1:2] 1 2 2 1 ...
 - attr(*, "levels")= chr [1:2] "1" "2"
 - attr(*, "class")= chr "factor"
> x[1,]
factor(0)
Levels: 1 2

(This is R 1.7.1 on WinXPPro.)

The alternative is to have a list instead, where each "column" makes up a
component of the list.  But it would be nice to have the matrix...

Best,
Andy
Andy Liaw, PhD
Biometrics Research      PO Box 2000, RY33-300     
Merck Research Labs           Rahway, NJ 07065
mailto:andy_liaw at merck.com        732-594-0820



From mkondrin at hppi.troitsk.ru  Tue Sep 30 05:05:17 2003
From: mkondrin at hppi.troitsk.ru (M.Kondrin)
Date: Mon, 29 Sep 2003 20:05:17 -0700
Subject: [R] Solving nonlinear system equation
In-Reply-To: <BAY8-F92WAE1EHApwbW0002209e@hotmail.com>
References: <BAY8-F92WAE1EHApwbW0002209e@hotmail.com>
Message-ID: <3F78F2ED.4060106@hppi.troitsk.ru>

Wong Jerry wrote:
> Hi all,
> 
> I would like to ask that is there any function in R which can solve 
> nonlinear system equations with  several variables. Thats mean some 
> functions similar to the 'fsolve' or 'fzero' in matlab.
> 
> Thanks you
> 
> Jerry
> 
> _________________________________________________________________
> Get 10Mb extra storage for MSN Hotmail. Subscribe Now!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

You may take a look at page http://www.hppi.troitsk.ru/Kondrin and 
download a package RMinpack. This is (incomplete) port of Minpack 
Fortran library and it now contains only one function FSolve(fun,guess) 
which do exactly what you have requested.
Comments welcome.



From aniko.szabo at hci.utah.edu  Mon Sep 29 18:21:10 2003
From: aniko.szabo at hci.utah.edu (Aniko Szabo)
Date: Mon, 29 Sep 2003 10:21:10 -0600
Subject: [R] Rcmdr and Macintosh
Message-ID: <F062093E456F8C4A9566C5CA59726C6E2DA51B@EMAIL.hci.utah.edu>

Hi everyone!
I am planning to use R and Rcmdr in a basic stat course. I have no access to a computer lab, but I can expect all students to have a laptop. Of couse, I have no control over their OS and in my experience several of them will have Macs. I have Windows. My question is the following: can I expect them to be able to install R, Tcl/Tk and Rcmdr (i.e. does anybody has experinece with it?) Are there any installation tricks/tips/instructions you can help me with? 

Thanks,
Aniko Szabo



This e-mail may contain confidential and/or privileged information for the sole use of the intended recipient. Any review or distribution by anyone other than the person for whom it was originally intended is strictly prohibited. If you have received this e-mail in error, please contact the sender and delete all copies. Opinions, conclusions or other information contained in this e-mail may not be that of the organization.



From andrejk at zrc-sazu.si  Mon Sep 29 19:04:47 2003
From: andrejk at zrc-sazu.si (Andrej Kveder)
Date: Mon, 29 Sep 2003 19:04:47 +0200
Subject: [R] predicting values from the LME
Message-ID: <FHEEJBDDCNPPNJEACDJAEELBDDAA.andrejk@zrc-sazu.si>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030929/6775a3cc/attachment.pl

From Kang.Daiwen at epamail.epa.gov  Mon Sep 29 19:15:36 2003
From: Kang.Daiwen at epamail.epa.gov (Kang.Daiwen@epamail.epa.gov)
Date: Mon, 29 Sep 2003 13:15:36 -0400
Subject: [R] Data frame transpose
Message-ID: <OF7220A327.9C44538F-ON85256DB0.005D59C0@epamail.epa.gov>





Hi All,

I want to ask if there is a transpose function for data frame like the
procedure of transpose in SAS? Because I want to partially transpose a
data frame which contains 5 columns (siteid, date, time, obs, mod), what
I want to do is to put time as the column variables along with siteid,
and date, and put obs and mod in the row names. specifically to
transpose a data frame:

siteid     date    time   obs     mod
    A       7/8        01       2         5
    A       7/8        02        3        8
    A       7/8        03        5        8
     A       7/9       01       3          6
   A         7/9      02        5          8
   A         7/9       03       6           7
                       ......
   B         7/8      01          4         7
    B        7/8      02        7        19
   B         7/8     03         4        9
                      ......

To

siteid    date    name     01    02     03   ....
A              7/8       obs       2      3        5
A              7/8       mod      5      8        8
A              7/9       obs       3      5         6
A              7/9       mod      6      8        7
                 .......
B              7/8        obs       4      7        4
B              7/8        mod      7      19      9
                ........


Thank you very much!

Dave



From andy_liaw at merck.com  Mon Sep 29 19:48:03 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 29 Sep 2003 13:48:03 -0400
Subject: [R] can I have a matrix of factors, please?
Message-ID: <3A822319EB35174CA3714066D590DCD50205CBCC@usrymx25.merck.com>

> From: Liaw, Andy [mailto:andy_liaw at merck.com] 
> 
> Dear R-help,
> 
> Is it a violation of the S language to have a matrix of 
> factors?  What I would like to have is just a factor object 
> that has dim attribute, and can be printed (and subsetted) 
> like a matrix; i.e., all columns/rows have the identical 
> levels.  However, I can't get it to work:
> 
> > x <- factor(sample(2, 10, replace=TRUE))
> > dim(x)<- c(5,2)
> > x
>  [1] 1 2 2 1 2 1 1 1 2 1
> Levels: 1 2
> > str(x)
>  int [1:5, 1:2] 1 2 2 1 ...
>  - attr(*, "levels")= chr [1:2] "1" "2"
>  - attr(*, "class")= chr "factor"
> > x[1,]
> factor(0)
> Levels: 1 2
> 
> (This is R 1.7.1 on WinXPPro.)

This is wierder than I thought!  Try:

> x[,1]
[1] 1 2 2 1 2
Levels: 1 2
> x[2,]
factor(0)
Levels: 1 2

I.e., column extraction "works", but not row extraction.

> y <- factor(1:12)
> dim(y) <- c(3,4)
> y[,1]
[1] 1 2 3
Levels: 1 2 3
> y[1,1]
[1] 1
Levels: 1
> y[1,]
factor(0)
Levels: 1 2 3 4 5 6 7 8 9 10 11 12
> y[1, 1:ncol(y)]
[1] 1  4  7  10
Levels: 1 4 7 10
Warning message: 
the condition has length > 1 and only the first element will be used in: if
(drop) factor(y) else y 

Column extraction and element extraction "work", but notice the unused
levels mysteriously disappeared!  The last warning also seems strange.

> is.matrix(y)
[1] TRUE
> class(y)
[1] "factor"

This also baffles me:  Given a numeric vector, (say y <- 1:12, dim(y) <- 3:4
will give y the "matrix" class.  Yet if I do this with a factor, it doesn't!
Apparently that's not what is.matrix tests for.

> The alternative is to have a list instead, where each 
> "column" makes up a component of the list.  But it would be 
> nice to have the matrix...

Short of as.list(as.data.frame(matrix))), does anyone know of an efficient
way to turn a matrix into a list with each component containing a column?
 
Best,
Andy



From tlumley at u.washington.edu  Mon Sep 29 20:27:09 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 29 Sep 2003 11:27:09 -0700 (PDT)
Subject: [R] Data frame transpose
In-Reply-To: <OF7220A327.9C44538F-ON85256DB0.005D59C0@epamail.epa.gov>
References: <OF7220A327.9C44538F-ON85256DB0.005D59C0@epamail.epa.gov>
Message-ID: <Pine.A41.4.58.0309291126290.157832@homer35.u.washington.edu>

On Mon, 29 Sep 2003 Kang.Daiwen at epamail.epa.gov wrote:
>
> Hi All,
>
> I want to ask if there is a transpose function for data frame like the
> procedure of transpose in SAS? Because I want to partially transpose a
> data frame which contains 5 columns (siteid, date, time, obs, mod), what
> I want to do is to put time as the column variables along with siteid,
> and date, and put obs and mod in the row names. specifically to

I think reshape() does what you want

	-thomas


> transpose a data frame:
>
> siteid     date    time   obs     mod
>     A       7/8        01       2         5
>     A       7/8        02        3        8
>     A       7/8        03        5        8
>      A       7/9       01       3          6
>    A         7/9      02        5          8
>    A         7/9       03       6           7
>                        ......
>    B         7/8      01          4         7
>     B        7/8      02        7        19
>    B         7/8     03         4        9
>                       ......
>
> To
>
> siteid    date    name     01    02     03   ....
> A              7/8       obs       2      3        5
> A              7/8       mod      5      8        8
> A              7/9       obs       3      5         6
> A              7/9       mod      6      8        7
>                  .......
> B              7/8        obs       4      7        4
> B              7/8        mod      7      19      9
>                 ........
>
>
> Thank you very much!
>
> Dave
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From tblackw at umich.edu  Mon Sep 29 20:29:03 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Mon, 29 Sep 2003 14:29:03 -0400 (EDT)
Subject: [R] Data frame transpose
In-Reply-To: <OF7220A327.9C44538F-ON85256DB0.005D59C0@epamail.epa.gov>
References: <OF7220A327.9C44538F-ON85256DB0.005D59C0@epamail.epa.gov>
Message-ID: <Pine.SOL.4.58.0309291401300.21656@rygar.gpcc.itd.umich.edu>

Dave  -

I'm not sure whether there is already a function which does
exactly what you want, because this is kind of a special case.
The functions I wold look at are: "by", "aggregate", "tapply",
"mapply", and, in the package "nlme" one I didn't know about
before called "gapply".

But, in your case, the part that makes it doable is that all
of the columns in that part of the dataframe which you want
to transpose are numeric.  (At least, it looks that way from
your email.)  And you have the same number of time points in
every site x date.  So you could extract just the three columns
"time", "obs", "mod" as a numeric matrix, cast it to an array,
use  aperm(), then cast it back to a matrix and then back to a
dataframe.  The basic tools for this are: "data.matrix", "array",
"aperm", "matrix" and "data.frame".

I've got to let you work out the details yourself.  The key
when planning this is to remember that multi-dimensional arrays
in R use Fortran storage order: the first index varies fastest.
Some one else may be able to come up with a much more direct
solution.

HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Mon, 29 Sep 2003 Kang.Daiwen at epamail.epa.gov wrote:

> I want to ask if there is a transpose function for data frame like the
> procedure of transpose in SAS? Because I want to partially transpose a
> data frame which contains 5 columns (siteid, date, time, obs, mod), what
> I want to do is to put time as the column variables along with siteid,
> and date, and put obs and mod in the row names. specifically to
> transpose a data frame:
>
> siteid     date    time   obs     mod
>     A       7/8        01       2         5
>     A       7/8        02        3        8
>     A       7/8        03        5        8
>      A       7/9       01       3          6
>    A         7/9      02        5          8
>    A         7/9       03       6           7
>                        ......
>    B         7/8      01          4         7
>     B        7/8      02        7        19
>    B         7/8     03         4        9
>                       ......
> To
>
> siteid    date    name     01    02     03   ....
> A              7/8       obs       2      3        5
> A              7/8       mod      5      8        8
> A              7/9       obs       3      5         6
> A              7/9       mod      6      8        7
>                  .......
> B              7/8        obs       4      7        4
> B              7/8        mod      7      19      9
>                 ........
>
> Thank you very much!
>
> Dave



From jcr753+ at pitt.edu  Mon Sep 29 20:30:21 2003
From: jcr753+ at pitt.edu (Juan Carlos Rodriguez-Raga)
Date: Mon, 29 Sep 2003 14:30:21 -0400
Subject: [R] multilevel (hierarchical) statistical analysis
Message-ID: <24464207.1064845821@PH111.fdl.pitt.edu>

Is there any package developed in R for multilevel (hierarchical) analysis 
of continuous and categorical dependent variables?



From clists at perrin.socsci.unc.edu  Mon Sep 29 20:52:35 2003
From: clists at perrin.socsci.unc.edu (Andrew Perrin)
Date: Mon, 29 Sep 2003 14:52:35 -0400 (EDT)
Subject: [R] multilevel (hierarchical) statistical analysis
In-Reply-To: <24464207.1064845821@PH111.fdl.pitt.edu>
References: <24464207.1064845821@PH111.fdl.pitt.edu>
Message-ID: <Pine.LNX.4.53.0309291451560.17881@perrin.socsci.unc.edu>

For continuous, see the lme package. For categorical, see glmmPQL in the
MASS package, or GLMM in LME4.

ap

----------------------------------------------------------------------
Andrew J Perrin - http://www.unc.edu/~aperrin
Assistant Professor of Sociology, U of North Carolina, Chapel Hill
clists at perrin.socsci.unc.edu * andrew_perrin (at) unc.edu


On Mon, 29 Sep 2003, Juan Carlos Rodriguez-Raga wrote:

> Is there any package developed in R for multilevel (hierarchical) analysis
> of continuous and categorical dependent variables?
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>



From daniel.ielpo at uniriotec.br  Mon Sep 29 21:50:01 2003
From: daniel.ielpo at uniriotec.br (daniel.ielpo@uniriotec.br)
Date: Mon, 29 Sep 2003 16:50:01 -0300
Subject: [R] Parsing R matrix to C
Message-ID: <1064865001.3f788ce9de933@webmail.uniriotec.br>

I'm developing a C dll to use as a package in R. I need to parse a R Matrix as 
a parameter to a function in a dll. I?d like to know how can I use the Sexp 
type and how to handle this as a matrix in the C code.

Sorry for the bad english.

Thanks,

Daniel Ielpo

-------------------------------------------------
This mail sent through IMP: http://horde.org/imp/



From ross at biostat.ucsf.edu  Mon Sep 29 22:44:46 2003
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Mon, 29 Sep 2003 13:44:46 -0700
Subject: [R] Help needed: plotting with no device
Message-ID: <20030929204446.GC2341@wheat.boylan.org>

I have a hung session I would very much like to recover, since it has
some simulation results I haven't saved (that took about 12 hours to
create).  Yes, I know, I should have saved while I had the chance.

I tried to do a hist() in an environment without a plotting device.
My R session now seems to be hung; ^C doesn't do anything.  I thought
it would timeout, but it has not so far.

The details of this session's environment are a bit baroque.  In case
it matters, here they are:
Running an xterm locally, used the "screen" program to start a shell.
Ran R.
Then, from a remote computer, used ssh to log in (without X forwarding
enabled).  Grabbed the session by doing screen -d -r.  (screen lets
you trade the controlling tty of a session; that's why I was using
it).

After detaching and reattaching the session a couple of times (still
remote) I did
> hist(tres4$singles[["a"]])
tres4$singles is a dataframe.
I can still type on the terminal, but get no response.

R 1.7.1 on Debian.

Is there any way to get the R session back without killing it?

Thanks.



From bolker at zoo.ufl.edu  Mon Sep 29 23:09:49 2003
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Mon, 29 Sep 2003 17:09:49 -0400 (EDT)
Subject: [R] Help needed: plotting with no device
In-Reply-To: <20030929204446.GC2341@wheat.boylan.org>
Message-ID: <Pine.LNX.4.44.0309291708070.31941-100000@bolker.zoo.ufl.edu>


  Can you use save.image() to rescue your results?
  I would try save.image(file="salvage.RData") and see if the file 
appears.  Otherwise I would say you're probably out of luck.

  

On Mon, 29 Sep 2003, Ross Boylan wrote:

> I have a hung session I would very much like to recover, since it has
> some simulation results I haven't saved (that took about 12 hours to
> create).  Yes, I know, I should have saved while I had the chance.
> 
> I tried to do a hist() in an environment without a plotting device.
> My R session now seems to be hung; ^C doesn't do anything.  I thought
> it would timeout, but it has not so far.
> 
> The details of this session's environment are a bit baroque.  In case
> it matters, here they are:
> Running an xterm locally, used the "screen" program to start a shell.
> Ran R.
> Then, from a remote computer, used ssh to log in (without X forwarding
> enabled).  Grabbed the session by doing screen -d -r.  (screen lets
> you trade the controlling tty of a session; that's why I was using
> it).
> 
> After detaching and reattaching the session a couple of times (still
> remote) I did
> > hist(tres4$singles[["a"]])
> tres4$singles is a dataframe.
> I can still type on the terminal, but get no response.
> 
> R 1.7.1 on Debian.
> 
> Is there any way to get the R session back without killing it?
> 
> Thanks.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From pgreen at umich.edu  Mon Sep 29 23:06:06 2003
From: pgreen at umich.edu (Paul Green)
Date: Mon, 29 Sep 2003 17:06:06 -0400
Subject: [R] BIC or AIC from nnet 
Message-ID: <5.1.0.14.2.20030929170243.00b154e8@mailkardia.sph.umich.edu>

Is AIC or BIC available when using the
nnet package?

Thank you

Paul Green



From ross at biostat.ucsf.edu  Mon Sep 29 23:14:59 2003
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Mon, 29 Sep 2003 14:14:59 -0700
Subject: [R] Help needed: plotting with no device
In-Reply-To: <Pine.LNX.4.44.0309291708070.31941-100000@bolker.zoo.ufl.edu>
References: <20030929204446.GC2341@wheat.boylan.org>
	<Pine.LNX.4.44.0309291708070.31941-100000@bolker.zoo.ufl.edu>
Message-ID: <20030929211459.GF2341@wheat.boylan.org>

On Mon, Sep 29, 2003 at 05:09:49PM -0400, Ben Bolker wrote:
> 
>   Can you use save.image() to rescue your results?
>   I would try save.image(file="salvage.RData") and see if the file 
> appears.  Otherwise I would say you're probably out of luck.
> 
The problem is I can't get back to the command prompt, so I can't do
save.image() or anything else.



From luke at stat.uiowa.edu  Mon Sep 29 23:25:18 2003
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Mon, 29 Sep 2003 16:25:18 -0500 (CDT)
Subject: [R] Help needed: plotting with no device
In-Reply-To: <20030929211459.GF2341@wheat.boylan.org>
Message-ID: <Pine.LNX.4.44.0309291624250.32258-100000@itasca2.stat.uiowa.edu>

Look at ?Signal and see if that would help.  You may need to rename
the appropriate .RData beforehand to be safer.

luke

On Mon, 29 Sep 2003, Ross Boylan wrote:

> On Mon, Sep 29, 2003 at 05:09:49PM -0400, Ben Bolker wrote:
> > 
> >   Can you use save.image() to rescue your results?
> >   I would try save.image(file="salvage.RData") and see if the file 
> > appears.  Otherwise I would say you're probably out of luck.
> > 
> The problem is I can't get back to the command prompt, so I can't do
> save.image() or anything else.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Luke Tierney
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
   Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu



From jasont at indigoindustrial.co.nz  Mon Sep 29 23:32:58 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Tue, 30 Sep 2003 09:32:58 +1200
Subject: [R] Help needed: plotting with no device
In-Reply-To: <20030929211459.GF2341@wheat.boylan.org>
References: <20030929204446.GC2341@wheat.boylan.org>	<Pine.LNX.4.44.0309291708070.31941-100000@bolker.zoo.ufl.edu>
	<20030929211459.GF2341@wheat.boylan.org>
Message-ID: <3F78A50A.1060107@indigoindustrial.co.nz>

Ross Boylan wrote:

> On Mon, Sep 29, 2003 at 05:09:49PM -0400, Ben Bolker wrote:
> 
>>  Can you use save.image() to rescue your results?
>>  I would try save.image(file="salvage.RData") and see if the file 
>>appears.  Otherwise I would say you're probably out of luck.
>>
> 
> The problem is I can't get back to the command prompt, so I can't do
> save.image() or anything else.

It may be possible to reconstruct the state from a core dump.  I say 
"may" with not much confidence it'll be worth the effort, but it might 
be possible.

Only problem is, there's no way I know under Linux to dump core and 
continue; you only get one shot at it.

man 7 signal on my SuSE box gives a list of which signals cause a 
process to dump core.  After that, you'll have to find a Local Guru to 
pick it apart - and R's memory structures aren't trivial.

It might be easier to start again.

Hope it helps

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
64-21-343-545
jasont at indigoindustrial.co.nz



From ggrothendieck at myway.com  Mon Sep 29 23:34:38 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 29 Sep 2003 17:34:38 -0400 (EDT)
Subject: [R] Data frame transpose
Message-ID: <20030929213438.5A6233996@xmxpita.myway.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030929/4d741eee/attachment.pl

From tlumley at u.washington.edu  Mon Sep 29 23:46:11 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 29 Sep 2003 14:46:11 -0700 (PDT)
Subject: [R] Help needed: plotting with no device
In-Reply-To: <20030929204446.GC2341@wheat.boylan.org>
References: <20030929204446.GC2341@wheat.boylan.org>
Message-ID: <Pine.A41.4.58.0309291445070.43324@homer29.u.washington.edu>

On Mon, 29 Sep 2003, Ross Boylan wrote:

> I have a hung session I would very much like to recover, since it has
> some simulation results I haven't saved (that took about 12 hours to
> create).  Yes, I know, I should have saved while I had the chance.
>
> I tried to do a hist() in an environment without a plotting device.
> My R session now seems to be hung; ^C doesn't do anything.  I thought
> it would timeout, but it has not so far.

You may be able to send SIGUSR1 to the process, which tells it to quit and
save, or SIGUSR2, which is quit and save without running .Last and
.on.exit stuff.  It depends on how badly it is wedged.

	-thomas



From ggrothendieck at myway.com  Mon Sep 29 23:47:18 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 29 Sep 2003 17:47:18 -0400 (EDT)
Subject: [R] Data frame transpose
Message-ID: <20030929214718.A68A73A06@xmxpita.myway.com>



Sorry about the formatting in that previous email.  Here it is
again, hopefully with the correct formatting this time.

Assuming that the data frame is called m, you can 
- split the data frame by the values of siteid and date
- apply a function to create the new data frame for each such group and 
- use rbind to put it back together like this: 

fn <- function(x) {
  y <- t(x[,4:5])
  data.frame( siteid=x[1,1], date=x[1,2], name=colnames(x)[4:5], x01=y[,1], x02=y[,2], x03=y[,3] )
 }
m <- do.call( "rbind", lapply(split(m,list(m$siteid,m$date)),fn) )

If order matters, add this:

m <- m[order(m$siteid,m$date),]





 --- On Mon 09/29,  < Kang.Daiwen at epamail.epa.gov > wrote:
From:  [mailto: Kang.Daiwen at epamail.epa.gov]
To: r-help at stat.math.ethz.ch
Date: Mon, 29 Sep 2003 13:15:36 -0400
Subject: [R] Data frame transpose

<br><br><br><br>Hi All,<br><br>I want to ask if there is a transpose function for data frame like the<br>procedure of transpose in SAS? Because I want to partially transpose a<br>data frame which contains 5 columns (siteid, date, time, obs, mod), what<br>I want to do is to put time as the column variables along with siteid,<br>and date, and put obs and mod in the row names. specifically to<br>transpose a data frame:<br><br>siteid     date    time   obs     mod<br>    A       7/8        01       2         5<br>    A       7/8        02        3        8<br>    A       7/8        03        5        8<br>     A       7/9       01       3          6<br>   A         7/9      02        5          8<br>   A         7/9       03       6           7<br>                       ......<br>   B         7/8      01          4         7<br>    B        7/8      02        7        19<br>   B         7/8     03         4        9<br>                      ......<br><br>To<br><br>siteid    date    name     01    02     03   ....<br>A              7/8       obs       2      3        5<br>A              7/8       mod      5      8        8<br>A              7/9       obs       3      5         6<br>A              7/9       mod      6      8        7<br>                 .......<br>B              7/8        obs       4      7        4<br>B              7/8        mod      7      19      9<br>                ........<br><br><br>Thank you very much!<br><br>Dave<br><br>______________________________________________<br>R-help at stat.math.ethz.ch mailing list<br>https://www.stat.math.ethz.ch/mailman/listinfo/r-help<br>

_______________________________________________
No banners. No pop-ups. No kidding.
Introducing My Way - http://www.myway.com



From mzhang1208 at hotmail.com  Tue Sep 30 00:00:03 2003
From: mzhang1208 at hotmail.com (weidong zhang)
Date: Mon, 29 Sep 2003 22:00:03 +0000
Subject: [R] CP for rpart
Message-ID: <BAY1-F150VAhwrZV2Xq0000d421@hotmail.com>

Hi All,

I have some questions on using library rpart. Given my data below, the 
plotcp gives me increasing 'xerrors' across different cp's with huge xstd 
(plot attached). What causes the problem or it's not a problem at all? I am 
thinking 'xerror's should be decreasing when 'cp' gets smaller. Also what 
the 'xstd' really tells us? If the error bars for each xerror overlap for 
different cp's, does that mean we don't have significant improvement for 
misclassification rate when we split the tree?

My data have are two classes with 138 observations and 129 attributes. Here 
is what I did:
>dim(man.dat[,c(1,8:136)])
[1] 138 130
>man.dt1 <- rpart(Target~.,data=man.dat[,c(1,8:136)], 
>method='class',cp=1e-5, parms=list(split='information'))

>plotcp(man.dt1)

>printcp(man.dt1)

Classification tree:
rpart(formula = Target ~ ., data = man.dat[, c(1, 8:136)], method = "class",
    parms = list(split = "information"), cp = 1e-05)

Variables actually used in tree construction:
[1] CHX.V  CYN.Cu SPF.Bi

Root node error: 25/138 = 0.18116

n= 138

       CP nsplit rel error xerror    xstd
1 0.18667      0      1.00   1.00 0.18098
2 0.00001      3      0.44   1.12 0.18897


I would appreciate your help on this,

Weidong

_________________________________________________________________
Instant message with integrated webcam using MSN Messenger 6.0. Try it now 
FREE!  http://msnmessenger-download.com
-------------- next part --------------
A non-text attachment was scrubbed...
Name: plotcp.pdf
Type: application/pdf
Size: 3990 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030929/42f5f6e2/plotcp.pdf

From ihaka at stat.auckland.ac.nz  Tue Sep 30 00:05:42 2003
From: ihaka at stat.auckland.ac.nz (Ross Ihaka)
Date: Tue, 30 Sep 2003 10:05:42 +1200
Subject: [R] parametric surfaces
In-Reply-To: <1445.193.219.42.106.1064838270.squirrel@kedras.mif.vu.lt>
References: <1445.193.219.42.106.1064838270.squirrel@kedras.mif.vu.lt>
Message-ID: <3F78ACB6.5020209@stat.auckland.ac.nz>

vtas at uosis.mif.vu.lt wrote:
> Hi,
> does anyone know how to plot 3D parametric surface,e.g ellipsoid:
> x=a*cos(s)*cos(t),
> y=b*sin(s)*cos(t),
> z=sin(t);
> s in [0,2*pi],
> t in [-pi,pi].
> 
> Vytautas Maniusis,
> Vilnius University, Lithuania

A genuine 3d vector rendering package is on my todo list, but it has
lower priorty than many other tasks (i.e. it is some years off).

You might try looking at RGL to see if that meets your needs.

-- 
Ross Ihaka                         Email:  ihaka at stat.auckland.ac.nz
Department of Statistics           Phone:  (64-9) 373-7599 x 85054
University of Auckland             Fax:    (64-9) 373-7018
Private Bag 92019, Auckland
New Zealand



From pauljohn at ku.edu  Tue Sep 30 00:43:50 2003
From: pauljohn at ku.edu (Paul E Johnson)
Date: Mon, 29 Sep 2003 17:43:50 -0500
Subject: [R] Slide Show at ground zero from one of my R using students
Message-ID: <3F78B5A6.7030400@ku.edu>

In case you have students who want try out R, this may help. One of my 
students, Jeff Morrow, made a PowerPoint Slide Show.  He was trying to 
follow along with this little tutorial I made for people who want to 
test out R:

http://lark.cc.ku.edu/~pauljohn/ps707/Rtutorial1.txt

Jeff became intrigued and frustrated. Import of Excel data failed 
because the saved file output from Excel had commas inside the numbers. 
  That sent him chasing his tail in frustration because the import 
seemed fine, but the numbers were treated as factor data and plots were 
bizarre. That made him angry and determined enough to work out the kinks.

So in case you are a student interested to see what R is about from the 
very beginning level, or you are a professor and want to see know how 
your beginning students will see it, this might be a good place:

http://www.ku.edu/~pauljohn/R/JeffRLesson1.ppt

-- 
Paul E. Johnson                       email: pauljohn at ku.edu
Dept. of Political Science            http://lark.cc.ku.edu/~pauljohn
1541 Lilac Lane, Rm 504
University of Kansas                  Office: (785) 864-9086
Lawrence, Kansas 66044-3177           FAX: (785) 864-5700



From jfox at mcmaster.ca  Tue Sep 30 02:27:28 2003
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 29 Sep 2003 20:27:28 -0400
Subject: [R] Rcmdr and Macintosh
In-Reply-To: <F062093E456F8C4A9566C5CA59726C6E2DA51B@EMAIL.hci.utah.edu>
Message-ID: <5.1.0.14.2.20030929200920.01fa9fa8@127.0.0.1>

Dear Aniko,

At 10:21 AM 9/29/2003 -0600, Aniko Szabo wrote:
>Hi everyone!
>I am planning to use R and Rcmdr in a basic stat course. I have no access 
>to a computer lab, but I can expect all students to have a laptop. Of 
>couse, I have no control over their OS and in my experience several of 
>them will have Macs. I have Windows. My question is the following: can I 
>expect them to be able to install R, Tcl/Tk and Rcmdr (i.e. does anybody 
>has experinece with it?) Are there any installation 
>tricks/tips/instructions you can help me with?

I was hoping that a Mac user would pick up this question, since I have no 
direct experience using the Rcmdr package on a Mac. I've been told by 
several people that the package works fine under OS X. You do need to have 
the tcltk package installed, and of course Tcl/Tk.

I've been using R with the Rcmdr package in an introductory social 
statistics class this fall. Remarkably, every one of the approximately 50 
students in the class has a Windows computer. I distributed a Windows 
CD/ROM with a pre-installed copy of R that runs from a batch file and loads 
the Rcmdr package on startup. The CD also contains the Windows R installer, 
all of the contributed Windows binary packages on CRAN, all the data for 
the course, and complete installation instructions. I told students that 
they could run the software from the CD/ROM, but that it would perform 
better if installed on their computers, and as near as I can tell, most 
seem to have installed it successfully. So far, everything seems to be 
going smoothly.

I've prepared an introduction to the R Commander that's specific to my 
class but may be of more general interest; you can find a copy at 
<http://socserv.socsci.mcmaster.ca/jfox/Courses/soc3h6/R-Commander.pdf>. I 
plan eventually to revise this document to make it more general.

I hope that this helps,
  John
-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox



From zitan at mediasculpt.net  Tue Sep 30 22:03:27 2003
From: zitan at mediasculpt.net (Zitan Broth)
Date: Tue, 30 Sep 2003 13:03:27 -0700
Subject: [R] R Production Performance
References: <OF8F028250.C58EE9BB-ON85256DAA.00422BB2@convergys.com>
	<00d401c382c3$d0b4a880$3201a8c0@zitan>
	<005301c38242$eba7c900$f07afea9@computer>
	<3F7121EE.6070603@joeconway.com>
	<011901c383aa$dc7d6430$414c4fcb@zitan> <3F72767C.6080509@joeconway.com>
Message-ID: <017a01c3878d$e9c77f90$3201a8c0@zitan>

Hi Joe,

Thanks for your follow up note ....

> I don't know of a way to achieve it with pure PHP short of writing your
own C extension to PHP. I had considered that at one point, but have found
it unnecessary since my data is already in Postgres and PL/R lets me do what
I need.

I could use swig (http://swig.sourceforge.net/) but I'd need to understand
how to access R's c functions directly, which could be a little tricky. We
may well go with the Postgres Option you have provided, my only reservation
is that using PHP makes for an easy LVS (Linux Virtual Server) roll out if
we need to scale.  However the counter to this argument is that the database
is more robust and faster - so its a toss up ;-)

> There are no thread safety issues because Postgres is multi-process, not
> multi-threaded. Each database connection gets its own private copy of R,
> and only does one thing at a time.

Right but R is only "preloaded" once?  I personally think multi-processing
is a definite enterprise alternative to multi-threading, given the right
technology ;-)

> There may be some considerations if you do connection pooling or use
> persistent connections though. I haven't needed that so far, so I can't
> say I've thought much about it yet.

Yeah persistent connections are nice for performance, but I can't see how
this (or pooling db connections) would affect the database or the
architecture of PL/R.

Awesome,
Z.



From jeff_hamann at hamanndonald.com  Tue Sep 30 05:01:42 2003
From: jeff_hamann at hamanndonald.com (Jeff D. Hamann)
Date: Mon, 29 Sep 2003 20:01:42 -0700
Subject: [R] can't get names from vector in nlm calls
Message-ID: <001201c386ff$2d7e9a00$0a00a8c0@rodan>

I've been trying to figure out how to get the names of the parameter vector
variables when inside the function that nlm calls to return the objective
function value:

knls <- function( theta, eqns, data, fitmethod="OLS", instr=NULL, S=NULL )
  {

    ##     print( names( theta ) )              # returns NULL
    ## get the values of the parameters
    for( i in 1:length( theta ) )
      {
        val <- theta[i]
        storage.mode( val ) <-  "double"
        assign( names( theta )[i], val )          # gags here cause I can't
get the names...
      }

    ## resids = eval( lhs ) - eval( rhs )
    for( i in length( eqns ) )
      {
        lhs[[i]] <- eval( formula( eqns[[i]] )[2] )
        rhs[[i]] <- eval( formula( eqns[[i]] )[3] )
        residi[[i]] <- lhs[[i]] - rhs[[i]]
        r <- rbind( r, as.matrix( residi[[i]] ) )
      }

    ## blah, blah, blah....

    knls <- obj
}


print( "calling nlstest" )
demand2 <- q ~ d0 + d1 * p + d2 * d
supply2 <- q ~ s0 + s1 * p + s2 * f + s3 * a
system2 <- list( demand2, supply2 )
sv2 <- c(d0=3,d2=4,d1=4.234,s0=-2.123,s2=2.123,s3=4.234,s1=0.234)

### call the nlm function to get the estimates...
estnew <- nlm( knls, sv2, hessian=TRUE, print.level=1, eqns=system2,
data=kmenta, fitmethod="OLS" )


My question is why can't I simply call names on the vector (sv2) that is
passed into the nlm function to get the parameters?

Thanks,
Jeff.



---
Jeff D. Hamann
Hamann, Donald and Associates, Inc.
PO Box 1421
Corvallis, Oregon USA 97339-1421
(office) 541-754-1428
(cell) 541-740-5988
jeff_hamann at hamanndonald.com
www.hamanndonald.com



From huut2003 at yahoo.ca  Tue Sep 30 05:38:24 2003
From: huut2003 at yahoo.ca (p hu)
Date: Mon, 29 Sep 2003 23:38:24 -0400 (EDT)
Subject: [R] shared object
Message-ID: <20030930033824.17868.qmail@web14811.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030929/f3907447/attachment.pl

From Arnaud.Dowkiw at dpi.qld.gov.au  Tue Sep 30 05:49:21 2003
From: Arnaud.Dowkiw at dpi.qld.gov.au (Dowkiw, Arnaud)
Date: Tue, 30 Sep 2003 13:49:21 +1000
Subject: [R] Wricke's ecovalences
Message-ID: <200309300349.h8U3nO5T019540@dpi-gw1.dpi.qld.gov.au>

Help !
Does anybody know how to calculate Wricke's ecovalences with R ?
Thanks.
 
Arnaud 

********************************DISCLAIMER******************...{{dropped}}



From fjmolina at ams.ucsc.edu  Tue Sep 30 08:00:56 2003
From: fjmolina at ams.ucsc.edu (Francisco J Molina)
Date: Mon, 29 Sep 2003 23:00:56 -0700
Subject: [R] debugging R
Message-ID: <16249.7192.159280.380253@dhcp-63-193.cse.ucsc.edu>


To debug R "from within Xemacs" I have tried two different things: 

C-u M-x R RET - d SPC gdb RET to start an inferior R process with arguments
@option{-d gdb}

This is the way described in the official documentation of R.

and also 

M-x R and then start GUD (M-x gdb) giving the R binary (using its full path
name: /usr/bin/R ) as the program to debug. Use the program @command{ps} to find the
process number of the currently running R process then use the attach
command in gdb to attach it to that process.

I have had problems with the last way: R freezes.

Has anyone been succesfull in debugging R in last way?

Thank you.



From hwood at iprimus.com.au  Tue Sep 30 07:59:53 2003
From: hwood at iprimus.com.au (Hannah Wood)
Date: Tue, 30 Sep 2003 15:59:53 +1000
Subject: [R] NNet value and convergence
Message-ID: <000e01c38718$138cb820$2de832d2@hannah>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030930/4eb00c2f/attachment.pl

From andrejk at zrc-sazu.si  Tue Sep 30 08:29:47 2003
From: andrejk at zrc-sazu.si (Andrej Kveder)
Date: Tue, 30 Sep 2003 08:29:47 +0200
Subject: [R] FW: error predicting values from the LME
Message-ID: <FHEEJBDDCNPPNJEACDJACEMBDDAA.andrejk@zrc-sazu.si>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030930/f77a9faf/attachment.pl

From ligges at statistik.uni-dortmund.de  Tue Sep 30 08:56:03 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 30 Sep 2003 08:56:03 +0200
Subject: [R] shared object
In-Reply-To: <20030930033824.17868.qmail@web14811.mail.yahoo.com>
References: <20030930033824.17868.qmail@web14811.mail.yahoo.com>
Message-ID: <3F792903.7010401@statistik.uni-dortmund.de>

p hu wrote:

> Dear R-helper,
> I have one question for creating shared objects (C code) on Unix.
> Since there is a set of softwares (such as Rtools, Perl, etc.) to be dowloaded for generating shared objects on windows, I am wondering whether I need to install a set of these kind of softwares to generating shared objects on unix.
> 
> Assume I have a c code called foo.c, I just simly typed
>  
> R CMD SHLIB foo.c
> it tells me that 'make' not found.
>  
> Therefore could you tell me what software I need to install for generating shared objects on unix???

Well, at least "make" and some compiler, of course.
For details see  Appendix "Essential and useful other programs" in the 
"R Installation and Administration" manual.

Uwe Ligges


> Thanks
>  
> Hu
> 
> 
> 
> ---------------------------------
> Post your free ad now! Yahoo! Canada Personals
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From maechler at stat.math.ethz.ch  Tue Sep 30 09:54:43 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 30 Sep 2003 09:54:43 +0200
Subject: [R] shared object
In-Reply-To: <20030930033824.17868.qmail@web14811.mail.yahoo.com>
References: <20030930033824.17868.qmail@web14811.mail.yahoo.com>
Message-ID: <16249.14019.644615.239231@gargle.gargle.HOWL>

>>>>> "Hu" == p hu <huut2003 at yahoo.ca>
>>>>>     on Mon, 29 Sep 2003 23:38:24 -0400 (EDT) writes:

    Hu> Dear R-helper, I have one question for creating shared
    Hu> objects (C code) on Unix.  Since there is a set of
    Hu> softwares (such as Rtools, Perl, etc.) to be dowloaded
    Hu> for generating shared objects on windows, I am wondering
    Hu> whether I need to install a set of these kind of
    Hu> softwares to generating shared objects on unix.

What is "unix" here?
There are many flavors of Unix around the most famous nowadays
is Linux which I guess you are *not* using.

Tell us what
     "uname -a"
gives (or other relevant information about your "Unix").


    Hu> Assume I have a c code called foo.c, I just simly typed
 
    Hu> R CMD SHLIB foo.c 

    Hu> it tells me that 'make' not found.

which I guess is because "make" is not in your PATH, while it
still exists on your computer / file server.

    Hu> Therefore could you tell me what software I need to
    Hu> install for generating shared objects on unix???
 
Do you have a system administrator (person!) for your unix
environment?  If yes, ask her/him !
If no, you probably should learn quite a bit more about your
unix by reading a basic introduction...

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



From christoph.lehmann at gmx.ch  Tue Sep 30 10:16:11 2003
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Tue, 30 Sep 2003 10:16:11 +0200
Subject: [R] using identify() together with plot () and pixmap()
Message-ID: <1064909771.1121.37.camel@christophl>

Dear R users
I have a two-dimensional array, whose values I want to plot, using the
pixmapGrey class. Plotting works fine, and now I would like to be able
to identify some of the points in the plot using identify(). But I get
the following message while pressing the left mouse button:

> plot(pixmapGrey(fmri.vtc[,,slice,volume]))
> identify(fmri.vtc[,,slice,volume])
warning: no point with 0.25 inches


pressing the right mouse button I get:
numeric(0)

what is the problem  here and how can I solve it?

many thanks for your help

Cheers! 

Christoph


-- 
Christoph Lehmann <christoph.lehmann at gmx.ch>



From Arnaud.Dowkiw at dpi.qld.gov.au  Tue Sep 30 10:31:56 2003
From: Arnaud.Dowkiw at dpi.qld.gov.au (Dowkiw, Arnaud)
Date: Tue, 30 Sep 2003 18:31:56 +1000
Subject: [R] Biclassification
Message-ID: <200309300831.h8U8Vx5T003162@dpi-gw1.dpi.qld.gov.au>

Is there any R package/function for biclassification (hierarchical reciprocal clustering of 2 factors) ?
Thanks,

Arnaud 

********************************DISCLAIMER******************...{{dropped}}



From B.Rowlingson at lancaster.ac.uk  Tue Sep 30 10:38:31 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 30 Sep 2003 09:38:31 +0100
Subject: [R] using identify() together with plot () and pixmap()
In-Reply-To: <1064909771.1121.37.camel@christophl>
References: <1064909771.1121.37.camel@christophl>
Message-ID: <3F794107.2010907@lancaster.ac.uk>

Christoph Lehmann wrote:

>>plot(pixmapGrey(fmri.vtc[,,slice,volume]))
>>identify(fmri.vtc[,,slice,volume])
> 
> warning: no point with 0.25 inches
> 
> 
> pressing the right mouse button I get:
> numeric(0)
> 
> what is the problem  here and how can I solve it?

  The problem is that there is no method for identifying points on a 
pixmap (and anyway, you are feeding identify() a matrix).

  You'll need to write an "identify.pixmapGrey" function. This would do 
something like use the 'locator()' function to get clicks on the screen, 
and then it would compute which grid cell the coordinates of those 
clicks were in. pixmap objects store enough information for you to work 
this out from the attributes - look at the 'bbox' attribute for example.

  It would make a nice addition to the pixmap library. Although one 
thing that just suprised me was that the different flavours of pixmap - 
pixmapGrey, pixmapIndexed, pixmapRGB - dont all inherit from a 'pixmap' 
class, which might make it easier to write a single identify function 
for all the types.

Baz



From Friedrich.Leisch at ci.tuwien.ac.at  Tue Sep 30 11:07:14 2003
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Tue, 30 Sep 2003 11:07:14 +0200
Subject: [R] using identify() together with plot () and pixmap()
In-Reply-To: <1064909771.1121.37.camel@christophl>
References: <1064909771.1121.37.camel@christophl>
Message-ID: <16249.18370.736719.829281@galadriel.ci.tuwien.ac.at>

>>>>> On Tue, 30 Sep 2003 10:16:11 +0200,
>>>>> Christoph Lehmann (CL) wrote:

  > Dear R users
  > I have a two-dimensional array, whose values I want to plot, using the
  > pixmapGrey class. Plotting works fine, and now I would like to be able
  > to identify some of the points in the plot using identify(). But I get
  > the following message while pressing the left mouse button:

  >> plot(pixmapGrey(fmri.vtc[,,slice,volume]))
  >> identify(fmri.vtc[,,slice,volume])
  > warning: no point with 0.25 inches


identify() needs x and y values, you are passing it the z values of
the image.

Maybe you want to use locator()?

.f



From ligges at statistik.uni-dortmund.de  Tue Sep 30 11:37:58 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 30 Sep 2003 11:37:58 +0200
Subject: [R] BIC or AIC from nnet
In-Reply-To: <5.1.0.14.2.20030929170243.00b154e8@mailkardia.sph.umich.edu>
References: <5.1.0.14.2.20030929170243.00b154e8@mailkardia.sph.umich.edu>
Message-ID: <3F794EF6.7040900@statistik.uni-dortmund.de>

Paul Green wrote:

> Is AIC or BIC available when using the
> nnet package?

Given you are talking about multinom(): Yes, it returns the AIC for the 
fit, but that's already mentioned in the help file...

Uwe Ligges


> Thank you
> 
> Paul Green
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Friedrich.Leisch at ci.tuwien.ac.at  Tue Sep 30 11:38:34 2003
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Tue, 30 Sep 2003 11:38:34 +0200
Subject: [R] using identify() together with plot () and pixmap()
In-Reply-To: <3F794107.2010907@lancaster.ac.uk>
References: <1064909771.1121.37.camel@christophl>
	<3F794107.2010907@lancaster.ac.uk>
Message-ID: <16249.20250.565338.580965@galadriel.ci.tuwien.ac.at>

>>>>> On Tue, 30 Sep 2003 09:38:31 +0100,
>>>>> Barry Rowlingson (BR) wrote:

  > Christoph Lehmann wrote:
  >>> plot(pixmapGrey(fmri.vtc[,,slice,volume]))
  >>> identify(fmri.vtc[,,slice,volume])
  >> 
  >> warning: no point with 0.25 inches
  >> 
  >> 
  >> pressing the right mouse button I get:
  >> numeric(0)
  >> 
  >> what is the problem  here and how can I solve it?

  >   The problem is that there is no method for identifying points on a 
  > pixmap (and anyway, you are feeding identify() a matrix).

  >   You'll need to write an "identify.pixmapGrey" function. This would do 
  > something like use the 'locator()' function to get clicks on the screen, 
  > and then it would compute which grid cell the coordinates of those 
  > clicks were in. pixmap objects store enough information for you to work 
  > this out from the attributes - look at the 'bbox' attribute for example.

  >   It would make a nice addition to the pixmap library. Although one 
  > thing that just suprised me was that the different flavours of pixmap - 
  > pixmapGrey, pixmapIndexed, pixmapRGB - dont all inherit from a 'pixmap' 
  > class,

But they do, and class "pixmap" has the necessary geometry
information, i.e., size, bounding box and resolution of the image.

  > which might make it easier to write a single identify function 
  > for all the types.

yes, shouldn't bbe too hard (all contributions welcome).

.f



From elsawy at ysbl.york.ac.uk  Tue Sep 30 11:39:14 2003
From: elsawy at ysbl.york.ac.uk (Karim Elsawy)
Date: Tue, 30 Sep 2003 10:39:14 +0100
Subject: [R] rgl crashes R
References: <3.0.5.32.20030908131309.007d7790@pop-server.ucl.ac.uk>
Message-ID: <3F794F41.7644D855@ysbl.york.ac.uk>

I was using rgl library and it was going well, all of a sudden it
started to crash 
which leads R to quit giving this error message

X Error of failed request:  BadValue (integer parameter out of range for
operation)
  Major opcode of failed request:  142 (XFree86-DRI)
  Minor opcode of failed request:  13 ()
  Value in failed request:  0x2e00067
  Serial number of failed request:  705
  Current serial number in output stream:  705

what is intriguing is that when I re-run R it works only for the first
time and fails
again every second time

this almost the same script I used:
step.x<-20;step.y<-20;step.z<-15
xseq <- seq(-300,300,step.x)
yseq<-  seq(-300,300,step.y)
zseq <- seq(-105,105,step.z)
library(rgl)
       rgl.open() 
      
rgl.bbox(xseq,yseq,zseq,xlab=xseq,ylab=yseq,zlab=zseq,color="yellow")
min.tmp<-c(2.2,4.5,9.3)
rgl.spheres(min.tmp[1],min.tmp[2],min.tmp[3],radius=10)

and I'm using R 1.7.1 under linux red hat

any ideas what is going wrong
best regards
karim



From ligges at statistik.uni-dortmund.de  Tue Sep 30 11:54:39 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 30 Sep 2003 11:54:39 +0200
Subject: [R] NNet value and convergence
In-Reply-To: <000e01c38718$138cb820$2de832d2@hannah>
References: <000e01c38718$138cb820$2de832d2@hannah>
Message-ID: <3F7952DF.6010502@statistik.uni-dortmund.de>

Hannah Wood wrote:

> Hi,  
> 
> I'm using the R nnet package and have a few simple (?) questions.  
> 
> What is the "value " that is output after every 10 iterations during the training of the network and how is it calculated? 
> 
> # weights:  177
> initial  value 506.134586 
> iter  10 value 128.222774
> iter  20 value 95.399782
> iter  30 value 87.184564
> ...
> 
> Is the "value" the error, if not, is there any way to see the error values during training?  

 From ?nnet:
"value of fitting criterion plus weight decay term."


> Also, how does the network decide when it has converged?  

More than one criterion. You can adjust the criterions with arguments to 
nnet(), see ?nnet.

Please read the references given in ?nnet for more details:

- Ripley, B. D. (1996) Pattern Recognition and Neural Networks. Cambridge.
- Venables, W. N. and Ripley, B. D. (2002) Modern Applied Statistics 
with S. Fourth edition. Springer.


Uwe Ligges


> Thanks
> 
> Hannah



From ligges at statistik.uni-dortmund.de  Tue Sep 30 11:55:23 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 30 Sep 2003 11:55:23 +0200
Subject: [R] Parsing R matrix to C
In-Reply-To: <1064865001.3f788ce9de933@webmail.uniriotec.br>
References: <1064865001.3f788ce9de933@webmail.uniriotec.br>
Message-ID: <3F79530B.5020400@statistik.uni-dortmund.de>

daniel.ielpo at uniriotec.br wrote:

> I'm developing a C dll to use as a package in R. I need to parse a R Matrix as 
> a parameter to a function in a dll. I?d like to know how can I use the Sexp 
> type and how to handle this as a matrix in the C code.

There are several examples in the R sources, just read the code and go on.

Uwe Ligges


> Sorry for the bad english.
> 
> Thanks,
> 
> Daniel Ielpo
> 
> -------------------------------------------------
> This mail sent through IMP: http://horde.org/imp/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From ligges at statistik.uni-dortmund.de  Tue Sep 30 12:06:35 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 30 Sep 2003 12:06:35 +0200
Subject: [R] CP for rpart
In-Reply-To: <BAY1-F150VAhwrZV2Xq0000d421@hotmail.com>
References: <BAY1-F150VAhwrZV2Xq0000d421@hotmail.com>
Message-ID: <3F7955AB.7060207@statistik.uni-dortmund.de>

weidong zhang wrote:

> Hi All,
> 
> I have some questions on using library rpart. Given my data below, the 
> plotcp gives me increasing 'xerrors' across different cp's with huge 
> xstd (plot attached). What causes the problem or it's not a problem at 
> all? I am thinking 'xerror's should be decreasing when 'cp' gets 
> smaller. 

No. Why? BTW: It's calculated by cross validation.


 > Also what the 'xstd' really tells us? If the error bars for
> each xerror overlap for different cp's, does that mean we don't have 
> significant improvement for misclassification rate when we split the tree?
 >
> 
> My data have are two classes with 138 observations and 129 attributes. 

Your problem is called overfitting, I guess.

Are you sure the class variable can be "explained" by the other 
variables in a way? Do you think the linear and othogonal separation of 
classes is appropriate for your problem?

You might want to look into a good book on Classification Theory.

Uwe Ligges


> Here is what I did:
> 
>> dim(man.dat[,c(1,8:136)])
> 
> [1] 138 130
> 
>> man.dt1 <- rpart(Target~.,data=man.dat[,c(1,8:136)], 
>> method='class',cp=1e-5, parms=list(split='information'))
> 
> 
>> plotcp(man.dt1)
> 
> 
>> printcp(man.dt1)
> 
> 
> Classification tree:
> rpart(formula = Target ~ ., data = man.dat[, c(1, 8:136)], method = 
> "class",
>    parms = list(split = "information"), cp = 1e-05)
> 
> Variables actually used in tree construction:
> [1] CHX.V  CYN.Cu SPF.Bi
> 
> Root node error: 25/138 = 0.18116
> 
> n= 138
> 
>       CP nsplit rel error xerror    xstd
> 1 0.18667      0      1.00   1.00 0.18098
> 2 0.00001      3      0.44   1.12 0.18897
> 
> 
> I would appreciate your help on this,
 >
> Weidong
> 
> _________________________________________________________________
> Instant message with integrated webcam using MSN Messenger 6.0. Try it 
> now FREE!  http://msnmessenger-download.com
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From mailinglist.wegmann at web.de  Tue Sep 30 12:41:07 2003
From: mailinglist.wegmann at web.de (Martin Wegmann)
Date: Tue, 30 Sep 2003 12:41:07 +0200
Subject: [R] cluster & mgcv update
Message-ID: <200309301241.07603.mailinglist.wegmann@web.de>

Hello, 

After reinstalling the whole OS and R as well, I tried to update.packages() 
and get the follwing error message:

concerning the mgcv update: atlas2-base is installed and blas as well (on 
debian). I haven't found lf77blas, I assume it's a library or something 
similar associated with blas.

any suggestion how to solve that, thanks Martin


* Installing *source* package 'cluster' ...
** libs
gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp  -fPIC  -g -O2 -c 
clara.c -o clara.o
g77 -mieee-fp  -fPIC  -g -O2 -c daisy.f -o daisy.o
make: g77: Command not found
make: *** [daisy.o] Error 127
ERROR: compilation failed for package 'cluster'

* Installing *source* package 'mgcv' ...
** libs
gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp -Wall -pedantic  
-fPIC  -g -O2 -c gcv.c -o gcv.o
gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp -Wall -pedantic  
-fPIC  -g -O2 -c magic.c -o magic.o
gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp -Wall -pedantic  
-fPIC  -g -O2 -c mat.c -o mat.o
gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp -Wall -pedantic  
-fPIC  -g -O2 -c matrix.c -o matrix.o
gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp -Wall -pedantic  
-fPIC  -g -O2 -c mgcv.c -o mgcv.o
gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp -Wall -pedantic  
-fPIC  -g -O2 -c qp.c -o qp.o
gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp -Wall -pedantic  
-fPIC  -g -O2 -c tprs.c -o tprs.o
gcc -shared  -o mgcv.so gcv.o magic.o mat.o matrix.o mgcv.o qp.o tprs.o 
-L/usr/lib/R/bin -lRlapack -lf77blas -latlas 
-L/usr/lib/gcc-lib/i386-linux/3.3 -L/usr/lib/gcc-lib/i386-linux/3.3/../../.. 
-lfrtbegin -lg2c-pic -lm -lgcc_s  -L/usr/lib/R/bin -lR
/usr/bin/ld: cannot find -lf77blas
collect2: ld returned 1 exit status
make: *** [mgcv.so] Error 1
ERROR: compilation failed for package 'mgcv'

Delete downloaded files (y/N)? y

Warning messages:
1: Installation of package cluster had non-zero exit status in: 
install.packages(update[, "Package"], instlib, contriburl = contriburl,
2: Installation of package mgcv had non-zero exit status in: 
install.packages(update[, "Package"], instlib, contriburl = contriburl,
>



From ligges at statistik.uni-dortmund.de  Tue Sep 30 12:57:31 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 30 Sep 2003 12:57:31 +0200
Subject: [R] cluster & mgcv update
In-Reply-To: <200309301241.07603.mailinglist.wegmann@web.de>
References: <200309301241.07603.mailinglist.wegmann@web.de>
Message-ID: <3F79619B.6000100@statistik.uni-dortmund.de>

Martin Wegmann wrote:

> Hello, 
> 
> After reinstalling the whole OS and R as well, I tried to update.packages() 
> and get the follwing error message:
> 
> concerning the mgcv update: atlas2-base is installed and blas as well (on 
> debian). I haven't found lf77blas, I assume it's a library or something 
> similar associated with blas.
> 
> any suggestion how to solve that, thanks Martin
> 
> 
> * Installing *source* package 'cluster' ...
> ** libs
> gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp  -fPIC  -g -O2 -c 
> clara.c -o clara.o
> g77 -mieee-fp  -fPIC  -g -O2 -c daisy.f -o daisy.o
> make: g77: Command not found
> make: *** [daisy.o] Error 127
> ERROR: compilation failed for package 'cluster'


The Fortran Compiler g77 is missing (at least not in your path), as well 
as some related libraries (see error message below).

Uwe Ligges


> * Installing *source* package 'mgcv' ...
> ** libs
> gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp -Wall -pedantic  
> -fPIC  -g -O2 -c gcv.c -o gcv.o
> gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp -Wall -pedantic  
> -fPIC  -g -O2 -c magic.c -o magic.o
> gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp -Wall -pedantic  
> -fPIC  -g -O2 -c mat.c -o mat.o
> gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp -Wall -pedantic  
> -fPIC  -g -O2 -c matrix.c -o matrix.o
> gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp -Wall -pedantic  
> -fPIC  -g -O2 -c mgcv.c -o mgcv.o
> gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp -Wall -pedantic  
> -fPIC  -g -O2 -c qp.c -o qp.o
> gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp -Wall -pedantic  
> -fPIC  -g -O2 -c tprs.c -o tprs.o
> gcc -shared  -o mgcv.so gcv.o magic.o mat.o matrix.o mgcv.o qp.o tprs.o 
> -L/usr/lib/R/bin -lRlapack -lf77blas -latlas 
> -L/usr/lib/gcc-lib/i386-linux/3.3 -L/usr/lib/gcc-lib/i386-linux/3.3/../../.. 
> -lfrtbegin -lg2c-pic -lm -lgcc_s  -L/usr/lib/R/bin -lR
> /usr/bin/ld: cannot find -lf77blas
> collect2: ld returned 1 exit status
> make: *** [mgcv.so] Error 1
> ERROR: compilation failed for package 'mgcv'
> 
> Delete downloaded files (y/N)? y
> 
> Warning messages:
> 1: Installation of package cluster had non-zero exit status in: 
> install.packages(update[, "Package"], instlib, contriburl = contriburl,
> 2: Installation of package mgcv had non-zero exit status in: 
> install.packages(update[, "Package"], instlib, contriburl = contriburl,
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From edd at debian.org  Tue Sep 30 13:26:10 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 30 Sep 2003 06:26:10 -0500
Subject: [R] cluster & mgcv update
In-Reply-To: <200309301241.07603.mailinglist.wegmann@web.de>
References: <200309301241.07603.mailinglist.wegmann@web.de>
Message-ID: <20030930112610.GA13944@sonny.eddelbuettel.com>

On Tue, Sep 30, 2003 at 12:41:07PM +0200, Martin Wegmann wrote:
> concerning the mgcv update: atlas2-base is installed and blas as well (on 
> debian). I haven't found lf77blas, I assume it's a library or something 
> similar associated with blas.
> 
> any suggestion how to solve that, thanks Martin

You need to add atlas2-base-dev:

$ apt-get install atlas2-base-dev

Dirk
--

Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From mailinglist.wegmann at web.de  Tue Sep 30 14:04:23 2003
From: mailinglist.wegmann at web.de (Martin Wegmann)
Date: Tue, 30 Sep 2003 14:04:23 +0200
Subject: [R] cluster & mgcv update
In-Reply-To: <20030930112610.GA13944@sonny.eddelbuettel.com>
References: <200309301241.07603.mailinglist.wegmann@web.de>
	<20030930112610.GA13944@sonny.eddelbuettel.com>
Message-ID: <200309301404.23558.mailinglist.wegmann@web.de>


> You need to add atlas2-base-dev:
>
> $ apt-get install atlas2-base-dev

I installed atlas2-base-dev and g77 but know I get the error messages pasted 
below. Both (cluster and mgcv) requires lfrtbegin, but that does not seem to 
be programm which I can install via apt-get. 

Martin

* Installing *source* package 'cluster' ...
** libs
gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp  -fPIC  -g -O2 -c 
clara.c -o clara.o
g77 -mieee-fp  -fPIC  -g -O2 -c daisy.f -o daisy.o
g77 -mieee-fp  -fPIC  -g -O2 -c fanny.f -o fanny.o
g77 -mieee-fp  -fPIC  -g -O2 -c meet.f -o meet.o
g77 -mieee-fp  -fPIC  -g -O2 -c mona.f -o mona.o
g77 -mieee-fp  -fPIC  -g -O2 -c pam.f -o pam.o
gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp  -fPIC  -g -O2 -c 
spannel.c -o spannel.o
g77 -mieee-fp  -fPIC  -g -O2 -c twins.f -o twins.o
gcc -shared  -o cluster.so clara.o daisy.o fanny.o meet.o mona.o pam.o 
spannel.o twins.o  -L/usr/lib/gcc-lib/i386-linux/3.3 
-L/usr/lib/gcc-lib/i386-linux/3.3/../../.. -lfrtbegin -lg2c-pic -lm -lgcc_s 
-L/usr/lib/R/bin -lR
/usr/bin/ld: cannot find -lfrtbegin
collect2: ld returned 1 exit status
make: *** [cluster.so] Error 1
ERROR: compilation failed for package 'cluster'
* Installing *source* package 'mgcv' ...
** libs
gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp -Wall -pedantic  
-fPIC  -g -O2 -c gcv.c -o gcv.o
gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp -Wall -pedantic  
-fPIC  -g -O2 -c magic.c -o magic.o
gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp -Wall -pedantic  
-fPIC  -g -O2 -c mat.c -o mat.o
gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp -Wall -pedantic  
-fPIC  -g -O2 -c matrix.c -o matrix.o
gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp -Wall -pedantic  
-fPIC  -g -O2 -c mgcv.c -o mgcv.o
gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp -Wall -pedantic  
-fPIC  -g -O2 -c qp.c -o qp.o
gcc -I/usr/lib/R/include   -D__NO_MATH_INLINES -mieee-fp -Wall -pedantic  
-fPIC  -g -O2 -c tprs.c -o tprs.o
gcc -shared  -o mgcv.so gcv.o magic.o mat.o matrix.o mgcv.o qp.o tprs.o 
-L/usr/lib/R/bin -lRlapack -lf77blas -latlas 
-L/usr/lib/gcc-lib/i386-linux/3.3 -L/usr/lib/gcc-lib/i386-linux/3.3/../../.. 
-lfrtbegin -lg2c-pic -lm -lgcc_s  -L/usr/lib/R/bin -lR
/usr/bin/ld: cannot find -lfrtbegin
collect2: ld returned 1 exit status
make: *** [mgcv.so] Error 1
ERROR: compilation failed for package 'mgcv'

Delete downloaded files (y/N)? y

Warning messages:
1: Installation of package cluster had non-zero exit status in: 
install.packages(update[, "Package"], instlib, contriburl = contriburl,
2: Installation of package mgcv had non-zero exit status in: 
install.packages(update[, "Package"], instlib, contriburl = contriburl,
>



From christoph.lehmann at gmx.ch  Tue Sep 30 14:09:35 2003
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Tue, 30 Sep 2003 14:09:35 +0200
Subject: [R] overlay two pixmap
In-Reply-To: <Pine.LNX.4.44.0309261231300.24559-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0309261231300.24559-100000@reclus.nhh.no>
Message-ID: <1064923774.3067.13.camel@christophl>

when I try to overlay a completely transparent pixmap on another pixmap,
I get an error.

For reproduction: just the transparent pixmap itself gives an error:

tmp <- array(0,c(x.dim,y.dim))
tmp <- pixmapIndexed(tmp[,])
for (x in 1:x.dim) {
for (y in 1:y.dim) {
tmp at index[x,y] <- NA 
} }
plot(tmp)

---- Error:

Error in image.default(x = X, y = Y, z = t(x at index[nrow(x at index):1, ]), 
:
        invalid z limits
In addition: Warning messages:
1: no finite arguments to min; returning Inf
2: no finite arguments to max; returning -Inf


what happened here? 

many thanks

christoph


On Fri, 2003-09-26 at 12:44, Roger Bivand wrote:
> Christoph Lehmann wrote:
> 
> > I need to overlay two pixmaps (library (pixmap)). One, a pixmapGrey, is
> > the basis, and on this I need to overlay a pixmapIndexed, BUT: the
> > pixmapIndexed has set only some of its "pixels" to an indexed color,
> > many of its pixels should not cover the basis pixmapGrey pixel, means,
> > for this "in pixmapIndexed not defined pixels" it should be transparent.
> 
> > What would you recommend me to do? Should I go for another solution than
> > pixmap?
> 
> Determine which of the indexed colours in the pixmapIndexed object are to 
> be transparent, and change them to NA - you access them in say:
> 
> library(pixmap)
> x <- read.pnm(system.file("pictures/logo.ppm", package = "pixmap")[1])
> x
> plot(x)
> xx <- as(x, "pixmapIndexed")
> xx
> plot(xx)
> example(pixmap)
> z <- pixmapRGB(c(z1, z2, z3), 100, 100, bbox = c(0, 0, 100, 100))
> plot(z)
> xx at col[1:20]
> xx at col[1] <- NA
> plot(xx, add=T)
> 
> Here xx at col[1] was "white" aka "#FFFFFF", you could use col2rgb() to help 
> set thresholds. Admittedly, this is messy if you don't know your 
> threshold.
> 
> Roger
-- 
Christoph Lehmann <christoph.lehmann at gmx.ch>



From ahenningsen at email.uni-kiel.de  Tue Sep 30 14:18:11 2003
From: ahenningsen at email.uni-kiel.de (Arne Henningsen)
Date: Tue, 30 Sep 2003 14:18:11 +0200
Subject: [R] checking generic/method consistency
In-Reply-To: <000f01c38444$e0d9ab70$3b0040d5@maths.lth.se>
References: <000f01c38444$e0d9ab70$3b0040d5@maths.lth.se>
Message-ID: <200309301418.11208.ahenningsen@email.uni-kiel.de>

Hi *,

thanks for all your answers and discussions. And additionally special thanks 
to Henrik Bengtsson for writing the first draft of the "R Coding 
Conventions". I think that this document contains a lot of good ideas to make 
the code more readable. Since my package is *new* code, I adjusted it 
according to most recommendations of the RCC.

However, one thing is still unclear to me: According to the RCC I gave the 
class of result of my function "linProg" also the name "linProg", but the RCC 
says that classes must start with uppercase, while functions must start with 
lowercase, which is contradictory in this case. In one of the examples of the 
RCC, a function that returns an object with a class attribute starts with 
uppercase:
> Line <- function(x0, y0, x1, y1) {
>   line <- list(x=c(x0,y0), y=(x1,y1));
>   class(line) <- "Line";
>   line;
> }
Does this mean that the names of these functions should start with uppercase?

Best wishes,
Arne


On Friday 26 September 2003 17:43, you wrote:
> Hi, it looks from the names of your argument that your function is a
> "plain function", i.e. it is not a function specific to a class. If this
> is true, I would avoid the period and rename your function to
>
>   solveLP <- function(cvec, bvec, Amat, maximum, maxiter, verbose) ...
>
> Under the S3 style of programming with classes methods coupled to
> classes are written in the format
>
>   method.class <- function(object, arg1, arg2, ...
>
> That is, the part before the period is the name of a generic function
> and the part after is the name of the class. This is why R CMD check
> believe your that you have written a method 'solve' for class 'LP'. All
> methods named 'solve' should have a argument signature that match the
> generic function 'solve' and your solve.LP doesn't. I do not think this
> was your intention, correct? See help.start() -> "R Language Definition"
> -> "Object-oriented programming:" for more details about the S3 style.
>
> To avoid problems like these I am working on a R Coding Conventions
> (RCC), http://www.maths.lth.se/help/R/RCC/ (see Naming Conventions). It
> is an early version and not everyone agrees with it, but the intention
> is to find a style that avoid problems like yours, where it says that
> you should avoid periods in function names except if you use it for S3
> class methods. Feedback is appreciated.
>
> Cheers
>
> Henrik Bengtsson
> Lund University
>
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Arne Henningsen
> > Sent: den 26 september 2003 17:03
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] checking generic/method consistency
> >
> >
> > Hi,
> >
> > I wrote a package for linear programming and want to submit
> > it to CRAN.
> > Since the package 'quadprog' has a function with the name
> > 'solve.QP' to
> > perform Quadratic Programming, I named my (main) function 'solve.LP'.
> > However 'R CMD check' gives one warning:
> >
> > * checking generic/method consistency ... WARNING
> > solve:
> >   function(a, b, ...)
> > solve.LP:
> >   function(cvec, bvec, Amat, maximum, maxiter, verbose)
> >
> > while 'R CMD check' gives no warnings when the function has the name
> > 'solve.QP'.
> >
> > What do you recommend me to do?
> > 1) Ignore the warning and upload the package to CRAN as it is?
> > 2) Rename the function? (any suggestions?)
> > 3) Change something that avoids this problem without renaming
> > the functions?
> >
> > I would prefer the third point, but I don't know how.
> >
> > Thank you for your answers,
> >
> > Arne
> >
> > --
> > Arne Henningsen
> > Department of Agricultural Economics
> > Christian-Albrechts-University Kiel 24098 Kiel, Germany
> > Tel: +49-431-880-4445
> > Fax: +49-431-880-1397
> > ahenningsen at email.uni-kiel.de
> > http://www.uni-> kiel.de/agrarpol/ahenningsen.html
> >
> >
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo> /r-help

-- 
Arne Henningsen
Department of Agricultural Economics
Christian-Albrechts-University Kiel
24098 Kiel, Germany
Tel: +49-431-880-4445
Fax: +49-431-880-1397 
ahenningsen at email.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/



From edd at debian.org  Tue Sep 30 14:20:57 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 30 Sep 2003 07:20:57 -0500
Subject: [R] cluster & mgcv update
In-Reply-To: <200309301404.23558.mailinglist.wegmann@web.de>
References: <200309301241.07603.mailinglist.wegmann@web.de>
	<20030930112610.GA13944@sonny.eddelbuettel.com>
	<200309301404.23558.mailinglist.wegmann@web.de>
Message-ID: <20030930122057.GA14336@sonny.eddelbuettel.com>

On Tue, Sep 30, 2003 at 02:04:23PM +0200, Martin Wegmann wrote:
> 
> > You need to add atlas2-base-dev:
> >
> > $ apt-get install atlas2-base-dev
> 
> I installed atlas2-base-dev and g77 but know I get the error messages pasted 
> below. Both (cluster and mgcv) requires lfrtbegin, but that does not seem to 
> be programm which I can install via apt-get. 

Weird.   

When R is built, certain configure values are recorded, see (on Debian) the
files in /etc/R/:

edd at homebud:/etc/R> grep frtb * 
Makeconf:FLIBS =  -L/usr/lib/gcc-lib/i486-linux/3.3.2
-L/usr/lib/gcc-lib/i486-linux/3.3.2/../../.. -lfrtbegin -lg2c-pic -lm -lgcc_s

If your Makeconf has values stored that your system doesn't have, then you
may have a mismatch between the compiler used for building R (i.e. the
binary you got yourself) and the one currently installed to build the package.

Let's discuss off-line exactly what Debian 'flavour' and gcc/g77 versions
you are using.  

One way out for you would be to rebuild R locally. We can discuss that too.

Dirk

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From d_pleydell at yahoo.com  Tue Sep 30 14:28:58 2003
From: d_pleydell at yahoo.com (=?iso-8859-1?q?David=20Pleydell?=)
Date: Tue, 30 Sep 2003 13:28:58 +0100 (BST)
Subject: [R] non-linear trends in kriging model
Message-ID: <20030930122858.55871.qmail@web41507.mail.yahoo.com>

Hi 
I am struggling to fit a non-linear trend using the
likfit function in geoR.

Specifically I want a sigmoidal function, something
like SSfpl in the nls package to fit the trend.  But
it seems trend.spatial in geoR only works with lm or
glm type models.

Any ideas how I can specify the model to calculate the
kriging parameters using REML, including the
parameters of a sigmoidal trend function (such as
SSfpl)?

Thanks
David



From paulojus at est.ufpr.br  Tue Sep 30 14:46:09 2003
From: paulojus at est.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Tue, 30 Sep 2003 09:46:09 -0300 (BRT)
Subject: [R] non-linear trends in kriging model
In-Reply-To: <20030930122858.55871.qmail@web41507.mail.yahoo.com>
References: <20030930122858.55871.qmail@web41507.mail.yahoo.com>
Message-ID: <Pine.LNX.4.56.0309300940120.4635@gauss.est.ufpr.br>

David

Indeed, the trend term in geoR must be a linear one.
You can:
1) fit you model by alternating between using nls() and passing the
residuals to the functions in geoR
or
2) try trying to fit using the functions in the nlme() package

Regards
P.J.

On Tue, 30 Sep 2003, David Pleydell wrote:

> Hi
> I am struggling to fit a non-linear trend using the
> likfit function in geoR.
>
> Specifically I want a sigmoidal function, something
> like SSfpl in the nls package to fit the trend.  But
> it seems trend.spatial in geoR only works with lm or
> glm type models.
>
> Any ideas how I can specify the model to calculate the
> kriging parameters using REML, including the
> parameters of a sigmoidal trend function (such as
> SSfpl)?
>
> Thanks
> David
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>

Paulo Justiniano Ribeiro Jr
Departamento de Estat?stica
Universidade Federal do Paran?
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 361 3471
Fax: (+55) 41 361 3141
e-mail: pj at est.ufpr.br
http://www.est.ufpr.br/~paulojus



From spencer.graves at pdf.com  Tue Sep 30 15:13:13 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 30 Sep 2003 08:13:13 -0500
Subject: [R] FW: error predicting values from the LME
In-Reply-To: <FHEEJBDDCNPPNJEACDJACEMBDDAA.andrejk@zrc-sazu.si>
References: <FHEEJBDDCNPPNJEACDJACEMBDDAA.andrejk@zrc-sazu.si>
Message-ID: <3F798169.9020201@pdf.com>

      Could you dumb it down to a toy example with 4 observations for a 
model like "y ~ 1 | inter", 2 observations for each of 2 levels of 
"inter"?  If that works, then you can play with the example that works 
and the example that doesn't;  this is one of the strategies mentioned 
in Poly (1971) How to Solve It (Princeton U. Pr.).  With luck, this will 
help you figure out what you need to do to get the answers you want.  If 
not, it should help you produce a small toy example that doesn't work, 
which you can then send us.  Please include a data.frame call, so 
someone can copy your example into R and try it in 2 seconds.  That 
should increase the chances that you would get a helpful reply. 

      Also, have you read Pinhiero and Bates (2000) Mixed-Effect Models 
in S and S-Plus (Springer)?  I've found that book to be indispensible 
for using "lme". 

      hope this helps.  spencer graves

Andrej Kveder wrote:

>HI all,
>
>I might add some more information in order to possibly solve my problem. I'm
>really stuck and no obvious solutions do the trick.
>I'm using R 1.7.1 on Windows 2000 with the packages regurarly updated.
>I'm using hypothetical data constructed as a pseudo population conforming to
>a certain Var-Cov structure.
>I might add that just
>
>  
>
>>predict(level2)
>>    
>>
>
>works. But when I add the new dataset it doesn't. Following a suggestion I
>even tried refactoring of the grouping variable (inter) after I created the
>subset. It didn't work. I have no other factor variables in the model. I
>really have got no clue what could be wrong.
>
>There is a sample from my data:
>  
>
>>dnNew
>>    
>>
>Grouped Data: y ~ v11 + v21 + v22 + v23 | inter
>         v11             v21          v22         v23    inter
>4 5.55186635 5.6620022 24.18033 5.003409 1
>13 2.03852426 5.6620022 24.18033 5.003409 1
>15 2.19825772 7.5676798 31.03986 4.746891 2
>16 4.51368278 7.5676798 31.03986 4.746891 2
>18 3.35322702 7.5676798 31.03986 4.746891 2
>19 2.46414346 7.5676798 31.03986 4.746891 2
>20 2.66670834 7.5676798 31.03986 4.746891 2
>
>and this is the model:
>  
>
>>level2
>>    
>>
>Linear mixed-effects model fit by REML
>Data: d.n.gr.2
>Log-restricted-likelihood: -533.0011
>Fixed: model$fixed
>(Intercept) v11 v21 v22 v23 v11:v21
>3.205519074 0.298941539 -0.017743958 0.016007280 -0.410760471 0.002700954
>v11:v22 v11:v23
>-0.003680952 -0.018005717
>Random effects:
>Formula: ~v11 | inter
>Structure: General positive-definite, Log-Cholesky parametrization
>StdDev Corr
>(Intercept) 0.385620605 (Intr)
>v11 0.003147431 -0.048
>Residual 0.450012367
>Number of Observations: 729
>Number of Groups: 50
>If this give you some more insight to my problem.
>
>I would reallly appreciate any suggestion.
>
>Thanks
>
>Andrej
>
>-----Original Message-----
>From: Andrej Kveder [mailto:andrejk at zrc-sazu.si]
>Sent: Monday, September 29, 2003 7:05 PM
>To: R-Help
>Subject: predicting values from the LME
>
>
>Dear listers,
>
>I experinced a problem prdicting the values using the LME with multilevel
>data.
>I have NA's in my dependent variable and the model is fitted only on the
>completed cases.
>I want to estimate the predicted values for the rest of the data (those
>cases with missing dep. variable)
>I extracted a subset from the original file containing the variables used in
>the model as well as the second level indicator.
>I used the following command
>
>p<-predict(level2,newdata=d.n.new,level=0:1)
>
>where level2 is my LME model.
>But, I get the following error:
>
>Error in eval(expr, envir, enclos) : 1 argument passed to "$" which requires
>2.
>
>I tried with omitting the level specification (which is 0 by default) and I
>transformed the new data to be groupedData with no luck.
>
>I have tried the example from the Pinheiro,Bates book and it works - mine
>doesn't. Does anybody have an idea what could be wrong?
>
>Thanks for all the suggestions.
>
>Andrej
>
>_________
>Andrej Kveder, M.A.
>researcher
>Institute of Medical Sciences SRS SASA; Novi trg 2, SI-1000 Ljubljana,
>Slovenia
>phone: +386 1 47 06 440   fax: +386 1 42 61 493
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From bates at stat.wisc.edu  Tue Sep 30 15:11:21 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 30 Sep 2003 13:11:21 -0000
Subject: [R] debugging R
In-Reply-To: <16249.7192.159280.380253@dhcp-63-193.cse.ucsc.edu>
References: <16249.7192.159280.380253@dhcp-63-193.cse.ucsc.edu>
Message-ID: <6rad8mqv35.fsf@bates4.stat.wisc.edu>

Francisco J Molina <fjmolina at ams.ucsc.edu> writes:

> To debug R "from within Xemacs" I have tried two different things: 
> 
> C-u M-x R RET - d SPC gdb RET to start an inferior R process with arguments
> @option{-d gdb}
> 
> This is the way described in the official documentation of R.
> 
> and also 
> 
> M-x R and then start GUD (M-x gdb) giving the R binary (using its full path
> name: /usr/bin/R ) as the program to debug. Use the program @command{ps} to find the
> process number of the currently running R process then use the attach
> command in gdb to attach it to that process.
> 
> I have had problems with the last way: R freezes.

That is because gdb has interrupted the R process.  At this point I
usually set a breakpoint at the function of interest, go to the gdb
window and restart R by sending the 0 signal

gdb> sig 0

Then you are able to get a response in the ESS window with R.

This technique is particularly useful if you have compiled code in a
package because you can attach the package and load the shared object
before invoking the debugger.

> Has anyone been succesfull in debugging R in last way?

Yes - more times than I would care to count.



From maechler at stat.math.ethz.ch  Tue Sep 30 15:23:10 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 30 Sep 2003 15:23:10 +0200
Subject: [R] checking generic/method consistency
In-Reply-To: <200309301418.11208.ahenningsen@email.uni-kiel.de>
References: <000f01c38444$e0d9ab70$3b0040d5@maths.lth.se>
	<200309301418.11208.ahenningsen@email.uni-kiel.de>
Message-ID: <16249.33726.139183.772475@gargle.gargle.HOWL>

>>>>> "Arne" == Arne Henningsen <ahenningsen at email.uni-kiel.de>
>>>>>     on Tue, 30 Sep 2003 14:18:11 +0200 writes:

    Arne> Hi *,

    Arne> thanks for all your answers and discussions. And
    Arne> additionally special thanks to Henrik Bengtsson for
    Arne> writing the first draft of the "R Coding
    Arne> Conventions". I think that this document contains a
    Arne> lot of good ideas to make the code more
    Arne> readable. Since my package is *new* code, I adjusted
    Arne> it according to most recommendations of the RCC.

    Arne> However, one thing is still unclear to me: According
    Arne> to the RCC I gave the class of result of my function
    Arne> "linProg" also the name "linProg", but the RCC says
    Arne> that classes must start with uppercase, while
    Arne> functions must start with lowercase, which is
    Arne> contradictory in this case. In one of the examples of
    Arne> the RCC, a function that returns an object with a
    Arne> class attribute starts with uppercase:

    >> Line <- function(x0, y0, x1, y1) {
    >>      line <- list(x=c(x0,y0), y=(x1,y1));
    >>      class(line) <- "Line";
    >>      line;
    >> }

do not end lines with ";" in S (i.e. R or S-plus); it's
superfluous and considered ugly by many (incl. me) and teaches
(by example) a wrong idea.

    Arne> Does this mean that the names of these functions
    Arne> should start with uppercase?

While I agree that Henrik has put up several well thought out
recommendations {and very helpful postings such as the one you
cite below!} , these are *Henrik*'s recommendations and are
still subject to discussion and feedback.
The S language has quite a long tradition and existing function
and class base which cannot be changed mostly for compatibility
reasons.
One thing in this tradition is to have function "foobar" return
objects of class "foobar" (identical spelling including case).
This particularly applies to the "old" or S3 class/method system
on which still very much of the basic S models are based.
When using S3 classes (as you are above), I'd definitely keep
that S tradition.

This naming scheme can well change when the S4 class/methods
system is used (as it is more and more), since there, you
construct objects rather by   
  new("<classname>",....),
  as(obj, "<classname>", ....)
etc.

Regards,
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><


    Arne> On Friday 26 September 2003 17:43, you wrote:
    >> Hi, it looks from the names of your argument that your function is a
    >> "plain function", i.e. it is not a function specific to a class. If this
    >> is true, I would avoid the period and rename your function to
    >> 
    >> solveLP <- function(cvec, bvec, Amat, maximum, maxiter, verbose) ...
    >> 
    >> Under the S3 style of programming with classes methods coupled to
    >> classes are written in the format
    >> 
    >> method.class <- function(object, arg1, arg2, ...
    >> 
    >> That is, the part before the period is the name of a generic function
    >> and the part after is the name of the class. This is why R CMD check
    >> believe your that you have written a method 'solve' for class 'LP'. All
    >> methods named 'solve' should have a argument signature that match the
    >> generic function 'solve' and your solve.LP doesn't. I do not think this
    >> was your intention, correct? See help.start() -> "R Language Definition"
    -> "Object-oriented programming:" for more details about the S3 style.
    >> 
    >> To avoid problems like these I am working on a R Coding Conventions
    >> (RCC), http://www.maths.lth.se/help/R/RCC/ (see Naming Conventions). It
    >> is an early version and not everyone agrees with it, but the intention
    >> is to find a style that avoid problems like yours, where it says that
    >> you should avoid periods in function names except if you use it for S3
    >> class methods. Feedback is appreciated.
    >> 
    >> Cheers
    >> 
    >> Henrik Bengtsson
    >> Lund University
    >> 
    >> > -----Original Message-----
    >> > From: r-help-bounces at stat.math.ethz.ch
    >> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Arne Henningsen
    >> > Sent: den 26 september 2003 17:03
    >> > To: r-help at stat.math.ethz.ch
    >> > Subject: [R] checking generic/method consistency
    >> >
    >> >
    >> > Hi,
    >> >
    >> > I wrote a package for linear programming and want to submit
    >> > it to CRAN.
    >> > Since the package 'quadprog' has a function with the name
    >> > 'solve.QP' to
    >> > perform Quadratic Programming, I named my (main) function 'solve.LP'.
    >> > However 'R CMD check' gives one warning:
    >> >
    >> > * checking generic/method consistency ... WARNING
    >> > solve:
    >> >   function(a, b, ...)
    >> > solve.LP:
    >> >   function(cvec, bvec, Amat, maximum, maxiter, verbose)
    >> >
    >> > while 'R CMD check' gives no warnings when the function has the name
    >> > 'solve.QP'.
    >> >
    >> > What do you recommend me to do?
    >> > 1) Ignore the warning and upload the package to CRAN as it is?
    >> > 2) Rename the function? (any suggestions?)
    >> > 3) Change something that avoids this problem without renaming
    >> > the functions?
    >> >
    >> > I would prefer the third point, but I don't know how.
    >> >
    >> > Thank you for your answers,
    >> >
    >> > Arne
    >> >
    >> > --
    >> > Arne Henningsen
    >> > Department of Agricultural Economics
    >> > Christian-Albrechts-University Kiel 24098 Kiel, Germany
    >> > Tel: +49-431-880-4445
    >> > Fax: +49-431-880-1397
    >> > ahenningsen at email.uni-kiel.de
    >> > http://www.uni-> kiel.de/agrarpol/ahenningsen.html
    >> >
    >> >
    >> >
    >> > ______________________________________________
    >> > R-help at stat.math.ethz.ch mailing list
    >> > https://www.stat.math.ethz.ch/mailman/listinfo> /r-help

    Arne> -- 
    Arne> Arne Henningsen
    Arne> Department of Agricultural Economics
    Arne> Christian-Albrechts-University Kiel
    Arne> 24098 Kiel, Germany
    Arne> Tel: +49-431-880-4445
    Arne> Fax: +49-431-880-1397 
    Arne> ahenningsen at email.uni-kiel.de
    Arne> http://www.uni-kiel.de/agrarpol/ahenningsen/

    Arne> ______________________________________________
    Arne> R-help at stat.math.ethz.ch mailing list
    Arne> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From MZodet at ahrq.gov  Tue Sep 30 15:24:20 2003
From: MZodet at ahrq.gov (MZodet@ahrq.gov)
Date: Tue, 30 Sep 2003 09:24:20 -0400
Subject: [R] Stepwise procedures
Message-ID: <3598558AD728D41183350008C7CF291C0A5CD36C@exchange1.ahrq.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030930/90ea7a6d/attachment.pl

From ahenningsen at email.uni-kiel.de  Tue Sep 30 17:14:17 2003
From: ahenningsen at email.uni-kiel.de (Arne Henningsen)
Date: Tue, 30 Sep 2003 17:14:17 +0200
Subject: [R] checking generic/method consistency
In-Reply-To: <16249.33726.139183.772475@gargle.gargle.HOWL>
References: <000f01c38444$e0d9ab70$3b0040d5@maths.lth.se>
	<200309301418.11208.ahenningsen@email.uni-kiel.de>
	<16249.33726.139183.772475@gargle.gargle.HOWL>
Message-ID: <200309301714.17592.ahenningsen@email.uni-kiel.de>

On Tuesday 30 September 2003 15:23, Martin Maechler wrote:
> >>>>> "Arne" == Arne Henningsen <ahenningsen at email.uni-kiel.de>
> >>>>>     on Tue, 30 Sep 2003 14:18:11 +0200 writes:
>
>     Arne> Hi *,
>
>     Arne> thanks for all your answers and discussions. And
>     Arne> additionally special thanks to Henrik Bengtsson for
>     Arne> writing the first draft of the "R Coding
>     Arne> Conventions". I think that this document contains a
>     Arne> lot of good ideas to make the code more
>     Arne> readable. Since my package is *new* code, I adjusted
>     Arne> it according to most recommendations of the RCC.
>
>     Arne> However, one thing is still unclear to me: According
>     Arne> to the RCC I gave the class of result of my function
>     Arne> "linProg" also the name "linProg", but the RCC says
>     Arne> that classes must start with uppercase, while
>     Arne> functions must start with lowercase, which is
>     Arne> contradictory in this case. In one of the examples of
>     Arne> the RCC, a function that returns an object with a
>
>     Arne> class attribute starts with uppercase:
>     >> Line <- function(x0, y0, x1, y1) {
>     >>      line <- list(x=c(x0,y0), y=(x1,y1));
>     >>      class(line) <- "Line";
>     >>      line;
>     >> }
>
> do not end lines with ";" in S (i.e. R or S-plus); it's
> superfluous and considered ugly by many (incl. me) and teaches
> (by example) a wrong idea.

Fortunately, I adjusted my code according to *most* (and not all) 
recommendations of the RCC and e.g. did *not* add the (also in my opinion) 
ugly semicolons.

>     Arne> Does this mean that the names of these functions
>     Arne> should start with uppercase?
>
> While I agree that Henrik has put up several well thought out
> recommendations {and very helpful postings such as the one you
> cite below!} , these are *Henrik*'s recommendations and are
> still subject to discussion and feedback.
> The S language has quite a long tradition and existing function
> and class base which cannot be changed mostly for compatibility
> reasons.
> One thing in this tradition is to have function "foobar" return
> objects of class "foobar" (identical spelling including case).
> This particularly applies to the "old" or S3 class/method system
> on which still very much of the basic S models are based.
> When using S3 classes (as you are above), I'd definitely keep
> that S tradition.

Thanks for your comment. Now I don't feel so bad if I ignore some of Henrik's 
RCCs ;-). However, I think it's important for us to agree on some coding 
conventions since the inconsistency of the syntax between R packages is a 
drawback of R (see e.g. Jeff Racine, Rob Hyndman: Using R to teach 
econometrics, Journal of Applied Econometrics 17 (2002), p. 176, 
http://www3.interscience.wiley.com/cgi-bin/fulltext/93514548/PDFSTART).
I there a discussion on R coding conventions taking place at the moment?

Best wishes,
Arne

> This naming scheme can well change when the S4 class/methods
> system is used (as it is more and more), since there, you
> construct objects rather by
>   new("<classname>",....),
>   as(obj, "<classname>", ....)
> etc.
>
> Regards,
> Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
> Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
> ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
> phone: x-41-1-632-3408		fax: ...-1228			<><
>
>     Arne> On Friday 26 September 2003 17:43, you wrote:
>     >> Hi, it looks from the names of your argument that your function is a
>     >> "plain function", i.e. it is not a function specific to a class. If
>     >> this is true, I would avoid the period and rename your function to
>     >>
>     >> solveLP <- function(cvec, bvec, Amat, maximum, maxiter, verbose) ...
>     >>
>     >> Under the S3 style of programming with classes methods coupled to
>     >> classes are written in the format
>     >>
>     >> method.class <- function(object, arg1, arg2, ...
>     >>
>     >> That is, the part before the period is the name of a generic
>     >> function and the part after is the name of the class. This is why R
>     >> CMD check believe your that you have written a method 'solve' for
>     >> class 'LP'. All methods named 'solve' should have a argument
>     >> signature that match the generic function 'solve' and your solve.LP
>     >> doesn't. I do not think this was your intention, correct? See
>     >> help.start() -> "R Language Definition"
>
>     -> "Object-oriented programming:" for more details about the S3 style.
>
>     >> To avoid problems like these I am working on a R Coding Conventions
>     >> (RCC), http://www.maths.lth.se/help/R/RCC/ (see Naming Conventions).
>     >> It is an early version and not everyone agrees with it, but the
>     >> intention is to find a style that avoid problems like yours, where
>     >> it says that you should avoid periods in function names except if
>     >> you use it for S3 class methods. Feedback is appreciated.
>     >>
>     >> Cheers
>     >>
>     >> Henrik Bengtsson
>     >> Lund University
>     >>
>     >> > -----Original Message-----
>     >> > From: r-help-bounces at stat.math.ethz.ch
>     >> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Arne
>     >> > Henningsen Sent: den 26 september 2003 17:03
>     >> > To: r-help at stat.math.ethz.ch
>     >> > Subject: [R] checking generic/method consistency
>     >> >
>     >> >
>     >> > Hi,
>     >> >
>     >> > I wrote a package for linear programming and want to submit
>     >> > it to CRAN.
>     >> > Since the package 'quadprog' has a function with the name
>     >> > 'solve.QP' to
>     >> > perform Quadratic Programming, I named my (main) function
>     >> > 'solve.LP'. However 'R CMD check' gives one warning:
>     >> >
>     >> > * checking generic/method consistency ... WARNING
>     >> > solve:
>     >> >   function(a, b, ...)
>     >> > solve.LP:
>     >> >   function(cvec, bvec, Amat, maximum, maxiter, verbose)
>     >> >
>     >> > while 'R CMD check' gives no warnings when the function has the
>     >> > name 'solve.QP'.
>     >> >
>     >> > What do you recommend me to do?
>     >> > 1) Ignore the warning and upload the package to CRAN as it is?
>     >> > 2) Rename the function? (any suggestions?)
>     >> > 3) Change something that avoids this problem without renaming
>     >> > the functions?
>     >> >
>     >> > I would prefer the third point, but I don't know how.
>     >> >
>     >> > Thank you for your answers,
>     >> >
>     >> > Arne
>     >> >
>     >> > --
>     >> > ______________________________________________
>     >> > R-help at stat.math.ethz.ch mailing list
>     >> > https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
>
>     Arne> ______________________________________________
>     Arne> R-help at stat.math.ethz.ch mailing list
>     Arne> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
Arne Henningsen
Department of Agricultural Economics
Christian-Albrechts-University Kiel
24098 Kiel, Germany
Tel: +49-431-880-4445
Fax: +49-431-880-1397 
ahenningsen at email.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/



From xavier.fim at eresmas.net  Tue Sep 30 17:42:02 2003
From: xavier.fim at eresmas.net (Xavier =?iso-8859-1?q?Fern=E1ndez=20i=20Mar=EDn?=)
Date: Tue, 30 Sep 2003 17:42:02 +0200
Subject: [R] Generation of labels for 2 factors
Message-ID: <200309301742.02974.xavier.fim@eresmas.net>

Hello,

I have a data set with 10 countries, 10 sectors of public policy and 15 years 
like
country	sector	year
a	aa	1980
a	aa	1981
...
a	bb	1980
a	bb	1981
...
b	aa	1980
b	aa	1981
...
b	bb	1980
b	bb	1981
....

with 1500 observations.

My cases are the couple country/sector. So, I want to have 100 cases over 15 
years. (both country and sector are factors)

I want to assign to each case a label (e.i. country 'a' + sector 'aa' have 
value '1', country 'a' + sector 'b' have value 2...) and I have been trying 
differents ways, but I can't.


Is there a function to do it directly or I have to write a function? 

Thank you,


Xavier



From feh3k at spamcop.net  Tue Sep 30 17:43:13 2003
From: feh3k at spamcop.net (Frank E Harrell Jr)
Date: Tue, 30 Sep 2003 17:43:13 +0200
Subject: [R] Stepwise procedures
In-Reply-To: <3598558AD728D41183350008C7CF291C0A5CD36C@exchange1.ahrq.gov>
References: <3598558AD728D41183350008C7CF291C0A5CD36C@exchange1.ahrq.gov>
Message-ID: <20030930174313.3cf596da.feh3k@spamcop.net>

On Tue, 30 Sep 2003 09:24:20 -0400
MZodet at ahrq.gov wrote:

> Is there a function in R which performs stepwise estimation in ways similar
> to SAS/STATA (i.e., allows the analyst to specify the significance levels
> for removal/addition of terms).
> 
>  
> 
> I've been asked to evaluate two final models:  one resulting from a
> backwards selection in R (stepAIC) and one resulting from a backwards
> selection using PROC LOGISTIC in SAS.  The final terms are slightly
> different and I'm trying to understand the differences between the two
> packages (approaches) so I can explain why the final terms might be
> different.
> 
>  
> 
> Thanks for your help.
> 
>  
> 
> Marc
>

Marc,

Stepwise variable selection doesn't work well for the sample size you are using.

Frank
---
Frank E Harrell Jr    Professor and Chair            School of Medicine
                      Department of Biostatistics    Vanderbilt University



From mt at michaelltaylor.com  Tue Sep 30 17:50:27 2003
From: mt at michaelltaylor.com (michaell taylor)
Date: Tue, 30 Sep 2003 15:50:27 -0000
Subject: [R] ts - unit conversion
Message-ID: <1064937066.7343.23.camel@xeon>


I've been using R for a while, but now find myself needing to understand
time-series objects for a short course I am teaching.  I am putting
together some daily financial datasets for illustration, but having some
trouble in aggregating the data to months or weeks. I am getting a
"cannot change frequency from 1 to 12" message.  

I am not sure that aggregation is where I want to go anyway.  Assuming
for the moment that I had one full year of data, I would like the
observations to relate to real months with various numbers of days, not
simply 1/12th of a year.  It is unclear to me how sophisticated the
aggregator is in this regard.

I have V&R but it seems there may be some SPlus/R differences here. Any
suggestions for documents that addresses these issues would be
wonderful.  Thanks.

> ibm <- get.hist.quote('ibm',start='2003-01-01')
trying URL
`http://chart.yahoo.com/table.csv?s=ibm&a=11&b=31&c=2002&d=8&e=28&f=2003&g=d&q=q&y=0&z=ibm&x=.csv'
Content type `application/octet-stream' length unknown
opened URL
........
downloaded 8990 bytes

time series starts 2002-12-30
time series ends   2003-09-25

Just to check what I have....

> attributes(ibm)
$dim
[1] 270   4

$dimnames
$dimnames[[1]]
NULL

$dimnames[[2]]
[1] "Open"  "High"  "Low"   "Close"


$tsp
[1] 37621 37890     1

$class
[1] "mts" "ts"

Attempting to pull monthly means .....

> aggregate(ibm,12,mean)
Error in aggregate.ts(ibm, 12, mean) : cannot change frequency from 1 to
12

I thought perhaps I had a non-integer number of months in the data which
may be causing problems.

> length(ibm)
[1] 1080
> 1080/12
[1] 90
>

Alternatively...making the data coordinate to real months...
> ibm <- get.hist.quote('ibm',start='2003-01-01',end='2003-08-31')
trying URL
`http://chart.yahoo.com/table.csv?s=ibm&a=11&b=31&c=2002&d=7&e=30&f=2003&g=d&q=q&y=0&z=ibm&x=.csv'
Content type `application/octet-stream' length unknown
opened URL
.......
downloaded 8082 bytes

time series starts 2002-12-30
time series ends   2003-08-28
> aggregate(ibm,12,mean)
Error in aggregate.ts(ibm, 12, mean) : cannot change frequency from 1 to
12



From matjaz.kukar at fri.uni-lj.si  Tue Sep 30 18:10:59 2003
From: matjaz.kukar at fri.uni-lj.si (Matjaz Kukar)
Date: Tue, 30 Sep 2003 18:10:59 +0200
Subject: [R] Grouped bar plots
Message-ID: <3F79AB13.E6CEDB86@fri.uni-lj.si>

Dear R experts!

I'm wondering if it is possible in R to make
a certain type of bar plots, in S-Plus
known as "Grouped Bar Plots" (see the attachment
for an example).

In S-Plus they can be created with 
the guiPlot function.

Thank you for any answers.

Best regards,

Matjaz.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: grouped_barplot.png
Type: image/png
Size: 2698 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030930/b6a7782d/grouped_barplot.png

From ligges at statistik.uni-dortmund.de  Tue Sep 30 18:11:14 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 30 Sep 2003 18:11:14 +0200
Subject: [R] Grouped bar plots
In-Reply-To: <3F79AB13.E6CEDB86@fri.uni-lj.si>
References: <3F79AB13.E6CEDB86@fri.uni-lj.si>
Message-ID: <3F79AB22.2030405@statistik.uni-dortmund.de>

Matjaz Kukar wrote:
> Dear R experts!
> 
> I'm wondering if it is possible in R to make
> a certain type of bar plots, in S-Plus
> known as "Grouped Bar Plots" (see the attachment
> for an example).
> 
> In S-Plus they can be created with 
> the guiPlot function.
> 
> Thank you for any answers.

?barplot

Uwe Ligges

> Best regards,
> 
> Matjaz.
> 
> 
> ------------------------------------------------------------------------
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From mail at joeconway.com  Tue Sep 30 18:25:53 2003
From: mail at joeconway.com (Joe Conway)
Date: Tue, 30 Sep 2003 09:25:53 -0700
Subject: [R] R Production Performance
In-Reply-To: <017a01c3878d$e9c77f90$3201a8c0@zitan>
References: <OF8F028250.C58EE9BB-ON85256DAA.00422BB2@convergys.com>	<00d401c382c3$d0b4a880$3201a8c0@zitan>	<005301c38242$eba7c900$f07afea9@computer>	<3F7121EE.6070603@joeconway.com>	<011901c383aa$dc7d6430$414c4fcb@zitan>
	<3F72767C.6080509@joeconway.com>
	<017a01c3878d$e9c77f90$3201a8c0@zitan>
Message-ID: <3F79AE91.3070604@joeconway.com>

Zitan Broth wrote:
> Right but R is only "preloaded" once?

Yes. The plr shared library gets loaded and initialized (which in turn 
loads and initializes libR) only once -- on Postgres's postmaster 
startup. From that point forward, every new database connection gets a 
forked copy of the postmaster, and hence a preinitialized copy of the R 
interpreter.

Of course (as I think I mentioned already, but it is worth repeating) to 
get this performance enhancement you need to be using either Postgres 
7.4 beta or a patched version of Postgres 7.3 (found at the URL on the 
original post), and have the following line in your postgresql.conf:

preload_libraries = '$libdir/plr:plr_init'

This is getting a bit off topic, so if you have any more PL/R specific 
questions, please write me off list.

Joe



From andy_liaw at merck.com  Tue Sep 30 18:27:36 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 30 Sep 2003 12:27:36 -0400
Subject: [R] Generation of labels for 2 factors
Message-ID: <3A822319EB35174CA3714066D590DCD50205CBDE@usrymx25.merck.com>

Not sure exactly what you want, but try:

  countrySector <- factor(paste(df$country, df$sector, sep=":"))

where df is the data frame.  This creates a factor for the combination.  If
you want numeric code, just coerce with as.numeric().

HTH,
Andy

> -----Original Message-----
> From: Xavier Fern?ndez i Mar?n [mailto:xavier.fim at eresmas.net] 
> Sent: Tuesday, September 30, 2003 11:42 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Generation of labels for 2 factors
> 
> 
> Hello,
> 
> I have a data set with 10 countries, 10 sectors of public 
> policy and 15 years 
> like
> country	sector	year
> a	aa	1980
> a	aa	1981
> ...
> a	bb	1980
> a	bb	1981
> ...
> b	aa	1980
> b	aa	1981
> ...
> b	bb	1980
> b	bb	1981
> ....
> 
> with 1500 observations.
> 
> My cases are the couple country/sector. So, I want to have 
> 100 cases over 15 
> years. (both country and sector are factors)
> 
> I want to assign to each case a label (e.i. country 'a' + 
> sector 'aa' have 
> value '1', country 'a' + sector 'b' have value 2...) and I 
> have been trying 
> differents ways, but I can't.
> 
> 
> Is there a function to do it directly or I have to write a function? 
> 
> Thank you,
> 
> 
> Xavier
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
>



From Giles.Heywood at CommerzbankIB.com  Tue Sep 30 18:36:12 2003
From: Giles.Heywood at CommerzbankIB.com (Heywood, Giles)
Date: Tue, 30 Sep 2003 17:36:12 +0100
Subject: [R] ts - unit conversion
Message-ID: <8CBAA121CEB4D5118CB200508BB2BBEF5404B9@xmx8lonib.lonib.commerzbank.com>

Financial data, as you point out, is generally irregular, which is
in essence what prompted the devlopment of the irregular time-series
(its) package, which is posted on CRAN (v0.1.2 posted today, incidentally).
In the its class, the time-stamps of the rows of a matrix are represented 
using the POSIXct class, so irregularity can be represented accurately.

Inspection of get.hist.quote() shows that it would be quite straightforward
to adapt it to return an 'its'.  I would do so myself, but have no
spare time in the short term to do this (and I'm behind a proxy/firewall
which seems to complicate matters).

Giles

> -----Original Message-----
> From: michaell taylor [mailto:mt at michaelltaylor.com]
> Sent: 30 September 2003 16:51
> To: R-help at stat.math.ethz.ch
> Subject: [R] ts - unit conversion
> 
> 
> 
> I've been using R for a while, but now find myself needing to 
> understand
> time-series objects for a short course I am teaching.  I am putting
> together some daily financial datasets for illustration, but 
> having some
> trouble in aggregating the data to months or weeks. I am getting a
> "cannot change frequency from 1 to 12" message.  
> 
> I am not sure that aggregation is where I want to go anyway.  Assuming
> for the moment that I had one full year of data, I would like the
> observations to relate to real months with various numbers of 
> days, not
> simply 1/12th of a year.  It is unclear to me how sophisticated the
> aggregator is in this regard.
> 
> I have V&R but it seems there may be some SPlus/R differences 
> here. Any
> suggestions for documents that addresses these issues would be
> wonderful.  Thanks.
> 
> > ibm <- get.hist.quote('ibm',start='2003-01-01')
> trying URL
> `http://chart.yahoo.com/table.csv?s=ibm&a=11&b=31&c=2002&d=8&e
> =28&f=2003&g=d&q=q&y=0&z=ibm&x=.csv'
> Content type `application/octet-stream' length unknown
> opened URL
> ........
> downloaded 8990 bytes
> 
> time series starts 2002-12-30
> time series ends   2003-09-25
> 
> Just to check what I have....
> 
> > attributes(ibm)
> $dim
> [1] 270   4
> 
> $dimnames
> $dimnames[[1]]
> NULL
> 
> $dimnames[[2]]
> [1] "Open"  "High"  "Low"   "Close"
> 
> 
> $tsp
> [1] 37621 37890     1
> 
> $class
> [1] "mts" "ts"
> 
> Attempting to pull monthly means .....
> 
> > aggregate(ibm,12,mean)
> Error in aggregate.ts(ibm, 12, mean) : cannot change 
> frequency from 1 to
> 12
> 
> I thought perhaps I had a non-integer number of months in the 
> data which
> may be causing problems.
> 
> > length(ibm)
> [1] 1080
> > 1080/12
> [1] 90
> >
> 
> Alternatively...making the data coordinate to real months...
> > ibm <- get.hist.quote('ibm',start='2003-01-01',end='2003-08-31')
> trying URL
> `http://chart.yahoo.com/table.csv?s=ibm&a=11&b=31&c=2002&d=7&e
> =30&f=2003&g=d&q=q&y=0&z=ibm&x=.csv'
> Content type `application/octet-stream' length unknown
> opened URL
> .......
> downloaded 8082 bytes
> 
> time series starts 2002-12-30
> time series ends   2003-08-28
> > aggregate(ibm,12,mean)
> Error in aggregate.ts(ibm, 12, mean) : cannot change 
> frequency from 1 to
> 12
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


********************************************************************** 
This is a commercial communication from Commerzbank AG.\ \ T...{{dropped}}



From subianto at cs.uu.nl  Tue Sep 30 18:51:52 2003
From: subianto at cs.uu.nl (Muhammad Subianto)
Date: Tue, 30 Sep 2003 18:51:52 +0200
Subject: [R] Remove comma (,) in data set
Message-ID: <3F79B4A8.7020009@cs.uu.nl>

Dear R-helper,
I am new learning R. Now, I have a data set like:

24,2,3,3,1,1,2,3,0,1
45,1,3,10,1,1,3,4,0,1
43,2,3,7,1,1,3,4,0,1
42,3,2,9,1,1,3,3,0,1
36,3,3,8,1,1,3,2,0,1
19,4,4,0,1,1,3,3,0,1
38,2,3,6,1,1,3,2,0,1
21,3,3,1,1,0,3,2,0,1
27,2,3,3,1,1,3,4,0,1
45,1,1,8,1,1,2,2,1,1
... with 3730 rows

I want to remove comma (,) in data set. The result like:

24 2 3  3 1 1 2 3 0 1
45 1 3 10 1 1 3 4 0 1
43 2 3  7 1 1 3 4 0 1
42 3 2  9 1 1 3 3 0 1
36 3 3  8 1 1 3 2 0 1
19 4 4  0 1 1 3 3 0 1
38 2 3  6 1 1 3 2 0 1
21 3 3  1 1 0 3 2 0 1
27 2 3  3 1 1 3 4 0 1
45 1 1  8 1 1 2 2 1 1
...

How can I do it. Thanks you for your help.

Best regards,

Muhammad Subianto



From ggrothendieck at myway.com  Tue Sep 30 18:53:36 2003
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 30 Sep 2003 12:53:36 -0400 (EDT)
Subject: [R] ts - unit conversion
Message-ID: <20030930165336.A533C3986@xmxpita.myway.com>



Change the line in get.hist.quote that pastes the url together
so that g=d (i.e. daily) is replaced with g=m (i.e. monthly).  
That will cause monthly data to be downloaded.  With this new
get.hist.quote try this:

ibm <- get.hist.quote("ibm")
ibm <- ts( ibm[!is.na(rowSums(ibm)),], end=c(2003,8), freq=12 )

 --- On Tue 09/30, michaell taylor < mt at michaelltaylor.com > wrote:
I've been using R for a while, but now find myself needing to understand
time-series objects for a short course I am teaching. I am putting
together some daily financial datasets for illustration, but having some
trouble in aggregating the data to months or weeks. I am getting a
"cannot change frequency from 1 to 12" message. 

I am not sure that aggregation is where I want to go anyway. Assuming
for the moment that I had one full year of data, I would like the
observations to relate to real months with various numbers of days, not
simply 1/12th of a year. It is unclear to me how sophisticated the
aggregator is in this regard.

I have V&R but it seems there may be some SPlus/R differences here. Any
suggestions for documents that addresses these issues would be
wonderful. Thanks.

> ibm <- get.hist.quote('ibm',start='2003-01-01')
trying URL
`http://chart.yahoo.com/table.csv?s=ibm&a=11&b=31&c=2002&d=8&e=28&f=2003&g=d&q=q&y=0&z=ibm&x=.csv'
Content type `application/octet-stream' length unknown
opened URL
........
downloaded 8990 bytes

time series starts 2002-12-30
time series ends 2003-09-25

Just to check what I have....

> attributes(ibm)
$dim
[1] 270 4

$dimnames
$dimnames[[1]]
NULL

$dimnames[[2]]
[1] "Open" "High" "Low" "Close"


$tsp
[1] 37621 37890 1

$class
[1] "mts" "ts"

Attempting to pull monthly means .....

> aggregate(ibm,12,mean)
Error in aggregate.ts(ibm, 12, mean) : cannot change frequency from 1 to
12

I thought perhaps I had a non-integer number of months in the data which
may be causing problems.

> length(ibm)
[1] 1080
> 1080/12
[1] 90
>

Alternatively...making the data coordinate to real months...
> ibm <- get.hist.quote('ibm',start='2003-01-01',end='2003-08-31')
trying URL
`http://chart.yahoo.com/table.csv?s=ibm&a=11&b=31&c=2002&d=7&e=30&f=2003&g=d&q=q&y=0&z=ibm&x=.csv'
Content type `application/octet-stream' length unknown
opened URL
.......
downloaded 8082 bytes

time series starts 2002-12-30
time series ends 2003-08-28
> aggregate(ibm,12,mean)
Error in aggregate.ts(ibm, 12, mean) : cannot change frequency from 1 to
12



_______________________________________________
No banners. No pop-ups. No kidding.
Introducing My Way - http://www.myway.com



From dmurdoch at pair.com  Tue Sep 30 19:09:40 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue, 30 Sep 2003 13:09:40 -0400
Subject: [R] Remove comma (,) in data set
In-Reply-To: <3F79B4A8.7020009@cs.uu.nl>
References: <3F79B4A8.7020009@cs.uu.nl>
Message-ID: <kudjnv8va2hghate51k1b3k5aq0emnoji1@4ax.com>

On Tue, 30 Sep 2003 18:51:52 +0200, Muhammad Subianto
<subianto at cs.uu.nl> wrote :

>Dear R-helper,
>I am new learning R. Now, I have a data set like:
>
>24,2,3,3,1,1,2,3,0,1
>45,1,3,10,1,1,3,4,0,1
>... with 3730 rows
>
>I want to remove comma (,) in data set. The result like:
>
>24 2 3  3 1 1 2 3 0 1
>45 1 3 10 1 1 3 4 0 1
>...
>How can I do it. Thanks you for your help.

I assume you're talking about reading a file with commas, and writing
one without.

Use one of the read functions (e.g. read.csv, read.table, or scan)
which can deal with the commas on input.  Then write using write.table
with the default separator, a space.

You'll likely want non-default choices for the row.names and col.names
parameters.

Duncan Murdoch



From rxg218 at psu.edu  Tue Sep 30 19:10:12 2003
From: rxg218 at psu.edu (Rajarshi Guha)
Date: Tue, 30 Sep 2003 17:10:12 -0000
Subject: [R] subsetting a matrix
Message-ID: <1064942077.4121.6.camel@ra.chem.psu.edu>

Hi,
  I'm trying to take a set of rows and columns out of a matrix. I hve
been using the index aray approach. My overll matrix is X and is 179 x
65. I want to take out 4 columns and 161 rows.

Thus I made a 161 x 2 array I and filled it up with the row,col indices.
However doing,

X[ I ] gives me a vector of the extracted elements. Is there anyway I
can coerce this into a 161 x 4 matrix?

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
Disembowelling takes guts.



From arrayprofile at yahoo.com  Tue Sep 30 19:24:53 2003
From: arrayprofile at yahoo.com (array chip)
Date: Tue, 30 Sep 2003 10:24:53 -0700 (PDT)
Subject: [R] lme vs. aov
Message-ID: <20030930172453.45330.qmail@web41207.mail.yahoo.com>

Hi,

I have a question about using "lme" and "aov" for the
following dataset. If I understand correctly, using
"aov" with Error term in the formula is equivalent to
using "lme" with default settings, i.e. both assume
compound symmetry correlation structure. And I have
found that equivalency in the past. However, with the
follwing dataset, I got different answers, can anyone
explain what happened here? I have 2 differnt response
variables "x" and "y" in the following dataset, with
"y", I achieved the equivalency between "lme" and
"aov", but with "x", I got different p values for the
ANOVA table.

-------

x<-c(-0.0649,-0.0923,-0.0623,0.1809,0.0719,0.1017,0.0144,-0.1727,-0.1332,0.0986,0.304,-0.4093,0.2054,0.251,-0.1062,0.3833,
0.0649,0.2908,0.1073,0.0919,0.1167,0.2369,0.306,0.1379)

y<-c(-0.0649,-0.0923,0.32,0.08,0.0719,0.1017,0.05,-0.1727,-0.1332,0.15,0.304,-0.4093,0.2054,0.251,-0.1062,0.3833,0.0649,
0.2908,0.1073,0.0919,0.1167,0.2369,0.306,0.1379)

treat<-as.factor(c(1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2))
time<-as.factor(c(1,1,1,1,2,2,2,2,3,3,3,3,1,1,1,1,2,2,2,2,3,3,3,3))
sex<-as.factor(c('F','F','M','M','F','F','M','M','F','F','M','M','F','F','M','M','F','F','M','M','F','F','M','M'))
subject<-as.factor(c(rep(1:4,3),rep(5:8,3)))
xx<-cbind(x=data.frame(x),y=y,treat=treat,time=time,sex=sex,subject=subject)

######## using x as dependable variable

xx.lme<-lme(x~treat*sex*time,random=~1|subject,xx)
xx.aov<-aov(x~treat*sex*time+Error(subject),xx)

summary(xx.aov)

Error: subject
          Df   Sum Sq  Mean Sq F value  Pr(>F)  
treat      1 0.210769 0.210769  6.8933 0.05846 .
sex        1 0.005775 0.005775  0.1889 0.68627  
treat:sex  1 0.000587 0.000587  0.0192 0.89649  
Residuals  4 0.122304 0.030576                  
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.'
0.1 ` ' 1 

Error: Within
               Df  Sum Sq Mean Sq F value Pr(>F)
time            2 0.00102 0.00051  0.0109 0.9891
treat:time      2 0.00998 0.00499  0.1066 0.9002
sex:time        2 0.02525 0.01263  0.2696 0.7704
treat:sex:time  2 0.03239 0.01619  0.3458 0.7178
Residuals       8 0.37469 0.04684 

anova(xx.lme)
               numDF denDF  F-value p-value
(Intercept)        1     8 3.719117  0.0899
treat              1     4 5.089022  0.0871
sex                1     4 0.139445  0.7278
time               2     8 0.012365  0.9877
treat:sex          1     4 0.014175  0.9110
treat:time         2     8 0.120538  0.8880
sex:time           2     8 0.304878  0.7454
treat:sex:time     2     8 0.391012  0.6886

#### using y as dependable variable

xx.lme2<-lme(y~treat*sex*time,random=~1|subject,xx)
xx.aov2<-aov(y~treat*sex*time+Error(subject),xx)

 summary(xx.aov2)

Error: subject
          Df   Sum Sq  Mean Sq F value Pr(>F)
treat      1 0.147376 0.147376  2.0665 0.2239
sex        1 0.000474 0.000474  0.0067 0.9389
treat:sex  1 0.006154 0.006154  0.0863 0.7836
Residuals  4 0.285268 0.071317               

Error: Within
               Df   Sum Sq  Mean Sq F value Pr(>F)
time            2 0.009140 0.004570  0.1579 0.8565
treat:time      2 0.012598 0.006299  0.2177 0.8090
sex:time        2 0.043132 0.021566  0.7453 0.5049
treat:sex:time  2 0.069733 0.034866  1.2050 0.3488
Residuals       8 0.231480 0.028935               

anova(xx.lme2)
               numDF denDF   F-value p-value
(Intercept)        1     8 3.0667809  0.1180
treat              1     4 2.0664919  0.2239
sex                1     4 0.0066516  0.9389
time               2     8 0.1579473  0.8565
treat:sex          1     4 0.0862850  0.7836
treat:time         2     8 0.2177028  0.8090
sex:time           2     8 0.7453185  0.5049
treat:sex:time     2     8 1.2049883  0.3488



From tblackw at umich.edu  Tue Sep 30 19:34:44 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Tue, 30 Sep 2003 13:34:44 -0400 (EDT)
Subject: [R] subsetting a matrix
In-Reply-To: <1064942077.4121.6.camel@ra.chem.psu.edu>
References: <1064942077.4121.6.camel@ra.chem.psu.edu>
Message-ID: <Pine.SOL.4.58.0309301331150.3042@rygar.gpcc.itd.umich.edu>

Rajarshi  -

Why not simply subscript your matrix X to return the rows and
columns you want to keep ?  For example,

new <- X[16:176, c(3,5,7,9)]

assuming those are the rows and columns you want.
See  help("Extract").

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Tue, 30 Sep 2003, Rajarshi Guha wrote:

>   I'm trying to take a set of rows and columns out of a matrix. I hve
> been using the index aray approach. My overll matrix is X and is 179 x
> 65. I want to take out 4 columns and 161 rows.
>
> Thus I made a 161 x 2 array I and filled it up with the row,col indices.
> However doing,
>
> X[ I ] gives me a vector of the extracted elements. Is there anyway I
> can coerce this into a 161 x 4 matrix?
>
> -------------------------------------------------------------------
> Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
> GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
> -------------------------------------------------------------------



From mathieu.drapeau at bioneq.qc.ca  Tue Sep 30 20:14:55 2003
From: mathieu.drapeau at bioneq.qc.ca (Mathieu Drapeau)
Date: Tue, 30 Sep 2003 14:14:55 -0400
Subject: [R] generic function object
Message-ID: <3F79C81F.2030100@bioneq.qc.ca>

Hi,
I would like to know if there is a way to see the code of a generic 
function?
Like when I only type the function name, it prints the source of that 
function. But I cannot see the code of a generic function, it prints:
...
function (object, ...)
standardGeneric("normalize")
<environment: 0x8e9e368>
Methods may be defined for arguments: object
...

Thanks,
Mathieu



From spencer.graves at pdf.com  Tue Sep 30 21:01:33 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 30 Sep 2003 12:01:33 -0700
Subject: [R] Preserving names from "p" to "f" in "nlm" (was:  can't get
	names from vector in nlm calls)
In-Reply-To: <001201c386ff$2d7e9a00$0a00a8c0@rodan>
References: <001201c386ff$2d7e9a00$0a00a8c0@rodan>
Message-ID: <3F79D30D.2090707@pdf.com>

Perhaps someone else can help you figure out how to preserve the names 
from argument "p" to function "f" in calls to "nlm", but I'm now beyond 
the limits of my knowledge.  I'm sorry, but I can't help further with 
this. 

Spencer Graves
########################
Jeff D. Hamann wrote:

I started looking at the R and C code to examine where to change this and
found the

SEXP do_nlm(SEXP call, SEXP op, SEXP args, SEXP rho)

function, but I'm not really sure how to modifiy yet to preserve the
variable names, if there are variable names when it gets to that function.
Plus I'd have to install lots of new and potentially conflicting tools on my
win32 machine and then debug to the code... so i think I'm going to have to
find another solution to my problem, which is a drag as the solution I
originally thought of (get the names from p vector) would be the best one so
far.

Jeff.

----- Original Message ----- 
From: "Spencer Graves" <spencer.graves at pdf.com>
To: "Spencer Graves" <spencer.graves at pdf.com>
Cc: "Jeff D. Hamann" <jeff_hamann at hamanndonald.com>
Sent: Tuesday, September 30, 2003 5:44 AM
Subject: Re: [R] can't get names from vector in nlm calls



>     I've written functions to ask first if the input vector had
>names.  If it didn't, I checked the length and then assigned the names I
>expected it to have.  Then I checked the names.  That worked for me.
>
>      I believe it would be possible to get nlm/optim to preserve the
>names, as you ask.  However, it would not be easy, and it might slow
>down the code.  To check this, I typed "nlm" and "optim" at a command
>prompt and read the code.  When I did that, I found that most of the
>work in both is done via a call to ".Internal", which passes control to
>a compiled function.  R is open source, which means you could get the
>source code and modify it to do what you want.  However, that would be
>difficult, at least for me.
>
>      hope this helps.  spencer graves
>
>Jeff D. Hamann wrote:
>
> >optim give the same results. is it possible to "get" nlm/optim to
>  
>
preserve

> >the names?
> >
> >
> >----- Original Message -----
> >From: "Spencer Graves" <spencer.graves at pdf.com>
> >To: "Jeff D. Hamann" <jeff_hamann at hamanndonald.com>
> >Sent: Monday, September 29, 2003 8:18 PM
> >Subject: Re: [R] can't get names from vector in nlm calls
> >
> >
> >
> >
> >>      I have not used nlm, but it may not preserve the names of the
> >>starting values in "p".
> >>
> >>      hope this helps.  spencer graves
> >>
> >>Jeff D. Hamann wrote:
> >>
> >>
> >>
> >>>I've been trying to figure out how to get the names of the parameter
> >>>
> >>>
> >vector
> >
> >
> >>>variables when inside the function that nlm calls to return the
>objective
> >>>function value:
> >>>
> >>>knls <- function( theta, eqns, data, fitmethod="OLS", instr=NULL,
> >>>
> >>>
> >S=NULL )
> >
> >
> >>> {
> >>>
> >>>   ##     print( names( theta ) )              # returns NULL
> >>>   ## get the values of the parameters
> >>>   for( i in 1:length( theta ) )
> >>>     {
> >>>       val <- theta[i]
> >>>       storage.mode( val ) <-  "double"
> >>>       assign( names( theta )[i], val )          # gags here cause I
> >>>
> >>>
> >can't
> >
> >
> >>>get the names...
> >>>     }
> >>>
> >>>   ## resids = eval( lhs ) - eval( rhs )
> >>>   for( i in length( eqns ) )
> >>>     {
> >>>       lhs[[i]] <- eval( formula( eqns[[i]] )[2] )
> >>>       rhs[[i]] <- eval( formula( eqns[[i]] )[3] )
> >>>       residi[[i]] <- lhs[[i]] - rhs[[i]]
> >>>       r <- rbind( r, as.matrix( residi[[i]] ) )
> >>>     }
> >>>
> >>>   ## blah, blah, blah....
> >>>
> >>>   knls <- obj
> >>>}
> >>>
> >>>
> >>>print( "calling nlstest" )
> >>>demand2 <- q ~ d0 + d1 * p + d2 * d
> >>>supply2 <- q ~ s0 + s1 * p + s2 * f + s3 * a
> >>>system2 <- list( demand2, supply2 )
> >>>sv2 <- c(d0=3,d2=4,d1=4.234,s0=-2.123,s2=2.123,s3=4.234,s1=0.234)
> >>>
> >>>### call the nlm function to get the estimates...
> >>>estnew <- nlm( knls, sv2, hessian=TRUE, print.level=1, eqns=system2,
> >>>data=kmenta, fitmethod="OLS" )
> >>>
> >>>
> >>>My question is why can't I simply call names on the vector (sv2) that
>  
>
is

> >>>passed into the nlm function to get the parameters?
> >>>
> >>>Thanks,
> >>>Jeff.
> >>>
> >>>
> >>>
> >>>---
> >>>Jeff D. Hamann
> >>>Hamann, Donald and Associates, Inc.
> >>>PO Box 1421
> >>>Corvallis, Oregon USA 97339-1421
> >>>(office) 541-754-1428
> >>>(cell) 541-740-5988
> >>>jeff_hamann at hamanndonald.com
> >>>www.hamanndonald.com
> >>>
> >>>______________________________________________
> >>>R-help at stat.math.ethz.ch mailing list
> >>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>  
>



From jmacdon at med.umich.edu  Tue Sep 30 21:00:22 2003
From: jmacdon at med.umich.edu (James MacDonald)
Date: Tue, 30 Sep 2003 15:00:22 -0400
Subject: [R] generic function object
Message-ID: <sf799a90.042@med-gwia-01a.med.umich.edu>

getMethods("normalize") should do the trick.

Best,

Jim



James W. MacDonald
Affymetrix and cDNA Microarray Core
University of Michigan Cancer Center
1500 E. Medical Center Drive
7410 CCGC
Ann Arbor MI 48109
734-647-5623

>>> Mathieu Drapeau <mathieu.drapeau at bioneq.qc.ca> 09/30/03 02:14PM
>>>
Hi,
I would like to know if there is a way to see the code of a generic 
function?
Like when I only type the function name, it prints the source of that 
function. But I cannot see the code of a generic function, it prints:
...
function (object, ...)
standardGeneric("normalize")
<environment: 0x8e9e368>
Methods may be defined for arguments: object
...

Thanks,
Mathieu

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help



From Ted.Harding at nessie.mcc.ac.uk  Tue Sep 30 20:48:09 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue, 30 Sep 2003 19:48:09 +0100 (BST)
Subject: [R] subsetting a matrix
In-Reply-To: <1064942077.4121.6.camel@ra.chem.psu.edu>
Message-ID: <XFMail.030930194809.Ted.Harding@nessie.mcc.ac.uk>

On 30-Sep-03 Rajarshi Guha wrote:
> Hi,
>   I'm trying to take a set of rows and columns out of a matrix. I hve
> been using the index aray approach. My overll matrix is X and is 179 x
> 65. I want to take out 4 columns and 161 rows.
> 
> Thus I made a 161 x 2 array I and filled it up with the row,col
> indices.
> However doing,
> 
> X[ I ] gives me a vector of the extracted elements. Is there anyway I
> can coerce this into a 161 x 4 matrix?

  X[c(list_of_rows),c(list_of_cols)]

should do it. E.g.

  X[c(2,5,7,9),c(3,5,6)]

Alternatively you can make index vectors iR (for rows), iC (for cols)
which have values TRUE for what you want to select and FALSE for the
rest; then

  X[iR,iC]

will also do it. There are other approaches -- you should choose
whichever most closely fits in with your criteria for row and column
selection. E.g.

  X[iR,c(3,5,6)]

would also do! What it all boils down to is an expression of the form

  X[rowselector, colselector]

Hope this helps,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 30-Sep-03                                       Time: 19:48:09
------------------------------ XFMail ------------------------------



From edd at debian.org  Tue Sep 30 21:28:10 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 30 Sep 2003 14:28:10 -0500
Subject: [R] cluster & mgcv update
In-Reply-To: <200309301404.23558.mailinglist.wegmann@web.de>
References: <200309301241.07603.mailinglist.wegmann@web.de>
	<20030930112610.GA13944@sonny.eddelbuettel.com>
	<200309301404.23558.mailinglist.wegmann@web.de>
Message-ID: <20030930192809.GA18323@sonny.eddelbuettel.com>

On Tue, Sep 30, 2003 at 02:04:23PM +0200, Martin Wegmann wrote:
> 
> > You need to add atlas2-base-dev:
> >
> > $ apt-get install atlas2-base-dev
> 
> I installed atlas2-base-dev and g77 but know I get the error messages pasted 
> below. Both (cluster and mgcv) requires lfrtbegin, but that does not seem to 
> be programm which I can install via apt-get. 

FWIW this appears to have been in inconsistency between the newest Knoppix
version and Debian testing/unstable which Martin was able to solve by
grabbing the current gcc, g77 and g++ from Debian unstable. 

Dirk

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From lwalters at cs.uct.ac.za  Tue Sep 30 21:39:40 2003
From: lwalters at cs.uct.ac.za (Lourens Olivier Walters)
Date: Tue, 30 Sep 2003 21:39:40 +0200
Subject: [R] fitdistr, mle's and gamma distribution
Message-ID: <1064950780.547.59.camel@stochastic>

Dear R Users, 

I am trying to obtain a best-fit analytic distribution for a dataset
with 11535459 entries. The data range in value from 1 to 300000000. I
use: fitdistr(data, "gamma") to obtain mle's for the parameters.
 
I get the following error:

Error in optim(start, mylogfn, x = x, hessian = TRUE, ...) :
        non-finite finite-difference value [1]

And the following warnings:

NaNs produced in: dgamma(x, shape, scale, log)

I have the same problem with the exponential distribution, but the
lognormal and weibull distributions don't have this problem. 

I suspect the problem has to do with:

"It means that in computing derivatives by finite differencing, one 
of the values is NA, +Inf or -Inf. Put some print values in 
your objective function and find out why it is giving a non-finite
value." - quote by Prof Ripley from r-help

as from the warnings it is clear that some of the values obtained during
maximum likelihood computations are NaN. I cannot however print values
of the objective function, as in my case it is dgamma which is called by
fitdistr, over which I don't have control.  

Can anyone please point me in the right direction?

Lourens

-- 
Lourens Olivier Walters <lwalters at cs.uct.ac.za>
Computer Science Masters Student
University of Cape Town
South Africa
http://people.cs.uct.ac.za/~lwalters/



From jasont at indigoindustrial.co.nz  Tue Sep 30 21:51:01 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Wed, 01 Oct 2003 07:51:01 +1200
Subject: [R] subsetting a matrix
In-Reply-To: <XFMail.030930194809.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.030930194809.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <3F79DEA5.9000608@indigoindustrial.co.nz>

(Ted Harding) wrote:

> On 30-Sep-03 Rajarshi Guha wrote:
> 
>>Hi,
>>  I'm trying to take a set of rows and columns out of a matrix. I hve
>>been using the index aray approach. My overll matrix is X and is 179 x
>>65. I want to take out 4 columns and 161 rows.
...
This is documented in "An Introduction to R", under the section "Arrays 
and Matricies".  There's lots of good stuff in there.  From R:

help.start()

And click on "An Introduction to R".

The short answer to this particular question:
a) negative indicies remove rows or columns.  Since you only want to 
remove 4 columns, I'd use that.
b) Since you only want to keep 18 rows, I'd use the numbers of the rows 
you want to keep.

As a toy example, say you wanted to remove columns 51 to 54, and keep 
the last 18 rows:

newX <- X[162:179,-(51:54)]

There's even more handy stuff in the document mentioned above.

cheers

Jason
-- 
Indigo Industrial Controls Ltd.
http://www.indigoindustrial.co.nz
64-21-343-545
jasont at indigoindustrial.co.nz



From Phguardiol at aol.com  Tue Sep 30 21:56:03 2003
From: Phguardiol at aol.com (Phguardiol@aol.com)
Date: Tue, 30 Sep 2003 15:56:03 EDT
Subject: [R] Problem with R1.8beta
Message-ID: <1ee.1095b94e.2cab39d3@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030930/d8f2afd8/attachment.pl

From rxg218 at psu.edu  Tue Sep 30 21:58:43 2003
From: rxg218 at psu.edu (Rajarshi Guha)
Date: Tue, 30 Sep 2003 19:58:43 -0000
Subject: [R] subsetting a matrix
In-Reply-To: <3F79DEA5.9000608@indigoindustrial.co.nz>
References: <XFMail.030930194809.Ted.Harding@nessie.mcc.ac.uk>
	<3F79DEA5.9000608@indigoindustrial.co.nz>
Message-ID: <1064952185.2439.0.camel@ra.chem.psu.edu>

On Tue, 2003-09-30 at 15:51, Jason Turner wrote:
> (Ted Harding) wrote:
> 
> > On 30-Sep-03 Rajarshi Guha wrote:
> > 
> >>Hi,
> >>  I'm trying to take a set of rows and columns out of a matrix. I hve
> >>been using the index aray approach. My overll matrix is X and is 179 x
> >>65. I want to take out 4 columns and 161 rows.
> ...
> This is documented in "An Introduction to R", under the section "Arrays 
> and Matricies".  There's lots of good stuff in there.  From R:
> 
> help.start()
> 
> And click on "An Introduction to R".
> 
> The short answer to this particular question:
> a) negative indicies remove rows or columns.  Since you only want to 
> remove 4 columns, I'd use that.
> b) Since you only want to keep 18 rows, I'd use the numbers of the rows 
> you want to keep.


Thanks for all the answers. I had been writing loops and extracting
elements - I've been spending too much time in C :-/

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
Build a system that even a fool can use and only a fool will want to use
it.



From Phguardiol at aol.com  Tue Sep 30 22:00:55 2003
From: Phguardiol at aol.com (Phguardiol@aol.com)
Date: Tue, 30 Sep 2003 16:00:55 EDT
Subject: [R] in addition R1.8b install
Message-ID: <14.19a34d30.2cab3af7@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030930/23c0d6f1/attachment.pl

From spencer.graves at pdf.com  Tue Sep 30 22:07:11 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 30 Sep 2003 13:07:11 -0700
Subject: [R] fitdistr, mle's and gamma distribution
In-Reply-To: <1064950780.547.59.camel@stochastic>
References: <1064950780.547.59.camel@stochastic>
Message-ID: <3F79E26F.7000104@pdf.com>

      In my experience, the most likely cause of this problem is that 
optim may try to test nonpositive values for shape or scale.  I avoid 
this situation by programming the log(likelihood) in terms of log(shape) 
and log(scale) as follows: 

 > gammaLoglik <-
+ function(x, logShape, logScale, negative=TRUE){
+ lglk <- sum(dgamma(x, shape=exp(logShape), scale=exp(logScale),
+ log=TRUE))
+ if(negative) return(-lglk) else return(lglk)
+ }
 > tst <- rgamma(10, 1)
 > gammaLoglik(tst, 0, 0)
[1] 12.29849

Then I then call optim directly to minimize the negative of the 
log(likelihood). 

      If I've guessed correctly, this should fix the problem.  If not, 
let us know. 

      hope this helps.  spencer graves

Lourens Olivier Walters wrote:

>Dear R Users, 
>
>I am trying to obtain a best-fit analytic distribution for a dataset
>with 11535459 entries. The data range in value from 1 to 300000000. I
>use: fitdistr(data, "gamma") to obtain mle's for the parameters.
> 
>I get the following error:
>
>Error in optim(start, mylogfn, x = x, hessian = TRUE, ...) :
>        non-finite finite-difference value [1]
>
>And the following warnings:
>
>NaNs produced in: dgamma(x, shape, scale, log)
>
>I have the same problem with the exponential distribution, but the
>lognormal and weibull distributions don't have this problem. 
>
>I suspect the problem has to do with:
>
>"It means that in computing derivatives by finite differencing, one 
>of the values is NA, +Inf or -Inf. Put some print values in 
>your objective function and find out why it is giving a non-finite
>value." - quote by Prof Ripley from r-help
>
>as from the warnings it is clear that some of the values obtained during
>maximum likelihood computations are NaN. I cannot however print values
>of the objective function, as in my case it is dgamma which is called by
>fitdistr, over which I don't have control.  
>
>Can anyone please point me in the right direction?
>
>Lourens
>
>  
>



From MSchwartz at medanalytics.com  Tue Sep 30 22:35:23 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 30 Sep 2003 15:35:23 -0500
Subject: [R] in addition R1.8b install
In-Reply-To: <14.19a34d30.2cab3af7@aol.com>
References: <14.19a34d30.2cab3af7@aol.com>
Message-ID: <1064954123.12303.422.camel@localhost>

On Tue, 2003-09-30 at 15:00, Phguardiol at aol.com wrote:
> this problem also occurred later in the installation process:
> C:\Program Files\R\rw1080beta\doc\manual\refman.pdf
> C:\Program Files\R\rw1080beta\library\mva\html\loadings.html
> C:\Program Files\R\rw1080beta\library\ctest\html\fisher.test.html
> C:\Program Files\R\rw1080beta\library\base\chtml\base.chm
> C:\Program Files\R\rw1080beta\afm\hvo____.afm
> An error occured while trying to copy a file:
> The source file is corrupted.
> 
> however by the end R opened correctly....
> any suggestions ?
> thanks
> Philippe


The first thing to try would be to re-download the ZIP file to rule
in/out the possibility that the download was corrupted.

HTH,

Marc Schwartz



From MSchwartz at medanalytics.com  Tue Sep 30 22:46:45 2003
From: MSchwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 30 Sep 2003 15:46:45 -0500
Subject: [R] in addition R1.8b install
In-Reply-To: <1064954123.12303.422.camel@localhost>
References: <14.19a34d30.2cab3af7@aol.com>
	<1064954123.12303.422.camel@localhost>
Message-ID: <1064954805.12303.434.camel@localhost>

On Tue, 2003-09-30 at 15:35, Marc Schwartz wrote:
> On Tue, 2003-09-30 at 15:00, Phguardiol at aol.com wrote:
> > this problem also occurred later in the installation process:
> > C:\Program Files\R\rw1080beta\doc\manual\refman.pdf
> > C:\Program Files\R\rw1080beta\library\mva\html\loadings.html
> > C:\Program Files\R\rw1080beta\library\ctest\html\fisher.test.html
> > C:\Program Files\R\rw1080beta\library\base\chtml\base.chm
> > C:\Program Files\R\rw1080beta\afm\hvo____.afm
> > An error occured while trying to copy a file:
> > The source file is corrupted.
> > 
> > however by the end R opened correctly....
> > any suggestions ?
> > thanks
> > Philippe
> 
> 
> The first thing to try would be to re-download the ZIP file to rule
> in/out the possibility that the download was corrupted.
> 
> HTH,
> 
> Marc Schwartz


Correction, that should read EXE file...

Sorry.

Marc



From bolker at zoo.ufl.edu  Tue Sep 30 23:18:53 2003
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Tue, 30 Sep 2003 17:18:53 -0400 (EDT)
Subject: [R] fitdistr, mle's and gamma distribution
In-Reply-To: <1064950780.547.59.camel@stochastic>
Message-ID: <Pine.LNX.4.44.0309301712410.25265-100000@bolker.zoo.ufl.edu>


  Spencer Graves's suggestion of using shape and scale parameters on a log 
scale is a good one.

  To do specifically what you want (check values for which the objective 
function is called and see what happens) you can do the following 
(untested!), which makes a local copy of dgamma that you can mess with:

dgamma.old <- dgamma
dgamma <- function(x,shape,rate,...) {
   d <- dgamma.old(x,shape,rate,...)
   cat(shape,rate,d,"\n")
   return(d)
}


On Tue, 30 Sep 2003, Lourens Olivier Walters wrote:

> Dear R Users, 
> 
> I am trying to obtain a best-fit analytic distribution for a dataset
> with 11535459 entries. The data range in value from 1 to 300000000. I
> use: fitdistr(data, "gamma") to obtain mle's for the parameters.
>  
> I get the following error:
> 
> Error in optim(start, mylogfn, x = x, hessian = TRUE, ...) :
>         non-finite finite-difference value [1]
> 
> And the following warnings:
> 
> NaNs produced in: dgamma(x, shape, scale, log)
> 
> I have the same problem with the exponential distribution, but the
> lognormal and weibull distributions don't have this problem. 
> 
> I suspect the problem has to do with:
> 
> "It means that in computing derivatives by finite differencing, one 
> of the values is NA, +Inf or -Inf. Put some print values in 
> your objective function and find out why it is giving a non-finite
> value." - quote by Prof Ripley from r-help
> 
> as from the warnings it is clear that some of the values obtained during
> maximum likelihood computations are NaN. I cannot however print values
> of the objective function, as in my case it is dgamma which is called by
> fitdistr, over which I don't have control.  
> 
> Can anyone please point me in the right direction?
> 
> Lourens
> 
> 

-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From jgcesped at carpa.ciagri.usp.br  Tue Sep 30 23:04:12 2003
From: jgcesped at carpa.ciagri.usp.br (Juliana Garcia Cespedes)
Date: Tue, 30 Sep 2003 18:04:12 -0300
Subject: [R] truncated multivariate normal 
Message-ID: <200309302111.h8ULBGrI005859@stat.math.ethz.ch>

Please,    

I would like to know how to generate a truncated multivariate normal
distribution k - dimensional,    X ~ NT(mu, Sigma),  where the
elements of X to be non-negative (except the first), and the first
dimension is strictly larger than zero.    

Example:  

X ~ NT_2(mu, Sigma),   

where mu=c(0.5, 0.5) and Sigma=c([120, 191], [191,154]), with X_1>0
and X_2>=0  
Could anybody help me?     
  
Thanks in advanced.

Juliana G. Cespedes
Mestranda em Estat?stica e Experimenta??o Agron?mica
Departamento de Ci?ncias Exatas - ESALQ/USP
S?o Paulo - Brasil



From bolker at zoo.ufl.edu  Tue Sep 30 23:25:49 2003
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Tue, 30 Sep 2003 17:25:49 -0400 (EDT)
Subject: [R] fitdistr, mle's and gamma distribution
In-Reply-To: <Pine.LNX.4.44.0309301712410.25265-100000@bolker.zoo.ufl.edu>
Message-ID: <Pine.LNX.4.44.0309301725130.25293-100000@bolker.zoo.ufl.edu>


  PS.  11 MILLION entries??

On Tue, 30 Sep 2003, Ben Bolker wrote:

> 
>   Spencer Graves's suggestion of using shape and scale parameters on a log 
> scale is a good one.
> 
>   To do specifically what you want (check values for which the objective 
> function is called and see what happens) you can do the following 
> (untested!), which makes a local copy of dgamma that you can mess with:
> 
> dgamma.old <- dgamma
> dgamma <- function(x,shape,rate,...) {
>    d <- dgamma.old(x,shape,rate,...)
>    cat(shape,rate,d,"\n")
>    return(d)
> }
> 
> 
> On Tue, 30 Sep 2003, Lourens Olivier Walters wrote:
> 
> > Dear R Users, 
> > 
> > I am trying to obtain a best-fit analytic distribution for a dataset
> > with 11535459 entries. The data range in value from 1 to 300000000. I
> > use: fitdistr(data, "gamma") to obtain mle's for the parameters.
> >  
> > I get the following error:
> > 
> > Error in optim(start, mylogfn, x = x, hessian = TRUE, ...) :
> >         non-finite finite-difference value [1]
> > 
> > And the following warnings:
> > 
> > NaNs produced in: dgamma(x, shape, scale, log)
> > 
> > I have the same problem with the exponential distribution, but the
> > lognormal and weibull distributions don't have this problem. 
> > 
> > I suspect the problem has to do with:
> > 
> > "It means that in computing derivatives by finite differencing, one 
> > of the values is NA, +Inf or -Inf. Put some print values in 
> > your objective function and find out why it is giving a non-finite
> > value." - quote by Prof Ripley from r-help
> > 
> > as from the warnings it is clear that some of the values obtained during
> > maximum likelihood computations are NaN. I cannot however print values
> > of the objective function, as in my case it is dgamma which is called by
> > fitdistr, over which I don't have control.  
> > 
> > Can anyone please point me in the right direction?
> > 
> > Lourens
> > 
> > 
> 
> 

-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From ross at biostat.ucsf.edu  Tue Sep 30 23:15:27 2003
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Tue, 30 Sep 2003 14:15:27 -0700
Subject: [R] Re: Help needed: plotting with no device
In-Reply-To: <20030929204446.GC2341@wheat.boylan.org>
References: <20030929204446.GC2341@wheat.boylan.org>
Message-ID: <1064956527.1085.132.camel@iron.libaux.ucsf.edu>

Thanks to everyone for your help.  I decided to see if the session could
be recovered if I connected back from the original, local terminal.

The local screen was locked by the KDE screensaver.  Either my unlocking
it, or the passage of time, seems to have got the process unstuck.  It
happened before I reattached to the screen session from a local
terminal.

Whew!



From bolker at zoo.ufl.edu  Tue Sep 30 23:29:43 2003
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Tue, 30 Sep 2003 17:29:43 -0400 (EDT)
Subject: [R] truncated multivariate normal 
In-Reply-To: <200309302111.h8ULBGrI005859@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.44.0309301726360.25293-100000@bolker.zoo.ufl.edu>


  Do you mean you want to generate deviates from this distribution or that 
you want the density function (or distribution function)?

mvrnorm in package MASS (library(MASS)) will generate multivariate normal
deviates.  A brute-force approach would just keep picking values until you
get ones in the right quadrant, although with your example (large
variance, small mean) that would mean you would be wasting 3/4 of your 
values -- so there are probably more efficient approaches.  Depends how 
much time you want to spend programming, how many values you want to draw, 
and how fast your computer is ...

   Ben

On Tue, 30 Sep 2003, Juliana Garcia Cespedes wrote:

> Please,    
> 
> I would like to know how to generate a truncated multivariate normal
> distribution k - dimensional,    X ~ NT(mu, Sigma),  where the
> elements of X to be non-negative (except the first), and the first
> dimension is strictly larger than zero.    
> 
> Example:  
> 
> X ~ NT_2(mu, Sigma),   
> 
> where mu=c(0.5, 0.5) and Sigma=c([120, 191], [191,154]), with X_1>0
> and X_2>=0  
> Could anybody help me?     
>   
> Thanks in advanced.
> 
> Juliana G. Cespedes
> Mestranda em Estat?stica e Experimenta??o Agron?mica
> Departamento de Ci?ncias Exatas - ESALQ/USP
> S?o Paulo - Brasil
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From ross at biostat.ucsf.edu  Tue Sep 30 23:19:16 2003
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Tue, 30 Sep 2003 14:19:16 -0700
Subject: [R] Help needed: plotting with no device
In-Reply-To: <Pine.LNX.4.44.0309291624250.32258-100000@itasca2.stat.uiowa.edu>
References: <Pine.LNX.4.44.0309291624250.32258-100000@itasca2.stat.uiowa.edu>
Message-ID: <1064956756.1085.136.camel@iron.libaux.ucsf.edu>

On Mon, 2003-09-29 at 14:25, Luke Tierney wrote:
> Look at ?Signal and see if that would help.  You may need to rename
> the appropriate .RData beforehand to be safer.
> 
> luke
For those who follow, note it's actually
?Signals
you want. It talks about USR1 and USR2 (as did some other people in this
thread).



From forkusam at yahoo.com  Tue Sep 30 23:38:54 2003
From: forkusam at yahoo.com (forkusam)
Date: Tue, 30 Sep 2003 14:38:54 -0700 (PDT)
Subject: [R] variables
Message-ID: <20030930213854.7462.qmail@web10505.mail.yahoo.com>

Hi,
can someone please help me.
I will give a simple example of my problem. 
p <- function()
{
 i <- 1
 sr <- function(){
 i<-i+3
 i<- sqrt(i)
}
cat(i) 
}
 This is just an example. My main problem is defining
i like a global variable which I can use in the sub-
and main functions without any complicated switches. 
Thanks in advance.
cilver


=====
=====================
Sylvie B. Forkusam
Eppelheimer Str.52/A2-5-2
69115 Heidelberg, Germany
Tel: (0049)-06221/346913
Mobile: 0179-6816276



From sigma at consultoresestadisticos.com  Mon Sep 29 19:59:50 2003
From: sigma at consultoresestadisticos.com (Carlos J. Gil Bellosta)
Date: Mon, 29 Sep 2003 19:59:50 +0200
Subject: [R] R icon for RedHat 9.
Message-ID: <3F787316.2090205@consultoresestadisticos.com>

Dear R-helpers,

I just installed R on a RedHat 9 machine and when I was trying add a 
launcher on the panel to it, I could not find any R icon in png format. 
Is there any available? Do I have it and I could not find it in my file 
hierarchy?

Thank you for your help.

Carlos J. Gil Bellosta
Sigma Consultores Estad?sticos
http://www.consultoresestadisticos.com



From sigma at consultoresestadisticos.com  Sun Sep 28 19:06:43 2003
From: sigma at consultoresestadisticos.com (Carlos J. Gil Bellosta)
Date: Sun, 28 Sep 2003 19:06:43 +0200
Subject: [R] R-icon for RH Linux 9.
Message-ID: <3F771523.8050203@consultoresestadisticos.com>

Dear R helpers,

It is the first time I have to install R under Linux (Red Hat 9) and as 
I was setting up the panels, I could not find any png icon to launch the 
program. Does it exist and I have overlooked it? Can I get it somewhere?

Carlos J. Gil Bellosta
Sigma Consultores Estad?sticos
http://www.consultoresestadisticos.com



