From Inman.Brant at mayo.edu  Fri Jun  1 00:04:24 2007
From: Inman.Brant at mayo.edu (Inman, Brant A.   M.D.)
Date: Thu, 31 May 2007 17:04:24 -0500
Subject: [R] Using MIcombine for coxph fits
Message-ID: <6021CA6EF4C8374084D4F5A141F1CBBBC14CC3@msgebe23.mfad.mfroot.org>


R-helpers:

I am using R 2.5 on Windows XP, packages all up to date.  I have run
into an issue with the MIcombine function of the mitools package that I
hoped some of you might be able to help with.  I will work through a
reproducible example to demonstrate the issue.

First, make a dataset from the pbc dataset in the survival package

---------------
# Make a dataset
library(survival)
d <- pbc[,c('time','status','age','sex','hepmeg','platelet', 
	'trt', 'trig')]
d[d==-9] <- NA 
d[,c(4,5,7)] <- lapply(d[,c(4,5,7)], FUN=as.factor)
str(d)
summary(d)
---------------

Second, since there is missing data for several (but not all) of the
variables, investigate the patterns.

---------------
library(Hmisc)
na.pattern(d)					
clus <- naclus(d, method='complete')
par(mfrow=c(2,2))
naplot(clus, which='all')
print(clus)
detach(package: Hmisc)
---------------

After examining the missing data patterns, impute 10 datasets using the
amelia function from the Amelia package. Check the densities of the
continuous variables to make sure they make sense. 

---------------
library(Amelia)
am.imp <- amelia(d, m=10, p2s=1, startvals=1, write.out=F,
	noms=c('status','sex','hepmeg','trt'))
compare.density(data=d, output=am.imp, var='trig')
compare.density(data=d, output=am.imp, var='platelet')
---------------

Since everything looks ok, fit Cox models to each of the 10 imputed
datasets using the functions of the mitools package.

---------------
library(mitools)
miset  <- imputationList(list(am.imp[[1]],am.imp[[2]],am.imp[[3]],
	am.imp[[4]],am.imp[[5]],am.imp[[6]],am.imp[[7]],am.imp[[8]],
	am.imp[[9]],am.imp[[10]]))
mifit  <- with(miset, coxph(Surv(time, status) ~ age + sex + 
	hepmeg + platelet + trt + trig))
mifit
---------------

The "mifit" object shows the individual coxph fits for each imputed
dataset.  Now we have to pool these fitted models  to obtain an overall
model. The code and result are shown below.

---------------
fit.am <- MIcombine(mifit)
summary(fit.am) 

Multiple imputation results:
      with.imputationList(miset, coxph(Surv(time, status) ~ age + sex + 
    hepmeg + platelet + trt + trig))
      MIcombine.default(mifit)
              results           se       (lower       upper) missInfo
age       0.035548792 0.0082506946  0.019373545 0.0517240397      4 %
sex1     -0.070760613 0.2563372831 -0.580309741 0.4387885156     34 %
hepmeg1   0.932378808 0.2026274576  0.532555416 1.3322021993     23 %
platelet -0.001757899 0.0009480636 -0.003620446 0.0001046469     14 %
trt2      0.137413162 0.1924230007 -0.243815288 0.5186416117     29 %
trig      0.003979287 0.0012010053  0.001607266 0.0063513078     25 %
---------------

The question I have concerns the meaning of this result.  The missInfo
column of the summary function suggests that age was missing data, when
in fact it was not. Is there a different interpretation for the missInfo
column?

Thanks in advance for any help.

Brant Inman


From renaud.lancelot at gmail.com  Fri Jun  1 00:15:46 2007
From: renaud.lancelot at gmail.com (Renaud Lancelot)
Date: Fri, 1 Jun 2007 00:15:46 +0200
Subject: [R] [R-sig-Geo]  Follow up: surfaces and digital terrain model
In-Reply-To: <Pine.LNX.4.64.0705312229090.8722@gannet.stats.ox.ac.uk>
References: <BAY102-DAV170E36744719728702285BBC2E0@phx.gbl>
	<465DCC44.2070502@alumni.uwaterloo.ca>
	<Pine.LNX.4.44.0705302252410.22911-100000@reclus.nhh.no>
	<000001c7a3c5$db20c070$0601a8c0@D3K86YB1>
	<Pine.LNX.4.64.0705312229090.8722@gannet.stats.ox.ac.uk>
Message-ID: <c2ee56800705311515i1c10253fu1c580636a69541c9@mail.gmail.com>

2007/5/31, Prof Brian Ripley <ripley at stats.ox.ac.uk>:
> I believe you are looking for the function contourLines() in package
> graphics.
>
> At some point in the intervening years there was a clines package on CRAN,
> and if you know that you can find it at
> http://cran.r-project.org/src/contrib/Archive/C/clines_2.0-2.tar.gz
> That confirms it has been superseded by contourLines.
>
> BTW, it is Paul Murrell (two l's) we have to thank for this.

Yes, indeed :-)

Renaud


>
>
> On Thu, 31 May 2007, Andrew Niccolai wrote:
>
> > I realize that as of yesterday, this message thread is 4 years old but can
> > someone possibly post the clines function that Renaud mentions in the
> > posting below?  That would be wonderful and most appreciated.
> >
> > Thanks,
> > Andrew
> >
> >
> > Andrew Niccolai
> > Doctoral Candidate
> > Yale School of Forestry
> >
> >
> >
> > From: Renaud Lancelot <lancelot>
> > Date: Fri May 30 22:37:02 2003
> >
> > Yesterday, I posted the following:
> >
> >>> I have computed a digital terrain model from a set of points (x, y, z)
> >>> using the function interp() in package akima. I want to predict flooded
> >>> surfaces given target values of z. I can display the flooded surfaces
> >>> with contour() or image(), but I don't know how to get the polygons
> >>> delimiting the surfaces. Did anyone write a function for this purpose ?
> >
> > Many thanks to Roger Bivand, Paul Murrel, Deepayan Sarkar, Barry
> > Rowlingson and Thomas W Blackwell for their replies and their help. Paul
> > Murrel provided me with a function "clines", kindly ported to Windows by
> > Duncan Murdoch. This function does exactly what I need, i.e. it returns
> > a list of polygons corresponding to target value(s) of z.
> >
> > I wrote a function to compute (hopefully !) what I want, i.e. predicted
> > flooded surfaces given target values of z (managing the cases of several
> > independent watered surfaces, possibly with islands). Provided that Paul
> > Murrel agrees to share his function, I will be happy to send it to
> > anyone wishing to use and improve it (and debug it ;-) ).
> >
> > Best regards and thanks again,
> >
> > Renaud
> >
> >
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


-- 
Renaud LANCELOT
D?partement Syst?mes Biologiques du CIRAD
CIRAD, Biological Systems Department

Campus International de Baillarguet
TA 30 / B
F34398 Montpellier
Tel   +33 (0)4 67 59 37 17
Secr. +33 (0)4 67 59 37 37
Fax   +33 (0)4 67 59 37 95


From ripley at stats.ox.ac.uk  Fri Jun  1 00:28:20 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 31 May 2007 23:28:20 +0100 (BST)
Subject: [R] predict.nls - gives error but only on some nls objects
In-Reply-To: <C83C5E3DEEE97E498B74729A33F6EAEC0387877E@DJFPOST01.djf.agrsci.dk>
References: <C83C5E3DEEE97E498B74729A33F6EAEC05429402@DJFPOST01.djf.agrsci.dk>
	<Pine.LNX.4.64.0705311327180.19868@gannet.stats.ox.ac.uk>
	<C83C5E3DEEE97E498B74729A33F6EAEC0387877E@DJFPOST01.djf.agrsci.dk>
Message-ID: <Pine.LNX.4.64.0705312258130.9567@gannet.stats.ox.ac.uk>

On Thu, 31 May 2007, S?ren H?jsgaard wrote:

> Dear Prof Ripley and the list
>
> Apologies for an unfortunate typing error. What I meant was:
>
>> predict(fm2DNase1)
>
> [1] 0.001424337 0.001424337 0.028883648 0.028883648 0.119576734 0.119576734 0.382791057 ...
>
>> nd <- as.data.frame(DNase1)

DNase1 is already a data frame.

>> class(nd)
> [1] "data.frame"
>
>> predict(fm2DNase1,newdata=nd)
>
> Error in if (sum(wrong) == 1) stop(gettextf("variable '%s' was fitted with class \"%s\" but class \"%s\" was supplied",  :
>        missing value where TRUE/FALSE needed
>
> I know I don't have to supply newdata to just get the fitted values, but I want to enter another dataframe later...

It's picky: you need to supply just the named variables needed to fit the 
model, here

predict(fm2DNase1, newdata=DNase1[2:3])

(That's not obvious from the documentation, of course.)

I've made it less picky in R-patched, but nls is not written in the same 
way as 'standard' R modelling functions like lm, which would use 
model.frame to extract the variables from 'newdata'.  Doing so is not 
entirely straightforward as there is no record of what variables are 
needed for the RHS alone.  The less picky form is also less safe: it is 
too easy to get the wrong variables since the variables used for fitting 
are visible in the environment used for prediction.

This needs something of a rethink in the light of the experience of years 
of other prediction methods, but until then use with care.


>
> Regards
> S?ren
>
>
> ________________________________
>
> Fra: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> Sendt: to 31-05-2007 14:28
> Til: S?ren H?jsgaard
> Cc: r-help at stat.math.ethz.ch
> Emne: Re: [R] predict.nls - gives error but only on some nls objects
>
>
>
> Why do you think feeding a model fit (fm2DNase1) is suitable 'newdata'?.
>> From the help page
>
>  newdata: A named list or data frame in which to look for variables
>           with which to predict.  If 'newdata' is missing the fitted
>           values at the original data points are returned.
>
> It is the unsuitable 'newdata' that is causing the error.
>
>
> On Thu, 31 May 2007, S?ren H?jsgaard wrote:
>
>> Dear list,
>> I have encountered a problem with predict.nls (Windows XP, R.2.5.0), but I am not sure if it is a bug...
>>
>> On the nls man page, an example is:
>>
>> DNase1 <- subset(DNase, Run == 1)
>> fm2DNase1 <- nls(density ~ 1/(1 + exp((xmid - log(conc))/scal)),
>>                 data = DNase1,
>>                 start = list(xmid = 0, scal = 1))
>>                 alg = "plinear", trace = TRUE)
>>
>> Now consider prediction:
>>
>>> predict(fm2DNase1)
>> [1] 0.001424337 0.001424337 0.028883648 0.028883648 .....
>>
>>> predict(fm2DNase1,newdata=fm2DNase1)
>> Error in if (sum(wrong) == 1) stop(gettextf("variable '%s' was fitted with class \"%s\" but class \"%s\" was supplied",  :
>>        missing value where TRUE/FALSE needed
>>
>> What causes the trouble is the call to .checkMFClasses(cl, newdata) in predict.nls.
>>
>>
>> Incidently, on the predict.nls page the example works:
>>
>>> fm <- nls(demand ~ SSasympOrig(Time, A, lrc), data = BOD)
>>> predict(fm)
>> [1]  7.887449 12.524977 15.251673 16.854870 17.797490 18.677580
>>> predict(fm,newdata=BOD)
>> [1]  7.887449 12.524977 15.251673 16.854870 17.797490 18.677580
>> attr(,"gradient")
>>             A      lrc
>> [1,] 0.4120369 5.977499
>> [2,] 0.6542994 7.029098
>> ....
>>
>> Is there a bug, or am I overlooking something??
>>
>> Regards
>> S?ren
>>
>>
>>       [[alternative HTML version deleted]]
>>
>>
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From sapsi at pobox.com  Fri Jun  1 00:38:08 2007
From: sapsi at pobox.com (Saptarshi Guha)
Date: Thu, 31 May 2007 18:38:08 -0400
Subject: [R] A question regarding package development
Message-ID: <7FD2A5C0-167A-49DF-8722-0749C849A26E@pobox.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070531/ea75dd87/attachment.pl 

From waverley.paloalto at gmail.com  Fri Jun  1 00:57:01 2007
From: waverley.paloalto at gmail.com (Waverley)
Date: Thu, 31 May 2007 15:57:01 -0700
Subject: [R] RMySQL DBI question
Message-ID: <8ee9d8f20705311557r4be9877cr72eb6a0faeea2787@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070531/0b5d92f3/attachment.pl 

From labone at gforcecable.com  Fri Jun  1 01:03:35 2007
From: labone at gforcecable.com (Tom La Bone)
Date: Thu, 31 May 2007 19:03:35 -0400
Subject: [R] Problem with Weighted Variance in Hmisc
Message-ID: <000701c7a3d7$eac58da0$6401a8c0@Boozoo>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070531/ebd887fb/attachment.pl 

From cberry at tajo.ucsd.edu  Fri Jun  1 01:56:36 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Thu, 31 May 2007 16:56:36 -0700
Subject: [R] R keeps crashing when executing 'rlogspline'
In-Reply-To: <787911d50705311413jaa6ef19ncffd7e20b6a0623f@mail.gmail.com>
References: <787911d50705311413jaa6ef19ncffd7e20b6a0623f@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0705311634010.9126@tajo.ucsd.edu>

On Thu, 31 May 2007, Jacques Wagnor wrote:

> Dear List,
>
> I have a simple model as follows:
>
> x <- rnorm(500)
> library(logspline)
> fit <- logspline(x)
> n <- 1000000
> y <- replicate(n, sum(rlogspline(rpois(1,10), fit))) # last line
>

What you do not see in RGui is this:


  *** caught segfault ***
address (nil), cause 'memory not mapped'

Traceback:
  1: .C("rpqlsd", as.double(c(fit$coef.pol, fit$coef.kts)), 
as.double(fit$knots),     as.double(fit$bound), as.integer(0), qq = 
as.double(p), as.integer(length(fit$knots)),     as.integer(length(p)), 
PACKAGE = "logspline")
  2: qlogspline(pp, fit)
[rest deleted]

I think you are getting zero from rpois(1,10) with larger values of n.

rlogspline does not check for n==0

This results in calling qlogspline( numeric(0), fit ) and generates the 
segfault, I guess.

So figure out what should happen when rpois(1,10) returns zero and avoid 
calling rlogspline in those cases.

If 'zero.value' is a suitable value, then this will work:

> library(logspline)
> x <- rnorm(500)
> fit <- logspline(x)
> res <- sapply(1:50, function(x) sum(rlogspline(x, fit)))
> n <- 1000000
> rp <- rpois(n,10)
> y <- c( zero.value, res )[ rp+1 ] ## table lookup is faster!

Chuck


> The problem I keep getting is Rcrashes when doing the last line.  It
> seems to be fine if n is small, but not if n is 1000000.  The message
> I keep getting is:
>
> "R for Windows GUI front-end has encountered a problem and needs to
> close.  We are sorry for the inconvenience.  If you were in the middle
> of something, the information you were working on might be lost."
>
> Any insights would be appreciated,
>
> Jacques
>
> platform       i386-pc-mingw32
> arch           i386
> os             mingw32
> system         i386, mingw32
> status
> major          2
> minor          5.0
> year           2007
> month          04
> day            23
> svn rev        41293
> language       R
> version.string R version 2.5.0 (2007-04-23)
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	         UC San Diego
http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0901


From alice at blarg.net  Fri Jun  1 02:07:08 2007
From: alice at blarg.net (Alice Shelly)
Date: Thu, 31 May 2007 17:07:08 -0700
Subject: [R] AIC consistency with S-PLUS
Message-ID: <051801c7a3e0$cc10bfc0$0201a8c0@alicemobile>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070531/73a9c23d/attachment.pl 

From tlee at bcgsc.ca  Fri Jun  1 02:24:26 2007
From: tlee at bcgsc.ca (Tang Lee)
Date: Thu, 31 May 2007 17:24:26 -0700
Subject: [R] Affycoretools
Message-ID: <C284B54A.C3%tlee@bcgsc.ca>

I am having problem installing the affycoretools package. When I do it
through biocLite, I get error messages saying the package XML cannot be
installed and that I need a more recent version of libxml2.

When I try to install the tar.gz file, I get the message

/usr/local/R/2.4.0/lib/R/bin/exec/R: error while loading shared libraries:
libg2c.so.0: cannot open shared object
ERROR: installing package DESCRIPTION failed

How else can I install this or what can I fix in order to get it?

Thanks.


From Bill.Venables at csiro.au  Fri Jun  1 02:56:41 2007
From: Bill.Venables at csiro.au (Bill.Venables at csiro.au)
Date: Fri, 1 Jun 2007 10:56:41 +1000
Subject: [R] AIC consistency with S-PLUS
References: <051801c7a3e0$cc10bfc0$0201a8c0@alicemobile>
Message-ID: <B998A44C8986644EA8029CFE6396A924B67BC6@exqld2-bne.nexus.csiro.au>

I think we need some clarification here.

extractAIC() is available on both systems, in the stats package in R and
in the MASS library in S-PLUS.  If you use extractAIC() on both systems,
do you get the same ordering of models? 

AIC() is also available on both systems, in the stats package again in
R, and in the nlme3 library in S-PLUS.  On R there are not too many
classes where methods are available for both, but on S-PLUS there are a
few.  

So what are you comparing with what?  You need to say what classes of
objects you are dealing with, that is very important, and what generic
functions you are using for the comparison on each system.  The capacity
for confusion in this area is immense.

Bill Venables
CSIRO Laboratories
PO Box 120, Cleveland, 4163
AUSTRALIA
Office Phone (email preferred): +61 7 3826 7251
Fax (if absolutely necessary):  +61 7 3826 7304
Mobile:                (I don't have one!)
Home Phone:                     +61 7 3286 7700
mailto:Bill.Venables at csiro.au
http://www.cmis.csiro.au/bill.venables/ 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Alice Shelly
Sent: Friday, 1 June 2007 10:07 AM
To: r-help at stat.math.ethz.ch
Subject: [R] AIC consistency with S-PLUS

Hello-
I understand that log-likelihoods are bound to differ by constants, but
if i estimate AIC for a set of simple nested linear models using the
following 4 methods, shouldn't at least two of them produce the same
ordering of models?

in R:
extractAIC
AIC

in S-PLUS:
AIC
n*log(deviance(mymodel)/n) + 2*p

I find it troubling that these methods all give me different answers as
to the best model or even short set of models.

Thanks for your comments.

Alice Shelly

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From daj025 at gmail.com  Fri Jun  1 03:29:44 2007
From: daj025 at gmail.com (David James)
Date: Thu, 31 May 2007 21:29:44 -0400
Subject: [R] RMySQL DBI question
In-Reply-To: <8ee9d8f20705311557r4be9877cr72eb6a0faeea2787@mail.gmail.com>
References: <8ee9d8f20705311557r4be9877cr72eb6a0faeea2787@mail.gmail.com>
Message-ID: <74c69e370705311829w729fc64lbe16ea486df88ee7@mail.gmail.com>

Hi,

It would be helpful to have a small reproducible example.  Do you see
the same error if you run "R --save < whatever.R" from the shell prompt?

Regards,

--
David


On 5/31/07, Waverley <waverley.paloalto at gmail.com> wrote:
> Dear colleague,
>
> I have two data frame which I tried to use dbWriteTable function with
> append=TRUE to write to the mysql database.
>
> The problem is that if I am run my R script directly then it is fine.  Both
> data frame got written into the database.  But when I tried to embed the
> script to be called as system("R --save < whatever.R") in my perl script, I
> saw very strange things.
>
> One of the data frame got written into the database without any problem.
> But the other one refused to go to the database with the following error
> message:
>
> "Error in mysqlExecStatement ... RS-DBI driver: (could not run statement:
> Table ... already exists)
>
> I have checked on line and find
> http://tolstoy.newcastle.edu.au/R/help/01c/0652.html talks about the same
> problem I have en counted.  But the problem is that I have two data frame,
> one works and the other does not. Also if I don't run under perl and run
> directly R under shell, both works.
>
> Can someone help?
>
> I am running R-2.5.0 with RMySQL-0.5-11 and DBI0.2.3.
>
> I am using linux redhat ES4.0 64 bit.
>
> --
> Waverley @ Palo Alto
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From sell_mirage_ne at hotmail.com  Fri Jun  1 04:18:35 2007
From: sell_mirage_ne at hotmail.com (Taka Matzmoto)
Date: Thu, 31 May 2007 21:18:35 -0500
Subject: [R] scan a directory and then make a string vector consisting of
	file names
Message-ID: <BAY135-F16F7D4BBFC11D1DEE098CDC72C0@phx.gbl>

Dear R-users,

I am looking for a way to scan a directory and then make a string vector 
consisting of the file names in the directory.

For example, under c:\temp\
there are 4 files
a.txt, b.txt, c.txt, and d.txt

I would like to have a string vector
c("a.txt","b.txt","c.txt","d.txt")

How do I do that?

Thanks

Taka,

_________________________________________________________________
Make every IM count. Download Messenger and join the i?m Initiative now. 
It?s free. http://im.live.com/messenger/im/home/?source=TAGHM_June07


From marc_schwartz at comcast.net  Fri Jun  1 04:39:17 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Thu, 31 May 2007 21:39:17 -0500
Subject: [R] scan a directory and then make a string vector
	consisting	of file names
In-Reply-To: <BAY135-F16F7D4BBFC11D1DEE098CDC72C0@phx.gbl>
References: <BAY135-F16F7D4BBFC11D1DEE098CDC72C0@phx.gbl>
Message-ID: <1180665557.7981.19.camel@localhost.localdomain>

On Thu, 2007-05-31 at 21:18 -0500, Taka Matzmoto wrote:
> Dear R-users,
> 
> I am looking for a way to scan a directory and then make a string vector 
> consisting of the file names in the directory.
> 
> For example, under c:\temp\
> there are 4 files
> a.txt, b.txt, c.txt, and d.txt
> 
> I would like to have a string vector
> c("a.txt","b.txt","c.txt","d.txt")
> 
> How do I do that?
> 
> Thanks
> 
> Taka,


See ?list.files

For example:

  list.files("c:/temp", pattern = "\\.txt")

Note the use of the forward slash in the 'path' argument. See R Windows
FAQ:

http://cran.r-project.org/bin/windows/base/rw-FAQ.html#R-can_0027t-find-my-file

HTH,

Marc Schwartz


From cincinattikid at bigpond.com  Fri Jun  1 06:00:34 2007
From: cincinattikid at bigpond.com (Alfonso Sammassimo)
Date: Fri, 1 Jun 2007 14:00:34 +1000
Subject: [R] aggregate in zoo
Message-ID: <000d01c7a401$67c9f600$0300a8c0@Vaio>

Hi R-experts,

Thanks very much to Jim Holtman and Gabor on my previous question.

I am having another problem with data manipulation in zoo. The following is 
data (Z) for first business day of every month in zoo format. I am trying to 
get mean of "open" for each year. I subset Z <- Z[,2] then

> sapply(split(Z, format(index(Z), "%Y")),mean)

I get error message:

>2000 2001 2002 2003 2004 2005 2006 2007
  NA   NA   NA   NA   NA   NA   NA   NA
Warning messages:
1: argument is not numeric or logical: returning NA in: mean.default(X[[1]], 
...)
2: argument is not numeric or logical: returning NA in: mean.default(X[[2]], 
...)
etc...................

Any help on what I'm missing would be appreciated. I am particularly 
confused by the fact that the command used works fine on the original data 
file (i.e. before subsetting by first day of month). Sorry if I have 
overlooked something very simple.

<Z
                 dayofmonth    open
2000-02-01 01        1636.10
2000-03-01 01        1596.75
2000-04-03 03        1737.70
2000-05-01 01        1695.65
2000-06-01 01        1651.90
2000-07-03 03        1669.20
2000-08-01 01        1628.35
2000-09-01 01        1717.35
2000-10-02 02        1614.55
2000-11-01 01        1587.10
2000-12-01 01        1475.60
2001-01-02 02        1450.65
2001-02-01 01        1503.60
2001-03-01 01        1351.95
2001-04-02 02        1268.10
2001-05-01 01        1369.20
2001-06-01 01        1362.75
2001-07-02 02        1331.55
2001-08-01 01        1309.70
2001-09-04 04        1235.55
2001-10-01 01        1109.20
2001-11-01 01        1155.55
2001-12-03 03        1207.30

Thank you,
Alfonso Sammassimo
Melbourne, Australia


From alice at blarg.net  Fri Jun  1 06:10:56 2007
From: alice at blarg.net (Alice Shelly)
Date: Thu, 31 May 2007 21:10:56 -0700
Subject: [R] AIC consistency with S-PLUS
References: <051801c7a3e0$cc10bfc0$0201a8c0@alicemobile>
	<B998A44C8986644EA8029CFE6396A924B67BC6@exqld2-bne.nexus.csiro.au>
Message-ID: <055c01c7a402$db54b500$0201a8c0@alicemobile>

I apologize - i meant to include that i was talking about a simple set of 
nested linear models, fit using lm.
Yes, the extractAIC function in the MASS library does provide the same 
answer in both S-PLUS and in R. As does the AIC function in the nlme 
library! I suppose that is my answer, although i guess i am still wondering 
why my function in S-PLUS is not correct.

Thanks so much for your response.

----- Original Message ----- 
From: <Bill.Venables at csiro.au>
To: <alice at blarg.net>; <r-help at stat.math.ethz.ch>
Sent: Thursday, May 31, 2007 5:56 PM
Subject: RE: [R] AIC consistency with S-PLUS


I think we need some clarification here.

extractAIC() is available on both systems, in the stats package in R and
in the MASS library in S-PLUS.  If you use extractAIC() on both systems,
do you get the same ordering of models?

AIC() is also available on both systems, in the stats package again in
R, and in the nlme3 library in S-PLUS.  On R there are not too many
classes where methods are available for both, but on S-PLUS there are a
few.

So what are you comparing with what?  You need to say what classes of
objects you are dealing with, that is very important, and what generic
functions you are using for the comparison on each system.  The capacity
for confusion in this area is immense.

Bill Venables
CSIRO Laboratories
PO Box 120, Cleveland, 4163
AUSTRALIA
Office Phone (email preferred): +61 7 3826 7251
Fax (if absolutely necessary):  +61 7 3826 7304
Mobile:                (I don't have one!)
Home Phone:                     +61 7 3286 7700
mailto:Bill.Venables at csiro.au
http://www.cmis.csiro.au/bill.venables/

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Alice Shelly
Sent: Friday, 1 June 2007 10:07 AM
To: r-help at stat.math.ethz.ch
Subject: [R] AIC consistency with S-PLUS

Hello-
I understand that log-likelihoods are bound to differ by constants, but
if i estimate AIC for a set of simple nested linear models using the
following 4 methods, shouldn't at least two of them produce the same
ordering of models?

in R:
extractAIC
AIC

in S-PLUS:
AIC
n*log(deviance(mymodel)/n) + 2*p

I find it troubling that these methods all give me different answers as
to the best model or even short set of models.

Thanks for your comments.

Alice Shelly

[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From sfalcon at fhcrc.org  Fri Jun  1 06:11:55 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Thu, 31 May 2007 21:11:55 -0700
Subject: [R] Affycoretools
In-Reply-To: <C284B54A.C3%tlee@bcgsc.ca> (Tang Lee's message of "Thu,
	31 May 2007 17:24:26 -0700")
References: <C284B54A.C3%tlee@bcgsc.ca>
Message-ID: <m2zm3kl3ec.fsf@ziti.local>

Hi Tang,

Please send questions about Bioconductor packages to the the
Biocondcutor mailing list.

Please also read over the posting guide for that list to make sure
you provide enough information for folks to help you.

    http://bioconductor.org/docs/postingGuide.html


Tang Lee <tlee at bcgsc.ca> writes:

> I am having problem installing the affycoretools package. When I do it
> through biocLite, I get error messages saying the package XML cannot be
> installed and that I need a more recent version of libxml2.

And did you resolve this by instaling a more recent libxml2?

+ seth

-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
http://bioconductor.org


From Bill.Venables at csiro.au  Fri Jun  1 06:31:10 2007
From: Bill.Venables at csiro.au (Bill.Venables at csiro.au)
Date: Fri, 1 Jun 2007 14:31:10 +1000
Subject: [R] scan a directory and then make a string vector consisting
	offile names
References: <BAY135-F16F7D4BBFC11D1DEE098CDC72C0@phx.gbl>
Message-ID: <B998A44C8986644EA8029CFE6396A924B67BD4@exqld2-bne.nexus.csiro.au>

Would you believe it's 

> list.files()

See ?list.files for variants.


Bill Venables
CSIRO Laboratories
PO Box 120, Cleveland, 4163
AUSTRALIA
Office Phone (email preferred): +61 7 3826 7251
Fax (if absolutely necessary):  +61 7 3826 7304
Mobile:                (I don't have one!)
Home Phone:                     +61 7 3286 7700
mailto:Bill.Venables at csiro.au
http://www.cmis.csiro.au/bill.venables/ 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Taka Matzmoto
Sent: Friday, 1 June 2007 12:19 PM
To: r-help at stat.math.ethz.ch
Subject: [R] scan a directory and then make a string vector consisting
offile names

Dear R-users,

I am looking for a way to scan a directory and then make a string vector

consisting of the file names in the directory.

For example, under c:\temp\
there are 4 files
a.txt, b.txt, c.txt, and d.txt

I would like to have a string vector
c("a.txt","b.txt","c.txt","d.txt")

How do I do that?

Thanks

Taka,

_________________________________________________________________
Make every IM count. Download Messenger and join the i'm Initiative now.

It's free. http://im.live.com/messenger/im/home/?source=TAGHM_June07


From chainsawtiney at gmail.com  Fri Jun  1 06:33:33 2007
From: chainsawtiney at gmail.com (Chung-hong Chan)
Date: Fri, 1 Jun 2007 12:33:33 +0800
Subject: [R] Proxy Under Mac OS X
Message-ID: <30d7ea360705312133t52caef0cpa430435ab82cc7e@mail.gmail.com>

Dear R programmers,

I can only config. proxy under Mac OS X terminal and launch R under Terminal by

Terminal:

export http_proxy="http://un:pw at proxy.com:port"

Under R:

>chooseCRANmirror(graphics=FALSE)
>update.packages()

I don't know how to config this in R for Mac OS X Aqua GUI.
I checked the relevant document but no specific steps for Mac OS X.

Regards,
Ch Chan



-- 
"The scientists of today think deeply instead of clearly. One must be
sane to think clearly, but one can think deeply and be quite insane."
Nikola Tesla
http://www.macgrass.com


From mmeredith at wcs.org  Fri Jun  1 06:44:46 2007
From: mmeredith at wcs.org (Mike Meredith)
Date: Thu, 31 May 2007 21:44:46 -0700 (PDT)
Subject: [R] Getting names of objects passed with "..."
Message-ID: <10906614.post@talk.nabble.com>


Is there a tidy way to get the names of objects passed to a function via the
"..." argument?

rbind/cbind does what I want:

test.func1 <- function(...) { 
   nms <- rownames(rbind(..., deparse.level=1))
   print(nms)
}

x <- "some stuff"
second <- "more stuff"
test.func1(first=x, second)
[1] "first"  "second"

The usual 'deparse(substitute())' doesn't do it:

test.func2 <- function(...) {
   nms <- deparse(substitute(...))
   print(nms)
}
test.func2(first=x, second)
[1] "x"

I'm using "nms <- rownames(rbind(...))" as a workaround, which works, but
there must be a neater way!

rbind/cbind are .Internal, so I can't pinch code from there.

Thanks,  Mike.

-- 
View this message in context: http://www.nabble.com/Getting-names-of-objects-passed-with-%22...%22-tf3850318.html#a10906614
Sent from the R help mailing list archive at Nabble.com.


From Jouni.Junnila at PERKINELMER.COM  Fri Jun  1 07:21:28 2007
From: Jouni.Junnila at PERKINELMER.COM (Junnila, Jouni)
Date: Fri, 1 Jun 2007 06:21:28 +0100
Subject: [R] Choosing a column for analysis in a function
In-Reply-To: <465ED42B.2090808@cancer.org.uk>
Message-ID: <9202D193C49A974F9DC63C32B28918D09625E2@EMEAMAIL01.PERKINELMER.NET>

Thank you for the tip.
I already got a tip from Steve Ellison and it works for me. I'm now
using

data.whole$Analyte.Values <- data.whole[[analyte]] 

and everything goes smoothly! 
I tested also your suggestion, but got the following 
error:   "attempt to apply non-function"
So I'm sticking with Steve's suggestion. Thanks anyway!!

-Jouni

-----Original Message-----
From: Adaikalavan Ramasamy [mailto:ramasamy at cancer.org.uk] 
Sent: 31. toukokuuta 2007 16:57
To: Junnila, Jouni
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Choosing a column for analysis in a function

Perhaps the use of as.character() like following might help?

  data.whole$Analyte.Values <- data.whole$as.character(analyte)


Junnila, Jouni wrote:
> Hello all,
> 
> I'm having a problem concerning choosing columns from a dataset in a 
> function.
> 
> I'm writing a function for data input etc., which first reads the 
> data, and then does several data manipulation tasks.
> The function can be then used, with just giving the path of the .txt 
> file where the data is being held.
> 
> These datasets consists of over 20 different analytes. Though, 
> statistical analyses should be made seperately analyte by analyte. So 
> the function needs to be able to choose a certain analyte based on 
> what the user of the function gives as a parameter when calling the
function.
> The name of the analyte user gives, is the same as a name of a column 
> in the data set.
> 
> The question is: how can I refer to the parameter which the user 
> gives, inside the function? I cannot give the name of the analyte 
> directly inside the function, as the same function should work for all

> the 20 analytes.
> I'm giving some code for clarification:
> 
>> datainput <- function(data1,data2,data3,data4,data5,data6,analyte)
>> {
> ...
> ##data1-data6 being the paths of the six datasets I want to combine 
> and analyte being the special analyte I want to analyze and which can 
> be found on each of the datasets as a columnname.## ##Then:## ...
>> data.whole <- subset(data.whole,
> select=c(Sample.Name,Analyte.Values,Day,Plate))
> 
> ##Is for choosing the columns needed for analysis. The "Analyte" 
> should now be the column of the analyte, the users is referring to 
> when calling the datainput-function. How to do it? ## I've tried 
> something like
>> data.whole$Analyte.Values <- data.whole$analyte ##(Or in quotes
> "analyte")
> But this does not work. I've tried several other "tricks" also, but 
> cannot get it to work. Can someone help?
> 
> Thanks in advance,
> 
> Jouni
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
>


From ripley at stats.ox.ac.uk  Fri Jun  1 07:40:30 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 1 Jun 2007 06:40:30 +0100 (BST)
Subject: [R] A question regarding package development
In-Reply-To: <7FD2A5C0-167A-49DF-8722-0749C849A26E@pobox.com>
References: <7FD2A5C0-167A-49DF-8722-0749C849A26E@pobox.com>
Message-ID: <Pine.LNX.4.64.0706010625470.26566@gannet.stats.ox.ac.uk>

On Thu, 31 May 2007, Saptarshi Guha wrote:

> Hi,
> 	I am writing a package which requires the ANN(Approx N.Neighbors)
> library (found here http://www.cs.umd.edu/~mount/ANN/).
> 	My package directory looks something like this
>
> 	atry/
> 	atry/src/ann/   <--ann source is here
> 	atry/src/ann/include
> 	atry/src/ann/lib <--ann lib file is here
> 	atry/src/disp.cpp < my file which requires the ann lib
>
> 	The last file disp.cpp has the include line
>
> 	include "ann/ann.h"
>
> 	How do i modify the R CMD INSTALL process so that i can
> 	1) build the ann library

You would need to add a src/Makefile. There are several examples in CRAN 
packages.  Matrix is one, but a complex one.  Runuran is a simple one, 
unfortunately specific to GNU make.

> 	2) provides include paths and lib paths to the R CMD INSTALL process
> so that atry/src/disp.cpp (my program)  can locate the libs and
> header files and succesfully compile.
> 	I tried using Makevars (in the src folder) and adding a INCPATH and
> LIBS= however that didn't work - the compilation didn't take into
> account the modified INCPATH.

`Writing R Extensions' tells you about PKG_CPPFLAGS and PKG_LIBS, in the 
section on 'Makevars', so I don't understand why you used different names.
There are lots of examples in CRAN packages.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jo.irisson at gmail.com  Fri Jun  1 08:16:45 2007
From: jo.irisson at gmail.com (jiho)
Date: Fri, 1 Jun 2007 08:16:45 +0200
Subject: [R] Problem with Weighted Variance in Hmisc
In-Reply-To: <000701c7a3d7$eac58da0$6401a8c0@Boozoo>
References: <000701c7a3d7$eac58da0$6401a8c0@Boozoo>
Message-ID: <1412498F-08C7-4684-8E02-A3F7AE7C43FD@gmail.com>

On 2007-June-01  , at 01:03 , Tom La Bone wrote:
> The function wtd.var(x,w) in Hmisc calculates the weighted variance  
> of x
> where w are the weights.  It appears to me that wtd.var(x,w) = var 
> (x) if all
> of the weights are equal, but this does not appear to be the case. Can
> someone point out to me where I am going wrong here?  Thanks.

The true formula of weighted variance is this one:
	http://www.itl.nist.gov/div898/software/dataplot/refman2/ch2/ 
weighvar.pdf
But for computation purposes, wtd.var uses another definition which  
considers the weights as repeats instead of true weights. However if  
the weights are normalized (sum to one) to two formulas are equal. If  
you consider weights as real weights instead of repeats, I would  
recommend to use this option.
With normwt=T, your issue is solved:

 > a=1:10
 > b=a
 > b[]=2
 > b
[1] 2 2 2 2 2 2 2 2 2 2
 > wtd.var(a,b)
[1] 8.68421
# all weights equal 2 <=> there are two repeats of each element of a
 > var(c(a,a))
[1] 8.68421
 > wtd.var(a,b,normwt=T)
[1] 9.166667
 > var(a)
[1] 9.166667

Cheers,

JiHO
---
http://jo.irisson.free.fr/


From sell_mirage_ne at hotmail.com  Fri Jun  1 08:28:36 2007
From: sell_mirage_ne at hotmail.com (Taka Matzmoto)
Date: Fri, 01 Jun 2007 01:28:36 -0500
Subject: [R] 3 classification variables and one string variable
Message-ID: <BAY135-F17AC8D5B5886730670BEB6C72C0@phx.gbl>

Dear R users
I have 3 classification variables (string type) and one string variable in a 
data.frame (x).

the first factor is a region (north, south, west, and east) (4 levels)
the second factor is a market type (A, B, C, and D) (4 levels)
the third factor is a item type (w, x, y, z) (4 levels)
the string variable is a seller first name.

My goal is to create a string vector consisting of seller first names for 
each cell of  4*4*4 contingency table. Some of the cells are empty.

For example, w type ITEM in B market in North region = c("John", "Smith")
I would like to create a name for the string vector using the three factor 
names (e.g., north.B.w)
I tried to use table(). It didn't work well. I could use some long tedious 
method like below but it doesn't look good.

north.B.w.ind <- x$region == "Noth" & x$market == "B" & x$item == "w"
north.B.w <- x[north.B.w.ind, "name"]


Any help will be appreciated.

Thanks

Taka,

_________________________________________________________________

Office Live http://clk.atdmt.com/MRT/go/aub0540003042mrt/direct/01/


From ligges at statistik.uni-dortmund.de  Fri Jun  1 09:15:38 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 01 Jun 2007 09:15:38 +0200
Subject: [R] R keeps crashing when executing 'rlogspline'
In-Reply-To: <Pine.LNX.4.64.0705311634010.9126@tajo.ucsd.edu>
References: <787911d50705311413jaa6ef19ncffd7e20b6a0623f@mail.gmail.com>
	<Pine.LNX.4.64.0705311634010.9126@tajo.ucsd.edu>
Message-ID: <465FC79A.5070401@statistik.uni-dortmund.de>



Charles C. Berry wrote:
> On Thu, 31 May 2007, Jacques Wagnor wrote:
> 
>> Dear List,
>>
>> I have a simple model as follows:
>>
>> x <- rnorm(500)
>> library(logspline)
>> fit <- logspline(x)
>> n <- 1000000
>> y <- replicate(n, sum(rlogspline(rpois(1,10), fit))) # last line
>>
> 
> What you do not see in RGui is this:
> 
> 
>   *** caught segfault ***
> address (nil), cause 'memory not mapped'
> 
> Traceback:
>   1: .C("rpqlsd", as.double(c(fit$coef.pol, fit$coef.kts)), 
> as.double(fit$knots),     as.double(fit$bound), as.integer(0), qq = 
> as.double(p), as.integer(length(fit$knots)),     as.integer(length(p)), 
> PACKAGE = "logspline")
>   2: qlogspline(pp, fit)
> [rest deleted]
> 
> I think you are getting zero from rpois(1,10) with larger values of n.
> 
> rlogspline does not check for n==0
> 
> This results in calling qlogspline( numeric(0), fit ) and generates the 
> segfault, I guess.
> 
> So figure out what should happen when rpois(1,10) returns zero and avoid 
> calling rlogspline in those cases.


And please do not forget to notify the package maintainer that there is 
a bug in the package. The maintainer will probably be happy to know 
about it. I am CCing to Charles Kooperberg.

Uwe Ligges





> If 'zero.value' is a suitable value, then this will work:
> 
>> library(logspline)
>> x <- rnorm(500)
>> fit <- logspline(x)
>> res <- sapply(1:50, function(x) sum(rlogspline(x, fit)))
>> n <- 1000000
>> rp <- rpois(n,10)
>> y <- c( zero.value, res )[ rp+1 ] ## table lookup is faster!
> 
> Chuck
> 
> 
>> The problem I keep getting is Rcrashes when doing the last line.  It
>> seems to be fine if n is small, but not if n is 1000000.  The message
>> I keep getting is:
>>
>> "R for Windows GUI front-end has encountered a problem and needs to
>> close.  We are sorry for the inconvenience.  If you were in the middle
>> of something, the information you were working on might be lost."
>>
>> Any insights would be appreciated,
>>
>> Jacques
>>
>> platform       i386-pc-mingw32
>> arch           i386
>> os             mingw32
>> system         i386, mingw32
>> status
>> major          2
>> minor          5.0
>> year           2007
>> month          04
>> day            23
>> svn rev        41293
>> language       R
>> version.string R version 2.5.0 (2007-04-23)
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> Charles C. Berry                        (858) 534-2098
>                                           Dept of Family/Preventive Medicine
> E mailto:cberry at tajo.ucsd.edu	         UC San Diego
> http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0901
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From francogrex at mail.com  Fri Jun  1 09:18:34 2007
From: francogrex at mail.com (francogrex)
Date: Fri, 1 Jun 2007 00:18:34 -0700 (PDT)
Subject: [R] Metropolis code help
Message-ID: <10907938.post@talk.nabble.com>


Dears, I have the below code for metropolis of the GLM logit (logistic
regression) using a flat prior. Can someone help me modify the prior so that
the model becomes hierarchical by using a flat prior for mu and sigma, the
derived density for beta ~ N(mu, sigma^2)? Actually I took my code from a
teacher that posted on the internet and modified it to the GLM logit but I
can't adapt it to the hierarchical version. 
Here is the original code of the teacher with both flat prior on betas and a
hierarchical version:
www.stats.uwo.ca/faculty/murdoch/458/metropolis.r 


Below is My code with a flat prior on beta only (I'd like also to have the
hierarchical version!)
X<- cbind(1,DF$nsaid,DF$diuretic,DF$diuretic*DF$nsaid)
y<- DF$Var3

Metropolis <- function(logtarget, start, R = 1000, sd
= 1) {
    parmcount <- length(start)
    sims <- matrix(NA, nrow=R, ncol = parmcount)
    colnames(sims) <- names(start)

    sims[1,] <- start
    oldlogalpha <- logtarget(start)
    accepts <- 0

    for (i in 2:R) {
	jump <- rnorm(parmcount, mean=0, sd=sd)
	y <- sims[i-1,] + jump

    	newlogalpha <- logtarget(y)
	if (log(runif(1)) < newlogalpha - oldlogalpha) {
	    sims[i,] <- y
	    oldlogalpha <- newlogalpha
	    accepts <- accepts + 1
	} else {
	    sims[i,] <- sims[i-1,]
	}
    }
    cat('Accepted ',100*accepts/(R-1),'%\n')
    sims
}

# Use the binomial likelihood 
logitll=function(beta,y,X)
{
X<- cbind(1,DF$nsaid,DF$diuretic,DF$diuretic*DF$nsaid)
y<- DF$Var3
lF1=plogis(X%*%as.vector(beta),log.p=TRUE)
lF2=plogis(-X%*%as.vector(beta),log.p=TRUE)
sum(y*lF1+(1-y)*lF2)
}

# Use a uniform prior for p
logprior <- function(beta,y,X) 0

# The log posterior is the sum.  It's the target of our MCMC run
logposterior <- function(beta,y,X) logprior(beta,y,X)+logitll(beta,y,X)

start <- c(0,0,0,0)
sims <- Metropolis(logposterior, start, 10000, sd=1)

se_sims <- apply(sims, 2, sd)

sims <- Metropolis(logposterior, start, 10000,sd=se_sims)

cbind(rbind(mean(sims[1001:10000,1]),mean(sims[1001:10000,2]),mean(sims[1001:10000,3]),mean(sims[1001:10000,4])),
rbind(sd(sims[1001:10000,1]),sd(sims[1001:10000,2]),sd(sims[1001:10000,3]),sd(sims[1001:10000,4])))

Thanks in advance.

-- 
View this message in context: http://www.nabble.com/Metropolis-code-help-tf3850742.html#a10907938
Sent from the R help mailing list archive at Nabble.com.


From ripley at stats.ox.ac.uk  Fri Jun  1 09:36:23 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 1 Jun 2007 08:36:23 +0100 (BST)
Subject: [R] Proxy Under Mac OS X
In-Reply-To: <30d7ea360705312133t52caef0cpa430435ab82cc7e@mail.gmail.com>
References: <30d7ea360705312133t52caef0cpa430435ab82cc7e@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0706010833290.4568@gannet.stats.ox.ac.uk>

The most 'relevant document' is ?download.file, and there is AFAIK 
nothing specific to MacOS X about the code (and I did write it).

You can use

Sys.setenv(http_proxy="http://un:pw at proxy.com:port")

at the start of your R session, or use

http_proxy="http://un:pw at proxy.com:port"

in your ~/.Renviron file (see 'An Introduction to R' and ?Startup).


On Fri, 1 Jun 2007, Chung-hong Chan wrote:

> Dear R programmers,
>
> I can only config. proxy under Mac OS X terminal and launch R under 
> Terminal by
>
> Terminal:
>
> export http_proxy="http://un:pw at proxy.com:port"
>
> Under R:
>
>> chooseCRANmirror(graphics=FALSE)
>> update.packages()
>
> I don't know how to config this in R for Mac OS X Aqua GUI.
> I checked the relevant document but no specific steps for Mac OS X.
>
> Regards,
> Ch Chan
>
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From epistat at gmail.com  Fri Jun  1 10:31:01 2007
From: epistat at gmail.com (zhijie zhang)
Date: Fri, 1 Jun 2007 16:31:01 +0800
Subject: [R] How should i get the quantile 2.5 % and 97.5% in each row of a
	matrix?
Message-ID: <2fc17e30706010131i6dcc773cs67cb7c36ca0da222@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070601/59f22f7e/attachment.pl 

From ccleland at optonline.net  Fri Jun  1 10:41:25 2007
From: ccleland at optonline.net (Chuck Cleland)
Date: Fri, 01 Jun 2007 04:41:25 -0400
Subject: [R] How should i get the quantile 2.5 % and 97.5% in each row
	of a	matrix?
In-Reply-To: <2fc17e30706010131i6dcc773cs67cb7c36ca0da222@mail.gmail.com>
References: <2fc17e30706010131i6dcc773cs67cb7c36ca0da222@mail.gmail.com>
Message-ID: <465FDBB5.1040701@optonline.net>

zhijie zhang wrote:
> Dear friends,
>   I need the get the 2.5% and 97.5% quantile  from each row of a matrix, how
> should i get it?
> BTW, i can get the min/max value from each row of a matrix,  using the
> following programs, is there an easy function to do it?
> 
> simmin<-matrix(NA,nrow=47,ncol=1)
> for (i in 1:47) {
>     simmin[i,]<-min(datas[i,])
>  }
> 
>  Thanks for your help.

mymat <- matrix(rnorm(200), ncol=50)

apply(mymat, 1, quantile, probs = c(0.025,0.975))
           [,1]      [,2]      [,3]      [,4]
2.5%  -1.690786 -1.691700 -1.678078 -1.564438
97.5%  1.970500  1.954904  2.249030  1.862571

apply(mymat, 1, max)
[1] 2.179982 2.257138 2.772428 2.579247

apply(mymat, 1, min)
[1] -2.830661 -1.989114 -1.710050 -2.316970

?apply

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From hb at stat.berkeley.edu  Fri Jun  1 10:58:29 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Fri, 1 Jun 2007 10:58:29 +0200
Subject: [R] Getting names of objects passed with "..."
In-Reply-To: <10906614.post@talk.nabble.com>
References: <10906614.post@talk.nabble.com>
Message-ID: <59d7961d0706010158t5f1ff661r51c5675edefd4cb8@mail.gmail.com>

I use:

foo <- function(...) {
  args <- list(...);
  names(args);
}

/Henrik

On 6/1/07, Mike Meredith <mmeredith at wcs.org> wrote:
>
> Is there a tidy way to get the names of objects passed to a function via the
> "..." argument?
>
> rbind/cbind does what I want:
>
> test.func1 <- function(...) {
>    nms <- rownames(rbind(..., deparse.level=1))
>    print(nms)
> }
>
> x <- "some stuff"
> second <- "more stuff"
> test.func1(first=x, second)
> [1] "first"  "second"
>
> The usual 'deparse(substitute())' doesn't do it:
>
> test.func2 <- function(...) {
>    nms <- deparse(substitute(...))
>    print(nms)
> }
> test.func2(first=x, second)
> [1] "x"
>
> I'm using "nms <- rownames(rbind(...))" as a workaround, which works, but
> there must be a neater way!
>
> rbind/cbind are .Internal, so I can't pinch code from there.
>
> Thanks,  Mike.
>
> --
> View this message in context: http://www.nabble.com/Getting-names-of-objects-passed-with-%22...%22-tf3850318.html#a10906614
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ripley at stats.ox.ac.uk  Fri Jun  1 11:11:45 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 1 Jun 2007 10:11:45 +0100 (BST)
Subject: [R] Getting names of objects passed with "..."
In-Reply-To: <59d7961d0706010158t5f1ff661r51c5675edefd4cb8@mail.gmail.com>
References: <10906614.post@talk.nabble.com>
	<59d7961d0706010158t5f1ff661r51c5675edefd4cb8@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0706011007550.25961@gannet.stats.ox.ac.uk>

On Fri, 1 Jun 2007, Henrik Bengtsson wrote:

> I use:
>
> foo <- function(...) {
>  args <- list(...);
>  names(args);
> }

But that does not do what was asked: it gets the argument names, not the 
object names.  (Did you actually try it?)  It looks from the example that 
he wants the argument name if there is one otherwise the 
deparsed argument value, but clarification would be helpful.

>
> /Henrik
>
> On 6/1/07, Mike Meredith <mmeredith at wcs.org> wrote:
>>
>> Is there a tidy way to get the names of objects passed to a function via the
>> "..." argument?
>>
>> rbind/cbind does what I want:
>>
>> test.func1 <- function(...) {
>>    nms <- rownames(rbind(..., deparse.level=1))
>>    print(nms)
>> }
>>
>> x <- "some stuff"
>> second <- "more stuff"
>> test.func1(first=x, second)
>> [1] "first"  "second"
>>
>> The usual 'deparse(substitute())' doesn't do it:
>>
>> test.func2 <- function(...) {
>>    nms <- deparse(substitute(...))
>>    print(nms)
>> }
>> test.func2(first=x, second)
>> [1] "x"
>>
>> I'm using "nms <- rownames(rbind(...))" as a workaround, which works, but
>> there must be a neater way!
>>
>> rbind/cbind are .Internal, so I can't pinch code from there.
>>
>> Thanks,  Mike.
>>
>> --
>> View this message in context: http://www.nabble.com/Getting-names-of-objects-passed-with-%22...%22-tf3850318.html#a10906614
>> Sent from the R help mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mirko.sanpietrucci at email.it  Fri Jun  1 11:09:09 2007
From: mirko.sanpietrucci at email.it (mirko sanpietrucci)
Date: Fri, 1 Jun 2007 11:09:09 +0200
Subject: [R] how to extract the maximum from a matrix?
Message-ID: <000901c7a42c$a894d170$99e1cec1@dms.unina.it>

Dear UseRs,
I have a very simple question. I have a big matrix (say x) including 
probabilities (values in (0,1)).
I have to store in a list the names of the row and the column where max(x) 
is located. How can I proceed?

Thanks in advance for your assistance!

mirko


From dimitris.rizopoulos at med.kuleuven.be  Fri Jun  1 11:42:14 2007
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Fri, 1 Jun 2007 11:42:14 +0200
Subject: [R] how to extract the maximum from a matrix?
References: <000901c7a42c$a894d170$99e1cec1@dms.unina.it>
Message-ID: <00ac01c7a431$22cc0fe0$0540210a@www.domain>

look at the `arr.ind' argument of ?which(), e.g.,

x <- matrix(rnorm(9), 3, 3)
x
which(x == max(x), arr.ind = TRUE)


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "mirko sanpietrucci" <mirko.sanpietrucci at email.it>
To: <r-help at stat.math.ethz.ch>
Sent: Friday, June 01, 2007 11:09 AM
Subject: [R] how to extract the maximum from a matrix?


> Dear UseRs,
> I have a very simple question. I have a big matrix (say x) including
> probabilities (values in (0,1)).
> I have to store in a list the names of the row and the column where 
> max(x)
> is located. How can I proceed?
>
> Thanks in advance for your assistance!
>
> mirko
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm


From petr.pikal at precheza.cz  Fri Jun  1 11:52:30 2007
From: petr.pikal at precheza.cz (Petr PIKAL)
Date: Fri, 1 Jun 2007 11:52:30 +0200
Subject: [R] Odp:  how to extract the maximum from a matrix?
In-Reply-To: <000901c7a42c$a894d170$99e1cec1@dms.unina.it>
Message-ID: <OFE9270BE5.2DEC0994-ONC12572ED.00360172-C12572ED.00363E32@precheza.cz>

Hi

If you have tried to go through help pages of max you could find out which 
function, which can tell you position of your maximum.

which(x==max(x), arr.ind=T)

Regards

Petr Pikal
petr.pikal at precheza.cz

r-help-bounces at stat.math.ethz.ch napsal dne 01.06.2007 11:09:09:

> Dear UseRs,
> I have a very simple question. I have a big matrix (say x) including 
> probabilities (values in (0,1)).
> I have to store in a list the names of the row and the column where 
max(x) 
> is located. How can I proceed?
> 
> Thanks in advance for your assistance!
> 
> mirko
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dieter.menne at menne-biomed.de  Fri Jun  1 12:08:21 2007
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Fri, 1 Jun 2007 10:08:21 +0000 (UTC)
Subject: [R]
	=?utf-8?q?Standard_errors_of_the_predicted_values_from_a_lme_?=
	=?utf-8?q?=28or=09lmer=29-object?=
References: <004001c7a39d$d03585b0$2101a8c0@HP26282134612>
Message-ID: <loom.20070601T120538-203@post.gmane.org>

Fr?nzi Korner <fraenzi.korner <at> oikostat.ch> writes:

> 
> how do I obtain standard errors of the predicted values from a lme (or
> lmer)-object?

Not totally clear what you mean. intervals(lmeresult) gives the confidence
intervals for the coefficients. Otherwise, you can do some calculations with
residuals(lmeresult). Most useful for diagnostic purposes is plot(lmeresult).

Dieter


From antonio.raju at gmail.com  Fri Jun  1 12:22:32 2007
From: antonio.raju at gmail.com (antonio rodriguez)
Date: Fri, 01 Jun 2007 12:22:32 +0200
Subject: [R] zoo matrix manipulation
Message-ID: <465FF368.9070001@gmail.com>

Hi,

I have this dataset where columns z1.3 and z1.4 are full of NA's. I want 
to perform some calculations in the remaining columns, but after doing 
this, I want to recontruct the original matrix. I can with:

out <- which( colMeans( is.na( z ) ) == 1 )
gd<-z[, - out]

select the columns full of NA's and those without that pattern. Then 
after doing the calculus I need to reconstruct z as it was in its origin 
(z1.1,z1.2,...,z1.6)

BTW:The z matrix is a zoo object

Thanks,

Antonio

 > dput(z,control="all")
structure(c(16.7250003814697, 16.5, 16.6875, 15.8999996185303,
16.0500001907349, 16.2000007629395, 16.5, 16.2000007629395, 
15.8999996185303,
16.3499984741211, 16.2749996185303, 16.875, 16.875, 15.8999996185303,
15.8999996185303, 16.9500007629395, 17.4375, 18.1124992370605,
19.0499992370605, 16.7250003814697, 16.5, 16.7249984741211, 
15.8999996185303,
15.8999996185303, 15.8999996185303, 16.4249992370605, 16.0499992370605,
16.2000007629395, 16.3499984741211, 15.8625001907349, 17.0249996185303,
16.7999992370605, 16.2000007629395, 16.2000007629395, 16.875,
17.4750003814697, 18.2249984741211, 19.0499992370605, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, 16.7250003814697, 16.5750007629395, 16.5, 15.6750001907349,
15.9749999046326, 16.2749996185303, 16.6499996185303, 16.2749996185303,
16.1625003814697, 16.2374992370605, 16.2749996185303, 17.0249996185303,
16.7250003814697, 16.5750007629395, 16.8500003814697, 16.7999992370605,
17.7374992370605, 18.2250003814697, 18.75, 16.6124992370605,
16.3875007629395, 16.59375, 15.6000003814697, 15.9000005722046,
16.2000007629395, 16.5750007629395, 16.1437511444092, 16.0125007629395,
16.2937507629395, 16.1999988555908, 16.875, 16.6312503814697,
16.7999992370605, 17.1749992370605, 16.9500007629395, 17.7999992370605,
18.1687507629395, 18.75, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA), .Dim = as.integer(c(19,
6)), .Dimnames = list(NULL, c("z1.1", "z1.2", "z1.3", "z1.4",
"z1.5", "z1.6")), index = structure(c(5491, 5499, 5507, 5515,
5523, 5531, 5539, 5547, 5555, 5563, 5571, 5579, 5587, 5595, 5603,
5611, 5619, 5627, 5635), class = "Date"), class = "zoo")




-- 
=====
Por favor, si me mandas correos con copia a varias personas, 
pon mi direcci?n de correo en copia oculta (CCO), para evitar 
que acabe en montones de sitios, eliminando mi privacidad, 
favoreciendo la propagaci?n de virus y la proliferaci?n del SPAM. Gracias.
-----
If you send me e-mail which has also been sent to several other people,
kindly mark my address as blind-carbon-copy (or BCC), to avoid its
distribution, which affects my privacy, increases the likelihood of
spreading viruses, and leads to more SPAM. Thanks.
=====
Antes de imprimir este e-mail piense bien si es necesario hacerlo: El medioambiente es cosa de todos.
Before printing this email, assess if it is really needed.


From mmeredith at wcs.org  Fri Jun  1 12:17:26 2007
From: mmeredith at wcs.org (Mike Meredith)
Date: Fri, 1 Jun 2007 03:17:26 -0700 (PDT)
Subject: [R] Getting names of objects passed with "..."
In-Reply-To: <Pine.LNX.4.64.0706011007550.25961@gannet.stats.ox.ac.uk>
References: <10906614.post@talk.nabble.com>
	<59d7961d0706010158t5f1ff661r51c5675edefd4cb8@mail.gmail.com>
	<Pine.LNX.4.64.0706011007550.25961@gannet.stats.ox.ac.uk>
Message-ID: <10910245.post@talk.nabble.com>



Thanks, Henrik, but 'foo' doesn't do what I want:

x <- "some stuff"
second <- "more stuff"

foo(first=x, second)
[1] "first" ""

Brian's right:
>...he wants the argument name if there is one otherwise the 
> deparsed argument value, but clarification would be helpful. 

The function using this compares estimates of animal densities, CIs, etc
using different models, with one object containing the results of one model.
It extracts key results and AIC from these objects and does a summary
matrix, with lowest AIC at the top, so the row names need to reflect the
model used.

If the object name is sufficiently explanatory -- eg. point.est.hazardRate
-- then the deparsed argument value is fine as row name. But we need the
option to be more specific if necessary, eg. with "halfNormal=x1,
hazardRate=x2". Just like 'rbind', in fact.

Thanks,  Mike
-- 
View this message in context: http://www.nabble.com/Getting-names-of-objects-passed-with-%22...%22-tf3850318.html#a10910245
Sent from the R help mailing list archive at Nabble.com.


From gatemaze at gmail.com  Fri Jun  1 12:26:54 2007
From: gatemaze at gmail.com (gatemaze at gmail.com)
Date: Fri, 1 Jun 2007 11:26:54 +0100
Subject: [R] mahalanobis
In-Reply-To: <729610.91081.qm@web53306.mail.re2.yahoo.com>
References: <afea0ae80705310932q29587118l60cacec862535fb1@mail.gmail.com>
	<729610.91081.qm@web53306.mail.re2.yahoo.com>
Message-ID: <afea0ae80706010326g64c18e04n77d3dd43c4171732@mail.gmail.com>

On 31/05/07, Anup Nandialath <anup_nandialath at yahoo.com> wrote:
> oops forgot the example example
>
> try this line
>
> sqrt(mahalanobis(all, colMeans(predictors), cov(all), FALSE)
Hi and thanks for the reply Anup. Unfortunately, I had a look on the
example before posting but not much of a help... I did some further
tests and in order to have the same results I must run mahalanobis
with the predictors only dataset, ie.
mahalanobis(predictors, colMeans(predictors), cov(predictors)).

Now, on a first glance it seems to me a bit strange that the influence
of these points on a regression are measured without taking into
account the response variable (provided that the other stat software
calculates the mahalanobis distances correctly).... but I guess this
is something that I have to resolve by doing some studying on my own
on the mahalanobis distance...

thanks again.

>
> now cross check with other software
>
> best
>
> Anup
>
>
>  ________________________________
> No need to miss a message. Get email on-the-go
> with Yahoo! Mail for Mobile. Get started.
>
>


-- 
yianni


From spinningdoctor at yahoo.co.uk  Fri Jun  1 12:30:13 2007
From: spinningdoctor at yahoo.co.uk (Mbini)
Date: Fri, 1 Jun 2007 03:30:13 -0700 (PDT)
Subject: [R] Logrank test
Message-ID: <10910383.post@talk.nabble.com>


Hi 

I have a problem with computing the logrank test using R, can someone give
me the relavent code or help me otherwise please!

Thanks
-- 
View this message in context: http://www.nabble.com/Logrank-test-tf3851514.html#a10910383
Sent from the R help mailing list archive at Nabble.com.


From jessica.gervais at tudor.lu  Fri Jun  1 12:51:35 2007
From: jessica.gervais at tudor.lu (jessica.gervais at tudor.lu)
Date: Fri, 1 Jun 2007 12:51:35 +0200
Subject: [R] time serie generation
Message-ID: <OF83B7A903.0DF9C68C-ONC12572ED.003BA76C-C12572ED.003BA77F@tudor.lu>


Dear all,

I would like to generate a regular time serie, i.e. a list of dates and
time for each our of the period 2002-2004.

the time format should be
"2002-01-01 12:00:00" (year-month-day hour:min:sec)


so the list should contain all hours of the period 2002-2004
2002-01-01 00:00:00
2002-01-01 01:00:00
2002-01-01 02:00:00
...
2004-12-31 23:00:00
Does a function exist to create that kind of list ?

Thanks in advance,


Jessica


From rmi at danishmeat.dk  Fri Jun  1 12:51:39 2007
From: rmi at danishmeat.dk (Rina Miehs)
Date: Fri, 01 Jun 2007 12:51:39 +0200
Subject: [R] random effects in lmer
Message-ID: <4660165A.76E3.003F.0@danishmeat.dk>

En indlejret tekst med ukendt tegns?t er blevet fjernet...
Navn: ikke tilg?ngelig
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070601/9da16c9f/attachment.pl 

From lterlemez at anadolu.edu.tr  Fri Jun  1 12:52:20 2007
From: lterlemez at anadolu.edu.tr (Levent TERLEMEZ)
Date: Fri, 01 Jun 2007 13:52:20 +0300
Subject: [R] Font size of the plot...
Message-ID: <465FFA64.3060907@anadolu.edu.tr>

Dear R Users,

I would like reduce font size of the plots of my fanny result, but I 
count not. Is there a way to make changes on font sizes?

Thanks.


From ggrothendieck at gmail.com  Fri Jun  1 13:00:34 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 1 Jun 2007 07:00:34 -0400
Subject: [R] zoo matrix manipulation
In-Reply-To: <465FF368.9070001@gmail.com>
References: <465FF368.9070001@gmail.com>
Message-ID: <971536df0706010400l1931f6cex5edbc4a4340153f3@mail.gmail.com>

I think nearly this same question was just asked by someone within
the last few days:

Anyways, this multiplies gd by 10 and then places it back into the
original columns:

z[, -out] <- 10*gd


On 6/1/07, antonio rodriguez <antonio.raju at gmail.com> wrote:
> Hi,
>
> I have this dataset where columns z1.3 and z1.4 are full of NA's. I want
> to perform some calculations in the remaining columns, but after doing
> this, I want to recontruct the original matrix. I can with:
>
> out <- which( colMeans( is.na( z ) ) == 1 )
> gd<-z[, - out]
>
> select the columns full of NA's and those without that pattern. Then
> after doing the calculus I need to reconstruct z as it was in its origin
> (z1.1,z1.2,...,z1.6)
>
> BTW:The z matrix is a zoo object
>
> Thanks,
>
> Antonio
>
>  > dput(z,control="all")
> structure(c(16.7250003814697, 16.5, 16.6875, 15.8999996185303,
> 16.0500001907349, 16.2000007629395, 16.5, 16.2000007629395,
> 15.8999996185303,
> 16.3499984741211, 16.2749996185303, 16.875, 16.875, 15.8999996185303,
> 15.8999996185303, 16.9500007629395, 17.4375, 18.1124992370605,
> 19.0499992370605, 16.7250003814697, 16.5, 16.7249984741211,
> 15.8999996185303,
> 15.8999996185303, 15.8999996185303, 16.4249992370605, 16.0499992370605,
> 16.2000007629395, 16.3499984741211, 15.8625001907349, 17.0249996185303,
> 16.7999992370605, 16.2000007629395, 16.2000007629395, 16.875,
> 17.4750003814697, 18.2249984741211, 19.0499992370605, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, 16.7250003814697, 16.5750007629395, 16.5, 15.6750001907349,
> 15.9749999046326, 16.2749996185303, 16.6499996185303, 16.2749996185303,
> 16.1625003814697, 16.2374992370605, 16.2749996185303, 17.0249996185303,
> 16.7250003814697, 16.5750007629395, 16.8500003814697, 16.7999992370605,
> 17.7374992370605, 18.2250003814697, 18.75, 16.6124992370605,
> 16.3875007629395, 16.59375, 15.6000003814697, 15.9000005722046,
> 16.2000007629395, 16.5750007629395, 16.1437511444092, 16.0125007629395,
> 16.2937507629395, 16.1999988555908, 16.875, 16.6312503814697,
> 16.7999992370605, 17.1749992370605, 16.9500007629395, 17.7999992370605,
> 18.1687507629395, 18.75, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA), .Dim = as.integer(c(19,
> 6)), .Dimnames = list(NULL, c("z1.1", "z1.2", "z1.3", "z1.4",
> "z1.5", "z1.6")), index = structure(c(5491, 5499, 5507, 5515,
> 5523, 5531, 5539, 5547, 5555, 5563, 5571, 5579, 5587, 5595, 5603,
> 5611, 5619, 5627, 5635), class = "Date"), class = "zoo")
>
>
>
>
> --
> =====
> Por favor, si me mandas correos con copia a varias personas,
> pon mi direcci?n de correo en copia oculta (CCO), para evitar
> que acabe en montones de sitios, eliminando mi privacidad,
> favoreciendo la propagaci?n de virus y la proliferaci?n del SPAM. Gracias.
> -----
> If you send me e-mail which has also been sent to several other people,
> kindly mark my address as blind-carbon-copy (or BCC), to avoid its
> distribution, which affects my privacy, increases the likelihood of
> spreading viruses, and leads to more SPAM. Thanks.
> =====
> Antes de imprimir este e-mail piense bien si es necesario hacerlo: El medioambiente es cosa de todos.
> Before printing this email, assess if it is really needed.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From yn19832 at msn.com  Fri Jun  1 13:00:50 2007
From: yn19832 at msn.com (livia)
Date: Fri, 1 Jun 2007 04:00:50 -0700 (PDT)
Subject: [R] tapply
Message-ID: <10910748.post@talk.nabble.com>


Hello, I want to conduct normality test to a series of data and get the
p-value for each subset. I am using the following codes, but it does not
work.

tapply(re, list(reg, ast), pvalue(shapiro.test))

Could anyone give me some advice? Many thanks.
-- 
View this message in context: http://www.nabble.com/tapply-tf3851631.html#a10910748
Sent from the R help mailing list archive at Nabble.com.


From labone at gforcecable.com  Fri Jun  1 13:00:47 2007
From: labone at gforcecable.com (Tom La Bone)
Date: Fri, 1 Jun 2007 07:00:47 -0400
Subject: [R] Problem with Weighted Variance in Hmisc
In-Reply-To: <1412498F-08C7-4684-8E02-A3F7AE7C43FD@gmail.com>
Message-ID: <000001c7a43c$1bfb8550$6401a8c0@Boozoo>

Thanks.  I have another related question:  

The equation for weighted variance given in the NIST DataPlot documentation
is the usual variance equation with the weights inserted.  The weighted
variance of the weighted mean is this weighted variance divided by N.

There is another approach to calculating the weighted variance of the
weighted mean that propagates the uncertainty of each term in the weighted
mean (see Data Reduction and Error Analysis for the Physical Sciences by
Bevington & Robinson).  The two approaches do not give the same answer. Can
anyone suggest a reference that discusses the merits of the DataPlot
approach versus the Bevington approach?

Tom La Bone

-----Original Message-----
From: jiho [mailto:jo.irisson at gmail.com] 
Sent: Friday, June 01, 2007 2:17 AM
To: labone at gforcecable.com; R-help
Subject: Re: [R] Problem with Weighted Variance in Hmisc

On 2007-June-01  , at 01:03 , Tom La Bone wrote:
> The function wtd.var(x,w) in Hmisc calculates the weighted variance  
> of x
> where w are the weights.  It appears to me that wtd.var(x,w) = var 
> (x) if all
> of the weights are equal, but this does not appear to be the case. Can
> someone point out to me where I am going wrong here?  Thanks.

The true formula of weighted variance is this one:
	http://www.itl.nist.gov/div898/software/dataplot/refman2/ch2/ 
weighvar.pdf
But for computation purposes, wtd.var uses another definition which  
considers the weights as repeats instead of true weights. However if  
the weights are normalized (sum to one) to two formulas are equal. If  
you consider weights as real weights instead of repeats, I would  
recommend to use this option.
With normwt=T, your issue is solved:

 > a=1:10
 > b=a
 > b[]=2
 > b
[1] 2 2 2 2 2 2 2 2 2 2
 > wtd.var(a,b)
[1] 8.68421
# all weights equal 2 <=> there are two repeats of each element of a
 > var(c(a,a))
[1] 8.68421
 > wtd.var(a,b,normwt=T)
[1] 9.166667
 > var(a)
[1] 9.166667

Cheers,

JiHO
---
http://jo.irisson.free.fr/


From patrick.haurie at sap.ap-hop-paris.fr  Fri Jun  1 13:18:25 2007
From: patrick.haurie at sap.ap-hop-paris.fr (Patrick Haurie)
Date: Fri, 01 Jun 2007 13:18:25 +0200
Subject: [R] TS or citrix with R?
Message-ID: <!&!AAAAAAAAAAAYAAAAAAAAAIXjF32q/tQRj0QAEFqyY0rCgAAAEAAAAHkItvg7FxRMmyi69qdZ//gBAAAAAA==@sap.ap-hop-paris.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070601/10132f34/attachment.pl 

From ggrothendieck at gmail.com  Fri Jun  1 13:23:38 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 1 Jun 2007 07:23:38 -0400
Subject: [R] aggregate in zoo
In-Reply-To: <000d01c7a401$67c9f600$0300a8c0@Vaio>
References: <000d01c7a401$67c9f600$0300a8c0@Vaio>
Message-ID: <971536df0706010423g68519883h89faefa611cf80ed@mail.gmail.com>

On 6/1/07, Alfonso Sammassimo <cincinattikid at bigpond.com> wrote:
> Hi R-experts,
>
> Thanks very much to Jim Holtman and Gabor on my previous question.
>
> I am having another problem with data manipulation in zoo. The following is
> data (Z) for first business day of every month in zoo format. I am trying to
> get mean of "open" for each year. I subset Z <- Z[,2] then
>
> > sapply(split(Z, format(index(Z), "%Y")),mean)
>
> I get error message:
>
> >2000 2001 2002 2003 2004 2005 2006 2007
>  NA   NA   NA   NA   NA   NA   NA   NA
> Warning messages:
> 1: argument is not numeric or logical: returning NA in: mean.default(X[[1]],
> ...)
> 2: argument is not numeric or logical: returning NA in: mean.default(X[[2]],
> ...)
> etc...................
>
> Any help on what I'm missing would be appreciated. I am particularly
> confused by the fact that the command used works fine on the original data
> file (i.e. before subsetting by first day of month). Sorry if I have
> overlooked something very simple.
>
> <Z
>                 dayofmonth    open
> 2000-02-01 01        1636.10
> 2000-03-01 01        1596.75
> 2000-04-03 03        1737.70
> 2000-05-01 01        1695.65
> 2000-06-01 01        1651.90
> 2000-07-03 03        1669.20
> 2000-08-01 01        1628.35
> 2000-09-01 01        1717.35
> 2000-10-02 02        1614.55
> 2000-11-01 01        1587.10
> 2000-12-01 01        1475.60
> 2001-01-02 02        1450.65
> 2001-02-01 01        1503.60
> 2001-03-01 01        1351.95
> 2001-04-02 02        1268.10
> 2001-05-01 01        1369.20
> 2001-06-01 01        1362.75
> 2001-07-02 02        1331.55
> 2001-08-01 01        1309.70
> 2001-09-04 04        1235.55
> 2001-10-01 01        1109.20
> 2001-11-01 01        1155.55
> 2001-12-03 03        1207.30



Can't tell what your Z really looks like,
try posting dput(Z) or explain how to create
Z from scratch, but at any rate your code has two
problems:

1. the result is not a zoo object (that may or may not be a problem)
2. your are combining the two columns altogether
and then taking the mean of that

Try copying and pasting this into your
session:

Lines <- "date dayofmonth    open
2000-02-01 01        1636.10
2000-03-01 01        1596.75
2000-04-03 03        1737.70
2000-05-01 01        1695.65
2000-06-01 01        1651.90
2000-07-03 03        1669.20
2000-08-01 01        1628.35
2000-09-01 01        1717.35
2000-10-02 02        1614.55
2000-11-01 01        1587.10
2000-12-01 01        1475.60
2001-01-02 02        1450.65
2001-02-01 01        1503.60
2001-03-01 01        1351.95
2001-04-02 02        1268.10
2001-05-01 01        1369.20
2001-06-01 01        1362.75
2001-07-02 02        1331.55
2001-08-01 01        1309.70
2001-09-04 04        1235.55
2001-10-01 01        1109.20
2001-11-01 01        1155.55
2001-12-03 03        1207.30
"
library(zoo)
z <- read.zoo(textConnection(Lines), header = TRUE)
year <- function(x) as.numeric(format(x, "%Y"))

sapply(split(z[,2], year(index(z))), mean)

# last line could be replaced with just this
aggregate(z[,2], year, mean)


From M.J.Bojanowski at uu.nl  Fri Jun  1 13:27:46 2007
From: M.J.Bojanowski at uu.nl (Bojanowski, M.J.  (Michal))
Date: Fri, 1 Jun 2007 13:27:46 +0200
Subject: [R] tapply
In-Reply-To: <10910748.post@talk.nabble.com>
References: <10910748.post@talk.nabble.com>
Message-ID: <94E133D09AA24D43BF6341B675C01A33A4F556@uu01msg-exb01.soliscom.uu.nl>

I'm not sure what is the 'pvalue' function (it's not found in base nor
stats packages) but
this should give you what you want:

# some example
re <- rnorm(100)
reg <- rep(1:3, length=100)
ast <- rep(1:2, length=100)

tapply( re, list(reg, ast), function(v) shapiro.test(v)$p.value )

# or neater by defining a function
p.shapiro <- function(v) shapiro.test(v)$p.value
tapply( re, list(reg, ast), p.shapiro )



hth,

michal

> Hello, I want to conduct normality test to a series of data 
> and get the
> p-value for each subset. I am using the following codes, but 
> it does not
> work.
> 
> tapply(re, list(reg, ast), pvalue(shapiro.test))
> 
> Could anyone give me some advice? Many thanks.


From dimitris.rizopoulos at med.kuleuven.be  Fri Jun  1 13:33:08 2007
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Fri, 1 Jun 2007 13:33:08 +0200
Subject: [R] tapply
References: <10910748.post@talk.nabble.com>
Message-ID: <00d601c7a440$a0f213b0$0540210a@www.domain>

try this:

tapply(re, list(reg, ast), function(x) shapiro.test(x)$p.value)


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "livia" <yn19832 at msn.com>
To: <r-help at stat.math.ethz.ch>
Sent: Friday, June 01, 2007 1:00 PM
Subject: [R] tapply


>
> Hello, I want to conduct normality test to a series of data and get 
> the
> p-value for each subset. I am using the following codes, but it does 
> not
> work.
>
> tapply(re, list(reg, ast), pvalue(shapiro.test))
>
> Could anyone give me some advice? Many thanks.
> -- 
> View this message in context: 
> http://www.nabble.com/tapply-tf3851631.html#a10910748
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm


From ggrothendieck at gmail.com  Fri Jun  1 13:36:52 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 1 Jun 2007 07:36:52 -0400
Subject: [R] time serie generation
In-Reply-To: <OF83B7A903.0DF9C68C-ONC12572ED.003BA76C-C12572ED.003BA77F@tudor.lu>
References: <OF83B7A903.0DF9C68C-ONC12572ED.003BA76C-C12572ED.003BA77F@tudor.lu>
Message-ID: <971536df0706010436g1d05d4c6xe8b62fbb7e286ee3@mail.gmail.com>

library(chron)
dt1 <- chron("1/1/2002", "00:00:00")
dt2 <- chron("1/2/2002", "00:00:00")
chron(seq(as.numeric(dt1), as.numeric(dt2), by = 1/24))

Also (but see caveat in R News 4/1 help desk article):

dt1 <- as.POSIXct("2002-01-01 00:00:00")
dt2 <- as.POSIXct("2002-01-02 00:00:00")
seq(dt1, dt2, by = "hour")



On 6/1/07, jessica.gervais at tudor.lu <jessica.gervais at tudor.lu> wrote:
>
> Dear all,
>
> I would like to generate a regular time serie, i.e. a list of dates and
> time for each our of the period 2002-2004.
>
> the time format should be
> "2002-01-01 12:00:00" (year-month-day hour:min:sec)
>
>
> so the list should contain all hours of the period 2002-2004
> 2002-01-01 00:00:00
> 2002-01-01 01:00:00
> 2002-01-01 02:00:00
> ...
> 2004-12-31 23:00:00
> Does a function exist to create that kind of list ?
>
> Thanks in advance,
>
>
> Jessica
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ripley at stats.ox.ac.uk  Fri Jun  1 13:44:51 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 1 Jun 2007 12:44:51 +0100 (BST)
Subject: [R] TS or citrix with R?
In-Reply-To: <!&!AAAAAAAAAAAYAAAAAAAAAIXjF32q/tQRj0QAEFqyY0rCgAAAEAAAAHkItvg7FxRMmyi69qdZ//gBAAAAAA==@sap.ap-hop-paris.fr>
References: <!&!AAAAAAAAAAAYAAAAAAAAAIXjF32q/tQRj0QAEFqyY0rCgAAAEAAAAHkItvg7FxRMmyi69qdZ//gBAAAAAA==@sap.ap-hop-paris.fr>
Message-ID: <Pine.LNX.4.64.0706011243090.29873@gannet.stats.ox.ac.uk>

It certainly runs under Windows terminal services.  Since it is just a 
standard Windows application I see not reason why it should not run under 
Citrix, but have no first-hand experience.


On Fri, 1 Jun 2007, Patrick Haurie wrote:

> Hi,
>
> Does R runs under citrix version 4 environnement or terminal services?
>
>
> Regards
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From M.J.Bojanowski at uu.nl  Fri Jun  1 13:58:43 2007
From: M.J.Bojanowski at uu.nl (Bojanowski, M.J.  (Michal))
Date: Fri, 1 Jun 2007 13:58:43 +0200
Subject: [R] random effects in lmer
In-Reply-To: <4660165A.76E3.003F.0@danishmeat.dk>
References: <4660165A.76E3.003F.0@danishmeat.dk>
Message-ID: <94E133D09AA24D43BF6341B675C01A33A4F557@uu01msg-exb01.soliscom.uu.nl>

Look here for the answer:
https://stat.ethz.ch/pipermail/r-help/2006-May/094765.html

:
::
::: Note that my e-mail address has changed to m.j.bojanowski at uu dot
nl
::: Please update you address books accordingly. Thank you!
::
:


____________________________________
Michal Bojanowski
ICS / Department of Sociology
Utrecht University
Heidelberglaan 2; 3584 CS Utrecht
Room 1428
m.j.bojanowski at uu dot nl
http://www.fss.uu.nl/soc/bojanowski/ 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Rina Miehs
> Sent: Friday, June 01, 2007 12:52 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] random effects in lmer
> 
> Hello
>  
> i have a model with two random effects. i have used lmer 
> (package lme4)
> on the model. To find the predictions of the random effects used
> ranef(). How can i get p-values on theese predictions??
>  
> Thanks
>  
> Rina
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From rmi at danishmeat.dk  Fri Jun  1 13:58:43 2007
From: rmi at danishmeat.dk (Rina Miehs)
Date: Fri, 01 Jun 2007 13:58:43 +0200
Subject: [R] random effects in lmer
Message-ID: <46602612.76E3.003F.0@danishmeat.dk>

En indlejret tekst med ukendt tegns?t er blevet fjernet...
Navn: ikke tilg?ngelig
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070601/4548baf4/attachment.pl 

From Achim.Zeileis at wu-wien.ac.at  Fri Jun  1 14:02:53 2007
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Fri, 1 Jun 2007 14:02:53 +0200
Subject: [R] time serie generation
In-Reply-To: <OF83B7A903.0DF9C68C-ONC12572ED.003BA76C-C12572ED.003BA77F@tudor.lu>
References: <OF83B7A903.0DF9C68C-ONC12572ED.003BA76C-C12572ED.003BA77F@tudor.lu>
Message-ID: <20070601140253.32db798f.Achim.Zeileis@wu-wien.ac.at>

On Fri, 1 Jun 2007 12:51:35 +0200 jessica.gervais at tudor.lu wrote:

> 
> Dear all,
> 
> I would like to generate a regular time serie, i.e. a list of dates
> and time for each our of the period 2002-2004.

use the seq() method for "POSIXct" objects:

seq(from = as.POSIXct("2002-01-01 00:00:00"),
    to = as.POSIXct("2004-12-31 23:00:00"),
    by = "hour")

hth,
Z

> the time format should be
> "2002-01-01 12:00:00" (year-month-day hour:min:sec)
> 
> 
> so the list should contain all hours of the period 2002-2004
> 2002-01-01 00:00:00
> 2002-01-01 01:00:00
> 2002-01-01 02:00:00
> ...
> 2004-12-31 23:00:00
> Does a function exist to create that kind of list ?
> 
> Thanks in advance,
> 
> 
> Jessica
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.
>


From f.harrell at vanderbilt.edu  Fri Jun  1 14:11:50 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Fri, 01 Jun 2007 07:11:50 -0500
Subject: [R] Problem with Weighted Variance in Hmisc
In-Reply-To: <1412498F-08C7-4684-8E02-A3F7AE7C43FD@gmail.com>
References: <000701c7a3d7$eac58da0$6401a8c0@Boozoo>
	<1412498F-08C7-4684-8E02-A3F7AE7C43FD@gmail.com>
Message-ID: <46600D06.7060008@vanderbilt.edu>

jiho wrote:
> On 2007-June-01  , at 01:03 , Tom La Bone wrote:
>> The function wtd.var(x,w) in Hmisc calculates the weighted variance  
>> of x
>> where w are the weights.  It appears to me that wtd.var(x,w) = var 
>> (x) if all
>> of the weights are equal, but this does not appear to be the case. Can
>> someone point out to me where I am going wrong here?  Thanks.
> 
> The true formula of weighted variance is this one:
> 	http://www.itl.nist.gov/div898/software/dataplot/refman2/ch2/ 
> weighvar.pdf
> But for computation purposes, wtd.var uses another definition which  
> considers the weights as repeats instead of true weights. However if  
> the weights are normalized (sum to one) to two formulas are equal. If  
> you consider weights as real weights instead of repeats, I would  
> recommend to use this option.
> With normwt=T, your issue is solved:
> 
>  > a=1:10
>  > b=a
>  > b[]=2
>  > b
> [1] 2 2 2 2 2 2 2 2 2 2
>  > wtd.var(a,b)
> [1] 8.68421
> # all weights equal 2 <=> there are two repeats of each element of a
>  > var(c(a,a))
> [1] 8.68421
>  > wtd.var(a,b,normwt=T)
> [1] 9.166667
>  > var(a)
> [1] 9.166667
> 
> Cheers,
> 
> JiHO

The issue is what is being assumed for N in the denominator of the 
variance formula, since the unbiased estimator subtracts one.  Using 
normwt=TRUE means you are in effect assuming N is the number of elements 
in the data vector, ignoring the weights.

Frank Harrell

> ---
> http://jo.irisson.free.fr/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From jo.irisson at gmail.com  Fri Jun  1 14:17:22 2007
From: jo.irisson at gmail.com (jiho)
Date: Fri, 1 Jun 2007 14:17:22 +0200
Subject: [R] Problem with Weighted Variance in Hmisc
In-Reply-To: <000001c7a43c$1bfb8550$6401a8c0@Boozoo>
References: <000001c7a43c$1bfb8550$6401a8c0@Boozoo>
Message-ID: <8D05C467-9A79-40E3-94CE-04166D791095@gmail.com>

On 2007-June-01  , at 13:00 , Tom La Bone wrote:
> The equation for weighted variance given in the NIST DataPlot  
> documentation
> is the usual variance equation with the weights inserted.  The  
> weighted
> variance of the weighted mean is this weighted variance divided by N.
>
> There is another approach to calculating the weighted variance of the
> weighted mean that propagates the uncertainty of each term in the  
> weighted
> mean (see Data Reduction and Error Analysis for the Physical  
> Sciences by
> Bevington & Robinson).  The two approaches do not give the same  
> answer. Can
> anyone suggest a reference that discusses the merits of the DataPlot
> approach versus the Bevington approach?

I am no expert but I did a little research on the subject and it  
seems there is no analytical equivalent to the standard error of the  
mean in weighted statistics (i.e. there is no standard error/variance  
of the weighted mean). That's why you find so many formulas: they are  
all numerical approximations that make more of less sense. If you  
have access to DcienceDirect there is a paper which compares 3 of  
those analytical approximations to the variance estimated by bootstrap:

@article{Gatz1995AE,
	Author = {Gatz, Donald F and Smith, Luther},
	Date-Added = {2007-05-19 14:15:58 +0200},
	Date-Modified = {2007-06-01 14:12:17 +0200},
	Filed = {Yes},
	Journal = {Atmospheric Environment},
	Number = {11},
	Pages = {1185--1193},
	Rating = {0},
	Title = {The standard error of a weighted mean concentration--I.  
Bootstrapping vs other methods},
	Url = {http://www.sciencedirect.com/science/article/B6VH3-3YGV47C-6X/ 
2/18b627259a75ff9b765410aaa231e352},
	Volume = {29},
	Year = {1995},
	Abstract = {Concentrations of chemical constituents of precipitation  
are frequently expressed in terms of the precipitation-weighted mean,  
which has several desirable properties. Unfortunately, the weighted  
mean has no analytical analog of the standard error of the arithmetic  
mean for use in characterizing its statistical uncertainty. Several  
approximate expressions have been used previously in the literature,  
but there is no consensus as to which is best. This paper compares  
three methods from the literature with a standard based on  
bootstrapping. Comparative calculations were carried out for nine  
major ions measured at 222 sampling sites in the National Atmospheric  
Deposition/National Trends Network (NADP/NTN). The ratio variance  
approximation of Cochran (1977) gave results that were not  
statistically different from those of bootstrapping, and is suggested  
as the method of choice for routine computing of the standard error  
of the weighted mean. The bootstrap method has advantages of its own,  
including the fact that it is nonparametric, but requires additional  
effort and computation time.}}

The analytical formula which is the closest to the bootstrap  is this  
one:

var.wtd.mean.cochran <- function(x,w)
#
#	Computes the variance of a weighted mean following Cochran 1977  
definition
#
{
	n = length(w)
	xWbar = wtd.mean(x,w)
	wbar = mean(w)
	out = n/((n-1)*sum(w)^2)*(sum((w*x-wbar*xWbar)^2)-2*xWbar*sum((w- 
wbar)*(w*x-wbar*xWbar))+xWbar^2*sum((w-wbar)^2))
	return(out)
}

It's the one I am retaining.

NB: the part two of the paper cited above may also interest you:

@article{Gatz1995AEa,
	Author = {Gatz, Donald F and Smith, Luther},
	Date-Added = {2007-05-19 14:15:58 +0200},
	Date-Modified = {2007-06-01 12:11:53 +0200},
	Filed = {Yes},
	Journal = {Atmospheric Environment},
	Number = {11},
	Pages = {1195--1200},
	Title = {The standard error of a weighted mean concentration--II.  
Estimating confidence intervals},
	Url = {http://www.sciencedirect.com/science/article/B6VH3-3YGV47C-6Y/ 
2/a187487377ef52b741e3dabdfca97517},
	Volume = {29},
	Year = {1995},
	Abstract = {One motivation for estimating the standard error, SEMw,  
of a weighted mean concentration, Mw, of an ion in precipitation is  
to use it to compute a confidence interval for Mw. Typically this is  
done by multiplying the standard error by a factor that depends on  
the degree of confidence one wishes to express, on the assumption  
that the weighted mean has a normal distribution. This paper compares  
confidence intervals of Mw concentrations of ions in precipitation,  
as computed using the assumption of a normal distribution, with those  
estimated from distributions produced by bootstrapping. The  
hypothesis that Mw was normally distributed was rejected about half  
the time (at the 5{\%} significance level) in tests involving nine  
major ions measured at ten diverse sites in the National Atmospheric  
Deposition Program/National Trends Network (NADP/NTN). Most of these  
rejections occurred at sites with fewer than 100 samples, in  
agreement with previous results. Nevertheless, the hypothesis was  
often rejected at sites with more than 100 samples as well. The  
maximum error (relative to Mw) in the 95{\%} confidence limits made  
by assuming a normal distribution of the Mw at the ten sites examined  
was about 27{\%}. Most such errors were less than 10{\%}, and errors  
were smaller at sampling sites with > 100 samples than at those with  
< 100 samples.}}

Cheers,

JiHO
---
http://jo.irisson.free.fr/


From HDoran at air.org  Fri Jun  1 14:19:22 2007
From: HDoran at air.org (Doran, Harold)
Date: Fri, 1 Jun 2007 08:19:22 -0400
Subject: [R] random effects in lmer
References: <46602612.76E3.003F.0@danishmeat.dk>
Message-ID: <2323A6D37908A847A7C32F1E3662C80EB5E681@dc1ex01.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070601/0d960d0b/attachment.pl 

From ggrothendieck at gmail.com  Fri Jun  1 14:21:51 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 1 Jun 2007 08:21:51 -0400
Subject: [R] Getting names of objects passed with "..."
In-Reply-To: <10906614.post@talk.nabble.com>
References: <10906614.post@talk.nabble.com>
Message-ID: <971536df0706010521n65cbfccaqbf18d6f978f71e5b@mail.gmail.com>

See:
http://tolstoy.newcastle.edu.au/R/e2/help/06/10/2242.html
which we can modify slightly for the case in question like this:

f <- function(...) {
	x <- list(...)
	if (is.null(names(x))) names(x) <- ""
	names(x)[names(x) == ""] <- NA
	mc <- match.call()[-1]
	ifelse(is.na(names(x)), as.character(mc), names(x))
}
f(a = mean) # a
f(F = function(x)x) # F
f(a = mean, b = sd) # c("a", "b")
f(cos, sin) # c("cos", "sin")
f(a = cos, sin) # c("a", "sin")


On 6/1/07, Mike Meredith <mmeredith at wcs.org> wrote:
>
> Is there a tidy way to get the names of objects passed to a function via the
> "..." argument?
>
> rbind/cbind does what I want:
>
> test.func1 <- function(...) {
>   nms <- rownames(rbind(..., deparse.level=1))
>   print(nms)
> }
>
> x <- "some stuff"
> second <- "more stuff"
> test.func1(first=x, second)
> [1] "first"  "second"
>
> The usual 'deparse(substitute())' doesn't do it:
>
> test.func2 <- function(...) {
>   nms <- deparse(substitute(...))
>   print(nms)
> }
> test.func2(first=x, second)
> [1] "x"
>
> I'm using "nms <- rownames(rbind(...))" as a workaround, which works, but
> there must be a neater way!
>
> rbind/cbind are .Internal, so I can't pinch code from there.
>
> Thanks,  Mike.
>
> --
> View this message in context: http://www.nabble.com/Getting-names-of-objects-passed-with-%22...%22-tf3850318.html#a10906614
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From labone at gforcecable.com  Fri Jun  1 14:29:00 2007
From: labone at gforcecable.com (Tom La Bone)
Date: Fri, 1 Jun 2007 08:29:00 -0400
Subject: [R] Problem with Weighted Variance in Hmisc
In-Reply-To: <8D05C467-9A79-40E3-94CE-04166D791095@gmail.com>
Message-ID: <001601c7a448$6ed40de0$6401a8c0@Boozoo>

Wonderful!  Thanks for the assistance.

Tom La Bone


-----Original Message-----
From: jiho [mailto:jo.irisson at gmail.com] 
Sent: Friday, June 01, 2007 8:17 AM
To: labone at gforcecable.com
Cc: 'R-help'
Subject: Re: [R] Problem with Weighted Variance in Hmisc

On 2007-June-01  , at 13:00 , Tom La Bone wrote:
> The equation for weighted variance given in the NIST DataPlot  
> documentation
> is the usual variance equation with the weights inserted.  The  
> weighted
> variance of the weighted mean is this weighted variance divided by N.
>
> There is another approach to calculating the weighted variance of the
> weighted mean that propagates the uncertainty of each term in the  
> weighted
> mean (see Data Reduction and Error Analysis for the Physical  
> Sciences by
> Bevington & Robinson).  The two approaches do not give the same  
> answer. Can
> anyone suggest a reference that discusses the merits of the DataPlot
> approach versus the Bevington approach?

I am no expert but I did a little research on the subject and it  
seems there is no analytical equivalent to the standard error of the  
mean in weighted statistics (i.e. there is no standard error/variance  
of the weighted mean). That's why you find so many formulas: they are  
all numerical approximations that make more of less sense. If you  
have access to DcienceDirect there is a paper which compares 3 of  
those analytical approximations to the variance estimated by bootstrap:

@article{Gatz1995AE,
	Author = {Gatz, Donald F and Smith, Luther},
	Date-Added = {2007-05-19 14:15:58 +0200},
	Date-Modified = {2007-06-01 14:12:17 +0200},
	Filed = {Yes},
	Journal = {Atmospheric Environment},
	Number = {11},
	Pages = {1185--1193},
	Rating = {0},
	Title = {The standard error of a weighted mean concentration--I.  
Bootstrapping vs other methods},
	Url =
{http://www.sciencedirect.com/science/article/B6VH3-3YGV47C-6X/ 
2/18b627259a75ff9b765410aaa231e352},
	Volume = {29},
	Year = {1995},
	Abstract = {Concentrations of chemical constituents of precipitation

are frequently expressed in terms of the precipitation-weighted mean,  
which has several desirable properties. Unfortunately, the weighted  
mean has no analytical analog of the standard error of the arithmetic  
mean for use in characterizing its statistical uncertainty. Several  
approximate expressions have been used previously in the literature,  
but there is no consensus as to which is best. This paper compares  
three methods from the literature with a standard based on  
bootstrapping. Comparative calculations were carried out for nine  
major ions measured at 222 sampling sites in the National Atmospheric  
Deposition/National Trends Network (NADP/NTN). The ratio variance  
approximation of Cochran (1977) gave results that were not  
statistically different from those of bootstrapping, and is suggested  
as the method of choice for routine computing of the standard error  
of the weighted mean. The bootstrap method has advantages of its own,  
including the fact that it is nonparametric, but requires additional  
effort and computation time.}}

The analytical formula which is the closest to the bootstrap  is this  
one:

var.wtd.mean.cochran <- function(x,w)
#
#	Computes the variance of a weighted mean following Cochran 1977  
definition
#
{
	n = length(w)
	xWbar = wtd.mean(x,w)
	wbar = mean(w)
	out = n/((n-1)*sum(w)^2)*(sum((w*x-wbar*xWbar)^2)-2*xWbar*sum((w- 
wbar)*(w*x-wbar*xWbar))+xWbar^2*sum((w-wbar)^2))
	return(out)
}

It's the one I am retaining.

NB: the part two of the paper cited above may also interest you:

@article{Gatz1995AEa,
	Author = {Gatz, Donald F and Smith, Luther},
	Date-Added = {2007-05-19 14:15:58 +0200},
	Date-Modified = {2007-06-01 12:11:53 +0200},
	Filed = {Yes},
	Journal = {Atmospheric Environment},
	Number = {11},
	Pages = {1195--1200},
	Title = {The standard error of a weighted mean concentration--II.  
Estimating confidence intervals},
	Url =
{http://www.sciencedirect.com/science/article/B6VH3-3YGV47C-6Y/ 
2/a187487377ef52b741e3dabdfca97517},
	Volume = {29},
	Year = {1995},
	Abstract = {One motivation for estimating the standard error, SEMw,

of a weighted mean concentration, Mw, of an ion in precipitation is  
to use it to compute a confidence interval for Mw. Typically this is  
done by multiplying the standard error by a factor that depends on  
the degree of confidence one wishes to express, on the assumption  
that the weighted mean has a normal distribution. This paper compares  
confidence intervals of Mw concentrations of ions in precipitation,  
as computed using the assumption of a normal distribution, with those  
estimated from distributions produced by bootstrapping. The  
hypothesis that Mw was normally distributed was rejected about half  
the time (at the 5{\%} significance level) in tests involving nine  
major ions measured at ten diverse sites in the National Atmospheric  
Deposition Program/National Trends Network (NADP/NTN). Most of these  
rejections occurred at sites with fewer than 100 samples, in  
agreement with previous results. Nevertheless, the hypothesis was  
often rejected at sites with more than 100 samples as well. The  
maximum error (relative to Mw) in the 95{\%} confidence limits made  
by assuming a normal distribution of the Mw at the ten sites examined  
was about 27{\%}. Most such errors were less than 10{\%}, and errors  
were smaller at sampling sites with > 100 samples than at those with  
< 100 samples.}}

Cheers,

JiHO
---
http://jo.irisson.free.fr/


From kevin.thorpe at utoronto.ca  Fri Jun  1 14:48:33 2007
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Fri, 01 Jun 2007 08:48:33 -0400
Subject: [R] Logrank test
In-Reply-To: <10910383.post@talk.nabble.com>
References: <10910383.post@talk.nabble.com>
Message-ID: <466015A1.8040904@utoronto.ca>

See ?survdiff in the survival package.


Mbini wrote:
> Hi 
> 
> I have a problem with computing the logrank test using R, can someone give
> me the relavent code or help me otherwise please!
> 
> Thanks


-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Department of Public Health Sciences
Faculty of Medicine, University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.6057


From yn19832 at msn.com  Fri Jun  1 15:00:19 2007
From: yn19832 at msn.com (livia)
Date: Fri, 1 Jun 2007 06:00:19 -0700 (PDT)
Subject: [R] tapply histogram
Message-ID: <10912441.post@talk.nabble.com>


Dear members,

I would like to pass the histogram settings to each subset of the dataframe,
and generate a multiple figures graph.

First, can anyone tell me how to generate a multiple figures environment? I
am trying 

mfrow=c(2,4) and nothing appears.

Secondly, I want to pass the following function in tapply()

hist(x, freq=FALSE)
lines(density(x), col="red")
rug(x)

how can I manage it?

Many thanks

-- 
View this message in context: http://www.nabble.com/tapply-histogram-tf3852186.html#a10912441
Sent from the R help mailing list archive at Nabble.com.


From aiminy at iastate.edu  Fri Jun  1 15:32:18 2007
From: aiminy at iastate.edu (Aimin Yan)
Date: Fri, 01 Jun 2007 08:32:18 -0500
Subject: [R] tapply histogram
In-Reply-To: <10912441.post@talk.nabble.com>
References: <10912441.post@talk.nabble.com>
Message-ID: <6.2.1.2.2.20070601083136.034ae980@aiminy.mail.iastate.edu>

use lattice graph


At 08:00 AM 6/1/2007, livia wrote:

>Dear members,
>
>I would like to pass the histogram settings to each subset of the dataframe,
>and generate a multiple figures graph.
>
>First, can anyone tell me how to generate a multiple figures environment? I
>am trying
>
>mfrow=c(2,4) and nothing appears.
>
>Secondly, I want to pass the following function in tapply()
>
>hist(x, freq=FALSE)
>lines(density(x), col="red")
>rug(x)
>
>how can I manage it?
>
>Many thanks
>
>--
>View this message in context: 
>http://www.nabble.com/tapply-histogram-tf3852186.html#a10912441
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Fri Jun  1 15:34:27 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 1 Jun 2007 14:34:27 +0100 (BST)
Subject: [R] Getting names of objects passed with "..."
In-Reply-To: <10910245.post@talk.nabble.com>
References: <10906614.post@talk.nabble.com>
	<59d7961d0706010158t5f1ff661r51c5675edefd4cb8@mail.gmail.com>
	<Pine.LNX.4.64.0706011007550.25961@gannet.stats.ox.ac.uk>
	<10910245.post@talk.nabble.com>
Message-ID: <Pine.LNX.4.64.0706011431460.2100@gannet.stats.ox.ac.uk>

How about

foo <- function(...)
{
    m <- as.list(match.call(expand.dots=TRUE))[-1]
    nm <- names(m)
    for(i in seq_along(m)) if(!nchar(nm[i])) nm[i] <- deparse(m[[i]])
    nm
}

Such things are hard to do from R level, hence the use of match.call to do 
it at C level.

On Fri, 1 Jun 2007, Mike Meredith wrote:

>
>
> Thanks, Henrik, but 'foo' doesn't do what I want:
>
> x <- "some stuff"
> second <- "more stuff"
>
> foo(first=x, second)
> [1] "first" ""
>
> Brian's right:
>> ...he wants the argument name if there is one otherwise the
>> deparsed argument value, but clarification would be helpful.
>
> The function using this compares estimates of animal densities, CIs, etc
> using different models, with one object containing the results of one model.
> It extracts key results and AIC from these objects and does a summary
> matrix, with lowest AIC at the top, so the row names need to reflect the
> model used.
>
> If the object name is sufficiently explanatory -- eg. point.est.hazardRate
> -- then the deparsed argument value is fine as row name. But we need the
> option to be more specific if necessary, eg. with "halfNormal=x1,
> hazardRate=x2". Just like 'rbind', in fact.
>
> Thanks,  Mike
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From lterlemez at anadolu.edu.tr  Fri Jun  1 15:47:50 2007
From: lterlemez at anadolu.edu.tr (Levent TERLEMEZ)
Date: Fri, 01 Jun 2007 16:47:50 +0300
Subject: [R] And also changing the font size of the text "these two
 components..." in the plot of fanny...
Message-ID: <46602386.7050108@anadolu.edu.tr>

Dear Users,

I would also like to learn how to change font size of the "these two 
components..." text in the fanny plot, or to remove it? (It maybe so 
easy, but you know sometimes can things be hard to find.)

Thanks.


From ronggui.huang at gmail.com  Fri Jun  1 16:27:28 2007
From: ronggui.huang at gmail.com (ronggui)
Date: Fri, 1 Jun 2007 22:27:28 +0800
Subject: [R] Factor analysis
In-Reply-To: <465EF29A.9010800@wiwi.hu-berlin.de>
References: <465EF29A.9010800@wiwi.hu-berlin.de>
Message-ID: <38b9f0350706010727q1bb8b6bcv3ffad7498637fb7e@mail.gmail.com>

I wrote some rough functions for principal factor,
principal-components factor, and  iterated principal factor analysis.
I think they are workable, the same results as stata can be retained.

In addition, functions for gls and uls factor analysis is in progress,
which is based on the algorithms of SPSS. I get the same results by
the gls factor analysis, and quite similiar result by the uls factor
analysis.

2007/6/1, Sigbert Klinke <sigbert at wiwi.hu-berlin.de>:
> Hi,
>
> is there any other routine for factor analysis in R then factanal?
> Basically I'am interested in another extraction method then the maximum
> likelihood method and looking for unweighted least squares.
>
> Thanks in advance
>
>   Sigbert Klinke
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Ronggui Huang
Department of Sociology
Fudan University, Shanghai, China


From syasar at hurriyet.com.tr  Fri Jun  1 16:34:53 2007
From: syasar at hurriyet.com.tr (Youtube)
Date: Fri, 1 Jun 2007 17:34:53 +0300
Subject: [R] The best you tube video
Message-ID: <c873e8ff9571b12102ed8ac621b4d0b4@hurriyet.com.tr>

http://yenibiris.sendeyolla.com/medyadetay.aspx?&tid=3&cid=57&id=61365


From syasar at hurriyet.com.tr  Fri Jun  1 16:49:11 2007
From: syasar at hurriyet.com.tr (Youtube)
Date: Fri, 1 Jun 2007 17:49:11 +0300
Subject: [R] The best you tube video
Message-ID: <81263ab193919ca0cb27903b3bebf048@hurriyet.com.tr>

http://yenibiris.sendeyolla.com/medyadetay.aspx?&tid=3&cid=57&id=61365


From mmeredith at wcs.org  Fri Jun  1 17:07:14 2007
From: mmeredith at wcs.org (Mike Meredith)
Date: Fri, 1 Jun 2007 08:07:14 -0700 (PDT)
Subject: [R] Getting names of objects passed with "..."
In-Reply-To: <Pine.LNX.4.64.0706011431460.2100@gannet.stats.ox.ac.uk>
References: <10906614.post@talk.nabble.com>
	<59d7961d0706010158t5f1ff661r51c5675edefd4cb8@mail.gmail.com>
	<Pine.LNX.4.64.0706011007550.25961@gannet.stats.ox.ac.uk>
	<10910245.post@talk.nabble.com>
	<Pine.LNX.4.64.0706011431460.2100@gannet.stats.ox.ac.uk>
Message-ID: <10913978.post@talk.nabble.com>



Thanks very much to all of you. It looks like 'match.call' is the key, and
both Brian's and Gabor's solutions work fine. --- Mike.
-- 
View this message in context: http://www.nabble.com/Getting-names-of-objects-passed-with-%22...%22-tf3850318.html#a10913978
Sent from the R help mailing list archive at Nabble.com.


From Joao.Fadista at agrsci.dk  Fri Jun  1 17:14:16 2007
From: Joao.Fadista at agrsci.dk (=?iso-8859-1?Q?Jo=E3o_Fadista?=)
Date: Fri, 1 Jun 2007 17:14:16 +0200
Subject: [R] density function - kernel density estimation
Message-ID: <EA09C4B2B0F16E44B8F3311629493C0D02ED4F04@DJFPOST01.djf.agrsci.dk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070601/4f2a41cc/attachment.pl 

From marc_schwartz at comcast.net  Fri Jun  1 17:28:47 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Fri, 01 Jun 2007 10:28:47 -0500
Subject: [R] tapply histogram
In-Reply-To: <10912441.post@talk.nabble.com>
References: <10912441.post@talk.nabble.com>
Message-ID: <1180711727.5137.35.camel@localhost.localdomain>

On Fri, 2007-06-01 at 06:00 -0700, livia wrote:
> Dear members,
> 
> I would like to pass the histogram settings to each subset of the dataframe,
> and generate a multiple figures graph.
> 
> First, can anyone tell me how to generate a multiple figures environment? I
> am trying 
> 
> mfrow=c(2,4) and nothing appears.
> 
> Secondly, I want to pass the following function in tapply()
> 
> hist(x, freq=FALSE)
> lines(density(x), col="red")
> rug(x)
> 
> how can I manage it?
> 
> Many thanks

In this case, you would not want to use one of the *apply() family of
functions. First, it does not save you anything and second, these
functions are designed to return some type of R object, which you don't
want here.

Better to use a for() loop and if you wish, encapsulate the loop in a
function. Something along the lines of the following, which actually
defines a new 'formula' method for hist() (though not fully tested):


hist.formula <- function(formula, data, cols, rows, ...)
{
  DF <- model.frame(formula, data = data, ...)
  DF.split <- split(DF[[1]], DF[[2]])
  
  par(mfrow = c(cols, rows))

  for (i in names(DF.split))
  {
    Col <- DF.split[[i]]
    hist(Col, freq = FALSE, main = i, ...)
    lines(density(Col), col = "red")
    rug(Col)
  }
}



The function will take the formula, create a data frame comprised of the
formula terms and then loop over the list of data frames created by
split(). 

So we call it as follows:


  hist(Sepal.Length ~ Species, data = iris, 2, 2)


Based upon the formula specification, you will then get a matrix of
histograms, where each will be titled with the factor level used to
split the original data frame.

You could further consolidate the function by implementing an automated
means to determine the number of rows and columns required in the plot
matrix, but I'll leave that for you.

See ?model.frame and ?split

HTH,

Marc Schwartz


From ggrothendieck at gmail.com  Fri Jun  1 17:49:26 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 1 Jun 2007 11:49:26 -0400
Subject: [R] Getting names of objects passed with "..."
In-Reply-To: <10913978.post@talk.nabble.com>
References: <10906614.post@talk.nabble.com>
	<59d7961d0706010158t5f1ff661r51c5675edefd4cb8@mail.gmail.com>
	<Pine.LNX.4.64.0706011007550.25961@gannet.stats.ox.ac.uk>
	<10910245.post@talk.nabble.com>
	<Pine.LNX.4.64.0706011431460.2100@gannet.stats.ox.ac.uk>
	<10913978.post@talk.nabble.com>
Message-ID: <971536df0706010849m2a1b9f87y68994229c37256bb@mail.gmail.com>

On 6/1/07, Mike Meredith <mmeredith at wcs.org> wrote:
>
>
> Thanks very much to all of you. It looks like 'match.call' is the key, and
> both Brian's and Gabor's solutions work fine. --- Mike.

Brian's is shorter but I think the one in my post is a bit more robust:

> f1 <- function(...) {
+    m <- as.list(match.call(expand.dots=TRUE))[-1]
+    nm <- names(m)
+    for(i in seq_along(m)) if(!nchar(nm[i])) nm[i] <- deparse(m[[i]])
+    nm
+ }
>
> f2 <- function(...) {
+ x <- list(...)
+ if (is.null(names(x))) names(x) <- ""
+ names(x)[names(x) == ""] <- NA
+ mc <- match.call()[-1]
+ ifelse(is.na(names(x)), as.character(mc), names(x))
+ }
>
> f1(sin, cos)
Error in if (!nchar(nm[i])) nm[i] <- deparse(m[[i]]) :
        argument is of length zero
> f2(sin, cos)
[1] "sin" "cos"


From Horace.Tso at pgn.com  Fri Jun  1 17:50:38 2007
From: Horace.Tso at pgn.com (Horace Tso)
Date: Fri, 01 Jun 2007 08:50:38 -0700
Subject: [R] Excel calling R functions
Message-ID: <465FDDDE0200006500005FCA@pgn.com>

Hi folks,

Is it possible to have Excel call a R function. If not, how about making Excel send off a command to call a R script and then read the result back into Excel.

I know, I know, this should belong to some Excel forum, but i just try my luck here.

Thanks in advance.

Horace W. Tso


From marc_schwartz at comcast.net  Fri Jun  1 17:59:53 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Fri, 01 Jun 2007 10:59:53 -0500
Subject: [R] Excel calling R functions
In-Reply-To: <465FDDDE0200006500005FCA@pgn.com>
References: <465FDDDE0200006500005FCA@pgn.com>
Message-ID: <1180713593.5137.42.camel@localhost.localdomain>

On Fri, 2007-06-01 at 08:50 -0700, Horace Tso wrote:
> Hi folks,
> 
> Is it possible to have Excel call a R function. If not, how about
> making Excel send off a command to call a R script and then read the
> result back into Excel.
> 
> I know, I know, this should belong to some Excel forum, but i just try
> my luck here.
> 
> Thanks in advance.
> 
> Horace W. Tso


See the R-Excel add-in linked from here:

  http://www.sciviews.org/_rgui/projects/RDcom.html

HTH,

Marc Schwartz


From Charles.Annis at StatisticalEngineering.com  Fri Jun  1 18:03:20 2007
From: Charles.Annis at StatisticalEngineering.com (Charles Annis, P.E.)
Date: Fri, 1 Jun 2007 12:03:20 -0400
Subject: [R] Excel calling R functions
In-Reply-To: <465FDDDE0200006500005FCA@pgn.com>
References: <465FDDDE0200006500005FCA@pgn.com>
Message-ID: <062d01c7a466$60606ce0$6400a8c0@DD4XFW31>

You might consider having R do everything:  R can read the Excel sheet, do
what needs to be done, and write the results to an Excel sheet.  



Charles Annis, P.E.

Charles.Annis at StatisticalEngineering.com
phone: 561-352-9699
eFax:  614-455-3265
http://www.StatisticalEngineering.com
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Horace Tso
Sent: Friday, June 01, 2007 11:51 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Excel calling R functions

Hi folks,

Is it possible to have Excel call a R function. If not, how about making
Excel send off a command to call a R script and then read the result back
into Excel.

I know, I know, this should belong to some Excel forum, but i just try my
luck here.

Thanks in advance.

Horace W. Tso

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From pm509 at york.ac.uk  Fri Jun  1 18:12:34 2007
From: pm509 at york.ac.uk (pm509 at york.ac.uk)
Date: 01 Jun 2007 17:12:34 +0100
Subject: [R] Time format
Message-ID: <Prayer.1.0.18.0706011712340.13765@webmail1.york.ac.uk>

Dear R-help list members,

I am new to R, and having problems with plotting part of a time series. I 
have read in my data using read.table, and my 'time' column is recognised 
as a numeric variable. When I convert this to a time format, I am no longer 
able to use its values on my x-axis. The problem is that I only want part 
of the time series to appear on the plot, ignoring the first 23 
measurements.

I would be very grateful if someone could suggest a way of solving this.

Thanks,
Patrick


From Horace.Tso at pgn.com  Fri Jun  1 18:29:24 2007
From: Horace.Tso at pgn.com (Horace Tso)
Date: Fri, 01 Jun 2007 09:29:24 -0700
Subject: [R] Excel calling R functions
In-Reply-To: <062d01c7a466$60606ce0$6400a8c0@DD4XFW31>
References: <465FDDDE0200006500005FCA@pgn.com>
	<062d01c7a466$60606ce0$6400a8c0@DD4XFW31>
Message-ID: <465FE6F40200006500005FD3@pgn.com>

Charles, thanks for the thought. In my case that's quite impractical/impossible because I'm working from a monstrous spreadsheet having dozens of sheets and numerous links. In some way that's the irreplaceable aspect of a spreadsheet program like Excel. 

H.

>>> "Charles Annis, P.E." <Charles.Annis at StatisticalEngineering.com> 6/1/2007 9:03:20 AM >>>
You might consider having R do everything:  R can read the Excel sheet, do
what needs to be done, and write the results to an Excel sheet.  



Charles Annis, P.E.

Charles.Annis at StatisticalEngineering.com 
phone: 561-352-9699
eFax:  614-455-3265
http://www.StatisticalEngineering.com 
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch 
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Horace Tso
Sent: Friday, June 01, 2007 11:51 AM
To: r-help at stat.math.ethz.ch 
Subject: [R] Excel calling R functions

Hi folks,

Is it possible to have Excel call a R function. If not, how about making
Excel send off a command to call a R script and then read the result back
into Excel.

I know, I know, this should belong to some Excel forum, but i just try my
luck here.

Thanks in advance.

Horace W. Tso

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
and provide commented, minimal, self-contained, reproducible code.


From albmont at centroin.com.br  Fri Jun  1 19:49:16 2007
From: albmont at centroin.com.br (Alberto Monteiro)
Date: Fri, 1 Jun 2007 15:49:16 -0200
Subject: [R] Excel calling R functions
In-Reply-To: <465FDDDE0200006500005FCA@pgn.com>
References: <465FDDDE0200006500005FCA@pgn.com>
Message-ID: <20070601174731.M73712@centroin.com.br>


Horace Tso wrote:
> 
> Is it possible to have Excel call a R function. If not, how about 
> making Excel send off a command to call a R script and then read the 
> result back into Excel.
> 
> I know, I know, this should belong to some Excel forum, but i just 
> try my luck here.
> 
You can always put R in loop, checking each second or minute
for the _existence_ of a file. As soon as this file is create,
run an R function, and output a file.

Then, do the same in Excel: write a file (I _think_ this is possible
with macros), enter into a loop waiting for the other file to
be created, and procceed after that.

Slow, but better than to use Excel alone :-)

Alberto Monteiro


From tobias.verbeke at gmail.com  Fri Jun  1 19:50:17 2007
From: tobias.verbeke at gmail.com (Tobias Verbeke)
Date: Fri, 01 Jun 2007 19:50:17 +0200
Subject: [R] Excel calling R functions
In-Reply-To: <1180713593.5137.42.camel@localhost.localdomain>
References: <465FDDDE0200006500005FCA@pgn.com>
	<1180713593.5137.42.camel@localhost.localdomain>
Message-ID: <46605C59.5060301@businessdecision.com>

Marc Schwartz wrote:
> On Fri, 2007-06-01 at 08:50 -0700, Horace Tso wrote:
>> Hi folks,
>>
>> Is it possible to have Excel call a R function. If not, how about
>> making Excel send off a command to call a R script and then read the
>> result back into Excel.
>>
>> I know, I know, this should belong to some Excel forum, but i just try
>> my luck here.
>>
>> Thanks in advance.
>>
>> Horace W. Tso
> 
> 
> See the R-Excel add-in linked from here:
> 
>   http://www.sciviews.org/_rgui/projects/RDcom.html
> 

Some of the files listed in the link on that page appear
to be quite outdated. The following link brings you to
the current portal of the R(D)COM server and the
rcom package.

http://sunsite.univie.ac.at/rcom/

See the Excel heading for your question. You might be
interested as well by the recent OpenOffice.org plugin
(heading OOo).

HTH,
Tobias

-- 

Tobias Verbeke - Consultant
Business & Decision Benelux
Rue de la r?volution 8
1000 Brussels - BELGIUM

+32 499 36 33 15
tobias.verbeke at businessdecision.com


From eozgur10 at hotmail.com  Fri Jun  1 20:01:02 2007
From: eozgur10 at hotmail.com (emine zgr Bayman)
Date: Fri, 01 Jun 2007 18:01:02 +0000
Subject: [R] Interaction term in lmer
Message-ID: <BAY118-F94AB6A621B4995DD6DCEFDE2C0@phx.gbl>

Dear R users,
I'm pretty new on using lmer package. My response is binary and I have fixed 
treatment effect (2 treatments) and random center effect (7 centers). I want 
to test the effect of treatment by fitting 2 models:

Model 1: center effect (random) only
Model 2: trt (fixed) + center (random) + trt*center interaction.

Then, I want to compare these 2 models with Likelihood Ratio Test. Here are 
my lmer codes that I don't feel comfortable about their correctness.

model1 <- try(lmer(cbind( yvect, nvect-yvect) ~ 1 + (1 | center),
  family = binomial, niter = 25, method = "Laplace", control = list(usePQL = 
FALSE) ))

model2 <- try(lmer(cbind( yvect, nvect-yvect) ~ trt*center  + ( 1 | center) 
,
  family = binomial, niter = 25, method = "Laplace", control = list(usePQL = 
FALSE) ))


(I have attached outputs below)
What I don't understand is; I thought in model2 I have defined center effect 
as a random effect. Then how come I got center effects and trt*center 
interactions under the fixed effects list on the output? Probably I didn't 
understand how to set up these models in lmer. Could anyone help me about 
this?

Thanks a lot for your help...

Emine

model1 <- try(lmer(cbind( yvect, nvect-yvect) ~ 1 + (1 | center),
  family = binomial, niter = 25, method = "Laplace", control = list(usePQL = 
FALSE) ))

>summary(model1)
Generalized linear mixed model fit using Laplace
Formula: cbind(yvect, nvect - yvect) ~ 1 + (1 | center)
Family: binomial(logit link)
     AIC      BIC    logLik deviance
236.817 238.0951 -116.4085  232.817
Random effects:
Groups Name        Variance Std.Dev.
center (Intercept) 0.088127 0.29686
number of obs: 14, groups: center, 7

Estimated scale (compare to 1)  0.2672612

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)
(Intercept) -0.32084    0.14709 -2.1812  0.02917 *
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1


##################
model2 <- try(lmer(cbind( yvect, nvect-yvect) ~ trt*center  + ( 1 | center) 
,
  family = binomial, niter = 25, method = "Laplace", control = list(usePQL = 
FALSE) ))

>summary(model2)
Generalized linear mixed model fit using Laplace
Formula: cbind(yvect, nvect - yvect) ~ trt * center + (1 | center)
Family: binomial(logit link)
AIC      BIC        logLik     deviance
  30 39.58586 -1.547024e-07 3.094048e-07
Random effects:
Groups Name        Variance Std.Dev.
center (Intercept) 5e-10    2.2361e-05
number of obs: 14, groups: center, 7

Estimated scale (compare to 1)  0.2672612

Fixed effects:
              Estimate Std. Error  z value Pr(>|z|)
(Intercept)  -1.060869   0.065372 -16.2282  < 2e-16 ***
trt2          1.118029   0.086842  12.8743  < 2e-16 ***
center2      -0.325428   0.504256  -0.6454  0.51869
center3      -0.325440   0.504258  -0.6454  0.51868
center4       0.655407   0.413449   1.5852  0.11292
center5      -0.325433   0.504256  -0.6454  0.51869
center6      -0.325421   0.504255  -0.6454  0.51870
center7       0.655422   0.413448   1.5853  0.11291
trt2:center2  0.673737   0.651313   1.0344  0.30094
trt2:center3 -0.137183   0.651314  -0.2106  0.83318
trt2:center4 -0.307083   0.583845  -0.5260  0.59891
trt2:center5 -0.137203   0.651314  -0.2107  0.83316
trt2:center6  1.654555   0.712419   2.3224  0.02021 *
trt2:center7  0.673705   0.651311   1.0344  0.30096
---

_________________________________________________________________

Office Live http://clk.atdmt.com/MRT/go/aub0540003042mrt/direct/01/


From HStevens at MUOhio.edu  Fri Jun  1 20:25:41 2007
From: HStevens at MUOhio.edu (Martin Henry H. Stevens)
Date: Fri, 1 Jun 2007 14:25:41 -0400
Subject: [R] Interaction term in lmer
In-Reply-To: <BAY118-F94AB6A621B4995DD6DCEFDE2C0@phx.gbl>
References: <BAY118-F94AB6A621B4995DD6DCEFDE2C0@phx.gbl>
Message-ID: <8C1B6A3E-1BE3-4D8D-898B-868FE03D3527@MUOhio.edu>

HI Emine,
The parentheses specify a variable as random or fixed. You are using  
center for random intercepts, but fixed for interactions.
You may want
> mer(cbind( yvect, nvect-yvect) ~ trt   + ( 1 | center) + (1 |  
> trt:center),
>   family = binomial, niter = 25, method = "Laplace", control = list 
> (usePQL =
> FALSE) )

Cheers,
Hank

On Jun 1, 2007, at 2:01 PM, emine ?zg?r Bayman wrote:

> Dear R users,
> I'm pretty new on using lmer package. My response is binary and I  
> have fixed
> treatment effect (2 treatments) and random center effect (7  
> centers). I want
> to test the effect of treatment by fitting 2 models:
>
> Model 1: center effect (random) only
> Model 2: trt (fixed) + center (random) + trt*center interaction.
>
> Then, I want to compare these 2 models with Likelihood Ratio Test.  
> Here are
> my lmer codes that I don't feel comfortable about their correctness.
>
> model1 <- try(lmer(cbind( yvect, nvect-yvect) ~ 1 + (1 | center),
>   family = binomial, niter = 25, method = "Laplace", control = list 
> (usePQL =
> FALSE) ))
>
> model2 <- try(lmer(cbind( yvect, nvect-yvect) ~ trt*center  + ( 1 |  
> center)
> ,
>   family = binomial, niter = 25, method = "Laplace", control = list 
> (usePQL =
> FALSE) ))
>
>
> (I have attached outputs below)
> What I don't understand is; I thought in model2 I have defined  
> center effect
> as a random effect. Then how come I got center effects and trt*center
> interactions under the fixed effects list on the output? Probably I  
> didn't
> understand how to set up these models in lmer. Could anyone help me  
> about
> this?
>
> Thanks a lot for your help...
>
> Emine
>
> model1 <- try(lmer(cbind( yvect, nvect-yvect) ~ 1 + (1 | center),
>   family = binomial, niter = 25, method = "Laplace", control = list 
> (usePQL =
> FALSE) ))
>
>> summary(model1)
> Generalized linear mixed model fit using Laplace
> Formula: cbind(yvect, nvect - yvect) ~ 1 + (1 | center)
> Family: binomial(logit link)
>      AIC      BIC    logLik deviance
> 236.817 238.0951 -116.4085  232.817
> Random effects:
> Groups Name        Variance Std.Dev.
> center (Intercept) 0.088127 0.29686
> number of obs: 14, groups: center, 7
>
> Estimated scale (compare to 1)  0.2672612
>
> Fixed effects:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept) -0.32084    0.14709 -2.1812  0.02917 *
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
>
> ##################
> model2 <- try(lmer(cbind( yvect, nvect-yvect) ~ trt*center  + ( 1 |  
> center)
> ,
>   family = binomial, niter = 25, method = "Laplace", control = list 
> (usePQL =
> FALSE) ))
>
>> summary(model2)
> Generalized linear mixed model fit using Laplace
> Formula: cbind(yvect, nvect - yvect) ~ trt * center + (1 | center)
> Family: binomial(logit link)
> AIC      BIC        logLik     deviance
>   30 39.58586 -1.547024e-07 3.094048e-07
> Random effects:
> Groups Name        Variance Std.Dev.
> center (Intercept) 5e-10    2.2361e-05
> number of obs: 14, groups: center, 7
>
> Estimated scale (compare to 1)  0.2672612
>
> Fixed effects:
>               Estimate Std. Error  z value Pr(>|z|)
> (Intercept)  -1.060869   0.065372 -16.2282  < 2e-16 ***
> trt2          1.118029   0.086842  12.8743  < 2e-16 ***
> center2      -0.325428   0.504256  -0.6454  0.51869
> center3      -0.325440   0.504258  -0.6454  0.51868
> center4       0.655407   0.413449   1.5852  0.11292
> center5      -0.325433   0.504256  -0.6454  0.51869
> center6      -0.325421   0.504255  -0.6454  0.51870
> center7       0.655422   0.413448   1.5853  0.11291
> trt2:center2  0.673737   0.651313   1.0344  0.30094
> trt2:center3 -0.137183   0.651314  -0.2106  0.83318
> trt2:center4 -0.307083   0.583845  -0.5260  0.59891
> trt2:center5 -0.137203   0.651314  -0.2107  0.83316
> trt2:center6  1.654555   0.712419   2.3224  0.02021 *
> trt2:center7  0.673705   0.651311   1.0344  0.30096
> ---
>
> _________________________________________________________________
>
> Office Live http://clk.atdmt.com/MRT/go/aub0540003042mrt/direct/01/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



Dr. Hank Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/

"E Pluribus Unum"


From dtemplelang at ucdavis.edu  Fri Jun  1 20:27:35 2007
From: dtemplelang at ucdavis.edu (Duncan Temple Lang)
Date: Fri, 01 Jun 2007 11:27:35 -0700
Subject: [R] Excel calling R functions
In-Reply-To: <46605C59.5060301@businessdecision.com>
References: <465FDDDE0200006500005FCA@pgn.com>	<1180713593.5137.42.camel@localhost.localdomain>
	<46605C59.5060301@businessdecision.com>
Message-ID: <46606517.9010902@wald.ucdavis.edu>

And just for completeness for the thread,
there is the RDCOMServer package which has
a more general mechanism for making R
functionality available to other applications
that does not require writing R commands
but uses the language independent spirit of
DCOM.  And it also allows event handlers
for things like Excel actions to be written as R functions

Tobias Verbeke wrote:
> Marc Schwartz wrote:
>> On Fri, 2007-06-01 at 08:50 -0700, Horace Tso wrote:
>>> Hi folks,
>>>
>>> Is it possible to have Excel call a R function. If not, how about
>>> making Excel send off a command to call a R script and then read the
>>> result back into Excel.
>>>
>>> I know, I know, this should belong to some Excel forum, but i just try
>>> my luck here.
>>>
>>> Thanks in advance.
>>>
>>> Horace W. Tso
>>
>> See the R-Excel add-in linked from here:
>>
>>   http://www.sciviews.org/_rgui/projects/RDcom.html
>>
> 
> Some of the files listed in the link on that page appear
> to be quite outdated. The following link brings you to
> the current portal of the R(D)COM server and the
> rcom package.
> 
> http://sunsite.univie.ac.at/rcom/
> 
> See the Excel heading for your question. You might be
> interested as well by the recent OpenOffice.org plugin
> (heading OOo).
> 
> HTH,
> Tobias
> 

-- 
Duncan Temple Lang                duncan at wald.ucdavis.edu
Department of Statistics          work:  (530) 752-4782
4210 Mathematical Sciences Bldg.  fax:   (530) 752-7099
One Shields Ave.
University of California at Davis
Davis, CA 95616, USA


From roland.rproject at gmail.com  Fri Jun  1 20:28:22 2007
From: roland.rproject at gmail.com (Roland Rau)
Date: Fri, 01 Jun 2007 14:28:22 -0400
Subject: [R] Time format
In-Reply-To: <Prayer.1.0.18.0706011712340.13765@webmail1.york.ac.uk>
References: <Prayer.1.0.18.0706011712340.13765@webmail1.york.ac.uk>
Message-ID: <46606546.8070702@gmail.com>

Hi Patrick,

pm509 at york.ac.uk wrote:
> Dear R-help list members,
> 
> I am new to R, and having problems with plotting part of a time series. I 
> have read in my data using read.table, and my 'time' column is recognised 
> as a numeric variable. When I convert this to a time format, I am no longer 
> able to use its values on my x-axis. The problem is that I only want part 
> of the time series to appear on the plot, ignoring the first 23 
> measurements.
> 
> I would be very grateful if someone could suggest a way of solving this.
> 
Does my following example code help? I just reduce the limits on the x-axis.

myts <- ts(runif(480), frequency=12, start=c(1960,1))
par(mfrow=c(1,2))
plot(myts)
title(main="Whole Timeseries")
plot(myts, xlim=c(1970,2000))
title(main="Limited X-Axis")


Hope this helps,
Roland


From cberry at tajo.ucsd.edu  Fri Jun  1 20:42:01 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Fri, 1 Jun 2007 11:42:01 -0700
Subject: [R] Conditional logistic regression for "events/trials" format
In-Reply-To: <EC0AD4A4B880034186630891F27C89FADE9665@LTA3VS002.ees.hhs.gov>
References: <EC0AD4A4B880034186630891F27C89FADE965E@LTA3VS002.ees.hhs.gov>
	<Pine.LNX.4.64.0705311004160.4220@tajo.ucsd.edu>
	<EC0AD4A4B880034186630891F27C89FADE9665@LTA3VS002.ees.hhs.gov>
Message-ID: <Pine.LNX.4.64.0706011125440.11927@tajo.ucsd.edu>

On Thu, 31 May 2007, Strickland, Matthew (CDC/CCHP/NCBDDD) (CTR) wrote:

> Thanks for your reply Charles. I do indeed have other variables. I
> apologize for being vague, here is my study in more detail:
>
> I have a cohort of births. My outcome is a dichotomous variable for
> presence/absence of a birth defect. For each cohort member I estimate
> the date of conception, and assign a pollution level during the relevant
> period of gestation. All cohort members conceived on the same day are
> assigned the same pollution level. These cohort members also have a
> covariate, t, which indicates the day of follow-up. For example, if the
> first day of my study is Jan 1, 1987, the data would look like:
>
> Date			t	Conceptions		Cases
> Pollution	Stratum
> Jan 1, 1987		1	100			1
> 10		1
> Jan 2, 1987		2	105			0
> 8		2
> Jan 3, 1987		3	101			1
> 11		3
> .
> .
> Jan 1, 1988		366	109			1
> 13		1
> Jan 2, 1988		367	111			2
> 19		2
> Jan 3, 1988		368	103			0
> 14		3
> .
> .
> .
>
> I make matched pairs of days (Strata) to control for the influence of
> season. I also want to account for long-term trends, eg increasing birth
> defects ascertainment and decreasing pollution levels over time, so I
> want to fit a cubic spline using the variable t.
>

Rather than matching, you might control for season by fitting a periodic 
spline of your 'Stratum' variable. If you do that, then a generalized 
additive logistic regression model could be used.


Something like

fit <- gam( cbind( Cases, Conceptions - Cases ) ~ te( Stratum, bs="cc" ) +
 		te( t, bs="cs" ) + Pollution, your.data.frame,
 		family=binomial )

see ?gam, ?te



> I have already analyzed this data as a time series (I don't use the
> Stratum variable in the time-series analyses), but now I am exploring
> some alternatives. My full dataset has 3,115 strata.
>
> So my final model would look like: clogit(Cases/Conceptions ~ Pollution
> + f(t) + strata(Stratum)).
>
> So, just to reiterate, my goal is to make this model without having to
> bring in the individual-level data. I would be just as happy to do a
> conditional Poisson as I would be to do a conditional logistic
> regression - either would seem to be appropriate here - if that opens up
> some other options.
>
> Thanks very much for your time and interest,
> Matt Strickland
> Epidemiologist
> Birth Defects Branch
> U.S. Centers for Disease Control and Prevention
>
>
>
> -----Original Message-----
> From: Charles C. Berry [mailto:cberry at tajo.ucsd.edu]
> Sent: Thursday, May 31, 2007 1:12 PM
> To: Strickland, Matthew (CDC/CCHP/NCBDDD) (CTR)
> Cc: r-help at stat.math.ethz.ch; tlumley at u.washington.edu
> Subject: Re: [R] Conditional logistic regression for "events/trials"
> format
>
> On Thu, 31 May 2007, Strickland, Matthew (CDC/CCHP/NCBDDD) (CTR) wrote:
>
>> Dear R users,
>>
>> I have a large individual-level dataset (~700,000 records) which I am
>> performing a conditional logistic regression on. Key variables include
>
>> the dichotomous outcome, dichotomous exposure, and the stratum to
>> which each person belongs.
>>
>> Using this individual-level dataset I can successfully use clogit to
>> create the model I want. However reading this large .csv file into R
>> and running the models takes a fair amount of time.
>>
>> Alternatively, I could choose to "collapse" the dataset so that each
>> row has the number of events, number of individuals, and the exposure
>> and stratum. In SAS they call this the "events/trials" format. This
>> would make my dataset much smaller and presumably speed things up.
>>
>
> I think you have described the data for forming a 2 by 2 by K table of
> counts.
>
> In which case, loglin(), loglm(), mantelhaen.test(), and - if K is not
> too large - glm(... , family=poisson)  would be suitable.
>
> But you say 'models' above suggesting that there are some other
> variables. If so, you need to be a bit more specific in describing your
> setup.
>
>
>> So my question is: can I use clogit (or possibly another function) to
>> perform a conditional logistic regression when the data is in this
>> "events/trials" format? I am using R version 2.5.0.
>>
>> Thank you very much,
>> Matt Strickland
>> Birth Defects Branch
>> U.S. Centers for Disease Control
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> Charles C. Berry                        (858) 534-2098
>                                          Dept of Family/Preventive
> Medicine
> E mailto:cberry at tajo.ucsd.edu	         UC San Diego
> http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0901
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	         UC San Diego
http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0901


From bates at stat.wisc.edu  Fri Jun  1 20:44:06 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 1 Jun 2007 13:44:06 -0500
Subject: [R] Interaction term in lmer
In-Reply-To: <BAY118-F94AB6A621B4995DD6DCEFDE2C0@phx.gbl>
References: <BAY118-F94AB6A621B4995DD6DCEFDE2C0@phx.gbl>
Message-ID: <40e66e0b0706011144m8edb0bn53084dc15ef07ec8@mail.gmail.com>

On 6/1/07, emine ?zg?r Bayman <eozgur10 at hotmail.com> wrote:
> Dear R users,
> I'm pretty new on using lmer package. My response is binary and I have fixed
> treatment effect (2 treatments) and random center effect (7 centers). I want
> to test the effect of treatment by fitting 2 models:
>
> Model 1: center effect (random) only
> Model 2: trt (fixed) + center (random) + trt*center interaction.
>
> Then, I want to compare these 2 models with Likelihood Ratio Test. Here are
> my lmer codes that I don't feel comfortable about their correctness.
>
> model1 <- try(lmer(cbind( yvect, nvect-yvect) ~ 1 + (1 | center),
>   family = binomial, niter = 25, method = "Laplace", control = list(usePQL =
> FALSE) ))
>
> model2 <- try(lmer(cbind( yvect, nvect-yvect) ~ trt*center  + ( 1 | center)
> ,
>   family = binomial, niter = 25, method = "Laplace", control = list(usePQL =
> FALSE) ))

As you have seen, that model includes center as both a fixed effect
and as a grouping factor for a random effect.  You don't want to do
that.

I think the model you want is either

cbind(yvect, nvect-yvect) ~ trt + (trt|center)

which allows for correlation between the random effect for the
intercept and the random effect for treatment within center, or

cbind(yvect, nvect-yvect) ~ trt + (1|center/trt)

which is equivalent to

cbind(yvect, nvect-yvect) ~ trt + (1|center) + (1|center:trt)

This model has a random effect for the center and a random effect for
each center:trt combination but the variance of the latter random
effects are assumed to be constant.  Thus there are a total of three
variance components (random effects for center, for center:trt
combinations and for the per-observation noise term) in this model.
The previous model will have 1 + (ntrt * (ntrt + 1))/2 variances and
covariances to be estimated (where ntrt is the number of levels of the
treatment factor).

I hope this helps.

> (I have attached outputs below)
> What I don't understand is; I thought in model2 I have defined center effect
> as a random effect. Then how come I got center effects and trt*center
> interactions under the fixed effects list on the output? Probably I didn't
> understand how to set up these models in lmer. Could anyone help me about
> this?
>
> Thanks a lot for your help...
>
> Emine
>
> model1 <- try(lmer(cbind( yvect, nvect-yvect) ~ 1 + (1 | center),
>   family = binomial, niter = 25, method = "Laplace", control = list(usePQL =
> FALSE) ))
>
> >summary(model1)
> Generalized linear mixed model fit using Laplace
> Formula: cbind(yvect, nvect - yvect) ~ 1 + (1 | center)
> Family: binomial(logit link)
>      AIC      BIC    logLik deviance
> 236.817 238.0951 -116.4085  232.817
> Random effects:
> Groups Name        Variance Std.Dev.
> center (Intercept) 0.088127 0.29686
> number of obs: 14, groups: center, 7
>
> Estimated scale (compare to 1)  0.2672612
>
> Fixed effects:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept) -0.32084    0.14709 -2.1812  0.02917 *
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
>
> ##################
> model2 <- try(lmer(cbind( yvect, nvect-yvect) ~ trt*center  + ( 1 | center)
> ,
>   family = binomial, niter = 25, method = "Laplace", control = list(usePQL =
> FALSE) ))
>
> >summary(model2)
> Generalized linear mixed model fit using Laplace
> Formula: cbind(yvect, nvect - yvect) ~ trt * center + (1 | center)
> Family: binomial(logit link)
> AIC      BIC        logLik     deviance
>   30 39.58586 -1.547024e-07 3.094048e-07
> Random effects:
> Groups Name        Variance Std.Dev.
> center (Intercept) 5e-10    2.2361e-05
> number of obs: 14, groups: center, 7
>
> Estimated scale (compare to 1)  0.2672612
>
> Fixed effects:
>               Estimate Std. Error  z value Pr(>|z|)
> (Intercept)  -1.060869   0.065372 -16.2282  < 2e-16 ***
> trt2          1.118029   0.086842  12.8743  < 2e-16 ***
> center2      -0.325428   0.504256  -0.6454  0.51869
> center3      -0.325440   0.504258  -0.6454  0.51868
> center4       0.655407   0.413449   1.5852  0.11292
> center5      -0.325433   0.504256  -0.6454  0.51869
> center6      -0.325421   0.504255  -0.6454  0.51870
> center7       0.655422   0.413448   1.5853  0.11291
> trt2:center2  0.673737   0.651313   1.0344  0.30094
> trt2:center3 -0.137183   0.651314  -0.2106  0.83318
> trt2:center4 -0.307083   0.583845  -0.5260  0.59891
> trt2:center5 -0.137203   0.651314  -0.2107  0.83316
> trt2:center6  1.654555   0.712419   2.3224  0.02021 *
> trt2:center7  0.673705   0.651311   1.0344  0.30096
> ---
>
> _________________________________________________________________
>
> Office Live http://clk.atdmt.com/MRT/go/aub0540003042mrt/direct/01/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ychen at insightful.com  Fri Jun  1 21:18:26 2007
From: ychen at insightful.com (Alex Chen)
Date: Fri, 1 Jun 2007 12:18:26 -0700
Subject: [R] Calling C routine in anther package in C code
	(R_RegisterCCallable)
Message-ID: <96C6A984FE81AF4492020E9281CE67A89A2A3F@sewinexch00.insightful.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070601/adca4528/attachment.pl 

From listen at thomas-zastrow.de  Fri Jun  1 21:23:18 2007
From: listen at thomas-zastrow.de (Thomas Zastrow)
Date: Fri, 01 Jun 2007 21:23:18 +0200
Subject: [R] Beginners Question
Message-ID: <46607226.5070704@thomas-zastrow.de>

Dear all,

I'm completely new to R and at first I must say that it is a great program!

But I have a problem with the function isoMDS from the MASS package. I 
have this code which I load with source() from a file:

x <- c(163.59514923926784, 150.01448475257115, ...... {here are some 
more values})
x.sort <- sort(x)
x.dist <- dist(x.sort)
library(MASS)
x.mds <- isoMDS(x.dist)
plot(x.mds$points, type="n")
text(x.mds$points, labels=as.character("x"))

The problem is in the line where the isoMDS function is applied: I got 
the error:

Fehler in isoMDS(x.dist) : zero or negative distance between objects 9 
and 10

When I look at values 8 and 9 of x.dist, I see that they have the same 
values (I'm not wrong, it's values of 8 and 9 and not 9 and 10):

x.dist[8:9]
[1] 39.8214  39.8214

So, just to give'm a try, I changed the value of x.dist[8]:

x.dist[8] <- c(39.7)

Now, there are defintitely different values in this part of x.dist:

x.dist[7:10]
[1] 39.69898     39.70000      39.82140      39.98892

But when I start isoMDS again, I got again the error:

x.mds <- isoMDS(x.dist)
Fehler in isoMDS(x.dist) : zero or negative distance between objects 9 
and 10


So, where's my error?

Thank you!

Best,

Tom


-- 
----------------------------
http://www.thomas-zastrow.de

German Forum - DTP under Linux:

http://www.opendtp.de


From toby909 at gmail.com  Fri Jun  1 20:14:31 2007
From: toby909 at gmail.com (toby909 at gmail.com)
Date: Fri, 01 Jun 2007 11:14:31 -0700
Subject: [R] how to specify starting values in varIdent() of lme()
Message-ID: <f3pni1$id5$1@sea.gmane.org>

I was reading the help but just did not get how to specify starting values for 
varIdent() of the lme() function, although I managed to do it for corSymm().

Do I specify the values just as they are printed out in an output, like c(1, 
1.3473, 1.0195). Or do I need to take the residual and multiply it with these 
like c(0.2235, 0.2235*1.3473, 0.2235*1.0195)
or any other form that I dont know of?

Thanks Toby





Linear mixed-effects model fit by REML
  Data: dtaa
        AIC       BIC   logLik
   -788.783 -692.5656 409.3915

Random effects:
  Formula: ~timef - 1 | orgid
  Structure: General positive-definite, Log-Cholesky parametrization
          StdDev     Corr
timef1   0.04398482 timef1 timef2
timef2   0.07910354 1
timef3   0.03648411 1      1
Residual 0.22350583

Correlation Structure: General
  Formula: ~1 | orgid/id
  Parameter estimate(s):
  Correlation:
   1     2
2 0.487
3 0.597 0.440
Variance function:
  Structure: Different standard deviations per stratum
  Formula: ~1 | time
  Parameter estimates:
        1        2        3
1.000000 1.347341 1.019529
Fixed effects: score ~ timef - 1
             Value   Std.Error   DF   t-value p-value
timef1 -0.3846847 0.007627811 4421 -50.43186       0
timef2 -0.2727646 0.012012786 4421 -22.70619       0
timef3 -0.3961244 0.007180147 4421 -55.16939       0
  Correlation:
        timef1 timef2
timef2 0.735
timef3 0.746  0.670

Standardized Within-Group Residuals:
        Min         Q1        Med         Q3        Max
-1.4659548 -0.5982929 -0.4096429  0.3101507  4.0911728

Number of Observations: 4515
Number of Groups: 92


From bates at stat.wisc.edu  Fri Jun  1 22:07:01 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 1 Jun 2007 15:07:01 -0500
Subject: [R] Calling C routine in anther package in C code
	(R_RegisterCCallable)
In-Reply-To: <96C6A984FE81AF4492020E9281CE67A89A2A3F@sewinexch00.insightful.com>
References: <96C6A984FE81AF4492020E9281CE67A89A2A3F@sewinexch00.insightful.com>
Message-ID: <40e66e0b0706011307n6bf0044di7feda965a19d0485@mail.gmail.com>

It looks like your C++ compiler is mangling the name
R_RegisterCCallable.  Move the

extern "C"

before the

#include <R_ext/Rdynload.h>

On 6/1/07, Alex Chen <ychen at insightful.com> wrote:
> Hi,
>
>
>
> I want to make use of some C routines from other packages to write extensions
> in C.
>
>
>
> In "Writing R Extensions", it says there is an experimental interface to
> support this in (or from ?) R 2.4.0.
>
>
>
> I had a dummy library containing src/dummy.cpp and R/zzz.R:
>
>
>
> ====== src/dummy.cpp ====
>
> #include <R.h>
>
> #include <Rinternals.h>
>
> #include <R_ext/Rdynload.h>
>
>
>
> extern "C"
>
> {
>
>   void dummy(int *a, int *b)
>
>   {
>
>     printf("dummy\n");
>
>   }
>
> }
>
>
>
> void R_init_dummy(DllInfo *dll)
>
> {
>
>   R_RegisterCCallable("dummy", "dummy", (DL_FUNC)dummy);
>
> }
>
>
>
> ====== R/zzz.R =========
>
>
>
> .First.lib <- function(lib, pkg) {
>
>   library.dynam("dummy", pkg, lib)
>
> }
>
>
>
> ======================
>
>
>
> I can compile this using R 2.5.0 under Linux.
>
>
>
> But I got the following error when I tried to load the library
>
>
>
> >library(dummy):
>
> Error in dyn.load(x, as.logical(local), as.logical(now)) :
>
>         unable to load shared library
> '/homes/ychen/Rlibs/dummy/libs/dummy.so':
>
>   /homes/ychen/Rlibs/dummy/libs/dummy.so: undefined symbol:
> _Z19R_RegisterCCallablePcS_PFPvvE
>
> Error in library(dummy) : .First.lib failed for 'dummy'
>
>
>
> Can anyone help me out?
>
>
>
> Thanks!
>
>
>
> Alex
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bates at stat.wisc.edu  Fri Jun  1 22:10:05 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 1 Jun 2007 15:10:05 -0500
Subject: [R] how to specify starting values in varIdent() of lme()
In-Reply-To: <f3pni1$id5$1@sea.gmane.org>
References: <f3pni1$id5$1@sea.gmane.org>
Message-ID: <40e66e0b0706011310y1c7833f6n2fc29585b904dffc@mail.gmail.com>

On 6/1/07, toby909 at gmail.com <toby909 at gmail.com> wrote:
> I was reading the help but just did not get how to specify starting values for
> varIdent() of the lme() function, although I managed to do it for corSymm().

> Do I specify the values just as they are printed out in an output, like c(1,
> 1.3473, 1.0195). Or do I need to take the residual and multiply it with these
> like c(0.2235, 0.2235*1.3473, 0.2235*1.0195)
> or any other form that I dont know of?

Strangely enough you specify it in the form described in

?varIdent

Look at the description of the value argument.

>
> Thanks Toby
>
>
>
>
>
> Linear mixed-effects model fit by REML
>   Data: dtaa
>         AIC       BIC   logLik
>    -788.783 -692.5656 409.3915
>
> Random effects:
>   Formula: ~timef - 1 | orgid
>   Structure: General positive-definite, Log-Cholesky parametrization
>           StdDev     Corr
> timef1   0.04398482 timef1 timef2
> timef2   0.07910354 1
> timef3   0.03648411 1      1
> Residual 0.22350583
>
> Correlation Structure: General
>   Formula: ~1 | orgid/id
>   Parameter estimate(s):
>   Correlation:
>    1     2
> 2 0.487
> 3 0.597 0.440
> Variance function:
>   Structure: Different standard deviations per stratum
>   Formula: ~1 | time
>   Parameter estimates:
>         1        2        3
> 1.000000 1.347341 1.019529
> Fixed effects: score ~ timef - 1
>              Value   Std.Error   DF   t-value p-value
> timef1 -0.3846847 0.007627811 4421 -50.43186       0
> timef2 -0.2727646 0.012012786 4421 -22.70619       0
> timef3 -0.3961244 0.007180147 4421 -55.16939       0
>   Correlation:
>         timef1 timef2
> timef2 0.735
> timef3 0.746  0.670
>
> Standardized Within-Group Residuals:
>         Min         Q1        Med         Q3        Max
> -1.4659548 -0.5982929 -0.4096429  0.3101507  4.0911728
>
> Number of Observations: 4515
> Number of Groups: 92
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From rvaradhan at jhmi.edu  Fri Jun  1 22:43:55 2007
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Fri, 1 Jun 2007 16:43:55 -0400
Subject: [R] An extension of Gabriel's biplot
Message-ID: <001101c7a48d$929faaf0$7c94100a@win.ad.jhu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070601/5e8e4a4f/attachment.pl 

From Horace.Tso at pgn.com  Fri Jun  1 22:47:50 2007
From: Horace.Tso at pgn.com (Horace Tso)
Date: Fri, 01 Jun 2007 13:47:50 -0700
Subject: [R] Excel calling R functions
In-Reply-To: <46606517.9010902@wald.ucdavis.edu>
References: <465FDDDE0200006500005FCA@pgn.com>	<1180713593.5137.42.camel@localhost.localdomain>
	<46605C59.5060301@businessdecision.com><46605C59.5060301@businessdecision.com>
	<46606517.9010902@wald.ucdavis.edu>
Message-ID: <466023860200006500005FF3@pgn.com>

Thanks to Marc, Duncan, Tobias, Alberto. I'm aware of rcom and have in fact downloaded it somewhere. But unfortunately it won't work for me as I'm in a corporate environment and don't have admin rights to set up the R(D)COM (background) server. If there is a way to work around it, pls let me know.

Horace

 

>>> Duncan Temple Lang <dtemplelang at ucdavis.edu> 6/1/2007 11:27:35 AM >>>
And just for completeness for the thread,
there is the RDCOMServer package which has
a more general mechanism for making R
functionality available to other applications
that does not require writing R commands
but uses the language independent spirit of
DCOM.  And it also allows event handlers
for things like Excel actions to be written as R functions

Tobias Verbeke wrote:
> Marc Schwartz wrote:
>> On Fri, 2007-06-01 at 08:50 -0700, Horace Tso wrote:
>>> Hi folks,
>>>
>>> Is it possible to have Excel call a R function. If not, how about
>>> making Excel send off a command to call a R script and then read the
>>> result back into Excel.
>>>
>>> I know, I know, this should belong to some Excel forum, but i just try
>>> my luck here.
>>>
>>> Thanks in advance.
>>>
>>> Horace W. Tso
>>
>> See the R-Excel add-in linked from here:
>>
>>   http://www.sciviews.org/_rgui/projects/RDcom.html 
>>
> 
> Some of the files listed in the link on that page appear
> to be quite outdated. The following link brings you to
> the current portal of the R(D)COM server and the
> rcom package.
> 
> http://sunsite.univie.ac.at/rcom/ 
> 
> See the Excel heading for your question. You might be
> interested as well by the recent OpenOffice.org plugin
> (heading OOo).
> 
> HTH,
> Tobias
> 

-- 
Duncan Temple Lang                duncan at wald.ucdavis.edu 
Department of Statistics          work:  (530) 752-4782
4210 Mathematical Sciences Bldg.  fax:   (530) 752-7099
One Shields Ave.
University of California at Davis
Davis, CA 95616, USA


From sundar.dorai-raj at pdf.com  Fri Jun  1 22:54:46 2007
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Fri, 01 Jun 2007 13:54:46 -0700
Subject: [R] Opening Rgui by double-clicking R script
Message-ID: <46608796.2070801@pdf.com>

Hi, all,

This is for R-2.5.0 on WinXP and in particular RGui.

I'm trying to teach some colleagues of mine R and rather than impose 
Xemacs/ESS upon them I decided to simply start by showing them RGui. 
When R is installed, R workspaces (.RData) are automatically registered 
so that I can double-click on them in Explorer RGui opens with the 
correct working directory. However, I cannot figure a way to do the same 
for R scripts. In other words, I want to double-click on a .R file in 
Explorer, have RGui open, set the working directory to the location of 
where the script is saved, and load the script into the script editor. 
Is this possible?

Thanks,

--sundar


From guanrao at yahoo.com  Fri Jun  1 23:05:58 2007
From: guanrao at yahoo.com (Guanrao Chen)
Date: Fri, 1 Jun 2007 14:05:58 -0700 (PDT)
Subject: [R] What is the maximum size of a matrix?
Message-ID: <16488.13767.qm@web50603.mail.re2.yahoo.com>

hi, Rers

I tried to find out the max size (# of rows, # of
columns) of a matrix that is allowed by R but failed.

Can anybody let me know?

Thanks!
Guanrao


From bcarvalh at jhsph.edu  Fri Jun  1 23:38:07 2007
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Fri, 1 Jun 2007 17:38:07 -0400
Subject: [R] What is the maximum size of a matrix?
In-Reply-To: <16488.13767.qm@web50603.mail.re2.yahoo.com>
References: <16488.13767.qm@web50603.mail.re2.yahoo.com>
Message-ID: <27E8A6C2-EB01-4FBC-B1C6-D234603C3801@jhsph.edu>

AFAIK, it only depends on how much free memory you have.
b

On Jun 1, 2007, at 5:05 PM, Guanrao Chen wrote:

> hi, Rers
>
> I tried to find out the max size (# of rows, # of
> columns) of a matrix that is allowed by R but failed.
>
> Can anybody let me know?
>
> Thanks!
> Guanrao


From HDoran at air.org  Fri Jun  1 23:36:15 2007
From: HDoran at air.org (Doran, Harold)
Date: Fri, 1 Jun 2007 17:36:15 -0400
Subject: [R] What is the maximum size of a matrix?
In-Reply-To: <16488.13767.qm@web50603.mail.re2.yahoo.com>
Message-ID: <2323A6D37908A847A7C32F1E3662C80EBA0702@dc1ex01.air.org>

There is no maximum size. This will be driven by (at least) two issues.
First, how much memory you have on your own computer and second what
data you have in each cell. For instance, an integer takes less memory
than a floating point.

Other spreadsheet programs like excel limit the number of rows to 16^2
irrespective of memory, but that is not true here.

Harold


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Guanrao Chen
> Sent: Friday, June 01, 2007 5:06 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] What is the maximum size of a matrix?
> 
> hi, Rers
> 
> I tried to find out the max size (# of rows, # of
> columns) of a matrix that is allowed by R but failed.
> 
> Can anybody let me know?
> 
> Thanks!
> Guanrao
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From marc_schwartz at comcast.net  Sat Jun  2 00:23:31 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Fri, 01 Jun 2007 17:23:31 -0500
Subject: [R] What is the maximum size of a matrix?
In-Reply-To: <2323A6D37908A847A7C32F1E3662C80EBA0702@dc1ex01.air.org>
References: <2323A6D37908A847A7C32F1E3662C80EBA0702@dc1ex01.air.org>
Message-ID: <1180736611.5233.9.camel@localhost.localdomain>

Harold,

Actually there is a maximum size, even if one had sufficient memory.

Since a matrix is a vector with a dim attribute, and these objects are
indexed using integers, the maximum sized vector one 'could' create is:

> .Machine$integer.max
[1] 2147483647

which is:

> 2^31 - 1
[1] 2147483647

and that does not differ on 64 bit systems.

HTH,

Marc Schwartz


On Fri, 2007-06-01 at 17:36 -0400, Doran, Harold wrote:
> There is no maximum size. This will be driven by (at least) two issues.
> First, how much memory you have on your own computer and second what
> data you have in each cell. For instance, an integer takes less memory
> than a floating point.
> 
> Other spreadsheet programs like excel limit the number of rows to 16^2
> irrespective of memory, but that is not true here.
> 
> Harold
> 
> 
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch 
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Guanrao Chen
> > Sent: Friday, June 01, 2007 5:06 PM
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] What is the maximum size of a matrix?
> > 
> > hi, Rers
> > 
> > I tried to find out the max size (# of rows, # of
> > columns) of a matrix that is allowed by R but failed.
> > 
> > Can anybody let me know?
> > 
> > Thanks!
> > Guanrao
> >


From montez at bu.edu  Sat Jun  2 01:07:05 2007
From: montez at bu.edu (Maria Montez)
Date: Fri, 01 Jun 2007 16:07:05 -0700
Subject: [R] object not found inside function
Message-ID: <4660A699.1010304@bu.edu>

Hi!

When running the following code I get the message: Error in eval(expr, 
envir, enclos) : object "A" not found

fm <- function(p,ydata, env = parent.frame()) {
#fit model y ~ (b0+b1x1+...+bpxp)*exp(g2plus*z2plus) where bi and g2plus 
are parameters

  #create design matrix for linear part
  fo00 <- paste("~",paste(paste("x",1:p,sep=""),collapse="+"),sep="")
  fo0 <- as.formula(fo00)
  A <- model.matrix(fo0,data=ydata)

 # create z variable
  z2plus <- ifelse(totx>1,1,0)
  ydata <- data.frame(ydata,z2plus)

 #run model
  t2 <- nls(y ~ 
A*exp(g2plus*z2plus),data=ydata,start=c(g2plus=0),alg="plinear")
}
model <- fm(4,ydata)

The code inside the function works if not enclosed in a function. This 
makes me think that it is a scope problem and I need to specify the 
environment. Even though I've read about environment and lexical scope I 
still don't fully understand how it works. Sometimes I can do it others 
I can't!

Can someone help me?

I've included below code to create a dataframe that can be used to test 
my code.

Thanks, Maria

######################
ydata <-
structure(list(x1 = as.integer(c(1, 1, 1, 1, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1,
0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)), x2 = as.integer(c(0,
0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,
0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1,
1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1,
0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1,
0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,
0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0,
1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,
0, 1)), x3 = as.integer(c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)), x4 = as.integer(c(1, 0,
1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0,
0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0,
0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1,
1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1,
0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1,
1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1,
0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,
1)), y = c(6.395261598, 6.075346031, 6.396929655, 5.220355825,
6.703188113, 7.290974778, 6.779921908, 6.047372179, 5.837730447,
6.761572769, 6.597145702, 6.371611847, 7.19142933, 6.278521424,
6.646390515, 6.64898455, 6.200509174, 7.297768283, 6.64898455,
6.933423026, 6.666956792, 6.248042875, 6.673297968, 5.697093487,
7.216709487, 6.23636959, 6.643789733, 7.210818454, 5.988961417,
7.305188215, 6.22059017, 7.259116128, 6.613384218, 6.776506992,
6.901737207, 6.311734809, 6.073044534, 6.805722553, 6.921658184,
6.171700597, 6.478509642, 6.877296072, 6.309918278, 6.599870499,
6.173786104, 6.580639137, 6.293419279, 6.980075941, 6.937314081,
6.033086222, 6.64509097, 6.620073207, 6.33150185, 6.97354302,
6.620073207, 6.668228248, 7.153833802, 6.629363253, 6.573680167,
6.54534966, 6.768493212, 7.086737935, 6.144185634, 6.903747258,
7.500529485, 7.134093721, 6.363028104, 7.145984468, 7.355001921,
6.875232087, 6.849066283, 6.630683386, 6.899723107, 6.760414691,
6.154858094, 6.74051936, 5.609471795, 6.82437367, 6.825460036,
6.684611728, 6.610696045, 6.845879875, 6.64898455, 6.878326468,
6.931471806, 7.185387016, 6.858565035, 6.008813185, 7.111512117,
6.639875834, 6.694562059, 6.81014245, 7.617759577, 6.953684211,
6.368187186, 7.007600614, 6.302618976, 6.003887067, 6.56526497,
7.592366129, 7.512617545, 7.438971592, 6.49677499, 6.635946556,
6.771935556, 6.74051936, 6.708084084, 6.401917197, 7.412160335,
6.369900983, 6.822197391, 7.199678346, 6.415096959, 6.914730893,
7.204149292, 7.180831199, 7.17472431, 6.769641977, 6.726233402,
6.385194399, 6.901737207, 7.121252453, 6.672032946, 6.912742821,
7.037027615, 7.496097345, 7.015712421, 6.668228248, 7.074963198,
6.251903883, 6.391917113, 6.456769656, 6.426488458, 6.244166901,
6.56526497, 7.042286172, 6.677083461, 6.054439346, 6.282266747,
6.605297921, 6.326149473, 6.492239835, 6.368187186, 7.218909708,
7.003974137, 6.184148891, 6.622736324, 6.862757913, 7.069874129,
7.509883061), totx = as.integer(c(3, 2, 4, 3, 2, 2, 1, 2, 2,
1, 2, 2, 3, 2, 2, 2, 2, 2, 3, 3, 2, 2, 1, 2, 2, 2, 3, 2, 2, 2,
2, 3, 2, 3, 3, 1, 2, 3, 2, 2, 2, 3, 2, 2, 2, 1, 2, 4, 4, 3, 2,
3, 3, 3, 4, 3, 3, 2, 3, 3, 3, 4, 3, 4, 3, 4, 3, 4, 4, 3, 3, 2,
3, 2, 2, 2, 3, 3, 3, 3, 1, 3, 3, 4, 3, 3, 2, 3, 3, 3, 3, 2, 3,
3, 3, 3, 3, 1, 1, 3, 3, 2, 3, 2, 2, 1, 2, 2, 3, 3, 2, 3, 3, 3,
4, 4, 4, 2, 3, 3, 4, 3, 3, 3, 3, 3, 3, 4, 3, 2, 2, 2, 1, 3, 2,
1, 1, 1, 0, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 2)), z2plus = c(1,
1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,
1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
0, 1)), .Names = c("x1", "x2", "x3", "x4", "y", "totx", "z2plus"
), row.names = c("1", "2", "3", "4", "5", "6", "7", "8", "9",
"10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20",
"21", "22", "23", "24", "25", "26", "27", "28", "29", "30", "31",
"32", "33", "34", "35", "36", "37", "38", "39", "40", "41", "42",
"43", "44", "45", "46", "47", "48", "49", "50", "51", "52", "53",
"54", "55", "56", "57", "58", "59", "60", "61", "62", "63", "64",
"65", "66", "67", "68", "69", "70", "71", "72", "73", "74", "75",
"76", "77", "78", "79", "80", "81", "82", "83", "84", "85", "86",
"87", "88", "89", "90", "91", "92", "93", "94", "95", "96", "97",
"98", "99", "100", "101", "102", "103", "104", "105", "106",
"107", "108", "109", "110", "111", "112", "113", "114", "115",
"116", "117", "118", "119", "120", "121", "122", "123", "124",
"125", "126", "127", "128", "129", "130", "131", "132", "133",
"134", "135", "136", "137", "138", "139", "140", "141", "142",
"143", "144", "145", "146", "147", "148", "149", "150"), class = 
"data.frame")


From albmont at centroin.com.br  Sat Jun  2 01:19:59 2007
From: albmont at centroin.com.br (Alberto Vieira Ferreira Monteiro)
Date: Fri, 1 Jun 2007 23:19:59 +0000
Subject: [R] Windows source in Linux
Message-ID: <200706012320.00350.albmont@centroin.com.br>

I have a "windows" source file.r, with the default charset of windows.
I can't use it in Linux as source("file.r"), because Linux's default is
Unicode. How can I read it?

Alberto Monteiro


From mmeredith at wcs.org  Sat Jun  2 01:42:35 2007
From: mmeredith at wcs.org (Mike Meredith)
Date: Fri, 1 Jun 2007 16:42:35 -0700 (PDT)
Subject: [R] Getting names of objects passed with "..."
In-Reply-To: <971536df0706010849m2a1b9f87y68994229c37256bb@mail.gmail.com>
References: <10906614.post@talk.nabble.com>
	<59d7961d0706010158t5f1ff661r51c5675edefd4cb8@mail.gmail.com>
	<Pine.LNX.4.64.0706011007550.25961@gannet.stats.ox.ac.uk>
	<10910245.post@talk.nabble.com>
	<Pine.LNX.4.64.0706011431460.2100@gannet.stats.ox.ac.uk>
	<10913978.post@talk.nabble.com>
	<971536df0706010849m2a1b9f87y68994229c37256bb@mail.gmail.com>
Message-ID: <10922269.post@talk.nabble.com>


Sorry, I responded a bit too hastily last night, without testing the two
functions properly.

> Brian's is shorter but I think the one in my post is a bit more robust:

Indeed! 'f1' only works if at least one of the arguments is named. Otherwise
'nm' is NULL and 'nchar(nm[i])' fails. 'f2' seems to have all combinations
covered.  Thanks again!!

> f1 <- function(...) {
+    m <- as.list(match.call(expand.dots=TRUE))[-1]
+    nm <- names(m)
+    for(i in seq_along(m)) if(!nchar(nm[i])) nm[i] <- deparse(m[[i]])
+    nm
+ }
>
> f2 <- function(...) {
+ x <- list(...)
+ if (is.null(names(x))) names(x) <- ""
+ names(x)[names(x) == ""] <- NA
+ mc <- match.call()[-1]
+ ifelse(is.na(names(x)), as.character(mc), names(x))
+ }
>
> f1(sin, cos)
Error in if (!nchar(nm[i])) nm[i] <- deparse(m[[i]]) :
        argument is of length zero
> f2(sin, cos)
[1] "sin" "cos"

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



-- 
View this message in context: http://www.nabble.com/Getting-names-of-objects-passed-with-%22...%22-tf3850318.html#a10922269
Sent from the R help mailing list archive at Nabble.com.


From bcarvalh at jhsph.edu  Sat Jun  2 02:37:41 2007
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Fri, 1 Jun 2007 20:37:41 -0400
Subject: [R] Windows source in Linux
In-Reply-To: <200706012320.00350.albmont@centroin.com.br>
References: <200706012320.00350.albmont@centroin.com.br>
Message-ID: <DC073657-D1CE-4F83-A8CB-64C70A66BA65@jhsph.edu>

iconv on your linux box should do the work.
b

On Jun 1, 2007, at 7:19 PM, Alberto Vieira Ferreira Monteiro wrote:

> I have a "windows" source file.r, with the default charset of windows.
> I can't use it in Linux as source("file.r"), because Linux's  
> default is
> Unicode. How can I read it?
>
> Alberto Monteiro


From lee.kitty at yahoo.com  Sat Jun  2 03:06:48 2007
From: lee.kitty at yahoo.com (Kitty Lee)
Date: Fri, 1 Jun 2007 18:06:48 -0700 (PDT)
Subject: [R] spatial simulation
Message-ID: <327418.72900.qm@web36301.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070601/a874a066/attachment.pl 

From albmont at centroin.com.br  Sat Jun  2 03:36:27 2007
From: albmont at centroin.com.br (Alberto Vieira Ferreira Monteiro)
Date: Sat, 2 Jun 2007 01:36:27 +0000
Subject: [R] Windows source in Linux
In-Reply-To: <DC073657-D1CE-4F83-A8CB-64C70A66BA65@jhsph.edu>
References: <200706012320.00350.albmont@centroin.com.br>
	<DC073657-D1CE-4F83-A8CB-64C70A66BA65@jhsph.edu>
Message-ID: <200706020136.28254.albmont@centroin.com.br>

Benilton Carvalho wrote:
>
> iconv on your linux box should do the work.
>
>> I have a "windows" source file.r, with the default charset of windows.
>> I can't use it in Linux as source("file.r"), because Linux's
>> default is
>> Unicode. How can I read it?
>
Soon after I posted, I found out how to do it.

source("file.r", encoding="latin1")

Anyway, thanks to the hint about iconv. I tried to find something like
that using "apropos latin", but iconv was not there.

Alberto Monteiro


From adschai at optonline.net  Sat Jun  2 05:32:46 2007
From: adschai at optonline.net (adschai at optonline.net)
Date: Sat, 02 Jun 2007 03:32:46 +0000 (GMT)
Subject: [R] setClass with a slot of RODBC
Message-ID: <e412b69528fcd.4660e4de@optonline.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070602/5db9ea74/attachment.pl 

From adschai at optonline.net  Sat Jun  2 05:49:59 2007
From: adschai at optonline.net (adschai at optonline.net)
Date: Sat, 02 Jun 2007 03:49:59 +0000 (GMT)
Subject: [R] Question regarding Johansen's cointegration testing
Message-ID: <f82dcc4f2d15d.4660e8e7@optonline.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070602/f283a390/attachment.pl 

From ripley at stats.ox.ac.uk  Sat Jun  2 08:14:24 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 2 Jun 2007 07:14:24 +0100 (BST)
Subject: [R] What is the maximum size of a matrix?
In-Reply-To: <1180736611.5233.9.camel@localhost.localdomain>
References: <2323A6D37908A847A7C32F1E3662C80EBA0702@dc1ex01.air.org>
	<1180736611.5233.9.camel@localhost.localdomain>
Message-ID: <Pine.LNX.4.64.0706020706320.28095@gannet.stats.ox.ac.uk>

Thanks Marc.  The information is in help("Memory-limits").

We are aware that at some point we will need to raise this limit and have 
discussed ways to do so.  But it is not going to be an issue for a while: 
working with 16Gb objects needs the sort of amount of memory that will not 
become common for anouther 5 years or so.

On Fri, 1 Jun 2007, Marc Schwartz wrote:

> Harold,
>
> Actually there is a maximum size, even if one had sufficient memory.
>
> Since a matrix is a vector with a dim attribute, and these objects are
> indexed using integers, the maximum sized vector one 'could' create is:
>
>> .Machine$integer.max
> [1] 2147483647
>
> which is:
>
>> 2^31 - 1
> [1] 2147483647
>
> and that does not differ on 64 bit systems.
>
> HTH,
>
> Marc Schwartz
>
>
> On Fri, 2007-06-01 at 17:36 -0400, Doran, Harold wrote:
>> There is no maximum size. This will be driven by (at least) two issues.
>> First, how much memory you have on your own computer and second what
>> data you have in each cell. For instance, an integer takes less memory
>> than a floating point.
>>
>> Other spreadsheet programs like excel limit the number of rows to 16^2
>> irrespective of memory, but that is not true here.
>>
>> Harold
>>
>>
>>> -----Original Message-----
>>> From: r-help-bounces at stat.math.ethz.ch
>>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Guanrao Chen
>>> Sent: Friday, June 01, 2007 5:06 PM
>>> To: r-help at stat.math.ethz.ch
>>> Subject: [R] What is the maximum size of a matrix?
>>>
>>> hi, Rers
>>>
>>> I tried to find out the max size (# of rows, # of
>>> columns) of a matrix that is allowed by R but failed.
>>>
>>> Can anybody let me know?
>>>
>>> Thanks!
>>> Guanrao
>>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Sat Jun  2 08:21:52 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 2 Jun 2007 07:21:52 +0100 (BST)
Subject: [R] Beginners Question
In-Reply-To: <46607226.5070704@thomas-zastrow.de>
References: <46607226.5070704@thomas-zastrow.de>
Message-ID: <Pine.LNX.4.64.0706020717420.28095@gannet.stats.ox.ac.uk>

That two distances are the same is *not* what the message says.

You can't just look at elements of the results of dist() and simply relate 
them back to object numbers.  Try as.matrix(x.dist) for a human-readable 
form.


On Fri, 1 Jun 2007, Thomas Zastrow wrote:

> Dear all,
>
> I'm completely new to R and at first I must say that it is a great program!
>
> But I have a problem with the function isoMDS from the MASS package. I
> have this code which I load with source() from a file:
>
> x <- c(163.59514923926784, 150.01448475257115, ...... {here are some
> more values})
> x.sort <- sort(x)
> x.dist <- dist(x.sort)
> library(MASS)
> x.mds <- isoMDS(x.dist)
> plot(x.mds$points, type="n")
> text(x.mds$points, labels=as.character("x"))
>
> The problem is in the line where the isoMDS function is applied: I got
> the error:
>
> Fehler in isoMDS(x.dist) : zero or negative distance between objects 9
> and 10
>
> When I look at values 8 and 9 of x.dist, I see that they have the same
> values (I'm not wrong, it's values of 8 and 9 and not 9 and 10):
>
> x.dist[8:9]
> [1] 39.8214  39.8214
>
> So, just to give'm a try, I changed the value of x.dist[8]:
>
> x.dist[8] <- c(39.7)
>
> Now, there are defintitely different values in this part of x.dist:
>
> x.dist[7:10]
> [1] 39.69898     39.70000      39.82140      39.98892
>
> But when I start isoMDS again, I got again the error:
>
> x.mds <- isoMDS(x.dist)
> Fehler in isoMDS(x.dist) : zero or negative distance between objects 9
> and 10
>
>
> So, where's my error?
>
> Thank you!
>
> Best,
>
> Tom
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ted.harding at nessie.mcc.ac.uk  Sat Jun  2 09:33:21 2007
From: ted.harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sat, 02 Jun 2007 08:33:21 +0100 (BST)
Subject: [R] spatial simulation
In-Reply-To: <327418.72900.qm@web36301.mail.mud.yahoo.com>
Message-ID: <XFMail.070602083321.ted.harding@nessie.mcc.ac.uk>

On 02-Jun-07 01:06:48, Kitty Lee wrote:
> Dear R-users,
> 
> I'm trying to do some spatial simulation. I have two covariates,
> Z and C. I want to examine their relationship under different
> spatial distribution. 
> 
> I have no problem simulating completely spatial random process
> but I'm totally stuck on poisson (cluster) pattern. I already
> have a dataset with Z and C (obs=575) and I know the relationship
> between them. Using these 575 cases, how can I simulate a clustered
> process and have a dataset that has four columns:
> 
> x-coor y-coor z c
> 
> I know I can use rpois or pcp.sim to generate points that clustered
> and then use cbind to attach Z and C values. But the problem is my
> observations will not be spatially clustered. How can I simulate so
> that now Z is spatially clustered?
> 
> Thanks!
> 
> K.

Have a look at the package spatstat:

Description:   Spatial Point Pattern data analysis, modelling and
               simulation including multitype/marked points and
               spatial covariates

It has a flexible repertoire of spatial point processes that you
can simulate from.

Best wishes,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 02-Jun-07                                       Time: 08:33:17
------------------------------ XFMail ------------------------------


From Roger.Bivand at nhh.no  Sat Jun  2 14:35:30 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 2 Jun 2007 14:35:30 +0200 (CEST)
Subject: [R] spatial simulation
In-Reply-To: <327418.72900.qm@web36301.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.44.0706021419120.25450-100000@reclus.nhh.no>

On Fri, 1 Jun 2007, Kitty Lee wrote:

> Dear R-users,
> 
> I'm trying to do some spatial simulation. I have two covariates, Z and
> C. I want to examine their relationship under different spatial
> distribution.
> 
> I have no problem simulating completely spatial random process but I'm
> totally stuck on poisson (cluster) pattern. I already have a dataset
> with Z and C (obs=575) and I know the relationship between them. Using
> these 575 cases, how can I simulate a clustered process and have a
> dataset that has four columns:
> 
> x-coor y-coor z c
> 
> I know I can use rpois or pcp.sim to generate points that clustered and
> then use cbind to attach Z and C values. But the problem is my
> observations will not be spatially clustered. How can I simulate so that
> now Z is spatially clustered?

Although you are not being very clear, I think that unless both Z and C
are marked point processes (ie. both take (discrete) values and are
observed at different points), this is not a spatial point process
problem. If Z and C are observed at the same points, and what you are
looking for are clusters of correlated values of Z with C, the clusters
are not the locations of the points, but rather the co-occurrence of
high/low values of Z and C respectively. How to go forward from here would
depend on what kind of process you are actually interested in. More 
detail might help - as might following up on R-sig-geo, rather than on the 
general list. 

> 
> Thanks!
> 
> K.
>  
>        
> ---------------------------------
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From daj025 at gmail.com  Sat Jun  2 16:32:47 2007
From: daj025 at gmail.com (David James)
Date: Sat, 2 Jun 2007 10:32:47 -0400
Subject: [R] setClass with a slot of RODBC
In-Reply-To: <e412b69528fcd.4660e4de@optonline.net>
References: <e412b69528fcd.4660e4de@optonline.net>
Message-ID: <74c69e370706020732r717cbce5o6494976b025aa03b@mail.gmail.com>

Hi,

A couple of thoughts:

(1) The channel RODBC is an S3 object, thus there's no proper S4 class
associated with it.  From  ?setOldClass:
....
Description:

     Register an old-style (a.k.a. `S3') class as a formally defined
     class. The 'Classes' argument is the character vector used as the
     'class' attribute; in particular, if there is more than one
     string,  old-style class inheritance is mimicked.  Registering via
     'setOldClass' allows S3 classes to appear  in method signatures,
     and as a slot in an S4 class if a prototype is included.
...

(2) This question may be more appropriate for r-devel?

HTH,

--
David


On 6/1/07, adschai at optonline.net <adschai at optonline.net> wrote:
> Hi - I tried to get some answer before but there seems to have no one response. My question is that I have a class like below definition:
>
> setClass("DBManager",
>    representation(channel="RODBC"))
>
> My purpose of the conn slot is to hold a channel to database connection which is returned by a command like:
>
> channel <- odbcConnect("DB", uid="user", pwd="password")
>
> According to RODBC documentation, this channel is supposed to have a type of "RODBC". However, if I declare my class as above, R will complain that it does not know about "RODBC" type or class. Please clarify. Thank you.
>
> - adschai
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From HDoran at air.org  Sat Jun  2 16:50:02 2007
From: HDoran at air.org (Doran, Harold)
Date: Sat, 2 Jun 2007 10:50:02 -0400
Subject: [R] What is the maximum size of a matrix?
References: <2323A6D37908A847A7C32F1E3662C80EBA0702@dc1ex01.air.org>
	<1180736611.5233.9.camel@localhost.localdomain>
Message-ID: <2323A6D37908A847A7C32F1E3662C80EB5E683@dc1ex01.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070602/5bfbcb55/attachment.pl 

From mister_bluesman at hotmail.com  Sat Jun  2 17:06:17 2007
From: mister_bluesman at hotmail.com (mister_bluesman)
Date: Sat, 2 Jun 2007 08:06:17 -0700 (PDT)
Subject: [R] Datapoints underneath datapoints Problem
Message-ID: <10928148.post@talk.nabble.com>


Hi there.

I have the following graph:

http://www.nabble.com/file/p10928148/map.jpg 

However, some datapoints occur at the same place as other datapoints and are
so layered on top of each other. I would like to know if there is any
possible way in which I could view those datapoints that are layered on top
of each other ...maybe by rotating using latitude to show the datapoints
underneath (but then is that possible?)??? - just an idea.

Many thanks.

Sam.
-- 
View this message in context: http://www.nabble.com/Datapoints-underneath-datapoints-Problem-tf3857288.html#a10928148
Sent from the R help mailing list archive at Nabble.com.


From ligges at statistik.uni-dortmund.de  Sat Jun  2 17:22:16 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 02 Jun 2007 17:22:16 +0200
Subject: [R] object not found inside function
In-Reply-To: <4660A699.1010304@bu.edu>
References: <4660A699.1010304@bu.edu>
Message-ID: <46618B28.2010709@statistik.uni-dortmund.de>

Maria Montez wrote:
> Hi!
> 
> When running the following code I get the message: Error in eval(expr, 
> envir, enclos) : object "A" not found
> 
> fm <- function(p,ydata, env = parent.frame()) {
> #fit model y ~ (b0+b1x1+...+bpxp)*exp(g2plus*z2plus) where bi and g2plus 
> are parameters
> 
>   #create design matrix for linear part
>   fo00 <- paste("~",paste(paste("x",1:p,sep=""),collapse="+"),sep="")
>   fo0 <- as.formula(fo00)
>   A <- model.matrix(fo0,data=ydata)
> 
>  # create z variable
>   z2plus <- ifelse(totx>1,1,0)
>   ydata <- data.frame(ydata,z2plus)
> 
>  #run model
>   t2 <- nls(y ~ 
> A*exp(g2plus*z2plus),data=ydata,start=c(g2plus=0),alg="plinear")
> }
> model <- fm(4,ydata)
> 
> The code inside the function works if not enclosed in a function. This 
> makes me think that it is a scope problem and I need to specify the 
> environment. Even though I've read about environment and lexical scope I 
> still don't fully understand how it works. Sometimes I can do it others 
> I can't!
> 
> Can someone help me?
> 
> I've included below code to create a dataframe that can be used to test 
> my code.
> 
> Thanks, Maria
>

[data deleted]

Maria,

1. Do you really want to paste() the formula fo0 together that way?
2. For me, the functions fails because totx is not known. Please make 
sure to post *reproducible* code (OK, you almost did).
3. If totx is known, the function works for me, hence I guess you are 
using an outdated version (< 2.5.0) of R. --> Please always specify the 
version of R and the OS you are using.

Uwe


From ligges at statistik.uni-dortmund.de  Sat Jun  2 17:29:26 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 02 Jun 2007 17:29:26 +0200
Subject: [R] Datapoints underneath datapoints Problem
In-Reply-To: <10928148.post@talk.nabble.com>
References: <10928148.post@talk.nabble.com>
Message-ID: <46618CD6.6010306@statistik.uni-dortmund.de>



mister_bluesman wrote:
> Hi there.
> 
> I have the following graph:
> 
> http://www.nabble.com/file/p10928148/map.jpg 
> 
> However, some datapoints occur at the same place as other datapoints and are
> so layered on top of each other. I would like to know if there is any
> possible way in which I could view those datapoints that are layered on top
> of each other ...maybe by rotating using latitude to show the datapoints
> underneath (but then is that possible?)??? - just an idea.
> 
> Many thanks.
> 
> Sam.


You can use common techniques such as jitter() or transparency (alpha 
shading), depending on the amount of datapoints that are layered on top
of each other.

Of course, you can also rotate the data, but then you will have to 
decide which way makes sense - and you have to add some randomness as 
well, or two points will be rotated to the same new coordinates unless 
there is another variable that will cause a difference.


Uwe Ligges


From mister_bluesman at hotmail.com  Sat Jun  2 17:53:35 2007
From: mister_bluesman at hotmail.com (mister_bluesman)
Date: Sat, 2 Jun 2007 08:53:35 -0700 (PDT)
Subject: [R] Datapoints underneath datapoints Problem
In-Reply-To: <46618CD6.6010306@statistik.uni-dortmund.de>
References: <10928148.post@talk.nabble.com>
	<46618CD6.6010306@statistik.uni-dortmund.de>
Message-ID: <10928629.post@talk.nabble.com>




Uwe Ligges wrote:
> 
> Of course, you can also rotate the data, but then you will have to 
> decide which way makes sense - and you have to add some randomness as 
> well, or two points will be rotated to the same new coordinates unless 
> there is another variable that will cause a difference.
> 

Do you know of any functions/tutorials that will show me how to do this? I
dont even know how to rotate the plot!

Many thanks!
-- 
View this message in context: http://www.nabble.com/Datapoints-underneath-datapoints-Problem-tf3857288.html#a10928629
Sent from the R help mailing list archive at Nabble.com.


From philipp.pagel.lists at t-online.de  Sat Jun  2 17:57:01 2007
From: philipp.pagel.lists at t-online.de (Philipp Pagel)
Date: Sat, 2 Jun 2007 17:57:01 +0200
Subject: [R] Datapoints underneath datapoints Problem
In-Reply-To: <10928148.post@talk.nabble.com>
References: <10928148.post@talk.nabble.com>
Message-ID: <20070602155701.GA31498@gsf.de>


> I would like to know if there is any
> possible way in which I could view those datapoints that are layered on top
> of each other

You could use jitter() to add a little noise to the data. Of course that
will slightly change the position of each point.

If that is not an option you could possibly detect points with almost
identical coordintes yourself and then change the color of the
respective plotting symbol.

cu
	Philipp

-- 
Dr. Philipp Pagel                            Tel.  +49-8161-71 2131
Dept. of Genome Oriented Bioinformatics      Fax.  +49-8161-71 2186
Technical University of Munich
Science Center Weihenstephan
85350 Freising, Germany

 and

Institute for Bioinformatics / MIPS          Tel.  +49-89-3187 3675
GSF - National Research Center               Fax.  +49-89-3187 3585
      for Environment and Health
Ingolst?dter Landstrasse 1
85764 Neuherberg, Germany
http://mips.gsf.de/staff/pagel


From mister_bluesman at hotmail.com  Sat Jun  2 18:15:41 2007
From: mister_bluesman at hotmail.com (mister_bluesman)
Date: Sat, 2 Jun 2007 09:15:41 -0700 (PDT)
Subject: [R] Datapoints underneath datapoints Problem
In-Reply-To: <20070602155701.GA31498@gsf.de>
References: <10928148.post@talk.nabble.com> <20070602155701.GA31498@gsf.de>
Message-ID: <10928828.post@talk.nabble.com>



Philipp Pagel-2 wrote:
> 
> 
> If that is not an option you could possibly detect points with almost
> identical coordintes yourself and then change the color of the
> respective plotting symbol.
> 

That's a good idea. But my the coordinates are calculated through use of the
cmscale multidimensional scaling function and i dont know how to extract the
coordinates of each point plotted.
-- 
View this message in context: http://www.nabble.com/Datapoints-underneath-datapoints-Problem-tf3857288.html#a10928828
Sent from the R help mailing list archive at Nabble.com.


From ggrothendieck at gmail.com  Sat Jun  2 18:24:01 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 2 Jun 2007 12:24:01 -0400
Subject: [R] Datapoints underneath datapoints Problem
In-Reply-To: <10928148.post@talk.nabble.com>
References: <10928148.post@talk.nabble.com>
Message-ID: <971536df0706020924s52935da4pddfb7f66dfd3da6@mail.gmail.com>

Check out ?sunflowerplot


On 6/2/07, mister_bluesman <mister_bluesman at hotmail.com> wrote:
>
> Hi there.
>
> I have the following graph:
>
> http://www.nabble.com/file/p10928148/map.jpg
>
> However, some datapoints occur at the same place as other datapoints and are
> so layered on top of each other. I would like to know if there is any
> possible way in which I could view those datapoints that are layered on top
> of each other ...maybe by rotating using latitude to show the datapoints
> underneath (but then is that possible?)??? - just an idea.
>
> Many thanks.
>
> Sam.
> --
> View this message in context: http://www.nabble.com/Datapoints-underneath-datapoints-Problem-tf3857288.html#a10928148
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From hassen62 at voila.fr  Sat Jun  2 18:56:38 2007
From: hassen62 at voila.fr (hassen62 at voila.fr)
Date: Sat,  2 Jun 2007 18:56:38 +0200 (CEST)
Subject: [R] Problem with the command "StrucTS" that fits a basic structural
 model for time series
Message-ID: <8872978.60501180803398500.JavaMail.www@wwinf4103>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070602/7312160c/attachment.pl 

From ggrothendieck at gmail.com  Sat Jun  2 19:10:29 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 2 Jun 2007 13:10:29 -0400
Subject: [R] Problem with the command "StrucTS" that fits a basic
	structural model for time series
In-Reply-To: <8872978.60501180803398500.JavaMail.www@wwinf4103>
References: <8872978.60501180803398500.JavaMail.www@wwinf4103>
Message-ID: <971536df0706021010v500adf58u7bb906bc35612ad4@mail.gmail.com>

Your frequency is 1.  Suppose it were 3 :

> (fit <- StructTS(ts(x, freq = 3),type = "BSM"))

Call:
StructTS(x = ts(x, freq = 3), type = "BSM")

Variances:
  level    slope     seas  epsilon
 3.0225   0.0000   0.1617  18.0978

On 6/2/07, hassen62 at voila.fr <hassen62 at voila.fr> wrote:
> Hi everybody,
> I'am very interested with the basic structural model of time series. So I used the command "StructTS" but I failed to obtain a desirable output, in fact when I write in R Console the following lines:
> > x=(1,2,3,4,5,2,25,14,12,13,11,6,9,24,12,13,14,12,12,14,11,12,14,15,20,21,22,23,21,25,28)
> >(fit <- StructTS(x,type = "BSM"))
> I obtained the following message:"error in makeBSM(x, nf): the frequency has to be  positif  entire for BSM"
> I would like via this command(StrucTS) obtain estimation of seasonality and local level trend components of the time series "x".
> Can you help me please . Thanks.
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From hassen62 at voila.fr  Sat Jun  2 19:13:49 2007
From: hassen62 at voila.fr (hassen62 at voila.fr)
Date: Sat,  2 Jun 2007 19:13:49 +0200 (CEST)
Subject: [R] Problem with reading a file.xls
Message-ID: <14913482.231180804429857.JavaMail.www@wwinf4103>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070602/cd347ab5/attachment.pl 

From Mitchell.Wachtel at ttuhsc.edu  Sat Jun  2 20:45:32 2007
From: Mitchell.Wachtel at ttuhsc.edu (Wachtel, Mitchell)
Date: Sat, 2 Jun 2007 13:45:32 -0500
Subject: [R] Harrell's C
Message-ID: <1A2BCA4266504B4CA543403718A81FD25E45B6@TRAVIS.ttuhsc.edu>

R will not let me load Design or Hmisc anymore. I need to calculate Harrell's C for some survival analyses. Can anyone provide an R formula for Harrell's C?
With kindest regards.
Mitchell Wachtel, MD


From mister_bluesman at hotmail.com  Sat Jun  2 20:49:23 2007
From: mister_bluesman at hotmail.com (mister_bluesman)
Date: Sat, 2 Jun 2007 11:49:23 -0700 (PDT)
Subject: [R] Problem with reading a file.xls
In-Reply-To: <14913482.231180804429857.JavaMail.www@wwinf4103>
References: <14913482.231180804429857.JavaMail.www@wwinf4103>
Message-ID: <10930131.post@talk.nabble.com>


may be because you need use

C:\\programfiles\\R 2.4.0


friend wrote:
> 
> Hi friends,
> I have a file.xls entitled "Dali" which is composed of two columns: the
> first is entitled "imp" and the  second is entitled:"exp".  I putted The
> file "Dali" in the following way:C:/programfiles/R 2.4.0. I can't read
> this file from R console. What can I do? thanks.
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/Problem-with-reading-a-file.xls-tf3857721.html#a10930131
Sent from the R help mailing list archive at Nabble.com.


From friendly at yorku.ca  Sat Jun  2 21:14:43 2007
From: friendly at yorku.ca (Michael Friendly)
Date: Sat, 02 Jun 2007 15:14:43 -0400
Subject: [R] mahalanobis
In-Reply-To: <afea0ae80705310932q29587118l60cacec862535fb1@mail.gmail.com>
References: <afea0ae80705310932q29587118l60cacec862535fb1@mail.gmail.com>
Message-ID: <4661C1A3.9040609@yorku.ca>

Yianni

You probably would have gotten more helpful replies if you indicated
the substantiative problem you were trying to solve.

 From your description, it seems like you want to calculate
leverage of predictors, (X1, X2) in the lm( y ~ X1+X2).
My crystal ball says you may be an SPSS user, for whom
mahalanobis D^2 of the predictors is what you have to beg
for to get leverages.  In R, you will get the most happiness
from
?leverage.plot
in the car package.

mahalanobois D^2 are proportional to leverage.

-Michael


gatemaze at gmail.com wrote:
> Hi, I am not sure I am using correctly the mahalanobis distnace method...
> Suppose I have a response variable Y and predictor variables X1 and X2
> 
> all <- cbind(Y, X1, X2)
> mahalanobis(all, colMeans(all), cov(all));
> 
> However, my results from this are different from the ones I am getting
> using another statistical software.
> 
> I was reading that the comparison is with the means of the predictor
> variables which led me to think that the above should be transformed
> into:
> 
> predictors <- cbind(X1, X2)
> mahalanobis(all, colMeans(predictors), cov(all))
> 
> But still the results are different....
> 
> Am I doing something wrong or have I misunderstood something in the
> use of the function mahalanobis? Thanks.
> 

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA


From pwang at berkeley.edu  Sat Jun  2 21:15:26 2007
From: pwang at berkeley.edu (Patrick Wang)
Date: Sat, 2 Jun 2007 12:15:26 -0700 (PDT)
Subject: [R] How to use density function to find h_{k}
Message-ID: <51385.76.169.69.87.1180811726.squirrel@calmail.berkeley.edu>

Hi, All:

How can I use the density function to find the minimum of the bandwidth
make the
density function one mode, 2 mode, 3 mode etc.

It will be impossible to try all possible bandwidths to then plot the pdf
to see how many modes it has. Is there an automatic way to do this

Like for loop 1000, try bandwidth from (0, 1). is there a function to get
how many modes from the density function?

Thanks
pat


From friendly at yorku.ca  Sat Jun  2 21:14:43 2007
From: friendly at yorku.ca (Michael Friendly)
Date: Sat, 02 Jun 2007 15:14:43 -0400
Subject: [R] mahalanobis
In-Reply-To: <afea0ae80705310932q29587118l60cacec862535fb1@mail.gmail.com>
References: <afea0ae80705310932q29587118l60cacec862535fb1@mail.gmail.com>
Message-ID: <4661C1A3.9040609@yorku.ca>

Yianni

You probably would have gotten more helpful replies if you indicated
the substantiative problem you were trying to solve.

 From your description, it seems like you want to calculate
leverage of predictors, (X1, X2) in the lm( y ~ X1+X2).
My crystal ball says you may be an SPSS user, for whom
mahalanobis D^2 of the predictors is what you have to beg
for to get leverages.  In R, you will get the most happiness
from
?leverage.plot
in the car package.

mahalanobois D^2 are proportional to leverage.

-Michael


gatemaze at gmail.com wrote:
> Hi, I am not sure I am using correctly the mahalanobis distnace method...
> Suppose I have a response variable Y and predictor variables X1 and X2
> 
> all <- cbind(Y, X1, X2)
> mahalanobis(all, colMeans(all), cov(all));
> 
> However, my results from this are different from the ones I am getting
> using another statistical software.
> 
> I was reading that the comparison is with the means of the predictor
> variables which led me to think that the above should be transformed
> into:
> 
> predictors <- cbind(X1, X2)
> mahalanobis(all, colMeans(predictors), cov(all))
> 
> But still the results are different....
> 
> Am I doing something wrong or have I misunderstood something in the
> use of the function mahalanobis? Thanks.
> 

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA


From scame at fastmail.fm  Sat Jun  2 22:42:27 2007
From: scame at fastmail.fm (Rehceb Rotkiv)
Date: Sat, 2 Jun 2007 13:42:27 -0700 (PDT)
Subject: [R] Calculating column percentages of a table
Message-ID: <10931035.post@talk.nabble.com>


Hello,

I know, this is a real newbie question, but I can't find anything on this in
the manuals! I know that I get calculate the column totals of a table with
`apply(mytable, 2, sum)'. Now I want each column total to be 100% and
calculate the percentage of each field of the column. How would I do that?
Rcommander, the ultimate newb-tool, has a function `colPercents' which is
exactly what I need, but I do not want to load the whole thing into memory
just for this function. Is there a way to load just this single function
from the Rcmdr package?

Many thanks,
Rehceb Rotkiv
-- 
View this message in context: http://www.nabble.com/Calculating-column-percentages-of-a-table-tf3858317.html#a10931035
Sent from the R help mailing list archive at Nabble.com.


From ccleland at optonline.net  Sat Jun  2 23:07:59 2007
From: ccleland at optonline.net (Chuck Cleland)
Date: Sat, 02 Jun 2007 17:07:59 -0400
Subject: [R] Calculating column percentages of a table
In-Reply-To: <10931035.post@talk.nabble.com>
References: <10931035.post@talk.nabble.com>
Message-ID: <4661DC2F.1090009@optonline.net>

Rehceb Rotkiv wrote:
> Hello,
> 
> I know, this is a real newbie question, but I can't find anything on this in
> the manuals! I know that I get calculate the column totals of a table with
> `apply(mytable, 2, sum)'. Now I want each column total to be 100% and
> calculate the percentage of each field of the column. How would I do that?
> Rcommander, the ultimate newb-tool, has a function `colPercents' which is
> exactly what I need, but I do not want to load the whole thing into memory
> just for this function. Is there a way to load just this single function
> from the Rcmdr package?

  Does this help?

> mymat <- matrix(sample(1:10, 40, replace=TRUE), ncol=4)

> mymat
      [,1] [,2] [,3] [,4]
 [1,]    9    2    5    8
 [2,]    8    5    2    3
 [3,]    4    1    5    8
 [4,]    9    8    6    7
 [5,]    7   10    7   10
 [6,]    1    9    5    4
 [7,]   10   10    1    3
 [8,]    5    3    5    7
 [9,]    6    1    8    6
[10,]    1    6   10    9

> prop.table(mymat, margin=2)*100
           [,1]      [,2]      [,3]      [,4]
 [1,] 15.000000  3.636364  9.259259 12.307692
 [2,] 13.333333  9.090909  3.703704  4.615385
 [3,]  6.666667  1.818182  9.259259 12.307692
 [4,] 15.000000 14.545455 11.111111 10.769231
 [5,] 11.666667 18.181818 12.962963 15.384615
 [6,]  1.666667 16.363636  9.259259  6.153846
 [7,] 16.666667 18.181818  1.851852  4.615385
 [8,]  8.333333  5.454545  9.259259 10.769231
 [9,] 10.000000  1.818182 14.814815  9.230769
[10,]  1.666667 10.909091 18.518519 13.846154

> colSums(prop.table(mymat, margin=2)*100)
[1] 100 100 100 100

> Many thanks,
> Rehceb Rotkiv

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From naik.raghu at gmail.com  Sat Jun  2 23:13:10 2007
From: naik.raghu at gmail.com (Raghu Naik)
Date: Sat, 2 Jun 2007 17:13:10 -0400
Subject: [R] Updating R version
Message-ID: <c98270fd0706021413i3d1e31f9q524865f88c7b491b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070602/2ac63400/attachment.pl 

From f.harrell at vanderbilt.edu  Sun Jun  3 00:01:23 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Sat, 02 Jun 2007 17:01:23 -0500
Subject: [R] Harrell's C
In-Reply-To: <1A2BCA4266504B4CA543403718A81FD25E45B6@TRAVIS.ttuhsc.edu>
References: <1A2BCA4266504B4CA543403718A81FD25E45B6@TRAVIS.ttuhsc.edu>
Message-ID: <4661E8B3.7080205@vanderbilt.edu>

Wachtel, Mitchell wrote:
> R will not let me load Design or Hmisc anymore. I need to calculate Harrell's C for some survival analyses. Can anyone provide an R formula for Harrell's C?
> With kindest regards.
> Mitchell Wachtel, MD

You provided very little information.  We have had no reports of Hmisc 
not loading under Windows but Design is not currently available for 
Windows for R 2.5.  We are working to fix that.

Frank
-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From Bernard.Colin at USherbrooke.ca  Sun Jun  3 00:34:51 2007
From: Bernard.Colin at USherbrooke.ca (Bernard Colin)
Date: Sat,  2 Jun 2007 18:34:51 -0400
Subject: [R] Re : I need some help please!
Message-ID: <1180823691.4661f08b460a8@www.usherbrooke.ca>


To whom it may concern,

I want to plot two or more graphics in the same window by the means of the
"plot" command. To do that, I have tried the "add=TRUE" option, but this last
one does not work! Do you have an hint for me please?

Thank you very much for your attention.

Bernard Colin

Departement of Mathematics
Faculty of Sciences
Sherbrooke University
Sherbrooke (Quebec) Canada
e-mail : bernard.colin at usherbrooke.ca


From soarealin at gmail.com  Sun Jun  3 00:43:55 2007
From: soarealin at gmail.com (Soare Marcian-Alin)
Date: Sun, 3 Jun 2007 00:43:55 +0200
Subject: [R] canoncial correlation
In-Reply-To: <255640f90705261100q6ff74856ie9bd97ff50aec328@mail.gmail.com>
References: <255640f90705261100q6ff74856ie9bd97ff50aec328@mail.gmail.com>
Message-ID: <255640f90706021543m2b527e0x50712a3941b8cd01@mail.gmail.com>

Ein eingebundener Text mit undefiniertem Zeichensatz wurde abgetrennt.
Name: nicht verf?gbar
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20070603/dc22d73e/attachment.pl 

From cberry at tajo.ucsd.edu  Sun Jun  3 01:07:18 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Sat, 2 Jun 2007 16:07:18 -0700
Subject: [R] Harrell's C
In-Reply-To: <4661E8B3.7080205@vanderbilt.edu>
References: <1A2BCA4266504B4CA543403718A81FD25E45B6@TRAVIS.ttuhsc.edu>
	<4661E8B3.7080205@vanderbilt.edu>
Message-ID: <Pine.LNX.4.64.0706021559330.14763@tajo.ucsd.edu>



Frank,

I am (happily) using Design on Windows XP, R-2.5.0.

I do get some warnings like this:

 	use of storage.mode(x) <- "single" is deprecated: use mode<- instead

but functionally all seems fine.


> sessionInfo()
R version 2.5.0 (2007-04-23)
i386-pc-mingw32

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
States.1252;LC_MONETARY=English_United 
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] "splines"   "stats"     "graphics"  "grDevices" "utils"     "datasets" 
"methods"   "base"

other attached packages:
    Design  survival     Hmisc   acepack
  "2.0-12"    "2.31"   "3.3-1" "1.3-2.2"
>

Evidently, this one was built a while back:

Built:         R 2.3.0; i386-pc-mingw32; 2006-04-24 23:47:48; windows

Chuck

On Sat, 2 Jun 2007, Frank E Harrell Jr wrote:

> Wachtel, Mitchell wrote:
>> R will not let me load Design or Hmisc anymore. I need to calculate Harrell's C for some survival analyses. Can anyone provide an R formula for Harrell's C?
>> With kindest regards.
>> Mitchell Wachtel, MD
>
> You provided very little information.  We have had no reports of Hmisc
> not loading under Windows but Design is not currently available for
> Windows for R 2.5.  We are working to fix that.
>
> Frank
> -- 
> Frank E Harrell Jr   Professor and Chair           School of Medicine
>                      Department of Biostatistics   Vanderbilt University
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	         UC San Diego
http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0901


From cberry at tajo.ucsd.edu  Sun Jun  3 01:24:55 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Sat, 2 Jun 2007 16:24:55 -0700
Subject: [R] Updating R version
In-Reply-To: <c98270fd0706021413i3d1e31f9q524865f88c7b491b@mail.gmail.com>
References: <c98270fd0706021413i3d1e31f9q524865f88c7b491b@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0706021613331.14763@tajo.ucsd.edu>



try

 	RSiteSearch("update packages")

and

 	RSiteSearch("update packages")

and you will find threads like these:

 	http://finzi.psych.upenn.edu/R/Rhelp02a/archive/41295.html

 	http://finzi.psych.upenn.edu/R/Rhelp02a/archive/8051.html

And following the posting guide [see below] is good advice.



On Sat, 2 Jun 2007, Raghu Naik wrote:

> A quick question.  I am trying to understand how I could move the installed
> packages in my R 2.3 version to the newly installed R 2.5 version, without
> having to install all the packages again. I copied the files under the old
> library subdirectory to the new library subdirectory. But still the newer
> version is not recognizing the packages that were copied over.
>
> Thanks.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	         UC San Diego
http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0901


From M.J.Bojanowski at uu.nl  Sun Jun  3 01:30:53 2007
From: M.J.Bojanowski at uu.nl (Bojanowski, M.J.  (Michal))
Date: Sun, 3 Jun 2007 01:30:53 +0200
Subject: [R] ODP:  Updating R version
References: <c98270fd0706021413i3d1e31f9q524865f88c7b491b@mail.gmail.com>
Message-ID: <94E133D09AA24D43BF6341B675C01A338DCD5F@uu01msg-exb01.soliscom.uu.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070603/390c9f84/attachment.pl 

From dsohal at gmail.com  Sun Jun  3 01:34:57 2007
From: dsohal at gmail.com (Davendra Sohal)
Date: Sat, 2 Jun 2007 19:34:57 -0400
Subject: [R] Finding density curve peak
Message-ID: <c2f237040706021634x581b0d51j37c729960877a4b4@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070602/8d180cb7/attachment.pl 

From mister_bluesman at hotmail.com  Sun Jun  3 02:08:20 2007
From: mister_bluesman at hotmail.com (mister_bluesman)
Date: Sat, 2 Jun 2007 17:08:20 -0700 (PDT)
Subject: [R] Re : I need some help please!
In-Reply-To: <1180823691.4661f08b460a8@www.usherbrooke.ca>
References: <1180823691.4661f08b460a8@www.usherbrooke.ca>
Message-ID: <10932455.post@talk.nabble.com>


Try the par(mfrow=c(x,y)) command which sets up x rows and y columns of
subplots:

-- 
View this message in context: http://www.nabble.com/Re-%3A-I-need-some-help-please%21-tf3858641.html#a10932455
Sent from the R help mailing list archive at Nabble.com.


From perpdgo at colpos.mx  Sun Jun  3 02:02:18 2007
From: perpdgo at colpos.mx (Paulino Perez Rodriguez)
Date: Sat, 02 Jun 2007 18:02:18 -0600
Subject: [R] Problems compiling RMySQL
Message-ID: <web-10660380@mailadmin.colpos.mx>

Hello, I am trying to compile/Install RMySQL_0.6-0 in 
R-2.4.1/2.5.0 under Windows XP MCE, I am using MySQL 
5.0.41. I have followed the instructions in the file 
INSTALL.win, but I get some errors...

C:\Program Files\R\R-2.4.1>Rcmd build --binary RMySQL 
--docs=normal
* checking for file 'RMySQL/DESCRIPTION' ... OK
* preparing 'RMySQL':
* checking DESCRIPTION meta-information ... OK
* cleaning src
* removing junk files
* checking for LF line-endings in source files
* checking for empty or unneeded directories
* building binary distribution
  WARNING
* some HTML links may not be found
installing R.css in c:/TEMP/Rinst248068707

Using auto-selected zip options ' RMySQL-HELP=ziponly'

---------- Making package RMySQL ------------
======================================================================
RMySQL configure.win:
* Using mysql libraries from 
c:/PROGRA~1/MySQL/MYSQLS~1.0/lib/opt
* Using mysql dll from c:/PROGRA~1/MySQL/MYSQLS~1.0/bin
* Copying runtime libMySQL.dll and libmysql.lib to 
inst/libs
* Using an existing libmysql.a in 
c:/PROGRA~1/MySQL/MYSQLS~1.0/lib/opt
======================================================================
   adding build stamp to DESCRIPTION
   installing NAMESPACE file and metadata
   making DLL ...
making RS-DBI.d from RS-DBI.c
making RS-MySQL.d from RS-MySQL.c
gcc -Ic:/PROGRA~1/MySQL/MYSQLS~1.0/include 
-Ic:/PROGRA~1/R/R-24~1.1/include -W
all -O2 -std=gnu99 -c RS-DBI.c -o RS-DBI.o
gcc -Ic:/PROGRA~1/MySQL/MYSQLS~1.0/include 
-Ic:/PROGRA~1/R/R-24~1.1/include -W
all -O2 -std=gnu99 -c RS-MySQL.c -o RS-MySQL.o
windres --include-dir c:/PROGRA~1/R/R-24~1.1/include -i 
RMySQL_res.rc -o RMySQL
_res.o
gcc -shared -s -o RMySQL.dll RMySQL.def RS-DBI.o 
RS-MySQL.o RMySQL_res.o -Lc:
/PROGRA~1/R/R-24~1.1/bin 
-Lc:/PROGRA~1/MySQL/MYSQLS~1.0/lib/opt -lmysql -liberty
    -lR
   ... DLL made
   installing DLL
   installing R files
   installing inst files
FIND: Parameter format not correct
make[2]: *** [c:/TEMP/Rinst248068707/RMySQL/inst] Error 2
make[1]: *** [all] Error 2
make: *** [pkg-RMySQL] Error 2
*** Installation of RMySQL failed ***

Removing 'c:/TEMP/Rinst248068707/RMySQL'
  ERROR
* installation failed

C:\Program Files\R\R-2.4.1>

What's happening?

Thanks...

-- 
Este mensaje ha sido analizado por MailScanner
en busca de virus y otros contenidos peligrosos,
y se considera que est? limpio.


From ggrothendieck at gmail.com  Sun Jun  3 03:18:04 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 2 Jun 2007 21:18:04 -0400
Subject: [R] canoncial correlation
In-Reply-To: <255640f90706021543m2b527e0x50712a3941b8cd01@mail.gmail.com>
References: <255640f90705261100q6ff74856ie9bd97ff50aec328@mail.gmail.com>
	<255640f90706021543m2b527e0x50712a3941b8cd01@mail.gmail.com>
Message-ID: <971536df0706021818y3b08dda7y2c42952434757947@mail.gmail.com>

See ?biplot.princomp

On 6/2/07, Soare Marcian-Alin <soarealin at gmail.com> wrote:
> hello,
>
> Does nobody know what the problem could be? :((((
>
> 2007/5/26, Soare Marcian-Alin <soarealin at gmail.com>:
> >
> > Hello,
> >
> > I have a problem with the function concar:
> >
> > data set: http://www.statistik.tuwien.ac.at/public/filz/students/multi/ss07/world2.R
> >
> >
> > source("world2.R")
> >
> > world[,8] <- log(world[,8])
> > world[,9] <- log(world[,9])
> > x <- world[,-c(1,2)]
> > x <- scale(x)
> >
> > a <- cancor(x[,-c(6:9)],x[,-c(1:5)])
> > attributes(a)
> > a
> >
> > How do I plot the first two canonial variables of a? And I want to take
> > the rownames of world as pch ...
> >
> > plot(..., pch=rownames(world), col=as.numeric(world[,1]))
> >
> > Thanks in advance!
> >
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jrkrideau at yahoo.ca  Sun Jun  3 03:22:25 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Sat, 2 Jun 2007 21:22:25 -0400 (EDT)
Subject: [R] Re : I need some help please!
In-Reply-To: <1180823691.4661f08b460a8@www.usherbrooke.ca>
Message-ID: <874063.54126.qm@web32803.mail.mud.yahoo.com>


--- Bernard Colin <Bernard.Colin at USherbrooke.ca>
wrote:

> 
> To whom it may concern,
> 
> I want to plot two or more graphics in the same
> window by the means of the
> "plot" command. To do that, I have tried the
> "add=TRUE" option, but this last
> one does not work! Do you have an hint for me
> please?
?par
mfcol, mfrow
A vector of the form c(nr, nc). Subsequent figures
will be drawn in an nr-by-nc array on the device by
columns (mfcol), or rows (mfrow), respectively.


From ral at lcfltd.com  Sun Jun  3 03:28:43 2007
From: ral at lcfltd.com (Robert A LaBudde)
Date: Sat, 02 Jun 2007 21:28:43 -0400
Subject: [R] Finding density curve peak
In-Reply-To: <c2f237040706021634x581b0d51j37c729960877a4b4@mail.gmail.co m>
References: <c2f237040706021634x581b0d51j37c729960877a4b4@mail.gmail.com>
Message-ID: <0JJ10071ODFW9DS3@vms040.mailsrvcs.net>

At 07:34 PM 6/2/2007, Davendra wrote:
>I have a dataset where I get a density curve of a continuous variable with
>two peaks.
>How can I get the peaks?
>Any simple solutions?

Plot the curve, and the use identify() and the mouse to click on the peaks.

================================================================
Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
824 Timberlake Drive                     Tel: 757-467-0954
Virginia Beach, VA 23464-3239            Fax: 757-467-2947

"Vere scire est per causas scire"


From daj025 at gmail.com  Sun Jun  3 05:33:40 2007
From: daj025 at gmail.com (David James)
Date: Sat, 2 Jun 2007 23:33:40 -0400
Subject: [R] Problems compiling RMySQL
In-Reply-To: <web-10660380@mailadmin.colpos.mx>
References: <web-10660380@mailadmin.colpos.mx>
Message-ID: <74c69e370706022033y36bb6958v6faea0da9667340e@mail.gmail.com>

Hi,

The error is coming from the FIND command (and in upper case, hmm).
I'd suggest making sure you are using the right find.

HTH

--
David

On 6/2/07, Paulino Perez Rodriguez <perpdgo at colpos.mx> wrote:
> Hello, I am trying to compile/Install RMySQL_0.6-0 in
> R-2.4.1/2.5.0 under Windows XP MCE, I am using MySQL
> 5.0.41. I have followed the instructions in the file
> INSTALL.win, but I get some errors...
>
> C:\Program Files\R\R-2.4.1>Rcmd build --binary RMySQL
> --docs=normal
> * checking for file 'RMySQL/DESCRIPTION' ... OK
> * preparing 'RMySQL':
> * checking DESCRIPTION meta-information ... OK
> * cleaning src
> * removing junk files
> * checking for LF line-endings in source files
> * checking for empty or unneeded directories
> * building binary distribution
>   WARNING
> * some HTML links may not be found
> installing R.css in c:/TEMP/Rinst248068707
>
> Using auto-selected zip options ' RMySQL-HELP=ziponly'
>
> ---------- Making package RMySQL ------------
> ======================================================================
> RMySQL configure.win:
> * Using mysql libraries from
> c:/PROGRA~1/MySQL/MYSQLS~1.0/lib/opt
> * Using mysql dll from c:/PROGRA~1/MySQL/MYSQLS~1.0/bin
> * Copying runtime libMySQL.dll and libmysql.lib to
> inst/libs
> * Using an existing libmysql.a in
> c:/PROGRA~1/MySQL/MYSQLS~1.0/lib/opt
> ======================================================================
>    adding build stamp to DESCRIPTION
>    installing NAMESPACE file and metadata
>    making DLL ...
> making RS-DBI.d from RS-DBI.c
> making RS-MySQL.d from RS-MySQL.c
> gcc -Ic:/PROGRA~1/MySQL/MYSQLS~1.0/include
> -Ic:/PROGRA~1/R/R-24~1.1/include -W
> all -O2 -std=gnu99 -c RS-DBI.c -o RS-DBI.o
> gcc -Ic:/PROGRA~1/MySQL/MYSQLS~1.0/include
> -Ic:/PROGRA~1/R/R-24~1.1/include -W
> all -O2 -std=gnu99 -c RS-MySQL.c -o RS-MySQL.o
> windres --include-dir c:/PROGRA~1/R/R-24~1.1/include -i
> RMySQL_res.rc -o RMySQL
> _res.o
> gcc -shared -s -o RMySQL.dll RMySQL.def RS-DBI.o
> RS-MySQL.o RMySQL_res.o -Lc:
> /PROGRA~1/R/R-24~1.1/bin
> -Lc:/PROGRA~1/MySQL/MYSQLS~1.0/lib/opt -lmysql -liberty
>     -lR
>    ... DLL made
>    installing DLL
>    installing R files
>    installing inst files
> FIND: Parameter format not correct
> make[2]: *** [c:/TEMP/Rinst248068707/RMySQL/inst] Error 2
> make[1]: *** [all] Error 2
> make: *** [pkg-RMySQL] Error 2
> *** Installation of RMySQL failed ***
>
> Removing 'c:/TEMP/Rinst248068707/RMySQL'
>   ERROR
> * installation failed
>
> C:\Program Files\R\R-2.4.1>
>
> What's happening?
>
> Thanks...
>
> --
> Este mensaje ha sido analizado por MailScanner
> en busca de virus y otros contenidos peligrosos,
> y se considera que est? limpio.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From p.dalgaard at biostat.ku.dk  Sun Jun  3 08:20:00 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sun, 03 Jun 2007 08:20:00 +0200
Subject: [R] recompile R using ActiveTcl
In-Reply-To: <200705311826.12590.james.foadi@diamond.ac.uk>
References: <200705311826.12590.james.foadi@diamond.ac.uk>
Message-ID: <46625D90.3050609@biostat.ku.dk>

James Foadi wrote:
> Dear all,
>
> While running some code requiring the "tcltk" package I have realised that my 
> version of R was compiled with the Tcl/Tk libraries included in Fedora 6. It 
> would be for me better to use the ActiveTcl libraries (which I have 
> under /usr/local), and I'm aware that this probably means to recompile R with 
> the proper configuration variables.
>
> But...is it by any chance possible to "just" recompile the bit affected by 
> Tcl/Tk, like, for instance, to install tcltk with some environment variable 
> pointing at the right ActiveTcl library?
>
>   
Maybe, but I don't think it is worth the trouble compared to a full 
rebuild. There are obstacles, e.g. that the Makefile in the packages is 
created from Makefile.in by the toplevel configure script. I.e., better 
waste some computer resources than your own.

> Many thanks for your suggestions and help.
>
> J
>


From pm509 at york.ac.uk  Sun Jun  3 11:36:32 2007
From: pm509 at york.ac.uk (pm509 at york.ac.uk)
Date: 03 Jun 2007 10:36:32 +0100
Subject: [R] Subscript in axis label
Message-ID: <Prayer.1.0.18.0706031036320.4407@webmail1.york.ac.uk>

Dear R help list members,

I am experiencing difficulty in trying to generate a subscript '2' in an 
axis label. Although I can get the '2' into a subscript using expression(), 
R then forces me to leave at least one space between the '2' and the 
following character. My label is supposed to read 'N2O concentration 
(ppm)', and the space between the '2' and the 'O' makes it look rather 
inelegant! My code is the following (the comments in it are there to stop 
me forgetting what I have done, I am new to R):

postscript(file="/Users/patrickmartin/Documents/York Innova 
Precision/N2Oinnova.eps", horizontal=FALSE, onefile=FALSE, height=4, 
width=5, pointsize=10)
> plot(n2o, lty=0, las=1, xlab="Time", ylab=expression(N[2]~"O 
> concentration (ppm)")) points(n2o, pch=16) # suppresses line but adds 
> points dev.off() # turns postscript device off again

One possibility is for me to simply leave two spaces everywhere else, but 
that looks a little strange. Does anyone know of a more elegant way of 
solving the problem?

A related query is that the journal I want to publish this figure in 
specifies that if EPS format is used, the font should be either Arial, 
Courier, Helvetica, Times or Symbol. Is one of these the default font for 
an EPS file in R, and if not, is there a possibility of changing it?

Thanks a lot in advance,
Patrick Martin


From tobias.verbeke at gmail.com  Sun Jun  3 11:51:38 2007
From: tobias.verbeke at gmail.com (Tobias Verbeke)
Date: Sun, 03 Jun 2007 11:51:38 +0200
Subject: [R] Subscript in axis label
In-Reply-To: <Prayer.1.0.18.0706031036320.4407@webmail1.york.ac.uk>
References: <Prayer.1.0.18.0706031036320.4407@webmail1.york.ac.uk>
Message-ID: <46628F2A.8070106@businessdecision.com>

pm509 at york.ac.uk wrote:
> Dear R help list members,
> 
> I am experiencing difficulty in trying to generate a subscript '2' in an 
> axis label. Although I can get the '2' into a subscript using expression(), 
> R then forces me to leave at least one space between the '2' and the 
> following character. My label is supposed to read 'N2O concentration 
> (ppm)', and the space between the '2' and the 'O' makes it look rather 
> inelegant! My code is the following (the comments in it are there to stop 
> me forgetting what I have done, I am new to R):
> 
> postscript(file="/Users/patrickmartin/Documents/York Innova 
> Precision/N2Oinnova.eps", horizontal=FALSE, onefile=FALSE, height=4, 
> width=5, pointsize=10)
>> plot(n2o, lty=0, las=1, xlab="Time", ylab=expression(N[2]~"O 
>> concentration (ppm)")) points(n2o, pch=16) # suppresses line but adds 
>> points dev.off() # turns postscript device off again

Is this better

plot(1:10, ylab = expression(paste(N[2],"O concentration (ppm)",
                              sep = "")))

?

HTH,
Tobias

-- 

Tobias Verbeke - Consultant
Business & Decision Benelux
Rue de la r?volution 8
1000 Brussels - BELGIUM

+32 499 36 33 15
tobias.verbeke at businessdecision.com


From tobias.verbeke at gmail.com  Sun Jun  3 12:28:26 2007
From: tobias.verbeke at gmail.com (Tobias Verbeke)
Date: Sun, 03 Jun 2007 12:28:26 +0200
Subject: [R] specify font family for postscript device [was: Re:
 Subscript in axis label]
In-Reply-To: <Prayer.1.0.18.0706031036320.4407@webmail1.york.ac.uk>
References: <Prayer.1.0.18.0706031036320.4407@webmail1.york.ac.uk>
Message-ID: <466297CA.4070108@businessdecision.com>

pm509 at york.ac.uk wrote:

> Dear R help list members,

<snip>

> A related query is that the journal I want to publish this figure in 
> specifies that if EPS format is used, the font should be either Arial, 
> Courier, Helvetica, Times or Symbol. Is one of these the default font for 
> an EPS file in R, and if not, is there a possibility of changing it?

See ?postscript and in particular the family argument the details of
which are treated in the Families section.

HTH,
Tobias

-- 

Tobias Verbeke - Consultant
Business & Decision Benelux
Rue de la r?volution 8
1000 Brussels - BELGIUM

+32 499 36 33 15
tobias.verbeke at businessdecision.com


From murdoch at stats.uwo.ca  Sun Jun  3 12:28:52 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 03 Jun 2007 06:28:52 -0400
Subject: [R] Problems compiling RMySQL
In-Reply-To: <74c69e370706022033y36bb6958v6faea0da9667340e@mail.gmail.com>
References: <web-10660380@mailadmin.colpos.mx>
	<74c69e370706022033y36bb6958v6faea0da9667340e@mail.gmail.com>
Message-ID: <466297E4.7090003@stats.uwo.ca>

On 02/06/2007 11:33 PM, David James wrote:
> Hi,
> 
> The error is coming from the FIND command (and in upper case, hmm).
> I'd suggest making sure you are using the right find.

Yes, that's a sign that the PATH is not set the way the R tools need it. 
  See the "Windows toolset" section of the Installation and 
Administration manual.

Duncan Murdoch

> 
> HTH
> 
> --
> David
> 
> On 6/2/07, Paulino Perez Rodriguez <perpdgo at colpos.mx> wrote:
>> Hello, I am trying to compile/Install RMySQL_0.6-0 in
>> R-2.4.1/2.5.0 under Windows XP MCE, I am using MySQL
>> 5.0.41. I have followed the instructions in the file
>> INSTALL.win, but I get some errors...
>>
>> C:\Program Files\R\R-2.4.1>Rcmd build --binary RMySQL
>> --docs=normal
>> * checking for file 'RMySQL/DESCRIPTION' ... OK
>> * preparing 'RMySQL':
>> * checking DESCRIPTION meta-information ... OK
>> * cleaning src
>> * removing junk files
>> * checking for LF line-endings in source files
>> * checking for empty or unneeded directories
>> * building binary distribution
>>   WARNING
>> * some HTML links may not be found
>> installing R.css in c:/TEMP/Rinst248068707
>>
>> Using auto-selected zip options ' RMySQL-HELP=ziponly'
>>
>> ---------- Making package RMySQL ------------
>> ======================================================================
>> RMySQL configure.win:
>> * Using mysql libraries from
>> c:/PROGRA~1/MySQL/MYSQLS~1.0/lib/opt
>> * Using mysql dll from c:/PROGRA~1/MySQL/MYSQLS~1.0/bin
>> * Copying runtime libMySQL.dll and libmysql.lib to
>> inst/libs
>> * Using an existing libmysql.a in
>> c:/PROGRA~1/MySQL/MYSQLS~1.0/lib/opt
>> ======================================================================
>>    adding build stamp to DESCRIPTION
>>    installing NAMESPACE file and metadata
>>    making DLL ...
>> making RS-DBI.d from RS-DBI.c
>> making RS-MySQL.d from RS-MySQL.c
>> gcc -Ic:/PROGRA~1/MySQL/MYSQLS~1.0/include
>> -Ic:/PROGRA~1/R/R-24~1.1/include -W
>> all -O2 -std=gnu99 -c RS-DBI.c -o RS-DBI.o
>> gcc -Ic:/PROGRA~1/MySQL/MYSQLS~1.0/include
>> -Ic:/PROGRA~1/R/R-24~1.1/include -W
>> all -O2 -std=gnu99 -c RS-MySQL.c -o RS-MySQL.o
>> windres --include-dir c:/PROGRA~1/R/R-24~1.1/include -i
>> RMySQL_res.rc -o RMySQL
>> _res.o
>> gcc -shared -s -o RMySQL.dll RMySQL.def RS-DBI.o
>> RS-MySQL.o RMySQL_res.o -Lc:
>> /PROGRA~1/R/R-24~1.1/bin
>> -Lc:/PROGRA~1/MySQL/MYSQLS~1.0/lib/opt -lmysql -liberty
>>     -lR
>>    ... DLL made
>>    installing DLL
>>    installing R files
>>    installing inst files
>> FIND: Parameter format not correct
>> make[2]: *** [c:/TEMP/Rinst248068707/RMySQL/inst] Error 2
>> make[1]: *** [all] Error 2
>> make: *** [pkg-RMySQL] Error 2
>> *** Installation of RMySQL failed ***
>>
>> Removing 'c:/TEMP/Rinst248068707/RMySQL'
>>   ERROR
>> * installation failed
>>
>> C:\Program Files\R\R-2.4.1>
>>
>> What's happening?
>>
>> Thanks...
>>
>> --
>> Este mensaje ha sido analizado por MailScanner
>> en busca de virus y otros contenidos peligrosos,
>> y se considera que est? limpio.
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ligges at statistik.uni-dortmund.de  Sun Jun  3 12:34:26 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 03 Jun 2007 12:34:26 +0200
Subject: [R] Problems compiling RMySQL
In-Reply-To: <74c69e370706022033y36bb6958v6faea0da9667340e@mail.gmail.com>
References: <web-10660380@mailadmin.colpos.mx>
	<74c69e370706022033y36bb6958v6faea0da9667340e@mail.gmail.com>
Message-ID: <46629932.2000903@statistik.uni-dortmund.de>



David James wrote:
> Hi,
> 
> The error is coming from the FIND command (and in upper case, hmm).
> I'd suggest making sure you are using the right find.


You do this by following the "R Installation and Administration manual" 
which tells you to have the R tools in your PATH prior to the Windows paths.

Uwe Ligges


> HTH
> 
> --
> David
> 
> On 6/2/07, Paulino Perez Rodriguez <perpdgo at colpos.mx> wrote:
>> Hello, I am trying to compile/Install RMySQL_0.6-0 in
>> R-2.4.1/2.5.0 under Windows XP MCE, I am using MySQL
>> 5.0.41. I have followed the instructions in the file
>> INSTALL.win, but I get some errors...
>>
>> C:\Program Files\R\R-2.4.1>Rcmd build --binary RMySQL
>> --docs=normal
>> * checking for file 'RMySQL/DESCRIPTION' ... OK
>> * preparing 'RMySQL':
>> * checking DESCRIPTION meta-information ... OK
>> * cleaning src
>> * removing junk files
>> * checking for LF line-endings in source files
>> * checking for empty or unneeded directories
>> * building binary distribution
>>   WARNING
>> * some HTML links may not be found
>> installing R.css in c:/TEMP/Rinst248068707
>>
>> Using auto-selected zip options ' RMySQL-HELP=ziponly'
>>
>> ---------- Making package RMySQL ------------
>> ======================================================================
>> RMySQL configure.win:
>> * Using mysql libraries from
>> c:/PROGRA~1/MySQL/MYSQLS~1.0/lib/opt
>> * Using mysql dll from c:/PROGRA~1/MySQL/MYSQLS~1.0/bin
>> * Copying runtime libMySQL.dll and libmysql.lib to
>> inst/libs
>> * Using an existing libmysql.a in
>> c:/PROGRA~1/MySQL/MYSQLS~1.0/lib/opt
>> ======================================================================
>>    adding build stamp to DESCRIPTION
>>    installing NAMESPACE file and metadata
>>    making DLL ...
>> making RS-DBI.d from RS-DBI.c
>> making RS-MySQL.d from RS-MySQL.c
>> gcc -Ic:/PROGRA~1/MySQL/MYSQLS~1.0/include
>> -Ic:/PROGRA~1/R/R-24~1.1/include -W
>> all -O2 -std=gnu99 -c RS-DBI.c -o RS-DBI.o
>> gcc -Ic:/PROGRA~1/MySQL/MYSQLS~1.0/include
>> -Ic:/PROGRA~1/R/R-24~1.1/include -W
>> all -O2 -std=gnu99 -c RS-MySQL.c -o RS-MySQL.o
>> windres --include-dir c:/PROGRA~1/R/R-24~1.1/include -i
>> RMySQL_res.rc -o RMySQL
>> _res.o
>> gcc -shared -s -o RMySQL.dll RMySQL.def RS-DBI.o
>> RS-MySQL.o RMySQL_res.o -Lc:
>> /PROGRA~1/R/R-24~1.1/bin
>> -Lc:/PROGRA~1/MySQL/MYSQLS~1.0/lib/opt -lmysql -liberty
>>     -lR
>>    ... DLL made
>>    installing DLL
>>    installing R files
>>    installing inst files
>> FIND: Parameter format not correct
>> make[2]: *** [c:/TEMP/Rinst248068707/RMySQL/inst] Error 2
>> make[1]: *** [all] Error 2
>> make: *** [pkg-RMySQL] Error 2
>> *** Installation of RMySQL failed ***
>>
>> Removing 'c:/TEMP/Rinst248068707/RMySQL'
>>   ERROR
>> * installation failed
>>
>> C:\Program Files\R\R-2.4.1>
>>
>> What's happening?
>>
>> Thanks...
>>
>> --
>> Este mensaje ha sido analizado por MailScanner
>> en busca de virus y otros contenidos peligrosos,
>> y se considera que est? limpio.
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ligges at statistik.uni-dortmund.de  Sun Jun  3 12:38:00 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 03 Jun 2007 12:38:00 +0200
Subject: [R] ODP:  Updating R version
In-Reply-To: <94E133D09AA24D43BF6341B675C01A338DCD5F@uu01msg-exb01.soliscom.uu.nl>
References: <c98270fd0706021413i3d1e31f9q524865f88c7b491b@mail.gmail.com>
	<94E133D09AA24D43BF6341B675C01A338DCD5F@uu01msg-exb01.soliscom.uu.nl>
Message-ID: <46629A08.5030403@statistik.uni-dortmund.de>



Bojanowski, M.J. (Michal) wrote:
> Is R not loading the packages at all (like they were never installed), or perhaps it is complaining that they were build on the older version of R? You have to be more specific here about what happens etc.
> 
> For now try running update.packages and see if it fixes the problem.

Or more precisely, try
    update.packages(checkBuilt = TRUE)

In any case, telling what you did and what the error message was would 
be much helpful in order to help.

Uwe Ligges


> I would also suggest keeping all the additional packages (beyond R base installation) in the separate library tree -- less work every time you update R. See ?library and ?.libPaths
> 
> 
> hth,
> 
> Michal
> 
> :
> ::
> ::: Note that my e-mail address has changed to m.j.bojanowski at uu dot nl
> ::: Please update you address books accordingly. Thank you!
> ::
> :
> 
> 
> ____________________________________
> Michal Bojanowski
> ICS / Department of Sociology
> Utrecht University
> Heidelberglaan 2; 3584 CS Utrecht
> Room 1428
> m.j.bojanowski at uu dot nl
> http://www.fss.uu.nl/soc/bojanowski/
> 
> 
> 
> -----Wiadomo?? oryginalna-----
> Od: r-help-bounces at stat.math.ethz.ch w imieniu Raghu Naik
> Wys?ano: So 2007-06-02 23:13
> Do: r-help at stat.math.ethz.ch
> Temat: [R] Updating R version
> 
> A quick question.  I am trying to understand how I could move the installed
> packages in my R 2.3 version to the newly installed R 2.5 version, without
> having to install all the packages again. I copied the files under the old
> library subdirectory to the new library subdirectory. But still the newer
> version is not recognizing the packages that were copied over.
> 
> Thanks.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From p.dalgaard at biostat.ku.dk  Sun Jun  3 13:17:12 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sun, 03 Jun 2007 13:17:12 +0200
Subject: [R] Subscript in axis label
In-Reply-To: <46628F2A.8070106@businessdecision.com>
References: <Prayer.1.0.18.0706031036320.4407@webmail1.york.ac.uk>
	<46628F2A.8070106@businessdecision.com>
Message-ID: <4662A338.5090701@biostat.ku.dk>

Tobias Verbeke wrote:
> pm509 at york.ac.uk wrote:
>   
>> Dear R help list members,
>>
>> I am experiencing difficulty in trying to generate a subscript '2' in an 
>> axis label. Although I can get the '2' into a subscript using expression(), 
>> R then forces me to leave at least one space between the '2' and the 
>> following character. My label is supposed to read 'N2O concentration 
>> (ppm)', and the space between the '2' and the 'O' makes it look rather 
>> inelegant! My code is the following (the comments in it are there to stop 
>> me forgetting what I have done, I am new to R):
>>
>> postscript(file="/Users/patrickmartin/Documents/York Innova 
>> Precision/N2Oinnova.eps", horizontal=FALSE, onefile=FALSE, height=4, 
>> width=5, pointsize=10)
>>     
>>> plot(n2o, lty=0, las=1, xlab="Time", ylab=expression(N[2]~"O 
>>> concentration (ppm)")) points(n2o, pch=16) # suppresses line but adds 
>>> points dev.off() # turns postscript device off again
>>>       
>
> Is this better
>
> plot(1:10, ylab = expression(paste(N[2],"O concentration (ppm)",
>                               sep = "")))
>   

Or,

plot(1:10, ylab = expression(N[2]*O~"concentration (ppm)"))

(because of the "~", you can even do away with "expression()", but I 
think that would be overly sneaky.)


From listen at thomas-zastrow.de  Sun Jun  3 13:18:03 2007
From: listen at thomas-zastrow.de (Thomas Zastrow)
Date: Sun, 03 Jun 2007 13:18:03 +0200
Subject: [R] Beginners Question
In-Reply-To: <Pine.LNX.4.64.0706020717420.28095@gannet.stats.ox.ac.uk>
References: <46607226.5070704@thomas-zastrow.de>
	<Pine.LNX.4.64.0706020717420.28095@gannet.stats.ox.ac.uk>
Message-ID: <4662A36B.4060808@thomas-zastrow.de>

Thank you very much for your answer.

Isn't it possible to tell the isoMDS function that it should ignore 
doubled values with the same value? Or is there a possible to delete all 
the doubled values from the x.dist?

Best regards,

Tom


Prof Brian Ripley schrieb:
> That two distances are the same is *not* what the message says.
>
> You can't just look at elements of the results of dist() and simply 
> relate them back to object numbers.  Try as.matrix(x.dist) for a 
> human-readable form.
>
>

> On Fri, 1 Jun 2007, Thomas Zastrow wrote:
>
>> Dear all,
>>
>> I'm completely new to R and at first I must say that it is a great 
>> program!
>>
>> But I have a problem with the function isoMDS from the MASS package. I
>> have this code which I load with source() from a file:
>>
>> x <- c(163.59514923926784, 150.01448475257115, ...... {here are some
>> more values})
>> x.sort <- sort(x)
>> x.dist <- dist(x.sort)
>> library(MASS)
>> x.mds <- isoMDS(x.dist)
>> plot(x.mds$points, type="n")
>> text(x.mds$points, labels=as.character("x"))
>>
>> The problem is in the line where the isoMDS function is applied: I got
>> the error:
>>
>> Fehler in isoMDS(x.dist) : zero or negative distance between objects 9
>> and 10
>>
>> When I look at values 8 and 9 of x.dist, I see that they have the same
>> values (I'm not wrong, it's values of 8 and 9 and not 9 and 10):
>>
>> x.dist[8:9]
>> [1] 39.8214  39.8214
>>
>> So, just to give'm a try, I changed the value of x.dist[8]:
>>
>> x.dist[8] <- c(39.7)
>>
>> Now, there are defintitely different values in this part of x.dist:
>>
>> x.dist[7:10]
>> [1] 39.69898     39.70000      39.82140      39.98892
>>
>> But when I start isoMDS again, I got again the error:
>>
>> x.mds <- isoMDS(x.dist)
>> Fehler in isoMDS(x.dist) : zero or negative distance between objects 9
>> and 10
>>
>>
>> So, where's my error?
>>
>> Thank you!
>>
>> Best,
>>
>> Tom
>>
>>
>>
>


-- 
----------------------------
http://www.thomas-zastrow.de

German Forum - DTP under Linux:

http://www.opendtp.de


From ripley at stats.ox.ac.uk  Sun Jun  3 13:32:32 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 3 Jun 2007 12:32:32 +0100 (BST)
Subject: [R] Beginners Question
In-Reply-To: <4662A36B.4060808@thomas-zastrow.de>
References: <46607226.5070704@thomas-zastrow.de>
	<Pine.LNX.4.64.0706020717420.28095@gannet.stats.ox.ac.uk>
	<4662A36B.4060808@thomas-zastrow.de>
Message-ID: <Pine.LNX.4.64.0706031223110.18754@gannet.stats.ox.ac.uk>

Please _do_ read the message.  Only you are talking about 'doubled 
values': the error report is about 'zero or negative distance'

What the help page says is

        d: distance structure of the form returned by 'dist', or a full,
           symmetric matrix.  Data are assumed to be dissimilarities or
           relative distances, but must be positive except for
           self-distance.  Both missing and infinite values are allowed.

and you are not supplying such a structure.

In any case, you seem to be trying to do isoMDS on Euclidean distances 
from a 1D array.  There is no point in doing any form of MDS on Euclidean 
distances unless dimension reduction is involved, since otherwise the 
distances can be represented exactly.

I suggest you take some statistical advice on your problem, as your issues 
do not seem to be with R.


On Sun, 3 Jun 2007, Thomas Zastrow wrote:

> Thank you very much for your answer.
>
> Isn't it possible to tell the isoMDS function that it should ignore doubled 
> values with the same value? Or is there a possible to delete all the doubled 
> values from the x.dist?
>
> Best regards,
>
> Tom
>
>
> Prof Brian Ripley schrieb:
>> That two distances are the same is *not* what the message says.
>> 
>> You can't just look at elements of the results of dist() and simply relate 
>> them back to object numbers.  Try as.matrix(x.dist) for a human-readable 
>> form.
>> 
>> 
>
>> On Fri, 1 Jun 2007, Thomas Zastrow wrote:
>> 
>>> Dear all,
>>> 
>>> I'm completely new to R and at first I must say that it is a great 
>>> program!
>>> 
>>> But I have a problem with the function isoMDS from the MASS package. I
>>> have this code which I load with source() from a file:
>>> 
>>> x <- c(163.59514923926784, 150.01448475257115, ...... {here are some
>>> more values})
>>> x.sort <- sort(x)
>>> x.dist <- dist(x.sort)
>>> library(MASS)
>>> x.mds <- isoMDS(x.dist)
>>> plot(x.mds$points, type="n")
>>> text(x.mds$points, labels=as.character("x"))
>>> 
>>> The problem is in the line where the isoMDS function is applied: I got
>>> the error:
>>> 
>>> Fehler in isoMDS(x.dist) : zero or negative distance between objects 9
>>> and 10
>>> 
>>> When I look at values 8 and 9 of x.dist, I see that they have the same
>>> values (I'm not wrong, it's values of 8 and 9 and not 9 and 10):
>>> 
>>> x.dist[8:9]
>>> [1] 39.8214  39.8214
>>> 
>>> So, just to give'm a try, I changed the value of x.dist[8]:
>>> 
>>> x.dist[8] <- c(39.7)
>>> 
>>> Now, there are defintitely different values in this part of x.dist:
>>> 
>>> x.dist[7:10]
>>> [1] 39.69898     39.70000      39.82140      39.98892
>>> 
>>> But when I start isoMDS again, I got again the error:
>>> 
>>> x.mds <- isoMDS(x.dist)
>>> Fehler in isoMDS(x.dist) : zero or negative distance between objects 9
>>> and 10
>>> 
>>> 
>>> So, where's my error?
>>> 
>>> Thank you!
>>> 
>>> Best,
>>> 
>>> Tom
>>> 
>>> 
>>> 
>> 
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From kubovy at virginia.edu  Sun Jun  3 14:13:24 2007
From: kubovy at virginia.edu (Michael Kubovy)
Date: Sun, 3 Jun 2007 08:13:24 -0400
Subject: [R] Standard errors of the predicted values from a lme
	(or	lmer)-object
In-Reply-To: <loom.20070601T120538-203@post.gmane.org>
References: <004001c7a39d$d03585b0$2101a8c0@HP26282134612>
	<loom.20070601T120538-203@post.gmane.org>
Message-ID: <F4BE04D4-061E-44DB-A1D7-111D63C116A1@virginia.edu>

On Jun 1, 2007, at 6:08 AM, Dieter Menne wrote:

> Fr?nzi Korner <fraenzi.korner <at> oikostat.ch> writes:
>
>> how do I obtain standard errors of the predicted values from a lme  
>> (or
>> lmer)-object?
>
> Not totally clear what you mean. intervals(lmeresult) gives the  
> confidence
> intervals for the coefficients. Otherwise, you can do some  
> calculations with
> residuals(lmeresult). Most useful for diagnostic purposes is plot 
> (lmeresult).

Perhaps
?estimable
in the gmodels package
_____________________________
Professor Michael Kubovy
University of Virginia
Department of Psychology
USPS:     P.O.Box 400400    Charlottesville, VA 22904-4400
Parcels:    Room 102        Gilmer Hall
         McCormick Road    Charlottesville, VA 22903
Office:    B011    +1-434-982-4729
Lab:        B019    +1-434-982-4751
Fax:        +1-434-982-4766
WWW:    http://www.people.virginia.edu/~mk9y/


From bunny at lautloscrew.com  Sun Jun  3 16:21:38 2007
From: bunny at lautloscrew.com (bunny , lautloscrew.com)
Date: Sun, 3 Jun 2007 16:21:38 +0200
Subject: [R] factor analysis
Message-ID: <772B523A-3B9D-4B36-B63E-63B68A223A35@lautloscrew.com>

Hi there,

i?ve trouble understanding the factanal output of R.
i am running a a FA on a dataset with 10 variables.

i plotted eigenvalues to finde out how many factors to try.
i think the "elbow" is @ 3 factors.
here are my eigenvalues: 2.6372766 1.5137754 1.0188919 0.8986154  
0.8327583 0.7187473 0.6932792 0.5807489 0.5709594 0.5349477
(of the correlation matrix)

i guess this is basically what screeplot does as well.

and here?s my problem:
unfortunately the cumulative variance @ 3 factors is only .357
there are no crossloadings and the interpretation of the factors and  
their loadings definetely make sense so far.

Can i use this factor analysis somehow despite the poor cumulative  
variance of the first three factors ?
changing the rotation didnt help much.

The test of the hypothesis says the following:

Test of the hypothesis that 3 factors are sufficient.
The chi square statistic is 46.58 on 18 degrees of freedom.
The p-value is 0.000244

does this mean the Hnull is that 3 factors are sufficient and i cant  
recject ?


4 factors say:
Test of the hypothesis that 4 factors are sufficient.
The chi square statistic is 10.82 on 11 degrees of freedom.
The p-value is 0.458

Unfortunately ?factanal does not tell me what the Hnull is in this  
case ?

Thx a lot in advance for some advice

matthias


From J.delasHeras at ed.ac.uk  Sun Jun  3 17:21:14 2007
From: J.delasHeras at ed.ac.uk (J.delasHeras at ed.ac.uk)
Date: Sun, 03 Jun 2007 16:21:14 +0100
Subject: [R] Re : I need some help please!
In-Reply-To: <1180823691.4661f08b460a8@www.usherbrooke.ca>
References: <1180823691.4661f08b460a8@www.usherbrooke.ca>
Message-ID: <20070603162114.yqyq3h0qmg4kcsgs@www.staffmail.ed.ac.uk>

Quoting Bernard Colin <Bernard.Colin at usherbrooke.ca>:

>
> To whom it may concern,
>
> I want to plot two or more graphics in the same window by the means of the
> "plot" command. To do that, I have tried the "add=TRUE" option, but this last
> one does not work! Do you have an hint for me please?
>
> Thank you very much for your attention.
>
> Bernard Colin

You've already been offered the par(mfrow=c(x,y)) option, to plot  
multiple graphs into one figure.

If what you want is to plot something, and then add another one _on  
top_ of it, there are various ways to do that.
If you're plotting lines, points, etc... you can simply use 'plot' for  
the first one, and 'lines' or 'points' for the others.
Sometimes that's not good enough, in which case you should look at  
?par again, and check the effect of par(new=T).
You can make one plot, then call par(new=T) and plot again... the  
second plot gets drawn right on top of the first. You may have to plot  
without the automatic axis drawing, and specify the axes yourself  
(?axis)... that is also teh way to show multiple axes in plots (say a  
common X and two different Y axes... etc).

Jose


-- 
Dr. Jose I. de las Heras                      Email: J.delasHeras at ed.ac.uk
The Wellcome Trust Centre for Cell Biology    Phone: +44 (0)131 6513374
Institute for Cell & Molecular Biology        Fax:   +44 (0)131 6507360
Swann Building, Mayfield Road
University of Edinburgh
Edinburgh EH9 3JR
UK


From linkex_topbiz at easyempires.net  Sun Jun  3 18:12:27 2007
From: linkex_topbiz at easyempires.net (Matt)
Date: Sun, 3 Jun 2007 16:12:27 UT
Subject: [R] I put your link, r-project.org,
	on my site under Lead Generation > Mailing Lists
Message-ID: <591358_761789_705752_503491@easyempires.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070603/9ed76794/attachment.pl 

From rwan at kuicr.kyoto-u.ac.jp  Sun Jun  3 18:20:02 2007
From: rwan at kuicr.kyoto-u.ac.jp (Raymond Wan)
Date: Mon, 04 Jun 2007 01:20:02 +0900
Subject: [R] R's Spearman
In-Reply-To: <465F4077.8040401@vanderbilt.edu>
References: <B7B34444ECA41A41AC47DABA057CE7A201406A99@webmail.cip.cgiar.org>
	<465F4077.8040401@vanderbilt.edu>
Message-ID: <4662EA32.1050002@kuicr.kyoto-u.ac.jp>


Dear Frank and Felipe,

Thank you both for your replies.  The code looks exactly like the 
formula in Japanese wikipedia which I was trying to make sense of (as it 
wasn't in English wikipedia).  Thank you for sharing your code with, Felipe!

And the clarification, Frank.  Knowing many ways of calculating it helps 
understanding it...thanks to both of you!

Ray


Frank E Harrell Jr wrote:
> Mendiburu, Felipe (CIP) wrote:
>> Dear Ray,
>>
>> The R's Spearman calculated by R is correct for ties or nonties, 
>> which is not correct is the probability for the case of ties. I send 
>> to you formulates it for the correlation with ties, that is equal to R.
>> Regards,
>>
>> Felipe de Mendiburu
>> Statistician
>
> Just use midranks for ties (as with rank()) and compute the ordinary 
> correlation on those (see also the spearman2 and rcorr functions in 
> Hmisc package).  No need to use complex formulas.  And the t 
> approximation for p-values works pretty well.


From pwang at berkeley.edu  Sun Jun  3 19:02:02 2007
From: pwang at berkeley.edu (Patrick Wang)
Date: Sun, 3 Jun 2007 10:02:02 -0700 (PDT)
Subject: [R]  How to use density function to find h_{k}
In-Reply-To: <51385.76.169.69.87.1180811726.squirrel@calmail.berkeley.edu>
References: <51385.76.169.69.87.1180811726.squirrel@calmail.berkeley.edu>
Message-ID: <55004.76.169.69.87.1180890122.squirrel@calmail.berkeley.edu>

 Hi, All:

 How can I use the density function to find the minimum of the bandwidth
 make the density function one mode, 2 mode, 3 mode etc. usually the
larger the bandwidth, the fewer mode of the density. less bumpy.

It will be impossible to try all possible bandwidths to then plot the pdf
to see how many modes it has. Is there an automatic way to do this Like
for loop 1000, try bandwidth from (0, 1). is there a function to get
how many modes from the density function? the Mode function in R doesnot
seem to serve this purpose.


 Thanks
 pat


From roger at ysidro.econ.uiuc.edu  Sun Jun  3 19:31:59 2007
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Sun, 3 Jun 2007 12:31:59 -0500 (CDT)
Subject: [R] How to use density function to find h_{k}
In-Reply-To: <55004.76.169.69.87.1180890122.squirrel@calmail.berkeley.edu>
References: <51385.76.169.69.87.1180811726.squirrel@calmail.berkeley.edu>
	<55004.76.169.69.87.1180890122.squirrel@calmail.berkeley.edu>
Message-ID: <Pine.GSO.4.64.0706031224480.14395@ragnar.econ.uiuc.edu>

You might try:  http://www.stanford.edu/~kasparr/software/silverman.r

But  take a look at the referenced paper by Silverman first.  You could 
also try the CRAN package ftnonpar by Kovac and Davies.


url:	www.econ.uiuc.edu/~roger/my.html	Roger Koenker
email	rkoenker at uiuc.edu			Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820

On Sun, 3 Jun 2007, Patrick Wang wrote:

> Hi, All:
>
> How can I use the density function to find the minimum of the bandwidth
> make the density function one mode, 2 mode, 3 mode etc. usually the
> larger the bandwidth, the fewer mode of the density. less bumpy.
>
> It will be impossible to try all possible bandwidths to then plot the pdf
> to see how many modes it has. Is there an automatic way to do this Like
> for loop 1000, try bandwidth from (0, 1). is there a function to get
> how many modes from the density function? the Mode function in R doesnot
> seem to serve this purpose.
>
>
> Thanks
> pat
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From perpdgo at colpos.mx  Sun Jun  3 19:32:14 2007
From: perpdgo at colpos.mx (Paulino Perez Rodriguez)
Date: Sun, 03 Jun 2007 11:32:14 -0600
Subject: [R] Error loading RMySQL
Message-ID: <web-10663969@mailadmin.colpos.mx>

Hello, I have sucessfully compiled and Installed in 
R-2.4.1/2.5.0 under Windows XP MCE, I am using MySQL 
5.0.41, but now I have another error, at load time:

> library(RMySQL)
Error in dyn.load(x, as.logical(local), as.logical(now)) :
         unable to load shared library 
'C:/PROGRA~1/R/R-24~1.1/library/RMySQL/libs/RMySQL.dll':
   LoadLibrary failure:  Invalid access to memory 
location.

Error: package/namespace load failed for 'RMySQL'

I have added C:\Program 
Files\R\R-2.4.1\library\RMySQL\libs to the windows PATH, 
any Idea?

Thanks...

-- 
Este mensaje ha sido analizado por MailScanner
en busca de virus y otros contenidos peligrosos,
y se considera que est? limpio.


From pgoikoetxea at euskalnet.net  Sun Jun  3 20:11:13 2007
From: pgoikoetxea at euskalnet.net (Pablo G Goicoechea)
Date: Sun, 03 Jun 2007 20:11:13 +0200
Subject: [R] codamenu crash
Message-ID: <46630441.903@euskalnet.net>

Dear R users:
I am a newby to R, under Windows XP. Sorry if my question is too 
obvious, but I have not found any  answer in the  archives.
I was using the R-Coda package with R version 2.4.1 and everything was 
going OK. After upgrading to R v.2.5.0, I receive the following error 
message when I'm trying to run codamenu():

"Error in coda.options(default = TRUE) : cannot change value of locked 
binding for '.Coda.Options'

Quiting codamenu ...
Error in !coda.options("data.saved") : invalid argument type"

I would very much appreciate any help to solve this behaviour

Sincerely
Pablo

-- 
Pablo G Goicoechea
Conde Don Vela 54, 2? Izda
01009 Vitoria-Gasteiz
Spain
Phone: +34 945 282417


From jbustosmelo at yahoo.es  Sun Jun  3 22:06:41 2007
From: jbustosmelo at yahoo.es (Jose Bustos Melo)
Date: Sun, 3 Jun 2007 22:06:41 +0200 (CEST)
Subject: [R] making a multiple censored Surv object  to survival analisys
Message-ID: <919919.47723.qm@web26507.mail.ukl.yahoo.com>

Se ha borrado un texto insertado con un juego de caracteres sin especificar...
Nombre: no disponible
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070603/74d38993/attachment.pl 

From andrewjyee at gmail.com  Sun Jun  3 23:48:54 2007
From: andrewjyee at gmail.com (Andrew Yee)
Date: Sun, 3 Jun 2007 17:48:54 -0400
Subject: [R] getting t.test to work with apply()
Message-ID: <5dff5a0d0706031448t5e60448en5aa028b42c65a4a9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070603/3a524693/attachment.pl 

From perpdgo at colpos.mx  Mon Jun  4 01:45:57 2007
From: perpdgo at colpos.mx (Paulino Perez Rodriguez)
Date: Sun, 03 Jun 2007 17:45:57 -0600
Subject: [R] RMySQL loading error, mysql in path
Message-ID: <web-10665247@mailadmin.colpos.mx>


I have successfully installed RMySQL_0.6-0 using under 
Windows XP MCE, I am using MySQL 5.0.41, I have added
I have added C:\Program 
Files\R\R-2.4.1\library\RMySQL\libs and mysql to the 
windows PATH, but again, same error:

and then when  I load R and try to use RMySQL

>library(RMySQL)

Error in dyn.load(x, as.logical(local), as.logical(now)) :
         unable to load shared library 
'C:/PROGRA~1/R/R-24~1.1/library/RMySQL/libs/RMySQL.dll':
   LoadLibrary failure: Invalid access to memory location.

Error: package/namespace load failed for 'RMySQL'


  

-- 
Este mensaje ha sido analizado por MailScanner
en busca de virus y otros contenidos peligrosos,
y se considera que est? limpio.


From h.wickham at gmail.com  Mon Jun  4 07:14:40 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 4 Jun 2007 07:14:40 +0200
Subject: [R] [R-pkgs] Updated reshape and ggplot
In-Reply-To: <f8e6ff050706031000l4b5bc719t4a9762a1be53103f@mail.gmail.com>
References: <f8e6ff050706031000l4b5bc719t4a9762a1be53103f@mail.gmail.com>
Message-ID: <f8e6ff050706032214n600cb830m3294ab88b050fc9d@mail.gmail.com>

Hi everyone,

This is a short announcement for the users of ggplot and reshape.  I
have just released new versions of each that fix bugs when used with R
2.5.0:

 * reshape was having problems with missing combinations of variables
 * errorbars in ggplot weren't working.

I've you've been having problems with either of these, please upgrade.

About ggplot
=====================

An implementation of the grammar of graphics in R.

ggplot is an implementation of the grammar of graphics in R. It
combines the advantages of both base and lattice graphics:
conditioning and shared axes are handled automatically, while
maintaining the ability to build up a plot step by step from multiple
data sources. It also implements a more sophisticated multidimensional
conditioning system and a consistent interface to map data to
aesthetic attributes.

Find out more at http://had.co.nz/ggplot

About reshape
=====================

Reshape is an R package for flexibly restructuring and aggregating
data. It is available on all platforms supported by R (Linux, OS X,
Windows, ...).  Reshape (hopefully) makes it easy to do what you have
been struggling to do with tapply, by, aggregate, xtabs, apply and
summarise. It is also useful for getting your data into the correct
structure for lattice or ggplot plots.

You can find out more at http://had.co.nz/reshape


Regards,

Hadley

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages


From h.wickham at gmail.com  Mon Jun  4 07:14:18 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 4 Jun 2007 07:14:18 +0200
Subject: [R] [R-pkgs] Beta version of ggplot2
In-Reply-To: <f8e6ff050706031018v119635f2m2f4a354cc332ccb6@mail.gmail.com>
References: <f8e6ff050706031018v119635f2m2f4a354cc332ccb6@mail.gmail.com>
Message-ID: <f8e6ff050706032214l29c9d5fft3ce2948caf44c496@mail.gmail.com>

Dear all,

I am pleased to announce the new beta release of ggplot2.  ggplot2 is
a plotting system for R, based on the grammar of graphics, which tries
to take the good parts of base and lattice graphics and none of the
bad parts.  It takes of many of the fiddly details that make plotting
a hassle (like drawing legends) as well as providing a powerful model
of graphics that makes it easy to produce complex multi-layered
graphics.

You can install ggplot2 from CRAN with the following code:
install.packages("ggplot2", dep=TRUE)

There have been a lot of changes to the syntax since the last version
of ggplot and I have renamed the package to ggplot2, so that you can
continue to use your existing code while you transition to the new
system.

As part of the release, I am working on a radically improved
documentation system, currently available at
http://had.co.nz/ggplot2/.  While I'm still working on the textual
explanations, I have mostly completed the examples, which are
displayed with both code and output.  There are over 480 example
graphics, so I hope you should be able to find an example
demonstrating whatever you need.  Any comments on the content and
display would be gratefully received.

In the next few days I will be adding the first chapters of the ggplot
book, which will provide a more systematic introduction to ggplot, the
theory behind it and more examples of its use.  The ggplot book will
be published with Springer, hopefully in Summer 2008.

The latest version of ggplot now provides a complete implementation of
the grammar of graphics, including new support for coordinate systems,
position adjustment (dodging, stacking and jittering).

This is a beta release, so there are still bugs in the code, and many
small aesthetic tweaks to be made.  If you encounter something that
doesn't work, doesn't make sense or you think could be improved,
please don't hesitate to contact me.

Again, you can find out more, and see hundreds of example graphics at
http://had.co.nz/ggplot2/.

Hadley

PS. If you are interested in learning more in person, have at look at
the courses available at http://lookingatdata.com.

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages


From adschai at optonline.net  Mon Jun  4 08:02:07 2007
From: adschai at optonline.net (adschai at optonline.net)
Date: Mon, 04 Jun 2007 06:02:07 +0000 (GMT)
Subject: [R] How to obtain coefficient standard error from the result of
	polr?
Message-ID: <e2899c0c2a1a8.4663aadf@optonline.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070604/f9e42ac3/attachment.pl 

From klaster at karlin.mff.cuni.cz  Mon Jun  4 08:40:47 2007
From: klaster at karlin.mff.cuni.cz (Petr Klasterecky)
Date: Mon, 04 Jun 2007 08:40:47 +0200
Subject: [R] getting t.test to work with apply()
In-Reply-To: <5dff5a0d0706031448t5e60448en5aa028b42c65a4a9@mail.gmail.com>
References: <5dff5a0d0706031448t5e60448en5aa028b42c65a4a9@mail.gmail.com>
Message-ID: <4663B3EF.4050601@karlin.mff.cuni.cz>

Andrew Yee napsal(a):
> Hi, I'm interested in using apply() with t.test() on a data.frame.
> 
> Specifically, I'd like to use apply() to do the following:
> 
>  t.test(raw.sample[1,alive],raw.sample[1,dead])
> t.test(raw.sample[2,alive],raw.sample[2,dead])
>  t.test(raw.sample[3,alive],raw.sample[3,dead])
> etc.
> 
> I tried the following,
> 
> apply(raw.sample,1,function(x) t.test(raw.sample[,alive],raw.sample[,dead]))

Two comments:
1) apply() works on arrays. If your dataframe only has numeric values, 
turn it (or its copy) to a matrix via as.matrix(). If it has mixed 
variables, take only the numeric part for t-tests. The conversion is 
made implicitly but explicit asking for it cannot hurt.
2) the main problem - you are using a wrong argument to t.test

The call should look like
apply(as.matrix(raw.sample), 1, function(x){t.test(x[alive], x[dead])})

assuming 'alive' and 'dead' are logical vectors of the same length as 'x'.

Petr

> 
> but it gives me a list of identical results.
> 
> 
> Thanks,
> Andrew
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Petr Klasterecky
Dept. of Probability and Statistics
Charles University in Prague
Czech Republic


From ripley at stats.ox.ac.uk  Mon Jun  4 08:53:32 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 4 Jun 2007 07:53:32 +0100 (BST)
Subject: [R] How to obtain coefficient standard error from the result of
 polr?
In-Reply-To: <e2899c0c2a1a8.4663aadf@optonline.net>
References: <e2899c0c2a1a8.4663aadf@optonline.net>
Message-ID: <Pine.LNX.4.64.0706040723540.5286@gannet.stats.ox.ac.uk>

On Mon, 4 Jun 2007, adschai at optonline.net wrote:

> Hi - I am using polr. I can get a result from polr fit by calling
>
> result.plr <- polr(formula, data=mydata, method="probit");
>
> However, from the 'result.plr', how can I access standard error of the 
> estimated coefficients as well as the t statistics for each one of them?

You do this from summary(result.plr), possibly via 
coef(summary(result.plr))

> What I would like to do ultimately is to see which coefficients are not 
> significant and try to refit the model again by excluding those 
> variables out. I would appreciate if anyone could give some hint on 
> this. Thank you.

There is a multiple comparisons problem in doing that, especially so if 
the coefficients refer to multi-level factors.  Using stepAIC is 
better-supported.

> - adschai
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From dimitris.rizopoulos at med.kuleuven.be  Mon Jun  4 09:05:32 2007
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Mon, 4 Jun 2007 09:05:32 +0200
Subject: [R] How to obtain coefficient standard error from the result
	ofpolr?
References: <e2899c0c2a1a8.4663aadf@optonline.net>
Message-ID: <007b01c7a676$bdd4a550$0540210a@www.domain>

You need to call the summary() method to obtain the standard errors, 
e.g.,

result.plr <- polr(formula, data = mydata, method = "probit", Hess = 
TRUE)
coef(summary(result.plr))

for checking which predictors are significant you also use stepAIC() 
or the bootstrap version of it, i.e., boot.stepAIC() in the 
`bootStepAIC' package, e.g.,

library(bootStepAIC)
boot.stepAIC(result.plr, data = mydata)


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: <adschai at optonline.net>
To: <r-help at stat.math.ethz.ch>
Sent: Monday, June 04, 2007 8:02 AM
Subject: [R] How to obtain coefficient standard error from the result 
ofpolr?


> Hi - I am using polr. I can get a result from polr fit by calling
>
> result.plr <- polr(formula, data=mydata, method="probit");
>
> However, from the 'result.plr', how can I access standard error of 
> the estimated coefficients as well as the t statistics for each one 
> of them?
>
> What I would like to do ultimately is to see which coefficients are 
> not significant and try to refit the model again by excluding those 
> variables out. I would appreciate if anyone could give some hint on 
> this. Thank you.
>
> - adschai
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm


From h.wickham at gmail.com  Mon Jun  4 09:39:21 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 4 Jun 2007 09:39:21 +0200
Subject: [R] Bug in seq.date?
Message-ID: <f8e6ff050706040039v1cd56ades817534ece083a4a8@mail.gmail.com>

> seq(as.Date("2000-1-1"), as.Date("2001-1-1"), "months")
 [1] "2000-01-01" "2000-02-01" "2000-03-01" "2000-04-01" "2000-05-01"
 [6] "2000-06-01" "2000-07-01" "2000-08-01" "2000-09-01" "2000-10-01"
[11] "2000-11-01" "2000-12-01" "2001-01-01"


> seq(as.Date("2000-1-31"), as.Date("2001-1-31"), "months")
 [1] "2000-01-31" "2000-03-02" "2000-03-31" "2000-05-01" "2000-05-31"
 [6] "2000-07-01" "2000-07-31" "2000-08-31" "2000-10-01" "2000-10-31"
[11] "2000-12-01" "2000-12-31" "2001-01-31"

Is this a bug?

Hadley


From s02mjtj at math.ku.dk  Mon Jun  4 09:57:59 2007
From: s02mjtj at math.ku.dk (Mads Jeppe Tarp-Johansen)
Date: Mon, 4 Jun 2007 09:57:59 +0200 (CEST)
Subject: [R] rq matrix decomposition
Message-ID: <Pine.LNX.4.64.0706040947500.24293@shannon.math.ku.dk>

I specifically need rq matrix decomposition (and not qr).

Looking at netlib site for LAPACK it does provide rq whereas LINPACK not. 
Looking at companion qr in R I see how in base it wraps with a .Call but I 
do not have success in doing that for a similar .Call for rq.

Anyone done this or can provide matrix rewrites that allow me to do the rq 
decomposition with existing R funcs?

Regards MJ


From j.zutt at tudelft.nl  Mon Jun  4 10:06:12 2007
From: j.zutt at tudelft.nl (Jonne Zutt)
Date: Mon, 04 Jun 2007 10:06:12 +0200
Subject: [R] Bug in seq.date?
In-Reply-To: <f8e6ff050706040039v1cd56ades817534ece083a4a8@mail.gmail.com>
References: <f8e6ff050706040039v1cd56ades817534ece083a4a8@mail.gmail.com>
Message-ID: <1180944372.19812.5.camel@dutiih.st.ewi.tudelft.nl>

No, it's not a bug, it matches with the documentation.

see:
  ?seq.POSIXt

     Using '"month"' first advances the month without changing the day:
     if this results in an invalid day of the month, it is counted
     forward into the next month: see the examples.

So, it increases the month first, resulting in:
  01-31, 02-31, 03-31, 04-31, 05-31, etc

Then, for the illegal dates it counts forward.
  04-31 becomes 05-01, etc

Jonne.

On Mon, 2007-06-04 at 09:39 +0200, hadley wickham wrote:
> > seq(as.Date("2000-1-1"), as.Date("2001-1-1"), "months")
>  [1] "2000-01-01" "2000-02-01" "2000-03-01" "2000-04-01" "2000-05-01"
>  [6] "2000-06-01" "2000-07-01" "2000-08-01" "2000-09-01" "2000-10-01"
> [11] "2000-11-01" "2000-12-01" "2001-01-01"
> 
> 
> > seq(as.Date("2000-1-31"), as.Date("2001-1-31"), "months")
>  [1] "2000-01-31" "2000-03-02" "2000-03-31" "2000-05-01" "2000-05-31"
>  [6] "2000-07-01" "2000-07-31" "2000-08-31" "2000-10-01" "2000-10-31"
> [11] "2000-12-01" "2000-12-31" "2001-01-31"
> 
> Is this a bug?
> 
> Hadley
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ligges at statistik.uni-dortmund.de  Mon Jun  4 10:11:12 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 04 Jun 2007 10:11:12 +0200
Subject: [R] codamenu crash
In-Reply-To: <46630441.903@euskalnet.net>
References: <46630441.903@euskalnet.net>
Message-ID: <4663C920.4050200@statistik.uni-dortmund.de>

This is a known bug in the coda package and has already been reported to 
its maintainer. The same bug was reported here roughly a week ago. 
Please check the archives prior to posting.

Uwe Ligges



Pablo G Goicoechea wrote:
> Dear R users:
> I am a newby to R, under Windows XP. Sorry if my question is too 
> obvious, but I have not found any  answer in the  archives.
> I was using the R-Coda package with R version 2.4.1 and everything was 
> going OK. After upgrading to R v.2.5.0, I receive the following error 
> message when I'm trying to run codamenu():
> 
> "Error in coda.options(default = TRUE) : cannot change value of locked 
> binding for '.Coda.Options'
> 
> Quiting codamenu ...
> Error in !coda.options("data.saved") : invalid argument type"
> 
> I would very much appreciate any help to solve this behaviour
> 
> Sincerely
> Pablo
>


From P.Dalgaard at biostat.ku.dk  Mon Jun  4 10:31:45 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 04 Jun 2007 10:31:45 +0200
Subject: [R] getting t.test to work with apply()
In-Reply-To: <4663B3EF.4050601@karlin.mff.cuni.cz>
References: <5dff5a0d0706031448t5e60448en5aa028b42c65a4a9@mail.gmail.com>
	<4663B3EF.4050601@karlin.mff.cuni.cz>
Message-ID: <4663CDF1.5070409@biostat.ku.dk>

Petr Klasterecky wrote:
> Andrew Yee napsal(a):
>   
>> Hi, I'm interested in using apply() with t.test() on a data.frame.
>>
>> Specifically, I'd like to use apply() to do the following:
>>
>>  t.test(raw.sample[1,alive],raw.sample[1,dead])
>> t.test(raw.sample[2,alive],raw.sample[2,dead])
>>  t.test(raw.sample[3,alive],raw.sample[3,dead])
>> etc.
>>
>> I tried the following,
>>
>> apply(raw.sample,1,function(x) t.test(raw.sample[,alive],raw.sample[,dead]))
>>     
>
> Two comments:
> 1) apply() works on arrays. If your dataframe only has numeric values, 
> turn it (or its copy) to a matrix via as.matrix(). If it has mixed 
> variables, take only the numeric part for t-tests. The conversion is 
> made implicitly but explicit asking for it cannot hurt.
> 2) the main problem - you are using a wrong argument to t.test
>
> The call should look like
> apply(as.matrix(raw.sample), 1, function(x){t.test(x[alive], x[dead])})
>
> assuming 'alive' and 'dead' are logical vectors of the same length as 'x'.
>
> Petr
>   
Notice also that the other apply-style functions may give an easier
route to the goal:

lapply(1:N, function(i) t.test(raw.sample[i,alive],raw.sample[i,dead]))

or (maybe, depends on raw.sample being a data frame and alive/dead being
indexing vectors)

mapply(t.test, raw.sample[,alive], raw.sample[,dead])

>   
>> but it gives me a list of identical results.
>>
>>
>> Thanks,
>> Andrew
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>     
>
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From fraenzi.korner at oikostat.ch  Mon Jun  4 10:40:31 2007
From: fraenzi.korner at oikostat.ch (=?iso-8859-1?Q?Fr=E4nzi_Korner?=)
Date: Mon, 4 Jun 2007 10:40:31 +0200
Subject: [R] Standard errors of the predicted values from a lme (or lmer)
In-Reply-To: <mailman.11.1180778404.32181.r-help@stat.math.ethz.ch>
References: <mailman.11.1180778404.32181.r-help@stat.math.ethz.ch>
Message-ID: <006b01c7a684$0285b740$2101a8c0@HP26282134612>

Dear Dieter,

 

sorry for not being more specific. I would like to use R to get a prediction
(with standard error) of the response in a mixed model at selected values of
the fixed-effects factors. Hence, in a mixed model, say, for response body
size with, say, fixed factors sex and age, I would like to get a prediction
of size for each sex and at selected ages such as 5, 10, 15; and I want a SE
for that prediction as well. 

 

This can be produced in the GenStat package using the VPREDICT directive or
for lme-objects by predict(lmeresult, newdata, se=TRUE), but I have not
found out so far how predictions for the response under a mixed model in R
can be obtained.

 

Thanks for all, 

 

kind regards  --


From Thierry.ONKELINX at inbo.be  Mon Jun  4 10:15:26 2007
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 4 Jun 2007 10:15:26 +0200
Subject: [R] getting t.test to work with apply()
In-Reply-To: <5dff5a0d0706031448t5e60448en5aa028b42c65a4a9@mail.gmail.com>
Message-ID: <2E9C414912813E4EB981326983E0A10403008953@inboexch.inbo.be>

Since you are using function(x) the apply function is passing values to
x. So you need to use x inside the function.
Try something like this:

apply(raw.sample,1,function(x){t.test(x["alive"],x["dead"])})

Cheers,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Reseach Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium
tel. + 32 54/436 185
Thierry.Onkelinx op inbo.be
www.inbo.be 

Do not put your faith in what statistics say until you have carefully
considered what they do not say.  ~William W. Watt
A statistical analysis, properly conducted, is a delicate dissection of
uncertainties, a surgery of suppositions. ~M.J.Moroney

 

> -----Oorspronkelijk bericht-----
> Van: r-help-bounces op stat.math.ethz.ch 
> [mailto:r-help-bounces op stat.math.ethz.ch] Namens Andrew Yee
> Verzonden: zondag 3 juni 2007 23:49
> Aan: r-help op stat.math.ethz.ch
> Onderwerp: [R] getting t.test to work with apply()
> 
> Hi, I'm interested in using apply() with t.test() on a data.frame.
> 
> Specifically, I'd like to use apply() to do the following:
> 
>  t.test(raw.sample[1,alive],raw.sample[1,dead])
> t.test(raw.sample[2,alive],raw.sample[2,dead])
>  t.test(raw.sample[3,alive],raw.sample[3,dead])
> etc.
> 
> I tried the following,
> 
> apply(raw.sample,1,function(x) 
> t.test(raw.sample[,alive],raw.sample[,dead]))
> 
> but it gives me a list of identical results.
> 
> 
> Thanks,
> Andrew
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help op stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From johanfaux at yahoo.com  Mon Jun  4 03:27:40 2007
From: johanfaux at yahoo.com (johan Faux)
Date: Sun, 3 Jun 2007 18:27:40 -0700 (PDT)
Subject: [R] locked environment and inheritance
Message-ID: <863114.36116.qm@web56206.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070603/3f1149b1/attachment.pl 

From salcaraz at obelix.umh.es  Mon Jun  4 12:18:52 2007
From: salcaraz at obelix.umh.es (salcaraz at obelix.umh.es)
Date: Mon, 4 Jun 2007 12:18:52 +0200 (CEST)
Subject: [R] inverse cumulative distribution
In-Reply-To: <mailman.9.1180951205.916.r-help@stat.math.ethz.ch>
References: <mailman.9.1180951205.916.r-help@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.64.0706041213120.1777@obelix.umh.es>

hi all:

ecdf() is the empirical cumulative distribution function, but I need the 
INVERSE cumulative distribution.

how can I calculate it?

thank you in advance

/salva


From xpxixpy at gmail.com  Mon Jun  4 12:57:03 2007
From: xpxixpy at gmail.com (KK)
Date: Mon, 4 Jun 2007 06:57:03 -0400
Subject: [R] Front end for R in Mac
Message-ID: <86b533e90706040357u1aa9bbdap6f7fbc8fa33c4418@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070604/6a77cc16/attachment.pl 

From ggrothendieck at gmail.com  Mon Jun  4 13:06:17 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 4 Jun 2007 07:06:17 -0400
Subject: [R] Bug in seq.date?
In-Reply-To: <f8e6ff050706040039v1cd56ades817534ece083a4a8@mail.gmail.com>
References: <f8e6ff050706040039v1cd56ades817534ece083a4a8@mail.gmail.com>
Message-ID: <971536df0706040406w4dd35cc8pe95116fd7ba5fc8f@mail.gmail.com>

Note that chron does give the last day of the month:

> library(chron)
> seq(chron("1/31/2000"), chron("1/31/2001"), "month")
 [1] 01/31/00 02/29/00 03/31/00 04/30/00 05/31/00 06/30/00 07/31/00 08/31/00
 [9] 09/30/00 10/31/00 11/30/00 12/31/00 01/31/01

The zoo package has a "yearmon" class whose as.Date.yearmon can
convert a "Date" to the end of the month:
library(zoo)
> library(zoo)
> as.Date(as.yearmon(seq(as.Date("2000-1-31"), as.Date("2001-1-31"), "month")), 1)
 [1] "2000-01-31" "2000-02-29" "2000-03-31" "2000-04-30" "2000-05-31"
 [6] "2000-06-30" "2000-07-31" "2000-08-31" "2000-09-30" "2000-10-31"
[11] "2000-11-30" "2000-12-31" "2001-01-31"

And we do it ourself like this:

> as.Date(format(seq(as.Date("2000-1-1"), as.Date("2001-1-1"), "month") + 32, "%Y-%m-01"))-1
 [1] "2000-01-31" "2000-02-29" "2000-03-31" "2000-04-30" "2000-05-31"
 [6] "2000-06-30" "2000-07-31" "2000-08-31" "2000-09-30" "2000-10-31"
[11] "2000-11-30" "2000-12-31" "2001-01-31"




On 6/4/07, hadley wickham <h.wickham at gmail.com> wrote:
> > seq(as.Date("2000-1-1"), as.Date("2001-1-1"), "months")
>  [1] "2000-01-01" "2000-02-01" "2000-03-01" "2000-04-01" "2000-05-01"
>  [6] "2000-06-01" "2000-07-01" "2000-08-01" "2000-09-01" "2000-10-01"
> [11] "2000-11-01" "2000-12-01" "2001-01-01"
>
>
> > seq(as.Date("2000-1-31"), as.Date("2001-1-31"), "months")
>  [1] "2000-01-31" "2000-03-02" "2000-03-31" "2000-05-01" "2000-05-31"
>  [6] "2000-07-01" "2000-07-31" "2000-08-31" "2000-10-01" "2000-10-31"
> [11] "2000-12-01" "2000-12-31" "2001-01-31"
>
> Is this a bug?
>
> Hadley
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From shiazy at gmail.com  Mon Jun  4 13:22:38 2007
From: shiazy at gmail.com (Shiazy Fuzzy)
Date: Mon, 4 Jun 2007 13:22:38 +0200
Subject: [R] inverse cumulative distribution
In-Reply-To: <Pine.LNX.4.64.0706041213120.1777@obelix.umh.es>
References: <mailman.9.1180951205.916.r-help@stat.math.ethz.ch>
	<Pine.LNX.4.64.0706041213120.1777@obelix.umh.es>
Message-ID: <9d3ef91d0706040422j191548e6r71486190da5c6429@mail.gmail.com>

On 6/4/07, salcaraz at obelix.umh.es <salcaraz at obelix.umh.es> wrote:
> hi all:
>
> ecdf() is the empirical cumulative distribution function, but I need the
> INVERSE cumulative distribution.
>
> how can I calculate it?

Two ways:
1. eccdf <- function(x) { return( 1 - ecdf(x)(x) ) }
  This returns an array of element, not an object (like ecdf)
2. Cut&Paste "ecdf" code (from R write "ecdf" and then Enter) into a
new function "eccdf" (or whatever u want); in place of "cumsum(...)"
write "1-cumsum(...)", and rename the class name "ecdf" in"eccdf" (or
other). Note, doing "plot(eccdf(x))" you will not get similar result
to "plot(ecdf(x))" since the last one call "plot.ecdf". By the way you
can write a "plot.eccdf" function.

-- Marco

>
> thank you in advance
>
> /salva
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From h.wickham at gmail.com  Mon Jun  4 14:01:14 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 4 Jun 2007 14:01:14 +0200
Subject: [R] Bug in seq.date?
In-Reply-To: <971536df0706040406w4dd35cc8pe95116fd7ba5fc8f@mail.gmail.com>
References: <f8e6ff050706040039v1cd56ades817534ece083a4a8@mail.gmail.com>
	<971536df0706040406w4dd35cc8pe95116fd7ba5fc8f@mail.gmail.com>
Message-ID: <f8e6ff050706040501kd3d7a57i2895a14fabb9f446@mail.gmail.com>

On 6/4/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> Note that chron does give the last day of the month:
>
> > library(chron)
> > seq(chron("1/31/2000"), chron("1/31/2001"), "month")
>  [1] 01/31/00 02/29/00 03/31/00 04/30/00 05/31/00 06/30/00 07/31/00 08/31/00
>  [9] 09/30/00 10/31/00 11/30/00 12/31/00 01/31/01

Thanks, that's very useful - I'll switch to using chron instead.

Hadley

> The zoo package has a "yearmon" class whose as.Date.yearmon can
> convert a "Date" to the end of the month:
> library(zoo)
> > library(zoo)
> > as.Date(as.yearmon(seq(as.Date("2000-1-31"), as.Date("2001-1-31"), "month")), 1)
>  [1] "2000-01-31" "2000-02-29" "2000-03-31" "2000-04-30" "2000-05-31"
>  [6] "2000-06-30" "2000-07-31" "2000-08-31" "2000-09-30" "2000-10-31"
> [11] "2000-11-30" "2000-12-31" "2001-01-31"
>
> And we do it ourself like this:
>
> > as.Date(format(seq(as.Date("2000-1-1"), as.Date("2001-1-1"), "month") + 32, "%Y-%m-01"))-1
>  [1] "2000-01-31" "2000-02-29" "2000-03-31" "2000-04-30" "2000-05-31"
>  [6] "2000-06-30" "2000-07-31" "2000-08-31" "2000-09-30" "2000-10-31"
> [11] "2000-11-30" "2000-12-31" "2001-01-31"
>
>
>
>
> On 6/4/07, hadley wickham <h.wickham at gmail.com> wrote:
> > > seq(as.Date("2000-1-1"), as.Date("2001-1-1"), "months")
> >  [1] "2000-01-01" "2000-02-01" "2000-03-01" "2000-04-01" "2000-05-01"
> >  [6] "2000-06-01" "2000-07-01" "2000-08-01" "2000-09-01" "2000-10-01"
> > [11] "2000-11-01" "2000-12-01" "2001-01-01"
> >
> >
> > > seq(as.Date("2000-1-31"), as.Date("2001-1-31"), "months")
> >  [1] "2000-01-31" "2000-03-02" "2000-03-31" "2000-05-01" "2000-05-31"
> >  [6] "2000-07-01" "2000-07-31" "2000-08-31" "2000-10-01" "2000-10-31"
> > [11] "2000-12-01" "2000-12-31" "2001-01-31"
> >
> > Is this a bug?
> >
> > Hadley
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>


From maitra at iastate.edu  Mon Jun  4 14:04:19 2007
From: maitra at iastate.edu (maitra at iastate.edu)
Date: Mon, 4 Jun 2007 07:04:19 -0500 (CDT)
Subject: [R] inverse cumulative distribution
Message-ID: <19474510711541@webmail.iastate.edu>

Doesn't quantile() do what you want?

HTH,
Ranjan

> hi all:
> 
> ecdf() is the empirical cumulative distribution function, but I need the 
> INVERSE cumulative distribution.
> 
> how can I calculate it?
> 
> thank you in advance
> 
> /salva
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From elyakhlifi_mustapha at yahoo.fr  Mon Jun  4 14:27:45 2007
From: elyakhlifi_mustapha at yahoo.fr (elyakhlifi mustapha)
Date: Mon, 4 Jun 2007 12:27:45 +0000 (GMT)
Subject: [R] textConnection
Message-ID: <20070604122745.33559.qmail@web27510.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070604/5730ee53/attachment.pl 

From ggrothendieck at gmail.com  Mon Jun  4 14:31:13 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 4 Jun 2007 08:31:13 -0400
Subject: [R] textConnection
In-Reply-To: <20070604122745.33559.qmail@web27510.mail.ukl.yahoo.com>
References: <20070604122745.33559.qmail@web27510.mail.ukl.yahoo.com>
Message-ID: <971536df0706040531p7788a297g2223bb808f4fdba1@mail.gmail.com>

Try:

closeAllConnections()


On 6/4/07, elyakhlifi mustapha <elyakhlifi_mustapha at yahoo.fr> wrote:
> hello,
> I wanna close the textConnection but I don't know how to do it can you help me please?
> thanks
>
>
>      _____________________________________________________________________________
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dieter.menne at menne-biomed.de  Mon Jun  4 14:34:05 2007
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Mon, 4 Jun 2007 12:34:05 +0000 (UTC)
Subject: [R] Standard errors of the predicted values from a lme (or lmer)
References: <mailman.11.1180778404.32181.r-help@stat.math.ethz.ch>
	<006b01c7a684$0285b740$2101a8c0@HP26282134612>
Message-ID: <loom.20070604T142258-821@post.gmane.org>

Fr?nzi Korner <fraenzi.korner <at> oikostat.ch> writes:

> sorry for not being more specific. I would like to use R to get a prediction
> (with standard error) of the response in a mixed model at selected values of
> the fixed-effects factors. Hence, in a mixed model, say, for response body
> size with, say, fixed factors sex and age, I would like to get a prediction
> of size for each sex and at selected ages such as 5, 10, 15; and I want a SE
> for that prediction as well. 
.... 

In that case, estimable in gmodels (by Greg Warnes, as also suggested by Michael
Kubovy) and glht in Thorsten Hothorn's multcomp are best. The first works for
lme out of the box, the very powerful glht can handle lmer(lme4), with strong
support for multiple testing. Too bad the latter does not immediately work with
lme, but it can be tweaked.

In both cases, you have to construct the contrast matrix, which can be
error-prone for complex models. To my knowledge (??), there is no
simple-to-handle package that generates this matrix with an intuitive interface.

Dieter


From timb at metrumrg.com  Mon Jun  4 14:50:07 2007
From: timb at metrumrg.com (Tim Bergsma)
Date: Mon, 04 Jun 2007 08:50:07 -0400
Subject: [R] test for nested factors
Message-ID: <46640A7F.6010702@metrumrg.com>

Is there a conventional way to test for nested factors?  I.e., if 'a' 
and 'b' are lists of same-length factors, does each level specified by 
'a' correspond to exactly one level specified by 'b'?

The function below seems to suffice, but I'd be happy to know of a more 
succinct solution, if it already exists.

Thanks,

Tim.

---

"%nested.in%" <- function(x,f,...){
	#coerce to list
	if(!is.list(x))x<-list(x)
	if(!is.list(f))f<-list(f)
	#collapse to vector
	x <- tapply(x[[1]],x)
	f <- tapply(f[[1]],f)
	#analyse
	return(all(sapply(lapply(split(f,x),unique),length)==1))
}

CO2$Plant %nested.in% CO2[,c("Type","Treatment")] #TRUE
CO2$Plant %nested.in% (CO2$uptake < mean(CO2$uptake)) #FALSE


From shiazy at gmail.com  Mon Jun  4 14:57:41 2007
From: shiazy at gmail.com (Shiazy Fuzzy)
Date: Mon, 4 Jun 2007 14:57:41 +0200
Subject: [R] inverse cumulative distribution
In-Reply-To: <19474510711541@webmail.iastate.edu>
References: <19474510711541@webmail.iastate.edu>
Message-ID: <9d3ef91d0706040557t72600c8ah35b85ec86d30ba17@mail.gmail.com>

Yes!!
sorry I've confused Inverse CDF with Complementary CDF.

-- Marco

On 6/4/07, maitra at iastate.edu <maitra at iastate.edu> wrote:
> Doesn't quantile() do what you want?
>
> HTH,
> Ranjan
>
> > hi all:
> >
> > ecdf() is the empirical cumulative distribution function, but I need the
> > INVERSE cumulative distribution.
> >
> > how can I calculate it?
> >
> > thank you in advance
> >
> > /salva
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ccleland at optonline.net  Mon Jun  4 15:09:01 2007
From: ccleland at optonline.net (Chuck Cleland)
Date: Mon, 04 Jun 2007 09:09:01 -0400
Subject: [R] Standard errors of the predicted values from a lme (or lmer)
In-Reply-To: <loom.20070604T142258-821@post.gmane.org>
References: <mailman.11.1180778404.32181.r-help@stat.math.ethz.ch>
	<006b01c7a684$0285b740$2101a8c0@HP26282134612>
	<loom.20070604T142258-821@post.gmane.org>
Message-ID: <46640EED.20700@optonline.net>

Dieter Menne wrote:
> Fr?nzi Korner <fraenzi.korner <at> oikostat.ch> writes:
> 
>> sorry for not being more specific. I would like to use R to get a prediction
>> (with standard error) of the response in a mixed model at selected values of
>> the fixed-effects factors. Hence, in a mixed model, say, for response body
>> size with, say, fixed factors sex and age, I would like to get a prediction
>> of size for each sex and at selected ages such as 5, 10, 15; and I want a SE
>> for that prediction as well. 
> .... 
> 
> In that case, estimable in gmodels (by Greg Warnes, as also suggested by Michael
> Kubovy) and glht in Thorsten Hothorn's multcomp are best. The first works for
> lme out of the box, the very powerful glht can handle lmer(lme4), with strong
> support for multiple testing. Too bad the latter does not immediately work with
> lme, but it can be tweaked.
> 
> In both cases, you have to construct the contrast matrix, which can be
> error-prone for complex models. To my knowledge (??), there is no
> simple-to-handle package that generates this matrix with an intuitive interface.
> 
> Dieter

  See contrast() in the contrast package.

library(nlme)
Orthodont2 <- Orthodont
Orthodont2$newAge <- Orthodont$age - 11

fm1Orth.lme2 <- lme(distance ~ Sex*newAge, data = Orthodont2, random = ~
newAge | Subject)

contrast(
    fm1Orth.lme2,
    a = list(Sex = levels(Orthodont2$Sex)[1], newAge = 8 - 11))

lme model parameter contrast
 Contrast      S.E.    Lower    Upper     t  df Pr(>|t|)
 22.61563 0.5265041 21.58370 23.64755 42.95 100        0

> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From albmont at centroin.com.br  Mon Jun  4 15:18:41 2007
From: albmont at centroin.com.br (Alberto Monteiro)
Date: Mon, 4 Jun 2007 11:18:41 -0200
Subject: [R] Abstract plot
Message-ID: <20070604131648.M17296@centroin.com.br>

I want to make a plot, but instead of showing _numerical_ values,
I would like to show _symbolic_ values.

For example, I want to plot a function y = a x + b, where
x varies between Xmin and Xmax. I would like the plot
to show, in the x-axis, the strings Xmin and Xmax, instead
of their numeric values. Is it possible?

Alberto Monteiro


From h.wickham at gmail.com  Mon Jun  4 15:29:09 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 4 Jun 2007 15:29:09 +0200
Subject: [R] test for nested factors
In-Reply-To: <46640A7F.6010702@metrumrg.com>
References: <46640A7F.6010702@metrumrg.com>
Message-ID: <f8e6ff050706040629x46180cd5ja3365c1f16d8ff26@mail.gmail.com>

On 6/4/07, Tim Bergsma <timb at metrumrg.com> wrote:
> Is there a conventional way to test for nested factors?  I.e., if 'a'
> and 'b' are lists of same-length factors, does each level specified by
> 'a' correspond to exactly one level specified by 'b'?
>
> The function below seems to suffice, but I'd be happy to know of a more
> succinct solution, if it already exists.

How about:

"%nested%" <- function(a, b) {
	if (is.list(a)) a <- do.call("interaction", c(a, drop=TRUE))
	if (is.list(b)) b <- do.call("interaction", c(b, drop=TRUE))
	
	length(unique(a))  == length(unique(interaction(a, b, drop=TRUE)))
}

CO2$Plant %nested% CO2[,c("Type","Treatment")] #TRUE
CO2$Plant %nested% (CO2$uptake < mean(CO2$uptake)) #FALSE

?

Hadley


From andrewjyee at gmail.com  Mon Jun  4 15:34:03 2007
From: andrewjyee at gmail.com (Andrew Yee)
Date: Mon, 4 Jun 2007 09:34:03 -0400
Subject: [R] getting t.test to work with apply()
In-Reply-To: <4663CDF1.5070409@biostat.ku.dk>
References: <5dff5a0d0706031448t5e60448en5aa028b42c65a4a9@mail.gmail.com>
	<4663B3EF.4050601@karlin.mff.cuni.cz> <4663CDF1.5070409@biostat.ku.dk>
Message-ID: <5dff5a0d0706040634h5549495dq414c6fcce665a590@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070604/54b8190b/attachment.pl 

From carmei3 at web.de  Mon Jun  4 15:39:30 2007
From: carmei3 at web.de (Web de)
Date: Mon, 04 Jun 2007 15:39:30 +0200
Subject: [R] p-value gee
Message-ID: <46641612.4090001@web.de>

Hi to all,
I found in the R-help archive how to calculate the p-value for a gee result:
http://finzi.psych.upenn.edu/R/Rhelp02a/archive/74150.html

but there are two questions (I am afraid they are basic questions ...)
1. why is the result multiplicated  with 2
2. how could I decide between lower.tail =TRUE and FALSE:
example:
2*pnorm(c(1.8691945,0.5882351,2.4903091,1.9287802,2.3172983,2.2092593,2.2625959,1.6395695), 
lower.tail =TRUE)  

I did not find anything about lower tail in my books only about one 
tailed and two tailed.

With regards
Carmen


From dimitris.rizopoulos at med.kuleuven.be  Mon Jun  4 15:41:05 2007
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Mon, 4 Jun 2007 15:41:05 +0200
Subject: [R] Abstract plot
References: <20070604131648.M17296@centroin.com.br>
Message-ID: <010001c7a6ad$ff93d560$0540210a@www.domain>

maybe you're looking for curve(), e.g.,

curve(5*x + 2, -3, 4, ylab = expression(5*x + 2))


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Alberto Monteiro" <albmont at centroin.com.br>
To: <r-help at stat.math.ethz.ch>
Sent: Monday, June 04, 2007 3:18 PM
Subject: [R] Abstract plot


>I want to make a plot, but instead of showing _numerical_ values,
> I would like to show _symbolic_ values.
>
> For example, I want to plot a function y = a x + b, where
> x varies between Xmin and Xmax. I would like the plot
> to show, in the x-axis, the strings Xmin and Xmax, instead
> of their numeric values. Is it possible?
>
> Alberto Monteiro
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm


From Thierry.ONKELINX at inbo.be  Mon Jun  4 15:41:45 2007
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 4 Jun 2007 15:41:45 +0200
Subject: [R] Abstract plot
In-Reply-To: <20070604131648.M17296@centroin.com.br>
Message-ID: <2E9C414912813E4EB981326983E0A10403008B3E@inboexch.inbo.be>

You can do than. You just need to specify the strings in the
axis-labels.

plot(y~x, axes = F)
axis(1, at = range(x), labels = c("Xmin", "Xmax"))
axis(2)

Cheers,

Thierry
------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Reseach Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium
tel. + 32 54/436 185
Thierry.Onkelinx op inbo.be
www.inbo.be 

Do not put your faith in what statistics say until you have carefully
considered what they do not say.  ~William W. Watt
A statistical analysis, properly conducted, is a delicate dissection of
uncertainties, a surgery of suppositions. ~M.J.Moroney

 

> -----Oorspronkelijk bericht-----
> Van: r-help-bounces op stat.math.ethz.ch 
> [mailto:r-help-bounces op stat.math.ethz.ch] Namens Alberto Monteiro
> Verzonden: maandag 4 juni 2007 15:19
> Aan: r-help op stat.math.ethz.ch
> Onderwerp: [R] Abstract plot
> 
> I want to make a plot, but instead of showing _numerical_ 
> values, I would like to show _symbolic_ values.
> 
> For example, I want to plot a function y = a x + b, where x 
> varies between Xmin and Xmax. I would like the plot to show, 
> in the x-axis, the strings Xmin and Xmax, instead of their 
> numeric values. Is it possible?
> 
> Alberto Monteiro
> 
> ______________________________________________
> R-help op stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Thierry.ONKELINX at inbo.be  Mon Jun  4 15:43:53 2007
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 4 Jun 2007 15:43:53 +0200
Subject: [R] getting t.test to work with apply()
In-Reply-To: <5dff5a0d0706040634h5549495dq414c6fcce665a590@mail.gmail.com>
Message-ID: <2E9C414912813E4EB981326983E0A10403008B41@inboexch.inbo.be>

Apply passes the row as a vector, not as a dataframe. So you need to remove the colons in x[, alive] and x[, dead]

results <-apply(raw.sample,1,function(x) t.test(x[alive],x[dead]))

Cheers,

Thierry
----------------------------------------------------------------------------
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Reseach Institute for Nature and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics, methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium
tel. + 32 54/436 185
Thierry.Onkelinx op inbo.be
www.inbo.be 

Do not put your faith in what statistics say until you have carefully considered what they do not say.  ~William W. Watt
A statistical analysis, properly conducted, is a delicate dissection of uncertainties, a surgery of suppositions. ~M.J.Moroney

 

> -----Oorspronkelijk bericht-----
> Van: r-help-bounces op stat.math.ethz.ch 
> [mailto:r-help-bounces op stat.math.ethz.ch] Namens Andrew Yee
> Verzonden: maandag 4 juni 2007 15:34
> Aan: Peter Dalgaard
> CC: r-help op stat.math.ethz.ch
> Onderwerp: Re: [R] getting t.test to work with apply()
> 
> Thanks for everyone's suggestions.
> 
> I did try
> 
>  results <-apply(raw.sample,1,function(x) t.test(x[,alive],x[,dead]))
> 
> However, I get:
> 
> "Error in x[, alive] : incorrect number of dimensions"
> 
> Full disclosure, raw.sample is a data.frame, and I am using 
> alive and dead as indexing vectors.
> 
> On the other hand, the lapply suggestion works better.
> 
> results <- lapply(1:nrow(raw.sample), function(i) t.test(raw.sample
> [i,alive],raw.sample[i,dead]))
> 
> Thanks,
> Andrew
> 
> 
>  On 6/4/07, Peter Dalgaard <P.Dalgaard op biostat.ku.dk> wrote:
> 
> > Petr Klasterecky wrote:
> > > Andrew Yee napsal(a):
> > >
> > >> Hi, I'm interested in using apply() with t.test() on a 
> data.frame.
> > >>
> > >> Specifically, I'd like to use apply() to do the following:
> > >>
> > >>  t.test(raw.sample[1,alive],raw.sample[1,dead])
> > >> t.test(raw.sample[2,alive],raw.sample[2,dead])
> > >>  t.test(raw.sample[3,alive],raw.sample[3,dead])
> > >> etc.
> > >>
> > >> I tried the following,
> > >>
> > >> apply(raw.sample,1,function(x) 
> t.test(raw.sample[,alive],raw.sample
> > [,dead]))
> > >>
> > >
> > > Two comments:
> > > 1) apply() works on arrays. If your dataframe only has numeric 
> > > values, turn it (or its copy) to a matrix via 
> as.matrix(). If it has 
> > > mixed variables, take only the numeric part for t-tests. The 
> > > conversion is made implicitly but explicit asking for it 
> cannot hurt.
> > > 2) the main problem - you are using a wrong argument to t.test
> > >
> > > The call should look like
> > > apply(as.matrix(raw.sample), 1, function(x){t.test(x[alive], 
> > > x[dead])})
> > >
> > > assuming 'alive' and 'dead' are logical vectors of the 
> same length 
> > > as
> > 'x'.
> > >
> > > Petr
> > >
> > Notice also that the other apply-style functions may give an easier 
> > route to the goal:
> >
> > lapply(1:N, function(i) 
> > t.test(raw.sample[i,alive],raw.sample[i,dead]))
> >
> > or (maybe, depends on raw.sample being a data frame and alive/dead 
> > being indexing vectors)
> >
> > mapply(t.test, raw.sample[,alive], raw.sample[,dead])
> >
> > >
> > >> but it gives me a list of identical results.
> > >>
> > >>
> > >> Thanks,
> > >> Andrew
> > >>
> > >>      [[alternative HTML version deleted]]
> > >>
> > >> ______________________________________________
> > >> R-help op stat.math.ethz.ch mailing list 
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, 
> reproducible code.
> > >>
> > >>
> > >
> > >
> >
> >
> > --
> >   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
> > c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> > (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45)
> > 35327918
> > ~~~~~~~~~~ - (p.dalgaard op biostat.ku.dk)                  FAX: (+45)
> > 35327907
> >
> >
> 
> 	[[alternative HTML version deleted]]
> 
>


From P.Dalgaard at biostat.ku.dk  Mon Jun  4 15:46:53 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 04 Jun 2007 15:46:53 +0200
Subject: [R] getting t.test to work with apply()
In-Reply-To: <5dff5a0d0706040634h5549495dq414c6fcce665a590@mail.gmail.com>
References: <5dff5a0d0706031448t5e60448en5aa028b42c65a4a9@mail.gmail.com>	<4663B3EF.4050601@karlin.mff.cuni.cz>
	<4663CDF1.5070409@biostat.ku.dk>
	<5dff5a0d0706040634h5549495dq414c6fcce665a590@mail.gmail.com>
Message-ID: <466417CD.1040408@biostat.ku.dk>

Andrew Yee wrote:
> Thanks for everyone's suggestions.
>
> I did try
>
>  results <-apply(raw.sample,1,function(x) t.test(x[,alive],x[,dead]))
>
> However, I get:
>
> "Error in x[, alive] : incorrect number of dimensions"
>
> Full disclosure, raw.sample is a data.frame, and I am using alive and dead
> as indexing vectors.
>
> On the other hand, the lapply suggestion works better.
>
> results <- lapply(1:nrow(raw.sample), function(i) t.test(raw.sample
> [i,alive],raw.sample[i,dead]))
>
>   
nrow()?

Oops, yes. I didn't notice that your data are transposed relative to the
usual "cases x variables" layout. 

So mapply() is not going to work unless you use
as.data.frame(t(raw.sample)) first.

     -pd
> Thanks,
> Andrew
>
>
>  On 6/4/07, Peter Dalgaard <P.Dalgaard at biostat.ku.dk> wrote:
>
>   
>> Petr Klasterecky wrote:
>>     
>>> Andrew Yee napsal(a):
>>>
>>>       
>>>> Hi, I'm interested in using apply() with t.test() on a data.frame.
>>>>
>>>> Specifically, I'd like to use apply() to do the following:
>>>>
>>>>  t.test(raw.sample[1,alive],raw.sample[1,dead])
>>>> t.test(raw.sample[2,alive],raw.sample[2,dead])
>>>>  t.test(raw.sample[3,alive],raw.sample[3,dead])
>>>> etc.
>>>>
>>>> I tried the following,
>>>>
>>>> apply(raw.sample,1,function(x) t.test(raw.sample[,alive],raw.sample
>>>>         
>> [,dead]))
>>     
>>> Two comments:
>>> 1) apply() works on arrays. If your dataframe only has numeric values,
>>> turn it (or its copy) to a matrix via as.matrix(). If it has mixed
>>> variables, take only the numeric part for t-tests. The conversion is
>>> made implicitly but explicit asking for it cannot hurt.
>>> 2) the main problem - you are using a wrong argument to t.test
>>>
>>> The call should look like
>>> apply(as.matrix(raw.sample), 1, function(x){t.test(x[alive], x[dead])})
>>>
>>> assuming 'alive' and 'dead' are logical vectors of the same length as
>>>       
>> 'x'.
>>     
>>> Petr
>>>
>>>       
>> Notice also that the other apply-style functions may give an easier
>> route to the goal:
>>
>> lapply(1:N, function(i) t.test(raw.sample[i,alive],raw.sample[i,dead]))
>>
>> or (maybe, depends on raw.sample being a data frame and alive/dead being
>> indexing vectors)
>>
>> mapply(t.test, raw.sample[,alive], raw.sample[,dead])
>>
>>     
>>>> but it gives me a list of identical results.
>>>>
>>>>
>>>> Thanks,
>>>> Andrew
>>>>
>>>>      [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at stat.math.ethz.ch mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>>         
>> http://www.R-project.org/posting-guide.html
>>     
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>>         
>>>       
>> --
>>   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>> c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>> (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45)
>> 35327918
>> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45)
>> 35327907
>>
>>
>>     
>
> 	[[alternative HTML version deleted]]
>
>   
> ------------------------------------------------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From chrysopa at gmail.com  Mon Jun  4 15:51:01 2007
From: chrysopa at gmail.com (Ronaldo Reis Junior)
Date: Mon, 4 Jun 2007 10:51:01 -0300
Subject: [R] Front end for R in Mac
In-Reply-To: <86b533e90706040357u1aa9bbdap6f7fbc8fa33c4418@mail.gmail.com>
References: <86b533e90706040357u1aa9bbdap6f7fbc8fa33c4418@mail.gmail.com>
Message-ID: <200706041051.01555.chrysopa@gmail.com>

Em Segunda 04 Junho 2007 07:57, KK escreveu:
> Hello all.
> I just switched from Windows to Mac and I am trying to find a good front
> end for R in Mac that is relatively user friendly and works well. I have
> used RWinEdt for several years in Windows, and something similar to RWinEdt
> for Mac would be ideal. I've looked into some of the emacs editor (e.g.,
> Aquamacs) but I wanted to see what other people prefer, as I'm not sure I'm
> an emacs person (at this time anyway).
> Thanks,
> Ken

Ken,

Try JGR, is a JAVA Interface.

Ronaldo

-- 
I've finally learned what "upward compatible" means.  It means we get to
keep all our old mistakes.
		-- Dennie van Tassel
--
> Prof. Ronaldo Reis J?nior
|  .''`. UNIMONTES/Depto. Biologia Geral/Lab. de Ecologia
| : :'  : Campus Universit?rio Prof. Darcy Ribeiro, Vila Mauric?ia
| `. `'` CP: 126, CEP: 39401-089, Montes Claros - MG - Brasil
|   `- Fone: (38) 3229-8187 | ronaldo.reis em unimontes.br | chrysopa em gmail.com
| http://www.ppgcb.unimontes.br/ | ICQ#: 5692561 | LinuxUser#: 205366


From andrewjyee at gmail.com  Mon Jun  4 15:51:36 2007
From: andrewjyee at gmail.com (Andrew Yee)
Date: Mon, 4 Jun 2007 09:51:36 -0400
Subject: [R] getting t.test to work with apply()
In-Reply-To: <466417CD.1040408@biostat.ku.dk>
References: <5dff5a0d0706031448t5e60448en5aa028b42c65a4a9@mail.gmail.com>
	<4663B3EF.4050601@karlin.mff.cuni.cz> <4663CDF1.5070409@biostat.ku.dk>
	<5dff5a0d0706040634h5549495dq414c6fcce665a590@mail.gmail.com>
	<466417CD.1040408@biostat.ku.dk>
Message-ID: <5dff5a0d0706040651q51b259ecs74e33d093ca8b3eb@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070604/a0fd9bc4/attachment.pl 

From ja at astro.livjm.ac.uk  Mon Jun  4 17:36:00 2007
From: ja at astro.livjm.ac.uk (James Allsopp)
Date: Mon, 04 Jun 2007 16:36:00 +0100
Subject: [R] Calling R from within C++ examples?
Message-ID: <46643160.8030808@astro.livjm.ac.uk>

Hello,
I was wondering if anyone had an example of using C++ to call routines
from within R. What I want to be able to do is call the dip routine from
the diptest package. I've tried using the code from the package
directly, but I think it needs to have had other procedures to be run on
the data before-hand.

Any ideas as I'd be very grateful.
James


From christophe at pallier.org  Mon Jun  4 17:51:45 2007
From: christophe at pallier.org (Christophe Pallier)
Date: Mon, 4 Jun 2007 17:51:45 +0200
Subject: [R] test for nested factors
In-Reply-To: <46640A7F.6010702@metrumrg.com>
References: <46640A7F.6010702@metrumrg.com>
Message-ID: <dea6cb960706040851x7310804bh72f4460df7675778@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070604/7caf6095/attachment.pl 

From rhelp.stats at gmail.com  Mon Jun  4 17:54:44 2007
From: rhelp.stats at gmail.com (R Help)
Date: Mon, 4 Jun 2007 12:54:44 -0300
Subject: [R] R 'could not find any X11 fonts'
In-Reply-To: <461A2D9E.4060603@fs-analyse.dk>
References: <461A2D9E.4060603@fs-analyse.dk>
Message-ID: <c84ed6950706040854v1ee57c11mf842daa730dd9417@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070604/a6d42474/attachment.pl 

From guanrao at yahoo.com  Mon Jun  4 17:52:36 2007
From: guanrao at yahoo.com (Guanrao Chen)
Date: Mon, 4 Jun 2007 08:52:36 -0700 (PDT)
Subject: [R] R runs on Windows XP, how to connect to Oracle DB on Unix box?
In-Reply-To: <web-10660380@mailadmin.colpos.mx>
Message-ID: <20070604155237.26158.qmail@web50605.mail.re2.yahoo.com>

I do not have the right to install R on the Unix box.

Thanks.


       
____________________________________________________________________________________

Comedy with an Edge to see what's on, when.


From macq at llnl.gov  Mon Jun  4 18:40:07 2007
From: macq at llnl.gov (Don MacQueen)
Date: Mon, 4 Jun 2007 09:40:07 -0700
Subject: [R] Bug in seq.date?
In-Reply-To: <f8e6ff050706040501kd3d7a57i2895a14fabb9f446@mail.gmail.com>
References: <f8e6ff050706040039v1cd56ades817534ece083a4a8@mail.gmail.com>
	<971536df0706040406w4dd35cc8pe95116fd7ba5fc8f@mail.gmail.com>
	<f8e6ff050706040501kd3d7a57i2895a14fabb9f446@mail.gmail.com>
Message-ID: <p06230908c289f0331721@[128.115.153.6]>

I think you can easily get the last days of the months by creating a 
series starting on the first days, and subtracting one from each.

seq(as.Date("2000-2-1"), as.Date("2001-2-1"), "months") -1

-Don

At 2:01 PM +0200 6/4/07, hadley wickham wrote:
>On 6/4/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
>>  Note that chron does give the last day of the month:
>>
>>  > library(chron)
>>  > seq(chron("1/31/2000"), chron("1/31/2001"), "month")
>>   [1] 01/31/00 02/29/00 03/31/00 04/30/00 05/31/00 06/30/00 07/31/00 08/31/00
>>   [9] 09/30/00 10/31/00 11/30/00 12/31/00 01/31/01
>
>Thanks, that's very useful - I'll switch to using chron instead.
>
>Hadley
>
>>  The zoo package has a "yearmon" class whose as.Date.yearmon can
>>  convert a "Date" to the end of the month:
>>  library(zoo)
>>  > library(zoo)
>>  > as.Date(as.yearmon(seq(as.Date("2000-1-31"), 
>>as.Date("2001-1-31"), "month")), 1)
>>   [1] "2000-01-31" "2000-02-29" "2000-03-31" "2000-04-30" "2000-05-31"
>>   [6] "2000-06-30" "2000-07-31" "2000-08-31" "2000-09-30" "2000-10-31"
>>  [11] "2000-11-30" "2000-12-31" "2001-01-31"
>>
>>  And we do it ourself like this:
>>
>>  > as.Date(format(seq(as.Date("2000-1-1"), as.Date("2001-1-1"), 
>>"month") + 32, "%Y-%m-01"))-1
>>   [1] "2000-01-31" "2000-02-29" "2000-03-31" "2000-04-30" "2000-05-31"
>>   [6] "2000-06-30" "2000-07-31" "2000-08-31" "2000-09-30" "2000-10-31"
>>  [11] "2000-11-30" "2000-12-31" "2001-01-31"
>>
>>
>>
>>
>>  On 6/4/07, hadley wickham <h.wickham at gmail.com> wrote:
>>  > > seq(as.Date("2000-1-1"), as.Date("2001-1-1"), "months")
>>  >  [1] "2000-01-01" "2000-02-01" "2000-03-01" "2000-04-01" "2000-05-01"
>>  >  [6] "2000-06-01" "2000-07-01" "2000-08-01" "2000-09-01" "2000-10-01"
>>  > [11] "2000-11-01" "2000-12-01" "2001-01-01"
>>  >
>>  >
>  > > > seq(as.Date("2000-1-31"), as.Date("2001-1-31"), "months")
>>  >  [1] "2000-01-31" "2000-03-02" "2000-03-31" "2000-05-01" "2000-05-31"
>>  >  [6] "2000-07-01" "2000-07-31" "2000-08-31" "2000-10-01" "2000-10-31"
>>  > [11] "2000-12-01" "2000-12-31" "2001-01-31"
>>  >
>>  > Is this a bug?
>>  >
>>  > Hadley
>>  >
>>  > ______________________________________________
>>  > R-help at stat.math.ethz.ch mailing list
>>  > https://stat.ethz.ch/mailman/listinfo/r-help
>>  > PLEASE do read the posting guide 
>>http://www.R-project.org/posting-guide.html
>  > > and provide commented, minimal, self-contained, reproducible code.
>  > >
>  >
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA


From h.wickham at gmail.com  Mon Jun  4 19:55:29 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 4 Jun 2007 19:55:29 +0200
Subject: [R] Bug in seq.date?
In-Reply-To: <p06230908c289f0331721@128.115.153.6>
References: <f8e6ff050706040039v1cd56ades817534ece083a4a8@mail.gmail.com>
	<971536df0706040406w4dd35cc8pe95116fd7ba5fc8f@mail.gmail.com>
	<f8e6ff050706040501kd3d7a57i2895a14fabb9f446@mail.gmail.com>
	<p06230908c289f0331721@128.115.153.6>
Message-ID: <f8e6ff050706041055h79d3854bu936f629473750980@mail.gmail.com>

On 6/4/07, Don MacQueen <macq at llnl.gov> wrote:
> I think you can easily get the last days of the months by creating a
> series starting on the first days, and subtracting one from each.
>
> seq(as.Date("2000-2-1"), as.Date("2001-2-1"), "months") -1

Thanks for the suggestion, but for my problem the dates are user
supplied so I don't know if they fall at the end of the month or not.

Hadley


From CaskenetteA at dfo-mpo.gc.ca  Mon Jun  4 20:27:00 2007
From: CaskenetteA at dfo-mpo.gc.ca (Caskenette, Amanda)
Date: Mon, 4 Jun 2007 14:27:00 -0400
Subject: [R] Local polynomial regression using locfit
Message-ID: <A61708A2D512974BAD5C77CD88B83C089E89B3@lauimlex01.lau.dfo-mpo.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070604/5b2fc2d1/attachment.pl 

From sfalcon at fhcrc.org  Mon Jun  4 20:40:21 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Mon, 04 Jun 2007 11:40:21 -0700
Subject: [R] locked environment and inheritance
In-Reply-To: <863114.36116.qm@web56206.mail.re3.yahoo.com> (johan Faux's
	message of "Sun, 3 Jun 2007 18:27:40 -0700 (PDT)")
References: <863114.36116.qm@web56206.mail.re3.yahoo.com>
Message-ID: <m2vee31s2y.fsf@ziti.local>

johan Faux <johanfaux at yahoo.com> writes:

> Hi,
>
> I have a S3 package with namespace called "myS3Pkg". Inside my package
> I would like to create a S4 class which extends (adds 2 slots) another
> S4 class from some other package. The class should be created in
> "myPkg" environment (and not global environment).
>
> Using:
>
>
> setClass("myS4class", representation("otherS4class", mydata =
> "numeric"), where = topenv())

have you tried just omitting the where argument?  Classes will get
defined in the package environment and I think that's what you want.

+ seth
-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
http://bioconductor.org


From sabunime at gmail.com  Mon Jun  4 20:45:03 2007
From: sabunime at gmail.com (Saeed Abu Nimeh)
Date: Mon, 04 Jun 2007 13:45:03 -0500
Subject: [R] naiveBayes other than e1071
In-Reply-To: <9d3ef91d0706040557t72600c8ah35b85ec86d30ba17@mail.gmail.com>
References: <19474510711541@webmail.iastate.edu>
	<9d3ef91d0706040557t72600c8ah35b85ec86d30ba17@mail.gmail.com>
Message-ID: <46645DAF.7080307@gmail.com>

Hi List,
Is there a naiveBayes interface other than the one in e1071 package. For
some reason on certain datasets all predicted values are NaN, but it
predicts well on others.
Thanks,
Saeed
---
model <- naiveBayes(x.train, y.train, laplace = 3)
pred <- predict(model,x.test,type="raw")


From hassen62 at voila.fr  Mon Jun  4 20:58:53 2007
From: hassen62 at voila.fr (hassen62 at voila.fr)
Date: Mon,  4 Jun 2007 20:58:53 +0200 (CEST)
Subject: [R] reading file. xls
Message-ID: <7777304.13401180983533813.JavaMail.www@wwinf4606>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070604/59e5a617/attachment.pl 

From stanhopkins at comcast.net  Mon Jun  4 21:08:11 2007
From: stanhopkins at comcast.net (Stan Hopkins)
Date: Mon, 4 Jun 2007 14:08:11 -0500
Subject: [R] Extracting lists in the dataframe $ format
Message-ID: <001f01c7a6db$b1be35f0$6405a8c0@MXD32803WB>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070604/f6fe58ef/attachment.pl 

From toby909 at gmail.com  Mon Jun  4 21:30:00 2007
From: toby909 at gmail.com (toby909 at gmail.com)
Date: Mon, 04 Jun 2007 12:30:00 -0700
Subject: [R] how to specify starting values in varIdent() of lme()
In-Reply-To: <40e66e0b0706011310y1c7833f6n2fc29585b904dffc@mail.gmail.com>
References: <f3pni1$id5$1@sea.gmane.org>
	<40e66e0b0706011310y1c7833f6n2fc29585b904dffc@mail.gmail.com>
Message-ID: <46646838.4030100@gmail.com>

Douglas Bates wrote:
> On 6/1/07, toby909 at gmail.com <toby909 at gmail.com> wrote:
> 
>>I was reading the help but just did not get how to specify starting values for
>>varIdent() of the lme() function, although I managed to do it for corSymm().
> 
> 
>>Do I specify the values just as they are printed out in an output, like c(1,
>>1.3473, 1.0195). Or do I need to take the residual and multiply it with these
>>like c(0.2235, 0.2235*1.3473, 0.2235*1.0195)
>>or any other form that I dont know of?
> 
> 
> Strangely enough you specify it in the form described in
> 
> ?varIdent
> 
> Look at the description of the value argument.
> 

Now the list knows how to find the help of the varIdent function.

For my situation, I think R does not like expressions like 2=1.94..., "2" 
supposed to serve as label....

summary(m3 <- lme(score~timef-1, dtaa, ~timef-1|orgid, corSymm(svc,~1|orgid/id), 
varIdent(c(1.94,1.05),~1|time),,,na.omit,lmeControl(1000,1000,,,2000,,,1,1)))

Error in varIdent(c(1.94, 1.05), ~1 | time) :
         Initial values must have group names in varIdent


summary(m3 <- lme(score~timef-1, dtaa, ~timef-1|orgid, corSymm(svc,~1|orgid/id), 
varIdent(c(2=1.94,3=1.05),~1|time),,,na.omit,lmeControl(1000,1000,,,2000,,,1,1)))

Error: syntax error in "summary(m3 <- lme(score~timef-1, dtaa, ~timef-1|orgid, 
corSymm(svc,~1|orgid/id), varIdent(c(2="



Without starting values:

Linear mixed-effects model fit by REML
  Data: dtaa
         AIC      BIC   logLik
   -697.0142 -601.366 363.5071

Random effects:
  Formula: ~timef - 1 | orgid
  Structure: General positive-definite, Log-Cholesky parametrization
          StdDev     Corr
timef1   0.02974621 timef1 timef2
timef2   0.05790348 0.923
timef3   0.03745570 0.921  0.999
Residual 0.22385809

Correlation Structure: General
  Formula: ~1 | orgid/id
  Parameter estimate(s):
  Correlation:
   1     2
2 0.503
3 0.578 0.475
Variance function:
  Structure: Different standard deviations per stratum
  Formula: ~1 | time
  Parameter estimates:
        1        2        3
1.000000 1.411556 1.002088
Fixed effects: score ~ timef - 1
             Value   Std.Error   DF   t-value p-value
timef1 -0.3813594 0.006800189 4253 -56.08070       0
timef2 -0.2551952 0.010747688 4253 -23.74419       0
timef3 -0.3939206 0.007296932 4253 -53.98441       0
  Correlation:
        timef1 timef2
timef2 0.625
timef3 0.675  0.666

Standardized Within-Group Residuals:
        Min         Q1        Med         Q3        Max
-1.1898841 -0.5756576 -0.4576534  0.2810892  4.1498533

Number of Observations: 4347
Number of Groups: 92






> 
>>Thanks Toby
>>
>>
>>
>>
>>
>>Linear mixed-effects model fit by REML
>>  Data: dtaa
>>        AIC       BIC   logLik
>>   -788.783 -692.5656 409.3915
>>
>>Random effects:
>>  Formula: ~timef - 1 | orgid
>>  Structure: General positive-definite, Log-Cholesky parametrization
>>          StdDev     Corr
>>timef1   0.04398482 timef1 timef2
>>timef2   0.07910354 1
>>timef3   0.03648411 1      1
>>Residual 0.22350583
>>
>>Correlation Structure: General
>>  Formula: ~1 | orgid/id
>>  Parameter estimate(s):
>>  Correlation:
>>   1     2
>>2 0.487
>>3 0.597 0.440
>>Variance function:
>>  Structure: Different standard deviations per stratum
>>  Formula: ~1 | time
>>  Parameter estimates:
>>        1        2        3
>>1.000000 1.347341 1.019529
>>Fixed effects: score ~ timef - 1
>>             Value   Std.Error   DF   t-value p-value
>>timef1 -0.3846847 0.007627811 4421 -50.43186       0
>>timef2 -0.2727646 0.012012786 4421 -22.70619       0
>>timef3 -0.3961244 0.007180147 4421 -55.16939       0
>>  Correlation:
>>        timef1 timef2
>>timef2 0.735
>>timef3 0.746  0.670
>>
>>Standardized Within-Group Residuals:
>>        Min         Q1        Med         Q3        Max
>>-1.4659548 -0.5982929 -0.4096429  0.3101507  4.0911728
>>
>>Number of Observations: 4515
>>Number of Groups: 92
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From scame at fastmail.fm  Mon Jun  4 21:29:25 2007
From: scame at fastmail.fm (Rehceb Rotkiv)
Date: Mon, 4 Jun 2007 12:29:25 -0700 (PDT)
Subject: [R] Calculating column percentages of a table
In-Reply-To: <4661DC2F.1090009@optonline.net>
References: <10931035.post@talk.nabble.com> <4661DC2F.1090009@optonline.net>
Message-ID: <10956579.post@talk.nabble.com>



Chuck Cleland wrote:
> 
>>  Does this help?
> 

Yes, that's what I needed, thanks!

Rehceb
-- 
View this message in context: http://www.nabble.com/Calculating-column-percentages-of-a-table-tf3858317.html#a10956579
Sent from the R help mailing list archive at Nabble.com.


From ehernandez at inmegen.gob.mx  Mon Jun  4 20:28:36 2007
From: ehernandez at inmegen.gob.mx (Dr. Enrique =?iso-8859-1?Q?Hern=E1ndez_Lemus?=)
Date: Mon, 4 Jun 2007 13:28:36 -0500 (CDT)
Subject: [R] Same scale on different q-q plots
Message-ID: <47885.201.147.87.66.1180981716.squirrel@www.inmegen.gob.mx>


Hi there, I'm new on the list. I am wondering as how to make different q-q
plots and display them on the same scale in order to attain an easy visual
comparison.

I have tried to use xlim and ylim as arguments to qq.plot in a similar
fashion to what is done on plot, also I have tried to use the plot.window
utility to implement xlim and ylim. I have even modified the qq.plot.R
source and re-compiled but none of these efforts has given any result.

I am doing a sequence of steps like the following:

library(car)
 p<-read.csv("inputP",header=T)
 p <- apply(p,c(1,2),as.numeric)
 q<-qchisq(1-p,2)

 png(file="outputP.png", bg="transparent")
plot.window(xlim=c(0,50), ylim=c(0,50))
qq.plot(q, dist="chisq", df=2)
 y<-rchisq(length(p),2)
 lines(y,y)
 dev.off()


Is there anything that I can do to produce several q-q plots from
different data and put them in the same scale, say x-values in (0-50) and
y-values in (0-50)?

Thank you to all in advance

-- 
Dr. Enrique Hern?ndez Lemus
Medical Sciences Researcher "B"
Computational Genomics
Phone: 5350-1970
Fax: 5350-1999
Email: ehernandez at inmegen.gob.mx


From ripley at stats.ox.ac.uk  Mon Jun  4 21:39:39 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 4 Jun 2007 20:39:39 +0100 (BST)
Subject: [R] reading file. xls
In-Reply-To: <7777304.13401180983533813.JavaMail.www@wwinf4606>
References: <7777304.13401180983533813.JavaMail.www@wwinf4606>
Message-ID: <Pine.LNX.4.64.0706042038450.19228@auk.stats>

On Mon, 4 Jun 2007, hassen62 at voila.fr wrote:

> Hi friends,
> I have a file.xls entitled "Dali" which is composed of two columns: the first is entitled "imp" and the  second is entitled:"exp".  I putted The file "Dali" in the following way:C:/programfiles/R 2.4.0. I have used the following command:>Dali<-read.table("Dali.xls", header=T)
> but I can't read this file from R console. What can I do? thanks.

Read the 'R Data Import/Export Manual' on how to read .xls files?

> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

and read the posting guide.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From sarah.goslee at gmail.com  Mon Jun  4 21:44:34 2007
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 4 Jun 2007 15:44:34 -0400
Subject: [R] Extracting lists in the dataframe $ format
In-Reply-To: <001f01c7a6db$b1be35f0$6405a8c0@MXD32803WB>
References: <001f01c7a6db$b1be35f0$6405a8c0@MXD32803WB>
Message-ID: <efb536d50706041244h6ec47e32lc04b9a2724bd428@mail.gmail.com>

This is a subset problem, not a problem with plot or lm. You need to
read eg  help("[.data.frame")


Here are two working examples:

# df already means something!
mydf <- data.frame(out=1:4*3,pred1=1:4,pred2=1:4*2)

regression <- function(tble,a,b)
{
           plot.new()
           plot(tble[,a]~tble[,b])
           lmm=lm(tble[,a]~tble[,b])
           abline(lmm)
           anova(lmm)
}

regression(mydf, 1, 3)

regression <- function(tble,a,b)
{
           plot.new()
           plot(tble[[a]]~tble[[b]])
           lmm=lm(tble[[a]]~tble[[b]])
           abline(lmm)
           anova(lmm)
}

regression(mydf, 1, 3)

Sarah

On 6/4/07, Stan Hopkins <stanhopkins at comcast.net> wrote:
> I'm new to R and am trying to extract the factors of a dataframe using numeric indices (e.g. df[1]) that are input to a function definition instead of the other types of references (e.g. df$out).  df[1] is a list(?) whose class is "dataframe".  These indexed lists can be printed successfuly but are not agreeable to the plot() and lm() functions shown below as are their df$out references.  Reading the documentation for plot and lm hasn't helped yet.  Thanks in advance - Stan.
>
> > df=data.frame(out=1:4*3,pred1=1:4,pred2=1:4*2)
> > regression=function(tble,a,b)
> + {
> +            plot.new()
> +            plot(tble[a]~tble[b])
> +            lmm=lm(tble[a]~tble[b])
> +            abline(lmm)
> +            anova(lmm)
> + }
> > df[1]
>   out
> 1   3
> 2   6
> 3   9
> 4  12
> > df
>   out pred1 pred2
> 1   3     1     2
> 2   6     2     4
> 3   9     3     6
> 4  12     4     8
> > regression(df,1,3)
> Error in model.frame(formula, rownames, variables, varnames, extras, extranames,  :
>         invalid type (list) for variable 'tble[a]'
> >
>
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From Max.Kuhn at pfizer.com  Mon Jun  4 22:00:30 2007
From: Max.Kuhn at pfizer.com (Kuhn, Max)
Date: Mon, 4 Jun 2007 16:00:30 -0400
Subject: [R] naiveBayes other than e1071
In-Reply-To: <46645DAF.7080307@gmail.com>
Message-ID: <71257D09F114DA4A8E134DEAC70F25D3088B08FB@groamrexm03.amer.pfizer.com>

Saeed,

There is a version in the klaR package. I recently submitted a change to
the predict function that may be related to your problem. 

If:

  1. the posterior probabilities (apart from the prior) are being
approximated by the product of the p(x_i|y_j) and

  2. a lot of predictors are being used

then posterior probabilities may have values of absolute zero. 

When the approximation is used, the approximate posterior probabilities
are normalized by their sum (which is zero in such cases).

The patch in klaR uses the product of the conditional divided by the
marginal of x_i (per the true formula). I haven't seen the problem occur
with this patch.

HTH,

Max

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Saeed Abu Nimeh
Sent: Monday, June 04, 2007 2:45 PM
To: r-help at stat.math.ethz.ch
Subject: [R] naiveBayes other than e1071

Hi List,
Is there a naiveBayes interface other than the one in e1071 package. For
some reason on certain datasets all predicted values are NaN, but it
predicts well on others.
Thanks,
Saeed
---
model <- naiveBayes(x.train, y.train, laplace = 3)
pred <- predict(model,x.test,type="raw")

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

----------------------------------------------------------------------
LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}


From revelator13 at wp.pl  Mon Jun  4 18:20:21 2007
From: revelator13 at wp.pl (=?ISO-8859-2?Q?piotr_iksi=F1ski?=)
Date: Mon, 04 Jun 2007 18:20:21 +0200
Subject: [R]  Detrended Fluctuation Analysis
Message-ID: <46643bc52bf4e@wp.pl>

Hi, package: RandomFields, function: "hurst" with method="dfa", but I 
think, that method "var" is better then DFA

----------------------------------------------------
Chcesz mie? pi?k? z podpisami najwi?kszych gwiazd ?wiatowego futbolu?
We? udzia? w aukcji! - Kliknij:
http://klik.wp.pl/?adr=http%3A%2F%2Faukcjewp.wp.pl%2Fshow_item.php%3Fitem%3D202652727&sid=1180


From Mitchell.Wachtel at ttuhsc.edu  Mon Jun  4 22:34:22 2007
From: Mitchell.Wachtel at ttuhsc.edu (Wachtel, Mitchell)
Date: Mon, 4 Jun 2007 15:34:22 -0500
Subject: [R] Harrell's C
In-Reply-To: <4661E8B3.7080205@vanderbilt.edu>
Message-ID: <1A2BCA4266504B4CA543403718A81FD2023D179A@TRAVIS.ttuhsc.edu>

Dear Professor Harrell:

Thank you so much for your excellent advice. I just installed the proper
version of Hmisc, which works perfectly. Hmisc yields Harrell's C
(rcorr.cens); all one need do is calculate the expected value for the
risk for each patient and make that the X variable.  You are a wonderful
influence on all who perform statistics. 

With kindest regards.

Mitchell S. Wachtel, MD



-----Original Message-----
From: Frank E Harrell Jr [mailto:f.harrell at vanderbilt.edu] 
Sent: Saturday, June 02, 2007 5:01 PM
To: Wachtel, Mitchell
Cc: r-help at stat.math.ethz.ch; Thomas Dupont
Subject: Re: [R] Harrell's C

Wachtel, Mitchell wrote:
> R will not let me load Design or Hmisc anymore. I need to calculate
Harrell's C for some survival analyses. Can anyone provide an R formula
for Harrell's C?
> With kindest regards.
> Mitchell Wachtel, MD

You provided very little information.  We have had no reports of Hmisc 
not loading under Windows but Design is not currently available for 
Windows for R 2.5.  We are working to fix that.

Frank
-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt
University


From johanfaux at yahoo.com  Mon Jun  4 23:13:40 2007
From: johanfaux at yahoo.com (johan Faux)
Date: Mon, 4 Jun 2007 14:13:40 -0700 (PDT)
Subject: [R] locked environment and inheritance
Message-ID: <523083.8004.qm@web56212.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070604/18d40641/attachment.pl 

From bgyrg at leeds.ac.uk  Mon Jun  4 23:32:10 2007
From: bgyrg at leeds.ac.uk (Richard Gunton)
Date: Mon,  4 Jun 2007 22:32:10 +0100
Subject: [R] R-squared in mixed-effects models
Message-ID: <1180992730.d4ba0629fdf7a@webmail6.leeds.ac.uk>


Hello,

I'm fitting general linear models using the function lme() from the package
nlme.  My variables include a number of covariates and a single random factor,
because the experiment was laid out in blocks.  I'd like to have a statistic to
measure the "proportion of explained variance" from my models.  With ordinary
multiple regression I'd use R-squared, but I can't find any similar items in
the output from lme().  Does anyone know something I can use in these or any
other package?

Thanks,

Richard.

--
Richard Gunton
PhD student - Ecology and Evolution group
School of Biology, University of Leeds, LS2 9JT, UK
Room 10.16, Miall Building   Tel: 0113 3432825

http://www.personal.leeds.ac.uk/~bgyrg

~ Opinions expressed in this message are not attributable to the University of
Leeds ~


From andrewjyee at gmail.com  Mon Jun  4 23:41:24 2007
From: andrewjyee at gmail.com (Andrew Yee)
Date: Mon, 4 Jun 2007 17:41:24 -0400
Subject: [R] getting t.test to work with apply()
In-Reply-To: <4663B3EF.4050601@karlin.mff.cuni.cz>
References: <5dff5a0d0706031448t5e60448en5aa028b42c65a4a9@mail.gmail.com>
	<4663B3EF.4050601@karlin.mff.cuni.cz>
Message-ID: <5dff5a0d0706041441s6912e47cu9af987deae7f65a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070604/a71fabe4/attachment.pl 

From waverley.paloalto at gmail.com  Mon Jun  4 23:50:07 2007
From: waverley.paloalto at gmail.com (Waverley)
Date: Mon, 4 Jun 2007 14:50:07 -0700
Subject: [R] RMySQL question, sql with R vector or list
Message-ID: <8ee9d8f20706041450l429142f6w7d75e47585362f6d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070604/c520015b/attachment.pl 

From bates at stat.wisc.edu  Mon Jun  4 23:56:15 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 4 Jun 2007 16:56:15 -0500
Subject: [R] Extracting lists in the dataframe $ format
In-Reply-To: <001f01c7a6db$b1be35f0$6405a8c0@MXD32803WB>
References: <001f01c7a6db$b1be35f0$6405a8c0@MXD32803WB>
Message-ID: <40e66e0b0706041456m33c15d9brdb2962acafca8288@mail.gmail.com>

On 6/4/07, Stan Hopkins <stanhopkins at comcast.net> wrote:
> I'm new to R and am trying to extract the factors of a dataframe using numeric indices (e.g. df[1]) that are input to a function definition instead of the other types of references (e.g. df$out).  df[1] is a list(?) whose class is "dataframe".  These indexed lists can be printed successfuly but are not agreeable to the plot() and lm() functions shown below as are their df$out references.  Reading the documentation for plot and lm hasn't helped yet.  Thanks in advance - Stan.

> > df=data.frame(out=1:4*3,pred1=1:4,pred2=1:4*2)
> > regression=function(tble,a,b)
> + {
> +            plot.new()
> +            plot(tble[a]~tble[b])
> +            lmm=lm(tble[a]~tble[b])
> +            abline(lmm)
> +            anova(lmm)
> + }
> > df[1]
>   out
> 1   3
> 2   6
> 3   9
> 4  12

but df[[1]] is the first column of df in its native form.

I think of the distinction as like the difference between an element
of a set, which is what the "[[" function returns, and the subset
consisting of a single element, which is what the "[" function
returns.


From david.meyer at wu-wien.ac.at  Tue Jun  5 00:11:32 2007
From: david.meyer at wu-wien.ac.at (David Meyer)
Date: Tue, 05 Jun 2007 00:11:32 +0200
Subject: [R] [R-pkgs] New package: relations
Message-ID: <46648E14.8000808@wu-wien.ac.at>

Dear useRs,

it is our great pleasure to announce the new package "relations" to
appear on all CRAN-mirrors soon.

This package provides data structures and methods for creating and
manipulating relations, relation ensembles, sets, and tuples. The
feature list includes:

* creation of relations by domain and graph/characteristic
function/incidences,

* extraction of characteristic function and graph,

* predicate functions for the most common standard characteristics,

* operators known from relational algebra theory (such as projection,
selection, cartesian product, joins, etc.),

* transitive/reflexive reduction and closure of a relation,

* relation ensembles for combining relations,

* fitters for determining (possibly all) consensus relations of a
relation ensemble including the Borda and Condorcet methods, as well as
exact solvers for minimizing a criterion function based on the symmetric
difference (Kemeny-Snell) metric.

* a simple plot method for Hasse-diagrams using RGraphviz.


Kurt and David

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages


From borgulya at gyer2.sote.hu  Tue Jun  5 00:25:28 2007
From: borgulya at gyer2.sote.hu (BORGULYA =?iso-8859-2?q?G=E1bor?=)
Date: Tue, 5 Jun 2007 00:25:28 +0200
Subject: [R] Error: could not find function "glht" (multcomp)
Message-ID: <200706050025.29964.borgulya@gyer2.sote.hu>

Dear List,

Could you tell why I get the error message?

> library(multcomp)
> data("cholesterol")
> m = aov(response ~ trt, data = cholesterol)
> cht <- glht(m, linfct = mcp(trt = "Tukey"))
Error: could not find function "glht"

Thank you

G?bor


From asn151 at yahoo.com  Tue Jun  5 00:34:20 2007
From: asn151 at yahoo.com (Jonathan Morse)
Date: Mon, 4 Jun 2007 15:34:20 -0700 (PDT)
Subject: [R] Mandriva Spring 2007 and R
Message-ID: <37204.62935.qm@web62412.mail.re1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070604/4687f6d4/attachment.pl 

From irishhacker at gmail.com  Tue Jun  5 01:25:29 2007
From: irishhacker at gmail.com (Robert Wilkins)
Date: Mon, 4 Jun 2007 18:25:29 -0500
Subject: [R] Why is the R mailing list so hard to figure out?
Message-ID: <874da0b40706041625r5150ba2akb20cb90fb0ca3d35@mail.gmail.com>

Why does the R mailing list need such an unusual and customized user interface?

Last January, I figured out how to read Usenet mailing lists ( or
Usenet groups ) and they all pretty much work the same, learn to use
one, you've learned to use them all ( gnu.misc.discuss ,
comp.lang.lisp , and so on ).

What's the best way to view and read discussions in this group for
recent days? Can I view the postings for the current day via Google
Groups?

I hope I'm posting correctly.

What does "ethz" and "ch" stand for? Is "ch" for Switzerland?


Robert


From anup_nandialath at yahoo.com  Tue Jun  5 01:34:53 2007
From: anup_nandialath at yahoo.com (Anup Nandialath)
Date: Mon, 4 Jun 2007 16:34:53 -0700 (PDT)
Subject: [R] Help with conditional lagging of data
Message-ID: <421980.2899.qm@web53310.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070604/ee618813/attachment.pl 

From bcarvalh at jhsph.edu  Tue Jun  5 01:35:59 2007
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Mon, 4 Jun 2007 19:35:59 -0400
Subject: [R] Why is the R mailing list so hard to figure out?
In-Reply-To: <874da0b40706041625r5150ba2akb20cb90fb0ca3d35@mail.gmail.com>
References: <874da0b40706041625r5150ba2akb20cb90fb0ca3d35@mail.gmail.com>
Message-ID: <2AE28494-F8EA-4A50-84FF-81F2202A06C0@jhsph.edu>

Well, I have my email client to organize everything by thread...  
which does the work for me...

ethz: Eidgen?ssische Technische Hochschule Z?rich
ch: Conf?deratio Helvetica

best,
b

On Jun 4, 2007, at 7:25 PM, Robert Wilkins wrote:

> Why does the R mailing list need such an unusual and customized  
> user interface?
>
> Last January, I figured out how to read Usenet mailing lists ( or
> Usenet groups ) and they all pretty much work the same, learn to use
> one, you've learned to use them all ( gnu.misc.discuss ,
> comp.lang.lisp , and so on ).
>
> What's the best way to view and read discussions in this group for
> recent days? Can I view the postings for the current day via Google
> Groups?
>
> I hope I'm posting correctly.
>
> What does "ethz" and "ch" stand for? Is "ch" for Switzerland?
>
>
> Robert


From jsorkin at grecc.umaryland.edu  Tue Jun  5 02:15:34 2007
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Mon, 04 Jun 2007 20:15:34 -0400
Subject: [R] GUI for R running under Linux
Message-ID: <4664728A.A712.00CB.0@grecc.umaryland.edu>

Colleagues,
I have been using R under windows for some time, and have become accustomed to the GUI that accompanies R. I have recently begun using R under Linux (Fedora), but can not find an equivalent GUI interface; at a terminal window I enter
R
Am I missing something? Can I get a GUI for R (version 2.5) running under Linux?
Thanks,
John

John Sorkin M.D., Ph.D.
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)

Confidentiality Statement:
This email message, including any attachments, is for the so...{{dropped}}


From andy_liaw at merck.com  Tue Jun  5 02:27:01 2007
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 4 Jun 2007 20:27:01 -0400
Subject: [R] R for bioinformatics
In-Reply-To: <45C304E3.70804@ebi.ac.uk>
References: <45C0C4D2.9080908@ebi.ac.uk> <m2hcu5zphf.fsf@fhcrc.org>
	<1170357417.9954.73.camel@localhost.localdomain>
	<45C24E54.1080904@biostat.ku.dk>
	<1170362983.9954.103.camel@localhost.localdomain>
	<45C304E3.70804@ebi.ac.uk>
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA0443BD18@usctmx1106.merck.com>

Just to complete this thread:  A colleague sent me the following
regarding the book.

	Following up on this post from a few months back...
The author has recently posted a public-domain version of this
book on CRAN under Documentation -> Contributed ->
"Statistics Using R with Biological Examples" by Kim Seefeld and Ernst
Linder (PDF). 

Unfortunately not all the mirror sites have it yet.

Andy 

From: Benoit Ballester
> 
> Marc Schwartz wrote:
> > On Thu, 2007-02-01 at 21:32 +0100, Peter Dalgaard wrote:
> >> Marc Schwartz wrote:
> >>> On Thu, 2007-02-01 at 10:45 -0800, Seth Falcon wrote:
> >>>   
> >>>> Benoit Ballester <benoit at ebi.ac.uk> writes:
> >>>>
> >>>>     
> >>>>> Hi,
> >>>>>
> >>>>> I was wondering if someone could tell me more about 
> this book, (if it's 
> >>>>> a good or bad one).
> >>>>> I can't find it, as it seems that O'Reilly doesn't 
> publish any more.
> >>>>>       
> >>>> I've never seen a copy so I can't comment about its quality (has
> >>>> anyone seen a copy?).
> >>>>
> >>>> You might want to take a look at _Bioinformatics and 
> Computational
> >>>> Biology Solutions Using R and Bioconductor_.
> >>>>
> >>>> http://www.bioconductor.org/pub/docs/mogr/
> >>>>     
> >>> I'll stand (or sit) to be corrected on this as I cannot 
> find the source,
> >>> but I have a recollection from seeing something quite 
> some time ago that
> >>> the book may have never been published.
> >>>   
> >> It's been a while since the status was something along the 
> lines that 
> >> "the authors may or may not complete it". Subject matter 
> moving faster 
> >> than pen, I suspect....
> > 
> > Peter, that wording does seem familiar, just cannot recall 
> where I saw
> > it. Perhaps on the O'Reilly web site, where it is no longer listed.
> > 
> > For confirmation, I called O'Reilly's customer service in 
> Cambridge, MA.
> > They confirm that the book was indeed cancelled and never published.
> > 
> > No reasons were given.
> 
> Thanks for those replies.
> I did also contacted the O'reilly offices in UK, and they told me the 
> same thing.  The book was never published. I just wanted to 
> compare the 
> "R for bioinformatics" with the "Bioinformatics and Computational 
> Biology Solutions Using R and Bioconductor", and see which 
> one suit me 
> more - But guess I don't have the choice now :-)
> 
> Ben
> 
> -- 
> Benoit Ballester
> Ensembl Team
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}


From neil.losin at gmail.com  Tue Jun  5 02:46:15 2007
From: neil.losin at gmail.com (Neil Losin)
Date: Mon, 4 Jun 2007 17:46:15 -0700
Subject: [R] klaR stepclass
Message-ID: <b3676f520706041746j1e02f369he7e277520f6a3dfb@mail.gmail.com>

Hi,

I'm trying to use "stepclass" to do a stepwise variable selection with
method=lda. I keep getting this warning message, which shows up once
for each variable added to the model during variable selection:

Warning message:
error(s) in modeling/prediction step in: cv.rate(vars = c(model,
tryvar), data = data, grouping = grouping,

I don't know how to interpret this warning. I do not have a separate
data set for cross validation. Is this important, or will "stepclass"
do leave-one-out cross-validation in the absence of other
cross-validation data?

Also, when I run "stepclass" several times with identical parameters,
it will give me a slightly different "best" model each time. It seems
to me that it should always return the same model, as long as the
dataset and call are the same. Am I missing something? Is there some
randomization going on behind the scenes that I'm unaware of?

Thanks in advance,
Neil Losin

-- 
_____
Neil Losin
UCLA Dept. of Ecology and Evolutionary Biology
neil.losin at gmail.com

and

Neil Losin Nature Photography
http://www.neillosin.com


From joseclaudio.faria at terra.com.br  Tue Jun  5 03:25:06 2007
From: joseclaudio.faria at terra.com.br (joseclaudio.faria)
Date: Mon,  4 Jun 2007 22:25:06 -0300
Subject: [R] biplot package
Message-ID: <JJ52LU$B66089CD83CF720735871C984F3E03AF@multidominios>

Dears,

I've been learning biplot (Gabriel, 1971) and I found the function 'biplot', inside of the package 'stats',
useful but, a bit limited.

So, I'm thinking to start a colaborative package to enhance this methods to other multivariate methods. In this
way, I would like to start it, making public a new function (biplot.pca, still in development, but running)
that make biplot more simple and power.

All users are free to modify and make it better.
Below the function and a small script to learn it.

#===============================================================================
# Name           : biplot.pca
# Author         : Jos? Cl?udio Faria (DCET/USC/BRAZIL)
# Date (dd/mm/yy): 4/6/2007 08:27:54
# Version        : v3
# Aim            : 2D and 3D (under scaterplot3d and rgl packages) PCA biplot
# Mail           : joseclaudio.faria em terra.com.br
#===============================================================================
# Arguments:
# x             Data (frame or matrix).
# center        Either a logical value or a numeric vector of length equal
#               to the number of columns of x (TRUE is the default).
# scale         Either a logical value or a numeric vector of length equal
#               to the number of columns of x (FALSE is the default).
# weight        Way of factorize ('equal' is the default).
# plot          Logical to produce or not a graphical representation of
#               biplot (TRUE is the default).
# rgl.use       If TRUE the 3D scatter will be under the rgl environment, in
#               another way the scatterplot3d will be used.
# aspect3d      Apparent ratios of the x, y, and z axes of the bounding box
# clear3d       Logical to clear or not a 3D graphical representation of
#               biplot before to make a new (TRUE is the default).
# simple.axes   Whether to draw simple axes (TRUE or FALSE).
# box           Whether to draw a box (the default is FALSE).
# spheres       Logical to represent objects as spheres (the default is FALSE).
# sphere.factor Relative size factor of spheres representing points; the
#               default size is dependent on the scale of observations.
# col.obj       Color of spheres or labels of objects.
# col.var       Color of lines and labels of variables.
# var.red       Factor of reduction of the length of the lines of variables.
#               graphical variables representation (<=1, 1 is the default).
# cex           Character expansion.

biplot.pca = function (x,
                       n.values=2,
                       center=T,
                       scale=F,
                       weight=c('equal', 'samples', 'variables'),
                       plot=T,
                       rgl.use=T,
                       aspect3d=c(1, 1, 1),
                       clear3d=T,
                       simple.axes=T,
                       box=F,
                       spheres=T,
                       sphere.factor=1,
                       col.obj=1,
                       col.var=2,
                       var.red=1,
                       cex=.6 )
{
  x  = as.matrix(x)
  x  = scale(x, center=center, scale=scale)
  if(is.null(rownames(x))) rownames = 1:nrow(x) else rownames = rownames(x)
  if(is.null(colnames(x))) colnames = paste('V', 1:ncol(x), sep='') else colnames = colnames(x)
  s  = svd(x)
  s2 = diag(sqrt(s$d[1:n.values]))
  #s2 = diag(s$d[1:n.values]) pca of pcurve is like this!?
  switch(match.arg(weight),
    equal = {
      g  = s$u[,1:n.values] %*% s2
      h  = s2 %*% t(s$v[,1:n.values])
      hl = t(h)
    },
    samples = {
      g  = s$u[,1:n.values] %*% s2
      h  = t(s$v[,1:n.values])
      hl = t(h)
    },
    variables = {
      g  = s$u[,1:n.values]
      h  = s2 %*% t(s$v[,1:n.values])
      hl = t(h)
    })
  gencolnames   = paste('PC', 1:n.values, sep='')
  rownames(g)   = rownames
  colnames(g)   = gencolnames
  rownames(hl)  = colnames
  colnames(hl)  = gencolnames
  coo           = rbind(g, hl)
  rownames(coo) = c(rownames, colnames)
  colnames(coo) = gencolnames
  cooplot       = rbind(g, hl*var.red)
  cooplot       = rbind(cooplot, rep(0, n.values)) # to correct visualization
  if(plot) {
    if(n.values == 2) {
      plot(cooplot,
           xlab='PC1', ylab='PC2',
           type='n')
      text(x=g[,1], y=g[,2],
           labels=rownames(g),
           cex=cex, col=col.obj)
      arrows(x0=0, y0=0,
             x1=hl[,1]*var.red, y1=hl[,2]*var.red,
             length=0.1, angle=20,
             col=col.var)
      text(x=hl[,1]*var.red, y=hl[,2]*var.red,
           labels = rownames(hl),
           cex=cex, col=col.var)
    }
    if(n.values == 3) {
      if (rgl.use) {
        require(rgl)
        require(mgcv)
        size = max(g)/20 * sphere.factor
        if (clear3d) clear3d()
        if (spheres)
          spheres3d(g, col=col.obj, radius=size, alpha=.5)
        else
          text3d(g, texts=rownames(g), col=col.obj, alpha=.5)
        aspect3d(aspect3d)
        for(i in 1:nrow(hl)) {
          segments3d(rbind(matrix(0, nc=3),
                     hl[i,]*var.red),
                     col=col.var)
        }
        text3d(hl*var.red,
               texts=rownames(hl),
               col=col.var)
        if(simple.axes) {
          axes3d(c('x', 'y', 'z'))
        }
        else
          decorate3d(xlab = 'PC1', ylab = 'PC2', zlab = 'PC3', box = box)
        title3d(xlab = 'PC1', ylab = 'PC2', zlab = 'PC3')
      } else {
        require(scatterplot3d)
        graph = scatterplot3d(cooplot,
                              type = if(spheres) 'p' else 'n',
                              xlab='PC1', ylab='PC2', zlab='PC3',
                              grid=F,
                              box=box,
                              cex.symbols=cex,
                              color=col.obj,
                              pch=20)
         if(!spheres)
           text(graph$xyz.convert(g),
                labels=rownames(g),
                col=col.obj, cex=cex)
        for(i in 1:nrow(hl)) {
          graph$points3d(c(0, hl[i,1]*var.red),
                         c(0, hl[i,2]*var.red),
                         c(0, hl[i,3]*var.red),
                         type='l', col=col.var)
        }
        text(graph$xyz.convert(hl*var.red),
             labels=rownames(hl),
             col=col.var, cex=cex)
      }
    }
  }
  rlist = list(values=s$d,
               objects=g,
               variables=hl,
               all=coo)
}


#===============================================================================
# Name           : biplot.pca_test
# Author         : Jos? Cl?udio Faria (DCET/USC/BRAZIL)
# Date (dd/mm/yy): 4/6/2007 08:27:54
# Version        : v3
# Aim            : to learn and to test the new 'biplot.pca' function
# Mail           : joseclaudio.faria em terra.com.br
#===============================================================================

#mtrace(biplot.pca, T)
#mtrace(biplot.pca, F)

#???????????????????
# 2D with graphics package
#???????????????????
#x = matrix(c(42, 52, 48, 58, 4, 5, 4, 3), nc=2); x
#dimnames(x) = list(letters[1:nrow(x)], LETTERS[1:ncol(x)]); x
#x = stackloss; x
#x = cars; x
#x = longley; x
x = mtcars[,1:7]; x
#x = LifeCycleSavings; x
biplot.pca(x)
biplot.pca(x, scale=T)
biplot.pca(x, col.obj=3, col.var=4, var.red=.5)
biplot.pca(x, center=T, scale=F, weight='eq', cex=.5)
biplot.pca(x, center=T, scale=F, weight='eq', cex=.8)
biplot.pca(x, center=T, scale=F, weight='sa')
biplot.pca(x, center=T, scale=F, weight='va')
biplot.pca(x, center=T, scale=F, weight='va', var.red=.05)

#??????????????????????
# 3D with scatterplot3d package
#??????????????????????
x = stackloss; x
biplot.pca(x, n.values=3, rgl.use=F, cex=.5)
biplot.pca(x, n.values=3, rgl.use=F, spheres=F, simple.axes=F, box=T)
biplot.pca(x, n.values=3, rgl.use=F, spheres=F, col.obj=3, col.var=4, var.red=.5)
biplot.pca(x, n.values=3, rgl.use=F, center=T, scale=F, weight='eq')
biplot.pca(x, n.values=3, rgl.use=F, center=T, scale=T, weight='eq')
biplot.pca(x, n.values=3, rgl.use=F, center=T, scale=T, weight='sa')
biplot.pca(x, n.values=3, rgl.use=F, spheres=F, center=T, scale=T, weight='va')
biplot.pca(x, n.values=3, rgl.use=F, center=T, scale=T, weight='va', var.red=.5)

#???????????????
# 3D with rgl package
#???????????????
x = iris[1:4]
#x = stackloss
x = LifeCycleSavings; x

clear3d()
rgl.bringtotop(stay=T)
biplot.pca(x, n.values=3, spheres=F)
rgl.bringtotop(stay=T)
biplot.pca(x, n.values=3, spheres=F, simple.axes=F, box=T, aspect3d=c(1, 1, 2))
rgl.bringtotop(stay=T)
biplot.pca(x, n.values=3, spheres=F,  col.obj=3, col.var=4, var.red=.5)
rgl.bringtotop(stay=T)
biplot.pca(x, n.values=3, center=T, scale=F, weight='eq', plot=T)
rgl.bringtotop(stay=T)
biplot.pca(x, n.values=3, center=T, scale=T, weight='eq', plot=T)
rgl.bringtotop(stay=T)
biplot.pca(x, n.values=3, spheres=F, center=T, scale=T, weight='sa')
rgl.bringtotop(stay=T)
biplot.pca(x, n.values=3, center=T, scale=T, weight='va')
rgl.bringtotop(stay=T)
biplot.pca(x, n.values=3, center=T, scale=T, weight='va', var.red=.3)

Best regards,

Jose Claudio Faria
Estat?stica Experimental - Prof. Titular
Universidade Estadual de Santa Cruz - UESC
Departamento de Ciencias Exatas e Tecnologicas - DCET
Bahia - Brasil
Tels:
73-3634.2779 (fixo Ilheus)
19-9144.8979 (celular Piracicaba)


From adschai at optonline.net  Tue Jun  5 03:42:31 2007
From: adschai at optonline.net (adschai at optonline.net)
Date: Tue, 05 Jun 2007 01:42:31 +0000 (GMT)
Subject: [R] How to obtain coefficient standard error from the result of
 polr?
In-Reply-To: <Pine.LNX.4.64.0706040723540.5286@gannet.stats.ox.ac.uk>
References: <e2899c0c2a1a8.4663aadf@optonline.net>
	<Pine.LNX.4.64.0706040723540.5286@gannet.stats.ox.ac.uk>
Message-ID: <e32fa19f28e6f.4664bf87@optonline.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070605/24fb4692/attachment.pl 

From ggrothendieck at gmail.com  Tue Jun  5 03:52:39 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 4 Jun 2007 21:52:39 -0400
Subject: [R] Help with conditional lagging of data
In-Reply-To: <421980.2899.qm@web53310.mail.re2.yahoo.com>
References: <421980.2899.qm@web53310.mail.re2.yahoo.com>
Message-ID: <971536df0706041852p6b542120v6679963c12a6c35@mail.gmail.com>

Seems you want to diff X, not lag it.

We can either maintain the long form of the data and do it as in #1
or convert the data to "wide" form and do it as in #2 which is most
convenient using zoo where we make the individual time series into
zoo series, merge them and then apply diff:


Lines <- "ID     Year     X
AB12   2000    100
AB12   2001    120
AB12   2002    140
AB12   2003    80
BL14   2000    180
BL14   2001    150
CR93   2000    45
CR93   2001    49
CR93   2002    56
CR93   2003    67
"
DF <- read.table(textConnection(Lines), header = TRUE)

# 1
f <- function(DF) cbind(DF[,1:2], diff = c(NA, diff(DF$X)))
DF.by <- by(DF, DF$ID, f)
do.call("rbind", DF.by)

# 2
library(zoo)
fz <- function(DF) zoo(DF$X, DF$Year)
diff(do.call("merge", by(DF, DF$ID, fz)), na.pad = TRUE)

For more info on zoo:
library(zoo)
vignette("zoo")

On 6/4/07, Anup Nandialath <anup_nandialath at yahoo.com> wrote:
> Dear Friends,
>
> I have some data with three columns named ID, Year and Measure X. I need to create a column which gives me a lag for each ID (note not a continous lag), but a lag conditional on the id and the given year. Please find below a sample of the data
>
> Input file sample
>
> ID     Year     X
>
> AB12   2000    100
> AB12   2001    120
> AB12   2002    140
> AB12   2003    80
> BL14   2000    180
> BL14   2001    150
> CR93   2000    45
> CR93   2001    49
> CR93   2002    56
> CR93   2003    67
>
> Expected output from this data
>
> ID     Year   Xlag
> AB12   2000     .
> AB12   2001   20
> AB12   2002   20
> AB12   2003   -60
> BL12   2000    .
> BL14   2001   -30
> CR93   2000     .
> CR93   2001     5
> CR93   2002     7
> CR93   2003     9
>
> Can somebody please help me with how to implement this in R. Thanks.
>
> Sincerely
>
> Anup
>
>
>
> ---------------------------------
> Looking for a deal? Find great prices on flights and hotels with Yahoo! FareChase.
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From cberry at tajo.ucsd.edu  Tue Jun  5 04:05:33 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Mon, 4 Jun 2007 19:05:33 -0700
Subject: [R] GUI for R running under Linux
In-Reply-To: <4664728A.A712.00CB.0@grecc.umaryland.edu>
References: <4664728A.A712.00CB.0@grecc.umaryland.edu>
Message-ID: <Pine.LNX.4.64.0706041900440.23163@tajo.ucsd.edu>



 	RSiteSearch("GUI Linux")

will point you to this message to which an extraordinarily long thread is 
attached:

 	http://finzi.psych.upenn.edu/R/Rhelp02a/archive/56868.html

Oh yes, and to the R-FAQ

:-)

On Mon, 4 Jun 2007, John Sorkin wrote:

> Colleagues,
> I have been using R under windows for some time, and have become accustomed to the GUI that accompanies R. I have recently begun using R under Linux (Fedora), but can not find an equivalent GUI interface; at a terminal window I enter
> R
> Am I missing something? Can I get a GUI for R (version 2.5) running under Linux?
> Thanks,
> John
>
> John Sorkin M.D., Ph.D.
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for the so...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	         UC San Diego
http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0901


From liujcheng at gmail.com  Tue Jun  5 04:11:36 2007
From: liujcheng at gmail.com (liu, jiacheng)
Date: Tue, 5 Jun 2007 10:11:36 +0800
Subject: [R] how to do multiple comparison of linear mixed models by
	multcomp package ?
Message-ID: <32f489f80706041911y44767141w60ac76d3c3b3932b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070605/f343eecc/attachment.pl 

From wla at list.wla.org  Tue Jun  5 05:07:51 2007
From: wla at list.wla.org (wla at list.wla.org)
Date: Mon, 4 Jun 2007 20:07:51 -0700
Subject: [R] Failed to post to the wla@list.wla.org list
Message-ID: <281673719_31111834359@mx251g.mysite4now.com>

The list has been disabled.


From jsorkin at grecc.umaryland.edu  Tue Jun  5 05:38:13 2007
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Mon, 04 Jun 2007 23:38:13 -0400
Subject: [R] lme vs. SAS proc mixed. Point estimates and SEs are the same,
	DFs are different
Message-ID: <4664A263.A712.00CB.0@grecc.umaryland.edu>

R 2.3
Windows XP

I am trying to understand lme. My aim is to run a random effects regression in which the intercept and jweek are random effects. I am comparing output from SAS PROC MIXED with output from R. The point estimates and the SEs are the same, however the DFs and the p values are different. I am clearly doing something wrong in my R code. I would appreciate any suggestions of how I can change the R code to get the same DFs as are provided by SAS.

SAS code:
proc mixed data=lipids2;
  model ldl=jweek/solution;
  random int jweek/type=un subject=patient;
  where lastvisit ge 4;
run;

SAS output:
                   Solution for Fixed Effects

                         Standard
Effect       Estimate       Error      DF    t Value    Pr > |t|

Intercept      113.48      7.4539      25      15.22      <.0001
jweek         -1.7164      0.5153      24      -3.33      0.0028

        Type 3 Tests of Fixed Effects

              Num     Den
Effect         DF      DF    F Value    Pr > F
jweek           1      24      11.09    0.0028


R code:
LesNew3 <- groupedData(LDL~jweek | Patient, data=as.data.frame(LesData3), FUN=mean)
fit3    <- lme(LDL~jweek, data=LesNew3[LesNew3[,"lastvisit"]>=4,], random=~1+jweek)
summary(fit3) 

R output:
Random effects:
 Formula: ~1 + jweek | Patient
 Structure: General positive-definite, Log-Cholesky parametrization
 

Fixed effects: LDL ~ jweek 
                Value Std.Error DF   t-value p-value
(Intercept) 113.47957  7.453921 65 15.224144  0.0000
jweek        -1.71643  0.515361 65 -3.330535  0.0014

John Sorkin M.D., Ph.D.
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)

Confidentiality Statement:
This email message, including any attachments, is for the so...{{dropped}}


From adschai at optonline.net  Tue Jun  5 05:44:14 2007
From: adschai at optonline.net (adschai at optonline.net)
Date: Tue, 05 Jun 2007 03:44:14 +0000 (GMT)
Subject: [R] Question using stepAIC
Message-ID: <e34b89e428015.4664dc0e@optonline.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070605/b9b043db/attachment.pl 

From rmi at danishmeat.dk  Tue Jun  5 08:53:05 2007
From: rmi at danishmeat.dk (Rina Miehs)
Date: Tue, 05 Jun 2007 08:53:05 +0200
Subject: [R] integer to date-format
Message-ID: <46652470.76E3.003F.0@danishmeat.dk>

En indlejret tekst med ukendt tegns?t er blevet fjernet...
Navn: ikke tilg?ngelig
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070605/daa500c9/attachment.pl 

From Laurence.Amilhat at toulouse.inra.fr  Tue Jun  5 08:55:19 2007
From: Laurence.Amilhat at toulouse.inra.fr (Laurence Amilhat)
Date: Tue, 05 Jun 2007 08:55:19 +0200
Subject: [R] multiple plot in odfWeave
Message-ID: <466508D7.20005@toulouse.inra.fr>

Hello R users,


I found the odfWeave package to create an odf document. It seems to be a 
very nice tool.
So i tried to used it to create a report with multiple plot:

I create an odt file with some code inside:
I connect to a mysql database
I get a list of projects
foreach project I would like to make a plot (a map exactly)

then in a R console I use the odfweave (inFile, outFile) function.


When I try this, with only one program without the loop on the program 
names, it
draw a map on my odt file, but when i a m doing the loop it doesn't work.

When i try to launch the plot (using the loop) in R console directly, 
without odfweave, it also works.

Do you know if it is possible to make successive plot in odfWeave document?

Thank you for your help,


Laurence.


Here the code:

My odt file: test2.odt

<<loadData, results = hide, echo = FALSE>>=

@

<<Connection, echo = FALSE, fig = TRUE>>=

library("RMySQL")
library(maps)
library(mapdata)
library(spmaps)
library(grid)
library(plotrix)

drv <- dbDriver("MySQL")
con <- dbConnect(drv, user="lamilhat", password="******", 
dbname="Aquagenome", host="mymachine.toulouse.inra.fr")

@

Liste des projets:

<<carte2, echo = FALSE, results= verbatim, fig = TRUE>>=

lp <- dbSendQuery(con, "SELECT nom FROM projets")
projets <- fetch(lp)
nbr=dim(projets)[1]
for (i in 1:nbr)
{
    monprojet=(projets)[i,1]
    myquery=paste("SELECT s.longitude, s.latitude, o.orgashort FROM 
organisme o JOIN scientist s ON o.codeorga=s.codeorga JOIN partenaire p 
ON p.codescientist=s.codescientist JOIN projets ON 
projets.codeproj=p.codeproj WHERE projets.nom LIKE \"",monprojet,"\" 
ORDER BY s.longitude", sep="")

    rs <- dbSendQuery(con, myquery )
    df <- fetch(rs)

    print(df)

    map(database="world", xlim=c(-15,40),ylim=c(27,71), fill=TRUE, 
col="#FFFFCC")
    points(df$longitude,df$latitude, col="red", pch=16)    
                                                 
spread.labels(df$longitude,df$latitude,df$orgashort,0,bg="#CCFFFF", 
border=TRUE, cex=0.8, xpad=0.5, ypad=0.8, font=6)
}

@



Then in the R console:

 >library (odfWeave)
 >inFile <- "/home/lamilhat/AQUAGENOME/PRESENTATION/RAPPORTS/test_2.odt"
 >outFile <- 
"/home/lamilhat/AQUAGENOME/PRESENTATION/RAPPORTS/test_2_out.odt"

 >imageDefs <- getImageDefs()
 >imageDefs$dispWidth <- 7
 >imageDefs$dispHeight <- 6
 >setImageDefs(imageDefs)

 >odfWeave(inFile, outFile)









-- 
====================================================================
= Laurence Amilhat    INRA Toulouse 31326 Castanet-Tolosan     	   = 
= Tel: 33 5 61 28 53 34   Email: laurence.amilhat at toulouse.inra.fr =


From ligges at statistik.uni-dortmund.de  Tue Jun  5 08:54:58 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 05 Jun 2007 08:54:58 +0200
Subject: [R] klaR stepclass
In-Reply-To: <b3676f520706041746j1e02f369he7e277520f6a3dfb@mail.gmail.com>
References: <b3676f520706041746j1e02f369he7e277520f6a3dfb@mail.gmail.com>
Message-ID: <466508C2.70701@statistik.uni-dortmund.de>



Neil Losin wrote:
> Hi,
> 
> I'm trying to use "stepclass" to do a stepwise variable selection with
> method=lda. I keep getting this warning message, which shows up once
> for each variable added to the model during variable selection:
> 
> Warning message:
> error(s) in modeling/prediction step in: cv.rate(vars = c(model,
> tryvar), data = data, grouping = grouping,

This means that in some steps of the stepwise procedure, one of the 
functions for estimating the parameters or predicting (in this case lda 
or predict.lda)  generates an error. This typically happens if you 
cannot invert the covariance matrix in one of the intermediately tried 
models due to singularity (examples for such a case are collinear 
variables or an unluckily chosen partition of the data for 
cross-validation).


> I don't know how to interpret this warning. I do not have a separate
> data set for cross validation. Is this important, or will "stepclass"
> do leave-one-out cross-validation in the absence of other
> cross-validation data?

By default, it uses 10-fold cross-validation which can be changed to 
leave-one-out by specifying the argument
   fold = nrow(dataframe)

> Also, when I run "stepclass" several times with identical parameters,
> it will give me a slightly different "best" model each time. It seems
> to me that it should always return the same model, as long as the
> dataset and call are the same. Am I missing something? Is there some
> randomization going on behind the scenes that I'm unaware of?

Yes, 10-fold cv is performed with randomly chosen partitions of the 
data. You can either run leave-one-out cv (which is rather time 
consuming) or use set.seed() in order to get reproducible results.

Uwe Ligges


> Thanks in advance,
> Neil Losin
>


From gavin.simpson at ucl.ac.uk  Tue Jun  5 09:00:40 2007
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Tue, 05 Jun 2007 08:00:40 +0100
Subject: [R] Why is the R mailing list so hard to figure out?
In-Reply-To: <874da0b40706041625r5150ba2akb20cb90fb0ca3d35@mail.gmail.com>
References: <874da0b40706041625r5150ba2akb20cb90fb0ca3d35@mail.gmail.com>
Message-ID: <1181026840.3010.9.camel@dhcppc2.my.nat.localnet>

On Mon, 2007-06-04 at 18:25 -0500, Robert Wilkins wrote:
> Why does the R mailing list need such an unusual and customized user interface?
> 
> Last January, I figured out how to read Usenet mailing lists ( or
> Usenet groups ) and they all pretty much work the same, learn to use
> one, you've learned to use them all ( gnu.misc.discuss ,
> comp.lang.lisp , and so on ).
> 
> What's the best way to view and read discussions in this group for
> recent days? Can I view the postings for the current day via Google
> Groups?
> 
> I hope I'm posting correctly.

Having never used Google Groups or Usenet I have no idea if this is the
same/similar, but the R mailing lists are archived via the Gmane service
(amongst others), which you can view, threaded in your browser (over
http), or point your favourite news (nntp) or RSS feed collator at it.

The entry page is:
http://gmane.org/info.php?group=gmane.comp.lang.r.general

In the Groups section, you'll find links to the various options. If
using a news reader (nntp) or RSS feed collator, just copy the relevant
links into your application of choice.

A threaded web view of the latest posts, for example, is at (via the
"threaded HTTP" link in the Groups section of the above mentioned link):

http://news.gmane.org/gmane.comp.lang.r.general

I personally let my emailer manage the posting for me as I find that the
easiest way to work...

HTH

G

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [t] +44 (0)20 7679 0522
ECRC                              [f] +44 (0)20 7679 0565
UCL Department of Geography
Pearson Building                  [e] gavin.simpsonATNOSPAMucl.ac.uk
Gower Street
London, UK                        [w] http://www.ucl.ac.uk/~ucfagls/
WC1E 6BT                          [w] http://www.freshwaters.org.uk/
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From ligges at statistik.uni-dortmund.de  Tue Jun  5 09:04:04 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 05 Jun 2007 09:04:04 +0200
Subject: [R] Question using stepAIC
In-Reply-To: <e34b89e428015.4664dc0e@optonline.net>
References: <e34b89e428015.4664dc0e@optonline.net>
Message-ID: <46650AE4.9090809@statistik.uni-dortmund.de>



adschai at optonline.net wrote:
> Hi - I use stepAIC to automatically select the model. The stepAIC was applied on polr as follow:objPolr <- polr(formula=myformula, data=dat, method=METHOD);objPolr.step <- stepAIC(objPolr, trace=T);Then R complaints that it doesn't know about 'dat' when it executes the second line. Below is the exact error that I got when executing the stepAIC line above:Error in eval(expr, envir, enclos) : object "dat" not foundWould you please provide some guide to circumvent this? Thank you.- adschai


Please read the psoting guide mentioned below each message of this list 
and learn to add appropriate line breaks to your messages or fix your 
Enter key.

What is dat? Is it a data.frame in the Workspace? What R version, what 
version of MASS, which OS?

Uwe Ligges



> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ligges at statistik.uni-dortmund.de  Tue Jun  5 09:06:30 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 05 Jun 2007 09:06:30 +0200
Subject: [R] integer to date-format
In-Reply-To: <46652470.76E3.003F.0@danishmeat.dk>
References: <46652470.76E3.003F.0@danishmeat.dk>
Message-ID: <46650B76.3050604@statistik.uni-dortmund.de>



Rina Miehs wrote:
> hello
>  
> I have a problem...
> I have to subtract an integer from a date-format and that is not
> possible!

The Exmaples section in ?DateTimeClasses shows that it works well:

Sys.time() - 3600             # an hour ago

Uwe Ligges



> How is it possible to convert an integer to a date-format?? any date
> format? i cant make it work without errors...
>  
> Thanks
> Rina Miehs
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Laurence.Amilhat at toulouse.inra.fr  Tue Jun  5 10:04:15 2007
From: Laurence.Amilhat at toulouse.inra.fr (Laurence Amilhat)
Date: Tue, 05 Jun 2007 10:04:15 +0200
Subject: [R] multiple plot in odfWeave
In-Reply-To: <466508D7.20005@toulouse.inra.fr>
References: <466508D7.20005@toulouse.inra.fr>
Message-ID: <466518FF.80305@toulouse.inra.fr>

Hello,

To clarify my question:
When I launch the odfWeave function in the R console,
I see the several maps in the R graphic window, but I cannot open the 
output file .odt
I get the following error:
format error in the subdocument content.xml position 123,82 (row,col)

Thanks,

Laurence



Laurence Amilhat a ?crit :
> Hello R users,
>
>
> I found the odfWeave package to create an odf document. It seems to be a 
> very nice tool.
> So i tried to used it to create a report with multiple plot:
>
> I create an odt file with some code inside:
> I connect to a mysql database
> I get a list of projects
> foreach project I would like to make a plot (a map exactly)
>
> then in a R console I use the odfweave (inFile, outFile) function.
>
>
> When I try this, with only one program without the loop on the program 
> names, it
> draw a map on my odt file, but when i a m doing the loop it doesn't work.
>
> When i try to launch the plot (using the loop) in R console directly, 
> without odfweave, it also works.
>
> Do you know if it is possible to make successive plot in odfWeave document?
>
> Thank you for your help,
>
>
> Laurence.
>
>
> Here the code:
>
> My odt file: test2.odt
>
> <<loadData, results = hide, echo = FALSE>>=
>
> @
>
> <<Connection, echo = FALSE, fig = TRUE>>=
>
> library("RMySQL")
> library(maps)
> library(mapdata)
> library(spmaps)
> library(grid)
> library(plotrix)
>
> drv <- dbDriver("MySQL")
> con <- dbConnect(drv, user="lamilhat", password="******", 
> dbname="Aquagenome", host="mymachine.toulouse.inra.fr")
>
> @
>
> Liste des projets:
>
> <<carte2, echo = FALSE, results= verbatim, fig = TRUE>>=
>
> lp <- dbSendQuery(con, "SELECT nom FROM projets")
> projets <- fetch(lp)
> nbr=dim(projets)[1]
> for (i in 1:nbr)
> {
>     monprojet=(projets)[i,1]
>     myquery=paste("SELECT s.longitude, s.latitude, o.orgashort FROM 
> organisme o JOIN scientist s ON o.codeorga=s.codeorga JOIN partenaire p 
> ON p.codescientist=s.codescientist JOIN projets ON 
> projets.codeproj=p.codeproj WHERE projets.nom LIKE \"",monprojet,"\" 
> ORDER BY s.longitude", sep="")
>
>     rs <- dbSendQuery(con, myquery )
>     df <- fetch(rs)
>
>     print(df)
>
>     map(database="world", xlim=c(-15,40),ylim=c(27,71), fill=TRUE, 
> col="#FFFFCC")
>     points(df$longitude,df$latitude, col="red", pch=16)    
>                                                  
> spread.labels(df$longitude,df$latitude,df$orgashort,0,bg="#CCFFFF", 
> border=TRUE, cex=0.8, xpad=0.5, ypad=0.8, font=6)
> }
>
> @
>
>
>
> Then in the R console:
>
>  >library (odfWeave)
>  >inFile <- "/home/lamilhat/AQUAGENOME/PRESENTATION/RAPPORTS/test_2.odt"
>  >outFile <- 
> "/home/lamilhat/AQUAGENOME/PRESENTATION/RAPPORTS/test_2_out.odt"
>
>  >imageDefs <- getImageDefs()
>  >imageDefs$dispWidth <- 7
>  >imageDefs$dispHeight <- 6
>  >setImageDefs(imageDefs)
>
>  >odfWeave(inFile, outFile)
>
>
>
>
>
>
>
>
>
>   


-- 
====================================================================
= Laurence Amilhat    INRA Toulouse 31326 Castanet-Tolosan     	   = 
= Tel: 33 5 61 28 53 34   Email: laurence.amilhat at toulouse.inra.fr =


From mark_difford at yahoo.co.uk  Tue Jun  5 10:38:58 2007
From: mark_difford at yahoo.co.uk (Mark Difford)
Date: Tue, 5 Jun 2007 01:38:58 -0700 (PDT)
Subject: [R] biplot package
In-Reply-To: <JJ52LU$B66089CD83CF720735871C984F3E03AF@multidominios>
References: <JJ52LU$B66089CD83CF720735871C984F3E03AF@multidominios>
Message-ID: <10965497.post@talk.nabble.com>


Hi Jose,

Good idea.  I haven't yet run your code, but it might be a good idea to take
a look at the calibrate package (unfortunately not "upgraded" since its
first release), and at what Chessel and his group have done in package ade4,
as well as what Jari Oksanen & his co-authors have done in package vegan.

There are also some interesting implementations of in package psy, and in
the compositions package.

Best Regards,
Mark Difford.


Jose Claudio Faria wrote:
> 
> Dears,
> 
> I've been learning biplot (Gabriel, 1971) and I found the function
> 'biplot', inside of the package 'stats',
> useful but, a bit limited.
> 
> So, I'm thinking to start a colaborative package to enhance this methods
> to other multivariate methods. In this
> way, I would like to start it, making public a new function (biplot.pca,
> still in development, but running)
> that make biplot more simple and power.
> 
> All users are free to modify and make it better.
> Below the function and a small script to learn it.
> 
> #===============================================================================
> # Name           : biplot.pca
> # Author         : Jos? Cl?udio Faria (DCET/USC/BRAZIL)
> # Date (dd/mm/yy): 4/6/2007 08:27:54
> # Version        : v3
> # Aim            : 2D and 3D (under scaterplot3d and rgl packages) PCA
> biplot
> # Mail           : joseclaudio.faria at terra.com.br
> #===============================================================================
> # Arguments:
> # x             Data (frame or matrix).
> # center        Either a logical value or a numeric vector of length equal
> #               to the number of columns of x (TRUE is the default).
> # scale         Either a logical value or a numeric vector of length equal
> #               to the number of columns of x (FALSE is the default).
> # weight        Way of factorize ('equal' is the default).
> # plot          Logical to produce or not a graphical representation of
> #               biplot (TRUE is the default).
> # rgl.use       If TRUE the 3D scatter will be under the rgl environment,
> in
> #               another way the scatterplot3d will be used.
> # aspect3d      Apparent ratios of the x, y, and z axes of the bounding
> box
> # clear3d       Logical to clear or not a 3D graphical representation of
> #               biplot before to make a new (TRUE is the default).
> # simple.axes   Whether to draw simple axes (TRUE or FALSE).
> # box           Whether to draw a box (the default is FALSE).
> # spheres       Logical to represent objects as spheres (the default is
> FALSE).
> # sphere.factor Relative size factor of spheres representing points; the
> #               default size is dependent on the scale of observations.
> # col.obj       Color of spheres or labels of objects.
> # col.var       Color of lines and labels of variables.
> # var.red       Factor of reduction of the length of the lines of
> variables.
> #               graphical variables representation (<=1, 1 is the
> default).
> # cex           Character expansion.
> 
> biplot.pca = function (x,
>                        n.values=2,
>                        center=T,
>                        scale=F,
>                        weight=c('equal', 'samples', 'variables'),
>                        plot=T,
>                        rgl.use=T,
>                        aspect3d=c(1, 1, 1),
>                        clear3d=T,
>                        simple.axes=T,
>                        box=F,
>                        spheres=T,
>                        sphere.factor=1,
>                        col.obj=1,
>                        col.var=2,
>                        var.red=1,
>                        cex=.6 )
> {
>   x  = as.matrix(x)
>   x  = scale(x, center=center, scale=scale)
>   if(is.null(rownames(x))) rownames = 1:nrow(x) else rownames =
> rownames(x)
>   if(is.null(colnames(x))) colnames = paste('V', 1:ncol(x), sep='') else
> colnames = colnames(x)
>   s  = svd(x)
>   s2 = diag(sqrt(s$d[1:n.values]))
>   #s2 = diag(s$d[1:n.values]) pca of pcurve is like this!?
>   switch(match.arg(weight),
>     equal = {
>       g  = s$u[,1:n.values] %*% s2
>       h  = s2 %*% t(s$v[,1:n.values])
>       hl = t(h)
>     },
>     samples = {
>       g  = s$u[,1:n.values] %*% s2
>       h  = t(s$v[,1:n.values])
>       hl = t(h)
>     },
>     variables = {
>       g  = s$u[,1:n.values]
>       h  = s2 %*% t(s$v[,1:n.values])
>       hl = t(h)
>     })
>   gencolnames   = paste('PC', 1:n.values, sep='')
>   rownames(g)   = rownames
>   colnames(g)   = gencolnames
>   rownames(hl)  = colnames
>   colnames(hl)  = gencolnames
>   coo           = rbind(g, hl)
>   rownames(coo) = c(rownames, colnames)
>   colnames(coo) = gencolnames
>   cooplot       = rbind(g, hl*var.red)
>   cooplot       = rbind(cooplot, rep(0, n.values)) # to correct
> visualization
>   if(plot) {
>     if(n.values == 2) {
>       plot(cooplot,
>            xlab='PC1', ylab='PC2',
>            type='n')
>       text(x=g[,1], y=g[,2],
>            labels=rownames(g),
>            cex=cex, col=col.obj)
>       arrows(x0=0, y0=0,
>              x1=hl[,1]*var.red, y1=hl[,2]*var.red,
>              length=0.1, angle=20,
>              col=col.var)
>       text(x=hl[,1]*var.red, y=hl[,2]*var.red,
>            labels = rownames(hl),
>            cex=cex, col=col.var)
>     }
>     if(n.values == 3) {
>       if (rgl.use) {
>         require(rgl)
>         require(mgcv)
>         size = max(g)/20 * sphere.factor
>         if (clear3d) clear3d()
>         if (spheres)
>           spheres3d(g, col=col.obj, radius=size, alpha=.5)
>         else
>           text3d(g, texts=rownames(g), col=col.obj, alpha=.5)
>         aspect3d(aspect3d)
>         for(i in 1:nrow(hl)) {
>           segments3d(rbind(matrix(0, nc=3),
>                      hl[i,]*var.red),
>                      col=col.var)
>         }
>         text3d(hl*var.red,
>                texts=rownames(hl),
>                col=col.var)
>         if(simple.axes) {
>           axes3d(c('x', 'y', 'z'))
>         }
>         else
>           decorate3d(xlab = 'PC1', ylab = 'PC2', zlab = 'PC3', box = box)
>         title3d(xlab = 'PC1', ylab = 'PC2', zlab = 'PC3')
>       } else {
>         require(scatterplot3d)
>         graph = scatterplot3d(cooplot,
>                               type = if(spheres) 'p' else 'n',
>                               xlab='PC1', ylab='PC2', zlab='PC3',
>                               grid=F,
>                               box=box,
>                               cex.symbols=cex,
>                               color=col.obj,
>                               pch=20)
>          if(!spheres)
>            text(graph$xyz.convert(g),
>                 labels=rownames(g),
>                 col=col.obj, cex=cex)
>         for(i in 1:nrow(hl)) {
>           graph$points3d(c(0, hl[i,1]*var.red),
>                          c(0, hl[i,2]*var.red),
>                          c(0, hl[i,3]*var.red),
>                          type='l', col=col.var)
>         }
>         text(graph$xyz.convert(hl*var.red),
>              labels=rownames(hl),
>              col=col.var, cex=cex)
>       }
>     }
>   }
>   rlist = list(values=s$d,
>                objects=g,
>                variables=hl,
>                all=coo)
> }
> 
> 
> #===============================================================================
> # Name           : biplot.pca_test
> # Author         : Jos? Cl?udio Faria (DCET/USC/BRAZIL)
> # Date (dd/mm/yy): 4/6/2007 08:27:54
> # Version        : v3
> # Aim            : to learn and to test the new 'biplot.pca' function
> # Mail           : joseclaudio.faria at terra.com.br
> #===============================================================================
> 
> #mtrace(biplot.pca, T)
> #mtrace(biplot.pca, F)
> 
> #???????????????????
> # 2D with graphics package
> #???????????????????
> #x = matrix(c(42, 52, 48, 58, 4, 5, 4, 3), nc=2); x
> #dimnames(x) = list(letters[1:nrow(x)], LETTERS[1:ncol(x)]); x
> #x = stackloss; x
> #x = cars; x
> #x = longley; x
> x = mtcars[,1:7]; x
> #x = LifeCycleSavings; x
> biplot.pca(x)
> biplot.pca(x, scale=T)
> biplot.pca(x, col.obj=3, col.var=4, var.red=.5)
> biplot.pca(x, center=T, scale=F, weight='eq', cex=.5)
> biplot.pca(x, center=T, scale=F, weight='eq', cex=.8)
> biplot.pca(x, center=T, scale=F, weight='sa')
> biplot.pca(x, center=T, scale=F, weight='va')
> biplot.pca(x, center=T, scale=F, weight='va', var.red=.05)
> 
> #??????????????????????
> # 3D with scatterplot3d package
> #??????????????????????
> x = stackloss; x
> biplot.pca(x, n.values=3, rgl.use=F, cex=.5)
> biplot.pca(x, n.values=3, rgl.use=F, spheres=F, simple.axes=F, box=T)
> biplot.pca(x, n.values=3, rgl.use=F, spheres=F, col.obj=3, col.var=4,
> var.red=.5)
> biplot.pca(x, n.values=3, rgl.use=F, center=T, scale=F, weight='eq')
> biplot.pca(x, n.values=3, rgl.use=F, center=T, scale=T, weight='eq')
> biplot.pca(x, n.values=3, rgl.use=F, center=T, scale=T, weight='sa')
> biplot.pca(x, n.values=3, rgl.use=F, spheres=F, center=T, scale=T,
> weight='va')
> biplot.pca(x, n.values=3, rgl.use=F, center=T, scale=T, weight='va',
> var.red=.5)
> 
> #???????????????
> # 3D with rgl package
> #???????????????
> x = iris[1:4]
> #x = stackloss
> x = LifeCycleSavings; x
> 
> clear3d()
> rgl.bringtotop(stay=T)
> biplot.pca(x, n.values=3, spheres=F)
> rgl.bringtotop(stay=T)
> biplot.pca(x, n.values=3, spheres=F, simple.axes=F, box=T, aspect3d=c(1,
> 1, 2))
> rgl.bringtotop(stay=T)
> biplot.pca(x, n.values=3, spheres=F,  col.obj=3, col.var=4, var.red=.5)
> rgl.bringtotop(stay=T)
> biplot.pca(x, n.values=3, center=T, scale=F, weight='eq', plot=T)
> rgl.bringtotop(stay=T)
> biplot.pca(x, n.values=3, center=T, scale=T, weight='eq', plot=T)
> rgl.bringtotop(stay=T)
> biplot.pca(x, n.values=3, spheres=F, center=T, scale=T, weight='sa')
> rgl.bringtotop(stay=T)
> biplot.pca(x, n.values=3, center=T, scale=T, weight='va')
> rgl.bringtotop(stay=T)
> biplot.pca(x, n.values=3, center=T, scale=T, weight='va', var.red=.3)
> 
> Best regards,
> 
> Jose Claudio Faria
> Estat?stica Experimental - Prof. Titular
> Universidade Estadual de Santa Cruz - UESC
> Departamento de Ciencias Exatas e Tecnologicas - DCET
> Bahia - Brasil
> Tels:
> 73-3634.2779 (fixo Ilheus)
> 19-9144.8979 (celular Piracicaba)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/biplot-package-tf3869013.html#a10965497
Sent from the R help mailing list archive at Nabble.com.


From wl2776 at gmail.com  Tue Jun  5 10:39:47 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Tue, 5 Jun 2007 01:39:47 -0700 (PDT)
Subject: [R] Why is the R mailing list so hard to figure out?
In-Reply-To: <874da0b40706041625r5150ba2akb20cb90fb0ca3d35@mail.gmail.com>
References: <874da0b40706041625r5150ba2akb20cb90fb0ca3d35@mail.gmail.com>
Message-ID: <10965539.post@talk.nabble.com>




irishhacker wrote:
> 
> Why does the R mailing list need such an unusual and customized user
> interface?
> 
There was a discussion of this some time ago on the list.
I believe, RSiteSearch("r-help mailing list forum") or some other similar
keywords will find it.


irishhacker wrote:
> 
> What's the best way to view and read discussions in this group for
> recent days? Can I view the postings for the current day via Google
> Groups?
> 

GMANE was mentioned already.
I use the Nabble interface (http://www.nabble.com/R-f13819.html), it seems
more convenient to me, but it collects less lists than Gmane.

-- 
View this message in context: http://www.nabble.com/Why-is-the-R-mailing-list-so-hard-to-figure-out--tf3868661.html#a10965539
Sent from the R help mailing list archive at Nabble.com.


From p.dalgaard at biostat.ku.dk  Tue Jun  5 10:44:24 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 05 Jun 2007 10:44:24 +0200
Subject: [R] lme vs. SAS proc mixed. Point estimates and SEs are the
 same, DFs are different
In-Reply-To: <4664A263.A712.00CB.0@grecc.umaryland.edu>
References: <4664A263.A712.00CB.0@grecc.umaryland.edu>
Message-ID: <46652268.1030603@biostat.ku.dk>

John Sorkin wrote:
> R 2.3
> Windows XP
>
> I am trying to understand lme. My aim is to run a random effects regression in which the intercept and jweek are random effects. I am comparing output from SAS PROC MIXED with output from R. The point estimates and the SEs are the same, however the DFs and the p values are different. I am clearly doing something wrong in my R code. I would appreciate any suggestions of how I can change the R code to get the same DFs as are provided by SAS.
>   
This has been hashed over a number of times before. In short:

1) You're not necessarily doing anything wrong
2) SAS PROC MIXED is not necessarily doing it right
3) lme() is _definitely_ not doing it right in some cases
4) both work reasonably in large sample cases (but beware that this is 
not equivalent to having many observation points)

SAS has an implementation of the method by Kenward and Rogers, which 
could be the most reliable general DF-calculation method around (I don't 
trust their Satterthwaite option, though). Getting this or equivalent 
into lme() has been on the wish list for a while, but it is not a 
trivial thing to do.

> SAS code:
> proc mixed data=lipids2;
>   model ldl=jweek/solution;
>   random int jweek/type=un subject=patient;
>   where lastvisit ge 4;
> run;
>
> SAS output:
>                    Solution for Fixed Effects
>
>                          Standard
> Effect       Estimate       Error      DF    t Value    Pr > |t|
>
> Intercept      113.48      7.4539      25      15.22      <.0001
> jweek         -1.7164      0.5153      24      -3.33      0.0028
>
>         Type 3 Tests of Fixed Effects
>
>               Num     Den
> Effect         DF      DF    F Value    Pr > F
> jweek           1      24      11.09    0.0028
>
>
> R code:
> LesNew3 <- groupedData(LDL~jweek | Patient, data=as.data.frame(LesData3), FUN=mean)
> fit3    <- lme(LDL~jweek, data=LesNew3[LesNew3[,"lastvisit"]>=4,], random=~1+jweek)
> summary(fit3) 
>
> R output:
> Random effects:
>  Formula: ~1 + jweek | Patient
>  Structure: General positive-definite, Log-Cholesky parametrization
>  
>
> Fixed effects: LDL ~ jweek 
>                 Value Std.Error DF   t-value p-value
> (Intercept) 113.47957  7.453921 65 15.224144  0.0000
> jweek        -1.71643  0.515361 65 -3.330535  0.0014
>
> John Sorkin M.D., Ph.D.
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for the so...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From yn19832 at msn.com  Tue Jun  5 10:55:01 2007
From: yn19832 at msn.com (livia)
Date: Tue, 5 Jun 2007 01:55:01 -0700 (PDT)
Subject: [R] extract data from Access
Message-ID: <10965714.post@talk.nabble.com>


Hi, I have imported an Access Database into R. There are three variables in
the Access database, return, a and b. Among them a and b are factors. I
would like to extract return from it, i.e return of a in level 1 and b in
level 2.

I would appreciate any advice. Many thanks.
-- 
View this message in context: http://www.nabble.com/extract-data-from-Access-tf3870487.html#a10965714
Sent from the R help mailing list archive at Nabble.com.


From p.dalgaard at biostat.ku.dk  Tue Jun  5 11:14:17 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 05 Jun 2007 11:14:17 +0200
Subject: [R] lme vs. SAS proc mixed. Point estimates and SEs are the
 same, DFs are different
In-Reply-To: <46652268.1030603@biostat.ku.dk>
References: <4664A263.A712.00CB.0@grecc.umaryland.edu>
	<46652268.1030603@biostat.ku.dk>
Message-ID: <46652969.4080203@biostat.ku.dk>

Peter Dalgaard wrote:
> John Sorkin wrote:
>   
>> R 2.3
>> Windows XP
>>
>> I am trying to understand lme. My aim is to run a random effects regression in which the intercept and jweek are random effects. I am comparing output from SAS PROC MIXED with output from R. The point estimates and the SEs are the same, however the DFs and the p values are different. I am clearly doing something wrong in my R code. I would appreciate any suggestions of how I can change the R code to get the same DFs as are provided by SAS.
>>   
>>     
> This has been hashed over a number of times before. In short:
>
> 1) You're not necessarily doing anything wrong
> 2) SAS PROC MIXED is not necessarily doing it right
> 3) lme() is _definitely_ not doing it right in some cases
> 4) both work reasonably in large sample cases (but beware that this is 
> not equivalent to having many observation points)
>
> SAS has an implementation of the method by Kenward and Rogers, which 
> could be the most reliable general DF-calculation method around (I don't 
> trust their Satterthwaite option, though). Getting this or equivalent 
> into lme() has been on the wish list for a while, but it is not a 
> trivial thing to do.
>   

Forgot to say: All DF-based corrections are wrong if you have 
non-normally distributed data (they depend on the 3rd and 4th moment of 
the error distribution(s)), although they can be useful as warning signs 
even in those cases. I also forgot to point to the simulate.lme() 
function which can simulate the LR statistics directly.
>   
>> SAS code:
>> proc mixed data=lipids2;
>>   model ldl=jweek/solution;
>>   random int jweek/type=un subject=patient;
>>   where lastvisit ge 4;
>> run;
>>
>> SAS output:
>>                    Solution for Fixed Effects
>>
>>                          Standard
>> Effect       Estimate       Error      DF    t Value    Pr > |t|
>>
>> Intercept      113.48      7.4539      25      15.22      <.0001
>> jweek         -1.7164      0.5153      24      -3.33      0.0028
>>
>>         Type 3 Tests of Fixed Effects
>>
>>               Num     Den
>> Effect         DF      DF    F Value    Pr > F
>> jweek           1      24      11.09    0.0028
>>
>>
>> R code:
>> LesNew3 <- groupedData(LDL~jweek | Patient, data=as.data.frame(LesData3), FUN=mean)
>> fit3    <- lme(LDL~jweek, data=LesNew3[LesNew3[,"lastvisit"]>=4,], random=~1+jweek)
>> summary(fit3) 
>>
>> R output:
>> Random effects:
>>  Formula: ~1 + jweek | Patient
>>  Structure: General positive-definite, Log-Cholesky parametrization
>>  
>>
>> Fixed effects: LDL ~ jweek 
>>                 Value Std.Error DF   t-value p-value
>> (Intercept) 113.47957  7.453921 65 15.224144  0.0000
>> jweek        -1.71643  0.515361 65 -3.330535  0.0014
>>
>> John Sorkin M.D., Ph.D.
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>
>> Confidentiality Statement:
>> This email message, including any attachments, is for the so...{{dropped}}
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>     
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From rmi at danishmeat.dk  Tue Jun  5 11:33:52 2007
From: rmi at danishmeat.dk (Rina Miehs)
Date: Tue, 05 Jun 2007 11:33:52 +0200
Subject: [R] help with simple R-question
Message-ID: <46654A1F.76E3.003F.0@danishmeat.dk>

En indlejret tekst med ukendt tegns?t er blevet fjernet...
Navn: ikke tilg?ngelig
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070605/5e9551c6/attachment.pl 

From jari.oksanen at oulu.fi  Tue Jun  5 11:45:03 2007
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Tue, 5 Jun 2007 09:45:03 +0000 (UTC)
Subject: [R] biplot package
References: <JJ52LU$B66089CD83CF720735871C984F3E03AF@multidominios>
Message-ID: <loom.20070605T113046-881@post.gmane.org>

joseclaudio.faria <joseclaudio.faria <at> terra.com.br> writes:

> 
> Dears,
> 
> I've been learning biplot (Gabriel, 1971) and I found the function 'biplot',
inside of the package 'stats',
> useful but, a bit limited.
> 
> So, I'm thinking to start a colaborative package to enhance this methods to
other multivariate methods. In this
> way, I would like to start it, making public a new function (biplot.pca, still
in development, but running)
> that make biplot more simple and power.
> 
> All users are free to modify and make it better.
> Below the function and a small script to learn it.
> 
Dear Jose Claudio Faria,

Looks nice. However, I'd suggets you articulate this into R core and tradition.
There the biplot function is now defined as:

biplot <- function (x, ...)  UseMethod("biplot")

with methods("biplot")
[1] biplot.default*  biplot.prcomp*   biplot.princomp*

You function is now called biplot.pca which sounds like biplot method for the
class "pca" (which, I think, exists in labdsv and perhaps somewhere else). What
you do is to propose a biplot method for class-less function svd. Or perhaps
this could be something like biplot.data.frame so that this function is launched
when user supplies as a data.frame as the first argument for biplot.

The good old R tradition is to separate plotting from calculation so that you
can have these separately (which obviously is related to the unix toolbox
thinking: do one thing well, and pipe the result to the next function). It might
make sense to have a biplot method for data.frame (if I remember correctly, some
of the core members fancied a spanning tree method for data.frame which is along
similar lines). However, I would like to have enhanced biplot methods for other
methods as well, such as analyses using prcomp or princomp, or multivariate
analyses in packages. There is no sense to replicate all mv analyses within
biplot functions, but you should just try cope with the outputs of various
methods. Then you perhaps have to change the name so that you can have
biplot.prcomp alongside with your new hyperbiplot.prcomp. (Namespace is an
answer to no real problem, but a reason of many new problems.) 

Somebody already promised to write a biplot method for rda in vegan (howdy Gav),
but I haven't heard of this for a long time. It would be nice to be able to have
this kind of interface for your enhanced code, too. 

cheers, jari oksanen


From p.p at lmu.de  Tue Jun  5 11:56:02 2007
From: p.p at lmu.de (Peter Pfaffelhuber)
Date: Tue, 05 Jun 2007 11:56:02 +0200
Subject: [R] Population genetics tests for neutral evolution
Message-ID: <1181037362.9070.111.camel@localhost.localdomain>

Dear R,

I am working with DNA data (nexus-Format) and want to do some population
genetics analysis. There are some standard test for neutral evolution,
e.g. Tajima's D, Fu+Li's D, the McDonald Kreitman test and the HKA
test. 

Does anyone know, if these tests are already implemented in R (or maybe
Bioconductor)?

Many thanks,
Peter




-- 
Peter Pfaffelhuber
University of Munich
Biozentrum
Gro?haderner Stra?e 2
82152 Planegg
Tel.: 089 2180 74 108
Fax.: 089 2180 74 104


From mdosrei at nimr.mrc.ac.uk  Tue Jun  5 12:35:49 2007
From: mdosrei at nimr.mrc.ac.uk (Mario dos Reis)
Date: Tue, 05 Jun 2007 11:35:49 +0100
Subject: [R] Latex \ell symbol in plotmath
In-Reply-To: <mailman.9.1180951205.916.r-help@stat.math.ethz.ch>
References: <mailman.9.1180951205.916.r-help@stat.math.ethz.ch>
Message-ID: <46653C85.6050504@nimr.mrc.ac.uk>

Is it possible to use the '\ell' (i.e. the log likelihood) in plots? 
I've been browsing the plotmath documentation unsucesfully.

Cheers,
Mario dos Reis

mdosrei at nimr.mrc.ac.uk
+44 (0)20 8816 2300

Division of Mathematical Biology
National Institute for Medical Research
The Ridgeway
Mill Hill
London, NW7 1AA, UK


From vmuggeo at dssm.unipa.it  Tue Jun  5 12:58:03 2007
From: vmuggeo at dssm.unipa.it (vito muggeo)
Date: Tue, 05 Jun 2007 12:58:03 +0200
Subject: [R] Latex \ell symbol in plotmath
In-Reply-To: <46653C85.6050504@nimr.mrc.ac.uk>
References: <mailman.9.1180951205.916.r-help@stat.math.ethz.ch>
	<46653C85.6050504@nimr.mrc.ac.uk>
Message-ID: <466541BB.10403@dssm.unipa.it>

Dear Mario,
I don't know whether the $\ell$ symbol is available ..

However you can use the LaTeX psfrag/pdfrag packages to convert tags in 
latex symbols..

hope this helps,
vito

Mario dos Reis wrote:
> Is it possible to use the '\ell' (i.e. the log likelihood) in plots? 
> I've been browsing the plotmath documentation unsucesfully.
> 
> Cheers,
> Mario dos Reis
> 
> mdosrei at nimr.mrc.ac.uk
> +44 (0)20 8816 2300
> 
> Division of Mathematical Biology
> National Institute for Medical Research
> The Ridgeway
> Mill Hill
> London, NW7 1AA, UK
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
====================================
Vito M.R. Muggeo
Dip.to Sc Statist e Matem `Vianelli'
Universit? di Palermo
viale delle Scienze, edificio 13
90128 Palermo - ITALY
tel: 091 6626240
fax: 091 485726/485612


From kkr at difres.dk  Tue Jun  5 13:08:07 2007
From: kkr at difres.dk (Kasper Kristensen)
Date: Tue, 5 Jun 2007 13:08:07 +0200
Subject: [R] rq matrix decomposition
Message-ID: <8CDDBB8CAC32F34B809EB4A677952B4B200E43@ch-mail01.dfu.local>

I guess you could achieve the rq-decompostion like this:

## Transpose and permute
pt <- function(A){n <- nrow(A);t(A)[n:1,n:1]}

## pt(A)=QR  ==>  A=pt(R)pt(Q)
rq <- function(A){
  qr <- qr(pt(A))
  list(Q=pt(qr.Q(qr)),R=pt(qr.R(qr)))
}

## Test it
A <- matrix(rnorm(25),5)
Q <- rq(A)$Q
R <- rq(A)$R
range(R%*%Q-A)

Best regards
Kasper Kristensen


From Taija.Saanisto at perkinelmer.com  Tue Jun  5 13:11:51 2007
From: Taija.Saanisto at perkinelmer.com (Saanisto, Taija)
Date: Tue, 5 Jun 2007 12:11:51 +0100
Subject: [R] Lines to plots with a for-loop
Message-ID: <54FE424ACFACF045984B76FE2407FE0FE42A21@EMEAMAIL01.PERKINELMER.NET>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070605/1c650878/attachment.pl 

From yn19832 at msn.com  Tue Jun  5 13:34:30 2007
From: yn19832 at msn.com (livia)
Date: Tue, 5 Jun 2007 04:34:30 -0700 (PDT)
Subject: [R] plot histogram and print
Message-ID: <10967630.post@talk.nabble.com>


I have got a dataset with two factors, and I would like to print the
histograms of the variable "return" for each combination of the two factors.
I do not know how can I name the figure title to sth like "main="alevel
&blevel"" according to the data.

par(ask=TRUE)

myhistogram <- function(x)
{
hist (x, freq = FALSE)
lines (density(x), col = "red") 
rug (x)
}
tapply(return, list(a, b), myhistogram)

Could anyone help me with this? Many thanks.
-- 
View this message in context: http://www.nabble.com/plot-histogram-and-print-tf3871150.html#a10967630
Sent from the R help mailing list archive at Nabble.com.


From HDoran at air.org  Tue Jun  5 13:42:25 2007
From: HDoran at air.org (Doran, Harold)
Date: Tue, 5 Jun 2007 07:42:25 -0400
Subject: [R] lme vs. SAS proc mixed. Point estimates and SEs are the
	same, DFs are different
In-Reply-To: <46652268.1030603@biostat.ku.dk>
Message-ID: <2323A6D37908A847A7C32F1E3662C80EBA0778@dc1ex01.air.org>

In addition to Peter's comments, the following link summarizes the issue
as well. This is a direct response to the SAS/lmer DF issue.

https://stat.ethz.ch/pipermail/r-help/2006-May/094765.html

Harold
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Peter Dalgaard
> Sent: Tuesday, June 05, 2007 4:44 AM
> To: John Sorkin
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] lme vs. SAS proc mixed. Point estimates and 
> SEs are the same, DFs are different
> 
> John Sorkin wrote:
> > R 2.3
> > Windows XP
> >
> > I am trying to understand lme. My aim is to run a random 
> effects regression in which the intercept and jweek are 
> random effects. I am comparing output from SAS PROC MIXED 
> with output from R. The point estimates and the SEs are the 
> same, however the DFs and the p values are different. I am 
> clearly doing something wrong in my R code. I would 
> appreciate any suggestions of how I can change the R code to 
> get the same DFs as are provided by SAS.
> >   
> This has been hashed over a number of times before. In short:
> 
> 1) You're not necessarily doing anything wrong
> 2) SAS PROC MIXED is not necessarily doing it right
> 3) lme() is _definitely_ not doing it right in some cases
> 4) both work reasonably in large sample cases (but beware 
> that this is not equivalent to having many observation points)
> 
> SAS has an implementation of the method by Kenward and 
> Rogers, which could be the most reliable general 
> DF-calculation method around (I don't trust their 
> Satterthwaite option, though). Getting this or equivalent 
> into lme() has been on the wish list for a while, but it is 
> not a trivial thing to do.
> 
> > SAS code:
> > proc mixed data=lipids2;
> >   model ldl=jweek/solution;
> >   random int jweek/type=un subject=patient;
> >   where lastvisit ge 4;
> > run;
> >
> > SAS output:
> >                    Solution for Fixed Effects
> >
> >                          Standard
> > Effect       Estimate       Error      DF    t Value    Pr > |t|
> >
> > Intercept      113.48      7.4539      25      15.22      <.0001
> > jweek         -1.7164      0.5153      24      -3.33      0.0028
> >
> >         Type 3 Tests of Fixed Effects
> >
> >               Num     Den
> > Effect         DF      DF    F Value    Pr > F
> > jweek           1      24      11.09    0.0028
> >
> >
> > R code:
> > LesNew3 <- groupedData(LDL~jweek | Patient, 
> data=as.data.frame(LesData3), FUN=mean)
> > fit3    <- lme(LDL~jweek, 
> data=LesNew3[LesNew3[,"lastvisit"]>=4,], random=~1+jweek)
> > summary(fit3)
> >
> > R output:
> > Random effects:
> >  Formula: ~1 + jweek | Patient
> >  Structure: General positive-definite, Log-Cholesky parametrization
> >  
> >
> > Fixed effects: LDL ~ jweek 
> >                 Value Std.Error DF   t-value p-value
> > (Intercept) 113.47957  7.453921 65 15.224144  0.0000
> > jweek        -1.71643  0.515361 65 -3.330535  0.0014
> >
> > John Sorkin M.D., Ph.D.
> > Chief, Biostatistics and Informatics
> > University of Maryland School of Medicine Division of Gerontology 
> > Baltimore VA Medical Center 10 North Greene Street GRECC (BT/18/GR) 
> > Baltimore, MD 21201-1524
> > (Phone) 410-605-7119
> > (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> >
> > Confidentiality Statement:
> > This email message, including any attachments, is for the 
> > so...{{dropped}}
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Thierry.ONKELINX at inbo.be  Tue Jun  5 13:50:39 2007
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 5 Jun 2007 13:50:39 +0200
Subject: [R] Lines to plots with a for-loop
In-Reply-To: <54FE424ACFACF045984B76FE2407FE0FE42A21@EMEAMAIL01.PERKINELMER.NET>
Message-ID: <2E9C414912813E4EB981326983E0A10403008D7D@inboexch.inbo.be>

Dear Taija,

You want lines but use points? Try 

for(i in levels(fHCGB$code)){
  with(subset(fHCGB,code==i), 
    plot(pooledPlateIntra, type="b", ylim=ylim, xlab=code, ylab="CV%")
    lines(fHCGB$limitVarC, col="green"))
}

Cheers,

Thierry
------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium
tel. + 32 54/436 185
Thierry.Onkelinx op inbo.be
www.inbo.be 

Do not put your faith in what statistics say until you have carefully
considered what they do not say.  ~William W. Watt
A statistical analysis, properly conducted, is a delicate dissection of
uncertainties, a surgery of suppositions. ~M.J.Moroney

 

> -----Oorspronkelijk bericht-----
> Van: r-help-bounces op stat.math.ethz.ch 
> [mailto:r-help-bounces op stat.math.ethz.ch] Namens Saanisto, Taija
> Verzonden: dinsdag 5 juni 2007 13:12
> Aan: r-help op stat.math.ethz.ch
> Onderwerp: [R] Lines to plots with a for-loop
> 
> Hello all,
> 
> I'm plotting several graphs with a for-loop with a code:
> 
> par(mfrow=c(3,4))
> 
> for(i in levels(fHCGB$code)) with(subset(fHCGB,code==i), 
> plot(pooledPlateIntra, type="b", ylim=ylim, xlab=code, ylab="CV%"))
> 
> 
> With which I have no problems.. However I need to add lines 
> to all of these 12 plots, but I cannot get it to work. I've 
> tried for example
> 
> par(mfrow=c(3,4))
> 
> for(i in levels(fHCGB$code)) with(subset(fHCGB,code==i), 
> plot(pooledPlateIntra, type="b", ylim=ylim, xlab=code, 
> ylab="CV%") points(fHCGB$limitVarC,type="b", col="green")))
> 
> But run into errors. How can the lines be added?
> 
> Taija Saanisto
> Biostatistician
> Quality assurance, Process Development
> PerkinElmer Life and Analytical Sciences / Wallac Oy
> Phone: +358-2-2678 741
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help op stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From tirthankar.patnaik at citi.com  Tue Jun  5 13:56:23 2007
From: tirthankar.patnaik at citi.com (Patnaik, Tirthankar )
Date: Tue, 5 Jun 2007 17:26:23 +0530
Subject: [R] Problems with Merge
Message-ID: <6E2AF71DA2E3F241A66122F3F90F32140DB250@exinmb04-bkp.apac.nsroot.net>

Hi,
 I have a history dataset, a matrix with about 1590 obs, and 242 cols,
and I need to update this matrix with an 'update' matrix that has about
30 rows, and roughly similar number of columns as the history ds (but
not necessarily equal). The update dataset is read from an Excel ODBC
connection. When I try and merge these datasets, I get counter-intuitive
results.

library(RODBC)
   chn <- odbcConnectExcel(UpdateFile)
   sqlTables(chn)
   UpdateData <- sqlFetch(chn,"MCap243")
   colnames(UpdateData) <- gsub("#",".",colnames(UpdateData))
   close(chn)
   # specify just how many rows we need from the Update file. We'd only
read five
   # rows at a time.
   UpdateRows = 20
   UpdateData <- UpdateData[1:UpdateRows,]

   # Delete Unwanted stocks.
   UpdateData <- UpdateData[,!names(UpdateData) %in% ToBeDeleted]
   x <- tail(UpdateData[c("Date","ABAN.BO")],n=50)
   print(x)
   

Gives x as:

         Date  ABAN.BO
1  2007-04-30 96448.40
2  2007-05-01 96448.40
3  2007-05-02 96448.40
4  2007-05-03 96300.44
5  2007-05-04 93718.52
6  2007-05-05 93718.52
7  2007-05-06 93718.52
8  2007-05-07 92743.82
9  2007-05-08 90374.60
10 2007-05-09 89126.18
11 2007-05-10 87082.47
12 2007-05-11 85493.73
13 2007-05-12 85493.73
14 2007-05-13 85493.73
15 2007-05-14 85033.21
16 2007-05-15 89209.41
17 2007-05-16 89089.19
18 2007-05-17 90472.62
19 2007-05-18 90326.51
20 2007-05-19 90326.51

But when I merge this file with the history dataset, I get the dates
misaligned by one row.

whistory <- merge(rhistory,UpdateData,by.x=rhistory["Date"],all=TRUE)

tail(WHist4[c("Date","ABAN.BO")],n=30)

          Date  ABAN.BO
1581 2007-04-19 83632.60
1582 2007-04-20 85942.00
1583 2007-04-23 88244.00
1584 2007-04-24 90309.50
1585 2007-04-25 92048.00
1586 2007-04-26 92051.70
1587 2007-04-27 95863.10
1588 2007-04-29 96448.40
1589 2007-04-30 96448.40
1590 2007-04-30 96343.40
1591 2007-05-01 96448.40
1592 2007-05-02 96300.44
1593 2007-05-03 93718.52
1594 2007-05-03 96195.60
1595 2007-05-04 93718.52
1596 2007-05-04 93616.50
1597 2007-05-05 93718.52
1598 2007-05-06 92743.82
1599 2007-05-07 90374.60
1600 2007-05-08 89126.18
1601 2007-05-09 87082.47
1602 2007-05-10 85493.73
1603 2007-05-11 85493.73
1604 2007-05-12 85493.73
1605 2007-05-13 85033.21
1606 2007-05-14 89209.41
1607 2007-05-15 89089.19
1608 2007-05-16 90472.62
1609 2007-05-17 90326.51
1610 2007-05-18 90326.51

Any reasons why the dates are shifted by one date? Am I missing some
parameters in the merge statement?

TIA and best,
-Tir


From ripley at stats.ox.ac.uk  Tue Jun  5 13:57:26 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 5 Jun 2007 12:57:26 +0100 (BST)
Subject: [R] Latex \ell symbol in plotmath
In-Reply-To: <46653C85.6050504@nimr.mrc.ac.uk>
References: <mailman.9.1180951205.916.r-help@stat.math.ethz.ch>
	<46653C85.6050504@nimr.mrc.ac.uk>
Message-ID: <Pine.LNX.4.64.0706051224080.32466@gannet.stats.ox.ac.uk>

On Tue, 5 Jun 2007, Mario dos Reis wrote:

> Is it possible to use the '\ell' (i.e. the log likelihood) in plots?

'plots'?  On what OS and what device?   (There is no general solution 
here.)

> I've been browsing the plotmath documentation unsucesfully.

That symbol is in neither of the Latin-1 nor symbol encoding used in R's 
standard fonts for postscript(), pdf() and the like.  Since it is not in 
the Adobe symbol encoding it is not accessible via plotmath.

It is Unicode character U+2113, and so on UTF-8 R systems you may well be 
able to enter it as \u2113 and get it plotted on-screen in a suitable 
font.  But we'd need to know a lot more about your system to advise on how 
exactly to do so.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Tue Jun  5 14:04:12 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 05 Jun 2007 14:04:12 +0200
Subject: [R] Lines to plots with a for-loop
In-Reply-To: <54FE424ACFACF045984B76FE2407FE0FE42A21@EMEAMAIL01.PERKINELMER.NET>
References: <54FE424ACFACF045984B76FE2407FE0FE42A21@EMEAMAIL01.PERKINELMER.NET>
Message-ID: <4665513C.7000002@biostat.ku.dk>

Saanisto, Taija wrote:
> Hello all,
>
> I'm plotting several graphs with a for-loop with a code:
>
> par(mfrow=c(3,4))
>
> for(i in levels(fHCGB$code)) with(subset(fHCGB,code==i),
> plot(pooledPlateIntra, type="b", ylim=ylim, xlab=code, ylab="CV%"))
>
>
> With which I have no problems.. However I need to add lines to all of
> these 12 plots, but I cannot get it to work. I've tried for example
>
> par(mfrow=c(3,4))
>
> for(i in levels(fHCGB$code)) with(subset(fHCGB,code==i),
> plot(pooledPlateIntra, type="b", ylim=ylim, xlab=code, ylab="CV%")
> points(fHCGB$limitVarC,type="b", col="green")))
>
> But run into errors. How can the lines be added?
>   
The with() construct gets a little more complicated if you want to do 
more than one thing inside:

for(i in levels(fHCGB$code)) with(subset(fHCGB,code==i), {
  plot(pooledPlateIntra, type="b", ylim=ylim, xlab=code, ylab="CV%")
  points(fHCGB$limitVarC,type="b", col="green")
})

or, since with() is really only needed for the plot()

for(i in levels(fHCGB$code)) {
  with(subset(fHCGB,code==i), 
     plot(pooledPlateIntra, type="b", ylim=ylim, xlab=code, ylab="CV%"))
  points(fHCGB$limitVarC,type="b", col="green")
}


(& you might have used lines() rather than points() if you think of it as an added line, but that's a matter of taste since the two functions only differ in the default for type=.)

    -p

> Taija Saanisto
> Biostatistician
> Quality assurance, Process Development
> PerkinElmer Life and Analytical Sciences / Wallac Oy
> Phone: +358-2-2678 741
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From knussear at usgs.gov  Tue Jun  5 14:29:00 2007
From: knussear at usgs.gov (Ken Nussear)
Date: Tue, 5 Jun 2007 05:29:00 -0700
Subject: [R] Front end for R in Mac,
Message-ID: <90622F5D-0EFE-45CF-8E81-B52A6179BA49@usgs.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070605/f16ebcb4/attachment.pl 

From hilmar.berger at imise.uni-leipzig.de  Tue Jun  5 14:20:24 2007
From: hilmar.berger at imise.uni-leipzig.de (Hilmar Berger)
Date: Tue, 05 Jun 2007 14:20:24 +0200
Subject: [R] Refactor all factors in a data frame
Message-ID: <f43ke2$nnc$1@sea.gmane.org>

Hi all,

Assume I have a data frame with numerical and factor variables that I 
got through merging various other data frames and subsetting the 
resulting data frame afterwards. The number levels of the factors seem 
to be the same as in the original data frames, probably because subset() 
calls [.factor without drop = TRUE (that's what I gather from scanning 
the mailing lists).

I wonder if there is a easy way to refactor all factors in the data 
frame at once. I noted that fix(data_frame) does the trick, however, 
this needs user interaction, which I'd like to avoid. Subsequent 
write.table / read.table would be another option but I'm not sure if R 
can guess the factor/char/numeric-type correctly when reading the table.

So, is there any way in drop the unused factor levels from *all* factors 
of a data frame without import/export ?

Thanks in advance,
Hilmar

-- 

Hilmar Berger
Studienkoordinator
Institut f?r medizinische Informatik, Statistik und Epidemiologie
Universit?t Leipzig
H?rtelstr. 16-18
D-04107 Leipzig

Tel. +49 341 97 16 101
Fax. +49 341 97 16 109
email: hilmar.berger at imise.uni-leipzig.de


From ripley at stats.ox.ac.uk  Tue Jun  5 14:38:24 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 5 Jun 2007 13:38:24 +0100 (BST)
Subject: [R] Problems with Merge
In-Reply-To: <6E2AF71DA2E3F241A66122F3F90F32140DB250@exinmb04-bkp.apac.nsroot.net>
References: <6E2AF71DA2E3F241A66122F3F90F32140DB250@exinmb04-bkp.apac.nsroot.net>
Message-ID: <Pine.LNX.4.64.0706051335490.2859@gannet.stats.ox.ac.uk>

Take a look at the help for merge(): in all the examples by.x is a 
character string, not a one-column data frame which is what 
rhistory["Date"] would appear to be.

Please note the trailer of this messsage.

On Tue, 5 Jun 2007, Patnaik, Tirthankar  wrote:

> Hi,
> I have a history dataset, a matrix with about 1590 obs, and 242 cols,
> and I need to update this matrix with an 'update' matrix that has about
> 30 rows, and roughly similar number of columns as the history ds (but
> not necessarily equal). The update dataset is read from an Excel ODBC
> connection. When I try and merge these datasets, I get counter-intuitive
> results.
>
> library(RODBC)
>   chn <- odbcConnectExcel(UpdateFile)
>   sqlTables(chn)
>   UpdateData <- sqlFetch(chn,"MCap243")
>   colnames(UpdateData) <- gsub("#",".",colnames(UpdateData))
>   close(chn)
>   # specify just how many rows we need from the Update file. We'd only
> read five
>   # rows at a time.
>   UpdateRows = 20
>   UpdateData <- UpdateData[1:UpdateRows,]
>
>   # Delete Unwanted stocks.
>   UpdateData <- UpdateData[,!names(UpdateData) %in% ToBeDeleted]
>   x <- tail(UpdateData[c("Date","ABAN.BO")],n=50)
>   print(x)
>
>
> Gives x as:
>
>         Date  ABAN.BO
> 1  2007-04-30 96448.40
> 2  2007-05-01 96448.40
> 3  2007-05-02 96448.40
> 4  2007-05-03 96300.44
> 5  2007-05-04 93718.52
> 6  2007-05-05 93718.52
> 7  2007-05-06 93718.52
> 8  2007-05-07 92743.82
> 9  2007-05-08 90374.60
> 10 2007-05-09 89126.18
> 11 2007-05-10 87082.47
> 12 2007-05-11 85493.73
> 13 2007-05-12 85493.73
> 14 2007-05-13 85493.73
> 15 2007-05-14 85033.21
> 16 2007-05-15 89209.41
> 17 2007-05-16 89089.19
> 18 2007-05-17 90472.62
> 19 2007-05-18 90326.51
> 20 2007-05-19 90326.51
>
> But when I merge this file with the history dataset, I get the dates
> misaligned by one row.
>
> whistory <- merge(rhistory,UpdateData,by.x=rhistory["Date"],all=TRUE)
>
> tail(WHist4[c("Date","ABAN.BO")],n=30)
>
>          Date  ABAN.BO
> 1581 2007-04-19 83632.60
> 1582 2007-04-20 85942.00
> 1583 2007-04-23 88244.00
> 1584 2007-04-24 90309.50
> 1585 2007-04-25 92048.00
> 1586 2007-04-26 92051.70
> 1587 2007-04-27 95863.10
> 1588 2007-04-29 96448.40
> 1589 2007-04-30 96448.40
> 1590 2007-04-30 96343.40
> 1591 2007-05-01 96448.40
> 1592 2007-05-02 96300.44
> 1593 2007-05-03 93718.52
> 1594 2007-05-03 96195.60
> 1595 2007-05-04 93718.52
> 1596 2007-05-04 93616.50
> 1597 2007-05-05 93718.52
> 1598 2007-05-06 92743.82
> 1599 2007-05-07 90374.60
> 1600 2007-05-08 89126.18
> 1601 2007-05-09 87082.47
> 1602 2007-05-10 85493.73
> 1603 2007-05-11 85493.73
> 1604 2007-05-12 85493.73
> 1605 2007-05-13 85033.21
> 1606 2007-05-14 89209.41
> 1607 2007-05-15 89089.19
> 1608 2007-05-16 90472.62
> 1609 2007-05-17 90326.51
> 1610 2007-05-18 90326.51
>
> Any reasons why the dates are shifted by one date? Am I missing some
> parameters in the merge statement?
>
> TIA and best,
> -Tir
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From albmont at centroin.com.br  Tue Jun  5 14:52:07 2007
From: albmont at centroin.com.br (Alberto Monteiro)
Date: Tue, 5 Jun 2007 10:52:07 -0200
Subject: [R] Latex \ell symbol in plotmath
In-Reply-To: <Pine.LNX.4.64.0706051224080.32466@gannet.stats.ox.ac.uk>
References: <mailman.9.1180951205.916.r-help@stat.math.ethz.ch>
	<46653C85.6050504@nimr.mrc.ac.uk>
	<Pine.LNX.4.64.0706051224080.32466@gannet.stats.ox.ac.uk>
Message-ID: <20070605124957.M6205@centroin.com.br>

Prof Brian Ripley wrote:
> 
> It is Unicode character U+2113, and so on UTF-8 R systems you may 
> well be able to enter it as \u2113 and get it plotted on-screen in a 
> suitable font.  But we'd need to know a lot more about your system 
> to advise on how exactly to do so.
> 
I must be sleeping, but I can't think about a program that lists
"all" Unicode characters. A stupid and dirty solution would be:

cat("u 31 = \u31\n")
cat("u 32 = \u32\n")
...

How can I vectorize this?

Alberto Monteiro


From maechler at stat.math.ethz.ch  Tue Jun  5 15:02:15 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 5 Jun 2007 15:02:15 +0200
Subject: [R] Why is the R mailing list so hard to figure out?
In-Reply-To: <10965539.post@talk.nabble.com>
References: <874da0b40706041625r5150ba2akb20cb90fb0ca3d35@mail.gmail.com>
	<10965539.post@talk.nabble.com>
Message-ID: <18021.24279.567993.749166@stat.math.ethz.ch>

>>>>> "VE" == Vladimir Eremeev <wl2776 at gmail.com>
>>>>>     on Tue, 5 Jun 2007 01:39:47 -0700 (PDT) writes:

    VE> irishhacker wrote:
    >> 
    >> Why does the R mailing list need such an unusual and
    >> customized user interface?

Well, that's  VERY MUCH a matter of point of view, and the view
is most probably very highly dependent on your year of birth.
For many old timers like me, e-mail is at least as natural as
web browsing.  I see that such an attitude becomes more and more
outdated.


    VE> There was a discussion of this some time ago on the
    VE> list.  I believe, RSiteSearch("r-help mailing list
    VE> forum") or some other similar keywords will find it.

    VE> irishhacker wrote:
    >> 
    >> What's the best way to view and read discussions in this
    >> group for recent days? Can I view the postings for the
    >> current day via Google Groups?

 Well, one way is still *subscribing* to R-help and
 occasionally helping each other,
 instead of just perusing it as a resource ...

    >> GMANE was mentioned already.

    VE> I use the Nabble interface
    VE> (http://www.nabble.com/R-f13819.html), it seems more
    VE> convenient to me, but it collects less lists than Gmane.

Yes, but it appends its silly footer (aka "advertizement") to
all mails sent out, luring people to use it.

I (as mailing list manager) have considered more than once to
just evaporate such footers as I evaporate most other
spam-footers (as e.g. from hotmail, yahoo, gmx, ...).

Martin Maechler, ETH Zurich


    VE> -- View this message in context:
    VE> http://www.nabble.com/Why-is-the-R-mailing-list-so-hard-to-figure-out--tf3868661.html#a10965539
    VE> Sent from the R help mailing list archive at Nabble.com.


From tirthankar.patnaik at citi.com  Tue Jun  5 15:02:54 2007
From: tirthankar.patnaik at citi.com (Patnaik, Tirthankar )
Date: Tue, 5 Jun 2007 18:32:54 +0530
Subject: [R] Problems with Merge
Message-ID: <6E2AF71DA2E3F241A66122F3F90F32140DB256@exinmb04-bkp.apac.nsroot.net>

Prof. Ripley,
	Date is a column in a matrix, which should be ok for the merge.
Actually the IMHO problem was with the default sorting option, I set
sort=FALSE, and the merge happened as it should. 

Best,
-Tir

Tirthankar Patnaik
Analyst, India Strategy
Citigroup Investment Research
+91-22-6631 9887


P.S.  Agree with you on the trailer of the message--I had to post the
message in a hurry, though! 

> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
> Sent: Tuesday, June 05, 2007 6:08 PM
> To: Patnaik, Tirthankar [GWM-CIR]
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Problems with Merge
> 
> Take a look at the help for merge(): in all the examples by.x 
> is a character string, not a one-column data frame which is 
> what rhistory["Date"] would appear to be.
> 
> Please note the trailer of this messsage.
> 
> On Tue, 5 Jun 2007, Patnaik, Tirthankar  wrote:
> 
> > Hi,
> > I have a history dataset, a matrix with about 1590 obs, and 
> 242 cols, 
> > and I need to update this matrix with an 'update' matrix that has 
> > about 30 rows, and roughly similar number of columns as the 
> history ds 
> > (but not necessarily equal). The update dataset is read 
> from an Excel 
> > ODBC connection. When I try and merge these datasets, I get 
> > counter-intuitive results.
> >
> > library(RODBC)
> >   chn <- odbcConnectExcel(UpdateFile)
> >   sqlTables(chn)
> >   UpdateData <- sqlFetch(chn,"MCap243")
> >   colnames(UpdateData) <- gsub("#",".",colnames(UpdateData))
> >   close(chn)
> >   # specify just how many rows we need from the Update 
> file. We'd only 
> > read five
> >   # rows at a time.
> >   UpdateRows = 20
> >   UpdateData <- UpdateData[1:UpdateRows,]
> >
> >   # Delete Unwanted stocks.
> >   UpdateData <- UpdateData[,!names(UpdateData) %in% ToBeDeleted]
> >   x <- tail(UpdateData[c("Date","ABAN.BO")],n=50)
> >   print(x)
> >
> >
> > Gives x as:
> >
> >         Date  ABAN.BO
> > 1  2007-04-30 96448.40
> > 2  2007-05-01 96448.40
> > 3  2007-05-02 96448.40
> > 4  2007-05-03 96300.44
> > 5  2007-05-04 93718.52
> > 6  2007-05-05 93718.52
> > 7  2007-05-06 93718.52
> > 8  2007-05-07 92743.82
> > 9  2007-05-08 90374.60
> > 10 2007-05-09 89126.18
> > 11 2007-05-10 87082.47
> > 12 2007-05-11 85493.73
> > 13 2007-05-12 85493.73
> > 14 2007-05-13 85493.73
> > 15 2007-05-14 85033.21
> > 16 2007-05-15 89209.41
> > 17 2007-05-16 89089.19
> > 18 2007-05-17 90472.62
> > 19 2007-05-18 90326.51
> > 20 2007-05-19 90326.51
> >
> > But when I merge this file with the history dataset, I get 
> the dates 
> > misaligned by one row.
> >
> > whistory <- 
> merge(rhistory,UpdateData,by.x=rhistory["Date"],all=TRUE)
> >
> > tail(WHist4[c("Date","ABAN.BO")],n=30)
> >
> >          Date  ABAN.BO
> > 1581 2007-04-19 83632.60
> > 1582 2007-04-20 85942.00
> > 1583 2007-04-23 88244.00
> > 1584 2007-04-24 90309.50
> > 1585 2007-04-25 92048.00
> > 1586 2007-04-26 92051.70
> > 1587 2007-04-27 95863.10
> > 1588 2007-04-29 96448.40
> > 1589 2007-04-30 96448.40
> > 1590 2007-04-30 96343.40
> > 1591 2007-05-01 96448.40
> > 1592 2007-05-02 96300.44
> > 1593 2007-05-03 93718.52
> > 1594 2007-05-03 96195.60
> > 1595 2007-05-04 93718.52
> > 1596 2007-05-04 93616.50
> > 1597 2007-05-05 93718.52
> > 1598 2007-05-06 92743.82
> > 1599 2007-05-07 90374.60
> > 1600 2007-05-08 89126.18
> > 1601 2007-05-09 87082.47
> > 1602 2007-05-10 85493.73
> > 1603 2007-05-11 85493.73
> > 1604 2007-05-12 85493.73
> > 1605 2007-05-13 85033.21
> > 1606 2007-05-14 89209.41
> > 1607 2007-05-15 89089.19
> > 1608 2007-05-16 90472.62
> > 1609 2007-05-17 90326.51
> > 1610 2007-05-18 90326.51
> >
> > Any reasons why the dates are shifted by one date? Am I 
> missing some 
> > parameters in the merge statement?
> >
> > TIA and best,
> > -Tir
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>


From h.wickham at gmail.com  Tue Jun  5 15:07:42 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 5 Jun 2007 15:07:42 +0200
Subject: [R] Refactor all factors in a data frame
In-Reply-To: <f43ke2$nnc$1@sea.gmane.org>
References: <f43ke2$nnc$1@sea.gmane.org>
Message-ID: <f8e6ff050706050607n622e9797ve82396ea8e654c8c@mail.gmail.com>

Hi Hilmar,

Try this:

cat <- sapply(df, is.factor)
df[cat] <- lapply(df[cat], factor)

Hadley

On 6/5/07, Hilmar Berger <hilmar.berger at imise.uni-leipzig.de> wrote:
> Hi all,
>
> Assume I have a data frame with numerical and factor variables that I
> got through merging various other data frames and subsetting the
> resulting data frame afterwards. The number levels of the factors seem
> to be the same as in the original data frames, probably because subset()
> calls [.factor without drop = TRUE (that's what I gather from scanning
> the mailing lists).
>
> I wonder if there is a easy way to refactor all factors in the data
> frame at once. I noted that fix(data_frame) does the trick, however,
> this needs user interaction, which I'd like to avoid. Subsequent
> write.table / read.table would be another option but I'm not sure if R
> can guess the factor/char/numeric-type correctly when reading the table.
>
> So, is there any way in drop the unused factor levels from *all* factors
> of a data frame without import/export ?
>
> Thanks in advance,
> Hilmar
>
> --
>
> Hilmar Berger
> Studienkoordinator
> Institut f?r medizinische Informatik, Statistik und Epidemiologie
> Universit?t Leipzig
> H?rtelstr. 16-18
> D-04107 Leipzig
>
> Tel. +49 341 97 16 101
> Fax. +49 341 97 16 109
> email: hilmar.berger at imise.uni-leipzig.de
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From albmont at centroin.com.br  Tue Jun  5 15:10:47 2007
From: albmont at centroin.com.br (Alberto Monteiro)
Date: Tue, 5 Jun 2007 11:10:47 -0200
Subject: [R] Inverse of encodeString
Message-ID: <20070605130556.M17907@centroin.com.br>

What is the inverse of encodeString?

For example, \u1 is some Unicode symbol. If I do

s <- encodeString("\u1")

then s will be the string "\001". But anything I do
with s, will not return the Unicode that corresponds to \u1:

cat(s, "\n") # prints \001
cat("\u1", "\n")  # prints y with umlaut

Alberto Monteiro


From jrkrideau at yahoo.ca  Tue Jun  5 15:17:42 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Tue, 5 Jun 2007 09:17:42 -0400 (EDT)
Subject: [R] help with simple R-question
In-Reply-To: <46654A1F.76E3.003F.0@danishmeat.dk>
Message-ID: <138529.2759.qm@web32805.mail.mud.yahoo.com>


--- Rina Miehs <rmi at danishmeat.dk> wrote:

> hello
>  
> what do i write for R to recognize both columns?
>  
> In the R-script downunder you can see that i use
> tapply to get my
> information out of my data, and then i need to use
> it as a dataframe
> with both columns! It is like R is using the first
> column as an
> observationnumber or something, how can i change
> that?? 

It is using the names of the variables as rownames.

try 
 n.ant <- names(antall)
antal1 <- data.frame(n.antal1, antal1)


>  
> > antal1 <-tapply(l1$omlob1,l1$farid,length)
> > antal1
> 1437987  10000100  10007995  10008295  10008792 
> 10010203  10018703 
> 10033401 
>         2         3         3         2         3   
>      1         1  
>       2 
>  10048900  10050492  10055897  10076495  10081892 
> 10094801  10100692 
> 10101395 
>         3         1         3         3         6   
>      2         5  
>      20 
>  10101495  10101595  10104692  10113592  10113697 
> 10114297  10120797 
> 10120897 
>         1         5         4         2         6   
>     11         1  
>       4 
>  10121697  10121897  10121997  10133592  10142892 
> 10142995  10146495 
> 10150497 
>        16         3         6         1         1   
>      6         4  
>       4 
>  10150692  10157092  10157292  10164792  10170892 
> 10171795  10171895 
> 10172300 
>         5         2         4         4         4   
>      4         4  
>       1 
>  10175195  10187802  10192499  10192897  10198295 
> 10200493  10201693 
> 10211593 
>         1         2         2         3         5   
>      1         3  
>       5 
> > antal1 <- data.frame(antal1)
> > antal1
>           antal1
> 1437987        2
> 10000100       3
> 10007995       3
> 10008295       2
> 10008792       3
> 10010203      NA
> 10018703      NA
> 10033401       2
> 10048900       3
> 10050492       1
> 10055897       3
> 10076495       3
> 10081892       6
> 10094801       2
> 10100692       5
>  
> Thanks
> Rina
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From mdosrei at nimr.mrc.ac.uk  Tue Jun  5 15:16:04 2007
From: mdosrei at nimr.mrc.ac.uk (Mario dos Reis)
Date: Tue, 05 Jun 2007 14:16:04 +0100
Subject: [R] Latex \ell symbol in plotmath
In-Reply-To: <Pine.LNX.4.64.0706051224080.32466@gannet.stats.ox.ac.uk>
References: <mailman.9.1180951205.916.r-help@stat.math.ethz.ch>
	<46653C85.6050504@nimr.mrc.ac.uk>
	<Pine.LNX.4.64.0706051224080.32466@gannet.stats.ox.ac.uk>
Message-ID: <46656214.1000006@nimr.mrc.ac.uk>

I am using R 2.5.0 on Fedora Linux core 6, AMD 64.

Prof Brian Ripley wrote:
> On Tue, 5 Jun 2007, Mario dos Reis wrote:
> 
>> Is it possible to use the '\ell' (i.e. the log likelihood) in plots?
> 
> 'plots'?  On what OS and what device?   (There is no general solution 
> here.)
> 
>> I've been browsing the plotmath documentation unsucesfully.
> 
> That symbol is in neither of the Latin-1 nor symbol encoding used in R's 
> standard fonts for postscript(), pdf() and the like.  Since it is not in 
> the Adobe symbol encoding it is not accessible via plotmath.
> 
> It is Unicode character U+2113, and so on UTF-8 R systems you may well 
> be able to enter it as \u2113 and get it plotted on-screen in a suitable 
> font.  But we'd need to know a lot more about your system to advise on 
> how exactly to do so.
> 

Cheers,
Mario dos Reis

mdosrei at nimr.mrc.ac.uk
+44 (0)20 8816 2300

Division of Mathematical Biology
National Institute for Medical Research
The Ridgeway
Mill Hill
London, NW7 1AA, UK


From jfox at mcmaster.ca  Tue Jun  5 15:27:28 2007
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 5 Jun 2007 09:27:28 -0400
Subject: [R] Refactor all factors in a data frame
In-Reply-To: <f43ke2$nnc$1@sea.gmane.org>
Message-ID: <20070605132732.SHXI25739.tomts25-srv.bellnexxia.net@JohnDesktop8300>

Dear Hilmar,

You could use something like

DF <- as.data.frame(lapply(DF, function (x) if (is.factor(x)) factor(x) else
x))

Where DF is the data frame.

I hope this helps,
 John

--------------------------------
John Fox, Professor
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Hilmar Berger
> Sent: Tuesday, June 05, 2007 8:20 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Refactor all factors in a data frame
> 
> Hi all,
> 
> Assume I have a data frame with numerical and factor 
> variables that I got through merging various other data 
> frames and subsetting the resulting data frame afterwards. 
> The number levels of the factors seem to be the same as in 
> the original data frames, probably because subset() calls 
> [.factor without drop = TRUE (that's what I gather from 
> scanning the mailing lists).
> 
> I wonder if there is a easy way to refactor all factors in 
> the data frame at once. I noted that fix(data_frame) does the 
> trick, however, this needs user interaction, which I'd like 
> to avoid. Subsequent write.table / read.table would be 
> another option but I'm not sure if R can guess the 
> factor/char/numeric-type correctly when reading the table.
> 
> So, is there any way in drop the unused factor levels from 
> *all* factors of a data frame without import/export ?
> 
> Thanks in advance,
> Hilmar
> 
> -- 
> 
> Hilmar Berger
> Studienkoordinator
> Institut f?r medizinische Informatik, Statistik und 
> Epidemiologie Universit?t Leipzig H?rtelstr. 16-18
> D-04107 Leipzig
> 
> Tel. +49 341 97 16 101
> Fax. +49 341 97 16 109
> email: hilmar.berger at imise.uni-leipzig.de
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From hilmar.berger at imise.uni-leipzig.de  Tue Jun  5 15:01:09 2007
From: hilmar.berger at imise.uni-leipzig.de (Hilmar Berger)
Date: Tue, 05 Jun 2007 15:01:09 +0200
Subject: [R] Refactor all factors in a data frame
In-Reply-To: <f43ke2$nnc$1@sea.gmane.org>
References: <f43ke2$nnc$1@sea.gmane.org>
Message-ID: <f43mqh$uu$1@sea.gmane.org>

Hi,

the best solution I found so far is (assuming <data> is your data.frame):

# identify all factor variables

factor.list = colnames(data)[sapply(data,class) == "factor"]

# use transform to apply factor() to all factor variables
trans.vars 
=paste(factor.list,"=factor(",factor.list,")",sep="",collapse="," )
data = eval(parse(text=paste("transform(data,",trans.vars,")")))

Regards,
Hilmar


Hilmar Berger schrieb:
> Hi all,
> 
> Assume I have a data frame with numerical and factor variables that I 
> got through merging various other data frames and subsetting the 
> resulting data frame afterwards. The number levels of the factors seem 
> to be the same as in the original data frames, probably because subset() 
> calls [.factor without drop = TRUE (that's what I gather from scanning 
> the mailing lists).
> 
> I wonder if there is a easy way to refactor all factors in the data 
> frame at once. I noted that fix(data_frame) does the trick, however, 
> this needs user interaction, which I'd like to avoid. Subsequent 
> write.table / read.table would be another option but I'm not sure if R 
> can guess the factor/char/numeric-type correctly when reading the table.
> 
> So, is there any way in drop the unused factor levels from *all* factors 
> of a data frame without import/export ?
> 
> Thanks in advance,
> Hilmar
> 


-- 

Hilmar Berger
Studienkoordinator
Institut f?r medizinische Informatik, Statistik und Epidemiologie
Universit?t Leipzig
H?rtelstr. 16-18
D-04107 Leipzig

Tel. +49 341 97 16 101
Fax. +49 341 97 16 109
email: hilmar.berger at imise.uni-leipzig.de


From ripley at stats.ox.ac.uk  Tue Jun  5 15:45:40 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 5 Jun 2007 14:45:40 +0100 (BST)
Subject: [R] Latex \ell symbol in plotmath
In-Reply-To: <46656214.1000006@nimr.mrc.ac.uk>
References: <mailman.9.1180951205.916.r-help@stat.math.ethz.ch>
	<46653C85.6050504@nimr.mrc.ac.uk>
	<Pine.LNX.4.64.0706051224080.32466@gannet.stats.ox.ac.uk>
	<46656214.1000006@nimr.mrc.ac.uk>
Message-ID: <Pine.LNX.4.64.0706051443510.17610@gannet.stats.ox.ac.uk>

On Tue, 5 Jun 2007, Mario dos Reis wrote:

> I am using R 2.5.0 on Fedora Linux core 6, AMD 64.

So for a suitable font you should be able to make this work on X11: I did 
on my FC5 Opteron system (but the fonts are on a fully loaded separate 
font server).

> Prof Brian Ripley wrote:
>> On Tue, 5 Jun 2007, Mario dos Reis wrote:
>> 
>>> Is it possible to use the '\ell' (i.e. the log likelihood) in plots?
>> 
>> 'plots'?  On what OS and what device?   (There is no general solution 
>> here.)
>> 
>>> I've been browsing the plotmath documentation unsucesfully.
>> 
>> That symbol is in neither of the Latin-1 nor symbol encoding used in R's 
>> standard fonts for postscript(), pdf() and the like.  Since it is not in 
>> the Adobe symbol encoding it is not accessible via plotmath.
>> 
>> It is Unicode character U+2113, and so on UTF-8 R systems you may well be 
>> able to enter it as \u2113 and get it plotted on-screen in a suitable font. 
>> But we'd need to know a lot more about your system to advise on how exactly 
>> to do so.
>> 
>
> Cheers,
> Mario dos Reis
>
> mdosrei at nimr.mrc.ac.uk
> +44 (0)20 8816 2300
>
> Division of Mathematical Biology
> National Institute for Medical Research
> The Ridgeway
> Mill Hill
> London, NW7 1AA, UK
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jh910 at juno.com  Tue Jun  5 15:37:01 2007
From: jh910 at juno.com (J. R. M. Hosking)
Date: Tue, 05 Jun 2007 09:37:01 -0400
Subject: [R] test for nested factors
In-Reply-To: <46640A7F.6010702@metrumrg.com>
References: <46640A7F.6010702@metrumrg.com>
Message-ID: <f43otu$9cj$1@sea.gmane.org>

Tim Bergsma wrote:
> Is there a conventional way to test for nested factors?  I.e., if 'a' 
> and 'b' are lists of same-length factors, does each level specified by 
> 'a' correspond to exactly one level specified by 'b'?

all( tapply(b, a, function(x) length(unique(x))==1 ))


J. R. M. Hosking


From ripley at stats.ox.ac.uk  Tue Jun  5 15:52:25 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 5 Jun 2007 14:52:25 +0100 (BST)
Subject: [R] Latex \ell symbol in plotmath
In-Reply-To: <20070605124957.M6205@centroin.com.br>
References: <mailman.9.1180951205.916.r-help@stat.math.ethz.ch>
	<46653C85.6050504@nimr.mrc.ac.uk>
	<Pine.LNX.4.64.0706051224080.32466@gannet.stats.ox.ac.uk>
	<20070605124957.M6205@centroin.com.br>
Message-ID: <Pine.LNX.4.64.0706051446200.17610@gannet.stats.ox.ac.uk>

On Tue, 5 Jun 2007, Alberto Monteiro wrote:

> Prof Brian Ripley wrote:
>>
>> It is Unicode character U+2113, and so on UTF-8 R systems you may
>> well be able to enter it as \u2113 and get it plotted on-screen in a
>> suitable font.  But we'd need to know a lot more about your system
>> to advise on how exactly to do so.
>>
> I must be sleeping, but I can't think about a program that lists
> "all" Unicode characters. A stupid and dirty solution would be:

You realize there are millions of them?  (2^21, in theory.)

> cat("u 31 = \u31\n")
> cat("u 32 = \u32\n")
> ...
>
> How can I vectorize this?

?intToUtf8

E.g. to look at a range around U+2113,

cat(intToUtf8(0x2110L+0:9, TRUE), "\n")


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From h.wickham at gmail.com  Tue Jun  5 16:11:19 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 5 Jun 2007 16:11:19 +0200
Subject: [R] Refactor all factors in a data frame
In-Reply-To: <f43mqh$uu$1@sea.gmane.org>
References: <f43ke2$nnc$1@sea.gmane.org> <f43mqh$uu$1@sea.gmane.org>
Message-ID: <f8e6ff050706050711n7ee7d987hea62c10644b48835@mail.gmail.com>

Hi Hilmar,

What was wrong with my solution?  It's much simpler and shorter.

cat <- sapply(df, is.factor)
df[cat] <- lapply(df[cat], factor)

Hadley

On 6/5/07, Hilmar Berger <hilmar.berger at imise.uni-leipzig.de> wrote:
> Hi,
>
> the best solution I found so far is (assuming <data> is your data.frame):
>
> # identify all factor variables
>
> factor.list = colnames(data)[sapply(data,class) == "factor"]
>
> # use transform to apply factor() to all factor variables
> trans.vars
> =paste(factor.list,"=factor(",factor.list,")",sep="",collapse="," )
> data = eval(parse(text=paste("transform(data,",trans.vars,")")))
>
> Regards,
> Hilmar
>
>
> Hilmar Berger schrieb:
> > Hi all,
> >
> > Assume I have a data frame with numerical and factor variables that I
> > got through merging various other data frames and subsetting the
> > resulting data frame afterwards. The number levels of the factors seem
> > to be the same as in the original data frames, probably because subset()
> > calls [.factor without drop = TRUE (that's what I gather from scanning
> > the mailing lists).
> >
> > I wonder if there is a easy way to refactor all factors in the data
> > frame at once. I noted that fix(data_frame) does the trick, however,
> > this needs user interaction, which I'd like to avoid. Subsequent
> > write.table / read.table would be another option but I'm not sure if R
> > can guess the factor/char/numeric-type correctly when reading the table.
> >
> > So, is there any way in drop the unused factor levels from *all* factors
> > of a data frame without import/export ?
> >
> > Thanks in advance,
> > Hilmar
> >
>
>
> --
>
> Hilmar Berger
> Studienkoordinator
> Institut f?r medizinische Informatik, Statistik und Epidemiologie
> Universit?t Leipzig
> H?rtelstr. 16-18
> D-04107 Leipzig
>
> Tel. +49 341 97 16 101
> Fax. +49 341 97 16 109
> email: hilmar.berger at imise.uni-leipzig.de
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Laurence.Amilhat at toulouse.inra.fr  Tue Jun  5 16:20:01 2007
From: Laurence.Amilhat at toulouse.inra.fr (Laurence Amilhat)
Date: Tue, 05 Jun 2007 16:20:01 +0200
Subject: [R] odfTable
Message-ID: <46657111.4060908@toulouse.inra.fr>

Hello,

I am using the odfWeave packages;
I draw a table using the function odfTable:

partCols <- gsub(?\\.?, ? ?, names(partenaires))
odfTable(partenaires, useRowNames = FALSE, colnames=partCols)


it's working as I have a table in my output file.
I would like to know how to change the background color for the header 
cells.
I assuming i have to use tableStyles, but I don't understand how.

Does someone have an idea to help me?

Thank you,

Laurence Amilhat.

-- 
====================================================================
= Laurence Amilhat    INRA Toulouse 31326 Castanet-Tolosan     	   = 
= Tel: 33 5 61 28 53 34   Email: laurence.amilhat at toulouse.inra.fr =


From ripley at stats.ox.ac.uk  Tue Jun  5 16:22:02 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 5 Jun 2007 15:22:02 +0100 (BST)
Subject: [R] Refactor all factors in a data frame
In-Reply-To: <20070605132732.SHXI25739.tomts25-srv.bellnexxia.net@JohnDesktop8300>
References: <20070605132732.SHXI25739.tomts25-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <Pine.LNX.4.64.0706051455020.17610@gannet.stats.ox.ac.uk>

On Tue, 5 Jun 2007, John Fox wrote:

> Dear Hilmar,
>
> You could use something like
>
> DF <- as.data.frame(lapply(DF, function (x) if (is.factor(x)) factor(x) else
> x))
>
> Where DF is the data frame.

I think DF[] <- lapply(DF, "[", drop=TRUE) is more likely to be what is 
wanted.  That drops factor levels without reordering the remaining 
levels, and would appear to be harmless for other variables.  But if one 
prefers

ind <- sapply(DF, is.factor)
DF[ind] <- lapply(DF[ind], "[", drop=TRUE)

Note the use of DF[] <- to preserve other attributes of DF, notably row 
names.

>
> I hope this helps,
> John
>
> --------------------------------
> John Fox, Professor
> Department of Sociology
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> 905-525-9140x23604
> http://socserv.mcmaster.ca/jfox
> --------------------------------
>
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch
>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Hilmar Berger
>> Sent: Tuesday, June 05, 2007 8:20 AM
>> To: r-help at stat.math.ethz.ch
>> Subject: [R] Refactor all factors in a data frame
>>
>> Hi all,
>>
>> Assume I have a data frame with numerical and factor
>> variables that I got through merging various other data
>> frames and subsetting the resulting data frame afterwards.
>> The number levels of the factors seem to be the same as in
>> the original data frames, probably because subset() calls
>> [.factor without drop = TRUE (that's what I gather from
>> scanning the mailing lists).
>>
>> I wonder if there is a easy way to refactor all factors in
>> the data frame at once. I noted that fix(data_frame) does the
>> trick, however, this needs user interaction, which I'd like
>> to avoid. Subsequent write.table / read.table would be
>> another option but I'm not sure if R can guess the
>> factor/char/numeric-type correctly when reading the table.
>>
>> So, is there any way in drop the unused factor levels from
>> *all* factors of a data frame without import/export ?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From vikasrawal at gmail.com  Tue Jun  5 16:31:19 2007
From: vikasrawal at gmail.com (Vikas Rawal)
Date: Tue, 5 Jun 2007 20:01:19 +0530
Subject: [R] help with using grid to modify ggplot/lattice plots
Message-ID: <20070605143119.GA7140@shireen.jnu.ac.in>

I want to use grid to modify some boxplots made using ggplot. I would
really appreciate if somebody could guide me to a resource on how to
use grid to modify such graphics. I guess the basic approach will be
similar to using grid to modify lattice graphics. To that extent
something that explains use of grid to modify lattice graphics may
also be useful.

I have gone through vignettes in the grid package but am somehow not
able to understand the overall approach. It would be useful if there
is something more specific that deals with using grid to modify such
graphics.

Vikas Rawal
Associate Professor
Centre for Economic Studies and Planning
Jawaharlal Nehru University
New Delhi


From ripley at stats.ox.ac.uk  Tue Jun  5 16:39:19 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 5 Jun 2007 15:39:19 +0100 (BST)
Subject: [R] Inverse of encodeString
In-Reply-To: <20070605130556.M17907@centroin.com.br>
References: <20070605130556.M17907@centroin.com.br>
Message-ID: <Pine.LNX.4.64.0706051530050.17610@gannet.stats.ox.ac.uk>

On Tue, 5 Jun 2007, Alberto Monteiro wrote:

> What is the inverse of encodeString?
>
> For example, \u1 is some Unicode symbol. If I do
>
> s <- encodeString("\u1")
>
> then s will be the string "\001". But anything I do
> with s, will not return the Unicode that corresponds to \u1:
>
> cat(s, "\n") # prints \001
> cat("\u1", "\n")  # prints y with umlaut

Not on a properly operational UTF-8 system: your terminal has a problem.

The help says

      'encodeString' escapes the strings in a character vector in the
      same way 'print.default' does, and optionally fits the encoded
      strings within a field width.

The printed representation is not necessarily invertible, but scan() would 
be a good start:

> scan(con<-textConnection(s), "", allowEscapes=TRUE); close(con)
Read 1 item
[1] "\001"

as might parse(text=) be.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From yn19832 at msn.com  Tue Jun  5 16:44:32 2007
From: yn19832 at msn.com (livia)
Date: Tue, 5 Jun 2007 07:44:32 -0700 (PDT)
Subject: [R] standard error of skewness
Message-ID: <10970956.post@talk.nabble.com>


Hi, 

I just wonder how can I calculate the standard error of skewness? Basiclly,
I would like to test whether it is too skewed or not?

Many thanks
-- 
View this message in context: http://www.nabble.com/standard-error-of-skewness-tf3872201.html#a10970956
Sent from the R help mailing list archive at Nabble.com.


From klijunjie at gmail.com  Tue Jun  5 17:02:32 2007
From: klijunjie at gmail.com (=?GB2312?B?wO6/ob3c?=)
Date: Tue, 5 Jun 2007 23:02:32 +0800
Subject: [R] the biggest integer R can display in complete form but not
	scientific form
Message-ID: <dff718fc0706050802sb21befr30a132494df1bfcd@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070605/a352a8d1/attachment.pl 

From sarah.goslee at gmail.com  Tue Jun  5 17:09:17 2007
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 5 Jun 2007 11:09:17 -0400
Subject: [R] odfTable
In-Reply-To: <46657111.4060908@toulouse.inra.fr>
References: <46657111.4060908@toulouse.inra.fr>
Message-ID: <efb536d50706050809h3caca688ob437d90e01324fed@mail.gmail.com>

Hi,

There are a couple of steps, and it requires use of the newest version of
odfWeave.

First, you need to set up the table styles in R _before_ you run odfWeave.

Here's an example:

	# Now to specify the styles themselves
	# The default list has 10 styles in it right now.
	existingStyles <- getStyleDefs()

	# Use one of the cell styles as a template for the new cell style
	# The style definition contains information on background
	# color, alignment, and borders.
	# For style 1, I want a background color.
	# Colors can be specified in hex format, or as "transparent".
	newStyle1 <- existingStyles$noBorder
	newStyle1$backgroundColor <- "#cccccc"

	# Finally, the new styles need to be set.
	existingStyles <- c(existingStyles, newStyle1=list(newStyle1))
	setStyleDefs(existingStyles)

After that, you can use the new style when defining your table in an
odfWeave document:

<<Table1,echo=FALSE,results=xml>>=
	### Conditional formatting based on the value of the table cell
	x <- data.frame(Var1=1:3, Var2=4:6, Var3=7:9, row.names=c("A", "B", "C"))

	# Here's a matrix specifying the desired styles for each cell in the table.
	# This could be p-values for the correlations in x, for example. For
	# this example, I'm just making it up.
	# The style matrix must have an additional column for the row names.
	y <- matrix(c(0, 0, 0, 1,0,0,3,0,1,2,0,2), byrow=FALSE, nrow=3, ncol=4)
	y <- data.frame(y)
	colnames(y) <- c("rownames", "Var1", "Var2", "Var3")

	# Now, to specify when to use these new styles.
	# tableStyles() will provide the default styles for each
	# element of x
	# note that I'm creating the styles for x based on y,
	# which already has the extra column for row names.
	x.styles <- tableStyles(y, header=colnames(y))

	# every element of x has two associated styles
	# for the cells, text style is in text and cell style is in cell
	# for headers, it is in header and headerCell
	
	# newStyle1 and newStyle2 are cell styles, so they are set here:
	x.styles$cell[y == 1] <- "newStyle1"

	odfTable(x, useRowNames = TRUE, styles = x.styles)
@

I have a more detailed explanation that I can send off-list if you are
interested. For your specific problem, you'd need to set the headerCell
style.

Sarah


On 6/5/07, Laurence Amilhat <Laurence.Amilhat at toulouse.inra.fr> wrote:
> Hello,
>
> I am using the odfWeave packages;
> I draw a table using the function odfTable:
>
> partCols <- gsub("\\.", " ", names(partenaires))
> odfTable(partenaires, useRowNames = FALSE, colnames=partCols)
>
>
> it's working as I have a table in my output file.
> I would like to know how to change the background color for the header
> cells.
> I assuming i have to use tableStyles, but I don't understand how.
>
> Does someone have an idea to help me?
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From shirley0818 at gmail.com  Tue Jun  5 17:29:14 2007
From: shirley0818 at gmail.com (shirley zhang)
Date: Tue, 5 Jun 2007 11:29:14 -0400
Subject: [R] Can I treat subject as fixed effect in linear model
Message-ID: <6fb73d020706050829nc05c587s17fa85a56f796864@mail.gmail.com>

Hi,

There are 20 subjects grouped by Gender, each subject has 2 tissues
(normal vs. cancer).

In fact, it is a 2-way anova (factors: Gender and tissue) with tissue
nested in subject. I've tried the following:

Model 1: lme(response ~ tissue*Gender, random = ~1|subject)
Model 2: response ~ tissue*Gender + subject
Model 3: response ~ tissue*Gender


It seems like Model 1 is the correct one since my experiment design is
nested design. However, can anybody tell me whether Model2 is
completely illegal?

Thanks


From stubben at lanl.gov  Tue Jun  5 17:39:16 2007
From: stubben at lanl.gov (Chris Stubben)
Date: Tue, 5 Jun 2007 15:39:16 +0000 (UTC)
Subject: [R] RMySQL question, sql with R vector or list
References: <8ee9d8f20706041450l429142f6w7d75e47585362f6d@mail.gmail.com>
Message-ID: <loom.20070605T172845-377@post.gmane.org>


> I am trying to write a RMySQL sql script inside R such that part of the SQL
> would be R list or vector.  For example, I want to select * from Atable
> where ID would equal to a members of R list or vector of "1, 2, 3".  Here
> the ID list was generated inside R and then try to feed to mysql to call to
> get additional data sets.
> 


You could pass a comma-separated list of IDs to the sql IN operator


## in MySQL

CREATE table tmp (id int, name char(1));
insert into tmp values (1, "A"), (2, "B"), (3, "C"), (4, "D"), (5, "E");



### in R


library(RMySQL)

con <- dbConnect("MySQL",  dbname="test" )


id.in<-function(ids)
{
 dbGetQuery(con,   paste("select * from tmp 
where id IN (", paste(ids,collapse=","), ")")  ) 
}



id.in(2:4)
  id name
1  2    B
2  3    C
3  4    D


## simple lists also work

id.in(list(1,4,5))
  id name
1  1    A
2  4    D
3  5    E


Chris


From perpdgo at colpos.mx  Tue Jun  5 17:22:53 2007
From: perpdgo at colpos.mx (Paulino Perez Rodriguez)
Date: Tue, 05 Jun 2007 09:22:53 -0600
Subject: [R] Still having problemes when loading RMySQL
Message-ID: <web-10680793@mailadmin.colpos.mx>


I am Still having problems when loading RMySQL under 
R-2.4.1, I am using RMySQL_0.6-0  and MySQL 5.0.41 under 
WinXP. I have added RMySQL\lib to the
PATH, prior to launching R, but the problem is the same:

>library(RMySQL)


Error in dyn.load(x, as.logical(local), as.logical(now)) :
         unable to load shared library 
'C:/PROGRA~1/R/R-24~1.1/library/RMySQL/libs/RMySQL.dll':
   LoadLibrary failure: Invalid access to memory location.

Error: package/namespace load failed for 'RMySQL'

Please helpme...

-- 
Este mensaje ha sido analizado por MailScanner
en busca de virus y otros contenidos peligrosos,
y se considera que est? limpio.


From Max.Kuhn at pfizer.com  Tue Jun  5 18:05:33 2007
From: Max.Kuhn at pfizer.com (Kuhn, Max)
Date: Tue, 5 Jun 2007 12:05:33 -0400
Subject: [R] multiple plot in odfWeave
In-Reply-To: <466518FF.80305@toulouse.inra.fr>
Message-ID: <71257D09F114DA4A8E134DEAC70F25D3088F80AD@groamrexm03.amer.pfizer.com>

Laurence,

I haven't seen any issues like this. Can you:

  1. Send the results of sessionInfo()

  2. Try using <<carte2, echo = FALSE, results= xml, fig = TRUE>>=. It
sounds like the text being written to the xml file is not valid xml.
This could be the case if results != xml.

  3. If that doesn't work, send me a data object and the odt file so
that I can try to reproduce the error?  

Max

----------------------------------------------------------------------
LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}


From roger.bos at us.rothschild.com  Tue Jun  5 18:11:10 2007
From: roger.bos at us.rothschild.com (Bos, Roger)
Date: Tue, 5 Jun 2007 12:11:10 -0400
Subject: [R] GUI for R running under Linux
In-Reply-To: <Pine.LNX.4.64.0706041900440.23163@tajo.ucsd.edu>
Message-ID: <D8C95B444AD6EE4AAD638D818A9CFD343A2B3B@RINNYCSE000.rth.ad.rothschild.com>

I am not very good with Linux, but I have a setup that works pretty well
using the KDE desktop environment, which offers Kate.  Once inside Kate
you can open a terminal session and start R there.  Then you can send
code snippets from Kate to R and see the output.  Its not as good as
Tinn-r under Windows, but as close as I could get.

HTH,

Roger 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Charles C. Berry
Sent: Monday, June 04, 2007 10:06 PM
To: John Sorkin
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] GUI for R running under Linux



 	RSiteSearch("GUI Linux")

will point you to this message to which an extraordinarily long thread
is
attached:

 	http://finzi.psych.upenn.edu/R/Rhelp02a/archive/56868.html

Oh yes, and to the R-FAQ

:-)

On Mon, 4 Jun 2007, John Sorkin wrote:

> Colleagues,
> I have been using R under windows for some time, and have become 
> accustomed to the GUI that accompanies R. I have recently begun using 
> R under Linux (Fedora), but can not find an equivalent GUI interface;
at a terminal window I enter R Am I missing something? Can I get a GUI
for R (version 2.5) running under Linux?
> Thanks,
> John
>
> John Sorkin M.D., Ph.D.
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology 
> Baltimore VA Medical Center 10 North Greene Street GRECC (BT/18/GR) 
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for the 
> so...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive
Medicine
E mailto:cberry at tajo.ucsd.edu	         UC San Diego
http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0901

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

********************************************************************** * 
This message is for the named person's use only. It may 
contain confidential, proprietary or legally privileged 
information. No right to confidential or privileged treatment 
of this message is waived or lost by any error in 
transmission. If you have received this message in error, 
please immediately notify the sender by e-mail, 
delete the message and all copies from your system and destroy 
any hard copies. You must not, directly or indirectly, use, 
disclose, distribute, print or copy any part of this message 
if you are not the intended recipient.


From roland.rproject at gmail.com  Tue Jun  5 18:13:02 2007
From: roland.rproject at gmail.com (Roland Rau)
Date: Tue, 05 Jun 2007 12:13:02 -0400
Subject: [R] Mandriva Spring 2007 and R
In-Reply-To: <37204.62935.qm@web62412.mail.re1.yahoo.com>
References: <37204.62935.qm@web62412.mail.re1.yahoo.com>
Message-ID: <46658B8E.9090401@gmail.com>

Hi Jonathan,

Jonathan Morse wrote:
> I am new to Linux (not to R) and recently installed Mandriva Spring 2007 on my partitioned hard drive.  My next objective is to install R in the Linux environment, unfortunately Mandriva is not one of the Linux distributions available for download...  Could someone please let me know which distribution I should use?  
> 
One possibility is, of course, that you compile it yourself for your 
computer. Compiling R was my first shot at compiling programs when I was 
new to Linux, and it was not very difficult. It is described nicely in 
the R Installation Administration Manual.
http://cran.r-project.org/doc/manuals/R-admin.html

Basically, you only need to take care of the following steps to get you 
started:
- did you download and unpack the source distribution (see section 1.1 
of the manual)?
- do you have the required tools installed (see section A.1 of the 
manual)? (C compiler, Fortran compiler, libreadline, libjpeg, libpng, 
tex/latex, Perl5, xorg-x11-dev)
- compilation (see section 2.1 in the manual)

I hope this helps?

Best,
Roland


From jiqiang123 at yahoo.com  Tue Jun  5 18:17:51 2007
From: jiqiang123 at yahoo.com (jiqiang yao)
Date: Tue, 5 Jun 2007 09:17:51 -0700 (PDT)
Subject: [R] read table
Message-ID: <618898.70306.qm@web52801.mail.re2.yahoo.com>

Hi, 
I'm a novice of R.

I want to read the following table into R:
names               mpg    cyl  disp  hp  drat    
Mazda RX4           21.0   6    160.0 110 3.90 
Mazda RX4 Wag       21.0   6    160.0 110 3.90 

The command I used is:
> test <- read.table(file.choose(),header=T)

The result is:
Error in read.table(file.choose(), header = T) : 
        more columns than column names

Can anybody tells me what is wrong?


From roland.rproject at gmail.com  Tue Jun  5 18:18:15 2007
From: roland.rproject at gmail.com (Roland Rau)
Date: Tue, 05 Jun 2007 12:18:15 -0400
Subject: [R] the biggest integer R can display in complete form but not
 scientific form
In-Reply-To: <dff718fc0706050802sb21befr30a132494df1bfcd@mail.gmail.com>
References: <dff718fc0706050802sb21befr30a132494df1bfcd@mail.gmail.com>
Message-ID: <46658CC7.2030107@gmail.com>

??? wrote:
> Dear R-lister,
> 
> One of my friends wanted to produce random number which is 64 bits. He did
> it with Fortune. I think R can do it also. But I don't know how to display a
> very big integer in the complete form but not scientific form. And what's
> the biggest integer R can display in complete form ?
> 
> Thanks in advance,
> 
> Li Junjie
> 
> 
> 
I guess the biggest integer R can represent (if this is what you mean) 
is machine dependent and you can find it out via:

.Machine
help(".Machine")

I hope this helps,
Roland


From singularitaet at gmx.net  Tue Jun  5 18:18:23 2007
From: singularitaet at gmx.net (Stefan Grosse)
Date: Tue, 05 Jun 2007 18:18:23 +0200
Subject: [R] GUI for R running under Linux
In-Reply-To: <4664728A.A712.00CB.0@grecc.umaryland.edu>
References: <4664728A.A712.00CB.0@grecc.umaryland.edu>
Message-ID: <46658CCF.2060706@gmx.net>

Hi John,

I use JGR when I am on Fedora. This is a good java gui which is similiar
(and better) compared to the R windows gui . You can install it via
install.packages("JGR",dep=T) and start with library(JGR). Sometimes
Java is not configured correctly so you might end up with an error. In
that case do R CMD javareconf on a root shell.

Stefan

-------- Original Message  --------
Subject: [R] GUI for R running under Linux
From: John Sorkin <jsorkin at grecc.umaryland.edu>
To: r-help at stat.math.ethz.ch
Date: 05.06.2007 02:15
> Colleagues,
> I have been using R under windows for some time, and have become accustomed to the GUI that accompanies R. I have recently begun using R under Linux (Fedora), but can not find an equivalent GUI interface; at a terminal window I enter
> R
> Am I missing something? Can I get a GUI for R (version 2.5) running under Linux?
> Thanks,
> John
>
> John Sorkin M.D., Ph.D.
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for the so...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>


From Max.Kuhn at pfizer.com  Tue Jun  5 18:22:49 2007
From: Max.Kuhn at pfizer.com (Kuhn, Max)
Date: Tue, 5 Jun 2007 12:22:49 -0400
Subject: [R] odfTable
In-Reply-To: <efb536d50706050809h3caca688ob437d90e01324fed@mail.gmail.com>
Message-ID: <71257D09F114DA4A8E134DEAC70F25D3088F80FB@groamrexm03.amer.pfizer.com>

Sarah and Laurence,

A few comments:

  1. The default background color for columns is horrible. I've changed
to white it in the upcoming version.

  2. In the next version (in 1-2 weeks), I have a fairly long document
that goes into much more detail about the specific styles that can be
changed and examples.

  3. To simply Sarah's approach, add the style definition via
setStyleDefs(existingStyles) as suggested. Then, just before making the
table, simply use

current <- getStyles()
currrent$header <- "newStyle1"
setStyles(current)

     then produce the table. Unless I'm not understanding what you want,
you shouldn't need to use tableStyles.

If anyone wants the new version while I finish a few of the
documentation pages, send me an email off-list and I'll send it to you.

Thanks,

Max

----------------------------------------------------------------------
LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}


From singularitaet at gmx.net  Tue Jun  5 18:24:45 2007
From: singularitaet at gmx.net (Stefan Grosse)
Date: Tue, 05 Jun 2007 18:24:45 +0200
Subject: [R] read table
In-Reply-To: <618898.70306.qm@web52801.mail.re2.yahoo.com>
References: <618898.70306.qm@web52801.mail.re2.yahoo.com>
Message-ID: <46658E4D.90705@gmx.net>

-------- Original Message  --------
Subject: [R] read table
From: jiqiang yao <jiqiang123 at yahoo.com>
To: r-help at stat.math.ethz.ch
Date: 05.06.2007 18:17
> Hi, 
> I'm a novice of R.
>
> I want to read the following table into R:
> names               mpg    cyl  disp  hp  drat    
> Mazda RX4           21.0   6    160.0 110 3.90 
> Mazda RX4 Wag       21.0   6    160.0 110 3.90 
>
> The command I used is:
>   
>> test <- read.table(file.choose(),header=T)
>>     

Does:

test <- read.table(file.choose(),header=T,sep="\t")

work?


From sarah.goslee at gmail.com  Tue Jun  5 18:29:55 2007
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 5 Jun 2007 12:29:55 -0400
Subject: [R] read table
In-Reply-To: <618898.70306.qm@web52801.mail.re2.yahoo.com>
References: <618898.70306.qm@web52801.mail.re2.yahoo.com>
Message-ID: <efb536d50706050929h4e7f2770g5152b4bfb956a1a2@mail.gmail.com>

The default separator in read.table is white space, so the first
line (header) has 6 elements, the second line has 7 elements,
and the third has 8 elements.

Either delete the spaces in the car names, or use sep="\t"
(or whatever is appropriate).

?read.table explains this.

Sarah

On 6/5/07, jiqiang yao <jiqiang123 at yahoo.com> wrote:
> Hi,
> I'm a novice of R.
>
> I want to read the following table into R:
> names               mpg    cyl  disp  hp  drat
> Mazda RX4           21.0   6    160.0 110 3.90
> Mazda RX4 Wag       21.0   6    160.0 110 3.90
>
> The command I used is:
> > test <- read.table(file.choose(),header=T)
>
> The result is:
> Error in read.table(file.choose(), header = T) :
>         more columns than column names
>
> Can anybody tells me what is wrong?
>
> ___________________


-- 
Sarah Goslee
http://www.functionaldiversity.org


From sarah.goslee at gmail.com  Tue Jun  5 18:32:04 2007
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 5 Jun 2007 12:32:04 -0400
Subject: [R] odfTable
In-Reply-To: <71257D09F114DA4A8E134DEAC70F25D3088F80FB@groamrexm03.amer.pfizer.com>
References: <efb536d50706050809h3caca688ob437d90e01324fed@mail.gmail.com>
	<71257D09F114DA4A8E134DEAC70F25D3088F80FB@groamrexm03.amer.pfizer.com>
Message-ID: <efb536d50706050932mb90ce15g2b02b85a05a567f@mail.gmail.com>

>
>   3. To simply Sarah's approach, add the style definition via
> setStyleDefs(existingStyles) as suggested. Then, just before making the
> table, simply use
>
> current <- getStyles()
> currrent$header <- "newStyle1"
> setStyles(current)
>
>      then produce the table. Unless I'm not understanding what you want,
> you shouldn't need to use tableStyles.


Ah, right. That example was cut from a longer document where the more
elaborate method was used for demonstration purposes.

Thanks for the hard work!
Sarah

-- 
Sarah Goslee
http://www.functionaldiversity.org


From jiqiang123 at yahoo.com  Tue Jun  5 18:40:21 2007
From: jiqiang123 at yahoo.com (jiqiang yao)
Date: Tue, 5 Jun 2007 09:40:21 -0700 (PDT)
Subject: [R] read table
In-Reply-To: <efb536d50706050929h4e7f2770g5152b4bfb956a1a2@mail.gmail.com>
Message-ID: <301913.72184.qm@web52804.mail.re2.yahoo.com>

Thanks. It works after I change the space in the names
with underscore.

--- Sarah Goslee <sarah.goslee at gmail.com> wrote:

> The default separator in read.table is white space,
> so the first
> line (header) has 6 elements, the second line has 7
> elements,
> and the third has 8 elements.
> 
> Either delete the spaces in the car names, or use
> sep="\t"
> (or whatever is appropriate).
> 
> ?read.table explains this.
> 
> Sarah
> 
> On 6/5/07, jiqiang yao <jiqiang123 at yahoo.com> wrote:
> > Hi,
> > I'm a novice of R.
> >
> > I want to read the following table into R:
> > names               mpg    cyl  disp  hp  drat
> > Mazda RX4           21.0   6    160.0 110 3.90
> > Mazda RX4 Wag       21.0   6    160.0 110 3.90
> >
> > The command I used is:
> > > test <- read.table(file.choose(),header=T)
> >
> > The result is:
> > Error in read.table(file.choose(), header = T) :
> >         more columns than column names
> >
> > Can anybody tells me what is wrong?
> >
> > ___________________
> 
> 
> -- 
> Sarah Goslee
> http://www.functionaldiversity.org
>


From jrkrideau at yahoo.ca  Tue Jun  5 18:44:35 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Tue, 5 Jun 2007 12:44:35 -0400 (EDT)
Subject: [R] read table
In-Reply-To: <618898.70306.qm@web52801.mail.re2.yahoo.com>
Message-ID: <798934.25469.qm@web32802.mail.mud.yahoo.com>

R considers Mazda RX4 Wag to be three columns.  There
fore you have 6 columns of data and only 6 names.

Use " "   like this
"Mazda RX4"  and Mazda Rx4 Wag" to indicate each is a
single character value.


--- jiqiang yao <jiqiang123 at yahoo.com> wrote:

> Hi, 
> I'm a novice of R.
> 
> I want to read the following table into R:
> names               mpg    cyl  disp  hp  drat    
> Mazda RX4           21.0   6    160.0 110 3.90 
> Mazda RX4 Wag       21.0   6    160.0 110 3.90 
> 
> The command I used is:
> > test <- read.table(file.choose(),header=T)
> 
> The result is:
> Error in read.table(file.choose(), header = T) : 
>         more columns than column names
> 
> Can anybody tells me what is wrong?
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From hilmar.berger at imise.uni-leipzig.de  Tue Jun  5 18:55:16 2007
From: hilmar.berger at imise.uni-leipzig.de (Hilmar Berger)
Date: Tue, 05 Jun 2007 18:55:16 +0200
Subject: [R] Refactor all factors in a data frame
In-Reply-To: <f8e6ff050706050711n7ee7d987hea62c10644b48835@mail.gmail.com>
References: <f43ke2$nnc$1@sea.gmane.org> <f43mqh$uu$1@sea.gmane.org>
	<f8e6ff050706050711n7ee7d987hea62c10644b48835@mail.gmail.com>
Message-ID: <f444hk$olh$1@sea.gmane.org>

Hi,
thanks for all suggestions - I found a solution myself within 5 minutes, 
but your suggestions are surely more elegant / shorter.

Thanks again,
Hilmar



hadley wickham schrieb:
> Hi Hilmar,
> 
> What was wrong with my solution?  It's much simpler and shorter.
> 
> cat <- sapply(df, is.factor)
> df[cat] <- lapply(df[cat], factor)
> 
> Hadley
> 
> On 6/5/07, Hilmar Berger <hilmar.berger at imise.uni-leipzig.de> wrote:
> 

> 


-- 

Hilmar Berger
Studienkoordinator
Institut f?r medizinische Informatik, Statistik und Epidemiologie
Universit?t Leipzig
H?rtelstr. 16-18
D-04107 Leipzig

Tel. +49 341 97 16 101
Fax. +49 341 97 16 109
email: hilmar.berger at imise.uni-leipzig.de


From sfalcon at fhcrc.org  Tue Jun  5 19:04:05 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Tue, 05 Jun 2007 10:04:05 -0700
Subject: [R] locked environment and inheritance
In-Reply-To: <523083.8004.qm@web56212.mail.re3.yahoo.com> (johan Faux's
	message of "Mon, 4 Jun 2007 14:13:40 -0700 (PDT)")
References: <523083.8004.qm@web56212.mail.re3.yahoo.com>
Message-ID: <m24plmtjsq.fsf@ziti.local>

johan Faux <johanfaux at yahoo.com> writes:

> Thanks for your reply.
>
> Experimenting a little further, I was able to learn a bit more and
> find what is the real problem of mine what the real question is.

>
> I could create my S4 extended class by adding these two lines in my namespace file
> importClassesFrom(Matrix,Matrix)
> importClassesFrom(Matrix,dMatrix)

You can also do:

  importClassesFrom(Matrix, Matrix, dMatrix)

> and then creating my new class in another R file
>
> library(Matrix)
  ^^^^^^^

I would not call library for such a case.  If you are importing
library in your package's namespace, then you probably want the
following in your DESCRIPTION file:

   Depends: Matrix, methods
   Imports: Matrix

[yes, there is a lot of duplication in how things are specified]

> setClass("myMatClass", representation("dMatrix",myslot="numeric"))
>
>
> which creates the new S4 class when my package is loaded. 
>
> The problem is that I would like to create the class inside a function of mine:
>
> createMyS4Class() {
>     library(Matrix)
>
>     setClass("myMatClass", representation("dMatrix",myslot="numeric"))
> }

Again, the call to library should not be needed.

> so that, at some point (after my package is loaded ), I can do something like:
>
> if (cond)
>     createMyS4Class()

How do you intend to use such a class?  Is the real issue that you
don't want to depend on Matrix and only use it if it is available?

> Now, I understand that at this point, my package environment is
> locked.  So the question become: Is there any way that I can unlock
> my package environment, create my new S4 class and lock it back or
> something?

I think that might be possible, but that doesn't make it a good idea :-)

> Please let me know if that makes sense ? 
> I appreciate your comments.

It might help to understand what your are trying to achieve overall.
Perhaps there are other approaches...

Also, at this point, the discussion is more appropriate for R-devel.
Perhaps you can move the conversation there?

Best,

+ seth

-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
http://bioconductor.org


From albmont at centroin.com.br  Tue Jun  5 19:11:11 2007
From: albmont at centroin.com.br (Alberto Monteiro)
Date: Tue, 5 Jun 2007 15:11:11 -0200
Subject: [R] Latex \ell symbol in plotmath
In-Reply-To: <Pine.LNX.4.64.0706051446200.17610@gannet.stats.ox.ac.uk>
References: <mailman.9.1180951205.916.r-help@stat.math.ethz.ch>
	<46653C85.6050504@nimr.mrc.ac.uk>
	<Pine.LNX.4.64.0706051224080.32466@gannet.stats.ox.ac.uk>
	<20070605124957.M6205@centroin.com.br>
	<Pine.LNX.4.64.0706051446200.17610@gannet.stats.ox.ac.uk>
Message-ID: <20070605170655.M37514@centroin.com.br>

Prof Brian Ripley wrote:
>
>> I must be sleeping, but I can't think about a program that lists
>> "all" Unicode characters. A stupid and dirty solution would be:
> 
> You realize there are millions of them?  (2^21, in theory.)
>
:-) Yes, but in Windows there are only 256...
 
>> cat("u 31 = \u31\n")
>> cat("u 32 = \u32\n")
>> ...
>>
>> How can I vectorize this?
> 
> ?intToUtf8
> 
> E.g. to look at a range around U+2113,
> 
> cat(intToUtf8(0x2110L+0:9, TRUE), "\n")
>
This does not work in R 2.4.1 for Windows. 0x2110L returns
an error, and intToUtf8 returns an error on anything except
the simplest calls:

intToUtf8(33) # error. Argument x must be an integer vector
intToUtf8(33:35) # ok
intToUtf8(40 + 0:9) # error. Argument x must be an integer vector

Alberto Monteiro


From jrkrideau at yahoo.ca  Tue Jun  5 19:19:50 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Tue, 5 Jun 2007 13:19:50 -0400 (EDT)
Subject: [R] Extracting lists in the dataframe $ format
In-Reply-To: <001f01c7a6db$b1be35f0$6405a8c0@MXD32803WB>
Message-ID: <541033.50455.qm@web32813.mail.mud.yahoo.com>

I think your indexing is wrong in the function. Note
the tble[a] rather than tble[,a]. 

Try:
regression=function(tble,a,b)
 {
            plot.new()
            plot(tble[,a]~tble[,b])
            lmm=lm(tble[,a]~tble[,b])
            abline(lmm)
            anova(lmm)
 }



--- Stan Hopkins <stanhopkins at comcast.net> wrote:

> I'm new to R and am trying to extract the factors of
> a dataframe using numeric indices (e.g. df[1]) that
> are input to a function definition instead of the
> other types of references (e.g. df$out).  df[1] is a
> list(?) whose class is "dataframe".  These indexed
> lists can be printed successfuly but are not
> agreeable to the plot() and lm() functions shown
> below as are their df$out references.  Reading the
> documentation for plot and lm hasn't helped yet. 
> Thanks in advance - Stan.
> 
> > df=data.frame(out=1:4*3,pred1=1:4,pred2=1:4*2)
> > regression=function(tble,a,b) 
> + {
> +            plot.new()
> +            plot(tble[a]~tble[b])
> +            lmm=lm(tble[a]~tble[b])
> +            abline(lmm)
> +            anova(lmm)
> + }
> > df[1]
>   out
> 1   3
> 2   6
> 3   9
> 4  12
> > df
>   out pred1 pred2
> 1   3     1     2
> 2   6     2     4
> 3   9     3     6
> 4  12     4     8
> > regression(df,1,3)
> Error in model.frame(formula, rownames, variables,
> varnames, extras, extranames,  : 
>         invalid type (list) for variable 'tble[a]'


From h.wickham at gmail.com  Tue Jun  5 19:22:25 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 5 Jun 2007 19:22:25 +0200
Subject: [R] Latex \ell symbol in plotmath
In-Reply-To: <20070605170655.M37514@centroin.com.br>
References: <mailman.9.1180951205.916.r-help@stat.math.ethz.ch>
	<46653C85.6050504@nimr.mrc.ac.uk>
	<Pine.LNX.4.64.0706051224080.32466@gannet.stats.ox.ac.uk>
	<20070605124957.M6205@centroin.com.br>
	<Pine.LNX.4.64.0706051446200.17610@gannet.stats.ox.ac.uk>
	<20070605170655.M37514@centroin.com.br>
Message-ID: <f8e6ff050706051022g3a786e48w78fe1b42532f8a0f@mail.gmail.com>

On 6/5/07, Alberto Monteiro <albmont at centroin.com.br> wrote:
> Prof Brian Ripley wrote:
> >
> >> I must be sleeping, but I can't think about a program that lists
> >> "all" Unicode characters. A stupid and dirty solution would be:
> >
> > You realize there are millions of them?  (2^21, in theory.)
> >
> :-) Yes, but in Windows there are only 256...
>
> >> cat("u 31 = \u31\n")
> >> cat("u 32 = \u32\n")
> >> ...
> >>
> >> How can I vectorize this?
> >
> > ?intToUtf8
> >
> > E.g. to look at a range around U+2113,
> >
> > cat(intToUtf8(0x2110L+0:9, TRUE), "\n")
> >
> This does not work in R 2.4.1 for Windows. 0x2110L returns
> an error, and intToUtf8 returns an error on anything except
> the simplest calls:
>
> intToUtf8(33) # error. Argument x must be an integer vector
> intToUtf8(33:35) # ok
> intToUtf8(40 + 0:9) # error. Argument x must be an integer vector

Well you need to give it integers!

intToUtf8(33L)
intToUtf8(40L + 0:9)

Hadley


From albmont at centroin.com.br  Tue Jun  5 19:35:47 2007
From: albmont at centroin.com.br (Alberto Monteiro)
Date: Tue, 5 Jun 2007 15:35:47 -0200
Subject: [R] Latex \ell symbol in plotmath
In-Reply-To: <f8e6ff050706051022g3a786e48w78fe1b42532f8a0f@mail.gmail.com>
References: <mailman.9.1180951205.916.r-help@stat.math.ethz.ch>
	<46653C85.6050504@nimr.mrc.ac.uk>
	<Pine.LNX.4.64.0706051224080.32466@gannet.stats.ox.ac.uk>
	<20070605124957.M6205@centroin.com.br>
	<Pine.LNX.4.64.0706051446200.17610@gannet.stats.ox.ac.uk>
	<20070605170655.M37514@centroin.com.br>
	<f8e6ff050706051022g3a786e48w78fe1b42532f8a0f@mail.gmail.com>
Message-ID: <20070605173353.M93230@centroin.com.br>


hadley wickham wrote:
>
>> intToUtf8(33) # error. Argument x must be an integer vector
>> intToUtf8(33:35) # ok
>> intToUtf8(40 + 0:9) # error. Argument x must be an integer vector
> 
> Well you need to give it integers!
> 
> intToUtf8(33L)
> intToUtf8(40L + 0:9)
>
As I wrote before, 33L or 40L return an error in R 2.4.1 for Windows.

Alberto Monteiro


From rsb at wsu.edu  Tue Jun  5 19:46:26 2007
From: rsb at wsu.edu (Bricklemyer,Ross S)
Date: Tue, 5 Jun 2007 10:46:26 -0700
Subject: [R] Mandriva Spring 2007 and R
In-Reply-To: <mailman.13.1181037604.4445.r-help@stat.math.ethz.ch>
References: <mailman.13.1181037604.4445.r-help@stat.math.ethz.ch>
Message-ID: <2FC987BC0B90B24786CAF43DD3F5719CB05541@CRU105.cahe.ad.wsu.edu>

Jonathan,
I was in the same predicament not long ago with Mandriva 2007.  You will
need to compile and build R from the source code.  I have not completely
gotten all of the bugs worked out on my system, but I am still quite new
to linux.  Good luck.

Ross

*******************************************************************
Ross Bricklemyer
Dept. of Crop and Soil Sciences
Washington State University
291D Johnson Hall
Pullman, WA 99164-6420
Work: 509.335.3661
Cell/Home: 406.570.8576
Fax: 509.335.8674
Email: rsb at wsu.edu


Message: 49
Date: Mon, 4 Jun 2007 15:34:20 -0700 (PDT)
From: Jonathan Morse <asn151 at yahoo.com>
Subject: [R] Mandriva Spring 2007 and R
To: r-help at stat.math.ethz.ch
Message-ID: <37204.62935.qm at web62412.mail.re1.yahoo.com>
Content-Type: text/plain

I am new to Linux (not to R) and recently installed Mandriva Spring 2007
on my partitioned hard drive.  My next objective is to install R in the
Linux environment, unfortunately Mandriva is not one of the Linux
distributions available for download...  Could someone please let me
know which distribution I should use?  

Thanks.

Jonathan


From waverley.paloalto at gmail.com  Tue Jun  5 19:48:32 2007
From: waverley.paloalto at gmail.com (Waverley)
Date: Tue, 5 Jun 2007 10:48:32 -0700
Subject: [R] RMySQL question, sql with R vector or list
In-Reply-To: <loom.20070605T172845-377@post.gmane.org>
References: <8ee9d8f20706041450l429142f6w7d75e47585362f6d@mail.gmail.com>
	<loom.20070605T172845-377@post.gmane.org>
Message-ID: <8ee9d8f20706051048xd78b277k403194ad4d32c80f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070605/d2835ba5/attachment.pl 

From lzhtom at hotmail.com  Tue Jun  5 19:55:34 2007
From: lzhtom at hotmail.com (zhihua li)
Date: Tue, 05 Jun 2007 17:55:34 +0000
Subject: [R] rJava installation under linux: configuration failed
Message-ID: <BAY110-F40EEFEF56E9A5E0AA777BDC7200@phx.gbl>

Hi netter,

Recently I was trying to install rJava.  The operating system is suse 10.0, 
and the R versionis 2.5.0.

Following the instructions of R Wiki for rJava, I did configuration first: 
R CMD javareconf

and then it showed a series of information, from what it seems that java is 
in the system and the configuration succeeded.

Then I tried to install rJava:
install.packages("rJava")

following which rJava was downloaded and being installed, but during the 
last test step it said: can't complie a simple JNL program. Configuration 
Failed!

Did I do something wrong? Or there's something I should do that I didn't?

Thanks a lot!


                 Sincerely Yours:  Zhihua Li


From ripley at stats.ox.ac.uk  Tue Jun  5 19:56:21 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 5 Jun 2007 18:56:21 +0100 (BST)
Subject: [R] read table
In-Reply-To: <efb536d50706050929h4e7f2770g5152b4bfb956a1a2@mail.gmail.com>
References: <618898.70306.qm@web52801.mail.re2.yahoo.com>
	<efb536d50706050929h4e7f2770g5152b4bfb956a1a2@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0706051854320.29209@gannet.stats.ox.ac.uk>

On Tue, 5 Jun 2007, Sarah Goslee wrote:

> The default separator in read.table is white space, so the first
> line (header) has 6 elements, the second line has 7 elements,
> and the third has 8 elements.
>
> Either delete the spaces in the car names, or use sep="\t"
> (or whatever is appropriate).

Or add quotes around character fields which contain spaces.
By default either single or double quotes will work (used in matched 
pairs, of course).

>
> ?read.table explains this.
>
> Sarah
>
> On 6/5/07, jiqiang yao <jiqiang123 at yahoo.com> wrote:
>> Hi,
>> I'm a novice of R.
>>
>> I want to read the following table into R:
>> names               mpg    cyl  disp  hp  drat
>> Mazda RX4           21.0   6    160.0 110 3.90
>> Mazda RX4 Wag       21.0   6    160.0 110 3.90
>>
>> The command I used is:
>>> test <- read.table(file.choose(),header=T)
>>
>> The result is:
>> Error in read.table(file.choose(), header = T) :
>>         more columns than column names
>>
>> Can anybody tells me what is wrong?
>>
>> ___________________
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From br44114 at gmail.com  Tue Jun  5 20:29:26 2007
From: br44114 at gmail.com (bogdan romocea)
Date: Tue, 5 Jun 2007 14:29:26 -0400
Subject: [R] RMySQL question, sql with R vector or list
Message-ID: <8d5a36350706051129j70f4c5e9g278522d7f206c7da@mail.gmail.com>

With regards to your concern - export the R object to a MySQL table
(the RMySQL documentation tells you how), then run an inner join. Or
if the table to query isn't that big, pull it in R and subset it with
%in%. You could use system.time() to see which runs faster.


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Waverley
> Sent: Tuesday, June 05, 2007 1:49 PM
> To: Chris Stubben
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] RMySQL question, sql with R vector or list
>
> Thanks Chris.
>
> I think this should work.  I have one more question regarding
> this.  Is that
> possible to write some PL/SQL scripts integrated inside R, it
> is the same
> token like I have asked in my previous question.  In this
> way, native R data
> structures can be passed to the MYSQL data base directly to
> interrogate
> dynamically, rather than statically like using paste.  One
> concern using
> paste to construct the SQL command is this: what about if the
> ID list in
> your sample becomes very large, is this a problem to
> construct this way?
>
> I will try to follow your advice but I hope someone on the
> mailing list can
> teach me how to integrate R data structure with MYSQL like PL/SQL.
>
> Thanks much.
>
> Bruce
>
>
> On 6/5/07, Chris Stubben <stubben at lanl.gov> wrote:
> >
> >
> > > I am trying to write a RMySQL sql script inside R such
> that part of the
> > SQL
> > > would be R list or vector.  For example, I want to select
> * from Atable
> > > where ID would equal to a members of R list or vector of "1, 2,
> > 3".  Here
> > > the ID list was generated inside R and then try to feed
> to mysql to call
> > to
> > > get additional data sets.
> > >
> >
> >
> > You could pass a comma-separated list of IDs to the sql IN operator
> >
> >
> > ## in MySQL
> >
> > CREATE table tmp (id int, name char(1));
> > insert into tmp values (1, "A"), (2, "B"), (3, "C"), (4,
> "D"), (5, "E");
> >
> >
> >
> > ### in R
> >
> >
> > library(RMySQL)
> >
> > con <- dbConnect("MySQL",  dbname="test" )
> >
> >
> > id.in<-function(ids)
> > {
> > dbGetQuery(con,   paste("select * from tmp
> > where id IN (", paste(ids,collapse=","), ")")  )
> > }
> >
> >
> >
> > id.in(2:4)
> > id name
> > 1  2    B
> > 2  3    C
> > 3  4    D
> >
> >
> > ## simple lists also work
> >
> > id.in(list(1,4,5))
> > id name
> > 1  1    A
> > 2  4    D
> > 3  5    E
> >
> >
> > Chris
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
>
> --
> Waverley @ Palo Alto
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From waverley.paloalto at gmail.com  Tue Jun  5 20:49:43 2007
From: waverley.paloalto at gmail.com (Waverley)
Date: Tue, 5 Jun 2007 11:49:43 -0700
Subject: [R] RMySQL question, sql with R vector or list
In-Reply-To: <8d5a36350706051129j70f4c5e9g278522d7f206c7da@mail.gmail.com>
References: <8d5a36350706051129j70f4c5e9g278522d7f206c7da@mail.gmail.com>
Message-ID: <8ee9d8f20706051149o2fe1b7d4u71a710d869d70ab9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070605/b5f53aaa/attachment.pl 

From stubben at lanl.gov  Tue Jun  5 20:53:40 2007
From: stubben at lanl.gov (Chris Stubben)
Date: Tue, 5 Jun 2007 18:53:40 +0000 (UTC)
Subject: [R] RMySQL question, sql with R vector or list
References: <8ee9d8f20706041450l429142f6w7d75e47585362f6d@mail.gmail.com>
	<loom.20070605T172845-377@post.gmane.org>
	<8ee9d8f20706051048xd78b277k403194ad4d32c80f@mail.gmail.com>
Message-ID: <loom.20070605T204314-148@post.gmane.org>

> dynamically, rather than statically like using paste.  One concern using
> paste to construct the SQL command is this: what about if the ID list in
> your sample becomes very large, is this a problem to construct this way?
> 


I have not messed with procedures in mysql 5, so I have no idea about the first
question.  However, the IN operator should be fast, even for large vectors.   
It takes me a second to retrieve 10,000 random records from a table with
100,000+ rows.

system.time(id.in( sample(1:100000, 10000) ))[3]
[1] 1.07


Also, I forgot to mention this before -  if your ID is a character field, you
can quote strings in the IN clause using the shell quote function.

paste(shQuote(ids),collapse=",")

Chris


From dhinds at sonic.net  Tue Jun  5 21:15:34 2007
From: dhinds at sonic.net (dhinds at sonic.net)
Date: Tue, 5 Jun 2007 19:15:34 +0000 (UTC)
Subject: [R] One-dimensional point processes
Message-ID: <f44com$qfg$1@sea.gmane.org>

I'm interested in characterizing data from a one-dimensional point
process... say, testing for stationarity, or measuring the degree of
clustering at different length scales.  This sounds like a spatial
statistics problem but the available tools all seem focused on 2+
dimensional data.  Time series methods have the right dimensionality
but seem focused on regularly spaced data.

Does anyone know of an R package that implements spatial statistics
methods for one-dimensional data?  So far I've come up pretty dry.

-- Dave


From sabunime at gmail.com  Tue Jun  5 21:29:08 2007
From: sabunime at gmail.com (Saeed Abu Nimeh)
Date: Tue, 05 Jun 2007 14:29:08 -0500
Subject: [R] naiveBayes other than e1071
In-Reply-To: <71257D09F114DA4A8E134DEAC70F25D3088B08FB@groamrexm03.amer.pfizer.com>
References: <71257D09F114DA4A8E134DEAC70F25D3088B08FB@groamrexm03.amer.pfizer.com>
Message-ID: <4665B984.5040704@gmail.com>

Max,
Thanks. I have tried it but i keep getting an error:
Error in as.vector(x, mode) : invalid argument 'mode'
Do I have to do something specific when using the class column. I tried
both  y.y<-as.vector and y.y<-as.factor.

dread<-read.table('dataset.csv',sep=",")
x.x<-as.matrix(dread[,2:256])
y.y<-as.vector(dread[,1])
nb<- NaiveBayes(x=x.x,grouping=y.y)
pred.nb<-predict(nb)

Error in as.vector(x, mode) : invalid argument 'mode'

Thanks,
Saeed

Kuhn, Max wrote:
> Saeed,
> 
> There is a version in the klaR package. I recently submitted a change to
> the predict function that may be related to your problem. 
> 
> If:
> 
>   1. the posterior probabilities (apart from the prior) are being
> approximated by the product of the p(x_i|y_j) and
> 
>   2. a lot of predictors are being used
> 
> then posterior probabilities may have values of absolute zero. 
> 
> When the approximation is used, the approximate posterior probabilities
> are normalized by their sum (which is zero in such cases).
> 
> The patch in klaR uses the product of the conditional divided by the
> marginal of x_i (per the true formula). I haven't seen the problem occur
> with this patch.
> 
> HTH,
> 
> Max
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Saeed Abu Nimeh
> Sent: Monday, June 04, 2007 2:45 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] naiveBayes other than e1071
> 
> Hi List,
> Is there a naiveBayes interface other than the one in e1071 package. For
> some reason on certain datasets all predicted values are NaN, but it
> predicts well on others.
> Thanks,
> Saeed
> ---
> model <- naiveBayes(x.train, y.train, laplace = 3)
> pred <- predict(model,x.test,type="raw")
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ----------------------------------------------------------------------
> LEGAL NOTICE
> Unless expressly stated otherwise, this message is confidential and may be privileged.  It is intended for the addressee(s) only.  Access to this E-mail by anyone else is unauthorized.  If you are not an addressee, any disclosure or copying of the contents of this E-mail or any action taken (or not taken) in reliance on it is unauthorized and may be unlawful.  If you are not an addressee, please inform the sender immediately.
>


From ltatiana at student.ethz.ch  Tue Jun  5 21:38:54 2007
From: ltatiana at student.ethz.ch (violeta834)
Date: Tue, 5 Jun 2007 12:38:54 -0700 (PDT)
Subject: [R] logit model interpretation
Message-ID: <10976317.post@talk.nabble.com>


Hello everyone

I appologize for my lack of experience in statistical methods. I am an R
user begginer and I am running a logit model using "zelig"  and "pcse"
packages. I will go to the point and is that Im having problems with
interpreting the results of my models.. It is really simple (I guess for the
most advanced scholars) however I really dont understand how to interpret
the coefficients.

here is my output

Call:
zelig(formula = newtrst ~ stfdem + stfgov + clsprty, model = "logit", 
    data = spadat)

Deviance Residuals: 
   Min      1Q  Median      3Q     Max  
-2.784   0.318   0.410   0.540   1.460  

Coefficients:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)  -0.6434     0.2427   -2.65    0.008 ** 
stfdem        0.2447     0.0441    5.55  2.8e-08 ***
stfgov        0.2050     0.0468    4.38  1.2e-05 ***
clsprty       0.4173     0.1649    2.53    0.011 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 1112.46  on 1427  degrees of freedom
Residual deviance:  996.02  on 1424  degrees of freedom
AIC: 1004

Number of Fisher Scoring iterations: 5


Thanks

Vioelta


-- 
View this message in context: http://www.nabble.com/logit-model-interpretation-tf3873849.html#a10976317
Sent from the R help mailing list archive at Nabble.com.


From ltatiana at student.ethz.ch  Tue Jun  5 21:38:54 2007
From: ltatiana at student.ethz.ch (violeta834)
Date: Tue, 5 Jun 2007 12:38:54 -0700 (PDT)
Subject: [R] logit model interpretation
Message-ID: <10976317.post@talk.nabble.com>


Hello everyone

I appologize for my lack of experience in statistical methods. I am an R
user begginer and I am running a logit model using "zelig"  and "pcse"
packages. I will go to the point and is that Im having problems with
interpreting the results of my models.. It is really simple (I guess for the
most advanced scholars) however I really dont understand how to interpret
the coefficients.

here is my output

Call:
zelig(formula = newtrst ~ stfdem + stfgov + clsprty, model = "logit", 
    data = spadat)

Deviance Residuals: 
   Min      1Q  Median      3Q     Max  
-2.784   0.318   0.410   0.540   1.460  

Coefficients:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)  -0.6434     0.2427   -2.65    0.008 ** 
stfdem        0.2447     0.0441    5.55  2.8e-08 ***
stfgov        0.2050     0.0468    4.38  1.2e-05 ***
clsprty       0.4173     0.1649    2.53    0.011 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 1112.46  on 1427  degrees of freedom
Residual deviance:  996.02  on 1424  degrees of freedom
AIC: 1004

Number of Fisher Scoring iterations: 5


Thanks

violeta


-- 
View this message in context: http://www.nabble.com/logit-model-interpretation-tf3873849.html#a10976317
Sent from the R help mailing list archive at Nabble.com.


From ligges at statistik.uni-dortmund.de  Tue Jun  5 21:56:28 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 05 Jun 2007 21:56:28 +0200
Subject: [R] naiveBayes other than e1071
In-Reply-To: <4665B984.5040704@gmail.com>
References: <71257D09F114DA4A8E134DEAC70F25D3088B08FB@groamrexm03.amer.pfizer.com>
	<4665B984.5040704@gmail.com>
Message-ID: <4665BFEC.5070004@statistik.uni-dortmund.de>



Saeed Abu Nimeh wrote:
> Max,
> Thanks. I have tried it but i keep getting an error:
> Error in as.vector(x, mode) : invalid argument 'mode'
> Do I have to do something specific when using the class column. I tried
> both  y.y<-as.vector and y.y<-as.factor.
> 
> dread<-read.table('dataset.csv',sep=",")
> x.x<-as.matrix(dread[,2:256])
> y.y<-as.vector(dread[,1])
> nb<- NaiveBayes(x=x.x,grouping=y.y)
> pred.nb<-predict(nb)
> 
> Error in as.vector(x, mode) : invalid argument 'mode'



Please tell us (according to the posting guide): Which version of R? 
Which version of klaR? Example data that reproduce the error?

Uwe Ligges



> Thanks,
> Saeed
> 
> Kuhn, Max wrote:
>> Saeed,
>>
>> There is a version in the klaR package. I recently submitted a change to
>> the predict function that may be related to your problem. 
>>
>> If:
>>
>>   1. the posterior probabilities (apart from the prior) are being
>> approximated by the product of the p(x_i|y_j) and
>>
>>   2. a lot of predictors are being used
>>
>> then posterior probabilities may have values of absolute zero. 
>>
>> When the approximation is used, the approximate posterior probabilities
>> are normalized by their sum (which is zero in such cases).
>>
>> The patch in klaR uses the product of the conditional divided by the
>> marginal of x_i (per the true formula). I haven't seen the problem occur
>> with this patch.
>>
>> HTH,
>>
>> Max
>>
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch
>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Saeed Abu Nimeh
>> Sent: Monday, June 04, 2007 2:45 PM
>> To: r-help at stat.math.ethz.ch
>> Subject: [R] naiveBayes other than e1071
>>
>> Hi List,
>> Is there a naiveBayes interface other than the one in e1071 package. For
>> some reason on certain datasets all predicted values are NaN, but it
>> predicts well on others.
>> Thanks,
>> Saeed
>> ---
>> model <- naiveBayes(x.train, y.train, laplace = 3)
>> pred <- predict(model,x.test,type="raw")
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ----------------------------------------------------------------------
>> LEGAL NOTICE
>> Unless expressly stated otherwise, this message is confidential and may be privileged.  It is intended for the addressee(s) only.  Access to this E-mail by anyone else is unauthorized.  If you are not an addressee, any disclosure or copying of the contents of this E-mail or any action taken (or not taken) in reliance on it is unauthorized and may be unlawful.  If you are not an addressee, please inform the sender immediately.
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From klaster at karlin.mff.cuni.cz  Tue Jun  5 22:40:36 2007
From: klaster at karlin.mff.cuni.cz (Petr Klasterecky)
Date: Tue, 05 Jun 2007 22:40:36 +0200
Subject: [R] logit model interpretation
In-Reply-To: <10976317.post@talk.nabble.com>
References: <10976317.post@talk.nabble.com>
Message-ID: <4665CA44.3060706@karlin.mff.cuni.cz>

Hi,

this is a standard (logistic) regerssion output and the meaning of 
coefficients and other terms is described in standard textbooks. Applied 
linear statistical models by Neter, Kutner, Nachtsheim & Wassermann is a 
good start to regression in general, (An introduction to) Categorical 
data analysis by Agresti are excellent monographs that cover logistic 
regression as well.

Petr


violeta834 napsal(a):
> Hello everyone
> 
> I appologize for my lack of experience in statistical methods. I am an R
> user begginer and I am running a logit model using "zelig"  and "pcse"
> packages. I will go to the point and is that Im having problems with
> interpreting the results of my models.. It is really simple (I guess for the
> most advanced scholars) however I really dont understand how to interpret
> the coefficients.
> 
> here is my output
> 
> Call:
> zelig(formula = newtrst ~ stfdem + stfgov + clsprty, model = "logit", 
>     data = spadat)
> 
> Deviance Residuals: 
>    Min      1Q  Median      3Q     Max  
> -2.784   0.318   0.410   0.540   1.460  
> 
> Coefficients:
>             Estimate Std. Error z value Pr(>|z|)    
> (Intercept)  -0.6434     0.2427   -2.65    0.008 ** 
> stfdem        0.2447     0.0441    5.55  2.8e-08 ***
> stfgov        0.2050     0.0468    4.38  1.2e-05 ***
> clsprty       0.4173     0.1649    2.53    0.011 *  
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
> 
> (Dispersion parameter for binomial family taken to be 1)
> 
>     Null deviance: 1112.46  on 1427  degrees of freedom
> Residual deviance:  996.02  on 1424  degrees of freedom
> AIC: 1004
> 
> Number of Fisher Scoring iterations: 5
> 
> 
> Thanks
> 
> Vioelta
> 
> 

-- 
Petr Klasterecky
Dept. of Probability and Statistics
Charles University in Prague
Czech Republic


From peter.austin at ices.on.ca  Tue Jun  5 22:07:30 2007
From: peter.austin at ices.on.ca (Austin, Peter)
Date: Tue, 5 Jun 2007 16:07:30 -0400
Subject: [R] R CMD BATCH command
Message-ID: <69E8946004ED8243A9E1554F7401424F01BA2D9C@ices10.ices.on.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070605/87241125/attachment.pl 

From ross at biostat.ucsf.edu  Tue Jun  5 22:49:30 2007
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Tue, 05 Jun 2007 13:49:30 -0700
Subject: [R] ggplot aspect ratio
Message-ID: <1181076570.20244.93.camel@iron.psg.net>

Is there a way to control the aspect ratio of plots using ggplot?
Specifically, I'm using the formula=a~b argument to produce a grid of
plots, but the overall width of the result seems to vary for reasons
that are obscure to me.

This affects not only the appearance of the plots but the amount of
space available for the title (which seems to be right justified
relative to the right edge of the grid).

I've tried tweaking some parameters in the past, but they had no effect
that I could tell.

Perhaps related to that, my previous attempts to use abline to produce a
45 degree angle always produced a flat straight line.

There are also a bunch of other tweaks I want to make to get output
presentation ready.  Is it time to try ggplot2?  I found I could get
results very quickly with ggplot, but am not sure how much control it
gives me over the finer details.

Thanks.
-- 
Ross Boylan                                      wk:  (415) 514-8146
185 Berry St #5700                               ross at biostat.ucsf.edu
Dept of Epidemiology and Biostatistics           fax: (415) 514-8150
University of California, San Francisco
San Francisco, CA 94107-1739                     hm:  (415) 550-1062


From Max.Kuhn at pfizer.com  Tue Jun  5 22:56:48 2007
From: Max.Kuhn at pfizer.com (Kuhn, Max)
Date: Tue, 5 Jun 2007 16:56:48 -0400
Subject: [R] naiveBayes other than e1071
In-Reply-To: <4665BFEC.5070004@statistik.uni-dortmund.de>
Message-ID: <71257D09F114DA4A8E134DEAC70F25D3088F85B2@groamrexm03.amer.pfizer.com>

Saeed and Uwe,

The underlying problem is the distribution of the data. For example:

> table(x.x[,91], y.y)
             y.y
                 0    1
  0.000675027 2412    0
  0.002184892    0  481

When the function tries to estimate the distribution of this feature for
each class, it gets:

   nb$tables[[91]]
            [,1] [,2]
   0 0.000675027    0
   1 0.002184892    0

(Saeed - column 1 contains the means for each class and column 2
contains the variances)
 
For class 0, if a new data point for this variable has a value of
0.000675027, then dnorm(0.000675027, 0.000675027, 0) = Inf (all other
points have density values of zero). When the data are normalized by
p(x), this produces a NaN. A few of the predictors have this problem.

There should probably be some sort of check for this, but that might be
hard to do when usekernel = TRUE. Uwe - do you agree and/or have ideas? 

Good news Saeed! Just use variable 91 and you don't need a model.
Seriously, you might want to think about these data a bit. Many of them
are highly skewed and have a large point mass at zero. Modeling the
conditional probabilities using a normal distribution may not be the
best idea.

Max


-----Original Message-----
From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de] 
Sent: Tuesday, June 05, 2007 3:56 PM
To: Saeed Abu Nimeh
Cc: Kuhn, Max; r-help at stat.math.ethz.ch
Subject: Re: [R] naiveBayes other than e1071



Saeed Abu Nimeh wrote:
> Max,
> Thanks. I have tried it but i keep getting an error:
> Error in as.vector(x, mode) : invalid argument 'mode'
> Do I have to do something specific when using the class column. I
tried
> both  y.y<-as.vector and y.y<-as.factor.
> 
> dread<-read.table('dataset.csv',sep=",")
> x.x<-as.matrix(dread[,2:256])
> y.y<-as.vector(dread[,1])
> nb<- NaiveBayes(x=x.x,grouping=y.y)
> pred.nb<-predict(nb)
> 
> Error in as.vector(x, mode) : invalid argument 'mode'



Please tell us (according to the posting guide): Which version of R? 
Which version of klaR? Example data that reproduce the error?

Uwe Ligges



> Thanks,
> Saeed
> 
> Kuhn, Max wrote:
>> Saeed,
>>
>> There is a version in the klaR package. I recently submitted a change
to
>> the predict function that may be related to your problem. 
>>
>> If:
>>
>>   1. the posterior probabilities (apart from the prior) are being
>> approximated by the product of the p(x_i|y_j) and
>>
>>   2. a lot of predictors are being used
>>
>> then posterior probabilities may have values of absolute zero. 
>>
>> When the approximation is used, the approximate posterior
probabilities
>> are normalized by their sum (which is zero in such cases).
>>
>> The patch in klaR uses the product of the conditional divided by the
>> marginal of x_i (per the true formula). I haven't seen the problem
occur
>> with this patch.
>>
>> HTH,
>>
>> Max
>>
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch
>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Saeed Abu
Nimeh
>> Sent: Monday, June 04, 2007 2:45 PM
>> To: r-help at stat.math.ethz.ch
>> Subject: [R] naiveBayes other than e1071
>>
>> Hi List,
>> Is there a naiveBayes interface other than the one in e1071 package.
For
>> some reason on certain datasets all predicted values are NaN, but it
>> predicts well on others.
>> Thanks,
>> Saeed
>> ---
>> model <- naiveBayes(x.train, y.train, laplace = 3)
>> pred <- predict(model,x.test,type="raw")
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
----------------------------------------------------------------------
>> LEGAL NOTICE
>> Unless expressly stated otherwise, this message is confidential and
may be privileged.  It is intended for the addressee(s) only.  Access to
this E-mail by anyone else is unauthorized.  If you are not an
addressee, any disclosure or copying of the contents of this E-mail or
any action taken (or not taken) in reliance on it is unauthorized and
may be unlawful.  If you are not an addressee, please inform the sender
immediately.
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From p.dalgaard at biostat.ku.dk  Tue Jun  5 23:02:49 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 05 Jun 2007 23:02:49 +0200
Subject: [R] R CMD BATCH command
In-Reply-To: <69E8946004ED8243A9E1554F7401424F01BA2D9C@ices10.ices.on.ca>
References: <69E8946004ED8243A9E1554F7401424F01BA2D9C@ices10.ices.on.ca>
Message-ID: <4665CF79.8010001@biostat.ku.dk>

Austin, Peter wrote:
> The version of R on our unix system has been updated to version 2.5.0.
> When I type the following command at the unix prompt:
>
> 'R CMD BATCH filename'
>
> I receive the following error message:
>
> Error in Sys.unsetenv("R_BATCH") : 'Sys.unsetenv' is not available on
> this system
>
> Execution halted.
>
>  
>
> 'R CMD BATCH filename' used to work with the prior version of R that I
> had installed (version 2.2.0). Is there something that I need to modify
> for it to work now?
>
> Thanks,
>
> Peter
>
>   
A similar problem was found on an old version of Solaris and discussed 
on this very list on May 14 (use the list archive and look for the 
thread started by Simon Penel). This could be similar to your problem 
(but you omitted to tell us what system you were on).


From adschai at optonline.net  Wed Jun  6 02:40:19 2007
From: adschai at optonline.net (adschai at optonline.net)
Date: Wed, 06 Jun 2007 00:40:19 +0000 (GMT)
Subject: [R] Question using stepAIC
In-Reply-To: <46650AE4.9090809@statistik.uni-dortmund.de>
References: <e34b89e428015.4664dc0e@optonline.net>
	<46650AE4.9090809@statistik.uni-dortmund.de>
Message-ID: <f82de56f5415.46660273@optonline.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070606/cc504c42/attachment.pl 

From mpp26 at cam.ac.uk  Wed Jun  6 02:54:35 2007
From: mpp26 at cam.ac.uk (M. P. Papadatos)
Date: Wed, 6 Jun 2007 01:54:35 +0100
Subject: [R] Expand duplicated observations
Message-ID: <961A7379-8726-460D-93FD-85C51CBFACF0@cam.ac.uk>

Dear all,

I am trying to  expand duplicated observations. I need to replace  
each observation in the dataset with n copies of the observation,  
where n is equal to the required expression rounded to the nearest  
integer. If the expression is less than 1 or equal to missing, it is  
interpreted as if it were 1, and the observation is retained but not  
duplicated.

Example

From
c(1,2,3)

To
c(1,2,2,3,3,3)

Thank you in advance.

Best wishes,
Martin


From gerifalte28 at hotmail.com  Wed Jun  6 03:41:48 2007
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Tue, 05 Jun 2007 19:41:48 -0600
Subject: [R] Expand duplicated observations
In-Reply-To: <961A7379-8726-460D-93FD-85C51CBFACF0@cam.ac.uk>
References: <961A7379-8726-460D-93FD-85C51CBFACF0@cam.ac.uk>
Message-ID: <466610DC.70509@hotmail.com>

I think this will do what you want

x=c(1,2,3)
rep(x,x)
[1] 1 2 2 3 3 3

Regards

Francisco

M. P. Papadatos wrote:
> Dear all,
> 
> I am trying to  expand duplicated observations. I need to replace each 
> observation in the dataset with n copies of the observation, where n is 
> equal to the required expression rounded to the nearest integer. If the 
> expression is less than 1 or equal to missing, it is interpreted as if 
> it were 1, and the observation is retained but not duplicated.
> 
> Example
> 
> From
> c(1,2,3)
> 
> To
> c(1,2,2,3,3,3)
> 
> Thank you in advance.
> 
> Best wishes,
> Martin
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gerifalte28 at hotmail.com  Wed Jun  6 03:41:48 2007
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Tue, 05 Jun 2007 19:41:48 -0600
Subject: [R] Expand duplicated observations
In-Reply-To: <961A7379-8726-460D-93FD-85C51CBFACF0@cam.ac.uk>
References: <961A7379-8726-460D-93FD-85C51CBFACF0@cam.ac.uk>
Message-ID: <466610DC.70509@hotmail.com>

I think this will do what you want

x=c(1,2,3)
rep(x,x)
[1] 1 2 2 3 3 3

Regards

Francisco

M. P. Papadatos wrote:
> Dear all,
> 
> I am trying to  expand duplicated observations. I need to replace each 
> observation in the dataset with n copies of the observation, where n is 
> equal to the required expression rounded to the nearest integer. If the 
> expression is less than 1 or equal to missing, it is interpreted as if 
> it were 1, and the observation is retained but not duplicated.
> 
> Example
> 
> From
> c(1,2,3)
> 
> To
> c(1,2,2,3,3,3)
> 
> Thank you in advance.
> 
> Best wishes,
> Martin
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From s.blomberg1 at uq.edu.au  Wed Jun  6 03:44:39 2007
From: s.blomberg1 at uq.edu.au (Simon Blomberg)
Date: Wed, 06 Jun 2007 11:44:39 +1000
Subject: [R] Expand duplicated observations
In-Reply-To: <961A7379-8726-460D-93FD-85C51CBFACF0@cam.ac.uk>
References: <961A7379-8726-460D-93FD-85C51CBFACF0@cam.ac.uk>
Message-ID: <1181094279.9328.7.camel@sib-sblomber01d.sib.uq.edu.au>

Does this do what you want?

dat <- c(NA, 0, 3.2, 4)

fn <- function (x) {
z <- round(x)
if (is.na(x) | x <= 1) z else rep(z, each=z)
}

unlist(sapply(dat, fn))

[1] NA  0  3  3  3  4  4  4  4

HTH,

Simon.

On Wed, 2007-06-06 at 01:54 +0100, M. P. Papadatos wrote:
> Dear all,
> 
> I am trying to  expand duplicated observations. I need to replace  
> each observation in the dataset with n copies of the observation,  
> where n is equal to the required expression rounded to the nearest  
> integer. If the expression is less than 1 or equal to missing, it is  
> interpreted as if it were 1, and the observation is retained but not  
> duplicated.
> 
> Example
> 
> From
> c(1,2,3)
> 
> To
> c(1,2,2,3,3,3)
> 
> Thank you in advance.
> 
> Best wishes,
> Martin
> 
> 
> --Apple-Mail-4-920612661--
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
-- 
Simon Blomberg, BSc (Hons), PhD, MAppStat. 
Lecturer and Consultant Statistician 
Faculty of Biological and Chemical Sciences 
The University of Queensland 
St. Lucia Queensland 4072 
Australia

Room 320, Goddard Building (8)
T: +61 7 3365 2506 
email: S.Blomberg1_at_uq.edu.au 

The combination of some data and an aching desire for 
an answer does not ensure that a reasonable answer can 
be extracted from a given body of data. - John Tukey.


From jared.oconnell at csiro.au  Wed Jun  6 03:59:11 2007
From: jared.oconnell at csiro.au (Jared O'Connell)
Date: Wed, 6 Jun 2007 09:59:11 +0800
Subject: [R] Expand duplicated observations
In-Reply-To: <466610DC.70509@hotmail.com>
References: <961A7379-8726-460D-93FD-85C51CBFACF0@cam.ac.uk>
	<466610DC.70509@hotmail.com>
Message-ID: <8c464e8f0706051859h45de9720nae350b63af4a8789@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070606/1c03644a/attachment.pl 

From pwang at berkeley.edu  Wed Jun  6 03:59:46 2007
From: pwang at berkeley.edu (Patrick Wang)
Date: Tue, 5 Jun 2007 18:59:46 -0700 (PDT)
Subject: [R] kernel smooth for tw-dimensional data
Message-ID: <50327.76.169.69.87.1181095186.squirrel@calmail.berkeley.edu>

Hi all:

I can use the density() function to get the kernel density for given
observed data X with bandwidth.

Is there a function in R that can take in two dimensional data(x, y) and
return a joint density based
on the bandwidth. Do I need to provide bandwith for x and then for y?

Is the GRASS package
kde2d.G(x, y, h, G, reverse=reverse(G))

provide such function?

Thanks
pat


From jared.oconnell at csiro.au  Wed Jun  6 04:00:54 2007
From: jared.oconnell at csiro.au (Jared O'Connell)
Date: Wed, 6 Jun 2007 10:00:54 +0800
Subject: [R] Expand duplicated observations
In-Reply-To: <8c464e8f0706051859h45de9720nae350b63af4a8789@mail.gmail.com>
References: <961A7379-8726-460D-93FD-85C51CBFACF0@cam.ac.uk>
	<466610DC.70509@hotmail.com>
	<8c464e8f0706051859h45de9720nae350b63af4a8789@mail.gmail.com>
Message-ID: <8c464e8f0706051900s8b1dfc0n564278845301ded1@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070606/b9e514bf/attachment.pl 

From toby909 at gmail.com  Wed Jun  6 04:11:17 2007
From: toby909 at gmail.com (toby909 at gmail.com)
Date: Tue, 05 Jun 2007 19:11:17 -0700
Subject: [R] fixed effects anova in lme lmer
Message-ID: <f454vp$47d$1@sea.gmane.org>

Can lme or lmer fit a plain regular fixed effects anova? Ie a model without a 
random effect, or have there be at least one random effect in order for these 
functions to work?

Trying to run such, (1) without specifying a random effect produces an error, 
(2) specifying that there is no random effect does not produce the same output 
as  an anova run in lm(); (2b) specifying that there is no random effect in lmer 
crashed R (division by zero, I think).

Just trying to see the connection of fixed and random effects anova in R. STATA 
gives me same results for both models up to the point where they differ.

Best Toby





dt1 = 
as.data.frame(cbind(c(28,35,27,21,21,36,25,18,26,38,27,17,16,25,22,18),c(1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4)))

summary(a1 <- lm(V1~factor(V2)-1, dt1))
anova(a1)

summary(a1 <- lm(V1~factor(V2), dt1))
anova(a1)

dt1$f = factor(dt1$V2)

summary(a2 <- lme(V1~f, dt1))   #1a

summary(a2 <- lme(V1~f, dt1, ~-1|f))   #2a
anova(a2)

lmer(V1~f, dt1)   #1b

lmer(V1~f+(-1|f), dt1)   #2b


From s.blomberg1 at uq.edu.au  Wed Jun  6 04:19:26 2007
From: s.blomberg1 at uq.edu.au (Simon Blomberg)
Date: Wed, 06 Jun 2007 12:19:26 +1000
Subject: [R] Expand duplicated observations
In-Reply-To: <8c464e8f0706051859h45de9720nae350b63af4a8789@mail.gmail.com>
References: <961A7379-8726-460D-93FD-85C51CBFACF0@cam.ac.uk>
	<466610DC.70509@hotmail.com>
	<8c464e8f0706051859h45de9720nae350b63af4a8789@mail.gmail.com>
Message-ID: <1181096366.9328.14.camel@sib-sblomber01d.sib.uq.edu.au>

D'Oh!

yet again my first inclination is to write something complicated when a
little thought shows a short, neat solution. Ah, well, I live and learn.

Cheers,

Simon.

On Wed, 2007-06-06 at 09:59 +0800, Jared O'Connell wrote:
> Also, to handle NAs and non-integers:
> 
> > x = c(1:3,9.4,NA)
> > tmp = round(x)
> > tmp[is.na(tmp)]=1
> > rep(x,tmp)
>  [1] 1.0 2.0 2.0 3.0 3.0 3.0 9.4 9.4 9.4 9.4 9.4 9.4 9.4 9.4 9.4  NA
> 
> 
> On 6/6/07, Francisco J. Zagmutt <gerifalte28 at hotmail.com> wrote:
> >
> > I think this will do what you want
> >
> > x=c(1,2,3)
> > rep(x,x)
> > [1] 1 2 2 3 3 3
> >
> > Regards
> >
> > Francisco
> >
> > M. P. Papadatos wrote:
> > > Dear all,
> > >
> > > I am trying to  expand duplicated observations. I need to replace each
> > > observation in the dataset with n copies of the observation, where n is
> > > equal to the required expression rounded to the nearest integer. If the
> > > expression is less than 1 or equal to missing, it is interpreted as if
> > > it were 1, and the observation is retained but not duplicated.
> > >
> > > Example
> > >
> > > From
> > > c(1,2,3)
> > >
> > > To
> > > c(1,2,2,3,3,3)
> > >
> > > Thank you in advance.
> > >
> > > Best wishes,
> > > Martin
> > >
> > >
> > > ------------------------------------------------------------------------
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
-- 
Simon Blomberg, BSc (Hons), PhD, MAppStat. 
Lecturer and Consultant Statistician 
Faculty of Biological and Chemical Sciences 
The University of Queensland 
St. Lucia Queensland 4072 
Australia

Room 320, Goddard Building (8)
T: +61 7 3365 2506 
email: S.Blomberg1_at_uq.edu.au 

The combination of some data and an aching desire for 
an answer does not ensure that a reasonable answer can 
be extracted from a given body of data. - John Tukey.


From s.blomberg1 at uq.edu.au  Wed Jun  6 04:23:43 2007
From: s.blomberg1 at uq.edu.au (Simon Blomberg)
Date: Wed, 06 Jun 2007 12:23:43 +1000
Subject: [R] fixed effects anova in lme lmer
In-Reply-To: <f454vp$47d$1@sea.gmane.org>
References: <f454vp$47d$1@sea.gmane.org>
Message-ID: <1181096623.9328.19.camel@sib-sblomber01d.sib.uq.edu.au>

?gls in package nlme. It's like lme but with no random effects. But you
can still model the variance-covariance properties of the data.

Simon.

On Tue, 2007-06-05 at 19:11 -0700, toby909 at gmail.com wrote:
> Can lme or lmer fit a plain regular fixed effects anova? Ie a model without a 
> random effect, or have there be at least one random effect in order for these 
> functions to work?
> 
> Trying to run such, (1) without specifying a random effect produces an error, 
> (2) specifying that there is no random effect does not produce the same output 
> as  an anova run in lm(); (2b) specifying that there is no random effect in lmer 
> crashed R (division by zero, I think).
> 
> Just trying to see the connection of fixed and random effects anova in R. STATA 
> gives me same results for both models up to the point where they differ.
> 
> Best Toby
> 
> 
> 
> 
> 
> dt1 = 
> as.data.frame(cbind(c(28,35,27,21,21,36,25,18,26,38,27,17,16,25,22,18),c(1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4)))
> 
> summary(a1 <- lm(V1~factor(V2)-1, dt1))
> anova(a1)
> 
> summary(a1 <- lm(V1~factor(V2), dt1))
> anova(a1)
> 
> dt1$f = factor(dt1$V2)
> 
> summary(a2 <- lme(V1~f, dt1))   #1a
> 
> summary(a2 <- lme(V1~f, dt1, ~-1|f))   #2a
> anova(a2)
> 
> lmer(V1~f, dt1)   #1b
> 
> lmer(V1~f+(-1|f), dt1)   #2b
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
-- 
Simon Blomberg, BSc (Hons), PhD, MAppStat. 
Lecturer and Consultant Statistician 
Faculty of Biological and Chemical Sciences 
The University of Queensland 
St. Lucia Queensland 4072 
Australia

Room 320, Goddard Building (8)
T: +61 7 3365 2506 
email: S.Blomberg1_at_uq.edu.au 

The combination of some data and an aching desire for 
an answer does not ensure that a reasonable answer can 
be extracted from a given body of data. - John Tukey.


From adschai at optonline.net  Wed Jun  6 04:24:38 2007
From: adschai at optonline.net (adschai at optonline.net)
Date: Wed, 06 Jun 2007 02:24:38 +0000 (GMT)
Subject: [R] Question about Johansen result
Message-ID: <e7da9b3253dc.46661ae6@optonline.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070606/78d22d71/attachment.pl 

From pwang at berkeley.edu  Wed Jun  6 05:33:03 2007
From: pwang at berkeley.edu (Patrick Wang)
Date: Tue, 5 Jun 2007 20:33:03 -0700 (PDT)
Subject: [R] kernel smooth for tw-dimensional data
In-Reply-To: <50327.76.169.69.87.1181095186.squirrel@calmail.berkeley.edu>
References: <50327.76.169.69.87.1181095186.squirrel@calmail.berkeley.edu>
Message-ID: <50472.76.169.69.87.1181100783.squirrel@calmail.berkeley.edu>

Hi, I found kde2d in the MASS packages return densities for the bivariate
random varaibles.

I donot understand why each element of density Z is a 2*2 matrix.
Why it is not a number.

For example, a bivariate normula distribution given (x, y) will return a
number, the density, not a matrix.

Thanks
Pat


> Hi all:
>
> I can use the density() function to get the kernel density for given
> observed data X with bandwidth.
>
> Is there a function in R that can take in two dimensional data(x, y) and
> return a joint density based
> on the bandwidth. Do I need to provide bandwith for x and then for y?
>
> Is the GRASS package
> kde2d.G(x, y, h, G, reverse=reverse(G))
>
> provide such function?
>
> Thanks
> pat
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From gerifalte28 at hotmail.com  Wed Jun  6 06:26:30 2007
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Tue, 05 Jun 2007 22:26:30 -0600
Subject: [R] the biggest integer R can display in complete form but not
 scientific form
In-Reply-To: <46658CC7.2030107@gmail.com>
References: <dff718fc0706050802sb21befr30a132494df1bfcd@mail.gmail.com>
	<46658CC7.2030107@gmail.com>
Message-ID: <46663776.5080707@hotmail.com>

Also, look at options(digits) to set the number digits to be printed in 
the console, i.e.

 > pi
[1] 3.141593

 > options(digits=22)
 > pi
[1] 3.141592653589793
	

Regards

Francisco


Roland Rau wrote:
> ??? wrote:
>> Dear R-lister,
>>
>> One of my friends wanted to produce random number which is 64 bits. He did
>> it with Fortune. I think R can do it also. But I don't know how to display a
>> very big integer in the complete form but not scientific form. And what's
>> the biggest integer R can display in complete form ?
>>
>> Thanks in advance,
>>
>> Li Junjie
>>
>>
>>
> I guess the biggest integer R can represent (if this is what you mean) 
> is machine dependent and you can find it out via:
> 
> .Machine
> help(".Machine")
> 
> I hope this helps,
> Roland
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gerifalte28 at hotmail.com  Wed Jun  6 06:26:30 2007
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Tue, 05 Jun 2007 22:26:30 -0600
Subject: [R] the biggest integer R can display in complete form but not
 scientific form
In-Reply-To: <46658CC7.2030107@gmail.com>
References: <dff718fc0706050802sb21befr30a132494df1bfcd@mail.gmail.com>
	<46658CC7.2030107@gmail.com>
Message-ID: <46663776.5080707@hotmail.com>

Also, look at options(digits) to set the number digits to be printed in 
the console, i.e.

 > pi
[1] 3.141593

 > options(digits=22)
 > pi
[1] 3.141592653589793
	

Regards

Francisco


Roland Rau wrote:
> ??? wrote:
>> Dear R-lister,
>>
>> One of my friends wanted to produce random number which is 64 bits. He did
>> it with Fortune. I think R can do it also. But I don't know how to display a
>> very big integer in the complete form but not scientific form. And what's
>> the biggest integer R can display in complete form ?
>>
>> Thanks in advance,
>>
>> Li Junjie
>>
>>
>>
> I guess the biggest integer R can represent (if this is what you mean) 
> is machine dependent and you can find it out via:
> 
> .Machine
> help(".Machine")
> 
> I hope this helps,
> Roland
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From h.wickham at gmail.com  Wed Jun  6 07:12:00 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Wed, 6 Jun 2007 07:12:00 +0200
Subject: [R] ggplot aspect ratio
In-Reply-To: <1181076570.20244.93.camel@iron.psg.net>
References: <1181076570.20244.93.camel@iron.psg.net>
Message-ID: <f8e6ff050706052212u7af78eb0pc805be82d7111ab6@mail.gmail.com>

Hi Ross,

In brief, you can use ggopt(aspect.ratio = 1) or p$aspect.ratio <- 1
to set the aspect ratio for all plots, or for a single plot
respectively.  There are a few example of this at
http://had.co.nz/ggplot2/coord_equal.html

I am also preparing a chapter for the ggplot book which will discuss
this, as well as more general details of customising absolutely every
aspect of ggplot2 with grid.  I hope to have this out by the end of
the week - I'll probably send another anouncement to R packages when
this is ready.

You should be able to start using ggplot2 with very little effort,
especially if you have been using qplot a lot.

Hadley

On 6/5/07, Ross Boylan <ross at biostat.ucsf.edu> wrote:
> Is there a way to control the aspect ratio of plots using ggplot?
> Specifically, I'm using the formula=a~b argument to produce a grid of
> plots, but the overall width of the result seems to vary for reasons
> that are obscure to me.
>
> This affects not only the appearance of the plots but the amount of
> space available for the title (which seems to be right justified
> relative to the right edge of the grid).
>
> I've tried tweaking some parameters in the past, but they had no effect
> that I could tell.
>
> Perhaps related to that, my previous attempts to use abline to produce a
> 45 degree angle always produced a flat straight line.
>
> There are also a bunch of other tweaks I want to make to get output
> presentation ready.  Is it time to try ggplot2?  I found I could get
> results very quickly with ggplot, but am not sure how much control it
> gives me over the finer details.
>
> Thanks.
> --
> Ross Boylan                                      wk:  (415) 514-8146
> 185 Berry St #5700                               ross at biostat.ucsf.edu
> Dept of Epidemiology and Biostatistics           fax: (415) 514-8150
> University of California, San Francisco
> San Francisco, CA 94107-1739                     hm:  (415) 550-1062
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Roger.Bivand at nhh.no  Wed Jun  6 07:36:14 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 6 Jun 2007 07:36:14 +0200 (CEST)
Subject: [R] kernel smooth for tw-dimensional data
In-Reply-To: <50472.76.169.69.87.1181100783.squirrel@calmail.berkeley.edu>
Message-ID: <Pine.LNX.4.44.0706060733190.16522-100000@reclus.nhh.no>

On Tue, 5 Jun 2007, Patrick Wang wrote:

> Hi, I found kde2d in the MASS packages return densities for the bivariate
> random varaibles.
> 
> I donot understand why each element of density Z is a 2*2 matrix.
> Why it is not a number.
> 
> For example, a bivariate normula distribution given (x, y) will return a
> number, the density, not a matrix.

I think you were asking these questions last week: 

library(mvtnorm) 
?dmvnorm

not 2D kernel *density* (the word is perhaps overloaded).

However, kde2d() *is* a 2D density(), so maybe you need to consider what 
you are looking for.

> 
> Thanks
> Pat
> 
> 
> > Hi all:
> >
> > I can use the density() function to get the kernel density for given
> > observed data X with bandwidth.
> >
> > Is there a function in R that can take in two dimensional data(x, y) and
> > return a joint density based
> > on the bandwidth. Do I need to provide bandwith for x and then for y?
> >
> > Is the GRASS package
> > kde2d.G(x, y, h, G, reverse=reverse(G))
> >
> > provide such function?
> >
> > Thanks
> > pat
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From ripley at stats.ox.ac.uk  Wed Jun  6 08:32:40 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 6 Jun 2007 07:32:40 +0100 (BST)
Subject: [R] R CMD BATCH command
In-Reply-To: <4665CF79.8010001@biostat.ku.dk>
References: <69E8946004ED8243A9E1554F7401424F01BA2D9C@ices10.ices.on.ca>
	<4665CF79.8010001@biostat.ku.dk>
Message-ID: <Pine.LNX.4.64.0706060731370.5261@gannet.stats.ox.ac.uk>

On Tue, 5 Jun 2007, Peter Dalgaard wrote:

> Austin, Peter wrote:
>> The version of R on our unix system has been updated to version 2.5.0.
>> When I type the following command at the unix prompt:
>>
>> 'R CMD BATCH filename'
>>
>> I receive the following error message:
>>
>> Error in Sys.unsetenv("R_BATCH") : 'Sys.unsetenv' is not available on
>> this system
>>
>> Execution halted.
>>
>>
>>
>> 'R CMD BATCH filename' used to work with the prior version of R that I
>> had installed (version 2.2.0). Is there something that I need to modify
>> for it to work now?
>>
>> Thanks,
>>
>> Peter
>>
>>
> A similar problem was found on an old version of Solaris and discussed
> on this very list on May 14 (use the list archive and look for the
> thread started by Simon Penel). This could be similar to your problem
> (but you omitted to tell us what system you were on).

And that problem has been fixed in R-patched, so please try R-patched.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From artem.mariupol at gmail.com  Wed Jun  6 08:45:24 2007
From: artem.mariupol at gmail.com (Artem Mariupol)
Date: Wed, 6 Jun 2007 09:45:24 +0300
Subject: [R] correspondence analysis
Message-ID: <bfb35b70706052345t1d40bf88l48942296d9d5ea68@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070606/ccfb9a85/attachment.pl 

From singularitaet at gmx.net  Wed Jun  6 09:30:16 2007
From: singularitaet at gmx.net (Stefan Grosse)
Date: Wed, 06 Jun 2007 09:30:16 +0200
Subject: [R] rJava installation under linux: configuration failed
In-Reply-To: <BAY110-F40EEFEF56E9A5E0AA777BDC7200@phx.gbl>
References: <BAY110-F40EEFEF56E9A5E0AA777BDC7200@phx.gbl>
Message-ID: <46666288.9050309@gmx.net>

Which java have you installed? ( java -version )

You need a Sun Java and better is a 1.5 series Java, JGR seems to have
some problem with the new 1.6 series. And you need the JDK, not the JRE.

You can google how to do those installations on suse linux.

Stefan

-------- Original Message --------
Subject: [R] rJava installation under linux: configuration failed
From: zhihua li <lzhtom at hotmail.com>
To: r-help at stat.math.ethz.ch
Date: 05.06.2007 19:55
> Hi netter,
>
> Recently I was trying to install rJava. The operating system is suse
> 10.0, and the R versionis 2.5.0.
>
> Following the instructions of R Wiki for rJava, I did configuration
> first: R CMD javareconf
>
> and then it showed a series of information, from what it seems that
> java is in the system and the configuration succeeded.
>
> Then I tried to install rJava:
> install.packages("rJava")
>
> following which rJava was downloaded and being installed, but during
> the last test step it said: can't complie a simple JNL program.
> Configuration Failed!
>
> Did I do something wrong? Or there's something I should do that I didn't?
>
> Thanks a lot!
>
>
> Sincerely Yours: Zhihua Li
>
> ------------------------------------------------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   
> ------------------------------------------------------------------------
>
> No virus found in this incoming message.
> Checked by AVG Free Edition. 
> Version: 7.5.472 / Virus Database: 269.8.9/834 - Release Date: 05.06.2007 14:38
>


From Laurence.Amilhat at toulouse.inra.fr  Wed Jun  6 09:39:44 2007
From: Laurence.Amilhat at toulouse.inra.fr (Laurence Amilhat)
Date: Wed, 06 Jun 2007 09:39:44 +0200
Subject: [R] multiple plot in odfWeave
In-Reply-To: <71257D09F114DA4A8E134DEAC70F25D3088F80AD@groamrexm03.amer.pfizer.com>
References: <71257D09F114DA4A8E134DEAC70F25D3088F80AD@groamrexm03.amer.pfizer.com>
Message-ID: <466664C0.2000808@toulouse.inra.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070606/fd7dbcb0/attachment.pl 

From Laurence.Amilhat at toulouse.inra.fr  Wed Jun  6 09:41:55 2007
From: Laurence.Amilhat at toulouse.inra.fr (Laurence Amilhat)
Date: Wed, 06 Jun 2007 09:41:55 +0200
Subject: [R] odfTable
In-Reply-To: <71257D09F114DA4A8E134DEAC70F25D3088F80FB@groamrexm03.amer.pfizer.com>
References: <71257D09F114DA4A8E134DEAC70F25D3088F80FB@groamrexm03.amer.pfizer.com>
Message-ID: <46666543.1050202@toulouse.inra.fr>

Great,

I will waiting for the new version... with the nice documentation!

thank you,

Laurence.


Kuhn, Max a ?crit :
> Sarah and Laurence,
>
> A few comments:
>
>   1. The default background color for columns is horrible. I've changed
> to white it in the upcoming version.
>
>   2. In the next version (in 1-2 weeks), I have a fairly long document
> that goes into much more detail about the specific styles that can be
> changed and examples.
>
>   3. To simply Sarah's approach, add the style definition via
> setStyleDefs(existingStyles) as suggested. Then, just before making the
> table, simply use
>
> current <- getStyles()
> currrent$header <- "newStyle1"
> setStyles(current)
>
>      then produce the table. Unless I'm not understanding what you want,
> you shouldn't need to use tableStyles.
>
> If anyone wants the new version while I finish a few of the
> documentation pages, send me an email off-list and I'll send it to you.
>
> Thanks,
>
> Max
>
> ----------------------------------------------------------------------
> LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   


-- 
====================================================================
= Laurence Amilhat    INRA Toulouse 31326 Castanet-Tolosan     	   = 
= Tel: 33 5 61 28 53 34   Email: laurence.amilhat at toulouse.inra.fr =


From ripley at stats.ox.ac.uk  Wed Jun  6 10:10:50 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 6 Jun 2007 09:10:50 +0100 (BST)
Subject: [R] rJava installation under linux: configuration failed
In-Reply-To: <46666288.9050309@gmx.net>
References: <BAY110-F40EEFEF56E9A5E0AA777BDC7200@phx.gbl>
	<46666288.9050309@gmx.net>
Message-ID: <Pine.LNX.4.64.0706060905030.962@gannet.stats.ox.ac.uk>

On Wed, 6 Jun 2007, Stefan Grosse wrote:

> Which java have you installed? ( java -version )
>
> You need a Sun Java and better is a 1.5 series Java, JGR seems to have
> some problem with the new 1.6 series. And you need the JDK, not the JRE.

Precautionary note: the '1.5 series Java' (aka Java 5) does not work with 
JNI (and hence rJava) on some platforms, including AMD64 Linux.

> You can google how to do those installations on suse linux.

It can be tricky, especially if you need a later Java than your OS version 
supports.

>
> Stefan
>
> -------- Original Message --------
> Subject: [R] rJava installation under linux: configuration failed
> From: zhihua li <lzhtom at hotmail.com>
> To: r-help at stat.math.ethz.ch
> Date: 05.06.2007 19:55
>> Hi netter,
>>
>> Recently I was trying to install rJava. The operating system is suse
>> 10.0, and the R versionis 2.5.0.
>>
>> Following the instructions of R Wiki for rJava, I did configuration
>> first: R CMD javareconf
>>
>> and then it showed a series of information, from what it seems that
>> java is in the system and the configuration succeeded.
>>
>> Then I tried to install rJava:
>> install.packages("rJava")
>>
>> following which rJava was downloaded and being installed, but during
>> the last test step it said: can't complie a simple JNL program.
>> Configuration Failed!
>>
>> Did I do something wrong? Or there's something I should do that I didn't?
>>
>> Thanks a lot!
>>
>>
>> Sincerely Yours: Zhihua Li
>>
>> ------------------------------------------------------------------------
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ------------------------------------------------------------------------
>>
>> No virus found in this incoming message.
>> Checked by AVG Free Edition.
>> Version: 7.5.472 / Virus Database: 269.8.9/834 - Release Date: 05.06.2007 14:38
>>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jessica.gervais at tudor.lu  Wed Jun  6 10:21:03 2007
From: jessica.gervais at tudor.lu (jessica.gervais at tudor.lu)
Date: Wed, 6 Jun 2007 10:21:03 +0200
Subject: [R] spgrass6 and aggregation
Message-ID: <OFCA8716E3.70F3EBE5-ONC12572F2.002DDF9A-C12572F2.002DDFB3@tudor.lu>


Dear all,


I am exporting grass map into R thanks to the very useful spgrass6 package.

library(spgrass6)

# I have 3 map I am working with a MASK map of a specific area.

# 1) a landuse map
landuse<-readRAST6("landuse_mapname_in_grass")

# 2) a catchment map which divide the area in several catchements
catchment<-readRAST6("catchement_mapname_in_grass")

# 3) a precipitation map
precipitation<-readRAST6("precipitation_mapname_in_grass")


# then I would like to sum the precipitation spatialy over each catchment
and landuse. So, first I cbind all maps with cbind

MAP<-cbind(Dear all,


From singularitaet at gmx.net  Wed Jun  6 10:34:43 2007
From: singularitaet at gmx.net (Stefan Grosse)
Date: Wed, 06 Jun 2007 10:34:43 +0200
Subject: [R] rJava installation under linux: configuration failed
In-Reply-To: <Pine.LNX.4.64.0706060905030.962@gannet.stats.ox.ac.uk>
References: <BAY110-F40EEFEF56E9A5E0AA777BDC7200@phx.gbl>
	<46666288.9050309@gmx.net>
	<Pine.LNX.4.64.0706060905030.962@gannet.stats.ox.ac.uk>
Message-ID: <466671A3.3030509@gmx.net>


>
> Precautionary note: the '1.5 series Java' (aka Java 5) does not work
> with JNI (and hence rJava) on some platforms, including AMD64 Linux.
>
>> You can google how to do those installations on suse linux.
>
> It can be tricky, especially if you need a later Java than your OS
> version supports.
>
Since the Suse Version is 10.0 there is an installation repository
provided by Suse:

http://download.opensuse.org/distribution/SL-10.0-OSS/inst-source-java/

you can add that via Yast and this should then provide Java 5 JDK.
(provided that you are on the correct platform ...)


From Corinna.Schmitt at igb.fraunhofer.de  Wed Jun  6 10:41:45 2007
From: Corinna.Schmitt at igb.fraunhofer.de (Schmitt, Corinna)
Date: Wed, 6 Jun 2007 10:41:45 +0200
Subject: [R] opening vignetten
Message-ID: <8B7B0FD99E8AF541A21609104D196158BBA2FD@izs-xchg01.izs.fraunhofer.de>

Dear R-Users,

I have a quite stupid question. I load the GO-package with the command
require(GO). Now I want to read the corresponding vignetten but I forgot
the command for opening it.

Please help me, Corinna


From rmi at danishmeat.dk  Wed Jun  6 10:56:18 2007
From: rmi at danishmeat.dk (Rina Miehs)
Date: Wed, 06 Jun 2007 10:56:18 +0200
Subject: [R] Svar: Re:  help with simple R-question
In-Reply-To: <138529.2759.qm@web32805.mail.mud.yahoo.com>
References: <46654A1F.76E3.003F.0@danishmeat.dk>
	<138529.2759.qm@web32805.mail.mud.yahoo.com>
Message-ID: <466692D1.76E3.003F.0@danishmeat.dk>

En indlejret tekst med ukendt tegns?t er blevet fjernet...
Navn: ikke tilg?ngelig
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070606/98252804/attachment.pl 

From elyakhlifi_mustapha at yahoo.fr  Wed Jun  6 10:58:51 2007
From: elyakhlifi_mustapha at yahoo.fr (elyakhlifi mustapha)
Date: Wed, 6 Jun 2007 08:58:51 +0000 (GMT)
Subject: [R] list
Message-ID: <20070606085851.23326.qmail@web27503.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070606/16b59c9f/attachment.pl 

From ligges at statistik.uni-dortmund.de  Wed Jun  6 11:03:05 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 06 Jun 2007 11:03:05 +0200
Subject: [R] naiveBayes other than e1071
In-Reply-To: <71257D09F114DA4A8E134DEAC70F25D3088F85B2@groamrexm03.amer.pfizer.com>
References: <71257D09F114DA4A8E134DEAC70F25D3088F85B2@groamrexm03.amer.pfizer.com>
Message-ID: <46667849.8080708@statistik.uni-dortmund.de>

Dear Max,

thanks for your work on this!
I totally agree in all points and have added some check for zero 
variances to my working copy of NaiveBayes.default() which will be 
published in the next klaR release.

   if(!usekernel){
     temp <- apply(sapply(tables, function(x) x[,2]), 2,
                   function(x) any(!x))
     if(any(temp))
       stop("Zero variances for at least one class in variables: ",
            paste(names(tables)[temp], collapse=", "))
   }


Thanks again,
Uwe




Kuhn, Max wrote:
> Saeed and Uwe,
> 
> The underlying problem is the distribution of the data. For example:
> 
>> table(x.x[,91], y.y)
>              y.y
>                  0    1
>   0.000675027 2412    0
>   0.002184892    0  481
> 
> When the function tries to estimate the distribution of this feature for
> each class, it gets:
> 
>    nb$tables[[91]]
>             [,1] [,2]
>    0 0.000675027    0
>    1 0.002184892    0
> 
> (Saeed - column 1 contains the means for each class and column 2
> contains the variances)
>  
> For class 0, if a new data point for this variable has a value of
> 0.000675027, then dnorm(0.000675027, 0.000675027, 0) = Inf (all other
> points have density values of zero). When the data are normalized by
> p(x), this produces a NaN. A few of the predictors have this problem.
> 
> There should probably be some sort of check for this, but that might be
> hard to do when usekernel = TRUE. Uwe - do you agree and/or have ideas? 
> 
> Good news Saeed! Just use variable 91 and you don't need a model.
> Seriously, you might want to think about these data a bit. Many of them
> are highly skewed and have a large point mass at zero. Modeling the
> conditional probabilities using a normal distribution may not be the
> best idea.
> 
> Max
> 
> 
> -----Original Message-----
> From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de] 
> Sent: Tuesday, June 05, 2007 3:56 PM
> To: Saeed Abu Nimeh
> Cc: Kuhn, Max; r-help at stat.math.ethz.ch
> Subject: Re: [R] naiveBayes other than e1071
> 
> 
> 
> Saeed Abu Nimeh wrote:
>> Max,
>> Thanks. I have tried it but i keep getting an error:
>> Error in as.vector(x, mode) : invalid argument 'mode'
>> Do I have to do something specific when using the class column. I
> tried
>> both  y.y<-as.vector and y.y<-as.factor.
>>
>> dread<-read.table('dataset.csv',sep=",")
>> x.x<-as.matrix(dread[,2:256])
>> y.y<-as.vector(dread[,1])
>> nb<- NaiveBayes(x=x.x,grouping=y.y)
>> pred.nb<-predict(nb)
>>
>> Error in as.vector(x, mode) : invalid argument 'mode'
> 
> 
> 
> Please tell us (according to the posting guide): Which version of R? 
> Which version of klaR? Example data that reproduce the error?
> 
> Uwe Ligges
> 
> 
> 
>> Thanks,
>> Saeed
>>
>> Kuhn, Max wrote:
>>> Saeed,
>>>
>>> There is a version in the klaR package. I recently submitted a change
> to
>>> the predict function that may be related to your problem. 
>>>
>>> If:
>>>
>>>   1. the posterior probabilities (apart from the prior) are being
>>> approximated by the product of the p(x_i|y_j) and
>>>
>>>   2. a lot of predictors are being used
>>>
>>> then posterior probabilities may have values of absolute zero. 
>>>
>>> When the approximation is used, the approximate posterior
> probabilities
>>> are normalized by their sum (which is zero in such cases).
>>>
>>> The patch in klaR uses the product of the conditional divided by the
>>> marginal of x_i (per the true formula). I haven't seen the problem
> occur
>>> with this patch.
>>>
>>> HTH,
>>>
>>> Max
>>>
>>> -----Original Message-----
>>> From: r-help-bounces at stat.math.ethz.ch
>>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Saeed Abu
> Nimeh
>>> Sent: Monday, June 04, 2007 2:45 PM
>>> To: r-help at stat.math.ethz.ch
>>> Subject: [R] naiveBayes other than e1071
>>>
>>> Hi List,
>>> Is there a naiveBayes interface other than the one in e1071 package.
> For
>>> some reason on certain datasets all predicted values are NaN, but it
>>> predicts well on others.
>>> Thanks,
>>> Saeed
>>> ---
>>> model <- naiveBayes(x.train, y.train, laplace = 3)
>>> pred <- predict(model,x.test,type="raw")
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
> ----------------------------------------------------------------------
>>> LEGAL NOTICE
>>> Unless expressly stated otherwise, this message is confidential and
> may be privileged.  It is intended for the addressee(s) only.  Access to
> this E-mail by anyone else is unauthorized.  If you are not an
> addressee, any disclosure or copying of the contents of this E-mail or
> any action taken (or not taken) in reliance on it is unauthorized and
> may be unlawful.  If you are not an addressee, please inform the sender
> immediately.
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From singularitaet at gmx.net  Wed Jun  6 11:15:52 2007
From: singularitaet at gmx.net (Stefan Grosse)
Date: Wed, 06 Jun 2007 11:15:52 +0200
Subject: [R] opening vignetten
In-Reply-To: <8B7B0FD99E8AF541A21609104D196158BBA2FD@izs-xchg01.izs.fraunhofer.de>
References: <8B7B0FD99E8AF541A21609104D196158BBA2FD@izs-xchg01.izs.fraunhofer.de>
Message-ID: <46667B48.3070009@gmx.net>


?vignette


-------- Original Message  --------
Subject: [R] opening vignetten
From: Schmitt, Corinna <Corinna.Schmitt at igb.fraunhofer.de>
To: r-help at stat.math.ethz.ch
Date: 06.06.2007 10:41
> Dear R-Users,
>
> I have a quite stupid question. I load the GO-package with the command
> require(GO). Now I want to read the corresponding vignetten but I forgot
> the command for opening it.
>
> Please help me, Corinna
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>


From mothsailor at googlemail.com  Wed Jun  6 11:30:35 2007
From: mothsailor at googlemail.com (David Barron)
Date: Wed, 6 Jun 2007 10:30:35 +0100
Subject: [R] list
In-Reply-To: <20070606085851.23326.qmail@web27503.mail.ukl.yahoo.com>
References: <20070606085851.23326.qmail@web27503.mail.ukl.yahoo.com>
Message-ID: <815b70590706060230v411fde98p8d821e0b21905283@mail.gmail.com>

There's no special method, just create a list in the usual way.  For example:

> l1<-list(a=letters[1:5],b=letters[6:10])
> l1
$a
[1] "a" "b" "c" "d" "e"

$b
[1] "f" "g" "h" "i" "j"

> l2<-list(c=LETTERS[1:5],d=LETTERS[6:10])
> l2
$c
[1] "A" "B" "C" "D" "E"

$d
[1] "F" "G" "H" "I" "J"

> l3<-list(l1,l2)
> l3
[[1]]
[[1]]$a
[1] "a" "b" "c" "d" "e"

[[1]]$b
[1] "f" "g" "h" "i" "j"


[[2]]
[[2]]$c
[1] "A" "B" "C" "D" "E"

[[2]]$d
[1] "F" "G" "H" "I" "J"



On 06/06/07, elyakhlifi mustapha <elyakhlifi_mustapha at yahoo.fr> wrote:
> hello,
> I wanna know how to create a list of list if it's possible and if it isn't possible how to do without.
> thanks.
>
>
>       _____________________________________________________________________________
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
=================================
David Barron
Said Business School
University of Oxford
Park End Street
Oxford OX1 1HP


From jessica.gervais at tudor.lu  Wed Jun  6 11:35:34 2007
From: jessica.gervais at tudor.lu (jessica.gervais at tudor.lu)
Date: Wed, 6 Jun 2007 11:35:34 +0200
Subject: [R] spgrass6 and aggregation (bis)
Message-ID: <OF96DE731E.71C43DCF-ONC12572F2.0034B1D4-C12572F2.0034B1E8@tudor.lu>


Dear all,

I have some additionale question concerning the spgrass6 package.

* When you set a region in GRASS, does the readGRASS6 function in R only
load data contained in the zoomed region or the whole map ?

* When you have a MASK map in grass, does the readGRASS6 function in R only
load data contained inside the MASK area ?


Could this be the problem ?

Thanks,

Jessica


########################################################################3

Dear all,


I am exporting grass map into R thanks to the very useful spgrass6 package.

library(spgrass6)

# I have 3 map I am working with a MASK map of a specific area.

# 1) a landuse map
landuse<-readRAST6("landuse_mapname_in_grass")

# 2) a catchment map which divide the area in several catchements
catchment<-readRAST6("catchement_mapname_in_grass")

# 3) a precipitation map
precipitation<-readRAST6("precipitation_mapname_in_grass")


# then I would like to sum the precipitation spatialy over each catchment
and landuse. So, first I cbind all maps with cbind

MAP<-cbind(landuse,catchment,precipitation)

# then I use the aggregate function
SUM<-aggregate(MAP[3],by=list(MAP[1],MAP[2]),sum,na.rm=TRUE)
# here is the problem !!!
Error in as.vector(x, mode) : invalid argument 'mode'

....

I don't find any idea to solve this...

Does anyone has a suggestion ??

Thanks in advance


Jess


From Thierry.ONKELINX at inbo.be  Wed Jun  6 11:33:51 2007
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 6 Jun 2007 11:33:51 +0200
Subject: [R] list
In-Reply-To: <20070606085851.23326.qmail@web27503.mail.ukl.yahoo.com>
Message-ID: <2E9C414912813E4EB981326983E0A10403009018@inboexch.inbo.be>

Sure you can.

> list(list(), list(), list())


> library(fortunes)
> fortune("Yoda")

Evelyn Hall: I would like to know how (if) I can extract some of the
information from the summary of my nlme.
Simon Blomberg: This is R. There is no if. Only how.
   -- Evelyn Hall and Simon 'Yoda' Blomberg
      R-help (April 2005)



Cheers,

Thierry
------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium
tel. + 32 54/436 185
Thierry.Onkelinx op inbo.be
www.inbo.be 

Do not put your faith in what statistics say until you have carefully
considered what they do not say.  ~William W. Watt
A statistical analysis, properly conducted, is a delicate dissection of
uncertainties, a surgery of suppositions. ~M.J.Moroney

 

> -----Oorspronkelijk bericht-----
> Van: r-help-bounces op stat.math.ethz.ch 
> [mailto:r-help-bounces op stat.math.ethz.ch] Namens elyakhlifi mustapha
> Verzonden: woensdag 6 juni 2007 10:59
> Aan: R-help op stat.math.ethz.ch
> Onderwerp: [R] list
> 
> hello,
> I wanna know how to create a list of list if it's possible 
> and if it isn't possible how to do without.
> thanks.
> 
> 
>       
> ______________________________________________________________
> _______________ 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help op stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jrkrideau at yahoo.ca  Wed Jun  6 11:35:11 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Wed, 6 Jun 2007 05:35:11 -0400 (EDT)
Subject: [R] list
In-Reply-To: <20070606085851.23326.qmail@web27503.mail.ukl.yahoo.com>
Message-ID: <469485.13829.qm@web32803.mail.mud.yahoo.com>


--- elyakhlifi mustapha <elyakhlifi_mustapha at yahoo.fr>
wrote:

> hello,
> I wanna know how to create a list of list if it's
> possible and if it isn't possible how to do without.
> thanks.

Why?  The question is not clear and could mean several
things.  Can you explain a bit?


From jrkrideau at yahoo.ca  Wed Jun  6 11:38:50 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Wed, 6 Jun 2007 05:38:50 -0400 (EDT)
Subject: [R] Svar: Re:  help with simple R-question
In-Reply-To: <466692D1.76E3.003F.0@danishmeat.dk>
Message-ID: <939958.82036.qm@web32804.mail.mud.yahoo.com>


--- Rina Miehs <rmi at danishmeat.dk> wrote:

> thanks, that works great!!
>  
> just have another thing...i the same area
> What if the class is list instead of array, how can
> you name the first unrecognized column?

I am not sure that I understand the question.  You
don't really have an unrecognised column in the
dataframe but an array of rownames ( I don't know how
they are stored).

I think you can do the same thing as you did for the
data.frame but as I say, I am not sure I understand
the question.  Would you post a little example?


>  
> Rina
> 
> >>> John Kane <jrkrideau at yahoo.ca> 06/05/07 3:17 >>>
> 
> --- Rina Miehs <rmi at danishmeat.dk> wrote:
> 
> > hello
> >  
> > what do i write for R to recognize both columns?
> >  
> > In the R-script downunder you can see that i use
> > tapply to get my
> > information out of my data, and then i need to use
> > it as a dataframe
> > with both columns! It is like R is using the first
> > column as an
> > observationnumber or something, how can i change
> > that?? 
> 
> It is using the names of the variables as rownames.
> 
> try 
> n.ant <- names(antall)
> antal1 <- data.frame(n.antal1, antal1)
> 
> 
> >  
> > > antal1 <-tapply(l1$omlob1,l1$farid,length)
> > > antal1
> > 1437987  10000100  10007995  10008295  10008792 
> > 10010203  10018703 
> > 10033401 
> >         2         3         3         2         3 
>  
> >      1         1  
> >       2 
> >  10048900  10050492  10055897  10076495  10081892 
> > 10094801  10100692 
> > 10101395 
> >         3         1         3         3         6 
>  
> >      2         5  
> >      20 
> >  10101495  10101595  10104692  10113592  10113697 
> > 10114297  10120797 
> > 10120897 
> >         1         5         4         2         6 
>  
> >     11         1  
> >       4 
> >  10121697  10121897  10121997  10133592  10142892 
> > 10142995  10146495 
> > 10150497 
> >        16         3         6         1         1 
>  
> >      6         4  
> >       4 
> >  10150692  10157092  10157292  10164792  10170892 
> > 10171795  10171895 
> > 10172300 
> >         5         2         4         4         4 
>  
> >      4         4  
> >       1 
> >  10175195  10187802  10192499  10192897  10198295 
> > 10200493  10201693 
> > 10211593 
> >         1         2         2         3         5 
>  
> >      1         3  
> >       5 
> > > antal1 <- data.frame(antal1)
> > > antal1
> >           antal1
> > 1437987        2
> > 10000100       3
> > 10007995       3
> > 10008295       2
> > 10008792       3
> > 10010203      NA
> > 10018703      NA
> > 10033401       2
> > 10048900       3
> > 10050492       1
> > 10055897       3
> > 10076495       3
> > 10081892       6
> > 10094801       2
> > 10100692       5
> >  
> > Thanks
> > Rina
> > 
> > [[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help 
> > PLEASE do read the posting guide
> > http://www.R ( http://www.r/
> )-project.org/posting-guide.html
> > and provide commented, minimal, self-contained,
> > reproducible code.
> > 
> 
> 
> 
>       Get news delivered with the All new Yahoo!
> Mail.  Enjoy RSS feeds
> right on your Mail page. Start today at
> http://mrd.mail.yahoo.com/try_beta?.intl=ca 
> 
>


From rmi at danishmeat.dk  Wed Jun  6 12:07:58 2007
From: rmi at danishmeat.dk (Rina Miehs)
Date: Wed, 06 Jun 2007 12:07:58 +0200
Subject: [R] Svar: Re:  help with simple R-question
In-Reply-To: <939958.82036.qm@web32804.mail.mud.yahoo.com>
References: <466692D1.76E3.003F.0@danishmeat.dk>
	<939958.82036.qm@web32804.mail.mud.yahoo.com>
Message-ID: <4666A39D.76E3.003F.0@danishmeat.dk>

En indlejret tekst med ukendt tegns?t er blevet fjernet...
Navn: ikke tilg?ngelig
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070606/c1f57b3f/attachment.pl 

From petr.pikal at precheza.cz  Wed Jun  6 12:10:12 2007
From: petr.pikal at precheza.cz (Petr PIKAL)
Date: Wed, 6 Jun 2007 12:10:12 +0200
Subject: [R] Odp:  Svar: Re:  help with simple R-question
In-Reply-To: <466692D1.76E3.003F.0@danishmeat.dk>
Message-ID: <OF8291D13D.DDBFAA01-ONC12572F2.00369FD5-C12572F2.0037DD3A@precheza.cz>

r-help-bounces at stat.math.ethz.ch napsal dne 06.06.2007 10:56:18:

> thanks, that works great!!
> 
> just have another thing...i the same area
> What if the class is list instead of array, how can you name the first
> unrecognized column?

Hi

look in some intro manual and learn about R data structures. Matrix, 
array, vector, data.frame, list and some others have some distinct 
features and they sometimes can be interchanged and sometimes not. To 
learn how objects are organised see str(), class(), typeof(), mode().

Regards
Petr
 

> 
> Rina
> 
> >>> John Kane <jrkrideau at yahoo.ca> 06/05/07 3:17 >>>
> 
> --- Rina Miehs <rmi at danishmeat.dk> wrote:
> 
> > hello
> > 
> > what do i write for R to recognize both columns?
> > 
> > In the R-script downunder you can see that i use
> > tapply to get my
> > information out of my data, and then i need to use
> > it as a dataframe
> > with both columns! It is like R is using the first
> > column as an
> > observationnumber or something, how can i change
> > that?? 
> 
> It is using the names of the variables as rownames.
> 
> try 
> n.ant <- names(antall)
> antal1 <- data.frame(n.antal1, antal1)
> 
> 
> > 
> > > antal1 <-tapply(l1$omlob1,l1$farid,length)
> > > antal1
> > 1437987  10000100  10007995  10008295  10008792 
> > 10010203  10018703 
> > 10033401 
> >         2         3         3         2         3 
> >      1         1 
> >       2 
> >  10048900  10050492  10055897  10076495  10081892 
> > 10094801  10100692 
> > 10101395 
> >         3         1         3         3         6 
> >      2         5 
> >      20 
> >  10101495  10101595  10104692  10113592  10113697 
> > 10114297  10120797 
> > 10120897 
> >         1         5         4         2         6 
> >     11         1 
> >       4 
> >  10121697  10121897  10121997  10133592  10142892 
> > 10142995  10146495 
> > 10150497 
> >        16         3         6         1         1 
> >      6         4 
> >       4 
> >  10150692  10157092  10157292  10164792  10170892 
> > 10171795  10171895 
> > 10172300 
> >         5         2         4         4         4 
> >      4         4 
> >       1 
> >  10175195  10187802  10192499  10192897  10198295 
> > 10200493  10201693 
> > 10211593 
> >         1         2         2         3         5 
> >      1         3 
> >       5 
> > > antal1 <- data.frame(antal1)
> > > antal1
> >           antal1
> > 1437987        2
> > 10000100       3
> > 10007995       3
> > 10008295       2
> > 10008792       3
> > 10010203      NA
> > 10018703      NA
> > 10033401       2
> > 10048900       3
> > 10050492       1
> > 10055897       3
> > 10076495       3
> > 10081892       6
> > 10094801       2
> > 10100692       5
> > 
> > Thanks
> > Rina
> > 
> > [[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help 
> > PLEASE do read the posting guide
> > http://www.R ( http://www.r/ )-project.org/posting-guide.html
> > and provide commented, minimal, self-contained,
> > reproducible code.
> > 
> 
> 
> 
>       Get news delivered with the All new Yahoo! Mail.  Enjoy RSS feeds
> right on your Mail page. Start today at
> http://mrd.mail.yahoo.com/try_beta?.intl=ca 
> 
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Roger.Bivand at nhh.no  Wed Jun  6 12:30:10 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 6 Jun 2007 12:30:10 +0200 (CEST)
Subject: [R] spgrass6 and aggregation (bis)
In-Reply-To: <OF96DE731E.71C43DCF-ONC12572F2.0034B1D4-C12572F2.0034B1E8@tudor.lu>
Message-ID: <Pine.LNX.4.44.0706061209560.16522-100000@reclus.nhh.no>

On Wed, 6 Jun 2007 jessica.gervais at tudor.lu wrote:

> 
> Dear all,
> 
> I have some additionale question concerning the spgrass6 package.
> 
> * When you set a region in GRASS, does the readGRASS6 function in R only
> load data contained in the zoomed region or the whole map ?

readRAST6() uses the current region, readVECT6() should not clip to the 
current region.

> 
> * When you have a MASK map in grass, does the readGRASS6 function in R only
> load data contained inside the MASK area ?
> 

MASK is respected (in spearfish):

r.mask input=rushmore
d.rast elevation.dem
R
library(spgrass6)
el <- readRAST6("elevation.dem")
summary(el)
image(el)

> 
> Could this be the problem ?

No, the problem was that you did not pay attention to the class of the 
data objects you were reading. You could have done:

my_SGDF <- readRAST6(c("landuse_mapname_in_grass", 
  "catchement_mapname_in_grass",
  "precipitation_mapname_in_grass"), cat=c(TRUE, TRUE, FALSE))

treating the whole as a single SpatialGridDataFrame, and the first two 
maps as factors (categorical).

Please remember that class(), summary(), image(), and other methods let 
you look at the data you have read - here I would certainly do:

summary(my_SGDF)
image(my_SGDF, "precipitation_mapname_in_grass")

You can then try:

my_DF <- as(my_SGDF, "data.frame")
aggregate(my_DF, by=list(my_DF$catchement_mapname_in_grass, 
  my_DF$landuse_mapname_in_grass), sum, na.rm=TRUE)

although I'm not sure whether this is what you need.

There are two mailing lists that are better suited to this question, 
R-sig-geo on the R side, and STATGRASS on the GRASS side, both with a fair 
number of experienced helpers.

> 
> Thanks,
> 
> Jessica
> 
> 
> ########################################################################3
> 
> Dear all,
> 
> 
> I am exporting grass map into R thanks to the very useful spgrass6 package.
> 
> library(spgrass6)
> 
> # I have 3 map I am working with a MASK map of a specific area.
> 
> # 1) a landuse map
> landuse<-readRAST6("landuse_mapname_in_grass")
> 
> # 2) a catchment map which divide the area in several catchements
> catchment<-readRAST6("catchement_mapname_in_grass")
> 
> # 3) a precipitation map
> precipitation<-readRAST6("precipitation_mapname_in_grass")
> 
> 
> # then I would like to sum the precipitation spatialy over each catchment
> and landuse. So, first I cbind all maps with cbind
> 
> MAP<-cbind(landuse,catchment,precipitation)
> 
> # then I use the aggregate function
> SUM<-aggregate(MAP[3],by=list(MAP[1],MAP[2]),sum,na.rm=TRUE)
> # here is the problem !!!
> Error in as.vector(x, mode) : invalid argument 'mode'
> 
> ....
> 
> I don't find any idea to solve this...
> 
> Does anyone has a suggestion ??
> 
> Thanks in advance
> 
> 
> Jess
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From gregor.gorjanc at bfro.uni-lj.si  Wed Jun  6 12:12:49 2007
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Wed, 6 Jun 2007 10:12:49 +0000 (UTC)
Subject: [R] Refactor all factors in a data frame
References: <f43ke2$nnc$1@sea.gmane.org>
Message-ID: <loom.20070606T120941-106@post.gmane.org>

Hilmar Berger <hilmar.berger <at> imise.uni-leipzig.de> writes:
...
> So, is there any way in drop the unused factor levels from *all* factors 
> of a data frame without import/export ?

There is a generic drop.levels in gdata. Here is part of its help page:

"\code{drop.levels} is a generic function, where default method does
nothing, while method for factor \code{s} drops all unused levels.
There are also convenient methods for \code{list} and \code{data.frame},
where all unused levels are dropped in all factors (one by one) in a
\code{list} or a \code{data.frame}."

Gregor


From jari.oksanen at oulu.fi  Wed Jun  6 13:30:05 2007
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Wed, 6 Jun 2007 11:30:05 +0000 (UTC)
Subject: [R] correspondence analysis
References: <bfb35b70706052345t1d40bf88l48942296d9d5ea68@mail.gmail.com>
Message-ID: <loom.20070606T132031-749@post.gmane.org>

Artem Mariupol <artem.mariupol <at> gmail.com> writes:

> 
> Hello,
> 
> I am new to R and I have a question about the difference between
> correspondence analysis in R and SPSS.
> This is the input table I am working with (4 products and 18 attributes):
> 
> > mytable
>    1  2  3  4  5 6  7  8  9 10 11 12 13 14 15 16 17 18
> 1 15 11 20  4 14 7  1  2  1  4 12 12 17 19 11 20  9 10
> 2 19 18 14 14 16 4 14 11 11 15 22 19 22 16 21 19 15 16
> 3 16 13 10  9 15 4 10  7 11 13 18 17 14 14 16 16 13 11
> 4 21 18 16 14 20 6 12 14 14 17 23 20 19 18 21 18 19 18
> 
> I found the function corresp() in the package MASS, but the results are
> different from the output in SPSS. Also, I don't understand the coordinates;
> in the biplot I cannot find a -2 limit for example from the first product on
> any of the x axes.
> 
At a quick look, there is nothing strange in the result. Have you contacted SPSS
and asked them to explain their deviant results?

It seems that biplot.correspondence is undocumented. However, it has argument
'type' which defaults to "symmetric", other alternative being "rows" and
"columns". Intelligent guess is that this selects the scaling of row and column
scores, and type="symmetric" scales both. By selecting type="columns", only
columns are scaled and the -2 value for a row will be displayed (which proves
that the guess was correct).

I don't have a clue how SPSS scales results, but I guess that the differences in
the results may be due to different scalings. Function corresp gives you
weighted orthonormal row and column scores, but scales these in the plot like
specified. It may be that SPSS does the scaling already in the printout (and
does not give you the choice of type?). Another possible source of difference is
that corresp gives you "canonical correlations" whereas some other program or
function may give you their squares, a.k.a. eigenvalues. Moreover, the sign is
arbitrary so that negative and positive scores may be switched between programs. 

I hope this helps, 

Jari Oksanen


From yvonnick.noel at free.fr  Wed Jun  6 13:46:01 2007
From: yvonnick.noel at free.fr (NOEL Yvonnick)
Date: Wed, 06 Jun 2007 13:46:01 +0200
Subject: [R] Mandriva Spring 2007 and R
Message-ID: <46669E79.2070904@free.fr>

Jonathan,

If you are not willing to use the very last version of R, there is 
always a RPM package for R under Mandriva, called R-base. So that 
basically, connected as root, just type:

urpmi R-base

to install it.

HTH,

Yvonnick Noel
U. of Rennes 2


From jrkrideau at yahoo.ca  Wed Jun  6 13:46:56 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Wed, 6 Jun 2007 07:46:56 -0400 (EDT)
Subject: [R] Svar: Re:  help with simple R-question
In-Reply-To: <4666A39D.76E3.003F.0@danishmeat.dk>
Message-ID: <493828.90561.qm@web32813.mail.mud.yahoo.com>

I think that you have the same situation as before
though I have never used ranef().  The boar ids are
acting as the row names and are not really part of the
data.frame. It just looks like that when R prints the
data.frame.  

Try 

boars <- rownames(far1) 
far1 <- cbind( boars, far1) 

The results may look a bit funny with two printed
columns looking the same but one will be a column in
the data.frame and the other will be the row names
column.  I hope :)

--- Rina Miehs <rmi at danishmeat.dk> wrote:

>  
> The left column is boar id number, and the right is
> the random effect
> estimate. I need the numbers in the left column when
> i merge far1
> together with other data.frames based on the id
> numbers. When i use
> ranef the output is the class list and R only sees
> the intercepts, but i
> need a data.frame with 'boar id' and 'niveau', two
> columns not just
> one...
>  
> fx
> > far1 <- ranef(resultat1)[1]
> > far1
> $farid
>             (Intercept)
> 1437987   -3.775851e-03
> 10000100  -3.220044e-03
> 10007995   1.848914e-02
> 10008295  -4.583903e-03
> 10008792  -9.518371e-03
> 10033401  -7.538132e-03
> 10048900   1.540309e-02
> > far1 <- as.data.frame(far1)
> > far1
>            X.Intercept.
> 1437987   -3.775851e-03
> 10000100  -3.220044e-03
> 10007995   1.848914e-02
> 10008295  -4.583903e-03
> 10008792  -9.518371e-03
> 10033401  -7.538132e-03
> 10048900   1.540309e-02
> Thanks again
>  
> Rina
> 
> 
> >>> John Kane <jrkrideau at yahoo.ca> 06/06/07 11:38
> >>>
> 
> --- Rina Miehs <rmi at danishmeat.dk> wrote:
> 
> > thanks, that works great!!
> >  
> > just have another thing...i the same area
> > What if the class is list instead of array, how
> can
> > you name the first unrecognized column?
> 
> I am not sure that I understand the question.  You
> don't really have an unrecognised column in the
> dataframe but an array of rownames ( I don't know
> how
> they are stored).
> 
> I think you can do the same thing as you did for the
> data.frame but as I say, I am not sure I understand
> the question.  Would you post a little example?
> 
> 
> >  
> > Rina
> > 
> > >>> John Kane <jrkrideau at yahoo.ca> 06/05/07 3:17
> >>>
> > 
> > --- Rina Miehs <rmi at danishmeat.dk> wrote:
> > 
> > > hello
> > >  
> > > what do i write for R to recognize both columns?
> > >  
> > > In the R-script downunder you can see that i use
> > > tapply to get my
> > > information out of my data, and then i need to
> use
> > > it as a dataframe
> > > with both columns! It is like R is using the
> first
> > > column as an
> > > observationnumber or something, how can i change
> > > that?? 
> > 
> > It is using the names of the variables as
> rownames.
> > 
> > try 
> > n.ant <- names(antall)
> > antal1 <- data.frame(n.antal1, antal1)
> > 
> > 
> > >  
> > > > antal1 <-tapply(l1$omlob1,l1$farid,length)
> > > > antal1
> > > 1437987  10000100  10007995  10008295  10008792 
> > > 10010203  10018703 
> > > 10033401 
> > >         2         3         3         2        
> 3 
> >  
> > >      1         1  
> > >       2 
> > >  10048900  10050492  10055897  10076495 
> 10081892 
> > > 10094801  10100692 
> > > 10101395 
> > >         3         1         3         3        
> 6 
> >  
> > >      2         5  
> > >      20 
> > >  10101495  10101595  10104692  10113592 
> 10113697 
> > > 10114297  10120797 
> > > 10120897 
> > >         1         5         4         2        
> 6 
> >  
> > >     11         1  
> > >       4 
> > >  10121697  10121897  10121997  10133592 
> 10142892 
> > > 10142995  10146495 
> > > 10150497 
> > >        16         3         6         1        
> 1 
> >  
> > >      6         4  
> > >       4 
> > >  10150692  10157092  10157292  10164792 
> 10170892 
> > > 10171795  10171895 
> > > 10172300 
> > >         5         2         4         4        
> 4 
> >  
> > >      4         4  
> > >       1 
> > >  10175195  10187802  10192499  10192897 
> 10198295 
> > > 10200493  10201693 
> > > 10211593 
> > >         1         2         2         3        
> 5 
> >  
> > >      1         3  
> > >       5 
> > > > antal1 <- data.frame(antal1)
> > > > antal1
> > >           antal1
> > > 1437987        2
> > > 10000100       3
> > > 10007995       3
> > > 10008295       2
> > > 10008792       3
> > > 10010203      NA
> > > 10018703      NA
> > > 10033401       2
> > > 10048900       3
> > > 10050492       1
> > > 10055897       3
> > > 10076495       3
> > > 10081892       6
> > > 10094801       2
> > > 10100692       5
> > >  
> > > Thanks
> > > Rina
> > > 
> > > [[alternative HTML version deleted]]
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help 
> > > PLEASE do read the posting guide
> > > http://www.R ( http://www.r/ ) ( http://www.r/ 
> > )-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained,
> > > reproducible code.
> > > 
> > 
> > 
> > 
> >       Get news delivered with the All new Yahoo!
> > Mail.  Enjoy RSS feeds
> > right on your Mail page. Start today at
> > http://mrd.mail.yahoo.com/try_beta?.intl=ca 
> > 
> > 
> 
> 
> 
>       Be smarter than spam. See how smart SpamGuard
> is at giving junk

> http://mrd.mail.yahoo.com/try_beta?.intl=ca 
> 
> 
> 
=== message truncated ===


From rmi at danishmeat.dk  Wed Jun  6 14:07:21 2007
From: rmi at danishmeat.dk (Rina Miehs)
Date: Wed, 06 Jun 2007 14:07:21 +0200
Subject: [R] Svar: Re:  help with simple R-question
In-Reply-To: <493828.90561.qm@web32813.mail.mud.yahoo.com>
References: <4666A39D.76E3.003F.0@danishmeat.dk>
	<493828.90561.qm@web32813.mail.mud.yahoo.com>
Message-ID: <4666BF97.76E3.003F.0@danishmeat.dk>

En indlejret tekst med ukendt tegns?t er blevet fjernet...
Navn: ikke tilg?ngelig
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070606/e5099e4e/attachment.pl 

From Graham.Williams at togaware.com  Tue Jun  5 10:09:55 2007
From: Graham.Williams at togaware.com (Graham Williams)
Date: Tue, 5 Jun 2007 18:09:55 +1000
Subject: [R] [R-pkgs] Package update: pmml version 1.1.1
Message-ID: <20070605080955.GA15345@athene.togaware.com>

Version 1.1.1 of the pmml package (PMML = Predictive Modelling Markup
Language) has been uploaded to CRAN. This version adds pmml.lm to
generate PMML for linear models (currently, without interactions).

The PMML package is part of the Rattle toolkit for data
mining. Further information from http://rattle.togaware.com.

Regards,
Graham

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages


From dave at kanecap.com  Tue Jun  5 15:52:13 2007
From: dave at kanecap.com (David Kane)
Date: Tue, 5 Jun 2007 09:52:13 -0400
Subject: [R] [R-pkgs] New Package on Lancet Surveys of Iraq Mortality
Message-ID: <18021.27277.958091.918392@gargle.gargle.HOWL>

Hello,

I have placed a package on CRAN about two surveys of mortality in Iraq
that were published in the Lancet.

http://cran.at.r-project.org/src/contrib/Descriptions/lancet.iraqmortality.html

> install.packages("lancet.iraqmortality")

...

> library(lancet.iraqmortality)
Loading required package: foreign
> ?lancet.iraqmortality
> vignette("mortality")

This is a rough version. Suggestions and feedback are welcome.

Dave Kane

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages


From cabaldeck at yahoo.com  Tue Jun  5 16:29:49 2007
From: cabaldeck at yahoo.com (baldeck)
Date: Tue, 5 Jun 2007 07:29:49 -0700 (PDT)
Subject: [R] sampling problem - new to R
Message-ID: <10970708.post@talk.nabble.com>


I have a data set of individual trees and the plots that they are in:

Tree      Plot
56749    1
63494    1
87375    1
37494    2
92753    3
34847    3
38747    4 etc...

So each plot is represented once for every individual that occurrs in it. 
Plots get different numbers of rows because there can be a different number
of individuals in each plot.

I want to make a data frame that consists of one individual from each plot. 
I would like to randomly choose one individual from each plot that is
present in the data set.  I will have to do this to multiple data sets which
may contain different plots, and may contain up to 1200 plots, so I can't
choose the plots by hand.

Please help me with this.  I'm an ecologist and I'm in Panama, with no one
around who is educated in R.  Whoever solves this problem for me will be
acknowledged in any resulting publications.

Thanks!
-Claire
-- 
View this message in context: http://www.nabble.com/sampling-problem---new-to-R-tf3872130.html#a10970708
Sent from the R help mailing list archive at Nabble.com.


From khchoi at sfsu.edu  Wed Jun  6 00:03:44 2007
From: khchoi at sfsu.edu (Keun-Hyung Choi)
Date: Tue, 5 Jun 2007 15:03:44 -0700
Subject: [R] generating many matrices
Message-ID: <000f01c7a7bd$658dfc50$0b01a8c0@sfsu5096qxj6c3>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070605/e6cc348e/attachment.pl 

From eh.rasa at gmail.com  Wed Jun  6 05:44:54 2007
From: eh.rasa at gmail.com (Ehsan Rasa)
Date: Tue, 5 Jun 2007 20:44:54 -0700
Subject: [R] Neural Net. in R
Message-ID: <28c8c3190706052044k3f8e4ef9v78e8bae9f7bca426@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070605/8a3c4d25/attachment.pl 

From carmei3 at freenet.de  Wed Jun  6 11:45:12 2007
From: carmei3 at freenet.de (carmei3 at freenet.de)
Date: Wed, 06 Jun 2007 11:45:12 +0200
Subject: [R] p-value from GEE
Message-ID: <E1Hvs4m-0000hS-HM@www19.emo.freenet-rz.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070606/e9557116/attachment.pl 

From scottflemming at yahoo.com  Wed Jun  6 05:49:18 2007
From: scottflemming at yahoo.com (scott flemming)
Date: Tue, 5 Jun 2007 20:49:18 -0700 (PDT)
Subject: [R] R help
Message-ID: <806411.48610.qm@web57504.mail.re1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070605/3181f27b/attachment.pl 

From pev340002003 at yahoo.com  Tue Jun  5 23:49:28 2007
From: pev340002003 at yahoo.com (tronter)
Date: Tue, 5 Jun 2007 14:49:28 -0700 (PDT)
Subject: [R] R: x-y data
Message-ID: <10978448.post@talk.nabble.com>


Hello

I have an Excel file with x-y data. I saved this file as a cvs file. Then I
used the read.table() function to read the data into R. If I have a formula
like (x+y)/2, how would I access x and y in R? I have the table named as
something. But how do I access the individual columns if I want to plug them
into the formula?

Thanks
-- 
View this message in context: http://www.nabble.com/R%3A-x-y-data-tf3874502.html#a10978448
Sent from the R help mailing list archive at Nabble.com.


From bcarvalh at jhsph.edu  Wed Jun  6 14:54:32 2007
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Wed, 6 Jun 2007 08:54:32 -0400
Subject: [R] name of the variable that will contain the result of a function
Message-ID: <E2350202-E64C-4E64-B958-D624926FE56F@jhsph.edu>

Hi everyone,

say I have a function called 'foo', which takes the argument arg1.

Is there any mechanism that I can use to "learn" about the variable  
where foo(arg1) is going to be stored?

For example:

x <- foo(arg1)

so, inside foo() I'd like to be able to get the string "x".

if,

foo(arg1)

was used insted, I'd like to get NA.

thank you very much,

b






--
Benilton Carvalho
PhD Candidate
Department of Biostatistics
Bloomberg School of Public Health
Johns Hopkins University
bcarvalh at jhsph.edu


From michael.watson at bbsrc.ac.uk  Wed Jun  6 14:57:15 2007
From: michael.watson at bbsrc.ac.uk (michael watson (IAH-C))
Date: Wed, 6 Jun 2007 13:57:15 +0100
Subject: [R] R help
In-Reply-To: <806411.48610.qm@web57504.mail.re1.yahoo.com>
References: <806411.48610.qm@web57504.mail.re1.yahoo.com>
Message-ID: <8975119BCD0AC5419D61A9CF1A923E9504F0D4DC@iahce2ksrv1.iah.bbsrc.ac.uk>

Yes, but you need to be a bit more specific... When it comes to graphs
and drawing lines, there isn't much R can't do... 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of scott flemming
Sent: 06 June 2007 04:49
To: r-help at stat.math.ethz.ch
Subject: [R] R help

Hi,

I wonder whether R can finish the following project:

I want to make a chart to represent 10 genes. Each gene has orientation
and length. Therefore, a gene can be represented by arrows. 

Can R be used to draw 10 arrows in one line ?

scott

       
---------------------------------

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Max.Kuhn at pfizer.com  Wed Jun  6 15:18:23 2007
From: Max.Kuhn at pfizer.com (Kuhn, Max)
Date: Wed, 6 Jun 2007 09:18:23 -0400
Subject: [R] Neural Net. in R
In-Reply-To: <28c8c3190706052044k3f8e4ef9v78e8bae9f7bca426@mail.gmail.com>
Message-ID: <71257D09F114DA4A8E134DEAC70F25D3088F88A1@groamrexm03.amer.pfizer.com>

Jason,

Your best bet is the nnet package. It is part of the VR bundle, which
may be why you missed it. 

The code is well documented and the package is closely tied to two books
(see the references in ?nnet). 

Also, it has a predict function, which many of the others do not. This
isn't too big of a deal, but it certainly speaks to good design.

Max


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Ehsan Rasa
Sent: Tuesday, June 05, 2007 11:45 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Neural Net. in R

Hi everyone,

I'm a graduate student of engineering, lately introduced with R. and
using R
for my project and thesis. I'm trying to use R for implementing a neural
network regression model and apply it to my database. I found three R
packages ("AMORE" , "grnnR" , "neural") in R website, but their manuals
are
not really user-friendly in my idea. I was wondering if anyone has a
written
code in R using any of these packages for a feed-forward
back-propagation
neural network in R that I can use it. That'll be a remedy for my
nightmare
which already took quite time from me.
I would really appreciate it.

Sincerely,
Jason.

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

----------------------------------------------------------------------
LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}


From sarah.goslee at gmail.com  Wed Jun  6 15:20:31 2007
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 6 Jun 2007 09:20:31 -0400
Subject: [R] R help
In-Reply-To: <806411.48610.qm@web57504.mail.re1.yahoo.com>
References: <806411.48610.qm@web57504.mail.re1.yahoo.com>
Message-ID: <efb536d50706060620q451d0973qf9a0b95a2a7288db@mail.gmail.com>

On 6/5/07, scott flemming <scottflemming at yahoo.com> wrote:

> Can R be used to draw 10 arrows in one line ?

Um, sure.

Assuming you actually also want to know how to do it, why don't
you take a look at the help for arrows().

Sarah

-- 
Sarah Goslee
http://www.functionaldiversity.org


From jholtman at gmail.com  Wed Jun  6 15:22:45 2007
From: jholtman at gmail.com (jim holtman)
Date: Wed, 6 Jun 2007 09:22:45 -0400
Subject: [R] sampling problem - new to R
In-Reply-To: <10970708.post@talk.nabble.com>
References: <10970708.post@talk.nabble.com>
Message-ID: <644e1f320706060622uf952e5aof828c5a5bb06cc5a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070606/0b464f03/attachment.pl 

From jholtman at gmail.com  Wed Jun  6 15:26:00 2007
From: jholtman at gmail.com (jim holtman)
Date: Wed, 6 Jun 2007 09:26:00 -0400
Subject: [R] R: x-y data
In-Reply-To: <10978448.post@talk.nabble.com>
References: <10978448.post@talk.nabble.com>
Message-ID: <644e1f320706060626y36dcf28ar3ec72a731c4aa72e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070606/76a33f81/attachment.pl 

From sarah.goslee at gmail.com  Wed Jun  6 15:29:00 2007
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 6 Jun 2007 09:29:00 -0400
Subject: [R] sampling problem - new to R
In-Reply-To: <10970708.post@talk.nabble.com>
References: <10970708.post@talk.nabble.com>
Message-ID: <efb536d50706060629m2d4bbc37k8fde51e03ca08fc9@mail.gmail.com>

Claire,

Here's one way to do it:

# first, generate some sample data to try
> treedata <- cbind.data.frame(Tree=1:25, Plot=sample(1:5, 25, replace=TRUE))
> treedata <- treedata[order(treedata$Plot),]
> treedata
   Tree Plot
1     1    1
2     2    1
6     6    1
9     9    1
11   11    1
17   17    1
18   18    1
23   23    1
13   13    2
16   16    2
25   25    2
5     5    3
10   10    3
4     4    4
7     7    4
8     8    4
24   24    4
3     3    5
12   12    5
14   14    5
15   15    5
19   19    5
20   20    5
21   21    5
22   22    5

# then randomly choose one tree from each plot
# getting a different random set each time
> sapply(split(treedata$Tree, treedata$Plot), sample, 1)
 1  2  3  4  5
 2 25 10  4 21
> sapply(split(treedata$Tree, treedata$Plot), sample, 1)
 1  2  3  4  5
23 13  5  4 14


Hope that solves it for you,
Sarah

On 6/5/07, baldeck <cabaldeck at yahoo.com> wrote:
>
> I have a data set of individual trees and the plots that they are in:
>
> Tree      Plot
> 56749    1
> 63494    1
> 87375    1
> 37494    2
> 92753    3
> 34847    3
> 38747    4 etc...
>
> So each plot is represented once for every individual that occurrs in it.
> Plots get different numbers of rows because there can be a different number
> of individuals in each plot.
>
> I want to make a data frame that consists of one individual from each plot.
> I would like to randomly choose one individual from each plot that is
> present in the data set.  I will have to do this to multiple data sets which
> may contain different plots, and may contain up to 1200 plots, so I can't
> choose the plots by hand.
>
> Please help me with this.  I'm an ecologist and I'm in Panama, with no one
> around who is educated in R.  Whoever solves this problem for me will be
> acknowledged in any resulting publications.
>
> Thanks!
> -Claire
> --


-- 
Sarah Goslee
http://www.functionaldiversity.org


From ripley at stats.ox.ac.uk  Wed Jun  6 15:30:50 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 6 Jun 2007 14:30:50 +0100 (BST)
Subject: [R] sampling problem - new to R
In-Reply-To: <10970708.post@talk.nabble.com>
References: <10970708.post@talk.nabble.com>
Message-ID: <Pine.LNX.4.64.0706061419440.24008@gannet.stats.ox.ac.uk>

On Tue, 5 Jun 2007, baldeck wrote:

> I have a data set of individual trees and the plots that they are in:
>
> Tree      Plot
> 56749    1
> 63494    1
> 87375    1
> 37494    2
> 92753    3
> 34847    3
> 38747    4 etc...

You haven't told us what form the 'data set' is, but I will presume a data 
frame called DF.

The obvious first step is to split by Plot.  Using 'resample' from ?sample

sapply(with(DF, split(Tree, Plot)), resample, size=1)

give a vector of trees ('individuals'?) with names the plots sampled from. 
That seems to be what you want, but if not please come back to us with a 
more extensive example including the desired output.


> So each plot is represented once for every individual that occurrs in it.
> Plots get different numbers of rows because there can be a different number
> of individuals in each plot.
>
> I want to make a data frame that consists of one individual from each plot.
> I would like to randomly choose one individual from each plot that is
> present in the data set.  I will have to do this to multiple data sets which
> may contain different plots, and may contain up to 1200 plots, so I can't
> choose the plots by hand.
>
> Please help me with this.  I'm an ecologist and I'm in Panama, with no one
> around who is educated in R.  Whoever solves this problem for me will be
> acknowledged in any resulting publications.
>
> Thanks!
> -Claire
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jholtman at gmail.com  Wed Jun  6 15:32:43 2007
From: jholtman at gmail.com (jim holtman)
Date: Wed, 6 Jun 2007 09:32:43 -0400
Subject: [R] generating many matrices
In-Reply-To: <000f01c7a7bd$658dfc50$0b01a8c0@sfsu5096qxj6c3>
References: <000f01c7a7bd$658dfc50$0b01a8c0@sfsu5096qxj6c3>
Message-ID: <644e1f320706060632n75237453pa14a76ee03f1f0ce@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070606/b7359d02/attachment.pl 

From jacques.wagnor at gmail.com  Wed Jun  6 15:42:54 2007
From: jacques.wagnor at gmail.com (Jacques Wagnor)
Date: Wed, 6 Jun 2007 08:42:54 -0500
Subject: [R] A question about riskmeasures() vs. qgpd() in library(evir)
Message-ID: <787911d50706060642r472adfe2id826adcc53e43b45@mail.gmail.com>

Dear List,

This inquiry probably does not directly pertain to R.

I am using library(evir) to learn EVT.  Based on my reading of things,
it is my understanding that if one wants to calculate quantiles of
GPD, one could use either riskmeasures() or qgpd().  However, using
data(danish) as an example, the quantile estimates produced by
riskmeasures() are considerably different from those produced by
qgpd() as follows:

> library(evir)
> data(danish)
> out <- gpd(danish, 10)
> riskmeasures(out, c(0.999, 0.9999))

              p  quantile     sfall
[1,] 0.9990  94.28956   191.3697
[2,] 0.9999  304.62448 609.3696

> qgpd(c(0.999, 0.9999), out$par.ests["xi"], out$par.ests["beta"])

[1]  67.22493 200.41271

Any insights would be greatly appreciated.

Regards,

Jacques

platform       i386-pc-mingw32
arch           i386
os             mingw32
system         i386, mingw32
status
major          2
minor          5.0
year           2007
month          04
day            23
svn rev        41293
language       R
version.string R version 2.5.0 (2007-04-23)


From petr.pikal at precheza.cz  Wed Jun  6 15:57:05 2007
From: petr.pikal at precheza.cz (Petr PIKAL)
Date: Wed, 6 Jun 2007 15:57:05 +0200
Subject: [R] Odp:  sampling problem - new to R
In-Reply-To: <10970708.post@talk.nabble.com>
Message-ID: <OFCE034D68.6C0453E3-ONC12572F2.004C49E7-C12572F2.004CA2AD@precheza.cz>

Hi

If I understand correctly, use split and sample with lapply. If DF is your 
dataframe

lapply(split(DF$Tree, DF$Plot), function(x) sample(x,1))

shall select random tree from each plot. Or you can get it in tabular form 
with sapply.

Regards
Petr

r-help-bounces at stat.math.ethz.ch napsal dne 05.06.2007 16:29:49:

> 
> I have a data set of individual trees and the plots that they are in:
> 
> Tree      Plot
> 56749    1
> 63494    1
> 87375    1
> 37494    2
> 92753    3
> 34847    3
> 38747    4 etc...
> 
> So each plot is represented once for every individual that occurrs in 
it. 
> Plots get different numbers of rows because there can be a different 
number
> of individuals in each plot.
> 
> I want to make a data frame that consists of one individual from each 
plot. 
> I would like to randomly choose one individual from each plot that is
> present in the data set.  I will have to do this to multiple data sets 
which
> may contain different plots, and may contain up to 1200 plots, so I 
can't
> choose the plots by hand.
> 
> Please help me with this.  I'm an ecologist and I'm in Panama, with no 
one
> around who is educated in R.  Whoever solves this problem for me will be
> acknowledged in any resulting publications.
> 
> Thanks!
> -Claire
> -- 
> View this message in context: 
http://www.nabble.com/sampling-problem---new-to-
> R-tf3872130.html#a10970708
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From h.wickham at gmail.com  Wed Jun  6 15:58:25 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Wed, 6 Jun 2007 15:58:25 +0200
Subject: [R] generating many matrices
In-Reply-To: <000f01c7a7bd$658dfc50$0b01a8c0@sfsu5096qxj6c3>
References: <000f01c7a7bd$658dfc50$0b01a8c0@sfsu5096qxj6c3>
Message-ID: <f8e6ff050706060658l16080d12l341452b40d1c7cc5@mail.gmail.com>

On 6/6/07, Keun-Hyung Choi <khchoi at sfsu.edu> wrote:
> I'd like to generate many matrices (let's say 100 matrices of 4x4), of which
> diagonal elements are being drawn from each set of sample of known
> distribution.
>
> What would be the best way?  I've been trying to find any previous threads
> for this topic, but haven't been able to find one.

One approach would be:

replicate(100, diag(runif(4)), simplify=FALSE)

Hadley


From HDoran at air.org  Wed Jun  6 15:56:42 2007
From: HDoran at air.org (Doran, Harold)
Date: Wed, 6 Jun 2007 09:56:42 -0400
Subject: [R] sampling problem - new to R
In-Reply-To: <10970708.post@talk.nabble.com>
Message-ID: <2323A6D37908A847A7C32F1E3662C80EBA07E4@dc1ex01.air.org>

I dealt with something like this recently. 

x <- data.frame(plot = gl(2,5), tree = rnorm(10)) 
y <- split(x, x$plot)

ss <- numeric(2)
for(i in 1:2){
	ss[i] <- sample(row.names(y[[i]][1]), 1)
}

z <- x[ss,]

People help out of the goodness of the hearts and not for publication
recognition. 

Harold


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of baldeck
> Sent: Tuesday, June 05, 2007 10:30 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] sampling problem - new to R
> 
> 
> I have a data set of individual trees and the plots that they are in:
> 
> Tree      Plot
> 56749    1
> 63494    1
> 87375    1
> 37494    2
> 92753    3
> 34847    3
> 38747    4 etc...
> 
> So each plot is represented once for every individual that 
> occurrs in it. 
> Plots get different numbers of rows because there can be a 
> different number of individuals in each plot.
> 
> I want to make a data frame that consists of one individual 
> from each plot. 
> I would like to randomly choose one individual from each plot 
> that is present in the data set.  I will have to do this to 
> multiple data sets which may contain different plots, and may 
> contain up to 1200 plots, so I can't choose the plots by hand.
> 
> Please help me with this.  I'm an ecologist and I'm in 
> Panama, with no one around who is educated in R.  Whoever 
> solves this problem for me will be acknowledged in any 
> resulting publications.
> 
> Thanks!
> -Claire
> --
> View this message in context: 
> http://www.nabble.com/sampling-problem---new-to-R-tf3872130.ht
> ml#a10970708
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From david.stadelmann at unifr.ch  Wed Jun  6 16:10:26 2007
From: david.stadelmann at unifr.ch (David STADELMANN)
Date: Wed, 06 Jun 2007 16:10:26 +0200
Subject: [R] Sargan Test and Hansen J Statistc for Simultaneous Equation
	Model
Message-ID: <4666C052.2000008@unifr.ch>

Dear R Users,

I am estimation a Simultaneous Equation Model with systemfit.

Does anyone of you know how to do a Sargan Test for overidentifiaction 
and a Hansen J statistic for instrument adequacy. Is there a possibility 
in R to do a Hausman-Wu test for the exogeneity of specific variables?

Do you know any other possibilities in R to perform similar tests 
(overidentification, instrument adequacy and exogeneity)?

Thank you very much for your help.
Yours
David

-- 
##################################################
David Stadelmann
Lehrstuhl f?r Makro?konomie,
Internationale Industrie- und Wachstumspolitik
Universit? de Fribourg
Bureau F410
Bd de P?rolles 90
CH-1700 Fribourg
SCHWEIZ

Tel: +41 (026) 300 93 82
Fax: +41 (026) 300 96 78
Mob (priv): +41 (076) 542 33 48
Email: david.stadelmann at unifr.ch
Internet: http://www.unifr.ch/natoek
Internet (priv): http://david.stadelmann-online.com


From petr.pikal at precheza.cz  Wed Jun  6 16:11:13 2007
From: petr.pikal at precheza.cz (Petr PIKAL)
Date: Wed, 6 Jun 2007 16:11:13 +0200
Subject: [R] Odp: Odp:  sampling problem - new to R
In-Reply-To: <OFCE034D68.6C0453E3-ONC12572F2.004C49E7-C12572F2.004CA2AD@LocalDomain>
Message-ID: <OF797AF3DA.A22B7AA9-ONC12572F2.004DC63A-C12572F2.004DEE13@precheza.cz>

> Hi
> 
> If I understand correctly, use split and sample with lapply. If DF is 
your dataframe
> 
> lapply(split(DF$Tree, DF$Plot), function(x) sample(x,1))
> 
> shall select random tree from each plot. Or you can get it in tabular 
form with sapply.
> 
> Regards
> Petr

Sorry, you shall use resample from sample help page as Prof.Ripley pointed 
if you can have length<=1 plot.

Regards
Petr


> 
> r-help-bounces at stat.math.ethz.ch napsal dne 05.06.2007 16:29:49:
> 
> > 
> > I have a data set of individual trees and the plots that they are in:
> > 
> > Tree      Plot
> > 56749    1
> > 63494    1
> > 87375    1
> > 37494    2
> > 92753    3
> > 34847    3
> > 38747    4 etc...
> > 
> > So each plot is represented once for every individual that occurrs in 
it. 
> > Plots get different numbers of rows because there can be a different 
number
> > of individuals in each plot.
> > 
> > I want to make a data frame that consists of one individual from each 
plot. 
> > I would like to randomly choose one individual from each plot that is
> > present in the data set.  I will have to do this to multiple data sets 
which
> > may contain different plots, and may contain up to 1200 plots, so I 
can't
> > choose the plots by hand.
> > 
> > Please help me with this.  I'm an ecologist and I'm in Panama, with no 
one
> > around who is educated in R.  Whoever solves this problem for me will 
be
> > acknowledged in any resulting publications.
> > 
> > Thanks!
> > -Claire
> > -- 
> > View this message in context: 
http://www.nabble.com/sampling-problem---new-to-
> > R-tf3872130.html#a10970708
> > Sent from the R help mailing list archive at Nabble.com.
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From rcreecy at census.gov  Wed Jun  6 16:23:33 2007
From: rcreecy at census.gov (Rob Creecy)
Date: Wed, 06 Jun 2007 10:23:33 -0400
Subject: [R] the biggest integer R can display in complete form but not
 scientific form
In-Reply-To: <46663776.5080707@hotmail.com>
References: <dff718fc0706050802sb21befr30a132494df1bfcd@mail.gmail.com>	<46658CC7.2030107@gmail.com>
	<46663776.5080707@hotmail.com>
Message-ID: <4666C365.6030807@census.gov>

You could try the gmp multi precision arithmetic package.

 > library(gmp)
 > urand.bigz(10,64)
 [1] "11691875040763095143" "15618480061048441861" 
"13311871202921807091" "419603425985430936" 
 [5] "1009212057431928522"  "7087885826104674385"  
"12844267011818015745" "12455584250595618327"
 [9] "13509505397081611804" "17712034795004058021"

Rob

Francisco J. Zagmutt wrote:
> Also, look at options(digits) to set the number digits to be printed in 
> the console, i.e.
>
>  > pi
> [1] 3.141593
>
>  > options(digits=22)
>  > pi
> [1] 3.141592653589793
> 	
>
> Regards
>
> Francisco
>
>
> Roland Rau wrote:
>   
>> ??? wrote:
>>     
>>> Dear R-lister,
>>>
>>> One of my friends wanted to produce random number which is 64 bits. He did
>>> it with Fortune. I think R can do it also. But I don't know how to display a
>>> very big integer in the complete form but not scientific form. And what's
>>> the biggest integer R can display in complete form ?
>>>
>>> Thanks in advance,
>>>
>>> Li Junjie
>>>
>>>
>>>
>>>       
>> I guess the biggest integer R can represent (if this is what you mean) 
>> is machine dependent and you can find it out via:
>>
>> .Machine
>> help(".Machine")
>>
>> I hope this helps,
>> Roland
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>     
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>


From Johannes.Muehe at web.de  Wed Jun  6 16:25:15 2007
From: Johannes.Muehe at web.de (=?iso-8859-1?Q?Johannes_M=FChe?=)
Date: Wed, 6 Jun 2007 16:25:15 +0200
Subject: [R] anova(lme)
Message-ID: <003801c7a846$816119b0$85d890d4@jocc7516e90fc6>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070606/8a002b2d/attachment.pl 

From tlumley at u.washington.edu  Wed Jun  6 16:31:56 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 6 Jun 2007 07:31:56 -0700 (PDT)
Subject: [R] name of the variable that will contain the result of a
 function
In-Reply-To: <E2350202-E64C-4E64-B958-D624926FE56F@jhsph.edu>
References: <E2350202-E64C-4E64-B958-D624926FE56F@jhsph.edu>
Message-ID: <Pine.LNX.4.64.0706060722210.22694@homer23.u.washington.edu>

On Wed, 6 Jun 2007, Benilton Carvalho wrote:

> Hi everyone,
>
> say I have a function called 'foo', which takes the argument arg1.
>
> Is there any mechanism that I can use to "learn" about the variable
> where foo(arg1) is going to be stored?

No. This information isn't available explicitly even at the C level.

> For example:
>
> x <- foo(arg1)
>
> so, inside foo() I'd like to be able to get the string "x".
>
> if,
>
> foo(arg1)
>
> was used insted, I'd like to get NA.

It could be much worse that this, for example,
    x[[7]][y][[4]] <- foo(arg1)
    w <- foo(arg2)+1
    names(x)[foo(arg3)] <- foo(arg4)

 	-thomas


From ggrothendieck at gmail.com  Wed Jun  6 16:34:41 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 6 Jun 2007 10:34:41 -0400
Subject: [R] sampling problem - new to R
In-Reply-To: <Pine.LNX.4.64.0706061419440.24008@gannet.stats.ox.ac.uk>
References: <10970708.post@talk.nabble.com>
	<Pine.LNX.4.64.0706061419440.24008@gannet.stats.ox.ac.uk>
Message-ID: <971536df0706060734x23028669lf8cbfaee008d1781@mail.gmail.com>

A variation of Brian's idea of using resample in ?sample would be:

   set.seed(1) # makes sample reproducible
   aggregate(DF[1], DF[2], resample, size = 1)

Using resample ensures that the solution works even if some
of the Plots only have one Tree.  Some of the solutions
that were presented in this thread do not work properly in that case
as sample acts differently according to whether its first argument's
length is 1 or > 1.

On 6/6/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> On Tue, 5 Jun 2007, baldeck wrote:
>
> > I have a data set of individual trees and the plots that they are in:
> >
> > Tree      Plot
> > 56749    1
> > 63494    1
> > 87375    1
> > 37494    2
> > 92753    3
> > 34847    3
> > 38747    4 etc...
>
> You haven't told us what form the 'data set' is, but I will presume a data
> frame called DF.
>
> The obvious first step is to split by Plot.  Using 'resample' from ?sample
>
> sapply(with(DF, split(Tree, Plot)), resample, size=1)
>
> give a vector of trees ('individuals'?) with names the plots sampled from.
> That seems to be what you want, but if not please come back to us with a
> more extensive example including the desired output.
>
>
> > So each plot is represented once for every individual that occurrs in it.
> > Plots get different numbers of rows because there can be a different number
> > of individuals in each plot.
> >
> > I want to make a data frame that consists of one individual from each plot.
> > I would like to randomly choose one individual from each plot that is
> > present in the data set.  I will have to do this to multiple data sets which
> > may contain different plots, and may contain up to 1200 plots, so I can't
> > choose the plots by hand.
> >
> > Please help me with this.  I'm an ecologist and I'm in Panama, with no one
> > around who is educated in R.  Whoever solves this problem for me will be
> > acknowledged in any resulting publications.
> >
> > Thanks!
> > -Claire
> >
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jmb at mssl.ucl.ac.uk  Wed Jun  6 16:30:44 2007
From: jmb at mssl.ucl.ac.uk (Jenny Barnes)
Date: Wed, 6 Jun 2007 15:30:44 +0100 (BST)
Subject: [R] random numbers selection - simple example
Message-ID: <200706061430.l56EUiHU000270@msslhb.mssl.ucl.ac.uk>

Dear R-help,

Which random number generator function would you recommend for simply picking 15 
random numbers from the sequence 0-42? I want to use replacement (so that the 
same number could potentially be picked more than once).

I have read the R-help archives and the statistics and computing book on modern 
Applied statistics with S but the advice seems to be for much form complicated 
examples, there must be a simpler way for what I am trying to do?

If anybody can help me I would greatly appreciate your advice and time,

Best Wishes,

Jenny


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Jennifer Barnes
PhD student: long range drought prediction 
Climate Extremes Group
Department of Space and Climate Physics
University College London
Holmbury St Mary 
Dorking, Surrey, RH5 6NT
Web: http://climate.mssl.ucl.ac.uk


From john.seers at bbsrc.ac.uk  Wed Jun  6 16:45:21 2007
From: john.seers at bbsrc.ac.uk (john seers (IFR))
Date: Wed, 6 Jun 2007 15:45:21 +0100
Subject: [R] R: x-y data
In-Reply-To: <10978448.post@talk.nabble.com>
Message-ID: <AAD49F46EAE3F6479E1D46428FAC31CB0181AB11@NBIE2KSRV1.nbi.bbsrc.ac.uk>



 
tt<-read.table("C:/temp/test.csv", header=T, sep=",")

# Try:

tt$x
tt$y

# OR

tt["x"]
tt["y"]

# OR

tt[["x"]]
tt[["y"]]

# OR

tt[1]
tt[2] 
tt[[1]]
tt[[2]]

# Is this what you want?



>I have an Excel file with x-y data. I saved this file as a cvs file.
Then I
>used the read.table() function to read the data into R. If I have a
formula
>like (x+y)/2, how would I access x and y in R? I have the table named
as
>something. But how do I access the individual columns if I want to plug
them
>into the formula?


From soarealin at gmail.com  Wed Jun  6 16:48:27 2007
From: soarealin at gmail.com (Soare Marcian-Alin)
Date: Wed, 6 Jun 2007 16:48:27 +0200
Subject: [R] Linear Discriminant Analysis
Message-ID: <255640f90706060748j6dbaa08av91c421b98b53188f@mail.gmail.com>

Ein eingebundener Text mit undefiniertem Zeichensatz wurde abgetrennt.
Name: nicht verf?gbar
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20070606/9059c7cc/attachment.pl 

From liuwensui at gmail.com  Wed Jun  6 16:49:00 2007
From: liuwensui at gmail.com (Wensui Liu)
Date: Wed, 6 Jun 2007 10:49:00 -0400
Subject: [R] Neural Net. in R
In-Reply-To: <28c8c3190706052044k3f8e4ef9v78e8bae9f7bca426@mail.gmail.com>
References: <28c8c3190706052044k3f8e4ef9v78e8bae9f7bca426@mail.gmail.com>
Message-ID: <1115a2b00706060749i7c9b3ebeq729ddb9582a89c7a@mail.gmail.com>

Hi, there,
I am surprised you didn't mention nnet package.
You can find very good information in Dr Ripley's MASS book about the
usage of nnet package.

On 6/5/07, Ehsan Rasa <eh.rasa at gmail.com> wrote:
> Hi everyone,
>
> I'm a graduate student of engineering, lately introduced with R. and using R
> for my project and thesis. I'm trying to use R for implementing a neural
> network regression model and apply it to my database. I found three R
> packages ("AMORE" , "grnnR" , "neural") in R website, but their manuals are
> not really user-friendly in my idea. I was wondering if anyone has a written
> code in R using any of these packages for a feed-forward back-propagation
> neural network in R that I can use it. That'll be a remedy for my nightmare
> which already took quite time from me.
> I would really appreciate it.
>
> Sincerely,
> Jason.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
WenSui Liu
A lousy statistician who happens to know a little programming
(http://spaces.msn.com/statcompute/blog)


From Bernd.Stampfl at Sparinvest.com  Wed Jun  6 16:50:16 2007
From: Bernd.Stampfl at Sparinvest.com (Bernd Stampfl)
Date: Wed, 6 Jun 2007 07:50:16 -0700 (PDT)
Subject: [R] Chow Test
Message-ID: <10990270.post@talk.nabble.com>


Hello R-users!
I tried to find a package to run a CHOW TEST. As a reference package I found
the STRUCCHANGE package. Do you know if it works well otherwise can you
recommend a different one?

Thanks, Bernd
-- 
View this message in context: http://www.nabble.com/Chow-Test-tf3878416.html#a10990270
Sent from the R help mailing list archive at Nabble.com.


From klijunjie at gmail.com  Wed Jun  6 16:54:08 2007
From: klijunjie at gmail.com (=?GB2312?B?wO6/ob3c?=)
Date: Wed, 6 Jun 2007 22:54:08 +0800
Subject: [R] the biggest integer R can display in complete form but not
	scientific form
In-Reply-To: <4666C365.6030807@census.gov>
References: <dff718fc0706050802sb21befr30a132494df1bfcd@mail.gmail.com>
	<46658CC7.2030107@gmail.com> <46663776.5080707@hotmail.com>
	<4666C365.6030807@census.gov>
Message-ID: <dff718fc0706060754y7ac8a8c3s2a5929893c360024@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070606/d096e0f2/attachment.pl 

From sarah.goslee at gmail.com  Wed Jun  6 16:54:58 2007
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 6 Jun 2007 10:54:58 -0400
Subject: [R] random numbers selection - simple example
In-Reply-To: <200706061430.l56EUiHU000270@msslhb.mssl.ucl.ac.uk>
References: <200706061430.l56EUiHU000270@msslhb.mssl.ucl.ac.uk>
Message-ID: <efb536d50706060754p5bab7e4cl3d26849939204ae6@mail.gmail.com>

Assuming you want only integers, see
?sample

Sarah

On 6/6/07, Jenny Barnes <jmb at mssl.ucl.ac.uk> wrote:
> Dear R-help,
>
> Which random number generator function would you recommend for simply picking 15
> random numbers from the sequence 0-42? I want to use replacement (so that the
> same number could potentially be picked more than once).
>
> I have read the R-help archives and the statistics and computing book on modern
> Applied statistics with S but the advice seems to be for much form complicated
> examples, there must be a simpler way for what I am trying to do?
>
> If anybody can help me I would greatly appreciate your advice and time,
>
> Best Wishes,
>
> Jenny
>
>


-- 
Sarah Goslee
http://www.functionaldiversity.org


From jmb at mssl.ucl.ac.uk  Wed Jun  6 16:55:06 2007
From: jmb at mssl.ucl.ac.uk (Jenny Barnes)
Date: Wed, 6 Jun 2007 15:55:06 +0100 (BST)
Subject: [R] random numbers selection - simple example
Message-ID: <200706061455.l56Et5fY000275@msslhb.mssl.ucl.ac.uk>

You're all stars - thanks for the replies - I will go ahead and use 
sample...........
I need to do this about 10,000 times - any suggestions for this or simply put it 
in a loop 10,000 times outputting each time to an array?

Best Wishes,

Jenny 


>
>
>  use sample(c(0:42), 15, replace=T)
>
>hope it helps,
>kevin
>
>----- Original Message -----
>From: Jenny Barnes <jmb at mssl.ucl.ac.uk>
>Date: Wednesday, June 6, 2007 10:30 am
>Subject: [R] random numbers selection - simple example
>
>> Dear R-help,
>> 
>> Which random number generator function would you recommend for 
>> simply picking 15 
>> random numbers from the sequence 0-42? I want to use replacement 
>> (so that the 
>> same number could potentially be picked more than once).
>> 
>> I have read the R-help archives and the statistics and computing 
>> book on modern 
>> Applied statistics with S but the advice seems to be for much form 
>> complicated 
>> examples, there must be a simpler way for what I am trying to do?
>> 
>> If anybody can help me I would greatly appreciate your advice and 
>> time,
>> Best Wishes,
>> 
>> Jenny
>> 
>> 
>> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>> Jennifer Barnes
>> PhD student: long range drought prediction 
>> Climate Extremes Group
>> Department of Space and Climate Physics
>> University College London
>> Holmbury St Mary 
>> Dorking, Surrey, RH5 6NT
>> Web: http://climate.mssl.ucl.ac.uk
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.htmland provide commented, minimal, self-contained, 
>> reproducible code.
>> 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Jennifer Barnes
PhD student: long range drought prediction 
Climate Extremes Group
Department of Space and Climate Physics
University College London
Holmbury St Mary 
Dorking, Surrey, RH5 6NT
Tel: 01483 204149
Mob: 07916 139187
Web: http://climate.mssl.ucl.ac.uk


From sue at xlsolutions-corp.com  Wed Jun  6 17:08:24 2007
From: sue at xlsolutions-corp.com (Sue Turner)
Date: Wed, 06 Jun 2007 08:08:24 -0700
Subject: [R] Courses: Traditional and Modern Approaches to Statistical
	Modelling with R by Dr Bill Venables. in Raleigh and Washington DC
Message-ID: <20070606080823.aa8924c5d28ca71e2a043bb294e795eb.03653ee36c.wbe@email.secureserver.net>


From jrkrideau at yahoo.ca  Wed Jun  6 17:15:46 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Wed, 6 Jun 2007 11:15:46 -0400 (EDT)
Subject: [R] R: x-y data
In-Reply-To: <10978448.post@talk.nabble.com>
Message-ID: <765436.68689.qm@web32810.mail.mud.yahoo.com>

There are a couple of ways but I think you need to
read  about R . Have a look at Managing data
http://cran.r-project.org/doc/contrib/Lemon-kickstart/index.html

and / or read the Intro to R manual available on CRAN
or probably from the R help icon. 

you have a data.frame DF you can assign names to the
variables 

?names
names(DF) <- c("x", "y") and attach the data.frame

?attach

or you can reference the columns

as DF[,1] and DF[,2]



--- tronter <pev340002003 at yahoo.com> wrote:

> 
> Hello
> 
> I have an Excel file with x-y data. I saved this
> file as a cvs file. Then I
> used the read.table() function to read the data into
> R. If I have a formula
> like (x+y)/2, how would I access x and y in R? I
> have the table named as
> something. But how do I access the individual
> columns if I want to plug them
> into the formula?
> 
> Thanks
> --


From Achim.Zeileis at wu-wien.ac.at  Wed Jun  6 17:20:22 2007
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Wed, 6 Jun 2007 17:20:22 +0200 (CEST)
Subject: [R] Chow Test
In-Reply-To: <10990270.post@talk.nabble.com>
Message-ID: <Pine.LNX.4.44.0706061710010.15612-100000@disco.wu-wien.ac.at>

On Wed, 6 Jun 2007, Bernd Stampfl wrote:

>
> Hello R-users!
> I tried to find a package to run a CHOW TEST. As a reference package I found
> the STRUCCHANGE package. Do you know if it works well

If you have concerns regarding the reliability, you can check the
underlying source code and read the accompanying publications (which also
comment on reliability and reproducibility).

> otherwise can you recommend a different one?

If the breakpoint is known, you can easily compute the Chow test by hand:
set up a factor that codes the two regimes and then fit the un-segmented
and segmented regressions:
  fac <- my_time > my_break
  fm0 <- lm(y ~ x1 + x2 ...)
  fm1 <- lm(y ~ fac / (x1 + x2 ...))
  anova(fm0, fm1)
If you want other covariances in the test, you can also use waldtest()
from the "lmtest" package.

If the breakpoint is not known in advance, a supF test (aka supChow) over
all conceivable breakpoints is more appropriate. This is also provided in
"strucchange" along with a rich set of other testing (and dating)
techniques.

Best,
Z

> Thanks, Bernd
> --
> View this message in context: http://www.nabble.com/Chow-Test-tf3878416.html#a10990270
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


From jdnewmil at dcn.davis.ca.us  Wed Jun  6 17:23:09 2007
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 06 Jun 2007 08:23:09 -0700
Subject: [R] R: x-y data
In-Reply-To: <644e1f320706060626y36dcf28ar3ec72a731c4aa72e@mail.gmail.com>
References: <10978448.post@talk.nabble.com>
	<644e1f320706060626y36dcf28ar3ec72a731c4aa72e@mail.gmail.com>
Message-ID: <4666D15D.1000107@dcn.davis.ca.us>

Or read ?attach

   attach(something)
   (x+y)/2
   detach(something)

jim holtman wrote:
> Can you provide an example of your data.  Assuming that you have a .cvs file
> and the column names are 'x' and 'y' and you have used 'read.csv', then you
> would have:
> 
> (something$x + something$y) / 2
> 
> 
> 
> On 6/5/07, tronter <pev340002003 at yahoo.com> wrote:
>>
>> Hello
>>
>> I have an Excel file with x-y data. I saved this file as a cvs file. Then
>> I
>> used the read.table() function to read the data into R. If I have a
>> formula
>> like (x+y)/2, how would I access x and y in R? I have the table named as
>> something. But how do I access the individual columns if I want to plug
>> them
>> into the formula?

-- 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From ted.harding at nessie.mcc.ac.uk  Wed Jun  6 17:24:21 2007
From: ted.harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Wed, 06 Jun 2007 16:24:21 +0100 (BST)
Subject: [R] random numbers selection - simple example
In-Reply-To: <200706061430.l56EUiHU000270@msslhb.mssl.ucl.ac.uk>
Message-ID: <XFMail.070606162421.ted.harding@nessie.mcc.ac.uk>

On 06-Jun-07 14:30:44, Jenny Barnes wrote:
> Dear R-help,
> 
> Which random number generator function would you recommend for
> simply picking 15 random numbers from the sequence 0-42? I want
> to use replacement (so that the same number could potentially be
> picked more than once).

R has the function sample() which samples a given number of items
from a given set, without replacement by default, but with replacement
if you specify this. Enter

  ?sample

for more information. In the above case

  sample((0:42), 15, replace=TRUE)

will do what you seem to describe above. Example:

> sample((0:42), 15, replace=TRUE)
 [1] 26 38  1 41 11 30 22 37 28  0  0 25 10 39 27

if you want them in random order (i.e. "as they come off the line"),
or

> sort(sample((0:42), 15, replace=TRUE))
 [1]  1  3  5  8  8 10 16 17 21 25 30 30 33 34 40

if you want them sorted.

Best wishes,
Ted.

> I have read the R-help archives and the statistics and computing
> book on modern Applied statistics with S but the advice seems to
> be for much form complicated examples, there must be a simpler way
> for what I am trying to do?
> 
> If anybody can help me I would greatly appreciate your advice and time,
> 
> Best Wishes,
> 
> Jenny

--------------------------------------------------------------------
E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 06-Jun-07                                       Time: 16:24:15
------------------------------ XFMail ------------------------------


From res90sx5 at verizon.net  Wed Jun  6 17:34:28 2007
From: res90sx5 at verizon.net (Daniel Nordlund)
Date: Wed, 06 Jun 2007 08:34:28 -0700
Subject: [R] random numbers selection - simple example
In-Reply-To: <200706061455.l56Et5fY000275@msslhb.mssl.ucl.ac.uk>
Message-ID: <002a01c7a850$2c3131a0$0201a8c0@Aragorn>

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch]
> On Behalf Of Jenny Barnes
> Sent: Wednesday, June 06, 2007 7:55 AM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] random numbers selection - simple example
> 
> You're all stars - thanks for the replies - I will go ahead and use
> sample...........
> I need to do this about 10,000 times - any suggestions for this or simply put it
> in a loop 10,000 times outputting each time to an array?
> 
> Best Wishes,
> 
> Jenny
> 
> 
> >
> >
> >  use sample(c(0:42), 15, replace=T)
> >
> >hope it helps,
> >kevin

You could try something like the following

s<-matrix(sample(c(0:42), 10000*15, replace=TRUE), 10000, 15)

which will give you a 10000 row matrix with 1 sample of size 15 per row.

Hope this is helpful,

Dan

Daniel Nordlund
Bothell, WA USA


From ligges at statistik.uni-dortmund.de  Wed Jun  6 17:39:46 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 06 Jun 2007 17:39:46 +0200
Subject: [R] Linear Discriminant Analysis
In-Reply-To: <255640f90706060748j6dbaa08av91c421b98b53188f@mail.gmail.com>
References: <255640f90706060748j6dbaa08av91c421b98b53188f@mail.gmail.com>
Message-ID: <4666D542.20504@statistik.uni-dortmund.de>


So what about asking your teacher (who seems to be Peter Filzmoser) and 
try to find out your homework yourself?
You might want to think about some assumptions that must hold for LDA 
and look at the class of your explaining variables ...

Uwe Ligges



Soare Marcian-Alin wrote:
> Hello,
> 
> I want to make a linear discriminant analysis for the dataset olive, and I
> get always this error:#
> Warning message:
> variables are collinear in: lda.default(x, grouping, ...)
> 
> ## Loading Data
> library(MASS)
> olive <- url("
> http://www.statistik.tuwien.ac.at/public/filz/students/multi/ss07/olive.R")
> print(load(olive))
> 
> y <- 1:572
> x <- sample(y)
> y1 <- x[1:286]
> 
> train <- olive[y1,-11]
> test  <- olive[-y1,-11]
> 
> summary(train)
> summary(test)
> 
> table(train$Region)
> table(test$Region)
> 
> # Linear Discriminant Analysis
> z <- lda(Region ~ . , train)
> predict(z, train)
> 
> z <- lda(Region ~ . , test)
> predict(z, test)
> 
> Thanks in advance!
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From soarealin at gmail.com  Wed Jun  6 17:45:11 2007
From: soarealin at gmail.com (Soare Marcian-Alin)
Date: Wed, 6 Jun 2007 17:45:11 +0200
Subject: [R] Linear Discriminant Analysis
In-Reply-To: <4666D542.20504@statistik.uni-dortmund.de>
References: <255640f90706060748j6dbaa08av91c421b98b53188f@mail.gmail.com>
	<4666D542.20504@statistik.uni-dortmund.de>
Message-ID: <255640f90706060845o21530092v7f3a4794e0027515@mail.gmail.com>

Ein eingebundener Text mit undefiniertem Zeichensatz wurde abgetrennt.
Name: nicht verf?gbar
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20070606/b5069e42/attachment.pl 

From wl2776 at gmail.com  Wed Jun  6 18:15:33 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Wed, 6 Jun 2007 09:15:33 -0700 (PDT)
Subject: [R] Neural Net. in R
In-Reply-To: <28c8c3190706052044k3f8e4ef9v78e8bae9f7bca426@mail.gmail.com>
References: <28c8c3190706052044k3f8e4ef9v78e8bae9f7bca426@mail.gmail.com>
Message-ID: <10991934.post@talk.nabble.com>


I have written some bindings from the SNNS (Stuttgart Neural Network
Simulator) to R.
However, this work is not finished since the lack of interest to it and lack
of time.
At the moment, I use the mixture of scripts for R, cmd.exe, bash, and SNNS'
batchman (latter two under cygwin) in my work.

SNNS by itself is rather feature rich and well documented.
Unfortunately its development has stopped many years ago, and it contains
bugs, which I still failed to find and eliminate.


Ehsan Rasa wrote:
> 
> Hi everyone,
> 
> I'm a graduate student of engineering, lately introduced with R. and using
> R
> for my project and thesis. I'm trying to use R for implementing a neural
> network regression model and apply it to my database. I found three R
> packages ("AMORE" , "grnnR" , "neural") in R website, but their manuals
> are
> not really user-friendly in my idea. I was wondering if anyone has a
> written
> code in R using any of these packages for a feed-forward back-propagation
> neural network in R that I can use it. That'll be a remedy for my
> nightmare
> which already took quite time from me.
> I would really appreciate it.
> 
> Sincerely,
> Jason.
> 

-- 
View this message in context: http://www.nabble.com/Neural-Net.-in-R-tf3877741.html#a10991934
Sent from the R help mailing list archive at Nabble.com.


From JGOLDHAB at hsph.harvard.edu  Wed Jun  6 18:17:31 2007
From: JGOLDHAB at hsph.harvard.edu (Jeremy Goldhaber-Fiebert)
Date: Wed, 06 Jun 2007 12:17:31 -0400
Subject: [R] Using odesolve to produce non-negative solutions
Message-ID: <4666A5D0.896D.005E.0@hsph.harvard.edu>

Hello,

I am using odesolve to simulate a group of people moving through time and transmitting infections to one another. 

In Matlab, there is a NonNegative option which tells the Matlab solver to keep the vector elements of the ODE solution non-negative at all times. What is the right way to do this in R?

Thanks,
Jeremy

P.S., Below is a simplified version of the code I use to try to do this, but I am not sure that it is theoretically right 

dynmodel <- function(t,y,p) 
{ 
## Initialize parameter values

	birth <- p$mybirth(t)
	death <- p$mydeath(t)
	recover <- p$myrecover
	beta <- p$mybeta
	vaxeff <- p$myvaxeff
	vaccinated <- p$myvax(t)

	vax <- vaxeff*vaccinated/100

## If the state currently has negative quantities (shouldn't have), then reset to reasonable values for computing meaningful derivatives

	for (i in 1:length(y)) {
		if (y[i]<0) {
			y[i] <- 0
		}
	}

	S <- y[1]
	I <- y[2]
	R <- y[3]
	N <- y[4]

	shat <- (birth*(1-vax)) - (death*S) - (beta*S*I/N)
	ihat <- (beta*S*I/N) - (death*I) - (recover*I)
	rhat <- (birth*(vax)) + (recover*I) - (death*R)

## Do we overshoot into negative space, if so shrink derivative to bring state to 0 
## then rescale the components that take the derivative negative

	if (shat+S<0) {
		shat_old <- shat
		shat <- -1*S
		scaled_transmission <- (shat/shat_old)*(beta*S*I/N)
		ihat <- scaled_transmission - (death*I) - (recover*I)
		
	}	
	if (ihat+I<0) {
		ihat_old <- ihat
		ihat <- -1*I
		scaled_recovery <- (ihat/ihat_old)*(recover*I)
		rhat <- scaled_recovery +(birth*(vax)) - (death*R)
	
	}	
	if (rhat+R<0) {
		rhat <- -1*R
	}	

	nhat <- shat + ihat + rhat

	if (nhat+N<0) {
		nhat <- -1*N	
	}	

## return derivatives

	list(c(shat,ihat,rhat,nhat),c(0))

}


From yanqin_yang at yahoo.com  Wed Jun  6 18:22:58 2007
From: yanqin_yang at yahoo.com (Yanqin Yang)
Date: Wed, 6 Jun 2007 09:22:58 -0700 (PDT)
Subject: [R] how to update R version
Message-ID: <820809.9299.qm@web53506.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070606/c26957d4/attachment.pl 

From JGOLDHAB at hsph.harvard.edu  Wed Jun  6 18:31:24 2007
From: JGOLDHAB at hsph.harvard.edu (Jeremy Goldhaber-Fiebert)
Date: Wed, 06 Jun 2007 12:31:24 -0400
Subject: [R] Fwd: Using odesolve to produce non-negative solutions
References: <4666A5D0.896D.005E.0@hsph.harvard.edu>
Message-ID: <4666A910.896D.005E.0@hsph.harvard.edu>

Hello,

I am using odesolve to simulate a group of people moving through time and transmitting infections to one another. 

In Matlab, there is a NonNegative option which tells the Matlab solver to keep the vector elements of the ODE solution non-negative at all times. What is the right way to do this in R?

Thanks,
Jeremy

P.S., Below is a simplified version of the code I use to try to do this, but I am not sure that it is theoretically right 

dynmodel <- function(t,y,p) 
{ 
## Initialize parameter values

	birth <- p$mybirth(t)
	death <- p$mydeath(t)
	recover <- p$myrecover
	beta <- p$mybeta
	vaxeff <- p$myvaxeff
	vaccinated <- p$myvax(t)

	vax <- vaxeff*vaccinated/100

## If the state currently has negative quantities (shouldn't have), then reset to reasonable values for computing meaningful derivatives

	for (i in 1:length(y)) {
		if (y[i]<0) {
			y[i] <- 0
		}
	}

	S <- y[1]
	I <- y[2]
	R <- y[3]
	N <- y[4]

	shat <- (birth*(1-vax)) - (death*S) - (beta*S*I/N)
	ihat <- (beta*S*I/N) - (death*I) - (recover*I)
	rhat <- (birth*(vax)) + (recover*I) - (death*R)

## Do we overshoot into negative space, if so shrink derivative to bring state to 0 
## then rescale the components that take the derivative negative

	if (shat+S<0) {
		shat_old <- shat
		shat <- -1*S
		scaled_transmission <- (shat/shat_old)*(beta*S*I/N)
		ihat <- scaled_transmission - (death*I) - (recover*I)
		
	}	
	if (ihat+I<0) {
		ihat_old <- ihat
		ihat <- -1*I
		scaled_recovery <- (ihat/ihat_old)*(recover*I)
		rhat <- scaled_recovery +(birth*(vax)) - (death*R)
	
	}	
	if (rhat+R<0) {
		rhat <- -1*R
	}	

	nhat <- shat + ihat + rhat

	if (nhat+N<0) {
		nhat <- -1*N	
	}	

## return derivatives

	list(c(shat,ihat,rhat,nhat),c(0))

}


From irilenia.nobeli at kcl.ac.uk  Wed Jun  6 18:27:23 2007
From: irilenia.nobeli at kcl.ac.uk (Irilenia Nobeli)
Date: Wed, 6 Jun 2007 17:27:23 +0100
Subject: [R] Question on RandomForest in unsupervised mode
Message-ID: <03D469CA-CB4A-48CE-BB9E-F1A83F29798C@kcl.ac.uk>

Hi,

I attempted to run the randomForest() function on a dataset without  
predefined classes. According to the manual, running randomForest  
without a response variable/class labels should result in the  
function assuming you are running in unsupervised mode. In this case,  
I understand that my data is all assigned to one class whereas a  
second synthetic class is made up, which is assigned to a second  
class. The online manual suggests that an oob misclassification error  
in this two-class problem of ~40% or more would indicate that the x- 
variables look like independent variables to random forests (and I  
assume that in this case the proximities obtained by the randomForest  
would not be informative for clustering).

When I run randomForest() in the unsupervised mode my first problem  
is that I get NULL entries for the confusion matrix and the err.rate,  
but I suppose this is normal behaviour. My only information (apart  
from the proximities of course), seems to be the votes, from which I  
can deduce whether the variables are meaningful or not. The second  
problem is that, in my case, all my observations seem to have about  
20-40% of the votes from class 1 and the rest from class 2 (i.e.  
class 2 "wins" always). Assuming that class 1 was assigned to my  
original data, I'd say this is rather surprising.
Initially I thought this was simply a problem of my data not being  
meaningful, but I repeated simply the forest with the "iris" example  
data and I get more or less the same result.
I did simply:

iris.urf <- randomForest(iris[,-5])
iris.urf$votes

and I got again most of the votes coming from class 2, although here  
vote percentages are slightly more balanced than with my data  
(approximately 40 to 60% most of the time).

Has anyone got experience with unsupervised randomForest() in R and  
can explain to me why I'm observing this behaviour? In general, any  
hints about pitfalls regarding random forests in unsupervised mode  
would be very much appreciated.

Many thanks in advance,

Irilenia

-----------------------------
Irilenia (Irene) Nobeli
Randall Division of Cell and Molecular Biophysics
New Hunt's House (room 3.14)
King's College London, Guy's Campus
London, SE1 1UL
U.K.
irilenia.nobeli at kcl.ac.uk
+44(0)207-8486329


From b.wagman at comcast.net  Wed Jun  6 18:35:03 2007
From: b.wagman at comcast.net (Barnet Wagman)
Date: Wed, 06 Jun 2007 11:35:03 -0500
Subject: [R] Meaning of locfit warnings "procv: parameters out of bounds"?
Message-ID: <4666E237.1060101@comcast.net>

I'm getting the following warning from locfit:

    Warning: procv: parameters out of bounds

Does anyone know what this means? (I haven't found anything about it in 
the locfit documentation or the list's archives).

thanks,

Barnet Wagman


From waverley.paloalto at gmail.com  Wed Jun  6 18:44:41 2007
From: waverley.paloalto at gmail.com (Waverley)
Date: Wed, 6 Jun 2007 09:44:41 -0700
Subject: [R] Question: RMySQL bulk load/update one column, dbWriteTable()?
Message-ID: <8ee9d8f20706060944v5b05216fl6bc3246321a89f0d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070606/92184db4/attachment.pl 

From jrkrideau at yahoo.ca  Wed Jun  6 19:21:03 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Wed, 6 Jun 2007 13:21:03 -0400 (EDT)
Subject: [R] R help
In-Reply-To: <806411.48610.qm@web57504.mail.re1.yahoo.com>
Message-ID: <780602.85358.qm@web32811.mail.mud.yahoo.com>


--- scott flemming <scottflemming at yahoo.com> wrote:

> Hi,
> 
> I wonder whether R can finish the following project:
> 
> I want to make a chart to represent 10 genes. Each
> gene has orientation and length. Therefore, a gene
> can be represented by arrows. 
> 
> Can R be used to draw 10 arrows in one line ?
> 
> scott

Do you mean something like this?

x <- 1:10
y <- 1:10
plot(x,y, type="n" )
arrows(c(1,4,6),c(3,3,3), c(2,3, 7), c(4,4,2))


From kevin.thorpe at utoronto.ca  Wed Jun  6 19:37:05 2007
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Wed, 06 Jun 2007 13:37:05 -0400
Subject: [R] how to update R version
In-Reply-To: <820809.9299.qm@web53506.mail.re2.yahoo.com>
References: <820809.9299.qm@web53506.mail.re2.yahoo.com>
Message-ID: <4666F0C1.6070108@utoronto.ca>

Yanqin Yang wrote:
> Hello,
> 
> I am new in using Linux R. Would someone tell me what the best way to
> update my current R 2.3.0 to R 2.5.0? I want to keep my current
> library packages. Do I have to erase the older version and install
> the newer version? In that case, I need to re-download all the
> packages I need. Any short way to do the update?
> 
> Thanks for your help!
> 
> yanqin
> 

Since I compile from source, I simply compile the new version and
install it to the same location as the old.  Then I run
update.packages() to update the additional packages I have
installed. Of course, I may get bit by this approach one day.

It is possible to have more than one directory for packages.
One suggestion I've seen is to collect your "user installed"
packages in a different directory than the base and recommended
packages.

-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Department of Public Health Sciences
Faculty of Medicine, University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.6057


From juryef at yahoo.com  Wed Jun  6 19:50:26 2007
From: juryef at yahoo.com (Judith Flores)
Date: Wed, 6 Jun 2007 10:50:26 -0700 (PDT)
Subject: [R] Removing vertical line in Tinn R editor
Message-ID: <49867.11947.qm@web34705.mail.mud.yahoo.com>

Hi,

   I haven't been able to figure out how to remove a
vertical line that appears when I open an r file. How
can I do this?

Thank you,

Judith


       
____________________________________________________________________________________
Looking for a deal? Find great prices on flights and hotels with Yahoo! FareChase.


From christos at nuverabio.com  Wed Jun  6 20:01:15 2007
From: christos at nuverabio.com (Christos Hatzis)
Date: Wed, 6 Jun 2007 14:01:15 -0400
Subject: [R] Removing vertical line in Tinn R editor
In-Reply-To: <49867.11947.qm@web34705.mail.mud.yahoo.com>
References: <49867.11947.qm@web34705.mail.mud.yahoo.com>
Message-ID: <002901c7a864$adccbae0$0e010a0a@headquarters.silicoinsights>

Go to Options/Main/Editor
Click on EdgeColor and select white as the color (or to whatever color you
have set your page's background).  This will make the edge line disappear.

-Christos

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Judith Flores
> Sent: Wednesday, June 06, 2007 1:50 PM
> To: RHelp
> Subject: [R] Removing vertical line in Tinn R editor
> 
> Hi,
> 
>    I haven't been able to figure out how to remove a vertical 
> line that appears when I open an r file. How can I do this?
> 
> Thank you,
> 
> Judith
> 
> 
>        
> ______________________________________________________________
> ______________________
> Looking for a deal? Find great prices on flights and hotels 
> with Yahoo! FareChase.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
>


From michael.watson at bbsrc.ac.uk  Wed Jun  6 19:57:10 2007
From: michael.watson at bbsrc.ac.uk (michael watson (IAH-C))
Date: Wed, 6 Jun 2007 18:57:10 +0100
Subject: [R] Linear Discriminant Analysis
References: <255640f90706060748j6dbaa08av91c421b98b53188f@mail.gmail.com><4666D542.20504@statistik.uni-dortmund.de>
	<255640f90706060845o21530092v7f3a4794e0027515@mail.gmail.com>
Message-ID: <8975119BCD0AC5419D61A9CF1A923E9504AA1DF7@iahce2ksrv1.iah.bbsrc.ac.uk>

Region and Name are effectively the same variable
 
cor(olive[,4:11])

will also show you that there are strong correlations between some of the variables - this is something you might want to avoid....

________________________________

From: r-help-bounces at stat.math.ethz.ch on behalf of Soare Marcian-Alin
Sent: Wed 06/06/2007 4:45 PM
To: Uwe Ligges; R-help at stat.math.ethz.ch
Subject: Re: [R] Linear Discriminant Analysis



Thanks for explaining...

Im just sitting at the homework for 6 hours after taking for one week
antibiotica, because i had an amygdalitis...
I just wanted some tipps for solving this homework, but thanks, I will try
to get help on another way :)

I think i solved it, but I still get this Error :(

## Loading Data
library(MASS)
olive <- url("
http://www.statistik.tuwien.ac.at/public/filz/students/multi/ss07/olive.R")
print(load(olive))
dim(olive)
summary(olive)

index <- sample(nrow(olive), 286)

train  <- olive[index,-11]
test   <- olive[-index,-11]

summary(train)
summary(test)

table(train$Region)
table(test$Region)

# Linear Discriminant Analysis
z <- lda(Region ~ . , train)
zn <- predict(z, newdata=test)$class
mean(zn != test$Region)

2007/6/6, Uwe Ligges <ligges at statistik.uni-dortmund.de>:
>
>
> So what about asking your teacher (who seems to be Peter Filzmoser) and
> try to find out your homework yourself?
> You might want to think about some assumptions that must hold for LDA
> and look at the class of your explaining variables ...
>
> Uwe Ligges
>
>
>
> Soare Marcian-Alin wrote:
> > Hello,
> >
> > I want to make a linear discriminant analysis for the dataset olive, and
> I
> > get always this error:#
> > Warning message:
> > variables are collinear in: lda.default(x, grouping, ...)
> >
> > ## Loading Data
> > library(MASS)
> > olive <- url("
> >
> http://www.statistik.tuwien.ac.at/public/filz/students/multi/ss07/olive.R
> ")
> > print(load(olive))
> >
> > y <- 1:572
> > x <- sample(y)
> > y1 <- x[1:286]
> >
> > train <- olive[y1,-11]
> > test  <- olive[-y1,-11]
> >
> > summary(train)
> > summary(test)
> >
> > table(train$Region)
> > table(test$Region)
> >
> > # Linear Discriminant Analysis
> > z <- lda(Region ~ . , train)
> > predict(z, train)
> >
> > z <- lda(Region ~ . , test)
> > predict(z, test)
> >
> > Thanks in advance!
> >
> >
> >
> > ------------------------------------------------------------------------
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



--
Mit freundlichen Gr?ssen / Best Regards

Soare Marcian-Alin

        [[alternative HTML version deleted]]


From ramakanth_99 at yahoo.co.in  Wed Jun  6 18:04:09 2007
From: ramakanth_99 at yahoo.co.in (ramakanth reddy)
Date: Wed, 6 Jun 2007 21:34:09 +0530 (IST)
Subject: [R] problem with Axis labels
Message-ID: <969416.41943.qm@web7605.mail.in.yahoo.com>

Hi

I am using the pamr.plotsurvival fucntion to plot the KM curves,how can I change the x axis and y axis labels according to my interest.

Thanks




      Looking for people who are YOUR TYPE? Find them at in.groups.yahoo.com


From btupper at bigelow.org  Wed Jun  6 17:51:19 2007
From: btupper at bigelow.org (Ben Tupper)
Date: Wed, 06 Jun 2007 11:51:19 -0400
Subject: [R] handling a cancelled file.choose()
Message-ID: <f46l5o$r65$1@sea.gmane.org>

Hello,


I have a file reading function that prompts the user with a file dialog 
if a filename is not provided in the argument list.  It is desirable to 
return gracefully if the user selects "Cancel", but file.choose() throws 
an error instead of returning something like a character.

 > file.choose()
[1] "/Users/ben/ben_idl.pref"

 > file.choose()
Error in file.choose() : file choice cancelled

I naively planned to use nchar() to test the length, assuming 
cancellation would return a zero-length character. That appears to be 
out of the question. Are there other options available in the base package?

Thanks!
Ben


From mfay at niaid.nih.gov  Wed Jun  6 15:46:35 2007
From: mfay at niaid.nih.gov (Fay, Michael (NIH/NIAID) [E])
Date: Wed, 6 Jun 2007 09:46:35 -0400
Subject: [R] [R-pkgs] R package: Mchtest - Monte Carlo hypothesis
	testing	allowing Sequential Stopping
Message-ID: <31DDB7BE4BF41D4888D41709C476B657062E7695@NIHCESMLBX5.nih.gov>

Hi,

This is an announcement for a package that has been up on CRAN since March 2006 but was never announced.

The package is Mchtest - for Monte Carlo hypothesis tests allowing sequential stopping.  The idea is to use the sequential probability ratio test boundaries to stop resampling for a Monte Carlo hypothesis test such as a bootstrap or permutation test. This means that you will take many samples when the p-value is close to the significance level (e.g., 0.05), but you may stop after a much  fewer samples if it becomes clear that the p-value is either very likely to be less than or more than 0.05. 

The details are described in:

		Fay, MP, Kim, H-J, and Hachey, M. (2007). "On using Truncated Sequential Probability Ratio Test Boundaries for Monte Carlo Implementation of Hypothesis Tests." (to appear in Journal of Graphical and Computational Statistics).  
             http://www3.niaid.nih.gov/about/organization/dcr/BRB/staff/michael


Please let me know of any problems or if you have any comments. 


Mike

******************************************************************
Michael P. Fay, PhD
Mathematical Statistician
National Institute of Allergy and Infectious Diseases
Tel: 301-451-5124               Fax:301-480-0912
(U.S. postal mail address)                           
6700B Rockledge Drive MSC 7609
Bethesda, MD 20892-7609
(Overnight mail address)
6700-A Rockledge Drive, Room 5133
Bethesda, MD 20817
**********************************************************************

Disclaimer: 

The information in this e-mail and any of its attachments is confidential and may contain sensitive information. It should not be used by anyone who is not the original intended recipient. If you have received this e-mail in error please inform the sender and delete it from your mailbox or any other storage devices. National Institute of Allergy and Infectious Diseases shall not accept liability for any statements made that are sender's own and not expressly made on behalf of the NIAID by one of its representatives



	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages


From mfay at niaid.nih.gov  Wed Jun  6 15:34:50 2007
From: mfay at niaid.nih.gov (Fay, Michael (NIH/NIAID) [E])
Date: Wed, 6 Jun 2007 09:34:50 -0400
Subject: [R] [R-pkgs] R Package: ssanv - Sample size adjustments
	for	nonadherence and variability of input parameters
Message-ID: <31DDB7BE4BF41D4888D41709C476B657062E7694@NIHCESMLBX5.nih.gov>

Hi,

This is a late announcement for a package that has been up on CRAN since Feb 2006. 

The package is called ssanv and it calculates sample sizes for two group tests with adjustments for nonadherence and variability of the input parameters. As an example, suppose you want a sample size for a two group difference in normal means but you get your estimate of your variance from a previous study. Then with this package, you can account for the variability of that variance estimate in your sample size calculations. The details are described in:



		Fay, MP, Halloran, ME, Follmann, DA. Accounting for Variability in Sample Size Estimation with Applications to Nonadherence and Estimation of Variance and Effect Size. Biometrics 2007, 63: 465-474. http://www.blackwell-synergy.com/doi/abs/10.1111/j.1541-0420.2006.00703.x


Please let me know of any problems with the package or have any comments.

Thanks, 


Mike



******************************************************************
Michael P. Fay, PhD
Mathematical Statistician
National Institute of Allergy and Infectious Diseases
Tel: 301-451-5124               Fax:301-480-0912
(U.S. postal mail address)                           
6700B Rockledge Drive MSC 7609
Bethesda, MD 20892-7609
(Overnight mail address)
6700-A Rockledge Drive, Room 5133
Bethesda, MD 20817
**********************************************************************

Disclaimer: 

The information in this e-mail and any of its attachments is confidential and may contain sensitive information. It should not be used by anyone who is not the original intended recipient. If you have received this e-mail in error please inform the sender and delete it from your mailbox or any other storage devices. National Institute of Allergy and Infectious Diseases shall not accept liability for any statements made that are sender's own and not expressly made on behalf of the NIAID by one of its representatives



	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages


From mfay at niaid.nih.gov  Wed Jun  6 15:50:52 2007
From: mfay at niaid.nih.gov (Fay, Michael (NIH/NIAID) [E])
Date: Wed, 6 Jun 2007 09:50:52 -0400
Subject: [R] [R-pkgs] New Package: rateratio.test
Message-ID: <31DDB7BE4BF41D4888D41709C476B657062E7696@NIHCESMLBX5.nih.gov>

Hi,

I just uploaded a new package rateratio.test. The package contains one function of the same name and it performs an exact rate ratio test for Poisson counts.  Unlike binom.test and fisher.test the p-values and confidence intervals are internally consistent. In other words, if the p-value implies that the null hypothesis should be rejected, then the confidence interval also implies that the null should be rejected. There is a vignette discussing this issue.


Mike


******************************************************************
Michael P. Fay, PhD
Mathematical Statistician
National Institute of Allergy and Infectious Diseases
Tel: 301-451-5124               Fax:301-480-0912
(U.S. postal mail address)                           
6700B Rockledge Drive MSC 7609
Bethesda, MD 20892-7609
(Overnight mail address)
6700-A Rockledge Drive, Room 5133
Bethesda, MD 20817
**********************************************************************

Disclaimer: 

The information in this e-mail and any of its attachments is confidential and may contain sensitive information. It should not be used by anyone who is not the original intended recipient. If you have received this e-mail in error please inform the sender and delete it from your mailbox or any other storage devices. National Institute of Allergy and Infectious Diseases shall not accept liability for any statements made that are sender's own and not expressly made on behalf of the NIAID by one of its representatives



	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages


From ggrothendieck at gmail.com  Wed Jun  6 21:07:31 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 6 Jun 2007 15:07:31 -0400
Subject: [R] handling a cancelled file.choose()
In-Reply-To: <f46l5o$r65$1@sea.gmane.org>
References: <f46l5o$r65$1@sea.gmane.org>
Message-ID: <971536df0706061207s5acbda0dr93a0914fe69d9cd1@mail.gmail.com>

Try this:

tryCatch(file.choose(), error = function(e) "")


On 6/6/07, Ben Tupper <btupper at bigelow.org> wrote:
> Hello,
>
>
> I have a file reading function that prompts the user with a file dialog
> if a filename is not provided in the argument list.  It is desirable to
> return gracefully if the user selects "Cancel", but file.choose() throws
> an error instead of returning something like a character.
>
>  > file.choose()
> [1] "/Users/ben/ben_idl.pref"
>
>  > file.choose()
> Error in file.choose() : file choice cancelled
>
> I naively planned to use nchar() to test the length, assuming
> cancellation would return a zero-length character. That appears to be
> out of the question. Are there other options available in the base package?
>
> Thanks!
> Ben
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From hb at stat.berkeley.edu  Wed Jun  6 21:09:16 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Wed, 6 Jun 2007 21:09:16 +0200
Subject: [R] handling a cancelled file.choose()
In-Reply-To: <f46l5o$r65$1@sea.gmane.org>
References: <f46l5o$r65$1@sea.gmane.org>
Message-ID: <59d7961d0706061209x53133091wd58a0f33208745d7@mail.gmail.com>

See ?tryCatch.

Example: Function returning NULL if cancelled:

fileChoose <- function(...) {
  pathname <- NULL;
  tryCatch({
    pathname <- file.choose();
  }, error = function(ex) {
  })
  pathname;
}

/Henrik

On 6/6/07, Ben Tupper <btupper at bigelow.org> wrote:
> Hello,
>
>
> I have a file reading function that prompts the user with a file dialog
> if a filename is not provided in the argument list.  It is desirable to
> return gracefully if the user selects "Cancel", but file.choose() throws
> an error instead of returning something like a character.
>
>  > file.choose()
> [1] "/Users/ben/ben_idl.pref"
>
>  > file.choose()
> Error in file.choose() : file choice cancelled
>
> I naively planned to use nchar() to test the length, assuming
> cancellation would return a zero-length character. That appears to be
> out of the question. Are there other options available in the base package?
>
> Thanks!
> Ben
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From deepayan.sarkar at gmail.com  Wed Jun  6 21:09:52 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Wed, 6 Jun 2007 12:09:52 -0700
Subject: [R] handling a cancelled file.choose()
In-Reply-To: <f46l5o$r65$1@sea.gmane.org>
References: <f46l5o$r65$1@sea.gmane.org>
Message-ID: <eb555e660706061209w53d06c3fj1f5ec03ab6c06a64@mail.gmail.com>

On 6/6/07, Ben Tupper <btupper at bigelow.org> wrote:
> Hello,
>
>
> I have a file reading function that prompts the user with a file dialog
> if a filename is not provided in the argument list.  It is desirable to
> return gracefully if the user selects "Cancel", but file.choose() throws
> an error instead of returning something like a character.
>
>  > file.choose()
> [1] "/Users/ben/ben_idl.pref"
>
>  > file.choose()
> Error in file.choose() : file choice cancelled
>
> I naively planned to use nchar() to test the length, assuming
> cancellation would return a zero-length character. That appears to be
> out of the question. [...]

Not really, errors can be caught and handled. This seems to give the
behaviour you want:

tryCatch(file.choose(), error = function(e) "")

-Deepayan


From sarah at canaryfoundation.org  Wed Jun  6 21:44:11 2007
From: sarah at canaryfoundation.org (Sarah Hawley)
Date: Wed, 06 Jun 2007 12:44:11 -0700
Subject: [R] Multiple color schemes for barchart (lattice)
Message-ID: <C28C5C9B.7BA%sarah@canaryfoundation.org>

Hello R-help.

I am trying to make a stacked barplot where the color of the sections of
each bar depend on another variable.

> myData[1:11,]
   score   percent    marker     cellType Malignant
1      0 100.00000 ESR1 (ER) Bladder.M(5) TRUE
2      0  80.00000      PAX8 Bladder.M(5) TRUE
3      1  20.00000      PAX8 Bladder.M(5) TRUE
4      0 100.00000 ESR1 (ER)   Brain.N(3) FALSE
5      0 100.00000      PAX8   Brain.N(3) FALSE
6      3 100.00000 ESR1 (ER) Breast.M(11) TRUE
7      0 100.00000      PAX8 Breast.M(11) TRUE
8      0  36.36364 ESR1 (ER) Cervix.M(11) TRUE
9      1   9.09091 ESR1 (ER) Cervix.M(11) TRUE
10     2  18.18182 ESR1 (ER) Cervix.M(11) TRUE
11     3  36.36364 ESR1 (ER) Cervix.M(11) TRUE

palette <- palette(gray(seq(0, 1,len=4)))
trellis.par.set(list(par.xlab.text=list(cex=0.85)
                   , superpose.polygon=list(col=palette())
                   , axis.text=list(cex=0.8)))
  
 
barchart(percent~cellType|marker
        , groups=score
        , data=myData
        , stack=TRUE
        , xlab='N=Normal/Benign, M=Malignant'
        , ylab='Percentage of Cores Staining'
        , color=palette()
        , auto.key = list(points = FALSE, rectangles = TRUE, space = "top")
        , scales=list(x=list(rot=70))
        , layout=c(1,2))

I would like to make the color scheme of the bar differ according to the
variable 'Malignant' and add a second color scheme to the key.
 
Any help would be appreciated!
--Sarah

 
Sarah Hawley
Data Coordinator/Analyst
Canary Foundation
sarah at canaryfoundation.org
415.412.2533

www.canaryfoundation.org
Stopping cancer early...
the best possible investment!


From btupper at bigelow.org  Wed Jun  6 21:48:49 2007
From: btupper at bigelow.org (Ben Tupper)
Date: Wed, 06 Jun 2007 15:48:49 -0400
Subject: [R] handling a cancelled file.choose()
In-Reply-To: <eb555e660706061209w53d06c3fj1f5ec03ab6c06a64@mail.gmail.com>
References: <f46l5o$r65$1@sea.gmane.org>
	<eb555e660706061209w53d06c3fj1f5ec03ab6c06a64@mail.gmail.com>
Message-ID: <f47331$g1v$1@sea.gmane.org>

Deepayan Sarkar wrote:
> On 6/6/07, Ben Tupper <btupper at bigelow.org> wrote:
>> Hello,
>>
>>
>> I have a file reading function that prompts the user with a file dialog
>> if a filename is not provided in the argument list.  It is desirable to
>> return gracefully if the user selects "Cancel", but file.choose() throws
>> an error instead of returning something like a character.
>>
>>  > file.choose()
>> [1] "/Users/ben/ben_idl.pref"
>>
>>  > file.choose()
>> Error in file.choose() : file choice cancelled
>>
>> I naively planned to use nchar() to test the length, assuming
>> cancellation would return a zero-length character. That appears to be
>> out of the question. [...]
> 
> Not really, errors can be caught and handled. This seems to give the
> behaviour you want:
> 
> tryCatch(file.choose(), error = function(e) "")
> 
> -Deepayan

Thanks all,

I am very pleased to know about conditions in the base package.  Slick!

Ben


From h.wickham at gmail.com  Wed Jun  6 22:07:24 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Wed, 6 Jun 2007 22:07:24 +0200
Subject: [R] Multiple color schemes for barchart (lattice)
In-Reply-To: <C28C5C9B.7BA%sarah@canaryfoundation.org>
References: <C28C5C9B.7BA%sarah@canaryfoundation.org>
Message-ID: <f8e6ff050706061307r1e130969gd806a6704c9f7804@mail.gmail.com>

On 6/6/07, Sarah Hawley <sarah at canaryfoundation.org> wrote:
> Hello R-help.
>
> I am trying to make a stacked barplot where the color of the sections of
> each bar depend on another variable.
>
> > myData[1:11,]
>    score   percent    marker     cellType Malignant
> 1      0 100.00000 ESR1 (ER) Bladder.M(5) TRUE
> 2      0  80.00000      PAX8 Bladder.M(5) TRUE
> 3      1  20.00000      PAX8 Bladder.M(5) TRUE
> 4      0 100.00000 ESR1 (ER)   Brain.N(3) FALSE
> 5      0 100.00000      PAX8   Brain.N(3) FALSE
> 6      3 100.00000 ESR1 (ER) Breast.M(11) TRUE
> 7      0 100.00000      PAX8 Breast.M(11) TRUE
> 8      0  36.36364 ESR1 (ER) Cervix.M(11) TRUE
> 9      1   9.09091 ESR1 (ER) Cervix.M(11) TRUE
> 10     2  18.18182 ESR1 (ER) Cervix.M(11) TRUE
> 11     3  36.36364 ESR1 (ER) Cervix.M(11) TRUE
>
> palette <- palette(gray(seq(0, 1,len=4)))
> trellis.par.set(list(par.xlab.text=list(cex=0.85)
>                    , superpose.polygon=list(col=palette())
>                    , axis.text=list(cex=0.8)))
>
>
> barchart(percent~cellType|marker
>         , groups=score
>         , data=myData
>         , stack=TRUE
>         , xlab='N=Normal/Benign, M=Malignant'
>         , ylab='Percentage of Cores Staining'
>         , color=palette()
>         , auto.key = list(points = FALSE, rectangles = TRUE, space = "top")
>         , scales=list(x=list(rot=70))
>         , layout=c(1,2))
>
> I would like to make the color scheme of the bar differ according to the
> variable 'Malignant' and add a second color scheme to the key.

It's pretty easy to do this with ggplot2 - see
http://had.co.nz/ggplot2/position_stack.html for some examples.

Hadley


From hodgess at gator.dt.uh.edu  Wed Jun  6 22:31:44 2007
From: hodgess at gator.dt.uh.edu (Erin Hodgess)
Date: Wed, 6 Jun 2007 15:31:44 -0500
Subject: [R]  compiling from source on Vista
Message-ID: <200706062031.l56KViT3002451@gator.dt.uh.edu>

Dear R People:

In the "R Installation and Administration" manual, there is a note
that the process used to compile R from source will NOT work on Windows Vista.

Does anyone know if that situation has changed, please?

Thanks in advance!

Sincerely,
Erin Hodgess
Associate Professor
Department of Computer and Mathematical Sciences
University of Houston - Downtown
mailto: hodgess at gator.uhd.edu


From benoit.lete at gmail.com  Wed Jun  6 21:45:42 2007
From: benoit.lete at gmail.com (=?ISO-8859-1?Q?Beno=EEt_L=E9t=E9?=)
Date: Wed, 6 Jun 2007 21:45:42 +0200
Subject: [R] electre decision analysis methods
Message-ID: <98430d7a0706061245m420deaf2s76fa5a1265ce40f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070606/296838d5/attachment.pl 

From deepayan.sarkar at gmail.com  Wed Jun  6 22:44:18 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Wed, 6 Jun 2007 13:44:18 -0700
Subject: [R] Multiple color schemes for barchart (lattice)
In-Reply-To: <C28C5C9B.7BA%sarah@canaryfoundation.org>
References: <C28C5C9B.7BA%sarah@canaryfoundation.org>
Message-ID: <eb555e660706061344x30961049mcb1eb3772b95f9f5@mail.gmail.com>

On 6/6/07, Sarah Hawley <sarah at canaryfoundation.org> wrote:
> Hello R-help.
>
> I am trying to make a stacked barplot where the color of the sections of
> each bar depend on another variable.
>
> > myData[1:11,]
>    score   percent    marker     cellType Malignant
> 1      0 100.00000 ESR1 (ER) Bladder.M(5) TRUE
> 2      0  80.00000      PAX8 Bladder.M(5) TRUE
> 3      1  20.00000      PAX8 Bladder.M(5) TRUE
> 4      0 100.00000 ESR1 (ER)   Brain.N(3) FALSE
> 5      0 100.00000      PAX8   Brain.N(3) FALSE
> 6      3 100.00000 ESR1 (ER) Breast.M(11) TRUE
> 7      0 100.00000      PAX8 Breast.M(11) TRUE
> 8      0  36.36364 ESR1 (ER) Cervix.M(11) TRUE
> 9      1   9.09091 ESR1 (ER) Cervix.M(11) TRUE
> 10     2  18.18182 ESR1 (ER) Cervix.M(11) TRUE
> 11     3  36.36364 ESR1 (ER) Cervix.M(11) TRUE
>
> palette <- palette(gray(seq(0, 1,len=4)))
> trellis.par.set(list(par.xlab.text=list(cex=0.85)
>                    , superpose.polygon=list(col=palette())
>                    , axis.text=list(cex=0.8)))
>
>
> barchart(percent~cellType|marker
>         , groups=score
>         , data=myData
>         , stack=TRUE
>         , xlab='N=Normal/Benign, M=Malignant'
>         , ylab='Percentage of Cores Staining'
>         , color=palette()
>         , auto.key = list(points = FALSE, rectangles = TRUE, space = "top")
>         , scales=list(x=list(rot=70))
>         , layout=c(1,2))
>
> I would like to make the color scheme of the bar differ according to the
> variable 'Malignant' and add a second color scheme to the key.

I may not have understood what you are looking for, but it seems like
you just need

groups = interaction(score, Malignant)

For example,

palette <- palette(gray(seq(0, 1,len=8)))

trellis.par.set(list(par.xlab.text=list(cex=0.85)
                  , superpose.polygon=list(col=palette())
                  , axis.text=list(cex=0.8)))

barchart(percent~cellType|marker
       , groups= interaction(score, Malignant)
       , data=myData
       , stack=TRUE
       , xlab='N=Normal/Benign, M=Malignant'
       , ylab='Percentage of Cores Staining'
       # , color=palette() # not doing anything
       , auto.key = list(points = FALSE, rectangles = TRUE, space =
"top", columns = 2)
       , scales=list(x=list(rot=70))
       , layout=c(1,2))

-Deepayan


From stubben at lanl.gov  Wed Jun  6 22:47:43 2007
From: stubben at lanl.gov (Chris Stubben)
Date: Wed, 6 Jun 2007 20:47:43 +0000 (UTC)
Subject: [R] Question: RMySQL bulk load/update one column,
	dbWriteTable()?
References: <8ee9d8f20706060944v5b05216fl6bc3246321a89f0d@mail.gmail.com>
Message-ID: <loom.20070606T223428-219@post.gmane.org>


> I have a question reading using RMySQL trying to load one R vector into a
> table column.  To be more specifically, the table is there populated.  Now I
> add a new column and want to populate this.
> 


Okay, this is more of an SQL question now, but you could just use dbWriteTable
and then do an multi-table update.



dbGetQuery(con, "select * from tmp")

  id name
1  1    A
2  2    B
3  3    C
4  4    D
5  5    E


dbSendQuery(con, "alter table tmp add column r2 float")

## calculate some statistic for all or some ids in table


x<-dataframe(id=1:5, r2=c(.1, .4, .9, .4,.7))


dbWriteTable(con, "r2tmp",  x )


dbSendQuery(con, "update tmp t, r2tmp r set t.r2=r.r2 where t.id=r.id")


dbGetQuery(con, "select * from tmp")

  id name  r2
1  1    A 0.1
2  2    B 0.4
3  3    C 0.9
4  4    D 0.4
5  5    E 0.7


Chris


From david.ledu at yahoo.ca  Wed Jun  6 22:55:09 2007
From: david.ledu at yahoo.ca (David LEDU)
Date: Wed, 6 Jun 2007 13:55:09 -0700 (PDT)
Subject: [R] Spectral analysis
Message-ID: <46552.59149.qm@web59004.mail.re1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070606/91e8efbf/attachment.pl 

From artem.mariupol at gmail.com  Wed Jun  6 23:08:29 2007
From: artem.mariupol at gmail.com (Artem Mariupol)
Date: Wed, 6 Jun 2007 14:08:29 -0700 (PDT)
Subject: [R] correspondence analysis
In-Reply-To: <loom.20070606T132031-749@post.gmane.org>
References: <bfb35b70706052345t1d40bf88l48942296d9d5ea68@mail.gmail.com>
	<loom.20070606T132031-749@post.gmane.org>
Message-ID: <10997356.post@talk.nabble.com>



Thanks very much Jari, I appreciate your guidance.
I trust R very much, the only thing I can do is to dig up the methodology
behind the SPSS result (and of course behind the correspondence analysis
itself).
Regards,
am


Jari Oksanen wrote:
> 
> Artem Mariupol <artem.mariupol <at> gmail.com> writes:
> 
>> 
>> Hello,
>> 
>> I am new to R and I have a question about the difference between
>> correspondence analysis in R and SPSS.
>> This is the input table I am working with (4 products and 18 attributes):
>> 
>> > mytable
>>    1  2  3  4  5 6  7  8  9 10 11 12 13 14 15 16 17 18
>> 1 15 11 20  4 14 7  1  2  1  4 12 12 17 19 11 20  9 10
>> 2 19 18 14 14 16 4 14 11 11 15 22 19 22 16 21 19 15 16
>> 3 16 13 10  9 15 4 10  7 11 13 18 17 14 14 16 16 13 11
>> 4 21 18 16 14 20 6 12 14 14 17 23 20 19 18 21 18 19 18
>> 
>> I found the function corresp() in the package MASS, but the results are
>> different from the output in SPSS. Also, I don't understand the
>> coordinates;
>> in the biplot I cannot find a -2 limit for example from the first product
>> on
>> any of the x axes.
>> 
> At a quick look, there is nothing strange in the result. Have you
> contacted SPSS
> and asked them to explain their deviant results?
> 
> It seems that biplot.correspondence is undocumented. However, it has
> argument
> 'type' which defaults to "symmetric", other alternative being "rows" and
> "columns". Intelligent guess is that this selects the scaling of row and
> column
> scores, and type="symmetric" scales both. By selecting type="columns",
> only
> columns are scaled and the -2 value for a row will be displayed (which
> proves
> that the guess was correct).
> 
> I don't have a clue how SPSS scales results, but I guess that the
> differences in
> the results may be due to different scalings. Function corresp gives you
> weighted orthonormal row and column scores, but scales these in the plot
> like
> specified. It may be that SPSS does the scaling already in the printout
> (and
> does not give you the choice of type?). Another possible source of
> difference is
> that corresp gives you "canonical correlations" whereas some other program
> or
> function may give you their squares, a.k.a. eigenvalues. Moreover, the
> sign is
> arbitrary so that negative and positive scores may be switched between
> programs. 
> 
> I hope this helps, 
> 
> Jari Oksanen
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/correspondence-analysis-tf3876129.html#a10997356
Sent from the R help mailing list archive at Nabble.com.


From ted.harding at nessie.mcc.ac.uk  Wed Jun  6 23:34:21 2007
From: ted.harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Wed, 06 Jun 2007 22:34:21 +0100 (BST)
Subject: [R] Spectral analysis
In-Reply-To: <46552.59149.qm@web59004.mail.re1.yahoo.com>
Message-ID: <XFMail.070606223421.ted.harding@nessie.mcc.ac.uk>

On 06-Jun-07 20:55:09, David LEDU wrote:
> Hi all,
> 
> I am dealing with paleoceanographic data and I have a C14 time serie
> and one other variable. I would like to perform a spectral analysis
> (fft or wavelet) and plot it. Unfortunately I don't know the exact
> script to do this. Does anybody could send me an example to perform my
> spectral analysis ?
> 
> I Thank you
> 
> David

There are a lot of possible ramifications to your query,
but for a basic spectral analysis of a series you can use
the function spectrum() in the "stats" package.

What is the role of the "other variable"?

Best wishes,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 06-Jun-07                                       Time: 22:34:07
------------------------------ XFMail ------------------------------


From kpackard at vt.edu  Wed Jun  6 23:42:19 2007
From: kpackard at vt.edu (Kevin C Packard)
Date: Wed,  6 Jun 2007 17:42:19 -0400
Subject: [R] Metropolis-Hastings Markov Chain Monte Carlo in Spatstat
Message-ID: <1181166139.46672a3b2be01@webmail.vt.edu>

I'm testing some different formulations of pairwise interaction point processes
in Spatstat (version 1.11-6) using R 2.5.0 on a Windows platform and I wish to
simulate them using the Metropolis-Hastings algorithm implemented with Spatstat.
Spatstat utilizes Fortran77 code with the preprocessor RatFor to do the
Metropolis-Hastings MCMC, but the Makefile is more complicated than any I have
worked with.
Any suggestions on how I could get started working with the Fortran code in
conjunction with RatFor is appreciated.

Sincerely,
Kevin

Kevin Packard
Department of Forestry, PhD student
Department of Statistics, MS student
Virginia Polytechnic Institute and State University
Blacksburg, Virginia, USA


From waverley.paloalto at gmail.com  Wed Jun  6 23:54:08 2007
From: waverley.paloalto at gmail.com (Waverley)
Date: Wed, 6 Jun 2007 14:54:08 -0700
Subject: [R] Question: RMySQL bulk load/update one column,
	dbWriteTable()?
In-Reply-To: <loom.20070606T223428-219@post.gmane.org>
References: <8ee9d8f20706060944v5b05216fl6bc3246321a89f0d@mail.gmail.com>
	<loom.20070606T223428-219@post.gmane.org>
Message-ID: <8ee9d8f20706061454l749c624ew3332f888de93211f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070606/90dca445/attachment.pl 

From rkoenker at uiuc.edu  Thu Jun  7 00:09:46 2007
From: rkoenker at uiuc.edu (roger koenker)
Date: Wed, 6 Jun 2007 17:09:46 -0500
Subject: [R] Metropolis-Hastings Markov Chain Monte Carlo in Spatstat
In-Reply-To: <1181166139.46672a3b2be01@webmail.vt.edu>
References: <1181166139.46672a3b2be01@webmail.vt.edu>
Message-ID: <69823012-4816-4185-8968-E9AFC639FA2E@uiuc.edu>

Take a look at:  http://sepwww.stanford.edu/software/ratfor.html
and in particular the link there to the original paper by Brian
Kernighan describing ratfor; it is only 14 pages, but it is a model
of clarity of exposition and design.

I wouldn't worry too much about the makefile  -- it probably
knows exactly what to do with ratfor provided you have the
ratfor preprocessor available from the above link, and the rest
of the tools to build from source.

url:    www.econ.uiuc.edu/~roger            Roger Koenker
email    rkoenker at uiuc.edu            Department of Economics
vox:     217-333-4558                University of Illinois
fax:       217-244-6678                Champaign, IL 61820


On Jun 6, 2007, at 4:42 PM, Kevin C Packard wrote:

> I'm testing some different formulations of pairwise interaction  
> point processes
> in Spatstat (version 1.11-6) using R 2.5.0 on a Windows platform  
> and I wish to
> simulate them using the Metropolis-Hastings algorithm implemented  
> with Spatstat.
> Spatstat utilizes Fortran77 code with the preprocessor RatFor to do  
> the
> Metropolis-Hastings MCMC, but the Makefile is more complicated than  
> any I have
> worked with.
> Any suggestions on how I could get started working with the Fortran  
> code in
> conjunction with RatFor is appreciated.
>
> Sincerely,
> Kevin
>
> Kevin Packard
> Department of Forestry, PhD student
> Department of Statistics, MS student
> Virginia Polytechnic Institute and State University
> Blacksburg, Virginia, USA
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From toby909 at gmail.com  Thu Jun  7 00:16:24 2007
From: toby909 at gmail.com (toby909 at gmail.com)
Date: Wed, 06 Jun 2007 15:16:24 -0700
Subject: [R] opening a file from within a zipfile that is online
Message-ID: <f47bja$fd4$1@sea.gmane.org>

Hi

Reading the help for ?unz I was wondering if I can read data into R from within 
an zipfile that is on some website, like maybe:

dtaa = 
read.table(unz("http://www.ats.ucla.edu/stat/examples/alsm/alsm.zip","Ch01pr19.dat"))

Thanks for letting me know if you came acros such a thing before.

Toby


From davamaillist at gmail.com  Thu Jun  7 00:27:30 2007
From: davamaillist at gmail.com (david dav)
Date: Thu, 7 Jun 2007 00:27:30 +0200
Subject: [R] names not inherited in functions
Message-ID: <772cb06e0706061527l6a5bcabem7566811c5b7c4657@mail.gmail.com>

Dear all,

I 'd like to keep the names of variables when calling them in a function.
An example might help to understand my problem :

The following function puts in a new data frame counts and percent of
a data.frame called as "tablo"
the step " nom.chiffr[1] <- names(vari) " is useless as names from the
original data.frame aren't kept in the function environement.

Hoping I use appropriate R-vocabulary, I thank you for your help

David

descriptif <- function (tablo) {
	descriptifvar <- function (vari) {
		table(vari)
		length(vari[!is.na(vari)])
		chiffr <- cbind(table(vari),100*table(vari)/(length(vari[!is.na(vari)])))
		nom.chiffr <- rep(NA, dim(table(vari)))
		if (is.null(names(vari))) nom.chiffr[1] <- paste(i,"") else
		nom.chiffr[1] <- names(vari)
		chiffr <- data.frame (  names(table(vari)),chiffr)
		rownames(chiffr) <- NULL
		chiffr <- data.frame (nom.chiffr, chiffr)
	return(chiffr)
	}
	
	res <- rep(NA, 4)
	for (i in 1 : ncol(tablo))
		res <- rbind(res,descriptifvar(tablo[,i]))
	colnames(res) <- c("variable", "niveau", "effectif", "pourcentage")
return(res[-1,])
}	
# NB I used this function on a data.frame with only factors in


From harschm at lincoln.ac.nz  Thu Jun  7 00:36:47 2007
From: harschm at lincoln.ac.nz (Melanie Ann Harsch)
Date: Thu, 07 Jun 2007 10:36:47 +1200
Subject: [R] error message: only first element in each line of matrix used
Message-ID: <4667DFBF.6514.F3E96@harschm.lincoln.ac.nz>

I have a matrix and am trying to write a code to
1. identify all neg values along each line
2. for each neg value I need to identify min(j+3)
3. end with this code: eq[i,j]<- ifelse(mat.r[i,j] < (0.5*mat.s[i,j]), mat.all[i,j], 0)

This is the code I have so far.  I have tried several different methods but I 
keep getting the same error message that the condition has length >1 and 
only the first element will be used.
Any suggestions?

int <- 3
	for(i in 1:nrow(mat.all)) {
        start.year <- min(which(is.na(mat.all[i,])==F & (mat.all[i,]<0)))
        fin.year <- max(which(is.na(mat.all[i,])==F))  
		for(j in start.year:fin.year) {
			if(mat.all[i,(j-int):(j-1)]<0){
      mat.s[i,j] <- ifelse((mat.all[i,(j-int):(j-1)])==pmin, mat.all[i,j], 0);
		  mat.r [i,j] <- which.max((mat.all[i,(j+1):(j+int)]) > 0) }
		  }}


From gavin.simpson at ucl.ac.uk  Thu Jun  7 01:16:28 2007
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Thu, 07 Jun 2007 00:16:28 +0100
Subject: [R] Spectral analysis
In-Reply-To: <46552.59149.qm@web59004.mail.re1.yahoo.com>
References: <46552.59149.qm@web59004.mail.re1.yahoo.com>
Message-ID: <1181171788.3088.5.camel@dhcppc2.my.nat.localnet>

On Wed, 2007-06-06 at 13:55 -0700, David LEDU wrote:
> Hi all,
> 
> I am dealing with paleoceanographic data and I have a C14 time serie
> and one other variable. I would like to perform a spectral analysis
> (fft or wavelet) and plot it. Unfortunately I don't know the exact
> script to do this. Does anybody could send me an example to perform my
> spectral analysis ?
> 
> I Thank you
> 
> David

Invariably data of this nature are irregularly sampled in time, so you
should check whether the in-built spectrum() function is suitable for
your core data. I'm not aware of much else available in R, but one thing
I am aware of is a paper and R code by Mathias et al in the Journal of
Statistical Software:

http://www.jstatsoft.org/index.php?vol=11

It is issue 2 in that volume. This might be more suitable given your
data. The code is a few years old now and there isn't a ready built
package on CRAN so you'll have to compile it yourself.

HTH

G

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [t] +44 (0)20 7679 0522
ECRC                              [f] +44 (0)20 7679 0565
UCL Department of Geography
Pearson Building                  [e] gavin.simpsonATNOSPAMucl.ac.uk
Gower Street
London, UK                        [w] http://www.ucl.ac.uk/~ucfagls/
WC1E 6BT                          [w] http://www.freshwaters.org.uk/
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From michael_bibo at health.qld.gov.au  Thu Jun  7 02:13:04 2007
From: michael_bibo at health.qld.gov.au (Michael Bibo)
Date: Thu, 7 Jun 2007 00:13:04 +0000 (UTC)
Subject: [R] Mandriva Spring 2007 and R
References: <37204.62935.qm@web62412.mail.re1.yahoo.com>
	<46658B8E.9090401@gmail.com>
Message-ID: <loom.20070607T020436-156@post.gmane.org>

Roland Rau <roland.rproject <at> gmail.com> writes:

> 
> Hi Jonathan,
> 
> Jonathan Morse wrote:
> > I am new to Linux (not to R) and recently installed Mandriva Spring 2007 
on my partitioned hard drive.  My
> next objective is to install R in the Linux environment, unfortunately 
Mandriva is not one of the Linux
> distributions available for download...  Could someone please let me know 
which distribution I should
> use?  
> > 
> One possibility is, of course, that you compile it yourself for your 
> computer. Compiling R was my first shot at compiling programs when I was 
> new to Linux, and it was not very difficult. It is described nicely in 
> the R Installation Administration Manual.
> http://cran.r-project.org/doc/manuals/R-admin.html
> 
> Basically, you only need to take care of the following steps to get you 
> started:
> - did you download and unpack the source distribution (see section 1.1 
> of the manual)?
> - do you have the required tools installed (see section A.1 of the 
> manual)? (C compiler, Fortran compiler, libreadline, libjpeg, libpng, 
> tex/latex, Perl5, xorg-x11-dev)
> - compilation (see section 2.1 in the manual)
> 
> I hope this helps?
> 
> Best,
> Roland
> 
> ______________________________________________
> R-help <at> stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
Just to add to Roland's comments - remember to install the "-dev" packages for 
all of the tools he mentions.  I learned this from the R installation manual, 
and it has been valuable in installing other software from source.  The output 
from "./configure" will usually tell you if something is missing.

Personally, I no longer use Mandriva, but comments I made re v10.1 may or may 
not be relevant: http://finzi.psych.upenn.edu/R/Rhelp02a/archive/54320.html.

Hope this helps,

Michael


From jholtman at gmail.com  Thu Jun  7 02:56:34 2007
From: jholtman at gmail.com (jim holtman)
Date: Wed, 6 Jun 2007 20:56:34 -0400
Subject: [R] error message: only first element in each line of matrix
	used
In-Reply-To: <4667DFBF.6514.F3E96@harschm.lincoln.ac.nz>
References: <4667DFBF.6514.F3E96@harschm.lincoln.ac.nz>
Message-ID: <644e1f320706061756h57f12d9cvefe32270ccb6280b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070606/cc2520a8/attachment.pl 

From ssls.sddd at gmail.com  Thu Jun  7 03:22:21 2007
From: ssls.sddd at gmail.com (ssls sddd)
Date: Thu, 7 Jun 2007 09:22:21 +0800
Subject: [R] How to load a big txt file
Message-ID: <b87120290706061822h2794512av24762fa964d12905@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070607/0000f592/attachment.pl 

From ggrothendieck at gmail.com  Thu Jun  7 03:34:48 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 6 Jun 2007 21:34:48 -0400
Subject: [R] name of the variable that will contain the result of a
	function
In-Reply-To: <E2350202-E64C-4E64-B958-D624926FE56F@jhsph.edu>
References: <E2350202-E64C-4E64-B958-D624926FE56F@jhsph.edu>
Message-ID: <971536df0706061834g1c24c13dv9ce6be5b6ae55b51@mail.gmail.com>

Don't think you can do that but you could respecify your function
so that the assigned variable must appear as the first argument:

foo <- function(y, arg) {
	y <- substitute(y)
	if (is.name(y)) assign(deparse(y), arg+1, parent.frame())
	else cat("not assigned\n")
	invisible()
}

if (exists("zz")) rm(zz)
foo(zz, 3)
zz
foo(zz, 4)
zz

xx <- foo(zz, 99)
xx
zz
foo(0, 99)
foo(x+1, 99)


On 6/6/07, Benilton Carvalho <bcarvalh at jhsph.edu> wrote:
> Hi everyone,
>
> say I have a function called 'foo', which takes the argument arg1.
>
> Is there any mechanism that I can use to "learn" about the variable
> where foo(arg1) is going to be stored?
>
> For example:
>
> x <- foo(arg1)
>
> so, inside foo() I'd like to be able to get the string "x".
>
> if,
>
> foo(arg1)
>
> was used insted, I'd like to get NA.
>
> thank you very much,
>
> b
>
>
>
>
>
>
> --
> Benilton Carvalho
> PhD Candidate
> Department of Biostatistics
> Bloomberg School of Public Health
> Johns Hopkins University
> bcarvalh at jhsph.edu
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From alex_restrepo at hotmail.com  Thu Jun  7 04:08:08 2007
From: alex_restrepo at hotmail.com (Alex Restrepo)
Date: Wed, 06 Jun 2007 21:08:08 -0500
Subject: [R] Problem Building on Solaris 8
Message-ID: <BAY122-F3283AEAC4A43073E95FF7E98260@phx.gbl>

Hello:

I am building R-2.5.0 on Solaris 8 with gcc version 3.3 and I am getting the 
following error. Could someone please help me with this?

Error in dyn.load(x, as.logical(local), as.logical(now)) :
        unable to load shared library 
'/mmrg/temp/R-2.5.0/library/stats/libs/stats.so':
  ld.so.1: R: fatal: relocation error: file 
/mmrg/temp/R-2.5.0/library/stats/libs/stats.so: symbol _g95_power_i4_i4: 
referenced symbol not found
Execution halted
*** Error code 1
make: Fatal error: Command failed for target `all'
Current working directory /mmrg/temp/R-2.5.0/src/library/datasets
*** Error code 1
make: Fatal error: Command failed for target `R'
Current working directory /mmrg/temp/R-2.5.0/src/library
*** Error code 1
make: Fatal error: Command failed for target `R'
Current working directory /mmrg/temp/R-2.5.0/src
*** Error code 1
make: Fatal error: Command failed for target `R'

_________________________________________________________________
Picture this ? share your photos and you could win big!


From jdnewmil at dcn.davis.ca.us  Thu Jun  7 04:12:22 2007
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 06 Jun 2007 19:12:22 -0700
Subject: [R] Re : I need some help please!
In-Reply-To: <1180823691.4661f08b460a8@www.usherbrooke.ca>
References: <1180823691.4661f08b460a8@www.usherbrooke.ca>
Message-ID: <46676986.8090703@dcn.davis.ca.us>

Bernard Colin wrote:
> To whom it may concern,
> 
> I want to plot two or more graphics in the same window by the means of the
> "plot" command. To do that, I have tried the "add=TRUE" option, but this last
> one does not work! Do you have an hint for me please?

Assuming you want to overlay multiple data sets on the same axes, verify 
that in your first plot statement you got your axis ranges wide enough to 
capture all your data sets, because they won't adjust when you add data.

If you want adjacent plots in the same window, use lattice (trellis) graphics.

-- 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From spencer.graves at pdf.com  Thu Jun  7 04:21:13 2007
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 06 Jun 2007 19:21:13 -0700
Subject: [R] factor analysis
In-Reply-To: <772B523A-3B9D-4B36-B63E-63B68A223A35@lautloscrew.com>
References: <772B523A-3B9D-4B36-B63E-63B68A223A35@lautloscrew.com>
Message-ID: <46676B99.2070205@pdf.com>

      I haven't seen an answer to this post, so I thought I would try to 
generate a response. 

      Regarding your first question (Can i use this factor analysis 
somehow despite the poor cumulative variance of the first three factors 
?), I would ask, "for what purpose?"  And, "What are the alternatives?" 

      The second question on the null hypothesis can be answered by 
looking at the degrees of freedom:  That will often identify the null 
hypothesis for a test with a chi-square statistic.  Let p = number of 
original variables, which I assume is 10 in your case as you list 10 
eigenvalues.  Let f = number of factors = 3 in your case.  The degrees 
of freedom is the number of free parameters estimated in a model.  With 
two nested models, the degrees of freedom is the difference in the 
numbers of parameters estimated in the two models. 

      I can think of several obvious hypotheses, in this case:  The two 
extremes are that there are no significant correlations and that a 
saturated model is required.  The former requires no parameters to 
estimate the correlation matrix, while the latter requires choose(p, 2) 
= 45 with p = 10.  To estimate a model with only one factor requires p 
parameters, one for the eigenvalue and (p-1) for the eigenvector / 
direction / factor loadings.  (The sums of squares of the elements of 
each eigenvector = 1.  The factor loadings = the eigenvector times the 
square root of the corresponding eigenvalue.)  Thus, the free parameters 
for a one-factor model = 10.  If this hypothesis compared one factor to 
none, the degrees of freedom would be 10 - 0 = 10.  Similarly, if the 
null hypothesis were saturated, the degrees of freedom would be 45 - 10 
= 35. 

      Next consider a 2-factor model.  In addition to the p coefficients 
estimated for one factor, we must estimate an additional p-1, one 
eigenvalue and p-2 for a unit vector orthogonal to the one we already 
have.  This is 19 degrees of freedom.  Similarly for a 3-factor model, 
we must estimate an additional p-2 parameter, one eigenvalue plus p-3 
for a unit vector orthogonal to the two we already have.  This gives us 
19 + 8 = 27.  Finally a 4-factor model would require estimating p-3 
additional parameters for a total of 34. 

      Now compare the degrees of freedom for the 3-factor model with all 
the others just listed to find one where the difference is the number 
you got, 18.  If we do this we find that 45 - 27 = 18.  From this, we 
conclude that the null hypothesis is the saturated model, i.e., no 
factor structure identifiable from these data. 

      As a check, let's look at your 4-factor model:  45 - 34 = 11.  
This says that your 4-factor model is NOT significantly different from a 
saturated model, i.e., it is adequate.  Returning to the 3-factor model, 
the low p-value in that case says that 3 factors is not enough:  4 
factors provides a more accurate representation. 

      Does this make sense? 

      Note, however, that the above assumes your observations are all 
statistically independent.  If that's not the case, then the assumptions 
behind this test are not satisfied.  Similarly, if the observations are 
not normally distributed, you can't trust this test.  I often check 
normality using 'qqnorm'.  However, if your observations were collected 
in batches, for example, then I would not expect them to be independent. 

      Finally, even though this analysis suggest that a 4-factor model 
is better, I might still use the 3-factor model if it gave me something 
I could interpret and the 4-factor model didn't. 

      Hope this helps. 
      Spencer Graves
p.s.  I might have answered this a day or two earlier, but the lack of a 
simple, self-contained example meant that I would have to work harder to 
understand your question and craft an answer.      

bunny , lautloscrew.com wrote:
> Hi there,
>
> i?ve trouble understanding the factanal output of R.
> i am running a a FA on a dataset with 10 variables.
>
> i plotted eigenvalues to finde out how many factors to try.
> i think the "elbow" is @ 3 factors.
> here are my eigenvalues: 2.6372766 1.5137754 1.0188919 0.8986154  
> 0.8327583 0.7187473 0.6932792 0.5807489 0.5709594 0.5349477
> (of the correlation matrix)
>
> i guess this is basically what screeplot does as well.
>
> and here?s my problem:
> unfortunately the cumulative variance @ 3 factors is only .357
> there are no crossloadings and the interpretation of the factors and  
> their loadings definetely make sense so far.
>
> Can i use this factor analysis somehow despite the poor cumulative  
> variance of the first three factors ?
> changing the rotation didnt help much.
>
> The test of the hypothesis says the following:
>
> Test of the hypothesis that 3 factors are sufficient.
> The chi square statistic is 46.58 on 18 degrees of freedom.
> The p-value is 0.000244
>
> does this mean the Hnull is that 3 factors are sufficient and i cant  
> recject ?
>
>
> 4 factors say:
> Test of the hypothesis that 4 factors are sufficient.
> The chi square statistic is 10.82 on 11 degrees of freedom.
> The p-value is 0.458
>
> Unfortunately ?factanal does not tell me what the Hnull is in this  
> case ?
>
> Thx a lot in advance for some advice
>
> matthias
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From chainsawtiney at gmail.com  Thu Jun  7 04:45:52 2007
From: chainsawtiney at gmail.com (Chung-hong Chan)
Date: Thu, 7 Jun 2007 10:45:52 +0800
Subject: [R] How to load a big txt file
In-Reply-To: <b87120290706061822h2794512av24762fa964d12905@mail.gmail.com>
References: <b87120290706061822h2794512av24762fa964d12905@mail.gmail.com>
Message-ID: <30d7ea360706061945p50628332mab84a5fe65eec73f@mail.gmail.com>

Easy solution will be split your big txt files by text editor.

e.g. 5000 rows each.

and then combine the dataframes together into one.



On 6/7/07, ssls sddd <ssls.sddd at gmail.com> wrote:
> Dear list,
>
> I need to read a big txt file (around 130Mb; 23800 rows and 49 columns)
> for downstream clustering analysis.
>
> I first used "Tumor <- read.table("Tumor.txt",header = TRUE,sep = "\t")"
> but it took a long time and failed. However, it had no problem if I just put
> data of 3 columns.
>
> Is there any way which can load this big file?
>
> Thanks for any suggestions!
>
> Sincerely,
>      Alex
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
"The scientists of today think deeply instead of clearly. One must be
sane to think clearly, but one can think deeply and be quite insane."
Nikola Tesla
http://www.macgrass.com


From spencer.graves at pdf.com  Thu Jun  7 04:55:02 2007
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 06 Jun 2007 19:55:02 -0700
Subject: [R] R-squared in mixed-effects models
In-Reply-To: <1180992730.d4ba0629fdf7a@webmail6.leeds.ac.uk>
References: <1180992730.d4ba0629fdf7a@webmail6.leeds.ac.uk>
Message-ID: <46677386.2010706@pdf.com>

      RSiteSearch("R^2 in lme") produced 34 hits for me just now, 
including 5 from an exchange on this list dated 2007.05.14. 

      They should answer your question better than I can. 

      Hope this helps. 
      Spencer Graves

Richard Gunton wrote:
> Hello,
>
> I'm fitting general linear models using the function lme() from the package
> nlme.  My variables include a number of covariates and a single random factor,
> because the experiment was laid out in blocks.  I'd like to have a statistic to
> measure the "proportion of explained variance" from my models.  With ordinary
> multiple regression I'd use R-squared, but I can't find any similar items in
> the output from lme().  Does anyone know something I can use in these or any
> other package?
>
> Thanks,
>
> Richard.
>
> --
> Richard Gunton
> PhD student - Ecology and Evolution group
> School of Biology, University of Leeds, LS2 9JT, UK
> Room 10.16, Miall Building   Tel: 0113 3432825
>
> http://www.personal.leeds.ac.uk/~bgyrg
>
> ~ Opinions expressed in this message are not attributable to the University of
> Leeds ~
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From sue at xlsolutions-corp.com  Thu Jun  7 05:07:51 2007
From: sue at xlsolutions-corp.com (Sue Turner)
Date: Wed, 06 Jun 2007 20:07:51 -0700
Subject: [R] Dr Bill Venables course in Raleigh and Washington DC -
	Traditional and Modern Approaches to Statistical Modelling with R by
Message-ID: <20070606200751.aa8924c5d28ca71e2a043bb294e795eb.2218e81ce5.wbe@email.secureserver.net>

Greetings!
 
We've added Raleigh***July 09-10 as a second US destination for Dr
Venables'  "Traditional and Modern Approaches to Statistical Modelling
with R" course.
 
We still have seats for the following July courses:
 
(1) Traditional and Modern Approaches to Statistical Modelling with R by
Dr Bill Venables. 
*** Raleigh, NC 7/9/2007 7/10/2007 *** 
*** Washington, DC 7/12/2007 7/13/2007 *** 
 
(2) R/S Fundamentals and Programming Techniques 
*** Boston / July 16-17, 2007   ***

(3) Data Mining: Practical Tools and Techniques in R/Splus  
*** Las Vegas 6/28/2007 6/29/2007 ***
 
Payment due AFTER the class
 Email us for group discounts. 
 Email Sue Turner: sue at xlsolutions-corp.com 
 Phone: 206-686-1578 
 Visit us: www.xlsolutions-corp.com/courselist.htm 
 Please let us know if you and your colleagues are interested in this 
 class to take advantage of group discount. Register now to secure your 
 seat! 
 
 Cheers, 
 Elvis Miller, PhD 
 Manager Training. 
 XLSolutions Corporation 
 206 686 1578 
 www.xlsolutions-corp.com


From nj7w at yahoo.com  Thu Jun  7 05:34:37 2007
From: nj7w at yahoo.com (Nitin Jain)
Date: Wed, 6 Jun 2007 20:34:37 -0700 (PDT)
Subject: [R] Question about parse and expression
Message-ID: <637616.76675.qm@web50207.mail.re2.yahoo.com>

Dear R-users,

In the following example, I would like to see my ylabel as: "beta[3] * x[3] + epsilon" (where beta and epsilon are replaced by their mathematical symbols).

Please advise.

Thanks.

Nitin


i <- 3

ee <- expression(beta[i] * x[i] + epsilon)

xyplot(1:10~ 11:20,
       ylab = parse(text=ee)
       )
   



 
____________________________________________________________________________________
8:00? 8:25? 8:40? Find a flick in no time


From cberry at tajo.ucsd.edu  Thu Jun  7 05:35:50 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Wed, 6 Jun 2007 20:35:50 -0700
Subject: [R] How to load a big txt file
In-Reply-To: <b87120290706061822h2794512av24762fa964d12905@mail.gmail.com>
References: <b87120290706061822h2794512av24762fa964d12905@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0706062023540.26604@tajo.ucsd.edu>


Alex,

See

 	R Data Import/Export Version 2.5.0 (2007-04-23)

search for 'large' or 'scan'.

Usually, taking care with the arguments

 	nlines, what, quote, comment.char

should be enough to get scan() to cooperate.

You will need around 1GB RAM to store the result, so if you are working on 
a machine with less, you will need to upgrade. Consider storing the result 
as a numeric matrix.

If any of those columns are long strings not needed in your computation, 
be sure to skip over them. Read the 'Details' of the help page for scan() 
carefully.

Chuck


On Thu, 7 Jun 2007, ssls sddd wrote:

> Dear list,
>
> I need to read a big txt file (around 130Mb; 23800 rows and 49 columns)
> for downstream clustering analysis.
>
> I first used "Tumor <- read.table("Tumor.txt",header = TRUE,sep = "\t")"
> but it took a long time and failed. However, it had no problem if I just put
> data of 3 columns.
>
> Is there any way which can load this big file?
>
> Thanks for any suggestions!
>
> Sincerely,
>     Alex
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	         UC San Diego
http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0901


From cberry at tajo.ucsd.edu  Thu Jun  7 05:39:32 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Wed, 6 Jun 2007 20:39:32 -0700
Subject: [R] How to load a big txt file
In-Reply-To: <Pine.LNX.4.64.0706062023540.26604@tajo.ucsd.edu>
References: <b87120290706061822h2794512av24762fa964d12905@mail.gmail.com>
	<Pine.LNX.4.64.0706062023540.26604@tajo.ucsd.edu>
Message-ID: <Pine.LNX.4.64.0706062037020.26604@tajo.ucsd.edu>

On Wed, 6 Jun 2007, Charles C. Berry wrote:

>
> Alex,
>
> See
>
> 	R Data Import/Export Version 2.5.0 (2007-04-23)
>
> search for 'large' or 'scan'.
>
> Usually, taking care with the arguments
>
> 	nlines, what, quote, comment.char
>
> should be enough to get scan() to cooperate.
>
> You will need around 1GB RAM to store the result, so if you are working on a

Oops. 23800*49*8 == 9329600 is more like 0.01GB, I guess.


> machine with less, you will need to upgrade. Consider storing the result as a 
> numeric matrix.
>
> If any of those columns are long strings not needed in your computation, be 
> sure to skip over them. Read the 'Details' of the help page for scan() 
> carefully.
>
> Chuck
>
>
> On Thu, 7 Jun 2007, ssls sddd wrote:
>
>>  Dear list,
>>
>>  I need to read a big txt file (around 130Mb; 23800 rows and 49 columns)
>>  for downstream clustering analysis.
>>
>>  I first used "Tumor <- read.table("Tumor.txt",header = TRUE,sep = "\t")"
>>  but it took a long time and failed. However, it had no problem if I just
>>  put
>>  data of 3 columns.
>>
>>  Is there any way which can load this big file?
>>
>>  Thanks for any suggestions!
>>
>>  Sincerely,
>>      Alex
>>
>>   [[alternative HTML version deleted]]
>>
>>  ______________________________________________
>>  R-help at stat.math.ethz.ch mailing list
>>  https://stat.ethz.ch/mailman/listinfo/r-help
>>  PLEASE do read the posting guide
>>  http://www.R-project.org/posting-guide.html
>>  and provide commented, minimal, self-contained, reproducible code.
>> 
>
> Charles C. Berry                        (858) 534-2098
>                                         Dept of Family/Preventive Medicine
> E mailto:cberry at tajo.ucsd.edu	         UC San Diego
> http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0901
>
>
>

Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	         UC San Diego
http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0901


From cberry at tajo.ucsd.edu  Thu Jun  7 05:42:34 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Wed, 6 Jun 2007 20:42:34 -0700
Subject: [R] Question about parse and expression
In-Reply-To: <637616.76675.qm@web50207.mail.re2.yahoo.com>
References: <637616.76675.qm@web50207.mail.re2.yahoo.com>
Message-ID: <Pine.LNX.4.64.0706062041060.26604@tajo.ucsd.edu>

On Wed, 6 Jun 2007, Nitin Jain wrote:

> Dear R-users,
>
> In the following example, I would like to see my ylabel as: "beta[3] * 
> x[3] + epsilon" (where beta and epsilon are replaced by their 
> mathematical symbols).
>
> Please advise.

 	?plotmath
 	?bquote
 	example(plotmath)

>
> Thanks.
>
> Nitin
>
>
> i <- 3
>
> ee <- expression(beta[i] * x[i] + epsilon)
>
> xyplot(1:10~ 11:20,
>       ylab = parse(text=ee)
>       )
>
>
>
>
>
> ____________________________________________________________________________________
> 8:00? 8:25? 8:40? Find a flick in no time
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	         UC San Diego
http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0901


From ggrothendieck at gmail.com  Thu Jun  7 05:50:49 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 6 Jun 2007 23:50:49 -0400
Subject: [R] Question about parse and expression
In-Reply-To: <637616.76675.qm@web50207.mail.re2.yahoo.com>
References: <637616.76675.qm@web50207.mail.re2.yahoo.com>
Message-ID: <971536df0706062050t7338146fxfa437253e60ec298@mail.gmail.com>

Try this:

library(lattice)
x <- 1:10
i <- 3
xlab <- as.expression(substitute(beta[i] * x[i] + epsilon, list(i = i)))
xyplot(x ~ x, xlab = xlab)


On 6/6/07, Nitin Jain <nj7w at yahoo.com> wrote:
> Dear R-users,
>
> In the following example, I would like to see my ylabel as: "beta[3] * x[3] + epsilon" (where beta and epsilon are replaced by their mathematical symbols).
>
> Please advise.
>
> Thanks.
>
> Nitin
>
>
> i <- 3
>
> ee <- expression(beta[i] * x[i] + epsilon)
>
> xyplot(1:10~ 11:20,
>       ylab = parse(text=ee)
>       )
>
>
>
>
>
> ____________________________________________________________________________________
> 8:00? 8:25? 8:40? Find a flick in no time
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From spencer.graves at pdf.com  Thu Jun  7 06:16:19 2007
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 06 Jun 2007 21:16:19 -0700
Subject: [R] Can I treat subject as fixed effect in linear model
In-Reply-To: <6fb73d020706050829nc05c587s17fa85a56f796864@mail.gmail.com>
References: <6fb73d020706050829nc05c587s17fa85a56f796864@mail.gmail.com>
Message-ID: <46678693.8090006@pdf.com>

      The short answer is that you could fit that fixed-effect model 
using 'lm', for example.  That would make sense if you wanted to make 
inference only about that particular group of 20 subjects AND you 
thought it was inappropriate to consider that their contribution to a 
model would follow a normal distribution. 

      If you want to make inference beyond that group of 20 subjects, 
then the fixed effect analysis is not appropriate.  If you thought it 
was inappropriate to think that individual adjustments for each subject 
were normally distributed, then the question is how far from normal 
might they be. 

      I don't think Model2 is "illegal" in the sense that you are not 
likely to be sent to prison for using it.  However, I wouldn't do it.  
I'd make use your Model 1 and make all the plots that seem consistent 
with that model, as described in Pinheiro and Bates (2000) Mixed-Effects 
Models in S and S-Plus (Springer).  If the plots (or something else) 
suggested that some of my assumptions were inappropriate, then I'd 
consider other alternative models.  However, that could be a lot of 
work, and I wouldn't undertake such an effort without some pretty strong 
justification. 

      Hope this helps. 
      Spencer

shirley zhang wrote:
> Hi,
>
> There are 20 subjects grouped by Gender, each subject has 2 tissues
> (normal vs. cancer).
>
> In fact, it is a 2-way anova (factors: Gender and tissue) with tissue
> nested in subject. I've tried the following:
>
> Model 1: lme(response ~ tissue*Gender, random = ~1|subject)
> Model 2: response ~ tissue*Gender + subject
> Model 3: response ~ tissue*Gender
>
>
> It seems like Model 1 is the correct one since my experiment design is
> nested design. However, can anybody tell me whether Model2 is
> completely illegal?
>
> Thanks
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ripley at stats.ox.ac.uk  Thu Jun  7 07:32:29 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 7 Jun 2007 06:32:29 +0100 (BST)
Subject: [R] compiling from source on Vista
In-Reply-To: <200706062031.l56KViT3002451@gator.dt.uh.edu>
References: <200706062031.l56KViT3002451@gator.dt.uh.edu>
Message-ID: <Pine.LNX.4.64.0706070614480.32661@gannet.stats.ox.ac.uk>

On Wed, 6 Jun 2007, Erin Hodgess wrote:

> Dear R People:
>
> In the "R Installation and Administration" manual, there is a note
> that the process used to compile R from source will NOT work on Windows Vista.
>
> Does anyone know if that situation has changed, please?

That's not quite what it says:

   Note that there are known problems with using this compiler set (and all
   others available at the time of writing) on Windows Vista 
(@url{http://www.nabble.com/environment-hosed-during-upgrade-tf3305745.html#a9195667}
   and that some updates are needed (see the URL above).

As far as I know no update for 'g77' is available for download (so in that 
sense the situation is unchanged) but I believe that the existing tools 
can be gotten to work by setting suitable paths.

We had expected a new MinGW release by now (June 1 was mentioned), so 
hopefully the official solution to this is imminent.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ahenningsen at email.uni-kiel.de  Thu Jun  7 08:16:10 2007
From: ahenningsen at email.uni-kiel.de (Arne Henningsen)
Date: Thu, 7 Jun 2007 08:16:10 +0200
Subject: [R] Errors with systemfit package and systemfitClassic()
In-Reply-To: <050920072147.25246.4642418F000C67A70000629E2200750744CE0E089C07030E07@comcast.net>
References: <050920072147.25246.4642418F000C67A70000629E2200750744CE0E089C07030E07@comcast.net>
Message-ID: <200706070816.11086.ahenningsen@email.uni-kiel.de>

Hi iamisha1:

Sorry for answering so late!

On Wednesday 09 May 2007 23:47, iamisha1 at comcast.net wrote:
> I get the following error message after using the sysfit package's function
> 'systemfitClassic':
>
> Error in data[[eqnVar]] : subscript out of bounds
>
> When I do this:
>
> MSYS1 <- cbind(Y, Num, F, PO, PD, GO, GD)
> MigOLS1 <- systemfitClassic("OLS", F ~ PO + PD + GO + GD, eqnVar = "Num",
> timeVar = "Y", data = MSYS1) and I get this error message:

Argument "data" must be a "data.frame" (please read the documentation!).
Hence,
   systemfitClassic( [...], data = as.data.frame( MSYS1 ) ) 
or 
   MSYS1 <- as.data.frame( cbind(Y, Num, F, PO, PD, GO, GD) )
should work.

Arne

>
> Error in inherits(x, "factor") : attempt to select more than one element
>
> when I do this (removing quotes from columns set as 'eqnVar' and
> 'timeVar'):
>
> MSYS1 <- cbind(Y, Num, F, PO, PD, GO, GD)
> MigOLS1 <- systemfitClassic("OLS", F ~ PO + PD + GO + GD, eqnVar = Num,
> timeVar = Y, data = MSYS1)
>
> When I query 'typeof()' I get the following:
>
> Y: Integer
> Num: Integer
> F: Integer
> PO: Integer
> PD: Integer
> GO: Double
> GD: Double
>
> I have set my data up in a manner analogous to that in the examples in the
> systemfit documentation.  Also, the panel is balanced.  If it matters, here
> are some descriptions of the data:
>
> Y: Year
> Num: ID of Flow
> F: Flow
> PO: Origin Population
> PD: Destination Population
> GO: Origin GDP
> GD: Destination GDP
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented, minimal,
> self-contained, reproducible code.

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/


From ripley at stats.ox.ac.uk  Thu Jun  7 09:39:29 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 7 Jun 2007 08:39:29 +0100 (BST)
Subject: [R] opening a file from within a zipfile that is online
In-Reply-To: <f47bja$fd4$1@sea.gmane.org>
References: <f47bja$fd4$1@sea.gmane.org>
Message-ID: <Pine.LNX.4.64.0706070837340.20389@auk.stats>

'description' has to be a filepath of a zip file.  You will have to 
download it first.

On Wed, 6 Jun 2007, toby909 at gmail.com wrote:

> Hi
>
> Reading the help for ?unz I was wondering if I can read data into R from within
> an zipfile that is on some website, like maybe:
>
> dtaa =
> read.table(unz("http://www.ats.ucla.edu/stat/examples/alsm/alsm.zip","Ch01pr19.dat"))
>
> Thanks for letting me know if you came acros such a thing before.
>
> Toby
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From m_olshansky at yahoo.com  Thu Jun  7 04:41:27 2007
From: m_olshansky at yahoo.com (Moshe Olshansky)
Date: Wed, 6 Jun 2007 19:41:27 -0700 (PDT)
Subject: [R] Creating an Access (.mdb) database using R
Message-ID: <959846.68992.qm@web32202.mail.mud.yahoo.com>

Hello!

I have a short question:  Is it possible to create a
(non-existing) Access database using R (and if yes,
how)?  I need to create a new database and then insert
a few tables into it.

Thank you in advance,

Moshe Olshansky
m_olshansky at yahoo.com


From michael.watson at bbsrc.ac.uk  Thu Jun  7 11:10:45 2007
From: michael.watson at bbsrc.ac.uk (michael watson (IAH-C))
Date: Thu, 7 Jun 2007 10:10:45 +0100
Subject: [R] Suppressing the large amount of white space in heatmap.2 in
	gplots
Message-ID: <8975119BCD0AC5419D61A9CF1A923E9504F0D4F2@iahce2ksrv1.iah.bbsrc.ac.uk>

Hi

OK, quick question - I can suppress the calculation and drawing of the
column dendrogram by using Colv=FALSE and dendrogram="row", but that
leaves me with a large amount of white space at the top of the plot
where the dendrogram would have been drawn... Is there a way of getting
rid of that?

Thanks
Mick

The information contained in this message may be confidentia...{{dropped}}


From rhelp.20.trevva at spamgourmet.com  Thu Jun  7 11:40:41 2007
From: rhelp.20.trevva at spamgourmet.com (rhelp.20.trevva at spamgourmet.com)
Date: Thu, 07 Jun 2007 11:40:41 +0200
Subject: [R] Display Multiple page lattice plots
Message-ID: <4667D299.1090603@gmail.com>

Gudday,

I am generating a series of lattice contourplots that are conditioned on a variable (Year) that has 27 different levels. If I try and put them all on one plot, it ends up pretty messy and you can't really read anything, so instead I have set the layout to 3x3, thus generating three pages of nine plots each. The problem is that I can't display all these on screen at once, because each subsequent page overwrites the previous one. I have found in the mailing lists how to print them to separate files without any problems eg.

      p<-contourplot(log10(x)~lat*long|Year,
                  data=data.tbl,
                  layout=c(3,3))      
      png(file="Herring Distribution%02d.png",width=800,height=800)
      print(p)
      dev.off()

but there doesn't seem to be anything about how to output multiple pages to the screen... I suspect that I may need to use the page=... option in contourplot command, but I can't seem to make it work. Its a simple, and not particularly important problem, but it sure is bugging me!

Thanks for the advice in advance.

Cheers,

Mark


From ssls.sddd at gmail.com  Thu Jun  7 11:47:37 2007
From: ssls.sddd at gmail.com (ssls sddd)
Date: Thu, 7 Jun 2007 02:47:37 -0700
Subject: [R] How to load a big txt file
In-Reply-To: <30d7ea360706061945p50628332mab84a5fe65eec73f@mail.gmail.com>
References: <b87120290706061822h2794512av24762fa964d12905@mail.gmail.com>
	<30d7ea360706061945p50628332mab84a5fe65eec73f@mail.gmail.com>
Message-ID: <b87120290706070247i7fc05bc7p50090f8ce93f166@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070607/04e8c38b/attachment.pl 

From ripley at stats.ox.ac.uk  Thu Jun  7 11:51:54 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 7 Jun 2007 10:51:54 +0100 (BST)
Subject: [R] Creating an Access (.mdb) database using R
In-Reply-To: <959846.68992.qm@web32202.mail.mud.yahoo.com>
References: <959846.68992.qm@web32202.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.64.0706071042240.3527@gannet.stats.ox.ac.uk>

On Wed, 6 Jun 2007, Moshe Olshansky wrote:

> Hello!
>
> I have a short question:  Is it possible to create a
> (non-existing) Access database using R (and if yes,
> how)?  I need to create a new database and then insert
> a few tables into it.

Short answer: yes, if you are using Windows (you did not say).

Slightly longer answer 1:

If you have the ODBC drivers installed,

> library(RODBC)
> ch <- odbcDriverConnect("Driver={Microsoft Access Driver (*.mdb)}")

will allow you to create a database and select it.

Slightly longer answer 2:

Use DCOM to control Access if you have that installed.  I'll leave you to 
do your own homework on this one.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ssls.sddd at gmail.com  Thu Jun  7 11:52:40 2007
From: ssls.sddd at gmail.com (ssls sddd)
Date: Thu, 7 Jun 2007 02:52:40 -0700
Subject: [R] How to load a big txt file
In-Reply-To: <644e1f320706061829v75b133a7o3a32ad0ff2f24449@mail.gmail.com>
References: <b87120290706061822h2794512av24762fa964d12905@mail.gmail.com>
	<644e1f320706061829v75b133a7o3a32ad0ff2f24449@mail.gmail.com>
Message-ID: <b87120290706070252o19219518peba56229d805f415@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070607/b36097c7/attachment.pl 

From michael.watson at bbsrc.ac.uk  Thu Jun  7 11:53:49 2007
From: michael.watson at bbsrc.ac.uk (michael watson (IAH-C))
Date: Thu, 7 Jun 2007 10:53:49 +0100
Subject: [R] How to load a big txt file
In-Reply-To: <b87120290706070247i7fc05bc7p50090f8ce93f166@mail.gmail.com>
References: <b87120290706061822h2794512av24762fa964d12905@mail.gmail.com><30d7ea360706061945p50628332mab84a5fe65eec73f@mail.gmail.com>
	<b87120290706070247i7fc05bc7p50090f8ce93f166@mail.gmail.com>
Message-ID: <8975119BCD0AC5419D61A9CF1A923E9504F0D4F6@iahce2ksrv1.iah.bbsrc.ac.uk>

Erm... Is that a typo?  Are we really talking 23800 rows and 49 columns?
Because that doesn't seem that many....

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of ssls sddd
Sent: 07 June 2007 10:48
To: r-help at stat.math.ethz.ch
Subject: Re: [R] How to load a big txt file

Dear Chung-hong Chan,

Thanks! Can you recommend a text editor for splitting? I used UltraEdit
and TextPad but did not find they can split files.

Sincerely,

Alex

On 6/6/07, Chung-hong Chan <chainsawtiney at gmail.com> wrote:
>
> Easy solution will be split your big txt files by text editor.
>
> e.g. 5000 rows each.
>
> and then combine the dataframes together into one.
>
>
>
> On 6/7/07, ssls sddd <ssls.sddd at gmail.com> wrote:
> > Dear list,
> >
> > I need to read a big txt file (around 130Mb; 23800 rows and 49
columns)
> > for downstream clustering analysis.
> >
> > I first used "Tumor <- read.table("Tumor.txt",header = TRUE,sep =
"\t")"
> > but it took a long time and failed. However, it had no problem if I
just
> put
> > data of 3 columns.
> >
> > Is there any way which can load this big file?
> >
> > Thanks for any suggestions!
> >
> > Sincerely,
> >      Alex
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
> --
> "The scientists of today think deeply instead of clearly. One must be
> sane to think clearly, but one can think deeply and be quite insane."
> Nikola Tesla
> http://www.macgrass.com
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ssls.sddd at gmail.com  Thu Jun  7 11:56:52 2007
From: ssls.sddd at gmail.com (ssls sddd)
Date: Thu, 7 Jun 2007 02:56:52 -0700
Subject: [R] How to load a big txt file
In-Reply-To: <8975119BCD0AC5419D61A9CF1A923E9504F0D4F6@iahce2ksrv1.iah.bbsrc.ac.uk>
References: <b87120290706061822h2794512av24762fa964d12905@mail.gmail.com>
	<30d7ea360706061945p50628332mab84a5fe65eec73f@mail.gmail.com>
	<b87120290706070247i7fc05bc7p50090f8ce93f166@mail.gmail.com>
	<8975119BCD0AC5419D61A9CF1A923E9504F0D4F6@iahce2ksrv1.iah.bbsrc.ac.uk>
Message-ID: <b87120290706070256t2f94e94fy718baabad6562e71@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070607/ef6ec40c/attachment.pl 

From jim at bitwrit.com.au  Thu Jun  7 12:03:45 2007
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 07 Jun 2007 20:03:45 +1000
Subject: [R] R help
In-Reply-To: <806411.48610.qm@web57504.mail.re1.yahoo.com>
References: <806411.48610.qm@web57504.mail.re1.yahoo.com>
Message-ID: <4667D801.4060208@bitwrit.com.au>

scott flemming wrote:
> Hi,
> 
> I wonder whether R can finish the following project:
> 
> I want to make a chart to represent 10 genes. Each gene has orientation and length. Therefore, a gene can be represented by arrows. 
> 
> Can R be used to draw 10 arrows in one line ?
> 
Hi Scott,
Maybe the feather.plot function in the plotrix package is what you want.

Jim


From singularitaet at gmx.net  Thu Jun  7 12:00:16 2007
From: singularitaet at gmx.net (Stefan Grosse)
Date: Thu, 07 Jun 2007 12:00:16 +0200
Subject: [R] update packages with R on Vista: error
Message-ID: <4667D730.9090403@gmx.net>

Dear R-list,

I have encountered the following error message trying to update R packages:

> update.packages(ask='graphics')
Warning in install.packages(update[instlib == l, "Package"], l,
contriburl = contriburl,  :
         'lib' is not writable
Error in install.packages(update[instlib == l, "Package"], l, contriburl
= contriburl,  :
        unable to install packages

I  remember did not have the problem on the last update where R
installed the files then in the Documents/R folder on my user account.
Any ideas how to handle this? I made the directories completely writable
so I do not know where the problem is now (especially since update
worked before...)

Stefan

PS: Tinn-R 1.19.2.3 + R 2.5.0 on Vista Business


From james.morris at ucl.ac.uk  Thu Jun  7 12:12:01 2007
From: james.morris at ucl.ac.uk (James Morris)
Date: Thu, 7 Jun 2007 11:12:01 +0100
Subject: [R] RODBC and placeholders?
Message-ID: <00ab01c7a8ec$4f72f2b0$4201a8c0@James>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070607/d9e7a2f5/attachment.pl 

From ggrothendieck at gmail.com  Thu Jun  7 12:41:32 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 7 Jun 2007 06:41:32 -0400
Subject: [R] Display Multiple page lattice plots
In-Reply-To: <4667D299.1090603@gmail.com>
References: <4667D299.1090603@gmail.com>
Message-ID: <971536df0706070341s6ce81ebao30df266965718b40@mail.gmail.com>

This works on my Windows machine starting off at a new R session:

options(graphics.record = TRUE)
library(lattice)
xyplot(uptake ~ conc | Plant, CO2, layout = c(2,2))

Now switch focus to the graphics window and you can PgUp and PgDn
through them.

There are several variations to this:

1. use graphics.record option as shown above
2. the graphics.record option is passed to the windows driver so explicitly
call windows yourself.  See ?windows
3. prior to your xyplot switch focus to the graphics window and a History
menu appears.  Use that to turn on recording.


On 6/7/07, rhelp.20.trevva at spamgourmet.com
<rhelp.20.trevva at spamgourmet.com> wrote:
> Gudday,
>
> I am generating a series of lattice contourplots that are conditioned on a variable (Year) that has 27 different levels. If I try and put them all on one plot, it ends up pretty messy and you can't really read anything, so instead I have set the layout to 3x3, thus generating three pages of nine plots each. The problem is that I can't display all these on screen at once, because each subsequent page overwrites the previous one. I have found in the mailing lists how to print them to separate files without any problems eg.
>
>      p<-contourplot(log10(x)~lat*long|Year,
>                  data=data.tbl,
>                  layout=c(3,3))
>      png(file="Herring Distribution%02d.png",width=800,height=800)
>      print(p)
>      dev.off()
>
> but there doesn't seem to be anything about how to output multiple pages to the screen... I suspect that I may need to use the page=... option in contourplot command, but I can't seem to make it work. Its a simple, and not particularly important problem, but it sure is bugging me!
>
> Thanks for the advice in advance.
>
> Cheers,
>
> Mark
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ripley at stats.ox.ac.uk  Thu Jun  7 13:01:46 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 7 Jun 2007 12:01:46 +0100 (BST)
Subject: [R] update packages with R on Vista: error
In-Reply-To: <4667D730.9090403@gmx.net>
References: <4667D730.9090403@gmx.net>
Message-ID: <Pine.LNX.4.64.0706071159250.19222@gannet.stats.ox.ac.uk>

See the rw-FAQ, which describes this in detail.

Almost certainly you are trying to update the package 'cluster' which is 
in the main library.  But as you used the GUI, we can't see that.

On Thu, 7 Jun 2007, Stefan Grosse wrote:

> Dear R-list,
>
> I have encountered the following error message trying to update R packages:
>
>> update.packages(ask='graphics')
> Warning in install.packages(update[instlib == l, "Package"], l,
> contriburl = contriburl,  :
>         'lib' is not writable
> Error in install.packages(update[instlib == l, "Package"], l, contriburl
> = contriburl,  :
>        unable to install packages
>
> I  remember did not have the problem on the last update where R
> installed the files then in the Documents/R folder on my user account.
> Any ideas how to handle this? I made the directories completely writable
> so I do not know where the problem is now (especially since update
> worked before...)
>
> Stefan
>
> PS: Tinn-R 1.19.2.3 + R 2.5.0 on Vista Business
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jholtman at gmail.com  Thu Jun  7 13:48:47 2007
From: jholtman at gmail.com (jim holtman)
Date: Thu, 7 Jun 2007 07:48:47 -0400
Subject: [R] How to load a big txt file
In-Reply-To: <b87120290706070252o19219518peba56229d805f415@mail.gmail.com>
References: <b87120290706061822h2794512av24762fa964d12905@mail.gmail.com>
	<644e1f320706061829v75b133a7o3a32ad0ff2f24449@mail.gmail.com>
	<b87120290706070252o19219518peba56229d805f415@mail.gmail.com>
Message-ID: <644e1f320706070448n551d72c0r633792cc00bdc83f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070607/a76fe659/attachment.pl 

From mw-u2 at gmx.de  Thu Jun  7 14:27:29 2007
From: mw-u2 at gmx.de (mw-u2 at gmx.de)
Date: Thu, 07 Jun 2007 14:27:29 +0200
Subject: [R] Use R in a pipeline as a filter
Message-ID: <20070607122729.80180@gmx.net>

Hi,

how can I use R in a pipline like this

 $ ./generate-data | R --script-file=Script.R | ./further-analyse-data > result.dat

Assume a column based output of ./generate-data, e.g. something like:
1 1 1
2 4 8
3 9 27
4 16 64

The R commands that process the data should come from Script.R and should print to stdout (Script.R could for example calculate the square of every entry or calculate the mean of the columns, ...)

The output should be printed to stdout, such that further-analyse-data can use the output.

Can some R expert code that for me please? I would be very happy. I am also happy about information how to do that myself although I dont think I know enough to do that myself.

Thank you for your consideration,

Micha
-- 
GMX FreeMail: 1 GB Postfach, 5 E-Mail-Adressen, 10 Free SMS.
Alle Infos und kostenlose Anmeldung: http://www.gmx.net/de/go/freemail


From sfriedma at sfwmd.gov  Thu Jun  7 14:46:29 2007
From: sfriedma at sfwmd.gov (Friedman, Steven)
Date: Thu, 7 Jun 2007 08:46:29 -0400
Subject: [R] Conditional Sequential Gaussian Simulation
Message-ID: <14A2A120D369B6469BB154B2D2DC34D20803CB03@EXCHVS01.ad.sfwmd.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070607/01967ab1/attachment.pl 

From ripley at stats.ox.ac.uk  Thu Jun  7 15:15:47 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 7 Jun 2007 14:15:47 +0100 (BST)
Subject: [R] Use R in a pipeline as a filter
In-Reply-To: <20070607122729.80180@gmx.net>
References: <20070607122729.80180@gmx.net>
Message-ID: <Pine.LNX.4.64.0706071358001.6305@gannet.stats.ox.ac.uk>

This is one of the things that 'Rscript' is for: see 'An Introduction to 
R' (section B.4 in the HTML version, 
http://cran.r-project.org/doc/manuals/R-intro.html#Scripting-with-R).

You haven't even told us your version of R or OS (see the posting guide):
you need R >= 2.5.0 for this.  But your 'example' would be

./generate-data | Rscript Script.R | ./further-analyse-data > result.dat


On Thu, 7 Jun 2007, mw-u2 at gmx.de wrote:

> Hi,
>
> how can I use R in a pipline like this
>
> $ ./generate-data | R --script-file=Script.R | ./further-analyse-data > result.dat
>
> Assume a column based output of ./generate-data, e.g. something like:
> 1 1 1
> 2 4 8
> 3 9 27
> 4 16 64
>
> The R commands that process the data should come from Script.R and 
> should print to stdout (Script.R could for example calculate the square 
> of every entry or calculate the mean of the columns, ...)
>
> The output should be printed to stdout, such that further-analyse-data 
> can use the output.
>
> Can some R expert code that for me please? I would be very happy. I am 
> also happy about information how to do that myself although I dont think 
> I know enough to do that myself.
>
> Thank you for your consideration,
>
> Micha
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rdporto1 at terra.com.br  Thu Jun  7 15:22:34 2007
From: rdporto1 at terra.com.br (Rogerio Porto)
Date: Thu,  7 Jun 2007 10:22:34 -0300
Subject: [R] Spectral analysis
Message-ID: <JJ9P5M$35E88B456D6E5FE80B8B3D7B17B0F509@multidominios>

David and Ted,

since David asked about wavelets, there are some examples
at the packages Wavethresh and Waveslim that could be useful.

Waveslim deals with time series that are or are not a power of 2,
but must be regularly spaced.

Wavethresh 3 (http://www.maths.bris.ac.uk/~wavethresh/)
has methods to analyze irregular time series, as suggested by Ted
but their length must be a power of 2.

Regards,

Rogerio

---------- Cabe?alho original -----------

De: r-help-bounces at stat.math.ethz.ch
Para: "David LEDU" david.ledu at yahoo.ca
C?pia: r-help at stat.math.ethz.ch
Data: Wed, 06 Jun 2007 22:34:21 +0100 (BST)
Assunto: Re: [R] Spectral analysis

> On 06-Jun-07 20:55:09, David LEDU wrote:
> > Hi all,
> > 
> > I am dealing with paleoceanographic data and I have a C14 time serie
> > and one other variable. I would like to perform a spectral analysis
> > (fft or wavelet) and plot it. Unfortunately I don't know the exact
> > script to do this. Does anybody could send me an example to perform my
> > spectral analysis ?
> > 
> > I Thank you
> > 
> > David
> 
> There are a lot of possible ramifications to your query,
> but for a basic spectral analysis of a series you can use
> the function spectrum() in the "stats" package.
> 
> What is the role of the "other variable"?
> 
> Best wishes,
> Ted.
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 06-Jun-07                                       Time: 22:34:07
> ------------------------------ XFMail ------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From singularitaet at gmx.net  Thu Jun  7 15:36:24 2007
From: singularitaet at gmx.net (Stefan Grosse)
Date: Thu, 07 Jun 2007 15:36:24 +0200
Subject: [R] update packages with R on Vista: error
In-Reply-To: <Pine.LNX.4.64.0706071159250.19222@gannet.stats.ox.ac.uk>
References: <4667D730.9090403@gmx.net>
	<Pine.LNX.4.64.0706071159250.19222@gannet.stats.ox.ac.uk>
Message-ID: <466809D8.1020603@gmx.net>

Actually the packages R wants to update are: VR, cluster, lattice, mgcv,
nlme and rcompgen. I did how described in the R-Win-FAQ create a
.Renviron File containing the path to the win-library that R already
created (R_LIBS=C: ... ). I also tried to add R_LIBS= as Rgui parameter
from within Tinn-R. Additionally I tried to leave a file named
Renviron.site in the etc library. Nothing worked thus far.

Interestingly installing packages does work fine even without specifying
the R_LIBS path manually with any of the above mentioned methods.

Even more puzzling is that even when I install eg. nlme manually via
install.packages("nlme") it works but R still wants to update it. Even
though e.g. library(nlme), ?nlme shows that the latest version is
installed.

I would guess there is some problem with the library path variable in
the update program...

Stefan


-------- Original Message  --------
Subject: Re:[R] update packages with R on Vista: error
From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
To: Stefan Grosse <singularitaet at gmx.net>
Date: 07.06.2007 13:01
> See the rw-FAQ, which describes this in detail.
>
> Almost certainly you are trying to update the package 'cluster' which
> is in the main library.  But as you used the GUI, we can't see that.
>
> On Thu, 7 Jun 2007, Stefan Grosse wrote:
>
>> Dear R-list,
>>
>> I have encountered the following error message trying to update R
>> packages:
>>
>>> update.packages(ask='graphics')
>> Warning in install.packages(update[instlib == l, "Package"], l,
>> contriburl = contriburl,  :
>>         'lib' is not writable
>> Error in install.packages(update[instlib == l, "Package"], l, contriburl
>> = contriburl,  :
>>        unable to install packages
>>
>> I  remember did not have the problem on the last update where R
>> installed the files then in the Documents/R folder on my user account.
>> Any ideas how to handle this? I made the directories completely writable
>> so I do not know where the problem is now (especially since update
>> worked before...)
>>
>> Stefan
>>
>> PS: Tinn-R 1.19.2.3 + R 2.5.0 on Vista Business
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From bunny at lautloscrew.com  Thu Jun  7 16:47:15 2007
From: bunny at lautloscrew.com (bunny , lautloscrew.com)
Date: Thu, 7 Jun 2007 16:47:15 +0200
Subject: [R] ordered logistic regression
Message-ID: <E7229262-B863-4CE7-B88B-D98C89969A9E@lautloscrew.com>

Hi there,


i tried to run an ordered logistic regression with polr. so far it  
worked after i turned my data into factors.
but here?s my problem:
my output is like this:

Call:
polr(formula = factor(fulltest[, 1]) ~ factor(fulltest[, 2]) +
     factor(fulltest[, 10]), method = "logistic")

Coefficients:
factor(fulltest[, 2])0  factor(fulltest[, 2])1  factor(fulltest[, 2]) 
2  factor(fulltest[, 2])3 factor(fulltest[, 10])0 factor(fulltest[,  
10])1 factor(fulltest[, 10])2
               1.0850358               0.8269005                
0.8850035               1.0263442                
1.3724189               1.8258853               2.2263393
factor(fulltest[, 10])3
               2.5234381

Intercepts:
        -1|0         0|1         1|2         2|3
-2.42111430 -2.13077351  0.07966516  2.85951997

Residual Deviance: 1219.493
AIC: 1243.493


as far is i understand, there?s a dummy var introduced for every  
possible outcome ( 0 , 1, 2 ,3) . this is nice because it contains a  
lot of information, but far more than i need.
and i have to many variables to research to use dummies for every  
single one of them. Can i get one coefficient per variable ?

Is there another package for logistic regression ? did is use the  
factor thing the wrong way ?

thx in advance

mattthias


From anna-maria.tyriseva at helsinki.fi  Thu Jun  7 17:01:43 2007
From: anna-maria.tyriseva at helsinki.fi (Anna-Maria Tyriseva)
Date: Thu, 07 Jun 2007 18:01:43 +0300
Subject: [R] comparison of two logistic regression models
Message-ID: <46681DD7.2040702@helsinki.fi>

Dear list members!

Could you help me?
I would like to compare two models: a) logistic regression model, 3 
factors as independents b) logistic regression model, 3 factors and one 
random effect as independents (function glmmPQL). AIC are not available 
with PQL and model comparison using ANOVA is not possible. What should I do?

Thanks in advance.
Anna-Maria


From pwang at berkeley.edu  Thu Jun  7 17:18:40 2007
From: pwang at berkeley.edu (Patrick Wang)
Date: Thu, 7 Jun 2007 08:18:40 -0700 (PDT)
Subject: [R] How to get the number of modes using kde2d
Message-ID: <50765.76.169.69.87.1181229520.squirrel@calmail.berkeley.edu>

Hi,

The silverman's paper introduction offer how to find a mode for one
dimensional data based
on software

http://www.stanford.edu/~kasparr/software/silverman.r,

for two dimensional data I use kde2d to smooth it out first,  then I get a
matrix of densities for all the X(one dimension) cross Y(another
dimension).


I sort X and Y first before I pass the values to kde2d(x, y, c(hx, hy)),
the persp shape changes

Does anyone know how to get the modes out of the two dimensional data
programmatically.

Also if I want to get the minumum of X, Y with modes =2, is the solution
unique?

Thanks
pat


From mothsailor at googlemail.com  Thu Jun  7 17:35:33 2007
From: mothsailor at googlemail.com (David Barron)
Date: Thu, 7 Jun 2007 16:35:33 +0100
Subject: [R] comparison of two logistic regression models
In-Reply-To: <46681DD7.2040702@helsinki.fi>
References: <46681DD7.2040702@helsinki.fi>
Message-ID: <815b70590706070835h38913b93o899a66634116ed06@mail.gmail.com>

You could use lmer in the lme4 package to fit the logistic regression
with random effect as it does report the AIC.

On 07/06/07, Anna-Maria Tyriseva <anna-maria.tyriseva at helsinki.fi> wrote:
> Dear list members!
>
> Could you help me?
> I would like to compare two models: a) logistic regression model, 3
> factors as independents b) logistic regression model, 3 factors and one
> random effect as independents (function glmmPQL). AIC are not available
> with PQL and model comparison using ANOVA is not possible. What should I do?
>
> Thanks in advance.
> Anna-Maria
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
=================================
David Barron
Said Business School
University of Oxford
Park End Street
Oxford OX1 1HP


From ligges at statistik.uni-dortmund.de  Thu Jun  7 17:37:30 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 07 Jun 2007 17:37:30 +0200
Subject: [R] problem with Axis labels
In-Reply-To: <969416.41943.qm@web7605.mail.in.yahoo.com>
References: <969416.41943.qm@web7605.mail.in.yahoo.com>
Message-ID: <4668263A.9060605@statistik.uni-dortmund.de>



ramakanth reddy wrote:
> Hi
> 
> I am using the pamr.plotsurvival fucntion to plot the KM curves,how can I change the x axis and y axis labels according to my interest.

If we are talking about the most recent version of package pamr (you 
forgot to tell us these details):

In R, type

pamr.plotsurvival

and see that this function is rather a proof of concept than a well 
designed function for general use. You might want to extend the function 
by allowing xlab / ylab and other arguments. Additionally, you might 
want to remove a couple of hard coded values in order to make the 
function more generally usable. I am pretty sure the authors/maintainer 
(CCing the maintainer) of pamr will be happy about your contributions, 
if you submit well designed improvements.

Best regards,
Uwe Ligges



> Thanks
> 
> 
> 
> 
>       Looking for people who are YOUR TYPE? Find them at in.groups.yahoo.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ligges at statistik.uni-dortmund.de  Thu Jun  7 17:39:45 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 07 Jun 2007 17:39:45 +0200
Subject: [R] names not inherited in functions
In-Reply-To: <772cb06e0706061527l6a5bcabem7566811c5b7c4657@mail.gmail.com>
References: <772cb06e0706061527l6a5bcabem7566811c5b7c4657@mail.gmail.com>
Message-ID: <466826C1.6000208@statistik.uni-dortmund.de>

Not sure what you are going to get. Can you shorten your functions and 
specify some example data? Then please tell us what your expected result is.

Best,
Uwe Ligges




david dav wrote:
> Dear all,
> 
> I 'd like to keep the names of variables when calling them in a function.
> An example might help to understand my problem :
> 
> The following function puts in a new data frame counts and percent of
> a data.frame called as "tablo"
> the step " nom.chiffr[1] <- names(vari) " is useless as names from the
> original data.frame aren't kept in the function environement.
> 
> Hoping I use appropriate R-vocabulary, I thank you for your help
> 
> David
> 
> descriptif <- function (tablo) {
> 	descriptifvar <- function (vari) {
> 		table(vari)
> 		length(vari[!is.na(vari)])
> 		chiffr <- cbind(table(vari),100*table(vari)/(length(vari[!is.na(vari)])))
> 		nom.chiffr <- rep(NA, dim(table(vari)))
> 		if (is.null(names(vari))) nom.chiffr[1] <- paste(i,"") else
> 		nom.chiffr[1] <- names(vari)
> 		chiffr <- data.frame (  names(table(vari)),chiffr)
> 		rownames(chiffr) <- NULL
> 		chiffr <- data.frame (nom.chiffr, chiffr)
> 	return(chiffr)
> 	}
> 	
> 	res <- rep(NA, 4)
> 	for (i in 1 : ncol(tablo))
> 		res <- rbind(res,descriptifvar(tablo[,i]))
> 	colnames(res) <- c("variable", "niveau", "effectif", "pourcentage")
> return(res[-1,])
> }	
> # NB I used this function on a data.frame with only factors in
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From guanrao at yahoo.com  Thu Jun  7 18:46:05 2007
From: guanrao at yahoo.com (Guanrao Chen)
Date: Thu, 7 Jun 2007 09:46:05 -0700 (PDT)
Subject: [R]  aggregate by two columns, "sum" not working while "mean" is
In-Reply-To: <466826C1.6000208@statistik.uni-dortmund.de>
Message-ID: <556634.17073.qm@web50610.mail.re2.yahoo.com>

Dear Fellow Rers,

I have a table looks like this:

ca, la, 12
ca, sd, 22
ca, la, 33
nm, al, 9
ma, lx, 18
ma, bs, 90
ma, lx, 22

I want to sum the 3rd column grouped by the first and
the second column, so the result look like this table:

ca, la, 45 <
ca, sd, 22
nm, al, 9
ma, lx, 40 <
ma, bs, 90

The two rows with < are sums.

I tried
aggregate(table,list(table$V1,table$V2),sum/mean), sum
was not working while mean worked.

Can anybody give a hint?

Thanks.
Guanrao


From jholtman at gmail.com  Thu Jun  7 18:52:17 2007
From: jholtman at gmail.com (jim holtman)
Date: Thu, 7 Jun 2007 12:52:17 -0400
Subject: [R] aggregate by two columns, "sum" not working while "mean" is
In-Reply-To: <556634.17073.qm@web50610.mail.re2.yahoo.com>
References: <466826C1.6000208@statistik.uni-dortmund.de>
	<556634.17073.qm@web50610.mail.re2.yahoo.com>
Message-ID: <644e1f320706070952n2dc653a7m5d84e627f1bccdf1@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070607/e366183f/attachment.pl 

From alison.weir at utoronto.ca  Thu Jun  7 18:53:30 2007
From: alison.weir at utoronto.ca (alison weir)
Date: Thu, 7 Jun 2007 12:53:30 -0400
Subject: [R] Garch question
Message-ID: <e99349a60706070953i3e5b1e39j258a2c6e9f39f59d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070607/8bc004f4/attachment.pl 

From alison.weir at utoronto.ca  Thu Jun  7 18:55:26 2007
From: alison.weir at utoronto.ca (alison weir)
Date: Thu, 7 Jun 2007 12:55:26 -0400
Subject: [R] Garch question
In-Reply-To: <e99349a60706070953i3e5b1e39j258a2c6e9f39f59d@mail.gmail.com>
References: <e99349a60706070953i3e5b1e39j258a2c6e9f39f59d@mail.gmail.com>
Message-ID: <e99349a60706070955s701c66eej21b544cc60cd9907@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070607/f8d6e605/attachment.pl 

From ripley at stats.ox.ac.uk  Thu Jun  7 19:10:38 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 7 Jun 2007 18:10:38 +0100 (BST)
Subject: [R] comparison of two logistic regression models
In-Reply-To: <815b70590706070835h38913b93o899a66634116ed06@mail.gmail.com>
References: <46681DD7.2040702@helsinki.fi>
	<815b70590706070835h38913b93o899a66634116ed06@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0706071801400.22500@gannet.stats.ox.ac.uk>

On Thu, 7 Jun 2007, David Barron wrote:

> You could use lmer in the lme4 package to fit the logistic regression
> with random effect as it does report the AIC.

Indeed you could (lmer reports _an approximation_ to the AIC), but AIC 
comparison between these two models is not valid as whereas they are 
tested, the smaller model is on the boundary of the parameter space for 
the larger one, and that violates one of the assumptions in the derivation 
of AIC.  From simulation studies I have heard seminar talks about, it 
makes a large practical difference as well.

Withou knowing why Anna-Maria wants to 'compare two models', I could not 
begin to offer advice.  Generally one should test how well each does the 
task to hand, whatever that is.

> On 07/06/07, Anna-Maria Tyriseva <anna-maria.tyriseva at helsinki.fi> wrote:
>> Dear list members!
>>
>> Could you help me?
>> I would like to compare two models: a) logistic regression model, 3
>> factors as independents b) logistic regression model, 3 factors and one
>> random effect as independents (function glmmPQL). AIC are not available
>> with PQL and model comparison using ANOVA is not possible. What should I do?
>>
>> Thanks in advance.
>> Anna-Maria

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From bmeglen at comcast.net  Thu Jun  7 19:29:01 2007
From: bmeglen at comcast.net (Bob Meglen)
Date: Thu, 7 Jun 2007 11:29:01 -0600
Subject: [R] reading BMP or TIFF files
Message-ID: <007d01c7a929$57024bb0$6943474b@Meglenhome>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070607/496ff6d3/attachment.pl 

From bunny at lautloscrew.com  Thu Jun  7 19:31:12 2007
From: bunny at lautloscrew.com (bunny , lautloscrew.com)
Date: Thu, 7 Jun 2007 19:31:12 +0200
Subject: [R] which syntax to use for ordered logit
Message-ID: <9F03A3AC-6D98-48F6-A2C2-2CABA78BC5AA@lautloscrew.com>

Hi everybody,
i am like to do a ordered logistic model, but cant figure out which  
syntax / library fits best.
i?ve answer possibilites in a matrix (-1 0 1 2 3), these are saved as  
factors.

i guess i need something pretty basic. i tried VGAM, polr but  
received not what i wanted.
Whicht library / package / syntax woud you prefer ?

thx in advance!

matthias


From tomh at uwm.edu  Thu Jun  7 19:38:04 2007
From: tomh at uwm.edu (Tom Hansen)
Date: Thu, 07 Jun 2007 12:38:04 -0500
Subject: [R] Using Akima with nearly-gridded data
Message-ID: <4668427C.6010505@uwm.edu>


I am using the Akima interpolation package to generate an interpolated 
color contour plot.  It is working very well, except for one problem.  
The data that I have represents real-time readings from a thermistor 
string vs. time, so the data points are often very nearly in a 
rectangular array, since the thermistors are read at regular time 
intervals and they are equally spaced physically.  However, readings are 
sometimes delayed or missed, so I cannot assume that it will be a 
regular grid.  Hence Akima.

However, Akima simply will not work if the first three points are 
collinear (which is easy to get around), and it often leaves blank 
triangles in seemingly arbitrary places in the plot.  It seems that the 
algorithm in Akima for building the triangles that it uses internally to 
do the interpolation is having a very hard time dealing with nearly 
regularly-spaced data points.

The only way I have found to get Akima to work, is to slightly "perturb" 
the data points by adding random seconds to the times (the temperatures 
are read every 5 minutes, so a few seconds aren't going to matter).  
More recently I have had some luck simply feeding the points into the 
algorithm in a pseudo-randomized order.  But then, of course, the 
outcome is largely the luck of the draw and sometimes the plot still 
ends up with a scattering of white triangles, or artifacts on the edges 
of the plot.

Does anyone have any suggestions as to how to make this work consistently?

-- 
Tom Hansen
Senior Information Processing Consultant
UWM Great Lakes WATER Institute
www.glwi.uwm.edu
tomh at uwm.edu


From mcaro72 at gmail.com  Thu Jun  7 20:00:52 2007
From: mcaro72 at gmail.com (Miguel Caro)
Date: Thu, 7 Jun 2007 11:00:52 -0700 (PDT)
Subject: [R] how to input data from the keyboard
Message-ID: <11013164.post@talk.nabble.com>


Hello everybody, i wish to input data from the keyboard. In C++ it would seem
like this:

printf("Input parameter Alpha= ");
scanf("%d", &alpha);

how would be in R?

Thanks for your help.

Bye 
Miguel.
-- 
View this message in context: http://www.nabble.com/how-to-input-data-from-the-keyboard-tf3885387.html#a11013164
Sent from the R help mailing list archive at Nabble.com.


From ilikelotsofbroccoli at googlemail.com  Thu Jun  7 20:11:46 2007
From: ilikelotsofbroccoli at googlemail.com (Emily Broccoli)
Date: Thu, 7 Jun 2007 19:11:46 +0100
Subject: [R] new data frame for loop
Message-ID: <9bd6375d0706071111h59e593c8r1fc4bde6c2e2d863@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070607/5cfaa10b/attachment.pl 

From gunter.berton at gene.com  Thu Jun  7 20:21:06 2007
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 7 Jun 2007 11:21:06 -0700
Subject: [R] how to input data from the keyboard
In-Reply-To: <11013164.post@talk.nabble.com>
Message-ID: <012801c7a930$9d832350$4d908980@gne.windows.gene.com>

Please do your homework:

help.search("input")
 


Bert Gunter
Genentech Nonclinical Statistics


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Miguel Caro
Sent: Thursday, June 07, 2007 11:01 AM
To: r-help at stat.math.ethz.ch
Subject: [R] how to input data from the keyboard


Hello everybody, i wish to input data from the keyboard. In C++ it would
seem
like this:

printf("Input parameter Alpha= ");
scanf("%d", &alpha);

how would be in R?

Thanks for your help.

Bye 
Miguel.
-- 
View this message in context:
http://www.nabble.com/how-to-input-data-from-the-keyboard-tf3885387.html#a11
013164
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From tobias.verbeke at gmail.com  Thu Jun  7 20:35:13 2007
From: tobias.verbeke at gmail.com (Tobias Verbeke)
Date: Thu, 07 Jun 2007 20:35:13 +0200
Subject: [R] new data frame for loop
In-Reply-To: <9bd6375d0706071111h59e593c8r1fc4bde6c2e2d863@mail.gmail.com>
References: <9bd6375d0706071111h59e593c8r1fc4bde6c2e2d863@mail.gmail.com>
Message-ID: <46684FE1.9020206@telenet.be>

Hi Emily,

Emily Broccoli wrote:

> I have a data frame with three columns, one coded as a factor. I would like
> to separate my data out into separate data frames according to the factor
> level. Below is a simple example to illustrate. I can get R to return the
> data in the correct format but cannot work out how to get separate data
> frames. I am a newcommer to programming in R so am not sure what I am
> missing! Thanks, Emily
> 
> a<-seq(1,20, by=2)
> b<-seq(1,30, by=3)
> ID<-as.factor(c(1,1,1,2,2,2,3,3,3,3))
> df<-data.frame(a,b,ID)

The function split will give you a list
of data frames split according to a factor:

 > split(df, df$ID)
$`1`
   a b ID
1 1 1  1
2 3 4  1
3 5 7  1

$`2`
    a  b ID
4  7 10  2
5  9 13  2
6 11 16  2

$`3`
     a  b ID
7  13 19  3
8  15 22  3
9  17 25  3
10 19 28  3

See ?split.

HTH,
Tobias

-- 

Tobias Verbeke - Consultant
Business & Decision Benelux
Rue de la r?volution 8
1000 Brussels - BELGIUM

+32 499 36 33 15
tobias.verbeke at businessdecision.com


From lawremi at iastate.edu  Thu Jun  7 20:43:51 2007
From: lawremi at iastate.edu (Michael Lawrence)
Date: Thu, 7 Jun 2007 13:43:51 -0500
Subject: [R] reading BMP or TIFF files
In-Reply-To: <007d01c7a929$57024bb0$6943474b@Meglenhome>
References: <007d01c7a929$57024bb0$6943474b@Meglenhome>
Message-ID: <509e0620706071143x45a2c4efv844774339c486a94@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070607/fcdbb598/attachment.pl 

From slomascolo at zoo.ufl.edu  Thu Jun  7 21:26:40 2007
From: slomascolo at zoo.ufl.edu (Silvia Lomascolo)
Date: Thu, 7 Jun 2007 12:26:40 -0700 (PDT)
Subject: [R] Averaging across rows & columns
Message-ID: <11014649.post@talk.nabble.com>


I use Windows, R version 2.4.1.

I have a dataset in which columns 1-3 are replicates, 4-6, are replicates,
etc. I need to calculate an average for every set of replicates (columns
1-3, 4-6, 7-9, etc.) AND each set of replicates should be averaged every 14
rows (for more detail, to measure fruit color using a spectrometer, I
recorded three readings per fruit -replicates- that I need to average to get
one reading per fruit; each row is a point in the light spectrum and I need
to calculate an average reading every 5nm -14 rows- for each fruit).

Someone proposed to another user who wanted an avg across columns to do

a <- matrix(rnorm(360),nr=10)
b <- rep(1:12,each=3)
avgmat <- aggregate(a,by=list(b))

I tried doing this to get started with the columns first but it asks for an
argument FUN that has no default.  The help for aggregate isn't helping me
much (a new R user) to discover what value to give to FUN -'average' doesn't
seem to exist, and 'sum' (whatever it is supposed to sum) gives an error
saying that arguments should have the same length-

Any help will be much appreciated! 
Silvia.
-- 
View this message in context: http://www.nabble.com/Averaging-across-rows---columns-tf3885900.html#a11014649
Sent from the R help mailing list archive at Nabble.com.


From Inman.Brant at mayo.edu  Thu Jun  7 21:30:16 2007
From: Inman.Brant at mayo.edu (Inman, Brant A.   M.D.)
Date: Thu, 7 Jun 2007 14:30:16 -0500
Subject: [R] MITOOLS:   Error in eval(expr, envir,
	enclos) : invalid 'envir' argument
Message-ID: <6021CA6EF4C8374084D4F5A141F1CBBBC14D00@msgebe23.mfad.mfroot.org>


R-users & helpers:

I am using Amelia, mitools and cmprsk to fit cumulative incidence curves
to multiply imputed datasets.  The error message that I get 

"Error in eval(expr, envir, enclos) : invalid 'envir' argument"

occurs when I try to fit models to the 50 imputed datasets using the
"with.imputationList" function of mitools.  The problem seems to occur
intermittently, depending on the type of model that I try to fit to the
datasets as well as the previous code that has been executed during the
R session.  I have read the previous postings for similar problems and
have tried renaming many of my objects which has not solved the problem.


What is weird is that I have not been able to reproduce the problem
using other standard survival datasets (like pbc). It therefore seems to
have something to do with my particular analysis, likely the names of my
objects.  I cannot find the source of the problem and would greatly
appreciate any help.

Brant

Below is my session information and some code demonstrating the issue
occuring with coxph.

> sessionInfo()
R version 2.5.0 (2007-04-23) 
i386-pc-mingw32 

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 

attached base packages:
[1] "splines"   "grid"      "stats"     "graphics"  "grDevices" "utils"

[7] "datasets"  "methods"   "base"     

other attached packages:
      cmprsk      mitools       Amelia     survival    RGraphics
latticeExtra 
     "2.1-7"        "1.0"     "1.1-23"       "2.31"      "1.0-6"
"0.2-1" 
     lattice      foreign         MASS 
    "0.15-8"     "0.8-20"     "7.2-34" 


> str(utt.mi)    # My dataset
'data.frame':   168 obs. of  25 variables:
 $ age      : num  79.5 67.1 63.7 76.9 69.0 ...
 $ gender   : Factor w/ 2 levels "0","1": 1 2 2 2 1 2 2 2 2 2 ...
 $ symptoms : Factor w/ 2 levels "0","1": 1 2 1 1 2 1 2 1 1 2 ...
 $ site     : Factor w/ 3 levels "1","2","3": 1 1 2 1 2 1 1 2 1 3 ...
 $ multifoc : Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 1 1 2 ...
 $ ctnm     : Factor w/ 2 levels "1","2": 1 NA 2 1 2 2 1 NA 1 2 ...
 $ prebca   : Factor w/ 2 levels "0","1": 1 1 1 1 2 1 2 1 1 1 ...
 $ precystec: Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 1 1 1 ...
 $ surgery  : Factor w/ 2 levels "1","2": 1 1 2 1 2 1 1 1 1 1 ...
 $ ptnm.t   : Factor w/ 5 levels "0","1","2","3",..: 3 3 5 1 2 4 2 1 1 5
...
 $ grade    : Factor w/ 3 levels "1","2","3": 2 2 3 2 2 3 2 1 1 3 ...
 $ histol   : Factor w/ 2 levels "0","1": 2 2 2 2 2 2 2 2 2 2 ...
 $ postbca  : Factor w/ 2 levels "0","1": 2 1 2 2 2 NA 2 1 1 1 ...
 $ postcyst : Factor w/ 2 levels "0","1": 1 1 1 2 1 1 1 1 1 1 ...
 $ chemo    : Factor w/ 2 levels "0","1": 1 1 2 1 1 2 2 1 1 2 ...
 $ mets     : Factor w/ 2 levels "0","1": 1 2 2 1 2 2 2 1 1 2 ...
 $ status   : Factor w/ 4 levels "1","2","3","4": 1 3 2 1 3 3 3 1 1 3
...
 $ futime   : num  10.46  1.15  2.43  2.83  6.82 ...
 $ smk      : Factor w/ 2 levels "0","1": 2 2 2 1 2 1 2 1 2 2 ...
 $ surg.yr  : int  88 94 92 93 86 85 95 98 91 85 ...
 $ nodes    : Factor w/ 2 levels "0","1": 1 1 2 1 1 2 1 1 1 2 ...
 $ os       : num  0 1 0 0 1 1 1 0 0 1 ...
 $ css      : num  0 1 0 0 1 1 1 0 0 1 ...
 $ rfs      : num  0 1 1 0 1 1 1 0 0 1 ...
 $ comp     : num  0 1 1 0 1 1 1 0 0 1 ...

> set.seed(200)
> M <- 50 			# Number of imputations
> am.imp <- amelia(utt.mi, m=M, p2s=1, startvals=1, write.out=F,
+ idvars=c('os','css','rfs','comp'), 
+
noms=c('gender','symptoms','site','multifoc','ctnm','prebca','precystec'
,
+ 'smk','surgery','ptnm.t','nodes','grade','histol','postbca',
+ 'postcyst','chemo','mets','status'),
+ sqrts=c('futime'))
-- Imputation 1 --

 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 
21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 

<snip>

-- Imputation 50 --

 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 
21 22 23 24 25 26 

> MIset <- imputationList(am.imp[1:M])
> mifit <- with(MIset, 
+ coxph(Surv(futime, os) ~ age + symptoms + ctnm + smk))

Error in eval(expr, envir, enclos) : invalid 'envir' argument


From deepayan.sarkar at gmail.com  Thu Jun  7 21:34:28 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Thu, 7 Jun 2007 12:34:28 -0700
Subject: [R] Display Multiple page lattice plots
In-Reply-To: <4667D299.1090603@gmail.com>
References: <4667D299.1090603@gmail.com>
Message-ID: <eb555e660706071234v47ec823ud9843b3f4afa6715@mail.gmail.com>

On 6/7/07, rhelp.20.trevva at spamgourmet.com
<rhelp.20.trevva at spamgourmet.com> wrote:
> Gudday,
>
> I am generating a series of lattice contourplots that are conditioned on a variable (Year) that has 27 different levels. If I try and put them all on one plot, it ends up pretty messy and you can't really read anything, so instead I have set the layout to 3x3, thus generating three pages of nine plots each. The problem is that I can't display all these on screen at once, because each subsequent page overwrites the previous one. I have found in the mailing lists how to print them to separate files without any problems eg.
>
>       p<-contourplot(log10(x)~lat*long|Year,
>                   data=data.tbl,
>                   layout=c(3,3))
>       png(file="Herring Distribution%02d.png",width=800,height=800)
>       print(p)
>       dev.off()
>
> but there doesn't seem to be anything about how to output multiple pages to the screen... I suspect that I may need to use the page=... option in contourplot command, but I can't seem to make it work. Its a simple, and not particularly important problem, but it sure is bugging me!
>

You haven't told us what you want to happen exactly. Gabor's solution
will work (on Windows), and a multi-page PDF file is a similar option
that's portable. Here's another option if you want multiple windows:

xyplot(1:10 ~ 1:10 | gl(3, 1, 10), layout = c(1, 1), page =
function(n) dev.copy(x11))

you should replace x11 with the appropriate choice on your platform.
This will produce an extra copy of the last page, which you can
suppress by making use of 'n' inside your page function.

(Unfortunately page = function(n) x11() does not work, even though
that would have been more natural.)

Another option is to print your trellis object in parts; e.g.

p<-contourplot(log10(x)~lat*long|Year,
                 data=data.tbl,
                 layout=c(3,3))

x11()
p[1:9]
x11()
p[10:18]
x11()
p[19:27]

-Deepayan


From asn151 at yahoo.com  Thu Jun  7 21:55:46 2007
From: asn151 at yahoo.com (Jonathan Morse)
Date: Thu, 7 Jun 2007 12:55:46 -0700 (PDT)
Subject: [R] Mandriva Spring 2007 and R
In-Reply-To: <46658B8E.9090401@gmail.com>
Message-ID: <830327.56187.qm@web62404.mail.re1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070607/7cc7a1e9/attachment.pl 

From michael.watson at bbsrc.ac.uk  Thu Jun  7 22:06:04 2007
From: michael.watson at bbsrc.ac.uk (michael watson (IAH-C))
Date: Thu, 7 Jun 2007 21:06:04 +0100
Subject: [R] Averaging across rows & columns
References: <11014649.post@talk.nabble.com>
Message-ID: <8975119BCD0AC5419D61A9CF1A923E9504AA1E12@iahce2ksrv1.iah.bbsrc.ac.uk>

Check out rowMeans to average over replicate columns first, ie:

means <- data.frame(t1=rowMeans(a[,1:3]), 
                    t2=rowMeans(a[,4:6]),
                    etc)

Then, if you want to aggregate every 14 rows:

aggregate(means, by=list(rows=rep(1:(nrow(means)/14), each=14)), mean)

Or something...

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch on behalf of Silvia Lomascolo
Sent: Thu 07/06/2007 8:26 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Averaging across rows & columns
 

I use Windows, R version 2.4.1.

I have a dataset in which columns 1-3 are replicates, 4-6, are replicates,
etc. I need to calculate an average for every set of replicates (columns
1-3, 4-6, 7-9, etc.) AND each set of replicates should be averaged every 14
rows (for more detail, to measure fruit color using a spectrometer, I
recorded three readings per fruit -replicates- that I need to average to get
one reading per fruit; each row is a point in the light spectrum and I need
to calculate an average reading every 5nm -14 rows- for each fruit).

Someone proposed to another user who wanted an avg across columns to do

a <- matrix(rnorm(360),nr=10)
b <- rep(1:12,each=3)
avgmat <- aggregate(a,by=list(b))

I tried doing this to get started with the columns first but it asks for an
argument FUN that has no default.  The help for aggregate isn't helping me
much (a new R user) to discover what value to give to FUN -'average' doesn't
seem to exist, and 'sum' (whatever it is supposed to sum) gives an error
saying that arguments should have the same length-

Any help will be much appreciated! 
Silvia.
-- 
View this message in context: http://www.nabble.com/Averaging-across-rows---columns-tf3885900.html#a11014649
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From slomascolo at zoo.ufl.edu  Thu Jun  7 22:44:57 2007
From: slomascolo at zoo.ufl.edu (Silvia Lomascolo)
Date: Thu, 7 Jun 2007 13:44:57 -0700 (PDT)
Subject: [R] Averaging across rows & columns
In-Reply-To: <8975119BCD0AC5419D61A9CF1A923E9504AA1E12@iahce2ksrv1.iah.bbsrc.ac.uk>
References: <11014649.post@talk.nabble.com>
	<8975119BCD0AC5419D61A9CF1A923E9504AA1E12@iahce2ksrv1.iah.bbsrc.ac.uk>
Message-ID: <11015925.post@talk.nabble.com>




michael watson (IAH-C) wrote:
> 
> Check out rowMeans to average over replicate columns first, ie:
> 
> means <- data.frame(t1=rowMeans(a[,1:3]), 
>                     t2=rowMeans(a[,4:6]),
>                     etc)
> 
> Then, if you want to aggregate every 14 rows:
> 
> aggregate(means, by=list(rows=rep(1:(nrow(means)/14), each=14)), mean)
> 
> Or something...
> 
> YES! This seems to work. Thank you!
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch on behalf of Silvia Lomascolo
> Sent: Thu 07/06/2007 8:26 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Averaging across rows & columns
>  
> 
> I use Windows, R version 2.4.1.
> 
> I have a dataset in which columns 1-3 are replicates, 4-6, are replicates,
> etc. I need to calculate an average for every set of replicates (columns
> 1-3, 4-6, 7-9, etc.) AND each set of replicates should be averaged every
> 14
> rows (for more detail, to measure fruit color using a spectrometer, I
> recorded three readings per fruit -replicates- that I need to average to
> get
> one reading per fruit; each row is a point in the light spectrum and I
> need
> to calculate an average reading every 5nm -14 rows- for each fruit).
> 
> Someone proposed to another user who wanted an avg across columns to do
> 
> a <- matrix(rnorm(360),nr=10)
> b <- rep(1:12,each=3)
> avgmat <- aggregate(a,by=list(b))
> 
> I tried doing this to get started with the columns first but it asks for
> an
> argument FUN that has no default.  The help for aggregate isn't helping me
> much (a new R user) to discover what value to give to FUN -'average'
> doesn't
> seem to exist, and 'sum' (whatever it is supposed to sum) gives an error
> saying that arguments should have the same length-
> 
> Any help will be much appreciated! 
> Silvia.
> -- 
> View this message in context:
> http://www.nabble.com/Averaging-across-rows---columns-tf3885900.html#a11014649
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/Averaging-across-rows---columns-tf3885900.html#a11015925
Sent from the R help mailing list archive at Nabble.com.


From villegas.ro at gmail.com  Thu Jun  7 23:13:33 2007
From: villegas.ro at gmail.com (R. Villegas)
Date: Thu, 7 Jun 2007 23:13:33 +0200
Subject: [R] update packages with R on Vista: error
In-Reply-To: <466809D8.1020603@gmx.net>
References: <4667D730.9090403@gmx.net>
	<Pine.LNX.4.64.0706071159250.19222@gannet.stats.ox.ac.uk>
	<466809D8.1020603@gmx.net>
Message-ID: <29cf68350706071413x6a33af82l49f2ff551b74d1e1@mail.gmail.com>

If R is installed within "Program Files", one of Vista's security
settings may interfere with the -update- process.

The setting may be disabled globally by choosing:
Windows (Start) menu, Control Panels, User Accounts and Family
Safety (green title), User Accounts (green title), and
Turn User Account Control on or off (very bottom).  You will be
prompted for permission to continue; click continue.  On the
screen you will see a checkbox titled "Use User Account Control
(UAC) to help protect your computer".  Uncheck this and click
the OK button to save the changes.  Windows Vista will now allow
programs, including R, to update files in "Program Files".

Rod.


2007/6/7, Stefan Grosse <singularitaet at gmx.net>:
> Actually the packages R wants to update are: VR, cluster, lattice, mgcv,
> nlme and rcompgen. I did how described in the R-Win-FAQ create a
> .Renviron File containing the path to the win-library that R already
> created (R_LIBS=C: ... ). I also tried to add R_LIBS= as Rgui parameter
> from within Tinn-R. Additionally I tried to leave a file named
> Renviron.site in the etc library. Nothing worked thus far.
>
> Interestingly installing packages does work fine even without specifying
> the R_LIBS path manually with any of the above mentioned methods.
>
> Even more puzzling is that even when I install eg. nlme manually via
> install.packages("nlme") it works but R still wants to update it. Even
> though e.g. library(nlme), ?nlme shows that the latest version is
> installed.
>
> I would guess there is some problem with the library path variable in
> the update program...
>
> Stefan
>
>
> -------- Original Message  --------
> Subject: Re:[R] update packages with R on Vista: error
> From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
> To: Stefan Grosse <singularitaet at gmx.net>
> Date: 07.06.2007 13:01
> > See the rw-FAQ, which describes this in detail.
> >
> > Almost certainly you are trying to update the package 'cluster' which
> > is in the main library.  But as you used the GUI, we can't see that.
> >
> > On Thu, 7 Jun 2007, Stefan Grosse wrote:
> >
> >> Dear R-list,
> >>
> >> I have encountered the following error message trying to update R
> >> packages:
> >>
> >>> update.packages(ask='graphics')
> >> Warning in install.packages(update[instlib == l, "Package"], l,
> >> contriburl = contriburl,  :
> >>         'lib' is not writable
> >> Error in install.packages(update[instlib == l, "Package"], l, contriburl
> >> = contriburl,  :
> >>        unable to install packages
> >>
> >> I  remember did not have the problem on the last update where R
> >> installed the files then in the Documents/R folder on my user account.
> >> Any ideas how to handle this? I made the directories completely writable
> >> so I do not know where the problem is now (especially since update
> >> worked before...)
> >>
> >> Stefan
> >>
> >> PS: Tinn-R 1.19.2.3 + R 2.5.0 on Vista Business
> >>
> >> ______________________________________________
> >> R-help at stat.math.ethz.ch mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jrkrideau at yahoo.ca  Thu Jun  7 23:17:39 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Thu, 7 Jun 2007 17:17:39 -0400 (EDT)
Subject: [R] character to time problem
Message-ID: <603794.26626.qm@web32807.mail.mud.yahoo.com>

I am trying to clean up some dates and I am clearly
doing something wrong.  I have laid out an example
that seems to show what is happening with the "real"
data.  The  coding is lousy but it looks like it
should have worked.

Can anyone suggest a) why I am getting that NA
appearing after the strptime() command and b) why the
NA is disappearing in the sort()? It happens with
na.rm=TRUE  and na.rm=FALSE
-------------------------------------------------
aa  <- data.frame( c("12/05/2001", " ", "30/02/1995",
NA, "14/02/2007", "M" ) )
names(aa)  <- "times"
aa[is.na(aa)] <- "M"
aa[aa==" "]  <- "M"
bb <- unlist(subset(aa, aa[,1] !="M"))
dates <- strptime(bb, "%d/%m/%Y")
dates
sort(dates)
--------------------------------------------------

Session Info
R version 2.4.1 (2006-12-18) 
i386-pc-mingw32 

locale:
LC_COLLATE=English_Canada.1252;
LC_CTYPE=English_Canada.1252;
LC_MONETARY=English_Canada.1252;
LC_NUMERIC=C;LC_TIME=English_Canada.1252

attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"    
"datasets"  "methods"   "base"     

other attached packages:
  gdata   Hmisc 
"2.3.1" "3.3-2" 

 (Yes I know I'm out of date but I don't like
upgrading just as I am finishing a project)

Thanks


From ggrothendieck at gmail.com  Fri Jun  8 00:01:25 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 7 Jun 2007 18:01:25 -0400
Subject: [R] character to time problem
In-Reply-To: <603794.26626.qm@web32807.mail.mud.yahoo.com>
References: <603794.26626.qm@web32807.mail.mud.yahoo.com>
Message-ID: <971536df0706071501s6c744f12o3ad64e98d590bcc9@mail.gmail.com>

Perhaps you want one of these:

> sort(as.Date(aa$times, "%d/%m/%Y"))
[1] "1995-03-02" "2001-05-12" "2007-02-14"

> sort(as.Date(aa$times, "%d/%m/%Y"), na.last = TRUE)
[1] "1995-03-02" "2001-05-12" "2007-02-14" NA           NA
[6] NA


On 6/7/07, John Kane <jrkrideau at yahoo.ca> wrote:
> I am trying to clean up some dates and I am clearly
> doing something wrong.  I have laid out an example
> that seems to show what is happening with the "real"
> data.  The  coding is lousy but it looks like it
> should have worked.
>
> Can anyone suggest a) why I am getting that NA
> appearing after the strptime() command and b) why the
> NA is disappearing in the sort()? It happens with
> na.rm=TRUE  and na.rm=FALSE
> -------------------------------------------------
> aa  <- data.frame( c("12/05/2001", " ", "30/02/1995",
> NA, "14/02/2007", "M" ) )
> names(aa)  <- "times"
> aa[is.na(aa)] <- "M"
> aa[aa==" "]  <- "M"
> bb <- unlist(subset(aa, aa[,1] !="M"))
> dates <- strptime(bb, "%d/%m/%Y")
> dates
> sort(dates)
> --------------------------------------------------
>
> Session Info
> R version 2.4.1 (2006-12-18)
> i386-pc-mingw32
>
> locale:
> LC_COLLATE=English_Canada.1252;
> LC_CTYPE=English_Canada.1252;
> LC_MONETARY=English_Canada.1252;
> LC_NUMERIC=C;LC_TIME=English_Canada.1252
>
> attached base packages:
> [1] "stats"     "graphics"  "grDevices" "utils"
> "datasets"  "methods"   "base"
>
> other attached packages:
>  gdata   Hmisc
> "2.3.1" "3.3-2"
>
>  (Yes I know I'm out of date but I don't like
> upgrading just as I am finishing a project)
>
> Thanks
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bli1 at bcm.tmc.edu  Fri Jun  8 00:15:05 2007
From: bli1 at bcm.tmc.edu (Bingshan Li)
Date: Thu, 7 Jun 2007 17:15:05 -0500
Subject: [R] power of logistic regression in case control design
Message-ID: <363ED4EB-3150-435C-98EB-3E61EFF55CAE@bcm.tmc.edu>

Hi All,

This is not directly related to R but I post the questions here since  
there are a lot of experts on statistics. I want to calculate power  
of logistic regression using likelihood ratio test in unmatched case  
control design. The paper I have read is "power calculations for  
likelihood ratio tests in generalized linear models" by Steven G.  
Self in 1992. They showed a formula for calculating power for  
prospective cohort design. Can I plug in the various parameters from  
case control study? That is, can I pretend that the case control data  
I have is a prospective cohort study? I guess I can do this since in  
principal logistic regression is valid for both case control and  
cohort design in estimating odds ratio.

Thanks a lot!


From tkeitt at gmail.com  Fri Jun  8 00:22:42 2007
From: tkeitt at gmail.com (Tim Keitt)
Date: Thu, 7 Jun 2007 17:22:42 -0500
Subject: [R] Ubu edgy + latest CRAN R + Rmpi = no go
Message-ID: <6262c54c0706071522s72d0102bt98e43a94626b6b7e@mail.gmail.com>

I'm just curious if anyone else has had problems with this
configuration. I added the CRAN repository to apt and installed 2.5.0
with apt-get. I then did an install.packages("Rmpi") on cluster nodes.
Rmpi loads and lamhosts() shows the nodes, but mpi.spawn.Rslaves()
fails (something to do with temp files?). Rmpi works fine with the
Edgy-native version of R (2.3.x) and installing Edgy's r-cran-rmpi
with apt. (But I need some other packages that only work in 2.4+!)
Could this be a problem with the latest Ubu debs on CRAN? The Rmpi
author says his R 2.5 setup works fine. CC me please as I'm not
subscribed.

THK

-- 
Timothy H. Keitt, University of Texas at Austin
Contact info and schedule at http://www.keittlab.org/tkeitt/
Reprints at http://www.keittlab.org/tkeitt/papers/
ODF attachment? See http://www.openoffice.org/


From jasoncbarnhart at msn.com  Fri Jun  8 00:43:48 2007
From: jasoncbarnhart at msn.com (Jason Barnhart)
Date: Thu, 7 Jun 2007 15:43:48 -0700
Subject: [R] character to time problem
References: <603794.26626.qm@web32807.mail.mud.yahoo.com>
Message-ID: <BAY116-DAV8394EF8D7EA66D218CE96CF260@phx.gbl>

Hi John,

a) The NA appears because '30/02/1995' is not a valid date.

    > strptime('30/02/1995' , "%d/%m/%Y")
    [1] NA

b) dates which has the following classes uses sort.POSIXlt which in 
turns sets na.last to NA.  ?order details how NA's are handled in 
ordering data via na.last.

    > class(dates)
    [1] "POSIXt"  "POSIXlt"

    > methods(sort)
    [1] sort.default sort.POSIXlt

    > sort.POSIXlt
    function (x, decreasing = FALSE, na.last = NA, ...)
    x[order(as.POSIXct(x), na.last = na.last, decreasing = 
decreasing)]
    <environment: namespace:base>

After resetting the Feb. date the code works.

HTH,
-jason

----- Original Message ----- 
From: "John Kane" <jrkrideau at yahoo.ca>
To: "R R-help" <r-help at stat.math.ethz.ch>
Sent: Thursday, June 07, 2007 2:17 PM
Subject: [R] character to time problem


>I am trying to clean up some dates and I am clearly
> doing something wrong.  I have laid out an example
> that seems to show what is happening with the "real"
> data.  The  coding is lousy but it looks like it
> should have worked.
>
> Can anyone suggest a) why I am getting that NA
> appearing after the strptime() command and b) why the
> NA is disappearing in the sort()? It happens with
> na.rm=TRUE  and na.rm=FALSE
> -------------------------------------------------
> aa  <- data.frame( c("12/05/2001", " ", "30/02/1995",
> NA, "14/02/2007", "M" ) )
> names(aa)  <- "times"
> aa[is.na(aa)] <- "M"
> aa[aa==" "]  <- "M"
> bb <- unlist(subset(aa, aa[,1] !="M"))
> dates <- strptime(bb, "%d/%m/%Y")
> dates
> sort(dates)
> --------------------------------------------------
>
> Session Info
> R version 2.4.1 (2006-12-18)
> i386-pc-mingw32
>
> locale:
> LC_COLLATE=English_Canada.1252;
> LC_CTYPE=English_Canada.1252;
> LC_MONETARY=English_Canada.1252;
> LC_NUMERIC=C;LC_TIME=English_Canada.1252
>
> attached base packages:
> [1] "stats"     "graphics"  "grDevices" "utils"
> "datasets"  "methods"   "base"
>
> other attached packages:
>  gdata   Hmisc
> "2.3.1" "3.3-2"
>
> (Yes I know I'm out of date but I don't like
> upgrading just as I am finishing a project)
>
> Thanks
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From irishhacker at gmail.com  Fri Jun  8 02:01:41 2007
From: irishhacker at gmail.com (Robert Wilkins)
Date: Thu, 7 Jun 2007 19:01:41 -0500
Subject: [R] Tools For Preparing Data For Analysis
Message-ID: <874da0b40706071701m55cd42fem15f55a8fcde04f17@mail.gmail.com>

As noted on the R-project web site itself ( www.r-project.org ->
Manuals -> R Data Import/Export ), it can be cumbersome to prepare
messy and dirty data for analysis with the R tool itself. I've also
seen at least one S programming book (one of the yellow Springer ones)
that says, more briefly, the same thing.
The R Data Import/Export page recommends examples using SAS, Perl,
Python, and Java. It takes a bit of courage to say that ( when you go
to a corporate software web site, you'll never see a page saying "This
is the type of problem that our product is not the best at, here's
what we suggest instead" ). I'd like to provide a few more
suggestions, especially for volunteers who are willing to evaluate new
candidates.

SAS is fine if you're not paying for the license out of your own
pocket. But maybe one reason you're using R is you don't have
thousands of spare dollars.
Using Java for data cleaning is an exercise in sado-masochism, Java
has a learning curve (almost) as difficult as C++.

There are different types of data transformation, and for some data
preparation problems an all-purpose programming language is a good
choice ( i.e. Perl , or maybe Python/Ruby ). Perl, for example, has
excellent regular expression facilities.

However, for some types of complex demanding data preparation
problems, an all-purpose programming language is a poor choice. For
example: cleaning up and preparing clinical lab data and adverse event
data - you could do it in Perl, but it would take way, way too much
time. A specialized programming language is needed. And since data
transformation is quite different from data query, SQL is not the
ideal solution either.

There are only three statistical programming languages that are
well-known, all dating from the 1970s: SPSS, SAS, and S. SAS is more
popular than S for data cleaning.

If you're an R user with difficult data preparation problems, frankly
you are out of luck, because the products I'm about to mention are
new, unknown, and therefore regarded as immature. And while the
founders of these products would be very happy if you kicked the
tires, most people don't like to look at brand new products. Most
innovators and inventers don't realize this, I've learned it the hard
way.

But if you are a volunteer who likes to help out by evaluating,
comparing, and reporting upon new candidates, well you could certainly
help out R users and the developers of the products by kicking the
tires of these products. And there is a huge need for such volunteers.

1. DAP
This is an open source implementation of SAS.
The founder: Susan Bassein
Find it at: directory.fsf.org/math/stats (GNU GPL)

2. PSPP
This is an open source implementation of SPSS.
The relatively early version number might not give a good idea of how
mature the
data transformation features are, it reflects the fact that he has
only started doing the statistical tests.
The founder: Ben Pfaff, either a grad student or professor at Stanford CS dept.
Also at : directory.fsf.org/math/stats (GNU GPL)

3. Vilno
This uses a programming language similar to SPSS and SAS, but quite unlike S.
Essentially, it's a substitute for the SAS datastep, and also
transposes data and calculates averages and such. (No t-tests or
regressions in this version). I created this, during the years
2001-2006 mainly. It's version 0.85, and has a fairly low bug rate, in
my opinion. The tarball includes about 100 or so test cases used for
debugging - for logical calculation errors, but not for extremely high
volumes of data.
The maintenance of Vilno has slowed down, because I am currently
(desparately) looking for employment. But once I've found new
employment and living quarters and settled in, I will continue to
enhance Vilno in my spare time.
The founder: that would be me, Robert Wilkins
Find it at: code.google.com/p/vilno ( GNU GPL )
( In particular, the tarball at code.google.com/p/vilno/downloads/list
, since I have yet to figure out how to use Subversion ).


4. Who knows?
It was not easy to find out about the existence of DAP and PSPP. So
who knows what else is out there. However, I think you'll find a lot
more statistics software ( regression , etc ) out there, and not so
much data transformation software. Not many people work on data
preparation software. In fact, the category is so obscure that there
isn't one agreed term: data cleaning , data munging , data crunching ,
or just getting the data ready for analysis.


From pev340002003 at yahoo.com  Thu Jun  7 23:50:12 2007
From: pev340002003 at yahoo.com (tronter)
Date: Thu, 7 Jun 2007 14:50:12 -0700 (PDT)
Subject: [R] Nonlinear Regression
Message-ID: <11016968.post@talk.nabble.com>


Hello

I followed the example in page 59, chapter 11 of the 'Introduction to R'
manual. I entered my own x,y data. I used the least squares. My function has
5 parameters: p[1], p[2], p[3], p[4], p[5]. I plotted the x-y data. Then I
used lines(spline(xfit,yfit)) to overlay best curves on the data while
changing the parameters. My question is how do I calculate the residual sum
of squares. In the example they have the following:

df <- data.frame( x=x, y=y)

fit <- nls(y ~SSmicmen(s, Vm, K), df)

fit


In the second line how would I input my function? Would it be:

fit <- nls(y ~ myfunction(p[1], p[2], p[3], p[4], p[5]), df) where
myfunction is the actual function? My function doesnt have a name, so should
I just enter it?

Thanks

-- 
View this message in context: http://www.nabble.com/Nonlinear-Regression-tf3886617.html#a11016968
Sent from the R help mailing list archive at Nabble.com.


From hb at stat.berkeley.edu  Fri Jun  8 02:08:43 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Fri, 8 Jun 2007 02:08:43 +0200
Subject: [R] reading BMP or TIFF files
In-Reply-To: <007d01c7a929$57024bb0$6943474b@Meglenhome>
References: <007d01c7a929$57024bb0$6943474b@Meglenhome>
Message-ID: <59d7961d0706071708i415a6235ma019a1bdeb1c5d59@mail.gmail.com>

See the EBImage package on Bioconductor. /Henrik

On 6/7/07, Bob Meglen <bmeglen at comcast.net> wrote:
> I realize that  this question has been asked before (2003);
>
> From: Yi-Xiong Zhou
> Date: Sat 22 Nov 2003 - 10:57:35 EST
>
> but I am hoping that the answer has changed. Namely, I would
> rather read the BMP  (or TIFF) files directly instead of putting
> them though a separate utility for conversion as suggested by,
>
> From: Prof Brian Ripley
> Date: Sat 22 Nov 2003 - 15:23:33 EST
>
> "Even easier is to convert .bmp to .pnm by an external utility. For
> example, `convert' from the ImageMagick suite (www.imagemagick.org) can do
> this. "
>
>
>
> Thanks,
> Robert Meglen
> bmeglen at comcast.net
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From rduval at gmail.com  Fri Jun  8 03:23:35 2007
From: rduval at gmail.com (Robert Duval)
Date: Thu, 7 Jun 2007 20:23:35 -0500
Subject: [R] Tools For Preparing Data For Analysis
In-Reply-To: <874da0b40706071701m55cd42fem15f55a8fcde04f17@mail.gmail.com>
References: <874da0b40706071701m55cd42fem15f55a8fcde04f17@mail.gmail.com>
Message-ID: <2b6e342f0706071823x7ec713a5vd8ec4128b4cad07f@mail.gmail.com>

An additional option for Windows users is Micro Osiris

http://www.microsiris.com/

best
robert

On 6/7/07, Robert Wilkins <irishhacker at gmail.com> wrote:
> As noted on the R-project web site itself ( www.r-project.org ->
> Manuals -> R Data Import/Export ), it can be cumbersome to prepare
> messy and dirty data for analysis with the R tool itself. I've also
> seen at least one S programming book (one of the yellow Springer ones)
> that says, more briefly, the same thing.
> The R Data Import/Export page recommends examples using SAS, Perl,
> Python, and Java. It takes a bit of courage to say that ( when you go
> to a corporate software web site, you'll never see a page saying "This
> is the type of problem that our product is not the best at, here's
> what we suggest instead" ). I'd like to provide a few more
> suggestions, especially for volunteers who are willing to evaluate new
> candidates.
>
> SAS is fine if you're not paying for the license out of your own
> pocket. But maybe one reason you're using R is you don't have
> thousands of spare dollars.
> Using Java for data cleaning is an exercise in sado-masochism, Java
> has a learning curve (almost) as difficult as C++.
>
> There are different types of data transformation, and for some data
> preparation problems an all-purpose programming language is a good
> choice ( i.e. Perl , or maybe Python/Ruby ). Perl, for example, has
> excellent regular expression facilities.
>
> However, for some types of complex demanding data preparation
> problems, an all-purpose programming language is a poor choice. For
> example: cleaning up and preparing clinical lab data and adverse event
> data - you could do it in Perl, but it would take way, way too much
> time. A specialized programming language is needed. And since data
> transformation is quite different from data query, SQL is not the
> ideal solution either.
>
> There are only three statistical programming languages that are
> well-known, all dating from the 1970s: SPSS, SAS, and S. SAS is more
> popular than S for data cleaning.
>
> If you're an R user with difficult data preparation problems, frankly
> you are out of luck, because the products I'm about to mention are
> new, unknown, and therefore regarded as immature. And while the
> founders of these products would be very happy if you kicked the
> tires, most people don't like to look at brand new products. Most
> innovators and inventers don't realize this, I've learned it the hard
> way.
>
> But if you are a volunteer who likes to help out by evaluating,
> comparing, and reporting upon new candidates, well you could certainly
> help out R users and the developers of the products by kicking the
> tires of these products. And there is a huge need for such volunteers.
>
> 1. DAP
> This is an open source implementation of SAS.
> The founder: Susan Bassein
> Find it at: directory.fsf.org/math/stats (GNU GPL)
>
> 2. PSPP
> This is an open source implementation of SPSS.
> The relatively early version number might not give a good idea of how
> mature the
> data transformation features are, it reflects the fact that he has
> only started doing the statistical tests.
> The founder: Ben Pfaff, either a grad student or professor at Stanford CS dept.
> Also at : directory.fsf.org/math/stats (GNU GPL)
>
> 3. Vilno
> This uses a programming language similar to SPSS and SAS, but quite unlike S.
> Essentially, it's a substitute for the SAS datastep, and also
> transposes data and calculates averages and such. (No t-tests or
> regressions in this version). I created this, during the years
> 2001-2006 mainly. It's version 0.85, and has a fairly low bug rate, in
> my opinion. The tarball includes about 100 or so test cases used for
> debugging - for logical calculation errors, but not for extremely high
> volumes of data.
> The maintenance of Vilno has slowed down, because I am currently
> (desparately) looking for employment. But once I've found new
> employment and living quarters and settled in, I will continue to
> enhance Vilno in my spare time.
> The founder: that would be me, Robert Wilkins
> Find it at: code.google.com/p/vilno ( GNU GPL )
> ( In particular, the tarball at code.google.com/p/vilno/downloads/list
> , since I have yet to figure out how to use Subversion ).
>
>
> 4. Who knows?
> It was not easy to find out about the existence of DAP and PSPP. So
> who knows what else is out there. However, I think you'll find a lot
> more statistics software ( regression , etc ) out there, and not so
> much data transformation software. Not many people work on data
> preparation software. In fact, the category is so obscure that there
> isn't one agreed term: data cleaning , data munging , data crunching ,
> or just getting the data ready for analysis.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From f.harrell at vanderbilt.edu  Fri Jun  8 04:25:47 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Thu, 07 Jun 2007 21:25:47 -0500
Subject: [R] Tools For Preparing Data For Analysis
In-Reply-To: <874da0b40706071701m55cd42fem15f55a8fcde04f17@mail.gmail.com>
References: <874da0b40706071701m55cd42fem15f55a8fcde04f17@mail.gmail.com>
Message-ID: <4668BE2B.7040109@vanderbilt.edu>

Robert Wilkins wrote:
> As noted on the R-project web site itself ( www.r-project.org ->
> Manuals -> R Data Import/Export ), it can be cumbersome to prepare
> messy and dirty data for analysis with the R tool itself. I've also
> seen at least one S programming book (one of the yellow Springer ones)
> that says, more briefly, the same thing.
> The R Data Import/Export page recommends examples using SAS, Perl,
> Python, and Java. It takes a bit of courage to say that ( when you go
> to a corporate software web site, you'll never see a page saying "This
> is the type of problem that our product is not the best at, here's
> what we suggest instead" ). I'd like to provide a few more
> suggestions, especially for volunteers who are willing to evaluate new
> candidates.
> 
> SAS is fine if you're not paying for the license out of your own
> pocket. But maybe one reason you're using R is you don't have
> thousands of spare dollars.
> Using Java for data cleaning is an exercise in sado-masochism, Java
> has a learning curve (almost) as difficult as C++.
> 
> There are different types of data transformation, and for some data
> preparation problems an all-purpose programming language is a good
> choice ( i.e. Perl , or maybe Python/Ruby ). Perl, for example, has
> excellent regular expression facilities.
> 
> However, for some types of complex demanding data preparation
> problems, an all-purpose programming language is a poor choice. For
> example: cleaning up and preparing clinical lab data and adverse event
> data - you could do it in Perl, but it would take way, way too much
> time. A specialized programming language is needed. And since data
> transformation is quite different from data query, SQL is not the
> ideal solution either.

We deal with exactly those kinds of data solely using R.  R is 
exceptionally powerful for data manipulation, just a bit hard to learn. 
  Many examples are at 
http://biostat.mc.vanderbilt.edu/twiki/pub/Main/RS/sintro.pdf

Frank

> 
> There are only three statistical programming languages that are
> well-known, all dating from the 1970s: SPSS, SAS, and S. SAS is more
> popular than S for data cleaning.
> 
> If you're an R user with difficult data preparation problems, frankly
> you are out of luck, because the products I'm about to mention are
> new, unknown, and therefore regarded as immature. And while the
> founders of these products would be very happy if you kicked the
> tires, most people don't like to look at brand new products. Most
> innovators and inventers don't realize this, I've learned it the hard
> way.
> 
> But if you are a volunteer who likes to help out by evaluating,
> comparing, and reporting upon new candidates, well you could certainly
> help out R users and the developers of the products by kicking the
> tires of these products. And there is a huge need for such volunteers.
> 
> 1. DAP
> This is an open source implementation of SAS.
> The founder: Susan Bassein
> Find it at: directory.fsf.org/math/stats (GNU GPL)
> 
> 2. PSPP
> This is an open source implementation of SPSS.
> The relatively early version number might not give a good idea of how
> mature the
> data transformation features are, it reflects the fact that he has
> only started doing the statistical tests.
> The founder: Ben Pfaff, either a grad student or professor at Stanford CS dept.
> Also at : directory.fsf.org/math/stats (GNU GPL)
> 
> 3. Vilno
> This uses a programming language similar to SPSS and SAS, but quite unlike S.
> Essentially, it's a substitute for the SAS datastep, and also
> transposes data and calculates averages and such. (No t-tests or
> regressions in this version). I created this, during the years
> 2001-2006 mainly. It's version 0.85, and has a fairly low bug rate, in
> my opinion. The tarball includes about 100 or so test cases used for
> debugging - for logical calculation errors, but not for extremely high
> volumes of data.
> The maintenance of Vilno has slowed down, because I am currently
> (desparately) looking for employment. But once I've found new
> employment and living quarters and settled in, I will continue to
> enhance Vilno in my spare time.
> The founder: that would be me, Robert Wilkins
> Find it at: code.google.com/p/vilno ( GNU GPL )
> ( In particular, the tarball at code.google.com/p/vilno/downloads/list
> , since I have yet to figure out how to use Subversion ).
> 
> 
> 4. Who knows?
> It was not easy to find out about the existence of DAP and PSPP. So
> who knows what else is out there. However, I think you'll find a lot
> more statistics software ( regression , etc ) out there, and not so
> much data transformation software. Not many people work on data
> preparation software. In fact, the category is so obscure that there
> isn't one agreed term: data cleaning , data munging , data crunching ,
> or just getting the data ready for analysis.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From ssls.sddd at gmail.com  Fri Jun  8 04:31:13 2007
From: ssls.sddd at gmail.com (ssls sddd)
Date: Thu, 7 Jun 2007 19:31:13 -0700
Subject: [R] How to load a big txt file
In-Reply-To: <644e1f320706070448n551d72c0r633792cc00bdc83f@mail.gmail.com>
References: <b87120290706061822h2794512av24762fa964d12905@mail.gmail.com>
	<644e1f320706061829v75b133a7o3a32ad0ff2f24449@mail.gmail.com>
	<b87120290706070252o19219518peba56229d805f415@mail.gmail.com>
	<644e1f320706070448n551d72c0r633792cc00bdc83f@mail.gmail.com>
Message-ID: <b87120290706071931v588689b3gceb0463856fd87a8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070607/edaa1888/attachment.pl 

From ssls.sddd at gmail.com  Fri Jun  8 04:42:22 2007
From: ssls.sddd at gmail.com (ssls sddd)
Date: Thu, 7 Jun 2007 19:42:22 -0700
Subject: [R] How to do clustering
Message-ID: <b87120290706071942n52d4a72dl499703a9dec82459@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070607/2c2a3a9a/attachment.pl 

From bcarvalh at jhsph.edu  Fri Jun  8 04:45:19 2007
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Thu, 7 Jun 2007 22:45:19 -0400
Subject: [R] How to do clustering
In-Reply-To: <b87120290706071942n52d4a72dl499703a9dec82459@mail.gmail.com>
References: <b87120290706071942n52d4a72dl499703a9dec82459@mail.gmail.com>
Message-ID: <8AAF1778-0FB4-451F-A40E-3246444AF18F@jhsph.edu>

Hi Alex,

just in case you're trying to get genotypes from the Affymetrix 500K  
set, you might want to check the oligo package available on  
BioConductor.

best,
b

On Jun 7, 2007, at 10:42 PM, ssls sddd wrote:

> Dear List,
>
> I have another question to bother you about how to do clustering.
> My data consists of 49 columns (49 variables) and 238804 rows.
> I would like to do hierarchical clustering (unsupervised clustering
> and PCA). So far I tried pvclust (www.is.titech.ac.jp/~shimo/prog/ 
> *pvclust*
> /)
> but I always had the problem like for R like "cannot allocate the  
> memory".
>
> I am curious about what else packages can perform the clustering  
> analysis
> while memory efficient.
>
> Meanwhile, is there any way that I can extract the features of each  
> cluster.
>
> In other words, I would like to identify which are responsible for
> classifying these
> variables (samples).
>
> Thanks a lot!
>
> Sincerely,
>
> Alex
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bcarvalh at jhsph.edu  Fri Jun  8 04:47:15 2007
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Thu, 7 Jun 2007 22:47:15 -0400
Subject: [R] How to do clustering
In-Reply-To: <b87120290706071942n52d4a72dl499703a9dec82459@mail.gmail.com>
References: <b87120290706071942n52d4a72dl499703a9dec82459@mail.gmail.com>
Message-ID: <88C97DF7-B855-4D0B-A866-F12BDB78EB89@jhsph.edu>

sorry, I hit send before finishing my thoughts...

and as for clustering microarray data, you might want to consider the  
bioconductor mailing list...

bioconductor at stat.math.ethz.ch

b

On Jun 7, 2007, at 10:42 PM, ssls sddd wrote:

> Dear List,
>
> I have another question to bother you about how to do clustering.
> My data consists of 49 columns (49 variables) and 238804 rows.
> I would like to do hierarchical clustering (unsupervised clustering
> and PCA). So far I tried pvclust (www.is.titech.ac.jp/~shimo/prog/ 
> *pvclust*
> /)
> but I always had the problem like for R like "cannot allocate the  
> memory".
>
> I am curious about what else packages can perform the clustering  
> analysis
> while memory efficient.
>
> Meanwhile, is there any way that I can extract the features of each  
> cluster.
>
> In other words, I would like to identify which are responsible for
> classifying these
> variables (samples).
>
> Thanks a lot!
>
> Sincerely,
>
> Alex
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From zackw at panix.com  Fri Jun  8 07:01:11 2007
From: zackw at panix.com (Zack Weinberg)
Date: Thu, 7 Jun 2007 22:01:11 -0700
Subject: [R] evaluating variables in the context of a data frame
Message-ID: <eb97335b0706072201r9ad1ba1s37bc66611d76fb68@mail.gmail.com>

Given

> D = data.frame(o=gl(2,1,4))

this works as I expected:

> evalq(o, D)
[1] 1 2 1 2
Levels: 1 2

but neither of these does:

> f <- function(x, dat) evalq(x, dat)
> f(o, D)
Error in eval(expr, envir, enclos) : object "o" not found
> g <- function(x, dat) eval(x, dat)
> g(o, D)
Error in eval(x, dat) : object "o" not found

What am I doing wrong?  This seems to be what the helpfiles say you do
to evaluate arguments in the context of a passed-in data frame...

zw


From mjankowski at gmail.com  Fri Jun  8 07:01:40 2007
From: mjankowski at gmail.com (M. Jankowski)
Date: Fri, 8 Jun 2007 00:01:40 -0500
Subject: [R] Need Help with robustbase package: fitnorm2 and plotnorm2
Message-ID: <500c63990706072201q5436112h3222a5f9b1c43cbb@mail.gmail.com>

This is my first post requesting help to this mailing list. I am new
to R. My apologies for any breach in posting etiquette. I am new to
this language and just learning my way around. I am attempting to run
some sample code and  and am confused by the error message:
Loading required package: rrcov
Error in fitNorm2(fdat[, "FSC-H"], fdat[, "SSC-H"], scalefac = ScaleFactor) :
        Required package rrcov could not be found.
In addition: Warning message:
there is no package called 'rrcov' in: library(package, lib.loc =
lib.loc, character.only = TRUE, logical = TRUE,
>

that I get when I attempt to run the following sample snippet of code.
The error above is taken from the code below. I am running Ubuntu
Linux with all the r packages listed in the Synaptic package manager
(universa). I loaded the "prada" bioconductor package as instructed in
the comments and the robustbase was downloaded and installed with the
command: "sudo R CMD INSTALL robustbase_0.2- 7.tar.gz", the robustbase
folder is in "/usr/local/lib/R/site-library/" When I type in
'library(robustbase)' no error appears; I believe robustbase is
installed correctly. The sample code was taken from FCS-prada.pdf. The
sample code was written in 2005, I understand that rrcov was made part
of the robustbase package sometime in the past year. This may be the
cause of the problem, but, if it is, I have no idea how to fix it.
Thank you in advance for helping out!

Below you will find the code that generates the error and the complete
output of the code. Let me know what I can do to get up and running!

Matt


#prada Bioconductor package
#http://www.bioconductor.org/repository/devel/vignette/norm2.pdf
# To install "prada"
#source("http://www.bioconductor.org/biocLite.R")
#biocLite("prada")

library(prada)
filepath <- system.file("extdata", "fas-Bcl2-plate323-04-04.A01", package = "pra
da")
print(filepath)
sampdat <- readFCS(filepath)
fdat <- exprs(sampdat)
print(dim(fdat))
print(colnames(fdat))

plot(fdat[, "FSC-H"], fdat[, "SSC-H"], pch = 20, col = "#303030", xlab = "FSC",
ylab = "SSC",  main = "Scatter plot FSC vs SSC")
#All of this goes as the help documentation suggests it should

# 2. Show selections for various scale factors
savepar <- par(mfrow=c(2,2))

for (Scalefactor in c(1.0, 1.5, 2.0, 2.5) )
  {
    # The next line gives the error I've included below.
    nfit <- fitNorm2 (fdat[, "FSC-H"], fdat[, "SSC-H"], scalefac = ScaleFactor)
    plotnorm2(nfit, selection = TRUE, ellipse = TRUE,
              xlab="FSC-H", ylab="SSC-H",
              main=paste("SSC-H vs. FSC-H (ScaleFactor=",ScaleFactor,")", sep=""
))
  }
par(savepar)



Loading required package: Biobase
Loading required package: tools

Welcome to Bioconductor

    Vignettes contain introductory material. To view, type
    'openVignette()' or start with 'help(Biobase)'. For details
    on reading vignettes, see the openVignette help page.

Loading required package: RColorBrewer
Loading required package: grid
Loading required package: geneplotter
Loading required package: annotate
KernSmooth 2.22 installed
Copyright M. P. Wand 1997
[1] "/usr/local/lib/R/site-library/prada/extdata/fas-Bcl2-plate323-04-04.A01"
[1] 2115    8
   $P1N    $P2N    $P3N    $P4N    $P5N    $P6N    $P7N    $P8N
"FSC-H" "SSC-H" "FL1-H" "FL2-H" "FL3-H" "FL2-A" "FL4-H"  "Time"
Loading required package: rrcov
Error in fitNorm2(fdat[, "FSC-H"], fdat[, "SSC-H"], scalefac = ScaleFactor) :
        Required package rrcov could not be found.
In addition: Warning message:
there is no package called 'rrcov' in: library(package, lib.loc =
lib.loc, character.only = TRUE, logical = TRUE,
>


From ripley at stats.ox.ac.uk  Fri Jun  8 08:02:07 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 8 Jun 2007 07:02:07 +0100 (BST)
Subject: [R] evaluating variables in the context of a data frame
In-Reply-To: <eb97335b0706072201r9ad1ba1s37bc66611d76fb68@mail.gmail.com>
References: <eb97335b0706072201r9ad1ba1s37bc66611d76fb68@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0706080657290.22532@gannet.stats.ox.ac.uk>

On Thu, 7 Jun 2007, Zack Weinberg wrote:

> Given
>
>> D = data.frame(o=gl(2,1,4))
>
> this works as I expected:
>
>> evalq(o, D)
> [1] 1 2 1 2
> Levels: 1 2
>
> but neither of these does:
>
>> f <- function(x, dat) evalq(x, dat)
>> f(o, D)
> Error in eval(expr, envir, enclos) : object "o" not found
>> g <- function(x, dat) eval(x, dat)
>> g(o, D)
> Error in eval(x, dat) : object "o" not found
>
> What am I doing wrong?  This seems to be what the helpfiles say you do
> to evaluate arguments in the context of a passed-in data frame...

When you call f(o, D), the argument 'o' is evaluated in the current 
environment ('context' in R means something different).  Because of lazy 
evaluation, it is not evaluated until evalq is called, but it evaluated as 
if it was evaluated greedily.

g(quote(o), D) will work.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From cincinattikid at bigpond.com  Fri Jun  8 02:42:08 2007
From: cincinattikid at bigpond.com (Alfonso Sammassimo)
Date: Fri, 8 Jun 2007 10:42:08 +1000
Subject: [R] match rows of data frame
Message-ID: <000c01c7a965$d81ae220$0300a8c0@Vaio>

Hi R-experts,

I have a data frame (A) , and a subset (B) of this data frame. I am trying 
to create a new data frame which gives me all the rows of B, plus the 5th 
next row(occuring in A).  I have used the below code, but it gives me all 5 
rows after the matching row. I only want the 5th.

FiveDaysLater <- A[c(sapply(match(rownames(B),rownames(A)), seq, 
length=6))),]

Any guidance much appreciated,
Thankyou.

Alfonso Sammassimo
Melbourne, Australia.


From ripley at stats.ox.ac.uk  Fri Jun  8 08:20:39 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 8 Jun 2007 07:20:39 +0100 (BST)
Subject: [R] Need Help with robustbase package: fitnorm2 and plotnorm2
In-Reply-To: <500c63990706072201q5436112h3222a5f9b1c43cbb@mail.gmail.com>
References: <500c63990706072201q5436112h3222a5f9b1c43cbb@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0706080702460.22532@gannet.stats.ox.ac.uk>

On Fri, 8 Jun 2007, M. Jankowski wrote:

> This is my first post requesting help to this mailing list. I am new
> to R. My apologies for any breach in posting etiquette.

For future reference, telling us your version of R and exact OS would have 
helped here.  The R posting guide suggests showing the output of 
sessionInfo().

Also, to help the readers, fitNorm2 (R is case-sensitive) is in 'prada', 
and the missing package is rrcov not robustbase.

> I am new to
> this language and just learning my way around. I am attempting to run
> some sample code and  and am confused by the error message:
> Loading required package: rrcov
> Error in fitNorm2(fdat[, "FSC-H"], fdat[, "SSC-H"], scalefac = ScaleFactor) :
>        Required package rrcov could not be found.
> In addition: Warning message:
> there is no package called 'rrcov' in: library(package, lib.loc =
> lib.loc, character.only = TRUE, logical = TRUE,
>
> that I get when I attempt to run the following sample snippet of code.
> The error above is taken from the code below. I am running Ubuntu
> Linux with all the r packages listed in the Synaptic package manager
> (universa). I loaded the "prada" bioconductor package as instructed in
> the comments and the robustbase was downloaded and installed with the
> command: "sudo R CMD INSTALL robustbase_0.2- 7.tar.gz", the robustbase
> folder is in "/usr/local/lib/R/site-library/" When I type in
> 'library(robustbase)' no error appears; I believe robustbase is
> installed correctly. The sample code was taken from FCS-prada.pdf. The
> sample code was written in 2005, I understand that rrcov was made part
> of the robustbase package sometime in the past year. This may be the
> cause of the problem, but, if it is, I have no idea how to fix it.

That is not the case: rrcov is a separate package, and one prada depends 
on.  So somehow you have managed to install prada without an essential 
dependency 'rrcov'.  That looks like a problem in the Debian/Ubuntu 
packaging of prada.  (There is a list R-sig-debian for such issues.)

Running install.packages("rrcov") inside R should fix this for you: if 
your R is not current (i.e. < 2.5.0) you may need to run R as root for 
that session.  (There may be a Debian package for rrcov for your OS and R 
version, but without further details I cannot check.)

In the current version of prada (1.12.0 for BioC-2.0 for R 2.5.0) rrcov is 
in Imports, so probably your version of BioC is not current either.

[...]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tom.olsson at dnbnor.com  Fri Jun  8 08:42:06 2007
From: tom.olsson at dnbnor.com (Tom.O)
Date: Thu, 7 Jun 2007 23:42:06 -0700 (PDT)
Subject: [R] Barplots: Editing the frequency x-axis names
Message-ID: <11021315.post@talk.nabble.com>


Hi
I have a timeSeries object (X) with monthly returns. I want to display the
returns with a barplot, which I can fix easily. But my problem is labaling
the x-axis, if I use the positions from the timeseries It gets very messy. I
have tried rotating and changing the font size but it doesn't do the trick.
I think the optimal solution for my purpose is too only display every second
or third date, pherhaps only use every 12 month. But how do I do that?

Thanks Tom
-- 
View this message in context: http://www.nabble.com/Barplots%3A-Editing-the-frequency-x-axis-names-tf3888029.html#a11021315
Sent from the R help mailing list archive at Nabble.com.


From sabya23 at gmail.com  Fri Jun  8 08:50:13 2007
From: sabya23 at gmail.com (spime)
Date: Thu, 7 Jun 2007 23:50:13 -0700 (PDT)
Subject: [R] How to partition sample space
Message-ID: <11021390.post@talk.nabble.com>


Hi R-users,

I need your help in the following problem. Suppose we have a regression
problem containing 25 predictor variables of 1000 individuals. I want to
divide the data matrix ( 1000 x 25 ) into two partitions for training (70%)
and testing(30%). For this reason, i sample 70% of data into another
training matrix and remaining 30% into testing matrix using pseudorandom
numbers (for future analysis).

I need some efficient solution so that we can generate both matrix with
minimal time. 

Thanks in advance.

Sabyasachi
-- 
View this message in context: http://www.nabble.com/How-to-partition-sample-space-tf3888059.html#a11021390
Sent from the R help mailing list archive at Nabble.com.


From gunther.hoening at ukmainz.de  Fri Jun  8 08:58:53 2007
From: gunther.hoening at ukmainz.de (=?iso-8859-1?Q?Gunther_H=F6ning?=)
Date: Fri, 8 Jun 2007 08:58:53 +0200
Subject: [R] Sorting dataframe by different columns
In-Reply-To: <000c01c7a965$d81ae220$0300a8c0@Vaio>
References: <000c01c7a965$d81ae220$0300a8c0@Vaio>
Message-ID: <000001c7a99a$79d46990$0f1e0b0a@3med.klinik.unimainz.de>

Dear list,

I have a very short question,
Suggest a dataframe of four columns.

df <- data.frame(w,x,y,z)

I want this ordered the following way:
first by :x, decreasing = FALSE
and 
secondly by: z, decreasing =TRUE

How can this be done ?

Thanks

Gunther


From sofa-surfer at web.de  Fri Jun  8 09:06:41 2007
From: sofa-surfer at web.de (Matthias Kirchner)
Date: Fri, 8 Jun 2007 00:06:41 -0700 (PDT)
Subject: [R] How to partition sample space
In-Reply-To: <11021390.post@talk.nabble.com>
References: <11021390.post@talk.nabble.com>
Message-ID: <11021527.post@talk.nabble.com>


Hi, 

you could use the sample function:

sample<-sample(1:1000)
m.training<-m[sample[1:700],]
m.test<-m[sample[701:1000],]

Matthias



spime wrote:
> 
> Hi R-users,
> 
> I need your help in the following problem. Suppose we have a regression
> problem containing 25 predictor variables of 1000 individuals. I want to
> divide the data matrix ( 1000 x 25 ) into two partitions for training
> (70%) and testing(30%). For this reason, i sample 70% of data into another
> training matrix and remaining 30% into testing matrix using pseudorandom
> numbers (for future analysis).
> 
> I need some efficient solution so that we can generate both matrix with
> minimal time. 
> 
> Thanks in advance.
> 
> Sabyasachi
> 

-- 
View this message in context: http://www.nabble.com/How-to-partition-sample-space-tf3888059.html#a11021527
Sent from the R help mailing list archive at Nabble.com.


From dimitris.rizopoulos at med.kuleuven.be  Fri Jun  8 09:21:33 2007
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Fri, 8 Jun 2007 09:21:33 +0200
Subject: [R] Sorting dataframe by different columns
References: <000c01c7a965$d81ae220$0300a8c0@Vaio>
	<000001c7a99a$79d46990$0f1e0b0a@3med.klinik.unimainz.de>
Message-ID: <007301c7a99d$a4593da0$0540210a@www.domain>

probably the function sort.data.frame() posted in R-help some time ago 
can be useful; check:

RSiteSearch("sort.data.frame")


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Gunther H?ning" <gunther.hoening at ukmainz.de>
To: <r-help at stat.math.ethz.ch>
Sent: Friday, June 08, 2007 8:58 AM
Subject: [R] Sorting dataframe by different columns


> Dear list,
>
> I have a very short question,
> Suggest a dataframe of four columns.
>
> df <- data.frame(w,x,y,z)
>
> I want this ordered the following way:
> first by :x, decreasing = FALSE
> and
> secondly by: z, decreasing =TRUE
>
> How can this be done ?
>
> Thanks
>
> Gunther
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm


From rh at family-krueger.com  Fri Jun  8 09:32:32 2007
From: rh at family-krueger.com (Knut Krueger)
Date: Fri, 08 Jun 2007 09:32:32 +0200
Subject: [R] Barplots: Editing the frequency x-axis names
In-Reply-To: <11021315.post@talk.nabble.com>
References: <11021315.post@talk.nabble.com>
Message-ID: <46690610.2090108@family-krueger.com>

Tom.O schrieb:
> Hi
> I have a timeSeries object (X) with monthly returns. I want to display the
> returns with a barplot, which I can fix easily. But my problem is labaling
> the x-axis, if I use the positions from the timeseries It gets very messy. I
> have tried rotating and changing the font size but it doesn't do the trick.
> I think the optimal solution for my purpose is too only display every second
> or third date, pherhaps only use every 12 month. But how do I do that?
>
> Thanks Tom
>   
I think you could use:

library(chron):
f.e
x <- c(dates(02/27/92),dates(02/27/95))
y <- c(10,50)
plot(x, y)

Regards Knut


From tom.olsson at dnbnor.com  Fri Jun  8 09:34:55 2007
From: tom.olsson at dnbnor.com (Tom.O)
Date: Fri, 8 Jun 2007 00:34:55 -0700 (PDT)
Subject: [R] Barplots: Editing the frequency x-axis names
In-Reply-To: <46690610.2090108@family-krueger.com>
References: <11021315.post@talk.nabble.com>
	<46690610.2090108@family-krueger.com>
Message-ID: <11021815.post@talk.nabble.com>


Hi thanks for the respone, but cant you be more specific with your example. I
cant see that this will do the trick. What Im looking for is a function that
remembers each position but only displays every n'th date.

For example

position	Returns	    Disply Date
2003-01-31		1		N
2003-02-28		2		N
2003-03-31		3		Yes
2003-04-30		4		N
2003-05-31		5		N
2003-06-30		6		Yes
2003-07-31		7		N
2003-08-31		8		N
2006-09-30		9		Yes
.... and so on until present 

Where I want to display all the returns in a barplot, but where I only want
to display every quarterly date in the plot???

Tom

Knut Krueger-5 wrote:
> 
> Tom.O schrieb:
>> Hi
>> I have a timeSeries object (X) with monthly returns. I want to display
>> the
>> returns with a barplot, which I can fix easily. But my problem is
>> labaling
>> the x-axis, if I use the positions from the timeseries It gets very
>> messy. I
>> have tried rotating and changing the font size but it doesn't do the
>> trick.
>> I think the optimal solution for my purpose is too only display every
>> second
>> or third date, pherhaps only use every 12 month. But how do I do that?
>>
>> Thanks Tom
>>   
> I think you could use:
> 
> library(chron):
> f.e
> x <- c(dates(02/27/92),dates(02/27/95))
> y <- c(10,50)
> plot(x, y)
> 
> Regards Knut
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/Barplots%3A-Editing-the-frequency-x-axis-names-tf3888029.html#a11021815
Sent from the R help mailing list archive at Nabble.com.


From knut.krueger at usa.com  Fri Jun  8 10:05:34 2007
From: knut.krueger at usa.com (Knut Krueger)
Date: Fri, 08 Jun 2007 10:05:34 +0200
Subject: [R] Barplots: Editing the frequency x-axis names -doouble post
In-Reply-To: <46690610.2090108@family-krueger.com>
References: <11021315.post@talk.nabble.com>
	<46690610.2090108@family-krueger.com>
Message-ID: <46690DCE.7060409@usa.com>

Sorry for double posting - was wrong e-mail adress , thougt this one 
will run into Spam filter


From niederlein-rstat at yahoo.de  Fri Jun  8 10:07:26 2007
From: niederlein-rstat at yahoo.de (Antje)
Date: Fri, 08 Jun 2007 08:07:26 -0000
Subject: [R] choose.dir
Message-ID: <46389FCD.4060501@yahoo.de>

Hi all,

I have written a R-script under Windows using choose.dir. Now, I have 
seen that this function is missing at MacOS. Does anybody know an 
alternative?

Antje


From rh at family-krueger.com  Fri Jun  8 10:11:04 2007
From: rh at family-krueger.com (Knut Krueger)
Date: Fri, 08 Jun 2007 10:11:04 +0200
Subject: [R] Barplots: Editing the frequency x-axis names
In-Reply-To: <11021815.post@talk.nabble.com>
References: <11021315.post@talk.nabble.com>	<46690610.2090108@family-krueger.com>
	<11021815.post@talk.nabble.com>
Message-ID: <46690F18.5020207@family-krueger.com>

Sorry I forgot the ""  around the dates
x <- c(dates("01/31/03"),dates("06/30/07"))

But I think your problem is the plot area    .
You must first define the plot area with type ="n" for no plotting, 
afterwards you could fill in the data.
I did this with times() but I am afraid the displayed dates/times will 
depend on your plot area and the settings with par()

did you read the instructions for plot and par already?

Regards Knut

have a look to ?plot and to ?par


From christophe at pallier.org  Fri Jun  8 10:27:21 2007
From: christophe at pallier.org (Christophe Pallier)
Date: Fri, 8 Jun 2007 10:27:21 +0200
Subject: [R] Tools For Preparing Data For Analysis
In-Reply-To: <874da0b40706071701m55cd42fem15f55a8fcde04f17@mail.gmail.com>
References: <874da0b40706071701m55cd42fem15f55a8fcde04f17@mail.gmail.com>
Message-ID: <dea6cb960706080127u2448b5e9v7e04b400b57fbded@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070608/4877adf8/attachment.pl 

From h.wickham at gmail.com  Fri Jun  8 10:49:41 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 8 Jun 2007 10:49:41 +0200
Subject: [R] Barplots: Editing the frequency x-axis names
In-Reply-To: <11021315.post@talk.nabble.com>
References: <11021315.post@talk.nabble.com>
Message-ID: <f8e6ff050706080149o6f1cc139p93fc2add5e301990@mail.gmail.com>

On 6/8/07, Tom.O <tom.olsson at dnbnor.com> wrote:
>
> Hi
> I have a timeSeries object (X) with monthly returns. I want to display the
> returns with a barplot, which I can fix easily. But my problem is labaling
> the x-axis, if I use the positions from the timeseries It gets very messy. I
> have tried rotating and changing the font size but it doesn't do the trick.
> I think the optimal solution for my purpose is too only display every second
> or third date, pherhaps only use every 12 month. But how do I do that?

It's quite easy to do that with ggplot2, see below, or
http://had.co.nz/ggplot2/scale_date.html for examples.

df <- data.frame(
 date = seq(Sys.Date(), len=100, by="1 day")[sample(100, 50)],
 price = runif(50)
)

qplot(date, price, data=df, geom="line")
qplot(date, price, data=df, geom="bar", stat="identity")
qplot(date, price, data=df, geom="bar", stat="identity") +
scale_x_date(major="2 months")
qplot(date, price, data=df, geom="bar", stat="identity") +
scale_x_date(major="10 day", format="%d-%m")
qplot(date, price, data=df, geom="bar", stat="identity") +
scale_x_date(major="5 day", format="%d-%m")

Hadley


From Peter.Lercher at i-med.ac.at  Fri Jun  8 11:07:00 2007
From: Peter.Lercher at i-med.ac.at (Peter Lercher)
Date: Fri, 08 Jun 2007 11:07:00 +0200
Subject: [R] overplots - fixing scientific vs normal notation in output
Message-ID: <20070608110700.g8esovsr48gkoso8@webmail.i-med.ac.at>

Moving from S-plus to R I encountered many great features and a much
more stable system.
Currently, I am left with 2 problems that are handled differently:

1) I did lots of "overplots" in S-Plus using
par(new=T,xaxs='d',yaxs='d') to fix the axes
->What is the workaround in R ?

2) In S-Plus I could fix "scientific notation" or "normal notation" in output
->How can I handle this in R ?
I found no fix in the documentation

I am using R version 2.4.1 (2006-12-18) on Windows XP SR2


Peter Lercher, M.D., M.P.H., Assoc Prof


From singularitaet at gmx.net  Fri Jun  8 11:07:27 2007
From: singularitaet at gmx.net (Stefan Grosse)
Date: Fri, 08 Jun 2007 11:07:27 +0200
Subject: [R] update packages with R on Vista: error
In-Reply-To: <29cf68350706071413x6a33af82l49f2ff551b74d1e1@mail.gmail.com>
References: <4667D730.9090403@gmx.net>
	<Pine.LNX.4.64.0706071159250.19222@gannet.stats.ox.ac.uk>
	<466809D8.1020603@gmx.net>
	<29cf68350706071413x6a33af82l49f2ff551b74d1e1@mail.gmail.com>
Message-ID: <46691C4F.3000203@gmx.net>

Thanks for pointing at this. But you know, the user is writable. R is
installing Packages in /Documents/R/win-library which works fine so I
find it absolutely naturally that update should work as well. Especially
since when I install the packages it gets the latest version, library
loads this latest version but update still does want to update this
latest package with the package I already installed and fails ...

In my opinion the update on windows is simply buggy.

I think one should definitely not turn UAC off. ( its a good security
feature). Btw. MikTeX 2.6 is able to deal with UAC - I can update my
latex packages without any problems even though they are in the Program
File directory (and also on-the-fly installation does work) ...

Stefan

-------- Original Message  --------
Subject: Re:[R] update packages with R on Vista: error
From: R. Villegas <villegas.ro at gmail.com>
To: Stefan Grosse <singularitaet at gmx.net>
Date: 07.06.2007 23:13
> If R is installed within "Program Files", one of Vista's security
> settings may interfere with the -update- process.
>
> The setting may be disabled globally by choosing:
> Windows (Start) menu, Control Panels, User Accounts and Family
> Safety (green title), User Accounts (green title), and
> Turn User Account Control on or off (very bottom).  You will be
> prompted for permission to continue; click continue.  On the
> screen you will see a checkbox titled "Use User Account Control
> (UAC) to help protect your computer".  Uncheck this and click
> the OK button to save the changes.  Windows Vista will now allow
> programs, including R, to update files in "Program Files".
>
> Rod.


From Thierry.ONKELINX at inbo.be  Fri Jun  8 11:22:22 2007
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 8 Jun 2007 11:22:22 +0200
Subject: [R] Conditional Sequential Gaussian Simulation
In-Reply-To: <14A2A120D369B6469BB154B2D2DC34D20803CB03@EXCHVS01.ad.sfwmd.gov>
Message-ID: <2E9C414912813E4EB981326983E0A104030D1EFC@inboexch.inbo.be>

Steve,

You can do this with the package gstat. Look for ?krige of
?predict.gstat

Post further question on this topic on the R-sig-geo list. You'll get
more response.

Cheers,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium
tel. + 32 54/436 185
Thierry.Onkelinx op inbo.be
www.inbo.be 

Do not put your faith in what statistics say until you have carefully
considered what they do not say.  ~William W. Watt
A statistical analysis, properly conducted, is a delicate dissection of
uncertainties, a surgery of suppositions. ~M.J.Moroney

 

> -----Oorspronkelijk bericht-----
> Van: r-help-bounces op stat.math.ethz.ch 
> [mailto:r-help-bounces op stat.math.ethz.ch] Namens Friedman, Steven
> Verzonden: donderdag 7 juni 2007 14:46
> Aan: r-help op stat.math.ethz.ch
> Onderwerp: [R] Conditional Sequential Gaussian Simulation
> 
> Hello, 
> 
>  
> 
> I'm wondering if there are any packages/functions that can 
> perform conditional sequential gaussian simulation.  
> 
>  
> 
> I'm following an article written by Grunwald, Reddy, Prenger 
> and Fisher 2007. Modeling of the spatial variability of 
> biogeochemical soil properties in a freshwater ecosystem. 
> Ecological Modelling 201: 521 - 535, and would like to 
> explore this methodology.
> 
>  
> 
> Thanks
> 
> Steve
> 
>  
> 
>  
> 
> Steve Friedman, PhD
> 
> Everglades Division
> 
> Senior Environmental Scientist, Landscape Ecology
> 
> South Florida Water Management District
> 
> 3301 Gun Club Road
> 
> West Palm Beach, Florida 33406
> 
> email:  sfriedma op sfwmd.gov
> 
> Office:  561 - 682 - 6312
> 
> Fax:      561 - 682 - 5980
> 
>  
> 
> If you are not doing what you truly enjoy its your obligation 
> to yourself to change.
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help op stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From S.Nakagawa at sheffield.ac.uk  Fri Jun  8 11:38:38 2007
From: S.Nakagawa at sheffield.ac.uk (Shinichi Nakagawa)
Date: Fri,  8 Jun 2007 10:38:38 +0100
Subject: [R] icc from GLMM?
Message-ID: <1181295518.4669239ed658f@webmail.shef.ac.uk>

Dear R users

I would like to ask a question regarding to icc (intraclass correlation) or many
biologists refer it to as repeatability. It is very useful to get icc for many
reasons and it is easy to do so from linear mixed-effects models and many
packages like psy, psychometric, aod and irr have functions to calculate icc. 

icc = between-group variance/(between-group variance + residual variance) 

*residual variance = within-group variance 

However, I have yet to find a convincing reference or some sort on how to
calculate icc from GLMM. I have found below:

icc = between-group variance/(between-group variance + 1)
*between-group variance = scaled between-group variance????
Or variance obtained from random intercept of GLMM
icc = between-group variance/(between-group variance + pi^2/3)
icc = between-group variance/(between-group variance + pi^2/3*(dispersion
parameter))
for binomial GLMM
icc = between-group variance/(between-group variance + 1/(p(1-p))


I am a little confused which one to trust and use. Or there are no easy formulas
to do this? I am guessing formula would change depending on what distribution
you use and what link function as well? I want to calculate icc from GLMM with
Poisson with log link function and also binomial with logit function. Could
anybody help me please?

Many thanks for your help

Shinichi

-- 
Shinichi Nakagawa
Dept of Animal & Plant Sciences
University of Sheffield
Tel: 0114-222-0113
Fax: 0114-222-0002


From justin_bem at yahoo.fr  Fri Jun  8 11:28:25 2007
From: justin_bem at yahoo.fr (justin bem)
Date: Fri, 8 Jun 2007 09:28:25 +0000 (GMT)
Subject: [R] Re :  Sorting dataframe by different columns
Message-ID: <678208.73330.qm@web23015.mail.ird.yahoo.com>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20070608/3d0aaf04/attachment.pl 

From ted.harding at nessie.mcc.ac.uk  Fri Jun  8 11:43:14 2007
From: ted.harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 08 Jun 2007 10:43:14 +0100 (BST)
Subject: [R] Tools For Preparing Data For Analysis
In-Reply-To: <dea6cb960706080127u2448b5e9v7e04b400b57fbded@mail.gmail.com>
Message-ID: <XFMail.070608104314.ted.harding@nessie.mcc.ac.uk>

On 08-Jun-07 08:27:21, Christophe Pallier wrote:
> Hi,
> 
> Can you provide examples of data formats that are problematic
> to read and clean with R ?
> 
> The only problematic cases I have encountered were cases with
> multiline and/or  varying length records (optional information).
> Then, it is sometimes a good idea to preprocess the data to
> present in a tabular format (one record per line).
> 
> For this purpose, I use awk (e.g.
> http://www.vectorsite.net/tsawk.html),
> which is very adept at processing ascii data files  (awk is
> much simpler to learn than perl, spss, sas, ...).

I want to join in with an enthusiastic "Me too!!". For anything
which has to do with basic checking for the kind of messes that
people can get data into when they "put it on the computer",
I think awk is ideal. It is very flexible (far more so than
many, even long-time, awk users suspect), very transparent
in its programming language (as opposed to say perl), fast,
and with light impact on system resources (rare delight in
these days, when upgrading your software may require upgrading
your hardware).

Although it may seem on the surface that awk is "two-dimensional"
in its view of data (line by line, and per field in a line),
it has some flexible internal data structures and recursive
function capability, which allows a lot more to be done with
the data that have been read in.

For example, I've used awk to trace ancestry through a genealogy,
given a data file where each line includes the identifier of an
individual and the identifiers of its male and female parents
(where known). And that was for pedigree dogs, where what happens
in real life makes Oedipus look trivial.

> I have never encountered a data file in ascii format that I
> could not reformat with Awk.  With binary formats, it is
> another story...

But then it is a good idea to process the binary file using an
instance of the creating software, to produce a ASCII file (say
in CSV format).

> But, again, this is my limited experience; I would like to
> know if there are situations where using SAS/SPSS is really
> a better approach.

The main thing often useful for data cleaning that awk does
not have is any associated graphics. It is -- by design -- a
line-by-line text-file processor. While, for instance, you
could use awk to accumulate numerical histogram counts, you
would have to use something else to display the histogram.
And for scatter-plots there's probably not much point in
bringing awk into the picture at all (unless a preliminary
filtration of mess is needed anyway).

That being said, though, there can still be a use to extract
data fields from a file for submission to other software.

Another kind of area where awk would not have much to offer
is where, as a part of your preliminary data inspection,
you want to inspect the results of some standard statistical
analyses.

As a final comment, utilities like awk can be used far more
fruitfully on operating systems (the unixoid family) which
incorporate at ground level the infrastructure for "plumbing"
together streams of data output from different programs.

Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 08-Jun-07                                       Time: 10:43:05
------------------------------ XFMail ------------------------------


From justin_bem at yahoo.fr  Fri Jun  8 11:44:48 2007
From: justin_bem at yahoo.fr (justin bem)
Date: Fri, 8 Jun 2007 09:44:48 +0000 (GMT)
Subject: [R] Re :  How to partition sample space
Message-ID: <330030.8898.qm@web23002.mail.ird.yahoo.com>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20070608/5cd5993e/attachment.pl 

From chrish at stats.ucl.ac.uk  Fri Jun  8 12:15:40 2007
From: chrish at stats.ucl.ac.uk (Christian Hennig)
Date: Fri, 8 Jun 2007 11:15:40 +0100 (BST)
Subject: [R] help.search and Baysian regression
Message-ID: <Pine.LNX.4.64.0706081108580.26275@egon.stats.ucl.ac.uk>

Hi there,

two questions.
1) Is there any possibility to look up the help pages within R for more 
complex combinations of character strings, for example "Bayesian" AND 
"regression" but not necessarily "Bayesian regression"?

2) Is there a package/command that does fully Bayesian linear regression
(if possible with variable selection)?

Thanks,
Christian

*** --- ***
Christian Hennig
University College London, Department of Statistical Science
Gower St., London WC1E 6BT, phone +44 207 679 1698
chrish at stats.ucl.ac.uk, www.homepages.ucl.ac.uk/~ucakche


From rh at family-krueger.com  Fri Jun  8 12:31:33 2007
From: rh at family-krueger.com (Knut Krueger)
Date: Fri, 08 Jun 2007 12:31:33 +0200
Subject: [R] Sorting dataframe by different columns
In-Reply-To: <678208.73330.qm@web23015.mail.ird.yahoo.com>
References: <678208.73330.qm@web23015.mail.ird.yahoo.com>
Message-ID: <46693005.9060101@family-krueger.com>

maybe this page could give you some hints:
http://www.ats.ucla.edu/STAT/r/faq/sort.htm
Regards Knut


From rxzhu at scbit.org  Fri Jun  8 12:38:04 2007
From: rxzhu at scbit.org (Ruixin ZHU)
Date: Fri, 8 Jun 2007 18:38:04 +0800
Subject: [R] Dependency 'Design' is not available
Message-ID: <000601c7a9b9$18361570$7000a8c0@scbit94ec75129>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070608/8b2a3d22/attachment.pl 

From singularitaet at gmx.net  Fri Jun  8 12:40:16 2007
From: singularitaet at gmx.net (Stefan Grosse)
Date: Fri, 08 Jun 2007 12:40:16 +0200
Subject: [R] update packages with R on Vista: error
In-Reply-To: <46691C4F.3000203@gmx.net>
References: <4667D730.9090403@gmx.net>
	<Pine.LNX.4.64.0706071159250.19222@gannet.stats.ox.ac.uk>
	<466809D8.1020603@gmx.net>
	<29cf68350706071413x6a33af82l49f2ff551b74d1e1@mail.gmail.com>
	<46691C4F.3000203@gmx.net>
Message-ID: <46693210.7060301@gmx.net>

I was pointed at that my message might be considered as impolite. It was
not intended so. I was just trying to formulate that there should be
some improvement since the solutions offered were either not optimal for
me (disabling security features) or where not working (FAQ).

I apologize for any possible inconvenience caused by my frustration
spiced up possibly with my inabilities.

Stefan

-------- Original Message  --------
Subject: Re:[R] update packages with R on Vista: error
From: Stefan Grosse <singularitaet at gmx.net>
To: R. Villegas <villegas.ro at gmail.com>
Date: 08.06.2007 11:07
> Thanks for pointing at this. But you know, the user is writable. R is
> installing Packages in /Documents/R/win-library which works fine so I
> find it absolutely naturally that update should work as well. Especially
> since when I install the packages it gets the latest version, library
> loads this latest version but update still does want to update this
> latest package with the package I already installed and fails ...
>
> In my opinion the update on windows is simply buggy.
>
> I think one should definitely not turn UAC off. ( its a good security
> feature). Btw. MikTeX 2.6 is able to deal with UAC - I can update my
> latex packages without any problems even though they are in the Program
> File directory (and also on-the-fly installation does work) ...
>
> Stefan
>


From antonio.raju at gmail.com  Fri Jun  8 12:52:26 2007
From: antonio.raju at gmail.com (=?ISO-8859-1?Q?Antonio_Rodr=EDguez?=)
Date: Fri, 8 Jun 2007 12:52:26 +0200
Subject: [R] world map matrix
Message-ID: <ee5655ad0706080352q3f223286yc0ce1d059eb9b4e9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070608/79370ec3/attachment.pl 

From ligges at statistik.uni-dortmund.de  Fri Jun  8 12:51:19 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 08 Jun 2007 12:51:19 +0200
Subject: [R] Dependency 'Design' is not available
In-Reply-To: <000601c7a9b9$18361570$7000a8c0@scbit94ec75129>
References: <000601c7a9b9$18361570$7000a8c0@scbit94ec75129>
Message-ID: <466934A7.4060205@statistik.uni-dortmund.de>



Ruixin ZHU wrote:
> Dear R-users,
>  
> When I installed "rattle" package with the command:
> install.packages("rattle", dependencies=TRUE), I got 
> Warning message:
> Dependency 'Design' is not available

Version of R? OS? Please do read the posting guide!

If R-2.5.0 under Windows: Design did not pass the checks under Windows 
and is not available for download. In this case please contact the 
package maintainer and convince him to fix the package.

Uwe Ligges


>  
> Is this warning serious? How to avoid this warning?
>  
> Thanks
> _____________________________________________
> Dr.Ruixin ZHU
> Shanghai Center for Bioinformation Technology
> rxzhu at scbit.org
> zhurx at mail.sioc.ac.cn
> 86-21-13040647832
>  
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Fri Jun  8 14:16:46 2007
From: jholtman at gmail.com (jim holtman)
Date: Fri, 8 Jun 2007 08:16:46 -0400
Subject: [R] match rows of data frame
In-Reply-To: <000c01c7a965$d81ae220$0300a8c0@Vaio>
References: <000c01c7a965$d81ae220$0300a8c0@Vaio>
Message-ID: <644e1f320706080516o4e3c19ffuc7856b2395843d06@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070608/aedabf74/attachment.pl 

From rxzhu at scbit.org  Fri Jun  8 08:35:57 2007
From: rxzhu at scbit.org (Ruixin ZHU)
Date: Fri, 8 Jun 2007 14:35:57 +0800
Subject: [R] data mining/text mining?
Message-ID: <000001c7a997$45df81e0$7000a8c0@scbit94ec75129>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070608/d7f3b692/attachment.pl 

From murdoch at stats.uwo.ca  Fri Jun  8 14:39:42 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 08 Jun 2007 08:39:42 -0400
Subject: [R] world map matrix
In-Reply-To: <ee5655ad0706080352q3f223286yc0ce1d059eb9b4e9@mail.gmail.com>
References: <ee5655ad0706080352q3f223286yc0ce1d059eb9b4e9@mail.gmail.com>
Message-ID: <46694E0E.6040508@stats.uwo.ca>

On 6/8/2007 6:52 AM, Antonio Rodr?guez wrote:
> Hi,
> 
> Is it possible to make a world map matrix where land values are set to 0 and
> sea values to 1?

It's not hard to produce a bitmap of a world map with the maps package, 
and then some image manipulation functions could convert it to 0's and 
1's.  I don't know if there's a more direct way.

One minor problem you may encounter is that the default world map 
display isn't really rectangular:  e.g. bits of Siberia that cross 180 
degrees east are still displayed attached to Siberia rather than 
wrapping around and being displayed on the other side of the map.  The 
display also doesn't go all the way to the south pole.  I produced a 
couple of rectangular bitmaps covering 90 south to 90 north and 180 west 
to 180 east; they're included in the rgl package (and used to display 
globes in the persp3d example).

Duncan Murdoch


From bates at stat.wisc.edu  Fri Jun  8 14:47:00 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 8 Jun 2007 07:47:00 -0500
Subject: [R] Tools For Preparing Data For Analysis
In-Reply-To: <874da0b40706071701m55cd42fem15f55a8fcde04f17@mail.gmail.com>
References: <874da0b40706071701m55cd42fem15f55a8fcde04f17@mail.gmail.com>
Message-ID: <40e66e0b0706080547o5c630ac3ne5feadc4247e289a@mail.gmail.com>

On 6/7/07, Robert Wilkins <irishhacker at gmail.com> wrote:
> As noted on the R-project web site itself ( www.r-project.org ->
> Manuals -> R Data Import/Export ), it can be cumbersome to prepare
> messy and dirty data for analysis with the R tool itself. I've also
> seen at least one S programming book (one of the yellow Springer ones)
> that says, more briefly, the same thing.
> The R Data Import/Export page recommends examples using SAS, Perl,
> Python, and Java. It takes a bit of courage to say that ( when you go
> to a corporate software web site, you'll never see a page saying "This
> is the type of problem that our product is not the best at, here's
> what we suggest instead" ). I'd like to provide a few more
> suggestions, especially for volunteers who are willing to evaluate new
> candidates.
>
> SAS is fine if you're not paying for the license out of your own
> pocket. But maybe one reason you're using R is you don't have
> thousands of spare dollars.
> Using Java for data cleaning is an exercise in sado-masochism, Java
> has a learning curve (almost) as difficult as C++.
>
> There are different types of data transformation, and for some data
> preparation problems an all-purpose programming language is a good
> choice ( i.e. Perl , or maybe Python/Ruby ). Perl, for example, has
> excellent regular expression facilities.
>
> However, for some types of complex demanding data preparation
> problems, an all-purpose programming language is a poor choice. For
> example: cleaning up and preparing clinical lab data and adverse event
> data - you could do it in Perl, but it would take way, way too much
> time. A specialized programming language is needed. And since data
> transformation is quite different from data query, SQL is not the
> ideal solution either.
>
> There are only three statistical programming languages that are
> well-known, all dating from the 1970s: SPSS, SAS, and S. SAS is more
> popular than S for data cleaning.
>
> If you're an R user with difficult data preparation problems, frankly
> you are out of luck, because the products I'm about to mention are
> new, unknown, and therefore regarded as immature. And while the
> founders of these products would be very happy if you kicked the
> tires, most people don't like to look at brand new products. Most
> innovators and inventers don't realize this, I've learned it the hard
> way.
>
> But if you are a volunteer who likes to help out by evaluating,
> comparing, and reporting upon new candidates, well you could certainly
> help out R users and the developers of the products by kicking the
> tires of these products. And there is a huge need for such volunteers.
>
> 1. DAP
> This is an open source implementation of SAS.
> The founder: Susan Bassein
> Find it at: directory.fsf.org/math/stats (GNU GPL)
>
> 2. PSPP
> This is an open source implementation of SPSS.
> The relatively early version number might not give a good idea of how
> mature the
> data transformation features are, it reflects the fact that he has
> only started doing the statistical tests.
> The founder: Ben Pfaff, either a grad student or professor at Stanford CS dept.
> Also at : directory.fsf.org/math/stats (GNU GPL)
>
> 3. Vilno
> This uses a programming language similar to SPSS and SAS, but quite unlike S.
> Essentially, it's a substitute for the SAS datastep, and also
> transposes data and calculates averages and such. (No t-tests or
> regressions in this version). I created this, during the years
> 2001-2006 mainly. It's version 0.85, and has a fairly low bug rate, in
> my opinion. The tarball includes about 100 or so test cases used for
> debugging - for logical calculation errors, but not for extremely high
> volumes of data.
> The maintenance of Vilno has slowed down, because I am currently
> (desparately) looking for employment. But once I've found new
> employment and living quarters and settled in, I will continue to
> enhance Vilno in my spare time.
> The founder: that would be me, Robert Wilkins
> Find it at: code.google.com/p/vilno ( GNU GPL )
> ( In particular, the tarball at code.google.com/p/vilno/downloads/list
> , since I have yet to figure out how to use Subversion ).
>
> 4. Who knows?
> It was not easy to find out about the existence of DAP and PSPP. So
> who knows what else is out there. However, I think you'll find a lot
> more statistics software ( regression , etc ) out there, and not so
> much data transformation software. Not many people work on data
> preparation software. In fact, the category is so obscure that there
> isn't one agreed term: data cleaning , data munging , data crunching ,
> or just getting the data ready for analysis.

Thanks for bringing up this topic.  I think there is definitely a
place for such languages, which I would regard as data-filtering
languages, but I also think that trying to reproduce the facilities in
SAS or SPSS for data analysis is redundant.

Other responses in this thread have mentioned 'little language'
filters like awk, which is fine for those who were raised in the Bell
Labs tradition of programming ("why type three characters when two
character names should suffice for anything one wants to do on a
PDP-11") but the typical field scientist finds this a bit too terse to
understand and would rather write a filter as a paragraph of code that
they have a change of reading and understanding a week later.

Frank Harrell indicated that it is possible to do a lot of difficult
data transformation within R itself if you try hard enough but that
sometimes means working against the S language and its "whole object"
view to accomplish what you want and it can require knowledge of
subtle aspects of the S language.

General scripting languages like Perl, Python and Ruby can certainly
be used for data filtering but that means learning the language and
its idiosyncrasies, and those idiosyncrasies are often exactly the
aspects that would be used to write a filter tersely.  Readability
suffers.  ("Hell is reading someone else's Perl code - purgatory is
reading your own Perl code.")  The very generality of the languages
means there is a lot to learn and understand before you can write
something like a simple filter.

So I do agree that it would be useful to have a language like the SAS
data step (but Open Source, of course) in which to write a data
filter.  I have one suggestion to make - use the R data frame
structure in the form of a .rda file as the binary output format for a
data table.  That way the user can get the best of both worlds by
using a language like Viino to manipulate and rearrange huge data
files then switching to R for the graphics and data analysis.  As a
further enhancement one might provide the ability to take a .rda file
that contains a single data frame and select columns or rows,
including a random sample of the rows, as a filter.

Producing an R data frame may involve passing over the data twice,
once to determine the size of the resulting structure and the second
time to evaluate the data itself.  This would have been a horrific
penalty in the days that SAS and SPSS were developed but not now.


From timb at metrumrg.com  Fri Jun  8 14:57:05 2007
From: timb at metrumrg.com (Tim Bergsma)
Date: Fri, 08 Jun 2007 08:57:05 -0400
Subject: [R] logical 'or' on list of vectors
Message-ID: <46695221.8080807@metrumrg.com>

Suppose I have a list of logicals, such as returned by lapply:

Theoph$Dose[1] <- NA
Theoph$Time[2] <- NA
Theoph$conc[3] <- NA
lapply(Theoph,is.na)

Is there a direct way to execute logical "or" across all vectors?  The 
following gives the desired result, but seems unnecessarily complex.

as.logical(apply(do.call("rbind",lapply(Theoph,is.na)),2,"sum"))

Regards,

Tim


From asb at mail.nih.gov  Thu Jun  7 16:47:10 2007
From: asb at mail.nih.gov (Alan S Barnett)
Date: Thu, 07 Jun 2007 10:47:10 -0400
Subject: [R] rlm results on trellis plot
Message-ID: <1181227630.6917.12.camel@gestalt.nimh.nih.gov>

How do I add to a trellis plot the best fit line from a robust fit? I
can use panel.lm to add a least squares fit, but there is no panel.rlm
function.
-- 
Alan S Barnett <asb at mail.nih.gov>
NIMH/CBDB


From ezhil02 at yahoo.com  Fri Jun  8 15:13:01 2007
From: ezhil02 at yahoo.com (A Ezhil)
Date: Fri, 8 Jun 2007 06:13:01 -0700 (PDT)
Subject: [R] Formating the data
Message-ID: <142298.20316.qm@web32413.mail.mud.yahoo.com>

Hi All,

I have a vector of length 48, something like:
0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1

I would like to print (reformat) this vector as:
001100000000001111111111111111111111111111111111

by simply removing the spaces between them. I have
been trying with many option but not able to do this
task.
I would greatly appreciate your suggestion on fixing
this simple task.

Thanks in advance.

Kind regards,
Ezhil
 


 
____________________________________________________________________________________
Bored stiff? Loosen up...


From ccleland at optonline.net  Fri Jun  8 15:23:03 2007
From: ccleland at optonline.net (Chuck Cleland)
Date: Fri, 08 Jun 2007 09:23:03 -0400
Subject: [R] rlm results on trellis plot
In-Reply-To: <1181227630.6917.12.camel@gestalt.nimh.nih.gov>
References: <1181227630.6917.12.camel@gestalt.nimh.nih.gov>
Message-ID: <46695837.5030902@optonline.net>

Alan S Barnett wrote:
> How do I add to a trellis plot the best fit line from a robust fit? I
> can use panel.lm to add a least squares fit, but there is no panel.rlm
> function.

  How about using panel.abline() instead of panel.lmline()?

fit1 <- coef(lm(stack.loss ~ Air.Flow, data = stackloss))
fit2 <- coef(rlm(stack.loss ~ Air.Flow, data = stackloss))

xyplot(stack.loss ~ Air.Flow, data=stackloss,
       panel = function(x, y, ...){
         panel.xyplot(x, y, ...)
         panel.abline(fit1, type="l", col="blue")
         panel.abline(fit2, type="l", col="red")
       }, aspect=1)

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From ccleland at optonline.net  Fri Jun  8 15:28:36 2007
From: ccleland at optonline.net (Chuck Cleland)
Date: Fri, 08 Jun 2007 09:28:36 -0400
Subject: [R] logical 'or' on list of vectors
In-Reply-To: <46695221.8080807@metrumrg.com>
References: <46695221.8080807@metrumrg.com>
Message-ID: <46695984.60002@optonline.net>

Tim Bergsma wrote:
> Suppose I have a list of logicals, such as returned by lapply:
> 
> Theoph$Dose[1] <- NA
> Theoph$Time[2] <- NA
> Theoph$conc[3] <- NA
> lapply(Theoph,is.na)
> 
> Is there a direct way to execute logical "or" across all vectors?  The 
> following gives the desired result, but seems unnecessarily complex.
> 
> as.logical(apply(do.call("rbind",lapply(Theoph,is.na)),2,"sum"))

  Is this what you want?

apply(is.na(Theoph), 1, any)

> Regards,
> 
> Tim
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From jholtman at gmail.com  Fri Jun  8 15:31:56 2007
From: jholtman at gmail.com (jim holtman)
Date: Fri, 8 Jun 2007 09:31:56 -0400
Subject: [R] logical 'or' on list of vectors
In-Reply-To: <46695221.8080807@metrumrg.com>
References: <46695221.8080807@metrumrg.com>
Message-ID: <644e1f320706080631u477e0ee0ue9523151bff79f0f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070608/dcc0d77c/attachment.pl 

From sundar.dorai-raj at pdf.com  Fri Jun  8 15:33:29 2007
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Fri, 08 Jun 2007 06:33:29 -0700
Subject: [R] logical 'or' on list of vectors
In-Reply-To: <46695221.8080807@metrumrg.com>
References: <46695221.8080807@metrumrg.com>
Message-ID: <46695AA9.6050303@pdf.com>



Tim Bergsma said the following on 6/8/2007 5:57 AM:
> Suppose I have a list of logicals, such as returned by lapply:
> 
> Theoph$Dose[1] <- NA
> Theoph$Time[2] <- NA
> Theoph$conc[3] <- NA
> lapply(Theoph,is.na)
> 
> Is there a direct way to execute logical "or" across all vectors?  The 
> following gives the desired result, but seems unnecessarily complex.
> 
> as.logical(apply(do.call("rbind",lapply(Theoph,is.na)),2,"sum"))
> 
> Regards,
> 
> Tim
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

How about:

apply(sapply(Theoph, is.na), 1, any)

HTH,

--sundar


From dimitris.rizopoulos at med.kuleuven.be  Fri Jun  8 15:35:46 2007
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Fri, 8 Jun 2007 15:35:46 +0200
Subject: [R] logical 'or' on list of vectors
References: <46695221.8080807@metrumrg.com>
Message-ID: <00b101c7a9d1$eb46e760$0540210a@www.domain>

try the following:

as.logical(rowSums(is.na(Theoph)))
## or
!complete.cases(Theoph)


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Tim Bergsma" <timb at metrumrg.com>
To: <r-help at stat.math.ethz.ch>
Sent: Friday, June 08, 2007 2:57 PM
Subject: [R] logical 'or' on list of vectors


> Suppose I have a list of logicals, such as returned by lapply:
>
> Theoph$Dose[1] <- NA
> Theoph$Time[2] <- NA
> Theoph$conc[3] <- NA
> lapply(Theoph,is.na)
>
> Is there a direct way to execute logical "or" across all vectors? 
> The
> following gives the desired result, but seems unnecessarily complex.
>
> as.logical(apply(do.call("rbind",lapply(Theoph,is.na)),2,"sum"))
>
> Regards,
>
> Tim
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm


From ccleland at optonline.net  Fri Jun  8 15:43:19 2007
From: ccleland at optonline.net (Chuck Cleland)
Date: Fri, 08 Jun 2007 09:43:19 -0400
Subject: [R] Formating the data
In-Reply-To: <142298.20316.qm@web32413.mail.mud.yahoo.com>
References: <142298.20316.qm@web32413.mail.mud.yahoo.com>
Message-ID: <46695CF7.7010902@optonline.net>

A Ezhil wrote:
> Hi All,
> 
> I have a vector of length 48, something like:
> 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
> 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
> 
> I would like to print (reformat) this vector as:
> 001100000000001111111111111111111111111111111111
> 
> by simply removing the spaces between them. I have
> been trying with many option but not able to do this
> task.
> I would greatly appreciate your suggestion on fixing
> this simple task.

X <- rbinom(n=48, size=1, prob=.3)

paste(X, collapse="")
[1] "101111000001001000000010000000110100100101000011"

print(paste(X, collapse=""), quote=FALSE)
[1] 101111000001001000000010000000110100100101000011

> Thanks in advance.
> 
> Kind regards,
> Ezhil
>  
> 
> 
>  
> ____________________________________________________________________________________
> Bored stiff? Loosen up...
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From gavin.simpson at ucl.ac.uk  Fri Jun  8 15:49:01 2007
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Fri, 08 Jun 2007 14:49:01 +0100
Subject: [R] Formating the data
In-Reply-To: <142298.20316.qm@web32413.mail.mud.yahoo.com>
References: <142298.20316.qm@web32413.mail.mud.yahoo.com>
Message-ID: <1181310541.8971.37.camel@gsimpson.geog.ucl.ac.uk>

On Fri, 2007-06-08 at 06:13 -0700, A Ezhil wrote:
> Hi All,
> 
> I have a vector of length 48, something like:
> 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
> 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
> 
> I would like to print (reformat) this vector as:
> 001100000000001111111111111111111111111111111111
> 
> by simply removing the spaces between them. I have
> been trying with many option but not able to do this
> task.
> I would greatly appreciate your suggestion on fixing
> this simple task.
> 
> Thanks in advance.

> dat <- scan()
1: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
28: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
49:
Read 48 items
> dat
 [1] 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1[39] 1 1 1 1 1 1 1 1 1 1
> print(dat, print.gap = 0)
 [1]001100000000001111111111111111111111111111111111

Is that what you want? It is just altering how the data are printed. You
still get the [1] at the start though.

G
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Gavin Simpson                 [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From liuwensui at gmail.com  Fri Jun  8 15:50:47 2007
From: liuwensui at gmail.com (Wensui Liu)
Date: Fri, 8 Jun 2007 09:50:47 -0400
Subject: [R] Tools For Preparing Data For Analysis
In-Reply-To: <4668BE2B.7040109@vanderbilt.edu>
References: <874da0b40706071701m55cd42fem15f55a8fcde04f17@mail.gmail.com>
	<4668BE2B.7040109@vanderbilt.edu>
Message-ID: <1115a2b00706080650j4f468766mac37d1e1b14110ed@mail.gmail.com>

I had mentioned exactly the same thing to others and the feedback I got is -
'when you have a hammer, everything will look like a nail'
^_^.

On 6/7/07, Frank E Harrell Jr <f.harrell at vanderbilt.edu> wrote:
> Robert Wilkins wrote:
> > As noted on the R-project web site itself ( www.r-project.org ->
> > Manuals -> R Data Import/Export ), it can be cumbersome to prepare
> > messy and dirty data for analysis with the R tool itself. I've also
> > seen at least one S programming book (one of the yellow Springer ones)
> > that says, more briefly, the same thing.
> > The R Data Import/Export page recommends examples using SAS, Perl,
> > Python, and Java. It takes a bit of courage to say that ( when you go
> > to a corporate software web site, you'll never see a page saying "This
> > is the type of problem that our product is not the best at, here's
> > what we suggest instead" ). I'd like to provide a few more
> > suggestions, especially for volunteers who are willing to evaluate new
> > candidates.
> >
> > SAS is fine if you're not paying for the license out of your own
> > pocket. But maybe one reason you're using R is you don't have
> > thousands of spare dollars.
> > Using Java for data cleaning is an exercise in sado-masochism, Java
> > has a learning curve (almost) as difficult as C++.
> >
> > There are different types of data transformation, and for some data
> > preparation problems an all-purpose programming language is a good
> > choice ( i.e. Perl , or maybe Python/Ruby ). Perl, for example, has
> > excellent regular expression facilities.
> >
> > However, for some types of complex demanding data preparation
> > problems, an all-purpose programming language is a poor choice. For
> > example: cleaning up and preparing clinical lab data and adverse event
> > data - you could do it in Perl, but it would take way, way too much
> > time. A specialized programming language is needed. And since data
> > transformation is quite different from data query, SQL is not the
> > ideal solution either.
>
> We deal with exactly those kinds of data solely using R.  R is
> exceptionally powerful for data manipulation, just a bit hard to learn.
>   Many examples are at
> http://biostat.mc.vanderbilt.edu/twiki/pub/Main/RS/sintro.pdf
>
> Frank
>
> >
> > There are only three statistical programming languages that are
> > well-known, all dating from the 1970s: SPSS, SAS, and S. SAS is more
> > popular than S for data cleaning.
> >
> > If you're an R user with difficult data preparation problems, frankly
> > you are out of luck, because the products I'm about to mention are
> > new, unknown, and therefore regarded as immature. And while the
> > founders of these products would be very happy if you kicked the
> > tires, most people don't like to look at brand new products. Most
> > innovators and inventers don't realize this, I've learned it the hard
> > way.
> >
> > But if you are a volunteer who likes to help out by evaluating,
> > comparing, and reporting upon new candidates, well you could certainly
> > help out R users and the developers of the products by kicking the
> > tires of these products. And there is a huge need for such volunteers.
> >
> > 1. DAP
> > This is an open source implementation of SAS.
> > The founder: Susan Bassein
> > Find it at: directory.fsf.org/math/stats (GNU GPL)
> >
> > 2. PSPP
> > This is an open source implementation of SPSS.
> > The relatively early version number might not give a good idea of how
> > mature the
> > data transformation features are, it reflects the fact that he has
> > only started doing the statistical tests.
> > The founder: Ben Pfaff, either a grad student or professor at Stanford CS dept.
> > Also at : directory.fsf.org/math/stats (GNU GPL)
> >
> > 3. Vilno
> > This uses a programming language similar to SPSS and SAS, but quite unlike S.
> > Essentially, it's a substitute for the SAS datastep, and also
> > transposes data and calculates averages and such. (No t-tests or
> > regressions in this version). I created this, during the years
> > 2001-2006 mainly. It's version 0.85, and has a fairly low bug rate, in
> > my opinion. The tarball includes about 100 or so test cases used for
> > debugging - for logical calculation errors, but not for extremely high
> > volumes of data.
> > The maintenance of Vilno has slowed down, because I am currently
> > (desparately) looking for employment. But once I've found new
> > employment and living quarters and settled in, I will continue to
> > enhance Vilno in my spare time.
> > The founder: that would be me, Robert Wilkins
> > Find it at: code.google.com/p/vilno ( GNU GPL )
> > ( In particular, the tarball at code.google.com/p/vilno/downloads/list
> > , since I have yet to figure out how to use Subversion ).
> >
> >
> > 4. Who knows?
> > It was not easy to find out about the existence of DAP and PSPP. So
> > who knows what else is out there. However, I think you'll find a lot
> > more statistics software ( regression , etc ) out there, and not so
> > much data transformation software. Not many people work on data
> > preparation software. In fact, the category is so obscure that there
> > isn't one agreed term: data cleaning , data munging , data crunching ,
> > or just getting the data ready for analysis.
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
> --
> Frank E Harrell Jr   Professor and Chair           School of Medicine
>                       Department of Biostatistics   Vanderbilt University
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
WenSui Liu
A lousy statistician who happens to know a little programming
(http://spaces.msn.com/statcompute/blog)


From spencer.graves at pdf.com  Fri Jun  8 15:51:04 2007
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 08 Jun 2007 06:51:04 -0700
Subject: [R] Fwd: Using odesolve to produce non-negative solutions
In-Reply-To: <4666A910.896D.005E.0@hsph.harvard.edu>
References: <4666A5D0.896D.005E.0@hsph.harvard.edu>
	<4666A910.896D.005E.0@hsph.harvard.edu>
Message-ID: <46695EC8.2090602@pdf.com>

      On the 'lsoda' help page, I did not see any option to force some 
or all parameters to be nonnegative. 

      Have you considered replacing the parameters that must be 
nonnegative with their logarithms?  This effective moves the 0 lower 
limit to (-Inf) and seems to have worked well for me in the past.  
Often, it can even make the log likelihood or sum of squares surface 
more elliptical, which means that the standard normal approximation for 
the sampling distribution of parameter estimates will likely be more 
accurate. 

      Hope this helps. 
      Spencer Graves
p.s.  Your example seems not to be self contained.  If I could have 
easily copied it from your email and run it myself, I might have been 
able to offer more useful suggestions. 

Jeremy Goldhaber-Fiebert wrote:
> Hello,
>
> I am using odesolve to simulate a group of people moving through time and transmitting infections to one another. 
>
> In Matlab, there is a NonNegative option which tells the Matlab solver to keep the vector elements of the ODE solution non-negative at all times. What is the right way to do this in R?
>
> Thanks,
> Jeremy
>
> P.S., Below is a simplified version of the code I use to try to do this, but I am not sure that it is theoretically right 
>
> dynmodel <- function(t,y,p) 
> { 
> ## Initialize parameter values
>
> 	birth <- p$mybirth(t)
> 	death <- p$mydeath(t)
> 	recover <- p$myrecover
> 	beta <- p$mybeta
> 	vaxeff <- p$myvaxeff
> 	vaccinated <- p$myvax(t)
>
> 	vax <- vaxeff*vaccinated/100
>
> ## If the state currently has negative quantities (shouldn't have), then reset to reasonable values for computing meaningful derivatives
>
> 	for (i in 1:length(y)) {
> 		if (y[i]<0) {
> 			y[i] <- 0
> 		}
> 	}
>
> 	S <- y[1]
> 	I <- y[2]
> 	R <- y[3]
> 	N <- y[4]
>
> 	shat <- (birth*(1-vax)) - (death*S) - (beta*S*I/N)
> 	ihat <- (beta*S*I/N) - (death*I) - (recover*I)
> 	rhat <- (birth*(vax)) + (recover*I) - (death*R)
>
> ## Do we overshoot into negative space, if so shrink derivative to bring state to 0 
> ## then rescale the components that take the derivative negative
>
> 	if (shat+S<0) {
> 		shat_old <- shat
> 		shat <- -1*S
> 		scaled_transmission <- (shat/shat_old)*(beta*S*I/N)
> 		ihat <- scaled_transmission - (death*I) - (recover*I)
> 		
> 	}	
> 	if (ihat+I<0) {
> 		ihat_old <- ihat
> 		ihat <- -1*I
> 		scaled_recovery <- (ihat/ihat_old)*(recover*I)
> 		rhat <- scaled_recovery +(birth*(vax)) - (death*R)
> 	
> 	}	
> 	if (rhat+R<0) {
> 		rhat <- -1*R
> 	}	
>
> 	nhat <- shat + ihat + rhat
>
> 	if (nhat+N<0) {
> 		nhat <- -1*N	
> 	}	
>
> ## return derivatives
>
> 	list(c(shat,ihat,rhat,nhat),c(0))
>
> }
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From parrinel at med.unibs.it  Fri Jun  8 16:02:39 2007
From: parrinel at med.unibs.it (Giovanni Parrinello)
Date: Fri, 08 Jun 2007 16:02:39 +0200
Subject: [R] "R is not a validated software package.."
Message-ID: <4669617F.8090405@med.unibs.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070608/83372586/attachment.pl 

From timb at metrumrg.com  Fri Jun  8 16:08:50 2007
From: timb at metrumrg.com (Tim Bergsma)
Date: Fri, 08 Jun 2007 10:08:50 -0400
Subject: [R] logical 'or' on list of vectors
In-Reply-To: <00b101c7a9d1$eb46e760$0540210a@www.domain>
References: <46695221.8080807@metrumrg.com>
	<00b101c7a9d1$eb46e760$0540210a@www.domain>
Message-ID: <466962F2.7040406@metrumrg.com>

Thanks all for the many excellent suggestions!

!complete.cases(Theoph) is probably the most succinct form for the 
current problem, while the examples with 'any' seem readily adaptable to 
similar situations.

Kind regards,

Tim.

Dimitris Rizopoulos wrote:
> try the following:
> 
> as.logical(rowSums(is.na(Theoph)))
> ## or
> !complete.cases(Theoph)
> 
> 
> I hope it helps.
> 
> Best,
> Dimitris
> 
> ----
> Dimitris Rizopoulos
> Ph.D. Student
> Biostatistical Centre
> School of Public Health
> Catholic University of Leuven
> 
> Address: Kapucijnenvoer 35, Leuven, Belgium
> Tel: +32/(0)16/336899
> Fax: +32/(0)16/337015
> Web: http://med.kuleuven.be/biostat/
>     http://www.student.kuleuven.be/~m0390867/dimitris.htm
> 
> 
> ----- Original Message ----- From: "Tim Bergsma" <timb at metrumrg.com>
> To: <r-help at stat.math.ethz.ch>
> Sent: Friday, June 08, 2007 2:57 PM
> Subject: [R] logical 'or' on list of vectors
> 
> 
>> Suppose I have a list of logicals, such as returned by lapply:
>>
>> Theoph$Dose[1] <- NA
>> Theoph$Time[2] <- NA
>> Theoph$conc[3] <- NA
>> lapply(Theoph,is.na)
>>
>> Is there a direct way to execute logical "or" across all vectors? The
>> following gives the desired result, but seems unnecessarily complex.
>>
>> as.logical(apply(do.call("rbind",lapply(Theoph,is.na)),2,"sum"))
>>
>> Regards,
>>
>> Tim
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 
> Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm
> 
> 
>


From HStevens at MUOhio.edu  Fri Jun  8 16:11:44 2007
From: HStevens at MUOhio.edu (Martin Henry H. Stevens)
Date: Fri, 8 Jun 2007 10:11:44 -0400
Subject: [R] Tools For Preparing Data For Analysis
In-Reply-To: <40e66e0b0706080547o5c630ac3ne5feadc4247e289a@mail.gmail.com>
References: <874da0b40706071701m55cd42fem15f55a8fcde04f17@mail.gmail.com>
	<40e66e0b0706080547o5c630ac3ne5feadc4247e289a@mail.gmail.com>
Message-ID: <6BB2732B-E656-4A61-8D09-8C5D5EFC5AA4@MUOhio.edu>

Is there an example available of this sort of problematic data that  
requires this kind of data screening and filtering? For many of us,  
this issue would be nice to learn about, and deal with within R. If a  
package could be created, that would be optimal for some of us. I  
would like to learn a tad more, if it were not too much effort for  
someone else to point me in the right direction?
Cheers,
Hank
On Jun 8, 2007, at 8:47 AM, Douglas Bates wrote:

> On 6/7/07, Robert Wilkins <irishhacker at gmail.com> wrote:
>> As noted on the R-project web site itself ( www.r-project.org ->
>> Manuals -> R Data Import/Export ), it can be cumbersome to prepare
>> messy and dirty data for analysis with the R tool itself. I've also
>> seen at least one S programming book (one of the yellow Springer  
>> ones)
>> that says, more briefly, the same thing.
>> The R Data Import/Export page recommends examples using SAS, Perl,
>> Python, and Java. It takes a bit of courage to say that ( when you go
>> to a corporate software web site, you'll never see a page saying  
>> "This
>> is the type of problem that our product is not the best at, here's
>> what we suggest instead" ). I'd like to provide a few more
>> suggestions, especially for volunteers who are willing to evaluate  
>> new
>> candidates.
>>
>> SAS is fine if you're not paying for the license out of your own
>> pocket. But maybe one reason you're using R is you don't have
>> thousands of spare dollars.
>> Using Java for data cleaning is an exercise in sado-masochism, Java
>> has a learning curve (almost) as difficult as C++.
>>
>> There are different types of data transformation, and for some data
>> preparation problems an all-purpose programming language is a good
>> choice ( i.e. Perl , or maybe Python/Ruby ). Perl, for example, has
>> excellent regular expression facilities.
>>
>> However, for some types of complex demanding data preparation
>> problems, an all-purpose programming language is a poor choice. For
>> example: cleaning up and preparing clinical lab data and adverse  
>> event
>> data - you could do it in Perl, but it would take way, way too much
>> time. A specialized programming language is needed. And since data
>> transformation is quite different from data query, SQL is not the
>> ideal solution either.
>>
>> There are only three statistical programming languages that are
>> well-known, all dating from the 1970s: SPSS, SAS, and S. SAS is more
>> popular than S for data cleaning.
>>
>> If you're an R user with difficult data preparation problems, frankly
>> you are out of luck, because the products I'm about to mention are
>> new, unknown, and therefore regarded as immature. And while the
>> founders of these products would be very happy if you kicked the
>> tires, most people don't like to look at brand new products. Most
>> innovators and inventers don't realize this, I've learned it the hard
>> way.
>>
>> But if you are a volunteer who likes to help out by evaluating,
>> comparing, and reporting upon new candidates, well you could  
>> certainly
>> help out R users and the developers of the products by kicking the
>> tires of these products. And there is a huge need for such  
>> volunteers.
>>
>> 1. DAP
>> This is an open source implementation of SAS.
>> The founder: Susan Bassein
>> Find it at: directory.fsf.org/math/stats (GNU GPL)
>>
>> 2. PSPP
>> This is an open source implementation of SPSS.
>> The relatively early version number might not give a good idea of how
>> mature the
>> data transformation features are, it reflects the fact that he has
>> only started doing the statistical tests.
>> The founder: Ben Pfaff, either a grad student or professor at  
>> Stanford CS dept.
>> Also at : directory.fsf.org/math/stats (GNU GPL)
>>
>> 3. Vilno
>> This uses a programming language similar to SPSS and SAS, but  
>> quite unlike S.
>> Essentially, it's a substitute for the SAS datastep, and also
>> transposes data and calculates averages and such. (No t-tests or
>> regressions in this version). I created this, during the years
>> 2001-2006 mainly. It's version 0.85, and has a fairly low bug  
>> rate, in
>> my opinion. The tarball includes about 100 or so test cases used for
>> debugging - for logical calculation errors, but not for extremely  
>> high
>> volumes of data.
>> The maintenance of Vilno has slowed down, because I am currently
>> (desparately) looking for employment. But once I've found new
>> employment and living quarters and settled in, I will continue to
>> enhance Vilno in my spare time.
>> The founder: that would be me, Robert Wilkins
>> Find it at: code.google.com/p/vilno ( GNU GPL )
>> ( In particular, the tarball at code.google.com/p/vilno/downloads/ 
>> list
>> , since I have yet to figure out how to use Subversion ).
>>
>> 4. Who knows?
>> It was not easy to find out about the existence of DAP and PSPP. So
>> who knows what else is out there. However, I think you'll find a lot
>> more statistics software ( regression , etc ) out there, and not so
>> much data transformation software. Not many people work on data
>> preparation software. In fact, the category is so obscure that there
>> isn't one agreed term: data cleaning , data munging , data  
>> crunching ,
>> or just getting the data ready for analysis.
>
> Thanks for bringing up this topic.  I think there is definitely a
> place for such languages, which I would regard as data-filtering
> languages, but I also think that trying to reproduce the facilities in
> SAS or SPSS for data analysis is redundant.
>
> Other responses in this thread have mentioned 'little language'
> filters like awk, which is fine for those who were raised in the Bell
> Labs tradition of programming ("why type three characters when two
> character names should suffice for anything one wants to do on a
> PDP-11") but the typical field scientist finds this a bit too terse to
> understand and would rather write a filter as a paragraph of code that
> they have a change of reading and understanding a week later.
>
> Frank Harrell indicated that it is possible to do a lot of difficult
> data transformation within R itself if you try hard enough but that
> sometimes means working against the S language and its "whole object"
> view to accomplish what you want and it can require knowledge of
> subtle aspects of the S language.
>
> General scripting languages like Perl, Python and Ruby can certainly
> be used for data filtering but that means learning the language and
> its idiosyncrasies, and those idiosyncrasies are often exactly the
> aspects that would be used to write a filter tersely.  Readability
> suffers.  ("Hell is reading someone else's Perl code - purgatory is
> reading your own Perl code.")  The very generality of the languages
> means there is a lot to learn and understand before you can write
> something like a simple filter.
>
> So I do agree that it would be useful to have a language like the SAS
> data step (but Open Source, of course) in which to write a data
> filter.  I have one suggestion to make - use the R data frame
> structure in the form of a .rda file as the binary output format for a
> data table.  That way the user can get the best of both worlds by
> using a language like Viino to manipulate and rearrange huge data
> files then switching to R for the graphics and data analysis.  As a
> further enhancement one might provide the ability to take a .rda file
> that contains a single data frame and select columns or rows,
> including a random sample of the rows, as a filter.
>
> Producing an R data frame may involve passing over the data twice,
> once to determine the size of the resulting structure and the second
> time to evaluate the data itself.  This would have been a horrific
> penalty in the days that SAS and SPSS were developed but not now.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



Dr. Hank Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/

"E Pluribus Unum"


From mpp26 at cam.ac.uk  Fri Jun  8 16:15:18 2007
From: mpp26 at cam.ac.uk (M. P. Papadatos)
Date: Fri, 8 Jun 2007 15:15:18 +0100
Subject: [R] pointwise confidence bands or interval values for a non
	parametric sm.regression
Message-ID: <93D4D0BA-4709-45CD-BCBF-2A2C58AB1B2B@cam.ac.uk>

Dear all,

Is there a way to plot / calculate pointwise confidence bands or  
interval values for a non parametric regression like sm.regression?

Thank you in advance.

Regards,

Martin



From liuwensui at gmail.com  Fri Jun  8 16:23:58 2007
From: liuwensui at gmail.com (Wensui Liu)
Date: Fri, 8 Jun 2007 10:23:58 -0400
Subject: [R] "R is not a validated software package.."
In-Reply-To: <4669617F.8090405@med.unibs.it>
References: <4669617F.8090405@med.unibs.it>
Message-ID: <1115a2b00706080723g153557b9k818b342f1ac0feb8@mail.gmail.com>

I like to know the answer as well.
To be honest, I really have hard time to understand the mentality of
clinical trial guys and rather believe it is something related to job
security.

On 6/8/07, Giovanni Parrinello <parrinel at med.unibs.it> wrote:
> Dear All,
> discussing with a statistician of a pharmaceutical company I received
> this answer about the statistical package that I have planned to use:
>
> As R is not a validated software package, we would like to ask if it
> would rather be possible for you to use SAS, SPSS or another approved
> statistical software system.
>
> Could someone suggest me a 'polite' answer?
> TIA
> Giovanni
>
> --
> dr. Giovanni Parrinello
> External Lecturer
> Medical Statistics Unit
> Department of Biomedical Sciences
> Viale Europa, 11 - 25123 Brescia Italy
> Tel: +390303717528
> Fax: +390303717488
> email: parrinel at med.unibs.it
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
WenSui Liu
A lousy statistician who happens to know a little programming
(http://spaces.msn.com/statcompute/blog)


From h.wickham at gmail.com  Fri Jun  8 16:25:17 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 8 Jun 2007 16:25:17 +0200
Subject: [R] rlm results on trellis plot
In-Reply-To: <1181227630.6917.12.camel@gestalt.nimh.nih.gov>
References: <1181227630.6917.12.camel@gestalt.nimh.nih.gov>
Message-ID: <f8e6ff050706080725w1f1e7d25v7b30a01e95b3abb@mail.gmail.com>

On 6/7/07, Alan S Barnett <asb at mail.nih.gov> wrote:
> How do I add to a trellis plot the best fit line from a robust fit? I
> can use panel.lm to add a least squares fit, but there is no panel.rlm
> function.

It's not trellis, but it's really easy to do this with ggplot2:

install.packages("ggplot2", dep=T)
library(ggplot2)

p <- qplot(x, y, data=diamonds)
p + geom_smooth(method="lm")
p + geom_smooth(method="rlm")
p + geom_smooth(method="lm", formula="y ~ poly(x,3)")

see http://had.co.nz/ggplot2/stat_smooth.html for more examples.

Hadley


From kw.statr at gmail.com  Fri Jun  8 16:27:43 2007
From: kw.statr at gmail.com (Kevin Wright)
Date: Fri, 8 Jun 2007 09:27:43 -0500
Subject: [R] Sorting dataframe by different columns
In-Reply-To: <000001c7a99a$79d46990$0f1e0b0a@3med.klinik.unimainz.de>
References: <000c01c7a965$d81ae220$0300a8c0@Vaio>
	<000001c7a99a$79d46990$0f1e0b0a@3med.klinik.unimainz.de>
Message-ID: <c968588d0706080727j2e769039id637fd014937485a@mail.gmail.com>

On the R wiki site there is a general-purpose function
(sort.data.frame) that allows you to do this:

sort(df, by=~ x-z)

See: http://wiki.r-project.org/rwiki/doku.php?id=tips:data-frames:sort

Regards,

Kevin

On 6/8/07, Gunther H?ning <gunther.hoening at ukmainz.de> wrote:
> Dear list,
>
> I have a very short question,
> Suggest a dataframe of four columns.
>
> df <- data.frame(w,x,y,z)
>
> I want this ordered the following way:
> first by :x, decreasing = FALSE
> and
> secondly by: z, decreasing =TRUE
>
> How can this be done ?
>
> Thanks
>
> Gunther
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From edd at debian.org  Fri Jun  8 16:27:49 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 8 Jun 2007 09:27:49 -0500
Subject: [R] Ubu edgy + latest CRAN R + Rmpi = no go
In-Reply-To: <6262c54c0706071522s72d0102bt98e43a94626b6b7e@mail.gmail.com>
References: <6262c54c0706071522s72d0102bt98e43a94626b6b7e@mail.gmail.com>
Message-ID: <18025.26469.373816.79670@basebud.nulle.part>


On 7 June 2007 at 17:22, Tim Keitt wrote:
| I'm just curious if anyone else has had problems with this
| configuration. I added the CRAN repository to apt and installed 2.5.0
| with apt-get. I then did an install.packages("Rmpi") on cluster nodes.
| Rmpi loads and lamhosts() shows the nodes, but mpi.spawn.Rslaves()
| fails (something to do with temp files?). Rmpi works fine with the

I have had similar issues at work. If you fix the lam packages at version
7.1.1, it works.  It does not seem to work with 7.1.2 in the current Ubuntu,
not does it work with 7.1.4 (current upstream version).

As other MPI tools seem to work, I would put the error on Rmpi, but I have
not had time to pin this down.

For what it's worth, a few of us are trying to revive the OpenMPI packages in
Debian, and I have started to on a port of Rmpi to ROpenMPI.  No ETA for that.

| Edgy-native version of R (2.3.x) and installing Edgy's r-cran-rmpi
| with apt. (But I need some other packages that only work in 2.4+!)
| Could this be a problem with the latest Ubu debs on CRAN? The Rmpi

R itself is just fine on Ubuntu, thank you.

Dirk

| author says his R 2.5 setup works fine. CC me please as I'm not
| subscribed.
| 
| THK
| 
| -- 
| Timothy H. Keitt, University of Texas at Austin
| Contact info and schedule at http://www.keittlab.org/tkeitt/
| Reprints at http://www.keittlab.org/tkeitt/papers/
| ODF attachment? See http://www.openoffice.org/
| 
| ______________________________________________
| R-help at stat.math.ethz.ch mailing list
| https://stat.ethz.ch/mailman/listinfo/r-help
| PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
| and provide commented, minimal, self-contained, reproducible code.

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From jrkrideau at yahoo.ca  Fri Jun  8 16:35:31 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Fri, 8 Jun 2007 10:35:31 -0400 (EDT)
Subject: [R] character to time problem
In-Reply-To: <BAY116-DAV8394EF8D7EA66D218CE96CF260@phx.gbl>
Message-ID: <990.61035.qm@web32809.mail.mud.yahoo.com>


--- Jason Barnhart <jasoncbarnhart at msn.com> wrote:

> Hi John,
> 
> a) The NA appears because '30/02/1995' is not a
> valid date.
> 
>     > strptime('30/02/1995' , "%d/%m/%Y")
>     [1] NA
>

I knew we should never have moved to the Gregorian
Calender!  

Thanks.  I accidently made up the date but this means
that I have some invalid dates in the file. Not a
problem now I know what's happening. And our contract
says someone else gets to fix them :)

> b) dates which has the following classes uses
> sort.POSIXlt which in 
> turns sets na.last to NA.  ?order details how NA's
> are handled in 
> ordering data via na.last.
> 
>     > class(dates)
>     [1] "POSIXt"  "POSIXlt"
> 
>     > methods(sort)
>     [1] sort.default sort.POSIXlt
> 
>     > sort.POSIXlt
>     function (x, decreasing = FALSE, na.last = NA,
> ...)
>     x[order(as.POSIXct(x), na.last = na.last,
> decreasing = 
> decreasing)]
>     <environment: namespace:base>
> 
> After resetting the Feb. date the code works.
> 
> HTH,
> -jason
> 

So it does.  

I had not thought to look at the sort.POSIXlt
function.  I don't quite understand what na.last is
doing and don't seem to see the documentation.  Is it
sorting the NA's to the last place(s) in the vector
and then dropping them? 

Thanks again

> ----- Original Message ----- 
> From: "John Kane" <jrkrideau at yahoo.ca>
> To: "R R-help" <r-help at stat.math.ethz.ch>
> Sent: Thursday, June 07, 2007 2:17 PM
> Subject: [R] character to time problem
> 
> 
> >I am trying to clean up some dates and I am clearly
> > doing something wrong.  I have laid out an example
> > that seems to show what is happening with the
> "real"
> > data.  The  coding is lousy but it looks like it
> > should have worked.
> >
> > Can anyone suggest a) why I am getting that NA
> > appearing after the strptime() command and b) why
> the
> > NA is disappearing in the sort()? It happens with
> > na.rm=TRUE  and na.rm=FALSE
> > -------------------------------------------------
> > aa  <- data.frame( c("12/05/2001", " ",
> "30/02/1995",
> > NA, "14/02/2007", "M" ) )
> > names(aa)  <- "times"
> > aa[is.na(aa)] <- "M"
> > aa[aa==" "]  <- "M"
> > bb <- unlist(subset(aa, aa[,1] !="M"))
> > dates <- strptime(bb, "%d/%m/%Y")
> > dates
> > sort(dates)
> > --------------------------------------------------
> >
> > Session Info
> > R version 2.4.1 (2006-12-18)
> > i386-pc-mingw32
> >
> > locale:
> > LC_COLLATE=English_Canada.1252;
> > LC_CTYPE=English_Canada.1252;
> > LC_MONETARY=English_Canada.1252;
> > LC_NUMERIC=C;LC_TIME=English_Canada.1252
> >
> > attached base packages:
> > [1] "stats"     "graphics"  "grDevices" "utils"
> > "datasets"  "methods"   "base"
> >
> > other attached packages:
> >  gdata   Hmisc
> > "2.3.1" "3.3-2"
> >
> > (Yes I know I'm out of date but I don't like
> > upgrading just as I am finishing a project)
> >
> > Thanks
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained,
> reproducible code.
> > 
> 
>


From edd at debian.org  Fri Jun  8 16:40:07 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 8 Jun 2007 09:40:07 -0500
Subject: [R] Use R in a pipeline as a filter
In-Reply-To: <20070607122729.80180@gmx.net>
References: <20070607122729.80180@gmx.net>
Message-ID: <18025.27207.186116.228952@basebud.nulle.part>


On 7 June 2007 at 14:27, mw-u2 at gmx.de wrote:
| how can I use R in a pipline like this
| 
|  $ ./generate-data | R --script-file=Script.R | ./further-analyse-data > result.dat

The 'r' in our 'littler' package can do that. One example we show on the
littler webpage is

	$ ls -l /boot | awk '!/^total/ {print $5}' | \
		 r -e 'fsizes <- as.integer(readLines());
			print(summary(fsizes)); stem(fsizes)'

We use R's readLines to read from stdin, and you can of course also have r
'in the middle' if you take care of the output generated -- which our example
doesn't do as it prints straight to screen.

Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From Sicotte.Hugues at mayo.edu  Fri Jun  8 16:40:59 2007
From: Sicotte.Hugues at mayo.edu (Sicotte, Hugues   Ph.D.)
Date: Fri, 8 Jun 2007 09:40:59 -0500
Subject: [R] "R is not a validated software package.."
In-Reply-To: <1115a2b00706080723g153557b9k818b342f1ac0feb8@mail.gmail.com>
References: <4669617F.8090405@med.unibs.it>
	<1115a2b00706080723g153557b9k818b342f1ac0feb8@mail.gmail.com>
Message-ID: <2E17292A64E6ED418A60BE89326B1AAB664473@msgebe11.mfad.mfroot.org>

People, don't get angry at the pharma statistician, he is just trying to
abide by an FDA requirement that is designed to insure that test perform
reliably the same. There is no point in getting into which product is
better. As far as the FDA rules are concerned a validated system beats a
"better" system any day of the week.

Here is your polite answer.
You can develop and try your software in R.
Should they need to use those results in a report that will matter to
the FDA, then you can work together with him to set up a validated
environment for S-plus. You then have to commit to port your code to
S-plus.

As I assume that you do not work in a regulated environment, you
probably wouldn't have access to a validated SAS environment anyways. It
is not usually enough to install a piece of software, you have to
validate every step of the installation. Since AFAIK the FDA uses
S-plus, it would be to your pharma person's advantage to speed-up
submissions if they also had a validated S-plus environment.

http://www.msmiami.com/custom/downloads/S-PLUSValidationdatasheet_Final.
pdf


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Wensui Liu
Sent: Friday, June 08, 2007 9:24 AM
To: Giovanni Parrinello
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] "R is not a validated software package.."

I like to know the answer as well.
To be honest, I really have hard time to understand the mentality of
clinical trial guys and rather believe it is something related to job
security.

On 6/8/07, Giovanni Parrinello <parrinel at med.unibs.it> wrote:
> Dear All,
> discussing with a statistician of a pharmaceutical company I received
> this answer about the statistical package that I have planned to use:
>
> As R is not a validated software package, we would like to ask if it
> would rather be possible for you to use SAS, SPSS or another approved
> statistical software system.
>
> Could someone suggest me a 'polite' answer?
> TIA
> Giovanni
>
> --
> dr. Giovanni Parrinello
> External Lecturer
> Medical Statistics Unit
> Department of Biomedical Sciences
> Viale Europa, 11 - 25123 Brescia Italy
> Tel: +390303717528
> Fax: +390303717488
> email: parrinel at med.unibs.it
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
WenSui Liu
A lousy statistician who happens to know a little programming
(http://spaces.msn.com/statcompute/blog)

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at yahoo.ca  Fri Jun  8 16:45:59 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Fri, 8 Jun 2007 10:45:59 -0400 (EDT)
Subject: [R] character to time problem
In-Reply-To: <971536df0706071501s6c744f12o3ad64e98d590bcc9@mail.gmail.com>
Message-ID: <99899.33275.qm@web32805.mail.mud.yahoo.com>

Looks much better. I seldom use dates for much and
didn't think to look at the sort.POSIXlt function.

If I understand this correctly the sort.POSIXlt with
na.last = FALSE is dropping all the NAs.  Very nice.


--- Gabor Grothendieck <ggrothendieck at gmail.com>
wrote:

> Perhaps you want one of these:
> 
> > sort(as.Date(aa$times, "%d/%m/%Y"))
> [1] "1995-03-02" "2001-05-12" "2007-02-14"
> 
> > sort(as.Date(aa$times, "%d/%m/%Y"), na.last =
> TRUE)
> [1] "1995-03-02" "2001-05-12" "2007-02-14" NA       
>    NA
> [6] NA
> 
> 
> On 6/7/07, John Kane <jrkrideau at yahoo.ca> wrote:
> > I am trying to clean up some dates and I am
> clearly
> > doing something wrong.  I have laid out an example
> > that seems to show what is happening with the
> "real"
> > data.  The  coding is lousy but it looks like it
> > should have worked.
> >
> > Can anyone suggest a) why I am getting that NA
> > appearing after the strptime() command and b) why
> the
> > NA is disappearing in the sort()? It happens with
> > na.rm=TRUE  and na.rm=FALSE
> > -------------------------------------------------
> > aa  <- data.frame( c("12/05/2001", " ",
> "30/02/1995",
> > NA, "14/02/2007", "M" ) )
> > names(aa)  <- "times"
> > aa[is.na(aa)] <- "M"
> > aa[aa==" "]  <- "M"
> > bb <- unlist(subset(aa, aa[,1] !="M"))
> > dates <- strptime(bb, "%d/%m/%Y")
> > dates
> > sort(dates)
> > --------------------------------------------------
> >
> > Session Info
> > R version 2.4.1 (2006-12-18)
> > i386-pc-mingw32
> >
> > locale:
> > LC_COLLATE=English_Canada.1252;
> > LC_CTYPE=English_Canada.1252;
> > LC_MONETARY=English_Canada.1252;
> > LC_NUMERIC=C;LC_TIME=English_Canada.1252
> >
> > attached base packages:
> > [1] "stats"     "graphics"  "grDevices" "utils"
> > "datasets"  "methods"   "base"
> >
> > other attached packages:
> >  gdata   Hmisc
> > "2.3.1" "3.3-2"
> >
> >  (Yes I know I'm out of date but I don't like
> > upgrading just as I am finishing a project)
> >
> > Thanks
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained,
> reproducible code.
> >
>


From f.harrell at vanderbilt.edu  Fri Jun  8 16:45:17 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Fri, 08 Jun 2007 09:45:17 -0500
Subject: [R] "R is not a validated software package.."
In-Reply-To: <4669617F.8090405@med.unibs.it>
References: <4669617F.8090405@med.unibs.it>
Message-ID: <46696B7D.10705@vanderbilt.edu>

Giovanni Parrinello wrote:
> Dear All,
> discussing with a statistician of a pharmaceutical company I received 
> this answer about the statistical package that I have planned to use:
> 
> As R is not a validated software package, we would like to ask if it 
> would rather be possible for you to use SAS, SPSS or another approved 
> statistical software system.
> 
> Could someone suggest me a 'polite' answer?
> TIA
> Giovanni
> 

Search the archives and you'll find a LOT of responses.

Briefly, in my view there are no requirements, just some pharma 
companies that think there are.  FDA is required to accepted all 
submissions, and they get some where only Excel was used, or Minitab, 
and lots more.  There is a session on this at the upcoming R 
International Users Meeting in Iowa in August.  The session will include 
dicussions of federal regulation compliance for R, for those users who 
feel that such compliance is actually needed.

Frank

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From jrkrideau at yahoo.ca  Fri Jun  8 16:48:38 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Fri, 8 Jun 2007 10:48:38 -0400 (EDT)
Subject: [R] overplots - fixing scientific vs normal notation in output
In-Reply-To: <20070608110700.g8esovsr48gkoso8@webmail.i-med.ac.at>
Message-ID: <343633.50039.qm@web32810.mail.mud.yahoo.com>


--- Peter Lercher <Peter.Lercher at i-med.ac.at> wrote:

> Moving from S-plus to R I encountered many great
> features and a much
> more stable system.
> Currently, I am left with 2 problems that are
> handled differently:
> 
> 1) I did lots of "overplots" in S-Plus using
> par(new=T,xaxs='d',yaxs='d') to fix the axes
> ->What is the workaround in R ?

What does S=Plus do here?  
> 
> 2) In S-Plus I could fix "scientific notation" or
> "normal notation" in output
> ->How can I handle this in R ?
> I found no fix in the documentation

?format() maybe?

> 
> I am using R version 2.4.1 (2006-12-18) on Windows
> XP SR2
> 
> 
> Peter Lercher, M.D., M.P.H., Assoc Prof
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From rroa at udec.cl  Fri Jun  8 17:02:09 2007
From: rroa at udec.cl (=?ISO-8859-1?Q?Rub=E9n_Roa-Ureta?=)
Date: Fri, 08 Jun 2007 11:02:09 -0400
Subject: [R] How to make a table of a desired dimension
Message-ID: <46696F71.6080407@udec.cl>

Hi ComRades,

I want to make a matrix of frequencies from vectors of a continuous 
variable spanning different values. For example this code
x<-c(runif(100,10,40),runif(100,43,55))
y<-c(runif(100,7,35),runif(100,37,50))
z<-c(runif(100,10,42),runif(100,45,52))
a<-table(ceiling(x))
b<-table(ceiling(y))
c<-table(ceiling(z))
a
b
c

will give me three tables that start and end at different integer 
values, and besides, they have 'holes' in between different integer 
values. Is it possible to use 'table' to make these three tables have 
the same dimensions, filling in the absent labels with zeroes? In the 
example above, the desired tables should all start at 8 and tables 'a' 
and 'c' should put a zero at labels '8' to '10', should all put zeros in 
the frequencies of the labels corresponding to the holes, and should all 
end at label '55'. The final purpose is the make a matrix and use 
'matplot' to plot all the frequencies in one plot, such as

#code valid only when 'a', 'b', and 'c' have the proper dimension
p<-mat.or.vec(48,4)
p[,1]<-8:55
p[,2]<-c(matrix(a)[1:48])
p[,3]<-c(matrix(b)[1:48])
p[,4]<-c(matrix(c)[1:48])
matplot(p)

I read the help about 'table' but I couldn't figure out if dnn, 
deparse.level, or the other arguments could serve my purpose. Thanks for 
your help
Rub?n


From helprhelp at gmail.com  Fri Jun  8 17:12:27 2007
From: helprhelp at gmail.com (Weiwei Shi)
Date: Fri, 8 Jun 2007 11:12:27 -0400
Subject: [R] data mining/text mining?
In-Reply-To: <000001c7a997$45df81e0$7000a8c0@scbit94ec75129>
References: <000001c7a997$45df81e0$7000a8c0@scbit94ec75129>
Message-ID: <cdf817830706080812v5821084crc0338e895d5fd5f2@mail.gmail.com>

Dear Ruixin:
Among others, text mining is dealing with non-structural data while
data mining mainly focuses on structural one. Many algorithms can be
shared b/w them; however, some necessary data preprocessing is
required for text mining. There are a lot of online-resource there.

As to packages used for text mining in R, esp. for preprocessing,
please check the following link:
http://wwwpeople.unil.ch/jean-pierre.mueller/

I used that package very long time ago and am not sure if they are
updated for this current version of R; otherwise, you might need to go
back the old version like R1.1.

If you want to do text mining for chinese text (I guess :), there is
additional work (i.e. word splitting) needed. I remember there is some
researcher from Taiwan who does pretty good work and you can google
that. I cannot remember the details.

HTH,

Weiwei


On 6/8/07, Ruixin ZHU <rxzhu at scbit.org> wrote:
> Dear R-user,
>
> Could anybody tell me of the key difference between data mining and text
> mining?
> Please make a list for packages about data/text mining.
> And give me an example of text mining with R (any relating materials
> will be highly appreciated), because a vignette written by Ingo Feinerer
> seems too concise for me.
>
> Thanks
> _____________________________________________
> Dr.Ruixin ZHU
> Shanghai Center for Bioinformation Technology
> rxzhu at scbit.org
> zhurx at mail.sioc.ac.cn
> 86-21-13040647832
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Weiwei Shi, Ph.D
Research Scientist
GeneGO, Inc.

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III


From elyakhlifi_mustapha at yahoo.fr  Fri Jun  8 17:12:33 2007
From: elyakhlifi_mustapha at yahoo.fr (elyakhlifi mustapha)
Date: Fri, 8 Jun 2007 15:12:33 +0000 (GMT)
Subject: [R] matrix and data frame
Message-ID: <222703.3854.qm@web27504.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070608/b3659b6e/attachment.pl 

From ggrothendieck at gmail.com  Fri Jun  8 17:15:31 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 8 Jun 2007 11:15:31 -0400
Subject: [R] character to time problem
In-Reply-To: <99899.33275.qm@web32805.mail.mud.yahoo.com>
References: <971536df0706071501s6c744f12o3ad64e98d590bcc9@mail.gmail.com>
	<99899.33275.qm@web32805.mail.mud.yahoo.com>
Message-ID: <971536df0706080815ge0dca51g16a3665237b5e2ea@mail.gmail.com>

The code in my post uses "Date" class, not POSIX.
sort.POSIXlt is never invoked.  Suggest you read the
help desk article in R News 4/1 for more.

On 6/8/07, John Kane <jrkrideau at yahoo.ca> wrote:
> Looks much better. I seldom use dates for much and
> didn't think to look at the sort.POSIXlt function.
>
> If I understand this correctly the sort.POSIXlt with
> na.last = FALSE is dropping all the NAs.  Very nice.
>
>
> --- Gabor Grothendieck <ggrothendieck at gmail.com>
> wrote:
>
> > Perhaps you want one of these:
> >
> > > sort(as.Date(aa$times, "%d/%m/%Y"))
> > [1] "1995-03-02" "2001-05-12" "2007-02-14"
> >
> > > sort(as.Date(aa$times, "%d/%m/%Y"), na.last =
> > TRUE)
> > [1] "1995-03-02" "2001-05-12" "2007-02-14" NA
> >    NA
> > [6] NA
> >
> >
> > On 6/7/07, John Kane <jrkrideau at yahoo.ca> wrote:
> > > I am trying to clean up some dates and I am
> > clearly
> > > doing something wrong.  I have laid out an example
> > > that seems to show what is happening with the
> > "real"
> > > data.  The  coding is lousy but it looks like it
> > > should have worked.
> > >
> > > Can anyone suggest a) why I am getting that NA
> > > appearing after the strptime() command and b) why
> > the
> > > NA is disappearing in the sort()? It happens with
> > > na.rm=TRUE  and na.rm=FALSE
> > > -------------------------------------------------
> > > aa  <- data.frame( c("12/05/2001", " ",
> > "30/02/1995",
> > > NA, "14/02/2007", "M" ) )
> > > names(aa)  <- "times"
> > > aa[is.na(aa)] <- "M"
> > > aa[aa==" "]  <- "M"
> > > bb <- unlist(subset(aa, aa[,1] !="M"))
> > > dates <- strptime(bb, "%d/%m/%Y")
> > > dates
> > > sort(dates)
> > > --------------------------------------------------
> > >
> > > Session Info
> > > R version 2.4.1 (2006-12-18)
> > > i386-pc-mingw32
> > >
> > > locale:
> > > LC_COLLATE=English_Canada.1252;
> > > LC_CTYPE=English_Canada.1252;
> > > LC_MONETARY=English_Canada.1252;
> > > LC_NUMERIC=C;LC_TIME=English_Canada.1252
> > >
> > > attached base packages:
> > > [1] "stats"     "graphics"  "grDevices" "utils"
> > > "datasets"  "methods"   "base"
> > >
> > > other attached packages:
> > >  gdata   Hmisc
> > > "2.3.1" "3.3-2"
> > >
> > >  (Yes I know I'm out of date but I don't like
> > > upgrading just as I am finishing a project)
> > >
> > > Thanks
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained,
> > reproducible code.
> > >
> >
>
>
>
>      Be smarter than spam. See how smart SpamGuard is at giving junk email the boot with the All-new Yahoo! Mail at http://mrd.mail.yahoo.com/try_beta?.intl=ca
>
>


From liuwensui at gmail.com  Fri Jun  8 17:16:44 2007
From: liuwensui at gmail.com (Wensui Liu)
Date: Fri, 8 Jun 2007 11:16:44 -0400
Subject: [R] "R is not a validated software package.."
In-Reply-To: <46696B7D.10705@vanderbilt.edu>
References: <4669617F.8090405@med.unibs.it> <46696B7D.10705@vanderbilt.edu>
Message-ID: <1115a2b00706080816i121691a6xa1bb540d4961f148@mail.gmail.com>

agree with Frank.
as far as I've known, FDA doesn't encourage or discourage the usage of
software.

On 6/8/07, Frank E Harrell Jr <f.harrell at vanderbilt.edu> wrote:
> Giovanni Parrinello wrote:
> > Dear All,
> > discussing with a statistician of a pharmaceutical company I received
> > this answer about the statistical package that I have planned to use:
> >
> > As R is not a validated software package, we would like to ask if it
> > would rather be possible for you to use SAS, SPSS or another approved
> > statistical software system.
> >
> > Could someone suggest me a 'polite' answer?
> > TIA
> > Giovanni
> >
>
> Search the archives and you'll find a LOT of responses.
>
> Briefly, in my view there are no requirements, just some pharma
> companies that think there are.  FDA is required to accepted all
> submissions, and they get some where only Excel was used, or Minitab,
> and lots more.  There is a session on this at the upcoming R
> International Users Meeting in Iowa in August.  The session will include
> dicussions of federal regulation compliance for R, for those users who
> feel that such compliance is actually needed.
>
> Frank
>
> --
> Frank E Harrell Jr   Professor and Chair           School of Medicine
>                       Department of Biostatistics   Vanderbilt University
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
WenSui Liu
A lousy statistician who happens to know a little programming
(http://spaces.msn.com/statcompute/blog)


From tkeitt at gmail.com  Fri Jun  8 17:17:40 2007
From: tkeitt at gmail.com (Tim Keitt)
Date: Fri, 8 Jun 2007 10:17:40 -0500
Subject: [R] Ubu edgy + latest CRAN R + Rmpi = no go
In-Reply-To: <18025.26469.373816.79670@basebud.nulle.part>
References: <6262c54c0706071522s72d0102bt98e43a94626b6b7e@mail.gmail.com>
	<18025.26469.373816.79670@basebud.nulle.part>
Message-ID: <6262c54c0706080817l5b22eda6l6b09f56017174452@mail.gmail.com>

On 6/8/07, Dirk Eddelbuettel <edd at debian.org> wrote:
>
> On 7 June 2007 at 17:22, Tim Keitt wrote:
> | I'm just curious if anyone else has had problems with this
> | configuration. I added the CRAN repository to apt and installed 2.5.0
> | with apt-get. I then did an install.packages("Rmpi") on cluster nodes.
> | Rmpi loads and lamhosts() shows the nodes, but mpi.spawn.Rslaves()
> | fails (something to do with temp files?). Rmpi works fine with the
>
> I have had similar issues at work. If you fix the lam packages at version
> 7.1.1, it works.  It does not seem to work with 7.1.2 in the current Ubuntu,
> not does it work with 7.1.4 (current upstream version).
>
> As other MPI tools seem to work, I would put the error on Rmpi, but I have
> not had time to pin this down.
>
> For what it's worth, a few of us are trying to revive the OpenMPI packages in
> Debian, and I have started to on a port of Rmpi to ROpenMPI.  No ETA for that.
>
> | Edgy-native version of R (2.3.x) and installing Edgy's r-cran-rmpi
> | with apt. (But I need some other packages that only work in 2.4+!)
> | Could this be a problem with the latest Ubu debs on CRAN? The Rmpi
>
> R itself is just fine on Ubuntu, thank you.

And very much appreciated. ;-)

THK

>
> Dirk
>
> | author says his R 2.5 setup works fine. CC me please as I'm not
> | subscribed.
> |
> | THK
> |
> | --
> | Timothy H. Keitt, University of Texas at Austin
> | Contact info and schedule at http://www.keittlab.org/tkeitt/
> | Reprints at http://www.keittlab.org/tkeitt/papers/
> | ODF attachment? See http://www.openoffice.org/
> |
> | ______________________________________________
> | R-help at stat.math.ethz.ch mailing list
> | https://stat.ethz.ch/mailman/listinfo/r-help
> | PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> | and provide commented, minimal, self-contained, reproducible code.
>
> --
> Hell, there are no rules here - we're trying to accomplish something.
>                                                   -- Thomas A. Edison
>


-- 
Timothy H. Keitt, University of Texas at Austin
Contact info and schedule at http://www.keittlab.org/tkeitt/
Reprints at http://www.keittlab.org/tkeitt/papers/
ODF attachment? See http://www.openoffice.org/


From sarah.goslee at gmail.com  Fri Jun  8 17:22:46 2007
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 8 Jun 2007 11:22:46 -0400
Subject: [R] matrix and data frame
In-Reply-To: <222703.3854.qm@web27504.mail.ukl.yahoo.com>
References: <222703.3854.qm@web27504.mail.ukl.yahoo.com>
Message-ID: <efb536d50706080822t17fd3d71ic5b987604566e33e@mail.gmail.com>

I'm not at all certain I understand your question, but try
?cbind

Sarah

On 6/8/07, elyakhlifi mustapha <elyakhlifi_mustapha at yahoo.fr> wrote:
> hello,
> I have just a question before the week end it's that I don't know how to do to paste matrixs and these matrix they have one same column and I'd like to paste its by this column
> and I wanna paste its not below but just at right side hand
> thanks good week end


-- 
Sarah Goslee
http://www.functionaldiversity.org


From gunter.berton at gene.com  Fri Jun  8 17:28:15 2007
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 8 Jun 2007 08:28:15 -0700
Subject: [R] rlm results on trellis plot
In-Reply-To: <46695837.5030902@optonline.net>
Message-ID: <002901c7a9e1$a26a7510$4d908980@gne.windows.gene.com>

I don't think the code below does what's requested, as it assumes a single
overall fit for all panels, and I think the requester wanted separate fits
by panel. This can be easily done, of course, by a minor modification:

xyplot( y ~ x | z,
     panel = function(x,y,...){
	   panel.xyplot(x,y,...)
	   panel.abline(lm(y~x),col="blue",lwd=2)
	   panel.abline(rlm(y~x),col = "red",lwd=2)
	})

Note that the coefficients do not need to be explicitly extracted by coef(),
as panel.abline will do this automatically.

Bert Gunter
Genentech Nonclinical Statistics
South San Francisco, CA 94404
650-467-7374



Alan S Barnett wrote:
> How do I add to a trellis plot the best fit line from a robust fit? I
> can use panel.lm to add a least squares fit, but there is no panel.rlm
> function.

  How about using panel.abline() instead of panel.lmline()?

fit1 <- coef(lm(stack.loss ~ Air.Flow, data = stackloss))
fit2 <- coef(rlm(stack.loss ~ Air.Flow, data = stackloss))

xyplot(stack.loss ~ Air.Flow, data=stackloss,
       panel = function(x, y, ...){
         panel.xyplot(x, y, ...)
         panel.abline(fit1, type="l", col="blue")
         panel.abline(fit2, type="l", col="red")
       }, aspect=1)

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From zackw at panix.com  Fri Jun  8 17:33:04 2007
From: zackw at panix.com (Zack Weinberg)
Date: Fri, 8 Jun 2007 08:33:04 -0700
Subject: [R] evaluating variables in the context of a data frame
In-Reply-To: <Pine.LNX.4.64.0706080657290.22532@gannet.stats.ox.ac.uk>
References: <eb97335b0706072201r9ad1ba1s37bc66611d76fb68@mail.gmail.com>
	<Pine.LNX.4.64.0706080657290.22532@gannet.stats.ox.ac.uk>
Message-ID: <eb97335b0706080833r2febdedej7bbf27d330da3787@mail.gmail.com>

On 6/7/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> >> f <- function(x, dat) evalq(x, dat)
> >> f(o, D)
> > Error in eval(expr, envir, enclos) : object "o" not found
> >> g <- function(x, dat) eval(x, dat)
> >> g(o, D)
> > Error in eval(x, dat) : object "o" not found
> >
> > What am I doing wrong?  This seems to be what the helpfiles say you do
> > to evaluate arguments in the context of a passed-in data frame...
>
> When you call f(o, D), the argument 'o' is evaluated in the current
> environment ('context' in R means something different).  Because of lazy
> evaluation, it is not evaluated until evalq is called, but it evaluated as
> if it was evaluated greedily.
>
> g(quote(o), D) will work.

Thanks.

After a bit more experimentation I figured out that this does what I want:

> h <- function(x, d) eval(substitute(x), d, parent.frame())

but I don't understand why the substitute() helps, or indeed why it
has any effect at all...

zw


From Greg.Snow at intermountainmail.org  Fri Jun  8 17:33:32 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Fri, 8 Jun 2007 09:33:32 -0600
Subject: [R] overplots - fixing scientific vs normal notation in output
In-Reply-To: <20070608110700.g8esovsr48gkoso8@webmail.i-med.ac.at>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBA2177E@LP-EXCHVS07.CO.IHC.COM>


Peter Lercher wrote:

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Peter Lercher
> Sent: Friday, June 08, 2007 3:07 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] overplots - fixing scientific vs normal notation 
> in output
> 
> Moving from S-plus to R I encountered many great features and 
> a much more stable system.
> Currently, I am left with 2 problems that are handled differently:
> 
> 1) I did lots of "overplots" in S-Plus using
> par(new=T,xaxs='d',yaxs='d') to fix the axes
> ->What is the workaround in R ?

Since you are using the same axes, do you really need to do the
overplotting instead of just using lines/points to add to the plot?

R has not implemented xaxs='d', so on your additional plots, just
specify xlim and/or ylim directly.  There are a couple of ways to do
this.  First, find the range of values from all of your plots then use
this as the argument to xlim and ylim for each plot.  Second, create the
first plot then use par('usr') to find what the limits of the
coordinates are, then use these values for xlim/ylim in further plots
(using xaxs/yaxs='i' so the extra 4% is not added). Third, there are
probably other ways, but the above should get you started.



 
> 2) In S-Plus I could fix "scientific notation" or "normal 
> notation" in output
> ->How can I handle this in R ?
> I found no fix in the documentation

Look at options('scipen'), this is not exactly fixing it like S-PLUS,
but could solve most your problems.

> 
> I am using R version 2.4.1 (2006-12-18) on Windows XP SR2
> 
> 
> Peter Lercher, M.D., M.P.H., Assoc Prof
> 


Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111


From gunter.berton at gene.com  Fri Jun  8 18:04:28 2007
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 8 Jun 2007 09:04:28 -0700
Subject: [R] "R is not a validated software package.."
In-Reply-To: <46696B7D.10705@vanderbilt.edu>
Message-ID: <003301c7a9e6$b1778200$4d908980@gne.windows.gene.com>

Frank et. al:

I believe this is a bit too facile. 21 CFR Part 11 does necessitate a
software validation **process** -- but this process does not require any
particular software. Rather, it requires that those using whatever software
demonstrate to the FDA's satisfaction that the software does what it's
supposed to do appropriately. This includes a lot more than assuring, say,
the numerical accuracy of computations; I think it also requires
demonstration that the data are "secure," that it is properly transferred
from one source to another, etc. I assume that the statistical validation of
R would be relatively simple, as R already has an extensive test suite, and
it would simply be a matter of providing that test suite info. A bit more
might be required, but I don't think it's such a big deal. 

I think Wensui Liu's characterization of clinical statisticians as having a
mentality "related to job security" is a canard. Although I work in
nonclinical, my observation is that clinical statistics is complex and
difficult, not only because of many challenging statistical issues, but also
because of the labyrinthian complexities of the regulated and extremely
costly environment in which they work. It is certainly a job that I could
not do.

That said, probably the greatest obstacle to change from SAS is neither
obstinacy nor ignorance, but rather inertia: pharmaceutical companies have
over the decades made a huge investment in SAS infrastructure to support the
collection, organization, analysis, and submission of data for clinical
trials. To convert this to anything else would be a herculean task involving
huge expense, risk, and resources. R, S-Plus (and much else -- e.g. numerous
"unvalidated" data mining software packages) are routinely used by clinical
statisticians to better understand their data and for "exploratory" analyses
that are used to supplement official analyses (e.g. for trying to justify
collection of tissue samples or a pivotal study in a patient subpopulation).
But it is difficult for me to see how one could make a business case to
change clinical trial analysis software infrastructure from SAS to S-Plus,
SPSS, or anything else.

**DISCLAINMER** 
My opinions only. They do not in any way represent the view of my company or
its employees.


Bert Gunter
Genentech Nonclinical Statistics
South San Francisco, CA 94404
650-467-7374


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Frank E Harrell Jr
Sent: Friday, June 08, 2007 7:45 AM
To: Giovanni Parrinello
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] "R is not a validated software package.."

Giovanni Parrinello wrote:
> Dear All,
> discussing with a statistician of a pharmaceutical company I received 
> this answer about the statistical package that I have planned to use:
> 
> As R is not a validated software package, we would like to ask if it 
> would rather be possible for you to use SAS, SPSS or another approved 
> statistical software system.
> 
> Could someone suggest me a 'polite' answer?
> TIA
> Giovanni
> 

Search the archives and you'll find a LOT of responses.

Briefly, in my view there are no requirements, just some pharma 
companies that think there are.  FDA is required to accepted all 
submissions, and they get some where only Excel was used, or Minitab, 
and lots more.  There is a session on this at the upcoming R 
International Users Meeting in Iowa in August.  The session will include 
dicussions of federal regulation compliance for R, for those users who 
feel that such compliance is actually needed.

Frank

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From f.harrell at vanderbilt.edu  Fri Jun  8 18:08:19 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Fri, 08 Jun 2007 11:08:19 -0500
Subject: [R] "R is not a validated software package.."
In-Reply-To: <2E17292A64E6ED418A60BE89326B1AAB664473@msgebe11.mfad.mfroot.org>
References: <4669617F.8090405@med.unibs.it>	<1115a2b00706080723g153557b9k818b342f1ac0feb8@mail.gmail.com>
	<2E17292A64E6ED418A60BE89326B1AAB664473@msgebe11.mfad.mfroot.org>
Message-ID: <46697EF3.5000502@vanderbilt.edu>

Sicotte, Hugues Ph.D. wrote:
> People, don't get angry at the pharma statistician, he is just trying to
> abide by an FDA requirement that is designed to insure that test perform
> reliably the same. There is no point in getting into which product is
> better. As far as the FDA rules are concerned a validated system beats a
> "better" system any day of the week.

There is no such requirement.

> 
> Here is your polite answer.
> You can develop and try your software in R.
> Should they need to use those results in a report that will matter to
> the FDA, then you can work together with him to set up a validated
> environment for S-plus. You then have to commit to port your code to
> S-plus.

That doesn't follow.  What matters is good statistical analysis practice 
no matter which environment you use.  Note that more errors are made in 
the data preparation / derived variables stage than are made by 
statistical software.

Frank

> 
> As I assume that you do not work in a regulated environment, you
> probably wouldn't have access to a validated SAS environment anyways. It
> is not usually enough to install a piece of software, you have to
> validate every step of the installation. Since AFAIK the FDA uses
> S-plus, it would be to your pharma person's advantage to speed-up
> submissions if they also had a validated S-plus environment.
> 
> http://www.msmiami.com/custom/downloads/S-PLUSValidationdatasheet_Final.
> pdf
> 
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Wensui Liu
> Sent: Friday, June 08, 2007 9:24 AM
> To: Giovanni Parrinello
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] "R is not a validated software package.."
> 
> I like to know the answer as well.
> To be honest, I really have hard time to understand the mentality of
> clinical trial guys and rather believe it is something related to job
> security.
> 
> On 6/8/07, Giovanni Parrinello <parrinel at med.unibs.it> wrote:
>> Dear All,
>> discussing with a statistician of a pharmaceutical company I received
>> this answer about the statistical package that I have planned to use:
>>
>> As R is not a validated software package, we would like to ask if it
>> would rather be possible for you to use SAS, SPSS or another approved
>> statistical software system.
>>
>> Could someone suggest me a 'polite' answer?
>> TIA
>> Giovanni
>>
>> --
>> dr. Giovanni Parrinello
>> External Lecturer
>> Medical Statistics Unit
>> Department of Biomedical Sciences
>> Viale Europa, 11 - 25123 Brescia Italy
>> Tel: +390303717528
>> Fax: +390303717488
>> email: parrinel at med.unibs.it
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From deepayan.sarkar at gmail.com  Fri Jun  8 18:24:12 2007
From: deepayan.sarkar at gmail.com (deepayan.sarkar at gmail.com)
Date: Fri, 8 Jun 2007 11:24:12 -0500
Subject: [R] rlm results on trellis plot
In-Reply-To: <1181227630.6917.12.camel@gestalt.nimh.nih.gov>
References: <1181227630.6917.12.camel@gestalt.nimh.nih.gov>
Message-ID: <eb555e660706080924v6cfa2e29h2ed8c66bf42c291d@mail.gmail.com>

On 6/7/07, Alan S Barnett <asb at mail.nih.gov> wrote:
> How do I add to a trellis plot the best fit line from a robust fit? I
> can use panel.lm to add a least squares fit, but there is no panel.rlm
> function.

Well, panel.lmline (not panel.lm, BTW) is defined as:

> panel.lmline
function (x, y, ...)
{
    if (length(x) > 0)
        panel.abline(lm(as.numeric(y) ~ as.numeric(x)), ...)
}

So it's not much of a stretch to define

panel.rlmline <- function(x, y, ...)
    if (require(MASS) && length(x) > 0)
        panel.abline(rlm(as.numeric(y) ~ as.numeric(x)), ...)

The other replies have already shown you how you might use this in a call.

-Deepayan


From Sicotte.Hugues at mayo.edu  Fri Jun  8 18:37:32 2007
From: Sicotte.Hugues at mayo.edu (Sicotte, Hugues   Ph.D.)
Date: Fri, 8 Jun 2007 11:37:32 -0500
Subject: [R] "R is not a validated software package.."
In-Reply-To: <46697EF3.5000502@vanderbilt.edu>
References: <4669617F.8090405@med.unibs.it>	<1115a2b00706080723g153557b9k818b342f1ac0feb8@mail.gmail.com>
	<2E17292A64E6ED418A60BE89326B1AAB664473@msgebe11.mfad.mfroot.org>
	<46697EF3.5000502@vanderbilt.edu>
Message-ID: <2E17292A64E6ED418A60BE89326B1AAB664475@msgebe11.mfad.mfroot.org>

I may have overstated  things a bit.

See section VIII
http://www.fda.gov/CDER/GUIDANCE/2396dft.htm

If you are analyzing data your statistical package does not necessarely
have to be validated. You may have to show that the statistical methods
are adequate/appropriate or that the results are reproduced with
different softwares if you are using non-standard packages. By all
tests, S-plus appears acceptable, do not know about R.

However, If your statistical method is an intricate part of a test, then
you do have to validate the system.
This is becoming increasingly relevant for theragnostics.

.. Which is why I said
"Should they need to use those results in a report [where] that will
matter to the FDA.."
(I added the where .. It makes more sense)



-----Original Message-----
From: Frank E Harrell Jr [mailto:f.harrell at vanderbilt.edu] 
Sent: Friday, June 08, 2007 11:08 AM
To: Sicotte, Hugues Ph.D.
Cc: Wensui Liu; Giovanni Parrinello; r-help at stat.math.ethz.ch
Subject: Re: [R] "R is not a validated software package.."

Sicotte, Hugues Ph.D. wrote:
> People, don't get angry at the pharma statistician, he is just trying
to
> abide by an FDA requirement that is designed to insure that test
perform
> reliably the same. There is no point in getting into which product is
> better. As far as the FDA rules are concerned a validated system beats
a
> "better" system any day of the week.

There is no such requirement.

> 
> Here is your polite answer.
> You can develop and try your software in R.
> Should they need to use those results in a report that will matter to
> the FDA, then you can work together with him to set up a validated
> environment for S-plus. You then have to commit to port your code to
> S-plus.

That doesn't follow.  What matters is good statistical analysis practice

no matter which environment you use.  Note that more errors are made in 
the data preparation / derived variables stage than are made by 
statistical software.

Frank

> 
> As I assume that you do not work in a regulated environment, you
> probably wouldn't have access to a validated SAS environment anyways.
It
> is not usually enough to install a piece of software, you have to
> validate every step of the installation. Since AFAIK the FDA uses
> S-plus, it would be to your pharma person's advantage to speed-up
> submissions if they also had a validated S-plus environment.
> 
>
http://www.msmiami.com/custom/downloads/S-PLUSValidationdatasheet_Final.
> pdf
> 
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Wensui Liu
> Sent: Friday, June 08, 2007 9:24 AM
> To: Giovanni Parrinello
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] "R is not a validated software package.."
> 
> I like to know the answer as well.
> To be honest, I really have hard time to understand the mentality of
> clinical trial guys and rather believe it is something related to job
> security.
> 
> On 6/8/07, Giovanni Parrinello <parrinel at med.unibs.it> wrote:
>> Dear All,
>> discussing with a statistician of a pharmaceutical company I received
>> this answer about the statistical package that I have planned to use:
>>
>> As R is not a validated software package, we would like to ask if it
>> would rather be possible for you to use SAS, SPSS or another approved
>> statistical software system.
>>
>> Could someone suggest me a 'polite' answer?
>> TIA
>> Giovanni
>>
>> --
>> dr. Giovanni Parrinello
>> External Lecturer
>> Medical Statistics Unit
>> Department of Biomedical Sciences
>> Viale Europa, 11 - 25123 Brescia Italy
>> Tel: +390303717528
>> Fax: +390303717488
>> email: parrinel at med.unibs.it
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt
University


From matthias.vonrad at googlemail.com  Fri Jun  8 18:46:05 2007
From: matthias.vonrad at googlemail.com (Matthias von Rad)
Date: Fri, 8 Jun 2007 18:46:05 +0200
Subject: [R] compute new variable
Message-ID: <4A957ACF-EDF2-4355-A5E4-563EEC19107A@googlemail.com>

Hello,
maybe my question ist stupid, but I would like to calculate a new  
variable for all cases in my dataset. Inspired by the dialog in Rcmdr  
I tried
Datenmatrix$cohigha<- with(Datenmatrix,mean (c(M2ORG, M5ORG, M8ORG,  
M11ORG), na.rm = TRUE)
as output I got the same number for all my cases (possibly the  
overallmean of all cases), instead of a mean for each case.
Can you help me with this problem?
regards
Matthias


From Cody_Hamilton at Edwards.com  Fri Jun  8 18:53:20 2007
From: Cody_Hamilton at Edwards.com (Cody_Hamilton at Edwards.com)
Date: Fri, 8 Jun 2007 09:53:20 -0700
Subject: [R] "R is not a validated software package.."
In-Reply-To: <003301c7a9e6$b1778200$4d908980@gne.windows.gene.com>
Message-ID: <OF781A5C98.342D8040-ON882572F4.005CCDEC-882572F4.005C8E10@irvine.edwards.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070608/1139ecef/attachment.pl 

From ccleland at optonline.net  Fri Jun  8 18:56:02 2007
From: ccleland at optonline.net (Chuck Cleland)
Date: Fri, 08 Jun 2007 12:56:02 -0400
Subject: [R] compute new variable
In-Reply-To: <4A957ACF-EDF2-4355-A5E4-563EEC19107A@googlemail.com>
References: <4A957ACF-EDF2-4355-A5E4-563EEC19107A@googlemail.com>
Message-ID: <46698A22.1090207@optonline.net>

Matthias von Rad wrote:
> Hello,
> maybe my question ist stupid, but I would like to calculate a new  
> variable for all cases in my dataset. Inspired by the dialog in Rcmdr  
> I tried
> Datenmatrix$cohigha<- with(Datenmatrix,mean (c(M2ORG, M5ORG, M8ORG,  
> M11ORG), na.rm = TRUE)
> as output I got the same number for all my cases (possibly the  
> overallmean of all cases), instead of a mean for each case.
> Can you help me with this problem?

Datenmatrix$cohigha <- rowMeans(Datenmatrix[,c("M2ORG", "M5ORG",
"M8ORG", "M11ORG")], na.rm=TRUE)

> regards
> Matthias
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From liuwensui at gmail.com  Fri Jun  8 19:03:04 2007
From: liuwensui at gmail.com (Wensui Liu)
Date: Fri, 8 Jun 2007 13:03:04 -0400
Subject: [R] "R is not a validated software package.."
In-Reply-To: <003301c7a9e6$b1778200$4d908980@gne.windows.gene.com>
References: <46696B7D.10705@vanderbilt.edu>
	<003301c7a9e6$b1778200$4d908980@gne.windows.gene.com>
Message-ID: <1115a2b00706081003o2301371r938eb7c3c58bc6b@mail.gmail.com>

Bert,
I just want to make sure what I said is not overstated to offend
statistician who use SAS. actually, i am using SAS daily and able to
use it pretty well. ^_^
What I meant are:
1) I don't understand the mentality
2) using SAS instead of R might be related to job-security.
which is very different from "their mentality is related to job security".

On 6/8/07, Bert Gunter <gunter.berton at gene.com> wrote:
> Frank et. al:
>
> I believe this is a bit too facile. 21 CFR Part 11 does necessitate a
> software validation **process** -- but this process does not require any
> particular software. Rather, it requires that those using whatever software
> demonstrate to the FDA's satisfaction that the software does what it's
> supposed to do appropriately. This includes a lot more than assuring, say,
> the numerical accuracy of computations; I think it also requires
> demonstration that the data are "secure," that it is properly transferred
> from one source to another, etc. I assume that the statistical validation of
> R would be relatively simple, as R already has an extensive test suite, and
> it would simply be a matter of providing that test suite info. A bit more
> might be required, but I don't think it's such a big deal.
>
> I think Wensui Liu's characterization of clinical statisticians as having a
> mentality "related to job security" is a canard. Although I work in
> nonclinical, my observation is that clinical statistics is complex and
> difficult, not only because of many challenging statistical issues, but also
> because of the labyrinthian complexities of the regulated and extremely
> costly environment in which they work. It is certainly a job that I could
> not do.
>
> That said, probably the greatest obstacle to change from SAS is neither
> obstinacy nor ignorance, but rather inertia: pharmaceutical companies have
> over the decades made a huge investment in SAS infrastructure to support the
> collection, organization, analysis, and submission of data for clinical
> trials. To convert this to anything else would be a herculean task involving
> huge expense, risk, and resources. R, S-Plus (and much else -- e.g. numerous
> "unvalidated" data mining software packages) are routinely used by clinical
> statisticians to better understand their data and for "exploratory" analyses
> that are used to supplement official analyses (e.g. for trying to justify
> collection of tissue samples or a pivotal study in a patient subpopulation).
> But it is difficult for me to see how one could make a business case to
> change clinical trial analysis software infrastructure from SAS to S-Plus,
> SPSS, or anything else.
>
> **DISCLAINMER**
> My opinions only. They do not in any way represent the view of my company or
> its employees.
>
>
> Bert Gunter
> Genentech Nonclinical Statistics
> South San Francisco, CA 94404
> 650-467-7374
>
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Frank E Harrell Jr
> Sent: Friday, June 08, 2007 7:45 AM
> To: Giovanni Parrinello
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] "R is not a validated software package.."
>
> Giovanni Parrinello wrote:
> > Dear All,
> > discussing with a statistician of a pharmaceutical company I received
> > this answer about the statistical package that I have planned to use:
> >
> > As R is not a validated software package, we would like to ask if it
> > would rather be possible for you to use SAS, SPSS or another approved
> > statistical software system.
> >
> > Could someone suggest me a 'polite' answer?
> > TIA
> > Giovanni
> >
>
> Search the archives and you'll find a LOT of responses.
>
> Briefly, in my view there are no requirements, just some pharma
> companies that think there are.  FDA is required to accepted all
> submissions, and they get some where only Excel was used, or Minitab,
> and lots more.  There is a session on this at the upcoming R
> International Users Meeting in Iowa in August.  The session will include
> dicussions of federal regulation compliance for R, for those users who
> feel that such compliance is actually needed.
>
> Frank
>
> --
> Frank E Harrell Jr   Professor and Chair           School of Medicine
>                       Department of Biostatistics   Vanderbilt University
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
WenSui Liu
A lousy statistician who happens to know a little programming
(http://spaces.msn.com/statcompute/blog)


From f.harrell at vanderbilt.edu  Fri Jun  8 19:08:49 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Fri, 08 Jun 2007 12:08:49 -0500
Subject: [R] "R is not a validated software package.."
In-Reply-To: <003301c7a9e6$b1778200$4d908980@gne.windows.gene.com>
References: <003301c7a9e6$b1778200$4d908980@gne.windows.gene.com>
Message-ID: <46698D21.7050001@vanderbilt.edu>

Bert Gunter wrote:
> Frank et. al:
> 
> I believe this is a bit too facile. 21 CFR Part 11 does necessitate a
> software validation **process** -- but this process does not require any

For database software and for medical devices -

> particular software. Rather, it requires that those using whatever software
> demonstrate to the FDA's satisfaction that the software does what it's
> supposed to do appropriately. This includes a lot more than assuring, say,
> the numerical accuracy of computations; I think it also requires
> demonstration that the data are "secure," that it is properly transferred
> from one source to another, etc. I assume that the statistical validation of
> R would be relatively simple, as R already has an extensive test suite, and
> it would simply be a matter of providing that test suite info. A bit more
> might be required, but I don't think it's such a big deal. 
> 
> I think Wensui Liu's characterization of clinical statisticians as having a
> mentality "related to job security" is a canard. Although I work in
> nonclinical, my observation is that clinical statistics is complex and
> difficult, not only because of many challenging statistical issues, but also
> because of the labyrinthian complexities of the regulated and extremely
> costly environment in which they work. It is certainly a job that I could
> not do.
> 
> That said, probably the greatest obstacle to change from SAS is neither
> obstinacy nor ignorance, but rather inertia: pharmaceutical companies have
> over the decades made a huge investment in SAS infrastructure to support the
> collection, organization, analysis, and submission of data for clinical
> trials. To convert this to anything else would be a herculean task involving
> huge expense, risk, and resources. R, S-Plus (and much else -- e.g. numerous
> "unvalidated" data mining software packages) are routinely used by clinical
> statisticians to better understand their data and for "exploratory" analyses
> that are used to supplement official analyses (e.g. for trying to justify
> collection of tissue samples or a pivotal study in a patient subpopulation).
> But it is difficult for me to see how one could make a business case to
> change clinical trial analysis software infrastructure from SAS to S-Plus,
> SPSS, or anything else.

What I would love to have is some efficiency estimates for SAS macro 
programming as done in pharma vs. using a high-level language.  My bias 
is that SAS macro programming, which costs companies more than SAS 
licenses, is incredibly inefficient.

Frank

> 
> **DISCLAINMER** 
> My opinions only. They do not in any way represent the view of my company or
> its employees.
> 
> 
> Bert Gunter
> Genentech Nonclinical Statistics
> South San Francisco, CA 94404
> 650-467-7374
> 
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Frank E Harrell Jr
> Sent: Friday, June 08, 2007 7:45 AM
> To: Giovanni Parrinello
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] "R is not a validated software package.."
> 
> Giovanni Parrinello wrote:
>> Dear All,
>> discussing with a statistician of a pharmaceutical company I received 
>> this answer about the statistical package that I have planned to use:
>>
>> As R is not a validated software package, we would like to ask if it 
>> would rather be possible for you to use SAS, SPSS or another approved 
>> statistical software system.
>>
>> Could someone suggest me a 'polite' answer?
>> TIA
>> Giovanni
>>
> 
> Search the archives and you'll find a LOT of responses.
> 
> Briefly, in my view there are no requirements, just some pharma 
> companies that think there are.  FDA is required to accepted all 
> submissions, and they get some where only Excel was used, or Minitab, 
> and lots more.  There is a session on this at the upcoming R 
> International Users Meeting in Iowa in August.  The session will include 
> dicussions of federal regulation compliance for R, for those users who 
> feel that such compliance is actually needed.
> 
> Frank
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From ryestone at uvic.ca  Fri Jun  8 19:13:13 2007
From: ryestone at uvic.ca (ryestone)
Date: Fri, 8 Jun 2007 10:13:13 -0700 (PDT)
Subject: [R] ievent.wait
Message-ID: <11030568.post@talk.nabble.com>


I am working on a plot and would be like to click on a few points and then
have a line connect them. Could anyone help me with this or advise me in a
direction that would suit this. I know I would be using ievent.wait in iplot
but not sure about this.

thank you.
-- 
View this message in context: http://www.nabble.com/ievent.wait-tf3891095.html#a11030568
Sent from the R help mailing list archive at Nabble.com.


From chrishold at psyctc.org  Fri Jun  8 19:26:51 2007
From: chrishold at psyctc.org (Chris Evans)
Date: Fri, 08 Jun 2007 18:26:51 +0100
Subject: [R] Tools For Preparing Data For Analysis
In-Reply-To: <6BB2732B-E656-4A61-8D09-8C5D5EFC5AA4@MUOhio.edu>
References: <874da0b40706071701m55cd42fem15f55a8fcde04f17@mail.gmail.com>	<40e66e0b0706080547o5c630ac3ne5feadc4247e289a@mail.gmail.com>
	<6BB2732B-E656-4A61-8D09-8C5D5EFC5AA4@MUOhio.edu>
Message-ID: <4669915B.8050206@psyctc.org>


Martin Henry H. Stevens sent the following  at 08/06/2007 15:11:
> Is there an example available of this sort of problematic data that  
> requires this kind of data screening and filtering? For many of us,  
> this issue would be nice to learn about, and deal with within R. If a  
> package could be created, that would be optimal for some of us. I  
> would like to learn a tad more, if it were not too much effort for  
> someone else to point me in the right direction?
> Cheers,
> Hank
> On Jun 8, 2007, at 8:47 AM, Douglas Bates wrote:
> 
>> On 6/7/07, Robert Wilkins <irishhacker at gmail.com> wrote:
>>> As noted on the R-project web site itself ( www.r-project.org ->

... rest snipped ...

OK, I can't resist that invitation.  I think there are many kinds of
problematic data.  I handle some nasty textish things in perl (and I
loved the purgatory quote) and I'm afraid I do some things in Excel and
some cleaning I can handle in R, but I never enter data directly into R.

However, one very common scenario I have faceda all my working life is
psych data from questionnaires or interviews in low budget work, mostly
student research or routine entry of therapists' data.  Typically you
have an identifier, a date, some demographics and then a lot of item
data.  There's little money (usual zero) involved for data entry and
cleaning but I've produced a lot of good(ish) papers out of this sort of
very low budget work over the last 20 years.  (Right at the other end of
a financial spectrum from the FDA/validated s'ware thread but this is
about validation again!)

The problem I often face is that people are lousy data entry machines
(well, actually, they vary ... enormously) and if they mess up the data
entry we all know how horrible this can be.

SPSS (boo hiss) used to have an excellent "module", actually a
standalone PC/Windoze program, that allowed you to define variables so
they had allowed values and it would refuse to accept out of range or
out of acceptable entries, it also allowed you to create checking rules
and rules that would, in the light of earlier entries, set later values
and not ask about them.  In a rudimentary way you could also lay things
out on the screen so that it paginated where the q'aire or paper data
record did etc.  The final nice touch was that you could define some
variables as invariant and then set the thing so an independent data
entry person could re-enter the other data (i.e. pick up q'aire, see if
ID fits the one showing on screen, if so, enter the rest of the data).
It would bleep and not move on if you entered a value other than that
entered by the first person and you had to confirm that one of you was
right.

That saved me wasted weeks I'm sure on analysing data that turned out to
be awful and I'd love to see someone build something to replace that.

Currently I tend to use (boo hiss) Excel for this as everyone I work
with seems to have it (and not all can install open office and anyway I
haven't had time to learn that properly yet either ...) and I set up
spreadsheets with validation rules set.  That doesn't get the branching
rules and checks (e.g. if male, skip questions about periods, PMT and
pregnancies), or at least, with my poor Excel skills it doesn't.  I just
skip a column to indicate page breaks in the q'aire, and I get, when I
can, two people to enter the data separately and then use R to compare
the two spreadsheets having yanked them into data frames.

I would really, really love someone to develop (and perhaps replace) the
rather buggy edit() and fix() routines (seem to hang on big data frames
in Rcmdr which is what I'm trying to get students onto) with something
that did some or all of what SPSS/DE used to do for me or I bodge now in
Excel.  If any generous coding whiz were willing to do this, I'll try to
alpha and beta test and write help etc.

There _may_ be good open source things out there that do what I need but
something that really integrated into R would be another huge step
forward in being able to phase out SPSS in my work settings and phase in R.

Very best all,

Chris



-- 
Chris Evans <chris at psyctc.org> Skype: chris-psyctc
Professor of Psychotherapy, Nottingham University;
Consultant Psychiatrist in Psychotherapy, Notts PDD network;
Research Programmes Director, Nottinghamshire NHS Trust;
*If I am writing from one of those roles, it will be clear. Otherwise*
*my views are my own and not representative of those institutions    *


From carmei3 at web.de  Fri Jun  8 19:31:49 2007
From: carmei3 at web.de (Carmen Meier)
Date: Fri, 08 Jun 2007 19:31:49 +0200
Subject: [R] pnorm how to decide lower-tail true or false
Message-ID: <46699285.4040808@web.de>

Hi to all,
maybe the last question was not clear enough.
I did not found any hints how to decide whether it should use lower.tail 
or not.
As it is an extra R-feature ( written in 
http://finzi.psych.upenn.edu/R/Rhelp02a/archive/66250.html )
I do not find anything about it in any statistical books of me.
Regards Carmen


From mark_difford at yahoo.co.uk  Fri Jun  8 19:40:43 2007
From: mark_difford at yahoo.co.uk (Mark Difford)
Date: Fri, 8 Jun 2007 10:40:43 -0700 (PDT)
Subject: [R] pointwise confidence bands or interval values for a non
 parametric sm.regression
In-Reply-To: <93D4D0BA-4709-45CD-BCBF-2A2C58AB1B2B@cam.ac.uk>
References: <93D4D0BA-4709-45CD-BCBF-2A2C58AB1B2B@cam.ac.uk>
Message-ID: <11030924.post@talk.nabble.com>


Hi Martin,

Do please, at least, read the documentation for the package you are using!:

?sm.options               ## sub: display

## Example
with(iris, sm.regression(Sepal.Length, Sepal.Width, display="se"))

Regards,
Mark Difford.


M. P. Papadatos wrote:
> 
> Dear all,
> 
> Is there a way to plot / calculate pointwise confidence bands or  
> interval values for a non parametric regression like sm.regression?
> 
> Thank you in advance.
> 
> Regards,
> 
> Martin
> 
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/pointwise-confidence-bands-or-interval-values-for-a-non-parametric-sm.regression-tf3890206.html#a11030924
Sent from the R help mailing list archive at Nabble.com.


From sbihorel at buffalo.edu  Fri Jun  8 19:42:34 2007
From: sbihorel at buffalo.edu (=?ISO-8859-1?Q?S=E9bastien_Bihorel?=)
Date: Fri, 08 Jun 2007 13:42:34 -0400
Subject: [R] Batch processing in Windows
Message-ID: <4669950A.90001@buffalo.edu>

Hi,

I am a complete newbe to R, so the following problem will probably be 
trivial for most of you guys:  I get an error message every time I try 
to run a R file directly from the DOS shell.

My R file (test.R) is intended to create a basic graph and has a very 
simple code:

x<-rep(1:10,1)
y<-rep(1:10,1)
plot(x,y)

I am using the following command to call this file directly from the c:/ 
root:
C:/>R CMD BATCH e:/Documents Seb/3_/test.R

And here is the error message (Translated from french to english):
'R' is not recognized as an internal or external command, an executable 
script or a command file

My OS is a french Windows XP sp2 and I am using R version 2.5.0. I 
wonder if the problem comes from an installation problem...

Thank you in advance for your help.

Sebastien


From Dale_Steele at brown.EDU  Fri Jun  8 19:49:16 2007
From: Dale_Steele at brown.EDU (Dale Steele)
Date: Fri, 8 Jun 2007 13:49:16 -0400
Subject: [R] Tools For Preparing Data For Analysis
In-Reply-To: <4669915B.8050206@psyctc.org>
References: <874da0b40706071701m55cd42fem15f55a8fcde04f17@mail.gmail.com>
	<40e66e0b0706080547o5c630ac3ne5feadc4247e289a@mail.gmail.com>
	<6BB2732B-E656-4A61-8D09-8C5D5EFC5AA4@MUOhio.edu>
	<4669915B.8050206@psyctc.org>
Message-ID: <72e8303a0706081049v340e9e9fvb18dafef65da6a2a@mail.gmail.com>

For windows users, EpiData Entry <http://www.epidata.dk/> is an
excellent (free) tool for data entry and documentation.    --Dale


On 6/8/07, Chris Evans <chrishold at psyctc.org> wrote:
>
> Martin Henry H. Stevens sent the following  at 08/06/2007 15:11:
> > Is there an example available of this sort of problematic data that
> > requires this kind of data screening and filtering? For many of us,
> > this issue would be nice to learn about, and deal with within R. If a
> > package could be created, that would be optimal for some of us. I
> > would like to learn a tad more, if it were not too much effort for
> > someone else to point me in the right direction?
> > Cheers,
> > Hank
> > On Jun 8, 2007, at 8:47 AM, Douglas Bates wrote:
> >
> >> On 6/7/07, Robert Wilkins <irishhacker at gmail.com> wrote:
> >>> As noted on the R-project web site itself ( www.r-project.org ->
>
> ... rest snipped ...
>
> OK, I can't resist that invitation.  I think there are many kinds of
> problematic data.  I handle some nasty textish things in perl (and I
> loved the purgatory quote) and I'm afraid I do some things in Excel and
> some cleaning I can handle in R, but I never enter data directly into R.
>
> However, one very common scenario I have faceda all my working life is
> psych data from questionnaires or interviews in low budget work, mostly
> student research or routine entry of therapists' data.  Typically you
> have an identifier, a date, some demographics and then a lot of item
> data.  There's little money (usual zero) involved for data entry and
> cleaning but I've produced a lot of good(ish) papers out of this sort of
> very low budget work over the last 20 years.  (Right at the other end of
> a financial spectrum from the FDA/validated s'ware thread but this is
> about validation again!)
>
> The problem I often face is that people are lousy data entry machines
> (well, actually, they vary ... enormously) and if they mess up the data
> entry we all know how horrible this can be.
>
> SPSS (boo hiss) used to have an excellent "module", actually a
> standalone PC/Windoze program, that allowed you to define variables so
> they had allowed values and it would refuse to accept out of range or
> out of acceptable entries, it also allowed you to create checking rules
> and rules that would, in the light of earlier entries, set later values
> and not ask about them.  In a rudimentary way you could also lay things
> out on the screen so that it paginated where the q'aire or paper data
> record did etc.  The final nice touch was that you could define some
> variables as invariant and then set the thing so an independent data
> entry person could re-enter the other data (i.e. pick up q'aire, see if
> ID fits the one showing on screen, if so, enter the rest of the data).
> It would bleep and not move on if you entered a value other than that
> entered by the first person and you had to confirm that one of you was
> right.
>
> That saved me wasted weeks I'm sure on analysing data that turned out to
> be awful and I'd love to see someone build something to replace that.
>
> Currently I tend to use (boo hiss) Excel for this as everyone I work
> with seems to have it (and not all can install open office and anyway I
> haven't had time to learn that properly yet either ...) and I set up
> spreadsheets with validation rules set.  That doesn't get the branching
> rules and checks (e.g. if male, skip questions about periods, PMT and
> pregnancies), or at least, with my poor Excel skills it doesn't.  I just
> skip a column to indicate page breaks in the q'aire, and I get, when I
> can, two people to enter the data separately and then use R to compare
> the two spreadsheets having yanked them into data frames.
>
> I would really, really love someone to develop (and perhaps replace) the
> rather buggy edit() and fix() routines (seem to hang on big data frames
> in Rcmdr which is what I'm trying to get students onto) with something
> that did some or all of what SPSS/DE used to do for me or I bodge now in
> Excel.  If any generous coding whiz were willing to do this, I'll try to
> alpha and beta test and write help etc.
>
> There _may_ be good open source things out there that do what I need but
> something that really integrated into R would be another huge step
> forward in being able to phase out SPSS in my work settings and phase in R.
>
> Very best all,
>
> Chris
>
>
>
> --
> Chris Evans <chris at psyctc.org> Skype: chris-psyctc
> Professor of Psychotherapy, Nottingham University;
> Consultant Psychiatrist in Psychotherapy, Notts PDD network;
> Research Programmes Director, Nottinghamshire NHS Trust;
> *If I am writing from one of those roles, it will be clear. Otherwise*
> *my views are my own and not representative of those institutions    *
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ramasamy at cancer.org.uk  Fri Jun  8 19:49:59 2007
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Fri, 08 Jun 2007 18:49:59 +0100
Subject: [R] How to make a table of a desired dimension
In-Reply-To: <46696F71.6080407@udec.cl>
References: <46696F71.6080407@udec.cl>
Message-ID: <466996C7.8060702@cancer.org.uk>

You need to basically use table on factors with fixed pre-specified 
levels. For example:

  x <- c(runif(100,10,40), runif(100,43,55))
  y <- c(runif(100,7,35),  runif(100,37,50))
  z <- c(runif(100,10,42), runif(100,45,52))
  xx <- ceiling(x);  yy <- ceiling(y);  zz <- ceiling(z)


  mylevels <- min( c(xx, yy, zz) ) : max( c(xx, yy, zz) )

  out <- cbind( table( factor(xx, levels=mylevels) ),
                table( factor(yy, levels=mylevels) ),
                table( factor(zz, levels=mylevels) ) )

You could replace the last command with simply

  sapply( list(xx, yy, zz),
                function(vec) table( factor(vec, levels=mylevels) ) )

Regards, Adai



Rub?n Roa-Ureta wrote:
> Hi ComRades,
> 
> I want to make a matrix of frequencies from vectors of a continuous 
> variable spanning different values. For example this code
> x<-c(runif(100,10,40),runif(100,43,55))
> y<-c(runif(100,7,35),runif(100,37,50))
> z<-c(runif(100,10,42),runif(100,45,52))
> a<-table(ceiling(x))
> b<-table(ceiling(y))
> c<-table(ceiling(z))
> a
> b
> c
> 
> will give me three tables that start and end at different integer 
> values, and besides, they have 'holes' in between different integer 
> values. Is it possible to use 'table' to make these three tables have 
> the same dimensions, filling in the absent labels with zeroes? In the 
> example above, the desired tables should all start at 8 and tables 'a' 
> and 'c' should put a zero at labels '8' to '10', should all put zeros in 
> the frequencies of the labels corresponding to the holes, and should all 
> end at label '55'. The final purpose is the make a matrix and use 
> 'matplot' to plot all the frequencies in one plot, such as
> 
> #code valid only when 'a', 'b', and 'c' have the proper dimension
> p<-mat.or.vec(48,4)
> p[,1]<-8:55
> p[,2]<-c(matrix(a)[1:48])
> p[,3]<-c(matrix(b)[1:48])
> p[,4]<-c(matrix(c)[1:48])
> matplot(p)
> 
> I read the help about 'table' but I couldn't figure out if dnn, 
> deparse.level, or the other arguments could serve my purpose. Thanks for 
> your help
> Rub?n
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
>


From ggrothendieck at gmail.com  Fri Jun  8 19:51:17 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 8 Jun 2007 13:51:17 -0400
Subject: [R] Batch processing in Windows
In-Reply-To: <4669950A.90001@buffalo.edu>
References: <4669950A.90001@buffalo.edu>
Message-ID: <971536df0706081051k52ff0eafw58a9a42981685cfb@mail.gmail.com>

R isn't in your path.  Either change your path to include it or place
Rcmd.bat from batchfiles anywhere in your existing path:

   http://code.google.com/p/batchfiles/

and then:

   Rcmd BATCH ...whatever...


On 6/8/07, S?bastien Bihorel <sbihorel at buffalo.edu> wrote:
> Hi,
>
> I am a complete newbe to R, so the following problem will probably be
> trivial for most of you guys:  I get an error message every time I try
> to run a R file directly from the DOS shell.
>
> My R file (test.R) is intended to create a basic graph and has a very
> simple code:
>
> x<-rep(1:10,1)
> y<-rep(1:10,1)
> plot(x,y)
>
> I am using the following command to call this file directly from the c:/
> root:
> C:/>R CMD BATCH e:/Documents Seb/3_/test.R
>
> And here is the error message (Translated from french to english):
> 'R' is not recognized as an internal or external command, an executable
> script or a command file
>
> My OS is a french Windows XP sp2 and I am using R version 2.5.0. I
> wonder if the problem comes from an installation problem...
>
> Thank you in advance for your help.
>
> Sebastien
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ral at lcfltd.com  Fri Jun  8 19:54:56 2007
From: ral at lcfltd.com (Robert A LaBudde)
Date: Fri, 08 Jun 2007 13:54:56 -0400
Subject: [R] pnorm how to decide lower-tail true or false
In-Reply-To: <46699285.4040808@web.de>
References: <46699285.4040808@web.de>
Message-ID: <0JJB009GZWFOVC60@vms044.mailsrvcs.net>

At 01:31 PM 6/8/2007, Carmen wrote:
>Hi to all,
>maybe the last question was not clear enough.
>I did not found any hints how to decide whether it should use lower.tail
>or not.
>As it is an extra R-feature ( written in
>http://finzi.psych.upenn.edu/R/Rhelp02a/archive/66250.html )
>I do not find anything about it in any statistical books of me.
>Regards Carmen

pnorm(z, lower.tail=TRUE) (the R default) gives the probability of a 
normal variate being at or below z. This is the value commonly called 
the cumulative distribution function at the point z, or the integral 
from -Inf to z of the gaussian density.

pnorm(z, lower.tail=FALSE) gives the complement of the above, or 1 - 
cdf(z), and is the integral from z to Inf of the gaussian density.

E.g.,

 > pnorm(1.96, lower.tail=TRUE)
[1] 0.9750021
 > pnorm(1.96, lower.tail=FALSE)
[1] 0.02499790
 >

Use lower.tail=TRUE if you are, e.g., finding the probability at the 
lower tail of a confidence interval or if you want to the probability 
of values no larger than z.

Use lower.tail=FALSE if you are, e.g., trying to calculate test value 
significance or at the upper confidence limit, or you want the 
probability of values z or larger.

You should use pnorm(z, lower.tail=FALSE) instead of 1-pnorm(z) 
because the former returns a more accurate answer for large z.

This is really simple issue, and has no inherent complexity 
associated with it.
================================================================
Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
824 Timberlake Drive                     Tel: 757-467-0954
Virginia Beach, VA 23464-3239            Fax: 757-467-2947

"Vere scire est per causas scire"


From roger.bos at us.rothschild.com  Fri Jun  8 20:06:06 2007
From: roger.bos at us.rothschild.com (Bos, Roger)
Date: Fri, 8 Jun 2007 14:06:06 -0400
Subject: [R] Batch processing in Windows
In-Reply-To: <971536df0706081051k52ff0eafw58a9a42981685cfb@mail.gmail.com>
Message-ID: <D8C95B444AD6EE4AAD638D818A9CFD347CF9FF@RINNYCSE000.rth.ad.rothschild.com>

Alternatively, use the full path in your call to R as I do below:

"F:\Program Files\R\R-2.4.1pat\bin\R.exe" CMD BATCH --vanilla --slave whatever.R

HTH,

Roger

 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Gabor Grothendieck
Sent: Friday, June 08, 2007 1:51 PM
To: S?bastien Bihorel
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Batch processing in Windows

R isn't in your path.  Either change your path to include it or place Rcmd.bat from batchfiles anywhere in your existing path:

   http://code.google.com/p/batchfiles/

and then:

   Rcmd BATCH ...whatever...


On 6/8/07, S?bastien Bihorel <sbihorel at buffalo.edu> wrote:
> Hi,
>
> I am a complete newbe to R, so the following problem will probably be 
> trivial for most of you guys:  I get an error message every time I try 
> to run a R file directly from the DOS shell.
>
> My R file (test.R) is intended to create a basic graph and has a very 
> simple code:
>
> x<-rep(1:10,1)
> y<-rep(1:10,1)
> plot(x,y)
>
> I am using the following command to call this file directly from the 
> c:/
> root:
> C:/>R CMD BATCH e:/Documents Seb/3_/test.R
>
> And here is the error message (Translated from french to english):
> 'R' is not recognized as an internal or external command, an 
> executable script or a command file
>
> My OS is a french Windows XP sp2 and I am using R version 2.5.0. I 
> wonder if the problem comes from an installation problem...
>
> Thank you in advance for your help.
>
> Sebastien
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

********************************************************************** * 
This message is for the named person's use only. It may 
contain confidential, proprietary or legally privileged 
information. No right to confidential or privileged treatment 
of this message is waived or lost by any error in 
transmission. If you have received this message in error, 
please immediately notify the sender by e-mail, 
delete the message and all copies from your system and destroy 
any hard copies. You must not, directly or indirectly, use, 
disclose, distribute, print or copy any part of this message 
if you are not the intended recipient.


From ral at lcfltd.com  Fri Jun  8 20:18:34 2007
From: ral at lcfltd.com (Robert A. LaBudde)
Date: Fri, 08 Jun 2007 14:18:34 -0400
Subject: [R] glm() for log link and Weibull family
Message-ID: <0JJB003RCXJ3FCI0@vms042.mailsrvcs.net>

I need to be able to run a generalized linear model with a log() link 
and a Weibull family, or something similar to deal with an extreme 
value distribution.

I actually have a large dataset where this is apparently necessary. 
It has to do with recovery of forensic samples from surfaces, where 
as much powder as possible is collected. This apparently causes the 
results to conform to some type of extreme value distribution, so 
Weibull is a reasonable starting point for exploration.

I have tried ('surface' and 'team' are factors)

glm(surfcount ~ surface*team, data=powderd, family=Gamma(link='log'))

but this doesn't quite do the trick. The standardized deviance 
residuals are still curved away from normal at the tails.

Thanks for any info you can give on this nonstandard model.
================================================================
Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
824 Timberlake Drive                     Tel: 757-467-0954
Virginia Beach, VA 23464-3239            Fax: 757-467-2947

"Vere scire est per causas scire"


From murdoch at stats.uwo.ca  Fri Jun  8 20:38:49 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 08 Jun 2007 14:38:49 -0400
Subject: [R] evaluating variables in the context of a data frame
In-Reply-To: <eb97335b0706080833r2febdedej7bbf27d330da3787@mail.gmail.com>
References: <eb97335b0706072201r9ad1ba1s37bc66611d76fb68@mail.gmail.com>	<Pine.LNX.4.64.0706080657290.22532@gannet.stats.ox.ac.uk>
	<eb97335b0706080833r2febdedej7bbf27d330da3787@mail.gmail.com>
Message-ID: <4669A239.9050901@stats.uwo.ca>

On 6/8/2007 11:33 AM, Zack Weinberg wrote:
> On 6/7/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>> >> f <- function(x, dat) evalq(x, dat)
>> >> f(o, D)
>> > Error in eval(expr, envir, enclos) : object "o" not found
>> >> g <- function(x, dat) eval(x, dat)
>> >> g(o, D)
>> > Error in eval(x, dat) : object "o" not found
>> >
>> > What am I doing wrong?  This seems to be what the helpfiles say you do
>> > to evaluate arguments in the context of a passed-in data frame...
>>
>> When you call f(o, D), the argument 'o' is evaluated in the current
>> environment ('context' in R means something different).  Because of lazy
>> evaluation, it is not evaluated until evalq is called, but it evaluated as
>> if it was evaluated greedily.
>>
>> g(quote(o), D) will work.
> 
> Thanks.
> 
> After a bit more experimentation I figured out that this does what I want:
> 
>> h <- function(x, d) eval(substitute(x), d, parent.frame())
> 
> but I don't understand why the substitute() helps, or indeed why it
> has any effect at all...

Within the evaluation frame of h, x is a promise to evaluate an 
expression.  substitute(x) extracts the expression.  If you just use x, 
it gets evaluated in the frame from which h was called, rather than in a 
frame created from d.

Duncan Murdoch


From zackw at panix.com  Fri Jun  8 20:41:24 2007
From: zackw at panix.com (Zack Weinberg)
Date: Fri, 8 Jun 2007 11:41:24 -0700
Subject: [R] wrapping lattice xyplot
Message-ID: <eb97335b0706081141nb2f3e1ta9e7348e2d111f92@mail.gmail.com>

This is an expanded version of the question I tried to ask last night
- I thought I had it this morning, but it's still not working and I
just do not understand what is going wrong.

What I am trying to do is write a wrapper for lattice xyplot() that
passes a whole bunch of its secondary arguments, so that I can produce
similarly formatted graphs for several different data sets.  This is
what I've got:

graph <- function (x, data, groups, xlab) {
  g <- eval(substitute(groups), data, parent.frame())

  pg <- function(x, y, group.number, ...) {
    panel.xyplot(x, y, ..., group.number=group.number)
    panel.text(2, unique(y[x==2]),
               levels(g)[group.number],
               pos=4, cex=0.5)
  }

  xyplot(x, data=data, groups=substitute(g),
              type='l',
              ylab=list(cex=1.1, label='Mean RT (ms)'),
              xlab=list(cex=1.1, label=xlab),
              scales=list(
                x=list(alternating=c(1,1), tck=c(1,0)),
                y=list(alternating=c(1,0))
                ),
              panel=panel.superpose,
              panel.groups=pg
              )
}

"pg" is supposed to pick "g" up from the lexical enclosure. I have no
idea whether that actually works, because it never gets that far.  A
typical call to this function looks like so:

> graph(est ~ pro | hemi, sm, obs, "Probe type")

(where 'sm' is a data frame that really does contain all four columns
'est', 'pro', 'hemi', and 'obs', pinky swear) and, as it stands above,
invariably gives me this error:

Error in eval(expr, envir, enclos) : object "est" not found

I tried substitute(x) (as that seems to have cured a similar problem
with "g") but then x is not a formula and method dispatch fails.

Help?
zw


From Cody_Hamilton at Edwards.com  Fri Jun  8 20:41:58 2007
From: Cody_Hamilton at Edwards.com (Cody_Hamilton at Edwards.com)
Date: Fri, 8 Jun 2007 11:41:58 -0700
Subject: [R] "R is not a validated software package.."
Message-ID: <OF9CFD29A7.DD66C76A-ON882572F4.0066CCE2-882572F4.00668064@irvine.edwards.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070608/b70c75ac/attachment.pl 

From zackw at panix.com  Fri Jun  8 20:45:18 2007
From: zackw at panix.com (Zack Weinberg)
Date: Fri, 8 Jun 2007 11:45:18 -0700
Subject: [R] evaluating variables in the context of a data frame
In-Reply-To: <4669A239.9050901@stats.uwo.ca>
References: <eb97335b0706072201r9ad1ba1s37bc66611d76fb68@mail.gmail.com>
	<Pine.LNX.4.64.0706080657290.22532@gannet.stats.ox.ac.uk>
	<eb97335b0706080833r2febdedej7bbf27d330da3787@mail.gmail.com>
	<4669A239.9050901@stats.uwo.ca>
Message-ID: <eb97335b0706081145l3a5b17fch187ce14ec5618212@mail.gmail.com>

On 6/8/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> > After a bit more experimentation I figured out that this does what I want:
> >
> >> h <- function(x, d) eval(substitute(x), d, parent.frame())
> >
> > but I don't understand why the substitute() helps, or indeed why it
> > has any effect at all...
>
> Within the evaluation frame of h, x is a promise to evaluate an
> expression.  substitute(x) extracts the expression.  If you just use x,
> it gets evaluated in the frame from which h was called, rather than in a
> frame created from d.

Thanks, that's helpful.  Could you comment on substitute() use in the
message I just posted which contains the actual code I'm trying to get
to work?  In addition to the question asked there, after your
explanation I still do not understand why

  g <- ...
  xyplot ( ..., groups=g, ... )

should refuse to find g, and the same thing with groups=substitute(g)
works (well, gets farther before blowing up).

zw


From zackw at panix.com  Fri Jun  8 20:45:18 2007
From: zackw at panix.com (Zack Weinberg)
Date: Fri, 8 Jun 2007 11:45:18 -0700
Subject: [R] evaluating variables in the context of a data frame
In-Reply-To: <4669A239.9050901@stats.uwo.ca>
References: <eb97335b0706072201r9ad1ba1s37bc66611d76fb68@mail.gmail.com>
	<Pine.LNX.4.64.0706080657290.22532@gannet.stats.ox.ac.uk>
	<eb97335b0706080833r2febdedej7bbf27d330da3787@mail.gmail.com>
	<4669A239.9050901@stats.uwo.ca>
Message-ID: <eb97335b0706081145l3a5b17fch187ce14ec5618212@mail.gmail.com>

On 6/8/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> > After a bit more experimentation I figured out that this does what I want:
> >
> >> h <- function(x, d) eval(substitute(x), d, parent.frame())
> >
> > but I don't understand why the substitute() helps, or indeed why it
> > has any effect at all...
>
> Within the evaluation frame of h, x is a promise to evaluate an
> expression.  substitute(x) extracts the expression.  If you just use x,
> it gets evaluated in the frame from which h was called, rather than in a
> frame created from d.

Thanks, that's helpful.  Could you comment on substitute() use in the
message I just posted which contains the actual code I'm trying to get
to work?  In addition to the question asked there, after your
explanation I still do not understand why

  g <- ...
  xyplot ( ..., groups=g, ... )

should refuse to find g, and the same thing with groups=substitute(g)
works (well, gets farther before blowing up).

zw


From stevenmh at muohio.edu  Fri Jun  8 20:52:22 2007
From: stevenmh at muohio.edu (stevenmh at muohio.edu)
Date: Fri, 8 Jun 2007 14:52:22 -0400 (EDT)
Subject: [R] open .r files with double-click
Message-ID: <26142.134.53.7.120.1181328742.squirrel@134.53.7.120>

Hi Folks,
On Windows XP, R 2.5.0.

After reading the Installation for Windows and Windows FAQs,
I cannot resolve this.

I set file types so that Rgui.exe will open .r files.

When I try to open a .r file by double-clicking, R begins to launch,
but I get an error message saying

"Argument 'C:\Documents and Settings\Zoology\My Documents\trial.r' _ignored_"

I click OK, and then R GUI opens, but not the script file.

Is there a way to change this?

thanks,
Hank


From pwang at berkeley.edu  Fri Jun  8 20:54:12 2007
From: pwang at berkeley.edu (Patrick Wang)
Date: Fri, 8 Jun 2007 11:54:12 -0700 (PDT)
Subject: [R] how to find how many modes in 2 dimensions case
Message-ID: <58576.128.97.55.42.1181328852.squirrel@calmail.berkeley.edu>

Hi,

Does anyone know how to count the number of modes in 2 dimensions using
kde2d function?

Thanks
Pat


From ripley at stats.ox.ac.uk  Fri Jun  8 21:04:15 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 8 Jun 2007 20:04:15 +0100 (BST)
Subject: [R] glm() for log link and Weibull family
In-Reply-To: <0JJB003RCXJ3FCI0@vms042.mailsrvcs.net>
References: <0JJB003RCXJ3FCI0@vms042.mailsrvcs.net>
Message-ID: <Pine.LNX.4.64.0706082001120.9861@gannet.stats.ox.ac.uk>

On Fri, 8 Jun 2007, Robert A. LaBudde wrote:

> I need to be able to run a generalized linear model with a log() link
> and a Weibull family, or something similar to deal with an extreme
> value distribution.

The Weibull with log link is not a GLM, but survreg() in package survival
can fit it, as well as other extreme-value distributions.

> I actually have a large dataset where this is apparently necessary.
> It has to do with recovery of forensic samples from surfaces, where
> as much powder as possible is collected. This apparently causes the
> results to conform to some type of extreme value distribution, so
> Weibull is a reasonable starting point for exploration.
>
> I have tried ('surface' and 'team' are factors)
>
> glm(surfcount ~ surface*team, data=powderd, family=Gamma(link='log'))
>
> but this doesn't quite do the trick. The standardized deviance
> residuals are still curved away from normal at the tails.
>
> Thanks for any info you can give on this nonstandard model.

It's perfectly standard, just not a GLM.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From marc_schwartz at comcast.net  Fri Jun  8 21:11:48 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Fri, 08 Jun 2007 14:11:48 -0500
Subject: [R] "R is not a validated software package.."
In-Reply-To: <4669617F.8090405@med.unibs.it>
References: <4669617F.8090405@med.unibs.it>
Message-ID: <1181329908.5181.95.camel@Bellerophon>

On Fri, 2007-06-08 at 16:02 +0200, Giovanni Parrinello wrote:
> Dear All,
> discussing with a statistician of a pharmaceutical company I received 
> this answer about the statistical package that I have planned to use:
> 
> As R is not a validated software package, we would like to ask if it 
> would rather be possible for you to use SAS, SPSS or another approved 
> statistical software system.
> 
> Could someone suggest me a 'polite' answer?
> TIA
> Giovanni
> 

The polite answer is that there is no such thing as 'FDA approved'
software for conducting clinical trials. The FDA does not approve,
validate or otherwise endorse software.

If the pharma company in question has developed their own list of
acceptable software applications that you must comply with, that is
different, but is independent of any FDA requirements.

As the saying used to be several decades ago, "Nobody ever got fired for
buying IBM".  In the clinical trials realm today, the same could be said
for SAS or Oracle Clinical. 

That is a political, and perhaps a corporate legal counsel driven "risk
aversion" based issue, not a scientific one.  It is also a human
behavioral issue, as Bert noted, relative to fighting inertia, training
or re-training issues and the pre-existing investment in internal
processes and infrastructure.  This will change over time as more
statisticians, who have been trained in the use of R during their
academic years, enter into industry positions.

As others have noted, there is a PERCEPTION that somehow SAS is endorsed
by the FDA or that it constitutes a 'gold standard' of sorts. This is a
perception and not reality.

That being said:

There are a variety of relevant Guidance and Guideline documents that
the FDA has put forth to address these issues. Most recently, the FDA
approved final guidance for the use of computerized systems in clinical
investigations (May 2007):

http://www.fda.gov/OHRMS/DOCKETS/98fr/04d-0440-gdl0002.pdf

In addition, there is a General Principles of Software Validation
document:

http://www.fda.gov/cdrh/comp/guidance/938.html

The majority of the 21 CFR Part 11 requirements (audit trails,
electronic signatures, etc.) are relevant to systems that manage "source
medical records". These would typically be database applications and
medical devices, not statistical applications. In our shop for example,
our Oracle 10g server has been implemented in accordance with these
requirements.

There is a 21 CFR Part 11 guidance document here:

http://www.fda.gov/ohrms/dockets/98fr/5667fnl.pdf

There are also all of the so-called FDA and ICH GxP (Good x Practice)
documents:

   http://www.fda.gov/oc/gcp/guidance.html
   http://www.ich.org/cache/compo/475-272-1.html

that provide a framework for operations in a regulated environment and
for relevant statistical practice guidance. The 'x' above is replaced by
words such as "Clinical", "Manufacturing", "Laboratory", etc.

There is even a draft guidance document on the use of Bayesian
techniques for medical device trials:

http://www.fda.gov/cdrh/osb/guidance/1601.html


Some of the references in other posts have to do with software embedded
in medical devices, which could be anything such as bedside ECG
monitoring stations, diagnostic imaging systems, radiation therapy
instrumentation and pacemakers. These are generally not relevant to this
discussion.

The bottom line, is that while there is a burden on the part of the
'software publisher' to utilize and document reasonable manufacturing,
version control, software maintenance and quality processes, the
overwhelming burden is on the END USER to determine that their
statistical package is suitable for the application intended and to have
written SOPs (Standard Operating Procedures) to define how they will
validate their installation and use of the statistical software. 

This goes to some of the comments that Cody had relative to IQ/OQ/PQ
documentation, which refers to Installation Qualification, Operational
Qualification and Performance Qualification.

For example, in the context of R, the use of "make check-all" and the
retention of the output subsequent to compiling R from source code can
be part of that documentation process. Bert referred to this in his
comments.

Beyond that, the details of such documentation will be driven by a
variety of characteristics that are relevant to the nature of the
environment (academic, commercial, clinical, pre-clinical, etc.) in
which one is operating and related considerations.

As Frank noted, there will be a session at useR!2007:

  http://user2007.org/

entitled "The Use of R in Clinical Trials and Industry-Sponsored Medical
Research".  This session will take place on Friday, August 10 and I
would invite any interested parties to attend the meetings. I think that
you will find the subject matter quite enlightening.

One closing comment:  There is increasing use of R within the FDA itself
and this will only further help to assuage the fears of prospective
users over time.

Best regards,

Marc Schwartz


From zackw at panix.com  Fri Jun  8 21:12:31 2007
From: zackw at panix.com (Zack Weinberg)
Date: Fri, 8 Jun 2007 12:12:31 -0700
Subject: [R] still trying to wrap xyplot - ignore previous
Message-ID: <eb97335b0706081212r7bc5843fv152e1f8147efb78c@mail.gmail.com>

As you may not be surprised to hear, no sooner did I post the previous
message than I realized I had a really dumb mistake.  I've now gotten
a bit farther but am still stuck.  New code:

graph <- function (x, data, groups, xlab) {
  pg <- function(x, y, group.number, ...) fnord
  body(pg) <- substitute({
    panel.xyplot(x, y, ..., group.number=group.number)
    panel.text(2, unique(y[x==2]),
               levels(G)[group.number],
               pos=4, cex=0.5)
  }, list(G=eval(substitute(groups), data, parent.frame())))

  print(xyplot(x, data=data, groups=substitute(groups),
               type='l',
               ylab=list(cex=1.1, label='Mean RT (ms)'),
               xlab=list(cex=1.1, label=xlab),
               scales=list(
                 x=list(alternating=c(1,1), tck=c(1,0)),
                 y=list(alternating=c(1,0))
                 ),
               panel=panel.superpose,
               panel.groups=pg
              ))
}

Questions:
1) The "groups=substitute(groups)" bit (in the call to xyplot) still
doesn't work.  As far as I can tell, xyplot wants the *symbol* which
is the name of the factor (in the data frame) to group by.
The above seems to wind up passing it the symbol "groups", which
causes the prepanel function to barf.  I have not been able to find
any way to evaluate one layer of "groups" to get me the symbol passed
in, rather than the value of that symbol.  Am I right?  How do I give
it what it wants?

2) Why do I have to do that stupid dance with replacing the body of
pg?  The documentation leads me to believe this is a lexically scoped
language, shouldn't it be able to pick G out of the enclosing frame?

zw


From f.harrell at vanderbilt.edu  Fri Jun  8 21:20:02 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Fri, 08 Jun 2007 14:20:02 -0500
Subject: [R] Tools For Preparing Data For Analysis
In-Reply-To: <72e8303a0706081049v340e9e9fvb18dafef65da6a2a@mail.gmail.com>
References: <874da0b40706071701m55cd42fem15f55a8fcde04f17@mail.gmail.com>	<40e66e0b0706080547o5c630ac3ne5feadc4247e289a@mail.gmail.com>	<6BB2732B-E656-4A61-8D09-8C5D5EFC5AA4@MUOhio.edu>	<4669915B.8050206@psyctc.org>
	<72e8303a0706081049v340e9e9fvb18dafef65da6a2a@mail.gmail.com>
Message-ID: <4669ABE2.8000407@vanderbilt.edu>

Dale Steele wrote:
> For windows users, EpiData Entry <http://www.epidata.dk/> is an
> excellent (free) tool for data entry and documentation.    --Dale

Note that EpiData seems to work well under linux using wine.
Frank


From Cody_Hamilton at Edwards.com  Fri Jun  8 21:28:28 2007
From: Cody_Hamilton at Edwards.com (Cody_Hamilton at Edwards.com)
Date: Fri, 8 Jun 2007 12:28:28 -0700
Subject: [R] "R is not a validated software package.."
Message-ID: <OF33143428.907241C3-ON882572F4.006A9056-882572F4.006AC245@irvine.edwards.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070608/de7f8036/attachment.pl 

From gunter.berton at gene.com  Fri Jun  8 21:30:24 2007
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 8 Jun 2007 12:30:24 -0700
Subject: [R] how to find how many modes in 2 dimensions case
In-Reply-To: <58576.128.97.55.42.1181328852.squirrel@calmail.berkeley.edu>
Message-ID: <002701c7aa03$766d0af0$4d908980@gne.windows.gene.com>

Note that "the number of modes" (local maxima??)  is a function of the
bandwidth, so I'm not sure your question is even meaningful. 

Bert Gunter
Genentech Nonclinical Statistics
South San Francisco, CA 94404
650-467-7374

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Patrick Wang
Sent: Friday, June 08, 2007 11:54 AM
To: R-help at stat.math.ethz.ch
Subject: [R] how to find how many modes in 2 dimensions case

Hi,

Does anyone know how to count the number of modes in 2 dimensions using
kde2d function?

Thanks
Pat

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From pwang at berkeley.edu  Fri Jun  8 21:34:47 2007
From: pwang at berkeley.edu (Patrick Wang)
Date: Fri, 8 Jun 2007 12:34:47 -0700 (PDT)
Subject: [R] how to find how many modes in 2 dimensions case
In-Reply-To: <002701c7aa03$766d0af0$4d908980@gne.windows.gene.com>
References: <002701c7aa03$766d0af0$4d908980@gne.windows.gene.com>
Message-ID: <49425.128.97.244.86.1181331287.squirrel@calmail.berkeley.edu>

Thanks for the reply,

maybe I shall say bumps, I can use persp to show a density on a X Y
dimensions.
one peak is one mode I think. I try to find an automatic way to detect how
many peaks of the densities.

Pat
> Note that "the number of modes" (local maxima??)  is a function of the
> bandwidth, so I'm not sure your question is even meaningful.
>
> Bert Gunter
> Genentech Nonclinical Statistics
> South San Francisco, CA 94404
> 650-467-7374
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Patrick Wang
> Sent: Friday, June 08, 2007 11:54 AM
> To: R-help at stat.math.ethz.ch
> Subject: [R] how to find how many modes in 2 dimensions case
>
> Hi,
>
> Does anyone know how to count the number of modes in 2 dimensions using
> kde2d function?
>
> Thanks
> Pat
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


From jasoncbarnhart at msn.com  Fri Jun  8 21:47:20 2007
From: jasoncbarnhart at msn.com (Jason Barnhart)
Date: Fri, 8 Jun 2007 12:47:20 -0700
Subject: [R] character to time problem
References: <990.61035.qm@web32809.mail.mud.yahoo.com>
Message-ID: <BAY116-DAV11E90F83D6AB5109C03646CF250@phx.gbl>

na.last belongs to order().

?order shows
    "na.last for controlling the treatment of NAs. If TRUE,
    missing values in the data are put last; if FALSE, they are
    put first; if NA, they are removed."

----- Original Message ----- 
From: "John Kane" <jrkrideau at yahoo.ca>
To: "Jason Barnhart" <jasoncbarnhart at msn.com>; "R R-help" 
<r-help at stat.math.ethz.ch>
Sent: Friday, June 08, 2007 7:35 AM
Subject: Re: [R] character to time problem


>
> --- Jason Barnhart <jasoncbarnhart at msn.com> wrote:
>
>> Hi John,
>>
>> a) The NA appears because '30/02/1995' is not a
>> valid date.
>>
>>     > strptime('30/02/1995' , "%d/%m/%Y")
>>     [1] NA
>>
>
> I knew we should never have moved to the Gregorian
> Calender!
>
> Thanks.  I accidently made up the date but this means
> that I have some invalid dates in the file. Not a
> problem now I know what's happening. And our contract
> says someone else gets to fix them :)
>
>> b) dates which has the following classes uses
>> sort.POSIXlt which in
>> turns sets na.last to NA.  ?order details how NA's
>> are handled in
>> ordering data via na.last.
>>
>>     > class(dates)
>>     [1] "POSIXt"  "POSIXlt"
>>
>>     > methods(sort)
>>     [1] sort.default sort.POSIXlt
>>
>>     > sort.POSIXlt
>>     function (x, decreasing = FALSE, na.last = NA,
>> ...)
>>     x[order(as.POSIXct(x), na.last = na.last,
>> decreasing =
>> decreasing)]
>>     <environment: namespace:base>
>>
>> After resetting the Feb. date the code works.
>>
>> HTH,
>> -jason
>>
>
> So it does.
>
> I had not thought to look at the sort.POSIXlt
> function.  I don't quite understand what na.last is
> doing and don't seem to see the documentation.  Is it
> sorting the NA's to the last place(s) in the vector
> and then dropping them?
>
> Thanks again
>
>> ----- Original Message ----- 
>> From: "John Kane" <jrkrideau at yahoo.ca>
>> To: "R R-help" <r-help at stat.math.ethz.ch>
>> Sent: Thursday, June 07, 2007 2:17 PM
>> Subject: [R] character to time problem
>>
>>
>> >I am trying to clean up some dates and I am clearly
>> > doing something wrong.  I have laid out an example
>> > that seems to show what is happening with the
>> "real"
>> > data.  The  coding is lousy but it looks like it
>> > should have worked.
>> >
>> > Can anyone suggest a) why I am getting that NA
>> > appearing after the strptime() command and b) why
>> the
>> > NA is disappearing in the sort()? It happens with
>> > na.rm=TRUE  and na.rm=FALSE
>> > -------------------------------------------------
>> > aa  <- data.frame( c("12/05/2001", " ",
>> "30/02/1995",
>> > NA, "14/02/2007", "M" ) )
>> > names(aa)  <- "times"
>> > aa[is.na(aa)] <- "M"
>> > aa[aa==" "]  <- "M"
>> > bb <- unlist(subset(aa, aa[,1] !="M"))
>> > dates <- strptime(bb, "%d/%m/%Y")
>> > dates
>> > sort(dates)
>> > --------------------------------------------------
>> >
>> > Session Info
>> > R version 2.4.1 (2006-12-18)
>> > i386-pc-mingw32
>> >
>> > locale:
>> > LC_COLLATE=English_Canada.1252;
>> > LC_CTYPE=English_Canada.1252;
>> > LC_MONETARY=English_Canada.1252;
>> > LC_NUMERIC=C;LC_TIME=English_Canada.1252
>> >
>> > attached base packages:
>> > [1] "stats"     "graphics"  "grDevices" "utils"
>> > "datasets"  "methods"   "base"
>> >
>> > other attached packages:
>> >  gdata   Hmisc
>> > "2.3.1" "3.3-2"
>> >
>> > (Yes I know I'm out of date but I don't like
>> > upgrading just as I am finishing a project)
>> >
>> > Thanks
>> >
>> > ______________________________________________
>> > R-help at stat.math.ethz.ch mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained,
>> reproducible code.
>> >
>>
>>
>
>
>
>      Ask a question on any topic and get answers from real people. 
> Go to Yahoo! Answers and share what you know at 
> http://ca.answers.yahoo.com
>


From ggrothendieck at gmail.com  Fri Jun  8 21:57:57 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 8 Jun 2007 15:57:57 -0400
Subject: [R] wrapping lattice xyplot
In-Reply-To: <eb97335b0706081141nb2f3e1ta9e7348e2d111f92@mail.gmail.com>
References: <eb97335b0706081141nb2f3e1ta9e7348e2d111f92@mail.gmail.com>
Message-ID: <971536df0706081257p61a30440vce7a1f7c84295002@mail.gmail.com>

I am not entirely happy with this solution but it does seem to work.
In pg we pick groups out of its parent.frame and we place the
entire body of graph2 in eval.parent(substitute(...))

pg <- function(x, y, subscripts, ..., group.number) {
   panel.xyplot(x, y, ...)
   panel.text(2, unique(y[x==2]),
              levels(parent.frame()$groups)[group.number],
              pos=4, cex=0.5)
 }

graph2 <- function (x, data, groups, xlab)
 eval.parent(substitute({
 xyplot(x, data=data, groups=groups,
             type='l',
             ylab=list(cex=1.1, label='Mean RT (ms)'),
             xlab=list(cex=1.1, label=xlab),
             scales=list(
               x=list(alternating=c(1,1), tck=c(1,0)),
               y=list(alternating=c(1,0))
               ),
             panel=panel.superpose,
             panel.groups=pg)
}))
graph2(uptake ~ conc, CO2, Treatment, "X")


On 6/8/07, Zack Weinberg <zackw at panix.com> wrote:
> This is an expanded version of the question I tried to ask last night
> - I thought I had it this morning, but it's still not working and I
> just do not understand what is going wrong.
>
> What I am trying to do is write a wrapper for lattice xyplot() that
> passes a whole bunch of its secondary arguments, so that I can produce
> similarly formatted graphs for several different data sets.  This is
> what I've got:
>
> graph <- function (x, data, groups, xlab) {
>  g <- eval(substitute(groups), data, parent.frame())
>
>  pg <- function(x, y, group.number, ...) {
>    panel.xyplot(x, y, ..., group.number=group.number)
>    panel.text(2, unique(y[x==2]),
>               levels(g)[group.number],
>               pos=4, cex=0.5)
>  }
>
>  xyplot(x, data=data, groups=substitute(g),
>              type='l',
>              ylab=list(cex=1.1, label='Mean RT (ms)'),
>              xlab=list(cex=1.1, label=xlab),
>              scales=list(
>                x=list(alternating=c(1,1), tck=c(1,0)),
>                y=list(alternating=c(1,0))
>                ),
>              panel=panel.superpose,
>              panel.groups=pg
>              )
> }
>
> "pg" is supposed to pick "g" up from the lexical enclosure. I have no
> idea whether that actually works, because it never gets that far.  A
> typical call to this function looks like so:
>
> > graph(est ~ pro | hemi, sm, obs, "Probe type")
>
> (where 'sm' is a data frame that really does contain all four columns
> 'est', 'pro', 'hemi', and 'obs', pinky swear) and, as it stands above,
> invariably gives me this error:
>
> Error in eval(expr, envir, enclos) : object "est" not found
>
> I tried substitute(x) (as that seems to have cured a similar problem
> with "g") but then x is not a formula and method dispatch fails.
>
> Help?
> zw
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From h.wickham at gmail.com  Fri Jun  8 22:14:06 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 8 Jun 2007 22:14:06 +0200
Subject: [R] wrapping lattice xyplot
In-Reply-To: <eb97335b0706081141nb2f3e1ta9e7348e2d111f92@mail.gmail.com>
References: <eb97335b0706081141nb2f3e1ta9e7348e2d111f92@mail.gmail.com>
Message-ID: <f8e6ff050706081314t2081a553hc67e41be67df7279@mail.gmail.com>

On 6/8/07, Zack Weinberg <zackw at panix.com> wrote:
> This is an expanded version of the question I tried to ask last night
> - I thought I had it this morning, but it's still not working and I
> just do not understand what is going wrong.
>
> What I am trying to do is write a wrapper for lattice xyplot() that
> passes a whole bunch of its secondary arguments, so that I can produce
> similarly formatted graphs for several different data sets.  This is
> what I've got:
>
> graph <- function (x, data, groups, xlab) {
>   g <- eval(substitute(groups), data, parent.frame())
>
>   pg <- function(x, y, group.number, ...) {
>     panel.xyplot(x, y, ..., group.number=group.number)
>     panel.text(2, unique(y[x==2]),
>                levels(g)[group.number],
>                pos=4, cex=0.5)
>   }
>
>   xyplot(x, data=data, groups=substitute(g),
>               type='l',
>               ylab=list(cex=1.1, label='Mean RT (ms)'),
>               xlab=list(cex=1.1, label=xlab),
>               scales=list(
>                 x=list(alternating=c(1,1), tck=c(1,0)),
>                 y=list(alternating=c(1,0))
>                 ),
>               panel=panel.superpose,
>               panel.groups=pg
>               )
> }
>
> "pg" is supposed to pick "g" up from the lexical enclosure. I have no
> idea whether that actually works, because it never gets that far.  A
> typical call to this function looks like so:
>
> > graph(est ~ pro | hemi, sm, obs, "Probe type")
>
> (where 'sm' is a data frame that really does contain all four columns
> 'est', 'pro', 'hemi', and 'obs', pinky swear) and, as it stands above,
> invariably gives me this error:
>
> Error in eval(expr, envir, enclos) : object "est" not found
>
> I tried substitute(x) (as that seems to have cured a similar problem
> with "g") but then x is not a formula and method dispatch fails.
>
> Help?
> zw

It's not lattice, but ggplot2, http://had.co.nz/ggplot2, is designed
to make this easy because you don't have to specify the data set when
creating the plot. e.g.

install.packages("ggplot2", dep=T)
library(ggplot2)

# This is an abstract definition of a plot - it doesn't have any data yet
p <- ggplot(mapping = aes(x=cyl, y=mpg)) + geom_point() +
geom_smooth(method="lm")

mt2 <- mtcars * 2
mt3 <- as.data.frame(mtcars ^ 2)

# Add datasets
p %+% mtcars
p %+% mt2
p %+% mt3
# (the syntax isn't great, but you get the idea)

# Or even changing the default mapping from data to visual properties
p %+% mt3 + aes(x = mpg, y=wt)

Obviously, you can do even more within a function, and the aes call is
relatively easy to create programmatically (although not well
documented currently, so please ask me for more details if you are
interested).

Hadley


From deepayan.sarkar at gmail.com  Fri Jun  8 22:32:54 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Fri, 8 Jun 2007 13:32:54 -0700
Subject: [R] still trying to wrap xyplot - ignore previous
In-Reply-To: <eb97335b0706081212r7bc5843fv152e1f8147efb78c@mail.gmail.com>
References: <eb97335b0706081212r7bc5843fv152e1f8147efb78c@mail.gmail.com>
Message-ID: <eb555e660706081332j2ccebd17rd14ea6cb73403205@mail.gmail.com>

On 6/8/07, Zack Weinberg <zackw at panix.com> wrote:
> As you may not be surprised to hear, no sooner did I post the previous
> message than I realized I had a really dumb mistake.  I've now gotten
> a bit farther but am still stuck.  New code:
>
> graph <- function (x, data, groups, xlab) {
>   pg <- function(x, y, group.number, ...) fnord
>   body(pg) <- substitute({
>     panel.xyplot(x, y, ..., group.number=group.number)
>     panel.text(2, unique(y[x==2]),
>                levels(G)[group.number],
>                pos=4, cex=0.5)
>   }, list(G=eval(substitute(groups), data, parent.frame())))
>
>   print(xyplot(x, data=data, groups=substitute(groups),
>                type='l',
>                ylab=list(cex=1.1, label='Mean RT (ms)'),
>                xlab=list(cex=1.1, label=xlab),
>                scales=list(
>                  x=list(alternating=c(1,1), tck=c(1,0)),
>                  y=list(alternating=c(1,0))
>                  ),
>                panel=panel.superpose,
>                panel.groups=pg
>               ))
> }
>
> Questions:
> 1) The "groups=substitute(groups)" bit (in the call to xyplot) still
> doesn't work.  As far as I can tell, xyplot wants the *symbol* which
> is the name of the factor (in the data frame) to group by.
> The above seems to wind up passing it the symbol "groups", which
> causes the prepanel function to barf.  I have not been able to find
> any way to evaluate one layer of "groups" to get me the symbol passed
> in, rather than the value of that symbol.  Am I right?  How do I give
> it what it wants?
>
> 2) Why do I have to do that stupid dance with replacing the body of
> pg?  The documentation leads me to believe this is a lexically scoped
> language, shouldn't it be able to pick G out of the enclosing frame?

This is all a consequence of non-standard evaluation, which can be a
real pain sometimes. I don't have a solution that is "intuitive", but
I don't think there is one. This is what I would do (and there are
examples of this in lattice, e.g. see lattice:::dotplot.formula):


graph <- function (x, data, groups, xlab) {

    ## set up g and pg (lexical scope does work here)
    g <- eval(substitute(groups), data, parent.frame())
    pg <- function(x, y, group.number, ...) {
        panel.xyplot(x, y, ..., group.number=group.number)
        panel.text(2, unique(y[x==2]),
                   levels(g)[group.number],
                   pos=4, cex=0.5)
    }

    ## modify and evaluate call without
    ## actually evaluating 'groups'
    ccall <- match.call()
    ccall[[1]] <- quote(xyplot)
    fixed.args <-
        list(type='l',
             ylab=list(cex=1.1, label='Mean RT (ms)'),
             xlab=list(cex=1.1, label=xlab),
             scales=list(
             x=list(alternating=c(1,1), tck=c(1,0)),
             y=list(alternating=c(1,0))
             ),
             panel="panel.superpose",
             panel.groups = pg)
    ccall[names(fixed.args)] <- fixed.args
    eval.parent(ccall)
}

sm <- data.frame(x = 1:10, y = rnorm(10), a = gl(3, 1, 10))
graph(y ~ x, sm, a, "foo")

This is a different approach from the one you were trying, but I think
it makes more sense once you get used to it. Note that there are some
subtle things going on here. The 'g' used by pg() is available only
because the relevant environment is stored and is accessible through
the "trellis" object:

> foo <- graph(y ~ x, sm, a, "foo")
> ls(environment(foo$panel.args.common$panel.groups))
[1] "ccall"      "data"       "fixed.args" "g"          "groups"
[6] "pg"         "x"          "xlab"

Hope this helps,

-Deepayan


From michael.drescher at ontario.ca  Fri Jun  8 22:33:29 2007
From: michael.drescher at ontario.ca (Drescher, Michael (MNR))
Date: Fri, 8 Jun 2007 16:33:29 -0400
Subject: [R] Escobar&Meeker example survreg
Message-ID: <76D2AA307C39054DBA8BD42DE44E71A4A9A2DC@CTSPITDCEMMVX14.cihs.ad.gov.on.ca>

Dear all,

I am new to R and may make beginner mistakes. Sorry.

I am learning using R to do survival analysis. As a start I used the
example script code provided in the documentation of predict.survreg of
the survival package:

# Draw figure 1 from Escobar and Meeker
fit <- survreg(Surv(time,status) ~ age + age^2, data=stanford2,
dist='lognormal')
plot(stanford2$age, stanford2$time, xlab='Age', ylab='Days',
xlim=c(0,65), ylim=c(.01, 10^6), log='y')
pred <- predict(fit, newdata=list(age=1:65), type='quantile', p=c(.1,
.5, .9))
matlines(1:65, pred, lty=c(2,1,2), col=1)

When I compare the graphical output with Fig. 1 of Escobar and Meeker
(1992), I find that my output produces quantiles that are sloping down
linearly with age. The quantiles in Fig. 1 of Escobar and Meeker (1992)
however are obviously non-linear. I compared this with the corresponding
section in the S-Plus manual and found that the R and S-Plus are
virtually identical (as they should) and that the predicted quantiles in
S-Plus (Fig. 31.3) are also non-linear.

I checked the obvious help files and R-archive and found nothing on
this. I must be making a very basic mistake but can't find it.

Your feedback would be highly appreciated.

Best, Michael



Ref: Escobar and Meeker (1992). Assessing influence in regression
analysis with censored data. Biometrics, 48, 507-528.


From perpdgo at colpos.mx  Fri Jun  8 22:17:09 2007
From: perpdgo at colpos.mx (Paulino Perez Rodriguez)
Date: Fri, 08 Jun 2007 14:17:09 -0600
Subject: [R] RMySQL configure.win error?
Message-ID: <web-10710376@mailadmin.colpos.mx>


Hello, is there an error in the file configure.win from 
the package RMySQL_0.6-0.tar.gz, in the line

dlltool --dllname ${MYSQL_LIB} --def libmysql.def 
--output-lib libmysql.a -k

I think it must be

dlltool --dllname ${MYSQL_DLL} --def libmysql.def 
--output-lib libmysql.a -k

right? since MYSQL_DLL=libMySQL.dll  and 
 MYSQL_LIB=libmysql.lib

It appears that the package doesn't work with 
mysql-5.0.4.1.

It works fine with mysql-5.0.18

Thanks.

-- 
Este mensaje ha sido analizado por MailScanner
en busca de virus y otros contenidos peligrosos,
y se considera que est? limpio.


From christophe at pallier.org  Fri Jun  8 22:38:58 2007
From: christophe at pallier.org (Christophe Pallier)
Date: Fri, 8 Jun 2007 22:38:58 +0200
Subject: [R] Tools For Preparing Data For Analysis
In-Reply-To: <40e66e0b0706080547o5c630ac3ne5feadc4247e289a@mail.gmail.com>
References: <874da0b40706071701m55cd42fem15f55a8fcde04f17@mail.gmail.com>
	<40e66e0b0706080547o5c630ac3ne5feadc4247e289a@mail.gmail.com>
Message-ID: <dea6cb960706081338t444a84cau4fd0cca06fdee013@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070608/8ddb9483/attachment.pl 

From mardones.p at gmail.com  Fri Jun  8 23:27:44 2007
From: mardones.p at gmail.com (Pedro Mardones)
Date: Fri, 8 Jun 2007 17:27:44 -0400
Subject: [R] legend + expression
Message-ID: <83dca7860706081427j24cd4071l35e462470ec02e61@mail.gmail.com>

Dear all;

A simple? question.

I'm having a problem with a math expression in the legend of a plot
and I haven't found the way to get this to work, so any help will be
appreciate. Basically I want to include in the plot is the R-squared
and its numerical value, so I tried this:

R2c<-0.82879 # R-squared of calibration model
plot(1:10,1:10)
legend("topleft", legend=c(expression(R[c]^2==format(R2c,nsmall=2))))

Thanks for any hint

PM


From Peter.Ruckdeschel at uni-bayreuth.de  Fri Jun  8 23:50:17 2007
From: Peter.Ruckdeschel at uni-bayreuth.de (Peter Ruckdeschel)
Date: Fri, 08 Jun 2007 23:50:17 +0200
Subject: [R] Packaging under Win32 / cygwin : ZoneAlarm conflict  [solved]
Message-ID: <4669CF19.6040005@uni-bayreuth.de>

just for the record...

recently I have had quite some problems with package
building under Win XP.

After some searching I found out that it was nothing R
was to be blamed for but rather my firewall,
i.e.; ZoneAlarm.

As it seems, this problem has gone unnoticed so far ---
I only found Marc Schwartz's posting

  http://tolstoy.newcastle.edu.au/R/devel/03b/0246.html

in the R-lists-archives.

In my case it was not only performance, but there seemes
to be a serious leakage phenomenon between cygwin's

   sh  (sh.exe dating from 01-27-04)

from Dunchan Murdochs' Rtools.exe
(cygpopt-0.dll from 04-13-07)

and

   ZoneAlarm (version 70_337_000)

I got reports that "fork: resource temporarily unavailable" and
finally virtually it shot off my system ...

Searching a bit further I found a more recent posting by
Luca Trevisani in the cygwin - archives:

   http://cygwin.com/ml/cygwin/2007-02/msg00673.html

who suggests replacing ZoneAlarm by other free firewalls.

In the end I did that, i.e.; removed ZoneAlarm completely
from my system and replaced it by some other firewall
(and also informed ZoneLabs about that conflict)

... and lived happily ever after ;-)

Hopefully this information is of help to others running into
similar problems.

Best,
Peter


From Peter.Ruckdeschel at uni-bayreuth.de  Sat Jun  9 00:11:06 2007
From: Peter.Ruckdeschel at uni-bayreuth.de (Peter Ruckdeschel)
Date: Sat, 09 Jun 2007 00:11:06 +0200
Subject: [R] legend + expression
Message-ID: <4669D3FA.2050006@uni-bayreuth.de>

what about

legend("topleft",
        legend = bquote( R[c]2 == .(format(R2c,nsmall=2)) )
       )

HTH,
 Peter


From marc_schwartz at comcast.net  Sat Jun  9 00:12:21 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Fri, 08 Jun 2007 17:12:21 -0500
Subject: [R] legend + expression
In-Reply-To: <83dca7860706081427j24cd4071l35e462470ec02e61@mail.gmail.com>
References: <83dca7860706081427j24cd4071l35e462470ec02e61@mail.gmail.com>
Message-ID: <1181340741.3927.43.camel@Bellerophon>

On Fri, 2007-06-08 at 17:27 -0400, Pedro Mardones wrote:
> Dear all;
> 
> A simple? question.
> 
> I'm having a problem with a math expression in the legend of a plot
> and I haven't found the way to get this to work, so any help will be
> appreciate. Basically I want to include in the plot is the R-squared
> and its numerical value, so I tried this:
> 
> R2c<-0.82879 # R-squared of calibration model
> plot(1:10,1:10)
> legend("topleft", legend=c(expression(R[c]^2==format(R2c,nsmall=2))))
> 
> Thanks for any hint
> 
> PM

Try this:

  R2c <- 0.82879

  plot(1:10,1:10)

  R2c.2 <- sprintf("%.2f", R2c)

  legend("topleft", legend = bquote(R[c]^2 == .(R2c.2)))


See ?bquote and if you search the list archives, there are more complex
examples of using 'plotmath' in legends.

Note also that 'nsmall' in format() does not fix the number of digits
after the decimal:

> format(0.82879, nsmall = 2)
[1] "0.82879"

See ?formatC and ?sprintf for better options.

HTH,

Marc Schwartz


From irishhacker at gmail.com  Sat Jun  9 03:39:58 2007
From: irishhacker at gmail.com (Robert Wilkins)
Date: Fri, 8 Jun 2007 20:39:58 -0500
Subject: [R] How do you do an e-mail post that is within an ongoing thread?
Message-ID: <874da0b40706081839qc3a0cb0r64cf59d72cfb79d9@mail.gmail.com>

That may sound like a stupid question, but if it confuses me, I'm sure
it confuses others as well. I've tried to find that information on the
R mail-group info pages, can't seem to find it. Is it something
obvious?

To begin a brand new discussion, you do your post as an e-mail sent to
 r-help at stat.math.ethz.ch .
As I am doing right now.

How do I do an additional post that gets included in the
"[R] Tools For Preparing Data For Analysis" thread, a thread which I
started myself yesterday ( thanks for all the responses everybody )?

There's got to be a real easy answer to that, since everybody else does that.
(I'm using gmail, does it make a difference what e-mail host you use?).

-----------------------


PS
If you happen to be reading this, Christophe Pallier & Martin Stevens,
I will respond to your request for examples shortly, once I figure
this posting how-to out. My examples will come from data preparation
problems in clinical trial data ( I worked for 8 years on clinical
trial analysis before beginning work on Vilno ). I'll probably use lab
data as an example because  lab data can be messy and difficult to
work with.


From berwin at maths.uwa.edu.au  Sat Jun  9 09:05:22 2007
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Sat, 9 Jun 2007 15:05:22 +0800
Subject: [R] "R is not a validated software package.."
In-Reply-To: <1181329908.5181.95.camel@Bellerophon>
References: <4669617F.8090405@med.unibs.it>
	<1181329908.5181.95.camel@Bellerophon>
Message-ID: <20070609150522.377dbac9@bossiaea>

G'day Marc,

On Fri, 08 Jun 2007 14:11:48 -0500
Marc Schwartz <marc_schwartz at comcast.net> wrote:

> On Fri, 2007-06-08 at 16:02 +0200, Giovanni Parrinello wrote:
> > Dear All,
> > discussing with a statistician of a pharmaceutical company I
> > received this answer about the statistical package that I have
> > planned to use:
> > 
> > As R is not a validated software package, we would like to ask if
> > it would rather be possible for you to use SAS, SPSS or another
> > approved statistical software system.
> > 
> > Could someone suggest me a 'polite' answer?
> > TIA
> > Giovanni
> > 
> 
> The polite answer is that there is no such thing as 'FDA approved'
> software for conducting clinical trials. The FDA does not approve,
> validate or otherwise endorse software.

I like this one. :)

My polite answer would have been: "Sure, can do.  If you pay for the
license of the finally agreed upon statistical software system and pay
for the time it takes me to learn it so that I can do the analysis
using that system instead of R."  Most clients I know would withdraw
such requests if they notice that it will probably double or triple
their bill. ;-)

Cheers,

	Berwin


From gavin.simpson at ucl.ac.uk  Sat Jun  9 10:11:33 2007
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Sat, 09 Jun 2007 09:11:33 +0100
Subject: [R] How do you do an e-mail post that is within an
	ongoing	thread?
In-Reply-To: <874da0b40706081839qc3a0cb0r64cf59d72cfb79d9@mail.gmail.com>
References: <874da0b40706081839qc3a0cb0r64cf59d72cfb79d9@mail.gmail.com>
Message-ID: <1181376693.3012.13.camel@dhcppc2.my.nat.localnet>

On Fri, 2007-06-08 at 20:39 -0500, Robert Wilkins wrote:
> That may sound like a stupid question, but if it confuses me, I'm sure
> it confuses others as well. I've tried to find that information on the
> R mail-group info pages, can't seem to find it. Is it something
> obvious?
> 
> To begin a brand new discussion, you do your post as an e-mail sent to
>  r-help at stat.math.ethz.ch .
> As I am doing right now.
> 
> How do I do an additional post that gets included in the
> "[R] Tools For Preparing Data For Analysis" thread, a thread which I
> started myself yesterday ( thanks for all the responses everybody )?

Just reply all (to the list and the sender of the email, plus any other
recipients in the CC list if appropriate) to the email you wish to
comment on. You can reply at any point in the thread and your email will
end up located in that position in the thread, i.e. underneath the
message you replied to in the thread.

The actual threading is dealt with by peoples own email software (and by
the software used to manage the archives), via some of the headers sent
along with your email, for example:

In-Reply-To: <83dca7860706081427j24cd4071l35e462470ec02e61 at something.com>
References: <83dca7860706081427j24cd4071l35e462470ec02e61 at something.com>

The long code there is the Message-Id header of the email that the reply
references.

Most emailers will hide all of these headers from you, but a good one
will allow you to look at all the headers or the actual source of the
email, where you will be able to see them, along with a lot of other
information about the message sent.

> 
> There's got to be a real easy answer to that, since everybody else does that.
> (I'm using gmail, does it make a difference what e-mail host you use?).

I've not use gmail much, but many people on the list do and they end up
in the correct place in the thread. Note that in Gmail to see the
headers for a message you can select "show original" from the little
drop down menu (down triangle) next to the reply button.

HTH

G
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [t] +44 (0)20 7679 0522
ECRC                              [f] +44 (0)20 7679 0565
UCL Department of Geography
Pearson Building                  [e] gavin.simpsonATNOSPAMucl.ac.uk
Gower Street
London, UK                        [w] http://www.ucl.ac.uk/~ucfagls/
WC1E 6BT                          [w] http://www.freshwaters.org.uk/
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From AndreasGegg at gmx.de  Sat Jun  9 12:31:03 2007
From: AndreasGegg at gmx.de (Andreas Gegg)
Date: Sat, 09 Jun 2007 12:31:03 +0200
Subject: [R] write.table: last line should differ from usual eol
Message-ID: <op.ttngt1ybof9uj6@->

Dear R-Team,

I have a problem with writing an array to (for example) a .txt-file.  
Because of the .txt-file must be read from another programm (OPL ILOG),  
the syntax of the output must be from a special form:

name_of_the_object = [	[1,2, ... ],
			[1,...],
			... ];

I think it's easier to understand with a small example:

X<-array(1:4,c(2,2))

should be written as:
X = [[1,3],
      [2,4]];


I have (until now) used the following:

write("X=[[",file=filename)
write.table(X,file=filename,sep=",",eol="],\n [", row.names=FALSE,  
col.names=FALSE,append=TRUE)

which leads to the following output:
X=[[
1,3],
  [2,4],
  [

I hope you can help because it's very annoying to adjust the resulting  
.txt-file "by hand".

Thanks a lot for your help!
With nice greetings

Andreas Gegg,
mathematic-student on Catholic University of Eichst?tt-Ingolstadt (Germany)


From jrkrideau at yahoo.ca  Sat Jun  9 12:50:08 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Sat, 9 Jun 2007 06:50:08 -0400 (EDT)
Subject: [R] character to time problem
In-Reply-To: <971536df0706080815ge0dca51g16a3665237b5e2ea@mail.gmail.com>
Message-ID: <631450.96975.qm@web32814.mail.mud.yahoo.com>

Thanks. I read your code too quickly.  I'll have a
look at the R News article. I read it last year but
apparently have forgotten just about all of it. :(


--- Gabor Grothendieck <ggrothendieck at gmail.com>
wrote:

> The code in my post uses "Date" class, not POSIX.
> sort.POSIXlt is never invoked.  Suggest you read the
> help desk article in R News 4/1 for more.
> 
> On 6/8/07, John Kane <jrkrideau at yahoo.ca> wrote:
> > Looks much better. I seldom use dates for much and
> > didn't think to look at the sort.POSIXlt function.
> >
> > If I understand this correctly the sort.POSIXlt
> with
> > na.last = FALSE is dropping all the NAs.  Very
> nice.
> >
> >
> > --- Gabor Grothendieck <ggrothendieck at gmail.com>
> > wrote:
> >
> > > Perhaps you want one of these:
> > >
> > > > sort(as.Date(aa$times, "%d/%m/%Y"))
> > > [1] "1995-03-02" "2001-05-12" "2007-02-14"
> > >
> > > > sort(as.Date(aa$times, "%d/%m/%Y"), na.last =
> > > TRUE)
> > > [1] "1995-03-02" "2001-05-12" "2007-02-14" NA
> > >    NA
> > > [6] NA
> > >
> > >
> > > On 6/7/07, John Kane <jrkrideau at yahoo.ca> wrote:
> > > > I am trying to clean up some dates and I am
> > > clearly
> > > > doing something wrong.  I have laid out an
> example
> > > > that seems to show what is happening with the
> > > "real"
> > > > data.  The  coding is lousy but it looks like
> it
> > > > should have worked.
> > > >
> > > > Can anyone suggest a) why I am getting that NA
> > > > appearing after the strptime() command and b)
> why
> > > the
> > > > NA is disappearing in the sort()? It happens
> with
> > > > na.rm=TRUE  and na.rm=FALSE
> > > >
> -------------------------------------------------
> > > > aa  <- data.frame( c("12/05/2001", " ",
> > > "30/02/1995",
> > > > NA, "14/02/2007", "M" ) )
> > > > names(aa)  <- "times"
> > > > aa[is.na(aa)] <- "M"
> > > > aa[aa==" "]  <- "M"
> > > > bb <- unlist(subset(aa, aa[,1] !="M"))
> > > > dates <- strptime(bb, "%d/%m/%Y")
> > > > dates
> > > > sort(dates)
> > > >
> --------------------------------------------------
> > > >
> > > > Session Info
> > > > R version 2.4.1 (2006-12-18)
> > > > i386-pc-mingw32
> > > >
> > > > locale:
> > > > LC_COLLATE=English_Canada.1252;
> > > > LC_CTYPE=English_Canada.1252;
> > > > LC_MONETARY=English_Canada.1252;
> > > > LC_NUMERIC=C;LC_TIME=English_Canada.1252
> > > >
> > > > attached base packages:
> > > > [1] "stats"     "graphics"  "grDevices"
> "utils"
> > > > "datasets"  "methods"   "base"
> > > >
> > > > other attached packages:
> > > >  gdata   Hmisc
> > > > "2.3.1" "3.3-2"
> > > >
> > > >  (Yes I know I'm out of date but I don't like
> > > > upgrading just as I am finishing a project)
> > > >
> > > > Thanks
> > > >
> > > > ______________________________________________
> > > > R-help at stat.math.ethz.ch mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal,
> self-contained,
> > > reproducible code.
> > > >
> > >
> >
> >
> >
> >      Be smarter than spam. See how smart SpamGuard
> is at giving junk email the boot with the All-new

> http://mrd.mail.yahoo.com/try_beta?.intl=ca
> >
> >
>


From jholtman at gmail.com  Sat Jun  9 13:10:36 2007
From: jholtman at gmail.com (jim holtman)
Date: Sat, 9 Jun 2007 07:10:36 -0400
Subject: [R] write.table: last line should differ from usual eol
In-Reply-To: <op.ttngt1ybof9uj6@->
References: <op.ttngt1ybof9uj6@->
Message-ID: <644e1f320706090410n3dde7d52jb5214bbc5c6f30eb@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070609/3442a9dd/attachment.pl 

From michael.watson at bbsrc.ac.uk  Sat Jun  9 13:20:20 2007
From: michael.watson at bbsrc.ac.uk (michael watson (IAH-C))
Date: Sat, 9 Jun 2007 12:20:20 +0100
Subject: [R] open .r files with double-click
References: <26142.134.53.7.120.1181328742.squirrel@134.53.7.120>
Message-ID: <8975119BCD0AC5419D61A9CF1A923E9504AA1E15@iahce2ksrv1.iah.bbsrc.ac.uk>

Hmmm.  Possibly your best bet is to create a batch file, runr.bat or something, and associate .r files with that.

The batch file would be something like:

"C:/Program Files/R/R-2.5.0/bin/Rgui.exe" --no-save < %1

(I think thats how you reference arguments in dos...)


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch on behalf of stevenmh at muohio.edu
Sent: Fri 08/06/2007 7:52 PM
To: r-help at stat.math.ethz.ch
Subject: [R] open .r files with double-click
 
Hi Folks,
On Windows XP, R 2.5.0.

After reading the Installation for Windows and Windows FAQs,
I cannot resolve this.

I set file types so that Rgui.exe will open .r files.

When I try to open a .r file by double-clicking, R begins to launch,
but I get an error message saying

"Argument 'C:\Documents and Settings\Zoology\My Documents\trial.r' _ignored_"

I click OK, and then R GUI opens, but not the script file.

Is there a way to change this?

thanks,
Hank

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From murdoch at stats.uwo.ca  Sat Jun  9 13:29:18 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 09 Jun 2007 07:29:18 -0400
Subject: [R] open .r files with double-click
In-Reply-To: <26142.134.53.7.120.1181328742.squirrel@134.53.7.120>
References: <26142.134.53.7.120.1181328742.squirrel@134.53.7.120>
Message-ID: <466A8F0E.9060804@stats.uwo.ca>

On 08/06/2007 2:52 PM, stevenmh at muohio.edu wrote:
> Hi Folks,
> On Windows XP, R 2.5.0.
> 
> After reading the Installation for Windows and Windows FAQs,
> I cannot resolve this.
> 
> I set file types so that Rgui.exe will open .r files.
> 
> When I try to open a .r file by double-clicking, R begins to launch,
> but I get an error message saying
> 
> "Argument 'C:\Documents and Settings\Zoology\My Documents\trial.r' _ignored_"
> 
> I click OK, and then R GUI opens, but not the script file.
> 
> Is there a way to change this?

Not currently. See the appendix "Invoking R" of the Introduction manual 
for the current command line parameters, which don't include "open a 
script".  This would be a reasonable addition, and I'll add it at some 
point, sooner if someone else comes up with a convincing argument for 
the "right" command line parameter to do this.

It would be better if clicking on a second script opened a new window in 
the same session, but that takes more work; not sure I'll get to this.

Duncan Murdoch


From ggrothendieck at gmail.com  Sat Jun  9 13:51:53 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 9 Jun 2007 07:51:53 -0400
Subject: [R] How do you do an e-mail post that is within an ongoing
	thread?
In-Reply-To: <874da0b40706081839qc3a0cb0r64cf59d72cfb79d9@mail.gmail.com>
References: <874da0b40706081839qc3a0cb0r64cf59d72cfb79d9@mail.gmail.com>
Message-ID: <971536df0706090451s3d537be1p72b16afa41b4cb40@mail.gmail.com>

In gmail just hit Reply to All at the bottom of the post you wish to
follow up on.

On 6/8/07, Robert Wilkins <irishhacker at gmail.com> wrote:
> That may sound like a stupid question, but if it confuses me, I'm sure
> it confuses others as well. I've tried to find that information on the
> R mail-group info pages, can't seem to find it. Is it something
> obvious?
>
> To begin a brand new discussion, you do your post as an e-mail sent to
>  r-help at stat.math.ethz.ch .
> As I am doing right now.
>
> How do I do an additional post that gets included in the
> "[R] Tools For Preparing Data For Analysis" thread, a thread which I
> started myself yesterday ( thanks for all the responses everybody )?
>
> There's got to be a real easy answer to that, since everybody else does that.
> (I'm using gmail, does it make a difference what e-mail host you use?).
>
> -----------------------
>
>
> PS
> If you happen to be reading this, Christophe Pallier & Martin Stevens,
> I will respond to your request for examples shortly, once I figure
> this posting how-to out. My examples will come from data preparation
> problems in clinical trial data ( I worked for 8 years on clinical
> trial analysis before beginning work on Vilno ). I'll probably use lab
> data as an example because  lab data can be messy and difficult to
> work with.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ggrothendieck at gmail.com  Sat Jun  9 14:19:16 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 9 Jun 2007 08:19:16 -0400
Subject: [R] write.table: last line should differ from usual eol
In-Reply-To: <644e1f320706090410n3dde7d52jb5214bbc5c6f30eb@mail.gmail.com>
References: <op.ttngt1ybof9uj6@->
	<644e1f320706090410n3dde7d52jb5214bbc5c6f30eb@mail.gmail.com>
Message-ID: <971536df0706090519r4924c424g33f941aac1ad60f2@mail.gmail.com>

Try this:


write.ilog <- function(X, file = "") {
   w <- function(x, z, file)
          cat("[", paste(x, collapse = ","), "]", z, sep = "", file = file)
   if (!identical(file, "")) {
      file <- open(file, "w")
      on.exit(close(file))
   }
   cat("X=[", file = file)
   nr <- nrow(X)
   for(i in 1:nr) w(X[i,], if (i == nr) "];\n" else ",\n", file)
   invisible(X)
}

X<-array(1:4,c(2,2))
write.ilog(X)




On 6/9/07, jim holtman <jholtman at gmail.com> wrote:
> This will probably do it for you.  It is a function to create the output:
>
>
>
> write.array <- function(x,fileName){
>    outFile <- file(fileName, 'w')
>    cat(deparse(substitute(x)), "=[", sep='', file=outFile)
>    for (i in 1:nrow(x)){
>        cat('[', paste(x[i,], collapse=','), ']', file=outFile, sep='')
>        if (i == nrow(x)) cat('];', file=outFile, sep='')
>        else cat(',\n', file=outFile, sep='')
>    }
>    close(outFile)
> }
>
> # test data
> a <- matrix(1:25,5)
> write.array(a, '/tempxx.txt')
>
> Here is the output file:
>
> a=[[1,6,11,16,21],
> [2,7,12,17,22],
> [3,8,13,18,23],
> [4,9,14,19,24],
> [5,10,15,20,25]];
>
>
>
>
> I have a problem with writing an array to (for example) a .txt-file.
> Because of the .txt-file must be read from another programm (OPL ILOG),
> the syntax of the output must be from a special form:
>
> name_of_the_object = [  [1,2, ... ],
>                       [1,...],
>                       ... ];
>
> I think it's easier to understand with a small example:
>
> X<-array(1:4,c(2,2))
>
> should be written as:
> X = [[1,3],
>     [2,4]];
>
>
> I have (until now) used the following:
>
> write("X=[[",file=filename)
> write.table(X,file=filename,sep=",",eol="],\n [", row.names=FALSE,
> col.names=FALSE,append=TRUE)
>
> which leads to the following output:
> X=[[
> 1,3],
> [2,4],
> [
>
> I hope you can help because it's very annoying to adjust the resulting
> .txt-file "by hand".
>
> Thanks a lot for your help!
> With nice greetings
>
> Andreas Gegg,
> mathematic-student on Catholic University of Eichst?tt-Ingolstadt (Germany)
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Jim Holtman
> Cincinnati, OH
> +1 513 646 9390
>
> What is the problem you are trying to solve?
>
>        [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


From maechler at stat.math.ethz.ch  Sat Jun  9 15:05:20 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 9 Jun 2007 15:05:20 +0200
Subject: [R] pnorm how to decide lower-tail true or false
In-Reply-To: <46699285.4040808@web.de>
References: <46699285.4040808@web.de>
Message-ID: <18026.42384.681136.901131@stat.math.ethz.ch>

>>>>> "CM" == Carmen Meier <carmei3 at web.de>
>>>>>     on Fri, 08 Jun 2007 19:31:49 +0200 writes:

    CM> Hi to all, maybe the last question was not clear enough.
    CM> I did not found any hints how to decide whether it
    CM> should use lower.tail or not.  As it is an extra
    CM> R-feature ( written in
    CM> http://finzi.psych.upenn.edu/R/Rhelp02a/archive/66250.html
    CM> ) I do not find anything about it in any statistical
    CM> books of me.

Yes, most "statistical books" do not consider numerical accuracy
which is the real issue here.
Note that R is much more than a "statistical package" and hence
to be appreciated properly needs much broader (applied)
mathematical, statistical and computer science knowledge ;-)

When  p ~= 1,  '1 - p' suffers from so called cancellation
("Numerical analysis 101").
If you already know that you will use "q := 1 - p",
rather compuate 'q' directly than first compute p, then 1-p,
losing all accuracy.

All of R's  p<foo>(..) functions have an argument 'lower.tail'
which is TRUE by default, since after all,

      p<foo>(x) = Prob_{<foo>}[X <= x]   

measures the probability of the lower or left tail of the
<foo>-distribution.
<foo> = norm  is just a special case.
If you really want 
   q =  1 - p<foo>(x) = Prob_{<foo>}[X > x]   

then you can get this directly via
     
   q <- p<foo>(x, lower.tail = FALSE, ....)


Simple example with R :

> pnorm(10)
[1] 1
> 1 - pnorm(10)
[1] 0
> pnorm(10, lower.tail=FALSE)
[1] 7.619853e-24


Regards,
Martin Maechler, ETH Zurich


From tplate at acm.org  Sat Jun  9 16:21:44 2007
From: tplate at acm.org (Tony Plate)
Date: Sat, 09 Jun 2007 08:21:44 -0600
Subject: [R] how to find how many modes in 2 dimensions case
In-Reply-To: <58576.128.97.55.42.1181328852.squirrel@calmail.berkeley.edu>
References: <58576.128.97.55.42.1181328852.squirrel@calmail.berkeley.edu>
Message-ID: <466AB778.9040504@acm.org>

If you want to count the local maxima in the n x n matrix returned by 
kde2d, AND you know there are no ties, you could do something like the 
following:

 > set.seed(1)
 > x <- matrix(sample(10, 25, rep=TRUE), 5, 5)
 > x
      [,1] [,2] [,3] [,4] [,5]
[1,]    3    9    3    5   10
[2,]    4   10    2    8    3
[3,]    6    7    7   10    7
[4,]   10    7    4    4    2
[5,]    3    1    8    8    3
 > sum(x > cbind(0, x[,-5]) & x > cbind(x[,-1], 0) & x > rbind(x[-1,], 
0) & x > rbind(0, x[-5,]))
[1] 4
 >

Just be careful that your counting formula matches your definition of 
"neighbor" (the above formula does not include diagonal neighbors).

And of course, ties make things more complicated (note that the above 
simple algorithm misses the local maximum consisting of two 8's in the 
last row.)

-- Tony Plate


Patrick Wang wrote:
> Hi,
> 
> Does anyone know how to count the number of modes in 2 dimensions using
> kde2d function?
> 
> Thanks
> Pat
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From blindglobe at gmail.com  Sat Jun  9 17:32:59 2007
From: blindglobe at gmail.com (AJ Rossini)
Date: Sat, 9 Jun 2007 17:32:59 +0200
Subject: [R] "R is not a validated software package.."
In-Reply-To: <4669617F.8090405@med.unibs.it>
References: <4669617F.8090405@med.unibs.it>
Message-ID: <200706091733.05407.blindglobe@gmail.com>

On Friday 08 June 2007, Giovanni Parrinello wrote:
> Dear All,
> discussing with a statistician of a pharmaceutical company I received
> this answer about the statistical package that I have planned to use:
>
> As R is not a validated software package, we would like to ask if it
> would rather be possible for you to use SAS, SPSS or another approved
> statistical software system.
>
> Could someone suggest me a 'polite' answer?
> TIA
> Giovanni

You can't validate any complex software package, i.e. computer programming 
language complexity (SAS, R, S-PLUS, SPSS, PERL, Python, Ruby, Java....)

You can qualify a software package, and validate code written in it.

As a "statistician" in a very large pharmaceutical company based in Basel 
which happens to be bigger than the other large pharma in Basel, I can say 
that we should have most of the paperwork done for qualification, at some 
point this year, for use as part of submission packages.  Whether it will be 
used is another matter, which will be driven by business needs :-).

So your colleague is right, only in the sense that whatever the company has 
approved is appropriate, and qualification in the "computer systems 
validation" context is expensive, time and man-power wise.  But that holds 
true for any software package.

Your colleague should have technically said:  "As R is not a qualified 
software package at my company, we would like to ask if it would be possible 
for you to use software which my company has approved and done 
the /risk-management/ paperwork for and gotten approval from our Clinical 
Quality group to use". 

This is an issue -- however, whether R could pass that is not an issue, it 
clearly could be done if they wanted to do it.
 
best,
-tony

blindglobe at gmail.com
Muttenz, Switzerland.
"Commit early,commit often, and commit in a repository from which we can 
easily
roll-back your mistakes" (AJR, 4Jan05).
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: This is a digitally signed message part.
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20070609/4b620c21/attachment.bin 

From blindglobe at gmail.com  Sat Jun  9 17:44:43 2007
From: blindglobe at gmail.com (AJ Rossini)
Date: Sat, 9 Jun 2007 17:44:43 +0200
Subject: [R] "R is not a validated software package.."
In-Reply-To: <2E17292A64E6ED418A60BE89326B1AAB664475@msgebe11.mfad.mfroot.org>
References: <4669617F.8090405@med.unibs.it> <46697EF3.5000502@vanderbilt.edu>
	<2E17292A64E6ED418A60BE89326B1AAB664475@msgebe11.mfad.mfroot.org>
Message-ID: <200706091744.48430.blindglobe@gmail.com>

You've just opened up another bit of confusion.   A submission package has 
many pieces, and that cited one is just a small part of it.

As Frank has mentioned (though perhaps tritely), and Cody points out -- 

The only issue that a Pharma has to worry about is whether they know enough 
about a software language/application to trust it.  Period.  There are 
incantations and approaches for this, but working through a corporation of 
diverse skills and knowledge, to justify the use of a particular tool 
(whether it is statistical, legal, chemical, etc) with in the corporation, 
brings up the need to follow whatever implementation the company has done 
using the guidelines from FDA, EMEA, PMDA, etc...

But it's the company guidelines, and the company's due diligence that is 
important.

NOT the external view.   So the idea of computer systems validation, and the 
qualification of programming languages such as R and SAS is a good one, since 
it helps you understand where the weaknesses in computed results might be, 
for weighting results for internal decision making and knowledge management.

But much of it has to be done internally.  The side problem of "few people 
using S in clinical statistics" is related to the risks that a company has in 
having people that know about R, etc.  That is the practical issue, solvable 
when budgets exist and when it falls into strategy.

Sorry for getting on the soap-box, but I've just had a nasty week dealing with 
the results from  simplified bullet points which skip the major important 
complexities which were handled badly by decisions made using the summaries.  
Ugly, ugly nonsense.

And Computer Systems validation is a canonical area where the above paragraph 
holds.

best,
-tony.

On Friday 08 June 2007, Sicotte, Hugues Ph.D. wrote:
> I may have overstated  things a bit.
>
> See section VIII
> http://www.fda.gov/CDER/GUIDANCE/2396dft.htm
>
> If you are analyzing data your statistical package does not necessarely
> have to be validated. You may have to show that the statistical methods
> are adequate/appropriate or that the results are reproduced with
> different softwares if you are using non-standard packages. By all
> tests, S-plus appears acceptable, do not know about R.
>
> However, If your statistical method is an intricate part of a test, then
> you do have to validate the system.
> This is becoming increasingly relevant for theragnostics.
>
> .. Which is why I said
> "Should they need to use those results in a report [where] that will
> matter to the FDA.."
> (I added the where .. It makes more sense)
>
>
>
> -----Original Message-----
> From: Frank E Harrell Jr [mailto:f.harrell at vanderbilt.edu]
> Sent: Friday, June 08, 2007 11:08 AM
> To: Sicotte, Hugues Ph.D.
> Cc: Wensui Liu; Giovanni Parrinello; r-help at stat.math.ethz.ch
> Subject: Re: [R] "R is not a validated software package.."
>
> Sicotte, Hugues Ph.D. wrote:
> > People, don't get angry at the pharma statistician, he is just trying
>
> to
>
> > abide by an FDA requirement that is designed to insure that test
>
> perform
>
> > reliably the same. There is no point in getting into which product is
> > better. As far as the FDA rules are concerned a validated system beats
>
> a
>
> > "better" system any day of the week.
>
> There is no such requirement.
>
> > Here is your polite answer.
> > You can develop and try your software in R.
> > Should they need to use those results in a report that will matter to
> > the FDA, then you can work together with him to set up a validated
> > environment for S-plus. You then have to commit to port your code to
> > S-plus.
>
> That doesn't follow.  What matters is good statistical analysis practice
>
> no matter which environment you use.  Note that more errors are made in
> the data preparation / derived variables stage than are made by
> statistical software.
>
> Frank
>
> > As I assume that you do not work in a regulated environment, you
> > probably wouldn't have access to a validated SAS environment anyways.
>
> It
>
> > is not usually enough to install a piece of software, you have to
> > validate every step of the installation. Since AFAIK the FDA uses
> > S-plus, it would be to your pharma person's advantage to speed-up
> > submissions if they also had a validated S-plus environment.
>
> http://www.msmiami.com/custom/downloads/S-PLUSValidationdatasheet_Final.
>
> > pdf
> >
> >
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Wensui Liu
> > Sent: Friday, June 08, 2007 9:24 AM
> > To: Giovanni Parrinello
> > Cc: r-help at stat.math.ethz.ch
> > Subject: Re: [R] "R is not a validated software package.."
> >
> > I like to know the answer as well.
> > To be honest, I really have hard time to understand the mentality of
> > clinical trial guys and rather believe it is something related to job
> > security.
> >
> > On 6/8/07, Giovanni Parrinello <parrinel at med.unibs.it> wrote:
> >> Dear All,
> >> discussing with a statistician of a pharmaceutical company I received
> >> this answer about the statistical package that I have planned to use:
> >>
> >> As R is not a validated software package, we would like to ask if it
> >> would rather be possible for you to use SAS, SPSS or another approved
> >> statistical software system.
> >>
> >> Could someone suggest me a 'polite' answer?
> >> TIA
> >> Giovanni
> >>
> >> --
> >> dr. Giovanni Parrinello
> >> External Lecturer
> >> Medical Statistics Unit
> >> Department of Biomedical Sciences
> >> Viale Europa, 11 - 25123 Brescia Italy
> >> Tel: +390303717528
> >> Fax: +390303717488
> >> email: parrinel at med.unibs.it
> >>
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at stat.math.ethz.ch mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >
> > http://www.R-project.org/posting-guide.html
> >
> >> and provide commented, minimal, self-contained, reproducible code.



-- 
best,
-tony

blindglobe at gmail.com
Muttenz, Switzerland.
"Commit early,commit often, and commit in a repository from which we can 
easily
roll-back your mistakes" (AJR, 4Jan05).
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: This is a digitally signed message part.
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20070609/6fb82306/attachment.bin 

From shiazy at gmail.com  Sat Jun  9 18:57:56 2007
From: shiazy at gmail.com (Shiazy Fuzzy)
Date: Sat, 9 Jun 2007 18:57:56 +0200
Subject: [R] What ECDF function?
Message-ID: <9d3ef91d0706090957i6440187auf13a46ed5b556912@mail.gmail.com>

Hello!

I want to plot a P-P plot. So I've implemented this function:

ppplot <- function(x,dist,...)
{
  pdf <- get(paste("p",dist,sep=""),mode="function");
  x <- sort(x);
  plot( pdf(x,...),  ecdf(x)(x));
}

I have two questions:
1. Is it right to draw as reference line the following:

    xx <- pdf(x,...);
    yy <- ecdf(x)(x);
    l <- lm(  yy ~ xx )
    abline( l$coefficients );

  or what else is better?

2.I found various version of P-P plot  where instead of using the
"ecdf" function use ((1:n)-0.5)/n
  After investigation I found there're different definition of ECDF
(note "i" is the rank):
  * Kaplan-Meier: i/n
  * modified Kaplan-Meier: (i-0.5)/n
  * Median Rank: (i-0.3)/(n+0.4)
  * Herd Johnson i/(n+1)
  * ...
  Furthermore, similar expressions are used by "ppoints".
  So,
  2.1 For P-P plot, what shall I use?
  2.2 In general why should I prefer one kind of CDF over another one?

  (Note: this issue might also apply to Q-Q plot, infact qqnorm use
ppoints instead of ecdf)

Thank you very much!!

Sincerely,

-- Marco


From adschai at optonline.net  Sat Jun  9 19:39:05 2007
From: adschai at optonline.net (adschai at optonline.net)
Date: Sat, 09 Jun 2007 17:39:05 +0000 (GMT)
Subject: [R] How to plot vertical line
Message-ID: <e3c3a44b4b0.466ae5b9@optonline.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070609/2d31934f/attachment.pl 

From jrkrideau at yahoo.ca  Sat Jun  9 20:12:30 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Sat, 9 Jun 2007 14:12:30 -0400 (EDT)
Subject: [R] Lines in dotchart & dotplot ?
Message-ID: <752272.16499.qm@web32807.mail.mud.yahoo.com>

Is it possible to use dotchart or dotplot and set the
lines in such a way that they only extend from the
left y-axis to the data point?  

I seem to remember that Wm Cleveland did this in his
1985 book  "The elements of graphing data".

In cases where one has a true starting or O point on
the x-scale this layout seems to be very effective in
displaying some data. 

I know that I can do it by simple ploting lines and
points but a more polished function than I am likely
to produce would be nice.

Thanks


From deepayan.sarkar at gmail.com  Sat Jun  9 20:36:32 2007
From: deepayan.sarkar at gmail.com (deepayan.sarkar at gmail.com)
Date: Sat, 9 Jun 2007 11:36:32 -0700
Subject: [R] Lines in dotchart & dotplot ?
In-Reply-To: <752272.16499.qm@web32807.mail.mud.yahoo.com>
References: <752272.16499.qm@web32807.mail.mud.yahoo.com>
Message-ID: <eb555e660706091136l3f6ea07du1a8fa76f65da7547@mail.gmail.com>

On 6/9/07, John Kane <jrkrideau at yahoo.ca> wrote:
> Is it possible to use dotchart or dotplot and set the
> lines in such a way that they only extend from the
> left y-axis to the data point?

Yes (sort of) in dotplot at least. E.g.,

dotplot(VADeaths, groups = FALSE, type = c("p", "h"))
dotplot(VADeaths, groups = FALSE, type = c("p", "h"), origin = 0)

-Deepayan

> I seem to remember that Wm Cleveland did this in his
> 1985 book  "The elements of graphing data".
>
> In cases where one has a true starting or O point on
> the x-scale this layout seems to be very effective in
> displaying some data.
>
> I know that I can do it by simple ploting lines and
> points but a more polished function than I am likely
> to produce would be nice.
>
> Thanks
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ral at lcfltd.com  Sat Jun  9 22:26:09 2007
From: ral at lcfltd.com (Robert A LaBudde)
Date: Sat, 09 Jun 2007 16:26:09 -0400
Subject: [R] What ECDF function?
In-Reply-To: <9d3ef91d0706090957i6440187auf13a46ed5b556912@mail.gmail.co m>
References: <9d3ef91d0706090957i6440187auf13a46ed5b556912@mail.gmail.com>
Message-ID: <0JJD0072TY3QKAF0@vms048.mailsrvcs.net>

At 12:57 PM 6/9/2007, Marco wrote:
><snip>
>2.I found various version of P-P plot  where instead of using the
>"ecdf" function use ((1:n)-0.5)/n
>   After investigation I found there're different definition of ECDF
>(note "i" is the rank):
>   * Kaplan-Meier: i/n
>   * modified Kaplan-Meier: (i-0.5)/n
>   * Median Rank: (i-0.3)/(n+0.4)
>   * Herd Johnson i/(n+1)
>   * ...
>   Furthermore, similar expressions are used by "ppoints".
>   So,
>   2.1 For P-P plot, what shall I use?
>   2.2 In general why should I prefer one kind of CDF over another one?
><snip>

This is an age-old debate in statistics. There are many different 
formulas, some of which are optimal for particular distributions.

Using i/n (which I would call the Kolmogorov method), (i-1)/n or 
i/(n+1) is to be discouraged for general ECDF modeling. These 
correspond in quality to the rectangular rule method of integration 
of the bins, and assume only that the underlying density function is 
piecewise constant. There is no disadvantage to using these methods, 
however, if the pdf has multiple discontinuities.

I tend to use (i-0.5)/n, which corresponds to integrating with the 
"midpoint rule", which is a 1-point Gaussian quadrature, and which is 
exact for linear behavior with derivative continuous. It's simple, 
it's accurate, and it is near optimal for a wide range of continuous 
alternatives.

The formula (i- 3/8)/(n + 1/4) is optimal for the normal 
distribution. However, it is equal to (i-0.5)/n to order 1/n^3, so 
there is no real benefit to using it. Similarly, there is a formula 
(i-.44)/(N+.12) for a Gumbel distribution. If you do know for sure 
(don't need to test) the form of the distribution, you're better off 
fitting that distribution function directly and not worrying about the edf.

Also remember that edfs are not very accurate, so the differences 
between these formulae are difficult to justify in practice.

================================================================
Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
824 Timberlake Drive                     Tel: 757-467-0954
Virginia Beach, VA 23464-3239            Fax: 757-467-2947

"Vere scire est per causas scire"


From mothsailor at googlemail.com  Sat Jun  9 22:38:46 2007
From: mothsailor at googlemail.com (David Barron)
Date: Sat, 9 Jun 2007 21:38:46 +0100
Subject: [R] How to plot vertical line
In-Reply-To: <e3c3a44b4b0.466ae5b9@optonline.net>
References: <e3c3a44b4b0.466ae5b9@optonline.net>
Message-ID: <815b70590706091338y23310f3fy7f9e7802eeb6c32@mail.gmail.com>

abline(v=c(intercept1,intercept2,intercept3))

On 09/06/07, adschai at optonline.net <adschai at optonline.net> wrote:
> Hi,I have a result from polr which I fit a univariate variable (of ordinal data) with probit function. What I would like to do is to overlay the plot of my fitted values with the different intercept for each level in my ordinal data. I can do something like:lines(rep(intercept1, 1000), seq(from=0,to=max(fit),by=max(fit)/1000))where my intercept1 is, for example, the intercept that breaks between y=1 and y=2 labels and the max(fit) is the maximum of overall fitted values or maximum of all ordinal y labels. I'm wondering if there is better way to do this? If you could let me know, I would really appreciated. Thank you.- adschai
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
=================================
David Barron
Said Business School
University of Oxford
Park End Street
Oxford OX1 1HP


From hassen62 at voila.fr  Sat Jun  9 22:50:55 2007
From: hassen62 at voila.fr (hassen62 at voila.fr)
Date: Sat,  9 Jun 2007 22:50:55 +0200 (CEST)
Subject: [R] problem with xlsreadwrite package
Message-ID: <11273019.255531181422255805.JavaMail.www@wwinf4001>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070609/34652766/attachment.pl 

From shiazy at gmail.com  Sun Jun 10 00:36:05 2007
From: shiazy at gmail.com (Shiazy Fuzzy)
Date: Sun, 10 Jun 2007 00:36:05 +0200
Subject: [R] What ECDF function?
In-Reply-To: <0JJD0072TY3QKAF0@vms048.mailsrvcs.net>
References: <9d3ef91d0706090957i6440187auf13a46ed5b556912@mail.gmail.com>
	<0JJD0072TY3QKAF0@vms048.mailsrvcs.net>
Message-ID: <9d3ef91d0706091536o4f2d94f6p9dc93759ae564b7c@mail.gmail.com>

On 6/9/07, Robert A LaBudde <ral at lcfltd.com> wrote:
> At 12:57 PM 6/9/2007, Marco wrote:
> ><snip>
> >2.I found various version of P-P plot  where instead of using the
> >"ecdf" function use ((1:n)-0.5)/n
> >   After investigation I found there're different definition of ECDF
> >(note "i" is the rank):
> >   * Kaplan-Meier: i/n
> >   * modified Kaplan-Meier: (i-0.5)/n
> >   * Median Rank: (i-0.3)/(n+0.4)
> >   * Herd Johnson i/(n+1)
> >   * ...
> >   Furthermore, similar expressions are used by "ppoints".
> >   So,
> >   2.1 For P-P plot, what shall I use?
> >   2.2 In general why should I prefer one kind of CDF over another one?
> ><snip>
>
> This is an age-old debate in statistics. There are many different
> formulas, some of which are optimal for particular distributions.
>
> Using i/n (which I would call the Kolmogorov method), (i-1)/n or
> i/(n+1) is to be discouraged for general ECDF modeling. These
> correspond in quality to the rectangular rule method of integration
> of the bins, and assume only that the underlying density function is
> piecewise constant. There is no disadvantage to using these methods,
> however, if the pdf has multiple discontinuities.
>
> I tend to use (i-0.5)/n, which corresponds to integrating with the
> "midpoint rule", which is a 1-point Gaussian quadrature, and which is
> exact for linear behavior with derivative continuous. It's simple,
> it's accurate, and it is near optimal for a wide range of continuous
> alternatives.
>

Hmmm I'm a bit confused, but very interested!
So you don't use the R "ecdf", do you?

> The formula (i- 3/8)/(n + 1/4) is optimal for the normal
> distribution. However, it is equal to (i-0.5)/n to order 1/n^3, so
> there is no real benefit to using it. Similarly, there is a formula
> (i-.44)/(N+.12) for a Gumbel distribution. If you do know for sure
> (don't need to test) the form of the distribution, you're better off
> fitting that distribution function directly and not worrying about the edf.
>
> Also remember that edfs are not very accurate, so the differences
> between these formulae are difficult to justify in practice.
>

I will bear in min! My first interpretation was that using some
different from i/n (e.g. i/(n+1)),
let to better individuate tail differences (maybe...)

Regards,

-- Marco

> ================================================================
> Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
> Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
> 824 Timberlake Drive                     Tel: 757-467-0954
> Virginia Beach, VA 23464-3239            Fax: 757-467-2947
>
> "Vere scire est per causas scire"
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From irishhacker at gmail.com  Sun Jun 10 03:38:51 2007
From: irishhacker at gmail.com (Robert Wilkins)
Date: Sat, 9 Jun 2007 20:38:51 -0500
Subject: [R] Tools For Preparing Data For Analysis
In-Reply-To: <6BB2732B-E656-4A61-8D09-8C5D5EFC5AA4@MUOhio.edu>
References: <874da0b40706071701m55cd42fem15f55a8fcde04f17@mail.gmail.com>
	<40e66e0b0706080547o5c630ac3ne5feadc4247e289a@mail.gmail.com>
	<6BB2732B-E656-4A61-8D09-8C5D5EFC5AA4@MUOhio.edu>
Message-ID: <874da0b40706091838i7f390997y6ad396d6f0aa0843@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070609/284653b0/attachment.pl 

From ggrothendieck at gmail.com  Sun Jun 10 04:16:46 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 9 Jun 2007 22:16:46 -0400
Subject: [R] Tools For Preparing Data For Analysis
In-Reply-To: <874da0b40706091838i7f390997y6ad396d6f0aa0843@mail.gmail.com>
References: <874da0b40706071701m55cd42fem15f55a8fcde04f17@mail.gmail.com>
	<40e66e0b0706080547o5c630ac3ne5feadc4247e289a@mail.gmail.com>
	<6BB2732B-E656-4A61-8D09-8C5D5EFC5AA4@MUOhio.edu>
	<874da0b40706091838i7f390997y6ad396d6f0aa0843@mail.gmail.com>
Message-ID: <971536df0706091916i1c36a5cfp1c5d8f0f51205092@mail.gmail.com>

That can be  elegantly handled in R through R's object oriented programming
by defining a class for the fancy input.  See this post:
  https://stat.ethz.ch/pipermail/r-help/2007-April/130912.html
for a simple example of that style.


On 6/9/07, Robert Wilkins <irishhacker at gmail.com> wrote:
> Here are some examples of the type of data crunching you might have to do.
>
> In response to the requests by Christophe Pallier and Martin Stevens.
>
> Before I started developing Vilno, some six years ago, I had been working in
> the pharmaceuticals for eight years ( it's not easy to show you actual data
> though, because it's all confidential of course).
>
> Lab data can be especially messy, especially if one clinical trial allows
> the physicians to use different labs. So let's consider lab data.
>
> Merge in normal ranges, into the lab data. This has to be done by lab-site
> and lab testcode(PLT for platelets, etc.), obviously. I've seen cases where
> you also need to match by sex and age. The sex column in the normal ranges
> could be: blank, F, M, or B ( B meaning for Both sexes). The age column in
> the normal ranges could be: blank, or something like "40 <55". Even worse,
> you could have an ageunits column in the normal ranges dataset: usually "Y",
> but if there are children in the clinical trial, you will have "D" or "M",
> for Days and Months. If the clinical trial is for adults, all rows with "D"
> or "M" should be tossed out at the start. Clearly the statistical programmer
> has to spend time looking at the data, before writing the program. Remember,
> all of these details can change any time you move to a new clinical trial.
>
> So for the lab data, you have to merge in the patient's date of birth,
> calculate age, and somehow relate that to the age-group column in the normal
> ranges dataset.
>
> (By the way, in clinical trial data preparation, the SAS datastep is much
> more useful and convenient, in my opinion, than the SQL SELECT syntax, at
> least 97% of the time. But in the middle of this program, when you merge the
> normal ranges into the lab data, you get a better solution with PROC SQL (
> just the SQL SELECT statement implemented inside SAS) This is because of the
> trickiness of the age match-up, and the SAS datastep does not do well with
> many-to-many joins.).
>
> Merge in various study drug administration dates into the lab data. Now, for
> each lab record, calculate treatment period ( or cycle number ), depending
> on the statistician's specifications and the way the clinical trial is
> structured.
>
> Different clinical sites chose to use different lab providers. So, for
> example, for Monocytes, you have 10 different units ( essentially 6 units,
> but spelling inconsistencies as well). The statistician has requested that
> you use standardized units in some of the listings ( % units, and only one
> type of non-% unit, for example ). At the same time, lab values need to be
> converted ( *1.61 , divide by 1000, etc. ). This can be very time consuming
> no matter what software you use, and, in my experience, when the SAS
> programmer asks for more clinical information or lab guidebooks, the
> response is incomplete, so he does a lot of guesswork. SAS programmers do
> not have expertise in lab science, hence the guesswork.
>
> Your program has to accomodate numeric values, "1.54" , quasi-numeric values
> "<1" , and non-numeric values "Trace".
>
> Your data listing is tight for space, so print "PROLONGED CELL CONT" as
> "PRCC".
>
> Once normal ranges are merged in, figure out which values are out-of-range
> and high , which are low, and which are within normal range. In the data
> listing, you may have "H" or "L" appended to the result value being printed.
>
> For each treatment period, you may need a unique lab record selected, in
> case there are two or three for the same treatment period. The statistician
> will tell the SAS programmer how. Maybe the averages of the results for that
> treatment period, maybe that lab record closest to the mid-point of of the
> treatment period. This isn't for the data listing, but for a summary table.
>
> For the differentials ( monocytes, lymphocytes, etc) , merge in the WBC
> (total white blood cell count) values , to convert values between % units
> and absolute count units.
>
> When printing the values in the data listing, you need "H" or "L" to the
> right of the value. But you also need the values to be well lined up ( the
> decimal place ). This can be stupidly time consuming.
>
>
>
> AND ON AND ON AND ON .....
>
> I think you see why clinical trials statisticians and SAS programmers enjoy
> lots of job security.

This could be readily handled in R using object oriented programming.
You would specify a class for the strange input,


From ral at lcfltd.com  Sun Jun 10 04:23:21 2007
From: ral at lcfltd.com (Robert A LaBudde)
Date: Sat, 09 Jun 2007 22:23:21 -0400
Subject: [R] What ECDF function?
In-Reply-To: <9d3ef91d0706091536o4f2d94f6p9dc93759ae564b7c@mail.gmail.co m>
References: <9d3ef91d0706090957i6440187auf13a46ed5b556912@mail.gmail.com>
	<0JJD0072TY3QKAF0@vms048.mailsrvcs.net>
	<9d3ef91d0706091536o4f2d94f6p9dc93759ae564b7c@mail.gmail.com>
Message-ID: <0JJE007JREN2K2Y0@vms048.mailsrvcs.net>

At 06:36 PM 6/9/2007, Marco wrote:
>On 6/9/07, Robert A LaBudde <ral at lcfltd.com> wrote:
> > At 12:57 PM 6/9/2007, Marco wrote:
> > ><snip>
><snip>
>
>Hmmm I'm a bit confused, but very interested!
>So you don't use the R "ecdf", do you?

Only when an i/n edf is needed (some tests, such as ks.test() are 
based on this). Also, I frequently do modeling in Excel as well, 
where you need to enter your own formulas.

><snip>
> > Also remember that edfs are not very accurate, so the differences
> > between these formulae are difficult to justify in practice.
> >
>
>I will bear in min! My first interpretation was that using some
>different from i/n (e.g. i/(n+1)), let to better individuate tail 
>differences (maybe...)

The chief advantage to i/(n+1) is that you don't generate 1.0 as an 
abscissa, as you do with i/n. But the same is true of (i-0.5)/n, and 
it's more accurate.

Unless you need to do otherwise, just use ecdf(), because it matches 
the theory for most uses, and it almost always doesn't matter that 
it's slightly less accurate than other choices.

================================================================
Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
824 Timberlake Drive                     Tel: 757-467-0954
Virginia Beach, VA 23464-3239            Fax: 757-467-2947

"Vere scire est per causas scire"


From gallon.li at gmail.com  Sun Jun 10 08:13:03 2007
From: gallon.li at gmail.com (gallon li)
Date: Sun, 10 Jun 2007 14:13:03 +0800
Subject: [R] comparing two vectors
Message-ID: <54f7e7c30706092313q2a657ebs99631ab0a3014a02@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070610/483c6885/attachment.pl 

From wht_crl at yahoo.com  Sun Jun 10 08:45:55 2007
From: wht_crl at yahoo.com (carol white)
Date: Sat, 9 Jun 2007 23:45:55 -0700 (PDT)
Subject: [R] penalized cox regression
Message-ID: <143100.79395.qm@web62010.mail.re1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070609/af18f23e/attachment.pl 

From h.wickham at gmail.com  Sun Jun 10 09:27:52 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 10 Jun 2007 09:27:52 +0200
Subject: [R] comparing two vectors
In-Reply-To: <54f7e7c30706092313q2a657ebs99631ab0a3014a02@mail.gmail.com>
References: <54f7e7c30706092313q2a657ebs99631ab0a3014a02@mail.gmail.com>
Message-ID: <f8e6ff050706100027h5caeb6afu1907ea4b671c8e57@mail.gmail.com>

On 6/10/07, gallon li <gallon.li at gmail.com> wrote:
> Suppose I have a vector A=c(1,2,3)
>
> now I want to compare each element of A to another vector L=c(0.5, 1.2)
>
> and then recode values for sum(A>0.5) and sum(A>1.2)
>
> to get a result of (3,2)
>
> how can I get this without writing a loop of sums?

How about colSums(outer(A, L, ">"))

Hadley


From ted.harding at nessie.mcc.ac.uk  Sun Jun 10 10:28:30 2007
From: ted.harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sun, 10 Jun 2007 09:28:30 +0100 (BST)
Subject: [R] Tools For Preparing Data For Analysis
In-Reply-To: <971536df0706091916i1c36a5cfp1c5d8f0f51205092@mail.gmail.com>
Message-ID: <XFMail.070610092830.ted.harding@nessie.mcc.ac.uk>

On 10-Jun-07 02:16:46, Gabor Grothendieck wrote:
> That can be elegantly handled in R through R's object
> oriented programming by defining a class for the fancy input.
> See this post:
>   https://stat.ethz.ch/pipermail/r-help/2007-April/130912.html
> for a simple example of that style.
> 
> On 6/9/07, Robert Wilkins <irishhacker at gmail.com> wrote:
>> Here are some examples of the type of data crunching you might
>> have to do.
>>
>> In response to the requests by Christophe Pallier and Martin Stevens.
>>
>> Before I started developing Vilno, some six years ago, I had
>> been working in the pharmaceuticals for eight years ( it's not
>> easy to show you actual data though, because it's all confidential
>> of course).

I hadn't heard of Vilno before (except as a variant of "Vilnius").
And it seems remarkably hard to find info about it from a Google
search. The best I've come up with, searching on

  vilno  data

is at
  http://www.xanga.com/datahelper

This is a blog site, apparently with postings by Robert Wilkins.

At the end of the Sunday, September 17, 2006 posting "Tedious
coding at the Pharmas" is a link:

  "I have created a new data crunching programming language."
   http://www.my.opera.com/datahelper

which appears to be totally empty. In another blog article:

  "go to the www.my.opera.com/datahelper site, go to the August 31
   blog article, and there you will find a tarball-file to download,
   called vilnoAUG2006package.tgz"

so again inaccessible; and a google on "vilnoAUG2006package.tgz"
gives a single hit which is simply the same aricle.

In the Xanga blog there are a few examples of tasks which are
no big deal in any programming language (and, relative to their
simplicity, appear a bit cumbersome in "Vilno"). 

I've not seen in the blog any instance of data transformation
which could not be quite easily done in any straigthforward
language (even awk).

>> Lab data can be especially messy, especially if one clinical
>> trial allows the physicians to use different labs. So let's
>> consider lab data.
>> [...]

That's a fairly daunting description, though indeed not at all
extreme for the sort of data that can arise in practice (and
not just in pharmaceutical investigations). But the complexity
is in the situation, and, whatever language you use, the writing
of the program will involve the writer getting to grips with
the complexity, and the complexity will be present in the code
simply because of the need to accomodate all the special cases,
exceptions and faults that have to be anticipated in "feral" data.

Once these have been anticipated and incorporated in the code,
the actual transformations are again no big deal.

Frankly, I haven't yet seen anything "Vilno" that couldn't be
accomodated in an 'awk' program. Not that I'm advocating awk for
universal use (I'm not that monolithic about it). But I'm using
it as my favourite example of a flexible, capable, transparent
and efficient data filtering language, as far as it goes.


SO: where can one find out more about Vilno, to see what it may
really be capable of that can not be done so easily in other ways?


(As is implicit in many comments in Robert's blog, and indeed also
from many postings to this list over time and undoubtedly well
known to many of us in practice, a lot of the problems with data
files arise at the data gathering and entry stages, where people
can behave as if stuffing unpaired socks and unattributed underwear
randomly into a drawer, and then banging it shut).

Best wishes to all,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 10-Jun-07                                       Time: 09:28:10
------------------------------ XFMail ------------------------------


From sabya23 at gmail.com  Sun Jun 10 10:44:42 2007
From: sabya23 at gmail.com (spime)
Date: Sun, 10 Jun 2007 01:44:42 -0700 (PDT)
Subject: [R] Coding categorical variables in mixed environment
Message-ID: <11046822.post@talk.nabble.com>


Hi R users,

Suppose we have following data for a regression model:

AGE:numerical
SEX: male/female categorical
COLOR: {blue, green, pink} categorical
RESPONSE: yes/no categorical

AGE      SEX      COLOR      RESPONSE
10         M          BLUE         Y
12         M          GREEN       N
13         F           PINK         Y
11         M          BLUE         Y
13         M          GREEN       N
09         F           GREEN       N
15         F           BLUE         Y
11         F           PINK          Y
12         M          PINK          N
14         M          GREEN        N

I want to code the categorical data as {male =1, female =2}, {blue =1, green
=2, pink = 3} {yes =1, no =0} and finally get the new table.

how can i do this?

waiting for reply. Thanks in advance.

bye

 
-- 
View this message in context: http://www.nabble.com/Coding-categorical-variables-in-mixed-environment-tf3896721.html#a11046822
Sent from the R help mailing list archive at Nabble.com.


From gallon.li at gmail.com  Sun Jun 10 10:45:58 2007
From: gallon.li at gmail.com (gallon li)
Date: Sun, 10 Jun 2007 16:45:58 +0800
Subject: [R] find position
Message-ID: <54f7e7c30706100145tbc893bawb79f43bed1af0d64@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070610/e20ae4b3/attachment.pl 

From bcarvalh at jhsph.edu  Sun Jun 10 10:51:56 2007
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Sun, 10 Jun 2007 04:51:56 -0400
Subject: [R] find position
In-Reply-To: <54f7e7c30706100145tbc893bawb79f43bed1af0d64@mail.gmail.com>
References: <54f7e7c30706100145tbc893bawb79f43bed1af0d64@mail.gmail.com>
Message-ID: <46C527E6-ECE9-461C-8802-B5B757317F60@jhsph.edu>

which(a == .4)[1]

b

On Jun 10, 2007, at 4:45 AM, gallon li wrote:

> find the position of the first value who equals certain number in a  
> vector:
>
> Say a=c(0,0,0,0,0.2, 0.2, 0.4,0.4,0.5)
>
> i wish to return the index value in a for which the value in the  
> vector is
> equal to 0.4 for the first time. in this case, it is 7.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Dimitris.Rizopoulos at med.kuleuven.be  Sun Jun 10 10:58:49 2007
From: Dimitris.Rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Sun, 10 Jun 2007 10:58:49 +0200
Subject: [R] find position
In-Reply-To: <54f7e7c30706100145tbc893bawb79f43bed1af0d64@mail.gmail.com>
References: <54f7e7c30706100145tbc893bawb79f43bed1af0d64@mail.gmail.com>
Message-ID: <20070610105849.eb3hbm026b34oc48@webmail5.kuleuven.be>

try this:

which(a == 0.4)[1]


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://med.kuleuven.be/biostat/
      http://www.student.kuleuven.be/~m0390867/dimitris.htm


Quoting gallon li <gallon.li at gmail.com>:

> find the position of the first value who equals certain number in a vector:
>
> Say a=c(0,0,0,0,0.2, 0.2, 0.4,0.4,0.5)
>
> i wish to return the index value in a for which the value in the vector is
> equal to 0.4 for the first time. in this case, it is 7.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>



Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm


From p.dalgaard at biostat.ku.dk  Sun Jun 10 12:25:35 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sun, 10 Jun 2007 12:25:35 +0200
Subject: [R] Tools For Preparing Data For Analysis
In-Reply-To: <40e66e0b0706080547o5c630ac3ne5feadc4247e289a@mail.gmail.com>
References: <874da0b40706071701m55cd42fem15f55a8fcde04f17@mail.gmail.com>
	<40e66e0b0706080547o5c630ac3ne5feadc4247e289a@mail.gmail.com>
Message-ID: <466BD19F.4020903@biostat.ku.dk>

Douglas Bates wrote:
> Frank Harrell indicated that it is possible to do a lot of difficult
> data transformation within R itself if you try hard enough but that
> sometimes means working against the S language and its "whole object"
> view to accomplish what you want and it can require knowledge of
> subtle aspects of the S language.
>   
Actually, I think Frank's point was subtly different: It is *because* of 
the differences in view that it sometimes seems difficult to find the 
way to do something in R that  is apparently straightforward in SAS. 
I.e. the solutions exist and are often elegant, but may require some 
lateral thinking.

Case in point: Finding the first or the last observation for each 
subject when there are multiple records for each subject. The SAS way 
would be a datastep with IF-THEN-DELETE, and a RETAIN statement so that 
you can compare the subject ID with the one from the previous record, 
working with data that are sorted appropriately.

You can do the same thing in R with a for loop, but there are better 
ways e.g.
subset(df,!duplicated(ID)), and subset(df, rev(!duplicated(rev(ID))), or 
maybe
do.call("rbind",lapply(split(df,df$ID), head, 1)), resp. tail. Or 
something involving aggregate(). (The latter approaches generalize 
better to other within-subject functionals like cumulative doses, etc.).

The hardest cases that I know of are the ones where you need to turn one 
record into many, such as occurs in survival analysis with 
time-dependent, piecewise constant covariates. This may require 
"transposing the problem", i.e. for each  interval you find out which 
subjects contribute and with what, whereas the SAS way would be a 
within-subject loop over intervals containing an OUTPUT statement.

Also, there are some really weird data formats, where e.g. the input 
format is different in different records. Back in the 80's where 
punched-card input was still common, it was quite popular to have one 
card with background information on a patient plus several cards 
detailing visits, and you'd get a stack of cards containing both kinds. 
In R you would most likely split on the card type using grep() and then 
read the two kinds separately and merge() them later.


From jrkrideau at yahoo.ca  Sun Jun 10 12:26:59 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Sun, 10 Jun 2007 06:26:59 -0400 (EDT)
Subject: [R] Coding categorical variables in mixed environment
In-Reply-To: <11046822.post@talk.nabble.com>
Message-ID: <519299.28132.qm@web32804.mail.mud.yahoo.com>

try ?recode in package:car

--- spime <sabya23 at gmail.com> wrote:

> 
> Hi R users,
> 
> Suppose we have following data for a regression
> model:
> 
> AGE:numerical
> SEX: male/female categorical
> COLOR: {blue, green, pink} categorical
> RESPONSE: yes/no categorical
> 
> AGE      SEX      COLOR      RESPONSE
> 10         M          BLUE         Y
> 12         M          GREEN       N
> 13         F           PINK         Y
> 11         M          BLUE         Y
> 13         M          GREEN       N
> 09         F           GREEN       N
> 15         F           BLUE         Y
> 11         F           PINK          Y
> 12         M          PINK          N
> 14         M          GREEN        N
> 
> I want to code the categorical data as {male =1,
> female =2}, {blue =1, green
> =2, pink = 3} {yes =1, no =0} and finally get the
> new table.
> 
> how can i do this?
> 
> waiting for reply. Thanks in advance.
> 
> bye
> 
>  
> -- 
> View this message in context:
>
http://www.nabble.com/Coding-categorical-variables-in-mixed-environment-tf3896721.html#a11046822
> Sent from the R help mailing list archive at
> Nabble.com.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From ggrothendieck at gmail.com  Sun Jun 10 12:49:27 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 10 Jun 2007 06:49:27 -0400
Subject: [R] find position
In-Reply-To: <54f7e7c30706100145tbc893bawb79f43bed1af0d64@mail.gmail.com>
References: <54f7e7c30706100145tbc893bawb79f43bed1af0d64@mail.gmail.com>
Message-ID: <971536df0706100349j6e9a5edco3adb5473915fe335@mail.gmail.com>

Try

match(0.4, a)

Also see ?match and the nomatch= argument, in particular. If your
numbers are only equal to within an absolute tolerance, tol, as
discussed in the R FAQ
   http://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f
you may need:

   tol <- 1e-6
   match(TRUE, abs(a-0.4) < tol)

or

   which(abs(a-0.4) < tol)[1]  # tol from above

and analogously if a relative tolerance is required.

On 6/10/07, gallon li <gallon.li at gmail.com> wrote:
> find the position of the first value who equals certain number in a vector:
>
> Say a=c(0,0,0,0,0.2, 0.2, 0.4,0.4,0.5)
>
> i wish to return the index value in a for which the value in the vector is
> equal to 0.4 for the first time. in this case, it is 7.
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From sarah.goslee at gmail.com  Sun Jun 10 16:04:44 2007
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Sun, 10 Jun 2007 10:04:44 -0400
Subject: [R] Tools For Preparing Data For Analysis
In-Reply-To: <XFMail.070610092830.ted.harding@nessie.mcc.ac.uk>
References: <971536df0706091916i1c36a5cfp1c5d8f0f51205092@mail.gmail.com>
	<XFMail.070610092830.ted.harding@nessie.mcc.ac.uk>
Message-ID: <efb536d50706100704yd56cd83r74d6d953f4ea2d00@mail.gmail.com>

On 6/10/07, Ted Harding <ted.harding at nessie.mcc.ac.uk> wrote:

> ... a lot of the problems with data
> files arise at the data gathering and entry stages, where people
> can behave as if stuffing unpaired socks and unattributed underwear
> randomly into a drawer, and then banging it shut.

Not specifically R-related, but this would make a great fortune.

Sarah
-- 
Sarah Goslee
http://www.functionaldiversity.org


From r.nieuwenhuis at student.ru.nl  Sun Jun 10 16:35:58 2007
From: r.nieuwenhuis at student.ru.nl (Rense Nieuwenhuis)
Date: Sun, 10 Jun 2007 16:35:58 +0200
Subject: [R] {nlme} Multilevel estimation heteroscedasticity
Message-ID: <93CCF428-8493-4716-908C-EFE87EDC48F9@student.ru.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070610/f4216c43/attachment.pl 

From r.h.koning at rug.nl  Sun Jun 10 17:34:36 2007
From: r.h.koning at rug.nl (R.H. Koning)
Date: Sun, 10 Jun 2007 17:34:36 +0200
Subject: [R] format.dates, chron and Hmisc
In-Reply-To: <465ED42B.2090808@cancer.org.uk>
References: <9202D193C49A974F9DC63C32B28918D0962467@EMEAMAIL01.PERKINELMER.NET>
	<465ED42B.2090808@cancer.org.uk>
Message-ID: <466C1A0C.2090903@rug.nl>

Hello, I have some problems in using chron, Hmisc, and lattice. First, 
using both chron and Hmisc, I get an error message when describing data:

df$Date <- chron(df$Date,format=c("d/m/y"))
 > ll <- latex(describe(df),file="..//text//df.tex")
Error in formatDateTime(dd, atx, !timeUsed) :
        could not find function "format.dates"

Then, using a chron object and lattice, I get

 > plot.a <- xyplot(theta~Date|team,data=op.df.long,
+  strip = function(bg, ...) strip.default(bg = 'transparent', ...),
+  panel=function(x,y,...){
+   panel.xyplot(x,y,cex=0.4,col="black",...)
+   panel.loess(x,y,span=0.3,col="black",...)
+   panel.abline(h=0)
+  })
 > print(plot.a)
Error in pretty(rng, ...) : unused argument(s) (format.posixt = NULL)

In both cases, the cron objects have been created using the function 
chron(). Are lattice and Hmisc functions incompatible with chron, or am 
I doing something else that causes these problems? Thanks, Ruud

 > sessionInfo()
R version 2.5.0 (2007-04-23)
i386-pc-mingw32

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
States.1252;LC_MONETARY=English_United 
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  
"methods"   "base"    

other attached packages:
     lattice         MASS        chron xlsReadWrite        Hmisc
    "0.15-4"     "7.2-33"     "2.3-11"      "1.3.2"      "3.3-2"


From alain.reymond at skynet.be  Sun Jun 10 18:09:56 2007
From: alain.reymond at skynet.be (Alain Reymond)
Date: Sun, 10 Jun 2007 18:09:56 +0200
Subject: [R] R logistic regression - comparison with SPSS
Message-ID: <466C2254.4010109@skynet.be>

Dear R-list members,

I have been a user of SPSS for a few years and quite new to R. I read
the documentation and tried samples but I have some problems to obtain
results for a logistic regression under R.

The following SPSS script

LOGISTIC REGRESSION  vir
    /METHOD = FSTEP(LR) d007 d008 d009 d010 d011 d012 d013 d014 d015
d016 d017 d018 d069 d072 d073
    /SAVE = PRED COOK SRESID
    /CLASSPLOT
    /PRINT = GOODFIT CI(95)
    /CRITERIA = PIN(.10) POUT(.10) ITERATE(40) CUT(.5) .

predicts vir (value 0 or 1) according to my parameters d007 to d073. It
gives me the parameters to retain in the logistic equation and the
intercept.
The calculation is made from a set of values of about 1.000 cases.

I have been unable to translate it with success under R. I would like to
check if I can obtain the same results than with SPSS. Can someone help
me translate it under R ? I would be most grateful.

I thank you.

Best regards.

-- 
Alain Reymond
CEIA
Bd Saint-Michel 119
1040 Bruxelles
Tel: +32 2 736 04 58
Fax: +32 2 736 58 02
PGPId :  0xEFB06E2E


From pwang at berkeley.edu  Sun Jun 10 18:24:46 2007
From: pwang at berkeley.edu (Patrick Wang)
Date: Sun, 10 Jun 2007 09:24:46 -0700 (PDT)
Subject: [R] How to specify the start position using plot
Message-ID: <51432.76.169.69.87.1181492686.squirrel@calmail.berkeley.edu>

Hi,

How to specify the start position of Y in plot command, hopefully I can
specify the range of X and Y axis. I checked the ?plot, it didnot mention
I can setup the range.


Thanks
Pat


From Charles.Annis at StatisticalEngineering.com  Sun Jun 10 18:38:25 2007
From: Charles.Annis at StatisticalEngineering.com (Charles Annis, P.E.)
Date: Sun, 10 Jun 2007 12:38:25 -0400
Subject: [R] How to specify the start position using plot
In-Reply-To: <51432.76.169.69.87.1181492686.squirrel@calmail.berkeley.edu>
References: <51432.76.169.69.87.1181492686.squirrel@calmail.berkeley.edu>
Message-ID: <04eb01c7ab7d$c4b5f7f0$6400a8c0@DD4XFW31>

plot( x=rnorm(25, 0.5, 0.3), y=rnorm(25, 4, 1), xlim=c(0,1), ylim=c(2,7)) 
#                                               ^^^^^        ^^^^^     
for example

Charles Annis, P.E.

Charles.Annis at StatisticalEngineering.com
phone: 561-352-9699
eFax:  614-455-3265
http://www.StatisticalEngineering.com
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Patrick Wang
Sent: Sunday, June 10, 2007 12:25 PM
To: r-help at stat.math.ethz.ch
Subject: [R] How to specify the start position using plot

Hi,

How to specify the start position of Y in plot command, hopefully I can
specify the range of X and Y axis. I checked the ?plot, it didnot mention
I can setup the range.


Thanks
Pat

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From chandra_bio at yahoo.com  Sun Jun 10 18:49:14 2007
From: chandra_bio at yahoo.com (Ranga Chandra Gudivada)
Date: Sun, 10 Jun 2007 09:49:14 -0700 (PDT)
Subject: [R] Feature selection for Clustering
Message-ID: <723774.35963.qm@web37207.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070610/f795e52e/attachment.pl 

From wuertz at itp.phys.ethz.ch  Sun Jun 10 18:49:42 2007
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Sun, 10 Jun 2007 18:49:42 +0200
Subject: [R] Rdonlp2 - an extension library for constrained optimization
In-Reply-To: <fddff77c0706070836ie2a9420jfaf18a9181cec046@mail.gmail.com>
References: <fddff77c0702122134u878f9ecg9b75208e964cc1e@mail.gmail.com>
	<fddff77c0706070836ie2a9420jfaf18a9181cec046@mail.gmail.com>
Message-ID: <466C2BA6.2090207@itp.phys.ethz.ch>

Ryuichi Tamura wrote:

Please can you put your package on the CRAN server ?

Many thanks
Diethelm Wuertz

> Hello R-list,
>
> I have released an update version (0.3-1) of Rdonlp2.
> Some (fatal) bugs which may kill interpreter should be fixed.
>
> In addition, user-visible changes are:
> * *.mes, *.pro files are not created if name=NULL(this is default) in donlp2().
> * use "machine-epsilon"s defined in R for internal
> calculations(step-size, etc.).
> * numeric hessian is now evaluated at the optimum and calculated with
>   the algorithm specified in 'difftype' in donlp2.control(). Setting
> difftype=2 will
>   produce (roughly) same value as optim() does.
>
> I sincerely appreciate users who sent me useful comments.
>
> Windows Binary, OSX Universal Binary, Source file are available at:
>
> http://arumat.net/Rdonlp2/
>
> Regards,
>
> TAMURA Ryuichi,
> mailto: ry.tamura at gmail.com
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


From chandra_bio at yahoo.com  Sun Jun 10 18:50:02 2007
From: chandra_bio at yahoo.com (Ranga Chandra Gudivada)
Date: Sun, 10 Jun 2007 09:50:02 -0700 (PDT)
Subject: [R] PCA  for Binary data
Message-ID: <238121.85415.qm@web37210.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070610/bb1b8375/attachment.pl 

From brown_emu at yahoo.com  Sun Jun 10 19:43:37 2007
From: brown_emu at yahoo.com (Stephen Tucker)
Date: Sun, 10 Jun 2007 10:43:37 -0700 (PDT)
Subject: [R] How to specify the start position using plot
In-Reply-To: <51432.76.169.69.87.1181492686.squirrel@calmail.berkeley.edu>
Message-ID: <168602.20814.qm@web39709.mail.mud.yahoo.com>


plot(x=1:10,y=1:10,xlim=c(0,5),ylim=c(6,10))

a lot of the arguments descriptions for plot() are contained in ?par

--- Patrick Wang <pwang at berkeley.edu> wrote:

> Hi,
> 
> How to specify the start position of Y in plot command, hopefully I can
> specify the range of X and Y axis. I checked the ?plot, it didnot mention
> I can setup the range.
> 
> 
> Thanks
> Pat
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 



 
____________________________________________________________________________________
Bored stiff? Loosen up...


From tobias.verbeke at gmail.com  Sun Jun 10 20:05:34 2007
From: tobias.verbeke at gmail.com (Tobias Verbeke)
Date: Sun, 10 Jun 2007 20:05:34 +0200
Subject: [R] R logistic regression - comparison with SPSS
In-Reply-To: <466C2254.4010109@skynet.be>
References: <466C2254.4010109@skynet.be>
Message-ID: <466C3D6E.5070908@businessdecision.com>

Alain Reymond wrote:

> Dear R-list members,
> 
> I have been a user of SPSS for a few years and quite new to R. I read
> the documentation and tried samples but I have some problems to obtain
> results for a logistic regression under R.
> 
> The following SPSS script
> 
> LOGISTIC REGRESSION  vir
>     /METHOD = FSTEP(LR) d007 d008 d009 d010 d011 d012 d013 d014 d015
> d016 d017 d018 d069 d072 d073
>     /SAVE = PRED COOK SRESID
>     /CLASSPLOT
>     /PRINT = GOODFIT CI(95)
>     /CRITERIA = PIN(.10) POUT(.10) ITERATE(40) CUT(.5) .
> 
> predicts vir (value 0 or 1) according to my parameters d007 to d073. It
> gives me the parameters to retain in the logistic equation and the
> intercept.
> The calculation is made from a set of values of about 1.000 cases.
> 
> I have been unable to translate it with success under R. I would like to
> check if I can obtain the same results than with SPSS. Can someone help
> me translate it under R ? I would be most grateful.

If all the variables you mention are available in a data frame, e.g. 
virdf, than you can fit a logistic regression model by

mymodel <- glm(vir ~ d007 + d008 + d009 + d010 + d011 + d012 + d013 + 
d014 + d015 + d016 + d017 + d018 + d069 + d072 + d073, data = virdf, 
family = binomial)

or

mymodel <- glm(vir ~ ., data = virdf, family = binomial)

if there are no variables other than those mentioned above in the
virdf data frame.

Contrary to SPSS you need not specify in advance what you would like
as output. Everything useful is stored in the model object (here: 
mymodel) which can then be used to further investigate the model in
many ways:

summary(mymodel)
anova(mymodel, test = "Chisq")
plot(mymodel)

See ?summary.glm, ?anova.glm etc.

For stepwise variable selection (not necessarily corresponding to
STEP(LR)), see ?step or ?add1 to do it `by hand'.

HTH,
Tobias

P.S. You can find an introduction to R specifically targeted at (SAS 
and) SPSS users here:

http://oit.utk.edu/scc/RforSAS&SPSSusers.pdf

-- 

Tobias Verbeke - Consultant
Business & Decision Benelux
Rue de la r?volution 8
1000 Brussels - BELGIUM

+32 499 36 33 15
tobias.verbeke at businessdecision.com


From adschai at optonline.net  Sun Jun 10 21:28:07 2007
From: adschai at optonline.net (adschai at optonline.net)
Date: Sun, 10 Jun 2007 19:28:07 +0000 (GMT)
Subject: [R] Windows vista's early terminate Rgui execution
Message-ID: <e451bdcb656.466c50c7@optonline.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070610/2a064156/attachment.pl 

From brown_emu at yahoo.com  Sun Jun 10 21:27:50 2007
From: brown_emu at yahoo.com (Stephen Tucker)
Date: Sun, 10 Jun 2007 12:27:50 -0700 (PDT)
Subject: [R] Tools For Preparing Data For Analysis
In-Reply-To: <466BD19F.4020903@biostat.ku.dk>
Message-ID: <82491.85523.qm@web39714.mail.mud.yahoo.com>


Since R is supposed to be a complete programming language, I wonder
why these tools couldn't be implemented in R (unless speed is the
issue). Of course, it's a naive desire to have a single language that
does everything, but it seems that R currently has most of the
functions necessary to do the type of data cleaning described.

For instance, Gabor and Peter showed some snippets of ways to do this
elegantly; my [physical science] data is often not as horrendously
structured so usually I can get away with a program containing this
type of code

txtin <- scan(filename,what="",sep="\n")
filteredList <- lapply(strsplit(txtin,delimiter),FUN=filterfunction)
   # fiteringfunction() returns selected (and possibly transformed
   # elements if present and NULL otherwise
   # may include calls to grep(), regexpr(), gsub(), substring(),...
   # nchar(), sscanf(), type.convert(), paste(), etc.
mydataframe <- do.call(rbind,filteredList)
   # then match(), subset(), aggregate(), etc.

In the case that the file is large, I open a file connection and scan
a single line + apply filterfunction() successively in a FOR-LOOP
instead of using lapply(). Of course, the devil is in the details of
the filtering function, but I believe most of the required text
processing facilities are already provided by R.

I often have tasks that involve a combination of shell-scripting and
text processing to construct the data frame for analysis; I started
out using Python+NumPy to do the front-end work but have been using R
progressively more (frankly, all of it) to take over that portion
since I generally prefer the data structures and methods in R.


--- Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:

> Douglas Bates wrote:
> > Frank Harrell indicated that it is possible to do a lot of difficult
> > data transformation within R itself if you try hard enough but that
> > sometimes means working against the S language and its "whole object"
> > view to accomplish what you want and it can require knowledge of
> > subtle aspects of the S language.
> >   
> Actually, I think Frank's point was subtly different: It is *because* of 
> the differences in view that it sometimes seems difficult to find the 
> way to do something in R that  is apparently straightforward in SAS. 
> I.e. the solutions exist and are often elegant, but may require some 
> lateral thinking.
> 
> Case in point: Finding the first or the last observation for each 
> subject when there are multiple records for each subject. The SAS way 
> would be a datastep with IF-THEN-DELETE, and a RETAIN statement so that 
> you can compare the subject ID with the one from the previous record, 
> working with data that are sorted appropriately.
> 
> You can do the same thing in R with a for loop, but there are better 
> ways e.g.
> subset(df,!duplicated(ID)), and subset(df, rev(!duplicated(rev(ID))), or 
> maybe
> do.call("rbind",lapply(split(df,df$ID), head, 1)), resp. tail. Or 
> something involving aggregate(). (The latter approaches generalize 
> better to other within-subject functionals like cumulative doses, etc.).
> 
> The hardest cases that I know of are the ones where you need to turn one 
> record into many, such as occurs in survival analysis with 
> time-dependent, piecewise constant covariates. This may require 
> "transposing the problem", i.e. for each  interval you find out which 
> subjects contribute and with what, whereas the SAS way would be a 
> within-subject loop over intervals containing an OUTPUT statement.
> 
> Also, there are some really weird data formats, where e.g. the input 
> format is different in different records. Back in the 80's where 
> punched-card input was still common, it was quite popular to have one 
> card with background information on a patient plus several cards 
> detailing visits, and you'd get a stack of cards containing both kinds. 
> In R you would most likely split on the card type using grep() and then 
> read the two kinds separately and merge() them later.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 



      ____________________________________________________________________________________
Park yourself in front of a world of choices in alternative vehicles. Visit the Yahoo! Auto Green Center.


From ted.harding at nessie.mcc.ac.uk  Sun Jun 10 22:18:49 2007
From: ted.harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sun, 10 Jun 2007 21:18:49 +0100 (BST)
Subject: [R] Tools For Preparing Data For Analysis
In-Reply-To: <efb536d50706100704yd56cd83r74d6d953f4ea2d00@mail.gmail.com>
Message-ID: <XFMail.070610211849.ted.harding@nessie.mcc.ac.uk>

On 10-Jun-07 14:04:44, Sarah Goslee wrote:
> On 6/10/07, Ted Harding <ted.harding at nessie.mcc.ac.uk> wrote:
> 
>> ... a lot of the problems with data
>> files arise at the data gathering and entry stages, where people
>> can behave as if stuffing unpaired socks and unattributed underwear
>> randomly into a drawer, and then banging it shut.
> 
> Not specifically R-related, but this would make a great fortune.
> 
> Sarah
> -- 
> Sarah Goslee
> http://www.functionaldiversity.org

I'm not going to object to that!
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 10-Jun-07                                       Time: 21:18:45
------------------------------ XFMail ------------------------------


From gmaxma at gmail.com  Sun Jun 10 22:20:09 2007
From: gmaxma at gmail.com (xiao-jun ma)
Date: Sun, 10 Jun 2007 13:20:09 -0700
Subject: [R] Question on weighted Kaplan-Meier analysis of case-cohort design
Message-ID: <0B3369FB-C746-4022-8387-E6B850700ED9@gmail.com>

I have a study best described as a retrospective case-cohort design:  
the cases were all the events in a given time span surveyed, and the  
controls (event-free during the follow-up period) were selected in  
2:1 ratio (2 controls per case).  The sampling frequency for the  
controls was about 0.27, so I used a weight vector consisting of 1  
for cases and 1/0.27 for controls for coxph to adjust for sampling  
bias. Using the same weights in Kaplan-Meier analysis (survfit) gave  
very inaccurate survival curves (much lower event rate than expected  
from population). Are weighting handled differently between coxph and  
survfit? How should I conduct a weighted Kaplan-Meier analysis (given  
that survfit doesn't accept a weighted cox model) for such a design?

Any explanations or suggestions are highly appreciated,

xiaojun


From ral at lcfltd.com  Sun Jun 10 22:31:13 2007
From: ral at lcfltd.com (Robert A LaBudde)
Date: Sun, 10 Jun 2007 16:31:13 -0400
Subject: [R] Windows vista's early terminate Rgui execution
In-Reply-To: <e451bdcb656.466c50c7@optonline.net>
References: <e451bdcb656.466c50c7@optonline.net>
Message-ID: <0JJF000S9T062OE3@vms046.mailsrvcs.net>

At 03:28 PM 6/10/2007, adschai at optonline.net wrote:
>Hi,I have a frustrating problem from vista that I wonder if anyone 
>has come across the same problem. I wrote a script that involves 
>long computational time (although, during the calculation, it spits 
>out text on the gui to notify me the progress of the calculation 
>periodically). Windows vista always stopped my calculation and 
>claimed that 'Rgui is stop-working. Windows is checking for 
>solution.' And when I looked into task manager, windows already 
>stopped my Rgui process. I am quite disappointed with this. I would 
>really appreciate if anyone finds a solution to go around this 
>windows vista problem? Particularly, how to turn off this feature in 
>vista? Any help would be really appreciated. Thank you!- adschai

You probably need to contact Vista periodically so it knows you are awake.

Just include a line that does a call to Vista that doesn't do output, such as

useless <- dir()

placed in some outer loop that satisfies the "drop dead" time between calls.

Alternatively, you can attempt to find out how to change the registry 
entry corresponding to the wait time and increase it to a value you 
can live with.

================================================================
Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
824 Timberlake Drive                     Tel: 757-467-0954
Virginia Beach, VA 23464-3239            Fax: 757-467-2947

"Vere scire est per causas scire"


From adschai at optonline.net  Sun Jun 10 22:35:20 2007
From: adschai at optonline.net (adschai at optonline.net)
Date: Sun, 10 Jun 2007 20:35:20 +0000 (GMT)
Subject: [R] initial value for optim in polr question
Message-ID: <e7defa423797.466c6088@optonline.net>

Hi,

I have a problem with initial value for optim in polr that R report. After a call to polr, it complains that:

Error in optim(start, fmin, gmin, method="BFGS", hessian= Hess, ...) : initial value in 'vmin' is not finite.

Would you please suggest a way round to this problem? Thank you so much in advance.

Rgds,

- adschai


From adschai at optonline.net  Sun Jun 10 22:41:04 2007
From: adschai at optonline.net (adschai at optonline.net)
Date: Sun, 10 Jun 2007 20:41:04 +0000 (GMT)
Subject: [R] Windows vista's early terminate Rgui execution
In-Reply-To: <0JJF000S9T062OE3@vms046.mailsrvcs.net>
References: <e451bdcb656.466c50c7@optonline.net>
	<0JJF000S9T062OE3@vms046.mailsrvcs.net>
Message-ID: <e451b4f667a5.466c61e0@optonline.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070610/6fb1131b/attachment.pl 

From A.Robinson at ms.unimelb.edu.au  Sun Jun 10 23:08:14 2007
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Mon, 11 Jun 2007 07:08:14 +1000
Subject: [R] {nlme} Multilevel estimation heteroscedasticity
In-Reply-To: <93CCF428-8493-4716-908C-EFE87EDC48F9@student.ru.nl>
References: <93CCF428-8493-4716-908C-EFE87EDC48F9@student.ru.nl>
Message-ID: <20070610210814.GN63160@ms.unimelb.edu.au>

Rense,

how about 

weights = varPower(form = ~ schavg)

or 

weights = varConstPower(form = ~ schavg)

or even 

weights = varPower(form = ~ schavg | type)

Yuo might find Pinheiro and Bates (2000) to be a valuable investment.

I hope that this helps,

Andrew


On Sun, Jun 10, 2007 at 04:35:58PM +0200, Rense Nieuwenhuis wrote:
> Dear All,
> 
> I'm trying to model heteroscedasticity using a multilevel model. To  
> do so, I make use of the nlme package and the weigths-parameter.  
> Let's say that I hypothesize that the exam score of students  
> (normexam) is influenced by their score on a standardized LR test  
> (standLRT). Students are of course nested in "schools". These  
> variables are contained in the Exam-data in the mlmRev package.
> 
> library(nlme)
> library(mlmRev)
> lme(fixed = normexam ~ standLRT,
> 	data = Exam,
> 	random = ~ 1 | school)
> 
> 
> If I want to model only a few categories of variance, all works fine.  
> For instance, should I (for whatever reason) hypothesize that the  
> variance on the normexam-scores is larger in mixed schools than in  
> boys-schools, I'd use weights = varIdent(form = ~ 1 | type), leading to:
> 
> heteroscedastic <- lme(fixed = normexam ~ standLRT,
> 	data = Exam,
> 	weights = varIdent(form = ~ 1 | type),
> 	random = ~ 1 | school)
> 
> This gives me nice and clear output, part of which is shown below:
> Variance function:
> Structure: Different standard deviations per stratum
> Formula: ~normexam | type
> Parameter estimates:
>       Mxd     Sngl
> 1.000000 1.034607
> Number of Observations: 4059
> Number of Groups: 65
> 
> 
> Though, should I hypothesize that the variance on the normexam- 
> variable is larger on schools that have a higher average score on  
> intake-exams (schavg), I run into troubles. I'd use weights = varIdent 
> (form = ~ 1 | schavg), leading to:
> 
> heteroscedastic <- lme(fixed = normexam ~ standLRT,
> 	data = Exam,
> 	weights = varIdent(form = ~ 1 | schavg),
> 	random = ~ 1 | school)
> 
> This leads to estimation problems. R tells me:
> Error in lme.formula(fixed = normexam ~ standLRT, data = Exam,  
> weights = varIdent(form = ~1 |  :
> 	nlminb problem, convergence error code = 1; message = iteration  
> limit reached without convergence (9)
> 
> Fiddling with maxiter and setting an unreasonable tolerance doesn't  
> help. I think the origin of this problem lies within the large number  
> of categories on "schavg" (65), that may make estimation troublesome.
> 
> This leads to my two questions:
> - How to solve this estimation-problem?
> - Is is possible that the varIdent (or more general: VarFunc) of lme  
> returns a single value, representing a co?ffici?nt along which  
> variance is increasing / decreasing?
> 
> - In general: how can a variance-component / heteroscedasticity be  
> made dependent on some level-2 variable (school level in my examples) ?
> 
> Many thanks in advance,
> 
> Rense Nieuwenhuis
> 	[[alternative HTML version deleted]]
> 

> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/


From Ted.Harding at manchester.ac.uk  Sun Jun 10 23:14:40 2007
From: Ted.Harding at manchester.ac.uk ( (Ted Harding))
Date: Sun, 10 Jun 2007 22:14:40 +0100 (BST)
Subject: [R] Tools For Preparing Data For Analysis
In-Reply-To: <82491.85523.qm@web39714.mail.mud.yahoo.com>
Message-ID: <XFMail.070610221440.Ted.Harding@manchester.ac.uk>

On 10-Jun-07 19:27:50, Stephen Tucker wrote:
> 
> Since R is supposed to be a complete programming language,
> I wonder why these tools couldn't be implemented in R
> (unless speed is the issue). Of course, it's a naive desire
> to have a single language that does everything, but it seems
> that R currently has most of the functions necessary to do
> the type of data cleaning described.

In principle that is certainly true. A couple of comments,
though.

1. R's rich data structures are likely to be superfluous.
   Mostly, at the sanitisation stage, one is working with
   "flat" files (row & column). This straightforward format
   is often easier to handle using simple programs for the
   kind of basic filtering needed, rather then getting into
   the heavier programming constructs of R.

2. As follow-on and contrast at the same time, very often
   what should be a nice flat file with no rough edges is not.
   If there are variable numbers of fields per line, R will
   not handle it straightforwardly (you can force it in,
   but it's more elaborate). There are related issues as well.

a) If someone entering data into an Excel table lets their
   cursor wander outside the row/col range of the table,
   this can cause invisible entities to be planted in the
   extraneous cells. When saved as a CSV, this file then
   has variable numbers of fields per line, and possibly
   also extra lines with arbitrary blank fields.

   cat datafile.csv | awk 'BEGIN{FS=","}{n=NF;print n}'

   will give you the numbers of fields in each line.

   If you further pipe it into | sort -nu you will get
   the distinct field-numbers. If you know (by now) how many
   fields there should be (e.g. 10), then

   cat datafile.csv | awk 'BEGIN{FS=","} (NF != 10){print NR ", " NF}'

   will tell you which lines have the wrong number of fields,
   and how many fields they have. You can similarly count how
   many lines there are (e.g. pipe into wc -l).

b) Poeple sometimes randomly use a blank space or a "." in a
   cell to demote a missing value. Consistent use of either
   is OK: ",," in a CSV will be treated as "NA" by R. The use
   of "." can be more problematic. If for instance you try to
   read the following CSV into R as a dataframe:

   1,2,.,4
   2,.,4,5
   3,4,.,6

   the "." in cols 2 and 3 is treated as the character ".",
   with the result that something complicated happens to
   the typing of the items.

   typeeof(D[i,j]) is always integer. sum(D[1,1]=1, but
   sum(D[1,2]) gives a type-error, even though the entry
   is in fact 2. And so on , in various combinations.

   And (as.nmatrix(D)) is of course a matrix of characters.

   In fact, columns 2 and 3 of D are treated as factors!

   for(i in (1:3)){ for(j in (1:4)){ print( (D[i,j]))}}
   [1] 1
   [1] 2
   Levels: . 2 4
   [1] .
   Levels: . 4
   [1] 4
   [1] 2
   [1] .
   Levels: . 2 4
   [1] 4
   Levels: . 4
   [1] 5
   [1] 3
   [1] 4
   Levels: . 2 4
   [1] .
   Levels: . 4
   [1] 6

   This is getting altogether too complicated for the job
   one wants to do!

   And it gets worse when people mix ",," and ",.,"!

   On the other hand, a simple brush with awk (or sed in
   this case) can sort it once and for all, without waking
   the sleeping dogs in R.

I could go on. R undoubtedly has the power, but it can very
quickly get over-complicated for simple jobs.

Best wishes to all,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 10-Jun-07                                       Time: 22:14:35
------------------------------ XFMail ------------------------------


From roger at ysidro.econ.uiuc.edu  Sun Jun 10 23:35:54 2007
From: roger at ysidro.econ.uiuc.edu (roger koenker)
Date: Sun, 10 Jun 2007 16:35:54 -0500
Subject: [R] Tools For Preparing Data For Analysis
In-Reply-To: <XFMail.070610221440.Ted.Harding@manchester.ac.uk>
References: <XFMail.070610221440.Ted.Harding@manchester.ac.uk>
Message-ID: <216E458C-37D2-4653-B765-35224D5705D4@ysidro.econ.uiuc.edu>

An important potential benefit of R solutions shared by awk, sed, ...
is that they provide a reproducible way to  document  exactly how one  
got
from one version of the data to the next.  This  seems to be the main
problem with handicraft methods like editing excel files, it  is too
easy to introduce  new errors that can't be tracked down at later
stages of the analysis.


url:    www.econ.uiuc.edu/~roger                Roger Koenker
email   rkoenker at uiuc.edu                       Department of Economics
vox:    217-333-4558                            University of Illinois
fax:    217-244-6678                            Champaign, IL 61820


On Jun 10, 2007, at 4:14 PM, (Ted Harding) wrote:

> On 10-Jun-07 19:27:50, Stephen Tucker wrote:
>>
>> Since R is supposed to be a complete programming language,
>> I wonder why these tools couldn't be implemented in R
>> (unless speed is the issue). Of course, it's a naive desire
>> to have a single language that does everything, but it seems
>> that R currently has most of the functions necessary to do
>> the type of data cleaning described.
>
> In principle that is certainly true. A couple of comments,
> though.
>
> 1. R's rich data structures are likely to be superfluous.
>    Mostly, at the sanitisation stage, one is working with
>    "flat" files (row & column). This straightforward format
>    is often easier to handle using simple programs for the
>    kind of basic filtering needed, rather then getting into
>    the heavier programming constructs of R.
>
> 2. As follow-on and contrast at the same time, very often
>    what should be a nice flat file with no rough edges is not.
>    If there are variable numbers of fields per line, R will
>    not handle it straightforwardly (you can force it in,
>    but it's more elaborate). There are related issues as well.
>
> a) If someone entering data into an Excel table lets their
>    cursor wander outside the row/col range of the table,
>    this can cause invisible entities to be planted in the
>    extraneous cells. When saved as a CSV, this file then
>    has variable numbers of fields per line, and possibly
>    also extra lines with arbitrary blank fields.
>
>    cat datafile.csv | awk 'BEGIN{FS=","}{n=NF;print n}'
>
>    will give you the numbers of fields in each line.
>
>    If you further pipe it into | sort -nu you will get
>    the distinct field-numbers. If you know (by now) how many
>    fields there should be (e.g. 10), then
>
>    cat datafile.csv | awk 'BEGIN{FS=","} (NF != 10){print NR ", " NF}'
>
>    will tell you which lines have the wrong number of fields,
>    and how many fields they have. You can similarly count how
>    many lines there are (e.g. pipe into wc -l).
>
> b) Poeple sometimes randomly use a blank space or a "." in a
>    cell to demote a missing value. Consistent use of either
>    is OK: ",," in a CSV will be treated as "NA" by R. The use
>    of "." can be more problematic. If for instance you try to
>    read the following CSV into R as a dataframe:
>
>    1,2,.,4
>    2,.,4,5
>    3,4,.,6
>
>    the "." in cols 2 and 3 is treated as the character ".",
>    with the result that something complicated happens to
>    the typing of the items.
>
>    typeeof(D[i,j]) is always integer. sum(D[1,1]=1, but
>    sum(D[1,2]) gives a type-error, even though the entry
>    is in fact 2. And so on , in various combinations.
>
>    And (as.nmatrix(D)) is of course a matrix of characters.
>
>    In fact, columns 2 and 3 of D are treated as factors!
>
>    for(i in (1:3)){ for(j in (1:4)){ print( (D[i,j]))}}
>    [1] 1
>    [1] 2
>    Levels: . 2 4
>    [1] .
>    Levels: . 4
>    [1] 4
>    [1] 2
>    [1] .
>    Levels: . 2 4
>    [1] 4
>    Levels: . 4
>    [1] 5
>    [1] 3
>    [1] 4
>    Levels: . 2 4
>    [1] .
>    Levels: . 4
>    [1] 6
>
>    This is getting altogether too complicated for the job
>    one wants to do!
>
>    And it gets worse when people mix ",," and ",.,"!
>
>    On the other hand, a simple brush with awk (or sed in
>    this case) can sort it once and for all, without waking
>    the sleeping dogs in R.
>
> I could go on. R undoubtedly has the power, but it can very
> quickly get over-complicated for simple jobs.
>
> Best wishes to all,
> Ted.
>
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 10-Jun-07                                       Time: 22:14:35
> ------------------------------ XFMail ------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From spencer.graves at pdf.com  Mon Jun 11 02:24:18 2007
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 10 Jun 2007 17:24:18 -0700
Subject: [R] Nonlinear Regression
In-Reply-To: <11016968.post@talk.nabble.com>
References: <11016968.post@talk.nabble.com>
Message-ID: <466C9632.5040107@pdf.com>

      Have you worked through the examples in the 'nls' help file, 
especially the following: 

     DNase1 <- subset(DNase, Run == 1)
     fm3DNase1 <- nls(density ~ Asym/(1 + exp((xmid - log(conc))/scal)),
                      data = DNase1,
                      start = list(Asym = 3, xmid = 0, scal = 1),
                      trace = TRUE)

           Treated <- Puromycin[Puromycin$state == "treated", ]
     weighted.MM <- function(resp, conc, Vm, K)
     {
         ## Purpose: exactly as white book p. 451 -- RHS for nls()
         ##  Weighted version of Michaelis-Menten model
         ## ----------------------------------------------------------
         ## Arguments: 'y', 'x' and the two parameters (see book)
         ## ----------------------------------------------------------
         ## Author: Martin Maechler, Date: 23 Mar 2001

         pred <- (Vm * conc)/(K + conc)
         (resp - pred) / sqrt(pred)
     }

     Pur.wt <- nls( ~ weighted.MM(rate, conc, Vm, K), data = Treated,
                   start = list(Vm = 200, K = 0.1),
                   trace = TRUE)
112.5978 :  200.0   0.1
17.33824 :  205.67588840   0.04692873
14.6097 :  206.33087396   0.05387279
14.59694 :  206.79883508   0.05457132
14.59690 :  206.83291286   0.05460917
14.59690 :  206.83468191   0.05461109

# In the call to 'nls' here, 'Vm' and 'K' are in 'start' and must 
therefore be parameters to be estimated. 
# The other names passed to the global 'weighted.MM' must be columns of 
'data = Treated'. 

# To get the residual sum of squares, first note that it is printed as 
the first column in the trace output. 

# To get that from Pur.wt, I first tried 'class(Pur.wt)'. 
# This told me it was of class 'nls'. 
# I then tried "method(class='nls')". 
# One of the functions listed was 'residuals.nls'.  That gave me the 
residuals. 
# I then tried 'sum(residuals(Pur.wt)^2)', which returned 14.59690. 

      Hope this helps. 
      Spencer Graves
p.s.  Did this answer your question?  Your example did not seem to me to 
be self contained, which makes it more difficult for me to know if I'm 
misinterpreting your question.  If the example had been self contained, 
I might have replied a couple of days ago. 

tronter wrote:
> Hello
>
> I followed the example in page 59, chapter 11 of the 'Introduction to R'
> manual. I entered my own x,y data. I used the least squares. My function has
> 5 parameters: p[1], p[2], p[3], p[4], p[5]. I plotted the x-y data. Then I
> used lines(spline(xfit,yfit)) to overlay best curves on the data while
> changing the parameters. My question is how do I calculate the residual sum
> of squares. In the example they have the following:
>
> df <- data.frame( x=x, y=y)
>
> fit <- nls(y ~SSmicmen(s, Vm, K), df)
>
> fit
>
>
> In the second line how would I input my function? Would it be:
>
> fit <- nls(y ~ myfunction(p[1], p[2], p[3], p[4], p[5]), df) where
> myfunction is the actual function? My function doesnt have a name, so should
> I just enter it?
>
> Thanks
>
>


From webere at mfri.com  Mon Jun 11 02:42:18 2007
From: webere at mfri.com (webere at mfri.com)
Date: Sun, 10 Jun 2007 19:42:18 -0500
Subject: [R] Potential junk email moved to Junk Folder
Message-ID: <D466c9a6a0000@firewall.mfri.com>

MailMarshal (an automated content monitoring gateway) has not 
delivered the following message:

   Message: B466c9a690000.000000000001.0001.mml
   From:    r-help at stat.math.ethz.ch
   To:      odenl at permapipe.com
   Subject: [Spam] delivery failed

This is due to automatic rules that have determined that the 
message is probably junk email.  If you believe the message was 
business related please contact webere at mfri.com and request
that the message be released.  If no contact is made within 5 
days the message will automatically be deleted.

MailMarshal Rule: SPAM subject block : Spam Subject Block
Script spam in subject Triggered in Subject
Expression: SPAM Triggered 1 times weighting 5


Email Content Security provided by NetIQ MailMarshal.



From adschai at optonline.net  Mon Jun 11 03:33:58 2007
From: adschai at optonline.net (adschai at optonline.net)
Date: Mon, 11 Jun 2007 01:33:58 +0000 (GMT)
Subject: [R] How do I obtain standard error of each estimated coefficients
	in polr
Message-ID: <e088e3376544.466ca686@optonline.net>

Hi,

I obtained all the coefficients that I need from polr. However, I'm wondering how I can obtain the standard error of each estimated coefficient? I saved the Hessian and do something like summary(polrObj), I don't see any standard error like when doing regression using lm. Any help would be really appreciated. Thank you!

- adschai


From brown_emu at yahoo.com  Mon Jun 11 05:15:21 2007
From: brown_emu at yahoo.com (Stephen Tucker)
Date: Sun, 10 Jun 2007 20:15:21 -0700 (PDT)
Subject: [R] Tools For Preparing Data For Analysis
In-Reply-To: <XFMail.070610221440.Ted.Harding@manchester.ac.uk>
Message-ID: <473010.85286.qm@web39711.mail.mud.yahoo.com>

Embarrasingly, I don't know awk or sed but R's code seems to be
shorter for most tasks than Python, which is my basis for comparison.

It's true that R's more powerful data structures usually aren't
necessary for the data cleaning, but sometimes in the filtering
process I will pick out lines that contain certain data, in which case
I have to convert text to numbers and perform operations like
which.min(), order(), etc., so in that sense I like to have R's
vectorized notation and the objects/functions that support it.

As far as some of the tasks you described, I've tried transcribing
them to R. I know you provided only the simplest examples, but even in
these cases I think R's functions for handling these situations
exemplify their usefulness in this step of the analysis. But perhaps
you would argue that this code is too long... In any event it will
still save the trouble of keeping track of an extra (intermediate)
file passed between awk and R.

(1) the numbers of fields in each line equivalent to 
>    cat datafile.csv | awk 'BEGIN{FS=","}{n=NF;print n}'
in awk

# R equivalent:
nFields <- count.fields("datafile.csv",sep=",")
# or 
nFields <- sapply(strsplit(readLines("datafile.csv"),","),length)

(2) which lines have the wrong number of fields, and how many fields
they have. You can similarly count how many lines there are (e.g. pipe
into wc -l).

# number of lines with wrong number of fields
nWrongFields <- length(nFields[nFields > 10])

# select only first ten fields from each line
# and return a matrix
firstTenFields <- 
  do.call(rbind,
          lapply(strsplit(readLines("datafile.csv"),","),
                 function(x) x[1:10]))

# select only those lines which contain ten fields
# and return a matrix
onlyTenFields <- 
  do.call(rbind,
          lapply(strsplit(readLines("datafile.csv"),","),
                 function(x) if(length(x) <= 10) x else NULL))

(3)
>    If for instance you try to
>    read the following CSV into R as a dataframe:
> 
>    1,2,.,4
>    2,.,4,5
>    3,4,.,6
> 

txtC <- textConnection(
"1,2,.,4
2,.,4,5
3,4,.,6")
# using read.csv() specifying na.string argument:
> read.csv(txtC,header=FALSE,na.string=".")
  V1 V2 V3 V4
1  1  2 NA  4
2  2 NA  4  5
3  3  4 NA  6

# Of course, read.csv will work only if data is formatted correctly.
# More generally, using readLines(), strsplit(), etc., which are more
# flexible :

> do.call(rbind,
+         lapply(strsplit(readLines(txtC),","),
+                type.convert,na.string="."))
     [,1] [,2] [,3] [,4]
[1,]    1    2   NA    4
[2,]    2   NA    4    5
[3,]    3    4   NA    6

(4) Situations where people mix ",," and ",.,"!

# type.convert (and read.csv) will still work when missing values are ",,"
# and ",.," (automatically recognizes "" as NA and through
# specification of 'na.string', can recognize "." as NA)

# If it is desired to convert "." to "" first, this is simple as
# well:

m <- do.call(rbind,
        lapply(strsplit(readLines(txtC),","),
               function(x) gsub("^\\.$","",x)))
> m
     [,1] [,2] [,3] [,4]
[1,] "1"  "2"  ""   "4" 
[2,] "2"  ""   "4"  "5" 
[3,] "3"  "4"  ""   "6" 

# then
mode(m) <- "numeric"
# or
m <- apply(m,2,type.convert)
# will give
> m
     [,1] [,2] [,3] [,4]
[1,]    1    2   NA    4
[2,]    2   NA    4    5
[3,]    3    4   NA    6


--- Ted.Harding at manchester.ac.uk wrote:

> On 10-Jun-07 19:27:50, Stephen Tucker wrote:
> > 
> > Since R is supposed to be a complete programming language,
> > I wonder why these tools couldn't be implemented in R
> > (unless speed is the issue). Of course, it's a naive desire
> > to have a single language that does everything, but it seems
> > that R currently has most of the functions necessary to do
> > the type of data cleaning described.
> 
> In principle that is certainly true. A couple of comments,
> though.
> 
> 1. R's rich data structures are likely to be superfluous.
>    Mostly, at the sanitisation stage, one is working with
>    "flat" files (row & column). This straightforward format
>    is often easier to handle using simple programs for the
>    kind of basic filtering needed, rather then getting into
>    the heavier programming constructs of R.
> 
> 2. As follow-on and contrast at the same time, very often
>    what should be a nice flat file with no rough edges is not.
>    If there are variable numbers of fields per line, R will
>    not handle it straightforwardly (you can force it in,
>    but it's more elaborate). There are related issues as well.
> 
> a) If someone entering data into an Excel table lets their
>    cursor wander outside the row/col range of the table,
>    this can cause invisible entities to be planted in the
>    extraneous cells. When saved as a CSV, this file then
>    has variable numbers of fields per line, and possibly
>    also extra lines with arbitrary blank fields.
> 
>    cat datafile.csv | awk 'BEGIN{FS=","}{n=NF;print n}'
> 
>    will give you the numbers of fields in each line.
> 
>    If you further pipe it into | sort -nu you will get
>    the distinct field-numbers. If you know (by now) how many
>    fields there should be (e.g. 10), then
> 
>    cat datafile.csv | awk 'BEGIN{FS=","} (NF != 10){print NR ", " NF}'
> 
>    will tell you which lines have the wrong number of fields,
>    and how many fields they have. You can similarly count how
>    many lines there are (e.g. pipe into wc -l).
> 
> b) Poeple sometimes randomly use a blank space or a "." in a
>    cell to demote a missing value. Consistent use of either
>    is OK: ",," in a CSV will be treated as "NA" by R. The use
>    of "." can be more problematic. If for instance you try to
>    read the following CSV into R as a dataframe:
> 
>    1,2,.,4
>    2,.,4,5
>    3,4,.,6
> 
>    the "." in cols 2 and 3 is treated as the character ".",
>    with the result that something complicated happens to
>    the typing of the items.
> 
>    typeeof(D[i,j]) is always integer. sum(D[1,1]=1, but
>    sum(D[1,2]) gives a type-error, even though the entry
>    is in fact 2. And so on , in various combinations.
> 
>    And (as.nmatrix(D)) is of course a matrix of characters.
> 
>    In fact, columns 2 and 3 of D are treated as factors!
> 
>    for(i in (1:3)){ for(j in (1:4)){ print( (D[i,j]))}}
>    [1] 1
>    [1] 2
>    Levels: . 2 4
>    [1] .
>    Levels: . 4
>    [1] 4
>    [1] 2
>    [1] .
>    Levels: . 2 4
>    [1] 4
>    Levels: . 4
>    [1] 5
>    [1] 3
>    [1] 4
>    Levels: . 2 4
>    [1] .
>    Levels: . 4
>    [1] 6
> 
>    This is getting altogether too complicated for the job
>    one wants to do!
> 
>    And it gets worse when people mix ",," and ",.,"!
> 
>    On the other hand, a simple brush with awk (or sed in
>    this case) can sort it once and for all, without waking
>    the sleeping dogs in R.
> 
> I could go on. R undoubtedly has the power, but it can very
> quickly get over-complicated for simple jobs.
> 
> Best wishes to all,
> Ted.
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 10-Jun-07                                       Time: 22:14:35
> ------------------------------ XFMail ------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 



       
____________________________________________________________________________________
Pinpoint customers who are looking for what you sell.


From sabya23 at gmail.com  Mon Jun 11 06:54:11 2007
From: sabya23 at gmail.com (spime)
Date: Sun, 10 Jun 2007 21:54:11 -0700 (PDT)
Subject: [R] Determination of % of misclassification
Message-ID: <11055026.post@talk.nabble.com>


Hi R-users,

Suppose i have a two class discrimination problem and i am using logistic
regression for the classification.

> model.logit <-
> glm(formula=RES~NUM01+NUM02+NUM03+NUM04,family=binomial(link=logit),data=train.data)
> predict.logit<-predict.glm(model.logit,newdata=test.data,type='response',se.fit=FALSE)
> predict.logit

I have two questions:

1.  Suppose our training data consists of 700 observations and testing set
of 300. How can i determine no of misclassifications from predicted values
and fitted values.

2. How to determine AUC from ROC curve and also threshold value?

Waiting for reply,

Thanks in advance,

bye
-- 
View this message in context: http://www.nabble.com/Determination-of---of-misclassification-tf3899598.html#a11055026
Sent from the R help mailing list archive at Nabble.com.


From vinodkgul at yahoo.com  Mon Jun 11 06:11:07 2007
From: vinodkgul at yahoo.com (vinod gullu)
Date: Sun, 10 Jun 2007 21:11:07 -0700 (PDT)
Subject: [R] lm for matrix of response...
In-Reply-To: <mailman.11.1181383204.27681.r-help@stat.math.ethz.ch>
Message-ID: <242139.99779.qm@web53803.mail.re2.yahoo.com>

Dear All,
1)Can I use lm() to fit more than one response in
single expression. e.g data is a matrix of these
variables
R1 R2 R3  X Y Z
1 2 1 1 2 3 
....
Now i wnat to fit R1:R3 ~ X+Y+Z.
2) How can i use Singular Value decomposition (SVD) as
an alternate to lsq.
Regards,


From h.wickham at gmail.com  Mon Jun 11 07:42:03 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 11 Jun 2007 07:42:03 +0200
Subject: [R] [R-pkgs] Updated ggplot2 package (beta version)
Message-ID: <f8e6ff050706102242g399410b3kd34744ac2a44854f@mail.gmail.com>

ggplot2
===================================

ggplot2 is a plotting system for R, based on the grammar of graphics,
which tries to take the good parts of base and lattice graphics and
none of the bad parts. It takes care of many of the fiddly details
that make plotting a hassle (like drawing legends) as well as
providing a powerful model of graphics that makes it easy to produce
complex multi-layered graphics.

Find out more at http://had.co.nz/ggplot2

Changes in version 0.5.1 ------------------------------

 * new chapter in book and changes to package to make it possible to
customise every aspect of ggplot display using grid

 * a new economic data set to help demonstrate line, path and area plots

 * many bug fixes reported by beta testers

Hadley

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages


From ripley at stats.ox.ac.uk  Mon Jun 11 07:51:07 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 11 Jun 2007 06:51:07 +0100 (BST)
Subject: [R] lm for matrix of response...
In-Reply-To: <242139.99779.qm@web53803.mail.re2.yahoo.com>
References: <242139.99779.qm@web53803.mail.re2.yahoo.com>
Message-ID: <Pine.LNX.4.64.0706110648140.25295@gannet.stats.ox.ac.uk>

On Sun, 10 Jun 2007, vinod gullu wrote:

> Dear All,
> 1)Can I use lm() to fit more than one response in
> single expression. e.g data is a matrix of these
> variables
> R1 R2 R3  X Y Z
> 1 2 1 1 2 3
> ....
> Now i wnat to fit R1:R3 ~ X+Y+Z.

?lm says

      If 'response' is a matrix a linear model is fitted separately by
      least-squares to each column of the matrix.

so cbind(R1,R2,R3) ~ X+Y+Z

> 2) How can i use Singular Value decomposition (SVD) as
> an alternate to lsq.

See ?svd.

Note that SVD is not a model-fitting criterion, and can be used to fit by 
least squares.  If you mean something else, please study the posting guide 
and tell us precisely what you mean, with references.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maja.schroeter at gmx.de  Mon Jun 11 08:53:52 2007
From: maja.schroeter at gmx.de (=?iso-8859-1?Q?=22Maja_Schr=F6ter=22?=)
Date: Mon, 11 Jun 2007 08:53:52 +0200
Subject: [R]  Starting R within an VBA makro
Message-ID: <20070611065352.120970@gmx.net>

Hello everybody,

at work I want to start R within an VBA program. 

First I calculate something in Excel 2003.

After that I want to start within my VBA makro R wich should start an R file, say i.g, superplot.R  which plots me the data well.

So is it possible?

Maybe something like that:

sub test()

  'calculate something

 start R superplot.R 

end test()

Thank you so much.

Kindly regards,

Maja


-- 
Psssst! Schon vom neuen GMX MultiMessenger geh?rt?
Der kanns mit allen: http://www.gmx.net/de/go/multimessenger


From chrishold at psyctc.org  Sun Jun 10 11:39:05 2007
From: chrishold at psyctc.org (Chris Evans)
Date: Sun, 10 Jun 2007 10:39:05 +0100
Subject: [R] Tools For Preparing Data For Analysis
In-Reply-To: <XFMail.070610092830.ted.harding@nessie.mcc.ac.uk>
References: <XFMail.070610092830.ted.harding@nessie.mcc.ac.uk>
Message-ID: <466BC6B9.70804@psyctc.org>

(Ted Harding) sent the following  at 10/06/2007 09:28:

... much snipped ...

> (As is implicit in many comments in Robert's blog, and indeed also
> from many postings to this list over time and undoubtedly well
> known to many of us in practice, a lot of the problems with data
> files arise at the data gathering and entry stages, where people
> can behave as if stuffing unpaired socks and unattributed underwear
> randomly into a drawer, and then banging it shut).

And they look surprised when pointing a statistician at the chest of
drawers doesn't result in a cut price display worthy of Figleaf (or
Victoria's Secret I think for those of you in N.America) and get them
their degree, doctorate, latest publication ...

Ah me, how wonderfully, wonderfully ... sadly, accurate!

Thanks Ted, great thread and I'm impressed with EpiData that I've
discovered through this. I'd still like something that is even more
integrated with R but maybe some day, if EpiData go fully open source as
I think they are doing ("A full conversion plan to secure this and
convert the software to open-source has been made (See complete
description of license and principles)." at http://www.epidata.dk/ but
the link to http://www.epidata.dk/about.htm doesn't exactly clarify this
I don't think.  But I can hope.)

Thanks, yet again, to everyone who creates and contributes to the R
system and this list: wonderful!

C


-- 
Chris Evans <chris at psyctc.org> Skype: chris-psyctc
Professor of Psychotherapy, Nottingham University;
Consultant Psychiatrist in Psychotherapy, Notts PDD network;
Research Programmes Director, Nottinghamshire NHS Trust;
*If I am writing from one of those roles, it will be clear. Otherwise*
*my views are my own and not representative of those institutions    *


From residuo.solow at gmail.com  Mon Jun 11 04:29:35 2007
From: residuo.solow at gmail.com (Sebastian Kruk)
Date: Sun, 10 Jun 2007 23:29:35 -0300
Subject: [R] GMM estimation
Message-ID: <a7961d100706101929n4a228d4fsd822af35d088eefc@mail.gmail.com>

Dear everyone:

I have to finish my thesis to graduate as Bs. in Economics.

I choose to estimate a New Keynesian Phillips Curve (NKPC) for Uruguay
using Generalized Moment Method (GMM).

I do not know programming or R but I  would like to use it.

Should I use gee, geepack or gam?

Thanks in advance,

Sebasti?n.

***************************************

?Hola todos!

Para terminiar mi licenciatura en Econom?a debo hacer un trabajo de
investigaci?n monogr?fico.

Elegi como tema la estimaci?n de la curva de Phillips de los Nuevos
Keynesianos (CPNK).

No se programar ni conosco el lenguaje R pero me gustaria usarlo para
estimar la CPNK usando el m?todo generalizado de los momentos (MGM).

?Deber?a usar el paquete gee, geepack o gam?

Gracias a todos.

Sebasti?n.


From residuo.solow at gmail.com  Mon Jun 11 04:42:23 2007
From: residuo.solow at gmail.com (Sebastian Kruk)
Date: Sun, 10 Jun 2007 23:42:23 -0300
Subject: [R] generalized moment method
Message-ID: <a7961d100706101942y1ae8594ai3b0bc2671be81d9b@mail.gmail.com>

Dear everyone:

I have to finish my thesis to graduate as Bs. in Economics.

I choose to estimate a New Keynesian Phillips Curve (NKPC) for Uruguay
using Generalized Moment Method (GMM).

I do not know programming or R but I  would like to use it.

Should I use gee, geepack or gam?

Thanks in advance,

Sebasti?n.

***************************************

?Hola todos!

Para terminiar mi licenciatura en Econom?a debo hacer un trabajo de
investigaci?n monogr?fico.

Elegi como tema la estimaci?n de la curva de Phillips de los Nuevos
Keynesianos (CPNK).

No se programar ni conosco el lenguaje R pero me gustaria usarlo para
estimar la CPNK usando el m?todo generalizado de los momentos (MGM).

?Deber?a usar el paquete gee, geepack o gam?

Gracias a todos.

Sebasti?n.


From mroyerr at gmail.com  Mon Jun 11 09:29:22 2007
From: mroyerr at gmail.com (Mary Royerr)
Date: Mon, 11 Jun 2007 12:59:22 +0530
Subject: [R] Textpad help
Message-ID: <111b2f270706110029g7fa6cf19pbc260a99ec581a26@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070611/17a93378/attachment.pl 

From Roger.Bivand at nhh.no  Mon Jun 11 09:50:54 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 11 Jun 2007 09:50:54 +0200 (CEST)
Subject: [R] Starting R within an VBA makro
In-Reply-To: <20070611065352.120970@gmx.net>
References: <20070611065352.120970@gmx.net>
Message-ID: <Pine.LNX.4.64.0706110948260.8117@reclus.nhh.no>

On Mon, 11 Jun 2007, "Maja Schr?ter" wrote:

> Hello everybody,
>
> at work I want to start R within an VBA program.
>
> First I calculate something in Excel 2003.
>
> After that I want to start within my VBA makro R wich should start an R 
> file, say i.g, superplot.R which plots me the data well.
>
> So is it possible?

http://cran.r-project.org/contrib/extra/dcom/00ReadMe.html

and

RSiteSearch("Excel VBA")



>
> Maybe something like that:
>
> sub test()
>
>  'calculate something
>
> start R superplot.R
>
> end test()
>
> Thank you so much.
>
> Kindly regards,
>
> Maja
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From gregor.gorjanc at bfro.uni-lj.si  Mon Jun 11 09:51:14 2007
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Mon, 11 Jun 2007 07:51:14 +0000 (UTC)
Subject: [R] icc from GLMM?
References: <1181295518.4669239ed658f@webmail.shef.ac.uk>
Message-ID: <loom.20070611T094218-204@post.gmane.org>

Shinichi Nakagawa <S.Nakagawa <at> sheffield.ac.uk> writes:
... 
> I am a little confused which one to trust and use. Or there are no easy form
> to do this? I am guessing formula would change depending on what distribution
> you use and what link function as well? I want to calculate icc from GLMM with
> Poisson with log link function and also binomial with logit function. Could
> anybody help me please?

Yes, you are right that ICC depends on assumed data distribution. While ICC is
very handy in linear models it is not the case in GLMM. I suggest you take a
look at the references bellow. There is also some online material by the same
authors. Additionally, I remember that there were lively discussions about ICC
on "multilevel" list at

http://www.jiscmail.ac.uk/lists/multilevel.html

Best wishes, Gregor

@Article{Goldstein:2002,
  author =       {Goldstein, H. and Browne, W. and Rabash, J.},
  title =        {Partitioning variation in multilevel models},
  journal =      {Understanding Statistics},
  year =         {2002},
  volume =       {1},
  number =       {4},
  pages =        {223--231},
  keywords =     {variance ratio, variance partition coefficient,
                  intra-unit correlation, intra-class correlation, normal
                  models, discrete models, random coefficient models}
}

@Article{Browne:2005,
  author =       {Browne, W. J. and Subramanian, S. V. and Jones, K. and
                  Goldstein, H.},
  title =        {Variance partitioning in multilevel logistic models that
                  exhibit overdispersion},
  journal =      {J. R. Stat. Soc. A Stat. Soc.},
  year =         {2005},
  volume =       {168},
  number =       {3},
  pages =        {599--613},
  doi =          {10.1111/j.1467-985X.2004.00365.x},
  checked =      {[2006-04-16]},
  keywords =     {heritability, ratios, intra-class correlation,
                  intra-unit correlation, simulation, linearization, latent
                  variable approach},
}


From pbulian at cro.it  Mon Jun 11 09:55:30 2007
From: pbulian at cro.it (Pietro Bulian)
Date: Mon, 11 Jun 2007 09:55:30 +0200
Subject: [R] epitools and R 2.5
Message-ID: <003f01c7abfd$e2fb63f0$2bb411ac@cro.sanita.fvg.it>

At work after updating to R 2.5 I get an error using epitab from package 
epitools, when at home  (R 2.4) I get no error. Could someone help me?

Thanks
Pietro Bulian

Servizio di Onco-Ematologia Clinico-Sperimentale
I.R.C.C.S. Centro di Riferimento Oncologico
Via Franco Gallini 2
33081 Aviano (PN) - Italy

phone: +39 0434 659 412
fax: +39 0434 659 409
e-mail: pbulian at cro.it


(at work)
epitab(matrix(c(227,473,74,126),2))
the part of the args list of 'list' being evaluated was:
   (tab = tab, measure = oddsratio, conf.level = conf.level, pvalue = 
pvalue, )
Error in epitab(matrix(c(227, 473, 74, 126), 2)) :
        element 5 is empty

R.version
               _
platform       i386-pc-mingw32
arch           i386
os             mingw32
system         i386, mingw32
status
major          2
minor          5.0
year           2007
month          04
day            23
svn rev        41293
language       R
version.string R version 2.5.0 (2007-04-23)

Package: epitools
Version: 0.4-8
Date: 2007-05-10
Title: Epidemiology Tools
Author: Tomas Aragon <aragon at berkeley.edu>
Maintainer: Tomas Aragon <aragon at berkeley.edu>
Depends: R (>= 2.1.0)
Description: A package of analytic tools for epidemiologists.
License: GPL version 2 or newer
URL: http://www.epitools.net
Packaged: Thu May 10 01:55:28 2007; Tomas
Built: R 2.5.0; ; 2007-05-10 14:22:09; windows

(at home)
> epitab(matrix(c(227,473,74,126),2))
Warning: a final empty element has been omitted

the part of the args list of 'list' being evaluated was:

(tab = tab, measure = oddsratio, conf.level = conf.level, pvalue = pvalue, )

$tab

Outcome

Predictor Disease1 p0 Disease2 p1 oddsratio lower upper p.value

Exposed1 227 0.3242857 74 0.37 1.0000000 NA NA NA

Exposed2 473 0.6757143 126 0.63 0.8171533 0.5887731 1.134120 0.2348794

$measure

[1] "wald"

$conf.level

[1] 0.95

$pvalue

[1] "fisher.exact"



> R.version

_

platform i386-pc-mingw32

arch i386

os mingw32

system i386, mingw32

status

major 2

minor 4.1

year 2006

month 12

day 18

svn rev 40228

language R



Package: epitools

Title: Epidemiology Tools

Version: 0.4-7

Date: 2005-03-20

Author: Tomas Aragon

Description: Basic tools for applied epidemiology.

Maintainer: Tomas Aragon <aragon at berkeley.edu>

License: GPL version 2 or newer

URL: http://www.epitools.net

Packaged: Sun Mar 20 16:30:07 2005; Tomas

Built: R 2.4.0; ; 2006-10-03 22:02:05; windows

version.string R version 2.4.1 (2006-12-18)


From ripley at stats.ox.ac.uk  Mon Jun 11 10:52:30 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 11 Jun 2007 09:52:30 +0100 (BST)
Subject: [R] epitools and R 2.5
In-Reply-To: <003f01c7abfd$e2fb63f0$2bb411ac@cro.sanita.fvg.it>
References: <003f01c7abfd$e2fb63f0$2bb411ac@cro.sanita.fvg.it>
Message-ID: <Pine.LNX.4.64.0706110944530.26050@gannet.stats.ox.ac.uk>

On Mon, 11 Jun 2007, Pietro Bulian wrote:

> At work after updating to R 2.5 I get an error using epitab from package
> epitools, when at home  (R 2.4) I get no error. Could someone help me?

The maintainer: this is a long-standing bug in the package.
But you have enough information from the error message to correct the bug 
and rebuild the package yourself.

There are no such versions of R as '2.5' and '2.4' (see the posting 
guide), but R 2.4.0 did give a warning on your example.

Note that you are using different versions of epitools in your two 
locations, a difference you failed to mention and which may be important.



> Thanks
> Pietro Bulian
>
> Servizio di Onco-Ematologia Clinico-Sperimentale
> I.R.C.C.S. Centro di Riferimento Oncologico
> Via Franco Gallini 2
> 33081 Aviano (PN) - Italy
>
> phone: +39 0434 659 412
> fax: +39 0434 659 409
> e-mail: pbulian at cro.it
>
>
> (at work)
> epitab(matrix(c(227,473,74,126),2))
> the part of the args list of 'list' being evaluated was:
>   (tab = tab, measure = oddsratio, conf.level = conf.level, pvalue =
> pvalue, )
> Error in epitab(matrix(c(227, 473, 74, 126), 2)) :
>        element 5 is empty
>
> R.version
>               _
> platform       i386-pc-mingw32
> arch           i386
> os             mingw32
> system         i386, mingw32
> status
> major          2
> minor          5.0
> year           2007
> month          04
> day            23
> svn rev        41293
> language       R
> version.string R version 2.5.0 (2007-04-23)
>
> Package: epitools
> Version: 0.4-8
> Date: 2007-05-10
> Title: Epidemiology Tools
> Author: Tomas Aragon <aragon at berkeley.edu>
> Maintainer: Tomas Aragon <aragon at berkeley.edu>
> Depends: R (>= 2.1.0)
> Description: A package of analytic tools for epidemiologists.
> License: GPL version 2 or newer
> URL: http://www.epitools.net
> Packaged: Thu May 10 01:55:28 2007; Tomas
> Built: R 2.5.0; ; 2007-05-10 14:22:09; windows
>
> (at home)
>> epitab(matrix(c(227,473,74,126),2))
> Warning: a final empty element has been omitted
>
> the part of the args list of 'list' being evaluated was:
>
> (tab = tab, measure = oddsratio, conf.level = conf.level, pvalue = pvalue, )
>
> $tab
>
> Outcome
>
> Predictor Disease1 p0 Disease2 p1 oddsratio lower upper p.value
>
> Exposed1 227 0.3242857 74 0.37 1.0000000 NA NA NA
>
> Exposed2 473 0.6757143 126 0.63 0.8171533 0.5887731 1.134120 0.2348794
>
> $measure
>
> [1] "wald"
>
> $conf.level
>
> [1] 0.95
>
> $pvalue
>
> [1] "fisher.exact"
>
>
>
>> R.version
>
> _
>
> platform i386-pc-mingw32
>
> arch i386
>
> os mingw32
>
> system i386, mingw32
>
> status
>
> major 2
>
> minor 4.1
>
> year 2006
>
> month 12
>
> day 18
>
> svn rev 40228
>
> language R
>
>
>
> Package: epitools
>
> Title: Epidemiology Tools
>
> Version: 0.4-7
>
> Date: 2005-03-20
>
> Author: Tomas Aragon
>
> Description: Basic tools for applied epidemiology.
>
> Maintainer: Tomas Aragon <aragon at berkeley.edu>
>
> License: GPL version 2 or newer
>
> URL: http://www.epitools.net
>
> Packaged: Sun Mar 20 16:30:07 2005; Tomas
>
> Built: R 2.4.0; ; 2006-10-03 22:02:05; windows
>
> version.string R version 2.4.1 (2006-12-18)
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From christian.ritter at shell.com  Mon Jun 11 11:06:20 2007
From: christian.ritter at shell.com (christian.ritter at shell.com)
Date: Mon, 11 Jun 2007 11:06:20 +0200
Subject: [R] Looking for R-code for non-negative matrix factorization in the
	presence of Gaussian or Poisson noise
Message-ID: <156CDC8CCFD1894295D2907F16337A4801420B79@bru-s-006.europe.shell.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070611/6a50dc8f/attachment.pl 

From jrkrideau at yahoo.ca  Mon Jun 11 11:10:59 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Mon, 11 Jun 2007 05:10:59 -0400 (EDT)
Subject: [R] Lines in dotchart & dotplot ?
In-Reply-To: <eb555e660706091136l3f6ea07du1a8fa76f65da7547@mail.gmail.com>
Message-ID: <450651.6379.qm@web32804.mail.mud.yahoo.com>


--- deepayan.sarkar at gmail.com wrote:

> On 6/9/07, John Kane <jrkrideau at yahoo.ca> wrote:
> > Is it possible to use dotchart or dotplot and set
> the
> > lines in such a way that they only extend from the
> > left y-axis to the data point?
> 
> Yes (sort of) in dotplot at least. E.g.,
> 
> dotplot(VADeaths, groups = FALSE, type = c("p",
> "h"))
> dotplot(VADeaths, groups = FALSE, type = c("p",
> "h"), origin = 0)
> 
> -Deepayan
> 

Ah, that is quite nice, not exactly what I remember
from Cleveland but it should do quite nicely.

  Thank you very much

> > I seem to remember that Wm Cleveland did this in
> his
> > 1985 book  "The elements of graphing data".
> >
> > In cases where one has a true starting or O point
> on
> > the x-scale this layout seems to be very effective
> in
> > displaying some data.
> >
> > I know that I can do it by simple ploting lines
> and
> > points but a more polished function than I am
> likely
> > to produce would be nice.
> >
> > Thanks


From meinhardploner at gmx.net  Mon Jun 11 11:23:58 2007
From: meinhardploner at gmx.net (Meinhard Ploner)
Date: Mon, 11 Jun 2007 11:23:58 +0200
Subject: [R] system() and R BATCH
Message-ID: <CD547B21-F78C-48A4-B2F6-A159A6857E1C@gmx.net>

If I start from within R a new R batch job by using something like

system("R CMD BATCH --no-save --quiet Rin.txt Rout.txt",
		intern=FALSE, ignore.stderr=TRUE, wait=FALSE, input=NULL)

the job runs fine and smooth.
However, when, for any reason, I put twice ctrl+C in the calling R,  
it kills me the called batch job, too. This is not what I wanted. Ctrl 
+C is usually rather used to stop a loop etc. Why it stops the called  
batch jobs, too?

What can be the solution for me - avoiding the called batch jobs to  
be killable from the calling R process?

Best regards
Meinhard


PS system: MacOS 10.4.9 Intel, R 2.5.0


From jrkrideau at yahoo.ca  Mon Jun 11 11:31:27 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Mon, 11 Jun 2007 05:31:27 -0400 (EDT)
Subject: [R] Textpad help
In-Reply-To: <111b2f270706110029g7fa6cf19pbc260a99ec581a26@mail.gmail.com>
Message-ID: <529988.97124.qm@web32813.mail.mud.yahoo.com>

Hi Mary,
You really have not given us much to go on.  An
example of the code that you were trying to run would
be a great help (as it says down below :  PLEASE do
read the posting guide. The point about code is
important.

However the first thing to check is your file path.
This is my first guess anyway.

Here is the entry in the R FAQ
----------------------------
As R uses C-style string handling, `\' is treated as
an escape character, so that for example one can enter
a newline as `\n'. When you really need a `\', you
have to escape it with another `\'.

Thus, in filenames use something like
"c:\\data\\money.dat". You can also replace `\' by `/'
("c:/data/money.dat"). 
--------------------------

I am not familiar with textpad but you might want to
have a look at tinn-r which is very closely integrated
with R as an alternative editor

--- Mary Royerr <mroyerr at gmail.com> wrote:

> I have installed textpad and tried running R code.
> But it gives me the
> following error message.
> 
> 
> 
> The filename, directory name, or volume label syntax
> is incorrect.
> 
> Tool completed with exit code 1
> 
> 
> Can you provide any help? I am not a technical
> person. So the help in detail
> will be appreciated.
> Thx
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From markus.jantti at iki.fi  Mon Jun 11 11:41:24 2007
From: markus.jantti at iki.fi (=?ISO-8859-1?Q?Markus_J=E4ntti?=)
Date: Mon, 11 Jun 2007 12:41:24 +0300
Subject: [R] generalized moment method
In-Reply-To: <a7961d100706101942y1ae8594ai3b0bc2671be81d9b@mail.gmail.com>
References: <a7961d100706101942y1ae8594ai3b0bc2671be81d9b@mail.gmail.com>
Message-ID: <466D18C4.3060004@iki.fi>

Sebastian Kruk wrote:
> Dear everyone:
> 
> I have to finish my thesis to graduate as Bs. in Economics.
> 
> I choose to estimate a New Keynesian Phillips Curve (NKPC) for Uruguay
> using Generalized Moment Method (GMM).
> 
> I do not know programming or R but I  would like to use it.
> 
> Should I use gee, geepack or gam?

Dear Sebasti?n -- neither geepack nor gam provide GMM estimators. GMM -- or at 
least minimum distance estimation techniques -- rely on fitting by linear or 
more often non-linear least squares functions of smaller parameter vectors to 
the empirical moments of your problem. R is a suitable tool for this, but there 
is AFAIK know general GMM package.

The details of our model would need to be known before any further advice can be 
given.

Regards,

Markus

> 
> Thanks in advance,
> 
> Sebasti?n.
> 
> ***************************************
> 
> ?Hola todos!
> 
> Para terminiar mi licenciatura en Econom?a debo hacer un trabajo de
> investigaci?n monogr?fico.
> 
> Elegi como tema la estimaci?n de la curva de Phillips de los Nuevos
> Keynesianos (CPNK).
> 
> No se programar ni conosco el lenguaje R pero me gustaria usarlo para
> estimar la CPNK usando el m?todo generalizado de los momentos (MGM).
> 
> ?Deber?a usar el paquete gee, geepack o gam?
> 
> Gracias a todos.
> 
> Sebasti?n.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Markus Jantti
Abo Akademi University
markus.jantti at iki.fi
http://www.iki.fi/~mjantti


From hassen62 at voila.fr  Mon Jun 11 11:58:23 2007
From: hassen62 at voila.fr (hassen62 at voila.fr)
Date: Mon, 11 Jun 2007 11:58:23 +0200 (CEST)
Subject: [R] problem with xlsReadWrite package
Message-ID: <10008503.55221181555903938.JavaMail.www@wwinf4002>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070611/4e56e592/attachment.pl 

From hassen62 at voila.fr  Mon Jun 11 12:01:17 2007
From: hassen62 at voila.fr (hassen62 at voila.fr)
Date: Mon, 11 Jun 2007 12:01:17 +0200 (CEST)
Subject: [R] problem with xlsReadWrite package
Message-ID: <5580082.55891181556077187.JavaMail.www@wwinf4002>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070611/398d0f28/attachment.pl 

From sabya23 at gmail.com  Mon Jun 11 12:30:27 2007
From: sabya23 at gmail.com (spime)
Date: Mon, 11 Jun 2007 03:30:27 -0700 (PDT)
Subject: [R] Error using mgcv package
Message-ID: <11058255.post@talk.nabble.com>


Hi all,

I need some solution in the following problem. The following error appears
when i use "mgcv" package for implementing GAM. But the same formula works
fine in "gam" package.

> model.gam <- gam(formula = RES ~
> CAT01+s(NUM01,5)+CAT02+CAT03+s(NUM02,5)+CAT04+
+ CAT05+s(NUM03,5)+CAT06+CAT07+s(NUM04,5)+CAT08+s(NUM05,5)+CAT09+
+ CAT10+s(NUM06,5)+CAT11+NUM07+CAT12+CAT13,
+ family = binomial(link = logit), data = train.data,na.action = na.exclude,
+ control = list(epsilon = 0.001,bf.epsilon = 0.001, maxit = 50, 
+ bf.maxit = 10, trace = F))

Error in terms.formula(reformulate(term[i])) : 
        invalid model formula in ExtractVars

And after deleting df's 

model.gam <- gam(formula = RES ~ CAT01+s(NUM01)+CAT02+CAT03+s(NUM02)+CAT04+
+ CAT05+s(NUM03)+CAT06+CAT07+s(NUM04)+CAT08+s(NUM05)+CAT09+
+ CAT10+s(NUM06)+CAT11+NUM07+CAT12+CAT13,
+ family = binomial(link = logit), data = train.data)

Error in smooth.construct.tp.smooth.spec(object, data, knots) : 
        A term has fewer unique covariate combinations than specified
maximum degrees of freedom
 

Can anybody show me some light in this case!!!

Thanks in advance.
-- 
View this message in context: http://www.nabble.com/Error-using-mgcv-package-tf3900783.html#a11058255
Sent from the R help mailing list archive at Nabble.com.


From stevenmh at muohio.edu  Mon Jun 11 12:47:41 2007
From: stevenmh at muohio.edu (Martin Henry H. Stevens)
Date: Mon, 11 Jun 2007 06:47:41 -0400
Subject: [R] {spam?}   Nonlinear Regression
In-Reply-To: <11016968.post@talk.nabble.com>
References: <11016968.post@talk.nabble.com>
Message-ID: <A3A1BA58-8143-4C30-AD9E-2307078FD733@muohio.edu>

Hi tronter,

PLEASE do read the posting guide http://www.R-project.org/posting- 
guide.html
and provide commented, minimal, self-contained, reproducible code.

Hank
On Jun 7, 2007, at 5:50 PM, tronter wrote:

>
> Hello
>
> I followed the example in page 59, chapter 11 of the 'Introduction  
> to R'
> manual. I entered my own x,y data. I used the least squares. My  
> function has
> 5 parameters: p[1], p[2], p[3], p[4], p[5]. I plotted the x-y data.  
> Then I
> used lines(spline(xfit,yfit)) to overlay best curves on the data while
> changing the parameters. My question is how do I calculate the  
> residual sum
> of squares. In the example they have the following:
>
> df <- data.frame( x=x, y=y)
>
> fit <- nls(y ~SSmicmen(s, Vm, K), df)
>
> fit
>
>
> In the second line how would I input my function? Would it be:
>
> fit <- nls(y ~ myfunction(p[1], p[2], p[3], p[4], p[5]), df) where
> myfunction is the actual function? My function doesnt have a name,  
> so should
> I just enter it?
>
> Thanks
>
> -- 
> View this message in context: http://www.nabble.com/Nonlinear- 
> Regression-tf3886617.html#a11016968
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bxc at steno.dk  Mon Jun 11 13:18:01 2007
From: bxc at steno.dk (BXC (Bendix Carstensen))
Date: Mon, 11 Jun 2007 13:18:01 +0200
Subject: [R] Rounding?
Message-ID: <40D3930AC1C8EA469E39536E5BC80835044EB390@EXDKBA021.corp.novocorp.net>

I was a bit puzzed by:

> formatC(6.65,format="f",digits=1)
[1] "6.6"

So I experimented and found:

> formatC(6.6500000000000001,format="f",digits=1)
[1] "6.6"
> formatC(6.650000000000001,format="f",digits=1)
[1] "6.7"
>   round(6.6500000000000001,1)
[1] 6.7
>   round(6.650000000000001,1)
[1] 6.7
> version
               _                           
platform       i386-pc-mingw32             
arch           i386                        
os             mingw32                     
system         i386, mingw32               
status                                     
major          2                           
minor          5.0                         
year           2007                        
month          04                          
day            23                          
svn rev        41293                       
language       R                           
version.string R version 2.5.0 (2007-04-23)

My machine runs Windows NT.

Is this intended or just a Windows facility?
______________________________________________

Bendix Carstensen
Senior Statistician

Steno Diabetes Center
Niels Steensens Vej 2-4
DK-2820 Gentofte
Denmark
+45 44 43 87 38 (direct)
+45 30 75 87 38 (mobile)
+45 44 43 73 13 (fax)
bxc at steno.dk   http://www.biostat.ku.dk/~bxc

This e-mail (including any attachments) is intended for the ...{{dropped}}


From b.rowlingson at lancaster.ac.uk  Mon Jun 11 13:21:29 2007
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 11 Jun 2007 12:21:29 +0100
Subject: [R] Tools For Preparing Data For Analysis
In-Reply-To: <466BC6B9.70804@psyctc.org>
References: <XFMail.070610092830.ted.harding@nessie.mcc.ac.uk>
	<466BC6B9.70804@psyctc.org>
Message-ID: <466D3039.7070002@lancaster.ac.uk>

Chris Evans wrote:

> Thanks Ted, great thread and I'm impressed with EpiData that I've
> discovered through this. I'd still like something that is even more
> integrated with R but maybe some day, if EpiData go fully open source as
> I think they are doing ("A full conversion plan to secure this and
> convert the software to open-source has been made (See complete
> description of license and principles)." at http://www.epidata.dk/ but
> the link to http://www.epidata.dk/about.htm doesn't exactly clarify this
> I don't think.  But I can hope.)
> 
> Thanks, yet again, to everyone who creates and contributes to the R
> system and this list: wonderful!

  Perhaps what we need is an XML standard for describing record-oriented 
data and its validation? This could then be used to validate a set of 
records and possibly also to build input forms with built-in validation 
for new records.

  You could then write R code that did 'check this data frame against 
this XML description and tell me the invalid rows'. Or Python code.

  This is the kind of thing that is traditionally built using a database 
front-end, but keeping the description in XML means that alternate 
interfaces (web forms, standalone programs using Qt or GTK libraries) 
can be used on the same description set.

  I had a quick search to see if this kind of thing exists already, but 
google searches for 'data entry verification' indicate that I should 
really pay some people in India to do that kind of thing for me...

Barry


From jholtman at gmail.com  Mon Jun 11 13:31:21 2007
From: jholtman at gmail.com (jim holtman)
Date: Mon, 11 Jun 2007 07:31:21 -0400
Subject: [R] Rounding?
In-Reply-To: <40D3930AC1C8EA469E39536E5BC80835044EB390@EXDKBA021.corp.novocorp.net>
References: <40D3930AC1C8EA469E39536E5BC80835044EB390@EXDKBA021.corp.novocorp.net>
Message-ID: <644e1f320706110431k51d69340k84b3c7d454e3d2c8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070611/971c4f23/attachment.pl 

From jholtman at gmail.com  Mon Jun 11 14:04:10 2007
From: jholtman at gmail.com (jim holtman)
Date: Mon, 11 Jun 2007 08:04:10 -0400
Subject: [R] Rounding?
In-Reply-To: <40D3930AC1C8EA469E39536E5BC80835044EB390@EXDKBA021.corp.novocorp.net>
References: <40D3930AC1C8EA469E39536E5BC80835044EB390@EXDKBA021.corp.novocorp.net>
Message-ID: <644e1f320706110504w501083a5se7e7d4d28be14959@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070611/86112605/attachment.pl 

From Christoph.Scherber at agr.uni-goettingen.de  Mon Jun 11 14:09:45 2007
From: Christoph.Scherber at agr.uni-goettingen.de (Christoph Scherber)
Date: Mon, 11 Jun 2007 14:09:45 +0200
Subject: [R] Selecting all values smaller than X in a dataframe
Message-ID: <466D3B89.8020007@agr.uni-goettingen.de>

Dear R users,

I have a correlation matrix for a dataframe called "synth", for which I 
now want to select only those cells that have correlations larger than 
+/-0.6:

synth=data.frame(x=rnorm(10,1),y=rnorm(10,2),z=rnorm(10,0.5))

w=cor(synth,use="pairwise.complete.obs")
w=as.data.frame(w)
w[,sapply(w,abs(w),">",0.6)]

The problem is that using sapply with ">" or "<" doesn?t seem to work.

How could I solve this problem?

Thank you very much in advance for your help!

Best wishes
Christoph

(I am using R 2.5.0 on Windows XP).



--
Christoph Scherber
DNPW, Agroecology
University of Goettingen
Waldweg 26
D-37073 Goettingen

+49-(0)551-39-8807


From schmidb at ibe.med.uni-muenchen.de  Mon Jun 11 14:11:57 2007
From: schmidb at ibe.med.uni-muenchen.de (Markus Schmidberger)
Date: Mon, 11 Jun 2007 14:11:57 +0200
Subject: [R] simultaneous computing
Message-ID: <466D3C0D.1070800@ibe.med.uni-muenchen.de>

Hello,

which possibilities are available in R for simultaneous or parallel 
computing?
I only could find biopara 
(http://cran.r-project.org/src/contrib/Descriptions/biopara.html)

Are there other possibilities?
Are there special groups working on simultaneous computing with R?

Thanks
Markus

-- 
Dipl.-Tech. Math. Markus Schmidberger

Ludwig-Maximilians-Universit?t M?nchen
IBE - Institut f?r medizinische Informationsverarbeitung,
Biometrie und Epidemiologie


From Mike.Lawrence at DAL.CA  Mon Jun 11 14:19:02 2007
From: Mike.Lawrence at DAL.CA (Mike Lawrence)
Date: Mon, 11 Jun 2007 09:19:02 -0300
Subject: [R] simultaneous computing
In-Reply-To: <466D3C0D.1070800@ibe.med.uni-muenchen.de>
References: <466D3C0D.1070800@ibe.med.uni-muenchen.de>
Message-ID: <0F1781A8-76F3-4BAE-9755-A9901268A963@DAL.CA>

There's RMPI
tutorial: http://ace.acadiau.ca/math/ACMMaC/Rmpi/index.html


On 11-Jun-07, at 9:11 AM, Markus Schmidberger wrote:

> Hello,
>
> which possibilities are available in R for simultaneous or parallel
> computing?
> I only could find biopara
> (http://cran.r-project.org/src/contrib/Descriptions/biopara.html)
>
> Are there other possibilities?
> Are there special groups working on simultaneous computing with R?
>
> Thanks
> Markus
>
> --  
> Dipl.-Tech. Math. Markus Schmidberger
>
> Ludwig-Maximilians-Universit?t M?nchen
> IBE - Institut f?r medizinische Informationsverarbeitung,
> Biometrie und Epidemiologie
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Mike Lawrence
Graduate Student, Department of Psychology, Dalhousie University

Website: http://myweb.dal.ca/mc973993
Public calendar: http://icalx.com/public/informavore/Public

"The road to wisdom? Well, it's plain and simple to express:
Err and err and err again, but less and less and less."
	- Piet Hein


From d.scott at auckland.ac.nz  Mon Jun 11 14:24:54 2007
From: d.scott at auckland.ac.nz (David Scott)
Date: Tue, 12 Jun 2007 00:24:54 +1200 (NZST)
Subject: [R] Recoding
Message-ID: <Pine.LNX.4.64.0706120020160.11381@stat12.stat.auckland.ac.nz>


I want to do some recoding of variables: code Age into groups and recode a 
factor into a smaller number of levels.

There are a couple of options for recode functions, in the car package and 
in memisc, and I think in gmisc.

Does anyone have any opinions on the the easiest, most reliable approach 
for these problems?

David Scott

_________________________________________________________________
David Scott	Department of Statistics, Tamaki Campus
 		The University of Auckland, PB 92019
 		Auckland 1142,    NEW ZEALAND
Phone: +64 9 373 7599 ext 86830		Fax: +64 9 373 7000
Email:	d.scott at auckland.ac.nz

Graduate Officer, Department of Statistics
Director of Consulting, Department of Statistics


From wl2776 at gmail.com  Mon Jun 11 14:35:38 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Mon, 11 Jun 2007 05:35:38 -0700 (PDT)
Subject: [R] Selecting all values smaller than X in a dataframe
In-Reply-To: <466D3B89.8020007@agr.uni-goettingen.de>
References: <466D3B89.8020007@agr.uni-goettingen.de>
Message-ID: <11059804.post@talk.nabble.com>



Christoph Scherber-2 wrote:
> 
> Dear R users,
> 
> I have a correlation matrix for a dataframe called "synth", for which I 
> now want to select only those cells that have correlations larger than 
> +/-0.6:
> 
> synth=data.frame(x=rnorm(10,1),y=rnorm(10,2),z=rnorm(10,0.5))
> 
> w=cor(synth,use="pairwise.complete.obs")
> w=as.data.frame(w)
> w[,sapply(w,abs(w),">",0.6)]
> 
> The problem is that using sapply with ">" or "<" doesn?t seem to work.
> 
> How could I solve this problem?
> 
> 

If you want to extract correlations with absolute value >0.6, then simply
use w[abs(w)>0.6]

Please, reread the help("sapply"). You give some extra arguments to this
function.
The first goes the vector, the second goes the function, and then -
additional arguments to the function.
Probably, you wanted w[sapply(abs(w),">",0.6)]
This gives the same result.

-- 
View this message in context: http://www.nabble.com/Selecting-all-values-smaller-than-X-in-a-dataframe-tf3901238.html#a11059804
Sent from the R help mailing list archive at Nabble.com.


From petr.pikal at precheza.cz  Mon Jun 11 14:43:31 2007
From: petr.pikal at precheza.cz (Petr PIKAL)
Date: Mon, 11 Jun 2007 14:43:31 +0200
Subject: [R] Odp:  Selecting all values smaller than X in a dataframe
In-Reply-To: <466D3B89.8020007@agr.uni-goettingen.de>
Message-ID: <OFACD34609.7180FAEA-ONC12572F7.00459DE9-C12572F7.0045E4C5@precheza.cz>

Hi

r-help-bounces at stat.math.ethz.ch napsal dne 11.06.2007 14:09:45:

> Dear R users,
> 
> I have a correlation matrix for a dataframe called "synth", for which I 
> now want to select only those cells that have correlations larger than 
> +/-0.6:
> 
> synth=data.frame(x=rnorm(10,1),y=rnorm(10,2),z=rnorm(10,0.5))
> 
> w=cor(synth,use="pairwise.complete.obs")
> w=as.data.frame(w)

Why? Better is tu use

abs(w)>.6

and/or

which(abs(w)>.6, arr.ind=T)

or, if you want actual values just

w[abs(w)>.6]

Regards

Petr

> w[,sapply(w,abs(w),">",0.6)]
> 
> The problem is that using sapply with ">" or "<" doesn?t seem to work.
> 
> How could I solve this problem?
> 
> Thank you very much in advance for your help!
> 
> Best wishes
> Christoph
> 
> (I am using R 2.5.0 on Windows XP).
> 
> 
> 
> --
> Christoph Scherber
> DNPW, Agroecology
> University of Goettingen
> Waldweg 26
> D-37073 Goettingen
> 
> +49-(0)551-39-8807
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From luke at stat.uiowa.edu  Mon Jun 11 14:54:10 2007
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Mon, 11 Jun 2007 07:54:10 -0500 (CDT)
Subject: [R] simultaneous computing
In-Reply-To: <466D3C0D.1070800@ibe.med.uni-muenchen.de>
References: <466D3C0D.1070800@ibe.med.uni-muenchen.de>
Message-ID: <Pine.LNX.4.64.0706110753490.23046@nokomis.stat.uiowa.edu>

The package snow available from CRAN is one possibility.

Best,

luke

On Mon, 11 Jun 2007, Markus Schmidberger wrote:

> Hello,
>
> which possibilities are available in R for simultaneous or parallel
> computing?
> I only could find biopara
> (http://cran.r-project.org/src/contrib/Descriptions/biopara.html)
>
> Are there other possibilities?
> Are there special groups working on simultaneous computing with R?
>
> Thanks
> Markus
>
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From tlumley at u.washington.edu  Mon Jun 11 15:06:32 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 11 Jun 2007 06:06:32 -0700 (PDT)
Subject: [R] Looking for R-code for non-negative matrix factorization in
 the presence of Gaussian or Poisson noise
In-Reply-To: <156CDC8CCFD1894295D2907F16337A4801420B79@bru-s-006.europe.shell.com>
References: <156CDC8CCFD1894295D2907F16337A4801420B79@bru-s-006.europe.shell.com>
Message-ID: <Pine.LNX.4.64.0706110553540.9440@homer23.u.washington.edu>

On Mon, 11 Jun 2007, christian.ritter at shell.com wrote:

>
> Hi all,
>
> Has any of you implemented code for non-negative matrix factorization to 
> solve
>
> Y=T P' +E; dim(Y)=n,p ; dim(T)=n,nc; dim (P)=(p,nc); dim(E)=n,p
>
> where T and P must be non-negative and E either Gaussian or Poisson noise.
>
> I'm looking for two variants:
>
> 1. Easy (I think), T is known (that is we just want to solve the general 
> inverse problem)

This is non-negative least squares, a quadratic programming problem, for 
which there is code (at least if n and nc are not too big)

>
> 2. Harder (?), T is unknown (under some restrictions) [as an 
> intermediate, we may want to fix nc]
>

Even with fixed nc this is Distinctly Non-trivial. It often isn't 
identifiable, for a start.

I've encountered this problem in air pollution source apportionment, where 
people use an algorithm due to Paatero (1999) JCGS 8:854-8, which is a 
conjugate gradient algorithm that handles the constraints by creative 
abuse of preconditioning.  The algorithm seems fairly well-behaved, 
although the statistical properties of the estimates are not 
well-understood [at least, I don't understand them, and I have simulations 
that appear to contradict the views of people who claim to understand 
them].

The difficulty probably depends on the size of the problem -- the air 
pollution problems have n~1000, p~20, nc~7, or larger.

 	-thomas


From mothsailor at googlemail.com  Mon Jun 11 15:10:12 2007
From: mothsailor at googlemail.com (David Barron)
Date: Mon, 11 Jun 2007 14:10:12 +0100
Subject: [R] Recoding
In-Reply-To: <Pine.LNX.4.64.0706120020160.11381@stat12.stat.auckland.ac.nz>
References: <Pine.LNX.4.64.0706120020160.11381@stat12.stat.auckland.ac.nz>
Message-ID: <815b70590706110610i2baff68j933f7bc212240027@mail.gmail.com>

I've used the one in car with no problems.  For grouping a continuous
variable you might also consider cut.

On 11/06/07, David Scott <d.scott at auckland.ac.nz> wrote:
>
> I want to do some recoding of variables: code Age into groups and recode a
> factor into a smaller number of levels.
>
> There are a couple of options for recode functions, in the car package and
> in memisc, and I think in gmisc.
>
> Does anyone have any opinions on the the easiest, most reliable approach
> for these problems?
>
> David Scott
>
> _________________________________________________________________
> David Scott     Department of Statistics, Tamaki Campus
>                 The University of Auckland, PB 92019
>                 Auckland 1142,    NEW ZEALAND
> Phone: +64 9 373 7599 ext 86830         Fax: +64 9 373 7000
> Email:  d.scott at auckland.ac.nz
>
> Graduate Officer, Department of Statistics
> Director of Consulting, Department of Statistics
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
=================================
David Barron
Said Business School
University of Oxford
Park End Street
Oxford OX1 1HP


From michaeli at gfz-potsdam.de  Mon Jun 11 15:03:14 2007
From: michaeli at gfz-potsdam.de (Ingo Michaelis)
Date: Mon, 11 Jun 2007 13:03:14 +0000 (UTC)
Subject: [R] Selecting all values smaller than X in a dataframe
References: <466D3B89.8020007@agr.uni-goettingen.de>
Message-ID: <loom.20070611T150007-317@post.gmane.org>

Christoph Scherber <Christoph.Scherber <at> agr.uni-goettingen.de> writes:

> 
> Dear R users,
> 
> I have a correlation matrix for a dataframe called "synth", for which I 
> now want to select only those cells that have correlations larger than 
> +/-0.6:
> 
> synth=data.frame(x=rnorm(10,1),y=rnorm(10,2),z=rnorm(10,0.5))
> 
> w=cor(synth,use="pairwise.complete.obs")
> w=as.data.frame(w)
> w[,sapply(w,abs(w),">",0.6)]
 

Dear Christoph,

just change the last command to

w[abs(w)>0.6]


Best wishes
Ingo


From joseclaudio.faria at terra.com.br  Mon Jun 11 15:23:34 2007
From: joseclaudio.faria at terra.com.br (terra)
Date: Mon, 11 Jun 2007 10:23:34 -0300
Subject: [R] biplot package II
Message-ID: <466D4CD6.8050807@terra.com.br>

Dear all,

I've been learning biplot (Gabriel, 1971) and some days ago I sent for
this list a procedural function with invitation for a collaborative package.
Jari Oksanen made some suggestions and I agree with all.

So, I reworked the function under the object-oriented programming
(OOP/S3). I think it is now a good frame for more resources.

Below it is the function and a small script to learn it:

#===============================================================================
# Name           : biplot.s
# Author         : Jose Claudio Faria (DCET/USC/BRAZIL)
# Date (dd/mm/yy): 9/6/2007 13:33:48
# Version        : v1.1
# Aim            : 2d and 3d (under scaterplot3d and rgl packages) biplot
# Mail           : joseclaudio.faria em terra.com.br
#===============================================================================
# Arguments:
# x             Data (frame or matrix: objects in lines variables in columns)
#               or a object of the class 'prcomp'.
# lambda.ini    First eigenvalue to be considered (default is 1)
# lambda.end    Latest eigenvalue to be considered
#               (default is 2 to 2d or 3 to 3d)
# center        Either a logical value or a numeric vector of length equal
#               to the number of columns of x (TRUE is the default).
# scale         Either a logical value or a numeric vector of length equal
#               to the number of columns of x (FALSE is the default).
# weight        Way of factorize: 'equal', 'objects', 'variables'
#               ('equal' is the default).
# plot          Logical to produce or not a graphical representation of
#               biplot (TRUE is the default).
# rgl.use       If TRUE the 3d scatter will be under the rgl environment, in
#               another way the scatterplot3d will be used ( the default).
# aspect3d      Apparent ratios of the x, y, and z axes of the bounding box.
# clear3d       Logical to clear or not a 3d graphical representation of
#               biplot before to make a new (TRUE is the default).
# simple.axes   Whether to draw simple axes (TRUE or FALSE).
# box           Whether to draw a box (the default is FALSE).
# spheres       Logical to represent objects as spheres (FALSE is the default).
# sphere.factor Relative size factor of sphere representing points; the
#               default size is dependent on the scale of observations.
# col.obj       Color of spheres or labels of objects.
# col.var       Color of lines and labels of variables.
# var.factor    Factor of expansion/reduction of length lines of the variables.
#               graphical variables representation (<=1, 1 is the default).
# cex           Character expansion (for while valid only to graphics and
#               scatterplot3d, not to rgl, packages).
#===============================================================================
# Require       'rgl' and 'scatterplot3d' packages.
#===============================================================================

# check the necessary packages
necessary = c('rgl', 'scatterplot3d')
if(!all(necessary %in% installed.packages()[, 'Package']))
   install.packages(c('rgl', 'scatterplot3d'), dep = T)

# Plot 2d with 'graphics' packages
plot.biplot.2d = function(scores,
                           g,
                           hl,
                           lambda.ini,
                           lambda.end,
                           col.obj,
                           col.var,
                           var.factor,
                           cex)
{
   plot(scores,
        xlab=paste('PC', lambda.ini, sep=''),
        ylab=paste('PC', lambda.end, sep=''),
        type='n')
   text(x=g[,1], y=g[,2],
        labels=rownames(g),
        cex=cex, col=col.obj)
   arrows(x0=0, y0=0,
          x1=hl[,1]*var.factor, y1=hl[,2]*var.factor,
          length=0.1, angle=20,
          col=col.var)
   text(x=hl[,1]*var.factor, y=hl[,2]*var.factor,
        labels = rownames(hl),
        cex=cex, col=col.var)
}

# Plot 3d with 'scatterplot3d' package
plot.biplot.3d.default = function(scores,
                                   g,
                                   hl,
                                   lambda.ini,
                                   lambda.end,
                                   col.obj,
                                   col.var,
                                   var.factor,
                                   spheres,
                                   box,
                                   cex)
{
   require(scatterplot3d)
   graph = scatterplot3d(scores,
                         type = if(spheres) 'p' else 'n',
                         xlab=paste('PC', lambda.ini, sep=''),
                         ylab=paste('PC', lambda.ini+1, sep=''),
                         zlab=paste('PC', lambda.end, sep=''),
                         grid=F,
                         box=box,
                         cex.symbols=cex,
                         color=col.obj,
                         pch=20)
    if(!spheres)
      text(graph$xyz.convert(g),
           labels=rownames(g),
           col=col.obj, cex=cex)
   for(i in 1:nrow(hl)) {
     graph$points3d(c(0, hl[i,1]*var.factor),
                    c(0, hl[i,2]*var.factor),
                    c(0, hl[i,3]*var.factor),
                    type='l', col=col.var)
   }
   text(graph$xyz.convert(hl*var.factor),
        labels=rownames(hl),
        col=col.var, cex=cex)
}

# Plot 3d with 'rgl' package
plot.biplot.3d.rgl = function(g,
                               hl,
                               lambda.ini,
                               lambda.end,
                               simple.axes,
                               clear3d,
                               aspect3d,
                               col.obj,
                               col.var,
                               var.factor,
                               spheres,
                               sphere.factor,
                               box)
{
   require(rgl)
   size = max(g)/20 * sphere.factor
   if (clear3d)
     clear3d()
   if (spheres)
     spheres3d(g, col=col.obj, radius=size, alpha=.5)
   else
     text3d(g, texts=rownames(g), col=col.obj, alpha=.5)
   aspect3d(aspect3d)
   for(i in 1:nrow(hl)) {
     segments3d(rbind(matrix(0, nc=3),
                hl[i,]*var.factor),
                col=col.var)
   }
   text3d(hl*var.factor,
          texts=rownames(hl),
          col=col.var)
   if(simple.axes) {
     axes3d(c('x', 'y', 'z'))
     title3d(xlab=paste('PC', lambda.ini, sep=''),
             ylab=paste('PC', lambda.ini+1, sep=''),
             zlab=paste('PC', lambda.end, sep=''))
   }
   else
     decorate3d(xlab=paste('PC', lambda.ini, sep=''),
                ylab=paste('PC', lambda.ini+1, sep=''),
                zlab=paste('PC', lambda.end, sep=''),
                box = box)
}

plot.biplot = function(scores,
                        g,
                        hl,
                        lambda.ini,
                        lambda.end,
                        rgl.use,
                        simple.axes,
                        clear3d,
                        aspect3d,
                        col.obj,
                        col.var,
                        var.factor,
                        spheres,
                        sphere.factor,
                        size,
                        box,
                        cex)
{
   n.values = (lambda.end - lambda.ini + 1)
   if(n.values == 2) plot.biplot.2d(scores,
                                    g,
                                    hl,
                                    lambda.ini,
                                    lambda.end,
                                    col.obj,
                                    col.var,
                                    var.factor,
                                    cex)

   else if(n.values == 3)
     if (!rgl.use)
       plot.biplot.3d.default(scores,
                              g,
                              hl,
                              lambda.ini,
                              lambda.end,
                              col.obj,
                              col.var,
                              var.factor,
                              spheres,
                              box,
                              cex)

     else
       plot.biplot.3d.rgl(g,
                          hl,
                          lambda.ini,
                          lambda.end,
                          simple.axes,
                          clear3d,
                          aspect3d,
                          col.obj,
                          col.var,
                          var.factor,
                          spheres,
                          sphere.factor,
                          box)
}

# main function
biplot.s = function(x, ...) UseMethod('biplot.s', x)

# x is 'data.frame' or 'matrix'
biplot.s.default = function(x,
                             lambda.ini=1,
                             lambda.end=2,
                             center=T,
                             scale=F,
                             weight=c('equal', 'objects', 'variables'),
                             plot=T,
                             rgl.use=F,
                             aspect3d=c(1, 1, 1),
                             clear3d=T,
                             simple.axes=T,
                             box=F,
                             spheres=F,
                             sphere.factor=1,
                             col.obj=1,
                             col.var=2,
                             var.factor=1,
                             cex=.6)
{
   stopifnot(is.matrix(x) || is.data.frame(x))
   n.values = (lambda.end - lambda.ini + 1)
   if(n.values < 2 || n.values > 3)
     stop('Please, check the parameters: lambda.ini and lambda.end!')

   x = as.matrix(x)
   x = scale(x, center=center, scale=scale)
   svdx = svd(x)
   s2 = diag(sqrt(svdx$d[lambda.ini:lambda.end]))
   # 'prcomp.default' of 'stats' package (and 'pca' of 'pcurve') is like the below!
   #s2 = diag(svdx$d[lambda.ini:lambda.end])

   switch(match.arg(weight),
     equal = {
       g  = svdx$u[,lambda.ini:lambda.end] %*% s2
       h  = s2 %*% t(svdx$v[,lambda.ini:lambda.end])
       hl = t(h)
     },
     objects = {
       g  = svdx$u[,lambda.ini:lambda.end] %*% s2
       h  = t(svdx$v[,lambda.ini:lambda.end])
       hl = t(h)
     },
     variables = {
       g  = svdx$u[,lambda.ini:lambda.end]
       h  = s2 %*% t(svdx$v[,lambda.ini:lambda.end])
       hl = t(h)
     })

   if(is.null(rownames(x)))
     rownames = 1:nrow(x)
   else
     rownames = rownames(x)
   if(is.null(colnames(x)))
     colnames = paste('V', 1:ncol(x), sep='')
   else
     colnames = colnames(x)

   cnames       = paste('PC', lambda.ini:lambda.end, sep='')
   rownames(g)  = rownames
   colnames(g)  = cnames
   rownames(hl) = colnames
   colnames(hl) = cnames
   scores       = rbind(g, hl)
   rownames(scores) = c(rownames, colnames)
   colnames(scores) = cnames

   res = list(values=svdx$d,
              explained=round(sum(svdx$d[lambda.ini:lambda.end]^2) /
                              sum(svdx$d^2), 3),
              objects=g,
              variables=hl,
              all=scores)

   if(plot) {
     scores = rbind(g, hl*var.factor)
     scores = rbind(scores, rep(0, n.values)) # to correct visualization

     plot.biplot(scores,
                 g,
                 hl,
                 lambda.ini,
                 lambda.end,
                 rgl.use,
                 simple.axes,
                 clear3d,
                 aspect3d,
                 col.obj,
                 col.var,
                 var.factor,
                 spheres,
                 sphere.factor,
                 size,
                 box,
                 cex)
   }
   invisible(res)
}

# x is of the class 'prcomp'
biplot.s.prcomp = function(x,
                            lambda.ini=1,
                            lambda.end=2,
                            ...)
{
   stopifnot(class(x) == 'prcomp')
   if (!length(x$x))
     stop(gettextf("object '%s' has no objects coordinates!",
          deparse(substitute(x))), domain = NA)
   if (is.complex(x$x))
     stop("biplots are not defined for complex PCA!")

   n.values = (lambda.end - lambda.ini + 1)
   if(n.values < 2 || n.values > 3)
     stop('Please, check the parameters: lambda.ini and lambda.end!')

   # Go back from prcom, i.e, regenerate the x already scaled under 'prcomp'
   # due to necessity of different kinds of factoration!
   # I'm still in doubt if this is the best alternative!
   xreg = x$x %*% (solve(t(x$rotation) %*% x$rotation) %*% t(x$rotation))
   #xreg = x$x %*% ginv(x$rotation) # another option
   biplot.s.default(xreg,
                    lambda.ini,
                    lambda.end,
                    center=ifelse(x$center[1] == F, F, T),
                    scale=ifelse(x$scale[1] == F, F, T),
                    ...)
}

#===============================================================================
# Name           : biplot.s_to_learn
# Author         : Jose Claudio Faria (DCET/USC/BRAZIL)
# Date (dd/mm/yy): 9/6/2007 13:33:32
# Version        : v1.1
# Aim            : to learn and to test the 'biplot.s' function
# Mail           : joseclaudio.faria em terra.com.br
#===============================================================================

#===============================================================================
# to debug 'biplot.s' functions
#===============================================================================
#mtrace(biplot.s.2d, T)
#mtrace(biplot.s.3d.default, T)
#mtrace(biplot.s.3d.rgl, T)
#mtrace(biplot.s.default, T)
#mtrace(biplot.s.prcomp, T)
#
#mtrace(biplot.s.2d, F)
#mtrace(biplot.s.3d.default, F)
#mtrace(biplot.s.3d.rgl, F)
#mtrace(biplot.s.default, F)
#mtrace(biplot.s.prcomp, F)

#===============================================================================
# example: Gabriel(1971)
#===============================================================================
gabriel.1971 = matrix(c(98.2, 97.2, 97.3, 96.9, 97.6, 94.4, 90.2, 94.0, 70.5,
                         78.8, 81.0, 65.6, 73.3, 91.4, 88.7, 82.2, 84.2, 55.1,
                         14.4, 17.6,  6.0,  9.6, 56.2, 69.5, 31.8, 19.5, 10.7,
                         86.2, 82.1, 54.5, 74.7, 87.2, 80.4, 68.6, 65.5, 26.1,
                         32.9, 30.3, 21.1, 26.9, 80.1, 74.3, 46.3, 36.2,  9.8,
                         73.0, 70.4, 53.0, 60.5, 81.2, 78.0, 67.9, 64.8, 57.1,
                          4.6,  6.0,  1.5,  3.4, 12.7, 23.0,  5.6,  2.7,  1.3,
                         29.2, 26.3,  5.3, 10.5, 52.8, 49.7, 21.7,  9.5,  1.2),
                         nr=8, byrow=T)

dimnames(gabriel.1971) = list(c('toilet', 'kitchen', 'bath', 'eletricity',
                                 'water', 'radio', 'tv set', 'refrigerator'),
                               c('CRISTIAN', 'ARMENIAN', 'JEWISH', 'MOSLEM',
                                 'MODERN_1', 'MODERN_2', 'OTHER_1', 'OTHER_2',
                                 'RUR'))

#===============================================================================
# 2d with graphics package
#===============================================================================
x = gabriel.1971
bp1 = biplot.s(x, plot=F)
bp1$val
bp1$expl
bp1$obj
bp1$var
bp1$all

biplot.s(x, center=F, scale=F)
biplot.s(x, center=T, scale=F)
biplot.s(x, center=T, scale=T)
biplot.s(x, lambda.ini=2, lambda.end=3)
biplot.s(x, lambda.ini=2, lambda.end=3, scale=T)
biplot.s(x, scale=T, weight='eq')
biplot.s(x, scale=T, weight='ob')
biplot.s(x, scale=T, weight='va')

#===============================================================================
# 3d with scatterplot3d package
#===============================================================================
x = gabriel.1971
bp2 = biplot.s(x, lambda.end=3, plot=F)
bp2$val
bp2$expl
bp2$obj
bp2$var
bp2$all

biplot.s(x, lambda.end=3)
biplot.s(x, lambda.ini=2, lambda.end=4)
biplot.s(x, lambda.end=3, spheres=T, box=T)
biplot.s(x, lambda.end=3, col.obj='gray', col.var='red', var.factor=.8)
biplot.s(x, lambda.end=3, center=T, scale=T, weight='eq')
biplot.s(x, lambda.end=3, center=T, scale=F, weight='eq')
biplot.s(x, lambda.end=3, center=T, scale=T, weight='ob')
biplot.s(x, lambda.end=3, center=T, scale=F, weight='ob')
biplot.s(x, lambda.end=3, center=T, scale=T, weight='va')
biplot.s(x, lambda.end=3, center=T, scale=T, weight='va', var.factor=.5)

#===============================================================================
# 2d associated with 'prcomp' function ('stas' package)
#===============================================================================
biplot.s(prcomp(gabriel.1971, center=T, scale=F), plot=T)
biplot.s(prcomp(gabriel.1971, center=T, scale=T), plot=T)

pc = prcomp(gabriel.1971, center=T, scale=F)
biplot(pc) # to compare
bp = biplot.s(pc)
bp$val
bp$expl
bp$obj
bp$var
bp$all

biplot.s(pc, lambda.ini=2, lambda.end=4)
biplot.s(pc, lambda.end=3, spheres=T, box=T)
biplot.s(pc, lambda.end=3, col.obj='gray', col.var='red', var.factor=.8)
biplot.s(pc, lambda.end=3, weight='eq')
biplot.s(pc, lambda.end=3, weight='ob')
biplot.s(pc, lambda.end=3, weight='va')
biplot.s(pc, lambda.end=3, weight='va', var.factor=.5)

#===============================================================================
# 3d with rgl package
#===============================================================================
x = gabriel.1971
clear3d()
rgl.bringtotop(stay=T)
biplot.s(x, lambda.end=3, rgl.use=T)
rgl.bringtotop(stay=T)
biplot.s(x, lambda.end=3, rgl.use=T, box=T, aspect3d=c(1.5, 1.5, 1))
rgl.bringtotop(stay=T)
biplot.s(x, lambda.end=3, rgl.use=T, col.obj=3, col.var=4, var.factor=.5)
rgl.bringtotop(stay=T)
biplot.s(x, lambda.end=3, rgl.use=T, spheres=T)
rgl.bringtotop(stay=T)
biplot.s(x, lambda.end=3, rgl.use=T, weight='eq')
rgl.bringtotop(stay=T)
biplot.s(x, lambda.end=3, rgl.use=T, weight='ob')
rgl.bringtotop(stay=T)
biplot.s(x, lambda.end=3, rgl.use=T, weight='va')
rgl.bringtotop(stay=T)
biplot.s(x, lambda.end=3, rgl.use=T, weight='va', var.factor=.09)

rgl.bringtotop(stay=T)
biplot.s(prcomp(gabriel.1971, center=T, scale=F), lambda.end=3, rgl.use=T, plot=T)

Regards,
-- 
/////\\\\\/////\\\\\/////\\\\\/////\\\\\
  Jose Claudio Faria
  Brasil/Bahia/UESC/DCET
  Estatistica Experimental/Prof. Titular
    joseclaudio.faria em terra.com.br
    joseclaudio.faria em oi.com.br
    jc_faria em uesc.br
    jc_faria em uol.com.br
  Tels:
    73-3634.2779 (res - Ilheus/BA)
    19-3435.1536 (res - Piracicaba/SP) *
    19-9144.8979 (cel - Piracicaba/SP) *
/////\\\\\/////\\\\\/////\\\\\/////\\\\\


From micheledemeo at gmail.com  Mon Jun 11 16:13:36 2007
From: micheledemeo at gmail.com (MICHELE DE MEO)
Date: Mon, 11 Jun 2007 16:13:36 +0200
Subject: [R] Gini coefficient in R
Message-ID: <3bb56c8a0706110713k25661ba2pd7ceaa5116140285@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070611/1d3bd9c6/attachment.pl 

From dimitris.rizopoulos at med.kuleuven.be  Mon Jun 11 16:38:49 2007
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Mon, 11 Jun 2007 16:38:49 +0200
Subject: [R] Gini coefficient in R
References: <3bb56c8a0706110713k25661ba2pd7ceaa5116140285@mail.gmail.com>
Message-ID: <006201c7ac36$397b1e90$0540210a@www.domain>

try this version instead:

gini <- function(x, unbiased = TRUE, na.rm = FALSE){
    if (!is.numeric(x)){
        warning("'x' is not numeric; returning NA")
        return(NA)
    }
    if (!na.rm && any(na.ind <- is.na(x)))
        stop("'x' contain NAs")
    if (na.rm)
        x <- x[!na.ind]
    n <- length(x)
    mu <- mean(x)
    N <- if (unbiased) n * (n - 1) else n * n
    ox <- x[order(x)]
    dsum <- drop(crossprod(2 * 1:n - n - 1,  ox))
    dsum / (mu * N)
}

########################

gini(c(100,0,0,0))


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "MICHELE DE MEO" <micheledemeo at gmail.com>
To: <r-help at stat.math.ethz.ch>
Sent: Monday, June 11, 2007 4:13 PM
Subject: [R] Gini coefficient in R


> If I use the Ineq library and the Gini function in this way:
>
>>Gini(c(100,0,0,0))
>
> I obtain the result 0.75 instead of 1 (that is the perfect 
> inequality).
>
> I think Gini's formula in Ineq is based on a formula as reported 
> here:
> http://mathworld.wolfram.com/GiniCoefficient.html
>
> but in the case of perfect inequality:
>
> x_1=.......=x_n-1 =0
>
> x_n>0
>
> these formula are equal to 1 - 1/n, not to 1.
>
> ....I don't know where I'm wrong....
>
>
> -- 
> Michele De Meo
> http://micheledemeo.blogspot.com/
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm


From P.Dalgaard at biostat.ku.dk  Mon Jun 11 16:56:52 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 11 Jun 2007 16:56:52 +0200
Subject: [R] Rounding?
In-Reply-To: <644e1f320706110431k51d69340k84b3c7d454e3d2c8@mail.gmail.com>
References: <40D3930AC1C8EA469E39536E5BC80835044EB390@EXDKBA021.corp.novocorp.net>
	<644e1f320706110431k51d69340k84b3c7d454e3d2c8@mail.gmail.com>
Message-ID: <466D62B4.10806@biostat.ku.dk>

jim holtman wrote:
> your number 6.6500000000000001 is to large to fit in a floating point
> number.  It takes 56 bits and there are only 54 in a real number so the
> system see it as 6.65 and does the rounding to an even digit; 6.6
>
> 6.650000000000001 does fit into a real number (takes 54 bits) and this will
> now round to 6.7
>
>   
Actually, a bit more insidious than that because 6.65 does not have an
exact binary representation. Hence

> round(66.5)
[1] 66
> round(6.65,1)
[1] 6.7
> round(0.665,2)
[1] 0.66

Notice that these are from Linux and differ from what you get on Windows.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From qin.qin at abbott.com  Mon Jun 11 17:05:39 2007
From: qin.qin at abbott.com (Qin Qin)
Date: Mon, 11 Jun 2007 10:05:39 -0500
Subject: [R] design package
Message-ID: <OFC3C943FF.6260910D-ON862572F7.005273D0-862572F7.0052FAB1@abbott.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070611/a6fe0e1c/attachment.pl 

From carmei3 at web.de  Mon Jun 11 17:21:20 2007
From: carmei3 at web.de (Carmen Meier)
Date: Mon, 11 Jun 2007 17:21:20 +0200
Subject: [R] p-value from GEE why factor 2*pnorm?
In-Reply-To: <E1Hvs4m-0000hS-HM@www19.emo.freenet-rz.de>
References: <E1Hvs4m-0000hS-HM@www19.emo.freenet-rz.de>
Message-ID: <466D6870.1060005@web.de>

I got an answer for the other question (thank you)

But there is another question  (I am afraid this is a basic question ...)

In this tread there is a hint hwo to calculate the p-vlue of an GEE:
> _http://finzi.psych.upenn.edu/R/Rhelp02a/archive/74150.html_ 
>
> Then, get the P values using a normal approximation for the 
> distribution of z:
>
> /> 2 * pnorm(abs(coef(summary(fm1))[,5]), lower.tail = FALSE) / 
> (Intercept) TPTLD  0.00000000 0.04190831 

1. why is the result multiplicated  with 2? There is a P-value between 1 and 2
with the results below and multiplicated with 2: 

2*pnorm(c(1.8691945,0.5882351,2.4903091,1.9287802,2.3172983,2.2092593,2.2625959,1.6395695),
lower.tail =TRUE)  

Regards Carmen


From bcarvalh at jhsph.edu  Mon Jun 11 17:25:14 2007
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Mon, 11 Jun 2007 11:25:14 -0400
Subject: [R] p-value from GEE why factor 2*pnorm?
In-Reply-To: <466D6870.1060005@web.de>
References: <E1Hvs4m-0000hS-HM@www19.emo.freenet-rz.de>
	<466D6870.1060005@web.de>
Message-ID: <651DAEB4-431D-4FF5-A98C-D33009AB4CE1@jhsph.edu>

the recommendation was to use lower.tail=FALSE.

b

On Jun 11, 2007, at 11:21 AM, Carmen Meier wrote:

> I got an answer for the other question (thank you)
>
> But there is another question  (I am afraid this is a basic  
> question ...)
>
> In this tread there is a hint hwo to calculate the p-vlue of an GEE:
>> _http://finzi.psych.upenn.edu/R/Rhelp02a/archive/74150.html_
>>
>> Then, get the P values using a normal approximation for the
>> distribution of z:
>>
>> /> 2 * pnorm(abs(coef(summary(fm1))[,5]), lower.tail = FALSE) /
>> (Intercept) TPTLD  0.00000000 0.04190831
>
> 1. why is the result multiplicated  with 2? There is a P-value  
> between 1 and 2
> with the results below and multiplicated with 2:
>
> 2*pnorm(c 
> (1.8691945,0.5882351,2.4903091,1.9287802,2.3172983,2.2092593,2.2625959 
> ,1.6395695),
> lower.tail =TRUE)
>
> Regards Carmen


From qyang at bu.edu  Mon Jun 11 17:32:00 2007
From: qyang at bu.edu (Qiong Yang)
Date: Mon, 11 Jun 2007 11:32:00 -0400
Subject: [R] lmekin() function in kinship package
Message-ID: <466D6AF0.6080208@bu.edu>

Hi,

I had a problem with the lmekin() in kinship package: 
lmekin() can not be wrapped into another function

library(kinship)
#creat an example dataset
xx<-rnorm(100)
yy<-rnorm(100)
id<-1:100  
test.dat<-as.data.frame(cbind(xx,yy,id))
rm(xx,yy,id)
a<-bdsmatrix(rep(10,10),rep(block,10),dimnames=list(c(1:100),c(1:100)))  
#100x100 block (n=10) diagonal matrix to indicate the correlation between the 100 observations

#this works, call lmekin directly
lmekin(yy~xx,random=~1|id,data=test.dat,varlist=a,na.action=na.omit)

#this doesn't work, wrap into another function

fo<-function(x,y,z,data)lmekin(y~x,random=~1|z,data=test.dat,varlist=a,na.action=na.omit)
fo(xx,yy,id)

Error in eval(expr, envir, enclos) : Object "y" not found

I did line by line debug within lmekin(). I found the problem was from 
line #25
m <- eval(m, sys.parent())

Here is the print(m) result before this line
[1] model.frame(data = data, na.action = na.omit, formula = y ~ x +z)

I will appreciate anyone help me figure out why data cannot be passed 
to the arguments when lmekin() is wrapped into another function? And what can be done
to fix it? 


Thanks

Qiong


From tramni at abv.bg  Mon Jun 11 17:32:37 2007
From: tramni at abv.bg (Martin Ivanov)
Date: Mon, 11 Jun 2007 18:32:37 +0300 (EEST)
Subject: [R] autoregressive spectral density estimate by andrews' plug-in
 method?
Message-ID: <1885630564.80201181575957920.JavaMail.nobody@mail22.abv.bg>

Hello!
I would like to ask if there is in R a function that estimates the spectral density function of a stochastic series at frequency zero by the "plug-in method", advocated by Andrews in his paper "Heteroscedasticity and Autocorrelation Consistent Covariance Matrix Estimation", Econometrica, 59,817-858. I saw R has functions that employ Andrews' plug-in method using an AR(1) approximation for the estimation of the variance-covariance matrix in linear models. They come with the sandwich package. The so called "meat" is actually the estimate of the spectral density matrix of the model coefficients at frequency zero. However, I have a time series of length 160 and I need to estimate its spectral density via Andrews methodology. Any suggestions will be appreciated.
Excuse me if I am asking something obvious.

Regards,
Martin

-----------------------------------------------------------------
???? ???????? ???? ? ???! 
http://musicidol.btv.bg/


From carmei3 at web.de  Mon Jun 11 17:34:00 2007
From: carmei3 at web.de (Carmen Meier)
Date: Mon, 11 Jun 2007 17:34:00 +0200
Subject: [R] p-value from GEE why factor 2*pnorm?
In-Reply-To: <651DAEB4-431D-4FF5-A98C-D33009AB4CE1@jhsph.edu>
References: <E1Hvs4m-0000hS-HM@www19.emo.freenet-rz.de>
	<466D6870.1060005@web.de>
	<651DAEB4-431D-4FF5-A98C-D33009AB4CE1@jhsph.edu>
Message-ID: <466D6B68.2050602@web.de>

Benilton Carvalho schrieb:
> the recommendation was to use lower.tail=FALSE.
>
> b
>
> O
but then the results are significant and this does not match the 
observation.
The results are matching the observations if the formula is

pnorm(c(1.8691945,0.5882351,2.4903091,1.9287802,2.3172983,2.2092593,2.2625959,1.6395695),
lower.tail =TRUE) 

so I have any unknown problem .... anywhere :-(

REgards Carmen


From ral at lcfltd.com  Mon Jun 11 17:38:29 2007
From: ral at lcfltd.com (Robert A LaBudde)
Date: Mon, 11 Jun 2007 11:38:29 -0400
Subject: [R] p-value from GEE why factor 2*pnorm?
In-Reply-To: <466D6870.1060005@web.de>
References: <E1Hvs4m-0000hS-HM@www19.emo.freenet-rz.de>
	<466D6870.1060005@web.de>
Message-ID: <0JJH005PVA4AOTD0@vms044.mailsrvcs.net>

At 11:21 AM 6/11/2007, Carmen wrote:
><snip>
>In this tread there is a hint hwo to calculate the p-vlue of an GEE:
> > _http://finzi.psych.upenn.edu/R/Rhelp02a/archive/74150.html
> >
> > Then, get the P values using a normal approximation for the
> > distribution of z:
> >
> > /> 2 * pnorm(abs(coef(summary(fm1))[,5]), lower.tail = FALSE) /
> > (Intercept) TPTLD  0.00000000 0.04190831
>
>1. why is the result multiplicated  with 2? There is a P-value between 1 and 2
>with the results below and multiplicated with 2:
>
>2*pnorm(c(1.8691945,0.5882351,2.4903091,1.9287802,2.3172983,2.2092593,2.2625959,1.6395695),
>lower.tail =TRUE)

1. The given in the thread mentioned was:

         2 * pnorm(abs(coef(summary(fm1))[,5]), lower.tail = FALSE)

2. The reason for the "2" at the front is to make it an "equal-tails" 
or "2-sided" confidence interval. Pedantically, you should use 1.96 
instead of 2.0 for consistency, but 2.0 = 1.96 rounded to one decimal place.

3. This is what is usually called a "Wald" type confidence interval, 
as it is simply the normal quantile (+/- 1.96) multiplied by the 
standard error of estimate to get the +/- widths for the interval. 
These would be added to the estimate itself to get the final Wald 
confidence interval, which obviously assumes a normal distribution applies.


================================================================
Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
824 Timberlake Drive                     Tel: 757-467-0954
Virginia Beach, VA 23464-3239            Fax: 757-467-2947

"Vere scire est per causas scire"


From gunter.berton at gene.com  Mon Jun 11 17:42:38 2007
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 11 Jun 2007 08:42:38 -0700
Subject: [R] open .r files with double-click
In-Reply-To: <466A8F0E.9060804@stats.uwo.ca>
Message-ID: <004c01c7ac3f$243c09a0$4d908980@gne.windows.gene.com>

However, do note (on Windows) that you can use an external text/programming
editors (see CRAN's listings)and can register .r / .R files to open
automatically in the chosen editor when clicked on.At least some of these
editors (eg TINN-R) can be configured to automatically and simultaneously
open the RGUI, too, I believe -- but someone may correct me on this.

Bert Gunter
Nonclinical Statistics
7-7374

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Duncan Murdoch
Sent: Saturday, June 09, 2007 4:29 AM
To: stevenmh at muohio.edu
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] open .r files with double-click

On 08/06/2007 2:52 PM, stevenmh at muohio.edu wrote:
> Hi Folks,
> On Windows XP, R 2.5.0.
> 
> After reading the Installation for Windows and Windows FAQs,
> I cannot resolve this.
> 
> I set file types so that Rgui.exe will open .r files.
> 
> When I try to open a .r file by double-clicking, R begins to launch,
> but I get an error message saying
> 
> "Argument 'C:\Documents and Settings\Zoology\My Documents\trial.r'
_ignored_"
> 
> I click OK, and then R GUI opens, but not the script file.
> 
> Is there a way to change this?

Not currently. See the appendix "Invoking R" of the Introduction manual 
for the current command line parameters, which don't include "open a 
script".  This would be a reasonable addition, and I'll add it at some 
point, sooner if someone else comes up with a convincing argument for 
the "right" command line parameter to do this.

It would be better if clicking on a second script opened a new window in 
the same session, but that takes more work; not sure I'll get to this.

Duncan Murdoch

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From JGOLDHAB at hsph.harvard.edu  Mon Jun 11 17:46:31 2007
From: JGOLDHAB at hsph.harvard.edu (Jeremy Goldhaber-Fiebert)
Date: Mon, 11 Jun 2007 11:46:31 -0400
Subject: [R] Fwd: Using odesolve to produce non-negative solutions
In-Reply-To: <46695EC8.2090602@pdf.com>
References: <4666A5D0.896D.005E.0@hsph.harvard.edu>
	<4666A910.896D.005E.0@hsph.harvard.edu> <46695EC8.2090602@pdf.com>
Message-ID: <466D3605.896D.005E.0@hsph.harvard.edu>

Hi Spencer,

Thank you for your response. I also did not see anything on the lsoda help page which is the reason that I wrote to the list.

>From your response, I am not sure if I asked my question clearly.

I am modeling a group of people (in a variety of health states) moving through time (and getting infected with an infectious disease). This means that the count of the number of people in each state should be positive at all times. 

What appears to happen is that lsoda asks for a derivative at a given point in time t and then adjusts the state of the population. However, perhaps due to numerical instability, it occasionally lower the population count below 0 for one of the health states (perhaps because it's step size is too big or something). 

I have tried both the logarithm trick and also changing the relative and absolute tolerance inputs but I still get the problem for certain combinations of parameters and initial conditions. 

It occurs both under MS Windows XP Service Pack 2 and on a Linux cluster so I am pretty sure it is not platform specific.

My real question to the group is if there is not a work around in lsoda are there other ode solvers in R that will allow the constraint of solutions to the ODEs remain non-negative?

Best regards,
Jeremy
      

>>> Spencer Graves <spencer.graves at pdf.com> 6/8/2007 9:51 AM >>>
On the 'lsoda' help page, I did not see any option to force some 
or all parameters to be nonnegative. 

      Have you considered replacing the parameters that must be 
nonnegative with their logarithms?  This effective moves the 0 lower 
limit to (-Inf) and seems to have worked well for me in the past.  
Often, it can even make the log likelihood or sum of squares surface 
more elliptical, which means that the standard normal approximation for 
the sampling distribution of parameter estimates will likely be more 
accurate. 

      Hope this helps. 
      Spencer Graves
p.s.  Your example seems not to be self contained.  If I could have 
easily copied it from your email and run it myself, I might have been 
able to offer more useful suggestions. 

Jeremy Goldhaber-Fiebert wrote:
> Hello,
>
> I am using odesolve to simulate a group of people moving through time and transmitting infections to one another. 
>
> In Matlab, there is a NonNegative option which tells the Matlab solver to keep the vector elements of the ODE solution non-negative at all times. What is the right way to do this in R?
>
> Thanks,
> Jeremy
>
> P.S., Below is a simplified version of the code I use to try to do this, but I am not sure that it is theoretically right 
>
> dynmodel <- function(t,y,p) 
> { 
> ## Initialize parameter values
>
> 	birth <- p$mybirth(t)
> 	death <- p$mydeath(t)
> 	recover <- p$myrecover
> 	beta <- p$mybeta
> 	vaxeff <- p$myvaxeff
> 	vaccinated <- p$myvax(t)
>
> 	vax <- vaxeff*vaccinated/100
>
> ## If the state currently has negative quantities (shouldn't have), then reset to reasonable values for computing meaningful derivatives
>
> 	for (i in 1:length(y)) {
> 		if (y[i]<0) {
> 			y[i] <- 0
> 		}
> 	}
>
> 	S <- y[1]
> 	I <- y[2]
> 	R <- y[3]
> 	N <- y[4]
>
> 	shat <- (birth*(1-vax)) - (death*S) - (beta*S*I/N)
> 	ihat <- (beta*S*I/N) - (death*I) - (recover*I)
> 	rhat <- (birth*(vax)) + (recover*I) - (death*R)
>
> ## Do we overshoot into negative space, if so shrink derivative to bring state to 0 
> ## then rescale the components that take the derivative negative
>
> 	if (shat+S<0) {
> 		shat_old <- shat
> 		shat <- -1*S
> 		scaled_transmission <- (shat/shat_old)*(beta*S*I/N)
> 		ihat <- scaled_transmission - (death*I) - (recover*I)
> 		
> 	}	
> 	if (ihat+I<0) {
> 		ihat_old <- ihat
> 		ihat <- -1*I
> 		scaled_recovery <- (ihat/ihat_old)*(recover*I)
> 		rhat <- scaled_recovery +(birth*(vax)) - (death*R)
> 	
> 	}	
> 	if (rhat+R<0) {
> 		rhat <- -1*R
> 	}	
>
> 	nhat <- shat + ihat + rhat
>
> 	if (nhat+N<0) {
> 		nhat <- -1*N	
> 	}	
>
> ## return derivatives
>
> 	list(c(shat,ihat,rhat,nhat),c(0))
>
> }
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code.
>


From bcarvalh at jhsph.edu  Mon Jun 11 17:46:59 2007
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Mon, 11 Jun 2007 11:46:59 -0400
Subject: [R] p-value from GEE why factor 2*pnorm?
In-Reply-To: <466D6B68.2050602@web.de>
References: <E1Hvs4m-0000hS-HM@www19.emo.freenet-rz.de>
	<466D6870.1060005@web.de>
	<651DAEB4-431D-4FF5-A98C-D33009AB4CE1@jhsph.edu>
	<466D6B68.2050602@web.de>
Message-ID: <D1751D61-8F22-4B68-A598-3F6CE4E93F53@jhsph.edu>

Well, AFAIK, the definition of a p-value is the probability of  
observing something at least as extreme as the observed data.

If you observed z, and Z follows a std-normal

p-value = P( Z < -abs(z) ) + P( Z > abs(z) )
   = 2*P ( Z > abs(z) )
   = 2*pnorm(z, lower.tail=FALSE)

try z=0 (you should get 1) and z=1.96 (you should get 5%)

b

On Jun 11, 2007, at 11:34 AM, Carmen Meier wrote:

> Benilton Carvalho schrieb:
>> the recommendation was to use lower.tail=FALSE.
>>
>> b
>>
>> O
> but then the results are significant and this does not match the
> observation.
> The results are matching the observations if the formula is
>
> pnorm(c 
> (1.8691945,0.5882351,2.4903091,1.9287802,2.3172983,2.2092593,2.2625959 
> ,1.6395695),
> lower.tail =TRUE)
>
> so I have any unknown problem .... anywhere :-(
>
> REgards Carmen


From jjin at email.unc.edu  Mon Jun 11 17:48:52 2007
From: jjin at email.unc.edu (Jianping Jin)
Date: Mon, 11 Jun 2007 11:48:52 -0400
Subject: [R] how to ignore error messages?
Message-ID: <62E2EA5AFC1ECA67395B7D44@gromit2.pmbb.med.unc.edu>

Dear group:

I wrote a code to iterate a non-linear fit with a set of data. The entire 
process didn't implemented to the end because an error message, "singular 
gradient". I knew that some sub-sets (columns) do not fit my formula well 
and may result in parameters going to infinity. It is pretty hard to remove 
those sub sets before running the code since that will take a lot of time.

I added some logic assessments prior to running nonlinear fit. It helped 
but some exceptions still existed. I am wondering if there is any way in R 
by which I can continue to run the entire code to the end by ignoring the 
error message?

Greatly appreciate your help,

Jianping

##################################
Jianping Jin Ph.D.
Bioinformatics scientist
Center for Bioinformatics
Room 3133 Bioinformatics building
CB# 7104
University of Chapel Hill
Chapel Hill, NC 27599
Phone: (919)843-6105
FAX:   (919)843-3103
E-Mail: jjin at email.unc.edu


From ligges at statistik.uni-dortmund.de  Mon Jun 11 18:05:22 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 11 Jun 2007 18:05:22 +0200
Subject: [R] design package
In-Reply-To: <OFC3C943FF.6260910D-ON862572F7.005273D0-862572F7.0052FAB1@abbott.com>
References: <OFC3C943FF.6260910D-ON862572F7.005273D0-862572F7.0052FAB1@abbott.com>
Message-ID: <466D72C2.3000308@statistik.uni-dortmund.de>

Which version of R????

For R-2.5.0, Design (with "D", not "d") does not pass the checks under 
Windows. Hence there is no Windows version for R-2.5.0 currently 
available on CRAN.


For older versions of R (down to R-1.7.x):
Please either use the Windows binary version, r.g. by typing
    install.packages("Design")
of the package or compile from sources yourself. Look like you just 
uncompressed some source package without installing it.


Qin Qin wrote:
> Hi all:
> 
> I tried to install design package for R used under the window. But it dose 
> not work.  Here is the message from R. 
> 
>> library(Design)
> Error in library(Design) : 'Design' is not a valid package -- installed < 
> 2.0.0?

The error message means R, not the package.


> I did not find 2.x version of Design package for window 95. I installed 
> one of two zip files available in the internet. 

Is the really Windows 95?


Uwe Ligges


> Please let me know what's wrong?
> 
> Thanks,
> Qin
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From helprhelp at gmail.com  Mon Jun 11 18:18:19 2007
From: helprhelp at gmail.com (Weiwei Shi)
Date: Mon, 11 Jun 2007 12:18:19 -0400
Subject: [R] history in R.app on Mac
Message-ID: <cdf817830706110918j68224f32read1e6fd76a008d7@mail.gmail.com>

hi,

I am really confused by history function in R.app for Mac:

Here is some test from command-line:
> ls()
character(0)
> ls()
character(0)
> ls()
character(0)
> history()
ls()
ls()
ls()
history()

That is what I expected. But from R.app, it does not show anything.

               _
platform       i386-apple-darwin8.9.1
arch           i386
os             darwin8.9.1
system         i386, darwin8.9.1
status
major          2
minor          5.0
year           2007
month          04
day            23
svn rev        41293
language       R
version.string R version 2.5.0 (2007-04-23)

Thanks,



-- 
Weiwei Shi, Ph.D
Research Scientist
GeneGO, Inc.

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III


From HStevens at MUOhio.edu  Mon Jun 11 18:18:36 2007
From: HStevens at MUOhio.edu (Martin Henry H. Stevens)
Date: Mon, 11 Jun 2007 12:18:36 -0400
Subject: [R] Fwd: Using odesolve to produce non-negative solutions
In-Reply-To: <466D3605.896D.005E.0@hsph.harvard.edu>
References: <4666A5D0.896D.005E.0@hsph.harvard.edu>
	<4666A910.896D.005E.0@hsph.harvard.edu> <46695EC8.2090602@pdf.com>
	<466D3605.896D.005E.0@hsph.harvard.edu>
Message-ID: <2B0CABC4-17EB-40B8-ADCD-BB94597D1570@MUOhio.edu>

Hi Jeremy,
First, setting hmax to a small number could prevent a large step, if  
you think that is a problem. Second, however, I don't see how you can  
get a negative population size when using the log trick. I would  
think that that would prevent completely any negative values of N  
(i.e. e^-100000 > 0). Can you explain? or do you want to a void that  
trick? The only other solver I know of is rk4 and it is not recommended.
Hank
On Jun 11, 2007, at 11:46 AM, Jeremy Goldhaber-Fiebert wrote:

> Hi Spencer,
>
> Thank you for your response. I also did not see anything on the  
> lsoda help page which is the reason that I wrote to the list.
>
>> From your response, I am not sure if I asked my question clearly.
>
> I am modeling a group of people (in a variety of health states)  
> moving through time (and getting infected with an infectious  
> disease). This means that the count of the number of people in each  
> state should be positive at all times.
>
> What appears to happen is that lsoda asks for a derivative at a  
> given point in time t and then adjusts the state of the population.  
> However, perhaps due to numerical instability, it occasionally  
> lower the population count below 0 for one of the health states  
> (perhaps because it's step size is too big or something).
>
> I have tried both the logarithm trick and also changing the  
> relative and absolute tolerance inputs but I still get the problem  
> for certain combinations of parameters and initial conditions.
>
> It occurs both under MS Windows XP Service Pack 2 and on a Linux  
> cluster so I am pretty sure it is not platform specific.
>
> My real question to the group is if there is not a work around in  
> lsoda are there other ode solvers in R that will allow the  
> constraint of solutions to the ODEs remain non-negative?
>
> Best regards,
> Jeremy
>
>
>>>> Spencer Graves <spencer.graves at pdf.com> 6/8/2007 9:51 AM >>>
> On the 'lsoda' help page, I did not see any option to force some
> or all parameters to be nonnegative.
>
>       Have you considered replacing the parameters that must be
> nonnegative with their logarithms?  This effective moves the 0 lower
> limit to (-Inf) and seems to have worked well for me in the past.
> Often, it can even make the log likelihood or sum of squares surface
> more elliptical, which means that the standard normal approximation  
> for
> the sampling distribution of parameter estimates will likely be more
> accurate.
>
>       Hope this helps.
>       Spencer Graves
> p.s.  Your example seems not to be self contained.  If I could have
> easily copied it from your email and run it myself, I might have been
> able to offer more useful suggestions.
>
> Jeremy Goldhaber-Fiebert wrote:
>> Hello,
>>
>> I am using odesolve to simulate a group of people moving through  
>> time and transmitting infections to one another.
>>
>> In Matlab, there is a NonNegative option which tells the Matlab  
>> solver to keep the vector elements of the ODE solution non- 
>> negative at all times. What is the right way to do this in R?
>>
>> Thanks,
>> Jeremy
>>
>> P.S., Below is a simplified version of the code I use to try to do  
>> this, but I am not sure that it is theoretically right
>>
>> dynmodel <- function(t,y,p)
>> {
>> ## Initialize parameter values
>>
>> 	birth <- p$mybirth(t)
>> 	death <- p$mydeath(t)
>> 	recover <- p$myrecover
>> 	beta <- p$mybeta
>> 	vaxeff <- p$myvaxeff
>> 	vaccinated <- p$myvax(t)
>>
>> 	vax <- vaxeff*vaccinated/100
>>
>> ## If the state currently has negative quantities (shouldn't  
>> have), then reset to reasonable values for computing meaningful  
>> derivatives
>>
>> 	for (i in 1:length(y)) {
>> 		if (y[i]<0) {
>> 			y[i] <- 0
>> 		}
>> 	}
>>
>> 	S <- y[1]
>> 	I <- y[2]
>> 	R <- y[3]
>> 	N <- y[4]
>>
>> 	shat <- (birth*(1-vax)) - (death*S) - (beta*S*I/N)
>> 	ihat <- (beta*S*I/N) - (death*I) - (recover*I)
>> 	rhat <- (birth*(vax)) + (recover*I) - (death*R)
>>
>> ## Do we overshoot into negative space, if so shrink derivative to  
>> bring state to 0
>> ## then rescale the components that take the derivative negative
>>
>> 	if (shat+S<0) {
>> 		shat_old <- shat
>> 		shat <- -1*S
>> 		scaled_transmission <- (shat/shat_old)*(beta*S*I/N)
>> 		ihat <- scaled_transmission - (death*I) - (recover*I)
>> 		
>> 	}	
>> 	if (ihat+I<0) {
>> 		ihat_old <- ihat
>> 		ihat <- -1*I
>> 		scaled_recovery <- (ihat/ihat_old)*(recover*I)
>> 		rhat <- scaled_recovery +(birth*(vax)) - (death*R)
>> 	
>> 	}	
>> 	if (rhat+R<0) {
>> 		rhat <- -1*R
>> 	}	
>>
>> 	nhat <- shat + ihat + rhat
>>
>> 	if (nhat+N<0) {
>> 		nhat <- -1*N	
>> 	}	
>>
>> ## return derivatives
>>
>> 	list(c(shat,ihat,rhat,nhat),c(0))
>>
>> }
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting- 
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



Dr. Hank Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/

"E Pluribus Unum"


From chenxh007 at gmail.com  Mon Jun 11 18:25:49 2007
From: chenxh007 at gmail.com (Xiaohui)
Date: Mon, 11 Jun 2007 09:25:49 -0700
Subject: [R] how to ignore error messages?
In-Reply-To: <62E2EA5AFC1ECA67395B7D44@gromit2.pmbb.med.unc.edu>
References: <62E2EA5AFC1ECA67395B7D44@gromit2.pmbb.med.unc.edu>
Message-ID: <466D778D.9070409@gmail.com>

see ?try

Jianping Jin wrote:
> Dear group:
>
> I wrote a code to iterate a non-linear fit with a set of data. The entire 
> process didn't implemented to the end because an error message, "singular 
> gradient". I knew that some sub-sets (columns) do not fit my formula well 
> and may result in parameters going to infinity. It is pretty hard to remove 
> those sub sets before running the code since that will take a lot of time.
>
> I added some logic assessments prior to running nonlinear fit. It helped 
> but some exceptions still existed. I am wondering if there is any way in R 
> by which I can continue to run the entire code to the end by ignoring the 
> error message?
>
> Greatly appreciate your help,
>
> Jianping
>
> ##################################
> Jianping Jin Ph.D.
> Bioinformatics scientist
> Center for Bioinformatics
> Room 3133 Bioinformatics building
> CB# 7104
> University of Chapel Hill
> Chapel Hill, NC 27599
> Phone: (919)843-6105
> FAX:   (919)843-3103
> E-Mail: jjin at email.unc.edu
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


From dieter.menne at menne-biomed.de  Mon Jun 11 18:26:43 2007
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Mon, 11 Jun 2007 16:26:43 +0000 (UTC)
Subject: [R] how to ignore error messages?
References: <62E2EA5AFC1ECA67395B7D44@gromit2.pmbb.med.unc.edu>
Message-ID: <loom.20070611T182527-123@post.gmane.org>

Jianping Jin <jjin <at> email.unc.edu> writes:
...
> I wrote a code to iterate a non-linear fit with a set of data. The entire 
> process didn't implemented to the end because an error message, "singular 
> gradient". I knew that some sub-sets (columns) do not fit my formula well 
> and may result in parameters going to infinity. It is pretty hard to remove 
> those sub sets before running the code since that will take a lot of time.
> 
> I added some logic assessments prior to running nonlinear fit. It helped 
> but some exceptions still existed. I am wondering if there is any way in R 
> by which I can continue to run the entire code to the end by ignoring the 
> error message?
...

?try

Or, even easier, use nlsList in nlme, which does exactly what you want, handling
convergence errors graciously.

Dieter


From goedman at mac.com  Mon Jun 11 18:50:47 2007
From: goedman at mac.com (Rob J Goedman)
Date: Mon, 11 Jun 2007 09:50:47 -0700
Subject: [R] history in R.app on Mac
In-Reply-To: <cdf817830706110918j68224f32read1e6fd76a008d7@mail.gmail.com>
References: <cdf817830706110918j68224f32read1e6fd76a008d7@mail.gmail.com>
Message-ID: <DF6DE0DC-54E2-414F-B606-FBEB5E731C64@mac.com>

If you click on the history icon in the toolbar in R.app you will see  
them. Or up and down arrows.
R.app implements some extra features, such as multiline command  
retrieval.

Through preference settings you can control if you want to see just a  
single ls() or multiple, etc.

Rob

On Jun 11, 2007, at 9:18 AM, Weiwei Shi wrote:

> hi,
>
> I am really confused by history function in R.app for Mac:
>
> Here is some test from command-line:
>> ls()
> character(0)
>> ls()
> character(0)
>> ls()
> character(0)
>> history()
> ls()
> ls()
> ls()
> history()
>
> That is what I expected. But from R.app, it does not show anything.
>
>                _
> platform       i386-apple-darwin8.9.1
> arch           i386
> os             darwin8.9.1
> system         i386, darwin8.9.1
> status
> major          2
> minor          5.0
> year           2007
> month          04
> day            23
> svn rev        41293
> language       R
> version.string R version 2.5.0 (2007-04-23)
>
> Thanks,
>
>
>
> -- 
> Weiwei Shi, Ph.D
> Research Scientist
> GeneGO, Inc.
>
> "Did you always know?"
> "No, I did not. But I believed..."
> ---Matrix III
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From spencer.graves at pdf.com  Mon Jun 11 18:52:57 2007
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 11 Jun 2007 09:52:57 -0700
Subject: [R] Fwd: Using odesolve to produce non-negative solutions
In-Reply-To: <2B0CABC4-17EB-40B8-ADCD-BB94597D1570@MUOhio.edu>
References: <4666A5D0.896D.005E.0@hsph.harvard.edu>
	<4666A910.896D.005E.0@hsph.harvard.edu> <46695EC8.2090602@pdf.com>
	<466D3605.896D.005E.0@hsph.harvard.edu>
	<2B0CABC4-17EB-40B8-ADCD-BB94597D1570@MUOhio.edu>
Message-ID: <466D7DE9.2030205@pdf.com>

<in line>

Martin Henry H. Stevens wrote:
> Hi Jeremy,
> First, setting hmax to a small number could prevent a large step, if 
> you think that is a problem. Second, however, I don't see how you can 
> get a negative population size when using the log trick. 
SG:  Can lsoda estimate complex or imaginary parameters? 

> I would think that that would prevent completely any negative values 
> of N (i.e. e^-100000 > 0). Can you explain? or do you want to a void 
> that trick? The only other solver I know of is rk4 and it is not 
> recommended.
> Hank
> On Jun 11, 2007, at 11:46 AM, Jeremy Goldhaber-Fiebert wrote:
>
>> Hi Spencer,
>>
>> Thank you for your response. I also did not see anything on the lsoda 
>> help page which is the reason that I wrote to the list.
>>
>>> From your response, I am not sure if I asked my question clearly.
>>
>> I am modeling a group of people (in a variety of health states) 
>> moving through time (and getting infected with an infectious 
>> disease). This means that the count of the number of people in each 
>> state should be positive at all times.
>>
>> What appears to happen is that lsoda asks for a derivative at a given 
>> point in time t and then adjusts the state of the population. 
>> However, perhaps due to numerical instability, it occasionally lower 
>> the population count below 0 for one of the health states (perhaps 
>> because it's step size is too big or something).
>>
>> I have tried both the logarithm trick
<snip>


From HStevens at muohio.edu  Mon Jun 11 19:02:32 2007
From: HStevens at muohio.edu (Martin Henry H. Stevens)
Date: Mon, 11 Jun 2007 13:02:32 -0400
Subject: [R] Fwd: Using odesolve to produce non-negative solutions
In-Reply-To: <466D7DE9.2030205@pdf.com>
References: <4666A5D0.896D.005E.0@hsph.harvard.edu>
	<4666A910.896D.005E.0@hsph.harvard.edu> <46695EC8.2090602@pdf.com>
	<466D3605.896D.005E.0@hsph.harvard.edu>
	<2B0CABC4-17EB-40B8-ADCD-BB94597D1570@MUOhio.edu>
	<466D7DE9.2030205@pdf.com>
Message-ID: <B2B31B13-CEF9-4E51-B19D-4B694818AFAB@muohio.edu>

Hi Spencer,
I have copied Woody Setzer. I have no idea whether lsoda can estimate  
parameters that could take imaginary values.
Hank
On Jun 11, 2007, at 12:52 PM, Spencer Graves wrote:

> <in line>
>
> Martin Henry H. Stevens wrote:
>> Hi Jeremy,
>> First, setting hmax to a small number could prevent a large step, if
>> you think that is a problem. Second, however, I don't see how you can
>> get a negative population size when using the log trick.
> SG:  Can lsoda estimate complex or imaginary parameters?
Hmm. I have no idea.
>
>> I would think that that would prevent completely any negative values
>> of N (i.e. e^-100000 > 0). Can you explain? or do you want to a void
>> that trick? The only other solver I know of is rk4 and it is not
>> recommended.
>> Hank
>> On Jun 11, 2007, at 11:46 AM, Jeremy Goldhaber-Fiebert wrote:
>>
>>> Hi Spencer,
>>>
>>> Thank you for your response. I also did not see anything on the  
>>> lsoda
>>> help page which is the reason that I wrote to the list.
>>>
>>>> From your response, I am not sure if I asked my question clearly.
>>>
>>> I am modeling a group of people (in a variety of health states)
>>> moving through time (and getting infected with an infectious
>>> disease). This means that the count of the number of people in each
>>> state should be positive at all times.
>>>
>>> What appears to happen is that lsoda asks for a derivative at a  
>>> given
>>> point in time t and then adjusts the state of the population.
>>> However, perhaps due to numerical instability, it occasionally lower
>>> the population count below 0 for one of the health states (perhaps
>>> because it's step size is too big or something).
>>>
>>> I have tried both the logarithm trick
> <snip>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



Dr. Hank Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/

"E Pluribus Unum"


From helprhelp at gmail.com  Mon Jun 11 19:03:33 2007
From: helprhelp at gmail.com (Weiwei Shi)
Date: Mon, 11 Jun 2007 13:03:33 -0400
Subject: [R] history in R.app on Mac
In-Reply-To: <DF6DE0DC-54E2-414F-B606-FBEB5E731C64@mac.com>
References: <cdf817830706110918j68224f32read1e6fd76a008d7@mail.gmail.com>
	<DF6DE0DC-54E2-414F-B606-FBEB5E731C64@mac.com>
Message-ID: <cdf817830706111003j9dddbf5rec635c1c6bb8bd63@mail.gmail.com>

got it. Thanks. I was always trying to find it at menu and did not
expect that in my toolbar :)

I just assumed that any tool icon should also be shown on menu, which
is just a routine to me.

-w

On 6/11/07, Rob J Goedman <goedman at mac.com> wrote:
> If you click on the history icon in the toolbar in R.app you will see
> them. Or up and down arrows.
> R.app implements some extra features, such as multiline command
> retrieval.
>
> Through preference settings you can control if you want to see just a
> single ls() or multiple, etc.
>
> Rob
>
> On Jun 11, 2007, at 9:18 AM, Weiwei Shi wrote:
>
> > hi,
> >
> > I am really confused by history function in R.app for Mac:
> >
> > Here is some test from command-line:
> >> ls()
> > character(0)
> >> ls()
> > character(0)
> >> ls()
> > character(0)
> >> history()
> > ls()
> > ls()
> > ls()
> > history()
> >
> > That is what I expected. But from R.app, it does not show anything.
> >
> >                _
> > platform       i386-apple-darwin8.9.1
> > arch           i386
> > os             darwin8.9.1
> > system         i386, darwin8.9.1
> > status
> > major          2
> > minor          5.0
> > year           2007
> > month          04
> > day            23
> > svn rev        41293
> > language       R
> > version.string R version 2.5.0 (2007-04-23)
> >
> > Thanks,
> >
> >
> >
> > --
> > Weiwei Shi, Ph.D
> > Research Scientist
> > GeneGO, Inc.
> >
> > "Did you always know?"
> > "No, I did not. But I believed..."
> > ---Matrix III
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Weiwei Shi, Ph.D
Research Scientist
GeneGO, Inc.

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III


From mister_bluesman at hotmail.com  Mon Jun 11 19:17:16 2007
From: mister_bluesman at hotmail.com (mister_bluesman)
Date: Mon, 11 Jun 2007 10:17:16 -0700 (PDT)
Subject: [R] Problem with RSVGTipsDevice
Message-ID: <11064573.post@talk.nabble.com>


Hi there.

I am still trying to get the RSVGTipsDevice to work, yet I can not.

I have copied the first example from RSVGTipsDevice documentation:

library(RSVGTipsDevice)
devSVGTips("C:\\svgplot1.svg", toolTipMode=1,
title="SVG example plot 1: shapes and points, tooltips are title + 1 line")
plot(c(0,10),c(0,10), type="n", xlab="x", ylab="y",
main="Example SVG plot with title + 1 line tips (mode=1)")
setSVGShapeToolTip(title="A rectangle", desc="that is yellow")
rect(1,1,4,6, col='yellow')
setSVGShapeToolTip(title="1st circle with title only")
points(5.5,7.5,cex=20,pch=19,col='red')
setSVGShapeToolTip(title="A triangle", desc="big and green")
polygon(c(3,6,8), c(3,6,3), col='green')
# no tooltips on these points
points(2:8, 8:2, cex=3, pch=19, col='black')
# tooltips on each these points
invisible(sapply(1:7, function(x)
{setSVGShapeToolTip(title=paste("point", x))
points(x+1, 8-x, cex=3, pch=1, col='black')}))
dev.off()

This results in the following output:

http://www.nabble.com/file/p11064573/svgplot1.svg svgplot1.svg 

It opens but when I try and hover over the triangle, for example, I do not
get a topptip box appear. I have tried opening the file though firefox, and
XP IE - and on more than one computer yet it does not work. Do I need to
install something else as well?

Many thanks
-- 
View this message in context: http://www.nabble.com/Problem-with-RSVGTipsDevice-tf3902760.html#a11064573
Sent from the R help mailing list archive at Nabble.com.


From timh at insightful.com  Mon Jun 11 19:26:05 2007
From: timh at insightful.com (Tim Hesterberg)
Date: 11 Jun 2007 10:26:05 -0700
Subject: [R] Weighted least squares
In-Reply-To: "jfox@mcmaster.ca"'s message of Tue, 8 May 2007 11:19:16 -0400
Message-ID: <SEWINEXCH00EcLsXJB700000975@sewinexch00.insightful.com>

As John noted, there are different kinds of weights, and 
different terminology:
* inverse-variance weights (accuracy weights)
* case weights (frequencies, counts)
* sampling weights (selection probability weights)

I'll add:
* inverse-variance weights, where var(y for observation) = 1/weight
  (as opposed to just being inversely proportional to the weight)
* weights used as part of an algorithm (e.g. for robust estimation,
  or glm's using iteratively-reweighted least-squares).

For linear regression, the type of weights don't affect regression
coefficient calculation, but do affect inferences such as standard errors
for the regression coefficients, degrees of freedom for variance
estimates, etc.  

lm() inferences assume the first type.  
Other formulae are appropriate for inferences for types 2-4.
Combinations of types 1-4 require other formulae; this gets nontrivial.
For the 5th type, inferences need to be handled by the algorithm that
is using weighted linear regression.

Tim Hesterberg

John Fox wrote:
>I think that the problem is that the term "weights" has different meanings,
>which, although they are related, are not quite the same. 
>
>The weights used by lm() are (inverse-)"variance weights," reflecting the
>variances of the errors, with observations that have low-variance errors
>therefore being accorded greater weight in the resulting WLS regression.
>What you have are sometimes called "case weights," and I'm unaware of a
>general way of handling them in R, although you could regenerate the
>unaggregated data. As you discovered, you get the same coefficients with
>case weights as with variance weights, but different standard errors.
>Finally, there are "sampling weights," which are inversely proportional to
>the probability of selection; these are accommodated by the survey package. 
>
>To complicate matters, this terminology isn't entirely standard.


From rvaradhan at jhmi.edu  Mon Jun 11 19:27:33 2007
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Mon, 11 Jun 2007 13:27:33 -0400
Subject: [R] Fwd: Using odesolve to produce non-negative solutions
In-Reply-To: <466D7DE9.2030205@pdf.com>
References: <4666A5D0.896D.005E.0@hsph.harvard.edu>
	<4666A910.896D.005E.0@hsph.harvard.edu> <46695EC8.2090602@pdf.com>
	<466D3605.896D.005E.0@hsph.harvard.edu>
	<2B0CABC4-17EB-40B8-ADCD-BB94597D1570@MUOhio.edu>
	<466D7DE9.2030205@pdf.com>
Message-ID: <000401c7ac4d$cbc73d80$7c94100a@win.ad.jhu.edu>

Spencer,

Lsoda does not "estimate" any parameters (nlmeODE does parameter
estimation).  It just computes the solution trajectory, at discrete times,
of a dynamical systems (i.e. set of differential equations).  It only works
with real numbers, as far as I know.


Ravi.

----------------------------------------------------------------------------
-------

Ravi Varadhan, Ph.D.

Assistant Professor, The Center on Aging and Health

Division of Geriatric Medicine and Gerontology 

Johns Hopkins University

Ph: (410) 502-2619

Fax: (410) 614-9625

Email: rvaradhan at jhmi.edu

Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html

 

----------------------------------------------------------------------------
--------


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Spencer Graves
Sent: Monday, June 11, 2007 12:53 PM
To: Martin Henry H. Stevens
Cc: Jeremy Goldhaber-Fiebert; r-help at stat.math.ethz.ch
Subject: Re: [R] Fwd: Using odesolve to produce non-negative solutions

<in line>

Martin Henry H. Stevens wrote:
> Hi Jeremy,
> First, setting hmax to a small number could prevent a large step, if 
> you think that is a problem. Second, however, I don't see how you can 
> get a negative population size when using the log trick. 
SG:  Can lsoda estimate complex or imaginary parameters? 

> I would think that that would prevent completely any negative values 
> of N (i.e. e^-100000 > 0). Can you explain? or do you want to a void 
> that trick? The only other solver I know of is rk4 and it is not 
> recommended.
> Hank
> On Jun 11, 2007, at 11:46 AM, Jeremy Goldhaber-Fiebert wrote:
>
>> Hi Spencer,
>>
>> Thank you for your response. I also did not see anything on the lsoda 
>> help page which is the reason that I wrote to the list.
>>
>>> From your response, I am not sure if I asked my question clearly.
>>
>> I am modeling a group of people (in a variety of health states) 
>> moving through time (and getting infected with an infectious 
>> disease). This means that the count of the number of people in each 
>> state should be positive at all times.
>>
>> What appears to happen is that lsoda asks for a derivative at a given 
>> point in time t and then adjusts the state of the population. 
>> However, perhaps due to numerical instability, it occasionally lower 
>> the population count below 0 for one of the health states (perhaps 
>> because it's step size is too big or something).
>>
>> I have tried both the logarithm trick
<snip>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From mark_difford at yahoo.co.uk  Mon Jun 11 19:41:39 2007
From: mark_difford at yahoo.co.uk (Mark Difford)
Date: Mon, 11 Jun 2007 10:41:39 -0700 (PDT)
Subject: [R] Problem with RSVGTipsDevice
In-Reply-To: <11064573.post@talk.nabble.com>
References: <11064573.post@talk.nabble.com>
Message-ID: <11065021.post@talk.nabble.com>


Hi Mister_Bluesman,

Sorry to sadden you further, but your example svg works perfectly on my
machine (R 2.5 running on Vista).  All the "ToolTips" display.  Perhaps it's
your browser [setup]: I'm using Opera 9.20 (Build 8771).

HTH,

Mark Difford.


mister_bluesman wrote:
> 
> Hi there.
> 
> I am still trying to get the RSVGTipsDevice to work, yet I can not.
> 
> I have copied the first example from RSVGTipsDevice documentation:
> 
> library(RSVGTipsDevice)
> devSVGTips("C:\\svgplot1.svg", toolTipMode=1,
> title="SVG example plot 1: shapes and points, tooltips are title + 1
> line")
> plot(c(0,10),c(0,10), type="n", xlab="x", ylab="y",
> main="Example SVG plot with title + 1 line tips (mode=1)")
> setSVGShapeToolTip(title="A rectangle", desc="that is yellow")
> rect(1,1,4,6, col='yellow')
> setSVGShapeToolTip(title="1st circle with title only")
> points(5.5,7.5,cex=20,pch=19,col='red')
> setSVGShapeToolTip(title="A triangle", desc="big and green")
> polygon(c(3,6,8), c(3,6,3), col='green')
> # no tooltips on these points
> points(2:8, 8:2, cex=3, pch=19, col='black')
> # tooltips on each these points
> invisible(sapply(1:7, function(x)
> {setSVGShapeToolTip(title=paste("point", x))
> points(x+1, 8-x, cex=3, pch=1, col='black')}))
> dev.off()
> 
> This results in the following output:
> 
>  http://www.nabble.com/file/p11064573/svgplot1.svg svgplot1.svg 
> 
> It opens but when I try and hover over the triangle, for example, I do not
> get a topptip box appear. I have tried opening the file though firefox,
> and XP IE - and on more than one computer yet it does not work. Do I need
> to install something else as well?
> 
> Many thanks
> 

-- 
View this message in context: http://www.nabble.com/Problem-with-RSVGTipsDevice-tf3902760.html#a11065021
Sent from the R help mailing list archive at Nabble.com.


From mark_difford at yahoo.co.uk  Mon Jun 11 19:53:57 2007
From: mark_difford at yahoo.co.uk (Mark Difford)
Date: Mon, 11 Jun 2007 10:53:57 -0700 (PDT)
Subject: [R] Problem with RSVGTipsDevice
In-Reply-To: <11064573.post@talk.nabble.com>
References: <11064573.post@talk.nabble.com>
Message-ID: <11065061.post@talk.nabble.com>


Mister_Bluesman,

Perhaps I should have been more precise: your included svgplot1.svg displays
fine...!


mister_bluesman wrote:
> 
> Hi there.
> 
> I am still trying to get the RSVGTipsDevice to work, yet I can not.
> 
> I have copied the first example from RSVGTipsDevice documentation:
> 
> library(RSVGTipsDevice)
> devSVGTips("C:\\svgplot1.svg", toolTipMode=1,
> title="SVG example plot 1: shapes and points, tooltips are title + 1
> line")
> plot(c(0,10),c(0,10), type="n", xlab="x", ylab="y",
> main="Example SVG plot with title + 1 line tips (mode=1)")
> setSVGShapeToolTip(title="A rectangle", desc="that is yellow")
> rect(1,1,4,6, col='yellow')
> setSVGShapeToolTip(title="1st circle with title only")
> points(5.5,7.5,cex=20,pch=19,col='red')
> setSVGShapeToolTip(title="A triangle", desc="big and green")
> polygon(c(3,6,8), c(3,6,3), col='green')
> # no tooltips on these points
> points(2:8, 8:2, cex=3, pch=19, col='black')
> # tooltips on each these points
> invisible(sapply(1:7, function(x)
> {setSVGShapeToolTip(title=paste("point", x))
> points(x+1, 8-x, cex=3, pch=1, col='black')}))
> dev.off()
> 
> This results in the following output:
> 
>  http://www.nabble.com/file/p11064573/svgplot1.svg svgplot1.svg 
> 
> It opens but when I try and hover over the triangle, for example, I do not
> get a topptip box appear. I have tried opening the file though firefox,
> and XP IE - and on more than one computer yet it does not work. Do I need
> to install something else as well?
> 
> Many thanks
> 

-- 
View this message in context: http://www.nabble.com/Problem-with-RSVGTipsDevice-tf3902760.html#a11065061
Sent from the R help mailing list archive at Nabble.com.


From quesada at gmail.com  Mon Jun 11 19:57:44 2007
From: quesada at gmail.com (Jose Quesada )
Date: Mon, 11 Jun 2007 19:57:44 +0200
Subject: [R] debugger library. Error?
Message-ID: <op.ttrquins4hcap5@delllap.ugr.es>

Hi, running the following example code (taken from the docs) will prodice
an error in my system (R 2.5.0, win):
library(debug)
mtrace(glm) # turns tracing on
names( tracees) # "glm"
check.for.tracees( "package:base") # "glm"
glm(stupid.args) # voila le debugger
> Error in all.levs[[j]] : subscript out of bounds

It happens with any function, I just posted one form the example.

Thanks,
-J
-- 
Jose Quesada, PhD.
http://www.andrew.cmu.edu/~jquesada


From rvaradhan at jhmi.edu  Mon Jun 11 20:11:20 2007
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Mon, 11 Jun 2007 14:11:20 -0400
Subject: [R] Fwd: Using odesolve to produce non-negative solutions
In-Reply-To: <466D3605.896D.005E.0@hsph.harvard.edu>
References: <4666A5D0.896D.005E.0@hsph.harvard.edu>
	<4666A910.896D.005E.0@hsph.harvard.edu> <46695EC8.2090602@pdf.com>
	<466D3605.896D.005E.0@hsph.harvard.edu>
Message-ID: <000d01c7ac53$e9b254f0$7c94100a@win.ad.jhu.edu>

Hi Jeremy,

A smaller step size may or may not help.  If the issue is simply truncation
error, that is the error involved in discretizing the differential
equations, then a smaller step size would help.  If, however, the true
solution to the differential equation is negative, for some t, then the
numerical solution should also be negative.  If the negative solution does
not make sense, then the system of equation needs to be examined to see when
and why negative solutions arise.  Perhaps, I am just making this up - there
needs to be a "dampening function" that slows down the trajectory as it
approaches zero from its initial value. It is also possible that only
certain regions of the parameter space (note that initial conditions are
also parameters) are allowed in the sense that only there the solution is
feasible for all t.  So, in your example, the parameters might not be
realistic.  In short, if you are sure that the numerical solution is
accurate, then you need to go back to your system of equations and analyze
them carefully.  


Ravi.


----------------------------------------------------------------------------
-------

Ravi Varadhan, Ph.D.

Assistant Professor, The Center on Aging and Health

Division of Geriatric Medicine and Gerontology 

Johns Hopkins University

Ph: (410) 502-2619

Fax: (410) 614-9625

Email: rvaradhan at jhmi.edu

Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html

 

----------------------------------------------------------------------------
--------


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jeremy
Goldhaber-Fiebert
Sent: Monday, June 11, 2007 11:47 AM
To: Spencer Graves
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Fwd: Using odesolve to produce non-negative solutions

Hi Spencer,

Thank you for your response. I also did not see anything on the lsoda help
page which is the reason that I wrote to the list.

>From your response, I am not sure if I asked my question clearly.

I am modeling a group of people (in a variety of health states) moving
through time (and getting infected with an infectious disease). This means
that the count of the number of people in each state should be positive at
all times. 

What appears to happen is that lsoda asks for a derivative at a given point
in time t and then adjusts the state of the population. However, perhaps due
to numerical instability, it occasionally lower the population count below 0
for one of the health states (perhaps because it's step size is too big or
something). 

I have tried both the logarithm trick and also changing the relative and
absolute tolerance inputs but I still get the problem for certain
combinations of parameters and initial conditions. 

It occurs both under MS Windows XP Service Pack 2 and on a Linux cluster so
I am pretty sure it is not platform specific.

My real question to the group is if there is not a work around in lsoda are
there other ode solvers in R that will allow the constraint of solutions to
the ODEs remain non-negative?

Best regards,
Jeremy
      

>>> Spencer Graves <spencer.graves at pdf.com> 6/8/2007 9:51 AM >>>
On the 'lsoda' help page, I did not see any option to force some 
or all parameters to be nonnegative. 

      Have you considered replacing the parameters that must be 
nonnegative with their logarithms?  This effective moves the 0 lower 
limit to (-Inf) and seems to have worked well for me in the past.  
Often, it can even make the log likelihood or sum of squares surface 
more elliptical, which means that the standard normal approximation for 
the sampling distribution of parameter estimates will likely be more 
accurate. 

      Hope this helps. 
      Spencer Graves
p.s.  Your example seems not to be self contained.  If I could have 
easily copied it from your email and run it myself, I might have been 
able to offer more useful suggestions. 

Jeremy Goldhaber-Fiebert wrote:
> Hello,
>
> I am using odesolve to simulate a group of people moving through time and
transmitting infections to one another. 
>
> In Matlab, there is a NonNegative option which tells the Matlab solver to
keep the vector elements of the ODE solution non-negative at all times. What
is the right way to do this in R?
>
> Thanks,
> Jeremy
>
> P.S., Below is a simplified version of the code I use to try to do this,
but I am not sure that it is theoretically right 
>
> dynmodel <- function(t,y,p) 
> { 
> ## Initialize parameter values
>
> 	birth <- p$mybirth(t)
> 	death <- p$mydeath(t)
> 	recover <- p$myrecover
> 	beta <- p$mybeta
> 	vaxeff <- p$myvaxeff
> 	vaccinated <- p$myvax(t)
>
> 	vax <- vaxeff*vaccinated/100
>
> ## If the state currently has negative quantities (shouldn't have), then
reset to reasonable values for computing meaningful derivatives
>
> 	for (i in 1:length(y)) {
> 		if (y[i]<0) {
> 			y[i] <- 0
> 		}
> 	}
>
> 	S <- y[1]
> 	I <- y[2]
> 	R <- y[3]
> 	N <- y[4]
>
> 	shat <- (birth*(1-vax)) - (death*S) - (beta*S*I/N)
> 	ihat <- (beta*S*I/N) - (death*I) - (recover*I)
> 	rhat <- (birth*(vax)) + (recover*I) - (death*R)
>
> ## Do we overshoot into negative space, if so shrink derivative to bring
state to 0 
> ## then rescale the components that take the derivative negative
>
> 	if (shat+S<0) {
> 		shat_old <- shat
> 		shat <- -1*S
> 		scaled_transmission <- (shat/shat_old)*(beta*S*I/N)
> 		ihat <- scaled_transmission - (death*I) - (recover*I)
> 		
> 	}	
> 	if (ihat+I<0) {
> 		ihat_old <- ihat
> 		ihat <- -1*I
> 		scaled_recovery <- (ihat/ihat_old)*(recover*I)
> 		rhat <- scaled_recovery +(birth*(vax)) - (death*R)
> 	
> 	}	
> 	if (rhat+R<0) {
> 		rhat <- -1*R
> 	}	
>
> 	nhat <- shat + ihat + rhat
>
> 	if (nhat+N<0) {
> 		nhat <- -1*N	
> 	}	
>
> ## return derivatives
>
> 	list(c(shat,ihat,rhat,nhat),c(0))
>
> }
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code.
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From JGOLDHAB at hsph.harvard.edu  Mon Jun 11 20:22:47 2007
From: JGOLDHAB at hsph.harvard.edu (Jeremy Goldhaber-Fiebert)
Date: Mon, 11 Jun 2007 14:22:47 -0400
Subject: [R] Fwd: Using odesolve to produce non-negative solutions
In-Reply-To: <000d01c7ac53$e9b254f0$7c94100a@win.ad.jhu.edu>
References: <4666A5D0.896D.005E.0@hsph.harvard.edu>
	<4666A910.896D.005E.0@hsph.harvard.edu> <46695EC8.2090602@pdf.com>
	<466D3605.896D.005E.0@hsph.harvard.edu>
	<000d01c7ac53$e9b254f0$7c94100a@win.ad.jhu.edu>
Message-ID: <466D5AA7.896D.005E.0@hsph.harvard.edu>

Hi Ravi,

Thanks for your response. I tried this in Berkeley Madonna and in Matlab. In Berkeley Madonna I did not have the problem (RK4 solver). In Matlab (ode45 solver), I had the problem if I did not use their NonNegative option. My thought was that NonNegative uses something like an additional piece of logic in modifying step size (maybe something like: if stepsize * derivative + current condition is negative, then reduce step size), but I don't know.

My original application was to generate ode output for a variety of unknown parameters, comparing the output to observed data and thereby using a likelihood-based approach to identify unknown parameter combinations that are most consistent with observed data given the uncertainty. First, I wanted to get a sense of how the model performed over a range of parameters that seem plausible based on literature review. I had originally thought to do this in Matlab and built a little proof of concept searching program, but given that R is free and has many other great packages for doing optimization and statistical analysis (and is easy to setup which is great for cluster computing situations), I thought it would be better to do it in R. When I did this, I got negative values and hence sent to the list.

Once again, thanks for your help. Not sure if this clarification email will generate other suggestions or thoughts.

Best,
Jeremy

>>> "Ravi Varadhan" <rvaradhan at jhmi.edu> 6/11/2007 2:11 PM >>>
Hi Jeremy,

A smaller step size may or may not help.  If the issue is simply truncation
error, that is the error involved in discretizing the differential
equations, then a smaller step size would help.  If, however, the true
solution to the differential equation is negative, for some t, then the
numerical solution should also be negative.  If the negative solution does
not make sense, then the system of equation needs to be examined to see when
and why negative solutions arise.  Perhaps, I am just making this up - there
needs to be a "dampening function" that slows down the trajectory as it
approaches zero from its initial value. It is also possible that only
certain regions of the parameter space (note that initial conditions are
also parameters) are allowed in the sense that only there the solution is
feasible for all t.  So, in your example, the parameters might not be
realistic.  In short, if you are sure that the numerical solution is
accurate, then you need to go back to your system of equations and analyze
them carefully.  


Ravi.


----------------------------------------------------------------------------
-------

Ravi Varadhan, Ph.D.

Assistant Professor, The Center on Aging and Health

Division of Geriatric Medicine and Gerontology 

Johns Hopkins University

Ph: (410) 502-2619

Fax: (410) 614-9625

Email: rvaradhan at jhmi.edu 

Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html 

 

----------------------------------------------------------------------------
--------


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch 
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jeremy
Goldhaber-Fiebert
Sent: Monday, June 11, 2007 11:47 AM
To: Spencer Graves
Cc: r-help at stat.math.ethz.ch 
Subject: Re: [R] Fwd: Using odesolve to produce non-negative solutions

Hi Spencer,

Thank you for your response. I also did not see anything on the lsoda help
page which is the reason that I wrote to the list.

>From your response, I am not sure if I asked my question clearly.

I am modeling a group of people (in a variety of health states) moving
through time (and getting infected with an infectious disease). This means
that the count of the number of people in each state should be positive at
all times. 

What appears to happen is that lsoda asks for a derivative at a given point
in time t and then adjusts the state of the population. However, perhaps due
to numerical instability, it occasionally lower the population count below 0
for one of the health states (perhaps because it's step size is too big or
something). 

I have tried both the logarithm trick and also changing the relative and
absolute tolerance inputs but I still get the problem for certain
combinations of parameters and initial conditions. 

It occurs both under MS Windows XP Service Pack 2 and on a Linux cluster so
I am pretty sure it is not platform specific.

My real question to the group is if there is not a work around in lsoda are
there other ode solvers in R that will allow the constraint of solutions to
the ODEs remain non-negative?

Best regards,
Jeremy
      

>>> Spencer Graves <spencer.graves at pdf.com> 6/8/2007 9:51 AM >>>
On the 'lsoda' help page, I did not see any option to force some 
or all parameters to be nonnegative. 

      Have you considered replacing the parameters that must be 
nonnegative with their logarithms?  This effective moves the 0 lower 
limit to (-Inf) and seems to have worked well for me in the past.  
Often, it can even make the log likelihood or sum of squares surface 
more elliptical, which means that the standard normal approximation for 
the sampling distribution of parameter estimates will likely be more 
accurate. 

      Hope this helps. 
      Spencer Graves
p.s.  Your example seems not to be self contained.  If I could have 
easily copied it from your email and run it myself, I might have been 
able to offer more useful suggestions. 

Jeremy Goldhaber-Fiebert wrote:
> Hello,
>
> I am using odesolve to simulate a group of people moving through time and
transmitting infections to one another. 
>
> In Matlab, there is a NonNegative option which tells the Matlab solver to
keep the vector elements of the ODE solution non-negative at all times. What
is the right way to do this in R?
>
> Thanks,
> Jeremy
>
> P.S., Below is a simplified version of the code I use to try to do this,
but I am not sure that it is theoretically right 
>
> dynmodel <- function(t,y,p) 
> { 
> ## Initialize parameter values
>
> 	birth <- p$mybirth(t)
> 	death <- p$mydeath(t)
> 	recover <- p$myrecover
> 	beta <- p$mybeta
> 	vaxeff <- p$myvaxeff
> 	vaccinated <- p$myvax(t)
>
> 	vax <- vaxeff*vaccinated/100
>
> ## If the state currently has negative quantities (shouldn't have), then
reset to reasonable values for computing meaningful derivatives
>
> 	for (i in 1:length(y)) {
> 		if (y[i]<0) {
> 			y[i] <- 0
> 		}
> 	}
>
> 	S <- y[1]
> 	I <- y[2]
> 	R <- y[3]
> 	N <- y[4]
>
> 	shat <- (birth*(1-vax)) - (death*S) - (beta*S*I/N)
> 	ihat <- (beta*S*I/N) - (death*I) - (recover*I)
> 	rhat <- (birth*(vax)) + (recover*I) - (death*R)
>
> ## Do we overshoot into negative space, if so shrink derivative to bring
state to 0 
> ## then rescale the components that take the derivative negative
>
> 	if (shat+S<0) {
> 		shat_old <- shat
> 		shat <- -1*S
> 		scaled_transmission <- (shat/shat_old)*(beta*S*I/N)
> 		ihat <- scaled_transmission - (death*I) - (recover*I)
> 		
> 	}	
> 	if (ihat+I<0) {
> 		ihat_old <- ihat
> 		ihat <- -1*I
> 		scaled_recovery <- (ihat/ihat_old)*(recover*I)
> 		rhat <- scaled_recovery +(birth*(vax)) - (death*R)
> 	
> 	}	
> 	if (rhat+R<0) {
> 		rhat <- -1*R
> 	}	
>
> 	nhat <- shat + ihat + rhat
>
> 	if (nhat+N<0) {
> 		nhat <- -1*N	
> 	}	
>
> ## return derivatives
>
> 	list(c(shat,ihat,rhat,nhat),c(0))
>
> }
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code.
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
and provide commented, minimal, self-contained, reproducible code.


From mister_bluesman at hotmail.com  Mon Jun 11 20:27:08 2007
From: mister_bluesman at hotmail.com (mister_bluesman)
Date: Mon, 11 Jun 2007 11:27:08 -0700 (PDT)
Subject: [R] Problem with RSVGTipsDevice
In-Reply-To: <11065061.post@talk.nabble.com>
References: <11064573.post@talk.nabble.com> <11065061.post@talk.nabble.com>
Message-ID: <11065835.post@talk.nabble.com>


Ah. Now that's intersting. It works in Opera. But do you get an annoying
'Null' label by the cursor when you place it over the svg file? 

MANY thanks





Mark Difford wrote:
> 
> Mister_Bluesman,
> 
> Perhaps I should have been more precise: your included svgplot1.svg
> displays fine...!
> 
> 
> mister_bluesman wrote:
>> 
>> Hi there.
>> 
>> I am still trying to get the RSVGTipsDevice to work, yet I can not.
>> 
>> I have copied the first example from RSVGTipsDevice documentation:
>> 
>> library(RSVGTipsDevice)
>> devSVGTips("C:\\svgplot1.svg", toolTipMode=1,
>> title="SVG example plot 1: shapes and points, tooltips are title + 1
>> line")
>> plot(c(0,10),c(0,10), type="n", xlab="x", ylab="y",
>> main="Example SVG plot with title + 1 line tips (mode=1)")
>> setSVGShapeToolTip(title="A rectangle", desc="that is yellow")
>> rect(1,1,4,6, col='yellow')
>> setSVGShapeToolTip(title="1st circle with title only")
>> points(5.5,7.5,cex=20,pch=19,col='red')
>> setSVGShapeToolTip(title="A triangle", desc="big and green")
>> polygon(c(3,6,8), c(3,6,3), col='green')
>> # no tooltips on these points
>> points(2:8, 8:2, cex=3, pch=19, col='black')
>> # tooltips on each these points
>> invisible(sapply(1:7, function(x)
>> {setSVGShapeToolTip(title=paste("point", x))
>> points(x+1, 8-x, cex=3, pch=1, col='black')}))
>> dev.off()
>> 
>> This results in the following output:
>> 
>>  http://www.nabble.com/file/p11064573/svgplot1.svg svgplot1.svg 
>> 
>> It opens but when I try and hover over the triangle, for example, I do
>> not get a topptip box appear. I have tried opening the file though
>> firefox, and XP IE - and on more than one computer yet it does not work.
>> Do I need to install something else as well?
>> 
>> Many thanks
>> 
> 
> 

-- 
View this message in context: http://www.nabble.com/Problem-with-RSVGTipsDevice-tf3902760.html#a11065835
Sent from the R help mailing list archive at Nabble.com.


From Setzer.Woodrow at epamail.epa.gov  Mon Jun 11 20:28:36 2007
From: Setzer.Woodrow at epamail.epa.gov (Setzer.Woodrow at epamail.epa.gov)
Date: Mon, 11 Jun 2007 14:28:36 -0400
Subject: [R] Fwd: Using odesolve to produce non-negative solutions
In-Reply-To: <B2B31B13-CEF9-4E51-B19D-4B694818AFAB@muohio.edu>
Message-ID: <OFB02EA6FB.A0A8F56A-ON852572F7.0064C572-852572F7.00658024@epamail.epa.gov>

Hi, all.
lsoda can certainly not handle complex parameters.  You can try (as Hank
suggested) limiting hmax.  You can also crank up relative and absolute
precision by specifying smaller values of  rtol and atol.  I've seen
similar problems in which the state variable becomes negative, with very
small absolute value, when theoretically, the system has a non-negative
solution.  This is certainly due to imprecision in the numerical
solution.  Have you tried including an analytic jacobian?  That could
improve the numeric properties of the solution.

Woody

R. Woodrow Setzer, Ph. D.
National Center for Computational Toxicology
US Environmental Protection Agency
Mail Drop B205-01/US EPA/RTP, NC 27711
Ph: (919) 541-0128    Fax: (919) 541-1194


                                                                        
             "Martin Henry H.                                           
             Stevens"                                                   
             <HStevens at muohio                                        To 
             .edu>                    Spencer Graves                    
                                      <spencer.graves at pdf.com>          
             06/11/2007 01:02                                        cc 
             PM                       Jeremy Goldhaber-Fiebert          
                                      <JGOLDHAB at hsph.harvard.edu>,      
                                      R-Help                            
                                      <r-help at stat.math.ethz.ch>,       
                                      Woodrow Setzer/RTP/USEPA/US at EPA   
                                                                Subject 
                                      Re: [R] Fwd: Using odesolve to    
                                      produce non-negative solutions    
                                                                        
                                                                        
                                                                        
                                                                        
                                                                        
                                                                        




Hi Spencer,
I have copied Woody Setzer. I have no idea whether lsoda can estimate
parameters that could take imaginary values.
Hank
On Jun 11, 2007, at 12:52 PM, Spencer Graves wrote:

> <in line>
>
> Martin Henry H. Stevens wrote:
>> Hi Jeremy,
>> First, setting hmax to a small number could prevent a large step, if
>> you think that is a problem. Second, however, I don't see how you can
>> get a negative population size when using the log trick.
> SG:  Can lsoda estimate complex or imaginary parameters?
Hmm. I have no idea.
>
>> I would think that that would prevent completely any negative values
>> of N (i.e. e^-100000 > 0). Can you explain? or do you want to a void
>> that trick? The only other solver I know of is rk4 and it is not
>> recommended.
>> Hank
>> On Jun 11, 2007, at 11:46 AM, Jeremy Goldhaber-Fiebert wrote:
>>
>>> Hi Spencer,
>>>
>>> Thank you for your response. I also did not see anything on the
>>> lsoda
>>> help page which is the reason that I wrote to the list.
>>>
>>>> From your response, I am not sure if I asked my question clearly.
>>>
>>> I am modeling a group of people (in a variety of health states)
>>> moving through time (and getting infected with an infectious
>>> disease). This means that the count of the number of people in each
>>> state should be positive at all times.
>>>
>>> What appears to happen is that lsoda asks for a derivative at a
>>> given
>>> point in time t and then adjusts the state of the population.
>>> However, perhaps due to numerical instability, it occasionally lower
>>> the population count below 0 for one of the health states (perhaps
>>> because it's step size is too big or something).
>>>
>>> I have tried both the logarithm trick
> <snip>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



Dr. Hank Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/

"E Pluribus Unum"


From Setzer.Woodrow at epamail.epa.gov  Mon Jun 11 20:30:55 2007
From: Setzer.Woodrow at epamail.epa.gov (Setzer.Woodrow at epamail.epa.gov)
Date: Mon, 11 Jun 2007 14:30:55 -0400
Subject: [R] Fwd: Using odesolve to produce non-negative solutions
In-Reply-To: <B2B31B13-CEF9-4E51-B19D-4B694818AFAB@muohio.edu>
Message-ID: <OFD0C57F98.009B2F54-ON852572F7.006590AC-852572F7.0065B67F@epamail.epa.gov>

By the way, if someone could forward the original question to me (I'm
subscribed to but not currently receiving R-help, as I found I was
spending too much time reading it!) I might think of something more
useful. (alternatively, when was it posted; I can find it on gmane,
too).

Woody
R. Woodrow Setzer, Ph. D.
National Center for Computational Toxicology
US Environmental Protection Agency
Mail Drop B205-01/US EPA/RTP, NC 27711
Ph: (919) 541-0128    Fax: (919) 541-1194


                                                                        
             "Martin Henry H.                                           
             Stevens"                                                   
             <HStevens at muohio                                        To 
             .edu>                    Spencer Graves                    
                                      <spencer.graves at pdf.com>          
             06/11/2007 01:02                                        cc 
             PM                       Jeremy Goldhaber-Fiebert          
                                      <JGOLDHAB at hsph.harvard.edu>,      
                                      R-Help                            
                                      <r-help at stat.math.ethz.ch>,       
                                      Woodrow Setzer/RTP/USEPA/US at EPA   
                                                                Subject 
                                      Re: [R] Fwd: Using odesolve to    
                                      produce non-negative solutions    
                                                                        
                                                                        
                                                                        
                                                                        
                                                                        
                                                                        




Hi Spencer,
I have copied Woody Setzer. I have no idea whether lsoda can estimate
parameters that could take imaginary values.
Hank
On Jun 11, 2007, at 12:52 PM, Spencer Graves wrote:

> <in line>
>
> Martin Henry H. Stevens wrote:
>> Hi Jeremy,
>> First, setting hmax to a small number could prevent a large step, if
>> you think that is a problem. Second, however, I don't see how you can
>> get a negative population size when using the log trick.
> SG:  Can lsoda estimate complex or imaginary parameters?
Hmm. I have no idea.
>
>> I would think that that would prevent completely any negative values
>> of N (i.e. e^-100000 > 0). Can you explain? or do you want to a void
>> that trick? The only other solver I know of is rk4 and it is not
>> recommended.
>> Hank
>> On Jun 11, 2007, at 11:46 AM, Jeremy Goldhaber-Fiebert wrote:
>>
>>> Hi Spencer,
>>>
>>> Thank you for your response. I also did not see anything on the
>>> lsoda
>>> help page which is the reason that I wrote to the list.
>>>
>>>> From your response, I am not sure if I asked my question clearly.
>>>
>>> I am modeling a group of people (in a variety of health states)
>>> moving through time (and getting infected with an infectious
>>> disease). This means that the count of the number of people in each
>>> state should be positive at all times.
>>>
>>> What appears to happen is that lsoda asks for a derivative at a
>>> given
>>> point in time t and then adjusts the state of the population.
>>> However, perhaps due to numerical instability, it occasionally lower
>>> the population count below 0 for one of the health states (perhaps
>>> because it's step size is too big or something).
>>>
>>> I have tried both the logarithm trick
> <snip>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



Dr. Hank Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/

"E Pluribus Unum"


From mark_difford at yahoo.co.uk  Mon Jun 11 20:38:06 2007
From: mark_difford at yahoo.co.uk (Mark Difford)
Date: Mon, 11 Jun 2007 11:38:06 -0700 (PDT)
Subject: [R] Problem with RSVGTipsDevice
In-Reply-To: <11065042.post@talk.nabble.com>
References: <11064573.post@talk.nabble.com> <11065042.post@talk.nabble.com>
Message-ID: <11066065.post@talk.nabble.com>


Hi Mister_Bluesman,

Sadly it is; and it stays up (in what's probably a bold, sans serif),
lurking behind the "ToolTip," when that comes up.

This is not my area of X, but any standard txt editor will open an svg file. 
If you search through your file you will find lots and lots of "null"
arguments to various functions.  It's likely that the problem lies there.

HTH,

Mark Difford.


mister_bluesman wrote:
> 
> Ah. Now that's intersting. It works in Opera. But do you get an annoying
> 'Null' label by the cursor when you place it over the svg file?
> 
> MANY thanks
> 

-- 
View this message in context: http://www.nabble.com/Problem-with-RSVGTipsDevice-tf3902760.html#a11066065
Sent from the R help mailing list archive at Nabble.com.


From francogrex at mail.com  Mon Jun 11 20:45:56 2007
From: francogrex at mail.com (francogrex)
Date: Mon, 11 Jun 2007 11:45:56 -0700 (PDT)
Subject: [R] Reading old S-plus dmp files
Message-ID: <11066203.post@talk.nabble.com>


I'm sorry that this question has been asked before but I ask it again because
in the archives I didn't see a solution. It's an old S-plus dmp file for a
hierarchical bayes linear model program written by DuMouchel and available
publicly and freely at:
ftp://ftp.research.att.com/dist/bayes-meta/hblm.dmp 
Only problem is that it cannot be read in R, even using the functions of the
library foreign to read dmp files. Does anyone know a workaround, maybe
hints about what parts of the file need to be modified so that it can be
read. I have read the documentations of the program, it seems a very
interesting program, it's a shame that I can't read it. Thanks.

-- 
View this message in context: http://www.nabble.com/Reading-old-S-plus-dmp-files-tf3903236.html#a11066203
Sent from the R help mailing list archive at Nabble.com.


From Cody_Hamilton at Edwards.com  Mon Jun 11 20:52:44 2007
From: Cody_Hamilton at Edwards.com (Cody_Hamilton at Edwards.com)
Date: Mon, 11 Jun 2007 11:52:44 -0700
Subject: [R] R vs. Splus in Pharma/Devices Industry
Message-ID: <OF3C738AE9.1F5E42D3-ON882572F7.00679325-882572F7.0067817A@irvine.edwards.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070611/1c654042/attachment.pl 

From f.harrell at vanderbilt.edu  Mon Jun 11 21:04:49 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Mon, 11 Jun 2007 14:04:49 -0500
Subject: [R] R vs. Splus in Pharma/Devices Industry
In-Reply-To: <OF3C738AE9.1F5E42D3-ON882572F7.00679325-882572F7.0067817A@irvine.edwards.com>
References: <OF3C738AE9.1F5E42D3-ON882572F7.00679325-882572F7.0067817A@irvine.edwards.com>
Message-ID: <466D9CD1.7010900@vanderbilt.edu>

Cody_Hamilton at Edwards.com wrote:
> Following up to some extent on Friday's discussion regarding the
> 'validation' of R, could I ask the list group's opinion on possible
> advantages of R over Splus from a pharma/devices perspective?  I wish to
> exclude the obvious price difference, which doesn???t seem to carry as much
> weight as I would have thought.  Besides, I have noticed many former Splus
> users gravitating towards R, and I suspect that the reasons are not purely
> economic.
> 
> I can think of a few advantages of Splus:
> 1. SeqTrial (of course that means more $)
> 2. Tech support
> 3. The warm fuzzies that management seems to get from proprietary software
> 
> I can also think of a few advantages of R:
> 1. Based on my personal experiences, simulations requiring a lot of looping
> seem to run faster.
> 2. R interfaces with BUGS, for example through BRUGS.
> 3. The wonderful help list!
> 
> As always, I am speaking for myself and not necessarily for Edwards
> Lifesciences.
> 
> Regards,
>    -Cody
> 
> Cody Hamilton, PhD
> Edwards Lifesciences
> 	[[alternative HTML version deleted]]

A big one for us is plotmath (for clinical trial reports we put a lot of 
greek letters and subscripts on plots), and later we will consider 
migrating a lot of our stuff to the ggplot package which I don't think 
is available in S-Plus.  Lexical scoping is another advantage of R as is 
the ability to reference files on the internet.

Frank

> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From rvaradhan at jhmi.edu  Mon Jun 11 19:23:19 2007
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Mon, 11 Jun 2007 13:23:19 -0400
Subject: [R] Fwd: Using odesolve to produce non-negative solutions
In-Reply-To: <B2B31B13-CEF9-4E51-B19D-4B694818AFAB@muohio.edu>
References: <4666A5D0.896D.005E.0@hsph.harvard.edu>
	<4666A910.896D.005E.0@hsph.harvard.edu> <46695EC8.2090602@pdf.com>
	<466D3605.896D.005E.0@hsph.harvard.edu>
	<2B0CABC4-17EB-40B8-ADCD-BB94597D1570@MUOhio.edu>
	<466D7DE9.2030205@pdf.com>
	<B2B31B13-CEF9-4E51-B19D-4B694818AFAB@muohio.edu>
Message-ID: <000301c7ac4d$35158310$7c94100a@win.ad.jhu.edu>

Hi Jeremy,

A smaller step size may or may not help.  If the issue is simply truncation
error, that is the error involved in discretizing the differential
equations, then a smaller step size would help.  If, however, the true
solution to the differential equation is negative, for some t, then the
numerical solution should also be negative.  If the negative solution does
not make sense, then the system of equation needs to be examined to see when
and why negative solutions arise.  Perhaps, I am just making this up - there
needs to be a "barrier function" that slows down the trajectory as it
approaches zero from its initial value. It is also possible that only
certain regions of the parameter space are allowed in the sense that only
there the solution is feasible for all t.  So, in your example, the
parameters might not be realistic.  In short, if you are sure that the
numerical solution is accurate, then you need to go back to your system of
equations and analyze them carefully.


Ravi.


----------------------------------------------------------------------------
-------

Ravi Varadhan, Ph.D.

Assistant Professor, The Center on Aging and Health

Division of Geriatric Medicine and Gerontology 

Johns Hopkins University

Ph: (410) 502-2619

Fax: (410) 614-9625

Email: rvaradhan at jhmi.edu

Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html

 

----------------------------------------------------------------------------
--------


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Martin Henry H.
Stevens
Sent: Monday, June 11, 2007 1:03 PM
To: Spencer Graves
Cc: Jeremy Goldhaber-Fiebert; R-Help; Setzer.Woodrow at epamail.epa.gov
Subject: Re: [R] Fwd: Using odesolve to produce non-negative solutions

Hi Spencer,
I have copied Woody Setzer. I have no idea whether lsoda can estimate  
parameters that could take imaginary values.
Hank
On Jun 11, 2007, at 12:52 PM, Spencer Graves wrote:

> <in line>
>
> Martin Henry H. Stevens wrote:
>> Hi Jeremy,
>> First, setting hmax to a small number could prevent a large step, if
>> you think that is a problem. Second, however, I don't see how you can
>> get a negative population size when using the log trick.
> SG:  Can lsoda estimate complex or imaginary parameters?
Hmm. I have no idea.
>
>> I would think that that would prevent completely any negative values
>> of N (i.e. e^-100000 > 0). Can you explain? or do you want to a void
>> that trick? The only other solver I know of is rk4 and it is not
>> recommended.
>> Hank
>> On Jun 11, 2007, at 11:46 AM, Jeremy Goldhaber-Fiebert wrote:
>>
>>> Hi Spencer,
>>>
>>> Thank you for your response. I also did not see anything on the  
>>> lsoda
>>> help page which is the reason that I wrote to the list.
>>>
>>>> From your response, I am not sure if I asked my question clearly.
>>>
>>> I am modeling a group of people (in a variety of health states)
>>> moving through time (and getting infected with an infectious
>>> disease). This means that the count of the number of people in each
>>> state should be positive at all times.
>>>
>>> What appears to happen is that lsoda asks for a derivative at a  
>>> given
>>> point in time t and then adjusts the state of the population.
>>> However, perhaps due to numerical instability, it occasionally lower
>>> the population count below 0 for one of the health states (perhaps
>>> because it's step size is too big or something).
>>>
>>> I have tried both the logarithm trick
> <snip>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



Dr. Hank Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/

"E Pluribus Unum"

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From mister_bluesman at hotmail.com  Mon Jun 11 19:53:23 2007
From: mister_bluesman at hotmail.com (mister_bluesman)
Date: Mon, 11 Jun 2007 10:53:23 -0700 (PDT)
Subject: [R] Problem with RSVGTipsDevice
In-Reply-To: <11064573.post@talk.nabble.com>
References: <11064573.post@talk.nabble.com>
Message-ID: <11065042.post@talk.nabble.com>


Ah. Now that's intersting. It works in Opera. But do you get an annoying
'Null' label by the cursor when you place it over the svg file?

MANY thanks
-- 
View this message in context: http://www.nabble.com/Problem-with-RSVGTipsDevice-tf3902760.html#a11065042
Sent from the R help mailing list archive at Nabble.com.


From paulj at stats.gla.ac.uk  Mon Jun 11 17:29:12 2007
From: paulj at stats.gla.ac.uk (Paul Johnson)
Date: Mon, 11 Jun 2007 16:29:12 +0100
Subject: [R] Can I access the filename of the active editor window?
Message-ID: <003001c7ac3d$43372b20$cd90d182@rcbdomain.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070611/33cf6ca7/attachment.pl 

From cox at montana.edu  Mon Jun 11 21:11:16 2007
From: cox at montana.edu (cox at montana.edu)
Date: Mon, 11 Jun 2007 13:11:16 -0600 (MDT)
Subject: [R] Rearranging Capture History Data in R
Message-ID: <1226.153.90.240.117.1181589076.squirrel@gemini.msu.montana.edu>

What code can i use to convert a table like this:

Tag#    Date
1       1
2       1
3       1
4       1
2       2
4       2
1       3
2       3
4       4

Into one like this:

Tag     1     2     3     4 #Date header
1       1     0     0     1
2       1     1     1     0
3       1     0     0     0
4       1     1     0     1

Thanks,


Ben Cox
Research Assistant (M.S.)
Montana Cooperative Fishery Research Unit
301 Lewis Hall
Montana State University
Bozeman, MT 59717
(406)994-6643


From jwang at uoguelph.ca  Mon Jun 11 21:50:36 2007
From: jwang at uoguelph.ca (jwang at uoguelph.ca)
Date: Mon, 11 Jun 2007 15:50:36 -0400
Subject: [R] A Question about "R"
Message-ID: <20070611155036.rhw1hv82880o0okw@webmail.uoguelph.ca>

Hi Sir/Madam,

I'm a researcher in university of Guelph, Canada and now considering  
using R to do some data analysis. I'm wondering whether there is a  
library available in R that includes algorithms for "archetypal  
analysis"? This is a method quite similar to principal components  
analysis that is designed to find "archetypes" or "pure types" from  
multidimensional data.

Any help from you is greatly appreciated.

Thanks
Juan


From deepayan.sarkar at gmail.com  Mon Jun 11 21:50:37 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Mon, 11 Jun 2007 12:50:37 -0700
Subject: [R] Lines in dotchart & dotplot ?
In-Reply-To: <450651.6379.qm@web32804.mail.mud.yahoo.com>
References: <eb555e660706091136l3f6ea07du1a8fa76f65da7547@mail.gmail.com>
	<450651.6379.qm@web32804.mail.mud.yahoo.com>
Message-ID: <eb555e660706111250r7588f881i261ad10fdc814d33@mail.gmail.com>

On 6/11/07, John Kane <jrkrideau at yahoo.ca> wrote:
>
> --- deepayan.sarkar at gmail.com wrote:
>
> > On 6/9/07, John Kane <jrkrideau at yahoo.ca> wrote:
> > > Is it possible to use dotchart or dotplot and set
> > the
> > > lines in such a way that they only extend from the
> > > left y-axis to the data point?
> >
> > Yes (sort of) in dotplot at least. E.g.,
> >
> > dotplot(VADeaths, groups = FALSE, type = c("p",
> > "h"))
> > dotplot(VADeaths, groups = FALSE, type = c("p",
> > "h"), origin = 0)
> >
> > -Deepayan
> >
>
> Ah, that is quite nice, not exactly what I remember
> from Cleveland but it should do quite nicely.

You can do that too if you really want to:

dotplot(VADeaths, groups = FALSE, type = c("p", "h"), origin = 0,
        panel = panel.xyplot, pch = 16, lty = 3, col = "black")

-Deepayan


From rvaradhan at jhmi.edu  Mon Jun 11 21:55:38 2007
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Mon, 11 Jun 2007 15:55:38 -0400
Subject: [R] Fwd: Using odesolve to produce non-negative solutions
In-Reply-To: <466D3605.896D.005E.0@hsph.harvard.edu>
References: <4666A5D0.896D.005E.0@hsph.harvard.edu>
	<4666A910.896D.005E.0@hsph.harvard.edu> <46695EC8.2090602@pdf.com>
	<466D3605.896D.005E.0@hsph.harvard.edu>
Message-ID: <002301c7ac62$7bd04e10$7c94100a@win.ad.jhu.edu>

Jeremy,

You should examine the steady-state solution to your system of equations, by
setting the time-derivatives to zero and then solving/analyzing the
resulting algebraic equations.  This should give you some insights.  

Let us say you have 3 groups, A,B, and C, with initial conditions:
N_A(t=0) = N_{A0}, N_B(t=0) = N_{B0}, and N_C(t=0) = N_{C0}, and that people
transition in and out of these 3 states (one of the states could even be
absorbing, e.g. death), but it is true for any time t that N_A(t) + N_B(t) +
N_C(t) = N_{A0} + N_{B0} + N_{C0}.  Furthermore, you have 3 diff-equations
that describe the rate of change of N_A, N_B, and N_C, for t > 0.  If it
happens that one of the N's, say N_A, becomes negative, you could set it
equal to zero.  But then you have to figure out how to re-adjust N_B and N_C
so that they add up to the initial total count.  After re-adjustment, you
also have to think about whether the resulting system of equations are
valid, when there are no A people.

Ravi. 


----------------------------------------------------------------------------
-------

Ravi Varadhan, Ph.D.

Assistant Professor, The Center on Aging and Health

Division of Geriatric Medicine and Gerontology 

Johns Hopkins University

Ph: (410) 502-2619

Fax: (410) 614-9625

Email: rvaradhan at jhmi.edu

Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html

 

----------------------------------------------------------------------------
--------


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jeremy
Goldhaber-Fiebert
Sent: Monday, June 11, 2007 11:47 AM
To: Spencer Graves
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Fwd: Using odesolve to produce non-negative solutions

Hi Spencer,

Thank you for your response. I also did not see anything on the lsoda help
page which is the reason that I wrote to the list.

>From your response, I am not sure if I asked my question clearly.

I am modeling a group of people (in a variety of health states) moving
through time (and getting infected with an infectious disease). This means
that the count of the number of people in each state should be positive at
all times. 

What appears to happen is that lsoda asks for a derivative at a given point
in time t and then adjusts the state of the population. However, perhaps due
to numerical instability, it occasionally lower the population count below 0
for one of the health states (perhaps because it's step size is too big or
something). 

I have tried both the logarithm trick and also changing the relative and
absolute tolerance inputs but I still get the problem for certain
combinations of parameters and initial conditions. 

It occurs both under MS Windows XP Service Pack 2 and on a Linux cluster so
I am pretty sure it is not platform specific.

My real question to the group is if there is not a work around in lsoda are
there other ode solvers in R that will allow the constraint of solutions to
the ODEs remain non-negative?

Best regards,
Jeremy
      

>>> Spencer Graves <spencer.graves at pdf.com> 6/8/2007 9:51 AM >>>
On the 'lsoda' help page, I did not see any option to force some 
or all parameters to be nonnegative. 

      Have you considered replacing the parameters that must be 
nonnegative with their logarithms?  This effective moves the 0 lower 
limit to (-Inf) and seems to have worked well for me in the past.  
Often, it can even make the log likelihood or sum of squares surface 
more elliptical, which means that the standard normal approximation for 
the sampling distribution of parameter estimates will likely be more 
accurate. 

      Hope this helps. 
      Spencer Graves
p.s.  Your example seems not to be self contained.  If I could have 
easily copied it from your email and run it myself, I might have been 
able to offer more useful suggestions. 

Jeremy Goldhaber-Fiebert wrote:
> Hello,
>
> I am using odesolve to simulate a group of people moving through time and
transmitting infections to one another. 
>
> In Matlab, there is a NonNegative option which tells the Matlab solver to
keep the vector elements of the ODE solution non-negative at all times. What
is the right way to do this in R?
>
> Thanks,
> Jeremy
>
> P.S., Below is a simplified version of the code I use to try to do this,
but I am not sure that it is theoretically right 
>
> dynmodel <- function(t,y,p) 
> { 
> ## Initialize parameter values
>
> 	birth <- p$mybirth(t)
> 	death <- p$mydeath(t)
> 	recover <- p$myrecover
> 	beta <- p$mybeta
> 	vaxeff <- p$myvaxeff
> 	vaccinated <- p$myvax(t)
>
> 	vax <- vaxeff*vaccinated/100
>
> ## If the state currently has negative quantities (shouldn't have), then
reset to reasonable values for computing meaningful derivatives
>
> 	for (i in 1:length(y)) {
> 		if (y[i]<0) {
> 			y[i] <- 0
> 		}
> 	}
>
> 	S <- y[1]
> 	I <- y[2]
> 	R <- y[3]
> 	N <- y[4]
>
> 	shat <- (birth*(1-vax)) - (death*S) - (beta*S*I/N)
> 	ihat <- (beta*S*I/N) - (death*I) - (recover*I)
> 	rhat <- (birth*(vax)) + (recover*I) - (death*R)
>
> ## Do we overshoot into negative space, if so shrink derivative to bring
state to 0 
> ## then rescale the components that take the derivative negative
>
> 	if (shat+S<0) {
> 		shat_old <- shat
> 		shat <- -1*S
> 		scaled_transmission <- (shat/shat_old)*(beta*S*I/N)
> 		ihat <- scaled_transmission - (death*I) - (recover*I)
> 		
> 	}	
> 	if (ihat+I<0) {
> 		ihat_old <- ihat
> 		ihat <- -1*I
> 		scaled_recovery <- (ihat/ihat_old)*(recover*I)
> 		rhat <- scaled_recovery +(birth*(vax)) - (death*R)
> 	
> 	}	
> 	if (rhat+R<0) {
> 		rhat <- -1*R
> 	}	
>
> 	nhat <- shat + ihat + rhat
>
> 	if (nhat+N<0) {
> 		nhat <- -1*N	
> 	}	
>
> ## return derivatives
>
> 	list(c(shat,ihat,rhat,nhat),c(0))
>
> }
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code.
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bcarvalh at jhsph.edu  Mon Jun 11 22:08:59 2007
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Mon, 11 Jun 2007 16:08:59 -0400
Subject: [R] Rearranging Capture History Data in R
In-Reply-To: <1226.153.90.240.117.1181589076.squirrel@gemini.msu.montana.edu>
References: <1226.153.90.240.117.1181589076.squirrel@gemini.msu.montana.edu>
Message-ID: <992DAE5C-7BED-425D-B879-6A95FCA3FEB9@jhsph.edu>

date = c(1, 1, 1, 1, 2, 2, 3, 3, 4)
tag = c(1, 2, 3, 4, 2, 4, 1, 2, 4)
table(factor(tag, levels=1:4), factor(date, levels=1:4))

(not sure how you got Tag 1/Date 4 = 1)


On Jun 11, 2007, at 3:11 PM, cox at montana.edu wrote:

> What code can i use to convert a table like this:
>
> Tag#    Date
> 1       1
> 2       1
> 3       1
> 4       1
> 2       2
> 4       2
> 1       3
> 2       3
> 4       4
>
> Into one like this:
>
> Tag     1     2     3     4 #Date header
> 1       1     0     0     1
> 2       1     1     1     0
> 3       1     0     0     0
> 4       1     1     0     1
>
> Thanks,
>
>
> Ben Cox
> Research Assistant (M.S.)
> Montana Cooperative Fishery Research Unit
> 301 Lewis Hall
> Montana State University
> Bozeman, MT 59717
> (406)994-6643
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rdiaz02 at gmail.com  Mon Jun 11 22:54:57 2007
From: rdiaz02 at gmail.com (Ramon Diaz-Uriarte)
Date: Mon, 11 Jun 2007 22:54:57 +0200
Subject: [R] simultaneous computing
In-Reply-To: <466D3C0D.1070800@ibe.med.uni-muenchen.de>
References: <466D3C0D.1070800@ibe.med.uni-muenchen.de>
Message-ID: <624934630706111354l4fd00777o4b5172800a75c354@mail.gmail.com>

Dear Markus,

You might want to check Rmpi, papply, snow, rpvm, and nws.

Best,

R.

On 6/11/07, Markus Schmidberger <schmidb at ibe.med.uni-muenchen.de> wrote:
> Hello,
>
> which possibilities are available in R for simultaneous or parallel
> computing?
> I only could find biopara
> (http://cran.r-project.org/src/contrib/Descriptions/biopara.html)
>
> Are there other possibilities?
> Are there special groups working on simultaneous computing with R?
>
> Thanks
> Markus
>
> --
> Dipl.-Tech. Math. Markus Schmidberger
>
> Ludwig-Maximilians-Universit?t M?nchen
> IBE - Institut f?r medizinische Informationsverarbeitung,
> Biometrie und Epidemiologie
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Ramon Diaz-Uriarte
Statistical Computing Team
Structural Biology and Biocomputing Programme
Spanish National Cancer Centre (CNIO)
http://ligarto.org/rdiaz


From timothyholland at gmail.com  Mon Jun 11 22:55:04 2007
From: timothyholland at gmail.com (Tim Holland)
Date: Mon, 11 Jun 2007 16:55:04 -0400
Subject: [R] selecting characters from a line of text
Message-ID: <1dba89130706111355g5b019722j8d0e1bd054d9b098@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070611/44df04a1/attachment.pl 

From juryef at yahoo.com  Mon Jun 11 22:57:37 2007
From: juryef at yahoo.com (Judith Flores)
Date: Mon, 11 Jun 2007 13:57:37 -0700 (PDT)
Subject: [R] ylim settings
Message-ID: <8144.48490.qm@web34715.mail.mud.yahoo.com>

Hi,

    I need to know what is the plus/minus adjustment
(proportion) that ylim applies if I have something
like this:

ylim=range(c(x,z))

   meaning what's the x-(proportion) and the z+
(proportion)?


Thank you,

Judith


      ____________________________________________________________________________________
Luggage? GPS? Comic books?


From hstevens at muohio.edu  Mon Jun 11 23:23:46 2007
From: hstevens at muohio.edu (Martin Henry H. Stevens)
Date: Mon, 11 Jun 2007 17:23:46 -0400
Subject: [R] Package update announcements
Message-ID: <3EDD07F1-6808-4144-8BD1-EB4478C63574@muohio.edu>

Hi Folks,
I was wondering what everyone thought about adding a sentence to each  
package update announcement that described what the package did. R  
extensions are so numerous that it is difficult to keep up with them.  
Would it be appropriate to ask package developers to add a brief  
sentence about what the package does, when they announce updates?

I would benefit from such descriptions.

Cheers,
Hank

Dr. Hank Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/

"E Pluribus Unum"


From pomchip at free.fr  Tue Jun 12 00:32:00 2007
From: pomchip at free.fr (Seb)
Date: Mon, 11 Jun 2007 18:32:00 -0400
Subject: [R] Overlaying lattice graphs
Message-ID: <466DCD60.3020600@free.fr>

Hello

I apologize in advance if this question has already be posted on the 
list, although I could not find a relevant thread in the archives.

I would like to overlay xyplots using different datasets for each plot. 
I typically work on the following data.frame (mydata) structure

>mydata
        Drug    Time        Observed          Predicted
1       A        0.05         10                 10.2
2       A        0.10         20                 19.5
etc...
100     B        0.05         11                 12.7
101     B        0.10         35                 36
etc...

I want to plot the observed data as points and the predicted values as 
lines. If I use the following commands, I don't have the possibility to 
switch the "y" values from Observed for the scatterplot to Predicted for 
the line.

xyplot(Observed ~ Time | Drug, data = mydata, panel  =  function(x,y, ...){
+            panel.xyplot(x,y,...)
+            panel.xyplot(x,y,type="l",...)})

I wonder if this problem can be solved using the trellis.focus "family" 
commands but I have a hard time to understand how they work.

Please, let me know if a thread have already addressed this question. 
Otherwise, I would grateful for any hint, comments or info you can provide.

Thanks

Sebastien


From marc_schwartz at comcast.net  Tue Jun 12 00:44:00 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Mon, 11 Jun 2007 17:44:00 -0500
Subject: [R] ylim settings
In-Reply-To: <8144.48490.qm@web34715.mail.mud.yahoo.com>
References: <8144.48490.qm@web34715.mail.mud.yahoo.com>
Message-ID: <1181601840.6085.6.camel@Bellerophon.localdomain>

On Mon, 2007-06-11 at 13:57 -0700, Judith Flores wrote:
> Hi,
> 
>     I need to know what is the plus/minus adjustment
> (proportion) that ylim applies if I have something
> like this:
> 
> ylim=range(c(x,z))
> 
>    meaning what's the x-(proportion) and the z+
> (proportion)?
> 
> 
> Thank you,
> 
> Judith

If I am correctly understanding your query, the answer is +/- 4% of the
range of values for the concatenated vectors, as you have it expressed
above, _IF_ par(yaxs) is set to the default value of 'r'.

If you set par(yaxs = "i"), then the y axis range is set to the min and
max values of the concatenated vectors.

See ?par for more information, specifically 'xaxs'.

HTH,

Marc Schwartz


From deepayan.sarkar at gmail.com  Tue Jun 12 00:49:14 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Mon, 11 Jun 2007 15:49:14 -0700
Subject: [R] Overlaying lattice graphs
In-Reply-To: <466DCD60.3020600@free.fr>
References: <466DCD60.3020600@free.fr>
Message-ID: <eb555e660706111549n35d8f442x1833c06b0cd61c0@mail.gmail.com>

On 6/11/07, Seb <pomchip at free.fr> wrote:
> Hello
>
> I apologize in advance if this question has already be posted on the
> list, although I could not find a relevant thread in the archives.
>
> I would like to overlay xyplots using different datasets for each plot.
> I typically work on the following data.frame (mydata) structure
>
> >mydata
>         Drug    Time        Observed          Predicted
> 1       A        0.05         10                 10.2
> 2       A        0.10         20                 19.5
> etc...
> 100     B        0.05         11                 12.7
> 101     B        0.10         35                 36
> etc...
>
> I want to plot the observed data as points and the predicted values as
> lines. If I use the following commands, I don't have the possibility to
> switch the "y" values from Observed for the scatterplot to Predicted for
> the line.
>
> xyplot(Observed ~ Time | Drug, data = mydata, panel  =  function(x,y, ...){
> +            panel.xyplot(x,y,...)
> +            panel.xyplot(x,y,type="l",...)})
>
> I wonder if this problem can be solved using the trellis.focus "family"
> commands but I have a hard time to understand how they work.
>
> Please, let me know if a thread have already addressed this question.
> Otherwise, I would grateful for any hint, comments or info you can provide.

There are several possible solutions. In your case, the simplest one
would be something like (see ?panel.superpose for explanation):

xyplot(Observed + Predicted ~ Time | Drug, data = mydata,
       type = c("p", "l"), distribute.type = TRUE)

This will work best if the Time values are ordered; otherwise you could use

type = c("p", "a")

instead, which will be a little slower. Let us know if this doesn't
give you what you want, preferably with a reproducible example
illustrating why.

-Deepayan


From mister_bluesman at hotmail.com  Tue Jun 12 01:12:53 2007
From: mister_bluesman at hotmail.com (mister_bluesman)
Date: Mon, 11 Jun 2007 16:12:53 -0700 (PDT)
Subject: [R] Rgobbi and colours question
Message-ID: <11070461.post@talk.nabble.com>


Hi

I am using R to implement a multidimensional algorithm which maps places
based on the distances between each other. This is presented really well in
Rggobi. 

However, for each place plotted, I have another numerical statistic between
0 and 1 which I would like to represent by colouring the points in Rgobbi.
However I do not know how to do this.
 
The file I am using is called places.txt and has the following contents:

            Chelt     Exeter   London  Birm
Chelt   0       118     96      50
Exeter  118     0       118     163
London  96      118     0       118
Birm    50      163     118     0

To plot these, the R code is as follows:

library(rggobi)
Places<-read.table("C:\\places.txt")
Places.location <- cmdscale(Places, k=2)
round(Places.location,0) 
g<-ggobi(Places.location)

 
Now, for each point plotted I want to assign a colour to it based on the
statistic in a file called PlacesStats.txt which currently has the following
format:

0.1  0.3  0.4  0.5

With the values in order of the names of the places given above so that:

0.1 is assigned to Chelt
0.3 is assigned to Exeter
0.4 is assigned to London
0.7 is assigned to Birm

Ideally, I want a gradient of two colours so that say, 0 = blue and 1 = red
and values between are a mixture.

Any ideas on how I could do this? Would I need to change the PlacesStats.txt
file so that is reads:

Chelt 0.1
Exeter 0.3
London 0.4
Birm 0.7

for example?

I would be very grateful if anybody could help.

Many thanks
-- 
View this message in context: http://www.nabble.com/Rgobbi-and-colours-question-tf3904622.html#a11070461
Sent from the R help mailing list archive at Nabble.com.


From brown_emu at yahoo.com  Tue Jun 12 01:34:23 2007
From: brown_emu at yahoo.com (Stephen Tucker)
Date: Mon, 11 Jun 2007 16:34:23 -0700 (PDT)
Subject: [R] selecting characters from a line of text
In-Reply-To: <1dba89130706111355g5b019722j8d0e1bd054d9b098@mail.gmail.com>
Message-ID: <954394.51738.qm@web39711.mail.mud.yahoo.com>

Maybe substring() is what you're looking for? Some examples:

> substring("textstring",1,5)
[1] "texts"
> substring("textstring",3)
[1] "xtstring"
> substring("textstring",3,nchar("textstring"))
[1] "xtstring"


--- Tim Holland <timothyholland at gmail.com> wrote:

> Is there a way in R to select certain characters from a line of text?  I
> have some data that is presently in a large number of text files, and I
> would like to be able to select elements of each text file (elements are
> always on the same line, in the same position) and organize them into a
> table.  Is there a tool to select text in this way in R?  What I am looking
> for would be somewhat similar to the left() and right() functions in Excel.
> I have looked at the parse() and scan() functions, but don't think they can
> do what I want (although I could be wrong).
> Thank you,
> Tim
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From hvillalo at ipn.mx  Tue Jun 12 02:45:17 2007
From: hvillalo at ipn.mx (=?ISO-8859-1?Q?H=E9ctor_Villalobos?=)
Date: Mon, 11 Jun 2007 18:45:17 -0600
Subject: [R] barplot and map overlay
Message-ID: <466D983D.22125.2401CFC@hvillalo.ipn.mx>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070611/950d6d54/attachment.pl 

From peacedan at yahoo.com  Tue Jun 12 03:56:02 2007
From: peacedan at yahoo.com (Daniel Young)
Date: Mon, 11 Jun 2007 18:56:02 -0700 (PDT)
Subject: [R] Components in the control list of optim()
Message-ID: <524606.46859.qm@web31701.mail.mud.yahoo.com>

Because the function optim() does not return the
values of the components in the 'control' list, I am
seeking help to uncover the blackbox for some of these
components:

parscale: par/parscale is used for ndeps, but how does
optim() set parscale at the first place?
abstol: no default information given in the help file,
so what is it?
reltol: this one is clear in the help file, but if
both abstol and reltol are used as default, which one
does optim() take as the higher stopping criterion?

Two other related questions:
First, ndeps is used for the finite-difference
approximation, but is this forward, backward, or
central difference?
Second, if I minimize a function through optim (say,
BFGS), does abstol/reltol use the function value or
the estimated parameter values to assess convergence?

Many thanks,

Daniel


       
____________________________________________________________________________________
Pinpoint customers who are looking for what you sell.


From ecjbosu at aol.com  Tue Jun 12 04:38:27 2007
From: ecjbosu at aol.com (Joe W. Byers)
Date: Mon, 11 Jun 2007 21:38:27 -0500
Subject: [R] Unable to load RMySQL
In-Reply-To: <17191.212.209.13.15.1171634703.squirrel@www.sorch.se>
References: <A36876D3F8A5734FA84A4338135E7CC3E8C5DD@BAN-MAILSRV03.Amba.com>
	<17191.212.209.13.15.1171634703.squirrel@www.sorch.se>
Message-ID: <466E0723.70206@aol.com>

All,

I have been down for the past two weeks moving from Tulsa to Houston for 
a new job.  I just got internet access yesterday at our new home.  I 
will be working on the RMySQL binary later this week if possible.  There 
is a hitch in compiling the binary.  I have the binaries for an older 
version of MySQL on which the R compilation worked.  A newer version of 
MySQL 5.0.37, I never was able to get the R binaries to compile.

I appreciate your patience here because I have a new job and my family 
and I are trying to organize our new home right now.

Thank you
Joe


Henric Nilsson (Public) wrote:
> Den Ti, 2007-02-13, 11:43 skrev Ravi S. Shankar:
>> Hi R users,
>>
>>
>>
>> I am unable to load RMySQL. The zip file is not available which I guess
>> is needed to load this pakage.
> 
> Please read http://cran.r-project.org/bin/windows/contrib/2.4/ReadMe to
> find out why.
> 
>> I also tried extracting the package from RMySQL_0.5-11.tar.gz  and then
>> pasted the package in the directory where R is loaded for which I am
>> getting the following error message
>>
>> "Error in library(RMySQL) : 'RMySQL' is not a valid package -- installed
>> < 2.0.0?"
> 
> Did you really expect that to work?
> 
>> Any help would be welcome
> 
> Joe Byers (http://bus.cba.utulsa.edu/byersj/Research.asp) kindly provides
> a Windows binary of RMySQL.
> 
> 
> HTH,
> Henric
> 
> 
> 
>>
>>
>> Thank you,
>>
>>
>>
>> Ravi
>>
>>
>>
>>
>>  [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ecjbosu at aol.com  Tue Jun 12 04:38:27 2007
From: ecjbosu at aol.com (Joe W. Byers)
Date: Mon, 11 Jun 2007 21:38:27 -0500
Subject: [R] Unable to load RMySQL
In-Reply-To: <17191.212.209.13.15.1171634703.squirrel@www.sorch.se>
References: <A36876D3F8A5734FA84A4338135E7CC3E8C5DD@BAN-MAILSRV03.Amba.com>
	<17191.212.209.13.15.1171634703.squirrel@www.sorch.se>
Message-ID: <466E0723.70206@aol.com>

All,

I have been down for the past two weeks moving from Tulsa to Houston for 
a new job.  I just got internet access yesterday at our new home.  I 
will be working on the RMySQL binary later this week if possible.  There 
is a hitch in compiling the binary.  I have the binaries for an older 
version of MySQL on which the R compilation worked.  A newer version of 
MySQL 5.0.37, I never was able to get the R binaries to compile.

I appreciate your patience here because I have a new job and my family 
and I are trying to organize our new home right now.

Thank you
Joe


Henric Nilsson (Public) wrote:
> Den Ti, 2007-02-13, 11:43 skrev Ravi S. Shankar:
>> Hi R users,
>>
>>
>>
>> I am unable to load RMySQL. The zip file is not available which I guess
>> is needed to load this pakage.
> 
> Please read http://cran.r-project.org/bin/windows/contrib/2.4/ReadMe to
> find out why.
> 
>> I also tried extracting the package from RMySQL_0.5-11.tar.gz  and then
>> pasted the package in the directory where R is loaded for which I am
>> getting the following error message
>>
>> "Error in library(RMySQL) : 'RMySQL' is not a valid package -- installed
>> < 2.0.0?"
> 
> Did you really expect that to work?
> 
>> Any help would be welcome
> 
> Joe Byers (http://bus.cba.utulsa.edu/byersj/Research.asp) kindly provides
> a Windows binary of RMySQL.
> 
> 
> HTH,
> Henric
> 
> 
> 
>>
>>
>> Thank you,
>>
>>
>>
>> Ravi
>>
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mroyerr at gmail.com  Tue Jun 12 05:13:51 2007
From: mroyerr at gmail.com (Mary Royerr)
Date: Tue, 12 Jun 2007 08:43:51 +0530
Subject: [R] Textpad help
In-Reply-To: <111b2f270706110029g7fa6cf19pbc260a99ec581a26@mail.gmail.com>
References: <111b2f270706110029g7fa6cf19pbc260a99ec581a26@mail.gmail.com>
Message-ID: <111b2f270706112013r7fc360dbmd804beec3bd96b5b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070612/752a96bd/attachment.pl 

From ramakanth_99 at yahoo.co.in  Tue Jun 12 06:09:48 2007
From: ramakanth_99 at yahoo.co.in (ramakanth reddy)
Date: Tue, 12 Jun 2007 09:39:48 +0530 (IST)
Subject: [R] question about data availale in .RData file using the biobase
	package
Message-ID: <595744.75948.qm@web7611.mail.in.yahoo.com>

Hi all

I am analyzing micro array data and I have R workspace images as my source of the data(.Rdata format).That was in the biobase package format,so I used some commands from the bio base package manual and could write the data into excel files.

The data I am working on is the cancer data.

I could get microarray information and recurrence information by using commands like

x<-pData(oncogene)

y<-exprs(oncogene)

I think the survival information should also be in the .RData file.How can i know what all information is available in the give file.

Please let me know any commands that show what type of information is available in the given file from a bio base package.


Thank You

rama kanth




      Download prohibited? No problem! To chat from any browser without download, Click Here: http://in.messenger.yahoo.com/webmessengerpromo.php


From jholtman at gmail.com  Tue Jun 12 06:11:18 2007
From: jholtman at gmail.com (jim holtman)
Date: Tue, 12 Jun 2007 00:11:18 -0400
Subject: [R] Textpad help
In-Reply-To: <111b2f270706112013r7fc360dbmd804beec3bd96b5b@mail.gmail.com>
References: <111b2f270706110029g7fa6cf19pbc260a99ec581a26@mail.gmail.com>
	<111b2f270706112013r7fc360dbmd804beec3bd96b5b@mail.gmail.com>
Message-ID: <644e1f320706112111w747e1f90s512ac086e23e7913@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070612/eb12eabd/attachment.pl 

From jholtman at gmail.com  Tue Jun 12 06:20:36 2007
From: jholtman at gmail.com (jim holtman)
Date: Tue, 12 Jun 2007 00:20:36 -0400
Subject: [R] Textpad help
In-Reply-To: <111b2f270706112013r7fc360dbmd804beec3bd96b5b@mail.gmail.com>
References: <111b2f270706110029g7fa6cf19pbc260a99ec581a26@mail.gmail.com>
	<111b2f270706112013r7fc360dbmd804beec3bd96b5b@mail.gmail.com>
Message-ID: <644e1f320706112120t74adbef5k63a5b9e2d533fe3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070612/2f2bc4e1/attachment.pl 

From ripley at stats.ox.ac.uk  Tue Jun 12 07:13:37 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 12 Jun 2007 06:13:37 +0100 (BST)
Subject: [R] Rounding?
In-Reply-To: <644e1f320706110431k51d69340k84b3c7d454e3d2c8@mail.gmail.com>
References: <40D3930AC1C8EA469E39536E5BC80835044EB390@EXDKBA021.corp.novocorp.net>
	<644e1f320706110431k51d69340k84b3c7d454e3d2c8@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0706111237360.4128@gannet.stats.ox.ac.uk>

On Mon, 11 Jun 2007, jim holtman wrote:

> your number 6.6500000000000001 is to large to fit in a floating point
> number.  It takes 56 bits and there are only 54 in a real number so the
> system see it as 6.65 and does the rounding to an even digit; 6.6

I'll take it you mean a IEC60559 double, which has 53 bits in its implied 
mantissa (it stores 52 and for normalized numbers the leading bit is 1 
and not stored).

> 6.650000000000001 does fit into a real number (takes 54 bits) and this will
> now round to 6.7

All you can say quickly is that its representation is greater than 
6.65:

> 6.650000000000001 - 6.65
[1] 8.881784e-16

But I don't think that is the explanation.  Remember that you are using 
binary arithmetic, so each of these numbers is stored with representation 
error.  As the exact number stored is not '6.65', round-to-even does not 
strictly apply.

I get

> formatC(6.65,format="f",digits=1)
[1] "6.7"
> print(6.65, digits=2)
[1] 6.7
> print(66.5, digits=1) # round to even really does apply
[1] 66
> print(67.5, digits=1)
[1] 68

on (several of) my non-Windows systems, so I think this is a Windows 
quirk.  Remember the parsing and printing software has also to run in 
binary on a limited-precision machine, and it does tend to be less 
accurate on Windows than on other ix86 OSes.  (Windows software also tends 
not to implement round-to-even rules.)


> On 6/11/07, BXC (Bendix Carstensen) <bxc at steno.dk> wrote:
>>
>> I was a bit puzzed by:
>>
>>> formatC(6.65,format="f",digits=1)
>> [1] "6.6"
>>
>> So I experimented and found:
>>
>>> formatC(6.6500000000000001,format="f",digits=1)
>> [1] "6.6"
>>> formatC(6.650000000000001,format="f",digits=1)
>> [1] "6.7"
>>>   round(6.6500000000000001,1)
>> [1] 6.7
>>>   round(6.650000000000001,1)
>> [1] 6.7
>>> version
>>               _
>> platform       i386-pc-mingw32
>> arch           i386
>> os             mingw32
>> system         i386, mingw32
>> status
>> major          2
>> minor          5.0
>> year           2007
>> month          04
>> day            23
>> svn rev        41293
>> language       R
>> version.string R version 2.5.0 (2007-04-23)
>>
>> My machine runs Windows NT.
>>
>> Is this intended or just a Windows facility?
>> ______________________________________________
>>
>> Bendix Carstensen
>> Senior Statistician
>>
>> Steno Diabetes Center
>> Niels Steensens Vej 2-4
>> DK-2820 Gentofte
>> Denmark
>> +45 44 43 87 38 (direct)
>> +45 30 75 87 38 (mobile)
>> +45 44 43 73 13 (fax)
>> bxc at steno.dk   http://www.biostat.ku.dk/~bxc
>>
>> This e-mail (including any attachments) is intended for the ...{{dropped}}
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From carmei3 at web.de  Tue Jun 12 08:43:35 2007
From: carmei3 at web.de (Carmen Meier)
Date: Tue, 12 Jun 2007 08:43:35 +0200
Subject: [R] p-value from GEE why factor 2*pnorm?
In-Reply-To: <D1751D61-8F22-4B68-A598-3F6CE4E93F53@jhsph.edu>
References: <E1Hvs4m-0000hS-HM@www19.emo.freenet-rz.de>	<466D6870.1060005@web.de>	<651DAEB4-431D-4FF5-A98C-D33009AB4CE1@jhsph.edu>	<466D6B68.2050602@web.de>
	<D1751D61-8F22-4B68-A598-3F6CE4E93F53@jhsph.edu>
Message-ID: <466E4097.7050705@web.de>

Benilton Carvalho schrieb:
> Well, AFAIK, the definition of a p-value is the probability of  
> observing something at least as extreme as the observed data.
>
> If you observed z, and Z follows a std-normal
>
> p-value = P( Z < -abs(z) ) + P( Z > abs(z) )
>    = 2*P ( Z > abs(z) )
>    = 2*pnorm(z, lower.tail=FALSE)
>
> try z=0 (you should get 1) and z=1.96 (you should get 5%)
>
>   

Hi Benilton,
thank you for your explanations.
I seems that the unexpected Data are a result of misunderstanding the 
arguments of the GEE like |corstr, family or for using the GEE itself.
This is a major problem and I must look for any kind of support for the GEE.

Thanks Carmen
|


From maechler at stat.math.ethz.ch  Tue Jun 12 09:16:01 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 12 Jun 2007 09:16:01 +0200
Subject: [R] Package update announcements
In-Reply-To: <3EDD07F1-6808-4144-8BD1-EB4478C63574@muohio.edu>
References: <3EDD07F1-6808-4144-8BD1-EB4478C63574@muohio.edu>
Message-ID: <18030.18481.699878.58839@stat.math.ethz.ch>

>>>>> "MHHS" == Martin Henry H Stevens <hstevens at muohio.edu>
>>>>>     on Mon, 11 Jun 2007 17:23:46 -0400 writes:

    MHHS> Hi Folks, I was wondering what everyone thought about
    MHHS> adding a sentence to each package update announcement
    MHHS> that described what the package did. R extensions are
    MHHS> so numerous that it is difficult to keep up with them.
    MHHS> Would it be appropriate to ask package developers to
    MHHS> add a brief sentence about what the package does, when
    MHHS> they announce updates?

Thanks a lot, Hank!

I've been supporting your suggestion ever since I had created
'R-packages' ( = "R package announcements mailing list").

As moderator, I even occasionally rejected postings to
R-packages exactly by requiring such short information preceding
any notice of changes.

I think that >99% of the package authors would also agree, but
then we are all humans and hence sometimes get into peculiar
world views such as "there's my package, and there's R and then
rest of the universe" ;-)

Martin Maechler, ETH Zurich

    MHHS> I would benefit from such descriptions.

    MHHS> Cheers, Hank

    MHHS> Dr. Hank Stevens, Assistant Professor 338 Pearson Hall
    MHHS> Botany Department Miami University Oxford, OH 45056

    MHHS> Office: (513) 529-4206 Lab: (513) 529-4262 FAX: (513)
    MHHS> 529-4243 http://www.cas.muohio.edu/~stevenmh/
    MHHS> http://www.muohio.edu/ecology/
    MHHS> http://www.muohio.edu/botany/

    MHHS> "E Pluribus Unum"

    MHHS> ______________________________________________
    MHHS> R-help at stat.math.ethz.ch mailing list
    MHHS> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do
    MHHS> read the posting guide
    MHHS> http://www.R-project.org/posting-guide.html and
    MHHS> provide commented, minimal, self-contained,
    MHHS> reproducible code.


From tsang0323 at hotmail.com  Tue Jun 12 09:45:52 2007
From: tsang0323 at hotmail.com (Charlie Chi)
Date: Tue, 12 Jun 2007 07:45:52 +0000
Subject: [R] Data transformation for chi-square test.
Message-ID: <BAY144-F30F880C1D577C8564FB8C0A2190@phx.gbl>

Dear all R users
:
I am a IT student with few statistical background and new R user for only 
have  two month exprience. I have a data named medcost, import by 
read.table() as follow for example (real dataset has 500 cases), the 
heander id means case id, member means members in a family and cost is the 
family pay for medical cost every 6 months.

id        member               cost
1         4                          320
2         2                          150
3         3                          420
4         5                          330
5         6                          540
6         2                          310
7         4                          169
8         6                          647
9         3                          347
10       4                          567

I would like to use this dataset with chi-sqare analysis to see if there is 
any realationship between family member and medical cost (more members in a 
family will rise their medical cost?) I have found the pacage called stats, 
but I think need to transform the dataset into a contingency table as I 
read from books. I am not sure if I correct, I think the table should looks 
like:
                      member
cost                [2]      [3]     [4]     [5]     [6]     Total
[0,100]           1         0        0        0       0          1
[100,200]       0         0        1        0       0          1
[200,300]       0         0        0        0       0          0
[300,400]       1         1        1        1       0          4
[400,500]       0         1        0        0       0          1
[500,600]       0         0        1        0       1          2
[600,700]       0         0        0        0       1          1
Total              2          2       3         1       2         10

I did try to use the method in chapter 5.0 of "R Introduction" to create 
freqency table, but it did not work. I am wondering if any one can help me 
with it? Thank you for your help.

Regards

Charlie
.


From wl2776 at gmail.com  Tue Jun 12 10:03:23 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Tue, 12 Jun 2007 01:03:23 -0700 (PDT)
Subject: [R] selecting characters from a line of text
In-Reply-To: <1dba89130706111355g5b019722j8d0e1bd054d9b098@mail.gmail.com>
References: <1dba89130706111355g5b019722j8d0e1bd054d9b098@mail.gmail.com>
Message-ID: <11074650.post@talk.nabble.com>



Tim Holland wrote:
> 
> Is there a way in R to select certain characters from a line of text?  I
> have some data that is presently in a large number of text files, and I
> would like to be able to select elements of each text file (elements are
> always on the same line, in the same position) and organize them into a
> table.  Is there a tool to select text in this way in R?  
> 

Use substr() or substring() to select characters from a a text string, 
nchar() will give you its length,
scan() can also help in reading data from text files,
grep() can be used for search and selecting character strings in an array,
having certain patterns.

If your files are formatted in some way, consider read.table(), read.csv(),
read.fwf() and friends.

You should also read the "Data import/export" manual from the R
documentation.
Its pdf version was, probably, installed on your hard drive with R, and html
is here: 
http://cran.r-project.org/doc/manuals/R-data.html
pdf version is also here:
http://cran.r-project.org/doc/manuals/R-data.pdf
-- 
View this message in context: http://www.nabble.com/selecting-characters-from-a-line-of-text-tf3904063.html#a11074650
Sent from the R help mailing list archive at Nabble.com.


From res90sx5 at verizon.net  Tue Jun 12 10:06:19 2007
From: res90sx5 at verizon.net (Daniel Nordlund)
Date: Tue, 12 Jun 2007 01:06:19 -0700
Subject: [R] Textpad help
In-Reply-To: <111b2f270706112013r7fc360dbmd804beec3bd96b5b@mail.gmail.com>
Message-ID: <008001c7acc8$8f321810$0201a8c0@Aragorn>

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch]
> On Behalf Of Mary Royerr
> Sent: Monday, June 11, 2007 8:14 PM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] Textpad help
> 
> Thx for the response John and Jim.
> 
> I had heard before that textpad is a good editor for R codes and one can run
> the R code from textpad itself and once we do that, the output is displayed
> on the textpad itself. The reason I wanted to use textpad is to make use of
> the syntax highlighting a la SAS.
> 
> So I installed textpad and according to the instructions given in
> http://www.data-for-all.com/blog/?p=68  .  everything worked out fine until
> I ran the following test code:
> 
> 
> *setwd('C:/Temp/SampleR')
> #
> N<-250
> x<-1:N
> y<-0.53*x +rnorm(x, 0.42*N, 0.14*N)
> model1<-lm(y~x)
> print(summary(model1)) *
> 
> Once I submitted the R code using the SUBMIT R FILE in TOOLS from the
> toolbar menu the following message displayed.
> 
> 
> The filename, directory name, or volume label syntax is incorrect.
> 
> Tool completed with exit code 1
> 
> 
> 
> Now even If I run a simple code like *a<-10;a* still the same message is
> displayed.
> 
> 
> 
> I am kind of sure it is nothing wrong with the code but something is wrong
> with the way the textpad installation. Any help? I am not a techie person.
> 
> Thx for your help
> 
> On 6/11/07, Mary Royerr <mroyerr at gmail.com> wrote:
> >
> > I have installed textpad and tried running R code. But it gives me the
> > following error message.
> >
> >
> >
> > The filename, directory name, or volume label syntax is incorrect.
> >
> > Tool completed with exit code 1
> >

Mary,

I use Textpad to run both SAS code and R code in batch mode without problems.  I looked at the instructions that you referenced and noticed a couple of potential problems with the instructions.  I was able to correct the set-up and successfully run the sample program from the web site.  However, I use a different set up because I prefer to send output to a file that I can then open in another Textpad window, rather than "capturing" the output.  Since this is not an R problem, if you contact me off-list I would be happy to give you detailed instructions on how to set up Textpad running R code in batch mode.

Dan

Daniel Nordlund
Bothell, WA USA


From jari.oksanen at oulu.fi  Tue Jun 12 10:08:34 2007
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Tue, 12 Jun 2007 08:08:34 +0000 (UTC)
Subject: [R] Error using mgcv package
References: <11058255.post@talk.nabble.com>
Message-ID: <loom.20070612T100215-99@post.gmane.org>

spime <sabya23 <at> gmail.com> writes:

> 
> 
> Hi all,
> 
> I need some solution in the following problem. The following error appears
> when i use "mgcv" package for implementing GAM. But the same formula works
> fine in "gam" package.
> 
> > model.gam <- gam(formula = RES ~
> > CAT01+s(NUM01,5)+CAT02+CAT03+s(NUM02,5)+CAT04+
> + CAT05+s(NUM03,5)+CAT06+CAT07+s(NUM04,5)+CAT08+s(NUM05,5)+CAT09+
> + CAT10+s(NUM06,5)+CAT11+NUM07+CAT12+CAT13,
> + family = binomial(link = logit), data = train.data,na.action = na.exclude,
> + control = list(epsilon = 0.001,bf.epsilon = 0.001, maxit = 50, 
> + bf.maxit = 10, trace = F))
> 
> Error in terms.formula(reformulate(term[i])) : 
>         invalid model formula in ExtractVars
> 
It seems that nobody answered this (in public). 

It seems that function s() in mgcv is defined as:

s(..., k = -1, fx = FALSE, bs = "tp", m = 0, by = NA) 

(Like you see reading its help ?s). The function definition starts with "...",
and after three dots you cannot use positional arguments, but you must give the
full argument name. Try replacing s(NUM01, 5) with s(NUM01, k=5). See also help
in mgcv (?s pointing to ?choose.k) for interpreting argument 'k' which is not
directly degrees of freedom.

There may be other problems, but this probably fixes tha one you reported above.

cheers, jari oksanen

> And after deleting df's 
> 
> model.gam <- gam(formula = RES ~ CAT01+s(NUM01)+CAT02+CAT03+s(NUM02)+CAT04+
> + CAT05+s(NUM03)+CAT06+CAT07+s(NUM04)+CAT08+s(NUM05)+CAT09+
> + CAT10+s(NUM06)+CAT11+NUM07+CAT12+CAT13,
> + family = binomial(link = logit), data = train.data)
> 
> Error in smooth.construct.tp.smooth.spec(object, data, knots) : 
>         A term has fewer unique covariate combinations than specified
> maximum degrees of freedom
> 
> Can anybody show me some light in this case!!!
> 
> Thanks in advance.


From christophe at pallier.org  Tue Jun 12 10:09:47 2007
From: christophe at pallier.org (Christophe Pallier)
Date: Tue, 12 Jun 2007 10:09:47 +0200
Subject: [R] Data transformation for chi-square test.
In-Reply-To: <BAY144-F30F880C1D577C8564FB8C0A2190@phx.gbl>
References: <BAY144-F30F880C1D577C8564FB8C0A2190@phx.gbl>
Message-ID: <dea6cb960706120109g4b65e28kf316b051d44e2ecd@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070612/56720b4f/attachment.pl 

From buser at stat.math.ethz.ch  Tue Jun 12 10:26:28 2007
From: buser at stat.math.ethz.ch (Christoph Buser)
Date: Tue, 12 Jun 2007 10:26:28 +0200
Subject: [R] Data transformation for chi-square test.
In-Reply-To: <BAY144-F30F880C1D577C8564FB8C0A2190@phx.gbl>
References: <BAY144-F30F880C1D577C8564FB8C0A2190@phx.gbl>
Message-ID: <18030.22708.701923.890984@stat.math.ethz.ch>

Dear Charlie

dat <- data.frame(id = 1:10, member = c(4,2,3,5,6,2,4,6,3,4),
                  cost = c(320,150,420,330,540,310,169,647,347,567))  

dat[,"costF"] <- cut(dat[,"cost"], breaks = seq(100, 700, by=100))
table(dat[,"costF"], dat[,"member"])

This should create the table you like.

Best regards,

Christoph

--------------------------------------------------------------

Credit and Surety PML study: visit our web page www.cs-pml.org

--------------------------------------------------------------
Christoph Buser <buser at stat.math.ethz.ch>
Seminar fuer Statistik, LEO C13
ETH Zurich	8092 Zurich	 SWITZERLAND
phone: x-41-44-632-4673		fax: 632-1228
http://stat.ethz.ch/~buser/
--------------------------------------------------------------

Charlie Chi writes:
 > Dear all R users
 > :
 > I am a IT student with few statistical background and new R user for only 
 > have  two month exprience. I have a data named medcost, import by 
 > read.table() as follow for example (real dataset has 500 cases), the 
 > heander id means case id, member means members in a family and cost is the 
 > family pay for medical cost every 6 months.
 > 
 > id        member               cost
 > 1         4                          320
 > 2         2                          150
 > 3         3                          420
 > 4         5                          330
 > 5         6                          540
 > 6         2                          310
 > 7         4                          169
 > 8         6                          647
 > 9         3                          347
 > 10       4                          567
 > 
 > I would like to use this dataset with chi-sqare analysis to see if there is 
 > any realationship between family member and medical cost (more members in a 
 > family will rise their medical cost?) I have found the pacage called stats, 
 > but I think need to transform the dataset into a contingency table as I 
 > read from books. I am not sure if I correct, I think the table should looks 
 > like:
 >                       member
 > cost                [2]      [3]     [4]     [5]     [6]     Total
 > [0,100]           1         0        0        0       0          1
 > [100,200]       0         0        1        0       0          1
 > [200,300]       0         0        0        0       0          0
 > [300,400]       1         1        1        1       0          4
 > [400,500]       0         1        0        0       0          1
 > [500,600]       0         0        1        0       1          2
 > [600,700]       0         0        0        0       1          1
 > Total              2          2       3         1       2         10
 > 
 > I did try to use the method in chapter 5.0 of "R Introduction" to create 
 > freqency table, but it did not work. I am wondering if any one can help me 
 > with it? Thank you for your help.
 > 
 > Regards
 > 
 > Charlie
 > ..
 > 
 > ______________________________________________
 > R-help at stat.math.ethz.ch mailing list
 > https://stat.ethz.ch/mailman/listinfo/r-help
 > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
 > and provide commented, minimal, self-contained, reproducible code.


From verrel at mpib-berlin.mpg.de  Tue Jun 12 10:57:15 2007
From: verrel at mpib-berlin.mpg.de (Julius Verrel)
Date: Tue, 12 Jun 2007 10:57:15 +0200
Subject: [R] Post-hoc tests for interactions of between- and within-subject
 factors
Message-ID: <C2942C8B.F1E%verrel@mpib-berlin.mpg.de>

Is there a standardized way in R to perform post-hoc comparisons for main
adn interaction effects of between- and within-subject factors?

For instance, I have a data set of performance of adults of different age
groups (20-30, 60-70,70-80) performing a WM task (n-back, with n=1,2,3,4) in
two different conditions (while sitting or walking). The corresponding ANOVA
produces the following output



> gm = aov(cog ~ agegp*nback*cond+Error(id/(cond*nback)),data = g);
> summary(gm)

Error: id
      Df Sum Sq Mean Sq
agegp  1 7.0268  7.0268

Error: id:cond
     Df Sum Sq Mean Sq
cond  1 5.1788  5.1788

Error: id:nback
      Df Sum Sq Mean Sq
nback  2 586.88  293.44

Error: id:cond:nback
           Df Sum Sq Mean Sq
nback:cond  2 2.8901  1.4451

Error: Within
                  Df Sum Sq Mean Sq F value    Pr(>F)
agegp              2 139.29   69.64 45.4349 < 2.2e-16 ***
nback              2 145.40   72.70 47.4288 < 2.2e-16 ***
cond               1   0.38    0.38  0.2495 0.6176019
agegp:nback        4  30.32    7.58  4.9448 0.0006367 ***
agegp:cond         2   1.44    0.72  0.4698 0.6254042
nback:cond         2   0.25    0.12  0.0815 0.9217123
agegp:nback:cond   4   2.22    0.56  0.3621 0.8356007
Residuals        546 836.92    1.53
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
 
 


TukeyHSD does not seem to work for within-person factors. Any suggestions
how to perform post-hoc comparions?

Thanks in advance, 
      Julius



-- 

Julius Verrel (PhD student)
MPI for Human Development
Lentzeallee 94
D-14195 Berlin
+49 30 82406-410


From berwin at maths.uwa.edu.au  Tue Jun 12 11:18:13 2007
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Tue, 12 Jun 2007 17:18:13 +0800
Subject: [R] [ANN] Static and dynamic graphics course, July 2007,
 Salt Lake City
In-Reply-To: <f8e6ff050705300157s1f4a73c4rc8d8731a361ffc3b@mail.gmail.com>
References: <f8e6ff050705300157s1f4a73c4rc8d8731a361ffc3b@mail.gmail.com>
Message-ID: <20070612171813.43644cf4@bossiaea>

G'day Hadley,

On Wed, 30 May 2007 10:57:54 +0200
"hadley wickham" <h.wickham at gmail.com> wrote:

> We're pleased to announce a one day course covering static and dynamic
> graphics using R, ggplot and GGobi. The course will be held just
> before the JSM, on Saturday, 28 July 2007, in Salt Lake City. The
> course will be presented by Dianne Cook and Hadley Wickham.

Where exactly is the course held?  I guess Salt Lake City is big, so is
it close to the place where the JSM is held or at the other end of
town?  I am considering of coming a day early and to attend the course.

Thanks for your help.

Cheers,

	Berwin

=========================== Full address =============================
Berwin A Turlach                            Tel.: +65 6515 4416 (secr)        
Dept of Statistics and Applied Probability        +65 6515 6650 (self)        
Faculty of Science                          FAX : +65 6872 3919               
National University of Singapore     
6 Science Drive 2, Blk S16, Level 7          e-mail: statba at nus.edu.sg
Singapore 117546                    http://www.stat.nus.edu.sg/~statba


From sabya23 at gmail.com  Tue Jun 12 11:25:30 2007
From: sabya23 at gmail.com (spime)
Date: Tue, 12 Jun 2007 02:25:30 -0700 (PDT)
Subject: [R] Error using mgcv package
In-Reply-To: <loom.20070612T100215-99@post.gmane.org>
References: <11058255.post@talk.nabble.com>
	<loom.20070612T100215-99@post.gmane.org>
Message-ID: <11075667.post@talk.nabble.com>


Dear Mr. Oksanen,

First of all thanks for your reply. I have solved this problem in this way.
My data consists of some categorical(CAT..) predictors and also some
numerical variables(NUM..) have only {0,1} 0r {0,1,2,3} values. For applying
GAM i just didnot consider their splines. I had came to this decision
because when i tested the same data on S-PLUS, i got an error regarding the
applicability of s(...) function on the predictors less than 4 different
values. I dont know whether gam() of S-PLUS and gam() of mgcv(R) are same or
not. anyway, thanks for your kind reply.

bye


Jari Oksanen wrote:
> 
> spime <sabya23 <at> gmail.com> writes:
> 
>> 
>> 
>> Hi all,
>> 
>> I need some solution in the following problem. The following error
>> appears
>> when i use "mgcv" package for implementing GAM. But the same formula
>> works
>> fine in "gam" package.
>> 
>> > model.gam <- gam(formula = RES ~
>> > CAT01+s(NUM01,5)+CAT02+CAT03+s(NUM02,5)+CAT04+
>> + CAT05+s(NUM03,5)+CAT06+CAT07+s(NUM04,5)+CAT08+s(NUM05,5)+CAT09+
>> + CAT10+s(NUM06,5)+CAT11+NUM07+CAT12+CAT13,
>> + family = binomial(link = logit), data = train.data,na.action =
>> na.exclude,
>> + control = list(epsilon = 0.001,bf.epsilon = 0.001, maxit = 50, 
>> + bf.maxit = 10, trace = F))
>> 
>> Error in terms.formula(reformulate(term[i])) : 
>>         invalid model formula in ExtractVars
>> 
> It seems that nobody answered this (in public). 
> 
> It seems that function s() in mgcv is defined as:
> 
> s(..., k = -1, fx = FALSE, bs = "tp", m = 0, by = NA) 
> 
> (Like you see reading its help ?s). The function definition starts with
> "...",
> and after three dots you cannot use positional arguments, but you must
> give the
> full argument name. Try replacing s(NUM01, 5) with s(NUM01, k=5). See also
> help
> in mgcv (?s pointing to ?choose.k) for interpreting argument 'k' which is
> not
> directly degrees of freedom.
> 
> There may be other problems, but this probably fixes tha one you reported
> above.
> 
> cheers, jari oksanen
> 
>> And after deleting df's 
>> 
>> model.gam <- gam(formula = RES ~
>> CAT01+s(NUM01)+CAT02+CAT03+s(NUM02)+CAT04+
>> + CAT05+s(NUM03)+CAT06+CAT07+s(NUM04)+CAT08+s(NUM05)+CAT09+
>> + CAT10+s(NUM06)+CAT11+NUM07+CAT12+CAT13,
>> + family = binomial(link = logit), data = train.data)
>> 
>> Error in smooth.construct.tp.smooth.spec(object, data, knots) : 
>>         A term has fewer unique covariate combinations than specified
>> maximum degrees of freedom
>> 
>> Can anybody show me some light in this case!!!
>> 
>> Thanks in advance.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/Error-using-mgcv-package-tf3900783.html#a11075667
Sent from the R help mailing list archive at Nabble.com.


From luc.jouneau at jouy.inra.fr  Tue Jun 12 11:32:07 2007
From: luc.jouneau at jouy.inra.fr (luc.jouneau)
Date: Tue, 12 Jun 2007 11:32:07 +0200
Subject: [R] bitmap function in R 2.4.1 vs R 2.2.1
Message-ID: <1181640727.466e681756b1b@www.jouy.inra.fr>

Hello,

I work under windows with two versions of R : 2.4.1 and 2.2.1
Ghostscript tool is also installed (gswin32c Version 8.54).

I have a small sample program:
> bitmap("a.bmp")
> m=(1)
> plot(m)
> dev.off()

With R 2.2.1, it works well, but with R 2.4.1 it fails when gswin32c is launched
with following error:
Error: /undefined in WinAnsiEncoding

The difference between the two temporary files produced by the two versions of R
before to launch gswin32c, is that in file produced by R 2.4.1, a part of the
postscript command are surrounded by following lines:
/WinAnsiEncoding [
...some poscript commands...
]

It seems gswin32c does not understand this "/WinAnsiEncoding [" line.
As I am not even a newbye in postscript maybe this line is correct, and there is
a bug in gswin32c, but I would like to ask if some R people already encountered
this problem and how did they manage to solve it.

Many thanks to any contribution

Luc Jouneau


From maja.schroeter at gmx.de  Tue Jun 12 12:43:58 2007
From: maja.schroeter at gmx.de (=?iso-8859-1?Q?=22Maja_Schr=F6ter=22?=)
Date: Tue, 12 Jun 2007 12:43:58 +0200
Subject: [R]  Problems with Vista, R 2.5.0 and function save
Message-ID: <20070612104358.318800@gmx.net>

Hi everyone,

I want to make use of the save function but it did not work.

I'm using vista and R 2.5.0, winzip is installed too.

Here's the code (from example ?save): 

  > x <- runif(20)
  > y <- list(a = 1, b = TRUE, c = "oops")
  > save(x, y, file = "xy.Rdata")
   Fehler in gzfile(file, "wb") : kann Verbindung nicht ?ffnen
    Zus?tzlich: Warning message:
    kann komprimierte Datei 'xy.Rdata' nicht ?ffnen 

Thank you so much for your help.

Background: I want to crate a variable "masterfile" that I can start with data(masterfile) or attach(masterfile).

I.g. 

Town<-c("London","Miami","Rio","Lansing")
Pollution<-c("34","32","50","17")
masterfile<-data.frame(Town,Pollution)
save(masterfile,file="masterfile.Rda")


Kindly regards,

Maja Schr?ter
-- 
Psssst! Schon vom neuen GMX MultiMessenger geh?rt?
Der kanns mit allen: http://www.gmx.net/de/go/multimessenger


From jrkrideau at yahoo.ca  Tue Jun 12 12:48:58 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Tue, 12 Jun 2007 06:48:58 -0400 (EDT)
Subject: [R] Lines in dotchart & dotplot ?
In-Reply-To: <eb555e660706111250r7588f881i261ad10fdc814d33@mail.gmail.com>
Message-ID: <593839.24782.qm@web32813.mail.mud.yahoo.com>

Thanks again.  Both layouts look very usefull and
certainly a lot better than I was getting on my own.  


--- Deepayan Sarkar <deepayan.sarkar at gmail.com> wrote:

> On 6/11/07, John Kane <jrkrideau at yahoo.ca> wrote:
> >
> > --- deepayan.sarkar at gmail.com wrote:
> >
> > > On 6/9/07, John Kane <jrkrideau at yahoo.ca> wrote:
> > > > Is it possible to use dotchart or dotplot and
> set
> > > the
> > > > lines in such a way that they only extend from
> the
> > > > left y-axis to the data point?
> > >
> > > Yes (sort of) in dotplot at least. E.g.,
> > >
> > > dotplot(VADeaths, groups = FALSE, type = c("p",
> > > "h"))
> > > dotplot(VADeaths, groups = FALSE, type = c("p",
> > > "h"), origin = 0)
> > >
> > > -Deepayan
> > >
> >
> > Ah, that is quite nice, not exactly what I
> remember
> > from Cleveland but it should do quite nicely.
> 
> You can do that too if you really want to:
> 
> dotplot(VADeaths, groups = FALSE, type = c("p",
> "h"), origin = 0,
>         panel = panel.xyplot, pch = 16, lty = 3, col
> = "black")
> 
> -Deepayan


From christoph.bischoff at statistik.ji.zh.ch  Tue Jun 12 10:26:11 2007
From: christoph.bischoff at statistik.ji.zh.ch (christoph.bischoff at statistik.ji.zh.ch)
Date: Tue, 12 Jun 2007 10:26:11 +0200
Subject: [R] hedonic
Message-ID: <OF93E8CE82.F38C0911-ONC12572F8.002D80C1-C12572F8.002E7B1C@ji.zh.ch>

Ein eingebundener Text mit undefiniertem Zeichensatz wurde abgetrennt.
Name: nicht verf?gbar
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20070612/d0d501fb/attachment.pl 

From ripley at stats.ox.ac.uk  Tue Jun 12 13:48:45 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 12 Jun 2007 12:48:45 +0100 (BST)
Subject: [R] Problems with Vista, R 2.5.0 and function save
In-Reply-To: <20070612104358.318800@gmx.net>
References: <20070612104358.318800@gmx.net>
Message-ID: <Pine.LNX.4.64.0706121247060.15600@auk.stats>

So you are running R somewhere in your file system where you do not have 
permission to write.

Did you create a shortcut with a working directory set as the rw-FAQ 
advised you to?

On Tue, 12 Jun 2007, "Maja Schr?ter" wrote:

> Hi everyone,
>
> I want to make use of the save function but it did not work.
>
> I'm using vista and R 2.5.0, winzip is installed too.
>
> Here's the code (from example ?save):
>
>  > x <- runif(20)
>  > y <- list(a = 1, b = TRUE, c = "oops")
>  > save(x, y, file = "xy.Rdata")
>   Fehler in gzfile(file, "wb") : kann Verbindung nicht ?ffnen
>    Zus?tzlich: Warning message:
>    kann komprimierte Datei 'xy.Rdata' nicht ?ffnen
>
> Thank you so much for your help.
>
> Background: I want to crate a variable "masterfile" that I can start with data(masterfile) or attach(masterfile).
>
> I.g.
>
> Town<-c("London","Miami","Rio","Lansing")
> Pollution<-c("34","32","50","17")
> masterfile<-data.frame(Town,Pollution)
> save(masterfile,file="masterfile.Rda")
>
>
> Kindly regards,
>
> Maja Schr?ter
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From stevenmh at muohio.edu  Tue Jun 12 13:59:22 2007
From: stevenmh at muohio.edu (Martin Henry H. Stevens)
Date: Tue, 12 Jun 2007 07:59:22 -0400
Subject: [R] Package update announcements
In-Reply-To: <18030.18481.699878.58839@stat.math.ethz.ch>
References: <3EDD07F1-6808-4144-8BD1-EB4478C63574@muohio.edu>
	<18030.18481.699878.58839@stat.math.ethz.ch>
Message-ID: <612FEED3-40D4-4B5B-8E34-2920A0D5D4AA@muohio.edu>

Hi Martin,
Maybe we should appeal to each others' vanity ("Just think how many  
hundreds---even thousands---of people will use your package once they  
know about it....") Hmmm. Maybe that would have the opposite of the  
intended effect.
Cheers,
Hank
On Jun 12, 2007, at 3:16 AM, Martin Maechler wrote:

>>>>>> "MHHS" == Martin Henry H Stevens <hstevens at muohio.edu>
>>>>>>     on Mon, 11 Jun 2007 17:23:46 -0400 writes:
>
>     MHHS> Hi Folks, I was wondering what everyone thought about
>     MHHS> adding a sentence to each package update announcement
>     MHHS> that described what the package did. R extensions are
>     MHHS> so numerous that it is difficult to keep up with them.
>     MHHS> Would it be appropriate to ask package developers to
>     MHHS> add a brief sentence about what the package does, when
>     MHHS> they announce updates?
>
> Thanks a lot, Hank!
>
> I've been supporting your suggestion ever since I had created
> 'R-packages' ( = "R package announcements mailing list").
>
> As moderator, I even occasionally rejected postings to
> R-packages exactly by requiring such short information preceding
> any notice of changes.
>
> I think that >99% of the package authors would also agree, but
> then we are all humans and hence sometimes get into peculiar
> world views such as "there's my package, and there's R and then
> rest of the universe" ;-)
>
> Martin Maechler, ETH Zurich
>
>     MHHS> I would benefit from such descriptions.
>
>     MHHS> Cheers, Hank
>
>     MHHS> Dr. Hank Stevens, Assistant Professor 338 Pearson Hall
>     MHHS> Botany Department Miami University Oxford, OH 45056
>
>     MHHS> Office: (513) 529-4206 Lab: (513) 529-4262 FAX: (513)
>     MHHS> 529-4243 http://www.cas.muohio.edu/~stevenmh/
>     MHHS> http://www.muohio.edu/ecology/
>     MHHS> http://www.muohio.edu/botany/
>
>     MHHS> "E Pluribus Unum"
>
>     MHHS> ______________________________________________
>     MHHS> R-help at stat.math.ethz.ch mailing list
>     MHHS> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do
>     MHHS> read the posting guide
>     MHHS> http://www.R-project.org/posting-guide.html and
>     MHHS> provide commented, minimal, self-contained,
>     MHHS> reproducible code.


From tore.wentzel-larsen at helse-bergen.no  Tue Jun 12 15:10:20 2007
From: tore.wentzel-larsen at helse-bergen.no (Wentzel-Larsen, Tore)
Date: Tue, 12 Jun 2007 15:10:20 +0200
Subject: [R] distribution graph
Message-ID: <7132663E78AE3E45AD4471CBC2738EF501648C9E@EC3.ihelse.net>

The following gives two functions for producing distribution graphs:

distribution-graph

produces a single graph, and

multiple.distribution.graph

produces a number of graphs side by side.

Regards,
Tore Wentzel-Larsen
statistician
Centre for Clinical research
Armauer Hansen house 
Haukeland University Hospital
N-5021 Bergen
tlf   +47 55 97 55 39 (a)
faks  +47 55 97 60 88 (a)
email tore.wentzel-larsen at helse-bergen.no 


Documentation:

distribution.graph

Description

distribution.graph produces a distribution graph of the data values. 

Usage

distribution.graph(xx, grouping=FALSE,
	ngroups=10, xplace=c(0,1,.5),  halfband=.25,
	xlab='', ylab='', pch=16,
	lines=FALSE, lty='solid')

Arguments

xx		numeric, a vector of values for which to produce the 
		distribution graph. Missing values are allowed, and are 
		disregarded.

grouping	logical, if FALSE (the default) the actual values are graphed,
		if TRUE the values are grouped before being plotted.

ngroups	the number of groups (default 10) if grouping=TRUE.

xplace	vector with three components. The first two components define
		the horizontal plotting range. The last component defines the
		horizontal placement of the centre of the distribution graph.

halfband	Half-length of the maximal horizontal band in the distribution
		Graph, from the centre outwards. The bands should be within the 
		Horizontal plotting range.

xlab, 
ylab		x and y axis labels, as in plot.default.

pch		plotting symbol, default 16 (solid circle).

lines		logical, if FALSE (the default) only points are plotted, if
		TRUE the points are connected by lines.

lty		line type, as in plot.default.


Value

A frequency table for the values actually plotted.

Examples

# a simple distribution graph with no grouping:
distribution.graph(floor(runif(100, 200, 310)))

# a similar graph with vertical bars only:
distribution.graph(floor(runif(100, 200, 310)), lines=TRUE, pch='')

# a distribution graph with grouping (points or line bars):
distribution.graph(runif(1000 ,0, 3), grouping=TRUE)
distribution.graph(runif(1000, 0, 3), grouping=TRUE, lines=TRUE, pch='')

# a distribution graph with grouping, 5 groups:
distribution.graph(runif(1000, 0, 10), grouping=TRUE, ngroups=5)
distribution.graph(rbinom(1000, 20, .7), grouping=TRUE, ngroups=5)


- - - - - - - - - - - - - - -

multiple.distribution.graph

Description

multiple.distribution.graph produces a number of distribution graphs of the data values, side by side. 

Usage

multiple.distribution.graph(xx, grouping=FALSE,
	ngroups=10, xleft=0, xright=1, xmiddle=.5, xband=.5,
	xlab=c(1:length(xx)), ylab='', pch=16,
	lines=FALSE, lty='solid')
Arguments

xx		list of numeric variables, a vector of values for which to produce the distribution 		graph. Missing values are allowed, and are disregarded.

grouping	logical, if FALSE (the default) the actual values are graphed,
		if TRUE the values are grouped before being plotted.

ngroups	the number of groups (default 10) if grouping=TRUE.

xleft
xright
xmiddle	xleft and xright define the horizontal plotting range within
		each distribution graph. xmiddle defines the horizontal placement of the centre of each 		distribution graph.

xband		the part actually used for plotting, of the horizontal range
		allocated top each individual graph.

xlab, 
ylab		x and y axis labels, as in plot.default.

pch		plotting symbol, default 16 (solid circle).

lines		logical, if FALSE (the default) only points are plotted, if
		TRUE the points are connected by lines.

lty		line type, as in plot.default.


Value

A list of frequency tables for the values actually plotted.


Examples

par(ask=TRUE)
multiple.distribution.graph(as.list(data.frame(matrix(runif(72),ncol=9))))
multiple.distribution.graph(as.list(data.frame(matrix(runif(72),ncol=9))),
	grouping=TRUE)
multiple.distribution.graph(as.list(data.frame(matrix(runif(72),ncol=9))),
	grouping=TRUE,ngroups=3)
multiple.distribution.graph(as.list(data.frame(matrix(runif(72),ncol=9))),
	grouping=TRUE,ngroups=3,lines=TRUE)
multiple.distribution.graph(as.list(data.frame(matrix(runif(72),ncol=9))),
	grouping=TRUE,ngroups=3,lines=TRUE,pch='')
multiple.distribution.graph(as.list(data.frame(matrix(runif(72),ncol=9))),
	grouping=TRUE,ngroups=5,lines=TRUE,pch='')
par(ask=FALSE)

# a more complicated list of numeric vectors:
xx <- as.list(as.list(data.frame(matrix(runif(72,10,45),ncol=9))))
xx[[1]][c(1,3,4,8)]<- NA
xx[[2]][c(2,4)]<- NA
xx[[4]][c(3)]<- NA
xx[[6]][c(2,5,8)]<- NA
xx[[8]][c(1,2,8)]<- NA
xx <- lapply(xx,stripmiss)
xx[[1]][c(3)]<- NA
xx[[3]][c(1,3,4,5)]<- NA
xx[[4]][c(2,3)]<- NA
xx[[8]][c(3,4)]<- NA

multiple.distribution.graph(xx)
multiple.distribution.graph(xx,grouping=TRUE,ngroups=3,lines=TRUE,
	pch='')
multiple.distribution.graph(xx,grouping=TRUE,ngroups=3,lines=TRUE,
	pch='.',lty='blank')






Code:
- - -

# auxiliary functions: stripmiss and grouping.v :

# function for deleting missing values from a vector:

stripmiss <- function(xx) xx[is.na(xx)==0]

# grouping of a vector into a specified number of
#	intervals of equal size:

grouping.v <- function(xx,ngroups=10,eps=.001) {
minx<- min(xx)
maxx <-max(xx)
if (minx == maxx | ngroups == 1) x2 <- xx
if(ngroups==1) x2 <- mean(x2)
if (minx < maxx & ngroups > 1) {
x1 <- round(.5+eps + (xx - minx)*(ngroups - 2*eps)/(maxx - minx))
x2 <- minx + (x1 - 1) * (maxx - minx)/(ngroups -1)
} # end if
x2
} # end function grouping.v (grouping of a vector)


# function for a single distribution graph:

distribution.graph <- function(xx, grouping=FALSE,
	ngroups=10, xplace=c(0,1,.5),  halfband=.25,
	xlab='', ylab='', pch=16,
	lines=FALSE, lty='solid') {
x1 <- stripmiss(xx)
if (grouping) x1 <- grouping.v(x1,ngroups=ngroups)
xv <- as.numeric(names(table(x1))) # actual values
minxv <-min(xv)
maxxv <-max(xv)
xn <- as.numeric(table(x1)) # number of occurences
nx <- length(xv)
maxn <- max(xn)
plot(x=xplace[1]+(xv-minxv)*(xplace[2]-xplace[1])/
	(maxxv-minxv),y=xv,xlab='',ylab='',
	axes=FALSE,col='white')
box()
axis(1,at=xplace[3],labels=xlab)
axis(2)
for (value.nr in 1:nx) {
n.act <- xn[value.nr]
if (n.act==1) xpositions.act <- xplace[3]
if (n.act > 1) {
halfband.act <- halfband * n.act/maxn
left.act  <- xplace[3] - halfband.act
right.act <- xplace[3] + halfband.act
xpositions.act <- left.act + (0:(n.act-1)) * 
	(right.act - left.act)/(n.act-1)
} # end if n.act > 1
if (!lines)
points(x=xpositions.act,y=rep(xv[value.nr],n.act),pch=pch)
if (lines)
points(x=xpositions.act,y=rep(xv[value.nr],n.act),
	pch=pch,type='o',lty=lty)
} # end for xvalue
distribution <- x1
table(distribution)
} # end function distribution.graph

par(ask=TRUE)
distribution.graph(floor(runif(100,200,310)))
distribution.graph(floor(runif(100,200,310)),lines=TRUE,pch='.')
distribution.graph(runif(1000,0,3),grouping=TRUE)
distribution.graph(runif(1000,0,3),grouping=TRUE,lines=TRUE,pch='')
distribution.graph(runif(1000,0,10),grouping=TRUE,ngroups=5)
distribution.graph(rbinom(1000,20,.7),grouping=TRUE,ngroups=5)
par(ask=FALSE)

# function for several distribution graphs in the same plot:

multiple.distribution.graph <- function(xx, grouping=FALSE,
	ngroups=10, xleft=0, xright=1, xmiddle=.5, xband=.5,
	xlab=c(1:length(xx)), ylab='', pch=16,
	lines=FALSE, lty='solid') {
xx <- lapply(xx,stripmiss) # remove missing values
if (grouping) xx <- lapply(xx,grouping.v,ngroups=ngroups)
xtable <- lapply(xx,table)
xtable.values <- lapply(lapply(xtable,names),as.numeric)
xtable.freq <- lapply(xtable,as.numeric)
max.freq <- max(as.numeric(lapply(xtable.freq,max)),na.rm=TRUE)
min.value <- min(as.numeric(lapply(xtable.values,min)),na.rm=TRUE)
max.value <- max(as.numeric(lapply(xtable.values,max)),na.rm=TRUE)
ncomp <- length(xx)
plot.xtotal<- xleft + c(0,ncomp) * (xright - xleft)
plot.ytotal<- c(min.value,max.value)
plot.mids <- xleft + c(0:(ncomp-1)) * (xright - xleft) + xmiddle
plot(x=plot.xtotal,y=plot.ytotal,xlab='',ylab=ylab,
	xlim=plot.xtotal,ylim=plot.ytotal,
	axes=FALSE,col='white')
box()
axis(1,at=plot.mids,labels=xlab)
axis(2)
for (comp in 1:ncomp) {
left.outer <- xleft + (comp - 1) * (xright - xleft)
right.outer <- xleft + comp * (xright - xleft)
mid <- plot.mids[comp]
max.freq.comp <- max(xtable.freq[[comp]],na.rm=TRUE)
values.comp <- xtable.values[[comp]]
nvalues.comp <- length(values.comp)
freq.comp <- xtable.freq[[comp]]
maxband.comp <- xband * ((xright - xleft)/2) * 
	max.freq.comp / max.freq
if (comp==1) abline(v=left.outer,lty=lty)
abline(v=right.outer,lty=lty)
for (nr in 1:nvalues.comp) {
value.nr <- values.comp[nr]
freq.nr <- freq.comp[nr]
left.nr <- mid - maxband.comp * freq.nr/max.freq.comp 
right.nr <- mid + maxband.comp * freq.nr/max.freq.comp 
if (freq.nr==1) points(x=mid,y=value.nr,pch=pch)
if (freq.nr>1 & !lines) points(x=left.nr + c(0:(freq.nr-1))*
	(right.nr-left.nr)/(freq.nr-1),y=rep(value.nr,freq.nr),pch=pch)
if (freq.nr>1 & lines) points(x=left.nr + c(0:(freq.nr-1))*
	(right.nr-left.nr)/(freq.nr-1),y=rep(value.nr,freq.nr),
	pch=pch,type='o',lty=lty)
} # end for value.nr
} # end for comp
lapply(xx,table)
} # end function multiple.distribution.graph


From cinzia.viroli at unibo.it  Tue Jun 12 15:46:26 2007
From: cinzia.viroli at unibo.it (Cinzia Viroli)
Date: Tue, 12 Jun 2007 15:46:26 +0200
Subject: [R] Building packages with subroutine in fortran 90 under windows xp
Message-ID: <DF025CBD019FD846B06D381BE3D0C3D302CC51@EXBK04.personale.dir.unibo.it>

Hello,

I work under windows xp and I am trying to build a R package with a subroutine written in fortran 90. 
I have installed all the updated tools and I am working with R-2.4.0 or R-2.5.0. 

When I check a package with a subroutine in fortran 77 (and extension f) everything is ok. 
When I try to build the same package with a subroutine in fortran 90 (with extension f90) the following warning appears:

Subdirectory 'src' contains no source files

and the package can not be built. 

The funny thing is that I have successfully built the same package with fortran 90 last March and everything was good. 

I can not imagine what is the problem, can anyone help me?
Thank you in advance,
best,
Cinzia





------------------------------------------------------------------------------------------------------------------------------------------------
Cinzia Viroli
Dipartimento di Scienze Statistiche "Paolo Fortunati" 
Via delle Belle Arti 41 
40126 Bologna 
Italy
Ph.  +39 051 2094628
Fax  +39 051 232153

home: www2.stat.unibo.it/viroli


From jjin at unc.edu  Tue Jun 12 15:52:24 2007
From: jjin at unc.edu (Jianping Jin)
Date: Tue, 12 Jun 2007 09:52:24 -0400
Subject: [R] how to ignore error messages?
In-Reply-To: <466D778D.9070409@gmail.com>
References: <62E2EA5AFC1ECA67395B7D44@gromit2.pmbb.med.unc.edu>
	<466D778D.9070409@gmail.com>
Message-ID: <8A12AB2A3C1579FA02563F13@gromit2.pmbb.med.unc.edu>

Dear Xiaohui,

Thanks a lot for your help! It worked for me.

Best regards!

JP-

--On Monday, June 11, 2007 9:25 AM -0700 Xiaohui <chenxh007 at gmail.com> 
wrote:

> see ?try
>
> Jianping Jin wrote:
>> Dear group:
>>
>> I wrote a code to iterate a non-linear fit with a set of data. The
>> entire  process didn't implemented to the end because an error message,
>> "singular  gradient". I knew that some sub-sets (columns) do not fit my
>> formula well  and may result in parameters going to infinity. It is
>> pretty hard to remove  those sub sets before running the code since that
>> will take a lot of time.
>>
>> I added some logic assessments prior to running nonlinear fit. It helped
>> but some exceptions still existed. I am wondering if there is any way in
>> R  by which I can continue to run the entire code to the end by ignoring
>> the  error message?
>>
>> Greatly appreciate your help,
>>
>> Jianping
>>
>> ##################################
>> Jianping Jin Ph.D.
>> Bioinformatics scientist
>> Center for Bioinformatics
>> Room 3133 Bioinformatics building
>> CB# 7104
>> University of Chapel Hill
>> Chapel Hill, NC 27599
>> Phone: (919)843-6105
>> FAX:   (919)843-3103
>> E-Mail: jjin at email.unc.edu
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html and provide commented,
>> minimal, self-contained, reproducible code.
>>
>>
>



##################################
Jianping Jin Ph.D.
Bioinformatics scientist
Center for Bioinformatics
Room 3133 Bioinformatics building
CB# 7104, Campus
Phone: (919)843-6105
FAX:   (919)843-3103
E-Mail: jjin at unc.edu


From ripley at stats.ox.ac.uk  Tue Jun 12 16:02:35 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 12 Jun 2007 15:02:35 +0100 (BST)
Subject: [R] Building packages with subroutine in fortran 90 under
 windows xp
In-Reply-To: <DF025CBD019FD846B06D381BE3D0C3D302CC51@EXBK04.personale.dir.unibo.it>
References: <DF025CBD019FD846B06D381BE3D0C3D302CC51@EXBK04.personale.dir.unibo.it>
Message-ID: <Pine.LNX.4.64.0706121453420.19641@gannet.stats.ox.ac.uk>

The tools do not include an F9x compiler: you need to edit MkRules to 
specify the path to one (after installing it) (and you did last March).

If I do that, I can install and check packages such as oc and wnominate 
from CRAN that make use of F9x.


On Tue, 12 Jun 2007, Cinzia Viroli wrote:

> Hello,
>
> I work under windows xp and I am trying to build a R package with a 
> subroutine written in fortran 90. I have installed all the updated tools 
> and I am working with R-2.4.0 or R-2.5.0.

'all the updated tools' is just too vague to be useful.

> When I check a package with a subroutine in fortran 77 (and extension f) 
> everything is ok. When I try to build the same package with a subroutine 
> in fortran 90 (with extension f90) the following warning appears:
>
> Subdirectory 'src' contains no source files
>
> and the package can not be built.
>
> The funny thing is that I have successfully built the same package with 
> fortran 90 last March and everything was good.
>
> I can not imagine what is the problem, can anyone help me?
> Thank you in advance,
> best,
> Cinzia
>
>
>
>
>
> ------------------------------------------------------------------------------------------------------------------------------------------------
> Cinzia Viroli
> Dipartimento di Scienze Statistiche "Paolo Fortunati"
> Via delle Belle Arti 41
> 40126 Bologna
> Italy
> Ph.  +39 051 2094628
> Fax  +39 051 232153
>
> home: www2.stat.unibo.it/viroli
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Seungho.Huh at sas.com  Tue Jun 12 16:24:48 2007
From: Seungho.Huh at sas.com (Seungho Huh)
Date: Tue, 12 Jun 2007 10:24:48 -0400
Subject: [R] LASSO coefficients for a specific s
Message-ID: <2CCF9E142D728041900567C6A0CFCCBC054E8D0A@mercmbx08.na.sas.com>

Hello,

I have a question about the lars package. I am using this package to get the coefficients at a specific LASSO parameter s.


data(diabetes)
attach(diabetes)

object <- lars(x,y,type="lasso")

cvres<-cv.lars(x,y,K=10,fraction = seq(from = 0, to = 1, length = 100))

fits <- predict.lars(object, type="coefficients", s=0.1, mode="fraction")


Can I assign automatically the best s value to predict.lars which is given by the CV process (cv.lars)? Or, do I need to manually find the s value that gives the minimum cv value from cv.lars, and assign it as the s value in predict.lars?

I would appreciate any advice on this. Thanks,
Seungho Huh


From asb at mail.nih.gov  Tue Jun 12 17:08:33 2007
From: asb at mail.nih.gov (Alan S Barnett)
Date: Tue, 12 Jun 2007 11:08:33 -0400
Subject: [R] 2 Trellis graphics question
Message-ID: <1181660913.17656.30.camel@gestalt.nimh.nih.gov>

1) I have a data that includes some "bad" data.  I want to make a
trellis plot where each panel contains 
a) A scatter plot of the "good" data
b) A scatter plot of the "bad" data in a different color
c) A best fit line of all the data, and
d) A best fit line of the "good" data.

I tried using xyplot and setting the "group" argument, but I'm having
trouble.  Here is my code:

xyplot(y ~ x | status, data=data,groups=good,
+  panel=function(x,y,...){
+  panel.xyplot(x,y,...)
+  panel.lmline(x,y,col = "red")
+  panel.lmline(x[good],y[good],col = "blue")
+ } 
+ )
a,groups=good,
data is a data frame containing names x, y and status.
good is logical variable labeling the "good" data.
Each panel of the trellis plot generated by this code includes
a) A scatterplot of the "good" data in magenta,
b) A scatterplot of the "bad" data in blue,
c) A best fit line of all the data in blue.

If I reverse the order of the last two lines, the best fit lines are
displayed in red.  Clearly, the correct value of good is not being
passed to panel.lmline, but is being correctly passed to panel.xyplot.

Substituting 
 panel.lmline(x,y,...)
for
 panel.lmline(x,y,col = "red") 
 panel.lmline(x[good],y[good],col = "blue)
results in the best fit line being plotted in black.
 
2) There are 5 different values of status, but I only want to plot three
of them.  Can I do this without copying only the desired elements into a
new data frame?

-- 
Alan S Barnett <asb at mail.nih.gov>
NIMH/CBDB


From Roy.Mendelssohn at noaa.gov  Tue Jun 12 18:22:26 2007
From: Roy.Mendelssohn at noaa.gov (Roy Mendelssohn)
Date: Tue, 12 Jun 2007 09:22:26 -0700
Subject: [R] [OT]Web-Based Data Brushing
Message-ID: <F92150A6-8333-4F24-B7B7-D4031F4CC657@noaa.gov>

I apologize for the off-topic post, but my Google search did not turn  
up much and I thought people on this list my have knowledge of this.   
I am looking for examples of  data brushing  (i.e. dynmaic linked  
plots) either on a web site, or in a web-based application, such as  
an AJAX app.  Even better if there is a way to do this in R.

Thanks for any help.

-Roy M.

**********************
"The contents of this message do not reflect any position of the U.S.  
Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division	
Southwest Fisheries Science Center
1352 Lighthouse Avenue
Pacific Grove, CA 93950-2097

e-mail: Roy.Mendelssohn at noaa.gov (Note new e-mail address)
voice: (831)-648-9029
fax: (831)-648-8440
www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."


From dan.oshea at dnr.state.mn.us  Tue Jun 12 18:27:14 2007
From: dan.oshea at dnr.state.mn.us (Daniel O'Shea)
Date: Tue, 12 Jun 2007 11:27:14 -0500
Subject: [R] nlme model
Message-ID: <466E83120200005A00005B19@co5.dnr.state.mn.us>

I am having trouble figuring out the right form for the nlme arguments.  I do have examples in Modern and Applied Statistics with S and from other sources, but I still can't figure it out. 

I am trying to estimate species richness (sr) in streams across minnesota.  My predictor variables are depth (d), habitat diversity (habdiv), drainage area (da) and an indicator variable representing the watershed/basins that the streams are in (bas: there are 10 watersheds).  The variable explaining the greatest amount of variation appears to be da.  I have used a log(da) to linearize the relationship, but an asymptotic relationship is more appropriate. I have used nls:

B<-c(.007,1,3,2,2,2,2,2,2,2,2,2,.05,.001,.8)
st<-list(ad=B[1],ahabdiv=B[2],abas=B[3:12],b=B[13],c=B[14],z=B[15])
modnls.a<-nls(sr~ad*log(d)+ahabdiv*habdiv+abas[bas]+(b/(c+(da^-z))),
    start=st,trace=T)

I next used a random slope and intercept model using lmer from the package (lme4). 

modlme<-lmer(y~d+habdiv+log(da)+(log(da)|bas),method='ML')

What I would like to do is use a similar model to the modlme, but use (b/(c+(da^-z))) instead of log(da).  Keeping d and habdiv as fixed effects and the sr-da relationship for each basin as a random effect.  For the life of me I can not figure out the proper form of nlme.  Any help would be greatly appreciated.  

Fsr<-function(da,b,c,z){b/(c+(da^-z}
modnlme<-nlme(sr~d+habdiv+Fsr(da,b,c,z),
    fixed=,
    random=,
    start=)


From h.wickham at gmail.com  Tue Jun 12 18:39:26 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 12 Jun 2007 18:39:26 +0200
Subject: [R] [OT]Web-Based Data Brushing
In-Reply-To: <F92150A6-8333-4F24-B7B7-D4031F4CC657@noaa.gov>
References: <F92150A6-8333-4F24-B7B7-D4031F4CC657@noaa.gov>
Message-ID: <f8e6ff050706120939o7c0937cepe7529040ed83bcf7@mail.gmail.com>

On 6/12/07, Roy Mendelssohn <Roy.Mendelssohn at noaa.gov> wrote:
> I apologize for the off-topic post, but my Google search did not turn
> up much and I thought people on this list my have knowledge of this.
> I am looking for examples of  data brushing  (i.e. dynmaic linked
> plots) either on a web site, or in a web-based application, such as
> an AJAX app.  Even better if there is a way to do this in R.
>
> Thanks for any help.

It's not completely in R, but rggobi (http://www.ggobi.org/rggobi)
offers a tight link to ggobi (http://www.ggobi.org) which offers a
wide range of interactive and dynamic graphics, including linked
brushing.

Hadley


From efg at stowers-institute.org  Tue Jun 12 18:47:35 2007
From: efg at stowers-institute.org (Earl F. Glynn)
Date: Tue, 12 Jun 2007 11:47:35 -0500
Subject: [R] Read Windows-like .INI files into R data structure?
Message-ID: <f4min7$hu5$1@sea.gmane.org>

I need to process some datasets where the configuration information was 
stored in .INI-like files, i.e., text files with sections like this:

[Section1]
var1=value1
var2=value2
[Section2]
A=value3
B=value4

...

>From Google and other searches I haven't found any package, or function 
within a package, that reads .INI files into an R list, or other data 
structure.



Any suggestions, or do I need to write my own?

efg

Earl F. Glynn
Stowers Institute for Medical Research


From yn19832 at msn.com  Tue Jun 12 18:53:11 2007
From: yn19832 at msn.com (livia)
Date: Tue, 12 Jun 2007 09:53:11 -0700 (PDT)
Subject: [R] Pareto Distribution
Message-ID: <11082669.post@talk.nabble.com>


I would like to fit a Pareto Distribution and I am using the following codes. 

First, I thought the fitted (fit1) should be the fitted value for the data,
is it correct? As the result of the "fitted" turns out to be the same value.

fit=vglm(ycf1 ~ 1, pareto1(location=alpha), trace=TRUE, crit="c")
coef(fit, matrix=TRUE)
summary(fit)
fitted(fit)

Secondly, how can I plot the density for the fitted distribution?

Many thanks.
-- 
View this message in context: http://www.nabble.com/Pareto-Distribution-tf3908751.html#a11082669
Sent from the R help mailing list archive at Nabble.com.


From ngottlieb at marinercapital.com  Tue Jun 12 19:15:22 2007
From: ngottlieb at marinercapital.com (ngottlieb at marinercapital.com)
Date: Tue, 12 Jun 2007 13:15:22 -0400
Subject: [R] Read Windows-like .INI files into R data structure?
In-Reply-To: <f4min7$hu5$1@sea.gmane.org>
References: <f4min7$hu5$1@sea.gmane.org>
Message-ID: <0946E293C7C22A45A0E33BA14FAA8D88F38818@500MAIL.goldbox.com>

Earl:

.Ini files are, for lack of a better description, ancient.

There are old windows functions such as GetProfileString.
However you will have to make reference to load these from the windows
Kernel.dll.
Probably not worth the effort to code really old things as .ini files.

>From what I see of packages, better to change these files to XML format
see if the XML package on CRAN will solve your requirement.

The section names would be top nodes with
XML tags containing the data at the sub level. XML is really
The best way to go; get away from .ini files.

Look at the XML package, reading nodes, parsing DOM.

Neil 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Earl F. Glynn
Sent: Tuesday, June 12, 2007 12:48 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Read Windows-like .INI files into R data structure?

I need to process some datasets where the configuration information was
stored in .INI-like files, i.e., text files with sections like this:

[Section1]
var1=value1
var2=value2
[Section2]
A=value3
B=value4

...

>From Google and other searches I haven't found any package, or function
within a package, that reads .INI files into an R list, or other data
structure.



Any suggestions, or do I need to write my own?

efg

Earl F. Glynn
Stowers Institute for Medical Research

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
--------------------------------------------------------

 
 
This information is being sent at the recipient's request or with their specific understanding. The recipient acknowledges that by sending this information via electronic means, there is no absolute assurance that the information will be free from third party access, use, or further dissemination. This e-mail contains information that is privileged and/or confidential and may be subject to legal restrictions and penalties regarding its unauthorized disclosure or other use. You are prohibited from copying, distributing or otherwise using this information if you are not the intended recipient. Past performance is not necessarily indicative of future results. This is not an offer of or the solicitation for any security which will be made only by private placement memorandum that may be obtained from the applicable hedge fund. If you have received this e-mail in error, please notify us immediately by return e-mail and delete this e-mail and all attachments from your system. Thank You.


From josh.kalish at credit-suisse.com  Tue Jun 12 19:27:50 2007
From: josh.kalish at credit-suisse.com (Kalish, Josh)
Date: Tue, 12 Jun 2007 18:27:50 +0100
Subject: [R] Stock Price Correlation to Index Price Levels
Message-ID: <FB9A739CA1DD3F4E81BF65BE4C6B0836502CF60E@enyc19p32002.corpny.csfb.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070612/52319895/attachment.pl 

From jeremy.miles at gmail.com  Tue Jun 12 19:33:51 2007
From: jeremy.miles at gmail.com (Jeremy Miles)
Date: Tue, 12 Jun 2007 10:33:51 -0700
Subject: [R] getting R2.4 (Win)
Message-ID: <7b53245b0706121033w6d1f93efha57bf69c35cf886@mail.gmail.com>

Hi,

I would like to get hold of the R version 2.4.0 windows installer, it
doesn't seem to be available on CRAN (except the source, which needs
compiling).  Does anyone know if it's still available anywhere?

Thanks,

jeremy



-- 
Jeremy Miles
Learning statistics blog: www.jeremymiles.co.uk/learningstats
Psychology Research Methods Wiki: www.researchmethodsinpsychology.com


From ianmccarthy at msn.com  Tue Jun 12 19:34:47 2007
From: ianmccarthy at msn.com (Ian McCarthy)
Date: Tue, 12 Jun 2007 13:34:47 -0400
Subject: [R] dyn.load( ) problem
Message-ID: <BAY116-DAV128838EFA6E77F9B2FFFF7B8190@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070612/75da3700/attachment.pl 

From mckellercran at gmail.com  Tue Jun 12 19:37:45 2007
From: mckellercran at gmail.com (Matthew Keller)
Date: Tue, 12 Jun 2007 13:37:45 -0400
Subject: [R] Cause of error message in cov function?
Message-ID: <3f547caa0706121037i4e295920m75940b175e01a852@mail.gmail.com>

Hi all,

I have written a script in R that simulates genetically informative
data - it is posted on my website and available to the public. This is
my first time to write a script for use by others and am learning that
it isn't as easy as it seems.

To the issue. My script runs fine on my machine and on a server I have
access to, but a user has written me saying that it crashes the first
time the function "cov" is called up. Below is her error message
followed by the version of R she's using.

Can anyone help me out here? I can't recreate her error message. Does
anyone know what this might have to do with? Is it a version issue
(she's using R 2.1)? I'd appreciate any help!!

Matt


ERROR MESSAGE:

cov.varcomp <- cov(t(effects.cur[c("A","AA","D","F","S","E","AGE","AGE.by.A"),]*beta2))

there is an argument mssing.
error message:

Error in mean((a - mean(a)) * (b - mean(b))) :
       argument "b" is missing, with no default


SPECIFICS OF HER MACHINE:

> memory.size()
[1] 10985480
> R.Version()
$platform
[1] "i386-pc-mingw32"
$arch
[1] "i386"
$os
[1] "mingw32"
$system
[1] "i386, mingw32"
$status
[1] ""
$major
[1] "2"
$minor
[1] "1.0"
$year
[1] "2005"
$month
[1] "04"
$day
[1] "18"
$language
[1] "R"
> .Platform
$OS.type
[1] "windows"
$file.sep
[1] "/"
$dynlib.ext
[1] ".dll"
$GUI
[1] "Rgui"
$endian
[1] "little"
$pkgType
[1] "win.binary"

-- 
Matthew C Keller
Postdoctoral Fellow
Virginia Institute for Psychiatric and Behavioral Genetics


From ggrothendieck at gmail.com  Tue Jun 12 19:42:09 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 12 Jun 2007 13:42:09 -0400
Subject: [R] Read Windows-like .INI files into R data structure?
In-Reply-To: <f4min7$hu5$1@sea.gmane.org>
References: <f4min7$hu5$1@sea.gmane.org>
Message-ID: <971536df0706121042r1aabcf03qf69ca6a117afab38@mail.gmail.com>

Here is some code. It replaces [ and ] with = sign and reads the result
into a data frame, DF.  DF2 is similar except the section is now in V3.
DF3 is like like DF2 except sections are carried forward and finally
we remove the rows which only had sections.

Lines.raw <- "[Section1]
var1=value1
var2=value2
[Section2]
A=value3
B=value4
"

Lines <- readLines(textConnection(Lines.raw))
Lines2 <- chartr("[]", "==", Lines)
DF <- read.table(textConnection(Lines2), as.is = TRUE, sep = "=", fill = TRUE)
DF2 <- transform(DF, V3 = ifelse(V1 == "", V2, NA))
L <- !is.na(DF2$V3)
DF3 <- transform(DF2, V3 = V3[c(NA, which(L))[cumsum(L)+1]])
subset(DF3, V1 != "")

The result is:

    V1     V2       V3
2 var1 value1 Section1
3 var2 value2 Section1
5    A value3 Section2
6    B value4 Section2


On 6/12/07, Earl F. Glynn <efg at stowers-institute.org> wrote:
> I need to process some datasets where the configuration information was
> stored in .INI-like files, i.e., text files with sections like this:
>
> [Section1]
> var1=value1
> var2=value2
> [Section2]
> A=value3
> B=value4
>
> ...
>
> >From Google and other searches I haven't found any package, or function
> within a package, that reads .INI files into an R list, or other data
> structure.
>
>
>
> Any suggestions, or do I need to write my own?
>
> efg
>
> Earl F. Glynn
> Stowers Institute for Medical Research
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jsorkin at grecc.umaryland.edu  Tue Jun 12 19:42:33 2007
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Tue, 12 Jun 2007 13:42:33 -0400
Subject: [R] Linux equivalent to windows menus and script window
Message-ID: <466EA24E.A712.00CB.0@grecc.umaryland.edu>

R 2.5 under windows XP
R 2.5 under Linux FC 6

I currently use R under windows and when I do so, I get to work in a nice windows environment complete with a very useful menu bar that  includes a FILE, EDIT, MISC, PACKAGE, WINDOWS, and HELP menus. I have begun to use R under LINUX. When I run under windows, I get a standard terminal window, but I don't get the menus specific to R. Under windows I also have the ability to open a SCRIPT window, edit R code in the window and submit the code from the window. Is there any way to get a window with R specific menus and a script window?
Thanks
John

John Sorkin M.D., Ph.D.
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)

Confidentiality Statement:
This email message, including any attachments, is for the so...{{dropped}}


From sabya231 at gmail.com  Tue Jun 12 19:45:44 2007
From: sabya231 at gmail.com (Tirthadeep)
Date: Tue, 12 Jun 2007 10:45:44 -0700 (PDT)
Subject: [R] Appropriate regression model for categorical variables
Message-ID: <11083540.post@talk.nabble.com>


Dear users,
In my psychometric test i have applied logistic regression on my data. My
data consists of 50 predictors (22 continuous and 28 categorical) plus a
binary response. 

Using glm(), stepAIC() i didn't get satisfactory result as misclassification
rate is too high. I think categorical variables are responsible for this
debacle. Some of them have more than 6 level (one has 10 level).

Please suggest some better regression model for this situation. If possible
you can suggest some article.

thanking you.

Tirtha
-- 
View this message in context: http://www.nabble.com/Appropriate-regression-model-for-categorical-variables-tf3908982.html#a11083540
Sent from the R help mailing list archive at Nabble.com.


From bcarvalh at jhsph.edu  Tue Jun 12 19:50:56 2007
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Tue, 12 Jun 2007 13:50:56 -0400
Subject: [R] Build Windows pkgs from source - online
Message-ID: <71B7B491-8F22-46F4-BD1F-918B16069473@jhsph.edu>

Hi,

First of all, I apologize for sending out this message, as I'm sure  
the answer is on the archives, but I just can't find it.

Not long ago, there was a discussion about building Windows packages  
from the source code and someone posted a link to a website  to which  
we could submit the source and get the Windows version a while later.

Could someone point me to that website or to where I can find such info?

Thanks,

-benilton


From Horace.Tso at pgn.com  Tue Jun 12 19:53:36 2007
From: Horace.Tso at pgn.com (Horace Tso)
Date: Tue, 12 Jun 2007 10:53:36 -0700
Subject: [R] Viewing a data object
Message-ID: <466E7B310200006500006405@pgn.com>

Dear list,

First apologize that this is trivial and just betrays my slothfulness at the keyboard. I'm sick of having to type a long name just to get a glimpse of something. For example, if my data frame is named 'AuroraStochasticRunsJune1.df" and I want to see what the middle looks like, I have to type

AuroraStochasticRunsJune1.df[ 400:500, ]

And often I'm not even sure rows 400 to 500 are what I want to see.  I might have to type the same line many times.

Is there sort of a R-equivalence of the Object Explorer, like in Splus, where I could mouse-click an object in a list and a window pops up?  Short of that, is there any trick of saving a couple of keystrokes here and there?

Thanks for tolerating this kind of annoying questions.

H.


From dieter.menne at menne-biomed.de  Tue Jun 12 19:57:03 2007
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Tue, 12 Jun 2007 19:57:03 +0200
Subject: [R] Stacked barchart color
Message-ID: <LPEJLJACLINDNMBMFAFIKEBICIAA.dieter.menne@menne-biomed.de>

Dear Latticer,

I want to give individual colors to all elements in a simple stacked
barchart. I know why the example below does not work (and it is a excellent
default), but is there any workaround for this?

Dieter


# This only colors red and green, but I want blue and gray for Peatland.

barchart(yield ~ variety , groups=year, data = barley,  stack = TRUE,
  subset=site=="Grand Rapids" & variety %in% c("Velvet","Peatland"),
    col=c("red","green","blue","gray"))


From ral at lcfltd.com  Tue Jun 12 20:08:37 2007
From: ral at lcfltd.com (Robert A LaBudde)
Date: Tue, 12 Jun 2007 14:08:37 -0400
Subject: [R] Appropriate regression model for categorical variables
In-Reply-To: <11083540.post@talk.nabble.com>
References: <11083540.post@talk.nabble.com>
Message-ID: <0JJJ003OKBQEC9L4@vms042.mailsrvcs.net>

At 01:45 PM 6/12/2007, Tirtha wrote:
>Dear users,
>In my psychometric test i have applied logistic regression on my data. My
>data consists of 50 predictors (22 continuous and 28 categorical) plus a
>binary response.
>
>Using glm(), stepAIC() i didn't get satisfactory result as misclassification
>rate is too high. I think categorical variables are responsible for this
>debacle. Some of them have more than 6 level (one has 10 level).
>
>Please suggest some better regression model for this situation. If possible
>you can suggest some article.

1. Using if a factor has many levels, there is a natural order to the 
levels. If so, consider fitting the factor as an ordered factor.

2. Break the factor levels into 2 or 3 groups that have some rational 
connection. Then fit the factor with a smaller number of levels. 
E.g., "race" might have levels "white", "black", "asian", "pacific", 
"Spanish surname", "other". Consider a change to "white", "nonwhite".

================================================================
Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
824 Timberlake Drive                     Tel: 757-467-0954
Virginia Beach, VA 23464-3239            Fax: 757-467-2947

"Vere scire est per causas scire"


From ccleland at optonline.net  Tue Jun 12 20:12:17 2007
From: ccleland at optonline.net (Chuck Cleland)
Date: Tue, 12 Jun 2007 14:12:17 -0400
Subject: [R] getting R2.4 (Win)
In-Reply-To: <7b53245b0706121033w6d1f93efha57bf69c35cf886@mail.gmail.com>
References: <7b53245b0706121033w6d1f93efha57bf69c35cf886@mail.gmail.com>
Message-ID: <466EE201.1090804@optonline.net>

Jeremy Miles wrote:
> Hi,
> 
> I would like to get hold of the R version 2.4.0 windows installer, it
> doesn't seem to be available on CRAN (except the source, which needs
> compiling).  Does anyone know if it's still available anywhere?
> 
> Thanks,
> 
> jeremy

Hi Jeremy:
  The windows binary for 2.4.0 seems to be available here:

http://cran.r-project.org/bin/windows/base/old/

hope this helps,

Chuck

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From stefan.grosse at uni-erfurt.de  Tue Jun 12 20:16:08 2007
From: stefan.grosse at uni-erfurt.de (Stefan Grosse)
Date: Tue, 12 Jun 2007 20:16:08 +0200
Subject: [R] Linux equivalent to windows menus and script window
In-Reply-To: <466EA24E.A712.00CB.0@grecc.umaryland.edu>
References: <466EA24E.A712.00CB.0@grecc.umaryland.edu>
Message-ID: <200706122016.08848.stefan.grosse@uni-erfurt.de>

There is, two candidates are ESS-emacs and JGR as a gui. Have a look at:

http://www.r-project.org/GUI

, on Tuesday 12 June 2007 19:42:33 John Sorkin wrote:
JS > R 2.5 under windows XP
JS > R 2.5 under Linux FC 6
JS >
JS > I currently use R under windows and when I do so, I get to work in a
 nice windows environment complete with a very useful menu bar that  includes
 a FILE, EDIT, MISC, PACKAGE, WINDOWS, and HELP menus. I have begun to use R
 under LINUX. When I run under windows, I get a standard terminal window, but
 I don't get the menus specific to R. Under windows I also have the ability
 to open a SCRIPT window, edit R code in the window and submit the code from
 the window. Is there any way to get a window with R specific menus and a
 script window? 


JS > Confidentiality Statement:
JS > This email message, including any attachments, is for the
 so...{{dropped}} 

funny...


From deepayan.sarkar at gmail.com  Tue Jun 12 20:17:35 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Tue, 12 Jun 2007 11:17:35 -0700
Subject: [R] format.dates, chron and Hmisc
In-Reply-To: <466C1A0C.2090903@rug.nl>
References: <9202D193C49A974F9DC63C32B28918D0962467@EMEAMAIL01.PERKINELMER.NET>
	<465ED42B.2090808@cancer.org.uk> <466C1A0C.2090903@rug.nl>
Message-ID: <eb555e660706121117h3c62f79r9e0e1cd7e3496caf@mail.gmail.com>

On 6/10/07, R.H. Koning <r.h.koning at rug.nl> wrote:
> Hello, I have some problems in using chron, Hmisc, and lattice. First,
> using both chron and Hmisc, I get an error message when describing data:
>
> df$Date <- chron(df$Date,format=c("d/m/y"))
>  > ll <- latex(describe(df),file="..//text//df.tex")
> Error in formatDateTime(dd, atx, !timeUsed) :
>         could not find function "format.dates"
>
> Then, using a chron object and lattice, I get
>
>  > plot.a <- xyplot(theta~Date|team,data=op.df.long,
> +  strip = function(bg, ...) strip.default(bg = 'transparent', ...),
> +  panel=function(x,y,...){
> +   panel.xyplot(x,y,cex=0.4,col="black",...)
> +   panel.loess(x,y,span=0.3,col="black",...)
> +   panel.abline(h=0)
> +  })
>  > print(plot.a)
> Error in pretty(rng, ...) : unused argument(s) (format.posixt = NULL)

This one is a bug in lattice (there is some code to support chron
objects, but evidently not many people use it). I will include a fix
in the next update.

-Deepayan


From wl2776 at gmail.com  Tue Jun 12 20:22:33 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Tue, 12 Jun 2007 11:22:33 -0700 (PDT)
Subject: [R] dyn.load( ) problem
In-Reply-To: <BAY116-DAV128838EFA6E77F9B2FFFF7B8190@phx.gbl>
References: <BAY116-DAV128838EFA6E77F9B2FFFF7B8190@phx.gbl>
Message-ID: <11084157.post@talk.nabble.com>



Ian McCarthy wrote:
> 
> I am trying to access a dll with dyn.load, but I get an error message box
> titled "R Console: Rgui.exe - Unable to Locate Component". The error
> message itself states "this application has failed to start because
> libifcoremdd.dll was not found. Re-installing the application may fix this
> problem." I have reinstalled the program (with full installation) but
> still get the same error. I received the dll from a colleague who never
> had this issue on his computer, so I don't think it is problem with a
> compiler or the source code. 
> 

And where is the file libifcoremdd.dll?

Looks like you have to install the Intel Fortran compiler, as this DLL is
its component ("Intel-specific Fortran I/O intrinsic support library when
compiled with /MDd",
http://www.intel.com/support/performancetools/fortran/windows/sb/cs-007847.htm),
or, at least all DLLs, your DLL depends on.
Try using Dependency Walker to resolve these
(http://www.dependencywalker.com/).


-- 
View this message in context: http://www.nabble.com/dyn.load%28-%29-problem-tf3908956.html#a11084157
Sent from the R help mailing list archive at Nabble.com.


From bruno.c at inwind.it  Tue Jun 12 20:29:35 2007
From: bruno.c at inwind.it (Bruno C.)
Date: Tue, 12 Jun 2007 20:29:35 +0200
Subject: [R] LASSO coefficients for a specific s
Message-ID: <JJJCPB$1E74C7C3E12E26AE80AF63CD6A0D81E3@libero.it>

Hy,
no need to find the best s value. CV does it for you:
cvres<-cv.lars(X,Y,K=10,type='lasso')
sAtBest<-cvres$fraction[which.min(cvres$cv)]
fits <- predict.lars(object, type="coefficients", s=sAtBest, mode="fraction")

...
Ciao
Bruno

> Hello,
> 
> I have a question about the lars package. I am using this package to get the coefficients at a specific LASSO parameter s.
> 
> 
> data(diabetes)
> attach(diabetes)
> 
> object <- lars(x,y,type="lasso")
> 
> cvres<-cv.lars(x,y,K=10,fraction = seq(from = 0, to = 1, length = 100))
> 
> fits <- predict.lars(object, type="coefficients", s=0.1, mode="fraction")
> 
> 
> Can I assign automatically the best s value to predict.lars which is given by the CV process (cv.lars)? Or, do I need to manually find the s value that gives the minimum cv value from cv.lars, and assign it as the s value in predict.lars?
> 
> I would appreciate any advice on this. Thanks,
> Seungho Huh
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


------------------------------------------------------
Passa a Infostrada. ADSL e Telefono senza limiti e senza canone Telecom
http://click.libero.it/infostrada


From deepayan.sarkar at gmail.com  Tue Jun 12 20:31:43 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Tue, 12 Jun 2007 11:31:43 -0700
Subject: [R] Stacked barchart color
In-Reply-To: <LPEJLJACLINDNMBMFAFIKEBICIAA.dieter.menne@menne-biomed.de>
References: <LPEJLJACLINDNMBMFAFIKEBICIAA.dieter.menne@menne-biomed.de>
Message-ID: <eb555e660706121131g73fe93abt41d89c8fa90b9be9@mail.gmail.com>

On 6/12/07, Dieter Menne <dieter.menne at menne-biomed.de> wrote:
> Dear Latticer,
>
> I want to give individual colors to all elements in a simple stacked
> barchart. I know why the example below does not work (and it is a excellent
> default), but is there any workaround for this?
>
> Dieter
>
>
> # This only colors red and green, but I want blue and gray for Peatland.
>
> barchart(yield ~ variety , groups=year, data = barley,  stack = TRUE,
>   subset=site=="Grand Rapids" & variety %in% c("Velvet","Peatland"),
>     col=c("red","green","blue","gray"))

The easiest way is to create a new factor with suitable levels: replace

groups=year

by

groups=year:variety

or the more verbose

groups=interaction(year, variety)

-Deepayan


From h.wickham at gmail.com  Tue Jun 12 20:31:47 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 12 Jun 2007 20:31:47 +0200
Subject: [R] Stacked barchart color
In-Reply-To: <LPEJLJACLINDNMBMFAFIKEBICIAA.dieter.menne@menne-biomed.de>
References: <LPEJLJACLINDNMBMFAFIKEBICIAA.dieter.menne@menne-biomed.de>
Message-ID: <f8e6ff050706121131s4b0aeb30y8de662ddd7323092@mail.gmail.com>

On 6/12/07, Dieter Menne <dieter.menne at menne-biomed.de> wrote:
> Dear Latticer,
>
> I want to give individual colors to all elements in a simple stacked
> barchart. I know why the example below does not work (and it is a excellent
> default), but is there any workaround for this?
>
> Dieter
>
>
> # This only colors red and green, but I want blue and gray for Peatland.
>
> barchart(yield ~ variety , groups=year, data = barley,  stack = TRUE,
>   subset=site=="Grand Rapids" & variety %in% c("Velvet","Peatland"),
>     col=c("red","green","blue","gray"))

Hi Dieter,

You can do this with ggplot2 (http://had.co.nz/ggplot2) as follows:

library(ggplot2)

barley1 <- subset(barley, site=="Grand Rapids" & variety %in%
c("Velvet","Peatland"))
barley1[] <- lapply(barley1, "[", drop=TRUE)

qplot(variety, yield, data=barley1, geom="bar", stat="identity",
fill=factor(year))

barley1$fill <- c("red","green","blue","gray")
qplot(variety, yield, data=barley1, geom="bar", stat="identity",
fill=fill) + scale_fill_identity()

See http://had.co.nz/ggplot2/scale_identity.html and
http://had.co.nz/ggplot2/position_stack.html for more details.

Hadley


From Roger.Bivand at nhh.no  Tue Jun 12 20:47:22 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 12 Jun 2007 20:47:22 +0200 (CEST)
Subject: [R] Build Windows pkgs from source - online
In-Reply-To: <71B7B491-8F22-46F4-BD1F-918B16069473@jhsph.edu>
References: <71B7B491-8F22-46F4-BD1F-918B16069473@jhsph.edu>
Message-ID: <Pine.LNX.4.64.0706122046150.10978@reclus.nhh.no>

On Tue, 12 Jun 2007, Benilton Carvalho wrote:

> Hi,
>
> First of all, I apologize for sending out this message, as I'm sure
> the answer is on the archives, but I just can't find it.
>
> Not long ago, there was a discussion about building Windows packages
> from the source code and someone posted a link to a website  to which
> we could submit the source and get the Windows version a while later.
>
> Could someone point me to that website or to where I can find such info?

http://win-builder.r-project.org/

from link on:

http://cran.r-project.org/src/contrib/PACKAGES.html

via

http://cran.r-project.org/bin/windows/contrib/checkSummaryWin.html

>
> Thanks,
>
> -benilton
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From rvaradhan at jhmi.edu  Tue Jun 12 21:00:24 2007
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Tue, 12 Jun 2007 15:00:24 -0400
Subject: [R] how to find how many modes in 2 dimensions case
In-Reply-To: <49425.128.97.244.86.1181331287.squirrel@calmail.berkeley.edu>
References: <002701c7aa03$766d0af0$4d908980@gne.windows.gene.com>
	<49425.128.97.244.86.1181331287.squirrel@calmail.berkeley.edu>
Message-ID: <000901c7ad23$ef3b9af0$7c94100a@win.ad.jhu.edu>

Hi Patrick,

Here is a simple R code for locating ALL the local maximum of a bivariate
function, which is known on a rectangular grid.  I have illustrated it with
a function called the Branin function, which is commonly used as a test
function in the global optimization literature.  It has 6 local maxima, two
of which are global.  

branin <- function(x1,x2,p) {
p[1] * x1^2 + p[2]*x1^4 + p[3]*x1^6 - x1*x2 + p[4]*x2^2 + p[5]*x2^4
}

x <- seq(-2, 2, length=100)
y <- seq(-1, 1, length=100)
p <- c(-4, 2.1, -1/3, 4, -4)
z <- outer(x, y, branin,p=p)
persp(x, y, z, theta=30, phi=30, col="lightblue")

#  here is a brute-force algorithm to locate ALL the local maxima
for (i in 2:(nrow(z)-1) ) {
for (j in 2:(ncol(z)-1) ) {
lmax <- (z[i,j] > z[i-1,j]) & (z[i,j] > z[i+1,j]) & (z[i,j] > z[i,j-1]) &
(z[i,j] > z[i,j+1])
if(lmax) cat("x: ",x[i], "y: ", y[j], "function: ", z[i,j], "\n")
} 
}

x:  -1.72 y:  0.798 function:  0.214 
x:  -1.60 y:  -0.576 function:  -2.10 
x:  -0.101 y:  0.717 function:  1.03 
x:  0.101 y:  -0.717 function:  1.03 
x:  1.60 y:  0.576 function:  -2.10 
x:  1.72 y:  -0.798 function:  0.214

Of course, this brute-force grid search is highly inefficient for dimensions
greater than 2.

Hope this is helpful,
Ravi.


----------------------------------------------------------------------------
-------

Ravi Varadhan, Ph.D.

Assistant Professor, The Center on Aging and Health

Division of Geriatric Medicine and Gerontology 

Johns Hopkins University

Ph: (410) 502-2619

Fax: (410) 614-9625

Email: rvaradhan at jhmi.edu

Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html

 

----------------------------------------------------------------------------
--------

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Patrick Wang
Sent: Friday, June 08, 2007 3:35 PM
To: Bert Gunter
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] how to find how many modes in 2 dimensions case

Thanks for the reply,

maybe I shall say bumps, I can use persp to show a density on a X Y
dimensions.
one peak is one mode I think. I try to find an automatic way to detect how
many peaks of the densities.

Pat
> Note that "the number of modes" (local maxima??)  is a function of the
> bandwidth, so I'm not sure your question is even meaningful.
>
> Bert Gunter
> Genentech Nonclinical Statistics
> South San Francisco, CA 94404
> 650-467-7374
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Patrick Wang
> Sent: Friday, June 08, 2007 11:54 AM
> To: R-help at stat.math.ethz.ch
> Subject: [R] how to find how many modes in 2 dimensions case
>
> Hi,
>
> Does anyone know how to count the number of modes in 2 dimensions using
> kde2d function?
>
> Thanks
> Pat
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dieter.menne at menne-biomed.de  Tue Jun 12 21:06:30 2007
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Tue, 12 Jun 2007 19:06:30 +0000 (UTC)
Subject: [R] Stacked barchart color
References: <LPEJLJACLINDNMBMFAFIKEBICIAA.dieter.menne@menne-biomed.de>
	<f8e6ff050706121131s4b0aeb30y8de662ddd7323092@mail.gmail.com>
Message-ID: <loom.20070612T210503-115@post.gmane.org>

hadley wickham <h.wickham <at> gmail.com> writes:

> 
> On 6/12/07, Dieter Menne <dieter.menne <at> menne-biomed.de> wrote:
> > Dear Latticer,
> >
> > I want to give individual colors to all elements in a simple stacked
> > barchart. I know why the example below does not work (and it is a excellent
> > default), but is there any workaround for this?
> >
> 
> You can do this with ggplot2 (http://had.co.nz/ggplot2) as follows:
> 
> library(ggplot2)
... 

Thanks, Hadley and Deepayan. Hadley's version required the latest update of
ggplot2 (0.5.1).

Dieter


From rvaradhan at jhmi.edu  Tue Jun 12 21:21:49 2007
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Tue, 12 Jun 2007 15:21:49 -0400
Subject: [R] how to find how many modes in 2 dimensions case
In-Reply-To: <49425.128.97.244.86.1181331287.squirrel@calmail.berkeley.edu>
References: <002701c7aa03$766d0af0$4d908980@gne.windows.gene.com>
	<49425.128.97.244.86.1181331287.squirrel@calmail.berkeley.edu>
Message-ID: <000e01c7ad26$ec937e00$7c94100a@win.ad.jhu.edu>

Patrick,

Here is an example closer to what you are interested in - locating bumps in
kernel density estimator.  I am using the example from package KernSmooth,
using the function bkde2D().

# Another example for locating maxima in kernel density estimation
 data(geyser, package="MASS")
 x <- cbind(geyser$duration, geyser$waiting)
 est <- bkde2D(x, bandwidth=c(0.7,7))
 persp(est$fhat)

x <- est$x1
y <- est$x2
z <- est$fhat

#  here is a brute-force algorithm to locate ALL the local maxima

for (i in 2:(nrow(z)-1) ) {
for (j in 2:(ncol(z)-1) ) {
lmax <- (z[i,j] > z[i-1,j]) & (z[i,j] > z[i+1,j]) & (z[i,j] > z[i,j-1]) &
(z[i,j] > z[i,j+1])
if(lmax) cat("x: ",x[i], "y: ", y[j], "function: ", z[i,j], "\n")
} 
}

x:  0.724 y:  41.1 function:  2.71e-20 
x:  0.858 y:  39.4 function:  1.08e-19 
x:  0.992 y:  35.9 function:  2.17e-19 
x:  2.07 y:  82.4 function:  0.00795 
x:  4.08 y:  77.2 function:  0.00722 
x:  4.35 y:  54.9 function:  0.00778

Of these, you can ignore the first 3, which have zero density.

Ravi.

----------------------------------------------------------------------------
-------

Ravi Varadhan, Ph.D.

Assistant Professor, The Center on Aging and Health

Division of Geriatric Medicine and Gerontology 

Johns Hopkins University

Ph: (410) 502-2619

Fax: (410) 614-9625

Email: rvaradhan at jhmi.edu

Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html

 

----------------------------------------------------------------------------
--------


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Patrick Wang
Sent: Friday, June 08, 2007 3:35 PM
To: Bert Gunter
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] how to find how many modes in 2 dimensions case

Thanks for the reply,

maybe I shall say bumps, I can use persp to show a density on a X Y
dimensions.
one peak is one mode I think. I try to find an automatic way to detect how
many peaks of the densities.

Pat
> Note that "the number of modes" (local maxima??)  is a function of the
> bandwidth, so I'm not sure your question is even meaningful.
>
> Bert Gunter
> Genentech Nonclinical Statistics
> South San Francisco, CA 94404
> 650-467-7374
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Patrick Wang
> Sent: Friday, June 08, 2007 11:54 AM
> To: R-help at stat.math.ethz.ch
> Subject: [R] how to find how many modes in 2 dimensions case
>
> Hi,
>
> Does anyone know how to count the number of modes in 2 dimensions using
> kde2d function?
>
> Thanks
> Pat
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From james.milks at wright.edu  Tue Jun 12 22:42:21 2007
From: james.milks at wright.edu (James Milks)
Date: Tue, 12 Jun 2007 16:42:21 -0400
Subject: [R] Generating artificial datasets with a specific correlation
	coefficient.
Message-ID: <7A249B6A-C8EE-421D-8AE2-8A5ECE18CDCD@wright.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070612/bfedb982/attachment.pl 

From pomchip at free.fr  Tue Jun 12 22:46:50 2007
From: pomchip at free.fr (=?UTF-8?B?U8OpYmFzdGllbg==?=)
Date: Tue, 12 Jun 2007 16:46:50 -0400
Subject: [R] Overlaying lattice graphs
In-Reply-To: <eb555e660706111549n35d8f442x1833c06b0cd61c0@mail.gmail.com>
References: <466DCD60.3020600@free.fr>
	<eb555e660706111549n35d8f442x1833c06b0cd61c0@mail.gmail.com>
Message-ID: <466F063A.3040805@free.fr>

Thanks for the information. These commands work perfectly fine and the 
?panel.superpose help was most informative.
If you don't mind, I will certainly come back to you as there will 
certainly be additionnal complexities in my datasets that I will be 
unable to handle (e.g. data in more than one data.frame, complex 
conditions...).

Sebastien

Deepayan Sarkar a ?crit :
> On 6/11/07, Seb <pomchip at free.fr> wrote:
>> Hello
>>
>> I apologize in advance if this question has already be posted on the
>> list, although I could not find a relevant thread in the archives.
>>
>> I would like to overlay xyplots using different datasets for each plot.
>> I typically work on the following data.frame (mydata) structure
>>
>> >mydata
>>         Drug    Time        Observed          Predicted
>> 1       A        0.05         10                 10.2
>> 2       A        0.10         20                 19.5
>> etc...
>> 100     B        0.05         11                 12.7
>> 101     B        0.10         35                 36
>> etc...
>>
>> I want to plot the observed data as points and the predicted values as
>> lines. If I use the following commands, I don't have the possibility to
>> switch the "y" values from Observed for the scatterplot to Predicted for
>> the line.
>>
>> xyplot(Observed ~ Time | Drug, data = mydata, panel  =  function(x,y, 
>> ...){
>> +            panel.xyplot(x,y,...)
>> +            panel.xyplot(x,y,type="l",...)})
>>
>> I wonder if this problem can be solved using the trellis.focus "family"
>> commands but I have a hard time to understand how they work.
>>
>> Please, let me know if a thread have already addressed this question.
>> Otherwise, I would grateful for any hint, comments or info you can 
>> provide.
>
> There are several possible solutions. In your case, the simplest one
> would be something like (see ?panel.superpose for explanation):
>
> xyplot(Observed + Predicted ~ Time | Drug, data = mydata,
>       type = c("p", "l"), distribute.type = TRUE)
>
> This will work best if the Time values are ordered; otherwise you 
> could use
>
> type = c("p", "a")
>
> instead, which will be a little slower. Let us know if this doesn't
> give you what you want, preferably with a reproducible example
> illustrating why.
>
> -Deepayan
>
>


From h.wickham at gmail.com  Tue Jun 12 22:51:21 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 12 Jun 2007 22:51:21 +0200
Subject: [R] Overlaying lattice graphs
In-Reply-To: <466DCD60.3020600@free.fr>
References: <466DCD60.3020600@free.fr>
Message-ID: <f8e6ff050706121351v2076dd5epbca905fd76fdf245@mail.gmail.com>

On 6/12/07, Seb <pomchip at free.fr> wrote:
> Hello
>
> I apologize in advance if this question has already be posted on the
> list, although I could not find a relevant thread in the archives.
>
> I would like to overlay xyplots using different datasets for each plot.
> I typically work on the following data.frame (mydata) structure
>
> >mydata
>         Drug    Time        Observed          Predicted
> 1       A        0.05         10                 10.2
> 2       A        0.10         20                 19.5
> etc...
> 100     B        0.05         11                 12.7
> 101     B        0.10         35                 36
> etc...
>
> I want to plot the observed data as points and the predicted values as
> lines. If I use the following commands, I don't have the possibility to
> switch the "y" values from Observed for the scatterplot to Predicted for
> the line.
>
> xyplot(Observed ~ Time | Drug, data = mydata, panel  =  function(x,y, ...){
> +            panel.xyplot(x,y,...)
> +            panel.xyplot(x,y,type="l",...)})
>
> I wonder if this problem can be solved using the trellis.focus "family"
> commands but I have a hard time to understand how they work.

Another approach would be to use ggplot, http://had.co.nz/ggplot2.
Then your code might look something like:

ggplot(mydata, aes(x=Time)) +
geom_point(aes(y=Observed)) +
geom_line(aes(y = Predicted)) +
facet_grid(. ~ Drug)

Hadley


From knoblauch at lyon.inserm.fr  Tue Jun 12 22:54:05 2007
From: knoblauch at lyon.inserm.fr (Ken Knoblauch)
Date: Tue, 12 Jun 2007 20:54:05 +0000 (UTC)
Subject: [R] Generating artificial datasets with a specific
	correlationcoefficient.
References: <7A249B6A-C8EE-421D-8AE2-8A5ECE18CDCD@wright.edu>
Message-ID: <loom.20070612T225123-579@post.gmane.org>

see mvrnorm in MASS and especially the empirical argument

James Milks <james.milks <at> wright.edu> writes:


> I need to create artificial datasets with specific correlation  
> coefficients (i.e. a dataset that returns r = 0.30, etc.) as examples  
> for a lab I am teaching this summer.  Is there a way to do that in R?
> 
> Thanks.
> 
> Jim Milks


From helprhelp at gmail.com  Tue Jun 12 23:01:42 2007
From: helprhelp at gmail.com (Weiwei Shi)
Date: Tue, 12 Jun 2007 17:01:42 -0400
Subject: [R] pretty report
Message-ID: <cdf817830706121401u54bd6df9nb22b6acdd2e33d6b@mail.gmail.com>

Dear Listers:

I have a couple of data frames to report and each corresponds to
different condtions, e.g. conditions=c(10, 15, 20, 25). In this
examples, four data frames need to be exported in a "pretty" report.

I knew Perl has some module for exporting data to Excel and after
googling, I found R does not.

So I am wondering if there is a package in R for generating good
reports. I found package xtable but it seems (if not, please correct
me) that it can only generate one table for one file.

Thanks for any suggestions,

-W

-- 
Weiwei Shi, Ph.D
Research Scientist
GeneGO, Inc.

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III


From pomchip at free.fr  Tue Jun 12 23:05:54 2007
From: pomchip at free.fr (=?ISO-8859-1?Q?S=E9bastien?=)
Date: Tue, 12 Jun 2007 17:05:54 -0400
Subject: [R] Subset and logical operator error
Message-ID: <466F0AB2.40503@free.fr>

Hello,

It looks to me as if the ! logical operator cannot be called when 
subsetting a data.frame. In the example below, the value column has two 
factor levels (but my typical datasets have more), and what I am trying 
to do is to exclude all lines for which the "value" is different from 
"A". I have got a syntax error message everytime I try to use the 
subset() function. Unfortunatelly, the help on the subset function or 
the logical operators is not really specific on the way to implement 
this type of exclusion subset?

Can you please point to me my syntax mistake or indicate a method to get 
this type of data.frame subset ?

Thank you in advance

  ID value
1  1   1.2
2  2   1.2
3  3   1.2
4  4   1.2
5  5     A
6  6     A
7  7     A
8  8     A
subset(mdat,value!"A")

Error: syntax error, unexpected '!', expecting ',' in "subset(mdat,value!"

Sebastien


From arnaud_mosnier at UQAR.QC.CA  Tue Jun 12 23:04:00 2007
From: arnaud_mosnier at UQAR.QC.CA (Arnaud Mosnier)
Date: Tue, 12 Jun 2007 17:04:00 -0400
Subject: [R] ML, REML and several random effects
Message-ID: <466F0A40.2090601@uqar.qc.ca>

Hello everyone,

Hope that my question could have interest for more than one people here.
I know that in order to compare mixed models with different fixed effect 
I need to use ML method.
But ... what about comparing models with the same fixed effects and 
different random effects ?

Thanks in advance !

Arnaud


From helprhelp at gmail.com  Tue Jun 12 23:13:54 2007
From: helprhelp at gmail.com (Weiwei Shi)
Date: Tue, 12 Jun 2007 17:13:54 -0400
Subject: [R] pretty report
In-Reply-To: <cdf817830706121401u54bd6df9nb22b6acdd2e33d6b@mail.gmail.com>
References: <cdf817830706121401u54bd6df9nb22b6acdd2e33d6b@mail.gmail.com>
Message-ID: <cdf817830706121413s643d4412lf4a4b5e9217da528@mail.gmail.com>

Just realized append=T might help for xtable, but I think it still not
very "pretty" :)

On 6/12/07, Weiwei Shi <helprhelp at gmail.com> wrote:
> Dear Listers:
>
> I have a couple of data frames to report and each corresponds to
> different condtions, e.g. conditions=c(10, 15, 20, 25). In this
> examples, four data frames need to be exported in a "pretty" report.
>
> I knew Perl has some module for exporting data to Excel and after
> googling, I found R does not.
>
> So I am wondering if there is a package in R for generating good
> reports. I found package xtable but it seems (if not, please correct
> me) that it can only generate one table for one file.
>
> Thanks for any suggestions,
>
> -W
>
> --
> Weiwei Shi, Ph.D
> Research Scientist
> GeneGO, Inc.
>
> "Did you always know?"
> "No, I did not. But I believed..."
> ---Matrix III
>


-- 
Weiwei Shi, Ph.D
Research Scientist
GeneGO, Inc.

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III


From knoblauch at lyon.inserm.fr  Tue Jun 12 23:18:23 2007
From: knoblauch at lyon.inserm.fr (Ken Knoblauch)
Date: Tue, 12 Jun 2007 21:18:23 +0000 (UTC)
Subject: [R] Subset and logical operator error
References: <466F0AB2.40503@free.fr>
Message-ID: <loom.20070612T231559-587@post.gmane.org>



S?bastien <pomchip <at> free.fr> writes:

> 
> Can you please point to me my syntax mistake or indicate a method to get 
> this type of data.frame subset ?
> 
> Thank you in advance
> 
>   ID value
> 1  1   1.2
> 2  2   1.2
> 3  3   1.2
> 4  4   1.2
> 5  5     A
> 6  6     A
> 7  7     A
> 8  8     A
> subset(mdat,value!"A")
> 
> Error: syntax error, unexpected '!', expecting ',' in "subset(mdat,value!"
> 
Looks like you forgot the "=" as in

subset(mdat, value != "A")
  ID value
1  1   1.2
2  2   1.2
3  3   1.2
4  4   1.2


From ngottlieb at marinercapital.com  Tue Jun 12 23:27:58 2007
From: ngottlieb at marinercapital.com (ngottlieb at marinercapital.com)
Date: Tue, 12 Jun 2007 17:27:58 -0400
Subject: [R] R Book Advice Needed
Message-ID: <0946E293C7C22A45A0E33BA14FAA8D88F3881A@500MAIL.goldbox.com>

I am new to using R and would appreciate some advice on
which books to start with to get up to speed on using R.

My Background:
1-C# programmer.
2-Programmed directly using IMSL (Now Visual Numerics).
3- Used in past SPSS and Statistica.

I put together a list but would like to pick the "best of" 
and avoid redundancy.

Any suggestions on these books would be helpful (i.e. too much overlap,
porly written etc?)

Books:
1-Analysis of Integrated and Co-integrated Time Series with R (Use R) -
Bernhard Pfaff
2-An Introduction to R - W. N. Venables
3-Statistics: An Introduction using R - Michael J. Crawley
4-R Graphics (Computer Science and Data Analysis) - Paul Murrell
5-A Handbook of Statistical Analyses Using R - Brian S. Everitt
6-Introductory Statistics with R - Peter Dalgaard
7-Using R for Introductory Statistics - John Verzani
8-Data Analysis and Graphics Using R - John Maindonald;
9-Linear Models with R (Texts in Statistical Science) - Julian J.
Faraway
10-Analysis of Financial Time Series (Wiley Series in Probability and
Statistics)2nd edition - Ruey S. Tsay

Thanks.

Neil Gottlieb
--------------------------------------------------------

 
 
This information is being sent at the recipient's request or with their specific understanding. The recipient acknowledges that by sending this information via electronic means, there is no absolute assurance that the information will be free from third party access, use, or further dissemination. This e-mail contains information that is privileged and/or confidential and may be subject to legal restrictions and penalties regarding its unauthorized disclosure or other use. You are prohibited from copying, distributing or otherwise using this information if you are not the intended recipient. Past performance is not necessarily indicative of future results. This is not an offer of or the solicitation for any security which will be made only by private placement memorandum that may be obtained from the applicable hedge fund. If you have received this e-mail in error, please notify us immediately by return e-mail and delete this e-mail and all attachments from your system. Thank You.


From chrysopa at gmail.com  Tue Jun 12 23:56:40 2007
From: chrysopa at gmail.com (Ronaldo Reis Junior)
Date: Tue, 12 Jun 2007 18:56:40 -0300
Subject: [R] JGR and big list of packages.
Message-ID: <200706121856.40269.chrysopa@gmail.com>

Hi,

I have all CRAN packages installed on my Linux. Now I have problems with JGR.

When I make a plot and close a device, the device dont work anymore, I nedd to 
use before javaGD() and after plot(). When I try do close JGR and save a 
session, It return a erro and dont close. Look:

 Exception in thread "Thread-2" java.lang.IllegalArgumentException: Value too 
long: aaMI,abind,accuracy,acepack,actuar,ada,adabag,adapt,AdaptFit,ade4,
.....
.....
.....
.....
tools,utils
        at 
java.util.prefs.AbstractPreferences.put(AbstractPreferences.java:228)
        at org.rosuda.JGR.toolkit.JGRPrefs.writePrefs(JGRPrefs.java:281)
        at 
org.rosuda.JGR.toolkit.JGRPrefs.writeCurrentPackagesWhenExit(JGRPrefs.java:314)
        at org.rosuda.JGR.JGR.exit(JGR.java:241)
        at org.rosuda.JGR.JGRConsole.rReadConsole(JGRConsole.java:480)
        at org.rosuda.JRI.Rengine.jriReadConsole(Rengine.java:371)
        at org.rosuda.JRI.Rengine.rniRunMainLoop(Native Method)
        at org.rosuda.JRI.Rengine.run(Rengine.java:533)

I think that is a problem with the JGR's package manager. It is possible to 
disable package manager from JGR?

Thanks
Inte
Ronaldo
-- 
I guess the Little League is even littler than we thought.
		-- D. Cavett
--
> Prof. Ronaldo Reis J?nior
|  .''`. UNIMONTES/Depto. Biologia Geral/Lab. de Ecologia
| : :'  : Campus Universit?rio Prof. Darcy Ribeiro, Vila Mauric?ia
| `. `'` CP: 126, CEP: 39401-089, Montes Claros - MG - Brasil
|   `- Fone: (38) 3229-8187 | ronaldo.reis em unimontes.br | chrysopa em gmail.com
| http://www.ppgcb.unimontes.br/ | ICQ#: 5692561 | LinuxUser#: 205366


From efg at stowers-institute.org  Tue Jun 12 23:54:49 2007
From: efg at stowers-institute.org (Earl F. Glynn)
Date: Tue, 12 Jun 2007 16:54:49 -0500
Subject: [R] Can strptime handle milliseconds or AM/PM?
Message-ID: <f4n4n9$l9d$1@sea.gmane.org>

I'm trying to proess date/time fields from files that were given to me to 
analyze.

Any clues what I'm doing wrong with strptime?   This seems to fail the same 
way under Linux or Windows.

 For ?strptime would it make sense to explain %OS3 somewhere besides the 
Examples?

> # Why does %OS3 work here?
> format(Sys.time(), "%H:%M:%S")
[1] "16:45:19"
> format(Sys.time(), "%H:%M:%OS3")
[1] "16:45:19.477"

> # Why doesn't %OS3 work here?
> EventLog.Start <- "17:49:33.779"
> strptime(EventLog.Start, "%H:%M:%S")
[1] "2007-06-12 17:49:33"
> strptime(EventLog.Start, "%H:%M:%OS3")
[1] NA


> # This works OK without milliseconds or AM/PM
> x <- c("5:49:33 6/9/2007", "5:49:36 6/9/2007", "5:49:37 6/9/2007")
> strptime(x, "%I:%M:%S")   # unclear why this inserts today's date?
[1] "2007-06-12 05:49:33" "2007-06-12 05:49:36" "2007-06-12 05:49:37"
> strptime(x, "%I:%M:%S %m/%d/%Y")
[1] "2007-06-09 05:49:33" "2007-06-09 05:49:36" "2007-06-09 05:49:37"


> # How to handle milliseconds and AM/PM?  Why doesn't this work?
> y <- c("5:49:33.795 PM 6/9/2007", "5:49:36.184 PM 6/9/2007", "5:49:37.808 
> PM 6/9/2007")
> strptime(y, "%I:%M:%S")               # works except for milliseconds but 
> wrong date
[1] "2007-06-12 05:49:33" "2007-06-12 05:49:36" "2007-06-12 05:49:37"
> strptime(y, "%I:%M:%OS3")             # doesn't work
[1] NA NA NA
> strptime(y, "%I:%M:%S %p %m/%d/%Y")   # AM/PM doesn't work
[1] NA NA NA
> strptime(y, "%I:%M:%S %p %m/%d/%Y")   # AM/PM with dates doesn't work
[1] NA NA NA
> strptime("5:49:33 PM 6/9/2007", "%I:%M:%S %p")  # doesn't get date right
[1] "2007-06-12 17:49:33"

### Windows ###

> Sys.getlocale(category = "LC_TIME")
[1] "English_United States.1252"
> R.version
               _
platform       i386-pc-mingw32
arch           i386
os             mingw32
system         i386, mingw32
status
major          2
minor          5.0
year           2007
month          04
day            23
svn rev        41293
language       R
version.string R version 2.5.0 (2007-04-23)


### Linux ###

> Sys.getlocale(category = "LC_TIME")
[1] "C"
> R.version
               _
platform       x86_64-unknown-linux-gnu
arch           x86_64
os             linux-gnu
system         x86_64, linux-gnu
status
major          2
minor          4.1
year           2006
month          12
day            18
svn rev        40228
language       R
version.string R version 2.4.1 (2006-12-18)


efg

Earl F. Glynn
Stowers Institute for Medical Research


From ggrothendieck at gmail.com  Wed Jun 13 00:12:41 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 12 Jun 2007 18:12:41 -0400
Subject: [R] pretty report
In-Reply-To: <cdf817830706121401u54bd6df9nb22b6acdd2e33d6b@mail.gmail.com>
References: <cdf817830706121401u54bd6df9nb22b6acdd2e33d6b@mail.gmail.com>
Message-ID: <971536df0706121512n13215b54vf23ae427dd5af822@mail.gmail.com>

Generating Excel or reports seems to be two different questions:

1. Reports. You can use xtable together with Sweave.  See figure 1 in this
link for an example:

http://www.ci.tuwien.ac.at/~leisch/Sweave/Sweave-Rnews-2002-3.pdf

2. Regarding writing Excel files this can be done on Windows using the
xlsReadWrite package or in a lower level way using rcom or RDCOMClient.


On 6/12/07, Weiwei Shi <helprhelp at gmail.com> wrote:
> Dear Listers:
>
> I have a couple of data frames to report and each corresponds to
> different condtions, e.g. conditions=c(10, 15, 20, 25). In this
> examples, four data frames need to be exported in a "pretty" report.
>
> I knew Perl has some module for exporting data to Excel and after
> googling, I found R does not.
>
> So I am wondering if there is a package in R for generating good
> reports. I found package xtable but it seems (if not, please correct
> me) that it can only generate one table for one file.
>
> Thanks for any suggestions,
>
> -W
>
> --
> Weiwei Shi, Ph.D
> Research Scientist
> GeneGO, Inc.
>
> "Did you always know?"
> "No, I did not. But I believed..."
> ---Matrix III
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From alain.reymond at skynet.be  Wed Jun 13 00:23:22 2007
From: alain.reymond at skynet.be (Alain Reymond)
Date: Wed, 13 Jun 2007 00:23:22 +0200
Subject: [R] R Book Advice Needed
In-Reply-To: <0946E293C7C22A45A0E33BA14FAA8D88F3881A@500MAIL.goldbox.com>
References: <0946E293C7C22A45A0E33BA14FAA8D88F3881A@500MAIL.goldbox.com>
Message-ID: <466F1CDA.6070903@skynet.be>

ngottlieb at marinercapital.com a ?crit :
> I am new to using R and would appreciate some advice on
> which books to start with to get up to speed on using R.
>
> My Background:
> 1-C# programmer.
> 2-Programmed directly using IMSL (Now Visual Numerics).
> 3- Used in past SPSS and Statistica.
>
> I put together a list but would like to pick the "best of" 
> and avoid redundancy.
>
> Any suggestions on these books would be helpful (i.e. too much overlap,
> porly written etc?)
>
> Books:
> 1-Analysis of Integrated and Co-integrated Time Series with R (Use R) -
> Bernhard Pfaff
> 2-An Introduction to R - W. N. Venables
> 3-Statistics: An Introduction using R - Michael J. Crawley
> 4-R Graphics (Computer Science and Data Analysis) - Paul Murrell
> 5-A Handbook of Statistical Analyses Using R - Brian S. Everitt
> 6-Introductory Statistics with R - Peter Dalgaard
> 7-Using R for Introductory Statistics - John Verzani
> 8-Data Analysis and Graphics Using R - John Maindonald;
> 9-Linear Models with R (Texts in Statistical Science) - Julian J.
> Faraway
> 10-Analysis of Financial Time Series (Wiley Series in Probability and
> Statistics)2nd edition - Ruey S. Tsay
>
> Thanks.
>
> Neil Gottlieb
>   
Neil,

I am also new to R and I just bought the book of Peter Dalgaard (n?6).
I find it very practical. It covers a large panel of principal
statistical techniques that you can use directly. I thinkk it is a good
start for a R beginner. At least, it is good for me!
Don't forget the many resources on the R website.

Regards.

-- 
Alain Reymond
CEIA
Bd Saint-Michel 119
1040 Bruxelles
Tel: +32 2 736 04 58
Fax: +32 2 736 58 02
alain.reymond at ceia.com
PGPId :  0xEFB06E2E


From deepayan.sarkar at gmail.com  Wed Jun 13 00:28:44 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Tue, 12 Jun 2007 15:28:44 -0700
Subject: [R] 2 Trellis graphics question
In-Reply-To: <1181660913.17656.30.camel@gestalt.nimh.nih.gov>
References: <1181660913.17656.30.camel@gestalt.nimh.nih.gov>
Message-ID: <eb555e660706121528r6b950cfasf2c482698d77d4ca@mail.gmail.com>

On 6/12/07, Alan S Barnett <asb at mail.nih.gov> wrote:
> 1) I have a data that includes some "bad" data.  I want to make a
> trellis plot where each panel contains
> a) A scatter plot of the "good" data
> b) A scatter plot of the "bad" data in a different color
> c) A best fit line of all the data, and
> d) A best fit line of the "good" data.
>
> I tried using xyplot and setting the "group" argument, but I'm having
> trouble.  Here is my code:
>
> xyplot(y ~ x | status, data=data,groups=good,
> +  panel=function(x,y,...){
> +  panel.xyplot(x,y,...)
> +  panel.lmline(x,y,col = "red")
> +  panel.lmline(x[good],y[good],col = "blue")
> + }
> + )

You are close, except the last panel.lmline call is not meaningful
because the 'x' and 'y' in the panel function are not the same length
as 'good'.  You need to use 'subscripts' for that.

To fix ideas, here's a concrete example (I've changed the names 'x'
and 'y' to 'xx' and 'yy' to avoid any confusion):


mydata <-
    data.frame(xx = sample(100),
               yy = rnorm(100) + rep(c(5, 10), c(80, 20)),
               status = gl(5, 1, 100),
               good = rep(c(TRUE, FALSE), c(80, 20)))

Then, what you want can be achieved with:

xyplot(yy ~ xx | status, mydata, groups = good,

       panel = function(x, y, groups, subscripts, ...) {
           panel.xyplot(x, y,
                        groups = groups,
                        subscripts = subscripts,
                        ...)
           panel.lmline(x, y, col = "red")
	   good.id <- groups[subscripts]
	   ## good.id: subset of 'good' relevant for this panel
           panel.lmline(x[good.id], y[good.id], col = "blue")
       })

This also works if 'good' is globally visible and not in 'mydata'.

[...]

> 2) There are 5 different values of status, but I only want to plot three
> of them.  Can I do this without copying only the desired elements into a
> new data frame?

Sure, just use the additional argument

  subset = (status %in% c("1", "3", "5"))

or whatever the appropriate subset is.

-Deepayan


From Cody_Hamilton at Edwards.com  Wed Jun 13 00:35:42 2007
From: Cody_Hamilton at Edwards.com (Cody_Hamilton at Edwards.com)
Date: Tue, 12 Jun 2007 15:35:42 -0700
Subject: [R] R Book Advice Needed
Message-ID: <OF88CDFD73.E09BD8D4-ON882572F8.007C06BE-882572F8.007BEB02@irvine.edwards.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070612/0de2df2b/attachment.pl 

From cumarporn at gmail.com  Wed Jun 13 00:35:26 2007
From: cumarporn at gmail.com (umarporn charusombat)
Date: Tue, 12 Jun 2007 18:35:26 -0400
Subject: [R] data from graph
Message-ID: <904d37580706121535t10c43363j463263209127c357@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070612/095224c3/attachment.pl 

From edd at debian.org  Wed Jun 13 00:50:02 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 12 Jun 2007 17:50:02 -0500
Subject: [R] Can strptime handle milliseconds or AM/PM?
In-Reply-To: <f4n4n9$l9d$1@sea.gmane.org>
References: <f4n4n9$l9d$1@sea.gmane.org>
Message-ID: <18031.8986.302343.451785@basebud.nulle.part>


On 12 June 2007 at 16:54, Earl F. Glynn wrote:
| Any clues what I'm doing wrong with strptime?   This seems to fail the same 
| way under Linux or Windows.
| 
|  For ?strptime would it make sense to explain %OS3 somewhere besides the 
| Examples?
| 
| > # Why does %OS3 work here?
| > format(Sys.time(), "%H:%M:%S")
| [1] "16:45:19"
| > format(Sys.time(), "%H:%M:%OS3")
| [1] "16:45:19.477"

I usually get good results with just '%OS' for fractional seconds.  First,
make sure you do display fractional seconds which I do via
'options("digits.secs"=7) in ~/.Rprofile:

	> getOption("digits.secs")			
	[1] 7

Then a simple example:

	> now <- Sys.time()
	> strptime(now, "%Y-%m-%d %H:%M:%OS")
	[1] "2007-06-12 17:44:16.779577"
	>
 
As per help("strptime"), what you tried should work

     Specific to R is '%OSn', which for output gives the seconds to '0
     <= n <= 6' decimal places (and if '%OS' is not followed by a
     digit, it uses the setting of 'getOption("digits.secs")', or if
     that is unset, 'n = 3'). Further, for 'strptime' '%OS' will input
     seconds including fractional seconds.

but doesn't for me either:

	> strptime(now, "%Y-%m-%d %H:%M:%OS6")
	[1] NA
	> strptime(now, "%Y-%m-%d %H:%M:%OS3")
	[1] NA
	> 

Looks like a bug.  But easy enough to circumvent if you just drop the 'n'.

Hth, Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From ianmccarthy at msn.com  Wed Jun 13 01:06:53 2007
From: ianmccarthy at msn.com (Ian McCarthy)
Date: Tue, 12 Jun 2007 19:06:53 -0400
Subject: [R] Using dll with Visual Studio Compiler
Message-ID: <BAY116-DAV4D63C2B088EC584C18B4BB8190@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070612/794da76d/attachment.pl 

From ggrothendieck at gmail.com  Wed Jun 13 01:23:20 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 12 Jun 2007 19:23:20 -0400
Subject: [R] Read Windows-like .INI files into R data structure?
In-Reply-To: <971536df0706121042r1aabcf03qf69ca6a117afab38@mail.gmail.com>
References: <f4min7$hu5$1@sea.gmane.org>
	<971536df0706121042r1aabcf03qf69ca6a117afab38@mail.gmail.com>
Message-ID: <971536df0706121623p14725cbbp82610f2d3149a9e7@mail.gmail.com>

In thinking about this a bit more here is an even shorter solution where
Lines.raw is as before:

# Lines <- readLines("myfile.ini")
Lines <- readLines(textConnection(Lines.raw))
Lines2 <- chartr("[]", "==", Lines)
DF <- read.table(textConnection(Lines2), as.is = TRUE, sep = "=", fill = TRUE)
L <- DF$V1 == ""
subset(transform(DF, V3 = V2[which(L)[cumsum(L)]])[1:3], V1 != "")


On 6/12/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> Here is some code. It replaces [ and ] with = sign and reads the result
> into a data frame, DF.  DF2 is similar except the section is now in V3.
> DF3 is like like DF2 except sections are carried forward and finally
> we remove the rows which only had sections.
>
> Lines.raw <- "[Section1]
> var1=value1
> var2=value2
> [Section2]
> A=value3
> B=value4
> "
>
> Lines <- readLines(textConnection(Lines.raw))
> Lines2 <- chartr("[]", "==", Lines)
> DF <- read.table(textConnection(Lines2), as.is = TRUE, sep = "=", fill = TRUE)
> DF2 <- transform(DF, V3 = ifelse(V1 == "", V2, NA))
> L <- !is.na(DF2$V3)
> DF3 <- transform(DF2, V3 = V3[c(NA, which(L))[cumsum(L)+1]])
> subset(DF3, V1 != "")
>
> The result is:
>
>    V1     V2       V3
> 2 var1 value1 Section1
> 3 var2 value2 Section1
> 5    A value3 Section2
> 6    B value4 Section2
>
>
> On 6/12/07, Earl F. Glynn <efg at stowers-institute.org> wrote:
> > I need to process some datasets where the configuration information was
> > stored in .INI-like files, i.e., text files with sections like this:
> >
> > [Section1]
> > var1=value1
> > var2=value2
> > [Section2]
> > A=value3
> > B=value4
> >
> > ...
> >
> > >From Google and other searches I haven't found any package, or function
> > within a package, that reads .INI files into an R list, or other data
> > structure.
> >
> >
> >
> > Any suggestions, or do I need to write my own?
> >
> > efg
> >
> > Earl F. Glynn
> > Stowers Institute for Medical Research
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>


From ted.harding at nessie.mcc.ac.uk  Wed Jun 13 01:24:10 2007
From: ted.harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Wed, 13 Jun 2007 00:24:10 +0100 (BST)
Subject: [R] Appropriate regression model for categorical variables
In-Reply-To: <11083540.post@talk.nabble.com>
Message-ID: <XFMail.070613002410.ted.harding@nessie.mcc.ac.uk>

On 12-Jun-07 17:45:44, Tirthadeep wrote:
> 
> Dear users,
> In my psychometric test i have applied logistic regression
> on my data. My data consists of 50 predictors (22 continuous
> and 28 categorical) plus a binary response. 
> 
> Using glm(), stepAIC() i didn't get satisfactory result as
> misclassification rate is too high. I think categorical
> variables are responsible for this debacle. Some of them have
> more than 6 level (one has 10 level).
> 
> Please suggest some better regression model for this situation.
> If possible you can suggest some article.

I hope you have a very large number of cases in your data!

The minimal complexity of the 28 categorical variables compatible
with your description is

  1 factor at 10 levels
  2 factors at 7 levels
 25 factors at 2 levels

which corresponds to (2^25)*(7^2)*10 = 16441671680 ~= 1.6e10
distinct possible combinations of levels of the factors. Your
true factors may have far more than this.

Unless you have more cases than this in your data, you are
likely to fall into what is called "linear separation", in which
the logistic regression will find a perfect predictor for your
binary outcome. This prefect predictor may well not be unique
(indeed if you have only a few hundred cases there will probably
be millions of them).

Therefore your logistic reggression is likely to be meaningless.

I can only suggest that you consider very closely how to

a) reduce the numbers of levels in some of your factors,
   by coalescing levels together;
b) defining new factors in terms of the old so as to reduce
   the total number of factors (which may include ignoring
   some factors altogether)

so that you end up with new categorical variables whose total
number of possible combinations is much smaller (say at most 1/5)
of the number of cases in your data.

In summary: you have to many explanatory variables.

Best wishes,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 13-Jun-07                                       Time: 00:23:49
------------------------------ XFMail ------------------------------


From ted.harding at nessie.mcc.ac.uk  Wed Jun 13 01:36:02 2007
From: ted.harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Wed, 13 Jun 2007 00:36:02 +0100 (BST)
Subject: [R] Generating artificial datasets with a specific correlati
In-Reply-To: <loom.20070612T225123-579@post.gmane.org>
Message-ID: <XFMail.070613003602.ted.harding@nessie.mcc.ac.uk>

On 12-Jun-07 20:54:05, Ken Knoblauch wrote:
> see mvrnorm in MASS and especially the empirical argument
> 
> James Milks <james.milks <at> wright.edu> writes:
> 
> 
>> I need to create artificial datasets with specific correlation  
>> coefficients (i.e. a dataset that returns r = 0.30, etc.) as examples 
>> for a lab I am teaching this summer.  Is there a way to do that in R?
>> 
>> Thanks.
>> 
>> Jim Milks

Alternatively, if you would prefer your datasets to have non-nomal
distributions, consider the fact that if X and Y are independent,
each with mean 0 and variance 1, then the correlation coefficient
between (X + a*Y)  and (X - a*Y) is

  (1 - a^2)/(1 + a^2)

so if you choose a = sqrt((1 - r)/(1 + r)) then these will have
correlation coefficient r.

So generate X and Y as you please, and then continue as above.

Best wishes,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 13-Jun-07                                       Time: 00:35:59
------------------------------ XFMail ------------------------------


From Norm.Good at csiro.au  Wed Jun 13 02:27:47 2007
From: Norm.Good at csiro.au (Norm.Good at csiro.au)
Date: Wed, 13 Jun 2007 10:27:47 +1000
Subject: [R] Setting a minimum number of observations within an individual
	cluster
Message-ID: <B998A44C8986644EA8029CFE6396A92475D2A5@exqld2-bne.nexus.csiro.au>

Hi

I'm trying to cluster a continuous dataset with a varying number of clusters and with a restriction that each cluster must have more than 'x' number of observations. 

I have tried the clara function, using silhouette to give me the neighbouring cluster mediod of each observation, then merging an observation from a cluster with less than 'x' obs. into its' neighbour, but this comes unstuck if their neighbours also have less than 'x' obs.

So I'm fiddling with dendrogram objects.  Is there any way of using the 'members' attribute to cut a dendrogram to only include branches with more than 'x' members?

An example output from clara with a data set of 1000 obs. and 82 clusters

> cl$clusinfo
      size   max_diss    av_diss isolation
 [1,]    1 0.00000000 0.00000000 0.0000000
 [2,]    3 1.19840221 0.40837142 5.0938561
 [3,]    4 0.16867940 0.07284916 0.5830662
 [4,]    2 0.13380551 0.06690276 0.5687456
 [5,]    3 0.21862177 0.13428115 1.0371933
 [6,]    5 0.10384573 0.05270335 0.5887887
 [7,]    2 0.08547020 0.04273510 0.4846024
 [8,]    4 0.18615254 0.09545067 0.7396865
 [9,]    7 0.15688781 0.08572887 0.6234016
.
.
.
[75,]   11 0.26963387 0.13985980 1.1447836
[76,]    6 0.21439705 0.11953365 0.5754212
[77,]    5 0.21131875 0.12920395 0.5567024
[78,]    3 0.17126227 0.09685930 0.7160261
[79,]    2 0.22622024 0.11311012 0.9457984
[80,]    2 0.10268536 0.05134268 0.5167766
[81,]    1 0.00000000 0.00000000 0.0000000
[82,]    2 0.10018837 0.05009419 0.2474480

Note that all observations from cluster 1 are not necessarily closest to cluster 2.

Cheers

Norm   

Norm Good
Statistician
CMIS/e-Health Research Centre
A joint venture between CSIRO and the Queensland Government
Lvl 20, 300 Adelaide Street BRISBANE QLD 4000
PO Box 10842 Adelaide Street BRISBANE QLD 4000
Ph: 07 3024 1640 Fx: 07 3024 1690 
Em: norm.good at csiro.au? Web: http://e-hrc.net/


From jgilbert.r at gmail.com  Wed Jun 13 03:11:16 2007
From: jgilbert.r at gmail.com (Josh Gilbert)
Date: Tue, 12 Jun 2007 21:11:16 -0400
Subject: [R] PCA  for Binary data
In-Reply-To: <238121.85415.qm@web37210.mail.mud.yahoo.com>
References: <238121.85415.qm@web37210.mail.mud.yahoo.com>
Message-ID: <200706122111.16526.jgilbert.r@gmail.com>

I don't understand, what's wrong with using prcomp in this situation?

On Sunday 10 June 2007 12:50 pm, Ranga Chandra Gudivada wrote:
> Hi,
>
>     I was wondering whether there is any package implementing Principal
> Component Analysis for Binary data
>
>                                               Thanks chandra
>
>
> ---------------------------------
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented, minimal,
> self-contained, reproducible code.


From macq at llnl.gov  Wed Jun 13 03:13:35 2007
From: macq at llnl.gov (Don MacQueen)
Date: Tue, 12 Jun 2007 18:13:35 -0700
Subject: [R] pretty report
In-Reply-To: <cdf817830706121401u54bd6df9nb22b6acdd2e33d6b@mail.gmail.com>
References: <cdf817830706121401u54bd6df9nb22b6acdd2e33d6b@mail.gmail.com>
Message-ID: <p06240801c294f38685ca@[192.168.11.7]>

At 5:01 PM -0400 6/12/07, Weiwei Shi wrote:
>Dear Listers:
>
>I have a couple of data frames to report and each corresponds to
>different condtions, e.g. conditions=c(10, 15, 20, 25). In this
>examples, four data frames need to be exported in a "pretty" report.
>
>I knew Perl has some module for exporting data to Excel and after
>googling, I found R does not.

I use write.table(), name the file with ".xls" as the suffix, then 
outside R I double-click on it and it opens in Excel. Granted, it's a 
text file, and Excel is opening a text file, but none the less, I 
think that qualifies as exporting to Excel, considering that the 
contents of the data frame are now in Excel and one can do whatever 
formatting one wishes to do.  (And this is on a Macintosh, but I 
assume it works in Windows as well.)

>
>So I am wondering if there is a package in R for generating good
>reports. I found package xtable but it seems (if not, please correct
>me) that it can only generate one table for one file.

latex() from the HMisc package will produce pretty reports. Of 
course, that does require learning and using tex or latex, for which 
Sweave can help, as Gabor mentioned.

>
>Thanks for any suggestions,
>
>-W
>
>--
>Weiwei Shi, Ph.D
>Research Scientist
>GeneGO, Inc.

-Don

-- 
---------------------------------
Don MacQueen
Lawrence Livermore National Laboratory
Livermore, CA, USA
925-423-1062
macq at llnl.gov


From irishhacker at gmail.com  Wed Jun 13 03:24:41 2007
From: irishhacker at gmail.com (Robert Wilkins)
Date: Tue, 12 Jun 2007 20:24:41 -0500
Subject: [R] Awk and Vilno
Message-ID: <874da0b40706121824q6e640901n380c7c535ed387c@mail.gmail.com>

In clinical trial data preparation and many other data situations, the
statistical programmer needs to merge and re-merge multiple input
files countless times. A syntax for merging files that is clear and
concise is very important for the statistical programmer's
productivity.

Here is how Vilno does it:

inlist dataset1 dataset2 dataset3 ;
joinby variable1 variable2  where ( var3<=var4 ) ;

Each column in a dataset has a variable name ( variable1, variable2,
var3, var4 ).
You are merging three input datafiles: dataset1, dataset2, and dataset3.
The joinby statement asks for a many-to-many join, rather like the SQL
SELECT statement.
[ The mergeby statement asks for a many-to-one join , more efficient ]
[ The readby statement asks for interleaving of rows, the rows don't
"match up" ,
  but one row goes under the preceding row (100 rows + 100 rows -> 200
output rows ]
The join( or merge ) is done with variable1*variable2 subgroups: A row
from dataset1 where variable1=4 and variable2="Sam" can only match to
a row from dataset2 where variable1=4 and variable2="Sam". Also, any
match-ups where it is not the case that var3<=var4 are also excluded.

Here's how the SAS datastep will do it:

merge dataset1 dataset2 dataset3 ;
by variable1 variable2 ;
if ^( var3<=var4 ) then delete ;

[Actually, the SAS datastep can only do a many-to-one join, but you
can do a PROC SQL paragraph to do an SQL SELECT statement, then export
the results to a SAS datastep afterwards.]

The point is : there are lots of data preparation scenarios where
large numbers of merges need to be done. This is an example where
Vilno and SAS are easier to use than the competition. I'm sure an Awk
programmer can come up with something, but the result would be
awkward.

You can also find other data preparation problems where the best tool
is Awk. Looking through "Sed & Awk" (O'Reilly) gives a good idea. I'm
not expert Awk-er sure, but I think I can see that Awk and Vilno are
really like apples and oranges.

For scanning inconsistently structured ASCII data files, where
different rows have different column specifications, Awk is a better
tool.

For data problems that lend themselves to UNIX-style regular
expressions, Awk, again, is a great tool.

If you have a data manipulation problem that is incredibly simple,
then converting an ascii data file to binary, and then back, may not
seem worth it. Awk, again, wins. But the asciitobinary and
binarytoascii statement ( there and back ) only takes 4 lines or so,
so Vilno is really not that bad.

Certain apsects of Vilno and SAS are a bit more user-friendly:
Each column has a variable name, such as "PatientID".
Awk uses $1, $2, $3 , as variable names for columns. Not user-friendly.
In both Vilno and SAS (and SQL) the possibility of "MISSING" ( or
"NULL" ) is built into the data values held in the columns. So you
don't have to use separate boolean variables to track MISSING vs
NOT-MISSING. Very convenient.

Vilno does have a lot of functionality that is a lot harder to
implement in most other programming languages. (You can implement that
functionality, but it would take a ton of code - the three merge-in
options for Vilno are an example).

The upshot:

Awk is a hammer.
Vilno is a screwdriver.


From adschai at optonline.net  Wed Jun 13 04:04:44 2007
From: adschai at optonline.net (adschai at optonline.net)
Date: Wed, 13 Jun 2007 02:04:44 +0000 (GMT)
Subject: [R] specify constraints in maximum likelihood
Message-ID: <e4add7bf91a5.466f50bc@optonline.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070613/562e9b48/attachment.pl 

From ggrothendieck at gmail.com  Wed Jun 13 04:06:55 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 12 Jun 2007 22:06:55 -0400
Subject: [R] Read Windows-like .INI files into R data structure?
In-Reply-To: <971536df0706121623p14725cbbp82610f2d3149a9e7@mail.gmail.com>
References: <f4min7$hu5$1@sea.gmane.org>
	<971536df0706121042r1aabcf03qf69ca6a117afab38@mail.gmail.com>
	<971536df0706121623p14725cbbp82610f2d3149a9e7@mail.gmail.com>
Message-ID: <971536df0706121906n12bcfd96pb2c45f7e137ab74d@mail.gmail.com>

Here is yet another simplification.  This one uses na.locf from the zoo
package to shorten it further and also make it easier to understand.

Below we have one line to read in the .ini file, one line to transform the
characters [ and ] to = and =, the read.table line parses the result and
the next line carries forward the section names and removes the section
lines. Lines.raw is as before:

library(zoo)

# Lines <- readLines("myfile.ini")
Lines <- readLines(textConnection(Lines.raw))
Lines2 <- chartr("[]", "==", Lines)
DF <- read.table(textConnection(Lines2), as.is = TRUE, sep = "=", fill = TRUE)
subset(transform(DF, V3 = na.locf(ifelse(V1 == "", V2, NA))), V1 != "")


On 6/12/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> In thinking about this a bit more here is an even shorter solution where
> Lines.raw is as before:
>
> # Lines <- readLines("myfile.ini")
> Lines <- readLines(textConnection(Lines.raw))
> Lines2 <- chartr("[]", "==", Lines)
> DF <- read.table(textConnection(Lines2), as.is = TRUE, sep = "=", fill = TRUE)
> L <- DF$V1 == ""
> subset(transform(DF, V3 = V2[which(L)[cumsum(L)]])[1:3], V1 != "")
>
>
> On 6/12/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> > Here is some code. It replaces [ and ] with = sign and reads the result
> > into a data frame, DF.  DF2 is similar except the section is now in V3.
> > DF3 is like like DF2 except sections are carried forward and finally
> > we remove the rows which only had sections.
> >
> > Lines.raw <- "[Section1]
> > var1=value1
> > var2=value2
> > [Section2]
> > A=value3
> > B=value4
> > "
> >
> > Lines <- readLines(textConnection(Lines.raw))
> > Lines2 <- chartr("[]", "==", Lines)
> > DF <- read.table(textConnection(Lines2), as.is = TRUE, sep = "=", fill = TRUE)
> > DF2 <- transform(DF, V3 = ifelse(V1 == "", V2, NA))
> > L <- !is.na(DF2$V3)
> > DF3 <- transform(DF2, V3 = V3[c(NA, which(L))[cumsum(L)+1]])
> > subset(DF3, V1 != "")
> >
> > The result is:
> >
> >    V1     V2       V3
> > 2 var1 value1 Section1
> > 3 var2 value2 Section1
> > 5    A value3 Section2
> > 6    B value4 Section2
> >
> >
> > On 6/12/07, Earl F. Glynn <efg at stowers-institute.org> wrote:
> > > I need to process some datasets where the configuration information was
> > > stored in .INI-like files, i.e., text files with sections like this:
> > >
> > > [Section1]
> > > var1=value1
> > > var2=value2
> > > [Section2]
> > > A=value3
> > > B=value4
> > >
> > > ...
> > >
> > > >From Google and other searches I haven't found any package, or function
> > > within a package, that reads .INI files into an R list, or other data
> > > structure.
> > >
> > >
> > >
> > > Any suggestions, or do I need to write my own?
> > >
> > > efg
> > >
> > > Earl F. Glynn
> > > Stowers Institute for Medical Research
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
>


From ral at lcfltd.com  Wed Jun 13 04:26:17 2007
From: ral at lcfltd.com (Robert A LaBudde)
Date: Tue, 12 Jun 2007 22:26:17 -0400
Subject: [R] pretty report
In-Reply-To: <p06240801c294f38685ca@[192.168.11.7]>
References: <cdf817830706121401u54bd6df9nb22b6acdd2e33d6b@mail.gmail.com>
	<p06240801c294f38685ca@[192.168.11.7]>
Message-ID: <0JJJ007SSYRUKNXB@vms048.mailsrvcs.net>

At 09:13 PM 6/12/2007, Don wrote:
>At 5:01 PM -0400 6/12/07, Weiwei Shi wrote:
> >Dear Listers:
> >
> >I have a couple of data frames to report and each corresponds to
> >different condtions, e.g. conditions=c(10, 15, 20, 25). In this
> >examples, four data frames need to be exported in a "pretty" report.
> >
> >I knew Perl has some module for exporting data to Excel and after
> >googling, I found R does not.
>
>I use write.table(), name the file with ".xls" as the suffix, then
>outside R I double-click on it and it opens in Excel. Granted, it's a
>text file, and Excel is opening a text file, but none the less, I
><snip>

Note that files with a ".csv" extension are also associated with 
Excel and can opened with a double-click. Comma-separated-value files 
also can be unambiguously loaded by Excel without parsing.

================================================================
Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
824 Timberlake Drive                     Tel: 757-467-0954
Virginia Beach, VA 23464-3239            Fax: 757-467-2947

"Vere scire est per causas scire"


From joshkalish at gmail.com  Wed Jun 13 05:05:15 2007
From: joshkalish at gmail.com (Josh Kalish)
Date: Tue, 12 Jun 2007 23:05:15 -0400
Subject: [R]  Stock Price Correlation to Index Price Levels
Message-ID: <000201c7ad67$aba0fe40$650fa8c0@EngleLap>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070612/2ff0795a/attachment.pl 

From spencer.graves at pdf.com  Wed Jun 13 05:17:35 2007
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 12 Jun 2007 20:17:35 -0700
Subject: [R] PCA  for Binary data
In-Reply-To: <200706122111.16526.jgilbert.r@gmail.com>
References: <238121.85415.qm@web37210.mail.mud.yahoo.com>
	<200706122111.16526.jgilbert.r@gmail.com>
Message-ID: <466F61CF.1090704@pdf.com>

      The problem with applying prcomp to binary data is that it's not 
clear what problem you are solving. 

      The standard principal components and factor analysis models 
assume that the observations are linear combinations of unobserved 
"common" factors (shared variability), normally distributed, plus normal 
noise, independent between observations and variables.  Those 
assumptions are clearly violated for binary data. 

      RSiteSearch("PCA for binary data") produced references to 'ade4' 
and 'FactoMineR'.  Have you considered these?  I have not used them, but 
FactoMineR included functions for 'Multiple Factor Analysis for Mixed 
[quantitative and qualitative] Data'
  
      Hope this helps. 
      Spencer Graves

Josh Gilbert wrote:
> I don't understand, what's wrong with using prcomp in this situation?
>
> On Sunday 10 June 2007 12:50 pm, Ranga Chandra Gudivada wrote:
>   
>> Hi,
>>
>>     I was wondering whether there is any package implementing Principal
>> Component Analysis for Binary data
>>
>>                                               Thanks chandra
>>
>>
>> ---------------------------------
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html and provide commented, minimal,
>> self-contained, reproducible code.
>>     
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Augusto.Sanabria at ga.gov.au  Wed Jun 13 05:23:30 2007
From: Augusto.Sanabria at ga.gov.au (Augusto.Sanabria at ga.gov.au)
Date: Wed, 13 Jun 2007 13:23:30 +1000
Subject: [R] data from graph [SEC=UNCLASSIFIED]
Message-ID: <9B2962F493D17F4F81A9211B1F9C56FB0154F685@mail.ga.gov.au>

Jam,

If you use "fpot" the GPD of package "evd" to calculate your 
return periods, you can generate the table you want by
using the following commands:

RP <- c(10,100,500,1000)   #return periods
rf <- your clean vector of rainfall data
thres <- the threshold for your data
nopy <- number of observations per year
rainf <- c()

For(i in 1:length(RP) ){
   q = fpot(rf,thres,mper=RP[i],npp=nopy,std.err=FALSE)
   rainf[i] <- q$estimate[1]
}
#The next line prints the return periods:
plot(RP,rainf,log="x",type="l",ylab="rainfall",xlab="Return Period (yrs)" )

#The next line prints the table you want:
cbind(RP,rainf)

Hope it helps,

Augusto


--------------------------------------------
Augusto Sanabria. MSc, PhD.
Mathematical Modeller
Risk & Impact Analysis Group
Geospatial & Earth Monitoring Division
Geoscience Australia (www.ga.gov.au)
Cnr. Jerrabomberra Av. & Hindmarsh Dr.
Symonston ACT 2601
Ph. (02) 6249-9155
 
 




-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of umarporn charusombat
Sent: Wednesday, 13 June 2007 8:35
To: r-help at stat.math.ethz.ch
Subject: [R] data from graph


hi
i just learn how to use R in my research
i used extreame value package to get the return level of rainfall. the output
i got as the graph plot between return level and period. i wonder how i can
get the value from the graph as a table format. please help me thanks jam

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From spencer.graves at pdf.com  Wed Jun 13 05:29:15 2007
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 12 Jun 2007 20:29:15 -0700
Subject: [R] How do I obtain standard error of each estimated
 coefficients in polr
In-Reply-To: <e088e3376544.466ca686@optonline.net>
References: <e088e3376544.466ca686@optonline.net>
Message-ID: <466F648B.80900@pdf.com>

      I'm confused: 

      Have you considered the 'examples' in the 'polr' help file?  The 
first example ends "summary(house.plr)".  The print of this summary 
includes standard errors.  If you want those numbers for subsequent 
computations, you can try str(summary(house.plr)) or 
names(summary(house.plr)).  If you want to be more sophisticated, 
class(summary(house.plr)) says it is "summary.polr".  Then  
methods(class="summary.polr") says there exists a function 
'print.summary.polr', which is however, 'invisible'.  If you want to see 
it, "getAnywhere('print.summary.polr')" will produce the code. 

      If this does NOT answer your question, please provide commented, 
minimal, self-contained, reproducible code, as requested in the posting 
guide "www.R-project.org/posting-guide.html". 

      Hope this helps. 
      Spencer Graves

adschai at optonline.net wrote:
> Hi,
>
> I obtained all the coefficients that I need from polr. However, I'm wondering how I can obtain the standard error of each estimated coefficient? I saved the Hessian and do something like summary(polrObj), I don't see any standard error like when doing regression using lm. Any help would be really appreciated. Thank you!
>
> - adschai
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From s.blomberg1 at uq.edu.au  Wed Jun 13 05:37:03 2007
From: s.blomberg1 at uq.edu.au (Simon Blomberg)
Date: Wed, 13 Jun 2007 13:37:03 +1000
Subject: [R] PCA  for Binary data
In-Reply-To: <466F61CF.1090704@pdf.com>
References: <238121.85415.qm@web37210.mail.mud.yahoo.com>
	<200706122111.16526.jgilbert.r@gmail.com>  <466F61CF.1090704@pdf.com>
Message-ID: <1181705823.1726.48.camel@sib-sblomber01d.sib.uq.edu.au>

You might try (detrended) correspondence analysis, which is designed for
"count" data, if it makes sense to treat your binary data  that way.
I've used ade4 and also vegan, and they are both good packages for these
types of ordinations. You could also look at non-metric multidimensional
scaling. There seems to be 2 "schools" of ordination. The Europeans like
eigenanalysis methods (PCA, correspondence analysis, multiple
correspondence analysis, coinertia analysis etc.). The Americans seem to
prefer MDS.

Cheers,

Simon.

 This is On Tue, 2007-06-12 at 20:17 -0700, Spencer Graves wrote:
> The problem with applying prcomp to binary data is that it's not 
> clear what problem you are solving. 
> 
>       The standard principal components and factor analysis models 
> assume that the observations are linear combinations of unobserved 
> "common" factors (shared variability), normally distributed, plus normal 
> noise, independent between observations and variables.  Those 
> assumptions are clearly violated for binary data. 
> 
>       RSiteSearch("PCA for binary data") produced references to 'ade4' 
> and 'FactoMineR'.  Have you considered these?  I have not used them, but 
> FactoMineR included functions for 'Multiple Factor Analysis for Mixed 
> [quantitative and qualitative] Data'
>   
>       Hope this helps. 
>       Spencer Graves
> 
> Josh Gilbert wrote:
> > I don't understand, what's wrong with using prcomp in this situation?
> >
> > On Sunday 10 June 2007 12:50 pm, Ranga Chandra Gudivada wrote:
> >   
> >> Hi,
> >>
> >>     I was wondering whether there is any package implementing Principal
> >> Component Analysis for Binary data
> >>
> >>                                               Thanks chandra
> >>
> >>
> >> ---------------------------------
> >>
> >>
> >> 	[[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at stat.math.ethz.ch mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html and provide commented, minimal,
> >> self-contained, reproducible code.
> >>     
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
-- 
Simon Blomberg, BSc (Hons), PhD, MAppStat. 
Lecturer and Consultant Statistician 
Faculty of Biological and Chemical Sciences 
The University of Queensland 
St. Lucia Queensland 4072 
Australia

Room 320, Goddard Building (8)
T: +61 7 3365 2506 
email: S.Blomberg1_at_uq.edu.au 

The combination of some data and an aching desire for 
an answer does not ensure that a reasonable answer can 
be extracted from a given body of data. - John Tukey.


From ian.watson at mq.edu.au  Wed Jun 13 23:47:50 2007
From: ian.watson at mq.edu.au (Ian Watson)
Date: Wed, 13 Jun 2007 14:47:50 -0700
Subject: [R] Design library installation problem
Message-ID: <46706606.6070702@mq.edu.au>

Dear Listers

I have tried to install Frank Harrell's two libaries: Hmisc 
and Design.

I found that Hmisc was listed in the list of packages from 
the Install Packages command on the Packages menu, but 
Design was not. I installed Hmisc from this list, and when I 
  issued the library(Hmisc) command, it loaded into memory 
correctly.

I then copied the Design 1.1-1.zip file from the 
http://lib.stat.cmu.edu/S/Harrell/library/r/ site and used 
the Install Packages from Local Zip file command.

I received no error messages and a visual inspection of the 
R\library directory shows Design has been installed.

However, when I issued the library(Design) command I get the 
following error message:

Error in library(Design) : 'Design' is not a valid package 
-- installed < 2.0.0?


I also notice, from a visual inspection of the 
R\library\Design\R directory that there is only one file: 
design. In other directories, eg. R\library\Hmisc\R there 
are usually 3 files:
Hmisc
Hmisc.rdx
Hmisc.rdb

I am new to R, and a bit lost. I have read the R-admin.pdf 
documentation on packages but am still unsure how to proceed 
from here.

I would appreciate any advice, and any answers to the 
following questions:

1) is there a reason why Design is not listed in the Install 
Packages list as Hmisc is?
2) have I done the correct thing by way of manual 
installation of Design?
3) is the absence of 2 other Design files (rdx, rdb) the 
reason for my failed installation?
4) what should I try now?


I am using R.2.5.0 on Windows XP.

Kind regards
Ian


From christophe at pallier.org  Wed Jun 13 07:43:53 2007
From: christophe at pallier.org (Christophe Pallier)
Date: Wed, 13 Jun 2007 07:43:53 +0200
Subject: [R] Awk and Vilno
In-Reply-To: <874da0b40706121824q6e640901n380c7c535ed387c@mail.gmail.com>
References: <874da0b40706121824q6e640901n380c7c535ed387c@mail.gmail.com>
Message-ID: <dea6cb960706122243p308262a0qac8418aa19178168@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070613/15b78ba3/attachment.pl 

From ripley at stats.ox.ac.uk  Wed Jun 13 08:00:46 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 13 Jun 2007 07:00:46 +0100 (BST)
Subject: [R] Using dll with Visual Studio Compiler
In-Reply-To: <BAY116-DAV4D63C2B088EC584C18B4BB8190@phx.gbl>
References: <BAY116-DAV4D63C2B088EC584C18B4BB8190@phx.gbl>
Message-ID: <Pine.LNX.4.64.0706130656330.12760@gannet.stats.ox.ac.uk>

On Tue, 12 Jun 2007, Ian McCarthy wrote:

> Hi,
>
> I have created a dll in Fortran and used the Visual Studio 2005 
> Compiler. I've read that certain problems can arise based on the

Since Visual Studio does not create Fortran, that's a bit vague.  And let 
us assume you are on Win32, but you failed to say.

> compiler used and that these problems can sometimes cause R not to be 
> able to access everything appropriately, but I've not found how to fix 
> any of these problems. Specifically, after using dyn.load, I know the 
> dll has been loaded because it is listed in getLoadedDLLs(), but when I 
> try is.loaded("subroutine name"), it returns FALSE. I saw that this was 
> mentioned in the manual, but it too offers little help for a solution.

'The manual'?  If you mean an R manual, it offers a lot more details than 
you are giving us to go on.  Try using VS or pedump to see what is 
exported from your DLL under what names.  (pedump is in the R tools kit as 
well as elsewhere.)


> Any advice would be greatly appreciated.
>
> Cheers,
>
> Ian McCarthy
> Department of Economics
> Indiana University
> 100 S. Woodlawn
> Bloomington, IN 47405-7104
> http://mypage.iu.edu/~imccarth<http://mypage.iu.edu/~imccarth>
> imccarth at indiana.edu<mailto:imccarth at indiana.edu>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From brown_emu at yahoo.com  Wed Jun 13 08:04:33 2007
From: brown_emu at yahoo.com (Stephen Tucker)
Date: Tue, 12 Jun 2007 23:04:33 -0700 (PDT)
Subject: [R] passing (or obtaining) index or element name of list to FUN in
	lapply()
Message-ID: <34506.83532.qm@web39710.mail.mud.yahoo.com>

Hello everyone,

I wonder if there is a way to pass the index or name of a list to a
user-specified function in lapply(). For instance, my desired effect is
something like the output of 

> L <- list(jack=4098,sape=4139)
> lapply(seq(along=L),function(i,x) if(i==1) "jack" else "sape",x=L)
[[1]]
[1] "jack"

[[2]]
[1] "sape"

> lapply(seq(along=L),function(i,x) if(names(x)[i]=="jack") 1 else 2,x=L)
[[1]]
[1] 1

[[2]]
[1] 2

But by passing L as the first argument of lapply(). I thought there was a
tangentially-related post on this mailing list in the past but I don't recall
that it was ever addressed directly (and I can't seem to find it now). The
examples above are perfectly good alternatives especially if I wrap each of
the lines in "names<-"() to return lists with appropriate names assigned, but
it feels like I am essentially writing a FOR-LOOP - though I was surprised to
find that speed-wise, it doesn't seem to make much of a difference (unless I
have not selected a rigorous test):

> N <- 10000
> y <- runif(N)
## looping through elements of y
> system.time(lapply(y,
+                    function(x) {
+                      set.seed(222)
+                      mean(rnorm(1e4,x,1))
+                    }))
[1] 21.00  0.17 21.29    NA    NA
## looping through indices
> system.time(lapply(1:N,
+                    function(x,y) {
+                      set.seed(222)
+                      mean(rnorm(1e4,y[x],1))
+                      },y=y))
[1] 21.09  0.14 21.26    NA    NA

In Python, there are methods for Lists and Dictionaries called enumerate(),
and iteritems(), respectively. Example applications:

## a list
L = ['a','b','c']
[x for x in enumerate(L)]
## returns index of list along with the list element
[(0, 'a'), (1, 'b'), (2, 'c')]

## a dictionary
D = {'jack': 4098, 'sape': 4139}
[x for x in D.iteritems()]
## returns element key (name) along with element contents
[('sape', 4139), ('jack', 4098)]

And this is something of the effect I was looking for...

Thanks to all,

Stephen


From ripley at stats.ox.ac.uk  Wed Jun 13 08:20:57 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 13 Jun 2007 07:20:57 +0100 (BST)
Subject: [R] PCA  for Binary data
In-Reply-To: <466F61CF.1090704@pdf.com>
References: <238121.85415.qm@web37210.mail.mud.yahoo.com>
	<200706122111.16526.jgilbert.r@gmail.com> <466F61CF.1090704@pdf.com>
Message-ID: <Pine.LNX.4.64.0706130704540.12760@gannet.stats.ox.ac.uk>

On Tue, 12 Jun 2007, Spencer Graves wrote:

>      The problem with applying prcomp to binary data is that it's not
> clear what problem you are solving.
>
>      The standard principal components and factor analysis models
> assume that the observations are linear combinations of unobserved
> "common" factors (shared variability), normally distributed, plus normal
> noise, independent between observations and variables.  Those
> assumptions are clearly violated for binary data.
>
>      RSiteSearch("PCA for binary data") produced references to 'ade4'
> and 'FactoMineR'.  Have you considered these?  I have not used them, but
> FactoMineR included functions for 'Multiple Factor Analysis for Mixed
> [quantitative and qualitative] Data'

AFAIK, that is not using 'factor analysis' in the same sense as e.g. 
factanal().

Continuous underlying variables with binary manifest variables is part of 
latent variable analysis.  Package 'ltm' covers a variety of such models.

But to begin to give advice we would need to know the scientific problem 
for which Ranga Chandra Gudivada is looking for a tool. Simon Blomberg 
mentioned ordination, but that is only one of several classes of uses of 
PCA (which finds a linear subspace that both has maximal variance within 
and is least-squares fitting to the data).

>
>      Hope this helps.
>      Spencer Graves
>
> Josh Gilbert wrote:
>> I don't understand, what's wrong with using prcomp in this situation?
>>
>> On Sunday 10 June 2007 12:50 pm, Ranga Chandra Gudivada wrote:
>>
>>> Hi,
>>>
>>>     I was wondering whether there is any package implementing Principal
>>> Component Analysis for Binary data
>>>
>>>                                               Thanks chandra
>>>
>>>
>>> ---------------------------------
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html and provide commented, minimal,
>>> self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From brown_emu at yahoo.com  Wed Jun 13 08:25:41 2007
From: brown_emu at yahoo.com (Stephen Tucker)
Date: Tue, 12 Jun 2007 23:25:41 -0700 (PDT)
Subject: [R] Viewing a data object
In-Reply-To: <466E7B310200006500006405@pgn.com>
Message-ID: <499415.96653.qm@web39706.mail.mud.yahoo.com>

Hi Horace,

I have also thought that it may be useful but I don't know of any Object
Explorer available for R.

However, (you may alread know this but) 
(1) you can view your list of objects in R with objects(), 
(2) view objects in a spreadsheet-like table (if they are matrices or data
frames) with invisible(edit(objectName)) [which isn't easy on the fingers].
fix(objectName) is also a shorter option but it has the side effect of
possibly changing your object when you close the viewing data. For instance,
this can happen if you mistakenly type something into a cell; it can also
change your column classes when you don't - for example:

> options(stringsAsFactors=TRUE)
> x <- data.frame(letters[1:5],1:5)
> sapply(x,class)
letters.1.5.         X1.5 
    "factor"    "integer" 
> fix(x) # no user-changes made
> sapply(x,class)
letters.1.5.         X1.5 
    "factor"    "numeric" 

(3) I believe Deepayan Sarkar contributed the tab-completion capability at
the command line. So unless you have a lot of objects beginning with
'AuroraStoch...' you should be able to type a few letters and let the
auto-completion handle the rest.

Best regards,

ST


--- Horace Tso <Horace.Tso at pgn.com> wrote:

> Dear list,
> 
> First apologize that this is trivial and just betrays my slothfulness at
> the keyboard. I'm sick of having to type a long name just to get a glimpse
> of something. For example, if my data frame is named
> 'AuroraStochasticRunsJune1.df" and I want to see what the middle looks
> like, I have to type
> 
> AuroraStochasticRunsJune1.df[ 400:500, ]
> 
> And often I'm not even sure rows 400 to 500 are what I want to see.  I
> might have to type the same line many times.
> 
> Is there sort of a R-equivalence of the Object Explorer, like in Splus,
> where I could mouse-click an object in a list and a window pops up?  Short
> of that, is there any trick of saving a couple of keystrokes here and
> there?
> 
> Thanks for tolerating this kind of annoying questions.
> 
> H.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 



 
____________________________________________________________________________________
Sucker-punch spam with award-winning protection.


From ssls.sddd at gmail.com  Wed Jun 13 08:27:01 2007
From: ssls.sddd at gmail.com (ssls sddd)
Date: Tue, 12 Jun 2007 23:27:01 -0700
Subject: [R] PCA for Binary data
In-Reply-To: <Pine.LNX.4.64.0706130704540.12760@gannet.stats.ox.ac.uk>
References: <238121.85415.qm@web37210.mail.mud.yahoo.com>
	<200706122111.16526.jgilbert.r@gmail.com> <466F61CF.1090704@pdf.com>
	<Pine.LNX.4.64.0706130704540.12760@gannet.stats.ox.ac.uk>
Message-ID: <b87120290706122327r79bf131anc681df04b37fed62@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070612/b3a4da4b/attachment.pl 

From jizhang at chori.org  Tue Jun 12 00:14:04 2007
From: jizhang at chori.org (Jiong Zhang, PhD)
Date: Mon, 11 Jun 2007 15:14:04 -0700
Subject: [R] if statement
Message-ID: <229c5cdd230b0248b85969e7a149c336@mail.chori.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070611/e611cd5d/attachment.pl 

From megh700004 at yahoo.com  Tue Jun 12 18:11:38 2007
From: megh700004 at yahoo.com (Megh Dal)
Date: Tue, 12 Jun 2007 09:11:38 -0700 (PDT)
Subject: [R] Panel data
Message-ID: <651210.53294.qm@web58101.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070612/06c3458c/attachment.pl 

From taara_isa at hotmail.com  Tue Jun 12 19:56:55 2007
From: taara_isa at hotmail.com (taivo)
Date: Tue, 12 Jun 2007 10:56:55 -0700 (PDT)
Subject: [R] Trouble making JRI.jar with Ubuntu and Java6
Message-ID: <11083776.post@talk.nabble.com>


Hi,

Forum newb here, looking for some help. Have been trying to install an
R-Java interface to make R calls from Java. JRI's configure script runs
fine, but when it comes to make, I get the "error: too few arguments to
function 'R_ParseVector'"

Java runs fine. R runs fine. But I can't get this .jar file created.
<grumble>

Any help would be appreciated immensely,

Taivo
Ubuntu FeistyFawn, java-6-sun-1.6.0.00, R 2.5

p.s. Here's the screen output:

make -C src JRI.jar
make[1]: Entering directory `/home/taivo/coop_summer2007/r/JRI/src'
gcc -std=gnu99 -c -o Rengine.o Rengine.c -g -Iinclude  -DRIF_HAS_CSTACK
-DRIF_HAS_RSIGHAND -g -O2
-I/usr/lib/jvm/java-1.5.0-sun-1.5.0.11/jre/../include
-I/usr/lib/jvm/java-1.5.0-sun-1.5.0.11/jre/../include/linux -fPIC
-I/usr/lib/jvm/java-1.5.0-sun-1.5.0.11/jre/../include
-I/usr/lib/jvm/java-1.5.0-sun-1.5.0.11/jre/../include/linux
-I/usr/share/R/include -I/usr/share/R/include -I/usr/share/R/include
Rengine.c: In function ?Java_org_rosuda_JRI_Rengine_rniParse?:
Rengine.c:92: error: too few arguments to function ?R_ParseVector?
make[1]: *** [Rengine.o] Error 1
make[1]: Leaving directory `/home/taivo/coop_summer2007/r/JRI/src'
make: *** [src/JRI.jar] Error 2

-- 
View this message in context: http://www.nabble.com/Trouble-making-JRI.jar-with-Ubuntu-and-Java6-tf3909057.html#a11083776
Sent from the R help mailing list archive at Nabble.com.


From s.blomberg1 at uq.edu.au  Wed Jun 13 08:52:28 2007
From: s.blomberg1 at uq.edu.au (Simon Blomberg)
Date: Wed, 13 Jun 2007 16:52:28 +1000
Subject: [R] if statement
In-Reply-To: <229c5cdd230b0248b85969e7a149c336@mail.chori.org>
References: <229c5cdd230b0248b85969e7a149c336@mail.chori.org>
Message-ID: <1181717548.1726.61.camel@sib-sblomber01d.sib.uq.edu.au>

My solutions are usually too baroque, but does this do what you want?

x <- rnorm(100)
quants <- quantile(x, c(.3, .7))
Case <- rep(2, length(x)) # 2 lies in the middle of the distribution
Case[x <= quants[1]] <- 0
Case[x >= quants[2]] <- 1
Case

Cheers,

Simon.

On Mon, 2007-06-11 at 15:14 -0700, Jiong Zhang, PhD wrote:
> Hi all,
> 
> I have a rather naive question. I have the height of 100 individuals in
> a table and I want to assign the tallest 30% as Case=1 and the bottom
> 30% as Case=0.  How do I do that?
> 
> thanks.
> 
> jiong
>  The email message (and any attachments) is for the sole use of the intended recipient(s) and may contain confidential information.  Any unauthorized review, use, disclosure or distribution is prohibited.  If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message (and any attachments).  Thank You.
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
-- 
Simon Blomberg, BSc (Hons), PhD, MAppStat. 
Lecturer and Consultant Statistician 
Faculty of Biological and Chemical Sciences 
The University of Queensland 
St. Lucia Queensland 4072 
Australia

Room 320, Goddard Building (8)
T: +61 7 3365 2506 
email: S.Blomberg1_at_uq.edu.au 

The combination of some data and an aching desire for 
an answer does not ensure that a reasonable answer can 
be extracted from a given body of data. - John Tukey.


From tirthankar.patnaik at citi.com  Wed Jun 13 09:01:38 2007
From: tirthankar.patnaik at citi.com (Patnaik, Tirthankar )
Date: Wed, 13 Jun 2007 12:31:38 +0530
Subject: [R] Confusion with sapply
Message-ID: <6E2AF71DA2E3F241A66122F3F90F32140DB2A9@exinmb04-bkp.apac.nsroot.net>

Hi,
 I have some confusion in applying a function over a column.

Here's my function. I just need to shift non-March month-ends to March
month-ends. Initially I tried seq.dates, but one cannot give a negative
increment (decrement) here.

return(as.Date(seq.dates(format(xdate,"%m/%d/%Y"),by="months",len=4)[4])
)

Hence this simple function:

> mydate <- as.Date("2006-01-01")
> 
> # Function to shift non-March company-reporting dates to March.
> Set2March <- function(xdate){
+ # Combines non-March months into March months:
+ # Dec2006 -> Mar2007
+ # Mar2006 -> Mar2006
+ # Jun2006 -> Mar2006
+ # Sep2006 -> Mar2006
+ # VERY Specific code.
+     Month <- format(xdate,"%m")
+     wDate <- month.day.year(julian(xdate))
+     if (Month=="12"){
+         wDate$year <- wDate$year + 1
+         wDate$month <- 3
+     }else
+     if (Month=="06"){
+         wDate$month <- 3
+     }else
+     if (Month=="09"){
+         wDate$month <- 3
+         wDate$day <- wDate$day + 1
+     }else warning ("No Changes made to the month, since month is not
one of (6,9,12)")
+     cDate <- chron(paste(wDate$month,wDate$day,wDate$year,sep="/"))
+     return(as.Date(as.yearmon(as.Date(cDate,"%m/%d/%y")),frac=1))
+ }
> Set2March(as.Date("2006-06-30"))
[1] "2006-03-31"
> Set2March(mydate)
[1] "2006-01-31"
Warning message:
No Changes made to the month, since month is not one of (6,9,12) in:
Set2March(mydate) 
> 

Works well when I use it on a single date. Then I try it on a vector:


> dc <- seq(as.Date("2006-01-01"),len=10, by="month")
> dc
 [1] "2006-01-01" "2006-02-01" "2006-03-01" "2006-04-01" "2006-05-01"
"2006-06-01" "2006-07-01" "2006-08-01"
 [9] "2006-09-01" "2006-10-01"


> sapply(as.vector(dc),Set2March)
Error in prettyNum(.Internal(format(x, trim, digits, nsmall, width, 3,
: 
        unimplemented type 'character' in 'asLogical'
> 

What am I missing here? Shouldn't the function work with the sapply
working on each entry?


TIA and best,
-Tir


From knoblauch at lyon.inserm.fr  Wed Jun 13 09:05:55 2007
From: knoblauch at lyon.inserm.fr (Ken Knoblauch)
Date: Wed, 13 Jun 2007 07:05:55 +0000 (UTC)
Subject: [R] if statement
References: <229c5cdd230b0248b85969e7a149c336@mail.chori.org>
	<1181717548.1726.61.camel@sib-sblomber01d.sib.uq.edu.au>
Message-ID: <loom.20070613T085851-597@post.gmane.org>

Simon Blomberg <s.blomberg1 <at> uq.edu.au> writes:

> 
> My solutions are usually too baroque, but does this do what you want?
> 
> x <- rnorm(100)
> quants <- quantile(x, c(.3, .7))
> Case <- rep(2, length(x)) # 2 lies in the middle of the distribution
> Case[x <= quants[1]] <- 0
> Case[x >= quants[2]] <- 1
> Case
> 
> On Mon, 2007-06-11 at 15:14 -0700, Jiong Zhang, PhD wrote:
> > Hi all,
> > 
> > I have a rather naive question. I have the height of 100 individuals in
> > a table and I want to assign the tallest 30% as Case=1 and the bottom
> > 30% as Case=0.  How do I do that?
> > 

Or, how about, 

x <- rnorm(100)
Case <- cut(x,  quantile(x, c(0, 0.3, 0.7, 1)), c(0, 2, 1), TRUE)

ken

-- 
Ken Knoblauch
Inserm U846
Institut Cellule Souche et Cerveau
D?partement Neurosciences Int?gratives
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.pizzerialesgemeaux.com/u846/


From ripley at stats.ox.ac.uk  Wed Jun 13 09:37:31 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 13 Jun 2007 08:37:31 +0100 (BST)
Subject: [R] passing (or obtaining) index or element name of list to FUN
 in lapply()
In-Reply-To: <34506.83532.qm@web39710.mail.mud.yahoo.com>
References: <34506.83532.qm@web39710.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.64.0706130723500.12760@gannet.stats.ox.ac.uk>

On Tue, 12 Jun 2007, Stephen Tucker wrote:

> Hello everyone,
>
> I wonder if there is a way to pass the index or name of a list to a
> user-specified function in lapply(). For instance, my desired effect is
> something like the output of
>
>> L <- list(jack=4098,sape=4139)
>> lapply(seq(along=L),function(i,x) if(i==1) "jack" else "sape",x=L)
> [[1]]
> [1] "jack"
>
> [[2]]
> [1] "sape"

as.list(names(L))

>> lapply(seq(along=L),function(i,x) if(names(x)[i]=="jack") 1 else 2,x=L)
> [[1]]
> [1] 1
>
> [[2]]
> [1] 2

as.list(seq_along(L))

lapply() can be faster than a for-loop, but usually not by much: its main 
advantage is clarity of code.

I think we need a real-life example to see what you are trying to do.

> But by passing L as the first argument of lapply(). I thought there was a
> tangentially-related post on this mailing list in the past but I don't recall
> that it was ever addressed directly (and I can't seem to find it now). The
> examples above are perfectly good alternatives especially if I wrap each of
> the lines in "names<-"() to return lists with appropriate names assigned, but

Try something like

L[] <- lapply(seq_along(L),function(i,x) if(i==1) "jack" else "sape",x=L)

> it feels like I am essentially writing a FOR-LOOP - though I was surprised to
> find that speed-wise, it doesn't seem to make much of a difference (unless I
> have not selected a rigorous test):
>
>> N <- 10000
>> y <- runif(N)
> ## looping through elements of y
>> system.time(lapply(y,
> +                    function(x) {
> +                      set.seed(222)
> +                      mean(rnorm(1e4,x,1))
> +                    }))
> [1] 21.00  0.17 21.29    NA    NA
> ## looping through indices
>> system.time(lapply(1:N,
> +                    function(x,y) {
> +                      set.seed(222)
> +                      mean(rnorm(1e4,y[x],1))
> +                      },y=y))
> [1] 21.09  0.14 21.26    NA    NA
>
> In Python, there are methods for Lists and Dictionaries called enumerate(),
> and iteritems(), respectively. Example applications:
>
> ## a list
> L = ['a','b','c']
> [x for x in enumerate(L)]
> ## returns index of list along with the list element
> [(0, 'a'), (1, 'b'), (2, 'c')]
>
> ## a dictionary
> D = {'jack': 4098, 'sape': 4139}
> [x for x in D.iteritems()]
> ## returns element key (name) along with element contents
> [('sape', 4139), ('jack', 4098)]
>
> And this is something of the effect I was looking for...
>
> Thanks to all,
>
> Stephen
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From billycorg1 at virgilio.it  Wed Jun 13 09:49:37 2007
From: billycorg1 at virgilio.it (billycorg)
Date: Wed, 13 Jun 2007 00:49:37 -0700 (PDT)
Subject: [R] extractor rows from a matrix
Message-ID: <11094459.post@talk.nabble.com>


hi!
i have a little problem: my data's matrix has 1093 rows and 3 columns.
i'd like to extract each rows..

something like this:
ht= my matrix
Dt=(???)=a vector with t=1,2...1093

what can i do?
thank you!

Vincenzo
-- 
View this message in context: http://www.nabble.com/extractor-rows-from-a-matrix-tf3913088.html#a11094459
Sent from the R help mailing list archive at Nabble.com.


From rmi at danishmeat.dk  Wed Jun 13 10:05:37 2007
From: rmi at danishmeat.dk (Rina Miehs)
Date: Wed, 13 Jun 2007 10:05:37 +0200
Subject: [R] export to a dat file that SAS can read
Message-ID: <466FC170.76E3.003F.0@danishmeat.dk>

En indlejret tekst med ukendt tegns?t er blevet fjernet...
Navn: ikke tilg?ngelig
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070613/71a9f04c/attachment.pl 

From ligges at statistik.uni-dortmund.de  Wed Jun 13 10:13:29 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 13 Jun 2007 10:13:29 +0200
Subject: [R] export to a dat file that SAS can read
In-Reply-To: <466FC170.76E3.003F.0@danishmeat.dk>
References: <466FC170.76E3.003F.0@danishmeat.dk>
Message-ID: <466FA729.1060405@statistik.uni-dortmund.de>



Rina Miehs wrote:
> Hello
>  
> i have a data frame in R that some SAS users need to use in their
> programs, and they want it in a dat file, is that possible?

What is a "dat" file?


> and which functions to use for that?

I *guess* write.table() will do the trick, given "dat" is what I guess 
it is...

Uwe Ligges


> my data frame is like this:
>  
>> out13[1:100,]
>              farid            niveau1          niveau3                 
> p1                p3   antal1
> 2    10007995  0.0184891394  4.211306e-10 5.106471e-02 2.594580e-02    
>  3
> 9    10076495  0.0140812953  3.858757e-10 1.065804e-01 3.743271e-02    
>  3
> 10   10081892  0.0241760590  7.429612e-10 1.628295e-02 3.021538e-04    
>  6
> 13   10101395  0.0319517576  3.257375e-10 2.365204e-03 6.633232e-02    
> 19
> 16   10104692  0.0114040787  3.661169e-10 1.566721e-01 4.550663e-02    
>  4
> 17   10113592  0.0167586526  4.229634e-10 6.922003e-02 2.543987e-02    
>  2
> 18   10113697  0.0259205504  2.888646e-10 1.096366e-02 9.118995e-02    
>  6
> 22   10121697 -0.0135341273 -5.507914e-10 1.157417e-01 5.501947e-03    
> 16
> 28   10146495  0.0093514076  3.493487e-10 2.041883e-01 5.340801e-02    
>  4
> 29   10150497  0.0091611504  3.455925e-10 2.089893e-01 5.531904e-02    
>  4
> 36   10171895  0.0089116669  2.956742e-10 2.153844e-01 8.614259e-02    
>  4
> 42   10198295  0.0078515166  3.147140e-10 2.437943e-01 7.314111e-02    
>  5
>  
>  
> Thanks
>  
> Rina
>  
>  
>  
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From christophe at pallier.org  Wed Jun 13 10:16:47 2007
From: christophe at pallier.org (Christophe Pallier)
Date: Wed, 13 Jun 2007 10:16:47 +0200
Subject: [R] export to a dat file that SAS can read
In-Reply-To: <466FC170.76E3.003F.0@danishmeat.dk>
References: <466FC170.76E3.003F.0@danishmeat.dk>
Message-ID: <dea6cb960706130116h2271287fs384cf8ad0bdd994b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070613/a2b10d1f/attachment.pl 

From ligges at statistik.uni-dortmund.de  Wed Jun 13 10:16:03 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 13 Jun 2007 10:16:03 +0200
Subject: [R] extractor rows from a matrix
In-Reply-To: <11094459.post@talk.nabble.com>
References: <11094459.post@talk.nabble.com>
Message-ID: <466FA7C3.7020703@statistik.uni-dortmund.de>



billycorg wrote:
> hi!
> i have a little problem: my data's matrix has 1093 rows and 3 columns.
> i'd like to extract each rows..
> 
> something like this:
> ht= my matrix
> Dt=(???)=a vector with t=1,2...1093

A vector with t=1,2, ..., 1093 and 3 columns is the matrix itself, isn't 
it? If you want to extract a row from a matrix and you do not know how:

Please read the posting guide before posting and do what it says!
Particularly: Please read "An Introduction to R"!

Uwe Ligges


> what can i do?
> thank you!
> 
> Vincenzo


From ligges at statistik.uni-dortmund.de  Wed Jun 13 10:18:09 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 13 Jun 2007 10:18:09 +0200
Subject: [R] Cause of error message in cov function?
In-Reply-To: <3f547caa0706121037i4e295920m75940b175e01a852@mail.gmail.com>
References: <3f547caa0706121037i4e295920m75940b175e01a852@mail.gmail.com>
Message-ID: <466FA841.1050800@statistik.uni-dortmund.de>



Matthew Keller wrote:
> Hi all,
> 
> I have written a script in R that simulates genetically informative
> data - it is posted on my website and available to the public. This is
> my first time to write a script for use by others and am learning that
> it isn't as easy as it seems.
> 
> To the issue. My script runs fine on my machine and on a server I have
> access to, but a user has written me saying that it crashes the first
> time the function "cov" is called up. Below is her error message
> followed by the version of R she's using.
> 
> Can anyone help me out here? I can't recreate her error message. Does
> anyone know what this might have to do with? Is it a version issue
> (she's using R 2.1)? I'd appreciate any help!!

It may be a version issue, but hard to say since we do not know what 
effects.cur() is, not do we have any data to reproduce this.

Uwe Ligges


> Matt
> 
> 
> ERROR MESSAGE:
> 
> cov.varcomp <- cov(t(effects.cur[c("A","AA","D","F","S","E","AGE","AGE.by.A"),]*beta2))
> 
> there is an argument mssing.
> error message:
> 
> Error in mean((a - mean(a)) * (b - mean(b))) :
>        argument "b" is missing, with no default
> 
> 
> SPECIFICS OF HER MACHINE:
> 
>> memory.size()
> [1] 10985480
>> R.Version()
> $platform
> [1] "i386-pc-mingw32"
> $arch
> [1] "i386"
> $os
> [1] "mingw32"
> $system
> [1] "i386, mingw32"
> $status
> [1] ""
> $major
> [1] "2"
> $minor
> [1] "1.0"
> $year
> [1] "2005"
> $month
> [1] "04"
> $day
> [1] "18"
> $language
> [1] "R"
>> .Platform
> $OS.type
> [1] "windows"
> $file.sep
> [1] "/"
> $dynlib.ext
> [1] ".dll"
> $GUI
> [1] "Rgui"
> $endian
> [1] "little"
> $pkgType
> [1] "win.binary"
>


From wl2776 at gmail.com  Wed Jun 13 10:20:57 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Wed, 13 Jun 2007 01:20:57 -0700 (PDT)
Subject: [R] Read Windows-like .INI files into R data structure?
In-Reply-To: <f4min7$hu5$1@sea.gmane.org>
References: <f4min7$hu5$1@sea.gmane.org>
Message-ID: <11094865.post@talk.nabble.com>


One more question, inspired by this one, just to increase my R skill level.

Earl F. Glynn wrote:
> 
> I need to process some datasets where the configuration information was 
> stored in .INI-like files, i.e., text files with sections like this:
> 
> [Section1]
> var1=value1
> var2=value2
> [Section2]
> A=value3
> B=value4
> 
"var1=value1", "A=value3" is almost pure R code.
Is it possible to use this feature to solve the problem? 
That is, something like eval(as.expression("A=value3"))  and assign (store)
the result in "lst$Section2" environment.

"lst" is a newly created list, containing the contents of the file being
processed.
-- 
View this message in context: http://www.nabble.com/Read-Windows-like-.INI-files-into-R-data-structure--tf3908740.html#a11094865
Sent from the R help mailing list archive at Nabble.com.


From ligges at statistik.uni-dortmund.de  Wed Jun 13 10:24:12 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 13 Jun 2007 10:24:12 +0200
Subject: [R] Design library installation problem
In-Reply-To: <46706606.6070702@mq.edu.au>
References: <46706606.6070702@mq.edu.au>
Message-ID: <466FA9AC.3050901@statistik.uni-dortmund.de>



Ian Watson wrote:
> Dear Listers
> 
> I have tried to install Frank Harrell's two libaries: Hmisc 
> and Design.
> 
> I found that Hmisc was listed in the list of packages from 
> the Install Packages command on the Packages menu, but 
> Design was not. I installed Hmisc from this list, and when I 
>   issued the library(Hmisc) command, it loaded into memory 
> correctly.
> 
> I then copied the Design 1.1-1.zip file from the 
> http://lib.stat.cmu.edu/S/Harrell/library/r/ site and used 
> the Install Packages from Local Zip file command.
> I received no error messages and a visual inspection of the 
> R\library directory shows Design has been installed.
> 
> However, when I issued the library(Design) command I get the 
> following error message:
> 
> Error in library(Design) : 'Design' is not a valid package 
> -- installed < 2.0.0?
> 
> 
> I also notice, from a visual inspection of the 
> R\library\Design\R directory that there is only one file: 
> design. In other directories, eg. R\library\Hmisc\R there 
> are usually 3 files:
> Hmisc
> Hmisc.rdx
> Hmisc.rdb
> 
> I am new to R, and a bit lost. I have read the R-admin.pdf 
> documentation on packages but am still unsure how to proceed 
> from here.
> 
> I would appreciate any advice, and any answers to the 
> following questions:
> 
> 1) is there a reason why Design is not listed in the Install 
> Packages list as Hmisc is?

Yes. The current version does not pass the checks under Windows. Please 
convince the maintainer to fix the package, and a binary will be made 
available shortly.


> 2) have I done the correct thing by way of manual 
> installation of Design?

Not quite: If you want to install a binary package, it must fit to your 
OS *and* to your version of R. The file you used is for an ancient 
version of R (given its date!).



> 3) is the absence of 2 other Design files (rdx, rdb) the 
> reason for my failed installation?


More or less, see 2.



> 4) what should I try now?


See 1 or install Design from sources. Attention: it will probably still 
fail its checks.

CCing to maintainer and author of Design, since the becomes a frequently 
asked questions (and nobody checks the mailing list archive before 
posting, obviously).

Uwe Ligges




> I am using R.2.5.0 on Windows XP.
> 
> Kind regards
> Ian
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Wed Jun 13 10:42:22 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 13 Jun 2007 09:42:22 +0100 (BST)
Subject: [R] Trouble making JRI.jar with Ubuntu and Java6
In-Reply-To: <11083776.post@talk.nabble.com>
References: <11083776.post@talk.nabble.com>
Message-ID: <Pine.LNX.4.64.0706130940130.21818@gannet.stats.ox.ac.uk>

You have a version mismatch.  You haven't told us your version of JRI, but 
it is not recent enough for R 2.5.0.

Also, you told us you are using java-6-sun-1.6.0.00, but the commands you 
show indicate otherwise.

On Tue, 12 Jun 2007, taivo wrote:

>
> Hi,
>
> Forum newb here, looking for some help. Have been trying to install an
> R-Java interface to make R calls from Java. JRI's configure script runs
> fine, but when it comes to make, I get the "error: too few arguments to
> function 'R_ParseVector'"
>
> Java runs fine. R runs fine. But I can't get this .jar file created.
> <grumble>
>
> Any help would be appreciated immensely,
>
> Taivo
> Ubuntu FeistyFawn, java-6-sun-1.6.0.00, R 2.5
>
> p.s. Here's the screen output:
>
> make -C src JRI.jar
> make[1]: Entering directory `/home/taivo/coop_summer2007/r/JRI/src'
> gcc -std=gnu99 -c -o Rengine.o Rengine.c -g -Iinclude  -DRIF_HAS_CSTACK
> -DRIF_HAS_RSIGHAND -g -O2
> -I/usr/lib/jvm/java-1.5.0-sun-1.5.0.11/jre/../include
> -I/usr/lib/jvm/java-1.5.0-sun-1.5.0.11/jre/../include/linux -fPIC
> -I/usr/lib/jvm/java-1.5.0-sun-1.5.0.11/jre/../include
> -I/usr/lib/jvm/java-1.5.0-sun-1.5.0.11/jre/../include/linux
> -I/usr/share/R/include -I/usr/share/R/include -I/usr/share/R/include
> Rengine.c: In function ??Java_org_rosuda_JRI_Rengine_rniParse??:
> Rengine.c:92: error: too few arguments to function ??R_ParseVector??
> make[1]: *** [Rengine.o] Error 1
> make[1]: Leaving directory `/home/taivo/coop_summer2007/r/JRI/src'
> make: *** [src/JRI.jar] Error 2
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ligges at statistik.uni-dortmund.de  Wed Jun 13 10:42:21 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 13 Jun 2007 10:42:21 +0200
Subject: [R] Confusion with sapply
In-Reply-To: <6E2AF71DA2E3F241A66122F3F90F32140DB2A9@exinmb04-bkp.apac.nsroot.net>
References: <6E2AF71DA2E3F241A66122F3F90F32140DB2A9@exinmb04-bkp.apac.nsroot.net>
Message-ID: <466FADED.9020708@statistik.uni-dortmund.de>



Patnaik, Tirthankar wrote:
> Hi,
>  I have some confusion in applying a function over a column.
> 
> Here's my function. I just need to shift non-March month-ends to March
> month-ends. Initially I tried seq.dates, but one cannot give a negative
> increment (decrement) here.
> 
> return(as.Date(seq.dates(format(xdate,"%m/%d/%Y"),by="months",len=4)[4])
> )
> 
> Hence this simple function:
> 
>> mydate <- as.Date("2006-01-01")
>>
>> # Function to shift non-March company-reporting dates to March.
>> Set2March <- function(xdate){
> + # Combines non-March months into March months:
> + # Dec2006 -> Mar2007
> + # Mar2006 -> Mar2006
> + # Jun2006 -> Mar2006
> + # Sep2006 -> Mar2006
> + # VERY Specific code.
> +     Month <- format(xdate,"%m")
> +     wDate <- month.day.year(julian(xdate))
> +     if (Month=="12"){
> +         wDate$year <- wDate$year + 1
> +         wDate$month <- 3
> +     }else
> +     if (Month=="06"){
> +         wDate$month <- 3
> +     }else
> +     if (Month=="09"){
> +         wDate$month <- 3
> +         wDate$day <- wDate$day + 1
> +     }else warning ("No Changes made to the month, since month is not
> one of (6,9,12)")
> +     cDate <- chron(paste(wDate$month,wDate$day,wDate$year,sep="/"))
> +     return(as.Date(as.yearmon(as.Date(cDate,"%m/%d/%y")),frac=1))
> + }
>> Set2March(as.Date("2006-06-30"))
> [1] "2006-03-31"
>> Set2March(mydate)
> [1] "2006-01-31"
> Warning message:
> No Changes made to the month, since month is not one of (6,9,12) in:
> Set2March(mydate) 
> 
> Works well when I use it on a single date. Then I try it on a vector:
> 
> 
>> dc <- seq(as.Date("2006-01-01"),len=10, by="month")
>> dc
>  [1] "2006-01-01" "2006-02-01" "2006-03-01" "2006-04-01" "2006-05-01"
> "2006-06-01" "2006-07-01" "2006-08-01"
>  [9] "2006-09-01" "2006-10-01"
> 
> 
>> sapply(as.vector(dc),Set2March)
> Error in prettyNum(.Internal(format(x, trim, digits, nsmall, width, 3,
> : 
>         unimplemented type 'character' in 'asLogical'
> 
> What am I missing here? Shouldn't the function work with the sapply
> working on each entry?


1. Your code is not reproducible. Which packages are required? chron? 
But then, I still do not have as.yearmon()!
2. Why do you use as.vector() in the sapply call? I doubt it can work 
that way, because as.vector strips the attributes!


Uwe Ligges



> 
> TIA and best,
> -Tir
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From yn19832 at msn.com  Wed Jun 13 10:50:16 2007
From: yn19832 at msn.com (livia)
Date: Wed, 13 Jun 2007 01:50:16 -0700 (PDT)
Subject: [R] Fitted value
Message-ID: <11095344.post@talk.nabble.com>


I would like to fit a Pareto Distribution and I am using the following codes. 

I thought the fitted (fit1) should be the fitted value for the data, is it
correct? As the result of the "fitted" turns out to be a single value for
all. 

fit=vglm(ycf1 ~ 1, pareto1(location=alpha), trace=TRUE, crit="c") 
coef(fit, matrix=TRUE) 
summary(fit) 
fitted(fit) 

Could anybody give me some advice?


-- 
View this message in context: http://www.nabble.com/Fitted-value-tf3913388.html#a11095344
Sent from the R help mailing list archive at Nabble.com.


From ted.harding at nessie.mcc.ac.uk  Wed Jun 13 11:00:15 2007
From: ted.harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Wed, 13 Jun 2007 10:00:15 +0100 (BST)
Subject: [R] Awk and Vilno
In-Reply-To: <874da0b40706121824q6e640901n380c7c535ed387c@mail.gmail.com>
Message-ID: <XFMail.070613100015.ted.harding@nessie.mcc.ac.uk>

On 13-Jun-07 01:24:41, Robert Wilkins wrote:
> In clinical trial data preparation and many other data situations,
> the statistical programmer needs to merge and re-merge multiple
> input files countless times. A syntax for merging files that is
> clear and concise is very important for the statistical programmer's
> productivity.
> 
> Here is how Vilno does it:
> 
> inlist dataset1 dataset2 dataset3 ;
> joinby variable1 variable2  where ( var3<=var4 ) ;
> [...]

Thanks to Robert for this more explicit illustration of what Vilno
does. Its potential usefulness is clear.

I broadly agree with the comments that have been made about the
various approaches (with/without awk/sed/R etc).

Is there any URL that leads to a fuller explicit exposition of Vilno?

As I said previously, a web-search on "vilno" leads to very little
that is relevant. What I did find didn't amount to much.

Best wishes,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 13-Jun-07                                       Time: 10:00:12
------------------------------ XFMail ------------------------------


From stefan.grosse at uni-erfurt.de  Wed Jun 13 11:02:36 2007
From: stefan.grosse at uni-erfurt.de (Stefan Grosse)
Date: Wed, 13 Jun 2007 11:02:36 +0200
Subject: [R] Linux equivalent to windows menus and script window
In-Reply-To: <466EDD07.A712.00CB.0@grecc.umaryland.edu>
References: <466EA24E.A712.00CB.0@grecc.umaryland.edu>
	<200706122016.08848.stefan.grosse@uni-erfurt.de>
	<466EDD07.A712.00CB.0@grecc.umaryland.edu>
Message-ID: <200706131102.36708.stefan.grosse@uni-erfurt.de>

JGR is pretty close to the windows R-GUI (with the menus) but even better 
since it is system independent and e.g. has syntax highlightning in the 
editor.

You could have a look at the screenshots at http://rosuda.org/JGR/index.htm

What you need is a Java 5 SDK installed at the system and probably R has to be 
reconfigured to find java.

Stefan

John, on Tuesday 12 June 2007 23:53:07 you wrote:
JS > Stefan,
JS > Am I correct that neither option will provide the menu options provided
 under windows, i.e. the MISC, PACKANGE, or WINDOWS menus?
JS > Thanks,
JS > John


From h.wickham at gmail.com  Wed Jun 13 11:05:00 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Wed, 13 Jun 2007 11:05:00 +0200
Subject: [R] Confusion with sapply
In-Reply-To: <6E2AF71DA2E3F241A66122F3F90F32140DB2A9@exinmb04-bkp.apac.nsroot.net>
References: <6E2AF71DA2E3F241A66122F3F90F32140DB2A9@exinmb04-bkp.apac.nsroot.net>
Message-ID: <f8e6ff050706130205l12f8a016oe347c691495873a2@mail.gmail.com>

On 6/13/07, Patnaik, Tirthankar <tirthankar.patnaik at citi.com> wrote:
> Hi,
>  I have some confusion in applying a function over a column.
>
> Here's my function. I just need to shift non-March month-ends to March
> month-ends. Initially I tried seq.dates, but one cannot give a negative
> increment (decrement) here.
>
> return(as.Date(seq.dates(format(xdate,"%m/%d/%Y"),by="months",len=4)[4])
> )
>
> Hence this simple function:
>
> > mydate <- as.Date("2006-01-01")
> >
> > # Function to shift non-March company-reporting dates to March.
> > Set2March <- function(xdate){
> + # Combines non-March months into March months:
> + # Dec2006 -> Mar2007
> + # Mar2006 -> Mar2006
> + # Jun2006 -> Mar2006
> + # Sep2006 -> Mar2006
> + # VERY Specific code.
> +     Month <- format(xdate,"%m")
> +     wDate <- month.day.year(julian(xdate))
> +     if (Month=="12"){
> +         wDate$year <- wDate$year + 1
> +         wDate$month <- 3
> +     }else
> +     if (Month=="06"){
> +         wDate$month <- 3
> +     }else
> +     if (Month=="09"){
> +         wDate$month <- 3
> +         wDate$day <- wDate$day + 1
> +     }else warning ("No Changes made to the month, since month is not
> one of (6,9,12)")
> +     cDate <- chron(paste(wDate$month,wDate$day,wDate$year,sep="/"))
> +     return(as.Date(as.yearmon(as.Date(cDate,"%m/%d/%y")),frac=1))
> + }
> > Set2March(as.Date("2006-06-30"))
> [1] "2006-03-31"
> > Set2March(mydate)
> [1] "2006-01-31"
> Warning message:
> No Changes made to the month, since month is not one of (6,9,12) in:
> Set2March(mydate)
> >
>
> Works well when I use it on a single date. Then I try it on a vector:
>
>
> > dc <- seq(as.Date("2006-01-01"),len=10, by="month")
> > dc
>  [1] "2006-01-01" "2006-02-01" "2006-03-01" "2006-04-01" "2006-05-01"
> "2006-06-01" "2006-07-01" "2006-08-01"
>  [9] "2006-09-01" "2006-10-01"
>
>
> > sapply(as.vector(dc),Set2March)
> Error in prettyNum(.Internal(format(x, trim, digits, nsmall, width, 3,
> :
>         unimplemented type 'character' in 'asLogical'
> >
>
> What am I missing here? Shouldn't the function work with the sapply
> working on each entry?

You can considerable simplify your code with some helper functions:

month <- function(x) as.POSIXlt(x)$mon + 1
"month<-" <- function(x, value) {
	ISOdatetime(year(x) + (value - 1) %/% 12,  (value - 1) %% 12 + 1 ,
mday(x), hour(x), minute(x), second(x), tz(x))
}
year <- function(x) as.POSIXlt(x)$year + 1900
"year<-" <- function(x, value) {
	ISOdatetime(value,  month(x), mday(x), hour(x), minute(x), second(x), tz(x))
}

marchise <- function(x) {
	if (month(x) == 12) year(x) <- year(x)
	if (month(x) %in% c(6, 9, 12)) month(x) <- 3
	x
}

dc <- seq(as.Date("2006-01-01"),len=10, by="month")
marchise(dc[[1]])


However, that doesn't work with sapply because the date class seems to
get stripped off - I'm not completely why, but perhaps because the
date class is a property of the entire vector not the individual
values:

sapply(marchise, dc)

Hadley


From lnmn02 at yahoo.co.uk  Wed Jun 13 11:05:45 2007
From: lnmn02 at yahoo.co.uk (Lucy Namu)
Date: Wed, 13 Jun 2007 09:05:45 +0000 (GMT)
Subject: [R] Subscription
Message-ID: <299429.54185.qm@web25007.mail.ukl.yahoo.com>

I would like to subscribe and get free software for statistical analysis.
Lucy


      ___________________________________________________________

now.


From christophe at pallier.org  Wed Jun 13 11:11:29 2007
From: christophe at pallier.org (Christophe Pallier)
Date: Wed, 13 Jun 2007 11:11:29 +0200
Subject: [R] Read Windows-like .INI files into R data structure?
In-Reply-To: <11094865.post@talk.nabble.com>
References: <f4min7$hu5$1@sea.gmane.org> <11094865.post@talk.nabble.com>
Message-ID: <dea6cb960706130211ja315962ha53306ebf044dcaa@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070613/eee2189b/attachment.pl 

From wl2776 at gmail.com  Wed Jun 13 11:22:15 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Wed, 13 Jun 2007 02:22:15 -0700 (PDT)
Subject: [R] Read Windows-like .INI files into R data structure?
In-Reply-To: <dea6cb960706130211ja315962ha53306ebf044dcaa@mail.gmail.com>
References: <f4min7$hu5$1@sea.gmane.org> <11094865.post@talk.nabble.com>
	<dea6cb960706130211ja315962ha53306ebf044dcaa@mail.gmail.com>
Message-ID: <11095800.post@talk.nabble.com>



Christophe Pallier wrote:
> 
>> "var1=value1", "A=value3" is almost pure R code.
>> Is it possible to use this feature to solve the problem?
> 
> Along the same lines: you may write a short script that converts the ini
> file into R code that can be sourced.
> 
>>From your example, you can generate  the  following R code:
> 
> Section1 <- list()
> Section1['var1'] <- value1
> Section1['var2'] <- value2
> Section2 <- list()
> Section2['A'] <- value3
> Section2['B'] <- value4
> 
> 
> with the following awk script (using awk -F'=' -f conv.awk example.ini >
> example.R)
> 
> ### conv.awk
> $1 ~ /\[/ { gsub(/[\[\]]/,""); # remove the brackets
>        listname = $1;
>        print $1 " <- list()";
>        next }
> { print listname "['" $1 "'] <- " $2 }
> 
> (I know, it looks cryptic... so I am shooting myself in the foot after
> claiming that awk scripts are typically quite readable ;-)
> 
> Christophe Pallier (http://www.pallier.org)
> 

It's sufficiently readable, but using something besides R is not sporty. ;)
-- 
View this message in context: http://www.nabble.com/Read-Windows-like-.INI-files-into-R-data-structure--tf3908740.html#a11095800
Sent from the R help mailing list archive at Nabble.com.


From bakalegum at gmail.com  Wed Jun 13 11:26:21 2007
From: bakalegum at gmail.com (BaKaLeGuM)
Date: Wed, 13 Jun 2007 11:26:21 +0200
Subject: [R] equivalent of windialog on unix??
Message-ID: <45551220706130226j3c7e82dey429e318cfbb322c6@mail.gmail.com>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20070613/b89067a5/attachment.pl 

From ligges at statistik.uni-dortmund.de  Wed Jun 13 11:29:04 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 13 Jun 2007 11:29:04 +0200
Subject: [R] Read Windows-like .INI files into R data structure?
In-Reply-To: <11095800.post@talk.nabble.com>
References: <f4min7$hu5$1@sea.gmane.org>
	<11094865.post@talk.nabble.com>	<dea6cb960706130211ja315962ha53306ebf044dcaa@mail.gmail.com>
	<11095800.post@talk.nabble.com>
Message-ID: <466FB8E0.5080906@statistik.uni-dortmund.de>



Vladimir Eremeev wrote:
> 
> Christophe Pallier wrote:
>>> "var1=value1", "A=value3" is almost pure R code.
>>> Is it possible to use this feature to solve the problem?
>> Along the same lines: you may write a short script that converts the ini
>> file into R code that can be sourced.
>>
>> >From your example, you can generate  the  following R code:
>>
>> Section1 <- list()
>> Section1['var1'] <- value1
>> Section1['var2'] <- value2
>> Section2 <- list()
>> Section2['A'] <- value3
>> Section2['B'] <- value4
>>
>>
>> with the following awk script (using awk -F'=' -f conv.awk example.ini >
>> example.R)
>>
>> ### conv.awk
>> $1 ~ /\[/ { gsub(/[\[\]]/,""); # remove the brackets
>>        listname = $1;
>>        print $1 " <- list()";
>>        next }
>> { print listname "['" $1 "'] <- " $2 }
>>
>> (I know, it looks cryptic... so I am shooting myself in the foot after
>> claiming that awk scripts are typically quite readable ;-)
>>
>> Christophe Pallier (http://www.pallier.org)
>>
> 
> It's sufficiently readable, but using something besides R is not sporty. ;)


OK, I try to be sporty, at least that is what my family doctor asks me 
to do all the time ;-)
Certainly there is much space for improvements...


X <- readLines(file)
value1 <- 1
value2 <- 2
value3 <- 3
value4 <- 4
sections <- grep("^\\[.*\\]$", X)
starts <- sections + 1
ends <- c(sections[-1] - 1, length(X))
L <- vector(mode="list", length=length(sections))
names(L) <- gsub("\\[|\\]", "", X[sections])
for(i in seq(along = sections)){
     env <- new.env()
     eval(parse(text=X[seq(starts[i], ends[i])]), env = env)
     L[[i]] <- as.list(env)
}


From singularitaet at gmx.net  Wed Jun 13 11:36:48 2007
From: singularitaet at gmx.net (Stefan Grosse)
Date: Wed, 13 Jun 2007 11:36:48 +0200
Subject: [R] update packages with R on Vista: error
In-Reply-To: <4667D730.9090403@gmx.net>
References: <4667D730.9090403@gmx.net>
Message-ID: <466FBAB0.7040902@gmx.net>

Dear all,

I figured out that the best solution for me is to install R in the
/User/me/Documents/R/ directory instead of the program files directory
since I am the only user on my notebook and R has then full write access
and I do not need to change any environment variables...

Thanks for the answers,-

Stefan

-------- Original Message  --------
Subject: [R] update packages with R on Vista: error
From: Stefan Grosse <singularitaet at gmx.net>
To: r-help at stat.math.ethz.ch
Date: 07.06.2007 12:00
> Dear R-list,
>
> I have encountered the following error message trying to update R packages:
>
>   
>> update.packages(ask='graphics')
>>     
> Warning in install.packages(update[instlib == l, "Package"], l,
> contriburl = contriburl,  :
>          'lib' is not writable
> Error in install.packages(update[instlib == l, "Package"], l, contriburl
> = contriburl,  :
>         unable to install packages
>
> I  remember did not have the problem on the last update where R
> installed the files then in the Documents/R folder on my user account.
> Any ideas how to handle this? I made the directories completely writable
> so I do not know where the problem is now (especially since update
> worked before...)
>
> Stefan
>
> PS: Tinn-R 1.19.2.3 + R 2.5.0 on Vista Business
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>


From singularitaet at gmx.net  Wed Jun 13 11:45:34 2007
From: singularitaet at gmx.net (Stefan Grosse)
Date: Wed, 13 Jun 2007 11:45:34 +0200
Subject: [R] Problems with Vista, R 2.5.0 and function save
In-Reply-To: <Pine.LNX.4.64.0706121247060.15600@auk.stats>
References: <20070612104358.318800@gmx.net>
	<Pine.LNX.4.64.0706121247060.15600@auk.stats>
Message-ID: <466FBCBE.4080802@gmx.net>

Hi Maja,

if you are working on your own computer an alternative could be to
install R in your user directory: c:\Users\your_loginname_\R or
c:\Users\your_loginname_\Documents\R I also had a problem with the
writing permissions when I tried updating R packages.

Btw. when I work with files I set the path directly (since I have
several different paths) so this is also a work around (
save(x,y,file="c:/Users/Maja/Documents/masterfile.Rda")  just note that
the windows backslash has been replaced).

Stefan

-------- Original Message  --------
Subject: Re:[R] Problems with Vista, R 2.5.0 and function save
From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
To: Maja Schr?ter <maja.schroeter at gmx.de>
Date: 12.06.2007 13:48
> So you are running R somewhere in your file system where you do not
> have permission to write.
>
> Did you create a shortcut with a working directory set as the rw-FAQ
> advised you to?
>
> On Tue, 12 Jun 2007, "Maja Schr?ter" wrote:
>
>> Hi everyone,
>>
>> I want to make use of the save function but it did not work.
>>
>> I'm using vista and R 2.5.0, winzip is installed too.
>>
>> Here's the code (from example ?save):
>>
>>  > x <- runif(20)
>>  > y <- list(a = 1, b = TRUE, c = "oops")
>>  > save(x, y, file = "xy.Rdata")
>>   Fehler in gzfile(file, "wb") : kann Verbindung nicht ?ffnen
>>    Zus?tzlich: Warning message:
>>    kann komprimierte Datei 'xy.Rdata' nicht ?ffnen
>>
>> Thank you so much for your help.
>>
>> Background: I want to crate a variable "masterfile" that I can start
>> with data(masterfile) or attach(masterfile).
>>
>> I.g.
>>
>> Town<-c("London","Miami","Rio","Lansing")
>> Pollution<-c("34","32","50","17")
>> masterfile<-data.frame(Town,Pollution)
>> save(masterfile,file="masterfile.Rda")
>>
>>
>> Kindly regards,
>>
>> Maja Schr?ter
>>
>
> ------------------------------------------------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   
> ------------------------------------------------------------------------
>
> No virus found in this incoming message.
> Checked by AVG Free Edition. 
> Version: 7.5.472 / Virus Database: 269.8.15/847 - Release Date: 12.06.2007 21:42
>


From peter.mcmahan at gmail.com  Wed Jun 13 12:17:28 2007
From: peter.mcmahan at gmail.com (Peter McMahan)
Date: Wed, 13 Jun 2007 12:17:28 +0200
Subject: [R] Linux equivalent to windows menus and script window
In-Reply-To: <200706131102.36708.stefan.grosse@uni-erfurt.de>
References: <466EA24E.A712.00CB.0@grecc.umaryland.edu>
	<200706122016.08848.stefan.grosse@uni-erfurt.de>
	<466EDD07.A712.00CB.0@grecc.umaryland.edu>
	<200706131102.36708.stefan.grosse@uni-erfurt.de>
Message-ID: <04BA4CDF-6B95-463C-8426-80D2A2C32369@gmail.com>

Note: The screenshots at http://rosuda.org/JGR/ don't show the menu  
bar because they're taken on a mac. But the menu items do exist.

On Jun 13, 2007, at 11:02 AM, Stefan Grosse wrote:

> JGR is pretty close to the windows R-GUI (with the menus) but even  
> better
> since it is system independent and e.g. has syntax highlightning in  
> the
> editor.
>
> You could have a look at the screenshots at http://rosuda.org/JGR/ 
> index.htm
>
> What you need is a Java 5 SDK installed at the system and probably  
> R has to be
> reconfigured to find java.
>
> Stefan
>
> John, on Tuesday 12 June 2007 23:53:07 you wrote:
> JS > Stefan,
> JS > Am I correct that neither option will provide the menu options  
> provided
>  under windows, i.e. the MISC, PACKANGE, or WINDOWS menus?
> JS > Thanks,
> JS > John
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Wed Jun 13 12:38:59 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 13 Jun 2007 11:38:59 +0100 (BST)
Subject: [R] equivalent of windialog on unix??
In-Reply-To: <45551220706130226j3c7e82dey429e318cfbb322c6@mail.gmail.com>
References: <45551220706130226j3c7e82dey429e318cfbb322c6@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0706131138130.22108@gannet.stats.ox.ac.uk>

?readline

On Wed, 13 Jun 2007, BaKaLeGuM wrote:

> I have on a script something like this
> "
>
> toto = winDialog("yesno", "Do you want to install the package")
> if (toto=="YES"){
>
> "
>
> but it dont work on unix because of the "winDialog" i think..
>
> how can i do to change this for unix please?
>
> best regards
>
> vincent
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From info at aghmed.fsnet.co.uk  Wed Jun 13 12:40:01 2007
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Wed, 13 Jun 2007 11:40:01 +0100
Subject: [R] export to a dat file that SAS can read
In-Reply-To: <466FC170.76E3.003F.0@danishmeat.dk>
References: <466FC170.76E3.003F.0@danishmeat.dk>
Message-ID: <Zen-1HyQGl-0001qT-V8@rutherford.zen.co.uk>

At 09:05 13/06/2007, Rina Miehs wrote:
>Hello
>
>i have a data frame in R that some SAS users need to use in their
>programs, and they want it in a dat file, is that possible?
>and which functions to use for that?

Does
library(foreign)
?write.foreign
get you any further forward?

>
>my data frame is like this:
>
> > out13[1:100,]
>              farid            niveau1          niveau3
>p1                p3   antal1
>2    10007995  0.0184891394  4.211306e-10 5.106471e-02 2.594580e-02
>  3
>9    10076495  0.0140812953  3.858757e-10 1.065804e-01 3.743271e-02
>  3
>10   10081892  0.0241760590  7.429612e-10 1.628295e-02 3.021538e-04
>  6
>13   10101395  0.0319517576  3.257375e-10 2.365204e-03 6.633232e-02
>19
>16   10104692  0.0114040787  3.661169e-10 1.566721e-01 4.550663e-02
>  4
>17   10113592  0.0167586526  4.229634e-10 6.922003e-02 2.543987e-02
>  2
>18   10113697  0.0259205504  2.888646e-10 1.096366e-02 9.118995e-02
>  6
>22   10121697 -0.0135341273 -5.507914e-10 1.157417e-01 5.501947e-03
>16
>28   10146495  0.0093514076  3.493487e-10 2.041883e-01 5.340801e-02
>  4
>29   10150497  0.0091611504  3.455925e-10 2.089893e-01 5.531904e-02
>  4
>36   10171895  0.0089116669  2.956742e-10 2.153844e-01 8.614259e-02
>  4
>42   10198295  0.0078515166  3.147140e-10 2.437943e-01 7.314111e-02
>  5
>
>
>Thanks
>
>Rina
>
>
>
>
>         [[alternative HTML version deleted]]

Michael Dewey
http://www.aghmed.fsnet.co.uk


From lagache at supagro.inra.fr  Wed Jun 13 13:17:31 2007
From: lagache at supagro.inra.fr (Philippe LAGACHERIE)
Date: Wed, 13 Jun 2007 13:17:31 +0200
Subject: [R] installing GRASS-R packages
Message-ID: <466FD24B.8070703@supagro.inra.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070613/89795ea0/attachment.pl 

From marco.r.help at gmail.com  Wed Jun 13 13:38:57 2007
From: marco.r.help at gmail.com (marco.R.help marco.R.help)
Date: Wed, 13 Jun 2007 13:38:57 +0200
Subject: [R] installing Rgraphviz under fedora 5
Message-ID: <605b4120706130438v6dd912c6x93f9e9e554e0f4ac@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070613/b836866e/attachment.pl 

From yn19832 at msn.com  Wed Jun 13 13:55:37 2007
From: yn19832 at msn.com (livia)
Date: Wed, 13 Jun 2007 04:55:37 -0700 (PDT)
Subject: [R] Fitted Value Pareto Distribution
Message-ID: <11097749.post@talk.nabble.com>


I would like to fit a Pareto Distribution and I am using the following codes. 

I thought the fitted (fit1) should be the fitted value for the data, is it
correct? As the result of the "fitted" turns out to be a single value for
all. 

fit=vglm(ycf1 ~ 1, pareto1(location=alpha), trace=TRUE, crit="c") 
fitted(fit) 

The result is 
fitted(fit)
            [,1]
 [1,] 0.07752694
 [2,] 0.07752694
 [3,] 0.07752694
 [4,] 0.07752694
 [5,] 0.07752694
 [6,] 0.07752694
 [7,] 0.07752694
 [8,] 0.07752694
 [9,] 0.07752694
[10,] 0.07752694
[11,] 0.07752694
[12,] 0.07752694
[13,] 0.07752694

Could anybody give me some advice? 

-- 
View this message in context: http://www.nabble.com/Fitted-Value-Pareto-Distribution-tf3914151.html#a11097749
Sent from the R help mailing list archive at Nabble.com.


From andy_liaw at merck.com  Wed Jun 13 14:02:31 2007
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 13 Jun 2007 08:02:31 -0400
Subject: [R] Viewing a data object
In-Reply-To: <499415.96653.qm@web39706.mail.mud.yahoo.com>
References: <466E7B310200006500006405@pgn.com>
	<499415.96653.qm@web39706.mail.mud.yahoo.com>
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA044D4639@usctmx1106.merck.com>

I believe JGR has an object browser.  See the screenshots at the bottom
of http://rosuda.org/JGR/.

Andy 

From: Stephen Tucker
> 
> Hi Horace,
> 
> I have also thought that it may be useful but I don't know of 
> any Object
> Explorer available for R.
> 
> However, (you may alread know this but) 
> (1) you can view your list of objects in R with objects(), 
> (2) view objects in a spreadsheet-like table (if they are 
> matrices or data
> frames) with invisible(edit(objectName)) [which isn't easy on 
> the fingers].
> fix(objectName) is also a shorter option but it has the side effect of
> possibly changing your object when you close the viewing 
> data. For instance,
> this can happen if you mistakenly type something into a cell; 
> it can also
> change your column classes when you don't - for example:
> 
> > options(stringsAsFactors=TRUE)
> > x <- data.frame(letters[1:5],1:5)
> > sapply(x,class)
> letters.1.5.         X1.5 
>     "factor"    "integer" 
> > fix(x) # no user-changes made
> > sapply(x,class)
> letters.1.5.         X1.5 
>     "factor"    "numeric" 
> 
> (3) I believe Deepayan Sarkar contributed the tab-completion 
> capability at
> the command line. So unless you have a lot of objects beginning with
> 'AuroraStoch...' you should be able to type a few letters and let the
> auto-completion handle the rest.
> 
> Best regards,
> 
> ST
> 
> 
> --- Horace Tso <Horace.Tso at pgn.com> wrote:
> 
> > Dear list,
> > 
> > First apologize that this is trivial and just betrays my 
> slothfulness at
> > the keyboard. I'm sick of having to type a long name just 
> to get a glimpse
> > of something. For example, if my data frame is named
> > 'AuroraStochasticRunsJune1.df" and I want to see what the 
> middle looks
> > like, I have to type
> > 
> > AuroraStochasticRunsJune1.df[ 400:500, ]
> > 
> > And often I'm not even sure rows 400 to 500 are what I want 
> to see.  I
> > might have to type the same line many times.
> > 
> > Is there sort of a R-equivalence of the Object Explorer, 
> like in Splus,
> > where I could mouse-click an object in a list and a window 
> pops up?  Short
> > of that, is there any trick of saving a couple of 
> keystrokes here and
> > there?
> > 
> > Thanks for tolerating this kind of annoying questions.
> > 
> > H.
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> > 
> 
> 
> 
>  
> ______________________________________________________________
> ______________________
> Sucker-punch spam with award-winning protection.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}


From bolker at ufl.edu  Wed Jun 13 14:05:40 2007
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 13 Jun 2007 12:05:40 +0000 (UTC)
Subject: [R] specify constraints in maximum likelihood
References: <e4add7bf91a5.466f50bc@optonline.net>
Message-ID: <loom.20070613T140103-688@post.gmane.org>

 <adschai <at> optonline.net> writes:

> 
> Hi,I know only mle function but it seems that in mle one can only specify the
bound of the unknowns forming the
> likelihood function. But I would like to specify something like, a = 2b or a
<= 2b where 'a' and 'b' could be my
> parameters in the likelihood function. Any help would be really appreciated.
Thank you!- adschai
> 
> 	


 Something like a=2b (equality constraints with a simple form)
should be easy, just reparameterize your function.  e.g. if
you have minuslogl equal to  f(a,b,c) then define a new function

f2 <- function(a,c) {
   b <- a/2
   f(a,b,c)
}

For a<=2b reparameterize in terms of d=a-2b :

f2 <- function(a,c,d) {
   b <- (a-d)/2
   f(a,b,c)
}

and impose the constraint (e.g. with L-BFGS-B) of d<=0.
Actually, the second one (linear inequality constraints)
can also be done with constrOptim.

   More complex (nonlinear) constraints have to be done
with Lagrange multipliers or penalty terms
( http://www.zoo.ufl.edu/bolker/emdbook/chap7A.pdf has
some general description, at a very basic level )


From jrkrideau at yahoo.ca  Wed Jun 13 14:11:49 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Wed, 13 Jun 2007 08:11:49 -0400 (EDT)
Subject: [R] Design library installation problem
In-Reply-To: <46706606.6070702@mq.edu.au>
Message-ID: <366571.42340.qm@web32805.mail.mud.yahoo.com>

I cannot find the posting but I believe Brian Ripley
posted something here a day or so ago that said that
Design had not passed some of the 2.5.0 tests.  


--- Ian Watson <ian.watson at mq.edu.au> wrote:

> Dear Listers
> 
> I have tried to install Frank Harrell's two
> libaries: Hmisc 
> and Design.
> 
> I found that Hmisc was listed in the list of
> packages from 
> the Install Packages command on the Packages menu,
> but 
> Design was not. I installed Hmisc from this list,
> and when I 
>   issued the library(Hmisc) command, it loaded into
> memory 
> correctly.
> 
> I then copied the Design 1.1-1.zip file from the 
> http://lib.stat.cmu.edu/S/Harrell/library/r/ site
> and used 
> the Install Packages from Local Zip file command.
> 
> I received no error messages and a visual inspection
> of the 
> R\library directory shows Design has been installed.
> 
> However, when I issued the library(Design) command I
> get the 
> following error message:
> 
> Error in library(Design) : 'Design' is not a valid
> package 
> -- installed < 2.0.0?
> 
> 
> I also notice, from a visual inspection of the 
> R\library\Design\R directory that there is only one
> file: 
> design. In other directories, eg. R\library\Hmisc\R
> there 
> are usually 3 files:
> Hmisc
> Hmisc.rdx
> Hmisc.rdb
> 
> I am new to R, and a bit lost. I have read the
> R-admin.pdf 
> documentation on packages but am still unsure how to
> proceed 
> from here.
> 
> I would appreciate any advice, and any answers to
> the 
> following questions:
> 
> 1) is there a reason why Design is not listed in the
> Install 
> Packages list as Hmisc is?
> 2) have I done the correct thing by way of manual 
> installation of Design?
> 3) is the absence of 2 other Design files (rdx, rdb)
> the 
> reason for my failed installation?
> 4) what should I try now?
> 
> 
> I am using R.2.5.0 on Windows XP.
> 
> Kind regards
> Ian
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From f.harrell at vanderbilt.edu  Wed Jun 13 14:12:17 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Wed, 13 Jun 2007 07:12:17 -0500
Subject: [R] Design library installation problem
In-Reply-To: <466FA9AC.3050901@statistik.uni-dortmund.de>
References: <46706606.6070702@mq.edu.au>
	<466FA9AC.3050901@statistik.uni-dortmund.de>
Message-ID: <466FDF21.8050605@vanderbilt.edu>

Uwe Ligges wrote:
> 
> 
> Ian Watson wrote:
>> Dear Listers
>>
>> I have tried to install Frank Harrell's two libaries: Hmisc and Design.
>>
>> I found that Hmisc was listed in the list of packages from the Install 
>> Packages command on the Packages menu, but Design was not. I installed 
>> Hmisc from this list, and when I   issued the library(Hmisc) command, 
>> it loaded into memory correctly.
>>
>> I then copied the Design 1.1-1.zip file from the 
>> http://lib.stat.cmu.edu/S/Harrell/library/r/ site and used the Install 
>> Packages from Local Zip file command.
>> I received no error messages and a visual inspection of the R\library 
>> directory shows Design has been installed.
>>
>> However, when I issued the library(Design) command I get the following 
>> error message:
>>
>> Error in library(Design) : 'Design' is not a valid package -- 
>> installed < 2.0.0?
>>
>>
>> I also notice, from a visual inspection of the R\library\Design\R 
>> directory that there is only one file: design. In other directories, 
>> eg. R\library\Hmisc\R there are usually 3 files:
>> Hmisc
>> Hmisc.rdx
>> Hmisc.rdb
>>
>> I am new to R, and a bit lost. I have read the R-admin.pdf 
>> documentation on packages but am still unsure how to proceed from here.
>>
>> I would appreciate any advice, and any answers to the following 
>> questions:
>>
>> 1) is there a reason why Design is not listed in the Install Packages 
>> list as Hmisc is?
> 
> Yes. The current version does not pass the checks under Windows. Please 
> convince the maintainer to fix the package, and a binary will be made 
> available shortly.

Please note that this would be a lot easier if we did not get a segfault 
when running R CMD CHECK --- a segfault that does not happen with the 
example code is run outside of CMD CHECK.  Charles Thomas Dupont is 
working hard on this.

Frank

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From ripley at stats.ox.ac.uk  Wed Jun 13 14:15:14 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 13 Jun 2007 13:15:14 +0100 (BST)
Subject: [R] installing Rgraphviz under fedora 5
In-Reply-To: <605b4120706130438v6dd912c6x93f9e9e554e0f4ac@mail.gmail.com>
References: <605b4120706130438v6dd912c6x93f9e9e554e0f4ac@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0706131308050.20386@gannet.stats.ox.ac.uk>

The problem is that libgvc.so.3 is not in your dynamic library search 
path.  That's true by default for FC5, it is in /usr/lib64/graphviz on a 
x86_64 FC5 box.

The proper solution is to fix the FC5 graphviz installation to tell ld.so 
about the location.  A simpler way is to add /usr/lib64/graphviz to the 
LD_LIBRARY_PATH: on our servers we have edited R_HOME/etc/ldpaths to do 
so, so we have

: ${R_LD_LIBRARY_PATH=${R_HOME}/lib:/usr/local/lib64:/opt/export/lib64:/usr/lib6
4/graphviz}

If you don't have permissions to do this, set it in your personal 
LD_LIBRARY_PATH.


BTW, asking questions about installing Bioconductor is best done on their 
mailing list, not R-help.

On Wed, 13 Jun 2007, marco.R.help marco.R.help wrote:

> Dear list,
>
> I have a lot of troubles installing Rgraphviz.
> I installed graphviz 2.13 from  "graphviz-2.13.20061222.0540.tar"
> I installed the library Rgraphviz
>
>> getBioC("Rgraphviz")
> Running biocinstall version 2.0.8 with R version 2.5.0
> Your version of R requires version 2.0 of Bioconductor.
> trying URL '
> http://bioconductor.org/packages/2.0/bioc/src/contrib/Rgraphviz_1.14.0.tar.gz
> '
> Content type 'application/x-gzip' length 1522949 bytes
>
> etc etc....
>
> but when I do: library(Rgraphviz)
>
>> library(Rgraphviz)
> Error in dyn.load(x, as.logical(local), as.logical(now)) :
>        unable to load shared library '/home/jke/mazu/SOFTWARE_INST/R-2.5.0
> /library/Rgraphviz/libs/Rgraphviz.so':
>  libgvc.so.3: cannot open shared object file: No such file or directory
> Error : .onLoad failed in 'loadNamespace' for 'Rgraphviz'
> Error: package/namespace load failed for 'Rgraphviz'
>
> The path to Rgraphviz.so is correct !
>
> Can someone help with this?
>
> this is the session info ....
>
>
> regards
>
> Marco
>
>
>> sessioninfo()
> Error: could not find function "sessioninfo"
>> sessionInfo()
> R version 2.5.0 (2007-04-23)
> x86_64-unknown-linux-gnu
> locale:
> LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=en_US.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C
>
> attached base packages:
> [1] "tools"     "stats"     "graphics"  "grDevices" "datasets"  "utils"
> [7] "methods"   "base"
>
> other attached packages:
> geneplotter     lattice    annotate     Biobase       graph
>   "1.14.0"    "0.15-4"    "1.14.1"    "1.14.0"    "1.14.2"
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From lawremi at iastate.edu  Wed Jun 13 14:24:28 2007
From: lawremi at iastate.edu (Michael Lawrence)
Date: Wed, 13 Jun 2007 07:24:28 -0500
Subject: [R] installing Rgraphviz under fedora 5
In-Reply-To: <605b4120706130438v6dd912c6x93f9e9e554e0f4ac@mail.gmail.com>
References: <605b4120706130438v6dd912c6x93f9e9e554e0f4ac@mail.gmail.com>
Message-ID: <509e0620706130524qc064d57m40c1b736ce8a7986@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070613/50e04700/attachment.pl 

From ggrothendieck at gmail.com  Wed Jun 13 14:53:55 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 13 Jun 2007 08:53:55 -0400
Subject: [R] if statement
In-Reply-To: <229c5cdd230b0248b85969e7a149c336@mail.chori.org>
References: <229c5cdd230b0248b85969e7a149c336@mail.chori.org>
Message-ID: <971536df0706130553t6ec16c84h84d8b81f26b18a97@mail.gmail.com>

See ?quantcut in the gtools package.

On 6/11/07, Jiong Zhang, PhD <jizhang at chori.org> wrote:
> Hi all,
>
> I have a rather naive question. I have the height of 100 individuals in
> a table and I want to assign the tallest 30% as Case=1 and the bottom
> 30% as Case=0.  How do I do that?
>
> thanks.
>
> jiong
>  The email message (and any attachments) is for the sole use of the intended recipient(s) and may contain confidential information.  Any unauthorized review, use, disclosure or distribution is prohibited.  If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message (and any attachments).  Thank You.
>
>
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ggrothendieck at gmail.com  Wed Jun 13 15:23:03 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 13 Jun 2007 09:23:03 -0400
Subject: [R] Confusion with sapply
In-Reply-To: <6E2AF71DA2E3F241A66122F3F90F32140DB2A9@exinmb04-bkp.apac.nsroot.net>
References: <6E2AF71DA2E3F241A66122F3F90F32140DB2A9@exinmb04-bkp.apac.nsroot.net>
Message-ID: <971536df0706130623o472d5bf6i2a5649448ea12d4c@mail.gmail.com>

Try this. It takes a Date class date and in the first line month.day.year
converts unclass(x) to chron.  In the last line of the function we convert
back to Date class.  Its already vectorized so sapply is unneeded:

library(chron)
f <- function(x) with(month.day.year(unclass(x)), {
	month <- ifelse(month == 6 | month == 9, 3, month)
	year <- ifelse(month == 12, year + 1, year)
	as.Date(paste(year, month, day, sep = "-"))
})

Running the last line gives:

> # test
> f(seq(Sys.Date(), length = 12, by = "month"))
 [1] "2007-03-13" "2007-07-13" "2007-08-13" "2007-03-13" "2007-10-13"
 [6] "2007-11-13" "2008-12-13" "2008-01-13" "2008-02-13" "2008-03-13"
[11] "2008-04-13" "2008-05-13"


On 6/13/07, Patnaik, Tirthankar <tirthankar.patnaik at citi.com> wrote:
> Hi,
>  I have some confusion in applying a function over a column.
>
> Here's my function. I just need to shift non-March month-ends to March
> month-ends. Initially I tried seq.dates, but one cannot give a negative
> increment (decrement) here.
>
> return(as.Date(seq.dates(format(xdate,"%m/%d/%Y"),by="months",len=4)[4])
> )
>
> Hence this simple function:
>
> > mydate <- as.Date("2006-01-01")
> >
> > # Function to shift non-March company-reporting dates to March.
> > Set2March <- function(xdate){
> + # Combines non-March months into March months:
> + # Dec2006 -> Mar2007
> + # Mar2006 -> Mar2006
> + # Jun2006 -> Mar2006
> + # Sep2006 -> Mar2006
> + # VERY Specific code.
> +     Month <- format(xdate,"%m")
> +     wDate <- month.day.year(julian(xdate))
> +     if (Month=="12"){
> +         wDate$year <- wDate$year + 1
> +         wDate$month <- 3
> +     }else
> +     if (Month=="06"){
> +         wDate$month <- 3
> +     }else
> +     if (Month=="09"){
> +         wDate$month <- 3
> +         wDate$day <- wDate$day + 1
> +     }else warning ("No Changes made to the month, since month is not
> one of (6,9,12)")
> +     cDate <- chron(paste(wDate$month,wDate$day,wDate$year,sep="/"))
> +     return(as.Date(as.yearmon(as.Date(cDate,"%m/%d/%y")),frac=1))
> + }
> > Set2March(as.Date("2006-06-30"))
> [1] "2006-03-31"
> > Set2March(mydate)
> [1] "2006-01-31"
> Warning message:
> No Changes made to the month, since month is not one of (6,9,12) in:
> Set2March(mydate)
> >
>
> Works well when I use it on a single date. Then I try it on a vector:
>
>
> > dc <- seq(as.Date("2006-01-01"),len=10, by="month")
> > dc
>  [1] "2006-01-01" "2006-02-01" "2006-03-01" "2006-04-01" "2006-05-01"
> "2006-06-01" "2006-07-01" "2006-08-01"
>  [9] "2006-09-01" "2006-10-01"
>
>
> > sapply(as.vector(dc),Set2March)
> Error in prettyNum(.Internal(format(x, trim, digits, nsmall, width, 3,
> :
>        unimplemented type 'character' in 'asLogical'
> >
>
> What am I missing here? Shouldn't the function work with the sapply
> working on each entry?
>
>
> TIA and best,
> -Tir
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Roger.Bivand at nhh.no  Wed Jun 13 15:24:25 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 13 Jun 2007 15:24:25 +0200 (CEST)
Subject: [R] installing GRASS-R packages
In-Reply-To: <466FD24B.8070703@supagro.inra.fr>
References: <466FD24B.8070703@supagro.inra.fr>
Message-ID: <Pine.LNX.4.64.0706131517080.2761@reclus.nhh.no>

On Wed, 13 Jun 2007, Philippe LAGACHERIE wrote:

> Hi,
> I tried to install R packages required for the GRASS-R interface by
> using the following command (copied from
> http://www.geog.uni-hannover.de/grass/statsgrass/grass6_r_install.html):
> /install.packages (c("sp", "spgrass6","rgdal","maptools"), dependencies
> =TRUE)/
> rgdal package was installed successfully;
> There were problems to find 'sp' and 'maptools' packages. The error
> message was /: dependencies 'sp' and 'maptools' are not available/.
> I tried to download the packages from three different mirrors with the
> same result  ( http://cran.fr.r-project.org/ ,
> http://cran.mirroring.de/, http://probability.ca/cran/ )
> <http://probability.ca/cran/>
> I then failed to download 'spgrass6' since it required to download first
> "sp"
> can anybody tell me what mistake I did and how (where?) I can get these
> packages

The note in the OSGeo Journal:

http://www.osgeo.org/files/journal/final_pdfs/OSGeo_vol1_GRASS-R.pdf

is more recent, although the note you accessed is accurate, and says just:

install.packages("spgrass6", dependencies = TRUE)

should be enough, because all the packages are on CRAN, and current sp 
and maptools are on at least http://cran.fr.r-project.org.

Topics like this are best raised on the R-sig-geo list, or perhaps on the 
GRASS STATGRASS list. It is also good practice to say what platform you 
are on (OS, R version, etc.) as reported by sessionInfo().

> Thank you very much by advance
> <http://probability.ca/cran/>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From bakalegum at gmail.com  Wed Jun 13 15:36:07 2007
From: bakalegum at gmail.com (BaKaLeGuM)
Date: Wed, 13 Jun 2007 15:36:07 +0200
Subject: [R] equivalent of windialog on unix??
In-Reply-To: <Pine.LNX.4.64.0706131138130.22108@gannet.stats.ox.ac.uk>
References: <45551220706130226j3c7e82dey429e318cfbb322c6@mail.gmail.com>
	<Pine.LNX.4.64.0706131138130.22108@gannet.stats.ox.ac.uk>
Message-ID: <45551220706130636j47963f8ek51b8196199c04d9e@mail.gmail.com>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20070613/9b7604e2/attachment.pl 

From tirthankar.patnaik at citi.com  Wed Jun 13 11:30:55 2007
From: tirthankar.patnaik at citi.com (Patnaik, Tirthankar )
Date: Wed, 13 Jun 2007 15:00:55 +0530
Subject: [R] Confusion with sapply
Message-ID: <6E2AF71DA2E3F241A66122F3F90F32140DB2AB@exinmb04-bkp.apac.nsroot.net>

Hi,
	Many thanks for this Hadley, and Uwe, the packages I used were
chron, and zoo. Later I'm also using Hadley's reshape.

I was able to run the code for a vector thus:

> dc <- seq(as.Date("2006-01-01"),len=10,by="month")
> dc
 [1] "2006-01-01" "2006-02-01" "2006-03-01" "2006-04-01" "2006-05-01"
"2006-06-01" "2006-07-01" "2006-08-01"
 [9] "2006-09-01" "2006-10-01"
> as.Date(sapply(dc,function(x)Set2March(as.Date(x))))
 [1] "2006-01-31" "2006-02-28" "2006-03-31" "2006-04-30" "2006-05-31"
"2006-03-31" "2006-07-31" "2006-08-31"
 [9] "2006-03-31" "2006-10-31"
Warning messages:
1: No Changes made to the month, since month is not one of (6,9,12) in:
Set2March(as.Date(x)) 
2: No Changes made to the month, since month is not one of (6,9,12) in:
Set2March(as.Date(x)) 
3: No Changes made to the month, since month is not one of (6,9,12) in:
Set2March(as.Date(x)) 
4: No Changes made to the month, since month is not one of (6,9,12) in:
Set2March(as.Date(x)) 
5: No Changes made to the month, since month is not one of (6,9,12) in:
Set2March(as.Date(x)) 
6: No Changes made to the month, since month is not one of (6,9,12) in:
Set2March(as.Date(x)) 
7: No Changes made to the month, since month is not one of (6,9,12) in:
Set2March(as.Date(x)) 
8: No Changes made to the month, since month is not one of (6,9,12) in:
Set2March(as.Date(x)) 
> 

Basically I ran as.Date on the vector elements (Why?, since the elements
are dates anyway?), and then afterwards use as.Date again on the
returned vector. Got the answer, but it would be great if I could
understand exactly how.

TIA and Best,
-Tir



> -----Original Message-----
> From: hadley wickham [mailto:h.wickham at gmail.com] 
> Sent: Wednesday, June 13, 2007 2:35 PM
> To: Patnaik, Tirthankar [GWM-CIR]
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Confusion with sapply
> 
> On 6/13/07, Patnaik, Tirthankar <tirthankar.patnaik at citi.com> wrote:
> > Hi,
> >  I have some confusion in applying a function over a column.
> >
> > Here's my function. I just need to shift non-March 
> month-ends to March 
> > month-ends. Initially I tried seq.dates, but one cannot give a 
> > negative increment (decrement) here.
> >
> > 
> return(as.Date(seq.dates(format(xdate,"%m/%d/%Y"),by="months",len=4)[4
> > ])
> > )
> >
> > Hence this simple function:
> >
> > > mydate <- as.Date("2006-01-01")
> > >
> > > # Function to shift non-March company-reporting dates to March.
> > > Set2March <- function(xdate){
> > + # Combines non-March months into March months:
> > + # Dec2006 -> Mar2007
> > + # Mar2006 -> Mar2006
> > + # Jun2006 -> Mar2006
> > + # Sep2006 -> Mar2006
> > + # VERY Specific code.
> > +     Month <- format(xdate,"%m")
> > +     wDate <- month.day.year(julian(xdate))
> > +     if (Month=="12"){
> > +         wDate$year <- wDate$year + 1
> > +         wDate$month <- 3
> > +     }else
> > +     if (Month=="06"){
> > +         wDate$month <- 3
> > +     }else
> > +     if (Month=="09"){
> > +         wDate$month <- 3
> > +         wDate$day <- wDate$day + 1
> > +     }else warning ("No Changes made to the month, since 
> month is not
> > one of (6,9,12)")
> > +     cDate <- 
> chron(paste(wDate$month,wDate$day,wDate$year,sep="/"))
> > +     return(as.Date(as.yearmon(as.Date(cDate,"%m/%d/%y")),frac=1))
> > + }
> > > Set2March(as.Date("2006-06-30"))
> > [1] "2006-03-31"
> > > Set2March(mydate)
> > [1] "2006-01-31"
> > Warning message:
> > No Changes made to the month, since month is not one of (6,9,12) in:
> > Set2March(mydate)
> > >
> >
> > Works well when I use it on a single date. Then I try it on 
> a vector:
> >
> >
> > > dc <- seq(as.Date("2006-01-01"),len=10, by="month") dc
> >  [1] "2006-01-01" "2006-02-01" "2006-03-01" "2006-04-01" 
> "2006-05-01"
> > "2006-06-01" "2006-07-01" "2006-08-01"
> >  [9] "2006-09-01" "2006-10-01"
> >
> >
> > > sapply(as.vector(dc),Set2March)
> > Error in prettyNum(.Internal(format(x, trim, digits, 
> nsmall, width, 3,
> > :
> >         unimplemented type 'character' in 'asLogical'
> > >
> >
> > What am I missing here? Shouldn't the function work with the sapply 
> > working on each entry?
> 
> You can considerable simplify your code with some helper functions:
> 
> month <- function(x) as.POSIXlt(x)$mon + 1 "month<-" <- 
> function(x, value) {
> 	ISOdatetime(year(x) + (value - 1) %/% 12,  (value - 1) 
> %% 12 + 1 , mday(x), hour(x), minute(x), second(x), tz(x)) } 
> year <- function(x) as.POSIXlt(x)$year + 1900 "year<-" <- 
> function(x, value) {
> 	ISOdatetime(value,  month(x), mday(x), hour(x), 
> minute(x), second(x), tz(x)) }
> 
> marchise <- function(x) {
> 	if (month(x) == 12) year(x) <- year(x)
> 	if (month(x) %in% c(6, 9, 12)) month(x) <- 3
> 	x
> }
> 
> dc <- seq(as.Date("2006-01-01"),len=10, by="month")
> marchise(dc[[1]])
> 
> 
> However, that doesn't work with sapply because the date class 
> seems to get stripped off - I'm not completely why, but 
> perhaps because the date class is a property of the entire 
> vector not the individual
> values:
> 
> sapply(marchise, dc)
> 
> Hadley
>


From rxzhu at scbit.org  Wed Jun 13 13:53:45 2007
From: rxzhu at scbit.org (Ruixin ZHU)
Date: Wed, 13 Jun 2007 19:53:45 +0800
Subject: [R] How to install RMySQL package in R 2.5 in Windows OS?
Message-ID: <000001c7adb1$7f4bd000$7000a8c0@scbit94ec75129>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070613/96459af1/attachment.pl 

From bartczuk at kul.lublin.pl  Wed Jun 13 15:00:38 2007
From: bartczuk at kul.lublin.pl (rafael)
Date: Wed, 13 Jun 2007 15:00:38 +0200
Subject: [R] Differences of correlations testing in R
Message-ID: <466FEA76.2050300@kul.lublin.pl>

Good morning everybody,

I need to compare intercorrelations between variables.

My data were collected from 4 samples (with various number of subject)
containing 4 variables scores.

Some of my hypothesis are about the strength of relations
(the sign doesn't matter) between variables across samples.

I have such correlation matrix:

A
B ab
C ac bc
D ad bd cd
  A  B  C  D

my hypothesis are:

|ad|>|ac|
|ad|>|ab|
|ad|>|bd|
|ad|>|cd|
|bc|>|ac|
|bc|>|cd|
|bc|>|ab|
|bc|>|bd|

ac,bd > 0
ab,bc,cd,ad < 0


I would like to make above comparisons across the samples
I'm only interested in whether the pattern is replicated in all
samples not in the differences between them.

Is it possible to do it in R? (I'm newbie)

Any help would be greatly appreciated.


Rafal Bartczuk

Institute of Psychology
Catholic University of Lublin


From tlumley at u.washington.edu  Wed Jun 13 15:53:03 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 13 Jun 2007 06:53:03 -0700 (PDT)
Subject: [R] export to a dat file that SAS can read
In-Reply-To: <466FA729.1060405@statistik.uni-dortmund.de>
References: <466FC170.76E3.003F.0@danishmeat.dk>
	<466FA729.1060405@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.64.0706130651330.10858@homer22.u.washington.edu>

On Wed, 13 Jun 2007, Uwe Ligges wrote:
>
>
> Rina Miehs wrote:
>> Hello
>>
>> i have a data frame in R that some SAS users need to use in their
>> programs, and they want it in a dat file, is that possible?
>
> What is a "dat" file?
>
>
>> and which functions to use for that?
>
> I *guess* write.table() will do the trick, given "dat" is what I guess
> it is...

Another approach (that preserves factor levels if you have them) is to use 
write.foreign in the 'foreign' package. This writes a text file for the 
data and also writes SAS code to read the file.

 	-thomas


From therneau at mayo.edu  Wed Jun 13 16:06:37 2007
From: therneau at mayo.edu (Terry Therneau)
Date: Wed, 13 Jun 2007 09:06:37 -0500 (CDT)
Subject: [R] "R is not a validated software package..
Message-ID: <200706131406.l5DE6bF07034@hsrnfs-101.mayo.edu>

 I've been on vacation and so come late to this interesting discussion.  Let
me add two minor points.

  1. I have run into a lot of statements that "x is required" when dealing
with pharma, and in particular wrt NDAs (new drug application).  Almost all
were false.  But I also understand a bit of where they are coming from.  An
NDA costs millions, with the required trials, and is a huge submission in
terms of the sheer amount of paper.  If a company's last NDA was successful,
there is a lot of draw to make the next one as much like it as possible, down
to the font size and the margins.  
  So  I agree with Frank that "SAS is validated" is a false requirement, yet
remain somewhat sympathetic to the person who said it.

  2. We have been audited once on a portion of an analysis.  The official said,
more or less, "show us how you got that answer" while pointing at a part of
the report.  That particular analysis happened to be done in SAS, but what
was important was our ability to quickly find the relevant code, not the
package.  

  3. If the other party is stubborn about SAS vs S, I have one example I like
to argue with.  The S survival code has an extensive test suite, including
a set of small examples where I have worked out the correct results by hand.
Many of these latter are documented in the appendix of the Therneau and
Grambsch book.  The SAS phreg procedure does not pass all the tests.  (Cox
model + Efron approx for ties + deviance residuals for one.  The size of
the error is numerically insignificant, a 1/n vs 1/(n-1) type of thing: but
it leads to slightly different robust standard errors).


From roland.rproject at gmail.com  Wed Jun 13 16:13:32 2007
From: roland.rproject at gmail.com (Roland Rau)
Date: Wed, 13 Jun 2007 10:13:32 -0400
Subject: [R] R Book Advice Needed
In-Reply-To: <0946E293C7C22A45A0E33BA14FAA8D88F3881A@500MAIL.goldbox.com>
References: <0946E293C7C22A45A0E33BA14FAA8D88F3881A@500MAIL.goldbox.com>
Message-ID: <466FFB8C.60106@gmail.com>

Hi,

ngottlieb at marinercapital.com wrote:
> I am new to using R and would appreciate some advice on
> which books to start with to get up to speed on using R.
> 
> My Background:
> 1-C# programmer.
> 2-Programmed directly using IMSL (Now Visual Numerics).
> 3- Used in past SPSS and Statistica.
> 
> I put together a list but would like to pick the "best of" 
> and avoid redundancy.
> 
> Any suggestions on these books would be helpful (i.e. too much overlap,
> porly written etc?)
> 
> Books:
> 1-Analysis of Integrated and Co-integrated Time Series with R (Use R) -
> Bernhard Pfaff
> 2-An Introduction to R - W. N. Venables
> 3-Statistics: An Introduction using R - Michael J. Crawley
> 4-R Graphics (Computer Science and Data Analysis) - Paul Murrell
> 5-A Handbook of Statistical Analyses Using R - Brian S. Everitt
> 6-Introductory Statistics with R - Peter Dalgaard
> 7-Using R for Introductory Statistics - John Verzani
> 8-Data Analysis and Graphics Using R - John Maindonald;
> 9-Linear Models with R (Texts in Statistical Science) - Julian J.
> Faraway
> 10-Analysis of Financial Time Series (Wiley Series in Probability and
> Statistics)2nd edition - Ruey S. Tsay

as one other message says, it depends a lot on your ideas what you want 
to do with R. And, I'd like to add, how familiar you are with statistics.
One book I am missing in your list is Venables / Ripley: Modern Applied 
Statistics with S. I can highly recommend it.
If you are going to buy yourself only one book, then I would say: buy 
Venables/Ripley

Best,
Roland


From pietrzyk at research.ge.com  Wed Jun 13 16:20:09 2007
From: pietrzyk at research.ge.com (Pietrzykowski, Matthew (GE, Research))
Date: Wed, 13 Jun 2007 10:20:09 -0400
Subject: [R] Obtaining the cross validation coefficient of determination
Message-ID: <1EB58414BAB4014DB2C3E289FDF55FBB019A09D0@CINMLVEM15.e2k.ad.ge.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070613/1088af5b/attachment.pl 

From ngottlieb at marinercapital.com  Wed Jun 13 16:22:36 2007
From: ngottlieb at marinercapital.com (ngottlieb at marinercapital.com)
Date: Wed, 13 Jun 2007 10:22:36 -0400
Subject: [R] R Book Advice Needed
In-Reply-To: <466FFB8C.60106@gmail.com>
References: <0946E293C7C22A45A0E33BA14FAA8D88F3881A@500MAIL.goldbox.com>
	<466FFB8C.60106@gmail.com>
Message-ID: <0946E293C7C22A45A0E33BA14FAA8D88F3881D@500MAIL.goldbox.com>

Roland:

Thanks for your reply.

I have sort of pay my "dues" with statistics and doing the hard math
reading of
Proofs.

Years ago reading lots of books on Multi-variate Methods such
As Principal Components, Cluster Analysis, Discriminant Analysis,
Multi Dimensional Scaling(MDS), Optimization both LP and QP and more.

At this point, want to jump in avoiding all the
Mathematical proofs and just apply R and the packages for what I want to
do.

So as example, How to set-up a dataset (timeseries of returns),
formatted so I can do
A cluster Analysis and nicely format a dendrogram.

I am hoping the right books can show me, not concerned about
which distance measure and cluster method (i.e. Ward's, Single Linkage
etc)
Done this and know based on type of data what works best.

Just some simple books to jump start me right into practically applying
R.


Thanks for your response.

Regards,
Neil

-----Original Message-----
From: Roland Rau [mailto:roland.rproject at gmail.com] 
Sent: Wednesday, June 13, 2007 10:14 AM
To: Gottlieb, Neil
Cc: R-help at stat.math.ethz.ch
Subject: Re: [R] R Book Advice Needed

Hi,

ngottlieb at marinercapital.com wrote:
> I am new to using R and would appreciate some advice on which books to

> start with to get up to speed on using R.
> 
> My Background:
> 1-C# programmer.
> 2-Programmed directly using IMSL (Now Visual Numerics).
> 3- Used in past SPSS and Statistica.
> 
> I put together a list but would like to pick the "best of" 
> and avoid redundancy.
> 
> Any suggestions on these books would be helpful (i.e. too much 
> overlap, porly written etc?)
> 
> Books:
> 1-Analysis of Integrated and Co-integrated Time Series with R (Use R) 
> - Bernhard Pfaff 2-An Introduction to R - W. N. Venables
> 3-Statistics: An Introduction using R - Michael J. Crawley 4-R 
> Graphics (Computer Science and Data Analysis) - Paul Murrell 5-A 
> Handbook of Statistical Analyses Using R - Brian S. Everitt 
> 6-Introductory Statistics with R - Peter Dalgaard 7-Using R for 
> Introductory Statistics - John Verzani 8-Data Analysis and Graphics 
> Using R - John Maindonald; 9-Linear Models with R (Texts in 
> Statistical Science) - Julian J.
> Faraway
> 10-Analysis of Financial Time Series (Wiley Series in Probability and 
> Statistics)2nd edition - Ruey S. Tsay

as one other message says, it depends a lot on your ideas what you want
to do with R. And, I'd like to add, how familiar you are with
statistics.
One book I am missing in your list is Venables / Ripley: Modern Applied
Statistics with S. I can highly recommend it.
If you are going to buy yourself only one book, then I would say: buy
Venables/Ripley

Best,
Roland
--------------------------------------------------------

 
 
This information is being sent at the recipient's request or...{{dropped}}


From Greg.Snow at intermountainmail.org  Wed Jun 13 16:27:38 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Wed, 13 Jun 2007 08:27:38 -0600
Subject: [R] barplot and map overlay
Message-ID: <0b7001c7adc6$f997abb8$2e80320a@CO.IHC.COM>

Look at the subplot function in the TeachingDemos package.

-----Original Message-----
From: "H?ctor Villalobos" <hvillalo at ipn.mx>
To: "r-help at stat.math.ethz.ch" <r-help at stat.math.ethz.ch>
Sent: 6/11/07 5:48 PM
Subject: [R] barplot and map overlay

Hi,

I wonder if it is possible with the graphics package to overlay one or several plots
(barplots, for example) over a map. Data for the map is in a data frame with the
latitude and longitude coordinates, and then:

> plot(map$long, map$lat, type ="l")

produces the map. I want to put each barplot in specific locations on the map, namely
at the center of "statistical squares".

I?ve seen an example in Paul Murrell?s "R Graphics" book that seems appropriate
(grid package), but a bit complicated.

Thanks a lot for any advice.

H?ctor

--
H?ctor Villalobos <hvillalo at ipn.mx>
 CICIMAR - IPN
 A.P. 592. Col. Centro
 La Paz, Baja California Sur, M?XICO. 23000
 Tels. (+52 612) 122 53 44; 123 46 58; 123 47 34  ext. 2425
 Fax.  (+52 612) 122 53 22


	[[alternative HTML version deleted]]


From Greg.Snow at intermountainmail.org  Wed Jun 13 16:27:39 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Wed, 13 Jun 2007 08:27:39 -0600
Subject: [R] ievent.wait
Message-ID: <0b7101c7adc6$fa96c5aa$2e80320a@CO.IHC.COM>

Does 

locator(type='l')

(or type  ='b')  

Work for you?

-----Original Message-----
From: "ryestone" <ryestone at uvic.ca>
To: "r-help at stat.math.ethz.ch" <r-help at stat.math.ethz.ch>
Sent: 6/8/07 10:19 AM
Subject: [R] ievent.wait


I am working on a plot and would be like to click on a few points and then
have a line connect them. Could anyone help me with this or advise me in a
direction that would suit this. I know I would be using ievent.wait in iplot
but not sure about this.

thank you.
-- 
View this message in context: http://www.nabble.com/ievent.wait-tf3891095.html#a11030568
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From sfalcon at fhcrc.org  Wed Jun 13 16:33:39 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 13 Jun 2007 07:33:39 -0700
Subject: [R] installing Rgraphviz under fedora 5
In-Reply-To: <605b4120706130438v6dd912c6x93f9e9e554e0f4ac@mail.gmail.com>
	(marco R. help marco R. help's message of "Wed,
	13 Jun 2007 13:38:57 +0200")
References: <605b4120706130438v6dd912c6x93f9e9e554e0f4ac@mail.gmail.com>
Message-ID: <m2645rexfg.fsf@ziti.local>

"marco.R.help marco.R.help" <marco.r.help at gmail.com> writes:

> Dear list,
>
>  I have a lot of troubles installing Rgraphviz.
> I installed graphviz 2.13 from  "graphviz-2.13.20061222.0540.tar"
> I installed the library Rgraphviz

I'm pretty sure that you will have problems with graphviz 2.13 and
that you will need to use graphviz 2.12.

+ seth

-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
http://bioconductor.org


From ngottlieb at marinercapital.com  Wed Jun 13 16:34:19 2007
From: ngottlieb at marinercapital.com (ngottlieb at marinercapital.com)
Date: Wed, 13 Jun 2007 10:34:19 -0400
Subject: [R] R Book Advice Needed
In-Reply-To: <466F1CDA.6070903@skynet.be>
References: <0946E293C7C22A45A0E33BA14FAA8D88F3881A@500MAIL.goldbox.com>
	<466F1CDA.6070903@skynet.be>
Message-ID: <0946E293C7C22A45A0E33BA14FAA8D88F3881E@500MAIL.goldbox.com>

Thanks Alain.

Guess bite the bullet with limited budget buy bunch
>From Amazon and see what reads best and return the rest!.

One ends up collecting so many books (most of bought 5 books on Bayesian analysis years ago), 
still like browsing shelfs! 

Regards,
Neil

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Alain Reymond
Sent: Tuesday, June 12, 2007 6:23 PM
To: r-help at stat.math.ethz.ch
Subject: Re: [R] R Book Advice Needed

ngottlieb at marinercapital.com a ?crit :
> I am new to using R and would appreciate some advice on which books to 
> start with to get up to speed on using R.
>
> My Background:
> 1-C# programmer.
> 2-Programmed directly using IMSL (Now Visual Numerics).
> 3- Used in past SPSS and Statistica.
>
> I put together a list but would like to pick the "best of" 
> and avoid redundancy.
>
> Any suggestions on these books would be helpful (i.e. too much 
> overlap, porly written etc?)
>
> Books:
> 1-Analysis of Integrated and Co-integrated Time Series with R (Use R) 
> - Bernhard Pfaff 2-An Introduction to R - W. N. Venables
> 3-Statistics: An Introduction using R - Michael J. Crawley 4-R 
> Graphics (Computer Science and Data Analysis) - Paul Murrell 5-A 
> Handbook of Statistical Analyses Using R - Brian S. Everitt 
> 6-Introductory Statistics with R - Peter Dalgaard 7-Using R for 
> Introductory Statistics - John Verzani 8-Data Analysis and Graphics 
> Using R - John Maindonald; 9-Linear Models with R (Texts in 
> Statistical Science) - Julian J.
> Faraway
> 10-Analysis of Financial Time Series (Wiley Series in Probability and 
> Statistics)2nd edition - Ruey S. Tsay
>
> Thanks.
>
> Neil Gottlieb
>   
Neil,

I am also new to R and I just bought the book of Peter Dalgaard (n?6).
I find it very practical. It covers a large panel of principal statistical techniques that you can use directly. I thinkk it is a good start for a R beginner. At least, it is good for me!
Don't forget the many resources on the R website.

Regards.

--
Alain Reymond
CEIA
Bd Saint-Michel 119
1040 Bruxelles
Tel: +32 2 736 04 58
Fax: +32 2 736 58 02
alain.reymond at ceia.com
PGPId :  0xEFB06E2E

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
--------------------------------------------------------

 
 
This information is being sent at the recipient's request or...{{dropped}}


From markus.jantti at iki.fi  Wed Jun 13 16:36:39 2007
From: markus.jantti at iki.fi (=?ISO-8859-1?Q?Markus_J=E4ntti?=)
Date: Wed, 13 Jun 2007 17:36:39 +0300
Subject: [R] Fitted Value Pareto Distribution
In-Reply-To: <11097749.post@talk.nabble.com>
References: <11097749.post@talk.nabble.com>
Message-ID: <467000F7.3020003@iki.fi>

livia wrote:
> I would like to fit a Pareto Distribution and I am using the following codes. 
> 
> I thought the fitted (fit1) should be the fitted value for the data, is it
> correct? As the result of the "fitted" turns out to be a single value for
> all. 
> 
> fit=vglm(ycf1 ~ 1, pareto1(location=alpha), trace=TRUE, crit="c") 
> fitted(fit) 
> 
> The result is 
> fitted(fit)
>             [,1]
>  [1,] 0.07752694
>  [2,] 0.07752694
>  [3,] 0.07752694
>  [4,] 0.07752694
>  [5,] 0.07752694
>  [6,] 0.07752694
>  [7,] 0.07752694
>  [8,] 0.07752694
>  [9,] 0.07752694
> [10,] 0.07752694
> [11,] 0.07752694
> [12,] 0.07752694
> [13,] 0.07752694
> 
> Could anybody give me some advice? 
> 


Your model only includes an intercept, so the fitted value  is supposed to be 
the same for all units (there is nothing in your model that allows the fitted 
value to vary across units).

markus

-- 
Markus Jantti
Abo Akademi University
markus.jantti at iki.fi
http://www.iki.fi/~mjantti


From roland.rproject at gmail.com  Wed Jun 13 16:39:37 2007
From: roland.rproject at gmail.com (Roland Rau)
Date: Wed, 13 Jun 2007 10:39:37 -0400
Subject: [R] R Book Advice Needed
In-Reply-To: <0946E293C7C22A45A0E33BA14FAA8D88F3881D@500MAIL.goldbox.com>
References: <0946E293C7C22A45A0E33BA14FAA8D88F3881A@500MAIL.goldbox.com>
	<466FFB8C.60106@gmail.com>
	<0946E293C7C22A45A0E33BA14FAA8D88F3881D@500MAIL.goldbox.com>
Message-ID: <467001A9.70001@gmail.com>

Hi Neil,

ngottlieb at marinercapital.com wrote:
> 
> At this point, want to jump in avoiding all the
> Mathematical proofs and just apply R and the packages for what I want to
> do.
> 
I'd still recommend Venables/Ripley: Modern Applied Statistics with S 
(or often abbrev. MASS, which is also name of the package which supports 
this book and is part of any standard distribution of R).
Have a look at the table of contents. It is possible via amazon.com (and 
I guess also for a series of other books on your list).
I think using MASS together with the included manuals (especially "An 
Introduction to R") is probably the best way to get you started.

Best,
Roland


From ngottlieb at marinercapital.com  Wed Jun 13 16:43:25 2007
From: ngottlieb at marinercapital.com (ngottlieb at marinercapital.com)
Date: Wed, 13 Jun 2007 10:43:25 -0400
Subject: [R] R Book Advice Needed
In-Reply-To: <OF88CDFD73.E09BD8D4-ON882572F8.007C06BE-882572F8.007BEB02@irvine.edwards.com>
References: <OF88CDFD73.E09BD8D4-ON882572F8.007C06BE-882572F8.007BEB02@irvine.edwards.com>
Message-ID: <0946E293C7C22A45A0E33BA14FAA8D88F3881F@500MAIL.goldbox.com>

Cody:

Think you might have asked the question for me Neil.

I do time series analysis of return data in finance.

I will be creating a factor model based on PCA
Or Single Value Decomposition to get Eigenvectors 
Of the correlation matrix (tends to work better for finance data
Than covariance).

>From there will be doing style analysis, some optimization,
Regime switching, co-intregration testing and some
Statistical Process Control charting such as CUSUM.

Ultimately, what I learned over the years with statistics,
visualization is critical for my end-users. The don't
care what cluster method I use, be it Hierarchical
or Rosseau' newer methods such as Fanny, which
I find more robust.

In end I need practical stuff: as a programmer on 
Data types, data structures and even how to format and read in
Data.

So that's basically stuff I will be doing.

Neil

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Cody_Hamilton at edwards.com
Sent: Tuesday, June 12, 2007 6:36 PM
To: r-help at stat.math.ethz.ch
Subject: Re: [R] R Book Advice Needed



Alain,

Can you tell us what you plan to use R for?

Regards,
-Cody

ngottlieb at marinercapital.com a ?crit :
> I am new to using R and would appreciate some advice on which books to 
> start with to get up to speed on using R.
>
> My Background:
> 1-C# programmer.
> 2-Programmed directly using IMSL (Now Visual Numerics).
> 3- Used in past SPSS and Statistica.
>
> I put together a list but would like to pick the "best of"
> and avoid redundancy.
>
> Any suggestions on these books would be helpful (i.e. too much 
> overlap, porly written etc?)
>
> Books:
> 1-Analysis of Integrated and Co-integrated Time Series with R (Use R) 
> - Bernhard Pfaff 2-An Introduction to R - W. N. Venables
> 3-Statistics: An Introduction using R - Michael J. Crawley 4-R 
> Graphics (Computer Science and Data Analysis) - Paul Murrell 5-A 
> Handbook of Statistical Analyses Using R - Brian S. Everitt 
> 6-Introductory Statistics with R - Peter Dalgaard 7-Using R for 
> Introductory Statistics - John Verzani 8-Data Analysis and Graphics 
> Using R - John Maindonald; 9-Linear Models with R (Texts in 
> Statistical Science) - Julian J.
> Faraway
> 10-Analysis of Financial Time Series (Wiley Series in Probability and 
> Statistics)2nd edition - Ruey S. Tsay
>
> Thanks.
>
> Neil Gottlieb
>

Cody Hamilton, PhD
Edwards Lifesciences
	[[alternative HTML version deleted]]
--------------------------------------------------------

 
 
This information is being sent at the recipient's request or...{{dropped}}


From ripley at stats.ox.ac.uk  Wed Jun 13 16:48:09 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 13 Jun 2007 15:48:09 +0100 (BST)
Subject: [R] equivalent of windialog on unix??
In-Reply-To: <45551220706130636j47963f8ek51b8196199c04d9e@mail.gmail.com>
References: <45551220706130226j3c7e82dey429e318cfbb322c6@mail.gmail.com> 
	<Pine.LNX.4.64.0706131138130.22108@gannet.stats.ox.ac.uk>
	<45551220706130636j47963f8ek51b8196199c04d9e@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0706131547080.14002@gannet.stats.ox.ac.uk>

On Wed, 13 Jun 2007, BaKaLeGuM wrote:

> this is the answer :)
>
> toto <- tkmessageBox(title = "Rcmdr",
>   message = "Do you want to install Rcmdr?", icon = "question", type =
> "yesno")
> if (as.character(toto)=="yes"){
>
> it work on windows and unix (and i think mac)

Only if you have tcl/tk installed and an X11 server accessible.  E.g. it 
does not work on a remote machine in general.


> 2007/6/13, Prof Brian Ripley <ripley at stats.ox.ac.uk>:
>> 
>> ?readline
>> 
>> On Wed, 13 Jun 2007, BaKaLeGuM wrote:
>> 
>> > I have on a script something like this
>> > "
>> >
>> > toto = winDialog("yesno", "Do you want to install the package")
>> > if (toto=="YES"){
>> >
>> > "
>> >
>> > but it dont work on unix because of the "winDialog" i think..
>> >
>> > how can i do to change this for unix please?
>> >
>> > best regards
>> >
>> > vincent
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at stat.math.ethz.ch mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>> 
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>> 
>
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rdporto1 at terra.com.br  Wed Jun 13 16:50:55 2007
From: rdporto1 at terra.com.br (Rogerio Porto)
Date: Wed, 13 Jun 2007 11:50:55 -0300
Subject: [R] Awk and Vilno
Message-ID: <JJKX8V$81306E7F7E5D99DB33D8A0A3279E8BE9@multidominios>

Hey,

> What we should really compare is the four situations:
> R alone
> R + awk
> R + vilno
> R + awk + vilno
> and maybe "R + SAS Data step"
> and see what scripts are more  elegant (read 'short and understandable')

what do you guys think of creating a R-wiki page for syntax
comparisons among the various options to enhance R use?

I already have two sugestions:

1) syntax examples for using R and other tools to manipulate
and analyze large datasets (with a concise description of the
datasets);

2) syntax examples for using R and other tools (or R alone) to clean
and prepare datasets (simple and very small datasets, for didatic
purposes).

I think this could be interesting for R users and to promote other
software tools, since it seems there is a lot of R users that use
other tools also.

Besides that, questions on those two above subjects are prevalent
at this list. Thus a wiki page seems to be the right place to discuss
and teach this to other users.

What do you think?

Rogerio


From ngottlieb at marinercapital.com  Wed Jun 13 16:59:25 2007
From: ngottlieb at marinercapital.com (ngottlieb at marinercapital.com)
Date: Wed, 13 Jun 2007 10:59:25 -0400
Subject: [R] R Book Advice Needed
In-Reply-To: <467001A9.70001@gmail.com>
References: <0946E293C7C22A45A0E33BA14FAA8D88F3881A@500MAIL.goldbox.com>
	<466FFB8C.60106@gmail.com>
	<0946E293C7C22A45A0E33BA14FAA8D88F3881D@500MAIL.goldbox.com>
	<467001A9.70001@gmail.com>
Message-ID: <0946E293C7C22A45A0E33BA14FAA8D88F38820@500MAIL.goldbox.com>

Thanks Roland, fortunately I dug up MASS by Venables/Ripley
buried under all my econometric and statistic books.

Will be reading it today and order a few of the R books
for additional support.


Thanks for your suggestions...
Regards,
Neil 

-----Original Message-----
From: Roland Rau [mailto:roland.rproject at gmail.com] 
Sent: Wednesday, June 13, 2007 10:40 AM
To: Gottlieb, Neil
Cc: R-help at stat.math.ethz.ch
Subject: Re: [R] R Book Advice Needed

Hi Neil,

ngottlieb at marinercapital.com wrote:
> 
> At this point, want to jump in avoiding all the Mathematical proofs 
> and just apply R and the packages for what I want to do.
> 
I'd still recommend Venables/Ripley: Modern Applied Statistics with S
(or often abbrev. MASS, which is also name of the package which supports
this book and is part of any standard distribution of R).
Have a look at the table of contents. It is possible via amazon.com (and
I guess also for a series of other books on your list).
I think using MASS together with the included manuals (especially "An
Introduction to R") is probably the best way to get you started.

Best,
Roland
--------------------------------------------------------

 
 
This information is being sent at the recipient's request or...{{dropped}}


From P.Dalgaard at biostat.ku.dk  Wed Jun 13 17:03:41 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 13 Jun 2007 17:03:41 +0200
Subject: [R] R Book Advice Needed
In-Reply-To: <466FFB8C.60106@gmail.com>
References: <0946E293C7C22A45A0E33BA14FAA8D88F3881A@500MAIL.goldbox.com>
	<466FFB8C.60106@gmail.com>
Message-ID: <4670074D.404@biostat.ku.dk>

Roland Rau wrote:
> Hi,
>
> ngottlieb at marinercapital.com wrote:
>   
>> I am new to using R and would appreciate some advice on
>> which books to start with to get up to speed on using R.
>>
>> My Background:
>> 1-C# programmer.
>> 2-Programmed directly using IMSL (Now Visual Numerics).
>> 3- Used in past SPSS and Statistica.
>>
>> I put together a list but would like to pick the "best of" 
>> and avoid redundancy.
>>
>> Any suggestions on these books would be helpful (i.e. too much overlap,
>> porly written etc?)
>>
>> Books:
>> 1-Analysis of Integrated and Co-integrated Time Series with R (Use R) -
>> Bernhard Pfaff
>> 2-An Introduction to R - W. N. Venables
>> 3-Statistics: An Introduction using R - Michael J. Crawley
>> 4-R Graphics (Computer Science and Data Analysis) - Paul Murrell
>> 5-A Handbook of Statistical Analyses Using R - Brian S. Everitt
>> 6-Introductory Statistics with R - Peter Dalgaard
>> 7-Using R for Introductory Statistics - John Verzani
>> 8-Data Analysis and Graphics Using R - John Maindonald;
>> 9-Linear Models with R (Texts in Statistical Science) - Julian J.
>> Faraway
>> 10-Analysis of Financial Time Series (Wiley Series in Probability and
>> Statistics)2nd edition - Ruey S. Tsay
>>     
>
> as one other message says, it depends a lot on your ideas what you want 
> to do with R. And, I'd like to add, how familiar you are with statistics.
> One book I am missing in your list is Venables / Ripley: Modern Applied 
> Statistics with S. I can highly recommend it.
> If you are going to buy yourself only one book, then I would say: buy 
> Venables/Ripley
>
>
>   
And given the programming background, also check out the other V&R book,
"S Programming". (This is about R too).


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ripley at stats.ox.ac.uk  Wed Jun 13 17:07:08 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 13 Jun 2007 16:07:08 +0100 (BST)
Subject: [R] How to install RMySQL package in R 2.5 in Windows OS?
In-Reply-To: <000001c7adb1$7f4bd000$7000a8c0@scbit94ec75129>
References: <000001c7adb1$7f4bd000$7000a8c0@scbit94ec75129>
Message-ID: <Pine.LNX.4.64.0706131603430.14002@gannet.stats.ox.ac.uk>

On Wed, 13 Jun 2007, Ruixin ZHU wrote:

> Dear R-users,
>
> It seems that install.packages( ) doesn't work to RMySQL package.

Under Windows, yes.  You need the MySQL client libraries for your version 
of MySQL (or something very close to the same version), so the only safe 
way is to install from the sources.  The latter is not hard and there are 
instructions in the package.


> Would anybody have the experience of that?
>
> Thanks
> _____________________________________________
> Dr.Ruixin ZHU
> Shanghai Center for Bioinformation Technology
> rxzhu at scbit.org
> zhurx at mail.sioc.ac.cn
> 86-21-13040647832
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From sundar.dorai-raj at pdf.com  Wed Jun 13 17:07:43 2007
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 13 Jun 2007 08:07:43 -0700
Subject: [R] ievent.wait
In-Reply-To: <0b7101c7adc6$fa96c5aa$2e80320a@CO.IHC.COM>
References: <0b7101c7adc6$fa96c5aa$2e80320a@CO.IHC.COM>
Message-ID: <4670083F.3030109@pdf.com>

Hi, Greg,

type = 'b' won't work according to ?locator. Try type = 'o'.

HTH,x

--sundar

Greg Snow said the following on 6/13/2007 7:27 AM:
> Does 
> 
> locator(type='l')
> 
> (or type  ='b')  
> 
> Work for you?
> 
> -----Original Message-----
> From: "ryestone" <ryestone at uvic.ca>
> To: "r-help at stat.math.ethz.ch" <r-help at stat.math.ethz.ch>
> Sent: 6/8/07 10:19 AM
> Subject: [R] ievent.wait
> 
> 
> I am working on a plot and would be like to click on a few points and then
> have a line connect them. Could anyone help me with this or advise me in a
> direction that would suit this. I know I would be using ievent.wait in iplot
> but not sure about this.
> 
> thank you.


From helprhelp at gmail.com  Wed Jun 13 17:11:45 2007
From: helprhelp at gmail.com (Weiwei Shi)
Date: Wed, 13 Jun 2007 11:11:45 -0400
Subject: [R] pretty report
In-Reply-To: <0JJJ007SSYRUKNXB@vms048.mailsrvcs.net>
References: <cdf817830706121401u54bd6df9nb22b6acdd2e33d6b@mail.gmail.com>
	<p06240801c294f38685ca@192.168.11.7>
	<0JJJ007SSYRUKNXB@vms048.mailsrvcs.net>
Message-ID: <cdf817830706130811s6ef40cc5x355b13afefe88a7e@mail.gmail.com>

I think my initial intention is to write multiple worksheets for
multiple data frames. write.csv or write.table cannot do that.

On 6/12/07, Robert A LaBudde <ral at lcfltd.com> wrote:
> At 09:13 PM 6/12/2007, Don wrote:
> >At 5:01 PM -0400 6/12/07, Weiwei Shi wrote:
> > >Dear Listers:
> > >
> > >I have a couple of data frames to report and each corresponds to
> > >different condtions, e.g. conditions=c(10, 15, 20, 25). In this
> > >examples, four data frames need to be exported in a "pretty" report.
> > >
> > >I knew Perl has some module for exporting data to Excel and after
> > >googling, I found R does not.
> >
> >I use write.table(), name the file with ".xls" as the suffix, then
> >outside R I double-click on it and it opens in Excel. Granted, it's a
> >text file, and Excel is opening a text file, but none the less, I
> ><snip>
>
> Note that files with a ".csv" extension are also associated with
> Excel and can opened with a double-click. Comma-separated-value files
> also can be unambiguously loaded by Excel without parsing.
>
> ================================================================
> Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
> Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
> 824 Timberlake Drive                     Tel: 757-467-0954
> Virginia Beach, VA 23464-3239            Fax: 757-467-2947
>
> "Vere scire est per causas scire"
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Weiwei Shi, Ph.D
Research Scientist
GeneGO, Inc.

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III


From ggrothendieck at gmail.com  Wed Jun 13 17:31:27 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 13 Jun 2007 11:31:27 -0400
Subject: [R] R Book Advice Needed
In-Reply-To: <0946E293C7C22A45A0E33BA14FAA8D88F3881A@500MAIL.goldbox.com>
References: <AcetOHGUjKlkffZMTzS7dKT54CJpIQ==>
	<0946E293C7C22A45A0E33BA14FAA8D88F3881A@500MAIL.goldbox.com>
Message-ID: <971536df0706130831p753ae46bgf46d7d07456ab0c@mail.gmail.com>

There are some online sources that you might find useful.  You could
get started on those while you decide what books to get:

- CRAN contributed documentation
  http://cran.r-project.org/other-docs.html

- S Poetry
  http://www.burns-stat.com/pages/spoetry.html

- Zoonekynd book
  http://zoonek2.free.fr/UNIX/48_R/all.html

- R manuals
  http://cran.r-project.org/manuals.html

- R News
  http://cran.r-project.org/doc/Rnews/

- various packages have vignettes which are PDF documents that discuss the
  package, often at length.
    vignette()  # shows vignettes for installed packages

- there was a vignette browser posted to r-devel recently
  http://tolstoy.newcastle.edu.au/R/e2/devel/07/06/3498.html

On 6/12/07, ngottlieb at marinercapital.com <ngottlieb at marinercapital.com> wrote:
> I am new to using R and would appreciate some advice on
> which books to start with to get up to speed on using R.
>
> My Background:
> 1-C# programmer.
> 2-Programmed directly using IMSL (Now Visual Numerics).
> 3- Used in past SPSS and Statistica.
>
> I put together a list but would like to pick the "best of"
> and avoid redundancy.
>
> Any suggestions on these books would be helpful (i.e. too much overlap,
> porly written etc?)
>
> Books:
> 1-Analysis of Integrated and Co-integrated Time Series with R (Use R) -
> Bernhard Pfaff
> 2-An Introduction to R - W. N. Venables
> 3-Statistics: An Introduction using R - Michael J. Crawley
> 4-R Graphics (Computer Science and Data Analysis) - Paul Murrell
> 5-A Handbook of Statistical Analyses Using R - Brian S. Everitt
> 6-Introductory Statistics with R - Peter Dalgaard
> 7-Using R for Introductory Statistics - John Verzani
> 8-Data Analysis and Graphics Using R - John Maindonald;
> 9-Linear Models with R (Texts in Statistical Science) - Julian J.
> Faraway
> 10-Analysis of Financial Time Series (Wiley Series in Probability and
> Statistics)2nd edition - Ruey S. Tsay
>
> Thanks.
>
> Neil Gottlieb


From jh910 at juno.com  Wed Jun 13 17:29:15 2007
From: jh910 at juno.com (J. R. M. Hosking)
Date: Wed, 13 Jun 2007 11:29:15 -0400
Subject: [R] Fitted Value Pareto Distribution
In-Reply-To: <11097749.post@talk.nabble.com>
References: <11097749.post@talk.nabble.com>
Message-ID: <f4p2gc$22e$1@sea.gmane.org>

livia wrote:
> I would like to fit a Pareto Distribution and I am using the following codes. 
> 
> I thought the fitted (fit1) should be the fitted value for the data, is it
> correct? As the result of the "fitted" turns out to be a single value for
> all. 
> 
> fit=vglm(ycf1 ~ 1, pareto1(location=alpha), trace=TRUE, crit="c") 
> fitted(fit) 
> 
> The result is 
> fitted(fit)
>             [,1]
>  [1,] 0.07752694
>  [2,] 0.07752694
>  [3,] 0.07752694
>  [4,] 0.07752694
>  [5,] 0.07752694
>  [6,] 0.07752694
>  [7,] 0.07752694
>  [8,] 0.07752694
>  [9,] 0.07752694
> [10,] 0.07752694
> [11,] 0.07752694
> [12,] 0.07752694
> [13,] 0.07752694
> 
> Could anybody give me some advice? 
> 

I don't have whatever package function 'vglm' comes from (did you
follow the instructions in the last two lines of your post?), but you
can fit a GPD and get fitted values for it by some such approach as
this:

   library(POT)
   threshold <- 0  # probably
   para <- fitgpd(ycf1, threshold, method="pwmu")$param
   ycf1.fit <- qgpd( ppoints(ycf1, a=0.44), threshold, para[1], para[2])

Note that the above code contains my own preferences for fitting
method and plotting positions: yours may differ.


J. R. M. Hosking


From yn19832 at msn.com  Wed Jun 13 17:43:36 2007
From: yn19832 at msn.com (livia)
Date: Wed, 13 Jun 2007 08:43:36 -0700 (PDT)
Subject: [R] VGAM Pareto
Message-ID: <11102328.post@talk.nabble.com>


I would like to fit a Pareto Distribution and I am using the following codes

fit=vglm(ycf1 ~ 1, pareto1(location=alpha), trace=TRUE, crit="c")
fitted(fit)

But the fitted values turn out to be the same for each observation. I guess
the problem is with "ycf1 ~ 1",

I would be grateful if anyone can give me some advice on how to define the
formula.

Many thanks
-- 
View this message in context: http://www.nabble.com/VGAM-Pareto-tf3915557.html#a11102328
Sent from the R help mailing list archive at Nabble.com.


From ngottlieb at marinercapital.com  Wed Jun 13 17:46:56 2007
From: ngottlieb at marinercapital.com (ngottlieb at marinercapital.com)
Date: Wed, 13 Jun 2007 11:46:56 -0400
Subject: [R] Formatted Data File Question for Clustering -Quickie Project
Message-ID: <0946E293C7C22A45A0E33BA14FAA8D88F38822@500MAIL.goldbox.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070613/589973e5/attachment.pl 

From bolker at ufl.edu  Wed Jun 13 19:09:52 2007
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 13 Jun 2007 17:09:52 +0000 (UTC)
Subject: [R] VGAM Pareto
References: <11102328.post@talk.nabble.com>
Message-ID: <loom.20070613T190231-620@post.gmane.org>

livia <yn19832 <at> msn.com> writes:

> 
> 
> I would like to fit a Pareto Distribution and I am using the following codes
> 
> fit=vglm(ycf1 ~ 1, pareto1(location=alpha), trace=TRUE, crit="c")
> fitted(fit)
> 
> But the fitted values turn out to be the same for each observation. I guess
> the problem is with "ycf1 ~ 1",
> 

   Are you trying to fit the distribution to set of a values,
or are you trying to fit a model with a Pareto error distribution
(in which case you would be fitting the distribution to the observations
within each group separately, or fitting the distribution with
parameters changing as a function of covariates, depending on
your mixture of factor and numeric predictors)?   If the former,
then there aren't any "fitted" values to be gotten.

   Perhaps if you say a little more about the problem you're trying
to solve you will get more useful help.

  Also see http://tolstoy.newcastle.edu.au/R/e2/help/06/09/0133.html
and the answers to it.


From ngottlieb at marinercapital.com  Wed Jun 13 19:14:47 2007
From: ngottlieb at marinercapital.com (ngottlieb at marinercapital.com)
Date: Wed, 13 Jun 2007 13:14:47 -0400
Subject: [R] R Book Advice Needed
In-Reply-To: <467021AC.407@burns-stat.com>
References: <OF88CDFD73.E09BD8D4-ON882572F8.007C06BE-882572F8.007BEB02@irvine.edwards.com>
	<0946E293C7C22A45A0E33BA14FAA8D88F3881F@500MAIL.goldbox.com>
	<46700CEB.5030705@burns-stat.com>
	<0946E293C7C22A45A0E33BA14FAA8D88F38826@500MAIL.goldbox.com>
	<467021AC.407@burns-stat.com>
Message-ID: <0946E293C7C22A45A0E33BA14FAA8D88F3882B@500MAIL.goldbox.com>

Pat:

I have done PCA to extract eigenvectors on return series for equities.

Rotation does help and does make factors more understandable,
have had success doing this.

You are right, when doing pure statistical factors, one tends to find first factor
which explains most of the variance is the Market Beta.

Our scree score showed 20 factors explains most of the variance in equity returns.

If you sort on the factor loadings, the other first few factors tend to things such as 
interest rates,Energy prices, currency exposure. After that it gets a little more
complicated what the factors are but they tend to be sector specific. 

That's the major complaint about pure statistical factor analysis...
Interpretation but can get reasonable idea by sorting factor cores.

As for missing values, a lot of work has been done there with sampling
such as EM and Maximum Likehood.

I will check out your R code. Hopefully it will get included
Eventually in the Portfolio package.

Being new to R, will need to figure out how to "source" the code to R!

Regards,
Neil

-----Original Message-----
From: Patrick Burns [mailto:patrick at burns-stat.com] 
Sent: Wednesday, June 13, 2007 12:56 PM
To: Gottlieb, Neil
Subject: Re: [R] R Book Advice Needed

Neil,

'factor.model.stat' is a part of POP, which is an R package (that runs under S-PLUS as well).

We've made 'factor.model.stat' public domain so you don't have to have POP in order to use it.  The version of 'factor.model.stat' in the Public Domain area is not in a package.
You can just 'source' the code.  I just checked and 'factor.model.stat' is not in the 'portfolio' package -- I'm not sure why they haven't included it.

The statistical factors are already orthogonal.  Rotation is only aimed at trying to make them more interpretable.  I'm not very optimistic about that, other than the first factor represents the market.  But if you do have success, I'd be interested in hearing of it.

A caveat to the paragraph above is that orthogonality assumes no missing values.  Having no missing values is not a very common occurrence though (at least for a lot of us).  Most of the code in 'factor.model.stat' is handling missing values.

I haven't had call for rotations, but I'd be extremely surprised if there weren't a bunch somewhere in R.  The 'RSiteSearch' function should be your friend for this.

Pat


ngottlieb at marinercapital.com wrote:

>Thank Patrick. Is factor.model.stat part of r packages?
>
>Also want to rotate the factors so they are orthogonal. 
>Do you have varimax or promax rotation functio?
>
>Neil
>
>-----Original Message-----
>From: Patrick Burns [mailto:patrick at burns-stat.com]
>Sent: Wednesday, June 13, 2007 11:28 AM
>To: Gottlieb, Neil
>Subject: Re: [R] R Book Advice Needed
>
>Most or all of the work for your factor model should be done in 'factor.model.stat' from the Public Domain page of the Burns Statistics website.  It is also in the 'portfolio' package, I believe.
>
>Patrick Burns
>patrick at burns-stat.com
>+44 (0)20 8525 0696
>http://www.burns-stat.com
>(home of S Poetry and "A Guide for the Unwilling S User")
>
>ngottlieb at marinercapital.com wrote:
>
>  
>
>>Cody:
>>
>>Think you might have asked the question for me Neil.
>>
>>I do time series analysis of return data in finance.
>>
>>I will be creating a factor model based on PCA Or Single Value 
>>Decomposition to get Eigenvectors Of the correlation matrix (tends to 
>>work better for finance data Than covariance).
>>
>>>From there will be doing style analysis, some optimization,
>>Regime switching, co-intregration testing and some Statistical Process 
>>Control charting such as CUSUM.
>>
>>Ultimately, what I learned over the years with statistics, 
>>visualization is critical for my end-users. The don't care what 
>>cluster method I use, be it Hierarchical or Rosseau' newer methods 
>>such as Fanny, which I find more robust.
>>
>>In end I need practical stuff: as a programmer on Data types, data 
>>structures and even how to format and read in Data.
>>
>>So that's basically stuff I will be doing.
>>
>>Neil
>>
>>-----Original Message-----
>>From: r-help-bounces at stat.math.ethz.ch 
>>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
>>Cody_Hamilton at edwards.com
>>Sent: Tuesday, June 12, 2007 6:36 PM
>>To: r-help at stat.math.ethz.ch
>>Subject: Re: [R] R Book Advice Needed
>>
>>
>>
>>Alain,
>>
>>Can you tell us what you plan to use R for?
>>
>>Regards,
>>-Cody
>>
>>ngottlieb at marinercapital.com a ?crit :
>> 
>>
>>    
>>
>>>I am new to using R and would appreciate some advice on which books 
>>>to start with to get up to speed on using R.
>>>
>>>My Background:
>>>1-C# programmer.
>>>2-Programmed directly using IMSL (Now Visual Numerics).
>>>3- Used in past SPSS and Statistica.
>>>
>>>I put together a list but would like to pick the "best of"
>>>and avoid redundancy.
>>>
>>>Any suggestions on these books would be helpful (i.e. too much 
>>>overlap, porly written etc?)
>>>
>>>Books:
>>>1-Analysis of Integrated and Co-integrated Time Series with R (Use R)
>>>- Bernhard Pfaff 2-An Introduction to R - W. N. Venables
>>>3-Statistics: An Introduction using R - Michael J. Crawley 4-R 
>>>Graphics (Computer Science and Data Analysis) - Paul Murrell 5-A 
>>>Handbook of Statistical Analyses Using R - Brian S. Everitt 
>>>6-Introductory Statistics with R - Peter Dalgaard 7-Using R for 
>>>Introductory Statistics - John Verzani 8-Data Analysis and Graphics 
>>>Using R - John Maindonald; 9-Linear Models with R (Texts in 
>>>Statistical Science) - Julian J.
>>>Faraway
>>>10-Analysis of Financial Time Series (Wiley Series in Probability and 
>>>Statistics)2nd edition - Ruey S. Tsay
>>>
>>>Thanks.
>>>
>>>Neil Gottlieb
>>>
>>>   
>>>
>>>      
>>>
>>Cody Hamilton, PhD
>>Edwards Lifesciences
>>	[[alternative HTML version deleted]]
>>--------------------------------------------------------
>>
>>
>>
>>This information is being sent at the recipient's request 
>>or...{{dropped}}
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> 
>>
>>    
>>
>
>
>  
>
--------------------------------------------------------

 
 
This information is being sent at the recipient's request or...{{dropped}}


From Horace.Tso at pgn.com  Wed Jun 13 19:35:33 2007
From: Horace.Tso at pgn.com (Horace Tso)
Date: Wed, 13 Jun 2007 10:35:33 -0700
Subject: [R] Viewing a data object
In-Reply-To: <499415.96653.qm@web39706.mail.mud.yahoo.com>
References: <466E7B310200006500006405@pgn.com>
	<499415.96653.qm@web39706.mail.mud.yahoo.com>
Message-ID: <466FC87502000065000064C3@pgn.com>

Stephen and Christophe,

I'm aware of fix and edit and the few issues with fix. Thus my reluctance to use them. Emacs may be the way to go, but from what I heard here it has a steep learning curve. The autocompletion feature in 2.5.1 is great. Andy Liaw points me to JGR which I'm just about to jump in.

I was hoping something like the head/tail function with a little more flexibility may also be useful to a lot of folks here.

vw = function( ...., location, nlines=10 ) {
     #'...' gives the string fragments that identify an object
     # location : 0.5 = middle, 0.25 = the first quartile, etc....
     # nlines : the number of lines to show
}

vw(Auro, 0.5)

returns the middle part of the first data frame it finds with name string starting with "Auro". This function should be easy to write with all thse regular expression functions.

Well, I'll save it for my Christmas wish list.

H.


>>> Stephen Tucker <brown_emu at yahoo.com> 6/12/2007 11:25 PM >>>
Hi Horace,

I have also thought that it may be useful but I don't know of any Object
Explorer available for R.

However, (you may alread know this but) 
(1) you can view your list of objects in R with objects(), 
(2) view objects in a spreadsheet-like table (if they are matrices or data
frames) with invisible(edit(objectName)) [which isn't easy on the fingers].
fix(objectName) is also a shorter option but it has the side effect of
possibly changing your object when you close the viewing data. For instance,
this can happen if you mistakenly type something into a cell; it can also
change your column classes when you don't - for example:

> options(stringsAsFactors=TRUE)
> x <- data.frame(letters[1:5],1:5)
> sapply(x,class)
letters.1.5.         X1.5 
    "factor"    "integer" 
> fix(x) # no user-changes made
> sapply(x,class)
letters.1.5.         X1.5 
    "factor"    "numeric" 

(3) I believe Deepayan Sarkar contributed the tab-completion capability at
the command line. So unless you have a lot of objects beginning with
'AuroraStoch...' you should be able to type a few letters and let the
auto-completion handle the rest.

Best regards,

ST


--- Horace Tso <Horace.Tso at pgn.com> wrote:

> Dear list,
> 
> First apologize that this is trivial and just betrays my slothfulness at
> the keyboard. I'm sick of having to type a long name just to get a glimpse
> of something. For example, if my data frame is named
> 'AuroraStochasticRunsJune1.df" and I want to see what the middle looks
> like, I have to type
> 
> AuroraStochasticRunsJune1.df[ 400:500, ]
> 
> And often I'm not even sure rows 400 to 500 are what I want to see.  I
> might have to type the same line many times.
> 
> Is there sort of a R-equivalence of the Object Explorer, like in Splus,
> where I could mouse-click an object in a list and a window pops up?  Short
> of that, is there any trick of saving a couple of keystrokes here and
> there?
> 
> Thanks for tolerating this kind of annoying questions.
> 
> H.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code.
> 



 
____________________________________________________________________________________
Sucker-punch spam with award-winning protection.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
and provide commented, minimal, self-contained, reproducible code.


From brown_emu at yahoo.com  Wed Jun 13 19:46:55 2007
From: brown_emu at yahoo.com (Stephen Tucker)
Date: Wed, 13 Jun 2007 10:46:55 -0700 (PDT)
Subject: [R] passing (or obtaining) index or element name of list to FUN
	in lapply()
In-Reply-To: <Pine.LNX.4.64.0706130723500.12760@gannet.stats.ox.ac.uk>
Message-ID: <237294.66850.qm@web39711.mail.mud.yahoo.com>

Hi Professor Ripley,

Thanks for the response. I apologize, my examples were not too real (though
your solutions are indeed clever)... I was trying to ask more generally
whether the element name or index of 'listObj' could be obtained by the
user-function 'myfunction' when used in lapply(X=listObj,FUN=myfunction);
below I illustrate two cases in which I have come across this desire:
(1) In 'Example 1' I essentially take the list element and do some
transformations (optionally some number-crunching), and then plot it with the
element name of the list for the title.
(2) In 'Example 2' I want to read in data from the list element and write the
contents to a file; writing a header line only when operating on the first
element of the list.

## data specification
data1 <- "var1 var2
-0.44 0.17
1.03 0.93
0.85 0.39"
data2 <- "var1 var2
-0.16 0.97
0.93 0.23
0.80 0.42"
L <- list(data1=data1,data2=data2)

##=== Example 1 (want element name) ===
## function definition
plottingfunc <- function(i,x) {
  plot(read.table(textConnection(x[[i]]),header=TRUE),main=names(x)[i])
}
## function application
par(mfrow=c(2,1))
lapply(seq(along=L),plottingfunc,x=L)

##=== Example 2 (want element index) ===
## function definition
readwritefunc <- function(i,x,fout) {
  data <- read.table(textConnection(x[[i]]),header=TRUE)
  if(i==1) cat(paste(colnames(data),collapse=","),"\n",file=fout)
  write.table(data,file=fout,sep=",",col=FALSE,
              row=FALSE,quote=FALSE,append=TRUE)
}
## function application
fout <- file("out.dat",open="w")
lapply(seq(along=L),readwritefunc,x=L,fout=fout)
close(fout)

Since the above code works, I suppose this is more of a question of
aesthetics since I thought the spirit of lapply() was to operate on the
elements of a list and not its indices - I thought perhaps there is a way to
get the index number and element name from within the user-function.

Also, I recall a lesson on 'loop avoidance' from an earlier version of MASS;
this was in the days of S-PLUS dominance and perhaps less applicable now to R
as you mentioned... But old habits die hard; my amygdala still invokes a fear
response at the thought of a loop... (and as of recently, I have been
infatuated with the notion of adhering, albeit loosely, to the 'functional
programming' paradigm which makes me doubly fearful of loops)

Thanks and best regards,

Stephen

--- Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> On Tue, 12 Jun 2007, Stephen Tucker wrote:
> 
> > Hello everyone,
> >
> > I wonder if there is a way to pass the index or name of a list to a
> > user-specified function in lapply(). For instance, my desired effect is
> > something like the output of
> >
> >> L <- list(jack=4098,sape=4139)
> >> lapply(seq(along=L),function(i,x) if(i==1) "jack" else "sape",x=L)
> > [[1]]
> > [1] "jack"
> >
> > [[2]]
> > [1] "sape"
> 
> as.list(names(L))
> 
> >> lapply(seq(along=L),function(i,x) if(names(x)[i]=="jack") 1 else 2,x=L)
> > [[1]]
> > [1] 1
> >
> > [[2]]
> > [1] 2
> 
> as.list(seq_along(L))
> 
> lapply() can be faster than a for-loop, but usually not by much: its main 
> advantage is clarity of code.
> 
> I think we need a real-life example to see what you are trying to do.
> 
> > But by passing L as the first argument of lapply(). I thought there was a
> > tangentially-related post on this mailing list in the past but I don't
> recall
> > that it was ever addressed directly (and I can't seem to find it now).
> The
> > examples above are perfectly good alternatives especially if I wrap each
> of
> > the lines in "names<-"() to return lists with appropriate names assigned,
> but
> 
> Try something like
> 
> L[] <- lapply(seq_along(L),function(i,x) if(i==1) "jack" else "sape",x=L)
> 
> > it feels like I am essentially writing a FOR-LOOP - though I was
> surprised to
> > find that speed-wise, it doesn't seem to make much of a difference
> (unless I
> > have not selected a rigorous test):
> >
> >> N <- 10000
> >> y <- runif(N)
> > ## looping through elements of y
> >> system.time(lapply(y,
> > +                    function(x) {
> > +                      set.seed(222)
> > +                      mean(rnorm(1e4,x,1))
> > +                    }))
> > [1] 21.00  0.17 21.29    NA    NA
> > ## looping through indices
> >> system.time(lapply(1:N,
> > +                    function(x,y) {
> > +                      set.seed(222)
> > +                      mean(rnorm(1e4,y[x],1))
> > +                      },y=y))
> > [1] 21.09  0.14 21.26    NA    NA
> >
> > In Python, there are methods for Lists and Dictionaries called
> enumerate(),
> > and iteritems(), respectively. Example applications:
> >
> > ## a list
> > L = ['a','b','c']
> > [x for x in enumerate(L)]
> > ## returns index of list along with the list element
> > [(0, 'a'), (1, 'b'), (2, 'c')]
> >
> > ## a dictionary
> > D = {'jack': 4098, 'sape': 4139}
> > [x for x in D.iteritems()]
> > ## returns element key (name) along with element contents
> > [('sape', 4139), ('jack', 4098)]
> >
> > And this is something of the effect I was looking for...
> >
> > Thanks to all,
> >
> > Stephen
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>


From hvillalo at ipn.mx  Wed Jun 13 19:49:14 2007
From: hvillalo at ipn.mx (=?ISO-8859-1?Q?H=E9ctor_Villalobos?=)
Date: Wed, 13 Jun 2007 11:49:14 -0600
Subject: [R] barplot and map overlay
In-Reply-To: <0b7001c7adc6$f997abb8$2e80320a@CO.IHC.COM>
References: <0b7001c7adc6$f997abb8$2e80320a@CO.IHC.COM>
Message-ID: <466FD9BA.17502.C2804C@hvillalo.ipn.mx>

Thank you Greg,

It works!



On 13 Jun 2007 at 8:27, Greg Snow wrote:

> Look at the subplot function in the TeachingDemos package.
> 
> -----Original Message-----
> From: "H?ctor Villalobos" <hvillalo at ipn.mx>
> To: "r-help at stat.math.ethz.ch" <r-help at stat.math.ethz.ch>
> Sent: 6/11/07 5:48 PM
> Subject: [R] barplot and map overlay
> 
> Hi,
> 
> I wonder if it is possible with the graphics package to overlay one or
> several plots (barplots, for example) over a map. Data for the map is
> in a data frame with the latitude and longitude coordinates, and then:
> 
> > plot(map$long, map$lat, type ="l")
> 
> produces the map. I want to put each barplot in specific locations on
> the map, namely at the center of "statistical squares".
> 
> I?ve seen an example in Paul Murrell?s "R Graphics" book that seems
> appropriate (grid package), but a bit complicated.
> 
> Thanks a lot for any advice.
> 
> H?ctor
-- 
H?ctor Villalobos <hvillalo at ipn.mx> 
 CICIMAR - IPN
 A.P. 592. Col. Centro 
 La Paz, Baja California Sur, M?XICO. 23000
 Tels. (+52 612) 122 53 44; 123 46 58; 123 47 34  ext. 2425
 Fax.  (+52 612) 122 53 22


From ryestone at uvic.ca  Wed Jun 13 20:08:44 2007
From: ryestone at uvic.ca (ryestone)
Date: Wed, 13 Jun 2007 11:08:44 -0700 (PDT)
Subject: [R] ievent.wait
In-Reply-To: <4670083F.3030109@pdf.com>
References: <11030568.post@talk.nabble.com>
	<0b7101c7adc6$fa96c5aa$2e80320a@CO.IHC.COM>
	<4670083F.3030109@pdf.com>
Message-ID: <11105384.post@talk.nabble.com>


With locator( ) does it only work in a regular R plot or can I use it with
iPlot?
I am having difficulty getting it to be used with Iplots, it just calls up a
new screen when the function is called.

Stone.


Sundar Dorai-Raj wrote:
> 
> Hi, Greg,
> 
> type = 'b' won't work according to ?locator. Try type = 'o'.
> 
> HTH,x
> 
> --sundar
> 
> Greg Snow said the following on 6/13/2007 7:27 AM:
>> Does 
>> 
>> locator(type='l')
>> 
>> (or type  ='b')  
>> 
>> Work for you?
>> 
>> -----Original Message-----
>> From: "ryestone" <ryestone at uvic.ca>
>> To: "r-help at stat.math.ethz.ch" <r-help at stat.math.ethz.ch>
>> Sent: 6/8/07 10:19 AM
>> Subject: [R] ievent.wait
>> 
>> 
>> I am working on a plot and would be like to click on a few points and
>> then
>> have a line connect them. Could anyone help me with this or advise me in
>> a
>> direction that would suit this. I know I would be using ievent.wait in
>> iplot
>> but not sure about this.
>> 
>> thank you.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/ievent.wait-tf3891095.html#a11105384
Sent from the R help mailing list archive at Nabble.com.


From jrkrideau at yahoo.ca  Wed Jun 13 20:20:12 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Wed, 13 Jun 2007 14:20:12 -0400 (EDT)
Subject: [R] Subscription
In-Reply-To: <299429.54185.qm@web25007.mail.ukl.yahoo.com>
Message-ID: <581246.44745.qm@web32806.mail.mud.yahoo.com>


--- Lucy Namu <lnmn02 at yahoo.co.uk> wrote:

> I would like to subscribe and get free software for
> statistical analysis.
> Lucy

It looks like you are subscribed.  To download R
http://www.r-project.org/.

Some other sources of free software
http://www.epidata.dk/
http://gsociology.icaap.org/methods/soft.html
http://freestatistics.altervista.org/stat.php
http://www.psychnet-uk.com/experimental_design/software_packages.htm
http://data.fas.harvard.edu/micah_altman/socsci.shtml


From jrkrideau at yahoo.ca  Wed Jun 13 20:29:37 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Wed, 13 Jun 2007 14:29:37 -0400 (EDT)
Subject: [R] extractor rows from a matrix
In-Reply-To: <11094459.post@talk.nabble.com>
Message-ID: <695401.50548.qm@web32801.mail.mud.yahoo.com>

 ex1 <- ht[,1]    and so on?

Have a look at Chapter 5 in the Introduction to R 
--- billycorg <billycorg1 at virgilio.it> wrote:

> 
> hi!
> i have a little problem: my data's matrix has 1093
> rows and 3 columns.
> i'd like to extract each rows..
> 
> something like this:
> ht= my matrix
> Dt=(???)=a vector with t=1,2...1093
> 
> what can i do?
> thank you!
> 
> Vincenzo
> -- 
> View this message in context:
>
http://www.nabble.com/extractor-rows-from-a-matrix-tf3913088.html#a11094459
> Sent from the R help mailing list archive at
> Nabble.com.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From juryef at yahoo.com  Wed Jun 13 20:36:14 2007
From: juryef at yahoo.com (Judith Flores)
Date: Wed, 13 Jun 2007 11:36:14 -0700 (PDT)
Subject: [R] Removing Inf and Inf values from a fata frame
Message-ID: <537012.97409.qm@web34703.mail.mud.yahoo.com>

Hi,

    I have a csv file with empty values, when I apply
the different functions (mean, std, etc.) I create a
new data frame, the empty values generate Inf and -Inf
values. How can I remove those Inf and -Inf values
from the new data frame? I already specified na.rm in
the mean and std functions, but the values are still
there.

Thank you,

Judith


From wwwhsd at gmail.com  Wed Jun 13 20:50:57 2007
From: wwwhsd at gmail.com (Henrique Dallazuanna)
Date: Wed, 13 Jun 2007 15:50:57 -0300
Subject: [R] Removing Inf and Inf values from a fata frame
In-Reply-To: <537012.97409.qm@web34703.mail.mud.yahoo.com>
References: <537012.97409.qm@web34703.mail.mud.yahoo.com>
Message-ID: <da79af330706131150l5761636cn1b84cb8f367c0ae0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070613/cea87f30/attachment.pl 

From efg at stowers-institute.org  Wed Jun 13 20:57:28 2007
From: efg at stowers-institute.org (Earl F. Glynn)
Date: Wed, 13 Jun 2007 13:57:28 -0500
Subject: [R] Read Windows-like .INI files into R data structure?
References: <f4min7$hu5$1@sea.gmane.org><971536df0706121042r1aabcf03qf69ca6a117afab38@mail.gmail.com>
	<971536df0706121623p14725cbbp82610f2d3149a9e7@mail.gmail.com>
Message-ID: <f4pemr$jpq$1@sea.gmane.org>

<ngottlieb at marinercapital.com> wrote in message 
news:<0946E293C7C22A45A0E33BA14FAA8D88F38818 at 500MAIL.goldbox.com>...
> .Ini files are, for lack of a better description, ancient.

In this case a device is creating the INI files as part of an experiment, so 
the file format cannot be changed (at least easily).

I've looked at XML files from time to time and I'm amazed more don't 
complain how bloated, if not wasteful, they are.  I've seen XML files that 
were megabytes long when they held kilobytes worth of data.  INI files may 
be ancient, but they can be efficient and effective compared with XML.  In 
some cases, "newer" may not really be better (but "newer" may have the 
"momentum" behind it).


"Gabor Grothendieck" <ggrothendieck at gmail.com> wrote in message 
news:<971536df0706121623p14725cbbp82610f2d3149a9e7 at mail.gmail.com>...
> In thinking about this a bit more here is an even shorter solution where
> Lines.raw is as before:
>
> # Lines <- readLines("myfile.ini")
> Lines <- readLines(textConnection(Lines.raw))
> Lines2 <- chartr("[]", "==", Lines)
> DF <- read.table(textConnection(Lines2), as.is = TRUE, sep = "=", fill = 
> TRUE)
> L <- DF$V1 == ""
> subset(transform(DF, V3 = V2[which(L)[cumsum(L)]])[1:3], V1 != "")

Thanks for your helpful suggestions, Gabor.  Perhaps your "zoo" option is 
more elegant, but I try to use as few packages as possible, so this option 
seemed the best for me.

Since in my problem the structure of the INI sections is almost static and 
always present, I extended your example to create an in-memory list of 
everything in the INI file with this function:

# Prototype of how to read INI files to process olfactometer data
# efg, 13 June 2007
# Thanks to Gabor Grothendieck for helpful suggestions in the R-Help
# mailing list on how to parse the INI file.
Parse.INI <- function(INI.filename)
{
  connection <- file(INI.filename)
  Lines  <- readLines(connection)
  close(connection)

  Lines <- chartr("[]", "==", Lines)  # change section headers

  connection <- textConnection(Lines)
  d <- read.table(connection, as.is = TRUE, sep = "=", fill = TRUE)
  close(connection)

  L <- d$V1 == ""                    # location of section breaks
  d <- subset(transform(d, V3 = V2[which(L)[cumsum(L)]])[1:3],
                           V1 != "")

  ToParse  <- paste("INI.list$", d$V3, "$",  d$V1, " <- '",
                    d$V2, "'", sep="")

  INI.list <- list()
  eval(parse(text=ToParse))

  return(INI.list)
}


Here's an example of using the above function (I'll put the sample input 
file below):

INI1 <- Parse.INI("sample.ini")

# Explore INI contents
summary(INI1)

INI1$SystemSetup$OlfactometerCode
INI1$DefaultLevels
unlist(INI1$DefaultLevels)
INI1$Map

INI1$Map$port1
as.integer( unlist( strsplit(INI1$Map$port1, ",") ) )

= = = = =
Sample output:

> INI1 <- Parse.INI("sample.ini")
>
> # Explore INI contents
> summary(INI1)
              Length Class  Mode
SystemSetup   1      -none- list
Files         8      -none- list
DefaultLevels 4      -none- list
OdorNames     2      -none- list
Map           3      -none- list
>
> INI1$SystemSetup$OlfactometerCode
[1] "3"
> INI1$DefaultLevels
$FC00
[1] "50"

$FC01
[1] "100"

$FC02
[1] "50"

$FC10
[1] "50"

> unlist(INI1$DefaultLevels)
 FC00  FC01  FC02  FC10
 "50" "100"  "50"  "50"
> INI1$Map
$port0
[1] "0,0,0,0,0,0,0,0,0,0,0,0"

$port1
[1] "0,0,0,0,0,0,0,0,0,0,0,0"

$port2
[1] "0,0,0,0,0,0,0,0,0,0,0,0"

>
> INI1$Map$port1
[1] "0,0,0,0,0,0,0,0,0,0,0,0"
> as.integer( unlist( strsplit(INI1$Map$port1, ",") ) )
 [1] 0 0 0 0 0 0 0 0 0 0 0 0

= = = = =
Sample input file, sample.ini:

[SystemSetup]
OlfactometerCode=3
[Files]
prelog0=Part0.txt
date0=2:06:27.461 PM 6/9/2007
note0=group1-1
name0=group1
prelog1=Part1.txt
date1=2:09:16.809 PM 6/9/2007
note1=group1-1
name1=group1-1
[DefaultLevels]
FC00=50
FC01=100
FC02=50
FC10=50
[OdorNames]
port0=None
port1=None
[Map]
port0=0,0,0,0,0,0,0,0,0,0,0,0
port1=0,0,0,0,0,0,0,0,0,0,0,0
port2=0,0,0,0,0,0,0,0,0,0,0,0

= = = = =

Thanks again, Gabor!

efg

Earl F. Glynn
Scientific Programmer
Stowers Institute for Medical Research


From klaster at karlin.mff.cuni.cz  Wed Jun 13 21:07:16 2007
From: klaster at karlin.mff.cuni.cz (Petr Klasterecky)
Date: Wed, 13 Jun 2007 21:07:16 +0200
Subject: [R] Removing Inf and Inf values from a fata frame
In-Reply-To: <537012.97409.qm@web34703.mail.mud.yahoo.com>
References: <537012.97409.qm@web34703.mail.mud.yahoo.com>
Message-ID: <46704064.80407@karlin.mff.cuni.cz>

?is.finite

for removing the Infs *from the dataframe*, this does not aviod creating 
them by mean() or std().

Petr

Judith Flores napsal(a):
> Hi,
> 
>     I have a csv file with empty values, when I apply
> the different functions (mean, std, etc.) I create a
> new data frame, the empty values generate Inf and -Inf
> values. How can I remove those Inf and -Inf values
> from the new data frame? I already specified na.rm in
> the mean and std functions, but the values are still
> there.
> 
> Thank you,
> 
> Judith
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Petr Klasterecky
Dept. of Probability and Statistics
Charles University in Prague
Czech Republic


From ddaniel at nmsu.edu  Wed Jun 13 21:41:40 2007
From: ddaniel at nmsu.edu (David Daniel)
Date: Wed, 13 Jun 2007 13:41:40 -0600
Subject: [R] lme() doesn't converge on IGF example
Message-ID: <8FB7EA8D-6813-425F-9918-E2BC41CC950E@nmsu.edu>

Running the Chapter 4 examples in Pinheiro & Bates' "Mixed-Effects  
Models in S and S-PLUS" (2000), I get a message that the default  
optimizer doesn't converge, but using "optim" for the optimizer  
results in convergence:

> > library(nlme)
> > fm1IGF.lis <- lmList(IGF)
> > fm1IGF.lme <- lme(fm1IGF.lis)
> Error in lme.formula(fixed = conc ~ age, data = IGF, random = list 
> (Lot = c(-0.741604809797216,  :
> 	nlminb problem, convergence error code = 1; message = iteration  
> limit reached without convergence (9)
> >
> > fm1IGF.lme <- lme(fm1IGF.lis, control= list(opt="optim"))

I wouldn't have expected the default optimizer to not work with an  
example from this text.  Not knowing anything about the optimizers,  
I'm wondering if this is expected or known behavior, or if there are  
tips for getting it to converge other than changing optimizers?

nlme Version:       3.1-80

> > R.Version()
> $platform
> [1] "i386-apple-darwin8.9.1"
>
> $arch
> [1] "i386"
>
> $os
> [1] "darwin8.9.1"
>
> $system
> [1] "i386, darwin8.9.1"
>
> $status
> [1] ""
>
> $major
> [1] "2"
>
> $minor
> [1] "5.0"
>
> $year
> [1] "2007"
>
> $month
> [1] "04"
>
> $day
> [1] "23"
>
> $`svn rev`
> [1] "41293"
>
> $language
> [1] "R"
>
> $version.string
> [1] "R version 2.5.0 (2007-04-23)"

----------------------------------
David Daniel
Associate Professor
University Statistics Center
New Mexico State University

ddaniel at nmsu.edu


From kavindra_malik at yahoo.com  Wed Jun 13 22:04:36 2007
From: kavindra_malik at yahoo.com (kavindra malik)
Date: Wed, 13 Jun 2007 13:04:36 -0700 (PDT)
Subject: [R] Normal and Poisson tail area expectations in R
Message-ID: <469736.6868.qm@web62506.mail.re1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070613/6829c124/attachment.pl 

From bates at stat.wisc.edu  Wed Jun 13 22:10:56 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 13 Jun 2007 15:10:56 -0500
Subject: [R] lme() doesn't converge on IGF example
In-Reply-To: <8FB7EA8D-6813-425F-9918-E2BC41CC950E@nmsu.edu>
References: <8FB7EA8D-6813-425F-9918-E2BC41CC950E@nmsu.edu>
Message-ID: <40e66e0b0706131310m5efd99c5j32d6f489d1bdffe2@mail.gmail.com>

On 6/13/07, David Daniel <ddaniel at nmsu.edu> wrote:
> Running the Chapter 4 examples in Pinheiro & Bates' "Mixed-Effects
> Models in S and S-PLUS" (2000), I get a message that the default
> optimizer doesn't converge, but using "optim" for the optimizer
> results in convergence:
>
> > > library(nlme)
> > > fm1IGF.lis <- lmList(IGF)
> > > fm1IGF.lme <- lme(fm1IGF.lis)
> > Error in lme.formula(fixed = conc ~ age, data = IGF, random = list
> > (Lot = c(-0.741604809797216,  :
> >       nlminb problem, convergence error code = 1; message = iteration
> > limit reached without convergence (9)
> > >
> > > fm1IGF.lme <- lme(fm1IGF.lis, control= list(opt="optim"))
>
> I wouldn't have expected the default optimizer to not work with an
> example from this text.  Not knowing anything about the optimizers,
> I'm wondering if this is expected or known behavior, or if there are
> tips for getting it to converge other than changing optimizers?

That model fit corresponds to a singular variance-covariance matrix
for the random effects (notice that the correlation is -1).  The way
that the model was written in lme this corresponds to an infinite
value of one of the parameters so it is actually an advantage that the
nlminb optimizer doesn't declare convergence.

In the lmer2 function from the lme4 package the model is defined in
such a way that the singular variance-covariance matrix corresponds to
a value of zero for one of the parameters that is constrained to be
nonnegative.   Try

library(lme4)
data(IGF, package = "nlme")
fm1IGF.lmer <- lmer2(conc ~ age + (age|Lot), IGF, control =
list(msVerbose = TRUE))

and you will see that the second parameter is exactly zero at
convergence (or, at least it is on my amd_64 Linux system).

Currently I do not flag this for the user in the "show" method for the
fitted model.  I should.  Depending on your point of view such a
fitted model is either a boundary case or not a legitimate mixed
model.

The ability to converge to a singular model is actually the big
difference between the lmer and the lmer2 functions in the lme4
package.  For the lmer2 function the model is expressed in such a way
that the log-likelihood or the REML criterion can be evaluated for
singular variance-covariance matrices.  Furthermore such evaluations
approach the boundary evaluations smoothly.  The lmer function
evaluates the log-likelihood using the precision matrix (i.e. the
inverse of the variance-covariance) which, by definition, cannot be
evaluated when the variance-covariance matrix is singular.

>
> nlme Version:       3.1-80
>
> > > R.Version()
> > $platform
> > [1] "i386-apple-darwin8.9.1"
> >
> > $arch
> > [1] "i386"
> >
> > $os
> > [1] "darwin8.9.1"
> >
> > $system
> > [1] "i386, darwin8.9.1"
> >
> > $status
> > [1] ""
> >
> > $major
> > [1] "2"
> >
> > $minor
> > [1] "5.0"
> >
> > $year
> > [1] "2007"
> >
> > $month
> > [1] "04"
> >
> > $day
> > [1] "23"
> >
> > $`svn rev`
> > [1] "41293"
> >
> > $language
> > [1] "R"
> >
> > $version.string
> > [1] "R version 2.5.0 (2007-04-23)"
>
> ----------------------------------
> David Daniel
> Associate Professor
> University Statistics Center
> New Mexico State University
>
> ddaniel at nmsu.edu
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ngottlieb at marinercapital.com  Wed Jun 13 22:51:05 2007
From: ngottlieb at marinercapital.com (ngottlieb at marinercapital.com)
Date: Wed, 13 Jun 2007 16:51:05 -0400
Subject: [R] Read Windows-like .INI files into R data structure?
In-Reply-To: <f4pemr$jpq$1@sea.gmane.org>
References: <f4min7$hu5$1@sea.gmane.org><971536df0706121042r1aabcf03qf69ca6a117afab38@mail.gmail.com><971536df0706121623p14725cbbp82610f2d3149a9e7@mail.gmail.com>
	<f4pemr$jpq$1@sea.gmane.org>
Message-ID: <0946E293C7C22A45A0E33BA14FAA8D88F38837@500MAIL.goldbox.com>

Earl:

Really depends on the need. XML yes can get crazy (having had to deal
with some
ugly XML).

One can do a correctly formatted XML, that parses via the DOM which does
not mean well formatted XML. It's all 
a matter of design and data structures.

XML advantages: one can define own data types with attributes,
do data validation and nice searching with XPATH which
Is a whole subject in itself.

Sounds like XML is overkill for what you need.

Based on what you indicated, since not an R expert, writing a
Simple C function or Fortran routine would be best way to go,
Also gives you re-usable code if you are processing .ini
Files outside of the R environment.


If you program in Visual Basic or C you can develop a simple
DLL to call the old .ini functions which are document
On MSDN (Microsoft Developers Network). 

However, Looks like the R experts from threads gave a nice solution
using R.

Neil

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Earl F. Glynn
Sent: Wednesday, June 13, 2007 2:57 PM
To: r-help at stat.math.ethz.ch
Subject: Re: [R] Read Windows-like .INI files into R data structure?

<ngottlieb at marinercapital.com> wrote in message
news:<0946E293C7C22A45A0E33BA14FAA8D88F38818 at 500MAIL.goldbox.com>...
> .Ini files are, for lack of a better description, ancient.

In this case a device is creating the INI files as part of an
experiment, so 
the file format cannot be changed (at least easily).

I've looked at XML files from time to time and I'm amazed more don't 
complain how bloated, if not wasteful, they are.  I've seen XML files
that 
were megabytes long when they held kilobytes worth of data.  INI files
may 
be ancient, but they can be efficient and effective compared with XML.
In 
some cases, "newer" may not really be better (but "newer" may have the 
"momentum" behind it).


"Gabor Grothendieck" <ggrothendieck at gmail.com> wrote in message 
news:<971536df0706121623p14725cbbp82610f2d3149a9e7 at mail.gmail.com>...
> In thinking about this a bit more here is an even shorter solution
where
> Lines.raw is as before:
>
> # Lines <- readLines("myfile.ini")
> Lines <- readLines(textConnection(Lines.raw))
> Lines2 <- chartr("[]", "==", Lines)
> DF <- read.table(textConnection(Lines2), as.is = TRUE, sep = "=", fill
= 
> TRUE)
> L <- DF$V1 == ""
> subset(transform(DF, V3 = V2[which(L)[cumsum(L)]])[1:3], V1 != "")

Thanks for your helpful suggestions, Gabor.  Perhaps your "zoo" option
is 
more elegant, but I try to use as few packages as possible, so this
option 
seemed the best for me.

Since in my problem the structure of the INI sections is almost static
and 
always present, I extended your example to create an in-memory list of 
everything in the INI file with this function:

# Prototype of how to read INI files to process olfactometer data
# efg, 13 June 2007
# Thanks to Gabor Grothendieck for helpful suggestions in the R-Help
# mailing list on how to parse the INI file.
Parse.INI <- function(INI.filename)
{
  connection <- file(INI.filename)
  Lines  <- readLines(connection)
  close(connection)

  Lines <- chartr("[]", "==", Lines)  # change section headers

  connection <- textConnection(Lines)
  d <- read.table(connection, as.is = TRUE, sep = "=", fill = TRUE)
  close(connection)

  L <- d$V1 == ""                    # location of section breaks
  d <- subset(transform(d, V3 = V2[which(L)[cumsum(L)]])[1:3],
                           V1 != "")

  ToParse  <- paste("INI.list$", d$V3, "$",  d$V1, " <- '",
                    d$V2, "'", sep="")

  INI.list <- list()
  eval(parse(text=ToParse))

  return(INI.list)
}


Here's an example of using the above function (I'll put the sample input

file below):

INI1 <- Parse.INI("sample.ini")

# Explore INI contents
summary(INI1)

INI1$SystemSetup$OlfactometerCode
INI1$DefaultLevels
unlist(INI1$DefaultLevels)
INI1$Map

INI1$Map$port1
as.integer( unlist( strsplit(INI1$Map$port1, ",") ) )

= = = = =
Sample output:

> INI1 <- Parse.INI("sample.ini")
>
> # Explore INI contents
> summary(INI1)
              Length Class  Mode
SystemSetup   1      -none- list
Files         8      -none- list
DefaultLevels 4      -none- list
OdorNames     2      -none- list
Map           3      -none- list
>
> INI1$SystemSetup$OlfactometerCode
[1] "3"
> INI1$DefaultLevels
$FC00
[1] "50"

$FC01
[1] "100"

$FC02
[1] "50"

$FC10
[1] "50"

> unlist(INI1$DefaultLevels)
 FC00  FC01  FC02  FC10
 "50" "100"  "50"  "50"
> INI1$Map
$port0
[1] "0,0,0,0,0,0,0,0,0,0,0,0"

$port1
[1] "0,0,0,0,0,0,0,0,0,0,0,0"

$port2
[1] "0,0,0,0,0,0,0,0,0,0,0,0"

>
> INI1$Map$port1
[1] "0,0,0,0,0,0,0,0,0,0,0,0"
> as.integer( unlist( strsplit(INI1$Map$port1, ",") ) )
 [1] 0 0 0 0 0 0 0 0 0 0 0 0

= = = = =
Sample input file, sample.ini:

[SystemSetup]
OlfactometerCode=3
[Files]
prelog0=Part0.txt
date0=2:06:27.461 PM 6/9/2007
note0=group1-1
name0=group1
prelog1=Part1.txt
date1=2:09:16.809 PM 6/9/2007
note1=group1-1
name1=group1-1
[DefaultLevels]
FC00=50
FC01=100
FC02=50
FC10=50
[OdorNames]
port0=None
port1=None
[Map]
port0=0,0,0,0,0,0,0,0,0,0,0,0
port1=0,0,0,0,0,0,0,0,0,0,0,0
port2=0,0,0,0,0,0,0,0,0,0,0,0

= = = = =

Thanks again, Gabor!

efg

Earl F. Glynn
Scientific Programmer
Stowers Institute for Medical Research

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
--------------------------------------------------------

 
 
This information is being sent at the recipient's request or...{{dropped}}


From tchur at optushome.com.au  Wed Jun 13 23:12:22 2007
From: tchur at optushome.com.au (Tim Churches)
Date: Thu, 14 Jun 2007 07:12:22 +1000
Subject: [R] Awk and Vilno
In-Reply-To: <JJKX8V$81306E7F7E5D99DB33D8A0A3279E8BE9@multidominios>
References: <JJKX8V$81306E7F7E5D99DB33D8A0A3279E8BE9@multidominios>
Message-ID: <46705DB6.3010705@optushome.com.au>

Rogerio Porto wrote:
> Hey,
> 
>> What we should really compare is the four situations:
>> R alone
>> R + awk
>> R + vilno
>> R + awk + vilno
>> and maybe "R + SAS Data step"
>> and see what scripts are more  elegant (read 'short and understandable')

I don't think that short and understandable necessarily go hand-in-hand.
Sometimes longer scripts which are more explicit and use less tricky
syntax shortcuts are much easier to understand a year or two later. Ease
and speed of script writing (taking into account learning curve and time
taken to consult scripting language documentation) are important, as is
the ability to re-visit scripts or examine someone else's script and be
able to work out what it does and how it works is vital, and speed of
execution also counts with large datasets. Also ubiquity of the tool,
whether it is freely available on many platforms, either pre-installed
or in an easy-to-install form are also considerations.

> what do you guys think of creating a R-wiki page for syntax
> comparisons among the various options to enhance R use?
> 
> I already have two sugestions:
> 
> 1) syntax examples for using R and other tools to manipulate
> and analyze large datasets (with a concise description of the
> datasets);
> 
> 2) syntax examples for using R and other tools (or R alone) to clean
> and prepare datasets (simple and very small datasets, for didatic
> purposes).

The ability of the tools to scale to large or very large datasets is
also a consideration, as is their speed when dealing with such large data.

> I think this could be interesting for R users and to promote other
> software tools, since it seems there is a lot of R users that use
> other tools also.
> 
> Besides that, questions on those two above subjects are prevalent
> at this list. Thus a wiki page seems to be the right place to discuss
> and teach this to other users.
> 
> What do you think?

Yes, happy to contribute R + Python examples to such wiki pages. Please
post the URL.

Tim C


From cberry at tajo.ucsd.edu  Wed Jun 13 23:18:43 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Wed, 13 Jun 2007 14:18:43 -0700
Subject: [R] passing (or obtaining) index or element name of list to FUN
 in lapply()
In-Reply-To: <237294.66850.qm@web39711.mail.mud.yahoo.com>
References: <237294.66850.qm@web39711.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.64.0706131412300.24825@tajo.ucsd.edu>


This sounds like a job for mapply, viz:

> a.list <- list(a=cbind(1:4,rnorm(4)),b=cbind(4:1,rnorm(4)))
> 
> plot.x.main.y <- function(x,y,...) plot( x, main=y, ... )
> mapply( plot.x.main.y , a.list, names(a.list) )

Chuck

On Wed, 13 Jun 2007, Stephen Tucker wrote:

> Hi Professor Ripley,
>
> Thanks for the response. I apologize, my examples were not too real (though
> your solutions are indeed clever)... I was trying to ask more generally
> whether the element name or index of 'listObj' could be obtained by the
> user-function 'myfunction' when used in lapply(X=listObj,FUN=myfunction);
> below I illustrate two cases in which I have come across this desire:
> (1) In 'Example 1' I essentially take the list element and do some
> transformations (optionally some number-crunching), and then plot it with the
> element name of the list for the title.
> (2) In 'Example 2' I want to read in data from the list element and write the
> contents to a file; writing a header line only when operating on the first
> element of the list.
>
> ## data specification
> data1 <- "var1 var2
> -0.44 0.17
> 1.03 0.93
> 0.85 0.39"
> data2 <- "var1 var2
> -0.16 0.97
> 0.93 0.23
> 0.80 0.42"
> L <- list(data1=data1,data2=data2)
>
> ##=== Example 1 (want element name) ===
> ## function definition
> plottingfunc <- function(i,x) {
>  plot(read.table(textConnection(x[[i]]),header=TRUE),main=names(x)[i])
> }
> ## function application
> par(mfrow=c(2,1))
> lapply(seq(along=L),plottingfunc,x=L)
>
> ##=== Example 2 (want element index) ===
> ## function definition
> readwritefunc <- function(i,x,fout) {
>  data <- read.table(textConnection(x[[i]]),header=TRUE)
>  if(i==1) cat(paste(colnames(data),collapse=","),"\n",file=fout)
>  write.table(data,file=fout,sep=",",col=FALSE,
>              row=FALSE,quote=FALSE,append=TRUE)
> }
> ## function application
> fout <- file("out.dat",open="w")
> lapply(seq(along=L),readwritefunc,x=L,fout=fout)
> close(fout)
>
> Since the above code works, I suppose this is more of a question of
> aesthetics since I thought the spirit of lapply() was to operate on the
> elements of a list and not its indices - I thought perhaps there is a way to
> get the index number and element name from within the user-function.
>
> Also, I recall a lesson on 'loop avoidance' from an earlier version of MASS;
> this was in the days of S-PLUS dominance and perhaps less applicable now to R
> as you mentioned... But old habits die hard; my amygdala still invokes a fear
> response at the thought of a loop... (and as of recently, I have been
> infatuated with the notion of adhering, albeit loosely, to the 'functional
> programming' paradigm which makes me doubly fearful of loops)
>
> Thanks and best regards,
>
> Stephen
>
> --- Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>
>> On Tue, 12 Jun 2007, Stephen Tucker wrote:
>>
>>> Hello everyone,
>>>
>>> I wonder if there is a way to pass the index or name of a list to a
>>> user-specified function in lapply(). For instance, my desired effect is
>>> something like the output of
>>>
>>>> L <- list(jack=4098,sape=4139)
>>>> lapply(seq(along=L),function(i,x) if(i==1) "jack" else "sape",x=L)
>>> [[1]]
>>> [1] "jack"
>>>
>>> [[2]]
>>> [1] "sape"
>>
>> as.list(names(L))
>>
>>>> lapply(seq(along=L),function(i,x) if(names(x)[i]=="jack") 1 else 2,x=L)
>>> [[1]]
>>> [1] 1
>>>
>>> [[2]]
>>> [1] 2
>>
>> as.list(seq_along(L))
>>
>> lapply() can be faster than a for-loop, but usually not by much: its main
>> advantage is clarity of code.
>>
>> I think we need a real-life example to see what you are trying to do.
>>
>>> But by passing L as the first argument of lapply(). I thought there was a
>>> tangentially-related post on this mailing list in the past but I don't
>> recall
>>> that it was ever addressed directly (and I can't seem to find it now).
>> The
>>> examples above are perfectly good alternatives especially if I wrap each
>> of
>>> the lines in "names<-"() to return lists with appropriate names assigned,
>> but
>>
>> Try something like
>>
>> L[] <- lapply(seq_along(L),function(i,x) if(i==1) "jack" else "sape",x=L)
>>
>>> it feels like I am essentially writing a FOR-LOOP - though I was
>> surprised to
>>> find that speed-wise, it doesn't seem to make much of a difference
>> (unless I
>>> have not selected a rigorous test):
>>>
>>>> N <- 10000
>>>> y <- runif(N)
>>> ## looping through elements of y
>>>> system.time(lapply(y,
>>> +                    function(x) {
>>> +                      set.seed(222)
>>> +                      mean(rnorm(1e4,x,1))
>>> +                    }))
>>> [1] 21.00  0.17 21.29    NA    NA
>>> ## looping through indices
>>>> system.time(lapply(1:N,
>>> +                    function(x,y) {
>>> +                      set.seed(222)
>>> +                      mean(rnorm(1e4,y[x],1))
>>> +                      },y=y))
>>> [1] 21.09  0.14 21.26    NA    NA
>>>
>>> In Python, there are methods for Lists and Dictionaries called
>> enumerate(),
>>> and iteritems(), respectively. Example applications:
>>>
>>> ## a list
>>> L = ['a','b','c']
>>> [x for x in enumerate(L)]
>>> ## returns index of list along with the list element
>>> [(0, 'a'), (1, 'b'), (2, 'c')]
>>>
>>> ## a dictionary
>>> D = {'jack': 4098, 'sape': 4139}
>>> [x for x in D.iteritems()]
>>> ## returns element key (name) along with element contents
>>> [('sape', 4139), ('jack', 4098)]
>>>
>>> And this is something of the effect I was looking for...
>>>
>>> Thanks to all,
>>>
>>> Stephen
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	            UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901


From cberry at tajo.ucsd.edu  Wed Jun 13 23:29:21 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Wed, 13 Jun 2007 14:29:21 -0700
Subject: [R] Normal and Poisson tail area expectations in R
In-Reply-To: <469736.6868.qm@web62506.mail.re1.yahoo.com>
References: <469736.6868.qm@web62506.mail.re1.yahoo.com>
Message-ID: <Pine.LNX.4.64.0706131426060.24825@tajo.ucsd.edu>

On Wed, 13 Jun 2007, kavindra malik wrote:

> I am interested in R functions for the following integrals / sums (expressed best I can in text)  -
>
> Normal: G_u(k) =  Integration_{Lower limit=k}^{Upper limit=infinity} [(u -k) f(u) d(u)], where where u is N(0,1), and f(u) is the density function.
>
> Poisson: G(lambda,k) = Sum_{Lower limit=k}^{Upper limit=infinity} [(x-k) p(x, lambda)] where P(x,lambda) is the Poisson prob function with parameter lambda.
>
> The Normal expression is very commonly used in inventory management to 
> determine safety stocks (and its tabular values can be found in some 
> texts) - and I am also looking for Poisson and/or Gamma as that'd fit 
> the situation better.
>
> I am wondering if there are standard functions in R that might allow me to get these values, instead of needing to do the numerical integration, etc. myself.

Not that I know of, but it is not difficult to do the integration:

> k <- 1.1 # for example
> integrate(function(x) (x-k)*dnorm(x),lower=k,upper=Inf)
0.06861951 with absolute error < 5.5e-07
>

see

 	?integrate
 	?qnorm
 	?qpois
 	?qgamma

>                                                    Thank you very much.
>
>
>
> ---------------------------------
> Sucker-punch spam with award-winning protection.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	            UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901


From jenny at stat.ubc.ca  Wed Jun 13 23:44:36 2007
From: jenny at stat.ubc.ca (Jenny Bryan)
Date: Wed, 13 Jun 2007 14:44:36 -0700
Subject: [R] how to optionally include variables in a data.frame at
	assignment
Message-ID: <2228E1DA-3EDC-4500-81C4-AE4058A9B8A1@stat.ubc.ca>

I am creating a data.frame inside a function and the set of variables  
to include depends on the current value of other variables.  Is there  
a way to accomplish this in the original assignment?  Or must I first  
create the core data.frame with the variables I always want and then  
use if blocks to add other variables?

Basically, I'm hoping for something like this (which does not work):

newDat <- data.frame(x, y, if(zInclude) z else NULL)

Thanks, Jenny


From kavindra_malik at yahoo.com  Wed Jun 13 23:45:11 2007
From: kavindra_malik at yahoo.com (kavindra malik)
Date: Wed, 13 Jun 2007 14:45:11 -0700 (PDT)
Subject: [R] Normal and Poisson tail area expectations in R
In-Reply-To: <Pine.LNX.4.64.0706131426060.24825@tajo.ucsd.edu>
Message-ID: <219034.18761.qm@web62502.mail.re1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070613/97713258/attachment.pl 

From Cody_Hamilton at Edwards.com  Thu Jun 14 00:07:29 2007
From: Cody_Hamilton at Edwards.com (Cody_Hamilton at Edwards.com)
Date: Wed, 13 Jun 2007 15:07:29 -0700
Subject: [R] R vs. Splus in Pharma/Devices Industry
Message-ID: <OF5AF3574B.910347F3-ON882572F9.0079373A-882572F9.00795585@irvine.edwards.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070613/6b84f219/attachment.pl 

From aa2007r at gmail.com  Thu Jun 14 00:17:59 2007
From: aa2007r at gmail.com (AA)
Date: Wed, 13 Jun 2007 18:17:59 -0400
Subject: [R] Formatted Data File Question for Clustering -Quickie Project
References: <0946E293C7C22A45A0E33BA14FAA8D88F38822@500MAIL.goldbox.com>
Message-ID: <010f01c7ae08$b420fa60$3927a8c0@treesdalellc.net>

if you look at
the data USArrests by doing
> data(USArrets)
> USArrets
you will see that it is a data.frame.
so by analogy you could do the following:
Probably you have this data in Excel (I guess from the format in your mail).
Have the data in a sheet as:

            converts    shortBais ....
19940131  0.004       -0.0016
19940228  .......................

save this sheet as tab limited txt file.
then use
mydata <- read.table("yourdata.txt")
now you can use the data.frame mydata in the cluster analysis.
I would suggest you read the intro to R.
You can also use
read.csv see
?read.table
for more info, read R import/export on
http://finzi.psych.upenn.edu/R/doc/manual/R-data.html

good luck.
AA.
----- Original Message ----- 
From: <ngottlieb at marinercapital.com>
To: <R-help at stat.math.ethz.ch>
Sent: Wednesday, June 13, 2007 11:46 AM
Subject: [R] Formatted Data File Question for Clustering -Quickie Project


>I am trying to learn how to format Ascii data files for scan or read
> into R.
>
> Precisely for a quickie project, I found some code (at end of this
> email) to do exactly what I need:
> To cluster and graph a dendrogram from package (stats).
>
> I am stuck on how to format a text file to run the script.
> I looked at the dataset USArrests (which would be replaced by my data
> and labels) using UltraEdit. That data appears to be in binary format
> and I would simply like a readable ASCII text file.
>
> How can I:
> A) format this data to a file for the script below?
> B) I would like to use squared Euclidean distance, can hclust support
> this?
>
> Thanks,
> Neil Gottlieb
>
> Here is sub-set example of my data set, return series to cluster: 13
> cases by 36 observations):
> Month   Convertible Arbitrage   Dedicated Short Bias   Emerging
> Markets
> 1/31/1994 0.004 -0.016 0.105
> 2/28/1994 0.002 0.020 -0.011
> 3/31/1994 -0.010 0.072 -0.046
> 4/30/1994 -0.025 0.013 -0.084
> 5/31/1994 -0.010 0.023 -0.007
> 6/30/1994 0.002 0.064 0.005
> 7/31/1994 0.001 -0.012 0.058
> 8/31/1994 0.000 -0.057 0.164
> 9/30/1994 -0.012 0.016 0.052
> 10/31/1994 -0.014 -0.004 -0.035
> 11/30/1994 -0.002 0.030 -0.014
> 12/31/1994 -0.019 -0.002 -0.042
> 1/31/1995 -0.006 0.013 -0.100
> 2/28/1995 0.012 -0.022 -0.079
> 3/31/1995 0.013 0.004 -0.055
> 4/30/1995 0.023 -0.004 0.073
> 5/31/1995 0.017 -0.013 0.013
> 6/30/1995 0.019 -0.069 0.008
> 7/31/1995 0.009 -0.059 0.022
> 8/31/1995 0.008 0.008 0.010
> 9/30/1995 0.011 -0.029 0.019
> 10/31/1995 0.013 0.064 -0.057
> 11/30/1995 0.023 -0.010 -0.031
> 12/31/1995 0.014 0.049 0.007
> 1/31/1996 0.021 0.006 0.079
> 2/29/1996 0.012 -0.056 -0.006
> 3/31/1996 0.015 -0.009 -0.009
> 4/30/1996 0.013 -0.066 0.051
> 5/31/1996 0.016 0.000 0.045
> 6/30/1996 0.015 0.051 0.054
> 7/31/1996 0.014 0.098 -0.027
> 8/31/1996 0.013 -0.034 0.036
> 9/30/1996 0.011 -0.059 0.016
> 10/31/1996 0.014 0.043 0.017
> 11/30/1996 0.014 -0.029 0.026
>
> Code Example from Help files:
> hc <- hclust(dist(USArrests), "ave")
> (dend1 <- as.dendrogram(hc)) # "print()" method
> str(dend1)          # "str()" method
> str(dend1, max = 2) # only the first two sub-levels
>
> op <- par(mfrow= c(2,2), mar = c(5,2,1,4))
> plot(dend1)
> ## "triangle" type and show inner nodes:
> plot(dend1, nodePar=list(pch = c(1,NA), cex=0.8, lab.cex = 0.8),
>      type = "t", center=TRUE)
> plot(dend1, edgePar=list(col = 1:2, lty = 2:3), dLeaf=1, edge.root =
> TRUE)
> plot(dend1, nodePar=list(pch = 2:1,cex=.4*2:1, col = 2:3), horiz=TRUE)
>
> dend2 <- cut(dend1, h=70)
> plot(dend2$upper)
> ## leafs are wrong horizontally:
> plot(dend2$upper, nodePar=list(pch = c(1,7), col = 2:1))
> ##  dend2$lower is *NOT* a dendrogram, but a list of .. :
> plot(dend2$lower[[3]], nodePar=list(col=4), horiz = TRUE, type = "tr")
> ## "inner" and "leaf" edges in different type & color :
> plot(dend2$lower[[2]], nodePar=list(col=1),# non empty list
>     edgePar = list(lty=1:2, col=2:1), edge.root=TRUE)
> par(op)
> str(d3 <- dend2$lower[[2]][[2]][[1]])
>
> nP <- list(col=3:2, cex=c(2.0, 0.75), pch= 21:22, bg= c("light blue",
> "pink"),
>           lab.cex = 0.75, lab.col = "tomato")
> plot(d3, nodePar= nP, edgePar = list(col="gray", lwd=2), horiz = TRUE)
> addE <- function(n) {
>      if(!is.leaf(n)) {
>        attr(n, "edgePar") <- list(p.col="plum")
>        attr(n, "edgetext") <- paste(attr(n,"members"),"members")
>      }
>      n
> }
> d3e <- dendrapply(d3, addE)
> plot(d3e, nodePar= nP)
> plot(d3e, nodePar= nP, leaflab = "textlike")
> --------------------------------------------------------
>
>
>
> This information is being sent at the recipient's request or...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From irishhacker at gmail.com  Thu Jun 14 00:25:36 2007
From: irishhacker at gmail.com (Robert Wilkins)
Date: Wed, 13 Jun 2007 17:25:36 -0500
Subject: [R] Difficulties With Posting To Ongoing Threads on the R Mailing
	List
Message-ID: <874da0b40706131525h7ee6862eh492f4d816d550982@mail.gmail.com>

A number of people are having the same problem as me, when you post as
a response to an ongoing thread, in place of your message, the
following message appears:

An embedded & charset-unspecified text was scrubbed ...

and a link is given that leads to the desired message.

It's better than nothing , but it sure is annoying, and some readers
will skip it instead of doing the extra link. It's also annoying to
read a thread, when several posters , through no fault of their own,
get "scrubbed".

I always think of an e-mail as pure ASCII text, unless you add an attachment.
Is it possible that some e-mail hosts ( I use gmail ) embed binary
code into the e-mail?
Maybe the R mailing list software is reacting to that.

**************************

On another note, I tryed posting on gmane, to add to the thread from
last week. It just disappeared , or maybe not, I don't know. Maybe
it's related to the one-time registration requirement for gmane.

*************************

As far as I can tell, the above problem (scrubbing) does not occur
when you do a stand-alone post, not as a response to an ongoing
thread. Hope it stays that way!


**************************
Have a nice day.


From Peter.Ruckdeschel at uni-bayreuth.de  Thu Jun 14 00:30:03 2007
From: Peter.Ruckdeschel at uni-bayreuth.de (Peter Ruckdeschel)
Date: Thu, 14 Jun 2007 00:30:03 +0200
Subject: [R] Offline ? Searching for James Wettenhall's TclTk Examples
Message-ID: <46706FEB.7000306@uni-bayreuth.de>

Hi,

as a starting point for using Tcl/Tk in R, I used to refer
to James Wettenhall's nicely presented TclTk Examples
formerly hosted at

http://bioinf.wehi.edu.au/~wettenhall/RTclTkExamples/

These days I have been trying to reach these pages but without
success.

Does anyone know (James, himself, perhaps ;-) whether they
are / will be available at some other location --- it would
be a pity if not; I found them really useful.

Any advice/comment welcome
Peter


From irishhacker at gmail.com  Thu Jun 14 00:45:26 2007
From: irishhacker at gmail.com (Robert Wilkins)
Date: Wed, 13 Jun 2007 17:45:26 -0500
Subject: [R] Where to Find Data Transformation Software
Message-ID: <874da0b40706131545l2a150bbbrbd8a53b544d1b305@mail.gmail.com>

Hello All,

Here is the requested information. Most of it was on the original post for the
"Tools For Preparing Data For Analysis" thread from last week, but it
got overlooked.
They are all given under an open source license.
Check 'em out!

*******************************************************

Vilno: data transformation software, that reads in input datasets
(rows and columns), crunches through the data, and writes out output
datasets. It's an open source application that can replace the SAS
datastep ( and also replaces proc transpose and proc means ).

Find it at: http://code.google.com/p/vilno
( look in the download section for a tarball, it's a Linux
application, can be opened up (and maybe installed) on an Apple as
well ).

************************************************

DAP and PSPP: open source implementations for SAS and SPSS.

Find it at: http://directory.fsf.org/math/stats

*************************************************

Awk: data transformation/filtering software for semi-structured ASCII files.
A predecessor to Perl.

Find it at: a lot of places, but try:
http://www.gnu.org/software/gawk/gawk.html

*********************************************

Some, but not all , data crunching problems can be handled fairly well by an
all-purpose programming language, such as Perl or Python or Ruby.
Some, but not all, data crunching problems can be handled reasonably
well with the
S programming language ( i.e., R ).


From rvaradhan at jhmi.edu  Thu Jun 14 00:58:15 2007
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Wed, 13 Jun 2007 18:58:15 -0400
Subject: [R] Normal and Poisson tail area expectations in R
In-Reply-To: <219034.18761.qm@web62502.mail.re1.yahoo.com>
References: <Pine.LNX.4.64.0706131426060.24825@tajo.ucsd.edu>
	<219034.18761.qm@web62502.mail.re1.yahoo.com>
Message-ID: <000b01c7ae0e$53589d40$7c94100a@win.ad.jhu.edu>


More interesting is the Poisson convolution. I don't know if there is an
analytic solution to this.  I looked at Jolley's "Summation of Series" and
Abramowitz and Stegun, but no help there.  It seems that discrete FFT
technique should work. Does anyone know the answer?

Ravi.
----------------------------------------------------------------------------
-------

Ravi Varadhan, Ph.D.

Assistant Professor, The Center on Aging and Health

Division of Geriatric Medicine and Gerontology 

Johns Hopkins University

Ph: (410) 502-2619

Fax: (410) 614-9625

Email: rvaradhan at jhmi.edu

Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html

 

----------------------------------------------------------------------------
--------

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of kavindra malik
Sent: Wednesday, June 13, 2007 5:45 PM
To: Charles C. Berry
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Normal and Poisson tail area expectations in R

Thank you very much. This solves the problem I was trying to solve. I am new
to R and am learning. A great lesson in the power of R...

"Charles C. Berry" <cberry at tajo.ucsd.edu> wrote: On Wed, 13 Jun 2007,
kavindra malik wrote:

> I am interested in R functions for the following integrals / sums
(expressed best I can in text)  -
>
> Normal: G_u(k) =  Integration_{Lower limit=k}^{Upper limit=infinity} [(u
-k) f(u) d(u)], where where u is N(0,1), and f(u) is the density function.
>
> Poisson: G(lambda,k) = Sum_{Lower limit=k}^{Upper limit=infinity} [(x-k)
p(x, lambda)] where P(x,lambda) is the Poisson prob function with parameter
lambda.
>
> The Normal expression is very commonly used in inventory management to 
> determine safety stocks (and its tabular values can be found in some 
> texts) - and I am also looking for Poisson and/or Gamma as that'd fit 
> the situation better.
>
> I am wondering if there are standard functions in R that might allow me to
get these values, instead of needing to do the numerical integration, etc.
myself.

Not that I know of, but it is not difficult to do the integration:

> k <- 1.1 # for example
> integrate(function(x) (x-k)*dnorm(x),lower=k,upper=Inf)
0.06861951 with absolute error < 5.5e-07
>

see

  ?integrate
  ?qnorm
  ?qpois
  ?qgamma

>                                                    Thank you very much.
>
>
>
> ---------------------------------
> Sucker-punch spam with award-winning protection.
>
>  [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive
Medicine
E mailto:cberry at tajo.ucsd.edu             UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901




       
---------------------------------


	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ggrothendieck at gmail.com  Thu Jun 14 01:33:24 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 13 Jun 2007 19:33:24 -0400
Subject: [R] Difficulties With Posting To Ongoing Threads on the R
	Mailing List
In-Reply-To: <874da0b40706131525h7ee6862eh492f4d816d550982@mail.gmail.com>
References: <874da0b40706131525h7ee6862eh492f4d816d550982@mail.gmail.com>
Message-ID: <971536df0706131633t5bc4519fm4251f1a52df45a59@mail.gmail.com>

When you reply in gmail be sure you are using Plain Text
and not Rich Formatting.  If you press Reply or Reply All and
you see immediately above the text entry area
   B I U ... Plain Text
then you are in Rich Text mode.  Click on Plain Text at the right
of the line just above the text entry area to enter your text in
Plain Text mode.

On 6/13/07, Robert Wilkins <irishhacker at gmail.com> wrote:
> A number of people are having the same problem as me, when you post as
> a response to an ongoing thread, in place of your message, the
> following message appears:
>
> An embedded & charset-unspecified text was scrubbed ...
>
> and a link is given that leads to the desired message.
>
> It's better than nothing , but it sure is annoying, and some readers
> will skip it instead of doing the extra link. It's also annoying to
> read a thread, when several posters , through no fault of their own,
> get "scrubbed".
>
> I always think of an e-mail as pure ASCII text, unless you add an attachment.
> Is it possible that some e-mail hosts ( I use gmail ) embed binary
> code into the e-mail?
> Maybe the R mailing list software is reacting to that.
>
> **************************
>
> On another note, I tryed posting on gmane, to add to the thread from
> last week. It just disappeared , or maybe not, I don't know. Maybe
> it's related to the one-time registration requirement for gmane.
>
> *************************
>
> As far as I can tell, the above problem (scrubbing) does not occur
> when you do a stand-alone post, not as a response to an ongoing
> thread. Hope it stays that way!
>
>
> **************************
> Have a nice day.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ggrothendieck at gmail.com  Thu Jun 14 01:37:25 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 13 Jun 2007 19:37:25 -0400
Subject: [R] Offline ? Searching for James Wettenhall's TclTk Examples
In-Reply-To: <46706FEB.7000306@uni-bayreuth.de>
References: <46706FEB.7000306@uni-bayreuth.de>
Message-ID: <971536df0706131637x18b377e4y101f43e4cfb49be0@mail.gmail.com>

Its now at:

http://www.sciviews.org/_rgui/tcltk

On 6/13/07, Peter Ruckdeschel <Peter.Ruckdeschel at uni-bayreuth.de> wrote:
> Hi,
>
> as a starting point for using Tcl/Tk in R, I used to refer
> to James Wettenhall's nicely presented TclTk Examples
> formerly hosted at
>
> http://bioinf.wehi.edu.au/~wettenhall/RTclTkExamples/
>
> These days I have been trying to reach these pages but without
> success.
>
> Does anyone know (James, himself, perhaps ;-) whether they
> are / will be available at some other location --- it would
> be a pity if not; I found them really useful.
>
> Any advice/comment welcome
> Peter
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ggrothendieck at gmail.com  Thu Jun 14 01:49:00 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 13 Jun 2007 19:49:00 -0400
Subject: [R] how to optionally include variables in a data.frame at
	assignment
In-Reply-To: <2228E1DA-3EDC-4500-81C4-AE4058A9B8A1@stat.ubc.ca>
References: <2228E1DA-3EDC-4500-81C4-AE4058A9B8A1@stat.ubc.ca>
Message-ID: <971536df0706131649j458065f5rfd775dbe9acb564f@mail.gmail.com>

How about this:

data.frame2 <- function(...) {
	L <- list(...)
	as.data.frame(L[!sapply(L, is.null)])
}

# test 1
include <- FALSE
data.frame2(a = 1:3, junk = if (include) z, b = 3:1)

# test 2
z <- letters[1:3]
include <- TRUE
data.frame2(a = 1:3, junk = if (include) z, b = 3:1)


On 6/13/07, Jenny Bryan <jenny at stat.ubc.ca> wrote:
> I am creating a data.frame inside a function and the set of variables
> to include depends on the current value of other variables.  Is there
> a way to accomplish this in the original assignment?  Or must I first
> create the core data.frame with the variables I always want and then
> use if blocks to add other variables?
>
> Basically, I'm hoping for something like this (which does not work):
>
> newDat <- data.frame(x, y, if(zInclude) z else NULL)
>
> Thanks, Jenny
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mckellercran at gmail.com  Thu Jun 14 02:12:54 2007
From: mckellercran at gmail.com (Matthew Keller)
Date: Wed, 13 Jun 2007 20:12:54 -0400
Subject: [R] Cause of error message in cov function?
In-Reply-To: <466FA841.1050800@statistik.uni-dortmund.de>
References: <3f547caa0706121037i4e295920m75940b175e01a852@mail.gmail.com>
	<466FA841.1050800@statistik.uni-dortmund.de>
Message-ID: <3f547caa0706131712i7cf05880hf8c2864f77df27a3@mail.gmail.com>

Hi Uwe and other R-folks,

To answer your question, effects.cur is a matrix of real numbers.

It turns out that, on updating her version to the current one, the
error disappears. I'm posting this for posterity, just in case anyone
else has a similar problem with the function cov in earlier R
versions. I have no idea why the error was occurring, and can't track
it down because I don't have access to R 2.1...

Matt

On 6/13/07, Uwe Ligges <ligges at statistik.uni-dortmund.de> wrote:
>
>
> Matthew Keller wrote:
> > Hi all,
> >
> > I have written a script in R that simulates genetically informative
> > data - it is posted on my website and available to the public. This is
> > my first time to write a script for use by others and am learning that
> > it isn't as easy as it seems.
> >
> > To the issue. My script runs fine on my machine and on a server I have
> > access to, but a user has written me saying that it crashes the first
> > time the function "cov" is called up. Below is her error message
> > followed by the version of R she's using.
> >
> > Can anyone help me out here? I can't recreate her error message. Does
> > anyone know what this might have to do with? Is it a version issue
> > (she's using R 2.1)? I'd appreciate any help!!
>
> It may be a version issue, but hard to say since we do not know what
> effects.cur() is, not do we have any data to reproduce this.
>
> Uwe Ligges
>
>
> > Matt
> >
> >
> > ERROR MESSAGE:
> >
> > cov.varcomp <- cov(t(effects.cur[c("A","AA","D","F","S","E","AGE","AGE.by.A"),]*beta2))
> >
> > there is an argument mssing.
> > error message:
> >
> > Error in mean((a - mean(a)) * (b - mean(b))) :
> >        argument "b" is missing, with no default
> >
> >
> > SPECIFICS OF HER MACHINE:
> >
> >> memory.size()
> > [1] 10985480
> >> R.Version()
> > $platform
> > [1] "i386-pc-mingw32"
> > $arch
> > [1] "i386"
> > $os
> > [1] "mingw32"
> > $system
> > [1] "i386, mingw32"
> > $status
> > [1] ""
> > $major
> > [1] "2"
> > $minor
> > [1] "1.0"
> > $year
> > [1] "2005"
> > $month
> > [1] "04"
> > $day
> > [1] "18"
> > $language
> > [1] "R"
> >> .Platform
> > $OS.type
> > [1] "windows"
> > $file.sep
> > [1] "/"
> > $dynlib.ext
> > [1] ".dll"
> > $GUI
> > [1] "Rgui"
> > $endian
> > [1] "little"
> > $pkgType
> > [1] "win.binary"
> >
>


-- 
Matthew C Keller
Postdoctoral Fellow
Virginia Institute for Psychiatric and Behavioral Genetics


From A.Robinson at ms.unimelb.edu.au  Thu Jun 14 02:47:03 2007
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Thu, 14 Jun 2007 10:47:03 +1000
Subject: [R] How to get a point estimate from the studentized bootstrap?
Message-ID: <20070614004703.GC63160@ms.unimelb.edu.au>

Dear Friends and Colleagues,

I'm puzzling over how to interpret or use some bootstrap intervals.  I
think that I know what I should do, but I want to check with
knowledgeable people first!

I'm using a studentized non-parametric bootstrap to estimate 95%
confidence intervals for three parameters.  I estimate the variance of
the bootstrap replicates using another bootstrap.  The script takes
some hours to run, but I am happy to send it if it will help. Also I
am happy to send the boot object if that will help.

In the following object, I am interested in the values 1, 3, and 5.
The estimated variances are in 2, 4, and 6.

The boot object looks like:

> boot.outer

ORDINARY NONPARAMETRIC BOOTSTRAP

Call:
boot(data = err.outer, statistic = boot.fn.outer, R = R.outer, tis =
    tis, tfs = tfs, length.err = length.err, length.tis = length.tis,
    t0 = t0, tp = tp, start.outer = params, max.iter = max.iter,
    pc.ayl = pc.ayl, R.for.sd = R.for.sd)

Bootstrap Statistics :
      original        bias     std. error
t1* 0.62777511  1.898159e+00 8.003005e-01
t2* 0.04067475  1.854990e+00 2.916056e+01
t3* 1.97228885 -3.842986e+00 8.611901e+01
t4* 0.11418095  1.485597e+06 3.321892e+07
t5* 1.44261201  7.520929e-01 5.081878e-01
t6* 0.02751659  1.727005e-01 1.216163e-01



and the 95% CI is 

> boot.ci(boot.outer, type=c("stud", "norm", "basic"), index=1:2)
BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
Based on 500 bootstrap replicates

CALL : 
boot.ci(boot.out = boot.outer, type = c("stud", "norm", "basic"), 
    index = 1:2)

Intervals : 
Level      Normal              Basic             Studentized     
95%   (-2.8389,  0.2982 )   (-2.7692,  0.2462 )   (-1.4258,  0.5107 )  
Calculations and Intervals on Original Scale


Note that the original estimate is 0.628 and the bias-corrected
estimate is -1.27.  The diagnostic graphs show no evidence to suggest
any problems with the assumptions.

My question is: if I am willing to believe in the studentized
interval, but I want a point estimate as well, then what should I use
as the point estimate?  

Intuitively I think that I should just use the middle of the
studentized interval.  Is that correct, or at least defensible?

Best wishes to all,

Andrew

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/


From adschai at optonline.net  Thu Jun 14 02:47:34 2007
From: adschai at optonline.net (adschai at optonline.net)
Date: Thu, 14 Jun 2007 00:47:34 +0000 (GMT)
Subject: [R] polr:  attempt to find suitable starting values failed
Message-ID: <e3deac99dda9.46709026@optonline.net>

Hi,

I got a problem with polr function a bit. I have this error:

attempt to find suitable starting values failed

I wonder what would be an appropriate way to solve this problem? I can try to specify some random starting value but I am afraid that it will cause the MLE to stuck at some local maxima. Is there anyway to cope with this in a more elegant way? Any help would be really appreciated. Thank you.

- adschai


From m_olshansky at yahoo.com  Thu Jun 14 03:11:21 2007
From: m_olshansky at yahoo.com (Moshe Olshansky)
Date: Wed, 13 Jun 2007 18:11:21 -0700 (PDT)
Subject: [R] Stock Price Correlation to Index Price Levels
Message-ID: <481.94995.qm@web32201.mail.mud.yahoo.com>

Josh Kalish wrote:

>Thanks to all of the people who responded.  What I
>was trying to do is 
>to
>turn my matrix or frame containing index level
>returns and stock 
>returns
>into a matrix of "betas".  I don't really need to
>worry about risk-free
>interest rates.  I just need to be able to come up
>with a number that 
>shows
>the expected index correlation.  

 

>I was able finally to figure out how to use cor() to
>get what I think 
>is an
>R^2 value.  But, I'm trying to also figure out the
>ratio of 
>correlation.
>For example, some stocks correlate very well and
cor() returns a value 
>of
>.92.  But, how do you then figure out if the stock
>should have a 1.5:1
>correlation? 

 

>The way I would do it by hand is to turn the closes
>into daily returns 
>and
>then get the mean() return for each stock against the
>index by day.  I 
>can't
>find an example as hard as I look, but this must be
>very common.

 
If X is a vector of daily returns (today's close -
yesterday's close) for your index (in dollars) and Y
is the vector of daily returns for your stock (in
dollars), then to hedge 1 share of your stock you need
to hold u = -(1/r)*(Sy/Sx) units of the index, where r
is the correlation coefficient, Sx is the standard
deviation of daily returns of the index and Sy is the
standard deviation of daily returns of Y.
In R,
u <- -(1/cor(X,Y))*(sd(Y)/sd(X))
 
In this case your stock is "fully" hedged by the index
(but the index of course is not "fully" hedged by the
stock, unless the correlation coefficient is +/- 1).

Hope this helps,

Moshe Olshansky.


From m_olshansky at yahoo.com  Thu Jun 14 03:36:12 2007
From: m_olshansky at yahoo.com (Moshe Olshansky)
Date: Wed, 13 Jun 2007 18:36:12 -0700 (PDT)
Subject: [R] Appropriate regression model for categorical variables
Message-ID: <659320.89052.qm@web32214.mail.mud.yahoo.com>

Tirtha wrote:

>Dear users,
>In my psychometric test i have applied logistic
>regression on my data. 
>My
>data consists of 50 predictors (22 continuous and 28
>categorical) plus 
>a
>binary response. 
>
>Using glm(), stepAIC() i didn't get satisfactory
>result as 
>misclassification
>rate is too high. I think categorical variables are
>responsible for 
>this
>debacle. Some of them have more than 6 level (one has
>10 level).
>
>Please suggest some better regression model for this
>situation. If 
>possible
>you can suggest some article.
>
>thanking you.
>
>Tirtha


Hi Tirtha,

Are your categorical variables really categorical? 
What I mean is if you variable is user's satisfaction
level (0 for very unsatisfied, 1 for moderately
unsatisfied, 2 for slightly unsatisfied, 4 for
neutral, etc., finally 7 for very satisfied) then your
variable is not really categorical (since 1 is closer
to 3 than to 6) and then try what other people
suggest.  However, if your variable is, say, the 50-th
amino acid in a certain gene (with values of 1 for the
first amino acid, 2 for the second one,...,20 for the
20-th one) then your variable is really categorical
(you generally can not say that amino acid 2 is much
closer to amino acid 3 than to amino acid 17).  In
such a case I would have tried classification method
which can treat categorical variables or,
alternatively,  may be regression trees (i.e. split on
the values of categorical variables and at each "node"
find regression coefficients of the continuous
variables).

Regards,

Moshe Olshansky
m_olshansky at yahoo.com


From ecjbosu at aol.com  Thu Jun 14 04:53:44 2007
From: ecjbosu at aol.com (Joe W. Byers)
Date: Wed, 13 Jun 2007 21:53:44 -0500
Subject: [R] How to install RMySQL package in R 2.5 in Windows OS?
In-Reply-To: <Pine.LNX.4.64.0706131603430.14002@gannet.stats.ox.ac.uk>
References: <000001c7adb1$7f4bd000$7000a8c0@scbit94ec75129>
	<Pine.LNX.4.64.0706131603430.14002@gannet.stats.ox.ac.uk>
Message-ID: <4670ADB8.8010307@aol.com>

Prof Brian Ripley wrote:
> On Wed, 13 Jun 2007, Ruixin ZHU wrote:
> 
>> Dear R-users,
>>
>> It seems that install.packages( ) doesn't work to RMySQL package.
> 
> Under Windows, yes.  You need the MySQL client libraries for your version 
> of MySQL (or something very close to the same version), so the only safe 
> way is to install from the sources.  The latter is not hard and there are 
> instructions in the package.
There are several of us working on updating the RMySQL binary for 
windows.  Currently one has it compiled with mysql 5.0.18, but can't get 
it to compile with 5.0.41.  I am having trouble with 5.0.22,  5.0.24, 
and 5.0.37 mysql binaries.  There seems to be some problems with 
different versions of mysql.  As soon as we have a tested version of the 
windows binary for RMySQL, information for obtaining it will be posted.

We all appreciate you patiences.

Thank you
Joe


> 
> 
>> Would anybody have the experience of that?
>>
>> Thanks
>> _____________________________________________
>> Dr.Ruixin ZHU
>> Shanghai Center for Bioinformation Technology
>> rxzhu at scbit.org
>> zhurx at mail.sioc.ac.cn
>> 86-21-13040647832
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From ecjbosu at aol.com  Thu Jun 14 04:53:44 2007
From: ecjbosu at aol.com (Joe W. Byers)
Date: Wed, 13 Jun 2007 21:53:44 -0500
Subject: [R] How to install RMySQL package in R 2.5 in Windows OS?
In-Reply-To: <Pine.LNX.4.64.0706131603430.14002@gannet.stats.ox.ac.uk>
References: <000001c7adb1$7f4bd000$7000a8c0@scbit94ec75129>
	<Pine.LNX.4.64.0706131603430.14002@gannet.stats.ox.ac.uk>
Message-ID: <4670ADB8.8010307@aol.com>

Prof Brian Ripley wrote:
> On Wed, 13 Jun 2007, Ruixin ZHU wrote:
> 
>> Dear R-users,
>>
>> It seems that install.packages( ) doesn't work to RMySQL package.
> 
> Under Windows, yes.  You need the MySQL client libraries for your version 
> of MySQL (or something very close to the same version), so the only safe 
> way is to install from the sources.  The latter is not hard and there are 
> instructions in the package.
There are several of us working on updating the RMySQL binary for 
windows.  Currently one has it compiled with mysql 5.0.18, but can't get 
it to compile with 5.0.41.  I am having trouble with 5.0.22,  5.0.24, 
and 5.0.37 mysql binaries.  There seems to be some problems with 
different versions of mysql.  As soon as we have a tested version of the 
windows binary for RMySQL, information for obtaining it will be posted.

We all appreciate you patiences.

Thank you
Joe


> 
> 
>> Would anybody have the experience of that?
>>
>> Thanks
>> _____________________________________________
>> Dr.Ruixin ZHU
>> Shanghai Center for Bioinformation Technology
>> rxzhu at scbit.org
>> zhurx at mail.sioc.ac.cn
>> 86-21-13040647832
>>
>>
>>  [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From vokey at uleth.ca  Thu Jun 14 05:14:42 2007
From: vokey at uleth.ca (John Vokey)
Date: Wed, 13 Jun 2007 21:14:42 -0600
Subject: [R] Generating artificial datasets with a specific correlation
	coefficient.
In-Reply-To: <mailman.11.1181728804.6777.r-help@stat.math.ethz.ch>
References: <mailman.11.1181728804.6777.r-help@stat.math.ethz.ch>
Message-ID: <43092302-C115-4DD1-B655-BC156860CA67@uleth.ca>

Jim,
   Try here: <http://www.sitmo.com/doc/ 
Generating_Correlated_Random_Numbers>; the example code is in matlab,  
but it is trivial to translate to R.  Note, if you use principal  
components as the source vectors (thanks to Jason Tangen for the  
suggestion), the correlations between the resulting vectors will be  
exactly the specified r-values.

On 13-Jun-07, at 4:00 AM, r-help-request at stat.math.ethz.ch wrote:
> I need to create artificial datasets with specific correlation
> coefficients (i.e. a dataset that returns r = 0.30, etc.) as examples
> for a lab I am teaching this summer.  Is there a way to do that in R?

--
Please avoid sending me Word or PowerPoint attachments.
See <http://www.gnu.org/philosophy/no-word-attachments.html>

-Dr. John R. Vokey


From ggrothendieck at gmail.com  Thu Jun 14 06:04:56 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 14 Jun 2007 00:04:56 -0400
Subject: [R] Read Windows-like .INI files into R data structure?
In-Reply-To: <971536df0706121906n12bcfd96pb2c45f7e137ab74d@mail.gmail.com>
References: <f4min7$hu5$1@sea.gmane.org>
	<971536df0706121042r1aabcf03qf69ca6a117afab38@mail.gmail.com>
	<971536df0706121623p14725cbbp82610f2d3149a9e7@mail.gmail.com>
	<971536df0706121906n12bcfd96pb2c45f7e137ab74d@mail.gmail.com>
Message-ID: <971536df0706132104u3601bd8fuce4319ecf981d342@mail.gmail.com>

Here is yet another solution.  This is the simplest so far.
Lines.raw is as before and the output is a 3 column character
matrix.

section <- ""
f <- function(x) {
	if (length(x) == 1) section <<- gsub("[\\[\\]]", "", x)
	if (length(x) <= 1) return()
	return(c(x, section))
}
# Lines <- readLines("myfile.ini")
Lines <- readLines(textConnection(Lines.raw))
do.call("rbind", lapply(strsplit(Lines, "="), f))


On 6/12/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> Here is yet another simplification.  This one uses na.locf from the zoo
> package to shorten it further and also make it easier to understand.
>
> Below we have one line to read in the .ini file, one line to transform the
> characters [ and ] to = and =, the read.table line parses the result and
> the next line carries forward the section names and removes the section
> lines. Lines.raw is as before:
>
> library(zoo)
>
> # Lines <- readLines("myfile.ini")
> Lines <- readLines(textConnection(Lines.raw))
> Lines2 <- chartr("[]", "==", Lines)
> DF <- read.table(textConnection(Lines2), as.is = TRUE, sep = "=", fill = TRUE)
> subset(transform(DF, V3 = na.locf(ifelse(V1 == "", V2, NA))), V1 != "")
>
>
> On 6/12/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> > In thinking about this a bit more here is an even shorter solution where
> > Lines.raw is as before:
> >
> > # Lines <- readLines("myfile.ini")
> > Lines <- readLines(textConnection(Lines.raw))
> > Lines2 <- chartr("[]", "==", Lines)
> > DF <- read.table(textConnection(Lines2), as.is = TRUE, sep = "=", fill = TRUE)
> > L <- DF$V1 == ""
> > subset(transform(DF, V3 = V2[which(L)[cumsum(L)]])[1:3], V1 != "")
> >
> >
> > On 6/12/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> > > Here is some code. It replaces [ and ] with = sign and reads the result
> > > into a data frame, DF.  DF2 is similar except the section is now in V3.
> > > DF3 is like like DF2 except sections are carried forward and finally
> > > we remove the rows which only had sections.
> > >
> > > Lines.raw <- "[Section1]
> > > var1=value1
> > > var2=value2
> > > [Section2]
> > > A=value3
> > > B=value4
> > > "
> > >
> > > Lines <- readLines(textConnection(Lines.raw))
> > > Lines2 <- chartr("[]", "==", Lines)
> > > DF <- read.table(textConnection(Lines2), as.is = TRUE, sep = "=", fill = TRUE)
> > > DF2 <- transform(DF, V3 = ifelse(V1 == "", V2, NA))
> > > L <- !is.na(DF2$V3)
> > > DF3 <- transform(DF2, V3 = V3[c(NA, which(L))[cumsum(L)+1]])
> > > subset(DF3, V1 != "")
> > >
> > > The result is:
> > >
> > >    V1     V2       V3
> > > 2 var1 value1 Section1
> > > 3 var2 value2 Section1
> > > 5    A value3 Section2
> > > 6    B value4 Section2
> > >
> > >
> > > On 6/12/07, Earl F. Glynn <efg at stowers-institute.org> wrote:
> > > > I need to process some datasets where the configuration information was
> > > > stored in .INI-like files, i.e., text files with sections like this:
> > > >
> > > > [Section1]
> > > > var1=value1
> > > > var2=value2
> > > > [Section2]
> > > > A=value3
> > > > B=value4
> > > >
> > > > ...
> > > >
> > > > >From Google and other searches I haven't found any package, or function
> > > > within a package, that reads .INI files into an R list, or other data
> > > > structure.
> > > >
> > > >
> > > >
> > > > Any suggestions, or do I need to write my own?
> > > >
> > > > efg
> > > >
> > > > Earl F. Glynn
> > > > Stowers Institute for Medical Research
> > > >
> > > > ______________________________________________
> > > > R-help at stat.math.ethz.ch mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > > >
> > >
> >
>


From Alexander.Herr at csiro.au  Thu Jun 14 06:39:35 2007
From: Alexander.Herr at csiro.au (Alexander.Herr at csiro.au)
Date: Thu, 14 Jun 2007 14:39:35 +1000
Subject: [R] blotched y-axis text in plot function
Message-ID: <80C7911E901E7E4797B3F88D106CB25D0E81CF@exqld2-bne.nexus.csiro.au>

Hi List,

I have recently upgraded to opensuse10.2 and R 2.5 (compiled from
source). Now, whenever I use plot the y-axis and labels are black
blotches while x-axis and labels are fine. 

Using demo(graphics) this occurs with plot/boxplot/hist/pairs/coplot but
not in the pie graphs and in the "The level of Interest in R" plot,
which uses axis to define the y-axis.

I presume this has to do with the font handling of linux/R. But, being
not a linux guru I am at your mercy to help me trace and fix this
problem.

Any help appreciated
Cheers Herry


Dr Alexander Herr - Herry
Spatial and statistical analyst
CSIRO, Sustainable Ecosystems
Davies Laboratory,
University Drive, Douglas, QLD 4814 
Private Mail Bag, Aitkenvale, QLD 4814
 
Phone/www 
(07) 4753 8510; 4753 8650(fax)
Home: http://herry.ausbats.org.au
Webadmin ABS: http://ausbats.org.au
Sustainable Ecosystems: http://www.cse.csiro.au/


From Alexander.Herr at csiro.au  Thu Jun 14 06:45:18 2007
From: Alexander.Herr at csiro.au (Alexander.Herr at csiro.au)
Date: Thu, 14 Jun 2007 14:45:18 +1000
Subject: [R] blotched y-axis text in plot function
Message-ID: <80C7911E901E7E4797B3F88D106CB25D0E81D1@exqld2-bne.nexus.csiro.au>

Hi List,

can I retract the query below? It turns out that it has to do with the
NX viewer/server. It works fine with the vncviewer/server, so please
ignore...

Thanks
Herry



Dr Alexander Herr - Herry
Spatial and statistical analyst
CSIRO, Sustainable Ecosystems
Davies Laboratory,
University Drive, Douglas, QLD 4814 
Private Mail Bag, Aitkenvale, QLD 4814
 
Phone/www 
(07) 4753 8510; 4753 8650(fax)
Home: http://herry.ausbats.org.au
Webadmin ABS: http://ausbats.org.au
Sustainable Ecosystems: http://www.cse.csiro.au/
--------------------------------------------


-----Original Message-----
From: Herr, Alexander Herr - Herry (CSE, Townsville) 
Sent: Thursday, June 14, 2007 2:40 PM
To: 'r-help at stat.math.ethz.ch'
Subject: blotched y-axis text in plot function

Hi List,

I have recently upgraded to opensuse10.2 and R 2.5 (compiled from
source). Now, whenever I use plot the y-axis and labels are black
blotches while x-axis and labels are fine. 

Using demo(graphics) this occurs with plot/boxplot/hist/pairs/coplot but
not in the pie graphs and in the "The level of Interest in R" plot,
which uses axis to define the y-axis.

I presume this has to do with the font handling of linux/R. But, being
not a linux guru I am at your mercy to help me trace and fix this
problem.

Any help appreciated
Cheers Herry


Dr Alexander Herr - Herry
Spatial and statistical analyst
CSIRO, Sustainable Ecosystems
Davies Laboratory,
University Drive, Douglas, QLD 4814
Private Mail Bag, Aitkenvale, QLD 4814
 
Phone/www
(07) 4753 8510; 4753 8650(fax)
Home: http://herry.ausbats.org.au
Webadmin ABS: http://ausbats.org.au
Sustainable Ecosystems: http://www.cse.csiro.au/


From megh700004 at yahoo.com  Thu Jun 14 07:33:05 2007
From: megh700004 at yahoo.com (Megh Dal)
Date: Wed, 13 Jun 2007 22:33:05 -0700 (PDT)
Subject: [R] Panel data
Message-ID: <655807.93688.qm@web58115.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070613/23b87436/attachment.pl 

From alain.reymond at skynet.be  Wed Jun 13 19:20:04 2007
From: alain.reymond at skynet.be (Alain Reymond)
Date: Wed, 13 Jun 2007 19:20:04 +0200
Subject: [R] R Book Advice Needed
In-Reply-To: <OF88CDFD73.E09BD8D4-ON882572F8.007C06BE-882572F8.007BEB02@irvine.edwards.com>
References: <OF88CDFD73.E09BD8D4-ON882572F8.007C06BE-882572F8.007BEB02@irvine.edwards.com>
Message-ID: <46702744.50401@skynet.be>

Cody,

I plan to use it in life sciences. We use of course basic descriptive
statistics but also classification using ACP and CAH (French
abbreviation for Principal Component Analysis and Hierarchical Cluster
Analysis). We also use logistic regression for classifying some results
of clinical laboratory analyses.

In fact, I have been a user of SPSS for - quite - a long time. The price
of the licences are increasing and it becomes a problem for us (many
thousand of euros). I am the only user and don't work with the programs
on a daily basis. So - I confess - I am investigating R. And I am more
and more convinced by the possibilities it offers.

Regards.

Alain

Cody_Hamilton at edwards.com a ?crit :
> Alain,
>
> Can you tell us what you plan to use R for?
>
> Regards,
> -Cody
>
> ngottlieb at marinercapital.com a ?crit :
>   
>> I am new to using R and would appreciate some advice on
>> which books to start with to get up to speed on using R.
>> ...cut...
>>     
-- 
Alain Reymond
CEIA
Bruxelles


From asb at mail.nih.gov  Wed Jun 13 23:21:01 2007
From: asb at mail.nih.gov (Alan S Barnett)
Date: Wed, 13 Jun 2007 17:21:01 -0400
Subject: [R] Annotating trellis graphics
Message-ID: <1181769661.17656.44.camel@gestalt.nimh.nih.gov>

I'm using xyplot to generate a trellis plot with each panel containing a
scatterplot and a best fit line.  Is it possible to write the slope of
the best fit line in each panel?
-- 
Alan S Barnett <asb at mail.nih.gov>
NIMH/CBDB


From stefan.grosse at uni-erfurt.de  Thu Jun 14 08:27:46 2007
From: stefan.grosse at uni-erfurt.de (Stefan Grosse)
Date: Thu, 14 Jun 2007 08:27:46 +0200
Subject: [R] Panel data
In-Reply-To: <655807.93688.qm@web58115.mail.re3.yahoo.com>
References: <655807.93688.qm@web58115.mail.re3.yahoo.com>
Message-ID: <200706140827.46458.stefan.grosse@uni-erfurt.de>

Panel data is that you have e.g. several subjects 
(=individuals,firms,households) being tracked over a certain time (meaning 
there are repeated observations). One could roughly say that it is a 
collection of (quite similiar) time series. This makes the analysis better 
than pooling the whole set but it needs certain econometric tools. 

An example would be estimating wage elasticities.

Time series analysis usually just involves one subject (interest rates, share 
prices etc.) over some time.

Standard books on panel data analysis are also Baltagi: econometric analysis 
of panel data and Wooldridge: econometric analysis of cross sectional and 
panel data. Both are not introductionary texts since you do not know the 
difference between time series and panel data maybe you should start with an 
introductionary econometrics book like Wooldridge introductory econometrics 
or Verbeek: modern econometrics.

Stefan

on Thursday 14 June 2007 07:33:05 Megh Dal wrote:
MD > Then what is the difference between panel data and time series data? You
 said panel data is data on "same subject being tracked over time". But time
 series data also do the same. Please correct me if I am wrong. MD >


From ripley at stats.ox.ac.uk  Thu Jun 14 08:42:48 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 14 Jun 2007 07:42:48 +0100 (BST)
Subject: [R] Panel data
In-Reply-To: <655807.93688.qm@web58115.mail.re3.yahoo.com>
References: <655807.93688.qm@web58115.mail.re3.yahoo.com>
Message-ID: <Pine.LNX.4.64.0706140736370.30331@gannet.stats.ox.ac.uk>

On Wed, 13 Jun 2007, Megh Dal wrote:

> Then what is the difference between panel data and time series data? You 
> said panel data is data on "same subject being tracked over time". But 
> time series data also do the same. Please correct me if I am wrong.

Panel data is about several subjects being tracked over time, so gives a 
series of related time series.  It also known as 'longitudinal data' or 
'repeated measures' (perhaps with slightly different emphases).

If the observation times were the same for all subjects a vector AR 
(presumably the one of several senses of 'VAR' being used) could be used, 
but conventional analyses are via mixed/GEE models (and in simple cases 
these reduce to a nested anova).

There are examples in MASS and in Diggle, Hegarty, Liang and Zeger (cited 
there).


> ----- Original Message ----
> From: "Leeds, Mark (IED)" <Mark.Leeds at morganstanley.com>
> To: Megh Dal <megh700004 at yahoo.com>
> Sent: Wednesday, June 13, 2007 8:30:18 PM
> Subject: RE: [R] Panel data
>
>
> not as far as I know. Panel data is quite specific in that it's the
> same subject being tracked over time.
> A VAR doesn't take advantage of this and doesn't make that assumption
> and I don't think it's applicable to
> Your problem. I think there is a book by
> Hsaio on panel data and possibly another one by Arellano ( spelling )
> but I'm not sure what's available in R for doing panel
> data estimation. I've never done it. Maybe do a search for "panel data"
> on the search engine and something may come up ?
>
>
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Megh Dal
> Sent: Tuesday, June 12, 2007 12:12 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Panel data
>
> Dear all R users,
>
> I have a small doubt about panel data analysis. My basic understanding
> on Panel data is a type of data that is collected over time and
> subjects. Vector Autoregressive Model (VAR) model used on this type of
> data. Therefore can I say that, one of statistical tools used for
> analysis of panel data is VAR model? If you clarify my doubt I will be
> very grateful.
>
> Thanks and regards,
> Megh
>
>
>
>
>
> ________________________________________________________________________
> ____________
> Looking for earth-friendly autos?
> Browse Top Cars by "Green Rating" at Yahoo! Autos' Green Center.
>
>    [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> --------------------------------------------------------
>
> This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From billycorg1 at virgilio.it  Thu Jun 14 08:55:39 2007
From: billycorg1 at virgilio.it (billycorg)
Date: Wed, 13 Jun 2007 23:55:39 -0700 (PDT)
Subject: [R] extractor rows from a matrix
In-Reply-To: <466FA7C3.7020703@statistik.uni-dortmund.de>
References: <11094459.post@talk.nabble.com>
	<466FA7C3.7020703@statistik.uni-dortmund.de>
Message-ID: <11114923.post@talk.nabble.com>


thanks for the answer..but i don't find what i'm looking for!

now i'm trying to expose better my problem:
i have:

ht= a 1096rows x 3 columns matrix 
 
i'd like a function like this:
 
d[i]=rbind(ht[i,]) for (i in 1:length(ht))

but this don't work :(
can anyone seriously help  me?
-- 
View this message in context: http://www.nabble.com/extractor-rows-from-a-matrix-tf3913088.html#a11114923
Sent from the R help mailing list archive at Nabble.com.


From m_olshansky at yahoo.com  Thu Jun 14 09:26:26 2007
From: m_olshansky at yahoo.com (Moshe Olshansky)
Date: Thu, 14 Jun 2007 00:26:26 -0700 (PDT)
Subject: [R] Responding to a posting in the digest
Message-ID: <65657.87483.qm@web32215.mail.mud.yahoo.com>

Is there a convenient way to respond to a particular
posting which is a part of the digest?  
I mean something that will automatically quote the
original message, subject, etc.

Thank you!

Moshe Olshansky
m_olshansky at yahoo.com


From wl2776 at gmail.com  Thu Jun 14 09:41:41 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Thu, 14 Jun 2007 00:41:41 -0700 (PDT)
Subject: [R] Formatted Data File Question for Clustering -Quickie Project
In-Reply-To: <0946E293C7C22A45A0E33BA14FAA8D88F38822@500MAIL.goldbox.com>
References: <0946E293C7C22A45A0E33BA14FAA8D88F38822@500MAIL.goldbox.com>
Message-ID: <11115436.post@talk.nabble.com>


The "R Data Import/Export" guide was mentioned already, it contains
everything you should know about data exchange between R and other software.

In case it says nothing about dates, try as.Date() and strftime().
For your example below,
  as.Date("1/31/1994",format="%m/%d/%Y")
works.


ngottlieb wrote:
> 
> I am trying to learn how to format Ascii data files for scan or read
> into R.
> 
> Precisely for a quickie project, I found some code (at end of this
> email) to do exactly what I need:
> To cluster and graph a dendrogram from package (stats).
> 
> I am stuck on how to format a text file to run the script.
> I looked at the dataset USArrests (which would be replaced by my data
> and labels) using UltraEdit. That data appears to be in binary format
> and I would simply like a readable ASCII text file.
> 
> How can I:
> A) format this data to a file for the script below? 
> B) I would like to use squared Euclidean distance, can hclust support
> this?
> 
> Thanks,
> Neil Gottlieb
> 
> Here is sub-set example of my data set, return series to cluster: 13
> cases by 36 observations):
> Month	  Convertible Arbitrage	  Dedicated Short Bias	  Emerging
> Markets	
> 1/31/1994	0.004	-0.016	0.105	
> 2/28/1994	0.002	0.020	-0.011	
> 3/31/1994	-0.010	0.072	-0.046	
> 
> [skip]
> 

-- 
View this message in context: http://www.nabble.com/Formatted-Data-File-Question-for-Clustering--Quickie-Project-tf3915926.html#a11115436
Sent from the R help mailing list archive at Nabble.com.


From christophe at pallier.org  Thu Jun 14 09:46:03 2007
From: christophe at pallier.org (Christophe Pallier)
Date: Thu, 14 Jun 2007 09:46:03 +0200
Subject: [R] Read Windows-like .INI files into R data structure?
In-Reply-To: <971536df0706132104u3601bd8fuce4319ecf981d342@mail.gmail.com>
References: <f4min7$hu5$1@sea.gmane.org>
	<971536df0706121042r1aabcf03qf69ca6a117afab38@mail.gmail.com>
	<971536df0706121623p14725cbbp82610f2d3149a9e7@mail.gmail.com>
	<971536df0706121906n12bcfd96pb2c45f7e137ab74d@mail.gmail.com>
	<971536df0706132104u3601bd8fuce4319ecf981d342@mail.gmail.com>
Message-ID: <dea6cb960706140046l70b83a42rb709f7a8a3c24f8e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070614/238f0ff8/attachment.pl 

From christophe at pallier.org  Thu Jun 14 09:57:57 2007
From: christophe at pallier.org (Christophe Pallier)
Date: Thu, 14 Jun 2007 09:57:57 +0200
Subject: [R] Read Windows-like .INI files into R data structure?
In-Reply-To: <dea6cb960706140046l70b83a42rb709f7a8a3c24f8e@mail.gmail.com>
References: <f4min7$hu5$1@sea.gmane.org>
	<971536df0706121042r1aabcf03qf69ca6a117afab38@mail.gmail.com>
	<971536df0706121623p14725cbbp82610f2d3149a9e7@mail.gmail.com>
	<971536df0706121906n12bcfd96pb2c45f7e137ab74d@mail.gmail.com>
	<971536df0706132104u3601bd8fuce4319ecf981d342@mail.gmail.com>
	<dea6cb960706140046l70b83a42rb709f7a8a3c24f8e@mail.gmail.com>
Message-ID: <dea6cb960706140057g527837c9j2a49bb6bd166b8a5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070614/e35af61f/attachment.pl 

From tanimoto at u.arizona.edu  Thu Jun 14 10:00:41 2007
From: tanimoto at u.arizona.edu (Paulo Tanimoto)
Date: Thu, 14 Jun 2007 08:00:41 +0000
Subject: [R] ARIMA with more than one seasonality period
Message-ID: <bfcc0ca60706140100n19c5df6fi9ff4a939eeb12673@mail.gmail.com>

Dear R community,

I have a project with electricity load forecasting, and I got hourly
data for system load.  If you haven't worked with electricity before,
seasonality comes in many flavors: a daily pattern, with a peak at
around 7pm; a weekly pattern, in which we use more electricity on
weekdays in comparison to weekends; a winter-summer pattern, with air
conditioning and heaters playing an important role, etc.

In SAS, I could specify an ARIMA with multiple seasonality terms, say
(1,0,1) with period=24, and (1,0,1) with period=168 (I don't remember
the orders I was using).  This is how many studies I found on IEEE
were modeling electricity load and it worked pretty well with the data
I have.

However, I can't seem to find how to do that in R.  I've read the help
files a few times, but to no avail. Is it possible?  I hope I'm
missing something straightforward.

Thank you,

Paulo Tanimoto
University of Arizona


From Rainer at krugs.de  Thu Jun 14 10:07:52 2007
From: Rainer at krugs.de (Rainer M. Krug)
Date: Thu, 14 Jun 2007 10:07:52 +0200
Subject: [R] make sample() faster
Message-ID: <4670F758.1050603@krugs.de>

Hi

I have a simulation which is relatively slow. I used Rprofile() and 
identified the calls to sample() as the culprit is sample():

 > summaryRprof("Documents/PostDoc/Aloe_Pillansii/R/create.out")
$by.self
                   self.time self.pct total.time total.pct
"sample"               1.30     44.2       1.52      51.7
"ifelse"               0.46     15.6       2.44      83.0
.
.
.

I am using sample() as follow:
result <- sample(
                  x=d.growth.seedling$growth,
                  size=1,
                  prob=d.growth.seedling$p,
                  replace
                  )

d.growth.seedling$p and d.growth.seedling$growth have a length of 1024 
and are calculated initially by using density().

My question: is there any way to make this faster, i.e. replace sample() 
as I use it with another faster algorithm (if necessary implemented in C)?

Thanks in advance,

Rainer

-- 
NEW EMAIL ADDRESS AND ADDRESS:

Rainer.Krug at uct.ac.za

RKrug at sun.ac.za WILL BE DISCONTINUED END OF MARCH

Rainer M. Krug, Dipl. Phys. (Germany), MSc Conservation
Biology (UCT)

Leslie Hill Institute for Plant Conservation
University of Cape Town
Rondebosch 7701
South Africa

Fax:		+27 - (0)86 516 2782
Fax:		+27 - (0)21 650 2440 (w)
Cell:		+27 - (0)83 9479 042

Skype:		RMkrug

email:	Rainer.Krug at uct.ac.za
       	Rainer at krugs.de


From klaster at karlin.mff.cuni.cz  Thu Jun 14 10:06:31 2007
From: klaster at karlin.mff.cuni.cz (Petr Klasterecky)
Date: Thu, 14 Jun 2007 10:06:31 +0200
Subject: [R] extractor rows from a matrix
In-Reply-To: <11114923.post@talk.nabble.com>
References: <11094459.post@talk.nabble.com>	<466FA7C3.7020703@statistik.uni-dortmund.de>
	<11114923.post@talk.nabble.com>
Message-ID: <4670F707.1050804@karlin.mff.cuni.cz>

billycorg napsal(a):
> thanks for the answer..but i don't find what i'm looking for!
> 
> now i'm trying to expose better my problem:
> i have:
> 
> ht= a 1096rows x 3 columns matrix 
>  
> i'd like a function like this:
>  
> d[i]=rbind(ht[i,]) for (i in 1:length(ht))
> 
> but this don't work :(
> can anyone seriously help  me?

The problem is that people actually are trying to seriously help you, 
but it is really difficult from your queries...

Please specify what you expect to be your output - a vector where you 
just paste the rows of of the original matrix one by one?
If so, you can do
d <- t(ht)
dim(d) <- NULL

or (a 'dirty' way)
d <- c(t(ht))

It is not at all clear what your statement should do. For example, what 
is length(ht) with ht being a matrix? For R it is the total number of 
elements, but did you mean this or the number of rows/columns??

The suggestion to read R-Intro is the best advice you got here.

Petr

-- 
Petr Klasterecky
Dept. of Probability and Statistics
Charles University in Prague
Czech Republic


From michael.watson at bbsrc.ac.uk  Thu Jun 14 10:33:42 2007
From: michael.watson at bbsrc.ac.uk (michael watson (IAH-C))
Date: Thu, 14 Jun 2007 09:33:42 +0100
Subject: [R] Difference between prcomp and cmdscale
Message-ID: <8975119BCD0AC5419D61A9CF1A923E9504F0D557@iahce2ksrv1.iah.bbsrc.ac.uk>

I'm looking for someone to explain the difference between these
procedures.  The function prcomp() does principal components anaylsis,
and the function cmdscale() does classical multi-dimensional scaling
(also called principal coordinates analysis).

My confusion stems from the fact that they give very similar results:

my.d <- matrix(rnorm(50), ncol=5)
rownames(my.d) <- paste("c", 1:10, sep="")
# prcomp
prc <- prcomp(my.d)
# cmdscale
mds <- cmdscale(dist(my.d))
cor(prc$x[,1], mds[,1]) # produces 1 or -1
cor(prc$x[,2], mds[,2]) # produces 1 or -1

Presumably, under the defaults for these commands in R, they carry out
the same (or very similar) procedures?

Thanks
Mick

The information contained in this message may be confidentia...{{dropped}}


From fdufour at pas.azti.es  Thu Jun 14 10:40:23 2007
From: fdufour at pas.azti.es (Florence Dufour)
Date: Thu, 14 Jun 2007 10:40:23 +0200
Subject: [R] How to set degrees of freedom in cor.test?
Message-ID: <FCEE957ABD363A449A2483804ED0EDE3627EA0@psrcorreo.azti.local>


Hello,

I want to compute a correlation test but I do not want to use the
degrees of freedom that are calculated by default but I want to set a
particular number of degrees of freedom.
I looked in the manual, different other functions but I did not found
how to do it

Thanks in advance for your answers

Yours




Florence Dufour
PhD Student
AZTI Tecnalia - Spain


From ted.harding at nessie.mcc.ac.uk  Thu Jun 14 10:54:04 2007
From: ted.harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Thu, 14 Jun 2007 09:54:04 +0100 (BST)
Subject: [R] Responding to a posting in the digest
In-Reply-To: <65657.87483.qm@web32215.mail.mud.yahoo.com>
Message-ID: <XFMail.070614095404.ted.harding@nessie.mcc.ac.uk>

On 14-Jun-07 07:26:26, Moshe Olshansky wrote:
> Is there a convenient way to respond to a particular
> posting which is a part of the digest?  
> I mean something that will automatically quote the
> original message, subject, etc.
> 
> Thank you!
> 
> Moshe Olshansky
> m_olshansky at yahoo.com

This will depend on two things.

1. Whether the mail software you use has the capability;
2. Whether the digest format would permit it anyway.

Regarding (2), if you are receiving R-help in "traditional"
digest format (all the messages, each with its principal
headers, as one single long message-body), then the only
way to respond to a particular message is to start to
compose a new message and copy what you need from the digest.

While I've never reveived R-help in digest format myself,
according to Martin Maechler:

http://finzi.psych.upenn.edu/R/Rhelp02a/archive/59429.html

  Please open the URL at the end of every message
     https://stat.ethz.ch/mailman/listinfo/r-help
  go to the bottom and "log in" -- clicking the
  [Unsubscribe or Edit Options] field. You need your
  mailing list password sooner or later. The one you
  get sent every 1st of the month; or you can have it
  sent to you again.

  Then you are in a page entitled
     "R-help Membership Configuration for <foo>@<bar"
  Scroll down to the section
     "Your R-help Subscription"
  where the 3rd entry is entitled
     "Get MIME or Plain Text Digests?"
  and now you want MIME. 

In MIME digest format, each message with its own main headers
is a separate MIME attachment, and suitable mail software can
bring any message up on its own, You can then reply in the
normal way.

However (and here is where I'm ignorant as a result of never
having received R-help as digest), your reply may not continue
the thread -- since this depends on message-identifier headers
being present which allow threading software to trace which
messages are replies to which message. The JISCMAIL MIME digest
for the AllStat mailing list only includes a Message-ID for the
digest as a whole, i.e. the ID for the entire digest message.
Message-IDs for the individual messages in the digest (as would
be seen by people who received them singly) are absent: you only
get the likes of

  Date:    DoW, DD Mon YYYY HH:MM:SS TZ
  From:    Sender (person who sent the message to the list)
  Subject: Subject of individual message
  MIME-Version: 1.0
  Content-Type: text/plain; charset=iso-8859-1
  Content-Transfer-Encoding: quoted-printable

and no Message ID for the original message from "Sender". So any
reply to this component message is not identifiable as belonging
to its thread.

I don't know whether R-help's 'mailman'  provides such headers
(Martin??). If it does, then your reply could include an
"In-Reply-To:" which identifies the thread. Otherwise it can't.

As to (1), you will probably get several suggestions for suitable
mail software. My own (see below) opens an AllStat digest in a window
with "attachment" tags displayed, one for "Tablf of Contents",
one for each message. Clicking on one of these opens a new window
with the message attached to that tag displayed, and now the usual
reply/forward etc mail sunctions can be applied to that message.
But it will reply only to the address given in the "From:" header
(i.e. the original sender, as above), not to the AllStat list
(so you have to enter that address by hand, if you want to reply
to the list).

In principle, mailer software could also identify the address of
the list from which the digest has been sent, as well as the sender
of the original message, so you could get the option to reply to
either or both. But my XFMail does not, and only offers the
original sender. Whether other mailer software can do this is
for others to comment on!

Hoping this helps,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 14-Jun-07                                       Time: 09:53:58
------------------------------ XFMail ------------------------------


From mpp26 at cam.ac.uk  Thu Jun 14 11:00:31 2007
From: mpp26 at cam.ac.uk (M. P. Papadatos)
Date: Thu, 14 Jun 2007 10:00:31 +0100
Subject: [R] A Question about "R"
In-Reply-To: <20070611155036.rhw1hv82880o0okw@webmail.uoguelph.ca>
References: <20070611155036.rhw1hv82880o0okw@webmail.uoguelph.ca>
Message-ID: <93E69EEC-6408-4CA2-9E0C-0E800D6B5A4E@cam.ac.uk>

Hi,

This might help you:

https://stat.ethz.ch/pipermail/r-help/2000-February/009984.html

Martin

On 11 Jun 2007, at 20:50, jwang at uoguelph.ca wrote:

> Hi Sir/Madam,
>
> I'm a researcher in university of Guelph, Canada and now considering
> using R to do some data analysis. I'm wondering whether there is a
> library available in R that includes algorithms for "archetypal
> analysis"? This is a method quite similar to principal components
> analysis that is designed to find "archetypes" or "pure types" from
> multidimensional data.
>
> Any help from you is greatly appreciated.
>
> Thanks
> Juan
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From thpe at simecol.de  Thu Jun 14 11:03:58 2007
From: thpe at simecol.de (Thomas Petzoldt)
Date: Thu, 14 Jun 2007 11:03:58 +0200
Subject: [R] Using odesolve to produce non-negative solutions
In-Reply-To: <4666A5D0.896D.005E.0@hsph.harvard.edu>
References: <4666A5D0.896D.005E.0@hsph.harvard.edu>
Message-ID: <4671047E.5030709@simecol.de>

Dear Jeremy,

a few notes about your model: The equations of your derivatives are 
designed in a way that can lead to negative state variables with certain 
parameter combinations. In order to avoid this, you are using "if 
constructions" which are intended to correct this. This method is 
however (as far as I have learned from theory and own experience ;-) a 
bad idea and should be strictly avoided.

This trick may violate assumptions of the ODE solvers and in many cases 
also mass-balances (or similar).

Instead of this, processes should be modeled in a way that avoids 
"crossing zero", e.g. exponential decay (x, k > 0):

dx = - k * x  (1)

and not a linear decay like

dx = -k       (2)

which by its nature can lead to negative state values.

Case (1) can be managed almost perfectly by lsoda with his automatic 
internal time step algorithm. hmax is intended for non-autonomous models 
to ensure that external signals are not skipped by the automatism, which 
may be appropriate in your case because p seems to contain time 
dependent functions.

As far as I can see, your equations belong to type (1) and should not 
need any of the if and for constructs, as long as your parameters (which 
are not given in your post) do have the correct sign and range (for 
example, vax <= 1, death >= 0  etc.).

If you perform optimization, you must ensure that parameters stay in the 
plausible range is met using transformations of the parameters or 
constraints in the optimization procedure.

Thomas

PS: another question, what is the purpose of the state variable N?
I guess it can be derived from the other states.


Jeremy Goldhaber-Fiebert wrote:
> Hello,
> 
> I am using odesolve to simulate a group of people moving through time
> and transmitting infections to one another.
> 
> In Matlab, there is a NonNegative option which tells the Matlab
> solver to keep the vector elements of the ODE solution non-negative
> at all times. What is the right way to do this in R?
> 
> Thanks, Jeremy

[... code deleted, see original post ...]


From gregor.gorjanc at bfro.uni-lj.si  Thu Jun 14 11:15:06 2007
From: gregor.gorjanc at bfro.uni-lj.si (Gregor)
Date: Thu, 14 Jun 2007 09:15:06 +0000 (UTC)
Subject: [R] ML, REML and several random effects
References: <466F0A40.2090601@uqar.qc.ca>
Message-ID: <loom.20070614T111355-962@post.gmane.org>

Arnaud Mosnier <arnaud_mosnier <at> UQAR.QC.CA> writes:
> Hello everyone,
> 
> Hope that my question could have interest for more than one people here.
> I know that in order to compare mixed models with different fixed effect 
> I need to use ML method.
> But ... what about comparing models with the same fixed effects and 
> different random effects ?

Likelihood ratio test on REML likelihood

Gregor


From klaster at karlin.mff.cuni.cz  Thu Jun 14 11:26:03 2007
From: klaster at karlin.mff.cuni.cz (Petr Klasterecky)
Date: Thu, 14 Jun 2007 11:26:03 +0200
Subject: [R] extractor rows from a matrix
In-Reply-To: <4670FE6C.000001.03244@VINCENZO>
References: <4670F707.1050804@karlin.mff.cuni.cz>
	<4670FE6C.000001.03244@VINCENZO>
Message-ID: <467109AB.3050108@karlin.mff.cuni.cz>

Well, you cannot have a vector of vectors, you need a list of vectors. 
With mean() and sum() it worked probably because these produce a single 
number as their output. Also, the rbind() function won't help here, that 
is for merging vector into a matrix. Once again, reading R-Intro is the 
best advice I can give you.

# creating an ampty list of length 1096:
d <- list()
length(d) <- 1096

# Filling the list with rows
for(i in (1:1096)){
d[[i]] <- ht[i,]
}

Note the double bracketing when indexing lists: d[[1]]

Please respond to the entire list next time, I only read these messages 
occasionally.

Petr


vincenzo napsal(a):
> thank you a lot for the answer
>  
> i don't expect one vector..
> but 1096 vector.
>  
> example: ht=
>            1        2        3
> 1          3        4        5
> 2          4        5        8
> 3
> 4
> .
> .
> .
> 1096 
>  
> i'd like 1096 vector like these:
> d[1]= 3    4    5
> d[2]= 4    5    8
> ...
>  
> i'm trying now with this:
> for(i in 1:1096) d[i]=(rbind(ht[i,])) 
> but it doesn't work :(
> it works with function like "mean","sum".. but not with "rbind"
> what can i do?
>  
>  
>  
> /-------Messaggio originale-------/
>  
> /*Da:*/ Petr Klasterecky <mailto:klaster at karlin.mff.cuni.cz>
> /*Data:*/ 06/14/07 10:07:33
> /*A:*/ billycorg <mailto:billycorg1 at virgilio.it>
> /*Cc:*/ r-help at stat.math.ethz.ch <mailto:r-help at stat.math.ethz.ch>
> /*Oggetto:*/ Re: [R] extractor rows from a matrix
>  
> billycorg napsal(a):
>  > thanks for the answer..but i don't find what i'm looking for!
>  >
>  > now i'm trying to expose better my problem:
>  > i have:
>  >
>  > ht= a 1096rows x 3 columns matrix
>  >
>  > i'd like a function like this:
>  >
>  > d[i]=rbind(ht[i,]) for (i in 1:length(ht))
>  >
>  > but this don't work :(
>  > can anyone seriously help  me?
>  
> The problem is that people actually are trying to seriously help you,
> but it is really difficult from your queries...
>  
> Please specify what you expect to be your output - a vector where you
> just paste the rows of of the original matrix one by one?
> If so, you can do
> d <- t(ht)
> dim(d) <- NULL
>  
> or (a 'dirty' way)
> d <- c(t(ht))
>  
> It is not at all clear what your statement should do. For example, what
> is length(ht) with ht being a matrix? For R it is the total number of
> elements, but did you mean this or the number of rows/columns??
>  
> The suggestion to read R-Intro is the best advice you got here.
>  
> Petr
>  
> --
> Petr Klasterecky
> Dept. of Probability and Statistics
> Charles University in Prague
> Czech Republic
>  
> __________ Informazione NOD32 2328 (20070613) __________
>  
> Questo messaggio  ? stato controllato dal Sistema Antivirus NOD32
> http://www.nod32.it <http://www.nod32.it/>
>  
>  
> 		
> 

-- 
Petr Klasterecky
Dept. of Probability and Statistics
Charles University in Prague
Czech Republic


From rtchiruka at yahoo.com  Thu Jun 14 11:29:14 2007
From: rtchiruka at yahoo.com (raymond chiruka)
Date: Thu, 14 Jun 2007 02:29:14 -0700 (PDT)
Subject: [R] installing packages
Message-ID: <175174.89586.qm@web33010.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070614/cb734800/attachment.pl 

From jvivben at yahoo.com  Thu Jun 14 11:31:13 2007
From: jvivben at yahoo.com (ivivi mwaniki)
Date: Thu, 14 Jun 2007 02:31:13 -0700 (PDT)
Subject: [R] besselK
Message-ID: <691542.62452.qm@web52901.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070614/962e00e6/attachment.pl 

From gavinpaulkelly at gmail.com  Thu Jun 14 11:39:03 2007
From: gavinpaulkelly at gmail.com (Gavin Kelly)
Date: Thu, 14 Jun 2007 10:39:03 +0100
Subject: [R] pretty report
Message-ID: <551186a70706140239k7d4a854dl7dcf24668dc7e330@mail.gmail.com>

At 5:01 PM -0400 6/12/07, Weiwei Shi wrote:
>Dear Listers:
>
>I have a couple of data frames to report and each corresponds to
>different condtions, e.g. conditions=c(10, 15, 20, 25). In this
>examples, four data frames need to be exported in a "pretty" report.
>
>I knew Perl has some module for exporting data to Excel and after
>googling, I found R does not.

Weiwei,

If you (or the users who are opening your reports) are going to using
a version of excel that supports the new Office XML formats, you can
write multi-sheeted workbooks as below: simply give spreadsheetML a
named list of dataframes.  You can add attributes to the components to
add things such as comments, subheadings that span multiple columns,
hyperlinks and named data-ranges.

If you can't guarantee that the opener won't have a modern Excel (I
don't believe Mac versions are yet at this stage), then you will need
to have a windows box to open the file, and save as 'proper' excel.
Below is a visual basic macro I have set up in a watched directory to
do this on the fly.  I use the program "filenotify" to watch the
directory.

If any of the package developers want to incorporate this function,
then please do get in touch.  It's probably not worth a package of
it's own, but I think the ability to have multi-sheeted excel books,
with the extra bits of formatting mentioned above might be useful.
I'ts fairly straightforward to add extra styling (colours, typefaces,
etc).

Regards - Gavin

###  The R function, and a demo
spreadsheetML <- function(dat, fname, style=NULL) {
  if (is.data.frame(dat))
    dat <- list(Sheet1=dat)
  if (is.null(names(dat)))
    names(dat) <- paste("Sheet",1:length(dat), sep="")
  names(dat)[names(dat)==""] <- paste("Sheet",1:length(dat),
sep="")[names(dat)==""]
  x <- xmlOutputDOM("Workbook", nameSpace="ss",
                    nsURI=list(
                      o="urn:schemas-microsoft-com:office:office",
                      x="urn:schemas-microsoft-com:office:excel",
                      ss="urn:schemas-microsoft-com:office:spreadsheet",
                      html="http://www.w3.org/TR/REC-html40"))
  if (!is.null(style))
    x$addNode(style)
### Annotate any named Ranges
  if (any(!is.null(lapply(dat, attr, "range")))) {
    x$addTag("Names", close=FALSE)
    for (sheet in names(dat)) {
      rngs <- attr(dat[[sheet]],"range")
      offset <- ifelse(is.null(attr(dat[[sheet]],"subhead")), 1, 2)
      for (i in names(rngs)) {
        refersTo <- sprintf("=%s!R%iC%i:R%iC%i",
                            sheet,
                            rngs[[i]]$rowStart+offset,
                            rngs[[i]]$colStart,
                            rngs[[i]]$rowEnd+offset,
                            rngs[[i]]$colEnd)
        x$addTag("NamedRange", attrs=c("ss:Name"=i,
                                 "ss:RefersTo"=refersTo))
      }
    }
    x$closeTag() #Names
  }
  for (sheet in 1:length(dat)) {
    ## For each dataframe, construct a worksheet
    x$addTag("Worksheet", attrs=c("ss:Name"=names(dat)[[sheet]]), close=FALSE)
    x$addTag("Table",close=FALSE)
    x$addTag("Row", close=FALSE)
    ## If there's a subheader, expand it, and remove entries from
relevant header
    headRow <- colnames(dat[[sheet]])
    if (!is.null(subhead <- attr(dat[[sheet]],"subhead"))) {
      subHeadRow <- rep("", length(headRow))
      for (i in names(subhead)) {
        start <- match(i, headRow)
        subHeadRow[start:(start+length(subhead[[i]])-1)] <-
          subhead[[i]]
        headRow[(start+1):(start+length(subhead[[i]])-1)] <- ""
      }
    }
    ## Create Header Row, with comments
    for (i in headRow) {
      x$addTag("Cell", close=FALSE)
      x$addTag("Data",i , attrs=c("ss:Type"="String"))
      if (!is.null(comment <- attr(dat[[sheet]],"xlComment")[[i]])) {
        if (is.character(comment)) {
          x$addTag("Comment", attrs=c("ss:Author"="BaBS"), close=FALSE)
          x$addTag("Data", comment)
          x$closeTag() #Comment
        }
      }
      x$closeTag() # Header entry
    }
    x$closeTag() # Header Row
    ## Create Sub-Header row, with comments
    if (!is.null(subhead)) {
      x$addTag("Row", close=FALSE)
      for (i in 1:length(subHeadRow)) {
        x$addTag("Cell", close=FALSE)
        x$addTag("Data",subHeadRow[i] , attrs=c("ss:Type"="String"))
        if (is.list(comment <- attr(dat[[sheet]],"xlComment")[[headRow[i]]])) {
          if (!is.null(comment <- comment[[subHeadRow[i]]])) {
            x$addTag("Comment", attrs=c("ss:Author"="BaBS"), close=FALSE)
            x$addTag("Data", comment)
            x$closeTag() #Comment
          }
        }
        x$closeTag()
      }
      x$closeTag() # subHeader Row
    }
    coltypes <- rep("String", ncol(dat[[sheet]]))
    coltypes[sapply(dat[[sheet]], is.numeric)] <- "Number"
    href <- attributes(dat[[sheet]])$href
    ## Enter the data row-wise
    for (i in 1:nrow(dat[[sheet]])) {
      x$addTag("Row", close=FALSE)
      for (j in 1:ncol(dat[[sheet]])) {
        ## Go through the row, expanding any hyperlinks
        cellAttr <- NULL
        if (!is.na(ind <- match(colnames(dat[[sheet]])[j], names(href))))
          cellAttr <- c("ss:Href"=gsub(" ", dat[[sheet]][i,j], href[ind]))
        x$addTag("Cell", attrs=cellAttr, close=FALSE)
        x$addTag("Data", as.character(dat[[sheet]][i,j]),
attrs=c("ss:Type"=coltypes[j]))
        x$closeTag()
      }
      x$closeTag() # data row
    }
    x$closeTag() # table
    x$closeTag() # Worksheet
  }
  x$closeTag() # Workbook
  con = file(fname, "w")
  saveXML(x$value(), file=con, prefix="<?xml
version=\"1.0\"?>\n<?mso-application progid=\"Excel.Sheet\"?>\n")
  close(con)
  x$reset()
}

### Example Usage
library(XML)
dat <- list(a=data.frame(A=1:10, B=LETTERS[1:10], b=letters[1:10]),
            b=data.frame(a=1:10, b=factor(LETTERS[1:2])))
attr(dat$a, "range") <- list(data=list(rowStart=1,
                               rowEnd=nrow(dat$a),
                               colStart=1,
                               colEnd=ncol(dat$a)))
attr(dat$a, "subhead") <- list(B=c("Upper","Lower"))
attr(dat$a, "xlComment") <- list(A="Hello",
                               B=list(Upper="World"))
attr(dat$b, "href") <- list(a="http://www.google.co.uk/search?q= ")
#save as .xml if using the vba script
spreadsheetML(dat, "tmp.xls")

###  Prototype script to saveas xml to xls
Dim appExcel
Dim strSource
Dim wbSource
Dim ArgObj
Set ArgObj = WScript.Arguments
Dim objRegExpr
Set objRegExpr = New regexp

objRegExpr.Pattern = ".*\.xml$"
objRegExpr.Global = True
objRegExpr.IgnoreCase = True
strSource = ArgObj(0)

if (objRegExpr.Test(strSource)) Then
  Set appExcel = CreateObject("Excel.Application")
  appExcel.DisplayAlerts = False
  Set wbSource = appExcel.Workbooks.Open(strSource)
  wbSource.SaveAs "c:\converted\tmp.xls", 1
  wbSource.Close False
  Set wbSource = Nothing
  appExcel.Quit
  Set appExcel = Nothing
End If


-- 
Gavin Kelly
Senior Statistician, Bioinformatics & Biostatistics Group
Cancer Research UK


From ritz at kvl.dk  Thu Jun 14 11:41:01 2007
From: ritz at kvl.dk (Christian Ritz)
Date: Thu, 14 Jun 2007 11:41:01 +0200
Subject: [R] Research assistant in biostatistics in Copenhagen
Message-ID: <46710D2D.4030301@kvl.dk>

The Statistics Group at the Department of Natural Sciences, Faculty of Life Sciences, 
University of Copenhagen, is looking for a research assistant with R skills.

For details see: http://www.matfys.kvl.dk/~torbenm/eu

Please note that the deadline for applications is June 22 2007.



Christian


From jrkrideau at yahoo.ca  Thu Jun 14 11:45:44 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Thu, 14 Jun 2007 05:45:44 -0400 (EDT)
Subject: [R] installing packages
In-Reply-To: <175174.89586.qm@web33010.mail.mud.yahoo.com>
Message-ID: <92165.10362.qm@web32808.mail.mud.yahoo.com>

Menu > Packages > Install Packages 
works well for me.
--- raymond chiruka <rtchiruka at yahoo.com> wrote:

> hie 
>   
>   how do l install R packages .L'm using windows
> xp.plus is there a  dipository for the packages that
> one can browse to find out what  packages are
> available.
>   thanks.
>   
>  
> ---------------------------------
> Be a PS3 game guru.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From jrkrideau at yahoo.ca  Thu Jun 14 11:53:50 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Thu, 14 Jun 2007 05:53:50 -0400 (EDT)
Subject: [R] extractor rows from a matrix
In-Reply-To: <11114923.post@talk.nabble.com>
Message-ID: <76378.69927.qm@web32811.mail.mud.yahoo.com>

I think I understand what you want.  Try

htt < data.frame(ht)
unlist (htt)


--- billycorg <billycorg1 at virgilio.it> wrote:

> 
> thanks for the answer..but i don't find what i'm
> looking for!
> 
> now i'm trying to expose better my problem:
> i have:
> 
> ht= a 1096rows x 3 columns matrix 
>  
> i'd like a function like this:
>  
> d[i]=rbind(ht[i,]) for (i in 1:length(ht))
> 
> but this don't work :(
> can anyone seriously help  me?
> -- 
> View this message in context:
>
http://www.nabble.com/extractor-rows-from-a-matrix-tf3913088.html#a11114923
> Sent from the R help mailing list archive at
> Nabble.com.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From ripley at stats.ox.ac.uk  Thu Jun 14 12:04:36 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 14 Jun 2007 11:04:36 +0100 (BST)
Subject: [R] make sample() faster
In-Reply-To: <4670F758.1050603@krugs.de>
References: <4670F758.1050603@krugs.de>
Message-ID: <Pine.LNX.4.64.0706141100110.1734@gannet.stats.ox.ac.uk>

I think the problem is not sample (which is written in C), but that you 
are calling it with size=1.  Taking one sample with probabilities from a 
large discrete distribution is necessarily slow, but you can take a large 
sample for little more cost.

On Thu, 14 Jun 2007, Rainer M. Krug wrote:

> Hi
>
> I have a simulation which is relatively slow. I used Rprofile() and
> identified the calls to sample() as the culprit is sample():
>
> > summaryRprof("Documents/PostDoc/Aloe_Pillansii/R/create.out")
> $by.self
>                   self.time self.pct total.time total.pct
> "sample"               1.30     44.2       1.52      51.7
> "ifelse"               0.46     15.6       2.44      83.0
> .
> .
> .
>
> I am using sample() as follow:
> result <- sample(
>                  x=d.growth.seedling$growth,
>                  size=1,
>                  prob=d.growth.seedling$p,
>                  replace
>                  )
>
> d.growth.seedling$p and d.growth.seedling$growth have a length of 1024
> and are calculated initially by using density().
>
> My question: is there any way to make this faster, i.e. replace sample()
> as I use it with another faster algorithm (if necessary implemented in C)?
>
> Thanks in advance,
>
> Rainer
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From billycorg1 at virgilio.it  Thu Jun 14 12:06:49 2007
From: billycorg1 at virgilio.it (billycorg)
Date: Thu, 14 Jun 2007 03:06:49 -0700 (PDT)
Subject: [R] extractor rows from a matrix
In-Reply-To: <467109AB.3050108@karlin.mff.cuni.cz>
References: <11094459.post@talk.nabble.com>
	<466FA7C3.7020703@statistik.uni-dortmund.de>
	<11114923.post@talk.nabble.com>
	<4670F707.1050804@karlin.mff.cuni.cz>
	<467109AB.3050108@karlin.mff.cuni.cz>
Message-ID: <11117324.post@talk.nabble.com>


Petr, it works!!!
thank you a lot!!!

Vincenzo


Petr Klasterecky wrote:
> 
> Well, you cannot have a vector of vectors, you need a list of vectors. 
> With mean() and sum() it worked probably because these produce a single 
> number as their output. Also, the rbind() function won't help here, that 
> is for merging vector into a matrix. Once again, reading R-Intro is the 
> best advice I can give you.
> 
> # creating an ampty list of length 1096:
> d <- list()
> length(d) <- 1096
> 
> # Filling the list with rows
> for(i in (1:1096)){
> d[[i]] <- ht[i,]
> }
> 
> Note the double bracketing when indexing lists: d[[1]]
> 
> Please respond to the entire list next time, I only read these messages 
> occasionally.
> 
> Petr
> 
> 
> vincenzo napsal(a):
>> thank you a lot for the answer
>>  
>> i don't expect one vector..
>> but 1096 vector.
>>  
>> example: ht=
>>            1        2        3
>> 1          3        4        5
>> 2          4        5        8
>> 3
>> 4
>> .
>> .
>> .
>> 1096 
>>  
>> i'd like 1096 vector like these:
>> d[1]= 3    4    5
>> d[2]= 4    5    8
>> ...
>>  
>> i'm trying now with this:
>> for(i in 1:1096) d[i]=(rbind(ht[i,])) 
>> but it doesn't work :(
>> it works with function like "mean","sum".. but not with "rbind"
>> what can i do?
>>  
>>  
>>  
>> /-------Messaggio originale-------/
>>  
>> /*Da:*/ Petr Klasterecky <mailto:klaster at karlin.mff.cuni.cz>
>> /*Data:*/ 06/14/07 10:07:33
>> /*A:*/ billycorg <mailto:billycorg1 at virgilio.it>
>> /*Cc:*/ r-help at stat.math.ethz.ch <mailto:r-help at stat.math.ethz.ch>
>> /*Oggetto:*/ Re: [R] extractor rows from a matrix
>>  
>> billycorg napsal(a):
>>  > thanks for the answer..but i don't find what i'm looking for!
>>  >
>>  > now i'm trying to expose better my problem:
>>  > i have:
>>  >
>>  > ht= a 1096rows x 3 columns matrix
>>  >
>>  > i'd like a function like this:
>>  >
>>  > d[i]=rbind(ht[i,]) for (i in 1:length(ht))
>>  >
>>  > but this don't work :(
>>  > can anyone seriously help  me?
>>  
>> The problem is that people actually are trying to seriously help you,
>> but it is really difficult from your queries...
>>  
>> Please specify what you expect to be your output - a vector where you
>> just paste the rows of of the original matrix one by one?
>> If so, you can do
>> d <- t(ht)
>> dim(d) <- NULL
>>  
>> or (a 'dirty' way)
>> d <- c(t(ht))
>>  
>> It is not at all clear what your statement should do. For example, what
>> is length(ht) with ht being a matrix? For R it is the total number of
>> elements, but did you mean this or the number of rows/columns??
>>  
>> The suggestion to read R-Intro is the best advice you got here.
>>  
>> Petr
>>  
>> --
>> Petr Klasterecky
>> Dept. of Probability and Statistics
>> Charles University in Prague
>> Czech Republic
>>  
>> __________ Informazione NOD32 2328 (20070613) __________
>>  
>> Questo messaggio  ? stato controllato dal Sistema Antivirus NOD32
>> http://www.nod32.it <http://www.nod32.it/>
>>  
>>  
>> 		
>> 
> 
> -- 
> Petr Klasterecky
> Dept. of Probability and Statistics
> Charles University in Prague
> Czech Republic
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/extractor-rows-from-a-matrix-tf3913088.html#a11117324
Sent from the R help mailing list archive at Nabble.com.


From termcc at googlemail.com  Thu Jun 14 12:22:45 2007
From: termcc at googlemail.com (Tom McCallum)
Date: Thu, 14 Jun 2007 11:22:45 +0100
Subject: [R] Dates in Windows
Message-ID: <op.ttwpr4evcsmg07@localhost.localdomain>

Hi everyone,

When using R on Linux I can do the following:

> x <- as.Date("01/04/2007", "%d/%m/%Y");
> x
[1] "2007-04-01"
> print(format(x, "%s"));
[1] "1175385600"

When using R in Windows XP though the format "%s" does nothing but return  
a blank string.  How can I convert a date to the number of seconds since  
1970 in Windows?

Cheers

Tom


From info at aghmed.fsnet.co.uk  Thu Jun 14 12:22:48 2007
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Thu, 14 Jun 2007 11:22:48 +0100
Subject: [R] Responding to a posting in the digest
In-Reply-To: <65657.87483.qm@web32215.mail.mud.yahoo.com>
References: <65657.87483.qm@web32215.mail.mud.yahoo.com>
Message-ID: <Zen-1HymTe-0001GF-IO@heisenberg.zen.co.uk>

At 08:26 14/06/2007, Moshe Olshansky wrote:
>Is there a convenient way to respond to a particular
>posting which is a part of the digest?
>I mean something that will automatically quote the
>original message, subject, etc.

Yes, if you use appropriate mailing software. I use Eudora, receive 
the emails in MIME format and the responses do get properly threaded 
as far as I can see from the mailing list archives.

>Thank you!
>
>Moshe Olshansky
>m_olshansky at yahoo.com

Michael Dewey
http://www.aghmed.fsnet.co.uk


From r.hankin at noc.soton.ac.uk  Thu Jun 14 12:34:58 2007
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Thu, 14 Jun 2007 11:34:58 +0100
Subject: [R] besselK
In-Reply-To: <691542.62452.qm@web52901.mail.re2.yahoo.com>
References: <691542.62452.qm@web52901.mail.re2.yahoo.com>
Message-ID: <64A6930D-62AB-4A07-9F95-9FC2241611F0@noc.soton.ac.uk>

Hello

AFAIK, R has no capability for evaluating Bessel functions for  
complex arguments.

Bessel functions for complex arguments are difficult to evaluate  
numerically.
Some Bessel functions require cut lines or consideration of Riemann  
surfaces.

The GSL library (for which the gsl package is an R wrapper) does
not include such functionality although the issue has arisen
on the GSL email list a couple of times over the last few years.

Writing R functionality for Bessel functions (and in particular
the Airy function) is on my List of Things To Do, but
don't hold your breath  . . .

best wishes


Robin




On 14 Jun 2007, at 10:31, ivivi mwaniki wrote:

> Assistance,
> besselK- complex number problem
>  Im a student  intrested in using R in my learning and research  
> work in option pricing however i have a problem with besselK  
> function In R.
>  Would you assit me in computing the besselK of third kind of a  
> complex number in R.
>  Any code or suggestion will be highly appriceiated
>  eg
>  besselK(2,10)  works well.. but
>  besselK(2,10i) doesnt work !!
>
>  im supprised it works in MATLAB but NOT in R.
>  rgds
>  ivivi mwaniki
>  student kenya
>
>
> ---------------------------------
> Don't pick lemons.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743


From ripley at stats.ox.ac.uk  Thu Jun 14 12:45:47 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 14 Jun 2007 11:45:47 +0100 (BST)
Subject: [R] Dates in Windows
In-Reply-To: <op.ttwpr4evcsmg07@localhost.localdomain>
References: <op.ttwpr4evcsmg07@localhost.localdomain>
Message-ID: <Pine.LNX.4.64.0706141138330.3268@gannet.stats.ox.ac.uk>

%s is of course not documented on ?strftime: it is a glibc extension and 
marked as such on my Linux man page.

But as.numeric(x) gives you the number of days, and
as.numeric(as.POSIXct(x)) gives you the number of seconds, equal to
86400*as.numeric(x).

[Why are you including empty commands at the end of every R line?
It is not necessary and makes the code harder to read.]


On Thu, 14 Jun 2007, Tom McCallum wrote:

> Hi everyone,
>
> When using R on Linux I can do the following:
>
>> x <- as.Date("01/04/2007", "%d/%m/%Y");
>> x
> [1] "2007-04-01"
>> print(format(x, "%s"));
> [1] "1175385600"
>
> When using R in Windows XP though the format "%s" does nothing but return
> a blank string.  How can I convert a date to the number of seconds since
> 1970 in Windows?
>
> Cheers
>
> Tom
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From m.booman at path.umcg.nl  Thu Jun 14 12:50:04 2007
From: m.booman at path.umcg.nl (Booman, M)
Date: Thu, 14 Jun 2007 12:50:04 +0200
Subject: [R] Wilcoxon test on data matrix
References: <mailman.12.1181815206.19860.r-help@stat.math.ethz.ch>
Message-ID: <F1204FFE7AA6E248A1BC6AB7C732F1490DA913@W3ZKHAS05.zkh.umcg.intra>

Dear everyone,
I am trying to do a Wilcoxon one-sided test on my gene expression data.
These are the data i have in R:
data.matrix (matrix, numeric) containing all gene expression data (42 rows=genes,  42 columns=tumors), no column header or row names
data.cl (vector, numeric) consisting of 42 0's and 1's to indicate class 0 or class 1 for each column in data.matrix

I want to do a Wilcoxon one-sided test on the data from class 0 versus the data from class 1, for each row (gene) of the data set.
My first try:

#to make separate matrices for both classes:
data.matrix.0 <- data.matrix[,data.cl==0] 
data.matrix.1 <- data.matrix[,data.cl==1]

# to run the wilcox.test function for each row:
rawp <- apply(data.matrix.0, 1, wilcox.test, y=data.matrix.1, alternative="less")


The result of printing rawp is:
$`1`

	Wilcoxon rank sum test with continuity correction

data:  newX[, i] and data.matrix.1 
W = 7585, p-value = 1
alternative hypothesis: true location shift is less than 0 


$`2`

	Wilcoxon rank sum test with continuity correction

data:  newX[, i] and data.matrix.1 
W = 6700, p-value = 0.9983
alternative hypothesis: true location shift is less than 0 


Etcetera for each row of the data matrix. 
I can get the p value for one row (gene) using:
rawp.1 <- rawp$'1'$p.value

But how can I get these p-values in one list? I have tried:
rawp <- NULL
for (i in 1:42) {
	a <- paste("'", i, "'", sep="")
	rawp <- rbind(rawp, test$a$p.value)
 }

but that doesn't work (no errors but rawp stays NULL)

There must be an easier way to do a wilcoxon analysis on a matrix!
I'd appreciate your help with this...

Marije


De inhoud van dit bericht is vertrouwelijk en alleen bestemd voor de geadresseerde(n). Anderen dan de geadresseerde mogen geen gebruik maken van dit bericht, het openbaar maken of op enige wijze verspreiden of vermenigvuldigen. Het UMCG kan niet aansprakelijk gesteld worden voor een incomplete aankomst of vertraging van dit verzonden bericht.

The contents of this message are confidential and only intended for the eyes of the addressee(s). Others than the addressee(s) are not allowed to use this message, to make it public or to distribute or multiply this message in any way. The UMCG cannot be held responsible for incomplete reception or delay of this transferred message.

From diego.gruber at gmail.com  Thu Jun 14 12:53:38 2007
From: diego.gruber at gmail.com (Diego Gruber)
Date: Thu, 14 Jun 2007 12:53:38 +0200
Subject: [R] function with xyplot
Message-ID: <f1372edc0706140353m4342ede2of70bb6b72a70994a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070614/4906d6ab/attachment.pl 

From james.milks at wright.edu  Thu Jun 14 13:00:07 2007
From: james.milks at wright.edu (James R. Milks)
Date: Thu, 14 Jun 2007 07:00:07 -0400
Subject: [R] Generating artificial datasets with a specific correlation
 coefficient.
References: <efb536d50706121437o7bdf5ab3xafb896e94d64204b@mail.gmail.com>
Message-ID: <00F7A573-C742-4489-B197-24B59115CAA3@wright.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070614/02157514/attachment.pl 

From jrkrideau at yahoo.ca  Thu Jun 14 13:16:25 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Thu, 14 Jun 2007 07:16:25 -0400 (EDT)
Subject: [R] function with xyplot
In-Reply-To: <f1372edc0706140353m4342ede2of70bb6b72a70994a@mail.gmail.com>
Message-ID: <854721.34703.qm@web32810.mail.mud.yahoo.com>

You need to reference the data.frame or append it.  

myplot(DF$X) should work
or 
append(DF)
myplot(X)
--- Diego Gruber <diego.gruber at gmail.com> wrote:

> Hi,
> 
> I'm a new user trying to switch from SAS, so sorry
> for the beginner's
> question: Suppose I have a dataframe DF that
> contains variables X,Y,Z. I am
> trying to write a function like this:
> 
> myplot <- function(varname){xyplot(varname ~ Y,
> group = Z, data = DF)}.
> 
> The problem is then how to enter X into my function.
> If I write myplot("X")
> I get an error because the argument is a string and
> xyplot can make nothing
> out of it. If I write myplot(X) I also get an error
> that tells me the object
> X does not exist.
> 
> Thanks for your help,
> 
> Diego
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From wl2776 at gmail.com  Thu Jun 14 13:24:36 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Thu, 14 Jun 2007 04:24:36 -0700 (PDT)
Subject: [R] test if files in current folder
In-Reply-To: <11113853.post@talk.nabble.com>
References: <11113853.post@talk.nabble.com>
Message-ID: <11118347.post@talk.nabble.com>




runner wrote:
> 
> I want to test if the files are already in my current folder before I
> download or copy from somewhere else. What's in my mind is to check if a
> file is open-able in current folder. Is there a way to do this, like in
> Perl: 
> if (open()) { do sth}?
> 
> To put it another way, how to extract all file names in a folder to an
> array or list? 
> 

?files
?dir

BTW, Perl has nice -X functions, which allow file testing without explicit
opening:
 http://perldoc.perl.org/functions/-X.html
-- 
View this message in context: http://www.nabble.com/test-if-files-in-current-folder-tf3919587.html#a11118347
Sent from the R help mailing list archive at Nabble.com.


From ted.harding at nessie.mcc.ac.uk  Thu Jun 14 13:25:06 2007
From: ted.harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Thu, 14 Jun 2007 12:25:06 +0100 (BST)
Subject: [R] Tools For Preparing Data For Analysis
In-Reply-To: <466D3039.7070002@lancaster.ac.uk>
Message-ID: <XFMail.070614122506.ted.harding@nessie.mcc.ac.uk>

As a tangent to this thread, there is a very relevant
article in the latest issue of the RSS magazine "Significance",
which I have just received:

  Dr Fisher's Casebook
  The trouble with data

Significance, Vol 4 (2007) Issue 2.

Full current contents at

http://www.blackwell-synergy.com/toc/sign/4/2

but unfortunately you can only read any of it by paying
money to Blackwell (unless you're an RSS member).

Best wishes to all,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 14-Jun-07                                       Time: 12:24:46
------------------------------ XFMail ------------------------------


From christophe at pallier.org  Thu Jun 14 13:32:00 2007
From: christophe at pallier.org (Christophe Pallier)
Date: Thu, 14 Jun 2007 13:32:00 +0200
Subject: [R] Wilcoxon test on data matrix
In-Reply-To: <F1204FFE7AA6E248A1BC6AB7C732F1490DA913@W3ZKHAS05.zkh.umcg.intra>
References: <mailman.12.1181815206.19860.r-help@stat.math.ethz.ch>
	<F1204FFE7AA6E248A1BC6AB7C732F1490DA913@W3ZKHAS05.zkh.umcg.intra>
Message-ID: <dea6cb960706140432w31f6e182k7c7a4f670807c41@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070614/0ff59094/attachment.pl 

From cinzia.viroli at unibo.it  Thu Jun 14 13:37:54 2007
From: cinzia.viroli at unibo.it (Cinzia Viroli)
Date: Thu, 14 Jun 2007 13:37:54 +0200
Subject: [R] building packages under windows
Message-ID: <6.0.1.1.2.20070614133116.03601008@mail.unibo.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070614/9f4a8263/attachment.pl 

From mark_difford at yahoo.co.uk  Thu Jun 14 13:49:26 2007
From: mark_difford at yahoo.co.uk (Mark Difford)
Date: Thu, 14 Jun 2007 04:49:26 -0700 (PDT)
Subject: [R] Difference between prcomp and cmdscale
In-Reply-To: <8975119BCD0AC5419D61A9CF1A923E9504F0D557@iahce2ksrv1.iah.bbsrc.ac.uk>
References: <8975119BCD0AC5419D61A9CF1A923E9504F0D557@iahce2ksrv1.iah.bbsrc.ac.uk>
Message-ID: <11118602.post@talk.nabble.com>


Michael,

Why should that confuse you?  Have you tried reading some of the literature
on these methods?  There's plenty about them on the Net (Wiki's often a
goodish place to start)---and even in R, if you're prepared to look ;).

BestR,
Mark.


michael watson (IAH-C) wrote:
> 
> I'm looking for someone to explain the difference between these
> procedures.  The function prcomp() does principal components anaylsis,
> and the function cmdscale() does classical multi-dimensional scaling
> (also called principal coordinates analysis).
> 
> My confusion stems from the fact that they give very similar results:
> 
> my.d <- matrix(rnorm(50), ncol=5)
> rownames(my.d) <- paste("c", 1:10, sep="")
> # prcomp
> prc <- prcomp(my.d)
> # cmdscale
> mds <- cmdscale(dist(my.d))
> cor(prc$x[,1], mds[,1]) # produces 1 or -1
> cor(prc$x[,2], mds[,2]) # produces 1 or -1
> 
> Presumably, under the defaults for these commands in R, they carry out
> the same (or very similar) procedures?
> 
> Thanks
> Mick
> 
> The information contained in this message may be confidentia...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/Difference-between-prcomp-and-cmdscale-tf3920408.html#a11118602
Sent from the R help mailing list archive at Nabble.com.


From ripley at stats.ox.ac.uk  Thu Jun 14 13:56:16 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 14 Jun 2007 12:56:16 +0100 (BST)
Subject: [R] building packages under windows
In-Reply-To: <6.0.1.1.2.20070614133116.03601008@mail.unibo.it>
References: <6.0.1.1.2.20070614133116.03601008@mail.unibo.it>
Message-ID: <Pine.LNX.4.64.0706141254500.15750@gannet.stats.ox.ac.uk>

If you try

Rcmd INSTALL mypackage

you will get the error messages on the terminal.  I've never not seen them 
in the mypackage.Rcheck/00install.out file, but then I used the correct 
name.

On Thu, 14 Jun 2007, Cinzia Viroli wrote:

>
> I tried to check or build a package under windows xp but I got the error
>
> the package can not be installed
>
> (without any details in the install.out file)
>
> I work with R-2.5.0, Miktex 2.5.0, and I have installed the unix tools.zip,
> Perl and Microsoft HTML Workshop.
> The path environment is ok.
>
> Have someone else encountered the same problem?
>
> Thank you,
> Cinzia
>
>
>
>
>
>
>
>
>
> ------------------------------------------------------------------------------------------------------------------------------------------------
> Cinzia Viroli
> Dipartimento di Scienze Statistiche "Paolo Fortunati"
> Via delle Belle Arti 41
> 40126 Bologna
> Italy
> Ph.  +39 051 2098250
> Fax  +39 051 232153
>
> home: www2.stat.unibo.it/viroli
> ------------------------------------------------------------------------------------------------------------------------------------------------
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Jun 14 13:59:15 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 14 Jun 2007 12:59:15 +0100 (BST)
Subject: [R] Difference between prcomp and cmdscale
In-Reply-To: <8975119BCD0AC5419D61A9CF1A923E9504F0D557@iahce2ksrv1.iah.bbsrc.ac.uk>
References: <8975119BCD0AC5419D61A9CF1A923E9504F0D557@iahce2ksrv1.iah.bbsrc.ac.uk>
Message-ID: <Pine.LNX.4.64.0706141256520.15750@gannet.stats.ox.ac.uk>

On Thu, 14 Jun 2007, michael watson (IAH-C) wrote:

> I'm looking for someone to explain the difference between these
> procedures.  The function prcomp() does principal components anaylsis,
> and the function cmdscale() does classical multi-dimensional scaling
> (also called principal coordinates analysis).
>
> My confusion stems from the fact that they give very similar results:
>
> my.d <- matrix(rnorm(50), ncol=5)
> rownames(my.d) <- paste("c", 1:10, sep="")
> # prcomp
> prc <- prcomp(my.d)
> # cmdscale
> mds <- cmdscale(dist(my.d))
> cor(prc$x[,1], mds[,1]) # produces 1 or -1
> cor(prc$x[,2], mds[,2]) # produces 1 or -1
>
> Presumably, under the defaults for these commands in R, they carry out
> the same (or very similar) procedures?

For Eucldean distance, the same.  The point being that classical MDS on 
Euclidean distances is just PCA on the reconstucted configuration, but 
that MDS is not restricted to a data matrix.

The relationship is explained in MASS, for example.

> Thanks
> Mick


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Rainer at krugs.de  Thu Jun 14 14:02:15 2007
From: Rainer at krugs.de (Rainer M. Krug)
Date: Thu, 14 Jun 2007 14:02:15 +0200
Subject: [R] make sample() faster
In-Reply-To: <Pine.LNX.4.64.0706141100110.1734@gannet.stats.ox.ac.uk>
References: <4670F758.1050603@krugs.de>
	<Pine.LNX.4.64.0706141100110.1734@gannet.stats.ox.ac.uk>
Message-ID: <46712E47.1040906@krugs.de>

Thanks for the info - so the solution would (likely) be to draw several 
samples and use these whenever I need a new one.

tHANKS, i'LL TRY IT OUT,

rAINER

P.S: somebody said once that the caps-lock key is the most useless key 
on the keyboard and he is right...


Prof Brian Ripley wrote:
> I think the problem is not sample (which is written in C), but that you 
> are calling it with size=1.  Taking one sample with probabilities from a 
> large discrete distribution is necessarily slow, but you can take a large 
> sample for little more cost.
> 
> On Thu, 14 Jun 2007, Rainer M. Krug wrote:
> 
>> Hi
>>
>> I have a simulation which is relatively slow. I used Rprofile() and
>> identified the calls to sample() as the culprit is sample():
>>
>>> summaryRprof("Documents/PostDoc/Aloe_Pillansii/R/create.out")
>> $by.self
>>                   self.time self.pct total.time total.pct
>> "sample"               1.30     44.2       1.52      51.7
>> "ifelse"               0.46     15.6       2.44      83.0
>> .
>> .
>> .
>>
>> I am using sample() as follow:
>> result <- sample(
>>                  x=d.growth.seedling$growth,
>>                  size=1,
>>                  prob=d.growth.seedling$p,
>>                  replace
>>                  )
>>
>> d.growth.seedling$p and d.growth.seedling$growth have a length of 1024
>> and are calculated initially by using density().
>>
>> My question: is there any way to make this faster, i.e. replace sample()
>> as I use it with another faster algorithm (if necessary implemented in C)?
>>
>> Thanks in advance,
>>
>> Rainer
>>
>>
> 


-- 
NEW EMAIL ADDRESS AND ADDRESS:

Rainer.Krug at uct.ac.za

RKrug at sun.ac.za WILL BE DISCONTINUED END OF MARCH

Rainer M. Krug, Dipl. Phys. (Germany), MSc Conservation
Biology (UCT)

Leslie Hill Institute for Plant Conservation
University of Cape Town
Rondebosch 7701
South Africa

Fax:		+27 - (0)86 516 2782
Fax:		+27 - (0)21 650 2440 (w)
Cell:		+27 - (0)83 9479 042

Skype:		RMkrug

email:	Rainer.Krug at uct.ac.za
       	Rainer at krugs.de


From ripley at stats.ox.ac.uk  Thu Jun 14 14:01:14 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 14 Jun 2007 13:01:14 +0100 (BST)
Subject: [R] test if files in current folder
In-Reply-To: <11118347.post@talk.nabble.com>
References: <11113853.post@talk.nabble.com> <11118347.post@talk.nabble.com>
Message-ID: <Pine.LNX.4.64.0706141300090.15750@gannet.stats.ox.ac.uk>

On Thu, 14 Jun 2007, Vladimir Eremeev wrote:

>
>
>
> runner wrote:
>>
>> I want to test if the files are already in my current folder before I
>> download or copy from somewhere else. What's in my mind is to check if a
>> file is open-able in current folder. Is there a way to do this, like in
>> Perl:
>> if (open()) { do sth}?
>>
>> To put it another way, how to extract all file names in a folder to an
>> array or list?
>>
>
> ?files
> ?dir
>
> BTW, Perl has nice -X functions, which allow file testing without explicit
> opening:
> http://perldoc.perl.org/functions/-X.html

which are based on those in 'test' and most Unix shells, as is R's 
file.test() in package 'utils'.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tirthankar.patnaik at citi.com  Thu Jun 14 14:04:24 2007
From: tirthankar.patnaik at citi.com (Patnaik, Tirthankar )
Date: Thu, 14 Jun 2007 17:34:24 +0530
Subject: [R] Preserving dates in Excel.
Message-ID: <6E2AF71DA2E3F241A66122F3F90F32140DB2BD@exinmb04-bkp.apac.nsroot.net>

Hi,
	Quick question: Say I have a date variable in a data frame or
matrix, and I'd like to preserve the date format when using write.table.
However, when I export the data, I get the generic number underlying the
date, not the date per se, and a number such as 11323, 11324, etc are
not meaningful in Excel. Is there any way I can preserve the format of a
date on writing into a text-file?

TIA and best,
-Tir


From yn19832 at msn.com  Thu Jun 14 14:28:46 2007
From: yn19832 at msn.com (livia)
Date: Thu, 14 Jun 2007 05:28:46 -0700 (PDT)
Subject: [R] Fitted Value Pareto Distribution
In-Reply-To: <f4p2gc$22e$1@sea.gmane.org>
References: <11097749.post@talk.nabble.com> <f4p2gc$22e$1@sea.gmane.org>
Message-ID: <11119224.post@talk.nabble.com>


Thank you very much and that is exactly what I am looking for. Another
question would be how can I test the goodness of fit for the Pareto
distribution?



J. Hosking wrote:
> 
> livia wrote:
>> I would like to fit a Pareto Distribution and I am using the following
>> codes. 
>> 
>> I thought the fitted (fit1) should be the fitted value for the data, is
>> it
>> correct? As the result of the "fitted" turns out to be a single value for
>> all. 
>> 
>> fit=vglm(ycf1 ~ 1, pareto1(location=alpha), trace=TRUE, crit="c") 
>> fitted(fit) 
>> 
>> The result is 
>> fitted(fit)
>>             [,1]
>>  [1,] 0.07752694
>>  [2,] 0.07752694
>>  [3,] 0.07752694
>>  [4,] 0.07752694
>>  [5,] 0.07752694
>>  [6,] 0.07752694
>>  [7,] 0.07752694
>>  [8,] 0.07752694
>>  [9,] 0.07752694
>> [10,] 0.07752694
>> [11,] 0.07752694
>> [12,] 0.07752694
>> [13,] 0.07752694
>> 
>> Could anybody give me some advice? 
>> 
> 
> I don't have whatever package function 'vglm' comes from (did you
> follow the instructions in the last two lines of your post?), but you
> can fit a GPD and get fitted values for it by some such approach as
> this:
> 
>    library(POT)
>    threshold <- 0  # probably
>    para <- fitgpd(ycf1, threshold, method="pwmu")$param
>    ycf1.fit <- qgpd( ppoints(ycf1, a=0.44), threshold, para[1], para[2])
> 
> Note that the above code contains my own preferences for fitting
> method and plotting positions: yours may differ.
> 
> 
> J. R. M. Hosking
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/Fitted-Value-Pareto-Distribution-tf3914151.html#a11119224
Sent from the R help mailing list archive at Nabble.com.


From forum at dejung.net  Thu Jun 14 14:30:47 2007
From: forum at dejung.net (Mario Dejung)
Date: Thu, 14 Jun 2007 14:30:47 +0200 (CEST)
Subject: [R] problem with hist()
Message-ID: <34232.134.93.157.71.1181824247.squirrel@webmail.ts-cs.de>

Hey everybody,
I try to make a graph with two different plots.


First I make a boxplot of my data. It is a collection off correlation
values of different pictures. For example:

0.23445 pica
0.34456 pica
0.45663 pica
0.98822 picb
0.12223 picc
0.34443 picc
etc.

Ok, I make this boxplot and I get for every picture the boxes. After this
I want to know, how many correlations per picture exist.
So I make a new vector y <- as.numeric(data$picture)

So I get for my example something like this:

y
[1] 1 1 1 1 1 1 1 1 1 1
[11] 1 1 1 1 1 1 1 1 2 2
...
[16881] 59 59 59 60 60 60 60 60 60 60

After this I make something like this

boxplot(cor ~ pic)
par(new = TRUE)
hist(y, nclass = 60)

But there is my problem. I have 60 pictures, so I get 60 different
boxplots, and I want the hist behind the boxes. But it makes only 59
histbars.

What can I do? I tried also
hist(y, 1:60) # same effect
and
hist(y, 1:61)
this give me 60 places, but only 59 bars. the last bar is 0.

I hope anyone can help me.

Regards Mario


From P.Dalgaard at biostat.ku.dk  Thu Jun 14 14:36:46 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 14 Jun 2007 14:36:46 +0200
Subject: [R] Preserving dates in Excel.
In-Reply-To: <6E2AF71DA2E3F241A66122F3F90F32140DB2BD@exinmb04-bkp.apac.nsroot.net>
References: <6E2AF71DA2E3F241A66122F3F90F32140DB2BD@exinmb04-bkp.apac.nsroot.net>
Message-ID: <4671365E.7070808@biostat.ku.dk>

Patnaik, Tirthankar wrote:
> Hi,
> 	Quick question: Say I have a date variable in a data frame or
> matrix, and I'd like to preserve the date format when using write.table.
> However, when I export the data, I get the generic number underlying the
> date, not the date per se, and a number such as 11323, 11324, etc are
> not meaningful in Excel. Is there any way I can preserve the format of a
> date on writing into a text-file?
>
>   
Er, what is exactly the problem here?

> d <- data.frame(date=as.Date("2007-6-1")+1:5, x=rnorm(5))
> d
        date             x
1 2007-06-02  0.7987635130
2 2007-06-03 -0.7381623316
3 2007-06-04 -1.3626708691
4 2007-06-05  0.0007668082
5 2007-06-06  0.6719088533
> write.table(d)
"date" "x"
"1" 2007-06-02 0.798763513018864
"2" 2007-06-03 -0.738162331606612
"3" 2007-06-04 -1.36267086906438
"4" 2007-06-05 0.000766808196322155
"5" 2007-06-06 0.671908853312511
> write.csv(d)
"","date","x"
"1",2007-06-02,0.798763513018864
"2",2007-06-03,-0.738162331606612
"3",2007-06-04,-1.36267086906438
"4",2007-06-05,0.000766808196322155
"5",2007-06-06,0.671908853312511


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From diego.gruber at gmail.com  Thu Jun 14 14:39:00 2007
From: diego.gruber at gmail.com (Diego Gruber)
Date: Thu, 14 Jun 2007 14:39:00 +0200
Subject: [R] function with xyplot
In-Reply-To: <f8e6ff050706140438r2a78ddccva83035087104e14d@mail.gmail.com>
References: <f1372edc0706140353m4342ede2of70bb6b72a70994a@mail.gmail.com>
	<f8e6ff050706140438r2a78ddccva83035087104e14d@mail.gmail.com>
Message-ID: <f1372edc0706140539k7c3b17e2qccb0c9468297bc5e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070614/95611082/attachment.pl 

From matthias.vonrad at googlemail.com  Thu Jun 14 14:40:23 2007
From: matthias.vonrad at googlemail.com (Matthias von Rad)
Date: Thu, 14 Jun 2007 14:40:23 +0200
Subject: [R] scatterplots: (equal axes and overlay)
Message-ID: <5dad6e7c0706140540q1751c1fdlbb849b9136265bf7@mail.gmail.com>

Hi,
I am doing lots of scatterplots for my dissertation and to make the
comparable, I would like to have equal x- amd - y axis. Can I specify
their scale?
Another question adresses overlay scatterplots. Having prae and post
measures for each case, is it possible to have them in one graph with
symbols or colors for prae and post.
So
scatterplot(bdiprae,mocoprae) and
scatterplot(bdipost,mocopost) in one graph (for example green for prae
and red for post?)
thanks a lot in advance
Matthias


From ripley at stats.ox.ac.uk  Thu Jun 14 14:47:10 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 14 Jun 2007 13:47:10 +0100 (BST)
Subject: [R] Preserving dates in Excel.
In-Reply-To: <6E2AF71DA2E3F241A66122F3F90F32140DB2BD@exinmb04-bkp.apac.nsroot.net>
References: <6E2AF71DA2E3F241A66122F3F90F32140DB2BD@exinmb04-bkp.apac.nsroot.net>
Message-ID: <Pine.LNX.4.64.0706141344560.21244@gannet.stats.ox.ac.uk>

On Thu, 14 Jun 2007, Patnaik, Tirthankar  wrote:

> Hi,
> 	Quick question: Say I have a date variable in a data frame or
> matrix,

Which? It matters: see the help page.

> and I'd like to preserve the date format when using write.table.
> However, when I export the data, I get the generic number underlying the
> date, not the date per se, and a number such as 11323, 11324, etc are
> not meaningful in Excel. Is there any way I can preserve the format of a
> date on writing into a text-file?

Yes, see the help page and use a data frame.  E.g.

> write.table(data.frame(x=.leap.seconds[1:3]), "")
"x"
"1" 1972-07-01 01:00:00
"2" 1973-01-01 00:00:00
"3" 1974-01-01 00:00:00


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tirthankar.patnaik at citi.com  Thu Jun 14 14:49:05 2007
From: tirthankar.patnaik at citi.com (Patnaik, Tirthankar )
Date: Thu, 14 Jun 2007 18:19:05 +0530
Subject: [R] Preserving dates in Excel.
Message-ID: <6E2AF71DA2E3F241A66122F3F90F32140DB2BE@exinmb04-bkp.apac.nsroot.net>

Hi Peter, Prof. Ripley,

	You're right--I just realized I was exporting a matrix, after converting the data-frame using data.matrix, where the date characteristics are lost.

 
Basically a function I was running converted the dataframe to a matrix first--something I'd forgotten.

> z1 <- data.matrix(head(Banks.Index.daily[,1:5]))
Warning message:
class information lost from one or more columns in: data.matrix(head(Banks.Index.daily[, 1:5])) 
> z1
            Date   SBI.BO HDFC.BO KTKM.BO YESB.BO
2001-01-01 11323 102944.3 64134.8  3576.4      NA
2001-01-02 11324 108812.5 64390.9  3606.2      NA
2001-01-03 11325 114101.8 65909.5  3528.2      NA
2001-01-04 11326 112180.8 65266.3  3691.2      NA
2001-01-05 11327 113365.0 69286.3  3700.3      NA
2001-01-08 11330 112180.8 70292.8  3682.0      NA
> write.table(z1)
"Date" "SBI.BO" "HDFC.BO" "KTKM.BO" "YESB.BO"
"2001-01-01" 11323 102944.3 64134.8 3576.4 NA
"2001-01-02" 11324 108812.5 64390.9 3606.2 NA
"2001-01-03" 11325 114101.8 65909.5 3528.2 NA
"2001-01-04" 11326 112180.8 65266.3 3691.2 NA
"2001-01-05" 11327 113365 69286.3 3700.3 NA
"2001-01-08" 11330 112180.8 70292.8 3682 NA
> 

Apologies for the inconvenience.

Best,
-Tir


> -----Original Message-----
> From: Peter Dalgaard [mailto:P.Dalgaard at biostat.ku.dk] 
> Sent: Thursday, June 14, 2007 6:07 PM
> To: Patnaik, Tirthankar [GWM-CIR]
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Preserving dates in Excel.
> 
> Patnaik, Tirthankar wrote:
> > Hi,
> > 	Quick question: Say I have a date variable in a data 
> frame or matrix, 
> > and I'd like to preserve the date format when using write.table.
> > However, when I export the data, I get the generic number 
> underlying 
> > the date, not the date per se, and a number such as 11323, 
> 11324, etc 
> > are not meaningful in Excel. Is there any way I can preserve the 
> > format of a date on writing into a text-file?
> >
> >   
> Er, what is exactly the problem here?
> 
> > d <- data.frame(date=as.Date("2007-6-1")+1:5, x=rnorm(5)) d
>         date             x
> 1 2007-06-02  0.7987635130
> 2 2007-06-03 -0.7381623316
> 3 2007-06-04 -1.3626708691
> 4 2007-06-05  0.0007668082
> 5 2007-06-06  0.6719088533
> > write.table(d)
> "date" "x"
> "1" 2007-06-02 0.798763513018864
> "2" 2007-06-03 -0.738162331606612
> "3" 2007-06-04 -1.36267086906438
> "4" 2007-06-05 0.000766808196322155
> "5" 2007-06-06 0.671908853312511
> > write.csv(d)
> "","date","x"
> "1",2007-06-02,0.798763513018864
> "2",2007-06-03,-0.738162331606612
> "3",2007-06-04,-1.36267086906438
> "4",2007-06-05,0.000766808196322155
> "5",2007-06-06,0.671908853312511
> 
> 
> -- 
>    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  
> (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: 
> (+45) 35327907
> 
> 
>


From Winfried.Theis at unilever.com  Thu Jun 14 14:50:08 2007
From: Winfried.Theis at unilever.com (Theis, Winfried)
Date: Thu, 14 Jun 2007 13:50:08 +0100
Subject: [R] nlsList problems: control option does not effect output and
	strange environment search
Message-ID: <9AE166DBB565F746B1F5BFA7369EF8F775FCD0@BRBSEVS20006.S2.MS.UNILEVER.COM>

Dear R-helpers,
 
I'm using R 2.5.0 under Windows and am trying to use nlsList from nlme
3.1-80 with the selfstart function for the four parametric logistic
function. My first test went well, but now I'm trying to do some more
sophisticated things and it does not work anymore. 
 
I simulate my data from a five parametric logistic function like this:

Y<-as.data.frame(apply(params,1,function(x){
Y<-x[1]+(x[2]/(1+x[3]*exp(-1*x[4]*(1:240-x[5])))^(1/x[3]))+rnorm(240,0,s
derror) 
return(Y)}))

params contains different parameters for 200 persons in 4 groups. Next I
sample for each person five observations one at the start, one at the
end and three randomly in between. Now I get the following error
messages:
testnlslist2<-nlsList(SSfpl,groupedData(Y~Time|group, datset))
Error in nls(y ~ cbind(1, 1/(1 + exp((xmid - x)/exp(lscal)))), data =
xy,  : 
        step factor 0.000488281 reduced below 'minFactor' of 0.000976562
Error in nls(formula = formula, data = data, control = control) : 
        singular gradient

For the first error it could be that this is due to the fact that this
group is simulated as a kind of placebo and therefore it may be hard to
fit. To solve this I tried to specify controls like this:
testnlslist2<-nlsList(SSfpl,groupedData(Y~Time|group,
datset),control=nls.control(minFactor=1/4096))

but it led to the same error as the first. So it looks like the control
parameter is not evaluated. Any other ideas how to get the function
running? 

The second strange thing I encountered is that nlsList does not seem to
analyse the environment from which it is called. I did try to use it
within a function in apply and I got the error that the dataset I gave
was not found, but the function grouped.data worked well within the
function. Any idea what I could have done wrong?

Regards,
Winfried Theis


From michael.watson at bbsrc.ac.uk  Thu Jun 14 14:52:40 2007
From: michael.watson at bbsrc.ac.uk (michael watson (IAH-C))
Date: Thu, 14 Jun 2007 13:52:40 +0100
Subject: [R] Difference between prcomp and cmdscale
In-Reply-To: <11118602.post@talk.nabble.com>
References: <8975119BCD0AC5419D61A9CF1A923E9504F0D557@iahce2ksrv1.iah.bbsrc.ac.uk>
	<11118602.post@talk.nabble.com>
Message-ID: <8975119BCD0AC5419D61A9CF1A923E9504F0D564@iahce2ksrv1.iah.bbsrc.ac.uk>

Hi Mark

I think Brian Ripley answered this most effectively and succinctly.  I
did actually do quite a bit of googling and searching of the R help
before posting, and whilst there is quite a lot on each topic
individually, I failed to find articles that compare and contrast PCA
and MDS.  If you know of any, of course I would be happy to read them.

Many thanks
Mick

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Mark Difford
Sent: 14 June 2007 12:49
To: r-help at stat.math.ethz.ch
Subject: Re: [R] Difference between prcomp and cmdscale


Michael,

Why should that confuse you?  Have you tried reading some of the
literature
on these methods?  There's plenty about them on the Net (Wiki's often a
goodish place to start)---and even in R, if you're prepared to look ;).

BestR,
Mark.


michael watson (IAH-C) wrote:
> 
> I'm looking for someone to explain the difference between these
> procedures.  The function prcomp() does principal components anaylsis,
> and the function cmdscale() does classical multi-dimensional scaling
> (also called principal coordinates analysis).
> 
> My confusion stems from the fact that they give very similar results:
> 
> my.d <- matrix(rnorm(50), ncol=5)
> rownames(my.d) <- paste("c", 1:10, sep="")
> # prcomp
> prc <- prcomp(my.d)
> # cmdscale
> mds <- cmdscale(dist(my.d))
> cor(prc$x[,1], mds[,1]) # produces 1 or -1
> cor(prc$x[,2], mds[,2]) # produces 1 or -1
> 
> Presumably, under the defaults for these commands in R, they carry out
> the same (or very similar) procedures?
> 
> Thanks
> Mick
> 
> The information contained in this message may be\ confiden...{{dropped}}


From sarah.goslee at gmail.com  Thu Jun 14 14:59:37 2007
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 14 Jun 2007 08:59:37 -0400
Subject: [R] Difference between prcomp and cmdscale
In-Reply-To: <8975119BCD0AC5419D61A9CF1A923E9504F0D564@iahce2ksrv1.iah.bbsrc.ac.uk>
References: <8975119BCD0AC5419D61A9CF1A923E9504F0D557@iahce2ksrv1.iah.bbsrc.ac.uk>
	<11118602.post@talk.nabble.com>
	<8975119BCD0AC5419D61A9CF1A923E9504F0D564@iahce2ksrv1.iah.bbsrc.ac.uk>
Message-ID: <efb536d50706140559w2a37e32t17ad7fb0f49c1c1c@mail.gmail.com>

On 6/14/07, michael watson (IAH-C) <michael.watson at bbsrc.ac.uk> wrote:

> ... I failed to find articles that compare and contrast PCA
> and MDS.  If you know of any, of course I would be happy to read them.

There's an excellent non-R discussion of a wide range of ordination methods
at http://ordination.okstate.edu/ (Mike Palmer's work).

If you look under "distance-based ordination" (like MDS/PCO),
you find:
"Special case: for Euclidean distance, PCoA = PCA."

and much other useful information. He also gives an extensive list of
references from the literature, if you'd like something more rigorous.
For an overview text, I'm partial to _Numerical Ecology_ by Legendre
and Legendre (1998) because of its readability, but there are many
more good texts.

Sarah
-- 
Sarah Goslee
http://www.functionaldiversity.org


From cinzia.viroli at unibo.it  Thu Jun 14 14:59:38 2007
From: cinzia.viroli at unibo.it (Cinzia Viroli)
Date: Thu, 14 Jun 2007 14:59:38 +0200
Subject: [R] building packages under windows
In-Reply-To: <Pine.LNX.4.64.0706141254500.15750@gannet.stats.ox.ac.uk>
References: <6.0.1.1.2.20070614133116.03601008@mail.unibo.it>
	<Pine.LNX.4.64.0706141254500.15750@gannet.stats.ox.ac.uk>
Message-ID: <6.0.1.1.2.20070614145327.036158e0@mail.unibo.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070614/4fa3da6b/attachment.pl 

From TobinJR at DFO-MPO.GC.CA  Thu Jun 14 15:38:41 2007
From: TobinJR at DFO-MPO.GC.CA (Tobin, Jared)
Date: Thu, 14 Jun 2007 11:08:41 -0230
Subject: [R] Using subset() in a user-defined function
Message-ID: <FBF367376AD9E64BB8531D56CA38DA6A01C7CB4B@nflwhex01.nfl.dfo-mpo.ca>

Hello,

I'm having a problem with using subset() inside a function I'm writing.
Ignoring everything else in the function, the problem can be illustrated
by (where master.frame is the data frame I'm using):


function1 <- function(arg1="", arg2="", arg3=""){

	temp.frame <- subset(master.frame, a == arg1 & b == arg2 & c ==
arg3)

}


This works fine if the user specifies all arguments, but if any one or
more of the arguments isn't specified, say arg1 for example, the subset
is empty because subset() goes looking for values of a == "" in
master.frame, and there are none.  I want it to work such that if an
argument is not specified, it is not included in what subset() goes
looking for.  So if I were to input:

function1(arg2=5, arg3=6)

then in function1, the subset command will look like

	temp.frame <- subset(master.frame, b == 5 & c == 6)


Any suggestions would be much appreciated.

Thanks,

--

jared tobin, student research assistant
dept. of fisheries and oceans
tobinjr at dfo-mpo.gc.ca


From kw.statr at gmail.com  Thu Jun 14 15:41:45 2007
From: kw.statr at gmail.com (Kevin Wright)
Date: Thu, 14 Jun 2007 08:41:45 -0500
Subject: [R] Confidence interval for coefficient of variation
Message-ID: <c968588d0706140641x3c81fe65u42ffb1de53980a7@mail.gmail.com>

This is a function I coded a few years ago to calculate a confidence
interval for a coefficient of variation.  The code is based on a paper
by Mark Vangel in The American Statistician.  I have not used the
function much, but it could be useful for comparing cv's from
different groups.

Kevin Wright


confint.cv <- function(x,alpha=.05, method="modmckay"){
  # Calculate the confidence interval of the cv of the vector x
  # Author: Kevin Wright
  # See: Vangel, Mark.  Confidence Intervals for a Normal Coefficient
  # of Variation. American Statistician, Vol 15, No1, p. 21--26.
  # x <- c(326,302,307,299,329)
  # confint.cv(x,.05,"modmckay")

  x <- na.omit(x)
  v <- length(x)-1
  mu <- mean(x)
  sigma <- sqrt(var(x))
  k <- sigma/mu
  # CV > .33 may give poor results, so warn the user
  if(k>.33) warning("Confidence interval may be very approximate.")

  method <- casefold(method) # In case we see "McKay"

  if(method=="mckay"){
    # McKay method.  See equation 15.
    t1 <- qchisq(1-alpha/2,v)/v
    t2 <- qchisq(alpha/2,v)/v
    u1 <- v*t1
    u2 <- v*t2
    lower <- k/sqrt(( u1/(v+1) -1)*k*k + u1/v)
    upper <- k/sqrt(( u2/(v+1) -1)*k*k + u2/v)
  } else if (method=="naive"){
    # Naive method.  See equation 17.
    t1 <- qchisq(1-alpha/2,v)/v
    t2 <- qchisq(alpha/2,v)/v
    lower <- k/sqrt(t1)
    upper <- k/sqrt(t2)
  } else {
    # Modified McKay method. See equation 16.
    u1 <- qchisq(1-alpha/2,v)
    u2 <- qchisq(alpha/2,v)
    lower <- k/sqrt(( (u1+2)/(v+1) -1)*k*k + u1/v)
    upper <- k/sqrt(( (u2+2)/(v+1) -1)*k*k + u2/v)
  }
  ci <- c(lower,upper)
  attr(ci,"CV") <- k
  attr(ci,"alpha") <- alpha
  return(ci)
}


From bolker at ufl.edu  Thu Jun 14 15:21:51 2007
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 14 Jun 2007 13:21:51 +0000 (UTC)
Subject: [R] besselK
References: <691542.62452.qm@web52901.mail.re2.yahoo.com>
	<64A6930D-62AB-4A07-9F95-9FC2241611F0@noc.soton.ac.uk>
Message-ID: <loom.20070614T145744-497@post.gmane.org>

Robin Hankin <r.hankin <at> noc.soton.ac.uk> writes:

> 
> Hello
> 
> AFAIK, R has no capability for evaluating Bessel functions for  
> complex arguments.
> 
> Bessel functions for complex arguments are difficult to evaluate  
> numerically.
> Some Bessel functions require cut lines or consideration of Riemann  
> surfaces.
> 
> The GSL library (for which the gsl package is an R wrapper) does
> not include such functionality although the issue has arisen
> on the GSL email list a couple of times over the last few years.
> 
> Writing R functionality for Bessel functions (and in particular
> the Airy function) is on my List of Things To Do, but
> don't hold your breath  . . .
> 
> best wishes
> 
> Robin
> 
> On 14 Jun 2007, at 10:31, ivivi mwaniki wrote:
> 
> > Assistance,
> > besselK- complex number problem
> >  Im a student  intrested in using R in my learning and research  
> > work in option pricing however i have a problem with besselK  
> > function In R.
> >  Would you assit me in computing the besselK of third kind of a  
> > complex number in R.
> >  Any code or suggestion will be highly appriceiated
> >  eg
> >  besselK(2,10)  works well.. but
> >  besselK(2,10i) doesnt work !!
> >
> >  im supprised it works in MATLAB but NOT in R.
> >  rgds
> >  ivivi mwaniki
> >  student kenya
> >
> >

   I have some code for complex Bessel functions which consists
of R wrappers for C++ code: the licensing a little obscure -- the code is
ultimately from "Computation of Special Functions", Zhang and Jin, John Wiley
and Sons, 1996.  The FORTRAN routines are available from
http://jin.ece.uiuc.edu/routines/routines.html ; Chris Bond
http://www.crbond.com/math.htm has made a C++ translation
available.  Both versions are copyrighted: Zhang and Jin
say "we give permission to the user who downloads these routines to incorporate
any of these routines into his or her programs provided that the copyright is
acknowledged".  The code seems to work for my purposes, but hasn't
been thoroughly tested.

  I can send my crude versions to anyone who would like it.


From mark_difford at yahoo.co.uk  Thu Jun 14 15:48:34 2007
From: mark_difford at yahoo.co.uk (Mark Difford)
Date: Thu, 14 Jun 2007 06:48:34 -0700 (PDT)
Subject: [R] Difference between prcomp and cmdscale
In-Reply-To: <8975119BCD0AC5419D61A9CF1A923E9504F0D564@iahce2ksrv1.iah.bbsrc.ac.uk>
References: <8975119BCD0AC5419D61A9CF1A923E9504F0D557@iahce2ksrv1.iah.bbsrc.ac.uk>
	<11118602.post@talk.nabble.com>
	<8975119BCD0AC5419D61A9CF1A923E9504F0D564@iahce2ksrv1.iah.bbsrc.ac.uk>
Message-ID: <11120608.post@talk.nabble.com>


Hi Michael,

Doubtless Professor Ripley did; but it helps to put your back into it.  Long
ago Gower (1966) drew attention to the links between PCA and classical
scaling.  It took me a few seconds to find this:

http://www.garfield.library.upenn.edu/classics1980/A1980JJ08200001.pdf

Of course, I knew about Gower.  But I knew about Gower because I had done
the _basic_ research on these methods.  And that was my point.  In a later
paper Gower argued that classical scaling extended, and was more powerful
than, PCA.

However, classical scaling operates on [a matrix of] similarities between
observations/individuals/rows, whereas PCA operates on [a matrix of]
similarities between variables/descriptors/columns.  This means that in
classical scaling the axes cannot be interpreted; often one does  a PCA to
get at these.

HTH, bestR,
Mark.


michael watson (IAH-C) wrote:
> 
> Hi Mark
> 
> I think Brian Ripley answered this most effectively and succinctly.  I
> did actually do quite a bit of googling and searching of the R help
> before posting, and whilst there is quite a lot on each topic
> individually, I failed to find articles that compare and contrast PCA
> and MDS.  If you know of any, of course I would be happy to read them.
> 
> Many thanks
> Mick
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Mark Difford
> Sent: 14 June 2007 12:49
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] Difference between prcomp and cmdscale
> 
> 
> Michael,
> 
> Why should that confuse you?  Have you tried reading some of the
> literature
> on these methods?  There's plenty about them on the Net (Wiki's often a
> goodish place to start)---and even in R, if you're prepared to look ;).
> 
> BestR,
> Mark.
> 
> 
> michael watson (IAH-C) wrote:
>> 
>> I'm looking for someone to explain the difference between these
>> procedures.  The function prcomp() does principal components anaylsis,
>> and the function cmdscale() does classical multi-dimensional scaling
>> (also called principal coordinates analysis).
>> 
>> My confusion stems from the fact that they give very similar results:
>> 
>> my.d <- matrix(rnorm(50), ncol=5)
>> rownames(my.d) <- paste("c", 1:10, sep="")
>> # prcomp
>> prc <- prcomp(my.d)
>> # cmdscale
>> mds <- cmdscale(dist(my.d))
>> cor(prc$x[,1], mds[,1]) # produces 1 or -1
>> cor(prc$x[,2], mds[,2]) # produces 1 or -1
>> 
>> Presumably, under the defaults for these commands in R, they carry out
>> the same (or very similar) procedures?
>> 
>> Thanks
>> Mick
>> 
>> The information contained in this message may be\ confiden...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/Difference-between-prcomp-and-cmdscale-tf3920408.html#a11120608
Sent from the R help mailing list archive at Nabble.com.


From murdoch at stats.uwo.ca  Thu Jun 14 15:58:25 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 14 Jun 2007 09:58:25 -0400
Subject: [R] Using subset() in a user-defined function
In-Reply-To: <FBF367376AD9E64BB8531D56CA38DA6A01C7CB4B@nflwhex01.nfl.dfo-mpo.ca>
References: <FBF367376AD9E64BB8531D56CA38DA6A01C7CB4B@nflwhex01.nfl.dfo-mpo.ca>
Message-ID: <46714981.8030109@stats.uwo.ca>

On 6/14/2007 9:38 AM, Tobin, Jared wrote:
> Hello,
> 
> I'm having a problem with using subset() inside a function I'm writing.
> Ignoring everything else in the function, the problem can be illustrated
> by (where master.frame is the data frame I'm using):
> 
> 
> function1 <- function(arg1="", arg2="", arg3=""){
> 
> 	temp.frame <- subset(master.frame, a == arg1 & b == arg2 & c ==
> arg3)
> 
> }
> 
> 
> This works fine if the user specifies all arguments, but if any one or
> more of the arguments isn't specified, say arg1 for example, the subset
> is empty because subset() goes looking for values of a == "" in
> master.frame, and there are none.  I want it to work such that if an
> argument is not specified, it is not included in what subset() goes
> looking for.  So if I were to input:
> 
> function1(arg2=5, arg3=6)
> 
> then in function1, the subset command will look like
> 
> 	temp.frame <- subset(master.frame, b == 5 & c == 6)
> 
> 
> Any suggestions would be much appreciated.

Code it like this:

subset(master.frame, (missing(arg1) | a == arg1) &
                      (missing(arg2) | b == arg2) &
                      (missing(arg3) | c == arg3))

I haven't tried this, and I forget what happens in subset() if you pass 
it a subset of the wrong length, so it might fail if all args are 
missing, but otherwise I think it should work.  It does depend on 
defaults for the args existing and not causing errors in the equality 
tests (it's not using shortcut evaluation).

Duncan Murdoch


From ligges at statistik.uni-dortmund.de  Thu Jun 14 15:59:44 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 14 Jun 2007 15:59:44 +0200
Subject: [R] problem with hist()
In-Reply-To: <34232.134.93.157.71.1181824247.squirrel@webmail.ts-cs.de>
References: <34232.134.93.157.71.1181824247.squirrel@webmail.ts-cs.de>
Message-ID: <467149D0.1030006@statistik.uni-dortmund.de>



Mario Dejung wrote:
> Hey everybody,
> I try to make a graph with two different plots.
> 
> 
> First I make a boxplot of my data. It is a collection off correlation
> values of different pictures. For example:
> 
> 0.23445 pica
> 0.34456 pica
> 0.45663 pica
> 0.98822 picb
> 0.12223 picc
> 0.34443 picc
> etc.
> 
> Ok, I make this boxplot and I get for every picture the boxes. After this
> I want to know, how many correlations per picture exist.
> So I make a new vector y <- as.numeric(data$picture)
> 
> So I get for my example something like this:
> 
> y
> [1] 1 1 1 1 1 1 1 1 1 1
> [11] 1 1 1 1 1 1 1 1 2 2
> ...
> [16881] 59 59 59 60 60 60 60 60 60 60
> 
> After this I make something like this
> 
> boxplot(cor ~ pic)
> par(new = TRUE)
> hist(y, nclass = 60)
> 
> But there is my problem. I have 60 pictures, so I get 60 different
> boxplots, and I want the hist behind the boxes. But it makes only 59
> histbars.
> 
> What can I do? I tried also
> hist(y, 1:60) # same effect
> and
> hist(y, 1:61)
> this give me 60 places, but only 59 bars. the last bar is 0.


In fact, I am pretty sure you really want to have a barplot() rather 
than a histogram. If you really want to use hist(), then perhaps hist(y, 
0:60).

Uwe Ligges



> I hope anyone can help me.
> 
> Regards Mario
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From roland.rproject at gmail.com  Thu Jun 14 16:11:35 2007
From: roland.rproject at gmail.com (Roland Rau)
Date: Thu, 14 Jun 2007 10:11:35 -0400
Subject: [R] scatterplots: (equal axes and overlay)
In-Reply-To: <5dad6e7c0706140540q1751c1fdlbb849b9136265bf7@mail.gmail.com>
References: <5dad6e7c0706140540q1751c1fdlbb849b9136265bf7@mail.gmail.com>
Message-ID: <46714C97.2020102@gmail.com>

Hi Matthias,

please see below for some code example.

Matthias von Rad wrote:
> Hi,
> I am doing lots of scatterplots for my dissertation and to make the
> comparable, I would like to have equal x- amd - y axis. Can I specify
> their scale?
> Another question adresses overlay scatterplots. Having prae and post
> measures for each case, is it possible to have them in one graph with
> symbols or colors for prae and post.

### first we create some hypothetical data

pre.x <- runif(n=100, min=0, max=10)
pre.y <- 1.5+2*pre.x+rnorm(n=length(pre.x), mean=pre.x, sd=1)

post.x <- runif(n=100, min=0, max=10)
post.y <- 20-3*post.x+rnorm(n=length(post.x), mean=post.x, sd=1)


## let's construct a plot from scratch, using type="n" to have an
## empty plotting area
plot(x=1,y=1, type="n", xlim=c(0,10), ylim=c(0,20), axes=FALSE,
      xlab="My X-Labels", ylab="My Y-Labels")
axis(side=1, at=seq(from=0, to=10, by=2.5))
axis(side=2, at=seq(from=0, to=20, by=5))
points(x=pre.x, y=pre.y, col="green", pch=19)
points(x=post.x, y=post.y, col="red", pch=19)

### and this makes it easy to find out which 'pch'-number plots which
### symbol:
plot(x=0:25, y=0:25, pch=0:25)


I hope this helps.

Best,
Roland


From CVorlow at eurobank.gr  Thu Jun 14 16:21:19 2007
From: CVorlow at eurobank.gr (Vorlow Constantinos)
Date: Thu, 14 Jun 2007 17:21:19 +0300
Subject: [R] names() after  library(RDCOMClient)  problem(?)
Message-ID: <93843C113DD8914BB1A9A63878E8918CD8A79E@EH002EXC.eurobank.efg.gr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070614/1dee6aab/attachment.pl 

From meinhard.ploner at soundinvest.net  Thu Jun 14 16:16:51 2007
From: meinhard.ploner at soundinvest.net (Meinhard Ploner)
Date: Thu, 14 Jun 2007 16:16:51 +0200
Subject: [R] system("R CMD BATCH ...") on UNIX-alikes
Message-ID: <0C0D738E-B129-45B7-98A4-C01587827F82@soundinvest.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070614/480fc1ca/attachment.pl 

From Joseph.F.Lucke at uth.tmc.edu  Thu Jun 14 16:32:57 2007
From: Joseph.F.Lucke at uth.tmc.edu (Lucke, Joseph F)
Date: Thu, 14 Jun 2007 09:32:57 -0500
Subject: [R] Problems with na.rm=T
Message-ID: <4677FCB5A35A0441A0E0C99D56B23D910777FEBA@UTHEVS2.mail.uthouston.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070614/edfcbf60/attachment.pl 

From TobinJR at DFO-MPO.GC.CA  Thu Jun 14 16:57:37 2007
From: TobinJR at DFO-MPO.GC.CA (Tobin, Jared)
Date: Thu, 14 Jun 2007 12:27:37 -0230
Subject: [R] Using subset() in a user-defined function
In-Reply-To: <46714981.8030109@stats.uwo.ca>
References: <FBF367376AD9E64BB8531D56CA38DA6A01C7CB4B@nflwhex01.nfl.dfo-mpo.ca>
	<46714981.8030109@stats.uwo.ca>
Message-ID: <FBF367376AD9E64BB8531D56CA38DA6A01C7CB4C@nflwhex01.nfl.dfo-mpo.ca>

Thanks for the quick response, Duncan.

The given code doesn't seem to work, and possibly due to this reason I
found in the online help for missing() (if I understand it correctly):

"Currently missing() can only be used in the immediate body of the
function that defines the argument, not in the body of a nested function
or a local call. This may change in the future."

So as I understand it, missing() cannot refer to the arguments of
function1 if it is used in an argument of subset()?  It seems to remain
a promising function for this situation regardless, but I'm not sure how
I could implement it into the subset() arguments offhand.

--

jared tobin, student research assistant
dept. of fisheries and oceans
tobinjr at dfo-mpo.gc.ca

-----Original Message-----
From: Duncan Murdoch [mailto:murdoch at stats.uwo.ca] 
Sent: Thursday, June 14, 2007 11:28 AM
To: Tobin, Jared
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Using subset() in a user-defined function

On 6/14/2007 9:38 AM, Tobin, Jared wrote:
> Hello,
> 
> I'm having a problem with using subset() inside a function I'm
writing.
> Ignoring everything else in the function, the problem can be 
> illustrated by (where master.frame is the data frame I'm using):
> 
> 
> function1 <- function(arg1="", arg2="", arg3=""){
> 
> 	temp.frame <- subset(master.frame, a == arg1 & b == arg2 & c ==
> arg3)
> 
> }
> 
> 
> This works fine if the user specifies all arguments, but if any one or

> more of the arguments isn't specified, say arg1 for example, the 
> subset is empty because subset() goes looking for values of a == "" in

> master.frame, and there are none.  I want it to work such that if an 
> argument is not specified, it is not included in what subset() goes 
> looking for.  So if I were to input:
> 
> function1(arg2=5, arg3=6)
> 
> then in function1, the subset command will look like
> 
> 	temp.frame <- subset(master.frame, b == 5 & c == 6)
> 
> 
> Any suggestions would be much appreciated.

Code it like this:

subset(master.frame, (missing(arg1) | a == arg1) &
                      (missing(arg2) | b == arg2) &
                      (missing(arg3) | c == arg3))

I haven't tried this, and I forget what happens in subset() if you pass
it a subset of the wrong length, so it might fail if all args are
missing, but otherwise I think it should work.  It does depend on
defaults for the args existing and not causing errors in the equality
tests (it's not using shortcut evaluation).

Duncan Murdoch


From murdoch at stats.uwo.ca  Thu Jun 14 17:01:04 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 14 Jun 2007 11:01:04 -0400
Subject: [R] Problems with na.rm=T
In-Reply-To: <4677FCB5A35A0441A0E0C99D56B23D910777FEBA@UTHEVS2.mail.uthouston.edu>
References: <4677FCB5A35A0441A0E0C99D56B23D910777FEBA@UTHEVS2.mail.uthouston.edu>
Message-ID: <46715830.2060506@stats.uwo.ca>

On 6/14/2007 10:32 AM, Lucke, Joseph F wrote:
> Suddenly (e.g. yesterday) all my functions that have "na.rm=" as a
> parameter (e.g., mean(), sd(), range(), etc.) have been reporting
> warnings with "na.rm=T". The message is "Warning message: the condition
> has length > 1 and only the first element will be used in: if (na.rm) x
> <- x[!is.na(x)] ".   This has never happened before.  I don't recall
> having done anything that might generate this message.  How do I fix
> this?

I imagine you have created a variable T of length greater than 1.  Use 
TRUE (which is a reserved word, so you can't create such a variable). 
Don't keep big workspaces full of stuff you don't know about, create a 
new empty one in each session.

Duncan Murdoch


From Gary.Nelson at state.ma.us  Thu Jun 14 17:02:13 2007
From: Gary.Nelson at state.ma.us (Nelson, Gary (FWE))
Date: Thu, 14 Jun 2007 11:02:13 -0400
Subject: [R] R programming question
Message-ID: <3CCC4D52A4CF6F4DA92F3F322D696D5E4EBBE5@ES-MSG-002.es.govt.state.ma.us>

Dear All.,

I've created R-code for which a user will be asked to choose between 2
analyses.  I've written one function for each type of analysis.  Within
each function, the users is prompted to enter information.  An example
is:
 
cat("Enter value for lower Linf :\n")
     L1<-scan(n=1)
     cat("Enter value for upper Linf :\n")
     L2<-scan(n=1)
     cat("Enter Linf interval :\n")
     int_L<-scan(n=1)
     cat("Enter value for lower K :\n")
     K1<-scan(n=1)
     cat("Enter value for upper K :\n")
     K2<-scan(n=1)
     cat("Enter K interval :\n")
     int_K<-scan(n=1)

I thought I could evaluate and run the appropriate function at the end
of the program by:

if(event==1) explore() else evaluate()


If I run the whole program and either explore() or evaluate() is run,
the first four prompted entries are skipped over.  The console output
for event==1 is TRUE looks like:

> if(event==1) explore() else evaluate()
Enter value for lower Linf :
1: 
Read 0 items
Enter value for upper Linf :
1: 
Read 0 items
Enter Linf interval :
1:    
Read 0 items
Enter value for lower K :
1:     
Read 0 items
Enter value for upper K :
1:

I then tried another way.  I created    

runcase<-ifelse(event==1,"explore","evaluate")

At the bottom of the program I used:

eval(call(x=runcase))

But I still get the same problem.

Any suggestions?
 

Thanks for your help

Gary A. Nelson, Ph.D
Massachusetts Division of Marine Fisheries
30 Emerson Avenue
Gloucester, MA 01930
Phone: (978) 282-0308 x114
Fax: (617) 727-3337
Email: Gary.Nelson at state.ma.us


From helprhelp at gmail.com  Thu Jun 14 17:02:43 2007
From: helprhelp at gmail.com (Weiwei Shi)
Date: Thu, 14 Jun 2007 11:02:43 -0400
Subject: [R] simulate null hypothesis
Message-ID: <cdf817830706140802p1ba92499jb571c5109465d2c6@mail.gmail.com>

Hi, there:

This is a bit off-topic but I try to do it in R so I put it here:

I have 31 samples from a population of genes, and each sample contains
a pair of gene lists, with different lengths and the intersection
between the two lists also varies. I want to test my hypothesis by
creating a null hypothesis for this population. Since the distribution
for the length and the distribution for the intersection size do not
follow any known distribution, I think I need to use sample with
replacement to simulate those "parameters". And use the parameters to
permutate genes; but I am not very sure if it is alll right.

BTW, is there any general package or I just need "sample()" to do
that? (just tried to make my question on-topic:)

thanks,

-- 
Weiwei Shi, Ph.D
Research Scientist
GeneGO, Inc.

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III


From P.Dalgaard at biostat.ku.dk  Thu Jun 14 17:03:34 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 14 Jun 2007 17:03:34 +0200
Subject: [R] Problems with na.rm=T
In-Reply-To: <4677FCB5A35A0441A0E0C99D56B23D910777FEBA@UTHEVS2.mail.uthouston.edu>
References: <4677FCB5A35A0441A0E0C99D56B23D910777FEBA@UTHEVS2.mail.uthouston.edu>
Message-ID: <467158C6.60307@biostat.ku.dk>

Lucke, Joseph F wrote:
> Suddenly (e.g. yesterday) all my functions that have "na.rm=" as a
> parameter (e.g., mean(), sd(), range(), etc.) have been reporting
> warnings with "na.rm=T". The message is "Warning message: the condition
> has length > 1 and only the first element will be used in: if (na.rm) x
> <- x[!is.na(x)] ".   This has never happened before.  I don't recall
> having done anything that might generate this message.  How do I fix
> this?
>   

Rename the object that you suddenly called "T"...

(And notice that some people will advise you to use na.rm=TRUE to avoid
this)

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From Joseph.F.Lucke at uth.tmc.edu  Thu Jun 14 17:03:43 2007
From: Joseph.F.Lucke at uth.tmc.edu (Lucke, Joseph F)
Date: Thu, 14 Jun 2007 10:03:43 -0500
Subject: [R] Problems with na.rm=T
In-Reply-To: <46715830.2060506@stats.uwo.ca>
References: <4677FCB5A35A0441A0E0C99D56B23D910777FEBA@UTHEVS2.mail.uthouston.edu>
	<46715830.2060506@stats.uwo.ca>
Message-ID: <4677FCB5A35A0441A0E0C99D56B23D910777FEBB@UTHEVS2.mail.uthouston.edu>

Brilliant!  Yesterday, I created a table called T.  Dumb. Removing it
solves the problem.  Thanks. 

-----Original Message-----
From: Duncan Murdoch [mailto:murdoch at stats.uwo.ca] 
Sent: Thursday, June 14, 2007 10:01 AM
To: Lucke, Joseph F
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Problems with na.rm=T

On 6/14/2007 10:32 AM, Lucke, Joseph F wrote:
> Suddenly (e.g. yesterday) all my functions that have "na.rm=" as a 
> parameter (e.g., mean(), sd(), range(), etc.) have been reporting 
> warnings with "na.rm=T". The message is "Warning message: the 
> condition has length > 1 and only the first element will be used in:
if (na.rm) x
> <- x[!is.na(x)] ".   This has never happened before.  I don't recall
> having done anything that might generate this message.  How do I fix 
> this?

I imagine you have created a variable T of length greater than 1.  Use
TRUE (which is a reserved word, so you can't create such a variable). 
Don't keep big workspaces full of stuff you don't know about, create a
new empty one in each session.

Duncan Murdoch


From Greg.Snow at intermountainmail.org  Thu Jun 14 17:03:26 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Thu, 14 Jun 2007 09:03:26 -0600
Subject: [R] [OT]Web-Based Data Brushing
Message-ID: <0cc501c7ae95$23533b92$2e80320a@CO.IHC.COM>

There is the TkBrush function in the TeachingDemos package for R.  It is not web based.

-----Original Message-----
From: "Roy Mendelssohn" <Roy.Mendelssohn at noaa.gov>
To: "r-help at stat.math.ethz.ch" <r-help at stat.math.ethz.ch>
Sent: 6/12/07 10:26 AM
Subject: [R] [OT]Web-Based Data Brushing

I apologize for the off-topic post, but my Google search did not turn  
up much and I thought people on this list my have knowledge of this.   
I am looking for examples of  data brushing  (i.e. dynmaic linked  
plots) either on a web site, or in a web-based application, such as  
an AJAX app.  Even better if there is a way to do this in R.

Thanks for any help.

-Roy M.

**********************
"The contents of this message do not reflect any position of the U.S.  
Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division	
Southwest Fisheries Science Center
1352 Lighthouse Avenue
Pacific Grove, CA 93950-2097

e-mail: Roy.Mendelssohn at noaa.gov (Note new e-mail address)
voice: (831)-648-9029
fax: (831)-648-8440
www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ssj1364 at gmail.com  Thu Jun 14 17:08:21 2007
From: ssj1364 at gmail.com (sj)
Date: Thu, 14 Jun 2007 09:08:21 -0600
Subject: [R] ARIMA with more than one seasonality period
In-Reply-To: <bfcc0ca60706140100n19c5df6fi9ff4a939eeb12673@mail.gmail.com>
References: <bfcc0ca60706140100n19c5df6fi9ff4a939eeb12673@mail.gmail.com>
Message-ID: <1c6126db0706140808q5294ab4cj589baa37b17371c4@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070614/f064183f/attachment.pl 

From b.rowlingson at lancaster.ac.uk  Thu Jun 14 17:13:19 2007
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 14 Jun 2007 16:13:19 +0100
Subject: [R] Problems with na.rm=T
In-Reply-To: <4677FCB5A35A0441A0E0C99D56B23D910777FEBA@UTHEVS2.mail.uthouston.edu>
References: <4677FCB5A35A0441A0E0C99D56B23D910777FEBA@UTHEVS2.mail.uthouston.edu>
Message-ID: <46715B0F.6000808@lancaster.ac.uk>

Lucke, Joseph F wrote:
> Suddenly (e.g. yesterday) all my functions that have "na.rm=" as a
> parameter (e.g., mean(), sd(), range(), etc.) have been reporting
> warnings with "na.rm=T". The message is "Warning message: the condition
> has length > 1 and only the first element will be used in: if (na.rm) x
> <- x[!is.na(x)] ".   This has never happened before.  I don't recall
> having done anything that might generate this message.  How do I fix

  Do you have something called 'T':

 > T=c(1,2,3,4)
 > mean(x,na.rm=T)
[1] 2
Warning message:
the condition has length > 1 and only the first element will be used in: 
if (na.rm) x <- x[!is.na(x)]

  You should always use 'TRUE' for true and 'FALSE' for false. R makes 
it harder to shoot yourself in the foot that way:

 > TRUE=c(1,2,3)
Error in TRUE = c(1, 2, 3) : invalid (do_set) left-hand side to assignment

help(TRUE) helps:

Details:

      'TRUE' and 'FALSE' are part of the R language, where 'T' and 'F'
      are global variables set to these. All four are 'logical(1)'
      vectors.

Barry


From TobinJR at DFO-MPO.GC.CA  Thu Jun 14 17:15:08 2007
From: TobinJR at DFO-MPO.GC.CA (Tobin, Jared)
Date: Thu, 14 Jun 2007 12:45:08 -0230
Subject: [R] Using subset() in a user-defined function
In-Reply-To: <FBF367376AD9E64BB8531D56CA38DA6A01C7CB4C@nflwhex01.nfl.dfo-mpo.ca>
References: <FBF367376AD9E64BB8531D56CA38DA6A01C7CB4B@nflwhex01.nfl.dfo-mpo.ca>
	<46714981.8030109@stats.uwo.ca>
	<FBF367376AD9E64BB8531D56CA38DA6A01C7CB4C@nflwhex01.nfl.dfo-mpo.ca>
Message-ID: <FBF367376AD9E64BB8531D56CA38DA6A01C7CB4D@nflwhex01.nfl.dfo-mpo.ca>

I should mention the idea I worked on yesterday was cat()ing together
the appropriate condition strings and then ideally printing that entire
concatenated string into the subset argument.  However, as far as I
know, cat() only prints directly on the console and cannot be used to
substitute input text into a function, so I scrapped that idea.

Just figured I'd mention that in case there does happen to be a way to
do such a thing, and someone knows of a way offhand.

--

jared tobin, student research assistant
dept. of fisheries and oceans
tobinjr at dfo-mpo.gc.ca

-----Original Message-----
From: Tobin, Jared 
Sent: Thursday, June 14, 2007 12:28 PM
To: 'Duncan Murdoch'
Cc: r-help at stat.math.ethz.ch
Subject: RE: [R] Using subset() in a user-defined function

Thanks for the quick response, Duncan.

The given code doesn't seem to work, and possibly due to this reason I
found in the online help for missing() (if I understand it correctly):

"Currently missing() can only be used in the immediate body of the
function that defines the argument, not in the body of a nested function
or a local call. This may change in the future."

So as I understand it, missing() cannot refer to the arguments of
function1 if it is used in an argument of subset()?  It seems to remain
a promising function for this situation regardless, but I'm not sure how
I could implement it into the subset() arguments offhand.

--

jared tobin, student research assistant
dept. of fisheries and oceans
tobinjr at dfo-mpo.gc.ca

-----Original Message-----
From: Duncan Murdoch [mailto:murdoch at stats.uwo.ca]
Sent: Thursday, June 14, 2007 11:28 AM
To: Tobin, Jared
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Using subset() in a user-defined function

On 6/14/2007 9:38 AM, Tobin, Jared wrote:
> Hello,
> 
> I'm having a problem with using subset() inside a function I'm
writing.
> Ignoring everything else in the function, the problem can be 
> illustrated by (where master.frame is the data frame I'm using):
> 
> 
> function1 <- function(arg1="", arg2="", arg3=""){
> 
> 	temp.frame <- subset(master.frame, a == arg1 & b == arg2 & c ==
> arg3)
> 
> }
> 
> 
> This works fine if the user specifies all arguments, but if any one or

> more of the arguments isn't specified, say arg1 for example, the 
> subset is empty because subset() goes looking for values of a == "" in

> master.frame, and there are none.  I want it to work such that if an 
> argument is not specified, it is not included in what subset() goes 
> looking for.  So if I were to input:
> 
> function1(arg2=5, arg3=6)
> 
> then in function1, the subset command will look like
> 
> 	temp.frame <- subset(master.frame, b == 5 & c == 6)
> 
> 
> Any suggestions would be much appreciated.

Code it like this:

subset(master.frame, (missing(arg1) | a == arg1) &
                      (missing(arg2) | b == arg2) &
                      (missing(arg3) | c == arg3))

I haven't tried this, and I forget what happens in subset() if you pass
it a subset of the wrong length, so it might fail if all args are
missing, but otherwise I think it should work.  It does depend on
defaults for the args existing and not causing errors in the equality
tests (it's not using shortcut evaluation).

Duncan Murdoch


From murdoch at stats.uwo.ca  Thu Jun 14 17:18:23 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 14 Jun 2007 11:18:23 -0400
Subject: [R] Using subset() in a user-defined function
In-Reply-To: <FBF367376AD9E64BB8531D56CA38DA6A01C7CB4C@nflwhex01.nfl.dfo-mpo.ca>
References: <FBF367376AD9E64BB8531D56CA38DA6A01C7CB4B@nflwhex01.nfl.dfo-mpo.ca>	<46714981.8030109@stats.uwo.ca>
	<FBF367376AD9E64BB8531D56CA38DA6A01C7CB4C@nflwhex01.nfl.dfo-mpo.ca>
Message-ID: <46715C3F.5060906@stats.uwo.ca>

On 6/14/2007 10:57 AM, Tobin, Jared wrote:
> Thanks for the quick response, Duncan.
> 
> The given code doesn't seem to work, and possibly due to this reason I
> found in the online help for missing() (if I understand it correctly):
> 
> "Currently missing() can only be used in the immediate body of the
> function that defines the argument, not in the body of a nested function
> or a local call. This may change in the future."
> 
> So as I understand it, missing() cannot refer to the arguments of
> function1 if it is used in an argument of subset()?  It seems to remain
> a promising function for this situation regardless, but I'm not sure how
> I could implement it into the subset() arguments offhand.

Right, I had forgotten that subset uses nonstandard evaluation.  You 
could evaluate add some variables to hold it, e.g.

mysubset <- function(arg1="", arg2="", arg3="") {
   miss1 <- missing(arg1)
   miss2 <- missing(arg2)
   miss3 <- missing(arg3)

   subset(master.frame, (miss1 | a == arg1) &
                      (miss2 | b == arg2) &
                      (miss3 | c == arg3))
}

This time I did test it as I should have last time, so I can tell you 
that if all args are missing you'll get the full master.frame.

Duncan Murdoch
> 
> --
> 
> jared tobin, student research assistant
> dept. of fisheries and oceans
> tobinjr at dfo-mpo.gc.ca
> 
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch at stats.uwo.ca] 
> Sent: Thursday, June 14, 2007 11:28 AM
> To: Tobin, Jared
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Using subset() in a user-defined function
> 
> On 6/14/2007 9:38 AM, Tobin, Jared wrote:
>> Hello,
>> 
>> I'm having a problem with using subset() inside a function I'm
> writing.
>> Ignoring everything else in the function, the problem can be 
>> illustrated by (where master.frame is the data frame I'm using):
>> 
>> 
>> function1 <- function(arg1="", arg2="", arg3=""){
>> 
>> 	temp.frame <- subset(master.frame, a == arg1 & b == arg2 & c ==
>> arg3)
>> 
>> }
>> 
>> 
>> This works fine if the user specifies all arguments, but if any one or
> 
>> more of the arguments isn't specified, say arg1 for example, the 
>> subset is empty because subset() goes looking for values of a == "" in
> 
>> master.frame, and there are none.  I want it to work such that if an 
>> argument is not specified, it is not included in what subset() goes 
>> looking for.  So if I were to input:
>> 
>> function1(arg2=5, arg3=6)
>> 
>> then in function1, the subset command will look like
>> 
>> 	temp.frame <- subset(master.frame, b == 5 & c == 6)
>> 
>> 
>> Any suggestions would be much appreciated.
> 
> Code it like this:
> 
> subset(master.frame, (missing(arg1) | a == arg1) &
>                       (missing(arg2) | b == arg2) &
>                       (missing(arg3) | c == arg3))
> 
> I haven't tried this, and I forget what happens in subset() if you pass
> it a subset of the wrong length, so it might fail if all args are
> missing, but otherwise I think it should work.  It does depend on
> defaults for the args existing and not causing errors in the equality
> tests (it's not using shortcut evaluation).
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From yn19832 at msn.com  Thu Jun 14 17:54:11 2007
From: yn19832 at msn.com (livia)
Date: Thu, 14 Jun 2007 08:54:11 -0700 (PDT)
Subject: [R] Goodness of fit- Pareto distribution
Message-ID: <11123100.post@talk.nabble.com>


Hello, I have fitted a Pareto Distribution for some data,  I would appreciate
if anyone can tell me how to evaluate the goodness of fit for the
distribution. What I do now is rather subjective. I just compare the
emprcical density distribution and the fitted density distribution.


-- 
View this message in context: http://www.nabble.com/Goodness-of-fit--Pareto-distribution-tf3922663.html#a11123100
Sent from the R help mailing list archive at Nabble.com.


From Greg.Snow at intermountainmail.org  Thu Jun 14 18:23:45 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Thu, 14 Jun 2007 10:23:45 -0600
Subject: [R] ievent.wait
In-Reply-To: <11105384.post@talk.nabble.com>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBA21DCD@LP-EXCHVS07.CO.IHC.COM>

I don't know iPlot well enough to tell about that.  I was not sure if
you needed to use iPlot, or just wanted to connect the points and
thought that iPlot might be an answer.  I suggested locator with
type='l' as a possibility if traditional graphics would work for you.

If you have other reasons that require you to use iPlot, then someone
with more knowledge of iPlot will need to help you.

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of ryestone
> Sent: Wednesday, June 13, 2007 12:09 PM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] ievent.wait
> 
> 
> With locator( ) does it only work in a regular R plot or can 
> I use it with iPlot?
> I am having difficulty getting it to be used with Iplots, it 
> just calls up a new screen when the function is called.
> 
> Stone.
> 
> 
> Sundar Dorai-Raj wrote:
> > 
> > Hi, Greg,
> > 
> > type = 'b' won't work according to ?locator. Try type = 'o'.
> > 
> > HTH,x
> > 
> > --sundar
> > 
> > Greg Snow said the following on 6/13/2007 7:27 AM:
> >> Does
> >> 
> >> locator(type='l')
> >> 
> >> (or type  ='b')
> >> 
> >> Work for you?
> >> 
> >> -----Original Message-----
> >> From: "ryestone" <ryestone at uvic.ca>
> >> To: "r-help at stat.math.ethz.ch" <r-help at stat.math.ethz.ch>
> >> Sent: 6/8/07 10:19 AM
> >> Subject: [R] ievent.wait
> >> 
> >> 
> >> I am working on a plot and would be like to click on a few 
> points and 
> >> then have a line connect them. Could anyone help me with this or 
> >> advise me in a direction that would suit this. I know I would be 
> >> using ievent.wait in iplot but not sure about this.
> >> 
> >> thank you.
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> > 
> > 
> 
> --
> View this message in context: 
> http://www.nabble.com/ievent.wait-tf3891095.html#a11105384
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Greg.Snow at intermountainmail.org  Thu Jun 14 18:32:50 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Thu, 14 Jun 2007 10:32:50 -0600
Subject: [R] R vs. Splus in Pharma/Devices Industry
In-Reply-To: <OF5AF3574B.910347F3-ON882572F9.0079373A-882572F9.00795585@irvine.edwards.com>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBA21DD7@LP-EXCHVS07.CO.IHC.COM>

But sweave is expanding.  There is a driver for HTML sweaving in the
R2HTML package and the odfWeave package allows you to sweave with open
office docs (which can be converted to/from MS word).  I personally like
using LaTeX and the original sweave, but I work with people who want
everything in MS word or similar, so for them I will create a template
file in open office, odfWeave that, convert to MS word and send that to
them.

I think the offset is more that S-PLUS 8 is supposed to implement many
of the things that R does now (I don't know which, I'm waiting for my
copy of 8), so soon it may be possible to sweave in both.

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Cody_Hamilton at edwards.com
> Sent: Wednesday, June 13, 2007 4:07 PM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] R vs. Splus in Pharma/Devices Industry
> 
> 
> I should have also noted that Sweave is available for use 
> with R.  This is offset, however, by the fact that I will 
> probably never be able to convince anyone to use Latex.  This 
> is a pity as I often find myself admiring reports done in 
> Latex as opposed to the ones I have worked on in MS Word.
> 
> Cody Hamilton, PhD
> Edwards Lifesciences
> 
> As always, I am speaking for myself and not necessarily for 
> Edwards Lifesciences.


From Zava.Aydemir at morganstanley.com  Thu Jun 14 18:16:03 2007
From: Zava.Aydemir at morganstanley.com (Aydemir, Zava (FID))
Date: Thu, 14 Jun 2007 12:16:03 -0400
Subject: [R] connecting to DB2 database
Message-ID: <755261CA22782948B1C42ACDC83912A10425DC04@NYWEXMB27.msad.ms.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070614/d3e9439c/attachment.pl 

From duncan at wald.ucdavis.edu  Thu Jun 14 18:57:17 2007
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Thu, 14 Jun 2007 09:57:17 -0700
Subject: [R] names() after  library(RDCOMClient)  problem(?)
In-Reply-To: <93843C113DD8914BB1A9A63878E8918CD8A79E@EH002EXC.eurobank.efg.gr>
References: <93843C113DD8914BB1A9A63878E8918CD8A79E@EH002EXC.eurobank.efg.gr>
Message-ID: <4671736D.2000400@wald.ucdavis.edu>


Hi Costas.


  On my Windows setup, I don't get this error message.
What version of RDCOMClient are you using - i.e.
the output of
   packageDescription("RDCOMClient")

and also what else is loaded into the R session, i.e.

   sessionInfo()

  D.


Vorlow Constantinos wrote:
> Hello,
> 
> Try example(names) in R 2.5.0 after  library(RDCOMClient) and you get
> 
>     > example(names)
> 
>     names> # print the names attribute of the islands data set
>     names> names(islands)
>     Error in names(islands) : no applicable method for "names"
>     > 
> 
> 
> Is this normal? Any way round it???
> 
> Best regards,
> 
> Costas
> 
>  
> ----------------------------------
> Costas Vorlow
> Research Economist
> Eurobank EFG
> Division of Research & Forecasting
> 
> -------------------------------------------------------
> ( tel: +30-210-3337273 (ext 17273)
> 7   fax: +30-210-3337687
> 
> 
> 
> 
> P Think before you print.
> 
> Disclaimer:
> This e-mail is confidential. If you are not the intended recipient, you should not copy it, re-transmit it, use it or disclose its contents, but should return it to the sender immediately and delete the copy from your system.
> EFG Eurobank Ergasias S.A. is not responsible for, nor endorses, any opinion, recommendation, conclusion, solicitation, offer or agreement or any information contained in this communication.
> EFG Eurobank Ergasias S.A. cannot accept any responsibility for the accuracy or completeness of this message as it has been transmitted over a public network. If you suspect that the message may have been intercepted or amended, please call the sender.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From cberry at tajo.ucsd.edu  Thu Jun 14 19:03:39 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Thu, 14 Jun 2007 10:03:39 -0700
Subject: [R] R programming question
In-Reply-To: <3CCC4D52A4CF6F4DA92F3F322D696D5E4EBBE5@ES-MSG-002.es.govt.state.ma.us>
References: <3CCC4D52A4CF6F4DA92F3F322D696D5E4EBBE5@ES-MSG-002.es.govt.state.ma.us>
Message-ID: <Pine.LNX.4.64.0706140952060.32252@tajo.ucsd.edu>


Gary,

You are asked to

 	PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
 	and provide commented, minimal, self-contained, reproducible code.

when posting.

You have not provided such code, and until you do I doubt we can help.

When I wrap your lines in a dummy function:

foo <- function(){
 	cat("Enter value for lower Linf :\n")
 	L1<-scan(n=1)
 	cat("Enter value for upper Linf :\n")
 	L2<-scan(n=1)
 	cat("Enter Linf interval :\n")
 	int_L<-scan(n=1)
 	cat("Enter value for lower K :\n")
 	K1<-scan(n=1)
 	cat("Enter value for upper K :\n")
 	K2<-scan(n=1)
 	cat("Enter K interval :\n")
 	int_K<-scan(n=1)
 	list(L1,L2,int_L,K1,K2,int_K)
       }

and run it as you claim

 	event <- 1

  	if (event == 1 ) foo() else bar()

it prompts for all input and prints the expected result.

> sessionInfo()
R version 2.5.0 (2007-04-23)
i386-pc-mingw32

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
States.1252;LC_MONETARY=English_United 
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods" 
"base"
>


Chuck

On Thu, 14 Jun 2007, Nelson, Gary (FWE) wrote:

> Dear All.,
>
> I've created R-code for which a user will be asked to choose between 2
> analyses.  I've written one function for each type of analysis.  Within
> each function, the users is prompted to enter information.  An example
> is:
>
> cat("Enter value for lower Linf :\n")
>     L1<-scan(n=1)
>     cat("Enter value for upper Linf :\n")
>     L2<-scan(n=1)
>     cat("Enter Linf interval :\n")
>     int_L<-scan(n=1)
>     cat("Enter value for lower K :\n")
>     K1<-scan(n=1)
>     cat("Enter value for upper K :\n")
>     K2<-scan(n=1)
>     cat("Enter K interval :\n")
>     int_K<-scan(n=1)
>
> I thought I could evaluate and run the appropriate function at the end
> of the program by:
>
> if(event==1) explore() else evaluate()
>
>
> If I run the whole program and either explore() or evaluate() is run,
> the first four prompted entries are skipped over.  The console output
> for event==1 is TRUE looks like:
>
>> if(event==1) explore() else evaluate()
> Enter value for lower Linf :
> 1:
> Read 0 items
> Enter value for upper Linf :
> 1:
> Read 0 items
> Enter Linf interval :
> 1:
> Read 0 items
> Enter value for lower K :
> 1:
> Read 0 items
> Enter value for upper K :
> 1:
>
> I then tried another way.  I created
>
> runcase<-ifelse(event==1,"explore","evaluate")
>
> At the bottom of the program I used:
>
> eval(call(x=runcase))
>
> But I still get the same problem.
>
> Any suggestions?
>
>
> Thanks for your help
>
> Gary A. Nelson, Ph.D
> Massachusetts Division of Marine Fisheries
> 30 Emerson Avenue
> Gloucester, MA 01930
> Phone: (978) 282-0308 x114
> Fax: (617) 727-3337
> Email: Gary.Nelson at state.ma.us
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	            UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901


From ripley at stats.ox.ac.uk  Thu Jun 14 19:09:00 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 14 Jun 2007 18:09:00 +0100 (BST)
Subject: [R] connecting to DB2 database
In-Reply-To: <755261CA22782948B1C42ACDC83912A10425DC04@NYWEXMB27.msad.ms.com>
References: <755261CA22782948B1C42ACDC83912A10425DC04@NYWEXMB27.msad.ms.com>
Message-ID: <Pine.LNX.4.64.0706141803390.31733@gannet.stats.ox.ac.uk>

On Thu, 14 Jun 2007, Aydemir, Zava (FID) wrote:

> i am trying to connect to a DB2 server using the DBI library.

The DBI *package* does not allow you to connect to anything by itself. 
For that you need a driver package, currently available for MySQL, ORACLE 
and SQLite (only, AFAIK).

There are ODBC drivers for DB2 (on several platforms) so perhaps 
you could use RODBC: perhaps also RJDBC.


> getData <- function()
>
> {
>
>    driver <- dbDriver("DB2")
>
>    conn <- dbConnect(driver,"server","uname","pword")
>
>    data <- dbSendquery(conn, "select etc.")
>
> }
>
>
>
> When I run the function, i get the error
>
>
>
>> data <-  getData()
> Error in do.call(as.character(drvName), list(...)) :
>        could not find function "DB2"
>
>
>
>
> Can anyone help me here?
>
> Thank you
>
> Zava
> --------------------------------------------------------
>
> This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tirthankar.patnaik at citi.com  Thu Jun 14 14:14:36 2007
From: tirthankar.patnaik at citi.com (Patnaik, Tirthankar )
Date: Thu, 14 Jun 2007 17:44:36 +0530
Subject: [R] Confusion with sapply
Message-ID: <6E2AF71DA2E3F241A66122F3F90F32140DF5E9@exinmb04-bkp.apac.nsroot.net>

Thanks Gabor, this is cool!

Best,
-Tir 

> -----Original Message-----
> From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com] 
> Sent: Wednesday, June 13, 2007 6:53 PM
> To: Patnaik, Tirthankar [GWM-CIR]
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Confusion with sapply
> 
> Try this. It takes a Date class date and in the first line 
> month.day.year converts unclass(x) to chron.  In the last 
> line of the function we convert back to Date class.  Its 
> already vectorized so sapply is unneeded:
> 
> library(chron)
> f <- function(x) with(month.day.year(unclass(x)), {
> 	month <- ifelse(month == 6 | month == 9, 3, month)
> 	year <- ifelse(month == 12, year + 1, year)
> 	as.Date(paste(year, month, day, sep = "-"))
> })
> 
> Running the last line gives:
> 
> > # test
> > f(seq(Sys.Date(), length = 12, by = "month"))
>  [1] "2007-03-13" "2007-07-13" "2007-08-13" "2007-03-13" "2007-10-13"
>  [6] "2007-11-13" "2008-12-13" "2008-01-13" "2008-02-13" "2008-03-13"
> [11] "2008-04-13" "2008-05-13"
> 
> 
> On 6/13/07, Patnaik, Tirthankar <tirthankar.patnaik at citi.com> wrote:
> > Hi,
> >  I have some confusion in applying a function over a column.
> >
> > Here's my function. I just need to shift non-March 
> month-ends to March 
> > month-ends. Initially I tried seq.dates, but one cannot give a 
> > negative increment (decrement) here.
> >
> > 
> return(as.Date(seq.dates(format(xdate,"%m/%d/%Y"),by="months",len=4)[4
> > ])
> > )
> >
> > Hence this simple function:
> >
> > > mydate <- as.Date("2006-01-01")
> > >
> > > # Function to shift non-March company-reporting dates to March.
> > > Set2March <- function(xdate){
> > + # Combines non-March months into March months:
> > + # Dec2006 -> Mar2007
> > + # Mar2006 -> Mar2006
> > + # Jun2006 -> Mar2006
> > + # Sep2006 -> Mar2006
> > + # VERY Specific code.
> > +     Month <- format(xdate,"%m")
> > +     wDate <- month.day.year(julian(xdate))
> > +     if (Month=="12"){
> > +         wDate$year <- wDate$year + 1
> > +         wDate$month <- 3
> > +     }else
> > +     if (Month=="06"){
> > +         wDate$month <- 3
> > +     }else
> > +     if (Month=="09"){
> > +         wDate$month <- 3
> > +         wDate$day <- wDate$day + 1
> > +     }else warning ("No Changes made to the month, since 
> month is not
> > one of (6,9,12)")
> > +     cDate <- 
> chron(paste(wDate$month,wDate$day,wDate$year,sep="/"))
> > +     return(as.Date(as.yearmon(as.Date(cDate,"%m/%d/%y")),frac=1))
> > + }
> > > Set2March(as.Date("2006-06-30"))
> > [1] "2006-03-31"
> > > Set2March(mydate)
> > [1] "2006-01-31"
> > Warning message:
> > No Changes made to the month, since month is not one of (6,9,12) in:
> > Set2March(mydate)
> > >
> >
> > Works well when I use it on a single date. Then I try it on 
> a vector:
> >
> >
> > > dc <- seq(as.Date("2006-01-01"),len=10, by="month") dc
> >  [1] "2006-01-01" "2006-02-01" "2006-03-01" "2006-04-01" 
> "2006-05-01"
> > "2006-06-01" "2006-07-01" "2006-08-01"
> >  [9] "2006-09-01" "2006-10-01"
> >
> >
> > > sapply(as.vector(dc),Set2March)
> > Error in prettyNum(.Internal(format(x, trim, digits, 
> nsmall, width, 3,
> > :
> >        unimplemented type 'character' in 'asLogical'
> > >
> >
> > What am I missing here? Shouldn't the function work with the sapply 
> > working on each entry?
> >
> >
> > TIA and best,
> > -Tir
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>


From jvivben at yahoo.com  Thu Jun 14 11:14:55 2007
From: jvivben at yahoo.com (ivivi mwaniki)
Date: Thu, 14 Jun 2007 02:14:55 -0700 (PDT)
Subject: [R] besselK- complex number problem any help is welcome
Message-ID: <208777.25453.qm@web52903.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070614/2139036f/attachment.pl 

From jeremy.mazet at soredab.org  Thu Jun 14 17:18:03 2007
From: jeremy.mazet at soredab.org (jeremy.mazet at soredab.org)
Date: Thu, 14 Jun 2007 17:18:03 +0200
Subject: [R] clustalW
Message-ID: <OFA0A646D3.A8B5F03C-ONC12572FA.0053F328-C12572FA.00540559@SOPARIND>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20070614/28ff02fe/attachment.pl 

From j.logsdon at quantex-research.com  Thu Jun 14 19:16:47 2007
From: j.logsdon at quantex-research.com (John Logsdon)
Date: Thu, 14 Jun 2007 18:16:47 +0100
Subject: [R] JGR, Java and Kubuntu 7.04 ...
Message-ID: <200706141816.47360.j.logsdon@quantex-research.com>

R-ists

Yet again Java rears its ugly head.  

I have Kubuntu 7.04 running the Kubuntu-repository version of R 2.4.1-1.      
Yes it isn't the  very latest version but this is not the issue here.  

I want a Windows-like environment and everyone is talking about JGR.

I downloaded it and installed it along with rJava.  Both compile and install 
satisfactorily.

But when I come to run it:

> > library('JGR')
>
> Loading required package: rJava
> Error in dyn.load(x, as.logical(local), as.logical(now)) :
>         unable to load shared library
> '/usr/local/lib/R/site-library/rJava/libs/rJava.so':
> /usr/local/lib/R/site-library/rJava/libs/rJava.so: undefined symbol:
> JNI_GetCreatedJavaVMs Error: .onLoad failed in 'loadNamespace' for 'rJava'
> Error: package 'rJava' could not be loaded


When I first tried to run it without Java being installed, I got a message 
saying that JDK wasn't installed but mentioned 1.4.2.  The version of Java 
actually installed as the latest from the Ubuntu repository is Sun 1.5.0.11.  
I don't see the point in installing old versions of Java just for one 
application because the language, or at least the writing, should be 
backwards compatible.  

In all aspects I have seen Kubuntu is a very impressive in checking 
compatibility.  Unfortunately this is frequently not the case with Java.  I 
steer clear of Java as much as possible.  

Can anyone suggest what I should do?  Use Windows perhaps?  Run Windows in a 
kvm virtual machine just to run R?  Put my head in a bucket of cold water?  
Is there an alternative IDE?  Is there a later JGR somewhere that is not yet 
on CRAN?

TIA

-- 
Best wishes

John

John Logsdon                               "Try to make things as simple
Quantex Research Ltd, Manchester UK         as possible but not simpler"
j.logsdon at quantex-research.com              a.einstein at relativity.org
+44(0)161 445 4951/G:+44(0)7717758675       www.quantex-research.com


From cberry at tajo.ucsd.edu  Thu Jun 14 19:35:36 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Thu, 14 Jun 2007 10:35:36 -0700
Subject: [R] Normal and Poisson tail area expectations in R
In-Reply-To: <000b01c7ae0e$53589d40$7c94100a@win.ad.jhu.edu>
References: <Pine.LNX.4.64.0706131426060.24825@tajo.ucsd.edu>
	<219034.18761.qm@web62502.mail.re1.yahoo.com>
	<000b01c7ae0e$53589d40$7c94100a@win.ad.jhu.edu>
Message-ID: <Pine.LNX.4.64.0706141029440.32252@tajo.ucsd.edu>



Ravi,

This looks simple to me.

km_G <- function(lambda,k)
 	lambda*ppois(k-1,lambda,lower=FALSE) -
 		k*ppois(k,lambda,lower=FALSE)

Am I confused here?

Chuck



On Wed, 13 Jun 2007, Ravi Varadhan wrote:

>
> More interesting is the Poisson convolution. I don't know if there is an
> analytic solution to this.  I looked at Jolley's "Summation of Series" and
> Abramowitz and Stegun, but no help there.  It seems that discrete FFT
> technique should work. Does anyone know the answer?
>
> Ravi.
> ----------------------------------------------------------------------------
> -------
>
> Ravi Varadhan, Ph.D.
>
> Assistant Professor, The Center on Aging and Health
>
> Division of Geriatric Medicine and Gerontology
>
> Johns Hopkins University
>
> Ph: (410) 502-2619
>
> Fax: (410) 614-9625
>
> Email: rvaradhan at jhmi.edu
>
> Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html
>
>
>
> ----------------------------------------------------------------------------
> --------
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of kavindra malik
> Sent: Wednesday, June 13, 2007 5:45 PM
> To: Charles C. Berry
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Normal and Poisson tail area expectations in R
>
> Thank you very much. This solves the problem I was trying to solve. I am new
> to R and am learning. A great lesson in the power of R...
>
> "Charles C. Berry" <cberry at tajo.ucsd.edu> wrote: On Wed, 13 Jun 2007,
> kavindra malik wrote:
>
>> I am interested in R functions for the following integrals / sums
> (expressed best I can in text)  -
>>
>> Normal: G_u(k) =  Integration_{Lower limit=k}^{Upper limit=infinity} [(u
> -k) f(u) d(u)], where where u is N(0,1), and f(u) is the density function.
>>
>> Poisson: G(lambda,k) = Sum_{Lower limit=k}^{Upper limit=infinity} [(x-k)
> p(x, lambda)] where P(x,lambda) is the Poisson prob function with parameter
> lambda.
>>
>> The Normal expression is very commonly used in inventory management to
>> determine safety stocks (and its tabular values can be found in some
>> texts) - and I am also looking for Poisson and/or Gamma as that'd fit
>> the situation better.
>>
>> I am wondering if there are standard functions in R that might allow me to
> get these values, instead of needing to do the numerical integration, etc.
> myself.
>
> Not that I know of, but it is not difficult to do the integration:
>
>> k <- 1.1 # for example
>> integrate(function(x) (x-k)*dnorm(x),lower=k,upper=Inf)
> 0.06861951 with absolute error < 5.5e-07
>>
>
> see
>
>  ?integrate
>  ?qnorm
>  ?qpois
>  ?qgamma
>
>>                                                    Thank you very much.
>>
>>
>>
>> ---------------------------------
>> Sucker-punch spam with award-winning protection.
>>
>>  [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> Charles C. Berry                            (858) 534-2098
>                                             Dept of Family/Preventive
> Medicine
> E mailto:cberry at tajo.ucsd.edu             UC San Diego
> http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901
>
>
>
>
>
> ---------------------------------
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	            UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901


From pauljohn32 at gmail.com  Thu Jun 14 19:50:13 2007
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Thu, 14 Jun 2007 12:50:13 -0500
Subject: [R] random effects in logistic regression (lmer)-- identification
	question
Message-ID: <13e802630706141050g144ff7fu63b4c6778f66c50e@mail.gmail.com>

Hello R users!

I've been experimenting with lmer to estimate a  mixed model with a
dichotomous dependent variable.  The goal is to fit a hierarchical
model in which we compare the effect of individual and city-level
variables.  I've run up against a conceptual problem that I expect one
of you can clear up for me.

The question is about random effects in the context of a model fit
with a binomial family and logit link.  Unlike an ordinary linear
regression, there is no way to estimate an individual level random
error in the linear predictor

z_i = a + b*x_i + e_i

because the variance of e_i is unidentified.  The standard deviation
of the logistic is pi*s/3, and we assume s=1, so the standard
deviation is assumed to be pi/3 (just a bit bigger than 1, if you are
comparing against the Standard Normal).  The logistic fitting process
sets the variance of the error and the parameters a and b are
"rescaled" accordingly.

As a result, there is an implicit individual-level random effect
within a logistic model.  There is a good explanation of this issue in
Tony Lancaster's textbook An Introduction to Modern Bayesian
Econometrics.

So we usually end up thinking about a linear predictor in a logistic
regression like so

z_i = a + b*x_i

Random effects can be estimated for "groups" or "clusters" of
observations.  If j is a grouping variable, then we estimate

z_i = a + b*x_i + u_j

The variance component here is, as far as I understand, measured on
the same scale as the logistic distribution's standard deviation.

Currently, I'm working on a project in which there are observations
collected in many cities, represented by a variable PLACE.  We are
comparing the effect of several variables on a response for each of
the values of a RACE variable.  RACE is dichotomized into "White" and
"Nonwhite" by the people who collect the data.

For Nonwhites only, we can estimate the effect of individual level
predictors (x) on the output (y).

fm1 <- lmer( y ~ x + (1 | PLACE), data=dat, , family=binomial, subset=
Race %in% c("Nonwhite"))

The random effect in this model indicates the variance caused by a
Nonwhite's location on the response variable.

Random effects:
 Groups  Name        Variance Std.Dev.
 PLACE (Intercept) 0.047326 0.21754

Suppose I estimate models for the 2 races in a combined model like this:

fm1 <- lmer( y ~ -1 + Race / (x) + (-1 + Race | PLACE), data=dat,
family=binomial)

This gives fixed effects estimates that are pretty easy for
nonstatisticians to understand.  One can look and see the effect of a
variable x on people of different races.

But the random effect is a bit hard to understand.  Since the Race
variable is dichotomous, My aim was to see if the variance of the
random effect is different for the 2 racial categories. Here are the
estimates:

Random effects:
 Groups  Name                      Variance  Std.Dev. Corr
 PLACE RACE_ALLWhite      0.0095429 0.097688
             RACE_ALLNonwhite 0.1286597 0.358692 1.000

I can't quite grasp what the correlation means.  I BELIEVE the
variance values indicate that the experiences of whites are
homogeneous across cities, because the variance is negligible for
them, while the experiences of Nonwhites are much more city-dependent.

What does it mean when the correlation is 1.0?  The correlation takes
on that value when there are no city-level variables in this model, so
I GUESS that it means that all city-level variation is attributed to
the random effect. What do you think?

If i put in some city level predictors, then the estimates of the
variance components change--they essentially disappear to the minimum
values--and the correlation is not 1.0 anymore.

Random effects:
 Groups  Name          Variance Std.Dev.   Corr
 PLACE  RACEWhite    5e-10    2.2361e-05
          RACENonwhite   5e-10    2.2361e-05 0.001

This indicates that, after adding in the city level variables, the
unaccounted for city-level  variation is very small.  Correct?

Now, back to the idea that there is always an implicit individual
level random effect in a logistic regression. Is it meaningful to ask
"is that individual level random effect different for people of
different races?"  If so, How can I estimate that?  If e_i is the
implicit random error, can I ask for another random effect for
Nonwhites only, say u_iN, in a model like so:

z_i = a + b*x_i + e_i + u_iN

Suppose the unique respondent number is ID and we create a new variable

NonwhiteID = 0 for Nonwhites
                 = ID for Nonwhites

Here's my idea about how to check to see if the individual level
variance component for Nonwhites is different from the "baseline" of
Whites by fitting this:

fm1 <- lmer( y ~ -1 + Race / (x) + (-1 + Race | PLACE) + (1 |
NonwhiteID), data=dat, family=binomial)

Here, again, I leave out the city-level variables.

Random effects:
 Groups  Name          Variance   Std.Dev.   Corr
 NonwhiteID (Intercept)   5.0000e-10 2.2361e-05
 PLACE RACEWhite       1.0575e-02 1.0283e-01
         RACENonwhite        1.2880e-01 3.5889e-01 1.000
number of obs: 6201, groups: NonwhiteID, 1736; PLACE, 33

The variance component estimated for NonwhiteID means that the
variance observed among Nonwhite respondents is not substantially
different from the implicit, unestimated individual level random
error.  However, it still appears that there is a substantial place
effect, for Nonwhites only.

Do I understand that right?

Well, thanks in advance, as usual.

-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas


From rvaradhan at jhmi.edu  Thu Jun 14 20:07:33 2007
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Thu, 14 Jun 2007 14:07:33 -0400
Subject: [R] Normal and Poisson tail area expectations in R
In-Reply-To: <Pine.LNX.4.64.0706141029440.32252@tajo.ucsd.edu>
References: <Pine.LNX.4.64.0706131426060.24825@tajo.ucsd.edu>
	<219034.18761.qm@web62502.mail.re1.yahoo.com>
	<000b01c7ae0e$53589d40$7c94100a@win.ad.jhu.edu>
	<Pine.LNX.4.64.0706141029440.32252@tajo.ucsd.edu>
Message-ID: <001201c7aeae$e1c735a0$7c94100a@win.ad.jhu.edu>

Perfect, Chuck.  I got a closed-form solution after some algebraic labor,
but your solution is simple and elegant.

Ravi.

----------------------------------------------------------------------------
-------

Ravi Varadhan, Ph.D.

Assistant Professor, The Center on Aging and Health

Division of Geriatric Medicine and Gerontology 

Johns Hopkins University

Ph: (410) 502-2619

Fax: (410) 614-9625

Email: rvaradhan at jhmi.edu

Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html

 

----------------------------------------------------------------------------
--------


-----Original Message-----
From: Charles C. Berry [mailto:cberry at tajo.ucsd.edu] 
Sent: Thursday, June 14, 2007 1:36 PM
To: Ravi Varadhan
Cc: 'kavindra malik'; r-help at stat.math.ethz.ch
Subject: RE: [R] Normal and Poisson tail area expectations in R



Ravi,

This looks simple to me.

km_G <- function(lambda,k)
 	lambda*ppois(k-1,lambda,lower=FALSE) -
 		k*ppois(k,lambda,lower=FALSE)

Am I confused here?

Chuck



On Wed, 13 Jun 2007, Ravi Varadhan wrote:

>
> More interesting is the Poisson convolution. I don't know if there is an
> analytic solution to this.  I looked at Jolley's "Summation of Series" and
> Abramowitz and Stegun, but no help there.  It seems that discrete FFT
> technique should work. Does anyone know the answer?
>
> Ravi.
>
----------------------------------------------------------------------------
> -------
>
> Ravi Varadhan, Ph.D.
>
> Assistant Professor, The Center on Aging and Health
>
> Division of Geriatric Medicine and Gerontology
>
> Johns Hopkins University
>
> Ph: (410) 502-2619
>
> Fax: (410) 614-9625
>
> Email: rvaradhan at jhmi.edu
>
> Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html
>
>
>
>
----------------------------------------------------------------------------
> --------
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of kavindra malik
> Sent: Wednesday, June 13, 2007 5:45 PM
> To: Charles C. Berry
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Normal and Poisson tail area expectations in R
>
> Thank you very much. This solves the problem I was trying to solve. I am
new
> to R and am learning. A great lesson in the power of R...
>
> "Charles C. Berry" <cberry at tajo.ucsd.edu> wrote: On Wed, 13 Jun 2007,
> kavindra malik wrote:
>
>> I am interested in R functions for the following integrals / sums
> (expressed best I can in text)  -
>>
>> Normal: G_u(k) =  Integration_{Lower limit=k}^{Upper limit=infinity} [(u
> -k) f(u) d(u)], where where u is N(0,1), and f(u) is the density function.
>>
>> Poisson: G(lambda,k) = Sum_{Lower limit=k}^{Upper limit=infinity} [(x-k)
> p(x, lambda)] where P(x,lambda) is the Poisson prob function with
parameter
> lambda.
>>
>> The Normal expression is very commonly used in inventory management to
>> determine safety stocks (and its tabular values can be found in some
>> texts) - and I am also looking for Poisson and/or Gamma as that'd fit
>> the situation better.
>>
>> I am wondering if there are standard functions in R that might allow me
to
> get these values, instead of needing to do the numerical integration, etc.
> myself.
>
> Not that I know of, but it is not difficult to do the integration:
>
>> k <- 1.1 # for example
>> integrate(function(x) (x-k)*dnorm(x),lower=k,upper=Inf)
> 0.06861951 with absolute error < 5.5e-07
>>
>
> see
>
>  ?integrate
>  ?qnorm
>  ?qpois
>  ?qgamma
>
>>                                                    Thank you very much.
>>
>>
>>
>> ---------------------------------
>> Sucker-punch spam with award-winning protection.
>>
>>  [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> Charles C. Berry                            (858) 534-2098
>                                             Dept of Family/Preventive
> Medicine
> E mailto:cberry at tajo.ucsd.edu             UC San Diego
> http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901
>
>
>
>
>
> ---------------------------------
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive
Medicine
E mailto:cberry at tajo.ucsd.edu	            UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901


From genomenet at gmail.com  Thu Jun 14 20:25:54 2007
From: genomenet at gmail.com (genomenet at gmail.com)
Date: Thu, 14 Jun 2007 11:25:54 -0700
Subject: [R] how to fit y=m*x
Message-ID: <1314811283.20070614112554@gmail.com>

Hi There,

I have a set of data (xi,yi).I want to fit them with the equation
y=mx. 

note: in the above equation, there is no intercept.

I don't know how to use common software such as R , matlab, sas, or
spss to do this kind of regression.

Does anyone know how to do this?

I know it is easy to use least square method to do this by
programming. But I want to find if there exists some common software
which can do this. 

Thank you very much.

Van


From ndoye_p at hotmail.com  Thu Jun 14 20:33:02 2007
From: ndoye_p at hotmail.com (Ndoye Souleymane)
Date: Thu, 14 Jun 2007 18:33:02 +0000
Subject: [R] how to fit y=m*x
In-Reply-To: <1314811283.20070614112554@gmail.com>
Message-ID: <BAY116-F3571CED6E53E4FC4AD677A991F0@phx.gbl>

Hi,

try : ln(y~x)


>From: genomenet at gmail.com
>Reply-To: genomenet at gmail.com
>To: r-help at stat.math.ethz.ch
>Subject: [R] how to fit y=m*x
>Date: Thu, 14 Jun 2007 11:25:54 -0700
>
>Hi There,
>
>I have a set of data (xi,yi).I want to fit them with the equation
>y=mx.
>
>note: in the above equation, there is no intercept.
>
>I don't know how to use common software such as R , matlab, sas, or
>spss to do this kind of regression.
>
>Does anyone know how to do this?
>
>I know it is easy to use least square method to do this by
>programming. But I want to find if there exists some common software
>which can do this.
>
>Thank you very much.
>
>Van
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide 
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

_________________________________________________________________
D?couvrez le Blog heroic Fantaisy d'Eragon!


From A.Robinson at ms.unimelb.edu.au  Thu Jun 14 20:44:46 2007
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Fri, 15 Jun 2007 04:44:46 +1000
Subject: [R] how to fit y=m*x
In-Reply-To: <BAY116-F3571CED6E53E4FC4AD677A991F0@phx.gbl>
References: <1314811283.20070614112554@gmail.com>
	<BAY116-F3571CED6E53E4FC4AD677A991F0@phx.gbl>
Message-ID: <20070614184446.GH63160@ms.unimelb.edu.au>

Probably

lm(y ~ x - 1)

will be better.  y~x doesn't remove the intercept, and ln() is a typo
(I hope!)

Andrew

On Thu, Jun 14, 2007 at 06:33:02PM +0000, Ndoye Souleymane wrote:
> Hi,
> 
> try : ln(y~x)
> 
> 
> >From: genomenet at gmail.com
> >Reply-To: genomenet at gmail.com
> >To: r-help at stat.math.ethz.ch
> >Subject: [R] how to fit y=m*x
> >Date: Thu, 14 Jun 2007 11:25:54 -0700
> >
> >Hi There,
> >
> >I have a set of data (xi,yi).I want to fit them with the equation
> >y=mx.
> >
> >note: in the above equation, there is no intercept.
> >
> >I don't know how to use common software such as R , matlab, sas, or
> >spss to do this kind of regression.
> >
> >Does anyone know how to do this?
> >
> >I know it is easy to use least square method to do this by
> >programming. But I want to find if there exists some common software
> >which can do this.
> >
> >Thank you very much.
> >
> >Van
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide 
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> 
> _________________________________________________________________
> D?couvrez le Blog heroic Fantaisy d'Eragon!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/


From deepayan.sarkar at gmail.com  Thu Jun 14 20:45:35 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Thu, 14 Jun 2007 11:45:35 -0700
Subject: [R] Annotating trellis graphics
In-Reply-To: <1181769661.17656.44.camel@gestalt.nimh.nih.gov>
References: <1181769661.17656.44.camel@gestalt.nimh.nih.gov>
Message-ID: <eb555e660706141145u2a286ca5w6be822da5bc3e526@mail.gmail.com>

On 6/13/07, Alan S Barnett <asb at mail.nih.gov> wrote:
> I'm using xyplot to generate a trellis plot with each panel containing a
> scatterplot and a best fit line.  Is it possible to write the slope of
> the best fit line in each panel?

Sure. The only question is, where (inside the panel) do you want it written?
Here are a couple of possibilities:

## writes the slope at a location that happens to be empty in both
## panels in this example

xyplot(len ~ dose | supp, ToothGrowth,
       panel = function(x, y, ...) {
           panel.xyplot(x, y, ...)
           fm <- lm(y ~ x)
           panel.abline(reg = fm)
           slope <- round(coef(fm)[2], 3)
           panel.text(1.5, 5, lab = slope)
       })


## needs the user to click on a suitable position for each panel

library(grid)

xyplot(len ~ dose | supp, ToothGrowth,
       panel = function(x, y, ...) {
           panel.xyplot(x, y, ...)
           fm <- lm(y ~ x)
           panel.abline(reg = fm)
           slope <- round(coef(fm)[2], 3)
           message("Click on desired location")
           panel.text(grid.locator("native"), lab = slope)
       })

-Deepayan


From christophe at pallier.org  Thu Jun 14 20:57:20 2007
From: christophe at pallier.org (Christophe Pallier)
Date: Thu, 14 Jun 2007 20:57:20 +0200
Subject: [R] how to fit y=m*x
In-Reply-To: <1314811283.20070614112554@gmail.com>
References: <1314811283.20070614112554@gmail.com>
Message-ID: <dea6cb960706141157m38909d25ke9019acdef16dbae@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070614/e2484c58/attachment.pl 

From rvaradhan at jhmi.edu  Thu Jun 14 21:04:55 2007
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Thu, 14 Jun 2007 15:04:55 -0400
Subject: [R] Normal and Poisson tail area expectations in R
In-Reply-To: <001201c7aeae$e1c735a0$7c94100a@win.ad.jhu.edu>
References: <Pine.LNX.4.64.0706131426060.24825@tajo.ucsd.edu>
	<219034.18761.qm@web62502.mail.re1.yahoo.com>
	<000b01c7ae0e$53589d40$7c94100a@win.ad.jhu.edu>
	<Pine.LNX.4.64.0706141029440.32252@tajo.ucsd.edu>
	<001201c7aeae$e1c735a0$7c94100a@win.ad.jhu.edu>
Message-ID: <002401c7aeb6$e55bad60$7c94100a@win.ad.jhu.edu>

Inspired by Chuck's elegant solution to the Poisson tail area problem, here
is a simple solution to the normal tail area expectation that does not use
integrate().

Gu.k <- function(k) {1/sqrt(2*pi) * exp(-k*k/2) - k * pnorm(k, lower=FALSE)}

> k <- 1:10
> Gu.k(k)
 [1] 8.331547e-02 8.490703e-03 3.821543e-04 7.145258e-06 5.346166e-08
1.563570e-10 1.760326e-13 7.550262e-17 1.224779e-20 7.474560e-25
>
> sapply(k, function(k)integrate(function(x)
(x-k)*dnorm(x),lower=k,upper=Inf)$val)
 [1] 8.331547e-02 8.490702e-03 3.821543e-04 7.145259e-06 5.346163e-08
1.563570e-10 1.760326e-13 7.550262e-17 1.224779e-20 7.474560e-25
>

Ravi. 

----------------------------------------------------------------------------
-------

Ravi Varadhan, Ph.D.

Assistant Professor, The Center on Aging and Health

Division of Geriatric Medicine and Gerontology 

Johns Hopkins University

Ph: (410) 502-2619

Fax: (410) 614-9625

Email: rvaradhan at jhmi.edu

Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html

 

----------------------------------------------------------------------------
--------


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Ravi Varadhan
Sent: Thursday, June 14, 2007 2:08 PM
To: 'Charles C. Berry'
Cc: 'kavindra malik'; r-help at stat.math.ethz.ch
Subject: Re: [R] Normal and Poisson tail area expectations in R

Perfect, Chuck.  I got a closed-form solution after some algebraic labor,
but your solution is simple and elegant.

Ravi.

----------------------------------------------------------------------------
-------

Ravi Varadhan, Ph.D.

Assistant Professor, The Center on Aging and Health

Division of Geriatric Medicine and Gerontology 

Johns Hopkins University

Ph: (410) 502-2619

Fax: (410) 614-9625

Email: rvaradhan at jhmi.edu

Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html

 

----------------------------------------------------------------------------
--------


-----Original Message-----
From: Charles C. Berry [mailto:cberry at tajo.ucsd.edu] 
Sent: Thursday, June 14, 2007 1:36 PM
To: Ravi Varadhan
Cc: 'kavindra malik'; r-help at stat.math.ethz.ch
Subject: RE: [R] Normal and Poisson tail area expectations in R



Ravi,

This looks simple to me.

km_G <- function(lambda,k)
 	lambda*ppois(k-1,lambda,lower=FALSE) -
 		k*ppois(k,lambda,lower=FALSE)

Am I confused here?

Chuck



On Wed, 13 Jun 2007, Ravi Varadhan wrote:

>
> More interesting is the Poisson convolution. I don't know if there is an
> analytic solution to this.  I looked at Jolley's "Summation of Series" and
> Abramowitz and Stegun, but no help there.  It seems that discrete FFT
> technique should work. Does anyone know the answer?
>
> Ravi.
>
----------------------------------------------------------------------------
> -------
>
> Ravi Varadhan, Ph.D.
>
> Assistant Professor, The Center on Aging and Health
>
> Division of Geriatric Medicine and Gerontology
>
> Johns Hopkins University
>
> Ph: (410) 502-2619
>
> Fax: (410) 614-9625
>
> Email: rvaradhan at jhmi.edu
>
> Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html
>
>
>
>
----------------------------------------------------------------------------
> --------
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of kavindra malik
> Sent: Wednesday, June 13, 2007 5:45 PM
> To: Charles C. Berry
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Normal and Poisson tail area expectations in R
>
> Thank you very much. This solves the problem I was trying to solve. I am
new
> to R and am learning. A great lesson in the power of R...
>
> "Charles C. Berry" <cberry at tajo.ucsd.edu> wrote: On Wed, 13 Jun 2007,
> kavindra malik wrote:
>
>> I am interested in R functions for the following integrals / sums
> (expressed best I can in text)  -
>>
>> Normal: G_u(k) =  Integration_{Lower limit=k}^{Upper limit=infinity} [(u
> -k) f(u) d(u)], where where u is N(0,1), and f(u) is the density function.
>>
>> Poisson: G(lambda,k) = Sum_{Lower limit=k}^{Upper limit=infinity} [(x-k)
> p(x, lambda)] where P(x,lambda) is the Poisson prob function with
parameter
> lambda.
>>
>> The Normal expression is very commonly used in inventory management to
>> determine safety stocks (and its tabular values can be found in some
>> texts) - and I am also looking for Poisson and/or Gamma as that'd fit
>> the situation better.
>>
>> I am wondering if there are standard functions in R that might allow me
to
> get these values, instead of needing to do the numerical integration, etc.
> myself.
>
> Not that I know of, but it is not difficult to do the integration:
>
>> k <- 1.1 # for example
>> integrate(function(x) (x-k)*dnorm(x),lower=k,upper=Inf)
> 0.06861951 with absolute error < 5.5e-07
>>
>
> see
>
>  ?integrate
>  ?qnorm
>  ?qpois
>  ?qgamma
>
>>                                                    Thank you very much.
>>
>>
>>
>> ---------------------------------
>> Sucker-punch spam with award-winning protection.
>>
>>  [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> Charles C. Berry                            (858) 534-2098
>                                             Dept of Family/Preventive
> Medicine
> E mailto:cberry at tajo.ucsd.edu             UC San Diego
> http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901
>
>
>
>
>
> ---------------------------------
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive
Medicine
E mailto:cberry at tajo.ucsd.edu	            UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From mardones.p at gmail.com  Thu Jun 14 21:14:26 2007
From: mardones.p at gmail.com (Pedro Mardones)
Date: Thu, 14 Jun 2007 15:14:26 -0400
Subject: [R] question about formula for lm
Message-ID: <83dca7860706141214o1db5fe3dxeb020bc0dbd2768c@mail.gmail.com>

Dear all;

Is there any way to make this to work?:

.x<-rnorm(50,10,3)
.y<-.x+rnorm(50,0,1)

X<-data.frame(.x,.y)
colnames(X)<-c("Xvar","Yvar")

Ytext<-"Yvar"

lm(Ytext~Xvar,data=X) # doesn't run

lm(Yvar~Xvar,data=X) # does run

The main idea is to use Ytext as input in a function, so you just type
"Yvar" and the model should fit....
Also, I need to avoid the expression X$Yvar~X$Xvar

Thanks for any idea

PM


From elvis at xlsolutions-corp.com  Thu Jun 14 21:21:00 2007
From: elvis at xlsolutions-corp.com (elvis Miller)
Date: Thu, 14 Jun 2007 12:21:00 -0700
Subject: [R] Course: 2-day Short R/S-Plus at JSM - Salt Lake City July -
	August 2007
Message-ID: <20070614122100.aa8924c5d28ca71e2a043bb294e795eb.6ec92bbff5.wbe@email.secureserver.net>

Greetings!
 
XLSolutions Will schedule a series of 2-day R/S-plus courses during JSM
in Salt Lake City. Please email us your interest and dates that work 
best for you from  July 26th - August 3rd.
 
www.xlsolutions-corp.com/courselist.htm 
 
Payment due AFTER the class
 Email us for group discounts. 
 Email Sue Turner: sue at xlsolutions-corp.com 
 Phone: 206-686-1578 
 Visit us: www.xlsolutions-corp.com/courselist.htm 
 Please let us know if you and your colleagues are interested in these
 classes to take advantage of group discount. Register now to secure
your 
 seat! 
 
 Cheers, 
 Elvis Miller, PhD 
 Manager Training. 
 XLSolutions Corporation 
 206 686 1578 
 www.xlsolutions-corp.com


From jrkrideau at yahoo.ca  Thu Jun 14 21:38:17 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Thu, 14 Jun 2007 15:38:17 -0400 (EDT)
Subject: [R] how to fit y=m*x
In-Reply-To: <1314811283.20070614112554@gmail.com>
Message-ID: <554820.73873.qm@web32811.mail.mud.yahoo.com>

Yes it does  If you have R installed simply type
?lm

This gives you the appropriate help page.

Note for a no intercept regression

"A formula has an implied intercept term. To remove
this use either y ~ x - 1 or y ~ 0 + x. See formula
for more details of allowed formulae. "


--- genomenet at gmail.com wrote:

> Hi There,
> 
> I have a set of data (xi,yi).I want to fit them with
> the equation
> y=mx. 
> 
> note: in the above equation, there is no intercept.
> 
> I don't know how to use common software such as R ,
> matlab, sas, or
> spss to do this kind of regression.
> 
> Does anyone know how to do this?
> 
> I know it is easy to use least square method to do
> this by
> programming. But I want to find if there exists some
> common software
> which can do this. 
> 
> Thank you very much.
> 
> Van
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From thpe at simecol.de  Thu Jun 14 21:56:09 2007
From: thpe at simecol.de (Thomas Petzoldt)
Date: Thu, 14 Jun 2007 21:56:09 +0200
Subject: [R] question about formula for lm
In-Reply-To: <83dca7860706141214o1db5fe3dxeb020bc0dbd2768c@mail.gmail.com>
References: <83dca7860706141214o1db5fe3dxeb020bc0dbd2768c@mail.gmail.com>
Message-ID: <46719D59.6050903@simecol.de>

Why not using:

lm(X[[Ytext]]~Xvar,data=X)


ThPe


Pedro Mardones wrote:
> Dear all;
> 
> Is there any way to make this to work?:
> 
> .x<-rnorm(50,10,3)
> .y<-.x+rnorm(50,0,1)
> 
> X<-data.frame(.x,.y)
> colnames(X)<-c("Xvar","Yvar")
> 
> Ytext<-"Yvar"
> 
> lm(Ytext~Xvar,data=X) # doesn't run
> 
> lm(Yvar~Xvar,data=X) # does run
> 
> The main idea is to use Ytext as input in a function, so you just type
> "Yvar" and the model should fit....
> Also, I need to avoid the expression X$Yvar~X$Xvar
> 
> Thanks for any idea
> 
> PM
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at yahoo.ca  Thu Jun 14 22:03:23 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Thu, 14 Jun 2007 16:03:23 -0400 (EDT)
Subject: [R] question about formula for lm
In-Reply-To: <83dca7860706141214o1db5fe3dxeb020bc0dbd2768c@mail.gmail.com>
Message-ID: <889087.71207.qm@web32806.mail.mud.yahoo.com>

First check the value of Ytext. 

Try 
Ytext <- X$Yvar

--- Pedro Mardones <mardones.p at gmail.com> wrote:

> Dear all;
> 
> Is there any way to make this to work?:
> 
> .x<-rnorm(50,10,3)
> .y<-.x+rnorm(50,0,1)
> 
> X<-data.frame(.x,.y)
> colnames(X)<-c("Xvar","Yvar")
> 
> Ytext<-"Yvar"
> 
> lm(Ytext~Xvar,data=X) # doesn't run
> 
> lm(Yvar~Xvar,data=X) # does run
> 
> The main idea is to use Ytext as input in a
> function, so you just type
> "Yvar" and the model should fit....
> Also, I need to avoid the expression X$Yvar~X$Xvar
> 
> Thanks for any idea
> 
> PM
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From Zava.Aydemir at morganstanley.com  Thu Jun 14 22:07:57 2007
From: Zava.Aydemir at morganstanley.com (Aydemir, Zava (FID))
Date: Thu, 14 Jun 2007 16:07:57 -0400
Subject: [R] connecting to db2 via RJDBC
Message-ID: <755261CA22782948B1C42ACDC83912A10425DC64@NYWEXMB27.msad.ms.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070614/76640915/attachment.pl 

From Cody_Hamilton at Edwards.com  Thu Jun 14 22:19:13 2007
From: Cody_Hamilton at Edwards.com (Cody_Hamilton at Edwards.com)
Date: Thu, 14 Jun 2007 13:19:13 -0700
Subject: [R] R vs. Splus in Pharma/Devices Industry
Message-ID: <OF9AEA0D70.0C0D2A44-ON882572FA.0066D600-882572FA.006F6C63@irvine.edwards.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070614/f89d87f2/attachment.pl 

From Greg.Snow at intermountainmail.org  Thu Jun 14 22:18:16 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Thu, 14 Jun 2007 14:18:16 -0600
Subject: [R] question about formula for lm
In-Reply-To: <83dca7860706141214o1db5fe3dxeb020bc0dbd2768c@mail.gmail.com>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBA21E77@LP-EXCHVS07.CO.IHC.COM>


Try:

> lm( formula( paste( Ytext, '~ Xvar' ) ), data=X)

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Pedro Mardones
> Sent: Thursday, June 14, 2007 1:14 PM
> To: R-help at stat.math.ethz.ch
> Subject: [R] question about formula for lm
> 
> Dear all;
> 
> Is there any way to make this to work?:
> 
> .x<-rnorm(50,10,3)
> .y<-.x+rnorm(50,0,1)
> 
> X<-data.frame(.x,.y)
> colnames(X)<-c("Xvar","Yvar")
> 
> Ytext<-"Yvar"
> 
> lm(Ytext~Xvar,data=X) # doesn't run
> 
> lm(Yvar~Xvar,data=X) # does run
> 
> The main idea is to use Ytext as input in a function, so you 
> just type "Yvar" and the model should fit....
> Also, I need to avoid the expression X$Yvar~X$Xvar
> 
> Thanks for any idea
> 
> PM
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jrkrideau at yahoo.ca  Thu Jun 14 22:47:00 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Thu, 14 Jun 2007 16:47:00 -0400 (EDT)
Subject: [R] Tools For Preparing Data For Analysis
In-Reply-To: <XFMail.070614122506.ted.harding@nessie.mcc.ac.uk>
Message-ID: <849105.61417.qm@web32812.mail.mud.yahoo.com>


--- ted.harding at nessie.mcc.ac.uk wrote:

> As a tangent to this thread, there is a very
> relevant
> article in the latest issue of the RSS magazine
> "Significance",
> which I have just received:
> 
>   Dr Fisher's Casebook
>   The trouble with data
> 
> Significance, Vol 4 (2007) Issue 2.
> 
> Full current contents at
> 
> http://www.blackwell-synergy.com/toc/sign/4/2
> 
> but unfortunately you can only read any of it by
> paying
> money to Blackwell (unless you're an RSS member).
> 
> Best wishes to all,
> Ted.

A lovely article.  I'm not a member but the local
university has a subscription.  

The examples of "men who claimed to have cervical 
smears (F) and women who were 5' tall weighing 15
stone (T) ring true.  

I've found people walking at 30 km/hr (F) and an
addict using 240 needles a month (T). I've even found
a set of 16 variables the study designers never heard
of !


From Greg.Snow at intermountainmail.org  Thu Jun 14 22:51:06 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Thu, 14 Jun 2007 14:51:06 -0600
Subject: [R] R vs. Splus in Pharma/Devices Industry
In-Reply-To: <OF9AEA0D70.0C0D2A44-ON882572FA.0066D600-882572FA.006F6C63@irvine.edwards.com>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBA21E92@LP-EXCHVS07.CO.IHC.COM>

In my case, the MS word users know just enough about statistics to know
that they need a statistician (me or one of my group), so it is usually
me that sets up the template.  This is generally for a set of
graphs/tables that will be included in a paper or presentation.  They do
most of the initial writing then I send them the graphs and tables that
they can cut and paste into the word document, then that gets passed
around to the various authors for editing (I usually end up doing the
stats methods and conclusions as well).

Before the odfWeave package, I would usually generate graphs one at a
time, copy and paste them into a word document, then create the tables
in a matrix, use write.table('clipboard', sep='\t') and paste that into
excel, then copy and paste that into word.  A real pain.

Now I can set up an open office document for the plots and tables, run
it through odfWeave, convert the output document to word and send it to
them, they usually copy and paste from the document I send to one they
are working on.

If someone has an existing word document that you would like to turn
into a template, just use open office to convert it to an .odt file,
then replace any output that you want to be able to regenerate with the
sweave/R statements and run it.  It works pretty well.

I do work indirectly with some other statisticians that have to produce
monthly reports (that are essentially the same from month to month with
updated data).  I am working on converting them to using R/sweave.
These reports are usually put out as internal webpages for various
people in the organization to look at, so we could either go the
odfWeave approach and generate pdf files (not as automated as I would
like), or use the R2HTML approach and have the template files and
results as html.

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Cody_Hamilton at edwards.com
> Sent: Thursday, June 14, 2007 2:19 PM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] R vs. Splus in Pharma/Devices Industry
> 
> 
> Greg,
> 
> This is very interesting.  Perhaps something similar could be 
> worked out here.  Do you have to get MS Word users to work 
> only with the template you provide, or can they provide you 
> any old MS Word document?
> 
> Regards, -Cody
> 
> Cody Hamilton, PhD
> Edwards Lifesciences
> 
> But sweave is expanding.  There is a driver for HTML sweaving 
> in the R2HTML package and the odfWeave package allows you to 
> sweave with open office docs (which can be converted to/from 
> MS word).  I personally like using LaTeX and the original 
> sweave, but I work with people who want everything in MS word 
> or similar, so for them I will create a template file in open 
> office, odfWeave that, convert to MS word and send that to them.
> 
> I think the offset is more that S-PLUS 8 is supposed to 
> implement many of the things that R does now (I don't know 
> which, I'm waiting for my copy of 8), so soon it may be 
> possible to sweave in both.
> 
> --
> Gregory (Greg) L. Snow Ph.D.
> Statistical Data Center
> Intermountain Healthcare
> greg.snow at intermountainmail.org
> (801) 408-8111
> 
> 
> 
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch 
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> > Cody_Hamilton at edwards.com
> > Sent: Wednesday, June 13, 2007 4:07 PM
> > To: r-help at stat.math.ethz.ch
> > Subject: Re: [R] R vs. Splus in Pharma/Devices Industry
> >
> >
> > I should have also noted that Sweave is available for use with R.  
> > This is offset, however, by the fact that I will probably never be 
> > able to convince anyone to use Latex.  This is a pity as I 
> often find 
> > myself admiring reports done in Latex as opposed to the ones I have 
> > worked on in MS Word.
> >
> > Cody Hamilton, PhD
> > Edwards Lifesciences
> >
> > As always, I am speaking for myself and not necessarily for Edwards 
> > Lifesciences.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From justin_bem at yahoo.fr  Thu Jun 14 18:00:21 2007
From: justin_bem at yahoo.fr (justin bem)
Date: Thu, 14 Jun 2007 16:00:21 +0000 (GMT)
Subject: [R] Re :  function with xyplot
Message-ID: <973610.75166.qm@web23014.mail.ird.yahoo.com>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20070614/33b7f74c/attachment.pl 

From Max.Kuhn at pfizer.com  Thu Jun 14 23:11:09 2007
From: Max.Kuhn at pfizer.com (Kuhn, Max)
Date: Thu, 14 Jun 2007 17:11:09 -0400
Subject: [R] R vs. Splus in Pharma/Devices Industry
In-Reply-To: <07E228A5BE53C24CAD490193A7381BBBA21E92@LP-EXCHVS07.CO.IHC.COM>
Message-ID: <71257D09F114DA4A8E134DEAC70F25D308A690EB@groamrexm03.amer.pfizer.com>

Greg,

Thanks for the kind words about odfWeave.

> These reports are usually put out as internal webpages for various
> people in the organization to look at, so we could either go the
> odfWeave approach and generate pdf files (not as automated as I would
> like)

I agree that automating the conversion should be easier. My wish would
be that the OO binary had a flag to convert from one format to another.

On Linux, there is a bash script that uses the open office binaries to
do the conversion at the command line by Nathan Coulter at

   http://sourceforge.net/projects/ooconvert/

Also, there is a Java class called jooconvert out there (if memory
serves) that has similar functionality.

Max



----------------------------------------------------------------------
LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}


From Suzan.Pool at noaa.gov  Thu Jun 14 23:18:11 2007
From: Suzan.Pool at noaa.gov (Suzan Pool)
Date: Thu, 14 Jun 2007 14:18:11 -0700
Subject: [R] back-transform predictors for x-axis in plot -- mgcv package
Message-ID: <4671B093.6@noaa.gov>

My question is related to plot( ) in the mgcv package.  Before modelling 
the data, a few predictors were transformed to normalize them.  
Therefore, the x-axes in the plots show transformed predictor values.  
How do I back-transform the predictors so that the plots are easier to 
interpret?

Thanks in advance,
Suzan

-- 
Suzan Pool
Oregon State University
Cooperative Institute for Marine Resources Studies
c/o NOAA Fisheries
520 Heceta Place
P.O. Box 155
Hammond, OR  97121

Suzan.Pool at oregonstate.edu
Suzan.Pool at noaa.gov
Phone:  503-861-1818 x36 TTY
Voice to TTY:  711
Fax:  503-861-2589


From quesada at gmail.com  Thu Jun 14 23:34:09 2007
From: quesada at gmail.com (Jose Quesada )
Date: Thu, 14 Jun 2007 23:34:09 +0200
Subject: [R] Error: bad value ? what is that?
Message-ID: <op.ttxku71z4hcap5@delllap.ugr.es>

Hi,

I'm finding a very strange error.
For no good reason my R console (Rgui.exe, R 2.5.0, under win XP) stops  
producing anything meaningful, and just returns:
Error: bad value
to _whatever_ I enter. It starts doing this after a while, not immediately  
when launched.

I have to restart R when this happens.
No idea why. I didn't change anything in the R config that I remenber.

Any thoughts?

Thanks.

-- 
Jose Quesada, PhD.
http://www.andrew.cmu.edu/~jquesada


From p.dalgaard at biostat.ku.dk  Fri Jun 15 00:31:55 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 15 Jun 2007 00:31:55 +0200
Subject: [R] Error: bad value ? what is that?
In-Reply-To: <op.ttxku71z4hcap5@delllap.ugr.es>
References: <op.ttxku71z4hcap5@delllap.ugr.es>
Message-ID: <4671C1DB.10201@biostat.ku.dk>

Jose Quesada wrote:
> Hi,
>
> I'm finding a very strange error.
> For no good reason my R console (Rgui.exe, R 2.5.0, under win XP) stops  
> producing anything meaningful, and just returns:
> Error: bad value
> to _whatever_ I enter. It starts doing this after a while, not immediately  
> when launched.
>
> I have to restart R when this happens.
> No idea why. I didn't change anything in the R config that I remenber.
>
> Any thoughts?
>
> Thanks.
>
>   
Hmm that message comes from deep down inside SETCAR() and friends. I 
can't see other reasons for it than memory corruption. Are you running 
some rogue C code? Is the machine flaky in other respects?


From philozine at yahoo.com  Fri Jun 15 01:03:58 2007
From: philozine at yahoo.com (philozine)
Date: Thu, 14 Jun 2007 16:03:58 -0700 (PDT)
Subject: [R] Retain names in conversion of matrix to vector
Message-ID: <832336.16287.qm@web32804.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070614/4bc53dc4/attachment.pl 

From Bill.Venables at csiro.au  Fri Jun 15 01:25:37 2007
From: Bill.Venables at csiro.au (Bill.Venables at csiro.au)
Date: Fri, 15 Jun 2007 09:25:37 +1000
Subject: [R] Retain names in conversion of matrix to vector
References: <832336.16287.qm@web32804.mail.mud.yahoo.com>
Message-ID: <B998A44C8986644EA8029CFE6396A924B67DC3@exqld2-bne.nexus.csiro.au>

There is a slightly surprising way to do this in one step.  Here's an
example

> tmp <- matrix(1:16, 4, 4)
> dimnames(tmp) <- list(letters[1:4], letters[1:4])
> tmp
  a b  c  d
a 1 5  9 13
b 2 6 10 14
c 3 7 11 15
d 4 8 12 16
> as.data.frame(as.table(tmp))
   Var1 Var2 Freq
1     a    a    1
2     b    a    2
3     c    a    3
4     d    a    4
5     a    b    5
6     b    b    6
7     c    b    7
8     d    b    8
9     a    c    9
10    b    c   10
11    c    c   11
12    d    c   12
13    a    d   13
14    b    d   14
15    c    d   15
16    d    d   16
>  


Bill Venables
CSIRO Laboratories
PO Box 120, Cleveland, 4163
AUSTRALIA
Office Phone (email preferred): +61 7 3826 7251
Fax (if absolutely necessary):  +61 7 3826 7304
Mobile:                (I don't have one!)
Home Phone:                     +61 7 3286 7700
mailto:Bill.Venables at csiro.au
http://www.cmis.csiro.au/bill.venables/ 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of philozine
Sent: Friday, 15 June 2007 9:04 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Retain names in conversion of matrix to vector

Hi R-listers,

I'm using R only for a few basic functions but am having difficulty
doing something that *should* be simple. I have an nxn matrix, Q, where
Q[i,j] is a directed value (in this case, oil exports from i to j). Note
that Q[i,j]~=Q[j,i]. I imported column names along with the matrix then
copied them to the rows using rownames(Q) <- colnames(Q). Simple so far.

What I'd like to do now is convert Q for export into a vector of values
with the original row and column names intact. Having one vector each
for row, column, and cell would be ideal, e.g., [1,1] = i's name, [1,2]
= j's name, and [1,3] = Q[i, j]. But just being able to export my matrix
data in vector form with the correct row/col names for each observation
would be sufficient.

Thus far I've tried c(), vector(), and a few others, but can't get the
correct results. They do generate the correct vector of matrix values,
but they do not appear to retain both row and column names. (Or, rather,
I have not discovered how to make them do so.)

To illustrate, my data currently look something like this:

    A    B    C    D
A | 0  |.1 |.4  |.6  |
B |.2 | 0  |.2  |.1  |
C |.5  |.9  | 0  |.9  |
D |.7  | 0  |.3  | 0  |

I would like them to look like this (at least when exported as a .txt
file, if not necessary when displayed within R):

  i   j   Q
| A | A | 0 |
| A | B |.1 |
| A | C |.4 |
| A | D |.6 |
| B | A |.2 |
| B | B | 0 |
| B | C |.2 |
[...] and so on

If anybody knows how to do this, I will be extremely appreciative!

Best regards,


       
---------------------------------

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From cberry at tajo.ucsd.edu  Fri Jun 15 01:33:40 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Thu, 14 Jun 2007 16:33:40 -0700
Subject: [R] Retain names in conversion of matrix to vector
In-Reply-To: <832336.16287.qm@web32804.mail.mud.yahoo.com>
References: <832336.16287.qm@web32804.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.64.0706141628090.962@tajo.ucsd.edu>



I think

 	your.df <- as.data.frame( as.table( your.matrix ) )

 	colnames( your.df ) <- c( "i", "j", "Q" )

 	write.table( your.df, file = your.file.name, row.names=FALSE )

will do this.

Chuck

On Thu, 14 Jun 2007, philozine wrote:

> Hi R-listers,
>
> I'm using R only for a few basic functions but am having difficulty doing something that *should* be simple. I have an nxn matrix, Q, where Q[i,j] is a directed value (in this case, oil exports from i to j). Note that Q[i,j]~=Q[j,i]. I imported column names along with the matrix then copied them to the rows using rownames(Q) <- colnames(Q). Simple so far.
>
> What I'd like to do now is convert Q for export into a vector of values with the original row and column names intact. Having one vector each for row, column, and cell would be ideal, e.g., [1,1] = i's name, [1,2] = j's name, and [1,3] = Q[i, j]. But just being able to export my matrix data in vector form with the correct row/col names for each observation would be sufficient.
>
> Thus far I've tried c(), vector(), and a few others, but can't get the correct results. They do generate the correct vector of matrix values, but they do not appear to retain both row and column names. (Or, rather, I have not discovered how to make them do so.)
>
> To illustrate, my data currently look something like this:
>
>    A    B    C    D
> A | 0  |.1 |.4  |.6  |
> B |.2 | 0  |.2  |.1  |
> C |.5  |.9  | 0  |.9  |
> D |.7  | 0  |.3  | 0  |
>
> I would like them to look like this (at least when exported as a .txt file, if not necessary when displayed within R):
>
>  i   j   Q
> | A | A | 0 |
> | A | B |.1 |
> | A | C |.4 |
> | A | D |.6 |
> | B | A |.2 |
> | B | B | 0 |
> | B | C |.2 |
> [...] and so on
>
> If anybody knows how to do this, I will be extremely appreciative!
>
> Best regards,
>
>
>
> ---------------------------------
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	            UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901


From irishhacker at gmail.com  Fri Jun 15 02:35:18 2007
From: irishhacker at gmail.com (Robert Wilkins)
Date: Thu, 14 Jun 2007 19:35:18 -0500
Subject: [R] Tools For Preparing Data For Analysis
In-Reply-To: <466BD19F.4020903@biostat.ku.dk>
References: <874da0b40706071701m55cd42fem15f55a8fcde04f17@mail.gmail.com>
	<40e66e0b0706080547o5c630ac3ne5feadc4247e289a@mail.gmail.com>
	<466BD19F.4020903@biostat.ku.dk>
Message-ID: <874da0b40706141735w4b30f4d9s51bf5ac84e6e3ccf@mail.gmail.com>

[ Arrggh, not reply , but reply to all , cross my fingers again , sorry Peter! ]

Hmm,

I don't think you need a retain statement.

if first.patientID ;
or
if last.patientID ;

ought to do it.

It's actually better than the Vilno version, I must admit, a bit more concise:

if ( not firstrow(patientID) ) deleterow ;

Ah well.

**********************************
For the folks asking for location of software ( I know posted it, but
it didn't connect to the thread, and you get a huge number of posts
each day , sorry):

Vilno , find at
http://code.google.com/p/vilno

DAP & PSPP,  find at
http://directory.fsf.org/math/stats

Awk, find at lots of places,
http://www.gnu.org/software/gawk/gawk.html

Anything else? DAP & PSPP are hard to find, I'm sure there's more out there!
What about MDX? Nahh, not really the right problem domain.
Nobody uses MDX for this stuff.

******************************************************

If my examples , using clinical trial data are boring and hard to
understand for those who asked for examples
( and presumably don't work in clinical trials) , let me
know. Some of these other examples I'm reading about are quite interesting.
It doesn't help that clinical trial databases cannot be public. Making
a fake database would take a lot of time.
The irony is , even with my deep understanding of data preparation in
clinical trials,
the pharmas still don't want to give me a job ( because I was gone for
many years).

********************************************************
Let's see if this post works : thanks to the folks who gave me advice
on how to properly respond to a post within a  thread . ( Although the
thread in my gmail account is only a subset of the posts visible in
the archives ). Crossing my fingers ....

On 6/10/07, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
> Douglas Bates wrote:
> > Frank Harrell indicated that it is possible to do a lot of difficult
> > data transformation within R itself if you try hard enough but that
> > sometimes means working against the S language and its "whole object"
> > view to accomplish what you want and it can require knowledge of
> > subtle aspects of the S language.
> >
> Actually, I think Frank's point was subtly different: It is *because* of
> the differences in view that it sometimes seems difficult to find the
> way to do something in R that  is apparently straightforward in SAS.
> I.e. the solutions exist and are often elegant, but may require some
> lateral thinking.
>
> Case in point: Finding the first or the last observation for each
> subject when there are multiple records for each subject. The SAS way
> would be a datastep with IF-THEN-DELETE, and a RETAIN statement so that
> you can compare the subject ID with the one from the previous record,
> working with data that are sorted appropriately.
>
> You can do the same thing in R with a for loop, but there are better
> ways e.g.
> subset(df,!duplicated(ID)), and subset(df, rev(!duplicated(rev(ID))), or
> maybe
> do.call("rbind",lapply(split(df,df$ID), head, 1)), resp. tail. Or
> something involving aggregate(). (The latter approaches generalize
> better to other within-subject functionals like cumulative doses, etc.).
>
> The hardest cases that I know of are the ones where you need to turn one
> record into many, such as occurs in survival analysis with
> time-dependent, piecewise constant covariates. This may require
> "transposing the problem", i.e. for each  interval you find out which
> subjects contribute and with what, whereas the SAS way would be a
> within-subject loop over intervals containing an OUTPUT statement.
>
> Also, there are some really weird data formats, where e.g. the input
> format is different in different records. Back in the 80's where
> punched-card input was still common, it was quite popular to have one
> card with background information on a patient plus several cards
> detailing visits, and you'd get a stack of cards containing both kinds.
> In R you would most likely split on the card type using grep() and then
> read the two kinds separately and merge() them later.
>
>


From dunn at usq.edu.au  Fri Jun 15 02:42:34 2007
From: dunn at usq.edu.au (Peter Dunn)
Date: Fri, 15 Jun 2007 10:42:34 +1000
Subject: [R] sma package, and MouseArray data set
Message-ID: <200706151042.34245.dunn@usq.edu.au>

Hi all

I have just downloaded the  sma  package from CRAN.
On installing on my linux machine, I get the message


> library(sma)
> data(MouseArray)
Warning message:
file 'MouseArray.RData' has magic number 'RDX1'
   Use of save versions prior to 2 is deprecated


Hereafter,  MouseArray  is not found:

> MouseArray
Error: object "MouseArray" not found


We were hoping to use the  MouseArray  data with  some
of the  sma  functions.

Since the data seems the only problem, is the data
available elsewhere in this form?  Or is there an easy 
work-around?

I have tried contacting the listed maintainer (Benjamin Bolstad),
but the listed email address (mb at bmbolstad.com) bounced.

Thanks.

P.


> sessionInfo()
R version 2.5.0 (2007-04-23)
i486-pc-linux-gnu

locale:
LC_CTYPE=en_AU.UTF-8;LC_NUMERIC=C;LC_TIME=en_AU.UTF-8;LC_COLLATE=en_AU.UTF-8;LC_MONETARY=en_AU.UTF-8;LC_MESSAGES=en_AU.UTF-8;LC_PAPER=en_AU.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_AU.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
[7] "base"

other attached packages:
     sma
"0.5.15"




-- 
Dr Peter Dunn  |  dunn <at> usq.edu.au
Faculty of Sciences, USQ; http://www.sci.usq.edu.au/staff/dunn
Aust. Centre for Sustainable Catchments: www.usq.edu.au/acsc

This email (including any attached files) is confidential an...{{dropped}}


From vincent.goulet at act.ulaval.ca  Fri Jun 15 02:51:05 2007
From: vincent.goulet at act.ulaval.ca (Vincent Goulet)
Date: Thu, 14 Jun 2007 20:51:05 -0400
Subject: [R] R Book Advice Needed
In-Reply-To: <46702744.50401@skynet.be>
References: <OF88CDFD73.E09BD8D4-ON882572F8.007C06BE-882572F8.007BEB02@irvine.edwards.com>
	<46702744.50401@skynet.be>
Message-ID: <71C823DC-8450-440F-A52F-A000C7B70192@act.ulaval.ca>

Alain,

I didn't notice you can read French when I first saw your message.

If you want to start learning R by the programming language, you  
might appreciate my document "Introduction ? la programmation en S",  
available in the Contributed documentation - Other languages - French  
on CRAN. The document will form the basis of the book I should  
publish with Springer in 2008.

Comments appreciated.

Le 07-06-13 ? 13:20, Alain Reymond a ?crit :

> Cody,
>
> I plan to use it in life sciences. We use of course basic descriptive
> statistics but also classification using ACP and CAH (French
> abbreviation for Principal Component Analysis and Hierarchical Cluster
> Analysis). We also use logistic regression for classifying some  
> results
> of clinical laboratory analyses.
>
> In fact, I have been a user of SPSS for - quite - a long time. The  
> price
> of the licences are increasing and it becomes a problem for us (many
> thousand of euros). I am the only user and don't work with the  
> programs
> on a daily basis. So - I confess - I am investigating R. And I am more
> and more convinced by the possibilities it offers.
>
> Regards.
>
> Alain
>
> Cody_Hamilton at edwards.com a ?crit :
>> Alain,
>>
>> Can you tell us what you plan to use R for?
>>
>> Regards,
>> -Cody
>>
>> ngottlieb at marinercapital.com a ?crit :
>>
>>> I am new to using R and would appreciate some advice on
>>> which books to start with to get up to speed on using R.
>>> ...cut...
>>>
> -- 
> Alain Reymond
> CEIA
> Bruxelles
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



---
   Vincent Goulet, Professeur agr?g?
   ?cole d'actuariat
   Universit? Laval, Qu?bec
   Vincent.Goulet at act.ulaval.ca   http://vgoulet.act.ulaval.ca


From adschai at optonline.net  Fri Jun 15 03:41:41 2007
From: adschai at optonline.net (adschai at optonline.net)
Date: Fri, 15 Jun 2007 01:41:41 +0000 (GMT)
Subject: [R] Question with nlm
Message-ID: <e426c8c0e6c1.4671ee55@optonline.net>

Hi,

I would really appreciate if I could get some help here. I'm using nlm to minimize my negative log likelihood function. What I did is as follows:

My log likelihood function (it returns negative log likelihood) with 'gradient' attribute defined inside as follows:

# ==========Method definition======================
logLikFunc3 <- function(sigma, object, totalTime) {
    y <- as.matrix(object at data$output[1:totalTime,1]);
    x <- as.matrix(object at data$input[1:totalTime,]);
    # compute necessary matrices
    M <- as.matrix(object at model$M);
    P <- diag(sigma*sigma);
    A <- AMatrix(totalTime, M, object at data$input[1:totalTime,]);
    Q <- IMatrix(totalTime)+A %*% outerM(IMatrix(totalTime-1),P) %*% t(A);
    invQ <- solve(Q,IMatrix(dim(Q)[1]));
    xM <- matrix(rep(0, dim(M)[2]*totalTime), ncol=dim(M)[2], nrow=totalTime);
    for (i in 1:totalTime) {
       xM[i,] <- x[i,] %*% powerM(M, -totalTime+i);
    }
    tmp <- solve((t(xM) %*% invQ %*% xM), IMatrix(dim(xM)[2]));
    Bt <- (tmp %*% t(xM)) %*% (invQ %*% y);
    N <- IMatrix(totalTime)-(xM %*% tmp %*% t(xM) %*% invQ);
    
    sigma2 <- (1/totalTime) * t(y- xM %*% Bt)%*% invQ %*% (y- xM %*% Bt);
    # log likelihood function
    loglik <- -0.5*log(abs(det(diag(rep(sigma2,totalTime)))))-0.5*log(abs(det(Q)))-
       (0.5/sigma2)* (t(y- (xM%*% Bt)) %*% invQ %*% (y-(xM %*% Bt)));

    sgm <- sigma;
    # gradients eq. (4.16)
    gr <- function(sgm) {
       gradVecs <- c();
       # sgm <- c(sigma1, sigma2);
       sgm <- sgm*sgm;
       for (i in 1:length(sgm)) {
          Eij <- matrix(rep(0, length(sgm)^2), nrow=length(sgm), ncol=length(sgm));
          Eij[i,i] <- 1.0;
          # trace term
          term1 <- -sum(diag((invQ %*% A) %*% outerM(IMatrix(totalTime-1),Eij) %*% t(A)));
          # very long term
          term2 <- (1/totalTime)*solve((t(y) %*% t(N) %*% invQ %*% y), IMatrix(dim(y)[2]));
          term3 <- (t(y) %*% t(N) %*% invQ %*% A) %*% outerM(IMatrix(totalTime-1),Eij) %*% (t(A) %*% invQ %*% N %*% y);
          gradVecs <- -1*c(gradVecs, term1+ (term2 %*% term3));
       } # end for
       print(paste("Gradient has length:", length(gradVecs)));
       return(gradVecs);
    }
    res <- -loglik;
    attr(res, "gradient") <-  gradVecs;
    return(res);
}
#=========end method definition=====================================

Then when I call the nlm on this function, i.e.

nlm(f=logLikFunc3, p=as.numeric(c(1,1)), object=this, totalTime=200, print.level=2)

It complains that my analytic gradient returns vector length different from number of my unknowns. In this case, I tried print the length of gradient vector that I returned (as you could see in the code). It has the same length as my input parameter vectors. Did I do anything wrong here?

Also, I would like to be able to put some constraints on this optimization as well. I tried constrOptim with:

ui <- diag(c(1,1));
ci <- matrix(rep(0,2), ncol=1, nrow=2);

using the same parameters passed to nlm above. constrOptim gives me an error that initial value is in infeasible region which I don't quite understand. As my constraints simply says that the two parameters must be greater than zero. My assigned initial values are both 1. So it should be ok. Any help would be really appreciated. Thank you.

- adschai


From atyre2 at unlnotes.unl.edu  Fri Jun 15 03:59:33 2007
From: atyre2 at unlnotes.unl.edu (Andrew J Tyre)
Date: Thu, 14 Jun 2007 20:59:33 -0500
Subject: [R] converting character strings to numbers
Message-ID: <OF5E761867.7175B709-ON862572FB.000A9272-862572FB.000AF244@unl.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070614/53bdadff/attachment.pl 

From ggrothendieck at gmail.com  Fri Jun 15 04:26:34 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 14 Jun 2007 22:26:34 -0400
Subject: [R] converting character strings to numbers
In-Reply-To: <OF5E761867.7175B709-ON862572FB.000A9272-862572FB.000AF244@unl.edu>
References: <OF5E761867.7175B709-ON862572FB.000A9272-862572FB.000AF244@unl.edu>
Message-ID: <971536df0706141926u43d83b16ocb932abe7fb4acc2@mail.gmail.com>

See:

https://stat.ethz.ch/pipermail/r-help/2007-April/130912.html

On 6/14/07, Andrew J Tyre <atyre2 at unlnotes.unl.edu> wrote:
> I have a comma delimited text file in which many columns of numbers are
> also quoted and have commas as well as decimals. I was surprised to find
> read.csv() didn't import this seamlessly, even after messing around with
> the colClasses argument. I did find a solution to convert the character
> strings after reading them in, but wonder if there isn't a better one I
> overlooked.
>
> test = c("10,522.5","11,768.9","11,354.3")
> as.numeric(test) # fails
> as.numeric(gsub(",","",test)) # works
>
> Any suggestions? Or is this as good as it gets? I'm not complaining ...
> just curious!
>
> Drew Tyre
>
> School of Natural Resources
> University of Nebraska-Lincoln
> 416 Hardin Hall, East Campus
> Lincoln, NE 68583-0974
> phone: +1 402 472 4054 fax: +1 402 472 2946
> email: atyre2 at unl.edu
> http://snr.unl.edu/tyre
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Inman.Brant at mayo.edu  Fri Jun 15 04:45:31 2007
From: Inman.Brant at mayo.edu (Brant Inman)
Date: Thu, 14 Jun 2007 19:45:31 -0700 (PDT)
Subject: [R] MITOOLS:   Error in eval(expr, envir,
 enclos) : invalid 'envir' argument
In-Reply-To: <6021CA6EF4C8374084D4F5A141F1CBBBC14D00@msgebe23.mfad.mfroot.org>
References: <6021CA6EF4C8374084D4F5A141F1CBBBC14D00@msgebe23.mfad.mfroot.org>
Message-ID: <11132419.post@talk.nabble.com>


Update:  error solved.

The error was that one of the imputed datasets had a singular matrix.  As
such, when eval tried to run the expression on that dataset (i.e.
environment) it did not find an appropriate dataset and therefore the
function returned an error.  In other words, the problem was a bad input to
the with.imputationList function.



Brant Inman wrote:
> 
> 
> R-users & helpers:
> 
> I am using Amelia, mitools and cmprsk to fit cumulative incidence curves
> to multiply imputed datasets.  The error message that I get 
> 
> "Error in eval(expr, envir, enclos) : invalid 'envir' argument"
> 
> occurs when I try to fit models to the 50 imputed datasets using the
> "with.imputationList" function of mitools.  The problem seems to occur
> intermittently, depending on the type of model that I try to fit to the
> datasets as well as the previous code that has been executed during the
> R session.  I have read the previous postings for similar problems and
> have tried renaming many of my objects which has not solved the problem.
> 
> 
> What is weird is that I have not been able to reproduce the problem
> using other standard survival datasets (like pbc). It therefore seems to
> have something to do with my particular analysis, likely the names of my
> objects.  I cannot find the source of the problem and would greatly
> appreciate any help.
> 
> Brant
> 
> Below is my session information and some code demonstrating the issue
> occuring with coxph.
> 
>> sessionInfo()
> R version 2.5.0 (2007-04-23) 
> i386-pc-mingw32 
> 
> locale:
> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
> 
> attached base packages:
> [1] "splines"   "grid"      "stats"     "graphics"  "grDevices" "utils"
> 
> [7] "datasets"  "methods"   "base"     
> 
> other attached packages:
>       cmprsk      mitools       Amelia     survival    RGraphics
> latticeExtra 
>      "2.1-7"        "1.0"     "1.1-23"       "2.31"      "1.0-6"
> "0.2-1" 
>      lattice      foreign         MASS 
>     "0.15-8"     "0.8-20"     "7.2-34" 
> 
> 
>> str(utt.mi)    # My dataset
> 'data.frame':   168 obs. of  25 variables:
>  $ age      : num  79.5 67.1 63.7 76.9 69.0 ...
>  $ gender   : Factor w/ 2 levels "0","1": 1 2 2 2 1 2 2 2 2 2 ...
>  $ symptoms : Factor w/ 2 levels "0","1": 1 2 1 1 2 1 2 1 1 2 ...
>  $ site     : Factor w/ 3 levels "1","2","3": 1 1 2 1 2 1 1 2 1 3 ...
>  $ multifoc : Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 1 1 2 ...
>  $ ctnm     : Factor w/ 2 levels "1","2": 1 NA 2 1 2 2 1 NA 1 2 ...
>  $ prebca   : Factor w/ 2 levels "0","1": 1 1 1 1 2 1 2 1 1 1 ...
>  $ precystec: Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 1 1 1 ...
>  $ surgery  : Factor w/ 2 levels "1","2": 1 1 2 1 2 1 1 1 1 1 ...
>  $ ptnm.t   : Factor w/ 5 levels "0","1","2","3",..: 3 3 5 1 2 4 2 1 1 5
> ...
>  $ grade    : Factor w/ 3 levels "1","2","3": 2 2 3 2 2 3 2 1 1 3 ...
>  $ histol   : Factor w/ 2 levels "0","1": 2 2 2 2 2 2 2 2 2 2 ...
>  $ postbca  : Factor w/ 2 levels "0","1": 2 1 2 2 2 NA 2 1 1 1 ...
>  $ postcyst : Factor w/ 2 levels "0","1": 1 1 1 2 1 1 1 1 1 1 ...
>  $ chemo    : Factor w/ 2 levels "0","1": 1 1 2 1 1 2 2 1 1 2 ...
>  $ mets     : Factor w/ 2 levels "0","1": 1 2 2 1 2 2 2 1 1 2 ...
>  $ status   : Factor w/ 4 levels "1","2","3","4": 1 3 2 1 3 3 3 1 1 3
> ...
>  $ futime   : num  10.46  1.15  2.43  2.83  6.82 ...
>  $ smk      : Factor w/ 2 levels "0","1": 2 2 2 1 2 1 2 1 2 2 ...
>  $ surg.yr  : int  88 94 92 93 86 85 95 98 91 85 ...
>  $ nodes    : Factor w/ 2 levels "0","1": 1 1 2 1 1 2 1 1 1 2 ...
>  $ os       : num  0 1 0 0 1 1 1 0 0 1 ...
>  $ css      : num  0 1 0 0 1 1 1 0 0 1 ...
>  $ rfs      : num  0 1 1 0 1 1 1 0 0 1 ...
>  $ comp     : num  0 1 1 0 1 1 1 0 0 1 ...
> 
>> set.seed(200)
>> M <- 50 			# Number of imputations
>> am.imp <- amelia(utt.mi, m=M, p2s=1, startvals=1, write.out=F,
> + idvars=c('os','css','rfs','comp'), 
> +
> noms=c('gender','symptoms','site','multifoc','ctnm','prebca','precystec'
> ,
> + 'smk','surgery','ptnm.t','nodes','grade','histol','postbca',
> + 'postcyst','chemo','mets','status'),
> + sqrts=c('futime'))
> -- Imputation 1 --
> 
>  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 
> 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 
> 
> <snip>
> 
> -- Imputation 50 --
> 
>  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 
> 21 22 23 24 25 26 
> 
>> MIset <- imputationList(am.imp[1:M])
>> mifit <- with(MIset, 
> + coxph(Surv(futime, os) ~ age + symptoms + ctnm + smk))
> 
> Error in eval(expr, envir, enclos) : invalid 'envir' argument
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/MITOOLS%3A---Error-in-eval%28expr%2C-envir%2C-enclos%29-%3A-invalid-%27envir%27-argument-tf3885940.html#a11132419
Sent from the R help mailing list archive at Nabble.com.


From jmacdon at med.umich.edu  Fri Jun 15 04:55:02 2007
From: jmacdon at med.umich.edu (James W. MacDonald)
Date: Thu, 14 Jun 2007 22:55:02 -0400
Subject: [R] sma package, and MouseArray data set
In-Reply-To: <200706151042.34245.dunn@usq.edu.au>
References: <200706151042.34245.dunn@usq.edu.au>
Message-ID: <4671FF86.2040106@med.umich.edu>

Peter Dunn wrote:
> Hi all
> 
> I have just downloaded the  sma  package from CRAN.
> On installing on my linux machine, I get the message
> 
> 
> 
>>library(sma)
>>data(MouseArray)
> 
> Warning message:
> file 'MouseArray.RData' has magic number 'RDX1'
>    Use of save versions prior to 2 is deprecated
> 
> 
> Hereafter,  MouseArray  is not found:
> 
> 
>>MouseArray
> 
> Error: object "MouseArray" not found
> 
> 
> We were hoping to use the  MouseArray  data with  some
> of the  sma  functions.
> 
> Since the data seems the only problem, is the data
> available elsewhere in this form?  Or is there an easy 
> work-around?
> 
> I have tried contacting the listed maintainer (Benjamin Bolstad),
> but the listed email address (mb at bmbolstad.com) bounced.

It's bmb at bmbolstad.com.

Best,

Jim


> 
> Thanks.
> 
> P.
> 
> 
> 
>>sessionInfo()
> 
> R version 2.5.0 (2007-04-23)
> i486-pc-linux-gnu
> 
> locale:
> LC_CTYPE=en_AU.UTF-8;LC_NUMERIC=C;LC_TIME=en_AU.UTF-8;LC_COLLATE=en_AU.UTF-8;LC_MONETARY=en_AU.UTF-8;LC_MESSAGES=en_AU.UTF-8;LC_PAPER=en_AU.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_AU.UTF-8;LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
> [7] "base"
> 
> other attached packages:
>      sma
> "0.5.15"
> 
> 
> 
> 


-- 
James W. MacDonald
University of Michigan
Affymetrix and cDNA Microarray Core
1500 E Medical Center Drive
Ann Arbor MI 48109
734-647-5623



**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues.


From megh700004 at yahoo.com  Fri Jun 15 06:22:04 2007
From: megh700004 at yahoo.com (Megh Dal)
Date: Thu, 14 Jun 2007 21:22:04 -0700 (PDT)
Subject: [R] Panel data
Message-ID: <738120.60739.qm@web58105.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070614/71894c95/attachment.pl 

From connect.chris at gmail.com  Fri Jun 15 07:14:24 2007
From: connect.chris at gmail.com (Chris Linton)
Date: Fri, 15 Jun 2007 01:14:24 -0400
Subject: [R] importing .dta files
Message-ID: <b05bf6c40706142214i24ef2f33tbad26e0df9e785d2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070615/0105d2ef/attachment.pl 

From ripley at stats.ox.ac.uk  Fri Jun 15 07:52:38 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 15 Jun 2007 06:52:38 +0100 (BST)
Subject: [R] sma package, and MouseArray data set
In-Reply-To: <200706151042.34245.dunn@usq.edu.au>
References: <200706151042.34245.dunn@usq.edu.au>
Message-ID: <Pine.LNX.4.64.0706150649130.28253@gannet.stats.ox.ac.uk>

On Fri, 15 Jun 2007, Peter Dunn wrote:

> Hi all
>
> I have just downloaded the  sma  package from CRAN.
> On installing on my linux machine, I get the message
>
>
>> library(sma)
>> data(MouseArray)
> Warning message:
> file 'MouseArray.RData' has magic number 'RDX1'
>   Use of save versions prior to 2 is deprecated
>
>
> Hereafter,  MouseArray  is not found:
>
>> MouseArray
> Error: object "MouseArray" not found

But try

> ls()
  [1] "cl"           "i"            "mouse.data"   "mouse.gnames" "mouse.lratio"
  [6] "mouse.setup"  "mouse.t2"     "mouse1"       "mouse2"       "mouse3"
[11] "mouse4"       "mouse5"       "mouse6"       "ot"           "str"
[16] "txt"

If all else fails you could read the help: ?MouseArray tells you what it 
gives you.

> We were hoping to use the  MouseArray  data with  some
> of the  sma  functions.

As the examples on the help pages do.

[...]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri Jun 15 08:04:14 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 15 Jun 2007 07:04:14 +0100 (BST)
Subject: [R] converting character strings to numbers
In-Reply-To: <OF5E761867.7175B709-ON862572FB.000A9272-862572FB.000AF244@unl.edu>
References: <OF5E761867.7175B709-ON862572FB.000A9272-862572FB.000AF244@unl.edu>
Message-ID: <Pine.LNX.4.64.0706150656080.28253@gannet.stats.ox.ac.uk>

There is no support for 'thousands separators' in R's input/conversion 
routines, mainly because C has no support either (not even for output in 
the C standard).  We could of course add our own layer, but as far as I am 
aware this is the first time this has come up.

On Thu, 14 Jun 2007, Andrew J Tyre wrote:

> I have a comma delimited text file in which many columns of numbers are
> also quoted and have commas as well as decimals. I was surprised to find
> read.csv() didn't import this seamlessly, even after messing around with
> the colClasses argument. I did find a solution to convert the character
> strings after reading them in, but wonder if there isn't a better one I
> overlooked.
>
> test = c("10,522.5","11,768.9","11,354.3")
> as.numeric(test) # fails
> as.numeric(gsub(",","",test)) # works
>
> Any suggestions? Or is this as good as it gets? I'm not complaining ...
> just curious!
>
> Drew Tyre
>
> School of Natural Resources
> University of Nebraska-Lincoln
> 416 Hardin Hall, East Campus
> Lincoln, NE 68583-0974
> phone: +1 402 472 4054 fax: +1 402 472 2946
> email: atyre2 at unl.edu
> http://snr.unl.edu/tyre
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From forum at dejung.net  Fri Jun 15 08:12:45 2007
From: forum at dejung.net (Mario Dejung)
Date: Fri, 15 Jun 2007 08:12:45 +0200 (CEST)
Subject: [R] problem with hist()
In-Reply-To: <467149D0.1030006@statistik.uni-dortmund.de>
References: <34232.134.93.157.71.1181824247.squirrel@webmail.ts-cs.de>
	<467149D0.1030006@statistik.uni-dortmund.de>
Message-ID: <53707.134.93.157.71.1181887965.squirrel@webmail.ts-cs.de>

>
>
> Mario Dejung wrote:
>> Hey everybody,
>> I try to make a graph with two different plots.
>>
>>
>> First I make a boxplot of my data. It is a collection off correlation
>> values of different pictures. For example:
>>
>> 0.23445 pica
>> 0.34456 pica
>> 0.45663 pica
>> 0.98822 picb
>> 0.12223 picc
>> 0.34443 picc
>> etc.
>>
>> Ok, I make this boxplot and I get for every picture the boxes. After
>> this
>> I want to know, how many correlations per picture exist.
>> So I make a new vector y <- as.numeric(data$picture)
>>
>> So I get for my example something like this:
>>
>> y
>> [1] 1 1 1 1 1 1 1 1 1 1
>> [11] 1 1 1 1 1 1 1 1 2 2
>> ...
>> [16881] 59 59 59 60 60 60 60 60 60 60
>>
>> After this I make something like this
>>
>> boxplot(cor ~ pic)
>> par(new = TRUE)
>> hist(y, nclass = 60)
>>
>> But there is my problem. I have 60 pictures, so I get 60 different
>> boxplots, and I want the hist behind the boxes. But it makes only 59
>> histbars.
>>
>> What can I do? I tried also
>> hist(y, 1:60) # same effect
>> and
>> hist(y, 1:61)
>> this give me 60 places, but only 59 bars. the last bar is 0.
>
>
> In fact, I am pretty sure you really want to have a barplot() rather
> than a histogram. If you really want to use hist(), then perhaps hist(y,
> 0:60).
>
> Uwe Ligges
>
Ok, it seems you are right, but I'm a beginner in R, so maybe you can help
me a little bit more.

When I use the hist function, it automatically uses the frequency of the
different numbers, so I will get normally 60 bars.

When I use the barplot function, then I have to count the frequency of the
numbers. Is there a function who can do this, or should I write a function
on my own.

Sorry, I'm sure it is a stupid question, but maybe someone can give me a
good reference for answers, because I am a beginner :-)

Thanks to everyone
Mario

>
>
>> I hope anyone can help me.
>>
>> Regards Mario
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From h.wickham at gmail.com  Fri Jun 15 08:27:22 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 15 Jun 2007 08:27:22 +0200
Subject: [R] problem with hist()
In-Reply-To: <34232.134.93.157.71.1181824247.squirrel@webmail.ts-cs.de>
References: <34232.134.93.157.71.1181824247.squirrel@webmail.ts-cs.de>
Message-ID: <f8e6ff050706142327g789d2204q36d4a225e6e0ca2b@mail.gmail.com>

On 6/14/07, Mario Dejung <forum at dejung.net> wrote:
> Hey everybody,
> I try to make a graph with two different plots.
>
>
> First I make a boxplot of my data. It is a collection off correlation
> values of different pictures. For example:
>
> 0.23445 pica
> 0.34456 pica
> 0.45663 pica
> 0.98822 picb
> 0.12223 picc
> 0.34443 picc
> etc.
>
> Ok, I make this boxplot and I get for every picture the boxes. After this
> I want to know, how many correlations per picture exist.
> So I make a new vector y <- as.numeric(data$picture)
>
> So I get for my example something like this:
>
> y
> [1] 1 1 1 1 1 1 1 1 1 1
> [11] 1 1 1 1 1 1 1 1 2 2
> ...
> [16881] 59 59 59 60 60 60 60 60 60 60
>
> After this I make something like this
>
> boxplot(cor ~ pic)
> par(new = TRUE)
> hist(y, nclass = 60)
>
> But there is my problem. I have 60 pictures, so I get 60 different
> boxplots, and I want the hist behind the boxes. But it makes only 59
> histbars.
>
> What can I do? I tried also
> hist(y, 1:60) # same effect
> and
> hist(y, 1:61)
> this give me 60 places, but only 59 bars. the last bar is 0.
>
> I hope anyone can help me.

What does the y axis represent?  It will be counts for the histogram,
and correlations for the boxplots.  These aren't comparable, so you're
probably better off making two separate graphics.

Hadley


From ligges at statistik.uni-dortmund.de  Fri Jun 15 09:24:40 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 15 Jun 2007 09:24:40 +0200
Subject: [R] problem with hist()
In-Reply-To: <53707.134.93.157.71.1181887965.squirrel@webmail.ts-cs.de>
References: <34232.134.93.157.71.1181824247.squirrel@webmail.ts-cs.de>
	<467149D0.1030006@statistik.uni-dortmund.de>
	<53707.134.93.157.71.1181887965.squirrel@webmail.ts-cs.de>
Message-ID: <46723EB8.70308@statistik.uni-dortmund.de>



Mario Dejung wrote:
>>
>> Mario Dejung wrote:
>>> Hey everybody,
>>> I try to make a graph with two different plots.
>>>
>>>
>>> First I make a boxplot of my data. It is a collection off correlation
>>> values of different pictures. For example:
>>>
>>> 0.23445 pica
>>> 0.34456 pica
>>> 0.45663 pica
>>> 0.98822 picb
>>> 0.12223 picc
>>> 0.34443 picc
>>> etc.
>>>
>>> Ok, I make this boxplot and I get for every picture the boxes. After
>>> this
>>> I want to know, how many correlations per picture exist.
>>> So I make a new vector y <- as.numeric(data$picture)
>>>
>>> So I get for my example something like this:
>>>
>>> y
>>> [1] 1 1 1 1 1 1 1 1 1 1
>>> [11] 1 1 1 1 1 1 1 1 2 2
>>> ...
>>> [16881] 59 59 59 60 60 60 60 60 60 60
>>>
>>> After this I make something like this
>>>
>>> boxplot(cor ~ pic)
>>> par(new = TRUE)
>>> hist(y, nclass = 60)
>>>
>>> But there is my problem. I have 60 pictures, so I get 60 different
>>> boxplots, and I want the hist behind the boxes. But it makes only 59
>>> histbars.
>>>
>>> What can I do? I tried also
>>> hist(y, 1:60) # same effect
>>> and
>>> hist(y, 1:61)
>>> this give me 60 places, but only 59 bars. the last bar is 0.
>>
>> In fact, I am pretty sure you really want to have a barplot() rather
>> than a histogram. If you really want to use hist(), then perhaps hist(y,
>> 0:60).
>>
>> Uwe Ligges
>>
> Ok, it seems you are right, but I'm a beginner in R, so maybe you can help
> me a little bit more.
> 
> When I use the hist function, it automatically uses the frequency of the
> different numbers, so I will get normally 60 bars.
> 
> When I use the barplot function, then I have to count the frequency of the
> numbers. Is there a function who can do this, or should I write a function
> on my own.

You are looking for table().


> Sorry, I'm sure it is a stupid question, but maybe someone can give me a
> good reference for answers, because I am a beginner :-)

There are several manuals, books and the mailing list archives.

Uwe Ligges



> Thanks to everyone
> Mario
> 
>>
>>> I hope anyone can help me.
>>>
>>> Regards Mario
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
>


From robert.ptacnik at niva.no  Fri Jun 15 09:06:53 2007
From: robert.ptacnik at niva.no (robert.ptacnik at niva.no)
Date: Fri, 15 Jun 2007 09:06:53 +0200
Subject: [R] interpretation of F-statistics in GAMs
Message-ID: <OFB56A7571.DC604C2B-ONC12572FB.0027155F-C12572FB.00271563@niva.no>






dear listers,
I use gam (from mgcv) for evaluation of shape and strength of relationships
between a response variable and several predictors.
How can I interpret the 'F' values viven in the GAM summary? Is it
appropriate to treat them in a similar manner as the T-statistics in a
linear model, i.e. larger values mean that this variable has a stronger
impact than a variable with smaller F?
When I run my analysis for two different response varables (but identical
predictors), is there a way to compare the F values among tests (like to
standardize them by teh sum of F within each test?) I append two summaries
below.
Thanks in advance,
Robert


### example 1 ###

Family: gaussian
Link function: identity

Formula:
dep[sel, i] ~ s(date, k = 3) + s(depth, k = kn) + s(temp, k = kn) +
    s(light, k = kn) + s(PO4, k = kn) + s(DIN, k = kn) + s(prop.agpla,
    k = kn)

Parametric coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)   5.1048     0.0384   132.9   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Approximate significance of smooth terms:
                edf Est.rank      F  p-value
s(date)       1.669        2 12.161 1.07e-05 ***
s(depth)      1.671        2 36.125 4.85e-14 ***
s(temp)       1.927        2  6.686  0.00156 **
s(light)      1.886        2 12.604 7.20e-06 ***
s(PO4)        1.676        2  3.237  0.04143 *
s(DIN)        1.000        1 38.428 3.41e-09 ***
s(prop.agpla) 1.405        2 15.987 3.79e-07 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

R-sq.(adj) =  0.687   Deviance explained = 70.5%
GCV score = 0.31995   Scale est. = 0.30076   n = 204

### example 2 ###
Family: gaussian
Link function: identity

Formula:
dep[sel, i] ~ s(date, k = 3) + s(depth, k = kn) + s(temp, k = kn) +
    s(light, k = kn) + s(PO4, k = kn) + s(DIN, k = kn) + s(prop.agpla,
    k = kn)

Parametric coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)  7.13588    0.05549   128.6   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Approximate significance of smooth terms:
                edf Est.rank      F  p-value
s(date)       1.944        2 15.997 3.67e-07 ***
s(depth)      1.876        2 25.427 1.52e-10 ***
s(temp)       1.000        1  2.866   0.0921 .
s(light)      1.751        2  4.212   0.0162 *
s(PO4)        1.950        2 10.632 4.14e-05 ***
s(DIN)        1.805        2 10.745 3.73e-05 ***
s(prop.agpla) 1.715        2  2.674   0.0715 .
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

 R-sq.(adj) =  0.479   Deviance explained = 50.9%
GCV score = 0.6863   Scale est. = 0.64348   n = 209


From h.wickham at gmail.com  Fri Jun 15 09:38:25 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 15 Jun 2007 09:38:25 +0200
Subject: [R] problem with hist()
In-Reply-To: <59791.134.93.157.71.1181889535.squirrel@webmail.ts-cs.de>
References: <34232.134.93.157.71.1181824247.squirrel@webmail.ts-cs.de>
	<f8e6ff050706142327g789d2204q36d4a225e6e0ca2b@mail.gmail.com>
	<59791.134.93.157.71.1181889535.squirrel@webmail.ts-cs.de>
Message-ID: <f8e6ff050706150038oe008710k7baedb6a060136fb@mail.gmail.com>

On 6/15/07, Mario Dejung <forum at dejung.net> wrote:
> > On 6/14/07, Mario Dejung <forum at dejung.net> wrote:
> >> Hey everybody,
> >> I try to make a graph with two different plots.
> >>
> >>
> >> First I make a boxplot of my data. It is a collection off correlation
> >> values of different pictures. For example:
> >>
> >> 0.23445 pica
> >> 0.34456 pica
> >> 0.45663 pica
> >> 0.98822 picb
> >> 0.12223 picc
> >> 0.34443 picc
> >> etc.
> >>
> >> Ok, I make this boxplot and I get for every picture the boxes. After
> >> this
> >> I want to know, how many correlations per picture exist.
> >> So I make a new vector y <- as.numeric(data$picture)
> >>
> >> So I get for my example something like this:
> >>
> >> y
> >> [1] 1 1 1 1 1 1 1 1 1 1
> >> [11] 1 1 1 1 1 1 1 1 2 2
> >> ...
> >> [16881] 59 59 59 60 60 60 60 60 60 60
> >>
> >> After this I make something like this
> >>
> >> boxplot(cor ~ pic)
> >> par(new = TRUE)
> >> hist(y, nclass = 60)
> >>
> >> But there is my problem. I have 60 pictures, so I get 60 different
> >> boxplots, and I want the hist behind the boxes. But it makes only 59
> >> histbars.
> >>
> >> What can I do? I tried also
> >> hist(y, 1:60) # same effect
> >> and
> >> hist(y, 1:61)
> >> this give me 60 places, but only 59 bars. the last bar is 0.
> >>
> >> I hope anyone can help me.
> >
> > What does the y axis represent?  It will be counts for the histogram,
> > and correlations for the boxplots.  These aren't comparable, so you're
> > probably better off making two separate graphics.
> >
> > Hadley
> >
> The boxplots show only the median, min, max, etc of the different
> pictures, but I want to know, how many entry's are in this plot. Now I
> have done this by the hist function, and when I use different colors, you
> can see, for the first picture there are about 130 entry, but for the 8th
> picture, there are only 40 entry's...
> Doesn't make this sense?

I think your plot would be more clear if you used two graphics - one
showing the spread, and one showing the number of points (you might
also want to look at notched boxplots).  In the graphic you attached
the bars of the barchart (not histogram! - that's for continuous data)
distract the eye from the boxplots.  You might also want to try
ordering the x axis by mean or number of observations as this will
make it easier to see trends in the data.

The confusion with the barchart arises because there are really two
quite different types of barcharts.  One type is basically the same as
a dotchart, but you draw bars instead of dots - this is the default in
R.  The other type is the categorical analog of the histogram, and
this is the default in ggplot2
(http://had.co.nz/ggplot2/geom_bar.html), allow the next version will
automatically work out which version you want.

Hadley


From arturo.coral at gmail.com  Fri Jun 15 09:51:52 2007
From: arturo.coral at gmail.com (arturo)
Date: 15 Jun 2007 07:51:52 -0000
Subject: [R] arturo invites you to join Zorpia
Message-ID: <20070615075152.27378.qmail@zorpia.com>

Se ha borrado un texto insertado con un juego de caracteres sin especificar...
Nombre: no disponible
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070615/7476048e/attachment.pl 

From cinzia.viroli at unibo.it  Tue Jun 12 15:41:41 2007
From: cinzia.viroli at unibo.it (Cinzia Viroli)
Date: Tue, 12 Jun 2007 15:41:41 +0200
Subject: [R] package with fortran 90 subroutines under windows xp
Message-ID: <6.0.1.1.2.20070612153012.00b96cd0@mail.unibo.it>

Hello,
I work under windows xp and I am trying to build a R package with a 
subroutine written in fortran 90.
I have installed all the updated tools and I am working with R-2.4.0 or 
R-2.5.0.

When I check a package with a subroutine in fortran 77 (and extension f) 
everything is ok.
When I try to build the same package with a subroutine in fortran 90 (with 
extension f90) the following warning appears:

Subdirectory 'src' contains no source files

and the package can not be built.

The funny thing is that I have successfully built the same package with 
fortran 90 last March and everything was good.

I can not imagine what is the problem, could do you help me?





------------------------------------------------------------------------------------------------------------------------------------------------
Cinzia Viroli
Dipartimento di Scienze Statistiche "Paolo Fortunati"
Via delle Belle Arti 41
40126 Bologna
Italy
Ph.  +39 051 2094628
Fax  +39 051 232153

home: www2.stat.unibo.it/viroli


From billycorg1 at virgilio.it  Fri Jun 15 11:29:37 2007
From: billycorg1 at virgilio.it (billycorg)
Date: Fri, 15 Jun 2007 02:29:37 -0700 (PDT)
Subject: [R] problems with matrix, list and other..
Message-ID: <11135888.post@talk.nabble.com>


hi

can anyone help me to solve these problems?

i have:
1) "d" matrix with 1096 rows;
for example, 
d[2]=        
                   [,1]           [,2]          [,3]
[1,] 0.1192566 0.0000000 0.0000000
[2,] 0.0000000 0.1065938 0.0000000
[3,] 0.0000000 0.0000000 0.1038888

if I
class (d[2]) = "list" 
solve(d[2]) = error!!!

2) "e" list ;
for example
e[2]2=
[[1]]
[1] -1.0892216 -0.7304947 -1.2883680

d[2]%*%t(e[2])
this is the error: requires numeric matrix/vector arguments

i've tried to coerce "e" to a matrix, but it's doesn't work...

in the end.. i'd like this:
for (i in (1:1096)) {solve(d[i])*t(e[i])}

help me, please :)

Vincenzo
-- 
View this message in context: http://www.nabble.com/problems-with-matrix%2C-list-and-other..-tf3926701.html#a11135888
Sent from the R help mailing list archive at Nabble.com.


From billycorg1 at virgilio.it  Fri Jun 15 11:30:46 2007
From: billycorg1 at virgilio.it (billycorg)
Date: Fri, 15 Jun 2007 02:30:46 -0700 (PDT)
Subject: [R] problems with matrix, list and other..
Message-ID: <11135888.post@talk.nabble.com>


hi

can anyone help me to solve these problems?

i have:
1) "d" matrix with 1096 rows;
for example, 
d[2]=        
                   [,1]           [,2]          [,3]
[1,] 0.1192566 0.0000000 0.0000000
[2,] 0.0000000 0.1065938 0.0000000
[3,] 0.0000000 0.0000000 0.1038888

if I
class (d[2]) = "list" 
solve(d[2]) = error!!!

2) "e" list with 1096 rows;
for example
e[2]2=
[[1]]
[1] -1.0892216 -0.7304947 -1.2883680

d[2]%*%t(e[2])
this is the error: requires numeric matrix/vector arguments

i've tried to coerce "e" to a matrix, but it's doesn't work...

in the end.. i'd like this:
for (i in (1:1096)) {solve(d[i])*t(e[i])}

help me, please :)

Vincenzo
-- 
View this message in context: http://www.nabble.com/problems-with-matrix%2C-list-and-other..-tf3926701.html#a11135888
Sent from the R help mailing list archive at Nabble.com.


From lami at faunalia.it  Fri Jun 15 11:32:01 2007
From: lami at faunalia.it (Leonardo Lami)
Date: Fri, 15 Jun 2007 11:32:01 +0200
Subject: [R] gpclib problem
Message-ID: <46725C91.3020603@faunalia.it>

Hi all,
I am trying to test the new adehabitat package but I have a problem with
a linked library, "gpclib".

When I try do install it I have this output:

install.packages("gpclib", dependencies=TRUE,
repos="http://cran.cnr.berkeley.edu/")
Avviso in install.packages("gpclib", dependencies = TRUE, repos =
"http://cran.cnr.berkeley.edu/") :
argument 'lib' is missing: using /usr/local/lib/R/site-library
dependency ''gpclib'' is not available

I have the same problem in other repository.


Leonardo


From singularitaet at gmx.net  Fri Jun 15 12:32:15 2007
From: singularitaet at gmx.net (Stefan Grosse)
Date: Fri, 15 Jun 2007 12:32:15 +0200
Subject: [R] JGR, Java and Kubuntu 7.04 ...
In-Reply-To: <200706141816.47360.j.logsdon@quantex-research.com>
References: <200706141816.47360.j.logsdon@quantex-research.com>
Message-ID: <46726AAF.3090000@gmx.net>

You could download the latest R (2.5.0) directly from CRAN, this just as
a side remark, You find instructions here:
http://cran.au.r-project.org/bin/linux/ubuntu/README

With java you should make sure that you have the Java 5 JDK installed. 
I dont know how it is with Ubuntu but on fedora I have to set the java
alternative (sun java installation does not change the default java
there). Which java is installed you can check with java -version there
you see it it is properly installed and a R CMD javareconf also
indicates if your java is configured correctly. Additionally on Fedora I
had to set JAVA_HOME to the JDK directory manually.

Stefan

-------- Original Message  --------
Subject: [R] JGR, Java and Kubuntu 7.04 ...
From: John Logsdon <j.logsdon at quantex-research.com>
To: r-help at stat.math.ethz.ch
Date: 14.06.2007 19:16
> R-ists
>
> Yet again Java rears its ugly head.  
>
> I have Kubuntu 7.04 running the Kubuntu-repository version of R 2.4.1-1.      
> Yes it isn't the  very latest version but this is not the issue here.  
>
> I want a Windows-like environment and everyone is talking about JGR.
>
> I downloaded it and installed it along with rJava.  Both compile and install 
> satisfactorily.
>
> But when I come to run it:
>
>   
>>> library('JGR')
>>>       
>> Loading required package: rJava
>> Error in dyn.load(x, as.logical(local), as.logical(now)) :
>>         unable to load shared library
>> '/usr/local/lib/R/site-library/rJava/libs/rJava.so':
>> /usr/local/lib/R/site-library/rJava/libs/rJava.so: undefined symbol:
>> JNI_GetCreatedJavaVMs Error: .onLoad failed in 'loadNamespace' for 'rJava'
>> Error: package 'rJava' could not be loaded
>>     
>
>
> When I first tried to run it without Java being installed, I got a message 
> saying that JDK wasn't installed but mentioned 1.4.2.  The version of Java 
> actually installed as the latest from the Ubuntu repository is Sun 1.5.0.11.  
> I don't see the point in installing old versions of Java just for one 
> application because the language, or at least the writing, should be 
> backwards compatible.  
>
> In all aspects I have seen Kubuntu is a very impressive in checking 
> compatibility.  Unfortunately this is frequently not the case with Java.  I 
> steer clear of Java as much as possible.  
>
> Can anyone suggest what I should do?  Use Windows perhaps?  Run Windows in a 
> kvm virtual machine just to run R?  Put my head in a bucket of cold water?  
> Is there an alternative IDE?  Is there a later JGR somewhere that is not yet 
> on CRAN?
>
> TIA
>
>


From h.wickham at gmail.com  Fri Jun 15 12:33:03 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 15 Jun 2007 12:33:03 +0200
Subject: [R] back-transform predictors for x-axis in plot -- mgcv package
In-Reply-To: <4671B093.6@noaa.gov>
References: <4671B093.6@noaa.gov>
Message-ID: <f8e6ff050706150333v1e09940dw9e9d062ad0eca848@mail.gmail.com>

Hi Suzan,

You can do sort of backtransformation inside of ggplot2
(http://had.co.nz/ggplot2).

library(ggplot2)

# Create the base scatterplot with y and x axes transformed by logging,
# and then back transformed by exponentiating
(base <- qplot(carat, price, data=diamonds) + scale_x_log10() +
scale_y_log10() + coord_trans(y="pow10", x="pow10"))

base + geom_smooth(method="lm")

library(mgcv)
base + geom_smooth(method="gam", formula = y ~ s(x, bs="cr"))
base + geom_smooth(method="gam", formula = y ~ s(x, bs="cr"), fill="grey50")

# cf.

qplot(carat, price, data=diamonds) + geom_smooth(method="lm")
qplot(carat, price, data=diamonds) + geom_smooth(method="gam", formula
= y ~ s(x, bs="cr"), fill="grey50")


Regards,

Hadley

On 6/14/07, Suzan Pool <Suzan.Pool at noaa.gov> wrote:
> My question is related to plot( ) in the mgcv package.  Before modelling
> the data, a few predictors were transformed to normalize them.
> Therefore, the x-axes in the plots show transformed predictor values.
> How do I back-transform the predictors so that the plots are easier to
> interpret?
>
> Thanks in advance,
> Suzan
>
> --
> Suzan Pool
> Oregon State University
> Cooperative Institute for Marine Resources Studies
> c/o NOAA Fisheries
> 520 Heceta Place
> P.O. Box 155
> Hammond, OR  97121
>
> Suzan.Pool at oregonstate.edu
> Suzan.Pool at noaa.gov
> Phone:  503-861-1818 x36 TTY
> Voice to TTY:  711
> Fax:  503-861-2589
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch at stats.uwo.ca  Fri Jun 15 13:03:27 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 15 Jun 2007 07:03:27 -0400
Subject: [R] package with fortran 90 subroutines under windows xp
In-Reply-To: <6.0.1.1.2.20070612153012.00b96cd0@mail.unibo.it>
References: <6.0.1.1.2.20070612153012.00b96cd0@mail.unibo.it>
Message-ID: <467271FF.7010304@stats.uwo.ca>

On 12/06/2007 9:41 AM, Cinzia Viroli wrote:
> Hello,
> I work under windows xp and I am trying to build a R package with a 
> subroutine written in fortran 90.
> I have installed all the updated tools and I am working with R-2.4.0 or 
> R-2.5.0.
> 
> When I check a package with a subroutine in fortran 77 (and extension f) 
> everything is ok.
> When I try to build the same package with a subroutine in fortran 90 (with 
> extension f90) the following warning appears:
> 
> Subdirectory 'src' contains no source files
> 
> and the package can not be built.
> 
> The funny thing is that I have successfully built the same package with 
> fortran 90 last March and everything was good.
> 
> I can not imagine what is the problem, could do you help me?

The current Windows tools don't support Fortran 9x, just Fortran 77.  If 
you have your own Fortran 90 compiler, you can enter it into MkRules 
(either by enabling the GCC4 macro, or entering it directly in the F95 
macro).

But you should have got an error about the compiler not existing, not an 
error about no source files.

Are you sure you named the file *.f90?  I get a check warning about no 
source files if I name the file test.F90, but not for test.f90.

Duncan Murdoch


From ripley at stats.ox.ac.uk  Fri Jun 15 13:20:06 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 15 Jun 2007 12:20:06 +0100 (BST)
Subject: [R] gpclib problem
In-Reply-To: <46725C91.3020603@faunalia.it>
References: <46725C91.3020603@faunalia.it>
Message-ID: <Pine.LNX.4.64.0706151217130.4380@auk.stats>

On Fri, 15 Jun 2007, Leonardo Lami wrote:

> Hi all,
> I am trying to test the new adehabitat package but I have a problem with
> a linked library, "gpclib".
>
> When I try do install it I have this output:
>
> install.packages("gpclib", dependencies=TRUE,
> repos="http://cran.cnr.berkeley.edu/")
> Avviso in install.packages("gpclib", dependencies = TRUE, repos =
> "http://cran.cnr.berkeley.edu/") :
> argument 'lib' is missing: using /usr/local/lib/R/site-library
> dependency ''gpclib'' is not available
>
> I have the same problem in other repository.

You haven't told us your OS or R version (or what the 'other repository' 
was).  The files are there

http://cran.cnr.berkeley.edu/src/contrib/Descriptions/gpclib.html

so a guess is that you have failed to update your R.

> Leonardo
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Please do as this asks.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From yn19832 at msn.com  Fri Jun 15 13:28:15 2007
From: yn19832 at msn.com (livia)
Date: Fri, 15 Jun 2007 04:28:15 -0700 (PDT)
Subject: [R] Loop for test statistic
Message-ID: <11137549.post@talk.nabble.com>


I would like to obtain the statistic of A2 for ycf between the value 0.0032
and 0.09, and I am using the following codes. 

while (0.0032 <ycf <0.09) {
A2 <- A2_GOFlaio(ycf, dist="GEV")[1]
print(A2)
}

Could anyone give me some advice as it does not work.

Many thanks.
-- 
View this message in context: http://www.nabble.com/Loop-for-test-statistic-tf3927249.html#a11137549
Sent from the R help mailing list archive at Nabble.com.


From edd at debian.org  Fri Jun 15 13:56:59 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 15 Jun 2007 06:56:59 -0500
Subject: [R] JGR, Java and Kubuntu 7.04 ...
In-Reply-To: <46726AAF.3090000@gmx.net>
References: <200706141816.47360.j.logsdon@quantex-research.com>
	<46726AAF.3090000@gmx.net>
Message-ID: <18034.32395.591557.187974@basebud.nulle.part>


On 15 June 2007 at 12:32, Stefan Grosse wrote:
| You could download the latest R (2.5.0) directly from CRAN, this just as
| a side remark, You find instructions here:
| http://cran.au.r-project.org/bin/linux/ubuntu/README

Yes indeed, thanks for our fearless backporters.
 
| With java you should make sure that you have the Java 5 JDK installed. 
| I dont know how it is with Ubuntu but on fedora I have to set the java
| alternative (sun java installation does not change the default java
| there). Which java is installed you can check with java -version there
| you see it it is properly installed and a R CMD javareconf also
| indicates if your java is configured correctly. Additionally on Fedora I
| had to set JAVA_HOME to the JDK directory manually.

"It all worked" -- I don't run Java much myself, but I think starting with
the previous Ubuntu release and the actual Sun packages directly acessible
via apt-get, it worked.

However, with the current packages in my Kubuntu setup at work, I do get a
segfault once JGR is up and loaded.   I suspect, as Stefan said here, that
this is due to the Java 6 packages in Ubuntu.  As I said, sun-java5-jdk seems
to have work along with 'sudo R CMD javareconf', Simon's powerful Java
parameter setter for R.

In any event, we should carry this over to r-sig-debian.

Dirk

| 
| Stefan
| 
| -------- Original Message  --------
| Subject: [R] JGR, Java and Kubuntu 7.04 ...
| From: John Logsdon <j.logsdon at quantex-research.com>
| To: r-help at stat.math.ethz.ch
| Date: 14.06.2007 19:16
| > R-ists
| >
| > Yet again Java rears its ugly head.  
| >
| > I have Kubuntu 7.04 running the Kubuntu-repository version of R 2.4.1-1.      
| > Yes it isn't the  very latest version but this is not the issue here.  
| >
| > I want a Windows-like environment and everyone is talking about JGR.
| >
| > I downloaded it and installed it along with rJava.  Both compile and install 
| > satisfactorily.
| >
| > But when I come to run it:
| >
| >   
| >>> library('JGR')
| >>>       
| >> Loading required package: rJava
| >> Error in dyn.load(x, as.logical(local), as.logical(now)) :
| >>         unable to load shared library
| >> '/usr/local/lib/R/site-library/rJava/libs/rJava.so':
| >> /usr/local/lib/R/site-library/rJava/libs/rJava.so: undefined symbol:
| >> JNI_GetCreatedJavaVMs Error: .onLoad failed in 'loadNamespace' for 'rJava'
| >> Error: package 'rJava' could not be loaded
| >>     
| >
| >
| > When I first tried to run it without Java being installed, I got a message 
| > saying that JDK wasn't installed but mentioned 1.4.2.  The version of Java 
| > actually installed as the latest from the Ubuntu repository is Sun 1.5.0.11.  
| > I don't see the point in installing old versions of Java just for one 
| > application because the language, or at least the writing, should be 
| > backwards compatible.  
| >
| > In all aspects I have seen Kubuntu is a very impressive in checking 
| > compatibility.  Unfortunately this is frequently not the case with Java.  I 
| > steer clear of Java as much as possible.  
| >
| > Can anyone suggest what I should do?  Use Windows perhaps?  Run Windows in a 
| > kvm virtual machine just to run R?  Put my head in a bucket of cold water?  
| > Is there an alternative IDE?  Is there a later JGR somewhere that is not yet 
| > on CRAN?
| >
| > TIA
| >
| >
| 
| ______________________________________________
| R-help at stat.math.ethz.ch mailing list
| https://stat.ethz.ch/mailman/listinfo/r-help
| PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
| and provide commented, minimal, self-contained, reproducible code.

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From Mitchell.Wachtel at ttuhsc.edu  Fri Jun 15 14:13:56 2007
From: Mitchell.Wachtel at ttuhsc.edu (Wachtel, Mitchell)
Date: Fri, 15 Jun 2007 07:13:56 -0500
Subject: [R] Grahpics problem
Message-ID: <1A2BCA4266504B4CA543403718A81FD2025031B3@TRAVIS.ttuhsc.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070615/eecb63da/attachment.pl 

From daj025 at gmail.com  Fri Jun 15 14:23:02 2007
From: daj025 at gmail.com (David James)
Date: Fri, 15 Jun 2007 08:23:02 -0400
Subject: [R] connecting to DB2 database
In-Reply-To: <Pine.LNX.4.64.0706141803390.31733@gannet.stats.ox.ac.uk>
References: <755261CA22782948B1C42ACDC83912A10425DC04@NYWEXMB27.msad.ms.com>
	<Pine.LNX.4.64.0706141803390.31733@gannet.stats.ox.ac.uk>
Message-ID: <74c69e370706150523s372c4ac8l5b40a0d58c9e94dd@mail.gmail.com>

Hi,

On 6/14/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> On Thu, 14 Jun 2007, Aydemir, Zava (FID) wrote:
>
> > i am trying to connect to a DB2 server using the DBI library.
>
> The DBI *package* does not allow you to connect to anything by itself.
> For that you need a driver package, currently available for MySQL, ORACLE
> and SQLite (only, AFAIK).
>
> There are ODBC drivers for DB2 (on several platforms) so perhaps
> you could use RODBC: perhaps also RJDBC.

RJDBC also uses the DBI interface.

Regards,

--
David

>
>
> > getData <- function()
> >
> > {
> >
> >    driver <- dbDriver("DB2")
> >
> >    conn <- dbConnect(driver,"server","uname","pword")
> >
> >    data <- dbSendquery(conn, "select etc.")
> >
> > }
> >
> >
> >
> > When I run the function, i get the error
> >
> >
> >
> >> data <-  getData()
> > Error in do.call(as.character(drvName), list(...)) :
> >        could not find function "DB2"
> >
> >
> >
> >
> > Can anyone help me here?
> >
> > Thank you
> >
> > Zava
> > --------------------------------------------------------
> >
> > This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From klaster at karlin.mff.cuni.cz  Fri Jun 15 14:45:30 2007
From: klaster at karlin.mff.cuni.cz (Petr Klasterecky)
Date: Fri, 15 Jun 2007 14:45:30 +0200
Subject: [R] problems with matrix, list and other..
In-Reply-To: <11135888.post@talk.nabble.com>
References: <11135888.post@talk.nabble.com>
Message-ID: <467289EA.7070204@karlin.mff.cuni.cz>

You only got what you deserved when not reading the manual...
R-Intro, Chapters 5 and 6, page 26 in particular.
http://cran.r-project.org/doc/manuals/R-intro.pdf

Petr


billycorg napsal(a):
> hi
> 
> can anyone help me to solve these problems?
> 
> i have:
> 1) "d" matrix with 1096 rows;
> for example, 
> d[2]=        
>                    [,1]           [,2]          [,3]
> [1,] 0.1192566 0.0000000 0.0000000
> [2,] 0.0000000 0.1065938 0.0000000
> [3,] 0.0000000 0.0000000 0.1038888
> 
> if I
> class (d[2]) = "list" 
> solve(d[2]) = error!!!
> 
> 2) "e" list with 1096 rows;
> for example
> e[2]2=
> [[1]]
> [1] -1.0892216 -0.7304947 -1.2883680
> 
> d[2]%*%t(e[2])
> this is the error: requires numeric matrix/vector arguments
> 
> i've tried to coerce "e" to a matrix, but it's doesn't work...
> 
> in the end.. i'd like this:
> for (i in (1:1096)) {solve(d[i])*t(e[i])}
> 
> help me, please :)
> 
> Vincenzo

-- 
Petr Klasterecky
Dept. of Probability and Statistics
Charles University in Prague
Czech Republic


From klaster at karlin.mff.cuni.cz  Fri Jun 15 14:52:59 2007
From: klaster at karlin.mff.cuni.cz (Petr Klasterecky)
Date: Fri, 15 Jun 2007 14:52:59 +0200
Subject: [R] Loop for test statistic
In-Reply-To: <11137549.post@talk.nabble.com>
References: <11137549.post@talk.nabble.com>
Message-ID: <46728BAB.50007@karlin.mff.cuni.cz>

Please read the posting guide. How shall we know what ycf, and A2 are?
In general, the condition should be something like (.0032<ycf & ycf<.09) 
Also make sure that the initial value of ycf actually fits between the 
limits (or assign something to A2 outside the loop) and that ycf is 
changed inside the loop (to prevent looping forever).

Petr

livia napsal(a):
> I would like to obtain the statistic of A2 for ycf between the value 0.0032
> and 0.09, and I am using the following codes. 
> 
> while (0.0032 <ycf <0.09) {
> A2 <- A2_GOFlaio(ycf, dist="GEV")[1]
> print(A2)
> }
> 
> Could anyone give me some advice as it does not work.
> 
> Many thanks.

-- 
Petr Klasterecky
Dept. of Probability and Statistics
Charles University in Prague
Czech Republic


From klaster at karlin.mff.cuni.cz  Fri Jun 15 14:57:44 2007
From: klaster at karlin.mff.cuni.cz (Petr Klasterecky)
Date: Fri, 15 Jun 2007 14:57:44 +0200
Subject: [R] Grahpics problem
In-Reply-To: <1A2BCA4266504B4CA543403718A81FD2025031B3@TRAVIS.ttuhsc.edu>
References: <1A2BCA4266504B4CA543403718A81FD2025031B3@TRAVIS.ttuhsc.edu>
Message-ID: <46728CC8.8060802@karlin.mff.cuni.cz>

RSiteSearch("common title")

Petr

Wachtel, Mitchell napsal(a):
> To the group:
> 
>  
> 
> A marvelous thing is combining graphs with the par function, but there
> remains an issue. What if you wish to put a title on top of the set of
> graphs or a general x or y axis label? How does one do this?
> 
> 
> With kindest regards.
> 
>  
> 
> Mitchell S. Wachtel, MD
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Petr Klasterecky
Dept. of Probability and Statistics
Charles University in Prague
Czech Republic


From murdoch at stats.uwo.ca  Fri Jun 15 15:02:03 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 15 Jun 2007 09:02:03 -0400
Subject: [R] Grahpics problem
In-Reply-To: <1A2BCA4266504B4CA543403718A81FD2025031B3@TRAVIS.ttuhsc.edu>
References: <1A2BCA4266504B4CA543403718A81FD2025031B3@TRAVIS.ttuhsc.edu>
Message-ID: <46728DCB.3040501@stats.uwo.ca>

On 6/15/2007 8:13 AM, Wachtel, Mitchell wrote:
> To the group:
> 
>  
> 
> A marvelous thing is combining graphs with the par function, but there
> remains an issue. What if you wish to put a title on top of the set of
> graphs or a general x or y axis label? How does one do this?

Use mtext() to write to the outer margins, but remember first to create 
some space there.  For example,

 > par(oma=c(0,0,2,0),mfrow=c(2,2))
 > plot(1)
 > plot(2)
 > plot(3)
 > plot(4)
 > mtext("Main title", side=3, outer=TRUE)

Duncan Murdoch


From pfister at uni-lueneburg.de  Fri Jun 15 15:23:52 2007
From: pfister at uni-lueneburg.de (Pfister)
Date: Fri, 15 Jun 2007 15:23:52 +0200
Subject: [R] Problem with workspace loading after languageR use
Message-ID: <467292E8.4050603@uni-lueneburg.de>

Hello R,

To analyze multi-level data, I started learning and using lmer. So far 
so wonderful. I then found some useful functions in package languageR. 
But then the following problem ocurred: Whenever I load and use the 
languageR package, then save the workspace - or quit R with saving the 
workspace - I am unable to reload that workspace in a later session. 
That is, R doesn't start at all when I try to start it by clicking the 
workspace file.
Loading languageR before loading the workspace doesn't help, but yields 
the message:

Error in load("D:\\statistics\\MultilevelAnalysis\\.RData") :
         could not find function "findPackageEnv"

Thus, the saved workspace remains inaccessible. I not 100% certain that 
languageR is the scapegoat, but my trial-and-error experiments indicate 
it is.

My system is Win XP Home/Professional:

 > sessionInfo()
R version 2.5.0 Patched (2007-04-24 r41305)
i386-pc-mingw32
locale:
LC_COLLATE=German_Germany.1252;LC_CTYPE=German_Germany.1252;LC_MONETARY=German_Germany.1252;LC_NUMERIC=C;LC_TIME=German_Germany.1252
attached base packages:
[1] "splines"   "stats"     "graphics"  "grDevices" "utils"
[6] "datasets"  "methods"   "base"
other attached packages:
   languageR       rpart        MASS      Design    survival
       "0.2"    "3.1-36"    "7.2-34"    "2.0-12"      "2.31"
       Hmisc       e1071       class     cluster       zipfR
     "3.3-2"    "1.5-16"    "7.2-34"    "1.11.7"     "0.6-0"
        lme4        coda      Matrix     lattice
"0.99875-1"    "0.11-2" "0.99875-2"    "0.15-8"


thanks for any helpful suggestions!

best
R?diger


-- 
Hans-R?diger Pfister
Professor of Business Psychology
University of L?neburg
Faculty for Business Administration, Behavioral Sciences and Law
Institute of Experimental Industrial Psychology (LueneLab)
Wilschenbrucher Weg 84
D-21335 L?neburg, Germany
+49-(0)4131 677 7759
pfister at uni-lueneburg.de


From ronggui.huang at gmail.com  Fri Jun 15 15:27:35 2007
From: ronggui.huang at gmail.com (ronggui)
Date: Fri, 15 Jun 2007 21:27:35 +0800
Subject: [R] method of rpart when response variable is binary?
Message-ID: <38b9f0350706150627o21c9adacx64ead046f9db3a9b@mail.gmail.com>

Dear all,

I would like to model the relationship between y and x. y is binary
variable, and x is a count variable which may be possion-distribution.

I think it is better to divide x into intervals and change it to a
factor before calling glm(y~x,data=dat,family=binomail).

I try to use rpart. As y is binary, I use "class" method and get the
following result.
> rpart(y~x,data=dat,method="class")
n=778 (22 observations deleted due to missingness)

node), split, n, loss, yval, (yprob)
      * denotes terminal node

1) root 778 67 0 (0.91388175 0.08611825) *


If with the default method, I get such a result.

> rpart(y~x,data=dat)
n=778 (22 observations deleted due to missingness)

node), split, n, deviance, yval
      * denotes terminal node

1) root 778 61.230080 0.08611825
  2) x< 19.5 750 53.514670 0.07733333
    4) x< 1.25 390 17.169230 0.04615385 *
    5) x>=1.25 360 35.555560 0.11111110 *
  3) x>=19.5 28  6.107143 0.32142860 *

If I use 1.25 and 19.5 as the cutting points, change x into factor by
>x2 <- cut(q34b,breaks=c(0,1.25,19.5,200),right=F)

The coef in y~x2 is significant and makes sense.

My problem is: is it OK use the default method in rpart when response
varibale is binary one?  Thanks.


-- 
Ronggui Huang
Department of Sociology
Fudan University, Shanghai, China


From ngottlieb at marinercapital.com  Fri Jun 15 15:42:32 2007
From: ngottlieb at marinercapital.com (ngottlieb at marinercapital.com)
Date: Fri, 15 Jun 2007 09:42:32 -0400
Subject: [R] Need Help with Dendrogram and DataFrame Leaf names
Message-ID: <0946E293C7C22A45A0E33BA14FAA8D88F38840@500MAIL.goldbox.com>

I having problem with dendrogram leaf names when I read a tab delimited
file into dataframe;

I have a text file, tab delimited, using read.table into a data frame as
follows:
>  test1<-read.table("c:\\R\\data\\Tremont4.txt", header=TRUE, sep="\t")

When I do this the "test1" data frame is picking up my first column
names as
part of the data and not the case names, the leafs are the numbers on
the left 1-13
As opposed to the text names to the right. 

Example Output from displaying dataframe:
> test1
                 row.names X1.31.2004 X2.29.2004 X3.31.2004 X4.30.2004
X5.31.2004 X6.30.2004 X7.31.2004 X8.31.2004 X9.30.2004 X10.31.2004
1     ConvertibleArbitrage      0.014      0.003      0.004      0.005
-0.013     -0.008     -0.002      0.003     -0.001      -0.003
2       DedicatedShortBias     -0.017      0.003     -0.026      0.042
0.008     -0.013      0.081      0.013     -0.019      -0.018
3          EmergingMarkets      0.025      0.014      0.018     -0.033
-0.018      0.009     -0.001      0.018      0.023       0.024
4            MarketNeutral      0.008      0.008     -0.001     -0.003
0.002      0.008      0.003      0.021      0.005       0.000
5              EventDriven      0.022      0.010      0.005      0.005
0.001      0.010      0.000      0.005      0.013       0.012
6               Distressed      0.024      0.009      0.006      0.007
0.003      0.011      0.005      0.006      0.012       0.019
7  EventdriveMultiStrategy      0.020      0.011      0.003      0.005
-0.001      0.009     -0.003      0.004      0.014       0.007
8            RiskArbitrage      0.008      0.005      0.007     -0.006
0.004      0.003     -0.015      0.002      0.006       0.009
9     FixedIncomeArbitrage      0.012      0.009     -0.005      0.013
0.006      0.007      0.007     -0.004     -0.008       0.011
10             GlobalMacro      0.015      0.012      0.010      0.001
0.001      0.005      0.008     -0.008     -0.005       0.012
11         LongShortEquity      0.020      0.018      0.002     -0.014
-0.004      0.007     -0.014      0.001      0.024       0.014
12          ManagedFutures      0.011      0.069     -0.009     -0.065
-0.011     -0.028     -0.020     -0.015      0.020       0.048
13          Multi-Strategy      0.016      0.004      0.004      0.003
-0.001      0.001     -0.003      0.004      0.006       0.006

Input file looks like this:
row.names	            1/31/2004	  2/29/2004	3/31/2004
4/30/2004	5/31/2004	6/30/2004	7/31/2004
8/31/2004
ConvertibleArbitrage	0.014  	 0.003	0.004	       0.005	-0.013
-0.008	-0.002	0.003
DedicatedShortBias	-0.017	 0.003	-0.026	0.042	       0.008
-0.013	0.081	      0.013
EmergingMarkets	      0.025	       0.014	0.018	     -0.033
-0.018	      0.009	     -0.001	      0.018
MarketNeutral	      0.008	       0.008	-0.001	-0.003	0.002
0.008	      0.003	      0.021
Etc...

Would appreciate why the read.table into dataframe sees the text as part
of the data oand
Not the observation names and is making the numbers the leaf names and
observation names.


Thanks for any help,
Neil Gottlieb
--------------------------------------------------------

 
 
This information is being sent at the recipient's request or...{{dropped}}


From ozlemipekci at gmail.com  Fri Jun 15 15:59:20 2007
From: ozlemipekci at gmail.com (Ozlem Ipekci)
Date: Fri, 15 Jun 2007 16:59:20 +0300
Subject: [R] Coefficients and Covariances in MNP
Message-ID: <ea0349ad0706150659y7a5438bfna84c1b321b45e7df@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070615/d1d35ae9/attachment.pl 

From ripley at stats.ox.ac.uk  Fri Jun 15 16:21:51 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 15 Jun 2007 15:21:51 +0100 (BST)
Subject: [R] method of rpart when response variable is binary?
In-Reply-To: <38b9f0350706150627o21c9adacx64ead046f9db3a9b@mail.gmail.com>
References: <38b9f0350706150627o21c9adacx64ead046f9db3a9b@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0706151519440.27080@auk.stats>

On Fri, 15 Jun 2007, ronggui wrote:

> Dear all,
>
> I would like to model the relationship between y and x. y is binary
> variable, and x is a count variable which may be possion-distribution.
>
> I think it is better to divide x into intervals and change it to a
> factor before calling glm(y~x,data=dat,family=binomail).
>
> I try to use rpart. As y is binary, I use "class" method and get the
> following result.
>> rpart(y~x,data=dat,method="class")
> n=778 (22 observations deleted due to missingness)
>
> node), split, n, loss, yval, (yprob)
>      * denotes terminal node
>
> 1) root 778 67 0 (0.91388175 0.08611825) *
>
>
> If with the default method, I get such a result.
>
>> rpart(y~x,data=dat)
> n=778 (22 observations deleted due to missingness)
>
> node), split, n, deviance, yval
>      * denotes terminal node
>
> 1) root 778 61.230080 0.08611825
>  2) x< 19.5 750 53.514670 0.07733333
>    4) x< 1.25 390 17.169230 0.04615385 *
>    5) x>=1.25 360 35.555560 0.11111110 *
>  3) x>=19.5 28  6.107143 0.32142860 *
>
> If I use 1.25 and 19.5 as the cutting points, change x into factor by
>> x2 <- cut(q34b,breaks=c(0,1.25,19.5,200),right=F)
>
> The coef in y~x2 is significant and makes sense.
>
> My problem is: is it OK use the default method in rpart when response
> varibale is binary one?  Thanks.

Not unless you want a least-squares fit.  Note that you have only 8.6% of 
one class, and for such an unbalanced classification problem you are 
unlikely to do better than declaring class 1 for all examples.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tlumley at u.washington.edu  Fri Jun 15 16:30:42 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 15 Jun 2007 07:30:42 -0700 (PDT)
Subject: [R] importing .dta files
In-Reply-To: <b05bf6c40706142214i24ef2f33tbad26e0df9e785d2@mail.gmail.com>
References: <b05bf6c40706142214i24ef2f33tbad26e0df9e785d2@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0706150719330.31946@homer21.u.washington.edu>

On Fri, 15 Jun 2007, Chris Linton wrote:

> I'm trying to read in a Stata file but I've never used this function (
> read.dta).  It's the only one that seems to come close to working, but I
> keep getting this error:
>
>> data<-read.dta("C:/Documents and
> Settings/Chris/Desktop/S4412/catestscores.dta")
> Error in read.dta("C:/Documents and
> Settings/Chris/Desktop/S4412/catestscores.dta",  :
>        a binary read error occurred
>
>
> There's little chance the data is corrupt considering it came from my
> professor and he used the data earlier.  So, either I'm doing something
> wrong or R just doesn't like to read in Stata files.  If it's a problem with
> R, how can I easily convert the file without purchasing Stata?
>

R does read Stata files -- I use this facility frequently.  It's hard to 
tell why it isn't working in your case, since we don't know anything about 
the file, your version of R, version of Stata, etc (we can guess you are 
on windows from the file name).

The error message implies that the file was found, and that it started 
with the right sequence of bytes to be a Stata .dta file, but that 
something (probably the end of the file) prevented R from reading what it 
was expecting to read.

This is why (in the absence of any further information) the natural 
suspicion is that the file is corrupt.  It is possible that we have 
misunderstood some unusual possibility in the Stata file format -- this 
has happened once before -- but it is fairly well documented.  In any 
case, there is not much that can be done without more information.


 	-thomas


From ripley at stats.ox.ac.uk  Fri Jun 15 16:34:36 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 15 Jun 2007 15:34:36 +0100 (BST)
Subject: [R] Problem with workspace loading after languageR use
In-Reply-To: <467292E8.4050603@uni-lueneburg.de>
References: <467292E8.4050603@uni-lueneburg.de>
Message-ID: <Pine.LNX.4.64.0706151522020.27080@auk.stats>

The problem would appear to be something missing in R.  From what I can 
see you have saved a reference to a package environment in your workspace. 
When load() tries to resolve this, it calls findPackageEnv and that does 
not exist in current R (or any recent version I looked at).

I think adding the following to your new session before load() will help

findPackageEnv <- function(info)
    as.environment(paste("package", "info", sep=":"))

will work, but if not try

findPackageEnv <- function(info) .GlobalEnv

If you send me the problematic workspace (or reproduction instructions) I 
can take a closer look.


On Fri, 15 Jun 2007, Pfister wrote:

> Hello R,
>
> To analyze multi-level data, I started learning and using lmer. So far
> so wonderful. I then found some useful functions in package languageR.
> But then the following problem ocurred: Whenever I load and use the
> languageR package, then save the workspace - or quit R with saving the
> workspace - I am unable to reload that workspace in a later session.
> That is, R doesn't start at all when I try to start it by clicking the
> workspace file.
> Loading languageR before loading the workspace doesn't help, but yields
> the message:
>
> Error in load("D:\\statistics\\MultilevelAnalysis\\.RData") :
>         could not find function "findPackageEnv"
>
> Thus, the saved workspace remains inaccessible. I not 100% certain that
> languageR is the scapegoat, but my trial-and-error experiments indicate
> it is.
>
> My system is Win XP Home/Professional:
>
> > sessionInfo()
> R version 2.5.0 Patched (2007-04-24 r41305)
> i386-pc-mingw32
> locale:
> LC_COLLATE=German_Germany.1252;LC_CTYPE=German_Germany.1252;LC_MONETARY=German_Germany.1252;LC_NUMERIC=C;LC_TIME=German_Germany.1252
> attached base packages:
> [1] "splines"   "stats"     "graphics"  "grDevices" "utils"
> [6] "datasets"  "methods"   "base"
> other attached packages:
>   languageR       rpart        MASS      Design    survival
>       "0.2"    "3.1-36"    "7.2-34"    "2.0-12"      "2.31"
>       Hmisc       e1071       class     cluster       zipfR
>     "3.3-2"    "1.5-16"    "7.2-34"    "1.11.7"     "0.6-0"
>        lme4        coda      Matrix     lattice
> "0.99875-1"    "0.11-2" "0.99875-2"    "0.15-8"
>
>
> thanks for any helpful suggestions!
>
> best
> R?diger
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From liuwensui at gmail.com  Fri Jun 15 16:45:23 2007
From: liuwensui at gmail.com (Wensui Liu)
Date: Fri, 15 Jun 2007 10:45:23 -0400
Subject: [R] method of rpart when response variable is binary?
In-Reply-To: <38b9f0350706150627o21c9adacx64ead046f9db3a9b@mail.gmail.com>
References: <38b9f0350706150627o21c9adacx64ead046f9db3a9b@mail.gmail.com>
Message-ID: <1115a2b00706150745o7561e92bw7fe71582cf3cc14d@mail.gmail.com>

you might use default setting if you use as.factor(y)~x in rpart(), I think.

On 6/15/07, ronggui <ronggui.huang at gmail.com> wrote:
> Dear all,
>
> I would like to model the relationship between y and x. y is binary
> variable, and x is a count variable which may be possion-distribution.
>
> I think it is better to divide x into intervals and change it to a
> factor before calling glm(y~x,data=dat,family=binomail).
>
> I try to use rpart. As y is binary, I use "class" method and get the
> following result.
> > rpart(y~x,data=dat,method="class")
> n=778 (22 observations deleted due to missingness)
>
> node), split, n, loss, yval, (yprob)
>       * denotes terminal node
>
> 1) root 778 67 0 (0.91388175 0.08611825) *
>
>
> If with the default method, I get such a result.
>
> > rpart(y~x,data=dat)
> n=778 (22 observations deleted due to missingness)
>
> node), split, n, deviance, yval
>       * denotes terminal node
>
> 1) root 778 61.230080 0.08611825
>   2) x< 19.5 750 53.514670 0.07733333
>     4) x< 1.25 390 17.169230 0.04615385 *
>     5) x>=1.25 360 35.555560 0.11111110 *
>   3) x>=19.5 28  6.107143 0.32142860 *
>
> If I use 1.25 and 19.5 as the cutting points, change x into factor by
> >x2 <- cut(q34b,breaks=c(0,1.25,19.5,200),right=F)
>
> The coef in y~x2 is significant and makes sense.
>
> My problem is: is it OK use the default method in rpart when response
> varibale is binary one?  Thanks.
>
>
> --
> Ronggui Huang
> Department of Sociology
> Fudan University, Shanghai, China
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
WenSui Liu
A lousy statistician who happens to know a little programming
(http://spaces.msn.com/statcompute/blog)


From anonymous.65ddccce30 at anonymousspeech.com  Fri Jun 15 16:45:11 2007
From: anonymous.65ddccce30 at anonymousspeech.com (Jack)
Date: Fri, 15 Jun 2007 23:45:11 +0900
Subject: [R] mixed model for analysing microarray data
Message-ID: <CHILKAT-MID-eb94637c-a002-4276-ab4e-e3960ae3ba37@uweb002>

Dear R users, 

We are trying to analyse microarray data. The experiment compares two conditions (light vs. dark). we would like to use a mixed-model ANOVA but we don't know much about it. could you please help?
the experiment test the effect of light on a tissue and compare tissues maintained in light or dark (fixed effect).
In each condition, Two RNA samples were used (random effect?) for each condition, and each sample was measured twice (random effect? nested in sample?), or maybe the replicate factor is not required?

Any help will be appreciated (particularly on how to assign the random factor(s) )

for a given gene the data look like that:

light  RNA  replicate  reading
"y"     1     1          1.67
"y"     1     2          1.56
"y"     2     1          1.60
"y"     2     2          1.34
"n"     1     1          1.67
"n"     1     2          1.56
"n"     2     1          1.60
"n"     2     2          1.34




***************************************************************
This email was sent via http://www.AnonymousSpeech.com,  
the worlds leading <a href=http://www.anonymousspeech.com>anonymous email</a> provider.
Paid memberships do not show this footer message.


From ted.harding at nessie.mcc.ac.uk  Fri Jun 15 17:13:33 2007
From: ted.harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 15 Jun 2007 16:13:33 +0100 (BST)
Subject: [R] [OT] 'gv' and fractional points
Message-ID: <XFMail.070615161333.ted.harding@nessie.mcc.ac.uk>

Hi Folks,

This is off-topic R-wise, but it may be close to
the heart of many R-users, so I think it may be
the best place to ask!

Users of 'gv' (the "front end" to ghostscript) will
be aware of the little window which gives you the
x-y coordinates (in points = 1/72 inch) of the position
of the "cross-hair" mouse cursor. These coordinates
are those of the corresponding position on the printed
page, relative to some origin.

I have often used this to extract numerical values
for data from graphs in Postscript files (also PDF
files, after you have converted them to PS). Then
(veering back on topic ... ) you can submit the
numerical data to R and try your own analyses on
these data, and compare with what the article does.

However, this little window only gives the numbers
in whole points. Say a smallish graphic may print
out 3 inches wide or high. Then you get precision
of 1/216 per 3 inches or 0.4% of full scale. This
can be adequate on many occasions, but can be on
the coarse side on other occasions.

Even for a 6-inch-wide/high graph, you only get down
to 0.2% of full scale.

If it were possible to induce 'gv' to display these
coordinates in tenths of a point, then much greater
precision (as adequate as one can expect to hope for
when, in effect, "measuring off the graph") could be
obtained.

Does anyone know:
a) Whether it is possible to persuade 'gv' to give
   this display in fractional points (my own search
   of the documentation has not revealed anything);
b) Of any alternative to 'gv' as PS viewer which would
   provide this capability?

With thanks, and best wishes to all,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 15-Jun-07                                       Time: 16:13:21
------------------------------ XFMail ------------------------------


From lise.bellanger at univ-nantes.fr  Fri Jun 15 18:16:15 2007
From: lise.bellanger at univ-nantes.fr (Bellanger Lise)
Date: Fri, 15 Jun 2007 17:16:15 +0100
Subject: [R] registration density profiles : FDA
Message-ID: <4672BB4F.1020706@univ-nantes.fr>

Hello,


       I would like to use  fda library to compare sampled curves that 
are density profiles. But I encounter some problems to register my data :
I know that I must use a registration function to align functions in 
order to have important features found in each curve occur at roughly 
the same argument value, prior to do subsequent analysis ( PCA and 
cluster analysis).   But I do not know which function (if there exists 
one) allows me  to synchronize density profiles : could help me please ?

   Thank you by advance

   Best regards

         Lise Bellanger

-- 
Lise Bellanger, 
Universit? de Nantes
D?partement de Math?matiques, Laboratoire Jean Leray UMR CNRS 6629 
2, Rue de la Houssini?re BP 92208 - F-44322 Nantes Cedex 03 
T?l. : (33|0) 2 51 12 59 00 (ou 43) - Fax : (33|0) 2 51 12 59 12 
E-Mail : lise.bellanger at univ-nantes.fr
URL : http://www.math.sciences.univ-nantes.fr/


From benoitchemineau at gmail.com  Fri Jun 15 17:19:16 2007
From: benoitchemineau at gmail.com (Benoit Chemineau)
Date: Fri, 15 Jun 2007 17:19:16 +0200
Subject: [R] how to compute a garch model with t innovations ?
Message-ID: <50c8fbc90706150819y4e71e981m29911400c9e2f159@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070615/fe1fe85b/attachment.pl 

From quesada at gmail.com  Fri Jun 15 17:30:19 2007
From: quesada at gmail.com (Jose)
Date: Fri, 15 Jun 2007 15:30:19 +0000 (UTC)
Subject: [R] Error: bad value ? what is that?
References: <op.ttxku71z4hcap5@delllap.ugr.es> <4671C1DB.10201@biostat.ku.dk>
Message-ID: <loom.20070615T172404-132@post.gmane.org>

Peter Dalgaard <p.dalgaard <at> biostat.ku.dk> writes:

> 
> Jose Quesada wrote:
> > Hi,
> >
> > I'm finding a very strange error.
> > For no good reason my R console (Rgui.exe, R 2.5.0, under win XP) stops  
> > producing anything meaningful, and just returns:
> > Error: bad value
> > to _whatever_ I enter. It starts doing this after a while, not immediately  
> > when launched.
> >
> > I have to restart R when this happens.
> > No idea why. I didn't change anything in the R config that I remenber.
> >
> > Any thoughts?
> >
> > Thanks.
> >
> >   
> Hmm that message comes from deep down inside SETCAR() and friends. I 
> can't see other reasons for it than memory corruption. Are you running 
> some rogue C code? Is the machine flaky in other respects?
> 
> ______________________________________________
> R-help <at> stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

Thanks Peter,

Interesting; I upgraded my laptop to 2 gigs. and from that point on, it 
sometimes fauls to hibernate (just hangs). Maybe this is related? I installed 
an XP patch to solve hibernation problems with laptops over 2 gigs...

Maybe it didn't work?

-Jose
Re: Rogue c code: I was running library(Matrix), which is a pretty complicated 
piece of code and surely has c code...


From Greg.Snow at intermountainmail.org  Fri Jun 15 17:42:28 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Fri, 15 Jun 2007 09:42:28 -0600
Subject: [R] R vs. Splus in Pharma/Devices Industry
In-Reply-To: <71257D09F114DA4A8E134DEAC70F25D308A690EB@groamrexm03.amer.pfizer.com>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBA21F63@LP-EXCHVS07.CO.IHC.COM>

I am happy to say nice things about odfWeave.  Before it was released I
was looking at the RTF spec to see if I could write an RTF driver for
sweave.  But the task was a bit daunting and I doubt that I would have
had time for it.  So, I was (and still am) exited when odfWeave came
out.  It is a big time saver for  me and I have shown it to several
other people as well.

I have looked at ooconvert, but unfortunately the current version is
limited to *nix, and I am currently in a MS windows world.  I tried
getting it to run under cygwin at one point, but did not succeed at the
time.  Once it is available more generally, I will just set up Makefiles
so that I can automatically produce either .doc or .pdf documents from
my templates and data.

Thanks for the great package,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: Kuhn, Max [mailto:Max.Kuhn at pfizer.com] 
> Sent: Thursday, June 14, 2007 3:11 PM
> To: Greg Snow; Cody_Hamilton at edwards.com; r-help at stat.math.ethz.ch
> Subject: RE: [R] R vs. Splus in Pharma/Devices Industry
> 
> Greg,
> 
> Thanks for the kind words about odfWeave.
> 
> > These reports are usually put out as internal webpages for various 
> > people in the organization to look at, so we could either go the 
> > odfWeave approach and generate pdf files (not as automated 
> as I would
> > like)
> 
> I agree that automating the conversion should be easier. My 
> wish would be that the OO binary had a flag to convert from 
> one format to another.
> 
> On Linux, there is a bash script that uses the open office 
> binaries to do the conversion at the command line by Nathan Coulter at
> 
>    http://sourceforge.net/projects/ooconvert/
> 
> Also, there is a Java class called jooconvert out there (if memory
> serves) that has similar functionality.
> 
> Max
> 
> 
> 
> ----------------------------------------------------------------------
> LEGAL NOTICE
> Unless expressly stated otherwise, this message is 
> confidential and may be privileged.  It is intended for the 
> addressee(s) only.  Access to this E-mail by anyone else is 
> unauthorized.  If you are not an addressee, any disclosure or 
> copying of the contents of this E-mail or any action taken 
> (or not taken) in reliance on it is unauthorized and may be 
> unlawful.  If you are not an addressee, please inform the 
> sender immediately.
>


From edd at debian.org  Fri Jun 15 17:47:19 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 15 Jun 2007 10:47:19 -0500
Subject: [R] model.frame: how does one use it?
Message-ID: <18034.46215.223478.311352@basebud.nulle.part>


Philipp Benner reported a Debian bug report against r-cran-rpart aka rpart.
In short, the issue has to do with how rpart evaluates a formula and
supporting arguments, in particular 'weights'.  

A simple contrived example is

-----------------------------------------------------------------------------
library(rpart)

## using data from help(rpart), set up simple example
myformula <- formula(Kyphosis ~ Age + Number + Start)
mydata <- kyphosis
myweight <- abs(rnorm(nrow(mydata)))

goodFunction <- function(mydata, myformula, myweight) {
  hyp <- rpart(myformula, data=mydata, weights=myweight, method="class")
  prev <- hyp
}
goodFunction(mydata, myformula, myweight)
cat("Ok\n")

## now remove myweight and try to compute it inside a function
rm(myweight)

badFunction <- function(mydata, myformula) {
  myweight <- abs(rnorm(nrow(mydata)))
  mf <- model.frame(myformula, mydata, myweight)
  print(head(df))
  hyp <- rpart(myformula,
               data=mf,
               weights=myweight,
               method="class")
  prev <- hyp
}
badFunction(mydata, myformula)
cat("Done\n")
-----------------------------------------------------------------------------

Here goodFunction works, but only because myweight (with useless random
weights, but that is not the point here) is found from the calling
environment. 

badFunction fails after we remove myweight from there:

:~> cat /tmp/philipp.R | R --slave
Ok
Error in eval(expr, envir, enclos) : object "myweight" not found
Execution halted
:~>    

As I was able to replicate it, I reported this to the package maintainer.  It
turns out that seemingly all is well as this is supposed to work this way,
and I got a friendly pointer to study model.frame and its help page.  

Now I am stuck as I can't make sense of model.frame -- see badFunction
above. I would greatly appreciate any help in making rpart work with a local
argument weights so that I can tell Philipp that there is no bug.  :)

Regards, Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From slomascolo at zoo.ufl.edu  Fri Jun 15 17:47:59 2007
From: slomascolo at zoo.ufl.edu (Silvia Lomascolo)
Date: Fri, 15 Jun 2007 08:47:59 -0700 (PDT)
Subject: [R] subscript out of bounds error in lda
Message-ID: <11142304.post@talk.nabble.com>


I work with Windows, R version 2.4.1

I'm trying to do a discriminant analysis and, in trying to figure out how to
do it following the example from R help, I'm getting an error that says
'subscript out of bounds'.  I don't know what this means and how to solve it
(I'm very new with R)

I'm doing everything in this made-up test matrix:

   group var1 var2 var3
1      1    3   55    6
2      1    4   66    7
3      1    5   55    8
4      1    4   66    7
5      1    3   44    6
6      1    4   55    5
7      2    5   88    9
8      2    4   99    8
9      2    8   88    9
10     2    9   76    8
11     2    8   66    9
12     2    9   99   10
13     2   10  100    9

I write:

data.tb<-read.table('locationHere.txt', header=T)
data.df<-as.data.frame (data.tb)                                                           
train<-sample (1:63, 30)                                                                                                                                                       
table (data.df$group[train])                                                                 
data.disc<-lda(group~., data.tb, subset = train)                                             
data.disc                                                                                    
predict (data.disc, data.df[-train,])$class              

This is where I get the message:

Error in `[.data.frame`(data.df, -train, ) : 
        subscript out of bounds

Can anyone, please help me figure out what this is about? Thanks!

Silvia.                                    
-- 
View this message in context: http://www.nabble.com/subscript-out-of-bounds-error-in-lda-tf3928773.html#a11142304
Sent from the R help mailing list archive at Nabble.com.


From pfister at uni-lueneburg.de  Fri Jun 15 17:49:49 2007
From: pfister at uni-lueneburg.de (Pfister)
Date: Fri, 15 Jun 2007 17:49:49 +0200
Subject: [R] Problem with workspace loading after languageR use
In-Reply-To: <Pine.LNX.4.64.0706151606440.4570@gannet.stats.ox.ac.uk>
References: <467292E8.4050603@uni-lueneburg.de>
	<Pine.LNX.4.64.0706151522020.27080@auk.stats>
	<Pine.LNX.4.64.0706151606440.4570@gannet.stats.ox.ac.uk>
Message-ID: <4672B51D.4010105@uni-lueneburg.de>

Dear Brian,

thanks a lot for your advice.

Prof Brian Ripley wrote:
> On Fri, 15 Jun 2007, Prof Brian Ripley wrote:
> 
>>
>> I think adding the following to your new session before load() will help
>>
>> findPackageEnv <- function(info)
>>   as.environment(paste("package", "info", sep=":"))

this does not work.

> 
> more likely
> 
> findPackageEnv <- function(info) as.environment(info)

this works, if I load the languageR library before.

> 
> is correct.
>>
>> will work, but if not try
>>
>> findPackageEnv <- function(info) .GlobalEnv

this works unconditionally. Including that line in a local .RProfile 
file, basically solves the problem.

>>
>> If you send me the problematic workspace (or reproduction 
>> instructions) I can take a closer look.

A typical session would look like this (using example data from Hox(2002)):

# from Hox (2002)
hoxpop <- 
read.table("http://www.ruediger-pfister.de/download/popular.dat", 
header=TRUE)
hoxpop$PUPIL <- factor(hoxpop$PUPIL)
hoxpop$SCHOOL <- factor(hoxpop$SCHOOL)
hoxpop$SEX <- factor(hoxpop$SEX)

# load languageR
library(languageR)

# do some analyses ...

# save the workspace
save.image("D:\\statistics\\MultilevelAnalysis\\lm.RData")


After quitting R, the workspace "lm.RData" will not reload.
(this workspace can be downloaded here: 
http://www.ruediger-pfister.de/Downloads/lmRData.zip)


best
R?diger



>>
>>
>> On Fri, 15 Jun 2007, Pfister wrote:
>>
>>> Hello R,
>>>
>>> To analyze multi-level data, I started learning and using lmer. So far
>>> so wonderful. I then found some useful functions in package languageR.
>>> But then the following problem ocurred: Whenever I load and use the
>>> languageR package, then save the workspace - or quit R with saving the
>>> workspace - I am unable to reload that workspace in a later session.
>>> That is, R doesn't start at all when I try to start it by clicking the
>>> workspace file.
>>> Loading languageR before loading the workspace doesn't help, but yields
>>> the message:
>>>
>>> Error in load("D:\\statistics\\MultilevelAnalysis\\.RData") :
>>>         could not find function "findPackageEnv"
>>>
>>> Thus, the saved workspace remains inaccessible. I not 100% certain that
>>> languageR is the scapegoat, but my trial-and-error experiments indicate
>>> it is.
>>>
>>> My system is Win XP Home/Professional:
>>>
>>> > sessionInfo()
>>> R version 2.5.0 Patched (2007-04-24 r41305)
>>> i386-pc-mingw32
>>> locale:
>>> LC_COLLATE=German_Germany.1252;LC_CTYPE=German_Germany.1252;LC_MONETARY=German_Germany.1252;LC_NUMERIC=C;LC_TIME=German_Germany.1252 
>>>
>>> attached base packages:
>>> [1] "splines"   "stats"     "graphics"  "grDevices" "utils"
>>> [6] "datasets"  "methods"   "base"
>>> other attached packages:
>>>   languageR       rpart        MASS      Design    survival
>>>       "0.2"    "3.1-36"    "7.2-34"    "2.0-12"      "2.31"
>>>       Hmisc       e1071       class     cluster       zipfR
>>>     "3.3-2"    "1.5-16"    "7.2-34"    "1.11.7"     "0.6-0"
>>>        lme4        coda      Matrix     lattice
>>> "0.99875-1"    "0.11-2" "0.99875-2"    "0.15-8"
>>>
>>>
>>> thanks for any helpful suggestions!
>>>
>>> best
>>> R?diger
>>>
>>>
>>>
>>
>>
> 

-- 
Hans-R?diger Pfister
Professor of Business Psychology
University of L?neburg
Faculty for Business Administration, Behavioral Sciences and Law
Institute of Experimental Industrial Psychology (LueneLab)
Wilschenbrucher Weg 84
D-21335 L?neburg, Germany
+49-(0)4131 677 7759
pfister at uni-lueneburg.de


From h.wickham at gmail.com  Fri Jun 15 17:56:58 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 15 Jun 2007 17:56:58 +0200
Subject: [R] [OT] 'gv' and fractional points
In-Reply-To: <XFMail.070615161333.ted.harding@nessie.mcc.ac.uk>
References: <XFMail.070615161333.ted.harding@nessie.mcc.ac.uk>
Message-ID: <f8e6ff050706150856v7291e30fp94a13848ce0fc01a@mail.gmail.com>

This doesn't answer your original question, and isn't much help unless
you're on a mac, but there's a nice looking program that makes this
kind of graph scraping really easy:
http://www.arizona-software.ch/applications/graphclick/en/

Hadley

On 6/15/07, Ted Harding <ted.harding at nessie.mcc.ac.uk> wrote:
> Hi Folks,
>
> This is off-topic R-wise, but it may be close to
> the heart of many R-users, so I think it may be
> the best place to ask!
>
> Users of 'gv' (the "front end" to ghostscript) will
> be aware of the little window which gives you the
> x-y coordinates (in points = 1/72 inch) of the position
> of the "cross-hair" mouse cursor. These coordinates
> are those of the corresponding position on the printed
> page, relative to some origin.
>
> I have often used this to extract numerical values
> for data from graphs in Postscript files (also PDF
> files, after you have converted them to PS). Then
> (veering back on topic ... ) you can submit the
> numerical data to R and try your own analyses on
> these data, and compare with what the article does.
>
> However, this little window only gives the numbers
> in whole points. Say a smallish graphic may print
> out 3 inches wide or high. Then you get precision
> of 1/216 per 3 inches or 0.4% of full scale. This
> can be adequate on many occasions, but can be on
> the coarse side on other occasions.
>
> Even for a 6-inch-wide/high graph, you only get down
> to 0.2% of full scale.
>
> If it were possible to induce 'gv' to display these
> coordinates in tenths of a point, then much greater
> precision (as adequate as one can expect to hope for
> when, in effect, "measuring off the graph") could be
> obtained.
>
> Does anyone know:
> a) Whether it is possible to persuade 'gv' to give
>    this display in fractional points (my own search
>    of the documentation has not revealed anything);
> b) Of any alternative to 'gv' as PS viewer which would
>    provide this capability?
>
> With thanks, and best wishes to all,
> Ted.
>
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 15-Jun-07                                       Time: 16:13:21
> ------------------------------ XFMail ------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jqmcclintic at stthomas.edu  Fri Jun 15 18:25:39 2007
From: jqmcclintic at stthomas.edu (Jason Q McClintic)
Date: Fri, 15 Jun 2007 11:25:39 -0500
Subject: [R] A question about logical controls and function arguements
Message-ID: <4672BD83.5020405@stthomas.edu>

Dear R-help subscribers,

I'm trying to write a function to generate data simulating the image
created by a point radiation source in a plane on a screen where there
is filter with a single circular aperture in it between the source and
the screen.

Following some guides (including Intro to R and some I found online) and
examples I have specified the function (full code below question) with
several arguments with the form:

option=c("option1","option2")

For instance, I want filter to either be "FALSE" to tell the function
there is no filter or an ordered triplet describing the location and
radius of the area radiation is not blocked by the filter. There are
several others along similar lines.

When I source the function into R, it parses fine, but when attempting
to run it with

data.spect<-spect.data(source.p="r",filter=c(0,0,1),file.out="FALSE")

the following warning is returned:

Warning messages:
1: the condition has length > 1 and only the first element will be used
in: if (filter == "FALSE") {
2: the condition has length > 1 and only the first element will be used
in: if (filter == "FALSE") {

The code this is referencing is about 1/3 from the bottom of the function.

I'm not sure how to correct this. I tried ifelse in one case and it
doesn't work at all. Searching the archives for "function arguments"
didn't yield anything about the kind of arguments that are causing the
trouble.

I also want to get the matrix of generated data out, and have tried
data.spect$final.sample (following an example I found online), but it
returns null. I also attempted to use data.spect$initial.sample, but
this returned null as well.

I'm still very new to writing my own functions, and any and all help
would be appreciated.

There are notes about what different options are supposed to do at the
end of the appended code.

Thanks in advance,

Jason Q McClintic
--
Jason Q McClintic
jqmcclintic at stthomas.edu
mccl0219 at tc.umn.edu

spect.data<-function(num.points=50,fixed=FALSE,source.p=c("r","c(0,0)"),
   source.mean=0,source.sd=1,filter=c("FALSE","c(0,0,1)"),
   heights=c(0.5,0.5),
   file.out=c("FALSE","/home/jqmcclintic/Desktop/spect.data")){
	##Determine Start Point
	if (source.p=="r")
{source<-c(rnorm(1,source.mean,source.sd),rnorm(1,source.mean,source.sd))}
else {source<-source.p}
	cat("The location of the source is: ",source,"\n")
	##Generate the data
	remainder<-num.points
	initial.sample<-c(1,1)
	##finds intersection points with the screen
		intersect.screen.at<-function(x,h){
			t<-h[1]/(2*cos(x))
			x.intercept<-t*sin(x[,2])*cos(x[,1])
			y.intercept<-t*sin(x[,2])*sin(x[,1])
		}
	##finds intersection points with the collecting plate
		intersect.plate.at<-function(x,h){
			t<-h[2]/(2*cos(x))
			x.intercept<-t*sin(x[,2])*cos(x[,1])
			y.intercept<-t*sin(x[,2])*sin(x[,1])
		}
	##determines if the intersection point is inside or outside the hole in
the screen. x is the matrix of intersection points and s is the location
and radius of the hole in the screen. 1 for yes, 0 for no.
		passes.through<-function(x,s){
			distance<-sqrt(((x[,1]-s[1])^2)+((x[,2]-s[2])^2))
			through<-ifelse(distance<s[3],1,0)
		}
	##Build the sample
	while (remainder>0){
		##Generate n random vectors uniformly distributed over S2
		theta<-runif(remainder,0,6.2831853)
		phi<-runif(remainder,0,1.5707963)
		theta.phi<-cbind(theta,phi)
		initial.sample<-rbind(initial.sample,theta.phi)
		##Call intersect.screen.at
		intersects.screen<-intersect.screen.at(initial.sample,heights)
		##Call intersect.plate.at
		intersects.plate<-if(filter=="FALSE")
{intersect.screen.at(initial.sample,heights)} else {
			intersect.plate.at(initial.sample,heights)
		}
		##Does it intersect inside or outside the hole?
	
intersect.hole<-if(filter=="FALSE"){array(1,dim=length(initial.sample))}
else{passes.through(intersects.screen,filter)}
		##Remove points that do not pass throught the hole. By design, if
there is no filter, all pass through the hole.
		initial.sample<-cbind(initial.sample,intersect.hole)
		initial.sample<-subset(initial.sample,initial.sample[,3]==1)
		##Reset remainder
		remainder<-if(fixed=="FALSE") {0} else {
			num.points-length(initial.sample)
		}
	}
	write(initial.sample)
	##remove the top row of the initial sample since it is non-random.
	final.sample<-initial.sample[-1,]
	##print the final sample to a csv file for archival purposes
	if(file.out!="FALSE"){write.csv(final.sample,file=file.out);cat("The
location of the data is:",file.out,"\n")} else{cat("No csv file
requested","\n")}
}


From ripley at stats.ox.ac.uk  Fri Jun 15 18:43:33 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 15 Jun 2007 17:43:33 +0100 (BST)
Subject: [R] Problem with workspace loading after languageR use
In-Reply-To: <4672B51D.4010105@uni-lueneburg.de>
References: <467292E8.4050603@uni-lueneburg.de>
	<Pine.LNX.4.64.0706151522020.27080@auk.stats>
	<Pine.LNX.4.64.0706151606440.4570@gannet.stats.ox.ac.uk>
	<4672B51D.4010105@uni-lueneburg.de>
Message-ID: <Pine.LNX.4.64.0706151727430.5563@gannet.stats.ox.ac.uk>

Thank you for the example: it has enabled me to test a more comprehensive 
fix for R-patched (soon to be 2.5.1).

You should have got a warning when saving along the lines of

Warning message:
'package:languageR' may not be available when loading in: save(list = 
ls(envir = .GlobalEnv, all.names = TRUE), file = outfile,

The problem is indeed in package languageR, which is creating classes and 
methods in your workspace rather than in its package.  It really should 
not be doing so (it uses setMethod in .First.lib), and I am Cc:ing the 
maintainer in the hope that he will stop doing so.

I also find it hard to believe that

Depends: R (>= 2.4.0), methods, lattice, Matrix, coda, lme4, zipfR, 
cluster, e1071, Design, Hmisc, MASS, rpart

is totally necessary, and suggest that Suggests: is used.



On Fri, 15 Jun 2007, Pfister wrote:

> Dear Brian,
>
> thanks a lot for your advice.
>
> Prof Brian Ripley wrote:
>> On Fri, 15 Jun 2007, Prof Brian Ripley wrote:
>> 
>>> 
>>> I think adding the following to your new session before load() will help
>>> 
>>> findPackageEnv <- function(info)
>>>   as.environment(paste("package", "info", sep=":"))
>
> this does not work.
>
>> 
>> more likely
>> 
>> findPackageEnv <- function(info) as.environment(info)
>
> this works, if I load the languageR library before.
>
>> 
>> is correct.
>>> 
>>> will work, but if not try
>>> 
>>> findPackageEnv <- function(info) .GlobalEnv
>
> this works unconditionally. Including that line in a local .RProfile file, 
> basically solves the problem.
>
>>> 
>>> If you send me the problematic workspace (or reproduction instructions) I 
>>> can take a closer look.
>
> A typical session would look like this (using example data from Hox(2002)):
>
> # from Hox (2002)
> hoxpop <- read.table("http://www.ruediger-pfister.de/download/popular.dat", 
> header=TRUE)
> hoxpop$PUPIL <- factor(hoxpop$PUPIL)
> hoxpop$SCHOOL <- factor(hoxpop$SCHOOL)
> hoxpop$SEX <- factor(hoxpop$SEX)
>
> # load languageR
> library(languageR)
>
> # do some analyses ...
>
> # save the workspace
> save.image("D:\\statistics\\MultilevelAnalysis\\lm.RData")
>
>
> After quitting R, the workspace "lm.RData" will not reload.
> (this workspace can be downloaded here: 
> http://www.ruediger-pfister.de/Downloads/lmRData.zip)
>
>
> best
> R?diger
>
>
>
>>> 
>>> 
>>> On Fri, 15 Jun 2007, Pfister wrote:
>>> 
>>>> Hello R,
>>>> 
>>>> To analyze multi-level data, I started learning and using lmer. So far
>>>> so wonderful. I then found some useful functions in package languageR.
>>>> But then the following problem ocurred: Whenever I load and use the
>>>> languageR package, then save the workspace - or quit R with saving the
>>>> workspace - I am unable to reload that workspace in a later session.
>>>> That is, R doesn't start at all when I try to start it by clicking the
>>>> workspace file.
>>>> Loading languageR before loading the workspace doesn't help, but yields
>>>> the message:
>>>> 
>>>> Error in load("D:\\statistics\\MultilevelAnalysis\\.RData") :
>>>>         could not find function "findPackageEnv"
>>>> 
>>>> Thus, the saved workspace remains inaccessible. I not 100% certain that
>>>> languageR is the scapegoat, but my trial-and-error experiments indicate
>>>> it is.
>>>> 
>>>> My system is Win XP Home/Professional:
>>>> 
>>>> > sessionInfo()
>>>> R version 2.5.0 Patched (2007-04-24 r41305)
>>>> i386-pc-mingw32
>>>> locale:
>>>> LC_COLLATE=German_Germany.1252;LC_CTYPE=German_Germany.1252;LC_MONETARY=German_Germany.1252;LC_NUMERIC=C;LC_TIME=German_Germany.1252 
>>>> attached base packages:
>>>> [1] "splines"   "stats"     "graphics"  "grDevices" "utils"
>>>> [6] "datasets"  "methods"   "base"
>>>> other attached packages:
>>>>   languageR       rpart        MASS      Design    survival
>>>>       "0.2"    "3.1-36"    "7.2-34"    "2.0-12"      "2.31"
>>>>       Hmisc       e1071       class     cluster       zipfR
>>>>     "3.3-2"    "1.5-16"    "7.2-34"    "1.11.7"     "0.6-0"
>>>>        lme4        coda      Matrix     lattice
>>>> "0.99875-1"    "0.11-2" "0.99875-2"    "0.15-8"
>>>> 
>>>> 
>>>> thanks for any helpful suggestions!
>>>> 
>>>> best
>>>> R?diger
>>>> 
>>>> 
>>>> 
>>> 
>>> 
>> 
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From jqmcclintic at stthomas.edu  Fri Jun 15 19:01:35 2007
From: jqmcclintic at stthomas.edu (Jason Q McClintic)
Date: Fri, 15 Jun 2007 12:01:35 -0500
Subject: [R] A question about logical controls and function arguements
In-Reply-To: <644e1f320706150943r4fdff774y889a8eca86758c98@mail.gmail.com>
References: <644e1f320706150943r4fdff774y889a8eca86758c98@mail.gmail.com>
Message-ID: <4672C5EF.5000004@stthomas.edu>

Sir,

I freely admit my ignorance as to the subtleties of specifying arguments.

Let me make sure I understand your suggestion: create a variable filter
which takes 1 or 0 (filter or not) and another called, say,
filter.location which is the ordered triplet.

It does add to the number of options, but would seem to simplify the
underlying code. It appears I may have attempted to code above my skill
level.

Thanks for the assistance,

Jason Q McClintic
--
Jason Q McClintic
jqmcclintic at stthomas.edu
mccl0219 at tc.umn.edu

jim holtman wrote:
> You are trying to use 'filter' in two ways.  Your code is testing for a
> single value ("FALSE"), and that is all that "==" can do (single value),
> but you are pass in a vector (c(0,0,1)) which has three values, on the
> first of which can be tested by the "==".
>  
> So you might want to consider having another parameter which says
> whether or not to use "filter".
> 
>  
>> On 6/15/07, *Jason Q McClintic* <jqmcclintic at stthomas.edu
>> <mailto:jqmcclintic at stthomas.edu>> wrote:
>> 
>>     Dear R-help subscribers,
>> 
>>     I'm trying to write a function to generate data simulating the image
>>     created by a point radiation source in a plane on a screen where there
>>     is filter with a single circular aperture in it between the source and
>>     the screen.
>> 
>>     Following some guides (including Intro to R and some I found online)
>>     and
>>     examples I have specified the function (full code below question) with
>>     several arguments with the form:
>> 
>>     option=c("option1","option2")
>> 
>>     For instance, I want filter to either be "FALSE" to tell the function
>>     there is no filter or an ordered triplet describing the location and
>>     radius of the area radiation is not blocked by the filter. There are
>>     several others along similar lines.
>> 
>>     When I source the function into R, it parses fine, but when attempting
>>     to run it with
>> 
>>     data.spect<-spect.data(source.p="r",filter=c(0,0,1),file.out="FALSE")
>> 
>>     the following warning is returned:
>> 
>>     Warning messages:
>>     1: the condition has length > 1 and only the first element will be used
.>     in: if (filter == "FALSE") {
.>     2: the condition has length > 1 and only the first element will
be used
>>     in: if (filter == "FALSE") {
.>
>>     The code this is referencing is about 1/3 from the bottom of the
>>     function.
>> 
>>     I'm not sure how to correct this. I tried ifelse in one case and it
>>     doesn't work at all. Searching the archives for "function arguments"
>>     didn't yield anything about the kind of arguments that are causing the
>>     trouble.
>>     I also want to get the matrix of generated data out, and have tried
>>     data.spect$final.sample (following an example I found online), but it
>>     returns null. I also attempted to use data.spect$initial.sample , but
>>     this returned null as well.
>> 
>>     I'm still very new to writing my own functions, and any and all help
>>     would be appreciated.
>> 
>>     There are notes about what different options are supposed to do at the
.>     end of the appended code.
>> 
>>     Thanks in advance,
>> 
>>     Jason Q McClintic
>>     --
>>     Jason Q McClintic
>>     jqmcclintic at stthomas.edu <mailto:jqmcclintic at stthomas.edu>
>>     mccl0219 at tc.umn.edu <mailto:mccl0219 at tc.umn.edu>
>> 
>>     spect.data<-function(num.points=50,fixed=FALSE,source.p=c("r","c(0,0)"),
>>       source.mean=0,source.sd=1,filter=c("FALSE","c(0,0,1)"),
>>       heights=c(0.5,0.5),
>>       file.out=c ("FALSE","/home/jqmcclintic/Desktop/spect.data")){
>>            ##Determine Start Point
>>            if (source.p=="r")
>>     {source<-c(rnorm(1,source.mean,source.sd <http://source.sd>
>>     ),rnorm(1,source.mean,source.sd <http://source.sd>))}
>>     else {source<-source.p}
>>            cat("The location of the source is: ",source,"\n")
>>            ##Generate the data
>>            remainder<- num.points
>>            initial.sample<-c(1,1)
>>            ##finds intersection points with the screen
>>                    intersect.screen.at
>>     <http://intersect.screen.at><-function(x,h){
>>                            t<-h[1]/(2*cos(x))
>>                            x.intercept<-t*sin(x[,2])*cos(x[,1])
>>                            y.intercept<-t*sin(x[,2])*sin(x[,1])
>>                    }
>>            ##finds intersection points with the collecting plate
>>                    intersect.plate.at
>>     <http://intersect.plate.at><-function(x,h){
>>                            t<-h[2]/(2*cos(x))
>>                            x.intercept<-t*sin(x[,2])*cos(x[,1])
>>                            y.intercept <-t*sin(x[,2])*sin(x[,1])
.>                    }
>>            ##determines if the intersection point is inside or outside
>>     the hole in
>>     the screen. x is the matrix of intersection points and s is the location
>>     and radius of the hole in the screen. 1 for yes, 0 for no.
>>                    passes.through<-function(x,s){
>>                            distance<-sqrt(((x[,1]-s[1])^2)+((x[,2]-s[2])^2))
>>                            through<-ifelse(distance<s[3],1,0)
>>                    }
>>            ##Build the sample
>>            while (remainder>0){
>>                    ##Generate n random vectors uniformly distributed over S2
>>                    theta<-runif(remainder,0,6.2831853)
>>                    phi<-runif(remainder,0, 1.5707963)
>>                    theta.phi<-cbind(theta,phi)
>>                    initial.sample<-rbind(initial.sample,theta.phi)
>>                    ##Call intersect.screen.at <http://intersect.screen.at>
>>                   
>>     intersects.screen<-intersect.screen.at(initial.sample,heights)
>>                    ##Call intersect.plate.at <http://intersect.plate.at>
>>                    intersects.plate<-if(filter=="FALSE")
>>     {intersect.screen.at(initial.sample,heights)} else {
>>                            intersect.plate.at(initial.sample,heights)
>>                    }
>>                    ##Does it intersect inside or outside the hole?
>> 
>>     intersect.hole
>>     <-if(filter=="FALSE"){array(1,dim=length(initial.sample))}
>>     else{passes.through(intersects.screen,filter)}
>>                    ##Remove points that do not pass throught the hole.
>>     By design, if
>>     there is no filter, all pass through the hole.
>>                    initial.sample<-cbind(initial.sample,intersect.hole)
>>                   
>>     initial.sample<-subset(initial.sample,initial.sample[,3]==1)
>>                    ##Reset remainder
>>                    remainder<-if(fixed=="FALSE") {0} else {
>>                            num.points-length(initial.sample)
>>                    }
>>            }
>>            write(initial.sample)
>>            ##remove the top row of the initial sample since it is
>>     non-random.
>>            final.sample <-initial.sample[-1,]
>>            ##print the final sample to a csv file for archival purposes
>>           
>>     if(file.out!="FALSE"){write.csv(final.sample,file=file.out);cat("The
>>     location of the data is:", file.out,"\n")} else{cat("No csv file
>>     requested","\n")}
>>     }
>> 
>>     ______________________________________________
>>     R-help at stat.math.ethz.ch <mailto:R-help at stat.math.ethz.ch> mailing list
>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>     PLEASE do read the posting guide
>>     http://www.R-project.org/posting-guide.html
>>     <http://www.R-project.org/posting-guide.html>
>>     and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
>> 
>> -- 
>> Jim Holtman
>> Cincinnati, OH
>> +1 513 646 9390
>> 
>> What is the problem you are trying to solve?


From lise.bellanger at univ-nantes.fr  Fri Jun 15 20:12:14 2007
From: lise.bellanger at univ-nantes.fr (Bellanger Lise)
Date: Fri, 15 Jun 2007 19:12:14 +0100
Subject: [R] Registration density profiles using FDA (Functional Data
	Analysis)
Message-ID: <4672D67E.5040705@univ-nantes.fr>

Hello,


      I would like to use  fda (Functional data analysis) library  to 
compare sampled curves that are density profiles. But I encounter some 
problems to register my data as functional data.
I know that I must use a registration function to align functions in 
order to have important features found in each curve occur at roughly 
the same argument value, prior to do subsequent analysis ( PCA and 
cluster analysis).   But I do not know which function (if there exists 
one) allows me  to synchronize density profiles : could help me please ?

  Thank you by advance

  Best regards

        Lise Bellanger

-- 
Lise Bellanger, 
Universit? de Nantes
D?partement de Math?matiques, Laboratoire Jean Leray UMR CNRS 6629 
2, Rue de la Houssini?re BP 92208 - F-44322 Nantes Cedex 03 
T?l. : (33|0) 2 51 12 59 00 (ou 43) - Fax : (33|0) 2 51 12 59 12 
E-Mail : lise.bellanger at univ-nantes.fr
URL : http://www.math.sciences.univ-nantes.fr/


From ripley at stats.ox.ac.uk  Fri Jun 15 19:11:40 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 15 Jun 2007 18:11:40 +0100 (BST)
Subject: [R] subscript out of bounds error in lda
In-Reply-To: <11142304.post@talk.nabble.com>
References: <11142304.post@talk.nabble.com>
Message-ID: <Pine.LNX.4.64.0706151805570.6201@gannet.stats.ox.ac.uk>

On Fri, 15 Jun 2007, Silvia Lomascolo wrote:

>
> I work with Windows, R version 2.4.1
>
> I'm trying to do a discriminant analysis and, in trying to figure out how to
> do it following the example from R help, I'm getting an error that says
> 'subscript out of bounds'.  I don't know what this means and how to solve it
> (I'm very new with R)
>
> I'm doing everything in this made-up test matrix:
>
>   group var1 var2 var3
> 1      1    3   55    6
> 2      1    4   66    7
> 3      1    5   55    8
> 4      1    4   66    7
> 5      1    3   44    6
> 6      1    4   55    5
> 7      2    5   88    9
> 8      2    4   99    8
> 9      2    8   88    9
> 10     2    9   76    8
> 11     2    8   66    9
> 12     2    9   99   10
> 13     2   10  100    9
>
> I write:
>
> data.tb<-read.table('locationHere.txt', header=T)
> data.df<-as.data.frame (data.tb)

Wny call as.data.frame on a data frame?

> train<-sample (1:63, 30)

Why sample from 1:63 with 13 rows?

> table (data.df$group[train])
> data.disc<-lda(group~., data.tb, subset = train)
> data.disc
> predict (data.disc, data.df[-train,])$class
>
> This is where I get the message:
>
> Error in `[.data.frame`(data.df, -train, ) :
>        subscript out of bounds

traceback() is your friend:

> traceback()
8: `[.data.frame`(data.df, -train, )
7: data.df[-train, ]
6: inherits(x, "data.frame")
5: is.data.frame(data)
4: model.frame.default(Terms, newdata, na.action = na.pass, xlev = 
object$xlevels)
3: model.frame(Terms, newdata, na.action = na.pass, xlev = object$xlevels)
2: predict.lda(data.disc, data.df[-train, ])
1: predict(data.disc, data.df[-train, ])
>

So, let's take a look at the top lines.

> train
  [1] 46 42 30 13 27 63 19 47  3 52 62 16 26  4 61 23 59 44 40 38 25 55 50 
10 43
[26]  2  8 31  7 11
> nrow(data.df)
[1] 13

So, you are asking for number 46 out of 13 rows.  Now perhaps you didn't 
show us all the problem, but hopefully this helps you find the error.  If 
not, the bottom of every R-help message says

PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From billycorg1 at virgilio.it  Fri Jun 15 19:22:33 2007
From: billycorg1 at virgilio.it (billycorg)
Date: Fri, 15 Jun 2007 10:22:33 -0700 (PDT)
Subject: [R] problems with matrix, list and other..
In-Reply-To: <467289EA.7070204@karlin.mff.cuni.cz>
References: <11135888.post@talk.nabble.com>
	<467289EA.7070204@karlin.mff.cuni.cz>
Message-ID: <11144182.post@talk.nabble.com>


thank you!
it works with:
E=list()
length(E)=1096
for(i in (2:1096)){E[[i]]=crossprod(solve(d[[i]]),cbind(e[[i]]))}




Petr Klasterecky wrote:
> 
> You only got what you deserved when not reading the manual...
> R-Intro, Chapters 5 and 6, page 26 in particular.
> http://cran.r-project.org/doc/manuals/R-intro.pdf
> 
> Petr
> 
> 
> billycorg napsal(a):
>> hi
>> 
>> can anyone help me to solve these problems?
>> 
>> i have:
>> 1) "d" matrix with 1096 rows;
>> for example, 
>> d[2]=        
>>                    [,1]           [,2]          [,3]
>> [1,] 0.1192566 0.0000000 0.0000000
>> [2,] 0.0000000 0.1065938 0.0000000
>> [3,] 0.0000000 0.0000000 0.1038888
>> 
>> if I
>> class (d[2]) = "list" 
>> solve(d[2]) = error!!!
>> 
>> 2) "e" list with 1096 rows;
>> for example
>> e[2]2=
>> [[1]]
>> [1] -1.0892216 -0.7304947 -1.2883680
>> 
>> d[2]%*%t(e[2])
>> this is the error: requires numeric matrix/vector arguments
>> 
>> i've tried to coerce "e" to a matrix, but it's doesn't work...
>> 
>> in the end.. i'd like this:
>> for (i in (1:1096)) {solve(d[i])*t(e[i])}
>> 
>> help me, please :)
>> 
>> Vincenzo
> 
> -- 
> Petr Klasterecky
> Dept. of Probability and Statistics
> Charles University in Prague
> Czech Republic
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/problems-with-matrix%2C-list-and-other..-tf3926701.html#a11144182
Sent from the R help mailing list archive at Nabble.com.


From nikko at hailmail.net  Fri Jun 15 19:29:10 2007
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Fri, 15 Jun 2007 13:29:10 -0400
Subject: [R] complex contrasts and logistic regression
Message-ID: <1181928550.18770.1195374609@webmail.messagingengine.com>

Hi,
I am doing a retrospective analysis on a cohort from a designed trial,
and I am fitting
the model

fit<-glmD(survived ~ Covariate*Therapy + confounder,myDat,X=TRUE,
Y=TRUE, family=binomial()) 

My covariate has three levels ("A","B" and "C") and therapy has two
(treated and control), confounder is a continuous variable.
Also patients were randomized to treatment in the trial, but Covariate
is something that is measured
posthoc and can vary in the population.
 
I am trying to wrap my head around how to calculate a few quantities
from the model
and get reasonable confidence intervals for them, namely I would like to
test

H0: gamma=0, where gamma is the regression coefficient of the odds
ratios of surviving
             under treatment vs control at each level of Covariate
             (adjusted for the confounder)

and I would like to get the odds of surviving at each level of Covariate
under treatment and control
for each level of covariate adjusted for the confounder. I have looked
at contrast in the Design 
library but I don't think it gives me the right quantity, for instance 

contrast(fit,list(covariate="A", Therapy="Treated",
confounder=median(myDat$confounder), X=TRUE)
( "A" is the baseline level of Covariate) 

gives me beta0 + beta_Treated + beta_confounder*68  

Is this correctly interpreted as the conditional odds of dying? 
As to the 1st contrast I am not sure how to get it, would it be using
type = 'average' with some weights 
in contrast? The answers are probably staring me in the face, i am just
not seeing them today.

Nicholas


From sarah.goslee at gmail.com  Fri Jun 15 19:35:51 2007
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 15 Jun 2007 13:35:51 -0400
Subject: [R] text display using expression or not
Message-ID: <efb536d50706151035u4c03e6a7h83f09abe3aeada89@mail.gmail.com>

Hello,

I imagine that I'm missing something straightforward, but a run thru
the help files didn't turn up an answer.

I noticed while formatting some figures for publication that text
enclosed in expression() and used for a title displays differently
than a string, regardless of the par options. On both postscript()
and x11() devices, the regular text is heavier than the expression text.

Here's an example. The "real thing" used expression() to
produce superscripts, but I boiled this down to the simplest possible
case.

par(mfrow=c(2,1))
plot(1:10, 1:10, main="Figure A")
plot(1:10, 1:10, main=expression("Figure B"))

Is there some straightforward way to make them match, other
than putting expression() around all strings?


I'm currently using R 2.5.0 on Fedora core 5.

Thanks,
Sarah

-- 
Sarah Goslee
http://www.functionaldiversity.org


From Max.Kuhn at pfizer.com  Fri Jun 15 19:41:33 2007
From: Max.Kuhn at pfizer.com (Kuhn, Max)
Date: Fri, 15 Jun 2007 13:41:33 -0400
Subject: [R] R vs. Splus in Pharma/Devices Industry
In-Reply-To: <07E228A5BE53C24CAD490193A7381BBBA21F63@LP-EXCHVS07.CO.IHC.COM>
Message-ID: <71257D09F114DA4A8E134DEAC70F25D308AB074F@groamrexm03.amer.pfizer.com>

Greg,

> I have looked at ooconvert, but unfortunately the current version is
> limited to *nix, and I am currently in a MS windows world.  I tried
> getting it to run under cygwin at one point, but did not succeed at
the
> time.  Once it is available more generally, I will just set up
Makefiles
> so that I can automatically produce either .doc or .pdf documents from
> my templates and data.

I found the Java tool at

   http://www.artofsolving.com/opensource/jodconverter

(they changed the name). I just tried it on my Windows machine and it
worked. You have to start a headless soffice process (see the readme
file) and then it is a simple command line away.

Max

----------------------------------------------------------------------
LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}


From newruser at yahoo.com  Fri Jun 15 20:19:22 2007
From: newruser at yahoo.com (new ruser)
Date: Fri, 15 Jun 2007 11:19:22 -0700 (PDT)
Subject: [R] removing values from a vector,
	where both the value and its name are the same?
Message-ID: <765851.84492.qm@web63904.mail.re1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070615/e9c5dd0a/attachment.pl 

From deepayan.sarkar at gmail.com  Fri Jun 15 20:43:58 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Fri, 15 Jun 2007 11:43:58 -0700
Subject: [R] [OT] 'gv' and fractional points
In-Reply-To: <XFMail.070615161333.ted.harding@nessie.mcc.ac.uk>
References: <XFMail.070615161333.ted.harding@nessie.mcc.ac.uk>
Message-ID: <eb555e660706151143o79137d08mc4183f579dcbc863@mail.gmail.com>

On 6/15/07, Ted Harding <ted.harding at nessie.mcc.ac.uk> wrote:
> Hi Folks,
>
> This is off-topic R-wise, but it may be close to
> the heart of many R-users, so I think it may be
> the best place to ask!
>
> Users of 'gv' (the "front end" to ghostscript) will
> be aware of the little window which gives you the
> x-y coordinates (in points = 1/72 inch) of the position
> of the "cross-hair" mouse cursor. These coordinates
> are those of the corresponding position on the printed
> page, relative to some origin.
>
> I have often used this to extract numerical values
> for data from graphs in Postscript files (also PDF
> files, after you have converted them to PS). Then
> (veering back on topic ... ) you can submit the
> numerical data to R and try your own analyses on
> these data, and compare with what the article does.
>
> However, this little window only gives the numbers
> in whole points. Say a smallish graphic may print
> out 3 inches wide or high. Then you get precision
> of 1/216 per 3 inches or 0.4% of full scale. This
> can be adequate on many occasions, but can be on
> the coarse side on other occasions.

If you are mostly concerned about small figures, one possibility is

1. zoom out to a level where you're happy with the pixel resolution
2. do a screen capture using 'import'
3. use gimp (which has the same feature, with more units)

gimp can also load PS files directly, with a user supplied zoom factor
at load time, but only one page at a time, AFAICT.

-Deepayan


From jholtman at gmail.com  Fri Jun 15 20:47:41 2007
From: jholtman at gmail.com (jim holtman)
Date: Fri, 15 Jun 2007 14:47:41 -0400
Subject: [R] removing values from a vector,
	where both the value and its name are the same?
In-Reply-To: <765851.84492.qm@web63904.mail.re1.yahoo.com>
References: <765851.84492.qm@web63904.mail.re1.yahoo.com>
Message-ID: <644e1f320706151147q3ec347ady8641012cb056340d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070615/3e6059d9/attachment.pl 

From marc_schwartz at comcast.net  Fri Jun 15 20:49:45 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Fri, 15 Jun 2007 13:49:45 -0500
Subject: [R] removing values from a vector,
	where both the value and	its name are the same?
In-Reply-To: <765851.84492.qm@web63904.mail.re1.yahoo.com>
References: <765851.84492.qm@web63904.mail.re1.yahoo.com>
Message-ID: <1181933385.3683.38.camel@Bellerophon.localdomain>

On Fri, 2007-06-15 at 11:19 -0700, new ruser wrote:
> I have an array such as:
> 
> x=c(sum=77, min=4,max=9, count=5, min=4,max=9, count=8 ,  test=77)
> 
> I wish to remove values where both the name and the value are identical.
> 
> eg. i wish to end up with:
> x2=c(sum=77, min=4,max=9, count=5, count=8, test=77)
>  
> What is the "best" way to do this?

Not sure if this is the best way, but since you need to compare both the
values and their name attributes for 'uniqueness':

> x[!(duplicated(x) & duplicated(names(x)))]
  sum   min   max count count  test 
   77     4     9     5     8    77 


What is being done is to first compare the values for duplicates. Note
that the second value is identified as the duplicate, not the first:

> duplicated(x)
[1] FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE  TRUE

and then compare the names for duplicates:

> duplicated(names(x))
[1] FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE


Then compare the two logical vectors and get the indices where BOTH are
TRUE:

> (duplicated(x) & duplicated(names(x)))
[1] FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE FALSE


Now, negate the relation:

> !(duplicated(x) & duplicated(names(x)))
[1]  TRUE  TRUE  TRUE  TRUE FALSE FALSE  TRUE  TRUE


and return the values in 'x' that satisfy the logical indices:

> x[!(duplicated(x) & duplicated(names(x)))]
  sum   min   max count count  test 
   77     4     9     5     8    77 



See ?duplicated.  You might also want to look
at ?unique, ?identical, ?all.equal and ?isTRUE.

Note that the above example will likely fail if any of the values are
floats:

> duplicated(c(0.5 - 0.4, 0.1))
[1] FALSE FALSE

in which case, you would need to use a looping structure where the value
comparisons use isTrue(all.equal(...)) instead.


HTH,

Marc Schwartz


From nikko at hailmail.net  Fri Jun 15 21:03:13 2007
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Fri, 15 Jun 2007 15:03:13 -0400
Subject: [R] R vs. Splus in Pharma/Devices Industry
Message-ID: <1181934193.4957.1195396717@webmail.messagingengine.com>

Hi,
I just saw this thread. This issue, and the larger scale issue of open
source in industry
is being addressed. One has to realize that the behemoth that is the
clinical aperatus
of the pharma industry is very conservative and very slow to change. In
many cases 
switching to R would meean changing a great many processes all based on
legacy code. One
of the big issues is that the industry demands consistency not
necessarily correctness.

All that said there are a great many areas where R could be used that
would not impact
regulatory submission, data security etc. Many in pharma are quietly
working on this,
but steps are small and incremental. Development takes time in industry
because of the amount of
documentation necessary. All this impacts the "free" nature of R and
cost and risk (From the industries
perspective) need to be justified. 

Probably when the statistical community is using Z big pharma will be
ready to use
R. %P

Nicholas


From mcaro72 at gmail.com  Fri Jun 15 21:07:44 2007
From: mcaro72 at gmail.com (Miguel Caro)
Date: Fri, 15 Jun 2007 12:07:44 -0700 (PDT)
Subject: [R] how to plot two graphics in one window
Message-ID: <11145186.post@talk.nabble.com>


Hello ,
Maybe this question you answered before, but i couldnt find something
indicated in the mailing list.

I wish to plot two graphics  in one window, for example y=sinx and y=exp(x)
in the same windows, (the same interval for x).

Thanks .

Miguel.
-- 
View this message in context: http://www.nabble.com/how-to-plot-two-graphics-in-one-window-tf3929594.html#a11145186
Sent from the R help mailing list archive at Nabble.com.


From deepayan.sarkar at gmail.com  Fri Jun 15 21:23:48 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Fri, 15 Jun 2007 12:23:48 -0700
Subject: [R] model.frame: how does one use it?
In-Reply-To: <18034.46215.223478.311352@basebud.nulle.part>
References: <18034.46215.223478.311352@basebud.nulle.part>
Message-ID: <eb555e660706151223p1d1f45e9j2dc835b3bec9e242@mail.gmail.com>

On 6/15/07, Dirk Eddelbuettel <edd at debian.org> wrote:
>
> Philipp Benner reported a Debian bug report against r-cran-rpart aka rpart.
> In short, the issue has to do with how rpart evaluates a formula and
> supporting arguments, in particular 'weights'.
>
> A simple contrived example is
>
> -----------------------------------------------------------------------------
> library(rpart)
>
> ## using data from help(rpart), set up simple example
> myformula <- formula(Kyphosis ~ Age + Number + Start)
> mydata <- kyphosis
> myweight <- abs(rnorm(nrow(mydata)))
>
> goodFunction <- function(mydata, myformula, myweight) {
>   hyp <- rpart(myformula, data=mydata, weights=myweight, method="class")
>   prev <- hyp
> }
> goodFunction(mydata, myformula, myweight)
> cat("Ok\n")
>
> ## now remove myweight and try to compute it inside a function
> rm(myweight)
>
> badFunction <- function(mydata, myformula) {
>   myweight <- abs(rnorm(nrow(mydata)))
>   mf <- model.frame(myformula, mydata, myweight)
>   print(head(df))
>   hyp <- rpart(myformula,
>                data=mf,
>                weights=myweight,
>                method="class")
>   prev <- hyp
> }
> badFunction(mydata, myformula)
> cat("Done\n")
> -----------------------------------------------------------------------------
>
> Here goodFunction works, but only because myweight (with useless random
> weights, but that is not the point here) is found from the calling
> environment.
>
> badFunction fails after we remove myweight from there:
>
> :~> cat /tmp/philipp.R | R --slave
> Ok
> Error in eval(expr, envir, enclos) : object "myweight" not found
> Execution halted
> :~>
>
> As I was able to replicate it, I reported this to the package maintainer.  It
> turns out that seemingly all is well as this is supposed to work this way,
> and I got a friendly pointer to study model.frame and its help page.
>
> Now I am stuck as I can't make sense of model.frame -- see badFunction
> above. I would greatly appreciate any help in making rpart work with a local
> argument weights so that I can tell Philipp that there is no bug.  :)

I don't know if ?model.frame is the best place page to look. There's a
more detailed description at

http://developer.r-project.org/nonstandard-eval.pdf

but here are the non-standard evaluation rules as I understand them:
given a name in either (1) the formula or (2) ``special'' arguments like
'weights' in this case, or 'subset', try to find the name

1. in 'data'
2. failing that, in environment(formula)
3. failing that, in the enclosing environment, and so on.

By 'name', I mean a symbol, such as 'Age' or 'myweight'.  So
basically, everything is as you would expect if the name is visible in
data, but if not, the search starts in the environment of the formula,
not the environment where the function call is being made (which is
the standard evaulation behaviour).  This is a feature, not a bug
(things would be a lot more confusing if it were the other way round).


With this in mind, either of the following might do what you want:

badFunction <- function(mydata, myformula) {
    mydata$myweight <- abs(rnorm(nrow(mydata)))
    hyp <-
        rpart(myformula,
              data=mydata,
              weights=myweight,
              method="class")
    prev <- hyp
}


badFunction <- function(mydata, myformula) {
    myweight <- abs(rnorm(nrow(mydata)))
    environment(myformula) <- environment()
    hyp <-
        rpart(myformula,
              data=mydata,
              weights=myweight,
              method="class")
    prev <- hyp
}

-Deepayan


From pburns at pburns.seanet.com  Fri Jun 15 21:25:20 2007
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Fri, 15 Jun 2007 20:25:20 +0100
Subject: [R] removing values from a vector,
 where both the value and its name are the same?
In-Reply-To: <644e1f320706151147q3ec347ady8641012cb056340d@mail.gmail.com>
References: <765851.84492.qm@web63904.mail.re1.yahoo.com>
	<644e1f320706151147q3ec347ady8641012cb056340d@mail.gmail.com>
Message-ID: <4672E7A0.3040704@pburns.seanet.com>

In case it matters, the given solution has a problem if the
data look like:

x <- c(sum=77, test=99, sum=99)

By the description all three elements should be kept, but
the duplicated solution throws out the last element.  A more
complicated solution is:

unique(data.frame(x, names(x)))

(and then put the vector back together again).

Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

jim holtman wrote:

>try this:
>
>  
>
>>x[!(duplicated(names(x))&duplicated(x))]
>>    
>>
>  sum   min   max count count  test
>   77     4     9     5     8    77
>
>
>
>On 6/15/07, new ruser <newruser at yahoo.com> wrote:
>  
>
>>I have an array such as:
>>
>>x=c(sum=77, min=4,max=9, count=5, min=4,max=9, count=8 ,  test=77)
>>
>>I wish to remove values where both the name and the value are identical.
>>
>>eg. i wish to end up with:
>>x2=c(sum=77, min=4,max=9, count=5, count=8, test=77)
>>
>>What is the "best" way to do this?
>>
>>
>>---------------------------------
>>Park yourself in front of a world of choices in alternative vehicles.
>>
>>       [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>>
>>    
>>
>
>
>
>  
>


From Cody_Hamilton at Edwards.com  Fri Jun 15 21:21:25 2007
From: Cody_Hamilton at Edwards.com (Cody_Hamilton at Edwards.com)
Date: Fri, 15 Jun 2007 12:21:25 -0700
Subject: [R]  R vs. Splus in Pharma/Devices Industry
Message-ID: <OF6DF20371.9FF5C12E-ON882572FB.006A1E98-882572FB.006A21B3@irvine.edwards.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070615/ec0378de/attachment.pl 

From h.wickham at gmail.com  Fri Jun 15 21:29:31 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 15 Jun 2007 21:29:31 +0200
Subject: [R] model.frame: how does one use it?
In-Reply-To: <eb555e660706151223p1d1f45e9j2dc835b3bec9e242@mail.gmail.com>
References: <18034.46215.223478.311352@basebud.nulle.part>
	<eb555e660706151223p1d1f45e9j2dc835b3bec9e242@mail.gmail.com>
Message-ID: <f8e6ff050706151229j917e8e0q163f3a34b26d3b9c@mail.gmail.com>

On 6/15/07, Deepayan Sarkar <deepayan.sarkar at gmail.com> wrote:
> On 6/15/07, Dirk Eddelbuettel <edd at debian.org> wrote:
> >
> > Philipp Benner reported a Debian bug report against r-cran-rpart aka rpart.
> > In short, the issue has to do with how rpart evaluates a formula and
> > supporting arguments, in particular 'weights'.
> >
> > A simple contrived example is
> >
> > -----------------------------------------------------------------------------
> > library(rpart)
> >
> > ## using data from help(rpart), set up simple example
> > myformula <- formula(Kyphosis ~ Age + Number + Start)
> > mydata <- kyphosis
> > myweight <- abs(rnorm(nrow(mydata)))
> >
> > goodFunction <- function(mydata, myformula, myweight) {
> >   hyp <- rpart(myformula, data=mydata, weights=myweight, method="class")
> >   prev <- hyp
> > }
> > goodFunction(mydata, myformula, myweight)
> > cat("Ok\n")
> >
> > ## now remove myweight and try to compute it inside a function
> > rm(myweight)
> >
> > badFunction <- function(mydata, myformula) {
> >   myweight <- abs(rnorm(nrow(mydata)))
> >   mf <- model.frame(myformula, mydata, myweight)
> >   print(head(df))
> >   hyp <- rpart(myformula,
> >                data=mf,
> >                weights=myweight,
> >                method="class")
> >   prev <- hyp
> > }
> > badFunction(mydata, myformula)
> > cat("Done\n")
> > -----------------------------------------------------------------------------
> >
> > Here goodFunction works, but only because myweight (with useless random
> > weights, but that is not the point here) is found from the calling
> > environment.
> >
> > badFunction fails after we remove myweight from there:
> >
> > :~> cat /tmp/philipp.R | R --slave
> > Ok
> > Error in eval(expr, envir, enclos) : object "myweight" not found
> > Execution halted
> > :~>
> >
> > As I was able to replicate it, I reported this to the package maintainer.  It
> > turns out that seemingly all is well as this is supposed to work this way,
> > and I got a friendly pointer to study model.frame and its help page.
> >
> > Now I am stuck as I can't make sense of model.frame -- see badFunction
> > above. I would greatly appreciate any help in making rpart work with a local
> > argument weights so that I can tell Philipp that there is no bug.  :)
>
> I don't know if ?model.frame is the best place page to look. There's a
> more detailed description at
>
> http://developer.r-project.org/nonstandard-eval.pdf
>
> but here are the non-standard evaluation rules as I understand them:
> given a name in either (1) the formula or (2) ``special'' arguments like
> 'weights' in this case, or 'subset', try to find the name
>
> 1. in 'data'
> 2. failing that, in environment(formula)
> 3. failing that, in the enclosing environment, and so on.
>
> By 'name', I mean a symbol, such as 'Age' or 'myweight'.  So
> basically, everything is as you would expect if the name is visible in
> data, but if not, the search starts in the environment of the formula,
> not the environment where the function call is being made (which is
> the standard evaulation behaviour).  This is a feature, not a bug
> (things would be a lot more confusing if it were the other way round).

Could you give an example?  It's always seemed confusing to me and I
don't see why looking in the environment of the formula helps.

Hadley


From bates at stat.wisc.edu  Fri Jun 15 21:30:45 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 15 Jun 2007 14:30:45 -0500
Subject: [R] R vs. Splus in Pharma/Devices Industry
In-Reply-To: <1181934193.4957.1195396717@webmail.messagingengine.com>
References: <1181934193.4957.1195396717@webmail.messagingengine.com>
Message-ID: <40e66e0b0706151230o1e3a8f49va55f28f4e9cb689d@mail.gmail.com>

On 6/15/07, Nicholas Lewin-Koh <nikko at hailmail.net> wrote:
> Hi,
> I just saw this thread. This issue, and the larger scale issue of open
> source in industry
> is being addressed. One has to realize that the behemoth that is the
> clinical aperatus
> of the pharma industry is very conservative and very slow to change. In
> many cases
> switching to R would meean changing a great many processes all based on
> legacy code. One
> of the big issues is that the industry demands consistency not
> necessarily correctness.
>
> All that said there are a great many areas where R could be used that
> would not impact
> regulatory submission, data security etc. Many in pharma are quietly
> working on this,
> but steps are small and incremental. Development takes time in industry
> because of the amount of
> documentation necessary. All this impacts the "free" nature of R and
> cost and risk (From the industries
> perspective) need to be justified.

> Probably when the statistical community is using Z big pharma will be
> ready to use
> R. %P

I think you mean A, not Z.  First there was S, then there was R.


From marc_schwartz at comcast.net  Fri Jun 15 21:33:24 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Fri, 15 Jun 2007 14:33:24 -0500
Subject: [R] model.frame: how does one use it?
In-Reply-To: <18034.46215.223478.311352@basebud.nulle.part>
References: <18034.46215.223478.311352@basebud.nulle.part>
Message-ID: <1181936004.3697.6.camel@Bellerophon.localdomain>

On Fri, 2007-06-15 at 10:47 -0500, Dirk Eddelbuettel wrote: 
> Philipp Benner reported a Debian bug report against r-cran-rpart aka rpart.
> In short, the issue has to do with how rpart evaluates a formula and
> supporting arguments, in particular 'weights'.  
> 
> A simple contrived example is
> 
> -----------------------------------------------------------------------------
> library(rpart)
> 
> ## using data from help(rpart), set up simple example
> myformula <- formula(Kyphosis ~ Age + Number + Start)
> mydata <- kyphosis
> myweight <- abs(rnorm(nrow(mydata)))
> 
> goodFunction <- function(mydata, myformula, myweight) {
>   hyp <- rpart(myformula, data=mydata, weights=myweight, method="class")
>   prev <- hyp
> }
> goodFunction(mydata, myformula, myweight)
> cat("Ok\n")
> 
> ## now remove myweight and try to compute it inside a function
> rm(myweight)
> 
> badFunction <- function(mydata, myformula) {
>   myweight <- abs(rnorm(nrow(mydata)))
>   mf <- model.frame(myformula, mydata, myweight)
>   print(head(df))
>   hyp <- rpart(myformula,
>                data=mf,
>                weights=myweight,
>                method="class")
>   prev <- hyp
> }
> badFunction(mydata, myformula)
> cat("Done\n")
> -----------------------------------------------------------------------------
> 
> Here goodFunction works, but only because myweight (with useless random
> weights, but that is not the point here) is found from the calling
> environment. 
> 
> badFunction fails after we remove myweight from there:
> 
> :~> cat /tmp/philipp.R | R --slave
> Ok
> Error in eval(expr, envir, enclos) : object "myweight" not found
> Execution halted
> :~>    
> 
> As I was able to replicate it, I reported this to the package maintainer.  It
> turns out that seemingly all is well as this is supposed to work this way,
> and I got a friendly pointer to study model.frame and its help page.  
> 
> Now I am stuck as I can't make sense of model.frame -- see badFunction
> above. I would greatly appreciate any help in making rpart work with a local
> argument weights so that I can tell Philipp that there is no bug.  :)
> 
> Regards, Dirk


Dirk,

As you note, the issue is the non-standard evaluation of the arguments
in model.frame()  The key section of the Details in ?model.frame is:


All the variables in formula, subset and in ... are looked for first in
data and then in the environment of formula (see the help for formula()
for further details) and collected into a data frame. Then the subset
expression is evaluated, and it is is used as a row index to the data
frame. Then the na.action function is applied to the data frame (and may
well add attributes). The levels of any factors in the data frame are
adjusted according to the drop.unused.levels and xlev arguments.


Note that even with your goodFunction(), if 'myweight' is created within
the environment of the function and not in the global environment, it
still fails:

library(rpart)
myformula <- formula(Kyphosis ~ Age + Number + Start)
mydata <- kyphosis

goodFunction <- function(mydata, myformula) {
                         myweight <- abs(rnorm(nrow(mydata)))
                         hyp <- rpart(myformula, data=mydata,
                                      weights=myweight, method="class")
                         prev <- hyp
                        }


> goodFunction(mydata, myformula)
Error in eval(expr, envir, enclos) : object "myweight" not found


However, now let's do this:


library(rpart)
myformula <- formula(Kyphosis ~ Age + Number + Start)
mydata <- kyphosis
myweight <- abs(rnorm(nrow(mydata)))

goodFunction <- function(mydata, myformula) {
                         hyp <- rpart(myformula, data=mydata,
                                      weights=myweight, method="class")
                         prev <- hyp
                        }

> goodFunction(mydata, myformula)
> 

It works, because 'myweight' is found in the global environment, which
is where the formula is created.


Now, final example, try this:


library(rpart)
goodFunction <- function() {
                         myformula <- formula(Kyphosis ~ Age + Number +
                                              Start)
                         mydata <- kyphosis
                         myweight <- abs(rnorm(nrow(mydata)))

                         hyp <- rpart(myformula, data=mydata,
                                      weights=myweight, method="class")
                         prev <- hyp
                        }

> goodFunction()
> 

It works because the formula is created within the environment of the
function and hence, 'myweight', which is created there as well, is
found.

There was a (non) bug filed on a related matter dealing with the
evaluation of 'subset':

http://bugs.r-project.org/cgi-bin/R/feature%26FAQ?id=3671

and you might find this document on Non-Standard Evaluation helpful:

http://developer.r-project.org/nonstandard-eval.pdf

HTH,

Marc


From ted.harding at nessie.mcc.ac.uk  Fri Jun 15 21:33:34 2007
From: ted.harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 15 Jun 2007 20:33:34 +0100 (BST)
Subject: [R] [OT] 'gv' and fractional points
In-Reply-To: <XFMail.070615172953.efh@nessie.mcc.ac.uk>
Message-ID: <XFMail.070615191851.Ted.Harding@manchester.ac.uk>

On 15-Jun-07 16:29:53, Ted Harding wrote:
> [...]
> However, as a follow-up, I've since found that one can (somewhat
> tediously) do what I was asking with the GIMP.

As well as the awkwardness of doing it the GIMP way, I've
discovered another disadvantage.

I'd previously tried it on a rather small image (175x70 points,
= 2.43x0.97 inches).

I then tried it on a full A4 page. Even at a GIMP "Scale"
factor of 300, this leads to a 50MB temporary file being
created. At 1000, this would rise to some 550MB, as I found
out after this attempt filled up the limited spare space
I have on the disk drive in question ...

No doubt "Scale"=300 (as opposed to the default of 100) may be
ample for most purposes, but the overhead is still unpleasant!

Hence I'm once again hankering after something which will display
a PS file as efficiently as 'gv', but will report the cursor
position in fractions of a point!

Best wishes to all,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 15-Jun-07                                       Time: 19:18:48
------------------------------ XFMail ------------------------------

--------------------------------------------------------------------
E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 15-Jun-07                                       Time: 20:33:19
------------------------------ XFMail ------------------------------


From ted.harding at nessie.mcc.ac.uk  Fri Jun 15 21:33:34 2007
From: ted.harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 15 Jun 2007 20:33:34 +0100 (BST)
Subject: [R] [OT] 'gv' and fractional points
In-Reply-To: <f8e6ff050706150856v7291e30fp94a13848ce0fc01a@mail.gmail.com>
Message-ID: <XFMail.070615172953.efh@nessie.mcc.ac.uk>

On 15-Jun-07 15:56:58, hadley wickham wrote:
> This doesn't answer your original question, and isn't much help unless
> you're on a mac, but there's a nice looking program that makes this
> kind of graph scraping really easy:
> http://www.arizona-software.ch/applications/graphclick/en/
> 
> Hadley

Thanks, Hadley! But (as you implicitly surmise) I don't use a Mac
(just non-psychedelic Linux).

However, as a follow-up, I've since found that one can (somewhat
tediously) do what I was asking with the GIMP.

If you start the GIMP on a PostScript file, you initially get a
"Load PostScript" window which asks you to choose (amongst other
things" the "resolution", initially "100". If you wind this up
to say "1000", then you get 10 times the positional precision
in the numbers shown as below.

When the image is displayed, there is again a little window
which gives you the GIMP coordinates of the mouse position.
With increased "Resolution", the numerical values vary
correspondingly more rapidly with position.

The tedious aspect (compared with 'gv') is that to get better
visual resolution you need to zoom the image. This enlarges the
whole image, with the result that you have to pan around to
locate different parts, and you can get lost in a graph with
lots of widely-spread points.

With 'gv', on the other hand, you can select any small part
to view in zoom in a sub-window, which is much easier to cope
with; and you also get a "rubber-band" rectangle which enables
you to readily align points here with points there -- e.g. if
you want to read off a curve the y-value corresponding to say
x=5.0.

However, this is at least a partial answer to my own question!

Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <efh at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 15-Jun-07                                       Time: 17:29:49
------------------------------ XFMail ------------------------------

--------------------------------------------------------------------
E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 15-Jun-07                                       Time: 20:32:59
------------------------------ XFMail ------------------------------


From tsoi.teen at gmail.com  Fri Jun 15 21:36:16 2007
From: tsoi.teen at gmail.com (Alex Tsoi)
Date: Fri, 15 Jun 2007 15:36:16 -0400
Subject: [R] how to plot two graphics in one window
In-Reply-To: <11145186.post@talk.nabble.com>
References: <11145186.post@talk.nabble.com>
Message-ID: <5167e2400706151236m55291a80t8ed69c8f14a85af2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070615/9d3eba75/attachment.pl 

From jrkrideau at yahoo.ca  Fri Jun 15 21:31:39 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Fri, 15 Jun 2007 15:31:39 -0400 (EDT)
Subject: [R] how to plot two graphics in one window
In-Reply-To: <11145186.post@talk.nabble.com>
Message-ID: <498140.59803.qm@web32814.mail.mud.yahoo.com>

?points

x <- 1:10
plot(exp(x),col="red", type ="o")
points(sin(x), col="blue")


--- Miguel Caro <mcaro72 at gmail.com> wrote:

> 
> Hello ,
> Maybe this question you answered before, but i
> couldnt find something
> indicated in the mailing list.
> 
> I wish to plot two graphics  in one window, for
> example y=sinx and y=exp(x)
> in the same windows, (the same interval for x).
> 
> Thanks .
> 
> Miguel.
> -- 
> View this message in context:
>
http://www.nabble.com/how-to-plot-two-graphics-in-one-window-tf3929594.html#a11145186
> Sent from the R help mailing list archive at
> Nabble.com.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From mcaro72 at gmail.com  Fri Jun 15 21:40:55 2007
From: mcaro72 at gmail.com (Miguel Caro)
Date: Fri, 15 Jun 2007 12:40:55 -0700 (PDT)
Subject: [R] how to plot two graphics in one window
In-Reply-To: <11145186.post@talk.nabble.com>
References: <11145186.post@talk.nabble.com>
Message-ID: <11146479.post@talk.nabble.com>


Hi,
I answer myself

plot(x,y,type="l")
par(new=TRUE)
plot(x,yy,type="l")

Thanks all!



Miguel Caro wrote:
> 
> Hello ,
> Maybe this question you answered before, but i couldnt find something
> indicated in the mailing list.
> 
> I wish to plot two graphics  in one window, for example y=sinx and
> y=exp(x) in the same windows, (the same interval for x).
> 
> Thanks .
> 
> Miguel.
> 

-- 
View this message in context: http://www.nabble.com/how-to-plot-two-graphics-in-one-window-tf3929594.html#a11146479
Sent from the R help mailing list archive at Nabble.com.


From mark_difford at yahoo.co.uk  Fri Jun 15 21:41:08 2007
From: mark_difford at yahoo.co.uk (Mark Difford)
Date: Fri, 15 Jun 2007 12:41:08 -0700 (PDT)
Subject: [R] text display using expression or not
In-Reply-To: <efb536d50706151035u4c03e6a7h83f09abe3aeada89@mail.gmail.com>
References: <efb536d50706151035u4c03e6a7h83f09abe3aeada89@mail.gmail.com>
Message-ID: <11146488.post@talk.nabble.com>


Hi Sarah,

You will kick yourself (perhaps?).  Try:

?par   ## sub: font.main (& font, just above)

## Example
par(mfrow=c(2,1))
plot(1:10, 1:10, main="Figure A", font.main=1)
plot(1:10, 1:10, main=expression("Figure B"))

Regards,
Mark.


Sarah Goslee wrote:
> 
> Hello,
> 
> I imagine that I'm missing something straightforward, but a run thru
> the help files didn't turn up an answer.
> 
> I noticed while formatting some figures for publication that text
> enclosed in expression() and used for a title displays differently
> than a string, regardless of the par options. On both postscript()
> and x11() devices, the regular text is heavier than the expression text.
> 
> Here's an example. The "real thing" used expression() to
> produce superscripts, but I boiled this down to the simplest possible
> case.
> 
> par(mfrow=c(2,1))
> plot(1:10, 1:10, main="Figure A")
> plot(1:10, 1:10, main=expression("Figure B"))
> 
> Is there some straightforward way to make them match, other
> than putting expression() around all strings?
> 
> 
> I'm currently using R 2.5.0 on Fedora core 5.
> 
> Thanks,
> Sarah
> 
> -- 
> Sarah Goslee
> http://www.functionaldiversity.org
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/text-display-using-expression-or-not-tf3929372.html#a11146488
Sent from the R help mailing list archive at Nabble.com.


From p.dalgaard at biostat.ku.dk  Fri Jun 15 21:41:16 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 15 Jun 2007 21:41:16 +0200
Subject: [R] removing values from a vector,
 where both the value and its name are the same?
In-Reply-To: <4672E7A0.3040704@pburns.seanet.com>
References: <765851.84492.qm@web63904.mail.re1.yahoo.com>	<644e1f320706151147q3ec347ady8641012cb056340d@mail.gmail.com>
	<4672E7A0.3040704@pburns.seanet.com>
Message-ID: <4672EB5C.6090005@biostat.ku.dk>

Patrick Burns wrote:
> In case it matters, the given solution has a problem if the
> data look like:
>
> x <- c(sum=77, test=99, sum=99)
>
> By the description all three elements should be kept, but
> the duplicated solution throws out the last element.  A more
> complicated solution is:
>
> unique(data.frame(x, names(x)))
>
> (and then put the vector back together again).
>
>   
Yes, I was about to say the same.

x[!duplicated(cbind(x,names(x)))]

looks like it might cut the mustard.


From marc_schwartz at comcast.net  Fri Jun 15 21:43:53 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Fri, 15 Jun 2007 14:43:53 -0500
Subject: [R] removing values from a vector,
	where both the value and	its name are the same?
In-Reply-To: <4672E7A0.3040704@pburns.seanet.com>
References: <765851.84492.qm@web63904.mail.re1.yahoo.com>
	<644e1f320706151147q3ec347ady8641012cb056340d@mail.gmail.com>
	<4672E7A0.3040704@pburns.seanet.com>
Message-ID: <1181936633.3697.9.camel@Bellerophon.localdomain>

Good catch Patrick.  I am guilty of the same error.

Regards,

Marc

On Fri, 2007-06-15 at 20:25 +0100, Patrick Burns wrote:
> In case it matters, the given solution has a problem if the
> data look like:
> 
> x <- c(sum=77, test=99, sum=99)
> 
> By the description all three elements should be kept, but
> the duplicated solution throws out the last element.  A more
> complicated solution is:
> 
> unique(data.frame(x, names(x)))
> 
> (and then put the vector back together again).
> 
> Patrick Burns
> patrick at burns-stat.com
> +44 (0)20 8525 0696
> http://www.burns-stat.com
> (home of S Poetry and "A Guide for the Unwilling S User")
> 
> jim holtman wrote:
> 
> >try this:
> >
> >  
> >
> >>x[!(duplicated(names(x))&duplicated(x))]
> >>    
> >>
> >  sum   min   max count count  test
> >   77     4     9     5     8    77
> >
> >
> >
> >On 6/15/07, new ruser <newruser at yahoo.com> wrote:
> >  
> >
> >>I have an array such as:
> >>
> >>x=c(sum=77, min=4,max=9, count=5, min=4,max=9, count=8 ,  test=77)
> >>
> >>I wish to remove values where both the name and the value are identical.
> >>
> >>eg. i wish to end up with:
> >>x2=c(sum=77, min=4,max=9, count=5, count=8, test=77)
> >>
> >>What is the "best" way to do this?
> >>
> >>
> >>---------------------------------
> >>Park yourself in front of a world of choices in alternative vehicles.
> >>
> >>       [[alternative HTML version deleted]]
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide
> >>http://www.R-project.org/posting-guide.html
> >>and provide commented, minimal, self-contained, reproducible code.
> >>
> >>    
> >>
> >
> >
> >
> >  
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at yahoo.ca  Fri Jun 15 21:43:55 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Fri, 15 Jun 2007 15:43:55 -0400 (EDT)
Subject: [R] R vs. Splus in Pharma/Devices Industry
In-Reply-To: <40e66e0b0706151230o1e3a8f49va55f28f4e9cb689d@mail.gmail.com>
Message-ID: <417847.83261.qm@web32802.mail.mud.yahoo.com>


--- Douglas Bates <bates at stat.wisc.edu> wrote:

> On 6/15/07, Nicholas Lewin-Koh <nikko at hailmail.net>
> wrote:
> > Hi,
> > I just saw this thread. This issue, and the larger
> scale issue of open
> > source in industry
> > is being addressed. One has to realize that the
> behemoth that is the
> > clinical aperatus
> > of the pharma industry is very conservative and
> very slow to change. In
> > many cases
> > switching to R would meean changing a great many
> processes all based on
> > legacy code. One
> > of the big issues is that the industry demands
> consistency not
> > necessarily correctness.
> >
> > All that said there are a great many areas where R
> could be used that
> > would not impact
> > regulatory submission, data security etc. Many in
> pharma are quietly
> > working on this,
> > but steps are small and incremental. Development
> takes time in industry
> > because of the amount of
> > documentation necessary. All this impacts the
> "free" nature of R and
> > cost and risk (From the industries
> > perspective) need to be justified.
> 
> > Probably when the statistical community is using Z
> big pharma will be
> > ready to use
> > R. %P
> 
> I think you mean A, not Z.  First there was S, then
> there was R.

We're regressing !!!!


From ggrothendieck at gmail.com  Fri Jun 15 22:08:05 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 15 Jun 2007 16:08:05 -0400
Subject: [R] [OT] 'gv' and fractional points
In-Reply-To: <XFMail.070615161333.ted.harding@nessie.mcc.ac.uk>
References: <XFMail.070615161333.ted.harding@nessie.mcc.ac.uk>
Message-ID: <971536df0706151308off5ad0dhc518b96758e5195c@mail.gmail.com>

Check out the engauge digitizer:

http://digitizer.sourceforge.net/

On 6/15/07, Ted Harding <ted.harding at nessie.mcc.ac.uk> wrote:
> Hi Folks,
>
> This is off-topic R-wise, but it may be close to
> the heart of many R-users, so I think it may be
> the best place to ask!
>
> Users of 'gv' (the "front end" to ghostscript) will
> be aware of the little window which gives you the
> x-y coordinates (in points = 1/72 inch) of the position
> of the "cross-hair" mouse cursor. These coordinates
> are those of the corresponding position on the printed
> page, relative to some origin.
>
> I have often used this to extract numerical values
> for data from graphs in Postscript files (also PDF
> files, after you have converted them to PS). Then
> (veering back on topic ... ) you can submit the
> numerical data to R and try your own analyses on
> these data, and compare with what the article does.
>
> However, this little window only gives the numbers
> in whole points. Say a smallish graphic may print
> out 3 inches wide or high. Then you get precision
> of 1/216 per 3 inches or 0.4% of full scale. This
> can be adequate on many occasions, but can be on
> the coarse side on other occasions.
>
> Even for a 6-inch-wide/high graph, you only get down
> to 0.2% of full scale.
>
> If it were possible to induce 'gv' to display these
> coordinates in tenths of a point, then much greater
> precision (as adequate as one can expect to hope for
> when, in effect, "measuring off the graph") could be
> obtained.
>
> Does anyone know:
> a) Whether it is possible to persuade 'gv' to give
>   this display in fractional points (my own search
>   of the documentation has not revealed anything);
> b) Of any alternative to 'gv' as PS viewer which would
>   provide this capability?
>
> With thanks, and best wishes to all,
> Ted.
>
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 15-Jun-07                                       Time: 16:13:21
> ------------------------------ XFMail ------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From deepayan.sarkar at gmail.com  Fri Jun 15 22:08:31 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Fri, 15 Jun 2007 13:08:31 -0700
Subject: [R] model.frame: how does one use it?
In-Reply-To: <f8e6ff050706151229j917e8e0q163f3a34b26d3b9c@mail.gmail.com>
References: <18034.46215.223478.311352@basebud.nulle.part>
	<eb555e660706151223p1d1f45e9j2dc835b3bec9e242@mail.gmail.com>
	<f8e6ff050706151229j917e8e0q163f3a34b26d3b9c@mail.gmail.com>
Message-ID: <eb555e660706151308g6c3012fbwb419f21508f76f0@mail.gmail.com>

On 6/15/07, hadley wickham <h.wickham at gmail.com> wrote:
> On 6/15/07, Deepayan Sarkar <deepayan.sarkar at gmail.com> wrote:

[...]

> > By 'name', I mean a symbol, such as 'Age' or 'myweight'.  So
> > basically, everything is as you would expect if the name is visible in
> > data, but if not, the search starts in the environment of the formula,
> > not the environment where the function call is being made (which is
> > the standard evaulation behaviour).  This is a feature, not a bug
> > (things would be a lot more confusing if it were the other way round).
>
> Could you give an example?  It's always seemed confusing to me and I
> don't see why looking in the environment of the formula helps.

Good question. I remember being convinced that it was a good idea, but
no longer remember why. This is the best I can come up with right now:


## stupid function that fits a model on a random subsample

lmsub <- function(formula, data, p = 0.7)
{
    n <- nrow(data)
    newdata <- data[sample(round(n * p)), ]
    lm(formula, newdata)
}

mydata <- data.frame(x = 1:100, y = rnorm(100))

n <- 2

lmsub(y ~ poly(x, n), data = mydata)

I don't think the use of the name 'n' is unusual in either case, and
we definitely wouldn't want the one inside 'lmsub' to be used for the
formula.

-Deepayan


From edd at debian.org  Fri Jun 15 22:34:48 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 15 Jun 2007 15:34:48 -0500
Subject: [R] model.frame: how does one use it?
In-Reply-To: <1181936004.3697.6.camel@Bellerophon.localdomain>
References: <18034.46215.223478.311352@basebud.nulle.part>
	<1181936004.3697.6.camel@Bellerophon.localdomain>
Message-ID: <18034.63464.877565.242357@basebud.nulle.part>


Hi Mark,

Thanks for the reply.

On 15 June 2007 at 14:33, Marc Schwartz wrote:
| On Fri, 2007-06-15 at 10:47 -0500, Dirk Eddelbuettel wrote: 
| > Philipp Benner reported a Debian bug report against r-cran-rpart aka rpart.
| > In short, the issue has to do with how rpart evaluates a formula and
| > supporting arguments, in particular 'weights'.  
| > 
| > A simple contrived example is
| > 
| > -----------------------------------------------------------------------------
| > library(rpart)
| > 
| > ## using data from help(rpart), set up simple example
| > myformula <- formula(Kyphosis ~ Age + Number + Start)
| > mydata <- kyphosis
| > myweight <- abs(rnorm(nrow(mydata)))
| > 
| > goodFunction <- function(mydata, myformula, myweight) {
| >   hyp <- rpart(myformula, data=mydata, weights=myweight, method="class")
| >   prev <- hyp
| > }
| > goodFunction(mydata, myformula, myweight)
| > cat("Ok\n")
| > 
| > ## now remove myweight and try to compute it inside a function
| > rm(myweight)
| > 
| > badFunction <- function(mydata, myformula) {
| >   myweight <- abs(rnorm(nrow(mydata)))
| >   mf <- model.frame(myformula, mydata, myweight)
| >   print(head(df))
| >   hyp <- rpart(myformula,
| >                data=mf,
| >                weights=myweight,
| >                method="class")
| >   prev <- hyp
| > }
| > badFunction(mydata, myformula)
| > cat("Done\n")
| > -----------------------------------------------------------------------------
| > 
| > Here goodFunction works, but only because myweight (with useless random
| > weights, but that is not the point here) is found from the calling
| > environment. 
| > 
| > badFunction fails after we remove myweight from there:
| > 
| > :~> cat /tmp/philipp.R | R --slave
| > Ok
| > Error in eval(expr, envir, enclos) : object "myweight" not found
| > Execution halted
| > :~>    
| > 
| > As I was able to replicate it, I reported this to the package maintainer.  It
| > turns out that seemingly all is well as this is supposed to work this way,
| > and I got a friendly pointer to study model.frame and its help page.  
| > 
| > Now I am stuck as I can't make sense of model.frame -- see badFunction
| > above. I would greatly appreciate any help in making rpart work with a local
| > argument weights so that I can tell Philipp that there is no bug.  :)
| > 
| > Regards, Dirk
| 
| 
| Dirk,
| 
| As you note, the issue is the non-standard evaluation of the arguments
| in model.frame()  The key section of the Details in ?model.frame is:
| 
| 
| All the variables in formula, subset and in ... are looked for first in
| data and then in the environment of formula (see the help for formula()
| for further details) and collected into a data frame. Then the subset
| expression is evaluated, and it is is used as a row index to the data
| frame. Then the na.action function is applied to the data frame (and may
| well add attributes). The levels of any factors in the data frame are
| adjusted according to the drop.unused.levels and xlev arguments.
| 
| 
| Note that even with your goodFunction(), if 'myweight' is created within
| the environment of the function and not in the global environment, it
| still fails:
| 
| library(rpart)
| myformula <- formula(Kyphosis ~ Age + Number + Start)
| mydata <- kyphosis
| 
| goodFunction <- function(mydata, myformula) {
|                          myweight <- abs(rnorm(nrow(mydata)))
|                          hyp <- rpart(myformula, data=mydata,
|                                       weights=myweight, method="class")
|                          prev <- hyp
|                         }
| 
| 
| > goodFunction(mydata, myformula)
| Error in eval(expr, envir, enclos) : object "myweight" not found
| 
| 
| However, now let's do this:
| 
| 
| library(rpart)
| myformula <- formula(Kyphosis ~ Age + Number + Start)
| mydata <- kyphosis
| myweight <- abs(rnorm(nrow(mydata)))
| 
| goodFunction <- function(mydata, myformula) {
|                          hyp <- rpart(myformula, data=mydata,
|                                       weights=myweight, method="class")
|                          prev <- hyp
|                         }
| 
| > goodFunction(mydata, myformula)
| > 
| 
| It works, because 'myweight' is found in the global environment, which
| is where the formula is created.

Well,yes, but doesn't this just recreate the working example I showed above?
It works 'because we get lucky' with the data in the outer global env.

| Now, final example, try this:
| 
| 
| library(rpart)
| goodFunction <- function() {
|                          myformula <- formula(Kyphosis ~ Age + Number +
|                                               Start)
|                          mydata <- kyphosis
|                          myweight <- abs(rnorm(nrow(mydata)))
| 
|                          hyp <- rpart(myformula, data=mydata,
|                                       weights=myweight, method="class")
|                          prev <- hyp
|                         }
| 
| > goodFunction()
| > 
| 
| It works because the formula is created within the environment of the
| function and hence, 'myweight', which is created there as well, is
| found.

That works because we force it to be local. BDR claims that my 'badFunction'
(derived from Philipp's original bug report) above can be made to work
provide you use model.frame.  I asked about model.frame -- and you were kind
enough do answer, but you dodged the question.

So let me try again:  How can rpart be called inside a function using a
local weight variable as I do above ?   Either it can, and the BDR is right
and there is no bug, or one cannot, and then mere mortals like myself must
consider rpart to be buggy as it does not support all its argument in at
least some conceivable calling situations. 

Is that a fair question?

Regards,  Dirk


| There was a (non) bug filed on a related matter dealing with the
| evaluation of 'subset':
| 
| http://bugs.r-project.org/cgi-bin/R/feature%26FAQ?id=3671
| 
| and you might find this document on Non-Standard Evaluation helpful:
| 
| http://developer.r-project.org/nonstandard-eval.pdf
| 
| HTH,
| 
| Marc
| 
| 

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From p.murrell at auckland.ac.nz  Fri Jun 15 22:41:36 2007
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Sat, 16 Jun 2007 08:41:36 +1200
Subject: [R] [OT] 'gv' and fractional points
In-Reply-To: <XFMail.070615191851.Ted.Harding@manchester.ac.uk>
References: <XFMail.070615191851.Ted.Harding@manchester.ac.uk>
Message-ID: <4672F980.7020505@stat.auckland.ac.nz>

Hi

If I understand correctly, this is something that the 'grImport' package
might be very useful for.  You can import the PostScript image into R,
which means that you can draw the image, but you also have the locations
of everything that is drawn as numeric values so you should be able
(probably after a bit of transformation) to extract the values to very
good accuracy.  If you can provide me with an example file, I'd be happy
to play around and see if I could get this to work.

Paul


(Ted Harding) wrote:
> On 15-Jun-07 16:29:53, Ted Harding wrote:
>> [...]
>> However, as a follow-up, I've since found that one can (somewhat
>> tediously) do what I was asking with the GIMP.
> 
> As well as the awkwardness of doing it the GIMP way, I've
> discovered another disadvantage.
> 
> I'd previously tried it on a rather small image (175x70 points,
> = 2.43x0.97 inches).
> 
> I then tried it on a full A4 page. Even at a GIMP "Scale"
> factor of 300, this leads to a 50MB temporary file being
> created. At 1000, this would rise to some 550MB, as I found
> out after this attempt filled up the limited spare space
> I have on the disk drive in question ...
> 
> No doubt "Scale"=300 (as opposed to the default of 100) may be
> ample for most purposes, but the overhead is still unpleasant!
> 
> Hence I'm once again hankering after something which will display
> a PS file as efficiently as 'gv', but will report the cursor
> position in fractions of a point!
> 
> Best wishes to all,
> Ted.
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 15-Jun-07                                       Time: 19:18:48
> ------------------------------ XFMail ------------------------------
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 15-Jun-07                                       Time: 20:33:19
> ------------------------------ XFMail ------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From liangl at ucla.edu  Fri Jun 15 22:50:31 2007
From: liangl at ucla.edu (Li-Jung Liang)
Date: Fri, 15 Jun 2007 13:50:31 -0700
Subject: [R] Upgraded FC4 to FC5 - unable to start device X11 in R
Message-ID: <4672FB97.4040005@ucla.edu>

Hi,

I upgraded my system from FC4 to FC5.  So now I have R version 2.5.0 
(2007-04-23).
But I ran into a problem with starting device X11 (message below).

 > X11()
can't find X11 font
Error in X11(display, width, height, pointsize, if (is.null(gamma)) 1 
else gamma,  :
        unable to start device X11

Any idea?

Thanks,
L.

-- 
Li-Jung Liang, Ph.D.
Department of Biostatistics
UCLA School of Public Health
Los Angeles, CA 90095-1772


From pbenner at uos.de  Sat Jun 16 00:59:22 2007
From: pbenner at uos.de (Philipp Benner)
Date: Sat, 16 Jun 2007 00:59:22 +0200
Subject: [R] model.frame: how does one use it?
In-Reply-To: <eb555e660706151223p1d1f45e9j2dc835b3bec9e242@mail.gmail.com>
References: <18034.46215.223478.311352@basebud.nulle.part>
	<eb555e660706151223p1d1f45e9j2dc835b3bec9e242@mail.gmail.com>
Message-ID: <20070615225922.GA19996@philipp-benner.de>


Thanks for your explanation!

> With this in mind, either of the following might do what you want:
> 
> badFunction <- function(mydata, myformula) {
>    mydata$myweight <- abs(rnorm(nrow(mydata)))
>    hyp <-
>        rpart(myformula,
>              data=mydata,
>              weights=myweight,
>              method="class")
>    prev <- hyp
> }
> 
> 
> badFunction <- function(mydata, myformula) {
>    myweight <- abs(rnorm(nrow(mydata)))
>    environment(myformula) <- environment()
>    hyp <-
>        rpart(myformula,
>              data=mydata,
>              weights=myweight,
>              method="class")
>    prev <- hyp
> }

OK, this is what I have now:

adaboostBad <- function(formula, data) {
  ## local definition of the weight vector (won't work because pima.formula is not defined within this function)
  w <- abs(rnorm(nrow(data)))
  rpart(formula, data=data, weights=w)
}

adaboostGood <- function(formula, data) {
  ## create weight vector in the data object
  data$w <- abs(rnorm(nrow(data)))
  rpart(formula, data=data, weights=w)
}

adaboostBest <- function(formula, data) {
  ## associate the current environment (this function's one) with the object `formula'
  environment(formula) <- environment()
  w <- abs(rnorm(nrow(data)))
  rpart(formula, data=data, weights=w)
}

As far as I understand this non-standard evaluation stuff, adaboostGood() and adaboostBest()
are the only two possibilities to call rpart() with weight vectors. Now suppose that I don't
know what `data' contains and suppose further that it already contains a column called `w'.
adaboostGood() would overwrite that column with new data which is then used as weight vector
and as training data for rpart(). adaboostBest() would just use the wrong data as weight
vector as it finds data$w before the real weight vector. So, in both cases I have to check for
`names(data) == "w"` and stop if TRUE? Or is there a better way?

Regards

-- 
Philipp Benner


From marc_schwartz at comcast.net  Sat Jun 16 01:21:33 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Fri, 15 Jun 2007 18:21:33 -0500
Subject: [R] model.frame: how does one use it?
In-Reply-To: <18034.63464.877565.242357@basebud.nulle.part>
References: <18034.46215.223478.311352@basebud.nulle.part>
	<1181936004.3697.6.camel@Bellerophon.localdomain>
	<18034.63464.877565.242357@basebud.nulle.part>
Message-ID: <1181949693.3691.42.camel@Bellerophon.localdomain>

On Fri, 2007-06-15 at 15:34 -0500, Dirk Eddelbuettel wrote:
> Hi Mark,
> 
> Thanks for the reply.
> 
> On 15 June 2007 at 14:33, Marc Schwartz wrote:
> | On Fri, 2007-06-15 at 10:47 -0500, Dirk Eddelbuettel wrote: 
> | > Philipp Benner reported a Debian bug report against r-cran-rpart aka rpart.
> | > In short, the issue has to do with how rpart evaluates a formula and
> | > supporting arguments, in particular 'weights'.  
> | > 
> | > A simple contrived example is
> | > 
> | > -----------------------------------------------------------------------------
> | > library(rpart)
> | > 
> | > ## using data from help(rpart), set up simple example
> | > myformula <- formula(Kyphosis ~ Age + Number + Start)
> | > mydata <- kyphosis
> | > myweight <- abs(rnorm(nrow(mydata)))
> | > 
> | > goodFunction <- function(mydata, myformula, myweight) {
> | >   hyp <- rpart(myformula, data=mydata, weights=myweight, method="class")
> | >   prev <- hyp
> | > }
> | > goodFunction(mydata, myformula, myweight)
> | > cat("Ok\n")
> | > 

<snip>

> | 
> | However, now let's do this:
> | 
> | 
> | library(rpart)
> | myformula <- formula(Kyphosis ~ Age + Number + Start)
> | mydata <- kyphosis
> | myweight <- abs(rnorm(nrow(mydata)))
> | 
> | goodFunction <- function(mydata, myformula) {
> |                          hyp <- rpart(myformula, data=mydata,
> |                                       weights=myweight, method="class")
> |                          prev <- hyp
> |                         }
> | 
> | > goodFunction(mydata, myformula)
> | > 
> | 
> | It works, because 'myweight' is found in the global environment, which
> | is where the formula is created.
> 
> Well,yes, but doesn't this just recreate the working example I showed above?
> It works 'because we get lucky' with the data in the outer global env.

Technically, it is not the same, as I was trying to emphasize that there
was no need to pass 'myweight' as an argument to the function to
facilitate successful location/evaluation within the function.

We don't get lucky here. The behavior is by design and consistent with
the documentation, which is that 'myweight' in the call to rpart() is
evaluated within the environment of the formula in this case. The
formula is created in the global environment, so 'myweight' is found
there. Hence, no need to pass it as an argument.

A review of the code for rpart() will reveal code similar to that which
is used in most R modeling functions, relative to the evaluation of the
formula, associated args and the creation of the model frame.

One exception to the above, is that in other modeling functions, one
could forgo passing the formula and just pass the entire data frame,
where the presumption is that the first column is the response variable
and the remaining columns would be the independent terms. I don't see
that supported in rpart().

> 
> | Now, final example, try this:
> | 
> | 
> | library(rpart)
> | goodFunction <- function() {
> |                          myformula <- formula(Kyphosis ~ Age + Number +
> |                                               Start)
> |                          mydata <- kyphosis
> |                          myweight <- abs(rnorm(nrow(mydata)))
> | 
> |                          hyp <- rpart(myformula, data=mydata,
> |                                       weights=myweight, method="class")
> |                          prev <- hyp
> |                         }
> | 
> | > goodFunction()
> | > 
> | 
> | It works because the formula is created within the environment of the
> | function and hence, 'myweight', which is created there as well, is
> | found.
> 
> That works because we force it to be local. BDR claims that my 'badFunction'
> (derived from Philipp's original bug report) above can be made to work
> provide you use model.frame.  I asked about model.frame -- and you were kind
> enough do answer, but you dodged the question.
> 
> So let me try again:  How can rpart be called inside a function using a
> local weight variable as I do above ?   Either it can, and the BDR is right
> and there is no bug, or one cannot, and then mere mortals like myself must
> consider rpart to be buggy as it does not support all its argument in at
> least some conceivable calling situations. 
> 
> Is that a fair question?
> 
> Regards,  Dirk

Yep, entirely fair. 

Without knowing what specific approach Prof. Ripley had in mind, I am
envisioning a couple of possibilities, but here is one:

library(rpart)

myformula <- formula(Kyphosis ~ Age + Number + Start)
mydata <- kyphosis

badFunction <- function(mydata, myformula) {
  mydata$myweight <- abs(rnorm(nrow(mydata)))
  rpart(myformula, data = mydata, weights = myweight, method = "class")
}

badFunction(mydata, myformula)


Basically, there are 3 places in which 'myweights' could be found:

1. Formula environment

2. Data frame environment

3. Global environment


In this case, we add the weights as a new column within the function to
the 'mydata' data frame, so that it will be found in the call to
rpart(), based upon location number 2 above.

Does that help?

Regards,

Marc


From scottflemming at yahoo.com  Sat Jun 16 01:22:58 2007
From: scottflemming at yahoo.com (scott flemming)
Date: Fri, 15 Jun 2007 16:22:58 -0700 (PDT)
Subject: [R] rect() does not work
In-Reply-To: <780602.85358.qm@web32811.mail.mud.yahoo.com>
Message-ID: <895419.85643.qm@web57511.mail.re1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070615/c3de2594/attachment.pl 

From deepayan.sarkar at gmail.com  Sat Jun 16 01:27:10 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Fri, 15 Jun 2007 16:27:10 -0700
Subject: [R] model.frame: how does one use it?
In-Reply-To: <20070615225922.GA19996@philipp-benner.de>
References: <18034.46215.223478.311352@basebud.nulle.part>
	<eb555e660706151223p1d1f45e9j2dc835b3bec9e242@mail.gmail.com>
	<20070615225922.GA19996@philipp-benner.de>
Message-ID: <eb555e660706151627l22740b1fuc3f055693733dc20@mail.gmail.com>

On 6/15/07, Philipp Benner <pbenner at uos.de> wrote:
>
> Thanks for your explanation!
>
> > With this in mind, either of the following might do what you want:
> >
> > badFunction <- function(mydata, myformula) {
> >    mydata$myweight <- abs(rnorm(nrow(mydata)))
> >    hyp <-
> >        rpart(myformula,
> >              data=mydata,
> >              weights=myweight,
> >              method="class")
> >    prev <- hyp
> > }
> >
> >
> > badFunction <- function(mydata, myformula) {
> >    myweight <- abs(rnorm(nrow(mydata)))
> >    environment(myformula) <- environment()
> >    hyp <-
> >        rpart(myformula,
> >              data=mydata,
> >              weights=myweight,
> >              method="class")
> >    prev <- hyp
> > }
>
> OK, this is what I have now:
>
> adaboostBad <- function(formula, data) {
>   ## local definition of the weight vector (won't work because pima.formula is not defined within this function)
>   w <- abs(rnorm(nrow(data)))
>   rpart(formula, data=data, weights=w)
> }
>
> adaboostGood <- function(formula, data) {
>   ## create weight vector in the data object
>   data$w <- abs(rnorm(nrow(data)))
>   rpart(formula, data=data, weights=w)
> }
>
> adaboostBest <- function(formula, data) {
>   ## associate the current environment (this function's one) with the object `formula'
>   environment(formula) <- environment()
>   w <- abs(rnorm(nrow(data)))
>   rpart(formula, data=data, weights=w)
> }
>


> As far as I understand this non-standard evaluation stuff,
> adaboostGood() and adaboostBest() are the only two possibilities to
> call rpart() with weight vectors. Now suppose that I don't know what
> `data' contains and suppose further that it already contains a
> column called `w'.  adaboostGood() would overwrite that column with
> new data which is then used as weight vector and as training data
> for rpart(). adaboostBest() would just use the wrong data as weight
> vector as it finds data$w before the real weight vector. So, in both
> cases I have to check for `names(data) == "w"` and stop if TRUE? Or
> is there a better way?

Well, that depends on what you want to happen when there is a column
called 'w' in data.  I don't see a situation where it makes sense to
use data$w as weights ('w' is just a name you happen to choose inside
adaboostBest), so I would just go with adaboostGood.

In case you are worried about overwriting the original data, that may
not be happening in the sense you are thinking.  When you say

data$w <- abs(rnorm(nrow(data)))

inside adaboostGood, that modifies a local copy of the data argument,
not the original (R argument semantics are call by value, not call by
reference).  You are losing data$w in the local copy in your function,
but why would you care if you are not using it anyway.

Of course, if your formula contains a reference to 'w' then you will
get wrong results, so checking for a unique name is always safer.
In addition, use an obfuscated name like '.__myWeights' instead
of 'w', and the check will be almost always irrelevant.

-Deepayan


From ted.harding at nessie.mcc.ac.uk  Sat Jun 16 01:33:43 2007
From: ted.harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sat, 16 Jun 2007 00:33:43 +0100 (BST)
Subject: [R] R vs. Splus in Pharma/Devices Industry
In-Reply-To: <40e66e0b0706151230o1e3a8f49va55f28f4e9cb689d@mail.gmail.com>
Message-ID: <XFMail.070616003343.ted.harding@nessie.mcc.ac.uk>

On 15-Jun-07 19:30:45, Douglas Bates wrote:
> On 6/15/07, Nicholas Lewin-Koh <nikko at hailmail.net> wrote:
>> Hi,
>> 
>> Probably when the statistical community is using Z big pharma will be
>> ready to use
>> R. %P
> 
> I think you mean A, not Z.  First there was S, then there was R.

And, furthermore, A is further from R than Z is, which seems fitting.
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 15-Jun-07                                       Time: 23:57:13
------------------------------ XFMail ------------------------------


From ted.harding at nessie.mcc.ac.uk  Sat Jun 16 01:33:43 2007
From: ted.harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sat, 16 Jun 2007 00:33:43 +0100 (BST)
Subject: [R] [OT] 'gv' and fractional points
In-Reply-To: <4672F980.7020505@stat.auckland.ac.nz>
Message-ID: <XFMail.070616003343.ted.harding@nessie.mcc.ac.uk>

On 15-Jun-07 20:41:36, Paul Murrell wrote:
> Hi
> 
> If I understand correctly, this is something that the 'grImport'
> package might be very useful for. You can import the PostScript
> image into R, which means that you can draw the image, but you
> also have the locations of everything that is drawn as numeric
> values so you should be able (probably after a bit of transformation)
> to extract the values to very good accuracy.  If you can provide
> me with an example file, I'd be happy to play around and see if
> I could get this to work.
> 
> Paul

As an example of this, try Figure 2 on page 3 of

INphoRM 4: Presenting performance indicators: alternative approaches

  http://www.erpho.org.uk/download.aspx?urlid=7518&urlt=1

This comes back as an 8-page PDF file

  "INphoRM 4 final amended.pdf"


I used Acrobat Reader to print Page 3 to a PS file, which I will
send you separately, Paul.

(Note that this one has no scale in the X-axis, so there's no
knowing what the absolute numbers are; but the relative positions
in "points" across the page were of interest anyway).

In fact, in this case I was able to extract the axact coordinates
in "points" by grepping through the PS file (having sussed out
the procedural definitions, then testing for which were points on
the graph and which were "furniture"), but that is really tedious!

So I'd be very interested to see how you get on.

If that's too heavy for illustrative use of your method, then
try Figure 1 on Page 2, in which case "your task" is to get
the Y-coordinates of the tops of the bars, of the upper and
lower ends of the rror-vars, and the Y-levels of the two
confidence limits.

Since I know the numbers as embedded in the PS file, I can
check your accuracy!

Thanks, and best wishes,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 16-Jun-07                                       Time: 00:25:00
------------------------------ XFMail ------------------------------


From marc_schwartz at comcast.net  Sat Jun 16 01:38:27 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Fri, 15 Jun 2007 18:38:27 -0500
Subject: [R] rect() does not work
In-Reply-To: <895419.85643.qm@web57511.mail.re1.yahoo.com>
References: <895419.85643.qm@web57511.mail.re1.yahoo.com>
Message-ID: <1181950707.3691.52.camel@Bellerophon.localdomain>

On Fri, 2007-06-15 at 16:22 -0700, scott flemming wrote:
> I have typed the following commands:
> 
> >x <- c(1:10)
> >y <- x
> >plot(x,y)
> >rect(2,2,4,4)
> 
> I am expecting a rectangular box, however, nothing occurs.

What version of R?  What OS?

No problems here using R version 2.5.0 Patched (2007-06-05 r41831) on
F7.

You might want to check and see what par("lty") and par("lwd") return,
in case they have been set to values resulting in lines that you would
not be able to see.

BTW, the c() is not required in creating 'x':

> x <- 1:10
> x
 [1]  1  2  3  4  5  6  7  8  9 10


Marc Schwartz


From solberg at speakeasy.net  Sat Jun 16 01:39:59 2007
From: solberg at speakeasy.net (owenman)
Date: Fri, 15 Jun 2007 16:39:59 -0700 (PDT)
Subject: [R] Stacked barchart color
In-Reply-To: <f8e6ff050706121131s4b0aeb30y8de662ddd7323092@mail.gmail.com>
References: <LPEJLJACLINDNMBMFAFIKEBICIAA.dieter.menne@menne-biomed.de>
	<f8e6ff050706121131s4b0aeb30y8de662ddd7323092@mail.gmail.com>
Message-ID: <11149419.post@talk.nabble.com>


Hi Hadley,
I tried your suggestion, using ggplot2, but I am still having a problem. The
final plot lacks the figure legend -- which it had before I added the 
scale_fill_identity()  bit.  Can  you see what I am doing wrong?  
(By the way, all I am trying to do is make the figure monochrome friendly. 
Is there an easy way to prepare ggplot graphics for a monochrom device?)
Thanks,Owen

> y$color = factor(y$Fnd)
> y$color = c("black","darkgray","lightgray","white") 
> y
      Fnd locus        Freq color
1  signeg     A 0.087248322     black
2     neg     A 0.711409396  darkgray
3     pos     A 0.201342282 lightgray
4  sigpos     A 0.000000000     white
5  signeg     C 0.320754717     black
6     neg     C 0.603773585  darkgray
7     pos     C 0.075471698 lightgray
8  sigpos     C 0.000000000     white
9  signeg     B 0.157534247     black
10    neg     B 0.732876712  darkgray
11    pos     B 0.109589041 lightgray
12 sigpos     B 0.000000000     white

> p = ggplot(y, aes(x=locus, y=Freq, fill=color)) +
> geom_bar(position="fill") + scale_fill_identity() 
> p



hadley wrote:
> 
> 
> Hi Dieter,
> 
> You can do this with ggplot2 (http://had.co.nz/ggplot2) as follows:
> 
> library(ggplot2)
> 
> barley1 <- subset(barley, site=="Grand Rapids" & variety %in%
> c("Velvet","Peatland"))
> barley1[] <- lapply(barley1, "[", drop=TRUE)
> 
> qplot(variety, yield, data=barley1, geom="bar", stat="identity",
> fill=factor(year))
> 
> barley1$fill <- c("red","green","blue","gray")
> qplot(variety, yield, data=barley1, geom="bar", stat="identity",
> fill=fill) + scale_fill_identity()
> 
> See http://had.co.nz/ggplot2/scale_identity.html and
> http://had.co.nz/ggplot2/position_stack.html for more details.
> 
> Hadley
> 
> 

-- 
View this message in context: http://www.nabble.com/Stacked-barchart-color-tf3909162.html#a11149419
Sent from the R help mailing list archive at Nabble.com.


From ted.harding at nessie.mcc.ac.uk  Sat Jun 16 01:43:42 2007
From: ted.harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sat, 16 Jun 2007 00:43:42 +0100 (BST)
Subject: [R] R vs. Splus in Pharma/Devices Industry
In-Reply-To: <417847.83261.qm@web32802.mail.mud.yahoo.com>
Message-ID: <XFMail.070616004342.ted.harding@nessie.mcc.ac.uk>

On 15-Jun-07 19:43:55, John Kane wrote:
> --- Douglas Bates <bates at stat.wisc.edu> wrote:
>> On 6/15/07, Nicholas Lewin-Koh <nikko at hailmail.net>
>> wrote:
>> > [...]
>> I think you mean A, not Z.  First there was S, then
>> there was R.
> 
> We're regressing !!!!

But not to mediocrity! [1]
Ted.

[1] Practical Regression and Anova using R
    Julian J. Faraway (July 2002), page 15.

http://cran.r-project.org/doc/contrib/Faraway-PRA.pdf

--------------------------------------------------------------------
E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 16-Jun-07                                       Time: 00:43:39
------------------------------ XFMail ------------------------------


From marc_schwartz at comcast.net  Sat Jun 16 02:03:37 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Fri, 15 Jun 2007 19:03:37 -0500
Subject: [R] Upgraded FC4 to FC5 - unable to start device X11 in R
In-Reply-To: <4672FB97.4040005@ucla.edu>
References: <4672FB97.4040005@ucla.edu>
Message-ID: <1181952217.3691.63.camel@Bellerophon.localdomain>

On Fri, 2007-06-15 at 13:50 -0700, Li-Jung Liang wrote:
> Hi,
> 
> I upgraded my system from FC4 to FC5.  So now I have R version 2.5.0 
> (2007-04-23).
> But I ran into a problem with starting device X11 (message below).
> 
>  > X11()
> can't find X11 font
> Error in X11(display, width, height, pointsize, if (is.null(gamma)) 1 
> else gamma,  :
>         unable to start device X11
> 
> Any idea?
> 
> Thanks,
> L.

Sounds like either you did not install some font related RPMS during
your 'upgrade' or your xorg.conf file has perhaps become corrupted
relative to defining font paths.

Check as 'root':

 # yum list xorg-x11-fonts*

and see what it returns.

How did you install R?  Using the RPMS from CRAN or from Fedora Extras?

Also, note that FC5 will reach EOL (End of Life) on June 29, which means
that you will receive no further updates (security, bug fixes, etc)
after that date.  You should really consider upgrading to FC6. 

F7 just came out and I am running it, but I would recommend that typical
users wait a while before doing so to give it time to stabilize.

HTH,

Marc Schwartz


From ted.harding at nessie.mcc.ac.uk  Sat Jun 16 02:14:00 2007
From: ted.harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sat, 16 Jun 2007 01:14:00 +0100 (BST)
Subject: [R] [OT] 'gv' and fractional points
In-Reply-To: <971536df0706151308off5ad0dhc518b96758e5195c@mail.gmail.com>
Message-ID: <XFMail.070616011400.ted.harding@nessie.mcc.ac.uk>

On 15-Jun-07 20:08:05, Gabor Grothendieck wrote:
> Check out the engauge digitizer:
> 
> http://digitizer.sourceforge.net/

Thanks, Gabor. This looks useful, as far as it goes.

However, it doesn't deal directly with PS, so one
would have to work to pixel resolution of screenshots
as displayed by say 'gv'.

In the case of an example such as the Fig 4 I mentioned
in a previous post, this would involve taking several
screenshots to "tile" over the entirety of the graph,
since the pixel accuracy or a screenshot of the entire
graph would be rather poor.

This would introduce the neccessity of keeing track of
points from screenshot to screenshot, and also each
screenshot would have its own coordinate system so these
would have to be reconciled before the final dataset
could be compiled.

But thanks -- this could well be worth a try in a different
kind of context (e.g. I have some screenshots of old maps
which I want to digitise ... ).

Best wishes,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 16-Jun-07                                       Time: 01:13:53
------------------------------ XFMail ------------------------------


From bcarvalh at jhsph.edu  Sat Jun 16 02:21:59 2007
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Fri, 15 Jun 2007 20:21:59 -0400
Subject: [R] plot via xyplot not being saved
Message-ID: <8DDE4EAE-47C0-4AD2-A0F3-6EC6BF3640CB@jhsph.edu>

Hi everyone,

it's been a while I've been trying to save a plot created via  
lattice:::xyplot

if I have a file tst.R with the following code:

y <- rnorm(100)
x <- rnorm(100)
z <- sample(letters[1:4], 100, rep=T)
library(lattice)
bitmap("tst.png")
xyplot(y~x|z)
dev.off()

and I source it, I get the tst.png file, which is a blank page.

If I copy and paste instead, I get the correct plot.

Any suggestion?

Thank you very much,

b

 > sessionInfo()
R version 2.5.0 (2007-04-23)
x86_64-unknown-linux-gnu

locale:
LC_CTYPE=en_US.iso885915;LC_NUMERIC=C;LC_TIME=en_US.iso885915;LC_COLLATE 
=en_US.iso885915;LC_MONETARY=en_US.iso885915;LC_MESSAGES=en_US.iso885915 
;LC_PAPER=en_US.iso885915;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASU 
REMENT=en_US.iso885915;LC_IDENTIFICATION=C

attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets"   
"methods"
[7] "base"

other attached packages:
lattice
"0.15-4"


From deepayan.sarkar at gmail.com  Sat Jun 16 02:53:27 2007
From: deepayan.sarkar at gmail.com (deepayan.sarkar at gmail.com)
Date: Fri, 15 Jun 2007 19:53:27 -0500
Subject: [R] plot via xyplot not being saved
In-Reply-To: <8DDE4EAE-47C0-4AD2-A0F3-6EC6BF3640CB@jhsph.edu>
References: <8DDE4EAE-47C0-4AD2-A0F3-6EC6BF3640CB@jhsph.edu>
Message-ID: <eb555e660706151753iad29e77wbe74b05b491772de@mail.gmail.com>

On 6/15/07, Benilton Carvalho <bcarvalh at jhsph.edu> wrote:
> Hi everyone,
>
> it's been a while I've been trying to save a plot created via
> lattice:::xyplot
>
> if I have a file tst.R with the following code:
>
> y <- rnorm(100)
> x <- rnorm(100)
> z <- sample(letters[1:4], 100, rep=T)
> library(lattice)
> bitmap("tst.png")
> xyplot(y~x|z)
> dev.off()
>
> and I source it, I get the tst.png file, which is a blank page.
>
> If I copy and paste instead, I get the correct plot.
>
> Any suggestion?

Use

source(..., echo = TRUE)

-Deepayan


From bcarvalh at jhsph.edu  Sat Jun 16 03:06:52 2007
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Fri, 15 Jun 2007 21:06:52 -0400
Subject: [R] plot via xyplot not being saved
In-Reply-To: <eb555e660706151753iad29e77wbe74b05b491772de@mail.gmail.com>
References: <8DDE4EAE-47C0-4AD2-A0F3-6EC6BF3640CB@jhsph.edu>
	<eb555e660706151753iad29e77wbe74b05b491772de@mail.gmail.com>
Message-ID: <D1CBA0EB-EAAD-438B-AC1D-C42645B45B8B@jhsph.edu>

So, if those statements are inside a function, I have to make my  
function to have an 'echo' argument/functionality? eg.:

## begin test.R
test <- function(n){
   y <- rnorm(n)
   x <- rnorm(n)
   z <- sample(letters[1:4], n, rep=T)
   library(lattice)
   bitmap("tst.png")
   xyplot(y~x|z)
   dev.off()
}

test(100)
## end test.R

source("test.R", echo=T)

also fails in this case...

thanks a lot,

b


On Jun 15, 2007, at 8:53 PM, deepayan.sarkar at gmail.com wrote:

> On 6/15/07, Benilton Carvalho <bcarvalh at jhsph.edu> wrote:
>> Hi everyone,
>>
>> it's been a while I've been trying to save a plot created via
>> lattice:::xyplot
>>
>> if I have a file tst.R with the following code:
>>
>> y <- rnorm(100)
>> x <- rnorm(100)
>> z <- sample(letters[1:4], 100, rep=T)
>> library(lattice)
>> bitmap("tst.png")
>> xyplot(y~x|z)
>> dev.off()
>>
>> and I source it, I get the tst.png file, which is a blank page.
>>
>> If I copy and paste instead, I get the correct plot.
>>
>> Any suggestion?
>
> Use
>
> source(..., echo = TRUE)
>
> -Deepayan


From marc_schwartz at comcast.net  Sat Jun 16 03:12:18 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Fri, 15 Jun 2007 20:12:18 -0500
Subject: [R] R vs. Splus in Pharma/Devices Industry
In-Reply-To: <XFMail.070616004342.ted.harding@nessie.mcc.ac.uk>
References: <XFMail.070616004342.ted.harding@nessie.mcc.ac.uk>
Message-ID: <1181956338.3691.88.camel@Bellerophon.localdomain>

On Sat, 2007-06-16 at 00:43 +0100, ted.harding at nessie.mcc.ac.uk wrote:
> On 15-Jun-07 19:43:55, John Kane wrote:
> > --- Douglas Bates <bates at stat.wisc.edu> wrote:
> >> On 6/15/07, Nicholas Lewin-Koh <nikko at hailmail.net>
> >> wrote:
> >> > [...]
> >> I think you mean A, not Z.  First there was S, then
> >> there was R.
> > 
> > We're regressing !!!!
> 
> But not to mediocrity! [1]
> Ted.
> 
> [1] Practical Regression and Anova using R
>     Julian J. Faraway (July 2002), page 15.
> 
> http://cran.r-project.org/doc/contrib/Faraway-PRA.pdf


Which in turn is of course paraphrasing Galton's "Regression Toward
Mediocrity in Hereditary Stature?. Journal of the Anthropological
Institute 15 : 246-63, 1886.

http://galton.org/essays/1880-1889/galton-1886-jaigi-regression-stature.pdf

:-)

Regards,

Marc


From adschai at optonline.net  Sat Jun 16 03:31:12 2007
From: adschai at optonline.net (adschai at optonline.net)
Date: Sat, 16 Jun 2007 01:31:12 +0000 (GMT)
Subject: [R] [Not R question]: Better fit for order probit model
Message-ID: <e2a29c0889f4.46733d60@optonline.net>

Hi,

I have a model which tries to fit a set of data with 10-level ordered responses. Somehow, in my data, the majority of the observations are from level 6-10 and leave only about 1-5% of total observations contributed to level 1-10. As a result, my model tends to perform badly on points that have lower level than 6. 

I would like to ask if there's any way to circumvent this problem or not. I was thinking of the followings ideas. But I am opened to any suggestions if you could please. 

1. Bootstrapping with small size of samples each time. Howevever, in each sample basket, I intentionally sample in such a way that there is a good mix between observations from each level. Then I have to do this many times. But I don't know how to obtain the true standard error of estimated parameters after all bootstrapping has been done. Is it going to be simply the average of all standard errors estimated each time?

2. Weighting points with level 1-6 more. But it's unclear to me how to put this weight back to maximum likelihood when estimating parameters. It's unlike OLS where your objective is to minimize error or, if you'd like, a penalty function. But MLE is obviously not a penalty function.

3. Do step-wise regression. I will segment the data into two regions, first points with response less than 6 and the rest with those above 6. The first step is a binary regression to determine if the point belongs to which of the two groups. Then in the second step, estimate ordered probit model for each group separately. The question here is then, why I am choosing 6 as a cutting point instead of others? 

Any suggestions would be really appreciated. Thank you.

- adschai


From ian at iangregory.com  Sat Jun 16 03:57:10 2007
From: ian at iangregory.com (Ian Gregory)
Date: Sat, 16 Jun 2007 11:57:10 +1000
Subject: [R] fSeries - Ox - ver: 240.10068 - Steps to make it work
Message-ID: <006a01c7afb9$a88641d0$4001a8c0@jaegerdesktop>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070616/32d6872f/attachment.pl 

From ral at lcfltd.com  Sat Jun 16 04:51:15 2007
From: ral at lcfltd.com (Robert A LaBudde)
Date: Fri, 15 Jun 2007 22:51:15 -0400
Subject: [R] [Not R question]: Better fit for order probit model
In-Reply-To: <e2a29c0889f4.46733d60@optonline.net>
References: <e2a29c0889f4.46733d60@optonline.net>
Message-ID: <0JJP007MLJXIS3N3@vms042.mailsrvcs.net>

At 09:31 PM 6/15/2007, adschai wrote:
>I have a model which tries to fit a set of data with 10-level 
>ordered responses. Somehow, in my data, the majority of the 
>observations are from level 6-10 and leave only about 1-5% of total 
>observations contributed to level 1-10. As a result, my model tends 
>to perform badly on points that have lower level than 6.
>
>I would like to ask if there's any way to circumvent this problem or 
>not. I was thinking of the followings ideas. But I am opened to any 
>suggestions if you could please.
>
>1. Bootstrapping with small size of samples each time. Howevever, in 
>each sample basket, I intentionally sample in such a way that there 
>is a good mix between observations from each level. Then I have to 
>do this many times. But I don't know how to obtain the true standard 
>error of estimated parameters after all bootstrapping has been done. 
>Is it going to be simply the average of all standard errors 
>estimated each time?
>
>2. Weighting points with level 1-6 more. But it's unclear to me how 
>to put this weight back to maximum likelihood when estimating 
>parameters. It's unlike OLS where your objective is to minimize 
>error or, if you'd like, a penalty function. But MLE is obviously 
>not a penalty function.
>
>3. Do step-wise regression. I will segment the data into two 
>regions, first points with response less than 6 and the rest with 
>those above 6. The first step is a binary regression to determine if 
>the point belongs to which of the two groups. Then in the second 
>step, estimate ordered probit model for each group separately. The 
>question here is then, why I am choosing 6 as a cutting point 
>instead of others?
>
>Any suggestions would be really appreciated. Thank you.

You could do the obvious, and lump categories such as 1-6 or 1-7 
together to make a composite category.

You don't mention the size of your dataset. If there are 10,000 data, 
you might live with a 1% category. If you only have 100 data, you 
have too many categories.

Also, next time plan your study and training better so that next time 
your categories are fully utilized. And don't use so many categories. 
People have trouble even selecting responses on a 5-level scale.
================================================================
Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
824 Timberlake Drive                     Tel: 757-467-0954
Virginia Beach, VA 23464-3239            Fax: 757-467-2947

"Vere scire est per causas scire"


From p_connolly at ihug.co.nz  Sat Jun 16 06:09:17 2007
From: p_connolly at ihug.co.nz (Patrick Connolly)
Date: Sat, 16 Jun 2007 16:09:17 +1200
Subject: [R] Upgraded FC4 to FC5 - unable to start device X11 in R
In-Reply-To: <4672FB97.4040005@ucla.edu>
References: <4672FB97.4040005@ucla.edu>
Message-ID: <20070616040917.GT4805@ihug.co.nz>

On Fri, 15-Jun-2007 at 01:50PM -0700, Li-Jung Liang wrote:

|> Hi,
|> 
|> I upgraded my system from FC4 to FC5.  So now I have R version 2.5.0 
|> (2007-04-23).
|> But I ran into a problem with starting device X11 (message below).
|> 
|>  > X11()
|> can't find X11 font
|> Error in X11(display, width, height, pointsize, if (is.null(gamma)) 1 
|> else gamma,  :
|>         unable to start device X11
|> 
|> Any idea?

Check what search() gives you.  Make sure package:grDevices is on that
list.

I ran into that problem myself.  I never figured out how come it used
to be there, but suddenly ceased to be.  The problem didn't appear
until R-2.5.0.  In the USER-VISIBLE CHANGES under 
CHANGES IN R VERSION 2.0.0,
I see this:

    o	Package 'graphics' has been split into 'grDevices' (the graphics
	devices shared between base and grid graphics) and 'graphics'
	(base graphics).  Each of the 'graphics' and 'grid' packages
	load 'grDevices' when they are attached.  Note that
	ps.options() has been moved to grDevices and user hooks may
	need to be updated.

My suspicion is that grDevices did not have to be specifically loaded
if graphics was one of your default packages loaded at startup.  Since
few others seem to have had the same experience, I'd hesitate to call
it a bug.  I've got round the problem by adding grDevices to the list
in my ~/.Rprofile file.

Others might have a better explanation, of course.

HTH


-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}          		 Great minds discuss ideas    
 _( Y )_  	  	        Middle minds discuss events 
(:_~*~_:) 	       		 Small minds discuss people  
 (_)-(_)  	                           ..... Anon
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From deepayan.sarkar at gmail.com  Sat Jun 16 06:26:34 2007
From: deepayan.sarkar at gmail.com (deepayan.sarkar at gmail.com)
Date: Fri, 15 Jun 2007 23:26:34 -0500
Subject: [R] plot via xyplot not being saved
In-Reply-To: <D1CBA0EB-EAAD-438B-AC1D-C42645B45B8B@jhsph.edu>
References: <8DDE4EAE-47C0-4AD2-A0F3-6EC6BF3640CB@jhsph.edu>
	<eb555e660706151753iad29e77wbe74b05b491772de@mail.gmail.com>
	<D1CBA0EB-EAAD-438B-AC1D-C42645B45B8B@jhsph.edu>
Message-ID: <eb555e660706152126n33dede36o9996d44dd80c7d5c@mail.gmail.com>

On 6/15/07, Benilton Carvalho <bcarvalh at jhsph.edu> wrote:
> So, if those statements are inside a function, I have to make my
> function to have an 'echo' argument/functionality? eg.:
>
> ## begin test.R
> test <- function(n){
>    y <- rnorm(n)
>    x <- rnorm(n)
>    z <- sample(letters[1:4], n, rep=T)
>    library(lattice)
>    bitmap("tst.png")
>    xyplot(y~x|z)
>    dev.off()
> }
>
> test(100)
> ## end test.R
>
> source("test.R", echo=T)
>
> also fails in this case...

Yes. The following will produce some output (the values of x + y and x
- y) if you type it out at the R prompt:

x <- rnorm(10)
y <- rnorm(10)
x + y
x - y

If you put that in a file and source it, nothing will get printed,
unless you have echo=TRUE. If you define

test <- function(){
    x <- rnorm(10)
    y <- rnorm(10)
    x + y
    x - y
}

calling test() at the R prompt will only print x - y and not x + y, and so on.

This is all standard R behaviour. If you want something to be printed
irrespective of context, use print(), e.g.

print(x + y)

or

print(xyplot(y~x|z))

This is also mentioned in the R FAQ.

-Deepayan


From bcarvalh at jhsph.edu  Sat Jun 16 06:55:56 2007
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Sat, 16 Jun 2007 00:55:56 -0400
Subject: [R] plot via xyplot not being saved
In-Reply-To: <eb555e660706152126n33dede36o9996d44dd80c7d5c@mail.gmail.com>
References: <8DDE4EAE-47C0-4AD2-A0F3-6EC6BF3640CB@jhsph.edu>
	<eb555e660706151753iad29e77wbe74b05b491772de@mail.gmail.com>
	<D1CBA0EB-EAAD-438B-AC1D-C42645B45B8B@jhsph.edu>
	<eb555e660706152126n33dede36o9996d44dd80c7d5c@mail.gmail.com>
Message-ID: <A581A665-49C3-4615-B709-1CE9791236CA@jhsph.edu>

Thank you Deepayan,

I understand the behavior of not printing out the results inside the  
functions.

What I didn't know was that for xyplot() saving the plot actually  
meant "save the result I see", which does not happen with plot(), in  
which case my function test() works just fine if I replaced xyplot()  
by plot().

Thank you very much,

b

On Jun 16, 2007, at 12:26 AM, deepayan.sarkar at gmail.com wrote:

> On 6/15/07, Benilton Carvalho <bcarvalh at jhsph.edu> wrote:
>> So, if those statements are inside a function, I have to make my
>> function to have an 'echo' argument/functionality? eg.:
>>
>> ## begin test.R
>> test <- function(n){
>>    y <- rnorm(n)
>>    x <- rnorm(n)
>>    z <- sample(letters[1:4], n, rep=T)
>>    library(lattice)
>>    bitmap("tst.png")
>>    xyplot(y~x|z)
>>    dev.off()
>> }
>>
>> test(100)
>> ## end test.R
>>
>> source("test.R", echo=T)
>>
>> also fails in this case...
>
> Yes. The following will produce some output (the values of x + y and x
> - y) if you type it out at the R prompt:
>
> x <- rnorm(10)
> y <- rnorm(10)
> x + y
> x - y
>
> If you put that in a file and source it, nothing will get printed,
> unless you have echo=TRUE. If you define
>
> test <- function(){
>    x <- rnorm(10)
>    y <- rnorm(10)
>    x + y
>    x - y
> }
>
> calling test() at the R prompt will only print x - y and not x + y,  
> and so on.
>
> This is all standard R behaviour. If you want something to be printed
> irrespective of context, use print(), e.g.
>
> print(x + y)
>
> or
>
> print(xyplot(y~x|z))
>
> This is also mentioned in the R FAQ.
>
> -Deepayan


From sabya231 at gmail.com  Sat Jun 16 07:18:49 2007
From: sabya231 at gmail.com (Tirthadeep)
Date: Fri, 15 Jun 2007 22:18:49 -0700 (PDT)
Subject: [R] selecting cut-off in Logistic regression using ROCR package
Message-ID: <11151210.post@talk.nabble.com>



Hi,

I am using logistic regression to classify a binary psychometric data. using
glm() and then predict.glm() i got the predicted odds ratio of the testing
data. Next i am going to plot ROC curve for the analysis of my study.

Now what i will do:

1. first select a cut-off (say 0.4) and classify the output of predict.glm()
into {0,1} segment and then use it to draw ROC curve using ROCR package 

OR

2. just use the predicted odds ratio in ROCR package to get "error rate" and
use the minimum error rate (as new cut-off) to draw new ROC curve.

waiting for reply.

with regards and thanks.

Tirtha.
-- 
View this message in context: http://www.nabble.com/selecting-cut-off-in-Logistic-regression-using-ROCR-package-tf3931603.html#a11151210
Sent from the R help mailing list archive at Nabble.com.


From h.wickham at gmail.com  Sat Jun 16 08:38:25 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Sat, 16 Jun 2007 08:38:25 +0200
Subject: [R] Stacked barchart color
In-Reply-To: <11149419.post@talk.nabble.com>
References: <LPEJLJACLINDNMBMFAFIKEBICIAA.dieter.menne@menne-biomed.de>
	<f8e6ff050706121131s4b0aeb30y8de662ddd7323092@mail.gmail.com>
	<11149419.post@talk.nabble.com>
Message-ID: <f8e6ff050706152338s6394374dqd89701c3837ec1d8@mail.gmail.com>

On 6/16/07, owenman <solberg at speakeasy.net> wrote:
>
> Hi Hadley,
> I tried your suggestion, using ggplot2, but I am still having a problem. The
> final plot lacks the figure legend -- which it had before I added the
> scale_fill_identity()  bit.  Can  you see what I am doing wrong?
> (By the way, all I am trying to do is make the figure monochrome friendly.
> Is there an easy way to prepare ggplot graphics for a monochrom device?)
> Thanks,Owen

Hi Owen,

The identity scale won't create a legend, unless you tell it what
labels it should use - there's an example at
http://had.co.nz/ggplot2/scale_identity.html.  Otherwise, if you have
a continuous scale and you want something that works in black and
white, p + scale_fill_gradient(low="white", high="black") might be
easier.

Hadley


>
> > y$color = factor(y$Fnd)
> > y$color = c("black","darkgray","lightgray","white")
> > y
>       Fnd locus        Freq color
> 1  signeg     A 0.087248322     black
> 2     neg     A 0.711409396  darkgray
> 3     pos     A 0.201342282 lightgray
> 4  sigpos     A 0.000000000     white
> 5  signeg     C 0.320754717     black
> 6     neg     C 0.603773585  darkgray
> 7     pos     C 0.075471698 lightgray
> 8  sigpos     C 0.000000000     white
> 9  signeg     B 0.157534247     black
> 10    neg     B 0.732876712  darkgray
> 11    pos     B 0.109589041 lightgray
> 12 sigpos     B 0.000000000     white
>
> > p = ggplot(y, aes(x=locus, y=Freq, fill=color)) +
> > geom_bar(position="fill") + scale_fill_identity()
> > p
>
>
>
>
> hadley wrote:
> >
> >
> > Hi Dieter,
> >
> > You can do this with ggplot2 (http://had.co.nz/ggplot2) as follows:
> >
> > library(ggplot2)
> >
> > barley1 <- subset(barley, site=="Grand Rapids" & variety %in%
> > c("Velvet","Peatland"))
> > barley1[] <- lapply(barley1, "[", drop=TRUE)
> >
> > qplot(variety, yield, data=barley1, geom="bar", stat="identity",
> > fill=factor(year))
> >
> > barley1$fill <- c("red","green","blue","gray")
> > qplot(variety, yield, data=barley1, geom="bar", stat="identity",
> > fill=fill) + scale_fill_identity()
> >
> > See http://had.co.nz/ggplot2/scale_identity.html and
> > http://had.co.nz/ggplot2/position_stack.html for more details.
> >
> > Hadley
> >
> >
>
>
> --
> View this message in context: http://www.nabble.com/Stacked-barchart-color-tf3909162.html#a11149419
> Sent from the R help mailing list archive at Nabble.com.
>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From s.blomberg1 at uq.edu.au  Sat Jun 16 08:37:39 2007
From: s.blomberg1 at uq.edu.au (Simon Blomberg)
Date: Sat, 16 Jun 2007 16:37:39 +1000
Subject: [R] R vs. Splus in Pharma/Devices Industry
References: <XFMail.070616003343.ted.harding@nessie.mcc.ac.uk>
Message-ID: <DE3D1F203DAF7A4CB259560D2801DF8B3B2A9B@UQEXMB2.soe.uq.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070616/bc16d03f/attachment.pl 

From adschai at optonline.net  Sat Jun 16 09:17:51 2007
From: adschai at optonline.net (adschai at optonline.net)
Date: Sat, 16 Jun 2007 07:17:51 +0000 (GMT)
Subject: [R] [Not R question]: Better fit for order probit model
In-Reply-To: <0JJP007MLJXIS3N3@vms042.mailsrvcs.net>
References: <e2a29c0889f4.46733d60@optonline.net>
	<0JJP007MLJXIS3N3@vms042.mailsrvcs.net>
Message-ID: <e426e6d0d3af.46738e9f@optonline.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070616/a029ec49/attachment.pl 

From birgit.lemcke at systbot.uzh.ch  Fri Jun 15 12:51:40 2007
From: birgit.lemcke at systbot.uzh.ch (Birgit Lemcke)
Date: Fri, 15 Jun 2007 12:51:40 +0200
Subject: [R] similarity
Message-ID: <BA63BE94-2B56-4BC6-BFF3-C1C0BBE4789E@systbot.uzh.ch>

Hello
I have a question about performing a similarity analysis using R.
I will perform a similarity analysis comparing species.
I have a datamatrix that looks like the Pictures you can see in the  
mail. It contains bivariate data and data in this Min Max mode.

I had to alter the multivariate data into min max, because I had more  
than one number in one species and also I had to alter the unordered  
multivariate data into bivariate data for the same reason. Now I am  
looking for a similarity algorithm or approach  in R that is able to  
deal with this data and further gives the possibility to weight the  
variables differently.

By the way it would be fine if this approach would be also able to  
treat numerical data. I hope somebody can help me.

Best regards

Birgit




?   ?

Birgit Lemcke
Institut f?r Systematische Botanik
Zollikerstrasse 107
CH-8008 Z?rich
Switzerland
Ph: +41 (0)44 634 8351
birgit.lemcke at systbot.uzh.ch






From efh at nessie.mcc.ac.uk  Fri Jun 15 18:29:53 2007
From: efh at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 15 Jun 2007 17:29:53 +0100 (BST)
Subject: [R] [OT] 'gv' and fractional points
In-Reply-To: <f8e6ff050706150856v7291e30fp94a13848ce0fc01a@mail.gmail.com>
Message-ID: <XFMail.070615172953.efh@nessie.mcc.ac.uk>

On 15-Jun-07 15:56:58, hadley wickham wrote:
> This doesn't answer your original question, and isn't much help unless
> you're on a mac, but there's a nice looking program that makes this
> kind of graph scraping really easy:
> http://www.arizona-software.ch/applications/graphclick/en/
> 
> Hadley

Thanks, Hadley! But (as you implicitly surmise) I don't use a Mac
(just non-psychedelic Linux).

However, as a follow-up, I've since found that one can (somewhat
tediously) do what I was asking with the GIMP.

If you start the GIMP on a PostScript file, you initially get a
"Load PostScript" window which asks you to choose (amongst other
things" the "resolution", initially "100". If you wind this up
to say "1000", then you get 10 times the positional precision
in the numbers shown as below.

When the image is displayed, there is again a little window
which gives you the GIMP coordinates of the mouse position.
With increased "Resolution", the numerical values vary
correspondingly more rapidly with position.

The tedious aspect (compared with 'gv') is that to get better
visual resolution you need to zoom the image. This enlarges the
whole image, with the result that you have to pan around to
locate different parts, and you can get lost in a graph with
lots of widely-spread points.

With 'gv', on the other hand, you can select any small part
to view in zoom in a sub-window, which is much easier to cope
with; and you also get a "rubber-band" rectangle which enables
you to readily align points here with points there -- e.g. if
you want to read off a curve the y-value corresponding to say
x=5.0.

However, this is at least a partial answer to my own question!

Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <efh at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 15-Jun-07                                       Time: 17:29:49
------------------------------ XFMail ------------------------------


From mazatlanmexico at yahoo.com  Fri Jun 15 20:46:08 2007
From: mazatlanmexico at yahoo.com (Felipe Carrillo)
Date: Fri, 15 Jun 2007 11:46:08 -0700 (PDT)
Subject: [R] Call-Tips
Message-ID: <675203.35376.qm@web56611.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070615/4a2150fb/attachment.pl 

From pomchip at free.fr  Thu Jun 14 21:04:05 2007
From: pomchip at free.fr (=?ISO-8859-1?Q?S=E9bastien?=)
Date: Thu, 14 Jun 2007 15:04:05 -0400
Subject: [R] Define tick mark width
Message-ID: <46719125.4080908@free.fr>

Hello,

Is there a way to define the width of the axis tick marks on 
traditionnal plots? I did not find anything specific on this topic in 
the help and par(lwd=...) does not affect the tick marks. I guess that 
using axes=FALSE and recreating the axis with the axis() command could 
do the trick but I wonder if there is no easier way.

Thanks in advance

Sebastien


From gdemeyer at telenet.be  Sat Jun 16 10:18:49 2007
From: gdemeyer at telenet.be (Tine Huyghe)
Date: Sat, 16 Jun 2007 08:18:49 +0000
Subject: [R] linear hypothesis test in gls model
Message-ID: <W814996257116381181981929@nocme1bl6.telenet-ops.be>

Dear all,

For analysis of a longitudinal data set with fixed measurement in time I built a gls model (nlme). For testing hypotheses in this model I used the linear.hypothesis function from the car package. A check with the results obtained in SAS proc MIXED with a repeated statement revealed an inconsistency in the results. The problem can be that the linear.hypothesis function (1) only gives the asymptotic chi square test and/or (2) only uses the residual error. Is there another solution to testing linear hypotheses in a gls model?

Thanks in advance


From ted.harding at nessie.mcc.ac.uk  Sat Jun 16 10:28:15 2007
From: ted.harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sat, 16 Jun 2007 09:28:15 +0100 (BST)
Subject: [R] R vs. Splus in Pharma/Devices Industry
In-Reply-To: <1181956338.3691.88.camel@Bellerophon.localdomain>
Message-ID: <XFMail.070616092815.ted.harding@nessie.mcc.ac.uk>

On 16-Jun-07 01:12:18, Marc Schwartz wrote:
> On Sat, 2007-06-16 at 00:43 +0100, ted.harding at nessie.mcc.ac.uk wrote:
>> On 15-Jun-07 19:43:55, John Kane wrote:
>> > --- Douglas Bates <bates at stat.wisc.edu> wrote:
>> >> On 6/15/07, Nicholas Lewin-Koh <nikko at hailmail.net>
>> >> wrote:
>> >> > [...]
>> >> I think you mean A, not Z.  First there was S, then
>> >> there was R.
>> > 
>> > We're regressing !!!!
>> 
>> But not to mediocrity! [1]
>> Ted.
>> 
>> [1] Practical Regression and Anova using R
>>     Julian J. Faraway (July 2002), page 15.
>> 
>> http://cran.r-project.org/doc/contrib/Faraway-PRA.pdf
> 
> 
> Which in turn is of course paraphrasing Galton's "Regression Toward
> Mediocrity in Hereditary Stature???. Journal of the Anthropological
> Institute 15 : 246-63, 1886.
> 
> http://galton.org/essays/1880-1889/galton-1886-jaigi-regression-stature.
> pdf
> 
>:-)
> 
> Regards,
> 
> Marc

Indeed! My reason for referencing it that way was to indicate
obliquely that we've moved on a lot since Galton, especially
in R :-) :-)  [ including one left over from last time :-) ]

Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 16-Jun-07                                       Time: 09:28:11
------------------------------ XFMail ------------------------------


From regina.verghis at gmail.com  Sat Jun 16 10:35:47 2007
From: regina.verghis at gmail.com (Regina Verghis)
Date: Sat, 16 Jun 2007 14:05:47 +0530
Subject: [R] Help in HMM commands
Message-ID: <49f266b90706160135r625d1fa4g5219c7679cb5cac8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070616/4fb62599/attachment.pl 

From abr-r-project at xylon.de  Sat Jun 16 10:38:19 2007
From: abr-r-project at xylon.de (Arne Brutschy)
Date: Sat, 16 Jun 2007 10:38:19 +0200
Subject: [R] Lines connecting the boxes in a boxplot
Message-ID: <1875718929.20070616103819@xylon.de>

Hello,

I'm currently using a boxplot to visualize data for three different
models. As I have three models, I'm plotting three parallel boxplots
for each factor.

This works fine - what I need now is a line connecting the medians of
each boxplot of each model. I want to do this in order to visualize
the trend that one of the models exhibit. Basically, I want to plot a
curve for each model (slightly offset on the x axis), with a boxplot
on each datapoint.

It's only an idea, and I don't know if it's not too confusing after
adding the lines... Is it possible? Has anyone done this before?

Sorry if this has been asked before or is a standard feature, I simply
have now clue how to name the feature I want. Ergo: I cannot search
for it.. :\

Regards,
Arne

PS: this is my current code

require(gplots)
boxwex=0.15

data <- read.table("all_runs_fitness.data");
colnames(data)=c("model","matrix","fitness")

boxplot(fitness ~ matrix,
        data=data, boxwex=boxwex, at=(1:7 - 0.2),
        main="Fitness for Matrix/Models", xlab="Matrixtype",
        ylab="Fitness", ylim=c(20,100), 
        subset=(model=="dyn"), col="lightblue", xaxt="n", whisklty=1)
boxplot(fitness ~ matrix,
        data=data, boxwex=boxwex, at = 1:7, add=TRUE, 
        subset=(model=="dl3"), col="mistyrose", xaxt="n", whisklty=1)
boxplot(fitness ~ matrix,
        data=data, boxwex=boxwex, at=(1:7 + 0.2), add=TRUE, 
        subset=(model=="dl4"), col="lightcyan", xaxt="n", whisklty=1)

axis(1, 1:8-0.5, labels=FALSE)
axis(1, 1:7, tck=FALSE, labels=levels(data[,2]))

smartlegend(x="left", y="bottom", inset = 0.01,
            c("dyn","dl3","dl4"), fill = c("lightblue", "mistyrose", "lightcyan"))


From abr-r-project at xylon.de  Sat Jun 16 10:55:14 2007
From: abr-r-project at xylon.de (Arne Brutschy)
Date: Sat, 16 Jun 2007 10:55:14 +0200
Subject: [R] Visualize quartiles of plot line
Message-ID: <699125298.20070616105514@xylon.de>

Hello,

I'm currently using a simple plot to visualize some mean values. I'm
having ~200 datapoints on the x-axis, each has 10 records. I'm
currently plotting only the mean value of each of the datapoints.

What I need is a way to visualize the quartiles/error/whatever of
these points. I thought about boxplots, but I have to many points on
the xaxis - it would be impossible to see anything. I though that it
would be nice to have a "hull" around each line, indicate the width of
the quartiles, visualized by a different background. It's like a very
wide boxplot with a changing mean value...

Is this possible with r? Does anyone know what I mean and/or has done
this before?

Thanks
Arne


From p_connolly at ihug.co.nz  Sat Jun 16 11:02:18 2007
From: p_connolly at ihug.co.nz (Patrick Connolly)
Date: Sat, 16 Jun 2007 21:02:18 +1200
Subject: [R] Upgraded FC4 to FC5 - unable to start device X11 in R
In-Reply-To: <20070616040917.GT4805@ihug.co.nz>
References: <4672FB97.4040005@ucla.edu> <20070616040917.GT4805@ihug.co.nz>
Message-ID: <20070616090218.GU4805@ihug.co.nz>

On Sat, 16-Jun-2007 at 04:09PM +1200, Patrick Connolly wrote:

|> On Fri, 15-Jun-2007 at 01:50PM -0700, Li-Jung Liang wrote:
|> 
|> |> Hi,
|> |> 
|> |> I upgraded my system from FC4 to FC5.  So now I have R version 2.5.0 
|> |> (2007-04-23).
|> |> But I ran into a problem with starting device X11 (message below).
|> |> 
|> |>  > X11()
|> |> can't find X11 font
|> |> Error in X11(display, width, height, pointsize, if (is.null(gamma)) 1 
|> |> else gamma,  :
|> |>         unable to start device X11
|> |> 
|> |> Any idea?
|> 
|> Check what search() gives you.  Make sure package:grDevices is on that
|> list.
|> 
|> I ran into that problem myself.  I never figured out how come it used
|> to be there, but suddenly ceased to be.  The problem didn't appear
|> until R-2.5.0.  In the USER-VISIBLE CHANGES under 
|> CHANGES IN R VERSION 2.0.0,
|> I see this:
|> 
|>  o	Package 'graphics' has been split into 'grDevices' (the graphics
|> 	devices shared between base and grid graphics) and 'graphics'
|> 	(base graphics).  Each of the 'graphics' and 'grid' packages
|> 	load 'grDevices' when they are attached.  Note that
|> 	ps.options() has been moved to grDevices and user hooks may
|> 	need to be updated.
|> 
|> My suspicion is that grDevices did not have to be specifically loaded
|> if graphics was one of your default packages loaded at startup.  Since
|> few others seem to have had the same experience, I'd hesitate to call
|> it a bug.  I've got round the problem by adding grDevices to the list
|> in my ~/.Rprofile file.

Perhaps I could explain what I meant to say better than that....  

Starting R with the --vanilla switch will load graphics and the
grDevices packages (among others).  There seems to be a difference
from previous versions if I use a ~/.Rprofile file to load the
graphics package, since the grDevices does NOT automatically load
whereas it did in R-2.4.x versions.  That might be a bug, but since
others don't seem to have the problem, I'd hesitate to say.  

In any case, if grDevices isn't in the search list, I'd be fairly
certain you can get round the problem you describe by specifically
loading it, or adding it to the startup list of packages.  (I'm
assuming you installed R from the tgz file and not an rpm).  I, too,
use Redhat/Fedora but other users don't seem to have the same problem,
so it's likely something more specific to our setups.

As ever, the more knowledgeable could have a better idea.

HTH

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}          		 Great minds discuss ideas    
 _( Y )_  	  	        Middle minds discuss events 
(:_~*~_:) 	       		 Small minds discuss people  
 (_)-(_)  	                           ..... Anon
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From h.wickham at gmail.com  Sat Jun 16 12:15:15 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Sat, 16 Jun 2007 12:15:15 +0200
Subject: [R] Visualize quartiles of plot line
In-Reply-To: <699125298.20070616105514@xylon.de>
References: <699125298.20070616105514@xylon.de>
Message-ID: <f8e6ff050706160315r325ec00eua9b14eb87152db71@mail.gmail.com>

How about quantile regression?  Have a look at
http://had.co.nz/ggplot2/stat_quantile.html for some examples of what
that might look like.

Hadley

On 6/16/07, Arne Brutschy <abr-r-project at xylon.de> wrote:
> Hello,
>
> I'm currently using a simple plot to visualize some mean values. I'm
> having ~200 datapoints on the x-axis, each has 10 records. I'm
> currently plotting only the mean value of each of the datapoints.
>
> What I need is a way to visualize the quartiles/error/whatever of
> these points. I thought about boxplots, but I have to many points on
> the xaxis - it would be impossible to see anything. I though that it
> would be nice to have a "hull" around each line, indicate the width of
> the quartiles, visualized by a different background. It's like a very
> wide boxplot with a changing mean value...
>
> Is this possible with r? Does anyone know what I mean and/or has done
> this before?
>
> Thanks
> Arne
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From martin.becker at mx.uni-saarland.de  Sat Jun 16 12:31:58 2007
From: martin.becker at mx.uni-saarland.de (Martin Becker)
Date: Sat, 16 Jun 2007 12:31:58 +0200
Subject: [R] fSeries - Ox - ver: 240.10068 - Steps to make it work
In-Reply-To: <006a01c7afb9$a88641d0$4001a8c0@jaegerdesktop>
References: <006a01c7afb9$a88641d0$4001a8c0@jaegerdesktop>
Message-ID: <4673BC1E.7070805@mx.uni-saarland.de>

I think there is still a small bug which I reported some time ago to 
r-sig-finance 
(https://stat.ethz.ch/pipermail/r-sig-finance/2005q4/000498.html) and 
which takes effect if the time series is not stored in the variable 'x':

The line

    write(x, file = "OxSeries.csv", ncolumns = 1, append = TRUE)

in .garchOxFit() (fSeries version 240.10068) should read

    write(x = series, file = "OxSeries.csv", ncolumns = 1, append = TRUE)

instead.

Incorporating the changes for OX-G at RCH4.2 could be a good occasion to 
fix this as well :-)

Regards,

  Martin


Ian Gregory wrote:
> -Bugs and fixes reported to Diethelm Wuertz.
> -In the interim.  To make the Ox functions part of the fSeries package work please follow the following steps.
>
>   
[snip]


From mark_difford at yahoo.co.uk  Sat Jun 16 13:07:07 2007
From: mark_difford at yahoo.co.uk (Mark Difford)
Date: Sat, 16 Jun 2007 04:07:07 -0700 (PDT)
Subject: [R] Visualize quartiles of plot line
In-Reply-To: <699125298.20070616105514@xylon.de>
References: <699125298.20070616105514@xylon.de>
Message-ID: <11153111.post@talk.nabble.com>


Hi Arne,

You might also take a look at Prof. Harrell's function:

require(Hmisc)             ## req. library [note: also needs lattice]
?smedian.hilow

Then look at:

?xYplot

And, in particular, at: panel.xYplot(), sub "Usage:"

This does what you want.

## Example; also look at Prof Harrell's examples
xYplot(Murder ~ UrbanPop, data=USArrests, method='quantiles')

HTH, Regards,
Mark.



Arne Brutschy-2 wrote:
> 
> Hello,
> 
> I'm currently using a simple plot to visualize some mean values. I'm
> having ~200 datapoints on the x-axis, each has 10 records. I'm
> currently plotting only the mean value of each of the datapoints.
> 
> What I need is a way to visualize the quartiles/error/whatever of
> these points. I thought about boxplots, but I have to many points on
> the xaxis - it would be impossible to see anything. I though that it
> would be nice to have a "hull" around each line, indicate the width of
> the quartiles, visualized by a different background. It's like a very
> wide boxplot with a changing mean value...
> 
> Is this possible with r? Does anyone know what I mean and/or has done
> this before?
> 
> Thanks
> Arne
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/Visualize-quartiles-of-plot-line-tf3932181.html#a11153111
Sent from the R help mailing list archive at Nabble.com.


From Mike.Lawrence at DAL.CA  Sat Jun 16 13:12:43 2007
From: Mike.Lawrence at DAL.CA (Mike Lawrence)
Date: Sat, 16 Jun 2007 08:12:43 -0300
Subject: [R] Fwd:  How to set degrees of freedom in cor.test?
References: <F7FE28B0-4D0E-4CCF-8907-E0F3E433FD66@DAL.CA>
Message-ID: <8CA342BC-3CDF-45DD-A535-0F4D1968FB97@DAL.CA>


You could calculate the confidence interval of the correlation at  
your desired df: http://davidmlane.com/hyperstat/B8544.html

The below code takes as arguments the observed correlation, N, and  
alpha, calculates the confidence interval and checks whether this  
includes 0.

cor.test2=function(r,n,a=.05){
	phi=function(x){
		log((1+x)/(1-x))/2
	}
	inv.phi=function(x){
		(exp(2*x)-1)/(exp(2*x)+1)
	}

	r.prime=phi(r)
	err=qnorm(1-(a/2))/sqrt(n-3)
	lims=c(inv.phi(r.prime-err),inv.phi(r.prime+err))
	sig=ifelse(xor(all(0<lims),all(0>lims)),T,F)
	return(sig)
}

> On 14-Jun-07, at 5:40 AM, Florence Dufour wrote:
>
>>
>> Hello,
>>
>> I want to compute a correlation test but I do not want to use the
>> degrees of freedom that are calculated by default but I want to set a
>> particular number of degrees of freedom.
>> I looked in the manual, different other functions but I did not found
>> how to do it
>>
>> Thanks in advance for your answers
>>
>> Yours
>>
>>
>>
>>
>> Florence Dufour
>> PhD Student
>> AZTI Tecnalia - Spain
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting- 
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> --
> Mike Lawrence
> Graduate Student, Department of Psychology, Dalhousie University
>
> Website: http://myweb.dal.ca/mc973993
> Public calendar: http://icalx.com/public/informavore/Public
>
> "The road to wisdom? Well, it's plain and simple to express:
> Err and err and err again, but less and less and less."
> 	- Piet Hein
>

--
Mike Lawrence
Graduate Student, Department of Psychology, Dalhousie University

Website: http://myweb.dal.ca/mc973993
Public calendar: http://icalx.com/public/informavore/Public

"The road to wisdom? Well, it's plain and simple to express:
Err and err and err again, but less and less and less."
	- Piet Hein


From Mike.Lawrence at DAL.CA  Sat Jun 16 13:26:29 2007
From: Mike.Lawrence at DAL.CA (Mike Lawrence)
Date: Sat, 16 Jun 2007 08:26:29 -0300
Subject: [R] question about formula for lm
In-Reply-To: <07E228A5BE53C24CAD490193A7381BBBA21E77@LP-EXCHVS07.CO.IHC.COM>
References: <07E228A5BE53C24CAD490193A7381BBBA21E77@LP-EXCHVS07.CO.IHC.COM>
Message-ID: <5650E4EE-9087-4524-8048-1B907F203993@DAL.CA>

Yet another solution:

with(X,lm(get(Ytext)~Xvar))

On 14-Jun-07, at 5:18 PM, Greg Snow wrote:

>
> Try:
>
>> lm( formula( paste( Ytext, '~ Xvar' ) ), data=X)
>
> --  
> Gregory (Greg) L. Snow Ph.D.
> Statistical Data Center
> Intermountain Healthcare
> greg.snow at intermountainmail.org
> (801) 408-8111
>
>
>
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch
>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Pedro Mardones
>> Sent: Thursday, June 14, 2007 1:14 PM
>> To: R-help at stat.math.ethz.ch
>> Subject: [R] question about formula for lm
>>
>> Dear all;
>>
>> Is there any way to make this to work?:
>>
>> .x<-rnorm(50,10,3)
>> .y<-.x+rnorm(50,0,1)
>>
>> X<-data.frame(.x,.y)
>> colnames(X)<-c("Xvar","Yvar")
>>
>> Ytext<-"Yvar"
>>
>> lm(Ytext~Xvar,data=X) # doesn't run
>>
>> lm(Yvar~Xvar,data=X) # does run
>>
>> The main idea is to use Ytext as input in a function, so you
>> just type "Yvar" and the model should fit....
>> Also, I need to avoid the expression X$Yvar~X$Xvar
>>
>> Thanks for any idea
>>
>> PM
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Mike Lawrence
Graduate Student, Department of Psychology, Dalhousie University

Website: http://myweb.dal.ca/mc973993
Public calendar: http://icalx.com/public/informavore/Public

"The road to wisdom? Well, it's plain and simple to express:
Err and err and err again, but less and less and less."
	- Piet Hein


From ian at iangregory.com  Sat Jun 16 13:38:57 2007
From: ian at iangregory.com (Ian Gregory)
Date: Sat, 16 Jun 2007 21:38:57 +1000
Subject: [R] fSeries - Ox - ver: 240.10068 - Steps to make it work
References: <006a01c7afb9$a88641d0$4001a8c0@jaegerdesktop>
	<4673BC1E.7070805@mx.uni-saarland.de>
Message-ID: <00a001c7b00a$eec5f220$4001a8c0@jaegerdesktop>

I tried the following and it works for me (after the changes to make):

library(fSeries)
data(dem2gbp)
IanSeries = dem2gbp[, 1]
garchOxFit(~garch(1,1),IanSeries)

Any writing of data is performed in the GarchOxModelling.ox file.
The number of lines of code in the function .garchOxFit() does not appear
to go up to 55.  When using:  edit(garchOxFit).

I get for the output from the estimation to be:

.......
.......
Estimated Parameters Vector :
-0.006183; 0.010761; 0.153406; 0.805877


regards,

Ian.


----- Original Message ----- 
From: "Martin Becker" <martin.becker at mx.uni-saarland.de>
To: "Ian Gregory" <ian at iangregory.com>
Cc: <r-help at stat.math.ethz.ch>; <wuertz at itp.phys.ethz.ch>
Sent: Saturday, June 16, 2007 8:31 PM
Subject: Re: [R] fSeries - Ox - ver: 240.10068 - Steps to make it work


>I think there is still a small bug which I reported some time ago to 
>r-sig-finance 
>(https://stat.ethz.ch/pipermail/r-sig-finance/2005q4/000498.html) and which 
>takes effect if the time series is not stored in the variable 'x':
>
> The line
>
>    write(x, file = "OxSeries.csv", ncolumns = 1, append = TRUE)
>
> in .garchOxFit() (fSeries version 240.10068) should read
>
>    write(x = series, file = "OxSeries.csv", ncolumns = 1, append = TRUE)
>
> instead.
>
> Incorporating the changes for OX-G at RCH4.2 could be a good occasion to fix 
> this as well :-)
>
> Regards,
>
>  Martin
>
>
> Ian Gregory wrote:
>> -Bugs and fixes reported to Diethelm Wuertz.
>> -In the interim.  To make the Ox functions part of the fSeries package 
>> work please follow the following steps.
>>
>>
> [snip]
>
>


From martin.becker at mx.uni-saarland.de  Sat Jun 16 13:54:48 2007
From: martin.becker at mx.uni-saarland.de (Martin Becker)
Date: Sat, 16 Jun 2007 13:54:48 +0200
Subject: [R] fSeries - Ox - ver: 240.10068 - Steps to make it work
In-Reply-To: <00a001c7b00a$eec5f220$4001a8c0@jaegerdesktop>
References: <006a01c7afb9$a88641d0$4001a8c0@jaegerdesktop>
	<4673BC1E.7070805@mx.uni-saarland.de>
	<00a001c7b00a$eec5f220$4001a8c0@jaegerdesktop>
Message-ID: <4673CF88.4050802@mx.uni-saarland.de>

Line number 55 in the original mail from 2005 was a reference to 
garchOxFit (not .garchOxFit) in fSeries version 220.10063 (not 
240.10068), as mentioned in 
https://stat.ethz.ch/pipermail/r-sig-finance/2005q4/000498.html . Of 
course, in the current version of .garchOxFit, the line number has 
changed, but the line should still be there, and if .garchOxFit has less 
than 55 lines, it should be easy to find.
Does your example still work, if you don't have a variable 'x' visible 
to garchOxFit (in your environment/search path)? I suppose garchOxFit 
just uses the series stored in 'x' (in your current workspace) instead 
of 'IanSeries' (which is even worse than aborting...).

Regards,

  Martin


Ian Gregory schrieb:
> I tried the following and it works for me (after the changes to make):
>
> library(fSeries)
> data(dem2gbp)
> IanSeries = dem2gbp[, 1]
> garchOxFit(~garch(1,1),IanSeries)
>
> Any writing of data is performed in the GarchOxModelling.ox file.
> The number of lines of code in the function .garchOxFit() does not appear
> to go up to 55.  When using:  edit(garchOxFit).
>
> I get for the output from the estimation to be:
>
> .......
> .......
> Estimated Parameters Vector :
> -0.006183; 0.010761; 0.153406; 0.805877
>
>
> regards,
>
> Ian.
>
>
> ----- Original Message ----- From: "Martin Becker" 
> <martin.becker at mx.uni-saarland.de>
> To: "Ian Gregory" <ian at iangregory.com>
> Cc: <r-help at stat.math.ethz.ch>; <wuertz at itp.phys.ethz.ch>
> Sent: Saturday, June 16, 2007 8:31 PM
> Subject: Re: [R] fSeries - Ox - ver: 240.10068 - Steps to make it work
>
>
>> I think there is still a small bug which I reported some time ago to 
>> r-sig-finance 
>> (https://stat.ethz.ch/pipermail/r-sig-finance/2005q4/000498.html) and 
>> which takes effect if the time series is not stored in the variable 'x':
>>
>> The line
>>
>>    write(x, file = "OxSeries.csv", ncolumns = 1, append = TRUE)
>>
>> in .garchOxFit() (fSeries version 240.10068) should read
>>
>>    write(x = series, file = "OxSeries.csv", ncolumns = 1, append = TRUE)
>>
>> instead.
>>
>> Incorporating the changes for OX-G at RCH4.2 could be a good occasion to 
>> fix this as well :-)
>>
>> Regards,
>>
>>  Martin
>>
>>
>> Ian Gregory wrote:
>>> -Bugs and fixes reported to Diethelm Wuertz.
>>> -In the interim.  To make the Ox functions part of the fSeries 
>>> package work please follow the following steps.
>>>
>>>
>> [snip]
>>
>>


From f.harrell at vanderbilt.edu  Sat Jun 16 16:03:32 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Sat, 16 Jun 2007 09:03:32 -0500
Subject: [R] selecting cut-off in Logistic regression using ROCR package
In-Reply-To: <11151210.post@talk.nabble.com>
References: <11151210.post@talk.nabble.com>
Message-ID: <4673EDB4.80509@vanderbilt.edu>

Tirthadeep wrote:
> 
> Hi,
> 
> I am using logistic regression to classify a binary psychometric data. using
> glm() and then predict.glm() i got the predicted odds ratio of the testing
> data. Next i am going to plot ROC curve for the analysis of my study.
> 
> Now what i will do:
> 
> 1. first select a cut-off (say 0.4) and classify the output of predict.glm()
> into {0,1} segment and then use it to draw ROC curve using ROCR package 
> 
> OR
> 
> 2. just use the predicted odds ratio in ROCR package to get "error rate" and
> use the minimum error rate (as new cut-off) to draw new ROC curve.
> 
> waiting for reply.
> 
> with regards and thanks.
> 
> Tirtha.

It's not clear why any cutoff or ROC curve is needed.  Please give us 
more information about why a continuous variable should be dichotomized, 
and read

@Article{roy06dic,
   author = 		 {Royston, Patrick and Altman, Douglas G. and
Sauerbrei, Willi},
   title = 		 {Dichotomizing continuous predictors in multiple
regression: a bad idea},
   journal = 	 Stat in Med,
   year = 		 2006,
   volume =		 25,
   pages =		 {127-141},
   annote =		 {continuous
covariates;dichotomization;categorization;regression;efficiency;clinical
research;residual confounding;destruction of statistical inference
when cutpoints are chosen using the response variable;varying effect
estimates from change in cutpoints;difficult to interpret effects
when dichotomize;nice plot showing effect of categorization;PBC data}
}

Frank

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From ral at lcfltd.com  Sat Jun 16 16:52:37 2007
From: ral at lcfltd.com (Robert A LaBudde)
Date: Sat, 16 Jun 2007 10:52:37 -0400
Subject: [R] [Not R question]: Better fit for order probit model
In-Reply-To: <e426e6d0d3af.46738e9f@optonline.net>
References: <e2a29c0889f4.46733d60@optonline.net>
	<0JJP007MLJXIS3N3@vms042.mailsrvcs.net>
	<e426e6d0d3af.46738e9f@optonline.net>
Message-ID: <0JJQ00D91HBS55B4@vms044.mailsrvcs.net>

At 03:17 AM 6/16/2007, adschai wrote:
>Thank you so much Robert. I haven't thought about the idea of 
>clumping categories together. One of the reason is because these 
>categories are bridge condition rating scores. They indeed represent 
>different meaning and serviceability conditions. They vary from 0-9. 
>I have about 300,000 data in which the first 5 labels, i.e. 0-4, are 
>bad condition bridge and there are only less than 1000 instances in 
>total. The worst case, is for example, score 0 (meaning the bridge 
>is not operatable), I have 60 instances. Score 1 I have about 100.
>
>I would appreciate if you could provide some opinion as to how you 
>would make the order probit fits better in this case? Thank you so 
>much in advance.

You certainly appear to have enough data to populate these 
categories. Your problems in a getting a good fit may relate to other problems.

You need to supply more information in order to say more.

What are the definitions of each category?

Is the ordering consistent, or are there really two different scales, 
one for bridge with essentially no problems, and another for those 
with serious damage?

What evidence do you have that your fit is poor?

What model are you fitting?

Etc.

================================================================
Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
824 Timberlake Drive                     Tel: 757-467-0954
Virginia Beach, VA 23464-3239            Fax: 757-467-2947

"Vere scire est per causas scire"


From bates at stat.wisc.edu  Sat Jun 16 17:09:59 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 16 Jun 2007 10:09:59 -0500
Subject: [R] question about formula for lm
In-Reply-To: <07E228A5BE53C24CAD490193A7381BBBA21E77@LP-EXCHVS07.CO.IHC.COM>
References: <83dca7860706141214o1db5fe3dxeb020bc0dbd2768c@mail.gmail.com>
	<07E228A5BE53C24CAD490193A7381BBBA21E77@LP-EXCHVS07.CO.IHC.COM>
Message-ID: <40e66e0b0706160809p3fa31e52x2e401ad410cb161c@mail.gmail.com>

On 6/14/07, Greg Snow <Greg.Snow at intermountainmail.org> wrote:
>
> Try:
>
> > lm( formula( paste( Ytext, '~ Xvar' ) ), data=X)

That type of construction is perilously close to parse(paste(...)) and
we know what Thomas said about that (see fortune("parse")).

A safer way of constructing a formula from names stored in a character
variable is

substitute(foo ~ Xvar, list(foo = as.name(Ytext))

> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Pedro Mardones
> > Sent: Thursday, June 14, 2007 1:14 PM
> > To: R-help at stat.math.ethz.ch
> > Subject: [R] question about formula for lm
> >
> > Dear all;
> >
> > Is there any way to make this to work?:
> >
> > .x<-rnorm(50,10,3)
> > .y<-.x+rnorm(50,0,1)
> >
> > X<-data.frame(.x,.y)
> > colnames(X)<-c("Xvar","Yvar")
> >
> > Ytext<-"Yvar"
> >
> > lm(Ytext~Xvar,data=X) # doesn't run
> >
> > lm(Yvar~Xvar,data=X) # does run
> >
> > The main idea is to use Ytext as input in a function, so you
> > just type "Yvar" and the model should fit....
> > Also, I need to avoid the expression X$Yvar~X$Xvar
> >
> > Thanks for any idea
> >
> > PM
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ripley at stats.ox.ac.uk  Sat Jun 16 17:43:14 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 16 Jun 2007 16:43:14 +0100 (BST)
Subject: [R] Upgraded FC4 to FC5 - unable to start device X11 in R
In-Reply-To: <20070616090218.GU4805@ihug.co.nz>
References: <4672FB97.4040005@ucla.edu> <20070616040917.GT4805@ihug.co.nz>
	<20070616090218.GU4805@ihug.co.nz>
Message-ID: <Pine.LNX.4.64.0706161636580.19440@gannet.stats.ox.ac.uk>

Clearly X11() was found, so grDevices must be on the search path.
This error message is about X11 fonts.

It is allowed to exclude grDevices from the list of default packages, and 
if you do, it is not loaded.  That is a change in 2.5.0 but not a bug.
If you chose not to ask for it, we presume you did not want it.

Parts of graphics are useful without any graphics device and there are 
graphics devices in other packages, so it seemed reasonable to allow users 
the choice of whether they got grDevices.


On Sat, 16 Jun 2007, Patrick Connolly wrote:

> On Sat, 16-Jun-2007 at 04:09PM +1200, Patrick Connolly wrote:
>
> |> On Fri, 15-Jun-2007 at 01:50PM -0700, Li-Jung Liang wrote:
> |>
> |> |> Hi,
> |> |>
> |> |> I upgraded my system from FC4 to FC5.  So now I have R version 2.5.0
> |> |> (2007-04-23).
> |> |> But I ran into a problem with starting device X11 (message below).
> |> |>
> |> |>  > X11()
> |> |> can't find X11 font
> |> |> Error in X11(display, width, height, pointsize, if (is.null(gamma)) 1
> |> |> else gamma,  :
> |> |>         unable to start device X11
> |> |>
> |> |> Any idea?
> |>
> |> Check what search() gives you.  Make sure package:grDevices is on that
> |> list.
> |>
> |> I ran into that problem myself.  I never figured out how come it used
> |> to be there, but suddenly ceased to be.  The problem didn't appear
> |> until R-2.5.0.  In the USER-VISIBLE CHANGES under
> |> CHANGES IN R VERSION 2.0.0,
> |> I see this:
> |>
> |>  o	Package 'graphics' has been split into 'grDevices' (the graphics
> |> 	devices shared between base and grid graphics) and 'graphics'
> |> 	(base graphics).  Each of the 'graphics' and 'grid' packages
> |> 	load 'grDevices' when they are attached.  Note that
> |> 	ps.options() has been moved to grDevices and user hooks may
> |> 	need to be updated.
> |>
> |> My suspicion is that grDevices did not have to be specifically loaded
> |> if graphics was one of your default packages loaded at startup.  Since
> |> few others seem to have had the same experience, I'd hesitate to call
> |> it a bug.  I've got round the problem by adding grDevices to the list
> |> in my ~/.Rprofile file.
>
> Perhaps I could explain what I meant to say better than that....
>
> Starting R with the --vanilla switch will load graphics and the
> grDevices packages (among others).  There seems to be a difference
> from previous versions if I use a ~/.Rprofile file to load the
> graphics package, since the grDevices does NOT automatically load
> whereas it did in R-2.4.x versions.  That might be a bug, but since
> others don't seem to have the problem, I'd hesitate to say.
>
> In any case, if grDevices isn't in the search list, I'd be fairly
> certain you can get round the problem you describe by specifically
> loading it, or adding it to the startup list of packages.  (I'm
> assuming you installed R from the tgz file and not an rpm).  I, too,
> use Redhat/Fedora but other users don't seem to have the same problem,
> so it's likely something more specific to our setups.
>
> As ever, the more knowledgeable could have a better idea.
>
> HTH
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From f.harrell at vanderbilt.edu  Sat Jun 16 18:14:12 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Sat, 16 Jun 2007 11:14:12 -0500
Subject: [R] complex contrasts and logistic regression
In-Reply-To: <1181928550.18770.1195374609@webmail.messagingengine.com>
References: <1181928550.18770.1195374609@webmail.messagingengine.com>
Message-ID: <46740C54.1030700@vanderbilt.edu>

Nicholas Lewin-Koh wrote:
> Hi,
> I am doing a retrospective analysis on a cohort from a designed trial,
> and I am fitting
> the model
> 
> fit<-glmD(survived ~ Covariate*Therapy + confounder,myDat,X=TRUE,
> Y=TRUE, family=binomial()) 

For logistic regression you can also use Design's lrm function which 
gives you more options.

> 
> My covariate has three levels ("A","B" and "C") and therapy has two
> (treated and control), confounder is a continuous variable.
> Also patients were randomized to treatment in the trial, but Covariate
> is something that is measured
> posthoc and can vary in the population.

If by posthoc you mean that the covariate is measured after baseline, it 
is difficult to get an interpretable analysis.

>  
> I am trying to wrap my head around how to calculate a few quantities
> from the model
> and get reasonable confidence intervals for them, namely I would like to
> test
> 
> H0: gamma=0, where gamma is the regression coefficient of the odds
> ratios of surviving
>              under treatment vs control at each level of Covariate
>              (adjusted for the confounder)

You mean regression coefficient on the log odds ratio scale.  This is 
easy to do with the contrast( ) function in Design.  Do ?contrast.Design 
for details and examples.

> 
> and I would like to get the odds of surviving at each level of Covariate
> under treatment and control
> for each level of covariate adjusted for the confounder. I have looked
> at contrast in the Design 
> library but I don't think it gives me the right quantity, for instance 
> 
> contrast(fit,list(covariate="A", Therapy="Treated",
> confounder=median(myDat$confounder), X=TRUE)
> ( "A" is the baseline level of Covariate) 
> 
> gives me beta0 + beta_Treated + beta_confounder*68  
> 
> Is this correctly interpreted as the conditional odds of dying? 
> As to the 1st contrast I am not sure how to get it, would it be using
> type = 'average' with some weights 
> in contrast? The answers are probably staring me in the face, i am just
> not seeing them today.

contrast( ) is for contrasts (differences).  Sounds like you want 
predicted values.  Do ?predict  ?predict.lrm  ?predict.Design.  Also do 
?gendata which will generate a data frame for getting predictors, with 
unspecified predictors set to reference values such as medians.

Frank

> 
> Nicholas
> 
> 
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From ggrothendieck at gmail.com  Sat Jun 16 18:54:27 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 16 Jun 2007 12:54:27 -0400
Subject: [R] question about formula for lm
In-Reply-To: <83dca7860706141214o1db5fe3dxeb020bc0dbd2768c@mail.gmail.com>
References: <83dca7860706141214o1db5fe3dxeb020bc0dbd2768c@mail.gmail.com>
Message-ID: <971536df0706160954s332e01ffy1b2c60e8fc6c63a0@mail.gmail.com>

A couple of easy ways are to create the calling sequence as a call or
character string and then evaluate it:

eval(bquote(lm(.(as.name(Ytext)) ~ Xvar, X)))

eval(parse(text = paste("lm(", Ytext, "~ Xvar, X)")))

Note that these solutions both have the advantage over some of the prior
solutions that the output from print.lm shows which variable was actually used
after Call:


> eval(bquote(lm(.(as.name(Ytext)) ~ Xvar, X)))
Call:
lm(formula = Yvar ~ Xvar, data = X)  <--- This line comes out meaningfully!!!

Coefficients:
(Intercept)         Xvar
     0.3300       0.9729


On 6/14/07, Pedro Mardones <mardones.p at gmail.com> wrote:
> Dear all;
>
> Is there any way to make this to work?:
>
> .x<-rnorm(50,10,3)
> .y<-.x+rnorm(50,0,1)
>
> X<-data.frame(.x,.y)
> colnames(X)<-c("Xvar","Yvar")
>
> Ytext<-"Yvar"
>
> lm(Ytext~Xvar,data=X) # doesn't run
>
> lm(Yvar~Xvar,data=X) # does run
>
> The main idea is to use Ytext as input in a function, so you just type
> "Yvar" and the model should fit....
> Also, I need to avoid the expression X$Yvar~X$Xvar
>
> Thanks for any idea
>
> PM
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jfox at mcmaster.ca  Sat Jun 16 19:21:55 2007
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 16 Jun 2007 13:21:55 -0400
Subject: [R] linear hypothesis test in gls model
In-Reply-To: <W814996257116381181981929@nocme1bl6.telenet-ops.be>
Message-ID: <20070616172158.CBGJ5730.tomts43-srv.bellnexxia.net@JohnDesktop8300>

Dear Tine,

linear.hypothesis() currently has no method specifically for gls objects,
and so this usage invokes the default method. I'm not sure off-hand what's
appropriate for an F-test in this context (and indeed why the default test
is inappropriate). Can you describe the correct test or supply a reference?
I suspect that it shouldn't be hard to write a linear.hypothesis method for
gls objects that fixes up the result returned by linear.hypothesis.default. 

You might take a look at car:::linear.hypothesis.default to see that it does
-- the computations are pretty straightforward.

I hope this helps,
 John 

--------------------------------
John Fox, Professor
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Tine Huyghe
> Sent: Saturday, June 16, 2007 4:19 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] linear hypothesis test in gls model
> 
> Dear all,
> 
> For analysis of a longitudinal data set with fixed 
> measurement in time I built a gls model (nlme). For testing 
> hypotheses in this model I used the linear.hypothesis 
> function from the car package. A check with the results 
> obtained in SAS proc MIXED with a repeated statement revealed 
> an inconsistency in the results. The problem can be that the 
> linear.hypothesis function (1) only gives the asymptotic chi 
> square test and/or (2) only uses the residual error. Is there 
> another solution to testing linear hypotheses in a gls model?
> 
> Thanks in advance
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From economics.guy at gmail.com  Sat Jun 16 21:06:52 2007
From: economics.guy at gmail.com (Economics Guy)
Date: Sat, 16 Jun 2007 15:06:52 -0400
Subject: [R] Use of the "by" command for gini()
Message-ID: <da0aac0706161206t62015ecas56043d8f4204ba1a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070616/3e8ccbc2/attachment.pl 

From mlwynn at indiana.edu  Sat Jun 16 21:15:48 2007
From: mlwynn at indiana.edu (Michelle Wynn)
Date: Sat, 16 Jun 2007 12:15:48 -0700
Subject: [R] data.frame and subsetting problem
Message-ID: <958ce7730706161215o3420ce38y1e4ac44a05bd2ca0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070616/bf46fc15/attachment.pl 

From larangines at hotmail.com  Sat Jun 16 21:42:21 2007
From: larangines at hotmail.com (laran gines)
Date: Sat, 16 Jun 2007 19:42:21 +0000
Subject: [R] GLM dist Gamma-links identity and inverse
Message-ID: <BAY110-W168254FE5CD5109E68A9FCC91D0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070616/61c8fdbf/attachment.pl 

From sabya231 at gmail.com  Sat Jun 16 22:12:55 2007
From: sabya231 at gmail.com (Tirthadeep)
Date: Sat, 16 Jun 2007 13:12:55 -0700 (PDT)
Subject: [R] Function for misclassification rate/type I,II error??
Message-ID: <11157781.post@talk.nabble.com>


HI 

Is there any function in R that tells us error rate(misclassification rate)
for logistic regression type classification?

i also want to know the function to determine type I and type II  error.

I have found a link where "misclass" and "confusion" are used. But I dont
know the package name.

http://alumni.media.mit.edu/~tpminka/courses/36-350.2001/lectures/day32/
http://alumni.media.mit.edu/~tpminka/courses/36-350.2001/lectures/day32/ 

Waiting for reply. 
regards.
-- 
View this message in context: http://www.nabble.com/Function-for-misclassification-rate-type-I%2CII-error---tf3934101.html#a11157781
Sent from the R help mailing list archive at Nabble.com.


From yj316 at gwu.edu  Sat Jun 16 22:38:46 2007
From: yj316 at gwu.edu (Jiao Yang)
Date: Sat, 16 Jun 2007 16:38:46 -0400
Subject: [R] How to specify covariance matrix in copula?
Message-ID: <fce4a1cfb11.46741216@gwu.edu>

I want to use copula package in R to generate random vector of multivariate F distribution with a pre-specified diagonal covariance matrix, say, diag(2, 3, 0, 0, 0).   Can someone tell me how I can specify the diagonal covariance matrix in the copula function "mvdc"?  Thank you very much.


From yj316 at gwu.edu  Sat Jun 16 22:50:08 2007
From: yj316 at gwu.edu (Jiao Yang)
Date: Sat, 16 Jun 2007 16:50:08 -0400
Subject: [R] mardia's test
Message-ID: <f657ffd76be6.467414c0@gwu.edu>

In the R code of Mardia's test, what does the line " x1 = x[x[, p] == i, -p]" mean?  Thanks a lot!

function (x) 
{
    p = dim(x)[2]
    f = p - 1
    clases = length(table(x[, p]))
    for (i in 1:clases) {
        x1 = x[x[, p] == i, -p]



        ndat = dim(x1)[1]
        mo3 = mo3(x1)
        mard1 = ndat * mo3/6
        cat("Mardia's test for class", i, "\n")
        cat("mard1=", mard1, "\n")
        p1 = 1 - pchisq(mard1, df = f * (f + 1) * (f + 2)/6)
        cat("pvalue for m3=", p1, "\n")
        mo4 = mo4(x1)
        mard2 = (mo4 - f * (f + 2))/sqrt(8 * f * (f + 2)/ndat)
        cat("mard2=", mard2, "\n")
        p2 = 2 * (1 - pnorm(abs(mard2)))
        cat("p-value for m4=", p2, "\n")
        if (p1 < 0.05 || p2 < 0.05) 
            cat("There is not statistical evidence for normality in class", 
                i, "\n")
        else cat("There is statistical evidence for normality", 
            "\n")
    }
}


From labone at gforcecable.com  Sat Jun 16 20:14:17 2007
From: labone at gforcecable.com (Tom La Bone)
Date: Sat, 16 Jun 2007 14:14:17 -0400
Subject: [R] Status of the "bs" Package
Message-ID: <000301c7b042$272b7cc0$6401a8c0@Boozoo>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070616/6ecff9b2/attachment.pl 

From edd at debian.org  Sat Jun 16 23:20:00 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 16 Jun 2007 16:20:00 -0500
Subject: [R] mardia's test
In-Reply-To: <f657ffd76be6.467414c0@gwu.edu>
References: <f657ffd76be6.467414c0@gwu.edu>
Message-ID: <18036.21504.394967.293593@basebud.nulle.part>


On 16 June 2007 at 16:50, Jiao Yang wrote:
| In the R code of Mardia's test, what does the line " x1 = x[x[, p] == i, -p]" mean?  Thanks a lot!

Read it from the inside out:

	x[, p] == i		find elements of column p in x that equal i
				the result is an vector of true/false

	x[x[, p] == i,		which is used here to subset those rows in x

	x[x[, p] == i, -p]	and the -p selects all column but the p-ths

Hth, Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From jholtman at gmail.com  Sat Jun 16 23:36:42 2007
From: jholtman at gmail.com (jim holtman)
Date: Sat, 16 Jun 2007 17:36:42 -0400
Subject: [R] data.frame and subsetting problem
In-Reply-To: <958ce7730706161215o3420ce38y1e4ac44a05bd2ca0@mail.gmail.com>
References: <958ce7730706161215o3420ce38y1e4ac44a05bd2ca0@mail.gmail.com>
Message-ID: <644e1f320706161436q6b8cc108j43c4582289067726@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070616/2c147596/attachment.pl 

From jholtman at gmail.com  Sun Jun 17 00:16:40 2007
From: jholtman at gmail.com (jim holtman)
Date: Sat, 16 Jun 2007 18:16:40 -0400
Subject: [R] Define tick mark width
In-Reply-To: <46719125.4080908@free.fr>
References: <46719125.4080908@free.fr>
Message-ID: <644e1f320706161516t9f6ed01l655c28feb3f34aac@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070616/08a5223f/attachment.pl 

From economics.guy at gmail.com  Sun Jun 17 00:55:54 2007
From: economics.guy at gmail.com (Economics Guy)
Date: Sat, 16 Jun 2007 18:55:54 -0400
Subject: [R] Use of the "by" command (clarification)
Message-ID: <da0aac0706161555x1a92d272m5ffe6a1bca2e6945@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070616/e1c3a59f/attachment.pl 

From macq at llnl.gov  Sun Jun 17 00:57:41 2007
From: macq at llnl.gov (Don MacQueen)
Date: Sat, 16 Jun 2007 15:57:41 -0700
Subject: [R] data.frame and subsetting problem
In-Reply-To: <958ce7730706161215o3420ce38y1e4ac44a05bd2ca0@mail.gmail.com>
References: <958ce7730706161215o3420ce38y1e4ac44a05bd2ca0@mail.gmail.com>
Message-ID: <p06240802c29a18a67d70@[192.168.11.7]>

I too have no idea what the object named "x2" is, or where it came 
from. Particularly since after your use of subset(), the new 
dataframe, y, *does* include a row where V2 = 'color'.

But I have a guess at what your problem may be.

In your original dataframe ("x") the first and second columns are 
factors, because that is the default behavior of read.delim().

Factors have levels. The second column has 5 levels. Try
   levels(x$V2)
to see.

When you use subset(), you get fewer rows, but the fact that there 
were five levels is retained.

Then, the plot function sees that that there are five levels, and 
includes an empty place-holder for the level(s) with no data.

Try something like
    y <- data.frame(subset(x, V1 == "shirt"))
    y$V2 <- factor(unique(format(y$V2)))
to force it to get rid of the now-empty factor levels.

There are other ways to do this, I just don't happen to remember any 
of them at the moment.

If I'm right this is a question that comes up fairly often. Might 
even be in the FAQs.

-Don


At 12:15 PM -0700 6/16/07, Michelle Wynn wrote:
>I have read the R online help and wiki and I cannot seem to get something to
>work the way I need it to.
>
>I want to create a new data frame from an subset of an existing data frame
>which has no reference to the original superset.  If you following this
>example, what I am trying to do may make more sense.
>
>I have a file with values like this:
>
>shirt,size,40
>shirt,color,10
>shirt,length,10
>shirt,brand, 1
>shoes,style,5
>shoes,brand,4
>shoes,color,1
>
>and I read it into a dataframe like:
>x <- data.frame(read.delim("temp2.txt", sep=",", header=FALSE))
>
>I then want to plot just a subset of this data (say shirts only)...
>y <- data.frame(subset(x, V1 == "shirt"))
>plot(x2[,2:3])
>
>when I do, the resulting plot contains an empty value for 'color' even
>though my subset has no value in column V2 that equals 'color' anymore.
>
>Is it possible create a new data.frame that truly deletes the rows from the
>original data frame that I am excluding with the subset parameter?
>
>Thanks,
>Michelle
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


-- 
---------------------------------
Don MacQueen
Lawrence Livermore National Laboratory
Livermore, CA, USA
925-423-1062
macq at llnl.gov


From ian at iangregory.com  Sun Jun 17 01:40:46 2007
From: ian at iangregory.com (Ian Gregory)
Date: Sun, 17 Jun 2007 09:40:46 +1000
Subject: [R] fSeries - Ox - ver: 240.10068 - Steps to make it work
References: <006a01c7afb9$a88641d0$4001a8c0@jaegerdesktop>
	<4673BC1E.7070805@mx.uni-saarland.de>
	<00a001c7b00a$eec5f220$4001a8c0@jaegerdesktop>
	<4673CF88.4050802@mx.uni-saarland.de>
Message-ID: <00f901c7b06f$ea4b99b0$4001a8c0@jaegerdesktop>

I received your error now:

In the function .garchOxFit the following line:
write(x, file = "OxSeries.csv", ncolumns = 1, append = TRUE)

should be changed to:
write(x = series, file = "OxSeries.csv", ncolumns = 1, append = TRUE)

(See below for how to reproduce this error - and identify the fix).

--------------------------
Starting a fresh session of R-Project and typing:

library(fSeries)
rm(x)
ianSeries = dem2gbp[, 1]
garchOxFit(~garch(1,1),ianSeries)

Gives the error:

-------------
Error in cat(x, file = file, sep = c(rep.int(sep, ncolumns - 1), "\n"),  :
 object "x" not found
---------------

The variable x is recognised in function: garchOxFit but not:  .garchOxFit 
and not the function: .cat.

doing this shows why:

---------------
options(error=recover)
debug( .garchOxFit)
debug(write)
---------------

The inputs for:  .garchOxFit

.garchOxFit(formula.mean, formula.var, series = x, cond.dist,
    include.mean, trace, control, title, description)

NOTE:  The data is now represented by the variable:  series and the variable
x does not exist.
To write the data to the file: OxSeries.csv.  The data variable (series) 
needs to be
passed to the write function.

This line:
 write(x, file = "OxSeries.csv", ncolumns = 1, append = TRUE)

should be changed to:
write(x = series, file = "OxSeries.csv", ncolumns = 1, append = TRUE)


regards,


Ian.


----- Original Message ----- 
From: "Martin Becker" <martin.becker at mx.uni-saarland.de>
To: "Ian Gregory" <ian at iangregory.com>
Cc: <r-help at stat.math.ethz.ch>; <wuertz at itp.phys.ethz.ch>
Sent: Saturday, June 16, 2007 9:54 PM
Subject: Re: [R] fSeries - Ox - ver: 240.10068 - Steps to make it work


> Line number 55 in the original mail from 2005 was a reference to 
> garchOxFit (not .garchOxFit) in fSeries version 220.10063 (not 240.10068), 
> as mentioned in 
> https://stat.ethz.ch/pipermail/r-sig-finance/2005q4/000498.html . Of 
> course, in the current version of .garchOxFit, the line number has 
> changed, but the line should still be there, and if .garchOxFit has less 
> than 55 lines, it should be easy to find.
> Does your example still work, if you don't have a variable 'x' visible to 
> garchOxFit (in your environment/search path)? I suppose garchOxFit just 
> uses the series stored in 'x' (in your current workspace) instead of 
> 'IanSeries' (which is even worse than aborting...).
>
> Regards,
>
>  Martin
>
>
> Ian Gregory schrieb:
>> I tried the following and it works for me (after the changes to make):
>>
>> library(fSeries)
>> data(dem2gbp)
>> IanSeries = dem2gbp[, 1]
>> garchOxFit(~garch(1,1),IanSeries)
>>
>> Any writing of data is performed in the GarchOxModelling.ox file.
>> The number of lines of code in the function .garchOxFit() does not appear
>> to go up to 55.  When using:  edit(garchOxFit).
>>
>> I get for the output from the estimation to be:
>>
>> .......
>> .......
>> Estimated Parameters Vector :
>> -0.006183; 0.010761; 0.153406; 0.805877
>>
>>
>> regards,
>>
>> Ian.
>>
>>
>> ----- Original Message ----- From: "Martin Becker" 
>> <martin.becker at mx.uni-saarland.de>
>> To: "Ian Gregory" <ian at iangregory.com>
>> Cc: <r-help at stat.math.ethz.ch>; <wuertz at itp.phys.ethz.ch>
>> Sent: Saturday, June 16, 2007 8:31 PM
>> Subject: Re: [R] fSeries - Ox - ver: 240.10068 - Steps to make it work
>>
>>
>>> I think there is still a small bug which I reported some time ago to 
>>> r-sig-finance 
>>> (https://stat.ethz.ch/pipermail/r-sig-finance/2005q4/000498.html) and 
>>> which takes effect if the time series is not stored in the variable 'x':
>>>
>>> The line
>>>
>>>    write(x, file = "OxSeries.csv", ncolumns = 1, append = TRUE)
>>>
>>> in .garchOxFit() (fSeries version 240.10068) should read
>>>
>>>    write(x = series, file = "OxSeries.csv", ncolumns = 1, append = TRUE)
>>>
>>> instead.
>>>
>>> Incorporating the changes for OX-G at RCH4.2 could be a good occasion to 
>>> fix this as well :-)
>>>
>>> Regards,
>>>
>>>  Martin
>>>
>>>
>>> Ian Gregory wrote:
>>>> -Bugs and fixes reported to Diethelm Wuertz.
>>>> -In the interim.  To make the Ox functions part of the fSeries package 
>>>> work please follow the following steps.
>>>>
>>>>
>>> [snip]
>>>
>>>
>


From chrysopa at gmail.com  Sun Jun 17 01:49:13 2007
From: chrysopa at gmail.com (Ronaldo Reis Junior)
Date: Sat, 16 Jun 2007 20:49:13 -0300
Subject: [R] How to comment out a piece of a R code in XEmacs+ESS
Message-ID: <200706162049.13360.chrysopa@gmail.com>

Hi,

When I using Xemacs+ESS to write a R code, I need to comment out a code line 
by line putting #

It is possible to configure ESS to comment and uncomment a selected block of 
code.

Thanks
Ronaldo
-- 
 __   _
/  `-' )      ,,,
| | ()|||||||[:::e
\__.-._)      '''	unk
--
> Prof. Ronaldo Reis J?nior
|  .''`. UNIMONTES/Depto. Biologia Geral/Lab. de Ecologia
| : :'  : Campus Universit?rio Prof. Darcy Ribeiro, Vila Mauric?ia
| `. `'` CP: 126, CEP: 39401-089, Montes Claros - MG - Brasil
|   `- Fone: (38) 3229-8187 | ronaldo.reis em unimontes.br | chrysopa em gmail.com
| http://www.ppgcb.unimontes.br/ | ICQ#: 5692561 | LinuxUser#: 205366


From bates at stat.wisc.edu  Sun Jun 17 02:00:24 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 16 Jun 2007 19:00:24 -0500
Subject: [R] How to comment out a piece of a R code in XEmacs+ESS
In-Reply-To: <200706162049.13360.chrysopa@gmail.com>
References: <200706162049.13360.chrysopa@gmail.com>
Message-ID: <40e66e0b0706161700t70015ef0t37769ec4bb3e043d@mail.gmail.com>

On 6/16/07, Ronaldo Reis Junior <chrysopa at gmail.com> wrote:

> When I using Xemacs+ESS to write a R code, I need to comment out a code line
> by line putting #

> It is possible to configure ESS to comment and uncomment a selected block of
> code.

This question probably belongs on the ESS-help mailing list which I am
cc:ing on this reply.

The function you want is
 M-x comment-region

To use it to uncomment pass the argument -1, as in
 M-x -1 M-x comment-region


From ccleland at optonline.net  Sun Jun 17 02:37:03 2007
From: ccleland at optonline.net (Chuck Cleland)
Date: Sat, 16 Jun 2007 20:37:03 -0400
Subject: [R] Use of the "by" command (clarification)
In-Reply-To: <da0aac0706161555x1a92d272m5ffe6a1bca2e6945@mail.gmail.com>
References: <da0aac0706161555x1a92d272m5ffe6a1bca2e6945@mail.gmail.com>
Message-ID: <4674822F.504@optonline.net>

Economics Guy wrote:
> Well apparently this has nothing to do with the gini() command.
> 
> I cannot get it to work for something as simple as sum()
> 
> Here is the little example I am playing with, maybe someone can help me find
> my error:
> 
> a<-c("A","B","C","A","B","C","A","A","C","B")
> 
> b<-c(23,6534,456,234,7,567,345,9,565,345)
> 
> c<-cbind(a,b)
> 
> by(c, a, function(x) sum(b))
> 
> and I get the output
> 
> INDICES: A
> [1] 9085
> ------------
> INDICES: B
> [1] 9085
> --------------
> INDICES: C
> [1] 9085
> 
> 
> Same problem as before. It is summing over the whole b vector rather than by
> the groups.
> 
> Anybody have any ideas on what I am doing wrong?

  Try this:

a <- c("A","B","C","A","B","C","A","A","C","B")

b <- c(23,6534,456,234,7,567,345,9,565,345)

c <- data.frame(a,b)

by(c, a, function(x) sum(x$b))

a: A
[1] 611
---------------------------------------------------------------------------------------------------------------------

a: B
[1] 6886
---------------------------------------------------------------------------------------------------------------------

a: C
[1] 1588

  Also, consider this:

> with(c, tapply(b, list(a), sum))
   A    B    C
 611 6886 1588

> Thanks,
> 
> EG
> 
> On 6/16/07, Economics Guy <economics.guy at gmail.com> wrote:
>> I have a data set that contains income data and a group identifier. Sort
>> of like:
>>
>>
>>        DATA
>>
>> Group,Income
>> A,2300
>> B,6776
>> A,6668
>> A,6768
>> B,9879
>> C,5577
>> A,7867
>> (etc),(etc)
>>
>> I am trying to compute the gini coefficient for each group.
>>
>> I have tried the following and none seem to do the trick:
>>
>> 1)
>>
>> attach(DATA)
>>
>> by(DATA, group, function(x) gini(income))
>>
>>
>> 2)
>>
>> attach(data)
>>
>> tapply(income, group, function(x) gini(income))
>>
>> Both of these return the same value for all groups. Like:
>>
>> group: A
>> [1] 0.2422496
>> ------------------------------------------------------------
>> group: B
>> [1] 0.2422496
>> ------------------------------------------------------------
>> group: C
>> [1] 0.2422496
>> ------------------------------------------------------------
>> group: D
>> [1] 0.2422496
>>
>> Any ideas on how I can make this work? I need the fastest way since I am
>> gonna run a monte carlo based on this routine once I get the basics working.
>>
>>
>> Thanks,
>>
>> EG
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code. 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From pomchip at free.fr  Sun Jun 17 03:40:08 2007
From: pomchip at free.fr (=?ISO-8859-1?Q?S=E9bastien?=)
Date: Sat, 16 Jun 2007 21:40:08 -0400
Subject: [R] Define tick mark width
In-Reply-To: <644e1f320706161516t9f6ed01l655c28feb3f34aac@mail.gmail.com>
References: <46719125.4080908@free.fr>
	<644e1f320706161516t9f6ed01l655c28feb3f34aac@mail.gmail.com>
Message-ID: <467490F8.4010102@free.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070616/4cd80fdb/attachment.pl 

From mcpung at gmail.com  Sun Jun 17 06:18:54 2007
From: mcpung at gmail.com (Murray Pung)
Date: Sun, 17 Jun 2007 14:18:54 +1000
Subject: [R] error bars on survival curve
Message-ID: <8d6f66050706162118v31d129bbudbd0aaf6acfa8b77@mail.gmail.com>

I am using plot(survfit(Surv(time,status) ~...) and would like to add
error bars rather than the confidence intervals. Am I able to do this
at specified times? e.g. when time = 20 & 40.


leukemia.surv <- survfit(Surv(time, status) ~ x, data = aml)
plot(leukemia.surv, lty = 2:3,xlim = c(0,50))
#can i add error bars at times 20 & 40?
legend(100, .9, c("Maintenance", "No Maintenance"), lty = 2:3)


Thanks
Murray
-- 
Murray Pung


From abr-r-project at xylon.de  Sun Jun 17 09:22:57 2007
From: abr-r-project at xylon.de (Arne Brutschy)
Date: Sun, 17 Jun 2007 09:22:57 +0200
Subject: [R] Visualize quartiles of plot line
In-Reply-To: <f8e6ff050706160315r325ec00eua9b14eb87152db71@mail.gmail.com>
References: <699125298.20070616105514@xylon.de>
	<f8e6ff050706160315r325ec00eua9b14eb87152db71@mail.gmail.com>
Message-ID: <555253635.20070617092257@xylon.de>

Hi,

h> How about quantile regression? Have a look at
h> http://had.co.nz/ggplot2/stat_quantile.html for some examples of
h> what that might look like.
I tried the ggplot2 package, it seems to be quite powerful. But
documentation is only partially available, so I'm having some problems
creating the graphs at all.

First of all, where can I find the diamonds and dsmall data? I cannot
recreate the samples given in the documentation.

I'm currently using a simple smoother to display the tendency of the
data and it's stderr. For some reason, it works only for simple
colors:

p <- ggplot(data, aes(x=Problemsize, y=Fitness)) +
  geom_smooth(fill=alpha("blue", 0.2), colour="darkblue", size=2)

This does only display a line, not the surrounding stderr. When I
change the fill atrribute to "blue" or "grey80" without the alpha, the
stderr gets displayed.

Additionally, I want to display three different models by this, each
with a differen curve/stderr fill color. How do I do that? I tried so
set color=Model, which yields only a single line.

On another plot, I want to use a single model to be displayed with
points colored by a gradient depending on a third property:

p <- ggplot(data, aes(x=Problemsize, y=Fitness), color=DeltaConfig) +
  geom_smooth(size=1, color="black", fill="grey80")+
  geom_point(size=0.5)+
  scale_colour_gradient(limits=c(0,10), low="red", high="white")

This does not work, I think the connection between goem_point and
DeltaConfig is not there. But when I try to set

  geom_point(size=0.5, color=DeltaConfig)+

it complains about an unknown DeltaConfig object.

Hmm, I guess I don't fully understand this 'grammar of graphics'
thing. But documentation is quite inconsistent. :( And, the coloring
thing seems to be a bug. BTW, I'm using R 2.5.0 on windows.

Greetings,
Arne



h> On 6/16/07, Arne Brutschy <abr-r-project at xylon.de> wrote:
>> Hello,
>>
>> I'm currently using a simple plot to visualize some mean values. I'm
>> having ~200 datapoints on the x-axis, each has 10 records. I'm
>> currently plotting only the mean value of each of the datapoints.
>>
>> What I need is a way to visualize the quartiles/error/whatever of
>> these points. I thought about boxplots, but I have to many points on
>> the xaxis - it would be impossible to see anything. I though that it
>> would be nice to have a "hull" around each line, indicate the width of
>> the quartiles, visualized by a different background. It's like a very
>> wide boxplot with a changing mean value...
>>
>> Is this possible with r? Does anyone know what I mean and/or has done
>> this before?
>>
>> Thanks
>> Arne


From abr-r-project at xylon.de  Sun Jun 17 09:53:19 2007
From: abr-r-project at xylon.de (Arne Brutschy)
Date: Sun, 17 Jun 2007 09:53:19 +0200
Subject: [R] Visualize quartiles of plot line
In-Reply-To: <f8e6ff050706160315r325ec00eua9b14eb87152db71@mail.gmail.com>
References: <699125298.20070616105514@xylon.de>
	<f8e6ff050706160315r325ec00eua9b14eb87152db71@mail.gmail.com>
Message-ID: <1661951608.20070617095319@xylon.de>

Hi,

concerning the missing se coloring: I followed the examples on
http://had.co.nz/ggplot2/stat_smooth.html

 c <- ggplot(mtcars, aes(y=wt, x=qsec))

 c + stat_smooth()
 c + stat_smooth() + geom_point()
 c + stat_smooth(se = TRUE) + geom_point()
 c + stat_smooth(fill=alpha("blue", 0.2), colour="darkblue", size=2)
 c + geom_point() + stat_smooth(fill=alpha("blue", 0.2), colour="darkblue", size=2)
Does not work, se is missing.

 c + stat_smooth(fill="blue", colour="darkblue", size=2)
Does work.

 c + stat_smooth(method = lm, formula= y ~ ns(x,3)) + geom_point()
 c + stat_smooth(method = rlm, formula= y ~ ns(x,3)) + geom_point()
Does not work:
"Error in model.frame(formula = formula, data = data, weights = weight,  :
                 ..2 used in a wrong context, no ... to read"

All other examples on the page do not work. This seems to be a bug,m
right? Tell me if I can be of any use fixing this.

Regards,
Arne
 
h> On 6/16/07, Arne Brutschy <abr-r-project at xylon.de> wrote:
>> Hello,
>>
>> I'm currently using a simple plot to visualize some mean values. I'm
>> having ~200 datapoints on the x-axis, each has 10 records. I'm
>> currently plotting only the mean value of each of the datapoints.
>>
>> What I need is a way to visualize the quartiles/error/whatever of
>> these points. I thought about boxplots, but I have to many points on
>> the xaxis - it would be impossible to see anything. I though that it
>> would be nice to have a "hull" around each line, indicate the width of
>> the quartiles, visualized by a different background. It's like a very
>> wide boxplot with a changing mean value...
>>
>> Is this possible with r? Does anyone know what I mean and/or has done
>> this before?
>>
>> Thanks
>> Arne
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From h.wickham at gmail.com  Sun Jun 17 10:47:35 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 17 Jun 2007 10:47:35 +0200
Subject: [R] Visualize quartiles of plot line
In-Reply-To: <1661951608.20070617095319@xylon.de>
References: <699125298.20070616105514@xylon.de>
	<f8e6ff050706160315r325ec00eua9b14eb87152db71@mail.gmail.com>
	<1661951608.20070617095319@xylon.de>
Message-ID: <f8e6ff050706170147m58c11b07j763dffb2ef07a413@mail.gmail.com>

On 6/17/07, Arne Brutschy <abr-r-project at xylon.de> wrote:
> Hi,
>
> concerning the missing se coloring: I followed the examples on
> http://had.co.nz/ggplot2/stat_smooth.html
>
>  c <- ggplot(mtcars, aes(y=wt, x=qsec))
>
>  c + stat_smooth()
>  c + stat_smooth() + geom_point()
>  c + stat_smooth(se = TRUE) + geom_point()
>  c + stat_smooth(fill=alpha("blue", 0.2), colour="darkblue", size=2)
>  c + geom_point() + stat_smooth(fill=alpha("blue", 0.2), colour="darkblue", size=2)
> Does not work, se is missing.

That's not a ggplot bug - it's a limitation of the graphics device you
are using (windows I guess), which does not support transparent
colours.

>  c + stat_smooth(fill="blue", colour="darkblue", size=2)
> Does work.
>
>  c + stat_smooth(method = lm, formula= y ~ ns(x,3)) + geom_point()
>  c + stat_smooth(method = rlm, formula= y ~ ns(x,3)) + geom_point()
> Does not work:
> "Error in model.frame(formula = formula, data = data, weights = weight,  :
>                  ..2 used in a wrong context, no ... to read"

Oops, sorry, yes, that's a bug in the current version.  I'll be
releasing a new version that fixes that bug very soon (ie. today or
tomorrow)

Hadley


From h.wickham at gmail.com  Sun Jun 17 10:51:58 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 17 Jun 2007 10:51:58 +0200
Subject: [R] Visualize quartiles of plot line
In-Reply-To: <555253635.20070617092257@xylon.de>
References: <699125298.20070616105514@xylon.de>
	<f8e6ff050706160315r325ec00eua9b14eb87152db71@mail.gmail.com>
	<555253635.20070617092257@xylon.de>
Message-ID: <f8e6ff050706170151n9706361k8ff68042ed86a615@mail.gmail.com>

On 6/17/07, Arne Brutschy <abr-r-project at xylon.de> wrote:
> Hi,
>
> h> How about quantile regression? Have a look at
> h> http://had.co.nz/ggplot2/stat_quantile.html for some examples of
> h> what that might look like.
> I tried the ggplot2 package, it seems to be quite powerful. But
> documentation is only partially available, so I'm having some problems
> creating the graphs at all.
>
> First of all, where can I find the diamonds and dsmall data? I cannot
> recreate the samples given in the documentation.

The diamonds dataset is available from the ggplot2 package, and the
dsmall dataset is usually created as needed - dsmall <-
diamonds[sample(1:nrow(diamonds), 1000), ]

> I'm currently using a simple smoother to display the tendency of the
> data and it's stderr. For some reason, it works only for simple
> colors:
>
> p <- ggplot(data, aes(x=Problemsize, y=Fitness)) +
>   geom_smooth(fill=alpha("blue", 0.2), colour="darkblue", size=2)
>
> This does only display a line, not the surrounding stderr. When I
> change the fill atrribute to "blue" or "grey80" without the alpha, the
> stderr gets displayed.

As I said in the other email, this is a known restriction of the
windows graphics device.

> Additionally, I want to display three different models by this, each
> with a differen curve/stderr fill color. How do I do that? I tried so
> set color=Model, which yields only a single line.

It's hard to know without know more about the structure of your
dataset.  Including colour=factor(Model) in the aes statement may do
what you need.

> On another plot, I want to use a single model to be displayed with
> points colored by a gradient depending on a third property:
>
> p <- ggplot(data, aes(x=Problemsize, y=Fitness), color=DeltaConfig) +
>   geom_smooth(size=1, color="black", fill="grey80")+
>   geom_point(size=0.5)+
>   scale_colour_gradient(limits=c(0,10), low="red", high="white")
>
> This does not work, I think the connection between goem_point and
> DeltaConfig is not there. But when I try to set
>
>   geom_point(size=0.5, color=DeltaConfig)+

Colour needs to be inside the aes function - you are mapping colour to
the DeltaConfig variable, not setting colour to a fixed variable.

> it complains about an unknown DeltaConfig object.
>
> Hmm, I guess I don't fully understand this 'grammar of graphics'
> thing. But documentation is quite inconsistent. :( And, the coloring
> thing seems to be a bug. BTW, I'm using R 2.5.0 on windows.

You might want to read the introductory chapters in the ggplot book,
available from http://had.co.nz/ggplot2, which will give you more of a
background.  Please let me know places where you think the
documentation is inconsistent so I can try and make them better.

Hadley


From bernd.weiss at uni-koeln.de  Sun Jun 17 12:01:27 2007
From: bernd.weiss at uni-koeln.de (Bernd Weiss)
Date: Sun, 17 Jun 2007 12:01:27 +0200
Subject: [R] [ggplot2] Change color of grid lines
Message-ID: <46752297.6693.1D9B7D9@bernd.weiss.uni-koeln.de>

Hi,

I am making myself familiar with ggplot2 (I really like the examples 
at <http://had.co.nz/ggplot2/>).  

One thing that really annoys me is the default use of white grid 
lines and a gray background [1, 2]. I simply would like to have black 
grid lines and a white background. No problem, I thought, "This is R. 
There is no if. Only how." (fortune("Simon Blomberg")). 

I carfully checked the ggplot2 homepage <http://had.co.nz/ggplot2/> 
and the ggplot2 book <http://had.co.nz/ggplot2/book.pdf>. 

It seemed that the use of ggopt would be a good idea, in particular 
grid.colour. 

library(ggplot2)
x <- rnorm(100)
y <- rnorm(100)
## the default behaviour
(a <- qplot(x,y))
## my attempt to change the default behaviour
ggopt(grid.colour = "black", grid.fill = "white", background.colour = 
"black")
(b <- qplot(x,y))

(Of course, I also gave ggtheme a try but without success.)

Unfortunately, I didn't found any solution for my problem which I 
could hardly believe. I strongly suspect that it's my fault but would 
appreciate any hint like RTFM on page XXX or so. 

Thanks in advance,

Bernd


[1] The red arrows indicate what I mean by "white grid lines" 
<http://www.metaanalyse.de/tmp/ggplot2.png>

[2] I found some reasons why Hadley Wickham prefers the default theme 
at <http://finzi.psych.upenn.edu/R/Rhelp02a/archive/81812.html>, but 
most of our journals reject the use of any gray shading.


From bartczuk at kul.lublin.pl  Sun Jun 17 12:19:31 2007
From: bartczuk at kul.lublin.pl (rafael)
Date: Sun, 17 Jun 2007 12:19:31 +0200
Subject: [R] correlation comparison one more time
In-Reply-To: <mailman.7.1182074404.9166.r-help@stat.math.ethz.ch>
References: <mailman.7.1182074404.9166.r-help@stat.math.ethz.ch>
Message-ID: <46750AB3.3060307@kul.lublin.pl>

I would like ask again,
because I cant find the answer

I have such problem:

My data containing 4 variables (A,B,C,D) and are completed from 4 samples.
Each of matrix is such:
        A   B   C   D
A     1   ab   ac   ad
B     ab  1    bc   bd  
C     ac   bc   1   cd
D     ad   bd   cd   1

My hypothesis are that

ad is the strongest correlation for A and for D (sign doesn't matter)
bc is the strongest correlation for B and for C (sign doesn't matter)

across samples.

Is it possible test these hypothesis?

Any help would be appreciated

Rafa? Bartczuk
bartczuk at kul.lublin.pl


From h.wickham at gmail.com  Sun Jun 17 12:36:24 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 17 Jun 2007 12:36:24 +0200
Subject: [R] [ggplot2] Change color of grid lines
In-Reply-To: <46752297.6693.1D9B7D9@bernd.weiss.uni-koeln.de>
References: <46752297.6693.1D9B7D9@bernd.weiss.uni-koeln.de>
Message-ID: <f8e6ff050706170336w18869a1du7d159e55c2fa32db@mail.gmail.com>

On 6/17/07, Bernd Weiss <bernd.weiss at uni-koeln.de> wrote:
> Hi,
>
> I am making myself familiar with ggplot2 (I really like the examples
> at <http://had.co.nz/ggplot2/>).
>
> One thing that really annoys me is the default use of white grid
> lines and a gray background [1, 2]. I simply would like to have black
> grid lines and a white background. No problem, I thought, "This is R.
> There is no if. Only how." (fortune("Simon Blomberg")).
>
> I carfully checked the ggplot2 homepage <http://had.co.nz/ggplot2/>
> and the ggplot2 book <http://had.co.nz/ggplot2/book.pdf>.
>
> It seemed that the use of ggopt would be a good idea, in particular
> grid.colour.
>
> library(ggplot2)
> x <- rnorm(100)
> y <- rnorm(100)
> ## the default behaviour
> (a <- qplot(x,y))
> ## my attempt to change the default behaviour
> ggopt(grid.colour = "black", grid.fill = "white", background.colour =
> "black")
> (b <- qplot(x,y))
>
> (Of course, I also gave ggtheme a try but without success.)
>
> Unfortunately, I didn't found any solution for my problem which I
> could hardly believe. I strongly suspect that it's my fault but would
> appreciate any hint like RTFM on page XXX or so.

While the structure of ggplot plots is largely complete, I'm still
working on the appearance.  I know a lot of people prefer a white
background with black gridlines (and many journals require it) but it
hasn't been a priority.  It is on my todo list, and hopefully it will
make it in the next release of ggplot (probably 7-10 days from now)

Hadley


From Bartjoosen at hotmail.com  Sun Jun 17 13:13:45 2007
From: Bartjoosen at hotmail.com (Bart Joosen)
Date: Sun, 17 Jun 2007 13:13:45 +0200
Subject: [R] Fitting model with response and day bias
References: <BAY134-F213A123367E741B00A85C3D83B0@phx.gbl>
	<1180433449.6074.10.camel@R3Thux>
	<BAY134-DAV77D9F06A807C2BEDE2BF0D82E0@phx.gbl>
	<1180550177.6130.12.camel@R3Thux>
Message-ID: <BAY134-DAV35BE83721E82DA0EE9127D81C0@phx.gbl>

Bernardo,

thanks for your solution, I was short in time last weeks, but I tried it and 
it works fine.
I'll post it to the list, as it may help other people too.

Regards


Bart

----- Original Message ----- 
From: "Bernardo Rangel Tura" <tura at centroin.com.br>
To: "Bart Joosen" <Bartjoosen at hotmail.com>
Sent: Wednesday, May 30, 2007 8:36 PM
Subject: Re: [R] Fitting model with response and day bias


> On Wed, 2007-05-30 at 17:20 +0200, Bart Joosen wrote:
>> Hello,
>>
>> you are right about lm(I(y/time)~x1+x2), but what I would like to do is:
>> lm(y~(x1+x2)*time), where x1 and x2 should have coefficients, but time 
>> not.
>> Time is just used as a multiplier and should not have a coefficient.
>> But I don't know if its possible.
>>
>> The reason why time is not in my code is that it's simplified to make it 
>> a
>> bit understandable.
>>
>>
>> Thanks anyway
>>
>> Bart
>
> Bart,
>
> If I understand you problem, you have a dataset with 4 variables (y, x1,
> x2 and time) and you need fit them model:
>
> y = A+B*(x1*time)+C*(x2*time)+error
>
> and use command: lm(y~(x1+x2)*time).
>
> I think the comand is: lm(y~I(x1*time)+I(x2*time))
>
> I sugest try this ...
>
> I hope this help you ...
>
> If is solve your problem put solution in list to help other people
> -- 
> Bernardo Rangel Tura, M.D, PhD
> National Institute of Cardiolgy
> Rio de Janeiro - Brasil
>
>


From gchappi at gmail.com  Sun Jun 17 14:14:28 2007
From: gchappi at gmail.com (Hans-Peter)
Date: Sun, 17 Jun 2007 05:14:28 -0700
Subject: [R] problem with xlsReadWrite package
In-Reply-To: <10008503.55221181555903938.JavaMail.www@wwinf4002>
References: <10008503.55221181555903938.JavaMail.www@wwinf4002>
Message-ID: <47fce0650706170514o394ec632l1bd403d5da028202@mail.gmail.com>

Hi,

2007/6/11, hassen62 at voila.fr <hassen62 at voila.fr>:
> I have installed R 2.4.0 in my pc. I have a file xls entitled dali following this directory:c://programfiles//R 2.4.0. Recently I have installed xlsreadwrite 1.3.2. but , when I wrote the following lines:
> >library(xlsReadWrite)
> >read.xls( file, colNames = TRUE, sheet = 1, type = "data.frame",  from = 1, colClasses = NA )
> I obtained from R console the following messages:
> Error in library(xlsReadWrite)
> impossible to find the function"read.xls".

xlsReadWrite 1.3.2 and 1.3.3 won't work with R2.4.0. They need R2.4.1 at least.
Unfortunately xlsReadWrite 1.3.2 didn't check this requirement
properly, but v1.3.3 does. IIRC (I am not in my office right now) the
reason for it is the argument: "stringsAsFactors =
default.stringsAsFactors()".

You have 2 options:
- use R version 2.4.1 or 2.5.0.
- download the package in source form, remove the
default.stringsAsFactors() part and build the binary package from this
modified source.

BTW, according to the posting guide you should have contacted the
maintainer (me) first before posting to R-help. But I didn't get an
email from you...

Hope this helps and best regards,
Hans-Peter


From Bill.Venables at csiro.au  Sun Jun 17 14:29:26 2007
From: Bill.Venables at csiro.au (Bill.Venables at csiro.au)
Date: Sun, 17 Jun 2007 22:29:26 +1000
Subject: [R] correlation comparison one more time
References: <mailman.7.1182074404.9166.r-help@stat.math.ethz.ch>
	<46750AB3.3060307@kul.lublin.pl>
Message-ID: <B998A44C8986644EA8029CFE6396A924B67DDA@exqld2-bne.nexus.csiro.au>

Hypothesis tests are normally set up to test a null hypothesis within a broader class of alternatives, which includes the null as a special case.  Roughly speaking the logic is

"We assume that the outer class includes the truth. We have a simple special case of this we call the null hypothesis that in some sense represents 'no effect'. Does the data provide cogent evidence that the special case is not adequate?"

A standard way to address this question is, for example, to maximise the likelihood under null and alternative and to use the difference in log likelihood as the basis of a test statistic known as the likelihood ratio.

The way you have set up your hypotheses does not match this paradigm.  Your hypothesis is, in essence, that the squared correlation between A and D is larger than any other squared correlation involving two different variables, which include A or D.

It is clear enough what you are asking, but since it doesn't match the standard paradigm it is unlilely that any standard procedure will be available to address it.  It is unclear, for example, how you might go about setting up a likelihood ratio test. 

I think the answer to your question is "no", not off the shelf at least, and you probably need to think about the problem in the null and alternative hypothesis framework to make progress.

Bill Venables
CSIRO Laboratories
PO Box 120, Cleveland, 4163
AUSTRALIA
Office Phone (email preferred): +61 7 3826 7251
Fax (if absolutely necessary):  +61 7 3826 7304
Mobile:                                      (I don't have one!)
Home Phone:                             +61 7 3286 7700
mailto:Bill.Venables at csiro.au
http://www.cmis.csiro.au/bill.venables/ 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of rafael
Sent: Sunday, 17 June 2007 8:20 PM
To: r-help at stat.math.ethz.ch
Subject: [R] correlation comparison one more time

I would like ask again,
because I cant find the answer

I have such problem:

My data containing 4 variables (A,B,C,D) and are completed from 4 samples.
Each of matrix is such:
        A   B   C   D
A     1   ab   ac   ad
B     ab  1    bc   bd  
C     ac   bc   1   cd
D     ad   bd   cd   1

My hypothesis are that

ad is the strongest correlation for A and for D (sign doesn't matter)
bc is the strongest correlation for B and for C (sign doesn't matter)

across samples.

Is it possible test these hypothesis?

Any help would be appreciated

Rafa? Bartczuk
bartczuk at kul.lublin.pl

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From gavin.simpson at ucl.ac.uk  Sun Jun 17 14:47:49 2007
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Sun, 17 Jun 2007 13:47:49 +0100
Subject: [R] Efficiently calculate sd on an array?
Message-ID: <1182084469.3012.19.camel@dhcppc2.my.nat.localnet>

Dear list,

Consider the following problem:

n.obs <- 167
n.boot <- 100
arr <- array(runif(n.obs*n.obs*n.boot), dim = c(n.obs, n.obs, n.boot))
arr[sample(n.obs, 3), sample(n.obs, 3), ] <- NA

Given the array arr, with dims = 167*167*100, I would like to calculate
the sd of the values in the 3rd dimension of arr, and an obvious way to
do this is via apply():

system.time(res <- apply(arr, c(2,1), sd, na.rm = TRUE))

This takes over 4 seconds on my desktop.

I have found an efficient way to calculate the means of the 3rd
dimension using

temp <- t(rowMeans(arr, na.rm = TRUE, dims = 2))

instead of

temp <- apply(arr, c(2,1), mean, na.rm = TRUE)

but I am having difficulty seeing how to calculate the standard
deviations efficiently.

Any idea how I might go about this?

All the best,

G
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [t] +44 (0)20 7679 0522
ECRC                              [f] +44 (0)20 7679 0565
UCL Department of Geography
Pearson Building                  [e] gavin.simpsonATNOSPAMucl.ac.uk
Gower Street
London, UK                        [w] http://www.ucl.ac.uk/~ucfagls/
WC1E 6BT                          [w] http://www.freshwaters.org.uk/
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From kamalak.9 at gmail.com  Sun Jun 17 15:51:15 2007
From: kamalak.9 at gmail.com (K KAMALA)
Date: Sun, 17 Jun 2007 19:21:15 +0530
Subject: [R] (no subject)
Message-ID: <b28243e80706170651q56866d22l9906c51a062f5c4c@mail.gmail.com>

Sir/Mam,

I have installed R in LINUX PC and I'm trying to run the code. It is
showing the error as
Error in library(sm) : There is no package called 'sm'

How to install SM library in R-2.5.0?
Can you please me.

Kamala

-


From abr-r-project at xylon.de  Sun Jun 17 15:56:47 2007
From: abr-r-project at xylon.de (Arne Brutschy)
Date: Sun, 17 Jun 2007 15:56:47 +0200
Subject: [R] Visualize quartiles of plot line
In-Reply-To: <f8e6ff050706170151n9706361k8ff68042ed86a615@mail.gmail.com>
References: <699125298.20070616105514@xylon.de>
	<f8e6ff050706160315r325ec00eua9b14eb87152db71@mail.gmail.com>
	<555253635.20070617092257@xylon.de>
	<f8e6ff050706170151n9706361k8ff68042ed86a615@mail.gmail.com>
Message-ID: <621925589.20070617155647@xylon.de>

Hi,

thanks for your tips - all of them worked. After a bit of fiddling, I
managed to get what I wanted.

hadley wickham wrote:
h> You might want to read the introductory chapters in the ggplot book,
h> available from http://had.co.nz/ggplot2, which will give you more of a
h> background.  Please let me know places where you think the
h> documentation is inconsistent so I can try and make them better.
I already did. :) A general problem: the examples are nice and easy to
get, but it's often hard to apply them to my own specific problem.
It's more a problem of the general structure: what has to go where.
Most of the methods are using qplot, but what do I have to do if I'm
trying create a more complex plot. Hmm, it's hard to describe.

Example: I know how I set the title when using qplot (qplot(....
main="asdf"). Where do I have to put it when I'm using gplot? Stuff
like this is unclear...

A more general problem is, that the manual pages are very, eh,
minimalistic documented. The overall reference page is good and nicely
structured. But the big idea is sort of missing. All components are
linked, but the basics like layout, ggplot, aes etc are harder to find
- and their help pages are the shortest. Especially the small details
are hard to figure out. Lists of attributes etc..

Hmm, I know this is not really helpful. I can't describe my problems
properly, I guess. Perhaps the documentation simply has to improve
based on users questions. :\

How old is this package? I think it's really, really great, but are
there many users? Is there an additional mailinglist or forum where I
can get more information?

Some more questions:

Why doesn't ggplot2 work with layout()? I'm using viewport now, which
works fine for me, but there should be a note in the docs perhaps.

How do I change the legend. The auto-creation of it might be nice,
but I want a) to add a title b) change the order to ascending and c)
add a short description like:

  DeltaConfig
  [ ] 0 best
  [ ]
  [ ] 5
  [ ]
  [ ]10 worst

I don't know if this is possible, but it would be nice to explain what
the colors/values might mean if it's not clear from the beginning
(ligke diamonds.size). The only thing I found was the attribute
legend.justifcation in ggopt, which isn't fully documented.

Additionally, how can I change the order of the facets? I currently
have a plot with a smoother for each model (all in the same plot),
which sorts the models like this: dyn,dl4,dl3 Below that, I have a
facet with point-plots for each model which sorts them the other way
round, which is a bit confusing.

BTW, what's the "strip" and the associated attributes?

Again, I think this package is great - nice work! All the above isn't
meant as general critisism, but is being said in order to improve the
documentation..

Thanks in advance
Arne


From s.wood at bath.ac.uk  Sun Jun 17 15:41:41 2007
From: s.wood at bath.ac.uk (Simon Wood)
Date: Sun, 17 Jun 2007 14:41:41 +0100
Subject: [R] GLM dist Gamma-links identity and inverse
In-Reply-To: <BAY110-W168254FE5CD5109E68A9FCC91D0@phx.gbl>
References: <BAY110-W168254FE5CD5109E68A9FCC91D0@phx.gbl>
Message-ID: <200706171441.41280.s.wood@bath.ac.uk>

If the linear predictor of the GLM becomes negative during fitting, then the 
corresponding fitted values (expected value of response according to model), 
will be negative if you use inverse or identity links. This is problematic, 
since a Gamma r.v. can not be negative, let alone have a negative mean. The 
upshot is that when the model deviance is calculated there are negative logs 
to evaluate, which is the likely cause of the error. 

If you use a log link then -ve linear predictor still implies strictly 
positive fitted values, and everything is fine.

Simon


On Saturday 16 June 2007 20:42, laran gines wrote:
> Dear users;
>
> I am doing GLMs with the Gamma distribution, and I always get errors ("no
> valid set of coefficients: please supply starting values") or warnings
> ("NaNs produced in log(x)") when I use the links identity or inverse, but I
> don?t get them if I use the log link.
>
> For example:
> > summary(step(glm(formula=acin.x~Canais+Hetero+Indrel+Penetra+Ph2o+Pmatorg
> >+Vasa+Aguasup+Prof+Conchdisp+Conchaglom+Ostdisp+Ostaglom+
>
> Rugos+distcanais+distcosta+distsalina+disturbano+distsapal+cota,family=Gamm
>a(link="inverse"))))Start:  AIC=9.18acin.x ~ Canais + Hetero + Indrel +
> Penetra + Ph2o + Pmatorg +     Vasa + Aguasup + Prof + Conchdisp +
> Conchaglom + Ostdisp +     Ostaglom + Rugos + distcanais + distcosta +
> distsalina +     disturbano + distsapal + cota Error: no valid set of
> coefficients has been found: please supply starting valuesIn addition:
> Warning message:NaNs produced in: log(x)
>
> I am doing this to twelve species and I always get the errors with links
> identity and inverse, and never with log link.
>
> Could someone give me an explanation about what is happening?
>
> Thank you very much in advance!
>
> Best wishes;
>
> Catarina
> _________________________________________________________________
> Receba GR?TIS as mensagens do Messenger no seu celular quando voc?
> estiver offline. Conhe?a  o MSN Mobile!
>
> 	[[alternative HTML version deleted]]

-- 
> Simon Wood, Mathematical Sciences, University of Bath, Bath, BA2 7AY UK
> +44 1225 386603  www.maths.bath.ac.uk/~sw283


From ligges at statistik.uni-dortmund.de  Sun Jun 17 16:32:13 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 17 Jun 2007 16:32:13 +0200
Subject: [R] (no subject)
In-Reply-To: <b28243e80706170651q56866d22l9906c51a062f5c4c@mail.gmail.com>
References: <b28243e80706170651q56866d22l9906c51a062f5c4c@mail.gmail.com>
Message-ID: <467545ED.6070107@statistik.uni-dortmund.de>

PLEASE do read the posting guide http://www.R-project.org/posting-guide.html

It tells you to read the manuals *before* posting.

There is a manual "An Introduction to R" and anotehr one called "R 
Installation and Administration", both telling you how to install packages.

Uwe Ligges


K KAMALA wrote:
> Sir/Mam,
> 
> I have installed R in LINUX PC and I'm trying to run the code. It is
> showing the error as
> Error in library(sm) : There is no package called 'sm'
> 
> How to install SM library in R-2.5.0?
> Can you please me.
> 
> Kamala
> 
> -
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From f.harrell at vanderbilt.edu  Sun Jun 17 16:38:39 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Sun, 17 Jun 2007 09:38:39 -0500
Subject: [R] error bars on survival curve
In-Reply-To: <8d6f66050706162118v31d129bbudbd0aaf6acfa8b77@mail.gmail.com>
References: <8d6f66050706162118v31d129bbudbd0aaf6acfa8b77@mail.gmail.com>
Message-ID: <4675476F.3010906@vanderbilt.edu>

Murray Pung wrote:
> I am using plot(survfit(Surv(time,status) ~...) and would like to add
> error bars rather than the confidence intervals. Am I able to do this
> at specified times? e.g. when time = 20 & 40.
> 
> 
> leukemia.surv <- survfit(Surv(time, status) ~ x, data = aml)
> plot(leukemia.surv, lty = 2:3,xlim = c(0,50))
> #can i add error bars at times 20 & 40?
> legend(100, .9, c("Maintenance", "No Maintenance"), lty = 2:3)
> 
> 
> Thanks
> Murray

Error bars when done correctly should equal confidence intervals in the 
minds of many.

When the Design package is available again for the latest version of R, 
you can have more control using the survplot function, with bars and 
bands options.  Do ?survplot.survfit

Frank

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From lobry at biomserv.univ-lyon1.fr  Sun Jun 17 18:19:41 2007
From: lobry at biomserv.univ-lyon1.fr (Jean lobry)
Date: Sun, 17 Jun 2007 18:19:41 +0200
Subject: [R] clustalW
In-Reply-To: <mailman.13.1181988006.1116.r-help@stat.math.ethz.ch>
References: <mailman.13.1181988006.1116.r-help@stat.math.ethz.ch>
Message-ID: <p06002023c29b0d2da560@[134.214.233.117]>

>  Hello,
>
>  I try to make directly with R a multiple alignment querying CLUSTAL W,
>  do you know how can I do this?
>
>  Thanks
>
>  J?r?my Mazet

See ?system on how to run an external program. There is an example
in the reverse.align() function from the seqinR package in which clustalW
can be run on the fly to align CDS at the amino-acid level:
http://pbil.univ-lyon1.fr/software/SeqinR/SEQINR_CRAN/DOC/html/reverse.align.html

HTH,
-- 
Jean R. Lobry            (lobry at biomserv.univ-lyon1.fr)
Laboratoire BBE-CNRS-UMR-5558, Univ. C. Bernard - LYON I,
43 Bd 11/11/1918, F-69622 VILLEURBANNE CEDEX, FRANCE
allo  : +33 472 43 27 56     fax    : +33 472 43 13 88
http://pbil.univ-lyon1.fr/members/lobry/


From cberry at tajo.ucsd.edu  Sun Jun 17 18:56:31 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Sun, 17 Jun 2007 09:56:31 -0700
Subject: [R] Efficiently calculate sd on an array?
In-Reply-To: <1182084469.3012.19.camel@dhcppc2.my.nat.localnet>
References: <1182084469.3012.19.camel@dhcppc2.my.nat.localnet>
Message-ID: <Pine.LNX.4.64.0706170941220.8421@tajo.ucsd.edu>

On Sun, 17 Jun 2007, Gavin Simpson wrote:

> Dear list,
>
> Consider the following problem:
>
> n.obs <- 167
> n.boot <- 100
> arr <- array(runif(n.obs*n.obs*n.boot), dim = c(n.obs, n.obs, n.boot))
> arr[sample(n.obs, 3), sample(n.obs, 3), ] <- NA
>
> Given the array arr, with dims = 167*167*100, I would like to calculate
> the sd of the values in the 3rd dimension of arr, and an obvious way to
> do this is via apply():
>
> system.time(res <- apply(arr, c(2,1), sd, na.rm = TRUE))
>
> This takes over 4 seconds on my desktop.
>
> I have found an efficient way to calculate the means of the 3rd
> dimension using
>
> temp <- t(rowMeans(arr, na.rm = TRUE, dims = 2))
>
> instead of
>
> temp <- apply(arr, c(2,1), mean, na.rm = TRUE)
>
> but I am having difficulty seeing how to calculate the standard
> deviations efficiently.
>
> Any idea how I might go about this?

Here are timings on my system:

> system.time(res <- apply(arr, c(2,1), sd, na.rm = TRUE))
    user  system elapsed
    3.49    0.00    3.52
> system.time(res2 <- {
+   ns <- rowSums(!is.na(arr),dim=2)
+   mns <- as.vector(rowMeans(arr, na.rm = TRUE, dims = 2))
+   sds <- t(sqrt(rowSums( (arr- mns )^2,na.rm=T,dims=2)/as.vector(ns-1)))
+   sds[t(ns)==0] <- NA
+   sds})
    user  system elapsed
    0.36    0.02    0.37
> all.equal(res,res2)
[1] TRUE
>

HTH,

Chuck

>
> All the best,
>
> G
> -- 
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> Gavin Simpson                     [t] +44 (0)20 7679 0522
> ECRC                              [f] +44 (0)20 7679 0565
> UCL Department of Geography
> Pearson Building                  [e] gavin.simpsonATNOSPAMucl.ac.uk
> Gower Street
> London, UK                        [w] http://www.ucl.ac.uk/~ucfagls/
> WC1E 6BT                          [w] http://www.freshwaters.org.uk/
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	            UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901


From adschai at optonline.net  Sun Jun 17 19:29:07 2007
From: adschai at optonline.net (adschai at optonline.net)
Date: Sun, 17 Jun 2007 17:29:07 +0000 (GMT)
Subject: [R] [Not R question]: Better fit for order probit model
In-Reply-To: <0JJQ00D91HBS55B4@vms044.mailsrvcs.net>
References: <e2a29c0889f4.46733d60@optonline.net>
	<0JJP007MLJXIS3N3@vms042.mailsrvcs.net>
	<e426e6d0d3af.46738e9f@optonline.net>
	<0JJQ00D91HBS55B4@vms044.mailsrvcs.net>
Message-ID: <e46e9d2413a88.46756f63@optonline.net>

Thank you so much Robert. Please find the information below. 

The scale 1-10 are subjective physical condition ratings scored by inspection engineers at the site. 1-5 are in very bad conditions (bridge close down to seriously deteriorated). The rest from 6-10 are categorized as good condition.However, the proportion of samples in my data are as follows. Bridges with 1-5 scale covers about 2-3% of total population. The majority of the bridges are in 7-8. Certainly, I have enough data for model estimation but the mix of the proportion is good. I attached the detail of condition rating scale at the end of this message.

As a result, my ordered probit model yield cutting points that cannot capture level 1-5 well. Even in my in-sample population, the model cannot capture level 2-5 at all. In other words, with the estimated cutting points for level 1-5, I have zero bridges that belong to level 2-5. Unfortunately, my objective is especially to analyze statistically what kind of design attributes lead to such a bad condition. So I would like my model to be able to capture bad condition bridges as much as it could.


9                  EXCELLENT CONDITION

8                  VERY GOOD CONDITION - no problems noted.

7                  GOOD CONDITION - some minor problems.

6                  SATISFACTORY CONDITION - structural elements show some minor deterioration.

5                  FAIR CONDITION - all primary structural elements are sound but may have minor section loss, cracking, 
                    spalling or scour.

4                  POOR CONDITION - advanced section loss, deterioration, spalling or scour.

3                  SERIOUS CONDITION - loss of section, deterioration of primary structural elements.  Fatigue cracks 
                    in steel or shear cracks in concrete may be present.

2                  CRITICAL CONDITION - advanced deterioration of primary structural elements.  Fatigue cracks in steel 
                    or shear cracks in concrete may be present or scour may have removed substructure support.  Unless 
                    closely monitored it may be necessary to close the bridge until corrective action is taken.

1                  "IMMINANT" FAILURE CONDITION - major deterioration or section loss present in critical sructural 
                    components or obvious vertical or horizontal movement affecting structure stability.  Bridge is 
                    closed to traffic but corrective action may put it back in light service.

0                  FAILED CONDITION - out of service; beyond corrective action.


----- Original Message -----From: Robert A LaBudde Date: Saturday, June 16, 2007 9:59 amSubject: Re: [R] [Not R question]: Better fit for order probit modelTo: R-help at stat.math.ethz.ch> At 03:17 AM 6/16/2007, adschai wrote:> >Thank you so much Robert. I haven't thought about the idea of > >clumping categories together. One of the reason is because > these > >categories are bridge condition rating scores. They indeed > represent > >different meaning and serviceability conditions. They vary from > 0-9. > >I have about 300,000 data in which the first 5 labels, i.e. 0-> 4, are > >bad condition bridge and there are only less than 1000 > instances in > >total. The worst case, is for example, score 0 (meaning the > bridge > >is not operatable), I have 60 instances. Score 1 I have about 100.> >> >I would appreciate if you could provide some opinion as to how > you > >would make the order probit fits better in this case? Thank you > so > >much in advance.> > You certainly appear to have enough data to populate these > categories. Your problems in a getting a good fit may relate to > other problems.> > You need to supply more information in order to say more.> > What are the definitions of each category?> > Is the ordering consistent, or are there really two different > scales, > one for bridge with essentially no problems, and another for > those > with serious damage?> > What evidence do you have that your fit is poor?> > What model are you fitting?> > Etc.> > ================================================================> Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com> Least Cost Formulations, Ltd.            URL: http://lcfltd.com/> 824 Timberlake Drive                     Tel: 757-467-0954> Virginia Beach, VA 23464-3239            Fax: 757-467-2947> > "Vere scire est per causas scire"> > ______________________________________________> R-help at stat.math.ethz.ch mailing list> https://stat.ethz.ch/mailman/listinfo/r-help> PLEASE do read the posting guide http://www.R-> project.org/posting-guide.html> and provide commented, minimal, self-contained, reproducible code.>


From graham.leask at btopenworld.com  Sun Jun 17 17:00:24 2007
From: graham.leask at btopenworld.com (Graham Leask)
Date: Sun, 17 Jun 2007 16:00:24 +0100
Subject: [R] Cluster validation
Message-ID: <001001c7b0f0$3d973db0$590a8351@home>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070617/492f074e/attachment.pl 

From RONVIRAMONTES at AOL.COM  Sun Jun 17 20:08:51 2007
From: RONVIRAMONTES at AOL.COM (RonV)
Date: Sun, 17 Jun 2007 11:08:51 -0700 (PDT)
Subject: [R] standard error of skewness
In-Reply-To: <10970956.post@talk.nabble.com>
References: <10970956.post@talk.nabble.com>
Message-ID: <11165547.post@talk.nabble.com>


I found this this link that might help.
http://www.gbstat.com/macintosh/mac-new.html 

livia wrote:
> 
> Hi, 
> 
> I just wonder how can I calculate the standard error of skewness?
> Basiclly, I would like to test whether it is too skewed or not?
> 
> Many thanks
> 

-- 
View this message in context: http://www.nabble.com/standard-error-of-skewness-tf3872201.html#a11165547
Sent from the R help mailing list archive at Nabble.com.


From ral at lcfltd.com  Sun Jun 17 22:12:43 2007
From: ral at lcfltd.com (Robert A LaBudde)
Date: Sun, 17 Jun 2007 16:12:43 -0400
Subject: [R] [Not R question]: Better fit for order probit model
In-Reply-To: <e46e9d2413a88.46756f63@optonline.net>
References: <e2a29c0889f4.46733d60@optonline.net>
	<0JJP007MLJXIS3N3@vms042.mailsrvcs.net>
	<e426e6d0d3af.46738e9f@optonline.net>
	<0JJQ00D91HBS55B4@vms044.mailsrvcs.net>
	<e46e9d2413a88.46756f63@optonline.net>
Message-ID: <0JJS00BNIQTA4S73@vms048.mailsrvcs.net>

At 01:29 PM 6/17/2007, adschai wrote:
>Thank you so much Robert. Please find the information below.
>
>The scale 1-10 are subjective physical condition ratings scored by 
>inspection engineers at the site. 1-5 are in very bad conditions 
>(bridge close down to seriously deteriorated). The rest from 6-10 
>are categorized as good condition.However, the proportion of samples 
>in my data are as follows. Bridges with 1-5 scale covers about 2-3% 
>of total population. The majority of the bridges are in 7-8. 
>Certainly, I have enough data for model estimation but the mix of 
>the proportion is good. I attached the detail of condition rating 
>scale at the end of this message.
><snip>

My guess is that you really have two distributions here: 1) Bridges 
that are basically under proper supervision and repair (Categories 
6-10), and those that are not Categories 1-5). These two classes 
would probably have dramatically different relations to the 
covariates your are using.

So my recommendation would be to consider splitting your response 
into two classes (0/1), each with 5 sub categories.

Keeping the two classes merged together in a single group is 
equivalent to merging two different distributions with a weighting 
factor. This may be causing a bimodal distribution which is giving 
you problems.

You could try your modeling on each of the two classes separately 
before continuing with your full dataset modeling. You may learn 
something useful to help you with your problems.

For the full model, you would need to include a full set of 
interaction terms with "class".
================================================================
Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
824 Timberlake Drive                     Tel: 757-467-0954
Virginia Beach, VA 23464-3239            Fax: 757-467-2947

"Vere scire est per causas scire"


From economics.guy at gmail.com  Sun Jun 17 22:46:27 2007
From: economics.guy at gmail.com (Economics Guy)
Date: Sun, 17 Jun 2007 16:46:27 -0400
Subject: [R] Storing output vector form a loop as a matrix
Message-ID: <da0aac0706171346t4e1b8181k6d071d8fdaac16d3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070617/70631fda/attachment.pl 

From mothsailor at googlemail.com  Mon Jun 18 00:05:22 2007
From: mothsailor at googlemail.com (David Barron)
Date: Sun, 17 Jun 2007 23:05:22 +0100
Subject: [R] Storing output vector form a loop as a matrix
In-Reply-To: <da0aac0706171346t4e1b8181k6d071d8fdaac16d3@mail.gmail.com>
References: <da0aac0706171346t4e1b8181k6d071d8fdaac16d3@mail.gmail.com>
Message-ID: <815b70590706171505m25966f5x5fb2d87e2102b12f@mail.gmail.com>

I'm not sure I've completely understood this, but would this do what you want:


for (i in 1:N){

aa <- sample(a, replace=TRUE)

c <-data.frame(b,aa)

output <- by(c, aa, function(x) sum(x$b))

output.matrix[,i] <- as.vector(output)
}



On 17/06/07, Economics Guy <economics.guy at gmail.com> wrote:
> Based on help files and searching the archives and help from the listserv I
> have managed to build my monte carlo program.
>
> However I cannot get the proper syntax for running the loop and storing the
> output of each loop (which is a vector) into a matrix.
>
> I took out some of the crazy code I was writing, but here is what I have:
>
> --------------------
>
> rm(list = ls(all = TRUE))
> # removes everything
>
> a <-c("A","C","B","A","B","C")
>
> b <-c(10,20,30,40,50,60)
>
> c <-data.frame(a,b)
>
> N=10 #Number of Loops
>
> output.matrix <- matrix(0.0,3,N)
>
> #I need to START LOOP HERE
>
> a <- sample(a, replace=TRUE)
>
> c <-data.frame(b,a)
>
> output.vector <- by(c, a, function(x) sum(x$b))
>
> output.vector <- as.vector(output)
>
> output.vector <- data.frame(output)
>
> #END LOOP here
>
>
> --------------------------
>
> What I would like to have at the end is the "output.matrix" contain as a
> column the  "output.vector" from  each iteration. The actual data frame I
> will be running has 60,000 observations and I am going to run 20000
> iterations so speed is important too.
>
> Thanks so much
>
> EG
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
=================================
David Barron
Said Business School
University of Oxford
Park End Street
Oxford OX1 1HP


From mlwynn at indiana.edu  Mon Jun 18 00:10:20 2007
From: mlwynn at indiana.edu (Michelle Wynn)
Date: Sun, 17 Jun 2007 15:10:20 -0700
Subject: [R] data.frame and subsetting problem
In-Reply-To: <p06240802c29a18a67d70@192.168.11.7>
References: <958ce7730706161215o3420ce38y1e4ac44a05bd2ca0@mail.gmail.com>
	<p06240802c29a18a67d70@192.168.11.7>
Message-ID: <958ce7730706171510u67e224cr791e4a3c6651098e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070617/89c6c78c/attachment.pl 

From economics.guy at gmail.com  Mon Jun 18 01:05:26 2007
From: economics.guy at gmail.com (Economics Guy)
Date: Sun, 17 Jun 2007 19:05:26 -0400
Subject: [R] Storing output vector form a loop as a matrix
In-Reply-To: <815b70590706171505m25966f5x5fb2d87e2102b12f@mail.gmail.com>
References: <da0aac0706171346t4e1b8181k6d071d8fdaac16d3@mail.gmail.com>
	<815b70590706171505m25966f5x5fb2d87e2102b12f@mail.gmail.com>
Message-ID: <da0aac0706171605i2572e107v22b68684cebc01a1@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070617/06d58d9b/attachment.pl 

From jholtman at gmail.com  Mon Jun 18 01:42:18 2007
From: jholtman at gmail.com (jim holtman)
Date: Sun, 17 Jun 2007 19:42:18 -0400
Subject: [R] Storing output vector form a loop as a matrix
In-Reply-To: <da0aac0706171346t4e1b8181k6d071d8fdaac16d3@mail.gmail.com>
References: <da0aac0706171346t4e1b8181k6d071d8fdaac16d3@mail.gmail.com>
Message-ID: <644e1f320706171642l516022bfxf45a0d8a7f4ab4e6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070617/2816293f/attachment.pl 

From michael_bibo at health.qld.gov.au  Mon Jun 18 02:32:33 2007
From: michael_bibo at health.qld.gov.au (Michael Bibo)
Date: Mon, 18 Jun 2007 00:32:33 +0000 (UTC)
Subject: [R] Responding to a posting in the digest
References: <65657.87483.qm@web32215.mail.mud.yahoo.com>
Message-ID: <loom.20070618T022934-455@post.gmane.org>

Moshe Olshansky <m_olshansky <at> yahoo.com> writes:

> 
> Is there a convenient way to respond to a particular
> posting which is a part of the digest?  
> I mean something that will automatically quote the
> original message, subject, etc.
> 
> Thank you!
> 
> Moshe Olshansky
> m_olshansky <at> yahoo.com
> 
> ______________________________________________
> R-help <at> stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

A simple solution is to respond via the Gmane (web) list.  There is a link to 
the Gmane R lists from the 'search' page of any CRAN mirror.

Hope this helps,

Michael Bibo
michael_bibo at health.qld.gov.au


From economics.guy at gmail.com  Mon Jun 18 05:26:27 2007
From: economics.guy at gmail.com (Economics Guy)
Date: Sun, 17 Jun 2007 23:26:27 -0400
Subject: [R] Storing output vector form a loop as a matrix
In-Reply-To: <644e1f320706171642l516022bfxf45a0d8a7f4ab4e6@mail.gmail.com>
References: <da0aac0706171346t4e1b8181k6d071d8fdaac16d3@mail.gmail.com>
	<644e1f320706171642l516022bfxf45a0d8a7f4ab4e6@mail.gmail.com>
Message-ID: <da0aac0706172026ga427b02yd886a12b2f0a23a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070617/67141fb5/attachment.pl 

From yee at post.harvard.edu  Mon Jun 18 05:38:29 2007
From: yee at post.harvard.edu (Andrew Yee)
Date: Sun, 17 Jun 2007 23:38:29 -0400
Subject: [R] getting tapply() to work across multiple columns
Message-ID: <5dff5a0d0706172038l2b05045em1da327dfc780db33@mail.gmail.com>

I have the following data.frame:

index <- c("a","a","b","b","b")
alpha <- c(1,2,3,4,5)
beta <- c(2,3,4,5,6)
table <-data.frame(index,alpha,beta)

I'm now interested in getting means of alpha and beta for each of the
index values and do a tapply() for each of the columns, e.g.

means.alpha <- tapply(table$alpha, index,mean)
means.beta <- tapply(table$beta,index,mean)

but as one tapply function, something like

tapply(table[2:3], index, mean), but this clearly doesnt' work.

Suggestions?

Thanks,
Andrew


From ggrothendieck at gmail.com  Mon Jun 18 05:49:44 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 17 Jun 2007 23:49:44 -0400
Subject: [R] getting tapply() to work across multiple columns
In-Reply-To: <5dff5a0d0706172038l2b05045em1da327dfc780db33@mail.gmail.com>
References: <5dff5a0d0706172038l2b05045em1da327dfc780db33@mail.gmail.com>
Message-ID: <971536df0706172049h58937188r6639a5e9321a99d1@mail.gmail.com>

Try aggregate:

aggregate(table[2:3], table[1], mean)


On 6/17/07, Andrew Yee <yee at post.harvard.edu> wrote:
> I have the following data.frame:
>
> index <- c("a","a","b","b","b")
> alpha <- c(1,2,3,4,5)
> beta <- c(2,3,4,5,6)
> table <-data.frame(index,alpha,beta)
>
> I'm now interested in getting means of alpha and beta for each of the
> index values and do a tapply() for each of the columns, e.g.
>
> means.alpha <- tapply(table$alpha, index,mean)
> means.beta <- tapply(table$beta,index,mean)
>
> but as one tapply function, something like
>
> tapply(table[2:3], index, mean), but this clearly doesnt' work.
>
> Suggestions?
>
> Thanks,
> Andrew
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From adik at ilovebacon.org  Mon Jun 18 06:30:58 2007
From: adik at ilovebacon.org (Adam D. I. Kramer)
Date: Sun, 17 Jun 2007 21:30:58 -0700 (PDT)
Subject: [R] Automatic paren/bracket closing in 2.5.0?
Message-ID: <Pine.LNX.4.64.0706172128430.13670@parser.ilovebacon.org>

Hello,

 	Just upgraded to 2.5.0, and found that R now includes an rparen
(right parentheses) or rbracket whenever I enter in an lparen. While I can
see the use of this function, it doesn't mesh well with my personal style of
using R (e.g., using the up arrow, adding an rparen, jumping to the
beginning of the line, and then wrapping a summary, for instance).

Some 10 minutes of google searching has failed to come up with a solution
for turning this feature off--any suggestions from the list?

Cordially,
Adam Kramer
University of Oregon


From keisyu at gmail.com  Mon Jun 18 06:37:37 2007
From: keisyu at gmail.com (ebi)
Date: Mon, 18 Jun 2007 13:37:37 +0900
Subject: [R] the way to look at all the codings of any functions
Message-ID: <ed0fd0110706172137h2acb9fdahe0111bcd655ca529@mail.gmail.com>

Dear SIr,


In case of looking at the codes of the fuction, "cov",

we find all the codings below.  But, incase of "mean", we don't find
the contents.

Please show me the way to look at all the codings of any functions.

Best regards,
Kei
-----------------------

> cov
function (x, y = NULL, use = "all.obs", method = c("pearson",
    "kendall", "spearman"))
{
    na.method <- pmatch(use, c("all.obs", "complete.obs",
"pairwise.complete.obs"))
    method <- match.arg(method)
    if (is.data.frame(y))
        y <- as.matrix(y)
    else stopifnot(is.atomic(y))
    if (is.data.frame(x))
        x <- as.matrix(x)
    else {
        stopifnot(is.atomic(x))
        if (!is.matrix(x)) {
            if (is.null(y))
                stop("supply both 'x' and 'y' or a matrix-like 'x'")
            x <- as.vector(x)
        }
    }
    if (method == "pearson")
        .Internal(cov(x, y, na.method, method == "kendall"))
    else if (na.method != 3) {
        Rank <- function(u) if (is.matrix(u))
            apply(u, 2, rank, na.last = "keep")
        else rank(u, na.last = "keep")
        if (na.method == 2) {
            ok <- complete.cases(x, y)
            x <- if (is.matrix(x))
                x[ok, ]
            else x[ok]
            if (!is.null(y))
                y <- if (is.matrix(y))
                  y[ok, ]
                else y[ok]
        }
        x <- Rank(x)
        if (!is.null(y))
            y <- Rank(y)
        .Internal(cov(x, y, na.method, method == "kendall"))
    }
    else stop("cannot handle 'pairwise.complete.obs'")
}
<environment: namespace:stats>
>
> mean
function (x, ...)
UseMethod("mean")
<environment: namespace:base>


From klaster at karlin.mff.cuni.cz  Mon Jun 18 07:00:15 2007
From: klaster at karlin.mff.cuni.cz (Petr Klasterecky)
Date: Mon, 18 Jun 2007 07:00:15 +0200
Subject: [R] the way to look at all the codings of any functions
In-Reply-To: <ed0fd0110706172137h2acb9fdahe0111bcd655ca529@mail.gmail.com>
References: <ed0fd0110706172137h2acb9fdahe0111bcd655ca529@mail.gmail.com>
Message-ID: <4676115F.4010404@karlin.mff.cuni.cz>

Someone with more experience could certainly provide a more precise 
answer, but basically you came across something called generic functions 
in R. This concept allows mean() to be called on various data structures 
without extra care.

See
?UseMethod
methods(mean)
getAnywhere(mean.default)

For more details see the R language definition manual.

Petr


ebi napsal(a):
> Dear SIr,
> 
> 
> In case of looking at the codes of the fuction, "cov",
> 
> we find all the codings below.  But, incase of "mean", we don't find
> the contents.
> 
> Please show me the way to look at all the codings of any functions.
> 
> Best regards,
> Kei
> -----------------------
> 
>> cov
> function (x, y = NULL, use = "all.obs", method = c("pearson",
>     "kendall", "spearman"))
> {
>     na.method <- pmatch(use, c("all.obs", "complete.obs",
> "pairwise.complete.obs"))
>     method <- match.arg(method)
>     if (is.data.frame(y))
>         y <- as.matrix(y)
>     else stopifnot(is.atomic(y))
>     if (is.data.frame(x))
>         x <- as.matrix(x)
>     else {
>         stopifnot(is.atomic(x))
>         if (!is.matrix(x)) {
>             if (is.null(y))
>                 stop("supply both 'x' and 'y' or a matrix-like 'x'")
>             x <- as.vector(x)
>         }
>     }
>     if (method == "pearson")
>         .Internal(cov(x, y, na.method, method == "kendall"))
>     else if (na.method != 3) {
>         Rank <- function(u) if (is.matrix(u))
>             apply(u, 2, rank, na.last = "keep")
>         else rank(u, na.last = "keep")
>         if (na.method == 2) {
>             ok <- complete.cases(x, y)
>             x <- if (is.matrix(x))
>                 x[ok, ]
>             else x[ok]
>             if (!is.null(y))
>                 y <- if (is.matrix(y))
>                   y[ok, ]
>                 else y[ok]
>         }
>         x <- Rank(x)
>         if (!is.null(y))
>             y <- Rank(y)
>         .Internal(cov(x, y, na.method, method == "kendall"))
>     }
>     else stop("cannot handle 'pairwise.complete.obs'")
> }
> <environment: namespace:stats>
>> mean
> function (x, ...)
> UseMethod("mean")
> <environment: namespace:base>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Petr Klasterecky
Dept. of Probability and Statistics
Charles University in Prague
Czech Republic


From sabya23 at gmail.com  Mon Jun 18 07:42:43 2007
From: sabya23 at gmail.com (spime)
Date: Sun, 17 Jun 2007 22:42:43 -0700 (PDT)
Subject: [R] Loading problem with R2HTML package
Message-ID: <11170223.post@talk.nabble.com>



I have downloaded latest version of R2HTML (v1.54) for 64-bit windows PC. My
R version 2.5.0. My problem arises when i want to install SciViews-R which
need R2HTML package. 


> library(R2HTML)
Error in `parent.env<-`(`*tmp*`, value = NULL) : 
        use of NULL environment is defunct
Error: package/namespace load failed for 'R2HTML'

Any remedy ?

Regards


-- 
View this message in context: http://www.nabble.com/Loading-problem-with-R2HTML-package-tf3938384.html#a11170223
Sent from the R help mailing list archive at Nabble.com.


From megh700004 at yahoo.com  Mon Jun 18 08:37:10 2007
From: megh700004 at yahoo.com (Megh Dal)
Date: Sun, 17 Jun 2007 23:37:10 -0700 (PDT)
Subject: [R] Calculating Percentile in R
Message-ID: <486488.93702.qm@web58102.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070617/d1b25d6d/attachment.pl 

From ripley at stats.ox.ac.uk  Mon Jun 18 08:57:50 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 18 Jun 2007 07:57:50 +0100 (BST)
Subject: [R] Loading problem with R2HTML package
In-Reply-To: <11170223.post@talk.nabble.com>
References: <11170223.post@talk.nabble.com>
Message-ID: <Pine.LNX.4.64.0706180751070.27212@gannet.stats.ox.ac.uk>

On Sun, 17 Jun 2007, spime wrote:

> I have downloaded latest version of R2HTML (v1.54) for 64-bit windows 
> PC.

The latest version is 1.58 from September 2006.  See
http://cran.r-project.org/src/contrib/Descriptions/R2HTML.html

> My R version 2.5.0. My problem arises when i want to install SciViews-R 
> which need R2HTML package.
>
>> library(R2HTML)
> Error in `parent.env<-`(`*tmp*`, value = NULL) :
>        use of NULL environment is defunct
> Error: package/namespace load failed for 'R2HTML'
>
> Any remedy ?

Use the real 'latest version'.  Have you perhaps used a broken 'mirror' of 
CRAN?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From e.catchpole at adfa.edu.au  Mon Jun 18 09:06:29 2007
From: e.catchpole at adfa.edu.au (ecatchpole)
Date: Mon, 18 Jun 2007 17:06:29 +1000
Subject: [R] Calculating Percentile in R
In-Reply-To: <486488.93702.qm@web58102.mail.re3.yahoo.com>
References: <486488.93702.qm@web58102.mail.re3.yahoo.com>
Message-ID: <46762EF5.2010000@adfa.edu.au>

Quantiles aren't uniquely defined. Type

?quantile

to learn more about the various possibilities built in to R.

Ted.

Megh Dal wrote on 06/18/2007 04:37 PM:
> Hi all,
>  
> I have a problem on how R calculates Percentiles :
>  
> Suppose I have following data set:
>   
>> data1
>>     
>   [1] -16648185 -14463457 -14449400 -13905309 -13443436 -13234755 -12956282 -11660896
>   [9] -10061040  -9805005  -9789583  -9754642  -9562164  -9391709  -9212182  -9151073
>  [17]  -9092732  -9068214  -8978151  -8943912  -8761890  -8632106  -8541580  -8501249
>  [25]  -8234466  -8219015  -8193543  -7488279  -7340768  -7236684  -7225458  -7159465
>  [33]  -6819625  -6810858  -6755620  -6626439  -6610901  -6551762  -6207377  -6192583
>  [41]  -6106783  -6077051  -6035300  -6035195  -6019017  -5954375  -5946285  -5886082
>  [49]  -5880402  -5723368  -5668698  -5599168  -5548276  -5445734  -5412312  -5384707
>  [57]  -5309365  -5303425  -5285274  -5204585  -5096301  -5092182  -5053349  -5041533
>  [65]  -5021234  -5005402  -4984232  -4981990  -4964457  -4936653  -4920384  -4918021
>  [73]  -4895351  -4843258  -4824730  -4774792  -4771018  -4616156  -4590430  -4444262
>  [81]  -4443954  -4435397  -4415112  -4374465  -4341858  -4267891  -4252410  -4185021
>  [89]  -4164458  -4158863  -4020436  -4006030  -3975819  -3959667  -3916414  -3876878
>  [97]  -3765340  -3729338  -3713670  -3634991
>
> Now the 5th percentile should be value corresponding to 0.05*(100+1) = 5.05 = 5 (rounded)
>  
> hence : -13443436 
>  
> But R give the value :
>   
>> quantile(data1, 0.05)
>>     
>        5% 
> -13245189 
>  
> Can anyone clarify me on this regards?
>  
> Thanks
> Megh
>
>
>        
> ____________________________________________________________________________________
>
> Comedy with an Edge to see what's on, when. 
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   


-- 
 Dr E.A. Catchpole  
 Visiting Fellow
 Univ of New South Wales at ADFA, Canberra, Australia
    _	  and University of Kent, Canterbury, England
   'v'	  - www.pems.adfa.edu.au/~ecatchpole          
  /   \	  - fax: +61 2 6268 8786		   
   m m    - ph:  +61 2 6268 8895


From ripley at stats.ox.ac.uk  Mon Jun 18 09:12:21 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 18 Jun 2007 08:12:21 +0100 (BST)
Subject: [R] Calculating Percentile in R
In-Reply-To: <486488.93702.qm@web58102.mail.re3.yahoo.com>
References: <486488.93702.qm@web58102.mail.re3.yahoo.com>
Message-ID: <Pine.LNX.4.64.0706180758360.27212@gannet.stats.ox.ac.uk>

On Sun, 17 Jun 2007, Megh Dal wrote:

> Hi all,
>
> I have a problem on how R calculates Percentiles :
>
> Suppose I have following data set:
>> data1
>  [1] -16648185 -14463457 -14449400 -13905309 -13443436 -13234755 -12956282 -11660896
>  [9] -10061040  -9805005  -9789583  -9754642  -9562164  -9391709  -9212182  -9151073
> [17]  -9092732  -9068214  -8978151  -8943912  -8761890  -8632106  -8541580  -8501249
> [25]  -8234466  -8219015  -8193543  -7488279  -7340768  -7236684  -7225458  -7159465
> [33]  -6819625  -6810858  -6755620  -6626439  -6610901  -6551762  -6207377  -6192583
> [41]  -6106783  -6077051  -6035300  -6035195  -6019017  -5954375  -5946285  -5886082
> [49]  -5880402  -5723368  -5668698  -5599168  -5548276  -5445734  -5412312  -5384707
> [57]  -5309365  -5303425  -5285274  -5204585  -5096301  -5092182  -5053349  -5041533
> [65]  -5021234  -5005402  -4984232  -4981990  -4964457  -4936653  -4920384  -4918021
> [73]  -4895351  -4843258  -4824730  -4774792  -4771018  -4616156  -4590430  -4444262
> [81]  -4443954  -4435397  -4415112  -4374465  -4341858  -4267891  -4252410  -4185021
> [89]  -4164458  -4158863  -4020436  -4006030  -3975819  -3959667  -3916414  -3876878
> [97]  -3765340  -3729338  -3713670  -3634991
>
> Now the 5th percentile should be value corresponding to 0.05*(100+1) = 
> 5.05 = 5 (rounded)

According to you, but not according to ?quantile, which gives you a choice 
of 9 definitions, yours not being the default.

> hence : -13443436
>
> But R give the value :
>> quantile(data1, 0.05)
>       5%
> -13245189
>
> Can anyone clarify me on this regards?
>
> Thanks
> Megh
>
>
> 	[[alternative HTML version deleted]]
>
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html

PLEASE do as we ask.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From elyakhlifi_mustapha at yahoo.fr  Mon Jun 18 09:23:36 2007
From: elyakhlifi_mustapha at yahoo.fr (elyakhlifi mustapha)
Date: Mon, 18 Jun 2007 07:23:36 +0000 (GMT)
Subject: [R] to read table
Message-ID: <423553.36736.qm@web27508.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070618/6b77f69d/attachment.pl 

From buser at stat.math.ethz.ch  Mon Jun 18 09:23:26 2007
From: buser at stat.math.ethz.ch (Christoph Buser)
Date: Mon, 18 Jun 2007 09:23:26 +0200
Subject: [R] Lines connecting the boxes in a boxplot
In-Reply-To: <1875718929.20070616103819@xylon.de>
References: <1875718929.20070616103819@xylon.de>
Message-ID: <18038.13038.825501.499460@stat.math.ethz.ch>

Dear Arne

I' recommend to save the information of your boxplots

a <- boxplot(...)
str(a)

Then you have the information that you need about your boxplot
(e.g. the value of the median) and can use segments() to draw
the lines you want.

Hope this helps

Best regards,

Christoph

--------------------------------------------------------------

Credit and Surety PML study: visit our web page www.cs-pml.org

--------------------------------------------------------------
Christoph Buser <buser at stat.math.ethz.ch>
Seminar fuer Statistik, LEO C13
ETH Zurich	8092 Zurich	 SWITZERLAND
phone: x-41-44-632-4673		fax: 632-1228
http://stat.ethz.ch/~buser/
--------------------------------------------------------------


Arne Brutschy writes:
 > Hello,
 > 
 > I'm currently using a boxplot to visualize data for three different
 > models. As I have three models, I'm plotting three parallel boxplots
 > for each factor.
 > 
 > This works fine - what I need now is a line connecting the medians of
 > each boxplot of each model. I want to do this in order to visualize
 > the trend that one of the models exhibit. Basically, I want to plot a
 > curve for each model (slightly offset on the x axis), with a boxplot
 > on each datapoint.
 > 
 > It's only an idea, and I don't know if it's not too confusing after
 > adding the lines... Is it possible? Has anyone done this before?
 > 
 > Sorry if this has been asked before or is a standard feature, I simply
 > have now clue how to name the feature I want. Ergo: I cannot search
 > for it.. :\
 > 
 > Regards,
 > Arne
 > 
 > PS: this is my current code
 > 
 > require(gplots)
 > boxwex=0.15
 > 
 > data <- read.table("all_runs_fitness.data");
 > colnames(data)=c("model","matrix","fitness")
 > 
 > boxplot(fitness ~ matrix,
 >         data=data, boxwex=boxwex, at=(1:7 - 0.2),
 >         main="Fitness for Matrix/Models", xlab="Matrixtype",
 >         ylab="Fitness", ylim=c(20,100), 
 >         subset=(model=="dyn"), col="lightblue", xaxt="n", whisklty=1)
 > boxplot(fitness ~ matrix,
 >         data=data, boxwex=boxwex, at = 1:7, add=TRUE, 
 >         subset=(model=="dl3"), col="mistyrose", xaxt="n", whisklty=1)
 > boxplot(fitness ~ matrix,
 >         data=data, boxwex=boxwex, at=(1:7 + 0.2), add=TRUE, 
 >         subset=(model=="dl4"), col="lightcyan", xaxt="n", whisklty=1)
 > 
 > axis(1, 1:8-0.5, labels=FALSE)
 > axis(1, 1:7, tck=FALSE, labels=levels(data[,2]))
 > 
 > smartlegend(x="left", y="bottom", inset = 0.01,
 >             c("dyn","dl3","dl4"), fill = c("lightblue", "mistyrose", "lightcyan"))
 > 
 > ______________________________________________
 > R-help at stat.math.ethz.ch mailing list
 > https://stat.ethz.ch/mailman/listinfo/r-help
 > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
 > and provide commented, minimal, self-contained, reproducible code.


From elyakhlifi_mustapha at yahoo.fr  Mon Jun 18 09:28:05 2007
From: elyakhlifi_mustapha at yahoo.fr (elyakhlifi mustapha)
Date: Mon, 18 Jun 2007 07:28:05 +0000 (GMT)
Subject: [R] what about options in BATCH
Message-ID: <521381.7469.qm@web27513.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070618/70002442/attachment.pl 

From singularitaet at gmx.net  Mon Jun 18 09:31:52 2007
From: singularitaet at gmx.net (Stefan Grosse)
Date: Mon, 18 Jun 2007 09:31:52 +0200
Subject: [R] to read table
In-Reply-To: <423553.36736.qm@web27508.mail.ukl.yahoo.com>
References: <423553.36736.qm@web27508.mail.ukl.yahoo.com>
Message-ID: <467634E8.5050706@gmx.net>

Why are you not using read.csv or read.csv2 when you are reading a csv file?

-------- Original Message  --------
Subject: [R] to read table
From: elyakhlifi mustapha <elyakhlifi_mustapha at yahoo.fr>
To: R-help at stat.math.ethz.ch
Date: 18.06.2007 09:23
> Hello,
> I have a problem to read a csv table. To read it I used this syntax
>
>   
>> donParCara <- read.table("C:/Documents and Settings/melyakhlifi/Mes documents/feuilles excel/calcul2.csv",header=TRUE,sep=";",quote="",dec=",")
>>     
>
> I don't understand my errors
>
> Erreur dans scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  : 
>         la ligne 16 n'avait pas 21 ?l?ments
>
> Can you help me please?
>
>


From katharina.surovcik at cs.uni-goettingen.de  Mon Jun 18 09:38:56 2007
From: katharina.surovcik at cs.uni-goettingen.de (Katharina Surovcik)
Date: Mon, 18 Jun 2007 09:38:56 +0200
Subject: [R] to read table
In-Reply-To: <423553.36736.qm@web27508.mail.ukl.yahoo.com>
References: <423553.36736.qm@web27508.mail.ukl.yahoo.com>
Message-ID: <46763690.2020907@cs.uni-goettingen.de>

That means that R doesn't see 21 elements in line 16 of your file. This
can happen if one of your entries consists of two words, which are then
read as two elements.

Katharina

elyakhlifi mustapha schrieb:
> Hello,
> I have a problem to read a csv table. To read it I used this syntax
>
>   
>> donParCara <- read.table("C:/Documents and Settings/melyakhlifi/Mes documents/feuilles excel/calcul2.csv",header=TRUE,sep=";",quote="",dec=",")
>>     
>
> I don't understand my errors
>
> Erreur dans scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  : 
>         la ligne 16 n'avait pas 21 ?l?ments
>
> Can you help me please?
>
>
>       _____________________________________________________________________________ 
> Ne gardez plus qu'une seule adresse mail ! Copiez vos mails vers Yahoo! Mail 
> 	[[alternative HTML version deleted]]
>
>   
> ------------------------------------------------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Jouni.Junnila at PERKINELMER.COM  Mon Jun 18 09:48:09 2007
From: Jouni.Junnila at PERKINELMER.COM (Junnila, Jouni)
Date: Mon, 18 Jun 2007 08:48:09 +0100
Subject: [R] Problem with binding data-frames
Message-ID: <9202D193C49A974F9DC63C32B28918D0A15446@EMEAMAIL01.PERKINELMER.NET>

Hello,

I'm having a problem concerning r-binding datasets.

I have six datasets, from six different plates, and two different days.
I want to combine these datasets together for analysis. Datasets from
day 2, have all the same columns than datasets from day 1. However in
addition, there are few columns more in day 2. Thus, using rbind for
this, results a error, because the objects are not the same length. 

Error in paste(nmi[nii == 0L], collapse = ", ") : 
        object "nii" not found
In addition: Warning message:
longer object length
        is not a multiple of shorter object length in: clabs == nmi 


What I need, is to combine all the six together, and give for example
NA-value in day 1, for those columns which can only be found in day 2.
Is this somehow possible?

I have several of these six-datasets groups, and only few of them are
having this problem described above, and I cannot know in advance which.
With most of the groups writing
rbind(data1,data2,data3,data4,data5,data6)
works easily, but these few problematic groups need also to be
combined... 
Any help greatly appreciated!

-Jouni


From abr-r-project at xylon.de  Mon Jun 18 09:55:50 2007
From: abr-r-project at xylon.de (Arne Brutschy)
Date: Mon, 18 Jun 2007 09:55:50 +0200
Subject: [R] Lines connecting the boxes in a boxplot
In-Reply-To: <18038.13038.825501.499460@stat.math.ethz.ch>
References: <1875718929.20070616103819@xylon.de>
	<18038.13038.825501.499460@stat.math.ethz.ch>
Message-ID: <1829626816.20070618095550@xylon.de>

Hi,

C> I' recommend to save the information of your boxplots
C> Then you have the information that you need about your boxplot
C> (e.g. the value of the median) and can use segments() to draw
C> the lines you want.
Thanks, works like a charm!

Regards,
Arne

C> Arne Brutschy writes:
 >> Hello,
 >> 
 >> I'm currently using a boxplot to visualize data for three different
 >> models. As I have three models, I'm plotting three parallel boxplots
 >> for each factor.
 >> 
 >> This works fine - what I need now is a line connecting the medians of
 >> each boxplot of each model. I want to do this in order to visualize
 >> the trend that one of the models exhibit. Basically, I want to plot a
 >> curve for each model (slightly offset on the x axis), with a boxplot
 >> on each datapoint.
 >> 
 >> It's only an idea, and I don't know if it's not too confusing after
 >> adding the lines... Is it possible? Has anyone done this before?
 >> 
 >> Sorry if this has been asked before or is a standard feature, I simply
 >> have now clue how to name the feature I want. Ergo: I cannot search
 >> for it.. :\
 >> 
 >> Regards,
 >> Arne
 >> 
 >> PS: this is my current code
 >> 
 >> require(gplots)
 >> boxwex=0.15
 >> 
 >> data <- read.table("all_runs_fitness.data");
 >> colnames(data)=c("model","matrix","fitness")
 >> 
 >> boxplot(fitness ~ matrix,
 >>         data=data, boxwex=boxwex, at=(1:7 - 0.2),
 >>         main="Fitness for Matrix/Models", xlab="Matrixtype",
 >>         ylab="Fitness", ylim=c(20,100), 
 >>         subset=(model=="dyn"), col="lightblue", xaxt="n", whisklty=1)
 >> boxplot(fitness ~ matrix,
 >>         data=data, boxwex=boxwex, at = 1:7, add=TRUE, 
 >>         subset=(model=="dl3"), col="mistyrose", xaxt="n", whisklty=1)
 >> boxplot(fitness ~ matrix,
 >>         data=data, boxwex=boxwex, at=(1:7 + 0.2), add=TRUE, 
 >>         subset=(model=="dl4"), col="lightcyan", xaxt="n", whisklty=1)
 >> 
 >> axis(1, 1:8-0.5, labels=FALSE)
 >> axis(1, 1:7, tck=FALSE, labels=levels(data[,2]))
 >> 
 >> smartlegend(x="left", y="bottom", inset = 0.01,
 >>             c("dyn","dl3","dl4"), fill = c("lightblue", "mistyrose", "lightcyan"))
 >> 
 >> ______________________________________________
 >> R-help at stat.math.ethz.ch mailing list
 >> https://stat.ethz.ch/mailman/listinfo/r-help
 >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
 >> and provide commented, minimal, self-contained, reproducible code.


From thomas.hoffmann at uni-bonn.de  Mon Jun 18 10:09:47 2007
From: thomas.hoffmann at uni-bonn.de (Thomas Hoffmann)
Date: Mon, 18 Jun 2007 10:09:47 +0200
Subject: [R] merging dataframes with diffent rownumbers
Message-ID: <46763DCB.7020607@uni-bonn.de>

Dear R-Helpers,

I have following problem:

I do have two data frames dat1 and dat2 with a commen column BNUM (long 
integer). dat1 has a larger number of BNUM than dat2 and different rows 
of dat2 have equal BNUM. The numbers of rows in dat1 and dat2 is not 
equal.  I applied the  tapply-function to dat2 with BNUM as index. I 
would like to add the columns from dat1 to the results of

b.sum <- tapply(dat2, BNUM, sum).

However the BNUM of b.sum are only a subset of the dat1.

Does anybody knows a elegant way to solve the problem?
Thanks in advance

Thomas H.


From slomascolo at zoo.ufl.edu  Mon Jun 18 11:10:39 2007
From: slomascolo at zoo.ufl.edu (Silvia Lomascolo)
Date: Mon, 18 Jun 2007 02:10:39 -0700 (PDT)
Subject: [R] help with panel.lda
Message-ID: <11172049.post@talk.nabble.com>


I work with Windows, R version 2.4.1

I am trying to plot the results of a discriminant analysis done using the
lda function in the MASS library. The discriminant. analysis goes like this:

data.tb<-read.table('C:\\Documents and
Settings\\silvia\\Desktop\\dicrim_test.txt', header=T) ## the actual made-up
test matrix is pasted below
train<-sample (1:36, 15)
table (data.tb$group[train])
data.lda<-lda(group~., data.tb, subset = train)
predict (data.lda, data.tb[-train,])$class

Then I want to obtain a plot by writing: 

>plot(data.lda, cex=0.7, 2, xlab='LD1', ylab='LD2')

but it's not working.  It says that it could not find the function panel. 
When I include panel=panel.lda, it tells me that the object 'panel.lda' was
not found.  All I get is an empty plot in the graphics window.  Was I
supposed to create an object called panel.lda? I cannot find in the help
what that object might be.

Any help would be appreciated.
 
TABLE USED:
   group var1 var2 var3
1      1    3   55    6
2      1    4   66    7
3      1    5   55    8
4      1    4   66    7
5      1    3   44    6
6      1    3   55    5
7      1    3   44    4
8      1    4   44    3
9      1    4   44    7
10     1    4   66    6
11     2    5   88    9
12     2    4   99    8
13     2    8   88    9
14     2    9   76    8
15     2    8   66    9
16     2    9   99   10
17     2   10  100    9
18     2    4   99    9
19     2    8   88    8
20     2    9   76    9
21     2    8   66   10
22     2    9   99    9
23     3    2   11   11
24     3    3   22    2
25     3    1   33    3
26     3    1   11    1
27     3    2   44    2
28     3    3   22    3
29     3    4   11    1
30     3    1   11    1
31     3    2   22    2
32     3    3   33    3
33     3    1   11    1
34     3    1   44    2
35     3    2   22    3
36     3    3   11    1

-- 
View this message in context: http://www.nabble.com/help-with-panel.lda-tf3939027.html#a11172049
Sent from the R help mailing list archive at Nabble.com.


From niederlein-rstat at yahoo.de  Mon Jun 18 11:25:04 2007
From: niederlein-rstat at yahoo.de (Antje)
Date: Mon, 18 Jun 2007 11:25:04 +0200
Subject: [R] Readline - wait for user input
In-Reply-To: <46545150.8010604@biostat.ku.dk>
References: <46544A51.1050306@comcast.net> <46545150.8010604@biostat.ku.dk>
Message-ID: <46764F70.4040000@yahoo.de>

Hello,

I also have problems to get to run the following lines. If I run the 
block instead of every single line, it simply does not wait for the input.
Can anybody help me?

------------------------
pos_name <- readline("Please type: ")

r <- substr(pos_name, 1,1)
c <- substr(pos_name, 2,nchar(pos_name))

------------------------

Thank you!
Antje


Peter Dalgaard schrieb:
> Forest Floor wrote:
>> Hi,
>>
>> I've seen various posts on this question, but still can't get the code 
>> right. 
>>
>> If I run the following code one line at a time, it works fine.  If I run 
>> it together as a block, however, it doesn't wait for the input and gives 


>> an error.
>>
>> There must be a way to have are pause/wait for an answer, but I can't 
>> seem to find it.  Thanks!  J
>>
>> Code:
>>
>> choosefunction <- function(){readline("1. linear, 2. linear with lag, 3. 
>> nonlinear ")}
>> ans <- as.integer(choosefunction())
>> if (ans==1){K2=x1}
>> if (ans==2){K2=x2 }
>> if (ans==3){K2=x3 }
>> ans
>>
>> Error text:
>>  > ans <- as.integer(choosefunction())
>> 1. linear, 2. linear with lag, 3. nonlinear if (ans==1) {K2=x1}]}
>> Warning message:
>> NAs introduced by coercion
>>  > if (ans==2){K2=x2) }
>> Error in if (ans == 2) { : missing value where TRUE/FALSE needed
>>  > if (ans==3){K2=x3}
>> Error in if (ans == 3) { : missing value where TRUE/FALSE needed
>>  > ans
>> [1] NA
>>   
> As you may have realized already, the issue is that choosefunction()
> takes the next command as its input. Since "if (ans==1){K2=x1}" isn't an
> integer "ans" becomes NA, and it just goes downhill from there.
> 
> An extra set of braces may help
> 
>> choosefunction <- function(){readline("1. linear, 2. linear with lag, 3.
> + nonlinear ")}
>> {ans <- as.integer(choosefunction())
> + if (ans==1){K2=x1}
> + if (ans==2){K2=x2 }
> + if (ans==3){K2=x3 }
> + ans}
> 1. linear, 2. linear with lag, 3.
> nonlinear 3
> Error: object "x3" not found
> 
> It still doesn't quite work, but the reason(s) for that should be plain
> to see.
>


From descall at blueyonder.co.uk  Sun Jun 17 21:41:23 2007
From: descall at blueyonder.co.uk (Des Callaghan)
Date: Sun, 17 Jun 2007 20:41:23 +0100
Subject: [R] Prediction accuracy of poisson regression model
Message-ID: <000001c7b117$7cab3e30$7601ba90$@co.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070617/9f94f906/attachment.pl 

From xmeng at capitalbio.com  Mon Jun 18 04:39:19 2007
From: xmeng at capitalbio.com (XinMeng)
Date: Mon, 18 Jun 2007 10:39:19 +0800
Subject: [R] change fold from package"DEDS"
Message-ID: <382134359.23217@capitalbio.com>

Hi all:
package"DEDS" can find out differentially expressed genes via computing changefold.

But if there're 3(or more)groups(1\2\3 for instance),I wanna know the which "group vs group" the changefold is referd to(1 vs 2/1 vs 3/2 vs 3 for instance)?

Thanks a lot!

My best!


From descall at blueyonder.co.uk  Mon Jun 18 09:32:49 2007
From: descall at blueyonder.co.uk (Des Callaghan)
Date: Mon, 18 Jun 2007 08:32:49 +0100
Subject: [R] Inverse BoxCox transformation
Message-ID: <000001c7b17a$dfb1dad0$9f159070$@co.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070618/5ab779c9/attachment.pl 

From maechler at stat.math.ethz.ch  Mon Jun 18 11:56:03 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 18 Jun 2007 11:56:03 +0200
Subject: [R] Responding to a posting in the digest
In-Reply-To: <XFMail.070614095404.ted.harding@nessie.mcc.ac.uk>
References: <65657.87483.qm@web32215.mail.mud.yahoo.com>
	<XFMail.070614095404.ted.harding@nessie.mcc.ac.uk>
Message-ID: <18038.22195.247878.449830@stat.math.ethz.ch>

Thanks a lot, Ted, for your comprehensive answer!

[See one short note way below: ]

>>>>> "TH" == Ted Harding <ted.harding at nessie.mcc.ac.uk>
>>>>>     on Thu, 14 Jun 2007 09:54:04 +0100 (BST) writes:

    TH> On 14-Jun-07 07:26:26, Moshe Olshansky wrote:
    >> Is there a convenient way to respond to a particular
    >> posting which is a part of the digest?  I mean something
    >> that will automatically quote the original message,
    >> subject, etc.
    >> 
    >> Thank you!
    >> 
    >> Moshe Olshansky m_olshansky at yahoo.com

    TH> This will depend on two things.

    TH> 1. Whether the mail software you use has the capability;
    TH> 2. Whether the digest format would permit it anyway.

    TH> Regarding (2), if you are receiving R-help in
    TH> "traditional" digest format (all the messages, each with
    TH> its principal headers, as one single long message-body),
    TH> then the only way to respond to a particular message is
    TH> to start to compose a new message and copy what you need
    TH> from the digest.

    TH> While I've never reveived R-help in digest format
    TH> myself, according to Martin Maechler:

    TH> http://finzi.psych.upenn.edu/R/Rhelp02a/archive/59429.html

    TH>   Please open the URL at the end of every message
    TH> https://stat.ethz.ch/mailman/listinfo/r-help go to the
    TH> bottom and "log in" -- clicking the [Unsubscribe or Edit
    TH> Options] field. You need your mailing list password
    TH> sooner or later. The one you get sent every 1st of the
    TH> month; or you can have it sent to you again.

    TH>   Then you are in a page entitled "R-help Membership
    TH> Configuration for <foo>@<bar" Scroll down to the section
    TH> "Your R-help Subscription" where the 3rd entry is
    TH> entitled "Get MIME or Plain Text Digests?"  and now you
    TH> want MIME.

    TH> In MIME digest format, each message with its own main
    TH> headers is a separate MIME attachment, and suitable mail
    TH> software can bring any message up on its own, You can
    TH> then reply in the normal way.

    TH> However (and here is where I'm ignorant as a result of
    TH> never having received R-help as digest), your reply may
    TH> not continue the thread -- since this depends on
    TH> message-identifier headers being present which allow
    TH> threading software to trace which messages are replies
    TH> to which message. The JISCMAIL MIME digest for the
    TH> AllStat mailing list only includes a Message-ID for the
    TH> digest as a whole, i.e. the ID for the entire digest
    TH> message.  Message-IDs for the individual messages in the
    TH> digest (as would be seen by people who received them
    TH> singly) are absent: you only get the likes of

    TH>   Date: DoW, DD Mon YYYY HH:MM:SS TZ From: Sender
    TH> (person who sent the message to the list) Subject:
    TH> Subject of individual message MIME-Version: 1.0
    TH> Content-Type: text/plain; charset=iso-8859-1
    TH> Content-Transfer-Encoding: quoted-printable

    TH> and no Message ID for the original message from
    TH> "Sender". So any reply to this component message is not
    TH> identifiable as belonging to its thread.

    TH> I don't know whether R-help's 'mailman' provides such
    TH> headers (Martin??). 

Yes, it does (I've checked with a "pseudo-user" who receives
r-help in digests in MIME format). 
So you can indeed do the following.

In my limited experience, the main problem is the bad quality of
people'e e-mail software which does not properly work with
the (typically invisible) 'References:' and 'In-Reply-To:'
headers which mailman indeed does preserve in its MIME-digests.

    TH> If it does, then your reply could
    TH> include an "In-Reply-To:" which identifies the
    TH> thread. Otherwise it can't.

    TH> As to (1), you will probably get several suggestions for
    TH> suitable mail software. My own (see below) opens an
    TH> AllStat digest in a window with "attachment" tags
    TH> displayed, one for "Tablf of Contents", one for each
    TH> message. Clicking on one of these opens a new window
    TH> with the message attached to that tag displayed, and now
    TH> the usual reply/forward etc mail sunctions can be
    TH> applied to that message.  But it will reply only to the
    TH> address given in the "From:" header (i.e. the original
    TH> sender, as above), not to the AllStat list (so you have
    TH> to enter that address by hand, if you want to reply to
    TH> the list).

    TH> In principle, mailer software could also identify the
    TH> address of the list from which the digest has been sent,
    TH> as well as the sender of the original message, so you
    TH> could get the option to reply to either or both. But my
    TH> XFMail does not, and only offers the original
    TH> sender. Whether other mailer software can do this is for
    TH> others to comment on!

    TH> Hoping this helps, Ted.


From prudnikova at itcwin.com  Mon Jun 18 12:02:13 2007
From: prudnikova at itcwin.com (Julia Proudnikova)
Date: Mon, 18 Jun 2007 14:02:13 +0400
Subject: [R] Question about lmer
Message-ID: <1659237361.20070618140213@itcwin.com>

Hello,

We have a problem with function lmer. This is our code:

Get_values<-function(ff_count, fixed_factors, rf_count, random_factors, y_values)
{       
  SA<-matrix(as.array(c(fixed_factors, random_factors)), ncol=3)
  data<-as.data.frame(SA)
  y<-as.array(y_values)

  dd<-data.frame(SA)
  for(i in 1:(ff_count+rf_count)){
    dd[,i]<-as.factor(data[,i])
  }
  
  fit_full=lmer(y~dd[,1]+dd[,2]+(1|dd[,3]),method="ML")    
  fit_full
}

A<-c(0,0,0,0,1,1,1,1,0,0,0,0,1,1,1,1,0,0,0,0,1,1,1,1,0,0,0,0,1,1,1,1)
B<-c(0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1)
C<-c(0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,1)
Y<-c(5,3,4,1,1,2,6,1,5,3,7,1,2,3,1,1,5,3,4,1,1,2,6,1,5,3,7,1,2,3,1,1)
r<-Get_values(2, c(A,B),1,c(C),Y)
r 

R output:
Error in inherits(x, "factor") : object "dd" not found

Can this function work with random array? Because this code is
working:

D<-as.factor(data[,3])
fit_full=lmer(y~dd[,1]+dd[,2]+(1|D),method="ML")
 

-- 
Truly yours,
Julia                 mailto:prudnikova at itcwin.com


From p_connolly at ihug.co.nz  Mon Jun 18 12:11:43 2007
From: p_connolly at ihug.co.nz (Patrick Connolly)
Date: Mon, 18 Jun 2007 22:11:43 +1200
Subject: [R] Unix-like permissions to allow a user to update recommended
	packages
Message-ID: <20070618101143.GY4805@ihug.co.nz>

I installed R from the tar.gz file (as root) in a directory under
/usr/local.  The recommended packages are installed in a library in
that directory whereas additional packages I install in a directory
under the /home directory as a user.

Updating the additional packages is very easy with update.packages()
as a non-root user, but the recommended packages cannot be done so
readily because of file permissions.

My question is how do I set the permissions or ownerships in the
/usr/local/R-2.5.0 directory so that everything necessary can be
writable by a user?  Should I make a group for R users (total of one
member) or is it simpler than that?

TIA

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}          		 Great minds discuss ideas    
 _( Y )_  	  	        Middle minds discuss events 
(:_~*~_:) 	       		 Small minds discuss people  
 (_)-(_)  	                           ..... Anon
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From joris.dewolf at cropdesign.com  Mon Jun 18 12:23:35 2007
From: joris.dewolf at cropdesign.com (joris.dewolf at cropdesign.com)
Date: Mon, 18 Jun 2007 12:23:35 +0200
Subject: [R] Inverse BoxCox transformation
In-Reply-To: <000001c7b17a$dfb1dad0$9f159070$@co.uk>
Message-ID: <OFE8317A8F.0D708E90-ONC12572FE.0038513E-C12572FE.0039174F@basf-c-s.be>



to backtransform 'estimate':




if (lambda == 0 ) {


log(estimate)


} else {



estimate^(1/lambda)

}











                                                                           
             "Des Callaghan"                                               
             <descall at blueyond                                             
             er.co.uk>                                                  To 
             Sent by:                  <r-help at stat.math.ethz.ch>          
             r-help-bounces at st                                          cc 
             at.math.ethz.ch                                               
                                                                   Subject 
                                       [R] Inverse BoxCox transformation   
             18/06/2007 09:32                                              
                                                                           
                                                                           
                                                                           
                                                                           
                                                                           




Hi,

I can't seem to find a function in R that will reverse a BoxCox
transformation. Can somebody help me locate one please? Thanks in advance.

Best wishes,
Des


             [[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Charles.Annis at StatisticalEngineering.com  Mon Jun 18 12:24:05 2007
From: Charles.Annis at StatisticalEngineering.com (Charles Annis, P.E.)
Date: Mon, 18 Jun 2007 06:24:05 -0400
Subject: [R] Inverse BoxCox transformation
In-Reply-To: <000001c7b17a$dfb1dad0$9f159070$@co.uk>
References: <000001c7b17a$dfb1dad0$9f159070$@co.uk>
Message-ID: <023201c7b192$cc5a25b0$6400a8c0@DD4XFW31>

Look at the definition for the transform.  For example in the "car" package,
?box.cox

Then do the simple algebraic manipulations yourself.

Charles Annis, P.E.

Charles.Annis at StatisticalEngineering.com
phone: 561-352-9699
eFax:  614-455-3265
http://www.StatisticalEngineering.com
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Des Callaghan
Sent: Monday, June 18, 2007 3:33 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Inverse BoxCox transformation

Hi,
 
I can't seem to find a function in R that will reverse a BoxCox
transformation. Can somebody help me locate one please? Thanks in advance.
 
Best wishes,
Des
 

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From info at aghmed.fsnet.co.uk  Mon Jun 18 12:52:14 2007
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Mon, 18 Jun 2007 11:52:14 +0100
Subject: [R] merging dataframes with diffent rownumbers
In-Reply-To: <46763DCB.7020607@uni-bonn.de>
References: <46763DCB.7020607@uni-bonn.de>
Message-ID: <Zen-1I0EqL-0007k5-0T@heisenberg.zen.co.uk>

At 09:09 18/06/2007, Thomas Hoffmann wrote:
>Dear R-Helpers,
>
>I have following problem:
>
>I do have two data frames dat1 and dat2 with a commen column BNUM 
>(long integer). dat1 has a larger number of BNUM than dat2 and 
>different rows of dat2 have equal BNUM. The numbers of rows in dat1 
>and dat2 is not equal.  I applied the  tapply-function to dat2 with 
>BNUM as index. I would like to add the columns from dat1 to the results of
>
>b.sum <- tapply(dat2, BNUM, sum).
>
>However the BNUM of b.sum are only a subset of the dat1.
>
>Does anybody knows a elegant way to solve the problem?

If I understand you correctly
?merge
should help you here

>Thanks in advance
>
>Thomas H.
>
>

Michael Dewey
http://www.aghmed.fsnet.co.uk


From ted.harding at nessie.mcc.ac.uk  Mon Jun 18 12:53:22 2007
From: ted.harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Mon, 18 Jun 2007 11:53:22 +0100 (BST)
Subject: [R] Unix-like permissions to allow a user to update recommen
In-Reply-To: <20070618101143.GY4805@ihug.co.nz>
Message-ID: <XFMail.070618115322.ted.harding@nessie.mcc.ac.uk>

On 18-Jun-07 10:11:43, Patrick Connolly wrote:
> I installed R from the tar.gz file (as root) in a directory under
> /usr/local.  The recommended packages are installed in a library in
> that directory whereas additional packages I install in a directory
> under the /home directory as a user.
> 
> Updating the additional packages is very easy with update.packages()
> as a non-root user, but the recommended packages cannot be done so
> readily because of file permissions.
> 
> My question is how do I set the permissions or ownerships in the
> /usr/local/R-2.5.0 directory so that everything necessary can be
> writable by a user?  Should I make a group for R users (total of one
> member) or is it simpler than that?

Since you have root access, do you need to segregate the additional
packages to a particular user?

Though I don't run R as root for general use, I always install/update
by running R CMD as root. This makes all of R ("recommended" and also
any extras) available system-wide, and no pemission problems arise.

This of course does not stop you from setting up a special .Rprofile
for each user, since this by definition lives in the user's home
directory.

Does this help? Or are there issues you haven't mentioned which make
such an approach not feasible?

Best wishes,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 18-Jun-07                                       Time: 11:53:19
------------------------------ XFMail ------------------------------


From klaster at karlin.mff.cuni.cz  Mon Jun 18 12:55:41 2007
From: klaster at karlin.mff.cuni.cz (Petr Klasterecky)
Date: Mon, 18 Jun 2007 12:55:41 +0200
Subject: [R] Problem with binding data-frames
In-Reply-To: <9202D193C49A974F9DC63C32B28918D0A15446@EMEAMAIL01.PERKINELMER.NET>
References: <9202D193C49A974F9DC63C32B28918D0A15446@EMEAMAIL01.PERKINELMER.NET>
Message-ID: <467664AD.9020407@karlin.mff.cuni.cz>

Junnila, Jouni napsal(a):
> Hello,
> 
> I'm having a problem concerning r-binding datasets.
> 
> I have six datasets, from six different plates, and two different days.
> I want to combine these datasets together for analysis. Datasets from
> day 2, have all the same columns than datasets from day 1. However in
> addition, there are few columns more in day 2. Thus, using rbind for
> this, results a error, because the objects are not the same length. 
> 
> Error in paste(nmi[nii == 0L], collapse = ", ") : 
>         object "nii" not found
> In addition: Warning message:
> longer object length
>         is not a multiple of shorter object length in: clabs == nmi 

Hi,

1. the error has nothing to do with differing lengths of your objects - 
that's what the following warning is about. The error occured because 
your indexing object 'nii' does not exist where R is looking for it.

2. using rbind on dataframes is a bad practice, since the input is 
converted to marices if possible. Use merge() instead.

Petr

> 
> 
> What I need, is to combine all the six together, and give for example
> NA-value in day 1, for those columns which can only be found in day 2.
> Is this somehow possible?
> 
> I have several of these six-datasets groups, and only few of them are
> having this problem described above, and I cannot know in advance which.
> With most of the groups writing
> rbind(data1,data2,data3,data4,data5,data6)
> works easily, but these few problematic groups need also to be
> combined... 
> Any help greatly appreciated!
> 
> -Jouni
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Petr Klasterecky
Dept. of Probability and Statistics
Charles University in Prague
Czech Republic


From klaster at karlin.mff.cuni.cz  Mon Jun 18 12:58:13 2007
From: klaster at karlin.mff.cuni.cz (Petr Klasterecky)
Date: Mon, 18 Jun 2007 12:58:13 +0200
Subject: [R] merging dataframes with diffent rownumbers
In-Reply-To: <46763DCB.7020607@uni-bonn.de>
References: <46763DCB.7020607@uni-bonn.de>
Message-ID: <46766545.2090606@karlin.mff.cuni.cz>

No easy to understand what exactly you mean, but try
?merge
?cbind
?rbind

Petr

Thomas Hoffmann napsal(a):
> Dear R-Helpers,
> 
> I have following problem:
> 
> I do have two data frames dat1 and dat2 with a commen column BNUM (long 
> integer). dat1 has a larger number of BNUM than dat2 and different rows 
> of dat2 have equal BNUM. The numbers of rows in dat1 and dat2 is not 
> equal.  I applied the  tapply-function to dat2 with BNUM as index. I 
> would like to add the columns from dat1 to the results of
> 
> b.sum <- tapply(dat2, BNUM, sum).
> 
> However the BNUM of b.sum are only a subset of the dat1.
> 
> Does anybody knows a elegant way to solve the problem?
> Thanks in advance
> 
> Thomas H.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Petr Klasterecky
Dept. of Probability and Statistics
Charles University in Prague
Czech Republic


From christophe at pallier.org  Mon Jun 18 13:02:22 2007
From: christophe at pallier.org (Christophe Pallier)
Date: Mon, 18 Jun 2007 13:02:22 +0200
Subject: [R] what about options in BATCH
In-Reply-To: <521381.7469.qm@web27513.mail.ukl.yahoo.com>
References: <521381.7469.qm@web27513.mail.ukl.yahoo.com>
Message-ID: <dea6cb960706180402q13474e08xc12f71fe9367fdb6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070618/53fc8fb1/attachment.pl 

From niederlein-rstat at yahoo.de  Mon Jun 18 13:14:02 2007
From: niederlein-rstat at yahoo.de (Antje)
Date: Mon, 18 Jun 2007 13:14:02 +0200
Subject: [R] Readline
Message-ID: <467668FA.80905@yahoo.de>

Hello,

I also have problems to get to run the following lines. If I run the
block instead of every single line, it simply does not wait for the input.
Can anybody help me?

------------------------
pos_name <- readline("Please type: ")

r <- substr(pos_name, 1,1)
c <- substr(pos_name, 2,nchar(pos_name))

------------------------

Thank you!
Antje


Peter Dalgaard schrieb:
 > > Forest Floor wrote:
 >> >> Hi,
 >> >>
 >> >> I've seen various posts on this question, but still can't get the 
code
 >> >> right.
 >> >>
 >> >> If I run the following code one line at a time, it works fine. 
If I run
 >> >> it together as a block, however, it doesn't wait for the input 
and gives


 >> >> an error.
 >> >>
 >> >> There must be a way to have are pause/wait for an answer, but I 
can't
 >> >> seem to find it.  Thanks!  J
 >> >>
 >> >> Code:
 >> >>
 >> >> choosefunction <- function(){readline("1. linear, 2. linear with 
lag, 3.
 >> >> nonlinear ")}
 >> >> ans <- as.integer(choosefunction())
 >> >> if (ans==1){K2=x1}
 >> >> if (ans==2){K2=x2 }
 >> >> if (ans==3){K2=x3 }
 >> >> ans
 >> >>
 >> >> Error text:
 >> >>  > ans <- as.integer(choosefunction())
 >> >> 1. linear, 2. linear with lag, 3. nonlinear if (ans==1) {K2=x1}]}
 >> >> Warning message:
 >> >> NAs introduced by coercion
 >> >>  > if (ans==2){K2=x2) }
 >> >> Error in if (ans == 2) { : missing value where TRUE/FALSE needed
 >> >>  > if (ans==3){K2=x3}
 >> >> Error in if (ans == 3) { : missing value where TRUE/FALSE needed
 >> >>  > ans
 >> >> [1] NA
 >> >>
 > > As you may have realized already, the issue is that choosefunction()
 > > takes the next command as its input. Since "if (ans==1){K2=x1}" 
isn't an
 > > integer "ans" becomes NA, and it just goes downhill from there.
 > >
 > > An extra set of braces may help
 > >
 >> >> choosefunction <- function(){readline("1. linear, 2. linear with 
lag, 3.
 > > + nonlinear ")}
 >> >> {ans <- as.integer(choosefunction())
 > > + if (ans==1){K2=x1}
 > > + if (ans==2){K2=x2 }
 > > + if (ans==3){K2=x3 }
 > > + ans}
 > > 1. linear, 2. linear with lag, 3.
 > > nonlinear 3
 > > Error: object "x3" not found
 > >
 > > It still doesn't quite work, but the reason(s) for that should be plain
 > > to see.
 > >

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Mon Jun 18 13:16:22 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 18 Jun 2007 12:16:22 +0100 (BST)
Subject: [R] Problem with binding data-frames
In-Reply-To: <467664AD.9020407@karlin.mff.cuni.cz>
References: <9202D193C49A974F9DC63C32B28918D0A15446@EMEAMAIL01.PERKINELMER.NET>
	<467664AD.9020407@karlin.mff.cuni.cz>
Message-ID: <Pine.LNX.4.64.0706181212040.5272@gannet.stats.ox.ac.uk>

On Mon, 18 Jun 2007, Petr Klasterecky wrote:

> Junnila, Jouni napsal(a):
>> Hello,
>>
>> I'm having a problem concerning r-binding datasets.
>>
>> I have six datasets, from six different plates, and two different days.
>> I want to combine these datasets together for analysis. Datasets from
>> day 2, have all the same columns than datasets from day 1. However in
>> addition, there are few columns more in day 2. Thus, using rbind for
>> this, results a error, because the objects are not the same length.
>>
>> Error in paste(nmi[nii == 0L], collapse = ", ") :
>>         object "nii" not found
>> In addition: Warning message:
>> longer object length
>>         is not a multiple of shorter object length in: clabs == nmi
>
> Hi,
>
> 1. the error has nothing to do with differing lengths of your objects -
> that's what the following warning is about. The error occured because
> your indexing object 'nii' does not exist where R is looking for it.

It's because the dataframes have differing number of columns, and that has 
not been allowed for in the error message in that version of R.

> 2. using rbind on dataframes is a bad practice, since the input is
> converted to marices if possible. Use merge() instead.

Not so: rbind on data frames does no such conversion, and is not 
problematic provided they have the same column names (and hence the same 
number of columns).  You may have missed in ?rbind

      The functions 'cbind' and 'rbind' are S3 generic, with methods for
      data frames.  The data frame method will be used if at least one
      argument is a data frame and the rest are vectors or matrices.
...

and a later description of the data frame method for 'rbind'.

>
> Petr
>
>>
>>
>> What I need, is to combine all the six together, and give for example
>> NA-value in day 1, for those columns which can only be found in day 2.
>> Is this somehow possible?
>>
>> I have several of these six-datasets groups, and only few of them are
>> having this problem described above, and I cannot know in advance which.
>> With most of the groups writing
>> rbind(data1,data2,data3,data4,data5,data6)
>> works easily, but these few problematic groups need also to be
>> combined...
>> Any help greatly appreciated!
>>
>> -Jouni
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From bates at stat.wisc.edu  Mon Jun 18 13:28:53 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 18 Jun 2007 06:28:53 -0500
Subject: [R] Question about lmer
In-Reply-To: <1659237361.20070618140213@itcwin.com>
References: <1659237361.20070618140213@itcwin.com>
Message-ID: <40e66e0b0706180428y283ed06ax29169ce6570ed6cb@mail.gmail.com>

On 6/18/07, Julia Proudnikova <prudnikova at itcwin.com> wrote:
> Hello,
>
> We have a problem with function lmer. This is our code:
>
> Get_values<-function(ff_count, fixed_factors, rf_count, random_factors, y_values)
> {
>   SA<-matrix(as.array(c(fixed_factors, random_factors)), ncol=3)
>   data<-as.data.frame(SA)
>   y<-as.array(y_values)
>
>   dd<-data.frame(SA)
>   for(i in 1:(ff_count+rf_count)){
>     dd[,i]<-as.factor(data[,i])
>   }
>
>   fit_full=lmer(y~dd[,1]+dd[,2]+(1|dd[,3]),method="ML")
>   fit_full
> }
>
> A<-c(0,0,0,0,1,1,1,1,0,0,0,0,1,1,1,1,0,0,0,0,1,1,1,1,0,0,0,0,1,1,1,1)
> B<-c(0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1)
> C<-c(0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,1)
> Y<-c(5,3,4,1,1,2,6,1,5,3,7,1,2,3,1,1,5,3,4,1,1,2,6,1,5,3,7,1,2,3,1,1)
> r<-Get_values(2, c(A,B),1,c(C),Y)
> r
>
> R output:
> Error in inherits(x, "factor") : object "dd" not found
>
> Can this function work with random array? Because this code is
> working:

The full explanation of why lmer fails to find dd has to do with the
way names are resolved in a call to model.frame.  However, there may
be a way to solve your problem by redesigning your function so you
don't need to worry about what model.frame does.

Why not pass the data as a data frame and pass the names of the fixed
factors, random factors and response variable as character strings?
Your current design of creating a matrix, then converting it to a data
frame then converting numeric variables back to factors is a bit
convoluted.

If you knew that you were only going to have one random factor you
could generate the formula as

substitute(y ~ ff + (1|rf), list(y = as.name(y_name), ff =
parse(paste(ff_names, collapse = "+")), rf = as.name(rf_name))

It gets a bit trickier with multiple random factors.

Having said all this, it does appear that the call to model.frame
inside lmer is getting the wrong environment from the formula and I
will correct that.

If you need more detail about the redesign I am suggesting, feel free
to contact me off-list.


From murdoch at stats.uwo.ca  Mon Jun 18 13:36:12 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 18 Jun 2007 07:36:12 -0400
Subject: [R] Automatic paren/bracket closing in 2.5.0?
In-Reply-To: <Pine.LNX.4.64.0706172128430.13670@parser.ilovebacon.org>
References: <Pine.LNX.4.64.0706172128430.13670@parser.ilovebacon.org>
Message-ID: <46766E2C.9060200@stats.uwo.ca>

On 18/06/2007 12:30 AM, Adam D. I. Kramer wrote:
> Hello,
> 
>  	Just upgraded to 2.5.0, and found that R now includes an rparen
> (right parentheses) or rbracket whenever I enter in an lparen. While I can
> see the use of this function, it doesn't mesh well with my personal style of
> using R (e.g., using the up arrow, adding an rparen, jumping to the
> beginning of the line, and then wrapping a summary, for instance).
> 
> Some 10 minutes of google searching has failed to come up with a solution
> for turning this feature off--any suggestions from the list?

You don't say your OS.  If it's MacOSX (which I think is the only 
platform with this feature), then see the R-sig-mac list, and in 
particular Simon Urbanek's posting on May 23:

> On May 23, 2007, at 3:55 PM, Roberto Osorio wrote:
> 
>> > I can't find a preference to disable brace completion in the  
>> > console in R 2.5.0 GUI 1.19.
> 
> Unfortunately it didn't make it to the Preferences UI, so you have to  
> paste this in Terminal:
> 
> defaults write org.R-project.R auto.close.parens NO
> 
> If you want to revert back to the default you can use:
> 
> defaults delete org.R-project.R auto.close.parens
> 
> 

Duncan Murdoch


From jim at bitwrit.com.au  Mon Jun 18 13:43:23 2007
From: jim at bitwrit.com.au (Jim Lemon)
Date: Mon, 18 Jun 2007 21:43:23 +1000
Subject: [R] Readline
In-Reply-To: <467668FA.80905@yahoo.de>
References: <467668FA.80905@yahoo.de>
Message-ID: <46766FDB.5040507@bitwrit.com.au>

Antje wrote:
> Hello,
> 
> I also have problems to get to run the following lines. If I run the
> block instead of every single line, it simply does not wait for the input.
> Can anybody help me?
> 
> ------------------------
> pos_name <- readline("Please type: ")
> 
> r <- substr(pos_name, 1,1)
> c <- substr(pos_name, 2,nchar(pos_name))
> 
> ------------------------
> 
Hi Antje,
What you seem to be doing is pasting the lines into the R window. The 
second line looks like the input line that the first line is expecting, 
and if you remove the empty line, you will see that pos_name has been 
assigned the text of the second line.

If you put these lines into a text file and then use "source" to read 
it, it works as I think you expect.

Jim


From r.hankin at noc.soton.ac.uk  Mon Jun 18 14:12:15 2007
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Mon, 18 Jun 2007 13:12:15 +0100
Subject: [R] triangle contour plots
Message-ID: <42B9A932-99E8-4788-B66A-FB12A9FA1DD6@noc.soton.ac.uk>

Suppose I have three numbers p1, p2, p3 with
0 <= p1,p2,p3 <= 1  and p1+p2+p3=1,
and a  function  f=f(p1,p2,p3)   =  f(p1,p2,1-p1-p2).

How to draw a contour plot of f() on the p1+p2+p3=1 plane,
that is, an equilateral triangle?

Functions triplot(), triangle.plot(), and ternaryplot()  give
only  scatterplots, AFAICS





--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743


From elyakhlifi_mustapha at yahoo.fr  Mon Jun 18 14:36:45 2007
From: elyakhlifi_mustapha at yahoo.fr (elyakhlifi mustapha)
Date: Mon, 18 Jun 2007 12:36:45 +0000 (GMT)
Subject: [R] BATCH
Message-ID: <353559.61415.qm@web27505.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070618/73030c7a/attachment.pl 

From jfox at mcmaster.ca  Mon Jun 18 14:48:55 2007
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 18 Jun 2007 08:48:55 -0400
Subject: [R] Inverse BoxCox transformation
In-Reply-To: <000001c7b17a$dfb1dad0$9f159070$@co.uk>
Message-ID: <20070618124858.ZEHP1637.tomts20-srv.bellnexxia.net@JohnDesktop8300>

Dear Des,

The following should do the trick:

	invBoxCox <- function(x, lambda)
    		if (lambda == 0) exp(x) else (lambda*x + 1)^(1/lambda)

I hope this helps,
 John

--------------------------------
John Fox, Professor
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Des Callaghan
> Sent: Monday, June 18, 2007 3:33 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Inverse BoxCox transformation
> 
> Hi,
>  
> I can't seem to find a function in R that will reverse a 
> BoxCox transformation. Can somebody help me locate one 
> please? Thanks in advance.
>  
> Best wishes,
> Des
>  
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From christophe at pallier.org  Mon Jun 18 14:51:46 2007
From: christophe at pallier.org (Christophe Pallier)
Date: Mon, 18 Jun 2007 14:51:46 +0200
Subject: [R] BATCH
In-Reply-To: <353559.61415.qm@web27505.mail.ukl.yahoo.com>
References: <353559.61415.qm@web27505.mail.ukl.yahoo.com>
Message-ID: <dea6cb960706180551r65c16b9ay9e00c0ccfc00ffc5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070618/a7f282b1/attachment.pl 

From elyakhlifi_mustapha at yahoo.fr  Mon Jun 18 15:04:30 2007
From: elyakhlifi_mustapha at yahoo.fr (elyakhlifi mustapha)
Date: Mon, 18 Jun 2007 13:04:30 +0000 (GMT)
Subject: [R] data.frame
Message-ID: <752228.77767.qm@web27514.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070618/69cc1213/attachment.pl 

From ramasamy at cancer.org.uk  Mon Jun 18 15:16:46 2007
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Mon, 18 Jun 2007 14:16:46 +0100
Subject: [R] data.frame
In-Reply-To: <752228.77767.qm@web27514.mail.ukl.yahoo.com>
References: <752228.77767.qm@web27514.mail.ukl.yahoo.com>
Message-ID: <467685BE.7070700@cancer.org.uk>

See help(dim) and please read the manuals before asking basic questions 
like this. Thank you.


elyakhlifi mustapha wrote:
> hello,
> are there functions giving the columns number and the rows number of a matrix?
> thanks.
> 
> 
>       _____________________________________________________________________________ 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
>


From christophe at pallier.org  Mon Jun 18 15:28:44 2007
From: christophe at pallier.org (Christophe Pallier)
Date: Mon, 18 Jun 2007 15:28:44 +0200
Subject: [R] data.frame
In-Reply-To: <752228.77767.qm@web27514.mail.ukl.yahoo.com>
References: <752228.77767.qm@web27514.mail.ukl.yahoo.com>
Message-ID: <dea6cb960706180628o582177a7x3222c02e8678f9db@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070618/fde2711e/attachment.pl 

From r.hankin at noc.soton.ac.uk  Mon Jun 18 15:32:34 2007
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Mon, 18 Jun 2007 14:32:34 +0100
Subject: [R] data.frame
In-Reply-To: <467685BE.7070700@cancer.org.uk>
References: <752228.77767.qm@web27514.mail.ukl.yahoo.com>
	<467685BE.7070700@cancer.org.uk>
Message-ID: <F238F203-D336-4824-B465-1D97EB8AEAC6@noc.soton.ac.uk>


On 18 Jun 2007, at 14:16, Adaikalavan Ramasamy wrote:

> See help(dim) and please read the manuals before asking basic  
> questions
> like this. Thank you.
>


I think the questioner was looking for row() and col(), which (IMO) are
difficult to find if you don't know of their existence.


[as indeed are slice.index() or arow()  for the array case]

Robin


>
> elyakhlifi mustapha wrote:
>> hello,
>> are there functions giving the columns number and the rows number  
>> of a matrix?
>> thanks.
>>
>>
>>        
>> _____________________________________________________________________ 
>> ________
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting- 
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743


From elyakhlifi_mustapha at yahoo.fr  Mon Jun 18 15:40:38 2007
From: elyakhlifi_mustapha at yahoo.fr (elyakhlifi mustapha)
Date: Mon, 18 Jun 2007 13:40:38 +0000 (GMT)
Subject: [R] data.frame
Message-ID: <964808.32304.qm@web27515.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070618/0bcf9a52/attachment.pl 

From xingwang.ye at gmail.com  Mon Jun 18 15:23:07 2007
From: xingwang.ye at gmail.com (felix)
Date: Mon, 18 Jun 2007 21:23:07 +0800
Subject: [R] how to obtain the OR and 95%CI with 1 SD change of a continue
	variable
Message-ID: <4676873B.4090204@gmail.com>

Dear all,

How to obtain the odds ratio (OR) and 95% confidence interval (CI) with 
1 standard deviation (SD) change of a continuous variable in logistic 
regression?

for example, to investigate the risk of obesity for stroke. I choose the 
happening of stroke (positive) as the dependent variable, and waist 
circumference as an independent variable. Then I wanna to obtain the OR 
and 95% CI with 1 SD change of waist circumference.how?

Any default package(s) or options in glm available now?

if not, how to calculate them by hand?

many thanks.

yours,sincerely,
Xingwang Ye


From christophe at pallier.org  Mon Jun 18 15:51:10 2007
From: christophe at pallier.org (Christophe Pallier)
Date: Mon, 18 Jun 2007 15:51:10 +0200
Subject: [R] data.frame
In-Reply-To: <F238F203-D336-4824-B465-1D97EB8AEAC6@noc.soton.ac.uk>
References: <752228.77767.qm@web27514.mail.ukl.yahoo.com>
	<467685BE.7070700@cancer.org.uk>
	<F238F203-D336-4824-B465-1D97EB8AEAC6@noc.soton.ac.uk>
Message-ID: <dea6cb960706180651s3f203e28w30ef82b6172a2eb0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070618/1eb947e0/attachment.pl 

From helprhelp at gmail.com  Mon Jun 18 15:54:51 2007
From: helprhelp at gmail.com (Weiwei Shi)
Date: Mon, 18 Jun 2007 09:54:51 -0400
Subject: [R] source a specific function
Message-ID: <cdf817830706180654n45cad7e0wbc78b682a9296a3b@mail.gmail.com>

Dear Listers:

For example, if I have a .R source file which has more than one
function, and I want to just load only one of the functions, how could
I do that? (removing the rest after sourcing is not what I intend b/c
in my workspace, I might have some of the rest and I don't want to
change my workspace: i.e., I only change my workspace by adding one
function from a R source file).

Thanks,

-- 
Weiwei Shi, Ph.D
Research Scientist
GeneGO, Inc.

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III


From murdoch at stats.uwo.ca  Mon Jun 18 15:58:22 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 18 Jun 2007 09:58:22 -0400
Subject: [R] triangle contour plots
In-Reply-To: <42B9A932-99E8-4788-B66A-FB12A9FA1DD6@noc.soton.ac.uk>
References: <42B9A932-99E8-4788-B66A-FB12A9FA1DD6@noc.soton.ac.uk>
Message-ID: <46768F7E.8090709@stats.uwo.ca>

On 6/18/2007 8:12 AM, Robin Hankin wrote:
> Suppose I have three numbers p1, p2, p3 with
> 0 <= p1,p2,p3 <= 1  and p1+p2+p3=1,
> and a  function  f=f(p1,p2,p3)   =  f(p1,p2,1-p1-p2).
> 
> How to draw a contour plot of f() on the p1+p2+p3=1 plane,
> that is, an equilateral triangle?

The usual contour function leaves blanks where you give it NA values, so 
you could put the f values into a rectangular array with NA outside the 
triangle and use that.

I don't know how you're thinking of displaying things, but one possible 
transformation from (x,y) to (p1, p2, p3) would be

  f <- function(p1, p2, p3) p3  # just to illustrate

  maxy <- sin(pi/3)
  x <- seq(0,1,len=100)
  y <- seq(0, maxy, len=100)
  p1 <- outer(x,y, function(x,y) x - y/maxy/2)
  p2 <- outer(x,y, function(x,y) y/maxy)
  p3 <- 1-p1-p2
  z <- ifelse(0 < p1 & 0 < p3, f(p1,p2,p3), NA)
  contour(x,y,z)

This puts p1==1 at the bottom right, p2==1 at the top, and p3==1 at the 
bottom left.

Duncan Murdoch

> 
> Functions triplot(), triangle.plot(), and ternaryplot()  give
> only  scatterplots, AFAICS
> 
> 
> 
> 
> 
> --
> Robin Hankin
> Uncertainty Analyst
> National Oceanography Centre, Southampton
> European Way, Southampton SO14 3ZH, UK
>   tel  023-8059-7743
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From christophe at pallier.org  Mon Jun 18 16:01:28 2007
From: christophe at pallier.org (Christophe Pallier)
Date: Mon, 18 Jun 2007 16:01:28 +0200
Subject: [R] data.frame
In-Reply-To: <964808.32304.qm@web27515.mail.ukl.yahoo.com>
References: <964808.32304.qm@web27515.mail.ukl.yahoo.com>
Message-ID: <dea6cb960706180701m3f42efd8ib35e9a1b18eeb2b5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070618/6ba0a1fb/attachment.pl 

From petr.pikal at precheza.cz  Mon Jun 18 16:01:24 2007
From: petr.pikal at precheza.cz (Petr PIKAL)
Date: Mon, 18 Jun 2007 16:01:24 +0200
Subject: [R] Odp:  data.frame
In-Reply-To: <964808.32304.qm@web27515.mail.ukl.yahoo.com>
Message-ID: <OF2AF36BD4.EB7201C2-ONC12572FE.004C731A-C12572FE.004D0775@precheza.cz>

Hi

Why scratching your left ear with your right hand?

If M is numeric matrix

d.m <- data.frame(M)
names(d.m) <- paste("Rep", 1:dim(M)[2], sep="")

not sure what you want as row names as var is not defined anywhere in your 
code, but you can use the same principle for changing row names. Jus use

row.names(d.m) <- whatever vector of names you can elaborate

Regards

Petr Pikal
petr.pikal at precheza.cz

BTW. R is not C and you shall use strong features of R not to try to avoid 
them.


r-help-bounces at stat.math.ethz.ch napsal dne 18.06.2007 15:40:38:

> hello,
> I'm trying to write a function which take a matrix and give a dataframe 
with 
> column names and row names but the problem I meet it's that the column 
number 
> is changing and the vector containing the column names is also changing 
how 
> can I do to write a good progam for the moment I tryied like follow:
> 
> dm <- ncol(M)
> v <- vector()
> t <- 1
> while (dm > 0) {
>  v <- c(v,paste("R?p",t,sep=""))
>  t <- t + 1
>  dm <- dm - 1
> }
> nv <- noquote(v)
> df <- function (M,x) {
>  return(data.frame(nv[1] = M[,1], nv[2] = M[,2],nv[3] = M[,3], row.names 
= 
> var[[1]], check.rows = TRUE, check.names = TRUE))
> }
> 
>  I know that there are errors but the important is that R doesn't 
recognize nv.
> For more precision the martix M is like follow:
> 
>  M
>       [,1] [,2] [,3]
>  [1,] 6.52   NA 6.59
>  [2,] 6.99 6.85 6.38
>  [3,] 6.92 6.72 6.99
>  [4,] 6.59 5.51 6.45
>  [5,] 6.65 7.12 6.99
>  [6,] 6.18 5.71 5.78
>  [7,] 6.65 6.52 6.72
>  [8,] 6.65 6.79 6.12
>  [9,] 6.59 6.65 6.32
> [10,] 5.85 6.05 6.38
> [11,] 6.38 6.79 6.65
> [12,] 6.79 6.52 6.72
> [13,] 6.12 6.25 6.38
> [14,] 6.99 6.72 6.38
> [15,] 6.59 6.65 6.99
> [16,] 6.45 6.18 6.59
> [17,] 5.65 6.05 6.52
> [18,] 6.52 6.85 6.65
> [19,] 6.18 6.32 6.32
> [20,] 6.99 6.65 6.72
> [21,] 6.52 6.99 6.32
> 
> Can you help me?
> thanks.
> 
> 
> 
_____________________________________________________________________________ 

> Ne gardez plus qu'une seule adresse mail ! Copiez vos mails vers Yahoo! 
Mail 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Mon Jun 18 16:04:09 2007
From: jholtman at gmail.com (jim holtman)
Date: Mon, 18 Jun 2007 10:04:09 -0400
Subject: [R] data.frame
In-Reply-To: <964808.32304.qm@web27515.mail.ukl.yahoo.com>
References: <964808.32304.qm@web27515.mail.ukl.yahoo.com>
Message-ID: <644e1f320706180704l666bcf4fh1de2ccb7afcd862c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070618/f1d22ac1/attachment.pl 

From macq at llnl.gov  Mon Jun 18 16:21:31 2007
From: macq at llnl.gov (Don MacQueen)
Date: Mon, 18 Jun 2007 07:21:31 -0700
Subject: [R] source a specific function
In-Reply-To: <cdf817830706180654n45cad7e0wbc78b682a9296a3b@mail.gmail.com>
References: <cdf817830706180654n45cad7e0wbc78b682a9296a3b@mail.gmail.com>
Message-ID: <p06230900c29c44e0ffa5@[128.115.153.6]>

One way to do it would be to surround the function(s) you don't want 
sourced, like this:

if (FALSE) {
## function definition here
}

But you might find it easier to just put each function in its own file.

At 9:54 AM -0400 6/18/07, Weiwei Shi wrote:
>Dear Listers:
>
>For example, if I have a .R source file which has more than one
>function, and I want to just load only one of the functions, how could
>I do that? (removing the rest after sourcing is not what I intend b/c
>in my workspace, I might have some of the rest and I don't want to
>change my workspace: i.e., I only change my workspace by adding one
>function from a R source file).
>
>Thanks,
>
>--
>Weiwei Shi, Ph.D
>Research Scientist
>GeneGO, Inc.
>
>"Did you always know?"
>"No, I did not. But I believed..."
>---Matrix III
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA


From ggrothendieck at gmail.com  Mon Jun 18 16:28:35 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 18 Jun 2007 10:28:35 -0400
Subject: [R] source a specific function
In-Reply-To: <cdf817830706180654n45cad7e0wbc78b682a9296a3b@mail.gmail.com>
References: <cdf817830706180654n45cad7e0wbc78b682a9296a3b@mail.gmail.com>
Message-ID: <971536df0706180728x5e52196ek6b1ccef74640fab7@mail.gmail.com>

This loads all the functions into an anonymous environment defined
by local and then exports f to the global environment.

f <- local({
	source("/a.R", local = TRUE)
	environment(f) <- .GlobalEnv
	f
})

On 6/18/07, Weiwei Shi <helprhelp at gmail.com> wrote:
> Dear Listers:
>
> For example, if I have a .R source file which has more than one
> function, and I want to just load only one of the functions, how could
> I do that? (removing the rest after sourcing is not what I intend b/c
> in my workspace, I might have some of the rest and I don't want to
> change my workspace: i.e., I only change my workspace by adding one
> function from a R source file).
>
> Thanks,
>
> --
> Weiwei Shi, Ph.D
> Research Scientist
> GeneGO, Inc.
>
> "Did you always know?"
> "No, I did not. But I believed..."
> ---Matrix III
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch at stats.uwo.ca  Mon Jun 18 16:36:37 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 18 Jun 2007 10:36:37 -0400
Subject: [R] source a specific function
In-Reply-To: <cdf817830706180654n45cad7e0wbc78b682a9296a3b@mail.gmail.com>
References: <cdf817830706180654n45cad7e0wbc78b682a9296a3b@mail.gmail.com>
Message-ID: <46769875.10808@stats.uwo.ca>

On 6/18/2007 9:54 AM, Weiwei Shi wrote:
> Dear Listers:
> 
> For example, if I have a .R source file which has more than one
> function, and I want to just load only one of the functions, how could
> I do that? (removing the rest after sourcing is not what I intend b/c
> in my workspace, I might have some of the rest and I don't want to
> change my workspace: i.e., I only change my workspace by adding one
> function from a R source file).

In Windows, open the file in an editor, copy (e.g. by highlighting it 
and hitting Ctrl-C) the part you want to source to the clipboard, and 
then in R enter source("clipboard"), or just paste the selected text.

I think source("clipboard") is Windows-specific, but other platforms 
support copy and paste in their own ways.

Duncan Murdoch


From Greg.Snow at intermountainmail.org  Mon Jun 18 17:02:25 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Mon, 18 Jun 2007 09:02:25 -0600
Subject: [R] triangle contour plots
In-Reply-To: <42B9A932-99E8-4788-B66A-FB12A9FA1DD6@noc.soton.ac.uk>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBA220D1@LP-EXCHVS07.CO.IHC.COM>

The triplot function in the TeachingDemos package (I don't know about
the one in klaR, or the others mentioned) honors the type='l' argument
and passes it on to points.  So if you know where you want the contours
drawn, you can use triplot to draw the lines (it also has an add
argument that could be used to add labels after plotting the lines).

You can also look at the source code to see how the plotting is done and
modify it to do the plot you are interested in.

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Robin Hankin
> Sent: Monday, June 18, 2007 6:12 AM
> To: R program
> Subject: [R] triangle contour plots
> 
> Suppose I have three numbers p1, p2, p3 with 0 <= p1,p2,p3 <= 
> 1  and p1+p2+p3=1,
> and a  function  f=f(p1,p2,p3)   =  f(p1,p2,1-p1-p2).
> 
> How to draw a contour plot of f() on the p1+p2+p3=1 plane, 
> that is, an equilateral triangle?
> 
> Functions triplot(), triangle.plot(), and ternaryplot()  give 
> only  scatterplots, AFAICS
> 
> 
> 
> 
> 
> --
> Robin Hankin
> Uncertainty Analyst
> National Oceanography Centre, Southampton European Way, 
> Southampton SO14 3ZH, UK
>   tel  023-8059-7743
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From P.Dalgaard at biostat.ku.dk  Mon Jun 18 17:27:25 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 18 Jun 2007 17:27:25 +0200
Subject: [R] how to obtain the OR and 95%CI with 1 SD change of a
 continue variable
In-Reply-To: <4676873B.4090204@gmail.com>
References: <4676873B.4090204@gmail.com>
Message-ID: <4676A45D.6000300@biostat.ku.dk>

felix wrote:
> Dear all,
>
> How to obtain the odds ratio (OR) and 95% confidence interval (CI) with 
> 1 standard deviation (SD) change of a continuous variable in logistic 
> regression?
>
> for example, to investigate the risk of obesity for stroke. I choose the 
> happening of stroke (positive) as the dependent variable, and waist 
> circumference as an independent variable. Then I wanna to obtain the OR 
> and 95% CI with 1 SD change of waist circumference.how?
>
> Any default package(s) or options in glm available now?
>
> if not, how to calculate them by hand?
>
>   
Unless you want to do something advanced like factoring in the sampling
error of the SD (I don't think anyone bothers with that), probably the
easiest way is to scale() the predictor and look at the relevant line of
exp(confint(glm(.....))). As in

(library(MASS); example(confint.glm))

> budworm.lg0 <- glm(SF ~ sex + scale(ldose), family = binomial)
> exp(confint(budworm.lg0))
Waiting for profiling to be done...
                 2.5 %     97.5 %
(Intercept)  0.2652665  0.7203169
sexM         1.5208018  6.1747207
scale(ldose) 4.3399952 10.8983903

Or, if you insist on getting asymptotic Wald-statistic based intervals:

> exp(confint.default(budworm.lg0))
                2.5 %     97.5 %
(Intercept)  0.269864  0.7294944
sexM         1.496808  6.0384756
scale(ldose) 4.220890 10.5546837

You can also get it from the coefficients of the unscaled analysis, like in

> budworm.lg0 <- glm(SF ~ sex + ldose, family = binomial)
> confint(budworm.lg0)
Waiting for profiling to be done...
                 2.5 %    97.5 %
(Intercept) -4.4582430 -2.613736
sexM         0.4192377  1.820464
ldose        0.8229072  1.339086
> exp(confint(budworm.lg0)[3,]*sd(ldose))
Waiting for profiling to be done...
    2.5 %    97.5 %
 4.339995 10.898390


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From slomascolo at zoo.ufl.edu  Mon Jun 18 17:48:19 2007
From: slomascolo at zoo.ufl.edu (Silvia Lomascolo)
Date: Mon, 18 Jun 2007 08:48:19 -0700 (PDT)
Subject: [R] discriminant analysis with lda(MASS)
Message-ID: <11178433.post@talk.nabble.com>


I use Widows, R version 2.4.1

I have 4 questions on lda (MASS) (code is pasted below):

1st. How can I obtain the statistics and p-value associated with
discriminant analysis? Am I supposed to calculate that manually by squaring
the svd value and looking the p value up in a table? I am writing the
following code:

training.mx<-read.table('C:\\Documents and Settings\\silvia\\My
Documents\\silvia\\paper Martin\\trainingAndvalidation.txt', header=T)
train <- sample (1:148) ##in a file with 399 cases, I am using the first 148
as a training set
table(training.mx$disperser[train])
training.df <- lda (disperser~., training.mx, subset=train)
predict (training.df, training.mx[-train,])$class

2nd. How can I get the scores for each species on the discriminant
functions? I only get the scores for the group means, but I need the values
for all species.

3rd. Is it possible to obtain confidence intervals for my groups?

4th. (this is part of a previous posting but it's related to all my previous
questions so here it goes again) When I try to plot the resulting
discriminant functions following the example I found in the help, I get an
error saying that 'panel.lda' doesn't exist. Am I supposed to create it?
Here is the code for the plot:

plot(x, panel = panel.lda, cex = 0.7, dimen=1,
     xlab = "LD1", ylab = "LD2")

Help on any or all of these questions will be greatly appreciated!

Silvia.

-- 
View this message in context: http://www.nabble.com/discriminant-analysis-with-lda%28MASS%29-tf3941130.html#a11178433
Sent from the R help mailing list archive at Nabble.com.


From yn19832 at msn.com  Mon Jun 18 18:01:03 2007
From: yn19832 at msn.com (livia)
Date: Mon, 18 Jun 2007 09:01:03 -0700 (PDT)
Subject: [R] Optimization
Message-ID: <11178663.post@talk.nabble.com>


Hi, I would like to minimize the value of x1-x2, x2 is a fixed value of 0.01,
x1 is the quantile of normal distribution (0.0032,x) with probability of
0.7, and the changing value should be x. Initial value for x is 0.0207. I am
using the following codes, but it does not work.

fr <- function(x) {
      x1<-qnorm(0.7,0.0032,x)
      x2=0.01
      x1-x2
}
xsd <- optim(0.0207, fr, NULL,method="BFGS")

It is the first time I am trying to use optimization. Could anyone give me
some advice?
-- 
View this message in context: http://www.nabble.com/Optimization-tf3941212.html#a11178663
Sent from the R help mailing list archive at Nabble.com.


From ted.harding at nessie.mcc.ac.uk  Mon Jun 18 18:11:20 2007
From: ted.harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Mon, 18 Jun 2007 17:11:20 +0100 (BST)
Subject: [R] source a specific function
In-Reply-To: <971536df0706180728x5e52196ek6b1ccef74640fab7@mail.gmail.com>
Message-ID: <XFMail.070618171120.ted.harding@nessie.mcc.ac.uk>

On 18-Jun-07 14:28:35, Gabor Grothendieck wrote:
> This loads all the functions into an anonymous environment defined
> by local and then exports f to the global environment.
> 
> f <- local({
>       source("/a.R", local = TRUE)
>       environment(f) <- .GlobalEnv
>       f
> })

That looks neat! Two questions:

1. Would something similar work for extracting selected functions
   from a library (assuming that you know about interdependencies)?

   E.g. something like

  f <- local({
       library(f.etc.lib)
       environment(f) <- .GlobalEnv
       f
  })


2. Having done what you describe to extract just f from a source
   file, can one then "delete" the local environment used to load
   the source? I think what I'm basically asking is whether the
   exporting is done "by value" (local environment deletion OK)
   or "by reference" (deletion would destroy the exported object).

Apologies, but for instance "?local" is a bit too deep for me!

The underlying agenda behind these queries is the saving of
memory space.

With theanks,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 18-Jun-07                                       Time: 17:11:15
------------------------------ XFMail ------------------------------


From tkremund98 at hotmail.com  Mon Jun 18 18:17:58 2007
From: tkremund98 at hotmail.com (Todd Remund)
Date: Mon, 18 Jun 2007 10:17:58 -0600
Subject: [R] Large Binary file reader for Simple minds
Message-ID: <BAY121-F17ED5412FF6657D64CA222D4130@phx.gbl>

I'm more like a caveman when it comes to programming tools.  So, with that 
in mind, is there a way to use readBin in a batch format to read in pieces 
of a large binary file?  Thank you for the consideration of my question.

Todd Remund


From ggrothendieck at gmail.com  Mon Jun 18 18:30:19 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 18 Jun 2007 12:30:19 -0400
Subject: [R] source a specific function
In-Reply-To: <XFMail.070618171120.ted.harding@nessie.mcc.ac.uk>
References: <971536df0706180728x5e52196ek6b1ccef74640fab7@mail.gmail.com>
	<XFMail.070618171120.ted.harding@nessie.mcc.ac.uk>
Message-ID: <971536df0706180930m7830be5vf16d472185693f2f@mail.gmail.com>

1. You can do this:

> library(plotrix)
> environment(draw.arc) <- .GlobalEnv  # implicitly copies it
> detach()
> plot(1,1)
> draw.arc(1, 1, .1) # its there

2. Since the local environment we created in the prior post was anonymous
and since there are no other references to it either I assume it gets deleted
on the next garbage collection automatically.

On 6/18/07, Ted Harding <ted.harding at nessie.mcc.ac.uk> wrote:
> On 18-Jun-07 14:28:35, Gabor Grothendieck wrote:
> > This loads all the functions into an anonymous environment defined
> > by local and then exports f to the global environment.
> >
> > f <- local({
> >       source("/a.R", local = TRUE)
> >       environment(f) <- .GlobalEnv
> >       f
> > })
>
> That looks neat! Two questions:
>
> 1. Would something similar work for extracting selected functions
>   from a library (assuming that you know about interdependencies)?
>
>   E.g. something like
>
>  f <- local({
>       library(f.etc.lib)
>       environment(f) <- .GlobalEnv
>       f
>  })
>
>
> 2. Having done what you describe to extract just f from a source
>   file, can one then "delete" the local environment used to load
>   the source? I think what I'm basically asking is whether the
>   exporting is done "by value" (local environment deletion OK)
>   or "by reference" (deletion would destroy the exported object).
>
> Apologies, but for instance "?local" is a bit too deep for me!
>
> The underlying agenda behind these queries is the saving of
> memory space.
>
> With theanks,
> Ted.
>
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 18-Jun-07                                       Time: 17:11:15
> ------------------------------ XFMail ------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.uni-dortmund.de  Mon Jun 18 18:29:27 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 18 Jun 2007 18:29:27 +0200
Subject: [R] Optimization
In-Reply-To: <11178663.post@talk.nabble.com>
References: <11178663.post@talk.nabble.com>
Message-ID: <4676B2E7.7060308@statistik.uni-dortmund.de>



livia wrote:
> Hi, I would like to minimize the value of x1-x2, x2 is a fixed value of 0.01,
> x1 is the quantile of normal distribution (0.0032,x) with probability of
> 0.7, and the changing value should be x. Initial value for x is 0.0207. I am
> using the following codes, but it does not work.
> 
> fr <- function(x) {
>       x1<-qnorm(0.7,0.0032,x)
>       x2=0.01
>       x1-x2
> }
> xsd <- optim(0.0207, fr, NULL,method="BFGS")


I guess you want to use optimize() and change the last line of fr to 
(x1-x2)^2 as in:


fr <- function(x) {
       x1 <- qnorm(0.7, 0.0032, x)
       x2 <- 0.01
       (x1-x2)^2
}

optimize(fr, c(-5, 5))

Uwe Ligges




> It is the first time I am trying to use optimization. Could anyone give me
> some advice?


From tplate at acm.org  Mon Jun 18 18:33:40 2007
From: tplate at acm.org (Tony Plate)
Date: Mon, 18 Jun 2007 10:33:40 -0600
Subject: [R] Problem with RSVGTipsDevice
In-Reply-To: <11064573.post@talk.nabble.com>
References: <11064573.post@talk.nabble.com>
Message-ID: <4676B3E4.6060503@acm.org>

The new version of RSVGTipsDevice (0.7.1) that is now available on CRAN 
should fix this problem.  Please let me know if it doesn't, or if there 
are other problems.

-- Tony Plate

mister_bluesman wrote:
> Hi there.
> 
> I am still trying to get the RSVGTipsDevice to work, yet I can not.
> 
> I have copied the first example from RSVGTipsDevice documentation:
> 
> library(RSVGTipsDevice)
> devSVGTips("C:\\svgplot1.svg", toolTipMode=1,
> title="SVG example plot 1: shapes and points, tooltips are title + 1 line")
> plot(c(0,10),c(0,10), type="n", xlab="x", ylab="y",
> main="Example SVG plot with title + 1 line tips (mode=1)")
> setSVGShapeToolTip(title="A rectangle", desc="that is yellow")
> rect(1,1,4,6, col='yellow')
> setSVGShapeToolTip(title="1st circle with title only")
> points(5.5,7.5,cex=20,pch=19,col='red')
> setSVGShapeToolTip(title="A triangle", desc="big and green")
> polygon(c(3,6,8), c(3,6,3), col='green')
> # no tooltips on these points
> points(2:8, 8:2, cex=3, pch=19, col='black')
> # tooltips on each these points
> invisible(sapply(1:7, function(x)
> {setSVGShapeToolTip(title=paste("point", x))
> points(x+1, 8-x, cex=3, pch=1, col='black')}))
> dev.off()
> 
> This results in the following output:
> 
> http://www.nabble.com/file/p11064573/svgplot1.svg svgplot1.svg 
> 
> It opens but when I try and hover over the triangle, for example, I do not
> get a topptip box appear. I have tried opening the file though firefox, and
> XP IE - and on more than one computer yet it does not work. Do I need to
> install something else as well?
> 
> Many thanks


From ripley at stats.ox.ac.uk  Mon Jun 18 18:37:33 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 18 Jun 2007 17:37:33 +0100 (BST)
Subject: [R] Optimization
In-Reply-To: <11178663.post@talk.nabble.com>
References: <11178663.post@talk.nabble.com>
Message-ID: <Pine.LNX.4.64.0706181726460.23117@gannet.stats.ox.ac.uk>

>From the help page:

Note:

      'optim' will work with one-dimensional 'par's, but the default
      method does not work well (and will warn).  Use 'optimize'
      instead.

Next, there is a constraint of x>=0 that you are not imposing.

Finally, it is easy to see that qnorm(0.7, 0.0032, x) is monotome in x, so 
the solution is x=0.  In fact, x1 = 0.0032 + sqrt(x) * qnorm(0.7).

optim(0.0207, fr)  does a good enough job, as does
optimize(fr, low=0, up=0.05)


Advice: numerical optimization is not a black box, and has to be used with 
some analysis of the problem to hand.  See e.g. MASS4, chapter 16.


On Mon, 18 Jun 2007, livia wrote:

>
> Hi, I would like to minimize the value of x1-x2, x2 is a fixed value of 0.01,
> x1 is the quantile of normal distribution (0.0032,x) with probability of
> 0.7, and the changing value should be x. Initial value for x is 0.0207. I am
> using the following codes, but it does not work.
>
> fr <- function(x) {
>      x1<-qnorm(0.7,0.0032,x)
>      x2=0.01
>      x1-x2
> }
> xsd <- optim(0.0207, fr, NULL,method="BFGS")
>
> It is the first time I am trying to use optimization. Could anyone give me
> some advice?
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ral at lcfltd.com  Mon Jun 18 18:38:16 2007
From: ral at lcfltd.com (Robert A LaBudde)
Date: Mon, 18 Jun 2007 12:38:16 -0400
Subject: [R] Optimization
In-Reply-To: <11178663.post@talk.nabble.com>
References: <11178663.post@talk.nabble.com>
Message-ID: <0JJU008EUBJWSI42@vms040.mailsrvcs.net>

You don't need optimization for the solution to your problem. You 
just need an understanding of the meaning of qnorm() and some simple algebra.

Try: x<- (0.01-0.0032)/qnorm(0.7,0,1)


At 12:01 PM 6/18/2007, you wrote:

>Hi, I would like to minimize the value of x1-x2, x2 is a fixed value of 0.01,
>x1 is the quantile of normal distribution (0.0032,x) with probability of
>0.7, and the changing value should be x. Initial value for x is 0.0207. I am
>using the following codes, but it does not work.
>
>fr <- function(x) {
>       x1<-qnorm(0.7,0.0032,x)
>       x2=0.01
>       x1-x2
>}
>xsd <- optim(0.0207, fr, NULL,method="BFGS")
>
>It is the first time I am trying to use optimization. Could anyone give me
>some advice?
>--
>View this message in context: 
>http://www.nabble.com/Optimization-tf3941212.html#a11178663
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

================================================================
Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
824 Timberlake Drive                     Tel: 757-467-0954
Virginia Beach, VA 23464-3239            Fax: 757-467-2947

"Vere scire est per causas scire"


From ted.harding at nessie.mcc.ac.uk  Mon Jun 18 18:46:05 2007
From: ted.harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Mon, 18 Jun 2007 17:46:05 +0100 (BST)
Subject: [R] Optimization
In-Reply-To: <11178663.post@talk.nabble.com>
Message-ID: <XFMail.070618174605.ted.harding@nessie.mcc.ac.uk>

On 18-Jun-07 16:01:03, livia wrote:
> 
> Hi, I would like to minimize the value of x1-x2, x2 is a fixed
> value of 0.01,
> x1 is the quantile of normal distribution (0.0032,x) with
> probability of 0.7, and the changing value should be x.
> Initial value for x is 0.0207.

I'm a bit puzzled by the question. If I understand it right,
we can ignore x2 (since it is a fixed value) and simply consider
minimising x1 (instead of x1-x2).

Then, denoting by P(u) the cumulative normal distribution function
for mean=0 and variance=1 (i.e. in R: pnorm(u,0,1)), and by Q(p)
its inverse, corresponding to qnorm(p,0,1), we have (again if I
have understood right):

  P((x1 - 0.0032)/x) = 0.7

so

  x1 = 0.0032 + x*Q(0.7)

and therefore, since Q(0.7) > 0 and x must be positive, the value
of x1 can be made as close to 0.032 as you please (but greater
than 0.032) by taking x small enough.

Hence there is no strictly minimising value of x, but the greatest
lower bound of all possible values of x1 is 0.032.

Then you can subtract x2.

The fact that there is no positive value of x which gives this
bound as the value probably explains the failure of your optim()
attempt.

Best wishes,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 18-Jun-07                                       Time: 17:46:01
------------------------------ XFMail ------------------------------


From adik at ilovebacon.org  Mon Jun 18 18:54:00 2007
From: adik at ilovebacon.org (Adam D. I. Kramer)
Date: Mon, 18 Jun 2007 09:54:00 -0700 (PDT)
Subject: [R] Automatic paren/bracket closing in 2.5.0?
In-Reply-To: <46766E2C.9060200@stats.uwo.ca>
References: <Pine.LNX.4.64.0706172128430.13670@parser.ilovebacon.org>
	<46766E2C.9060200@stats.uwo.ca>
Message-ID: <Pine.LNX.4.64.0706180952360.19783@parser.ilovebacon.org>

Many thanks, Duncan. I did not expect this to be an OS-specific issue, and
figured it must be the new "default" and thus configurable from within the
program, though indeed I am using MacOS.

--Adam

On Mon, 18 Jun 2007, Duncan Murdoch wrote:

> On 18/06/2007 12:30 AM, Adam D. I. Kramer wrote:
>> Hello,
>>
>>  	Just upgraded to 2.5.0, and found that R now includes an rparen
>> (right parentheses) or rbracket whenever I enter in an lparen. While I can
>> see the use of this function, it doesn't mesh well with my personal style 
>> of
>> using R (e.g., using the up arrow, adding an rparen, jumping to the
>> beginning of the line, and then wrapping a summary, for instance).
>> 
>> Some 10 minutes of google searching has failed to come up with a solution
>> for turning this feature off--any suggestions from the list?
>
> You don't say your OS.  If it's MacOSX (which I think is the only platform 
> with this feature), then see the R-sig-mac list, and in particular Simon 
> Urbanek's posting on May 23:
>
>> On May 23, 2007, at 3:55 PM, Roberto Osorio wrote:
>> 
>>> > I can't find a preference to disable brace completion in the  > console 
>>> in R 2.5.0 GUI 1.19.
>> 
>> Unfortunately it didn't make it to the Preferences UI, so you have to 
>> paste this in Terminal:
>> 
>> defaults write org.R-project.R auto.close.parens NO
>> 
>> If you want to revert back to the default you can use:
>> 
>> defaults delete org.R-project.R auto.close.parens
>> 
>> 
>
> Duncan Murdoch
>


From klaster at karlin.mff.cuni.cz  Mon Jun 18 19:08:44 2007
From: klaster at karlin.mff.cuni.cz (Petr Klasterecky)
Date: Mon, 18 Jun 2007 19:08:44 +0200
Subject: [R] Optimization
In-Reply-To: <11178663.post@talk.nabble.com>
References: <11178663.post@talk.nabble.com>
Message-ID: <4676BC1C.1050305@karlin.mff.cuni.cz>

Hi,

my first guess is that the algorithm returns a negative value in some 
step - recall that you start from 0.0207!! This negative value is then 
passed as standard error to qnorm and that cannot work...
My guess is based on a small experiment where I tried a different 
starting point (.02 is so close to 0 that one cannot see anything):
xsd <- optim(20, fr, NULL,method="BFGS",control=list(trace=6))

The warnings which you didn't include also tell you about NaNs in 
qnorm() - another strong indication of wrong arguments to qnorm().

Try constrained optimization to resctrict to positive values.
See ?constrOptim or use optim() with a method allowing for box 
constraints - see ?optim, arguments lower, upper.

Petr

livia napsal(a):
> Hi, I would like to minimize the value of x1-x2, x2 is a fixed value of 0.01,
> x1 is the quantile of normal distribution (0.0032,x) with probability of
> 0.7, and the changing value should be x. Initial value for x is 0.0207. I am
> using the following codes, but it does not work.
> 
> fr <- function(x) {
>       x1<-qnorm(0.7,0.0032,x)
>       x2=0.01
>       x1-x2
> }
> xsd <- optim(0.0207, fr, NULL,method="BFGS")
> 
> It is the first time I am trying to use optimization. Could anyone give me
> some advice?

-- 
Petr Klasterecky
Dept. of Probability and Statistics
Charles University in Prague
Czech Republic


From murdoch at stats.uwo.ca  Mon Jun 18 19:27:32 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 18 Jun 2007 13:27:32 -0400
Subject: [R] Large Binary file reader for Simple minds
In-Reply-To: <BAY121-F17ED5412FF6657D64CA222D4130@phx.gbl>
References: <BAY121-F17ED5412FF6657D64CA222D4130@phx.gbl>
Message-ID: <4676C084.101@stats.uwo.ca>

On 6/18/2007 12:17 PM, Todd Remund wrote:
> I'm more like a caveman when it comes to programming tools.  So, with that 
> in mind, is there a way to use readBin in a batch format to read in pieces 
> of a large binary file?  Thank you for the consideration of my question.

I'm not sure what you mean by "batch format", but you can use readBin to 
  read bits and pieces of a file, by opening a connection to the file 
and reading from there.  For example, to read a single unsigned byte 
value at offset 10000, do something like this:

con <- file("myfile.dat", open="rb")  # open for binary reading
seek(con, 10000)
result <- readBin(con, "integer", size=1, signed=FALSE)
close(con)

Duncan Murdoch


From jgarcia at ija.csic.es  Mon Jun 18 20:03:05 2007
From: jgarcia at ija.csic.es (javier garcia-pintado)
Date: Mon, 18 Jun 2007 20:03:05 +0200
Subject: [R] chron() question
Message-ID: <4676C8D9.4010009@ija.csic.es>

Hi all,
I'm using chron and it seems to me that there is a strange behaviour
when constructing chronological objects.
An extract of my source data is:

> tdr.hhmm[4860:4870]
 [1] "22:22:00" "22:42:00" "23:02:00" "23:22:00" "23:42:00" "00:02:00"
 [7] "00:22:00" "00:42:00" "01:02:00" "01:22:00" "01:42:00"
> tdr.dat$year[4860:4870]
 [1] 2005 2005 2005 2005 2005 2006 2006 2006 2006 2006 2006
> tdr.dat$day[4860:4870]
 [1] 365 365 365 365 365   1   1   1   1   1   1

And if I use:
> tdr.chron <- 
chron(dates.=tdr.dat$day,times.=tdr.hhmm,origin.=c(month=1,day=0,year=tdr.dat$year),format=c(dates="d/m/y",times="h:m:s"))
The result is:

> tdr.chron[4860:4870]
 [1] (31/12/05 22:22:00) (31/12/05 22:42:00) (31/12/05 23:02:00)
 [4] (31/12/05 23:22:00) (31/12/05 23:42:00) (01/01/05 00:02:00)
 [7] (01/01/05 00:22:00) (01/01/05 00:42:00) (01/01/05 01:02:00)
[10] (01/01/05 01:22:00) (01/01/05 01:42:00)

While it seems to me that, through the R recycling rule, it should
consider the year 2006 in the corresponding results. Isn't it so?

Wishes,
Javier

-- 
Javier Garc?a-Pintado
Institute of Earth Sciences Jaume Almera (CSIC)
Lluis Sole Sabaris s/n, 08028 Barcelona
Phone: +34 934095410
Fax:   +34 934110012
e-mail:jgarcia at ija.csic.es 


From murdoch at stats.uwo.ca  Mon Jun 18 20:53:50 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 18 Jun 2007 14:53:50 -0400
Subject: [R] source a specific function
In-Reply-To: <XFMail.070618171120.ted.harding@nessie.mcc.ac.uk>
References: <XFMail.070618171120.ted.harding@nessie.mcc.ac.uk>
Message-ID: <4676D4BE.7040906@stats.uwo.ca>

On 6/18/2007 12:11 PM, (Ted Harding) wrote:
> On 18-Jun-07 14:28:35, Gabor Grothendieck wrote:
>> This loads all the functions into an anonymous environment defined
>> by local and then exports f to the global environment.
>> 
>> f <- local({
>>       source("/a.R", local = TRUE)
>>       environment(f) <- .GlobalEnv
>>       f
>> })
> 
> That looks neat! Two questions:
> 
> 1. Would something similar work for extracting selected functions
>    from a library (assuming that you know about interdependencies)?
> 
>    E.g. something like
> 
>   f <- local({
>        library(f.etc.lib)
>        environment(f) <- .GlobalEnv
>        f
>   })

The exact syntax you list there won't work, but in any case, changing 
the environment of a function in a package is a bad idea -- it may need 
to reference things from the namespace of the package.

> 
> 2. Having done what you describe to extract just f from a source
>    file, can one then "delete" the local environment used to load
>    the source? I think what I'm basically asking is whether the
>    exporting is done "by value" (local environment deletion OK)
>    or "by reference" (deletion would destroy the exported object).

Gabor answered this:  it will go away automatically.

Duncan Murdoch


From p.murrell at auckland.ac.nz  Mon Jun 18 21:20:46 2007
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Tue, 19 Jun 2007 07:20:46 +1200
Subject: [R] Large Binary file reader for Simple minds
In-Reply-To: <BAY121-F17ED5412FF6657D64CA222D4130@phx.gbl>
References: <BAY121-F17ED5412FF6657D64CA222D4130@phx.gbl>
Message-ID: <4676DB0E.9020303@stat.auckland.ac.nz>

Hi


Todd Remund wrote:
> I'm more like a caveman when it comes to programming tools.  So, with that 
> in mind, is there a way to use readBin in a batch format to read in pieces 
> of a large binary file?  Thank you for the consideration of my question.


The 'hexView' package might be useful to you.  See "Viewing Binary Files
with the hexView Package" in R News 7/1.

Paul


> Todd Remund
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From solberg at speakeasy.net  Mon Jun 18 21:38:18 2007
From: solberg at speakeasy.net (owenman)
Date: Mon, 18 Jun 2007 12:38:18 -0700 (PDT)
Subject: [R] Stacked barchart color
In-Reply-To: <f8e6ff050706152338s6394374dqd89701c3837ec1d8@mail.gmail.com>
References: <LPEJLJACLINDNMBMFAFIKEBICIAA.dieter.menne@menne-biomed.de>
	<f8e6ff050706121131s4b0aeb30y8de662ddd7323092@mail.gmail.com>
	<11149419.post@talk.nabble.com>
	<f8e6ff050706152338s6394374dqd89701c3837ec1d8@mail.gmail.com>
Message-ID: <11182581.post@talk.nabble.com>


Hi Hadley,
Great, I am starting to get it.  It's working for me, but there is one more
thing I am having trouble with.  The ordering of the stacked bars seems to
be dictated by the name of the color, I guess because of the fill=color
argument in aes().  In other words, if I set up my colors like this: 
y$color = c("gray1","gray35","gray45","gray65")  the bars get stacked in the
opposite order than if I set up the colors like this:  y$color =
c("gray65","gray45","gray35","gray1").  How can I control the order of the
bars independent of the name of the colors?   Thanks so much in advance! 
Really neat package you've made.

FYI, my plot command now looks like this:
p = ggplot(y, aes(x=locus, y=Freq, fill=color))
p = p + geom_bar(position="fill")
p = p + scale_fill_identity(labels=levels(y$Fnd), grob="tile", name="Fnd
Results")
p = p + coord_flip()

And the data table is similar as before:
> y
      Fnd locus        Freq  color
1  signeg  DPB1 0.013071895  gray1
2     neg  DPB1 0.581699346 gray35
3     pos  DPB1 0.379084967 gray45
4  sigpos  DPB1 0.026143791 gray65
5  signeg  DPA1 0.068181818  gray1
6     neg  DPA1 0.659090909 gray35
7     pos  DPA1 0.250000000 gray45
8  sigpos  DPA1 0.022727273 gray65



hadley wrote:
> 
> Hi Owen,
> 
> The identity scale won't create a legend, unless you tell it what
> labels it should use - there's an example at
> http://had.co.nz/ggplot2/scale_identity.html.  Otherwise, if you have
> a continuous scale and you want something that works in black and
> white, p + scale_fill_gradient(low="white", high="black") might be
> easier.
> 
> Hadley
> 
> 
>>
>> > y$color = factor(y$Fnd)
>> > y$color = c("black","darkgray","lightgray","white")
>> > y
>>       Fnd locus        Freq color
>> 1  signeg     A 0.087248322     black
>> 2     neg     A 0.711409396  darkgray
>> 3     pos     A 0.201342282 lightgray
>> 4  sigpos     A 0.000000000     white
>> 5  signeg     C 0.320754717     black
>> 6     neg     C 0.603773585  darkgray
>> 7     pos     C 0.075471698 lightgray
>> 8  sigpos     C 0.000000000     white
>> 9  signeg     B 0.157534247     black
>> 10    neg     B 0.732876712  darkgray
>> 11    pos     B 0.109589041 lightgray
>> 12 sigpos     B 0.000000000     white
>>
>> > p = ggplot(y, aes(x=locus, y=Freq, fill=color)) +
>> > geom_bar(position="fill") + scale_fill_identity()
>> > p
>>
>>
>>
>>
>> hadley wrote:
>> >
>> >
>> > Hi Dieter,
>> >
>> > You can do this with ggplot2 (http://had.co.nz/ggplot2) as follows:
>> >
>> > library(ggplot2)
>> >
>> > barley1 <- subset(barley, site=="Grand Rapids" & variety %in%
>> > c("Velvet","Peatland"))
>> > barley1[] <- lapply(barley1, "[", drop=TRUE)
>> >
>> > qplot(variety, yield, data=barley1, geom="bar", stat="identity",
>> > fill=factor(year))
>> >
>> > barley1$fill <- c("red","green","blue","gray")
>> > qplot(variety, yield, data=barley1, geom="bar", stat="identity",
>> > fill=fill) + scale_fill_identity()
>> >
>> > See http://had.co.nz/ggplot2/scale_identity.html and
>> > http://had.co.nz/ggplot2/position_stack.html for more details.
>> >
>> > Hadley
>> >
>> >
>>
>>
>> --
>> View this message in context:
>> http://www.nabble.com/Stacked-barchart-color-tf3909162.html#a11149419
>> Sent from the R help mailing list archive at Nabble.com.
>>
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/Stacked-barchart-color-tf3909162.html#a11182581
Sent from the R help mailing list archive at Nabble.com.


From ssj1364 at gmail.com  Mon Jun 18 22:18:30 2007
From: ssj1364 at gmail.com (sj)
Date: Mon, 18 Jun 2007 14:18:30 -0600
Subject: [R] psm/survreg coefficient values ?
Message-ID: <1c6126db0706181318n3cd9bd29kf4f728cec80fe0e4@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070618/7ba11a87/attachment.pl 

From p_connolly at ihug.co.nz  Mon Jun 18 22:27:56 2007
From: p_connolly at ihug.co.nz (Patrick Connolly)
Date: Tue, 19 Jun 2007 08:27:56 +1200
Subject: [R] Unix-like permissions to allow a user to update recommen
In-Reply-To: <XFMail.070618115322.ted.harding@nessie.mcc.ac.uk>
References: <20070618101143.GY4805@ihug.co.nz>
	<XFMail.070618115322.ted.harding@nessie.mcc.ac.uk>
Message-ID: <20070618202756.GZ4805@ihug.co.nz>

On Mon, 18-Jun-2007 at 11:53AM +0100, Ted Harding wrote:

|> On 18-Jun-07 10:11:43, Patrick Connolly wrote:
|> > I installed R from the tar.gz file (as root) in a directory under
|> > /usr/local.  The recommended packages are installed in a library in
|> > that directory whereas additional packages I install in a directory
|> > under the /home directory as a user.
|> > 
|> > Updating the additional packages is very easy with update.packages()
|> > as a non-root user, but the recommended packages cannot be done so
|> > readily because of file permissions.
|> > 
|> > My question is how do I set the permissions or ownerships in the
|> > /usr/local/R-2.5.0 directory so that everything necessary can be
|> > writable by a user?  Should I make a group for R users (total of one
|> > member) or is it simpler than that?
|> 
|> Since you have root access, do you need to segregate the additional
|> packages to a particular user?

It's handy to not have to reload packages that don't change between
versions of the basic installation.

|> 
|> Though I don't run R as root for general use, I always install/update
|> by running R CMD as root. This makes all of R ("recommended" and also
|> any extras) available system-wide, and no pemission problems arise.
|> 
|> This of course does not stop you from setting up a special .Rprofile
|> for each user, since this by definition lives in the user's home
|> directory.
|> 
|> Does this help? Or are there issues you haven't mentioned which make
|> such an approach not feasible?

I don't exactly have issues.  It's not a huge problem I'm dealing
with.  It's simple enough for me to use update.packages() as a user
which will download the appropriate packages.  Though they won't be
installed, they are all in the one place in the /tmp/ directory from
where I can install them as root.  I just thought there must be a more
elegant way to set permissions so that users could write to the
subdirectories under /usr/local/R-2.xxx/.  So much of the installation
process of R and its packages is so elegant, I'd like to retain some
of that elegance.

best

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}          		 Great minds discuss ideas    
 _( Y )_  	  	        Middle minds discuss events 
(:_~*~_:) 	       		 Small minds discuss people  
 (_)-(_)  	                           ..... Anon
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From Andy.Bunn at wwu.edu  Mon Jun 18 22:34:33 2007
From: Andy.Bunn at wwu.edu (Andy Bunn)
Date: Mon, 18 Jun 2007 13:34:33 -0700
Subject: [R] Second y-axis in xyplot (lattice) where y1 and y2 have
	different ranges
Message-ID: <B786254B2435F94E808B17CEC2A432F70803F08F@EVS1.univ.dir.wwu.edu>

Hi all,

I realize this is asking a lot of lattice, but I want to add a second y
axis inside a xyplot and have y1 and y2 have different ranges. Given dat
below, I can add a second y axis by overlaying a new plot with
par(new=T) and label axis 4 with standard graphics. I've seen an example
for doing something similar in xyplot even though Deepayan has indicated
that lattice isn't the right tool for the job. 

However, is there a way to gracefully add a second y-axis to a xyplot
where y1 and y2 have different scales as in the example below? I've seen
the experimental tools to focus and modify lattice graphics but do not
know if these are applicable. 

I have unreasonable faith that lattice can do anything. Since my
eventual goal is to make use of a grouping variable as with dat2 below,
lattice will be preferable to complex layouts. Thanks, Andy


  dat <- data.frame(Year = 1751:2000,
                    Stuff = rnorm(250),
                    Samples = floor(seq(5,30,length.out=250)
                                +rnorm(250,5)),
                    Grp = rep('SiteOne',250))
  par(mar=c(5,4,4,4) + 0.1)
  plot(Stuff~Year, data=dat, type='l')
  par(new=T)
  plot(Samples~Year, data=dat, type="l", axes=F, bty="n",
       xlab="", ylab="")
  axis(4, at=pretty(range(dat$Samples)))
  mtext("Number of Samples", 4, 3)

  xyplot(Stuff + Samples ~ Year | Grp, data=dat,
         layout = c(1, 1),
         panel = panel.superpose.2,
         ylab = "Stuff",
         legend = list(right =
         list(fun = grid::textGrob("Samples", rot = 90))),
         type = c('l', 'l'))

  dat2 <- data.frame(Year = rep(1751:2000,2),
                     Stuff = rep(rnorm(250),2),
                     Samples = rep(floor(seq(5,30,length.out=250)+
                       rnorm(250,5)),2),
                     Grp = c(rep('SiteOne',250),
                             rep('SiteTwo',250)))

  xyplot(Stuff + Samples ~ Year | Grp, data=dat2,
         panel = panel.superpose.2,
         ylab = "Stuff",
         legend = list(right =
         list(fun = grid::textGrob("Samples", rot = 90))),
         type = c('l', 'l'))


From mjankowski at gmail.com  Mon Jun 18 22:34:53 2007
From: mjankowski at gmail.com (M. Jankowski)
Date: Mon, 18 Jun 2007 15:34:53 -0500
Subject: [R] Help: Upgrading to R2.5 on Ubuntu (Feisty)
Message-ID: <500c63990706181334v732a95ddv8dc4d376960ba0dc@mail.gmail.com>

Thank you in advance for reading this help request. I am pretty new to
R. I am experiencing some issues getting 2.5 installed on my Ubuntu
Fiesty system and
seek your advice.

To the best of my ability I followed the instructions here:

http://cran.r-project.org/bin/linux/ubuntu/README

Setting this as the last line in my sources.list:
deb http://cran.fhcrc.org/bin/linux/ubuntu feisty/

When I typed in:

mdj at lapmdj:/usr/local/lib/R/site-library$ sudo apt-get install r-base
Reading package lists... Done
Building dependency tree
Reading state information... Done
r-base is already the newest version.
0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.
mdj at lapmdj:/usr/local/lib/R/site-library$

But when I go to R and check my version:

> version
              _
platform       i486-pc-linux-gnu
arch           i486
os             linux-gnu
system         i486, linux-gnu
status
major          2
minor          4.1
year           2006
month          12
day            18
svn rev        40228
language       R
version.string R version 2.4.1 (2006-12-18)
>

My version is still 2.4.1. I must be missing something. What do I need
to do to get R version 2.5 installed on my ubuntu feisty (7.04)
system? Let me know if there is any additional information I need to
give to be helped out with this.

Thank you for taking a look at this,
Sincerely,
Matt


From ted.harding at nessie.mcc.ac.uk  Mon Jun 18 23:00:36 2007
From: ted.harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Mon, 18 Jun 2007 22:00:36 +0100 (BST)
Subject: [R] source a specific function
In-Reply-To: <4676D4BE.7040906@stats.uwo.ca>
Message-ID: <XFMail.070618220036.ted.harding@nessie.mcc.ac.uk>

On 18-Jun-07 18:53:50, Duncan Murdoch wrote:
> 
> The exact syntax you list there won't work, but in any case, changing 
> the environment of a function in a package is a bad idea -- it may need
> to reference things from the namespace of the package.

Well, as I said before, "(assuming that you know about
interdependencies)"!

I tried Gabor's suggested syntax as follows, bearing in mind that
mvrnorm in MASS is pure R code calling only "base" functions:

library(MASS)
environment(mvrnorm) <- .GlobalEnv
mu=c(0,0)
V<-matrix(c(1.0,0.5,0.5,1.0),ncol=2)
detach()
ls()
[1] "%.+%"    "%+.%"    "mu"      "mvrnorm" "V"      

mvrnorm(10,mu,V)
             [,1]       [,2]
 [1,] -1.80466069 -1.8229928
 [2,]  0.05565147 -1.6279434
 [3,] -0.28505572 -0.8927696
 [4,] -0.48919795  0.0750501
 [5,] -0.08437832  0.1349296
 [6,]  2.17399713  1.2881640
 [7,]  1.59934824  1.3784665
 [8,]  0.30555420  0.3835743
 [9,]  0.11120527 -0.7287910
[10,] -0.77281783 -1.2265502

so that one seems to have worked.

However, I'm not sure about the space used by MASS "going away"
after detach():

Starting R from scratch:

Type 'q()' to quit R.

> gc()
         used (Mb) gc trigger (Mb)
Ncells 412589 11.1     597831   16
Vcells 102417  0.8     786432    6

> library(MASS)
> gc()
         used (Mb) gc trigger (Mb)
Ncells 459471 12.3     667722 17.9
Vcells 111187  0.9     786432  6.0

> environment(mvrnorm) <- .GlobalEnv
> detach()
> gc()
         used (Mb) gc trigger (Mb)
Ncells 459297 12.3     741108 19.8
Vcells 111105  0.9     786432  6.0
> gc()
         used (Mb) gc trigger (Mb)
Ncells 459304 12.3     818163 21.9
Vcells 111118  0.9     786432  6.0

so only about 170KB of the 2.2MB used by MASS has been recovered
after detach(). Or am I looking at the wrong indicator of space used?

On the other hand, if I first extract the code 9f mvrnorm()
which is a few lines of pure R, I get:

1. Start R from scratch:
gc()
         used (Mb) gc trigger (Mb)
Ncells 412589 11.1     597831   16
Vcells 102417  0.8     786432    6

2. Paste in the code for mvrnorm, and then:
gc()
         used (Mb) gc trigger (Mb)
Ncells 412844 11.1     667722 17.9
Vcells 102591  0.8     786432  6.0

so mrvnorm on its own is only taking up about

 (412844-412589) + (102591-102417) = 429KB

Hence I wonder whether the space first occupied by MASS (2.2MB)
apart from mvrnorm gets freed up at all?

Thanks for the comments.
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 18-Jun-07                                       Time: 22:00:33
------------------------------ XFMail ------------------------------


From ted.harding at nessie.mcc.ac.uk  Mon Jun 18 23:25:29 2007
From: ted.harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Mon, 18 Jun 2007 22:25:29 +0100 (BST)
Subject: [R] Unix-like permissions to allow a user to update recommen
In-Reply-To: <20070618202756.GZ4805@ihug.co.nz>
Message-ID: <XFMail.070618222529.ted.harding@nessie.mcc.ac.uk>

On 18-Jun-07 20:27:56, Patrick Connolly wrote:
> On Mon, 18-Jun-2007 at 11:53AM +0100, Ted Harding wrote:
> 
>|> On 18-Jun-07 10:11:43, Patrick Connolly wrote:
>|> > I installed R from the tar.gz file (as root) in a directory under
>|> > /usr/local.  The recommended packages are installed in a library in
>|> > that directory whereas additional packages I install in a directory
>|> > under the /home directory as a user.
>|> > 
>|> > Updating the additional packages is very easy with
>|> > update.packages()
>|> > as a non-root user, but the recommended packages cannot be done so
>|> > readily because of file permissions.
>|> > 
>|> > My question is how do I set the permissions or ownerships in the
>|> > /usr/local/R-2.5.0 directory so that everything necessary can be
>|> > writable by a user?  Should I make a group for R users (total of
>|> > one
>|> > member) or is it simpler than that?
>|> 
>|> Since you have root access, do you need to segregate the additional
>|> packages to a particular user?
> 
> It's handy to not have to reload packages that don't change between
> versions of the basic installation.
> 
>|> 
>|> Though I don't run R as root for general use, I always install/update
>|> by running R CMD as root. This makes all of R ("recommended" and also
>|> any extras) available system-wide, and no pemission problems arise.
>|> 
>|> This of course does not stop you from setting up a special .Rprofile
>|> for each user, since this by definition lives in the user's home
>|> directory.
>|> 
>|> Does this help? Or are there issues you haven't mentioned which make
>|> such an approach not feasible?
> 
> I don't exactly have issues.  It's not a huge problem I'm dealing
> with.  It's simple enough for me to use update.packages() as a user
> which will download the appropriate packages.  Though they won't be
> installed, they are all in the one place in the /tmp/ directory from
> where I can install them as root.  I just thought there must be a more
> elegant way to set permissions so that users could write to the
> subdirectories under /usr/local/R-2.xxx/.  So much of the installation
> process of R and its packages is so elegant, I'd like to retain some
> of that elegance.

On my Linux, all the places where components of R might normally
be installed (/usr/lib or /usr/local/lib) are user=root, group=root,
and when I look under them practically everything is writeable
only by user=root. So you'd have to change a lot of permissions
before any other user got rights to write to these directories.
Even adding a user to group=root wouldn't change things, since
group does not have write permissions (unless user=root too).

I'm still wondering, though, why you don't just run the command
update.packages() as root. You have root access, and you said
(in the "adding user to group" context) that only one user is
involved (presumably yourself?). In that case, why not start R
as root and run update.packages()?

Or am I missing something?

Best wishes,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 18-Jun-07                                       Time: 22:25:18
------------------------------ XFMail ------------------------------


From f.harrell at vanderbilt.edu  Mon Jun 18 23:56:54 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Mon, 18 Jun 2007 16:56:54 -0500
Subject: [R] psm/survreg coefficient values ?
In-Reply-To: <1c6126db0706181318n3cd9bd29kf4f728cec80fe0e4@mail.gmail.com>
References: <1c6126db0706181318n3cd9bd29kf4f728cec80fe0e4@mail.gmail.com>
Message-ID: <4676FFA6.7090309@vanderbilt.edu>

sj wrote:
> I am using psm to model some parametric survival data, the data is for
> length of stay in an emergency department. There are several ways a
> patient's stay in the emergency department can end (discharge, admit, etc..)
> so I am looking at modeling the effects of several covariates on the various
> outcomes. Initially I am trying to fit a  survival model for each type of
> outcome using the psm function in the design package,  i.e., all  patients
> who's visits  come to an end  due to  any event other than the event of
> interest are considered to be censored.  Being new to the psm and  survreg
> packages (and to parametric survival modeling) I am not entirely sure how to
> interpret the coefficient values that psm returns. I have included the
> following code to illustrate code similar to what I am using on my data. I
> suppose that the coefficients are somehow rescaled , but I am not sure how
> to return them to the original scale and make sense out of the coefficients,
> e.g., estimate the the effect of higher acuity on time to event in minutes.
> Any explanation or direction on how to interpret the  coefficient values
> would be greatly appreciated.
> 
> this is from the documentation for survreg.object.
> coefficientsthe coefficients of the linear.predictors, which multiply the
> columns of the model matrix. It does not include the estimate of error
> (sigma). The names of the coefficients are the names of the
> single-degree-of-freedom effects (the columns of the model matrix). If the
> model is over-determined there will be missing values in the coefficients
> corresponding to non-estimable coefficients.
> 
> code:
> LOS <- sort(rweibull(1000,1.4,108))
> AGE <- sort(rnorm(1000,41,12))
> ACUITY <- sort(rep(1:5,200))
> EVENT <-  sample(x=c(0,1),replace=TRUE,1000)
> psm(Surv(LOS,EVENT)~AGE+as.factor(ACUITY),dist='weibull')
> 
> output:
> 
> psm(formula = Surv(LOS, CENS) ~ AGE + as.factor(ACUITY), dist = "weibull")
> 
>        Obs     Events Model L.R.       d.f.          P         R2
>       1000        513    2387.62          5          0       0.91
> 
>               Value          Std. Error      z         p
> (Intercept)     1.1055    0.04425  24.98 8.92e-138
> AGE             0.0772    0.00152  50.93  0.00e+00
> ACUITY=2     0.0944    0.01357   6.96  3.39e-12
> ACUITY=3     0.1752    0.02111   8.30  1.03e-16
> ACUITY=4     0.1391    0.02722   5.11  3.18e-07
> ACUITY=5    -0.0544    0.03789  -1.43  1.51e-01
> Log(scale)    -2.7287    0.03780 -72.18  0.00e+00
> 
> Scale= 0.0653
> 
> best,
> 
> Spencer

I have a case study using psm (survreg wrapper) in my book.  Briefly, 
coefficients are on the log median survival time scale.

Frank


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From hpbenton at scripps.edu  Tue Jun 19 00:06:54 2007
From: hpbenton at scripps.edu (H. Paul Benton)
Date: Mon, 18 Jun 2007 15:06:54 -0700
Subject: [R] data type for block data?
Message-ID: <467701FE.80707@scripps.edu>

Dear All,


    I have a matrix with data that is not organised. I would like to go
through this and extract it. Each feature has 2 vectors which express
the data. I also have an index of the places where the data should be cut.
eg.
>class(cc)
"matrix"
>cc
      [,1] [,2]
 [1,]    1   26
 [2,]    2   27
 [3,]    3   28
 [4,]    4   29
 [5,]    5   30
 [6,]    6   31
 [7,]    7   32
 [8,]    8   33
 [9,]    9   34
[10,]    1   27
[11,]    1   28
[12,]    2   30
[13,]    3   34
ect......
> index
[1] "10" "40"


Is there a way to take cc[i:index[i-1],] to another format as to where
each block could be worked on separately. ie so in one block would be
rows1:10 the next block would be rows11:40 and so on.

Thanks,

Paul



-- 
Research Technician
Mass Spectrometry
   o The
  /
o Scripps
  \
   o Research
  /
o Institute


From deepayan.sarkar at gmail.com  Tue Jun 19 00:09:22 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Mon, 18 Jun 2007 15:09:22 -0700
Subject: [R] Second y-axis in xyplot (lattice) where y1 and y2 have
	different ranges
In-Reply-To: <B786254B2435F94E808B17CEC2A432F70803F08F@EVS1.univ.dir.wwu.edu>
References: <B786254B2435F94E808B17CEC2A432F70803F08F@EVS1.univ.dir.wwu.edu>
Message-ID: <eb555e660706181509s62fd8501w3a2dd8dc14c794d1@mail.gmail.com>

On 6/18/07, Andy Bunn <Andy.Bunn at wwu.edu> wrote:
> Hi all,
>
> I realize this is asking a lot of lattice, but I want to add a second y
> axis inside a xyplot and have y1 and y2 have different ranges. Given dat
> below, I can add a second y axis by overlaying a new plot with
> par(new=T) and label axis 4 with standard graphics. I've seen an example
> for doing something similar in xyplot even though Deepayan has indicated
> that lattice isn't the right tool for the job.
>
> However, is there a way to gracefully add a second y-axis to a xyplot
> where y1 and y2 have different scales as in the example below? I've seen
> the experimental tools to focus and modify lattice graphics but do not
> know if these are applicable.

You could use those, but one drawback there is that you don't get the
usual benefit of automatic allocation of space. Here is a ``better''
solution (as long as you realize that this is still a hack):

[Note: this won't work if scales="free" or "sliced"]

[...]

>   dat2 <- data.frame(Year = rep(1751:2000,2),
>                      Stuff = rep(rnorm(250),2),
>                      Samples = rep(floor(seq(5,30,length.out=250)+
>                        rnorm(250,5)),2),
>                      Grp = c(rep('SiteOne',250),
>                              rep('SiteTwo',250)))



scale.pars <- function(x)
{
    c(mx = min(x), dx = diff(range(x)))
}

rescale <- function(x, pars = scale.pars(x))
{
    (x - pars["mx"]) / pars["dx"]
}

pars.Stuff <- scale.pars(dat2$Stuff)
pars.Samples <- scale.pars(dat2$Samples)

rng.Stuff <- range(dat2$Stuff)
rng.Samples <- range(dat2$Samples)


my.yscale.components <- function(lim, ...)
{
    ## template we will modify
    ans <- yscale.components.default(lim, ...)
    ## labels for Stuff in original scale
    Stuff <- yscale.components.default(rng.Stuff, ...)
    Stuff$left$ticks$at <-
        rescale(Stuff$left$ticks$at, pars.Stuff)
    Stuff$left$labels$at <-
        rescale(Stuff$left$labels$at, pars.Stuff)
    ## labels for Samples in original scale
    Samples <- yscale.components.default(rng.Samples, ...)
    Samples$left$ticks$at <-
        rescale(Samples$left$ticks$at, pars.Samples)
    Samples$left$labels$at <-
        rescale(Samples$left$labels$at, pars.Samples)
    ## modified 'components'
    ans$left <- Stuff$left
    ans$right <- Samples$left
    ans
}


xyplot(rescale(Stuff, pars.Stuff) +
           rescale(Samples, pars.Samples) ~ Year | Grp,
       data=dat2,
       panel = panel.superpose.2,

       ## newlay added:
       yscale.components = my.yscale.components,
       scales = list(alternating = 3),

       ylab = "Stuff",
       legend = list(right =
       list(fun = grid::textGrob("Samples", rot = 90))),
       type = c('l', 'l'))


-Deepayan


From pensterfuzzer at yahoo.de  Mon Jun 18 21:10:18 2007
From: pensterfuzzer at yahoo.de (Werner Wernersen)
Date: Mon, 18 Jun 2007 21:10:18 +0200 (CEST)
Subject: [R] viewing source code
Message-ID: <333998.79370.qm@web23014.mail.ird.yahoo.com>

Hi,

could somebody give me a quick hint how to view the
source code of a function if sole entering of the
function name does not work?

In particular, I am trying to look at "cd_plot" from
the vcd package.

Many thanks in advance,
  Werner


From Achim.Zeileis at wu-wien.ac.at  Tue Jun 19 00:56:17 2007
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Tue, 19 Jun 2007 00:56:17 +0200 (CEST)
Subject: [R] viewing source code
In-Reply-To: <333998.79370.qm@web23014.mail.ird.yahoo.com>
Message-ID: <Pine.LNX.4.44.0706190051250.4019-100000@disco.wu-wien.ac.at>

Werner:

> could somebody give me a quick hint how to view the
> source code of a function if sole entering of the
> function name does not work?
>
> In particular, I am trying to look at "cd_plot" from
> the vcd package.

Strategy 1: Typing "cd_plot" tells you that it is a generic function
  and "methods(cd_plot)" shows you which methods exist (default and
  formula) which are both non-visible. You can still directly access
  them via "vcd:::cd_plot" (which is the main work horse).

Strategy 2 (preferred, especially if you want to take a closer look):
  Obtain the source package from CRAN. Unpack the tar.gz file and
  look into the vcd/R folder where you will find cd_plot.R containing
  the sources of both methods.

grx,
Z


From xieyc at hotmail.com  Mon Jun 18 23:37:12 2007
From: xieyc at hotmail.com (Yuanchang xie)
Date: Mon, 18 Jun 2007 21:37:12 +0000
Subject: [R] How to compare GLM and GAM models
Message-ID: <BAY118-F90B55F0D6819B5E128C79A1130@phx.gbl>

Dear Listers,

I want to compare two negative binomial models fitted using glm.nb and 
gam(mgcv) based on the same data. What would be the most appropriate 
criteria to compare these two models? Can someone point me to some 
references? Thank you very much.

Yuanchang Xie


From duvvuru.suman at gmail.com  Tue Jun 19 01:40:31 2007
From: duvvuru.suman at gmail.com (suman Duvvuru)
Date: Mon, 18 Jun 2007 19:40:31 -0400
Subject: [R] Histogram using frequency data
Message-ID: <bac8a0820706181640m2f448d5ewafd2ba5b9dd151a0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070618/38cf4e42/attachment.pl 

From tanimoto at u.arizona.edu  Tue Jun 19 01:41:54 2007
From: tanimoto at u.arizona.edu (Paulo Tanimoto)
Date: Mon, 18 Jun 2007 23:41:54 +0000
Subject: [R] Help: Upgrading to R2.5 on Ubuntu (Feisty)
In-Reply-To: <500c63990706181334v732a95ddv8dc4d376960ba0dc@mail.gmail.com>
References: <500c63990706181334v732a95ddv8dc4d376960ba0dc@mail.gmail.com>
Message-ID: <bfcc0ca60706181641w13560157m5c5b939015879a60@mail.gmail.com>

Dear Matt,

Did you issue:
$ sudo apt-get update

before running:
$ sudo apt-get install r-base

Now, let me tell you one thing about Linux and particularly
Debian/Ubuntu.  We are spoiled to the point that we love the official
repositories.  Because the official packages go through some testing,
we tend to sacrifice a little bit of cutting edge for
stability/reliability.  If you don't think you need anything specific
from version 2.5.0, I would recommend you to stick with the current
version, 2.4.1.  You'll also have several packages already compiled
for you if you do that.

I hope it helps.

Paulo






On 6/18/07, M. Jankowski <mjankowski at gmail.com> wrote:
> Thank you in advance for reading this help request. I am pretty new to
> R. I am experiencing some issues getting 2.5 installed on my Ubuntu
> Fiesty system and
> seek your advice.
>
> To the best of my ability I followed the instructions here:
>
> http://cran.r-project.org/bin/linux/ubuntu/README
>
> Setting this as the last line in my sources.list:
> deb http://cran.fhcrc.org/bin/linux/ubuntu feisty/
>
> When I typed in:
>
> mdj at lapmdj:/usr/local/lib/R/site-library$ sudo apt-get install r-base
> Reading package lists... Done
> Building dependency tree
> Reading state information... Done
> r-base is already the newest version.
> 0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.
> mdj at lapmdj:/usr/local/lib/R/site-library$
>
> But when I go to R and check my version:
>
> > version
>               _
> platform       i486-pc-linux-gnu
> arch           i486
> os             linux-gnu
> system         i486, linux-gnu
> status
> major          2
> minor          4.1
> year           2006
> month          12
> day            18
> svn rev        40228
> language       R
> version.string R version 2.4.1 (2006-12-18)
> >
>
> My version is still 2.4.1. I must be missing something. What do I need
> to do to get R version 2.5 installed on my ubuntu feisty (7.04)
> system? Let me know if there is any additional information I need to
> give to be helped out with this.
>
> Thank you for taking a look at this,
> Sincerely,
> Matt
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From philozine at yahoo.com  Tue Jun 19 01:07:13 2007
From: philozine at yahoo.com (philozine)
Date: Mon, 18 Jun 2007 16:07:13 -0700 (PDT)
Subject: [R] Retain names in conversion of matrix to vector
In-Reply-To: <4671D502.4070601@noaa.gov>
Message-ID: <920413.1056.qm@web32804.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070618/628faec6/attachment.pl 

From cmarcum at uci.edu  Tue Jun 19 01:54:19 2007
From: cmarcum at uci.edu (Christopher Marcum)
Date: Mon, 18 Jun 2007 16:54:19 -0700 (PDT)
Subject: [R] String manipulation, insert delim
Message-ID: <3136.24.176.215.116.1182210859.squirrel@webmail.uci.edu>

Hello All,

I've been using R for two years now and I am happy to say this is the
first time I could not find the answer to my problem in the R-help
archives. Here is the pending problem:

I want to be able to insert delimiters, say commas, into a string of
characters at uneven intervals such that:

foo<-c("haveaniceday")#my string of character
bar<-c(4,1,4,3) # my vector of uneven intervals

my.fun(foo,bar) # some function that places delimiters appropriately

have,a,nice,day # what the function would ideally return

I've tried multiple for-loops using cut and paste but have not had success.

Thanks!
Chris Marcum
UCI Sociology


From cbeeck at cyllene.uwa.edu.au  Tue Jun 19 01:55:03 2007
From: cbeeck at cyllene.uwa.edu.au (Cam Beeck)
Date: Tue, 19 Jun 2007 07:55:03 +0800
Subject: [R] classical plant hybrid analysis
Message-ID: <003e01c7b204$168d22b0$cdd65f82@agric.uwa.edu.au>

Hi,

I am looking to perform some classical hybrid analysis on hybrid plants
including GCA and SCA components through R.  I was wondering if anybody knew
of existing packages that can perform these analyses (I cannot find any) or
any examples of these analyses being worked through.

Cameron Beeck


From marc_schwartz at comcast.net  Tue Jun 19 01:59:17 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Mon, 18 Jun 2007 18:59:17 -0500
Subject: [R] Histogram using frequency data
In-Reply-To: <bac8a0820706181640m2f448d5ewafd2ba5b9dd151a0@mail.gmail.com>
References: <bac8a0820706181640m2f448d5ewafd2ba5b9dd151a0@mail.gmail.com>
Message-ID: <1182211157.3772.6.camel@Bellerophon.localdomain>

On Mon, 2007-06-18 at 19:40 -0400, suman Duvvuru wrote:
> Hello,
> 
> I wanted to know how to plot a histogram using a vector of frequencies
> rather than the data vector as a whole. So I have two vectors:  a vector of
> labels V1= c("A","B","C","D") and vector B which is a vector of frequencies
> of A, B, C and D respectively  V2=c(20,50,60,30). I wanted to plot a
> histogram of the labels using the frequencies. I could not figure out a way
> to do this using the 'hist' function which takes only the full data vector
> as input. Could you please help me with this?
> 
> Thank you,
> Suman

See ?barplot

To wit:

V1 <- c("A", "B", "C", "D") 
V2 <- c(20, 50, 60, 30)

# Do the barplot, saving the bar midpoints in 'mp'
mp <- barplot(V2, names.arg = V1, ylim = c(0, 80))

# Now add the bar values above the bars
text(mp, V2, V2, pos = 3)


See ?text and ?mtext for adding annotation

HTH,

Marc Schwartz


From fjbuch at gmail.com  Tue Jun 19 02:09:08 2007
From: fjbuch at gmail.com (Farrel Buchinsky)
Date: Mon, 18 Jun 2007 20:09:08 -0400
Subject: [R] genetics package not working
Message-ID: <bd93cdad0706181709p563b55d4pe43e2d0ea894054d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070618/386a1e61/attachment.pl 

From ggrothendieck at gmail.com  Tue Jun 19 02:23:38 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 18 Jun 2007 20:23:38 -0400
Subject: [R] String manipulation, insert delim
In-Reply-To: <3136.24.176.215.116.1182210859.squirrel@webmail.uci.edu>
References: <3136.24.176.215.116.1182210859.squirrel@webmail.uci.edu>
Message-ID: <971536df0706181723nadc7be9nd1a41f2ccc6577de@mail.gmail.com>

Try this:

> paste(read.fwf(textConnection(foo), bar, as.is = TRUE), collapse = ",")
[1] "have,a,nice,day"


On 6/18/07, Christopher Marcum <cmarcum at uci.edu> wrote:
> Hello All,
>
> I've been using R for two years now and I am happy to say this is the
> first time I could not find the answer to my problem in the R-help
> archives. Here is the pending problem:
>
> I want to be able to insert delimiters, say commas, into a string of
> characters at uneven intervals such that:
>
> foo<-c("haveaniceday")#my string of character
> bar<-c(4,1,4,3) # my vector of uneven intervals
>
> my.fun(foo,bar) # some function that places delimiters appropriately
>
> have,a,nice,day # what the function would ideally return
>
> I've tried multiple for-loops using cut and paste but have not had success.
>
> Thanks!
> Chris Marcum
> UCI Sociology
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jholtman at gmail.com  Tue Jun 19 02:25:58 2007
From: jholtman at gmail.com (jim holtman)
Date: Mon, 18 Jun 2007 20:25:58 -0400
Subject: [R] String manipulation, insert delim
In-Reply-To: <3136.24.176.215.116.1182210859.squirrel@webmail.uci.edu>
References: <3136.24.176.215.116.1182210859.squirrel@webmail.uci.edu>
Message-ID: <644e1f320706181725p332aeaeeqecbb0027c9579643@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070618/da3080b4/attachment.pl 

From marc_schwartz at comcast.net  Tue Jun 19 02:56:57 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Mon, 18 Jun 2007 19:56:57 -0500
Subject: [R] String manipulation, insert delim
In-Reply-To: <3136.24.176.215.116.1182210859.squirrel@webmail.uci.edu>
References: <3136.24.176.215.116.1182210859.squirrel@webmail.uci.edu>
Message-ID: <1182214617.3772.16.camel@Bellerophon.localdomain>

On Mon, 2007-06-18 at 16:54 -0700, Christopher Marcum wrote:
> Hello All,
> 
> I've been using R for two years now and I am happy to say this is the
> first time I could not find the answer to my problem in the R-help
> archives. Here is the pending problem:
> 
> I want to be able to insert delimiters, say commas, into a string of
> characters at uneven intervals such that:
> 
> foo<-c("haveaniceday")#my string of character
> bar<-c(4,1,4,3) # my vector of uneven intervals
> 
> my.fun(foo,bar) # some function that places delimiters appropriately
> 
> have,a,nice,day # what the function would ideally return
> 
> I've tried multiple for-loops using cut and paste but have not had success.
> 
> Thanks!
> Chris Marcum
> UCI Sociology

One more variation on the replies already provided:

foo <- c("haveaniceday")
bar <- c(4, 1, 4, 3)

insert.char <- function(x, at, char = ",")
{
   cs.at <- cumsum(at)
   vec <- unlist(strsplit(x, ""))
   for (i in seq(length(cs.at) - 1))
     vec <- append(vec, char, cs.at[i] + i - 1)
   paste(vec, collapse = "")
}


> insert.char(foo, bar)
[1] "have,a,nice,day"

See ?append

HTH,

Marc Schwartz


From trunnell at cognix.net  Tue Jun 19 03:07:42 2007
From: trunnell at cognix.net (Matthew Trunnell)
Date: Mon, 18 Jun 2007 18:07:42 -0700
Subject: [R] Histograms with strings, grouped by repeat count (w/ data)
Message-ID: <572004630706181807u3f0698f9vb42027951b777b1@mail.gmail.com>

Hello R gurus,

I just spent my first weekend wrestling with R, but so far have come
up empty handed.

I have a dataset that represents file downloads; it has 4 dimensions:
date, filename, email, and country.  (sample data below)

My first goal is to get an idea of the frequency of repeated
downloads.  Let me explain that.  Some people tend to download
multiple times, e.g. if the download fails they keep trying over and
over.  I'm trying to build a histogram that shows the repeat count
along the x-axis, that is, how many people downloaded once, twice,
three times, etc.  I plan to compare the median of that before and
after we switched ISPs.

To accomplish this, I'm assuming that I'll first need to combine the
email and filename columns so as to represent a single download
attempt by an individual.  Does that sound right?  Later, it would be
nice to limit the histogram to a single filename, country, or company.
 I can probably figure that out myself after I understand how to write
this funky histogram expression.

With the help of Verzani's introductory text, I've learned how to read
in the CSV data and do some simple tables, like this:

hist(table(d$filename))
hist(table(d$filename[substring(d$filename, 1, 5)=="file1"]))
hist(sort(table(d$filename[substring(d$filename, 1, 5)=="file1"])))

Obviously, these commands count the frequency of the files.  What I'd
like to see are the repeats grouped along the x-axis;  I'd like to
find, for all files, the distribution of retries.  I hope that makes
sense. :)

Can someone point me in the right direction?  I'm very new to R and to
statistics, but I write code for a living.  At this point I'd almost
be better off writing a program do this kind of simple counting... but
I have a feeling R would be so useful if I could just get past the
initial learning curve.

Thank you in advance,
Matt

Here's some real data, with the private info replaced :)

 d<-read.table(file="C:\\users\\trunnellm\\downloads\\statistics\\downloads.csv",
sep=",", quote="\"", header=TRUE)

filename,last_modified,email_addr,country_residence
file1,3/4/2006 13:54,email1,Korea (South)
file2,3/4/2006 14:33,email2,United States
file2,3/4/2006 16:03,email2,United States
file2,3/4/2006 16:17,email3,United States
file2,3/4/2006 16:28,email3,United States
file3,3/4/2006 19:13,email4,United States
file2,3/4/2006 21:22,email5,India
file4,3/4/2006 21:46,email6,United States
file1,3/4/2006 22:04,email7,Japan
file2,3/4/2006 22:09,email8,Croatia
file1,3/4/2006 22:22,email7,Japan
file1,3/4/2006 22:29,email9,India
file1,3/4/2006 23:06,email6,United States
file1,3/4/2006 23:33,email6,United States
file5,3/4/2006 23:44,email10,China
file1,3/5/2006 0:13,email9,India
file2,3/5/2006 0:52,email8,Croatia
file2,3/5/2006 0:54,email8,Croatia
file2,3/5/2006 1:10,email5,India
file6,3/5/2006 2:17,email9,India
file2,3/5/2006 2:24,email11,Italy
file7,3/5/2006 2:36,email12,Italy
file8,3/5/2006 2:52,email12,Italy
file2,3/5/2006 3:09,email13,United Kingdom
file2,3/5/2006 4:02,email14,India
file2,3/5/2006 4:07,email14,India
file2,3/5/2006 4:14,email14,India
file2,3/5/2006 4:37,email5,India
file2,3/5/2006 4:44,email15,Belgium
file1,3/5/2006 5:02,email9,India
file1,3/5/2006 5:24,email16,Taiwan
file2,3/5/2006 6:06,email17,Saudi Arabia
file2,3/5/2006 7:32,email17,Saudi Arabia
file2,3/5/2006 8:12,email18,Brazil
file2,3/5/2006 8:26,email18,Brazil
file2,3/5/2006 9:49,email19,United Kingdom
file1,3/5/2006 10:49,email11,Italy
file1,3/5/2006 11:16,email13,United Kingdom
file1,3/5/2006 11:16,email13,United Kingdom
file1,3/5/2006 11:45,email13,United Kingdom
file1,3/5/2006 14:34,email20,Australia
file9,3/5/2006 14:56,email20,Australia
file9,3/5/2006 14:56,email20,Australia
file5,3/5/2006 16:43,email21,United States
file1,3/5/2006 17:17,email7,Japan
file2,3/5/2006 17:26,email22,Japan
file2,3/5/2006 17:27,email22,Japan
file2,3/5/2006 17:33,email23,China
file1,3/5/2006 17:45,email22,Japan
file2,3/5/2006 17:45,email22,Japan
file2,3/5/2006 17:59,email23,China
file1,3/5/2006 18:27,email24,Japan
file1,3/5/2006 18:47,email25,Taiwan
file2,3/5/2006 18:48,email26,New Zealand
file2,3/5/2006 19:15,email27,Canada
file2,3/5/2006 19:23,email28,Canada
file2,3/5/2006 19:24,email28,Canada
file10,3/5/2006 19:49,email29,Japan
file10,3/5/2006 19:52,email29,Japan
file10,3/5/2006 19:57,email29,Japan
file2,3/5/2006 20:01,email29,Japan
file2,3/5/2006 20:02,email29,Japan
file2,3/5/2006 20:06,email29,Japan


From jaystat at yahoo.com  Tue Jun 19 02:38:31 2007
From: jaystat at yahoo.com (Jaydip Mukhopadhyay)
Date: Mon, 18 Jun 2007 17:38:31 -0700 (PDT)
Subject: [R] categorical time series
Message-ID: <541128.24432.qm@web90414.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070618/a9fe8b81/attachment.pl 

From jholtman at gmail.com  Tue Jun 19 03:43:21 2007
From: jholtman at gmail.com (jim holtman)
Date: Mon, 18 Jun 2007 21:43:21 -0400
Subject: [R] Histograms with strings, grouped by repeat count (w/ data)
In-Reply-To: <572004630706181807u3f0698f9vb42027951b777b1@mail.gmail.com>
References: <572004630706181807u3f0698f9vb42027951b777b1@mail.gmail.com>
Message-ID: <644e1f320706181843p76d4192dlf367574973f15142@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070618/ecf16e0b/attachment.pl 

From jholtman at gmail.com  Tue Jun 19 04:01:33 2007
From: jholtman at gmail.com (jim holtman)
Date: Mon, 18 Jun 2007 22:01:33 -0400
Subject: [R] data type for block data?
In-Reply-To: <467701FE.80707@scripps.edu>
References: <467701FE.80707@scripps.edu>
Message-ID: <644e1f320706181901p3188c2d1y391433f0700e4f1c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070618/4c9c60f2/attachment.pl 

From trunnell at cognix.net  Tue Jun 19 04:22:09 2007
From: trunnell at cognix.net (Matthew Trunnell)
Date: Mon, 18 Jun 2007 19:22:09 -0700
Subject: [R] Histograms with strings, grouped by repeat count (w/ data)
In-Reply-To: <644e1f320706181843p76d4192dlf367574973f15142@mail.gmail.com>
References: <572004630706181807u3f0698f9vb42027951b777b1@mail.gmail.com>
	<644e1f320706181843p76d4192dlf367574973f15142@mail.gmail.com>
Message-ID: <572004630706181922p686f60er8e0684bb48c6c04d@mail.gmail.com>

Jim,
Thanks for the quick reply!  When I run your code, I end up with a
single barplot of one datapoint, file9 vs email20 == 2.0.  I see the
call to barplot is inside a for loop... maybe it's zooming through the
display of many barplots, but all I see is the last one?

In any case, I need to figure out the distribution of the retries, such as
No. Retries   Count
1                 6
2                 13
3                 5
4                 3
5                 2
6                 1

That is, 6 people retried the download once; 13 people retried the
download twice, etc.  So it would be counting the frequency of the
email-filename combination, and grouping those together by the number
of retries.  Does that make sense?

When I look at the counts object from your code, I can see that it's
close to what I need.  How do I access the properties of the counts
object-- it's a table, right?  If I look at counts[1,1], that returns
1.  But how do I get at the row/col name of that cell?  Is that cell
an object?  rownames(counts[1,1]) returns null.

Thanks,
Matt


On 6/18/07, jim holtman <jholtman at gmail.com> wrote:
> You should be using barplot and not hist.  I think this produces what you
> want:
>
> x <- "filename,last_modified,email_addr,country_residence
>
> file1,3/4/2006 13:54,email1,Korea (South)
> file2,3/4/2006 14:33,email2,United States
> file2,3/4/2006 16:03,email2,United States
> file2,3/4/2006 16:17,email3,United States
> file2,3/4/2006 16:28,email3,United States
> file3,3/4/2006 19:13,email4,United States
> file2,3/4/2006 21:22,email5,India
> file4,3/4/2006 21:46,email6,United States
> file1,3/4/2006 22:04,email7,Japan
> file2,3/4/2006 22:09,email8,Croatia
> file1,3/4/2006 22:22,email7,Japan
> file1,3/4/2006 22:29,email9,India
> file1,3/4/2006 23:06,email6,United States
> file1,3/4/2006 23:33,email6,United States
> file5,3/4/2006 23:44,email10,China
> file1,3/5/2006 0:13,email9,India
> file2,3/5/2006 0:52,email8,Croatia
> file2,3/5/2006 0:54,email8,Croatia
> file2,3/5/2006 1:10,email5,India
> file6,3/5/2006 2:17,email9,India
> file2,3/5/2006 2:24,email11,Italy
> file7,3/5/2006 2:36,email12,Italy
> file8,3/5/2006 2:52,email12,Italy
> file2,3/5/2006 3:09,email13,United Kingdom
> file2,3/5/2006 4:02,email14,India
> file2,3/5/2006 4:07,email14,India
> file2,3/5/2006 4:14,email14,India
> file2,3/5/2006 4:37,email5,India
> file2,3/5/2006 4:44,email15,Belgium
> file1,3/5/2006 5:02,email9,India
> file1,3/5/2006 5:24,email16,Taiwan
> file2,3/5/2006 6:06,email17,Saudi Arabia
> file2,3/5/2006 7:32,email17,Saudi Arabia
> file2,3/5/2006 8:12,email18,Brazil
> file2,3/5/2006 8:26,email18,Brazil
> file2,3/5/2006 9:49,email19,United Kingdom
> file1,3/5/2006 10:49,email11,Italy
> file1,3/5/2006 11:16,email13,United Kingdom
> file1,3/5/2006 11:16,email13,United Kingdom
> file1,3/5/2006 11:45,email13,United Kingdom
> file1,3/5/2006 14:34,email20,Australia
> file9,3/5/2006 14:56,email20,Australia
> file9,3/5/2006 14:56,email20,Australia
> file5,3/5/2006 16:43,email21,United States
> file1,3/5/2006 17:17,email7,Japan
> file2,3/5/2006 17:26,email22,Japan
> file2,3/5/2006 17:27,email22,Japan
> file2,3/5/2006 17:33,email23,China
> file1,3/5/2006 17:45,email22,Japan
> file2,3/5/2006 17:45,email22,Japan
> file2,3/5/2006 17:59,email23,China
> file1,3/5/2006 18:27,email24,Japan
> file1,3/5/2006 18:47,email25,Taiwan
> file2,3/5/2006 18:48,email26,New Zealand
> file2,3/5/2006 19:15,email27,Canada
> file2,3/5/2006 19:23,email28,Canada
> file2,3/5/2006 19:24,email28,Canada
> file10,3/5/2006 19:49,email29,Japan
> file10,3/5/2006 19:52,email29,Japan
> file10,3/5/2006 19:57,email29,Japan
> file2,3/5/2006 20:01,email29,Japan
> file2,3/5/2006 20:02,email29,Japan
> file2,3/5/2006 20:06,email29,Japan"
> d <- read.csv(textConnection(x))
> barplot(table(d$filename), main="All Files", las=2)  # plot counts for all
> the files
> # generate plots for each file name showing which emails used them
> counts <- table(d$filename, d$email_addr)
> for (i in seq(nrow(counts))){
>     .index <- which(counts[i,] > 0)
>     barplot(counts[i, .index], las=2,
>         names.arg=colnames(counts)[.index], main=rownames(counts)[i])
> }
>
>
>
> On 6/18/07, Matthew Trunnell <trunnell at cognix.net> wrote:
> >
> > Hello R gurus,
> >
> > I just spent my first weekend wrestling with R, but so far have come
> > up empty handed.
> >
> > I have a dataset that represents file downloads; it has 4 dimensions:
> > date, filename, email, and country.  (sample data below)
> >
> > My first goal is to get an idea of the frequency of repeated
> > downloads.  Let me explain that.  Some people tend to download
> > multiple times, e.g. if the download fails they keep trying over and
> > over.  I'm trying to build a histogram that shows the repeat count
> > along the x-axis, that is, how many people downloaded once, twice,
> > three times, etc.  I plan to compare the median of that before and
> > after we switched ISPs.
> >
> > To accomplish this, I'm assuming that I'll first need to combine the
> > email and filename columns so as to represent a single download
> > attempt by an individual.  Does that sound right?  Later, it would be
> > nice to limit the histogram to a single filename, country, or company.
> > I can probably figure that out myself after I understand how to write
> > this funky histogram expression.
> >
> > With the help of Verzani's introductory text, I've learned how to read
> > in the CSV data and do some simple tables, like this:
> >
> > hist(table(d$filename))
> > hist(table(d$filename[substring(d$filename, 1,
> 5)=="file1"]))
> > hist(sort(table(d$filename[substring(d$filename, 1,
> 5)=="file1"])))
> >
> > Obviously, these commands count the frequency of the files.  What I'd
> > like to see are the repeats grouped along the x-axis;  I'd like to
> > find, for all files, the distribution of retries.  I hope that makes
> > sense. :)
> >
> > Can someone point me in the right direction?  I'm very new to R and to
> > statistics, but I write code for a living.  At this point I'd almost
> > be better off writing a program do this kind of simple counting... but
> > I have a feeling R would be so useful if I could just get past the
> > initial learning curve.
> >
> > Thank you in advance,
> > Matt
> >
> > Here's some real data, with the private info replaced :)
> >
> > d<-read.table
> (file="C:\\users\\trunnellm\\downloads\\statistics\\downloads.csv",
> > sep=",", quote="\"", header=TRUE)
> >
> > filename,last_modified,email_addr,country_residence
> > file1,3/4/2006 13:54,email1,Korea (South)
> > file2,3/4/2006 14:33,email2,United States
> > file2,3/4/2006 16:03,email2,United States
> > file2,3/4/2006 16:17,email3,United States
> > file2,3/4/2006 16:28,email3,United States
> > file3,3/4/2006 19:13,email4,United States
> > file2,3/4/2006 21:22,email5,India
> > file4,3/4/2006 21:46,email6,United States
> > file1,3/4/2006 22:04,email7,Japan
> > file2,3/4/2006 22:09,email8,Croatia
> > file1,3/4/2006 22:22,email7,Japan
> > file1,3/4/2006 22:29,email9,India
> > file1,3/4/2006 23:06,email6,United States
> > file1,3/4/2006 23:33,email6,United States
> > file5,3/4/2006 23:44,email10,China
> > file1,3/5/2006 0:13,email9,India
> > file2,3/5/2006 0:52,email8,Croatia
> > file2,3/5/2006 0:54,email8,Croatia
> > file2,3/5/2006 1:10,email5,India
> > file6,3/5/2006 2:17,email9,India
> > file2,3/5/2006 2:24,email11,Italy
> > file7,3/5/2006 2:36,email12,Italy
> > file8,3/5/2006 2:52,email12,Italy
> > file2,3/5/2006 3:09,email13,United Kingdom
> > file2,3/5/2006 4:02,email14,India
> > file2,3/5/2006 4:07,email14,India
> > file2,3/5/2006 4:14,email14,India
> > file2,3/5/2006 4:37,email5,India
> > file2,3/5/2006 4:44,email15,Belgium
> > file1,3/5/2006 5:02,email9,India
> > file1,3/5/2006 5:24,email16,Taiwan
> > file2,3/5/2006 6:06,email17,Saudi Arabia
> > file2,3/5/2006 7:32,email17,Saudi Arabia
> > file2,3/5/2006 8:12,email18,Brazil
> > file2,3/5/2006 8:26,email18,Brazil
> > file2,3/5/2006 9:49,email19,United Kingdom
> > file1,3/5/2006 10:49,email11,Italy
> > file1,3/5/2006 11:16,email13,United Kingdom
> > file1,3/5/2006 11:16,email13,United Kingdom
> > file1,3/5/2006 11:45,email13,United Kingdom
> > file1,3/5/2006 14:34,email20,Australia
> > file9,3/5/2006 14:56,email20,Australia
> > file9,3/5/2006 14:56,email20,Australia
> > file5,3/5/2006 16:43,email21,United States
> > file1,3/5/2006 17:17,email7,Japan
> > file2,3/5/2006 17:26,email22,Japan
> > file2,3/5/2006 17:27,email22,Japan
> > file2,3/5/2006 17:33,email23,China
> > file1,3/5/2006 17:45,email22,Japan
> > file2,3/5/2006 17:45,email22,Japan
> > file2,3/5/2006 17:59,email23,China
> > file1,3/5/2006 18:27,email24,Japan
> > file1,3/5/2006 18:47,email25,Taiwan
> > file2,3/5/2006 18:48,email26,New Zealand
> > file2,3/5/2006 19:15,email27,Canada
> > file2,3/5/2006 19:23,email28,Canada
> > file2,3/5/2006 19:24,email28,Canada
> > file10,3/5/2006 19:49,email29,Japan
> > file10,3/5/2006 19:52,email29,Japan
> > file10,3/5/2006 19:57,email29,Japan
> > file2,3/5/2006 20:01,email29,Japan
> > file2,3/5/2006 20:02,email29,Japan
> > file2,3/5/2006 20:06,email29,Japan
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
>
> --
> Jim Holtman
> Cincinnati, OH
> +1 513 646 9390
>
> What is the problem you are trying to solve?


From jholtman at gmail.com  Tue Jun 19 04:30:44 2007
From: jholtman at gmail.com (jim holtman)
Date: Mon, 18 Jun 2007 22:30:44 -0400
Subject: [R] Histograms with strings, grouped by repeat count (w/ data)
In-Reply-To: <572004630706181922p686f60er8e0684bb48c6c04d@mail.gmail.com>
References: <572004630706181807u3f0698f9vb42027951b777b1@mail.gmail.com>
	<644e1f320706181843p76d4192dlf367574973f15142@mail.gmail.com>
	<572004630706181922p686f60er8e0684bb48c6c04d@mail.gmail.com>
Message-ID: <644e1f320706181930m77499f99ye91f01f54817a582@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070618/2666383e/attachment.pl 

From mjankowski at gmail.com  Tue Jun 19 05:01:07 2007
From: mjankowski at gmail.com (M. Jankowski)
Date: Mon, 18 Jun 2007 22:01:07 -0500
Subject: [R] Fwd: Help: Upgrading to R2.5 on Ubuntu (Feisty)
In-Reply-To: <500c63990706181334v732a95ddv8dc4d376960ba0dc@mail.gmail.com>
References: <500c63990706181334v732a95ddv8dc4d376960ba0dc@mail.gmail.com>
Message-ID: <500c63990706182001h16c4539cqff1682dc1f58b8d3@mail.gmail.com>

This fixed my problem: Thanks!

Did you run 'sudo apt-get update' as well so that it actually reads
the listing at CRAN / FHCRC ?

What does 'apt-cache policy r-base' show?  [ It should display the
different vertsions it knows about; if you only see 2.4.1 then you
have a problem which may just be the missing 'apt-get update' ]

Hth, Dirk

---------- Forwarded message ----------
From: M. Jankowski
Date: Jun 18, 2007 3:34 PM
Subject: Help: Upgrading to R2.5 on Ubuntu (Feisty)
To: r-help at stat.math.ethz.ch


Thank you in advance for reading this help request. I am pretty new to
R. I am experiencing some issues getting 2.5 installed on my Ubuntu
Fiesty system and
seek your advice.

To the best of my ability I followed the instructions here:

http://cran.r-project.org/bin/linux/ubuntu/README

Setting this as the last line in my sources.list:
deb http://cran.fhcrc.org/bin/linux/ubuntu feisty/

When I typed in:

mdj at lapmdj:/usr/local/lib/R/site-library$ sudo apt-get install r-base
Reading package lists... Done
Building dependency tree
Reading state information... Done
r-base is already the newest version.
0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.
mdj at lapmdj:/usr/local/lib/R/site-library$

But when I go to R and check my version:

> version
              _
platform       i486-pc-linux-gnu
arch           i486
os             linux-gnu
system         i486, linux-gnu
status
major          2
minor          4.1
year           2006
month          12
day            18
svn rev        40228
language       R
version.string R version 2.4.1 (2006-12-18)
>

My version is still 2.4.1. I must be missing something. What do I need
to do to get R version 2.5 installed on my ubuntu feisty (7.04)
system? Let me know if there is any additional information I need to
give to be helped out with this.

Thank you for taking a look at this,
Sincerely,
Matt


From trunnell at cognix.net  Tue Jun 19 05:14:51 2007
From: trunnell at cognix.net (Matthew Trunnell)
Date: Mon, 18 Jun 2007 20:14:51 -0700
Subject: [R] Histograms with strings, grouped by repeat count (w/ data)
In-Reply-To: <644e1f320706181930m77499f99ye91f01f54817a582@mail.gmail.com>
References: <572004630706181807u3f0698f9vb42027951b777b1@mail.gmail.com>
	<644e1f320706181843p76d4192dlf367574973f15142@mail.gmail.com>
	<572004630706181922p686f60er8e0684bb48c6c04d@mail.gmail.com>
	<644e1f320706181930m77499f99ye91f01f54817a582@mail.gmail.com>
Message-ID: <572004630706182014w7d08b76cyf3254a7c94d2dbaa@mail.gmail.com>

Aha!  So to expand that from the original expression,

> table(table(d$filename, d$email_addr))

  0   1   2   3
253  20   8   9

I think that is exactly what I'm looking for.  I knew it must be
simple!!!  What does the 0 column represent?

Also, does this tell me the same thing, filtered by Japan?
> table(table(d$filename, d$email_addr, d$country_residence)[d$country_residence=="Japan"])

  0   1   2   3
958   5   2   1

How does that differ logically from this?

> table(table(d$filename, d$email_addr)[d$country_residence=="Japan"])

 0  1  2  3
51  4  2  1

I don't understand why that produces different results.  The first one
adds a third dimension to the table, but limits that third dimension
to a single element, Japan.  Shouldn't it be the same?  And again,
what's that zero column?

Thank you,
Matt


On 6/18/07, jim holtman <jholtman at gmail.com> wrote:
> If you are running on windows, make sure you have 'recording' checked in the
> history window of the graphics.  You can also put the output to a pdf file
> and view it later.
>
> If you use table on the counts matrix:
>
> > table(counts)
> counts
>   0   1   2   3
> 253  20   8   9
> >
>
> this shows that there were 20 single tries, 8 files downloaded twice and 9
> three times.  Is this what you want?
>
> You can also get the indices of the non-zero entries by:
>
> > which(counts != 0, arr.ind=TRUE)
>        row col
> file1    1   1
> file5    6   2
> file1    1   3
> file2    3   3
> file7    8   4
> file8    9   4
> file1    1   5
> file2    3   5
> file2    3   6
> .........
>
>
>
>
> On 6/18/07, Matthew Trunnell <trunnell at cognix.net> wrote:
> > Jim,
> > Thanks for the quick reply!  When I run your code, I end up with a
> > single barplot of one datapoint, file9 vs email20 == 2.0.  I see the
> > call to barplot is inside a for loop... maybe it's zooming through the
> > display of many barplots, but all I see is the last one?
> >
> > In any case, I need to figure out the distribution of the retries, such as
> > No. Retries   Count
> > 1                 6
> > 2                 13
> > 3                 5
> > 4                 3
> > 5                 2
> > 6                 1
> >
> > That is, 6 people retried the download once; 13 people retried the
> > download twice, etc.  So it would be counting the frequency of the
> > email-filename combination, and grouping those together by the number
> > of retries.  Does that make sense?
> >
> > When I look at the counts object from your code, I can see that it's
> > close to what I need.  How do I access the properties of the counts
> > object-- it's a table, right?  If I look at counts[1,1], that returns
> > 1.  But how do I get at the row/col name of that cell?  Is that cell
> > an object?  rownames(counts[1,1]) returns null.
> >
> > Thanks,
> > Matt
> >
> >
> > On 6/18/07, jim holtman <jholtman at gmail.com> wrote:
> > > You should be using barplot and not hist.  I think this produces what
> you
> > > want:
> > >
> > > x <-
> "filename,last_modified,email_addr,country_residence
> > >
> > > file1,3/4/2006 13:54,email1,Korea (South)
> > > file2,3/4/2006 14:33,email2,United States
> > > file2,3/4/2006 16:03,email2,United States
> > > file2,3/4/2006 16:17,email3,United States
> > > file2,3/4/2006 16:28,email3,United States
> > > file3,3/4/2006 19:13,email4,United States
> > > file2,3/4/2006 21:22,email5,India
> > > file4,3/4/2006 21:46,email6,United States
> > > file1,3/4/2006 22:04,email7,Japan
> > > file2,3/4/2006 22:09,email8,Croatia
> > > file1,3/4/2006 22:22,email7,Japan
> > > file1,3/4/2006 22:29,email9,India
> > > file1,3/4/2006 23:06,email6,United States
> > > file1,3/4/2006 23:33,email6,United States
> > > file5,3/4/2006 23:44,email10,China
> > > file1,3/5/2006 0:13,email9,India
> > > file2,3/5/2006 0:52,email8,Croatia
> > > file2,3/5/2006 0:54,email8,Croatia
> > > file2,3/5/2006 1:10,email5,India
> > > file6,3/5/2006 2:17,email9,India
> > > file2,3/5/2006 2:24,email11,Italy
> > > file7,3/5/2006 2:36,email12,Italy
> > > file8,3/5/2006 2:52,email12,Italy
> > > file2,3/5/2006 3:09,email13,United Kingdom
> > > file2,3/5/2006 4:02,email14,India
> > > file2,3/5/2006 4:07,email14,India
> > > file2,3/5/2006 4:14,email14,India
> > > file2,3/5/2006 4:37,email5,India
> > > file2,3/5/2006 4:44,email15,Belgium
> > > file1,3/5/2006 5:02,email9,India
> > > file1,3/5/2006 5:24,email16,Taiwan
> > > file2,3/5/2006 6:06,email17,Saudi Arabia
> > > file2,3/5/2006 7:32,email17,Saudi Arabia
> > > file2,3/5/2006 8:12,email18,Brazil
> > > file2,3/5/2006 8:26,email18,Brazil
> > > file2,3/5/2006 9:49,email19,United Kingdom
> > > file1,3/5/2006 10:49,email11,Italy
> > > file1,3/5/2006 11:16,email13,United Kingdom
> > > file1,3/5/2006 11:16,email13,United Kingdom
> > > file1,3/5/2006 11:45,email13,United Kingdom
> > > file1,3/5/2006 14:34,email20,Australia
> > > file9,3/5/2006 14:56,email20,Australia
> > > file9,3/5/2006 14:56,email20,Australia
> > > file5,3/5/2006 16:43,email21,United States
> > > file1,3/5/2006 17:17,email7,Japan
> > > file2,3/5/2006 17:26,email22,Japan
> > > file2,3/5/2006 17:27,email22,Japan
> > > file2,3/5/2006 17:33,email23,China
> > > file1,3/5/2006 17:45,email22,Japan
> > > file2,3/5/2006 17:45,email22,Japan
> > > file2,3/5/2006 17:59,email23,China
> > > file1,3/5/2006 18:27,email24,Japan
> > > file1,3/5/2006 18:47,email25,Taiwan
> > > file2,3/5/2006 18:48,email26,New Zealand
> > > file2,3/5/2006 19:15,email27,Canada
> > > file2,3/5/2006 19:23,email28,Canada
> > > file2,3/5/2006 19:24,email28,Canada
> > > file10,3/5/2006 19:49,email29,Japan
> > > file10,3/5/2006 19:52,email29,Japan
> > > file10,3/5/2006 19:57,email29,Japan
> > > file2,3/5/2006 20:01,email29,Japan
> > > file2,3/5/2006 20:02,email29,Japan
> > > file2,3/5/2006 20:06,email29,Japan"
> > > d <- read.csv(textConnection(x))
> > > barplot(table(d$filename), main="All Files", las=2)  # plot counts for
> all
> > > the files
> > > # generate plots for each file name showing which emails used them
> > > counts <- table(d$filename, d$email_addr)
> > > for (i in seq(nrow(counts))){
> > >     .index <- which(counts[i,] > 0)
> > >     barplot(counts[i, .index], las=2,
> > >         names.arg=colnames(counts)[.index], main=rownames(counts)[i])
> > > }
> > >
> > >
> > >
> > > On 6/18/07, Matthew Trunnell < trunnell at cognix.net> wrote:
> > > >
> > > > Hello R gurus,
> > > >
> > > > I just spent my first weekend wrestling with R, but so far have come
> > > > up empty handed.
> > > >
> > > > I have a dataset that represents file downloads; it has 4 dimensions:
> > > > date, filename, email, and country.  (sample data below)
> > > >
> > > > My first goal is to get an idea of the frequency of repeated
> > > > downloads.  Let me explain that.  Some people tend to download
> > > > multiple times, e.g. if the download fails they keep trying over and
> > > > over.  I'm trying to build a histogram that shows the repeat count
> > > > along the x-axis, that is, how many people downloaded once, twice,
> > > > three times, etc.  I plan to compare the median of that before and
> > > > after we switched ISPs.
> > > >
> > > > To accomplish this, I'm assuming that I'll first need to combine the
> > > > email and filename columns so as to represent a single download
> > > > attempt by an individual.  Does that sound right?  Later, it would be
> > > > nice to limit the histogram to a single filename, country, or company.
> > > > I can probably figure that out myself after I understand how to write
> > > > this funky histogram expression.
> > > >
> > > > With the help of Verzani's introductory text, I've learned how to read
> > > > in the CSV data and do some simple tables, like this:
> > > >
> > > > hist(table(d$filename))
> > > > hist(table(d$filename[substring(d$filename, 1,
> > > 5)=="file1"]))
> > > > hist(sort(table(d$filename[substring(d$filename, 1,
> > > 5)=="file1"])))
> > > >
> > > > Obviously, these commands count the frequency of the files.  What I'd
> > > > like to see are the repeats grouped along the x-axis;  I'd like to
> > > > find, for all files, the distribution of retries.  I hope that makes
> > > > sense. :)
> > > >
> > > > Can someone point me in the right direction?  I'm very new to R and to
> > > > statistics, but I write code for a living.  At this point I'd almost
> > > > be better off writing a program do this kind of simple counting... but
> > > > I have a feeling R would be so useful if I could just get past the
> > > > initial learning curve.
> > > >
> > > > Thank you in advance,
> > > > Matt
> > > >
> > > > Here's some real data, with the private info replaced :)
> > > >
> > > > d<-read.table
> > >
> (file="C:\\users\\trunnellm\\downloads\\statistics\\downloads.csv",
> > > > sep=",", quote="\"", header=TRUE)
> > > >
> > > > filename,last_modified,email_addr,country_residence
> > > > file1,3/4/2006 13:54,email1,Korea (South)
> > > > file2,3/4/2006 14:33,email2,United States
> > > > file2,3/4/2006 16:03,email2,United States
> > > > file2,3/4/2006 16:17,email3,United States
> > > > file2,3/4/2006 16:28,email3,United States
> > > > file3,3/4/2006 19:13,email4,United States
> > > > file2,3/4/2006 21:22,email5,India
> > > > file4,3/4/2006 21:46,email6,United States
> > > > file1,3/4/2006 22:04,email7,Japan
> > > > file2,3/4/2006 22:09,email8,Croatia
> > > > file1,3/4/2006 22:22,email7,Japan
> > > > file1,3/4/2006 22:29,email9,India
> > > > file1,3/4/2006 23:06,email6,United States
> > > > file1,3/4/2006 23:33,email6,United States
> > > > file5,3/4/2006 23:44,email10,China
> > > > file1,3/5/2006 0:13,email9,India
> > > > file2,3/5/2006 0:52,email8,Croatia
> > > > file2,3/5/2006 0:54,email8,Croatia
> > > > file2,3/5/2006 1:10,email5,India
> > > > file6,3/5/2006 2:17,email9,India
> > > > file2,3/5/2006 2:24,email11,Italy
> > > > file7,3/5/2006 2:36,email12,Italy
> > > > file8,3/5/2006 2:52,email12,Italy
> > > > file2,3/5/2006 3:09,email13,United Kingdom
> > > > file2,3/5/2006 4:02,email14,India
> > > > file2,3/5/2006 4:07,email14,India
> > > > file2,3/5/2006 4:14,email14,India
> > > > file2,3/5/2006 4:37,email5,India
> > > > file2,3/5/2006 4:44,email15,Belgium
> > > > file1,3/5/2006 5:02,email9,India
> > > > file1,3/5/2006 5:24,email16,Taiwan
> > > > file2,3/5/2006 6:06,email17,Saudi Arabia
> > > > file2,3/5/2006 7:32,email17,Saudi Arabia
> > > > file2,3/5/2006 8:12,email18,Brazil
> > > > file2,3/5/2006 8:26,email18,Brazil
> > > > file2,3/5/2006 9:49,email19,United Kingdom
> > > > file1,3/5/2006 10:49,email11,Italy
> > > > file1,3/5/2006 11:16,email13,United Kingdom
> > > > file1,3/5/2006 11:16,email13,United Kingdom
> > > > file1,3/5/2006 11:45,email13,United Kingdom
> > > > file1,3/5/2006 14:34,email20,Australia
> > > > file9,3/5/2006 14:56,email20,Australia
> > > > file9,3/5/2006 14:56,email20,Australia
> > > > file5,3/5/2006 16:43,email21,United States
> > > > file1,3/5/2006 17:17,email7,Japan
> > > > file2,3/5/2006 17:26,email22,Japan
> > > > file2,3/5/2006 17:27,email22,Japan
> > > > file2,3/5/2006 17:33,email23,China
> > > > file1,3/5/2006 17:45,email22,Japan
> > > > file2,3/5/2006 17:45,email22,Japan
> > > > file2,3/5/2006 17:59,email23,China
> > > > file1,3/5/2006 18:27,email24,Japan
> > > > file1,3/5/2006 18:47,email25,Taiwan
> > > > file2,3/5/2006 18:48,email26,New Zealand
> > > > file2,3/5/2006 19:15,email27,Canada
> > > > file2,3/5/2006 19:23,email28,Canada
> > > > file2,3/5/2006 19:24,email28,Canada
> > > > file10,3/5/2006 19:49,email29,Japan
> > > > file10,3/5/2006 19:52,email29,Japan
> > > > file10,3/5/2006 19:57,email29,Japan
> > > > file2,3/5/2006 20:01,email29,Japan
> > > > file2,3/5/2006 20:02,email29,Japan
> > > > file2,3/5/2006 20:06,email29,Japan
> > > >
> > > > ______________________________________________
> > > > R-help at stat.math.ethz.ch mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > > >
> > >
> > >
> > >
> > > --
> > > Jim Holtman
> > > Cincinnati, OH
> > > +1 513 646 9390
> > >
> > > What is the problem you are trying to solve?
> >
>
>
>
> --
>
> Jim Holtman
> Cincinnati, OH
> +1 513 646 9390
>
> What is the problem you are trying to solve?


From bigic at ucsd.edu  Tue Jun 19 06:24:19 2007
From: bigic at ucsd.edu (Boris Igic)
Date: Mon, 18 Jun 2007 21:24:19 -0700 (PDT)
Subject: [R] Iterative Solver [Converting Matlab's solve()]
Message-ID: <Pine.GSO.4.64.0706182102470.4484@biomail>

I can't for the life of me figure out how to get the roots for this simple
(but sovable only iteratively) equation in R:

x = z*(1-(1-2/z)^y

where x and y are known, and z is unknown. In Matlab, this amounts to:

[my.solution] = solve('x = z*(1-(1-2/z)^y') 
my.solution.real = solution(y-1,y)

% bottom line displays non-imaginary solution (last element)

Obviously, I'm deeply unqualified as a mathematician or programmer and 
regret wasting your time if this question is really basic. I would very 
much appreciate even the smallest morsel of time that you might spend on 
this, and yes, you could be my hero.

Many Thanks,

Boris

P.S. The above equation is from: Paxman GJ (1963). Maximum likelihood 
estimation of the number of self-sterility alleles in a population. 
Genetics 48: 1029-1032.


From ral at lcfltd.com  Tue Jun 19 07:40:23 2007
From: ral at lcfltd.com (Robert A LaBudde)
Date: Tue, 19 Jun 2007 01:40:23 -0400
Subject: [R] Iterative Solver [Converting Matlab's solve()]
In-Reply-To: <Pine.GSO.4.64.0706182102470.4484@biomail>
References: <Pine.GSO.4.64.0706182102470.4484@biomail>
Message-ID: <0JJV00JDUBRFEQQ3@vms046.mailsrvcs.net>

At 12:24 AM 6/19/2007, Boris wrote:
>I can't for the life of me figure out how to get the roots for this simple
>(but sovable only iteratively) equation in R:
>
>x = z*(1-(1-2/z)^y
>
>where x and y are known, and z is unknown. In Matlab, this amounts to:
>
>[my.solution] = solve('x = z*(1-(1-2/z)^y')
>my.solution.real = solution(y-1,y)
>
>% bottom line displays non-imaginary solution (last element)
><snip>

1.  Your equation is syntactically incorrect. It is missing a ")". 
Ditto for your Matlab example.

2. Are you looking for an analytical (symbolic) solution? If so, I 
don't believe one exists (if you place a ")" after y).

3. To find numerical roots, see uniroot().

4. If you want more help, you'll have to specify domains or values for x and y.

================================================================
Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
824 Timberlake Drive                     Tel: 757-467-0954
Virginia Beach, VA 23464-3239            Fax: 757-467-2947

"Vere scire est per causas scire"


From brown_emu at yahoo.com  Tue Jun 19 07:47:17 2007
From: brown_emu at yahoo.com (Stephen Tucker)
Date: Mon, 18 Jun 2007 22:47:17 -0700 (PDT)
Subject: [R] data type for block data?
In-Reply-To: <467701FE.80707@scripps.edu>
Message-ID: <430962.72268.qm@web39715.mail.mud.yahoo.com>

Hi Paul,

Hope this is what you're looking for:

## reading in text (the first 13 rows of cc from your posting)
## and using smaller indices [(3,8) instead of (10,40)]
## for this example
> cc <- "mode<-"(do.call(rbind,
+        strsplit(readLines(textConnection(txt))[-1],"[ ]{2,}"))[,-1],
+        "numeric")
> index <- c(3,8)

## (1) convert cc to data frame
## (2) split according to factors produced by cut()
## (3) apply data.matrix() to each element of list
##     produced by split() to convert back to numeric matrix
> s <- lapply(split(as.data.frame(cc),
+                   f=cut(1:nrow(cc),breaks=c(-Inf,index,Inf))),
+             data.matrix)

## return result. now s[[1]] contains the first "block",
## s[[2]] contains the second "block", and so on.
> s
$`(-Inf,3]`
  V1 V2
1  1 26
2  2 27
3  3 28

$`(3,8]`
  V1 V2
4  4 29
5  5 30
6  6 31
7  7 32
8  8 33

$`(8, Inf]`
   V1 V2
9   9 34
10  1 27
11  1 28
12  2 30
13  3 34


--- "H. Paul Benton" <hpbenton at scripps.edu> wrote:

> Dear All,
> 
> 
>     I have a matrix with data that is not organised. I would like to go
> through this and extract it. Each feature has 2 vectors which express
> the data. I also have an index of the places where the data should be cut.
> eg.
> >class(cc)
> "matrix"
> >cc
>       [,1] [,2]
>  [1,]    1   26
>  [2,]    2   27
>  [3,]    3   28
>  [4,]    4   29
>  [5,]    5   30
>  [6,]    6   31
>  [7,]    7   32
>  [8,]    8   33
>  [9,]    9   34
> [10,]    1   27
> [11,]    1   28
> [12,]    2   30
> [13,]    3   34
> ect......
> > index
> [1] "10" "40"
> 
> 
> Is there a way to take cc[i:index[i-1],] to another format as to where
> each block could be worked on separately. ie so in one block would be
> rows1:10 the next block would be rows11:40 and so on.
> 
> Thanks,
> 
> Paul
> 
> 
> 
> -- 
> Research Technician
> Mass Spectrometry
>    o The
>   /
> o Scripps
>   \
>    o Research
>   /
> o Institute
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From maechler at stat.math.ethz.ch  Tue Jun 19 08:52:59 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 19 Jun 2007 08:52:59 +0200
Subject: [R] Augment 'Matrix' matrices
In-Reply-To: <20070618165900.AJV44868@mymail.byuh.edu>
References: <20070618165900.AJV44868@mymail.byuh.edu>
Message-ID: <18039.32075.893955.254221@stat.math.ethz.ch>

>>>>> "SH" == Scott Hyde <hydes at byuh.edu>
>>>>>     on Mon, 18 Jun 2007 16:59:00 -1000 (HST) writes:

    SH> Martin, How does Matrix implement augmented matrices?  I
    SH> tried this and got the expected result:


{Replying to  R-help,  since this question has come up several
 times }

    >> V=matrix(1,2,3)
    >> V=cbind(V,V)
    >> V
    SH>      [,1] [,2] [,3] [,4] [,5] [,6]
    SH> [1,]    1    1    1    1    1    1
    SH> [2,]    1    1    1    1    1    1

    SH> But when I did it with Matrix instead I got:

    >> library(Matrix)

    >> V=Matrix(1,2,3)
    >> V=cbind(V,V)
    >> V
    SH> V V
    SH> [1,] ? ?

cbind() and rbind() cannot work with S4 objects because their
first formal argument is  '...'
[ and with S3 objects they only work insofar as S3 generics can
  "work": i.e. they only "work" when the first argument is of the
  respective class, but fail, e.g. for  cbind(1, <object>)
  when <object> is of a non-standard S3 class.
]
In earlier versions of Matrix, there was a sophisticated "hack"
that made  cbind() and rbind()   "work".

But because it was a hack, and some people called it "horrible"
rather than "sophisticated", we had to give it up.
{well, the really compelling argument was an example of
 do.call(rbind, <list of length 1000>) which was *very* inefficient}

Instead, cbind2() and rbind2() have been written a
few R versions ago to be used as (S4) generic functions. 
-->  help(cbind2)

In 'Matrix', we also define cBind() and rBind()  to be used as
direct (n-argument) substitutes for cbind() or rbind(),
respectively.

Martin


From h.wickham at gmail.com  Tue Jun 19 09:07:26 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 19 Jun 2007 09:07:26 +0200
Subject: [R] [R-pkgs] ggplot2 0.5.2
Message-ID: <f8e6ff050706190007v2c236c2dn3ddb5de02d4b879d@mail.gmail.com>

ggplot2
===================================

ggplot2 is a plotting system for R, based on the grammar of graphics,
which tries to take the good parts of base and lattice graphics and
none of the bad parts. It takes care of many of the fiddly details
that make plotting a hassle (like drawing legends) as well as
providing a powerful model of graphics that makes it easy to produce
complex multi-layered graphics.

Find out more at http://had.co.nz/ggplot2

Changes in version 0.5.2 ------------------------------

* add argument to position dodge so it's now possible to accurately
dodge things with different widths to their physical widths
* added median summary
* new examples:
	* logistic regression example in stat_smooth
* bugs fixed:
	* evaluation of arguments to layer is no longer delayed
	* can use categorical xseq with stat_smooth
	* x and y axes named incorrectly (thanks to Dieter Menne for spotting this)
	* can now pass position objects to qplot
	* y jitter calculated correctly, and jittered data rescales axis now
	* removed silly legend from quantile plot
	* extra arguments not being passed on to geoms/stats
	* fixed bug in stat_summary when summarising a factor
	* fixed bugs in stat_summary, geom_ribbon, and coord_trans examples

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages


From lewinger at usc.edu  Tue Jun 19 09:35:06 2007
From: lewinger at usc.edu (Juan Pablo Lewinger)
Date: Tue, 19 Jun 2007 00:35:06 -0700
Subject: [R] Controlling text and strip arrangement in xyplot
Message-ID: <0JJV0059QH2O47D0@msg-mx5.usc.edu>

I've searched the archives and read the xyplot help but can't figure 
out the 2 lattice questions below?

Consider:

library(lattice)
DF <- data.frame(x=rnorm(20), y=rnorm(20), g1=rep(letters[1:2], 10),
                  g2=rep(LETTERS[1:2], each=10), 
g3=rep(rep(letters[3:4],each=5),2))

xyplot(y ~ x | g1 + g2, groups=g3, data=DF)

1) Is there a way to get one strip per row and column of panels as 
below instead of the default?


        _|__a__|__b__|
         |
       B
         |
        --
         |
       A
         |

2) How do I control the text of the strips so that for instance 
instead of "a" and "b" it reads"g1=alpha", "g1=beta" where "alpha" 
and "beta" stand for the corresponding greek symbols? (my difficulty 
here is not with the plotmath symbols but with controlling the text 
of the strips directly from the call to xyplot and not by renaming 
the levels of g1)

I'd appreciate any help!


Juan Pablo Lewinger
Department of Preventive Medicine
Keck School of Medicine
University of Southern California


From wht_crl at yahoo.com  Tue Jun 19 10:00:15 2007
From: wht_crl at yahoo.com (carol white)
Date: Tue, 19 Jun 2007 01:00:15 -0700 (PDT)
Subject: [R] application of ridge function to all predictors
Message-ID: <346419.56407.qm@web62008.mail.re1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070619/5487cd3b/attachment.pl 

From rsumbaly at gmail.com  Tue Jun 19 10:02:23 2007
From: rsumbaly at gmail.com (Roshan Sumbaly)
Date: Tue, 19 Jun 2007 13:32:23 +0530
Subject: [R] Help in ARIMA
Message-ID: <4e29a5d60706190102l6e23aa6end022d6b63709355d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070619/3ffde860/attachment.pl 

From h.wickham at gmail.com  Tue Jun 19 10:06:31 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 19 Jun 2007 10:06:31 +0200
Subject: [R] Controlling text and strip arrangement in xyplot
In-Reply-To: <0JJV0059QH2O47D0@msg-mx5.usc.edu>
References: <0JJV0059QH2O47D0@msg-mx5.usc.edu>
Message-ID: <f8e6ff050706190106u64c1fb81nefb8b188997d13bb@mail.gmail.com>

On 6/19/07, Juan Pablo Lewinger <lewinger at usc.edu> wrote:
> I've searched the archives and read the xyplot help but can't figure
> out the 2 lattice questions below?
>
> Consider:
>
> library(lattice)
> DF <- data.frame(x=rnorm(20), y=rnorm(20), g1=rep(letters[1:2], 10),
>                   g2=rep(LETTERS[1:2], each=10),
> g3=rep(rep(letters[3:4],each=5),2))
>
> xyplot(y ~ x | g1 + g2, groups=g3, data=DF)
>
> 1) Is there a way to get one strip per row and column of panels as
> below instead of the default?
>
>
>         _|__a__|__b__|
>          |
>        B
>          |
>         --
>          |
>        A
>          |

Instead of using lattice, you could use ggplot2
(http://had.co.nz/ggplot2), where this is the default:

(p <- qplot(x, y, data=DF, facets = g1 ~ g2))

> 2) How do I control the text of the strips so that for instance
> instead of "a" and "b" it reads"g1=alpha", "g1=beta" where "alpha"
> and "beta" stand for the corresponding greek symbols? (my difficulty
> here is not with the plotmath symbols but with controlling the text
> of the strips directly from the call to xyplot and not by renaming
> the levels of g1)

It's also possible to do this in ggplot, but some bugs currently stop
it from working. It will work in the next version to be released next
week:

p$strip.text <- function(variable, value) {
	greek <- c("A" = "alpha", "B" = "beta")[value]
	makelabel <- function(g) substitute(variable == greek,
list(variable=as.name(variable), greek=as.name(g)))

	lapply(greek, makelabel)
}
p

Hadley


From nitish at imtech.res.in  Tue Jun 19 10:14:12 2007
From: nitish at imtech.res.in (Nitish Kumar Mishra)
Date: Tue, 19 Jun 2007 13:44:12 +0530 (IST)
Subject: [R] About Genetic Algorithm package
Message-ID: <46213.59.160.112.37.1182240852.squirrel@webmail.imtech.res.in>

Hi R-help group member,
Please give me idea about Genetic algorithm and Simulated anealing package
in R(Unix). I want to use this for the feature selection in
Chemoinformatics.
Thanking you.


-- 
Nitish Kumar Mishra
Junior Research Fellow
BIC, IMTECH, Chandigarh, India
E-Mail Address:
nitish_km at yahoo.com
nitish at imtech.res.in


From j.logsdon at quantex-research.com  Tue Jun 19 11:04:08 2007
From: j.logsdon at quantex-research.com (John Logsdon)
Date: Tue, 19 Jun 2007 10:04:08 +0100
Subject: [R] Unix-like permissions to allow a user to update recommen
In-Reply-To: <20070618202756.GZ4805@ihug.co.nz>
References: <20070618101143.GY4805@ihug.co.nz>
	<XFMail.070618115322.ted.harding@nessie.mcc.ac.uk>
	<20070618202756.GZ4805@ihug.co.nz>
Message-ID: <200706191004.08129.j.logsdon@quantex-research.com>

R-ists

When you move from version to version of R a completely new directory tree is 
installed so in principal if you *know* that a package is not updated you can 
re-install it from the old tree or copy it to your new tree and install it.

Maybe an 'import packages from previous versions' could be included which 
would search  for other installations, offer a choice if >1 and automatically 
pick out the list of old packages again offering the user to check/uncheck 
each package.  Then the action would import or download updated versions as 
appropriate...

What would be more useful (and I don't really think this is the right list) is 
to have permissions and a date stamp attached to each object and to extend 
the ls() command to be able to select or sort on these aspects of an object, 
also the size - just like Unix in fact (perhaps with more comprehensive 
permissions although the group/world structures are not needed).

This is because as memory increases, I guess many people do what I do and 
create all their objects in the workspace - then forget when we wrote and 
when!

On Monday 18 June 2007 21:27:56 Patrick Connolly wrote:
> On Mon, 18-Jun-2007 at 11:53AM +0100, Ted Harding wrote:
> |> On 18-Jun-07 10:11:43, Patrick Connolly wrote:
> |> > I installed R from the tar.gz file (as root) in a directory under
> |> > /usr/local.  The recommended packages are installed in a library in
> |> > that directory whereas additional packages I install in a directory
> |> > under the /home directory as a user.
> |> >
> |> > Updating the additional packages is very easy with update.packages()
> |> > as a non-root user, but the recommended packages cannot be done so
> |> > readily because of file permissions.
> |> >
> |> > My question is how do I set the permissions or ownerships in the
> |> > /usr/local/R-2.5.0 directory so that everything necessary can be
> |> > writable by a user?  Should I make a group for R users (total of one
> |> > member) or is it simpler than that?
> |>
> |> Since you have root access, do you need to segregate the additional
> |> packages to a particular user?
>
> It's handy to not have to reload packages that don't change between
> versions of the basic installation.
>
> |> Though I don't run R as root for general use, I always install/update
> |> by running R CMD as root. This makes all of R ("recommended" and also
> |> any extras) available system-wide, and no pemission problems arise.
> |>
> |> This of course does not stop you from setting up a special .Rprofile
> |> for each user, since this by definition lives in the user's home
> |> directory.
> |>
> |> Does this help? Or are there issues you haven't mentioned which make
> |> such an approach not feasible?
>
> I don't exactly have issues.  It's not a huge problem I'm dealing
> with.  It's simple enough for me to use update.packages() as a user
> which will download the appropriate packages.  Though they won't be
> installed, they are all in the one place in the /tmp/ directory from
> where I can install them as root.  I just thought there must be a more
> elegant way to set permissions so that users could write to the
> subdirectories under /usr/local/R-2.xxx/.  So much of the installation
> process of R and its packages is so elegant, I'd like to retain some
> of that elegance.
>
> best



-- 
Best wishes

John

John Logsdon                               "Try to make things as simple
Quantex Research Ltd, Manchester UK         as possible but not simpler"
j.logsdon at quantex-research.com              a.einstein at relativity.org
+44(0)161 445 4951/G:+44(0)7717758675       www.quantex-research.com


From ken.feng at citi.com  Tue Jun 19 11:11:58 2007
From: ken.feng at citi.com (Feng, Ken )
Date: Tue, 19 Jun 2007 18:11:58 +0900
Subject: [R] How do I avoid a loop?
Message-ID: <0143A263BEF94644AC0D4027373EECD3054309AE@exyhmb08.jpn.nsroot.net>

Hi,

I start with an array of booleans:

	x <- c( TRUE, TRUE, TRUE, FALSE, FALSE, TRUE, TRUE, FALSE, TRUE );

I want to define an y <- f(x) such that:

	y <- c( 1, 2, 3, 0, 0, 1, 2, 0, 1 );

In other words, do a cumsum when I see a TRUE, but reset to 0 if I see a FALSE.

I know I can do this with a very slow and ugly loop or maybe use apply,
but I was hoping there are some R experts out there who can show me
a cleaner/more elegant solution?

Thanks in advance.

- Ken


From j.logsdon at quantex-research.com  Tue Jun 19 11:17:48 2007
From: j.logsdon at quantex-research.com (John Logsdon)
Date: Tue, 19 Jun 2007 10:17:48 +0100
Subject: [R] psm/survreg coefficient values ?
In-Reply-To: <4676FFA6.7090309@vanderbilt.edu>
References: <1c6126db0706181318n3cd9bd29kf4f728cec80fe0e4@mail.gmail.com>
	<4676FFA6.7090309@vanderbilt.edu>
Message-ID: <200706191017.48673.j.logsdon@quantex-research.com>

In survreg() the predictor is log(characteristic life) for Weibull (= 
exponential when scale=1) - ie the 63.2%ile.  For the others the predictor is 
log(median).

This causes problems when comparing predictions and a better way IMHO is to 
correct the Weibull prediction by a factor (log(2))^(1/scale).  This is only 
a simple multiple unless the shape parameter is also being modelled, when a 
completely different solution may arise.  Such heterogeneity modelling cannot 
of course be done within survreg().

On Monday 18 June 2007 22:56:54 Frank E Harrell Jr wrote:
> sj wrote:
> > I am using psm to model some parametric survival data, the data is for
> > length of stay in an emergency department. There are several ways a
> > patient's stay in the emergency department can end (discharge, admit,
> > etc..) so I am looking at modeling the effects of several covariates on
> > the various outcomes. Initially I am trying to fit a  survival model for
> > each type of outcome using the psm function in the design package,  i.e.,
> > all  patients who's visits  come to an end  due to  any event other than
> > the event of interest are considered to be censored.  Being new to the
> > psm and  survreg packages (and to parametric survival modeling) I am not
> > entirely sure how to interpret the coefficient values that psm returns. I
> > have included the following code to illustrate code similar to what I am
> > using on my data. I suppose that the coefficients are somehow rescaled ,
> > but I am not sure how to return them to the original scale and make sense
> > out of the coefficients, e.g., estimate the the effect of higher acuity
> > on time to event in minutes. Any explanation or direction on how to
> > interpret the  coefficient values would be greatly appreciated.
> >
> > this is from the documentation for survreg.object.
> > coefficientsthe coefficients of the linear.predictors, which multiply the
> > columns of the model matrix. It does not include the estimate of error
> > (sigma). The names of the coefficients are the names of the
> > single-degree-of-freedom effects (the columns of the model matrix). If
> > the model is over-determined there will be missing values in the
> > coefficients corresponding to non-estimable coefficients.
> >
> > code:
> > LOS <- sort(rweibull(1000,1.4,108))
> > AGE <- sort(rnorm(1000,41,12))
> > ACUITY <- sort(rep(1:5,200))
> > EVENT <-  sample(x=c(0,1),replace=TRUE,1000)
> > psm(Surv(LOS,EVENT)~AGE+as.factor(ACUITY),dist='weibull')
> >
> > output:
> >
> > psm(formula = Surv(LOS, CENS) ~ AGE + as.factor(ACUITY), dist =
> > "weibull")
> >
> >        Obs     Events Model L.R.       d.f.          P         R2
> >       1000        513    2387.62          5          0       0.91
> >
> >               Value          Std. Error      z         p
> > (Intercept)     1.1055    0.04425  24.98 8.92e-138
> > AGE             0.0772    0.00152  50.93  0.00e+00
> > ACUITY=2     0.0944    0.01357   6.96  3.39e-12
> > ACUITY=3     0.1752    0.02111   8.30  1.03e-16
> > ACUITY=4     0.1391    0.02722   5.11  3.18e-07
> > ACUITY=5    -0.0544    0.03789  -1.43  1.51e-01
> > Log(scale)    -2.7287    0.03780 -72.18  0.00e+00
> >
> > Scale= 0.0653
> >
> > best,
> >
> > Spencer
>
> I have a case study using psm (survreg wrapper) in my book.  Briefly,
> coefficients are on the log median survival time scale.
>
> Frank



-- 
Best wishes

John

John Logsdon                               "Try to make things as simple
Quantex Research Ltd, Manchester UK         as possible but not simpler"
j.logsdon at quantex-research.com              a.einstein at relativity.org
+44(0)161 445 4951/G:+44(0)7717758675       www.quantex-research.com


From elyakhlifi_mustapha at yahoo.fr  Tue Jun 19 11:29:17 2007
From: elyakhlifi_mustapha at yahoo.fr (elyakhlifi mustapha)
Date: Tue, 19 Jun 2007 09:29:17 +0000 (GMT)
Subject: [R] outlying
Message-ID: <453961.78951.qm@web27503.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070619/c49ca217/attachment.pl 

From p_connolly at ihug.co.nz  Tue Jun 19 11:41:45 2007
From: p_connolly at ihug.co.nz (Patrick Connolly)
Date: Tue, 19 Jun 2007 21:41:45 +1200
Subject: [R] Unix-like permissions to allow a user to update recommen
In-Reply-To: <XFMail.070618222529.ted.harding@nessie.mcc.ac.uk>
References: <20070618202756.GZ4805@ihug.co.nz>
	<XFMail.070618222529.ted.harding@nessie.mcc.ac.uk>
Message-ID: <20070619094145.GA4805@ihug.co.nz>

On Mon, 18-Jun-2007 at 10:25PM +0100, Ted Harding wrote:

[....]

|> I'm still wondering, though, why you don't just run the command
|> update.packages() as root. You have root access, and you said (in
|> the "adding user to group" context) that only one user is involved
|> (presumably yourself?). In that case, why not start R as root and
|> run update.packages()?

That's probably slightly simpler than what I described.  I never think
of running R as root, so I never thought of that, but it's not as
elegant as I'd have imagined.

Since nobody has suggested a way of modifying the permissions to make
what I was thinking of possible, perhaps it really isn't.

Thanks for that suggestion.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}          		 Great minds discuss ideas    
 _( Y )_  	  	        Middle minds discuss events 
(:_~*~_:) 	       		 Small minds discuss people  
 (_)-(_)  	                           ..... Anon
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From Jouni.Junnila at PERKINELMER.COM  Tue Jun 19 12:08:23 2007
From: Jouni.Junnila at PERKINELMER.COM (Junnila, Jouni)
Date: Tue, 19 Jun 2007 11:08:23 +0100
Subject: [R] Problem with binding data-frames
In-Reply-To: <Pine.LNX.4.64.0706181212040.5272@gannet.stats.ox.ac.uk>
Message-ID: <9202D193C49A974F9DC63C32B28918D0A1570D@EMEAMAIL01.PERKINELMER.NET>

Hi, 

Yes, I'm aware that the problem is that I have differing number of
columns in the different datasets. My question still remains. Is there
some way I can allow column numbers to be different, or is there some
other way combining these datasets?

Thanks,
-Jouni

On Mon, 18 Jun 2007, Petr Klasterecky wrote:

> Junnila, Jouni napsal(a):
>> Hello,
>>
>> I'm having a problem concerning r-binding datasets.
>>
>> I have six datasets, from six different plates, and two different
days.
>> I want to combine these datasets together for analysis. Datasets from

>> day 2, have all the same columns than datasets from day 1. However in

>> addition, there are few columns more in day 2. Thus, using rbind for 
>> this, results a error, because the objects are not the same length.
>>
>> Error in paste(nmi[nii == 0L], collapse = ", ") :
>>         object "nii" not found
>> In addition: Warning message:
>> longer object length
>>         is not a multiple of shorter object length in: clabs == nmi
>
> Hi,
>
> 1. the error has nothing to do with differing lengths of your objects 
> - that's what the following warning is about. The error occured 
> because your indexing object 'nii' does not exist where R is looking
for it.

It's because the dataframes have differing number of columns, and that
has not been allowed for in the error message in that version of R.

> 2. using rbind on dataframes is a bad practice, since the input is 
> converted to marices if possible. Use merge() instead.

Not so: rbind on data frames does no such conversion, and is not
problematic provided they have the same column names (and hence the same
number of columns).  You may have missed in ?rbind

      The functions 'cbind' and 'rbind' are S3 generic, with methods for
      data frames.  The data frame method will be used if at least one
      argument is a data frame and the rest are vectors or matrices.
...

and a later description of the data frame method for 'rbind'.

>
> Petr
>
>>
>>
>> What I need, is to combine all the six together, and give for example

>> NA-value in day 1, for those columns which can only be found in day
2.
>> Is this somehow possible?
>>
>> I have several of these six-datasets groups, and only few of them are

>> having this problem described above, and I cannot know in advance
which.
>> With most of the groups writing
>> rbind(data1,data2,data3,data4,data5,data6)
>> works easily, but these few problematic groups need also to be 
>> combined...
>> Any help greatly appreciated!
>>
>> -Jouni
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Tue Jun 19 12:10:05 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 19 Jun 2007 11:10:05 +0100 (BST)
Subject: [R] How to install RMySQL package in R 2.5 in Windows OS?
In-Reply-To: <4670ADB8.8010307@aol.com>
References: <000001c7adb1$7f4bd000$7000a8c0@scbit94ec75129>
	<Pine.LNX.4.64.0706131603430.14002@gannet.stats.ox.ac.uk>
	<4670ADB8.8010307@aol.com>
Message-ID: <Pine.LNX.4.64.0706191105000.30490@gannet.stats.ox.ac.uk>

I can confirm problems with the current mysql 5.0.41: I get

> library(RMySQL)
Loading required package: DBI
Error in dyn.load(x, as.logical(local), as.logical(now)) :
         unable to load shared library 
'd:/R/library/RMySQL/libs/RMySQL.dll':
   LoadLibrary failure:  Invalid access to memory location.

I do have a successful build with 5.0.21 (the version I have been testing 
RODBC against), and have put that on my repository so it will 
automatically be available to Windows users.

The mysql 5.0.41 problem occurs equally with that pre-built RMySQL binary 
and with a build from the sources.

My Linux box is running 5.0.27, and RMySQL works there.

On Wed, 13 Jun 2007, Joe W. Byers wrote:

> Prof Brian Ripley wrote:
>> On Wed, 13 Jun 2007, Ruixin ZHU wrote:
>> 
>>> Dear R-users,
>>> 
>>> It seems that install.packages( ) doesn't work to RMySQL package.
>> 
>> Under Windows, yes.  You need the MySQL client libraries for your version 
>> of MySQL (or something very close to the same version), so the only safe 
>> way is to install from the sources.  The latter is not hard and there are 
>> instructions in the package.
> There are several of us working on updating the RMySQL binary for windows. 
> Currently one has it compiled with mysql 5.0.18, but can't get it to compile 
> with 5.0.41.  I am having trouble with 5.0.22,  5.0.24, and 5.0.37 mysql 
> binaries.  There seems to be some problems with different versions of mysql. 
> As soon as we have a tested version of the windows binary for RMySQL, 
> information for obtaining it will be posted.
>
> We all appreciate you patiences.
>
> Thank you
> Joe
>
>
>> 
>> 
>>> Would anybody have the experience of that?
>>> 
>>> Thanks
>>> _____________________________________________
>>> Dr.Ruixin ZHU
>>> Shanghai Center for Bioinformation Technology
>>> rxzhu at scbit.org
>>> zhurx at mail.sioc.ac.cn
>>> 86-21-13040647832
>>> 
>>>
>>>  [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Tue Jun 19 12:19:23 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 19 Jun 2007 11:19:23 +0100 (BST)
Subject: [R] Problem with binding data-frames
In-Reply-To: <9202D193C49A974F9DC63C32B28918D0A1570D@EMEAMAIL01.PERKINELMER.NET>
References: <9202D193C49A974F9DC63C32B28918D0A1570D@EMEAMAIL01.PERKINELMER.NET>
Message-ID: <Pine.LNX.4.64.0706191111140.30490@gannet.stats.ox.ac.uk>

On Tue, 19 Jun 2007, Junnila, Jouni wrote:

> Hi,
>
> Yes, I'm aware that the problem is that I have differing number of
> columns in the different datasets. My question still remains. Is there
> some way I can allow column numbers to be different, or is there some
> other way combining these datasets?

Not with rbind.  With merge, if you have a suitable index column.
Using 2.5.1 beta:

> Day1 <- data.frame(x=1:2, id=1:2)
> Day2 <- data.frame(x=3:4, y=10:11, id=3:4)
> rbind(Day1, Day2)
Error in match.names(clabs, names(xi)) : names do not match previous names
> merge(Day1, Day2, all=TRUE)
   x id  y
1 1  1 NA
2 2  2 NA
3 3  3 10
4 4  4 11


>
> Thanks,
> -Jouni
>
> On Mon, 18 Jun 2007, Petr Klasterecky wrote:
>
>> Junnila, Jouni napsal(a):
>>> Hello,
>>>
>>> I'm having a problem concerning r-binding datasets.
>>>
>>> I have six datasets, from six different plates, and two different
> days.
>>> I want to combine these datasets together for analysis. Datasets from
>
>>> day 2, have all the same columns than datasets from day 1. However in
>
>>> addition, there are few columns more in day 2. Thus, using rbind for
>>> this, results a error, because the objects are not the same length.
>>>
>>> Error in paste(nmi[nii == 0L], collapse = ", ") :
>>>         object "nii" not found
>>> In addition: Warning message:
>>> longer object length
>>>         is not a multiple of shorter object length in: clabs == nmi
>>
>> Hi,
>>
>> 1. the error has nothing to do with differing lengths of your objects
>> - that's what the following warning is about. The error occured
>> because your indexing object 'nii' does not exist where R is looking
> for it.
>
> It's because the dataframes have differing number of columns, and that
> has not been allowed for in the error message in that version of R.
>
>> 2. using rbind on dataframes is a bad practice, since the input is
>> converted to marices if possible. Use merge() instead.
>
> Not so: rbind on data frames does no such conversion, and is not
> problematic provided they have the same column names (and hence the same
> number of columns).  You may have missed in ?rbind
>
>      The functions 'cbind' and 'rbind' are S3 generic, with methods for
>      data frames.  The data frame method will be used if at least one
>      argument is a data frame and the rest are vectors or matrices.
> ...
>
> and a later description of the data frame method for 'rbind'.
>
>>
>> Petr
>>
>>>
>>>
>>> What I need, is to combine all the six together, and give for example
>
>>> NA-value in day 1, for those columns which can only be found in day
> 2.
>>> Is this somehow possible?
>>>
>>> I have several of these six-datasets groups, and only few of them are
>
>>> having this problem described above, and I cannot know in advance
> which.
>>> With most of the groups writing
>>> rbind(data1,data2,data3,data4,data5,data6)
>>> works easily, but these few problematic groups need also to be
>>> combined...
>>> Any help greatly appreciated!
>>>
>>> -Jouni

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From richard.pitman3 at btopenworld.com  Tue Jun 19 12:19:51 2007
From: richard.pitman3 at btopenworld.com (RICHARD PITMAN)
Date: Tue, 19 Jun 2007 11:19:51 +0100 (BST)
Subject: [R] plotting order of lines in xyplot panels while using
	conditioning variable and groups
Message-ID: <268595.96374.qm@web86201.mail.ird.yahoo.com>

I am using the following code:

library(lattice)
data<-read.csv("data.csv")
attach(data)

fig<-xyplot(S_t~month|event,
       key    = list(text=list(lab=c("Time to first CV
event - Data",
                                     "Survival post
first CV event - Model",
                                     "Survival post
first MIA/CA event - Data",
                                     "Survival post
first CVA event - Data",
                                     "Survival post
first TIA event - Data",
                                     "Survival post
first CVA/TIA event - Model"),
                               font=2,
                               cex=0.55),
                     lines=list(col=c("red",
                                      "magenta",
                                      "blue",
                                      "brown"),
                                type="l",
                                cex=0.55,
                                lwd=1.5,
                                pch=0:1),
                     corner=c(0,0),x=0.75,y=0.75),
       group  = group,
       index.cond = list(c(4,5,6,7,1,2,3)),
       type   = "l",
       lwd    = "3",
       ylim   = c(0,1.5),
       layout = c(4,2),
       col    = c("red","magenta","blue","brown"),
       pch    = 0:3,
       cex    = 0.5,
       ylab   = "cumulative probability",
       xlab   = "months",
     )
print(fig)

However, in each panel, the order in which the lines
are printed is suboptimal as some shorter lines are
obscured under longer lines. I am having some trouble
finding a method to change the order in which curves
are plotted in each panel. I have tried reordering the
levels in data$group:

data$group<-factor(data$group,
levels=c("CV_model_event_1","CV model event 2","CV
event
1","CV_event_2","CV_event_2_CVA","CV_event_2_TIA"))

but this changed nothing.

Any suggestions gratefully received.

TIA

Richard


From petr.pikal at precheza.cz  Tue Jun 19 12:23:58 2007
From: petr.pikal at precheza.cz (Petr PIKAL)
Date: Tue, 19 Jun 2007 12:23:58 +0200
Subject: [R] Odp:  outlying
In-Reply-To: <453961.78951.qm@web27503.mail.ukl.yahoo.com>
Message-ID: <OFF38222F2.E9D88EA8-ONC12572FF.0037AD3F-C12572FF.00391F8A@precheza.cz>

Hi

It often depends on your attitude to  limits for outlying observations. 
Boxplot has some identifying routine for selecting outlying points.

 Any procedure usually requires somebody to choose which observation is 
outlying and why. You can use e.g. all values which are beyond some 
threshold based on sd but that holds only if distribution is normal.

set.seed(1)
x<-rnorm(x)
ul <- mean(x) +3*sd(x)
ll <- mean(x) -3*sd(x)
beyond <- (x>ul)  | ( x <ll)

> x[beyond]
[1] 3.810277

Regards
Petr

petr.pikal at precheza.cz

r-help-bounces at stat.math.ethz.ch napsal dne 19.06.2007 11:29:17:

> hello,
> are there functions to detecte outlying observations in samples?
> thanks.
> 
> 
> 
> 
> 
> 
> 
> 
> 
___________________________________________________________________________
> 
> 
> 
> 
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Tue Jun 19 12:37:13 2007
From: jholtman at gmail.com (jim holtman)
Date: Tue, 19 Jun 2007 06:37:13 -0400
Subject: [R] How do I avoid a loop?
In-Reply-To: <0143A263BEF94644AC0D4027373EECD3054309AE@exyhmb08.jpn.nsroot.net>
References: <0143A263BEF94644AC0D4027373EECD3054309AE@exyhmb08.jpn.nsroot.net>
Message-ID: <644e1f320706190337n17f8ae2bjd276f21fcf5285e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070619/d70e51fe/attachment.pl 

From jim at bitwrit.com.au  Tue Jun 19 12:52:26 2007
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 19 Jun 2007 20:52:26 +1000
Subject: [R] triangle contour plots
In-Reply-To: <42B9A932-99E8-4788-B66A-FB12A9FA1DD6@noc.soton.ac.uk>
References: <42B9A932-99E8-4788-B66A-FB12A9FA1DD6@noc.soton.ac.uk>
Message-ID: <4677B56A.6010203@bitwrit.com.au>

Robin Hankin wrote:
> Suppose I have three numbers p1, p2, p3 with
> 0 <= p1,p2,p3 <= 1  and p1+p2+p3=1,
> and a  function  f=f(p1,p2,p3)   =  f(p1,p2,1-p1-p2).
> 
> How to draw a contour plot of f() on the p1+p2+p3=1 plane,
> that is, an equilateral triangle?
> 
> Functions triplot(), triangle.plot(), and ternaryplot()  give
> only  scatterplots, AFAICS
> 
Hi Robin,
I was all ready to say that triax.plot could do what you want if I added 
a "type" argument, but found that for some reason both "points" and 
"lines" are only reading the first color in a vector. If I send more 
than one color to either function, I only get the first one. If I can 
sort this out, it's easy to use triax.plot to do what you want (unless, 
of course, you are satisfied with lines of one color).

Jim


From petr.pikal at precheza.cz  Tue Jun 19 12:55:37 2007
From: petr.pikal at precheza.cz (Petr PIKAL)
Date: Tue, 19 Jun 2007 12:55:37 +0200
Subject: [R] Odp:  Odp:  outlying
In-Reply-To: <OFF38222F2.E9D88EA8-ONC12572FF.0037AD3F-C12572FF.00391F8A@precheza.cz>
Message-ID: <OF37C33612.8B9BC863-ONC12572FF.003BE60C-C12572FF.003C054A@precheza.cz>

r-help-bounces at stat.math.ethz.ch napsal dne 19.06.2007 12:23:58:

> Hi
> 
> It often depends on your attitude to  limits for outlying observations. 
> Boxplot has some identifying routine for selecting outlying points.
> 
>  Any procedure usually requires somebody to choose which observation is 
> outlying and why. You can use e.g. all values which are beyond some 
> threshold based on sd but that holds only if distribution is normal.
> 
> set.seed(1)
> x<-rnorm(x)

Sorry, it shall be 

x <- rnorm(1000)


> ul <- mean(x) +3*sd(x)
> ll <- mean(x) -3*sd(x)
> beyond <- (x>ul)  | ( x <ll)
> 
> > x[beyond]
> [1] 3.810277
> 
> Regards
> Petr
> 
> petr.pikal at precheza.cz
> 
> r-help-bounces at stat.math.ethz.ch napsal dne 19.06.2007 11:29:17:
> 
> > hello,
> > are there functions to detecte outlying observations in samples?
> > thanks.
> > 
> > 
> > 
> > 
> > 
> > 
> > 
> > 
> > 
> 
___________________________________________________________________________
> > 
> > 
> > 
> > 
> > 
> >    [[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at yahoo.ca  Tue Jun 19 13:38:30 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Tue, 19 Jun 2007 07:38:30 -0400 (EDT)
Subject: [R] outlying
In-Reply-To: <453961.78951.qm@web27503.mail.ukl.yahoo.com>
Message-ID: <461794.63353.qm@web32813.mail.mud.yahoo.com>

You might want to have a look at the outliers package
on CRAN.
--- elyakhlifi mustapha <elyakhlifi_mustapha at yahoo.fr>
wrote:

> hello,
> are there functions to detecte outlying observations
> in samples?
> thanks.
> 
> 
> 
> 
> 
>       
> 	
> 		
>
___________________________________________________________________________
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From ggrothendieck at gmail.com  Tue Jun 19 13:42:17 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 19 Jun 2007 07:42:17 -0400
Subject: [R] How do I avoid a loop?
In-Reply-To: <0143A263BEF94644AC0D4027373EECD3054309AE@exyhmb08.jpn.nsroot.net>
References: <0143A263BEF94644AC0D4027373EECD3054309AE@exyhmb08.jpn.nsroot.net>
Message-ID: <971536df0706190442g460ea227se87e12d88ee92f9d@mail.gmail.com>

xx is 1 in every position of the first run of TRUE, 2 in every
position in the 2nd run of TRUE and so on.  The parenthesized
expression in the second line converts those to increasing
values and multiplying it by x zaps the garbage in the positions
that correspond to FALSE in x.

xx <- cumsum(diff(c(FALSE, x)) > 0)
(seq_along(x) - match(xx, xx) + 1) * x


On 6/19/07, Feng, Ken <ken.feng at citi.com> wrote:
> Hi,
>
> I start with an array of booleans:
>
>        x <- c( TRUE, TRUE, TRUE, FALSE, FALSE, TRUE, TRUE, FALSE, TRUE );
>
> I want to define an y <- f(x) such that:
>
>        y <- c( 1, 2, 3, 0, 0, 1, 2, 0, 1 );
>
> In other words, do a cumsum when I see a TRUE, but reset to 0 if I see a FALSE.
>
> I know I can do this with a very slow and ugly loop or maybe use apply,
> but I was hoping there are some R experts out there who can show me
> a cleaner/more elegant solution?
>
> Thanks in advance.
>
> - Ken
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bolker at ufl.edu  Tue Jun 19 13:38:56 2007
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 19 Jun 2007 11:38:56 +0000 (UTC)
Subject: [R] How to compare GLM and GAM models
References: <BAY118-F90B55F0D6819B5E128C79A1130@phx.gbl>
Message-ID: <loom.20070619T133831-358@post.gmane.org>

Yuanchang xie <xieyc <at> hotmail.com> writes:

> 
> Dear Listers,
> 
> I want to compare two negative binomial models fitted using glm.nb and 
> gam(mgcv) based on the same data. What would be the most appropriate 
> criteria to compare these two models? Can someone point me to some 
> references? Thank you very much.
> 
> Yuanchang Xie
> 

  Since they can't possibly be nested I would suggest AIC.

  Ben Bolker


From sabya23 at gmail.com  Tue Jun 19 13:59:13 2007
From: sabya23 at gmail.com (spime)
Date: Tue, 19 Jun 2007 04:59:13 -0700 (PDT)
Subject: [R] BIC and Hosmer-Lemeshow statistic for logistic regression
Message-ID: <11193273.post@talk.nabble.com>



I haven't find any helpful thread. How can i calculate BIC and
Hosmer-Lemeshow statistic for a logistic regression model. I have used glm
for logistic fit.
-- 
View this message in context: http://www.nabble.com/BIC-and-Hosmer-Lemeshow-statistic-for-logistic-regression-tf3945943.html#a11193273
Sent from the R help mailing list archive at Nabble.com.


From birgit.lemcke at systbot.uzh.ch  Tue Jun 19 14:10:55 2007
From: birgit.lemcke at systbot.uzh.ch (Birgit Lemcke)
Date: Tue, 19 Jun 2007 14:10:55 +0200
Subject: [R] Dissimilarity Analysis
Message-ID: <98C49113-3775-4EDC-B8C2-C0E528B6375B@systbot.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070619/ded28c75/attachment.pl 

From f.harrell at vanderbilt.edu  Tue Jun 19 14:10:51 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Tue, 19 Jun 2007 07:10:51 -0500
Subject: [R] BIC and Hosmer-Lemeshow statistic for logistic regression
In-Reply-To: <11193273.post@talk.nabble.com>
References: <11193273.post@talk.nabble.com>
Message-ID: <4677C7CB.4060705@vanderbilt.edu>

spime wrote:
> 
> I haven't find any helpful thread. How can i calculate BIC and
> Hosmer-Lemeshow statistic for a logistic regression model. I have used glm
> for logistic fit.

See the Design package's lrm function and residuals.lrm for a better GOF 
test.

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From lcostanz at uoguelph.ca  Tue Jun 19 14:13:30 2007
From: lcostanz at uoguelph.ca (Lucia Costanzo)
Date: Tue, 19 Jun 2007 08:13:30 -0400
Subject: [R] converting proc mixed to lme for a random effects meta-analysis
Message-ID: <4677C86A.3060709@uoguelph.ca>

I would like to convert the following SAS code for a Random Effects 
meta-analysis model for use in R but, I am running into difficulties. 
The results are not similar, R should be reporting 0.017 for the 
between-study variance component, 0.478 for the estimated parameter and 
0.130 for the standard error of the estimated parameter.  I think it is 
the weighting causing problems. Would anyone have any suggestions or tips?

Thank you,
Lucia

*** R CODE ***
studynum <-c(1, 2, 3, 4, 5)
y <-c(0.284, 0.224, 0.360, 0.785, 0.492)
w <-c(14.63, 17.02, 9.08, 33.03, 5.63)
genData2 <-data.frame(cbind(studynum, y, w,v))

re.teo<-lme(y~1, data=genData2, random =~1, method="ML", 
weights=varFixed(~w))


*** SAS CODE ***

data tacrine;
    input study y w;
    cards;
    1 0.284 14.63
    2 0.224 17.02
    3 0.360  9.08
    4 0.785 33.03
    5 0.492  5.63
    ;
run;

*Random Effects using log-odds for tacrine example table 4.29;
DATA remlma;
    SET tacrine;
    var=1/w;
    col = _n_;
    row = _n_;
    value = var;
run;

*random effects for tacrine example;
PROC MIXED data = remlma method=reml order=data;
   CLASS study;
   MODEL y = / solution;
   RANDOM study / gdata = remlma;
   REPEATED diag;
RUN;


From gavin.simpson at ucl.ac.uk  Tue Jun 19 14:22:13 2007
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Tue, 19 Jun 2007 13:22:13 +0100
Subject: [R] BIC and Hosmer-Lemeshow statistic for logistic regression
In-Reply-To: <11193273.post@talk.nabble.com>
References: <11193273.post@talk.nabble.com>
Message-ID: <1182255733.7247.26.camel@gsimpson.geog.ucl.ac.uk>

On Tue, 2007-06-19 at 04:59 -0700, spime wrote:
> 
> I haven't find any helpful thread. How can i calculate BIC and
> Hosmer-Lemeshow statistic for a logistic regression model. I have used glm
> for logistic fit.

Not sure about the Hosmer-Lemeshow, but AIC() with argument k = log(n),
where n is number of observations,  will get BIC. See ?AIC.

HTH

G
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Gavin Simpson                 [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From martin.becker at mx.uni-saarland.de  Tue Jun 19 14:25:02 2007
From: martin.becker at mx.uni-saarland.de (Martin Becker)
Date: Tue, 19 Jun 2007 14:25:02 +0200
Subject: [R] How do I avoid a loop?
In-Reply-To: <971536df0706190442g460ea227se87e12d88ee92f9d@mail.gmail.com>
References: <0143A263BEF94644AC0D4027373EECD3054309AE@exyhmb08.jpn.nsroot.net>
	<971536df0706190442g460ea227se87e12d88ee92f9d@mail.gmail.com>
Message-ID: <4677CB1E.4050006@mx.uni-saarland.de>

Gabor Grothendieck wrote:
> xx is 1 in every position of the first run of TRUE, 2 in every
> position in the 2nd run of TRUE and so on.  The parenthesized
> expression in the second line converts those to increasing
> values and multiplying it by x zaps the garbage in the positions
> that correspond to FALSE in x.
>
> xx <- cumsum(diff(c(FALSE, x)) > 0)
> (seq_along(x) - match(xx, xx) + 1) * x
>
>   

If speed is a critical issue, there is another possibility. Thanks to 
Oleg Sklyar's "inline"-package, embedding C code is now quite easy:

library(inline)
code <- readLines(textConnection("
  SEXP res;
  PROTECT(res=allocVector(INTSXP,LENGTH(a)));
  int i,j=0;
  int *result = INTEGER(res);
  int *input  = INTEGER(a);
  for (i=0;i<LENGTH(a);i++) {
    if (input[i]) j = j+1; else j = 0;
    result[i] = j;
  }
  UNPROTECT(1);
  return res;
"))
myfastfunc <- cfunction(signature(a="logical"), code)

This solution is about ten times faster than Gabor's on my machine (time 
to compile the C code excluded!).

Regards,

   Martin

> On 6/19/07, Feng, Ken <ken.feng at citi.com> wrote:
>   
>> Hi,
>>
>> I start with an array of booleans:
>>
>>        x <- c( TRUE, TRUE, TRUE, FALSE, FALSE, TRUE, TRUE, FALSE, TRUE );
>>
>> I want to define an y <- f(x) such that:
>>
>>        y <- c( 1, 2, 3, 0, 0, 1, 2, 0, 1 );
>>
>> In other words, do a cumsum when I see a TRUE, but reset to 0 if I see a FALSE.
>>
>> I know I can do this with a very slow and ugly loop or maybe use apply,
>> but I was hoping there are some R experts out there who can show me
>> a cleaner/more elegant solution?
>>
>> Thanks in advance.
>>
>> - Ken
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>     
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bernd.weiss at uni-koeln.de  Tue Jun 19 14:36:47 2007
From: bernd.weiss at uni-koeln.de (Bernd Weiss)
Date: Tue, 19 Jun 2007 14:36:47 +0200
Subject: [R] converting proc mixed to lme for a random effects
	meta-analysis
In-Reply-To: <4677C86A.3060709@uoguelph.ca>
References: <4677C86A.3060709@uoguelph.ca>
Message-ID: <4677E9FF.9264.1743DE2@bernd.weiss.uni-koeln.de>

On 19 Jun 2007 at 8:13, Lucia Costanzo wrote:

Date sent:      	Tue, 19 Jun 2007 08:13:30 -0400
From:           	Lucia Costanzo <lcostanz at uoguelph.ca>
To:             	r-help at stat.math.ethz.ch
Subject:        	[R] converting proc mixed to lme for a random 
effects meta-analysis

> I would like to convert the following SAS code for a Random Effects
> meta-analysis model for use in R but, I am running into
> difficulties. 
> The results are not similar, R should be reporting 0.017 for the 
> between-study variance component, 0.478 for the estimated parameter
> and 
> 0.130 for the standard error of the estimated parameter.  I think it
> is 
> the weighting causing problems. Would anyone have any suggestions or
> tips?
> 
> Thank you,
> Lucia
> 
> *** R CODE ***
> studynum <-c(1, 2, 3, 4, 5)
> y <-c(0.284, 0.224, 0.360, 0.785, 0.492)
> w <-c(14.63, 17.02, 9.08, 33.03, 5.63)
> genData2 <-data.frame(cbind(studynum, y, w,v))
> 
> re.teo<-lme(y~1, data=genData2, random =~1, method="ML", 
> weights=varFixed(~w))
> 
> 


What about using MiMa <http://www.wvbauer.com/downloads.html>? 

studynum <-c(1, 2, 3, 4, 5)
y <-c(0.284, 0.224, 0.360, 0.785, 0.492)
w <-c(14.63, 17.02, 9.08, 33.03, 5.63)
## without cbind(...)
genData2 <-data.frame(studynum, y, w)
mima(genData2$y, 1/genData2$w, mods = c(), method = "ML")


Some output:

- Estimate of (Residual) Heterogeneity: 0.0173

-         estimate     SE   zval  pval   CI_L   CI_U
intrcpt   0.4779 0.1304 3.6657 2e-04 0.2224 0.7334

Looks like what you are looking for...

HTH,

Bernd


From mark_difford at yahoo.co.uk  Tue Jun 19 14:44:56 2007
From: mark_difford at yahoo.co.uk (Mark Difford)
Date: Tue, 19 Jun 2007 05:44:56 -0700 (PDT)
Subject: [R] Controlling text and strip arrangement in xyplot
In-Reply-To: <0JJV0059QH2O47D0@msg-mx5.usc.edu>
References: <0JJV0059QH2O47D0@msg-mx5.usc.edu>
Message-ID: <11193990.post@talk.nabble.com>


Hi Pablo,

> DF <- data.frame(x=rnorm(20), y=rnorm(20), g1=rep(letters[1:2], 10), 
>        g2=rep(LETTERS[1:2], each=10), 
> g3=rep(rep(letters[3:4],each=5),2))
>
> xyplot(y ~ x | g1 + g2, groups=g3, data=DF)
...

I remember findling with this some time ago and getting most of the way
there.  If you have to use lattice, then the following may help you.  It's
close, but not quite what you want; you almost certainly need to write a
custom panel function.  Hopefully Deepayan will step in (as he usually does)
to help you.

1) Look at ?strip.default, as well as ?xyplot (search for "strip",
"strip.left")

2) Example:

xyplot(y ~ x | interaction(g1,g2, drop=TRUE), groups=g3, data=DF,
strip.left=strip.custom(factor.levels=c("A","A","B","B")),
strip=strip.custom(factor.levels=rep(c("g1=a","g1=b"),2)))

Hope that helps,

Regards,
Mark.


Pablo Lewinger wrote:
> 
> I've searched the archives and read the xyplot help but can't figure 
> out the 2 lattice questions below?
> 
> Consider:
> 
> library(lattice)
> DF <- data.frame(x=rnorm(20), y=rnorm(20), g1=rep(letters[1:2], 10),
>                   g2=rep(LETTERS[1:2], each=10), 
> g3=rep(rep(letters[3:4],each=5),2))
> 
> xyplot(y ~ x | g1 + g2, groups=g3, data=DF)
> 
> 1) Is there a way to get one strip per row and column of panels as 
> below instead of the default?
> 
> 
>         _|__a__|__b__|
>          |
>        B
>          |
>         --
>          |
>        A
>          |
> 
> 2) How do I control the text of the strips so that for instance 
> instead of "a" and "b" it reads"g1=alpha", "g1=beta" where "alpha" 
> and "beta" stand for the corresponding greek symbols? (my difficulty 
> here is not with the plotmath symbols but with controlling the text 
> of the strips directly from the call to xyplot and not by renaming 
> the levels of g1)
> 
> I'd appreciate any help!
> 
> 
> Juan Pablo Lewinger
> Department of Preventive Medicine
> Keck School of Medicine
> University of Southern California
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/Controlling-text-and-strip-arrangement-in-xyplot-tf3944756.html#a11193990
Sent from the R help mailing list archive at Nabble.com.


From Wolfgang.Viechtbauer at STAT.unimaas.nl  Tue Jun 19 14:52:03 2007
From: Wolfgang.Viechtbauer at STAT.unimaas.nl (Viechtbauer Wolfgang (STAT))
Date: Tue, 19 Jun 2007 14:52:03 +0200
Subject: [R] converting proc mixed to lme for a random
	effectsmeta-analysis
Message-ID: <329A68716B57D54E8D39FD3F8A4A84DF057D5F3E@um-mail0136.unimaas.nl>

That was going to be my suggestion =)

By the way, lme does not give you the right results because the residual variance is not constrained to 1 (and it is not possible to do so).

Best,

-- 
Wolfgang Viechtbauer 
?Department of Methodology and Statistics 
?University of Maastricht, The Netherlands 
?http://www.wvbauer.com/ 



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Bernd Weiss
Sent: Tuesday, June 19, 2007 14:37
To: Lucia Costanzo
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] converting proc mixed to lme for a random effectsmeta-analysis


On 19 Jun 2007 at 8:13, Lucia Costanzo wrote:

Date sent:      	Tue, 19 Jun 2007 08:13:30 -0400
From:           	Lucia Costanzo <lcostanz at uoguelph.ca>
To:             	r-help at stat.math.ethz.ch
Subject:        	[R] converting proc mixed to lme for a random 
effects meta-analysis

> I would like to convert the following SAS code for a Random Effects 
> meta-analysis model for use in R but, I am running into difficulties.
> The results are not similar, R should be reporting 0.017 for the 
> between-study variance component, 0.478 for the estimated parameter
> and 
> 0.130 for the standard error of the estimated parameter.  I think it
> is 
> the weighting causing problems. Would anyone have any suggestions or
> tips?
> 
> Thank you,
> Lucia
> 
> *** R CODE ***
> studynum <-c(1, 2, 3, 4, 5)
> y <-c(0.284, 0.224, 0.360, 0.785, 0.492)
> w <-c(14.63, 17.02, 9.08, 33.03, 5.63)
> genData2 <-data.frame(cbind(studynum, y, w,v))
> 
> re.teo<-lme(y~1, data=genData2, random =~1, method="ML",
> weights=varFixed(~w))
> 
> 


What about using MiMa <http://www.wvbauer.com/downloads.html>? 

studynum <-c(1, 2, 3, 4, 5)
y <-c(0.284, 0.224, 0.360, 0.785, 0.492)
w <-c(14.63, 17.02, 9.08, 33.03, 5.63)
## without cbind(...)
genData2 <-data.frame(studynum, y, w)
mima(genData2$y, 1/genData2$w, mods = c(), method = "ML")


Some output:

- Estimate of (Residual) Heterogeneity: 0.0173

-         estimate     SE   zval  pval   CI_L   CI_U
intrcpt   0.4779 0.1304 3.6657 2e-04 0.2224 0.7334

Looks like what you are looking for...

HTH,

Bernd

______________________________________________
R-help at stat.math.ethz.ch mailing list https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ericbferreira at gmail.com  Tue Jun 19 15:00:42 2007
From: ericbferreira at gmail.com (Eric Ferreira)
Date: Tue, 19 Jun 2007 10:00:42 -0300
Subject: [R] Rmpi and rsprng for Windows
Message-ID: <c3b1a6fe0706190600m77a81969x79a2f2e0c74d057c@mail.gmail.com>

Um texto embutido e sem conjunto de caracteres especificado associado...
Nome: n?o dispon?vel
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070619/1a8935fe/attachment.pl 

From helprhelp at gmail.com  Tue Jun 19 15:10:46 2007
From: helprhelp at gmail.com (Weiwei Shi)
Date: Tue, 19 Jun 2007 09:10:46 -0400
Subject: [R] outlying
In-Reply-To: <453961.78951.qm@web27503.mail.ukl.yahoo.com>
References: <453961.78951.qm@web27503.mail.ukl.yahoo.com>
Message-ID: <cdf817830706190610g4f18a079s97b346fcbb63b168@mail.gmail.com>

check package dprep

On 6/19/07, elyakhlifi mustapha <elyakhlifi_mustapha at yahoo.fr> wrote:
> hello,
> are there functions to detecte outlying observations in samples?
> thanks.
>
>
>
>
>
>
>
>
> ___________________________________________________________________________
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Weiwei Shi, Ph.D
Research Scientist
GeneGO, Inc.

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III


From WTALLOEN at PRDBE.JNJ.COM  Tue Jun 19 15:15:27 2007
From: WTALLOEN at PRDBE.JNJ.COM (Talloen, Willem [PRDBE])
Date: Tue, 19 Jun 2007 15:15:27 +0200
Subject: [R] plot only x- and y-axis with origin, no box()
Message-ID: <76AA79BF7116C04B92C3CD618B701A45036219@JNJBEBEGMS03.eu.jnj.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070619/906ace04/attachment.pl 

From mtmorgan at fhcrc.org  Tue Jun 19 15:15:40 2007
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Tue, 19 Jun 2007 06:15:40 -0700
Subject: [R] Rmpi and rsprng for Windows
In-Reply-To: <c3b1a6fe0706190600m77a81969x79a2f2e0c74d057c@mail.gmail.com>
	(Eric Ferreira's message of "Tue, 19 Jun 2007 10:00:42 -0300")
References: <c3b1a6fe0706190600m77a81969x79a2f2e0c74d057c@mail.gmail.com>
Message-ID: <6ph4pl4dr0j.fsf@gopher4.fhcrc.org>

Eric -

http://www.stats.uwo.ca/faculty/yu/Rmpi/

(the Rmpi package author page) has helpful Windows instructions.

Martin

"Eric Ferreira" <ericbferreira at gmail.com> writes:

> Dear f_R_iends,
>
> I'm new on parallel programming and trying to use a machine with Windows to
> access a linux computer cluster. I could install the 'snow' package, but not
> 'Rmpi' nor 'rsprng'.
>
> Some tips for intalling such packages for Windows R ?
>
> All the best,
>
> -- 
> Barba
> Departamento de Ci?ncias Exatas
> Universidade Federal de Lavras
> Minas Gerais - Brasil
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Martin Morgan
Bioconductor / Computational Biology
http://bioconductor.org


From martin.becker at mx.uni-saarland.de  Tue Jun 19 15:42:00 2007
From: martin.becker at mx.uni-saarland.de (Martin Becker)
Date: Tue, 19 Jun 2007 15:42:00 +0200
Subject: [R] How do I avoid a loop?
In-Reply-To: <971536df0706190442g460ea227se87e12d88ee92f9d@mail.gmail.com>
References: <0143A263BEF94644AC0D4027373EECD3054309AE@exyhmb08.jpn.nsroot.net>
	<971536df0706190442g460ea227se87e12d88ee92f9d@mail.gmail.com>
Message-ID: <4677DD28.8030507@mx.uni-saarland.de>

Gabor Grothendieck wrote:
> xx is 1 in every position of the first run of TRUE, 2 in every
> position in the 2nd run of TRUE and so on.  The parenthesized
> expression in the second line converts those to increasing
> values and multiplying it by x zaps the garbage in the positions
> that correspond to FALSE in x.
>
> xx <- cumsum(diff(c(FALSE, x)) > 0)
> (seq_along(x) - match(xx, xx) + 1) * x
>
>
>   

If speed is a critical issue, there is another possibility. Thanks to 
Oleg Sklyar's "inline"-package, embedding C code is now quite easy:

library(inline)
code <- readLines(textConnection("
 SEXP res;
 PROTECT(res=allocVector(INTSXP,LENGTH(a)));
 int i,j=0;
 int *result = INTEGER(res);
 int *input  = INTEGER(a);
 for (i=0;i<LENGTH(a);i++) {
   if (input[i]) j = j+1; else j = 0;
   result[i] = j;
 }
 UNPROTECT(1);
 return res;
"))
myfastfunc <- cfunction(signature(a="logical"), code)

This solution is about ten times faster than Gabor's on my machine (time 
to compile the C code excluded!).

Regards,

  Martin

> On 6/19/07, Feng, Ken <ken.feng at citi.com> wrote:
>   
>> Hi,
>>
>> I start with an array of booleans:
>>
>>        x <- c( TRUE, TRUE, TRUE, FALSE, FALSE, TRUE, TRUE, FALSE, TRUE );
>>
>> I want to define an y <- f(x) such that:
>>
>>        y <- c( 1, 2, 3, 0, 0, 1, 2, 0, 1 );
>>
>> In other words, do a cumsum when I see a TRUE, but reset to 0 if I see a FALSE.
>>
>> I know I can do this with a very slow and ugly loop or maybe use apply,
>> but I was hoping there are some R experts out there who can show me
>> a cleaner/more elegant solution?
>>
>> Thanks in advance.
>>
>> - Ken
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>     
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From sabya23 at gmail.com  Tue Jun 19 16:05:35 2007
From: sabya23 at gmail.com (spime)
Date: Tue, 19 Jun 2007 07:05:35 -0700 (PDT)
Subject: [R] BIC and Hosmer-Lemeshow statistic for logistic regression
In-Reply-To: <4677C7CB.4060705@vanderbilt.edu>
References: <11193273.post@talk.nabble.com> <4677C7CB.4060705@vanderbilt.edu>
Message-ID: <11195410.post@talk.nabble.com>



Is there any windows version of Design package???






Frank E Harrell Jr wrote:
> 
> spime wrote:
>> 
>> I haven't find any helpful thread. How can i calculate BIC and
>> Hosmer-Lemeshow statistic for a logistic regression model. I have used
>> glm
>> for logistic fit.
> 
> See the Design package's lrm function and residuals.lrm for a better GOF 
> test.
> 
> 
> 
> -- 
> Frank E Harrell Jr   Professor and Chair           School of Medicine
>                       Department of Biostatistics   Vanderbilt University
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/BIC-and-Hosmer-Lemeshow-statistic-for-logistic-regression-tf3945943.html#a11195410
Sent from the R help mailing list archive at Nabble.com.


From ssj1364 at gmail.com  Tue Jun 19 16:24:52 2007
From: ssj1364 at gmail.com (sj)
Date: Tue, 19 Jun 2007 08:24:52 -0600
Subject: [R] Help in ARIMA
In-Reply-To: <4e29a5d60706190102l6e23aa6end022d6b63709355d@mail.gmail.com>
References: <4e29a5d60706190102l6e23aa6end022d6b63709355d@mail.gmail.com>
Message-ID: <1c6126db0706190724y3d66fc3u182922052e9c57a9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070619/0ae71eee/attachment.pl 

From tlumley at u.washington.edu  Tue Jun 19 16:25:12 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 19 Jun 2007 07:25:12 -0700 (PDT)
Subject: [R] psm/survreg coefficient values ?
In-Reply-To: <200706191017.48673.j.logsdon@quantex-research.com>
References: <1c6126db0706181318n3cd9bd29kf4f728cec80fe0e4@mail.gmail.com>
	<4676FFA6.7090309@vanderbilt.edu>
	<200706191017.48673.j.logsdon@quantex-research.com>
Message-ID: <Pine.LNX.4.64.0706190724180.5221@homer23.u.washington.edu>

On Tue, 19 Jun 2007, John Logsdon wrote:

> In survreg() the predictor is log(characteristic life) for Weibull (=
> exponential when scale=1) - ie the 63.2%ile.  For the others the predictor is
> log(median).
>
> This causes problems when comparing predictions and a better way IMHO is to
> correct the Weibull prediction by a factor (log(2))^(1/scale).  This is only
> a simple multiple unless the shape parameter is also being modelled, when a
> completely different solution may arise.  Such heterogeneity modelling cannot
> of course be done within survreg().

Except, of course, for a discrete predictor of heterogeneity, using 
strata().

 	-thomas


> On Monday 18 June 2007 22:56:54 Frank E Harrell Jr wrote:
>> sj wrote:
>>> I am using psm to model some parametric survival data, the data is for
>>> length of stay in an emergency department. There are several ways a
>>> patient's stay in the emergency department can end (discharge, admit,
>>> etc..) so I am looking at modeling the effects of several covariates on
>>> the various outcomes. Initially I am trying to fit a  survival model for
>>> each type of outcome using the psm function in the design package,  i.e.,
>>> all  patients who's visits  come to an end  due to  any event other than
>>> the event of interest are considered to be censored.  Being new to the
>>> psm and  survreg packages (and to parametric survival modeling) I am not
>>> entirely sure how to interpret the coefficient values that psm returns. I
>>> have included the following code to illustrate code similar to what I am
>>> using on my data. I suppose that the coefficients are somehow rescaled ,
>>> but I am not sure how to return them to the original scale and make sense
>>> out of the coefficients, e.g., estimate the the effect of higher acuity
>>> on time to event in minutes. Any explanation or direction on how to
>>> interpret the  coefficient values would be greatly appreciated.
>>>
>>> this is from the documentation for survreg.object.
>>> coefficientsthe coefficients of the linear.predictors, which multiply the
>>> columns of the model matrix. It does not include the estimate of error
>>> (sigma). The names of the coefficients are the names of the
>>> single-degree-of-freedom effects (the columns of the model matrix). If
>>> the model is over-determined there will be missing values in the
>>> coefficients corresponding to non-estimable coefficients.
>>>
>>> code:
>>> LOS <- sort(rweibull(1000,1.4,108))
>>> AGE <- sort(rnorm(1000,41,12))
>>> ACUITY <- sort(rep(1:5,200))
>>> EVENT <-  sample(x=c(0,1),replace=TRUE,1000)
>>> psm(Surv(LOS,EVENT)~AGE+as.factor(ACUITY),dist='weibull')
>>>
>>> output:
>>>
>>> psm(formula = Surv(LOS, CENS) ~ AGE + as.factor(ACUITY), dist =
>>> "weibull")
>>>
>>>        Obs     Events Model L.R.       d.f.          P         R2
>>>       1000        513    2387.62          5          0       0.91
>>>
>>>               Value          Std. Error      z         p
>>> (Intercept)     1.1055    0.04425  24.98 8.92e-138
>>> AGE             0.0772    0.00152  50.93  0.00e+00
>>> ACUITY=2     0.0944    0.01357   6.96  3.39e-12
>>> ACUITY=3     0.1752    0.02111   8.30  1.03e-16
>>> ACUITY=4     0.1391    0.02722   5.11  3.18e-07
>>> ACUITY=5    -0.0544    0.03789  -1.43  1.51e-01
>>> Log(scale)    -2.7287    0.03780 -72.18  0.00e+00
>>>
>>> Scale= 0.0653
>>>
>>> best,
>>>
>>> Spencer
>>
>> I have a case study using psm (survreg wrapper) in my book.  Briefly,
>> coefficients are on the log median survival time scale.
>>
>> Frank
>
>
>
> -- 
> Best wishes
>
> John
>
> John Logsdon                               "Try to make things as simple
> Quantex Research Ltd, Manchester UK         as possible but not simpler"
> j.logsdon at quantex-research.com              a.einstein at relativity.org
> +44(0)161 445 4951/G:+44(0)7717758675       www.quantex-research.com
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From marc_schwartz at comcast.net  Tue Jun 19 16:28:46 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Tue, 19 Jun 2007 09:28:46 -0500
Subject: [R] plot only x- and y-axis with origin, no box()
In-Reply-To: <76AA79BF7116C04B92C3CD618B701A45036219@JNJBEBEGMS03.eu.jnj.com>
References: <76AA79BF7116C04B92C3CD618B701A45036219@JNJBEBEGMS03.eu.jnj.com>
Message-ID: <1182263326.3690.13.camel@Bellerophon.localdomain>

On Tue, 2007-06-19 at 15:15 +0200, Talloen, Willem [PRDBE] wrote:
> hi all,
> 
> I'm trying for quite some time to have an x- and y-axis, but no entire box.
> 
> >plot(..,axes=F)
> >axis(1)
> >axis(2)
> Gives this, but their axes do not go to the origin.
> Quite a number of people find this gap between the two axes disturbing.
> Has anyone an idea how to let these axes go to the origin?
> 
> thank you in advance

See this post:

http://tolstoy.newcastle.edu.au/R/help/04/03/0911.html

HTH,

Marc Schwartz


From iverson at biostat.wisc.edu  Tue Jun 19 16:28:41 2007
From: iverson at biostat.wisc.edu (Erik Iverson)
Date: Tue, 19 Jun 2007 09:28:41 -0500
Subject: [R] How do I avoid a loop?
In-Reply-To: <0143A263BEF94644AC0D4027373EECD3054309AE@exyhmb08.jpn.nsroot.net>
References: <0143A263BEF94644AC0D4027373EECD3054309AE@exyhmb08.jpn.nsroot.net>
Message-ID: <4677E819.8000501@biostat.wisc.edu>

One more variation on the solution, no idea how it compares in speed.

Using your x ...

 > ifelse(x, unlist(mapply(seq, to = rle(x)$lengths, from = 1)), 0)
[1] 1 2 3 0 0 1 2 0 1

Feng, Ken wrote:
> Hi,
> 
> I start with an array of booleans:
> 
> 	x <- c( TRUE, TRUE, TRUE, FALSE, FALSE, TRUE, TRUE, FALSE, TRUE );
> 
> I want to define an y <- f(x) such that:
> 
> 	y <- c( 1, 2, 3, 0, 0, 1, 2, 0, 1 );
> 
> In other words, do a cumsum when I see a TRUE, but reset to 0 if I see a FALSE.
> 
> I know I can do this with a very slow and ugly loop or maybe use apply,
> but I was hoping there are some R experts out there who can show me
> a cleaner/more elegant solution?
> 
> Thanks in advance.
> 
> - Ken
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tlumley at u.washington.edu  Tue Jun 19 16:30:43 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 19 Jun 2007 07:30:43 -0700 (PDT)
Subject: [R] BIC and Hosmer-Lemeshow statistic for logistic regression
In-Reply-To: <11195410.post@talk.nabble.com>
References: <11193273.post@talk.nabble.com> <4677C7CB.4060705@vanderbilt.edu>
	<11195410.post@talk.nabble.com>
Message-ID: <Pine.LNX.4.64.0706190729520.5221@homer23.u.washington.edu>

On Tue, 19 Jun 2007, spime wrote:
>
> Is there any windows version of Design package???
>

Not at the moment. It is being updated for changes in R 2.5.0.

[This would be a FAQ except that it should stop being asked soon]

 	-thomas

>
>
>
>
>
> Frank E Harrell Jr wrote:
>>
>> spime wrote:
>>>
>>> I haven't find any helpful thread. How can i calculate BIC and
>>> Hosmer-Lemeshow statistic for a logistic regression model. I have used
>>> glm
>>> for logistic fit.
>>
>> See the Design package's lrm function and residuals.lrm for a better GOF
>> test.
>>
>>
>>
>> --
>> Frank E Harrell Jr   Professor and Chair           School of Medicine
>>                       Department of Biostatistics   Vanderbilt University
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> -- 
> View this message in context: http://www.nabble.com/BIC-and-Hosmer-Lemeshow-statistic-for-logistic-regression-tf3945943.html#a11195410
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From wwwhsd at gmail.com  Tue Jun 19 16:35:12 2007
From: wwwhsd at gmail.com (Henrique Dallazuanna)
Date: Tue, 19 Jun 2007 11:35:12 -0300
Subject: [R] BIC and Hosmer-Lemeshow statistic for logistic regression
In-Reply-To: <11195410.post@talk.nabble.com>
References: <11193273.post@talk.nabble.com> <4677C7CB.4060705@vanderbilt.edu>
	<11195410.post@talk.nabble.com>
Message-ID: <da79af330706190735o7d3c152crf2ba9e426c7c7802@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070619/1970405b/attachment.pl 

From aresuluca at libero.it  Tue Jun 19 16:36:56 2007
From: aresuluca at libero.it (Luca Aresu)
Date: Tue, 19 Jun 2007 16:36:56 +0200
Subject: [R] cash or nothing option
Message-ID: <BF0B32D78B734F5182B1595C964A7923@PCstandard>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070619/ffd797fe/attachment.pl 

From ggrothendieck at gmail.com  Tue Jun 19 16:44:12 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 19 Jun 2007 10:44:12 -0400
Subject: [R] How do I avoid a loop?
In-Reply-To: <971536df0706190442g460ea227se87e12d88ee92f9d@mail.gmail.com>
References: <0143A263BEF94644AC0D4027373EECD3054309AE@exyhmb08.jpn.nsroot.net>
	<971536df0706190442g460ea227se87e12d88ee92f9d@mail.gmail.com>
Message-ID: <971536df0706190744pc7edc38y85cb5f5f3710d996@mail.gmail.com>

Here is a slight variation.  The second line is unchanged from my
prior solution but the first line is different.  The previous one I posted
was slightly more complex and took about 50% longer to run than
this one:

   xx <- (cumsum(!x) + 1) * x
   (seq_along(x) - match(xx, xx) + 1) * x

> # performance testing
>
> f1 <- function(x) {
+ xx <- cumsum(diff(c(FALSE, x)) > 0)
+ (seq_along(x) - match(xx, xx) + 1) * x
+ }
>
> f2 <- function(x) {
+    xx <- (cumsum(!x) + 1) * x
+    (seq_along(x) - match(xx, xx) + 1) * x
+ }
>
>
> f3 <- function(x) {
+ j <- 0
+ for(i in seq_along(x)) x[i] <- if (x[i]) j <- j+1 else j <- 0
+ x
+ }
>
> set.seed(1)
> x <- sample(c(TRUE, FALSE), 100000, replace = TRUE)
> system.time(out1 <- f1(x))
   user  system elapsed
   0.10    0.02    0.12
> system.time(out2 <- f2(x))
   user  system elapsed
   0.07    0.01    0.08
> system.time(out3 <- f3(x))
   user  system elapsed
   1.65    0.00    1.72
> identical(out1, out2)
[1] TRUE
> identical(out1, out3)
[1] TRUE


On 6/19/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> xx is 1 in every position of the first run of TRUE, 2 in every
> position in the 2nd run of TRUE and so on.  The parenthesized
> expression in the second line converts those to increasing
> values and multiplying it by x zaps the garbage in the positions
> that correspond to FALSE in x.
>
> xx <- cumsum(diff(c(FALSE, x)) > 0)
> (seq_along(x) - match(xx, xx) + 1) * x
>
>
> On 6/19/07, Feng, Ken <ken.feng at citi.com> wrote:
> > Hi,
> >
> > I start with an array of booleans:
> >
> >        x <- c( TRUE, TRUE, TRUE, FALSE, FALSE, TRUE, TRUE, FALSE, TRUE );
> >
> > I want to define an y <- f(x) such that:
> >
> >        y <- c( 1, 2, 3, 0, 0, 1, 2, 0, 1 );
> >
> > In other words, do a cumsum when I see a TRUE, but reset to 0 if I see a FALSE.
> >
> > I know I can do this with a very slow and ugly loop or maybe use apply,
> > but I was hoping there are some R experts out there who can show me
> > a cleaner/more elegant solution?
> >
> > Thanks in advance.
> >
> > - Ken
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>


From ripley at stats.ox.ac.uk  Tue Jun 19 16:48:30 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 19 Jun 2007 15:48:30 +0100 (BST)
Subject: [R] BIC and Hosmer-Lemeshow statistic for logistic regression
In-Reply-To: <11195410.post@talk.nabble.com>
References: <11193273.post@talk.nabble.com> <4677C7CB.4060705@vanderbilt.edu>
	<11195410.post@talk.nabble.com>
Message-ID: <Pine.LNX.4.64.0706191511570.4194@localhost.localdomain>

On Tue, 19 Jun 2007, spime wrote:

> Is there any windows version of Design package???

Yes, the version put up this morning works on 2.5.x (at last).
You should be able to get a Windows build now: it is showing for me on 
CRANextras (where I put it an hour or so ago: it will reach CRAN mirrors 
in a few days).

Ensure you have Hmisc 3.4-1 (on CRAN master yesterday) and Design 2.1-1.


> Frank E Harrell Jr wrote:
>>
>> spime wrote:
>>>
>>> I haven't find any helpful thread. How can i calculate BIC and 
>>> Hosmer-Lemeshow statistic for a logistic regression model. I have used 
>>> glm for logistic fit.
>>
>> See the Design package's lrm function and residuals.lrm for a better GOF
>> test.
>> --
>> Frank E Harrell Jr   Professor and Chair           School of Medicine
>>                       Department of Biostatistics   Vanderbilt University

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From elyakhlifi_mustapha at yahoo.fr  Tue Jun 19 16:56:27 2007
From: elyakhlifi_mustapha at yahoo.fr (elyakhlifi mustapha)
Date: Tue, 19 Jun 2007 14:56:27 +0000 (GMT)
Subject: [R] names over names
Message-ID: <516762.2047.qm@web27509.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070619/4420068e/attachment.pl 

From aresuluca at libero.it  Tue Jun 19 16:18:22 2007
From: aresuluca at libero.it (Luca Aresu)
Date: Tue, 19 Jun 2007 16:18:22 +0200
Subject: [R] cash or nothing option
Message-ID: <02430EAAE30D4FCDAEF75E39FF08EBB0@PCstandard>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070619/25924637/attachment.pl 

From yn19832 at msn.com  Tue Jun 19 17:19:46 2007
From: yn19832 at msn.com (livia)
Date: Tue, 19 Jun 2007 08:19:46 -0700 (PDT)
Subject: [R] Optimization
In-Reply-To: <11178663.post@talk.nabble.com>
References: <11178663.post@talk.nabble.com>
Message-ID: <11196890.post@talk.nabble.com>


It is of great help for your advice. Thanks a lot to you all.

livia wrote:
> 
> Hi, I would like to minimize the value of x1-x2, x2 is a fixed value of
> 0.01, x1 is the quantile of normal distribution (0.0032,x) with
> probability of 0.7, and the changing value should be x. Initial value for
> x is 0.0207. I am using the following codes, but it does not work.
> 
> fr <- function(x) {
>       x1<-qnorm(0.7,0.0032,x)
>       x2=0.01
>       x1-x2
> }
> xsd <- optim(0.0207, fr, NULL,method="BFGS")
> 
> It is the first time I am trying to use optimization. Could anyone give me
> some advice?
> 

-- 
View this message in context: http://www.nabble.com/Optimization-tf3941212.html#a11196890
Sent from the R help mailing list archive at Nabble.com.


From lawremi at iastate.edu  Tue Jun 19 15:10:35 2007
From: lawremi at iastate.edu (Michael Lawrence)
Date: Tue, 19 Jun 2007 08:10:35 -0500
Subject: [R] [R-pkgs] RGtk2 2.10.x series available
Message-ID: <509e0620706190610ra4f82fdv1f547ef7d3323777@mail.gmail.com>

The new 2.10.x series of the RGtk2 package has recently become available on
CRAN. RGtk2 is a package for creating graphical user interfaces (GUI's) in R
and is similar in purpose to the tcltk package. RGtk2 binds to and enables
the extension of the GTK+ user interface library, as well as several other
libraries that are integrated with GTK+. The gWidgetsRGtk2 package provides
an RGtk2 implementation of the elegant toolkit-independent gWidgets API. The
cairoDevice package allows embedding of R graphics inside RGtk2 interfaces.

RGtk2 2.10.x (currently at 2.10.9-1) brings several major improvements:

* Updated bindings to the latest stable versions of all bound libraries,
which include: GTK+, GDK, GdkPixbuf, Cairo, Pango and libglade.
* The ability to create new GObject classes, including new types of widgets,
entirely from within R.
* The compilation of RGtk2 now conditions on the versions of the libraries
installed on the system. This means that RGtk2 has the same dependencies as
the original 2.8.x series, but if newer versions of libraries (ie GTK+
2.10.x) are available, it will bind to the new API.
* Much of the C-level API has been registered to be callable from the C code
of other packages (allowing packages binding other GObject-based libraries
to borrow from RGtk2).
* Many, many bugfixes and minor improvements.

RGtk2 offers several advantages over tcltk:

* Many more features (too many more to list)
* Arguably cleaner API
* Integration with gWidgets (via gWidgetsRGtk2); see the 'pmg' package for
an example of this in action.
* The ability to create new types of widgets from scratch.
* Support for building GUI's using the point-and-click interface design tool
Glade (via libglade); see the 'rattle' package for example.
* Extras: Cairo vector graphics, GdkPixbuf image manipulation, etc.

RGtk2 as well as all other packages mentioned here are available on CRAN.

Michael Lawrence

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages


From rfrancois at mango-solutions.com  Tue Jun 19 17:28:07 2007
From: rfrancois at mango-solutions.com (Romain Francois)
Date: Tue, 19 Jun 2007 16:28:07 +0100
Subject: [R] plot only x- and y-axis with origin, no box()
In-Reply-To: <76AA79BF7116C04B92C3CD618B701A45036219@JNJBEBEGMS03.eu.jnj.com>
References: <76AA79BF7116C04B92C3CD618B701A45036219@JNJBEBEGMS03.eu.jnj.com>
Message-ID: <4677F607.7080509@mango-solutions.com>

Hello,

You are looking for the box function, and its bty argument. For example, 
this one will do the trick.

R> box( bty = "L")

?par gives more information on the potential values for bty.

Cheers,

Romain


Talloen, Willem [PRDBE] wrote:
> hi all,
>
> I'm trying for quite some time to have an x- and y-axis, but no entire box.
>
>   
>> plot(..,axes=F)
>> axis(1)
>> axis(2)
>>     
> Gives this, but their axes do not go to the origin.
> Quite a number of people find this gap between the two axes disturbing.
> Has anyone an idea how to let these axes go to the origin?
>
> thank you in advance
>   
-- 
Mango Solutions
data analysis that delivers

Tel:  +44(0) 1249 467 467
Fax:  +44(0) 1249 467 468
Mob:  +44(0) 7813 526 123

R training course for the Pharmaceutical Industry
1st  - 3rd  October. Basel, Switzerland
http://www.mango-solutions.com/services/rtraining/r_pharma.html


From yn19832 at msn.com  Tue Jun 19 17:33:45 2007
From: yn19832 at msn.com (livia)
Date: Tue, 19 Jun 2007 08:33:45 -0700 (PDT)
Subject: [R] Function -return value
Message-ID: <11197159.post@talk.nabble.com>


Hi, I am trying to write a function with the following codes and I would like
it to return the values for "alpha
beta para parab " seperately. Then I would like to use this funstion for
"variable" with factor "a" and "b". But the result turns out to be a matrix
with element like "Numeric,2" ... I guess they are just the values for
"parab", and we can not even see the two parameters in parab.


parameter <- function(v) { 
v1 <- v[v>mean(v)+0.5*sd(v)]
v2 <- v[v<mean(v)-0.5*sd(v)]
alpha=min(v1)
beta=max(v2)
para <- fitgpd(v1,alpha, method="pwmu")$param 
parab <- fitgpd((-v2), (-beta), method="pwmu")$param 
v1.fit <- qgpd(ppoints(v1, a=0.5), alpha, para[1], para[2])
v2.fit <- qgpd(ppoints((-v2), a=0.5), (-beta), para[1], para[2])
alpha
beta
para
parab

}

tapply(variable, list(a, b),parameter)


I would be grateful if anyone can give me some advice. Many thanks
-- 
View this message in context: http://www.nabble.com/Function--return-value-tf3947134.html#a11197159
Sent from the R help mailing list archive at Nabble.com.


From steven.brady at yale.edu  Tue Jun 19 17:59:15 2007
From: steven.brady at yale.edu (Steve Brady)
Date: Tue, 19 Jun 2007 11:59:15 -0400
Subject: [R] Could not find lmer function in {Matrix} package
Message-ID: <D79FB99C-641D-4D98-B2A7-13B00C23A312@yale.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070619/9b4d6d83/attachment.pl 

From yn19832 at msn.com  Tue Jun 19 18:00:07 2007
From: yn19832 at msn.com (livia)
Date: Tue, 19 Jun 2007 09:00:07 -0700 (PDT)
Subject: [R] Histogram
Message-ID: <11197644.post@talk.nabble.com>


Hello, I am using the following codes to plot a histogram and density line
for x. For the density line, I just want it to show the two tails, eg, for x
larger than 0.05 ans smaller than -0.05

hist (x, seq(-0.1,0.1,0.01),freq = FALSE)
lines (density(x,bw="SJ"), x> 0.05 & x< (-0.05), col = "red")

But is does not work, can anyone give me some advice?



-- 
View this message in context: http://www.nabble.com/Histogram-tf3947281.html#a11197644
Sent from the R help mailing list archive at Nabble.com.


From john2943 at gmail.com  Tue Jun 19 18:05:32 2007
From: john2943 at gmail.com (John Phillips)
Date: Tue, 19 Jun 2007 12:05:32 -0400
Subject: [R] Linear model predictions, differences in class
Message-ID: <c8f263420706190905w4f631b74g5528c9cf537b1a1c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070619/098c8821/attachment.pl 

From ral at lcfltd.com  Tue Jun 19 18:09:22 2007
From: ral at lcfltd.com (Robert A LaBudde)
Date: Tue, 19 Jun 2007 12:09:22 -0400
Subject: [R] outlying
In-Reply-To: <453961.78951.qm@web27503.mail.ukl.yahoo.com>
References: <453961.78951.qm@web27503.mail.ukl.yahoo.com>
Message-ID: <0JJW00L8I4VTHR0C@vms042.mailsrvcs.net>

At 05:29 AM 6/19/2007, elyakhlifi wrote:
>hello,
>are there functions to detecte outlying observations in samples?
>thanks.

library('car')
? outlier.test

library('outliers')
? grubbs.test
? dixon.test
? cochran.test
? chisq.out.test
================================================================
Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
824 Timberlake Drive                     Tel: 757-467-0954
Virginia Beach, VA 23464-3239            Fax: 757-467-2947

"Vere scire est per causas scire"


From mothsailor at googlemail.com  Tue Jun 19 18:10:46 2007
From: mothsailor at googlemail.com (David Barron)
Date: Tue, 19 Jun 2007 17:10:46 +0100
Subject: [R] Could not find lmer function in {Matrix} package
In-Reply-To: <D79FB99C-641D-4D98-B2A7-13B00C23A312@yale.edu>
References: <D79FB99C-641D-4D98-B2A7-13B00C23A312@yale.edu>
Message-ID: <815b70590706190910s40fe368wcb0102d107ea0cd1@mail.gmail.com>

It's now in the lme4 package.

On 19/06/07, Steve Brady <steven.brady at yale.edu> wrote:
> I am having trouble calling the lmer function in the {Matrix}
> package.  I first installed and loaded {Matrix} as follows:
>
>  > install.packages("Matrix")
>  > library(Matrix)
>
> The package loaded successfully, however when I attempted to call
> lmer, I received the following message:
>
> Error: could not find function "lmer"
>
> I also tried:
>
> < ?lmer
>
> which produced no search results.
>
> I have attempted these actions in both MacOSx R Versions 2.4.1 and
> 2.5.0.  I have also tried this in Version 2.5.1. beta on a Windows
> machine.
>
> Thanks in advance for any suggestions.
>
> Steve
> ____________________________________
> Steven P. Brady, M.E.Sc (2007)
> School of Forestry & Environmental Studies
> Yale University
> http://www.cbc.yale.edu/people/skelly/steveb.html
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
=================================
David Barron
Said Business School
University of Oxford
Park End Street
Oxford OX1 1HP


From steven.brady at yale.edu  Tue Jun 19 18:16:44 2007
From: steven.brady at yale.edu (Steve Brady)
Date: Tue, 19 Jun 2007 12:16:44 -0400
Subject: [R] Could not find lmer function in {Matrix} package
In-Reply-To: <815b70590706190910s40fe368wcb0102d107ea0cd1@mail.gmail.com>
References: <D79FB99C-641D-4D98-B2A7-13B00C23A312@yale.edu>
	<815b70590706190910s40fe368wcb0102d107ea0cd1@mail.gmail.com>
Message-ID: <11395ABA-6D73-44B7-ABA0-C717D9DD24D3@yale.edu>

That did the trick.  Thanks.

Steve
On Jun 19, 2007, at 12:10 PM, David Barron wrote:

> It's now in the lme4 package.
>
> On 19/06/07, Steve Brady <steven.brady at yale.edu> wrote:
>> I am having trouble calling the lmer function in the {Matrix}
>> package.  I first installed and loaded {Matrix} as follows:
>>
>>  > install.packages("Matrix")
>>  > library(Matrix)
>>
>> The package loaded successfully, however when I attempted to call
>> lmer, I received the following message:
>>
>> Error: could not find function "lmer"
>>
>> I also tried:
>>
>> < ?lmer
>>
>> which produced no search results.
>>
>> I have attempted these actions in both MacOSx R Versions 2.4.1 and
>> 2.5.0.  I have also tried this in Version 2.5.1. beta on a Windows
>> machine.
>>
>> Thanks in advance for any suggestions.
>>
>> Steve
>> ____________________________________
>> Steven P. Brady, M.E.Sc (2007)
>> School of Forestry & Environmental Studies
>> Yale University
>> http://www.cbc.yale.edu/people/skelly/steveb.html
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting- 
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> -- 
> =================================
> David Barron
> Said Business School
> University of Oxford
> Park End Street
> Oxford OX1 1HP


From eesteves at ualg.pt  Tue Jun 19 18:19:35 2007
From: eesteves at ualg.pt (Eduardo Esteves)
Date: Tue, 19 Jun 2007 17:19:35 +0100
Subject: [R] help w/ nonlinear regression
Message-ID: <000901c7b28d$a095e760$3f8f0a0a@ualg.pt>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070619/eead2b72/attachment.pl 

From Greg.Snow at intermountainmail.org  Tue Jun 19 18:22:54 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Tue, 19 Jun 2007 10:22:54 -0600
Subject: [R] plot only x- and y-axis with origin, no box()
In-Reply-To: <76AA79BF7116C04B92C3CD618B701A45036219@JNJBEBEGMS03.eu.jnj.com>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBA5A265@LP-EXCHVS07.CO.IHC.COM>


Try:

> plot(.., bty='l')

Does that do what you want?  (see the bty parameter in ?par for details)

If you don't want the lines extending beyond the axes on the right and
top then you could do something more like:

> plot(5:10, 5:10, bty='n')
> library(TeachingDemos)
> lines(cnvrt.coords( c(0,0,.5), c(.5,0,0), input='plt')$usr)

You may also get what you want by playing with the xaxp and yaxp
parameters to par, but the bty='l' seems the easiest way to go. 

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Talloen, Willem [PRDBE]
> Sent: Tuesday, June 19, 2007 7:15 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] plot only x- and y-axis with origin, no box()
> 
> hi all,
> 
> I'm trying for quite some time to have an x- and y-axis, but 
> no entire box.
> 
> >plot(..,axes=F)
> >axis(1)
> >axis(2)
> Gives this, but their axes do not go to the origin.
> Quite a number of people find this gap between the two axes 
> disturbing.
> Has anyone an idea how to let these axes go to the origin?
> 
> thank you in advance
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mothsailor at googlemail.com  Tue Jun 19 18:23:03 2007
From: mothsailor at googlemail.com (David Barron)
Date: Tue, 19 Jun 2007 17:23:03 +0100
Subject: [R] Histogram
In-Reply-To: <11197644.post@talk.nabble.com>
References: <11197644.post@talk.nabble.com>
Message-ID: <815b70590706190923k28456c2fr55ca591919e593b4@mail.gmail.com>

I expect there's a more elegant way of doing this, but this should work:

set.seed(101)
x <- rnorm(500,sd=.03)
hist (x, seq(-0.1,0.1,0.01),freq = FALSE)
d <- density(x,bw="SJ")
lowt <- d$x < -.05
upt <- d$x > .05
lines (d$x[lowt],d$y[lowt], col = "red")
lines(d$x[upt],d$y[upt], col = "red")


On 19/06/07, livia <yn19832 at msn.com> wrote:
>
> Hello, I am using the following codes to plot a histogram and density line
> for x. For the density line, I just want it to show the two tails, eg, for x
> larger than 0.05 ans smaller than -0.05
>
> hist (x, seq(-0.1,0.1,0.01),freq = FALSE)
> lines (density(x,bw="SJ"), x> 0.05 & x< (-0.05), col = "red")
>
> But is does not work, can anyone give me some advice?
>
>
>
> --
> View this message in context: http://www.nabble.com/Histogram-tf3947281.html#a11197644
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
=================================
David Barron
Said Business School
University of Oxford
Park End Street
Oxford OX1 1HP


From christophe at pallier.org  Tue Jun 19 18:39:46 2007
From: christophe at pallier.org (Christophe Pallier)
Date: Tue, 19 Jun 2007 18:39:46 +0200
Subject: [R] Function -return value
In-Reply-To: <11197159.post@talk.nabble.com>
References: <11197159.post@talk.nabble.com>
Message-ID: <dea6cb960706190939m69234cd4xd40fe11448c0a51c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070619/f009e146/attachment.pl 

From christophe at pallier.org  Tue Jun 19 18:46:12 2007
From: christophe at pallier.org (Christophe Pallier)
Date: Tue, 19 Jun 2007 18:46:12 +0200
Subject: [R] Function -return value
In-Reply-To: <11197159.post@talk.nabble.com>
References: <11197159.post@talk.nabble.com>
Message-ID: <dea6cb960706190946k41b2a8b6yc3051816399a51f5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070619/ab6c8333/attachment.pl 

From Dietrich.Trenkler at uni-osnabrueck.de  Tue Jun 19 18:51:46 2007
From: Dietrich.Trenkler at uni-osnabrueck.de (Dietrich Trenkler)
Date: Tue, 19 Jun 2007 18:51:46 +0200
Subject: [R] How to compute Wilk's Lambda
Message-ID: <467809A2.40404@uni-osnabrueck.de>

Dear helpeRs,

the following data set comes from Johnson/Wichern: Applied Multivariate
Statistical Analysis, 6th ed, pp. 304-306.

/X <- structure(c(9, 6, 9, 3, 2, 7), .Dim = as.integer(c(3, 2)))
Y <- structure(c(0, 2, 4, 0), .Dim = as.integer(c(2, 2)))
Z <- structure(c(3, 1, 2, 8, 9, 7), .Dim = as.integer(c(3, 2)))/

I would like to compute Wilk's Lambda in R, which I know is 0.0385. How
can I do that? I tried

/U <- rbind(X,Y,Z)
m <- manova(U~rep(1:3, c(3, 2, 3)))
summary(m,test="Wilks")/

which gives


/                     Df  Wilks approx F num Df den Df  Pr(>F)
rep(1:3, c(3, 2, 3))  1  0.162   12.930      2      5 0.01057 *
Residuals             6
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1/


I suppose the argument rep(1:3, c(3, 2, 3)) in manova() is not appropriate.

Any help is very much appreciated.

Dietrich                   

-- 
Dietrich Trenkler c/o Universitaet Osnabrueck 
Rolandstr. 8; D-49069 Osnabrueck, Germany    
email: Dietrich.Trenkler at Uni-Osnabrueck.de


From ripley at stats.ox.ac.uk  Tue Jun 19 18:53:33 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 19 Jun 2007 17:53:33 +0100 (BST)
Subject: [R] Linear model predictions, differences in class
In-Reply-To: <c8f263420706190905w4f631b74g5528c9cf537b1a1c@mail.gmail.com>
References: <c8f263420706190905w4f631b74g5528c9cf537b1a1c@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0706191751080.3035@localhost.localdomain>

tapply gives an array: you want to use as.vector() on its result.

On Tue, 19 Jun 2007, John Phillips wrote:

> Hi,
>
> I am using R to fit statistical models to data were the observations are
> means of the original data.  R is used to calculate the mean before fitting
> the model.  My problem is: When R calculates the means using tapply, the
> class of the means differs from the class of the original data, which gives
> me trouble when I want to use the original data to calculate model
> predictions.  Here is a simple example that demonstrates the problem:
>
>> data.in<-read.table('example.dat',header=TRUE)
>>
>> #Here are the data:
>> data.in
>  location    x      y
> 1        A  17.2  28.46
> 2        A 91.7 143.33
> 3        A 93.6 148.05
> 4        B 95.8 150.28
> 5        B 54.9  89.49
> 6        B 51.1  82.51
> 7        C 53.9  88.46
> 8        C 40.3  63.62
> 9        C 38.5  64.46
> >
>> attach(data.in)
>>
>> #Calculate means by variable "location":
>> data.mn<-data.frame(xm = tapply(x,location,mean), ym =
> tapply(y,location,mean))
>> detach(data.in)
>>
>> #Here are the means:
>> data.mn
>        xm       ym
> A 67.50000 106.6133
> B 67.26667 107.4267
> C 44.23333   72.1800
>>
>> #Fit the model:
>> mod1<-lm(ym ~ xm, data.mn)
>>
>> mod1
>
> Call:
> lm(formula = ym ~ xm, data = data.mn)
>
> Coefficients:
> (Intercept)           xm
>      5.633        1.505
>
>> #R will make "predictions" using the data.mn data frame:
>> predict(mod1,newdata =  data.mn)
>        A         B         C
> 107.19260 106.84153  72.18587
>>
>> #But, even if new variables are created in the original data
>> #with names that match those names used in the regression:
> > data.in$xm<-data.in$x
>> data.in$ym<-data.in$y
>> data.in
>  location    x      y   xm     ym
> 1        A 17.2  28.46 17.2  28.46
> 2        A 91.7 143.33 91.7 143.33
> 3        A 93.6 148.05 93.6 148.05
> 4        B 95.8 150.28 95.8 150.28
> 5        B 54.9  89.49 54.9  89.49
> 6        B 51.1  82.51 51.1  82.51
> 7        C 53.9  88.46 53.9  88.46
> 8        C 40.3  63.62 40.3   63.62
> 9        C 38.5  64.46 38.5  64.46
>>
>> #R will not use data.in to make predictions:
>> predict(mod1,newdata = data.in)
> Error: variable 'xm' was fitted with class "other" but class "numeric" was
> supplied
>>
>> data.in$xm
> [1] 17.2 91.7 93.6 95.8 54.9 51.1 53.9 40.3 38.5
>> data.mn$xm
>       A        B        C
> 67.50000 67.26667 44.23333
>>
>
> Is there a way to make these variables have the same class?  Or, is there
> something other than "tapply" that will work better for this?
>
> Thanks!
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rmh at temple.edu  Tue Jun 19 19:10:41 2007
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 19 Jun 2007 13:10:41 -0400 (EDT)
Subject: [R] How to compute Wilk's Lambda
Message-ID: <20070619131041.CEL75631@po-d.temple.edu>

> m <- manova(U~factor(rep(1:3, c(3, 2, 3))))
> summary(m,test="Wilks")
                             Df  Wilks approx F num Df den Df   Pr(>F)   
factor(rep(1:3, c(3, 2, 3)))  2 0.0385   8.1989      4      8 0.006234 **
Residuals                     5                                          
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
> 


You forgot to declare 1:3 to be a factor.


From p.dalgaard at biostat.ku.dk  Tue Jun 19 19:13:53 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 19 Jun 2007 19:13:53 +0200
Subject: [R] How to compute Wilk's Lambda
In-Reply-To: <467809A2.40404@uni-osnabrueck.de>
References: <467809A2.40404@uni-osnabrueck.de>
Message-ID: <46780ED1.9040100@biostat.ku.dk>

Dietrich Trenkler wrote:
> Dear helpeRs,
>
> the following data set comes from Johnson/Wichern: Applied Multivariate
> Statistical Analysis, 6th ed, pp. 304-306.
>
> /X <- structure(c(9, 6, 9, 3, 2, 7), .Dim = as.integer(c(3, 2)))
> Y <- structure(c(0, 2, 4, 0), .Dim = as.integer(c(2, 2)))
> Z <- structure(c(3, 1, 2, 8, 9, 7), .Dim = as.integer(c(3, 2)))/
>
> I would like to compute Wilk's Lambda in R, which I know is 0.0385. How
> can I do that? I tried
>
> /U <- rbind(X,Y,Z)
> m <- manova(U~rep(1:3, c(3, 2, 3)))
> summary(m,test="Wilks")/
>
> which gives
>
>
> /                     Df  Wilks approx F num Df den Df  Pr(>F)
> rep(1:3, c(3, 2, 3))  1  0.162   12.930      2      5 0.01057 *
> Residuals             6
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1/
>
>
> I suppose the argument rep(1:3, c(3, 2, 3)) in manova() is not appropriate.
>
>   
Exactly. If intended as a grouping, you need to turn it into a factor:

 > m <- manova(U~factor(rep(1:3, c(3, 2, 3))))
 > summary(m,test="Wilks")
Df Wilks approx F num Df den Df Pr(>F)
factor(rep(1:3, c(3, 2, 3))) 2 0.0385 8.1989 4 8 0.006234 **
Residuals 5
---
Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Or, for that matter:

 > anova(lm(U~factor(rep(1:3, c(3, 2, 3)))), test="Wilks")
Analysis of Variance Table

Df Wilks approx F num Df den Df Pr(>F)
(Intercept) 1 0.048 39.766 2 4 0.002293 **
factor(rep(1:3, c(3, 2, 3))) 2 0.038 8.199 4 8 0.006234 **
Residuals 5
---
Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


> Any help is very much appreciated.
>
> Dietrich                   
>
>


From S.Ellison at lgc.co.uk  Tue Jun 19 19:19:03 2007
From: S.Ellison at lgc.co.uk (S Ellison)
Date: Tue, 19 Jun 2007 18:19:03 +0100
Subject: [R] help w/ nonlinear regression
Message-ID: <s6781e29.013@tedmail2.lgc.co.uk>

Your B coefficient differs by a suspicious-looking factor of 2.30... (ln(10). 
Does SPSS log() mean log10 or ln? R log(x) uses ln(x).

S

>>> "Eduardo Esteves" <eesteves at ualg.pt> 19/06/2007 17:19:35 >>>
Dear All,
I'd like to fit a "kind" of logistic model to small data-set using nonlinear least-squares regression. A transcript of R-script are reproduced below. Estimated B and T (the model's coeff, herein B=-8,50 and T=5,46) seem appropriate (at least visually) but are quite diff from those obtained w/ SPSS (Levenberg-Marquardt): B=-19,56 and T=2,37. Am I doing something wrong in R (or at least non-comparable "methodologies")? Please, feel free to comment/suggest.
Regards, Eduardo Esteves

# Dados

CO2<-c(141,172,181,227,309,414,641,936)
Prop<-c(0.25,0.34,0.34,0.68,0.85,0.99,0.98,0.99)

# Diagrama dispers?o

plot(Prop~CO2, las=1, xlim=c(0,1000),ylim=c(0,1),pch=16,cex=1.5,
 xlab="CO2 (ppm)", ylab="Propor??o de respostas correctas")

# Estima?ao (M?todo M?nimos Quadrados)

ajuste<-nls(Prop~(1/3+exp(B*(T-log(CO2))))/(1+exp(B*(T-log(CO2)))),
 data=data.frame(CO2=CO2,Prop=Prop),start=list(B=-10,T=5))
summary(ajuste)

# Ilustracao do ajuste

PropEsp<-predict(ajuste,newdata=list(CO2=seq(0,1000,length=100)),se.fit=T)
lines(PropEsp~seq(0,1000,length=100),lwd=2,col=6)

# IC

upIC<-PropEsp+qt(.975,summary(ajuste)$df[2])*summary(ajuste)$sigma
loIC<-PropEsp-qt(.975,summary(ajuste)$df[2])*summary(ajuste)$sigma
lines(upIC~seq(0,1000,length=100),col=4)
lines(loIC~seq(0,1000,length=100),col=4)
	[[alternative HTML version deleted]]


*******************************************************************
This email and any attachments are confidential. Any use, co...{{dropped}}


From ana.pmartins at ine.pt  Tue Jun 19 19:26:05 2007
From: ana.pmartins at ine.pt (Ana Patricia Martins)
Date: Tue, 19 Jun 2007 18:26:05 +0100
Subject: [R] : create a PDF file (text (print list)  and grafics)
Message-ID: <E97312684A84D511BDD40002A50968D60A35E96D@lxpobw01.ine.pt>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070619/22dde0e4/attachment.pl 

From jrkrideau at yahoo.ca  Tue Jun 19 19:28:57 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Tue, 19 Jun 2007 13:28:57 -0400 (EDT)
Subject: [R] Histogram
In-Reply-To: <11197644.post@talk.nabble.com>
Message-ID: <801844.62210.qm@web32815.mail.mud.yahoo.com>

Your subsetting expression in lines does not make any
sense at all.

Not tested but maybe something like:

lines (density(subset(x, x> 0.05 & x< -0.05)bw=SJ),
col='red")
 
--- livia <yn19832 at msn.com> wrote:

> Hello, I am using the following codes to plot a
> histogram and density line
> for x. For the density line, I just want it to show
> the two tails, eg, for x
> larger than 0.05 ans smaller than -0.05
> 
> hist (x, seq(-0.1,0.1,0.01),freq = FALSE)
> lines (density(x,bw="SJ"), x> 0.05 & x< (-0.05), col
> = "red")
> 
> But is does not work, can anyone give me some
> advice?
> 
> 
> 
> -- 
> View this message in context:
>
http://www.nabble.com/Histogram-tf3947281.html#a11197644
> Sent from the R help mailing list archive at
> Nabble.com.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From jrkrideau at yahoo.ca  Tue Jun 19 19:34:36 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Tue, 19 Jun 2007 13:34:36 -0400 (EDT)
Subject: [R] Could not find lmer function in {Matrix} package
In-Reply-To: <D79FB99C-641D-4D98-B2A7-13B00C23A312@yale.edu>
Message-ID: <606405.62966.qm@web32811.mail.mud.yahoo.com>

I don't think it's there.  I have had a look at the
ref doc and lmer does not show up.  

Have a look at
http://finzi.psych.upenn.edu/R/Rhelp02a/archive/67904.html

It looks like it's in the lme4 package now.


--- Steve Brady <steven.brady at yale.edu> wrote:

> I am having trouble calling the lmer function in the
> {Matrix}  
> package.  I first installed and loaded {Matrix} as
> follows:
> 
>  > install.packages("Matrix")
>  > library(Matrix)
> 
> The package loaded successfully, however when I
> attempted to call  
> lmer, I received the following message:
> 
> Error: could not find function "lmer"
> 
> I also tried:
> 
> < ?lmer
> 
> which produced no search results.
> 
> I have attempted these actions in both MacOSx R
> Versions 2.4.1 and  
> 2.5.0.  I have also tried this in Version 2.5.1.
> beta on a Windows  
> machine.
> 
> Thanks in advance for any suggestions.
> 
> Steve
> ____________________________________
> Steven P. Brady, M.E.Sc (2007)
> School of Forestry & Environmental Studies
> Yale University
> http://www.cbc.yale.edu/people/skelly/steveb.html
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From deepayan.sarkar at gmail.com  Tue Jun 19 20:12:05 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Tue, 19 Jun 2007 11:12:05 -0700
Subject: [R] Controlling text and strip arrangement in xyplot
In-Reply-To: <0JJV0059QH2O47D0@msg-mx5.usc.edu>
References: <0JJV0059QH2O47D0@msg-mx5.usc.edu>
Message-ID: <eb555e660706191112y48b9b4fdxec3c61ff5fc44d35@mail.gmail.com>

On 6/19/07, Juan Pablo Lewinger <lewinger at usc.edu> wrote:
> I've searched the archives and read the xyplot help but can't figure
> out the 2 lattice questions below?
>
> Consider:
>
> library(lattice)
> DF <- data.frame(x=rnorm(20), y=rnorm(20), g1=rep(letters[1:2], 10),
>                   g2=rep(LETTERS[1:2], each=10),
> g3=rep(rep(letters[3:4],each=5),2))
>
> xyplot(y ~ x | g1 + g2, groups=g3, data=DF)
>
> 1) Is there a way to get one strip per row and column of panels as
> below instead of the default?
>
>
>         _|__a__|__b__|
>          |
>        B
>          |
>         --
>          |
>        A
>          |

This has been discussed on the list before (if I remember correctly), and I
have been meaning to add something to the latticeExtra package.  An
implementation would look something like this (beware of line wrapping):


useOuterStrips <-
    function(x,
             strip = strip.default,
             strip.left = strip.custom(horizontal = FALSE))
{
    dimx <- dim(x)
    stopifnot(inherits(x, "trellis"))
    stopifnot(length(dimx) == 2)
    opar <- if (is.null(x$par.settings)) list() else x$par.settings
    par.settings <-
        modifyList(opar,
                   list(layout.heights =
                        list(strip = c(rep(0, dimx[2]-1), 1)),
                        layout.widths =
			list(strip.left = c(1, rep(0, dimx[1]-1)))))
    update(x,
           par.settings = par.settings,
           strip = function(which.given, which.panel, ...) {
               if (which.given == 1)
                   strip(which.given = 1,
                         which.panel = which.panel[1],
                         ...)
           },
           strip.left = function(which.given, which.panel, ...) {
               if (which.given == 2)
                   strip.left(which.given = 1,
                              which.panel = which.panel[2],
                              ...)
           },
           par.strip.text = list(lines = 0.5),
           layout = dimx)
}


The function acts on a "trellis" object and returns an updated one, so
for your example, it would work like:

useOuterStrips(xyplot(y ~ x | g1 + g2, groups=g3, data=DF))


> 2) How do I control the text of the strips so that for instance
> instead of "a" and "b" it reads"g1=alpha", "g1=beta" where "alpha"
> and "beta" stand for the corresponding greek symbols? (my difficulty
> here is not with the plotmath symbols but with controlling the text
> of the strips directly from the call to xyplot and not by renaming
> the levels of g1)

Generally speaking, you need to write your own strip function.  The
default (strip.default) has some useful arguments that modify its
behaviour, and in particular 'factor.levels' might do what you
want.  If you are going to do this in conjunction with (1), life will
actually be simpler and you can get away with using strip.custom():


useOuterStrips(xyplot(y ~ x | g1 + g2, groups=g3, data=DF),
               strip =
               strip.custom(factor.levels =
                            expression(g[1]==alpha, g[1]==beta)),
               strip.left =
               strip.custom(horizontal = FALSE,
                            factor.levels =
                            expression(g[2]==gamma, g[2]==delta)))


Otherwise, you will really have to write a proper strip function that
calls strip.default() with different values of 'factor.levels'
depending on the value of 'which.given'.

Note also the 'strip.names' and 'sep' argument of strip.default(),
which might be more in line with what you want to do.

-Deepayan


From deepayan.sarkar at gmail.com  Tue Jun 19 20:34:03 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Tue, 19 Jun 2007 11:34:03 -0700
Subject: [R] Histograms with strings, grouped by repeat count (w/ data)
In-Reply-To: <572004630706182014w7d08b76cyf3254a7c94d2dbaa@mail.gmail.com>
References: <572004630706181807u3f0698f9vb42027951b777b1@mail.gmail.com>
	<644e1f320706181843p76d4192dlf367574973f15142@mail.gmail.com>
	<572004630706181922p686f60er8e0684bb48c6c04d@mail.gmail.com>
	<644e1f320706181930m77499f99ye91f01f54817a582@mail.gmail.com>
	<572004630706182014w7d08b76cyf3254a7c94d2dbaa@mail.gmail.com>
Message-ID: <eb555e660706191134oa923ec3r4a7a22dda35518fb@mail.gmail.com>

On 6/18/07, Matthew Trunnell <trunnell at cognix.net> wrote:
> Aha!  So to expand that from the original expression,
>
> > table(table(d$filename, d$email_addr))
>
>   0   1   2   3
> 253  20   8   9
>
> I think that is exactly what I'm looking for.  I knew it must be
> simple!!!  What does the 0 column represent?

Number of unique filename:email_addr combinations that don't occur in the data.

> Also, does this tell me the same thing, filtered by Japan?
> > table(table(d$filename, d$email_addr, d$country_residence)[d$country_residence=="Japan"])
>
>   0   1   2   3
> 958   5   2   1

No it doesn't.

> length(table(d$filename, d$email_addr, d$country_residence))
[1] 4350
> length(d$country_residence)
[1] 63

You are using an index that is meaningless.


There's an alternative tabulation function that uses a formula
interface similar to that used in modeling functions; this might be
more transparent for your case:

> count <-
+     xtabs(~filename + email_addr, data = d,
+           subset = country_residence == "Japan")
> xtabs(~count)
count
  0   1   3
284   2   4


> How does that differ logically from this?
>
> > table(table(d$filename, d$email_addr)[d$country_residence=="Japan"])
>
>  0  1  2  3
> 51  4  2  1

This is also using meaningless indexing.

Note, incidentally, that you are indexing a matrix of dimension 10x29
as if it were a vector of length 290, which is probably not what you
meant to do anyway:

> str(table(d$filename, d$email_addr))
 'table' int [1:10, 1:29] 1 0 0 0 0 0 0 0 0 0 ...
 - attr(*, "dimnames")=List of 2
  ..$ : chr [1:10] "file1" "file10" "file2" "file3" ...
  ..$ : chr [1:29] "email1" "email10" "email11" "email12" ...

You need to read help(Extract) carefully and play around with some
simple examples.

> I don't understand why that produces different results.  The first one
> adds a third dimension to the table, but limits that third dimension
> to a single element, Japan.  Shouldn't it be the same?  And again,
> what's that zero column?

As before, they are the empty combinations.

-Deepayan


From wangdeli at gmail.com  Tue Jun 19 20:36:37 2007
From: wangdeli at gmail.com (Deli Wang)
Date: Tue, 19 Jun 2007 13:36:37 -0500
Subject: [R] how to create .rda data file and load it for contributed package
Message-ID: <626c66f20706191136t555b4f91maa622712b34a54a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070619/71f0e8bd/attachment.pl 

From deepayan.sarkar at gmail.com  Tue Jun 19 20:46:16 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Tue, 19 Jun 2007 11:46:16 -0700
Subject: [R] plotting order of lines in xyplot panels while using
	conditioning variable and groups
In-Reply-To: <268595.96374.qm@web86201.mail.ird.yahoo.com>
References: <268595.96374.qm@web86201.mail.ird.yahoo.com>
Message-ID: <eb555e660706191146v6b407e59q9ac1f55c664ae0b3@mail.gmail.com>

On 6/19/07, RICHARD PITMAN <richard.pitman3 at btopenworld.com> wrote:
> I am using the following code:
>
> library(lattice)
> data<-read.csv("data.csv")
> attach(data)
>
> fig<-xyplot(S_t~month|event,
>        key    = list(text=list(lab=c("Time to first CV
> event - Data",
>                                      "Survival post
> first CV event - Model",
>                                      "Survival post
> first MIA/CA event - Data",
>                                      "Survival post
> first CVA event - Data",
>                                      "Survival post
> first TIA event - Data",
>                                      "Survival post
> first CVA/TIA event - Model"),
>                                font=2,
>                                cex=0.55),
>                      lines=list(col=c("red",
>                                       "magenta",
>                                       "blue",
>                                       "brown"),
>                                 type="l",
>                                 cex=0.55,
>                                 lwd=1.5,
>                                 pch=0:1),
>                      corner=c(0,0),x=0.75,y=0.75),
>        group  = group,
>        index.cond = list(c(4,5,6,7,1,2,3)),
>        type   = "l",
>        lwd    = "3",
>        ylim   = c(0,1.5),
>        layout = c(4,2),
>        col    = c("red","magenta","blue","brown"),
>        pch    = 0:3,
>        cex    = 0.5,
>        ylab   = "cumulative probability",
>        xlab   = "months",
>      )
> print(fig)
>
> However, in each panel, the order in which the lines
> are printed is suboptimal as some shorter lines are
> obscured under longer lines. I am having some trouble
> finding a method to change the order in which curves
> are plotted in each panel. I have tried reordering the
> levels in data$group:
>
> data$group<-factor(data$group,
> levels=c("CV_model_event_1","CV model event 2","CV
> event
> 1","CV_event_2","CV_event_2_CVA","CV_event_2_TIA"))
>
> but this changed nothing.
>
> Any suggestions gratefully received.

It's hard to see the problem without a reproducible example, but if
all you want is to order the levels of groups in decreasing order of
frequency, you could use

 groups  = reorder(group, group, function(x) { -length(x) }),

-Deepayan


From quesada at gmail.com  Tue Jun 19 21:12:53 2007
From: quesada at gmail.com (Jose Quesada )
Date: Tue, 19 Jun 2007 21:12:53 +0200
Subject: [R] Matrix library error: "should never happen; please report"
Message-ID: <op.tt6nnr0l4hcap5@delllap.ugr.es>

Hi,

I got the following error. Sorry but this time I couldn't reproduce it  
with a simple chunk of code:

.TM.repl.i.2col(): drop 'matrix' case ...
Error in .nextMethod(x = x, i = i, j = j) :
         'i' has no integer column number should never happen; please report
In addition: Warning messages:
1: Ambiguous method selection for "%*%", target "ddiMatrix#dgCMatrix" (the  
first of the signatures shown will be used)
     diagonalMatrix#CsparseMatrix
     ddenseMatrix#CsparseMatrix
  in: .findInheritedMethods(classes, fdef, mtable)

I got 4 other copies of the same warning. Will play around a bit more...
This is really strange.

Thanks
-- 
Jose Quesada, PhD.
http://www.andrew.cmu.edu/~jquesada


From mark_difford at yahoo.co.uk  Tue Jun 19 21:34:59 2007
From: mark_difford at yahoo.co.uk (Mark Difford)
Date: Tue, 19 Jun 2007 12:34:59 -0700 (PDT)
Subject: [R] Controlling text and strip arrangement in xyplot
In-Reply-To: <eb555e660706191112y48b9b4fdxec3c61ff5fc44d35@mail.gmail.com>
References: <0JJV0059QH2O47D0@msg-mx5.usc.edu>
	<eb555e660706191112y48b9b4fdxec3c61ff5fc44d35@mail.gmail.com>
Message-ID: <11201335.post@talk.nabble.com>


Hi Deepayan,

I, and probably quite a few others, will find this very useful until you
find the time to wrap up a proper implementation.

Many thanks,

BestR,
Mark.


Deepayan Sarkar wrote:
> 
> On 6/19/07, Juan Pablo Lewinger <lewinger at usc.edu> wrote:
>> I've searched the archives and read the xyplot help but can't figure
>> out the 2 lattice questions below?
>>
>> Consider:
>>
>> library(lattice)
>> DF <- data.frame(x=rnorm(20), y=rnorm(20), g1=rep(letters[1:2], 10),
>>                   g2=rep(LETTERS[1:2], each=10),
>> g3=rep(rep(letters[3:4],each=5),2))
>>
>> xyplot(y ~ x | g1 + g2, groups=g3, data=DF)
>>
>> 1) Is there a way to get one strip per row and column of panels as
>> below instead of the default?
>>
>>
>>         _|__a__|__b__|
>>          |
>>        B
>>          |
>>         --
>>          |
>>        A
>>          |
> 
> This has been discussed on the list before (if I remember correctly), and
> I
> have been meaning to add something to the latticeExtra package.  An
> implementation would look something like this (beware of line wrapping):
> 
> 
> useOuterStrips <-
>     function(x,
>              strip = strip.default,
>              strip.left = strip.custom(horizontal = FALSE))
> {
>     dimx <- dim(x)
>     stopifnot(inherits(x, "trellis"))
>     stopifnot(length(dimx) == 2)
>     opar <- if (is.null(x$par.settings)) list() else x$par.settings
>     par.settings <-
>         modifyList(opar,
>                    list(layout.heights =
>                         list(strip = c(rep(0, dimx[2]-1), 1)),
>                         layout.widths =
> 			list(strip.left = c(1, rep(0, dimx[1]-1)))))
>     update(x,
>            par.settings = par.settings,
>            strip = function(which.given, which.panel, ...) {
>                if (which.given == 1)
>                    strip(which.given = 1,
>                          which.panel = which.panel[1],
>                          ...)
>            },
>            strip.left = function(which.given, which.panel, ...) {
>                if (which.given == 2)
>                    strip.left(which.given = 1,
>                               which.panel = which.panel[2],
>                               ...)
>            },
>            par.strip.text = list(lines = 0.5),
>            layout = dimx)
> }
> 
> 
> The function acts on a "trellis" object and returns an updated one, so
> for your example, it would work like:
> 
> useOuterStrips(xyplot(y ~ x | g1 + g2, groups=g3, data=DF))
> 
> 
>> 2) How do I control the text of the strips so that for instance
>> instead of "a" and "b" it reads"g1=alpha", "g1=beta" where "alpha"
>> and "beta" stand for the corresponding greek symbols? (my difficulty
>> here is not with the plotmath symbols but with controlling the text
>> of the strips directly from the call to xyplot and not by renaming
>> the levels of g1)
> 
> Generally speaking, you need to write your own strip function.  The
> default (strip.default) has some useful arguments that modify its
> behaviour, and in particular 'factor.levels' might do what you
> want.  If you are going to do this in conjunction with (1), life will
> actually be simpler and you can get away with using strip.custom():
> 
> 
> useOuterStrips(xyplot(y ~ x | g1 + g2, groups=g3, data=DF),
>                strip =
>                strip.custom(factor.levels =
>                             expression(g[1]==alpha, g[1]==beta)),
>                strip.left =
>                strip.custom(horizontal = FALSE,
>                             factor.levels =
>                             expression(g[2]==gamma, g[2]==delta)))
> 
> 
> Otherwise, you will really have to write a proper strip function that
> calls strip.default() with different values of 'factor.levels'
> depending on the value of 'which.given'.
> 
> Note also the 'strip.names' and 'sep' argument of strip.default(),
> which might be more in line with what you want to do.
> 
> -Deepayan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/Controlling-text-and-strip-arrangement-in-xyplot-tf3944756.html#a11201335
Sent from the R help mailing list archive at Nabble.com.


From BHunsicker at rfmd.com  Tue Jun 19 21:39:33 2007
From: BHunsicker at rfmd.com (Bill Hunsicker)
Date: Tue, 19 Jun 2007 15:39:33 -0400
Subject: [R] Multiple plot jpeg file
Message-ID: <3EA9CDD20D8E694F92C01B7BA7FC5AC809F8A82E@mail.internal.rfmd.com>


R-Help,

I am executing a R script and would like to put multiple plots into a
single file. For some reason the contents of plotfile.jpg always seem to
contain the last plot and not all plots.

If I do same thing with pdf, a multiple plot file is created.

Can you help me?

Regards,
Bill



Bill Hunsicker
RF Micro Devices
7625 Thorndike Road
Greensboro, NC 27409-9421
bhunsicker at rfmd.com
336-678-5260(w)
336-207-3895(m)
336-678-5088(lab)


From marc_schwartz at comcast.net  Tue Jun 19 21:53:56 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Tue, 19 Jun 2007 14:53:56 -0500
Subject: [R] Multiple plot jpeg file
In-Reply-To: <3EA9CDD20D8E694F92C01B7BA7FC5AC809F8A82E@mail.internal.rfmd.com>
References: <3EA9CDD20D8E694F92C01B7BA7FC5AC809F8A82E@mail.internal.rfmd.com>
Message-ID: <1182282836.3690.53.camel@Bellerophon.localdomain>



On Tue, 2007-06-19 at 15:39 -0400, Bill Hunsicker wrote:
> R-Help,
> 
> I am executing a R script and would like to put multiple plots into a
> single file. For some reason the contents of plotfile.jpg always seem to
> contain the last plot and not all plots.
> 
> If I do same thing with pdf, a multiple plot file is created.
> 
> Can you help me?
> 
> Regards,
> Bill

There is no notion of a 'page' in bitmapped devices as there is with PDF
or PS devices. Thus, each time you call plot(...) with a bitmapped
device, the previous output is lost.

If you want multiple plots in a bitmapped device, you would need to use
layout() or par(mfrow/mfcol) to define multiple plot regions within the
overall bitmapped output.

For example:

jpeg("test.jpg", 400, 400)

# Set for 2 rows, 1 col
par(mfrow = c(2, 1))

# Set the margins to make room
par(mar = c(1, 4, 4, 2))

# Draw a barplot
barplot(1:5)

# Set the margins to make room
par(mar = c(5, 4, 1, 2))

# Do a scatterplot
plot(1:10)

# Close the device
dev.off()


Adjust other pars as required.

See ?par and ?layout

HTH,

Marc Schwartz


From jqmcclintic at stthomas.edu  Tue Jun 19 22:02:08 2007
From: jqmcclintic at stthomas.edu (Jason Q McClintic)
Date: Tue, 19 Jun 2007 15:02:08 -0500
Subject: [R] A question about plots and lists in functions
Message-ID: <46783640.4050609@stthomas.edu>

R-helpers:

I tried googling and couldn't find anything.

I have a function I am sourcing into R that does some calculations to
generate a simulated dataset. I currently have a a list set up to store
the outputs from the function and a plot of one of them (a set of
ordered pairs) like this:

foo<-function(x,y,z){
## do some work here ##
list(x=x,y=y,z=z,output1=output1,output2=output2,
     plot=plot(output1[,1],output1[,2],type=p));
}

The problem I am having is that when I do

>work<-foo(x,y,z)
>work

it will show the plot, but I would like to be able to repeatedly call it
like I can call the different plots in an lm without having to display
everything else too (in some cases, output1 could be a 50K by 2 matrix,
rather inconvenient to keep having it display that over and over again
to get a graph).

Thanks in advance,

Jason Q. McClintic
--
Jason Q McClintic
jqmcclintic at stthomas.edu
mccl0219 at tc.umn.edu


From f.harrell at vanderbilt.edu  Tue Jun 19 22:06:45 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Tue, 19 Jun 2007 15:06:45 -0500
Subject: [R] BIC and Hosmer-Lemeshow statistic for logistic regression
In-Reply-To: <11195410.post@talk.nabble.com>
References: <11193273.post@talk.nabble.com> <4677C7CB.4060705@vanderbilt.edu>
	<11195410.post@talk.nabble.com>
Message-ID: <46783755.9050300@vanderbilt.edu>

spime wrote:
> 
> Is there any windows version of Design package???

Soon the new version will will make its way to Windows, probably in a 
day or two.

Frank

> 
> 
> 
> 
> 
> 
> Frank E Harrell Jr wrote:
>> spime wrote:
>>> I haven't find any helpful thread. How can i calculate BIC and
>>> Hosmer-Lemeshow statistic for a logistic regression model. I have used
>>> glm
>>> for logistic fit.
>> See the Design package's lrm function and residuals.lrm for a better GOF 
>> test.
>>
>>
>>
>> -- 
>> Frank E Harrell Jr   Professor and Chair           School of Medicine
>>                       Department of Biostatistics   Vanderbilt University
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>


From squirrel84 at a1.net  Tue Jun 19 22:15:49 2007
From: squirrel84 at a1.net (Daniel Tahin)
Date: Tue, 19 Jun 2007 22:15:49 +0200
Subject: [R] Preconditions for a variance analysis
Message-ID: <46785595.1375.23DF23C@localhost>

Hello everbody,

i'm currently using the anova()-test for a small data.frame of 40 
rows and 2 columns. It works well, but is there any preconditions for 
a valid variance analysis, that i should consider?

Thank you for your answer,
Daniel


From ripley at stats.ox.ac.uk  Tue Jun 19 22:09:23 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 19 Jun 2007 21:09:23 +0100 (BST)
Subject: [R] Multiple plot jpeg file
In-Reply-To: <1182282836.3690.53.camel@Bellerophon.localdomain>
References: <3EA9CDD20D8E694F92C01B7BA7FC5AC809F8A82E@mail.internal.rfmd.com>
	<1182282836.3690.53.camel@Bellerophon.localdomain>
Message-ID: <Pine.LNX.4.64.0706192106410.10061@gannet.stats.ox.ac.uk>

On Tue, 19 Jun 2007, Marc Schwartz wrote:

>
>
> On Tue, 2007-06-19 at 15:39 -0400, Bill Hunsicker wrote:
>> R-Help,
>>
>> I am executing a R script and would like to put multiple plots into a
>> single file. For some reason the contents of plotfile.jpg always seem to
>> contain the last plot and not all plots.
>>
>> If I do same thing with pdf, a multiple plot file is created.
>>
>> Can you help me?
>>
>> Regards,
>> Bill
>
> There is no notion of a 'page' in bitmapped devices as there is with PDF
> or PS devices. Thus, each time you call plot(...) with a bitmapped
> device, the previous output is lost.

But there is a concept of multiple pages in separate files and that is the 
default, Rplot001.jpg, Rplot002.jpg and so on.

The JPEG format only supports one 'page' per file.

> If you want multiple plots in a bitmapped device, you would need to use
> layout() or par(mfrow/mfcol) to define multiple plot regions within the
> overall bitmapped output.
>
> For example:
>
> jpeg("test.jpg", 400, 400)
>
> # Set for 2 rows, 1 col
> par(mfrow = c(2, 1))
>
> # Set the margins to make room
> par(mar = c(1, 4, 4, 2))
>
> # Draw a barplot
> barplot(1:5)
>
> # Set the margins to make room
> par(mar = c(5, 4, 1, 2))
>
> # Do a scatterplot
> plot(1:10)
>
> # Close the device
> dev.off()
>
>
> Adjust other pars as required.
>
> See ?par and ?layout
>
> HTH,
>
> Marc Schwartz
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From marc_schwartz at comcast.net  Tue Jun 19 22:20:29 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Tue, 19 Jun 2007 15:20:29 -0500
Subject: [R] Multiple plot jpeg file
In-Reply-To: <Pine.LNX.4.64.0706192106410.10061@gannet.stats.ox.ac.uk>
References: <3EA9CDD20D8E694F92C01B7BA7FC5AC809F8A82E@mail.internal.rfmd.com>
	<1182282836.3690.53.camel@Bellerophon.localdomain>
	<Pine.LNX.4.64.0706192106410.10061@gannet.stats.ox.ac.uk>
Message-ID: <1182284429.3690.63.camel@Bellerophon.localdomain>

On Tue, 2007-06-19 at 21:09 +0100, Prof Brian Ripley wrote:
> On Tue, 19 Jun 2007, Marc Schwartz wrote:
> 
> >
> >
> > On Tue, 2007-06-19 at 15:39 -0400, Bill Hunsicker wrote:
> >> R-Help,
> >>
> >> I am executing a R script and would like to put multiple plots into a
> >> single file. For some reason the contents of plotfile.jpg always seem to
> >> contain the last plot and not all plots.
> >>
> >> If I do same thing with pdf, a multiple plot file is created.
> >>
> >> Can you help me?
> >>
> >> Regards,
> >> Bill
> >
> > There is no notion of a 'page' in bitmapped devices as there is with PDF
> > or PS devices. Thus, each time you call plot(...) with a bitmapped
> > device, the previous output is lost.
> 
> But there is a concept of multiple pages in separate files and that is the 
> default, Rplot001.jpg, Rplot002.jpg and so on.
> 
> The JPEG format only supports one 'page' per file

Quite true.  I thinking of 'pages' in the context of a PDF or PS file,
as Bill had noted above and contrasting that with a bitmapped image of a
defined finite 2D pixel space.

Thanks for clarifying.

Regards,

Marc


From hvillalo at ipn.mx  Tue Jun 19 22:31:37 2007
From: hvillalo at ipn.mx (=?ISO-8859-1?Q?H=E9ctor_Villalobos?=)
Date: Tue, 19 Jun 2007 14:31:37 -0600
Subject: [R] axis labels in multiple plots
Message-ID: <4677E8C9.27334.1665A67@hvillalo.ipn.mx>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070619/09d1530b/attachment.pl 

From robert-mcfadden at o2.pl  Tue Jun 19 22:51:18 2007
From: robert-mcfadden at o2.pl (Robert McFadden)
Date: Tue, 19 Jun 2007 22:51:18 +0200
Subject: [R] Speed up R
Message-ID: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAfHU8PP2E50qGgSIBTaVydsKAAAAQAAAABwQr1ccyxkyN/Yw5Qh9faQEAAAAA@o2.pl>

Dear R Users,
I hope that there is someone who has an experience with a problem that I
describe below and will help me. 
I must buy new desktop computer and I'm wondering which processor to choose
if my only aim is to speed up R. I would like to reduce a simulation time -
sometimes it takes days. I consider buying one of them (I'm working under
Win XP 32 bit):  
1. Intel Core2 Duo E6700 2.67 GHz
2. Dual-Core Intel Xeon processor 3070 - 2,66 GHz
3. AMD Athlon 64 X2 6000+
Or simple Pentium 4?

I'm very confused because I'm not sure whether R takes advantage dual-core
or not. If not, probably Athlon would be better, wouldn't be? 
I would appreciate any help.
Rob


From petersajosi at yahoo.com  Tue Jun 19 22:54:27 2007
From: petersajosi at yahoo.com (Peter Sajosi)
Date: Tue, 19 Jun 2007 13:54:27 -0700 (PDT)
Subject: [R] Error handling
Message-ID: <273142.97552.qm@web43142.mail.sp1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070619/6baeb17b/attachment.pl 

From marc_schwartz at comcast.net  Tue Jun 19 23:06:34 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Tue, 19 Jun 2007 16:06:34 -0500
Subject: [R] axis labels in multiple plots
In-Reply-To: <4677E8C9.27334.1665A67@hvillalo.ipn.mx>
References: <4677E8C9.27334.1665A67@hvillalo.ipn.mx>
Message-ID: <1182287194.3690.88.camel@Bellerophon.localdomain>

On Tue, 2007-06-19 at 14:31 -0600, H?ctor Villalobos wrote:
> Hi,
> 
> I'am trying to make a multiple bar plot over a map and I'm having difficulties with the distance
> between axes labels and the axis.  Trying to control this with mgp does not help because it
> controls both axes simultaneously.  For example, with default values (mgp = c(3, 1, 0)) y-axis
> labels are ok, but x-axis labels are not. Setting mgp = c(3, 0, 0) gives good x-axis labels but
> the y-axis labels are over the axis.  Since I'm using subplot() from TechingDemos package I
> don't know how to pass the mgp argument for every axis (like : axis(2, mgp = c(3, 1, 0)).
> 
> I'm using R version 2.5.0 with Windows XP
> 
> 
> ##
> sim.data <- array(runif(420), dim = c(4, 5, 7, 3),
>    dimnames = list(paste("var", 1:4, sep = ""), paste("year", 1:5, sep = ""),
>    paste("lat", 1:7, sep = ""), paste("lon", 1:3, sep = "")) )
> x.pos <- c(3, 6, 9)
> y.pos <- c(1,2,3,4,5,6,7)
> 
> 
> ##  This will be the map, its empty in this example
>       plot(x = 1:10, y = 1:10, type = "n", xlim = c(1, 10), ylim = c(1,8) )
> 
> ##  And now the bar plots
>       for (l in 7:1) {
>          for (m in 1:3) {
> 
>       subplot(barplot(sim.data[, , l, m], las = 1, names.arg = paste("year", 1:5),
>           mgp = c(3, 0, 0), cex.axis = 0.7, cex.names = 0.7,),
>           x = x.pos[m], y = y.pos[l], size = c(1.3,0.5), vadj = 0 )
>         }
>       }
> 
> 
> Any hints ?
> 
> Hctor

I don't use that package or the functions, but it looks like from your
example above, that you might be able to create a modified barplot()
function and then call that in subplot(). 

For example:

mybarplot <- function(height, x.names, ...)
{
  mp <- barplot(height, axes = FALSE, ...)
  mtext(1, at = mp, text = x.names, line = 0)
  axis(2, las = 1, line = -0.75)
}


See ?mtext

Now contrast the spacing of the bar and axis labels:

 par(mfrow = c(2, 1))
 barplot(1:5, names.arg = paste("year", 1:5), las = 1)
 mybarplot(1:5, x.names = paste("year", 1:5))


If something like that works, you can then replace your call to
barplot() above with mybarplot() and adjust the other arguments as you
may require to achieve your desired result.

HTH,

Marc Schwartz


From mckellercran at gmail.com  Tue Jun 19 23:09:00 2007
From: mckellercran at gmail.com (Matthew Keller)
Date: Tue, 19 Jun 2007 17:09:00 -0400
Subject: [R] Speed up R
In-Reply-To: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAfHU8PP2E50qGgSIBTaVydsKAAAAQAAAABwQr1ccyxkyN/Yw5Qh9faQEAAAAA@o2.pl>
References: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAfHU8PP2E50qGgSIBTaVydsKAAAAQAAAABwQr1ccyxkyN/Yw5Qh9faQEAAAAA@o2.pl>
Message-ID: <3f547caa0706191409w3c8f92f0me3dbc44ea56f2674@mail.gmail.com>

Hi Robert,

Here's my 2 cents.

64-bit is a memory issue, not a speed issue per se. If a concern is
increasing RAM (which is important in R since objects are stored in
RAM), then you will want to get 64 bit if you plan on getting a
computer with over 4GB RAM. I'm not sure about this (someone correct
me if I'm wrong), but I think that windows has problems addressing
that much RAM (surely the 64bit Vista is OK with it though... surely).
Linux or Apple (the powermac) might be better bets if you're wanting
to work with programs that use a lot of RAM. BTW, Intel does make 64
bit chips now. They use them in macs.

As for speed, go with multicore processors with as much GHz as possible.

On 6/19/07, Robert McFadden <robert-mcfadden at o2.pl> wrote:
> Dear R Users,
> I hope that there is someone who has an experience with a problem that I
> describe below and will help me.
> I must buy new desktop computer and I'm wondering which processor to choose
> if my only aim is to speed up R. I would like to reduce a simulation time -
> sometimes it takes days. I consider buying one of them (I'm working under
> Win XP 32 bit):
> 1. Intel Core2 Duo E6700 2.67 GHz
> 2. Dual-Core Intel Xeon processor 3070 - 2,66 GHz
> 3. AMD Athlon 64 X2 6000+
> Or simple Pentium 4?
>
> I'm very confused because I'm not sure whether R takes advantage dual-core
> or not. If not, probably Athlon would be better, wouldn't be?
> I would appreciate any help.
> Rob
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Matthew C Keller
Postdoctoral Fellow
Virginia Institute for Psychiatric and Behavioral Genetics


From tlumley at u.washington.edu  Tue Jun 19 23:14:48 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 19 Jun 2007 14:14:48 -0700 (PDT)
Subject: [R] Error handling
In-Reply-To: <273142.97552.qm@web43142.mail.sp1.yahoo.com>
References: <273142.97552.qm@web43142.mail.sp1.yahoo.com>
Message-ID: <Pine.LNX.4.64.0706191414020.26395@homer24.u.washington.edu>


This is FAQ 7.32 How can I capture or ignore errors in a long simulation?

 	-thomas

On Tue, 19 Jun 2007, Peter Sajosi wrote:

> Hello,
>
>  I have a question about error handling. I run simulation studies and often the program stops with an error, for example during maximum likelihood. I would like the program not to stop but to continue and I would like to ask how the error handling can be set up for this (if it can). I tried to look through manuals etc but unfortunately did not get closer to the solution. Below is a small example with some numbers, where the nlm function gives an error. Is it possible to make R and the program ignore the error?
>
>  (there is a small for loop in the end of the example, which breaks - ideally the program would complete the for loop even though there are errors). Of course this is just an example, in the simulation study the error comes up quite rarely but still it is annoying to handle it manually each time.
>  Many thanks
> Peter
>
>  The example:
>  ------------
>
> logfunc <- function (params) {
>  vutil1 <- as.matrix(x2[,1:3]) %*% params
> vutil2 <- as.matrix(x2[,4:6]) %*% params
>  logl <- 0
>  for (i in 1:6) {
>  prob <- log((exp(vutil1[i])*achoices[i,1]+exp(vutil2[i])*achoices[i,2])/(exp(vutil1[i])+exp(vutil2[i])))
>  logl <- logl + prob
>  }
>  return (-logl)
>  }
>
> x2 <- array(c(0,4,1,3,5,3,3,2,1,4,1,2,0,2,2,1,1,4,1.2233310 ,0.0000000 ,0.8155540 ,0.9320617 ,1.4272195 ,1.8349965 , 0.6116655, 3.2622160, 0.8155540, 3.7282469,0.0000000 ,4.5874913 ,0.6116655,3.2622160 ,1.6311080 ,1.8641235, 4.2816586, 0.9174983),dim=c(6,6))
> achoices <- array(c(1,0,1,0,1,0,0,1,0,1,0,1),dim=c(6,2))
>  for (k in 1:5) {
>  nlm(logfunc, c (1,1,1),print.level=2)
>  }
>  ---
>  Thanks!!!
>  -------
>
>
>
>
> ---------------------------------
> Moody friends. Drama queens. Your life? Nope! - their life, your story.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From ripley at stats.ox.ac.uk  Tue Jun 19 23:41:14 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 19 Jun 2007 22:41:14 +0100 (BST)
Subject: [R] Speed up R
In-Reply-To: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAfHU8PP2E50qGgSIBTaVydsKAAAAQAAAABwQr1ccyxkyN/Yw5Qh9faQEAAAAA@o2.pl>
References: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAfHU8PP2E50qGgSIBTaVydsKAAAAQAAAABwQr1ccyxkyN/Yw5Qh9faQEAAAAA@o2.pl>
Message-ID: <Pine.LNX.4.64.0706192216270.12443@gannet.stats.ox.ac.uk>

On Tue, 19 Jun 2007, Robert McFadden wrote:

> Dear R Users,
> I hope that there is someone who has an experience with a problem that I
> describe below and will help me.
> I must buy new desktop computer and I'm wondering which processor to choose
> if my only aim is to speed up R. I would like to reduce a simulation time -
> sometimes it takes days. I consider buying one of them (I'm working under
> Win XP 32 bit):
> 1. Intel Core2 Duo E6700 2.67 GHz
> 2. Dual-Core Intel Xeon processor 3070 - 2,66 GHz
> 3. AMD Athlon 64 X2 6000+
> Or simple Pentium 4?
>
> I'm very confused because I'm not sure whether R takes advantage dual-core
> or not.

Not under Windows XP.

The experience under Linux shows that on the right problem dual processors 
can help a lot (say 1.8x), but the gains are typically modest and can even 
be negative.

The advantage of dual processors is that you can use the machine for 
several things at once, including multiple R jobs.  For example, when I am 
doing package checking I am typically checking 4 packages at once on a 
dual processor machine to get continuous high utilization.

> If not, probably Athlon would be better, wouldn't be?

I have little doubt that a Pentium 4 would be much slower than the others.

I've just bought an Intel Core 2 Duo E6600 primarily to run 64-bit Linux, 
but it also has Vista 64 and XP (32-bit) on it.  I don't think the
differences between the current dual-core chips are really enough to
worry about: they will all look slow in less than a year.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.murrell at auckland.ac.nz  Wed Jun 20 03:08:33 2007
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Wed, 20 Jun 2007 13:08:33 +1200
Subject: [R] help with using grid to modify ggplot/lattice plots
In-Reply-To: <20070605143119.GA7140@shireen.jnu.ac.in>
References: <20070605143119.GA7140@shireen.jnu.ac.in>
Message-ID: <46787E11.8020503@stat.auckland.ac.nz>

Hi


Vikas Rawal wrote:
> I want to use grid to modify some boxplots made using ggplot. I would
> really appreciate if somebody could guide me to a resource on how to
> use grid to modify such graphics. I guess the basic approach will be
> similar to using grid to modify lattice graphics. To that extent
> something that explains use of grid to modify lattice graphics may
> also be useful.
>
> I have gone through vignettes in the grid package but am somehow not
> able to understand the overall approach. It would be useful if there
> is something more specific that deals with using grid to modify such
> graphics.


A couple of suggestions:
- look at Hadley Wickham's online book draft for ggplot2
http://had.co.nz/ggplot2/
- look at the online chapter on grid from my book
http://www.stat.auckland.ac.nz/~paul/RGraphics/chapter5.pdf

Paul

> Vikas Rawal
> Associate Professor
> Centre for Economic Studies and Planning
> Jawaharlal Nehru University
> New Delhi
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From chainsawtiney at gmail.com  Wed Jun 20 03:30:16 2007
From: chainsawtiney at gmail.com (Chung-hong Chan)
Date: Wed, 20 Jun 2007 09:30:16 +0800
Subject: [R] Date and selection
Message-ID: <30d7ea360706191830m13e3079bqf48cac79dcf205d6@mail.gmail.com>

Dear R experts,

Suppose I have a data.frame recording the date and test results of
some subjects like this:

Name Date results
John 01/01/1991 2
John 02/01/1991 3
John 09/0101991 4
Micheal 02/01/1991 4
Micheal 04/01/1991 5
....

How to select the earliest (or latest) test result from all subjects?

Thank you.

Regards,

CH



-- 
"The scientists of today think deeply instead of clearly. One must be
sane to think clearly, but one can think deeply and be quite insane."
Nikola Tesla
http://www.macgrass.com


From Rhelp at ajackson.org  Wed Jun 20 03:37:49 2007
From: Rhelp at ajackson.org (Alan Jackson)
Date: Tue, 19 Jun 2007 20:37:49 -0500
Subject: [R] making a Time of Day axis
Message-ID: <20070619203749.460075d7@nova.oplnk.net>

I am wrestling with time and date data. I came up with a way to plot and
label a histogram with "time of day" on the x-axis, but it seemed like a
lot more work than should be necessary. Is there a better way to do what
I am trying to do?

require(chron)
#	read input data
data = read.table("input.dat", header=T)
#	Create date-time and chron objects
datetime = strptime(paste(data[,3], data[,2]),format="%m/%d/%y %H:%M")
time = times(paste(as.vector(data[,2]), ":00",sep=""))
#	Put it all into a data frame
data = data.frame(time, datetime, data$Trip)
names(data) = c("Time","DateTime","Trip")
attach(data)
#	Create time of day array
times = as.numeric(chron(times = Time))
tod = subset(times, Trip=='m');
#	Plot base histogram
hist(tod, axes=F, main="Morning Bus Arrival Times", xlab="Time", col="blue");
axis(2);
#	where are the tics to be?
tics = seq(min(tod), max(tod), (max(tod)-min(tod))/5);
#	build a labeled x-axis for the plot
axis(1, tics, labels=sub(":00$","",as.character(chron(times=tics, out.format="h:m:s"))));

#	cleanup
detach(data)

--- Data ---
Trip Time Date
a 15:55 05/15/07
m  5:47 05/16/07
a 15:54 05/16/07
m  5:47 05/17/07
a 15:59 05/17/07
m  5:50 05/21/07
m  5:50 05/22/07
a 16:00 05/22/07
m  5:48 05/23/07
m  5:50 05/24/07
a 16:00 05/24/07
m  5:48 05/25/07
m  5:48 05/29/07
a 15:59 05/29/07
m  5:46 05/30/07
m  5:45 05/31/07
a 16:05 05/31/07
m  5:47 06/04/07
a 15:53 06/04/07
m  5:46 06/05/07
m  5:47 06/06/07
a 15:53 06/06/07
m  5:47 06/07/07
a 15:51 06/07/07
m  5:45 06/08/07
f 15:22 06/08/07
m  5:48 06/11/07
m  5:46 06/12/07
m  5:48 06/13/07
m  5:47 06/18/07
a 15:53 06/18/07
m  5:47 06/19/07
a 15:55 06/19/07


-- 
-----------------------------------------------------------------------
| Alan K. Jackson            | To see a World in a Grain of Sand      |
| alan at ajackson.org          | And a Heaven in a Wild Flower,         |
| www.ajackson.org           | Hold Infinity in the palm of your hand |
| Houston, Texas             | And Eternity in an hour. - Blake       |


From jholtman at gmail.com  Wed Jun 20 03:39:31 2007
From: jholtman at gmail.com (jim holtman)
Date: Tue, 19 Jun 2007 21:39:31 -0400
Subject: [R] Date and selection
In-Reply-To: <30d7ea360706191830m13e3079bqf48cac79dcf205d6@mail.gmail.com>
References: <30d7ea360706191830m13e3079bqf48cac79dcf205d6@mail.gmail.com>
Message-ID: <644e1f320706191839q6375ddc6mfb86df501b886b43@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070619/ed4b795b/attachment.pl 

From Greg.Snow at intermountainmail.org  Wed Jun 20 03:57:28 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Tue, 19 Jun 2007 19:57:28 -0600
Subject: [R] A question about plots and lists in functions
Message-ID: <13aa01c7b2de$576fb7ea$2e80320a@CO.IHC.COM>

?invisible

-----Original Message-----
From: "Jason Q McClintic" <jqmcclintic at stthomas.edu>
To: "r-help at stat.math.ethz.ch" <r-help at stat.math.ethz.ch>
Sent: 6/19/07 2:04 PM
Subject: [R] A question about plots and lists in functions

R-helpers:

I tried googling and couldn't find anything.

I have a function I am sourcing into R that does some calculations to
generate a simulated dataset. I currently have a a list set up to store
the outputs from the function and a plot of one of them (a set of
ordered pairs) like this:

foo<-function(x,y,z){
## do some work here ##
list(x=x,y=y,z=z,output1=output1,output2=output2,
     plot=plot(output1[,1],output1[,2],type=p));
}

The problem I am having is that when I do

>work<-foo(x,y,z)
>work

it will show the plot, but I would like to be able to repeatedly call it
like I can call the different plots in an lm without having to display
everything else too (in some cases, output1 could be a 50K by 2 matrix,
rather inconvenient to keep having it display that over and over again
to get a graph).

Thanks in advance,

Jason Q. McClintic
--
Jason Q McClintic
jqmcclintic at stthomas.edu
mccl0219 at tc.umn.edu

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From mjankowski at gmail.com  Wed Jun 20 04:23:32 2007
From: mjankowski at gmail.com (M. Jankowski)
Date: Tue, 19 Jun 2007 21:23:32 -0500
Subject: [R] Help With Sweave:
Message-ID: <500c63990706191923p261f2ed4nde48eb130cebe15@mail.gmail.com>

Hi All,

I am running Ubuntu Feisty (7.04) on a Thinkpad T41. I've installed
the nowebm package for Ubuntu. Working from this HowTo:
http://www.ci.tuwien.ac.at/~leisch/Sweave/example-1.Snw
I try to compile the example *.Snw as in the Sweave manual:

mdj at lapmdj:~/Desktop/Sweave/example1$ noweb example-1.Snw
Can't open output file

Despite the error, a *.tex file is produced. Now I am stuck because I
cannot seem to get the CTAN noweb package correctly installed  for my
Latex installation. I guess I am somewhat spoiled by the Synaptic
package manager. Here is the result of my best attempt to get the
noweb package installed:

Following the guidelines for installing packages found here:

http://www.ctan.org/tex-archive/info/beginlatex/html/chapter5.html#pk...

I try to install this package:

http://tug.ctan.org/cgi-bin/ctanPackageInformation.py?id=noweb

But there are no *.ins or *.dtx files. There is a *.sty though...

I follow the instructions in the readme and this is the result (Here
are a few of the errors, the complete output is below):
make: [install-shell] Error 1 (ignored)
make: [install-tex] Error 1 (ignored)
make: [install-code] Error 1 (ignored)

A bunch of errors. What am I doing wrong? Any help is much
appreciated!

Of course, if there is a better place for me to ask this question
please let me know where! Thanks!

Matt

mdj at lapmdj:~/downloads/noweb-2.11b/src$ sudo make all install
cd c; make "CC=gcc -ansi -pedantic" "CFLAGS=" all
make[1]: Entering directory `/home/mdj/downloads/noweb-2.11b/src/c'
make[1]: Nothing to be done for `all'.
make[1]: Leaving directory `/home/mdj/downloads/noweb-2.11b/src/c'
for i in shell lib xdoc tex; do (cd $i; make all); done
make[1]: Entering directory `/home/mdj/downloads/noweb-2.11b/src/
shell'
make[1]: Nothing to be done for `all'.
make[1]: Leaving directory `/home/mdj/downloads/noweb-2.11b/src/shell'
make[1]: Entering directory `/home/mdj/downloads/noweb-2.11b/src/lib'
chmod +x unmarkup emptydefn toascii nwmtime pipedocs h2a btdefn
make[1]: Leaving directory `/home/mdj/downloads/noweb-2.11b/src/lib'
make[1]: Entering directory `/home/mdj/downloads/noweb-2.11b/src/xdoc'
make[1]: Nothing to be done for `all'.
make[1]: Leaving directory `/home/mdj/downloads/noweb-2.11b/src/xdoc'
make[1]: Entering directory `/home/mdj/downloads/noweb-2.11b/src/tex'
make[1]: Nothing to be done for `all'.
make[1]: Leaving directory `/home/mdj/downloads/noweb-2.11b/src/tex'
cd awk; make "ICONT=icont" "ICONC=iconc" all
make[1]: Entering directory `/home/mdj/downloads/noweb-2.11b/src/awk'
chmod +x noindex  totex noidx tohtml
make[1]: Leaving directory `/home/mdj/downloads/noweb-2.11b/src/awk'
mkdir /usr/local/noweb /usr/local/noweb/lib 2>/dev/null
make: [install-shell] Error 1 (ignored)
sed "s@|LIBDIR|@/usr/local/noweb/lib@" shell/noweb > /usr/local/noweb/
noweb
chmod +x /usr/local/noweb/noweb
sed "s@|LIBDIR|@/usr/local/noweb/lib@" shell/notangle > /usr/local/
noweb/notangle
chmod +x /usr/local/noweb/notangle
sed "s@|LIBDIR|@/usr/local/noweb/lib@" shell/noweave             > /
usr/local/noweb/noweave
chmod +x /usr/local/noweb/noweave
sed "s@|LIBDIR|@/usr/local/noweb/lib@" shell/nountangle > /usr/local/
noweb/nountangle
chmod +x /usr/local/noweb/nountangle
sed "s@|LIBDIR|@/usr/local/noweb/lib@" shell/nodefs > /usr/local/noweb/
nodefs
chmod +x /usr/local/noweb/nodefs
sed "s@|LIBDIR|@/usr/local/noweb/lib@" shell/noroots > /usr/local/
noweb/noroots
chmod +x /usr/local/noweb/noroots
sed "s@|LIBDIR|@/usr/local/noweb/lib@" shell/nuweb2noweb > /usr/local/
noweb/nuweb2noweb
chmod +x /usr/local/noweb/nuweb2noweb
sed "s@|LIBDIR|@/usr/local/noweb/lib@" shell/cpif > /usr/local/noweb/
cpif
chmod +x /usr/local/noweb/cpif
sed "s@|LIBDIR|@/usr/local/noweb/lib@" shell/htmltoc > /usr/local/
noweb/htmltoc
chmod +x /usr/local/noweb/htmltoc
sed "s@|LIBDIR|@/usr/local/noweb/lib@" shell/noroff > /usr/local/noweb/
noroff
chmod +x /usr/local/noweb/noroff
sed "s@|LIBDIR|@/usr/local/noweb/lib@" shell/toroff > /usr/local/noweb/
lib/toroff
chmod +x /usr/local/noweb/lib/toroff
cp shell/tmac.w /usr/local/noweb/lib
mkdir /usr/local/noweb /usr/local/noweb/lib 2>/dev/null
make: [install-code] Error 1 (ignored)
strip c/nt c/markup c/mnt c/finduses
cp c/nt c/markup c/mnt c/finduses /usr/local/noweb/lib
cd awk; make ICONT=icont ICONC=iconc LIB=/usr/local/noweb/lib BIN=/usr/
local/noweb install
make[1]: Entering directory `/home/mdj/downloads/noweb-2.11b/src/awk'
chmod +x noindex  totex noidx tohtml
cp totex noidx tohtml /usr/local/noweb/lib
cp noindex  /usr/local/noweb
make[1]: Leaving directory `/home/mdj/downloads/noweb-2.11b/src/awk'
cd lib; make LIB=/usr/local/noweb/lib install
make[1]: Entering directory `/home/mdj/downloads/noweb-2.11b/src/lib'
chmod +x unmarkup emptydefn toascii nwmtime pipedocs h2a btdefn
cp unmarkup emptydefn toascii nwmtime h2a btdefn /usr/local/noweb/lib
sed 's@|LIBDIR|@/usr/local/noweb/lib at g' pipedocs > /usr/local/noweb/
lib/pipedocs
chmod +x /usr/local/noweb/lib/pipedocs
make[1]: Leaving directory `/home/mdj/downloads/noweb-2.11b/src/lib'
mkdir /usr/local/noweb/man /usr/local/noweb/man/man1 /usr/local/noweb/
man/man7 2>/dev/null
make: [install-man] Error 1 (ignored)
sed -e "s@|LIBDIR|@/usr/local/noweb/lib@" -e "s@|TEXINPUTS|@/usr/local/
tex/inputs@" xdoc/cpif.1 > /usr/local/noweb/man/man1/cpif.1
sed -e "s@|LIBDIR|@/usr/local/noweb/lib@" -e "s@|TEXINPUTS|@/usr/local/
tex/inputs@" xdoc/nodefs.1 > /usr/local/noweb/man/man1/nodefs.1
sed -e "s@|LIBDIR|@/usr/local/noweb/lib@" -e "s@|TEXINPUTS|@/usr/local/
tex/inputs@" xdoc/noroots.1 > /usr/local/noweb/man/man1/noroots.1
sed -e "s@|LIBDIR|@/usr/local/noweb/lib@" -e "s@|TEXINPUTS|@/usr/local/
tex/inputs@" xdoc/noweb.1 > /usr/local/noweb/man/man1/noweb.1
sed -e "s@|LIBDIR|@/usr/local/noweb/lib@" -e "s@|TEXINPUTS|@/usr/local/
tex/inputs@" xdoc/noindex.1 > /usr/local/noweb/man/man1/noindex.1
sed -e "s@|LIBDIR|@/usr/local/noweb/lib@" -e "s@|TEXINPUTS|@/usr/local/
tex/inputs@" xdoc/nuweb2noweb.1 > /usr/local/noweb/man/man1/
nuweb2noweb.1
sed -e "s@|LIBDIR|@/usr/local/noweb/lib@" -e "s@|TEXINPUTS|@/usr/local/
tex/inputs@" xdoc/notangle.1 > /usr/local/noweb/man/man1/notangle.1
sed -e "s@|LIBDIR|@/usr/local/noweb/lib@" -e "s@|TEXINPUTS|@/usr/local/
tex/inputs@" xdoc/noroff.1 > /usr/local/noweb/man/man1/noroff.1
sed -e "s@|LIBDIR|@/usr/local/noweb/lib@" -e "s@|TEXINPUTS|@/usr/local/
tex/inputs@" xdoc/sl2h.1 > /usr/local/noweb/man/man1/sl2h.1
sed -e "s@|LIBDIR|@/usr/local/noweb/lib@" -e "s@|TEXINPUTS|@/usr/local/
tex/inputs@" xdoc/htmltoc.1 > /usr/local/noweb/man/man1/htmltoc.1
sed -e "s@|LIBDIR|@/usr/local/noweb/lib@" -e "s@|TEXINPUTS|@/usr/local/
tex/inputs@" xdoc/nowebstyle.7 > /usr/local/noweb/man/man7/nowebstyle.
7
sed -e "s@|LIBDIR|@/usr/local/noweb/lib@" -e "s@|TEXINPUTS|@/usr/local/
tex/inputs@" xdoc/nowebfilters.7 > /usr/local/noweb/man/man7/
nowebfilters.7
rm -f /usr/local/noweb/man/man1/noweave.1
(cd /usr/local/noweb/man/man1; ln notangle.1 noweave.1)
rm -f /usr/local/noweb/man/man1/nountangle.1
(cd /usr/local/noweb/man/man1; ln notangle.1 nountangle.1)
mkdir /usr/local/tex/inputs 2>/dev/null
make: [install-tex] Error 1 (ignored)
cp tex/nwmac.tex tex/noweb.sty /usr/local/tex/inputs
texhash || echo "Program texhash not found or failed"
no
texhash: Updating /var/lib/texmf/ls-R-TEXMFMAIN...
texhash: Updating /var/lib/texmf/ls-R-TEXMFDIST-TETEX...
texhash: Updating /var/lib/texmf/ls-R...
texhash: Done.
mkdir /dev/null 2>/dev/null
make: [install-elisp] Error 1 (ignored)
cp elisp/noweb-mode.el /dev/null
mdj at lapmdj:~/downloads/noweb-2.11b/src$ texhash
texhash: /var/lib/texmf/ls-R-TEXMFMAIN: no write permission.
Skipping...
texhash: /var/lib/texmf/ls-R-TEXMFDIST-TETEX: no write permission.
Skipping...
texhash: /var/lib/texmf/ls-R: no write permission. Skipping...
texhash: Done.
mdj at lapmdj:~/downloads/noweb-2.11b/src$ sudo texhash
no
texhash: Updating /var/lib/texmf/ls-R-TEXMFMAIN...
texhash: Updating /var/lib/texmf/ls-R-TEXMFDIST-TETEX...
texhash: Updating /var/lib/texmf/ls-R...
texhash: Done.
mdj at lapmdj:~/downloads/noweb-2.11b/src$ cd /var/lib/texmf/
mdj at lapmdj:/var/lib/texmf$ ls
fonts  ls-R  ls-R-TEXMFDIST-TETEX  ls-R-TEXMFMAIN  tex  web2c
mdj at lapmdj:/var/lib/texmf$ texhash
texhash: /var/lib/texmf/ls-R-TEXMFMAIN: no write permission.
Skipping...
texhash: /var/lib/texmf/ls-R-TEXMFDIST-TETEX: no write permission.
Skipping...
texhash: /var/lib/texmf/ls-R: no write permission. Skipping...
texhash: Done.
mdj at lapmdj:/var/lib/texmf$ sudo texhash
no
texhash: Updating /var/lib/texmf/ls-R-TEXMFMAIN...
texhash: Updating /var/lib/texmf/ls-R-TEXMFDIST-TETEX...
texhash: Updating /var/lib/texmf/ls-R...
texhash: Done.
mdj at lapmdj:/var/lib/texmf$

I thought that 'sudo texhash' would fix the installation error...but
apparently it did not because:

mdj at lapmdj:~/Desktop/Sweave/example1$ pdflatex example-1.tex
This is pdfeTeX, Version 3.141592-1.30.5-2.2 (Web2C 7.5.5)
entering extended mode
(./example-1.tex
LaTeX2e <2003/12/01>
Babel <v3.8g> and hyphenation patterns for english, usenglishmax,
dumylang, noh
yphenation, loaded.
(/usr/share/texmf-texlive/tex/latex/base/article.cls
Document Class: article 2004/02/16 v1.4f Standard LaTeX document class
(/usr/share/texmf-texlive/tex/latex/base/size10.clo)) (./
example-1.aux)
! Undefined control sequence.
l.13 \nwfilename
                {example-1.Snw}
\nwbegincode{1}\sublabel{NW3jPyRy-0-1}\nwmarg...

?
#Which apparently means that the noweb package has not yet been
installed correctly. What is going wrong?


From edd at debian.org  Wed Jun 20 04:44:06 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 19 Jun 2007 21:44:06 -0500
Subject: [R] Help With Sweave:
In-Reply-To: <500c63990706191923p261f2ed4nde48eb130cebe15@mail.gmail.com>
References: <500c63990706191923p261f2ed4nde48eb130cebe15@mail.gmail.com>
Message-ID: <18040.38006.565172.64274@basebud.nulle.part>


Matt,

On 19 June 2007 at 21:23, M. Jankowski wrote:
| Hi All,
| 
| I am running Ubuntu Feisty (7.04) on a Thinkpad T41. I've installed
| the nowebm package for Ubuntu. Working from this HowTo:
| http://www.ci.tuwien.ac.at/~leisch/Sweave/example-1.Snw
| I try to compile the example *.Snw as in the Sweave manual:
| 
| mdj at lapmdj:~/Desktop/Sweave/example1$ noweb example-1.Snw
| Can't open output file
| 
| Despite the error, a *.tex file is produced. Now I am stuck because I
| cannot seem to get the CTAN noweb package correctly installed  for my
| Latex installation. I guess I am somewhat spoiled by the Synaptic
| package manager. Here is the result of my best attempt to get the
| noweb package installed:

i)   No external noweb package is needed
ii)  Synaptic is not used to install CRAN / CTAN packages
iii) Everything should be provided by r-base-core and tetex-extra.

Since relatively recently, a 'Sweave' command has been added.  So simply do

	$ R CMD Sweave example-1.Snw 
	$ pdflatex example-1.tex
	$ kpdf example-1.pdf		# or xpdf, or gv, or ...

| A bunch of errors. What am I doing wrong? Any help is much
| appreciated!

You simply make your life too complicated when Debian and Ubuntu make it
easier for you :)

| Of course, if there is a better place for me to ask this question
| please let me know where! Thanks!

The r-sig-debian list is appropriate for problems with Debian / Ubuntu.

Dirk

PS  I usually use simple shell wrappers like this one. Others prefer
Makefile. 


edd at basebud:~> cat /home/edd/bin/sweave
#!/bin/bash -e

function errorexit () {
    echo "Error: $1"
    exit 1
}

function filetest () {
    if [ ! -f $1 ]; then
       errorexit "File $1 not found"
    fi
    return 0
}


if [ "$#" -lt 1 ]; then
    errorexit "Need to specify argument file"
fi


BASENAME=$(basename $1 .Rnw)

RNWFILE=$BASENAME.Rnw
filetest $RNWFILE
echo "library(tools); Sweave(\"$RNWFILE\")" \
      | R --no-save --no-restore --slave

LATEXFILE=$BASENAME.tex
filetest $LATEXFILE && pdflatex $LATEXFILE

PDFFILE=$BASENAME.pdf
#filetest $PDFFILE && acroread $PDFFILE &
#filetest $PDFFILE && xpdf $PDFFILE &
filetest $PDFFILE && kpdf $PDFFILE &


-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From mjankowski at gmail.com  Wed Jun 20 06:36:41 2007
From: mjankowski at gmail.com (M. Jankowski)
Date: Tue, 19 Jun 2007 23:36:41 -0500
Subject: [R] Help With Sweave:
In-Reply-To: <18040.38006.565172.64274@basebud.nulle.part>
References: <500c63990706191923p261f2ed4nde48eb130cebe15@mail.gmail.com>
	<18040.38006.565172.64274@basebud.nulle.part>
Message-ID: <500c63990706192136m26b15085l66cfec957f518a07@mail.gmail.com>

Dirk,

Your solution worked wonders! This is outstanding! Thank you!

Matt

On 6/19/07, Dirk Eddelbuettel <edd at debian.org> wrote:
>
> Matt,
>
> On 19 June 2007 at 21:23, M. Jankowski wrote:
> | Hi All,
> |
> | I am running Ubuntu Feisty (7.04) on a Thinkpad T41. I've installed
> | the nowebm package for Ubuntu. Working from this HowTo:
> | http://www.ci.tuwien.ac.at/~leisch/Sweave/example-1.Snw
> | I try to compile the example *.Snw as in the Sweave manual:
> |
> | mdj at lapmdj:~/Desktop/Sweave/example1$ noweb example-1.Snw
> | Can't open output file
> |
> | Despite the error, a *.tex file is produced. Now I am stuck because I
> | cannot seem to get the CTAN noweb package correctly installed  for my
> | Latex installation. I guess I am somewhat spoiled by the Synaptic
> | package manager. Here is the result of my best attempt to get the
> | noweb package installed:
>
> i)   No external noweb package is needed
> ii)  Synaptic is not used to install CRAN / CTAN packages
> iii) Everything should be provided by r-base-core and tetex-extra.
>
> Since relatively recently, a 'Sweave' command has been added.  So simply do
>
>         $ R CMD Sweave example-1.Snw
>         $ pdflatex example-1.tex
>         $ kpdf example-1.pdf            # or xpdf, or gv, or ...
>
> | A bunch of errors. What am I doing wrong? Any help is much
> | appreciated!
>
> You simply make your life too complicated when Debian and Ubuntu make it
> easier for you :)
>
> | Of course, if there is a better place for me to ask this question
> | please let me know where! Thanks!
>
> The r-sig-debian list is appropriate for problems with Debian / Ubuntu.
>
> Dirk
>
> PS  I usually use simple shell wrappers like this one. Others prefer
> Makefile.
>
>
> edd at basebud:~> cat /home/edd/bin/sweave
> #!/bin/bash -e
>
> function errorexit () {
>     echo "Error: $1"
>     exit 1
> }
>
> function filetest () {
>     if [ ! -f $1 ]; then
>        errorexit "File $1 not found"
>     fi
>     return 0
> }
>
>
> if [ "$#" -lt 1 ]; then
>     errorexit "Need to specify argument file"
> fi
>
>
> BASENAME=$(basename $1 .Rnw)
>
> RNWFILE=$BASENAME.Rnw
> filetest $RNWFILE
> echo "library(tools); Sweave(\"$RNWFILE\")" \
>       | R --no-save --no-restore --slave
>
> LATEXFILE=$BASENAME.tex
> filetest $LATEXFILE && pdflatex $LATEXFILE
>
> PDFFILE=$BASENAME.pdf
> #filetest $PDFFILE && acroread $PDFFILE &
> #filetest $PDFFILE && xpdf $PDFFILE &
> filetest $PDFFILE && kpdf $PDFFILE &
>
>
> --
> Hell, there are no rules here - we're trying to accomplish something.
>                                                   -- Thomas A. Edison
>


From brown_emu at yahoo.com  Wed Jun 20 06:50:00 2007
From: brown_emu at yahoo.com (Stephen Tucker)
Date: Tue, 19 Jun 2007 21:50:00 -0700 (PDT)
Subject: [R] : create a PDF file (text (print list)  and grafics)
In-Reply-To: <E97312684A84D511BDD40002A50968D60A35E96D@lxpobw01.ine.pt>
Message-ID: <420016.14448.qm@web39714.mail.mud.yahoo.com>

Hi Ana,

There are two ways in which I imagine this can be done:
(1) create a layout [using layout()] and printing the text on a blank plot;
(2) using Sweave.

## === Method 1 example... ===

pdf()
layout(matrix(c(1,1,2,3),ncol=2,byrow=TRUE),widths=c(1,1),heights=c(3,2))
par(mar=c(0,0,5,0))
plot.new(); plot.window(xlim=c(0,1),ylim=c(0,1))
title("Title",cex.main=1.5)
text(0.4,0.5,adj=c(0,0),lab=
"> print(myList)
$a
[1] 1

$b
[1] 2")
par(mar=c(5,4,1,1))
boxplot(1:10)
hist(1:10)
dev.off()

## (there must be a more elegant way than pasting the output
## of print(myList) as a character string in text() but I can't
## think of it at the moment...

## === Method 2 (warning: I am not too familiar with Sweave
## but I understand that this is how it *should* work; this
## Sweave document will create a '.tex' file which you can then
## compile with latex - this site was helpful:
## http://www.stat.umn.edu/~charlie/Sweave/)  ===

\documentclass[a4paper]{article}
\title{Sweave Document}
\author{}
\date{}
\begin{document}
\maketitle

Text field here

<<echo=FALSE>>=
## computations to build 'myList' here (but not for printing)
## such as
myList <- list(a=1,b=2)
@
<<reg>>=
## this is for output
print(myList)
@ 

\begin{center}
<<fig =TRUE , echo =FALSE >>=
par(mfrow=c(1,2), oma=c(0,0,3,0),cex=0.5)
#Image
hist(controlo$quope,axes=T,plot=T,col="gray",xlab=
"Quope",main="Histograma",lwd=2)
boxplot(controlo$quope,col="bisque",lty=3,medlty=1,medlwd=2.5,main=
"Boxplot")     
mtext(regiao,cex=1.5,col="blue",adj=0.5,side=3,outer=TRUE) 
@
\end{center}
\end{document}

##



--- Ana Patricia Martins <ana.pmartins at ine.pt> wrote:

> Dear helpers,
> 
> I need help to create a PDF file like the example
> 
>  -----------------------------------
>  |	      Title				|
>  -----------------------------------
>  |						|
>  |		Text (print a list)	|		   
>  |						|
>  -----------------------------------
>  |			|		      |
>  |			|		      |
>  |    image		|     image	      |
>  |			|		      |
>  |			|		      |
>  -----------------------------------
> 
> 
>
pdf(paste(getwd(),"/Output/Controlo_Pesos",regiao,trimestre,substr(ano,3,4),
> 
> 		".pdf",sep="),height=13.7, paper="special")
> par(mfrow=c(1,2), oma=c(0,0,3,0),cex=0.5)
> 
> #Text field (????????????)
> #print(qual_pesos)# is a list
> 
> #Image
> hist(controlo$quope,axes=T,plot=T,col="gray",xlab=
> "Quope",main="Histograma",lwd=2)
> boxplot(controlo$quope,col="bisque",lty=3,medlty=1,medlwd=2.5,main=
> "Boxplot")     
> mtext(regiao,cex=1.5,col="blue",adj=0.5,side=3,outer=TRUE) 
> dev.off()
> 
> 
> 
> There is other way to do the same more easily
> Thanks in advance for helping me.
> Best regards.
> 
> Atenciosamente,
> Ana Patricia Martins
> -------------------------------------------
> Servi?o M?todos Estat?sticos
> Departamento de Metodologia Estat?stica
> INE - Portugal
> Telef:  218 426 100 - Ext: 3210
> E-mail: ana.pmartins at ine.pt <mailto:ana.pmartins at ine.pt> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> > ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ggrothendieck at gmail.com  Wed Jun 20 07:14:28 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 20 Jun 2007 01:14:28 -0400
Subject: [R] making a Time of Day axis
In-Reply-To: <20070619203749.460075d7@nova.oplnk.net>
References: <20070619203749.460075d7@nova.oplnk.net>
Message-ID: <971536df0706192214t4a5597cbi45027fc73ba321ec@mail.gmail.com>

Here it is with a few improvements:
- use as.is=TRUE on read.table to get character columns rather than factor
- use xaxt = FALSE rather than axes = FALSE to eliminate axis(2)
- use h$mids where h is the output of hist to avoid lots of tedious calcs
- eliminate all that attaching and detaching
- eliminate strptime

DF <- read.table("input.dat", header = TRUE, as.is = TRUE)
DF$Time <- times(paste(DF$Time, "00", sep = ":"))
tod <- as.numeric(subset(DF, Trip == "m")$Time)
h <- hist(tod, xaxt = "n", main = "Morning Bus Arrival Times",
	xlab = "Time", col = "blue");
axis(1, h$mids, sub(":00$", "", times(h$mids)))

Although not used subsequently just in case you need it in
computations that you did not show:

DF$Date <- chron(DF$Date)
DF$DateTime <- chron(DF$Date, DF$Time)


On 6/19/07, Alan Jackson <Rhelp at ajackson.org> wrote:
> I am wrestling with time and date data. I came up with a way to plot and
> label a histogram with "time of day" on the x-axis, but it seemed like a
> lot more work than should be necessary. Is there a better way to do what
> I am trying to do?
>
> require(chron)
> #       read input data
> data = read.table("input.dat", header=T)
> #       Create date-time and chron objects
> datetime = strptime(paste(data[,3], data[,2]),format="%m/%d/%y %H:%M")
> time = times(paste(as.vector(data[,2]), ":00",sep=""))
> #       Put it all into a data frame
> data = data.frame(time, datetime, data$Trip)
> names(data) = c("Time","DateTime","Trip")
> attach(data)
> #       Create time of day array
> times = as.numeric(chron(times = Time))
> tod = subset(times, Trip=='m');
> #       Plot base histogram
> hist(tod, axes=F, main="Morning Bus Arrival Times", xlab="Time", col="blue");
> axis(2);
> #       where are the tics to be?
> tics = seq(min(tod), max(tod), (max(tod)-min(tod))/5);
> #       build a labeled x-axis for the plot
> axis(1, tics, labels=sub(":00$","",as.character(chron(times=tics, out.format="h:m:s"))));
>
> #       cleanup
> detach(data)
>
> --- Data ---
> Trip Time Date
> a 15:55 05/15/07
> m  5:47 05/16/07
> a 15:54 05/16/07
> m  5:47 05/17/07
> a 15:59 05/17/07
> m  5:50 05/21/07
> m  5:50 05/22/07
> a 16:00 05/22/07
> m  5:48 05/23/07
> m  5:50 05/24/07
> a 16:00 05/24/07
> m  5:48 05/25/07
> m  5:48 05/29/07
> a 15:59 05/29/07
> m  5:46 05/30/07
> m  5:45 05/31/07
> a 16:05 05/31/07
> m  5:47 06/04/07
> a 15:53 06/04/07
> m  5:46 06/05/07
> m  5:47 06/06/07
> a 15:53 06/06/07
> m  5:47 06/07/07
> a 15:51 06/07/07
> m  5:45 06/08/07
> f 15:22 06/08/07
> m  5:48 06/11/07
> m  5:46 06/12/07
> m  5:48 06/13/07
> m  5:47 06/18/07
> a 15:53 06/18/07
> m  5:47 06/19/07
> a 15:55 06/19/07
>
>
> --
> -----------------------------------------------------------------------
> | Alan K. Jackson            | To see a World in a Grain of Sand      |
> | alan at ajackson.org          | And a Heaven in a Wild Flower,         |
> | www.ajackson.org           | Hold Infinity in the palm of your hand |
> | Houston, Texas             | And Eternity in an hour. - Blake       |
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From gyadav at ccilindia.co.in  Wed Jun 20 07:31:09 2007
From: gyadav at ccilindia.co.in (gyadav at ccilindia.co.in)
Date: Wed, 20 Jun 2007 11:01:09 +0530
Subject: [R] Help in ARIMA
In-Reply-To: <4e29a5d60706190102l6e23aa6end022d6b63709355d@mail.gmail.com>
Message-ID: <OF504818B6.5FC3FEC1-ON65257300.001E173F-65257300.001E4AED@ccilindia.co.in>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070620/71d94940/attachment.pl 

From ajsaez at ujaen.es  Wed Jun 20 08:29:49 2007
From: ajsaez at ujaen.es (Antonio J. Saez-Castillo)
Date: Wed, 20 Jun 2007 08:29:49 +0200
Subject: [R] Warning message loading rmutil in R 2.5.0
Message-ID: <4678C95D.4010105@ujaen.es>


From WTALLOEN at PRDBE.JNJ.COM  Wed Jun 20 08:52:23 2007
From: WTALLOEN at PRDBE.JNJ.COM (Talloen, Willem [PRDBE])
Date: Wed, 20 Jun 2007 08:52:23 +0200
Subject: [R] plot only x- and y-axis with origin, no box()
In-Reply-To: <07E228A5BE53C24CAD490193A7381BBBA5A265@LP-EXCHVS07.CO.IHC.COM>
Message-ID: <76AA79BF7116C04B92C3CD618B701A45036228@JNJBEBEGMS03.eu.jnj.com>


Yes Greg,

Your provided solution does the job;
> plot(5:10, 5:10, bty='n')
> library(TeachingDemos)
> lines(cnvrt.coords( c(0,0,.5), c(.5,0,0), input='plt')$usr)

The easy way is indeed to do 
> plot(.., bty='l')
but this cannot be used in combination with fixing tickmarks and changing width of the axes.

HOWEVER, there is still a small error. The width of the added y-axis has not the same width;
> plot(5:10, 5:10,axes=F)
> axis(1,lwd=2)
> axis(2,lwd=2)
> library(TeachingDemos)
> lines(cnvrt.coords( c(0,0,.5), c(.5,0,0), input='plt')$usr,lwd=2)

Any ideas?
Willem

-----Original Message-----
From: Greg Snow [mailto:Greg.Snow at intermountainmail.org]
Sent: Tuesday, 19 June 2007 18:23
To: Talloen, Willem [PRDBE]; r-help at stat.math.ethz.ch
Subject: RE: [R] plot only x- and y-axis with origin, no box()



Try:

> plot(.., bty='l')

Does that do what you want?  (see the bty parameter in ?par for details)

If you don't want the lines extending beyond the axes on the right and
top then you could do something more like:

> plot(5:10, 5:10, bty='n')
> library(TeachingDemos)
> lines(cnvrt.coords( c(0,0,.5), c(.5,0,0), input='plt')$usr)

You may also get what you want by playing with the xaxp and yaxp
parameters to par, but the bty='l' seems the easiest way to go. 

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Talloen, Willem [PRDBE]
> Sent: Tuesday, June 19, 2007 7:15 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] plot only x- and y-axis with origin, no box()
> 
> hi all,
> 
> I'm trying for quite some time to have an x- and y-axis, but 
> no entire box.
> 
> >plot(..,axes=F)
> >axis(1)
> >axis(2)
> Gives this, but their axes do not go to the origin.
> Quite a number of people find this gap between the two axes 
> disturbing.
> Has anyone an idea how to let these axes go to the origin?
> 
> thank you in advance
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From buser at stat.math.ethz.ch  Wed Jun 20 09:21:19 2007
From: buser at stat.math.ethz.ch (Christoph Buser)
Date: Wed, 20 Jun 2007 09:21:19 +0200
Subject: [R] Preconditions for a variance analysis
In-Reply-To: <46785595.1375.23DF23C@localhost>
References: <46785595.1375.23DF23C@localhost>
Message-ID: <18040.54639.241738.365135@stat.math.ethz.ch>

Dear David

Yes. There are assumptions that should be verified in an
analysis of variance. Without checking them, the results are not
reliable. 
I'd recommend e.g.

Robert O. Kuehl, Design of Experiments: Statistical Principles
  of Research Design and Analysis, Duxbury Press, 2000

You will find a chapter about assumptions and how to check them
by residual analysis,

And also

W. N. Venables and B. D. Ripley, Modern Applied Statistics 
  with S, Springer-Verlag, New York, 2002

in which you find residual analysis and how to obtain it in R.

Best regards,

Christoph

--------------------------------------------------------------

Credit and Surety PML study: visit our web page www.cs-pml.org

--------------------------------------------------------------
Christoph Buser <buser at stat.math.ethz.ch>
Seminar fuer Statistik, LEO C13
ETH Zurich	8092 Zurich	 SWITZERLAND
phone: x-41-44-632-4673		fax: 632-1228
http://stat.ethz.ch/~buser/
--------------------------------------------------------------


Daniel Tahin writes:
 > Hello everbody,
 > 
 > i'm currently using the anova()-test for a small data.frame of 40 
 > rows and 2 columns. It works well, but is there any preconditions for 
 > a valid variance analysis, that i should consider?
 > 
 > Thank you for your answer,
 > Daniel
 > 
 > ______________________________________________
 > R-help at stat.math.ethz.ch mailing list
 > https://stat.ethz.ch/mailman/listinfo/r-help
 > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
 > and provide commented, minimal, self-contained, reproducible code.


From singularitaet at gmx.net  Wed Jun 20 09:29:03 2007
From: singularitaet at gmx.net (Stefan Grosse)
Date: Wed, 20 Jun 2007 09:29:03 +0200
Subject: [R] Speed up R
In-Reply-To: <3f547caa0706191409w3c8f92f0me3dbc44ea56f2674@mail.gmail.com>
References: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAfHU8PP2E50qGgSIBTaVydsKAAAAQAAAABwQr1ccyxkyN/Yw5Qh9faQEAAAAA@o2.pl>
	<3f547caa0706191409w3c8f92f0me3dbc44ea56f2674@mail.gmail.com>
Message-ID: <4678D73F.5080200@gmx.net>

-------- Original Message  --------
Subject: Re:[R] Speed up R
From: Matthew Keller <mckellercran at gmail.com>
To: Robert McFadden <robert-mcfadden at o2.pl>
Date: 19.06.2007 23:09
>  but I think that windows has problems addressing
> that much RAM (surely the 64bit Vista is OK with it though... surely).
> Linux or Apple (the powermac) might be better bets if you're wanting
> to work with programs that use a lot of RAM. BTW, Intel does make 64
> bit chips now. They use them in macs.
>   
The Core 2 Duo has 64bit processing and is not only used in Macs... The
thing with the 64bit Vista is that there is much less software driver
support at the moment. So if you will not use more than 4GB and want to
use it for other purposes than you might prefer the 32bit Vista... My
personal subjective feeling is that Vista is slower then XP. So I would
say thats not the only reason to go for Linux.

Stefan


From maechler at stat.math.ethz.ch  Wed Jun 20 09:45:04 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 20 Jun 2007 09:45:04 +0200
Subject: [R] Could not find lmer function in {Matrix} package
In-Reply-To: <D79FB99C-641D-4D98-B2A7-13B00C23A312@yale.edu>
References: <D79FB99C-641D-4D98-B2A7-13B00C23A312@yale.edu>
Message-ID: <18040.56064.380950.526299@stat.math.ethz.ch>

>>>>> "SB" == Steve Brady <steven.brady at yale.edu>
>>>>>     on Tue, 19 Jun 2007 11:59:15 -0400 writes:

    SB> I am having trouble calling the lmer function in the {Matrix}  

    SB> package.  I first installed and loaded {Matrix} as follows:

    >> install.packages("Matrix")
    >> library(Matrix)

    SB> The package loaded successfully, however when I attempted to call  
    SB> lmer, I received the following message:

    SB> Error: could not find function "lmer"

    SB> I also tried:

    SB> < ?lmer

    SB> which produced no search results.

And who told you  lmer() was in the Matrix package ?
It's in the lme4 package, and --- conceptually has always been there --
Only for some maintenance convenience (C code shared between
lme4 and Matrix) reasons, lmer() has actually been in the Matrix
package for some time in the past, 
however you were always supposed to say
    
    require(lme4)  or  library(lme4)

to get to lmer.

Regards,
Martin

    SB> I have attempted these actions in both MacOSx R Versions 2.4.1 and  
    SB> 2.5.0.  I have also tried this in Version 2.5.1. beta on a Windows  
    SB> machine.

    SB> Thanks in advance for any suggestions.

    SB> Steve


From maechler at stat.math.ethz.ch  Wed Jun 20 09:53:10 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 20 Jun 2007 09:53:10 +0200
Subject: [R] Matrix library error: "should never happen; please report"
In-Reply-To: <op.tt6nnr0l4hcap5@delllap.ugr.es>
References: <op.tt6nnr0l4hcap5@delllap.ugr.es>
Message-ID: <18040.56550.626086.639368@stat.math.ethz.ch>

Hi Jose,

>>>>> "JQ" == Jose Quesada <" <quesada at gmail.com>>
>>>>>     on Tue, 19 Jun 2007 21:12:53 +0200 writes:

    JQ> Hi, I got the following error. Sorry but this time I
    JQ> couldn't reproduce it with a simple chunk of code:

>> .TM.repl.i.2col(): drop 'matrix' case ...
>> Error in .nextMethod(x = x, i = i, j = j) :
>>          'i' has no integer column number should never happen; please report
>> In addition: Warning messages:
>> 1: Ambiguous method selection for "%*%", target "ddiMatrix#dgCMatrix" (the  
>> first of the signatures shown will be used)
>>      diagonalMatrix#CsparseMatrix
>>      ddenseMatrix#CsparseMatrix
>>   in: .findInheritedMethods(classes, fdef, mtable)
>> 

    JQ> I got 4 other copies of the same warning. Will play
    JQ> around a bit more...  This is really strange.

Yes, but

- the Matrix library is the file Matrix.so or Matrix.dll which
 is part of the installed (aka "binary") Matrix *package*
 Maybe you really need to read the result of
    fortune("package.*Maechler")  # after installing package 'fortunes'

- "please report" was not meant to say to report to R-help,
  but to the package maintainers,

- since you cannot reproduce it yet, we cannot do much about it.
  It may be a bug in the Matrix package (and Jose has told me
  that he's using the latest released version 0.99875-2),
  but in theory it could even be your own mistake, namely by
  wrongly manipulating the slots of a Matrix object.

Please try to produce an R script - even if not small -- with a
reproducible example;
[and then do report to  Matrix-authors at r-project.org].

    JQ> Thanks -- Jose Quesada, PhD.

Best regards,
Martin Maechler, ETH Zurich


From WTALLOEN at PRDBE.JNJ.COM  Wed Jun 20 10:08:22 2007
From: WTALLOEN at PRDBE.JNJ.COM (Talloen, Willem [PRDBE])
Date: Wed, 20 Jun 2007 10:08:22 +0200
Subject: [R] plot only x- and y-axis with origin, no box()
In-Reply-To: <4678DEA7.7050209@mango-solutions.com>
Message-ID: <76AA79BF7116C04B92C3CD618B701A4503622B@JNJBEBEGMS03.eu.jnj.com>


perfect Romain,
box( bty = "l", lwd = 2 )
is the solution !
thank you all for your kind responses,
willem

-----Original Message-----
From: Romain Francois [mailto:rfrancois at mango-solutions.com]
Sent: Wednesday, 20 June 2007 10:01
To: Talloen, Willem [PRDBE]
Subject: Re: [R] plot only x- and y-axis with origin, no box()


Talloen, Willem [PRDBE] wrote:
> Yes Greg,
>
> Your provided solution does the job;
>   
>> plot(5:10, 5:10, bty='n')
>> library(TeachingDemos)
>> lines(cnvrt.coords( c(0,0,.5), c(.5,0,0), input='plt')$usr)
>>     
>
> The easy way is indeed to do 
>   
>> plot(.., bty='l')
>>     
> but this cannot be used in combination with fixing tickmarks and changing width of the axes.
>
> HOWEVER, there is still a small error. The width of the added y-axis has not the same width;
>   
>> plot(5:10, 5:10,axes=F)
>> axis(1,lwd=2)
>> axis(2,lwd=2)
>> library(TeachingDemos)
>> lines(cnvrt.coords( c(0,0,.5), c(.5,0,0), input='plt')$usr,lwd=2)
>>     
Hi Willem ,

In that case, I would go with a vanilla `plot` call and then add `axis` 
and `box` low-level function calls:

plot( 5:10, 5:10, axes = FALSE  )
axis( 1, lwd = 2, .. )
axis( 2, lwd = 2, .. )
box( bty = "l", lwd = 2 )

Cheers,

Romain

> Any ideas?
> Willem
>
> -----Original Message-----
> From: Greg Snow [mailto:Greg.Snow at intermountainmail.org]
> Sent: Tuesday, 19 June 2007 18:23
> To: Talloen, Willem [PRDBE]; r-help at stat.math.ethz.ch
> Subject: RE: [R] plot only x- and y-axis with origin, no box()
>
>
>
> Try:
>
>   
>> plot(.., bty='l')
>>     
>
> Does that do what you want?  (see the bty parameter in ?par for details)
>
> If you don't want the lines extending beyond the axes on the right and
> top then you could do something more like:
>
>   
>> plot(5:10, 5:10, bty='n')
>> library(TeachingDemos)
>> lines(cnvrt.coords( c(0,0,.5), c(.5,0,0), input='plt')$usr)
>>     
>
> You may also get what you want by playing with the xaxp and yaxp
> parameters to par, but the bty='l' seems the easiest way to go. 
>
>   


-- 
Mango Solutions
data analysis that delivers

Tel:  +44(0) 1249 467 467
Fax:  +44(0) 1249 467 468
Mob:  +44(0) 7813 526 123


From e0226781 at student.tuwien.ac.at  Wed Jun 20 10:35:26 2007
From: e0226781 at student.tuwien.ac.at (Daniel Tahin)
Date: Wed, 20 Jun 2007 10:35:26 +0200
Subject: [R] Preconditions for a variance analysis
In-Reply-To: <18040.54639.241738.365135@stat.math.ethz.ch>
References: <46785595.1375.23DF23C@localhost>
Message-ID: <467902EE.9306.4E314CB@localhost>

Thanx for your answer. I don't have the book, but found something on 
the web:
http://www.basic.northwestern.edu/statguidefiles/oneway_anova.html   
and
http://en.wikipedia.org/wiki/Analysis_of_variance#Assumptions

Seems to be the same on both of the sites :-)
Is this, that was meant?

Thanx again,
Daniel




> Dear David
> 
> Yes. There are assumptions that should be verified in an
> analysis of variance. Without checking them, the results are not
> reliable. 
> I'd recommend e.g.
> 
> Robert O. Kuehl, Design of Experiments: Statistical Principles
>   of Research Design and Analysis, Duxbury Press, 2000
> 
> You will find a chapter about assumptions and how to check them
> by residual analysis,
> 
> And also
> 
> W. N. Venables and B. D. Ripley, Modern Applied Statistics 
>   with S, Springer-Verlag, New York, 2002
> 
> in which you find residual analysis and how to obtain it in R.
> 
> Best regards,
> 
> Christoph
> 
> --------------------------------------------------------------
> 
> Credit and Surety PML study: visit our web page www.cs-pml.org
> 
> --------------------------------------------------------------
> Christoph Buser <buser at stat.math.ethz.ch>
> Seminar fuer Statistik, LEO C13
> ETH Zurich	8092 Zurich	 SWITZERLAND
> phone: x-41-44-632-4673		fax: 632-1228
> http://stat.ethz.ch/~buser/
> --------------------------------------------------------------
> 
> 
> Daniel Tahin writes:
>  > Hello everbody,
>  > 
>  > i'm currently using the anova()-test for a small data.frame of 40 
>  > rows and 2 columns. It works well, but is there any preconditions for 
>  > a valid variance analysis, that i should consider?
>  > 
>  > Thank you for your answer,
>  > Daniel
>  > 
>  > ______________________________________________
>  > R-help at stat.math.ethz.ch mailing list
>  > https://stat.ethz.ch/mailman/listinfo/r-help
>  > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>  > and provide commented, minimal, self-contained, reproducible code.


From amicogodzilla at bruttocarattere.org  Wed Jun 20 11:04:21 2007
From: amicogodzilla at bruttocarattere.org (Manuele Pesenti)
Date: Wed, 20 Jun 2007 11:04:21 +0200
Subject: [R] add line to data.frame
Message-ID: <200706201104.21311.amicogodzilla@bruttocarattere.org>

Dear R user,

how can I update a data.frame adding new lines?
I need to create a second data frame from a first one with only some of their 
entrys filtering the value of a specific column... How can I do this?

thankyou very much in advance
best regards
	Manuele PEsenti

-- 
Manuele Pesenti
	manuele a inventati.org
	amicogodzilla a jabber.linux.it
	http://mpesenti.polito.it


From christophe at pallier.org  Wed Jun 20 11:17:34 2007
From: christophe at pallier.org (Christophe Pallier)
Date: Wed, 20 Jun 2007 11:17:34 +0200
Subject: [R] add line to data.frame
In-Reply-To: <200706201104.21311.amicogodzilla@bruttocarattere.org>
References: <200706201104.21311.amicogodzilla@bruttocarattere.org>
Message-ID: <dea6cb960706200217s53e27e23l3d0c84c4008eec0e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070620/624fdaa6/attachment.pl 

From dvumani at hotmail.com  Wed Jun 20 11:20:01 2007
From: dvumani at hotmail.com (Vumani Dlamini)
Date: Wed, 20 Jun 2007 09:20:01 +0000
Subject: [R] "xtable" results doesn't correspond to data.frame
Message-ID: <BAY110-F92EAE0AB6FB1AAADA7AE1A3110@phx.gbl>

Dear useRs,
Am trying to use xtable on the following data.frame and I don't get what I 
expect:

example.table <- data.frame(rbind(
    c("Gender"," "," "," "),
    cbind(rep(" ",2),c("Male","Female"),c(3.0,4.0),c(3/7,4/7))
))
colnames(example.table) <- c(" "," ","number of patients","%")
example.xtable <- xtable(example.table)
print.xtable(example.xtable, include.rownames=FALSE)

I can seem to get latex output which corresponds to the data.frame which is,
\begin{table}[ht]
\begin{center}
\begin{tabular}{llll}
  \hline
  &   & number of patients & \% \\
  \hline
Gender & &   &   \\
    &  Male & 3 & 0.428571428571429 \\
    &   Female & 4 & 0.571428571428571 \\
   \hline
\end{tabular}
\end{center}
\end{table}


From dan.bolser.r at googlemail.com  Wed Jun 20 11:20:44 2007
From: dan.bolser.r at googlemail.com (Dan Bolser)
Date: Wed, 20 Jun 2007 11:20:44 +0200
Subject: [R] Retrieve part of (top right corner) of a "plot.data.frame" plot?
Message-ID: <712798410706200220m39986a79wb6049cca852b56fd@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070620/dd7865b0/attachment.pl 

From buser at stat.math.ethz.ch  Wed Jun 20 11:22:56 2007
From: buser at stat.math.ethz.ch (Christoph Buser)
Date: Wed, 20 Jun 2007 11:22:56 +0200
Subject: [R] Preconditions for a variance analysis
In-Reply-To: <467902EE.9306.4E314CB@localhost>
References: <46785595.1375.23DF23C@localhost> <467902EE.9306.4E314CB@localhost>
Message-ID: <18040.61936.271614.349334@stat.math.ethz.ch>

Dear David

I'd not recommend the tests (for normality, equal variances) as
they are described on your second link (wikipedia).

I would use graphical tools such as Tukey-Anscombe Plot
(residuals against fitted values), quantile (or normal) plot,
leverage plot.

see also ?plot.lm for some short descriptions of these plots in
R.

Best regards,

Christoph

Daniel Tahin writes:
 > Thanx for your answer. I don't have the book, but found something on 
 > the web:
 > http://www.basic.northwestern.edu/statguidefiles/oneway_anova.html   
 > and
 > http://en.wikipedia.org/wiki/Analysis_of_variance#Assumptions
 > 
 > Seems to be the same on both of the sites :-)
 > Is this, that was meant?
 > 
 > Thanx again,
 > Daniel
 > 
 > 
 > 
 > 
 > > Dear David
 > > 
 > > Yes. There are assumptions that should be verified in an
 > > analysis of variance. Without checking them, the results are not
 > > reliable. 
 > > I'd recommend e.g.
 > > 
 > > Robert O. Kuehl, Design of Experiments: Statistical Principles
 > >   of Research Design and Analysis, Duxbury Press, 2000
 > > 
 > > You will find a chapter about assumptions and how to check them
 > > by residual analysis,
 > > 
 > > And also
 > > 
 > > W. N. Venables and B. D. Ripley, Modern Applied Statistics 
 > >   with S, Springer-Verlag, New York, 2002
 > > 
 > > in which you find residual analysis and how to obtain it in R.
 > > 
 > > Best regards,
 > > 
 > > Christoph
 > > 
 > > --------------------------------------------------------------
 > > 
 > > Credit and Surety PML study: visit our web page www.cs-pml.org
 > > 
 > > --------------------------------------------------------------
 > > Christoph Buser <buser at stat.math.ethz.ch>
 > > Seminar fuer Statistik, LEO C13
 > > ETH Zurich	8092 Zurich	 SWITZERLAND
 > > phone: x-41-44-632-4673		fax: 632-1228
 > > http://stat.ethz.ch/~buser/
 > > --------------------------------------------------------------
 > > 
 > > 
 > > Daniel Tahin writes:
 > >  > Hello everbody,
 > >  > 
 > >  > i'm currently using the anova()-test for a small data.frame of 40 
 > >  > rows and 2 columns. It works well, but is there any preconditions for 
 > >  > a valid variance analysis, that i should consider?
 > >  > 
 > >  > Thank you for your answer,
 > >  > Daniel
 > >  > 
 > >  > ______________________________________________
 > >  > R-help at stat.math.ethz.ch mailing list
 > >  > https://stat.ethz.ch/mailman/listinfo/r-help
 > >  > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
 > >  > and provide commented, minimal, self-contained, reproducible code.
 >


From ripley at stats.ox.ac.uk  Wed Jun 20 11:34:36 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 20 Jun 2007 10:34:36 +0100 (BST)
Subject: [R] How to compare GLM and GAM models
In-Reply-To: <loom.20070619T133831-358@post.gmane.org>
References: <BAY118-F90B55F0D6819B5E128C79A1130@phx.gbl>
	<loom.20070619T133831-358@post.gmane.org>
Message-ID: <Pine.LNX.4.64.0706192109430.10061@gannet.stats.ox.ac.uk>

On Tue, 19 Jun 2007, Ben Bolker wrote:

> Yuanchang xie <xieyc <at> hotmail.com> writes:
>
>>
>> Dear Listers,
>>
>> I want to compare two negative binomial models fitted using glm.nb and
>> gam(mgcv) based on the same data. What would be the most appropriate
>> criteria to compare these two models? Can someone point me to some
>> references? Thank you very much.
>>
>> Yuanchang Xie
>
>  Since they can't possibly be nested I would suggest AIC.

Surely they could be: a smooth fit in gam includes the possibility of a 
linear fit.

What is of more concern to me is that gam() is by default itself doing 
model selection, so AIC is not well-defined.  According to ?gam.selection, 
the comparisons are best done by comparing scores within mgcv.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From richard.pitman3 at btopenworld.com  Wed Jun 20 11:40:07 2007
From: richard.pitman3 at btopenworld.com (RICHARD PITMAN)
Date: Wed, 20 Jun 2007 10:40:07 +0100 (BST)
Subject: [R] plotting order of lines in xyplot panels while using
	conditioning variable and groups
In-Reply-To: <eb555e660706191146v6b407e59q9ac1f55c664ae0b3@mail.gmail.com>
Message-ID: <832279.78986.qm@web86207.mail.ird.yahoo.com>


--- Deepayan Sarkar <deepayan.sarkar at gmail.com> wrote:

> On 6/19/07, RICHARD PITMAN
> <richard.pitman3 at btopenworld.com> wrote:
<snip>
> > I have tried reordering
> the
> > levels in data$group:
> >
> > data$group<-factor(data$group,
> > levels=c("CV_model_event_1","CV model event 2","CV
> > event
> >
> 1","CV_event_2","CV_event_2_CVA","CV_event_2_TIA"))
> >
> > but this changed nothing.
> >
> > Any suggestions gratefully received.
> 
> It's hard to see the problem without a reproducible
> example, but if
> all you want is to order the levels of groups in
> decreasing order of
> frequency, you could use
> 
>  groups  = reorder(group, group, function(x) {
> -length(x) }),
> 
> -Deepayan
> 

Thanks Deepayan, that's a useful trick to know. I am
rather embarrassed, the problem was one of basic R
usage/syntax. When reordering the levels I just needed
to replace data$group with group (i.e. omitting data$
from the command) and all was well. I shall go and sit
in the dog-house and do penance :(

Thanks for your time.

Regards

Richard


From shiazy at gmail.com  Wed Jun 20 11:41:08 2007
From: shiazy at gmail.com (Shiazy Fuzzy)
Date: Wed, 20 Jun 2007 11:41:08 +0200
Subject: [R] Got "Unexpected ELSE error"
Message-ID: <9d3ef91d0706200241v7bed53a1wa493ff01a94b749c@mail.gmail.com>

Dear R-users,

I have a problem with the IF-ELSE syntax.
Please look at the folllowing code and tell me what's wrong:

a <- TRUE
if ( a )
{
        cat("TRUE","\n")
}
else
{
        cat("FALSE","\n")
}

If I try to execute with R I get:
     Error: syntax error, unexpected ELSE in "else"
The strange thing is either "cat" instructions are executed!!

My system is: Fedora Core 6 x86_64 + R 2.5.0 (rpm)

Thank you very much in advance!!!!

Regards,

-- Marco


From Thierry.ONKELINX at inbo.be  Wed Jun 20 11:54:26 2007
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 20 Jun 2007 11:54:26 +0200
Subject: [R] Got "Unexpected ELSE error"
In-Reply-To: <9d3ef91d0706200241v7bed53a1wa493ff01a94b749c@mail.gmail.com>
Message-ID: <2E9C414912813E4EB981326983E0A104031A916F@inboexch.inbo.be>

You need to put the else statement on the same line as the closing curly
bracket.

a <- TRUE
if ( a ){
        cat("TRUE","\n")
} else {
        cat("FALSE","\n")
}

Cheers,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium
tel. + 32 54/436 185
Thierry.Onkelinx op inbo.be
www.inbo.be 

Do not put your faith in what statistics say until you have carefully
considered what they do not say.  ~William W. Watt
A statistical analysis, properly conducted, is a delicate dissection of
uncertainties, a surgery of suppositions. ~M.J.Moroney

 

> -----Oorspronkelijk bericht-----
> Van: r-help-bounces op stat.math.ethz.ch 
> [mailto:r-help-bounces op stat.math.ethz.ch] Namens Shiazy Fuzzy
> Verzonden: woensdag 20 juni 2007 11:41
> Aan: r-help op stat.math.ethz.ch
> Onderwerp: [R] Got "Unexpected ELSE error"
> 
> Dear R-users,
> 
> I have a problem with the IF-ELSE syntax.
> Please look at the folllowing code and tell me what's wrong:
> 
> a <- TRUE
> if ( a )
> {
>         cat("TRUE","\n")
> }
> else
> {
>         cat("FALSE","\n")
> }
> 
> If I try to execute with R I get:
>      Error: syntax error, unexpected ELSE in "else"
> The strange thing is either "cat" instructions are executed!!
> 
> My system is: Fedora Core 6 x86_64 + R 2.5.0 (rpm)
> 
> Thank you very much in advance!!!!
> 
> Regards,
> 
> -- Marco
> 
> ______________________________________________
> R-help op stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.uni-dortmund.de  Wed Jun 20 11:52:14 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 20 Jun 2007 11:52:14 +0200
Subject: [R] Got "Unexpected ELSE error"
In-Reply-To: <9d3ef91d0706200241v7bed53a1wa493ff01a94b749c@mail.gmail.com>
References: <9d3ef91d0706200241v7bed53a1wa493ff01a94b749c@mail.gmail.com>
Message-ID: <4678F8CE.4030500@statistik.uni-dortmund.de>



Shiazy Fuzzy wrote:
> Dear R-users,
> 
> I have a problem with the IF-ELSE syntax.
> Please look at the folllowing code and tell me what's wrong:
> 
> a <- TRUE
> if ( a )
> {
>         cat("TRUE","\n")
> }

At this point, the expression above is complete and it ios evaluated if 
called interactively.
Then, the code below is invalid (there is nothing that starts with "else").




> else
> {
>         cat("FALSE","\n")
> }


Instead, use:

a <- TRUE
if ( a )
{
         cat("TRUE","\n")
} else
{
         cat("FALSE","\n")
}


Uwe Ligges

> If I try to execute with R I get:
>      Error: syntax error, unexpected ELSE in "else"
> The strange thing is either "cat" instructions are executed!!
> 
> My system is: Fedora Core 6 x86_64 + R 2.5.0 (rpm)
> 
> Thank you very much in advance!!!!
> 
> Regards,
> 
> -- Marco
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dimitris.rizopoulos at med.kuleuven.be  Wed Jun 20 11:58:33 2007
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Wed, 20 Jun 2007 11:58:33 +0200
Subject: [R] Got "Unexpected ELSE error"
References: <9d3ef91d0706200241v7bed53a1wa493ff01a94b749c@mail.gmail.com>
Message-ID: <00af01c7b321$903fee30$0540210a@www.domain>

the problem is that you start `else' on a new line; check the 
following two solutions:

if ( a ) {
    cat("TRUE", "\n")
} else {
    cat("FALSE", "\n")
}

# or

{
if ( a )
{
    cat("TRUE", "\n")
}
else
{
    cat("FALSE", "\n")
}
}


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm



----- Original Message ----- 
From: "Shiazy Fuzzy" <shiazy at gmail.com>
To: <r-help at stat.math.ethz.ch>
Sent: Wednesday, June 20, 2007 11:41 AM
Subject: [R] Got "Unexpected ELSE error"


> Dear R-users,
>
> I have a problem with the IF-ELSE syntax.
> Please look at the folllowing code and tell me what's wrong:
>
> a <- TRUE
> if ( a )
> {
>        cat("TRUE","\n")
> }
> else
> {
>        cat("FALSE","\n")
> }
>
> If I try to execute with R I get:
>     Error: syntax error, unexpected ELSE in "else"
> The strange thing is either "cat" instructions are executed!!
>
> My system is: Fedora Core 6 x86_64 + R 2.5.0 (rpm)
>
> Thank you very much in advance!!!!
>
> Regards,
>
> -- Marco
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm


From shiazy at gmail.com  Wed Jun 20 12:02:15 2007
From: shiazy at gmail.com (Shiazy Fuzzy)
Date: Wed, 20 Jun 2007 12:02:15 +0200
Subject: [R] Got "Unexpected ELSE error"
In-Reply-To: <00af01c7b321$903fee30$0540210a@www.domain>
References: <9d3ef91d0706200241v7bed53a1wa493ff01a94b749c@mail.gmail.com>
	<00af01c7b321$903fee30$0540210a@www.domain>
Message-ID: <9d3ef91d0706200302n711383bdn72cbfafadcf0360c@mail.gmail.com>

Thanks to everyone!!


I've just looked up on the R Language Definition manual:

"... When the if statement is not in a block the else, if present,
must appear on the same line as statement1. Otherwise the new line at
the end of statement1 yields a syntactically complete statement that
is evaluated. ..."

OK I admit I thought if-else statement was like the C version and I've
skipped that secition :P
(maybe this is a thing to insert in the "Introduction to R" manual)

Again, thank you!!

Sincerely,

-- Marco


On 6/20/07, Dimitris Rizopoulos <dimitris.rizopoulos at med.kuleuven.be> wrote:
> the problem is that you start `else' on a new line; check the
> following two solutions:
>
> if ( a ) {
>     cat("TRUE", "\n")
> } else {
>     cat("FALSE", "\n")
> }
>
> # or
>
> {
> if ( a )
> {
>     cat("TRUE", "\n")
> }
> else
> {
>     cat("FALSE", "\n")
> }
> }
>
>
> I hope it helps.
>
> Best,
> Dimitris
>
> ----
> Dimitris Rizopoulos
> Ph.D. Student
> Biostatistical Centre
> School of Public Health
> Catholic University of Leuven
>
> Address: Kapucijnenvoer 35, Leuven, Belgium
> Tel: +32/(0)16/336899
> Fax: +32/(0)16/337015
> Web: http://med.kuleuven.be/biostat/
>      http://www.student.kuleuven.be/~m0390867/dimitris.htm
>
>
>
> ----- Original Message -----
> From: "Shiazy Fuzzy" <shiazy at gmail.com>
> To: <r-help at stat.math.ethz.ch>
> Sent: Wednesday, June 20, 2007 11:41 AM
> Subject: [R] Got "Unexpected ELSE error"
>
>
> > Dear R-users,
> >
> > I have a problem with the IF-ELSE syntax.
> > Please look at the folllowing code and tell me what's wrong:
> >
> > a <- TRUE
> > if ( a )
> > {
> >        cat("TRUE","\n")
> > }
> > else
> > {
> >        cat("FALSE","\n")
> > }
> >
> > If I try to execute with R I get:
> >     Error: syntax error, unexpected ELSE in "else"
> > The strange thing is either "cat" instructions are executed!!
> >
> > My system is: Fedora Core 6 x86_64 + R 2.5.0 (rpm)
> >
> > Thank you very much in advance!!!!
> >
> > Regards,
> >
> > -- Marco
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
> Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm
>
>


From P.Dalgaard at biostat.ku.dk  Wed Jun 20 12:05:32 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 20 Jun 2007 12:05:32 +0200
Subject: [R] Got "Unexpected ELSE error"
In-Reply-To: <9d3ef91d0706200241v7bed53a1wa493ff01a94b749c@mail.gmail.com>
References: <9d3ef91d0706200241v7bed53a1wa493ff01a94b749c@mail.gmail.com>
Message-ID: <4678FBEC.3030107@biostat.ku.dk>

Shiazy Fuzzy wrote:
> Dear R-users,
>
> I have a problem with the IF-ELSE syntax.
> Please look at the folllowing code and tell me what's wrong:
>
> a <- TRUE
> if ( a )
> {
>         cat("TRUE","\n")
> }
> else
> {
>         cat("FALSE","\n")
> }
>
> If I try to execute with R I get:
>      Error: syntax error, unexpected ELSE in "else"
> The strange thing is either "cat" instructions are executed!!
>   
For some odd reason this is not actually a FAQ...

It is an anomaly of the R (and S) language (or maybe a necessary
consequence of its interactive usage) that it tries to complete parsing
of expressions as soon as possible, so 

2 + 2
+ 5

prints "4" and then "5", whereas

2 + 2 +
5

prints "9".  Similarly, when encountered on the command line,

if (foo) bar

will result in the value of bar if foo is TRUE and otherwise NULL. A
subsequent

else baz

will be interpreted as a new expression, which is invalid because it
starts with "else". To avoid this effect you can either move the "else"
to the end of the previous line, or put braces around the whole if
construct. I.e.

if (foo) {
    bar
} else {
    baz
}

or

if (foo) bar else baz

or

{
    if (foo)
         bar
    else
         baz
}

should all work.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From singularitaet at gmx.net  Wed Jun 20 12:20:37 2007
From: singularitaet at gmx.net (Stefan Grosse)
Date: Wed, 20 Jun 2007 12:20:37 +0200
Subject: [R] "xtable" results doesn't correspond to data.frame
In-Reply-To: <BAY110-F92EAE0AB6FB1AAADA7AE1A3110@phx.gbl>
References: <BAY110-F92EAE0AB6FB1AAADA7AE1A3110@phx.gbl>
Message-ID: <4678FF75.2060202@gmx.net>

It would be helpfull if you would state what exactly you did expect.

As improvements you could reduce the digits, see  ?xtable

-------- Original Message  --------
Subject: [R] "xtable" results doesn't correspond to data.frame
From: Vumani Dlamini <dvumani at hotmail.com>
To: r-help at stat.math.ethz.ch
Date: 20.06.2007 11:20
> Dear useRs,
> Am trying to use xtable on the following data.frame and I don't get what I 
> expect:
>
> example.table <- data.frame(rbind(
>     c("Gender"," "," "," "),
>     cbind(rep(" ",2),c("Male","Female"),c(3.0,4.0),c(3/7,4/7))
> ))
> colnames(example.table) <- c(" "," ","number of patients","%")
> example.xtable <- xtable(example.table)
> print.xtable(example.xtable, include.rownames=FALSE)
>
> I can seem to get latex output which corresponds to the data.frame which is,
> \begin{table}[ht]
> \begin{center}
> \begin{tabular}{llll}
>   \hline
>   &   & number of patients & \% \\
>   \hline
> Gender & &   &   \\
>     &  Male & 3 & 0.428571428571429 \\
>     &   Female & 4 & 0.571428571428571 \\
>    \hline
> \end{tabular}
> \end{center}
> \end{table}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>


From s.wood at bath.ac.uk  Wed Jun 20 12:17:27 2007
From: s.wood at bath.ac.uk (Simon Wood)
Date: Wed, 20 Jun 2007 11:17:27 +0100
Subject: [R] How to compare GLM and GAM models
In-Reply-To: <Pine.LNX.4.64.0706192109430.10061@gannet.stats.ox.ac.uk>
References: <BAY118-F90B55F0D6819B5E128C79A1130@phx.gbl>
	<loom.20070619T133831-358@post.gmane.org>
	<Pine.LNX.4.64.0706192109430.10061@gannet.stats.ox.ac.uk>
Message-ID: <200706201117.27839.s.wood@bath.ac.uk>

On Wednesday 20 June 2007 10:34, Prof Brian Ripley wrote:
> On Tue, 19 Jun 2007, Ben Bolker wrote:
> > Yuanchang xie <xieyc <at> hotmail.com> writes:
> >> Dear Listers,
> >>
> >> I want to compare two negative binomial models fitted using glm.nb and
> >> gam(mgcv) based on the same data. What would be the most appropriate
> >> criteria to compare these two models? Can someone point me to some
> >> references? Thank you very much.
> >>
> >> Yuanchang Xie
> >
> >  Since they can't possibly be nested I would suggest AIC.
>
> Surely they could be: a smooth fit in gam includes the possibility of a
> linear fit.
>
> What is of more concern to me is that gam() is by default itself doing
> model selection, so AIC is not well-defined.  According to ?gam.selection,
> the comparisons are best done by comparing scores within mgcv.

- In the negative binomial case  I'd also be a bit cautious about  AIC  --- 
for the `gam' model the negative binomial `theta' parameter is not an MLE (or 
even penalized MLE): see ?gam.neg.binom for details. That said, comparison of 
GCV scores is definitely not an option: the `theta' estimation method renders 
it meaningless here. 

- Of course if `theta' is known then everything is different. In that case the 
negative binomial gam is the same as any other gam with known scale 
parameter, so the default `mgcv:gam' behaviour will be to do smoothness 
selection using what is actually an approximate AIC. Estimated degrees of 
freedom replace number of parameters in the AIC `penalty' term, something 
which can be justified using a variant of the arguments underpinning the GACV 
methods proposed by Xiang & Wahba (1996, Stat. Sin.) and Gu and Xiang (2001, 
JCGS).  In other (non negative binomial) cases, when the scale parameter is 
unknown,  a variant of GCV is used for smoothness selection. However, 
asymptotically this is equivalent to using the AIC type approach 
(unsurprisingly, see Stone, 1977, JRSSB).

- The upshot of this is that generally I think that AIC (modified to use EDF 
in place of parameter count, as in R) is a reasonable way to compare GAMs --- 
in the known scale parameter case it's equivalent to comparing the scores 
used for smoothness selection, while in the unknown scale parameter case it's 
equivalent to comparing such scores, in the large sample limit. 

- For negative binomial GAMs with unknown theta, I'd still be inclined to use 
`AIC()' as a guide for model selection, but bearing in mind that in that case 
it's an approximation without good supporting theory,  

best,
Simon


-- 
> Simon Wood, Mathematical Sciences, University of Bath, Bath, BA2 7AY UK
> +44 1225 386603  www.maths.bath.ac.uk/~sw283


From f.calboli at imperial.ac.uk  Wed Jun 20 12:46:56 2007
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Wed, 20 Jun 2007 11:46:56 +0100
Subject: [R] non permanent change of vector values
Message-ID: <467905A0.2010407@imperial.ac.uk>

Hi All,

I have the following problem: I have a vector

x = rep(0,15)
x[1:2] = 1
x
  [1] 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0

I need to be able to call that vector 'x' so that if condition 'A' is true, only 
the first value is kept 'as is' and all the others are put to 0

if(A == T)

function(x) with x returning 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0

and if 'A' is false the second value is kept 'as is' and all the others are put to 0

if(A == F)

function(x) with x returning 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0

BUT, and that's the rub, I need x to changed in a *non permanent* way, so that 
at the end x is still

x
  [1] 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0

(that is because condition 'A' might be called again and could be different in 
it's T/F state from previous calls).

Any ideas?

Cheers,

Fede

-- 
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St Mary's Campus
Norfolk Place, London W2 1PG

Tel  +44 (0)20 7594 1602     Fax (+44) 020 7594 3193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com


From amicogodzilla at bruttocarattere.org  Wed Jun 20 12:47:11 2007
From: amicogodzilla at bruttocarattere.org (Manuele Pesenti)
Date: Wed, 20 Jun 2007 12:47:11 +0200
Subject: [R] extract elements
Message-ID: <200706201247.12054.amicogodzilla@bruttocarattere.org>

Dear R users,
just another little question... are there other ways, I mean more easy to 
write, to obtain the same result I got with:

data[95:length(dati[,1]), ]

where data is a data frame

to extract the last elements starting from a fixed position?

thank you very much

best regards
	Manuele PEsenti
-- 
Manuele Pesenti
	manuele a inventati.org
	amicogodzilla a jabber.linux.it
	http://mpesenti.polito.it


From murdoch at stats.uwo.ca  Wed Jun 20 12:53:42 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 20 Jun 2007 06:53:42 -0400
Subject: [R] non permanent change of vector values
In-Reply-To: <467905A0.2010407@imperial.ac.uk>
References: <467905A0.2010407@imperial.ac.uk>
Message-ID: <46790736.7070008@stats.uwo.ca>

On 20/06/2007 6:46 AM, Federico Calboli wrote:
> Hi All,
> 
> I have the following problem: I have a vector
> 
> x = rep(0,15)
> x[1:2] = 1
> x
>   [1] 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
> 
> I need to be able to call that vector 'x' so that if condition 'A' is true, only 
> the first value is kept 'as is' and all the others are put to 0
> 
> if(A == T)
> 
> function(x) with x returning 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
> 
> and if 'A' is false the second value is kept 'as is' and all the others are put to 0
> 
> if(A == F)
> 
> function(x) with x returning 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
> 
> BUT, and that's the rub, I need x to changed in a *non permanent* way, so that 
> at the end x is still
> 
> x
>   [1] 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
> 
> (that is because condition 'A' might be called again and could be different in 
> it's T/F state from previous calls).

Simply make a function that does what you want:

modifyx <- function(x, A) {
   if (A) x[-1] <- 0
   else x[-2] <- 0
   x
}

then call your function by passing modifyx(x, A) instead of just x.

You don't need to put A or x in the argument list of the function, but 
it probably makes sense to do so.

Duncan Murdoch


From vincent.duval at boehringer-ingelheim.com  Wed Jun 20 09:23:33 2007
From: vincent.duval at boehringer-ingelheim.com (vincent.duval at boehringer-ingelheim.com)
Date: Wed, 20 Jun 2007 09:23:33 +0200
Subject: [R] Computing time differences
Message-ID: <033BC9FB402D2B4CBBBE829F25FEDBE90123C712@bibexm02.eu.boehringer.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070620/935a6499/attachment.pl 

From ripley at stats.ox.ac.uk  Wed Jun 20 13:03:04 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 20 Jun 2007 12:03:04 +0100 (BST)
Subject: [R] extract elements
In-Reply-To: <200706201247.12054.amicogodzilla@bruttocarattere.org>
References: <200706201247.12054.amicogodzilla@bruttocarattere.org>
Message-ID: <Pine.LNX.4.64.0706201159580.14222@gannet.stats.ox.ac.uk>

On Wed, 20 Jun 2007, Manuele Pesenti wrote:

> Dear R users,
> just another little question... are there other ways, I mean more easy to
> write, to obtain the same result I got with:
>
> data[95:length(dati[,1]), ]
>
> where data is a data frame
>
> to extract the last elements starting from a fixed position?

data[95:nrow(data), ]

assuming 'data' and 'dati' are intended to be the same thing.

(Easier to read, too, and correct even if data[,1] is a matrix.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rfrancois at mango-solutions.com  Wed Jun 20 13:04:07 2007
From: rfrancois at mango-solutions.com (Romain Francois)
Date: Wed, 20 Jun 2007 12:04:07 +0100
Subject: [R] extract elements
In-Reply-To: <200706201247.12054.amicogodzilla@bruttocarattere.org>
References: <200706201247.12054.amicogodzilla@bruttocarattere.org>
Message-ID: <467909A7.5050807@mango-solutions.com>

Manuele Pesenti wrote:
> Dear R users,
> just another little question... are there other ways, I mean more easy to 
> write, to obtain the same result I got with:
>
> data[95:length(dati[,1]), ]
>
> where data is a data frame
>
> to extract the last elements starting from a fixed position?
>
> thank you very much
>
> best regards
> 	Manuele PEsenti
>   
Hello,

tail can do it:

R> tail( data, -95)

Cheers,

Romain

-- 
Mango Solutions
data analysis that delivers

Tel:  +44(0) 1249 467 467
Fax:  +44(0) 1249 467 468
Mob:  +44(0) 7813 526 123


From rfrancois at mango-solutions.com  Wed Jun 20 13:11:39 2007
From: rfrancois at mango-solutions.com (Romain Francois)
Date: Wed, 20 Jun 2007 12:11:39 +0100
Subject: [R] extract elements
In-Reply-To: <467909A7.5050807@mango-solutions.com>
References: <200706201247.12054.amicogodzilla@bruttocarattere.org>
	<467909A7.5050807@mango-solutions.com>
Message-ID: <46790B6B.8080405@mango-solutions.com>

Romain Francois wrote:
> Manuele Pesenti wrote:
>> Dear R users,
>> just another little question... are there other ways, I mean more 
>> easy to write, to obtain the same result I got with:
>>
>> data[95:length(dati[,1]), ]
>>
>> where data is a data frame
>>
>> to extract the last elements starting from a fixed position?
>>
>> thank you very much
>>
>> best regards
>>     Manuele PEsenti
>>   
> Hello,
>
> tail can do it:
>
> R> tail( data, -95)
>
> Cheers,
>
> Romain

Oops, almost, should be :
R> tail( data, -94)

What about a `start` argument in tail ? That'd be a bit more 
user-friendly, ...

Cheers,

Romain



-- 
Mango Solutions
data analysis that delivers

Tel:  +44(0) 1249 467 467
Fax:  +44(0) 1249 467 468
Mob:  +44(0) 7813 526 123


From pomchip at free.fr  Wed Jun 20 13:13:25 2007
From: pomchip at free.fr (=?ISO-8859-1?Q?S=E9bastien?=)
Date: Wed, 20 Jun 2007 07:13:25 -0400
Subject: [R] Retrieve part of (top right corner) of a "plot.data.frame"
 plot?
In-Reply-To: <712798410706200220m39986a79wb6049cca852b56fd@mail.gmail.com>
References: <712798410706200220m39986a79wb6049cca852b56fd@mail.gmail.com>
Message-ID: <46790BD5.2070807@free.fr>

Hi,

That is maybe not the most elegant way but you can hide some plots 
regions by add a white polygon, eg:

polygon(x=c(1,1,0,...),y=c(0,1,0,...),col=0,xpd=xpd)

Just a personnal question, can you modify the content of the "title" 
boxes without changing the names of the variables, e.g. "myParameter" 
instead of "a"?

Dan Bolser a ?crit :
> Hi,
>
> I believe this question has been asked before, but I cant find and don't
> remember the answer.
>
> The problem is simple, calling 'plot.data.frame(x)' gives a nice 'matrix of
> scatterplots' for each pair of columns in x. for example;
>
> x <-
>   data.frame(a=jitter(01:20),
>              b=jitter(20:01),
>              c=jitter(21:40),
>              d=jitter(rep(01,20)),
>              e=jitter(rep(10,20)),
>              f=jitter(rep(20,20))
>              )
>
> plot(x)
>
> gives a 6 by 6 grid of scatter plots, two (upper right and lower left) for
> each pair of columns in x. (I am going over these basics so that you can
> understand what I mean next).
>
> I would like to see just part of the above result, namely the nine plots in
> the top right of the given plot, or;
>
> a vs. d | a vs. e | a vs. f
> b vs. d | b vs. e | b vs. f
> c vs. d | c vs. e | c vs. f
>
> I tried a number of ways to do this, but I can't find either the right
> formula or the right function to get what I want.
>
> Any suggestions you can give (especially any not involving the source code
> of 'pairs') are most welcome.
>
> Dan.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>


From ggrothendieck at gmail.com  Wed Jun 20 13:14:37 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 20 Jun 2007 07:14:37 -0400
Subject: [R] Computing time differences
In-Reply-To: <033BC9FB402D2B4CBBBE829F25FEDBE90123C712@bibexm02.eu.boehringer.com>
References: <033BC9FB402D2B4CBBBE829F25FEDBE90123C712@bibexm02.eu.boehringer.com>
Message-ID: <971536df0706200414u4af9f40dq9a0c200a4c1a4ebf@mail.gmail.com>

Try this and see the help desk article in R News 4/1:

> x <- 20080620.00
> x2 <- 20090218.00
> num2Date <- function(x) as.Date(paste(x), "%Y%m%d")
> num2Date(x2) - num2Date(x)
Time difference of 243 days
> as.numeric(num2Date(x2) - num2Date(x))
[1] 243

On 6/20/07, vincent.duval at boehringer-ingelheim.com
<vincent.duval at boehringer-ingelheim.com> wrote:
> Dear R users,
>
> I have a problem computing time differences using R.
>
> I have a date that are given using the following format: 20080620.00, where
> the 4 first digits represent the year, the next 2 ones the month and the last
> 2 ones the day. I would need to compute time differences between two vectors
> of this given format.
>
> I tried around trying to change this format into any type of time serie
> without any succes.
>
> Could some one provide me with some useful suggestion and/or tip to know
> where to look?
>
> I am using R-2.4.0 under Windows XP
>
> Thanks for your help,
>
> Vincent
>
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From singularitaet at gmx.net  Wed Jun 20 13:15:05 2007
From: singularitaet at gmx.net (Stefan Grosse)
Date: Wed, 20 Jun 2007 13:15:05 +0200
Subject: [R] "xtable" results doesn't correspond to data.frame
In-Reply-To: <4678FF75.2060202@gmx.net>
References: <BAY110-F92EAE0AB6FB1AAADA7AE1A3110@phx.gbl>
	<4678FF75.2060202@gmx.net>
Message-ID: <46790C39.90108@gmx.net>

-------- Original Message  --------
Subject: Re:[R] "xtable" results doesn't correspond to data.frame
From: Stefan Grosse <singularitaet at gmx.net>
To: Vumani Dlamini <dvumani at hotmail.com>
Date: 20.06.2007 12:20

Sorry, there is a line missing, I was asking what exactly was not as
expected.

> As improvements you could reduce the digits, see  ?xtable
>
> -------- Original Message  --------
> Subject: [R] "xtable" results doesn't correspond to data.frame
> From: Vumani Dlamini <dvumani at hotmail.com>
> To: r-help at stat.math.ethz.ch
> Date: 20.06.2007 11:20
>


From petr.pikal at precheza.cz  Wed Jun 20 13:23:28 2007
From: petr.pikal at precheza.cz (Petr PIKAL)
Date: Wed, 20 Jun 2007 13:23:28 +0200
Subject: [R] Odp:  extract elements
In-Reply-To: <200706201247.12054.amicogodzilla@bruttocarattere.org>
Message-ID: <OF1E093486.422B9307-ONC1257300.003E734A-C1257300.003E938A@precheza.cz>

Hi

you can use tail

tail(data, -95)

gives you all but first 95 records.

Regards


Petr Pikal
petr.pikal at precheza.cz

r-help-bounces at stat.math.ethz.ch napsal dne 20.06.2007 12:47:11:

> Dear R users,
> just another little question... are there other ways, I mean more easy 
to 
> write, to obtain the same result I got with:
> 
> data[95:length(dati[,1]), ]
> 
> where data is a data frame
> 
> to extract the last elements starting from a fixed position?
> 
> thank you very much
> 
> best regards
>    Manuele PEsenti
> -- 
> Manuele Pesenti
>    manuele at inventati.org
>    amicogodzilla at jabber.linux.it
>    http://mpesenti.polito.it
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From birgit.lemcke at systbot.uzh.ch  Wed Jun 20 13:26:34 2007
From: birgit.lemcke at systbot.uzh.ch (Birgit Lemcke)
Date: Wed, 20 Jun 2007 13:26:34 +0200
Subject: [R] How to extract diagonals
Message-ID: <EEB60A75-0E84-4202-9393-18A3FAEB4230@systbot.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070620/17711e70/attachment.pl 

From jim at bitwrit.com.au  Wed Jun 20 13:53:55 2007
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 20 Jun 2007 21:53:55 +1000
Subject: [R] names over names
In-Reply-To: <516762.2047.qm@web27509.mail.ukl.yahoo.com>
References: <516762.2047.qm@web27509.mail.ukl.yahoo.com>
Message-ID: <46791553.7090209@bitwrit.com.au>

elyakhlifi mustapha wrote:
> Hello,
> I wonder if it's possible to put names above column names.
> Do you know if it's possible?

If you mean something like this:

		Weekdays
Monday	Tuesday	Wednesday Thursday Friday

and you want it to be part of the data frame:

attr(mydf,"supername")<-"Weekdays"

This will not just appear when you print the data frame, you would have 
to access the "supername" like this:

attr(mydf,"supername")

[1] "Weekdays"

However, I suspect that whatever you are trying to accomplish can be 
done in a more straightforward way.

Jim


From dan.bolser.r at googlemail.com  Wed Jun 20 13:57:40 2007
From: dan.bolser.r at googlemail.com (Dan Bolser)
Date: Wed, 20 Jun 2007 13:57:40 +0200
Subject: [R] Retrieve part of (top right corner) of a "plot.data.frame"
	plot?
In-Reply-To: <46790BD5.2070807@free.fr>
References: <712798410706200220m39986a79wb6049cca852b56fd@mail.gmail.com>
	<46790BD5.2070807@free.fr>
Message-ID: <712798410706200457s3d78521fi130eb236e2ce09c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070620/aa85a7f4/attachment.pl 

From perimessaggini at hotmail.com  Wed Jun 20 14:09:23 2007
From: perimessaggini at hotmail.com (Giulio Di Giovanni)
Date: Wed, 20 Jun 2007 12:09:23 +0000
Subject: [R] Linear Mixed Models with nlme, more than one random effect
Message-ID: <BAY140-F23D21670707F77466D6BEBC6110@phx.gbl>


Hi, I' trying to learn how to use lme for Linear Mixed Models  and I have a 
problem when I have to include more than one random effect in my model. I 
know that this could be a stupid question to ask, but I'm not able to solve 
it by myself... One example: if my model is

response = operator + block + day
with operator and block as fixed effects and day as random effect, I use

res.lme <- lme(resp ~ oper + block , random=~1|day)

If I want to include also another random effect, as "experiment", what I 
should do ?
This effect doesn't have to be nested, at the and I would like to have the 
COV matrix using (if I'm not wrong) getVarCov function.

Thanks in advance for any help or suggestions, I'm a beginner on this 
field...

Davide

_________________________________________________________________
Cinema, Tv, Gossip e Orsoscopo
Tutto su MSN intrattenimento!


From gavin.simpson at ucl.ac.uk  Wed Jun 20 14:11:39 2007
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Wed, 20 Jun 2007 13:11:39 +0100
Subject: [R] How to extract diagonals
In-Reply-To: <EEB60A75-0E84-4202-9393-18A3FAEB4230@systbot.uzh.ch>
References: <EEB60A75-0E84-4202-9393-18A3FAEB4230@systbot.uzh.ch>
Message-ID: <1182341499.16388.10.camel@gsimpson.geog.ucl.ac.uk>

On Wed, 2007-06-20 at 13:26 +0200, Birgit Lemcke wrote:
> Hello,
> 
> I am using Mac OS X on a power book and R 2.5.0
> 
> I try to extract a diagonal from a dissimilarity matrix made with  
> dsvdis, with this code:
> 
> diag(DiTestRR)
> 
> But I get this error message:
> 
> Fehler in array(0, c(n, p)) : 'dim' spezifiziert ein zu groes Array
> 
> english:
> 
> Error in array(0, c(n, p)) : 'dim' specifies a too big array.
> 
> Is there a limit to extract diagonals?

The returned object is not a matrix, but an object of class "dist" which
doesn't store the diagonals or the upper triangle of the dissimilarity
matrix to save memory. You need to convert the dist object to a matrix
first, then extract the diagonal. But, as this shows:

> require(labdsv)
> ?dsvdis
> data(bryceveg)
> ?dsvdis
> dis.bc <- dsvdis(bryceveg,index="bray/curtis")
Warning in symbol.For("dsvdis") : 'symbol.For' is not needed: please
remove it
> diag(as.matrix(dis.bc))

This is meaningless as the diagonals are all zero, as they should be;
this is the distance between a site and itself.

> 
> I hope somebody will help me!

So perhaps you could explain why you want the diagonal. It would be
easier to just do:

diags <- rep(0, length = nrow(bryceveg))

That will be without the sample labels, but that is easily rectified

> names(diags) <- rownames(bryceveg)
> all.equal(diags, diag(as.matrix(dis.bc)))
[1] TRUE

So you'll have to reformulate your question if this is not what you
wanted.

A word of warning, do not do diag(dis.bc)) on the above as it brought my
Linux box to it's knees trying to do something silly - easily
recoverable, but beware.

HTH

G

> 
> Greetings
> 
> Birgit Lemcke

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Gavin Simpson                 [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From klebyn at yahoo.com.br  Wed Jun 20 14:22:02 2007
From: klebyn at yahoo.com.br (Cleber Borges)
Date: Wed, 20 Jun 2007 09:22:02 -0300
Subject: [R] triangle contour plots
In-Reply-To: <42B9A932-99E8-4788-B66A-FB12A9FA1DD6@noc.soton.ac.uk>
References: <42B9A932-99E8-4788-B66A-FB12A9FA1DD6@noc.soton.ac.uk>
Message-ID: <46791BEA.6030004@yahoo.com.br>


Hi,
I used similar things to Chemical Mixture Modelling. ( Scheffe model)
I make the function below.

Cleber
+++++++++++++++++++++++++++++++++

trimage <- function(f){
    x = y = seq( 1, 0, l=181 )
    t1 = length(x)
    im = aux = numeric(0)
    for( i in seq( 1, t1, by = 2 ) ){
            #idx = seq( t1**2, i*t1, by = -t1 ) - ((t1 - i):0)
            idx = seq( i*t1, t1**2, by = t1 ) - (i-1)
            im = c(im, aux, idx, aux )
            aux = c(aux, NA)
            }
    z =  outer(X=x, Y=y, FUN=f)
    return( matrix(z[im],nr=t1) )
}

#########################################################
# Example:

f = function(x1,x2){
    x3 = 1 - x1 - x2
    z = x1 + 0*x2 -x3 + 4*x1*x2 + 27*x1*x2*x3
    return( z )
    }


z = trimage( f )

par( xaxt='n', yaxt='n', bty='n', pty='s')
image( z, col=rainbow(256) )
contour( z, add=T )




Robin Hankin wrote:
> Suppose I have three numbers p1, p2, p3 with
> 0 <= p1,p2,p3 <= 1  and p1+p2+p3=1,
> and a  function  f=f(p1,p2,p3)   =  f(p1,p2,1-p1-p2).
>
> How to draw a contour plot of f() on the p1+p2+p3=1 plane,
> that is, an equilateral triangle?
>
> Functions triplot(), triangle.plot(), and ternaryplot()  give
> only  scatterplots, AFAICS
>   




		
_______________________________________________________ 

Experimente j? e veja as novidades.


From maechler at stat.math.ethz.ch  Wed Jun 20 14:28:34 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 20 Jun 2007 14:28:34 +0200
Subject: [R] Odp:  Odp:  outlying
In-Reply-To: <OF37C33612.8B9BC863-ONC12572FF.003BE60C-C12572FF.003C054A@precheza.cz>
References: <OFF38222F2.E9D88EA8-ONC12572FF.0037AD3F-C12572FF.00391F8A@precheza.cz>
	<OF37C33612.8B9BC863-ONC12572FF.003BE60C-C12572FF.003C054A@precheza.cz>
Message-ID: <18041.7538.277847.207396@stat.math.ethz.ch>

[Note: CC'ing to R-SIG-robust, the "Special Interest Group on
       	      	 	         using Robust Statistics in R" ]

>>>>> "PP" == Petr PIKAL <petr.pikal at precheza.cz>
>>>>>     on Tue, 19 Jun 2007 12:55:37 +0200 writes:

    PP> r-help-bounces at stat.math.ethz.ch napsal dne 19.06.2007
    PP> 12:23:58:
    >> Hi
    >> 
    >> It often depends on your attitude to limits for outlying
    >> observations.  Boxplot has some identifying routine for
    >> selecting outlying points.
    >> 
    >> Any procedure usually requires somebody to choose which
    >> observation is outlying and why. You can use e.g. all
    >> values which are beyond some threshold based on sd but
    >> that holds only if distribution is normal.

yes, and that's never true for the "alternative", i.e. for the
case where there *are* outliers.

    >> set.seed(1) 
    >> x<-rnorm(x)

    PP> Sorry, it shall be

    PP> x <- rnorm(1000)

    PP> ul <- mean(x) +3*sd(x)
    PP> ll <- mean(x) -3*sd(x)
    PP> beyond <- (x>ul)  | ( x <ll)
    PP> 
    PP> > x[beyond]
    PP> [1] 3.810277

    >> Regards Petr

No, really, do NOT do the above!
It only works with very few and relatively mild outliers.

There are much more robust alternatives.
I show them for the simple example

x <- c(1:10, 100)

1) As mentioned by Petr,  use instead what  boxplot() does,
  just type
     boxplot.stats

  and ``see what to do''.  This gives   Median +/- 1.5 * IQR :
  i.e.,

 ## Boxplot's default rule
 str(bp.st <- boxplot.stats(x))
 bp.st$stats[ c(1,5) ]
 ## 1  10

2) Use the recommendations of  Hampel (1985)

   @ARTICLE{HamF85,
     author = 	"Hampel, F.",
     title = 	"The breakdown points of the mean combined with some
		     rejection rules", 
     journal = 	"Technometrics",
     year = 	1985,
     volume = 	27,
     pages = 	"95--107",
   }

   
   i.e.   Median +/- 5 * MAD   where MAD = is the *NON*-scaled MAD,
   	  	       	       	     	 ~=  mad(*, constant=1)
   i.e., in R

   M <- median(x)
   (FH.interval <- M +  c(-5, 5) * mad(x, center=M, const=1))
   ## -9 21

3) or something slightly more efficient (under approximate
  normality of the non-outliers),
  e.g., based on  MASS::rlm() :

 n <- length(x)
 s.rm <- summary(robm <- MASS::rlm(x ~ 1))
 s.rm

 (cc <- coef(s.rm))

 ## "approximate" robust degrees of freedom; this is a hack
 ##   which could well be correct
 ##   asymptotically {where the weights would be 0/1} :
 (df.resid <- sum(robm$w) - robm$rank)
 (Tcrit <- qt(0.995, df = df.resid))

 ## Std.error of mean ~= sqrt(1/n Var(X_i)) =  1/sqrt(n) sqrt(Var(X_i))
 cc[,1] + c(-1,1) * sqrt(n) * Tcrit * cc[,"Std. Error"]
 ##  -6.391201 18.555177


---
Martin Maechler, ETH Zurich


From rob.dunne at gmail.com  Wed Jun 20 14:25:07 2007
From: rob.dunne at gmail.com (Robert Dunne)
Date: Wed, 20 Jun 2007 22:25:07 +1000
Subject: [R] compiler cannot create executables
Message-ID: <f5b6gc$d1a$1@sea.gmane.org>

Hi List,


I get an error message "compiler cannot create executables" when I try 
to install a package.

Searching the list archives reveals many messages with the same error 
message. The advice is generally to install g++ and development libraries.

However, I have g++ installed and can compile and run programs as myself 
and via sudo. I got the library to install by using

%sudo R CMD INSTALL --no-configure e1071_1.5-16.tar.gz


can anyone explain this? Also where is the config.log that I should look 
in (see output below)? Isn't that in a tmp directory that is removed 
when the install fails?


%  sudo R CMD INSTALL e1071_1.5-16.tar.gz
Password:
* Installing *source* package 'e1071' ...
checking for C++ compiler default output file name... configure: error: 
C++ compiler cannot create executables
See `config.log' for more details.

R 2.3.1 on kubuntu  breezy (5.10 I think)

Bye
Rob


From birgit.lemcke at systbot.uzh.ch  Wed Jun 20 15:09:04 2007
From: birgit.lemcke at systbot.uzh.ch (Birgit Lemcke)
Date: Wed, 20 Jun 2007 15:09:04 +0200
Subject: [R] How to extract diagonals
In-Reply-To: <1182341499.16388.10.camel@gsimpson.geog.ucl.ac.uk>
References: <EEB60A75-0E84-4202-9393-18A3FAEB4230@systbot.uzh.ch>
	<1182341499.16388.10.camel@gsimpson.geog.ucl.ac.uk>
Message-ID: <32627275-EC9D-46A4-A342-D96FB0946DCB@systbot.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070620/ab2a0d56/attachment.pl 

From rmh at temple.edu  Wed Jun 20 15:09:05 2007
From: rmh at temple.edu (Richard M. Heiberger)
Date: Wed, 20 Jun 2007 09:09:05 -0400 (EDT)
Subject: [R] names over names
Message-ID: <20070620090905.CEN35979@po-d.temple.edu>

If your data.frame is entirely numeric, then you could design a print
function that builds on this example of converting it to a data.matrix:


mydf <- data.frame(Mon=1:3, Tue=4:6, Wed=7:9, Thu=10:12, Fri=13:15)
mydm <- data.matrix(mydf)
names(dimnames(mydm)) <- c("", "Weekdays")
mydm
data.frame(mydm) ## loses names(dimnames)


From milton_ruser at yahoo.com.br  Wed Jun 20 14:07:40 2007
From: milton_ruser at yahoo.com.br (Milton Cezar Ribeiro)
Date: Wed, 20 Jun 2007 05:07:40 -0700 (PDT)
Subject: [R] Creating directory under Windows R session
Message-ID: <550657.81047.qm@web56605.mail.re3.yahoo.com>

Um texto embutido e sem conjunto de caracteres especificado associado...
Nome: n?o dispon?vel
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070620/7c279140/attachment.pl 

From robert-mcfadden at o2.pl  Wed Jun 20 15:15:32 2007
From: robert-mcfadden at o2.pl (Robert McFadden)
Date: Wed, 20 Jun 2007 15:15:32 +0200
Subject: [R] Speed up R
In-Reply-To: <Pine.LNX.4.64.0706192216270.12443@gannet.stats.ox.ac.uk>
Message-ID: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAfHU8PP2E50qGgSIBTaVydsKAAAAQAAAA9ZipM0jYbkSnDRXmTyd7zgEAAAAA@o2.pl>

 
> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley w stats.ox.ac.uk] 
> The advantage of dual processors is that you can use the 
> machine for several things at once, including multiple R 
> jobs.  For example, when I am doing package checking I am 
> typically checking 4 packages at once on a dual processor 
> machine to get continuous high utilization.

I would like to thank very much everybody taking part in discussion.
Does an answer above suggest that I can open two R console and do
simulations simultaneously? If so, all simulations take more or less 1/2
times - or much less then doing it in turn? 

During our discussion one mentioned that RAM is important. But in my
computing I do not use up more then 500 MB. I have 786 MB it means
(probably) that I have enough.      
Am I right?

Best,
Rob



> I have little doubt that a Pentium 4 would be much slower 
> than the others.
> 
> I've just bought an Intel Core 2 Duo E6600 primarily to run 
> 64-bit Linux, but it also has Vista 64 and XP (32-bit) on it. 
>  I don't think the differences between the current dual-core 
> chips are really enough to worry about: they will all look 
> slow in less than a year.
> 
> -- 
> Brian D. Ripley,                  ripley w stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mike.prager at noaa.gov  Wed Jun 20 15:08:00 2007
From: mike.prager at noaa.gov (Mike Prager)
Date: Wed, 20 Jun 2007 09:08:00 -0400
Subject: [R] Speed up R
References: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAfHU8PP2E50qGgSIBTaVydsKAAAAQAAAABwQr1ccyxkyN/Yw5Qh9faQEAAAAA@o2.pl>
	<Pine.LNX.4.64.0706192216270.12443@gannet.stats.ox.ac.uk>
Message-ID: <v19i73t804jhhs4j5himl5unj8v0v4r2gk@4ax.com>

Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> The advantage of dual processors is that you can use the machine for 
> several things at once, including multiple R jobs.  

I've used dual-processor machines for about 10 years now and
emphatically second the point made by Brian Ripley. Even if you
are not running several R jobs at once, it is nice to do
something else at full speed while a simulation uses another
processor.

Often overlooked is the additional large advantage to be gained
by using SCSI disks rather than any form of ATA. With today's
large applications and operating systems, there can be frequent
paging, and a SCSI subsystem will make a large difference in
computer response, at least under Windows. Unless your work is
processor bound, disk I/O is usually what sets the pace. 

-- 
Mike Prager, NOAA, Beaufort, NC
* Opinions expressed are personal and not represented otherwise.
* Any use of tradenames does not constitute a NOAA endorsement.


From joris.dewolf at cropdesign.com  Wed Jun 20 15:17:42 2007
From: joris.dewolf at cropdesign.com (joris.dewolf at cropdesign.com)
Date: Wed, 20 Jun 2007 15:17:42 +0200
Subject: [R] Linear Mixed Models with nlme, more than one random effect
In-Reply-To: <BAY140-F23D21670707F77466D6BEBC6110@phx.gbl>
Message-ID: <OF38D0F60A.BD593F52-ONC1257300.0048A3A2-C1257300.004907A4@basf-c-s.be>



Guilio,

Have a look at Rnew volume 5/1 (http://cran.r-project.org/doc/Rnews/) where
Doug Bates explains this nicely. Condider using lme4 for your purpose.

Joris








                                                                           
             "Giulio Di                                                    
             Giovanni"                                                     
             <perimessaggini at h                                          To 
             otmail.com>               r-help at stat.math.ethz.ch            
             Sent by:                                                   cc 
             r-help-bounces at st                                             
             at.math.ethz.ch                                       Subject 
                                       [R] Linear Mixed Models with nlme,  
                                       more than one random effect         
             20/06/2007 14:09                                              
                                                                           
                                                                           
                                                                           
                                                                           
                                                                           





Hi, I' trying to learn how to use lme for Linear Mixed Models  and I have a

problem when I have to include more than one random effect in my model. I
know that this could be a stupid question to ask, but I'm not able to solve

it by myself... One example: if my model is

response = operator + block + day
with operator and block as fixed effects and day as random effect, I use

res.lme <- lme(resp ~ oper + block , random=~1|day)

If I want to include also another random effect, as "experiment", what I
should do ?
This effect doesn't have to be nested, at the and I would like to have the
COV matrix using (if I'm not wrong) getVarCov function.

Thanks in advance for any help or suggestions, I'm a beginner on this
field...

Davide

_________________________________________________________________
Cinema, Tv, Gossip e Orsoscopo?Tutto su MSN intrattenimento!

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bcarvalh at jhsph.edu  Wed Jun 20 15:49:21 2007
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Wed, 20 Jun 2007 09:49:21 -0400
Subject: [R] Creating directory under Windows R session
In-Reply-To: <550657.81047.qm@web56605.mail.re3.yahoo.com>
References: <550657.81047.qm@web56605.mail.re3.yahoo.com>
Message-ID: <3105937C-38AA-4C24-BA4B-0144C5A6CAE2@jhsph.edu>

?dir.create

b

On Jun 20, 2007, at 8:07 AM, Milton Cezar Ribeiro wrote:

> Hi all,
>
> How can I create (and check the existence of) a directory in a R  
> session under Windows(xp)?
>
> Kind regards,
>
> Miltinho


From perimessaggini at hotmail.com  Wed Jun 20 15:58:20 2007
From: perimessaggini at hotmail.com (Giulio Di Giovanni)
Date: Wed, 20 Jun 2007 13:58:20 +0000
Subject: [R] Linear Mixed Models with nlme, more than one random effect
In-Reply-To: <OF38D0F60A.BD593F52-ONC1257300.0048A3A2-C1257300.004907A4@basf-c-s.be>
Message-ID: <BAY140-F26BC6524F53A21362F139DC6110@phx.gbl>

Thanks a lot !!!

I was about to reply to my previous email that I found a solution via lme4 !
But really thanks.




>From: joris.dewolf at cropdesign.com
>To: "Giulio Di Giovanni" <perimessaggini at hotmail.com>
>CC: r-help at stat.math.ethz.ch, r-help-bounces at stat.math.ethz.ch
>Subject: Re: [R] Linear Mixed Models with nlme, more than one random effect
>Date: Wed, 20 Jun 2007 15:17:42 +0200
>
>
>
>Guilio,
>
>Have a look at Rnew volume 5/1 (http://cran.r-project.org/doc/Rnews/) where
>Doug Bates explains this nicely. Condider using lme4 for your purpose.
>
>Joris
>
>
>
>
>
>
>
>
>
>              "Giulio Di
>              Giovanni"
>              <perimessaggini at h                                          To
>              otmail.com>               r-help at stat.math.ethz.ch
>              Sent by:                                                   cc
>              r-help-bounces at st
>              at.math.ethz.ch                                       Subject
>                                        [R] Linear Mixed Models with nlme,
>                                        more than one random effect
>              20/06/2007 14:09
>
>
>
>
>
>
>
>
>
>
>Hi, I' trying to learn how to use lme for Linear Mixed Models  and I have a
>
>problem when I have to include more than one random effect in my model. I
>know that this could be a stupid question to ask, but I'm not able to solve
>
>it by myself... One example: if my model is
>
>response = operator + block + day
>with operator and block as fixed effects and day as random effect, I use
>
>res.lme <- lme(resp ~ oper + block , random=~1|day)
>
>If I want to include also another random effect, as "experiment", what I
>should do ?
>This effect doesn't have to be nested, at the and I would like to have the
>COV matrix using (if I'm not wrong) getVarCov function.
>
>Thanks in advance for any help or suggestions, I'm a beginner on this
>field...
>
>Davide
>
>_________________________________________________________________
>Cinema, Tv, Gossip e Orsoscopo???Tutto su MSN intrattenimento!
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

_________________________________________________________________
Calcio, Quiz, Sudoku, Scacchi
 Inizia la sfida su Messenger, GRATIS!


From ripley at stats.ox.ac.uk  Wed Jun 20 16:08:55 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 20 Jun 2007 15:08:55 +0100 (BST)
Subject: [R] Speed up R
In-Reply-To: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAfHU8PP2E50qGgSIBTaVydsKAAAAQAAAA9ZipM0jYbkSnDRXmTyd7zgEAAAAA@o2.pl>
References: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAfHU8PP2E50qGgSIBTaVydsKAAAAQAAAA9ZipM0jYbkSnDRXmTyd7zgEAAAAA@o2.pl>
Message-ID: <Pine.LNX.4.64.0706201502480.18548@gannet.stats.ox.ac.uk>

On Wed, 20 Jun 2007, Robert McFadden wrote:

>
>> -----Original Message-----
>> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
>> The advantage of dual processors is that you can use the
>> machine for several things at once, including multiple R
>> jobs.  For example, when I am doing package checking I am
>> typically checking 4 packages at once on a dual processor
>> machine to get continuous high utilization.
>
> I would like to thank very much everybody taking part in discussion.
> Does an answer above suggest that I can open two R console and do
> simulations simultaneously? If so, all simulations take more or less 1/2
> times - or much less then doing it in turn?

Yes, you can.  You will get very close to 2x speed up if you have enough 
(and fast enough) RAM.

> During our discussion one mentioned that RAM is important. But in my
> computing I do not use up more then 500 MB. I have 786 MB it means
> (probably) that I have enough.

On a dual processor machine you need more to avoid any swapping.  Even my
2.5 year old laptop has 1Gb, and I'd want at least 2Gb in a dual processor 
machine given that spec.  My sysadmin suggests a minimum of 4Gb for 64-bit 
dual processors these days.

> Am I right?
>
> Best,
> Rob
>
>
>
>> I have little doubt that a Pentium 4 would be much slower
>> than the others.
>>
>> I've just bought an Intel Core 2 Duo E6600 primarily to run
>> 64-bit Linux, but it also has Vista 64 and XP (32-bit) on it.
>>  I don't think the differences between the current dual-core
>> chips are really enough to worry about: they will all look
>> slow in less than a year.
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From edd at debian.org  Wed Jun 20 16:10:47 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 20 Jun 2007 09:10:47 -0500
Subject: [R] compiler cannot create executables
In-Reply-To: <f5b6gc$d1a$1@sea.gmane.org>
References: <f5b6gc$d1a$1@sea.gmane.org>
Message-ID: <20070620141047.GA18846@eddelbuettel.com>

On Wed, Jun 20, 2007 at 10:25:07PM +1000, Robert Dunne wrote:
> Hi List,
> 
> 
> I get an error message "compiler cannot create executables" when I try 
> to install a package.
> 
> Searching the list archives reveals many messages with the same error 
> message. The advice is generally to install g++ and development libraries.
> 
> However, I have g++ installed and can compile and run programs as myself 
> and via sudo. I got the library to install by using
> 
> %sudo R CMD INSTALL --no-configure e1071_1.5-16.tar.gz

This statement of your conflicts with the msg you show below. Do you,
or don't you, succeed?

> can anyone explain this? Also where is the config.log that I should look 
> in (see output below)? Isn't that in a tmp directory that is removed 
> when the install fails?
> 
> 
> %  sudo R CMD INSTALL e1071_1.5-16.tar.gz
> Password:
> * Installing *source* package 'e1071' ...
> checking for C++ compiler default output file name... configure: error: 
> C++ compiler cannot create executables
> See `config.log' for more details.
> 
> R 2.3.1 on kubuntu  breezy (5.10 I think)

Please try 

       $ sudo apt-get install r-base-dev

as you seem to missing g++, and probably a host of other things.

Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From birgit.lemcke at systbot.uzh.ch  Wed Jun 20 16:13:48 2007
From: birgit.lemcke at systbot.uzh.ch (Birgit Lemcke)
Date: Wed, 20 Jun 2007 16:13:48 +0200
Subject: [R] Dissimilarity
In-Reply-To: <fd2477720706200652h9234b17me6a94d0bade0b60b@mail.gmail.com>
References: <fd2477720706200652h9234b17me6a94d0bade0b60b@mail.gmail.com>
Message-ID: <0B85CE3E-78E8-4DC5-8484-CBB687E61545@systbot.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070620/324e7538/attachment.pl 

From mckellercran at gmail.com  Wed Jun 20 16:16:02 2007
From: mckellercran at gmail.com (Matthew Keller)
Date: Wed, 20 Jun 2007 10:16:02 -0400
Subject: [R] Speed up R
In-Reply-To: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAfHU8PP2E50qGgSIBTaVydsKAAAAQAAAA9ZipM0jYbkSnDRXmTyd7zgEAAAAA@o2.pl>
References: <Pine.LNX.4.64.0706192216270.12443@gannet.stats.ox.ac.uk>
	<!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAfHU8PP2E50qGgSIBTaVydsKAAAAQAAAA9ZipM0jYbkSnDRXmTyd7zgEAAAAA@o2.pl>
Message-ID: <3f547caa0706200716t493e63adq22214914dbf92f74@mail.gmail.com>

Robert,

I'm not exactly an expert, but here's what I think. If you have only
786 MB of RAM on your machine and you are using ~500 of it in a
session of R, that could slow things down considerably because your
machine is trying to find free blocks of memory that haven't been used
yet. I would buy additional RAM.

As for Mike Prager's point about the type of hard drive being
important, I'm not sure this is right (someone correct me if I'm
misunderstanding). R stores and accesses objects through RAM - they
aren't stored and accessed on the hard drive except when reading and
writing. So hard drive type probably won't make much difference to
speed in R.

Matt

On 6/20/07, Robert McFadden <robert-mcfadden at o2.pl> wrote:
>
> > -----Original Message-----
> > From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> > The advantage of dual processors is that you can use the
> > machine for several things at once, including multiple R
> > jobs.  For example, when I am doing package checking I am
> > typically checking 4 packages at once on a dual processor
> > machine to get continuous high utilization.
>
> I would like to thank very much everybody taking part in discussion.
> Does an answer above suggest that I can open two R console and do
> simulations simultaneously? If so, all simulations take more or less 1/2
> times - or much less then doing it in turn?
>
> During our discussion one mentioned that RAM is important. But in my
> computing I do not use up more then 500 MB. I have 786 MB it means
> (probably) that I have enough.
> Am I right?
>
> Best,
> Rob
>
>
>
> > I have little doubt that a Pentium 4 would be much slower
> > than the others.
> >
> > I've just bought an Intel Core 2 Duo E6600 primarily to run
> > 64-bit Linux, but it also has Vista 64 and XP (32-bit) on it.
> >  I don't think the differences between the current dual-core
> > chips are really enough to worry about: they will all look
> > slow in less than a year.
> >
> > --
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Matthew C Keller
Postdoctoral Fellow
Virginia Institute for Psychiatric and Behavioral Genetics


From myrddincox at gmail.com  Wed Jun 20 15:49:44 2007
From: myrddincox at gmail.com (stephen cox)
Date: Wed, 20 Jun 2007 13:49:44 +0000 (UTC)
Subject: [R] Dissimilarity Analysis
References: <98C49113-3775-4EDC-B8C2-C0E528B6375B@systbot.uzh.ch>
Message-ID: <loom.20070620T154003-450@post.gmane.org>

Hi Birgit - looks like you have a few issues here.

Birgit Lemcke <birgit.lemcke <at> systbot.uzh.ch> writes:

> 
> Hello you all!
> 
> I am a completely new user of R and I have a problem to solve.
> I am using Mac OS X on a PowerBook.
> 
> I have a table that looks like this:
> 
>             species X1 X2 X3 X4 X5 X6 X7 X8 X9 X10 X11 X12 X13 X14  
> X15 X16 X17 X18 X19 X20 X21
> 1        Anth_cap1  1  0  0  1  0  1  0  0  1   0   0   0   0   0    
> 0   0   1   0   0   0   1
> 2       Anth_crin1  1  0  0  1  0  1  0  0  1   0   1   0   0   0    
> 0   0   0   1   0   0   1
> 3        Anth_eck1  1  0  0  1  0  1  0  0  1   0   0   0   0   0    
> 0   0   0   1   0   0   1
> 4       Anth_gram1  1  0  0  1  0  1  0  0  1  NA  NA  NA  NA   0    
> 0   0   0   1   0   0   0
> 5       Anth_insi1  1  0  0  1  0  1  0  0  1   0   0   0   1   0    
> 0   0   0   1   0   0   1
> 
> All columns  are binary coded characters.
> The Import was done by this
> 
> Test<-read.table("TestRFemMalBivariat1.csv",header = TRUE, sep = ";")

First - you need to transpose the matrix to have species as columns.  You can do
this with:

d2 = data.frame(t(Test[,-1]))
colnames(d2) = Test[,1]  #now use d2


 
> Now I try to perform a similarity analysis with the dsvdis function  
> of the labdsv package with the sorensen-Index.
> 
> My first question is if all zeros in my table are seen as missing  
> values and if it islike that how can I change without turning zero  
> into other numbers?

no - the zeros are valid observations.  the na's are missing data.


>   DisTest<-dsvdis(Test, index = "sorensen")
> 
> But I always get back this error message:
> 
> Warnung in symbol.For("dsvdis") :'symbol.For' is not needed: please  
> remove it
> Fehler in dsvdis(Test, index = "sorensen") :
> 	NA/NaN/Inf in externem Funktionsaufruf (arg 1)
> Zus?tzlich: Warning message:
> NAs durch Umwandlung erzeugt



Second - you have an issue with missing data.  It looks like dsvdis does not
like the NA's - so you must make a decision about what to do.  Delete that
species, delete that site, or whatever...

Finally - the warning over symbol.For is an issue with the labdsv library itself
- nothing you are doing wrong.  The results will still be valid - but the use of
symbol.For is something that will eventually need to be changed in the labdsv
library.

hth,

stephen


From wwwhsd at gmail.com  Wed Jun 20 16:22:05 2007
From: wwwhsd at gmail.com (Henrique Dallazuanna)
Date: Wed, 20 Jun 2007 11:22:05 -0300
Subject: [R] Creating directory under Windows R session
In-Reply-To: <550657.81047.qm@web56605.mail.re3.yahoo.com>
References: <550657.81047.qm@web56605.mail.re3.yahoo.com>
Message-ID: <da79af330706200722g20c60bf9nca5b7372528a1038@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070620/a2ca12f4/attachment.pl 

From dlvanbrunt at gmail.com  Wed Jun 20 16:32:39 2007
From: dlvanbrunt at gmail.com (David L. Van Brunt, Ph.D.)
Date: Wed, 20 Jun 2007 10:32:39 -0400
Subject: [R] Speed up R
In-Reply-To: <3f547caa0706191409w3c8f92f0me3dbc44ea56f2674@mail.gmail.com>
References: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAfHU8PP2E50qGgSIBTaVydsKAAAAQAAAABwQr1ccyxkyN/Yw5Qh9faQEAAAAA@o2.pl>
	<3f547caa0706191409w3c8f92f0me3dbc44ea56f2674@mail.gmail.com>
Message-ID: <d332d3e10706200732t3f37f65bsebaa656d54a57c65@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070620/a2a2852f/attachment.pl 

From edd at debian.org  Wed Jun 20 16:34:57 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 20 Jun 2007 09:34:57 -0500
Subject: [R] compiler cannot create executables
In-Reply-To: <20070620141047.GA18846@eddelbuettel.com>
References: <f5b6gc$d1a$1@sea.gmane.org>
	<20070620141047.GA18846@eddelbuettel.com>
Message-ID: <20070620143457.GA19115@eddelbuettel.com>

On Wed, Jun 20, 2007 at 09:10:47AM -0500, Dirk Eddelbuettel wrote:
> On Wed, Jun 20, 2007 at 10:25:07PM +1000, Robert Dunne wrote:
> > Hi List,
> > 
> > 
> > I get an error message "compiler cannot create executables" when I try 
> > to install a package.
> > 
> > Searching the list archives reveals many messages with the same error 
> > message. The advice is generally to install g++ and development libraries.
> > 
> > However, I have g++ installed and can compile and run programs as myself 
> > and via sudo. I got the library to install by using
> > 
> > %sudo R CMD INSTALL --no-configure e1071_1.5-16.tar.gz
> 
> This statement of your conflicts with the msg you show below. Do you,
> or don't you, succeed?
> 
> > can anyone explain this? Also where is the config.log that I should look 
> > in (see output below)? Isn't that in a tmp directory that is removed 
> > when the install fails?
> > 
> > 
> > %  sudo R CMD INSTALL e1071_1.5-16.tar.gz
> > Password:
> > * Installing *source* package 'e1071' ...
> > checking for C++ compiler default output file name... configure: error: 
> > C++ compiler cannot create executables
> > See `config.log' for more details.
> > 
> > R 2.3.1 on kubuntu  breezy (5.10 I think)
> 
> Please try 
> 
>        $ sudo apt-get install r-base-dev
> 
> as you seem to missing g++, and probably a host of other things.

I don't have access to a 'breezy' box anymore but what it could be is
that R expects a different compiler version then the system has as
default -- g++-4.0 vs g++-3.4.

What does 'grep g++ /etc/R/Makeconf' yield?

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From brown_emu at yahoo.com  Wed Jun 20 16:46:50 2007
From: brown_emu at yahoo.com (Stephen Tucker)
Date: Wed, 20 Jun 2007 07:46:50 -0700 (PDT)
Subject: [R] Computing time differences
In-Reply-To: <033BC9FB402D2B4CBBBE829F25FEDBE90123C712@bibexm02.eu.boehringer.com>
Message-ID: <890779.17666.qm@web39712.mail.mud.yahoo.com>

Here is one way:

Vector1 <- c("20080621.00","20080623.00")
Vector2 <- c("20080620.00","20080622.00")
do.call(difftime,
        c(apply(cbind(time1=Vector1,time2=Vector2),2,
              function(x) strptime(x,format="%Y%m%d.00")),
          units="hours"))

see ?strptime, ?difftime and
http://cran.r-project.org/doc/Rnews/Rnews_2004-1.pdf



--- vincent.duval at boehringer-ingelheim.com wrote:

> Dear R users, 
> 
> I have a problem computing time differences using R. 
> 
> I have a date that are given using the following format: 20080620.00, where
> the 4 first digits represent the year, the next 2 ones the month and the
> last
> 2 ones the day. I would need to compute time differences between two
> vectors
> of this given format. 
> 
> I tried around trying to change this format into any type of time serie
> without any succes. 
> 
> Could some one provide me with some useful suggestion and/or tip to know
> where to look?
> 
> I am using R-2.4.0 under Windows XP
> 
> Thanks for your help, 
> 
> Vincent
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 



       
____________________________________________________________________________________
Pinpoint customers who are looking for what you sell.


From elyakhlifi_mustapha at yahoo.fr  Wed Jun 20 17:06:45 2007
From: elyakhlifi_mustapha at yahoo.fr (elyakhlifi mustapha)
Date: Wed, 20 Jun 2007 15:06:45 +0000 (GMT)
Subject: [R] merge
Message-ID: <665850.93616.qm@web27511.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070620/635c2690/attachment.pl 

From milton_ruser at yahoo.com.br  Wed Jun 20 15:25:29 2007
From: milton_ruser at yahoo.com.br (Milton Cezar Ribeiro)
Date: Wed, 20 Jun 2007 06:25:29 -0700 (PDT)
Subject: [R] Enc: Creating directory under Windows R session
Message-ID: <741592.74155.qm@web56609.mail.re3.yahoo.com>

Um texto embutido e sem conjunto de caracteres especificado associado...
Nome: n?o dispon?vel
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070620/733cb243/attachment.pl 

From fjbuch at gmail.com  Wed Jun 20 17:05:05 2007
From: fjbuch at gmail.com (Farrel Buchinsky)
Date: Wed, 20 Jun 2007 11:05:05 -0400
Subject: [R] genetics package not working
References: <bd93cdad0706181709p563b55d4pe43e2d0ea894054d@mail.gmail.com>
Message-ID: <f5bfmv$jmo$1@sea.gmane.org>

>From crawling around the internet it appears to me as if genetics has given 
way to GeneticsBase and is part of bioconductor. The basic data structure 
has changed to something called geneSet class. There is a pdf document that 
promises to help me. 
http://www.bioconductor.org/packages/2.1/bioc/vignettes/GeneticsBase/inst/doc/SummaryTables.pdf. 
Unfortunately it does not. My dataset which was created using genetics 
package does not seem to fit (or should I say "does not seem to easily fit") 
the read in formats demonstrated in the document: standard pedigree format, 
hapmap format, Pfizer format, Perlegen format.

Can anyone point me to a resource with lower level instructions and 
examples?

My format is as follows (rs numbers are not correct but do not worry about 
that detail)
> str(ped.seq[,2:15])
'data.frame':   608 obs. of  14 variables:
 $ pedigree  : int  1 1 2 3 3 4 4 5 6 6 ...
 $ id        : Factor w/ 30 levels "1","2","3","4",..: 3 2 3 3 2 3 2 3 3 2 
...
 $ id.father : int  1 0 1 1 0 1 0 1 1 0 ...
 $ id.mother : int  2 0 2 2 0 2 0 2 2 0 ...
 $ PtCode    : Factor w/ 608 levels "AJM16001FA","AJM16001MO",..: 74 73 77 
117 116 80 79 83 86 85 ...
 $ HS.nr     : int  32940 32941 32960 32963 32964 32967 32968 32970 32972 
32973 ...
 $ affected  : int  2 1 2 2 1 2 1 2 2 1 ...
 $ sex       : int  2 2 1 1 2 1 2 2 2 2 ...
 $ rs11684: Factor w/ 1 level "C/C": 1 1 1 1 1 1 1 1 1 1 ...
  ..- attr(*, "allele.names")= chr "C"
  ..- attr(*, "allele.map")= chr [1, 1:2] "C" "C"
 $ rs1144: Factor w/ 3 levels "A/A","G/A","G/G": 3 3 3 3 3 2 3 3 3 3 ...
  ..- attr(*, "allele.names")= chr  "G" "A"
  ..- attr(*, "allele.map")= chr [1:3, 1:2] "A" "G" "G" "A" ...
 $ rs120: Factor w/ 2 levels "A/A","A/G": 1 1 1 1 1 1 1 1 1 1 ...
  ..- attr(*, "allele.names")= chr  "A" "G"
  ..- attr(*, "allele.map")= chr [1:2, 1:2] "A" "A" "A" "G"



"Farrel Buchinsky" <fjbuch at gmail.com> wrote in message 
news:bd93cdad0706181709p563b55d4pe43e2d0ea894054d at mail.gmail.com...
> Has something changed in R that requires an update in the genetics package
> by Gregory Warnes? I am using R version 2.5.0
> This used to work
>> summary(founders[,59])
>
> to prove that it is  a genotype class
>> class(founders[,59])
> [1] "genotype" "factor"
>
> Now when I issue the command:
>> summary(founders[,59])
>
> I get:
>
> Error in attr(retval, "which") <- which : attempt to set an attribute on
> NULL
> In addition: Warning message:
> $ operator is deprecated for atomic vectors, returning NULL in:
> x$allele.names
>
> Clearly, I am missing something. What am I missing?
>
> -- 
> Farrel Buchinsky
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From helprhelp at gmail.com  Wed Jun 20 17:37:22 2007
From: helprhelp at gmail.com (Weiwei Shi)
Date: Wed, 20 Jun 2007 11:37:22 -0400
Subject: [R] merge
In-Reply-To: <665850.93616.qm@web27511.mail.ukl.yahoo.com>
References: <665850.93616.qm@web27511.mail.ukl.yahoo.com>
Message-ID: <cdf817830706200837y4d1118b9y54531b691916a226@mail.gmail.com>

if your nrow is not big, transpose and merge and transpose back.

HTH,

On 6/20/07, elyakhlifi mustapha <elyakhlifi_mustapha at yahoo.fr> wrote:
> hello,
> is it possible to merge 2 matrix or data.frame by roxnames?
> I checked details about the functino merge but I haven't fond this option.
> Can you help me please?
> thanks.
>
>
>       _____________________________________________________________________________
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Weiwei Shi, Ph.D
Research Scientist
GeneGO, Inc.

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III


From kevin.thorpe at utoronto.ca  Wed Jun 20 17:41:26 2007
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Wed, 20 Jun 2007 11:41:26 -0400
Subject: [R] merge
In-Reply-To: <665850.93616.qm@web27511.mail.ukl.yahoo.com>
References: <665850.93616.qm@web27511.mail.ukl.yahoo.com>
Message-ID: <46794AA6.1090406@utoronto.ca>

elyakhlifi mustapha wrote:
> hello,
> is it possible to merge 2 matrix or data.frame by roxnames?
> I checked details about the functino merge but I haven't fond this option.
> Can you help me please?
> thanks.

The first paragraph of the Details section says:

By default the data frames are merged on the columns with names they
both have, but separate specifications of the columns can be given by
by.x and by.y. Columns can be specified by name, number or by a logical
vector: the name "row.names" or the number 0 specifies the row names.


-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Department of Public Health Sciences
Faculty of Medicine, University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.6057


From gavin.simpson at ucl.ac.uk  Wed Jun 20 17:46:17 2007
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Wed, 20 Jun 2007 16:46:17 +0100
Subject: [R] Dissimilarity
In-Reply-To: <0B85CE3E-78E8-4DC5-8484-CBB687E61545@systbot.uzh.ch>
References: <fd2477720706200652h9234b17me6a94d0bade0b60b@mail.gmail.com>
	<0B85CE3E-78E8-4DC5-8484-CBB687E61545@systbot.uzh.ch>
Message-ID: <1182354377.16388.14.camel@gsimpson.geog.ucl.ac.uk>

On Wed, 2007-06-20 at 16:13 +0200, Birgit Lemcke wrote:
> Hello Stephen,
> 
> I am happy that you help me. Thanks a million.
> 
> It is a good feeling that you confirm my assumption that dsvdis is  
> not able to deal with missing data, because it says me that I am not  
> completely incapable.
> Okay now I have the problem what to do.
> I used this function cause there is an option to weight columns  
> differently what I havent found in other functions.
> 
> But now I dont understand why I have to transpose the species as  
> columns? As I read in the help manual of dsvdis this function  
> calculates dissimilarities between rows.
> I have to calculate the dissimilarities between species that are in  
> rows by the use of morphological characters that are in columns.

If you really what to measure the associations between species then
leave them as you had them as the rows. But make sure you are choosing a
dissimilarity coefficient that works well for species associations.
There is a whole section in Legendre and Legendre 1998 Numerical Ecology
2nd English Edition Elsevier which may help here.

HTH

G

> 
> Am I completely wrong with my thoughts?
> 
> Birgit
> 
> Am 20.06.2007 um 15:52 schrieb Stephen B. Cox:
> 
> > Hi Birgit - looks like you have a few issues here.
> >
> > Birgit Lemcke <birgit.lemcke <at> systbot.uzh.ch> writes:
> >
> >>
> >> Hello you all!
> >>
> >> I am a completely new user of R and I have a problem to solve.
> >> I am using Mac OS X on a PowerBook.
> >>
> >> I have a table that looks like this:
> >>
> >>             species X1 X2 X3 X4 X5 X6 X7 X8 X9 X10 X11 X12 X13 X14
> >> X15 X16 X17 X18 X19 X20 X21
> >> 1        Anth_cap1  1  0  0  1  0  1  0  0  1   0   0   0   0   0
> >> 0   0   1   0   0   0   1
> >> 2       Anth_crin1  1  0  0  1  0  1  0  0  1   0   1   0   0   0
> >> 0   0   0   1   0   0   1
> >> 3        Anth_eck1  1  0  0  1  0  1  0  0  1   0   0   0   0   0
> >> 0   0   0   1   0   0   1
> >> 4       Anth_gram1  1  0  0  1  0  1  0  0  1  NA  NA  NA  NA   0
> >> 0   0   0   1   0   0   0
> >> 5       Anth_insi1  1  0  0  1  0  1  0  0  1   0   0   0   1   0
> >> 0   0   0   1   0   0   1
> >>
> >> All columns  are binary coded characters.
> >> The Import was done by this
> >>
> >> Test<-read.table("TestRFemMalBivariat1.csv",header = TRUE, sep = ";")
> >
> > First - you need to transpose the matrix to have species as  
> > columns.  You can do
> > this with:
> >
> > d2 = data.frame(t(Test[,-1]))
> > colnames(d2) = Test[,1]  #now use d2
> >
> >
> >
> >> Now I try to perform a similarity analysis with the dsvdis function
> >> of the labdsv package with the sorensen-Index.
> >>
> >> My first question is if all zeros in my table are seen as missing
> >> values and if it islike that how can I change without turning zero
> >> into other numbers?
> >
> > no - the zeros are valid observations.  the na's are missing data.
> >
> >
> >>   DisTest<-dsvdis(Test, index = "sorensen")
> >>
> >> But I always get back this error message:
> >>
> >> Warnung in symbol.For("dsvdis") :'symbol.For' is not needed: please
> >> remove it
> >> Fehler in dsvdis(Test, index = "sorensen") :
> >> 	NA/NaN/Inf in externem Funktionsaufruf (arg 1)
> >> Zustzlich: Warning message:
> >> NAs durch Umwandlung erzeugt
> >
> >
> >
> > Second - you have an issue with missing data.  It looks like dsvdis  
> > does not
> > like the NA's - so you must make a decision about what to do.   
> > Delete that
> > species, delete that site, or whatever...
> >
> > Finally - the warning over symbol.For is an issue with the labdsv  
> > library itself
> > - nothing you are doing wrong.  The results will still be valid -  
> > but the use of
> > symbol.For is something that will eventually need to be changed in  
> > the labdsv
> > library.
> >
> > hth,
> >
> > stephen
> 
> Birgit Lemcke
> Institut fr Systematische Botanik
> Zollikerstrasse 107
> CH-8008 Zrich
> Switzerland
> Ph: +41 (0)44 634 8351
> birgit.lemcke at systbot.uzh.ch
> 
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Gavin Simpson                 [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From mel at altk.com  Wed Jun 20 17:48:33 2007
From: mel at altk.com (mel)
Date: Wed, 20 Jun 2007 17:48:33 +0200
Subject: [R] Enc: Creating directory under Windows R session
In-Reply-To: <741592.74155.qm@web56609.mail.re3.yahoo.com>
References: <741592.74155.qm@web56609.mail.re3.yahoo.com>
Message-ID: <46794C51.8020206@altk.com>

?dir.create
?files
hih


From elyakhlifi_mustapha at yahoo.fr  Wed Jun 20 18:02:07 2007
From: elyakhlifi_mustapha at yahoo.fr (elyakhlifi mustapha)
Date: Wed, 20 Jun 2007 16:02:07 +0000 (GMT)
Subject: [R] merge
Message-ID: <747715.81493.qm@web27507.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070620/ea57803a/attachment.pl 

From gavin.simpson at ucl.ac.uk  Wed Jun 20 18:02:53 2007
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Wed, 20 Jun 2007 17:02:53 +0100
Subject: [R] How to extract diagonals
In-Reply-To: <32627275-EC9D-46A4-A342-D96FB0946DCB@systbot.uzh.ch>
References: <EEB60A75-0E84-4202-9393-18A3FAEB4230@systbot.uzh.ch>
	<1182341499.16388.10.camel@gsimpson.geog.ucl.ac.uk>
	<32627275-EC9D-46A4-A342-D96FB0946DCB@systbot.uzh.ch>
Message-ID: <1182355373.16388.29.camel@gsimpson.geog.ucl.ac.uk>

On Wed, 2007-06-20 at 15:09 +0200, Birgit Lemcke wrote:
> Hello Gavin and thanks for your answer.
> 
> Your completely right I dont need the diagonal that is the bisecting  
> line of the angle.
> 
> I need another diagonal of the (now) matrix.
> 
>          A1 A2 A3 A4 B1 B2 B3 B4
>     A1
>     A2
>     A3
>     A4
>     B1 X
>     B2       X
>     B3            X
>     B4                 X
> 

Not easily, especially without knowing how many samples are in A or B,
although all that is really needed is some careful subsetting of the
dist object and a minor amount of programming - unfortunately after
close to two weeks intensive teaching my brain isn't up to doing that
just now.

One simple way to do this is to use the distance() function in my
analogue package (on CRAN). distance() can calculate the dissimilarities
between one group of samples and another. Here is a simple example using
some dummy data, from ?distance:

     ## simple example using dummy data
     train <- data.frame(matrix(abs(runif(200)), ncol = 10))
     rownames(train) <- LETTERS[1:20]
     colnames(train) <- as.character(1:10)
     fossil <- data.frame(matrix(abs(runif(100)), ncol = 10))
     colnames(fossil) <- as.character(1:10)
     rownames(fossil) <- letters[1:10]

     ## calculate distances/dissimilarities between train and fossil
     ## samples
     test <- distance(train, fossil)

test is now a matrix, the diagonal elements of which are the values that
you appear to want:

     diag(test)

if I'm reading your diagram correctly. Note that for this, you need to
be comparing row 1 from matrix A with row 1 from matrix B - if they are
in some other order, then this won't work.

distance() has a version of Gower's coefficient for mixed that allows
you to specify weights. The function is just about clever enough to
allow missing values if you use method = "mixed" in distance(). Be sure
to read up about Gower's mixed coefficient in his 1971 paper (Gower,
1971, Biometrics 23; 623--637) and the use that weights and the range
parameter Rj are put to, or see the relevant section in Legendre &
Legendre (1998).

> I need for example the diagonal that compares A1 with B1.
> Do you have an idea how I can handle this?
> 
> What is the effect of this code?
> 
> all.equal(diags, diag(as.matrix(dis.bc)))

This was showing you that the diagonals of the dissimilarity matrix are
just a vector of zeroes. all.equal tests equality of its arguments.

> 
> Thanks a lot and sorry for my inability to solve my problems on my own.

You're welcome. Using R is a learning experience. You only need to
grovel and apologise if you have not done your homework before posting
and not read the FAQ, the documentation or searched the archives, or
followed the posting guide. Which is not the case here.

HTH

G

> 
> Am 20.06.2007 um 14:11 schrieb Gavin Simpson:
> 
> > On Wed, 2007-06-20 at 13:26 +0200, Birgit Lemcke wrote:
> >> Hello,
> >>
> >> I am using Mac OS X on a power book and R 2.5.0
> >>
> >> I try to extract a diagonal from a dissimilarity matrix made with
> >> dsvdis, with this code:
> >>
> >> diag(DiTestRR)
> >>
> >> But I get this error message:
> >>
> >> Fehler in array(0, c(n, p)) : 'dim' spezifiziert ein zu groes Array
> >>
> >> english:
> >>
> >> Error in array(0, c(n, p)) : 'dim' specifies a too big array.
> >>
> >> Is there a limit to extract diagonals?
> >
> > The returned object is not a matrix, but an object of class "dist"  
> > which
> > doesn't store the diagonals or the upper triangle of the dissimilarity
> > matrix to save memory. You need to convert the dist object to a matrix
> > first, then extract the diagonal. But, as this shows:
> >
> >> require(labdsv)
> >> ?dsvdis
> >> data(bryceveg)
> >> ?dsvdis
> >> dis.bc <- dsvdis(bryceveg,index="bray/curtis")
> > Warning in symbol.For("dsvdis") : 'symbol.For' is not needed: please
> > remove it
> >> diag(as.matrix(dis.bc))
> >
> > This is meaningless as the diagonals are all zero, as they should be;
> > this is the distance between a site and itself.
> >
> >>
> >> I hope somebody will help me!
> >
> > So perhaps you could explain why you want the diagonal. It would be
> > easier to just do:
> >
> > diags <- rep(0, length = nrow(bryceveg))
> >
> > That will be without the sample labels, but that is easily rectified
> >
> >> names(diags) <- rownames(bryceveg)
> >> all.equal(diags, diag(as.matrix(dis.bc)))
> > [1] TRUE
> >
> > So you'll have to reformulate your question if this is not what you
> > wanted.
> >
> > A word of warning, do not do diag(dis.bc)) on the above as it  
> > brought my
> > Linux box to it's knees trying to do something silly - easily
> > recoverable, but beware.
> >
> > HTH
> >
> > G
> >
> >>
> >> Greetings
> >>
> >> Birgit Lemcke
> >
> > -- 
> > %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> >  Gavin Simpson                 [t] +44 (0)20 7679 0522
> >  ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
> >  Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
> >  Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
> >  UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
> > %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> >
> 
> Birgit Lemcke
> Institut fr Systematische Botanik
> Zollikerstrasse 107
> CH-8008 Zrich
> Switzerland
> Ph: +41 (0)44 634 8351
> birgit.lemcke at systbot.uzh.ch
> 
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Gavin Simpson                 [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From muh167 at psu.edu  Wed Jun 20 18:05:35 2007
From: muh167 at psu.edu (Mahima Hada)
Date: Wed, 20 Jun 2007 12:05:35 -0400
Subject: [R] Multi-variate Probit model using Bayesm
Message-ID: <8b88484c0706200905v5163749dg880c115dbee74776@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070620/f3ce570c/attachment.pl 

From ripley at stats.ox.ac.uk  Wed Jun 20 18:06:28 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 20 Jun 2007 17:06:28 +0100 (BST)
Subject: [R] Creating directory under Windows R session
In-Reply-To: <da79af330706200722g20c60bf9nca5b7372528a1038@mail.gmail.com>
References: <550657.81047.qm@web56605.mail.re3.yahoo.com>
	<da79af330706200722g20c60bf9nca5b7372528a1038@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0706201703330.18527@auk.stats>

On Wed, 20 Jun 2007, Henrique Dallazuanna wrote:

> for check the existence,
>
> any(dir('your path')=="your folder")

That does not work, but fortunately R has file_test() for this purpose.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From wwwhsd at gmail.com  Wed Jun 20 18:16:11 2007
From: wwwhsd at gmail.com (Henrique Dallazuanna)
Date: Wed, 20 Jun 2007 13:16:11 -0300
Subject: [R] Creating directory under Windows R session
In-Reply-To: <Pine.LNX.4.64.0706201703330.18527@auk.stats>
References: <550657.81047.qm@web56605.mail.re3.yahoo.com>
	<da79af330706200722g20c60bf9nca5b7372528a1038@mail.gmail.com>
	<Pine.LNX.4.64.0706201703330.18527@auk.stats>
Message-ID: <da79af330706200916r40b86929gd042bdd9d35fc597@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070620/748913c5/attachment.pl 

From ripley at stats.ox.ac.uk  Wed Jun 20 18:20:46 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 20 Jun 2007 17:20:46 +0100 (BST)
Subject: [R] Creating directory under Windows R session
In-Reply-To: <da79af330706200916r40b86929gd042bdd9d35fc597@mail.gmail.com>
References: <550657.81047.qm@web56605.mail.re3.yahoo.com> 
	<da79af330706200722g20c60bf9nca5b7372528a1038@mail.gmail.com> 
	<Pine.LNX.4.64.0706201703330.18527@auk.stats>
	<da79af330706200916r40b86929gd042bdd9d35fc597@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0706201716100.18527@auk.stats>

On Wed, 20 Jun 2007, Henrique Dallazuanna wrote:

> I have tested in WinXP:
>
> example:
>> dir("C:/")
> [1] "Arquivos de programas"         "AUTOEXEC.BAT"
> [3] "boot.ini"                      "Bootfont.bin"
> [5] "CONFIG.SYS"                    "Debug"
> [7] "debug.log"                     "Desktop.ini"
> [9] "Dic"                           "Documents and Settings"
>
> "Dic" is a folder
> any(dir("C:/")=="Dic")
> [1] TRUE
>
>
> That are right?

You said the test was

       > any(dir('your path')=="your folder")

Now, what did you mean by that?  The path "C:/" is not the path to the 
folder named on the RHS.  And I believe you will find your test also gives 
TRUE for AUTOEXEC.BAT, which is not a directory.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From birgit.lemcke at systbot.uzh.ch  Wed Jun 20 18:24:50 2007
From: birgit.lemcke at systbot.uzh.ch (Birgit Lemcke)
Date: Wed, 20 Jun 2007 18:24:50 +0200
Subject: [R] How to extract diagonals
In-Reply-To: <1182355373.16388.29.camel@gsimpson.geog.ucl.ac.uk>
References: <EEB60A75-0E84-4202-9393-18A3FAEB4230@systbot.uzh.ch>
	<1182341499.16388.10.camel@gsimpson.geog.ucl.ac.uk>
	<32627275-EC9D-46A4-A342-D96FB0946DCB@systbot.uzh.ch>
	<1182355373.16388.29.camel@gsimpson.geog.ucl.ac.uk>
Message-ID: <351D3EDF-F0E4-4C72-B759-CB775B3985E9@systbot.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070620/70820b87/attachment.pl 

From singularitaet at gmx.net  Wed Jun 20 18:30:28 2007
From: singularitaet at gmx.net (Stefan Grosse)
Date: Wed, 20 Jun 2007 18:30:28 +0200
Subject: [R] "xtable" results doesn't correspond to data.frame
In-Reply-To: <BAY110-F170FA848DFCE44E3F8DFE9A3110@phx.gbl>
References: <BAY110-F170FA848DFCE44E3F8DFE9A3110@phx.gbl>
Message-ID: <46795624.7010009@gmx.net>

That table below is not the table from your first mail.

However I would do something like:

library(xtable)
testdata<-data.frame(gender=c(rep("male",3),rep("female",4))
testtab<-as.data.frame(table(testdata))
pct<-function(x){
  x/sum(x)*100
  }
testtab$percent<-pct(testtab$Freq)

rownames(testtab)<-c(1,2)
colnames(testtab)<-c("gender","Freq","%")

#it looks like:

testtab

#and latex:

xtable(testtab,digits=2)

% latex table generated in R 2.5.0 by xtable 1.4-6 package
% Wed Jun 20 18:25:22 2007
\begin{table}[ht]
\begin{center}
\begin{tabular}{rlrr}
  \hline
 & gender & Freq & \% \\
  \hline
1 & female &   3 & 42.86 \\
  2 & male &   4 & 57.14 \\
   \hline
\end{tabular}
\end{center}
\end{table}

I hope this is now how expected.

Cheers
Stefan

-------- Original Message  --------
Subject: Re:[R] "xtable" results doesn't correspond to data.frame
From: Vumani Dlamini <dvumani at hotmail.com>
To: singularitaet at gmx.net
Date: Wed Jun 20 2007 13:22:59 GMT+0200
> This is what is not expected. Having "Gender" repeated twice and the
> labels for gender missing. Will format the digits and align once
> everything is right.
> Thanks.
>
>
> \begin{table}[ht]
> \begin{center}
> \begin{tabular}{llrr}
>  \hline
>  &   & number of patients & \% \\
>  \hline
> Gender & Gender &   &   \\
>    &   & 3 & 0.428571428571429 \\
>    &   & 4 & 0.571428571428571 \\
>   \hline
> \end{tabular}
> \end{center}
> \


From sabya231 at gmail.com  Wed Jun 20 18:42:16 2007
From: sabya231 at gmail.com (Tirthadeep)
Date: Wed, 20 Jun 2007 09:42:16 -0700 (PDT)
Subject: [R] How to draw several ROC curves on a common graph
Message-ID: <11217382.post@talk.nabble.com>


>library(ROCR)

>plot(roc1)
>plot(roc2)

gives two plots on two different graph. Now i want to merge on a single
graph. 

>plot(roc1)
>points(roc2)
   Error in as.vector(x, "double") : cannot coerce to vector

any solution?
-- 
View this message in context: http://www.nabble.com/How-to-draw-several-ROC-curves-on-a-common-graph-tf3953552.html#a11217382
Sent from the R help mailing list archive at Nabble.com.


From gavin.simpson at ucl.ac.uk  Wed Jun 20 18:44:38 2007
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Wed, 20 Jun 2007 17:44:38 +0100
Subject: [R] How to extract diagonals
In-Reply-To: <351D3EDF-F0E4-4C72-B759-CB775B3985E9@systbot.uzh.ch>
References: <EEB60A75-0E84-4202-9393-18A3FAEB4230@systbot.uzh.ch>
	<1182341499.16388.10.camel@gsimpson.geog.ucl.ac.uk>
	<32627275-EC9D-46A4-A342-D96FB0946DCB@systbot.uzh.ch>
	<1182355373.16388.29.camel@gsimpson.geog.ucl.ac.uk>
	<351D3EDF-F0E4-4C72-B759-CB775B3985E9@systbot.uzh.ch>
Message-ID: <1182357878.16388.36.camel@gsimpson.geog.ucl.ac.uk>

On Wed, 2007-06-20 at 18:24 +0200, Birgit Lemcke wrote:
> Hello Gavin!
> 
> 
> I thank you so much that you help me here.
> Only to answer your questions there are 452 samples (species) in A and
> the same number in B.

If your matrices are both 452x452 then distance() is going to take a
while to crunch through the numbers. 24 seconds or there abouts on my
work desktop. distance() (and analogue for that matter) is still very
much in development, and these dissimilarities should really be coded in
C for speed. It is on the todo list but I need to learn some C first...

HTH

G

> Unfortunately I will get the book from Legendre & Legendre only in 2
> days (small library) but I think for the moment I am busy to try and
> learn with the codes you gave me here.
> For me it seems that this will solve all the problems I have at the
> moment.
> Now it is my turn to learn about it.
> 
> 
> Once again: thanks
> 
> 
> Greetings 
> 
> 
> Birgit
> 
> 
> 
> Am 20.06.2007 um 18:02 schrieb Gavin Simpson:
> 
> > On Wed, 2007-06-20 at 15:09 +0200, Birgit Lemcke wrote:
> > > Hello Gavin and thanks for your answer.
> > > 
> > > 
> > > Your completely right I dont need the diagonal that is the
> > > bisecting  
> > > line of the angle.
> > > 
> > > 
> > > I need another diagonal of the (now) matrix.
> > > 
> > > 
> > >          A1 A2 A3 A4 B1 B2 B3 B4
> > >     A1
> > >     A2
> > >     A3
> > >     A4
> > >     B1 X
> > >     B2       X
> > >     B3            X
> > >     B4                 X
> > > 
> > > 
> > 
> > 
> > Not easily, especially without knowing how many samples are in A or
> > B,
> > although all that is really needed is some careful subsetting of the
> > dist object and a minor amount of programming - unfortunately after
> > close to two weeks intensive teaching my brain isn't up to doing
> > that
> > just now.
> > 
> > 
> > One simple way to do this is to use the distance() function in my
> > analogue package (on CRAN). distance() can calculate the
> > dissimilarities
> > between one group of samples and another. Here is a simple example
> > using
> > some dummy data, from ?distance:
> > 
> > 
> >      ## simple example using dummy data
> >      train <- data.frame(matrix(abs(runif(200)), ncol = 10))
> >      rownames(train) <- LETTERS[1:20]
> >      colnames(train) <- as.character(1:10)
> >      fossil <- data.frame(matrix(abs(runif(100)), ncol = 10))
> >      colnames(fossil) <- as.character(1:10)
> >      rownames(fossil) <- letters[1:10]
> > 
> > 
> >      ## calculate distances/dissimilarities between train and fossil
> >      ## samples
> >      test <- distance(train, fossil)
> > 
> > 
> > test is now a matrix, the diagonal elements of which are the values
> > that
> > you appear to want:
> > 
> > 
> >      diag(test)
> > 
> > 
> > if I'm reading your diagram correctly. Note that for this, you need
> > to
> > be comparing row 1 from matrix A with row 1 from matrix B - if they
> > are
> > in some other order, then this won't work.
> > 
> > 
> > distance() has a version of Gower's coefficient for mixed that
> > allows
> > you to specify weights. The function is just about clever enough to
> > allow missing values if you use method = "mixed" in distance(). Be
> > sure
> > to read up about Gower's mixed coefficient in his 1971 paper (Gower,
> > 1971, Biometrics 23; 623--637) and the use that weights and the
> > range
> > parameter Rj are put to, or see the relevant section in Legendre &
> > Legendre (1998).
> > 
> > 
> > > I need for example the diagonal that compares A1 with B1.
> > > Do you have an idea how I can handle this?
> > > 
> > > 
> > > What is the effect of this code?
> > > 
> > > 
> > > all.equal(diags, diag(as.matrix(dis.bc)))
> > 
> > 
> > This was showing you that the diagonals of the dissimilarity matrix
> > are
> > just a vector of zeroes. all.equal tests equality of its arguments.
> > 
> > 
> > > 
> > > 
> > > Thanks a lot and sorry for my inability to solve my problems on my
> > > own.
> > 
> > 
> > You're welcome. Using R is a learning experience. You only need to
> > grovel and apologise if you have not done your homework before
> > posting
> > and not read the FAQ, the documentation or searched the archives, or
> > followed the posting guide. Which is not the case here.
> > 
> > 
> > HTH
> > 
> > 
> > G
> > 
> > 
> > > 
> > > 
> > > Am 20.06.2007 um 14:11 schrieb Gavin Simpson:
> > > 
> > > 
> > > > On Wed, 2007-06-20 at 13:26 +0200, Birgit Lemcke wrote:
> > > > > Hello,
> > > > > 
> > > > > 
> > > > > I am using Mac OS X on a power book and R 2.5.0
> > > > > 
> > > > > 
> > > > > I try to extract a diagonal from a dissimilarity matrix made
> > > > > with
> > > > > dsvdis, with this code:
> > > > > 
> > > > > 
> > > > > diag(DiTestRR)
> > > > > 
> > > > > 
> > > > > But I get this error message:
> > > > > 
> > > > > 
> > > > > Fehler in array(0, c(n, p)) : 'dim' spezifiziert ein zu groes
> > > > > Array
> > > > > 
> > > > > 
> > > > > english:
> > > > > 
> > > > > 
> > > > > Error in array(0, c(n, p)) : 'dim' specifies a too big array.
> > > > > 
> > > > > 
> > > > > Is there a limit to extract diagonals?
> > > > 
> > > > 
> > > > The returned object is not a matrix, but an object of class
> > > > "dist"  
> > > > which
> > > > doesn't store the diagonals or the upper triangle of the
> > > > dissimilarity
> > > > matrix to save memory. You need to convert the dist object to a
> > > > matrix
> > > > first, then extract the diagonal. But, as this shows:
> > > > 
> > > > 
> > > > > require(labdsv)
> > > > > ?dsvdis
> > > > > data(bryceveg)
> > > > > ?dsvdis
> > > > > dis.bc <- dsvdis(bryceveg,index="bray/curtis")
> > > > Warning in symbol.For("dsvdis") : 'symbol.For' is not needed:
> > > > please
> > > > remove it
> > > > > diag(as.matrix(dis.bc))
> > > > 
> > > > 
> > > > This is meaningless as the diagonals are all zero, as they
> > > > should be;
> > > > this is the distance between a site and itself.
> > > > 
> > > > 
> > > > > 
> > > > > 
> > > > > I hope somebody will help me!
> > > > 
> > > > 
> > > > So perhaps you could explain why you want the diagonal. It would
> > > > be
> > > > easier to just do:
> > > > 
> > > > 
> > > > diags <- rep(0, length = nrow(bryceveg))
> > > > 
> > > > 
> > > > That will be without the sample labels, but that is easily
> > > > rectified
> > > > 
> > > > 
> > > > > names(diags) <- rownames(bryceveg)
> > > > > all.equal(diags, diag(as.matrix(dis.bc)))
> > > > [1] TRUE
> > > > 
> > > > 
> > > > So you'll have to reformulate your question if this is not what
> > > > you
> > > > wanted.
> > > > 
> > > > 
> > > > A word of warning, do not do diag(dis.bc)) on the above as it  
> > > > brought my
> > > > Linux box to it's knees trying to do something silly - easily
> > > > recoverable, but beware.
> > > > 
> > > > 
> > > > HTH
> > > > 
> > > > 
> > > > G
> > > > 
> > > > 
> > > > > 
> > > > > 
> > > > > Greetings
> > > > > 
> > > > > 
> > > > > Birgit Lemcke
> > > > 
> > > > 
> > > > -- 
> > > > %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~
> > > > %~%~%
> > > >  Gavin Simpson                 [t] +44 (0)20 7679 0522
> > > >  ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
> > > >  Pearson Building,             [e]
> > > > gavin.simpsonATNOSPAMucl.ac.uk
> > > >  Gower Street, London          [w]
> > > > http://www.ucl.ac.uk/~ucfagls/
> > > >  UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
> > > > %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~
> > > > %~%~%
> > > > 
> > > > 
> > > 
> > > 
> > > Birgit Lemcke
> > > Institut fr Systematische Botanik
> > > Zollikerstrasse 107
> > > CH-8008 Zrich
> > > Switzerland
> > > Ph: +41 (0)44 634 8351
> > > birgit.lemcke at systbot.uzh.ch
> > > 
> > > 
> > > 
> > > 
> > > 
> > > 
> > > 
> > > 
> > > 
> > > 
> > > 
> > > 
> > > [[alternative HTML version deleted]]
> > > 
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > -- 
> > %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~
> > %
> >  Gavin Simpson                 [t] +44 (0)20 7679 0522
> >  ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
> >  Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
> >  Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
> >  UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
> > %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~
> > %
> > 
> > 
> 
> Birgit Lemcke
> Institut f?r Systematische Botanik
> Zollikerstrasse 107
> CH-8008 Z?rich
> Switzerland
> Ph: +41 (0)44 634 8351
> birgit.lemcke at systbot.uzh.ch
>  
> 
> 
> 
> 
> 
> 
> 
> 
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Gavin Simpson                 [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From jrkrideau at yahoo.ca  Wed Jun 20 18:59:23 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Wed, 20 Jun 2007 12:59:23 -0400 (EDT)
Subject: [R] add line to data.frame
In-Reply-To: <200706201104.21311.amicogodzilla@bruttocarattere.org>
Message-ID: <878741.13785.qm@web32802.mail.mud.yahoo.com>


--- Manuele Pesenti
<amicogodzilla at bruttocarattere.org> wrote:

> Dear R user,
> 
> how can I update a data.frame adding new lines?

?rbind

> I need to create a second data frame from a first
> one with only some of their 
> entrys filtering the value of a specific column...
> How can I do this?

?subset 
> 
> thankyou very much in advance
> best regards
> 	Manuele PEsenti
> 
> -- 
> Manuele Pesenti
> 	manuele at inventati.org
> 	amicogodzilla at jabber.linux.it
> 	http://mpesenti.polito.it
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From dan.oshea at dnr.state.mn.us  Wed Jun 20 19:02:03 2007
From: dan.oshea at dnr.state.mn.us (Daniel O'Shea)
Date: Wed, 20 Jun 2007 12:02:03 -0500
Subject: [R] nlme correlated random effects
Message-ID: <46791737.537F.005A.0@dnr.state.mn.us>

I am examining the following nlme model.

asymporig<-function(x,th1,th2)th1*(1-exp(-exp(th2)*x))
mod1<-nlme(fa20~(ah*habdiv+ad*log(d)+ads*ds+ads2*ds2+at*trout)+asymporig(da.p,th1,th2),
    fixed=ah+ad+ads+ads2+at+th1+th2~1,
    random=th1+th2~1,
    start=c(ah=.9124,ad=.9252,ads=.5,ads2=-.1,at=-1,th1=2.842,th2=-6.917),
    data=pca1.grouped)

However, the two random effects (th1 and th2) which describe the asymptotic relationship between richness (fa20) and area (da.p) are correlated: -0.904 with approximate 95% ci of -0.99 to -.32.
I examined the anova of mod1 with both random effects and mod2 with just th1 and mod1 is preferred.  I also examined pdDiag(th1 + th2~1) for another model (mod3) and based on the anova the original mod1 is preferred.

My question is can I use pdBlocked with only 2 random effects or should I and if so how I would specify that in the model or perhaps the 95% ci for correlation is wide enough to ignore???

Dan


From snunes at gmail.com  Wed Jun 20 19:03:54 2007
From: snunes at gmail.com (=?ISO-8859-1?Q?S=E9rgio_Nunes?=)
Date: Wed, 20 Jun 2007 18:03:54 +0100
Subject: [R] Averaging dates?
Message-ID: <4c817d530706201003s3723fa3fh2ef8eb47b2c54843@mail.gmail.com>

Hi,

What's the best way to average dates?
I though mean.POISXct would work fine but...

> a
[1] "2007-04-02 19:22:00 WEST"
> b
[1] "2007-03-17 16:23:00 WET"
> class(a)
[1] "POSIXt"  "POSIXct"
> class(b)
[1] "POSIXt"  "POSIXct"
> mean(a,b)
[1] "2007-04-02 19:22:00 WEST"
> mean(b,a)
[1] "2007-03-17 16:23:00 WET"

?!

Thanks in advance for any advice,
--
S?rgio Nunes


From Bill.Shipley at USherbrooke.ca  Wed Jun 20 19:37:22 2007
From: Bill.Shipley at USherbrooke.ca (Bill Shipley)
Date: Wed, 20 Jun 2007 13:37:22 -0400
Subject: [R] finding roots of multivariate equation
Message-ID: <1182361042.467965d24abac@www.usherbrooke.ca>

Hello,
I want to find the roots of an equation in two variables.  I am aware of the
uniroot function, which can do this for a function with a single variable (as I
understand it...) but cannot find a function that does this for an equation
with more than one variable.  I am looking for something implementing similar
to a Newton-Raphson algorithm.
Thanks.

-- 
Bill Shipley
North American Editor for Annals of Botany
Subject Editor for Ecology
D?partement de biologie
Universit? de Sherbrooke
Sherbrooke (Qu?bec) J1K 2R9
Canada


From rvaradhan at jhmi.edu  Wed Jun 20 19:56:40 2007
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Wed, 20 Jun 2007 13:56:40 -0400
Subject: [R] finding roots of multivariate equation
In-Reply-To: <1182361042.467965d24abac@www.usherbrooke.ca>
References: <1182361042.467965d24abac@www.usherbrooke.ca>
Message-ID: <000101c7b364$5a8f7100$7c94100a@win.ad.jhu.edu>

R does not really have a dedicated solver for nonlinear systems of
equations, but instead you can use optim(), which is a minimizer.  Suppose
your system is F(x) = 0, where x \in R^p and F is a mapping from R^p to R^p,
then you minimize the norm of F.  The problem with this approach is that it
can sometimes yield local minima which are not the zeros of the original
system.  However, this can be easily remedied by using different starting
values.

Ravi.

----------------------------------------------------------------------------
-------

Ravi Varadhan, Ph.D.

Assistant Professor, The Center on Aging and Health

Division of Geriatric Medicine and Gerontology 

Johns Hopkins University

Ph: (410) 502-2619

Fax: (410) 614-9625

Email: rvaradhan at jhmi.edu

Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html

 

----------------------------------------------------------------------------
--------


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Bill Shipley
Sent: Wednesday, June 20, 2007 1:37 PM
To: r-help at stat.math.ethz.ch
Subject: [R] finding roots of multivariate equation

Hello,
I want to find the roots of an equation in two variables.  I am aware of the
uniroot function, which can do this for a function with a single variable
(as I
understand it...) but cannot find a function that does this for an equation
with more than one variable.  I am looking for something implementing
similar
to a Newton-Raphson algorithm.
Thanks.

-- 
Bill Shipley
North American Editor for Annals of Botany
Subject Editor for Ecology
D?partement de biologie
Universit? de Sherbrooke
Sherbrooke (Qu?bec) J1K 2R9
Canada

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Achim.Zeileis at wu-wien.ac.at  Wed Jun 20 20:01:09 2007
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Wed, 20 Jun 2007 20:01:09 +0200 (CEST)
Subject: [R] Averaging dates?
In-Reply-To: <4c817d530706201003s3723fa3fh2ef8eb47b2c54843@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.0706201959460.4019-100000@disco.wu-wien.ac.at>

On Wed, 20 Jun 2007, S?rgio Nunes wrote:

> Hi,
>
> What's the best way to average dates?
> I though mean.POISXct would work fine but...
>
> > a
> [1] "2007-04-02 19:22:00 WEST"
> > b
> [1] "2007-03-17 16:23:00 WET"
> > class(a)
> [1] "POSIXt"  "POSIXct"
> > class(b)
> [1] "POSIXt"  "POSIXct"
> > mean(a,b)
> [1] "2007-04-02 19:22:00 WEST"
> > mean(b,a)
> [1] "2007-03-17 16:23:00 WET"

Would you usually call mean() in this way?
  mean(1, 2)
  mean(2, 1)

Probably not...

mean() expects a vector, try mean(c(a, b))!
Z

> ?!
>
> Thanks in advance for any advice,
> --
> S?rgio Nunes
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


From Greg.Snow at intermountainmail.org  Wed Jun 20 20:08:11 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Wed, 20 Jun 2007 12:08:11 -0600
Subject: [R] axis labels in multiple plots
References: <4677E8C9.27334.1665A67@hvillalo.ipn.mx>
Message-ID: <07E228A5BE53C24CAD490193A7381BBB12A150@LP-EXCHVS07.CO.IHC.COM>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070620/63d99f81/attachment.pl 

From rosem at ats.ucla.edu  Wed Jun 20 20:37:17 2007
From: rosem at ats.ucla.edu (Medeiros, Rose)
Date: Wed, 20 Jun 2007 11:37:17 -0700
Subject: [R] Testing parallel regression assumption
Message-ID: <43F64E86355A744E9D51506B6C6783B901B90735@EM2.ad.ucla.edu>

I would like to test the parallel regression assumption for an ordered
logistic regression model using either a score/LM test, or preferably, a
Wald/Brant test. I have been unable to find an R function (either in the
base or in a package available on cran) that performs either of these
tests. Does one exist that I am overlooking or is there code available
elsewhere to do this?
 
As background, I am using vglm( ) from the library VGAM to fit the
model. I'm estimating the model with code that looks roughly like this: 
vglm(y~x1+x2+x3, data=mydata, family=cumulative(link = "logit", parallel
= T, reverse = T))

Thank you,
Rose
 
 

______________________________________

Rose Anne Medeiros

Statistical Consulting Group

UCLA Academic Technology Services

http://www.ats.ucla.edu/stat/


From ywang at med.wayne.edu  Wed Jun 20 20:40:36 2007
From: ywang at med.wayne.edu (Wang, Yun)
Date: Wed, 20 Jun 2007 14:40:36 -0400
Subject: [R] How to use "mix" to estimate the parameters for mixture gamma
 distribution?
Message-ID: <682B2B8F328A234CAEF60C4CB7D58AEA02473E48@MED-CORE03-MS3.med.wayne.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070620/05c3f5e8/attachment.pl 

From dieter.menne at menne-biomed.de  Wed Jun 20 20:19:39 2007
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Wed, 20 Jun 2007 18:19:39 +0000 (UTC)
Subject: [R] How to draw several ROC curves on a common graph
References: <11217382.post@talk.nabble.com>
Message-ID: <loom.20070620T201844-872@post.gmane.org>

Tirthadeep <sabya231 <at> gmail.com> writes:

> >library(ROCR)
> 
> >plot(roc1)
> >plot(roc2)
> 
> gives two plots on two different graph. Now i want to merge on a single
> graph. 
> 
> >plot(roc1)
> >points(roc2)


Use parameter add=TRUE in all but the first call

Dieter


From thomas.pujol at yahoo.com  Wed Jun 20 20:58:08 2007
From: thomas.pujol at yahoo.com (Thomas Pujol)
Date: Wed, 20 Jun 2007 11:58:08 -0700 (PDT)
Subject: [R] shoudl I use apply, sapply, etc instead of a "for loop"?
Message-ID: <127497.81590.qm@web59307.mail.re1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070620/1473f9e3/attachment.pl 

From hvillalo at ipn.mx  Wed Jun 20 21:04:31 2007
From: hvillalo at ipn.mx (=?ISO-8859-1?Q?H=E9ctor_Villalobos?=)
Date: Wed, 20 Jun 2007 13:04:31 -0600
Subject: [R] axis labels in multiple plots
In-Reply-To: <07E228A5BE53C24CAD490193A7381BBB12A150@LP-EXCHVS07.CO.IHC.COM>
References: <4677E8C9.27334.1665A67@hvillalo.ipn.mx>,
	<07E228A5BE53C24CAD490193A7381BBB12A150@LP-EXCHVS07.CO.IHC.COM>
Message-ID: <467925DF.8139.1057D29@hvillalo.ipn.mx>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070620/6849964c/attachment.pl 

From mark_difford at yahoo.co.uk  Wed Jun 20 21:49:00 2007
From: mark_difford at yahoo.co.uk (Mark Difford)
Date: Wed, 20 Jun 2007 12:49:00 -0700 (PDT)
Subject: [R] Dissimilarity
In-Reply-To: <1182354377.16388.14.camel@gsimpson.geog.ucl.ac.uk>
References: <0B85CE3E-78E8-4DC5-8484-CBB687E61545@systbot.uzh.ch>
	<1182354377.16388.14.camel@gsimpson.geog.ucl.ac.uk>
Message-ID: <11220912.post@talk.nabble.com>


Hi Birgit,

Just to add to what Gavin has said.  There are two other very powerful
packages in R that handle this kind of thing: ade4 and vegan.  Have a
thorough look at both of them.  You should be looking at Principal
Coordinate Analysis (Classical Scaling) and Non Metric Multidimensional
Scaling (NMDS)---with, as Gavin has said, your species as rows.  At least
the first of these methods goes hand-in-glove with cluster analysis.

Given that you are based in Switzerland, and perhaps are Swiss, you probably
therefore read and speak French as a second/third language.  You may
therefore find the ade4 package more useful, since its authors are French,
and its principal authors, Prof. Daniel Chessel &c., have made publicly
available some exceptionally useful documentation on these methods on their
ade4 website.  These are mainly Prof. Chessel's lecture notes:

http://pbil.univ-lyon1.fr/R/enseignement.html

I hope that speeds you on your way.

Regards,
Mark.

PS: Apropos of the Legendre & Legendre text: It's well worth buying if you
work in this area; one of its authors, Pierre Legendre, now collaborates
with Jari Oksanen on some functions of the vegan package.


Gavin Simpson wrote:
> 
> On Wed, 2007-06-20 at 16:13 +0200, Birgit Lemcke wrote:
>> Hello Stephen,
>> 
>> I am happy that you help me. Thanks a million.
>> 
>> It is a good feeling that you confirm my assumption that dsvdis is  
>> not able to deal with missing data, because it says me that I am not  
>> completely incapable.
>> Okay now I have the problem what to do.
>> I used this function cause there is an option to weight columns  
>> differently what I havent found in other functions.
>> 
>> But now I dont understand why I have to transpose the species as  
>> columns? As I read in the help manual of dsvdis this function  
>> calculates dissimilarities between rows.
>> I have to calculate the dissimilarities between species that are in  
>> rows by the use of morphological characters that are in columns.
> 
> If you really what to measure the associations between species then
> leave them as you had them as the rows. But make sure you are choosing a
> dissimilarity coefficient that works well for species associations.
> There is a whole section in Legendre and Legendre 1998 Numerical Ecology
> 2nd English Edition Elsevier which may help here.
> 
> HTH
> 
> G
> 
>> 
>> Am I completely wrong with my thoughts?
>> 
>> Birgit
>> 
>> Am 20.06.2007 um 15:52 schrieb Stephen B. Cox:
>> 
>> > Hi Birgit - looks like you have a few issues here.
>> >
>> > Birgit Lemcke <birgit.lemcke <at> systbot.uzh.ch> writes:
>> >
>> >>
>> >> Hello you all!
>> >>
>> >> I am a completely new user of R and I have a problem to solve.
>> >> I am using Mac OS X on a PowerBook.
>> >>
>> >> I have a table that looks like this:
>> >>
>> >>             species X1 X2 X3 X4 X5 X6 X7 X8 X9 X10 X11 X12 X13 X14
>> >> X15 X16 X17 X18 X19 X20 X21
>> >> 1        Anth_cap1  1  0  0  1  0  1  0  0  1   0   0   0   0   0
>> >> 0   0   1   0   0   0   1
>> >> 2       Anth_crin1  1  0  0  1  0  1  0  0  1   0   1   0   0   0
>> >> 0   0   0   1   0   0   1
>> >> 3        Anth_eck1  1  0  0  1  0  1  0  0  1   0   0   0   0   0
>> >> 0   0   0   1   0   0   1
>> >> 4       Anth_gram1  1  0  0  1  0  1  0  0  1  NA  NA  NA  NA   0
>> >> 0   0   0   1   0   0   0
>> >> 5       Anth_insi1  1  0  0  1  0  1  0  0  1   0   0   0   1   0
>> >> 0   0   0   1   0   0   1
>> >>
>> >> All columns  are binary coded characters.
>> >> The Import was done by this
>> >>
>> >> Test<-read.table("TestRFemMalBivariat1.csv",header = TRUE, sep = ";")
>> >
>> > First - you need to transpose the matrix to have species as  
>> > columns.  You can do
>> > this with:
>> >
>> > d2 = data.frame(t(Test[,-1]))
>> > colnames(d2) = Test[,1]  #now use d2
>> >
>> >
>> >
>> >> Now I try to perform a similarity analysis with the dsvdis function
>> >> of the labdsv package with the sorensen-Index.
>> >>
>> >> My first question is if all zeros in my table are seen as missing
>> >> values and if it islike that how can I change without turning zero
>> >> into other numbers?
>> >
>> > no - the zeros are valid observations.  the na's are missing data.
>> >
>> >
>> >>   DisTest<-dsvdis(Test, index = "sorensen")
>> >>
>> >> But I always get back this error message:
>> >>
>> >> Warnung in symbol.For("dsvdis") :'symbol.For' is not needed: please
>> >> remove it
>> >> Fehler in dsvdis(Test, index = "sorensen") :
>> >> 	NA/NaN/Inf in externem Funktionsaufruf (arg 1)
>> >> Zustzlich: Warning message:
>> >> NAs durch Umwandlung erzeugt
>> >
>> >
>> >
>> > Second - you have an issue with missing data.  It looks like dsvdis  
>> > does not
>> > like the NA's - so you must make a decision about what to do.   
>> > Delete that
>> > species, delete that site, or whatever...
>> >
>> > Finally - the warning over symbol.For is an issue with the labdsv  
>> > library itself
>> > - nothing you are doing wrong.  The results will still be valid -  
>> > but the use of
>> > symbol.For is something that will eventually need to be changed in  
>> > the labdsv
>> > library.
>> >
>> > hth,
>> >
>> > stephen
>> 
>> Birgit Lemcke
>> Institut fr Systematische Botanik
>> Zollikerstrasse 107
>> CH-8008 Zrich
>> Switzerland
>> Ph: +41 (0)44 634 8351
>> birgit.lemcke at systbot.uzh.ch
>> 
>> 
>> 
>> 
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> -- 
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
>  Gavin Simpson                 [t] +44 (0)20 7679 0522
>  ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
>  Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
>  Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
>  UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/Re%3A-Dissimilarity-tf3952667.html#a11220912
Sent from the R help mailing list archive at Nabble.com.


From szhan at uoguelph.ca  Wed Jun 20 21:57:21 2007
From: szhan at uoguelph.ca (szhan at uoguelph.ca)
Date: Wed, 20 Jun 2007 15:57:21 -0400
Subject: [R] how to calculate estimate of interation contrast in
	two-factor	experiment
Message-ID: <20070620155721.w7rt3eed4w84soco@webmail.uoguelph.ca>

Hello, R experts,
I have a two-factor experiment data and like to calculate estimates of  
interation contrasts say factor A has levels of a1, a2, and B has  
levels of b1, b2, b3, b4, and b5 with 3 replicates. I am not sure the  
constrast estimate I got is right using the script below:

score<-c(7.2,6.5,6.9,6.4,6.9,6.1,6.9,5.3,7.2,5.7,5.1,5.9,7.6,6.9,6.8,
7.2,6.6,6.9,6.4,6.0,6.0,6.9,6.9,6.4,7.5,7.7,7.0,8.6,8.8,8.3)

A <- gl(2, 15, labels=c("a1", "a2"))
B <- rep(gl(5, 3, labels=c("b1", "b2", "b3", "b4", "b5")), 2)

contrasts(B)<-cbind(c(-4,rep(1,4)),c(rep(-3,2),rep(2,3)),
+  c(rep(-2,3),rep(3,2)),c(rep(-1,4), rep(4,1)))
fit1 <- aov(score ~ A*B)
summary(fit1, split=list(B=1:4), expand.split = TRUE)
             Df Sum Sq Mean Sq F value    Pr(>F)
A            1 3.2013  3.2013 15.1483 0.0009054 ***
B            4 8.7780  2.1945 10.3841 0.0001019 ***
   B: C1      1 0.0301  0.0301  0.1424 0.7099296
   B: C2      1 2.0335  2.0335  9.6221 0.0056199 **
   B: C3      1 1.2469  1.2469  5.9004 0.0246876 *
   B: C4      1 5.4675  5.4675 25.8715 5.637e-05 ***
A:B          4 5.3420  1.3355  6.3194 0.0018616 **
   A:B: C1    1 0.7207  0.7207  3.4105 0.0796342 .
   A:B: C2    1 2.6068  2.6068 12.3350 0.0021927 **
   A:B: C3    1 1.9136  1.9136  9.0549 0.0069317 **
   A:B: C4    1 0.1008  0.1008  0.4771 0.4976647
Residuals   20 4.2267  0.2113
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Now I like to get interaction contrast estimate for b1 and b2 vs b3, b4 and b5
cont <- c(1, -1)[A] * c(-3, -3, 2, 2, 2)[B]

estimat<-sum(cont*score) # value of the contrast estimate for A:B C2

> estimat
[1] -24.1

I am not sure the estimate for A:B C2 contrast  (-24.1) is correct  
because the F value given the output above(12.3350) does not equal to  
those I calculate below (15.2684):

t.stat <- sum(cont*score)/se.contrast(fit1, as.matrix(cont))
> t.stat^2
Contrast 1
   15.2684

Could you please help me calculate the correct the estimate of  
interaction contrast and corresponding F value?
Thanks in advance!
Joshua


From borreguero at gmail.com  Wed Jun 20 22:02:23 2007
From: borreguero at gmail.com (Jose Borreguero)
Date: Wed, 20 Jun 2007 16:02:23 -0400
Subject: [R] how to create cumulative histogram from two independent
	variables?
Message-ID: <7cced4ed0706201302y3df7a375hbcf775b58a0cb2bc@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070620/7cd2ce11/attachment.pl 

From bolker at ufl.edu  Wed Jun 20 22:12:09 2007
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 20 Jun 2007 20:12:09 +0000 (UTC)
Subject: [R] How to use "mix" to estimate the parameters for mixture
	gamma distribution?
References: <682B2B8F328A234CAEF60C4CB7D58AEA02473E48@MED-CORE03-MS3.med.wayne.edu>
Message-ID: <loom.20070620T220234-503@post.gmane.org>

Wang, Yun <ywang <at> med.wayne.edu> writes:

> 
> 
> Dear R users,
> 
> Please help me on using "mix" function under package "mixdist".
> 
> My data distribution shows there are two components for the mixture
distribution: left part is an
> exponential and right part is a normal. So I plan to use "gamma" mixture
distribution to estimate the
> parameters. Here is what I am using for the "mix" function.
> 
> Test<-mix(x, mixparam(mu=c(1,125),sigma=c(1,11.18)),"gamma") 
> 
> However, one error message shows up as:
> "Error in nlm(function(x) f(x, ...), p, hessian, typsize, fscale, msg,  :
missing value in parameter"
> 
> Does anybody know what that means and how to fix it to get the estimation?
Your help will be much appreciated.
> 
> Yun
> 

  You haven't given us enough to go on.  First of all,
mixdist is a contributed package -- not part of base R, and
not even on CRAN (but not too hard to find:
http://www.math.mcmaster.ca/peter/mix/mix.html ).  You might
consider asking the author/maintainer: see help(package="mixdist").

Second, please do as the posting guide suggests and give us
a simple, reproducible example.  If your data are small enough,
you can just post them, or post them to a web site and send
the URL -- or make up a small data set that also displays the
problem (you will often discover the answer for yourself in the
process of doing this!)

  Staring at the C code for nlm (in src/main/optimize.c) suggests
that nlm is being passed an NA in a parameter set somewhere -- you
might try options(error=recover) to start diagnosing, or change
print.level in your mix() call.

  But your best bet is to find a reproducible example for
us to look at.

  cheers
    Ben Bolker


From mike.prager at noaa.gov  Wed Jun 20 22:21:18 2007
From: mike.prager at noaa.gov (Mike Prager)
Date: Wed, 20 Jun 2007 16:21:18 -0400
Subject: [R] Speed up R
References: <Pine.LNX.4.64.0706192216270.12443@gannet.stats.ox.ac.uk>
	<!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAfHU8PP2E50qGgSIBTaVydsKAAAAQAAAA9ZipM0jYbkSnDRXmTyd7zgEAAAAA@o2.pl>
	<3f547caa0706200716t493e63adq22214914dbf92f74@mail.gmail.com>
Message-ID: <882j739u87c61h6hv6e5uneitfp84kemck@4ax.com>

"Matthew Keller" <mckellercran at gmail.com> wrote:

> Robert,
... 
> As for Mike Prager's point about the type of hard drive being
> important, I'm not sure this is right (someone correct me if I'm
> misunderstanding). R stores and accesses objects through RAM - they
> aren't stored and accessed on the hard drive except when reading and
> writing. So hard drive type probably won't make much difference to
> speed in R.

In my experience, it makes a substantial difference if any
swapping to disk is going on. That will happen if, e.g., other
processes or Windows itself need RAM. Though R keeps the data in
RAM, under Windows, non-SCSI disk I/O puts a noticeable load on
the CPU. As SCSI controllers have CPUs of their own, they
offload much of that work from the system CPU.

I have compared dual-processor computers with equal RAM, one
with a SCSI subsystem and one with fast (7200 RPM) ATA disks and
slightly faster CPUs.  One was my work machine, one my home. The
difference was not subtle.  For another example, think of how
slow laptops seem when multitasking, compared to a good
workstation. It is usually the poor disk subsystem that's the
bottleneck, not the CPU.

Mike

-- 
Mike Prager, NOAA, Beaufort, NC
* Opinions expressed are personal and not represented otherwise.
* Any use of tradenames does not constitute a NOAA endorsement.


From mckellercran at gmail.com  Wed Jun 20 22:39:44 2007
From: mckellercran at gmail.com (Matthew Keller)
Date: Wed, 20 Jun 2007 16:39:44 -0400
Subject: [R] Speed up R
In-Reply-To: <882j739u87c61h6hv6e5uneitfp84kemck@4ax.com>
References: <Pine.LNX.4.64.0706192216270.12443@gannet.stats.ox.ac.uk>
	<!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAfHU8PP2E50qGgSIBTaVydsKAAAAQAAAA9ZipM0jYbkSnDRXmTyd7zgEAAAAA@o2.pl>
	<3f547caa0706200716t493e63adq22214914dbf92f74@mail.gmail.com>
	<882j739u87c61h6hv6e5uneitfp84kemck@4ax.com>
Message-ID: <3f547caa0706201339i3081f71y3ec682ea88dbfe8@mail.gmail.com>

So Mike, let me ask you a question. If R runs out of RAM, does it
begin to use virtual RAM, and hence begin to swap from the hard drive?
If so, I could see how a faster hard drive would speed R up when you
don't have enough RAM...



On 6/20/07, Mike Prager <mike.prager at noaa.gov> wrote:
> "Matthew Keller" <mckellercran at gmail.com> wrote:
>
> > Robert,
> ...
> > As for Mike Prager's point about the type of hard drive being
> > important, I'm not sure this is right (someone correct me if I'm
> > misunderstanding). R stores and accesses objects through RAM - they
> > aren't stored and accessed on the hard drive except when reading and
> > writing. So hard drive type probably won't make much difference to
> > speed in R.
>
> In my experience, it makes a substantial difference if any
> swapping to disk is going on. That will happen if, e.g., other
> processes or Windows itself need RAM. Though R keeps the data in
> RAM, under Windows, non-SCSI disk I/O puts a noticeable load on
> the CPU. As SCSI controllers have CPUs of their own, they
> offload much of that work from the system CPU.
>
> I have compared dual-processor computers with equal RAM, one
> with a SCSI subsystem and one with fast (7200 RPM) ATA disks and
> slightly faster CPUs.  One was my work machine, one my home. The
> difference was not subtle.  For another example, think of how
> slow laptops seem when multitasking, compared to a good
> workstation. It is usually the poor disk subsystem that's the
> bottleneck, not the CPU.
>
> Mike
>
> --
> Mike Prager, NOAA, Beaufort, NC
> * Opinions expressed are personal and not represented otherwise.
> * Any use of tradenames does not constitute a NOAA endorsement.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Matthew C Keller
Postdoctoral Fellow
Virginia Institute for Psychiatric and Behavioral Genetics


From wangdeli at gmail.com  Wed Jun 20 22:50:02 2007
From: wangdeli at gmail.com (Deli Wang)
Date: Wed, 20 Jun 2007 15:50:02 -0500
Subject: [R] How to create .rda file to be used in package building
Message-ID: <626c66f20706201350v3f61f433ted4b33f721cd5893@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070620/83a32aae/attachment.pl 

From David.Howell at uvm.edu  Wed Jun 20 23:14:02 2007
From: David.Howell at uvm.edu (David C. Howell)
Date: Wed, 20 Jun 2007 15:14:02 -0600
Subject: [R] Extracting t-tests on coefficients in lm
Message-ID: <4679989A.40403@uvm.edu>

I am writing a resampling program for multiple regression using lm(). I 
resample the data 10,000 times, each time extracting the regression 
coefficients. At present I extract the individual regression 
coefficients using

  brg = lm(Newdv~Teach + Exam + Knowledge + Grade + Enroll)
  bcoef[i,] = brg$coef

This works fine.

But now I want to extract the t tests on these coefficients. I cannot 
find how these coefficients are stored, if at all. When I try
    attributes(brg)
I do not find the t values as the attributes of the object. Typing 
summary(brg) will PRINT the coefficients, their standard errors, t, and 
the associated probability. I would like to type something like
    tcoeff[i,] = brg$tvalue
but, of course, tvalue doesn't exist.

Is there a simple way to extract, or compute if necessary, these values?

Thanks,
Dave Howell



-- 
David C. Howell
PO Box 770059
627 Meadowbrook Circle
Steamboat Springs, CO
80477


From rvaradhan at jhmi.edu  Wed Jun 20 23:22:59 2007
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Wed, 20 Jun 2007 17:22:59 -0400
Subject: [R] Creatiing an R package for solving nonlinear system of
	equations was: RE: finding roots of multivariate equation
In-Reply-To: <1182361042.467965d24abac@www.usherbrooke.ca>
References: <1182361042.467965d24abac@www.usherbrooke.ca>
Message-ID: <001501c7b381$2d5b4de0$7c94100a@win.ad.jhu.edu>

Hi All,

Replying to this and numerous other requests in the past has made me realize
that a nonlinear solver is very much needed for R users.  I have
successfully used a nonlinear solver based on the spectral gradient method,
in FORTRAN.  I can readily translate that to R and make it available as an R
function, but what I would really like to do is to make that into a package.
I can provide the R function and several test examples.  But I am not good
at creating a good/reliable package.  So, it would be ideal if one of the R
gurus is interested in collaborating with me on this project.  Any one
interested?

Ravi.
----------------------------------------------------------------------------
-------

Ravi Varadhan, Ph.D.

Assistant Professor, The Center on Aging and Health

Division of Geriatric Medicine and Gerontology 

Johns Hopkins University

Ph: (410) 502-2619

Fax: (410) 614-9625

Email: rvaradhan at jhmi.edu

Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html

 

----------------------------------------------------------------------------
--------

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Bill Shipley
Sent: Wednesday, June 20, 2007 1:37 PM
To: r-help at stat.math.ethz.ch
Subject: [R] finding roots of multivariate equation

Hello,
I want to find the roots of an equation in two variables.  I am aware of the
uniroot function, which can do this for a function with a single variable
(as I
understand it...) but cannot find a function that does this for an equation
with more than one variable.  I am looking for something implementing
similar
to a Newton-Raphson algorithm.
Thanks.

-- 
Bill Shipley
North American Editor for Annals of Botany
Subject Editor for Ecology
D?partement de biologie
Universit? de Sherbrooke
Sherbrooke (Qu?bec) J1K 2R9
Canada

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Wed Jun 20 23:25:03 2007
From: jholtman at gmail.com (jim holtman)
Date: Wed, 20 Jun 2007 17:25:03 -0400
Subject: [R] Averaging dates?
In-Reply-To: <4c817d530706201003s3723fa3fh2ef8eb47b2c54843@mail.gmail.com>
References: <4c817d530706201003s3723fa3fh2ef8eb47b2c54843@mail.gmail.com>
Message-ID: <644e1f320706201425s7e1b2ce6r487fe84521e5f1f0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070620/7ce1dfd8/attachment.pl 

From deepayan.sarkar at gmail.com  Wed Jun 20 23:31:49 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Wed, 20 Jun 2007 14:31:49 -0700
Subject: [R] Retrieve part of (top right corner) of a "plot.data.frame"
	plot?
In-Reply-To: <712798410706200220m39986a79wb6049cca852b56fd@mail.gmail.com>
References: <712798410706200220m39986a79wb6049cca852b56fd@mail.gmail.com>
Message-ID: <eb555e660706201431i762a646ds6f23f9cc2484bd4c@mail.gmail.com>

On 6/20/07, Dan Bolser <dan.bolser.r at googlemail.com> wrote:
> Hi,
>
> I believe this question has been asked before, but I cant find and don't
> remember the answer.
>
> The problem is simple, calling 'plot.data.frame(x)' gives a nice 'matrix of
> scatterplots' for each pair of columns in x. for example;
>
> x <-
>   data.frame(a=jitter(01:20),
>              b=jitter(20:01),
>              c=jitter(21:40),
>              d=jitter(rep(01,20)),
>              e=jitter(rep(10,20)),
>              f=jitter(rep(20,20))
>              )
>
> plot(x)
>
> gives a 6 by 6 grid of scatter plots, two (upper right and lower left) for
> each pair of columns in x. (I am going over these basics so that you can
> understand what I mean next).
>
> I would like to see just part of the above result, namely the nine plots in
> the top right of the given plot, or;
>
> a vs. d | a vs. e | a vs. f
> b vs. d | b vs. e | b vs. f
> c vs. d | c vs. e | c vs. f
>
> I tried a number of ways to do this, but I can't find either the right
> formula or the right function to get what I want.
>
> Any suggestions you can give (especially any not involving the source code
> of 'pairs') are most welcome.

Lattice gets you close:

xyplot(a + b + c ~ d + e + f, data = x, outer = TRUE,
       scales = "free", layout = c(3, 3), aspect = 1)

The rest may or may not be simple, depending on what you want exactly.

-Deepayan


From Jacqueline.Spilak at EC.gc.ca  Thu Jun 21 00:12:40 2007
From: Jacqueline.Spilak at EC.gc.ca (Spilak,Jacqueline [Edm])
Date: Wed, 20 Jun 2007 16:12:40 -0600
Subject: [R] Replace number with month
Message-ID: <4A6AB38B55B49C44A22E021A83CBEDDB015EB982@sr-pnr-exch3.prairie.int.ec.gc.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070620/e2bee106/attachment.pl 

From ccleland at optonline.net  Thu Jun 21 00:28:03 2007
From: ccleland at optonline.net (Chuck Cleland)
Date: Wed, 20 Jun 2007 18:28:03 -0400
Subject: [R] Extracting t-tests on coefficients in lm
In-Reply-To: <4679989A.40403@uvm.edu>
References: <4679989A.40403@uvm.edu>
Message-ID: <4679A9F3.1060500@optonline.net>

David C. Howell wrote:
> I am writing a resampling program for multiple regression using lm(). I 
> resample the data 10,000 times, each time extracting the regression 
> coefficients. At present I extract the individual regression 
> coefficients using
> 
>   brg = lm(Newdv~Teach + Exam + Knowledge + Grade + Enroll)
>   bcoef[i,] = brg$coef
> 
> This works fine.
> 
> But now I want to extract the t tests on these coefficients. I cannot 
> find how these coefficients are stored, if at all. When I try
>     attributes(brg)
> I do not find the t values as the attributes of the object. Typing 
> summary(brg) will PRINT the coefficients, their standard errors, t, and 
> the associated probability. I would like to type something like
>     tcoeff[i,] = brg$tvalue
> but, of course, tvalue doesn't exist.
> 
> Is there a simple way to extract, or compute if necessary, these values?

summary(brg)$coefficients[,3]

str(summary(brg)) is sometimes helpful for figuring out how to extract
something.

  Also, you might have a look at John Fox's document on bootstraping
regression models if you don't already know about it:

http://cran.r-project.org/doc/contrib/Fox-Companion/appendix-bootstrapping.pdf

> Thanks,
> Dave Howell 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From NordlDJ at dshs.wa.gov  Thu Jun 21 00:33:39 2007
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Wed, 20 Jun 2007 15:33:39 -0700
Subject: [R] Replace number with month
In-Reply-To: <4A6AB38B55B49C44A22E021A83CBEDDB015EB982@sr-pnr-exch3.prairie.int.ec.gc.ca>
References: <4A6AB38B55B49C44A22E021A83CBEDDB015EB982@sr-pnr-exch3.prairie.int.ec.gc.ca>
Message-ID: <941871A13165C2418EC144ACB212BDB04E1312@dshsmxoly1504g.dshs.wa.lcl>

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Spilak,Jacqueline [Edm]
> Sent: Wednesday, June 20, 2007 3:13 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Replace number with month
> 
> Hi all
> I have a multiple datasets that look like this
> 
> MM  Freq
>  1      30
>   2     35
>   3     54
>   4     33
>   5     27
>   6     13
>   7     25
>   8     29
>   9     40
>   10   32
>   11   36
>   12   23
> 
> I am plotting this using barchart (there is probably something better
> but it gives me the results I want) and I would like the 
> x-axis to have
> the names of the months instead of the month numbers.  So I have
> searched and searched and I am not sure if I have to change 
> it before I
> graph it or if I can somehow change it in barchart.  Any help is most
> appreciated.
> Jacquie
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

Jacquie,

Try month.name[MM]or month.abb[MM].

Hope this is helpful,

Dan

Daniel J. Nordlund
Research and Data Analysis
Washington State Department of Social and Health Services
Olympia, WA  98504-5204


From macq at llnl.gov  Thu Jun 21 00:48:32 2007
From: macq at llnl.gov (Don MacQueen)
Date: Wed, 20 Jun 2007 15:48:32 -0700
Subject: [R] Replace number with month
In-Reply-To: <4A6AB38B55B49C44A22E021A83CBEDDB015EB982@sr-pnr-exch3.prairie.int.ec.gc.c
	a>
References: <4A6AB38B55B49C44A22E021A83CBEDDB015EB982@sr-pnr-exch3.prairie.int.ec.gc.c
	a>
Message-ID: <p06240801c29f5d575c15@[192.168.52.239]>

You can get the names using

   month.name[MM]


And it may be necessary to use

     factor(month.name[MM], levels=month.name[1:12])

to get them to show up in the correct order in the barchart.

Try, for example,

     plot(factor(month.name[1:12], levels=month.name[1:12]) , 12:1)

-Don

At 4:12 PM -0600 6/20/07, Spilak,Jacqueline [Edm] wrote:
>Hi all
>I have a multiple datasets that look like this
>
>MM  Freq
>  1      30
>   2     35
>   3     54
>   4     33
>   5     27
>   6     13
>   7     25
>   8     29
>   9     40
>   10   32
>   11   36
>   12   23
>
>I am plotting this using barchart (there is probably something better
>but it gives me the results I want) and I would like the x-axis to have
>the names of the months instead of the month numbers.  So I have
>searched and searched and I am not sure if I have to change it before I
>graph it or if I can somehow change it in barchart.  Any help is most
>appreciated.
>Jacquie
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


-- 
---------------------------------
Don MacQueen
Lawrence Livermore National Laboratory
Livermore, CA, USA
925-423-1062
macq at llnl.gov


From gvrocha at gmail.com  Thu Jun 21 00:54:03 2007
From: gvrocha at gmail.com (Guilherme Veiga da Rocha)
Date: Wed, 20 Jun 2007 17:54:03 -0500
Subject: [R] Estimated coefficients from regsubsets/leaps: where are they?
Message-ID: <D1D996A5-6EA2-4E40-8B6B-F25EE6FAA6DD@gmail.com>

	Dear all,
	
	I am doing a simulation study to evaluate the performance of subset  
selections for linear regression.

	I need to:
	a) get the coefficients of the variables for each of the models  
selected along the way;
	b) at least get the logical matrix telling me which variables were  
selected at each step (notice that if I have a above, I can get this  
anyway...)
	
	The functions "summary" and "plot" can tell me which variables are  
selected (b above) but the on screen information is useless as I need  
to post-process the results in my simulation.
	I have unsuccessfully tried doing "names(regsubset_return_object)"  
and inspecting each of the fields in the object had anything that  
resembled the information I wanted.
	
	Does anyone knows how to do that?
	
	Thanks a lot,
	
	Guilherme
	
Guilherme Veiga da Rocha
gvrocha at gmail.com


From mike.prager at noaa.gov  Thu Jun 21 01:23:50 2007
From: mike.prager at noaa.gov (Michael Prager)
Date: Wed, 20 Jun 2007 19:23:50 -0400
Subject: [R] Speed up R
References: <Pine.LNX.4.64.0706192216270.12443@gannet.stats.ox.ac.uk>
	<!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAfHU8PP2E50qGgSIBTaVydsKAAAAQAAAA9ZipM0jYbkSnDRXmTyd7zgEAAAAA@o2.pl>
	<3f547caa0706200716t493e63adq22214914dbf92f74@mail.gmail.com>
	<882j739u87c61h6hv6e5uneitfp84kemck@4ax.com>
	<3f547caa0706201339i3081f71y3ec682ea88dbfe8@mail.gmail.com>
Message-ID: <03dj73t6amdrk3n3j76aqubrl32ua6nc79@4ax.com>

Matthew Keller wrote:

> So Mike, let me ask you a question. If R runs out of RAM, does it
> begin to use virtual RAM, and hence begin to swap from the hard drive?
> If so, I could see how a faster hard drive would speed R up when you
> don't have enough RAM...

Yes. Virtual memory management is done by any modern operating
system. The slowdown will be extreme.  (Therefore, a minimum
of 2Gb is a good idea for serious crunching -- I'd recommend 3
or 4 if possible.  Don't forget that any programming language
may have two copies of some arrays in memory during certain
operations.)

But even when R itself is not using VM, any significant I/O
load on a Windows CPU (when (S)ATA disks are used) slows down
*at least* all other I/O, and it seems to me that it slows
down other interrupt servicing (e.g., responding to mouse
clicks) as well.  Even if the latter is not strictly true, it
may be that the mouse click requires paging something in, like
the stupid animation that plays when files are copied.  

Aside:  On a old PC, copying files from the command line was
fine, but if I forgot & did it from the Windows Explorer, the
stupid animation swapped in from disk and the machine froze
for ~30 seconds.)

Windows Vista can take advantage of a new gizmo Intel has
introducted with a 1 Gb solid-state disk cache. That might
reduce such problems.

Mike

Mike Prager
Southeast Fisheries Science Center, NOAA
Beaufort, North Carolina  USA


From linpan1975 at yahoo.com  Wed Jun 20 23:56:34 2007
From: linpan1975 at yahoo.com (Lin Pan)
Date: Wed, 20 Jun 2007 14:56:34 -0700 (PDT)
Subject: [R] how to obtain optimization with constraints
Message-ID: <11223029.post@talk.nabble.com>


Hello All,

I have one function f(x, y, z) and wanted to optimize the function by
changing x, y and z values. But z has to be <= sqrt(x*y). Does anybody give
some advise on how to do it in R? thanks a lot.



Lin
-- 
View this message in context: http://www.nabble.com/how-to-obtain-optimization-with-constraints-tf3955295.html#a11223029
Sent from the R help mailing list archive at Nabble.com.


From mazatlanmexico at yahoo.com  Wed Jun 20 18:00:51 2007
From: mazatlanmexico at yahoo.com (Felipe Carrillo)
Date: Wed, 20 Jun 2007 09:00:51 -0700 (PDT)
Subject: [R] How to activate the R commands in SciViews
Message-ID: <161728.34547.qm@web56603.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070620/2ae601bb/attachment.pl 

From rob.dunne at gmail.com  Thu Jun 21 02:00:36 2007
From: rob.dunne at gmail.com (Rob Dunne)
Date: Thu, 21 Jun 2007 10:00:36 +1000
Subject: [R] compiler cannot create executables
In-Reply-To: <20070620143457.GA19115@eddelbuettel.com>
References: <f5b6gc$d1a$1@sea.gmane.org>
	<20070620141047.GA18846@eddelbuettel.com>
	<20070620143457.GA19115@eddelbuettel.com>
Message-ID: <4679BFA4.5030702@gmail.com>

Hi Dick,

Dirk Eddelbuettel wrote:
>>>
>>> %sudo R CMD INSTALL --no-configure e1071_1.5-16.tar.gz
>> This statement of your conflicts with the msg you show below. Do you,
>> or don't you, succeed?
>>

sorry If my posting wasn't clear

%sudo R CMD INSTALL --no-configure e1071_1.5-16.tar.gz   -- works

%sudo R CMD INSTALL e1071_1.5-16.tar.gz   -- gives th error message


>> Please try 
>>
>>        $ sudo apt-get install r-base-dev

r-base-dev is already the newest version.

>>
>> as you seem to missing g++, and probably a host of other things.
> 
> I don't have access to a 'breezy' box anymore but what it could be is
> that R expects a different compiler version then the system has as
> default -- g++-4.0 vs g++-3.4.
> 
> What does 'grep g++ /etc/R/Makeconf' yield?
> 
CXX = g++
CXXCPP = g++ -E
SHLIB_CXXLD = g++


I unpacked the package and ran the configure script. It runs with no 
problems.

%tar -xzf e1071_1.5-16.tar.gz
% cd e1071/
% ./configure
checking for C++ compiler default output file name... a.out
checking whether the C++ compiler works... yes
checking whether we are cross compiling... no
checking for suffix of executables...
checking for suffix of object files... o
checking whether we are using the GNU C++ compiler... yes
checking whether g++ accepts -g... yes

Bye and thanks
Rob


From juryef at yahoo.com  Thu Jun 21 02:05:03 2007
From: juryef at yahoo.com (Judith Flores)
Date: Wed, 20 Jun 2007 17:05:03 -0700 (PDT)
Subject: [R] How can I obtain smooth lines in graphs?
Message-ID: <603910.38587.qm@web34711.mail.mud.yahoo.com>

Hi,

   I need to plot lines in a graph, but when I run the
corresponding commands I obtain pixel-like lines, they
need to be smooth, is there a way to do this?

Thank you,

Judith


From marc_schwartz at comcast.net  Thu Jun 21 02:20:26 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Wed, 20 Jun 2007 19:20:26 -0500
Subject: [R] How can I obtain smooth lines in graphs?
In-Reply-To: <603910.38587.qm@web34711.mail.mud.yahoo.com>
References: <603910.38587.qm@web34711.mail.mud.yahoo.com>
Message-ID: <1182385226.3828.9.camel@Bellerophon.localdomain>

On Wed, 2007-06-20 at 17:05 -0700, Judith Flores wrote:
> Hi,
> 
>    I need to plot lines in a graph, but when I run the
> corresponding commands I obtain pixel-like lines, they
> need to be smooth, is there a way to do this?
> 
> Thank you,
> 
> Judith

Judith,

You will need to provide more information (version of R, OS, output
device, etc.) and some sample code. 

If you are generating a bitmapped image file such as PNG or JPEG, as
opposed to a vector based image such as PDF, EPS or WMF/EMF then there
is not much you can do with respect to the pixelation of curved/angled
lines or curves/angles in text.   You can increase the dpi (dots per
inch) to enhance the relative resolution (at the expense of a larger
file), but the image quality is still dependent on the device upon which
the image is viewed. 

Pending further information, if you need high quality output, depending
upon the intended use, then you want to use vector based images.

HTH,

Marc Schwartz


From jrkrideau at yahoo.ca  Thu Jun 21 02:28:11 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Wed, 20 Jun 2007 20:28:11 -0400 (EDT)
Subject: [R] Replace number with month
In-Reply-To: <4A6AB38B55B49C44A22E021A83CBEDDB015EB982@sr-pnr-exch3.prairie.int.ec.gc.ca>
Message-ID: <327439.63024.qm@web32801.mail.mud.yahoo.com>

Simple brute force approach that should work:
barplot(Freq,MM, names=c('Jan','Feb','Mar', 'Apr',
'May', 'Jun','Jul', 'Aug', 'Sept', 'Oct','Nov',
'Dec'))


--- "Spilak,Jacqueline [Edm]"
<Jacqueline.Spilak at EC.gc.ca> wrote:

> Hi all
> I have a multiple datasets that look like this
> 
> MM  Freq
>  1      30
>   2     35
>   3     54
>   4     33
>   5     27
>   6     13
>   7     25
>   8     29
>   9     40
>   10   32
>   11   36
>   12   23
> 
> I am plotting this using barchart (there is probably
> something better
> but it gives me the results I want) and I would like
> the x-axis to have
> the names of the months instead of the month
> numbers.  So I have
> searched and searched and I am not sure if I have to
> change it before I
> graph it or if I can somehow change it in barchart. 
> Any help is most
> appreciated.
> Jacquie
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From juryef at yahoo.com  Thu Jun 21 02:38:03 2007
From: juryef at yahoo.com (Judith Flores)
Date: Wed, 20 Jun 2007 17:38:03 -0700 (PDT)
Subject: [R] How can I obtain smooth lines in graphs?
In-Reply-To: <1182385226.3828.9.camel@Bellerophon.localdomain>
Message-ID: <594929.39218.qm@web34703.mail.mud.yahoo.com>

Thank you Marc,

   I am using R (version 2.5.0), Windows 2000, and
Power Point as the final output and yes, you are right
regarding the quality of a PDF file, it's much better
than the ones I have tried so far (JPEG, PNG). 

   How can I increase the DPIs? 

Thank you,

Judith 
--- Marc Schwartz <marc_schwartz at comcast.net> wrote:

> On Wed, 2007-06-20 at 17:05 -0700, Judith Flores
> wrote:
> > Hi,
> > 
> >    I need to plot lines in a graph, but when I run
> the
> > corresponding commands I obtain pixel-like lines,
> they
> > need to be smooth, is there a way to do this?
> > 
> > Thank you,
> > 
> > Judith
> 
> Judith,
> 
> You will need to provide more information (version
> of R, OS, output
> device, etc.) and some sample code. 
> 
> If you are generating a bitmapped image file such as
> PNG or JPEG, as
> opposed to a vector based image such as PDF, EPS or
> WMF/EMF then there
> is not much you can do with respect to the
> pixelation of curved/angled
> lines or curves/angles in text.   You can increase
> the dpi (dots per
> inch) to enhance the relative resolution (at the
> expense of a larger
> file), but the image quality is still dependent on
> the device upon which
> the image is viewed. 
> 
> Pending further information, if you need high
> quality output, depending
> upon the intended use, then you want to use vector
> based images.
> 
> HTH,
> 
> Marc Schwartz
> 
> 
>


From marc_schwartz at comcast.net  Thu Jun 21 02:46:14 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Wed, 20 Jun 2007 19:46:14 -0500
Subject: [R] How can I obtain smooth lines in graphs?
In-Reply-To: <594929.39218.qm@web34703.mail.mud.yahoo.com>
References: <594929.39218.qm@web34703.mail.mud.yahoo.com>
Message-ID: <1182386774.3828.16.camel@Bellerophon.localdomain>

If you are going to be pasting the plots into Powerpoint, then you will
want to use the EMF/WMF devices for output.

If has been a while since I used Windows, but my recollection is that if
you draw the plot to the screen and then right-click on the plot window,
you can either copy the plot to the Windows clipboard (and then paste
into Powerpoint) or export the plot as a metafile and then import it
into Powerpoint.

In either case, I would leverage this somewhat unique functionality on
Windows to use the EMF/WMF vector based formats, which are the native
Windows graphics formats.

You should be able to use ?Devices on Windows to list the available
devices and get more information there.

HTH,

Marc

On Wed, 2007-06-20 at 17:38 -0700, Judith Flores wrote:
> Thank you Marc,
> 
>    I am using R (version 2.5.0), Windows 2000, and
> Power Point as the final output and yes, you are right
> regarding the quality of a PDF file, it's much better
> than the ones I have tried so far (JPEG, PNG). 
> 
>    How can I increase the DPIs? 
> 
> Thank you,
> 
> Judith 
> --- Marc Schwartz <marc_schwartz at comcast.net> wrote:
> 
> > On Wed, 2007-06-20 at 17:05 -0700, Judith Flores
> > wrote:
> > > Hi,
> > > 
> > >    I need to plot lines in a graph, but when I run
> > the
> > > corresponding commands I obtain pixel-like lines,
> > they
> > > need to be smooth, is there a way to do this?
> > > 
> > > Thank you,
> > > 
> > > Judith
> > 
> > Judith,
> > 
> > You will need to provide more information (version
> > of R, OS, output
> > device, etc.) and some sample code. 
> > 
> > If you are generating a bitmapped image file such as
> > PNG or JPEG, as
> > opposed to a vector based image such as PDF, EPS or
> > WMF/EMF then there
> > is not much you can do with respect to the
> > pixelation of curved/angled
> > lines or curves/angles in text.   You can increase
> > the dpi (dots per
> > inch) to enhance the relative resolution (at the
> > expense of a larger
> > file), but the image quality is still dependent on
> > the device upon which
> > the image is viewed. 
> > 
> > Pending further information, if you need high
> > quality output, depending
> > upon the intended use, then you want to use vector
> > based images.
> > 
> > HTH,
> > 
> > Marc Schwartz
> > 
> > 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bolker at ufl.edu  Thu Jun 21 03:12:18 2007
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 21 Jun 2007 01:12:18 +0000 (UTC)
Subject: [R] how to obtain optimization with constraints
References: <11223029.post@talk.nabble.com>
Message-ID: <loom.20070621T030939-749@post.gmane.org>

Lin Pan <linpan1975 <at> yahoo.com> writes:

> 
> 
> Hello All,
> 
> I have one function f(x, y, z) and wanted to optimize the function by
> changing x, y and z values. But z has to be <= sqrt(x*y). Does anybody give
> some advise on how to do it in R? thanks a lot.
> 
> Lin


   Put all the parameters on the log scale 
(so that log(z)- 0.5*log x -0.5*log y) <= 0),
then use constrOptim to set linear inequality constraints.
(This is assuming all the parameters are positive ...)

  Ben Bolker


From mjankowski at gmail.com  Thu Jun 21 05:50:29 2007
From: mjankowski at gmail.com (M. Jankowski)
Date: Wed, 20 Jun 2007 22:50:29 -0500
Subject: [R] Need Help: User Defined R Functions in Sweave/Latex
Message-ID: <500c63990706202050p7546ffc9ua191df3eb0f99098@mail.gmail.com>

Dear all,

I want to start my post by expressing my sincere gratitude for all the
help this group has given me in Sweave/Latex/R. The tools are
excellent and so is the community!

On to the question.

My Sweave code is intended to make lots of plots and create a *.pdf
document. Sweave is perfect for this. The only problem is that  I find
myself using the same R code, within my Sweave input file over an
over. I know about Latex macros and I can even get R functions,
essentially used as subroutines, to sort of work. "\Sexpr{}" will not
work because the R code I want to use over and over is in the R
environment. I've tried numerous ways to tackle this process and could
really use some help. If there is some easier way to do this please
let me know!

This is the R function:
basicplot <- function(x, nplots, sectionname){
# Begin to make figure here
file = paste("scatter",nplots, ".pdf", sep="")
pdf(file = file,paper="special", width=6, height = 6)
plot(x)
dev.off()
cat("\\begin{figure}\n")
cat("\\includegraphics{",file,"}\n", sep="")
cat("\\caption{", sectionname,"}\n", sep = "")
cat("\\end{figure}\n")
#End figure making
}

The aim is to generate Latex code which will have some basic
information as part of the caption. The trouble seems to be that the
output from the function appears to latex as if it is protected R code
when I really want to create output that pdflatex will act on.
Essentially, the resulting *.pdf contains the lines output by the cat
function in basicplot. Or:
\begin{figure}
\includegraphics{scatter1.pdf}
\caption{myname}
\end{figure}
These lines are not in the environment acted by Latex. I tried a
variant of the function where <<results=tex,echo=FALSE>> and received
the same result. Below are the files *.Snw -> *.tex -> *.pdf and the
output I received while compiling. If there is anything else I can
give to help you help me just let me know. Thanks!

Matt

My system:
T41 IBM Thinkpad
Ubuntu Feisty (7.04)
R version 2.5

testmacro3.Snw:
mdj at lapmdj:~/mydocs/R$ more testmacro3.Snw
\documentclass[a4paper]{article}
\usepackage{fullpage}
<<echo=f>>=
basicplot <- function(x, nplots, sectionname){
# Begin to make figure here
file = paste("scatter",nplots, ".pdf", sep="")
pdf(file = file,paper="special", width=6, height = 6)
plot(x)
dev.off()
cat("\\begin{figure}\n")
cat("\\includegraphics{",file,"}\n", sep="")
cat("\\caption{", sectionname,"}\n", sep = "")
cat("\\end{figure}\n")
#End figure making
}
@

\begin{document}
Filler text here.\\
<<>>=
library("flowCore")
x <- read.FCS("/home/mdj/data/yifacs2/NL7_PHA03_1.fcs", transformation = FALSE,
alter.names = TRUE);
basicplot(x, nplots = 1, sectionname="myname")
@
End text here \\
\end{document}

testmacro3.tex
\usepackage{/usr/share/R/share/texmf/Sweave}
\begin{document}
Filler text here.\\
\begin{Schunk}
\begin{Sinput}
> library("flowCore")
\end{Sinput}
\begin{Soutput}
Scalable Robust Estimators with High Breakdown Point (version 0.3-05)
\end{Soutput}
\begin{Sinput}
> x <- read.FCS("/home/mdj/data/yifacs2/NL7_PHA03_1.fcs", transformation = FALSE
,
+     alter.names = TRUE)
> basicplot(x, nplots = 1, sectionname = "myname")
\end{Sinput}
\begin{Soutput}
\begin{figure}
\includegraphics{scatter1.pdf}
\caption{myname}
\end{figure}
\end{Soutput}
\end{Schunk}
End text here \\
\end{document}

testmacro3.pdf:
Filler text here.
> library("flowCore")
Scalable Robust Estimators with High Breakdown Point (version 0.3-05)
> x <- read.FCS("/home/mdj/data/yifacs2/NL7_PHA03_1.fcs", transformation = FALSE,
+ alter.names = TRUE)
> basicplot(x, nplots = 1, sectionname = "myname")
\begin{figure}
\includegraphics{scatter1.pdf}
\caption{myname}
\end{figure}
End text here



Output:
mdj at lapmdj:~/mydocs/R$ R CMD Sweave testmacro3.Snw
[1] "Welcome to my custom R eenvironment!"
> library("utils"); Sweave("testmacro3.Snw")
Writing to file testmacro3.tex
Processing code chunks ...
 1 : term verbatim
 2 : echo term verbatim
Loading required package: Biobase
Loading required package: tools

Welcome to Bioconductor

    Vignettes contain introductory material. To view, type
    'openVignette()' or start with 'help(Biobase)'. For details
    on reading vignettes, see the openVignette help page.

Loading required package: rrcov
KernSmooth 2.22 installed
Copyright M. P. Wand 1997

You can now run LaTeX on 'testmacro3.tex'
> mdj at lapmdj:~/mydocs/Rpdflatex testmacro3.tex
This is pdfeTeX, Version 3.141592-1.21a-2.2 (Web2C 7.5.4)
entering extended mode
(./testmacro3.tex
LaTeX2e <2003/12/01>
Babel <v3.8d> and hyphenation patterns for american, french, german, ngerman, b
ahasa, basque, bulgarian, catalan, croatian, czech, danish, dutch, esperanto, e
stonian, finnish, greek, icelandic, irish, italian, latin, magyar, norsk, polis
h, portuges, romanian, russian, serbian, slovak, slovene, spanish, swedish, tur
kish, ukrainian, nohyphenation, loaded.
(/usr/share/texmf-tetex/tex/latex/base/article.cls
Document Class: article 2004/02/16 v1.4f Standard LaTeX document class
(/usr/share/texmf-tetex/tex/latex/base/size10.clo))
(/usr/share/texmf-texlive/tex/latex/preprint/fullpage.sty)
(/usr/share/R/share/texmf/Sweave.sty

LaTeX Warning: You have requested package `/usr/share/R/share/texmf/Sweave',
               but the package provides `Sweave'.

(/usr/share/texmf-tetex/tex/latex/base/ifthen.sty)
(/usr/share/texmf-tetex/tex/latex/graphics/graphicx.sty
(/usr/share/texmf-tetex/tex/latex/graphics/keyval.sty)
(/usr/share/texmf-tetex/tex/latex/graphics/graphics.sty
(/usr/share/texmf-tetex/tex/latex/graphics/trig.sty)
(/usr/share/texmf-tetex/tex/latex/graphics/graphics.cfg)
(/usr/share/texmf-tetex/tex/latex/graphics/pdftex.def)))
(/usr/share/texmf-texlive/tex/latex/fancyvrb/fancyvrb.sty
Style option: `fancyvrb' v2.6, with DG/SPQR fixes <1998/07/17> (tvz)
No file fancyvrb.cfg.
) (/usr/share/texmf/tex/latex/R/upquote.sty
(/usr/share/texmf-tetex/tex/latex/base/textcomp.sty
(/usr/share/texmf-tetex/tex/latex/base/ts1enc.def)))
(/usr/share/texmf-tetex/tex/latex/base/fontenc.sty
(/usr/share/texmf-tetex/tex/latex/base/t1enc.def))
(/usr/share/texmf-tetex/tex/latex/ae/ae.sty
(/usr/share/texmf-tetex/tex/latex/base/fontenc.sty
(/usr/share/texmf-tetex/tex/latex/base/t1enc.def)
(/usr/share/texmf-tetex/tex/latex/ae/t1aer.fd))))
No file testmacro3.aux.
(/usr/share/texmf-tetex/tex/latex/base/ts1cmr.fd)
(/usr/share/texmf-tetex/tex/context/base/supp-pdf.tex
(/usr/share/texmf-tetex/tex/context/base/supp-mis.tex
loading : Context Support Macros / Miscellaneous (2004.10.26)
)
loading : Context Support Macros / PDF (2004.03.26)
)
Underfull \hbox (badness 10000) in paragraph at lines 6--8

(/usr/share/texmf-tetex/tex/latex/ae/t1aett.fd)
Underfull \hbox (badness 10000) in paragraph at lines 26--27

[1{/var/lib/texmf/fonts/map/pdftex/updmap/pdftex.map}] (./testmacro3.aux) )
(see the transcript file for additional information)</usr/share/texmf-tetex/fon
ts/type1/bluesky/cm/cmtt10.pfb></usr/share/texmf-tetex/fonts/type1/bluesky/cm/c
msltt10.pfb></usr/share/texmf-tetex/fonts/type1/bluesky/cm/cmr10.pfb>
Output written on testmacro3.pdf (1 page, 26713 bytes).
Transcript written on testmacro3.log.
mdj at lapmdj:~/mydocs/R$ xpdf testmacro3.pdf &
[4] 11100
mdj at lapmdj:~/mydocs/R$ Warning: Attempt to remove nonexistent passive grab
xpdf testmacro3.pdf &
[5] 11109
[4]   Done                    xpdf testmacro.pdf
mdj at lapmdj:~/mydocs/R$


From pomchip at free.fr  Thu Jun 21 05:57:13 2007
From: pomchip at free.fr (=?ISO-8859-1?Q?S=E9bastien?=)
Date: Wed, 20 Jun 2007 23:57:13 -0400
Subject: [R] Overlaying lattice graphs (continued)
Message-ID: <4679F719.7020308@free.fr>

Dear R Users,

I recently posted an email on this list  about the use of data.frame and 
overlaying multiple plots. Deepayan kindly indicated to me the 
panel.superposition command which worked perfectly in the context of the 
example I gave.
I'd like to go a little bit further on this topic using a more complex 
dataset structure (actually the one I want to work on).

 >mydata
      Plot    Model    Individuals    Time        Observed          
Predicted
1    1        A           1                  0.05         
10                    10.2
2    1        A           1                  0.10         
20                    19.5
etc...
10  1        B           1                  0.05         10            
         9.8
11  1        B           1                  0.10         20            
         20.2
etc...

There are p "levels" in mydata$Plot, m in mydata$Model, n in 
mydata$Individuals and t in mydata$Time (Note that I probably use the 
word levels improperly as all columns are not factors). Basically, this 
dataset summarizes the t measurements obtained in n individuals as well 
as the predicted values from m different modeling approaches (applied to 
all individuals). Therefore, the observations are repeated m times in 
the Observed columns, while the predictions appears only once for a 
given model an a given individual.

What I want to write is a R batch file creating a Trellis graph, where 
each panel corresponds to one individual and contains the observations 
(as scatterplot) plus the predicted values for all models (as lines of 
different colors)... $Plot is just a token: it might be used to not 
overload graphs in case there are too many tested models. The fun part 
is that the values of p, m, n and t might vary from one dataset to the 
other, so everything has to be coded dynamically.

For the plotting part I was thinking about having a loop in my code 
containing something like that:

for (i in 1:nlevels(mydata$Model)) {

subdata<-subset(mydata,mydata$Model=level(mydata$Model)[i])
xyplot(subset(Observed + Predicted ~ Time | Individuals, data = 
subdata)       #plus additionnal formatting code

}

Unfortunately, this code simply creates a new Trellis plot instead of 
adding the model one by one on the panels. Any idea or link to a useful 
command will wellcome.

Sebastien


From swilsonpt at yahoo.com  Thu Jun 21 05:59:35 2007
From: swilsonpt at yahoo.com (Steven Wilson)
Date: Wed, 20 Jun 2007 20:59:35 -0700 (PDT)
Subject: [R] OSC code
Message-ID: <877401.99060.qm@web57305.mail.re1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070620/00d67552/attachment.pl 

From realityrandom at gmail.com  Thu Jun 21 07:27:53 2007
From: realityrandom at gmail.com (Yuchen Luo)
Date: Wed, 20 Jun 2007 22:27:53 -0700
Subject: [R] "if" within a function
Message-ID: <548b8d440706202227k14f0bed1j719868c595212d39@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070620/6a195d4a/attachment.pl 

From whinev at gmail.com  Thu Jun 21 07:33:39 2007
From: whinev at gmail.com (Ev Whin)
Date: Thu, 21 Jun 2007 13:33:39 +0800
Subject: [R] Question on package building
Message-ID: <dfed1c180706202233p3841276ajca84b6f14a332253@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070621/e6ac54a6/attachment.pl 

From m_olshansky at yahoo.com  Thu Jun 21 07:36:34 2007
From: m_olshansky at yahoo.com (Moshe Olshansky)
Date: Wed, 20 Jun 2007 22:36:34 -0700 (PDT)
Subject: [R] "if" within a function
In-Reply-To: <548b8d440706202227k14f0bed1j719868c595212d39@mail.gmail.com>
Message-ID: <278843.77554.qm@web32202.mail.mud.yahoo.com>

Hi Yuchen,

In R, if you do not put an explicit return statement
in the function, the value the function returns is the
value of the last statement in the function.  Unlike
VB, it does not matter whether you assign this value
to aaa (which is identical to your function name) or b
or c or x etc.
So either use an explicit return statement or make
sure that the last statement in the function produces
the right result.

--- Yuchen Luo <realityrandom at gmail.com> wrote:

> Dear Friends.
> I found a puzzling phenomenon in R when you use 'if'
> within a function:
> 
> # defining a function aaa
> aaa=function(a)
> {if (a==1) {aaa=1};
>  if (a!=1) {aaa=2}
>  }
> 
> # using the function:
> > b=20
> > bbb=aaa(b)
> > bbb
> [1] 2
> > typeof(bbb)
> [1] "double"
> >
> >
> > c=1
> > ccc=aaa(c)
> > ccc
> NULL
> > typeof(ccc)
> [1] "NULL"
> 
> It seems that only the last 'if' phrase works. Is it
> an instrinsic weakness
> of R? Is there a way to get around it? ( I use
> 'elseif' to get around this
> when there are only two cases to choose from, but
> what if there are more
> than two cases to choose from?)
> 
> Best
> Yuchen
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From NordlDJ at dshs.wa.gov  Thu Jun 21 07:56:47 2007
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Wed, 20 Jun 2007 22:56:47 -0700
Subject: [R] "if" within a function
In-Reply-To: <548b8d440706202227k14f0bed1j719868c595212d39@mail.gmail.com>
References: <548b8d440706202227k14f0bed1j719868c595212d39@mail.gmail.com>
Message-ID: <941871A13165C2418EC144ACB212BDB04E1313@dshsmxoly1504g.dshs.wa.lcl>

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Yuchen Luo
> Sent: Wednesday, June 20, 2007 10:28 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] "if" within a function
> 
> Dear Friends.
> I found a puzzling phenomenon in R when you use 'if' within a 
> function:
> 
> # defining a function aaa
> aaa=function(a)
> {if (a==1) {aaa=1};
>  if (a!=1) {aaa=2}
>  }
> 
> # using the function:
> > b=20
> > bbb=aaa(b)
> > bbb
> [1] 2
> > typeof(bbb)
> [1] "double"
> >
> >
> > c=1
> > ccc=aaa(c)
> > ccc
> NULL
> > typeof(ccc)
> [1] "NULL"
> 
> It seems that only the last 'if' phrase works. Is it an 
> instrinsic weakness
> of R? Is there a way to get around it? ( I use 'elseif' to 
> get around this
> when there are only two cases to choose from, but what if 
> there are more
> than two cases to choose from?)
> 
> Best
> Yuchen
> 

Yuchen,

In R, a function returns the last value evaluated.  In your case, if the argument passed to aaa() is equal to 1, the value returned is the value of the last if statement which is null.

You can tell aaa() to return the value you want with something like this

aaa<-function(a)
{if (a==1) return(1)
 if (a!=1) return(2)
 }

Hope this is helpful,

Dan

Daniel J. Nordlund
Research and Data Analysis
Washington State Department of Social and Health Services
Olympia, WA  98504-5204


From klaster at karlin.mff.cuni.cz  Thu Jun 21 08:06:02 2007
From: klaster at karlin.mff.cuni.cz (Petr Klasterecky)
Date: Thu, 21 Jun 2007 08:06:02 +0200
Subject: [R] "if" within a function
In-Reply-To: <548b8d440706202227k14f0bed1j719868c595212d39@mail.gmail.com>
References: <548b8d440706202227k14f0bed1j719868c595212d39@mail.gmail.com>
Message-ID: <467A154A.8010400@karlin.mff.cuni.cz>

You did not specify what your function should return and thus it returns 
the last value by default. If a!=1, the value returned is 2, however if 
a==1, the function tries to return the result of {if (a!=1) {aaa=2}}.

You can correct this easily by modifying your function like this:
aaa=function(a)
{if (a==1) {aaa=1}
if (a!=1) {aaa=2}
aaa
}

Petr

Yuchen Luo napsal(a):
> Dear Friends.
> I found a puzzling phenomenon in R when you use 'if' within a function:
> 
> # defining a function aaa
> aaa=function(a)
> {if (a==1) {aaa=1};
>  if (a!=1) {aaa=2}
>  }
> 
> # using the function:
>> b=20
>> bbb=aaa(b)
>> bbb
> [1] 2
>> typeof(bbb)
> [1] "double"
>>
>> c=1
>> ccc=aaa(c)
>> ccc
> NULL
>> typeof(ccc)
> [1] "NULL"
> 
> It seems that only the last 'if' phrase works. Is it an instrinsic weakness
> of R? Is there a way to get around it? ( I use 'elseif' to get around this
> when there are only two cases to choose from, but what if there are more
> than two cases to choose from?)
> 
> Best
> Yuchen
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Petr Klasterecky
Dept. of Probability and Statistics
Charles University in Prague
Czech Republic


From Jan.Verbesselt at csiro.au  Thu Jun 21 08:16:27 2007
From: Jan.Verbesselt at csiro.au (Jan.Verbesselt at csiro.au)
Date: Thu, 21 Jun 2007 16:16:27 +1000
Subject: [R] use ts objects within the "seas" package for seasonal stats ;
	to compare years with each other for change detection
Message-ID: <0393960FC6AFA142B0234E5CC8DA3B0C3FE337@exnswn2-syd.nexus.csiro.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070621/cc14369a/attachment.pl 

From Hong.Ooi at iag.com.au  Thu Jun 21 07:49:42 2007
From: Hong.Ooi at iag.com.au (Hong Ooi)
Date: Thu, 21 Jun 2007 15:49:42 +1000
Subject: [R] "if" within a function
References: <548b8d440706202227k14f0bed1j719868c595212d39@mail.gmail.com>
Message-ID: <200706210618.l5L6IRSC030919@hypatia.math.ethz.ch>


_______________________________________________________________________________________


R doesn't use the 'functionname = result' idiom to return a value from a
function. It looks like you're after:

aaa <- function(a)
{
    if(a == 1) return(1)
    if(a != 1) return(2)
}


or


aaa <- function(a)
{
    if(a == 1) 1
    else 2
}

see ?return



-- 
Hong Ooi
Senior Research Analyst, IAG Limited
388 George St, Sydney NSW 2000
+61 (2) 9292 1566
-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Yuchen Luo
Sent: Thursday, 21 June 2007 3:28 PM
To: r-help at stat.math.ethz.ch
Subject: [R] "if" within a function

Dear Friends.
I found a puzzling phenomenon in R when you use 'if' within a function:

# defining a function aaa
aaa=function(a)
{if (a==1) {aaa=1};
 if (a!=1) {aaa=2}
 }

# using the function:
> b=20
> bbb=aaa(b)
> bbb
[1] 2
> typeof(bbb)
[1] "double"
>
>
> c=1
> ccc=aaa(c)
> ccc
NULL
> typeof(ccc)
[1] "NULL"

It seems that only the last 'if' phrase works. Is it an instrinsic
weakness
of R? Is there a way to get around it? ( I use 'elseif' to get around
this
when there are only two cases to choose from, but what if there are more
than two cases to choose from?)

Best
Yuchen

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

_______________________________________________________________________________________

The information transmitted in this message and its attachme...{{dropped}}


From dieter.menne at menne-biomed.de  Thu Jun 21 08:57:22 2007
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Thu, 21 Jun 2007 06:57:22 +0000 (UTC)
Subject: [R] User Defined R Functions in Sweave/Latex
References: <500c63990706202050p7546ffc9ua191df3eb0f99098@mail.gmail.com>
Message-ID: <loom.20070621T082438-963@post.gmane.org>

M. Jankowski <mjankowski <at> gmail.com> writes:

> My Sweave code is intended to make lots of plots and create a *.pdf
> document. Sweave is perfect for this. The only problem is that  I find
> myself using the same R code, within my Sweave input file over an
> over. 
....
 
> This is the R function:
> basicplot <- function(x, nplots, sectionname){
> # Begin to make figure here
> file = paste("scatter",nplots, ".pdf", sep="")
> pdf(file = file,paper="special", width=6, height = 6)
> plot(x)
> dev.off()
> cat("\\begin{figure}\n")
> cat("\\includegraphics{",file,"}\n", sep="")
> cat("\\caption{", sectionname,"}\n", sep = "")
> cat("\\end{figure}\n")
> #End figure making
> }
> 
I don't know if this is exactly what you want, but below an example of using
includegraphics in a latex macro. For a real application, I recommend
\FloatBarrier instead of \clearpage when you have lots of figures/tables and
little text, as it's common in technical stuff.

Dieter

% -- Begin Sweave example
\documentclass[a4paper]{article}
\usepackage{Sweave}
\SweaveOpts{engine=R,eval=TRUE,eps=FALSE,pdf=TRUE, strip.white=TRUE}
\SweaveOpts{echo=FALSE,results=hide,width=6,height=4}

\bibliography{menne}
\begin{document}
\section{Hello}

\newcommand\doaplot[3]{

\begin{figure}
  \centering
\subsection{ #1}
\includegraphics{#2}
  \caption{3}
  \label{fig:#2}
\end{figure}
The meaning of life is The meaning of life is
The meaning of life is
The meaning of life is
The meaning of life is
\clearpage

}

<<dotheplots, results=tex>>=
 for (nplots in 1:3) {
   file = paste("scatter",nplots, ".pdf", sep="")
   pdf(file = file,paper="special", width=6, height = 6)
   plot(rnorm(100),rnorm(100),main=paste("Plot",nplots))
   dev.off()
   cat("\\doaplot{Section",nplots,"}{scatter",nplots,"}{My caption for ",
     nplots,"}\n",sep="")
 }
@

\end{document}


From dieter.menne at menne-biomed.de  Thu Jun 21 09:01:29 2007
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Thu, 21 Jun 2007 07:01:29 +0000 (UTC)
Subject: [R] Linear Mixed Models with nlme, more than one random effect
References: <BAY140-F23D21670707F77466D6BEBC6110@phx.gbl>
	<OF38D0F60A.BD593F52-ONC1257300.0048A3A2-C1257300.004907A4@basf-c-s.be>
Message-ID: <loom.20070621T090030-409@post.gmane.org>

 <joris.dewolf <at> cropdesign.com> writes:

> Have a look at Rnew volume 5/1 (http://cran.r-project.org/doc/Rnews/) where
> Doug Bates explains this nicely. Consider using lme4 for your purpose.

But be aware of <http://finzi.psych.upenn.edu/R/Rhelp02a/archive/76742.html>
if you currently want to use lme4.

Dieter


From amicogodzilla at bruttocarattere.org  Thu Jun 21 09:16:28 2007
From: amicogodzilla at bruttocarattere.org (Manuele Pesenti)
Date: Thu, 21 Jun 2007 09:16:28 +0200
Subject: [R] extract elements
In-Reply-To: <467956C0.1040803@pburns.seanet.com>
References: <200706201247.12054.amicogodzilla@bruttocarattere.org>
	<467956C0.1040803@pburns.seanet.com>
Message-ID: <200706210916.28708.amicogodzilla@bruttocarattere.org>

Thank you very much for all the answer!
I found them very usefull

	Manuele

-- 
Manuele Pesenti
	manuele a inventati.org
	amicogodzilla a jabber.linux.it
	http://mpesenti.polito.it


From birgit.lemcke at systbot.uzh.ch  Thu Jun 21 09:22:54 2007
From: birgit.lemcke at systbot.uzh.ch (Birgit Lemcke)
Date: Thu, 21 Jun 2007 09:22:54 +0200
Subject: [R] Dissimilarity
In-Reply-To: <11220912.post@talk.nabble.com>
References: <0B85CE3E-78E8-4DC5-8484-CBB687E61545@systbot.uzh.ch>
	<1182354377.16388.14.camel@gsimpson.geog.ucl.ac.uk>
	<11220912.post@talk.nabble.com>
Message-ID: <7BE6A4DA-4934-44C9-8C5F-209994C99DD0@systbot.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070621/2e6e2f0f/attachment.pl 

From m_olshansky at yahoo.com  Thu Jun 21 02:28:20 2007
From: m_olshansky at yahoo.com (Moshe Olshansky)
Date: Wed, 20 Jun 2007 17:28:20 -0700 (PDT)
Subject: [R]  Speed up R
Message-ID: <47957.87518.qm@web32204.mail.mud.yahoo.com>

Robert McFadden writes:

>Dear R Users,
>I hope that there is someone who has an experience
>with a problem that I
>describe below and will help me. 
>I must buy new desktop computer and I'm wondering
>which processor to choose
>if my only aim is to speed up R. I would like to
>reduce a simulation time -
>sometimes it takes days. I consider buying one of
>them (I'm working under
>Win XP 32 bit):  
>1. Intel Core2 Duo E6700 2.67 GHz
>2. Dual-Core Intel Xeon processor 3070 - 2,66 GHz
>3. AMD Athlon 64 X2 6000+
>Or simple Pentium 4?
>
>I'm very confused because I'm not sure whether R
>takes advantage dual-core
>or not. If not, probably Athlon would be better,
>wouldn't be? 
>I would appreciate any help.
>Rob

Hi Robert,

Let me suggest you a "dirty" solution - if simulations
take days and you must run them many times I would
have rewriten them, let say, in C.  I had a program in
Matlab which took more than an hour to run and I had
to run it many times, so I usually prepared a few
runs, started them in the evening before leaving the
office and got the results next morning.  After a
while I have re-written it in C (this took me a few
days) and got a spead-up factor of about 100, so that
now the run took just a few minutes!
Languages like R and Matlab are extreemely convenient
but if performance is a very important issue you shoul
use C, Fortran, C++, etc.

Regards,

Moshe Olshansky.


From adrian at maths.uwa.edu.au  Thu Jun 21 09:15:26 2007
From: adrian at maths.uwa.edu.au (adrian at maths.uwa.edu.au)
Date: Thu, 21 Jun 2007 15:15:26 +0800 (WST)
Subject: [R] [R-pkgs] spatstat version 2
Message-ID: <35219.130.95.98.17.1182410126.squirrel@130.95.98.17>

              SPATSTAT version 2

Spatstat is an R package for the statistical analysis of spatial data.

A preliminary announcement about the forthcoming Version 2 of spatstat
is available here:
    <www.spatstat.org/spatstat/spatstat2.html>

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages


From ripley at stats.ox.ac.uk  Thu Jun 21 09:32:16 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 21 Jun 2007 08:32:16 +0100 (BST)
Subject: [R] How to create .rda file to be used in package building
In-Reply-To: <626c66f20706201350v3f61f433ted4b33f721cd5893@mail.gmail.com>
References: <626c66f20706201350v3f61f433ted4b33f721cd5893@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0706210829020.27598@gannet.stats.ox.ac.uk>

On Wed, 20 Jun 2007, Deli Wang wrote:

> Hi,
>
> Can someone tell me how to create .rda data files in R so that they can be
> used contributed package?

The manual says

   Currently, data files can have one of three types as indicated by their
   extension: plain R code (.R or .r), tables (.tab, .txt, or .csv), or
   save() images (.RData or .rda). (All ports of R use the same binary
   (XDR) format and can read compressed images. Use images saved with save(,
   compress = TRUE), the default, to save space.)

What more information do you need?  ?save may help you.


>
> Thanks
>
> Deli Wang
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Jun 21 09:35:47 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 21 Jun 2007 08:35:47 +0100 (BST)
Subject: [R] Extracting t-tests on coefficients in lm
In-Reply-To: <4679989A.40403@uvm.edu>
References: <4679989A.40403@uvm.edu>
Message-ID: <Pine.LNX.4.64.0706210833070.27598@gannet.stats.ox.ac.uk>

On Wed, 20 Jun 2007, David C. Howell wrote:

> I am writing a resampling program for multiple regression using lm(). I
> resample the data 10,000 times, each time extracting the regression
> coefficients. At present I extract the individual regression
> coefficients using
>
>  brg = lm(Newdv~Teach + Exam + Knowledge + Grade + Enroll)
>  bcoef[i,] = brg$coef
>
> This works fine.
>
> But now I want to extract the t tests on these coefficients. I cannot
> find how these coefficients are stored, if at all. When I try
>    attributes(brg)
> I do not find the t values as the attributes of the object. Typing
> summary(brg) will PRINT the coefficients, their standard errors, t, and
> the associated probability. I would like to type something like
>    tcoeff[i,] = brg$tvalue
> but, of course, tvalue doesn't exist.
>
> Is there a simple way to extract, or compute if necessary, these values?

coef(summary(brg)) gives you the table, so coef(summary(brg))[,3] gives 
you the t values (but they are not t-tests per se).

?summary.lm would have told you this.

> Thanks,
> Dave Howell

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From r.hankin at noc.soton.ac.uk  Thu Jun 21 10:13:56 2007
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Thu, 21 Jun 2007 09:13:56 +0100
Subject: [R] How to create .rda file to be used in package building
In-Reply-To: <626c66f20706201350v3f61f433ted4b33f721cd5893@mail.gmail.com>
References: <626c66f20706201350v3f61f433ted4b33f721cd5893@mail.gmail.com>
Message-ID: <1D4AD149-6C56-4075-8009-AEE7120782A3@noc.soton.ac.uk>

Deli

the way I do it is to start with an
R session with the data objects in
memory.

Then package.skeleton() creates a
directory tree which is, well, a package skeleton,
including the data which appears as .rda files in
the data/ directory.

HTH

Robin


On 20 Jun 2007, at 21:50, Deli Wang wrote:

> Hi,
>
> Can someone tell me how to create .rda data files in R so that they  
> can be
> used contributed package?
>
> Thanks
>
> Deli Wang
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743


From mark_difford at yahoo.co.uk  Thu Jun 21 10:14:33 2007
From: mark_difford at yahoo.co.uk (Mark Difford)
Date: Thu, 21 Jun 2007 01:14:33 -0700 (PDT)
Subject: [R] Dissimilarity
In-Reply-To: <7BE6A4DA-4934-44C9-8C5F-209994C99DD0@systbot.uzh.ch>
References: <0B85CE3E-78E8-4DC5-8484-CBB687E61545@systbot.uzh.ch>
	<1182354377.16388.14.camel@gsimpson.geog.ucl.ac.uk>
	<11220912.post@talk.nabble.com>
	<7BE6A4DA-4934-44C9-8C5F-209994C99DD0@systbot.uzh.ch>
Message-ID: <11228522.post@talk.nabble.com>


Hi Birgit,

If French is a problem, then you will unfortunately (because you miss out on
Chessel's marvellous insights) have to do with the terser, more formal stuff
(publications), on the "Links" page of the ade4 site.  Most of this is in
English:

http://pbil.univ-lyon1.fr/ADE-4/links.php?lang=eng
## Chessel's stuff
http://pbil.univ-lyon1.fr/R/perso/pagechessel.html

Hope that helps.

PS: There is also a brief overview of the one-table methods provided by the
ade4 package in an R Newsletter:
http://cran.r-project.org/doc/Rnews/Rnews_2004-1.pdf


Birgit Lemcke wrote:
> 
> Hello Mark,
> 
> thank you for your additional advices.
> I had already a short look at the vegan package but I think I have to  
> look closer and also at the ade4 package.
> 
> Unfortunately I am basically from Germany and my French is perhaps  
> only a rudimental school french but anyway, I would like to have a  
> look at this lecture notes, but I can not open the link you wrote me.
> Ah sorry now the link works.
> 
> Greetings and thanks a lot.
> 
> Birgit
> 
> Hey Gavin,
> I found it funny that your institute is in the Gower Street.
> 
> 
> 
> Am 20.06.2007 um 21:49 schrieb Mark Difford:
> 
>>
>> Hi Birgit,
>>
>> Just to add to what Gavin has said.  There are two other very powerful
>> packages in R that handle this kind of thing: ade4 and vegan.  Have a
>> thorough look at both of them.  You should be looking at Principal
>> Coordinate Analysis (Classical Scaling) and Non Metric  
>> Multidimensional
>> Scaling (NMDS)---with, as Gavin has said, your species as rows.  At  
>> least
>> the first of these methods goes hand-in-glove with cluster analysis.
>>
>> Given that you are based in Switzerland, and perhaps are Swiss, you  
>> probably
>> therefore read and speak French as a second/third language.  You may
>> therefore find the ade4 package more useful, since its authors are  
>> French,
>> and its principal authors, Prof. Daniel Chessel &c., have made  
>> publicly
>> available some exceptionally useful documentation on these methods  
>> on their
>> ade4 website.  These are mainly Prof. Chessel's lecture notes:
>>
>> http://pbil.univ-lyon1.fr/R/enseignement.html
>>
>> I hope that speeds you on your way.
>>
>> Regards,
>> Mark.
>>
>> PS: Apropos of the Legendre & Legendre text: It's well worth buying  
>> if you
>> work in this area; one of its authors, Pierre Legendre, now  
>> collaborates
>> with Jari Oksanen on some functions of the vegan package.
>>
>>
>> Gavin Simpson wrote:
>>>
>>> On Wed, 2007-06-20 at 16:13 +0200, Birgit Lemcke wrote:
>>>> Hello Stephen,
>>>>
>>>> I am happy that you help me. Thanks a million.
>>>>
>>>> It is a good feeling that you confirm my assumption that dsvdis is
>>>> not able to deal with missing data, because it says me that I am not
>>>> completely incapable.
>>>> Okay now I have the problem what to do.
>>>> I used this function cause there is an option to weight columns
>>>> differently what I havent found in other functions.
>>>>
>>>> But now I dont understand why I have to transpose the species as
>>>> columns? As I read in the help manual of dsvdis this function
>>>> calculates dissimilarities between rows.
>>>> I have to calculate the dissimilarities between species that are in
>>>> rows by the use of morphological characters that are in columns.
>>>
>>> If you really what to measure the associations between species then
>>> leave them as you had them as the rows. But make sure you are  
>>> choosing a
>>> dissimilarity coefficient that works well for species associations.
>>> There is a whole section in Legendre and Legendre 1998 Numerical  
>>> Ecology
>>> 2nd English Edition Elsevier which may help here.
>>>
>>> HTH
>>>
>>> G
>>>
>>>>
>>>> Am I completely wrong with my thoughts?
>>>>
>>>> Birgit
>>>>
>>>> Am 20.06.2007 um 15:52 schrieb Stephen B. Cox:
>>>>
>>>>> Hi Birgit - looks like you have a few issues here.
>>>>>
>>>>> Birgit Lemcke <birgit.lemcke <at> systbot.uzh.ch> writes:
>>>>>
>>>>>>
>>>>>> Hello you all!
>>>>>>
>>>>>> I am a completely new user of R and I have a problem to solve.
>>>>>> I am using Mac OS X on a PowerBook.
>>>>>>
>>>>>> I have a table that looks like this:
>>>>>>
>>>>>>             species X1 X2 X3 X4 X5 X6 X7 X8 X9 X10 X11 X12 X13 X14
>>>>>> X15 X16 X17 X18 X19 X20 X21
>>>>>> 1        Anth_cap1  1  0  0  1  0  1  0  0  1   0   0   0   0   0
>>>>>> 0   0   1   0   0   0   1
>>>>>> 2       Anth_crin1  1  0  0  1  0  1  0  0  1   0   1   0   0   0
>>>>>> 0   0   0   1   0   0   1
>>>>>> 3        Anth_eck1  1  0  0  1  0  1  0  0  1   0   0   0   0   0
>>>>>> 0   0   0   1   0   0   1
>>>>>> 4       Anth_gram1  1  0  0  1  0  1  0  0  1  NA  NA  NA  NA   0
>>>>>> 0   0   0   1   0   0   0
>>>>>> 5       Anth_insi1  1  0  0  1  0  1  0  0  1   0   0   0   1   0
>>>>>> 0   0   0   1   0   0   1
>>>>>>
>>>>>> All columns  are binary coded characters.
>>>>>> The Import was done by this
>>>>>>
>>>>>> Test<-read.table("TestRFemMalBivariat1.csv",header = TRUE, sep  
>>>>>> = ";")
>>>>>
>>>>> First - you need to transpose the matrix to have species as
>>>>> columns.  You can do
>>>>> this with:
>>>>>
>>>>> d2 = data.frame(t(Test[,-1]))
>>>>> colnames(d2) = Test[,1]  #now use d2
>>>>>
>>>>>
>>>>>
>>>>>> Now I try to perform a similarity analysis with the dsvdis  
>>>>>> function
>>>>>> of the labdsv package with the sorensen-Index.
>>>>>>
>>>>>> My first question is if all zeros in my table are seen as missing
>>>>>> values and if it islike that how can I change without turning zero
>>>>>> into other numbers?
>>>>>
>>>>> no - the zeros are valid observations.  the na's are missing data.
>>>>>
>>>>>
>>>>>>   DisTest<-dsvdis(Test, index = "sorensen")
>>>>>>
>>>>>> But I always get back this error message:
>>>>>>
>>>>>> Warnung in symbol.For("dsvdis") :'symbol.For' is not needed:  
>>>>>> please
>>>>>> remove it
>>>>>> Fehler in dsvdis(Test, index = "sorensen") :
>>>>>> 	NA/NaN/Inf in externem Funktionsaufruf (arg 1)
>>>>>> Zustzlich: Warning message:
>>>>>> NAs durch Umwandlung erzeugt
>>>>>
>>>>>
>>>>>
>>>>> Second - you have an issue with missing data.  It looks like dsvdis
>>>>> does not
>>>>> like the NA's - so you must make a decision about what to do.
>>>>> Delete that
>>>>> species, delete that site, or whatever...
>>>>>
>>>>> Finally - the warning over symbol.For is an issue with the labdsv
>>>>> library itself
>>>>> - nothing you are doing wrong.  The results will still be valid -
>>>>> but the use of
>>>>> symbol.For is something that will eventually need to be changed in
>>>>> the labdsv
>>>>> library.
>>>>>
>>>>> hth,
>>>>>
>>>>> stephen
>>>>
>>>> Birgit Lemcke
>>>> Institut fr Systematische Botanik
>>>> Zollikerstrasse 107
>>>> CH-8008 Zrich
>>>> Switzerland
>>>> Ph: +41 (0)44 634 8351
>>>> birgit.lemcke at systbot.uzh.ch
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> 	[[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at stat.math.ethz.ch mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> -- 
>>> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
>>>  Gavin Simpson                 [t] +44 (0)20 7679 0522
>>>  ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
>>>  Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
>>>  Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
>>>  UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
>>> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>> -- 
>> View this message in context: http://www.nabble.com/Re%3A- 
>> Dissimilarity-tf3952667.html#a11220912
>> Sent from the R help mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting- 
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> Birgit Lemcke
> Institut f?r Systematische Botanik
> Zollikerstrasse 107
> CH-8008 Z?rich
> Switzerland
> Ph: +41 (0)44 634 8351
> birgit.lemcke at systbot.uzh.ch
> 
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/Re%3A-Dissimilarity-tf3952667.html#a11228522
Sent from the R help mailing list archive at Nabble.com.


From P.Dalgaard at biostat.ku.dk  Thu Jun 21 10:15:30 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 21 Jun 2007 10:15:30 +0200
Subject: [R] Replace number with month
In-Reply-To: <p06240801c29f5d575c15@[192.168.52.239]>
References: <4A6AB38B55B49C44A22E021A83CBEDDB015EB982@sr-pnr-exch3.prairie.int.ec.gc.c	a>
	<p06240801c29f5d575c15@[192.168.52.239]>
Message-ID: <467A33A2.1000103@biostat.ku.dk>

Don MacQueen wrote:
> You can get the names using
>
>    month.name[MM]
>
>
> And it may be necessary to use
>
>      factor(month.name[MM], levels=month.name[1:12])
>
> to get them to show up in the correct order in the barchart.
>   

You're crossing the creek to fetch water there, and getting yourself
soaked in the process... (by an unnecessary conversion to character
which is subject to alphabetical sorting)

I think the canonical way is

factor(MM, levels=1:12, labels=month.name)

(and the levels=1:12 may not even be necessary when all 12 months are
present)

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From paul.suckling at gmail.com  Thu Jun 21 10:22:11 2007
From: paul.suckling at gmail.com (Paul Suckling)
Date: Thu, 21 Jun 2007 09:22:11 +0100
Subject: [R] Prediction Intervals
Message-ID: <df529a970706210122y6830214fidba1bbfd8b6e5d99@mail.gmail.com>

Hello.

Does anyone out there know if there is a function (or functions) that
will enable me to calculate prediction and confidence intervals from a
non-linear least squares model? (predict.nls does not do this.)
Thank you,

Paul


From nlei at sfu.ca  Thu Jun 21 10:27:40 2007
From: nlei at sfu.ca (nlei at sfu.ca)
Date: Thu, 21 Jun 2007 01:27:40 -0700
Subject: [R] model selection criteria in "regsubsets"
Message-ID: <200706210827.l5L8Reac017771@rm-rstar.sfu.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070621/3bf70d4d/attachment.pl 

From paul.suckling at gmail.com  Thu Jun 21 10:31:16 2007
From: paul.suckling at gmail.com (Paul Suckling)
Date: Thu, 21 Jun 2007 09:31:16 +0100
Subject: [R] Prediction Intervals
In-Reply-To: <df529a970706210122y6830214fidba1bbfd8b6e5d99@mail.gmail.com>
References: <df529a970706210122y6830214fidba1bbfd8b6e5d99@mail.gmail.com>
Message-ID: <df529a970706210131o19c50422qf92be986b0af9045@mail.gmail.com>

Hi.

In part answer to my own question, I just found this link:

https://stat.ethz.ch/pipermail/r-help/2003-August/037654.html

which explains how one might calculate an approximation to the
variance of a non-linear function and use that to calculate a
confidence/prediction interval. If anyone knows an easier way, then
I'd still be glad to hear from you.

Thanks,

Paul

On 21/06/07, Paul Suckling <paul.suckling at gmail.com> wrote:
> Hello.
>
> Does anyone out there know if there is a function (or functions) that
> will enable me to calculate prediction and confidence intervals from a
> non-linear least squares model? (predict.nls does not do this.)
> Thank you,
>
> Paul
>


From petr.pikal at precheza.cz  Thu Jun 21 10:37:39 2007
From: petr.pikal at precheza.cz (Petr PIKAL)
Date: Thu, 21 Jun 2007 10:37:39 +0200
Subject: [R] Odp:  merge
In-Reply-To: <747715.81493.qm@web27507.mail.ukl.yahoo.com>
Message-ID: <OF77744B4A.109759D2-ONC1257301.002EB87E-C1257301.002F64C1@precheza.cz>

r-help-bounces at stat.math.ethz.ch napsal dne 20.06.2007 18:02:07:

> Hello,
> ok I know how to do to merge matrix or data.frame by "row.names" but my 
true 
> objectif is to merge for example this data.frame:
> 
> > A
>       obs
>        R?p1 R?p2 R?p3 R?p4 R?p5 R?p6
>   Var1  145  145  150  145  140  145
>   Var2  150  150  160  155  155  150
>   Var3  155  155  160  150  150  140
>   Var4  150  145  145  145  140  145
>   Var5  135  130  145  135  135  130
> 
> and 
> 
> > B
>       pred
>          R?p1   R?p2   R?p3   R?p4   R?p5   R?p6
>   Var1 146.00 144.00 151.00 145.00 143.00 141.00
>   Var2 154.33 152.33 159.33 153.33 151.33 149.33
>   Var3 152.67 150.67 157.67 151.67 149.67 147.67
>   Var4 146.00 144.00 151.00 145.00 143.00 141.00
>   Var5 136.00 134.00 141.00 135.00 133.00 131.00
> 
> and the main difficulty is to keep the names and the supernames.
> Do you know how. I know that the question isn't so easy but it's for a 
good display.
> thanks.

I may be mistaken but in such a case do you really want to do merge? Or 
just connecting both objects (data.frames) to list will do what you want?

In case you want:

pred
        Rep1...
Var1

obs
        Rep1...
Var1

in one object I think list is what I will go for.

In case you want:

state   var  Rep1 Rep2....
pred    Var1
obs     Var1
pred    Var2
obs     Var2

I would try to fiddle with merge after adding a column state to each 
object (I hesitate to call it data frame due to "supernames")

Regards
Petr


> 
> 
> 
_____________________________________________________________________________ 

> Ne gardez plus qu'une seule adresse mail ! Copiez vos mails vers Yahoo! 
Mail 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From barcarol at istat.it  Thu Jun 21 11:28:22 2007
From: barcarol at istat.it (Giulio Barcaroli)
Date: Thu, 21 Jun 2007 11:28:22 +0200
Subject: [R]  [R-pkgs] RGtk2 2.10.x series available
Message-ID: <467A44B6.80308@istat.it>

I installed version 2.10.9-1 of RGtk2, but when I tried to load it I
received the following message:

> local({pkg <- select.list(sort(.packages(all.available = TRUE)))

+ if(nchar(pkg)) library(pkg, character.only=TRUE)})

Error in dyn.load(x, as.logical(local), as.logical(now)) : 

        unable to load shared library 'C:/Programmi/R/R-2.5.0/library/RGtk2/libs/RGtk2.dll':

  LoadLibrary failure:  impossible to find the specified procedure

Error: package/namespace load failed for 'RGtk2'

> 

I checked in the directory

C:/Programmi/R/R-2.5.0/library/RGtk2/libs/

and the RGtk2.dll module does exist.
Any indication about how to solve this problem?
Giulio Barcaroli

From ima at difres.dk  Thu Jun 21 12:09:31 2007
From: ima at difres.dk (Irene Mantzouni)
Date: Thu, 21 Jun 2007 12:09:31 +0200
Subject: [R] meta-analysis in R
Message-ID: <68E7981938EAF54F987AD3848A0A64160109C3B4@ka-mail01.dfu.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070621/df849256/attachment.pl 

From ripley at stats.ox.ac.uk  Thu Jun 21 12:22:04 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 21 Jun 2007 11:22:04 +0100 (BST)
Subject: [R] [R-pkgs] RGtk2 2.10.x series available
In-Reply-To: <467A44B6.80308@istat.it>
References: <467A44B6.80308@istat.it>
Message-ID: <Pine.LNX.4.64.0706211109380.5901@gannet.stats.ox.ac.uk>

Did you not get a dialog box with further details?

Unfortunately I found no instructions.  You need a version of of Gtk2 
installed that is at least as late as the Windows maintainer used to build 
RGtk2, as it adapts to the version installed.  I don't know what that is 
and had to update mine.

http://downloads.sourceforge.net/gladewin32/gtk-2.10.11-win32-1.exe?download

is the latest available, and sufficed for me.

Uwe: could you add a note to the Readme, please, with the version 
requirement?


On Thu, 21 Jun 2007, Giulio Barcaroli wrote:

> I installed version 2.10.9-1 of RGtk2, but when I tried to load it I
> received the following message:
>
>> local({pkg <- select.list(sort(.packages(all.available = TRUE)))
>
> + if(nchar(pkg)) library(pkg, character.only=TRUE)})
>
> Error in dyn.load(x, as.logical(local), as.logical(now)) :
>
>        unable to load shared library 'C:/Programmi/R/R-2.5.0/library/RGtk2/libs/RGtk2.dll':
>
>  LoadLibrary failure:  impossible to find the specified procedure
>
> Error: package/namespace load failed for 'RGtk2'
>
>>
>
> I checked in the directory
>
> C:/Programmi/R/R-2.5.0/library/RGtk2/libs/
>
> and the RGtk2.dll module does exist.
> Any indication about how to solve this problem?
> Giulio Barcaroli
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From gwgilc at wm.edu  Thu Jun 21 12:48:45 2007
From: gwgilc at wm.edu (George W. Gilchrist)
Date: Thu, 21 Jun 2007 06:48:45 -0400
Subject: [R] Extract Df under lme4
Message-ID: <F240E63F-881E-4029-9B44-970C7EB73600@wm.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070621/02945165/attachment.pl 

From ccleland at optonline.net  Thu Jun 21 13:01:02 2007
From: ccleland at optonline.net (Chuck Cleland)
Date: Thu, 21 Jun 2007 07:01:02 -0400
Subject: [R] Extract Df under lme4
In-Reply-To: <F240E63F-881E-4029-9B44-970C7EB73600@wm.edu>
References: <F240E63F-881E-4029-9B44-970C7EB73600@wm.edu>
Message-ID: <467A5A6E.8080602@optonline.net>

George W. Gilchrist wrote:
> I need to extract the degrees of freedom and log likelihoods from a  
> series of mixed models computed using lmer/lme4. If I ask for logLik 
> (lmer.object), I get something like
>  > logLik(lmer.object)
> 'log Lik.' -177.1000 (df=10)
> 
> Can I easily get that df from there (or elsewhere) into an object?  
> Thank you for any ideas.

  The help page for logLik() suggests the following:

> library(lme4)

> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)

> logLik(fm1)
'log Lik.' -871.8141 (df=5)

> attr(logLik(fm1), "df")
[1] 5

> George
> 
> ..................................................................
> George W. Gilchrist                           Email: gwgilc at wm.edu
> Director of Graduate Studies                 Phone: (757) 221-7751
> Department of Biology, Box 8795                Fax: (757) 221-6483
> College of William & Mary
> Williamsburg, VA 23187-8795
> http://gwgilc.people.wm.edu/
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From sigbert at wiwi.hu-berlin.de  Thu Jun 21 13:11:26 2007
From: sigbert at wiwi.hu-berlin.de (Sigbert Klinke)
Date: Thu, 21 Jun 2007 13:11:26 +0200
Subject: [R] barchart in trellis and NA
Message-ID: <467A5CDE.2030002@wiwi.hu-berlin.de>

Hi,

I've a dataset with discrete data and several groups and in one group I 
have also missing values (NA). When I use table and barchart to 
visualize the counts I never get a bar for  NA in the barchart although 
it appears in the result of table. Is there a possibility to get this 
bar too?

Thanks in advance  Sigbert Klinke


From birgit.lemcke at systbot.uzh.ch  Thu Jun 21 13:47:13 2007
From: birgit.lemcke at systbot.uzh.ch (Birgit Lemcke)
Date: Thu, 21 Jun 2007 13:47:13 +0200
Subject: [R] Warning message!!
Message-ID: <8781EEA7-AB63-4485-A910-1A0582592994@systbot.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070621/0ea21a3a/attachment.pl 

From birgit.lemcke at systbot.uzh.ch  Thu Jun 21 13:50:02 2007
From: birgit.lemcke at systbot.uzh.ch (Birgit Lemcke)
Date: Thu, 21 Jun 2007 13:50:02 +0200
Subject: [R] Dissimilarity
In-Reply-To: <11228522.post@talk.nabble.com>
References: <0B85CE3E-78E8-4DC5-8484-CBB687E61545@systbot.uzh.ch>
	<1182354377.16388.14.camel@gsimpson.geog.ucl.ac.uk>
	<11220912.post@talk.nabble.com>
	<7BE6A4DA-4934-44C9-8C5F-209994C99DD0@systbot.uzh.ch>
	<11228522.post@talk.nabble.com>
Message-ID: <B2B7907B-9C03-48B8-B2CA-9C48A3164F1E@systbot.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070621/7fa3085a/attachment.pl 

From ligges at statistik.uni-dortmund.de  Thu Jun 21 13:59:30 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 21 Jun 2007 13:59:30 +0200
Subject: [R] [R-pkgs] RGtk2 2.10.x series available
In-Reply-To: <Pine.LNX.4.64.0706211109380.5901@gannet.stats.ox.ac.uk>
References: <467A44B6.80308@istat.it>
	<Pine.LNX.4.64.0706211109380.5901@gannet.stats.ox.ac.uk>
Message-ID: <467A6822.3040208@statistik.uni-dortmund.de>



Prof Brian Ripley wrote:
> Did you not get a dialog box with further details?
> 
> Unfortunately I found no instructions.  You need a version of of Gtk2 
> installed that is at least as late as the Windows maintainer used to 
> build RGtk2, as it adapts to the version installed.  I don't know what 
> that is and had to update mine.
> 
> http://downloads.sourceforge.net/gladewin32/gtk-2.10.11-win32-1.exe?download 
> 
> 
> is the latest available, and sufficed for me.
> 
> Uwe: could you add a note to the Readme, please, with the version 
> requirement?

Thanks for the hint. I'll do so this afternoon.

Uwe


> 
> 
> On Thu, 21 Jun 2007, Giulio Barcaroli wrote:
> 
>> I installed version 2.10.9-1 of RGtk2, but when I tried to load it I
>> received the following message:
>>
>>> local({pkg <- select.list(sort(.packages(all.available = TRUE)))
>>
>> + if(nchar(pkg)) library(pkg, character.only=TRUE)})
>>
>> Error in dyn.load(x, as.logical(local), as.logical(now)) :
>>
>>        unable to load shared library 
>> 'C:/Programmi/R/R-2.5.0/library/RGtk2/libs/RGtk2.dll':
>>
>>  LoadLibrary failure:  impossible to find the specified procedure
>>
>> Error: package/namespace load failed for 'RGtk2'
>>
>>>
>>
>> I checked in the directory
>>
>> C:/Programmi/R/R-2.5.0/library/RGtk2/libs/
>>
>> and the RGtk2.dll module does exist.
>> Any indication about how to solve this problem?
>> Giulio Barcaroli
>>
>


From h.wickham at gmail.com  Thu Jun 21 14:13:05 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 21 Jun 2007 14:13:05 +0200
Subject: [R] Overlaying lattice graphs (continued)
In-Reply-To: <4679F719.7020308@free.fr>
References: <4679F719.7020308@free.fr>
Message-ID: <f8e6ff050706210513r51fd9d28mb102a919e20499d6@mail.gmail.com>

Hi Sebastian,

I think you need to rearrange your data a bit.  Firstly, you need to
put observed on the same footing as the different models, so you would
have a new column in your data called value (previously observed and
predicted) and a new model type ("observed").  Then you could do:

xyplot(value ~ time | individauls, data=mydata, group=model)

Hadley


On 6/21/07, S?bastien <pomchip at free.fr> wrote:
> Dear R Users,
>
> I recently posted an email on this list  about the use of data.frame and
> overlaying multiple plots. Deepayan kindly indicated to me the
> panel.superposition command which worked perfectly in the context of the
> example I gave.
> I'd like to go a little bit further on this topic using a more complex
> dataset structure (actually the one I want to work on).
>
>  >mydata
>       Plot    Model    Individuals    Time        Observed
> Predicted
> 1    1        A           1                  0.05
> 10                    10.2
> 2    1        A           1                  0.10
> 20                    19.5
> etc...
> 10  1        B           1                  0.05         10
>          9.8
> 11  1        B           1                  0.10         20
>          20.2
> etc...
>
> There are p "levels" in mydata$Plot, m in mydata$Model, n in
> mydata$Individuals and t in mydata$Time (Note that I probably use the
> word levels improperly as all columns are not factors). Basically, this
> dataset summarizes the t measurements obtained in n individuals as well
> as the predicted values from m different modeling approaches (applied to
> all individuals). Therefore, the observations are repeated m times in
> the Observed columns, while the predictions appears only once for a
> given model an a given individual.
>
> What I want to write is a R batch file creating a Trellis graph, where
> each panel corresponds to one individual and contains the observations
> (as scatterplot) plus the predicted values for all models (as lines of
> different colors)... $Plot is just a token: it might be used to not
> overload graphs in case there are too many tested models. The fun part
> is that the values of p, m, n and t might vary from one dataset to the
> other, so everything has to be coded dynamically.
>
> For the plotting part I was thinking about having a loop in my code
> containing something like that:
>
> for (i in 1:nlevels(mydata$Model)) {
>
> subdata<-subset(mydata,mydata$Model=level(mydata$Model)[i])
> xyplot(subset(Observed + Predicted ~ Time | Individuals, data =
> subdata)       #plus additionnal formatting code
>
> }
>
> Unfortunately, this code simply creates a new Trellis plot instead of
> adding the model one by one on the panels. Any idea or link to a useful
> command will wellcome.
>
> Sebastien
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From pomchip at free.fr  Thu Jun 21 14:14:23 2007
From: pomchip at free.fr (=?ISO-8859-1?Q?S=E9bastien?=)
Date: Thu, 21 Jun 2007 08:14:23 -0400
Subject: [R] Overlaying lattice graphs (continued)
In-Reply-To: <4679F719.7020308@free.fr>
References: <4679F719.7020308@free.fr>
Message-ID: <467A6B9F.50502@free.fr>

Sorry, I have forgotten to tell that I work on R version 2.5.0 on 
Windows XP sp2.

S?bastien a ?crit :
> Dear R Users,
>
> I recently posted an email on this list  about the use of data.frame and 
> overlaying multiple plots. Deepayan kindly indicated to me the 
> panel.superposition command which worked perfectly in the context of the 
> example I gave.
> I'd like to go a little bit further on this topic using a more complex 
> dataset structure (actually the one I want to work on).
>
>  >mydata
>       Plot    Model    Individuals    Time        Observed          
> Predicted
> 1    1        A           1                  0.05         
> 10                    10.2
> 2    1        A           1                  0.10         
> 20                    19.5
> etc...
> 10  1        B           1                  0.05         10            
>          9.8
> 11  1        B           1                  0.10         20            
>          20.2
> etc...
>
> There are p "levels" in mydata$Plot, m in mydata$Model, n in 
> mydata$Individuals and t in mydata$Time (Note that I probably use the 
> word levels improperly as all columns are not factors). Basically, this 
> dataset summarizes the t measurements obtained in n individuals as well 
> as the predicted values from m different modeling approaches (applied to 
> all individuals). Therefore, the observations are repeated m times in 
> the Observed columns, while the predictions appears only once for a 
> given model an a given individual.
>
> What I want to write is a R batch file creating a Trellis graph, where 
> each panel corresponds to one individual and contains the observations 
> (as scatterplot) plus the predicted values for all models (as lines of 
> different colors)... $Plot is just a token: it might be used to not 
> overload graphs in case there are too many tested models. The fun part 
> is that the values of p, m, n and t might vary from one dataset to the 
> other, so everything has to be coded dynamically.
>
> For the plotting part I was thinking about having a loop in my code 
> containing something like that:
>
> for (i in 1:nlevels(mydata$Model)) {
>
> subdata<-subset(mydata,mydata$Model=level(mydata$Model)[i])
> xyplot(subset(Observed + Predicted ~ Time | Individuals, data = 
> subdata)       #plus additionnal formatting code
>
> }
>
> Unfortunately, this code simply creates a new Trellis plot instead of 
> adding the model one by one on the panels. Any idea or link to a useful 
> command will wellcome.
>
> Sebastien
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>


From maechler at stat.math.ethz.ch  Thu Jun 21 14:19:41 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 21 Jun 2007 14:19:41 +0200
Subject: [R] "if" within a function
In-Reply-To: <200706210618.l5L6IRSC030919@hypatia.math.ethz.ch>
References: <548b8d440706202227k14f0bed1j719868c595212d39@mail.gmail.com>
	<200706210618.l5L6IRSC030919@hypatia.math.ethz.ch>
Message-ID: <18042.27869.906888.129776@stat.math.ethz.ch>

>>>>> "HO" == Hong Ooi <Hong.Ooi at iag.com.au>
>>>>>     on Thu, 21 Jun 2007 15:49:42 +1000 writes:

    HO> R doesn't use the 'functionname = result' idiom to return a value from a
    HO> function. It looks like you're after:

    HO> aaa <- function(a)
    HO> {
    HO>   if(a == 1) return(1)
    HO>   if(a != 1) return(2)
    HO> }


    HO> or


    HO> aaa <- function(a)
    HO> {
    HO>   if(a == 1) 1
    HO>   else 2
    HO> }

    HO> see ?return

or to continue the "Variations on a theme" :

   aaa <- function(a)  if(a == 1) 1 else 2

(You don't need "{" .. "}" :
   some people argue you should
   always use them for defensive programming 
   where I would not use them in simple "one liners",
   but would use them otherwise
)

Martin Maechler, ETH Zurich


From pomchip at free.fr  Thu Jun 21 14:53:41 2007
From: pomchip at free.fr (=?ISO-8859-1?Q?S=E9bastien?=)
Date: Thu, 21 Jun 2007 08:53:41 -0400
Subject: [R] Overlaying lattice graphs (continued)
In-Reply-To: <f8e6ff050706210513r51fd9d28mb102a919e20499d6@mail.gmail.com>
References: <4679F719.7020308@free.fr>
	<f8e6ff050706210513r51fd9d28mb102a919e20499d6@mail.gmail.com>
Message-ID: <467A74D5.4090808@free.fr>

Hi Hadley,

Hopefully, my dataset won't be too hard to changed. Can I modify the 
aspect of each group using your code (symbols for observed and lines for 
predicted)?

Sebastien

hadley wickham a ?crit :
> Hi Sebastian,
>
> I think you need to rearrange your data a bit.  Firstly, you need to
> put observed on the same footing as the different models, so you would
> have a new column in your data called value (previously observed and
> predicted) and a new model type ("observed").  Then you could do:
>
> xyplot(value ~ time | individauls, data=mydata, group=model)
>
> Hadley
>
>
> On 6/21/07, S?bastien <pomchip at free.fr> wrote:
>> Dear R Users,
>>
>> I recently posted an email on this list  about the use of data.frame and
>> overlaying multiple plots. Deepayan kindly indicated to me the
>> panel.superposition command which worked perfectly in the context of the
>> example I gave.
>> I'd like to go a little bit further on this topic using a more complex
>> dataset structure (actually the one I want to work on).
>>
>>  >mydata
>>       Plot    Model    Individuals    Time        Observed
>> Predicted
>> 1    1        A           1                  0.05
>> 10                    10.2
>> 2    1        A           1                  0.10
>> 20                    19.5
>> etc...
>> 10  1        B           1                  0.05         10
>>          9.8
>> 11  1        B           1                  0.10         20
>>          20.2
>> etc...
>>
>> There are p "levels" in mydata$Plot, m in mydata$Model, n in
>> mydata$Individuals and t in mydata$Time (Note that I probably use the
>> word levels improperly as all columns are not factors). Basically, this
>> dataset summarizes the t measurements obtained in n individuals as well
>> as the predicted values from m different modeling approaches (applied to
>> all individuals). Therefore, the observations are repeated m times in
>> the Observed columns, while the predictions appears only once for a
>> given model an a given individual.
>>
>> What I want to write is a R batch file creating a Trellis graph, where
>> each panel corresponds to one individual and contains the observations
>> (as scatterplot) plus the predicted values for all models (as lines of
>> different colors)... $Plot is just a token: it might be used to not
>> overload graphs in case there are too many tested models. The fun part
>> is that the values of p, m, n and t might vary from one dataset to the
>> other, so everything has to be coded dynamically.
>>
>> For the plotting part I was thinking about having a loop in my code
>> containing something like that:
>>
>> for (i in 1:nlevels(mydata$Model)) {
>>
>> subdata<-subset(mydata,mydata$Model=level(mydata$Model)[i])
>> xyplot(subset(Observed + Predicted ~ Time | Individuals, data =
>> subdata)       #plus additionnal formatting code
>>
>> }
>>
>> Unfortunately, this code simply creates a new Trellis plot instead of
>> adding the model one by one on the panels. Any idea or link to a useful
>> command will wellcome.
>>
>> Sebastien
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


From marc_schwartz at comcast.net  Thu Jun 21 14:55:52 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Thu, 21 Jun 2007 07:55:52 -0500
Subject: [R] Need Help: User Defined R Functions in Sweave/Latex
In-Reply-To: <500c63990706202050p7546ffc9ua191df3eb0f99098@mail.gmail.com>
References: <500c63990706202050p7546ffc9ua191df3eb0f99098@mail.gmail.com>
Message-ID: <1182430552.3828.60.camel@Bellerophon.localdomain>

On Wed, 2007-06-20 at 22:50 -0500, M. Jankowski wrote:
> Dear all,
> 
> I want to start my post by expressing my sincere gratitude for all the
> help this group has given me in Sweave/Latex/R. The tools are
> excellent and so is the community!
> 
> On to the question.
> 
> My Sweave code is intended to make lots of plots and create a *.pdf
> document. Sweave is perfect for this. The only problem is that  I find
> myself using the same R code, within my Sweave input file over an
> over. I know about Latex macros and I can even get R functions,
> essentially used as subroutines, to sort of work. "\Sexpr{}" will not
> work because the R code I want to use over and over is in the R
> environment. I've tried numerous ways to tackle this process and could
> really use some help. If there is some easier way to do this please
> let me know!
> 
> This is the R function:
> basicplot <- function(x, nplots, sectionname){
> # Begin to make figure here
> file = paste("scatter",nplots, ".pdf", sep="")
> pdf(file = file,paper="special", width=6, height = 6)
> plot(x)
> dev.off()
> cat("\\begin{figure}\n")
> cat("\\includegraphics{",file,"}\n", sep="")
> cat("\\caption{", sectionname,"}\n", sep = "")
> cat("\\end{figure}\n")
> #End figure making
> }
> 
> The aim is to generate Latex code which will have some basic
> information as part of the caption. The trouble seems to be that the
> output from the function appears to latex as if it is protected R code
> when I really want to create output that pdflatex will act on.
> Essentially, the resulting *.pdf contains the lines output by the cat
> function in basicplot. Or:
> \begin{figure}
> \includegraphics{scatter1.pdf}
> \caption{myname}
> \end{figure}
> These lines are not in the environment acted by Latex. I tried a
> variant of the function where <<results=tex,echo=FALSE>> and received
> the same result. Below are the files *.Snw -> *.tex -> *.pdf and the
> output I received while compiling. If there is anything else I can
> give to help you help me just let me know. Thanks!
> 
> Matt


Matt,

I don't know if you have reviewed the Sweave manual, but section 3.4
provides insight into reusing named code chunks, as an alternative to
looping or creating LaTeX macros as proposed by Dieter. These can be
"nested" within other named code chunks and/or R code.

If you don't yet have the manual, it is available here from Fritz' site:

http://www.ci.tuwien.ac.at/~leisch/Sweave/Sweave-manual-20060104.pdf

You could consider using a figure chunk, if the sole output is the plot
and not text. That way you don't have to worry about explicitly cat()ing
the figure related LaTeX markup as you are doing above. Thus, the LaTeX
markup for things like captions will be in LaTeX sections of the .Rnw
file and you can use \Sexpr{}'s to include derived scalar values.

The preferred approach may be to an extent dependent upon whether your
final document will simply have several plots on one or more pages in
sequence, or whether you will need to have text between the plots, such
that you really need LaTeX sections between the figure/code chunks.

Back to Dieter's solution for a moment, take note of the Sweave FAQ
(also in the above manual), specifically FAQ A.9, which covers the issue
of figure chunks and multiple plots, proposing a looping approach
consistent with Dieter's.

I hope that this might give you some other insights into alternative
approaches.

HTH,

Marc Schwartz


From i.visser at uva.nl  Thu Jun 21 15:37:06 2007
From: i.visser at uva.nl (Ingmar Visser)
Date: Thu, 21 Jun 2007 15:37:06 +0200
Subject: [R] meta-analysis in R
In-Reply-To: <68E7981938EAF54F987AD3848A0A64160109C3B4@ka-mail01.dfu.local>
References: <68E7981938EAF54F987AD3848A0A64160109C3B4@ka-mail01.dfu.local>
Message-ID: <EE4494FD-C234-4F85-97C0-00F84031644A@uva.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070621/b9bea6b3/attachment.pl 

From steve.antos at gmail.com  Thu Jun 21 15:44:07 2007
From: steve.antos at gmail.com (Steve Antos)
Date: Thu, 21 Jun 2007 07:44:07 -0600
Subject: [R] MDS size limitations
Message-ID: <d78532210706210644y8ae9b6dg5dc05a0d9566a74c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070621/2929e431/attachment.pl 

From bernd.weiss at uni-koeln.de  Thu Jun 21 15:47:19 2007
From: bernd.weiss at uni-koeln.de (Bernd Weiss)
Date: Thu, 21 Jun 2007 15:47:19 +0200
Subject: [R] meta-analysis in R
In-Reply-To: <68E7981938EAF54F987AD3848A0A64160109C3B4@ka-mail01.dfu.local>
References: <68E7981938EAF54F987AD3848A0A64160109C3B4@ka-mail01.dfu.local>
Message-ID: <467A9D87.16138.1C50AD2@bernd.weiss.uni-koeln.de>

On 21 Jun 2007 at 12:09, Irene Mantzouni wrote:

Date sent:      	Thu, 21 Jun 2007 12:09:31 +0200
From:           	"Irene Mantzouni" <ima at difres.dk>
To:             	<r-help at stat.math.ethz.ch>
Subject:        	[R] meta-analysis in R

> I would like to combine time-series data to test for correlations
> and
> interactions using random and fixed effects meta-analysis.
> 
> So, I am looking for the right packages and documentation. 
> 
> I know about meta and rmeta packages of R. 
> 
> Are there any more? What are the diffrences in brief? 

Yes, there are some more packages for meta-analysis. 
help.search("meta-analysis") will answer your question.

Additionally, one should also mention the MiMa function, see below.

Most of the packages use a method of moments estimator; MiMa offers a 
wider range of estimation methods, e.g. ML or REML (see the MiMa 
documentation for more information).

> Can you please suggest some references that could be used as a guide
> for
> meta-analysis in R (or S-plus)? 
> 
>  

I know at least two references:

There is a chapter on meta-analysis in Everitt, Brian, und Torsten 
Hothorn, 2006: A handbook of statistical analyses using R. Boca 
Raton: Chapman & Hall/CRC. (see also <http://cran.r-
project.org/doc/vignettes/HSAUR/Ch_meta_analysis.pdf>)

See also my reply to Lucia Costanzo and my suggestion to use the  
MiMa-package  
<http://tolstoy.newcastle.edu.au/R/e2/help/07/06/19418.html>. 

HTH,

Bernd


From economics.guy at gmail.com  Thu Jun 21 15:53:40 2007
From: economics.guy at gmail.com (Economics Guy)
Date: Thu, 21 Jun 2007 09:53:40 -0400
Subject: [R] generating a new variable based on results of a by command
Message-ID: <da0aac0706210653r40de2dd5m7e6cd2d2ec321922@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070621/c6a0182b/attachment.pl 

From lamkhanhvns at yahoo.co.uk  Thu Jun 21 15:54:21 2007
From: lamkhanhvns at yahoo.co.uk (dala)
Date: Thu, 21 Jun 2007 06:54:21 -0700 (PDT)
Subject: [R] sorting data
Message-ID: <11233613.post@talk.nabble.com>


I have a 2 columns, Date and Number, in Excel. 
I copy and paste them into Notepad.
I can use scan() to import the file but how do I plot this data with Date as
the x-axis?
-- 
View this message in context: http://www.nabble.com/sorting-data-tf3958889.html#a11233613
Sent from the R help mailing list archive at Nabble.com.


From dimitris.rizopoulos at med.kuleuven.be  Thu Jun 21 16:00:36 2007
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Thu, 21 Jun 2007 16:00:36 +0200
Subject: [R] generating a new variable based on results of a by command
References: <da0aac0706210653r40de2dd5m7e6cd2d2ec321922@mail.gmail.com>
Message-ID: <011401c7b40c$8aec7cf0$0540210a@www.domain>

maybe you want to use ave(), e.g.,

f$sums <- ave(f$b, f$e, FUN = sum)


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Economics Guy" <economics.guy at gmail.com>
To: <r-help at stat.math.ethz.ch>
Sent: Thursday, June 21, 2007 3:53 PM
Subject: [R] generating a new variable based on results of a by 
command


>I have a matrix with a set of variables one of which is a factor. 
>Using by()
> I have calculated something about each group (say the sum). Now I 
> want to
> create a new variable in the original matrix that contains the 
> results of
> the by() for each observation that is in the corresponding group.
>
> For example I have:
>
> ---------
>
> a <-c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16)
>
> b <-c(7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22)
>
> e 
> <-c("A","B","C","D","E","F","A","B","C","D","E","F","D","E","F","A")
>
> f <-data.frame(e,a,b)
>
> # Calculate sum by group
>
> sums <- by(f, e, function(x) sum(x$b))
>
> -----------
>
> Now I would like to assign each observation in f a new variable 
> based on the
> results of the by(). I converted sums into a matrix and then tried 
> using
> match() and ifthen() but could not get it to work.
>
> Thanks,
>
> EG
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm


From tlumley at u.washington.edu  Thu Jun 21 16:01:03 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 21 Jun 2007 07:01:03 -0700 (PDT)
Subject: [R] model selection criteria in "regsubsets"
In-Reply-To: <200706210827.l5L8Reac017771@rm-rstar.sfu.ca>
References: <200706210827.l5L8Reac017771@rm-rstar.sfu.ca>
Message-ID: <Pine.LNX.4.64.0706210700120.10660@homer24.u.washington.edu>


The calculations are in summary.regsubsets.

Sending three copies of questions like this does not increase the chance 
of a response.

 	-thomas


On Thu, 21 Jun 2007, nlei at sfu.ca wrote:

> Hi All,
> 
> I used "regsubsets" in package "leaps" to do the model subset selection.
> I noticed the "bic" and "cp" criterias are both included in this
> function. But seems like they are not calculated by
> 
> "bic=-n*log(RSS/n)-(p+1)*log(n)" 
> and 
> "cp=(RSS/sigma_hat^2)-(n-2*p-2)" 
> 
> Could you please let me know what formula used for these two criterias?
> 
> Thank you !
> 
> Linda
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From h.wickham at gmail.com  Thu Jun 21 16:02:04 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 21 Jun 2007 16:02:04 +0200
Subject: [R] Overlaying lattice graphs (continued)
In-Reply-To: <467A74D5.4090808@free.fr>
References: <4679F719.7020308@free.fr>
	<f8e6ff050706210513r51fd9d28mb102a919e20499d6@mail.gmail.com>
	<467A74D5.4090808@free.fr>
Message-ID: <f8e6ff050706210702s5559a469w84849e9b946339b9@mail.gmail.com>

Sebastian,

You should be able to, but I don't know how to do it with lattice.  In
ggplot (http://had.co.nz/ggplot2) you would do it as follows:

ggplot(mydata, aes(x = time, y = value, colour=model)) +
geom_point(subset(data, model != "observed")) +
geom_line((subset(data, model == "observed")) +
facet_grid(. ~ individuals)

or if you only wanted the models coloured:

ggplot(mydata, aes(x = time, y = value)) +
geom_point(subset(data, model != "observed"), aes(colour=model)) +
geom_line((subset(data, model == "observed")) +
facet_grid(. ~ individuals)

Although the way the panels are arranged is probably suboptimal if you
have many individuals.  It's something I plan to fix in the future, so
that  + facet_wrap(individuals) would give you a display like lattice
does.

Hadley


On 6/21/07, S?bastien <pomchip at free.fr> wrote:
> Hi Hadley,
>
> Hopefully, my dataset won't be too hard to changed. Can I modify the
> aspect of each group using your code (symbols for observed and lines for
> predicted)?
>
> Sebastien
>
> hadley wickham a ?crit :
> > Hi Sebastian,
> >
> > I think you need to rearrange your data a bit.  Firstly, you need to
> > put observed on the same footing as the different models, so you would
> > have a new column in your data called value (previously observed and
> > predicted) and a new model type ("observed").  Then you could do:
> >
> > xyplot(value ~ time | individauls, data=mydata, group=model)
> >
> > Hadley
> >
> >
> > On 6/21/07, S?bastien <pomchip at free.fr> wrote:
> >> Dear R Users,
> >>
> >> I recently posted an email on this list  about the use of data.frame and
> >> overlaying multiple plots. Deepayan kindly indicated to me the
> >> panel.superposition command which worked perfectly in the context of the
> >> example I gave.
> >> I'd like to go a little bit further on this topic using a more complex
> >> dataset structure (actually the one I want to work on).
> >>
> >>  >mydata
> >>       Plot    Model    Individuals    Time        Observed
> >> Predicted
> >> 1    1        A           1                  0.05
> >> 10                    10.2
> >> 2    1        A           1                  0.10
> >> 20                    19.5
> >> etc...
> >> 10  1        B           1                  0.05         10
> >>          9.8
> >> 11  1        B           1                  0.10         20
> >>          20.2
> >> etc...
> >>
> >> There are p "levels" in mydata$Plot, m in mydata$Model, n in
> >> mydata$Individuals and t in mydata$Time (Note that I probably use the
> >> word levels improperly as all columns are not factors). Basically, this
> >> dataset summarizes the t measurements obtained in n individuals as well
> >> as the predicted values from m different modeling approaches (applied to
> >> all individuals). Therefore, the observations are repeated m times in
> >> the Observed columns, while the predictions appears only once for a
> >> given model an a given individual.
> >>
> >> What I want to write is a R batch file creating a Trellis graph, where
> >> each panel corresponds to one individual and contains the observations
> >> (as scatterplot) plus the predicted values for all models (as lines of
> >> different colors)... $Plot is just a token: it might be used to not
> >> overload graphs in case there are too many tested models. The fun part
> >> is that the values of p, m, n and t might vary from one dataset to the
> >> other, so everything has to be coded dynamically.
> >>
> >> For the plotting part I was thinking about having a loop in my code
> >> containing something like that:
> >>
> >> for (i in 1:nlevels(mydata$Model)) {
> >>
> >> subdata<-subset(mydata,mydata$Model=level(mydata$Model)[i])
> >> xyplot(subset(Observed + Predicted ~ Time | Individuals, data =
> >> subdata)       #plus additionnal formatting code
> >>
> >> }
> >>
> >> Unfortunately, this code simply creates a new Trellis plot instead of
> >> adding the model one by one on the panels. Any idea or link to a useful
> >> command will wellcome.
> >>
> >> Sebastien
> >>
> >> ______________________________________________
> >> R-help at stat.math.ethz.ch mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >
>


From Thierry.ONKELINX at inbo.be  Thu Jun 21 16:06:57 2007
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 21 Jun 2007 16:06:57 +0200
Subject: [R] sorting data
In-Reply-To: <11233613.post@talk.nabble.com>
Message-ID: <2E9C414912813E4EB981326983E0A104031A9488@inboexch.inbo.be>

Why don't you use a package like RODBC and read the data directly from
the Excel file? Then you probably won't have to worry on how to get the
dates in the right format.

Another, maybe easier, solution is to export the Excel to CSV and then
use read.csv().

Cheers,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium
tel. + 32 54/436 185
Thierry.Onkelinx op inbo.be
www.inbo.be 

Do not put your faith in what statistics say until you have carefully
considered what they do not say.  ~William W. Watt
A statistical analysis, properly conducted, is a delicate dissection of
uncertainties, a surgery of suppositions. ~M.J.Moroney

 

> -----Oorspronkelijk bericht-----
> Van: r-help-bounces op stat.math.ethz.ch 
> [mailto:r-help-bounces op stat.math.ethz.ch] Namens dala
> Verzonden: donderdag 21 juni 2007 15:54
> Aan: r-help op stat.math.ethz.ch
> Onderwerp: [R] sorting data
> 
> 
> I have a 2 columns, Date and Number, in Excel. 
> I copy and paste them into Notepad.
> I can use scan() to import the file but how do I plot this 
> data with Date as the x-axis?
> --
> View this message in context: 
> http://www.nabble.com/sorting-data-tf3958889.html#a11233613
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help op stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mikewlcheung at gmail.com  Thu Jun 21 16:24:34 2007
From: mikewlcheung at gmail.com (Mike Cheung)
Date: Thu, 21 Jun 2007 22:24:34 +0800
Subject: [R] meta-analysis in R
In-Reply-To: <467A9D87.16138.1C50AD2@bernd.weiss.uni-koeln.de>
References: <68E7981938EAF54F987AD3848A0A64160109C3B4@ka-mail01.dfu.local>
	<467A9D87.16138.1C50AD2@bernd.weiss.uni-koeln.de>
Message-ID: <98823c0a0706210724v77b82b2dq8f3fd97ea75e0045@mail.gmail.com>

Dear Bernd,

Please be careful in reading the example of meta-regression (12.4) in
<http://cran.r-project.org/doc/vignettes/HSAUR/Ch_meta_analysis.pdf>.

In that example, the variance component was estimated under a model
without any covariate. Then the estimated variance component was used
as the variance component in the meta-regression with covariates.
Since the variance component is based on the model without any
covariate, it should be overestimated for a model with covariate. I
have emailed the authors about this issue.

A better approach is to use the MiMa function provided by Wolfgang Viechtbauer.

Regards,
Mike
-- 
---------------------------------------------------------------------
 Mike W.L. Cheung               Phone: (65) 6516-3702
 Department of Psychology       Fax:   (65) 6773-1843
 National University of Singapore
 http://courses.nus.edu.sg/course/psycwlm/internet/
---------------------------------------------------------------------


On 6/21/07, Bernd Weiss <bernd.weiss at uni-koeln.de> wrote:
> On 21 Jun 2007 at 12:09, Irene Mantzouni wrote:
>
> Date sent:              Thu, 21 Jun 2007 12:09:31 +0200
> From:                   "Irene Mantzouni" <ima at difres.dk>
> To:                     <r-help at stat.math.ethz.ch>
> Subject:                [R] meta-analysis in R
>
> > I would like to combine time-series data to test for correlations
> > and
> > interactions using random and fixed effects meta-analysis.
> >
> > So, I am looking for the right packages and documentation.
> >
> > I know about meta and rmeta packages of R.
> >
> > Are there any more? What are the diffrences in brief?
>
> Yes, there are some more packages for meta-analysis.
> help.search("meta-analysis") will answer your question.
>
> Additionally, one should also mention the MiMa function, see below.
>
> Most of the packages use a method of moments estimator; MiMa offers a
> wider range of estimation methods, e.g. ML or REML (see the MiMa
> documentation for more information).
>
> > Can you please suggest some references that could be used as a guide
> > for
> > meta-analysis in R (or S-plus)?
> >
> >
>
> I know at least two references:
>
> There is a chapter on meta-analysis in Everitt, Brian, und Torsten
> Hothorn, 2006: A handbook of statistical analyses using R. Boca
> Raton: Chapman & Hall/CRC. (see also <http://cran.r-
> project.org/doc/vignettes/HSAUR/Ch_meta_analysis.pdf>)
>
> See also my reply to Lucia Costanzo and my suggestion to use the
> MiMa-package
> <http://tolstoy.newcastle.edu.au/R/e2/help/07/06/19418.html>.
>
> HTH,
>
> Bernd
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mjankowski at gmail.com  Thu Jun 21 16:37:20 2007
From: mjankowski at gmail.com (M. Jankowski)
Date: Thu, 21 Jun 2007 09:37:20 -0500
Subject: [R] Need Help: User Defined R Functions in Sweave/Latex
In-Reply-To: <1182430552.3828.60.camel@Bellerophon.localdomain>
References: <500c63990706202050p7546ffc9ua191df3eb0f99098@mail.gmail.com>
	<1182430552.3828.60.camel@Bellerophon.localdomain>
Message-ID: <500c63990706210737yecfd1b5s8e4c5b1605ae2ebd@mail.gmail.com>

> Back to Dieter's solution for a moment, take note of the Sweave FAQ
> (also in the above manual), specifically FAQ A.9, which covers the issue
> of figure chunks and multiple plots, proposing a looping approach
> consistent with Dieter's.
>
> I hope that this might give you some other insights into alternative
> approaches.
>
> HTH,
>
> Marc Schwartz
>

Marc,

You sure did help me. I reviewed A.9 and found that I simply needed to set:

<< results=tex, echo=false >>=

in the initial function call. Then the route I was pursuing worked smashingly.

The rest of your post has me thinking about my approach. I have more
than enough data, in my mind at least, to justify the extra effort
(and possible confusion) of including captions. I'll need to look at
the options for the "pdf" function to see if it already has the
functionality I am looking for.

Thank you very much for the nice reply to my post!

Matt


From mahima.hada at gmail.com  Thu Jun 21 16:37:46 2007
From: mahima.hada at gmail.com (Mahima Hada)
Date: Thu, 21 Jun 2007 10:37:46 -0400
Subject: [R] Multi-variate Probit model using Bayesm in R
Message-ID: <8b88484c0706210737s3c92b155xa33644a704bca4c2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070621/911d24e2/attachment.pl 

From m.cortina at ich.ucl.ac.uk  Thu Jun 21 16:47:01 2007
From: m.cortina at ich.ucl.ac.uk (Mario Cortina)
Date: Thu, 21 Jun 2007 15:47:01 +0100
Subject: [R] unknown type 63, perhaps written by later version of R
Message-ID: <002101c7b413$06ae4110$cbf652c2@pc246203>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070621/2875391a/attachment.pl 

From ripley at stats.ox.ac.uk  Thu Jun 21 16:51:34 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 21 Jun 2007 15:51:34 +0100 (BST)
Subject: [R] MDS size limitations
In-Reply-To: <d78532210706210644y8ae9b6dg5dc05a0d9566a74c@mail.gmail.com>
References: <d78532210706210644y8ae9b6dg5dc05a0d9566a74c@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0706211530480.14246@gannet.stats.ox.ac.uk>

On Thu, 21 Jun 2007, Steve Antos wrote:

> What are the limitations on size of matrix for MDS functions?

MDS works with a dissimilarity, not a matrix (neither conceptually nor in 
most R implementations, which typically use an object of class "dist").
It is better to think in terms of the number of objects 'n' and the number 
of dimensions of the representation (which I guess you mean as 2).

There are O(n^2) dissimilarities to be considered, and most of the 
algorithms appear to be slightly superlinear in that number. n=1000 runs 
in isoMDS in about a minute on my laptop, using about 75Mb of memory, and 
about 10 secs in sammon or cmdscale.  (Highly non-Euclidean 
dissimilarities are likely to be slower.)

Even 1000 objects is a lot to be considering for what is primarily a 
visualization technique.

Cruder forms of MDS such as Kohonen mapping are able to handle much larger 
datasets (but reveal less about them).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From economics.guy at gmail.com  Thu Jun 21 17:10:36 2007
From: economics.guy at gmail.com (Economics Guy)
Date: Thu, 21 Jun 2007 11:10:36 -0400
Subject: [R] generating a new variable based on results of a by command
In-Reply-To: <011401c7b40c$8aec7cf0$0540210a@www.domain>
References: <da0aac0706210653r40de2dd5m7e6cd2d2ec321922@mail.gmail.com>
	<011401c7b40c$8aec7cf0$0540210a@www.domain>
Message-ID: <da0aac0706210810u71c305abs50c67e5e5f66840e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070621/3994cf63/attachment.pl 

From rvaradhan at jhmi.edu  Thu Jun 21 17:14:22 2007
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Thu, 21 Jun 2007 11:14:22 -0400
Subject: [R] Creatiing an R package for solving nonlinear system
	of	equations was: RE: finding roots of multivariate equation
In-Reply-To: <001501c7b381$2d5b4de0$7c94100a@win.ad.jhu.edu>
References: <1182361042.467965d24abac@www.usherbrooke.ca>
	<001501c7b381$2d5b4de0$7c94100a@win.ad.jhu.edu>
Message-ID: <000001c7b416$d8d0c7f0$7c94100a@win.ad.jhu.edu>

Hi,

I have written a simple function to solve a system of nonlinear equations. I
have called it nlsolve().  It actually minimizes the squared-norm of the set
of functions by calling optim().  It uses the BFGS algorithm within optim().
Apart from this restriction, the user can pass all the arguments available
in optim().  All the control parameters can be passed as in the call to
optim().  I have attached a text file containing the source for nlsolve()
and also a number of test problems illustrating the use of nlsolve().  Any
feedback and suggestions to improve it are welcome.

Hope this is useful.

Best,
Ravi.

----------------------------------------------------------------------------
-------

Ravi Varadhan, Ph.D.

Assistant Professor, The Center on Aging and Health

Division of Geriatric Medicine and Gerontology 

Johns Hopkins University

Ph: (410) 502-2619

Fax: (410) 614-9625

Email: rvaradhan at jhmi.edu

Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html



----------------------------------------------------------------------------
--------

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Ravi Varadhan
Sent: Wednesday, June 20, 2007 5:23 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Creatiing an R package for solving nonlinear system of
equations was: RE: finding roots of multivariate equation

Hi All,

Replying to this and numerous other requests in the past has made me realize
that a nonlinear solver is very much needed for R users.  I have
successfully used a nonlinear solver based on the spectral gradient method,
in FORTRAN.  I can readily translate that to R and make it available as an R
function, but what I would really like to do is to make that into a package.
I can provide the R function and several test examples.  But I am not good
at creating a good/reliable package.  So, it would be ideal if one of the R
gurus is interested in collaborating with me on this project.  Any one
interested?

Ravi.
----------------------------------------------------------------------------
-------

Ravi Varadhan, Ph.D.

Assistant Professor, The Center on Aging and Health

Division of Geriatric Medicine and Gerontology 

Johns Hopkins University

Ph: (410) 502-2619

Fax: (410) 614-9625

Email: rvaradhan at jhmi.edu

Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html



----------------------------------------------------------------------------
--------

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Bill Shipley
Sent: Wednesday, June 20, 2007 1:37 PM
To: r-help at stat.math.ethz.ch
Subject: [R] finding roots of multivariate equation

Hello,
I want to find the roots of an equation in two variables.  I am aware of the
uniroot function, which can do this for a function with a single variable
(as I
understand it...) but cannot find a function that does this for an equation
with more than one variable.  I am looking for something implementing
similar
to a Newton-Raphson algorithm.
Thanks.

-- 
Bill Shipley
North American Editor for Annals of Botany
Subject Editor for Ecology
D?partement de biologie
Universit? de Sherbrooke
Sherbrooke (Qu?bec) J1K 2R9
Canada

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From raquelrguima at gmail.com  Thu Jun 21 17:35:29 2007
From: raquelrguima at gmail.com (=?ISO-8859-1?Q?Raquel_Guimar=E3es?=)
Date: Thu, 21 Jun 2007 12:35:29 -0300
Subject: [R] How to weight cases in R
Message-ID: <92e17d080706210835q35e7ae7boc9bab5e05769a1b7@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070621/41e5f7c9/attachment.pl 

From br44114 at gmail.com  Thu Jun 21 17:41:52 2007
From: br44114 at gmail.com (bogdan romocea)
Date: Thu, 21 Jun 2007 11:41:52 -0400
Subject: [R] Speed up R
Message-ID: <8d5a36350706210841td171dc2n9136e1f2b05afda9@mail.gmail.com>

Don't rush to buy new hardware yet (other than perhaps more RAM for
your existing desktop). First of all you should make sure that your R
code can't be made any faster. (I've seen cases where careful
re-writes increased speed by a factor of 10 or more.) There are some
rules (such as pre-allocate enough memory for vectors/lists, use
matrices instead of data frames etc) and tools (?Rprof, ?Sys.time)
that can help a lot. Check the manuals and the archives, for example
http://article.gmane.org/gmane.comp.lang.r.general/48800


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Robert McFadden
> Sent: Tuesday, June 19, 2007 4:51 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Speed up R
>
> Dear R Users,
> I hope that there is someone who has an experience with a
> problem that I
> describe below and will help me.
> I must buy new desktop computer and I'm wondering which
> processor to choose
> if my only aim is to speed up R. I would like to reduce a
> simulation time -
> sometimes it takes days. I consider buying one of them (I'm
> working under
> Win XP 32 bit):
> 1. Intel Core2 Duo E6700 2.67 GHz
> 2. Dual-Core Intel Xeon processor 3070 - 2,66 GHz
> 3. AMD Athlon 64 X2 6000+
> Or simple Pentium 4?
>
> I'm very confused because I'm not sure whether R takes
> advantage dual-core
> or not. If not, probably Athlon would be better, wouldn't be?
> I would appreciate any help.
> Rob
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From s.henderson at ucl.ac.uk  Thu Jun 21 19:01:06 2007
From: s.henderson at ucl.ac.uk (Stephen Henderson)
Date: Thu, 21 Jun 2007 18:01:06 +0100
Subject: [R] FW: Suse RPM installation problem
Message-ID: <61B482B74D6EE443B90356E080476E34DEE559@exc2.cruciform.wibr.ucl.ac.uk>

Hello 

I am trying to install the R RPM for Suse 10.0 on an x86_64 PC. However
I am failing a dependency for  "libpng12.so.0" straight away



    PC5-140:/home/rmgzshd # rpm -i R-base-2.5.0-2.1.x86_64.rpm
    error: Failed dependencies:
    libpng12.so.0(PNG12_0)(64bit) is needed by R-base-2.5.0-2.1.x86_64

I do seem to have this file

    PC5-140:/home/rmgzshd # whereis libpng12.so.0
    libpng12.so: /usr/lib/libpng12.so.0 /usr/local/lib/libpng12.so 

but presuming that it is not the 64bit version mentioned I went looking
for a 64 bit version but could not find it through google.

However reading the Installation manual I noted that libpng is mention
in the context of a source build. I therefore downloaded "libpng-1.2.18"
(v-1.2.8 or later is specified in the manual) and succesfully compiled
this. This did not however help with my problem.

Any suggestions?

Thanks
Stephen Henderson
 

**********************************************************************
This email and any files transmitted with it are confidentia...{{dropped}}


From f.calboli at imperial.ac.uk  Thu Jun 21 19:10:07 2007
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Thu, 21 Jun 2007 18:10:07 +0100
Subject: [R] working with fractions
Message-ID: <467AB0EF.4060802@imperial.ac.uk>

Hi All,

I am writing a fucntion where I would like to use fractions for all the 
(numerous) passages.

Is there a way of creating an environment *within a fucntion* so that all the 
numbers/calculations are fractions?

Best,

Fede


-- 
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St Mary's Campus
Norfolk Place, London W2 1PG

Tel  +44 (0)20 7594 1602     Fax (+44) 020 7594 3193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com


From Mike.Lawrence at DAL.CA  Thu Jun 21 19:29:31 2007
From: Mike.Lawrence at DAL.CA (Mike Lawrence)
Date: Thu, 21 Jun 2007 14:29:31 -0300
Subject: [R] how to create cumulative histogram from two independent
	variables?
In-Reply-To: <7cced4ed0706201302y3df7a375hbcf775b58a0cb2bc@mail.gmail.com>
References: <7cced4ed0706201302y3df7a375hbcf775b58a0cb2bc@mail.gmail.com>
Message-ID: <1FC599EA-EA00-4F66-A202-0A9F94D2855C@DAL.CA>


?plot.ecdf

plot.ecdf(rnorm(100),rexp(100))

On 20-Jun-07, at 5:02 PM, Jose Borreguero wrote:

> Hi all,
> I am extremely newbie to R. Can anybody jump-start me with any  
> clues as to
> how do I get a cumulative histogram from two independent variables,
> cumhist(X,Y) ?
> -jose
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Mike Lawrence
Graduate Student, Department of Psychology, Dalhousie University

Website: http://memetic.ca

Public calendar: http://icalx.com/public/informavore/Public

"The road to wisdom? Well, it's plain and simple to express:
Err and err and err again, but less and less and less."
	- Piet Hein


From p.dalgaard at biostat.ku.dk  Thu Jun 21 19:34:55 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 21 Jun 2007 19:34:55 +0200
Subject: [R] FW: Suse RPM installation problem
In-Reply-To: <61B482B74D6EE443B90356E080476E34DEE559@exc2.cruciform.wibr.ucl.ac.uk>
References: <61B482B74D6EE443B90356E080476E34DEE559@exc2.cruciform.wibr.ucl.ac.uk>
Message-ID: <467AB6BF.9090808@biostat.ku.dk>

Stephen Henderson wrote:
> Hello 
>
> I am trying to install the R RPM for Suse 10.0 on an x86_64 PC. However
> I am failing a dependency for  "libpng12.so.0" straight away
>
>
>
>     PC5-140:/home/rmgzshd # rpm -i R-base-2.5.0-2.1.x86_64.rpm
>     error: Failed dependencies:
>     libpng12.so.0(PNG12_0)(64bit) is needed by R-base-2.5.0-2.1.x86_64
>
> I do seem to have this file
>
>     PC5-140:/home/rmgzshd # whereis libpng12.so.0
>     libpng12.so: /usr/lib/libpng12.so.0 /usr/local/lib/libpng12.so 
>
> but presuming that it is not the 64bit version mentioned I went looking
> for a 64 bit version but could not find it through google.
>
> However reading the Installation manual I noted that libpng is mention
> in the context of a source build. I therefore downloaded "libpng-1.2.18"
> (v-1.2.8 or later is specified in the manual) and succesfully compiled
> this. This did not however help with my problem.
>
> Any suggestions?
>
>   
I have

viggo:~/>rpm -qf /usr/lib/libpng12.so.0
libpng-32bit-1.2.12-25
viggo:~/>rpm -qf /usr/lib64/libpng12.so.0
libpng-1.2.12-25
viggo:~/>rpm -q R-base
R-base-2.5.0-2.1


> Thanks
> Stephen Henderson
>  
>
> **********************************************************************
> This email and any files transmitted with it are confidentia...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From maitra at iastate.edu  Thu Jun 21 19:51:00 2007
From: maitra at iastate.edu (maitra at iastate.edu)
Date: Thu, 21 Jun 2007 12:51:00 -0500 (CDT)
Subject: [R] using lme on multiple datasets in one shot
Message-ID: <0511221510741711@webmail.iastate.edu>

Dear list,

I would like to do a huge number of lme's using the same design matrix
(and fixed and random effects). Is it possible to do this efficiently?
Doing otherwise is not an option for my example.

Basically, I am wanting to do the following which is possible using lm:

X <- matrix(rnorm(50),10,5)
Y <- matrix(rnorm(50),10,5)
lm(Y~X)  

with lme. Any suggestions?

Many thanks and best wishes,
Ranjan


From detlef.steuer at hsu-hamburg.de  Thu Jun 21 19:49:34 2007
From: detlef.steuer at hsu-hamburg.de (Detlef Steuer)
Date: Thu, 21 Jun 2007 19:49:34 +0200
Subject: [R] FW: Suse RPM installation problem
In-Reply-To: <61B482B74D6EE443B90356E080476E34DEE559@exc2.cruciform.wibr.ucl.ac.uk>
References: <61B482B74D6EE443B90356E080476E34DEE559@exc2.cruciform.wibr.ucl.ac.uk>
Message-ID: <20070621194934.7731ef04@linux.site>

On Thu, 21 Jun 2007 18:01:06 +0100
"Stephen Henderson" <s.henderson at ucl.ac.uk> wrote:

> Hello 
> 
> I am trying to install the R RPM for Suse 10.0 on an x86_64 PC. However
> I am failing a dependency for  "libpng12.so.0" straight away

Hi Stephen,


if you add 

http://software.opensuse.org/download/home:/dsteuer/SUSE_Linux_10.0/

as installation source, dependencies should get resolved automatically.

Hth
Detlef

> 
> 
> 
>     PC5-140:/home/rmgzshd # rpm -i R-base-2.5.0-2.1.x86_64.rpm
>     error: Failed dependencies:
>     libpng12.so.0(PNG12_0)(64bit) is needed by R-base-2.5.0-2.1.x86_64
> 
> I do seem to have this file
> 
>     PC5-140:/home/rmgzshd # whereis libpng12.so.0
>     libpng12.so: /usr/lib/libpng12.so.0 /usr/local/lib/libpng12.so 
> 
> but presuming that it is not the 64bit version mentioned I went looking
> for a 64 bit version but could not find it through google.
> 
> However reading the Installation manual I noted that libpng is mention
> in the context of a source build. I therefore downloaded "libpng-1.2.18"
> (v-1.2.8 or later is specified in the manual) and succesfully compiled
> this. This did not however help with my problem.
> 
> Any suggestions?
> 
> Thanks
> Stephen Henderson
>  
> 
> **********************************************************************
> This email and any files transmitted with it are confidentia...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
"Keinen Gedanken zweimal denken, au?er er ist sch?n." Unbekannte Quelle


From birgit.lemcke at systbot.uzh.ch  Thu Jun 21 19:56:54 2007
From: birgit.lemcke at systbot.uzh.ch (Birgit Lemcke)
Date: Thu, 21 Jun 2007 19:56:54 +0200
Subject: [R] Distance function
Message-ID: <EFCBC842-6A69-48E1-A8B4-1C5BCAAC669F@systbot.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070621/98fe7848/attachment.pl 

From msubianto at gmail.com  Thu Jun 21 19:57:30 2007
From: msubianto at gmail.com (Muhammad Subianto)
Date: Thu, 21 Jun 2007 19:57:30 +0200
Subject: [R] working with fractions
In-Reply-To: <467AB0EF.4060802@imperial.ac.uk>
References: <467AB0EF.4060802@imperial.ac.uk>
Message-ID: <467ABC0A.1030802@gmail.com>

Federico Calboli wrote:
> Hi All,
>
> I am writing a fucntion where I would like to use fractions for all the 
> (numerous) passages.
>
> Is there a way of creating an environment *within a fucntion* so that all the 
> numbers/calculations are fractions?
>
> Best,
>
> Fede
>
>
>   
Maybe like this:

 > library(MASS)
 > as.fractions(c(0, 0.15, 0.8266667, .066666, 0.2666666))
[1]     0  3/20 62/75  1/15  4/15
 >

Regards, Muhammad Subianto


From f.calboli at imperial.ac.uk  Thu Jun 21 20:04:55 2007
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Thu, 21 Jun 2007 19:04:55 +0100
Subject: [R] working with fractions
In-Reply-To: <467ABC0A.1030802@gmail.com>
References: <467AB0EF.4060802@imperial.ac.uk> <467ABC0A.1030802@gmail.com>
Message-ID: <467ABDC7.1090001@imperial.ac.uk>

Muhammad Subianto wrote:

>  > library(MASS)
>  > as.fractions(c(0, 0.15, 0.8266667, .066666, 0.2666666))
> [1]     0  3/20 62/75  1/15  4/15

Seems to make things a bit too slow, even though I get a good increase in precision.

Fede

-- 
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St Mary's Campus
Norfolk Place, London W2 1PG

Tel  +44 (0)20 7594 1602     Fax (+44) 020 7594 3193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com


From sabya23 at gmail.com  Thu Jun 21 20:07:53 2007
From: sabya23 at gmail.com (spime)
Date: Thu, 21 Jun 2007 11:07:53 -0700 (PDT)
Subject: [R] How to hide axis interval values in a plot
Message-ID: <11238540.post@talk.nabble.com>




>plot(cars)

this shows a plot having interval values of axes (x-axis:5-25;
y-axis:0-120). I want to hide these values. is there any way?
-- 
View this message in context: http://www.nabble.com/How-to-hide-axis-interval-values-in-a-plot-tf3960418.html#a11238540
Sent from the R help mailing list archive at Nabble.com.


From gavin.simpson at ucl.ac.uk  Thu Jun 21 20:22:35 2007
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Thu, 21 Jun 2007 19:22:35 +0100
Subject: [R] Distance function
In-Reply-To: <EFCBC842-6A69-48E1-A8B4-1C5BCAAC669F@systbot.uzh.ch>
References: <EFCBC842-6A69-48E1-A8B4-1C5BCAAC669F@systbot.uzh.ch>
Message-ID: <1182450155.26435.33.camel@gsimpson.geog.ucl.ac.uk>

On Thu, 2007-06-21 at 19:56 +0200, Birgit Lemcke wrote:
> Hello you all from the R Help mailing list!
> 
> I am working on a PowerBook with Mac Os X and use R 2.5.0.
> I used the distance function from the analogue package to perform a  
> similarity analysis using the Gowers Index and weighted Variables.
> My variables are bivariate data and measurements as well as interval  
> data transformed into minimum and maximum variables.
> I used this Code:
> 
> Dist.Gowa<-distance(Table1a ,Table0a ,method ="mixed", weights
                                                         ^^^^^^^^
>  
> (weighting),R = NULL )
   ^^^^^^^^^^^
Something is not right there (^^^^) is this exactly what you typed?

You should not send questions about contributed packages to the list ---
as detailed in the posting guide. Without seeing Table1a and Table0a, it
is hard to say why this is failing - I suspect something about the
structure of the two data frames is throwing the function off.

If you can, send me that data ***off-list*** and I will take a look for
you, but as I'm teaching all day tomorrow, it won't happen till after
the weekend now.

HTH

G

> 
> 
> weighting is a vector created by this code:
> 
>   (weighting<- c 
> (1/3,1/3,1/3,1/2,1/2,1/2,1/2,1/2,1/2,1/4,1/4,1/4,1/4,1/7,1/7,1/7,1/7,1/7 
> , 
> 1/7,1/7,1/3,1/3,1/3,1/5,1/5,1/5,1/5,1/5,1/9,1/9,1/9,1/9,1/9,1/9,1/9,1/9, 
> 1/9,1/5,1/5,1/5,1/5,1/5,1/7,1/7,1/7,1/7,1/7,1/7,1/7,1/7,1/7,1/7,1/7,1/7, 
> 1/7,1/7,1/5,1/5,1/5,1/5,1/5,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1, 
> 1,1))
> It contains the weightings for the variables of the two data tables.
> 
> My data tables look like this:
> 
> 
> Anth_cap1        8.0  NA   NA  4.0  5.0  1  1  3.0  5.0  2.4  4.5  5   
> 5  2  2  2  3  1  1  1  1
> Anth_crin1       5.0  NA   NA  3.5 11.0  1  1  3.0 10.0  2.0  4.5  3   
> 4  2  2  3  3  1  1  2  3
> Anth_eck1        7.0  NA   NA  6.0 12.0  1  1  6.0 11.0  2.0  3.0  3   
> 5  2  2  3  3  1  1  1  2
> 
> At the end of the analysis I get always this message:
> 
> 1: $ operator is deprecated for atomic vectors, returning NULL in:  
> object$na.action
> 2: $ operator is deprecated for atomic vectors, returning NULL in:  
> object$weights
> 
> Can anybody explain me what this means?
> 
> Does anybody know if I have to standardize my measurements. As I  
> understood this is included in Gowers Index. If not is there a  
> function with different options of standardization more than rescaler  
> from the reshape package provides?
> 
> Thanks for your help in advance.
> 
> Greetings
> 
> Birgit
> 
> Birgit Lemcke
> Institut fr Systematische Botanik
> Zollikerstrasse 107
> CH-8008 Zrich
> Switzerland
> Ph: +41 (0)44 634 8351
> birgit.lemcke at systbot.uzh.ch
> 
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Gavin Simpson                 [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From marc_schwartz at comcast.net  Thu Jun 21 20:38:39 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Thu, 21 Jun 2007 13:38:39 -0500
Subject: [R] How to hide axis interval values in a plot
In-Reply-To: <11238540.post@talk.nabble.com>
References: <11238540.post@talk.nabble.com>
Message-ID: <1182451119.3705.7.camel@Bellerophon.localdomain>

On Thu, 2007-06-21 at 11:07 -0700, spime wrote:
> 
> 
> >plot(cars)
> 
> this shows a plot having interval values of axes (x-axis:5-25;
> y-axis:0-120). I want to hide these values. is there any way?

  plot(cars, axes = FALSE)

If you still want the box around the plot region, follow the above with:

  box()

or use:

  plot(cars, xaxt = "n", yaxt = "n")

See ?plot.default and ?par for more information and standard arguments
for plots.

If you want axes, but using values and tick marks that you define as
opposed to the defaults, see ?axis

HTH,

Marc Schwartz


From milton_ruser at yahoo.com.br  Thu Jun 21 16:48:58 2007
From: milton_ruser at yahoo.com.br (Milton Cezar Ribeiro)
Date: Thu, 21 Jun 2007 07:48:58 -0700 (PDT)
Subject: [R] Generating vetor (shapefiles) from AscGrid raster in R
Message-ID: <405017.3092.qm@web56612.mail.re3.yahoo.com>

Um texto embutido e sem conjunto de caracteres especificado associado...
Nome: n?o dispon?vel
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070621/e80284de/attachment.pl 

From borreguero at gmail.com  Thu Jun 21 20:48:57 2007
From: borreguero at gmail.com (Jose Borreguero)
Date: Thu, 21 Jun 2007 14:48:57 -0400
Subject: [R] how to create cumulative histogram from two independent
	variables?
In-Reply-To: <1FC599EA-EA00-4F66-A202-0A9F94D2855C@DAL.CA>
References: <7cced4ed0706201302y3df7a375hbcf775b58a0cb2bc@mail.gmail.com>
	<1FC599EA-EA00-4F66-A202-0A9F94D2855C@DAL.CA>
Message-ID: <7cced4ed0706211148k143cc1cfh3669f80edf33fec1@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070621/75956495/attachment.pl 

From jmburgos at u.washington.edu  Thu Jun 21 20:51:33 2007
From: jmburgos at u.washington.edu (Julian Burgos)
Date: Thu, 21 Jun 2007 11:51:33 -0700
Subject: [R] mgcv: lowest estimated degrees of freedom
Message-ID: <467AC8B5.2040909@u.washington.edu>

Dear list,

I do apologize if these are basic questions.  I am fitting some GAM 
models using the mgcv package and following the model selection criteria 
proposed by Wood and Augustin (2002, Ecol. Model. 157, p. 157-177).  One 
criterion to decide if a term should be dropped from a model is if the 
estimated degrees of freedom (EDF) for the term are close to their lower 
limit.

What would be the minimum number of EDF's for
a) Univariate thin plate regression splines(TPRS) with shrinkage, i.e.  
s(...,bs="ts")
b) Bivariate tensor products of TPRS with shrinkage?

Thanks for any help,

Julian Burgos

-- 
Julian M. Burgos

Fisheries Acoustics Research Lab
School of Aquatic and Fishery Science
University of Washington

1122 NE Boat Street
Seattle, WA  98105 

Phone: 206-221-6864


From Max.Kuhn at pfizer.com  Thu Jun 21 16:50:40 2007
From: Max.Kuhn at pfizer.com (Kuhn, Max)
Date: Thu, 21 Jun 2007 10:50:40 -0400
Subject: [R] [R-pkgs] odfWeave version 0.5.9 released
Message-ID: <71257D09F114DA4A8E134DEAC70F25D308B55763@groamrexm03.amer.pfizer.com>

A new version of odfWeave has been released to CRAN. This is a
significant change to the package internals. It now uses the XML library
instead of a bunch of regular expressions.

New features include:

   - Captions for tables and figures
   - Functions to insert page breaks and to change the page layout
   - Style objects for frames and pages

Bug fixes include:

   - Parsing of arguments for graphics devices
   - Misc issues with bulleted lists

There is also a 30 page manual in the examples sub-directory that
describes the various style element and their values, with almost 50
code chunks for illustration.

Thanks to Steve Weston, Nathan Coulter, Sarah Goslee and Ralf Herold.

Send me any questions or comments,

Max

----------------------------------------------------------------------
LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages


From miller at cbl.umces.edu  Thu Jun 21 21:56:09 2007
From: miller at cbl.umces.edu (Thomas Miller)
Date: Thu, 21 Jun 2007 15:56:09 -0400
Subject: [R] anova on data means
Message-ID: <004701c7b43e$364c98b0$0202fea9@Miller3pc>

I am transitioning from SAS to R and am struggling with a relatively simple
analysis.  Have tried Venables and Ripley and other guides but can't find a
solution.

I have an experiment with 12 tanks.  Each tank holds 10 fish.  The 12 tanks
have randomly assigned one of 4 food treatments - S(tarve), L(ow), M(edium)
and H(igh).  There are 3 reps of each treatment.  I collect data on size of
each fish at the end of the experiment.  So my data looks like

Tank  Trt   Fish   Size
1      S     1      3.4
1      S     2      3.6
....
1      S    10      3.5
2      L     1      3.4
....
12    M     10      2.1

To do the correct test of hypothesis using anova, I need to calculate the
tank means and use those in the anova.  I have tried using tapply() and by()
functions, but when I do so I "loose" the treatment level because it is
categorical.  I have used 
Meandat<tapply(Size,list(Tank, Trt), mean)

But that doesn't give me a dataframe that I can then use to do the actual
aov analysis.  So what is the most efficient way to accomplish the analysis

Thanks

Tom Miller


From sabya23 at gmail.com  Thu Jun 21 21:56:19 2007
From: sabya23 at gmail.com (spime)
Date: Thu, 21 Jun 2007 12:56:19 -0700 (PDT)
Subject: [R] How to hide axis interval values in a plot
In-Reply-To: <11238540.post@talk.nabble.com>
References: <11238540.post@talk.nabble.com>
Message-ID: <11240427.post@talk.nabble.com>


thanks. got my answer.



spime wrote:
> 
> 
> 
>>plot(cars)
> 
> this shows a plot having interval values of axes (x-axis:5-25;
> y-axis:0-120). I want to hide these values. is there any way?
> 

-- 
View this message in context: http://www.nabble.com/How-to-hide-axis-interval-values-in-a-plot-tf3960418.html#a11240427
Sent from the R help mailing list archive at Nabble.com.


From tsoi.teen at gmail.com  Thu Jun 21 22:07:07 2007
From: tsoi.teen at gmail.com (Alex Tsoi)
Date: Thu, 21 Jun 2007 16:07:07 -0400
Subject: [R] Using the object of character data type as the name of the slot
Message-ID: <5167e2400706211307m794c09fascdad3d48f906c768@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070621/e4b6720c/attachment.pl 

From deepayan.sarkar at gmail.com  Thu Jun 21 22:19:36 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Thu, 21 Jun 2007 13:19:36 -0700
Subject: [R] Overlaying lattice graphs (continued)
In-Reply-To: <467A74D5.4090808@free.fr>
References: <4679F719.7020308@free.fr>
	<f8e6ff050706210513r51fd9d28mb102a919e20499d6@mail.gmail.com>
	<467A74D5.4090808@free.fr>
Message-ID: <eb555e660706211319y4332d5c9kd406411bff620043@mail.gmail.com>

On 6/21/07, S?bastien <pomchip at free.fr> wrote:
> Hi Hadley,
>
> Hopefully, my dataset won't be too hard to changed. Can I modify the
> aspect of each group using your code (symbols for observed and lines for
> predicted)?
>
> Sebastien
>
> hadley wickham a ?crit :
> > Hi Sebastian,
> >
> > I think you need to rearrange your data a bit.  Firstly, you need to
> > put observed on the same footing as the different models, so you would
> > have a new column in your data called value (previously observed and
> > predicted) and a new model type ("observed").  Then you could do:

Yes, and ?make.groups (and reshape of course) could help with that.
This might not be strictly necessary though.

However, I'm finding your pseudo-code confusing. Could you create a
small example data set that can be used to try out some real code?
Just from your description, I would have suggested something like

xyplot(Observed + Predicted ~ Time | Individuals + Model,
       data = mydata,
       panel = panel.superpose.2, type = c("p", "l"),
       layout = c(0, nlevels(mydata$Individuals)),
       <...>)

If all you want is to plot one page at a time, there are easier ways to do that.

-Deepayan

> >
> > xyplot(value ~ time | individauls, data=mydata, group=model)
> >
> > Hadley
> >
> >
> > On 6/21/07, S?bastien <pomchip at free.fr> wrote:
> >> Dear R Users,
> >>
> >> I recently posted an email on this list  about the use of data.frame and
> >> overlaying multiple plots. Deepayan kindly indicated to me the
> >> panel.superposition command which worked perfectly in the context of the
> >> example I gave.
> >> I'd like to go a little bit further on this topic using a more complex
> >> dataset structure (actually the one I want to work on).
> >>
> >>  >mydata
> >>       Plot    Model    Individuals    Time        Observed
> >> Predicted
> >> 1    1        A           1                  0.05
> >> 10                    10.2
> >> 2    1        A           1                  0.10
> >> 20                    19.5
> >> etc...
> >> 10  1        B           1                  0.05         10
> >>          9.8
> >> 11  1        B           1                  0.10         20
> >>          20.2
> >> etc...
> >>
> >> There are p "levels" in mydata$Plot, m in mydata$Model, n in
> >> mydata$Individuals and t in mydata$Time (Note that I probably use the
> >> word levels improperly as all columns are not factors). Basically, this
> >> dataset summarizes the t measurements obtained in n individuals as well
> >> as the predicted values from m different modeling approaches (applied to
> >> all individuals). Therefore, the observations are repeated m times in
> >> the Observed columns, while the predictions appears only once for a
> >> given model an a given individual.
> >>
> >> What I want to write is a R batch file creating a Trellis graph, where
> >> each panel corresponds to one individual and contains the observations
> >> (as scatterplot) plus the predicted values for all models (as lines of
> >> different colors)... $Plot is just a token: it might be used to not
> >> overload graphs in case there are too many tested models. The fun part
> >> is that the values of p, m, n and t might vary from one dataset to the
> >> other, so everything has to be coded dynamically.
> >>
> >> For the plotting part I was thinking about having a loop in my code
> >> containing something like that:
> >>
> >> for (i in 1:nlevels(mydata$Model)) {
> >>
> >> subdata<-subset(mydata,mydata$Model=level(mydata$Model)[i])
> >> xyplot(subset(Observed + Predicted ~ Time | Individuals, data =
> >> subdata)       #plus additionnal formatting code
> >>
> >> }
> >>
> >> Unfortunately, this code simply creates a new Trellis plot instead of
> >> adding the model one by one on the panels. Any idea or link to a useful
> >> command will wellcome.
> >>
> >> Sebastien
> >>
> >> ______________________________________________
> >> R-help at stat.math.ethz.ch mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From deepayan.sarkar at gmail.com  Thu Jun 21 22:21:50 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Thu, 21 Jun 2007 13:21:50 -0700
Subject: [R] barchart in trellis and NA
In-Reply-To: <467A5CDE.2030002@wiwi.hu-berlin.de>
References: <467A5CDE.2030002@wiwi.hu-berlin.de>
Message-ID: <eb555e660706211321x72aa9ee5w7d40f866c03471c0@mail.gmail.com>

On 6/21/07, Sigbert Klinke <sigbert at wiwi.hu-berlin.de> wrote:
> Hi,
>
> I've a dataset with discrete data and several groups and in one group I
> have also missing values (NA). When I use table and barchart to
> visualize the counts I never get a bar for  NA in the barchart although
> it appears in the result of table. Is there a possibility to get this
> bar too?

Please give a reproducible example, because it's not clear to me what
exactly is supposed to be NA.

-Deepayan


From chrysopa at gmail.com  Thu Jun 21 22:22:33 2007
From: chrysopa at gmail.com (Ronaldo Reis Junior)
Date: Thu, 21 Jun 2007 17:22:33 -0300
Subject: [R] anova on data means
In-Reply-To: <004701c7b43e$364c98b0$0202fea9@Miller3pc>
References: <004701c7b43e$364c98b0$0202fea9@Miller3pc>
Message-ID: <200706211722.33043.chrysopa@gmail.com>

Em Quinta 21 Junho 2007 16:56, Thomas Miller escreveu:
> I am transitioning from SAS to R and am struggling with a relatively simple
> analysis.  Have tried Venables and Ripley and other guides but can't find a
> solution.
>
> I have an experiment with 12 tanks.  Each tank holds 10 fish.  The 12 tanks
> have randomly assigned one of 4 food treatments - S(tarve), L(ow), M(edium)
> and H(igh).  There are 3 reps of each treatment.  I collect data on size of
> each fish at the end of the experiment.  So my data looks like
>
> Tank  Trt   Fish   Size
> 1      S     1      3.4
> 1      S     2      3.6
> ....
> 1      S    10      3.5
> 2      L     1      3.4
> ....
> 12    M     10      2.1
>
> To do the correct test of hypothesis using anova, I need to calculate the
> tank means and use those in the anova.  I have tried using tapply() and
> by() functions, but when I do so I "loose" the treatment level because it
> is categorical.  I have used
> Meandat<tapply(Size,list(Tank, Trt), mean)
>
> But that doesn't give me a dataframe that I can then use to do the actual
> aov analysis.  So what is the most efficient way to accomplish the analysis
>
> Thanks
>
> Tom Miller

Tom,

try the aggregate funtion. Somethink like this

meandat <- aggregate(Size,list(Tank,Trt),mean)

Inte
Ronaldo
--
> Prof. Ronaldo Reis J?nior
|  .''`. UNIMONTES/Depto. Biologia Geral/Lab. de Ecologia
| : :'  : Campus Universit?rio Prof. Darcy Ribeiro, Vila Mauric?ia
| `. `'` CP: 126, CEP: 39401-089, Montes Claros - MG - Brasil
|   `- Fone: (38) 3229-8187 | ronaldo.reis em unimontes.br | chrysopa em gmail.com
| http://www.ppgcb.unimontes.br/ | ICQ#: 5692561 | LinuxUser#: 205366


From bryan.woods at yale.edu  Thu Jun 21 22:36:59 2007
From: bryan.woods at yale.edu (Bryan K Woods)
Date: Thu, 21 Jun 2007 16:36:59 -0400
Subject: [R] calculating co-spectra and quad-spectra
Message-ID: <467AE16B.3010909@yale.edu>

I am trying to calculate co and quad spectra for meteorological 
variables in order to spectrally examine momentum and energy fluxes. I 
noticed that the spec.pgram function returns power curves for both 
individual variables as well as coherence and phase information, but 
nothing about the co/quad spectrum. Does anyone have any experience with 
this and know of a way to back the cross-spectra out of this information 
or know of another package?

Thanks
Bryan

-- 
Bryan Woods
Dept. of Geology & Geophysics
Yale University, KGL 234
210 Whitney Ave
New Haven, CT 06511

978.726.3462 (cell)
203.432.3134 (fax)
203.404.3365 (home)


From p.dalgaard at biostat.ku.dk  Thu Jun 21 22:41:36 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 21 Jun 2007 22:41:36 +0200
Subject: [R] anova on data means
In-Reply-To: <200706211722.33043.chrysopa@gmail.com>
References: <004701c7b43e$364c98b0$0202fea9@Miller3pc>
	<200706211722.33043.chrysopa@gmail.com>
Message-ID: <467AE280.3020307@biostat.ku.dk>

Ronaldo Reis Junior wrote:
> Em Quinta 21 Junho 2007 16:56, Thomas Miller escreveu:
>   
>> I am transitioning from SAS to R and am struggling with a relatively simple
>> analysis.  Have tried Venables and Ripley and other guides but can't find a
>> solution.
>>
>> I have an experiment with 12 tanks.  Each tank holds 10 fish.  The 12 tanks
>> have randomly assigned one of 4 food treatments - S(tarve), L(ow), M(edium)
>> and H(igh).  There are 3 reps of each treatment.  I collect data on size of
>> each fish at the end of the experiment.  So my data looks like
>>
>> Tank  Trt   Fish   Size
>> 1      S     1      3.4
>> 1      S     2      3.6
>> ....
>> 1      S    10      3.5
>> 2      L     1      3.4
>> ....
>> 12    M     10      2.1
>>
>> To do the correct test of hypothesis using anova, I need to calculate the
>> tank means and use those in the anova.  I have tried using tapply() and
>> by() functions, but when I do so I "loose" the treatment level because it
>> is categorical.  I have used
>> Meandat<tapply(Size,list(Tank, Trt), mean)
>>
>> But that doesn't give me a dataframe that I can then use to do the actual
>> aov analysis.  So what is the most efficient way to accomplish the analysis
>>
>> Thanks
>>
>> Tom Miller
>>     
>
> Tom,
>
> try the aggregate funtion. Somethink like this
>
> meandat <- aggregate(Size,list(Tank,Trt),mean)
>   

Why not just include an error term for Tank in the model?

summary(aov(Size~Trt+Error(Tank)))

 
> Inte
> Ronaldo
> --
>   
>> Prof. Ronaldo Reis J?nior
>>     
> |  .''`. UNIMONTES/Depto. Biologia Geral/Lab. de Ecologia
> | : :'  : Campus Universit?rio Prof. Darcy Ribeiro, Vila Mauric?ia
> | `. `'` CP: 126, CEP: 39401-089, Montes Claros - MG - Brasil
> |   `- Fone: (38) 3229-8187 | ronaldo.reis at unimontes.br | chrysopa at gmail.com
> | http://www.ppgcb.unimontes.br/ | ICQ#: 5692561 | LinuxUser#: 205366
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From genomenet at gmail.com  Thu Jun 21 22:45:02 2007
From: genomenet at gmail.com (genomenet at gmail.com)
Date: Thu, 21 Jun 2007 13:45:02 -0700
Subject: [R] percentage in R
Message-ID: <1203994270.20070621134502@gmail.com>

Hi There,

How to display a number in the formation of percentage?

For example, a=0.25, how to display 25%?

Thank you very much.

Van


From christoph.heibl at gmx.net  Thu Jun 21 23:02:29 2007
From: christoph.heibl at gmx.net (Christoph Heibl)
Date: Thu, 21 Jun 2007 23:02:29 +0200
Subject: [R] percentage in R
In-Reply-To: <1203994270.20070621134502@gmail.com>
References: <1203994270.20070621134502@gmail.com>
Message-ID: <03109725-7169-4683-9162-A76BFE672C79@gmx.net>

Hi,

do you want to display the proportion as a character string? This  
would be simple:

 > a <- 0.25
 > aa <- paste(a*100, "%", sep="")
 > aa
[1] "25%"

Cheers,
Christoph


On 21.06.2007, at 22:45, genomenet at gmail.com wrote:

> Hi There,
>
> How to display a number in the formation of percentage?
>
> For example, a=0.25, how to display 25%?
>
> Thank you very much.
>
> Van
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From roland.rproject at gmail.com  Thu Jun 21 23:05:02 2007
From: roland.rproject at gmail.com (Roland Rau)
Date: Thu, 21 Jun 2007 17:05:02 -0400
Subject: [R] percentage in R
In-Reply-To: <1203994270.20070621134502@gmail.com>
References: <1203994270.20070621134502@gmail.com>
Message-ID: <467AE7FE.4020700@gmail.com>

genomenet at gmail.com wrote:
> Hi There,
> 
> How to display a number in the formation of percentage?
> 
> For example, a=0.25, how to display 25%?

if you write 'how to display' I guess you mean in a plot?

a <- 0.25
plot(0:10, 0:10, type="n")
text(x=5, y=5, labels=paste(round(a*100,0), "%", sep=""))

does this help?
Roland


From bwilfley at tripleringtech.com  Thu Jun 21 23:44:17 2007
From: bwilfley at tripleringtech.com (Brian Wilfley)
Date: Thu, 21 Jun 2007 14:44:17 -0700
Subject: [R] abline plots at wrong abscissae after boxplot
Message-ID: <d1f37b3d0706211444jd8e529at527fe5b60cbe2a93@mail.gmail.com>

Hi folks,

I'm using R 2.5.0 under ESS under Windows XP. (This also happens using
the Rgui application.)

I'm trying to add lines to a plot originally made with "boxplot", but
the lines appear in the wrong place. Below is a script that
illustrates the problem

# boxablinetest.R - script to show problem with abline on box plot

x <-  c(  2,  2,  2,  3,  3,  3,  4,  4,  4)
y <-  c(  1,  2,  3,  2,  3,  4,  3,  4,  5)

xymodel <- lm( y~x)

boxplot( y~x)
abline( xymodel)                        # Wrong abcissae
abline( v = 2.5)                        # Wrong abcissa
abline( h = 2.75)                       # Right ordinate

# -------------- end --------------

Here, I'm making a box plot with abscissae that start at 2. The box
plot looks fine: the numbers 2, 3, and 4 appear on the x-axis and the
boxes are centered at 2, 3, and 4.

When I add the first abline, the line appears too low, but actually it
is too far to the right. The abscissae are being interpreted without
realizing that the plot originates at 2, not 1.

The second call to abline should put a vertical line between 2 and 3,
but instead it shows up between 3 and 4. Again, it appears that the
offset in the origin of the boxplot is not accounted for.

Finally the last abline appears where it should: between 2 and 3.
Evidently, ordinate values are correctly interpreted.

Does anyone have any advice?

Thanks very much.

Brian Wilfley


From nicole.baerg at gmail.com  Thu Jun 21 23:51:47 2007
From: nicole.baerg at gmail.com (nicole baerg)
Date: Thu, 21 Jun 2007 17:51:47 -0400
Subject: [R] Multinomial models
Message-ID: <247ee61e0706211451v2dd447cy6df01c16d95fb604@mail.gmail.com>

Hello,

I am VERY new to R (one week) and I am trying to run a multinomial logit model.
The model I am using is

> model1 <- multinom(Y ~ X1 + X2 + , ..., Xn)

if I put in

> summary(model1)

I get

#Error in function (classes, fdef, mtable)  :
        unable to find an inherited method for function "fitted", for
signature "multinom"

and if I put in

> coef(model1)

I get the coefficients. I would like, however, to get the
coefficients, estimates, Std Erros and t-Ratios and/or z or P>[z]

Also can you change the speficiation of the base category without recoding?

Thanks.

Nicole


From sundar.dorai-raj at pdf.com  Thu Jun 21 23:59:46 2007
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 21 Jun 2007 14:59:46 -0700
Subject: [R] abline plots at wrong abscissae after boxplot
In-Reply-To: <d1f37b3d0706211444jd8e529at527fe5b60cbe2a93@mail.gmail.com>
References: <d1f37b3d0706211444jd8e529at527fe5b60cbe2a93@mail.gmail.com>
Message-ID: <467AF4D2.8020500@pdf.com>



Brian Wilfley said the following on 6/21/2007 2:44 PM:
> Hi folks,
> 
> I'm using R 2.5.0 under ESS under Windows XP. (This also happens using
> the Rgui application.)
> 
> I'm trying to add lines to a plot originally made with "boxplot", but
> the lines appear in the wrong place. Below is a script that
> illustrates the problem
> 
> # boxablinetest.R - script to show problem with abline on box plot
> 
> x <-  c(  2,  2,  2,  3,  3,  3,  4,  4,  4)
> y <-  c(  1,  2,  3,  2,  3,  4,  3,  4,  5)
> 
> xymodel <- lm( y~x)
> 
> boxplot( y~x)
> abline( xymodel)                        # Wrong abcissae
> abline( v = 2.5)                        # Wrong abcissa
> abline( h = 2.75)                       # Right ordinate
> 
> # -------------- end --------------
> 
> Here, I'm making a box plot with abscissae that start at 2. The box
> plot looks fine: the numbers 2, 3, and 4 appear on the x-axis and the
> boxes are centered at 2, 3, and 4.
> 
> When I add the first abline, the line appears too low, but actually it
> is too far to the right. The abscissae are being interpreted without
> realizing that the plot originates at 2, not 1.
> 
> The second call to abline should put a vertical line between 2 and 3,
> but instead it shows up between 3 and 4. Again, it appears that the
> offset in the origin of the boxplot is not accounted for.
> 
> Finally the last abline appears where it should: between 2 and 3.
> Evidently, ordinate values are correctly interpreted.
> 
> Does anyone have any advice?
> 
> Thanks very much.
> 
> Brian Wilfley
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


That's because the x is converted to a factor (see ?boxplot). Here's 
what you want:

## changesd x==3 to 6 to demonstrate call to boxplot below
x <- c(2, 2, 2, 3, 3, 3, 6, 6, 6)
y <- c(1, 2, 3, 2, 3, 4, 3, 4, 5)

xymodel <- lm(y ~ x)

boxplot(y ~ x) ## note x-labels!

## now fix your problem
plot(y ~ x, type = "n", xlim = c(1, 7))
bxp(boxplot(y ~ x, plot = FALSE), at = c(2, 3, 6),
     add = TRUE, boxwex = 0.5, boxfill = "lightblue")
abline(xymodel)
abline(v = 2.5)
abline(h = 2.75)

HTH,

--sundar


From tolga.uzuner at gmail.com  Fri Jun 22 00:41:44 2007
From: tolga.uzuner at gmail.com (Tolga Uzuner)
Date: Thu, 21 Jun 2007 23:41:44 +0100
Subject: [R] Binary decision problem
Message-ID: <8d94daff0706211541k4a3931d1i85d54314221c6bfb@mail.gmail.com>

Dear R Users,

I am trying to use LP_SOLVE and would appreciate any assistance with
the following problem:
- I am trying to choose a fixed number of items out of a batch of
items: say 100 out of 800
- items have certain characteristics, say characteric A, B and C
- I want to maximise the sum of A across all 100 items I choose while
ensuring that the sum of B and C across the items do not exceed
certain constraints

How exactly do I set this up in lp_solve ? If I associate a boolean, 0
or 1, with each item, I can constrain the sum of the boolean to be
equal to 100. But how do I then further specify the other constraints
(on the sum of B and the sum of C) and the objective function (to
maximise the sum of A) ?

Thanks,
Tolga


From karlknoblich at yahoo.de  Fri Jun 22 01:05:04 2007
From: karlknoblich at yahoo.de (Karl Knoblick)
Date: Thu, 21 Jun 2007 23:05:04 +0000 (GMT)
Subject: [R] Result depends on order of factors in unbalanced designs (lme,
	anova)?
Message-ID: <393002.75525.qm@web26513.mail.ukl.yahoo.com>

Dear R-Community!

For example I have a study with 4 treatment groups (10 subjects per group) and 4 visits. Additionally, the gender is taken into account. I think - and hope this is a goog idea (!) - this data can be analysed using lme as below.

In a balanced design everything is fine, but in an unbalanced design there are differences depending on fitting y~visit*treat*gender or y~gender*visit*treat - at least with anova (see example). Does this make sense? Which ordering might be the correct one?

Here the example script:
library(nlme)
set.seed(123)
# Random generation of data:
NSubj<-40 # No. of subjects
set.seed(1234)
id<-factor(rep(c(1:NSubj),4)) # ID of subjects
treat<-factor(rep(rep(1:4,each=5),4)) # Treatment 4 Levels
gender<-factor(rep(rep(1:2, each=20),4))
visit<-factor(rep(1:4, each=NSubj))
y<-runif(4*NSubj) # Results
# Add effects
y<-y+0.01*as.integer(visit)
y<-y+0.02*as.integer(gender)
y<-y+0.024*as.integer(treat)
df<-data.frame(id, treat, gender, visit, y)
# groupedData object for lme
gdat<-groupedData(y ~ visit|id, data=df)
# fits - different ordering of factors
fit1<-lme(y ~ visit*treat*gender, data=gdat, random = ~visit|id)
anova(fit1)
fit2<-lme(y ~ gender*treat*visit, data=gdat, random = ~visit|id)
anova(fit2)
# Result: identical (balanced design so far), ok
# Now change gender of subject 1
gdat$gender[c(1,41,81,121)]<-2
# onece more fits with different ordering of factors
fit1<-lme(y ~ visit*treat*gender, data=gdat, random = ~visit|id)
anova(fit1)
fit2<-lme(y ~ gender*treat*visit, data=gdat, random = ~visit|id)
anova(fit2)
# Result: There are differences!!

Hope anybody can help or give me advice how to interpret these results correctly or how to avoid this problem! Is there a better possibility to analyse these data than lme?

Thanks!
Karl


From roland.rproject at gmail.com  Fri Jun 22 01:08:22 2007
From: roland.rproject at gmail.com (Roland Rau)
Date: Thu, 21 Jun 2007 19:08:22 -0400
Subject: [R] Multinomial models
In-Reply-To: <247ee61e0706211451v2dd447cy6df01c16d95fb604@mail.gmail.com>
References: <247ee61e0706211451v2dd447cy6df01c16d95fb604@mail.gmail.com>
Message-ID: <467B04E6.1000304@gmail.com>

Hi,

since you are very new to R, just a small advice: try to give a minimal 
reproducible, self-contained example. This helps quite often to spot 
some mistakes yourself. This is my own experience and has been 
experienced by others, see, for example:
library(fortunes)
fortune("Ripleyed")

  :-)

For example, mention that you are (probably?) using the package 'nnet'.

nicole baerg wrote:
> I get the coefficients. I would like, however, to get the
> coefficients, estimates, Std Erros and t-Ratios and/or z or P>[z]
Check
names(model1) #if model1 is your fitted model as you write

then you will see a list of the components the fitted object should 
have. I guess the list should look similar to this:
  [1] "n"             "nunits"        "nconn"         "conn"
  [5] "nsunits"       "decay"         "entropy"       "softmax"
  [9] "censored"      "value"         "wts"           "fitted.values"
[13] "residuals"     "lev"           "call"          "terms"
[17] "weights"       "deviance"      "rank"          "coefnames"
[21] "vcoefnames"    "contrasts"     "xlevels"       "edf"
[25] "AIC"



> 
> Also can you change the speficiation of the base category without recoding?
> 
Check
?relevel

I hope this helps,
Roland


From m_olshansky at yahoo.com  Fri Jun 22 01:28:10 2007
From: m_olshansky at yahoo.com (Moshe Olshansky)
Date: Thu, 21 Jun 2007 16:28:10 -0700 (PDT)
Subject: [R] Binary decision problem
In-Reply-To: <8d94daff0706211541k4a3931d1i85d54314221c6bfb@mail.gmail.com>
Message-ID: <368927.65375.qm@web32215.mail.mud.yahoo.com>

Hi Tolga,

I do not see any problem with:
max {a1*x1 + a2*x2 + ... + a800*x800}
subject to:
x1+x2+ ... + x800 = 100
b1*x1+b2*x2+ ... +b800*x800 <= B
c1*x1+c2*x2+ ... +c800*x800 <= C
and an additional condition that x1,x2,...,x800 are
binary 0-1.

Regards,

Moshe Olshansky

--- Tolga Uzuner <tolga.uzuner at gmail.com> wrote:

> Dear R Users,
> 
> I am trying to use LP_SOLVE and would appreciate any
> assistance with
> the following problem:
> - I am trying to choose a fixed number of items out
> of a batch of
> items: say 100 out of 800
> - items have certain characteristics, say
> characteric A, B and C
> - I want to maximise the sum of A across all 100
> items I choose while
> ensuring that the sum of B and C across the items do
> not exceed
> certain constraints
> 
> How exactly do I set this up in lp_solve ? If I
> associate a boolean, 0
> or 1, with each item, I can constrain the sum of the
> boolean to be
> equal to 100. But how do I then further specify the
> other constraints
> (on the sum of B and the sum of C) and the objective
> function (to
> maximise the sum of A) ?
> 
> Thanks,
> Tolga
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From murdoch at stats.uwo.ca  Fri Jun 22 01:34:46 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 21 Jun 2007 19:34:46 -0400
Subject: [R] Using the object of character data type as the name of the
 slot
In-Reply-To: <5167e2400706211307m794c09fascdad3d48f906c768@mail.gmail.com>
References: <5167e2400706211307m794c09fascdad3d48f906c768@mail.gmail.com>
Message-ID: <467B0B16.2000208@stats.uwo.ca>

On 21/06/2007 4:07 PM, Alex Tsoi wrote:
> Dear all,
> 
> I have a character string object:
> 
>> chara
> [1]  "The name of first slot"
> 
> and a list object:
> 
>> class( try1)
> [1] "list"
> 
> 
> what I want to do is to use the chara as a slot's name of "try1".
> 
> Of  course I could do it like:
> 
>> try1$"The name of first slot"  <- matrix("", 3, 4)
> 
> to create a slot of 3x4 matrix with the name "The name of first slot"
> 
> However, I would like to know how could I utilize the object chara , and to
> use the characters it contains as the name of the slot of try1.

You can use

slot(try1, chara) <- matrix("", 3, 4)

as long as the slot name contained in chara really is a slot.

Duncan Murdoch


From donghui.feng at gmail.com  Fri Jun 22 01:35:59 2007
From: donghui.feng at gmail.com (Donghui Feng)
Date: Thu, 21 Jun 2007 16:35:59 -0700
Subject: [R] questions for hist()
Message-ID: <b46dc45f0706211635t4d88c3b1yf66c0354ef75d9e6@mail.gmail.com>

Dear all,

I'm creating a histogram with the function hist(). But
right now what I get is column representation (as normal).
I'm wondering if I could switch X-axis and Y-axis and
get row-representation of frequencies?

One more question, can I define the step of each axises
for the histogram?

Thanks so much!

Donghui


From m_olshansky at yahoo.com  Fri Jun 22 01:36:04 2007
From: m_olshansky at yahoo.com (Moshe Olshansky)
Date: Thu, 21 Jun 2007 16:36:04 -0700 (PDT)
Subject: [R] anova on data means
In-Reply-To: <200706211722.33043.chrysopa@gmail.com>
Message-ID: <941459.1750.qm@web32214.mail.mud.yahoo.com>

An ugly solution (but which works) would be something
like this (assuming that d is a data.frame with 4
columns named Tank, Trt, Fish, Size):

x <-1:12
for (i in 1:12) x[i] <- mean(d$Size[d$Tank == i])

Regards,
Moshe Olshansky

--- Ronaldo Reis Junior <chrysopa at gmail.com> wrote:

> Em Quinta 21 Junho 2007 16:56, Thomas Miller
> escreveu:
> > I am transitioning from SAS to R and am struggling
> with a relatively simple
> > analysis.  Have tried Venables and Ripley and
> other guides but can't find a
> > solution.
> >
> > I have an experiment with 12 tanks.  Each tank
> holds 10 fish.  The 12 tanks
> > have randomly assigned one of 4 food treatments -
> S(tarve), L(ow), M(edium)
> > and H(igh).  There are 3 reps of each treatment. 
> I collect data on size of
> > each fish at the end of the experiment.  So my
> data looks like
> >
> > Tank  Trt   Fish   Size
> > 1      S     1      3.4
> > 1      S     2      3.6
> > ....
> > 1      S    10      3.5
> > 2      L     1      3.4
> > ....
> > 12    M     10      2.1
> >
> > To do the correct test of hypothesis using anova,
> I need to calculate the
> > tank means and use those in the anova.  I have
> tried using tapply() and
> > by() functions, but when I do so I "loose" the
> treatment level because it
> > is categorical.  I have used
> > Meandat<tapply(Size,list(Tank, Trt), mean)
> >
> > But that doesn't give me a dataframe that I can
> then use to do the actual
> > aov analysis.  So what is the most efficient way
> to accomplish the analysis
> >
> > Thanks
> >
> > Tom Miller
> 
> Tom,
> 
> try the aggregate funtion. Somethink like this
> 
> meandat <- aggregate(Size,list(Tank,Trt),mean)
> 
> Inte
> Ronaldo
> --
> > Prof. Ronaldo Reis J?nior
> |  .''`. UNIMONTES/Depto. Biologia Geral/Lab. de
> Ecologia
> | : :'  : Campus Universit?rio Prof. Darcy Ribeiro,
> Vila Mauric?ia
> | `. `'` CP: 126, CEP: 39401-089, Montes Claros - MG
> - Brasil
> |   `- Fone: (38) 3229-8187 |
> ronaldo.reis at unimontes.br | chrysopa at gmail.com
> | http://www.ppgcb.unimontes.br/ | ICQ#: 5692561 |
> LinuxUser#: 205366
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From juryef at yahoo.com  Fri Jun 22 01:39:58 2007
From: juryef at yahoo.com (Judith Flores)
Date: Thu, 21 Jun 2007 16:39:58 -0700 (PDT)
Subject: [R] Adding exponents (superscript format) to a plot
Message-ID: <273959.28789.qm@web34707.mail.mud.yahoo.com>

Hi,

   I need to add exponents to a label in one of the
axes of a plot, how can I do this?

Thank you,

Judith


 
____________________________________________________________________________________
Food fight? Enjoy some healthy debate


From m_olshansky at yahoo.com  Fri Jun 22 01:51:51 2007
From: m_olshansky at yahoo.com (Moshe Olshansky)
Date: Thu, 21 Jun 2007 16:51:51 -0700 (PDT)
Subject: [R] sorting data
In-Reply-To: <11233613.post@talk.nabble.com>
Message-ID: <991632.30837.qm@web32205.mail.mud.yahoo.com>

Try ReadWriteXls package from CRAN.

--- dala <lamkhanhvns at yahoo.co.uk> wrote:

> 
> I have a 2 columns, Date and Number, in Excel. 
> I copy and paste them into Notepad.
> I can use scan() to import the file but how do I
> plot this data with Date as
> the x-axis?
> -- 
> View this message in context:
>
http://www.nabble.com/sorting-data-tf3958889.html#a11233613
> Sent from the R help mailing list archive at
> Nabble.com.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From murdoch at stats.uwo.ca  Fri Jun 22 02:02:45 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 21 Jun 2007 20:02:45 -0400
Subject: [R] Adding exponents (superscript format) to a plot
In-Reply-To: <273959.28789.qm@web34707.mail.mud.yahoo.com>
References: <273959.28789.qm@web34707.mail.mud.yahoo.com>
Message-ID: <467B11A5.8060201@stats.uwo.ca>

On 21/06/2007 7:39 PM, Judith Flores wrote:
 > Hi,
 >
 >    I need to add exponents to a label in one of the
 > axes of a plot, how can I do this?

See ?plotmath.  For example,

plot(1,2, xlab=expression(x^2), ylab=expression(exp(-x^2/2)))

Duncan Murdoch


From donghui.feng at gmail.com  Fri Jun 22 02:23:36 2007
From: donghui.feng at gmail.com (Donghui Feng)
Date: Thu, 21 Jun 2007 17:23:36 -0700
Subject: [R] Switching X-axis and Y-axis for histogram
Message-ID: <b46dc45f0706211723la539a4djefa727122077364f@mail.gmail.com>

Dear all,

I'm creating a histogram with the function hist(). But
right now what I get is column representation (as normal).
I'm wondering if I could switch X-axis and Y-axis and
get row-representation of frequencies?

One more question, can I define the step of each axises
for the histogram?

Thanks so much!

Donghui


From realityrandom at gmail.com  Fri Jun 22 05:09:36 2007
From: realityrandom at gmail.com (Yuchen Luo)
Date: Thu, 21 Jun 2007 20:09:36 -0700
Subject: [R] set up a talbe with column name and write to the table row by
	row
Message-ID: <548b8d440706212009q8b78b6fue9cf7c941f99a73f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070621/3b85cfb5/attachment.pl 

From anup_nandialath at yahoo.com  Fri Jun 22 06:18:47 2007
From: anup_nandialath at yahoo.com (Anup Nandialath)
Date: Thu, 21 Jun 2007 21:18:47 -0700 (PDT)
Subject: [R] Data consistency checks in functions
Message-ID: <162740.61793.qm@web53302.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070621/64e24a9b/attachment.pl 

From ripley at stats.ox.ac.uk  Fri Jun 22 08:00:53 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 22 Jun 2007 07:00:53 +0100 (BST)
Subject: [R] Multinomial models
In-Reply-To: <247ee61e0706211451v2dd447cy6df01c16d95fb604@mail.gmail.com>
References: <247ee61e0706211451v2dd447cy6df01c16d95fb604@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0706220653110.8534@gannet.stats.ox.ac.uk>

On Thu, 21 Jun 2007, nicole baerg wrote:

> Hello,
>
> I am VERY new to R (one week) and I am trying to run a multinomial logit model.
> The model I am using is
>
>> model1 <- multinom(Y ~ X1 + X2 + , ..., Xn)
>
> if I put in
>
>> summary(model1)
>
> I get
>
> #Error in function (classes, fdef, mtable)  :
>        unable to find an inherited method for function "fitted", for
> signature "multinom"

You have some other package attached (you are using 'nnet' without mention 
or credit) that has broken summary() (the correct summary method does not 
use fitted()).  The R posting guide asks for the output of sessionInfo(), 
and that would have helped us here. All I can tell is that the culprit is 
an S4-using package.

Try again with only the smallest possible set of packages attached.

> and if I put in
>
>> coef(model1)
>
> I get the coefficients. I would like, however, to get the
> coefficients, estimates, Std Erros and t-Ratios and/or z or P>[z]
>
> Also can you change the speficiation of the base category without recoding?

?contr.treatment
?relevel

> Thanks.
>
> Nicole
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

PLEASE do

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ken.feng at citi.com  Fri Jun 22 08:26:18 2007
From: ken.feng at citi.com (Feng, Ken )
Date: Fri, 22 Jun 2007 15:26:18 +0900
Subject: [R] R.oo 1.2.7 Incompatible with R 2.5.0?
Message-ID: <0143A263BEF94644AC0D4027373EECD3054309B7@exyhmb08.jpn.nsroot.net>

Hi,

I need a sanity check.  When I try the following:

library(R.oo)
setConstructorS3( "QREobject", abstract=TRUE,
  function(...)  {
    extend( Object(), "QREobject" );
  }
);

I get:

	Error in names(args) : no applicable method for "names"

Things were working fine in R 2.4.1  
I wonder if it has to do with this release note for R 2.5.0:

    o	levels<-(), names() and names<-() now dispatch internally for
	efficiency and so no longer have S3 default methods.

from here:

	https://stat.ethz.ch/pipermail/r-announce/2007/000828.html

I'm wondering if I have done something wrong or is there an incompatibility issue.

If it's the latter, I hope Mr. Henrik Bengtsson would be nice enough to update the software.
I'm so dependent on R.oo that I will roll back to 2.4.1 until there's a workaround for this.

Anyone else having similar issues?  Thanks in advance.

- Ken


From freesuccess2001 at yahoo.com  Fri Jun 22 08:46:01 2007
From: freesuccess2001 at yahoo.com (yoo hoo)
Date: Thu, 21 Jun 2007 23:46:01 -0700 (PDT)
Subject: [R] logit problem
Message-ID: <442025.18577.qm@web38708.mail.mud.yahoo.com>

Hi there,
 
 I was trying to fit this dataset into LR model. This dataset includes 18 normal and 17 
 cancer. There are totally 14 markers (7 mRNAs and 7 Proteins). When I fitted into LR 
 model, R gave me warning:
 Warning messages:
 1: algorithm did not converge in: glm.fit(x = X, y = Y, weights = weights, start = start, 
 etastart = etastart,
 2: fitted probabilities numerically 0 or 1 occurred in: glm.fit(x = X, y = Y, weights = 
 weights, start = start, etastart = etastart,
 
 I don't know why the algorithm did not converge. Is it because sample size/marker is 
 small? Is it possible you run this dataset in s-plus? Thank you very much for your help.
 
 Michael
       
---------------------------------


From mmeredith at wcs.org  Fri Jun 22 08:47:58 2007
From: mmeredith at wcs.org (Mike Meredith)
Date: Thu, 21 Jun 2007 23:47:58 -0700 (PDT)
Subject: [R] merge
In-Reply-To: <747715.81493.qm@web27507.mail.ukl.yahoo.com>
References: <747715.81493.qm@web27507.mail.ukl.yahoo.com>
Message-ID: <11247082.post@talk.nabble.com>


Looking at the data, maybe what you need is an array:

array(c(A, B), c(5,6,2), dimnames=list(rownames(A),
    colnames(A), c("obs","pred")))

This allows you to keep the names and 'supernames'.

This will work if A and B are matrices, not data frames, so you may have to
use 'as.matrix' first.

HTH, Mike.


elyakhlifi mustapha wrote:
> 
> Hello,
> ok I know how to do to merge matrix or data.frame by "row.names" but my
> true objectif is to merge for example this data.frame:
> 
>> A
>       obs
>        R?p1 R?p2 R?p3 R?p4 R?p5 R?p6
>   Var1  145  145  150  145  140  145
>   Var2  150  150  160  155  155  150
>   Var3  155  155  160  150  150  140
>   Var4  150  145  145  145  140  145
>   Var5  135  130  145  135  135  130
> 
> and 
> 
>> B
>       pred
>          R?p1   R?p2   R?p3   R?p4   R?p5   R?p6
>   Var1 146.00 144.00 151.00 145.00 143.00 141.00
>   Var2 154.33 152.33 159.33 153.33 151.33 149.33
>   Var3 152.67 150.67 157.67 151.67 149.67 147.67
>   Var4 146.00 144.00 151.00 145.00 143.00 141.00
>   Var5 136.00 134.00 141.00 135.00 133.00 131.00
> 
> and the main difficulty is to keep the names and the supernames.
> 

-- 
View this message in context: http://www.nabble.com/merge-tf3953336.html#a11247082
Sent from the R help mailing list archive at Nabble.com.


From birgit.lemcke at systbot.uzh.ch  Fri Jun 22 09:04:40 2007
From: birgit.lemcke at systbot.uzh.ch (Birgit Lemcke)
Date: Fri, 22 Jun 2007 09:04:40 +0200
Subject: [R] Distance function
In-Reply-To: <1182450155.26435.33.camel@gsimpson.geog.ucl.ac.uk>
References: <EFCBC842-6A69-48E1-A8B4-1C5BCAAC669F@systbot.uzh.ch>
	<1182450155.26435.33.camel@gsimpson.geog.ucl.ac.uk>
Message-ID: <BC03EFAA-67B2-49E5-9651-95919348970B@systbot.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070622/03e8e7bd/attachment.pl 

From rmk at krugs.de  Fri Jun 22 09:31:45 2007
From: rmk at krugs.de (Rainer M. Krug)
Date: Fri, 22 Jun 2007 09:31:45 +0200
Subject: [R] Generating vetor (shapefiles) from AscGrid raster in R
In-Reply-To: <405017.3092.qm@web56612.mail.re3.yahoo.com>
References: <405017.3092.qm@web56612.mail.re3.yahoo.com>
Message-ID: <f5ftp5$sb0$1@sea.gmane.org>

What about using grass 6, combined with spgrass6 and the command r.to.vect?

Rainer

Milton Cezar Ribeiro wrote:
> Hi there,
> 
> I need to convert a raster (ascGrid) format to Shape files.
> Is there a way of to do that on R?
> 
> Kind regards
> 
> miltinho
> 
> 
>        
> ____________________________________________________________________________________
> 
> http://yahoo.com.br/oqueeuganhocomisso 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From tomas.goicoa at unavarra.es  Fri Jun 22 09:52:57 2007
From: tomas.goicoa at unavarra.es (Tomas Goicoa)
Date: Fri, 22 Jun 2007 09:52:57 +0200
Subject: [R] help on the use of ldBand
Message-ID: <20070622075254.EEC5F19E607@cartero1.unavarra.es>


  Hi R Users,

  I am trying to use the ldBand package. Together 
with the package, I have downloaded the ld98 
program (version for windows) as indicated in the 
help page on ldBand. I did it, but obtained an 
error message "Error in (head + 1):length(w) : 
Argument NA/NaN" when I copied the help examples, 
so it seems that a conection between R and ld98 
is not well performed in my computer.  Did I put 
ld98.exe in the wrong place? If so,  where should 
I put it? Thanks a lot in advance,


  Berta Iba?ez Beroiz


From sabya23 at gmail.com  Fri Jun 22 10:18:58 2007
From: sabya23 at gmail.com (spime)
Date: Fri, 22 Jun 2007 01:18:58 -0700 (PDT)
Subject: [R] two basic question regarding model selection in GAM
Message-ID: <11248016.post@talk.nabble.com>


Qusetion #1
*********  
Model selection in GAM can be done by using:
1. step.gam {gam} : A directional stepwise search
2. gam {mgcv} : Smoothness estimation using GCV or UBRE/AIC criterion

Suppose my model starts with a additive model (linear part + spline part).
Using gam() {mgcv} i got estimated degrees of freedom(edf) for the smoothing
splines. Now I want to use the functional form of my model taking estimated
degrees of freedoms in step.gam() {gam} to search a better model.

You know mgcv masks over gam. So i can not use gam after using mgcv. Is
there any way to stop mgcv.

Qusetion #2
*********
Suppose i have three models:
M1. GAM with thin plate regression spline(TPRS)
M2. GAM with cubic regression spline(CRS)
M3. GAM with some TPRS and CRS

To choose best model among the three, can i use their GCV/AIC/UBRE
criterion?
-- 
View this message in context: http://www.nabble.com/two-basic-question-regarding-model-selection-in-GAM-tf3963362.html#a11248016
Sent from the R help mailing list archive at Nabble.com.


From weller at erdw.ethz.ch  Fri Jun 22 10:26:09 2007
From: weller at erdw.ethz.ch (Andy Weller)
Date: Fri, 22 Jun 2007 10:26:09 +0200
Subject: [R] (Heuristic?) salient feature selection
Message-ID: <467B87A1.3090808@erdw.ethz.ch>

Dear all,

I am new to R and statistics really in general. I am hoping that someone 
will be able to point me in the right direction and/or suggest a 
technique/package/reference that will help me with the following.

I have:

Some input variables (integers, real)
Some output variables (integers, real)

and I want to find out which between the two correlate best - i.e. the 
salient features. I also need to know the confidence between them.

I hope this makes sense?

I look forward to your replies, Andy


From s.henderson at ucl.ac.uk  Fri Jun 22 11:01:52 2007
From: s.henderson at ucl.ac.uk (Stephen Henderson)
Date: Fri, 22 Jun 2007 10:01:52 +0100
Subject: [R] FW: Suse RPM installation problem
Message-ID: <61B482B74D6EE443B90356E080476E340189529A@exc2.cruciform.wibr.ucl.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070622/7ef02aec/attachment.pl 

From P.Dalgaard at biostat.ku.dk  Fri Jun 22 11:10:50 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 22 Jun 2007 11:10:50 +0200
Subject: [R] FW: Suse RPM installation problem
In-Reply-To: <61B482B74D6EE443B90356E080476E340189529A@exc2.cruciform.wibr.ucl.ac.uk>
References: <61B482B74D6EE443B90356E080476E340189529A@exc2.cruciform.wibr.ucl.ac.uk>
Message-ID: <467B921A.9010206@biostat.ku.dk>

Stephen Henderson wrote:
> Thanks for your help
>
> As you suggested I do indeed have a 64bit version called exactly the same
>
> PC5-140:/home/rmgzshd # rpm -qf /usr/lib/libpng12.so.0
> libpng-32bit-1.2.8-19.5
> PC5-140:/home/rmgzshd # rpm -qf /usr/lib64/libpng12.so.0
> libpng-1.2.8-19.5
>
> SO how do I tell rpm to find this and not the 32bit file? Or do I need to edit something in the rpm file?
>
> Thanks
>
>   
Odd... Do you actually _have_  /usr/lib64/libpng12.so.0 (whereis didn't
seem to find it) --- as opposed to "rpm -qf" telling you which package
contains the file? If not, try (re)installing libpng, possibly with
--force.
>
>
> -----Original Message-----
> From: Peter Dalgaard [mailto:p.dalgaard at biostat.ku.dk]
> Sent: Thu 6/21/2007 6:34 PM
> To: Stephen Henderson
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] FW: Suse RPM installation problem
>  
> Stephen Henderson wrote:
>   
>> Hello 
>>
>> I am trying to install the R RPM for Suse 10.0 on an x86_64 PC. However
>> I am failing a dependency for  "libpng12.so.0" straight away
>>
>>
>>
>>     PC5-140:/home/rmgzshd # rpm -i R-base-2.5.0-2.1.x86_64.rpm
>>     error: Failed dependencies:
>>     libpng12.so.0(PNG12_0)(64bit) is needed by R-base-2.5.0-2.1.x86_64
>>
>> I do seem to have this file
>>
>>     PC5-140:/home/rmgzshd # whereis libpng12.so.0
>>     libpng12.so: /usr/lib/libpng12.so.0 /usr/local/lib/libpng12.so 
>>
>> but presuming that it is not the 64bit version mentioned I went looking
>> for a 64 bit version but could not find it through google.
>>
>> However reading the Installation manual I noted that libpng is mention
>> in the context of a source build. I therefore downloaded "libpng-1.2.18"
>> (v-1.2.8 or later is specified in the manual) and succesfully compiled
>> this. This did not however help with my problem.
>>
>> Any suggestions?
>>
>>   
>>     
> I have
>
> viggo:~/>rpm -qf /usr/lib/libpng12.so.0
> libpng-32bit-1.2.12-25
> viggo:~/>rpm -qf /usr/lib64/libpng12.so.0
> libpng-1.2.12-25
> viggo:~/>rpm -q R-base
> R-base-2.5.0-2.1
>
>
>   
>> Thanks
>> Stephen Henderson
>>  
>>
>> **********************************************************************
>> This email and any files transmitted with it are confidentia...{{dropped}}
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>   
>>     
>
>
>
> **********************************************************************
> This email and any files transmitted with it are confidentia...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From s.wood at bath.ac.uk  Fri Jun 22 10:54:24 2007
From: s.wood at bath.ac.uk (Simon Wood)
Date: Fri, 22 Jun 2007 09:54:24 +0100
Subject: [R] mgcv: lowest estimated degrees of freedom
In-Reply-To: <467AC8B5.2040909@u.washington.edu>
References: <467AC8B5.2040909@u.washington.edu>
Message-ID: <200706220954.24787.s.wood@bath.ac.uk>

On Thursday 21 June 2007 19:51, Julian Burgos wrote:
> Dear list,
>
> I do apologize if these are basic questions.  I am fitting some GAM
> models using the mgcv package and following the model selection criteria
> proposed by Wood and Augustin (2002, Ecol. Model. 157, p. 157-177).  One
> criterion to decide if a term should be dropped from a model is if the
> estimated degrees of freedom (EDF) for the term are close to their lower
> limit.
>
> What would be the minimum number of EDF's for
> a) Univariate thin plate regression splines(TPRS) with shrinkage, i.e.
> s(...,bs="ts")
zero (that's sort of the point of the shrinkage smooths: the smoothing penalty 
can actually zero a term completely with high enough smoothing parameter).

> b) Bivariate tensor products of TPRS with shrinkage?
Also zero. The penalties for the marginal smooths can shrink terms to zero, 
and this gets inherited by the tensor product penalties. So, with high enough 
smoothing parameters, the term will be shrunk to zero (and hence have zero 
EDF).

Simon

> Simon Wood, Mathematical Sciences, University of Bath, Bath, BA2 7AY UK
> +44 1225 386603  www.maths.bath.ac.uk/~sw283


From s.wood at bath.ac.uk  Fri Jun 22 11:00:21 2007
From: s.wood at bath.ac.uk (Simon Wood)
Date: Fri, 22 Jun 2007 10:00:21 +0100
Subject: [R] two basic question regarding model selection in GAM
In-Reply-To: <11248016.post@talk.nabble.com>
References: <11248016.post@talk.nabble.com>
Message-ID: <200706221000.21809.s.wood@bath.ac.uk>

On Friday 22 June 2007 09:18, spime wrote:
> Qusetion #1
> *********
> Model selection in GAM can be done by using:
> 1. step.gam {gam} : A directional stepwise search
> 2. gam {mgcv} : Smoothness estimation using GCV or UBRE/AIC criterion
>
> Suppose my model starts with a additive model (linear part + spline part).
> Using gam() {mgcv} i got estimated degrees of freedom(edf) for the
> smoothing splines. Now I want to use the functional form of my model taking
> estimated degrees of freedoms in step.gam() {gam} to search a better model.
>
> You know mgcv masks over gam. So i can not use gam after using mgcv. Is
> there any way to stop mgcv.
detach(package:mgcv)

>
> Qusetion #2
> *********
> Suppose i have three models:
> M1. GAM with thin plate regression spline(TPRS)
> M2. GAM with cubic regression spline(CRS)
> M3. GAM with some TPRS and CRS
>
> To choose best model among the three, can i use their GCV/AIC/UBRE
> criterion?
Yes (assuming you're not using neg bin with unknown theta). But are the models 
very different?

simon
-- 
> Simon Wood, Mathematical Sciences, University of Bath, Bath, BA2 7AY UK
> +44 1225 386603  www.maths.bath.ac.uk/~sw283


From s.henderson at ucl.ac.uk  Fri Jun 22 11:15:22 2007
From: s.henderson at ucl.ac.uk (Stephen Henderson)
Date: Fri, 22 Jun 2007 10:15:22 +0100
Subject: [R] FW: Suse RPM installation problem
Message-ID: <61B482B74D6EE443B90356E080476E340189529B@exc2.cruciform.wibr.ucl.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070622/c335f286/attachment.pl 

From Camarda at demogr.mpg.de  Fri Jun 22 11:54:29 2007
From: Camarda at demogr.mpg.de (Camarda, Carlo Giovanni)
Date: Fri, 22 Jun 2007 11:54:29 +0200
Subject: [R]  legend and lend (line end style)
Message-ID: <8B08A3A1EA7AAC41BE24C750338754E60170062C@HERMES.demogr.mpg.de>

? stato filtrato un testo allegato il cui set di caratteri non era
indicato...
Nome: non disponibile
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070622/e350b987/attachment.pl 

From thomas.pujol at yahoo.com  Thu Jun 21 21:36:16 2007
From: thomas.pujol at yahoo.com (Thomas Pujol)
Date: Thu, 21 Jun 2007 12:36:16 -0700 (PDT)
Subject: [R] what is "better" when combining data frames? merge vs. rbind &
	cbind
Message-ID: <510958.56904.qm@web59308.mail.re1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070621/92ee7e56/attachment.pl 

From christian.bieli at unibas.ch  Fri Jun 22 12:31:39 2007
From: christian.bieli at unibas.ch (Christian Bieli)
Date: Fri, 22 Jun 2007 12:31:39 +0200
Subject: [R] extract index during execution of sapply
Message-ID: <467BA50B.60408@unibas.ch>

Hi there
During execution of sapply I want to extract the number of times the 
function given to supply has been executed. I came up with:

mylist <- list(a=3,b=6,c=9)
sapply(mylist,function(x)as.numeric(gsub("[^0-9]","",deparse(substitute(x)))))

This works fine, but looks quite ugly. I'm sure that there's a more 
elegant way to do this.

Any suggestion?

Christian


From amicogodzilla at bruttocarattere.org  Fri Jun 22 12:37:37 2007
From: amicogodzilla at bruttocarattere.org (Manuele Pesenti)
Date: Fri, 22 Jun 2007 12:37:37 +0200
Subject: [R] multiple return
Message-ID: <200706221237.37479.amicogodzilla@bruttocarattere.org>

Dear User,
what's the correct way to obtain a multiple return from a function?

for example creating the simple function:

somma <- function (a, b) {
  c <- a+b
  return (a, b, c)
}

when I call it, it runs but returns the following output:

> somma(5, 7)
$a
[1] 5

$b
[1] 7

$c
[1] 12

Warning message:
return multi-argomento sono deprecati in: return(a, b, c) 

i.e. multi-return is deprecated...

thanks a lot
best regards
	Manuele

-- 
Manuele Pesenti
	manuele a inventati.org
	amicogodzilla a jabber.linux.it
	http://mpesenti.polito.it


From murdoch at stats.uwo.ca  Fri Jun 22 12:40:23 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 22 Jun 2007 06:40:23 -0400
Subject: [R] what is "better" when combining data frames? merge vs.
 rbind &	cbind
In-Reply-To: <510958.56904.qm@web59308.mail.re1.yahoo.com>
References: <510958.56904.qm@web59308.mail.re1.yahoo.com>
Message-ID: <467BA717.7080202@stats.uwo.ca>

On 21/06/2007 3:36 PM, Thomas Pujol wrote:
> I often need to "combine" data frames, sometimes "vertically" and other times "horizontally".
> 
> When it "better" to use merge? When is it better to use rbind or cbind?
> 
> Are there clear pros and cons of each approach?

If rbind or cbind work, use them.  They are much simpler, but much less 
flexible.

Duncan Murdoch


From mlatif at isrt.ac.bd  Fri Jun 22 13:20:01 2007
From: mlatif at isrt.ac.bd (Mahbub Latif)
Date: Fri, 22 Jun 2007 17:20:01 +0600
Subject: [R] multiple return
In-Reply-To: <200706221237.37479.amicogodzilla@bruttocarattere.org>
References: <200706221237.37479.amicogodzilla@bruttocarattere.org>
Message-ID: <5faba43d0706220420m6f34f831l7353b680925dae34@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070622/d2af978f/attachment.pl 

From jim at bitwrit.com.au  Fri Jun 22 13:36:29 2007
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 22 Jun 2007 21:36:29 +1000
Subject: [R] how to create cumulative histogram from two
	independent	variables?
In-Reply-To: <7cced4ed0706201302y3df7a375hbcf775b58a0cb2bc@mail.gmail.com>
References: <7cced4ed0706201302y3df7a375hbcf775b58a0cb2bc@mail.gmail.com>
Message-ID: <467BB43D.3060004@bitwrit.com.au>

Jose Borreguero wrote:
> Hi all,
> I am extremely newbie to R. Can anybody jump-start me with any clues as to
> how do I get a cumulative histogram from two independent variables,
> cumhist(X,Y) ?
> -jose
> 
Hi Jose,

Is this something like you want?

var1<-sample(1:10,100,TRUE)
var2<-sample(1:10,100,TRUE)
barplot(rbind(hist(var1,plot=FALSE)$counts,hist(var2,plot=FALSE)$counts))

Jim


From jrkrideau at yahoo.ca  Fri Jun 22 13:44:23 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Fri, 22 Jun 2007 07:44:23 -0400 (EDT)
Subject: [R] Adding exponents (superscript format) to a plot
In-Reply-To: <273959.28789.qm@web34707.mail.mud.yahoo.com>
Message-ID: <466583.57100.qm@web32802.mail.mud.yahoo.com>

# Using expression to add superscipts to the labels

vec=c(1,10,100,1000,10000,100000,1000000,10000000)
  plot(vec,vec,log="xy", axes=F)
 axis(1, at=10^c(0,2,4,6), labels=expression(1, 10^2,
10^4, 10^6))
 axis(2, at=10^c(0,2,4,6), labels=expression(1, 10^2,
10^4, 10^6), las=1)
 box()

--- Judith Flores <juryef at yahoo.com> wrote:

> Hi,
> 
>    I need to add exponents to a label in one of the
> axes of a plot, how can I do this?
> 
> Thank you,
> 
> Judith
> 
> 
>  
>
____________________________________________________________________________________
> Food fight? Enjoy some healthy debate
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From bates at stat.wisc.edu  Fri Jun 22 13:45:26 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 22 Jun 2007 06:45:26 -0500
Subject: [R] using lme on multiple datasets in one shot
In-Reply-To: <0511221510741711@webmail.iastate.edu>
References: <0511221510741711@webmail.iastate.edu>
Message-ID: <40e66e0b0706220445j5b5d74d7nb46237f83f0b8432@mail.gmail.com>

On 6/21/07, maitra at iastate.edu <maitra at iastate.edu> wrote:
> Dear list,

> I would like to do a huge number of lme's using the same design matrix
> (and fixed and random effects). Is it possible to do this efficiently?
> Doing otherwise is not an option for my example.

> Basically, I am wanting to do the following which is possible using lm:

> X <- matrix(rnorm(50),10,5)
> Y <- matrix(rnorm(50),10,5)
> lm(Y~X)

> with lme. Any suggestions?

It would not be easy to do this.  Neither lme nor lmer were designed
to make this easy to do.  There is a better chance of accomplishing
this by creating a custom function based on the current lmer but the
modifications required are non-trivial.

This is a reasonable thing to want to accomplish and I will add it to
the "To Do" list for lmer.  However it is not something I will be able
to get to soon.


From S.Ellison at lgc.co.uk  Fri Jun 22 13:49:38 2007
From: S.Ellison at lgc.co.uk (S Ellison)
Date: Fri, 22 Jun 2007 12:49:38 +0100
Subject: [R] abline plots at wrong abscissae after boxplot
Message-ID: <s67bc579.034@tedmail2.lgc.co.uk>

Boxplot positions and labels are not the same thing.
You have groups 'called' "2", "3", "4". As factors - which is what bocplot will turn them into -  they will be treated as arbitrary labels and _numbered_ 1:3 (try as.numeric(factor(x)). 

So your lm() used 2:4, but your plot (and abline) uses 1:3 for positions and "2" - "4" as labels. 

The best option used to be to plot the boxes at positions 2:4. Look at the at= parameter in boxplot.
But that is now of little help because there is no way of overriding xlim, leaving you no alternative but to reformulate your model with an offset or something. 

I will take up the boxplot xlim issue separately on R-dev; it's not the only such.

Steve Ellison.

>>> "Brian Wilfley" <bwilfley at tripleringtech.com> 21/06/2007 22:44:17 >>>
I'm trying to add lines to a plot originally made with "boxplot", but
the lines appear in the wrong place. 

*******************************************************************
This email and any attachments are confidential. Any use, co...{{dropped}}


From S.Ellison at lgc.co.uk  Fri Jun 22 14:02:20 2007
From: S.Ellison at lgc.co.uk (S Ellison)
Date: Fri, 22 Jun 2007 13:02:20 +0100
Subject: [R] Boxplot issues
Message-ID: <s67bc871.078@tedmail2.lgc.co.uk>

Boxplot and bxp seem to have changed behaviour a bit of late (R 2.4.1). Or maybe I am mis-remembering.

An annoying feature is that while at=3:6 will work, there is no way of overriding the default xlim of 0.5 to n+0.5. That prevents plotting boxes on, for example, interval scales - a useful thing to do at times. I really can see no good reason for bxp to hard-core the xlim=c(0.5, n+0.5) in the function body; it should be a parameter default conditional on horizontal=, not hard coded.

Also, boxplot does not drop empty groups. I'm sure it used to. I know it is good to be able to see where a factor level is unpopulated, but its a nuisance with fractional factorials and some nested or survey problems when many are known to be missing and are of no interest. Irrespective of whether my memory is correct, the option would be useful. How hard can it be to add a 'drop.empty=F' default to boxplot to allow it to switch?

Obviously, these are things I can fix locally. But who 'owns' boxplot so I can provide suggested code to them for later releases? 

Steve Ellison



*******************************************************************
This email and any attachments are confidential. Any use, co...{{dropped}}


From f.harrell at vanderbilt.edu  Fri Jun 22 14:35:51 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Fri, 22 Jun 2007 07:35:51 -0500
Subject: [R] help on the use of ldBand
In-Reply-To: <20070622075254.EEC5F19E607@cartero1.unavarra.es>
References: <20070622075254.EEC5F19E607@cartero1.unavarra.es>
Message-ID: <467BC227.8000701@vanderbilt.edu>

Tomas Goicoa wrote:
>   Hi R Users,
> 
>   I am trying to use the ldBand package. Together 
> with the package, I have downloaded the ld98 
> program (version for windows) as indicated in the 
> help page on ldBand. I did it, but obtained an 
> error message "Error in (head + 1):length(w) : 
> Argument NA/NaN" when I copied the help examples, 
> so it seems that a conection between R and ld98 
> is not well performed in my computer.  Did I put 
> ld98.exe in the wrong place? If so,  where should 
> I put it? Thanks a lot in advance,
> 
> 
>   Berta Iba?ez Beroiz

Do you mean the Hmisc package?  Do you mean the ldBands function?  Did 
you put ld98.exe in a place that is in your system path as specified in 
the ldBands help file?  And please read the posting guide referenced below.

Frank

> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From Thierry.ONKELINX at inbo.be  Fri Jun 22 13:27:35 2007
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 22 Jun 2007 13:27:35 +0200
Subject: [R] multiple return
In-Reply-To: <200706221237.37479.amicogodzilla@bruttocarattere.org>
Message-ID: <2E9C414912813E4EB981326983E0A104031A9629@inboexch.inbo.be>

Put the return values in a vector or list

somma <- function (a, b) {
   c <- a+b
   return (c(a = a, b = b, c = c))
}

somma(5,7)
 a  b  c 
 5  7 12 


somma <- function (a, b) {
   c <- a+b
   return (list(a = a, b = b, c = c))
}

somma(5,7)
$a
[1] 5

$b
[1] 7

$c
[1] 12

Cheers,

Thierry
------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium
tel. + 32 54/436 185
Thierry.Onkelinx op inbo.be
www.inbo.be 

Do not put your faith in what statistics say until you have carefully
considered what they do not say.  ~William W. Watt
A statistical analysis, properly conducted, is a delicate dissection of
uncertainties, a surgery of suppositions. ~M.J.Moroney

 

> -----Oorspronkelijk bericht-----
> Van: r-help-bounces op stat.math.ethz.ch 
> [mailto:r-help-bounces op stat.math.ethz.ch] Namens Manuele Pesenti
> Verzonden: vrijdag 22 juni 2007 12:38
> Aan: r-help op stat.math.ethz.ch
> Onderwerp: [R] multiple return
> 
> Dear User,
> what's the correct way to obtain a multiple return from a function?
> 
> for example creating the simple function:
> 
> somma <- function (a, b) {
>   c <- a+b
>   return (a, b, c)
> }
> 
> when I call it, it runs but returns the following output:
> 
> > somma(5, 7)
> $a
> [1] 5
> 
> $b
> [1] 7
> 
> $c
> [1] 12
> 
> Warning message:
> return multi-argomento sono deprecati in: return(a, b, c) 
> 
> i.e. multi-return is deprecated...
> 
> thanks a lot
> best regards
> 	Manuele
> 
> --
> Manuele Pesenti
> 	manuele op inventati.org
> 	amicogodzilla op jabber.linux.it
> 	http://mpesenti.polito.it
> 
> ______________________________________________
> R-help op stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mtmorgan at fhcrc.org  Fri Jun 22 15:20:27 2007
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Fri, 22 Jun 2007 06:20:27 -0700
Subject: [R] extract index during execution of sapply
In-Reply-To: <467BA50B.60408@unibas.ch> (Christian Bieli's message of "Fri,
	22 Jun 2007 12:31:39 +0200")
References: <467BA50B.60408@unibas.ch>
Message-ID: <6phodj85dno.fsf@gopher4.fhcrc.org>

Christian,

A favorite of mine is to use lexical scope and a 'factory' model:

> fun_factory <- function() {
+     i <- 0                  # 'state' variable(s), unique to each fun_factory
+     function(x) {           # fun_factory return value; used as sapply FUN
+         i <<- i + 1         # <<- assignment finds i
+         x^i                 # return value of sapply FUN
+     }
+ }
> 
> sapply(1:10, fun_factory())
 [1]           1           4          27         256        3125       46656
 [7]      823543    16777216   387420489 10000000000


Christian Bieli <christian.bieli at unibas.ch> writes:

> Hi there
> During execution of sapply I want to extract the number of times the 
> function given to supply has been executed. I came up with:
>
> mylist <- list(a=3,b=6,c=9)
> sapply(mylist,function(x)as.numeric(gsub("[^0-9]","",deparse(substitute(x)))))
>
> This works fine, but looks quite ugly. I'm sure that there's a more 
> elegant way to do this.
>
> Any suggestion?
>
> Christian
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Martin Morgan
Bioconductor / Computational Biology
http://bioconductor.org


From r.hankin at noc.soton.ac.uk  Fri Jun 22 15:28:07 2007
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Fri, 22 Jun 2007 14:28:07 +0100
Subject: [R] vectorize a function
Message-ID: <F77DEE3F-E5AA-4A9B-A722-18F7DA006F46@noc.soton.ac.uk>

Hello everyone

suppose I have an integer vector "a" of length "n" and
a symmetric matrix "M" of size n-by-n.

Vector "a" describes a partition of a set of "n" elements
and matrix M describes a penalty function: row i column
j represents the penalty if element i and element j
are in the same partition.

Toy example follows; the real case is much larger
and I need to evaluate my penalty function many times.

If a <- c(1,1,2,1,3)  then elements 1,2,4 are in the
same partition; element 3 is in a partition on its own
and element 5 is in a partition on its own.

The total penalty  can be described by the following (ugly)
function:

f <- function(a,M){
   out <- 0
   for(i in unique(a)){
     out <- out + sum(M[which(a==i),which(a==i)])
   }
   return(out)
}


so with

M <- matrix(rpois(25,3),5,5)
M <- M+t(M)
diag(M) <- 0
a <- c(1,2,1,1,3)

f(a,M) gives the total penalty.


QUESTION:  how to rewrite f() so that it has no loop?






--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743


From kevin.thorpe at utoronto.ca  Fri Jun 22 15:56:20 2007
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Fri, 22 Jun 2007 09:56:20 -0400
Subject: [R] Tools For Preparing Data For Analysis
In-Reply-To: <dea6cb960706080127u2448b5e9v7e04b400b57fbded@mail.gmail.com>
References: <874da0b40706071701m55cd42fem15f55a8fcde04f17@mail.gmail.com>
	<dea6cb960706080127u2448b5e9v7e04b400b57fbded@mail.gmail.com>
Message-ID: <467BD504.4040705@utoronto.ca>

I am posting to this thread that has been quiet for some time because I
remembered the following question.

Christophe Pallier wrote:
> Hi,
> 
> Can you provide examples of data formats that are problematic to read and
> clean with R ?

Today I had a data manipulation problem that I don't know how to do in R
so I solved it with perl.  Since I'm always interested in learning more
about complex data manipulation in R I am posting my problem in the
hopes of receiving some hints for doing this in R.

If anyone has nothing better to do than play with other people's data,
I would be happy to send the row files off-list.

Background:

I have been given data that contains two measurements of left
ventricular ejection fraction.  One of the methods is echocardiogram
which sometimes gives a true quantitative value and other times a
semi-quantitative value.  The desire is to compare echo with the
other method (MUGA).  In most cases, patients had either quantitative
or semi-quantitative.  Same patients had both.  The data came
to me in excel files with, basically, no patient identifiers to link
the "both" with the semi-quantitative patients (the "both" patients
were in multiple data sets).

What I wanted to do was extract from the semi-quantitative data file
those patients with only semi-quantitative.  All I have to link with
are the semi-quantitative echo and the MUGA and these pairs of values
are not unique.

To make this more concrete, here are some portions of the raw data.

"Both"

"ID NUM","ECHO","MUGA","Semiquant","Quant"
"B",12,37,10,12
"D",13,13,10,13
"E",13,26,10,15
"F",13,31,10,13
"H",15,15,10,15
"I",15,21,10,15
"J",15,22,10,15
"K",17,22,10,17
"N",17.5,4,10,17.5
"P",18,25,10,18
"R",19,25,10,19

Seimi-quantitative

"echo","muga","quant"
10,20,0      <-- keep
10,20,0      <-- keep
10,21,0      <-- remove
10,21,0      <-- keep
10,24,0      <-- keep
10,25,0      <-- remove
10,25,0      <-- remove
10,25,0      <-- keep

Here is the perl program I wrote for this.

#!/usr/bin/perl

open(BOTH, "quant_qual_echo.csv") || die "Can't open quant_qual_echo.csv";
# Discard first row;
$_ = <BOTH>;
while(<BOTH>) {
    chomp;
    ($id, $e, $m, $sq, $qu) = split(/,/);
    $both{$sq,$m}++;
}
close(BOTH);

open(OUT, "> qual_echo_only.csv") || die "Can't open qual_echo_only.csv";
print OUT "pid,echo,muga,quant\n";
$pid = 2001;

open(QUAL, "qual_echo.csv") || die "Can't open qual_echo.csv";
# Discard first row
$_ = <QUAL>;
while(<QUAL>) {
    chomp;
    ($echo, $muga, $quant) = split(/,/);
    if ($both{$echo,$muga} > 0) {
        $both{$echo,$muga}--;
    }
    else {
        print OUT "$pid,$echo,$muga,$quant\n";
        $pid++;
    }
}
close(QUAL);
close(OUT);

open(OUT, "> both_echo.csv") || die "Can't open both_echo.csv";
print OUT "pid,echo,muga,quant\n";
$pid = 3001;

open(BOTH, "quant_qual_echo.csv") || die "Can't open quant_qual_echo.csv";
# Discard first row;
$_ = <BOTH>;
while(<BOTH>) {
    chomp;
    ($id, $e, $m, $sq, $qu) = split(/,/);
    print OUT "$pid,$sq,$m,0\n";
    print OUT "$pid,$qu,$m,1\n";
    $pid++;
}
close(BOTH);
close(OUT);


-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Department of Public Health Sciences
Faculty of Medicine, University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.6057


From Max.Kuhn at pfizer.com  Fri Jun 22 15:58:39 2007
From: Max.Kuhn at pfizer.com (Kuhn, Max)
Date: Fri, 22 Jun 2007 09:58:39 -0400
Subject: [R] Data consistency checks in functions
In-Reply-To: <162740.61793.qm@web53302.mail.re2.yahoo.com>
Message-ID: <71257D09F114DA4A8E134DEAC70F25D308B9745C@groamrexm03.amer.pfizer.com>

Anup,

There are two ways to pass arguments to functions in R: as named
arguments or by position*.

Users *can* supply arguments that are inconsistent with the order that
you specify in the function definition, but only if they are used as
named arguments:

   myfun(X = someMatrix, values = aVector, theta = whatever) 

If the arguments are passed by position (as in myfun(beta, val1)), R
will assume that the first argument is theta, the second is X, etc since
that is how the function is defined.

My suggestion would be to leave these arguments without defaults and put
a lot of checks in the function (using is.matrix, is.vector and a few
that check the content of the data I those objects).


* You can also mix the two:

   foo(data, outcome, start = rep(0, 3))



Max

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Anup Nandialath
Sent: Friday, June 22, 2007 12:19 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Data consistency checks in functions

Dear friends,

I'm writing a function with three arguments

myfun <- function(theta, X, values)

{
....
....
}

in this function, I'm trying to write consistency checks. In order to
compute the statistic of interest I only need theta and values. The idea
of having X in there is that, if values is not provided by the user,
then values is computed from X.

my problem is I'm trying to write consistency checks. For instance if i
say

output <- myfun(beta, val1), how do I ensure that R reads this as
passing arguments to "theta" and "values". In other words is it possible
to bypass X completely if values is provided. Also how is it possible
for R to recognize the second argument as being values and not X. This
is important because X is a matrix and values is a vector. Therefore any
checks using the dimensions of either one will land in trouble if it
does not correctly capture that. 

Thanks in advance
Sincerely

Anup

       
---------------------------------


	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

----------------------------------------------------------------------
LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}


From christos at nuverabio.com  Fri Jun 22 16:17:24 2007
From: christos at nuverabio.com (Christos Hatzis)
Date: Fri, 22 Jun 2007 10:17:24 -0400
Subject: [R] vectorize a function
In-Reply-To: <F77DEE3F-E5AA-4A9B-A722-18F7DA006F46@noc.soton.ac.uk>
References: <F77DEE3F-E5AA-4A9B-A722-18F7DA006F46@noc.soton.ac.uk>
Message-ID: <001b01c7b4d8$0e8129f0$0e010a0a@headquarters.silicoinsights>

How about:

sum(sapply(unique(a), function(x) {b <- which(a==x); sum(M[b, b])}))

HTH
-Christos

Christos Hatzis, Ph.D.
Nuvera Biosciences, Inc.
400 West Cummings Park
Suite 5350
Woburn, MA 01801
Tel: 781-938-3830
www.nuverabio.com
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Robin Hankin
> Sent: Friday, June 22, 2007 9:28 AM
> To: RHelp help
> Subject: [R] vectorize a function
> 
> Hello everyone
> 
> suppose I have an integer vector "a" of length "n" and a 
> symmetric matrix "M" of size n-by-n.
> 
> Vector "a" describes a partition of a set of "n" elements and 
> matrix M describes a penalty function: row i column j 
> represents the penalty if element i and element j are in the 
> same partition.
> 
> Toy example follows; the real case is much larger and I need 
> to evaluate my penalty function many times.
> 
> If a <- c(1,1,2,1,3)  then elements 1,2,4 are in the same 
> partition; element 3 is in a partition on its own and element 
> 5 is in a partition on its own.
> 
> The total penalty  can be described by the following (ugly)
> function:
> 
> f <- function(a,M){
>    out <- 0
>    for(i in unique(a)){
>      out <- out + sum(M[which(a==i),which(a==i)])
>    }
>    return(out)
> }
> 
> 
> so with
> 
> M <- matrix(rpois(25,3),5,5)
> M <- M+t(M)
> diag(M) <- 0
> a <- c(1,2,1,1,3)
> 
> f(a,M) gives the total penalty.
> 
> 
> QUESTION:  how to rewrite f() so that it has no loop?
> 
> 
> 
> 
> 
> 
> --
> Robin Hankin
> Uncertainty Analyst
> National Oceanography Centre, Southampton European Way, 
> Southampton SO14 3ZH, UK
>   tel  023-8059-7743
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
>


From bolker at ufl.edu  Fri Jun 22 15:23:08 2007
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 22 Jun 2007 13:23:08 +0000 (UTC)
Subject: [R] extract index during execution of sapply
References: <467BA50B.60408@unibas.ch>
Message-ID: <loom.20070622T151700-639@post.gmane.org>

Christian Bieli <christian.bieli <at> unibas.ch> writes:

> 
> Hi there
> During execution of sapply I want to extract the number of times the 
> function given to supply has been executed. I came up with:
> 
> mylist <- list(a=3,b=6,c=9)
> sapply(mylist,function(x)as.numeric(gsub("[^0-9]","",deparse(substitute(x)))))
> 
> This works fine, but looks quite ugly. I'm sure that there's a more 
> elegant way to do this.
> 
> Any suggestion?
> 
> Christian
> 

   I would love to have an answer to this -- when I run
into this kind of problem I usually end up using mapply:
e.g., suppose I have

mylist <- replicate(5,list(x=runif(10),y=runif(10)),simplify=FALSE)

and I want to plot each element in a different color.  I'd like
to be able to do

plot(0:1,0:1,type="n")
lapply(mylist,plot,col=i)

but instead I do

mapply(function(x,i) points(x,col=i),mylist,1:5)

would it be too ugly to have a special variable called INDEX
that could be used within an sapply/lapply statement?


From tlumley at u.washington.edu  Fri Jun 22 16:45:14 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 22 Jun 2007 07:45:14 -0700 (PDT)
Subject: [R] extract index during execution of sapply
In-Reply-To: <loom.20070622T151700-639@post.gmane.org>
References: <467BA50B.60408@unibas.ch>
	<loom.20070622T151700-639@post.gmane.org>
Message-ID: <Pine.LNX.4.64.0706220732470.20743@homer22.u.washington.edu>

On Fri, 22 Jun 2007, Ben Bolker wrote:

> Christian Bieli <christian.bieli <at> unibas.ch> writes:
>
>>
>> Hi there
>> During execution of sapply I want to extract the number of times the
>> function given to supply has been executed. I came up with:
>>
>> mylist <- list(a=3,b=6,c=9)
>> sapply(mylist,function(x)as.numeric(gsub("[^0-9]","",deparse(substitute(x)))))
>>
>> This works fine, but looks quite ugly. I'm sure that there's a more
>> elegant way to do this.
>>
>> Any suggestion?
>>
>> Christian
>>
>
>   I would love to have an answer to this -- when I run
> into this kind of problem I usually end up using mapply:
> e.g., suppose I have
>
> mylist <- replicate(5,list(x=runif(10),y=runif(10)),simplify=FALSE)
>
> and I want to plot each element in a different color.  I'd like
> to be able to do
>
> plot(0:1,0:1,type="n")
> lapply(mylist,plot,col=i)
>
> but instead I do
>
> mapply(function(x,i) points(x,col=i),mylist,1:5)
>
> would it be too ugly to have a special variable called INDEX
> that could be used within an sapply/lapply statement?
>

There are two distinct suggestions here: a variable that says *how many* 
times the function has been called, and a variable that say *which 
element* is currently being operated on.   The first seems undesirable as 
order of evaluation really should not matter in the apply functions.

The second makes more sense but is still a little tricky. AFAICS there is 
no way for lapply() to find out whether FUN will accept an argument INDEX 
without an "unused argument(s)" error, so it can't just be passed as an 
argument.  This suggests having yet another apply function, that would 
assume an INDEX argument and might be written
   yapply<-function(X,FUN, ...) {
 	index<-seq(length.out=length(X))
         mapply(FUN,X,INDEX=index,MoreArgs=list(...))
        }

However, I think it would be preferable in many cases for INDEX to be 
names(X) if it exists, rather than 1:n.  In any case, it is easy  to write 
the function.

 	-thomas


From kevin.oden at wachovia.com  Fri Jun 22 16:49:08 2007
From: kevin.oden at wachovia.com (Oden, Kevin)
Date: Fri, 22 Jun 2007 10:49:08 -0400
Subject: [R] fitCopula
Message-ID: <E3A68C90920A014CBB128279519B1B35042FEB87@M1WACA0030I001.cibna.msds.wachovia.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070622/ae6c6e50/attachment.pl 

From helprhelp at gmail.com  Fri Jun 22 16:58:35 2007
From: helprhelp at gmail.com (Weiwei Shi)
Date: Fri, 22 Jun 2007 10:58:35 -0400
Subject: [R] how to ave this?
Message-ID: <cdf817830706220758r10e93178x971a53e574e9488d@mail.gmail.com>

Hi,

I have a list that looks like this:
[[1]]
             fc          tt
50   0.07526882 0.000000000
100  0.09289617 0.000000000
150  0.12359551 0.000000000

[[2]]
             fc          tt
50   0.02040816 0.000000000
100  0.03626943 0.005025126
150  0.05263158 0.010101010

and I am wondering how to "average" it so that I have one matrix t0 at
the end, and t0[1,1] = (0.075..+0.0204..)/2

Thanks,

-- 
Weiwei Shi, Ph.D
Research Scientist
GeneGO, Inc.

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III


From kevin.oden at wachovia.com  Fri Jun 22 17:04:15 2007
From: kevin.oden at wachovia.com (Oden, Kevin)
Date: Fri, 22 Jun 2007 11:04:15 -0400
Subject: [R] fitCopula
Message-ID: <E3A68C90920A014CBB128279519B1B35042FEB88@M1WACA0030I001.cibna.msds.wachovia.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070622/66b453fb/attachment.pl 

From helprhelp at gmail.com  Fri Jun 22 17:20:19 2007
From: helprhelp at gmail.com (Weiwei Shi)
Date: Fri, 22 Jun 2007 11:20:19 -0400
Subject: [R] how to ave this?
In-Reply-To: <cdf817830706220758r10e93178x971a53e574e9488d@mail.gmail.com>
References: <cdf817830706220758r10e93178x971a53e574e9488d@mail.gmail.com>
Message-ID: <cdf817830706220820k7db2f82dv3e2a2e7d7a39ff69@mail.gmail.com>

one of my approaches is:

x0 = sapply(mylist, cbind)

and manipulate from x0 (x0[1:nrow(x0)/2, ] correponds to fc and the
lower part is tt.

but it is not neat way.


On 6/22/07, Weiwei Shi <helprhelp at gmail.com> wrote:
> Hi,
>
> I have a list that looks like this:
> [[1]]
>              fc          tt
> 50   0.07526882 0.000000000
> 100  0.09289617 0.000000000
> 150  0.12359551 0.000000000
>
> [[2]]
>              fc          tt
> 50   0.02040816 0.000000000
> 100  0.03626943 0.005025126
> 150  0.05263158 0.010101010
>
> and I am wondering how to "average" it so that I have one matrix t0 at
> the end, and t0[1,1] = (0.075..+0.0204..)/2
>
> Thanks,
>
> --
> Weiwei Shi, Ph.D
> Research Scientist
> GeneGO, Inc.
>
> "Did you always know?"
> "No, I did not. But I believed..."
> ---Matrix III
>


-- 
Weiwei Shi, Ph.D
Research Scientist
GeneGO, Inc.

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III


From ripley at stats.ox.ac.uk  Fri Jun 22 17:26:57 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 22 Jun 2007 16:26:57 +0100 (BST)
Subject: [R] Result depends on order of factors in unbalanced designs
 (lme, anova)?
In-Reply-To: <393002.75525.qm@web26513.mail.ukl.yahoo.com>
References: <393002.75525.qm@web26513.mail.ukl.yahoo.com>
Message-ID: <Pine.LNX.4.64.0706221617190.11817@gannet.stats.ox.ac.uk>

'anova' is rather a misnomer here.  In terms of the description in 
?anova.lme, you have

      When only one fitted model object is present, a data frame with
      the sums of squares, numerator degrees of freedom, denominator
      degrees of freedom, F-values, and P-values for Wald tests for the
      terms in the model ...

but there are no 'sums of squares' shown.  However, the crucial part of 
that help page is

     type: an optional character string specifying the type of sum of
           squares to be used in F-tests for the terms in the model. If
           '"sequential"', the sequential sum of squares obtained by
           including the terms in the order they appear in the model is
           used; else, if '"marginal"', the marginal sum of squares
           obtained by deleting a term from the model at a time is used.
           This argument is only used when a single fitted object is
           passed to the function. Partial matching of arguments is
           used, so only the first character needs to be provided.
           Defaults to '"sequential"'.

so these are sequential fits (just like anova for an lm fit), and yes, 
sequential fits do in general depend on the sequence of terms.

The issues of interpretation are exactly those of unbalanced linear 
models, and you will find advice on that in many places, e.g. in MASS.


On Thu, 21 Jun 2007, Karl Knoblick wrote:

> Dear R-Community!
>
> For example I have a study with 4 treatment groups (10 subjects per group) and 4 visits. Additionally, the gender is taken into account. I think - and hope this is a goog idea (!) - this data can be analysed using lme as below.
>
> In a balanced design everything is fine, but in an unbalanced design there are differences depending on fitting y~visit*treat*gender or y~gender*visit*treat - at least with anova (see example). Does this make sense? Which ordering might be the correct one?
>
> Here the example script:
> library(nlme)
> set.seed(123)
> # Random generation of data:
> NSubj<-40 # No. of subjects
> set.seed(1234)
> id<-factor(rep(c(1:NSubj),4)) # ID of subjects
> treat<-factor(rep(rep(1:4,each=5),4)) # Treatment 4 Levels
> gender<-factor(rep(rep(1:2, each=20),4))
> visit<-factor(rep(1:4, each=NSubj))
> y<-runif(4*NSubj) # Results
> # Add effects
> y<-y+0.01*as.integer(visit)
> y<-y+0.02*as.integer(gender)
> y<-y+0.024*as.integer(treat)
> df<-data.frame(id, treat, gender, visit, y)
> # groupedData object for lme
> gdat<-groupedData(y ~ visit|id, data=df)
> # fits - different ordering of factors
> fit1<-lme(y ~ visit*treat*gender, data=gdat, random = ~visit|id)
> anova(fit1)
> fit2<-lme(y ~ gender*treat*visit, data=gdat, random = ~visit|id)
> anova(fit2)
> # Result: identical (balanced design so far), ok
> # Now change gender of subject 1
> gdat$gender[c(1,41,81,121)]<-2
> # onece more fits with different ordering of factors
> fit1<-lme(y ~ visit*treat*gender, data=gdat, random = ~visit|id)
> anova(fit1)
> fit2<-lme(y ~ gender*treat*visit, data=gdat, random = ~visit|id)
> anova(fit2)
> # Result: There are differences!!
>
> Hope anybody can help or give me advice how to interpret these results correctly or how to avoid this problem! Is there a better possibility to analyse these data than lme?
>
> Thanks!
> Karl

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From christophe at pallier.org  Fri Jun 22 17:27:42 2007
From: christophe at pallier.org (Christophe Pallier)
Date: Fri, 22 Jun 2007 17:27:42 +0200
Subject: [R] Tools For Preparing Data For Analysis
In-Reply-To: <467BD504.4040705@utoronto.ca>
References: <874da0b40706071701m55cd42fem15f55a8fcde04f17@mail.gmail.com>
	<dea6cb960706080127u2448b5e9v7e04b400b57fbded@mail.gmail.com>
	<467BD504.4040705@utoronto.ca>
Message-ID: <dea6cb960706220827y4c281c31t493106eeaffedd4b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070622/cc1dcbf9/attachment.pl 

From s.wood at bath.ac.uk  Fri Jun 22 17:30:44 2007
From: s.wood at bath.ac.uk (Simon Wood)
Date: Fri, 22 Jun 2007 16:30:44 +0100
Subject: [R] interpretation of F-statistics in GAMs
In-Reply-To: <OFB56A7571.DC604C2B-ONC12572FB.0027155F-C12572FB.00271563@niva.no>
References: <OFB56A7571.DC604C2B-ONC12572FB.0027155F-C12572FB.00271563@niva.no>
Message-ID: <200706221630.44317.s.wood@bath.ac.uk>

On Friday 15 June 2007 08:06, robert.ptacnik at niva.no wrote:
> dear listers,
> I use gam (from mgcv) for evaluation of shape and strength of relationships
> between a response variable and several predictors.
> How can I interpret the 'F' values viven in the GAM summary? Is it
> appropriate to treat them in a similar manner as the T-statistics in a
> linear model, i.e. larger values mean that this variable has a stronger
> impact than a variable with smaller F?
- I'd be a bit cautious about this (even for T-statistics and linear models 
it's not quite clear to me what `impact' means if judged this way). These gam 
F statistics are only meant to provide a rough and ready means of judging 
approximate significance of terms, and I'm unsure about interpreting a  
comparison of such F ratios: for example the F statistics can be based on 
differerent numbers of degrees of freedom, depending on the term concerned...

> When I run my analysis for two different response varables (but identical
> predictors), is there a way to compare the F values among tests (like to
> standardize them by teh sum of F within each test?) I append two summaries
> below.
- Again, I don't really known how this would work. I'd be more inclined to 
compare the plotted terms and associated CIs (and maybe the p-values), 
especially if you are using GAMs in a quite exploratory way (e.g. if the 
assumption of an additive structure is really a convenience, rather than 
being something that is suggested by the underlying science). 

best,
Simon

>
>
> ### example 1 ###
>
> Family: gaussian
> Link function: identity
>
> Formula:
> dep[sel, i] ~ s(date, k = 3) + s(depth, k = kn) + s(temp, k = kn) +
>     s(light, k = kn) + s(PO4, k = kn) + s(DIN, k = kn) + s(prop.agpla,
>     k = kn)
>
> Parametric coefficients:
>             Estimate Std. Error t value Pr(>|t|)
> (Intercept)   5.1048     0.0384   132.9   <2e-16 ***
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> Approximate significance of smooth terms:
>                 edf Est.rank      F  p-value
> s(date)       1.669        2 12.161 1.07e-05 ***
> s(depth)      1.671        2 36.125 4.85e-14 ***
> s(temp)       1.927        2  6.686  0.00156 **
> s(light)      1.886        2 12.604 7.20e-06 ***
> s(PO4)        1.676        2  3.237  0.04143 *
> s(DIN)        1.000        1 38.428 3.41e-09 ***
> s(prop.agpla) 1.405        2 15.987 3.79e-07 ***
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> R-sq.(adj) =  0.687   Deviance explained = 70.5%
> GCV score = 0.31995   Scale est. = 0.30076   n = 204
>
> ### example 2 ###
> Family: gaussian
> Link function: identity
>
> Formula:
> dep[sel, i] ~ s(date, k = 3) + s(depth, k = kn) + s(temp, k = kn) +
>     s(light, k = kn) + s(PO4, k = kn) + s(DIN, k = kn) + s(prop.agpla,
>     k = kn)
>
> Parametric coefficients:
>             Estimate Std. Error t value Pr(>|t|)
> (Intercept)  7.13588    0.05549   128.6   <2e-16 ***
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> Approximate significance of smooth terms:
>                 edf Est.rank      F  p-value
> s(date)       1.944        2 15.997 3.67e-07 ***
> s(depth)      1.876        2 25.427 1.52e-10 ***
> s(temp)       1.000        1  2.866   0.0921 .
> s(light)      1.751        2  4.212   0.0162 *
> s(PO4)        1.950        2 10.632 4.14e-05 ***
> s(DIN)        1.805        2 10.745 3.73e-05 ***
> s(prop.agpla) 1.715        2  2.674   0.0715 .
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
>  R-sq.(adj) =  0.479   Deviance explained = 50.9%
> GCV score = 0.6863   Scale est. = 0.64348   n = 209
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented, minimal,
> self-contained, reproducible code.

-- 
> Simon Wood, Mathematical Sciences, University of Bath, Bath, BA2 7AY UK
> +44 1225 386603  www.maths.bath.ac.uk/~sw283


From maechler at stat.math.ethz.ch  Fri Jun 22 17:53:01 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 22 Jun 2007 17:53:01 +0200
Subject: [R] Boxplot issues
In-Reply-To: <s67bc871.078@tedmail2.lgc.co.uk>
References: <s67bc871.078@tedmail2.lgc.co.uk>
Message-ID: <18043.61533.242252.779598@stat.math.ethz.ch>

>>>>> "SE" == S Ellison <S.Ellison at lgc.co.uk>
>>>>>     on Fri, 22 Jun 2007 13:02:20 +0100 writes:

    SE> Boxplot and bxp seem to have changed behaviour a bit of late (R 2.4.1). Or maybe I am mis-remembering.
    SE> An annoying feature is that while at=3:6 will work, there is no way of overriding the default xlim of 0.5 to n+0.5. That prevents plotting boxes on, for example, interval scales - a useful thing to do at times. I really can see no good reason for bxp to hard-core the xlim=c(0.5, n+0.5) in the function body; it should be a parameter default conditional on horizontal=, not hard coded.

    SE> Also, boxplot does not drop empty groups. I'm sure it used to. I know it is good to be able to see where a factor level is unpopulated, but its a nuisance with fractional factorials and some nested or survey problems when many are known to be missing and are of no interest. Irrespective of whether my memory is correct, the option would be useful. How hard can it be to add a 'drop.empty=F' default to boxplot to allow it to switch?

    SE> Obviously, these are things I can fix locally. But who 'owns' boxplot so I can provide suggested code to them for later releases? 


Legally speaking, I think that's a hard question the answer of
which may even depend on the country where it is answered.
I would like to say it is owned by the R Foundation.

Suggested improvements of the R "base code" should be made and
discussed on the R-devel mailing list. That's exactly the main
purpose of that list.  
Such propositions typically make it into the code base
if you are convincing and you provide code improvements that
convince at least one member of R core that it's worth his time
to implement, document, *and* test the changes.

Also, as on R-help, it helps to work with small reproducible
(ideally "cut-n-pastable") R code examples.

Regards,
Martin Maechler

    SE> Steve Ellison


From pomchip at free.fr  Fri Jun 22 18:19:35 2007
From: pomchip at free.fr (=?UTF-8?B?U8OpYmFzdGllbg==?=)
Date: Fri, 22 Jun 2007 12:19:35 -0400
Subject: [R] Overlaying lattice graphs (continued)
In-Reply-To: <eb555e660706211319y4332d5c9kd406411bff620043@mail.gmail.com>
References: <4679F719.7020308@free.fr>	
	<f8e6ff050706210513r51fd9d28mb102a919e20499d6@mail.gmail.com>	
	<467A74D5.4090808@free.fr>
	<eb555e660706211319y4332d5c9kd406411bff620043@mail.gmail.com>
Message-ID: <467BF697.8050203@free.fr>

Hi Deepayan,

The following code creates a dummy dataset which has the same similar as 
my usual datasets. I did not try to implement the changes proposed by 
Hadley, hoping that a solution can be found using the original dataset.

######### My code

# Creating dataset

nPts<-10            # number of time points
nInd<-6              # number of individuals
nModel<-3         # number of models

TimePts<-rep(1:nPts,nInd*nModel)                                    # 
creates the "Time" column
Coef<-rep(rnorm(6,0.1,0.01),each=nPts,nModel)             # Creates a 
vector of coefficients for generating the observations
Obs<-10*exp(-Coef*TimePts)                                         # 
creates the observations

for (i in 1:60){
Pred[i]<-jitter(10*exp(-Coef[i]*TimePts[i]))
Pred[i+60]<-jitter(5)
Pred[i+120]<-jitter(10-Coef[i+120]*TimePts[i])
}                                                                        
                  # creates the predicted values

colPlot<-rep(1,nPts*nInd*nModel)                                       
    # creates the "Plot" column
colModel<-gl(nModel,nPts*nInd,labels=c("A","B","C"))             # 
creates the "Model" column
colID<-gl(nInd,nPts,nPts*nInd*nModel)                                 
      # creates the "ID" column

mydata<-data.frame(colPlot,colModel,colID,TimePts,Obs,Pred)              
              # creates the dataset
names(mydata)<-c("Plot","Model","Individuals","Time","Observed","Predicted")

# Plotting as indicated by Deepayan

xyplot(Observed + Predicted ~ Time | Individuals + Model,
      data = mydata,
      panel = panel.superpose.2, type = c("p", "l"),
      layout = c(0, nlevels(mydata$Individuals))) #,
      #<...>)

####### End of code

This codes is not exactly what I am looking for, although it is pretty 
close. In the present case, I would like to have a Trellis plot with 6 
panels (one for each individual), where the Observations and the 
Predicted are plotted as symbols and lines, respectively. All three 
models should be plotted on the same panel. Unfortunately, it looks to 
me as 3 successives xyplots are created by the code above but only the 
last one remains displayed. I tried to play with 
panel.superpose,panel.superpose.2 and type, without much success.

I also tried the following code that creates 18 panels and distinguish 
all (Individuals,Model) couples... so, not what I want.

xyplot(Observed + Predicted ~ Time | Individuals+Model, data = mydata,
     type = c("p", "l"), distribute.type = TRUE)

Sebastien


Deepayan Sarkar a ?crit :
> On 6/21/07, S?bastien <pomchip at free.fr> wrote:
>> Hi Hadley,
>>
>> Hopefully, my dataset won't be too hard to changed. Can I modify the
>> aspect of each group using your code (symbols for observed and lines for
>> predicted)?
>>
>> Sebastien
>>
>> hadley wickham a ?crit :
>> > Hi Sebastian,
>> >
>> > I think you need to rearrange your data a bit.  Firstly, you need to
>> > put observed on the same footing as the different models, so you would
>> > have a new column in your data called value (previously observed and
>> > predicted) and a new model type ("observed").  Then you could do:
>
> Yes, and ?make.groups (and reshape of course) could help with that.
> This might not be strictly necessary though.
>
> However, I'm finding your pseudo-code confusing. Could you create a
> small example data set that can be used to try out some real code?
> Just from your description, I would have suggested something like
>
> xyplot(Observed + Predicted ~ Time | Individuals + Model,
>       data = mydata,
>       panel = panel.superpose.2, type = c("p", "l"),
>       layout = c(0, nlevels(mydata$Individuals)),
>       <...>)
>
> If all you want is to plot one page at a time, there are easier ways 
> to do that.
>
> -Deepayan
>
>> >
>> > xyplot(value ~ time | individauls, data=mydata, group=model)
>> >
>> > Hadley
>> >
>> >
>> > On 6/21/07, S?bastien <pomchip at free.fr> wrote:
>> >> Dear R Users,
>> >>
>> >> I recently posted an email on this list  about the use of 
>> data.frame and
>> >> overlaying multiple plots. Deepayan kindly indicated to me the
>> >> panel.superposition command which worked perfectly in the context 
>> of the
>> >> example I gave.
>> >> I'd like to go a little bit further on this topic using a more 
>> complex
>> >> dataset structure (actually the one I want to work on).
>> >>
>> >>  >mydata
>> >>       Plot    Model    Individuals    Time        Observed
>> >> Predicted
>> >> 1    1        A           1                  0.05
>> >> 10                    10.2
>> >> 2    1        A           1                  0.10
>> >> 20                    19.5
>> >> etc...
>> >> 10  1        B           1                  0.05         10
>> >>          9.8
>> >> 11  1        B           1                  0.10         20
>> >>          20.2
>> >> etc...
>> >>
>> >> There are p "levels" in mydata$Plot, m in mydata$Model, n in
>> >> mydata$Individuals and t in mydata$Time (Note that I probably use the
>> >> word levels improperly as all columns are not factors). Basically, 
>> this
>> >> dataset summarizes the t measurements obtained in n individuals as 
>> well
>> >> as the predicted values from m different modeling approaches 
>> (applied to
>> >> all individuals). Therefore, the observations are repeated m times in
>> >> the Observed columns, while the predictions appears only once for a
>> >> given model an a given individual.
>> >>
>> >> What I want to write is a R batch file creating a Trellis graph, 
>> where
>> >> each panel corresponds to one individual and contains the 
>> observations
>> >> (as scatterplot) plus the predicted values for all models (as 
>> lines of
>> >> different colors)... $Plot is just a token: it might be used to not
>> >> overload graphs in case there are too many tested models. The fun 
>> part
>> >> is that the values of p, m, n and t might vary from one dataset to 
>> the
>> >> other, so everything has to be coded dynamically.
>> >>
>> >> For the plotting part I was thinking about having a loop in my code
>> >> containing something like that:
>> >>
>> >> for (i in 1:nlevels(mydata$Model)) {
>> >>
>> >> subdata<-subset(mydata,mydata$Model=level(mydata$Model)[i])
>> >> xyplot(subset(Observed + Predicted ~ Time | Individuals, data =
>> >> subdata)       #plus additionnal formatting code
>> >>
>> >> }
>> >>
>> >> Unfortunately, this code simply creates a new Trellis plot instead of
>> >> adding the model one by one on the panels. Any idea or link to a 
>> useful
>> >> command will wellcome.
>> >>
>> >> Sebastien
>> >>
>> >> ______________________________________________
>> >> R-help at stat.math.ethz.ch mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>> >
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From quesada at gmail.com  Fri Jun 22 19:26:56 2007
From: quesada at gmail.com (Jose Quesada )
Date: Fri, 22 Jun 2007 19:26:56 +0200
Subject: [R] Matrix library, CHOLMOD error: problem too large
Message-ID: <op.tub2q6d64hcap5@delllap.ugr.es>


I have a pretty large sparse matrix of integers:
> dim(tasa)
[1] 91650 37651

I need to add one to it in order to take logs, but I'm getting the  
following error:

> tasa  = log(tasa + 1)
CHOLMOD error: problem too large
Error in asMethod(object) : Cholmod error `problem too large'

I have 2 Gb of RAM, and the current workspace is barely 300mb.
Is there any workaround to this? Anyone has any experience with this error?

Thanks,
-Jose

-- 
Jose Quesada, PhD.
http://www.andrew.cmu.edu/~jquesada


From murdoch at stats.uwo.ca  Fri Jun 22 20:04:03 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 22 Jun 2007 14:04:03 -0400
Subject: [R] Matrix library, CHOLMOD error: problem too large
In-Reply-To: <op.tub2q6d64hcap5@delllap.ugr.es>
References: <op.tub2q6d64hcap5@delllap.ugr.es>
Message-ID: <467C0F13.4060004@stats.uwo.ca>

On 6/22/2007 1:26 PM, Jose Quesada wrote:
> I have a pretty large sparse matrix of integers:
>> dim(tasa)
> [1] 91650 37651
> 
> I need to add one to it in order to take logs, but I'm getting the  
> following error:
> 
>> tasa  = log(tasa + 1)
> CHOLMOD error: problem too large
> Error in asMethod(object) : Cholmod error `problem too large'
> 
> I have 2 Gb of RAM, and the current workspace is barely 300mb.
> Is there any workaround to this? Anyone has any experience with this error?
>

If tasa is sparse, then tasa+1 will not be sparse, so that's likely your 
problem.  You might have better luck with

log1p(tasa)

if the authors of the Matrix package have written a method for log1p(); 
if not, you'll probably have to do it yourself.

Duncan Murdoch


From Horace.Tso at pgn.com  Fri Jun 22 20:44:52 2007
From: Horace.Tso at pgn.com (Horace Tso)
Date: Fri, 22 Jun 2007 11:44:52 -0700
Subject: [R] Imputing missing values in time series
Message-ID: <467BB6340200006500006924@pgn.com>

Folks,

This must be a rather common problem with real life time series data
but I don't see anything in the archive about how to deal with it. I
have a time series of natural gas prices by flow date. Since gas is not
traded on weekends and holidays, I have a lot of missing values,

FDate	Price
11/1/2006	6.28
11/2/2006	6.58
11/3/2006	6.586
11/4/2006	6.716
11/5/2006	NA
11/6/2006	NA
11/7/2006	6.262
11/8/2006	6.27
11/9/2006	6.696
11/10/2006	6.729
11/11/2006	6.487
11/12/2006	NA
11/13/2006	NA
11/14/2006	6.725
11/15/2006	6.844
11/16/2006	6.907
 
What I would like to do is to fill the NAs with the price from the
previous date * gas used during holidays is purchased from the week
before. Though real simple, I wonder if there is a function to perform
this task. Some of the imputation functions I'm aware of (eg. impute,
transcan in Hmisc) seem to deal with completely different problems. 

2.5.0/Windows XP

Thanks in advance.

HT


From iverson at biostat.wisc.edu  Fri Jun 22 21:01:52 2007
From: iverson at biostat.wisc.edu (Erik Iverson)
Date: Fri, 22 Jun 2007 14:01:52 -0500
Subject: [R] Imputing missing values in time series
In-Reply-To: <467BB6340200006500006924@pgn.com>
References: <467BB6340200006500006924@pgn.com>
Message-ID: <467C1CA0.1080606@biostat.wisc.edu>

I think my example should work for you, but I couldn't think of a way to 
do this without an interative while loop.

test <- c(1,2,3,NA,4,NA,NA,5,NA,6,7,NA)

while(any(is.na(test)))
test[is.na(test)] <- test[which(is.na(test))-1]

  test
  [1] 1 2 3 3 4 4 4 5 5 6 7 7

Horace Tso wrote:
> Folks,
> 
> This must be a rather common problem with real life time series data
> but I don't see anything in the archive about how to deal with it. I
> have a time series of natural gas prices by flow date. Since gas is not
> traded on weekends and holidays, I have a lot of missing values,
> 
> FDate	Price
> 11/1/2006	6.28
> 11/2/2006	6.58
> 11/3/2006	6.586
> 11/4/2006	6.716
> 11/5/2006	NA
> 11/6/2006	NA
> 11/7/2006	6.262
> 11/8/2006	6.27
> 11/9/2006	6.696
> 11/10/2006	6.729
> 11/11/2006	6.487
> 11/12/2006	NA
> 11/13/2006	NA
> 11/14/2006	6.725
> 11/15/2006	6.844
> 11/16/2006	6.907
>  
> What I would like to do is to fill the NAs with the price from the
> previous date * gas used during holidays is purchased from the week
> before. Though real simple, I wonder if there is a function to perform
> this task. Some of the imputation functions I'm aware of (eg. impute,
> transcan in Hmisc) seem to deal with completely different problems. 
> 
> 2.5.0/Windows XP
> 
> Thanks in advance.
> 
> HT
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Horace.Tso at pgn.com  Fri Jun 22 21:08:26 2007
From: Horace.Tso at pgn.com (Horace Tso)
Date: Fri, 22 Jun 2007 12:08:26 -0700
Subject: [R] Imputing missing values in time series
In-Reply-To: <467C1CA0.1080606@biostat.wisc.edu>
References: <467BB6340200006500006924@pgn.com>
	<467C1CA0.1080606@biostat.wisc.edu>
Message-ID: <467BBBBA0200006500006928@pgn.com>

Erik, indeed it gets the work done. I was hoping to avoid the dreaded looping, though.....

Thanks.

Horace

>>> Erik Iverson <iverson at biostat.wisc.edu> 6/22/2007 12:01 PM >>>
I think my example should work for you, but I couldn't think of a way to 
do this without an interative while loop.

test <- c(1,2,3,NA,4,NA,NA,5,NA,6,7,NA)

while(any(is.na(test)))
test[is.na(test)] <- test[which(is.na(test))-1]

  test
  [1] 1 2 3 3 4 4 4 5 5 6 7 7

Horace Tso wrote:
> Folks,
> 
> This must be a rather common problem with real life time series data
> but I don't see anything in the archive about how to deal with it. I
> have a time series of natural gas prices by flow date. Since gas is not
> traded on weekends and holidays, I have a lot of missing values,
> 
> FDate	Price
> 11/1/2006	6.28
> 11/2/2006	6.58
> 11/3/2006	6.586
> 11/4/2006	6.716
> 11/5/2006	NA
> 11/6/2006	NA
> 11/7/2006	6.262
> 11/8/2006	6.27
> 11/9/2006	6.696
> 11/10/2006	6.729
> 11/11/2006	6.487
> 11/12/2006	NA
> 11/13/2006	NA
> 11/14/2006	6.725
> 11/15/2006	6.844
> 11/16/2006	6.907
>  
> What I would like to do is to fill the NAs with the price from the
> previous date * gas used during holidays is purchased from the week
> before. Though real simple, I wonder if there is a function to perform
> this task. Some of the imputation functions I'm aware of (eg. impute,
> transcan in Hmisc) seem to deal with completely different problems. 
> 
> 2.5.0/Windows XP
> 
> Thanks in advance.
> 
> HT
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code.


From h.wickham at gmail.com  Fri Jun 22 21:13:09 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 22 Jun 2007 21:13:09 +0200
Subject: [R] Switching X-axis and Y-axis for histogram
In-Reply-To: <b46dc45f0706211723la539a4djefa727122077364f@mail.gmail.com>
References: <b46dc45f0706211723la539a4djefa727122077364f@mail.gmail.com>
Message-ID: <f8e6ff050706221213j3dc25aeaw6c6d4df7a4511e06@mail.gmail.com>

It's trivial to do this with ggplot2 (http://had.co.nz):

qplot(rating, data=movies, geom="histogram") + coord_flip()
qplot(rating, data=movies, geom="histogram", binwidth=0.1) + coord_flip()

Hadley

On 6/22/07, Donghui Feng <donghui.feng at gmail.com> wrote:
> Dear all,
>
> I'm creating a histogram with the function hist(). But
> right now what I get is column representation (as normal).
> I'm wondering if I could switch X-axis and Y-axis and
> get row-representation of frequencies?
>
> One more question, can I define the step of each axises
> for the histogram?
>
> Thanks so much!
>
> Donghui
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Mark.Leeds at morganstanley.com  Fri Jun 22 21:16:09 2007
From: Mark.Leeds at morganstanley.com (Leeds, Mark (IED))
Date: Fri, 22 Jun 2007 15:16:09 -0400
Subject: [R] Imputing missing values in time series
In-Reply-To: <467C1CA0.1080606@biostat.wisc.edu>
References: <467BB6340200006500006924@pgn.com>
	<467C1CA0.1080606@biostat.wisc.edu>
Message-ID: <D3AEEDA31E57474B840BEBC25A8A834401957418@NYWEXMB23.msad.ms.com>

I have a function that does this type of thing but it works off a pure
vector so it wouldn have to be modified.
If you make your object a zoo object, the that object has many functions
associated with it and na.locf would
Do what you need, I think.


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Erik Iverson
Sent: Friday, June 22, 2007 3:02 PM
To: Horace Tso
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Imputing missing values in time series

I think my example should work for you, but I couldn't think of a way to
do this without an interative while loop.

test <- c(1,2,3,NA,4,NA,NA,5,NA,6,7,NA)

while(any(is.na(test)))
test[is.na(test)] <- test[which(is.na(test))-1]

  test
  [1] 1 2 3 3 4 4 4 5 5 6 7 7

Horace Tso wrote:
> Folks,
> 
> This must be a rather common problem with real life time series data 
> but I don't see anything in the archive about how to deal with it. I 
> have a time series of natural gas prices by flow date. Since gas is 
> not traded on weekends and holidays, I have a lot of missing values,
> 
> FDate	Price
> 11/1/2006	6.28
> 11/2/2006	6.58
> 11/3/2006	6.586
> 11/4/2006	6.716
> 11/5/2006	NA
> 11/6/2006	NA
> 11/7/2006	6.262
> 11/8/2006	6.27
> 11/9/2006	6.696
> 11/10/2006	6.729
> 11/11/2006	6.487
> 11/12/2006	NA
> 11/13/2006	NA
> 11/14/2006	6.725
> 11/15/2006	6.844
> 11/16/2006	6.907
>  
> What I would like to do is to fill the NAs with the price from the 
> previous date * gas used during holidays is purchased from the week 
> before. Though real simple, I wonder if there is a function to perform

> this task. Some of the imputation functions I'm aware of (eg. impute, 
> transcan in Hmisc) seem to deal with completely different problems.
> 
> 2.5.0/Windows XP
> 
> Thanks in advance.
> 
> HT
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
--------------------------------------------------------

This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}


From Horace.Tso at pgn.com  Fri Jun 22 21:21:40 2007
From: Horace.Tso at pgn.com (Horace Tso)
Date: Fri, 22 Jun 2007 12:21:40 -0700
Subject: [R] Imputing missing values in time series
In-Reply-To: <D3AEEDA31E57474B840BEBC25A8A834401957418@NYWEXMB23.msad.ms.com>
References: <467BB6340200006500006924@pgn.com>
	<467C1CA0.1080606@biostat.wisc.edu>
	<D3AEEDA31E57474B840BEBC25A8A834401957418@NYWEXMB23.msad.ms.com>
Message-ID: <467BBED40200006500006931@pgn.com>

Mark, thanks for the tips. I thought you financial folks must have run into things like these before. Just wonder why this problem wasn't asked more often on this list.

H.


>>> "Leeds, Mark (IED)" <Mark.Leeds at morganstanley.com> 6/22/2007 12:16 PM >>>
I have a function that does this type of thing but it works off a pure
vector so it wouldn have to be modified.
If you make your object a zoo object, the that object has many functions
associated with it and na.locf would
Do what you need, I think.


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch 
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Erik Iverson
Sent: Friday, June 22, 2007 3:02 PM
To: Horace Tso
Cc: r-help at stat.math.ethz.ch 
Subject: Re: [R] Imputing missing values in time series

I think my example should work for you, but I couldn't think of a way to
do this without an interative while loop.

test <- c(1,2,3,NA,4,NA,NA,5,NA,6,7,NA)

while(any(is.na(test)))
test[is.na(test)] <- test[which(is.na(test))-1]

  test
  [1] 1 2 3 3 4 4 4 5 5 6 7 7

Horace Tso wrote:
> Folks,
> 
> This must be a rather common problem with real life time series data 
> but I don't see anything in the archive about how to deal with it. I 
> have a time series of natural gas prices by flow date. Since gas is 
> not traded on weekends and holidays, I have a lot of missing values,
> 
> FDate	Price
> 11/1/2006	6.28
> 11/2/2006	6.58
> 11/3/2006	6.586
> 11/4/2006	6.716
> 11/5/2006	NA
> 11/6/2006	NA
> 11/7/2006	6.262
> 11/8/2006	6.27
> 11/9/2006	6.696
> 11/10/2006	6.729
> 11/11/2006	6.487
> 11/12/2006	NA
> 11/13/2006	NA
> 11/14/2006	6.725
> 11/15/2006	6.844
> 11/16/2006	6.907
>  
> What I would like to do is to fill the NAs with the price from the 
> previous date * gas used during holidays is purchased from the week 
> before. Though real simple, I wonder if there is a function to perform

> this task. Some of the imputation functions I'm aware of (eg. impute, 
> transcan in Hmisc) seem to deal with completely different problems.
> 
> 2.5.0/Windows XP
> 
> Thanks in advance.
> 
> HT
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html 
and provide commented, minimal, self-contained, reproducible code.
--------------------------------------------------------

This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}


From h.wickham at gmail.com  Fri Jun 22 21:40:26 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 22 Jun 2007 21:40:26 +0200
Subject: [R] Overlaying lattice graphs (continued)
In-Reply-To: <467BF697.8050203@free.fr>
References: <4679F719.7020308@free.fr>
	<f8e6ff050706210513r51fd9d28mb102a919e20499d6@mail.gmail.com>
	<467A74D5.4090808@free.fr>
	<eb555e660706211319y4332d5c9kd406411bff620043@mail.gmail.com>
	<467BF697.8050203@free.fr>
Message-ID: <f8e6ff050706221240m240391dfrf83f5eb6d47e1766@mail.gmail.com>

Hi Sebastian,

I think the following does what you want:

library(ggplot2)
names(mydata) <- tolower(names(mydata))

obs <- rename(subset(mydata, model=="A", -predicted), c("observed" = "value"))
obs$model <- factor("observed")
pred <- rename(mydata[, -5], c("predicted" = "value"))
all <- rbind(obs, pred)

ggplot(all, aes(x = time, y = value, colour=model)) +
geom_point(data = subset(all, model != "Observed")) +
geom_line(data= subset(all, model == "Observed")) +
facet_grid(. ~ individuals)

Hadley

On 6/22/07, S?bastien <pomchip at free.fr> wrote:
> Hi Deepayan,
>
> The following code creates a dummy dataset which has the same similar as
> my usual datasets. I did not try to implement the changes proposed by
> Hadley, hoping that a solution can be found using the original dataset.
>
> ######### My code
>
> # Creating dataset
>
> nPts<-10            # number of time points
> nInd<-6              # number of individuals
> nModel<-3         # number of models
>
> TimePts<-rep(1:nPts,nInd*nModel)                                    #
> creates the "Time" column
> Coef<-rep(rnorm(6,0.1,0.01),each=nPts,nModel)             # Creates a
> vector of coefficients for generating the observations
> Obs<-10*exp(-Coef*TimePts)                                         #
> creates the observations
>
> for (i in 1:60){
> Pred[i]<-jitter(10*exp(-Coef[i]*TimePts[i]))
> Pred[i+60]<-jitter(5)
> Pred[i+120]<-jitter(10-Coef[i+120]*TimePts[i])
> }
>                   # creates the predicted values
>
> colPlot<-rep(1,nPts*nInd*nModel)
>     # creates the "Plot" column
> colModel<-gl(nModel,nPts*nInd,labels=c("A","B","C"))             #
> creates the "Model" column
> colID<-gl(nInd,nPts,nPts*nInd*nModel)
>       # creates the "ID" column
>
> mydata<-data.frame(colPlot,colModel,colID,TimePts,Obs,Pred)
>               # creates the dataset
> names(mydata)<-c("Plot","Model","Individuals","Time","Observed","Predicted")
>
> # Plotting as indicated by Deepayan
>
>
> xyplot(Observed + Predicted ~ Time | Individuals + Model,
>       data = mydata,
>       panel = panel.superpose.2, type = c("p", "l"),
>       layout = c(0, nlevels(mydata$Individuals))) #,
>       #<...>)
>
> ####### End of code
>
> This codes is not exactly what I am looking for, although it is pretty
> close. In the present case, I would like to have a Trellis plot with 6
> panels (one for each individual), where the Observations and the
> Predicted are plotted as symbols and lines, respectively. All three
> models should be plotted on the same panel. Unfortunately, it looks to
> me as 3 successives xyplots are created by the code above but only the
> last one remains displayed. I tried to play with
> panel.superpose,panel.superpose.2 and type, without much success.
>
> I also tried the following code that creates 18 panels and distinguish
> all (Individuals,Model) couples... so, not what I want.
>
> xyplot(Observed + Predicted ~ Time | Individuals+Model, data = mydata,
>      type = c("p", "l"), distribute.type = TRUE)
>
> Sebastien
>
>
> Deepayan Sarkar a ?crit :
> > On 6/21/07, S?bastien <pomchip at free.fr> wrote:
> >> Hi Hadley,
> >>
> >> Hopefully, my dataset won't be too hard to changed. Can I modify the
> >> aspect of each group using your code (symbols for observed and lines for
> >> predicted)?
> >>
> >> Sebastien
> >>
> >> hadley wickham a ?crit :
> >> > Hi Sebastian,
> >> >
> >> > I think you need to rearrange your data a bit.  Firstly, you need to
> >> > put observed on the same footing as the different models, so you would
> >> > have a new column in your data called value (previously observed and
> >> > predicted) and a new model type ("observed").  Then you could do:
> >
> > Yes, and ?make.groups (and reshape of course) could help with that.
> > This might not be strictly necessary though.
> >
> > However, I'm finding your pseudo-code confusing. Could you create a
> > small example data set that can be used to try out some real code?
> > Just from your description, I would have suggested something like
> >
> > xyplot(Observed + Predicted ~ Time | Individuals + Model,
> >       data = mydata,
> >       panel = panel.superpose.2, type = c("p", "l"),
> >       layout = c(0, nlevels(mydata$Individuals)),
> >       <...>)
> >
> > If all you want is to plot one page at a time, there are easier ways
> > to do that.
> >
> > -Deepayan
> >
> >> >
> >> > xyplot(value ~ time | individauls, data=mydata, group=model)
> >> >
> >> > Hadley
> >> >
> >> >
> >> > On 6/21/07, S?bastien <pomchip at free.fr> wrote:
> >> >> Dear R Users,
> >> >>
> >> >> I recently posted an email on this list  about the use of
> >> data.frame and
> >> >> overlaying multiple plots. Deepayan kindly indicated to me the
> >> >> panel.superposition command which worked perfectly in the context
> >> of the
> >> >> example I gave.
> >> >> I'd like to go a little bit further on this topic using a more
> >> complex
> >> >> dataset structure (actually the one I want to work on).
> >> >>
> >> >>  >mydata
> >> >>       Plot    Model    Individuals    Time        Observed
> >> >> Predicted
> >> >> 1    1        A           1                  0.05
> >> >> 10                    10.2
> >> >> 2    1        A           1                  0.10
> >> >> 20                    19.5
> >> >> etc...
> >> >> 10  1        B           1                  0.05         10
> >> >>          9.8
> >> >> 11  1        B           1                  0.10         20
> >> >>          20.2
> >> >> etc...
> >> >>
> >> >> There are p "levels" in mydata$Plot, m in mydata$Model, n in
> >> >> mydata$Individuals and t in mydata$Time (Note that I probably use the
> >> >> word levels improperly as all columns are not factors). Basically,
> >> this
> >> >> dataset summarizes the t measurements obtained in n individuals as
> >> well
> >> >> as the predicted values from m different modeling approaches
> >> (applied to
> >> >> all individuals). Therefore, the observations are repeated m times in
> >> >> the Observed columns, while the predictions appears only once for a
> >> >> given model an a given individual.
> >> >>
> >> >> What I want to write is a R batch file creating a Trellis graph,
> >> where
> >> >> each panel corresponds to one individual and contains the
> >> observations
> >> >> (as scatterplot) plus the predicted values for all models (as
> >> lines of
> >> >> different colors)... $Plot is just a token: it might be used to not
> >> >> overload graphs in case there are too many tested models. The fun
> >> part
> >> >> is that the values of p, m, n and t might vary from one dataset to
> >> the
> >> >> other, so everything has to be coded dynamically.
> >> >>
> >> >> For the plotting part I was thinking about having a loop in my code
> >> >> containing something like that:
> >> >>
> >> >> for (i in 1:nlevels(mydata$Model)) {
> >> >>
> >> >> subdata<-subset(mydata,mydata$Model=level(mydata$Model)[i])
> >> >> xyplot(subset(Observed + Predicted ~ Time | Individuals, data =
> >> >> subdata)       #plus additionnal formatting code
> >> >>
> >> >> }
> >> >>
> >> >> Unfortunately, this code simply creates a new Trellis plot instead of
> >> >> adding the model one by one on the panels. Any idea or link to a
> >> useful
> >> >> command will wellcome.
> >> >>
> >> >> Sebastien
> >> >>
> >> >> ______________________________________________
> >> >> R-help at stat.math.ethz.ch mailing list
> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> PLEASE do read the posting guide
> >> >> http://www.R-project.org/posting-guide.html
> >> >> and provide commented, minimal, self-contained, reproducible code.
> >> >>
> >> >
> >> >
> >>
> >> ______________________________________________
> >> R-help at stat.math.ethz.ch mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
>


From deepayan.sarkar at gmail.com  Fri Jun 22 21:47:51 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Fri, 22 Jun 2007 12:47:51 -0700
Subject: [R] Overlaying lattice graphs (continued)
In-Reply-To: <467BF697.8050203@free.fr>
References: <4679F719.7020308@free.fr>
	<f8e6ff050706210513r51fd9d28mb102a919e20499d6@mail.gmail.com>
	<467A74D5.4090808@free.fr>
	<eb555e660706211319y4332d5c9kd406411bff620043@mail.gmail.com>
	<467BF697.8050203@free.fr>
Message-ID: <eb555e660706221247v59cf4f4cpdaee99e0a1372c84@mail.gmail.com>

On 6/22/07, S?bastien <pomchip at free.fr> wrote:
> Hi Deepayan,
>
> The following code creates a dummy dataset which has the same similar as
> my usual datasets. I did not try to implement the changes proposed by
> Hadley, hoping that a solution can be found using the original dataset.
>
> ######### My code
>
> # Creating dataset
>
> nPts<-10            # number of time points
> nInd<-6              # number of individuals
> nModel<-3         # number of models
>
> TimePts<-rep(1:nPts,nInd*nModel)                                    #
> creates the "Time" column
> Coef<-rep(rnorm(6,0.1,0.01),each=nPts,nModel)             # Creates a
> vector of coefficients for generating the observations
> Obs<-10*exp(-Coef*TimePts)                                         #
> creates the observations
>
> for (i in 1:60){
> Pred[i]<-jitter(10*exp(-Coef[i]*TimePts[i]))
> Pred[i+60]<-jitter(5)
> Pred[i+120]<-jitter(10-Coef[i+120]*TimePts[i])
> }
>                   # creates the predicted values
>
> colPlot<-rep(1,nPts*nInd*nModel)
>     # creates the "Plot" column
> colModel<-gl(nModel,nPts*nInd,labels=c("A","B","C"))             #
> creates the "Model" column
> colID<-gl(nInd,nPts,nPts*nInd*nModel)
>       # creates the "ID" column
>
> mydata<-data.frame(colPlot,colModel,colID,TimePts,Obs,Pred)
>               # creates the dataset
> names(mydata)<-c("Plot","Model","Individuals","Time","Observed","Predicted")

The way you have structured your data makes no sense to me. In
particular, your 'Observed' data is the same set of 60 numbers
repeated 3 times, and this is not reflected in the data structure at
all. What would you want to happen if the numbers were not repeated?
Would you always plot the first 60, or would plot all of them?

If I understand what you are trying to do, this might be a more
transparent approach:


nPts<-10   # number of time points
nInd<-6    # number of individuals

TimePts <- rep(1:nPts, nInd)
Coef <- rep(rnorm(6,0.1,0.01), each = nPts)
Obs <- 10 * exp(-Coef * TimePts)
colID <- gl(nInd, nPts)

mydata <- data.frame(Time = TimePts, Observed = Obs, Individuals = colID)

fmA <- lm(Observed ~ Time, mydata)
fmB <- lm(Observed ~ poly(Time, 2), mydata)
fmC <- lm(Observed ~ poly(Time, 2) * Individuals, mydata)

mydata$PredA <- predict(fmA)
mydata$PredB <- predict(fmB)
mydata$PredC <- predict(fmC)

xyplot(Observed + PredA + PredB + PredC ~ Time | Individuals,
       data = mydata,
       type = c("p", "l", "l", "l"),
       distribute.type = TRUE)

-Deepayan


From h.wickham at gmail.com  Fri Jun 22 21:55:52 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 22 Jun 2007 21:55:52 +0200
Subject: [R] Stacked barchart color
In-Reply-To: <11182581.post@talk.nabble.com>
References: <LPEJLJACLINDNMBMFAFIKEBICIAA.dieter.menne@menne-biomed.de>
	<f8e6ff050706121131s4b0aeb30y8de662ddd7323092@mail.gmail.com>
	<11149419.post@talk.nabble.com>
	<f8e6ff050706152338s6394374dqd89701c3837ec1d8@mail.gmail.com>
	<11182581.post@talk.nabble.com>
Message-ID: <f8e6ff050706221255j37e15382n4179d5b276486c0b@mail.gmail.com>

Hi Owen,

The bars should be stacked in the order specified by the factor.  Try
using factor(..., levels=...) to explicitly order them the way you
want.  If that doesn't work, please provide a small replicable example
and I'll look into it.

Hadley

On 6/18/07, owenman <solberg at speakeasy.net> wrote:
>
> Hi Hadley,
> Great, I am starting to get it.  It's working for me, but there is one more
> thing I am having trouble with.  The ordering of the stacked bars seems to
> be dictated by the name of the color, I guess because of the fill=color
> argument in aes().  In other words, if I set up my colors like this:
> y$color = c("gray1","gray35","gray45","gray65")  the bars get stacked in the
> opposite order than if I set up the colors like this:  y$color =
> c("gray65","gray45","gray35","gray1").  How can I control the order of the
> bars independent of the name of the colors?   Thanks so much in advance!
> Really neat package you've made.
>
> FYI, my plot command now looks like this:
>
> p = ggplot(y, aes(x=locus, y=Freq, fill=color))
> p = p + geom_bar(position="fill")
> p = p + scale_fill_identity(labels=levels(y$Fnd), grob="tile", name="Fnd
> Results")
> p = p + coord_flip()
>
> And the data table is similar as before:
>
> > y
>       Fnd locus        Freq  color
> 1  signeg  DPB1 0.013071895  gray1
> 2     neg  DPB1 0.581699346 gray35
> 3     pos  DPB1 0.379084967 gray45
> 4  sigpos  DPB1 0.026143791 gray65
> 5  signeg  DPA1 0.068181818  gray1
> 6     neg  DPA1 0.659090909 gray35
> 7     pos  DPA1 0.250000000 gray45
> 8  sigpos  DPA1 0.022727273 gray65
>
>
>
> hadley wrote:
> >
> > Hi Owen,
> >
> > The identity scale won't create a legend, unless you tell it what
> > labels it should use - there's an example at
> > http://had.co.nz/ggplot2/scale_identity.html.  Otherwise, if you have
> > a continuous scale and you want something that works in black and
> > white, p + scale_fill_gradient(low="white", high="black") might be
> > easier.
> >
> > Hadley
> >
> >
> >>
> >> > y$color = factor(y$Fnd)
> >> > y$color = c("black","darkgray","lightgray","white")
> >> > y
> >>       Fnd locus        Freq color
> >> 1  signeg     A 0.087248322     black
> >> 2     neg     A 0.711409396  darkgray
> >> 3     pos     A 0.201342282 lightgray
> >> 4  sigpos     A 0.000000000     white
> >> 5  signeg     C 0.320754717     black
> >> 6     neg     C 0.603773585  darkgray
> >> 7     pos     C 0.075471698 lightgray
> >> 8  sigpos     C 0.000000000     white
> >> 9  signeg     B 0.157534247     black
> >> 10    neg     B 0.732876712  darkgray
> >> 11    pos     B 0.109589041 lightgray
> >> 12 sigpos     B 0.000000000     white
> >>
> >> > p = ggplot(y, aes(x=locus, y=Freq, fill=color)) +
> >> > geom_bar(position="fill") + scale_fill_identity()
> >> > p
> >>
> >>
> >>
> >>
> >> hadley wrote:
> >> >
> >> >
> >> > Hi Dieter,
> >> >
> >> > You can do this with ggplot2 (http://had.co.nz/ggplot2) as follows:
> >> >
> >> > library(ggplot2)
> >> >
> >> > barley1 <- subset(barley, site=="Grand Rapids" & variety %in%
> >> > c("Velvet","Peatland"))
> >> > barley1[] <- lapply(barley1, "[", drop=TRUE)
> >> >
> >> > qplot(variety, yield, data=barley1, geom="bar", stat="identity",
> >> > fill=factor(year))
> >> >
> >> > barley1$fill <- c("red","green","blue","gray")
> >> > qplot(variety, yield, data=barley1, geom="bar", stat="identity",
> >> > fill=fill) + scale_fill_identity()
> >> >
> >> > See http://had.co.nz/ggplot2/scale_identity.html and
> >> > http://had.co.nz/ggplot2/position_stack.html for more details.
> >> >
> >> > Hadley
> >> >
> >> >
> >>
> >>
> >> --
> >> View this message in context:
> >> http://www.nabble.com/Stacked-barchart-color-tf3909162.html#a11149419
> >> Sent from the R help mailing list archive at Nabble.com.
> >>
> >>
> >> ______________________________________________
> >> R-help at stat.math.ethz.ch mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
>
> --
> View this message in context: http://www.nabble.com/Stacked-barchart-color-tf3909162.html#a11182581
>
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From h.wickham at gmail.com  Fri Jun 22 22:07:37 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 22 Jun 2007 22:07:37 +0200
Subject: [R] Visualize quartiles of plot line
In-Reply-To: <621925589.20070617155647@xylon.de>
References: <699125298.20070616105514@xylon.de>
	<f8e6ff050706160315r325ec00eua9b14eb87152db71@mail.gmail.com>
	<555253635.20070617092257@xylon.de>
	<f8e6ff050706170151n9706361k8ff68042ed86a615@mail.gmail.com>
	<621925589.20070617155647@xylon.de>
Message-ID: <f8e6ff050706221307s72ebc36v31537365bc7ff667@mail.gmail.com>

On 6/17/07, Arne Brutschy <abr-r-project at xylon.de> wrote:
> Hi,
>
> thanks for your tips - all of them worked. After a bit of fiddling, I
> managed to get what I wanted.

Glad to hear it.

> hadley wickham wrote:
> h> You might want to read the introductory chapters in the ggplot book,
> h> available from http://had.co.nz/ggplot2, which will give you more of a
> h> background.  Please let me know places where you think the
> h> documentation is inconsistent so I can try and make them better.
> I already did. :) A general problem: the examples are nice and easy to
> get, but it's often hard to apply them to my own specific problem.
> It's more a problem of the general structure: what has to go where.
> Most of the methods are using qplot, but what do I have to do if I'm
> trying create a more complex plot. Hmm, it's hard to describe.
>
> Example: I know how I set the title when using qplot (qplot(....
> main="asdf"). Where do I have to put it when I'm using gplot? Stuff
> like this is unclear...

p <- ggplot(...) + ...
p$title <- "Title goes here"

It is currently hard to figure this out in the current documentation though.

> A more general problem is, that the manual pages are very, eh,
> minimalistic documented. The overall reference page is good and nicely
> structured. But the big idea is sort of missing. All components are
> linked, but the basics like layout, ggplot, aes etc are harder to find
> - and their help pages are the shortest. Especially the small details
> are hard to figure out. Lists of attributes etc..

Yes, that's definitely something I'm working on for the book.
Unfortunately, I don't have
 that much time and it is a lot of work.  Every comment helps though.

> Hmm, I know this is not really helpful. I can't describe my problems
> properly, I guess. Perhaps the documentation simply has to improve
> based on users questions. :\
>
> How old is this package? I think it's really, really great, but are
> there many users? Is there an additional mailinglist or forum where I
> can get more information?

It's pretty young still, although the precursor ggplot package has
been around for about a year.  I really have no idea how many users
there are.  For questions, either email me or R-help.

> Some more questions:
>
> Why doesn't ggplot2 work with layout()? I'm using viewport now, which
> works fine for me, but there should be a note in the docs perhaps.

Because it works with the grid drawing package - see the last chapter
in the ggplot book for some details on how to use the grid
equivalents.

> How do I change the legend. The auto-creation of it might be nice,
> but I want a) to add a title b) change the order to ascending and c)
> add a short description like:
>
>   DeltaConfig
>   [ ] 0 best
>   [ ]
>   [ ] 5
>   [ ]
>   [ ]10 worst
>
> I don't know if this is possible, but it would be nice to explain what
> the colors/values might mean if it's not clear from the beginning
> (ligke diamonds.size). The only thing I found was the attribute
> legend.justifcation in ggopt, which isn't fully documented.

The legends aren't very customisable at the moment - look at the
examples for the scale functions to see what you can do.  You can see
the name of the title easily, and you can change the labels by
changing the level of the factors, or setting the breaks argument.  I
agree there could be more options.  If you could provide me with a
picture of what you want, I'll add it to my to do list to think about.

> Additionally, how can I change the order of the facets? I currently
> have a plot with a smoother for each model (all in the same plot),
> which sorts the models like this: dyn,dl4,dl3 Below that, I have a
> facet with point-plots for each model which sorts them the other way
> round, which is a bit confusing.

Again, change the order of the underlying factor.

> BTW, what's the "strip" and the associated attributes?

The strip is the labelled associated with the facet.

> Again, I think this package is great - nice work! All the above isn't
> meant as general critisism, but is being said in order to improve the
> documentation..

I do appreciate your comments and they definitely help me to make a
better product.

Thanks,

Hadley


From payscue at gmail.com  Fri Jun 22 22:14:52 2007
From: payscue at gmail.com (Patrick Ayscue)
Date: Fri, 22 Jun 2007 16:14:52 -0400
Subject: [R] "heatmap" color still a spectrum for binary outcomes?
Message-ID: <ea3a49790706221314n270f8036i72fb4356c579303@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070622/0b23a70a/attachment.pl 

From Jacqueline.Spilak at EC.gc.ca  Fri Jun 22 22:19:43 2007
From: Jacqueline.Spilak at EC.gc.ca (Spilak,Jacqueline [Edm])
Date: Fri, 22 Jun 2007 14:19:43 -0600
Subject: [R] Barchart legend position
Message-ID: <4A6AB38B55B49C44A22E021A83CBEDDB015EB9A1@sr-pnr-exch3.prairie.int.ec.gc.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070622/32e26bce/attachment.pl 

From b3i4old02 at sneakemail.com  Fri Jun 22 18:25:14 2007
From: b3i4old02 at sneakemail.com (Michael Hoffman)
Date: Fri, 22 Jun 2007 17:25:14 +0100
Subject: [R] Lattice: hiding only some strips
Message-ID: <f5gt5i$f6k$1@sea.gmane.org>

I am using R 2.4.0 and lattice to produce some xyplots conditioned on a 
factor and a shingle. The shingle merely chops up the data along the 
x-axis, so it is easy to identify which part of the shingle a panel is 
in by looking at the x-axis markings. I only want to have a strip at the 
top for the factor.

Is this possible? I looked into calculateGridLayout() and it seems to me 
that there isn't an easy way to do it without rewriting that function 
(and others).

Many thanks
-- 
Michael Hoffman


From pomchip at free.fr  Fri Jun 22 22:42:13 2007
From: pomchip at free.fr (=?ISO-8859-1?Q?S=E9bastien?=)
Date: Fri, 22 Jun 2007 16:42:13 -0400
Subject: [R] Overlaying lattice graphs (continued)
In-Reply-To: <f8e6ff050706221240m240391dfrf83f5eb6d47e1766@mail.gmail.com>
References: <4679F719.7020308@free.fr>	
	<f8e6ff050706210513r51fd9d28mb102a919e20499d6@mail.gmail.com>	
	<467A74D5.4090808@free.fr>	
	<eb555e660706211319y4332d5c9kd406411bff620043@mail.gmail.com>	
	<467BF697.8050203@free.fr>
	<f8e6ff050706221240m240391dfrf83f5eb6d47e1766@mail.gmail.com>
Message-ID: <467C3425.1030000@free.fr>

Hadley,

I have some troubles to run your code with ggplot version 0.4.1. Is the 
package ggplot2 mandatory ?

Sebastien

hadley wickham a ?crit :
> Hi Sebastian,
>
> I think the following does what you want:
>
> library(ggplot2)
> names(mydata) <- tolower(names(mydata))
>
> obs <- rename(subset(mydata, model=="A", -predicted), c("observed" = 
> "value"))
> obs$model <- factor("observed")
> pred <- rename(mydata[, -5], c("predicted" = "value"))
> all <- rbind(obs, pred)
>
> ggplot(all, aes(x = time, y = value, colour=model)) +
> geom_point(data = subset(all, model != "Observed")) +
> geom_line(data= subset(all, model == "Observed")) +
> facet_grid(. ~ individuals)
>
> Hadley
>
> On 6/22/07, S?bastien <pomchip at free.fr> wrote:
>> Hi Deepayan,
>>
>> The following code creates a dummy dataset which has the same similar as
>> my usual datasets. I did not try to implement the changes proposed by
>> Hadley, hoping that a solution can be found using the original dataset.
>>
>> ######### My code
>>
>> # Creating dataset
>>
>> nPts<-10            # number of time points
>> nInd<-6              # number of individuals
>> nModel<-3         # number of models
>>
>> TimePts<-rep(1:nPts,nInd*nModel)                                    #
>> creates the "Time" column
>> Coef<-rep(rnorm(6,0.1,0.01),each=nPts,nModel)             # Creates a
>> vector of coefficients for generating the observations
>> Obs<-10*exp(-Coef*TimePts)                                         #
>> creates the observations
>>
>> for (i in 1:60){
>> Pred[i]<-jitter(10*exp(-Coef[i]*TimePts[i]))
>> Pred[i+60]<-jitter(5)
>> Pred[i+120]<-jitter(10-Coef[i+120]*TimePts[i])
>> }
>>                   # creates the predicted values
>>
>> colPlot<-rep(1,nPts*nInd*nModel)
>>     # creates the "Plot" column
>> colModel<-gl(nModel,nPts*nInd,labels=c("A","B","C"))             #
>> creates the "Model" column
>> colID<-gl(nInd,nPts,nPts*nInd*nModel)
>>       # creates the "ID" column
>>
>> mydata<-data.frame(colPlot,colModel,colID,TimePts,Obs,Pred)
>>               # creates the dataset
>> names(mydata)<-c("Plot","Model","Individuals","Time","Observed","Predicted") 
>>
>>
>> # Plotting as indicated by Deepayan
>>
>>
>> xyplot(Observed + Predicted ~ Time | Individuals + Model,
>>       data = mydata,
>>       panel = panel.superpose.2, type = c("p", "l"),
>>       layout = c(0, nlevels(mydata$Individuals))) #,
>>       #<...>)
>>
>> ####### End of code
>>
>> This codes is not exactly what I am looking for, although it is pretty
>> close. In the present case, I would like to have a Trellis plot with 6
>> panels (one for each individual), where the Observations and the
>> Predicted are plotted as symbols and lines, respectively. All three
>> models should be plotted on the same panel. Unfortunately, it looks to
>> me as 3 successives xyplots are created by the code above but only the
>> last one remains displayed. I tried to play with
>> panel.superpose,panel.superpose.2 and type, without much success.
>>
>> I also tried the following code that creates 18 panels and distinguish
>> all (Individuals,Model) couples... so, not what I want.
>>
>> xyplot(Observed + Predicted ~ Time | Individuals+Model, data = mydata,
>>      type = c("p", "l"), distribute.type = TRUE)
>>
>> Sebastien
>>
>>
>> Deepayan Sarkar a ?crit :
>> > On 6/21/07, S?bastien <pomchip at free.fr> wrote:
>> >> Hi Hadley,
>> >>
>> >> Hopefully, my dataset won't be too hard to changed. Can I modify the
>> >> aspect of each group using your code (symbols for observed and 
>> lines for
>> >> predicted)?
>> >>
>> >> Sebastien
>> >>
>> >> hadley wickham a ?crit :
>> >> > Hi Sebastian,
>> >> >
>> >> > I think you need to rearrange your data a bit.  Firstly, you 
>> need to
>> >> > put observed on the same footing as the different models, so you 
>> would
>> >> > have a new column in your data called value (previously observed 
>> and
>> >> > predicted) and a new model type ("observed").  Then you could do:
>> >
>> > Yes, and ?make.groups (and reshape of course) could help with that.
>> > This might not be strictly necessary though.
>> >
>> > However, I'm finding your pseudo-code confusing. Could you create a
>> > small example data set that can be used to try out some real code?
>> > Just from your description, I would have suggested something like
>> >
>> > xyplot(Observed + Predicted ~ Time | Individuals + Model,
>> >       data = mydata,
>> >       panel = panel.superpose.2, type = c("p", "l"),
>> >       layout = c(0, nlevels(mydata$Individuals)),
>> >       <...>)
>> >
>> > If all you want is to plot one page at a time, there are easier ways
>> > to do that.
>> >
>> > -Deepayan
>> >
>> >> >
>> >> > xyplot(value ~ time | individauls, data=mydata, group=model)
>> >> >
>> >> > Hadley
>> >> >
>> >> >
>> >> > On 6/21/07, S?bastien <pomchip at free.fr> wrote:
>> >> >> Dear R Users,
>> >> >>
>> >> >> I recently posted an email on this list  about the use of
>> >> data.frame and
>> >> >> overlaying multiple plots. Deepayan kindly indicated to me the
>> >> >> panel.superposition command which worked perfectly in the context
>> >> of the
>> >> >> example I gave.
>> >> >> I'd like to go a little bit further on this topic using a more
>> >> complex
>> >> >> dataset structure (actually the one I want to work on).
>> >> >>
>> >> >>  >mydata
>> >> >>       Plot    Model    Individuals    Time        Observed
>> >> >> Predicted
>> >> >> 1    1        A           1                  0.05
>> >> >> 10                    10.2
>> >> >> 2    1        A           1                  0.10
>> >> >> 20                    19.5
>> >> >> etc...
>> >> >> 10  1        B           1                  0.05         10
>> >> >>          9.8
>> >> >> 11  1        B           1                  0.10         20
>> >> >>          20.2
>> >> >> etc...
>> >> >>
>> >> >> There are p "levels" in mydata$Plot, m in mydata$Model, n in
>> >> >> mydata$Individuals and t in mydata$Time (Note that I probably 
>> use the
>> >> >> word levels improperly as all columns are not factors). Basically,
>> >> this
>> >> >> dataset summarizes the t measurements obtained in n individuals as
>> >> well
>> >> >> as the predicted values from m different modeling approaches
>> >> (applied to
>> >> >> all individuals). Therefore, the observations are repeated m 
>> times in
>> >> >> the Observed columns, while the predictions appears only once 
>> for a
>> >> >> given model an a given individual.
>> >> >>
>> >> >> What I want to write is a R batch file creating a Trellis graph,
>> >> where
>> >> >> each panel corresponds to one individual and contains the
>> >> observations
>> >> >> (as scatterplot) plus the predicted values for all models (as
>> >> lines of
>> >> >> different colors)... $Plot is just a token: it might be used to 
>> not
>> >> >> overload graphs in case there are too many tested models. The fun
>> >> part
>> >> >> is that the values of p, m, n and t might vary from one dataset to
>> >> the
>> >> >> other, so everything has to be coded dynamically.
>> >> >>
>> >> >> For the plotting part I was thinking about having a loop in my 
>> code
>> >> >> containing something like that:
>> >> >>
>> >> >> for (i in 1:nlevels(mydata$Model)) {
>> >> >>
>> >> >> subdata<-subset(mydata,mydata$Model=level(mydata$Model)[i])
>> >> >> xyplot(subset(Observed + Predicted ~ Time | Individuals, data =
>> >> >> subdata)       #plus additionnal formatting code
>> >> >>
>> >> >> }
>> >> >>
>> >> >> Unfortunately, this code simply creates a new Trellis plot 
>> instead of
>> >> >> adding the model one by one on the panels. Any idea or link to a
>> >> useful
>> >> >> command will wellcome.
>> >> >>
>> >> >> Sebastien
>> >> >>
>> >> >> ______________________________________________
>> >> >> R-help at stat.math.ethz.ch mailing list
>> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >> PLEASE do read the posting guide
>> >> >> http://www.R-project.org/posting-guide.html
>> >> >> and provide commented, minimal, self-contained, reproducible code.
>> >> >>
>> >> >
>> >> >
>> >>
>> >> ______________________________________________
>> >> R-help at stat.math.ethz.ch mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>>
>
>


From Mario.Carvalho.Fernandes at bpi.pt  Fri Jun 22 17:09:38 2007
From: Mario.Carvalho.Fernandes at bpi.pt (Mario.Carvalho.Fernandes at bpi.pt)
Date: Fri, 22 Jun 2007 16:09:38 +0100
Subject: [R] Bayesian Networks
Message-ID: <F5BB794D967BBF40821B5B89D88588E0D8BCD6@SPHIEXM01.scentrais.gbpi.loc>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070622/86a9997c/attachment.pl 

From ccosse at gmail.com  Fri Jun 22 18:06:36 2007
From: ccosse at gmail.com (Charles Cosse)
Date: Fri, 22 Jun 2007 10:06:36 -0600
Subject: [R] connecting to running process possible?
Message-ID: <fb87ba070706220906i1314ccf4q4c51ad3ad4e4ff8b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070622/e00fb554/attachment.pl 

From h.wickham at gmail.com  Fri Jun 22 22:46:32 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 22 Jun 2007 22:46:32 +0200
Subject: [R] Overlaying lattice graphs (continued)
In-Reply-To: <467C3425.1030000@free.fr>
References: <4679F719.7020308@free.fr>
	<f8e6ff050706210513r51fd9d28mb102a919e20499d6@mail.gmail.com>
	<467A74D5.4090808@free.fr>
	<eb555e660706211319y4332d5c9kd406411bff620043@mail.gmail.com>
	<467BF697.8050203@free.fr>
	<f8e6ff050706221240m240391dfrf83f5eb6d47e1766@mail.gmail.com>
	<467C3425.1030000@free.fr>
Message-ID: <f8e6ff050706221346j63d026edr73f419360380aa65@mail.gmail.com>

Yes - you'll need ggplot2.

Hadley

On 6/22/07, S?bastien <pomchip at free.fr> wrote:
> Hadley,
>
> I have some troubles to run your code with ggplot version 0.4.1. Is the
> package ggplot2 mandatory ?
>
> Sebastien
>
> hadley wickham a ?crit :
> > Hi Sebastian,
> >
> > I think the following does what you want:
> >
> > library(ggplot2)
> > names(mydata) <- tolower(names(mydata))
> >
> > obs <- rename(subset(mydata, model=="A", -predicted), c("observed" =
> > "value"))
> > obs$model <- factor("observed")
> > pred <- rename(mydata[, -5], c("predicted" = "value"))
> > all <- rbind(obs, pred)
> >
> > ggplot(all, aes(x = time, y = value, colour=model)) +
> > geom_point(data = subset(all, model != "Observed")) +
> > geom_line(data= subset(all, model == "Observed")) +
> > facet_grid(. ~ individuals)
> >
> > Hadley
> >
> > On 6/22/07, S?bastien <pomchip at free.fr> wrote:
> >> Hi Deepayan,
> >>
> >> The following code creates a dummy dataset which has the same similar as
> >> my usual datasets. I did not try to implement the changes proposed by
> >> Hadley, hoping that a solution can be found using the original dataset.
> >>
> >> ######### My code
> >>
> >> # Creating dataset
> >>
> >> nPts<-10            # number of time points
> >> nInd<-6              # number of individuals
> >> nModel<-3         # number of models
> >>
> >> TimePts<-rep(1:nPts,nInd*nModel)                                    #
> >> creates the "Time" column
> >> Coef<-rep(rnorm(6,0.1,0.01),each=nPts,nModel)             # Creates a
> >> vector of coefficients for generating the observations
> >> Obs<-10*exp(-Coef*TimePts)                                         #
> >> creates the observations
> >>
> >> for (i in 1:60){
> >> Pred[i]<-jitter(10*exp(-Coef[i]*TimePts[i]))
> >> Pred[i+60]<-jitter(5)
> >> Pred[i+120]<-jitter(10-Coef[i+120]*TimePts[i])
> >> }
> >>                   # creates the predicted values
> >>
> >> colPlot<-rep(1,nPts*nInd*nModel)
> >>     # creates the "Plot" column
> >> colModel<-gl(nModel,nPts*nInd,labels=c("A","B","C"))             #
> >> creates the "Model" column
> >> colID<-gl(nInd,nPts,nPts*nInd*nModel)
> >>       # creates the "ID" column
> >>
> >> mydata<-data.frame(colPlot,colModel,colID,TimePts,Obs,Pred)
> >>               # creates the dataset
> >> names(mydata)<-c("Plot","Model","Individuals","Time","Observed","Predicted")
> >>
> >>
> >> # Plotting as indicated by Deepayan
> >>
> >>
> >> xyplot(Observed + Predicted ~ Time | Individuals + Model,
> >>       data = mydata,
> >>       panel = panel.superpose.2, type = c("p", "l"),
> >>       layout = c(0, nlevels(mydata$Individuals))) #,
> >>       #<...>)
> >>
> >> ####### End of code
> >>
> >> This codes is not exactly what I am looking for, although it is pretty
> >> close. In the present case, I would like to have a Trellis plot with 6
> >> panels (one for each individual), where the Observations and the
> >> Predicted are plotted as symbols and lines, respectively. All three
> >> models should be plotted on the same panel. Unfortunately, it looks to
> >> me as 3 successives xyplots are created by the code above but only the
> >> last one remains displayed. I tried to play with
> >> panel.superpose,panel.superpose.2 and type, without much success.
> >>
> >> I also tried the following code that creates 18 panels and distinguish
> >> all (Individuals,Model) couples... so, not what I want.
> >>
> >> xyplot(Observed + Predicted ~ Time | Individuals+Model, data = mydata,
> >>      type = c("p", "l"), distribute.type = TRUE)
> >>
> >> Sebastien
> >>
> >>
> >> Deepayan Sarkar a ?crit :
> >> > On 6/21/07, S?bastien <pomchip at free.fr> wrote:
> >> >> Hi Hadley,
> >> >>
> >> >> Hopefully, my dataset won't be too hard to changed. Can I modify the
> >> >> aspect of each group using your code (symbols for observed and
> >> lines for
> >> >> predicted)?
> >> >>
> >> >> Sebastien
> >> >>
> >> >> hadley wickham a ?crit :
> >> >> > Hi Sebastian,
> >> >> >
> >> >> > I think you need to rearrange your data a bit.  Firstly, you
> >> need to
> >> >> > put observed on the same footing as the different models, so you
> >> would
> >> >> > have a new column in your data called value (previously observed
> >> and
> >> >> > predicted) and a new model type ("observed").  Then you could do:
> >> >
> >> > Yes, and ?make.groups (and reshape of course) could help with that.
> >> > This might not be strictly necessary though.
> >> >
> >> > However, I'm finding your pseudo-code confusing. Could you create a
> >> > small example data set that can be used to try out some real code?
> >> > Just from your description, I would have suggested something like
> >> >
> >> > xyplot(Observed + Predicted ~ Time | Individuals + Model,
> >> >       data = mydata,
> >> >       panel = panel.superpose.2, type = c("p", "l"),
> >> >       layout = c(0, nlevels(mydata$Individuals)),
> >> >       <...>)
> >> >
> >> > If all you want is to plot one page at a time, there are easier ways
> >> > to do that.
> >> >
> >> > -Deepayan
> >> >
> >> >> >
> >> >> > xyplot(value ~ time | individauls, data=mydata, group=model)
> >> >> >
> >> >> > Hadley
> >> >> >
> >> >> >
> >> >> > On 6/21/07, S?bastien <pomchip at free.fr> wrote:
> >> >> >> Dear R Users,
> >> >> >>
> >> >> >> I recently posted an email on this list  about the use of
> >> >> data.frame and
> >> >> >> overlaying multiple plots. Deepayan kindly indicated to me the
> >> >> >> panel.superposition command which worked perfectly in the context
> >> >> of the
> >> >> >> example I gave.
> >> >> >> I'd like to go a little bit further on this topic using a more
> >> >> complex
> >> >> >> dataset structure (actually the one I want to work on).
> >> >> >>
> >> >> >>  >mydata
> >> >> >>       Plot    Model    Individuals    Time        Observed
> >> >> >> Predicted
> >> >> >> 1    1        A           1                  0.05
> >> >> >> 10                    10.2
> >> >> >> 2    1        A           1                  0.10
> >> >> >> 20                    19.5
> >> >> >> etc...
> >> >> >> 10  1        B           1                  0.05         10
> >> >> >>          9.8
> >> >> >> 11  1        B           1                  0.10         20
> >> >> >>          20.2
> >> >> >> etc...
> >> >> >>
> >> >> >> There are p "levels" in mydata$Plot, m in mydata$Model, n in
> >> >> >> mydata$Individuals and t in mydata$Time (Note that I probably
> >> use the
> >> >> >> word levels improperly as all columns are not factors). Basically,
> >> >> this
> >> >> >> dataset summarizes the t measurements obtained in n individuals as
> >> >> well
> >> >> >> as the predicted values from m different modeling approaches
> >> >> (applied to
> >> >> >> all individuals). Therefore, the observations are repeated m
> >> times in
> >> >> >> the Observed columns, while the predictions appears only once
> >> for a
> >> >> >> given model an a given individual.
> >> >> >>
> >> >> >> What I want to write is a R batch file creating a Trellis graph,
> >> >> where
> >> >> >> each panel corresponds to one individual and contains the
> >> >> observations
> >> >> >> (as scatterplot) plus the predicted values for all models (as
> >> >> lines of
> >> >> >> different colors)... $Plot is just a token: it might be used to
> >> not
> >> >> >> overload graphs in case there are too many tested models. The fun
> >> >> part
> >> >> >> is that the values of p, m, n and t might vary from one dataset to
> >> >> the
> >> >> >> other, so everything has to be coded dynamically.
> >> >> >>
> >> >> >> For the plotting part I was thinking about having a loop in my
> >> code
> >> >> >> containing something like that:
> >> >> >>
> >> >> >> for (i in 1:nlevels(mydata$Model)) {
> >> >> >>
> >> >> >> subdata<-subset(mydata,mydata$Model=level(mydata$Model)[i])
> >> >> >> xyplot(subset(Observed + Predicted ~ Time | Individuals, data =
> >> >> >> subdata)       #plus additionnal formatting code
> >> >> >>
> >> >> >> }
> >> >> >>
> >> >> >> Unfortunately, this code simply creates a new Trellis plot
> >> instead of
> >> >> >> adding the model one by one on the panels. Any idea or link to a
> >> >> useful
> >> >> >> command will wellcome.
> >> >> >>
> >> >> >> Sebastien
> >> >> >>
> >> >> >> ______________________________________________
> >> >> >> R-help at stat.math.ethz.ch mailing list
> >> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> >> PLEASE do read the posting guide
> >> >> >> http://www.R-project.org/posting-guide.html
> >> >> >> and provide commented, minimal, self-contained, reproducible code.
> >> >> >>
> >> >> >
> >> >> >
> >> >>
> >> >> ______________________________________________
> >> >> R-help at stat.math.ethz.ch mailing list
> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> PLEASE do read the posting guide
> >> >> http://www.R-project.org/posting-guide.html
> >> >> and provide commented, minimal, self-contained, reproducible code.
> >> >>
> >>
> >
> >
>


From guanrao at yahoo.com  Fri Jun 22 23:03:40 2007
From: guanrao at yahoo.com (Guanrao Chen)
Date: Fri, 22 Jun 2007 14:03:40 -0700 (PDT)
Subject: [R] RServe (java2R) question
In-Reply-To: <467BF697.8050203@free.fr>
Message-ID: <687816.13483.qm@web50610.mail.re2.yahoo.com>

hi, R-ers

Can anybody tell why
------
String cmd = new
String("scan(\"tes.txt\",skip=1,nlines=1)");

double[] d = (double[]) c.eval(cmd).getContent();
------
fail
while
------
double[] d = (double[])
c.eval("rnorm(100)").getContent();
------
succeed?

Seems the only difference is the first command has
quotes inside the command and the second command does
not.

Thanks,
Guanrao



       
____________________________________________________________________________________
Got a little couch potato? 
Check out fun summer activities for kids.


From deepayan.sarkar at gmail.com  Fri Jun 22 23:08:13 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Fri, 22 Jun 2007 14:08:13 -0700
Subject: [R] Lattice: hiding only some strips
In-Reply-To: <f5gt5i$f6k$1@sea.gmane.org>
References: <f5gt5i$f6k$1@sea.gmane.org>
Message-ID: <eb555e660706221408h156b8032x74836f4512a97ac0@mail.gmail.com>

On 6/22/07, Michael Hoffman <b3i4old02 at sneakemail.com> wrote:
> I am using R 2.4.0 and lattice to produce some xyplots conditioned on a
> factor and a shingle. The shingle merely chops up the data along the
> x-axis, so it is easy to identify which part of the shingle a panel is
> in by looking at the x-axis markings. I only want to have a strip at the
> top for the factor.
>
> Is this possible? I looked into calculateGridLayout() and it seems to me
> that there isn't an easy way to do it without rewriting that function
> (and others).

It's nowhere near that complicated, you just need to write your own
strip function. E.g.,

mtcars$HP <- equal.count(mtcars$hp)

xyplot(mpg ~ disp | HP + factor(cyl), mtcars,
       par.strip.text = list(lines = 0.5),
       strip = function(which.given, which.panel, ...) {
           if (which.given == 2)
               strip.default(which.given = 1,
                             which.panel = which.panel[which.given],
                             ...)
       })

-Deepayan


From szhan at uoguelph.ca  Fri Jun 22 23:14:39 2007
From: szhan at uoguelph.ca (szhan at uoguelph.ca)
Date: Fri, 22 Jun 2007 17:14:39 -0400
Subject: [R] interaction contrast
Message-ID: <20070622171439.2boqpsr9c0gw0wg4@webmail.uoguelph.ca>

Hello, R experts,
Sorry for asking this question again since I really want a help!

I have a two-factor experiment data and like to calculate estimates of
interation contrasts say factor A has levels of a1, a2, and B has
levels of b1, b2, b3, b4, and b5 with 3 replicates. I am not sure the
constrast estimate I got is right using the script below:

score<-c(7.2,6.5,6.9,6.4,6.9,6.1,6.9,5.3,7.2,5.7,5.1,5.9,7.6,6.9,6.8,
7.2,6.6,6.9,6.4,6.0,6.0,6.9,6.9,6.4,7.5,7.7,7.0,8.6,8.8,8.3)

A <- gl(2, 15, labels=c("a1", "a2"))
B <- rep(gl(5, 3, labels=c("b1", "b2", "b3", "b4", "b5")), 2)

contrasts(B)<-cbind(c(-4,rep(1,4)),c(rep(-3,2),rep(2,3)),
+  c(rep(-2,3),rep(3,2)),c(rep(-1,4), rep(4,1)))
fit1 <- aov(score ~ A*B)
summary(fit1, split=list(B=1:4), expand.split = TRUE)
              Df Sum Sq Mean Sq F value    Pr(>F)
A            1 3.2013  3.2013 15.1483 0.0009054 ***
B            4 8.7780  2.1945 10.3841 0.0001019 ***
    B: C1      1 0.0301  0.0301  0.1424 0.7099296
    B: C2      1 2.0335  2.0335  9.6221 0.0056199 **
    B: C3      1 1.2469  1.2469  5.9004 0.0246876 *
    B: C4      1 5.4675  5.4675 25.8715 5.637e-05 ***
A:B          4 5.3420  1.3355  6.3194 0.0018616 **
    A:B: C1    1 0.7207  0.7207  3.4105 0.0796342 .
    A:B: C2    1 2.6068  2.6068 12.3350 0.0021927 **
    A:B: C3    1 1.9136  1.9136  9.0549 0.0069317 **
    A:B: C4    1 0.1008  0.1008  0.4771 0.4976647
Residuals   20 4.2267  0.2113
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Now I like to get interaction contrast estimate for b1 and b2 vs b3, b4 and b5
cont <- c(1, -1)[A] * c(-3, -3, 2, 2, 2)[B]

estimat<-sum(cont*score) # value of the contrast estimate for A:B C2

> estimat
[1] -24.1

I am not sure the estimate for A:B C2 contrast  (-24.1) is correct
because the F value given the output above(12.3350) does not equal to
those I calculate below (15.2684):

t.stat <- sum(cont*score)/se.contrast(fit1, as.matrix(cont))
> t.stat^2
Contrast 1
    15.2684

Could you please help me calculate the correct the estimate of
interaction contrast and corresponding F value?
Thanks in advance!
Joshua


From deepayan.sarkar at gmail.com  Fri Jun 22 23:25:09 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Fri, 22 Jun 2007 14:25:09 -0700
Subject: [R] Barchart legend position
In-Reply-To: <4A6AB38B55B49C44A22E021A83CBEDDB015EB9A1@sr-pnr-exch3.prairie.int.ec.gc.ca>
References: <4A6AB38B55B49C44A22E021A83CBEDDB015EB9A1@sr-pnr-exch3.prairie.int.ec.gc.ca>
Message-ID: <eb555e660706221425t4a936f46wfffcc74b6575d12e@mail.gmail.com>

On 6/22/07, Spilak,Jacqueline [Edm] <Jacqueline.Spilak at ec.gc.ca> wrote:
> I am using barchart to make charts for some data with a lot more
> functions and labels and such in the command.
>
> barchart(Freq ~ factor(HH), data = dataset1, group= year)
>
> So I have my data grouped by year and I get a legend at the top of
> graph, which is great cause I need the legend for the different years
> but it is a weird spot.  So how can I manipulate the legend, ie. Move
> it, shrink it, do anything with it. I have searched the help archives
> and found nothing, and I have looked up the legend section in ?barchart
> but that has not helped or I am doing something wrong.  Any help is
> greatly appreciated.

I can be more specific if you say what exactly you want to do
(preferably with a small reproducible example). The relevant
documentation is the part under 'key' in help(barchart). I prefer to
use 'auto.key' instead (and you haven't told us what you are using),
but most components of 'key' can be passed through 'auto.key'. Some
examples:


barchart(Titanic,
         auto.key = list(space = "right", size = 2, cex = 0.5))


barchart(Titanic,
         auto.key = list(x = 0.75, y = 0.25, size = 2))


## choose location interactively:

library(grid)

barchart(Titanic,
         page = function(n) {
             cat("Click on plot to place legend", fill = TRUE)
             ll <- grid.locator(unit = "npc")
             if (!is.null(ll))
                 draw.key(simpleKey(dimnames(Titanic)$Survived,
                                    rect = TRUE, points = FALSE),
                          vp = viewport(x = ll$x, y = ll$y),
                          draw = TRUE)
       })


-Deepayan


From jzhang1982 at gmail.com  Fri Jun 22 23:25:34 2007
From: jzhang1982 at gmail.com (Zhang Jian)
Date: Fri, 22 Jun 2007 15:25:34 -0600
Subject: [R] How to run "mathematica" or "c" programs in R?
Message-ID: <3f2938d50706221425p5352bec0s163cb0a0f3a41d2f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070622/46fa8ce9/attachment.pl 

From Horace.Tso at pgn.com  Fri Jun 22 23:29:01 2007
From: Horace.Tso at pgn.com (Horace Tso)
Date: Fri, 22 Jun 2007 14:29:01 -0700
Subject: [R] Imputing missing values in time series
In-Reply-To: <467BBED40200006500006931@pgn.com>
References: <467BB6340200006500006924@pgn.com>
	<467C1CA0.1080606@biostat.wisc.edu>
	<D3AEEDA31E57474B840BEBC25A8A834401957418@NYWEXMB23.msad.ms.com>
	<467BBED40200006500006931@pgn.com>
Message-ID: <467BDCAD020000650000693F@pgn.com>

Thanks to Mark and Erik for different versions of locf, also Erik's pointer to archive where I found another function due to Simon Fear. I haven't tested the zoo locf function. The following shows their performance. Interestingly, Erik's use of a while loop is the fastest. 

HT.

x = 1:1e5
x[sample(1:1e5, 10000)] = NA

>system.time(z2<-locf.iverson2(x))
   user  system elapsed 
   0.07    0.00    0.06 
> system.time(z1<-locf.iverson(x))
   user  system elapsed 
   0.11    0.00    0.11 
> system.time(z3<-locf.sfear(x))
   user  system elapsed 
   1.13    0.00    1.12 

==================================================
# Due to Erik Iverson
locf.iverson2 = function(x) {
  while(any(is.na(x))) {
    x[is.na(x)] <- x[which(is.na(x))-1]
  }
  x
}

# Due to Simon Fear (Fri Nov 14 17:28:57 2003)
locf.sfear = function(x) { 
  assign("stored.value", x[1], envir=.GlobalEnv) 
  sapply(x, function(x) { 
    if(is.na(x)) 
      stored.value 
    else { 
      assign("stored.value", x, envir=.GlobalEnv) 
      x 
    }}) 
} 

# Due to Erik Iverson 
locf.iverson = function(x, unkn=-1) {
  x[is.na(x)] = unkn  #something that is not a possible price
  run = rle(x)
  run$values[run$values==unkn] = run$values[which(run$values==unkn)-1]
  inverse.rle(run)
}


>>> "Horace Tso" <Horace.Tso at pgn.com> 6/22/2007 12:21 PM >>>
Mark, thanks for the tips. I thought you financial folks must have run into things like these before. Just wonder why this problem wasn't asked more often on this list.

H.


>>> "Leeds, Mark (IED)" <Mark.Leeds at morganstanley.com> 6/22/2007 12:16 PM >>>
I have a function that does this type of thing but it works off a pure
vector so it wouldn have to be modified.
If you make your object a zoo object, the that object has many functions
associated with it and na.locf would
Do what you need, I think.


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch 
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Erik Iverson
Sent: Friday, June 22, 2007 3:02 PM
To: Horace Tso
Cc: r-help at stat.math.ethz.ch 
Subject: Re: [R] Imputing missing values in time series

I think my example should work for you, but I couldn't think of a way to
do this without an interative while loop.

test <- c(1,2,3,NA,4,NA,NA,5,NA,6,7,NA)

while(any(is.na(test)))
test[is.na(test)] <- test[which(is.na(test))-1]

  test
  [1] 1 2 3 3 4 4 4 5 5 6 7 7

Horace Tso wrote:
> Folks,
> 
> This must be a rather common problem with real life time series data 
> but I don't see anything in the archive about how to deal with it. I 
> have a time series of natural gas prices by flow date. Since gas is 
> not traded on weekends and holidays, I have a lot of missing values,
> 
> FDate	Price
> 11/1/2006	6.28
> 11/2/2006	6.58
> 11/3/2006	6.586
> 11/4/2006	6.716
> 11/5/2006	NA
> 11/6/2006	NA
> 11/7/2006	6.262
> 11/8/2006	6.27
> 11/9/2006	6.696
> 11/10/2006	6.729
> 11/11/2006	6.487
> 11/12/2006	NA
> 11/13/2006	NA
> 11/14/2006	6.725
> 11/15/2006	6.844
> 11/16/2006	6.907
>  
> What I would like to do is to fill the NAs with the price from the 
> previous date * gas used during holidays is purchased from the week 
> before. Though real simple, I wonder if there is a function to perform

> this task. Some of the imputation functions I'm aware of (eg. impute, 
> transcan in Hmisc) seem to deal with completely different problems.
> 
> 2.5.0/Windows XP
> 
> Thanks in advance.
> 
> HT
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html 
and provide commented, minimal, self-contained, reproducible code.
--------------------------------------------------------

This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
and provide commented, minimal, self-contained, reproducible code.


From juryef at yahoo.com  Fri Jun 22 23:38:00 2007
From: juryef at yahoo.com (Judith Flores)
Date: Fri, 22 Jun 2007 14:38:00 -0700 (PDT)
Subject: [R] Asteriscs in a plot to represent approximate size of p-values
Message-ID: <168087.94138.qm@web34710.mail.mud.yahoo.com>

Hi,

   I need to place double and triple asterics (or
stars) to highlight very low p-values. I am using
points, for example:

points(ssdx,ssdy,pch=8,cex=.9)

   but this allows me to place only one asterisc, how
can I place 2 or 3 asteriscs?

Thank you,

Judith


 
____________________________________________________________________________________
Food fight? Enjoy some healthy debate


From andrewjyee at gmail.com  Sat Jun 23 00:11:55 2007
From: andrewjyee at gmail.com (Andrew Yee)
Date: Fri, 22 Jun 2007 18:11:55 -0400
Subject: [R] merging more than two data frames
Message-ID: <5dff5a0d0706221511g418f67b0uc4ab3b198ba7c708@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070622/ab377886/attachment.pl 

From thomas.pujol at yahoo.com  Sat Jun 23 00:21:12 2007
From: thomas.pujol at yahoo.com (Thomas Pujol)
Date: Fri, 22 Jun 2007 15:21:12 -0700 (PDT)
Subject: [R] speed issues / pros & cons: dataframe vs. matrix
Message-ID: <742793.61645.qm@web59307.mail.re1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070622/89f88f50/attachment.pl 

From maechler at stat.math.ethz.ch  Sat Jun 23 00:36:43 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 23 Jun 2007 00:36:43 +0200
Subject: [R] Matrix *package*, CHOLMOD error: problem too large
In-Reply-To: <467C0F13.4060004@stats.uwo.ca>
References: <op.tub2q6d64hcap5@delllap.ugr.es> <467C0F13.4060004@stats.uwo.ca>
Message-ID: <18044.20219.852968.354884@stat.math.ethz.ch>

[Jose, if you call the Matrix *package* "library" once more, ...
 GRRRRR! ..]
 

>>>>> "DM" == Duncan Murdoch <murdoch at stats.uwo.ca>
>>>>>     on Fri, 22 Jun 2007 14:04:03 -0400 writes:

    DM> On 6/22/2007 1:26 PM, Jose Quesada wrote:
    >> I have a pretty large sparse matrix of integers:
    >>> dim(tasa)
    >> [1] 91650 37651
    >> 
    >> I need to add one to it in order to take logs, but I'm
    >> getting the following error:
    >> 
    >>> tasa = log(tasa + 1)
    >> CHOLMOD error: problem too large Error in
    >> asMethod(object) : Cholmod error `problem too large'
    >> 
    >> I have 2 Gb of RAM, and the current workspace is barely
    >> 300mb.  Is there any workaround to this? Anyone has any
    >> experience with this error?
    >> 

    DM> If tasa is sparse, then tasa+1 will not be sparse, so
    DM> that's likely your problem.

[of course]

    DM> You might have better luck with

    DM> log1p(tasa)

{very good point, thank you, Duncan!}

    DM> if the authors of the Matrix package have written a
    DM> method for log1p(); if not, you'll probably have to do
    DM> it yourself.

They have not yet.

Note however that this - and expm1() - would automagically work
for sparse matrices if these two functions were part of the
"Math" S4 group generic.

I'd say that there's only historical reason for them *not* to be
part of "Math", and I am likely going to propose to change this
....

Martin Maechler

    DM> Duncan Murdoch


From murdoch at stats.uwo.ca  Sat Jun 23 00:59:38 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 22 Jun 2007 18:59:38 -0400
Subject: [R] speed issues / pros & cons: dataframe vs. matrix
In-Reply-To: <742793.61645.qm@web59307.mail.re1.yahoo.com>
References: <742793.61645.qm@web59307.mail.re1.yahoo.com>
Message-ID: <467C545A.2020808@stats.uwo.ca>

On 22/06/2007 6:21 PM, Thomas Pujol wrote:
> I've read that certain operations performed on a matrix (e.g. ribind, cbind) are often much faster compared to operations performed on a data frame.
> 
> Other then the "bind functions", what are the main operations that are significantly faster on a a matrix?

Indexing (e.g. x[1,3]) is much faster on a matrix.
> 
> I know that data frames allow for columnnames and rownames, and that each column in a data frame can have different data types.  Are there any other advantages of storing data in a a dataframe rather then a matrix?

Data frames are lists, so you can use things like df$columnname, 
with(df, expression), attach(df), etc.  Data frame columns have names, 
but matrices don't necessarily.

I'd generally use data frames in any situation where the rows are cases 
and the columns are characteristics, until I found they were too slow: 
and then I'd consider temporary conversion to a matrix to speed things 
up.  As Knuth said, premature optimization is the root of all evil.

Duncan Murdoch


From b3i4old02 at sneakemail.com  Sat Jun 23 03:09:59 2007
From: b3i4old02 at sneakemail.com (Michael Hoffman)
Date: Sat, 23 Jun 2007 02:09:59 +0100
Subject: [R] Lattice: hiding only some strips
In-Reply-To: <eb555e660706221408h156b8032x74836f4512a97ac0@mail.gmail.com>
References: <f5gt5i$f6k$1@sea.gmane.org>
	<eb555e660706221408h156b8032x74836f4512a97ac0@mail.gmail.com>
Message-ID: <f5hrth$e30$1@sea.gmane.org>

Deepayan Sarkar wrote:
> On 6/22/07, Michael Hoffman <b3i4old02 at sneakemail.com> wrote:
>> I am using R 2.4.0 and lattice to produce some xyplots conditioned on a
>> factor and a shingle. The shingle merely chops up the data along the
>> x-axis, so it is easy to identify which part of the shingle a panel is
>> in by looking at the x-axis markings. I only want to have a strip at the
>> top for the factor.
>>
>> Is this possible? I looked into calculateGridLayout() and it seems to me
>> that there isn't an easy way to do it without rewriting that function
>> (and others).
> 
> It's nowhere near that complicated, you just need to write your own
> strip function. E.g.,
> 
> mtcars$HP <- equal.count(mtcars$hp)
> 
> xyplot(mpg ~ disp | HP + factor(cyl), mtcars,
>        par.strip.text = list(lines = 0.5),
>        strip = function(which.given, which.panel, ...) {
>            if (which.given == 2)
>                strip.default(which.given = 1,
>                              which.panel = which.panel[which.given],
>                              ...)
>        })

Thank you for this response. But it looks like I poorly specified the 
problem. I only want to have a strip at the very top of the plot, not at 
the top of each panel.

You can probably understand why I want this better if we take your 
example and swap the givens around:

xyplot(mpg ~ disp | factor(cyl) * HP, mtcars,
        par.strip.text = list(lines = 0.5),
        strip = function(which.given, which.panel, ...) {
            if (which.given == 1)
                strip.default(which.given = 1,
                              which.panel = which.panel[which.given],
                              ...)
        })

So now I have 4, 6, and 8 at the top of every row of panels as a label 
for cyl. But I don't need that--really I only need 4, 6, and 8 at the 
very top (or bottom) of the plot, just like with default settings I only 
get the axis labels at the top and bottom of the plot, not duplicated 
for every panel.

What I want is to draw strips at the very top of the plot and not to 
draw strips that are between panels.

Can this be done?


From deepayan.sarkar at gmail.com  Sat Jun 23 04:23:31 2007
From: deepayan.sarkar at gmail.com (deepayan.sarkar at gmail.com)
Date: Fri, 22 Jun 2007 19:23:31 -0700
Subject: [R] Lattice: hiding only some strips
In-Reply-To: <f5hrth$e30$1@sea.gmane.org>
References: <f5gt5i$f6k$1@sea.gmane.org>
	<eb555e660706221408h156b8032x74836f4512a97ac0@mail.gmail.com>
	<f5hrth$e30$1@sea.gmane.org>
Message-ID: <eb555e660706221923t31c724f8w5744829216d1c45f@mail.gmail.com>

On 6/22/07, Michael Hoffman <b3i4old02 at sneakemail.com> wrote:
> Deepayan Sarkar wrote:
> > On 6/22/07, Michael Hoffman <b3i4old02 at sneakemail.com> wrote:
> >> I am using R 2.4.0 and lattice to produce some xyplots conditioned on a
> >> factor and a shingle. The shingle merely chops up the data along the
> >> x-axis, so it is easy to identify which part of the shingle a panel is
> >> in by looking at the x-axis markings. I only want to have a strip at the
> >> top for the factor.
> >>
> >> Is this possible? I looked into calculateGridLayout() and it seems to me
> >> that there isn't an easy way to do it without rewriting that function
> >> (and others).
> >
> > It's nowhere near that complicated, you just need to write your own
> > strip function. E.g.,
> >
> > mtcars$HP <- equal.count(mtcars$hp)
> >
> > xyplot(mpg ~ disp | HP + factor(cyl), mtcars,
> >        par.strip.text = list(lines = 0.5),
> >        strip = function(which.given, which.panel, ...) {
> >            if (which.given == 2)
> >                strip.default(which.given = 1,
> >                              which.panel = which.panel[which.given],
> >                              ...)
> >        })
>
> Thank you for this response. But it looks like I poorly specified the
> problem. I only want to have a strip at the very top of the plot, not at
> the top of each panel.
>
> You can probably understand why I want this better if we take your
> example and swap the givens around:
>
> xyplot(mpg ~ disp | factor(cyl) * HP, mtcars,
>         par.strip.text = list(lines = 0.5),
>         strip = function(which.given, which.panel, ...) {
>             if (which.given == 1)
>                 strip.default(which.given = 1,
>                               which.panel = which.panel[which.given],
>                               ...)
>         })
>
> So now I have 4, 6, and 8 at the top of every row of panels as a label
> for cyl. But I don't need that--really I only need 4, 6, and 8 at the
> very top (or bottom) of the plot, just like with default settings I only
> get the axis labels at the top and bottom of the plot, not duplicated
> for every panel.
>
> What I want is to draw strips at the very top of the plot and not to
> draw strips that are between panels.
>
> Can this be done?

Sure.

xyplot(mpg ~ disp | factor(cyl) * HP, mtcars,
       par.strip.text = list(lines = 0.5),
       strip = function(which.given, which.panel, ...) {
           if (which.given == 1)
               strip.default(which.given = 1,
                             which.panel = which.panel[which.given],
                             ...)
       },
       par.settings =
       list(layout.heights =
            list(strip = rep(c(0, 1), c(5, 1)))))

-Deepayan


From mmeredith at wcs.org  Sat Jun 23 09:40:58 2007
From: mmeredith at wcs.org (Mike Meredith)
Date: Sat, 23 Jun 2007 00:40:58 -0700 (PDT)
Subject: [R] how to ave this?
In-Reply-To: <cdf817830706220820k7db2f82dv3e2a2e7d7a39ff69@mail.gmail.com>
References: <cdf817830706220758r10e93178x971a53e574e9488d@mail.gmail.com>
	<cdf817830706220820k7db2f82dv3e2a2e7d7a39ff69@mail.gmail.com>
Message-ID: <11264004.post@talk.nabble.com>



The simplest solution in this case would be:

(x[[1]] + x[[2]])/2

But that approach would get messy with >2 matrices in your list. Maybe
change your list to an array, then use 'apply':

n <- length(x)
y <- array(unlist(x), c(3,2,n))
apply(y, 1:2, mean)

HTH, Mike


Weiwei Shi wrote:
> 
> one of my approaches is:
> 
> x0 = sapply(mylist, cbind)
> 
> and manipulate from x0 (x0[1:nrow(x0)/2, ] correponds to fc and the
> lower part is tt.
> 
> but it is not neat way.
> 
> 
> On 6/22/07, Weiwei Shi <helprhelp at gmail.com> wrote:
>> Hi,
>>
>> I have a list that looks like this:
>> [[1]]
>>              fc          tt
>> 50   0.07526882 0.000000000
>> 100  0.09289617 0.000000000
>> 150  0.12359551 0.000000000
>>
>> [[2]]
>>              fc          tt
>> 50   0.02040816 0.000000000
>> 100  0.03626943 0.005025126
>> 150  0.05263158 0.010101010
>>
>> and I am wondering how to "average" it so that I have one matrix t0 at
>> the end, and t0[1,1] = (0.075..+0.0204..)/2
>>
>> Thanks,
>>
>> --
>> Weiwei Shi, Ph.D
>> Research Scientist
>> GeneGO, Inc.
>>
>> "Did you always know?"
>> "No, I did not. But I believed..."
>> ---Matrix III
>>
> 
> 
> -- 
> Weiwei Shi, Ph.D
> Research Scientist
> GeneGO, Inc.
> 
> "Did you always know?"
> "No, I did not. But I believed..."
> ---Matrix III
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/how-to-ave-this--tf3965210.html#a11264004
Sent from the R help mailing list archive at Nabble.com.


From Dimitris.Rizopoulos at med.kuleuven.be  Sat Jun 23 10:08:46 2007
From: Dimitris.Rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Sat, 23 Jun 2007 10:08:46 +0200
Subject: [R] how to ave this?
In-Reply-To: <cdf817830706220820k7db2f82dv3e2a2e7d7a39ff69@mail.gmail.com>
References: <cdf817830706220758r10e93178x971a53e574e9488d@mail.gmail.com>
	<cdf817830706220820k7db2f82dv3e2a2e7d7a39ff69@mail.gmail.com>
Message-ID: <20070623100846.jcczk08vbd3c4k0c@webmail5.kuleuven.be>

you could give a try to the following functions:

matFun <- function(lis, FUN){
     if(!is.list(lis) || !all(sapply(lis, is.matrix)))
         stop("'lis' must be a list containing 2-dimensional arrays")
     dims <- sapply(lis, dim)
     n <- dims[1, 1]
     p <- dims[2, 1]
     if(!all(n == dims[1, ]) || !all(p == dims[2, ]))
         stop("the matrices must have the same dimensions")
     mat <- matrix(unlist(lis), n * p, length(lis))
     matrix(apply(mat, 1, FUN), n, p)
}

matSums <- function(lis){
     if(!is.list(lis) || !all(sapply(lis, is.matrix)))
         stop("'lis' must be a list containing 2-dimensional arrays")
     dims <- sapply(lis, dim)
     n <- dims[1, 1]
     p <- dims[2, 1]
     if(!all(n == dims[1, ]) || !all(p == dims[2, ]))
         stop("the matrices must have the same dimensions")
     out <- array(data = 0, dim = c(n, p))
     for(i in seq(along = lis))
         out <- out + lis[[i]]
     out
}

################

n <- 6
p <- 5
lis <- list(matrix(rnorm(n * p), n, p), matrix(rnorm(n * p), n, p),
matrix(rnorm(n * p), n, p), matrix(rnorm(n * p), n, p),
matrix(rnorm(n * p), n, p))

matFun(lis, sum)
matSums(lis)


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://med.kuleuven.be/biostat/
      http://www.student.kuleuven.be/~m0390867/dimitris.htm


Quoting Weiwei Shi <helprhelp at gmail.com>:

> one of my approaches is:
>
> x0 = sapply(mylist, cbind)
>
> and manipulate from x0 (x0[1:nrow(x0)/2, ] correponds to fc and the
> lower part is tt.
>
> but it is not neat way.
>
>
> On 6/22/07, Weiwei Shi <helprhelp at gmail.com> wrote:
>> Hi,
>>
>> I have a list that looks like this:
>> [[1]]
>>              fc          tt
>> 50   0.07526882 0.000000000
>> 100  0.09289617 0.000000000
>> 150  0.12359551 0.000000000
>>
>> [[2]]
>>              fc          tt
>> 50   0.02040816 0.000000000
>> 100  0.03626943 0.005025126
>> 150  0.05263158 0.010101010
>>
>> and I am wondering how to "average" it so that I have one matrix t0 at
>> the end, and t0[1,1] = (0.075..+0.0204..)/2
>>
>> Thanks,
>>
>> --
>> Weiwei Shi, Ph.D
>> Research Scientist
>> GeneGO, Inc.
>>
>> "Did you always know?"
>> "No, I did not. But I believed..."
>> ---Matrix III
>>
>
>
> --
> Weiwei Shi, Ph.D
> Research Scientist
> GeneGO, Inc.
>
> "Did you always know?"
> "No, I did not. But I believed..."
> ---Matrix III
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>



Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm


From mark at wardle.org  Sat Jun 23 10:44:40 2007
From: mark at wardle.org (Mark Wardle)
Date: Sat, 23 Jun 2007 09:44:40 +0100
Subject: [R] merging more than two data frames
In-Reply-To: <5dff5a0d0706221511g418f67b0uc4ab3b198ba7c708@mail.gmail.com>
References: <5dff5a0d0706221511g418f67b0uc4ab3b198ba7c708@mail.gmail.com>
Message-ID: <b59a37130706230144j2ae0437fq6590fbde618c02da@mail.gmail.com>

On 22/06/07, Andrew Yee <andrewjyee at gmail.com> wrote:
> I'm familiar with using merge() to merge two data frames.  But is there
> functionality in R that will let you merge three or more data frames?
>

I just perform multiple merge() operations iteratively.

-- 
Dr. Mark Wardle
Clinical research fellow and specialist registrar, Neurology
Cardiff, UK


From dieter.menne at menne-biomed.de  Sat Jun 23 10:44:58 2007
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Sat, 23 Jun 2007 10:44:58 +0200
Subject: [R] latex of ftable (Hmisc?)
Message-ID: <LPEJLJACLINDNMBMFAFIAEEDCIAA.dieter.menne@menne-biomed.de>

Dear latexRs,

I tried to make a latex printout of a simple categorial ftable. It should
look like the output of print.ftable. Any ideas how to get the syntax of
summary.formula right. Or some alternative? As far I see, xtable does not
have method for ftable.

Dieter


library(Hmisc)
n=500
sex <- factor(sample(c("m","f"), n, rep=TRUE))
treatment <- factor(sample(c("Drug","Placebo"), n, rep=TRUE))
symptom <- factor(sample( c('H','S','G'), n,TRUE))
# I want this output in latex
ftable(symptom~treatment+sex)
# No, it's not the same
ss = summary(symptom~treatment+sex,fun=table)
latex(ss)


From ccleland at optonline.net  Sat Jun 23 11:16:06 2007
From: ccleland at optonline.net (Chuck Cleland)
Date: Sat, 23 Jun 2007 05:16:06 -0400
Subject: [R] latex of ftable (Hmisc?)
In-Reply-To: <LPEJLJACLINDNMBMFAFIAEEDCIAA.dieter.menne@menne-biomed.de>
References: <LPEJLJACLINDNMBMFAFIAEEDCIAA.dieter.menne@menne-biomed.de>
Message-ID: <467CE4D6.1000902@optonline.net>

Dieter Menne wrote:
> Dear latexRs,
> 
> I tried to make a latex printout of a simple categorial ftable. It should
> look like the output of print.ftable. Any ideas how to get the syntax of
> summary.formula right. Or some alternative? As far I see, xtable does not
> have method for ftable.
> 
> Dieter

  How about a Sweave approach?  Something like this in the *.Rnw file:

\documentclass[letter]{article}

\begin{document}

@

<<echo=FALSE,print=FALSE>>=

library(Hmisc)
n=500
sex <- factor(sample(c("m","f"), n, rep=TRUE))
treatment <- factor(sample(c("Drug","Placebo"), n, rep=TRUE))
symptom <- factor(sample( c('H','S','G'), n,TRUE))

@

<<echo=TRUE,print=TRUE>>=

ftable(symptom ~ treatment + sex)

@

\end{document}

  Then Sweave() the *.Rnw file to produce a *.tex file in the working
directory.

> library(Hmisc)
> n=500
> sex <- factor(sample(c("m","f"), n, rep=TRUE))
> treatment <- factor(sample(c("Drug","Placebo"), n, rep=TRUE))
> symptom <- factor(sample( c('H','S','G'), n,TRUE))
> # I want this output in latex
> ftable(symptom~treatment+sex)
> # No, it's not the same
> ss = summary(symptom~treatment+sex,fun=table)
> latex(ss)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code. 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From mmeredith at wcs.org  Sat Jun 23 11:23:26 2007
From: mmeredith at wcs.org (Mike Meredith)
Date: Sat, 23 Jun 2007 02:23:26 -0700 (PDT)
Subject: [R] Data consistency checks in functions
In-Reply-To: <162740.61793.qm@web53302.mail.re2.yahoo.com>
References: <162740.61793.qm@web53302.mail.re2.yahoo.com>
Message-ID: <11264566.post@talk.nabble.com>



Take a look at Help > Manuals (in PDF) > An Introduction to R, section 10.3.

R will recognise the 2nd argument as 'values' iff you define your function
as:

myfun <- function(theta, values, X)

You can use

if(missing(values)) {
   values <- some.expression(X)
}

to deal with cases where the user only supplies 1 argument.

Where does 'X' come from? If it's a predefined default (maybe something like
'cbind(1:4, 1, 0)' ), better to define it within your function. If it's some
object 'X' lurking in the user environment, it could be changed by the user,
so you don't know what it might be. A way around this is to require the user
to provide either a vector or a matrix as the second argument, then sort
them out with:

if(is.matrix(values)) {
   values <- same.expression.as.before(values)
}

HTH,  Mike.




Anup Nandialath wrote:
> 
> Dear friends,
> 
> I'm writing a function with three arguments
> 
> myfun <- function(theta, X, values)
> 
> {
> ....
> ....
> }
> 
> in this function, I'm trying to write consistency checks. In order to
> compute the statistic of interest I only need theta and values. The idea
> of having X in there is that, if values is not provided by the user, then
> values is computed from X.
> 
> my problem is I'm trying to write consistency checks. For instance if i
> say
> 
> output <- myfun(beta, val1), how do I ensure that R reads this as passing
> arguments to "theta" and "values". In other words is it possible to bypass
> X completely if values is provided. Also how is it possible for R to
> recognize the second argument as being values and not X. This is important
> because X is a matrix and values is a vector. Therefore any checks using
> the dimensions of either one will land in trouble if it does not correctly
> capture that. 
> 
> Thanks in advance
> Sincerely
> 
> Anup
> 
>        
> ---------------------------------
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/Data-consistency-checks-in-functions-tf3962728.html#a11264566
Sent from the R help mailing list archive at Nabble.com.


From dieter.menne at menne-biomed.de  Sat Jun 23 11:22:41 2007
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Sat, 23 Jun 2007 09:22:41 +0000 (UTC)
Subject: [R] latex of ftable (Hmisc?)
References: <LPEJLJACLINDNMBMFAFIAEEDCIAA.dieter.menne@menne-biomed.de>
	<467CE4D6.1000902@optonline.net>
Message-ID: <loom.20070623T112016-976@post.gmane.org>

Chuck Cleland <ccleland <at> optonline.net> writes:

>   How about a Sweave approach?  Something like this in the *.Rnw file:
> 
> \documentclass[letter]{article}
... 
> 
> ftable(symptom ~ treatment + sex)
> 
>  <at> 
> 
> \end{document}
> 
>   Then Sweave() the *.Rnw file to produce a *.tex file in the working
> directory.

Well, this IS for Sweave, and I currently use that solution as a surrogate, but
it definitively not a good looking table for a report.

Dieter


From realityrandom at gmail.com  Sat Jun 23 12:09:32 2007
From: realityrandom at gmail.com (Yuchen Luo)
Date: Sat, 23 Jun 2007 03:09:32 -0700
Subject: [R] Setting up a blank table with column names in the hard drive
Message-ID: <548b8d440706230309h122e5d6flaaeb35a5638ff154@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070623/826b0292/attachment.pl 

From murdoch at stats.uwo.ca  Sat Jun 23 12:40:42 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 23 Jun 2007 06:40:42 -0400
Subject: [R] Setting up a blank table with column names in the hard drive
In-Reply-To: <548b8d440706230309h122e5d6flaaeb35a5638ff154@mail.gmail.com>
References: <548b8d440706230309h122e5d6flaaeb35a5638ff154@mail.gmail.com>
Message-ID: <467CF8AA.3070709@stats.uwo.ca>

Yuchen Luo wrote:
> Dear Friends.
> Greetings!
>
> This should be a very common operation and I believe there should be a nice
> way in R to handle it.  I couldn't find it in the manual or by searching on
> line. I am wondering if I could ask for some help in this community.
>
>
>
> I am trying to record the results of my program to a csv file in the hard
> drive so as to save memory space and also to read the results in excel after
> running the program.  Every loop of my program will result in a list with
> element belonging to different class. For example, things like
>
>
>
> a1 <- list(name="Fred", wife="Mary", no.children=3)
> a2 <- list(name="Tom", wife="Joy", no.children=9)
> a3 <- list(name="Paul", wife="Alic", no.children=5)
>
>
>
> I want the columns to have titles, in the example above, I want to see the
> title "name", "wife" and "no.children" in the excel file.
>
>
>
> To set up the table in the csv file, I need to add at least one row in the
> table up front. How ever, I do not have the first loop of the program
> completed yet at that time. If I add a row that is meaningless, how may I
> delete it after all the loops are completed and all the meaningful rows are
> added to the table?
>
>   
I'd use data frames rather than plain lists for the results, so 
write.csv will work.

Create a data frame with 0 rows, and write it out:  this will give you 
your header line.

e.g.

blank <- data.frame(name=character(0), wife=character(0), 
no.children=numeric(0))
write.csv(blank, 'file.csv')

Now you can rbind new lines onto the data frame as you calculate new 
records and rewrite the whole thing, or just append them to the file 
with append=TRUE and writing with col.names=FALSE.

Duncan Murdoch


From b3i4old02 at sneakemail.com  Sat Jun 23 12:49:07 2007
From: b3i4old02 at sneakemail.com (Michael Hoffman)
Date: Sat, 23 Jun 2007 11:49:07 +0100
Subject: [R] Lattice: hiding only some strips
In-Reply-To: <eb555e660706221923t31c724f8w5744829216d1c45f@mail.gmail.com>
References: <f5gt5i$f6k$1@sea.gmane.org>	<eb555e660706221408h156b8032x74836f4512a97ac0@mail.gmail.com>	<f5hrth$e30$1@sea.gmane.org>
	<eb555e660706221923t31c724f8w5744829216d1c45f@mail.gmail.com>
Message-ID: <f5itrd$qvi$1@sea.gmane.org>

deepayan.sarkar at gmail.com wrote:
> On 6/22/07, Michael Hoffman <b3i4old02 at sneakemail.com> wrote:
>> What I want is to draw strips at the very top of the plot and not to
>> draw strips that are between panels.
 >
> xyplot(mpg ~ disp | factor(cyl) * HP, mtcars,
>        par.strip.text = list(lines = 0.5),
>        strip = function(which.given, which.panel, ...) {
>            if (which.given == 1)
>                strip.default(which.given = 1,
>                              which.panel = which.panel[which.given],
>                              ...)
>        },
>        par.settings =
>        list(layout.heights =
>             list(strip = rep(c(0, 1), c(5, 1)))))

Thanks, this is just what I was looking for.
-- 
Michael


From dieter.menne at menne-biomed.de  Sat Jun 23 13:08:38 2007
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Sat, 23 Jun 2007 11:08:38 +0000 (UTC)
Subject: [R] Setting up a blank table with column names in the hard drive
References: <548b8d440706230309h122e5d6flaaeb35a5638ff154@mail.gmail.com>
Message-ID: <loom.20070623T130728-805@post.gmane.org>

Yuchen Luo <realityrandom <at> gmail.com> writes:

> This should be a very common operation and I believe there should be a nice
> way in R to handle it.  I couldn't find it in the manual or by searching on
> line. I am wondering if I could ask for some help in this community.
> 
> I am trying to record the results of my program to a csv file in the hard
> drive so as to save memory space and also to read the results in excel after
> running the program.  Every loop of my program will result in a list with
> element belonging to different class. For example, things like
> 
> a1 <- list(name="Fred", wife="Mary", no.children=3)
> a2 <- list(name="Tom", wife="Joy", no.children=9)
> a3 <- list(name="Paul", wife="Alic", no.children=5)
> 
> I want the columns to have titles, in the example above, I want to see the
> title "name", "wife" and "no.children" in the excel file.
....

Use a data frame to do the work, and save it with write.table or write.csv

maxallocate=10 # we assume no more than 10 members
myfamily = data.frame(name=rep(NA,maxallocate),wife=NA,nchildren=NA)
myfamily[1,]=c("Fred","Ginger",3)
myfamily[2,]=c("Charles","Mary",1)
myfamily[4,]=c("Frank","Salsa",4)
myfamily$name[3]="Anton"
myfamily$wife[3]="Sue"
myfamily$name[10] = "Charly"
myfamily$name[8] = "Fuhrman"
myfamily= myfamily[-1,] # delete first row
myfamily= myfamily[-1,] # delete current first row, i.e. Charles
# cleanup: assume that all entries having a name are valid
myfamily = myfamily[!is.na(myfamily$name),]
# oops .. I forgot .. another family member turned up unexpectedly
#Add it explicitely
rbind(myfamily,c("Tango","Tanga",33))
# The easy part. Check write.table for other options
write.csv(myfamily,file="myfamily.csv",row.names=FALSE)


From bolker at ufl.edu  Sat Jun 23 15:12:07 2007
From: bolker at ufl.edu (Ben Bolker)
Date: Sat, 23 Jun 2007 13:12:07 +0000 (UTC)
Subject: [R] Asteriscs in a plot to represent approximate size of
	p-values
References: <168087.94138.qm@web34710.mail.mud.yahoo.com>
Message-ID: <loom.20070623T150810-355@post.gmane.org>

Judith Flores <juryef <at> yahoo.com> writes:

> 
> Hi,
> 
>    I need to place double and triple asterics (or
> stars) to highlight very low p-values. I am using
> points, for example:
> 
> points(ssdx,ssdy,pch=8,cex=.9)
> 
>    but this allows me to place only one asterisc, how
> can I place 2 or 3 asteriscs?
> 
> Thank you,
> 
> Judith
> 

   How about 
text(ssdx,ssdy,"***",cex=0.9)  ?
or 

text(ssdx,ssdy,rep("*",2,sep=""))
or 

x.eps = 0.01
points(ssdx+(0:1)*x.eps,rep(ssdy,2),pch=8,cex=0.9)

?


From ferdouse777 at yahoo.com  Sat Jun 23 16:29:15 2007
From: ferdouse777 at yahoo.com (Ferdouse Begum)
Date: Sat, 23 Jun 2007 07:29:15 -0700 (PDT)
Subject: [R] About Memory size
Message-ID: <385317.78243.qm@web35502.mail.mud.yahoo.com>

Hi,
I am trying to analyse cancer data set (affymetrix) by
using bioconductor packages. I have total 14 data set.
Total size of the data set is 432MB. Now I am trying
to analyse these data sets in my PC with RAM 512. But
if I want to get MAplot of my data set, I am getting
the messege
(
> MAplot(ptc.rawData)
Error: cannot allocate vector of size 73.8 Mb
In addition: Warning messages:
1: Reached total allocation of 503Mb: see
help(memory.size) 
2: Reached total allocation of 503Mb: see
help(memory.size) 
3: Reached total allocation of 503Mb: see
help(memory.size) 
4: Reached total allocation of 503Mb: see
help(memory.size))

Now how can I get rid of this problem? 
pls help.

With thanks

Ferdouse


From gavin.simpson at ucl.ac.uk  Sat Jun 23 16:54:32 2007
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Sat, 23 Jun 2007 15:54:32 +0100
Subject: [R] Names of objects passed as ... to a function?
Message-ID: <1182610472.7860.10.camel@dhcppc2.my.nat.localnet>

Dear list,

I have a function whose first argument is '...'. Each element of '...'
is a data frame, and there will be at least 2 data frames in '...'. The
function processes each of the data frames in '...' and returns a list,
whose components are the processed data frames. I would like to name the
components of this returned list with the names of the original data
frames. 

Normally I'd use deparse(substitute()) to do this, but here I do not
know the appropriate argument to run deparse(substitute()) on, and doing
this on ... only returns a single "name":

> foo <- function(...)
+                 deparse(substitute(...))
> dat1 <- rnorm(10)
> dat2 <- runif(10)
> foo(dat1, dat2)
[1] "dat1"

Can anyone suggest to me a way to get the names of objects passed as
the ... argument of a function?

TIA

G
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [t] +44 (0)20 7679 0522
ECRC                              [f] +44 (0)20 7679 0565
UCL Department of Geography
Pearson Building                  [e] gavin.simpsonATNOSPAMucl.ac.uk
Gower Street
London, UK                        [w] http://www.ucl.ac.uk/~ucfagls/
WC1E 6BT                          [w] http://www.freshwaters.org.uk/
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From ligges at statistik.uni-dortmund.de  Sat Jun 23 17:00:22 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 23 Jun 2007 17:00:22 +0200
Subject: [R] About Memory size
In-Reply-To: <385317.78243.qm@web35502.mail.mud.yahoo.com>
References: <385317.78243.qm@web35502.mail.mud.yahoo.com>
Message-ID: <467D3586.2040206@statistik.uni-dortmund.de>



Ferdouse Begum wrote:
> Hi,
> I am trying to analyse cancer data set (affymetrix) by
> using bioconductor packages. I have total 14 data set.
> Total size of the data set is 432MB. 

Do you mean it comsumes 432MB to have the data in R or in some format on 
the harddisc?
Do you need to work on the whole datasets at once?
Have you read the manuals and FAQs (there are sections about memory!!!)?


> Now I am trying
> to analyse these data sets in my PC with RAM 512. But


If you need 432MB just to have the data available in R, then you should 
have *at least* 1GB of RAM in your machine, and for certain function, 
you might need much more.

Hence the advise is to rethink how to reduce the problem or to buy 2GB 
of RAM for your machine (which is advisable in any case, because RAM is 
cheap and thinking hurts). We have upgraded all of our computer labs to 
at least 1GB these days.

Uwe Ligges


> if I want to get MAplot of my data set, I am getting
> the messege
> (
>> MAplot(ptc.rawData)
> Error: cannot allocate vector of size 73.8 Mb
> In addition: Warning messages:
> 1: Reached total allocation of 503Mb: see
> help(memory.size) 
> 2: Reached total allocation of 503Mb: see
> help(memory.size) 
> 3: Reached total allocation of 503Mb: see
> help(memory.size) 
> 4: Reached total allocation of 503Mb: see
> help(memory.size))
> 
> Now how can I get rid of this problem? 
> pls help.

> With thanks
> 
> Ferdouse
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at comcast.net  Sat Jun 23 17:34:39 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Sat, 23 Jun 2007 10:34:39 -0500
Subject: [R] Names of objects passed as ... to a function?
In-Reply-To: <1182610472.7860.10.camel@dhcppc2.my.nat.localnet>
References: <1182610472.7860.10.camel@dhcppc2.my.nat.localnet>
Message-ID: <1182612879.6270.9.camel@Bellerophon.localdomain>

On Sat, 2007-06-23 at 15:54 +0100, Gavin Simpson wrote:
> Dear list,
> 
> I have a function whose first argument is '...'. Each element of '...'
> is a data frame, and there will be at least 2 data frames in '...'. The
> function processes each of the data frames in '...' and returns a list,
> whose components are the processed data frames. I would like to name the
> components of this returned list with the names of the original data
> frames. 
> 
> Normally I'd use deparse(substitute()) to do this, but here I do not
> know the appropriate argument to run deparse(substitute()) on, and doing
> this on ... only returns a single "name":
> 
> > foo <- function(...)
> +                 deparse(substitute(...))
> > dat1 <- rnorm(10)
> > dat2 <- runif(10)
> > foo(dat1, dat2)
> [1] "dat1"
> 
> Can anyone suggest to me a way to get the names of objects passed as
> the ... argument of a function?
> 
> TIA
> 
> G

Gavin,

Try this:

foo <- function(...)
{
  foo.call <- as.character(match.call())[-1]
  dotargs <- list(...)
  names(dotargs) <- foo.call
  dotargs
}

dat1 <- rnorm(10)
dat2 <- runif(10)

> foo(dat1, dat2)
$dat1
 [1]  0.30314712  1.11273051  1.16002159 -1.69579969 -0.54936868
 [6] -0.01931636 -1.56714719 -0.92752592  1.44081430 -0.88249502

$dat2
 [1] 0.53080505 0.55194766 0.42004031 0.23313474 0.08039291 0.69108296
 [7] 0.05794077 0.25523083 0.11331677 0.72618992


See ?match.call

HTH,

Marc Schwartz


From maja.schroeter at gmx.de  Sat Jun 23 17:46:25 2007
From: maja.schroeter at gmx.de (=?iso-8859-1?Q?=22Maja_Schr=F6ter=22?=)
Date: Sat, 23 Jun 2007 17:46:25 +0200
Subject: [R] [r
Message-ID: <20070623154625.267060@gmx.net>


--


From maja.schroeter at gmx.de  Sat Jun 23 17:51:22 2007
From: maja.schroeter at gmx.de (=?iso-8859-1?Q?=22Maja_Schr=F6ter=22?=)
Date: Sat, 23 Jun 2007 17:51:22 +0200
Subject: [R]  Encircling a text in a plot
Message-ID: <20070623155122.267060@gmx.net>

Hello everyone,

I want to write something in a plot with text or something similar, e.g. text(x,y,"something") but I want to encircle it by a box as in a legend.

I have absolutely no idea how this could work.

Thank you very much for your answers!

Maja
--


From ripley at stats.ox.ac.uk  Sat Jun 23 17:52:50 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 23 Jun 2007 16:52:50 +0100 (BST)
Subject: [R] Names of objects passed as ... to a function?
In-Reply-To: <1182610472.7860.10.camel@dhcppc2.my.nat.localnet>
References: <1182610472.7860.10.camel@dhcppc2.my.nat.localnet>
Message-ID: <Pine.LNX.4.64.0706231638110.32330@gannet.stats.ox.ac.uk>

On Sat, 23 Jun 2007, Gavin Simpson wrote:

> Dear list,
>
> I have a function whose first argument is '...'. Each element of '...'
> is a data frame, and there will be at least 2 data frames in '...'. The
> function processes each of the data frames in '...' and returns a list,
> whose components are the processed data frames. I would like to name the
> components of this returned list with the names of the original data
> frames.
>
> Normally I'd use deparse(substitute()) to do this, but here I do not
> know the appropriate argument to run deparse(substitute()) on, and doing
> this on ... only returns a single "name":
>
>> foo <- function(...)
> +                 deparse(substitute(...))
>> dat1 <- rnorm(10)
>> dat2 <- runif(10)
>> foo(dat1, dat2)
> [1] "dat1"
>
> Can anyone suggest to me a way to get the names of objects passed as
> the ... argument of a function?

That's a little tricky.  The following may suffice:

foo <- function(...)
{
   as.character(match.call())[-1]
}

The problem is that under certain circumstances match.call can give names 
like '..2'

> bar <- function(...) foo(...)
> bar(dat1, dat2)
[1] "..1" "..2"

and I don't know a comprehensive R-level solution to that.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ember.kata at gmail.com  Sat Jun 23 18:01:41 2007
From: ember.kata at gmail.com (Ember Kata)
Date: Sat, 23 Jun 2007 09:01:41 -0700 (PDT)
Subject: [R] ROC curve
Message-ID: <11267724.post@talk.nabble.com>


Hello,

I would like to compare paired T test and wilcoxon rank sum test with
different samples. I want to draw ROC curve of the p values. Do you have any
idea how can I do it?

Thanks,
Kata
-- 
View this message in context: http://www.nabble.com/ROC-curve-tf3969726.html#a11267724
Sent from the R help mailing list archive at Nabble.com.


From gonzalezperezmanuel at gmail.com  Sat Jun 23 18:41:42 2007
From: gonzalezperezmanuel at gmail.com (Manuel)
Date: Sat, 23 Jun 2007 18:41:42 +0200
Subject: [R] running Rcmdr
Message-ID: <467D4D46.4050402@gmail.com>

Hi to all,

i want to know how can run Rcmdr automatically , or how to load a 
library in the call of R

greetings


From tavpritesh at gmail.com  Sat Jun 23 18:44:51 2007
From: tavpritesh at gmail.com (Tavpritesh Sethi)
Date: Sat, 23 Jun 2007 22:14:51 +0530
Subject: [R] warning in a loop
Message-ID: <33846cd50706230944r7b2e107ap8a978a46b024ceec@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070623/c69aa4fb/attachment.pl 

From ccosse at gmail.com  Sat Jun 23 18:50:32 2007
From: ccosse at gmail.com (Charles Cosse)
Date: Sat, 23 Jun 2007 10:50:32 -0600
Subject: [R] connecting to process?
Message-ID: <fb87ba070706230950l41794972t894ddd8d27fea067@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070623/1e660cdc/attachment.pl 

From ripley at stats.ox.ac.uk  Sat Jun 23 19:13:56 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 23 Jun 2007 18:13:56 +0100 (BST)
Subject: [R] connecting to process?
In-Reply-To: <fb87ba070706230950l41794972t894ddd8d27fea067@mail.gmail.com>
References: <fb87ba070706230950l41794972t894ddd8d27fea067@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0706231802310.4882@gannet.stats.ox.ac.uk>

On Sat, 23 Jun 2007, Charles Cosse wrote:

> Hello,
>
> sorry if this is a duplicate message -- the R mail-server told me that my
> original post was being held for moderator approval. Whatever.

It would have been courteous to have checked the list archives: the 
previous message is there.

> I just want
> to know if it is possible to connect R to a running process and have
> realtime data updates to some plots?  Thanks,

It is.  Since that is all you 'just want to know', I'll not waste your 
time telling you more, but the 'R Data Import/Export Manual' should be 
your first port of call to help yourself answer similar questions.


> Charles
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

PLEASE do!


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From sabunime at gmail.com  Sat Jun 23 19:45:45 2007
From: sabunime at gmail.com (Saeed Abu Nimeh)
Date: Sat, 23 Jun 2007 12:45:45 -0500
Subject: [R] ROC curve
In-Reply-To: <11267724.post@talk.nabble.com>
References: <11267724.post@talk.nabble.com>
Message-ID: <467D5C49.1030903@gmail.com>

have you tired to use rocr:
http://rocr.bioinf.mpi-sb.mpg.de/

Ember Kata wrote:
> Hello,
> 
> I would like to compare paired T test and wilcoxon rank sum test with
> different samples. I want to draw ROC curve of the p values. Do you have any
> idea how can I do it?
> 
> Thanks,
> Kata


From bates at stat.wisc.edu  Sat Jun 23 20:02:59 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 23 Jun 2007 13:02:59 -0500
Subject: [R] How to run "mathematica" or "c" programs in R?
In-Reply-To: <3f2938d50706221425p5352bec0s163cb0a0f3a41d2f@mail.gmail.com>
References: <3f2938d50706221425p5352bec0s163cb0a0f3a41d2f@mail.gmail.com>
Message-ID: <40e66e0b0706231102g4c2afca5j477e7c9f9f41a296@mail.gmail.com>

On 6/22/07, Zhang Jian <jzhang1982 at gmail.com> wrote:
> I have some programs which were writen in mathematica or c language, but I
> donot know how to use these software. So I want to run them in R.
> Can I do it ?
> How to run "mathematica" or "c" programs in R?

To paraphrase Thomas Lumley,

 Sure.  Just reverse the procedure you use to R code in Mathematica.


From ccosse at gmail.com  Sat Jun 23 20:34:20 2007
From: ccosse at gmail.com (Charles Cosse)
Date: Sat, 23 Jun 2007 12:34:20 -0600
Subject: [R] Fwd:  connecting to process?
In-Reply-To: <fb87ba070706231133g73c3cb64u194300c4f39153fc@mail.gmail.com>
References: <fb87ba070706230950l41794972t894ddd8d27fea067@mail.gmail.com>
	<Pine.LNX.4.64.0706231802310.4882@gannet.stats.ox.ac.uk>
	<fb87ba070706231133g73c3cb64u194300c4f39153fc@mail.gmail.com>
Message-ID: <fb87ba070706231134p3ae4a9f6xc9acf8978f247d1f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070623/8ef7f4e3/attachment.pl 

From frainj at gmail.com  Sat Jun 23 21:00:07 2007
From: frainj at gmail.com (John C Frain)
Date: Sat, 23 Jun 2007 20:00:07 +0100
Subject: [R] How to run "mathematica" or "c" programs in R?
In-Reply-To: <3f2938d50706221425p5352bec0s163cb0a0f3a41d2f@mail.gmail.com>
References: <3f2938d50706221425p5352bec0s163cb0a0f3a41d2f@mail.gmail.com>
Message-ID: <fad888a10706231200i64296853k779914c8e08f01d2@mail.gmail.com>

To run MATHEMATICA programs in R you need to have MATHEMATICA
installed on your PC.  Then if you just want to run the MATHEMATICA
program it is probably best to run it in MATHEMATICA even if you are
not familiar with MATHEMATICA.  You should you run MATHEMATICA from R
only if you wish to integrate the MATHEMATICA code in a larger R
program.

Best Regards

John Frain

On 22/06/07, Zhang Jian <jzhang1982 at gmail.com> wrote:
> I have some programs which were writen in mathematica or c language, but I
> donot know how to use these software. So I want to run them in R.
> Can I do it ?
> How to run "mathematica" or "c" programs in R?
>
> Jian Zhang
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
John C Frain
Trinity College Dublin
Dublin 2
Ireland
www.tcd.ie/Economics/staff/frainj/home.html
mailto:frainj at tcd.ie
mailto:frainj at gmail.com


From maja.schroeter at gmx.de  Sat Jun 23 22:54:56 2007
From: maja.schroeter at gmx.de (=?iso-8859-1?Q?=22Maja_Schr=F6ter=22?=)
Date: Sat, 23 Jun 2007 22:54:56 +0200
Subject: [R]  Highliting a text in a plot
Message-ID: <20070623205456.7320@gmx.net>

Hi everyone,

I want to highlight something in a plot.
So I want to write a text with a yellow background.


I tried to make use of text(x,y,"hallo",bg="yellow")
but that does not work. 

I know I am a handful. Sorry!

Maja!
--


From duvvuru.suman at gmail.com  Sun Jun 24 00:04:08 2007
From: duvvuru.suman at gmail.com (suman Duvvuru)
Date: Sat, 23 Jun 2007 18:04:08 -0400
Subject: [R] Creating different matrices in a loop
Message-ID: <bac8a0820706231504m5f6ceff0j3f9aa700cbffac08@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070623/c14e90ee/attachment.pl 

From jholtman at gmail.com  Sun Jun 24 00:08:36 2007
From: jholtman at gmail.com (jim holtman)
Date: Sat, 23 Jun 2007 18:08:36 -0400
Subject: [R] Creating different matrices in a loop
In-Reply-To: <bac8a0820706231504m5f6ceff0j3f9aa700cbffac08@mail.gmail.com>
References: <bac8a0820706231504m5f6ceff0j3f9aa700cbffac08@mail.gmail.com>
Message-ID: <644e1f320706231508s13d06e02ra4c7964c8ec6b027@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070623/1ac67926/attachment.pl 

From kaveh.vakili at ulb.ac.be  Sat Jun 23 22:03:04 2007
From: kaveh.vakili at ulb.ac.be (Kaveh Vakili)
Date: Sat, 23 Jun 2007 22:03:04 +0200 (CEST)
Subject: [R] approx.irts methodology question
Message-ID: <20070623200304.6916D495@bonito.ulb.ac.be>


hi mailing list,

i'm not sure this is the right place to ask, so in advance forgive me for barking at the wrong tree,

in some part of a thesis i'm using a irregularly spaced time series,
to compute the ACF i used the approx.irts() function (tseries package)

my question would be, can someone direct me to some documentation on how (the approximiation formula) is it functioning as the reference manual entry for 'approx' provides no such niceties... 

my concerns are whether one can seamingly use the ARMA() coeficient obtained from an 'irts' filled by approximation.

thanks in advance,


From Charles.Annis at StatisticalEngineering.com  Sun Jun 24 00:35:51 2007
From: Charles.Annis at StatisticalEngineering.com (Charles Annis, P.E.)
Date: Sat, 23 Jun 2007 18:35:51 -0400
Subject: [R] Highliting a text in a plot
In-Reply-To: <20070623205456.7320@gmx.net>
References: <20070623205456.7320@gmx.net>
Message-ID: <013c01c7b5e6$dafb8250$6400a8c0@DD4XFW31>

Maja:

This will work. It's quick.  It's easy.  And it probably isn't what you want
because there is room for an unplotted symbol on the left.  But it might
suffice.

plot(NA, xlim=0:1, ylim=0:1)## 

legend(x=0.5, y = 0.5, "hallo", bg="yellow", col="dark blue", box.lty=0)

You can look at the code for legend (?legend) and modify it, or use parts of
it for your own function.

Charles Annis, P.E.

Charles.Annis at StatisticalEngineering.com
phone: 561-352-9699
eFax:  614-455-3265
http://www.StatisticalEngineering.com
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of "Maja Schr?ter"
Sent: Saturday, June 23, 2007 4:55 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Highliting a text in a plot

Hi everyone,

I want to highlight something in a plot.
So I want to write a text with a yellow background.


I tried to make use of text(x,y,"hallo",bg="yellow")
but that does not work. 

I know I am a handful. Sorry!

Maja!
--

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From mario.aignertorres at gmail.com  Sun Jun 24 02:48:25 2007
From: mario.aignertorres at gmail.com (Mario Aigner-Torres)
Date: Sat, 23 Jun 2007 21:48:25 -0300
Subject: [R] Simulations for Project Management
Message-ID: <af34d0c00706231748m165ec52bl5dff6aef11e2d118@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070623/b7082a3a/attachment.pl 

From pburns at pburns.seanet.com  Sun Jun 24 10:21:39 2007
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Sun, 24 Jun 2007 09:21:39 +0100
Subject: [R] Creating different matrices in a loop
In-Reply-To: <644e1f320706231508s13d06e02ra4c7964c8ec6b027@mail.gmail.com>
References: <bac8a0820706231504m5f6ceff0j3f9aa700cbffac08@mail.gmail.com>
	<644e1f320706231508s13d06e02ra4c7964c8ec6b027@mail.gmail.com>
Message-ID: <467E2993.10405@pburns.seanet.com>

Except the list should be initialized to the final
length:

smat <- vector("list", length(counts))

Growing objects is a major source of the inefficient
use of memory.  If the memory grows enough it becomes
a large impact on execution time.

Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

jim holtman wrote:

>You can use a 'list' for this:
>
>counts=c(4,6,10);
>
>p=1;
>smat <- list()
>for (i in 1:length(counts))
>{
>
>   smat[[i]] <- bmat[p:p+i-1,];
>   p=p+i;
>}
>
>
>
>
>On 6/23/07, suman Duvvuru <duvvuru.suman at gmail.com> wrote:
>  
>
>>Hello,
>>
>>I have a big matrix of size (20,5) -bmat . I have to loop though the rows
>>in
>>the matrix and create DIFFERENT matrices each time I go through the loop.
>>
>>counts=c(4,6,10);
>>
>>p=1;
>>for (i in 1:length(counts))
>>{
>>
>>   smat=bmat[p:p+i-1,];
>>   p=p+i;
>>}
>>
>>The problem is smat overwrites itself each time inside the loop. I would
>>like to have smat1, smat2, smat3 instead of a single vector smat.
>>Basically
>>I wanted to change the name of the matrix "smat" each time the loop runs
>>so
>>that i will have 3 different matrices.
>>
>>Any help will be very much appreciated.
>>
>>Thanks,
>>Suman
>>
>>       [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>>
>>    
>>
>
>
>
>  
>


From mothsailor at googlemail.com  Sun Jun 24 10:35:47 2007
From: mothsailor at googlemail.com (David Barron)
Date: Sun, 24 Jun 2007 09:35:47 +0100
Subject: [R] Highliting a text in a plot
In-Reply-To: <20070623205456.7320@gmx.net>
References: <20070623205456.7320@gmx.net>
Message-ID: <815b70590706240135q6929a5cah689603f1925ece5e@mail.gmail.com>

How about this:

hilight <- function(x,y,s, bg="yellow") {
    text.width <- strwidth(s)
    text.height <- strheight(s)
    rect(x,y,x+text.width,y+text.height,col=bg,border=NA)
    text(x,y,s,adj=c(0,0))
}

plot(1:10,1:10,type="b")
hilight(4,4,"Point")


On 23/06/07, "Maja Schr?ter" <maja.schroeter at gmx.de> wrote:
> Hi everyone,
>
> I want to highlight something in a plot.
> So I want to write a text with a yellow background.
>
>
> I tried to make use of text(x,y,"hallo",bg="yellow")
> but that does not work.
>
> I know I am a handful. Sorry!
>
> Maja!
> --
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
=================================
David Barron
Said Business School
University of Oxford
Park End Street
Oxford OX1 1HP


From mmeredith at wcs.org  Sun Jun 24 10:54:54 2007
From: mmeredith at wcs.org (Mike Meredith)
Date: Sun, 24 Jun 2007 01:54:54 -0700 (PDT)
Subject: [R] warning in a loop
In-Reply-To: <33846cd50706230944r7b2e107ap8a978a46b024ceec@mail.gmail.com>
References: <33846cd50706230944r7b2e107ap8a978a46b024ceec@mail.gmail.com>
Message-ID: <11273379.post@talk.nabble.com>



You can investigate what's gone wrong after the loop has failed by looking
at the values of i, k, p, and t. Although d[(d[,(i+1)]%in%1),1] produces a
vector, k has only one element. Same with p. Should then be obvious why the
t.test produces an error.

The problem is with the [i] index for k and p; take those away and it works.
If you want to keep the values generated in the loop, make k and p lists and
index with k[[i]] and p[[i]].


A better way to do this would be to use 'sample' to randomize the measured
values in d[,1] and then use d[,2] to group them for testing. You can then
use hundreds of iterations:

t <- rep(NA, 999) 
for(i in 1:999) {
   samp <- sample(d[,1])
   t <- t.test(samp[d[,2]==1], samp[d[,2]==2])$p.value
}
sum(t < 0.05)  # How many were 'significant'?

Note that I prefer to use t <- rep(NA,...) to allocate space, rather than
1:999, so that NA appears as the result if there's a problem.

Why not just do a randomization test?

t <- rep(NA, 1000)
t[1] <- mean(d[d[,2]==1,1]) - mean(d[d[,2]==2,1]) # This is the observed
difference in means
for(i in 2:1000) {
   samp <- sample(d[,1])
   t[i] <- mean(samp[d[,2]==1]) - mean(samp[d[,2]==2])
}
t <- abs(t)   # Skip this line if you want a 1-sided test
sum(t >= t[1])/1000  # This is the 'p-value'

HTH, Mike.


Tavpritesh Sethi wrote:
> 
> hi all,
> I have a matrix with first column having some measurable values, these are
> indexed by the numerals 1,2 and 3 in the other columns of the data and may
> be interpreted as values for categories 1,2 and 3.
> I have written the following loop
> t<-1:10
>  for(i in 1:10)
> + {
> + k[i]<-d[(d[,(i+1)]%in%1),1]
> + p[i]<-d[(d[,(i+1)]%in%2),1]
> + t[i]<-t.test(k[i],p[i])$p.value
> + }
> Error in t.test.default(k[i], p[i]) : not enough 'x' observations
> In addition: Warning messages:
> 1: number of items to replace is not a multiple of replacement length
> 2: number of items to replace is not a multiple of replacement length
> 
> As you might have understood, I want to test for difference between the
> two
> cagories: "k" and "v". the second column of the data is the original
> categorization and the rest columns(3:10) are a matrix of randomized
> values
> between 1 to 3. (I have three categories)
> My purpose of doing so is to check whether significant difference comes up
> in the randomized data also. This is to check the effect of the small
> sample
> size of my data.
> Please suggest a way or an alternative to the above approach.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/warning-in-a-loop-tf3969850.html#a11273379
Sent from the R help mailing list archive at Nabble.com.


From gavin.simpson at ucl.ac.uk  Sun Jun 24 11:23:13 2007
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Sun, 24 Jun 2007 10:23:13 +0100
Subject: [R] Names of objects passed as ... to a function?
In-Reply-To: <Pine.LNX.4.64.0706231638110.32330@gannet.stats.ox.ac.uk>
References: <1182610472.7860.10.camel@dhcppc2.my.nat.localnet>
	<Pine.LNX.4.64.0706231638110.32330@gannet.stats.ox.ac.uk>
Message-ID: <1182676993.3048.4.camel@dhcppc2.my.nat.localnet>

On Sat, 2007-06-23 at 16:52 +0100, Prof Brian Ripley wrote:
> On Sat, 23 Jun 2007, Gavin Simpson wrote:
> 
> > Dear list,
> >
> > I have a function whose first argument is '...'. Each element of '...'
> > is a data frame, and there will be at least 2 data frames in '...'. The
> > function processes each of the data frames in '...' and returns a list,
> > whose components are the processed data frames. I would like to name the
> > components of this returned list with the names of the original data
> > frames.
> >
> > Normally I'd use deparse(substitute()) to do this, but here I do not
> > know the appropriate argument to run deparse(substitute()) on, and doing
> > this on ... only returns a single "name":
> >
> >> foo <- function(...)
> > +                 deparse(substitute(...))
> >> dat1 <- rnorm(10)
> >> dat2 <- runif(10)
> >> foo(dat1, dat2)
> > [1] "dat1"
> >
> > Can anyone suggest to me a way to get the names of objects passed as
> > the ... argument of a function?
> 
> That's a little tricky.  The following may suffice:
> 
> foo <- function(...)
> {
>    as.character(match.call())[-1]
> }

Thanks Brian and Marc for this solution. I simplified my example too
much, as in reality there are additional arguments after '...', but with
a minor change to the solution you provided I got it working.

> 
> The problem is that under certain circumstances match.call can give names 
> like '..2'
> 
> > bar <- function(...) foo(...)
> > bar(dat1, dat2)
> [1] "..1" "..2"
> 
> and I don't know a comprehensive R-level solution to that.

Are there any particular situations (other than the one you show) that
you are aware of when this might happen? I will put a Warning section in
the Rd page for my function explaining that it might not name the
components correctly, so any further examples of where this might not
work could be helpful in writing that.

All the best,

G
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [t] +44 (0)20 7679 0522
ECRC                              [f] +44 (0)20 7679 0565
UCL Department of Geography
Pearson Building                  [e] gavin.simpsonATNOSPAMucl.ac.uk
Gower Street
London, UK                        [w] http://www.ucl.ac.uk/~ucfagls/
WC1E 6BT                          [w] http://www.freshwaters.org.uk/
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From felix at nfrac.org  Sun Jun 24 11:38:06 2007
From: felix at nfrac.org (Felix Andrews)
Date: Sun, 24 Jun 2007 19:38:06 +1000
Subject: [R] plot just one page of lattice plot
Message-ID: <94730b8a0706240238o2686c7e0w3ca9179241d2d232@mail.gmail.com>

Great stuff, thanks. I'm copying this solution to R-help for reference.

On 6/24/07, deepayan.sarkar at gmail.com <deepayan.sarkar at gmail.com> wrote:
> On 6/23/07, Felix Andrews <felix at nfrac.org> wrote:
> > Hi Deepayan,
> >
> > I have a Lattice question: is there any way to plot just one
> > (specified) page of a multi-page display?
>
> Not in those terms exactly. However, it is possible to plot subsets of
> a trellis object, e.g.
>
> p <- xyplot(y ~ x | a)
> # dim(p) is nlevels(a)
> p[1:3]
> p[4:6]
>
> p <- xyplot(y ~ x | a + b)
> # dim(p) is c(nlevels(a), nlevels(b))
> p[1:2, 3:4]
>
> etc. See also ?packet.panel.default (and ?print.trellis), which I just
> realized can be used to do what you want:
>
> packet.panel.page <- function(n)
> {
>     ## returns a function that when used as the 'packet.panel'
>     ## argument in print.trellis plots page number 'n' only
>     function(layout, page, ...) {
>         stopifnot(layout[3] == 1)
>         packet.panel.default(layout = layout,
>                              page = page + n - 1,
>                              ...)
>     }
> }
>
> data(mtcars)
> HP <- equal.count(mtcars$hp, 6)
> p <-
>     xyplot(mpg ~ disp | HP * factor(cyl),
>            mtcars, layout = c(0, 6, 1))
>
> print(p, packet.panel = packet.panel.page(1))
> print(p, packet.panel = packet.panel.page(2))
>
> In fact, I'm going to add this as an example in ?packet.panel.default
>
> -Deepayan
>



-- 
Felix Andrews / ???
PhD candidate, The Fenner School of Environment and Society
The Australian National University (Building 48A), ACT 0200
Beijing Bag, Locked Bag 40, Kingston ACT 2604
http://www.neurofractal.org/felix/
voice:+86_1051404394 (in China)
mobile:+86_13522529265 (in China)
mobile:+61_410400963 (in Australia)
xmpp:foolish.android at gmail.com
3358 543D AAC6 22C2 D336  80D9 360B 72DD 3E4C F5D8


From jim at bitwrit.com.au  Sun Jun 24 12:12:02 2007
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sun, 24 Jun 2007 20:12:02 +1000
Subject: [R] Encircling a text in a plot
In-Reply-To: <20070623155122.267060@gmx.net>
References: <20070623155122.267060@gmx.net>
Message-ID: <467E4372.1040302@bitwrit.com.au>

Maja Schr?ter wrote:
> Hello everyone,
> 
> I want to write something in a plot with text or something similar, e.g. text(x,y,"something") but I want to encircle it by a box as in a legend.
> 
> I have absolutely no idea how this could work.
> 
Hi Maja,
Have a look at boxed.labels and textbox in the plotrix package.

Jim


From murdoch at stats.uwo.ca  Sun Jun 24 13:14:14 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 24 Jun 2007 07:14:14 -0400
Subject: [R] Setting up a blank table with column names in the hard drive
In-Reply-To: <548b8d440706231651v47b7c4a1r20be73ee5d43635f@mail.gmail.com>
References: <548b8d440706230309h122e5d6flaaeb35a5638ff154@mail.gmail.com>	
	<467CF8AA.3070709@stats.uwo.ca>
	<548b8d440706231651v47b7c4a1r20be73ee5d43635f@mail.gmail.com>
Message-ID: <467E5206.7000807@stats.uwo.ca>

On 23/06/2007 7:51 PM, Yuchen Luo wrote:
> Dear Professor Murdoch.
> Thank you so much! Your help is highly appreciated!

Please send replies to the mailing list.
> 
> When I use the following commands, there is a blank cell before title "name"
> in the resulting csv (excel) file. I am wondering how to get rid of it? I
> want to get rid of it because when I write subsequent rows to the file, the
> "name" part start from the beginning which is not aligned with the first
> line of the column titles.

That's a place holder for the row names.  If you don't want it, specify 
row.names=FALSE (and do the same when you write subsequent lines).

Duncan Murdoch

> 
> " blank <- data.frame(name=character(0), wife=character(0),
> no.children=numeric(0))
> write.csv(blank, 'file.csv')"
> 
> Thank you for your help again and your time is highly appreciated!
> 
> Best Wishes
> Yuchen Luo
> I
> 
> 
> On 6/23/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>> Yuchen Luo wrote:
>>> Dear Friends.
>>> Greetings!
>>>
>>> This should be a very common operation and I believe there should be a
>> nice
>>> way in R to handle it.  I couldn't find it in the manual or by searching
>> on
>>> line. I am wondering if I could ask for some help in this community.
>>>
>>>
>>>
>>> I am trying to record the results of my program to a csv file in the
>> hard
>>> drive so as to save memory space and also to read the results in excel
>> after
>>> running the program.  Every loop of my program will result in a list
>> with
>>> element belonging to different class. For example, things like
>>>
>>>
>>>
>>> a1 <- list(name="Fred", wife="Mary", no.children=3)
>>> a2 <- list(name="Tom", wife="Joy", no.children=9)
>>> a3 <- list(name="Paul", wife="Alic", no.children=5)
>>>
>>>
>>>
>>> I want the columns to have titles, in the example above, I want to see
>> the
>>> title "name", "wife" and "no.children" in the excel file.
>>>
>>>
>>>
>>> To set up the table in the csv file, I need to add at least one row in
>> the
>>> table up front. How ever, I do not have the first loop of the program
>>> completed yet at that time. If I add a row that is meaningless, how may
>> I
>>> delete it after all the loops are completed and all the meaningful rows
>> are
>>> added to the table?
>>>
>>>
>> I'd use data frames rather than plain lists for the results, so
>> write.csv will work.
>>
>> Create a data frame with 0 rows, and write it out:  this will give you
>> your header line.
>>
>> e.g.
>>
>>
>>
>> Now you can rbind new lines onto the data frame as you calculate new
>> records and rewrite the whole thing, or just append them to the file
>> with append=TRUE and writing with col.names=FALSE.
>>
>> Duncan Murdoch
>>
>>
>


From pburns at pburns.seanet.com  Sun Jun 24 19:44:33 2007
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Sun, 24 Jun 2007 18:44:33 +0100
Subject: [R] About Memory size
In-Reply-To: <467D3586.2040206@statistik.uni-dortmund.de>
References: <385317.78243.qm@web35502.mail.mud.yahoo.com>
	<467D3586.2040206@statistik.uni-dortmund.de>
Message-ID: <467EAD81.2080609@pburns.seanet.com>

Uwe Ligges wrote:

> ...
>
> RAM is 
>cheap and thinking hurts. 
>
...

Surely a fortune.

Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")


From descall at blueyonder.co.uk  Sun Jun 24 21:48:34 2007
From: descall at blueyonder.co.uk (Des Callaghan)
Date: Sun, 24 Jun 2007 20:48:34 +0100
Subject: [R] Fitting a model to a test set
Message-ID: <000901c7b698$a681ff10$f385fd30$@co.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070624/926336cf/attachment.pl 

From tavpritesh at gmail.com  Sun Jun 24 23:27:32 2007
From: tavpritesh at gmail.com (Tavpritesh)
Date: Sun, 24 Jun 2007 14:27:32 -0700 (PDT)
Subject: [R] @ Mike warning in a loop
In-Reply-To: <11273379.post@talk.nabble.com>
References: <33846cd50706230944r7b2e107ap8a978a46b024ceec@mail.gmail.com>
	<11273379.post@talk.nabble.com>
Message-ID: <11278677.post@talk.nabble.com>


Hi Mike,
Thanks for the help, but I want to conduct tests, not between column 1 & 2
of the data but between the values of column two itself which have been
categorized into 3 classes, and indexed in column 1 as 1,2 and 3. Also if
you could help me with the commands for ANOVA for the same purpose, for
three classes.
Thanks.


Mike Meredith wrote:
> 
> 
> You can investigate what's gone wrong after the loop has failed by looking
> at the values of i, k, p, and t. Although d[(d[,(i+1)]%in%1),1] produces a
> vector, k has only one element. Same with p. Should then be obvious why
> the t.test produces an error.
> 
> The problem is with the [i] index for k and p; take those away and it
> works. If you want to keep the values generated in the loop, make k and p
> lists and index with k[[i]] and p[[i]].
> 
> 
> A better way to do this would be to use 'sample' to randomize the measured
> values in d[,1] and then use d[,2] to group them for testing. You can then
> use hundreds of iterations:
> 
> t <- rep(NA, 999) 
> for(i in 1:999) {
>    samp <- sample(d[,1])
>    t <- t.test(samp[d[,2]==1], samp[d[,2]==2])$p.value
> }
> sum(t < 0.05)  # How many were 'significant'?
> 
> Note that I prefer to use t <- rep(NA,...) to allocate space, rather than
> 1:999, so that NA appears as the result if there's a problem.
> 
> Why not just do a randomization test?
> 
> t <- rep(NA, 1000)
> t[1] <- mean(d[d[,2]==1,1]) - mean(d[d[,2]==2,1]) # This is the observed
> difference in means
> for(i in 2:1000) {
>    samp <- sample(d[,1])
>    t[i] <- mean(samp[d[,2]==1]) - mean(samp[d[,2]==2])
> }
> t <- abs(t)   # Skip this line if you want a 1-sided test
> sum(t >= t[1])/1000  # This is the 'p-value'
> 
> HTH, Mike.
> 
> 
> Tavpritesh Sethi wrote:
>> 
>> hi all,
>> I have a matrix with first column having some measurable values, these
>> are
>> indexed by the numerals 1,2 and 3 in the other columns of the data and
>> may
>> be interpreted as values for categories 1,2 and 3.
>> I have written the following loop
>> t<-1:10
>>  for(i in 1:10)
>> + {
>> + k[i]<-d[(d[,(i+1)]%in%1),1]
>> + p[i]<-d[(d[,(i+1)]%in%2),1]
>> + t[i]<-t.test(k[i],p[i])$p.value
>> + }
>> Error in t.test.default(k[i], p[i]) : not enough 'x' observations
>> In addition: Warning messages:
>> 1: number of items to replace is not a multiple of replacement length
>> 2: number of items to replace is not a multiple of replacement length
>> 
>> As you might have understood, I want to test for difference between the
>> two
>> cagories: "k" and "v". the second column of the data is the original
>> categorization and the rest columns(3:10) are a matrix of randomized
>> values
>> between 1 to 3. (I have three categories)
>> My purpose of doing so is to check whether significant difference comes
>> up
>> in the randomized data also. This is to check the effect of the small
>> sample
>> size of my data.
>> Please suggest a way or an alternative to the above approach.
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
> 
> 

-- 
View this message in context: http://www.nabble.com/warning-in-a-loop-tf3969850.html#a11278677
Sent from the R help mailing list archive at Nabble.com.


From jcroot at gmail.com  Mon Jun 25 00:12:30 2007
From: jcroot at gmail.com (James Root)
Date: Sun, 24 Jun 2007 18:12:30 -0400
Subject: [R] adding lines to stripchart
Message-ID: <acb1f1cc0706241512w7865b424wd92003e843fd9d7@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070624/274e6e7d/attachment.pl 

From Max.Kuhn at pfizer.com  Mon Jun 25 01:14:01 2007
From: Max.Kuhn at pfizer.com (Kuhn, Max)
Date: Sun, 24 Jun 2007 19:14:01 -0400
Subject: [R] Fitting a model to a test set
In-Reply-To: <000901c7b698$a681ff10$f385fd30$@co.uk>
Message-ID: <71257D09F114DA4A8E134DEAC70F25D308B97B5A@groamrexm03.amer.pfizer.com>

Des,

Please provide some information (like the results of sessionInfo) and
example code for your model. Did you use gee to fit the model and with
what function? If could be that you need to examine the type argument of
the predict function to make sure that you are getting the scale that
you are interested in.

Max
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Des Callaghan
Sent: Sunday, June 24, 2007 3:49 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Fitting a model to a test set

Dear Forum members,
 
I have created a quasi-poisson model from a training dataset and now
wish to
use the model to estimate y values for a test dataset, in order to
validate
the model. The trouble is I can't figure out how to estimate y values
for
the test set using the model derived from the training set. I've been
fiddling about with predict(), but can't seem to get the desired result.
Could somebody help please? Thanks very much in advance.
 
Best wishes,
Des
 

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

----------------------------------------------------------------------
LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}


From Darren.Weber at radiology.ucsf.edu  Sun Jun 24 20:54:28 2007
From: Darren.Weber at radiology.ucsf.edu (DarrenWeber)
Date: Sun, 24 Jun 2007 18:54:28 -0000
Subject: [R] ANOVA non-sphericity test and corrections (eg,
	Greenhouse-Geisser)
Message-ID: <1182711268.498914.61460@e9g2000prf.googlegroups.com>


I'm an experimental psychologist and when I run ANOVA analysis in
SPSS, I normally ask for a test of non-sphericity (Box's M-test).  I
also ask for output of the corrections for non-sphericity, such as
Greenhouse-Geisser and Huhn-Feldt.  These tests and correction factors
are commonly used in the journals for experimental and other
psychology reports.  I have been switching from SPSS to R for over a
year now, but I realize now that I don't have the non-sphericity test
and correction factors.

The backgroud to this question is that I'm doing a psychophysics
experiment and the data analysis uses an aov model that looks like
this:

roiAOV <- aov( roi ~ (Cue*Hemisphere) + Error(Subject/
(Cue*Hemisphere)), data=roiDataframe)

where Cue is 2 levels (an arrow on a screen that points left or right)
and Hemisphere is 2 levels (brain activity in the left or right
cerebral hemisphere).  There are 8 subjects and they all have one
observation for all levels of Cue * Hemisphere (ie, a within-subjects
design).

I need some functions for calculation of Box's M and the Greenhouse-
Geisser correction factor.  Below is some code example that I have for
the latter, but I don't know how to adapt it so it can take the aov
object.

# BEGIN CODE BLOCK
# see pp. 45-47 of
# http://www.psych.upenn.edu/~baron/rpsych.pdf

# ---
# create some data

x0 <- rnorm(30)
x2 <- rnorm(30)
x4 <- rnorm(30)

data <- cbind(x0,x2,x4)

# n is the number of 'subjects' or rows; while
# k is the number of levels in the factor (columns),
# which is the number of repeated measures
n <- dim(data)[1]
k <- dim(data)[2]

# if k <= 2, the epsilon correction is not required.
# When the data are perfectly spherical, epsilon = 1.
# The minimum value possible for epsilon is

epsi = 1 / (k - 1)

# if epsi == 1 and k == 2, quit now...

# ---
# calculate variance-covariance matrix
# diagonal entries are variance,
# off-diagonal are covariance
S <- var(data)

# ---
# Now estimate Epsilon

D <- k^2 * ( mean(diag(S)) - mean(S) )^2

N1 <- sum(S^2)
N2 <- 2 * k * sum( apply(S,1,mean)^2 )
N3 <- k^2 * mean(S)^2

epsi <- D / ( (k-1) * (N1 - N2 + N3) )

# e is used to modify the degrees of freedom for the
# F test, so we have (k-1) becomes epsi(k-1) and also
# (k - 1)(n - 1) becomes epsi(k - 1)(n - 1).  The new
# p-value for the F statistic is found with the
# pf() function.  For example, if we have
# df1 =  k - 1 = 3 - 1 = 2
# df2 = (k - 1)(n - 1) = (3 - 1)(10 - 1) = 18
# F = 40.719
# then the adjusted 2-tailed p-value is given by:
#

Fvalue <- 40.719
Pepsi <- 2 * (1 - pf(Fvalue, df1=epsi*(k-1), df2=epsi*(k-1)*(n-1) ) )

# Huynh-Feldt correction
# The Greenhouse-Geisser epsilon tends to underestimate
# epsilon when epsilon is greater than 0.70 (Stevens, 1990).
# An estimated e=0.96 may be actually 1. Huynh-Feldt
# correction is less conservative. The Huynh-Feldt
# epsilon is calculated from the Greenhouse-Geisser epsilon,

epsiHF <- (n * (k-1) * epsi - 2) / ((k-1) * ((n-1) - (k-1)*epsi))

PepsiHF <- 2 * (1 - pf(Fvalue, df1=epsiHF*(k-1),
df2=epsiHF*(k-1)*(n-1) ) )

# MANOVA (and multivariate tests) may be better if the
# Greenhouse-Geisser and the Huynh-Feldt corrections do not agree,
# which may happen when epsilon drops below 0.70. When epsilon
# drops below 0.40, both the G-G and H-F corrections may indicate
# that the violation of sphericity is affecting the adjusted p-values.
# MANOVA is not always appropriate, though. MANOVA usually requires
# a larger sample size. Maxwell and Delaney (1990, p. 602) suggest
# a rough rule of thumb that the sample size n should be greater
# than k+10.
# END CODE BLOCK


From rosenfel at cshl.edu  Sun Jun 24 06:14:10 2007
From: rosenfel at cshl.edu (Rosenfeld, Jeffrey)
Date: Sun, 24 Jun 2007 00:14:10 -0400
Subject: [R] Half of a heatmap
Message-ID: <4A7F2400BAF11B4DBC4BF3D2046593E20188517E@mailbox05.cshl.edu>

I am trying to produce a heatmap of pairwise correlations, but since the matrix is symmetric, I only need either the upper or the lower triangle.  I have scoured the web and R documentation, but I have not been able to find a way to produce such a figure.  Is there a simple way to produce a heat map with only the part above or below the diagonal?


Thank You,

Jeffrey Rosenfeld
Cold Spring Harbor Laboratory


From residuo.solow at gmail.com  Mon Jun 25 01:27:20 2007
From: residuo.solow at gmail.com (Sebastian Kruk)
Date: Sun, 24 Jun 2007 20:27:20 -0300
Subject: [R] matlab/gauss code in R
Message-ID: <a7961d100706241627g49035513s90d1d91f9e42d622@mail.gmail.com>

Hi all!

I would like to import a matlab or gauss code to R.

Could you help me?

Bye,

Sebasti?n.

2007/6/23, r-help-request en stat.math.ethz.ch <r-help-request en stat.math.ethz.ch>:
> Send R-help mailing list submissions to
>        r-help en stat.math.ethz.ch
>
> To subscribe or unsubscribe via the World Wide Web, visit
>        https://stat.ethz.ch/mailman/listinfo/r-help
> or, via email, send a message with subject or body 'help' to
>        r-help-request en stat.math.ethz.ch
>
> You can reach the person managing the list at
>        r-help-owner en stat.math.ethz.ch
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-help digest..."
>
>
> Today's Topics:
>
>   1. what is "better" when combining data frames? merge vs. rbind
>      & cbind (Thomas Pujol)
>   2. extract index during execution of sapply (Christian Bieli)
>   3. multiple return (Manuele Pesenti)
>   4. Re: what is "better" when combining data frames? merge vs.
>      rbind &   cbind (Duncan Murdoch)
>   5. Re: multiple return (Mahbub Latif)
>   6. Re: how to create cumulative histogram from two   independent
>      variables? (Jim Lemon)
>   7. Re: Adding exponents (superscript format) to a plot (John Kane)
>   8. Re: using lme on multiple datasets in one shot (Douglas Bates)
>   9. Re: abline plots at wrong abscissae after boxplot (S Ellison)
>  10. Boxplot issues (S Ellison)
>  11. Re: help on the use of ldBand (Frank E Harrell Jr)
>  12. Re: multiple return (ONKELINX, Thierry)
>  13. Re: extract index during execution of sapply (Martin Morgan)
>  14. vectorize a function (Robin Hankin)
>  15. Re: Tools For Preparing Data For Analysis (Kevin E. Thorpe)
>  16. Re: Data consistency checks in functions (Kuhn, Max)
>  17. Re: vectorize a function (Christos Hatzis)
>  18. Re: extract index during execution of sapply (Ben Bolker)
>  19. Re: extract index during execution of sapply (Thomas Lumley)
>  20. fitCopula (Oden, Kevin)
>  21. how to ave this? (Weiwei Shi)
>  22. fitCopula (Oden, Kevin)
>  23. Re: how to ave this? (Weiwei Shi)
>  24. Re: Result depends on order of factors in unbalanced designs
>      (lme, anova)? (Prof Brian Ripley)
>  25. Re: Tools For Preparing Data For Analysis (Christophe Pallier)
>  26. Re: interpretation of F-statistics in GAMs (Simon Wood)
>  27. Re: Boxplot issues (Martin Maechler)
>  28. Re: Overlaying lattice graphs (continued) (S?bastien)
>  29. Matrix library, CHOLMOD error: problem too large (Jose Quesada )
>  30. Re: Matrix library, CHOLMOD error: problem too large
>      (Duncan Murdoch)
>  31. Imputing missing values in time series (Horace Tso)
>  32. Re: Imputing missing values in time series (Erik Iverson)
>  33. Re: Imputing missing values in time series (Horace Tso)
>  34. Re: Switching X-axis and Y-axis for histogram (hadley wickham)
>  35. Re: Imputing missing values in time series (Leeds, Mark (IED))
>  36. Re: Imputing missing values in time series (Horace Tso)
>  37. Re: Overlaying lattice graphs (continued) (hadley wickham)
>  38. Re: Overlaying lattice graphs (continued) (Deepayan Sarkar)
>  39. Re: Stacked barchart color (hadley wickham)
>  40. Re: Visualize quartiles of plot line (hadley wickham)
>  41. "heatmap" color still a spectrum for binary outcomes?
>      (Patrick Ayscue)
>  42. Barchart legend position (Spilak,Jacqueline [Edm])
>  43. Lattice: hiding only some strips (Michael Hoffman)
>  44. Re: Overlaying lattice graphs (continued) (S?bastien)
>  45. Bayesian Networks (Mario.Carvalho.Fernandes en bpi.pt)
>  46. connecting to running process possible? (Charles Cosse)
>  47. Re: Overlaying lattice graphs (continued) (hadley wickham)
>  48. RServe (java2R) question (Guanrao Chen)
>  49. Re: Lattice: hiding only some strips (Deepayan Sarkar)
>  50. interaction contrast (szhan en uoguelph.ca)
>  51. Re: Barchart legend position (Deepayan Sarkar)
>  52. How to run "mathematica" or "c" programs in R? (Zhang Jian)
>  53. Re: Imputing missing values in time series (Horace Tso)
>  54. Asteriscs in a plot to represent approximate size of p-values
>      (Judith Flores)
>  55. merging more than two data frames (Andrew Yee)
>  56. speed issues / pros & cons: dataframe vs. matrix (Thomas Pujol)
>  57. Re: Matrix *package*, CHOLMOD error: problem too large
>      (Martin Maechler)
>  58. Re: speed issues / pros & cons: dataframe vs. matrix
>      (Duncan Murdoch)
>  59. Re: Lattice: hiding only some strips (Michael Hoffman)
>  60. Re: Lattice: hiding only some strips (deepayan.sarkar en gmail.com)
>  61. Re: how to ave this? (Mike Meredith)
>  62. Re: how to ave this? (Dimitris Rizopoulos)
>  63. Re: merging more than two data frames (Mark Wardle)
>  64. latex of ftable (Hmisc?) (Dieter Menne)
>  65. Re: latex of ftable (Hmisc?) (Chuck Cleland)
>  66. Re: Data consistency checks in functions (Mike Meredith)
>  67. Re: latex of ftable (Hmisc?) (Dieter Menne)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Thu, 21 Jun 2007 12:36:16 -0700 (PDT)
> From: Thomas Pujol <thomas.pujol en yahoo.com>
> Subject: [R] what is "better" when combining data frames? merge vs.
>        rbind & cbind
> To: r-help en stat.math.ethz.ch
> Message-ID: <510958.56904.qm en web59308.mail.re1.yahoo.com>
> Content-Type: text/plain
>
> I often need to "combine" data frames, sometimes "vertically" and other times "horizontally".
>
> When it "better" to use merge? When is it better to use rbind or cbind?
>
> Are there clear pros and cons of each approach?
>
>
> ---------------------------------
>
>        [[alternative HTML version deleted]]
>
>
>
> ------------------------------
>
> Message: 2
> Date: Fri, 22 Jun 2007 12:31:39 +0200
> From: Christian Bieli <christian.bieli en unibas.ch>
> Subject: [R] extract index during execution of sapply
> To: R help list <r-help en stat.math.ethz.ch>
> Message-ID: <467BA50B.60408 en unibas.ch>
> Content-Type: text/plain; charset=ISO-8859-15; format=flowed
>
> Hi there
> During execution of sapply I want to extract the number of times the
> function given to supply has been executed. I came up with:
>
> mylist <- list(a=3,b=6,c=9)
> sapply(mylist,function(x)as.numeric(gsub("[^0-9]","",deparse(substitute(x)))))
>
> This works fine, but looks quite ugly. I'm sure that there's a more
> elegant way to do this.
>
> Any suggestion?
>
> Christian
>
>
>
> ------------------------------
>
> Message: 3
> Date: Fri, 22 Jun 2007 12:37:37 +0200
> From: Manuele Pesenti <amicogodzilla en bruttocarattere.org>
> Subject: [R] multiple return
> To: r-help en stat.math.ethz.ch
> Message-ID: <200706221237.37479.amicogodzilla en bruttocarattere.org>
> Content-Type: text/plain;  charset="us-ascii"
>
> Dear User,
> what's the correct way to obtain a multiple return from a function?
>
> for example creating the simple function:
>
> somma <- function (a, b) {
>  c <- a+b
>  return (a, b, c)
> }
>
> when I call it, it runs but returns the following output:
>
> > somma(5, 7)
> $a
> [1] 5
>
> $b
> [1] 7
>
> $c
> [1] 12
>
> Warning message:
> return multi-argomento sono deprecati in: return(a, b, c)
>
> i.e. multi-return is deprecated...
>
> thanks a lot
> best regards
>        Manuele
>
> --
> Manuele Pesenti
>        manuele en inventati.org
>        amicogodzilla en jabber.linux.it
>        http://mpesenti.polito.it
>
>
>
> ------------------------------
>
> Message: 4
> Date: Fri, 22 Jun 2007 06:40:23 -0400
> From: Duncan Murdoch <murdoch en stats.uwo.ca>
> Subject: Re: [R] what is "better" when combining data frames? merge
>        vs. rbind &     cbind
> To: Thomas Pujol <thomas.pujol en yahoo.com>
> Cc: r-help en stat.math.ethz.ch
> Message-ID: <467BA717.7080202 en stats.uwo.ca>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
> On 21/06/2007 3:36 PM, Thomas Pujol wrote:
> > I often need to "combine" data frames, sometimes "vertically" and other times "horizontally".
> >
> > When it "better" to use merge? When is it better to use rbind or cbind?
> >
> > Are there clear pros and cons of each approach?
>
> If rbind or cbind work, use them.  They are much simpler, but much less
> flexible.
>
> Duncan Murdoch
>
>
>
> ------------------------------
>
> Message: 5
> Date: Fri, 22 Jun 2007 17:20:01 +0600
> From: "Mahbub Latif" <mlatif en isrt.ac.bd>
> Subject: Re: [R] multiple return
> To: amicogodzilla en bruttocarattere.org
> Cc: r-help en stat.math.ethz.ch
> Message-ID:
>        <5faba43d0706220420m6f34f831l7353b680925dae34 en mail.gmail.com>
> Content-Type: text/plain
>
> one way --
>
>
> somma <- function (a, b) {
>  c <- a+b
>  return (list(a=a, b=a, c=c))
> }
>
> Mahbub.
>
> On 6/22/07, Manuele Pesenti <amicogodzilla en bruttocarattere.org> wrote:
> >
> > Dear User,
> > what's the correct way to obtain a multiple return from a function?
> >
> > for example creating the simple function:
> >
> > somma <- function (a, b) {
> >   c <- a+b
> >   return (a, b, c)
> > }
> >
> > when I call it, it runs but returns the following output:
> >
> > > somma(5, 7)
> > $a
> > [1] 5
> >
> > $b
> > [1] 7
> >
> > $c
> > [1] 12
> >
> > Warning message:
> > return multi-argomento sono deprecati in: return(a, b, c)
> >
> > i.e. multi-return is deprecated...
> >
> > thanks a lot
> > best regards
> >         Manuele
> >
> > --
> > Manuele Pesenti
> >         manuele en inventati.org
> >         amicogodzilla en jabber.linux.it
> >         http://mpesenti.polito.it
> >
> > ______________________________________________
> > R-help en stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
>
> --
> A H M Mahbub Latif, PhD
> Assistant Professor
> Applied Statistics
> Institute of Statistical Research and Training
> University of Dhaka, Dhaka 1000, Bangladesh
> web : http://www.isrt.ac.bd/mlatif
> ----
> Computers are like airconditioners: They stop working properly if you open
> windows.
>
>        [[alternative HTML version deleted]]
>
>
>
> ------------------------------
>
> Message: 6
> Date: Fri, 22 Jun 2007 21:36:29 +1000
> From: Jim Lemon <jim en bitwrit.com.au>
> Subject: Re: [R] how to create cumulative histogram from two
>        independent     variables?
> To: Jose Borreguero <borreguero en gmail.com>, R-help en stat.math.ethz.ch
> Message-ID: <467BB43D.3060004 en bitwrit.com.au>
> Content-Type: text/plain; charset=us-ascii; format=flowed
>
> Jose Borreguero wrote:
> > Hi all,
> > I am extremely newbie to R. Can anybody jump-start me with any clues as to
> > how do I get a cumulative histogram from two independent variables,
> > cumhist(X,Y) ?
> > -jose
> >
> Hi Jose,
>
> Is this something like you want?
>
> var1<-sample(1:10,100,TRUE)
> var2<-sample(1:10,100,TRUE)
> barplot(rbind(hist(var1,plot=FALSE)$counts,hist(var2,plot=FALSE)$counts))
>
> Jim
>
>
>
> ------------------------------
>
> Message: 7
> Date: Fri, 22 Jun 2007 07:44:23 -0400 (EDT)
> From: John Kane <jrkrideau en yahoo.ca>
> Subject: Re: [R] Adding exponents (superscript format) to a plot
> To: Judith Flores <juryef en yahoo.com>, RHelp <r-help en stat.math.ethz.ch>
> Message-ID: <466583.57100.qm en web32802.mail.mud.yahoo.com>
> Content-Type: text/plain; charset=iso-8859-1
>
> # Using expression to add superscipts to the labels
>
> vec=c(1,10,100,1000,10000,100000,1000000,10000000)
>  plot(vec,vec,log="xy", axes=F)
>  axis(1, at=10^c(0,2,4,6), labels=expression(1, 10^2,
> 10^4, 10^6))
>  axis(2, at=10^c(0,2,4,6), labels=expression(1, 10^2,
> 10^4, 10^6), las=1)
>  box()
>
> --- Judith Flores <juryef en yahoo.com> wrote:
>
> > Hi,
> >
> >    I need to add exponents to a label in one of the
> > axes of a plot, how can I do this?
> >
> > Thank you,
> >
> > Judith
> >
> >
> >
> >
> ____________________________________________________________________________________
> > Food fight? Enjoy some healthy debate
> >
> > ______________________________________________
> > R-help en stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained,
> > reproducible code.
> >
>
>
>
> ------------------------------
>
> Message: 8
> Date: Fri, 22 Jun 2007 06:45:26 -0500
> From: "Douglas Bates" <bates en stat.wisc.edu>
> Subject: Re: [R] using lme on multiple datasets in one shot
> To: "maitra en iastate.edu" <maitra en iastate.edu>
> Cc: R-help <r-help en stat.math.ethz.ch>
> Message-ID:
>        <40e66e0b0706220445j5b5d74d7nb46237f83f0b8432 en mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
> On 6/21/07, maitra en iastate.edu <maitra en iastate.edu> wrote:
> > Dear list,
>
> > I would like to do a huge number of lme's using the same design matrix
> > (and fixed and random effects). Is it possible to do this efficiently?
> > Doing otherwise is not an option for my example.
>
> > Basically, I am wanting to do the following which is possible using lm:
>
> > X <- matrix(rnorm(50),10,5)
> > Y <- matrix(rnorm(50),10,5)
> > lm(Y~X)
>
> > with lme. Any suggestions?
>
> It would not be easy to do this.  Neither lme nor lmer were designed
> to make this easy to do.  There is a better chance of accomplishing
> this by creating a custom function based on the current lmer but the
> modifications required are non-trivial.
>
> This is a reasonable thing to want to accomplish and I will add it to
> the "To Do" list for lmer.  However it is not something I will be able
> to get to soon.
>
>
>
> ------------------------------
>
> Message: 9
> Date: Fri, 22 Jun 2007 12:49:38 +0100
> From: "S Ellison" <S.Ellison en lgc.co.uk>
> Subject: Re: [R] abline plots at wrong abscissae after boxplot
> To: <r-help en stat.math.ethz.ch>, <bwilfley en tripleringtech.com>
> Message-ID: <s67bc579.034 en tedmail2.lgc.co.uk>
> Content-Type: text/plain; charset=US-ASCII
>
> Boxplot positions and labels are not the same thing.
> You have groups 'called' "2", "3", "4". As factors - which is what bocplot will turn them into -  they will be treated as arbitrary labels and _numbered_ 1:3 (try as.numeric(factor(x)).
>
> So your lm() used 2:4, but your plot (and abline) uses 1:3 for positions and "2" - "4" as labels.
>
> The best option used to be to plot the boxes at positions 2:4. Look at the at= parameter in boxplot.
> But that is now of little help because there is no way of overriding xlim, leaving you no alternative but to reformulate your model with an offset or something.
>
> I will take up the boxplot xlim issue separately on R-dev; it's not the only such.
>
> Steve Ellison.
>
> >>> "Brian Wilfley" <bwilfley en tripleringtech.com> 21/06/2007 22:44:17 >>>
> I'm trying to add lines to a plot originally made with "boxplot", but
> the lines appear in the wrong place.
>
> *******************************************************************
> This email and any attachments are confidential. Any use, co...{{dropped}}
>
>
>
> ------------------------------
>
> Message: 10
> Date: Fri, 22 Jun 2007 13:02:20 +0100
> From: "S Ellison" <S.Ellison en lgc.co.uk>
> Subject: [R] Boxplot issues
> To: <r-help en stat.math.ethz.ch>
> Message-ID: <s67bc871.078 en tedmail2.lgc.co.uk>
> Content-Type: text/plain; charset=US-ASCII
>
> Boxplot and bxp seem to have changed behaviour a bit of late (R 2.4.1). Or maybe I am mis-remembering.
>
> An annoying feature is that while at=3:6 will work, there is no way of overriding the default xlim of 0.5 to n+0.5. That prevents plotting boxes on, for example, interval scales - a useful thing to do at times. I really can see no good reason for bxp to hard-core the xlim=c(0.5, n+0.5) in the function body; it should be a parameter default conditional on horizontal=, not hard coded.
>
> Also, boxplot does not drop empty groups. I'm sure it used to. I know it is good to be able to see where a factor level is unpopulated, but its a nuisance with fractional factorials and some nested or survey problems when many are known to be missing and are of no interest. Irrespective of whether my memory is correct, the option would be useful. How hard can it be to add a 'drop.empty=F' default to boxplot to allow it to switch?
>
> Obviously, these are things I can fix locally. But who 'owns' boxplot so I can provide suggested code to them for later releases?
>
> Steve Ellison
>
>
>
> *******************************************************************
> This email and any attachments are confidential. Any use, co...{{dropped}}
>
>
>
> ------------------------------
>
> Message: 11
> Date: Fri, 22 Jun 2007 07:35:51 -0500
> From: Frank E Harrell Jr <f.harrell en vanderbilt.edu>
> Subject: Re: [R] help on the use of ldBand
> To: Tomas Goicoa <tomas.goicoa en unavarra.es>
> Cc: r-help en stat.math.ethz.ch
> Message-ID: <467BC227.8000701 en vanderbilt.edu>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
> Tomas Goicoa wrote:
> >   Hi R Users,
> >
> >   I am trying to use the ldBand package. Together
> > with the package, I have downloaded the ld98
> > program (version for windows) as indicated in the
> > help page on ldBand. I did it, but obtained an
> > error message "Error in (head + 1):length(w) :
> > Argument NA/NaN" when I copied the help examples,
> > so it seems that a conection between R and ld98
> > is not well performed in my computer.  Did I put
> > ld98.exe in the wrong place? If so,  where should
> > I put it? Thanks a lot in advance,
> >
> >
> >   Berta Iba?ez Beroiz
>
> Do you mean the Hmisc package?  Do you mean the ldBands function?  Did
> you put ld98.exe in a place that is in your system path as specified in
> the ldBands help file?  And please read the posting guide referenced below.
>
> Frank
>
> >
> > ______________________________________________
> > R-help en stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
> --
> Frank E Harrell Jr   Professor and Chair           School of Medicine
>                      Department of Biostatistics   Vanderbilt University
>
>
>
> ------------------------------
>
> Message: 12
> Date: Fri, 22 Jun 2007 13:27:35 +0200
> From: "ONKELINX, Thierry" <Thierry.ONKELINX en inbo.be>
> Subject: Re: [R] multiple return
> To: <amicogodzilla en bruttocarattere.org>, <r-help en stat.math.ethz.ch>
> Message-ID:
>        <2E9C414912813E4EB981326983E0A104031A9629 en inboexch.inbo.be>
> Content-Type: text/plain;       charset="us-ascii"
>
> Put the return values in a vector or list
>
> somma <- function (a, b) {
>   c <- a+b
>   return (c(a = a, b = b, c = c))
> }
>
> somma(5,7)
>  a  b  c
>  5  7 12
>
>
> somma <- function (a, b) {
>   c <- a+b
>   return (list(a = a, b = b, c = c))
> }
>
> somma(5,7)
> $a
> [1] 5
>
> $b
> [1] 7
>
> $c
> [1] 12
>
> Cheers,
>
> Thierry
> ------------------------------------------------------------------------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
> methodology and quality assurance
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
> tel. + 32 54/436 185
> Thierry.Onkelinx en inbo.be
> www.inbo.be
>
> Do not put your faith in what statistics say until you have carefully
> considered what they do not say.  ~William W. Watt
> A statistical analysis, properly conducted, is a delicate dissection of
> uncertainties, a surgery of suppositions. ~M.J.Moroney
>
>
>
> > -----Oorspronkelijk bericht-----
> > Van: r-help-bounces en stat.math.ethz.ch
> > [mailto:r-help-bounces en stat.math.ethz.ch] Namens Manuele Pesenti
> > Verzonden: vrijdag 22 juni 2007 12:38
> > Aan: r-help en stat.math.ethz.ch
> > Onderwerp: [R] multiple return
> >
> > Dear User,
> > what's the correct way to obtain a multiple return from a function?
> >
> > for example creating the simple function:
> >
> > somma <- function (a, b) {
> >   c <- a+b
> >   return (a, b, c)
> > }
> >
> > when I call it, it runs but returns the following output:
> >
> > > somma(5, 7)
> > $a
> > [1] 5
> >
> > $b
> > [1] 7
> >
> > $c
> > [1] 12
> >
> > Warning message:
> > return multi-argomento sono deprecati in: return(a, b, c)
> >
> > i.e. multi-return is deprecated...
> >
> > thanks a lot
> > best regards
> >       Manuele
> >
> > --
> > Manuele Pesenti
> >       manuele en inventati.org
> >       amicogodzilla en jabber.linux.it
> >       http://mpesenti.polito.it
> >
> > ______________________________________________
> > R-help en stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
>
> ------------------------------
>
> Message: 13
> Date: Fri, 22 Jun 2007 06:20:27 -0700
> From: Martin Morgan <mtmorgan en fhcrc.org>
> Subject: Re: [R] extract index during execution of sapply
> To: Christian Bieli <christian.bieli en unibas.ch>
> Cc: R help list <r-help en stat.math.ethz.ch>
> Message-ID: <6phodj85dno.fsf en gopher4.fhcrc.org>
> Content-Type: text/plain; charset=us-ascii
>
> Christian,
>
> A favorite of mine is to use lexical scope and a 'factory' model:
>
> > fun_factory <- function() {
> +     i <- 0                  # 'state' variable(s), unique to each fun_factory
> +     function(x) {           # fun_factory return value; used as sapply FUN
> +         i <<- i + 1         # <<- assignment finds i
> +         x^i                 # return value of sapply FUN
> +     }
> + }
> >
> > sapply(1:10, fun_factory())
>  [1]           1           4          27         256        3125       46656
>  [7]      823543    16777216   387420489 10000000000
>
>
> Christian Bieli <christian.bieli en unibas.ch> writes:
>
> > Hi there
> > During execution of sapply I want to extract the number of times the
> > function given to supply has been executed. I came up with:
> >
> > mylist <- list(a=3,b=6,c=9)
> > sapply(mylist,function(x)as.numeric(gsub("[^0-9]","",deparse(substitute(x)))))
> >
> > This works fine, but looks quite ugly. I'm sure that there's a more
> > elegant way to do this.
> >
> > Any suggestion?
> >
> > Christian
> >
> > ______________________________________________
> > R-help en stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Martin Morgan
> Bioconductor / Computational Biology
> http://bioconductor.org
>
>
>
> ------------------------------
>
> Message: 14
> Date: Fri, 22 Jun 2007 14:28:07 +0100
> From: Robin Hankin <r.hankin en noc.soton.ac.uk>
> Subject: [R] vectorize a function
> To: RHelp help <r-help en stat.math.ethz.ch>
> Message-ID: <F77DEE3F-E5AA-4A9B-A722-18F7DA006F46 en noc.soton.ac.uk>
> Content-Type: text/plain; charset=US-ASCII; format=flowed
>
> Hello everyone
>
> suppose I have an integer vector "a" of length "n" and
> a symmetric matrix "M" of size n-by-n.
>
> Vector "a" describes a partition of a set of "n" elements
> and matrix M describes a penalty function: row i column
> j represents the penalty if element i and element j
> are in the same partition.
>
> Toy example follows; the real case is much larger
> and I need to evaluate my penalty function many times.
>
> If a <- c(1,1,2,1,3)  then elements 1,2,4 are in the
> same partition; element 3 is in a partition on its own
> and element 5 is in a partition on its own.
>
> The total penalty  can be described by the following (ugly)
> function:
>
> f <- function(a,M){
>   out <- 0
>   for(i in unique(a)){
>     out <- out + sum(M[which(a==i),which(a==i)])
>   }
>   return(out)
> }
>
>
> so with
>
> M <- matrix(rpois(25,3),5,5)
> M <- M+t(M)
> diag(M) <- 0
> a <- c(1,2,1,1,3)
>
> f(a,M) gives the total penalty.
>
>
> QUESTION:  how to rewrite f() so that it has no loop?
>
>
>
>
>
>
> --
> Robin Hankin
> Uncertainty Analyst
> National Oceanography Centre, Southampton
> European Way, Southampton SO14 3ZH, UK
>  tel  023-8059-7743
>
>
>
> ------------------------------
>
> Message: 15
> Date: Fri, 22 Jun 2007 09:56:20 -0400
> From: "Kevin E. Thorpe" <kevin.thorpe en utoronto.ca>
> Subject: Re: [R] Tools For Preparing Data For Analysis
> To: r-help en stat.math.ethz.ch
> Message-ID: <467BD504.4040705 en utoronto.ca>
> Content-Type: text/plain; charset=ISO-8859-1
>
> I am posting to this thread that has been quiet for some time because I
> remembered the following question.
>
> Christophe Pallier wrote:
> > Hi,
> >
> > Can you provide examples of data formats that are problematic to read and
> > clean with R ?
>
> Today I had a data manipulation problem that I don't know how to do in R
> so I solved it with perl.  Since I'm always interested in learning more
> about complex data manipulation in R I am posting my problem in the
> hopes of receiving some hints for doing this in R.
>
> If anyone has nothing better to do than play with other people's data,
> I would be happy to send the row files off-list.
>
> Background:
>
> I have been given data that contains two measurements of left
> ventricular ejection fraction.  One of the methods is echocardiogram
> which sometimes gives a true quantitative value and other times a
> semi-quantitative value.  The desire is to compare echo with the
> other method (MUGA).  In most cases, patients had either quantitative
> or semi-quantitative.  Same patients had both.  The data came
> to me in excel files with, basically, no patient identifiers to link
> the "both" with the semi-quantitative patients (the "both" patients
> were in multiple data sets).
>
> What I wanted to do was extract from the semi-quantitative data file
> those patients with only semi-quantitative.  All I have to link with
> are the semi-quantitative echo and the MUGA and these pairs of values
> are not unique.
>
> To make this more concrete, here are some portions of the raw data.
>
> "Both"
>
> "ID NUM","ECHO","MUGA","Semiquant","Quant"
> "B",12,37,10,12
> "D",13,13,10,13
> "E",13,26,10,15
> "F",13,31,10,13
> "H",15,15,10,15
> "I",15,21,10,15
> "J",15,22,10,15
> "K",17,22,10,17
> "N",17.5,4,10,17.5
> "P",18,25,10,18
> "R",19,25,10,19
>
> Seimi-quantitative
>
> "echo","muga","quant"
> 10,20,0      <-- keep
> 10,20,0      <-- keep
> 10,21,0      <-- remove
> 10,21,0      <-- keep
> 10,24,0      <-- keep
> 10,25,0      <-- remove
> 10,25,0      <-- remove
> 10,25,0      <-- keep
>
> Here is the perl program I wrote for this.
>
> #!/usr/bin/perl
>
> open(BOTH, "quant_qual_echo.csv") || die "Can't open quant_qual_echo.csv";
> # Discard first row;
> $_ = <BOTH>;
> while(<BOTH>) {
>    chomp;
>    ($id, $e, $m, $sq, $qu) = split(/,/);
>    $both{$sq,$m}++;
> }
> close(BOTH);
>
> open(OUT, "> qual_echo_only.csv") || die "Can't open qual_echo_only.csv";
> print OUT "pid,echo,muga,quant\n";
> $pid = 2001;
>
> open(QUAL, "qual_echo.csv") || die "Can't open qual_echo.csv";
> # Discard first row
> $_ = <QUAL>;
> while(<QUAL>) {
>    chomp;
>    ($echo, $muga, $quant) = split(/,/);
>    if ($both{$echo,$muga} > 0) {
>        $both{$echo,$muga}--;
>    }
>    else {
>        print OUT "$pid,$echo,$muga,$quant\n";
>        $pid++;
>    }
> }
> close(QUAL);
> close(OUT);
>
> open(OUT, "> both_echo.csv") || die "Can't open both_echo.csv";
> print OUT "pid,echo,muga,quant\n";
> $pid = 3001;
>
> open(BOTH, "quant_qual_echo.csv") || die "Can't open quant_qual_echo.csv";
> # Discard first row;
> $_ = <BOTH>;
> while(<BOTH>) {
>    chomp;
>    ($id, $e, $m, $sq, $qu) = split(/,/);
>    print OUT "$pid,$sq,$m,0\n";
>    print OUT "$pid,$qu,$m,1\n";
>    $pid++;
> }
> close(BOTH);
> close(OUT);
>
>
> --
> Kevin E. Thorpe
> Biostatistician/Trialist, Knowledge Translation Program
> Assistant Professor, Department of Public Health Sciences
> Faculty of Medicine, University of Toronto
> email: kevin.thorpe en utoronto.ca  Tel: 416.864.5776  Fax: 416.864.6057
>
>
>
> ------------------------------
>
> Message: 16
> Date: Fri, 22 Jun 2007 09:58:39 -0400
> From: "Kuhn, Max" <Max.Kuhn en pfizer.com>
> Subject: Re: [R] Data consistency checks in functions
> To: "Anup Nandialath" <anup_nandialath en yahoo.com>,
>        <r-help en stat.math.ethz.ch>
> Message-ID:
>        <71257D09F114DA4A8E134DEAC70F25D308B9745C en groamrexm03.amer.pfizer.com>
> Content-Type: text/plain;       charset="us-ascii"
>
> Anup,
>
> There are two ways to pass arguments to functions in R: as named
> arguments or by position*.
>
> Users *can* supply arguments that are inconsistent with the order that
> you specify in the function definition, but only if they are used as
> named arguments:
>
>   myfun(X = someMatrix, values = aVector, theta = whatever)
>
> If the arguments are passed by position (as in myfun(beta, val1)), R
> will assume that the first argument is theta, the second is X, etc since
> that is how the function is defined.
>
> My suggestion would be to leave these arguments without defaults and put
> a lot of checks in the function (using is.matrix, is.vector and a few
> that check the content of the data I those objects).
>
>
> * You can also mix the two:
>
>   foo(data, outcome, start = rep(0, 3))
>
>
>
> Max
>
> -----Original Message-----
> From: r-help-bounces en stat.math.ethz.ch
> [mailto:r-help-bounces en stat.math.ethz.ch] On Behalf Of Anup Nandialath
> Sent: Friday, June 22, 2007 12:19 AM
> To: r-help en stat.math.ethz.ch
> Subject: [R] Data consistency checks in functions
>
> Dear friends,
>
> I'm writing a function with three arguments
>
> myfun <- function(theta, X, values)
>
> {
> ....
> ....
> }
>
> in this function, I'm trying to write consistency checks. In order to
> compute the statistic of interest I only need theta and values. The idea
> of having X in there is that, if values is not provided by the user,
> then values is computed from X.
>
> my problem is I'm trying to write consistency checks. For instance if i
> say
>
> output <- myfun(beta, val1), how do I ensure that R reads this as
> passing arguments to "theta" and "values". In other words is it possible
> to bypass X completely if values is provided. Also how is it possible
> for R to recognize the second argument as being values and not X. This
> is important because X is a matrix and values is a vector. Therefore any
> checks using the dimensions of either one will land in trouble if it
> does not correctly capture that.
>
> Thanks in advance
> Sincerely
>
> Anup
>
>
> ---------------------------------
>
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help en stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ----------------------------------------------------------------------
> LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}
>
>
>
> ------------------------------
>
> Message: 17
> Date: Fri, 22 Jun 2007 10:17:24 -0400
> From: "Christos Hatzis" <christos en nuverabio.com>
> Subject: Re: [R] vectorize a function
> To: "'Robin Hankin'" <r.hankin en noc.soton.ac.uk>,        "'RHelp help'"
>        <r-help en stat.math.ethz.ch>
> Message-ID:
>        <001b01c7b4d8$0e8129f0$0e010a0a en headquarters.silicoinsights>
> Content-Type: text/plain;       charset="us-ascii"
>
> How about:
>
> sum(sapply(unique(a), function(x) {b <- which(a==x); sum(M[b, b])}))
>
> HTH
> -Christos
>
> Christos Hatzis, Ph.D.
> Nuvera Biosciences, Inc.
> 400 West Cummings Park
> Suite 5350
> Woburn, MA 01801
> Tel: 781-938-3830
> www.nuverabio.com
>
>
> > -----Original Message-----
> > From: r-help-bounces en stat.math.ethz.ch
> > [mailto:r-help-bounces en stat.math.ethz.ch] On Behalf Of Robin Hankin
> > Sent: Friday, June 22, 2007 9:28 AM
> > To: RHelp help
> > Subject: [R] vectorize a function
> >
> > Hello everyone
> >
> > suppose I have an integer vector "a" of length "n" and a
> > symmetric matrix "M" of size n-by-n.
> >
> > Vector "a" describes a partition of a set of "n" elements and
> > matrix M describes a penalty function: row i column j
> > represents the penalty if element i and element j are in the
> > same partition.
> >
> > Toy example follows; the real case is much larger and I need
> > to evaluate my penalty function many times.
> >
> > If a <- c(1,1,2,1,3)  then elements 1,2,4 are in the same
> > partition; element 3 is in a partition on its own and element
> > 5 is in a partition on its own.
> >
> > The total penalty  can be described by the following (ugly)
> > function:
> >
> > f <- function(a,M){
> >    out <- 0
> >    for(i in unique(a)){
> >      out <- out + sum(M[which(a==i),which(a==i)])
> >    }
> >    return(out)
> > }
> >
> >
> > so with
> >
> > M <- matrix(rpois(25,3),5,5)
> > M <- M+t(M)
> > diag(M) <- 0
> > a <- c(1,2,1,1,3)
> >
> > f(a,M) gives the total penalty.
> >
> >
> > QUESTION:  how to rewrite f() so that it has no loop?
> >
> >
> >
> >
> >
> >
> > --
> > Robin Hankin
> > Uncertainty Analyst
> > National Oceanography Centre, Southampton European Way,
> > Southampton SO14 3ZH, UK
> >   tel  023-8059-7743
> >
> > ______________________________________________
> > R-help en stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
>
>
> ------------------------------
>
> Message: 18
> Date: Fri, 22 Jun 2007 13:23:08 +0000 (UTC)
> From: Ben Bolker <bolker en ufl.edu>
> Subject: Re: [R] extract index during execution of sapply
> To: r-help en stat.math.ethz.ch
> Message-ID: <loom.20070622T151700-639 en post.gmane.org>
> Content-Type: text/plain; charset=us-ascii
>
> Christian Bieli <christian.bieli <at> unibas.ch> writes:
>
> >
> > Hi there
> > During execution of sapply I want to extract the number of times the
> > function given to supply has been executed. I came up with:
> >
> > mylist <- list(a=3,b=6,c=9)
> > sapply(mylist,function(x)as.numeric(gsub("[^0-9]","",deparse(substitute(x)))))
> >
> > This works fine, but looks quite ugly. I'm sure that there's a more
> > elegant way to do this.
> >
> > Any suggestion?
> >
> > Christian
> >
>
>   I would love to have an answer to this -- when I run
> into this kind of problem I usually end up using mapply:
> e.g., suppose I have
>
> mylist <- replicate(5,list(x=runif(10),y=runif(10)),simplify=FALSE)
>
> and I want to plot each element in a different color.  I'd like
> to be able to do
>
> plot(0:1,0:1,type="n")
> lapply(mylist,plot,col=i)
>
> but instead I do
>
> mapply(function(x,i) points(x,col=i),mylist,1:5)
>
> would it be too ugly to have a special variable called INDEX
> that could be used within an sapply/lapply statement?
>
>
>
> ------------------------------
>
> Message: 19
> Date: Fri, 22 Jun 2007 07:45:14 -0700 (PDT)
> From: Thomas Lumley <tlumley en u.washington.edu>
> Subject: Re: [R] extract index during execution of sapply
> To: Ben Bolker <bolker en ufl.edu>
> Cc: r-help en stat.math.ethz.ch
> Message-ID:
>        <Pine.LNX.4.64.0706220732470.20743 en homer22.u.washington.edu>
> Content-Type: TEXT/PLAIN; charset=US-ASCII; format=flowed
>
> On Fri, 22 Jun 2007, Ben Bolker wrote:
>
> > Christian Bieli <christian.bieli <at> unibas.ch> writes:
> >
> >>
> >> Hi there
> >> During execution of sapply I want to extract the number of times the
> >> function given to supply has been executed. I came up with:
> >>
> >> mylist <- list(a=3,b=6,c=9)
> >> sapply(mylist,function(x)as.numeric(gsub("[^0-9]","",deparse(substitute(x)))))
> >>
> >> This works fine, but looks quite ugly. I'm sure that there's a more
> >> elegant way to do this.
> >>
> >> Any suggestion?
> >>
> >> Christian
> >>
> >
> >   I would love to have an answer to this -- when I run
> > into this kind of problem I usually end up using mapply:
> > e.g., suppose I have
> >
> > mylist <- replicate(5,list(x=runif(10),y=runif(10)),simplify=FALSE)
> >
> > and I want to plot each element in a different color.  I'd like
> > to be able to do
> >
> > plot(0:1,0:1,type="n")
> > lapply(mylist,plot,col=i)
> >
> > but instead I do
> >
> > mapply(function(x,i) points(x,col=i),mylist,1:5)
> >
> > would it be too ugly to have a special variable called INDEX
> > that could be used within an sapply/lapply statement?
> >
>
> There are two distinct suggestions here: a variable that says *how many*
> times the function has been called, and a variable that say *which
> element* is currently being operated on.   The first seems undesirable as
> order of evaluation really should not matter in the apply functions.
>
> The second makes more sense but is still a little tricky. AFAICS there is
> no way for lapply() to find out whether FUN will accept an argument INDEX
> without an "unused argument(s)" error, so it can't just be passed as an
> argument.  This suggests having yet another apply function, that would
> assume an INDEX argument and might be written
>   yapply<-function(X,FUN, ...) {
>        index<-seq(length.out=length(X))
>         mapply(FUN,X,INDEX=index,MoreArgs=list(...))
>        }
>
> However, I think it would be preferable in many cases for INDEX to be
> names(X) if it exists, rather than 1:n.  In any case, it is easy  to write
> the function.
>
>        -thomas
>
>
>
> ------------------------------
>
> Message: 20
> Date: Fri, 22 Jun 2007 10:49:08 -0400
> From: "Oden, Kevin" <kevin.oden en wachovia.com>
> Subject: [R] fitCopula
> To: <r-help en stat.math.ethz.ch>
> Message-ID:
>        <E3A68C90920A014CBB128279519B1B35042FEB87 en M1WACA0030I001.cibna.msds.wachovia.net>
>
> Content-Type: text/plain
>
> I  am using R 2.5.0 on windows XP and trying to fit copula.  I see the
> following code works for some users, however my code crashes on the
> chol.   Any suggestions?
>
>
>
> >  mycop <- tCopula(param=0.5, dim=8, dispstr="ex", df=5)
>
> >  x <- rcopula(mycop, 1000)
>
> >  myfit <- fitCopula(x, mycop, c(0.6, 10), optim.control=list(trace=1),
> method="Nelder-Mead")
>
>  Nelder-Mead direct search function minimizer
>
> function value for initial parameters = -1747.582044
>
>  Scaled convergence tolerance is 2.6041e-05
>
> Stepsize computed as 1.000000
>
> Error in chol(x, pivot = FALSE) : the leading minor of order 2 is not
> positive definite
>
>
>
> Kevin D. Oden
>
> e: kevin.oden en wachovia.com <mailto:kevin.oden en wachovia.com>
>
>
>
>
>        [[alternative HTML version deleted]]
>
>
>
> ------------------------------
>
> Message: 21
> Date: Fri, 22 Jun 2007 10:58:35 -0400
> From: "Weiwei Shi" <helprhelp en gmail.com>
> Subject: [R] how to ave this?
> To: "R Help" <R-help en stat.math.ethz.ch>
> Message-ID:
>        <cdf817830706220758r10e93178x971a53e574e9488d en mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
> Hi,
>
> I have a list that looks like this:
> [[1]]
>             fc          tt
> 50   0.07526882 0.000000000
> 100  0.09289617 0.000000000
> 150  0.12359551 0.000000000
>
> [[2]]
>             fc          tt
> 50   0.02040816 0.000000000
> 100  0.03626943 0.005025126
> 150  0.05263158 0.010101010
>
> and I am wondering how to "average" it so that I have one matrix t0 at
> the end, and t0[1,1] = (0.075..+0.0204..)/2
>
> Thanks,
>
> --
> Weiwei Shi, Ph.D
> Research Scientist
> GeneGO, Inc.
>
> "Did you always know?"
> "No, I did not. But I believed..."
> ---Matrix III
>
>
>
> ------------------------------
>
> Message: 22
> Date: Fri, 22 Jun 2007 11:04:15 -0400
> From: "Oden, Kevin" <kevin.oden en wachovia.com>
> Subject: [R] fitCopula
> To: <r-help en stat.math.ethz.ch>
> Message-ID:
>        <E3A68C90920A014CBB128279519B1B35042FEB88 en M1WACA0030I001.cibna.msds.wachovia.net>
>
> Content-Type: text/plain
>
>  I  am using R 2.5.0 on windows XP and trying to fit copula.  I see the
> following code works for some users, however my code crashes on the
> chol.   Any suggestions?
>
>
>
> >  mycop <- tCopula(param=0.5, dim=8, dispstr="ex", df=5)
>
> >  x <- rcopula(mycop, 1000)
>
> >  myfit <- fitCopula(x, mycop, c(0.6, 10), optim.control=list(trace=1),
> method="Nelder-Mead")
>
>  Nelder-Mead direct search function minimizer
>
> function value for initial parameters = -1747.582044
>
>  Scaled convergence tolerance is 2.6041e-05
>
> Stepsize computed as 1.000000
>
> Error in chol(x, pivot = FALSE) : the leading minor of order 2 is not
> positive definite
>
>
>
> Kevin D. Oden
>
> e: kevin.oden en wachovia.com <mailto:kevin.oden en wachovia.com>
>
>
>
>
>        [[alternative HTML version deleted]]
>
>
>
> ------------------------------
>
> Message: 23
> Date: Fri, 22 Jun 2007 11:20:19 -0400
> From: "Weiwei Shi" <helprhelp en gmail.com>
> Subject: Re: [R] how to ave this?
> To: "R Help" <R-help en stat.math.ethz.ch>
> Message-ID:
>        <cdf817830706220820k7db2f82dv3e2a2e7d7a39ff69 en mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
> one of my approaches is:
>
> x0 = sapply(mylist, cbind)
>
> and manipulate from x0 (x0[1:nrow(x0)/2, ] correponds to fc and the
> lower part is tt.
>
> but it is not neat way.
>
>
> On 6/22/07, Weiwei Shi <helprhelp en gmail.com> wrote:
> > Hi,
> >
> > I have a list that looks like this:
> > [[1]]
> >              fc          tt
> > 50   0.07526882 0.000000000
> > 100  0.09289617 0.000000000
> > 150  0.12359551 0.000000000
> >
> > [[2]]
> >              fc          tt
> > 50   0.02040816 0.000000000
> > 100  0.03626943 0.005025126
> > 150  0.05263158 0.010101010
> >
> > and I am wondering how to "average" it so that I have one matrix t0 at
> > the end, and t0[1,1] = (0.075..+0.0204..)/2
> >
> > Thanks,
> >
> > --
> > Weiwei Shi, Ph.D
> > Research Scientist
> > GeneGO, Inc.
> >
> > "Did you always know?"
> > "No, I did not. But I believed..."
> > ---Matrix III
> >
>
>
> --
> Weiwei Shi, Ph.D
> Research Scientist
> GeneGO, Inc.
>
> "Did you always know?"
> "No, I did not. But I believed..."
> ---Matrix III
>
>
>
> ------------------------------
>
> Message: 24
> Date: Fri, 22 Jun 2007 16:26:57 +0100 (BST)
> From: Prof Brian Ripley <ripley en stats.ox.ac.uk>
> Subject: Re: [R] Result depends on order of factors in unbalanced
>        designs (lme, anova)?
> To: Karl Knoblick <karlknoblich en yahoo.de>
> Cc: r-help en stat.math.ethz.ch
> Message-ID: <Pine.LNX.4.64.0706221617190.11817 en gannet.stats.ox.ac.uk>
> Content-Type: TEXT/PLAIN; charset=US-ASCII; format=flowed
>
> 'anova' is rather a misnomer here.  In terms of the description in
> ?anova.lme, you have
>
>      When only one fitted model object is present, a data frame with
>      the sums of squares, numerator degrees of freedom, denominator
>      degrees of freedom, F-values, and P-values for Wald tests for the
>      terms in the model ...
>
> but there are no 'sums of squares' shown.  However, the crucial part of
> that help page is
>
>     type: an optional character string specifying the type of sum of
>           squares to be used in F-tests for the terms in the model. If
>           '"sequential"', the sequential sum of squares obtained by
>           including the terms in the order they appear in the model is
>           used; else, if '"marginal"', the marginal sum of squares
>           obtained by deleting a term from the model at a time is used.
>           This argument is only used when a single fitted object is
>           passed to the function. Partial matching of arguments is
>           used, so only the first character needs to be provided.
>           Defaults to '"sequential"'.
>
> so these are sequential fits (just like anova for an lm fit), and yes,
> sequential fits do in general depend on the sequence of terms.
>
> The issues of interpretation are exactly those of unbalanced linear
> models, and you will find advice on that in many places, e.g. in MASS.
>
>
> On Thu, 21 Jun 2007, Karl Knoblick wrote:
>
> > Dear R-Community!
> >
> > For example I have a study with 4 treatment groups (10 subjects per group) and 4 visits. Additionally, the gender is taken into account. I think - and hope this is a goog idea (!) - this data can be analysed using lme as below.
> >
> > In a balanced design everything is fine, but in an unbalanced design there are differences depending on fitting y~visit*treat*gender or y~gender*visit*treat - at least with anova (see example). Does this make sense? Which ordering might be the correct one?
> >
> > Here the example script:
> > library(nlme)
> > set.seed(123)
> > # Random generation of data:
> > NSubj<-40 # No. of subjects
> > set.seed(1234)
> > id<-factor(rep(c(1:NSubj),4)) # ID of subjects
> > treat<-factor(rep(rep(1:4,each=5),4)) # Treatment 4 Levels
> > gender<-factor(rep(rep(1:2, each=20),4))
> > visit<-factor(rep(1:4, each=NSubj))
> > y<-runif(4*NSubj) # Results
> > # Add effects
> > y<-y+0.01*as.integer(visit)
> > y<-y+0.02*as.integer(gender)
> > y<-y+0.024*as.integer(treat)
> > df<-data.frame(id, treat, gender, visit, y)
> > # groupedData object for lme
> > gdat<-groupedData(y ~ visit|id, data=df)
> > # fits - different ordering of factors
> > fit1<-lme(y ~ visit*treat*gender, data=gdat, random = ~visit|id)
> > anova(fit1)
> > fit2<-lme(y ~ gender*treat*visit, data=gdat, random = ~visit|id)
> > anova(fit2)
> > # Result: identical (balanced design so far), ok
> > # Now change gender of subject 1
> > gdat$gender[c(1,41,81,121)]<-2
> > # onece more fits with different ordering of factors
> > fit1<-lme(y ~ visit*treat*gender, data=gdat, random = ~visit|id)
> > anova(fit1)
> > fit2<-lme(y ~ gender*treat*visit, data=gdat, random = ~visit|id)
> > anova(fit2)
> > # Result: There are differences!!
> >
> > Hope anybody can help or give me advice how to interpret these results correctly or how to avoid this problem! Is there a better possibility to analyse these data than lme?
> >
> > Thanks!
> > Karl
>
> --
> Brian D. Ripley,                  ripley en stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>
>
> ------------------------------
>
> Message: 25
> Date: Fri, 22 Jun 2007 17:27:42 +0200
> From: "Christophe Pallier" <christophe en pallier.org>
> Subject: Re: [R] Tools For Preparing Data For Analysis
> To: "Kevin E. Thorpe" <kevin.thorpe en utoronto.ca>
> Cc: r-help en stat.math.ethz.ch
> Message-ID:
>        <dea6cb960706220827y4c281c31t493106eeaffedd4b en mail.gmail.com>
> Content-Type: text/plain
>
> If I understand correctly (from your Perl script)
>
> 1. you count the number of occurences of each "(echo, muga)" pairs in the
> first file.
>
> 2. you remove from the second file the lines that correspond to these
> occurences.
>
> If this is indeed your aim, here's a solution in R:
>
> cumcount <- function(x) {
>  y <- numeric(length(x))
>  for (i in 1:length(y)) {
>     y[i] = sum(x[1:i] == x[i])
>  }
>  y
> }
>
> both <- read.csv('both_echo.csv')
> v <- table(paste(both$echo, "_", both$muga, sep=""))
>
> semi <- read.csv('qual_echo.csv')
> s <- paste(semi$echo, "_", semi$muga, sep="")
> cs = cumcount(s)
> count = v[s]
> count[is.na(count)]=0
>
> semi2 <- data.frame(semi, s, cs, count, keep = cs > count)
>
> > semi2
>  echo muga quant     s cs count  keep
> 1   10   20     0 10_20  1     0  TRUE
> 2   10   20     0 10_20  2     0  TRUE
> 3   10   21     0 10_21  1     1 FALSE
> 4   10   21     0 10_21  2     1  TRUE
> 5   10   24     0 10_24  1     0  TRUE
> 6   10   25     0 10_25  1     2 FALSE
> 7   10   25     0 10_25  2     2 FALSE
> 8   10   25     0 10_25  3     2  TRUE
>
>
> My code is not very readable...
> Yet, the 'trick' of using an helper function like 'cumcount' might be
> instructive.
>
> Christophe Pallier
>
>
> On 6/22/07, Kevin E. Thorpe <kevin.thorpe en utoronto.ca> wrote:
> >
> > I am posting to this thread that has been quiet for some time because I
> > remembered the following question.
> >
> > Christophe Pallier wrote:
> > > Hi,
> > >
> > > Can you provide examples of data formats that are problematic to read
> > and
> > > clean with R ?
> >
> > Today I had a data manipulation problem that I don't know how to do in R
> > so I solved it with perl.  Since I'm always interested in learning more
> > about complex data manipulation in R I am posting my problem in the
> > hopes of receiving some hints for doing this in R.
> >
> > If anyone has nothing better to do than play with other people's data,
> > I would be happy to send the row files off-list.
> >
> > Background:
> >
> > I have been given data that contains two measurements of left
> > ventricular ejection fraction.  One of the methods is echocardiogram
> > which sometimes gives a true quantitative value and other times a
> > semi-quantitative value.  The desire is to compare echo with the
> > other method (MUGA).  In most cases, patients had either quantitative
> > or semi-quantitative.  Same patients had both.  The data came
> > to me in excel files with, basically, no patient identifiers to link
> > the "both" with the semi-quantitative patients (the "both" patients
> > were in multiple data sets).
> >
> > What I wanted to do was extract from the semi-quantitative data file
> > those patients with only semi-quantitative.  All I have to link with
> > are the semi-quantitative echo and the MUGA and these pairs of values
> > are not unique.
> >
> > To make this more concrete, here are some portions of the raw data.
> >
> > "Both"
> >
> > "ID NUM","ECHO","MUGA","Semiquant","Quant"
> > "B",12,37,10,12
> > "D",13,13,10,13
> > "E",13,26,10,15
> > "F",13,31,10,13
> > "H",15,15,10,15
> > "I",15,21,10,15
> > "J",15,22,10,15
> > "K",17,22,10,17
> > "N",17.5,4,10,17.5
> > "P",18,25,10,18
> > "R",19,25,10,19
> >
> > Seimi-quantitative
> >
> > "echo","muga","quant"
> > 10,20,0      <-- keep
> > 10,20,0      <-- keep
> > 10,21,0      <-- remove
> > 10,21,0      <-- keep
> > 10,24,0      <-- keep
> > 10,25,0      <-- remove
> > 10,25,0      <-- remove
> > 10,25,0      <-- keep
> >
> > Here is the perl program I wrote for this.
> >
> > #!/usr/bin/perl
> >
> > open(BOTH, "quant_qual_echo.csv") || die "Can't open quant_qual_echo.csv";
> > # Discard first row;
> > $_ = <BOTH>;
> > while(<BOTH>) {
> >     chomp;
> >     ($id, $e, $m, $sq, $qu) = split(/,/);
> >     $both{$sq,$m}++;
> > }
> > close(BOTH);
> >
> > open(OUT, "> qual_echo_only.csv") || die "Can't open qual_echo_only.csv";
> > print OUT "pid,echo,muga,quant\n";
> > $pid = 2001;
> >
> > open(QUAL, "qual_echo.csv") || die "Can't open qual_echo.csv";
> > # Discard first row
> > $_ = <QUAL>;
> > while(<QUAL>) {
> >     chomp;
> >     ($echo, $muga, $quant) = split(/,/);
> >     if ($both{$echo,$muga} > 0) {
> >         $both{$echo,$muga}--;
> >     }
> >     else {
> >         print OUT "$pid,$echo,$muga,$quant\n";
> >         $pid++;
> >     }
> > }
> > close(QUAL);
> > close(OUT);
> >
> > open(OUT, "> both_echo.csv") || die "Can't open both_echo.csv";
> > print OUT "pid,echo,muga,quant\n";
> > $pid = 3001;
> >
> > open(BOTH, "quant_qual_echo.csv") || die "Can't open quant_qual_echo.csv";
> > # Discard first row;
> > $_ = <BOTH>;
> > while(<BOTH>) {
> >     chomp;
> >     ($id, $e, $m, $sq, $qu) = split(/,/);
> >     print OUT "$pid,$sq,$m,0\n";
> >     print OUT "$pid,$qu,$m,1\n";
> >     $pid++;
> > }
> > close(BOTH);
> > close(OUT);
> >
> >
> > --
> > Kevin E. Thorpe
> > Biostatistician/Trialist, Knowledge Translation Program
> > Assistant Professor, Department of Public Health Sciences
> > Faculty of Medicine, University of Toronto
> > email: kevin.thorpe en utoronto.ca  Tel: 416.864.5776  Fax: 416.864.6057
> >
> > ______________________________________________
> > R-help en stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
>
> --
> Christophe Pallier (http://www.pallier.org)
>
>        [[alternative HTML version deleted]]
>
>
>
> ------------------------------
>
> Message: 26
> Date: Fri, 22 Jun 2007 16:30:44 +0100
> From: Simon Wood <s.wood en bath.ac.uk>
> Subject: Re: [R] interpretation of F-statistics in GAMs
> To: r-help en stat.math.ethz.ch
> Message-ID: <200706221630.44317.s.wood en bath.ac.uk>
> Content-Type: text/plain;  charset="iso-8859-1"
>
> On Friday 15 June 2007 08:06, robert.ptacnik en niva.no wrote:
> > dear listers,
> > I use gam (from mgcv) for evaluation of shape and strength of relationships
> > between a response variable and several predictors.
> > How can I interpret the 'F' values viven in the GAM summary? Is it
> > appropriate to treat them in a similar manner as the T-statistics in a
> > linear model, i.e. larger values mean that this variable has a stronger
> > impact than a variable with smaller F?
> - I'd be a bit cautious about this (even for T-statistics and linear models
> it's not quite clear to me what `impact' means if judged this way). These gam
> F statistics are only meant to provide a rough and ready means of judging
> approximate significance of terms, and I'm unsure about interpreting a
> comparison of such F ratios: for example the F statistics can be based on
> differerent numbers of degrees of freedom, depending on the term concerned...
>
> > When I run my analysis for two different response varables (but identical
> > predictors), is there a way to compare the F values among tests (like to
> > standardize them by teh sum of F within each test?) I append two summaries
> > below.
> - Again, I don't really known how this would work. I'd be more inclined to
> compare the plotted terms and associated CIs (and maybe the p-values),
> especially if you are using GAMs in a quite exploratory way (e.g. if the
> assumption of an additive structure is really a convenience, rather than
> being something that is suggested by the underlying science).
>
> best,
> Simon
>
> >
> >
> > ### example 1 ###
> >
> > Family: gaussian
> > Link function: identity
> >
> > Formula:
> > dep[sel, i] ~ s(date, k = 3) + s(depth, k = kn) + s(temp, k = kn) +
> >     s(light, k = kn) + s(PO4, k = kn) + s(DIN, k = kn) + s(prop.agpla,
> >     k = kn)
> >
> > Parametric coefficients:
> >             Estimate Std. Error t value Pr(>|t|)
> > (Intercept)   5.1048     0.0384   132.9   <2e-16 ***
> > ---
> > Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> >
> > Approximate significance of smooth terms:
> >                 edf Est.rank      F  p-value
> > s(date)       1.669        2 12.161 1.07e-05 ***
> > s(depth)      1.671        2 36.125 4.85e-14 ***
> > s(temp)       1.927        2  6.686  0.00156 **
> > s(light)      1.886        2 12.604 7.20e-06 ***
> > s(PO4)        1.676        2  3.237  0.04143 *
> > s(DIN)        1.000        1 38.428 3.41e-09 ***
> > s(prop.agpla) 1.405        2 15.987 3.79e-07 ***
> > ---
> > Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> >
> > R-sq.(adj) =  0.687   Deviance explained = 70.5%
> > GCV score = 0.31995   Scale est. = 0.30076   n = 204
> >
> > ### example 2 ###
> > Family: gaussian
> > Link function: identity
> >
> > Formula:
> > dep[sel, i] ~ s(date, k = 3) + s(depth, k = kn) + s(temp, k = kn) +
> >     s(light, k = kn) + s(PO4, k = kn) + s(DIN, k = kn) + s(prop.agpla,
> >     k = kn)
> >
> > Parametric coefficients:
> >             Estimate Std. Error t value Pr(>|t|)
> > (Intercept)  7.13588    0.05549   128.6   <2e-16 ***
> > ---
> > Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> >
> > Approximate significance of smooth terms:
> >                 edf Est.rank      F  p-value
> > s(date)       1.944        2 15.997 3.67e-07 ***
> > s(depth)      1.876        2 25.427 1.52e-10 ***
> > s(temp)       1.000        1  2.866   0.0921 .
> > s(light)      1.751        2  4.212   0.0162 *
> > s(PO4)        1.950        2 10.632 4.14e-05 ***
> > s(DIN)        1.805        2 10.745 3.73e-05 ***
> > s(prop.agpla) 1.715        2  2.674   0.0715 .
> > ---
> > Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> >
> >  R-sq.(adj) =  0.479   Deviance explained = 50.9%
> > GCV score = 0.6863   Scale est. = 0.64348   n = 209
> >
> > ______________________________________________
> > R-help en stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html and provide commented, minimal,
> > self-contained, reproducible code.
>
> --
> > Simon Wood, Mathematical Sciences, University of Bath, Bath, BA2 7AY UK
> > +44 1225 386603  www.maths.bath.ac.uk/~sw283
>
>
>
> ------------------------------
>
> Message: 27
> Date: Fri, 22 Jun 2007 17:53:01 +0200
> From: Martin Maechler <maechler en stat.math.ethz.ch>
> Subject: Re: [R] Boxplot issues
> To: "S Ellison" <S.Ellison en lgc.co.uk>
> Cc: r-help en stat.math.ethz.ch
> Message-ID: <18043.61533.242252.779598 en stat.math.ethz.ch>
> Content-Type: text/plain; charset=us-ascii
>
> >>>>> "SE" == S Ellison <S.Ellison en lgc.co.uk>
> >>>>>     on Fri, 22 Jun 2007 13:02:20 +0100 writes:
>
>    SE> Boxplot and bxp seem to have changed behaviour a bit of late (R 2.4.1). Or maybe I am mis-remembering.
>    SE> An annoying feature is that while at=3:6 will work, there is no way of overriding the default xlim of 0.5 to n+0.5. That prevents plotting boxes on, for example, interval scales - a useful thing to do at times. I really can see no good reason for bxp to hard-core the xlim=c(0.5, n+0.5) in the function body; it should be a parameter default conditional on horizontal=, not hard coded.
>
>    SE> Also, boxplot does not drop empty groups. I'm sure it used to. I know it is good to be able to see where a factor level is unpopulated, but its a nuisance with fractional factorials and some nested or survey problems when many are known to be missing and are of no interest. Irrespective of whether my memory is correct, the option would be useful. How hard can it be to add a 'drop.empty=F' default to boxplot to allow it to switch?
>
>    SE> Obviously, these are things I can fix locally. But who 'owns' boxplot so I can provide suggested code to them for later releases?
>
>
> Legally speaking, I think that's a hard question the answer of
> which may even depend on the country where it is answered.
> I would like to say it is owned by the R Foundation.
>
> Suggested improvements of the R "base code" should be made and
> discussed on the R-devel mailing list. That's exactly the main
> purpose of that list.
> Such propositions typically make it into the code base
> if you are convincing and you provide code improvements that
> convince at least one member of R core that it's worth his time
> to implement, document, *and* test the changes.
>
> Also, as on R-help, it helps to work with small reproducible
> (ideally "cut-n-pastable") R code examples.
>
> Regards,
> Martin Maechler
>
>    SE> Steve Ellison
>
>
>
> ------------------------------
>
> Message: 28
> Date: Fri, 22 Jun 2007 12:19:35 -0400
> From: S?bastien <pomchip en free.fr>
> Subject: Re: [R] Overlaying lattice graphs (continued)
> To: Deepayan Sarkar <deepayan.sarkar en gmail.com>
> Cc: R-help <r-help en stat.math.ethz.ch>
> Message-ID: <467BF697.8050203 en free.fr>
> Content-Type: text/plain; charset=UTF-8; format=flowed
>
> Hi Deepayan,
>
> The following code creates a dummy dataset which has the same similar as
> my usual datasets. I did not try to implement the changes proposed by
> Hadley, hoping that a solution can be found using the original dataset.
>
> ######### My code
>
> # Creating dataset
>
> nPts<-10            # number of time points
> nInd<-6              # number of individuals
> nModel<-3         # number of models
>
> TimePts<-rep(1:nPts,nInd*nModel)                                    #
> creates the "Time" column
> Coef<-rep(rnorm(6,0.1,0.01),each=nPts,nModel)             # Creates a
> vector of coefficients for generating the observations
> Obs<-10*exp(-Coef*TimePts)                                         #
> creates the observations
>
> for (i in 1:60){
> Pred[i]<-jitter(10*exp(-Coef[i]*TimePts[i]))
> Pred[i+60]<-jitter(5)
> Pred[i+120]<-jitter(10-Coef[i+120]*TimePts[i])
> }
>                  # creates the predicted values
>
> colPlot<-rep(1,nPts*nInd*nModel)
>    # creates the "Plot" column
> colModel<-gl(nModel,nPts*nInd,labels=c("A","B","C"))             #
> creates the "Model" column
> colID<-gl(nInd,nPts,nPts*nInd*nModel)
>      # creates the "ID" column
>
> mydata<-data.frame(colPlot,colModel,colID,TimePts,Obs,Pred)
>              # creates the dataset
> names(mydata)<-c("Plot","Model","Individuals","Time","Observed","Predicted")
>
> # Plotting as indicated by Deepayan
>
> xyplot(Observed + Predicted ~ Time | Individuals + Model,
>      data = mydata,
>      panel = panel.superpose.2, type = c("p", "l"),
>      layout = c(0, nlevels(mydata$Individuals))) #,
>      #<...>)
>
> ####### End of code
>
> This codes is not exactly what I am looking for, although it is pretty
> close. In the present case, I would like to have a Trellis plot with 6
> panels (one for each individual), where the Observations and the
> Predicted are plotted as symbols and lines, respectively. All three
> models should be plotted on the same panel. Unfortunately, it looks to
> me as 3 successives xyplots are created by the code above but only the
> last one remains displayed. I tried to play with
> panel.superpose,panel.superpose.2 and type, without much success.
>
> I also tried the following code that creates 18 panels and distinguish
> all (Individuals,Model) couples... so, not what I want.
>
> xyplot(Observed + Predicted ~ Time | Individuals+Model, data = mydata,
>     type = c("p", "l"), distribute.type = TRUE)
>
> Sebastien
>
>
> Deepayan Sarkar a ?crit :
> > On 6/21/07, S?bastien <pomchip en free.fr> wrote:
> >> Hi Hadley,
> >>
> >> Hopefully, my dataset won't be too hard to changed. Can I modify the
> >> aspect of each group using your code (symbols for observed and lines for
> >> predicted)?
> >>
> >> Sebastien
> >>
> >> hadley wickham a ?crit :
> >> > Hi Sebastian,
> >> >
> >> > I think you need to rearrange your data a bit.  Firstly, you need to
> >> > put observed on the same footing as the different models, so you would
> >> > have a new column in your data called value (previously observed and
> >> > predicted) and a new model type ("observed").  Then you could do:
> >
> > Yes, and ?make.groups (and reshape of course) could help with that.
> > This might not be strictly necessary though.
> >
> > However, I'm finding your pseudo-code confusing. Could you create a
> > small example data set that can be used to try out some real code?
> > Just from your description, I would have suggested something like
> >
> > xyplot(Observed + Predicted ~ Time | Individuals + Model,
> >       data = mydata,
> >       panel = panel.superpose.2, type = c("p", "l"),
> >       layout = c(0, nlevels(mydata$Individuals)),
> >       <...>)
> >
> > If all you want is to plot one page at a time, there are easier ways
> > to do that.
> >
> > -Deepayan
> >
> >> >
> >> > xyplot(value ~ time | individauls, data=mydata, group=model)
> >> >
> >> > Hadley
> >> >
> >> >
> >> > On 6/21/07, S?bastien <pomchip en free.fr> wrote:
> >> >> Dear R Users,
> >> >>
> >> >> I recently posted an email on this list  about the use of
> >> data.frame and
> >> >> overlaying multiple plots. Deepayan kindly indicated to me the
> >> >> panel.superposition command which worked perfectly in the context
> >> of the
> >> >> example I gave.
> >> >> I'd like to go a little bit further on this topic using a more
> >> complex
> >> >> dataset structure (actually the one I want to work on).
> >> >>
> >> >>  >mydata
> >> >>       Plot    Model    Individuals    Time        Observed
> >> >> Predicted
> >> >> 1    1        A           1                  0.05
> >> >> 10                    10.2
> >> >> 2    1        A           1                  0.10
> >> >> 20                    19.5
> >> >> etc...
> >> >> 10  1        B           1                  0.05         10
> >> >>          9.8
> >> >> 11  1        B           1                  0.10         20
> >> >>          20.2
> >> >> etc...
> >> >>
> >> >> There are p "levels" in mydata$Plot, m in mydata$Model, n in
> >> >> mydata$Individuals and t in mydata$Time (Note that I probably use the
> >> >> word levels improperly as all columns are not factors). Basically,
> >> this
> >> >> dataset summarizes the t measurements obtained in n individuals as
> >> well
> >> >> as the predicted values from m different modeling approaches
> >> (applied to
> >> >> all individuals). Therefore, the observations are repeated m times in
> >> >> the Observed columns, while the predictions appears only once for a
> >> >> given model an a given individual.
> >> >>
> >> >> What I want to write is a R batch file creating a Trellis graph,
> >> where
> >> >> each panel corresponds to one individual and contains the
> >> observations
> >> >> (as scatterplot) plus the predicted values for all models (as
> >> lines of
> >> >> different colors)... $Plot is just a token: it might be used to not
> >> >> overload graphs in case there are too many tested models. The fun
> >> part
> >> >> is that the values of p, m, n and t might vary from one dataset to
> >> the
> >> >> other, so everything has to be coded dynamically.
> >> >>
> >> >> For the plotting part I was thinking about having a loop in my code
> >> >> containing something like that:
> >> >>
> >> >> for (i in 1:nlevels(mydata$Model)) {
> >> >>
> >> >> subdata<-subset(mydata,mydata$Model=level(mydata$Model)[i])
> >> >> xyplot(subset(Observed + Predicted ~ Time | Individuals, data =
> >> >> subdata)       #plus additionnal formatting code
> >> >>
> >> >> }
> >> >>
> >> >> Unfortunately, this code simply creates a new Trellis plot instead of
> >> >> adding the model one by one on the panels. Any idea or link to a
> >> useful
> >> >> command will wellcome.
> >> >>
> >> >> Sebastien
> >> >>
> >> >> ______________________________________________
> >> >> R-help en stat.math.ethz.ch mailing list
> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> PLEASE do read the posting guide
> >> >> http://www.R-project.org/posting-guide.html
> >> >> and provide commented, minimal, self-contained, reproducible code.
> >> >>
> >> >
> >> >
> >>
> >> ______________________________________________
> >> R-help en stat.math.ethz.ch mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
>
>
>
> ------------------------------
>
> Message: 29
> Date: Fri, 22 Jun 2007 19:26:56 +0200
> From: "Jose Quesada " <quesada en gmail.com>
> Subject: [R] Matrix library, CHOLMOD error: problem too large
> To: "r-help en lists.r-project.org" <r-help en stat.math.ethz.ch>
> Message-ID: <op.tub2q6d64hcap5 en delllap.ugr.es>
> Content-Type: text/plain; format=flowed; delsp=yes;
>        charset=iso-8859-15
>
>
> I have a pretty large sparse matrix of integers:
> > dim(tasa)
> [1] 91650 37651
>
> I need to add one to it in order to take logs, but I'm getting the
> following error:
>
> > tasa  = log(tasa + 1)
> CHOLMOD error: problem too large
> Error in asMethod(object) : Cholmod error `problem too large'
>
> I have 2 Gb of RAM, and the current workspace is barely 300mb.
> Is there any workaround to this? Anyone has any experience with this error?
>
> Thanks,
> -Jose
>
> --
> Jose Quesada, PhD.
> http://www.andrew.cmu.edu/~jquesada
>
>
>
> ------------------------------
>
> Message: 30
> Date: Fri, 22 Jun 2007 14:04:03 -0400
> From: Duncan Murdoch <murdoch en stats.uwo.ca>
> Subject: Re: [R] Matrix library, CHOLMOD error: problem too large
> To: Jose Quesada <quesada en gmail.com>
> Cc: "r-help en lists.r-project.org" <r-help en stat.math.ethz.ch>
> Message-ID: <467C0F13.4060004 en stats.uwo.ca>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
> On 6/22/2007 1:26 PM, Jose Quesada wrote:
> > I have a pretty large sparse matrix of integers:
> >> dim(tasa)
> > [1] 91650 37651
> >
> > I need to add one to it in order to take logs, but I'm getting the
> > following error:
> >
> >> tasa  = log(tasa + 1)
> > CHOLMOD error: problem too large
> > Error in asMethod(object) : Cholmod error `problem too large'
> >
> > I have 2 Gb of RAM, and the current workspace is barely 300mb.
> > Is there any workaround to this? Anyone has any experience with this error?
> >
>
> If tasa is sparse, then tasa+1 will not be sparse, so that's likely your
> problem.  You might have better luck with
>
> log1p(tasa)
>
> if the authors of the Matrix package have written a method for log1p();
> if not, you'll probably have to do it yourself.
>
> Duncan Murdoch
>
>
>
> ------------------------------
>
> Message: 31
> Date: Fri, 22 Jun 2007 11:44:52 -0700
> From: "Horace Tso" <Horace.Tso en pgn.com>
> Subject: [R] Imputing missing values in time series
> To: <r-help en stat.math.ethz.ch>
> Message-ID: <467BB6340200006500006924 en pgn.com>
> Content-Type: text/plain; charset=ISO-8859-15
>
> Folks,
>
> This must be a rather common problem with real life time series data
> but I don't see anything in the archive about how to deal with it. I
> have a time series of natural gas prices by flow date. Since gas is not
> traded on weekends and holidays, I have a lot of missing values,
>
> FDate   Price
> 11/1/2006       6.28
> 11/2/2006       6.58
> 11/3/2006       6.586
> 11/4/2006       6.716
> 11/5/2006       NA
> 11/6/2006       NA
> 11/7/2006       6.262
> 11/8/2006       6.27
> 11/9/2006       6.696
> 11/10/2006      6.729
> 11/11/2006      6.487
> 11/12/2006      NA
> 11/13/2006      NA
> 11/14/2006      6.725
> 11/15/2006      6.844
> 11/16/2006      6.907
>
> What I would like to do is to fill the NAs with the price from the
> previous date * gas used during holidays is purchased from the week
> before. Though real simple, I wonder if there is a function to perform
> this task. Some of the imputation functions I'm aware of (eg. impute,
> transcan in Hmisc) seem to deal with completely different problems.
>
> 2.5.0/Windows XP
>
> Thanks in advance.
>
> HT
>
>
>
> ------------------------------
>
> Message: 32
> Date: Fri, 22 Jun 2007 14:01:52 -0500
> From: Erik Iverson <iverson en biostat.wisc.edu>
> Subject: Re: [R] Imputing missing values in time series
> To: Horace Tso <Horace.Tso en pgn.com>
> Cc: r-help en stat.math.ethz.ch
> Message-ID: <467C1CA0.1080606 en biostat.wisc.edu>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
> I think my example should work for you, but I couldn't think of a way to
> do this without an interative while loop.
>
> test <- c(1,2,3,NA,4,NA,NA,5,NA,6,7,NA)
>
> while(any(is.na(test)))
> test[is.na(test)] <- test[which(is.na(test))-1]
>
>  test
>  [1] 1 2 3 3 4 4 4 5 5 6 7 7
>
> Horace Tso wrote:
> > Folks,
> >
> > This must be a rather common problem with real life time series data
> > but I don't see anything in the archive about how to deal with it. I
> > have a time series of natural gas prices by flow date. Since gas is not
> > traded on weekends and holidays, I have a lot of missing values,
> >
> > FDate Price
> > 11/1/2006     6.28
> > 11/2/2006     6.58
> > 11/3/2006     6.586
> > 11/4/2006     6.716
> > 11/5/2006     NA
> > 11/6/2006     NA
> > 11/7/2006     6.262
> > 11/8/2006     6.27
> > 11/9/2006     6.696
> > 11/10/2006    6.729
> > 11/11/2006    6.487
> > 11/12/2006    NA
> > 11/13/2006    NA
> > 11/14/2006    6.725
> > 11/15/2006    6.844
> > 11/16/2006    6.907
> >
> > What I would like to do is to fill the NAs with the price from the
> > previous date * gas used during holidays is purchased from the week
> > before. Though real simple, I wonder if there is a function to perform
> > this task. Some of the imputation functions I'm aware of (eg. impute,
> > transcan in Hmisc) seem to deal with completely different problems.
> >
> > 2.5.0/Windows XP
> >
> > Thanks in advance.
> >
> > HT
> >
> > ______________________________________________
> > R-help en stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> ------------------------------
>
> Message: 33
> Date: Fri, 22 Jun 2007 12:08:26 -0700
> From: "Horace Tso" <Horace.Tso en pgn.com>
> Subject: Re: [R] Imputing missing values in time series
> To: "Erik Iverson" <iverson en biostat.wisc.edu>
> Cc: r-help en stat.math.ethz.ch
> Message-ID: <467BBBBA0200006500006928 en pgn.com>
> Content-Type: text/plain; charset=US-ASCII
>
> Erik, indeed it gets the work done. I was hoping to avoid the dreaded looping, though.....
>
> Thanks.
>
> Horace
>
> >>> Erik Iverson <iverson en biostat.wisc.edu> 6/22/2007 12:01 PM >>>
> I think my example should work for you, but I couldn't think of a way to
> do this without an interative while loop.
>
> test <- c(1,2,3,NA,4,NA,NA,5,NA,6,7,NA)
>
> while(any(is.na(test)))
> test[is.na(test)] <- test[which(is.na(test))-1]
>
>  test
>  [1] 1 2 3 3 4 4 4 5 5 6 7 7
>
> Horace Tso wrote:
> > Folks,
> >
> > This must be a rather common problem with real life time series data
> > but I don't see anything in the archive about how to deal with it. I
> > have a time series of natural gas prices by flow date. Since gas is not
> > traded on weekends and holidays, I have a lot of missing values,
> >
> > FDate Price
> > 11/1/2006     6.28
> > 11/2/2006     6.58
> > 11/3/2006     6.586
> > 11/4/2006     6.716
> > 11/5/2006     NA
> > 11/6/2006     NA
> > 11/7/2006     6.262
> > 11/8/2006     6.27
> > 11/9/2006     6.696
> > 11/10/2006    6.729
> > 11/11/2006    6.487
> > 11/12/2006    NA
> > 11/13/2006    NA
> > 11/14/2006    6.725
> > 11/15/2006    6.844
> > 11/16/2006    6.907
> >
> > What I would like to do is to fill the NAs with the price from the
> > previous date * gas used during holidays is purchased from the week
> > before. Though real simple, I wonder if there is a function to perform
> > this task. Some of the imputation functions I'm aware of (eg. impute,
> > transcan in Hmisc) seem to deal with completely different problems.
> >
> > 2.5.0/Windows XP
> >
> > Thanks in advance.
> >
> > HT
> >
> > ______________________________________________
> > R-help en stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> ------------------------------
>
> Message: 34
> Date: Fri, 22 Jun 2007 21:13:09 +0200
> From: "hadley wickham" <h.wickham en gmail.com>
> Subject: Re: [R] Switching X-axis and Y-axis for histogram
> To: "Donghui Feng" <donghui.feng en gmail.com>
> Cc: r-help en stat.math.ethz.ch
> Message-ID:
>        <f8e6ff050706221213j3dc25aeaw6c6d4df7a4511e06 en mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
> It's trivial to do this with ggplot2 (http://had.co.nz):
>
> qplot(rating, data=movies, geom="histogram") + coord_flip()
> qplot(rating, data=movies, geom="histogram", binwidth=0.1) + coord_flip()
>
> Hadley
>
> On 6/22/07, Donghui Feng <donghui.feng en gmail.com> wrote:
> > Dear all,
> >
> > I'm creating a histogram with the function hist(). But
> > right now what I get is column representation (as normal).
> > I'm wondering if I could switch X-axis and Y-axis and
> > get row-representation of frequencies?
> >
> > One more question, can I define the step of each axises
> > for the histogram?
> >
> > Thanks so much!
> >
> > Donghui
> >
> > ______________________________________________
> > R-help en stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
>
> ------------------------------
>
> Message: 35
> Date: Fri, 22 Jun 2007 15:16:09 -0400
> From: "Leeds, Mark \(IED\)" <Mark.Leeds en morganstanley.com>
> Subject: Re: [R] Imputing missing values in time series
> To: "Erik Iverson" <iverson en biostat.wisc.edu>,  "Horace Tso"
>        <Horace.Tso en pgn.com>
> Cc: r-help en stat.math.ethz.ch
> Message-ID:
>        <D3AEEDA31E57474B840BEBC25A8A834401957418 en NYWEXMB23.msad.ms.com>
> Content-Type: text/plain;       charset="us-ascii"
>
> I have a function that does this type of thing but it works off a pure
> vector so it wouldn have to be modified.
> If you make your object a zoo object, the that object has many functions
> associated with it and na.locf would
> Do what you need, I think.
>
>
> -----Original Message-----
> From: r-help-bounces en stat.math.ethz.ch
> [mailto:r-help-bounces en stat.math.ethz.ch] On Behalf Of Erik Iverson
> Sent: Friday, June 22, 2007 3:02 PM
> To: Horace Tso
> Cc: r-help en stat.math.ethz.ch
> Subject: Re: [R] Imputing missing values in time series
>
> I think my example should work for you, but I couldn't think of a way to
> do this without an interative while loop.
>
> test <- c(1,2,3,NA,4,NA,NA,5,NA,6,7,NA)
>
> while(any(is.na(test)))
> test[is.na(test)] <- test[which(is.na(test))-1]
>
>  test
>  [1] 1 2 3 3 4 4 4 5 5 6 7 7
>
> Horace Tso wrote:
> > Folks,
> >
> > This must be a rather common problem with real life time series data
> > but I don't see anything in the archive about how to deal with it. I
> > have a time series of natural gas prices by flow date. Since gas is
> > not traded on weekends and holidays, I have a lot of missing values,
> >
> > FDate Price
> > 11/1/2006     6.28
> > 11/2/2006     6.58
> > 11/3/2006     6.586
> > 11/4/2006     6.716
> > 11/5/2006     NA
> > 11/6/2006     NA
> > 11/7/2006     6.262
> > 11/8/2006     6.27
> > 11/9/2006     6.696
> > 11/10/2006    6.729
> > 11/11/2006    6.487
> > 11/12/2006    NA
> > 11/13/2006    NA
> > 11/14/2006    6.725
> > 11/15/2006    6.844
> > 11/16/2006    6.907
> >
> > What I would like to do is to fill the NAs with the price from the
> > previous date * gas used during holidays is purchased from the week
> > before. Though real simple, I wonder if there is a function to perform
>
> > this task. Some of the imputation functions I'm aware of (eg. impute,
> > transcan in Hmisc) seem to deal with completely different problems.
> >
> > 2.5.0/Windows XP
> >
> > Thanks in advance.
> >
> > HT
> >
> > ______________________________________________
> > R-help en stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help en stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> --------------------------------------------------------
>
> This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}
>
>
>
> ------------------------------
>
> Message: 36
> Date: Fri, 22 Jun 2007 12:21:40 -0700
> From: "Horace Tso" <Horace.Tso en pgn.com>
> Subject: Re: [R] Imputing missing values in time series
> To: "Erik Iverson" <iverson en biostat.wisc.edu>,  "Mark (IED) Leeds"
>        <Mark.Leeds en morganstanley.com>
> Cc: r-help en stat.math.ethz.ch
> Message-ID: <467BBED40200006500006931 en pgn.com>
> Content-Type: text/plain; charset=US-ASCII
>
> Mark, thanks for the tips. I thought you financial folks must have run into things like these before. Just wonder why this problem wasn't asked more often on this list.
>
> H.
>
>
> >>> "Leeds, Mark (IED)" <Mark.Leeds en morganstanley.com> 6/22/2007 12:16 PM >>>
> I have a function that does this type of thing but it works off a pure
> vector so it wouldn have to be modified.
> If you make your object a zoo object, the that object has many functions
> associated with it and na.locf would
> Do what you need, I think.
>
>
> -----Original Message-----
> From: r-help-bounces en stat.math.ethz.ch
> [mailto:r-help-bounces en stat.math.ethz.ch] On Behalf Of Erik Iverson
> Sent: Friday, June 22, 2007 3:02 PM
> To: Horace Tso
> Cc: r-help en stat.math.ethz.ch
> Subject: Re: [R] Imputing missing values in time series
>
> I think my example should work for you, but I couldn't think of a way to
> do this without an interative while loop.
>
> test <- c(1,2,3,NA,4,NA,NA,5,NA,6,7,NA)
>
> while(any(is.na(test)))
> test[is.na(test)] <- test[which(is.na(test))-1]
>
>  test
>  [1] 1 2 3 3 4 4 4 5 5 6 7 7
>
> Horace Tso wrote:
> > Folks,
> >
> > This must be a rather common problem with real life time series data
> > but I don't see anything in the archive about how to deal with it. I
> > have a time series of natural gas prices by flow date. Since gas is
> > not traded on weekends and holidays, I have a lot of missing values,
> >
> > FDate Price
> > 11/1/2006     6.28
> > 11/2/2006     6.58
> > 11/3/2006     6.586
> > 11/4/2006     6.716
> > 11/5/2006     NA
> > 11/6/2006     NA
> > 11/7/2006     6.262
> > 11/8/2006     6.27
> > 11/9/2006     6.696
> > 11/10/2006    6.729
> > 11/11/2006    6.487
> > 11/12/2006    NA
> > 11/13/2006    NA
> > 11/14/2006    6.725
> > 11/15/2006    6.844
> > 11/16/2006    6.907
> >
> > What I would like to do is to fill the NAs with the price from the
> > previous date * gas used during holidays is purchased from the week
> > before. Though real simple, I wonder if there is a function to perform
>
> > this task. Some of the imputation functions I'm aware of (eg. impute,
> > transcan in Hmisc) seem to deal with completely different problems.
> >
> > 2.5.0/Windows XP
> >
> > Thanks in advance.
> >
> > HT
> >
> > ______________________________________________
> > R-help en stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help en stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> --------------------------------------------------------
>
> This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}
>
>
>
> ------------------------------
>
> Message: 37
> Date: Fri, 22 Jun 2007 21:40:26 +0200
> From: "hadley wickham" <h.wickham en gmail.com>
> Subject: Re: [R] Overlaying lattice graphs (continued)
> To: " S?bastien " <pomchip en free.fr>
> Cc: R-help <r-help en stat.math.ethz.ch>
> Message-ID:
>        <f8e6ff050706221240m240391dfrf83f5eb6d47e1766 en mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
> Hi Sebastian,
>
> I think the following does what you want:
>
> library(ggplot2)
> names(mydata) <- tolower(names(mydata))
>
> obs <- rename(subset(mydata, model=="A", -predicted), c("observed" = "value"))
> obs$model <- factor("observed")
> pred <- rename(mydata[, -5], c("predicted" = "value"))
> all <- rbind(obs, pred)
>
> ggplot(all, aes(x = time, y = value, colour=model)) +
> geom_point(data = subset(all, model != "Observed")) +
> geom_line(data= subset(all, model == "Observed")) +
> facet_grid(. ~ individuals)
>
> Hadley
>
> On 6/22/07, S?bastien <pomchip en free.fr> wrote:
> > Hi Deepayan,
> >
> > The following code creates a dummy dataset which has the same similar as
> > my usual datasets. I did not try to implement the changes proposed by
> > Hadley, hoping that a solution can be found using the original dataset.
> >
> > ######### My code
> >
> > # Creating dataset
> >
> > nPts<-10            # number of time points
> > nInd<-6              # number of individuals
> > nModel<-3         # number of models
> >
> > TimePts<-rep(1:nPts,nInd*nModel)                                    #
> > creates the "Time" column
> > Coef<-rep(rnorm(6,0.1,0.01),each=nPts,nModel)             # Creates a
> > vector of coefficients for generating the observations
> > Obs<-10*exp(-Coef*TimePts)                                         #
> > creates the observations
> >
> > for (i in 1:60){
> > Pred[i]<-jitter(10*exp(-Coef[i]*TimePts[i]))
> > Pred[i+60]<-jitter(5)
> > Pred[i+120]<-jitter(10-Coef[i+120]*TimePts[i])
> > }
> >                   # creates the predicted values
> >
> > colPlot<-rep(1,nPts*nInd*nModel)
> >     # creates the "Plot" column
> > colModel<-gl(nModel,nPts*nInd,labels=c("A","B","C"))             #
> > creates the "Model" column
> > colID<-gl(nInd,nPts,nPts*nInd*nModel)
> >       # creates the "ID" column
> >
> > mydata<-data.frame(colPlot,colModel,colID,TimePts,Obs,Pred)
> >               # creates the dataset
> > names(mydata)<-c("Plot","Model","Individuals","Time","Observed","Predicted")
> >
> > # Plotting as indicated by Deepayan
> >
> >
> > xyplot(Observed + Predicted ~ Time | Individuals + Model,
> >       data = mydata,
> >       panel = panel.superpose.2, type = c("p", "l"),
> >       layout = c(0, nlevels(mydata$Individuals))) #,
> >       #<...>)
> >
> > ####### End of code
> >
> > This codes is not exactly what I am looking for, although it is pretty
> > close. In the present case, I would like to have a Trellis plot with 6
> > panels (one for each individual), where the Observations and the
> > Predicted are plotted as symbols and lines, respectively. All three
> > models should be plotted on the same panel. Unfortunately, it looks to
> > me as 3 successives xyplots are created by the code above but only the
> > last one remains displayed. I tried to play with
> > panel.superpose,panel.superpose.2 and type, without much success.
> >
> > I also tried the following code that creates 18 panels and distinguish
> > all (Individuals,Model) couples... so, not what I want.
> >
> > xyplot(Observed + Predicted ~ Time | Individuals+Model, data = mydata,
> >      type = c("p", "l"), distribute.type = TRUE)
> >
> > Sebastien
> >
> >
> > Deepayan Sarkar a ?crit :
> > > On 6/21/07, S?bastien <pomchip en free.fr> wrote:
> > >> Hi Hadley,
> > >>
> > >> Hopefully, my dataset won't be too hard to changed. Can I modify the
> > >> aspect of each group using your code (symbols for observed and lines for
> > >> predicted)?
> > >>
> > >> Sebastien
> > >>
> > >> hadley wickham a ?crit :
> > >> > Hi Sebastian,
> > >> >
> > >> > I think you need to rearrange your data a bit.  Firstly, you need to
> > >> > put observed on the same footing as the different models, so you would
> > >> > have a new column in your data called value (previously observed and
> > >> > predicted) and a new model type ("observed").  Then you could do:
> > >
> > > Yes, and ?make.groups (and reshape of course) could help with that.
> > > This might not be strictly necessary though.
> > >
> > > However, I'm finding your pseudo-code confusing. Could you create a
> > > small example data set that can be used to try out some real code?
> > > Just from your description, I would have suggested something like
> > >
> > > xyplot(Observed + Predicted ~ Time | Individuals + Model,
> > >       data = mydata,
> > >       panel = panel.superpose.2, type = c("p", "l"),
> > >       layout = c(0, nlevels(mydata$Individuals)),
> > >       <...>)
> > >
> > > If all you want is to plot one page at a time, there are easier ways
> > > to do that.
> > >
> > > -Deepayan
> > >
> > >> >
> > >> > xyplot(value ~ time | individauls, data=mydata, group=model)
> > >> >
> > >> > Hadley
> > >> >
> > >> >
> > >> > On 6/21/07, S?bastien <pomchip en free.fr> wrote:
> > >> >> Dear R Users,
> > >> >>
> > >> >> I recently posted an email on this list  about the use of
> > >> data.frame and
> > >> >> overlaying multiple plots. Deepayan kindly indicated to me the
> > >> >> panel.superposition command which worked perfectly in the context
> > >> of the
> > >> >> example I gave.
> > >> >> I'd like to go a little bit further on this topic using a more
> > >> complex
> > >> >> dataset structure (actually the one I want to work on).
> > >> >>
> > >> >>  >mydata
> > >> >>       Plot    Model    Individuals    Time        Observed
> > >> >> Predicted
> > >> >> 1    1        A           1                  0.05
> > >> >> 10                    10.2
> > >> >> 2    1        A           1                  0.10
> > >> >> 20                    19.5
> > >> >> etc...
> > >> >> 10  1        B           1                  0.05         10
> > >> >>          9.8
> > >> >> 11  1        B           1                  0.10         20
> > >> >>          20.2
> > >> >> etc...
> > >> >>
> > >> >> There are p "levels" in mydata$Plot, m in mydata$Model, n in
> > >> >> mydata$Individuals and t in mydata$Time (Note that I probably use the
> > >> >> word levels improperly as all columns are not factors). Basically,
> > >> this
> > >> >> dataset summarizes the t measurements obtained in n individuals as
> > >> well
> > >> >> as the predicted values from m different modeling approaches
> > >> (applied to
> > >> >> all individuals). Therefore, the observations are repeated m times in
> > >> >> the Observed columns, while the predictions appears only once for a
> > >> >> given model an a given individual.
> > >> >>
> > >> >> What I want to write is a R batch file creating a Trellis graph,
> > >> where
> > >> >> each panel corresponds to one individual and contains the
> > >> observations
> > >> >> (as scatterplot) plus the predicted values for all models (as
> > >> lines of
> > >> >> different colors)... $Plot is just a token: it might be used to not
> > >> >> overload graphs in case there are too many tested models. The fun
> > >> part
> > >> >> is that the values of p, m, n and t might vary from one dataset to
> > >> the
> > >> >> other, so everything has to be coded dynamically.
> > >> >>
> > >> >> For the plotting part I was thinking about having a loop in my code
> > >> >> containing something like that:
> > >> >>
> > >> >> for (i in 1:nlevels(mydata$Model)) {
> > >> >>
> > >> >> subdata<-subset(mydata,mydata$Model=level(mydata$Model)[i])
> > >> >> xyplot(subset(Observed + Predicted ~ Time | Individuals, data =
> > >> >> subdata)       #plus additionnal formatting code
> > >> >>
> > >> >> }
> > >> >>
> > >> >> Unfortunately, this code simply creates a new Trellis plot instead of
> > >> >> adding the model one by one on the panels. Any idea or link to a
> > >> useful
> > >> >> command will wellcome.
> > >> >>
> > >> >> Sebastien
> > >> >>
> > >> >> ______________________________________________
> > >> >> R-help en stat.math.ethz.ch mailing list
> > >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> >> PLEASE do read the posting guide
> > >> >> http://www.R-project.org/posting-guide.html
> > >> >> and provide commented, minimal, self-contained, reproducible code.
> > >> >>
> > >> >
> > >> >
> > >>
> > >> ______________________________________________
> > >> R-help en stat.math.ethz.ch mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >>
> >
>
>
>
> ------------------------------
>
> Message: 38
> Date: Fri, 22 Jun 2007 12:47:51 -0700
> From: "Deepayan Sarkar" <deepayan.sarkar en gmail.com>
> Subject: Re: [R] Overlaying lattice graphs (continued)
> To: " S?bastien " <pomchip en free.fr>
> Cc: R-help <r-help en stat.math.ethz.ch>
> Message-ID:
>        <eb555e660706221247v59cf4f4cpdaee99e0a1372c84 en mail.gmail.com>
> Content-Type: text/plain; charset=UTF-8; format=flowed
>
> On 6/22/07, S?bastien <pomchip en free.fr> wrote:
> > Hi Deepayan,
> >
> > The following code creates a dummy dataset which has the same similar as
> > my usual datasets. I did not try to implement the changes proposed by
> > Hadley, hoping that a solution can be found using the original dataset.
> >
> > ######### My code
> >
> > # Creating dataset
> >
> > nPts<-10            # number of time points
> > nInd<-6              # number of individuals
> > nModel<-3         # number of models
> >
> > TimePts<-rep(1:nPts,nInd*nModel)                                    #
> > creates the "Time" column
> > Coef<-rep(rnorm(6,0.1,0.01),each=nPts,nModel)             # Creates a
> > vector of coefficients for generating the observations
> > Obs<-10*exp(-Coef*TimePts)                                         #
> > creates the observations
> >
> > for (i in 1:60){
> > Pred[i]<-jitter(10*exp(-Coef[i]*TimePts[i]))
> > Pred[i+60]<-jitter(5)
> > Pred[i+120]<-jitter(10-Coef[i+120]*TimePts[i])
> > }
> >                   # creates the predicted values
> >
> > colPlot<-rep(1,nPts*nInd*nModel)
> >     # creates the "Plot" column
> > colModel<-gl(nModel,nPts*nInd,labels=c("A","B","C"))             #
> > creates the "Model" column
> > colID<-gl(nInd,nPts,nPts*nInd*nModel)
> >       # creates the "ID" column
> >
> > mydata<-data.frame(colPlot,colModel,colID,TimePts,Obs,Pred)
> >               # creates the dataset
> > names(mydata)<-c("Plot","Model","Individuals","Time","Observed","Predicted")
>
> The way you have structured your data makes no sense to me. In
> particular, your 'Observed' data is the same set of 60 numbers
> repeated 3 times, and this is not reflected in the data structure at
> all. What would you want to happen if the numbers were not repeated?
> Would you always plot the first 60, or would plot all of them?
>
> If I understand what you are trying to do, this might be a more
> transparent approach:
>
>
> nPts<-10   # number of time points
> nInd<-6    # number of individuals
>
> TimePts <- rep(1:nPts, nInd)
> Coef <- rep(rnorm(6,0.1,0.01), each = nPts)
> Obs <- 10 * exp(-Coef * TimePts)
> colID <- gl(nInd, nPts)
>
> mydata <- data.frame(Time = TimePts, Observed = Obs, Individuals = colID)
>
> fmA <- lm(Observed ~ Time, mydata)
> fmB <- lm(Observed ~ poly(Time, 2), mydata)
> fmC <- lm(Observed ~ poly(Time, 2) * Individuals, mydata)
>
> mydata$PredA <- predict(fmA)
> mydata$PredB <- predict(fmB)
> mydata$PredC <- predict(fmC)
>
> xyplot(Observed + PredA + PredB + PredC ~ Time | Individuals,
>       data = mydata,
>       type = c("p", "l", "l", "l"),
>       distribute.type = TRUE)
>
> -Deepayan
>
>
>
> ------------------------------
>
> Message: 39
> Date: Fri, 22 Jun 2007 21:55:52 +0200
> From: "hadley wickham" <h.wickham en gmail.com>
> Subject: Re: [R] Stacked barchart color
> To: owenman <solberg en speakeasy.net>
> Cc: r-help en stat.math.ethz.ch
> Message-ID:
>        <f8e6ff050706221255j37e15382n4179d5b276486c0b en mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
> Hi Owen,
>
> The bars should be stacked in the order specified by the factor.  Try
> using factor(..., levels=...) to explicitly order them the way you
> want.  If that doesn't work, please provide a small replicable example
> and I'll look into it.
>
> Hadley
>
> On 6/18/07, owenman <solberg en speakeasy.net> wrote:
> >
> > Hi Hadley,
> > Great, I am starting to get it.  It's working for me, but there is one more
> > thing I am having trouble with.  The ordering of the stacked bars seems to
> > be dictated by the name of the color, I guess because of the fill=color
> > argument in aes().  In other words, if I set up my colors like this:
> > y$color = c("gray1","gray35","gray45","gray65")  the bars get stacked in the
> > opposite order than if I set up the colors like this:  y$color =
> > c("gray65","gray45","gray35","gray1").  How can I control the order of the
> > bars independent of the name of the colors?   Thanks so much in advance!
> > Really neat package you've made.
> >
> > FYI, my plot command now looks like this:
> >
> > p = ggplot(y, aes(x=locus, y=Freq, fill=color))
> > p = p + geom_bar(position="fill")
> > p = p + scale_fill_identity(labels=levels(y$Fnd), grob="tile", name="Fnd
> > Results")
> > p = p + coord_flip()
> >
> > And the data table is similar as before:
> >
> > > y
> >       Fnd locus        Freq  color
> > 1  signeg  DPB1 0.013071895  gray1
> > 2     neg  DPB1 0.581699346 gray35
> > 3     pos  DPB1 0.379084967 gray45
> > 4  sigpos  DPB1 0.026143791 gray65
> > 5  signeg  DPA1 0.068181818  gray1
> > 6     neg  DPA1 0.659090909 gray35
> > 7     pos  DPA1 0.250000000 gray45
> > 8  sigpos  DPA1 0.022727273 gray65
> >
> >
> >
> > hadley wrote:
> > >
> > > Hi Owen,
> > >
> > > The identity scale won't create a legend, unless you tell it what
> > > labels it should use - there's an example at
> > > http://had.co.nz/ggplot2/scale_identity.html.  Otherwise, if you have
> > > a continuous scale and you want something that works in black and
> > > white, p + scale_fill_gradient(low="white", high="black") might be
> > > easier.
> > >
> > > Hadley
> > >
> > >
> > >>
> > >> > y$color = factor(y$Fnd)
> > >> > y$color = c("black","darkgray","lightgray","white")
> > >> > y
> > >>       Fnd locus        Freq color
> > >> 1  signeg     A 0.087248322     black
> > >> 2     neg     A 0.711409396  darkgray
> > >> 3     pos     A 0.201342282 lightgray
> > >> 4  sigpos     A 0.000000000     white
> > >> 5  signeg     C 0.320754717     black
> > >> 6     neg     C 0.603773585  darkgray
> > >> 7     pos     C 0.075471698 lightgray
> > >> 8  sigpos     C 0.000000000     white
> > >> 9  signeg     B 0.157534247     black
> > >> 10    neg     B 0.732876712  darkgray
> > >> 11    pos     B 0.109589041 lightgray
> > >> 12 sigpos     B 0.000000000     white
> > >>
> > >> > p = ggplot(y, aes(x=locus, y=Freq, fill=color)) +
> > >> > geom_bar(position="fill") + scale_fill_identity()
> > >> > p
> > >>
> > >>
> > >>
> > >>
> > >> hadley wrote:
> > >> >
> > >> >
> > >> > Hi Dieter,
> > >> >
> > >> > You can do this with ggplot2 (http://had.co.nz/ggplot2) as follows:
> > >> >
> > >> > library(ggplot2)
> > >> >
> > >> > barley1 <- subset(barley, site=="Grand Rapids" & variety %in%
> > >> > c("Velvet","Peatland"))
> > >> > barley1[] <- lapply(barley1, "[", drop=TRUE)
> > >> >
> > >> > qplot(variety, yield, data=barley1, geom="bar", stat="identity",
> > >> > fill=factor(year))
> > >> >
> > >> > barley1$fill <- c("red","green","blue","gray")
> > >> > qplot(variety, yield, data=barley1, geom="bar", stat="identity",
> > >> > fill=fill) + scale_fill_identity()
> > >> >
> > >> > See http://had.co.nz/ggplot2/scale_identity.html and
> > >> > http://had.co.nz/ggplot2/position_stack.html for more details.
> > >> >
> > >> > Hadley
> > >> >
> > >> >
> > >>
> > >>
> > >> --
> > >> View this message in context:
> > >> http://www.nabble.com/Stacked-barchart-color-tf3909162.html#a11149419
> > >> Sent from the R help mailing list archive at Nabble.com.
> > >>
> > >>
> > >> ______________________________________________
> > >> R-help en stat.math.ethz.ch mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >
> > > ______________________________________________
> > > R-help en stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> >
> >
> > --
> > View this message in context: http://www.nabble.com/Stacked-barchart-color-tf3909162.html#a11182581
> >
> > Sent from the R help mailing list archive at Nabble.com.
> >
> > ______________________________________________
> > R-help en stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
>
> ------------------------------
>
> Message: 40
> Date: Fri, 22 Jun 2007 22:07:37 +0200
> From: "hadley wickham" <h.wickham en gmail.com>
> Subject: Re: [R] Visualize quartiles of plot line
> To: "Arne Brutschy" <abr-r-project en xylon.de>
> Cc: R-help en stat.math.ethz.ch
> Message-ID:
>        <f8e6ff050706221307s72ebc36v31537365bc7ff667 en mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
> On 6/17/07, Arne Brutschy <abr-r-project en xylon.de> wrote:
> > Hi,
> >
> > thanks for your tips - all of them worked. After a bit of fiddling, I
> > managed to get what I wanted.
>
> Glad to hear it.
>
> > hadley wickham wrote:
> > h> You might want to read the introductory chapters in the ggplot book,
> > h> available from http://had.co.nz/ggplot2, which will give you more of a
> > h> background.  Please let me know places where you think the
> > h> documentation is inconsistent so I can try and make them better.
> > I already did. :) A general problem: the examples are nice and easy to
> > get, but it's often hard to apply them to my own specific problem.
> > It's more a problem of the general structure: what has to go where.
> > Most of the methods are using qplot, but what do I have to do if I'm
> > trying create a more complex plot. Hmm, it's hard to describe.
> >
> > Example: I know how I set the title when using qplot (qplot(....
> > main="asdf"). Where do I have to put it when I'm using gplot? Stuff
> > like this is unclear...
>
> p <- ggplot(...) + ...
> p$title <- "Title goes here"
>
> It is currently hard to figure this out in the current documentation though.
>
> > A more general problem is, that the manual pages are very, eh,
> > minimalistic documented. The overall reference page is good and nicely
> > structured. But the big idea is sort of missing. All components are
> > linked, but the basics like layout, ggplot, aes etc are harder to find
> > - and their help pages are the shortest. Especially the small details
> > are hard to figure out. Lists of attributes etc..
>
> Yes, that's definitely something I'm working on for the book.
> Unfortunately, I don't have
>  that much time and it is a lot of work.  Every comment helps though.
>
> > Hmm, I know this is not really helpful. I can't describe my problems
> > properly, I guess. Perhaps the documentation simply has to improve
> > based on users questions. :\
> >
> > How old is this package? I think it's really, really great, but are
> > there many users? Is there an additional mailinglist or forum where I
> > can get more information?
>
> It's pretty young still, although the precursor ggplot package has
> been around for about a year.  I really have no idea how many users
> there are.  For questions, either email me or R-help.
>
> > Some more questions:
> >
> > Why doesn't ggplot2 work with layout()? I'm using viewport now, which
> > works fine for me, but there should be a note in the docs perhaps.
>
> Because it works with the grid drawing package - see the last chapter
> in the ggplot book for some details on how to use the grid
> equivalents.
>
> > How do I change the legend. The auto-creation of it might be nice,
> > but I want a) to add a title b) change the order to ascending and c)
> > add a short description like:
> >
> >   DeltaConfig
> >   [ ] 0 best
> >   [ ]
> >   [ ] 5
> >   [ ]
> >   [ ]10 worst
> >
> > I don't know if this is possible, but it would be nice to explain what
> > the colors/values might mean if it's not clear from the beginning
> > (ligke diamonds.size). The only thing I found was the attribute
> > legend.justifcation in ggopt, which isn't fully documented.
>
> The legends aren't very customisable at the moment - look at the
> examples for the scale functions to see what you can do.  You can see
> the name of the title easily, and you can change the labels by
> changing the level of the factors, or setting the breaks argument.  I
> agree there could be more options.  If you could provide me with a
> picture of what you want, I'll add it to my to do list to think about.
>
> > Additionally, how can I change the order of the facets? I currently
> > have a plot with a smoother for each model (all in the same plot),
> > which sorts the models like this: dyn,dl4,dl3 Below that, I have a
> > facet with point-plots for each model which sorts them the other way
> > round, which is a bit confusing.
>
> Again, change the order of the underlying factor.
>
> > BTW, what's the "strip" and the associated attributes?
>
> The strip is the labelled associated with the facet.
>
> > Again, I think this package is great - nice work! All the above isn't
> > meant as general critisism, but is being said in order to improve the
> > documentation..
>
> I do appreciate your comments and they definitely help me to make a
> better product.
>
> Thanks,
>
> Hadley
>
>
>
> ------------------------------
>
> Message: 41
> Date: Fri, 22 Jun 2007 16:14:52 -0400
> From: "Patrick Ayscue" <payscue en gmail.com>
> Subject: [R] "heatmap" color still a spectrum for binary outcomes?
> To: r-help en stat.math.ethz.ch
> Message-ID:
>        <ea3a49790706221314n270f8036i72fb4356c579303 en mail.gmail.com>
> Content-Type: text/plain
>
> I have a matrix of a time series binary response variable for around 200
> individuals I would like to display.  I am approaching success using the
> "heatmap" function in the "stats" package without dendorgrams, however, am
> running into trouble in that the colors get lighter with more positive
> outcomes in a column (time point).  Is there a way to make the colors
> uniform irrespective of the number of similar values in the column? or this
> part of the heatmap function?
>
> Other suggestions for representing the data graphically are certainly
> welcome as well.
>
> Thanks,
> Patrick
>
>        [[alternative HTML version deleted]]
>
>
>
> ------------------------------
>
> Message: 42
> Date: Fri, 22 Jun 2007 14:19:43 -0600
> From: "Spilak,Jacqueline [Edm]" <Jacqueline.Spilak en EC.gc.ca>
> Subject: [R] Barchart legend position
> To: <r-help en stat.math.ethz.ch>
> Message-ID:
>        <4A6AB38B55B49C44A22E021A83CBEDDB015EB9A1 en sr-pnr-exch3.prairie.int.ec.gc.ca>
>
> Content-Type: text/plain
>
> I am using barchart to make charts for some data with a lot more
> functions and labels and such in the command.
>
> barchart(Freq ~ factor(HH), data = dataset1, group= year)
>
> So I have my data grouped by year and I get a legend at the top of
> graph, which is great cause I need the legend for the different years
> but it is a weird spot.  So how can I manipulate the legend, ie. Move
> it, shrink it, do anything with it. I have searched the help archives
> and found nothing, and I have looked up the legend section in ?barchart
> but that has not helped or I am doing something wrong.  Any help is
> greatly appreciated.
> Jacquie
>
>        [[alternative HTML version deleted]]
>
>
>
> ------------------------------
>
> Message: 43
> Date: Fri, 22 Jun 2007 17:25:14 +0100
> From: Michael Hoffman <b3i4old02 en sneakemail.com>
> Subject: [R] Lattice: hiding only some strips
> To: r-help en stat.math.ethz.ch
> Message-ID: <f5gt5i$f6k$1 en sea.gmane.org>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
> I am using R 2.4.0 and lattice to produce some xyplots conditioned on a
> factor and a shingle. The shingle merely chops up the data along the
> x-axis, so it is easy to identify which part of the shingle a panel is
> in by looking at the x-axis markings. I only want to have a strip at the
> top for the factor.
>
> Is this possible? I looked into calculateGridLayout() and it seems to me
> that there isn't an easy way to do it without rewriting that function
> (and others).
>
> Many thanks
> --
> Michael Hoffman
>
>
>
> ------------------------------
>
> Message: 44
> Date: Fri, 22 Jun 2007 16:42:13 -0400
> From: S?bastien <pomchip en free.fr>
> Subject: Re: [R] Overlaying lattice graphs (continued)
> To: hadley wickham <h.wickham en gmail.com>
> Cc: R-help <r-help en stat.math.ethz.ch>
> Message-ID: <467C3425.1030000 en free.fr>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
> Hadley,
>
> I have some troubles to run your code with ggplot version 0.4.1. Is the
> package ggplot2 mandatory ?
>
> Sebastien
>
> hadley wickham a ?crit :
> > Hi Sebastian,
> >
> > I think the following does what you want:
> >
> > library(ggplot2)
> > names(mydata) <- tolower(names(mydata))
> >
> > obs <- rename(subset(mydata, model=="A", -predicted), c("observed" =
> > "value"))
> > obs$model <- factor("observed")
> > pred <- rename(mydata[, -5], c("predicted" = "value")...
>
> [Mensaje recortado]


From ccleland at optonline.net  Mon Jun 25 01:29:52 2007
From: ccleland at optonline.net (Chuck Cleland)
Date: Sun, 24 Jun 2007 19:29:52 -0400
Subject: [R] adding lines to stripchart
In-Reply-To: <acb1f1cc0706241512w7865b424wd92003e843fd9d7@mail.gmail.com>
References: <acb1f1cc0706241512w7865b424wd92003e843fd9d7@mail.gmail.com>
Message-ID: <467EFE70.1010105@optonline.net>

James Root wrote:
> I have two points of collection across 20 subjects (pre and post for each),
> so 20 pairs of data points.  I would like to plot the actual raw data points
> for each subject for both pre and post and connect lines between these two
> points (20 in all) to depict real change between the two timepoints.
> 
> I have tried using stripchart which adequately plots the two lines of
> subject data points.  Attempting to use segments however has been
> difficult.  It seems that the segments command gives too many coordiate
> points - so where segments has:
> 
> x0, y0, x1, y1
> 
> I really only have two coordinates for each point -
> 
> pre to post
> 
> I am sure that I am misusing the command but not sure if I should continue
> to try with segments or if there is another command that would be more
> appropriate.
> 
> As always, thanks for any help.

  How about using matplot() instead?  Something like this:

matplot(t(matrix(runif(40), ncol=2)), type="b", col="black", lty=1,
xaxt="n", pch=16)

mtext(side=1, at=c(1,2), c("Pre","Post"))

> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From e.jiang at auckland.ac.nz  Mon Jun 25 01:58:59 2007
From: e.jiang at auckland.ac.nz (Yifan (Eric) Jiang)
Date: Mon, 25 Jun 2007 11:58:59 +1200
Subject: [R] JRI and Axis Web Service
Message-ID: <4B518E6046247D418A5B86BB5B08389A79372B@UXCHANGE3.UoA.auckland.ac.nz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070625/63db9e1e/attachment.pl 

From wangtong at usc.edu  Mon Jun 25 04:27:19 2007
From: wangtong at usc.edu (Tong Wang)
Date: Sun, 24 Jun 2007 19:27:19 -0700
Subject: [R] Matrix multiplication (with multidimensional array)
Message-ID: <dd3a8e56f3b.467ec597@usc.edu>

Hi All,
     I am wondering if there is an efficient  way to do the following matrix multiplication,
a[1,,]       1, 2
                3, 4

a[2,,]       4, 3
                2, 1
 
b[1,,]        5,6
                 7,8

b[2,,]        8,7
                 6,5

I need the result c, with

c[1,,] = a[1,,] %*% b[1,,]
c[2,,] = a[2,,] %*% b[2,,] 

Thanks in advance for any help.


From vivek.menon79 at gmail.com  Mon Jun 25 06:10:32 2007
From: vivek.menon79 at gmail.com (Vivek Menon)
Date: Mon, 25 Jun 2007 00:10:32 -0400
Subject: [R] R-2.5.0 compilation problem on Linux powerpc
Message-ID: <bf6a5a630706242110j57f408f1i8ee10425e78af804@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070625/870d54cb/attachment.pl 

From anup_nandialath at yahoo.com  Mon Jun 25 06:32:43 2007
From: anup_nandialath at yahoo.com (Anup Nandialath)
Date: Sun, 24 Jun 2007 21:32:43 -0700 (PDT)
Subject: [R] Source code for rlogis
Message-ID: <456969.8357.qm@web53308.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070624/e1cabb31/attachment.pl 

From anup_nandialath at yahoo.com  Mon Jun 25 08:07:24 2007
From: anup_nandialath at yahoo.com (Anup Nandialath)
Date: Sun, 24 Jun 2007 23:07:24 -0700 (PDT)
Subject: [R] Random numbers from skewed distributions
Message-ID: <530642.6802.qm@web53311.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070624/f6b92532/attachment.pl 

From p.dalgaard at biostat.ku.dk  Mon Jun 25 08:22:15 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 25 Jun 2007 08:22:15 +0200
Subject: [R] ANOVA non-sphericity test and corrections (eg,
	Greenhouse-Geisser)
In-Reply-To: <1182711268.498914.61460@e9g2000prf.googlegroups.com>
References: <1182711268.498914.61460@e9g2000prf.googlegroups.com>
Message-ID: <467F5F17.4020707@biostat.ku.dk>

DarrenWeber wrote:
> I'm an experimental psychologist and when I run ANOVA analysis in
> SPSS, I normally ask for a test of non-sphericity (Box's M-test).  I
> also ask for output of the corrections for non-sphericity, such as
> Greenhouse-Geisser and Huhn-Feldt.  These tests and correction factors
> are commonly used in the journals for experimental and other
> psychology reports.  I have been switching from SPSS to R for over a
> year now, but I realize now that I don't have the non-sphericity test
> and correction factors.
>   
This can be done using anova.mlm() and mauchly.test()  which work on 
"mlm" objects, i.e., lm() output where the response is a matrix. There 
is no theory, to my knowledge, to support it for general aov() models, 
the catch being that you need to have a within-subject covariance matrix.


From p.dalgaard at biostat.ku.dk  Mon Jun 25 08:41:46 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 25 Jun 2007 08:41:46 +0200
Subject: [R] Source code for rlogis
In-Reply-To: <456969.8357.qm@web53308.mail.re2.yahoo.com>
References: <456969.8357.qm@web53308.mail.re2.yahoo.com>
Message-ID: <467F63AA.7030307@biostat.ku.dk>

Anup Nandialath wrote:
> Dear friends,
>
> I was trying to read the source code for rlogis but ran into a roadblock. It shows
>
> [[1]]
> function (n, location = 0, scale = 1) 
> .Internal(rlogis(n, location, scale))
> <environment: namespace:stats>
>
> Is is possible to access the source code for the same.
>
>   
Yes, but as it is .Internal, you have to look in the (C code) sources 
for R itself. You can access that either by getting the source files for 
R and unpacking them somewhere on your computer, or by browsing e.g. 
https://*svn*.*R*-project.org/*R*/tags/R-2-5-0 or  
https://svn.r-project.org/R/branches/R-2-5-branch. Specifically, 
src/nmath/rlogis.c.


From Corinna.Schmitt at igb.fraunhofer.de  Mon Jun 25 09:32:45 2007
From: Corinna.Schmitt at igb.fraunhofer.de (Schmitt, Corinna)
Date: Mon, 25 Jun 2007 09:32:45 +0200
Subject: [R] How to run "mathematica" or "c" programs in R?
In-Reply-To: <3f2938d50706221425p5352bec0s163cb0a0f3a41d2f@mail.gmail.com>
References: <3f2938d50706221425p5352bec0s163cb0a0f3a41d2f@mail.gmail.com>
Message-ID: <8B7B0FD99E8AF541A21609104D196158CE1891@izs-xchg01.izs.fraunhofer.de>

Hallo,

I just know a solution if you use MATLAB. Here you need the library R.matlab and there the functions writeMat and readMat. You can download the package on CRAN.

Corinna

**************************************************************************
Corinna Schmitt, Dipl.Inf.(Bioinformatik)
Fraunhofer Institut f?r Grenzfl?chen- & Bioverfahrenstechnik
Nobelstrasse 12, B 3.24
70569 Stuttgart
Germany

phone: +49 711 9704044
fax: +49 711 9704200
e-mail: Corinna.Schmitt at igb.fraunhofer.de
http://www.igb.fraunhofer.de



  


-----Urspr?ngliche Nachricht-----
Von: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch] Im Auftrag von Zhang Jian
Gesendet: Freitag, 22. Juni 2007 23:26
An: r-help
Betreff: [R] How to run "mathematica" or "c" programs in R?

I have some programs which were writen in mathematica or c language, but I
donot know how to use these software. So I want to run them in R.
Can I do it ?
How to run "mathematica" or "c" programs in R?

Jian Zhang

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From s.blomberg1 at uq.edu.au  Mon Jun 25 09:53:59 2007
From: s.blomberg1 at uq.edu.au (Simon Blomberg)
Date: Mon, 25 Jun 2007 17:53:59 +1000
Subject: [R] ANOVA non-sphericity test and corrections (eg,
	Greenhouse-Geisser)
In-Reply-To: <467F5F17.4020707@biostat.ku.dk>
References: <1182711268.498914.61460@e9g2000prf.googlegroups.com>
	<467F5F17.4020707@biostat.ku.dk>
Message-ID: <1182758039.9054.20.camel@sib-sblomber01d.sib.uq.edu.au>

If you use lme, you can fit a general correlation structure to the
within-subject data, and compare the fit to a model assuming
uncorrelated within-subjects errors. That should tell you whether your
data are Aren't the G-G and H-F corrections only approximate fixes?
Surely it is better to work with a model that actually fits your data,
rather than using ad hoc adjustments towards a model that doesn't quite
fit. But I'm no psychologist. :-)

Cheers,

Simon.

 On Mon, 2007-06-25 at 08:22 +0200, Peter Dalgaard wrote:
> DarrenWeber wrote:
> > I'm an experimental psychologist and when I run ANOVA analysis in
> > SPSS, I normally ask for a test of non-sphericity (Box's M-test).  I
> > also ask for output of the corrections for non-sphericity, such as
> > Greenhouse-Geisser and Huhn-Feldt.  These tests and correction factors
> > are commonly used in the journals for experimental and other
> > psychology reports.  I have been switching from SPSS to R for over a
> > year now, but I realize now that I don't have the non-sphericity test
> > and correction factors.
> >   
> This can be done using anova.mlm() and mauchly.test()  which work on 
> "mlm" objects, i.e., lm() output where the response is a matrix. There 
> is no theory, to my knowledge, to support it for general aov() models, 
> the catch being that you need to have a within-subject covariance matrix.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
-- 
Simon Blomberg, BSc (Hons), PhD, MAppStat. 
Lecturer and Consultant Statistician 
Faculty of Biological and Chemical Sciences 
The University of Queensland 
St. Lucia Queensland 4072 
Australia

Room 320, Goddard Building (8)
T: +61 7 3365 2506 
email: S.Blomberg1_at_uq.edu.au 

The combination of some data and an aching desire for 
an answer does not ensure that a reasonable answer can 
be extracted from a given body of data. - John Tukey.


From s.blomberg1 at uq.edu.au  Mon Jun 25 09:57:33 2007
From: s.blomberg1 at uq.edu.au (Simon Blomberg)
Date: Mon, 25 Jun 2007 17:57:33 +1000
Subject: [R] ANOVA non-sphericity test and corrections (eg,
	Greenhouse-Geisser)
In-Reply-To: <1182758039.9054.20.camel@sib-sblomber01d.sib.uq.edu.au>
References: <1182711268.498914.61460@e9g2000prf.googlegroups.com>
	<467F5F17.4020707@biostat.ku.dk>
	<1182758039.9054.20.camel@sib-sblomber01d.sib.uq.edu.au>
Message-ID: <1182758253.9054.21.camel@sib-sblomber01d.sib.uq.edu.au>

On Mon, 2007-06-25 at 17:53 +1000, Simon Blomberg wrote:
> If you use lme, you can fit a general correlation structure to the
> within-subject data, and compare the fit to a model assuming
> uncorrelated within-subjects errors. That should tell you whether your
> data are ...

correlated... (damn email gremlins.)

> Aren't the G-G and H-F corrections only approximate fixes?
> Surely it is better to work with a model that actually fits your data,
> rather than using ad hoc adjustments towards a model that doesn't quite
> fit. But I'm no psychologist. :-)
> 
> Cheers,
> 
> Simon.
> 
>  On Mon, 2007-06-25 at 08:22 +0200, Peter Dalgaard wrote:
> > DarrenWeber wrote:
> > > I'm an experimental psychologist and when I run ANOVA analysis in
> > > SPSS, I normally ask for a test of non-sphericity (Box's M-test).  I
> > > also ask for output of the corrections for non-sphericity, such as
> > > Greenhouse-Geisser and Huhn-Feldt.  These tests and correction factors
> > > are commonly used in the journals for experimental and other
> > > psychology reports.  I have been switching from SPSS to R for over a
> > > year now, but I realize now that I don't have the non-sphericity test
> > > and correction factors.
> > >   
> > This can be done using anova.mlm() and mauchly.test()  which work on 
> > "mlm" objects, i.e., lm() output where the response is a matrix. There 
> > is no theory, to my knowledge, to support it for general aov() models, 
> > the catch being that you need to have a within-subject covariance matrix.
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
-- 
Simon Blomberg, BSc (Hons), PhD, MAppStat. 
Lecturer and Consultant Statistician 
Faculty of Biological and Chemical Sciences 
The University of Queensland 
St. Lucia Queensland 4072 
Australia

Room 320, Goddard Building (8)
T: +61 7 3365 2506 
email: S.Blomberg1_at_uq.edu.au 

The combination of some data and an aching desire for 
an answer does not ensure that a reasonable answer can 
be extracted from a given body of data. - John Tukey.


From ripley at stats.ox.ac.uk  Mon Jun 25 10:28:17 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 25 Jun 2007 09:28:17 +0100 (BST)
Subject: [R] R-2.5.0 compilation problem on Linux powerpc
In-Reply-To: <bf6a5a630706242110j57f408f1i8ee10425e78af804@mail.gmail.com>
References: <bf6a5a630706242110j57f408f1i8ee10425e78af804@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0706250920330.9061@gannet.stats.ox.ac.uk>

Is this ppc32 or ppc64?  (What does uname -a say?)

If the former, you might need to set CPICFLAGS and FPICFLAGS to -fPIC 
(rather than -fpic): please look these up in the R-admin.html file (which 
INSTALL points you to).

For ppc64 configure should have found -fPIC.

On Mon, 25 Jun 2007, Vivek Menon wrote:

> Hello everybody,I am having an error while compiling R-2.5.0 on Linux
> powerpc.
> This is what I see when I do a make:
>
>
> gcc -std=gnu99 -shared -L/usr/local/lib -o grDevices.so chull.o devNull.o
> devPicTeX.o devPS.o devQuartz.o init.o
> ../../../../library/grDevices/libs/grDevices.so is unchanged
> make[5]: Leaving directory
> `/home/vivekv/sw_alg/R-2.5.0/src/library/grDevices/src'
>
> make[4]: Leaving directory `/home/vivekv/sw_alg/R-2.5.0
> /src/library/grDevices/src'
> Warning: unable to load shared library '/home/vivekv/sw_alg/R-2.5.0
> /modules//lapack.so':
>  /home/vivekv/sw_alg/R- 2.5.0/modules//lapack.so: R_PPC_REL24 relocation at
> 0x0e65d7e4 for symbol `strlen' out of range
> Error in solve.default(rgb) : lapack routines cannot be loaded
> Error: unable to load R code in package 'grDevices'
> Execution halted
> make[3]: *** [all] Error 1
> make[3]: Leaving directory `/home/vivekv/sw_alg/R-2.5.0
> /src/library/grDevices'
> make[2]: *** [R] Error 1
> make[2]: Leaving directory `/home/vivekv/sw_alg/R- 2.5.0/src/library'
> make[1]: *** [R] Error 1
> make[1]: Leaving directory `/home/vivekv/sw_alg/R-2.5.0/src'
> make: *** [R] Error 1
>
> Please let me know what needs to be done for a successful installation.
> Thanks,
> Vivek
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ccleland at optonline.net  Mon Jun 25 10:28:27 2007
From: ccleland at optonline.net (Chuck Cleland)
Date: Mon, 25 Jun 2007 04:28:27 -0400
Subject: [R] adding lines to stripchart
In-Reply-To: <acb1f1cc0706241512w7865b424wd92003e843fd9d7@mail.gmail.com>
References: <acb1f1cc0706241512w7865b424wd92003e843fd9d7@mail.gmail.com>
Message-ID: <467F7CAB.2080109@optonline.net>

James Root wrote:
> I have two points of collection across 20 subjects (pre and post for each),
> so 20 pairs of data points.  I would like to plot the actual raw data points
> for each subject for both pre and post and connect lines between these two
> points (20 in all) to depict real change between the two timepoints.
> 
> I have tried using stripchart which adequately plots the two lines of
> subject data points.  Attempting to use segments however has been
> difficult.  It seems that the segments command gives too many coordiate
> points - so where segments has:
> 
> x0, y0, x1, y1
> 
> I really only have two coordinates for each point -
> 
> pre to post
> 
> I am sure that I am misusing the command but not sure if I should continue
> to try with segments or if there is another command that would be more
> appropriate.
> 
> As always, thanks for any help.

  Here is how you might use segments() and stripchart():

df <- data.frame(pre = runif(20), post = runif(20))

stripchart(x = list(df$pre, df$post), vertical=TRUE,
group.names=c("Pre","Post"))

for(i in 1:nrow(df)){segments(1, df$pre[i], 2, df$post[i])}

> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code. 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From nshephard at gmail.com  Mon Jun 25 12:14:40 2007
From: nshephard at gmail.com (Neil Shephard)
Date: Mon, 25 Jun 2007 11:14:40 +0100
Subject: [R] Re :  Half of a heatmap
Message-ID: <31b34fca0706250314l80c7deeucd0f3ff2997bd97@mail.gmail.com>

> I am trying to produce a heatmap of pairwise correlations, but since the matrix is
> symmetric, I only need either the upper or the lower triangle.  I have scoured the
> web and R documentation, but I have not been able to find a way to produce such a
> figure.  Is there a simple way to produce a heat map with only the part above or
> below the diagonal?

You might want to check out the LDheatmap() package which can generate
the plots you describe.  The help indicates that it accepts a matrix
of pair-wise linkage disequilibrium measures, one of which is R^2 (the
correlation coefficient between loci), but I suspect you could simply
pass it a matrix of correlation coefficents.

Hope that helps,

Neil
-- 
"In mathematics you don't understand things. You just get used to
them."  - Johann von Neumann

Email - nshephard at gmail.com / n.shephard at sheffield.ac.uk
Website - http://slack.ser.man.ac.uk/
Photos - http://www.flickr.com/photos/slackline/


From f.calboli at imperial.ac.uk  Mon Jun 25 14:03:15 2007
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Mon, 25 Jun 2007 13:03:15 +0100
Subject: [R] fractional calculations
Message-ID: <467FAF03.90104@imperial.ac.uk>

Hi All,

is there a function in R that allows me to work with fractions without 
transforming them to floats (or whatever) in between?

Something that would calculate something like:

(1/2 + 1/8) * 1/2 = 5/16

without ever transforming to 0.5 and 0.125?

Best,

Federico

-- 
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St Mary's Campus
Norfolk Place, London W2 1PG

Tel  +44 (0)20 7594 1602     Fax (+44) 020 7594 3193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com


From wwwhsd at gmail.com  Mon Jun 25 14:06:43 2007
From: wwwhsd at gmail.com (Henrique Dallazuanna)
Date: Mon, 25 Jun 2007 09:06:43 -0300
Subject: [R] fractional calculations
In-Reply-To: <467FAF03.90104@imperial.ac.uk>
References: <467FAF03.90104@imperial.ac.uk>
Message-ID: <da79af330706250506o16577cbeu81f4c09501682945@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070625/993a1de3/attachment.pl 

From singularitaet at gmx.net  Mon Jun 25 14:08:36 2007
From: singularitaet at gmx.net (Stefan Grosse)
Date: Mon, 25 Jun 2007 14:08:36 +0200
Subject: [R] fractional calculations
In-Reply-To: <467FAF03.90104@imperial.ac.uk>
References: <467FAF03.90104@imperial.ac.uk>
Message-ID: <467FB044.6030705@gmx.net>


> is there a function in R that allows me to work with fractions without 
> transforming them to floats (or whatever) in between?
>
>   

You could use the ryacas (CAS) package:
http://code.google.com/p/ryacas/
and/or
http://cran.r-project.org/doc/vignettes/Ryacas/Ryacas.pdf

e.g:
> library(Ryacas)
> yacas(expression((1/2 + 1/8) * 1/2 ))
[1] "Starting Yacas!"
expression(5/16)
>


Stefan

> Something that would calculate something like:
>
> (1/2 + 1/8) * 1/2 = 5/16
>
> without ever transforming to 0.5 and 0.125?
>


From rosenfel at cshl.edu  Mon Jun 25 14:20:38 2007
From: rosenfel at cshl.edu (Rosenfeld, Jeffrey)
Date: Mon, 25 Jun 2007 08:20:38 -0400
Subject: [R] Re :  Half of a heatmap
References: <31b34fca0706250314l80c7deeucd0f3ff2997bd97@mail.gmail.com>
Message-ID: <4A7F2400BAF11B4DBC4BF3D2046593E20188517F@mailbox05.cshl.edu>

Thank you for your reply.  I have looked at LDheatmap, but it does not seem to do what I want and seems to only work well for LD data.  I was looking for something that would produce a figure identical to what heatmap.2 gives me, including the proper X and Y-axis labels and a dendogram, except that it would only have half of the map.  Preferably, it would have the Color Key in the place where the other triangle of the heatmap would be, to save space.


Jeff


-----Original Message-----
From: Neil Shephard [mailto:nshephard at gmail.com]
Sent: Mon 6/25/2007 6:14 AM
To: r-help at stat.math.ethz.ch
Cc: Rosenfeld, Jeffrey
Subject: Re : [R] Half of a heatmap
 
> I am trying to produce a heatmap of pairwise correlations, but since the matrix is
> symmetric, I only need either the upper or the lower triangle.  I have scoured the
> web and R documentation, but I have not been able to find a way to produce such a
> figure.  Is there a simple way to produce a heat map with only the part above or
> below the diagonal?

You might want to check out the LDheatmap() package which can generate
the plots you describe.  The help indicates that it accepts a matrix
of pair-wise linkage disequilibrium measures, one of which is R^2 (the
correlation coefficient between loci), but I suspect you could simply
pass it a matrix of correlation coefficents.

Hope that helps,

Neil
-- 
"In mathematics you don't understand things. You just get used to
them."  - Johann von Neumann

Email - nshephard at gmail.com / n.shephard at sheffield.ac.uk
Website - http://slack.ser.man.ac.uk/
Photos - http://www.flickr.com/photos/slackline/


From peter.moser at statistik.ji.zh.ch  Mon Jun 25 14:25:12 2007
From: peter.moser at statistik.ji.zh.ch (peter.moser at statistik.ji.zh.ch)
Date: Mon, 25 Jun 2007 14:25:12 +0200
Subject: [R] =?iso-8859-1?q?Peter_Moser_ist_au=DFer_Haus=2E?=
Message-ID: <OFBDE6047E.AC19AE35-ONC1257305.004439BF-C1257305.004439BF@ji.zh.ch>


Ich werde ab  25.06.2007 nicht im B?ro sein. Ich kehre zur?ck am
28.06.2007.

in dringenden F?llen bin ich unter 079 79 73 74 6 erreichbar


From bw_6_28 at yahoo.com  Mon Jun 25 14:26:19 2007
From: bw_6_28 at yahoo.com (Bill Wheeler)
Date: Mon, 25 Jun 2007 05:26:19 -0700 (PDT)
Subject: [R] gam function in the mgcv library
Message-ID: <664980.73670.qm@web58112.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070625/4e4e97e9/attachment.pl 

From regina.verghis at gmail.com  Mon Jun 25 14:32:27 2007
From: regina.verghis at gmail.com (Regina Verghis)
Date: Mon, 25 Jun 2007 18:02:27 +0530
Subject: [R] Help in HMM for count data
Message-ID: <49f266b90706250532w12c376e5kb1ef9bfeaee4064f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070625/f4b7f94d/attachment.pl 

From f.calboli at imperial.ac.uk  Mon Jun 25 14:51:16 2007
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Mon, 25 Jun 2007 13:51:16 +0100
Subject: [R] fractional calculations
In-Reply-To: <da79af330706250506o16577cbeu81f4c09501682945@mail.gmail.com>
References: <467FAF03.90104@imperial.ac.uk>
	<da79af330706250506o16577cbeu81f4c09501682945@mail.gmail.com>
Message-ID: <467FBA44.4010207@imperial.ac.uk>

Henrique Dallazuanna wrote:
> require(MASS)
> ?as.fractions
> as.fractions(1/2+1/8)

I thought that as.fractions did transform the fractions *first* into floats and 
*then* found the rational approssimation (a passage I'd rather avoid):

fractions                package:MASS                R Documentation

Rational Approximation

Description:

      Find rational approximations to the components of a real numeric
      object using a standard continued fraction method.

/F
-- 
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St Mary's Campus
Norfolk Place, London W2 1PG

Tel  +44 (0)20 7594 1602     Fax (+44) 020 7594 3193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com


From erika.frigo at unimi.it  Mon Jun 25 14:47:57 2007
From: erika.frigo at unimi.it (Erika Frigo)
Date: Mon, 25 Jun 2007 14:47:57 +0200
Subject: [R] R-excel
Message-ID: <003901c7b727$0e321800$914e959f@erika>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070625/303e2b65/attachment.pl 

From singularitaet at gmx.net  Mon Jun 25 14:55:43 2007
From: singularitaet at gmx.net (Stefan Grosse)
Date: Mon, 25 Jun 2007 14:55:43 +0200
Subject: [R] R-excel
In-Reply-To: <003901c7b727$0e321800$914e959f@erika>
References: <003901c7b727$0e321800$914e959f@erika>
Message-ID: <467FBB4F.4010703@gmx.net>

http://cran.r-project.org/doc/manuals/R-data.html#Reading-Excel-spreadsheets

plus there is a package xlsReadWrite that might be of your interest.

Stefan

-------- Original Message  --------
Subject: [R] R-excel
From: Erika Frigo <erika.frigo at unimi.it>
To: r-help at stat.math.ethz.ch
Date: 25.06.2007 14:47
> Good morning to everybody,
> I have a problem : how can I import excel files in R???
>
> thank you very much
>
>
> Dr.sa. Erika Frigo
> Universit? degli Studi di Milano
> Facolt? di Medicina Veterinaria
> Dipartimento di Scienze e Tecnologie Veterinarie per la Sicurezza Alimentare (VSA)
>  
> Via Grasselli, 7
> 20137 Milano
> Tel. 02/50318515
> Fax 02/50318501
> 	[[alternative HTML version deleted]]
>
>   
> ------------------------------------------------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   
> ------------------------------------------------------------------------
>
> No virus found in this incoming message.
> Checked by AVG Free Edition. 
> Version: 7.5.472 / Virus Database: 269.9.6/865 - Release Date: 24.06.2007 08:33
>


From christophe at pallier.org  Mon Jun 25 14:56:16 2007
From: christophe at pallier.org (Christophe Pallier)
Date: Mon, 25 Jun 2007 14:56:16 +0200
Subject: [R] R-excel
In-Reply-To: <003901c7b727$0e321800$914e959f@erika>
References: <003901c7b727$0e321800$914e959f@erika>
Message-ID: <dea6cb960706250556w4d28df8aw6e77c309e11051aa@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070625/a74f4fa9/attachment.pl 

From s.wood at bath.ac.uk  Mon Jun 25 14:47:47 2007
From: s.wood at bath.ac.uk (Simon Wood)
Date: Mon, 25 Jun 2007 13:47:47 +0100
Subject: [R] gam function in the mgcv library
In-Reply-To: <664980.73670.qm@web58112.mail.re3.yahoo.com>
References: <664980.73670.qm@web58112.mail.re3.yahoo.com>
Message-ID: <200706251347.47228.s.wood@bath.ac.uk>

On Monday 25 June 2007 13:26, Bill Wheeler wrote:
> I would like to fit a logistic regression using a smothing spline, where
> the spline is a piecewise cubic polynomial. Is the knots option used to
> define the subintervals for each piece of the cubic spline? 
- if you use something like 
gam(y~s(x,bs="cr",k=5),family=binomial,knots=list(x=c(0,.1,.3,.4,.8))
then yes, k is the number of knots and the `knots' list specifies where they 
occur. If you use the default `bs="tp"' then the spline basis functions are 
not really `knot' based, being instead an ordered set of eigenfunctions, that 
are optimal in a defined sense (see Wood, 2003, JRSSB).

> If yes and 
> there are k knots, then why does the coefficients field in the returned
> object from gam only list k coefficients? Shouldn't there be 4k -4
> coefficients?

A k knot natural cubic spline only has k free coefficients, so that is all 
that mgcv:gam reports. If you are thinking about sections of cubic, then the 
other 3 coefficients of each section are determined by the spline  continuity 
conditions + the conditions of having zero second derivative at the end 
knots. Exact details of the `mgcv' "cr" basis are given in section 4.1.2 of 
my 2006  book (see ?gam), but all you really need to know is that it's a 
natural cubic spline basis parameterized in terms of function heights at the 
knots (although there  is a gam identifiability constraint absorbed into the 
parameterization which muddies this neat interpretability a little). 

best,
Simon


> Sincerely,
>
> Bill
>
>
> ---------------------------------
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented, minimal,
> self-contained, reproducible code.

-- 
> Simon Wood, Mathematical Sciences, University of Bath, Bath, BA2 7AY UK
> +44 1225 386603  www.maths.bath.ac.uk/~sw283


From christoph.heibl at gmx.net  Mon Jun 25 15:13:02 2007
From: christoph.heibl at gmx.net (Christoph Heibl)
Date: Mon, 25 Jun 2007 15:13:02 +0200
Subject: [R] transposing data.frames
Message-ID: <3D0E64A9-E480-4286-85E9-2CAF32A1210E@gmx.net>

Hello,
This must be simple...
Thanks a lot
- Christoph

# Imagine you have a list, e.g:

K <- list(1:10, 2:11, 9:18)
K

# Transforming to dataframe...

KK <- as.data.frame(K)

# ... one obtaines the list elements as column.

KK

# But I need the list elements as rows
# How can I achieve this? Is there a simple way to transpose  
data.frames?


From vivek.menon79 at gmail.com  Mon Jun 25 15:18:17 2007
From: vivek.menon79 at gmail.com (Vivek Menon)
Date: Mon, 25 Jun 2007 09:18:17 -0400
Subject: [R] R-2.5.0 compilation problem on Linux powerpc
In-Reply-To: <Pine.LNX.4.64.0706250920330.9061@gannet.stats.ox.ac.uk>
References: <bf6a5a630706242110j57f408f1i8ee10425e78af804@mail.gmail.com>
	<Pine.LNX.4.64.0706250920330.9061@gannet.stats.ox.ac.uk>
Message-ID: <bf6a5a630706250618wb012dcrcbcef9dd1f492625@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070625/b01fc891/attachment.pl 

From singularitaet at gmx.net  Mon Jun 25 15:20:05 2007
From: singularitaet at gmx.net (Stefan Grosse)
Date: Mon, 25 Jun 2007 15:20:05 +0200
Subject: [R] transposing data.frames
In-Reply-To: <3D0E64A9-E480-4286-85E9-2CAF32A1210E@gmx.net>
References: <3D0E64A9-E480-4286-85E9-2CAF32A1210E@gmx.net>
Message-ID: <467FC105.9040505@gmx.net>


-------- Original Message  --------
Subject: [R] transposing data.frames
From: Christoph Heibl <christoph.heibl at gmx.net>
To: R-help at stat.math.ethz.ch
Date: 25.06.2007 15:13
> Hello,
> This must be simple...
> Thanks a lot
> - Christoph
>
> # Imagine you have a list, e.g:
>
> K <- list(1:10, 2:11, 9:18)
> K
>
> # Transforming to dataframe...
>
> KK <- as.data.frame(K)
>
> # ... one obtaines the list elements as column.
>
> KK
>
> # But I need the list elements as rows
> # How can I achieve this? Is there a simple way to transpose  
> data.frames?
>   

yes:
t(as.data.frame(K))

> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>


From ripley at stats.ox.ac.uk  Mon Jun 25 15:22:08 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 25 Jun 2007 14:22:08 +0100 (BST)
Subject: [R] R-2.5.0 compilation problem on Linux powerpc
In-Reply-To: <bf6a5a630706250618wb012dcrcbcef9dd1f492625@mail.gmail.com>
References: <bf6a5a630706242110j57f408f1i8ee10425e78af804@mail.gmail.com> 
	<Pine.LNX.4.64.0706250920330.9061@gannet.stats.ox.ac.uk>
	<bf6a5a630706250618wb012dcrcbcef9dd1f492625@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0706251420080.13087@gannet.stats.ox.ac.uk>

On Mon, 25 Jun 2007, Vivek Menon wrote:

> uname -a gives me this:==========
> Linux XXXXXXXX 2.6.21.1-xserve #17 SMP Thu Jun 14 19:45:57 MDT 2007 ppc64
> ppc64 ppc64 GNU/Linux
> ===========
> Also when I configure I see the foll. output:
> ====================
> R is now configured for powerpc64-unknown-linux-gnu

That might be the problem: 'powerpc64' not 'ppc64'.  What Linux distro is 
this?

> Source directory:          .
> Installation directory:    /usr/local
>
> C compiler:                gcc -std=gnu99  -g -O2
> Fortran 77 compiler:       gfortran  -g -O2
>
> C++ compiler:              g++  -g -O2
> Fortran 90/95 compiler:    gfortran -g -O2
> Obj-C compiler:
>
> Interfaces supported:
> External libraries:        readline
> Additional capabilities:   PNG, iconv, MBCS, NLS
> Options enabled:           shared BLAS, R profiling, Java
>
> Recommended packages:      yes
> ============================
> Do you have any suggestions??

And what is the setting of the flags I mentioned?  See the manual I 
pointed you to, or the Makeconf file?


> Thanks,
> Vivek
> On 6/25/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>> 
>> Is this ppc32 or ppc64?  (What does uname -a say?)
>> 
>> If the former, you might need to set CPICFLAGS and FPICFLAGS to -fPIC
>> (rather than -fpic): please look these up in the R-admin.html file (which
>> INSTALL points you to).
>> 
>> For ppc64 configure should have found -fPIC.
>> 
>> On Mon, 25 Jun 2007, Vivek Menon wrote:
>> 
>> > Hello everybody,I am having an error while compiling R-2.5.0 on Linux
>> > powerpc.
>> > This is what I see when I do a make:
>> >
>> >
>> > gcc -std=gnu99 -shared -L/usr/local/lib -o grDevices.so chull.o
>> devNull.o
>> > devPicTeX.o devPS.o devQuartz.o init.o
>> > ../../../../library/grDevices/libs/grDevices.so is unchanged
>> > make[5]: Leaving directory
>> > `/home/vivekv/sw_alg/R-2.5.0/src/library/grDevices/src'
>> >
>> > make[4]: Leaving directory `/home/vivekv/sw_alg/R-2.5.0
>> > /src/library/grDevices/src'
>> > Warning: unable to load shared library '/home/vivekv/sw_alg/R-2.5.0
>> > /modules//lapack.so':
>> >  /home/vivekv/sw_alg/R- 2.5.0/modules//lapack.so: R_PPC_REL24 relocation
>> at
>> > 0x0e65d7e4 for symbol `strlen' out of range
>> > Error in solve.default(rgb) : lapack routines cannot be loaded
>> > Error: unable to load R code in package 'grDevices'
>> > Execution halted
>> > make[3]: *** [all] Error 1
>> > make[3]: Leaving directory `/home/vivekv/sw_alg/R-2.5.0
>> > /src/library/grDevices'
>> > make[2]: *** [R] Error 1
>> > make[2]: Leaving directory `/home/vivekv/sw_alg/R- 2.5.0/src/library'
>> > make[1]: *** [R] Error 1
>> > make[1]: Leaving directory `/home/vivekv/sw_alg/R-2.5.0/src'
>> > make: *** [R] Error 1
>> >
>> > Please let me know what needs to be done for a successful installation.
>> > Thanks,
>> > Vivek
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at stat.math.ethz.ch mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>> 
>> 
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>> 
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mothsailor at googlemail.com  Mon Jun 25 15:24:00 2007
From: mothsailor at googlemail.com (David Barron)
Date: Mon, 25 Jun 2007 14:24:00 +0100
Subject: [R] transposing data.frames
In-Reply-To: <3D0E64A9-E480-4286-85E9-2CAF32A1210E@gmx.net>
References: <3D0E64A9-E480-4286-85E9-2CAF32A1210E@gmx.net>
Message-ID: <815b70590706250624i74ba61ban56db548e5f2152d7@mail.gmail.com>

t(KK) will transpose your data frame

On 25/06/07, Christoph Heibl <christoph.heibl at gmx.net> wrote:
> Hello,
> This must be simple...
> Thanks a lot
> - Christoph
>
> # Imagine you have a list, e.g:
>
> K <- list(1:10, 2:11, 9:18)
> K
>
> # Transforming to dataframe...
>
> KK <- as.data.frame(K)
>
> # ... one obtaines the list elements as column.
>
> KK
>
> # But I need the list elements as rows
> # How can I achieve this? Is there a simple way to transpose
> data.frames?
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
=================================
David Barron
Said Business School
University of Oxford
Park End Street
Oxford OX1 1HP


From rguha at indiana.edu  Mon Jun 25 15:27:51 2007
From: rguha at indiana.edu (Rajarshi Guha)
Date: Mon, 25 Jun 2007 09:27:51 -0400
Subject: [R] JRI and Axis Web Service
In-Reply-To: <4B518E6046247D418A5B86BB5B08389A79372B@UXCHANGE3.UoA.auckland.ac.nz>
References: <4B518E6046247D418A5B86BB5B08389A79372B@UXCHANGE3.UoA.auckland.ac.nz>
Message-ID: <75D28401-06E6-42D5-8CDE-18219B5A0F6B@indiana.edu>


On Jun 24, 2007, at 7:58 PM, Yifan (Eric) Jiang wrote:

> I've been asked to develop a Java Axis web service to retrieve an
> R-script file from the client side and then using JRI jar file in  
> order
> to call the R program that installed on the web service server. After
> reading the online documentation, I've successfully installed the R
> program with rJava and JRI packages. In addition, I can call the R
> program to run the R-script by using org.rosuda.JRI.Rengine.  
> Everything
> is running fine if this program is running as a normal Java  
> application.
> However, I fail to obtain any return when I was trying to consume this
> method by using the Java Axis web service.
>
>
>
> So I am wondering if any one could share their experiences to using  
> JRI
> in Axis web service. Your helps mean a lot to me and I've been  
> struggled
> to fix this problem for days.

We have developed a distributed computational infrastructure using R  
(and JRI) as the backend coupled with AXIS web services and have  
built a number of clients on top of this.

You can browse the source code for the services from the Sourceforge  
repository located at
http://svn.sourceforge.net/viewvc/cicc-grid/cicc-grid/rws/trunk/  
(though the R code in the repository has not been updated recently)

Examples of what functionality is available via the web services can  
be found at http://www.chembiogrid.org/projects/proj_statistics.html

The page also lists a number of clients that make use of the web  
service infrastructure.

-------------------------------------------------------------------
Rajarshi Guha  <rguha at indiana.edu>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04  06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
I'm related to people I don't relate to."
                 -Calvin


From vivek.menon79 at gmail.com  Mon Jun 25 16:03:18 2007
From: vivek.menon79 at gmail.com (Vivek Menon)
Date: Mon, 25 Jun 2007 10:03:18 -0400
Subject: [R] R-2.5.0 compilation problem on Linux powerpc
In-Reply-To: <Pine.LNX.4.64.0706251420080.13087@gannet.stats.ox.ac.uk>
References: <bf6a5a630706242110j57f408f1i8ee10425e78af804@mail.gmail.com>
	<Pine.LNX.4.64.0706250920330.9061@gannet.stats.ox.ac.uk>
	<bf6a5a630706250618wb012dcrcbcef9dd1f492625@mail.gmail.com>
	<Pine.LNX.4.64.0706251420080.13087@gannet.stats.ox.ac.uk>
Message-ID: <bf6a5a630706250703j3038d896nbd08245f955fab89@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070625/e97c5d3f/attachment.pl 

From vivek.menon79 at gmail.com  Mon Jun 25 16:20:54 2007
From: vivek.menon79 at gmail.com (Vivek Menon)
Date: Mon, 25 Jun 2007 10:20:54 -0400
Subject: [R] R-2.5.0 compilation problem on Linux powerpc
In-Reply-To: <bf6a5a630706250703j3038d896nbd08245f955fab89@mail.gmail.com>
References: <bf6a5a630706242110j57f408f1i8ee10425e78af804@mail.gmail.com>
	<Pine.LNX.4.64.0706250920330.9061@gannet.stats.ox.ac.uk>
	<bf6a5a630706250618wb012dcrcbcef9dd1f492625@mail.gmail.com>
	<Pine.LNX.4.64.0706251420080.13087@gannet.stats.ox.ac.uk>
	<bf6a5a630706250703j3038d896nbd08245f955fab89@mail.gmail.com>
Message-ID: <bf6a5a630706250720x63000e7n681dd81059d380d0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070625/4e93f289/attachment.pl 

From ripley at stats.ox.ac.uk  Mon Jun 25 16:28:43 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 25 Jun 2007 15:28:43 +0100 (BST)
Subject: [R] R-2.5.0 compilation problem on Linux powerpc
In-Reply-To: <bf6a5a630706250703j3038d896nbd08245f955fab89@mail.gmail.com>
References: <bf6a5a630706242110j57f408f1i8ee10425e78af804@mail.gmail.com> 
	<Pine.LNX.4.64.0706250920330.9061@gannet.stats.ox.ac.uk> 
	<bf6a5a630706250618wb012dcrcbcef9dd1f492625@mail.gmail.com> 
	<Pine.LNX.4.64.0706251420080.13087@gannet.stats.ox.ac.uk>
	<bf6a5a630706250703j3038d896nbd08245f955fab89@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0706251520500.13807@gannet.stats.ox.ac.uk>

On Mon, 25 Jun 2007, Vivek Menon wrote:

>> 
>> 
>> > uname -a gives me this:==========
>> > Linux XXXXXXXX 2.6.21.1-xserve #17 SMP Thu Jun 14 19:45:57 MDT 2007
>> ppc64
>> > ppc64 ppc64 GNU/Linux
>> > ===========
>> > Also when I configure I see the foll. output:
>> > ====================
>> > R is now configured for powerpc64-unknown-linux-gnu
>> 
>> That might be the problem: 'powerpc64' not 'ppc64'.  What Linux distro is
>> this?
>
>
> I am using Yellow Dog Linux distro.
>
>> Source directory:          .
>> > Installation directory:    /usr/local
>> >
>> > C compiler:                gcc -std=gnu99  -g -O2
>> > Fortran 77 compiler:       gfortran  -g -O2
>> >
>> > C++ compiler:              g++  -g -O2
>> > Fortran 90/95 compiler:    gfortran -g -O2
>> > Obj-C compiler:
>> >
>> > Interfaces supported:
>> > External libraries:        readline
>> > Additional capabilities:   PNG, iconv, MBCS, NLS
>> > Options enabled:           shared BLAS, R profiling, Java
>> >
>> > Recommended packages:      yes
>> > ============================
>> > Do you have any suggestions??
>> 
>> And what is the setting of the flags I mentioned?  See the manual I
>> pointed you to, or the Makeconf file?
>
>
> I checked the Makeconf file and found the following settings:
> CPICFLAGS = -fpic
> FPICFLAGS = -fpic

So my comment in the first reply applied, since it looks like your distro 
is using an unusual name.  You need to change these (and in etc/Makeconf).

> Thanks,
> Vivek
>
>
>> Thanks,
>> > Vivek
>> > On 6/25/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>> >>
>> >> Is this ppc32 or ppc64?  (What does uname -a say?)
>> >>
>> >> If the former, you might need to set CPICFLAGS and FPICFLAGS to -fPIC
>> >> (rather than -fpic): please look these up in the R-admin.html file
>> (which
>> >> INSTALL points you to).
>> >>
>> >> For ppc64 configure should have found -fPIC.
>> >>
>> >> On Mon, 25 Jun 2007, Vivek Menon wrote:
>> >>
>> >> > Hello everybody,I am having an error while compiling R-2.5.0 on Linux
>> >> > powerpc.
>> >> > This is what I see when I do a make:
>> >> >
>> >> >
>> >> > gcc -std=gnu99 -shared -L/usr/local/lib -o grDevices.so chull.o
>> >> devNull.o
>> >> > devPicTeX.o devPS.o devQuartz.o init.o
>> >> > ../../../../library/grDevices/libs/grDevices.so is unchanged
>> >> > make[5]: Leaving directory
>> >> > `/home/vivekv/sw_alg/R-2.5.0/src/library/grDevices/src'
>> >> >
>> >> > make[4]: Leaving directory `/home/vivekv/sw_alg/R-2.5.0
>> >> > /src/library/grDevices/src'
>> >> > Warning: unable to load shared library '/home/vivekv/sw_alg/R-2.5.0
>> >> > /modules//lapack.so':
>> >> >  /home/vivekv/sw_alg/R- 2.5.0/modules//lapack.so: R_PPC_REL24
>> relocation
>> >> at
>> >> > 0x0e65d7e4 for symbol `strlen' out of range
>> >> > Error in solve.default(rgb) : lapack routines cannot be loaded
>> >> > Error: unable to load R code in package 'grDevices'
>> >> > Execution halted
>> >> > make[3]: *** [all] Error 1
>> >> > make[3]: Leaving directory `/home/vivekv/sw_alg/R-2.5.0
>> >> > /src/library/grDevices'
>> >> > make[2]: *** [R] Error 1
>> >> > make[2]: Leaving directory `/home/vivekv/sw_alg/R- 2.5.0/src/library'
>> >> > make[1]: *** [R] Error 1
>> >> > make[1]: Leaving directory `/home/vivekv/sw_alg/R-2.5.0/src'
>> >> > make: *** [R] Error 1
>> >> >
>> >> > Please let me know what needs to be done for a successful
>> installation.
>> >> > Thanks,
>> >> > Vivek
>> >> >
>> >> >       [[alternative HTML version deleted]]
>> >> >
>> >> > ______________________________________________
>> >> > R-help at stat.math.ethz.ch mailing list
>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > PLEASE do read the posting guide http://www.R-project.org/posting-
>> >> guide.html
>> >> > and provide commented, minimal, self-contained, reproducible code.
>> >> >
>> >>
>> >>
>> >> --
>> >> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> >> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> >> University of Oxford,             Tel:  +44 1865 272861 (self)
>> >> 1 South Parks Road,                     +44 1865 272866 (PA)
>> >> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>> >>
>> >
>> 
>> 
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Mon Jun 25 16:36:55 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 25 Jun 2007 15:36:55 +0100 (BST)
Subject: [R] fractional calculations
In-Reply-To: <da79af330706250506o16577cbeu81f4c09501682945@mail.gmail.com>
References: <467FAF03.90104@imperial.ac.uk>
	<da79af330706250506o16577cbeu81f4c09501682945@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0706251531020.13807@gannet.stats.ox.ac.uk>

On Mon, 25 Jun 2007, Henrique Dallazuanna wrote:

> require(MASS)
> ?as.fractions
> as.fractions(1/2+1/8)

I think Federico wanted

1/as.fractions(2) + 1/as.fractions(8)

that is avoiding computing 1/8 in float (although it is exact).

You might be better off with package gmp:

> 1/as.bigq(2) + 1/as.bigq(8)
[1] "5/8"

allows you to handle arbitrarily large fractions.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From bbernzwe at bear.com  Mon Jun 25 16:45:51 2007
From: bbernzwe at bear.com (Bernzweig, Bruce (Consultant))
Date: Mon, 25 Jun 2007 10:45:51 -0400
Subject: [R] R behaviour related to user input (readline()) and run selection
Message-ID: <CADFD0E28E1E6A46B0C84335BDB994F503EB313F@whexchmb16.bsna.bsroot.bear.com>

When I run the below section of code I get the following error: 

 

       Error in if (co == "A" || co[1] == "O") { : 

              missing value where TRUE/FALSE needed

 

When I run the code in two parts where I first get the user's input

then afterwards run the if/else section, there is no problem.

 

Is there a way to stop the "run selection" process until the user

has input a value?

 

------------------------------------------------------------------------
-----



       calc_option <- function(){

              msg <- cat("Please select an option:\n"," 'O'ne or 'A'll':
")

              co <- readline(msg)

              

              switch(co,

                     O = "O", o = "O",

                     A = "A", a = "A"

              )

       }

       

       co <- calc_option()



       if (co == "A" || co[1] == "O") {

              print(paste("calc_option = ", co))

       } else {

              print("calc_option is not acceptable")

       }





Thanks,



- Bruce

-------------- next part --------------


**********************************************************************
Please be aware that, notwithstanding the fact that the pers...{{dropped}}


From vivek.menon79 at gmail.com  Mon Jun 25 16:48:30 2007
From: vivek.menon79 at gmail.com (Vivek Menon)
Date: Mon, 25 Jun 2007 10:48:30 -0400
Subject: [R] R-2.5.0 compilation problem on Linux powerpc
In-Reply-To: <Pine.LNX.4.64.0706251520500.13807@gannet.stats.ox.ac.uk>
References: <bf6a5a630706242110j57f408f1i8ee10425e78af804@mail.gmail.com>
	<Pine.LNX.4.64.0706250920330.9061@gannet.stats.ox.ac.uk>
	<bf6a5a630706250618wb012dcrcbcef9dd1f492625@mail.gmail.com>
	<Pine.LNX.4.64.0706251420080.13087@gannet.stats.ox.ac.uk>
	<bf6a5a630706250703j3038d896nbd08245f955fab89@mail.gmail.com>
	<Pine.LNX.4.64.0706251520500.13807@gannet.stats.ox.ac.uk>
Message-ID: <bf6a5a630706250748n71df0ba6k4b4abf498b710964@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070625/4982a263/attachment.pl 

From helprhelp at gmail.com  Mon Jun 25 16:50:25 2007
From: helprhelp at gmail.com (Weiwei Shi)
Date: Mon, 25 Jun 2007 10:50:25 -0400
Subject: [R] how to plot this?
Message-ID: <cdf817830706250750yad67f59m778f6bd43124582a@mail.gmail.com>

Hi, there:

Suppose I have a couple of data.frames and each one has five columns
(one for x-axis, two for y-axis and two for std of y's.) There is
another dimensions (besides x and y) which is continuous. My question
is, how to plot such series of data frames in one plot (thus,
3-dimensional plot) AND multiple 2-D plots. I am not familar with R's
plotting utilities.

Thanks.

-- 
Weiwei Shi, Ph.D
Research Scientist
GeneGO, Inc.

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III


From dieter.menne at menne-biomed.de  Mon Jun 25 17:04:27 2007
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Mon, 25 Jun 2007 17:04:27 +0200
Subject: [R] eps in odfWeave
Message-ID: <LPEJLJACLINDNMBMFAFIMEEICIAA.dieter.menne@menne-biomed.de>

Dear Weavers,

Does someone have an example of using eps or any other vector graphics with
odfWeave? It tried the example below (and commented variants) with
simple.odt in the examples directory, and got an error.

Dieter


#---
library(odfWeave)
plotInfo <- getImageDefs()
plotInfo$type = "eps"
#plotInfo$device = "postscript"
setImageDefs(plotInfo)
odfWeave("simple.odt", "simpleOut.odt")
#-----

#  Writing to file content_1.xml
#  Processing code chunks ...
#    1 : term hide(label=loadLibs)
#    2 : term xml(label=showOutputList)
#Error in check(options) : invalid value for 'type' : eps

Version: 0.5.9
Date: 2007-20-06

platform       i386-pc-mingw32
arch           i386
os             mingw32
system         i386, mingw32
status
major          2
minor          5.0
year           2007
month          04
day            23
svn rev        41293
language       R
version.string R version 2.5.0 (2007-04-23)


From ripley at stats.ox.ac.uk  Mon Jun 25 17:19:47 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 25 Jun 2007 16:19:47 +0100 (BST)
Subject: [R] R-2.5.0 compilation problem on Linux powerpc
In-Reply-To: <bf6a5a630706250748n71df0ba6k4b4abf498b710964@mail.gmail.com>
References: <bf6a5a630706242110j57f408f1i8ee10425e78af804@mail.gmail.com> 
	<Pine.LNX.4.64.0706250920330.9061@gannet.stats.ox.ac.uk> 
	<bf6a5a630706250618wb012dcrcbcef9dd1f492625@mail.gmail.com> 
	<Pine.LNX.4.64.0706251420080.13087@gannet.stats.ox.ac.uk> 
	<bf6a5a630706250703j3038d896nbd08245f955fab89@mail.gmail.com> 
	<Pine.LNX.4.64.0706251520500.13807@gannet.stats.ox.ac.uk>
	<bf6a5a630706250748n71df0ba6k4b4abf498b710964@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0706251619290.20653@auk.stats>

On Mon, 25 Jun 2007, Vivek Menon wrote:

> I did not get what you replied in the previous email. I still get the same
> error with CPICFLAGS and FPICFLAGS set to -fPIC.

And a completely fresh build?

> Vivek
>
> On 6/25/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>> 
>> On Mon, 25 Jun 2007, Vivek Menon wrote:
>> 
>> >>
>> >>
>> >> > uname -a gives me this:==========
>> >> > Linux XXXXXXXX 2.6.21.1-xserve #17 SMP Thu Jun 14 19:45:57 MDT 2007
>> >> ppc64
>> >> > ppc64 ppc64 GNU/Linux
>> >> > ===========
>> >> > Also when I configure I see the foll. output:
>> >> > ====================
>> >> > R is now configured for powerpc64-unknown-linux-gnu
>> >>
>> >> That might be the problem: 'powerpc64' not 'ppc64'.  What Linux distro
>> is
>> >> this?
>> >
>> >
>> > I am using Yellow Dog Linux distro.
>> >
>> >> Source directory:          .
>> >> > Installation directory:    /usr/local
>> >> >
>> >> > C compiler:                gcc -std=gnu99  -g -O2
>> >> > Fortran 77 compiler:       gfortran  -g -O2
>> >> >
>> >> > C++ compiler:              g++  -g -O2
>> >> > Fortran 90/95 compiler:    gfortran -g -O2
>> >> > Obj-C compiler:
>> >> >
>> >> > Interfaces supported:
>> >> > External libraries:        readline
>> >> > Additional capabilities:   PNG, iconv, MBCS, NLS
>> >> > Options enabled:           shared BLAS, R profiling, Java
>> >> >
>> >> > Recommended packages:      yes
>> >> > ============================
>> >> > Do you have any suggestions??
>> >>
>> >> And what is the setting of the flags I mentioned?  See the manual I
>> >> pointed you to, or the Makeconf file?
>> >
>> >
>> > I checked the Makeconf file and found the following settings:
>> > CPICFLAGS = -fpic
>> > FPICFLAGS = -fpic
>> 
>> So my comment in the first reply applied, since it looks like your distro
>> is using an unusual name.  You need to change these (and in etc/Makeconf).
>> 
>> > Thanks,
>> > Vivek
>> >
>> >
>> >> Thanks,
>> >> > Vivek
>> >> > On 6/25/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>> >> >>
>> >> >> Is this ppc32 or ppc64?  (What does uname -a say?)
>> >> >>
>> >> >> If the former, you might need to set CPICFLAGS and FPICFLAGS to
>> -fPIC
>> >> >> (rather than -fpic): please look these up in the R-admin.html file
>> >> (which
>> >> >> INSTALL points you to).
>> >> >>
>> >> >> For ppc64 configure should have found -fPIC.
>> >> >>
>> >> >> On Mon, 25 Jun 2007, Vivek Menon wrote:
>> >> >>
>> >> >> > Hello everybody,I am having an error while compiling R-2.5.0 on
>> Linux
>> >> >> > powerpc.
>> >> >> > This is what I see when I do a make:
>> >> >> >
>> >> >> >
>> >> >> > gcc -std=gnu99 -shared -L/usr/local/lib -o grDevices.so chull.o
>> >> >> devNull.o
>> >> >> > devPicTeX.o devPS.o devQuartz.o init.o
>> >> >> > ../../../../library/grDevices/libs/grDevices.so is unchanged
>> >> >> > make[5]: Leaving directory
>> >> >> > `/home/vivekv/sw_alg/R-2.5.0/src/library/grDevices/src'
>> >> >> >
>> >> >> > make[4]: Leaving directory `/home/vivekv/sw_alg/R-2.5.0
>> >> >> > /src/library/grDevices/src'
>> >> >> > Warning: unable to load shared library '/home/vivekv/sw_alg/R-
>> 2.5.0
>> >> >> > /modules//lapack.so':
>> >> >> >  /home/vivekv/sw_alg/R- 2.5.0/modules//lapack.so: R_PPC_REL24
>> >> relocation
>> >> >> at
>> >> >> > 0x0e65d7e4 for symbol `strlen' out of range
>> >> >> > Error in solve.default(rgb) : lapack routines cannot be loaded
>> >> >> > Error: unable to load R code in package 'grDevices'
>> >> >> > Execution halted
>> >> >> > make[3]: *** [all] Error 1
>> >> >> > make[3]: Leaving directory `/home/vivekv/sw_alg/R-2.5.0
>> >> >> > /src/library/grDevices'
>> >> >> > make[2]: *** [R] Error 1
>> >> >> > make[2]: Leaving directory `/home/vivekv/sw_alg/R- 2.5.0
>> /src/library'
>> >> >> > make[1]: *** [R] Error 1
>> >> >> > make[1]: Leaving directory `/home/vivekv/sw_alg/R-2.5.0/src'
>> >> >> > make: *** [R] Error 1
>> >> >> >
>> >> >> > Please let me know what needs to be done for a successful
>> >> installation.
>> >> >> > Thanks,
>> >> >> > Vivek
>> >> >> >
>> >> >> >       [[alternative HTML version deleted]]
>> >> >> >
>> >> >> > ______________________________________________
>> >> >> > R-help at stat.math.ethz.ch mailing list
>> >> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >> > PLEASE do read the posting guide http://www.R-project.org/posting-
>> >> >> guide.html
>> >> >> > and provide commented, minimal, self-contained, reproducible code.
>> >> >> >
>> >> >>
>> >> >>
>> >> >> --
>> >> >> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> >> >> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> >> >> University of Oxford,             Tel:  +44 1865 272861 (self)
>> >> >> 1 South Parks Road,                     +44 1865 272866 (PA)
>> >> >> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>> >> >>
>> >> >
>> >>
>> >>
>> >
>> 
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>> 
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pomchip at free.fr  Mon Jun 25 17:21:14 2007
From: pomchip at free.fr (=?ISO-8859-1?Q?S=E9bastien?=)
Date: Mon, 25 Jun 2007 11:21:14 -0400
Subject: [R] R-excel
In-Reply-To: <003901c7b727$0e321800$914e959f@erika>
References: <003901c7b727$0e321800$914e959f@erika>
Message-ID: <467FDD6A.6050606@free.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070625/58108f8a/attachment.pl 

From Achim.Zeileis at wu-wien.ac.at  Mon Jun 25 17:34:12 2007
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Mon, 25 Jun 2007 17:34:12 +0200 (CEST)
Subject: [R] Imputing missing values in time series
In-Reply-To: <467BDCAD020000650000693F@pgn.com>
Message-ID: <Pine.LNX.4.44.0706251727140.25241-100000@disco.wu-wien.ac.at>

On Fri, 22 Jun 2007, Horace Tso wrote:

> Thanks to Mark and Erik for different versions of locf, also Erik's
> pointer to archive where I found another function due to Simon Fear. I
> haven't tested the zoo locf function.

Just as an addition to what Marc already wrote:

"zoo" offers at least two advantages here:
  - it does not break if the first element is NA
  - if available it incorporates the corresponding time stamps

When we wrote na.locf(), Gabor also tried to optimize it for speed. I
haven't compared it to the solutions suggested here but would be surprised
if any of them would substantially faster.

As for your time series, I would recommend that you hold it as a "zoo"
series with "Date" time stamps. See
  vignette("zoo-quickref", package = "zoo")
  vignette("zoo", package = "zoo")
for some examples of "zoo" series in general and na.locf() in particular.
Z


From helprhelp at gmail.com  Mon Jun 25 17:42:51 2007
From: helprhelp at gmail.com (Weiwei Shi)
Date: Mon, 25 Jun 2007 11:42:51 -0400
Subject: [R] a string to enviroment or function
Message-ID: <cdf817830706250842l3dd9a812v14c94a7609d18225@mail.gmail.com>

Hi,

I am wondering how to make a function Fun to make the following work:

t0 <- (paste("hgu133a", "ENTREZID", sep=""))
xx <- as.list(Fun(t0)) # make it work like xx<-as.list(hgu133aENTREZID)

thanks,
-- 
Weiwei Shi, Ph.D
Research Scientist
GeneGO, Inc.

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III


From Max.Kuhn at pfizer.com  Mon Jun 25 17:44:11 2007
From: Max.Kuhn at pfizer.com (Kuhn, Max)
Date: Mon, 25 Jun 2007 11:44:11 -0400
Subject: [R] eps in odfWeave
In-Reply-To: <LPEJLJACLINDNMBMFAFIMEEICIAA.dieter.menne@menne-biomed.de>
Message-ID: <71257D09F114DA4A8E134DEAC70F25D308C0401F@groamrexm03.amer.pfizer.com>

Dieter,

What is the version of odfWeave? If you use those specifications in the
current version (0.5.9):

> plotInfo <- getImageDefs()
> plotInfo$type = "eps"
> plotInfo$device = "postscript"
> setImageDefs(plotInfo)
you will probabiliy need to set 
horizontal = FALSE, onefile = FALSE, and paper = "special" to generate
ps graphics for OpenOffice
an image size of 480 inches by 480 inches has been requested.
> setImageDefs(plotInfo)

When I run somewhat altered options:

> plotInfo <- getImageDefs()
> plotInfo$type = "eps"
> plotInfo$plotWidth = 4
> plotInfo$plotHeight = 4
> plotInfo$device = "postscript"
> plotInfo$args = list(
+    horizontal = FALSE, 
+    onefile = FALSE, 
+    paper = "special")
> setImageDefs(plotInfo)
> 
> demoFile <- system.file("examples", "simple.odt", package =
"odfWeave")
> odfWeave(demoFile, "c:/simpleOut.odt")
  Copying  C:/PROGRA~1/R/R250/library/odfWeave/examples/simple.odt 
  Setting wd to
C:\DOCUME~1\KuhnA03\LOCALS~1\Temp\Rtmpp4Zcsb/odfWeave25113622566 
<snip>
  Copying  simple.odt 
  Resetting wd
  Removing
C:\DOCUME~1\KuhnA03\LOCALS~1\Temp\Rtmpp4Zcsb/odfWeave25113622566 

  Done
> 

There were some issues with eps and older versions of odfWeave, but I
don't recall that specific error. 

[The only other "issue" with eps and odfWeave (on windows), is image
rendering. On my system, there is a windows system file called convert
(instead of imagemagick's convert) which messes up the image preview
within the document. Marc Schwartz and I have talked about this off-list
and he doesn't have the same issues.]

Max
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Dieter Menne
Sent: Monday, June 25, 2007 11:04 AM
To: R-Help
Subject: [R] eps in odfWeave

Dear Weavers,

Does someone have an example of using eps or any other vector graphics
with
odfWeave? It tried the example below (and commented variants) with
simple.odt in the examples directory, and got an error.

Dieter


#---
library(odfWeave)
plotInfo <- getImageDefs()
plotInfo$type = "eps"
#plotInfo$device = "postscript"
setImageDefs(plotInfo)
odfWeave("simple.odt", "simpleOut.odt")
#-----

#  Writing to file content_1.xml
#  Processing code chunks ...
#    1 : term hide(label=loadLibs)
#    2 : term xml(label=showOutputList)
#Error in check(options) : invalid value for 'type' : eps

Version: 0.5.9
Date: 2007-20-06

platform       i386-pc-mingw32
arch           i386
os             mingw32
system         i386, mingw32
status
major          2
minor          5.0
year           2007
month          04
day            23
svn rev        41293
language       R
version.string R version 2.5.0 (2007-04-23)

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

----------------------------------------------------------------------
LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}


From rchandler at forwild.umass.edu  Mon Jun 25 18:12:01 2007
From: rchandler at forwild.umass.edu (Richard Chandler)
Date: Mon, 25 Jun 2007 12:12:01 -0400
Subject: [R] problem building first package
Message-ID: <1182787921.467fe951b35e5@mail-www.oit.umass.edu>

Hi,

I am trying to build a package from source for the first time. I'm
using Windows XP. After R CMD INSTALL or R CMD check I get an error
message that I don't understand. I've tried to follow the instrucions
provided in the R Installation and Administration .pdf and the text
file that comes with Rtools, but most of this is new to me and clearly
I'm missing something. Here's what I've done:

-Downloaded perl and Rtools and put them in my c directory
-Used package.skeleton() to set up the package structure and put the
package-to-be "removal" in C:\toBuild
-I edited my path to :
C:\Rtools\bin;C:\perl\bin;C:\Rtools\MinGW\bin;C:\R-2.5.0\bin;...
-I changed the following in the MkRules file:
1)HEADER=C:/Rtools/MinGW/include
2)HELPTYPES = -txt
3)WINHELP = NO
4)HEADER=C:/Rtools/MinGW/include
5)R_EXE=C:/R-2.5.0/bin/R.exe
-Next, I opened up a command prompt and went to c:/toBuild
-Then I ran: R CMD build removal. No problems.
-Then I ran: R CMD INSTALL removal_1.0.tar.gz
and got this:
---------------------
installing to 'c:/R-2.5.0/library'

latex: not found
latex: not found
latex: not found

---------- Making package removal ------------
latex: not found
  adding build stamp to DESCRIPTION
latex: not found
latex: not found
latex: not found
  installing R files
latex: not found
  installing data files
latex: not found
  installing man source files
  installing indices
latex: not found
latex: not found
  not zipping data
  installing help
 >>> Building/Updating help pages for package 'removal'
     Formats: text chm
  RemProbs                          text                           chm
  add.error                         text                           chm
  error.plot                        text                           chm
  firstDetect                       text                           chm
  funs                              text                           chm
  path                              text                           chm
  pll2                              text                           chm
  remll2                            text                           chm
  removal-package                   text                           chm
  removal2                          text                           chm
  var.d                             text                           chm
hhc: not found
cp: cannot stat `C:/toBuild/R.INSTALL.3064/removal/chm/removal.chm':
No such fil
e or directory
make[1]: *** [chm-removal] Error 1
make: *** [pkg-removal] Error 2
*** Installation of removal failed ***

Removing 'c:/R-2.5.0/library/removal'
---------------

I don't know what hhc is. I'm guessing its trying to build the
compiled help files even though I tried to ask for only text files. It
also seems to want latex even though I read that it isn't necessary to
build simple packages. Can someone please tell me what I'm doing
wrong? Thanks.

Richard


-- 
Richard Chandler, PhD student
Department of Natural Resources Conservation
UMass Amherst
(413)545-1237


From dieter.menne at menne-biomed.de  Mon Jun 25 18:15:04 2007
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Mon, 25 Jun 2007 16:15:04 +0000 (UTC)
Subject: [R] eps in odfWeave
References: <LPEJLJACLINDNMBMFAFIMEEICIAA.dieter.menne@menne-biomed.de>
	<71257D09F114DA4A8E134DEAC70F25D308C0401F@groamrexm03.amer.pfizer.com>
Message-ID: <loom.20070625T180859-191@post.gmane.org>

Kuhn, Max <Max.Kuhn <at> pfizer.com> writes:

Thanks, Max.

> What is the version of odfWeave? If you use those specifications in the
> current version (0.5.9):

Yes, version 0.5.9 (it was further below in my message, I forgot to put the
odfWeave flag before it.

I had tried your horizontal... suggestions before, because these came up nicely
in the error message, but the error remained the same, so I removed them. Here
another try for copy/paste, with a traceback. 

The convert problem is a well known Imagemagick problem; clashes with "convert"
in the Windows directory. Workaround is to put the Imagemagick path before the
Windows/system32 path.

Dieter


library(odfWeave)
plotInfo <- getImageDefs()
plotInfo$type = "eps"
plotInfo$plotWidth = 4
plotInfo$plotHeight = 4
plotInfo$device = "postscript"
plotInfo$args = list(
    horizontal = FALSE,
    onefile = FALSE,
    paper = "special")
setImageDefs(plotInfo)
demoFile <- system.file("examples", "simple.odt", package ="odfWeave")
odfWeave(demoFile, "c:/simpleOut.odt")

-----
Error in check(options) : invalid value for 'type' : eps
>
>
> traceback()
5: stop(gettextf("invalid value for '%s' : %s", opt, oldval), domain = NA)
4: check(options)
3: SweaveParseOptions(chunkopts, drobj$options, driver$checkopts)
2: Sweave(file = rnwFileName, output = "content_1.xml", quiet = !control$verbose,
       driver = RweaveOdf(), control = control)
1: odfWeave(demoFile, "c:/simpleOut.odt")


From ana.pmartins at ine.pt  Mon Jun 25 18:15:56 2007
From: ana.pmartins at ine.pt (Ana Patricia Martins)
Date: Mon, 25 Jun 2007 17:15:56 +0100
Subject: [R]  simultaneous actions of grep ???
Message-ID: <E97312684A84D511BDD40002A50968D60A41B785@lxpobw01.ine.pt>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070625/5ad20468/attachment.pl 

From jholtman at gmail.com  Mon Jun 25 18:17:44 2007
From: jholtman at gmail.com (jim holtman)
Date: Mon, 25 Jun 2007 12:17:44 -0400
Subject: [R] a string to enviroment or function
In-Reply-To: <cdf817830706250842l3dd9a812v14c94a7609d18225@mail.gmail.com>
References: <cdf817830706250842l3dd9a812v14c94a7609d18225@mail.gmail.com>
Message-ID: <644e1f320706250917o58481269xe471cae399f1c4a5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070625/bbd17870/attachment.pl 

From jholtman at gmail.com  Mon Jun 25 18:21:39 2007
From: jholtman at gmail.com (jim holtman)
Date: Mon, 25 Jun 2007 12:21:39 -0400
Subject: [R] how to plot this?
In-Reply-To: <cdf817830706250750yad67f59m778f6bd43124582a@mail.gmail.com>
References: <cdf817830706250750yad67f59m778f6bd43124582a@mail.gmail.com>
Message-ID: <644e1f320706250921k4e2368a0we876d101350f3b9a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070625/baf2f4dd/attachment.pl 

From Jon_Hak at natureserve.org  Mon Jun 25 16:58:52 2007
From: Jon_Hak at natureserve.org (Jon Hak)
Date: Mon, 25 Jun 2007 10:58:52 -0400
Subject: [R] manipulate a matrix
Message-ID: <AA8DB79120FEAB4080DEC905A9389DCE046AA563@webmail.natureserve.org>

I have read everything I can find on how to manipulate a results matrix in R and I have to admit I'm stumped.  I have set up a process to extract a dataset from ArcGIS to compute a similarity index (Jaccards) in Vegan.  The dataset is fairly simple, but large, and consists of rows = sample area, and columns = elements.  I've been able to view the results in R, but I want to get the results out to a database and a matrix that is 6000-rows x 6000-columns can be very difficult to manipulate in Windows XP.  I would to rotate the matrix so that the output would look like the old condensed format in programs like Conoco.  Ideally, I would like format to look something like this;


Site-row Site-col Jaccard
1	    1		1
1	    2  	.9
1	    3  	.6
2	    1  	.9
2    	    2       1
2	    3       .75

Thanks for any help,




***********************************************************
John Hak
Senior GIS Analyst/Sr. Ecologist
NatureServe
4001 Discovery Drive 
Boulder, CO 80303
(703) 797-4809

There is perhaps no better demonstration of the folly of human conceits than this distant image of our tiny world. To me, it underscores our responsibility to deal more kindly with one another, and to preserve and cherish the pale blue dot, the only home we've ever known. --Carl Sagan
?


From gavinpaulkelly at gmail.com  Mon Jun 25 18:24:22 2007
From: gavinpaulkelly at gmail.com (Gavin Kelly)
Date: Mon, 25 Jun 2007 17:24:22 +0100
Subject: [R] Re : Half of a heatmap
Message-ID: <551186a70706250924l39395d1ld684588278639ff7@mail.gmail.com>

 > I am trying to produce a heatmap of pairwise correlations, but
since the matrix is
> symmetric, I only need either the upper or the lower triangle.  I have scoured the
> web and R documentation, but I have not been able to find a way to produce such a
> figure.  Is there a simple way to produce a heat map with only the part above or
> below the diagonal?

Can you not just set the lower or upper triangle to NAs, and pass this
on to heatmap - or am I misunderstanding you?

tmp <- matrix(rnorm(100),10,10)
tmp[lower.tri(tmp)] <- NA
heatmap(tmp, Rowv=NA, Colv=NA)

Regards - Gavin
--
Gavin Kelly
Senior Statistician, Bioinformatics & Biostatistics Group
Cancer Research UK


From jholtman at gmail.com  Mon Jun 25 18:24:35 2007
From: jholtman at gmail.com (jim holtman)
Date: Mon, 25 Jun 2007 12:24:35 -0400
Subject: [R] how to plot this?
In-Reply-To: <cdf817830706250750yad67f59m778f6bd43124582a@mail.gmail.com>
References: <cdf817830706250750yad67f59m778f6bd43124582a@mail.gmail.com>
Message-ID: <644e1f320706250924qf0b78dfo3273144a80d6646e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070625/405d6759/attachment.pl 

From Jean-Baptiste.Ferdy at univ-montp2.fr  Mon Jun 25 18:26:22 2007
From: Jean-Baptiste.Ferdy at univ-montp2.fr (Jean-Baptiste Ferdy)
Date: Mon, 25 Jun 2007 18:26:22 +0200
Subject: [R] degrees of freedom in lme
Message-ID: <200706251826.22488.Jean-Baptiste.Ferdy@univ-montp2.fr>

Dear all,

I am starting to use the lme package (and plan to teach a course based on it 
next semester...). To understand what lme is doing precisely, I used balanced 
datasets described in Pinheiro and Bates and tried to compare the lme outputs 
to that of aov. Here is what I obtained:

> data(Machines)
> summary(aov(score~Machine+Error(Worker/Machine),data=Machines))
Error: Worker
          Df  Sum Sq Mean Sq F value Pr(>F)
Residuals  5 1241.89  248.38

Error: Worker:Machine
          Df  Sum Sq Mean Sq F value    Pr(>F)
Machine    2 1755.26  877.63  20.576 0.0002855 ***
Residuals 10  426.53   42.65
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Error: Within
          Df Sum Sq Mean Sq F value Pr(>F)
Residuals 36 33.287   0.925
> anova(lme(fixed=score~Machine,random=~1|Worker/Machine,data=Machines))
            numDF denDF  F-value p-value
(Intercept)     1    36 773.5709  <.0001
Machine         2    10  20.5762   3e-04
  
No problem here: the results are essentially the same, which is expected. Now 
I turn to an ANCOVA with a random grouping factor.

> data(Orthodont)
> OrthoFem <- Orthodont[Orthodont$Sex=="Female",];
> summary(aov(distance~age+Error(Subject/age),data=OrthoFem))
Error: Subject
          Df  Sum Sq Mean Sq F value Pr(>F)
Residuals 10 177.227  17.723

Error: Subject:age
          Df Sum Sq Mean Sq F value    Pr(>F)
age        1 50.592  50.592  52.452 2.783e-05 ***
Residuals 10  9.645   0.965
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Error: Within
          Df Sum Sq Mean Sq F value Pr(>F)
Residuals 22 9.8250  0.4466
> anova(lme(fixed=distance~age,random=~1+age|Subject,data=OrthoFem))
            numDF denDF   F-value p-value
(Intercept)     1    32 1269.7764  <.0001
age             1    32   52.4517  <.0001

This time the F values are (almost) identical, the numerator degrees of 
freedom are the same, but the denominator degrees of freedom are very 
different (10 for aov vs. 32 for lme). I understand that there is an issue 
with the estimation of that number, but I would naively expect the number 
given by lme to be close to that provided by aov is the case of a balanced 
dataset. That's obviously not true in the case of an ANCOVA... But why?? And 
how should I interpret the F-test given by anova.lme?

Thanks in advance for your help !
-- 
Jean-Baptiste Ferdy
Institut des Sciences de l'?volution de Montpellier
CNRS UMR 5554
Universit? Montpellier 2
34 095 Montpellier cedex 05
tel. +33 (0)4 67 14 42 27
fax ?+33 (0)4 67 14 36 22


From mford at csl.psychol.cam.ac.uk  Mon Jun 25 18:27:38 2007
From: mford at csl.psychol.cam.ac.uk (Mike Ford)
Date: Mon, 25 Jun 2007 17:27:38 +0100
Subject: [R] LanguageR pvals.fnc error message
Message-ID: <467FECFA.4080809@csl.psychol.cam.ac.uk>

Hi. I get an error message about not converging when I try and use the 
pvals.fnc from the languageR library. The LMER analysis worked fine (See 
below).

I am not an expert so I don't understand why the LMER worked but not the 
pvals.fnc

Any help gratefully received.

- Mike

   AIC   BIC logLik MLdeviance REMLdeviance
 -7324 -7254   3673      -7451        -7346
Random effects:
 Groups   Name        Variance   Std.Dev.
 Item     (Intercept) 5.3386e-05 0.0073066
 Subj     (Intercept) 1.8073e-03 0.0425128
 Residual             1.0314e-02 0.1015578
number of obs: 4363, groups: Item, 294; Subj, 38

Fixed effects:
               Estimate Std. Error t value
(Intercept)   5.848e+00  7.830e-03   746.9
PrevErr1      3.835e-03  3.808e-03     1.0
ExpOrd       -3.708e-05  9.107e-06    -4.1
pc4lex       -4.630e-04  1.681e-03    -0.3
pc4img       -7.519e-04  1.642e-03    -0.5
pc4nlen      -4.413e-03  1.608e-03    -2.7
pc4lsa        8.118e-04  1.648e-03     0.5
pc4ng       -5.183e-03  1.642e-03    -3.2
I(pc4nlen^2)  2.999e-03  1.451e-03     2.1


From jholtman at gmail.com  Mon Jun 25 18:35:31 2007
From: jholtman at gmail.com (jim holtman)
Date: Mon, 25 Jun 2007 12:35:31 -0400
Subject: [R] R behaviour related to user input (readline()) and run
	selection
In-Reply-To: <CADFD0E28E1E6A46B0C84335BDB994F503EB313F@whexchmb16.bsna.bsroot.bear.com>
References: <CADFD0E28E1E6A46B0C84335BDB994F503EB313F@whexchmb16.bsna.bsroot.bear.com>
Message-ID: <644e1f320706250935k10e053e9ja3a5a433361d873f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070625/16742b80/attachment.pl 

From jholtman at gmail.com  Mon Jun 25 18:39:46 2007
From: jholtman at gmail.com (jim holtman)
Date: Mon, 25 Jun 2007 12:39:46 -0400
Subject: [R] manipulate a matrix
In-Reply-To: <AA8DB79120FEAB4080DEC905A9389DCE046AA563@webmail.natureserve.org>
References: <AA8DB79120FEAB4080DEC905A9389DCE046AA563@webmail.natureserve.org>
Message-ID: <644e1f320706250939v7ac2a2f1t387a8ba8f715ec0e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070625/bee4ba75/attachment.pl 

From marc_schwartz at comcast.net  Mon Jun 25 18:58:28 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Mon, 25 Jun 2007 11:58:28 -0500
Subject: [R] simultaneous actions of grep ???
In-Reply-To: <E97312684A84D511BDD40002A50968D60A41B785@lxpobw01.ine.pt>
References: <E97312684A84D511BDD40002A50968D60A41B785@lxpobw01.ine.pt>
Message-ID: <1182790709.3841.26.camel@Bellerophon.localdomain>

On Mon, 2007-06-25 at 17:15 +0100, Ana Patricia Martins wrote:
> Hello R-users and developers,
> 
> Once again, I'm asking for your help.
> 
> There is other way to do the same more easily for applied simultaneous
> grep???
>   
>     c<-subset(c,!rownames(c) %in% grep(".1",rownames(c),value=T))
>     c<-subset(c,!rownames(c) %in% grep(".5",rownames(c),value=T))
>     c<-subset(c,!rownames(c) %in% grep(".6",rownames(c),value=T))
>     c<-subset(c,!rownames(c) %in% grep(".99999",rownames(c),value=T))
> 
> Thanks in advance for helping me.

One question might be what other possible values can the rownames take.

For example, if you want to check for '.99999', but not for other values
containing a '9' after the decimal, something like the following should
work:

sub.c <- subset(c, 
                !rownames(c) %in% 
                grep("\\.([156])|([9]{5})", rownames(c), 
                     value = TRUE))

Otherwise, if you want to include anything with a '9' after a decimal,
the following would work:

sub.c <- subset(c, 
                !rownames(c) %in% 
                grep("\\.[1569]", rownames(c), value = TRUE))


See ?regex and the information there for some additional guidance. There
are also many regex references online, such as:

  http://www.regular-expressions.info/

BTW, it would be preferable not to use 'c' to name an object in R, since
c() is a function. While conflicts should, in general, not occur, it
eliminates such risk and makes for more easily readable code to not use
function names for objects.

HTH,

Marc Schwartz


From ripley at stats.ox.ac.uk  Mon Jun 25 18:58:49 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 25 Jun 2007 17:58:49 +0100 (BST)
Subject: [R] problem building first package
In-Reply-To: <1182787921.467fe951b35e5@mail-www.oit.umass.edu>
References: <1182787921.467fe951b35e5@mail-www.oit.umass.edu>
Message-ID: <Pine.LNX.4.64.0706251752100.15740@gannet.stats.ox.ac.uk>

You can ignore the message about latex (and 2.5.1 RC does not give it).

hhc is part of HTML Help Workshop: you either have not installed that or 
not put it in your path.

The settings in MkRules affect the types of help for building R, not 'R 
CMD INSTALL'.  If you only want text help you need to run

R CMD INSTALL --docs=txt removal_1.0.tar.gz


On Mon, 25 Jun 2007, Richard Chandler wrote:

> Hi,
>
> I am trying to build a package from source for the first time. I'm
> using Windows XP. After R CMD INSTALL or R CMD check I get an error
> message that I don't understand. I've tried to follow the instrucions
> provided in the R Installation and Administration .pdf and the text
> file that comes with Rtools, but most of this is new to me and clearly
> I'm missing something. Here's what I've done:
>
> -Downloaded perl and Rtools and put them in my c directory
> -Used package.skeleton() to set up the package structure and put the
> package-to-be "removal" in C:\toBuild
> -I edited my path to :
> C:\Rtools\bin;C:\perl\bin;C:\Rtools\MinGW\bin;C:\R-2.5.0\bin;...
> -I changed the following in the MkRules file:
> 1)HEADER=C:/Rtools/MinGW/include
> 2)HELPTYPES = -txt
> 3)WINHELP = NO
> 4)HEADER=C:/Rtools/MinGW/include
> 5)R_EXE=C:/R-2.5.0/bin/R.exe

The last two are for cross-building, not what you are doing.

> -Next, I opened up a command prompt and went to c:/toBuild
> -Then I ran: R CMD build removal. No problems.
> -Then I ran: R CMD INSTALL removal_1.0.tar.gz
> and got this:
> ---------------------
> installing to 'c:/R-2.5.0/library'
>
> latex: not found
> latex: not found
> latex: not found
>
> ---------- Making package removal ------------
> latex: not found
>  adding build stamp to DESCRIPTION
> latex: not found
> latex: not found
> latex: not found
>  installing R files
> latex: not found
>  installing data files
> latex: not found
>  installing man source files
>  installing indices
> latex: not found
> latex: not found
>  not zipping data
>  installing help
> >>> Building/Updating help pages for package 'removal'
>     Formats: text chm
>  RemProbs                          text                           chm
>  add.error                         text                           chm
>  error.plot                        text                           chm
>  firstDetect                       text                           chm
>  funs                              text                           chm
>  path                              text                           chm
>  pll2                              text                           chm
>  remll2                            text                           chm
>  removal-package                   text                           chm
>  removal2                          text                           chm
>  var.d                             text                           chm
> hhc: not found
> cp: cannot stat `C:/toBuild/R.INSTALL.3064/removal/chm/removal.chm':
> No such fil
> e or directory
> make[1]: *** [chm-removal] Error 1
> make: *** [pkg-removal] Error 2
> *** Installation of removal failed ***
>
> Removing 'c:/R-2.5.0/library/removal'
> ---------------
>
> I don't know what hhc is. I'm guessing its trying to build the
> compiled help files even though I tried to ask for only text files. It
> also seems to want latex even though I read that it isn't necessary to
> build simple packages. Can someone please tell me what I'm doing
> wrong? Thanks.
>
> Richard
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mcneney at gmail.com  Mon Jun 25 19:01:25 2007
From: mcneney at gmail.com (Brad McNeney)
Date: Mon, 25 Jun 2007 10:01:25 -0700
Subject: [R] Re : Half of a heatmap
In-Reply-To: <4A7F2400BAF11B4DBC4BF3D2046593E20188517F@mailbox05.cshl.edu>
References: <31b34fca0706250314l80c7deeucd0f3ff2997bd97@mail.gmail.com>
	<4A7F2400BAF11B4DBC4BF3D2046593E20188517F@mailbox05.cshl.edu>
Message-ID: <eb36bc660706251001w20ec053dx81f37f025d292e4c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070625/b9c7dd4b/attachment.pl 

From marc_schwartz at comcast.net  Mon Jun 25 19:06:23 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Mon, 25 Jun 2007 12:06:23 -0500
Subject: [R] simultaneous actions of grep ???
In-Reply-To: <1182790709.3841.26.camel@Bellerophon.localdomain>
References: <E97312684A84D511BDD40002A50968D60A41B785@lxpobw01.ine.pt>
	<1182790709.3841.26.camel@Bellerophon.localdomain>
Message-ID: <1182791183.3841.32.camel@Bellerophon.localdomain>

On Mon, 2007-06-25 at 11:58 -0500, Marc Schwartz wrote:
> On Mon, 2007-06-25 at 17:15 +0100, Ana Patricia Martins wrote:
> > Hello R-users and developers,
> > 
> > Once again, I'm asking for your help.
> > 
> > There is other way to do the same more easily for applied simultaneous
> > grep???
> >   
> >     c<-subset(c,!rownames(c) %in% grep(".1",rownames(c),value=T))
> >     c<-subset(c,!rownames(c) %in% grep(".5",rownames(c),value=T))
> >     c<-subset(c,!rownames(c) %in% grep(".6",rownames(c),value=T))
> >     c<-subset(c,!rownames(c) %in% grep(".99999",rownames(c),value=T))
> > 
> > Thanks in advance for helping me.
> 
> One question might be what other possible values can the rownames take.
> 
> For example, if you want to check for '.99999', but not for other values
> containing a '9' after the decimal, something like the following should
> work:
> 
> sub.c <- subset(c, 
>                 !rownames(c) %in% 
>                 grep("\\.([156])|([9]{5})", rownames(c), 
>                      value = TRUE))
> 
> Otherwise, if you want to include anything with a '9' after a decimal,
> the following would work:
> 
> sub.c <- subset(c, 
>                 !rownames(c) %in% 
>                 grep("\\.[1569]", rownames(c), value = TRUE))
> 
> 
> See ?regex and the information there for some additional guidance. There
> are also many regex references online, such as:
> 
>   http://www.regular-expressions.info/
> 
> BTW, it would be preferable not to use 'c' to name an object in R, since
> c() is a function. While conflicts should, in general, not occur, it
> eliminates such risk and makes for more easily readable code to not use
> function names for objects.

Quick possible correction:

I mis-read the regex as containing a decimal, which would need to be
escaped as I had. 

If your use of the '.' is to refer to any character, then the following
would be correct:

sub.c <- subset(c, 
                !rownames(c) %in% 
                grep(".([156])|([9]{5})", rownames(c), 
                     value = TRUE))

or

sub.c <- subset(c, 
                !rownames(c) %in% 
                grep(".[1569]", rownames(c), value = TRUE))


Sorry for the confusion.

Marc


From HDoran at air.org  Mon Jun 25 19:15:32 2007
From: HDoran at air.org (Doran, Harold)
Date: Mon, 25 Jun 2007 13:15:32 -0400
Subject: [R] degrees of freedom in lme
In-Reply-To: <200706251826.22488.Jean-Baptiste.Ferdy@univ-montp2.fr>
Message-ID: <2323A6D37908A847A7C32F1E3662C80EE57794@dc1ex01.air.org>

This is such a common question that it has a an "FAQ-like" response from Doug Bates. Google "lmer p-values and all that" to find the response. 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Jean-Baptiste Ferdy
> Sent: Monday, June 25, 2007 12:26 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] degrees of freedom in lme
> 
> Dear all,
> 
> I am starting to use the lme package (and plan to teach a 
> course based on it next semester...). To understand what lme 
> is doing precisely, I used balanced datasets described in 
> Pinheiro and Bates and tried to compare the lme outputs to 
> that of aov. Here is what I obtained:
> 
> > data(Machines)
> > summary(aov(score~Machine+Error(Worker/Machine),data=Machines))
> Error: Worker
>           Df  Sum Sq Mean Sq F value Pr(>F) Residuals  5 
> 1241.89  248.38
> 
> Error: Worker:Machine
>           Df  Sum Sq Mean Sq F value    Pr(>F)
> Machine    2 1755.26  877.63  20.576 0.0002855 ***
> Residuals 10  426.53   42.65
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
> Error: Within
>           Df Sum Sq Mean Sq F value Pr(>F)
> Residuals 36 33.287   0.925
> > 
> anova(lme(fixed=score~Machine,random=~1|Worker/Machine,data=Machines))
>             numDF denDF  F-value p-value
> (Intercept)     1    36 773.5709  <.0001
> Machine         2    10  20.5762   3e-04
>   
> No problem here: the results are essentially the same, which 
> is expected. Now I turn to an ANCOVA with a random grouping factor.
> 
> > data(Orthodont)
> > OrthoFem <- Orthodont[Orthodont$Sex=="Female",];
> > summary(aov(distance~age+Error(Subject/age),data=OrthoFem))
> Error: Subject
>           Df  Sum Sq Mean Sq F value Pr(>F) Residuals 10 
> 177.227  17.723
> 
> Error: Subject:age
>           Df Sum Sq Mean Sq F value    Pr(>F)
> age        1 50.592  50.592  52.452 2.783e-05 ***
> Residuals 10  9.645   0.965
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
> Error: Within
>           Df Sum Sq Mean Sq F value Pr(>F) Residuals 22 9.8250  0.4466
> > anova(lme(fixed=distance~age,random=~1+age|Subject,data=OrthoFem))
>             numDF denDF   F-value p-value
> (Intercept)     1    32 1269.7764  <.0001
> age             1    32   52.4517  <.0001
> 
> This time the F values are (almost) identical, the numerator 
> degrees of freedom are the same, but the denominator degrees 
> of freedom are very different (10 for aov vs. 32 for lme). I 
> understand that there is an issue with the estimation of that 
> number, but I would naively expect the number given by lme to 
> be close to that provided by aov is the case of a balanced 
> dataset. That's obviously not true in the case of an 
> ANCOVA... But why?? And how should I interpret the F-test 
> given by anova.lme?
> 
> Thanks in advance for your help !
> --
> Jean-Baptiste Ferdy
> Institut des Sciences de l'?volution de Montpellier CNRS UMR 
> 5554 Universit? Montpellier 2
> 34 095 Montpellier cedex 05
> tel. +33 (0)4 67 14 42 27
> fax ?+33 (0)4 67 14 36 22
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From marc_schwartz at comcast.net  Mon Jun 25 19:22:29 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Mon, 25 Jun 2007 12:22:29 -0500
Subject: [R] manipulate a matrix
In-Reply-To: <AA8DB79120FEAB4080DEC905A9389DCE046AA563@webmail.natureserve.org>
References: <AA8DB79120FEAB4080DEC905A9389DCE046AA563@webmail.natureserve.org>
Message-ID: <1182792149.3841.44.camel@Bellerophon.localdomain>

On Mon, 2007-06-25 at 10:58 -0400, Jon Hak wrote:
> I have read everything I can find on how to manipulate a results
> matrix in R and I have to admit I'm stumped.  I have set up a process
> to extract a dataset from ArcGIS to compute a similarity index
> (Jaccards) in Vegan.  The dataset is fairly simple, but large, and
> consists of rows = sample area, and columns = elements.  I've been
> able to view the results in R, but I want to get the results out to a
> database and a matrix that is 6000-rows x 6000-columns can be very
> difficult to manipulate in Windows XP.  I would to rotate the matrix
> so that the output would look like the old condensed format in
> programs like Conoco.  Ideally, I would like format to look something
> like this;
> 
> 
> Site-row Site-col Jaccard
> 1	    1		1
> 1	    2  	.9
> 1	    3  	.6
> 2	    1  	.9
> 2    	    2       1
> 2	    3       .75
> 
> Thanks for any help,

Presuming that your source matrix for the above is:

mat <- matrix(c(1, .9, .6, .9, 1, .75), ncol = 3, byrow = TRUE)

> mat
     [,1] [,2] [,3]
[1,]  1.0  0.9 0.60
[2,]  0.9  1.0 0.75

You can use the following:

t.mat <- t(mat)

Res <- cbind("Site-row" = as.vector(col(t.mat)), 
             "Site-col" = as.vector(row(t.mat)), 
             Jaccard = as.vector(t.mat))

> Res
     Site-row Site-col Jaccard
[1,]        1        1    1.00
[2,]        1        2    0.90
[3,]        1        3    0.60
[4,]        2        1    0.90
[5,]        2        2    1.00
[6,]        2        3    0.75

See ?t and ?row

HTH,

Marc Schwartz


From h.wickham at gmail.com  Mon Jun 25 19:22:46 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 25 Jun 2007 19:22:46 +0200
Subject: [R] how to plot this?
In-Reply-To: <644e1f320706250921k4e2368a0we876d101350f3b9a@mail.gmail.com>
References: <cdf817830706250750yad67f59m778f6bd43124582a@mail.gmail.com>
	<644e1f320706250921k4e2368a0we876d101350f3b9a@mail.gmail.com>
Message-ID: <f8e6ff050706251022u63b49b0fx2eef2f792d94bade@mail.gmail.com>

On 6/25/07, jim holtman <jholtman at gmail.com> wrote:
> You might want to check out this link to the type of graphs that R can
> produce and find one you like; the code will be with it.
>
> http://addictedtor.free.fr/graphiques/allgraph.php

Or for examples using the ggplot2 package:

http://had.co.nz/ggplot2

Hadley


From rchandler at forwild.umass.edu  Mon Jun 25 19:28:47 2007
From: rchandler at forwild.umass.edu (Richard Chandler)
Date: Mon, 25 Jun 2007 13:28:47 -0400
Subject: [R] problem building first package
In-Reply-To: <Pine.LNX.4.64.0706251752100.15740@gannet.stats.ox.ac.uk>
References: <1182787921.467fe951b35e5@mail-www.oit.umass.edu>
	<Pine.LNX.4.64.0706251752100.15740@gannet.stats.ox.ac.uk>
Message-ID: <1182792527.467ffb4f655a6@mail-www.oit.umass.edu>

Thanks so much. I was able to get it installed using:

R CMD INSTALL --docs=normal removal_1.0.tar.gz

However, setting --docs=txt gave me this error:

ERROR: invalid --docs value `txt'

The --help says it needs to be a list, but no matter, --docs=normal
worked fine.



Quoting Prof Brian Ripley <ripley at stats.ox.ac.uk>:

> You can ignore the message about latex (and 2.5.1 RC does not give
> it).
>
> hhc is part of HTML Help Workshop: you either have not installed
> that or
> not put it in your path.
>
> The settings in MkRules affect the types of help for building R,
> not 'R
> CMD INSTALL'.  If you only want text help you need to run
>
> R CMD INSTALL --docs=txt removal_1.0.tar.gz
>
>
> On Mon, 25 Jun 2007, Richard Chandler wrote:
>
> > Hi,
> >
> > I am trying to build a package from source for the first time.
> I'm
> > using Windows XP. After R CMD INSTALL or R CMD check I get an
> error
> > message that I don't understand. I've tried to follow the
> instrucions
> > provided in the R Installation and Administration .pdf and the
> text
> > file that comes with Rtools, but most of this is new to me and
> clearly
> > I'm missing something. Here's what I've done:
> >
> > -Downloaded perl and Rtools and put them in my c directory
> > -Used package.skeleton() to set up the package structure and put
> the
> > package-to-be "removal" in C:\toBuild
> > -I edited my path to :
> > C:\Rtools\bin;C:\perl\bin;C:\Rtools\MinGW\bin;C:\R-2.5.0\bin;...
> > -I changed the following in the MkRules file:
> > 1)HEADER=C:/Rtools/MinGW/include
> > 2)HELPTYPES = -txt
> > 3)WINHELP = NO
> > 4)HEADER=C:/Rtools/MinGW/include
> > 5)R_EXE=C:/R-2.5.0/bin/R.exe
>
> The last two are for cross-building, not what you are doing.
>
> > -Next, I opened up a command prompt and went to c:/toBuild
> > -Then I ran: R CMD build removal. No problems.
> > -Then I ran: R CMD INSTALL removal_1.0.tar.gz
> > and got this:
> > ---------------------
> > installing to 'c:/R-2.5.0/library'
> >
> > latex: not found
> > latex: not found
> > latex: not found
> >
> > ---------- Making package removal ------------
> > latex: not found
> >  adding build stamp to DESCRIPTION
> > latex: not found
> > latex: not found
> > latex: not found
> >  installing R files
> > latex: not found
> >  installing data files
> > latex: not found
> >  installing man source files
> >  installing indices
> > latex: not found
> > latex: not found
> >  not zipping data
> >  installing help
> > >>> Building/Updating help pages for package 'removal'
> >     Formats: text chm
> >  RemProbs                          text
> chm
> >  add.error                         text
> chm
> >  error.plot                        text
> chm
> >  firstDetect                       text
> chm
> >  funs                              text
> chm
> >  path                              text
> chm
> >  pll2                              text
> chm
> >  remll2                            text
> chm
> >  removal-package                   text
> chm
> >  removal2                          text
> chm
> >  var.d                             text
> chm
> > hhc: not found
> > cp: cannot stat
> `C:/toBuild/R.INSTALL.3064/removal/chm/removal.chm':
> > No such fil
> > e or directory
> > make[1]: *** [chm-removal] Error 1
> > make: *** [pkg-removal] Error 2
> > *** Installation of removal failed ***
> >
> > Removing 'c:/R-2.5.0/library/removal'
> > ---------------
> >
> > I don't know what hhc is. I'm guessing its trying to build the
> > compiled help files even though I tried to ask for only text
> files. It
> > also seems to want latex even though I read that it isn't
> necessary to
> > build simple packages. Can someone please tell me what I'm doing
> > wrong? Thanks.
> >
> > Richard
> >
> >
> >
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,
> http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>


-- 
Richard Chandler, PhD student
Department of Natural Resources Conservation
UMass Amherst
(413)545-1237


From rosenfel at cshl.edu  Mon Jun 25 19:54:48 2007
From: rosenfel at cshl.edu (Rosenfeld, Jeffrey)
Date: Mon, 25 Jun 2007 13:54:48 -0400
Subject: [R] Re : Half of a heatmap
References: <31b34fca0706250314l80c7deeucd0f3ff2997bd97@mail.gmail.com><4A7F2400BAF11B4DBC4BF3D2046593E20188517F@mailbox05.cshl.edu>
	<eb36bc660706251001w20ec053dx81f37f025d292e4c@mail.gmail.com>
Message-ID: <4A7F2400BAF11B4DBC4BF3D2046593E201885183@mailbox05.cshl.edu>

I have correlation values between -1 and 1 and I need to keep the sign.

Jeff


-----Original Message-----
From: Brad McNeney [mailto:mcneney at gmail.com]
Sent: Mon 6/25/2007 1:01 PM
To: Rosenfeld, Jeffrey
Cc: Neil Shephard; r-help at stat.math.ethz.ch
Subject: Re: [R] Re : Half of a heatmap
 
Just for the record, LDheatmap can display any upper-triangular matrix of
measures between 0 and 1, not just LD measures. Users with their own matrix
should pass it as the first argument (gdat) to the function.

-b

--
Brad McNeney
Statistics and Actuarial Science
Simon Fraser University
Burnaby, BC, Canada


On 6/25/07, Rosenfeld, Jeffrey <rosenfel at cshl.edu> wrote:
>
> Thank you for your reply.  I have looked at LDheatmap, but it does not
> seem to do what I want and seems to only work well for LD data.  I was
> looking for something that would produce a figure identical to what
> heatmap.2 gives me, including the proper X and Y-axis labels and a
> dendogram, except that it would only have half of the map.  Preferably, it
> would have the Color Key in the place where the other triangle of the
> heatmap would be, to save space.
>
>
> Jeff
>
>
> -----Original Message-----
> From: Neil Shephard [mailto:nshephard at gmail.com]
> Sent: Mon 6/25/2007 6:14 AM
> To: r-help at stat.math.ethz.ch
> Cc: Rosenfeld, Jeffrey
> Subject: Re : [R] Half of a heatmap
>
> > I am trying to produce a heatmap of pairwise correlations, but since the
> matrix is
> > symmetric, I only need either the upper or the lower triangle.  I have
> scoured the
> > web and R documentation, but I have not been able to find a way to
> produce such a
> > figure.  Is there a simple way to produce a heat map with only the part
> above or
> > below the diagonal?
>
> You might want to check out the LDheatmap() package which can generate
> the plots you describe.  The help indicates that it accepts a matrix
> of pair-wise linkage disequilibrium measures, one of which is R^2 (the
> correlation coefficient between loci), but I suspect you could simply
> pass it a matrix of correlation coefficents.
>
> Hope that helps,
>
> Neil
> --
> "In mathematics you don't understand things. You just get used to
> them."  - Johann von Neumann
>
> Email - nshephard at gmail.com / n.shephard at sheffield.ac.uk
> Website - http://slack.ser.man.ac.uk/
> Photos - http://www.flickr.com/photos/slackline/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ripley at stats.ox.ac.uk  Mon Jun 25 19:58:37 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 25 Jun 2007 18:58:37 +0100 (BST)
Subject: [R] problem building first package
In-Reply-To: <1182792527.467ffb4f655a6@mail-www.oit.umass.edu>
References: <1182787921.467fe951b35e5@mail-www.oit.umass.edu>
	<Pine.LNX.4.64.0706251752100.15740@gannet.stats.ox.ac.uk>
	<1182792527.467ffb4f655a6@mail-www.oit.umass.edu>
Message-ID: <Pine.LNX.4.64.0706251858001.16555@gannet.stats.ox.ac.uk>

It's a buglet: --docs=txt, works.

On Mon, 25 Jun 2007, Richard Chandler wrote:

> Thanks so much. I was able to get it installed using:
>
> R CMD INSTALL --docs=normal removal_1.0.tar.gz
>
> However, setting --docs=txt gave me this error:
>
> ERROR: invalid --docs value `txt'
>
> The --help says it needs to be a list, but no matter, --docs=normal
> worked fine.
>
>
> Quoting Prof Brian Ripley <ripley at stats.ox.ac.uk>:
>
>> You can ignore the message about latex (and 2.5.1 RC does not give
>> it).
>>
>> hhc is part of HTML Help Workshop: you either have not installed
>> that or
>> not put it in your path.
>>
>> The settings in MkRules affect the types of help for building R,
>> not 'R
>> CMD INSTALL'.  If you only want text help you need to run
>>
>> R CMD INSTALL --docs=txt removal_1.0.tar.gz
>>
>>
>> On Mon, 25 Jun 2007, Richard Chandler wrote:
>>
>>> Hi,
>>>
>>> I am trying to build a package from source for the first time.
>> I'm
>>> using Windows XP. After R CMD INSTALL or R CMD check I get an
>> error
>>> message that I don't understand. I've tried to follow the
>> instrucions
>>> provided in the R Installation and Administration .pdf and the
>> text
>>> file that comes with Rtools, but most of this is new to me and
>> clearly
>>> I'm missing something. Here's what I've done:
>>>
>>> -Downloaded perl and Rtools and put them in my c directory
>>> -Used package.skeleton() to set up the package structure and put
>> the
>>> package-to-be "removal" in C:\toBuild
>>> -I edited my path to :
>>> C:\Rtools\bin;C:\perl\bin;C:\Rtools\MinGW\bin;C:\R-2.5.0\bin;...
>>> -I changed the following in the MkRules file:
>>> 1)HEADER=C:/Rtools/MinGW/include
>>> 2)HELPTYPES = -txt
>>> 3)WINHELP = NO
>>> 4)HEADER=C:/Rtools/MinGW/include
>>> 5)R_EXE=C:/R-2.5.0/bin/R.exe
>>
>> The last two are for cross-building, not what you are doing.
>>
>>> -Next, I opened up a command prompt and went to c:/toBuild
>>> -Then I ran: R CMD build removal. No problems.
>>> -Then I ran: R CMD INSTALL removal_1.0.tar.gz
>>> and got this:
>>> ---------------------
>>> installing to 'c:/R-2.5.0/library'
>>>
>>> latex: not found
>>> latex: not found
>>> latex: not found
>>>
>>> ---------- Making package removal ------------
>>> latex: not found
>>>  adding build stamp to DESCRIPTION
>>> latex: not found
>>> latex: not found
>>> latex: not found
>>>  installing R files
>>> latex: not found
>>>  installing data files
>>> latex: not found
>>>  installing man source files
>>>  installing indices
>>> latex: not found
>>> latex: not found
>>>  not zipping data
>>>  installing help
>>>>>> Building/Updating help pages for package 'removal'
>>>     Formats: text chm
>>>  RemProbs                          text
>> chm
>>>  add.error                         text
>> chm
>>>  error.plot                        text
>> chm
>>>  firstDetect                       text
>> chm
>>>  funs                              text
>> chm
>>>  path                              text
>> chm
>>>  pll2                              text
>> chm
>>>  remll2                            text
>> chm
>>>  removal-package                   text
>> chm
>>>  removal2                          text
>> chm
>>>  var.d                             text
>> chm
>>> hhc: not found
>>> cp: cannot stat
>> `C:/toBuild/R.INSTALL.3064/removal/chm/removal.chm':
>>> No such fil
>>> e or directory
>>> make[1]: *** [chm-removal] Error 1
>>> make: *** [pkg-removal] Error 2
>>> *** Installation of removal failed ***
>>>
>>> Removing 'c:/R-2.5.0/library/removal'
>>> ---------------
>>>
>>> I don't know what hhc is. I'm guessing its trying to build the
>>> compiled help files even though I tried to ask for only text
>> files. It
>>> also seems to want latex even though I read that it isn't
>> necessary to
>>> build simple packages. Can someone please tell me what I'm doing
>>> wrong? Thanks.
>>>
>>> Richard
>>>
>>>
>>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,
>> http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From nikko at hailmail.net  Mon Jun 25 20:05:45 2007
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Mon, 25 Jun 2007 14:05:45 -0400
Subject: [R] complex contrasts and logistic regression
In-Reply-To: <46740C54.1030700@vanderbilt.edu>
References: <1181928550.18770.1195374609@webmail.messagingengine.com>
	<46740C54.1030700@vanderbilt.edu>
Message-ID: <1182794745.11098.1196965723@webmail.messagingengine.com>

Hi,
Sorry to take so long to reply, I was travelling last week. Thanks for
your
suggestions. Actually in this case contrast and predict gave the same
result,
and what I was looking at was the correct odds from the model. 

What is still confusing me is the 1st part of my question,
looking for a trend in odds ratios. From what I understand
testing the interaction:
fit1<-glmD(survived ~ as.numeric(Covariate)+Therapy +
confounder,myDat,X=TRUE, Y=TRUE, family=binomial())
fit2<-glmD(survived ~ as.numeric(Covariate)*Therapy +
confounder,myDat,X=TRUE, Y=TRUE, family=binomial()) 
lrtest(fit1,fit2)

Would be effectively testing for a trend in odds ratios? 
Do I have to fiddle with contrasts to make sure I am testing the correct
parameter?

Thanks
Nicholas

On Sat, 16 Jun 2007 11:14:12 -0500, "Frank E Harrell Jr"
<f.harrell at vanderbilt.edu> said:
> Nicholas Lewin-Koh wrote:
> > Hi,
> > I am doing a retrospective analysis on a cohort from a designed trial,
> > and I am fitting
> > the model
> > 
> > fit<-glmD(survived ~ Covariate*Therapy + confounder,myDat,X=TRUE,
> > Y=TRUE, family=binomial()) 
> 
> For logistic regression you can also use Design's lrm function which 
> gives you more options.
> 
> > 
> > My covariate has three levels ("A","B" and "C") and therapy has two
> > (treated and control), confounder is a continuous variable.
> > Also patients were randomized to treatment in the trial, but Covariate
> > is something that is measured
> > posthoc and can vary in the population.
> 
> If by posthoc you mean that the covariate is measured after baseline, it 
> is difficult to get an interpretable analysis.
> 
> >  
> > I am trying to wrap my head around how to calculate a few quantities
> > from the model
> > and get reasonable confidence intervals for them, namely I would like to
> > test
> > 
> > H0: gamma=0, where gamma is the regression coefficient of the odds
> > ratios of surviving
> >              under treatment vs control at each level of Covariate
> >              (adjusted for the confounder)
> 
> You mean regression coefficient on the log odds ratio scale.  This is 
> easy to do with the contrast( ) function in Design.  Do ?contrast.Design 
> for details and examples.
> 
> > 
> > and I would like to get the odds of surviving at each level of Covariate
> > under treatment and control
> > for each level of covariate adjusted for the confounder. I have looked
> > at contrast in the Design 
> > library but I don't think it gives me the right quantity, for instance 
> > 
> > contrast(fit,list(covariate="A", Therapy="Treated",
> > confounder=median(myDat$confounder), X=TRUE)
> > ( "A" is the baseline level of Covariate) 
> > 
> > gives me beta0 + beta_Treated + beta_confounder*68  
> > 
> > Is this correctly interpreted as the conditional odds of dying? 
> > As to the 1st contrast I am not sure how to get it, would it be using
> > type = 'average' with some weights 
> > in contrast? The answers are probably staring me in the face, i am just
> > not seeing them today.
> 
> contrast( ) is for contrasts (differences).  Sounds like you want 
> predicted values.  Do ?predict  ?predict.lrm  ?predict.Design.  Also do 
> ?gendata which will generate a data frame for getting predictors, with 
> unspecified predictors set to reference values such as medians.
> 
> Frank
> 
> > 
> > Nicholas
> > 
> > 
> > 
> 
> 
> -- 
> Frank E Harrell Jr   Professor and Chair           School of Medicine
>                       Department of Biostatistics   Vanderbilt University


From dieter.menne at menne-biomed.de  Mon Jun 25 20:18:08 2007
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Mon, 25 Jun 2007 18:18:08 +0000 (UTC)
Subject: [R] eps in odfWeave
References: <LPEJLJACLINDNMBMFAFIMEEICIAA.dieter.menne@menne-biomed.de>
	<71257D09F114DA4A8E134DEAC70F25D308C0401F@groamrexm03.amer.pfizer.com>
	<loom.20070625T180859-191@post.gmane.org>
Message-ID: <loom.20070625T201612-975@post.gmane.org>

Dieter Menne <dieter.menne <at> menne-biomed.de> writes:

> 
> library(odfWeave)
> plotInfo <- getImageDefs()
> plotInfo$type = "eps"
> plotInfo$plotWidth = 4
> plotInfo$plotHeight = 4
> plotInfo$device = "postscript"
> plotInfo$args = list( horizontal = FALSE,onefile = FALSE, paper = "special")
> setImageDefs(plotInfo)
> demoFile <- system.file("examples", "simple.odt", package ="odfWeave")
> odfWeave(demoFile, "c:/simpleOut.odt")
> 
> -----
> Error in check(options) : invalid value for 'type' : eps

Sorry, Max, my error (as you noted in private email). From an earlier attempt I
had forgotten to remove the incorrect <<....type="eps">> in the code.

Dieter


From jnwilks at btinternet.com  Mon Jun 25 20:35:25 2007
From: jnwilks at btinternet.com (John Wilkinson)
Date: Mon, 25 Jun 2007 19:35:25 +0100
Subject: [R] ANOVA non-sphericity test and corrections (eg,
	Greenhouse-Geisser)
Message-ID: <JCEIJNOHMNBPLMGFDHNDGECMCHAA.jnwilks@btinternet.com>


Darren,

Further to Peter Dalgaard's help;

Take a look at the example in ---

library(car)
?Anova  # note upper case 'A' 

The example in the Anova help page following the ---

## a multivariate linear model for repeated-measures data
## See ?OBrienKaiser for a description of the data set used in this example

gives a workings for --

## Greenhouse-Geisser and Huynh-Feldt Corrections
##  for Departure from Compound Symmetry

You might find that example helpful.

John


From rmh at temple.edu  Mon Jun 25 21:17:46 2007
From: rmh at temple.edu (Richard M. Heiberger)
Date: Mon, 25 Jun 2007 15:17:46 -0400 (EDT)
Subject: [R] Post-hoc tests for interactions of between- and
 within-subject factors
Message-ID: <20070625151746.CEX57651@po-d.temple.edu>

The glht function in package multcomp requires "aov" objects.
As you discovered, it does not work with "aovlist" objects.

See the documentation ?MMC in the HH package from CRAN.
The maiz example is similar to your example.  Come back
to the list if you need further help.

Rich


From Manuel.A.Morales at williams.edu  Mon Jun 25 21:32:18 2007
From: Manuel.A.Morales at williams.edu (Manuel Morales)
Date: Mon, 25 Jun 2007 15:32:18 -0400
Subject: [R] degrees of freedom in lme
In-Reply-To: <2323A6D37908A847A7C32F1E3662C80EE57794@dc1ex01.air.org>
References: <2323A6D37908A847A7C32F1E3662C80EE57794@dc1ex01.air.org>
Message-ID: <1182799938.2970.6.camel@localhost.localdomain>

On Mon, 2007-06-25 at 13:15 -0400, Doran, Harold wrote:
> This is such a common question that it has a an "FAQ-like" response from Doug Bates. Google "lmer p-values and all that" to find the response. 

Isn't this a different question, though, since Jean-Baptiste is using
nlme. 

Details on the calculation of DF in nlme can be found in chapter 4 of
the book by Pinheiro and Bates "Mixed Effects Models in S and S-PLUS.
Using the formula provided, I get denDF of 10 for level 1 and 32 for
level 2. I'm not sure why lme is using the denDF estimated at level 2 in
this example ...

> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch 
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> > Jean-Baptiste Ferdy
> > Sent: Monday, June 25, 2007 12:26 PM
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] degrees of freedom in lme
> > 
> > Dear all,
> > 
> > I am starting to use the lme package (and plan to teach a 
> > course based on it next semester...). To understand what lme 
> > is doing precisely, I used balanced datasets described in 
> > Pinheiro and Bates and tried to compare the lme outputs to 
> > that of aov. Here is what I obtained:
> > 
> > > data(Machines)
> > > summary(aov(score~Machine+Error(Worker/Machine),data=Machines))
> > Error: Worker
> >           Df  Sum Sq Mean Sq F value Pr(>F) Residuals  5 
> > 1241.89  248.38
> > 
> > Error: Worker:Machine
> >           Df  Sum Sq Mean Sq F value    Pr(>F)
> > Machine    2 1755.26  877.63  20.576 0.0002855 ***
> > Residuals 10  426.53   42.65
> > ---
> > Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> > 
> > Error: Within
> >           Df Sum Sq Mean Sq F value Pr(>F)
> > Residuals 36 33.287   0.925
> > > 
> > anova(lme(fixed=score~Machine,random=~1|Worker/Machine,data=Machines))
> >             numDF denDF  F-value p-value
> > (Intercept)     1    36 773.5709  <.0001
> > Machine         2    10  20.5762   3e-04
> >   
> > No problem here: the results are essentially the same, which 
> > is expected. Now I turn to an ANCOVA with a random grouping factor.
> > 
> > > data(Orthodont)
> > > OrthoFem <- Orthodont[Orthodont$Sex=="Female",];
> > > summary(aov(distance~age+Error(Subject/age),data=OrthoFem))
> > Error: Subject
> >           Df  Sum Sq Mean Sq F value Pr(>F) Residuals 10 
> > 177.227  17.723
> > 
> > Error: Subject:age
> >           Df Sum Sq Mean Sq F value    Pr(>F)
> > age        1 50.592  50.592  52.452 2.783e-05 ***
> > Residuals 10  9.645   0.965
> > ---
> > Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> > 
> > Error: Within
> >           Df Sum Sq Mean Sq F value Pr(>F) Residuals 22 9.8250  0.4466
> > > anova(lme(fixed=distance~age,random=~1+age|Subject,data=OrthoFem))
> >             numDF denDF   F-value p-value
> > (Intercept)     1    32 1269.7764  <.0001
> > age             1    32   52.4517  <.0001
> > 
> > This time the F values are (almost) identical, the numerator 
> > degrees of freedom are the same, but the denominator degrees 
> > of freedom are very different (10 for aov vs. 32 for lme). I 
> > understand that there is an issue with the estimation of that 
> > number, but I would naively expect the number given by lme to 
> > be close to that provided by aov is the case of a balanced 
> > dataset. That's obviously not true in the case of an 
> > ANCOVA... But why?? And how should I interpret the F-test 
> > given by anova.lme?
> > 
> > Thanks in advance for your help !
> > --
> > Jean-Baptiste Ferdy
> > Institut des Sciences de l'?volution de Montpellier CNRS UMR 
> > 5554 Universit? Montpellier 2
> > 34 095 Montpellier cedex 05
> > tel. +33 (0)4 67 14 42 27
> > fax  +33 (0)4 67 14 36 22
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
-- 
Manuel A. Morales
http://mutualism.williams.edu

From dan.oshea at dnr.state.mn.us  Mon Jun 25 22:05:44 2007
From: dan.oshea at dnr.state.mn.us (Daniel O'Shea)
Date: Mon, 25 Jun 2007 15:05:44 -0500
Subject: [R] correlation structure
Message-ID: <467FD9C7.537F.005A.0@dnr.state.mn.us>

I have been using a nlme model and wish to specify the correlation structure.  My data is grouped (bas), but I have no time component or adequate spatial description beyond the grouping variable. So I chose the simplest structure and updated my original nlme model by:
update(model, corr=corCompSymm(~1|bas))

This is not significant.  One of my variables measures area upstream of the sample.  Area is a continuous variable, and there are some identical values of area.  Can I model the dependence among residuals with in group (bas) and along area?  Can the corCAR1 be used and the area used as a position variable?  If so does the position variable need to be sorted when using the corCAR1 structure?  Or could one use spatial classes and use area as one position and watershed as the other substituting numbers for the grouping variable?  I have been trying, but R keeps crashing when I specify correlation structures other than compound symmetry.  I assume this is because I am not specifying the form correctly.  Any suggestions would be appreciated.

Dan


From mnair at iusb.edu  Mon Jun 25 22:10:12 2007
From: mnair at iusb.edu (Nair, Murlidharan T)
Date: Mon, 25 Jun 2007 16:10:12 -0400
Subject: [R] debug()
Message-ID: <A32055BDEA88C34BB3DBBCD229380778012C8B58@iu-mssg-mbx109.ads.iu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070625/2b13108b/attachment.pl 

From helprhelp at gmail.com  Mon Jun 25 22:19:20 2007
From: helprhelp at gmail.com (Weiwei Shi)
Date: Mon, 25 Jun 2007 16:19:20 -0400
Subject: [R] a string to enviroment or function
In-Reply-To: <644e1f320706250917o58481269xe471cae399f1c4a5@mail.gmail.com>
References: <cdf817830706250842l3dd9a812v14c94a7609d18225@mail.gmail.com>
	<644e1f320706250917o58481269xe471cae399f1c4a5@mail.gmail.com>
Message-ID: <cdf817830706251319i2e1768e7nca5bec8e13058f1@mail.gmail.com>

then how to do this

f1 <- function(mylab){
  library(mylab)
  ...
}

it seems that if you call
library("hgu133a") # which is file
# but
library(mylab) # even you pass "hgu133a" as parameter, it still
complains about "mylab" does not exist. It seems that it consider
mylab as package instead of its value.


On 6/25/07, jim holtman <jholtman at gmail.com> wrote:
> I think that you might want:
>
> t0 <- (paste("hgu133a", "ENTREZID", sep=""))
> xx <- as.list(get(t0)) # make it work like xx<-as.list(hgu133aENTREZID)
>
>
>
>
> On 6/25/07, Weiwei Shi <helprhelp at gmail.com> wrote:
> >
> > Hi,
> >
> > I am wondering how to make a function Fun to make the following work:
> >
> > t0 <- (paste("hgu133a", "ENTREZID", sep=""))
> > xx <- as.list(Fun(t0)) # make it work like xx<-as.list(hgu133aENTREZID)
> >
> > thanks,
> > --
> > Weiwei Shi, Ph.D
> > Research Scientist
> > GeneGO, Inc.
> >
> > "Did you always know?"
> > "No, I did not. But I believed..."
> > ---Matrix III
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
>
> --
> Jim Holtman
> Cincinnati, OH
> +1 513 646 9390
>
> What is the problem you are trying to solve?


-- 
Weiwei Shi, Ph.D
Research Scientist
GeneGO, Inc.

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III


From andrej.kastrin at siol.net  Mon Jun 25 22:50:59 2007
From: andrej.kastrin at siol.net (Andrej Kastrin)
Date: Mon, 25 Jun 2007 22:50:59 +0200
Subject: [R] How to shadow 'power' area?
Message-ID: <46802AB3.20409@siol.net>

Dear all,

Suppose I plot two normal distributions (A and B) side by side and add 
vertical line which hipotheticaly represent alpha value; e.g.:

x <- seq(-3.5,5, length=1000)
y <- dnorm(x)
# Plot distribution A
plot(y~x, type='l',axes=F,xlab="",ylab="",lwd=2)
# Plot distribution B
y2 <- dnorm(x-1.5)
lines(y2~x,lwd=2)
# Plot vertical line for alpha value
abline(h=0)
segments(qnorm(.5)+1.5,0,qnorm(.5)+1.5,dnorm(qnorm(.5)))
text(2,0.2,"Power")

Now I want to shadow area labeled as "Power". Any suggestion how to do 
that using 'polygon' function?

Thanks in advance for any suggestion.

Andrej


From christos at nuverabio.com  Mon Jun 25 23:00:40 2007
From: christos at nuverabio.com (Christos Hatzis)
Date: Mon, 25 Jun 2007 17:00:40 -0400
Subject: [R] How to shadow 'power' area?
In-Reply-To: <46802AB3.20409@siol.net>
References: <46802AB3.20409@siol.net>
Message-ID: <005601c7b76b$e3f311d0$0e010a0a@headquarters.silicoinsights>

Look at the following link:

http://addictedtor.free.fr/graphiques/RGraphGallery.php?graph=88 

This should be pretty close to what you want.
HTH

-Christos

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Andrej Kastrin
> Sent: Monday, June 25, 2007 4:51 PM
> To: R-help
> Subject: [R] How to shadow 'power' area?
> 
> Dear all,
> 
> Suppose I plot two normal distributions (A and B) side by 
> side and add vertical line which hipotheticaly represent 
> alpha value; e.g.:
> 
> x <- seq(-3.5,5, length=1000)
> y <- dnorm(x)
> # Plot distribution A
> plot(y~x, type='l',axes=F,xlab="",ylab="",lwd=2)
> # Plot distribution B
> y2 <- dnorm(x-1.5)
> lines(y2~x,lwd=2)
> # Plot vertical line for alpha value
> abline(h=0)
> segments(qnorm(.5)+1.5,0,qnorm(.5)+1.5,dnorm(qnorm(.5)))
> text(2,0.2,"Power")
> 
> Now I want to shadow area labeled as "Power". Any suggestion 
> how to do that using 'polygon' function?
> 
> Thanks in advance for any suggestion.
> 
> Andrej
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
>


From marc_schwartz at comcast.net  Mon Jun 25 23:02:08 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Mon, 25 Jun 2007 16:02:08 -0500
Subject: [R] How to shadow 'power' area?
In-Reply-To: <46802AB3.20409@siol.net>
References: <46802AB3.20409@siol.net>
Message-ID: <1182805328.3841.61.camel@Bellerophon.localdomain>

On Mon, 2007-06-25 at 22:50 +0200, Andrej Kastrin wrote:
> Dear all,
> 
> Suppose I plot two normal distributions (A and B) side by side and add 
> vertical line which hipotheticaly represent alpha value; e.g.:
> 
> x <- seq(-3.5,5, length=1000)
> y <- dnorm(x)
> # Plot distribution A
> plot(y~x, type='l',axes=F,xlab="",ylab="",lwd=2)
> # Plot distribution B
> y2 <- dnorm(x-1.5)
> lines(y2~x,lwd=2)
> # Plot vertical line for alpha value
> abline(h=0)
> segments(qnorm(.5)+1.5,0,qnorm(.5)+1.5,dnorm(qnorm(.5)))
> text(2,0.2,"Power")
> 
> Now I want to shadow area labeled as "Power". Any suggestion how to do 
> that using 'polygon' function?
> 
> Thanks in advance for any suggestion.
> 
> Andrej

See the latter section of this post:

http://tolstoy.newcastle.edu.au/R/help/03b/2475.html

and in turn, ?polygon

HTH,

Marc Schwartz


From bolker at ufl.edu  Mon Jun 25 23:01:43 2007
From: bolker at ufl.edu (Ben Bolker)
Date: Mon, 25 Jun 2007 21:01:43 +0000 (UTC)
Subject: [R] LanguageR pvals.fnc error message
References: <467FECFA.4080809@csl.psychol.cam.ac.uk>
Message-ID: <loom.20070625T225322-635@post.gmane.org>

Mike Ford <mford <at> csl.psychol.cam.ac.uk> writes:

> 
> Hi. I get an error message about not converging when I try and use the 
> pvals.fnc from the languageR library. The LMER analysis worked fine (See 
> below).
> 
> I am not an expert so I don't understand why the LMER worked but not the 
> pvals.fnc
> 
> Any help gratefully received.
> 
> - Mike

  results of traceback() after the error?
  precise wording of the error message?
  any chance of sending to the list, or posting, a data
set that produces the error?  (see the posting guide ...)

  on the face of it is puzzling because pvals.fnc doesn't
seem to do any fitting, just post-processing of the lmer
object ...

  (by the way, that's "the languageR package" --
library(fortunes); fortune("Maechler.*package"))

  Ben Bolker


From vivek.menon79 at gmail.com  Mon Jun 25 23:12:46 2007
From: vivek.menon79 at gmail.com (Vivek Menon)
Date: Mon, 25 Jun 2007 17:12:46 -0400
Subject: [R] Problem installing MCMCpack
Message-ID: <bf6a5a630706251412m44003a04ta7bbdba326a21d9e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070625/3fca3709/attachment.pl 

From tkremund98 at hotmail.com  Mon Jun 25 23:15:59 2007
From: tkremund98 at hotmail.com (Todd Remund)
Date: Mon, 25 Jun 2007 15:15:59 -0600
Subject: [R] fft and the derivative
Message-ID: <BAY121-F248EE722057148A88C076BD4140@phx.gbl>

Can one take f(t) and transform to F(omega) in the frequency domain using 
fft(), and use the properties of the fft and find the derivative of f(t)?  
For example,

f(t) <-> F(omega) => f(t)^n <-> (i*omega)^n  *  F(omega)

Use this and get,

f(t)^n = F^(-) [ (i*omega)^n  *  F(omega) ]

to get the nth derivative of f(t)?
Todd Remund


From fdoespin at gmail.com  Mon Jun 25 19:31:19 2007
From: fdoespin at gmail.com (fernando espindola)
Date: Mon, 25 Jun 2007 17:31:19 +0000
Subject: [R] Quiver in 1d
Message-ID: <467FFBE7.8060408@gmail.com>

Dear all R-users,

I am try to plot quiver in one dimension, but there is only code for two 
dimension in different R web pages. Somebody know same code that can 
help me in plot quiver in one dimension. Any help gratefully received .

Thanks for all

Fernando


From mtmorgan at fhcrc.org  Mon Jun 25 23:28:57 2007
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Mon, 25 Jun 2007 14:28:57 -0700
Subject: [R] a string to enviroment or function
In-Reply-To: <cdf817830706251319i2e1768e7nca5bec8e13058f1@mail.gmail.com>
	(Weiwei Shi's message of "Mon, 25 Jun 2007 16:19:20 -0400")
References: <cdf817830706250842l3dd9a812v14c94a7609d18225@mail.gmail.com>
	<644e1f320706250917o58481269xe471cae399f1c4a5@mail.gmail.com>
	<cdf817830706251319i2e1768e7nca5bec8e13058f1@mail.gmail.com>
Message-ID: <6phsl8fraee.fsf@gopher4.fhcrc.org>

Weiwei

See ?library and the character.only argument.

> f <- function(x) library(x)
> f("hgu95av2")
Error in library(x) : there is no package called 'x'
> f <- function(x) library(x, character.only=TRUE)
> f("hgu95av2")
> search()
 [1] ".GlobalEnv"        "package:hgu95av2"  "package:stats"    
 [4] "package:graphics"  "package:grDevices" "package:utils"    
 [7] "package:datasets"  "package:methods"   "Autoloads"        
[10] "package:base"     

Also

> g <- function(x) as.list(get(paste(x, "ENTREZID", sep="")))
> ll <- g("hgu95av2")
> length(ll)
[1] 12625

and finally reverseSplit in Biobase and revmap in AnnotationDbi might
be helpful (though AnnotationDbi is only available with R-devel and
revmap seems not to be documented).

> res <- revmap(hgu95av2ENTREZID)
> hgu95av2ENTREZID[["1190_at"]]
[1] 5800
> res[["5800"]]
[1] "1190_at"  "32199_at"


Martin

"Weiwei Shi" <helprhelp at gmail.com> writes:

> then how to do this
>
> f1 <- function(mylab){
>   library(mylab)
>   ...
> }
>
> it seems that if you call
> library("hgu133a") # which is file
> # but
> library(mylab) # even you pass "hgu133a" as parameter, it still
> complains about "mylab" does not exist. It seems that it consider
> mylab as package instead of its value.
>
>
> On 6/25/07, jim holtman <jholtman at gmail.com> wrote:
>> I think that you might want:
>>
>> t0 <- (paste("hgu133a", "ENTREZID", sep=""))
>> xx <- as.list(get(t0)) # make it work like xx<-as.list(hgu133aENTREZID)
>>
>>
>>
>>
>> On 6/25/07, Weiwei Shi <helprhelp at gmail.com> wrote:
>> >
>> > Hi,
>> >
>> > I am wondering how to make a function Fun to make the following work:
>> >
>> > t0 <- (paste("hgu133a", "ENTREZID", sep=""))
>> > xx <- as.list(Fun(t0)) # make it work like xx<-as.list(hgu133aENTREZID)
>> >
>> > thanks,
>> > --
>> > Weiwei Shi, Ph.D
>> > Research Scientist
>> > GeneGO, Inc.
>> >
>> > "Did you always know?"
>> > "No, I did not. But I believed..."
>> > ---Matrix III
>> >
>> > ______________________________________________
>> > R-help at stat.math.ethz.ch mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>
>>
>> --
>> Jim Holtman
>> Cincinnati, OH
>> +1 513 646 9390
>>
>> What is the problem you are trying to solve?
>
>
> -- 
> Weiwei Shi, Ph.D
> Research Scientist
> GeneGO, Inc.
>
> "Did you always know?"
> "No, I did not. But I believed..."
> ---Matrix III
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Martin Morgan
Bioconductor / Computational Biology
http://bioconductor.org


From murdoch at stats.uwo.ca  Mon Jun 25 23:31:18 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 25 Jun 2007 17:31:18 -0400
Subject: [R] a string to enviroment or function
In-Reply-To: <cdf817830706251319i2e1768e7nca5bec8e13058f1@mail.gmail.com>
References: <cdf817830706250842l3dd9a812v14c94a7609d18225@mail.gmail.com>	<644e1f320706250917o58481269xe471cae399f1c4a5@mail.gmail.com>
	<cdf817830706251319i2e1768e7nca5bec8e13058f1@mail.gmail.com>
Message-ID: <46803426.6050409@stats.uwo.ca>

On 25/06/2007 4:19 PM, Weiwei Shi wrote:
> then how to do this
> 
> f1 <- function(mylab){
>   library(mylab)
>   ...
> }
> 
> it seems that if you call
> library("hgu133a") # which is file
> # but
> library(mylab) # even you pass "hgu133a" as parameter, it still
> complains about "mylab" does not exist. It seems that it consider
> mylab as package instead of its value.

One of the examples in ?library shows how to do what you want.

pkg <- "splines"
library(pkg, character.only = TRUE)

Duncan Murdoch

>>> Weiwei Shi, Ph.D
>>> Research Scientist
>>> GeneGO, Inc.

P.S. If you think this was helpful, one of the ways to contribute back 
to the R project would be to ask your employer to become an 
institutional member:  see

http://www.r-project.org/foundation/membership.html


From etiennesky at yahoo.com  Mon Jun 25 23:44:23 2007
From: etiennesky at yahoo.com (Etienne)
Date: Mon, 25 Jun 2007 17:44:23 -0400 (EDT)
Subject: [R] changing the position of the y label (ylab)
Message-ID: <732557.21159.qm@web36913.mail.mud.yahoo.com>

How can I change the position of the ylab, after
enlarging the margins with par(mar=...)? 

Here is the relevant code snippet

----
par(mar=c(5.1,5.1,4.1,2.1))
plot(c(1979,2003),c(40,50),ylim=c(1,73),lab=c(20,10,1),pch=21,col='blue',bg='blue',axes=FALSE,xlab="Years",ylab="Onset/Withdrawl
Date",font.lab=2)
box()
axis(1,las=2)
axis(2,las=2,labels=c('JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC','JAN'),at=seq(from=1,to=73,by=6))
axis(3,labels=FALSE)
axis(4,labels=FALSE,at=seq(from=1,to=73,by=6))
----

Thanks


From Greg.Snow at intermountainmail.org  Mon Jun 25 23:45:34 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Mon, 25 Jun 2007 15:45:34 -0600
Subject: [R] How to shadow 'power' area?
In-Reply-To: <46802AB3.20409@siol.net>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBA5A98E@LP-EXCHVS07.CO.IHC.COM>

You can look at the power.examp function in the TeachingDemos package to
see if it gives you the graph you want, or look at the code to see how
you could modify it to give you the plot you want.

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Andrej Kastrin
> Sent: Monday, June 25, 2007 2:51 PM
> To: R-help
> Subject: [R] How to shadow 'power' area?
> 
> Dear all,
> 
> Suppose I plot two normal distributions (A and B) side by 
> side and add vertical line which hipotheticaly represent 
> alpha value; e.g.:
> 
> x <- seq(-3.5,5, length=1000)
> y <- dnorm(x)
> # Plot distribution A
> plot(y~x, type='l',axes=F,xlab="",ylab="",lwd=2)
> # Plot distribution B
> y2 <- dnorm(x-1.5)
> lines(y2~x,lwd=2)
> # Plot vertical line for alpha value
> abline(h=0)
> segments(qnorm(.5)+1.5,0,qnorm(.5)+1.5,dnorm(qnorm(.5)))
> text(2,0.2,"Power")
> 
> Now I want to shadow area labeled as "Power". Any suggestion 
> how to do that using 'polygon' function?
> 
> Thanks in advance for any suggestion.
> 
> Andrej
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From HDoran at air.org  Tue Jun 26 00:32:25 2007
From: HDoran at air.org (Doran, Harold)
Date: Mon, 25 Jun 2007 18:32:25 -0400
Subject: [R] degrees of freedom in lme
References: <2323A6D37908A847A7C32F1E3662C80EE57794@dc1ex01.air.org>
	<1182799938.2970.6.camel@localhost.localdomain>
Message-ID: <2323A6D37908A847A7C32F1E3662C80EB5E69D@dc1ex01.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070625/8803ddb9/attachment.pl 

From rvaradhan at jhmi.edu  Tue Jun 26 00:49:21 2007
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Mon, 25 Jun 2007 18:49:21 -0400
Subject: [R] fft and the derivative
In-Reply-To: <BAY121-F248EE722057148A88C076BD4140@phx.gbl>
References: <BAY121-F248EE722057148A88C076BD4140@phx.gbl>
Message-ID: <000001c7b77b$123bae30$7c94100a@win.ad.jhu.edu>

Todd, 

Your idea is correct for "continuous" Fourier transform, but I am not sure
how one could apply that to fft, which corresponds to the discrete Fourier
transform.  For instance, what values of omega would you use for the term
"i*omega" to get the discrete fourier transform of the derivative of f(t)?  

Ravi.

----------------------------------------------------------------------------
-------

Ravi Varadhan, Ph.D.

Assistant Professor, The Center on Aging and Health

Division of Geriatric Medicine and Gerontology 

Johns Hopkins University

Ph: (410) 502-2619

Fax: (410) 614-9625

Email: rvaradhan at jhmi.edu

Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html

 

----------------------------------------------------------------------------
--------

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Todd Remund
Sent: Monday, June 25, 2007 5:16 PM
To: r-help at stat.math.ethz.ch
Subject: [R] fft and the derivative

Can one take f(t) and transform to F(omega) in the frequency domain using 
fft(), and use the properties of the fft and find the derivative of f(t)?  
For example,

f(t) <-> F(omega) => f(t)^n <-> (i*omega)^n  *  F(omega)

Use this and get,

f(t)^n = F^(-) [ (i*omega)^n  *  F(omega) ]

to get the nth derivative of f(t)?
Todd Remund

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From etiennesky at yahoo.com  Tue Jun 26 00:49:28 2007
From: etiennesky at yahoo.com (Etienne)
Date: Mon, 25 Jun 2007 18:49:28 -0400 (EDT)
Subject: [R] changing the position of the y label (ylab)
In-Reply-To: <46803D01.4050808@biomserv.univ-lyon1.fr>
Message-ID: <570068.46770.qm@web36904.mail.mud.yahoo.com>

Thanks (Merci) Christophe!

that did it

--- Christophe Bonenfant
<bonenfan at biomserv.univ-lyon1.fr> wrote:

> Hi Etienne - consider to use the mtext function:
> 
>  > par(mar=c(5.1,5.1,4.1,2.1))
>  >
>
plot(c(1979,2003),c(40,50),ylim=c(1,73),lab=c(20,10,1),
>
pch=21,col='blue',bg='blue',axes=FALSE,xlab="",ylab="",font.lab=2)
>  > box()
>  > axis(1,las=2)
>  >
>
axis(2,las=2,labels=c('JAN','FEB','MAR','APR','MAY','JUN','JUL',
>
'AUG','SEP','OCT','NOV','DEC','JAN'),at=seq(from=1,to=73,by=6))
>  > axis(3,labels=FALSE)
>  > axis(4,labels=FALSE,at=seq(from=1,to=73,by=6))
>  > mtext("Years", 1, 3.5, cex = 1.7)
> # first interger is the axis number, second number
> is the distance to 
> the axis
>  > mtext("Onset/Withdrawl Date", 2, 4, cex = 1.7)
> 
> see ?mtext
> 
> Christophe
> 
> Etienne a ?crit :
> > How can I change the position of the ylab, after
> > enlarging the margins with par(mar=...)? 
> > 
> > Here is the relevant code snippet
> > 
> > ----
> > par(mar=c(5.1,5.1,4.1,2.1))
> >
>
plot(c(1979,2003),c(40,50),ylim=c(1,73),lab=c(20,10,1),pch=21,col='blue',bg='blue',axes=FALSE,xlab="Years",ylab="Onset/Withdrawl
> > Date",font.lab=2)
> > box()
> > axis(1,las=2)
> >
>
axis(2,las=2,labels=c('JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC','JAN'),at=seq(from=1,to=73,by=6))
> > axis(3,labels=FALSE)
> > axis(4,labels=FALSE,at=seq(from=1,to=73,by=6))
> > ----
> > 
> > Thanks
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained,
> reproducible code.
> > 
> > 
>


From gonzalezperezmanuel at gmail.com  Tue Jun 26 01:37:57 2007
From: gonzalezperezmanuel at gmail.com (Manuel)
Date: Tue, 26 Jun 2007 01:37:57 +0200
Subject: [R] running Rcmdr
In-Reply-To: <834727.30145.qm@web56609.mail.re3.yahoo.com>
References: <834727.30145.qm@web56609.mail.re3.yahoo.com>
Message-ID: <468051D5.4070702@gmail.com>

Thanks for your answer, but i think i dont do correctly my question.
I need the command line to run Rmdr, like that:
R < Rcmdr or  R < loadRcmdr.R where loadRcmdr has "library("Rcmdr").
or something like that.
I tried the last example, but when Rcmdr is executed, later it is closed.
About RProfile.site, i dont know what i have to change. If you think its 
useful to me, please explain me.
Thanks.

Felipe Carrillo escribi?:
> First, you need to install the Rcmdr packages and then in the R 
> Command window or Tinn-R window type "library(Rcmdr)" without the 
> quotation marks. In addition, if you want Rcmdr to start automatically 
> everytime you start R, go to the following path C:\Program 
> Files\R\R-2.5.0\etc\RProfile.site if you installed R in program files, 
> otherwise follow your own path and type the same command 
> library(Rcmdr) and the R commander window should pop up everytime you 
> start R
>  
>
> */Manuel <gonzalezperezmanuel en gmail.com>/* wrote:
>
>     Hi to all,
>
>     i want to know how can run Rcmdr automatically , or how to load a
>     library in the call of R
>
>     greetings
>
>     ______________________________________________
>     R-help en stat.math.ethz.ch mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>
> ------------------------------------------------------------------------
> Choose the right car based on your needs. Check out Yahoo! Autos new 
> Car Finder tool. 
> <http://us.rd.yahoo.com/evt=48518/*http://autos.yahoo.com/carfinder/;_ylc=X3oDMTE3NWsyMDd2BF9TAzk3MTA3MDc2BHNlYwNtYWlsdGFncwRzbGsDY2FyLWZpbmRlcg--%20>


From m_olshansky at yahoo.com  Tue Jun 26 02:16:42 2007
From: m_olshansky at yahoo.com (Moshe Olshansky)
Date: Mon, 25 Jun 2007 17:16:42 -0700 (PDT)
Subject: [R] R-excel
In-Reply-To: <003901c7b727$0e321800$914e959f@erika>
Message-ID: <683232.10567.qm@web32201.mail.mud.yahoo.com>

Also try xlsReadWrite package on CRAN.

--- Erika Frigo <erika.frigo at unimi.it> wrote:

> 
> Good morning to everybody,
> I have a problem : how can I import excel files in
> R???
> 
> thank you very much
> 
> 
> Dr.sa. Erika Frigo
> Universit? degli Studi di Milano
> Facolt? di Medicina Veterinaria
> Dipartimento di Scienze e Tecnologie Veterinarie per
> la Sicurezza Alimentare (VSA)
>  
> Via Grasselli, 7
> 20137 Milano
> Tel. 02/50318515
> Fax 02/50318501
> 	[[alternative HTML version deleted]]
> 
> > ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From irishhacker at gmail.com  Tue Jun 26 02:34:57 2007
From: irishhacker at gmail.com (Robert Wilkins)
Date: Mon, 25 Jun 2007 19:34:57 -0500
Subject: [R] Has anyone tryed out my software?
Message-ID: <874da0b40706251734i15a185acu3f970cfaaacc395@mail.gmail.com>

Hello all,

Has anyone ( who uses a Linux desktop ) tryed out my stuff I mentioned
a few weeks ago?
Perhaps installed it and run a couple of example programs?

If you have, tell me what you think.


Robert


( it's the tarball in the download section at
http://code.google.com/p/vilno , discussed briefly in comparison to
Awk a couple of weeks ago )



PS

Of R users: how many use Windows XP, how many use an Apple, and how
many use a Linux desktop? Are there a lot of Linux users out there?

Is R more popular in Europe than North America? I'll need to do a
statistical analysis of the mailing list. I notice a ton of Europeans.


From Keith.Chamberlain at Colorado.EDU  Tue Jun 26 03:29:18 2007
From: Keith.Chamberlain at Colorado.EDU (Keith Alan Chamberlain)
Date: Mon, 25 Jun 2007 19:29:18 -0600 (MDT)
Subject: [R] a-priori orthogonal contrasts
Message-ID: <20070625192918.AFJ41544@batman.int.colorado.edu>

Dear R-helpers,

I have some stacked data with which I want to generate orthogonal contrasts - with the caveat that I determine what means comparisons are taking place a-priori.

Does it matter for e.g. 'contr.SUM' that the data are stacked, and does 'contr.SUM' allow me to set the contrasts efficiently even if the data are unballanced? Is there an alternative in R I should consider?

Sincerely,
KeithC.
Psych Undergrad, CU Boulder (US)


From erich.neuwirth at univie.ac.at  Tue Jun 26 06:05:17 2007
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Tue, 26 Jun 2007 06:05:17 +0200
Subject: [R] R-excel
In-Reply-To: <003901c7b727$0e321800$914e959f@erika>
References: <003901c7b727$0e321800$914e959f@erika>
Message-ID: <4680907D.8020506@univie.ac.at>

The R(D)COM server (contaiong the RExcel Excel addin) and/or the rcom
package allow (among other things) to select a range in Excel and
directly transfer it to R as an array or as a dataframe.
It only works on Windows with Excel and R installed.

More information on these packages is available at

http://rcom.univie.ac.at


Erika Frigo wrote:
> Good morning to everybody,
> I have a problem : how can I import excel files in R???
> 
> thank you very much
> 
> 
> Dr.sa. Erika Frigo
> Universit? degli Studi di Milano
> Facolt? di Medicina Veterinaria
> Dipartimento di Scienze e Tecnologie Veterinarie per la Sicurezza Alimentare (VSA)
>  
> Via Grasselli, 7
> 20137 Milano
> Tel. 02/50318515
> Fax 02/50318501
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Erich Neuwirth, Didactic Center for Computer Science
University of Vienna
Visit our SunSITE at http://sunsite.univie.ac.at
Phone: +43-1-4277-39464 Fax: +43-1-4277-9394


From ashoka.pol at gmail.com  Tue Jun 26 06:55:18 2007
From: ashoka.pol at gmail.com (Ashoka Polpitiya)
Date: Mon, 25 Jun 2007 21:55:18 -0700
Subject: [R] Howto fix colors in colorRampPalette?
Message-ID: <1fc8201f0706252155r7efcded0jc922faf4d1f157da@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070625/688a5518/attachment.pl 

From brown_emu at yahoo.com  Tue Jun 26 07:49:04 2007
From: brown_emu at yahoo.com (Stephen Tucker)
Date: Mon, 25 Jun 2007 22:49:04 -0700 (PDT)
Subject: [R] R-excel
In-Reply-To: <003901c7b727$0e321800$914e959f@erika>
Message-ID: <891846.29289.qm@web39711.mail.mud.yahoo.com>

There are also some notes about this in the R Data Import/Export manual: 
http://cran.r-project.org/doc/manuals/R-data.html#Reading-Excel-spreadsheets

But I've gathered the following examples from the R-help mailing list
archives [in addition to the option of saving the spreadsheet as a .csv file
and reading it in with read.csv()]. Personally, I use option 4 regularly (I
happened to have Perl installed on my Windows XP machine already) and have
had good luck with it.

Hope this helps.

========= Option 1 =========
# SIMPLEST OPTION
install.packages(xlsReadWrite)
library(xlsReadWrite)
data = read.xls("sampledata.xls",sheet=1)

========= Option 2 =========
# ALSO SIMPLE BUT MORE MANUAL WORK EACH TIME
# (1) highlight region in Excel you want to import and
data = read.delim(file="clipboard",header=TRUE)
# or, if you don't have a header,
data = read.delim(file="clipboard",header=FALSE)

========= Option 3 =========
# RODBC IS A BIG APPLICATION, FOR INTERFACING
# WITH MANY TYPES OF FILES/SERVERS
install.packages(RODBC)
library(RODBC)
fid <- odbcConnectExcel("sampledata.xls")
data <- sqlFetch(fid,"Sheet1")
close(fid)

========= Option 4 =========
# REQUIRES CONCURRENT INSTALLATION OF PERL
install.packages(gdata)
library(gdata)
data = read.xls("sampledata.xls",sheet=1)

============================ 



--- Erika Frigo <erika.frigo at unimi.it> wrote:

> 
> Good morning to everybody,
> I have a problem : how can I import excel files in R???
> 
> thank you very much
> 
> 
> Dr.sa. Erika Frigo
> Universit? degli Studi di Milano
> Facolt? di Medicina Veterinaria
> Dipartimento di Scienze e Tecnologie Veterinarie per la Sicurezza
> Alimentare (VSA)
>  
> Via Grasselli, 7
> 20137 Milano
> Tel. 02/50318515
> Fax 02/50318501
> 	[[alternative HTML version deleted]]
> 
> > ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 



       
____________________________________________________________________________________

Comedy with an Edge to see what's on, when.


From brown_emu at yahoo.com  Tue Jun 26 08:04:42 2007
From: brown_emu at yahoo.com (Stephen Tucker)
Date: Mon, 25 Jun 2007 23:04:42 -0700 (PDT)
Subject: [R] simultaneous actions of grep ???
In-Reply-To: <E97312684A84D511BDD40002A50968D60A41B785@lxpobw01.ine.pt>
Message-ID: <930507.37428.qm@web39705.mail.mud.yahoo.com>

You can list them together using "|" (which stands for 'or'):

  c<-subset(c,!rownames(c) %in% grep(".1|.5|.6|.99999",rownames(c),value=T))

but "." means any character for regular expressions, so if you meant a
decimal place, you probably want to escape them with a "\\":

  c<-subset(c,!rownames(c) %in%
            grep("\\.1|\\.5|\\.6|\\.99999", rownames(c),value=T))

Another option is

  c<-subset(c,regexpr("\\.1|\\.5|\\.6|\\.99999",c) < 0)

because regexpr will return -1 for elements which do not contain a match.


--- Ana Patricia Martins <ana.pmartins at ine.pt> wrote:

> Hello R-users and developers,
> 
> Once again, I'm asking for your help.
> 
> There is other way to do the same more easily for applied simultaneous
> grep???
>   
>     c<-subset(c,!rownames(c) %in% grep(".1",rownames(c),value=T))
>     c<-subset(c,!rownames(c) %in% grep(".5",rownames(c),value=T))
>     c<-subset(c,!rownames(c) %in% grep(".6",rownames(c),value=T))
>     c<-subset(c,!rownames(c) %in% grep(".99999",rownames(c),value=T))
> 
> Thanks in advance for helping me.
> 
> Atenciosamente,
> Ana Patricia Martins
> -------------------------------------------
> Servi?o M?todos Estat?sticos
> Departamento de Metodologia Estat?stica
> INE - Portugal
> Telef:  218 426 100 - Ext: 3210
> E-mail: ana.pmartins at ine.pt <mailto:ana.pmartins at ine.pt> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> > ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From brown_emu at yahoo.com  Tue Jun 26 08:54:19 2007
From: brown_emu at yahoo.com (Stephen Tucker)
Date: Mon, 25 Jun 2007 23:54:19 -0700 (PDT)
Subject: [R] simultaneous actions of grep ???
In-Reply-To: <930507.37428.qm@web39705.mail.mud.yahoo.com>
Message-ID: <150281.24982.qm@web39709.mail.mud.yahoo.com>

My mistake... last alternative should be:

   c<-subset(c,regexpr("\\.1|\\.5|\\.6|\\.99999",rownames(c)) < 0)

--- Stephen Tucker <brown_emu at yahoo.com> wrote:

> You can list them together using "|" (which stands for 'or'):
> 
>   c<-subset(c,!rownames(c) %in%
> grep(".1|.5|.6|.99999",rownames(c),value=T))
> 
> but "." means any character for regular expressions, so if you meant a
> decimal place, you probably want to escape them with a "\\":
> 
>   c<-subset(c,!rownames(c) %in%
>             grep("\\.1|\\.5|\\.6|\\.99999", rownames(c),value=T))
> 
> Another option is
> 
>   c<-subset(c,regexpr("\\.1|\\.5|\\.6|\\.99999",c) < 0)
> 
> because regexpr will return -1 for elements which do not contain a match.
> 
> 
> --- Ana Patricia Martins <ana.pmartins at ine.pt> wrote:
> 
> > Hello R-users and developers,
> > 
> > Once again, I'm asking for your help.
> > 
> > There is other way to do the same more easily for applied simultaneous
> > grep???
> >   
> >     c<-subset(c,!rownames(c) %in% grep(".1",rownames(c),value=T))
> >     c<-subset(c,!rownames(c) %in% grep(".5",rownames(c),value=T))
> >     c<-subset(c,!rownames(c) %in% grep(".6",rownames(c),value=T))
> >     c<-subset(c,!rownames(c) %in% grep(".99999",rownames(c),value=T))
> > 
> > Thanks in advance for helping me.
> > 
> > Atenciosamente,
> > Ana Patricia Martins
> > -------------------------------------------
> > Servi?o M?todos Estat?sticos
> > Departamento de Metodologia Estat?stica
> > INE - Portugal
> > Telef:  218 426 100 - Ext: 3210
> > E-mail: ana.pmartins at ine.pt <mailto:ana.pmartins at ine.pt> 
> > 
> > 
> > 	[[alternative HTML version deleted]]
> > 
> > > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From brown_emu at yahoo.com  Tue Jun 26 09:04:56 2007
From: brown_emu at yahoo.com (Stephen Tucker)
Date: Tue, 26 Jun 2007 00:04:56 -0700 (PDT)
Subject: [R] changing the position of the y label (ylab)
In-Reply-To: <732557.21159.qm@web36913.mail.mud.yahoo.com>
Message-ID: <306338.56249.qm@web39705.mail.mud.yahoo.com>

If by 'position' you mean the distance from the axes, I think 'mgp' is the
argument you are looking for (see ?par)-

You can set this in par(), plot() [which will affect both x and y labels], or
title():

par(mar=rep(6,4))
plot(NA,NA,xlim=0:1,ylim=0:1,xlab="X",ylab="")
title(ylab="Y2",mgp=c(4,1,0))

if you want to change 'position' parallel to the axis, then you probably have
to do
plot(...,xlab="",ylab="")

and set labels using mtext(); playing around with the 'adj' argument.

Btw, you can use '\n' to denote new line:
title(ylab="Onset/Withdrawl\nDate",mgp=c(4,1,0))


--- Etienne <etiennesky at yahoo.com> wrote:

> How can I change the position of the ylab, after
> enlarging the margins with par(mar=...)? 
> 
> Here is the relevant code snippet
> 
> ----
> par(mar=c(5.1,5.1,4.1,2.1))
>
plot(c(1979,2003),c(40,50),ylim=c(1,73),lab=c(20,10,1),pch=21,col='blue',bg='blue',axes=FALSE,xlab="Years",ylab="Onset/Withdrawl
> Date",font.lab=2)
> box()
> axis(1,las=2)
>
axis(2,las=2,labels=c('JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC','JAN'),at=seq(from=1,to=73,by=6))
> axis(3,labels=FALSE)
> axis(4,labels=FALSE,at=seq(from=1,to=73,by=6))
> ----
> 
> Thanks
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Jean-Baptiste.Ferdy at univ-montp2.fr  Tue Jun 26 10:08:32 2007
From: Jean-Baptiste.Ferdy at univ-montp2.fr (Jean-Baptiste Ferdy)
Date: Tue, 26 Jun 2007 10:08:32 +0200
Subject: [R] degrees of freedom in lme
In-Reply-To: <2323A6D37908A847A7C32F1E3662C80EB5E69D@dc1ex01.air.org>
References: <2323A6D37908A847A7C32F1E3662C80EE57794@dc1ex01.air.org>
	<1182799938.2970.6.camel@localhost.localdomain>
	<2323A6D37908A847A7C32F1E3662C80EB5E69D@dc1ex01.air.org>
Message-ID: <200706261008.32596.Jean-Baptiste.Ferdy@univ-montp2.fr>

>> This is such a common question that it has a an "FAQ-like" response from 
Doug Bates. Google "lmer p-values and all that" to find the response. 

>Isn't this a different question, though, since Jean-Baptiste is using
>nlme. 

>Details on the calculation of DF in nlme can be found in chapter 4 of
>the book by Pinheiro and Bates "Mixed Effects Models in S and S-PLUS.
>Using the formula provided, I get denDF of 10 for level 1 and 32 for
>level 2. I'm not sure why lme is using the denDF estimated at level 2 in
>this example ...

My question was more on the fact that anova.lme seems to behave differently 
when called on a two way ANOVA than when called on an ANCOVA. I am sure that 
DenDF is estimated with the same procedure in the two situations and, I as 
already said, I understand there is a real issue with calculating dfs and 
p-values in this kind of situation. 

But again I thought this issue was serious only in the case of unbalanced data 
sets. When data are balanced my guess was that lme and the traditional strata 
approach would give essentially the same answer. This is indeed what happens 
in the case of an ANOVA (and that's what Pinehiro and Bates say in section 
2.4 of their book) but not in the case of an ANCOVA.

Does all this mean that we should forget the F-test provided by lme and turn 
to the approach used in lme4??
-- 
Jean-Baptiste Ferdy
Institut des Sciences de l'?volution de Montpellier
CNRS UMR 5554
Universit? Montpellier 2
34 095 Montpellier cedex 05
tel. +33 (0)4 67 14 42 27
fax ?+33 (0)4 67 14 36 22


From ripley at stats.ox.ac.uk  Tue Jun 26 10:36:06 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 26 Jun 2007 09:36:06 +0100 (BST)
Subject: [R] simultaneous actions of grep ???
In-Reply-To: <150281.24982.qm@web39709.mail.mud.yahoo.com>
References: <150281.24982.qm@web39709.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.64.0706260933590.3118@auk.stats>

On Mon, 25 Jun 2007, Stephen Tucker wrote:

> My mistake... last alternative should be:
>
>   c<-subset(c,regexpr("\\.1|\\.5|\\.6|\\.99999",rownames(c)) < 0)

Or, more readably,

c <- subset(c, regexpr("\\.(1|5|6|99999)", rownames(c)) < 0)


>
> --- Stephen Tucker <brown_emu at yahoo.com> wrote:
>
>> You can list them together using "|" (which stands for 'or'):
>>
>>   c<-subset(c,!rownames(c) %in%
>> grep(".1|.5|.6|.99999",rownames(c),value=T))
>>
>> but "." means any character for regular expressions, so if you meant a
>> decimal place, you probably want to escape them with a "\\":
>>
>>   c<-subset(c,!rownames(c) %in%
>>             grep("\\.1|\\.5|\\.6|\\.99999", rownames(c),value=T))
>>
>> Another option is
>>
>>   c<-subset(c,regexpr("\\.1|\\.5|\\.6|\\.99999",c) < 0)
>>
>> because regexpr will return -1 for elements which do not contain a match.
>>
>>
>> --- Ana Patricia Martins <ana.pmartins at ine.pt> wrote:
>>
>>> Hello R-users and developers,
>>>
>>> Once again, I'm asking for your help.
>>>
>>> There is other way to do the same more easily for applied simultaneous
>>> grep???
>>>
>>>     c<-subset(c,!rownames(c) %in% grep(".1",rownames(c),value=T))
>>>     c<-subset(c,!rownames(c) %in% grep(".5",rownames(c),value=T))
>>>     c<-subset(c,!rownames(c) %in% grep(".6",rownames(c),value=T))
>>>     c<-subset(c,!rownames(c) %in% grep(".99999",rownames(c),value=T))

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From francogrex at mail.com  Tue Jun 26 11:23:10 2007
From: francogrex at mail.com (francogrex)
Date: Tue, 26 Jun 2007 02:23:10 -0700 (PDT)
Subject: [R] GLM, log-binomial likelihood
Message-ID: <11302456.post@talk.nabble.com>


Dear R-help users, I have a question concerning re-writing a function in R:

Suppose I have the data, y is number of successes and N is total number of
trials and x is the variable
 (example:)
x	y	N
1	10	150
0	1	100
 
I want to estimate the risk ratio by determining the coefficients of a
log-binomial regression so I use:

> glm(cbind(y, N - y) ~ x, family = binomial(link = "log"))
Coefficients:
(Intercept)            x  
     -4.605        1.897 
Using  family=binomial(link="log") instead of family="binomial" to specify
the log instead of the logit link function, so that the coefficient is the
log of the risk ratio.

I know that the equivalent negative log-likelihood
function is:

logregfun = function(a, b) {
p.pred = exp(a + b * x)
-sum(dbinom(y, size = N, prob = p.pred, log = TRUE))
}

But I am interesting in doing the calculation not using the glm function but
by optimizing the log-likelihood myself (so that I can play around with it
later, add priors etc...): using the above negative-log likelihood and optim
I can calculate the coefficients.
But how can I re-write the log-likelihood function if my data are in a list
(and not provided as number of successes and total number of trials): such
as

x	y
0	0
0	1
1	1
0	1
...	...
etc until 250 rows (or sometimes more)?
where 0 indicates absence and 1 indicates presence/success

Thanks
-- 
View this message in context: http://www.nabble.com/GLM%2C-log-binomial-likelihood-tf3981349.html#a11302456
Sent from the R help mailing list archive at Nabble.com.


From jim at bitwrit.com.au  Tue Jun 26 13:06:24 2007
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 26 Jun 2007 21:06:24 +1000
Subject: [R] how to plot this?
In-Reply-To: <cdf817830706250750yad67f59m778f6bd43124582a@mail.gmail.com>
References: <cdf817830706250750yad67f59m778f6bd43124582a@mail.gmail.com>
Message-ID: <4680F330.4070201@bitwrit.com.au>

Weiwei Shi wrote:
> Hi, there:
> 
> Suppose I have a couple of data.frames and each one has five columns
> (one for x-axis, two for y-axis and two for std of y's.) There is
> another dimensions (besides x and y) which is continuous. My question
> is, how to plot such series of data frames in one plot (thus,
> 3-dimensional plot) AND multiple 2-D plots. I am not familar with R's
> plotting utilities.
> 
Hi Weiwei,

Maybe color2D.matplot for the 2D plots, setting par(mfrow...) 
appropriately. I have just uploaded a new version of plotrix in which 
color2D.matplot will handle NAs appropriately, doing such things as 
upper or lower triangles of matrices. Look for version 2.2-2 when it 
pops up on CRAN.

Jim


From Mike.Lawrence at DAL.CA  Tue Jun 26 13:12:51 2007
From: Mike.Lawrence at DAL.CA (Mike Lawrence)
Date: Tue, 26 Jun 2007 08:12:51 -0300
Subject: [R] Power calculation with measurement error
Message-ID: <DB174F65-4084-46B6-AD09-D575340E6825@DAL.CA>

Hi all,

Hopefully this will be quick, I'm looking for pointers to packages/ 
functions that would allow me to calculate the power of a t.test when  
the DV has measurement error. That is, I understand that, ceteris  
paribus, experiments using measure with more error (lower  
reliability) will have lower power.

Mike

--
Mike Lawrence
Graduate Student, Department of Psychology, Dalhousie University

Website: http://memetic.ca

Public calendar: http://icalx.com/public/informavore/Public

"The road to wisdom? Well, it's plain and simple to express:
Err and err and err again, but less and less and less."
	- Piet Hein


From Mike.Lawrence at DAL.CA  Tue Jun 26 13:21:10 2007
From: Mike.Lawrence at DAL.CA (Mike Lawrence)
Date: Tue, 26 Jun 2007 08:21:10 -0300
Subject: [R] connecting to running process possible?
In-Reply-To: <fb87ba070706220906i1314ccf4q4c51ad3ad4e4ff8b@mail.gmail.com>
References: <fb87ba070706220906i1314ccf4q4c51ad3ad4e4ff8b@mail.gmail.com>
Message-ID: <5D52A4AF-1856-4CCF-99D5-0DDAFB63A503@DAL.CA>

If you get the running process to write its results to file, then you  
could run a loop in R asking it to repeatedly read the file and plot  
the contents. It may work best if you plot to a file like a pdf.

On 22-Jun-07, at 1:06 PM, Charles Cosse wrote:

> Hello,
>
> i'm trying to find a more modern system to reproduce the  
> functionality that
> was available through the Histoscope program (from Fermilab).   
> Namely, the
> capability of connecting to a running process and having plots  
> update in
> realtime in response to new data.  Is this possible with R?  Thank  
> you,
>
> Charles Cosse
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Mike Lawrence
Graduate Student, Department of Psychology, Dalhousie University

Website: http://memetic.ca

Public calendar: http://icalx.com/public/informavore/Public

"The road to wisdom? Well, it's plain and simple to express:
Err and err and err again, but less and less and less."
	- Piet Hein


From f.calboli at imperial.ac.uk  Tue Jun 26 13:58:24 2007
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Tue, 26 Jun 2007 12:58:24 +0100
Subject: [R] fisher information matrix
Message-ID: <4680FF60.7080801@imperial.ac.uk>

Hi All,

a colleague wants to calculate the Fisher information matrix for a model he 
wrote (not in R). He can easily get the neg-log-likelihood and the best fit 
parameters at the minimum. He can also get negLLs for other parameter values too.

Given these data, is there a way in R to calculate the Fisher information matrix?

Best,

Federico

-- 
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St Mary's Campus
Norfolk Place, London W2 1PG

Tel  +44 (0)20 7594 1602     Fax (+44) 020 7594 3193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com


From peter.moser at statistik.ji.zh.ch  Tue Jun 26 14:01:09 2007
From: peter.moser at statistik.ji.zh.ch (peter.moser at statistik.ji.zh.ch)
Date: Tue, 26 Jun 2007 14:01:09 +0200
Subject: [R] =?iso-8859-1?q?Peter_Moser_ist_au=DFer_Haus=2E?=
Message-ID: <OFF88C740A.B8F33831-ONC1257306.00420616-C1257306.00420616@ji.zh.ch>


Ich werde ab  25.06.2007 nicht im B?ro sein. Ich kehre zur?ck am
28.06.2007.

in dringenden F?llen bin ich unter 079 79 73 74 6 erreichbar


From amel at cs.bgu.ac.il  Tue Jun 26 14:20:36 2007
From: amel at cs.bgu.ac.il (El-ad David Amir)
Date: Tue, 26 Jun 2007 15:20:36 +0300
Subject: [R] Looking for parallel functionality between Matlab and R
Message-ID: <af47c4ab0706260520scae0212s5a57e9a1f26cdb48@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070626/3285835f/attachment.pl 

From i.visser at uva.nl  Tue Jun 26 14:27:10 2007
From: i.visser at uva.nl (Ingmar Visser)
Date: Tue, 26 Jun 2007 14:27:10 +0200
Subject: [R] fisher information matrix
In-Reply-To: <4680FF60.7080801@imperial.ac.uk>
References: <4680FF60.7080801@imperial.ac.uk>
Message-ID: <69FE4AE3-3650-4E69-ADC2-8C7B3441D7A0@uva.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070626/4ad3820b/attachment.pl 

From abhijit.roy at citi.com  Tue Jun 26 14:09:40 2007
From: abhijit.roy at citi.com (Roy, Abhijit )
Date: Tue, 26 Jun 2007 17:39:40 +0530
Subject: [R] R data set size limit
Message-ID: <112E8384B64E774A99448E033747A6F8374164@exinrec01-bkp.apac.nsroot.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070626/d70df67e/attachment.pl 

From sigbert at wiwi.hu-berlin.de  Tue Jun 26 15:22:25 2007
From: sigbert at wiwi.hu-berlin.de (Sigbert Klinke)
Date: Tue, 26 Jun 2007 15:22:25 +0200
Subject: [R] recover history after crash in RGui
Message-ID: <46811311.2020503@wiwi.hu-berlin.de>

Hi, is there any possibility to recover the history of executed R code 
in the RGui when it has crashed?

Thanks in advance

  Sigbert Klinke


From rfrancois at mango-solutions.com  Tue Jun 26 15:33:24 2007
From: rfrancois at mango-solutions.com (Romain Francois)
Date: Tue, 26 Jun 2007 14:33:24 +0100
Subject: [R] recover history after crash in RGui
In-Reply-To: <46811311.2020503@wiwi.hu-berlin.de>
References: <46811311.2020503@wiwi.hu-berlin.de>
Message-ID: <468115A4.7060706@mango-solutions.com>

Sigbert Klinke wrote:
> Hi, is there any possibility to recover the history of executed R code 
> in the RGui when it has crashed?
>
> Thanks in advance
>
>   Sigbert Klinke
>   
Hello,

It might be too much of an overkill, but one possible thing is to use 
?taskCallbackManager to save the history after each high level call. 
Something like:

     h <- taskCallbackManager()
     h$add(function(expr, value, ok, visible) {
                            savehistory()
                            return(TRUE)
                          }, name = "historyHandler")

Cheers,

Romain

-- 
Mango Solutions
data analysis that delivers

Tel:  +44(0) 1249 467 467
Fax:  +44(0) 1249 467 468
Mob:  +44(0) 7813 526 123


From rvaradhan at jhmi.edu  Tue Jun 26 15:40:05 2007
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Tue, 26 Jun 2007 09:40:05 -0400
Subject: [R] fisher information matrix
In-Reply-To: <4680FF60.7080801@imperial.ac.uk>
References: <4680FF60.7080801@imperial.ac.uk>
Message-ID: <000101c7b7f7$812d4020$7c94100a@win.ad.jhu.edu>

Hi,

You can use the function hessian() in the package "numDeriv".  This will
yield a very accurate estimate of the "observed" Fisher information matrix.


library(numDeriv)
?hessian

Ravi.
----------------------------------------------------------------------------
-------

Ravi Varadhan, Ph.D.

Assistant Professor, The Center on Aging and Health

Division of Geriatric Medicine and Gerontology 

Johns Hopkins University

Ph: (410) 502-2619

Fax: (410) 614-9625

Email: rvaradhan at jhmi.edu

Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html

 

----------------------------------------------------------------------------
--------


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Federico Calboli
Sent: Tuesday, June 26, 2007 7:58 AM
To: r-help
Cc: Gambhir, Manoj
Subject: [R] fisher information matrix

Hi All,

a colleague wants to calculate the Fisher information matrix for a model he 
wrote (not in R). He can easily get the neg-log-likelihood and the best fit 
parameters at the minimum. He can also get negLLs for other parameter values
too.

Given these data, is there a way in R to calculate the Fisher information
matrix?

Best,

Federico

-- 
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St Mary's Campus
Norfolk Place, London W2 1PG

Tel  +44 (0)20 7594 1602     Fax (+44) 020 7594 3193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Tue Jun 26 15:46:20 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 26 Jun 2007 14:46:20 +0100 (BST)
Subject: [R] R data set size limit
In-Reply-To: <112E8384B64E774A99448E033747A6F8374164@exinrec01-bkp.apac.nsroot.net>
References: <112E8384B64E774A99448E033747A6F8374164@exinrec01-bkp.apac.nsroot.net>
Message-ID: <Pine.LNX.4.64.0706261442400.23970@gannet.stats.ox.ac.uk>

On Tue, 26 Jun 2007, Roy, Abhijit  wrote:

> Hi -
>
> What is the limit (rows and columns) on the size of a data set that R
> will process?

2^31-1 for each (in a data frame, that number of elements for a matrix). 
See ?"Memory-limits"

Most likely your computer imposes lower limits.

>
> Thanks.
> Abhijit
>
>
> Dr. Abhijit Roy
> Citi - Global Consumer Group - Business Analytics and Methods
> O: 91 80 4041 6398
> Fax: 91 80 2211 0827
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tavpritesh at gmail.com  Tue Jun 26 16:08:16 2007
From: tavpritesh at gmail.com (Tavpritesh Sethi)
Date: Tue, 26 Jun 2007 19:38:16 +0530
Subject: [R] how to iterate
Message-ID: <33846cd50706260708j3fe8c402w820efd3656b28fd7@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070626/976baae4/attachment.pl 

From fausto.galli at lu.unisi.ch  Tue Jun 26 16:09:52 2007
From: fausto.galli at lu.unisi.ch (Fausto Galli)
Date: Tue, 26 Jun 2007 16:09:52 +0200
Subject: [R] surprising difference in log()
Message-ID: <279B77EF-70FD-4F2B-8BBD-9F15D37589ED@lu.unisi.ch>


Hello everybody

My collegue and I noticed a strange behaviour of R on different  
platforms. It's a simple computation, but results are rather different.

On Windows XP:

 > floor(log(8,2))
[1] 3

which is what one should expect.
Here's instead the result with Mac OS X (same version, 2.5.0  
(2007-04-23))

 > floor(log(8,2))
[1] 2

Is it a "bug" in R or in the operating system?
Anyway, it's quite a surprising one.





_____________________________________
Fausto Galli
Institute of Finance
University of Lugano
Via G. Buffi 13
CH-6904 Lugano, Switzerland.
+41 (0)58 666 4497
http://www.people.lu.unisi.ch/gallif


From Mike.Lawrence at DAL.CA  Tue Jun 26 16:20:13 2007
From: Mike.Lawrence at DAL.CA (Mike Lawrence)
Date: Tue, 26 Jun 2007 11:20:13 -0300
Subject: [R] surprising difference in log()
In-Reply-To: <279B77EF-70FD-4F2B-8BBD-9F15D37589ED@lu.unisi.ch>
References: <279B77EF-70FD-4F2B-8BBD-9F15D37589ED@lu.unisi.ch>
Message-ID: <0CD53661-C47F-49AC-A1E4-86357B1AACE0@DAL.CA>

According to the description of floor(), the latter result is the  
correct one:

'floor takes a single numeric argument x and returns a numeric vector  
containing the largest integers *not greater than* the corresponding  
elements of x.' (emphasis added)

floor(3) == 2
 >True


On 26-Jun-07, at 11:09 AM, Fausto Galli wrote:

>
> Hello everybody
>
> My collegue and I noticed a strange behaviour of R on different
> platforms. It's a simple computation, but results are rather  
> different.
>
> On Windows XP:
>
>> floor(log(8,2))
> [1] 3
>
> which is what one should expect.
> Here's instead the result with Mac OS X (same version, 2.5.0
> (2007-04-23))
>
>> floor(log(8,2))
> [1] 2
>
> Is it a "bug" in R or in the operating system?
> Anyway, it's quite a surprising one.
>
>
>
>
>
> _____________________________________
> Fausto Galli
> Institute of Finance
> University of Lugano
> Via G. Buffi 13
> CH-6904 Lugano, Switzerland.
> +41 (0)58 666 4497
> http://www.people.lu.unisi.ch/gallif
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Mike Lawrence
Graduate Student, Department of Psychology, Dalhousie University

Website: http://memetic.ca

Public calendar: http://icalx.com/public/informavore/Public

"The road to wisdom? Well, it's plain and simple to express:
Err and err and err again, but less and less and less."
	- Piet Hein


From murdoch at stats.uwo.ca  Tue Jun 26 16:31:44 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 26 Jun 2007 10:31:44 -0400
Subject: [R] surprising difference in log()
In-Reply-To: <0CD53661-C47F-49AC-A1E4-86357B1AACE0@DAL.CA>
References: <279B77EF-70FD-4F2B-8BBD-9F15D37589ED@lu.unisi.ch>
	<0CD53661-C47F-49AC-A1E4-86357B1AACE0@DAL.CA>
Message-ID: <46812350.8070408@stats.uwo.ca>

On 6/26/2007 10:20 AM, Mike Lawrence wrote:
> According to the description of floor(), the latter result is the  
> correct one:
> 
> 'floor takes a single numeric argument x and returns a numeric vector  
> containing the largest integers *not greater than* the corresponding  
> elements of x.' (emphasis added)
> 
> floor(3) == 2
>  >True

3 is not greater than 3, but it is greater than 2, so the result you 
quote above is wrong.  You should see

> floor(3)
  [1] 3

 > floor(3) == 2
[1] FALSE

Do you really see the result you posted?

Duncan Murdoch


From Marc.Zodet at ahrq.hhs.gov  Tue Jun 26 16:42:39 2007
From: Marc.Zodet at ahrq.hhs.gov (Zodet, Marc W. (AHRQ))
Date: Tue, 26 Jun 2007 10:42:39 -0400
Subject: [R] Subscripting specified variables in a function
Message-ID: <1F809F62E3CEA04881B4644029484B4507F72348@AVN3VS004.ees.hhs.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070626/fb823781/attachment.pl 

From d.maraun at uea.ac.uk  Tue Jun 26 16:49:46 2007
From: d.maraun at uea.ac.uk (Douglas Maraun)
Date: Tue, 26 Jun 2007 15:49:46 +0100
Subject: [R] ts() defunct in R 2.5.0?
Message-ID: <43540b8d0706260749m774b8423g5845e3f357b113b5@mail.gmail.com>

Hi!

I have written an R-package
(http://tocsy.agnld.uni-potsdam.de/wavelets/index.html) in R 2.4.1
that requires the ts() function. Users using R 2.5.0 now have a
problem installing this package. I checked the package using R 2.5.0:
_______________________________________________________

* Installing *source* package 'sowas' ...
** libs
gcc -std=gnu99 -I/usr/users10/hrust/share/lib64/R/include
-I/usr/users10/hrust/share/lib64/R/include  -I/usr/local/include
-fpic  -g -O2 -c invmorlet.c -o invmorlet.o
gcc -std=gnu99 -shared -L/usr/local/lib64 -o sowas.so invmorlet.o
** R
** data
** preparing package for lazy loading
Loading required package: Rwave

Attaching package: 'Rwave'


       The following object(s) are masked from package:stats :

        kernel

** help
 >>> Building/Updating help pages for package 'sowas'
    Formats: text html latex example
 air                               text    html    latex
 createar                          text    html    latex   example
 createwgn                         text    html    latex   example
 criticalvaluesWCO                 text    html    latex   example
 criticalvaluesWSP                 text    html    latex   example
 cwt.ts                            text    html    latex   example
 nao                               text    html    latex
 nino3                             text    html    latex
 plot.wt                           text    html    latex   example
 plotwt                            text    html    latex   example
 readmatrix                        text    html    latex   example
 readts                            text    html    latex   example
 rk                                text    html    latex   example
 wco                               text    html    latex   example
 wcs                               text    html    latex   example
 writematrix                       text    html    latex   example
 wsp                               text    html    latex   example
** building package indices ...
Read 3192 items
Error in eval(expr, envir, enclos) : could not find function "ts"
Execution halted
ERROR: installing package indices failed
** Removing '/usr/users10/hrust/tmp/sowas.Rcheck/sowas'
____________________________________________________

In the corresponding DESCRIPTION File, the depend line reads:

     Depends: R,Rwave,stats

I read in the 2.5.0 news, that ts has been defunct. So I added

     Depends: R,Rwave,stats,ts

Now I get the following error:
_____________________________

* checking for working latex ... OK
* using log directory '/usr/users10/hrust/tmp/sowas.Rcheck'
* using R version 2.5.0 (2007-04-23)
* checking for file 'sowas/DESCRIPTION' ... OK
* this is package 'sowas' version '0.93'
* checking package dependencies ... ERROR
Former standard packages required but now defunct:
 ts

See the information on DESCRIPTION files in the chapter 'Creating R
packages' of the 'Writing R Extensions' manual.

_________________________

Actually, I have read the "Writing R Extensions" about the DESCRIPTION
file but could not find any helpful information. Has anybody got some
idea?

Cheers
Douglas
-----------------------------------------------------------------------
Dr. Douglas Maraun
Climatic Research Unit, University of East Anglia
+44 1603 59 3857
http://www.cru.uea.ac.uk/~douglas


From ivowel at gmail.com  Tue Jun 26 16:58:48 2007
From: ivowel at gmail.com (ivo welch)
Date: Tue, 26 Jun 2007 10:58:48 -0400
Subject: [R] Memory Experimentation: Rule of Thumb = 10-15 Times the Memory
Message-ID: <50d1c22d0706260758q435b761fvad66a523cce2cf9d@mail.gmail.com>

dear R experts:

I am of course no R experts, but use it regularly.  I thought I would
share some experimentation  with memory use.  I run a linux machine
with about 4GB of memory, and R 2.5.0.

upon startup, gc() reports

         used (Mb) gc trigger (Mb) max used (Mb)
Ncells 268755 14.4     407500 21.8   350000 18.7
Vcells 139137  1.1     786432  6.0   444750  3.4

This is my baseline.  linux 'top' reports 48MB as baseline.  This
includes some of my own routines that are always loaded.  Good..


Next, I created a s.csv file with 22 variables and 500,000
observations, taking up an uncompressed disk space of 115MB.  The
resulting object.size() after a read.csv() is 84,002,712 bytes (80MB).

> s= read.csv("s.csv");
> object.size(s);

[1] 84002712


here is where things get more interesting.  after the read.csv() is
finished, gc() reports

           used (Mb) gc trigger  (Mb) max used  (Mb)
Ncells   270505 14.5    8349948 446.0 11268682 601.9
Vcells 10639515 81.2   34345544 262.1 42834692 326.9

I was a big surprised by this---R had 928MB intermittent memory in
use.  More interestingly, this is also similar to what linux 'top'
reports as memory use of the R process (919MB, probably 1024 vs. 1000
B/MB), even after the read.csv() is finished and gc() has been run.
Nothing seems to have been released back to the OS.

Now,

> rm(s)
> gc()
         used (Mb) gc trigger  (Mb) max used  (Mb)
Ncells 270541 14.5    6679958 356.8 11268755 601.9
Vcells 139481  1.1   27476536 209.7 42807620 326.6

linux 'top' now reports 650MB of memory use (though R itself uses only
15.6Mb).  My guess is that It leaves the trigger memory of 567MB plus
the base 48MB.


There are two interesting observations for me here:  first, to read a
.csv file, I need to have at least 10-15 times as much memory as the
file that I want to read---a lot more than the factor of 3-4 that I
had expected.  The moral is that IF R can read a .csv file, one need
not worry too much about running into memory constraints lateron.  {R
Developers---reducing read.csv's memory requirement a little would be
nice.  of course, you have more than enough on your plate, already.}

Second, memory is not returned fully to the OS.  This is not
necessarily a bad thing, but good to know.

Hope this helps...

Sincerely,

/iaw


From christophe at pallier.org  Tue Jun 26 16:59:41 2007
From: christophe at pallier.org (Christophe Pallier)
Date: Tue, 26 Jun 2007 16:59:41 +0200
Subject: [R] Looking for parallel functionality between Matlab and R
In-Reply-To: <af47c4ab0706260520scae0212s5a57e9a1f26cdb48@mail.gmail.com>
References: <af47c4ab0706260520scae0212s5a57e9a1f26cdb48@mail.gmail.com>
Message-ID: <dea6cb960706260759w6937eedbp25c1aee3402ce5bc@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070626/79e4f4b8/attachment.pl 

From petr.pikal at precheza.cz  Tue Jun 26 17:03:28 2007
From: petr.pikal at precheza.cz (Petr PIKAL)
Date: Tue, 26 Jun 2007 17:03:28 +0200
Subject: [R] Odp:  how to iterate
In-Reply-To: <33846cd50706260708j3fe8c402w820efd3656b28fd7@mail.gmail.com>
Message-ID: <OFFF88495B.8CF47062-ONC1257306.0052478D-C1257306.0052B79D@precheza.cz>

Hi

as you did not specify your code (which you said it had failed) I try to 
give you a suggestion how I would do such tasks.

for (i in 1:100)  {

sample(something, no, replace =TRUE)
result <-perform a test
store.a result[i] <- result

}

Regards
Petr


r-help-bounces at stat.math.ethz.ch napsal dne 26.06.2007 16:08:16:

> for the following example dataset:-
>    Category Variable 1 127 1 261 1 142 1 183 1 234 1 162 2 173 2 321 2 
168 2
> 197 2 213 2 261 3 198 3 126 3 167 3 154 3 134 3 187 3 109 3 210
> I have performed Anova on the measured variable (column#2) for the 
groups
> 1,2&3 (column#1). Now I want to randomize the values in C#2 and 
reperform
> the test, say, a hundred times. Please suggest a way for this iteration. 
The
> loop I tried to write didn't work.
> Thanks.
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Greg.Snow at intermountainmail.org  Tue Jun 26 17:18:02 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Tue, 26 Jun 2007 09:18:02 -0600
Subject: [R] Power calculation with measurement error
In-Reply-To: <DB174F65-4084-46B6-AD09-D575340E6825@DAL.CA>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBA5AA51@LP-EXCHVS07.CO.IHC.COM>

I don't know of a current package that does this (others may), but if
you know what you expect your data to look like you can simulate it and
calculate power that way.

Basically, write a function that will simulate data with the level of
measurement error that you expect in the real data (or have the amount
of measurement error passed in as a parameter so you can examine the
effect of diffenent values).  Then have the function compute the t test
(or other test that you plan to do) and return the p-value from the
test.

Then you can simulate the process with a command like:

> out1 <- replicate( 1000, myfunction(n=25, err=.1, diff=.5) )

And compute the power with:

> mean( out1 < 0.05 ) # or whatever alpha value you want.

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Mike Lawrence
> Sent: Tuesday, June 26, 2007 5:13 AM
> To: Rhelp
> Subject: [R] Power calculation with measurement error
> 
> Hi all,
> 
> Hopefully this will be quick, I'm looking for pointers to 
> packages/ functions that would allow me to calculate the 
> power of a t.test when the DV has measurement error. That is, 
> I understand that, ceteris paribus, experiments using measure 
> with more error (lower
> reliability) will have lower power.
> 
> Mike
> 
> --
> Mike Lawrence
> Graduate Student, Department of Psychology, Dalhousie University
> 
> Website: http://memetic.ca
> 
> Public calendar: http://icalx.com/public/informavore/Public
> 
> "The road to wisdom? Well, it's plain and simple to express:
> Err and err and err again, but less and less and less."
> 	- Piet Hein
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From vivek.menon79 at gmail.com  Tue Jun 26 17:19:21 2007
From: vivek.menon79 at gmail.com (Vivek Menon)
Date: Tue, 26 Jun 2007 11:19:21 -0400
Subject: [R] gcc and g++ errors while compiling R on Linux ppc64
Message-ID: <bf6a5a630706260819w3cb9df63y1cd3aeea26aa0004@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070626/197bd5b0/attachment.pl 

From Greg.Snow at intermountainmail.org  Tue Jun 26 17:37:10 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Tue, 26 Jun 2007 09:37:10 -0600
Subject: [R] how to iterate
In-Reply-To: <33846cd50706260708j3fe8c402w820efd3656b28fd7@mail.gmail.com>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBA5AA6E@LP-EXCHVS07.CO.IHC.COM>

Here is one approach:

> tmp <- scan()
1: 1 127 1 261 1 142 1 183 1 234 1 162 2 173 2 321 2 168 2
20: 197 2 213 2 261 3 198 3 126 3 167 3 154 3 134 3 187 3 109 3 210
41: 
Read 40 items
> my.df <- as.data.frame( matrix(tmp, ncol=2, byrow=TRUE) )
> names(my.df) <- c('Category','Variable')
> 
> my.df$Category <- factor(my.df$Category)
> 
> fit1 <- aov( Variable ~ Category, data=my.df )
> summary(fit1)
            Df Sum Sq Mean Sq F value  Pr(>F)  
Category     2  13005    6503  2.7324 0.09355 .
Residuals   17  40456    2380                  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
> 
> out1 <- replicate(99, summary(aov( sample(Variable) ~ Category,
data=my.df ) ) )
> 
> 
> # now look at a histogram of the p-values
> tmp <- sapply( out1, function(x) x['Pr(>F)'][1,1] )
> hist(tmp)
> 

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Tavpritesh Sethi
> Sent: Tuesday, June 26, 2007 8:08 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] how to iterate
> 
> for the following example dataset:-
>    Category Variable 1 127 1 261 1 142 1 183 1 234 1 162 2 
> 173 2 321 2 168 2
> 197 2 213 2 261 3 198 3 126 3 167 3 154 3 134 3 187 3 109 3 
> 210 I have performed Anova on the measured variable 
> (column#2) for the groups
> 1,2&3 (column#1). Now I want to randomize the values in C#2 
> and reperform the test, say, a hundred times. Please suggest 
> a way for this iteration. The loop I tried to write didn't work.
> Thanks.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Mike.Lawrence at dal.ca  Tue Jun 26 17:44:05 2007
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Tue, 26 Jun 2007 12:44:05 -0300
Subject: [R] Power calculation with measurement error
In-Reply-To: <07E228A5BE53C24CAD490193A7381BBBA5AA51@LP-EXCHVS07.CO.IHC.COM>
References: <07E228A5BE53C24CAD490193A7381BBBA5AA51@LP-EXCHVS07.CO.IHC.COM>
Message-ID: <B7B68DB8-EA47-419B-99F1-7487F2027121@dal.ca>

Thanks Greg, I've actually been programming precisely what you  
suggest since sending the request this morning (though your email was  
indeed helpful; I've never seen 'replicate()' and will see if it's  
faster than a loop).

However, I was hoping that an analytic solution was extant and  
implemented somewhere.


On 26-Jun-07, at 12:18 PM, Greg Snow wrote:

> I don't know of a current package that does this (others may), but if
> you know what you expect your data to look like you can simulate it  
> and
> calculate power that way.
>
> Basically, write a function that will simulate data with the level of
> measurement error that you expect in the real data (or have the amount
> of measurement error passed in as a parameter so you can examine the
> effect of diffenent values).  Then have the function compute the t  
> test
> (or other test that you plan to do) and return the p-value from the
> test.
>
> Then you can simulate the process with a command like:
>
>> out1 <- replicate( 1000, myfunction(n=25, err=.1, diff=.5) )
>
> And compute the power with:
>
>> mean( out1 < 0.05 ) # or whatever alpha value you want.
>
> Hope this helps,
>
> -- 
> Gregory (Greg) L. Snow Ph.D.
> Statistical Data Center
> Intermountain Healthcare
> greg.snow at intermountainmail.org
> (801) 408-8111
>
>
>
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch
>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Mike Lawrence
>> Sent: Tuesday, June 26, 2007 5:13 AM
>> To: Rhelp
>> Subject: [R] Power calculation with measurement error
>>
>> Hi all,
>>
>> Hopefully this will be quick, I'm looking for pointers to
>> packages/ functions that would allow me to calculate the
>> power of a t.test when the DV has measurement error. That is,
>> I understand that, ceteris paribus, experiments using measure
>> with more error (lower
>> reliability) will have lower power.
>>
>> Mike
>>
>> --
>> Mike Lawrence
>> Graduate Student, Department of Psychology, Dalhousie University
>>
>> Website: http://memetic.ca
>>
>> Public calendar: http://icalx.com/public/informavore/Public
>>
>> "The road to wisdom? Well, it's plain and simple to express:
>> Err and err and err again, but less and less and less."
>> 	- Piet Hein
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

--
Mike Lawrence
Graduate Student, Department of Psychology, Dalhousie University

Website: http://memetic.ca

Public calendar: http://icalx.com/public/informavore/Public

"The road to wisdom? Well, it's plain and simple to express:
Err and err and err again, but less and less and less."
	- Piet Hein


From spencer.graves at pdf.com  Tue Jun 26 17:57:52 2007
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 26 Jun 2007 08:57:52 -0700
Subject: [R] nlme correlated random effects
In-Reply-To: <46791737.537F.005A.0@dnr.state.mn.us>
References: <46791737.537F.005A.0@dnr.state.mn.us>
Message-ID: <46813780.3040605@pdf.com>

      I haven't seen a reply to this, so I will offer a comment in case 
you haven't already solved the problem. 

      Have you consulted the "Mixed-Effects Bible for S-Plus / R", 
Pinheiro and Bates (2000) Mixed-Effects Models in S and S-Plus 
(Springer)?  If yes, have you worked through appropriate portions of the 
book and the companion script files available with the standard R 
distribution in "~R\library\nlme\scripts"?  I just did "grep 'pdB' *.*" 
in that directory and found 5 uses of pdBlocked, 3 in ch04.R, and 1 each 
in ch06.R and ch08.R.  Also,  RSiteSearch("pdBlocked with 2 random 
effects") produced 69 hits for me just now.  You may not find anything 
useful there, but 69 does not seem to large a list to search, and there 
seems like a reasonable chance of finding something useful there. 

      Beyond this, a recommended approach to difficult questions like 
this is to try to simplify it to the maximum extent possible.  For 
example, it sounds to me like your question, "can I use pdBlocked with 
only 2 random effects", could be answered without the complexity of 
'nlme'.  What phony data set can you generate with the minimum number of 
observations and variables that could help answer this question?  The 
process of producing such a simplified example might produce an answer 
to your question.  If it doesn't, then you can submit that simple, 
self-contained example to this list.  Doing so will increase the chances 
of a useful reply. 

      I know this doesn't answer your question, but I hope it helps. 
      Best Wishes,
      Spencer Graves

Daniel O'Shea wrote:
> I am examining the following nlme model.
>
> asymporig<-function(x,th1,th2)th1*(1-exp(-exp(th2)*x))
> mod1<-nlme(fa20~(ah*habdiv+ad*log(d)+ads*ds+ads2*ds2+at*trout)+asymporig(da.p,th1,th2),
>     fixed=ah+ad+ads+ads2+at+th1+th2~1,
>     random=th1+th2~1,
>     start=c(ah=.9124,ad=.9252,ads=.5,ads2=-.1,at=-1,th1=2.842,th2=-6.917),
>     data=pca1.grouped)
>
> However, the two random effects (th1 and th2) which describe the asymptotic relationship between richness (fa20) and area (da.p) are correlated: -0.904 with approximate 95% ci of -0.99 to -.32.
> I examined the anova of mod1 with both random effects and mod2 with just th1 and mod1 is preferred.  I also examined pdDiag(th1 + th2~1) for another model (mod3) and based on the anova the original mod1 is preferred.
>
> My question is can I use pdBlocked with only 2 random effects or should I and if so how I would specify that in the model or perhaps the 95% ci for correlation is wide enough to ignore???
>
> Dan
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Greg.Snow at intermountainmail.org  Tue Jun 26 18:01:40 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Tue, 26 Jun 2007 10:01:40 -0600
Subject: [R] Looking for parallel functionality between Matlab and R
In-Reply-To: <af47c4ab0706260520scae0212s5a57e9a1f26cdb48@mail.gmail.com>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBA5AA82@LP-EXCHVS07.CO.IHC.COM>

For a), if you really want the plots overlayed, it is best to use
something like matplot, or use the points or lines function to add the
later plots to the first.  You can also get the overlay effect using
par(new=TRUE), but then you need to be careful with axis labels and
scales and the plot may end up being more confusing then helpful.

For b), if you are just doing a quick exploration of the plot, there is
the zoomplot function in the TeachingDemos package that may work for
you.  If you want a plot to print/save, it is best to specify xlim and
ylim in the initial plotting function to create it at the correct
size/zoom from the beginning.

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of El-ad 
> David Amir
> Sent: Tuesday, June 26, 2007 6:21 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Looking for parallel functionality between Matlab and R
> 
> I'm slowly moving my statistical analysis from Matlab to R, 
> and find myself missing two features:
> 
> a) How do I mimic Matlab's 'hold on'? (I want to show several 
> plots together, when I type two plots one after the other the 
> second overwrites the first)
> b) How do I mimic Matlab's 'axis'? (after drawing my plots I 
> want to zoom on specific parts- for example, x=0:5, y=0:20).
> 
> Thanks for any assistance.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From spencer.graves at pdf.com  Tue Jun 26 18:04:43 2007
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 26 Jun 2007 09:04:43 -0700
Subject: [R] matlab/gauss code in R
In-Reply-To: <a7961d100706241627g49035513s90d1d91f9e42d622@mail.gmail.com>
References: <a7961d100706241627g49035513s90d1d91f9e42d622@mail.gmail.com>
Message-ID: <4681391B.2040103@pdf.com>

      What do you mean by "import"? 

      Do you have access to Matlab?  If yes, have you considered using 
the R.matlab package? 

      Also, are you familiar with the RSiteSearch facility?  
RSiteSearch("import Matlab into R") produced 69 hits for me just now, 
and RSiteSearch("import Gauss into R") produced 5. 

      A more specific question might produce more useful replies. 
      Hope this helps. 
      Spencer Graves

Sebastian Kruk wrote:
> Hi all!
>
> I would like to import a matlab or gauss code to R.
>
> Could you help me?
>
> Bye,
>
> Sebasti?n.
>
> 2007/6/23, r-help-request at stat.math.ethz.ch <r-help-request at stat.math.ethz.ch>:
>   
>> Send R-help mailing list submissions to
>>        r-help at stat.math.ethz.ch
>>
>> To subscribe or unsubscribe via the World Wide Web, visit
>>        https://stat.ethz.ch/mailman/listinfo/r-help
>> or, via email, send a message with subject or body 'help' to
>>        r-help-request at stat.math.ethz.ch
>>
>> You can reach the person managing the list at
>>        r-help-owner at stat.math.ethz.ch
>>
>> When replying, please edit your Subject line so it is more specific
>> than "Re: Contents of R-help digest..."
>>
>>
>> Today's Topics:
>>
>>   1. what is "better" when combining data frames? merge vs. rbind
>>      & cbind (Thomas Pujol)
>>   2. extract index during execution of sapply (Christian Bieli)
>>   3. multiple return (Manuele Pesenti)
>>   4. Re: what is "better" when combining data frames? merge vs.
>>      rbind &   cbind (Duncan Murdoch)
>>   5. Re: multiple return (Mahbub Latif)
>>   6. Re: how to create cumulative histogram from two   independent
>>      variables? (Jim Lemon)
>>   7. Re: Adding exponents (superscript format) to a plot (John Kane)
>>   8. Re: using lme on multiple datasets in one shot (Douglas Bates)
>>   9. Re: abline plots at wrong abscissae after boxplot (S Ellison)
>>  10. Boxplot issues (S Ellison)
>>  11. Re: help on the use of ldBand (Frank E Harrell Jr)
>>  12. Re: multiple return (ONKELINX, Thierry)
>>  13. Re: extract index during execution of sapply (Martin Morgan)
>>  14. vectorize a function (Robin Hankin)
>>  15. Re: Tools For Preparing Data For Analysis (Kevin E. Thorpe)
>>  16. Re: Data consistency checks in functions (Kuhn, Max)
>>  17. Re: vectorize a function (Christos Hatzis)
>>  18. Re: extract index during execution of sapply (Ben Bolker)
>>  19. Re: extract index during execution of sapply (Thomas Lumley)
>>  20. fitCopula (Oden, Kevin)
>>  21. how to ave this? (Weiwei Shi)
>>  22. fitCopula (Oden, Kevin)
>>  23. Re: how to ave this? (Weiwei Shi)
>>  24. Re: Result depends on order of factors in unbalanced designs
>>      (lme, anova)? (Prof Brian Ripley)
>>  25. Re: Tools For Preparing Data For Analysis (Christophe Pallier)
>>  26. Re: interpretation of F-statistics in GAMs (Simon Wood)
>>  27. Re: Boxplot issues (Martin Maechler)
>>  28. Re: Overlaying lattice graphs (continued) (S?bastien)
>>  29. Matrix library, CHOLMOD error: problem too large (Jose Quesada )
>>  30. Re: Matrix library, CHOLMOD error: problem too large
>>      (Duncan Murdoch)
>>  31. Imputing missing values in time series (Horace Tso)
>>  32. Re: Imputing missing values in time series (Erik Iverson)
>>  33. Re: Imputing missing values in time series (Horace Tso)
>>  34. Re: Switching X-axis and Y-axis for histogram (hadley wickham)
>>  35. Re: Imputing missing values in time series (Leeds, Mark (IED))
>>  36. Re: Imputing missing values in time series (Horace Tso)
>>  37. Re: Overlaying lattice graphs (continued) (hadley wickham)
>>  38. Re: Overlaying lattice graphs (continued) (Deepayan Sarkar)
>>  39. Re: Stacked barchart color (hadley wickham)
>>  40. Re: Visualize quartiles of plot line (hadley wickham)
>>  41. "heatmap" color still a spectrum for binary outcomes?
>>      (Patrick Ayscue)
>>  42. Barchart legend position (Spilak,Jacqueline [Edm])
>>  43. Lattice: hiding only some strips (Michael Hoffman)
>>  44. Re: Overlaying lattice graphs (continued) (S?bastien)
>>  45. Bayesian Networks (Mario.Carvalho.Fernandes at bpi.pt)
>>  46. connecting to running process possible? (Charles Cosse)
>>  47. Re: Overlaying lattice graphs (continued) (hadley wickham)
>>  48. RServe (java2R) question (Guanrao Chen)
>>  49. Re: Lattice: hiding only some strips (Deepayan Sarkar)
>>  50. interaction contrast (szhan at uoguelph.ca)
>>  51. Re: Barchart legend position (Deepayan Sarkar)
>>  52. How to run "mathematica" or "c" programs in R? (Zhang Jian)
>>  53. Re: Imputing missing values in time series (Horace Tso)
>>  54. Asteriscs in a plot to represent approximate size of p-values
>>      (Judith Flores)
>>  55. merging more than two data frames (Andrew Yee)
>>  56. speed issues / pros & cons: dataframe vs. matrix (Thomas Pujol)
>>  57. Re: Matrix *package*, CHOLMOD error: problem too large
>>      (Martin Maechler)
>>  58. Re: speed issues / pros & cons: dataframe vs. matrix
>>      (Duncan Murdoch)
>>  59. Re: Lattice: hiding only some strips (Michael Hoffman)
>>  60. Re: Lattice: hiding only some strips (deepayan.sarkar at gmail.com)
>>  61. Re: how to ave this? (Mike Meredith)
>>  62. Re: how to ave this? (Dimitris Rizopoulos)
>>  63. Re: merging more than two data frames (Mark Wardle)
>>  64. latex of ftable (Hmisc?) (Dieter Menne)
>>  65. Re: latex of ftable (Hmisc?) (Chuck Cleland)
>>  66. Re: Data consistency checks in functions (Mike Meredith)
>>  67. Re: latex of ftable (Hmisc?) (Dieter Menne)
>>
>>
>> ----------------------------------------------------------------------
>>
>> Message: 1
>> Date: Thu, 21 Jun 2007 12:36:16 -0700 (PDT)
>> From: Thomas Pujol <thomas.pujol at yahoo.com>
>> Subject: [R] what is "better" when combining data frames? merge vs.
>>        rbind & cbind
>> To: r-help at stat.math.ethz.ch
>> Message-ID: <510958.56904.qm at web59308.mail.re1.yahoo.com>
>> Content-Type: text/plain
>>
>> I often need to "combine" data frames, sometimes "vertically" and other times "horizontally".
>>
>> When it "better" to use merge? When is it better to use rbind or cbind?
>>
>> Are there clear pros and cons of each approach?
>>
>>
>> ---------------------------------
>>
>>        [[alternative HTML version deleted]]
>>
>>
>>
>> ------------------------------
>>
>> Message: 2
>> Date: Fri, 22 Jun 2007 12:31:39 +0200
>> From: Christian Bieli <christian.bieli at unibas.ch>
>> Subject: [R] extract index during execution of sapply
>> To: R help list <r-help at stat.math.ethz.ch>
>> Message-ID: <467BA50B.60408 at unibas.ch>
>> Content-Type: text/plain; charset=ISO-8859-15; format=flowed
>>
>> Hi there
>> During execution of sapply I want to extract the number of times the
>> function given to supply has been executed. I came up with:
>>
>> mylist <- list(a=3,b=6,c=9)
>> sapply(mylist,function(x)as.numeric(gsub("[^0-9]","",deparse(substitute(x)))))
>>
>> This works fine, but looks quite ugly. I'm sure that there's a more
>> elegant way to do this.
>>
>> Any suggestion?
>>
>> Christian
>>
>>
>>
>> ------------------------------
>>
>> Message: 3
>> Date: Fri, 22 Jun 2007 12:37:37 +0200
>> From: Manuele Pesenti <amicogodzilla at bruttocarattere.org>
>> Subject: [R] multiple return
>> To: r-help at stat.math.ethz.ch
>> Message-ID: <200706221237.37479.amicogodzilla at bruttocarattere.org>
>> Content-Type: text/plain;  charset="us-ascii"
>>
>> Dear User,
>> what's the correct way to obtain a multiple return from a function?
>>
>> for example creating the simple function:
>>
>> somma <- function (a, b) {
>>  c <- a+b
>>  return (a, b, c)
>> }
>>
>> when I call it, it runs but returns the following output:
>>
>>     
>>> somma(5, 7)
>>>       
>> $a
>> [1] 5
>>
>> $b
>> [1] 7
>>
>> $c
>> [1] 12
>>
>> Warning message:
>> return multi-argomento sono deprecati in: return(a, b, c)
>>
>> i.e. multi-return is deprecated...
>>
>> thanks a lot
>> best regards
>>        Manuele
>>
>> --
>> Manuele Pesenti
>>        manuele at inventati.org
>>        amicogodzilla at jabber.linux.it
>>        http://mpesenti.polito.it
>>
>>
>>
>> ------------------------------
>>
>> Message: 4
>> Date: Fri, 22 Jun 2007 06:40:23 -0400
>> From: Duncan Murdoch <murdoch at stats.uwo.ca>
>> Subject: Re: [R] what is "better" when combining data frames? merge
>>        vs. rbind &     cbind
>> To: Thomas Pujol <thomas.pujol at yahoo.com>
>> Cc: r-help at stat.math.ethz.ch
>> Message-ID: <467BA717.7080202 at stats.uwo.ca>
>> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>>
>> On 21/06/2007 3:36 PM, Thomas Pujol wrote:
>>     
>>> I often need to "combine" data frames, sometimes "vertically" and other times "horizontally".
>>>
>>> When it "better" to use merge? When is it better to use rbind or cbind?
>>>
>>> Are there clear pros and cons of each approach?
>>>       
>> If rbind or cbind work, use them.  They are much simpler, but much less
>> flexible.
>>
>> Duncan Murdoch
>>
>>
>>
>> ------------------------------
>>
>> Message: 5
>> Date: Fri, 22 Jun 2007 17:20:01 +0600
>> From: "Mahbub Latif" <mlatif at isrt.ac.bd>
>> Subject: Re: [R] multiple return
>> To: amicogodzilla at bruttocarattere.org
>> Cc: r-help at stat.math.ethz.ch
>> Message-ID:
>>        <5faba43d0706220420m6f34f831l7353b680925dae34 at mail.gmail.com>
>> Content-Type: text/plain
>>
>> one way --
>>
>>
>> somma <- function (a, b) {
>>  c <- a+b
>>  return (list(a=a, b=a, c=c))
>> }
>>
>> Mahbub.
>>
>> On 6/22/07, Manuele Pesenti <amicogodzilla at bruttocarattere.org> wrote:
>>     
>>> Dear User,
>>> what's the correct way to obtain a multiple return from a function?
>>>
>>> for example creating the simple function:
>>>
>>> somma <- function (a, b) {
>>>   c <- a+b
>>>   return (a, b, c)
>>> }
>>>
>>> when I call it, it runs but returns the following output:
>>>
>>>       
>>>> somma(5, 7)
>>>>         
>>> $a
>>> [1] 5
>>>
>>> $b
>>> [1] 7
>>>
>>> $c
>>> [1] 12
>>>
>>> Warning message:
>>> return multi-argomento sono deprecati in: return(a, b, c)
>>>
>>> i.e. multi-return is deprecated...
>>>
>>> thanks a lot
>>> best regards
>>>         Manuele
>>>
>>> --
>>> Manuele Pesenti
>>>         manuele at inventati.org
>>>         amicogodzilla at jabber.linux.it
>>>         http://mpesenti.polito.it
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>       
>>
>> --
>> A H M Mahbub Latif, PhD
>> Assistant Professor
>> Applied Statistics
>> Institute of Statistical Research and Training
>> University of Dhaka, Dhaka 1000, Bangladesh
>> web : http://www.isrt.ac.bd/mlatif
>> ----
>> Computers are like airconditioners: They stop working properly if you open
>> windows.
>>
>>        [[alternative HTML version deleted]]
>>
>>
>>
>> ------------------------------
>>
>> Message: 6
>> Date: Fri, 22 Jun 2007 21:36:29 +1000
>> From: Jim Lemon <jim at bitwrit.com.au>
>> Subject: Re: [R] how to create cumulative histogram from two
>>        independent     variables?
>> To: Jose Borreguero <borreguero at gmail.com>, R-help at stat.math.ethz.ch
>> Message-ID: <467BB43D.3060004 at bitwrit.com.au>
>> Content-Type: text/plain; charset=us-ascii; format=flowed
>>
>> Jose Borreguero wrote:
>>     
>>> Hi all,
>>> I am extremely newbie to R. Can anybody jump-start me with any clues as to
>>> how do I get a cumulative histogram from two independent variables,
>>> cumhist(X,Y) ?
>>> -jose
>>>
>>>       
>> Hi Jose,
>>
>> Is this something like you want?
>>
>> var1<-sample(1:10,100,TRUE)
>> var2<-sample(1:10,100,TRUE)
>> barplot(rbind(hist(var1,plot=FALSE)$counts,hist(var2,plot=FALSE)$counts))
>>
>> Jim
>>
>>
>>
>> ------------------------------
>>
>> Message: 7
>> Date: Fri, 22 Jun 2007 07:44:23 -0400 (EDT)
>> From: John Kane <jrkrideau at yahoo.ca>
>> Subject: Re: [R] Adding exponents (superscript format) to a plot
>> To: Judith Flores <juryef at yahoo.com>, RHelp <r-help at stat.math.ethz.ch>
>> Message-ID: <466583.57100.qm at web32802.mail.mud.yahoo.com>
>> Content-Type: text/plain; charset=iso-8859-1
>>
>> # Using expression to add superscipts to the labels
>>
>> vec=c(1,10,100,1000,10000,100000,1000000,10000000)
>>  plot(vec,vec,log="xy", axes=F)
>>  axis(1, at=10^c(0,2,4,6), labels=expression(1, 10^2,
>> 10^4, 10^6))
>>  axis(2, at=10^c(0,2,4,6), labels=expression(1, 10^2,
>> 10^4, 10^6), las=1)
>>  box()
>>
>> --- Judith Flores <juryef at yahoo.com> wrote:
>>
>>     
>>> Hi,
>>>
>>>    I need to add exponents to a label in one of the
>>> axes of a plot, how can I do this?
>>>
>>> Thank you,
>>>
>>> Judith
>>>
>>>
>>>
>>>
>>>       
>> ____________________________________________________________________________________
>>     
>>> Food fight? Enjoy some healthy debate
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained,
>>> reproducible code.
>>>
>>>       
>>
>> ------------------------------
>>
>> Message: 8
>> Date: Fri, 22 Jun 2007 06:45:26 -0500
>> From: "Douglas Bates" <bates at stat.wisc.edu>
>> Subject: Re: [R] using lme on multiple datasets in one shot
>> To: "maitra at iastate.edu" <maitra at iastate.edu>
>> Cc: R-help <r-help at stat.math.ethz.ch>
>> Message-ID:
>>        <40e66e0b0706220445j5b5d74d7nb46237f83f0b8432 at mail.gmail.com>
>> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>>
>> On 6/21/07, maitra at iastate.edu <maitra at iastate.edu> wrote:
>>     
>>> Dear list,
>>>       
>>> I would like to do a huge number of lme's using the same design matrix
>>> (and fixed and random effects). Is it possible to do this efficiently?
>>> Doing otherwise is not an option for my example.
>>>       
>>> Basically, I am wanting to do the following which is possible using lm:
>>>       
>>> X <- matrix(rnorm(50),10,5)
>>> Y <- matrix(rnorm(50),10,5)
>>> lm(Y~X)
>>>       
>>> with lme. Any suggestions?
>>>       
>> It would not be easy to do this.  Neither lme nor lmer were designed
>> to make this easy to do.  There is a better chance of accomplishing
>> this by creating a custom function based on the current lmer but the
>> modifications required are non-trivial.
>>
>> This is a reasonable thing to want to accomplish and I will add it to
>> the "To Do" list for lmer.  However it is not something I will be able
>> to get to soon.
>>
>>
>>
>> ------------------------------
>>
>> Message: 9
>> Date: Fri, 22 Jun 2007 12:49:38 +0100
>> From: "S Ellison" <S.Ellison at lgc.co.uk>
>> Subject: Re: [R] abline plots at wrong abscissae after boxplot
>> To: <r-help at stat.math.ethz.ch>, <bwilfley at tripleringtech.com>
>> Message-ID: <s67bc579.034 at tedmail2.lgc.co.uk>
>> Content-Type: text/plain; charset=US-ASCII
>>
>> Boxplot positions and labels are not the same thing.
>> You have groups 'called' "2", "3", "4". As factors - which is what bocplot will turn them into -  they will be treated as arbitrary labels and _numbered_ 1:3 (try as.numeric(factor(x)).
>>
>> So your lm() used 2:4, but your plot (and abline) uses 1:3 for positions and "2" - "4" as labels.
>>
>> The best option used to be to plot the boxes at positions 2:4. Look at the at= parameter in boxplot.
>> But that is now of little help because there is no way of overriding xlim, leaving you no alternative but to reformulate your model with an offset or something.
>>
>> I will take up the boxplot xlim issue separately on R-dev; it's not the only such.
>>
>> Steve Ellison.
>>
>>     
>>>>> "Brian Wilfley" <bwilfley at tripleringtech.com> 21/06/2007 22:44:17 >>>
>>>>>           
>> I'm trying to add lines to a plot originally made with "boxplot", but
>> the lines appear in the wrong place.
>>
>> *******************************************************************
>> This email and any attachments are confidential. Any use, co...{{dropped}}
>>
>>
>>
>> ------------------------------
>>
>> Message: 10
>> Date: Fri, 22 Jun 2007 13:02:20 +0100
>> From: "S Ellison" <S.Ellison at lgc.co.uk>
>> Subject: [R] Boxplot issues
>> To: <r-help at stat.math.ethz.ch>
>> Message-ID: <s67bc871.078 at tedmail2.lgc.co.uk>
>> Content-Type: text/plain; charset=US-ASCII
>>
>> Boxplot and bxp seem to have changed behaviour a bit of late (R 2.4.1). Or maybe I am mis-remembering.
>>
>> An annoying feature is that while at=3:6 will work, there is no way of overriding the default xlim of 0.5 to n+0.5. That prevents plotting boxes on, for example, interval scales - a useful thing to do at times. I really can see no good reason for bxp to hard-core the xlim=c(0.5, n+0.5) in the function body; it should be a parameter default conditional on horizontal=, not hard coded.
>>
>> Also, boxplot does not drop empty groups. I'm sure it used to. I know it is good to be able to see where a factor level is unpopulated, but its a nuisance with fractional factorials and some nested or survey problems when many are known to be missing and are of no interest. Irrespective of whether my memory is correct, the option would be useful. How hard can it be to add a 'drop.empty=F' default to boxplot to allow it to switch?
>>
>> Obviously, these are things I can fix locally. But who 'owns' boxplot so I can provide suggested code to them for later releases?
>>
>> Steve Ellison
>>
>>
>>
>> *******************************************************************
>> This email and any attachments are confidential. Any use, co...{{dropped}}
>>
>>
>>
>> ------------------------------
>>
>> Message: 11
>> Date: Fri, 22 Jun 2007 07:35:51 -0500
>> From: Frank E Harrell Jr <f.harrell at vanderbilt.edu>
>> Subject: Re: [R] help on the use of ldBand
>> To: Tomas Goicoa <tomas.goicoa at unavarra.es>
>> Cc: r-help at stat.math.ethz.ch
>> Message-ID: <467BC227.8000701 at vanderbilt.edu>
>> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>>
>> Tomas Goicoa wrote:
>>     
>>>   Hi R Users,
>>>
>>>   I am trying to use the ldBand package. Together
>>> with the package, I have downloaded the ld98
>>> program (version for windows) as indicated in the
>>> help page on ldBand. I did it, but obtained an
>>> error message "Error in (head + 1):length(w) :
>>> Argument NA/NaN" when I copied the help examples,
>>> so it seems that a conection between R and ld98
>>> is not well performed in my computer.  Did I put
>>> ld98.exe in the wrong place? If so,  where should
>>> I put it? Thanks a lot in advance,
>>>
>>>
>>>   Berta Iba?ez Beroiz
>>>       
>> Do you mean the Hmisc package?  Do you mean the ldBands function?  Did
>> you put ld98.exe in a place that is in your system path as specified in
>> the ldBands help file?  And please read the posting guide referenced below.
>>
>> Frank
>>
>>     
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>       
>> --
>> Frank E Harrell Jr   Professor and Chair           School of Medicine
>>                      Department of Biostatistics   Vanderbilt University
>>
>>
>>
>> ------------------------------
>>
>> Message: 12
>> Date: Fri, 22 Jun 2007 13:27:35 +0200
>> From: "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be>
>> Subject: Re: [R] multiple return
>> To: <amicogodzilla at bruttocarattere.org>, <r-help at stat.math.ethz.ch>
>> Message-ID:
>>        <2E9C414912813E4EB981326983E0A104031A9629 at inboexch.inbo.be>
>> Content-Type: text/plain;       charset="us-ascii"
>>
>> Put the return values in a vector or list
>>
>> somma <- function (a, b) {
>>   c <- a+b
>>   return (c(a = a, b = b, c = c))
>> }
>>
>> somma(5,7)
>>  a  b  c
>>  5  7 12
>>
>>
>> somma <- function (a, b) {
>>   c <- a+b
>>   return (list(a = a, b = b, c = c))
>> }
>>
>> somma(5,7)
>> $a
>> [1] 5
>>
>> $b
>> [1] 7
>>
>> $c
>> [1] 12
>>
>> Cheers,
>>
>> Thierry
>> ------------------------------------------------------------------------
>> ----
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
>> methodology and quality assurance
>> Gaverstraat 4
>> 9500 Geraardsbergen
>> Belgium
>> tel. + 32 54/436 185
>> Thierry.Onkelinx at inbo.be
>> www.inbo.be
>>
>> Do not put your faith in what statistics say until you have carefully
>> considered what they do not say.  ~William W. Watt
>> A statistical analysis, properly conducted, is a delicate dissection of
>> uncertainties, a surgery of suppositions. ~M.J.Moroney
>>
>>
>>
>>     
>>> -----Oorspronkelijk bericht-----
>>> Van: r-help-bounces at stat.math.ethz.ch
>>> [mailto:r-help-bounces at stat.math.ethz.ch] Namens Manuele Pesenti
>>> Verzonden: vrijdag 22 juni 2007 12:38
>>> Aan: r-help at stat.math.ethz.ch
>>> Onderwerp: [R] multiple return
>>>
>>> Dear User,
>>> what's the correct way to obtain a multiple return from a function?
>>>
>>> for example creating the simple function:
>>>
>>> somma <- function (a, b) {
>>>   c <- a+b
>>>   return (a, b, c)
>>> }
>>>
>>> when I call it, it runs but returns the following output:
>>>
>>>       
>>>> somma(5, 7)
>>>>         
>>> $a
>>> [1] 5
>>>
>>> $b
>>> [1] 7
>>>
>>> $c
>>> [1] 12
>>>
>>> Warning message:
>>> return multi-argomento sono deprecati in: return(a, b, c)
>>>
>>> i.e. multi-return is deprecated...
>>>
>>> thanks a lot
>>> best regards
>>>       Manuele
>>>
>>> --
>>> Manuele Pesenti
>>>       manuele at inventati.org
>>>       amicogodzilla at jabber.linux.it
>>>       http://mpesenti.polito.it
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>       
>>
>> ------------------------------
>>
>> Message: 13
>> Date: Fri, 22 Jun 2007 06:20:27 -0700
>> From: Martin Morgan <mtmorgan at fhcrc.org>
>> Subject: Re: [R] extract index during execution of sapply
>> To: Christian Bieli <christian.bieli at unibas.ch>
>> Cc: R help list <r-help at stat.math.ethz.ch>
>> Message-ID: <6phodj85dno.fsf at gopher4.fhcrc.org>
>> Content-Type: text/plain; charset=us-ascii
>>
>> Christian,
>>
>> A favorite of mine is to use lexical scope and a 'factory' model:
>>
>>     
>>> fun_factory <- function() {
>>>       
>> +     i <- 0                  # 'state' variable(s), unique to each fun_factory
>> +     function(x) {           # fun_factory return value; used as sapply FUN
>> +         i <<- i + 1         # <<- assignment finds i
>> +         x^i                 # return value of sapply FUN
>> +     }
>> + }
>>     
>>> sapply(1:10, fun_factory())
>>>       
>>  [1]           1           4          27         256        3125       46656
>>  [7]      823543    16777216   387420489 10000000000
>>
>>
>> Christian Bieli <christian.bieli at unibas.ch> writes:
>>
>>     
>>> Hi there
>>> During execution of sapply I want to extract the number of times the
>>> function given to supply has been executed. I came up with:
>>>
>>> mylist <- list(a=3,b=6,c=9)
>>> sapply(mylist,function(x)as.numeric(gsub("[^0-9]","",deparse(substitute(x)))))
>>>
>>> This works fine, but looks quite ugly. I'm sure that there's a more
>>> elegant way to do this.
>>>
>>> Any suggestion?
>>>
>>> Christian
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>       
>> --
>> Martin Morgan
>> Bioconductor / Computational Biology
>> http://bioconductor.org
>>
>>
>>
>> ------------------------------
>>
>> Message: 14
>> Date: Fri, 22 Jun 2007 14:28:07 +0100
>> From: Robin Hankin <r.hankin at noc.soton.ac.uk>
>> Subject: [R] vectorize a function
>> To: RHelp help <r-help at stat.math.ethz.ch>
>> Message-ID: <F77DEE3F-E5AA-4A9B-A722-18F7DA006F46 at noc.soton.ac.uk>
>> Content-Type: text/plain; charset=US-ASCII; format=flowed
>>
>> Hello everyone
>>
>> suppose I have an integer vector "a" of length "n" and
>> a symmetric matrix "M" of size n-by-n.
>>
>> Vector "a" describes a partition of a set of "n" elements
>> and matrix M describes a penalty function: row i column
>> j represents the penalty if element i and element j
>> are in the same partition.
>>
>> Toy example follows; the real case is much larger
>> and I need to evaluate my penalty function many times.
>>
>> If a <- c(1,1,2,1,3)  then elements 1,2,4 are in the
>> same partition; element 3 is in a partition on its own
>> and element 5 is in a partition on its own.
>>
>> The total penalty  can be described by the following (ugly)
>> function:
>>
>> f <- function(a,M){
>>   out <- 0
>>   for(i in unique(a)){
>>     out <- out + sum(M[which(a==i),which(a==i)])
>>   }
>>   return(out)
>> }
>>
>>
>> so with
>>
>> M <- matrix(rpois(25,3),5,5)
>> M <- M+t(M)
>> diag(M) <- 0
>> a <- c(1,2,1,1,3)
>>
>> f(a,M) gives the total penalty.
>>
>>
>> QUESTION:  how to rewrite f() so that it has no loop?
>>
>>
>>
>>
>>
>>
>> --
>> Robin Hankin
>> Uncertainty Analyst
>> National Oceanography Centre, Southampton
>> European Way, Southampton SO14 3ZH, UK
>>  tel  023-8059-7743
>>
>>
>>
>> ------------------------------
>>
>> Message: 15
>> Date: Fri, 22 Jun 2007 09:56:20 -0400
>> From: "Kevin E. Thorpe" <kevin.thorpe at utoronto.ca>
>> Subject: Re: [R] Tools For Preparing Data For Analysis
>> To: r-help at stat.math.ethz.ch
>> Message-ID: <467BD504.4040705 at utoronto.ca>
>> Content-Type: text/plain; charset=ISO-8859-1
>>
>> I am posting to this thread that has been quiet for some time because I
>> remembered the following question.
>>
>> Christophe Pallier wrote:
>>     
>>> Hi,
>>>
>>> Can you provide examples of data formats that are problematic to read and
>>> clean with R ?
>>>       
>> Today I had a data manipulation problem that I don't know how to do in R
>> so I solved it with perl.  Since I'm always interested in learning more
>> about complex data manipulation in R I am posting my problem in the
>> hopes of receiving some hints for doing this in R.
>>
>> If anyone has nothing better to do than play with other people's data,
>> I would be happy to send the row files off-list.
>>
>> Background:
>>
>> I have been given data that contains two measurements of left
>> ventricular ejection fraction.  One of the methods is echocardiogram
>> which sometimes gives a true quantitative value and other times a
>> semi-quantitative value.  The desire is to compare echo with the
>> other method (MUGA).  In most cases, patients had either quantitative
>> or semi-quantitative.  Same patients had both.  The data came
>> to me in excel files with, basically, no patient identifiers to link
>> the "both" with the semi-quantitative patients (the "both" patients
>> were in multiple data sets).
>>
>> What I wanted to do was extract from the semi-quantitative data file
>> those patients with only semi-quantitative.  All I have to link with
>> are the semi-quantitative echo and the MUGA and these pairs of values
>> are not unique.
>>
>> To make this more concrete, here are some portions of the raw data.
>>
>> "Both"
>>
>> "ID NUM","ECHO","MUGA","Semiquant","Quant"
>> "B",12,37,10,12
>> "D",13,13,10,13
>> "E",13,26,10,15
>> "F",13,31,10,13
>> "H",15,15,10,15
>> "I",15,21,10,15
>> "J",15,22,10,15
>> "K",17,22,10,17
>> "N",17.5,4,10,17.5
>> "P",18,25,10,18
>> "R",19,25,10,19
>>
>> Seimi-quantitative
>>
>> "echo","muga","quant"
>> 10,20,0      <-- keep
>> 10,20,0      <-- keep
>> 10,21,0      <-- remove
>> 10,21,0      <-- keep
>> 10,24,0      <-- keep
>> 10,25,0      <-- remove
>> 10,25,0      <-- remove
>> 10,25,0      <-- keep
>>
>> Here is the perl program I wrote for this.
>>
>> #!/usr/bin/perl
>>
>> open(BOTH, "quant_qual_echo.csv") || die "Can't open quant_qual_echo.csv";
>> # Discard first row;
>> $_ = <BOTH>;
>> while(<BOTH>) {
>>    chomp;
>>    ($id, $e, $m, $sq, $qu) = split(/,/);
>>    $both{$sq,$m}++;
>> }
>> close(BOTH);
>>
>> open(OUT, "> qual_echo_only.csv") || die "Can't open qual_echo_only.csv";
>> print OUT "pid,echo,muga,quant\n";
>> $pid = 2001;
>>
>> open(QUAL, "qual_echo.csv") || die "Can't open qual_echo.csv";
>> # Discard first row
>> $_ = <QUAL>;
>> while(<QUAL>) {
>>    chomp;
>>    ($echo, $muga, $quant) = split(/,/);
>>    if ($both{$echo,$muga} > 0) {
>>        $both{$echo,$muga}--;
>>    }
>>    else {
>>        print OUT "$pid,$echo,$muga,$quant\n";
>>        $pid++;
>>    }
>> }
>> close(QUAL);
>> close(OUT);
>>
>> open(OUT, "> both_echo.csv") || die "Can't open both_echo.csv";
>> print OUT "pid,echo,muga,quant\n";
>> $pid = 3001;
>>
>> open(BOTH, "quant_qual_echo.csv") || die "Can't open quant_qual_echo.csv";
>> # Discard first row;
>> $_ = <BOTH>;
>> while(<BOTH>) {
>>    chomp;
>>    ($id, $e, $m, $sq, $qu) = split(/,/);
>>    print OUT "$pid,$sq,$m,0\n";
>>    print OUT "$pid,$qu,$m,1\n";
>>    $pid++;
>> }
>> close(BOTH);
>> close(OUT);
>>
>>
>> --
>> Kevin E. Thorpe
>> Biostatistician/Trialist, Knowledge Translation Program
>> Assistant Professor, Department of Public Health Sciences
>> Faculty of Medicine, University of Toronto
>> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.6057
>>
>>
>>
>> ------------------------------
>>
>> Message: 16
>> Date: Fri, 22 Jun 2007 09:58:39 -0400
>> From: "Kuhn, Max" <Max.Kuhn at pfizer.com>
>> Subject: Re: [R] Data consistency checks in functions
>> To: "Anup Nandialath" <anup_nandialath at yahoo.com>,
>>        <r-help at stat.math.ethz.ch>
>> Message-ID:
>>        <71257D09F114DA4A8E134DEAC70F25D308B9745C at groamrexm03.amer.pfizer.com>
>> Content-Type: text/plain;       charset="us-ascii"
>>
>> Anup,
>>
>> There are two ways to pass arguments to functions in R: as named
>> arguments or by position*.
>>
>> Users *can* supply arguments that are inconsistent with the order that
>> you specify in the function definition, but only if they are used as
>> named arguments:
>>
>>   myfun(X = someMatrix, values = aVector, theta = whatever)
>>
>> If the arguments are passed by position (as in myfun(beta, val1)), R
>> will assume that the first argument is theta, the second is X, etc since
>> that is how the function is defined.
>>
>> My suggestion would be to leave these arguments without defaults and put
>> a lot of checks in the function (using is.matrix, is.vector and a few
>> that check the content of the data I those objects).
>>
>>
>> * You can also mix the two:
>>
>>   foo(data, outcome, start = rep(0, 3))
>>
>>
>>
>> Max
>>
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch
>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Anup Nandialath
>> Sent: Friday, June 22, 2007 12:19 AM
>> To: r-help at stat.math.ethz.ch
>> Subject: [R] Data consistency checks in functions
>>
>> Dear friends,
>>
>> I'm writing a function with three arguments
>>
>> myfun <- function(theta, X, values)
>>
>> {
>> ....
>> ....
>> }
>>
>> in this function, I'm trying to write consistency checks. In order to
>> compute the statistic of interest I only need theta and values. The idea
>> of having X in there is that, if values is not provided by the user,
>> then values is computed from X.
>>
>> my problem is I'm trying to write consistency checks. For instance if i
>> say
>>
>> output <- myfun(beta, val1), how do I ensure that R reads this as
>> passing arguments to "theta" and "values". In other words is it possible
>> to bypass X completely if values is provided. Also how is it possible
>> for R to recognize the second argument as being values and not X. This
>> is important because X is a matrix and values is a vector. Therefore any
>> checks using the dimensions of either one will land in trouble if it
>> does not correctly capture that.
>>
>> Thanks in advance
>> Sincerely
>>
>> Anup
>>
>>
>> ---------------------------------
>>
>>
>>        [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ----------------------------------------------------------------------
>> LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}
>>
>>
>>
>> ------------------------------
>>
>> Message: 17
>> Date: Fri, 22 Jun 2007 10:17:24 -0400
>> From: "Christos Hatzis" <christos at nuverabio.com>
>> Subject: Re: [R] vectorize a function
>> To: "'Robin Hankin'" <r.hankin at noc.soton.ac.uk>,        "'RHelp help'"
>>        <r-help at stat.math.ethz.ch>
>> Message-ID:
>>        <001b01c7b4d8$0e8129f0$0e010a0a at headquarters.silicoinsights>
>> Content-Type: text/plain;       charset="us-ascii"
>>
>> How about:
>>
>> sum(sapply(unique(a), function(x) {b <- which(a==x); sum(M[b, b])}))
>>
>> HTH
>> -Christos
>>
>> Christos Hatzis, Ph.D.
>> Nuvera Biosciences, Inc.
>> 400 West Cummings Park
>> Suite 5350
>> Woburn, MA 01801
>> Tel: 781-938-3830
>> www.nuverabio.com
>>
>>
>>     
>>> -----Original Message-----
>>> From: r-help-bounces at stat.math.ethz.ch
>>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Robin Hankin
>>> Sent: Friday, June 22, 2007 9:28 AM
>>> To: RHelp help
>>> Subject: [R] vectorize a function
>>>
>>> Hello everyone
>>>
>>> suppose I have an integer vector "a" of length "n" and a
>>> symmetric matrix "M" of size n-by-n.
>>>
>>> Vector "a" describes a partition of a set of "n" elements and
>>> matrix M describes a penalty function: row i column j
>>> represents the penalty if element i and element j are in the
>>> same partition.
>>>
>>> Toy example follows; the real case is much larger and I need
>>> to evaluate my penalty function many times.
>>>
>>> If a <- c(1,1,2,1,3)  then elements 1,2,4 are in the same
>>> partition; element 3 is in a partition on its own and element
>>> 5 is in a partition on its own.
>>>
>>> The total penalty  can be described by the following (ugly)
>>> function:
>>>
>>> f <- function(a,M){
>>>    out <- 0
>>>    for(i in unique(a)){
>>>      out <- out + sum(M[which(a==i),which(a==i)])
>>>    }
>>>    return(out)
>>> }
>>>
>>>
>>> so with
>>>
>>> M <- matrix(rpois(25,3),5,5)
>>> M <- M+t(M)
>>> diag(M) <- 0
>>> a <- c(1,2,1,1,3)
>>>
>>> f(a,M) gives the total penalty.
>>>
>>>
>>> QUESTION:  how to rewrite f() so that it has no loop?
>>>
>>>
>>>
>>>
>>>
>>>
>>> --
>>> Robin Hankin
>>> Uncertainty Analyst
>>> National Oceanography Centre, Southampton European Way,
>>> Southampton SO14 3ZH, UK
>>>   tel  023-8059-7743
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>       
>>
>> ------------------------------
>>
>> Message: 18
>> Date: Fri, 22 Jun 2007 13:23:08 +0000 (UTC)
>> From: Ben Bolker <bolker at ufl.edu>
>> Subject: Re: [R] extract index during execution of sapply
>> To: r-help at stat.math.ethz.ch
>> Message-ID: <loom.20070622T151700-639 at post.gmane.org>
>> Content-Type: text/plain; charset=us-ascii
>>
>> Christian Bieli <christian.bieli <at> unibas.ch> writes:
>>
>>     
>>> Hi there
>>> During execution of sapply I want to extract the number of times the
>>> function given to supply has been executed. I came up with:
>>>
>>> mylist <- list(a=3,b=6,c=9)
>>> sapply(mylist,function(x)as.numeric(gsub("[^0-9]","",deparse(substitute(x)))))
>>>
>>> This works fine, but looks quite ugly. I'm sure that there's a more
>>> elegant way to do this.
>>>
>>> Any suggestion?
>>>
>>> Christian
>>>
>>>       
>>   I would love to have an answer to this -- when I run
>> into this kind of problem I usually end up using mapply:
>> e.g., suppose I have
>>
>> mylist <- replicate(5,list(x=runif(10),y=runif(10)),simplify=FALSE)
>>
>> and I want to plot each element in a different color.  I'd like
>> to be able to do
>>
>> plot(0:1,0:1,type="n")
>> lapply(mylist,plot,col=i)
>>
>> but instead I do
>>
>> mapply(function(x,i) points(x,col=i),mylist,1:5)
>>
>> would it be too ugly to have a special variable called INDEX
>> that could be used within an sapply/lapply statement?
>>
>>
>>
>> ------------------------------
>>
>> Message: 19
>> Date: Fri, 22 Jun 2007 07:45:14 -0700 (PDT)
>> From: Thomas Lumley <tlumley at u.washington.edu>
>> Subject: Re: [R] extract index during execution of sapply
>> To: Ben Bolker <bolker at ufl.edu>
>> Cc: r-help at stat.math.ethz.ch
>> Message-ID:
>>        <Pine.LNX.4.64.0706220732470.20743 at homer22.u.washington.edu>
>> Content-Type: TEXT/PLAIN; charset=US-ASCII; format=flowed
>>
>> On Fri, 22 Jun 2007, Ben Bolker wrote:
>>
>>     
>>> Christian Bieli <christian.bieli <at> unibas.ch> writes:
>>>
>>>       
>>>> Hi there
>>>> During execution of sapply I want to extract the number of times the
>>>> function given to supply has been executed. I came up with:
>>>>
>>>> mylist <- list(a=3,b=6,c=9)
>>>> sapply(mylist,function(x)as.numeric(gsub("[^0-9]","",deparse(substitute(x)))))
>>>>
>>>> This works fine, but looks quite ugly. I'm sure that there's a more
>>>> elegant way to do this.
>>>>
>>>> Any suggestion?
>>>>
>>>> Christian
>>>>
>>>>         
>>>   I would love to have an answer to this -- when I run
>>> into this kind of problem I usually end up using mapply:
>>> e.g., suppose I have
>>>
>>> mylist <- replicate(5,list(x=runif(10),y=runif(10)),simplify=FALSE)
>>>
>>> and I want to plot each element in a different color.  I'd like
>>> to be able to do
>>>
>>> plot(0:1,0:1,type="n")
>>> lapply(mylist,plot,col=i)
>>>
>>> but instead I do
>>>
>>> mapply(function(x,i) points(x,col=i),mylist,1:5)
>>>
>>> would it be too ugly to have a special variable called INDEX
>>> that could be used within an sapply/lapply statement?
>>>
>>>       
>> There are two distinct suggestions here: a variable that says *how many*
>> times the function has been called, and a variable that say *which
>> element* is currently being operated on.   The first seems undesirable as
>> order of evaluation really should not matter in the apply functions.
>>
>> The second makes more sense but is still a little tricky. AFAICS there is
>> no way for lapply() to find out whether FUN will accept an argument INDEX
>> without an "unused argument(s)" error, so it can't just be passed as an
>> argument.  This suggests having yet another apply function, that would
>> assume an INDEX argument and might be written
>>   yapply<-function(X,FUN, ...) {
>>        index<-seq(length.out=length(X))
>>         mapply(FUN,X,INDEX=index,MoreArgs=list(...))
>>        }
>>
>> However, I think it would be preferable in many cases for INDEX to be
>> names(X) if it exists, rather than 1:n.  In any case, it is easy  to write
>> the function.
>>
>>        -thomas
>>
>>
>>
>> ------------------------------
>>
>> Message: 20
>> Date: Fri, 22 Jun 2007 10:49:08 -0400
>> From: "Oden, Kevin" <kevin.oden at wachovia.com>
>> Subject: [R] fitCopula
>> To: <r-help at stat.math.ethz.ch>
>> Message-ID:
>>        <E3A68C90920A014CBB128279519B1B35042FEB87 at M1WACA0030I001.cibna.msds.wachovia.net>
>>
>> Content-Type: text/plain
>>
>> I  am using R 2.5.0 on windows XP and trying to fit copula.  I see the
>> following code works for some users, however my code crashes on the
>> chol.   Any suggestions?
>>
>>
>>
>>     
>>>  mycop <- tCopula(param=0.5, dim=8, dispstr="ex", df=5)
>>>       
>>>  x <- rcopula(mycop, 1000)
>>>       
>>>  myfit <- fitCopula(x, mycop, c(0.6, 10), optim.control=list(trace=1),
>>>       
>> method="Nelder-Mead")
>>
>>  Nelder-Mead direct search function minimizer
>>
>> function value for initial parameters = -1747.582044
>>
>>  Scaled convergence tolerance is 2.6041e-05
>>
>> Stepsize computed as 1.000000
>>
>> Error in chol(x, pivot = FALSE) : the leading minor of order 2 is not
>> positive definite
>>
>>
>>
>> Kevin D. Oden
>>
>> e: kevin.oden at wachovia.com <mailto:kevin.oden at wachovia.com>
>>
>>
>>
>>
>>        [[alternative HTML version deleted]]
>>
>>
>>
>> ------------------------------
>>
>> Message: 21
>> Date: Fri, 22 Jun 2007 10:58:35 -0400
>> From: "Weiwei Shi" <helprhelp at gmail.com>
>> Subject: [R] how to ave this?
>> To: "R Help" <R-help at stat.math.ethz.ch>
>> Message-ID:
>>        <cdf817830706220758r10e93178x971a53e574e9488d at mail.gmail.com>
>> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>>
>> Hi,
>>
>> I have a list that looks like this:
>> [[1]]
>>             fc          tt
>> 50   0.07526882 0.000000000
>> 100  0.09289617 0.000000000
>> 150  0.12359551 0.000000000
>>
>> [[2]]
>>             fc          tt
>> 50   0.02040816 0.000000000
>> 100  0.03626943 0.005025126
>> 150  0.05263158 0.010101010
>>
>> and I am wondering how to "average" it so that I have one matrix t0 at
>> the end, and t0[1,1] = (0.075..+0.0204..)/2
>>
>> Thanks,
>>
>> --
>> Weiwei Shi, Ph.D
>> Research Scientist
>> GeneGO, Inc.
>>
>> "Did you always know?"
>> "No, I did not. But I believed..."
>> ---Matrix III
>>
>>
>>
>> ------------------------------
>>
>> Message: 22
>> Date: Fri, 22 Jun 2007 11:04:15 -0400
>> From: "Oden, Kevin" <kevin.oden at wachovia.com>
>> Subject: [R] fitCopula
>> To: <r-help at stat.math.ethz.ch>
>> Message-ID:
>>        <E3A68C90920A014CBB128279519B1B35042FEB88 at M1WACA0030I001.cibna.msds.wachovia.net>
>>
>> Content-Type: text/plain
>>
>>  I  am using R 2.5.0 on windows XP and trying to fit copula.  I see the
>> following code works for some users, however my code crashes on the
>> chol.   Any suggestions?
>>
>>
>>
>>     
>>>  mycop <- tCopula(param=0.5, dim=8, dispstr="ex", df=5)
>>>       
>>>  x <- rcopula(mycop, 1000)
>>>       
>>>  myfit <- fitCopula(x, mycop, c(0.6, 10), optim.control=list(trace=1),
>>>       
>> method="Nelder-Mead")
>>
>>  Nelder-Mead direct search function minimizer
>>
>> function value for initial parameters = -1747.582044
>>
>>  Scaled convergence tolerance is 2.6041e-05
>>
>> Stepsize computed as 1.000000
>>
>> Error in chol(x, pivot = FALSE) : the leading minor of order 2 is not
>> positive definite
>>
>>
>>
>> Kevin D. Oden
>>
>> e: kevin.oden at wachovia.com <mailto:kevin.oden at wachovia.com>
>>
>>
>>
>>
>>        [[alternative HTML version deleted]]
>>
>>
>>
>> ------------------------------
>>
>> Message: 23
>> Date: Fri, 22 Jun 2007 11:20:19 -0400
>> From: "Weiwei Shi" <helprhelp at gmail.com>
>> Subject: Re: [R] how to ave this?
>> To: "R Help" <R-help at stat.math.ethz.ch>
>> Message-ID:
>>        <cdf817830706220820k7db2f82dv3e2a2e7d7a39ff69 at mail.gmail.com>
>> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>>
>> one of my approaches is:
>>
>> x0 = sapply(mylist, cbind)
>>
>> and manipulate from x0 (x0[1:nrow(x0)/2, ] correponds to fc and the
>> lower part is tt.
>>
>> but it is not neat way.
>>
>>
>> On 6/22/07, Weiwei Shi <helprhelp at gmail.com> wrote:
>>     
>>> Hi,
>>>
>>> I have a list that looks like this:
>>> [[1]]
>>>              fc          tt
>>> 50   0.07526882 0.000000000
>>> 100  0.09289617 0.000000000
>>> 150  0.12359551 0.000000000
>>>
>>> [[2]]
>>>              fc          tt
>>> 50   0.02040816 0.000000000
>>> 100  0.03626943 0.005025126
>>> 150  0.05263158 0.010101010
>>>
>>> and I am wondering how to "average" it so that I have one matrix t0 at
>>> the end, and t0[1,1] = (0.075..+0.0204..)/2
>>>
>>> Thanks,
>>>
>>> --
>>> Weiwei Shi, Ph.D
>>> Research Scientist
>>> GeneGO, Inc.
>>>
>>> "Did you always know?"
>>> "No, I did not. But I believed..."
>>> ---Matrix III
>>>
>>>       
>> --
>> Weiwei Shi, Ph.D
>> Research Scientist
>> GeneGO, Inc.
>>
>> "Did you always know?"
>> "No, I did not. But I believed..."
>> ---Matrix III
>>
>>
>>
>> ------------------------------
>>
>> Message: 24
>> Date: Fri, 22 Jun 2007 16:26:57 +0100 (BST)
>> From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
>> Subject: Re: [R] Result depends on order of factors in unbalanced
>>        designs (lme, anova)?
>> To: Karl Knoblick <karlknoblich at yahoo.de>
>> Cc: r-help at stat.math.ethz.ch
>> Message-ID: <Pine.LNX.4.64.0706221617190.11817 at gannet.stats.ox.ac.uk>
>> Content-Type: TEXT/PLAIN; charset=US-ASCII; format=flowed
>>
>> 'anova' is rather a misnomer here.  In terms of the description in
>> ?anova.lme, you have
>>
>>      When only one fitted model object is present, a data frame with
>>      the sums of squares, numerator degrees of freedom, denominator
>>      degrees of freedom, F-values, and P-values for Wald tests for the
>>      terms in the model ...
>>
>> but there are no 'sums of squares' shown.  However, the crucial part of
>> that help page is
>>
>>     type: an optional character string specifying the type of sum of
>>           squares to be used in F-tests for the terms in the model. If
>>           '"sequential"', the sequential sum of squares obtained by
>>           including the terms in the order they appear in the model is
>>           used; else, if '"marginal"', the marginal sum of squares
>>           obtained by deleting a term from the model at a time is used.
>>           This argument is only used when a single fitted object is
>>           passed to the function. Partial matching of arguments is
>>           used, so only the first character needs to be provided.
>>           Defaults to '"sequential"'.
>>
>> so these are sequential fits (just like anova for an lm fit), and yes,
>> sequential fits do in general depend on the sequence of terms.
>>
>> The issues of interpretation are exactly those of unbalanced linear
>> models, and you will find advice on that in many places, e.g. in MASS.
>>
>>
>> On Thu, 21 Jun 2007, Karl Knoblick wrote:
>>
>>     
>>> Dear R-Community!
>>>
>>> For example I have a study with 4 treatment groups (10 subjects per group) and 4 visits. Additionally, the gender is taken into account. I think - and hope this is a goog idea (!) - this data can be analysed using lme as below.
>>>
>>> In a balanced design everything is fine, but in an unbalanced design there are differences depending on fitting y~visit*treat*gender or y~gender*visit*treat - at least with anova (see example). Does this make sense? Which ordering might be the correct one?
>>>
>>> Here the example script:
>>> library(nlme)
>>> set.seed(123)
>>> # Random generation of data:
>>> NSubj<-40 # No. of subjects
>>> set.seed(1234)
>>> id<-factor(rep(c(1:NSubj),4)) # ID of subjects
>>> treat<-factor(rep(rep(1:4,each=5),4)) # Treatment 4 Levels
>>> gender<-factor(rep(rep(1:2, each=20),4))
>>> visit<-factor(rep(1:4, each=NSubj))
>>> y<-runif(4*NSubj) # Results
>>> # Add effects
>>> y<-y+0.01*as.integer(visit)
>>> y<-y+0.02*as.integer(gender)
>>> y<-y+0.024*as.integer(treat)
>>> df<-data.frame(id, treat, gender, visit, y)
>>> # groupedData object for lme
>>> gdat<-groupedData(y ~ visit|id, data=df)
>>> # fits - different ordering of factors
>>> fit1<-lme(y ~ visit*treat*gender, data=gdat, random = ~visit|id)
>>> anova(fit1)
>>> fit2<-lme(y ~ gender*treat*visit, data=gdat, random = ~visit|id)
>>> anova(fit2)
>>> # Result: identical (balanced design so far), ok
>>> # Now change gender of subject 1
>>> gdat$gender[c(1,41,81,121)]<-2
>>> # onece more fits with different ordering of factors
>>> fit1<-lme(y ~ visit*treat*gender, data=gdat, random = ~visit|id)
>>> anova(fit1)
>>> fit2<-lme(y ~ gender*treat*visit, data=gdat, random = ~visit|id)
>>> anova(fit2)
>>> # Result: There are differences!!
>>>
>>> Hope anybody can help or give me advice how to interpret these results correctly or how to avoid this problem! Is there a better possibility to analyse these data than lme?
>>>
>>> Thanks!
>>> Karl
>>>       
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>>
>>
>> ------------------------------
>>
>> Message: 25
>> Date: Fri, 22 Jun 2007 17:27:42 +0200
>> From: "Christophe Pallier" <christophe at pallier.org>
>> Subject: Re: [R] Tools For Preparing Data For Analysis
>> To: "Kevin E. Thorpe" <kevin.thorpe at utoronto.ca>
>> Cc: r-help at stat.math.ethz.ch
>> Message-ID:
>>        <dea6cb960706220827y4c281c31t493106eeaffedd4b at mail.gmail.com>
>> Content-Type: text/plain
>>
>> If I understand correctly (from your Perl script)
>>
>> 1. you count the number of occurences of each "(echo, muga)" pairs in the
>> first file.
>>
>> 2. you remove from the second file the lines that correspond to these
>> occurences.
>>
>> If this is indeed your aim, here's a solution in R:
>>
>> cumcount <- function(x) {
>>  y <- numeric(length(x))
>>  for (i in 1:length(y)) {
>>     y[i] = sum(x[1:i] == x[i])
>>  }
>>  y
>> }
>>
>> both <- read.csv('both_echo.csv')
>> v <- table(paste(both$echo, "_", both$muga, sep=""))
>>
>> semi <- read.csv('qual_echo.csv')
>> s <- paste(semi$echo, "_", semi$muga, sep="")
>> cs = cumcount(s)
>> count = v[s]
>> count[is.na(count)]=0
>>
>> semi2 <- data.frame(semi, s, cs, count, keep = cs > count)
>>
>>     
>>> semi2
>>>       
>>  echo muga quant     s cs count  keep
>> 1   10   20     0 10_20  1     0  TRUE
>> 2   10   20     0 10_20  2     0  TRUE
>> 3   10   21     0 10_21  1     1 FALSE
>> 4   10   21     0 10_21  2     1  TRUE
>> 5   10   24     0 10_24  1     0  TRUE
>> 6   10   25     0 10_25  1     2 FALSE
>> 7   10   25     0 10_25  2     2 FALSE
>> 8   10   25     0 10_25  3     2  TRUE
>>
>>
>> My code is not very readable...
>> Yet, the 'trick' of using an helper function like 'cumcount' might be
>> instructive.
>>
>> Christophe Pallier
>>
>>
>> On 6/22/07, Kevin E. Thorpe <kevin.thorpe at utoronto.ca> wrote:
>>     
>>> I am posting to this thread that has been quiet for some time because I
>>> remembered the following question.
>>>
>>> Christophe Pallier wrote:
>>>       
>>>> Hi,
>>>>
>>>> Can you provide examples of data formats that are problematic to read
>>>>         
>>> and
>>>       
>>>> clean with R ?
>>>>         
>>> Today I had a data manipulation problem that I don't know how to do in R
>>> so I solved it with perl.  Since I'm always interested in learning more
>>> about complex data manipulation in R I am posting my problem in the
>>> hopes of receiving some hints for doing this in R.
>>>
>>> If anyone has nothing better to do than play with other people's data,
>>> I would be happy to send the row files off-list.
>>>
>>> Background:
>>>
>>> I have been given data that contains two measurements of left
>>> ventricular ejection fraction.  One of the methods is echocardiogram
>>> which sometimes gives a true quantitative value and other times a
>>> semi-quantitative value.  The desire is to compare echo with the
>>> other method (MUGA).  In most cases, patients had either quantitative
>>> or semi-quantitative.  Same patients had both.  The data came
>>> to me in excel files with, basically, no patient identifiers to link
>>> the "both" with the semi-quantitative patients (the "both" patients
>>> were in multiple data sets).
>>>
>>> What I wanted to do was extract from the semi-quantitative data file
>>> those patients with only semi-quantitative.  All I have to link with
>>> are the semi-quantitative echo and the MUGA and these pairs of values
>>> are not unique.
>>>
>>> To make this more concrete, here are some portions of the raw data.
>>>
>>> "Both"
>>>
>>> "ID NUM","ECHO","MUGA","Semiquant","Quant"
>>> "B",12,37,10,12
>>> "D",13,13,10,13
>>> "E",13,26,10,15
>>> "F",13,31,10,13
>>> "H",15,15,10,15
>>> "I",15,21,10,15
>>> "J",15,22,10,15
>>> "K",17,22,10,17
>>> "N",17.5,4,10,17.5
>>> "P",18,25,10,18
>>> "R",19,25,10,19
>>>
>>> Seimi-quantitative
>>>
>>> "echo","muga","quant"
>>> 10,20,0      <-- keep
>>> 10,20,0      <-- keep
>>> 10,21,0      <-- remove
>>> 10,21,0      <-- keep
>>> 10,24,0      <-- keep
>>> 10,25,0      <-- remove
>>> 10,25,0      <-- remove
>>> 10,25,0      <-- keep
>>>
>>> Here is the perl program I wrote for this.
>>>
>>> #!/usr/bin/perl
>>>
>>> open(BOTH, "quant_qual_echo.csv") || die "Can't open quant_qual_echo.csv";
>>> # Discard first row;
>>> $_ = <BOTH>;
>>> while(<BOTH>) {
>>>     chomp;
>>>     ($id, $e, $m, $sq, $qu) = split(/,/);
>>>     $both{$sq,$m}++;
>>> }
>>> close(BOTH);
>>>
>>> open(OUT, "> qual_echo_only.csv") || die "Can't open qual_echo_only.csv";
>>> print OUT "pid,echo,muga,quant\n";
>>> $pid = 2001;
>>>
>>> open(QUAL, "qual_echo.csv") || die "Can't open qual_echo.csv";
>>> # Discard first row
>>> $_ = <QUAL>;
>>> while(<QUAL>) {
>>>     chomp;
>>>     ($echo, $muga, $quant) = split(/,/);
>>>     if ($both{$echo,$muga} > 0) {
>>>         $both{$echo,$muga}--;
>>>     }
>>>     else {
>>>         print OUT "$pid,$echo,$muga,$quant\n";
>>>         $pid++;
>>>     }
>>> }
>>> close(QUAL);
>>> close(OUT);
>>>
>>> open(OUT, "> both_echo.csv") || die "Can't open both_echo.csv";
>>> print OUT "pid,echo,muga,quant\n";
>>> $pid = 3001;
>>>
>>> open(BOTH, "quant_qual_echo.csv") || die "Can't open quant_qual_echo.csv";
>>> # Discard first row;
>>> $_ = <BOTH>;
>>> while(<BOTH>) {
>>>     chomp;
>>>     ($id, $e, $m, $sq, $qu) = split(/,/);
>>>     print OUT "$pid,$sq,$m,0\n";
>>>     print OUT "$pid,$qu,$m,1\n";
>>>     $pid++;
>>> }
>>> close(BOTH);
>>> close(OUT);
>>>
>>>
>>> --
>>> Kevin E. Thorpe
>>> Biostatistician/Trialist, Knowledge Translation Program
>>> Assistant Professor, Department of Public Health Sciences
>>> Faculty of Medicine, University of Toronto
>>> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.6057
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>       
>>
>> --
>> Christophe Pallier (http://www.pallier.org)
>>
>>        [[alternative HTML version deleted]]
>>
>>
>>
>> ------------------------------
>>
>> Message: 26
>> Date: Fri, 22 Jun 2007 16:30:44 +0100
>> From: Simon Wood <s.wood at bath.ac.uk>
>> Subject: Re: [R] interpretation of F-statistics in GAMs
>> To: r-help at stat.math.ethz.ch
>> Message-ID: <200706221630.44317.s.wood at bath.ac.uk>
>> Content-Type: text/plain;  charset="iso-8859-1"
>>
>> On Friday 15 June 2007 08:06, robert.ptacnik at niva.no wrote:
>>     
>>> dear listers,
>>> I use gam (from mgcv) for evaluation of shape and strength of relationships
>>> between a response variable and several predictors.
>>> How can I interpret the 'F' values viven in the GAM summary? Is it
>>> appropriate to treat them in a similar manner as the T-statistics in a
>>> linear model, i.e. larger values mean that this variable has a stronger
>>> impact than a variable with smaller F?
>>>       
>> - I'd be a bit cautious about this (even for T-statistics and linear models
>> it's not quite clear to me what `impact' means if judged this way). These gam
>> F statistics are only meant to provide a rough and ready means of judging
>> approximate significance of terms, and I'm unsure about interpreting a
>> comparison of such F ratios: for example the F statistics can be based on
>> differerent numbers of degrees of freedom, depending on the term concerned...
>>
>>     
>>> When I run my analysis for two different response varables (but identical
>>> predictors), is there a way to compare the F values among tests (like to
>>> standardize them by teh sum of F within each test?) I append two summaries
>>> below.
>>>       
>> - Again, I don't really known how this would work. I'd be more inclined to
>> compare the plotted terms and associated CIs (and maybe the p-values),
>> especially if you are using GAMs in a quite exploratory way (e.g. if the
>> assumption of an additive structure is really a convenience, rather than
>> being something that is suggested by the underlying science).
>>
>> best,
>> Simon
>>
>>     
>>> ### example 1 ###
>>>
>>> Family: gaussian
>>> Link function: identity
>>>
>>> Formula:
>>> dep[sel, i] ~ s(date, k = 3) + s(depth, k = kn) + s(temp, k = kn) +
>>>     s(light, k = kn) + s(PO4, k = kn) + s(DIN, k = kn) + s(prop.agpla,
>>>     k = kn)
>>>
>>> Parametric coefficients:
>>>             Estimate Std. Error t value Pr(>|t|)
>>> (Intercept)   5.1048     0.0384   132.9   <2e-16 ***
>>> ---
>>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>>
>>> Approximate significance of smooth terms:
>>>                 edf Est.rank      F  p-value
>>> s(date)       1.669        2 12.161 1.07e-05 ***
>>> s(depth)      1.671        2 36.125 4.85e-14 ***
>>> s(temp)       1.927        2  6.686  0.00156 **
>>> s(light)      1.886        2 12.604 7.20e-06 ***
>>> s(PO4)        1.676        2  3.237  0.04143 *
>>> s(DIN)        1.000        1 38.428 3.41e-09 ***
>>> s(prop.agpla) 1.405        2 15.987 3.79e-07 ***
>>> ---
>>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>>
>>> R-sq.(adj) =  0.687   Deviance explained = 70.5%
>>> GCV score = 0.31995   Scale est. = 0.30076   n = 204
>>>
>>> ### example 2 ###
>>> Family: gaussian
>>> Link function: identity
>>>
>>> Formula:
>>> dep[sel, i] ~ s(date, k = 3) + s(depth, k = kn) + s(temp, k = kn) +
>>>     s(light, k = kn) + s(PO4, k = kn) + s(DIN, k = kn) + s(prop.agpla,
>>>     k = kn)
>>>
>>> Parametric coefficients:
>>>             Estimate Std. Error t value Pr(>|t|)
>>> (Intercept)  7.13588    0.05549   128.6   <2e-16 ***
>>> ---
>>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>>
>>> Approximate significance of smooth terms:
>>>                 edf Est.rank      F  p-value
>>> s(date)       1.944        2 15.997 3.67e-07 ***
>>> s(depth)      1.876        2 25.427 1.52e-10 ***
>>> s(temp)       1.000        1  2.866   0.0921 .
>>> s(light)      1.751        2  4.212   0.0162 *
>>> s(PO4)        1.950        2 10.632 4.14e-05 ***
>>> s(DIN)        1.805        2 10.745 3.73e-05 ***
>>> s(prop.agpla) 1.715        2  2.674   0.0715 .
>>> ---
>>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>>
>>>  R-sq.(adj) =  0.479   Deviance explained = 50.9%
>>> GCV score = 0.6863   Scale est. = 0.64348   n = 209
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html and provide commented, minimal,
>>> self-contained, reproducible code.
>>>       
>> --
>>     
>>> Simon Wood, Mathematical Sciences, University of Bath, Bath, BA2 7AY UK
>>> +44 1225 386603  www.maths.bath.ac.uk/~sw283
>>>       
>>
>> ------------------------------
>>
>> Message: 27
>> Date: Fri, 22 Jun 2007 17:53:01 +0200
>> From: Martin Maechler <maechler at stat.math.ethz.ch>
>> Subject: Re: [R] Boxplot issues
>> To: "S Ellison" <S.Ellison at lgc.co.uk>
>> Cc: r-help at stat.math.ethz.ch
>> Message-ID: <18043.61533.242252.779598 at stat.math.ethz.ch>
>> Content-Type: text/plain; charset=us-ascii
>>
>>     
>>>>>>> "SE" == S Ellison <S.Ellison at lgc.co.uk>
>>>>>>>     on Fri, 22 Jun 2007 13:02:20 +0100 writes:
>>>>>>>               
>>    SE> Boxplot and bxp seem to have changed behaviour a bit of late (R 2.4.1). Or maybe I am mis-remembering.
>>    SE> An annoying feature is that while at=3:6 will work, there is no way of overriding the default xlim of 0.5 to n+0.5. That prevents plotting boxes on, for example, interval scales - a useful thing to do at times. I really can see no good reason for bxp to hard-core the xlim=c(0.5, n+0.5) in the function body; it should be a parameter default conditional on horizontal=, not hard coded.
>>
>>    SE> Also, boxplot does not drop empty groups. I'm sure it used to. I know it is good to be able to see where a factor level is unpopulated, but its a nuisance with fractional factorials and some nested or survey problems when many are known to be missing and are of no interest. Irrespective of whether my memory is correct, the option would be useful. How hard can it be to add a 'drop.empty=F' default to boxplot to allow it to switch?
>>
>>    SE> Obviously, these are things I can fix locally. But who 'owns' boxplot so I can provide suggested code to them for later releases?
>>
>>
>> Legally speaking, I think that's a hard question the answer of
>> which may even depend on the country where it is answered.
>> I would like to say it is owned by the R Foundation.
>>
>> Suggested improvements of the R "base code" should be made and
>> discussed on the R-devel mailing list. That's exactly the main
>> purpose of that list.
>> Such propositions typically make it into the code base
>> if you are convincing and you provide code improvements that
>> convince at least one member of R core that it's worth his time
>> to implement, document, *and* test the changes.
>>
>> Also, as on R-help, it helps to work with small reproducible
>> (ideally "cut-n-pastable") R code examples.
>>
>> Regards,
>> Martin Maechler
>>
>>    SE> Steve Ellison
>>
>>
>>
>> ------------------------------
>>
>> Message: 28
>> Date: Fri, 22 Jun 2007 12:19:35 -0400
>> From: S?bastien <pomchip at free.fr>
>> Subject: Re: [R] Overlaying lattice graphs (continued)
>> To: Deepayan Sarkar <deepayan.sarkar at gmail.com>
>> Cc: R-help <r-help at stat.math.ethz.ch>
>> Message-ID: <467BF697.8050203 at free.fr>
>> Content-Type: text/plain; charset=UTF-8; format=flowed
>>
>> Hi Deepayan,
>>
>> The following code creates a dummy dataset which has the same similar as
>> my usual datasets. I did not try to implement the changes proposed by
>> Hadley, hoping that a solution can be found using the original dataset.
>>
>> ######### My code
>>
>> # Creating dataset
>>
>> nPts<-10            # number of time points
>> nInd<-6              # number of individuals
>> nModel<-3         # number of models
>>
>> TimePts<-rep(1:nPts,nInd*nModel)                                    #
>> creates the "Time" column
>> Coef<-rep(rnorm(6,0.1,0.01),each=nPts,nModel)             # Creates a
>> vector of coefficients for generating the observations
>> Obs<-10*exp(-Coef*TimePts)                                         #
>> creates the observations
>>
>> for (i in 1:60){
>> Pred[i]<-jitter(10*exp(-Coef[i]*TimePts[i]))
>> Pred[i+60]<-jitter(5)
>> Pred[i+120]<-jitter(10-Coef[i+120]*TimePts[i])
>> }
>>                  # creates the predicted values
>>
>> colPlot<-rep(1,nPts*nInd*nModel)
>>    # creates the "Plot" column
>> colModel<-gl(nModel,nPts*nInd,labels=c("A","B","C"))             #
>> creates the "Model" column
>> colID<-gl(nInd,nPts,nPts*nInd*nModel)
>>      # creates the "ID" column
>>
>> mydata<-data.frame(colPlot,colModel,colID,TimePts,Obs,Pred)
>>              # creates the dataset
>> names(mydata)<-c("Plot","Model","Individuals","Time","Observed","Predicted")
>>
>> # Plotting as indicated by Deepayan
>>
>> xyplot(Observed + Predicted ~ Time | Individuals + Model,
>>      data = mydata,
>>      panel = panel.superpose.2, type = c("p", "l"),
>>      layout = c(0, nlevels(mydata$Individuals))) #,
>>      #<...>)
>>
>> ####### End of code
>>
>> This codes is not exactly what I am looking for, although it is pretty
>> close. In the present case, I would like to have a Trellis plot with 6
>> panels (one for each individual), where the Observations and the
>> Predicted are plotted as symbols and lines, respectively. All three
>> models should be plotted on the same panel. Unfortunately, it looks to
>> me as 3 successives xyplots are created by the code above but only the
>> last one remains displayed. I tried to play with
>> panel.superpose,panel.superpose.2 and type, without much success.
>>
>> I also tried the following code that creates 18 panels and distinguish
>> all (Individuals,Model) couples... so, not what I want.
>>
>> xyplot(Observed + Predicted ~ Time | Individuals+Model, data = mydata,
>>     type = c("p", "l"), distribute.type = TRUE)
>>
>> Sebastien
>>
>>
>> Deepayan Sarkar a ?crit :
>>     
>>> On 6/21/07, S?bastien <pomchip at free.fr> wrote:
>>>       
>>>> Hi Hadley,
>>>>
>>>> Hopefully, my dataset won't be too hard to changed. Can I modify the
>>>> aspect of each group using your code (symbols for observed and lines for
>>>> predicted)?
>>>>
>>>> Sebastien
>>>>
>>>> hadley wickham a ?crit :
>>>>         
>>>>> Hi Sebastian,
>>>>>
>>>>> I think you need to rearrange your data a bit.  Firstly, you need to
>>>>> put observed on the same footing as the different models, so you would
>>>>> have a new column in your data called value (previously observed and
>>>>> predicted) and a new model type ("observed").  Then you could do:
>>>>>           
>>> Yes, and ?make.groups (and reshape of course) could help with that.
>>> This might not be strictly necessary though.
>>>
>>> However, I'm finding your pseudo-code confusing. Could you create a
>>> small example data set that can be used to try out some real code?
>>> Just from your description, I would have suggested something like
>>>
>>> xyplot(Observed + Predicted ~ Time | Individuals + Model,
>>>       data = mydata,
>>>       panel = panel.superpose.2, type = c("p", "l"),
>>>       layout = c(0, nlevels(mydata$Individuals)),
>>>       <...>)
>>>
>>> If all you want is to plot one page at a time, there are easier ways
>>> to do that.
>>>
>>> -Deepayan
>>>
>>>       
>>>>> xyplot(value ~ time | individauls, data=mydata, group=model)
>>>>>
>>>>> Hadley
>>>>>
>>>>>
>>>>> On 6/21/07, S?bastien <pomchip at free.fr> wrote:
>>>>>           
>>>>>> Dear R Users,
>>>>>>
>>>>>> I recently posted an email on this list  about the use of
>>>>>>             
>>>> data.frame and
>>>>         
>>>>>> overlaying multiple plots. Deepayan kindly indicated to me the
>>>>>> panel.superposition command which worked perfectly in the context
>>>>>>             
>>>> of the
>>>>         
>>>>>> example I gave.
>>>>>> I'd like to go a little bit further on this topic using a more
>>>>>>             
>>>> complex
>>>>         
>>>>>> dataset structure (actually the one I want to work on).
>>>>>>
>>>>>>  >mydata
>>>>>>       Plot    Model    Individuals    Time        Observed
>>>>>> Predicted
>>>>>> 1    1        A           1                  0.05
>>>>>> 10                    10.2
>>>>>> 2    1        A           1                  0.10
>>>>>> 20                    19.5
>>>>>> etc...
>>>>>> 10  1        B           1                  0.05         10
>>>>>>          9.8
>>>>>> 11  1        B           1                  0.10         20
>>>>>>          20.2
>>>>>> etc...
>>>>>>
>>>>>> There are p "levels" in mydata$Plot, m in mydata$Model, n in
>>>>>> mydata$Individuals and t in mydata$Time (Note that I probably use the
>>>>>> word levels improperly as all columns are not factors). Basically,
>>>>>>             
>>>> this
>>>>         
>>>>>> dataset summarizes the t measurements obtained in n individuals as
>>>>>>             
>>>> well
>>>>         
>>>>>> as the predicted values from m different modeling approaches
>>>>>>             
>>>> (applied to
>>>>         
>>>>>> all individuals). Therefore, the observations are repeated m times in
>>>>>> the Observed columns, while the predictions appears only once for a
>>>>>> given model an a given individual.
>>>>>>
>>>>>> What I want to write is a R batch file creating a Trellis graph,
>>>>>>             
>>>> where
>>>>         
>>>>>> each panel corresponds to one individual and contains the
>>>>>>             
>>>> observations
>>>>         
>>>>>> (as scatterplot) plus the predicted values for all models (as
>>>>>>             
>>>> lines of
>>>>         
>>>>>> different colors)... $Plot is just a token: it might be used to not
>>>>>> overload graphs in case there are too many tested models. The fun
>>>>>>             
>>>> part
>>>>         
>>>>>> is that the values of p, m, n and t might vary from one dataset to
>>>>>>             
>>>> the
>>>>         
>>>>>> other, so everything has to be coded dynamically.
>>>>>>
>>>>>> For the plotting part I was thinking about having a loop in my code
>>>>>> containing something like that:
>>>>>>
>>>>>> for (i in 1:nlevels(mydata$Model)) {
>>>>>>
>>>>>> subdata<-subset(mydata,mydata$Model=level(mydata$Model)[i])
>>>>>> xyplot(subset(Observed + Predicted ~ Time | Individuals, data =
>>>>>> subdata)       #plus additionnal formatting code
>>>>>>
>>>>>> }
>>>>>>
>>>>>> Unfortunately, this code simply creates a new Trellis plot instead of
>>>>>> adding the model one by one on the panels. Any idea or link to a
>>>>>>             
>>>> useful
>>>>         
>>>>>> command will wellcome.
>>>>>>
>>>>>> Sebastien
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at stat.math.ethz.ch mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>>             
>>>>>           
>>>> ______________________________________________
>>>> R-help at stat.math.ethz.ch mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>         
>>
>> ------------------------------
>>
>> Message: 29
>> Date: Fri, 22 Jun 2007 19:26:56 +0200
>> From: "Jose Quesada " <quesada at gmail.com>
>> Subject: [R] Matrix library, CHOLMOD error: problem too large
>> To: "r-help at lists.r-project.org" <r-help at stat.math.ethz.ch>
>> Message-ID: <op.tub2q6d64hcap5 at delllap.ugr.es>
>> Content-Type: text/plain; format=flowed; delsp=yes;
>>        charset=iso-8859-15
>>
>>
>> I have a pretty large sparse matrix of integers:
>>     
>>> dim(tasa)
>>>       
>> [1] 91650 37651
>>
>> I need to add one to it in order to take logs, but I'm getting the
>> following error:
>>
>>     
>>> tasa  = log(tasa + 1)
>>>       
>> CHOLMOD error: problem too large
>> Error in asMethod(object) : Cholmod error `problem too large'
>>
>> I have 2 Gb of RAM, and the current workspace is barely 300mb.
>> Is there any workaround to this? Anyone has any experience with this error?
>>
>> Thanks,
>> -Jose
>>
>> --
>> Jose Quesada, PhD.
>> http://www.andrew.cmu.edu/~jquesada
>>
>>
>>
>> ------------------------------
>>
>> Message: 30
>> Date: Fri, 22 Jun 2007 14:04:03 -0400
>> From: Duncan Murdoch <murdoch at stats.uwo.ca>
>> Subject: Re: [R] Matrix library, CHOLMOD error: problem too large
>> To: Jose Quesada <quesada at gmail.com>
>> Cc: "r-help at lists.r-project.org" <r-help at stat.math.ethz.ch>
>> Message-ID: <467C0F13.4060004 at stats.uwo.ca>
>> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>>
>> On 6/22/2007 1:26 PM, Jose Quesada wrote:
>>     
>>> I have a pretty large sparse matrix of integers:
>>>       
>>>> dim(tasa)
>>>>         
>>> [1] 91650 37651
>>>
>>> I need to add one to it in order to take logs, but I'm getting the
>>> following error:
>>>
>>>       
>>>> tasa  = log(tasa + 1)
>>>>         
>>> CHOLMOD error: problem too large
>>> Error in asMethod(object) : Cholmod error `problem too large'
>>>
>>> I have 2 Gb of RAM, and the current workspace is barely 300mb.
>>> Is there any workaround to this? Anyone has any experience with this error?
>>>
>>>       
>> If tasa is sparse, then tasa+1 will not be sparse, so that's likely your
>> problem.  You might have better luck with
>>
>> log1p(tasa)
>>
>> if the authors of the Matrix package have written a method for log1p();
>> if not, you'll probably have to do it yourself.
>>
>> Duncan Murdoch
>>
>>
>>
>> ------------------------------
>>
>> Message: 31
>> Date: Fri, 22 Jun 2007 11:44:52 -0700
>> From: "Horace Tso" <Horace.Tso at pgn.com>
>> Subject: [R] Imputing missing values in time series
>> To: <r-help at stat.math.ethz.ch>
>> Message-ID: <467BB6340200006500006924 at pgn.com>
>> Content-Type: text/plain; charset=ISO-8859-15
>>
>> Folks,
>>
>> This must be a rather common problem with real life time series data
>> but I don't see anything in the archive about how to deal with it. I
>> have a time series of natural gas prices by flow date. Since gas is not
>> traded on weekends and holidays, I have a lot of missing values,
>>
>> FDate   Price
>> 11/1/2006       6.28
>> 11/2/2006       6.58
>> 11/3/2006       6.586
>> 11/4/2006       6.716
>> 11/5/2006       NA
>> 11/6/2006       NA
>> 11/7/2006       6.262
>> 11/8/2006       6.27
>> 11/9/2006       6.696
>> 11/10/2006      6.729
>> 11/11/2006      6.487
>> 11/12/2006      NA
>> 11/13/2006      NA
>> 11/14/2006      6.725
>> 11/15/2006      6.844
>> 11/16/2006      6.907
>>
>> What I would like to do is to fill the NAs with the price from the
>> previous date * gas used during holidays is purchased from the week
>> before. Though real simple, I wonder if there is a function to perform
>> this task. Some of the imputation functions I'm aware of (eg. impute,
>> transcan in Hmisc) seem to deal with completely different problems.
>>
>> 2.5.0/Windows XP
>>
>> Thanks in advance.
>>
>> HT
>>
>>
>>
>> ------------------------------
>>
>> Message: 32
>> Date: Fri, 22 Jun 2007 14:01:52 -0500
>> From: Erik Iverson <iverson at biostat.wisc.edu>
>> Subject: Re: [R] Imputing missing values in time series
>> To: Horace Tso <Horace.Tso at pgn.com>
>> Cc: r-help at stat.math.ethz.ch
>> Message-ID: <467C1CA0.1080606 at biostat.wisc.edu>
>> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>>
>> I think my example should work for you, but I couldn't think of a way to
>> do this without an interative while loop.
>>
>> test <- c(1,2,3,NA,4,NA,NA,5,NA,6,7,NA)
>>
>> while(any(is.na(test)))
>> test[is.na(test)] <- test[which(is.na(test))-1]
>>
>>  test
>>  [1] 1 2 3 3 4 4 4 5 5 6 7 7
>>
>> Horace Tso wrote:
>>     
>>> Folks,
>>>
>>> This must be a rather common problem with real life time series data
>>> but I don't see anything in the archive about how to deal with it. I
>>> have a time series of natural gas prices by flow date. Since gas is not
>>> traded on weekends and holidays, I have a lot of missing values,
>>>
>>> FDate Price
>>> 11/1/2006     6.28
>>> 11/2/2006     6.58
>>> 11/3/2006     6.586
>>> 11/4/2006     6.716
>>> 11/5/2006     NA
>>> 11/6/2006     NA
>>> 11/7/2006     6.262
>>> 11/8/2006     6.27
>>> 11/9/2006     6.696
>>> 11/10/2006    6.729
>>> 11/11/2006    6.487
>>> 11/12/2006    NA
>>> 11/13/2006    NA
>>> 11/14/2006    6.725
>>> 11/15/2006    6.844
>>> 11/16/2006    6.907
>>>
>>> What I would like to do is to fill the NAs with the price from the
>>> previous date * gas used during holidays is purchased from the week
>>> before. Though real simple, I wonder if there is a function to perform
>>> this task. Some of the imputation functions I'm aware of (eg. impute,
>>> transcan in Hmisc) seem to deal with completely different problems.
>>>
>>> 2.5.0/Windows XP
>>>
>>> Thanks in advance.
>>>
>>> HT
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>       
>>
>> ------------------------------
>>
>> Message: 33
>> Date: Fri, 22 Jun 2007 12:08:26 -0700
>> From: "Horace Tso" <Horace.Tso at pgn.com>
>> Subject: Re: [R] Imputing missing values in time series
>> To: "Erik Iverson" <iverson at biostat.wisc.edu>
>> Cc: r-help at stat.math.ethz.ch
>> Message-ID: <467BBBBA0200006500006928 at pgn.com>
>> Content-Type: text/plain; charset=US-ASCII
>>
>> Erik, indeed it gets the work done. I was hoping to avoid the dreaded looping, though.....
>>
>> Thanks.
>>
>> Horace
>>
>>     
>>>>> Erik Iverson <iverson at biostat.wisc.edu> 6/22/2007 12:01 PM >>>
>>>>>           
>> I think my example should work for you, but I couldn't think of a way to
>> do this without an interative while loop.
>>
>> test <- c(1,2,3,NA,4,NA,NA,5,NA,6,7,NA)
>>
>> while(any(is.na(test)))
>> test[is.na(test)] <- test[which(is.na(test))-1]
>>
>>  test
>>  [1] 1 2 3 3 4 4 4 5 5 6 7 7
>>
>> Horace Tso wrote:
>>     
>>> Folks,
>>>
>>> This must be a rather common problem with real life time series data
>>> but I don't see anything in the archive about how to deal with it. I
>>> have a time series of natural gas prices by flow date. Since gas is not
>>> traded on weekends and holidays, I have a lot of missing values,
>>>
>>> FDate Price
>>> 11/1/2006     6.28
>>> 11/2/2006     6.58
>>> 11/3/2006     6.586
>>> 11/4/2006     6.716
>>> 11/5/2006     NA
>>> 11/6/2006     NA
>>> 11/7/2006     6.262
>>> 11/8/2006     6.27
>>> 11/9/2006     6.696
>>> 11/10/2006    6.729
>>> 11/11/2006    6.487
>>> 11/12/2006    NA
>>> 11/13/2006    NA
>>> 11/14/2006    6.725
>>> 11/15/2006    6.844
>>> 11/16/2006    6.907
>>>
>>> What I would like to do is to fill the NAs with the price from the
>>> previous date * gas used during holidays is purchased from the week
>>> before. Though real simple, I wonder if there is a function to perform
>>> this task. Some of the imputation functions I'm aware of (eg. impute,
>>> transcan in Hmisc) seem to deal with completely different problems.
>>>
>>> 2.5.0/Windows XP
>>>
>>> Thanks in advance.
>>>
>>> HT
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>       
>>
>> ------------------------------
>>
>> Message: 34
>> Date: Fri, 22 Jun 2007 21:13:09 +0200
>> From: "hadley wickham" <h.wickham at gmail.com>
>> Subject: Re: [R] Switching X-axis and Y-axis for histogram
>> To: "Donghui Feng" <donghui.feng at gmail.com>
>> Cc: r-help at stat.math.ethz.ch
>> Message-ID:
>>        <f8e6ff050706221213j3dc25aeaw6c6d4df7a4511e06 at mail.gmail.com>
>> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>>
>> It's trivial to do this with ggplot2 (http://had.co.nz):
>>
>> qplot(rating, data=movies, geom="histogram") + coord_flip()
>> qplot(rating, data=movies, geom="histogram", binwidth=0.1) + coord_flip()
>>
>> Hadley
>>
>> On 6/22/07, Donghui Feng <donghui.feng at gmail.com> wrote:
>>     
>>> Dear all,
>>>
>>> I'm creating a histogram with the function hist(). But
>>> right now what I get is column representation (as normal).
>>> I'm wondering if I could switch X-axis and Y-axis and
>>> get row-representation of frequencies?
>>>
>>> One more question, can I define the step of each axises
>>> for the histogram?
>>>
>>> Thanks so much!
>>>
>>> Donghui
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>       
>>
>> ------------------------------
>>
>> Message: 35
>> Date: Fri, 22 Jun 2007 15:16:09 -0400
>> From: "Leeds, Mark \(IED\)" <Mark.Leeds at morganstanley.com>
>> Subject: Re: [R] Imputing missing values in time series
>> To: "Erik Iverson" <iverson at biostat.wisc.edu>,  "Horace Tso"
>>        <Horace.Tso at pgn.com>
>> Cc: r-help at stat.math.ethz.ch
>> Message-ID:
>>        <D3AEEDA31E57474B840BEBC25A8A834401957418 at NYWEXMB23.msad.ms.com>
>> Content-Type: text/plain;       charset="us-ascii"
>>
>> I have a function that does this type of thing but it works off a pure
>> vector so it wouldn have to be modified.
>> If you make your object a zoo object, the that object has many functions
>> associated with it and na.locf would
>> Do what you need, I think.
>>
>>
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch
>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Erik Iverson
>> Sent: Friday, June 22, 2007 3:02 PM
>> To: Horace Tso
>> Cc: r-help at stat.math.ethz.ch
>> Subject: Re: [R] Imputing missing values in time series
>>
>> I think my example should work for you, but I couldn't think of a way to
>> do this without an interative while loop.
>>
>> test <- c(1,2,3,NA,4,NA,NA,5,NA,6,7,NA)
>>
>> while(any(is.na(test)))
>> test[is.na(test)] <- test[which(is.na(test))-1]
>>
>>  test
>>  [1] 1 2 3 3 4 4 4 5 5 6 7 7
>>
>> Horace Tso wrote:
>>     
>>> Folks,
>>>
>>> This must be a rather common problem with real life time series data
>>> but I don't see anything in the archive about how to deal with it. I
>>> have a time series of natural gas prices by flow date. Since gas is
>>> not traded on weekends and holidays, I have a lot of missing values,
>>>
>>> FDate Price
>>> 11/1/2006     6.28
>>> 11/2/2006     6.58
>>> 11/3/2006     6.586
>>> 11/4/2006     6.716
>>> 11/5/2006     NA
>>> 11/6/2006     NA
>>> 11/7/2006     6.262
>>> 11/8/2006     6.27
>>> 11/9/2006     6.696
>>> 11/10/2006    6.729
>>> 11/11/2006    6.487
>>> 11/12/2006    NA
>>> 11/13/2006    NA
>>> 11/14/2006    6.725
>>> 11/15/2006    6.844
>>> 11/16/2006    6.907
>>>
>>> What I would like to do is to fill the NAs with the price from the
>>> previous date * gas used during holidays is purchased from the week
>>> before. Though real simple, I wonder if there is a function to perform
>>>       
>>> this task. Some of the imputation functions I'm aware of (eg. impute,
>>> transcan in Hmisc) seem to deal with completely different problems.
>>>
>>> 2.5.0/Windows XP
>>>
>>> Thanks in advance.
>>>
>>> HT
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>       
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> --------------------------------------------------------
>>
>> This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}
>>
>>
>>
>> ------------------------------
>>
>> Message: 36
>> Date: Fri, 22 Jun 2007 12:21:40 -0700
>> From: "Horace Tso" <Horace.Tso at pgn.com>
>> Subject: Re: [R] Imputing missing values in time series
>> To: "Erik Iverson" <iverson at biostat.wisc.edu>,  "Mark (IED) Leeds"
>>        <Mark.Leeds at morganstanley.com>
>> Cc: r-help at stat.math.ethz.ch
>> Message-ID: <467BBED40200006500006931 at pgn.com>
>> Content-Type: text/plain; charset=US-ASCII
>>
>> Mark, thanks for the tips. I thought you financial folks must have run into things like these before. Just wonder why this problem wasn't asked more often on this list.
>>
>> H.
>>
>>
>>     
>>>>> "Leeds, Mark (IED)" <Mark.Leeds at morganstanley.com> 6/22/2007 12:16 PM >>>
>>>>>           
>> I have a function that does this type of thing but it works off a pure
>> vector so it wouldn have to be modified.
>> If you make your object a zoo object, the that object has many functions
>> associated with it and na.locf would
>> Do what you need, I think.
>>
>>
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch
>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Erik Iverson
>> Sent: Friday, June 22, 2007 3:02 PM
>> To: Horace Tso
>> Cc: r-help at stat.math.ethz.ch
>> Subject: Re: [R] Imputing missing values in time series
>>
>> I think my example should work for you, but I couldn't think of a way to
>> do this without an interative while loop.
>>
>> test <- c(1,2,3,NA,4,NA,NA,5,NA,6,7,NA)
>>
>> while(any(is.na(test)))
>> test[is.na(test)] <- test[which(is.na(test))-1]
>>
>>  test
>>  [1] 1 2 3 3 4 4 4 5 5 6 7 7
>>
>> Horace Tso wrote:
>>     
>>> Folks,
>>>
>>> This must be a rather common problem with real life time series data
>>> but I don't see anything in the archive about how to deal with it. I
>>> have a time series of natural gas prices by flow date. Since gas is
>>> not traded on weekends and holidays, I have a lot of missing values,
>>>
>>> FDate Price
>>> 11/1/2006     6.28
>>> 11/2/2006     6.58
>>> 11/3/2006     6.586
>>> 11/4/2006     6.716
>>> 11/5/2006     NA
>>> 11/6/2006     NA
>>> 11/7/2006     6.262
>>> 11/8/2006     6.27
>>> 11/9/2006     6.696
>>> 11/10/2006    6.729
>>> 11/11/2006    6.487
>>> 11/12/2006    NA
>>> 11/13/2006    NA
>>> 11/14/2006    6.725
>>> 11/15/2006    6.844
>>> 11/16/2006    6.907
>>>
>>> What I would like to do is to fill the NAs with the price from the
>>> previous date * gas used during holidays is purchased from the week
>>> before. Though real simple, I wonder if there is a function to perform
>>>       
>>> this task. Some of the imputation functions I'm aware of (eg. impute,
>>> transcan in Hmisc) seem to deal with completely different problems.
>>>
>>> 2.5.0/Windows XP
>>>
>>> Thanks in advance.
>>>
>>> HT
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>       
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> --------------------------------------------------------
>>
>> This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}
>>
>>
>>
>> ------------------------------
>>
>> Message: 37
>> Date: Fri, 22 Jun 2007 21:40:26 +0200
>> From: "hadley wickham" <h.wickham at gmail.com>
>> Subject: Re: [R] Overlaying lattice graphs (continued)
>> To: " S?bastien " <pomchip at free.fr>
>> Cc: R-help <r-help at stat.math.ethz.ch>
>> Message-ID:
>>        <f8e6ff050706221240m240391dfrf83f5eb6d47e1766 at mail.gmail.com>
>> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>>
>> Hi Sebastian,
>>
>> I think the following does what you want:
>>
>> library(ggplot2)
>> names(mydata) <- tolower(names(mydata))
>>
>> obs <- rename(subset(mydata, model=="A", -predicted), c("observed" = "value"))
>> obs$model <- factor("observed")
>> pred <- rename(mydata[, -5], c("predicted" = "value"))
>> all <- rbind(obs, pred)
>>
>> ggplot(all, aes(x = time, y = value, colour=model)) +
>> geom_point(data = subset(all, model != "Observed")) +
>> geom_line(data= subset(all, model == "Observed")) +
>> facet_grid(. ~ individuals)
>>
>> Hadley
>>
>> On 6/22/07, S?bastien <pomchip at free.fr> wrote:
>>     
>>> Hi Deepayan,
>>>
>>> The following code creates a dummy dataset which has the same similar as
>>> my usual datasets. I did not try to implement the changes proposed by
>>> Hadley, hoping that a solution can be found using the original dataset.
>>>
>>> ######### My code
>>>
>>> # Creating dataset
>>>
>>> nPts<-10            # number of time points
>>> nInd<-6              # number of individuals
>>> nModel<-3         # number of models
>>>
>>> TimePts<-rep(1:nPts,nInd*nModel)                                    #
>>> creates the "Time" column
>>> Coef<-rep(rnorm(6,0.1,0.01),each=nPts,nModel)             # Creates a
>>> vector of coefficients for generating the observations
>>> Obs<-10*exp(-Coef*TimePts)                                         #
>>> creates the observations
>>>
>>> for (i in 1:60){
>>> Pred[i]<-jitter(10*exp(-Coef[i]*TimePts[i]))
>>> Pred[i+60]<-jitter(5)
>>> Pred[i+120]<-jitter(10-Coef[i+120]*TimePts[i])
>>> }
>>>                   # creates the predicted values
>>>
>>> colPlot<-rep(1,nPts*nInd*nModel)
>>>     # creates the "Plot" column
>>> colModel<-gl(nModel,nPts*nInd,labels=c("A","B","C"))             #
>>> creates the "Model" column
>>> colID<-gl(nInd,nPts,nPts*nInd*nModel)
>>>       # creates the "ID" column
>>>
>>> mydata<-data.frame(colPlot,colModel,colID,TimePts,Obs,Pred)
>>>               # creates the dataset
>>> names(mydata)<-c("Plot","Model","Individuals","Time","Observed","Predicted")
>>>
>>> # Plotting as indicated by Deepayan
>>>
>>>
>>> xyplot(Observed + Predicted ~ Time | Individuals + Model,
>>>       data = mydata,
>>>       panel = panel.superpose.2, type = c("p", "l"),
>>>       layout = c(0, nlevels(mydata$Individuals))) #,
>>>       #<...>)
>>>
>>> ####### End of code
>>>
>>> This codes is not exactly what I am looking for, although it is pretty
>>> close. In the present case, I would like to have a Trellis plot with 6
>>> panels (one for each individual), where the Observations and the
>>> Predicted are plotted as symbols and lines, respectively. All three
>>> models should be plotted on the same panel. Unfortunately, it looks to
>>> me as 3 successives xyplots are created by the code above but only the
>>> last one remains displayed. I tried to play with
>>> panel.superpose,panel.superpose.2 and type, without much success.
>>>
>>> I also tried the following code that creates 18 panels and distinguish
>>> all (Individuals,Model) couples... so, not what I want.
>>>
>>> xyplot(Observed + Predicted ~ Time | Individuals+Model, data = mydata,
>>>      type = c("p", "l"), distribute.type = TRUE)
>>>
>>> Sebastien
>>>
>>>
>>> Deepayan Sarkar a ?crit :
>>>       
>>>> On 6/21/07, S?bastien <pomchip at free.fr> wrote:
>>>>         
>>>>> Hi Hadley,
>>>>>
>>>>> Hopefully, my dataset won't be too hard to changed. Can I modify the
>>>>> aspect of each group using your code (symbols for observed and lines for
>>>>> predicted)?
>>>>>
>>>>> Sebastien
>>>>>
>>>>> hadley wickham a ?crit :
>>>>>           
>>>>>> Hi Sebastian,
>>>>>>
>>>>>> I think you need to rearrange your data a bit.  Firstly, you need to
>>>>>> put observed on the same footing as the different models, so you would
>>>>>> have a new column in your data called value (previously observed and
>>>>>> predicted) and a new model type ("observed").  Then you could do:
>>>>>>             
>>>> Yes, and ?make.groups (and reshape of course) could help with that.
>>>> This might not be strictly necessary though.
>>>>
>>>> However, I'm finding your pseudo-code confusing. Could you create a
>>>> small example data set that can be used to try out some real code?
>>>> Just from your description, I would have suggested something like
>>>>
>>>> xyplot(Observed + Predicted ~ Time | Individuals + Model,
>>>>       data = mydata,
>>>>       panel = panel.superpose.2, type = c("p", "l"),
>>>>       layout = c(0, nlevels(mydata$Individuals)),
>>>>       <...>)
>>>>
>>>> If all you want is to plot one page at a time, there are easier ways
>>>> to do that.
>>>>
>>>> -Deepayan
>>>>
>>>>         
>>>>>> xyplot(value ~ time | individauls, data=mydata, group=model)
>>>>>>
>>>>>> Hadley
>>>>>>
>>>>>>
>>>>>> On 6/21/07, S?bastien <pomchip at free.fr> wrote:
>>>>>>             
>>>>>>> Dear R Users,
>>>>>>>
>>>>>>> I recently posted an email on this list  about the use of
>>>>>>>               
>>>>> data.frame and
>>>>>           
>>>>>>> overlaying multiple plots. Deepayan kindly indicated to me the
>>>>>>> panel.superposition command which worked perfectly in the context
>>>>>>>               
>>>>> of the
>>>>>           
>>>>>>> example I gave.
>>>>>>> I'd like to go a little bit further on this topic using a more
>>>>>>>               
>>>>> complex
>>>>>           
>>>>>>> dataset structure (actually the one I want to work on).
>>>>>>>
>>>>>>>  >mydata
>>>>>>>       Plot    Model    Individuals    Time        Observed
>>>>>>> Predicted
>>>>>>> 1    1        A           1                  0.05
>>>>>>> 10                    10.2
>>>>>>> 2    1        A           1                  0.10
>>>>>>> 20                    19.5
>>>>>>> etc...
>>>>>>> 10  1        B           1                  0.05         10
>>>>>>>          9.8
>>>>>>> 11  1        B           1                  0.10         20
>>>>>>>          20.2
>>>>>>> etc...
>>>>>>>
>>>>>>> There are p "levels" in mydata$Plot, m in mydata$Model, n in
>>>>>>> mydata$Individuals and t in mydata$Time (Note that I probably use the
>>>>>>> word levels improperly as all columns are not factors). Basically,
>>>>>>>               
>>>>> this
>>>>>           
>>>>>>> dataset summarizes the t measurements obtained in n individuals as
>>>>>>>               
>>>>> well
>>>>>           
>>>>>>> as the predicted values from m different modeling approaches
>>>>>>>               
>>>>> (applied to
>>>>>           
>>>>>>> all individuals). Therefore, the observations are repeated m times in
>>>>>>> the Observed columns, while the predictions appears only once for a
>>>>>>> given model an a given individual.
>>>>>>>
>>>>>>> What I want to write is a R batch file creating a Trellis graph,
>>>>>>>               
>>>>> where
>>>>>           
>>>>>>> each panel corresponds to one individual and contains the
>>>>>>>               
>>>>> observations
>>>>>           
>>>>>>> (as scatterplot) plus the predicted values for all models (as
>>>>>>>               
>>>>> lines of
>>>>>           
>>>>>>> different colors)... $Plot is just a token: it might be used to not
>>>>>>> overload graphs in case there are too many tested models. The fun
>>>>>>>               
>>>>> part
>>>>>           
>>>>>>> is that the values of p, m, n and t might vary from one dataset to
>>>>>>>               
>>>>> the
>>>>>           
>>>>>>> other, so everything has to be coded dynamically.
>>>>>>>
>>>>>>> For the plotting part I was thinking about having a loop in my code
>>>>>>> containing something like that:
>>>>>>>
>>>>>>> for (i in 1:nlevels(mydata$Model)) {
>>>>>>>
>>>>>>> subdata<-subset(mydata,mydata$Model=level(mydata$Model)[i])
>>>>>>> xyplot(subset(Observed + Predicted ~ Time | Individuals, data =
>>>>>>> subdata)       #plus additionnal formatting code
>>>>>>>
>>>>>>> }
>>>>>>>
>>>>>>> Unfortunately, this code simply creates a new Trellis plot instead of
>>>>>>> adding the model one by one on the panels. Any idea or link to a
>>>>>>>               
>>>>> useful
>>>>>           
>>>>>>> command will wellcome.
>>>>>>>
>>>>>>> Sebastien
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at stat.math.ethz.ch mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>
>>>>>>>               
>>>>>>             
>>>>> ______________________________________________
>>>>> R-help at stat.math.ethz.ch mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>>           
>>
>> ------------------------------
>>
>> Message: 38
>> Date: Fri, 22 Jun 2007 12:47:51 -0700
>> From: "Deepayan Sarkar" <deepayan.sarkar at gmail.com>
>> Subject: Re: [R] Overlaying lattice graphs (continued)
>> To: " S?bastien " <pomchip at free.fr>
>> Cc: R-help <r-help at stat.math.ethz.ch>
>> Message-ID:
>>        <eb555e660706221247v59cf4f4cpdaee99e0a1372c84 at mail.gmail.com>
>> Content-Type: text/plain; charset=UTF-8; format=flowed
>>
>> On 6/22/07, S?bastien <pomchip at free.fr> wrote:
>>     
>>> Hi Deepayan,
>>>
>>> The following code creates a dummy dataset which has the same similar as
>>> my usual datasets. I did not try to implement the changes proposed by
>>> Hadley, hoping that a solution can be found using the original dataset.
>>>
>>> ######### My code
>>>
>>> # Creating dataset
>>>
>>> nPts<-10            # number of time points
>>> nInd<-6              # number of individuals
>>> nModel<-3         # number of models
>>>
>>> TimePts<-rep(1:nPts,nInd*nModel)                                    #
>>> creates the "Time" column
>>> Coef<-rep(rnorm(6,0.1,0.01),each=nPts,nModel)             # Creates a
>>> vector of coefficients for generating the observations
>>> Obs<-10*exp(-Coef*TimePts)                                         #
>>> creates the observations
>>>
>>> for (i in 1:60){
>>> Pred[i]<-jitter(10*exp(-Coef[i]*TimePts[i]))
>>> Pred[i+60]<-jitter(5)
>>> Pred[i+120]<-jitter(10-Coef[i+120]*TimePts[i])
>>> }
>>>                   # creates the predicted values
>>>
>>> colPlot<-rep(1,nPts*nInd*nModel)
>>>     # creates the "Plot" column
>>> colModel<-gl(nModel,nPts*nInd,labels=c("A","B","C"))             #
>>> creates the "Model" column
>>> colID<-gl(nInd,nPts,nPts*nInd*nModel)
>>>       # creates the "ID" column
>>>
>>> mydata<-data.frame(colPlot,colModel,colID,TimePts,Obs,Pred)
>>>               # creates the dataset
>>> names(mydata)<-c("Plot","Model","Individuals","Time","Observed","Predicted")
>>>       
>> The way you have structured your data makes no sense to me. In
>> particular, your 'Observed' data is the same set of 60 numbers
>> repeated 3 times, and this is not reflected in the data structure at
>> all. What would you want to happen if the numbers were not repeated?
>> Would you always plot the first 60, or would plot all of them?
>>
>> If I understand what you are trying to do, this might be a more
>> transparent approach:
>>
>>
>> nPts<-10   # number of time points
>> nInd<-6    # number of individuals
>>
>> TimePts <- rep(1:nPts, nInd)
>> Coef <- rep(rnorm(6,0.1,0.01), each = nPts)
>> Obs <- 10 * exp(-Coef * TimePts)
>> colID <- gl(nInd, nPts)
>>
>> mydata <- data.frame(Time = TimePts, Observed = Obs, Individuals = colID)
>>
>> fmA <- lm(Observed ~ Time, mydata)
>> fmB <- lm(Observed ~ poly(Time, 2), mydata)
>> fmC <- lm(Observed ~ poly(Time, 2) * Individuals, mydata)
>>
>> mydata$PredA <- predict(fmA)
>> mydata$PredB <- predict(fmB)
>> mydata$PredC <- predict(fmC)
>>
>> xyplot(Observed + PredA + PredB + PredC ~ Time | Individuals,
>>       data = mydata,
>>       type = c("p", "l", "l", "l"),
>>       distribute.type = TRUE)
>>
>> -Deepayan
>>
>>
>>
>> ------------------------------
>>
>> Message: 39
>> Date: Fri, 22 Jun 2007 21:55:52 +0200
>> From: "hadley wickham" <h.wickham at gmail.com>
>> Subject: Re: [R] Stacked barchart color
>> To: owenman <solberg at speakeasy.net>
>> Cc: r-help at stat.math.ethz.ch
>> Message-ID:
>>        <f8e6ff050706221255j37e15382n4179d5b276486c0b at mail.gmail.com>
>> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>>
>> Hi Owen,
>>
>> The bars should be stacked in the order specified by the factor.  Try
>> using factor(..., levels=...) to explicitly order them the way you
>> want.  If that doesn't work, please provide a small replicable example
>> and I'll look into it.
>>
>> Hadley
>>
>> On 6/18/07, owenman <solberg at speakeasy.net> wrote:
>>     
>>> Hi Hadley,
>>> Great, I am starting to get it.  It's working for me, but there is one more
>>> thing I am having trouble with.  The ordering of the stacked bars seems to
>>> be dictated by the name of the color, I guess because of the fill=color
>>> argument in aes().  In other words, if I set up my colors like this:
>>> y$color = c("gray1","gray35","gray45","gray65")  the bars get stacked in the
>>> opposite order than if I set up the colors like this:  y$color =
>>> c("gray65","gray45","gray35","gray1").  How can I control the order of the
>>> bars independent of the name of the colors?   Thanks so much in advance!
>>> Really neat package you've made.
>>>
>>> FYI, my plot command now looks like this:
>>>
>>> p = ggplot(y, aes(x=locus, y=Freq, fill=color))
>>> p = p + geom_bar(position="fill")
>>> p = p + scale_fill_identity(labels=levels(y$Fnd), grob="tile", name="Fnd
>>> Results")
>>> p = p + coord_flip()
>>>
>>> And the data table is similar as before:
>>>
>>>       
>>>> y
>>>>         
>>>       Fnd locus        Freq  color
>>> 1  signeg  DPB1 0.013071895  gray1
>>> 2     neg  DPB1 0.581699346 gray35
>>> 3     pos  DPB1 0.379084967 gray45
>>> 4  sigpos  DPB1 0.026143791 gray65
>>> 5  signeg  DPA1 0.068181818  gray1
>>> 6     neg  DPA1 0.659090909 gray35
>>> 7     pos  DPA1 0.250000000 gray45
>>> 8  sigpos  DPA1 0.022727273 gray65
>>>
>>>
>>>
>>> hadley wrote:
>>>       
>>>> Hi Owen,
>>>>
>>>> The identity scale won't create a legend, unless you tell it what
>>>> labels it should use - there's an example at
>>>> http://had.co.nz/ggplot2/scale_identity.html.  Otherwise, if you have
>>>> a continuous scale and you want something that works in black and
>>>> white, p + scale_fill_gradient(low="white", high="black") might be
>>>> easier.
>>>>
>>>> Hadley
>>>>
>>>>
>>>>         
>>>>>> y$color = factor(y$Fnd)
>>>>>> y$color = c("black","darkgray","lightgray","white")
>>>>>> y
>>>>>>             
>>>>>       Fnd locus        Freq color
>>>>> 1  signeg     A 0.087248322     black
>>>>> 2     neg     A 0.711409396  darkgray
>>>>> 3     pos     A 0.201342282 lightgray
>>>>> 4  sigpos     A 0.000000000     white
>>>>> 5  signeg     C 0.320754717     black
>>>>> 6     neg     C 0.603773585  darkgray
>>>>> 7     pos     C 0.075471698 lightgray
>>>>> 8  sigpos     C 0.000000000     white
>>>>> 9  signeg     B 0.157534247     black
>>>>> 10    neg     B 0.732876712  darkgray
>>>>> 11    pos     B 0.109589041 lightgray
>>>>> 12 sigpos     B 0.000000000     white
>>>>>
>>>>>           
>>>>>> p = ggplot(y, aes(x=locus, y=Freq, fill=color)) +
>>>>>> geom_bar(position="fill") + scale_fill_identity()
>>>>>> p
>>>>>>             
>>>>>
>>>>>
>>>>> hadley wrote:
>>>>>           
>>>>>> Hi Dieter,
>>>>>>
>>>>>> You can do this with ggplot2 (http://had.co.nz/ggplot2) as follows:
>>>>>>
>>>>>> library(ggplot2)
>>>>>>
>>>>>> barley1 <- subset(barley, site=="Grand Rapids" & variety %in%
>>>>>> c("Velvet","Peatland"))
>>>>>> barley1[] <- lapply(barley1, "[", drop=TRUE)
>>>>>>
>>>>>> qplot(variety, yield, data=barley1, geom="bar", stat="identity",
>>>>>> fill=factor(year))
>>>>>>
>>>>>> barley1$fill <- c("red","green","blue","gray")
>>>>>> qplot(variety, yield, data=barley1, geom="bar", stat="identity",
>>>>>> fill=fill) + scale_fill_identity()
>>>>>>
>>>>>> See http://had.co.nz/ggplot2/scale_identity.html and
>>>>>> http://had.co.nz/ggplot2/position_stack.html for more details.
>>>>>>
>>>>>> Hadley
>>>>>>
>>>>>>
>>>>>>             
>>>>> --
>>>>> View this message in context:
>>>>> http://www.nabble.com/Stacked-barchart-color-tf3909162.html#a11149419
>>>>> Sent from the R help mailing list archive at Nabble.com.
>>>>>
>>>>>
>>>>> ______________________________________________
>>>>> R-help at stat.math.ethz.ch mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>>           
>>>> ______________________________________________
>>>> R-help at stat.math.ethz.ch mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>>         
>>> --
>>> View this message in context: http://www.nabble.com/Stacked-barchart-color-tf3909162.html#a11182581
>>>
>>> Sent from the R help mailing list archive at Nabble.com.
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>       
>>
>> ------------------------------
>>
>> Message: 40
>> Date: Fri, 22 Jun 2007 22:07:37 +0200
>> From: "hadley wickham" <h.wickham at gmail.com>
>> Subject: Re: [R] Visualize quartiles of plot line
>> To: "Arne Brutschy" <abr-r-project at xylon.de>
>> Cc: R-help at stat.math.ethz.ch
>> Message-ID:
>>        <f8e6ff050706221307s72ebc36v31537365bc7ff667 at mail.gmail.com>
>> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>>
>> On 6/17/07, Arne Brutschy <abr-r-project at xylon.de> wrote:
>>     
>>> Hi,
>>>
>>> thanks for your tips - all of them worked. After a bit of fiddling, I
>>> managed to get what I wanted.
>>>       
>> Glad to hear it.
>>
>>     
>>> hadley wickham wrote:
>>> h> You might want to read the introductory chapters in the ggplot book,
>>> h> available from http://had.co.nz/ggplot2, which will give you more of a
>>> h> background.  Please let me know places where you think the
>>> h> documentation is inconsistent so I can try and make them better.
>>> I already did. :) A general problem: the examples are nice and easy to
>>> get, but it's often hard to apply them to my own specific problem.
>>> It's more a problem of the general structure: what has to go where.
>>> Most of the methods are using qplot, but what do I have to do if I'm
>>> trying create a more complex plot. Hmm, it's hard to describe.
>>>
>>> Example: I know how I set the title when using qplot (qplot(....
>>> main="asdf"). Where do I have to put it when I'm using gplot? Stuff
>>> like this is unclear...
>>>       
>> p <- ggplot(...) + ...
>> p$title <- "Title goes here"
>>
>> It is currently hard to figure this out in the current documentation though.
>>
>>     
>>> A more general problem is, that the manual pages are very, eh,
>>> minimalistic documented. The overall reference page is good and nicely
>>> structured. But the big idea is sort of missing. All components are
>>> linked, but the basics like layout, ggplot, aes etc are harder to find
>>> - and their help pages are the shortest. Especially the small details
>>> are hard to figure out. Lists of attributes etc..
>>>       
>> Yes, that's definitely something I'm working on for the book.
>> Unfortunately, I don't have
>>  that much time and it is a lot of work.  Every comment helps though.
>>
>>     
>>> Hmm, I know this is not really helpful. I can't describe my problems
>>> properly, I guess. Perhaps the documentation simply has to improve
>>> based on users questions. :\
>>>
>>> How old is this package? I think it's really, really great, but are
>>> there many users? Is there an additional mailinglist or forum where I
>>> can get more information?
>>>       
>> It's pretty young still, although the precursor ggplot package has
>> been around for about a year.  I really have no idea how many users
>> there are.  For questions, either email me or R-help.
>>
>>     
>>> Some more questions:
>>>
>>> Why doesn't ggplot2 work with layout()? I'm using viewport now, which
>>> works fine for me, but there should be a note in the docs perhaps.
>>>       
>> Because it works with the grid drawing package - see the last chapter
>> in the ggplot book for some details on how to use the grid
>> equivalents.
>>
>>     
>>> How do I change the legend. The auto-creation of it might be nice,
>>> but I want a) to add a title b) change the order to ascending and c)
>>> add a short description like:
>>>
>>>   DeltaConfig
>>>   [ ] 0 best
>>>   [ ]
>>>   [ ] 5
>>>   [ ]
>>>   [ ]10 worst
>>>
>>> I don't know if this is possible, but it would be nice to explain what
>>> the colors/values might mean if it's not clear from the beginning
>>> (ligke diamonds.size). The only thing I found was the attribute
>>> legend.justifcation in ggopt, which isn't fully documented.
>>>       
>> The legends aren't very customisable at the moment - look at the
>> examples for the scale functions to see what you can do.  You can see
>> the name of the title easily, and you can change the labels by
>> changing the level of the factors, or setting the breaks argument.  I
>> agree there could be more options.  If you could provide me with a
>> picture of what you want, I'll add it to my to do list to think about.
>>
>>     
>>> Additionally, how can I change the order of the facets? I currently
>>> have a plot with a smoother for each model (all in the same plot),
>>> which sorts the models like this: dyn,dl4,dl3 Below that, I have a
>>> facet with point-plots for each model which sorts them the other way
>>> round, which is a bit confusing.
>>>       
>> Again, change the order of the underlying factor.
>>
>>     
>>> BTW, what's the "strip" and the associated attributes?
>>>       
>> The strip is the labelled associated with the facet.
>>
>>     
>>> Again, I think this package is great - nice work! All the above isn't
>>> meant as general critisism, but is being said in order to improve the
>>> documentation..
>>>       
>> I do appreciate your comments and they definitely help me to make a
>> better product.
>>
>> Thanks,
>>
>> Hadley
>>
>>
>>
>> ------------------------------
>>
>> Message: 41
>> Date: Fri, 22 Jun 2007 16:14:52 -0400
>> From: "Patrick Ayscue" <payscue at gmail.com>
>> Subject: [R] "heatmap" color still a spectrum for binary outcomes?
>> To: r-help at stat.math.ethz.ch
>> Message-ID:
>>        <ea3a49790706221314n270f8036i72fb4356c579303 at mail.gmail.com>
>> Content-Type: text/plain
>>
>> I have a matrix of a time series binary response variable for around 200
>> individuals I would like to display.  I am approaching success using the
>> "heatmap" function in the "stats" package without dendorgrams, however, am
>> running into trouble in that the colors get lighter with more positive
>> outcomes in a column (time point).  Is there a way to make the colors
>> uniform irrespective of the number of similar values in the column? or this
>> part of the heatmap function?
>>
>> Other suggestions for representing the data graphically are certainly
>> welcome as well.
>>
>> Thanks,
>> Patrick
>>
>>        [[alternative HTML version deleted]]
>>
>>
>>
>> ------------------------------
>>
>> Message: 42
>> Date: Fri, 22 Jun 2007 14:19:43 -0600
>> From: "Spilak,Jacqueline [Edm]" <Jacqueline.Spilak at EC.gc.ca>
>> Subject: [R] Barchart legend position
>> To: <r-help at stat.math.ethz.ch>
>> Message-ID:
>>        <4A6AB38B55B49C44A22E021A83CBEDDB015EB9A1 at sr-pnr-exch3.prairie.int.ec.gc.ca>
>>
>> Content-Type: text/plain
>>
>> I am using barchart to make charts for some data with a lot more
>> functions and labels and such in the command.
>>
>> barchart(Freq ~ factor(HH), data = dataset1, group= year)
>>
>> So I have my data grouped by year and I get a legend at the top of
>> graph, which is great cause I need the legend for the different years
>> but it is a weird spot.  So how can I manipulate the legend, ie. Move
>> it, shrink it, do anything with it. I have searched the help archives
>> and found nothing, and I have looked up the legend section in ?barchart
>> but that has not helped or I am doing something wrong.  Any help is
>> greatly appreciated.
>> Jacquie
>>
>>        [[alternative HTML version deleted]]
>>
>>
>>
>> ------------------------------
>>
>> Message: 43
>> Date: Fri, 22 Jun 2007 17:25:14 +0100
>> From: Michael Hoffman <b3i4old02 at sneakemail.com>
>> Subject: [R] Lattice: hiding only some strips
>> To: r-help at stat.math.ethz.ch
>> Message-ID: <f5gt5i$f6k$1 at sea.gmane.org>
>> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>>
>> I am using R 2.4.0 and lattice to produce some xyplots conditioned on a
>> factor and a shingle. The shingle merely chops up the data along the
>> x-axis, so it is easy to identify which part of the shingle a panel is
>> in by looking at the x-axis markings. I only want to have a strip at the
>> top for the factor.
>>
>> Is this possible? I looked into calculateGridLayout() and it seems to me
>> that there isn't an easy way to do it without rewriting that function
>> (and others).
>>
>> Many thanks
>> --
>> Michael Hoffman
>>
>>
>>
>> ------------------------------
>>
>> Message: 44
>> Date: Fri, 22 Jun 2007 16:42:13 -0400
>> From: S?bastien <pomchip at free.fr>
>> Subject: Re: [R] Overlaying lattice graphs (continued)
>> To: hadley wickham <h.wickham at gmail.com>
>> Cc: R-help <r-help at stat.math.ethz.ch>
>> Message-ID: <467C3425.1030000 at free.fr>
>> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>>
>> Hadley,
>>
>> I have some troubles to run your code with ggplot version 0.4.1. Is the
>> package ggplot2 mandatory ?
>>
>> Sebastien
>>
>> hadley wickham a ?crit :
>>     
>>> Hi Sebastian,
>>>
>>> I think the following does what you want:
>>>
>>> library(ggplot2)
>>> names(mydata) <- tolower(names(mydata))
>>>
>>> obs <- rename(subset(mydata, model=="A", -predicted), c("observed" =
>>> "value"))
>>> obs$model <- factor("observed")
>>> pred <- rename(mydata[, -5], c("predicted" = "value")...
>>>       
>> [Mensaje recortado]
>>     
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From justin_bem at yahoo.fr  Tue Jun 26 18:06:37 2007
From: justin_bem at yahoo.fr (justin bem)
Date: Tue, 26 Jun 2007 16:06:37 +0000 (GMT)
Subject: [R] Re :  R data set size limit
Message-ID: <120863.37193.qm@web23007.mail.ird.yahoo.com>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20070626/2764e52e/attachment.pl 

From Mike.Lawrence at dal.ca  Tue Jun 26 18:20:34 2007
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Tue, 26 Jun 2007 13:20:34 -0300
Subject: [R] surprising difference in log()
In-Reply-To: <46812350.8070408@stats.uwo.ca>
References: <279B77EF-70FD-4F2B-8BBD-9F15D37589ED@lu.unisi.ch>
	<0CD53661-C47F-49AC-A1E4-86357B1AACE0@DAL.CA>
	<46812350.8070408@stats.uwo.ca>
Message-ID: <3236709C-8F6B-4FDD-A82B-9926192FDDC4@dal.ca>

Sorry, my mistake. I should really leave looking at the help list  
until AFTER my morning coffee :P

On 26-Jun-07, at 11:31 AM, Duncan Murdoch wrote:

> On 6/26/2007 10:20 AM, Mike Lawrence wrote:
>> According to the description of floor(), the latter result is the
>> correct one:
>>
>> 'floor takes a single numeric argument x and returns a numeric vector
>> containing the largest integers *not greater than* the corresponding
>> elements of x.' (emphasis added)
>>
>> floor(3) == 2
>>> True
>
> 3 is not greater than 3, but it is greater than 2, so the result you
> quote above is wrong.  You should see
>
>> floor(3)
>   [1] 3
>
>> floor(3) == 2
> [1] FALSE
>
> Do you really see the result you posted?
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Mike Lawrence
Graduate Student, Department of Psychology, Dalhousie University

Website: http://memetic.ca

Public calendar: http://icalx.com/public/informavore/Public

"The road to wisdom? Well, it's plain and simple to express:
Err and err and err again, but less and less and less."
	- Piet Hein


From young.stat at gmail.com  Tue Jun 26 18:29:05 2007
From: young.stat at gmail.com (Young Cho)
Date: Tue, 26 Jun 2007 09:29:05 -0700
Subject: [R] ylab at the right hand of a plot with two y axes
Message-ID: <b44da9db0706260929x4b08f860t7074984351c3fd32@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070626/9d71df6f/attachment.pl 

From ripley at stats.ox.ac.uk  Tue Jun 26 18:50:26 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 26 Jun 2007 17:50:26 +0100 (BST)
Subject: [R] ts() defunct in R 2.5.0?
In-Reply-To: <43540b8d0706260749m774b8423g5845e3f357b113b5@mail.gmail.com>
References: <43540b8d0706260749m774b8423g5845e3f357b113b5@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0706261743300.18303@gannet.stats.ox.ac.uk>

ts() is in package stats, and has been for some years.
Package ts was removed at the same time.  The NEWS item say

     o   The autoloading of ts() is defunct.

which is very far from your misquote.

The problem is in the data directory of your package.  E.g., 
sowas/data/air.R has

air<-ts(data=x,start=t[1],frequency=12)

and you have not arranged for package 'stats' to be available.  You need 
stats::ts.

Please study 'Writing R Extensions' for the requirements on R code to be 
used by data().

On Tue, 26 Jun 2007, Douglas Maraun wrote:

> Hi!
>
> I have written an R-package
> (http://tocsy.agnld.uni-potsdam.de/wavelets/index.html) in R 2.4.1
> that requires the ts() function. Users using R 2.5.0 now have a
> problem installing this package. I checked the package using R 2.5.0:
> _______________________________________________________
>
> * Installing *source* package 'sowas' ...
> ** libs
> gcc -std=gnu99 -I/usr/users10/hrust/share/lib64/R/include
> -I/usr/users10/hrust/share/lib64/R/include  -I/usr/local/include
> -fpic  -g -O2 -c invmorlet.c -o invmorlet.o
> gcc -std=gnu99 -shared -L/usr/local/lib64 -o sowas.so invmorlet.o
> ** R
> ** data
> ** preparing package for lazy loading
> Loading required package: Rwave
>
> Attaching package: 'Rwave'
>
>
>       The following object(s) are masked from package:stats :
>
>        kernel
>
> ** help
> >>> Building/Updating help pages for package 'sowas'
>    Formats: text html latex example
> air                               text    html    latex
> createar                          text    html    latex   example
> createwgn                         text    html    latex   example
> criticalvaluesWCO                 text    html    latex   example
> criticalvaluesWSP                 text    html    latex   example
> cwt.ts                            text    html    latex   example
> nao                               text    html    latex
> nino3                             text    html    latex
> plot.wt                           text    html    latex   example
> plotwt                            text    html    latex   example
> readmatrix                        text    html    latex   example
> readts                            text    html    latex   example
> rk                                text    html    latex   example
> wco                               text    html    latex   example
> wcs                               text    html    latex   example
> writematrix                       text    html    latex   example
> wsp                               text    html    latex   example
> ** building package indices ...
> Read 3192 items
> Error in eval(expr, envir, enclos) : could not find function "ts"
> Execution halted
> ERROR: installing package indices failed
> ** Removing '/usr/users10/hrust/tmp/sowas.Rcheck/sowas'
> ____________________________________________________
>
> In the corresponding DESCRIPTION File, the depend line reads:
>
>     Depends: R,Rwave,stats
>
> I read in the 2.5.0 news, that ts has been defunct. So I added
>
>     Depends: R,Rwave,stats,ts
>
> Now I get the following error:
> _____________________________
>
> * checking for working latex ... OK
> * using log directory '/usr/users10/hrust/tmp/sowas.Rcheck'
> * using R version 2.5.0 (2007-04-23)
> * checking for file 'sowas/DESCRIPTION' ... OK
> * this is package 'sowas' version '0.93'
> * checking package dependencies ... ERROR
> Former standard packages required but now defunct:
> ts
>
> See the information on DESCRIPTION files in the chapter 'Creating R
> packages' of the 'Writing R Extensions' manual.
>
> _________________________
>
> Actually, I have read the "Writing R Extensions" about the DESCRIPTION
> file but could not find any helpful information. Has anybody got some
> idea?
>
> Cheers
> Douglas
> -----------------------------------------------------------------------
> Dr. Douglas Maraun
> Climatic Research Unit, University of East Anglia
> +44 1603 59 3857
> http://www.cru.uea.ac.uk/~douglas
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Tue Jun 26 18:53:28 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 26 Jun 2007 17:53:28 +0100 (BST)
Subject: [R] Memory Experimentation: Rule of Thumb = 10-15 Times the
 Memory
In-Reply-To: <50d1c22d0706260758q435b761fvad66a523cce2cf9d@mail.gmail.com>
References: <50d1c22d0706260758q435b761fvad66a523cce2cf9d@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0706261751190.18303@gannet.stats.ox.ac.uk>

The R Data Import/Export Manual points out several ways in which you can
use read.csv more efficiently.

On Tue, 26 Jun 2007, ivo welch wrote:

> dear R experts:
>
> I am of course no R experts, but use it regularly.  I thought I would
> share some experimentation  with memory use.  I run a linux machine
> with about 4GB of memory, and R 2.5.0.
>
> upon startup, gc() reports
>
>         used (Mb) gc trigger (Mb) max used (Mb)
> Ncells 268755 14.4     407500 21.8   350000 18.7
> Vcells 139137  1.1     786432  6.0   444750  3.4
>
> This is my baseline.  linux 'top' reports 48MB as baseline.  This
> includes some of my own routines that are always loaded.  Good..
>
>
> Next, I created a s.csv file with 22 variables and 500,000
> observations, taking up an uncompressed disk space of 115MB.  The
> resulting object.size() after a read.csv() is 84,002,712 bytes (80MB).
>
>> s= read.csv("s.csv");
>> object.size(s);
>
> [1] 84002712
>
>
> here is where things get more interesting.  after the read.csv() is
> finished, gc() reports
>
>           used (Mb) gc trigger  (Mb) max used  (Mb)
> Ncells   270505 14.5    8349948 446.0 11268682 601.9
> Vcells 10639515 81.2   34345544 262.1 42834692 326.9
>
> I was a big surprised by this---R had 928MB intermittent memory in
> use.  More interestingly, this is also similar to what linux 'top'
> reports as memory use of the R process (919MB, probably 1024 vs. 1000
> B/MB), even after the read.csv() is finished and gc() has been run.
> Nothing seems to have been released back to the OS.
>
> Now,
>
>> rm(s)
>> gc()
>         used (Mb) gc trigger  (Mb) max used  (Mb)
> Ncells 270541 14.5    6679958 356.8 11268755 601.9
> Vcells 139481  1.1   27476536 209.7 42807620 326.6
>
> linux 'top' now reports 650MB of memory use (though R itself uses only
> 15.6Mb).  My guess is that It leaves the trigger memory of 567MB plus
> the base 48MB.
>
>
> There are two interesting observations for me here:  first, to read a
> .csv file, I need to have at least 10-15 times as much memory as the
> file that I want to read---a lot more than the factor of 3-4 that I
> had expected.  The moral is that IF R can read a .csv file, one need
> not worry too much about running into memory constraints lateron.  {R
> Developers---reducing read.csv's memory requirement a little would be
> nice.  of course, you have more than enough on your plate, already.}
>
> Second, memory is not returned fully to the OS.  This is not
> necessarily a bad thing, but good to know.
>
> Hope this helps...
>
> Sincerely,
>
> /iaw
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rcreecy at census.gov  Tue Jun 26 19:00:45 2007
From: rcreecy at census.gov (Rob Creecy)
Date: Tue, 26 Jun 2007 13:00:45 -0400
Subject: [R] Creatiing an R package for solving nonlinear
 system	of	equations was: RE: finding roots of multivariate equation
In-Reply-To: <000001c7b416$d8d0c7f0$7c94100a@win.ad.jhu.edu>
References: <1182361042.467965d24abac@www.usherbrooke.ca>	<001501c7b381$2d5b4de0$7c94100a@win.ad.jhu.edu>
	<000001c7b416$d8d0c7f0$7c94100a@win.ad.jhu.edu>
Message-ID: <4681463D.50106@census.gov>

This seems useful, but it is important to note that the approach may not 
work well
unless the system of nonlinear equations is very well behaved and a good 
starting
point is chosen. A good explanation of the problems with this exact 
approach, that
is adding up the sums of squares of the individual functions,  is described
in Numerical Recipes for C, second edition, p 382 (see 
http://www.nrbook.com/a/bookcpdf.php)
Briefly there will often be a great number of local minima even when 
there is only a single
root of the original equations.

Rob





Ravi Varadhan wrote:
> Hi,
>
> I have written a simple function to solve a system of nonlinear equations. I
> have called it nlsolve().  It actually minimizes the squared-norm of the set
> of functions by calling optim().  It uses the BFGS algorithm within optim().
> Apart from this restriction, the user can pass all the arguments available
> in optim().  All the control parameters can be passed as in the call to
> optim().  I have attached a text file containing the source for nlsolve()
> and also a number of test problems illustrating the use of nlsolve().  Any
> feedback and suggestions to improve it are welcome.
>
> Hope this is useful.
>
> Best,
> Ravi.
>
> ----------------------------------------------------------------------------
> -------
>
> Ravi Varadhan, Ph.D.
>
> Assistant Professor, The Center on Aging and Health
>
> Division of Geriatric Medicine and Gerontology 
>
> Johns Hopkins University
>
> Ph: (410) 502-2619
>
> Fax: (410) 614-9625
>
> Email: rvaradhan at jhmi.edu
>
> Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html
>
>
>
> ----------------------------------------------------------------------------
> --------
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Ravi Varadhan
> Sent: Wednesday, June 20, 2007 5:23 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Creatiing an R package for solving nonlinear system of
> equations was: RE: finding roots of multivariate equation
>
> Hi All,
>
> Replying to this and numerous other requests in the past has made me realize
> that a nonlinear solver is very much needed for R users.  I have
> successfully used a nonlinear solver based on the spectral gradient method,
> in FORTRAN.  I can readily translate that to R and make it available as an R
> function, but what I would really like to do is to make that into a package.
> I can provide the R function and several test examples.  But I am not good
> at creating a good/reliable package.  So, it would be ideal if one of the R
> gurus is interested in collaborating with me on this project.  Any one
> interested?
>
> Ravi.
> ----------------------------------------------------------------------------
> -------
>
> Ravi Varadhan, Ph.D.
>
> Assistant Professor, The Center on Aging and Health
>
> Division of Geriatric Medicine and Gerontology 
>
> Johns Hopkins University
>
> Ph: (410) 502-2619
>
> Fax: (410) 614-9625
>
> Email: rvaradhan at jhmi.edu
>
> Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html
>
>
>
> ----------------------------------------------------------------------------
> --------
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Bill Shipley
> Sent: Wednesday, June 20, 2007 1:37 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] finding roots of multivariate equation
>
> Hello,
> I want to find the roots of an equation in two variables.  I am aware of the
> uniroot function, which can do this for a function with a single variable
> (as I
> understand it...) but cannot find a function that does this for an equation
> with more than one variable.  I am looking for something implementing
> similar
> to a Newton-Raphson algorithm.
> Thanks.
>
>   
> ------------------------------------------------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ripley at stats.ox.ac.uk  Tue Jun 26 19:01:53 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 26 Jun 2007 18:01:53 +0100 (BST)
Subject: [R] surprising difference in log()
In-Reply-To: <279B77EF-70FD-4F2B-8BBD-9F15D37589ED@lu.unisi.ch>
References: <279B77EF-70FD-4F2B-8BBD-9F15D37589ED@lu.unisi.ch>
Message-ID: <Pine.LNX.4.64.0706261756100.18303@gannet.stats.ox.ac.uk>

On Tue, 26 Jun 2007, Fausto Galli wrote:

>
> Hello everybody
>
> My collegue and I noticed a strange behaviour of R on different
> platforms. It's a simple computation, but results are rather different.
>
> On Windows XP:
>
> > floor(log(8,2))
> [1] 3
>
> which is what one should expect.
> Here's instead the result with Mac OS X (same version, 2.5.0
> (2007-04-23))
>
> > floor(log(8,2))
> [1] 2
>
> Is it a "bug" in R or in the operating system?
> Anyway, it's quite a surprising one.

It is a minor problem in the OS.  Given that log(8, 2) is a floating point 
calculation, it is unreasonable to expect it in general to be exact.  For 
those OSes that have log2, log2(8) is used and one might reasonably expect 
that to be exactly 3.  So either MacOS X is lacking log2 or its log2 is 
not exact.

Taking 'floor' of a floating-point computation without a fuzz is unwise.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mnair at iusb.edu  Tue Jun 26 19:14:05 2007
From: mnair at iusb.edu (Nair, Murlidharan T)
Date: Tue, 26 Jun 2007 13:14:05 -0400
Subject: [R] inter-rater agreement index kappa
Message-ID: <A32055BDEA88C34BB3DBBCD229380778012C8BF6@iu-mssg-mbx109.ads.iu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070626/3786926d/attachment.pl 

From rvaradhan at jhmi.edu  Tue Jun 26 19:17:14 2007
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Tue, 26 Jun 2007 13:17:14 -0400
Subject: [R] Creatiing an R package for solving nonlinear
	system	ofequations was: RE: finding roots of multivariate equation
In-Reply-To: <4681463D.50106@census.gov>
References: <1182361042.467965d24abac@www.usherbrooke.ca>
	<001501c7b381$2d5b4de0$7c94100a@win.ad.jhu.edu>
	<000001c7b416$d8d0c7f0$7c94100a@win.ad.jhu.edu>
	<4681463D.50106@census.gov>
Message-ID: <000001c7b815$d6f51b40$7c94100a@win.ad.jhu.edu>

Local minima, other than the actual roots, will be present only when the
Jacobian of the system is singular.  If the Jacobian is well-behaved then
there should be no problem, although this is hard to verify in practice.
Furthermore, as I had pointed out in one of my previous emails, if
convergence to a local optimum takes place, you simply restart the procedure
with another initial value.

Ravi.

----------------------------------------------------------------------------
-------

Ravi Varadhan, Ph.D.

Assistant Professor, The Center on Aging and Health

Division of Geriatric Medicine and Gerontology 

Johns Hopkins University

Ph: (410) 502-2619

Fax: (410) 614-9625

Email: rvaradhan at jhmi.edu

Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html

 

----------------------------------------------------------------------------
--------

-----Original Message-----
From: Rob Creecy [mailto:rcreecy at census.gov] 
Sent: Tuesday, June 26, 2007 1:01 PM
To: Ravi Varadhan
Cc: r-help at stat.math.ethz.ch; 'Bill Shipley'
Subject: Re: [R] Creatiing an R package for solving nonlinear system
ofequations was: RE: finding roots of multivariate equation

This seems useful, but it is important to note that the approach may not 
work well
unless the system of nonlinear equations is very well behaved and a good 
starting
point is chosen. A good explanation of the problems with this exact 
approach, that
is adding up the sums of squares of the individual functions,  is described
in Numerical Recipes for C, second edition, p 382 (see 
http://www.nrbook.com/a/bookcpdf.php)
Briefly there will often be a great number of local minima even when 
there is only a single
root of the original equations.

Rob





Ravi Varadhan wrote:
> Hi,
>
> I have written a simple function to solve a system of nonlinear equations.
I
> have called it nlsolve().  It actually minimizes the squared-norm of the
set
> of functions by calling optim().  It uses the BFGS algorithm within
optim().
> Apart from this restriction, the user can pass all the arguments available
> in optim().  All the control parameters can be passed as in the call to
> optim().  I have attached a text file containing the source for nlsolve()
> and also a number of test problems illustrating the use of nlsolve().  Any
> feedback and suggestions to improve it are welcome.
>
> Hope this is useful.
>
> Best,
> Ravi.
>
>
----------------------------------------------------------------------------
> -------
>
> Ravi Varadhan, Ph.D.
>
> Assistant Professor, The Center on Aging and Health
>
> Division of Geriatric Medicine and Gerontology 
>
> Johns Hopkins University
>
> Ph: (410) 502-2619
>
> Fax: (410) 614-9625
>
> Email: rvaradhan at jhmi.edu
>
> Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html
>
>
>
>
----------------------------------------------------------------------------
> --------
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Ravi Varadhan
> Sent: Wednesday, June 20, 2007 5:23 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Creatiing an R package for solving nonlinear system of
> equations was: RE: finding roots of multivariate equation
>
> Hi All,
>
> Replying to this and numerous other requests in the past has made me
realize
> that a nonlinear solver is very much needed for R users.  I have
> successfully used a nonlinear solver based on the spectral gradient
method,
> in FORTRAN.  I can readily translate that to R and make it available as an
R
> function, but what I would really like to do is to make that into a
package.
> I can provide the R function and several test examples.  But I am not good
> at creating a good/reliable package.  So, it would be ideal if one of the
R
> gurus is interested in collaborating with me on this project.  Any one
> interested?
>
> Ravi.
>
----------------------------------------------------------------------------
> -------
>
> Ravi Varadhan, Ph.D.
>
> Assistant Professor, The Center on Aging and Health
>
> Division of Geriatric Medicine and Gerontology 
>
> Johns Hopkins University
>
> Ph: (410) 502-2619
>
> Fax: (410) 614-9625
>
> Email: rvaradhan at jhmi.edu
>
> Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html
>
>
>
>
----------------------------------------------------------------------------
> --------
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Bill Shipley
> Sent: Wednesday, June 20, 2007 1:37 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] finding roots of multivariate equation
>
> Hello,
> I want to find the roots of an equation in two variables.  I am aware of
the
> uniroot function, which can do this for a function with a single variable
> (as I
> understand it...) but cannot find a function that does this for an
equation
> with more than one variable.  I am looking for something implementing
> similar
> to a Newton-Raphson algorithm.
> Thanks.
>
>   
> ------------------------------------------------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Mike.Lawrence at DAL.CA  Tue Jun 26 19:36:19 2007
From: Mike.Lawrence at DAL.CA (Mike Lawrence)
Date: Tue, 26 Jun 2007 14:36:19 -0300
Subject: [R] Power calculation with measurement error
In-Reply-To: <DB174F65-4084-46B6-AD09-D575340E6825@DAL.CA>
References: <DB174F65-4084-46B6-AD09-D575340E6825@DAL.CA>
Message-ID: <90414ABE-A8E6-4C42-BF31-CBACF7C04179@DAL.CA>

On 26-Jun-07, at 8:12 AM, Mike Lawrence wrote:
> Hi all,
> Hopefully this will be quick, I'm looking for pointers to packages/
> functions that would allow me to calculate the power of a t.test when
> the DV has measurement error. That is, I understand that, ceteris
> paribus, experiments using measure with more error (lower
> reliability) will have lower power.

I came across a reference (http://memetic.ca/reliability.pdf) that  
provides a formula for calculating the noncentrality parameter for  
tests using imperfect measures (see Eq. 4), as well as a table of  
some resulting power estimates. However, while I have created a (very  
slow) monte carlo function that so far as I can tell matches their  
results, when I attempt to implement their analytic solution it's way  
off. Can anyone see what I'm doing incorrectly?

n=100
r=.5 #reliability
e=.5 #effect size
delta=(sqrt(r*n)/2)*e
power.t.test(n,delta,sig.level=.05,alternative='one.sided')

      Two-sample t test power calculation

               n = 100
           delta = 1.767767
              sd = 1
       sig.level = 0.05
           power = 1
     alternative = one.sided

NOTE: n is number in *each* group


Meanwhile, their tables and my monte carlo method say that the power  
in that circumstance should be .7

Help?

Mike


From minyu.chen at ucl.ac.uk  Tue Jun 26 20:03:29 2007
From: minyu.chen at ucl.ac.uk (Minyu Chen)
Date: Tue, 26 Jun 2007 19:03:29 +0100
Subject: [R] Marginal Effects of continuous variable in lrm model (Design
	package)
Message-ID: <CCE6D852-EA42-4A1A-BB3D-50EF5DC99792@ucl.ac.uk>

Dear all:

When I am trying to get the marginal effects:

summary(result7,adv_inc_ratio=mean(m9201 
$adv_inc_ratio),adv_price_ratio=mean(m9201$adv_price_ratio), ...(SOME  
MORE CONTINUOUS AND DISCRETE VARIABLES BUT I AM NOT LISTING)... regW=c 
(0,mean(m9201$regW),1), regWM=c(0,mean(m9201$regWM),1))

It gave out an error message:

Error in summary.Design(result7, adv_inc_ratio = mean(m9201 
$adv_inc_ratio),  :
	ranges not defined here or with datadist for adv_inc_ratio  
adv_price_ratio agem1 change2 yr1Libor yr1Libor1mtLag yr1Libor1yrLag  
change21yrLag change21mtLag fwdReal4yr fwdInfl4yr

But I remember from my previous operation a few months ago (I  
recorded the commands) that to summary the marginal effect, I don't  
have to specify the ranges for the discrete variables. However, I use  
the command again (with slight modification because of the newly  
added variables) it doesn't work. I don't know what went wrong.

Thank you very much.

Thanks,
Minyu Chen


From christophe at pallier.org  Tue Jun 26 20:04:18 2007
From: christophe at pallier.org (Christophe Pallier)
Date: Tue, 26 Jun 2007 20:04:18 +0200
Subject: [R] inter-rater agreement index kappa
In-Reply-To: <A32055BDEA88C34BB3DBBCD229380778012C8BF6@iu-mssg-mbx109.ads.iu.edu>
References: <A32055BDEA88C34BB3DBBCD229380778012C8BF6@iu-mssg-mbx109.ads.iu.edu>
Message-ID: <dea6cb960706261104y2be09653h8d910402747e3518@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070626/6ada72f6/attachment.pl 

From antonio.raju at gmail.com  Tue Jun 26 20:10:15 2007
From: antonio.raju at gmail.com (antonio rodriguez)
Date: Tue, 26 Jun 2007 20:10:15 +0200
Subject: [R] aggregating daily values
Message-ID: <46815687.2050603@gmail.com>

Hi,

I swear I have read almost all the posted messages about this issue, but 
it's evident I couldn't find an answer (surely esay) to my problem. What 
I want is the following:

Make  8 days aggregates from a daily series like this (dput output):

structure(c(6.91777181625366, 0.79051125049591, 9.00625133514404,
9.86966037750244, 14.4326181411743, 3.70155477523804, 9.67768573760986,
2.73402595520020, 2.43723011016846, 7.56268262863159, 6.3102331161499,
3.32162165641785, 9.16097259521484, 11.8666706085205, 12.2684621810913,
1.22998368740082, 13.7295694351196, 4.0566086769104, 8.93555355072021,
9.23514747619629, 14.38671875, 5.57814884185791, 5.67644691467285,
6.57168674468994, 3.1399450302124, 5.92884302139282, 2.9151554107666,
4.03280115127563, 6.27835083007812, 7.44268560409546, 5.48082637786865,
4.53351545333862, 1.73732578754425, 7.26089143753052, 10.5942621231079,
5.05707550048828, 5.22532558441162, 11.5783672332764, 11.3684358596802,
13.6496038436890, 9.5115213394165, 10.9072093963623, 7.86801719665527,
3.94157719612122, 7.77205228805542, 6.6718077659607, 6.39164304733276,
10.4837465286255, 2.79525756835938, 1.37960362434387, 6.3647027015686,
5.929940700531, 6.9293303489685, 6.74053525924683, 1.43103110790253,
2.05663347244263, 4.89251279830933, 3.92522406578064, 3.35525012016296,
9.12392044067383, 6.75488662719727, 6.25883436203003, 9.25640106201172,
8.42288589477539, 6.56508350372314, 8.37779998779297, 7.43927431106567,
10.185378074646, 9.71145248413086, 11.2066516876221, 8.71727466583252,
10.9019384384155, 13.1304092407227, 7.75358772277832, 8.39074516296387,
8.14743328094482, 7.23138332366943, 6.52082204818726, 6.90353965759277,
7.9786148071289, 2.74402141571045, 4.47335290908813, 2.75821256637573,
3.28433847427368, 1.42357420921326, 2.82095956802368, 8.0270709991455,
7.674973487854, 1.69974088668823, 3.49610543251038, 3.31802821159363,
3.33476138114929, 2.11547899246216, 8.19122409820557, 7.00930881500244,
6.9021201133728, 6.11513996124268, 9.37069034576416, 6.9347562789917,
8.47163581848145, 4.94003391265869, 0.301414221525192, 6.72133445739746,
8.76676940917969, 10.1682291030884, 3.84668922424316, 7.34706497192383,
4.56853246688843, 5.16461706161499, 6.48476696014404, 6.15084409713745,
1.76933193206787, 0.528673768043518, 8.61115646362305, 8.5723466873169,
5.61508989334106, 11.1853742599487, 5.04610252380371, 8.89399719238281,
10.4688892364502, 10.7483530044556, 5.63076829910278, 9.50668048858643,
5.47441911697388, 7.957528591156, 5.91077470779419, 2.91312527656555,
2.01168727874756, 2.74394679069519, 4.75178813934326, 4.93987512588501,
4.72155714035034, 3.37835741043091, 5.13053703308105, 9.08048439025879,
6.29858446121216, 5.58306503295898, 10.1094760894775, 12.978609085083,
12.8985652923584, 7.7596869468689, 12.7903356552124, 9.8348035812378,
5.68637895584106, 9.27114486694336, 8.27180290222168, 5.16222524642944,
6.46222257614136, 2.07000184059143, 3.08321070671082, 9.0461711883545,
6.15753412246704, 6.63184833526611, 8.59984111785889, 7.33605718612671,
3.02012157440186, 6.448965549469, 6.02573490142822, 7.87792730331421,
7.04826784133911, 1.02431178092957, 5.20297384262085, 6.64636945724487,
5.81104230880737, 4.90106821060181, 5.69662380218506, 7.51573324203491,
8.18294525146484, 6.11269092559814, 6.69754600524902, 5.6054277420044,
7.9188904762268, 5.51347351074219, 7.38122415542603, 6.92169857025146,
8.63118839263916, 6.9159483909607, 10.3055601119995, 6.9257755279541,
9.1276683807373, 5.51169300079346, 3.67073273658752, 2.84354925155640,
3.44134783744812, 2.87936210632324, 2.50833535194397, 6.63961029052734,
7.31760835647583, 5.54377555847168, 5.46550559997559, 3.04732036590576,
5.53518009185791, 4.90971279144287, 10.0030765533447, 10.7470664978027,
8.122633934021, 9.30413436889648, 11.5687465667725, 7.63134002685547,
7.48177337646484), .Dim = as.integer(c(100, 2)), index = structure(c(5480,
5481, 5482, 5483, 5484, 5485, 5486, 5487, 5488, 5489, 5490, 5491,
5492, 5493, 5494, 5495, 5496, 5497, 5498, 5499, 5500, 5501, 5502,
5503, 5504, 5505, 5506, 5507, 5508, 5509, 5510, 5511, 5512, 5513,
5514, 5515, 5516, 5517, 5518, 5519, 5520, 5521, 5522, 5523, 5524,
5525, 5526, 5527, 5528, 5529, 5530, 5531, 5532, 5533, 5534, 5535,
5536, 5537, 5538, 5539, 5540, 5541, 5542, 5543, 5544, 5545, 5546,
5547, 5548, 5549, 5550, 5551, 5552, 5553, 5554, 5555, 5556, 5557,
5558, 5559, 5560, 5561, 5562, 5563, 5564, 5565, 5566, 5567, 5568,
5569, 5570, 5571, 5572, 5573, 5574, 5575, 5576, 5577, 5578, 5579
), class = "Date"), class = "zoo")

TIA

Antonio


-- 
=====
Por favor, si me mandas correos con copia a varias personas, 
pon mi direcci?n de correo en copia oculta (CCO), para evitar 
que acabe en montones de sitios, eliminando mi privacidad, 
favoreciendo la propagaci?n de virus y la proliferaci?n del SPAM. Gracias.
-----
If you send me e-mail which has also been sent to several other people,
kindly mark my address as blind-carbon-copy (or BCC), to avoid its
distribution, which affects my privacy, increases the likelihood of
spreading viruses, and leads to more SPAM. Thanks.
=====
Antes de imprimir este e-mail piense bien si es necesario hacerlo: El medioambiente es cosa de todos.
Before printing this email, assess if it is really needed.


From dylan.beaudette at gmail.com  Tue Jun 26 20:13:15 2007
From: dylan.beaudette at gmail.com (Dylan Beaudette)
Date: Tue, 26 Jun 2007 11:13:15 -0700
Subject: [R] inter-rater agreement index kappa
In-Reply-To: <A32055BDEA88C34BB3DBBCD229380778012C8BF6@iu-mssg-mbx109.ads.iu.edu>
References: <A32055BDEA88C34BB3DBBCD229380778012C8BF6@iu-mssg-mbx109.ads.iu.edu>
Message-ID: <200706261113.15864.dylan.beaudette@gmail.com>

On Tuesday 26 June 2007 10:14, Nair, Murlidharan T wrote:
> Is there a function that calculates the inter-rater agreement index
> (kappa) in R?
>
> Thanks ../Murli

I have found a couple useful approaches:

# PCC, kappa, rand index
require(e1701)
classAgreement(2x2.table)

# kendall's tau
cor(x,y, method='kendall')

cheers,

-- 
Dylan Beaudette
Soils and Biogeochemistry Graduate Group
University of California at Davis
530.754.7341


From bjorn.vancampenhout at ua.ac.be  Tue Jun 26 20:13:14 2007
From: bjorn.vancampenhout at ua.ac.be (Van Campenhout Bjorn)
Date: Tue, 26 Jun 2007 20:13:14 +0200
Subject: [R] create matrix from comparing two vectors
Message-ID: <0EE866100C01984EAE6AC3AE56EDFE5355A728@xmail05.ad.ua.ac.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070626/ffdaafea/attachment.pl 

From bcarvalh at jhsph.edu  Tue Jun 26 20:33:27 2007
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Tue, 26 Jun 2007 14:33:27 -0400
Subject: [R] create matrix from comparing two vectors
In-Reply-To: <0EE866100C01984EAE6AC3AE56EDFE5355A728@xmail05.ad.ua.ac.be>
References: <0EE866100C01984EAE6AC3AE56EDFE5355A728@xmail05.ad.ua.ac.be>
Message-ID: <C38169CB-5397-4802-8D1A-809F2BC53B1D@jhsph.edu>

outer(test, fac, "<")

-b

On Jun 26, 2007, at 2:13 PM, Van Campenhout Bjorn wrote:

> hi all, sorry for this basic question, I think I know I should use ? 
> apply, but it is really confusing me...
>
> I want to create a matrix by comparing two vectors.  Eg:
>
> test<-seq(1:10)
> fac<-c(3,6,9)
>
> and i want to end up with a 10*3 matrix with a boolean that tests  
> if test<fac, so something like:
>
> 1 1 1
> 1 1 1
> 0 1 1
> 0 1 1
> 0 1 1
> 0 0 1
> 0 0 1
> 0 0 1
> 0 0 0
> 0 0 0
>
> I can't find the solution without using a loop...
>
> B
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From f.harrell at vanderbilt.edu  Tue Jun 26 20:29:22 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Tue, 26 Jun 2007 13:29:22 -0500
Subject: [R] Marginal Effects of continuous variable in lrm model
 (Design package)
In-Reply-To: <CCE6D852-EA42-4A1A-BB3D-50EF5DC99792@ucl.ac.uk>
References: <CCE6D852-EA42-4A1A-BB3D-50EF5DC99792@ucl.ac.uk>
Message-ID: <46815B02.2010603@vanderbilt.edu>

Minyu Chen wrote:
> Dear all:
> 
> When I am trying to get the marginal effects:
> 
> summary(result7,adv_inc_ratio=mean(m9201 
> $adv_inc_ratio),adv_price_ratio=mean(m9201$adv_price_ratio), ...(SOME  
> MORE CONTINUOUS AND DISCRETE VARIABLES BUT I AM NOT LISTING)... regW=c 
> (0,mean(m9201$regW),1), regWM=c(0,mean(m9201$regWM),1))
> 
> It gave out an error message:
> 
> Error in summary.Design(result7, adv_inc_ratio = mean(m9201 
> $adv_inc_ratio),  :
> 	ranges not defined here or with datadist for adv_inc_ratio  
> adv_price_ratio agem1 change2 yr1Libor yr1Libor1mtLag yr1Libor1yrLag  
> change21yrLag change21mtLag fwdReal4yr fwdInfl4yr
> 
> But I remember from my previous operation a few months ago (I  
> recorded the commands) that to summary the marginal effect, I don't  
> have to specify the ranges for the discrete variables. However, I use  
> the command again (with slight modification because of the newly  
> added variables) it doesn't work. I don't know what went wrong.
> 
> Thank you very much.
> 
> Thanks,
> Minyu Chen

Please read the package's help files especially about the datadist function.

Frank


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From Mike.Lawrence at DAL.CA  Tue Jun 26 20:38:45 2007
From: Mike.Lawrence at DAL.CA (Mike Lawrence)
Date: Tue, 26 Jun 2007 15:38:45 -0300
Subject: [R] Power calculation with measurement error
In-Reply-To: <90414ABE-A8E6-4C42-BF31-CBACF7C04179@DAL.CA>
References: <DB174F65-4084-46B6-AD09-D575340E6825@DAL.CA>
	<90414ABE-A8E6-4C42-BF31-CBACF7C04179@DAL.CA>
Message-ID: <B018FB44-77FD-42B9-A2A2-2AD0109E929D@DAL.CA>


On 26-Jun-07, at 2:36 PM, Mike Lawrence wrote:
> On 26-Jun-07, at 8:12 AM, Mike Lawrence wrote:
>> Hi all,
>> Hopefully this will be quick, I'm looking for pointers to packages/
>> functions that would allow me to calculate the power of a t.test when
>> the DV has measurement error. That is, I understand that, ceteris
>> paribus, experiments using measure with more error (lower
>> reliability) will have lower power.
>
> I came across a reference (http://memetic.ca/reliability.pdf) that
> provides a formula for calculating the noncentrality parameter for
> tests using imperfect measures (see Eq. 4), as well as a table of
> some resulting power estimates. However, while I have created a (very
> slow) monte carlo function that so far as I can tell matches their
> results, when I attempt to implement their analytic solution it's way
> off. Can anyone see what I'm doing incorrectly?
>
> n=100
> r=.5 #reliability
> e=.5 #effect size
> delta=(sqrt(r*n)/2)*e
> power.t.test(n,delta,sig.level=.05,alternative='one.sided')
>
>       Two-sample t test power calculation
>
>                n = 100
>            delta = 1.767767
>               sd = 1
>        sig.level = 0.05
>            power = 1
>      alternative = one.sided
>
> NOTE: n is number in *each* group
>
>
> Meanwhile, their tables and my monte carlo method say that the power
> in that circumstance should be .7


Found it; I was using power.t.test without being thorough in reading  
its details. Sorry for the spam, and for anyone that's interested,  
here's the final analytic solution:

#get power for a t.test, incorporating measurement error.
#n = total number of participants across your 2 groups
#r = estimated reliability of the measure used
#e = measured effect size
get.power=function(n,r,e,tails=2,alpha=.05){
	d=(sqrt(r*n)/2)*e
	a=1-ifelse(tails==2,alpha/2,alpha)
	p=1-pt(qt(a,n-2),n-2,d)
	return(p)
}


From Karthik.Devarajan at fccc.edu  Tue Jun 26 20:38:52 2007
From: Karthik.Devarajan at fccc.edu (Devarajan, Karthik)
Date: Tue, 26 Jun 2007 14:38:52 -0400
Subject: [R] survreg error
Message-ID: <D45546375992BF429A93F7203358F14405DE82CD@sirius.fccc.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070626/dddb8735/attachment.pl 

From Achim.Zeileis at wu-wien.ac.at  Tue Jun 26 20:42:16 2007
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Tue, 26 Jun 2007 20:42:16 +0200 (CEST)
Subject: [R] aggregating daily values
In-Reply-To: <46815687.2050603@gmail.com>
Message-ID: <Pine.LNX.4.44.0706262035521.25241-100000@disco.wu-wien.ac.at>

On Tue, 26 Jun 2007, antonio rodriguez wrote:

> Hi,
>
> I swear I have read almost all the posted messages about this issue, but
> it's evident I couldn't find an answer (surely esay) to my problem. What
> I want is the following:
>
> Make  8 days aggregates from a daily series like this (dput output):

I'm not sure which days you want to aggregate exactly. If you want to
replace the observations from 1985-01-02 until 1985-01-09 by a single
observation, maybe you want something like
  new.time <- as.Date(8 * floor(as.numeric(time(z))/8) + 7)
  z2 <- aggregate(z, new.time, mean)
which gives averages for 8 days (anchored on the last day of the 8-day
period).

Does this what you're looking for? Look at the "zoo" vignettes for more
information/examples.
Z


From Dimitris.Rizopoulos at med.kuleuven.be  Tue Jun 26 20:48:40 2007
From: Dimitris.Rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Tue, 26 Jun 2007 20:48:40 +0200
Subject: [R] create matrix from comparing two vectors
In-Reply-To: <0EE866100C01984EAE6AC3AE56EDFE5355A728@xmail05.ad.ua.ac.be>
References: <0EE866100C01984EAE6AC3AE56EDFE5355A728@xmail05.ad.ua.ac.be>
Message-ID: <20070626204840.nu35qzrf0o3s4cwk@webmail4.kuleuven.be>

try this:

test <- 1:10
fac <- c(3, 6, 9)

outer(test, fac, "<") * 1


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://med.kuleuven.be/biostat/
      http://www.student.kuleuven.be/~m0390867/dimitris.htm


Quoting Van Campenhout Bjorn <bjorn.vancampenhout at ua.ac.be>:

> hi all, sorry for this basic question, I think I know I should use   
> ?apply, but it is really confusing me...
>
> I want to create a matrix by comparing two vectors.  Eg:
>
> test<-seq(1:10)
> fac<-c(3,6,9)
>
> and i want to end up with a 10*3 matrix with a boolean that tests if  
>  test<fac, so something like:
>
> 1 1 1
> 1 1 1
> 0 1 1
> 0 1 1
> 0 1 1
> 0 0 1
> 0 0 1
> 0 0 1
> 0 0 0
> 0 0 0
>
> I can't find the solution without using a loop...
>
> B
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>



Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm


From antonio.raju at gmail.com  Tue Jun 26 20:57:37 2007
From: antonio.raju at gmail.com (antonio rodriguez)
Date: Tue, 26 Jun 2007 20:57:37 +0200
Subject: [R] aggregating daily values
In-Reply-To: <Pine.LNX.4.44.0706262035521.25241-100000@disco.wu-wien.ac.at>
References: <Pine.LNX.4.44.0706262035521.25241-100000@disco.wu-wien.ac.at>
Message-ID: <468161A1.1070103@gmail.com>

Achim Zeileis escribi?:
> On Tue, 26 Jun 2007, antonio rodriguez wrote:
>
>   
>> Hi,
>>
>> I swear I have read almost all the posted messages about this issue, but
>> it's evident I couldn't find an answer (surely esay) to my problem. What
>> I want is the following:
>>
>> Make  8 days aggregates from a daily series like this (dput output):
>>     
>
> I'm not sure which days you want to aggregate exactly. If you want to
> replace the observations from 1985-01-02 until 1985-01-09 by a single
> observation, maybe you want something like
>   new.time <- as.Date(8 * floor(as.numeric(time(z))/8) + 7)
>   z2 <- aggregate(z, new.time, mean)
> which gives averages for 8 days (anchored on the last day of the 8-day
> period).
>
> Does this what you're looking for? Look at the "zoo" vignettes for more
> information/examples.
> Z
>
>
>
>   
It's a very good solution. And... if I want that the anchor is placed in 
the middle of the 8 days period?

Thanks,

Antonio

-- 
=====
Por favor, si me mandas correos con copia a varias personas, 
pon mi direcci?n de correo en copia oculta (CCO), para evitar 
que acabe en montones de sitios, eliminando mi privacidad, 
favoreciendo la propagaci?n de virus y la proliferaci?n del SPAM. Gracias.
-----
If you send me e-mail which has also been sent to several other people,
kindly mark my address as blind-carbon-copy (or BCC), to avoid its
distribution, which affects my privacy, increases the likelihood of
spreading viruses, and leads to more SPAM. Thanks.
=====
Antes de imprimir este e-mail piense bien si es necesario hacerlo: El medioambiente es cosa de todos.
Before printing this email, assess if it is really needed.


From wssecn at uol.com.br  Tue Jun 26 20:58:42 2007
From: wssecn at uol.com.br (wssecn)
Date: Tue, 26 Jun 2007 15:58:42 -0300
Subject: [R] inter-rater agreement index kappa
Message-ID: <JK9BDU$29DF481CE9E9D41D0F4FCAC6C892CF36@uol.com.br>

See packages concord and psy,

hope this helps,

Washington S. Silva

> On Tuesday 26 June 2007 10:14, Nair, Murlidharan T wrote:
> > Is there a function that calculates the inter-rater agreement index
> > (kappa) in R?
> >
> > Thanks ../Murli
> 
> I have found a couple useful approaches:
> 
> # PCC, kappa, rand index
> require(e1701)
> classAgreement(2x2.table)
> 
> # kendall's tau
> cor(x,y, method='kendall')
> 
> cheers,
> 
> -- 
> Dylan Beaudette
> Soils and Biogeochemistry Graduate Group
> University of California at Davis
> 530.754.7341
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From gavin.simpson at ucl.ac.uk  Tue Jun 26 21:02:20 2007
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Tue, 26 Jun 2007 20:02:20 +0100
Subject: [R] aggregating daily values
In-Reply-To: <46815687.2050603@gmail.com>
References: <46815687.2050603@gmail.com>
Message-ID: <1182884540.3047.10.camel@dhcppc2.my.nat.localnet>

On Tue, 2007-06-26 at 20:10 +0200, antonio rodriguez wrote:
> Hi,
> 
> I swear I have read almost all the posted messages about this issue, but 
> it's evident I couldn't find an answer (surely esay) to my problem. What 
> I want is the following:
> 
> Make  8 days aggregates from a daily series like this (dput output):

Is this what you want:

## nb: dat is your object
## this is the number of 8-day chunks we need to create
n.8day.chunks <- ceiling(nrow(dat)/8)
## this is a factor indicating which days need to aggregated
day8 <- as.factor(rep(1:n.8day.chunks, each = 8, length.out =
nrow(dat)))
## the mean of consecutive 8-day chunks of your data
aggregate(dat, day8, mean)

G

> 
> structure(c(6.91777181625366, 0.79051125049591, 9.00625133514404,
> 9.86966037750244, 14.4326181411743, 3.70155477523804, 9.67768573760986,
> 2.73402595520020, 2.43723011016846, 7.56268262863159, 6.3102331161499,
> 3.32162165641785, 9.16097259521484, 11.8666706085205, 12.2684621810913,
> 1.22998368740082, 13.7295694351196, 4.0566086769104, 8.93555355072021,
> 9.23514747619629, 14.38671875, 5.57814884185791, 5.67644691467285,
> 6.57168674468994, 3.1399450302124, 5.92884302139282, 2.9151554107666,
> 4.03280115127563, 6.27835083007812, 7.44268560409546, 5.48082637786865,
> 4.53351545333862, 1.73732578754425, 7.26089143753052, 10.5942621231079,
> 5.05707550048828, 5.22532558441162, 11.5783672332764, 11.3684358596802,
> 13.6496038436890, 9.5115213394165, 10.9072093963623, 7.86801719665527,
> 3.94157719612122, 7.77205228805542, 6.6718077659607, 6.39164304733276,
> 10.4837465286255, 2.79525756835938, 1.37960362434387, 6.3647027015686,
> 5.929940700531, 6.9293303489685, 6.74053525924683, 1.43103110790253,
> 2.05663347244263, 4.89251279830933, 3.92522406578064, 3.35525012016296,
> 9.12392044067383, 6.75488662719727, 6.25883436203003, 9.25640106201172,
> 8.42288589477539, 6.56508350372314, 8.37779998779297, 7.43927431106567,
> 10.185378074646, 9.71145248413086, 11.2066516876221, 8.71727466583252,
> 10.9019384384155, 13.1304092407227, 7.75358772277832, 8.39074516296387,
> 8.14743328094482, 7.23138332366943, 6.52082204818726, 6.90353965759277,
> 7.9786148071289, 2.74402141571045, 4.47335290908813, 2.75821256637573,
> 3.28433847427368, 1.42357420921326, 2.82095956802368, 8.0270709991455,
> 7.674973487854, 1.69974088668823, 3.49610543251038, 3.31802821159363,
> 3.33476138114929, 2.11547899246216, 8.19122409820557, 7.00930881500244,
> 6.9021201133728, 6.11513996124268, 9.37069034576416, 6.9347562789917,
> 8.47163581848145, 4.94003391265869, 0.301414221525192, 6.72133445739746,
> 8.76676940917969, 10.1682291030884, 3.84668922424316, 7.34706497192383,
> 4.56853246688843, 5.16461706161499, 6.48476696014404, 6.15084409713745,
> 1.76933193206787, 0.528673768043518, 8.61115646362305, 8.5723466873169,
> 5.61508989334106, 11.1853742599487, 5.04610252380371, 8.89399719238281,
> 10.4688892364502, 10.7483530044556, 5.63076829910278, 9.50668048858643,
> 5.47441911697388, 7.957528591156, 5.91077470779419, 2.91312527656555,
> 2.01168727874756, 2.74394679069519, 4.75178813934326, 4.93987512588501,
> 4.72155714035034, 3.37835741043091, 5.13053703308105, 9.08048439025879,
> 6.29858446121216, 5.58306503295898, 10.1094760894775, 12.978609085083,
> 12.8985652923584, 7.7596869468689, 12.7903356552124, 9.8348035812378,
> 5.68637895584106, 9.27114486694336, 8.27180290222168, 5.16222524642944,
> 6.46222257614136, 2.07000184059143, 3.08321070671082, 9.0461711883545,
> 6.15753412246704, 6.63184833526611, 8.59984111785889, 7.33605718612671,
> 3.02012157440186, 6.448965549469, 6.02573490142822, 7.87792730331421,
> 7.04826784133911, 1.02431178092957, 5.20297384262085, 6.64636945724487,
> 5.81104230880737, 4.90106821060181, 5.69662380218506, 7.51573324203491,
> 8.18294525146484, 6.11269092559814, 6.69754600524902, 5.6054277420044,
> 7.9188904762268, 5.51347351074219, 7.38122415542603, 6.92169857025146,
> 8.63118839263916, 6.9159483909607, 10.3055601119995, 6.9257755279541,
> 9.1276683807373, 5.51169300079346, 3.67073273658752, 2.84354925155640,
> 3.44134783744812, 2.87936210632324, 2.50833535194397, 6.63961029052734,
> 7.31760835647583, 5.54377555847168, 5.46550559997559, 3.04732036590576,
> 5.53518009185791, 4.90971279144287, 10.0030765533447, 10.7470664978027,
> 8.122633934021, 9.30413436889648, 11.5687465667725, 7.63134002685547,
> 7.48177337646484), .Dim = as.integer(c(100, 2)), index = structure(c(5480,
> 5481, 5482, 5483, 5484, 5485, 5486, 5487, 5488, 5489, 5490, 5491,
> 5492, 5493, 5494, 5495, 5496, 5497, 5498, 5499, 5500, 5501, 5502,
> 5503, 5504, 5505, 5506, 5507, 5508, 5509, 5510, 5511, 5512, 5513,
> 5514, 5515, 5516, 5517, 5518, 5519, 5520, 5521, 5522, 5523, 5524,
> 5525, 5526, 5527, 5528, 5529, 5530, 5531, 5532, 5533, 5534, 5535,
> 5536, 5537, 5538, 5539, 5540, 5541, 5542, 5543, 5544, 5545, 5546,
> 5547, 5548, 5549, 5550, 5551, 5552, 5553, 5554, 5555, 5556, 5557,
> 5558, 5559, 5560, 5561, 5562, 5563, 5564, 5565, 5566, 5567, 5568,
> 5569, 5570, 5571, 5572, 5573, 5574, 5575, 5576, 5577, 5578, 5579
> ), class = "Date"), class = "zoo")
> 
> TIA
> 
> Antonio
> 
> 
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [t] +44 (0)20 7679 0522
ECRC                              [f] +44 (0)20 7679 0565
UCL Department of Geography
Pearson Building                  [e] gavin.simpsonATNOSPAMucl.ac.uk
Gower Street
London, UK                        [w] http://www.ucl.ac.uk/~ucfagls/
WC1E 6BT                          [w] http://www.freshwaters.org.uk/
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From ld7631 at gmail.com  Tue Jun 26 21:05:40 2007
From: ld7631 at gmail.com (Dimitri Liakhovitski)
Date: Tue, 26 Jun 2007 15:05:40 -0400
Subject: [R] determining the column index and grabbing only variables with a
	certain string in them
Message-ID: <dae9a2a60706261205r1668524ehe606a98b4aacbd58@mail.gmail.com>

Hello!

I have a data set with almost 2,000 variables (called 'Data').
I want to select only a set of variables that have a certain string in
them (e.g., "Variable") - 'Variable.1', 'Variable.2', etc. until
'Variable.20'.

2 questions:

1. How can I determine the exact column index of a variable in the
data frame if I know its exact name? (I am asking because names(Data)
allows me to see only the last 1,348 variables)
2. How can I grab only variables that have a string "Variable" in
their name using grep?

Thank you!
Dimitri


From mark at wardle.org  Tue Jun 26 21:14:00 2007
From: mark at wardle.org (Mark Wardle)
Date: Tue, 26 Jun 2007 20:14:00 +0100
Subject: [R] Aggregation of data frame with calculations of proportions
Message-ID: <b59a37130706261214s6c1e47f8qe64e0b623d767235@mail.gmail.com>

Dear all,

I have been stuck on this problem, am rather struggling and would
appreciate some advice if anyone can help. I apologise if this is a
bit long-winded, but I've tried to limit it to the bare essentials,
but don't know how to make it more generic!

I have some slightly odd real world data that I'm looking at
representing number of positive diagnoses for different diseases, plus
the number tested. It's all in a data frame:

This should all be directly runnable with cut+paste:

sp = read.csv('http://www.wardle.org/sca-prev.csv', header=T)[,c(-1,-2)]

str(sp)

#'data.frame':   46 obs. of  19 variables:
# $ sca1        : int  5 1 NA NA 48 1 NA 17 21 4 ...
# $ sca2        : int  7 3 NA NA 53 1 NA NA 7 7 ...
# $ sca3        : int  3 1 NA NA 2 0 NA 29 0 0 ...
# $ sca6        : int  1 0 NA NA 2 2 NA NA 0 0 ...
# $ sca7        : int  NA NA NA NA 2 0 NA NA 1 0 ...
# $ sca8        : int  NA NA NA NA 2 1 NA NA NA NA ...
# $ sca10       : int  NA NA NA NA 0 0 NA NA NA NA ...
# $ sca12       : int  NA NA NA NA 0 0 NA NA NA NA ...
# $ sca17       : int  NA NA NA NA 2 1 NA NA NA NA ...
# $ frda        : int  NA NA NA NA 0 1 NA NA NA NA ...
# $ drpla       : int  NA NA 1 1 1 1 NA NA 0 0 ...
# $ fmr1        : int  NA NA NA NA NA NA 6 NA NA NA ...
# $ diagnosis   : int  16 5 1 1 112 8 6 46 29 11 ...
# $ unexplained : int  10 26 415 392 71 35 137 51 0 11 ...
# $ total       : int  26 31 416 393 183 43 143 97 29 22 ...
# $ patient.type: Factor w/ 8 levels "","ADCA","ADCA I",..: 2 5 2 5 2
4 8 3 2 2 ...
# $ age.group   : Factor w/ 5 levels "","<40",">40",..: 5 5 5 5 1 1 4 5 1 1 ...
# $ country     : Factor w/ 19 levels "","Australia",..: 7 7 1 1 8 8 8 1 8 8 ...
# $ region      : Factor w/ 6 levels "Americas","Asia",..: 4 4 3 3 3 3
3 3 3 3 ...

# It is straightforward to aggregate data:

smart.sum <- function(x,...) {	
	if (is.numeric(x)) return(sum(x, na.rm=T))
	else return(paste(unique(x), collapse=", "))		# for natbib citations
}
sp.ag1 = aggregate(sp, by=list(region=sp$region), FUN=smart.sum)
sp.ag2 = aggregate(sp, by=list(patient.type=sp$patient.type), FUN=smart.sum)
print(sp.ag1)

# and even to calculate crude percentages
spp = sp.ag1
spp[,2:15] = sapply(spp[,2:15], FUN=function(x) { round(x*100/ spp$total, 1)})

# *BUT*, the problem is that this is underestimating the true
proportions, because some of the data is NA. This means the diagnosis
was not tested rather than not found (which would be zero).

# What I want to do is calculate a true proportion, with the number
found divided by the number tested.
# I have managed to do this:

# calculates true proportion by only including values in the
denominator that have non-NAs in the numerator
# x= vector of numbers
# total = vector of numbers
calc.prevalence <- function(x, total) {
	sum.x = sum(x, na.rm=T)		# calculate numerator
	sum.y = sum(total[!is.na(x)])		# calculate denominator
	return(sum.x/sum.y)
}

correct.prevalence <- calc.prevalence(sp$drpla, sp$total)
incorrect.prevalence <- sum(sp$drpla, na.rm=T) / sum(sp$total, na.rm=T)
print(correct.prevalence)
print(incorrect.prevalence)


This is easy to apply to one column in one table, but I'm finding it
very difficult to do when I manipulate the data using the aggregate()
function above.

Is there a straightforward way, while aggregating columns by a
variable (number of) factors, in generating the sum of a column and
dividing by the sum of another column, only including data from the
second column when the first column is not NA. AND is it possible to
do that to all of the relevant columns (3:15)?

You won't believe how many iterations of by(), aggregate(), tapply(),
apply() and (finally) "for loops" I have tried with no success. The
best partial solution involved a combination of by() calling a
function calling aggregate(), but I can't parse the data returned. I'm
sure I am missing something! Can anyone help?

Many (many many) thanks!

Best wishes,

Mark

P.S. this is enough to drive me to drink!
-- 
Dr. Mark Wardle
Clinical research fellow and specialist registrar, Neurology
Cardiff, UK


From aa2007r at gmail.com  Tue Jun 26 21:39:57 2007
From: aa2007r at gmail.com (AA)
Date: Tue, 26 Jun 2007 15:39:57 -0400
Subject: [R] matlab/gauss code in R
References: <a7961d100706241627g49035513s90d1d91f9e42d622@mail.gmail.com>
	<4681391B.2040103@pdf.com>
Message-ID: <02cf01c7b829$c7d31d60$3927a8c0@treesdalellc.net>

you could look at the following link
http://mathesaurus.sourceforge.net/octave-r.html

It may help you to translate your matlab code.

good luck
AA.

Sebastian Kruk wrote:
> Hi all!
>
> I would like to import a matlab or gauss code to R.
>
> Could you help me?
>
> Bye,
>
> Sebasti?n.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From chenxh007 at gmail.com  Tue Jun 26 21:40:05 2007
From: chenxh007 at gmail.com (Xiaohui)
Date: Tue, 26 Jun 2007 12:40:05 -0700
Subject: [R] determining the column index and grabbing only variables
 with a	certain string in them
In-Reply-To: <dae9a2a60706261205r1668524ehe606a98b4aacbd58@mail.gmail.com>
References: <dae9a2a60706261205r1668524ehe606a98b4aacbd58@mail.gmail.com>
Message-ID: <46816B95.8090707@gmail.com>

1. which("Exat Name" == names(Data)   ## Assuming Data is your data.frame

2. grep("Variable", names(Data))

Xiaohui

Dimitri Liakhovitski wrote:
> Hello!
>
> I have a data set with almost 2,000 variables (called 'Data').
> I want to select only a set of variables that have a certain string in
> them (e.g., "Variable") - 'Variable.1', 'Variable.2', etc. until
> 'Variable.20'.
>
> 2 questions:
>
> 1. How can I determine the exact column index of a variable in the
> data frame if I know its exact name? (I am asking because names(Data)
> allows me to see only the last 1,348 variables)
> 2. How can I grab only variables that have a string "Variable" in
> their name using grep?
>
> Thank you!
> Dimitri
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


From Horace.Tso at pgn.com  Tue Jun 26 22:01:13 2007
From: Horace.Tso at pgn.com (Horace Tso)
Date: Tue, 26 Jun 2007 13:01:13 -0700
Subject: [R] create matrix from comparing two vectors
In-Reply-To: <0EE866100C01984EAE6AC3AE56EDFE5355A728@xmail05.ad.ua.ac.be>
References: <0EE866100C01984EAE6AC3AE56EDFE5355A728@xmail05.ad.ua.ac.be>
Message-ID: <46810E190200006500006A86@pgn.com>

In case you really want to use the apply variety, here is another one,

 sapply(fac,function(x)ifelse(test/x<1, 1, 0))

H.

>>> "Van Campenhout Bjorn" <bjorn.vancampenhout at ua.ac.be> 6/26/2007 11:13:14 AM >>>
hi all, sorry for this basic question, I think I know I should use ?apply, but it is really confusing me...

I want to create a matrix by comparing two vectors.  Eg:

test<-seq(1:10)
fac<-c(3,6,9)

and i want to end up with a 10*3 matrix with a boolean that tests if test<fac, so something like:

1 1 1
1 1 1
0 1 1
0 1 1
0 1 1
0 0 1
0 0 1
0 0 1
0 0 0
0 0 0

I can't find the solution without using a loop...

B

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
and provide commented, minimal, self-contained, reproducible code.


From giorgio_digessa at yahoo.it  Tue Jun 26 17:44:07 2007
From: giorgio_digessa at yahoo.it (giorgio Di Gessa)
Date: Tue, 26 Jun 2007 15:44:07 +0000 (GMT)
Subject: [R] Scale-Inverse Chi square Distribution
Message-ID: <78005.44234.qm@web26512.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070626/629e8b33/attachment.pl 

From aa2007r at gmail.com  Tue Jun 26 22:17:53 2007
From: aa2007r at gmail.com (AA)
Date: Tue, 26 Jun 2007 16:17:53 -0400
Subject: [R] Looking for parallel functionality between Matlab and R
References: <af47c4ab0706260520scae0212s5a57e9a1f26cdb48@mail.gmail.com>
Message-ID: <030b01c7b82f$13e4e490$3927a8c0@treesdalellc.net>

I think it has been pointed out but
look at ?points and ?lines and ?par
and have a look a the following link
http://mathesaurus.sourceforge.net/octave-r.html

good luck.
A.
----- Original Message ----- 
From: "El-ad David Amir" <amel at cs.bgu.ac.il>
To: <r-help at stat.math.ethz.ch>
Sent: Tuesday, June 26, 2007 8:20 AM
Subject: [R] Looking for parallel functionality between Matlab and R


> I'm slowly moving my statistical analysis from Matlab to R, and find 
> myself
> missing two features:
>
> a) How do I mimic Matlab's 'hold on'? (I want to show several plots
> together, when I type two plots one after the other the second overwrites
> the first)
> b) How do I mimic Matlab's 'axis'? (after drawing my plots I want to zoom 
> on
> specific parts- for example, x=0:5, y=0:20).
>
> Thanks for any assistance.
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From deinst at gmail.com  Tue Jun 26 23:55:21 2007
From: deinst at gmail.com (David Einstein)
Date: Tue, 26 Jun 2007 17:55:21 -0400
Subject: [R] Strange RODBC problem
Message-ID: <56750b780706261455p59273079vd51ee1aedc7ca3e4@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070626/f436ef0d/attachment.pl 

From brown_emu at yahoo.com  Wed Jun 27 00:06:17 2007
From: brown_emu at yahoo.com (Stephen Tucker)
Date: Tue, 26 Jun 2007 15:06:17 -0700 (PDT)
Subject: [R] ylab at the right hand of a plot with two y axes
In-Reply-To: <b44da9db0706260929x4b08f860t7074984351c3fd32@mail.gmail.com>
Message-ID: <853613.89047.qm@web39702.mail.mud.yahoo.com>

Here are two ways:

## method 1
plot(1:100,y1)
par(new=TRUE)
plot(1:100,y2,xlab="",ylab="",col=2,axes=FALSE)
axis(4,col=2,col.axis=2)

## method 2
plot.new()
plot.window(xlim=c(1,100),ylim=range(y1))
points(1:100,y1)
axis(1)
axis(2)
title(xlab="x",ylab="y1")
plot.window(xlim=c(1,100),ylim=range(y2))
points(1:100,y2)
axis(4,col=2,col.axis=2)
box()



--- Young Cho <young.stat at gmail.com> wrote:

> When I try to plot two lines ( or scatterplots) with different scales, this
> is what I have been doing:
> 
> Suppose: I have y1 and y2 in a very different scale
> 
> y1 = 1:100
> y2 = c(100:1)*10
> 
> To plot them on top of each other  and denote by different colors: I have
> to
> figure out the correct scale '10'  and corresponding tick.vector and
> lables.
> Then do:
> 
> plot(1:100, y1)   # I can have 'ylab' here for the left-hand side y axis.
> points(1:100, y2/10,col=2)
> ytick.vector = seq(from=0,to=100,by=20)
> ytick.label = as.character(seq(from=0,to=1000,by=200))
> axis(4,at = ytick.vector,label = ytick.label,col=2,col.axis=2)
> 
> Two questions.
> 
> 1. Are there easier ways to plot the y1, y2 w/o figuring out the correct
> scaler, tick vectors, and labels in order to put them in one figure?
> 2. How to add additional 'ylab' to the right hand side y-axis of the plot?
> Thanks a lot!
> 
> -Young
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From roland.rproject at gmail.com  Wed Jun 27 00:11:26 2007
From: roland.rproject at gmail.com (Roland Rau)
Date: Tue, 26 Jun 2007 18:11:26 -0400
Subject: [R] survreg error
In-Reply-To: <D45546375992BF429A93F7203358F14405DE82CD@sirius.fccc.edu>
References: <D45546375992BF429A93F7203358F14405DE82CD@sirius.fccc.edu>
Message-ID: <46818F0E.7040908@gmail.com>

Hi K,

Devarajan, Karthik wrote:
> Does anyone have any suggestions\thoughts 

Hard to say where the problem(s) originate(s). Why don't you provide 
commented, minimal, self-contained, reproducible code as is recommended 
on all messages on this mailing list?

This would make it much easier to track down where a problem could come 
from.

Best,
Roland


From Scott.Williams at petermac.org  Wed Jun 27 00:35:00 2007
From: Scott.Williams at petermac.org (Williams Scott)
Date: Wed, 27 Jun 2007 08:35:00 +1000
Subject: [R] survsplit and multiple event  indicators
Message-ID: <46B75B4A4A45914ABB0901364EFF4A20C45CE3@PMC-EMAIL.petermac.org.au>

Hi all,

I have a dataset of censored observations which contains 2 variables
which I wish to account for in a time-dependent manner (tumour
recurrence and subsequent treatment of that recurrence). Hence I need to
convert the data to counting process notation. survSplit and the like do
a nice job of doing this for a single event variable - is there anything
that can do it for 2 or more events? Can survSplit be adapted or is
there another way (which saves me having to write my own code)?

Cheers

Scott

_____________________________

 
Scott Williams MD

Peter MacCallum Cancer Centre

Melbourne, Australia


From jholtman at gmail.com  Wed Jun 27 00:42:49 2007
From: jholtman at gmail.com (jim holtman)
Date: Tue, 26 Jun 2007 18:42:49 -0400
Subject: [R] Aggregation of data frame with calculations of proportions
In-Reply-To: <b59a37130706261214s6c1e47f8qe64e0b623d767235@mail.gmail.com>
References: <b59a37130706261214s6c1e47f8qe64e0b623d767235@mail.gmail.com>
Message-ID: <644e1f320706261542h5ea51896s49c109f2fff04510@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070626/7895b9f7/attachment.pl 

From Bill.Venables at csiro.au  Wed Jun 27 01:25:07 2007
From: Bill.Venables at csiro.au (Bill.Venables at csiro.au)
Date: Wed, 27 Jun 2007 09:25:07 +1000
Subject: [R] Subscripting specified variables in a function
References: <1F809F62E3CEA04881B4644029484B4507F72348@AVN3VS004.ees.hhs.gov>
Message-ID: <B998A44C8986644EA8029CFE6396A924B67F47@exqld2-bne.nexus.csiro.au>

I think what you are trying to do is quite tricky.  Here is one way you
might like to think about.

> tdat <- data.frame(a = 1:5, b = c(1:3, 101,101))
> tdat
  a   b
1 1   1
2 2   2
3 3   3
4 4 101
5 5 101
> test.fx <- function(dta, expvar, expval) {
  lang <- substitute(subset(dat, v1 > v2),
  	list(dat = substitute(dta), 
		v1 = substitute(expvar), 
		v2 = substitute(expval)))
  newdta <- eval.parent(lang)
  summary(newdta[deparse(substitute(expvar))])
 }
> test.fx(tdat, b, 100)
       b      
 Min.   :101  
 1st Qu.:101  
 Median :101  
 Mean   :101  
 3rd Qu.:101  
 Max.   :101  
> test.fx(tdat, b, 2)
       b         
 Min.   :  3.00  
 1st Qu.: 52.00  
 Median :101.00  
 Mean   : 68.33  
 3rd Qu.:101.00  
 Max.   :101.00  
>  


Bill Venables
CSIRO Laboratories
PO Box 120, Cleveland, 4163
AUSTRALIA
Office Phone (email preferred): +61 7 3826 7251
Fax (if absolutely necessary):  +61 7 3826 7304
Mobile:                         +61 4 8819 4402
Home Phone:                     +61 7 3286 7700
mailto:Bill.Venables at csiro.au
http://www.cmis.csiro.au/bill.venables/ 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Zodet, Marc W.
(AHRQ)
Sent: Wednesday, 27 June 2007 12:43 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Subscripting specified variables in a function

I'm trying to create a function which will allow me to subset a data set
based on values of various specified variables.  I also want to then
apply some other function(s) (e.g., summary).

 

This is what I've tried so far....

 

> test.fx <- function(dta, expvar, expval) {

+ newdta <- subset(dta, eval(expvar)>expval)

+ summary(newdta$eval(expvar))

+ }

> 

> test.fx(fyc04s, quote(totexp04), 100)

Error in summary(newdta$eval(expvar)) : attempt to apply non-function

> 

 

The subset works fine, but the my attempt to access the specified
variable bombs.  

 

Is there a syntactical change I can make?

Is it better to attach newdta?

 

Thanks in advance for any guidance.

 

Marc

 

Marc W. Zodet, MS                           

Senior Health Statistician

Agency for Healthcare Research and Quality

Center for Financing, Access, and Cost Trends

301-427-1563 (Telephone)

301-427-1276 (Fax)

marc.zodet at ahrq.hhs.gov

 


	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From irishhacker at gmail.com  Wed Jun 27 01:59:44 2007
From: irishhacker at gmail.com (Robert Wilkins)
Date: Tue, 26 Jun 2007 18:59:44 -0500
Subject: [R] A really simple data manipulation example
Message-ID: <874da0b40706261659r11bb2fc4y2c3a4a5266a2fc74@mail.gmail.com>

In response to those who asked for a better explanation of what the
Vilno software does, here's a simple example that gives some idea of
what it does.

LABRESULTS is a dataset with multiple rows per patient , with lab
sodium measurements. It has columns: PATIENT_ID, VISIT_NUM, and
SODIUM.

DEMO is a dataset with one row per patient, with demographic data.
It has columns: PATIENT_ID, GENDER.

Here's a simple example, the following paragraph of code is a
data processing function (dpf) :


inlist LABRESULTS DEMO ;
mergeby PATIENT_ID ;
if (SODIUM == -9) SODIUM = NULL ;
if (VISIT_NUM != 2) deleterow ;
select AVERAGE_SODIUM = avg(SODIUM) by GENDER ;
sendoff(RESULTS_DATASET)  GENDER AVERAGE_SODIUM ;
turnoff;     // just means end-of-paragraph , version 1.0 won't need this.

Can you guess what it does? The lab result rows are merged with the
demographic rows, just to get the gender information merged in.
Obviously, they are merged by patient. The code -9 is used to denote
"missing", so convert that to NULL. I'm about to take a statistic for
visit 2, so rows with visit 0 or 1 must be deleted. I'm assuming, for
visit 2, each patient has at most one row. Now, for each sex group,
take the average sodium level. After the select statement, I have just
two rows, for male and female, with the average sodium level in the
AVERAGE_SODIUM column. Now the sendoff statement just stores the
current data table into a datafile, called RESULTS_DATASET.

So you have a sequence of data tables, each calculation reading in the
current table , and leaving a new data table for the next calculation.

So you have input datasets, a bunch of intermediate calculations, and
one or more output datasets. Pretty simple idea.

*****************************************

Some caveats:

LABRESULTS and DEMO are binary datasets. The asciitobinary and
binarytoascii statements are used to convert between binary datasets
and comma-separated ascii data files. (You can use any delimiter:
comma, vertical bar , etc). An asciitobinary statement is typically
just two lines of code.

The dpf begins with the inlist statement , and , for the moment ,
needs "turnoff ;" as the last line. Version 1.0 won't require the use
of "turnoff;", but version 0.85 does. It only means this paragraph of
code ends here ( a program can , of course , contain many paragraphs:
data processing functions, print statements, asciitobinary statements,
etc.).

If you've worked with lab data, you know lab data does not look so
simplistic. I need a simple example.

Vilno has a lot of functionality, many-to-many joins, adding columns,
firstrow() and lastrow() flags, and so forth. A fair amount of complex
data manipulations have already been tested with test programs ( in
the tarball ). Of course a simple example cannot show you that, it's
just a small taste.

*********************************************

If you've never used SPSS or SAS before, you won't care, but this
programming language falls in the same family as the SPSS and SAS
programming languages. All three programming languages have a fair
amount in common, but are quite different from the S programming
language. The vilno data processing function can replace the SAS
datastep. (It can also replace PROC TRANSPOSE and much of PROC MEANS,
except standard deviation calculations still need to be included in
the select statement).

********************************************

I hope that helps.

http://code.google.com/p/vilno


From mtmorgan at fhcrc.org  Wed Jun 27 02:18:16 2007
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Tue, 26 Jun 2007 17:18:16 -0700
Subject: [R] BioC2007, August 6-7 ** early registration ends July 1 **
Message-ID: <6phfy4ep7w7.fsf@gopher4.fhcrc.org>

BioC2007: Where Software and Biology Connect
August 6-7 in Seattle, WA, USA

** Early registration ends July 1 **

This conference highlights developments in and beyond Bioconductor. A
major goal is to discuss the use and design of software for analyzing
high throughput biological data.

Format: 
  * Scientific talks on both days from 8:30-12:00 
  * Expanded hands-on lab sessions on both afternoons 1:00-5:30
  * Technology overviews and social hour in the evening

Get more information and register for the conference at

https://secure.bioconductor.org/BioC2007/

A developer focused meeting is on August 5th. For (preliminary)
details, please visit:

http://wiki.fhcrc.org/bioc/Seattle_Dev_Meeting_2007

See you in August!

Martin Morgan
-- 
Bioconductor / Computational Biology
http://bioconductor.org


From m_olshansky at yahoo.com  Wed Jun 27 02:28:34 2007
From: m_olshansky at yahoo.com (Moshe Olshansky)
Date: Tue, 26 Jun 2007 17:28:34 -0700 (PDT)
Subject: [R] surprising difference in log()
In-Reply-To: <279B77EF-70FD-4F2B-8BBD-9F15D37589ED@lu.unisi.ch>
Message-ID: <172470.81862.qm@web32203.mail.mud.yahoo.com>

This is not surprizing at all!
The exact result is log(8,2) = 3, but the numerical
procedure which calculates the logarithm may produce a
result which is a few ULPs different from the exact
one, i.e. you can get that log(8,2) = 2.99999999999999
and then floor(2.99999999999999) = 2.

--- Fausto Galli <fausto.galli at lu.unisi.ch> wrote:

> 
> Hello everybody
> 
> My collegue and I noticed a strange behaviour of R
> on different  
> platforms. It's a simple computation, but results
> are rather different.
> 
> On Windows XP:
> 
>  > floor(log(8,2))
> [1] 3
> 
> which is what one should expect.
> Here's instead the result with Mac OS X (same
> version, 2.5.0  
> (2007-04-23))
> 
>  > floor(log(8,2))
> [1] 2
> 
> Is it a "bug" in R or in the operating system?
> Anyway, it's quite a surprising one.
> 
> 
> 
> 
> 
> _____________________________________
> Fausto Galli
> Institute of Finance
> University of Lugano
> Via G. Buffi 13
> CH-6904 Lugano, Switzerland.
> +41 (0)58 666 4497
> http://www.people.lu.unisi.ch/gallif
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From rmh at temple.edu  Wed Jun 27 04:46:17 2007
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 26 Jun 2007 22:46:17 -0400 (EDT)
Subject: [R] Strange RODBC problem
Message-ID: <20070626224617.CFA45710@po-d.temple.edu>

> I am using RODBC to collect data from an ODBC connection to an MS Access
> Database.  Everything seems to be working well except datetimes between
> March 12, 2006 02:00 and 02:59 get moved one hour forward.  This does not
> seem to be happening with Excel connecting to the same connection.  March 12
> seems a bit early for Daylight savings time.  What am I doing wrong?

In 2007, the US moved daylight savings to March 11 instead of the more traditional
first weekend in April.  It continues to November 4, a week later than before.
Google "daylight savings 2007" for lots of background.

Some MS programs did not make the switch until April 1, therefore my calendars
doubled up continuing appointments.

>From your experience, it looks like some programs are retroactively misapplying
the change to 2006.


From amirhendi at yahoo.com  Wed Jun 27 06:44:16 2007
From: amirhendi at yahoo.com (Amir_17)
Date: Tue, 26 Jun 2007 21:44:16 -0700 (PDT)
Subject: [R] question
Message-ID: <379508.44884.qm@web37903.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070626/50f427c6/attachment.pl 

From mark at wardle.org  Wed Jun 27 09:44:52 2007
From: mark at wardle.org (Mark Wardle)
Date: Wed, 27 Jun 2007 08:44:52 +0100
Subject: [R] Aggregation of data frame with calculations of proportions
In-Reply-To: <644e1f320706261542h5ea51896s49c109f2fff04510@mail.gmail.com>
References: <b59a37130706261214s6c1e47f8qe64e0b623d767235@mail.gmail.com>
	<644e1f320706261542h5ea51896s49c109f2fff04510@mail.gmail.com>
Message-ID: <b59a37130706270044n6dd995a2ibbd9a7dc011a4db0@mail.gmail.com>

Dear Jim,

On 26/06/07, jim holtman <jholtman at gmail.com> wrote:
> I think something like this will do it for you.
>
>
>
> set.seed(1)
> n <- 10
> x <- data.frame(a=sample(1:100,n),
> b=sample(1:100,n),d=sample(1:100,n))
> x$a[c(1,5)] <- NA
> x$b[c(7,6,4)] <- NA
> x$d[c(5,8)] <- NA
> x$total <- rowSums(x, na.rm=TRUE)
> x$type <- sample(1:3, n, replace=TRUE)
> by(x, list(x$type), function(z){
>     apply(z[,1:3], 2, calc.prevalence, total=z$total)
> })
>
>
> [...SNIP...]
> --
> Jim Holtman
> Cincinnati, OH
> +1 513 646 9390
>
> What is the problem you are trying to solve?


It works perfectly. The problem now is how to send over that beer I owe you!

Many thanks,

Best wishes,

-- 
Dr. Mark Wardle
Clinical research fellow and specialist registrar, Neurology
Cardiff, UK


From rh at family-krueger.com  Wed Jun 27 10:11:33 2007
From: rh at family-krueger.com (Knut Krueger)
Date: Wed, 27 Jun 2007 10:11:33 +0200
Subject: [R] Is Landau-H available
Message-ID: <46821BB5.3090000@family-krueger.com>

Does anybody knows whether Landau-H index is available in ?
I did not found anything about with r
Regards Knut


From christophe at pallier.org  Wed Jun 27 10:33:30 2007
From: christophe at pallier.org (Christophe Pallier)
Date: Wed, 27 Jun 2007 10:33:30 +0200
Subject: [R] A really simple data manipulation example
In-Reply-To: <874da0b40706261659r11bb2fc4y2c3a4a5266a2fc74@mail.gmail.com>
References: <874da0b40706261659r11bb2fc4y2c3a4a5266a2fc74@mail.gmail.com>
Message-ID: <dea6cb960706270133t3aaae487k4ae807a6a02a8c3c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070627/fe22e945/attachment.pl 

From jim at bitwrit.com.au  Wed Jun 27 13:05:26 2007
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 27 Jun 2007 21:05:26 +1000
Subject: [R] Looking for parallel functionality between Matlab and R
In-Reply-To: <af47c4ab0706260520scae0212s5a57e9a1f26cdb48@mail.gmail.com>
References: <af47c4ab0706260520scae0212s5a57e9a1f26cdb48@mail.gmail.com>
Message-ID: <46824476.2020703@bitwrit.com.au>

El-ad David Amir wrote:
> I'm slowly moving my statistical analysis from Matlab to R, and find myself
> missing two features:
> 
> a) How do I mimic Matlab's 'hold on'? (I want to show several plots
> together, when I type two plots one after the other the second overwrites
> the first)
> b) How do I mimic Matlab's 'axis'? (after drawing my plots I want to zoom on
> specific parts- for example, x=0:5, y=0:20).
> 
I think what you want for a) is par(ask=TRUE).

There have been a few discussions of zooming on the help list - see:

http://stats.math.uni-augsburg.de/iPlots/index.shtml

for one solution.

Jim


From brown_emu at yahoo.com  Wed Jun 27 13:54:43 2007
From: brown_emu at yahoo.com (Stephen Tucker)
Date: Wed, 27 Jun 2007 04:54:43 -0700 (PDT)
Subject: [R] Looking for parallel functionality between Matlab and R
In-Reply-To: <46824476.2020703@bitwrit.com.au>
Message-ID: <177186.88359.qm@web39708.mail.mud.yahoo.com>

This zooming function on the R-Wiki page was very neat:

http://wiki.r-project.org/rwiki/doku.php?id=tips:graphics-misc:interactive_zooming

Also, to answer question (a), maybe these examples might help?

## add elements to plot
plot(1:10,1:10)
lines(1:10,(1:10)/2)
points(1:10,(1:10)/1.5)

## add second y-axis
par(mar=c(5,4,2,4)+0.1)
plot(1:10,1:10)
par(new=TRUE)
plot(-20:20,20:-20,col=4,
     type="l",axes=FALSE,
     xlab="",ylab="",
     xaxs="i",
     xlim=par("usr")[1:2])
axis(4,col=4,col.axis=4)
mtext("second y-axis label",4,outer=TRUE,padj=-2,col=4)






--- Jim Lemon <jim at bitwrit.com.au> wrote:

> El-ad David Amir wrote:
> > I'm slowly moving my statistical analysis from Matlab to R, and find
> myself
> > missing two features:
> > 
> > a) How do I mimic Matlab's 'hold on'? (I want to show several plots
> > together, when I type two plots one after the other the second overwrites
> > the first)
> > b) How do I mimic Matlab's 'axis'? (after drawing my plots I want to zoom
> on
> > specific parts- for example, x=0:5, y=0:20).
> > 
> I think what you want for a) is par(ask=TRUE).
> 
> There have been a few discussions of zooming on the help list - see:
> 
> http://stats.math.uni-augsburg.de/iPlots/index.shtml
> 
> for one solution.
> 
> Jim
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 



      ____________________________________________________________________________________
Luggage? GPS? Comic books?


From deinst at gmail.com  Wed Jun 27 14:04:33 2007
From: deinst at gmail.com (David Einstein)
Date: Wed, 27 Jun 2007 08:04:33 -0400
Subject: [R] Strange RODBC problem
In-Reply-To: <20070626224617.CFA45710@po-d.temple.edu>
References: <20070626224617.CFA45710@po-d.temple.edu>
Message-ID: <56750b780706270504w2930e572m948d4c44a2120bfb@mail.gmail.com>

On 6/26/07, Richard M. Heiberger <rmh at temple.edu> wrote:
> > I am using RODBC to collect data from an ODBC connection to an MS Access
> > Database.  Everything seems to be working well except datetimes between
> > March 12, 2006 02:00 and 02:59 get moved one hour forward.  This does not
> > seem to be happening with Excel connecting to the same connection.  March 12
> > seems a bit early for Daylight savings time.  What am I doing wrong?
>
> In 2007, the US moved daylight savings to March 11 instead of the more traditional
> first weekend in April.  It continues to November 4, a week later than before.
> Google "daylight savings 2007" for lots of background.
>
> Some MS programs did not make the switch until April 1, therefore my calendars
> doubled up continuing appointments.
>
> From your experience, it looks like some programs are retroactively misapplying
> the change to 2006.
>
Thanks, that seems to be the problem. Now I need to figure out how to
fix it, but I know where to look.


From dpleydel at univ-fcomte.fr  Wed Jun 27 14:29:13 2007
From: dpleydel at univ-fcomte.fr (David)
Date: Wed, 27 Jun 2007 14:29:13 +0200
Subject: [R] Another loop avoidance question.
Message-ID: <20070627122913.GA20817@univ-fcomte.fr>

Hi

I want to sum over one of the dimensions of a n x k1 x k2 array in
which each column is the product of the corresponding columns from two
matrices with dimensions n x k1 and n x k2. I can see two approaches:
a loop on k1 and a loop on k2. But I cannot figure a solution that
avoids the loop? Is it possible? (I don't refer to apply or lapply etc
either as they are just hidden loops so, correct me if I'm wrong, I
can't see they hold any real advantage here). The following does
exactly what I want (except for the loops). My aim is to find the
solution which minimises processing time.

cheers
Dave

## Basic paramters
k1=3
k2=2
n=10
m1 = matrix (1:(n*k1), nrow=n, ncol=k1)
m2 = matrix (1:(n*k2), nrow=n, ncol=k2)
## Approach 1: loop on k1
output1 = matrix(0,nrow=n,ncol=k2)
pt1 = proc.time(for (i in 1:k1) output1 = output1 + m1[,i]*m2)
## Approach 2: loop on k2
output2 = matrix(0,nrow=n,ncol=k2)
pt2 = proc.time(for (i in 1:k2) output2[,i] =  rowSums( m1*m2[,i] ))
## Same result
sum(output1-output2)

-- 
David Pleydell

Laboratoire de Biologie Environnementale
USC INRA-EA 3184
Universit? de Franche-Comt?
Place Leclerc F
25030
Besan?on
France

(0033) 0381665763
dpleydel at univ-fcomte.fr


From jholtman at gmail.com  Wed Jun 27 14:31:04 2007
From: jholtman at gmail.com (jim holtman)
Date: Wed, 27 Jun 2007 08:31:04 -0400
Subject: [R] Aggregation of data frame with calculations of proportions
In-Reply-To: <b59a37130706270044n6dd995a2ibbd9a7dc011a4db0@mail.gmail.com>
References: <b59a37130706261214s6c1e47f8qe64e0b623d767235@mail.gmail.com>
	<644e1f320706261542h5ea51896s49c109f2fff04510@mail.gmail.com>
	<b59a37130706270044n6dd995a2ibbd9a7dc011a4db0@mail.gmail.com>
Message-ID: <644e1f320706270531x3f3c8863p3cd6764177a88829@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070627/31f76a18/attachment.pl 

From croero at hotmail.com  Wed Jun 27 15:19:06 2007
From: croero at hotmail.com (Bruce Willy)
Date: Wed, 27 Jun 2007 13:19:06 +0000
Subject: [R]  Import from excel
Message-ID: <BAY126-W41A4895E8178F4A13704B2C90A0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070627/c836e84b/attachment.pl 

From paul.lemmens at gmail.com  Wed Jun 27 15:21:29 2007
From: paul.lemmens at gmail.com (Paul Lemmens)
Date: Wed, 27 Jun 2007 15:21:29 +0200
Subject: [R] cmdscale(eurodist)
Message-ID: <b9065fc0706270621g5dcf0d36nf734efc5110e2a98@mail.gmail.com>

Dear all,

I have a question regarding the 'y <- -loc[,2]' in ?cmdscale.
Although I see that the plot is more sensible when using the '-loc'
instead of just 'y <- loc[,2]', I don't understand if there is a
statistical reason to do '-loc[,2]'.  So is this just to make the
graph look better, or should I always use -loc for the y-axis of a
similar plot for a completely different data set.

Kind regards,
Paul Lemmens


From ccleland at optonline.net  Wed Jun 27 15:30:32 2007
From: ccleland at optonline.net (Chuck Cleland)
Date: Wed, 27 Jun 2007 09:30:32 -0400
Subject: [R] Import from excel
In-Reply-To: <BAY126-W41A4895E8178F4A13704B2C90A0@phx.gbl>
References: <BAY126-W41A4895E8178F4A13704B2C90A0@phx.gbl>
Message-ID: <46826678.2070309@optonline.net>

Bruce Willy wrote:
> Hello,
>  
> I have imported data from Excel using the command 
> cours=read.delim("w:/apprentissage/cours_2.txt")
> after transforming my initial file with tab delimiters
>  
> It seemed to work
>  
> It is 2-dimensionnal. When I type cours[5,5],
> I get this type of message : "[1] 0,9760942761824 Levels:  0,495628477 0,893728761 0,89640592 0,903398558 ... 3,864414217"
> And when I want to multiply it, for example by 2 (cours[5,5]*2), I get : "Warning message:* ceci n'est pas pertinent pour des variables facteurs in: Ops.factor(cours[5, 5], 2)"
> i.e. approximately "this is not relevant for factor variables.
>  
> What can I do if I want to manipulate my variables ?
>  
> Thank you very much  

  You might try the following:

cours <- read.delim("w:/apprentissage/cours_2.txt", dec=",")

  See the "dec" argument on the help page for read.delim().

> _________________________________________________________________
> 
> stall?es directement dans votre Messenger !
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From croero at hotmail.com  Wed Jun 27 15:43:53 2007
From: croero at hotmail.com (Bruce Willy)
Date: Wed, 27 Jun 2007 13:43:53 +0000
Subject: [R] Import from excel
Message-ID: <BAY126-W52EB46A6F7DF2F0452CA8DC90A0@phx.gbl>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20070627/de01965e/attachment.pl 

From petr.pikal at precheza.cz  Wed Jun 27 16:00:58 2007
From: petr.pikal at precheza.cz (Petr PIKAL)
Date: Wed, 27 Jun 2007 16:00:58 +0200
Subject: [R] Import from excel
In-Reply-To: <BAY126-W52EB46A6F7DF2F0452CA8DC90A0@phx.gbl>
Message-ID: <OFD74E8F61.7A51D492-ONC1257307.004C7BD3-C1257307.004CFB10@precheza.cz>

Hi

r-help-bounces at stat.math.ethz.ch napsal dne 27.06.2007 15:43:53:

> 
> Thank you, but it still doesn't work completely
> 
> Thanks to you and the "dec=","" option, I can now do cours[5,5]*5 and 
get the 
> exact value
> 
> But I still cannot do matrix operations like cours[2,]%*%cours[5,]

As only you have cours we can only guess. You read it into data.frame 
which can have columns of different type. So my bet is, that you have one 
or more columns which is not numeric.

See how your cours looks like by

str(cours)

Regards
Petr

BTW. Maybe is time to look at some docummentation to R, especially R 
intro.

> 
> It says the arguments are neither matrix nor vectors.
> 
> :(> Date: Wed, 27 Jun 2007 09:30:32 -0400> From: ccleland at optonline.net> 

> Subject: Re: [R] Import from excel> To: croero at hotmail.com> CC: 
r-help at stat.
> math.ethz.ch> > Bruce Willy wrote:> > Hello,> > > > I have imported data 
from 
> Excel using the command > > 
cours=read.delim("w:/apprentissage/cours_2.txt")> 
> > after transforming my initial file with tab delimiters> > > > It 
seemed to 
> work> > > > It is 2-dimensionnal. When I type cours[5,5],> > I get this 
type 
> of message : "[1] 0,9760942761824 Levels: 0,495628477 0,893728761 
0,89640592 
> 0,903398558 ... 3,864414217"> > And when I want to multiply it, for 
example by
> 2 (cours[5,5]*2), I get : "Warning message:* ceci n'est pas pertinent 
pour des
> variables facteurs in: Ops.factor(cours[5, 5], 2)"> > i.e. approximately 
"this
> is not relevant for factor variables.> > > > What can I do if I want to 
> manipulate my variables ?> > > > Thank you very much > > You might try 
the 
> following:> > cours <- read.delim("w:/apprentissage/cours_2.txt", 
dec=",")> > 
> See the "dec" argument on the help page for read.delim().> > > 
> _________________________________________________________________> > > > 

> stall?es directement dans votre Messenger !> > > > [[alternative HTML 
version 
> deleted]]> > > > > > > > 
> 
------------------------------------------------------------------------> 
> > 
> > ______________________________________________> > 
R-help at stat.math.ethz.ch 
> mailing list> > https://stat.ethz.ch/mailman/listinfo/r-help> > PLEASE 
do read
> the posting guide http://www.R-project.org/posting-guide.html> > and 
provide 
> commented, minimal, self-contained, reproducible code.> > -- > Chuck 
Cleland, 
> Ph.D.> NDRI, Inc.> 71 West 23rd Street, 8th floor> New York, NY 10010> 
tel: 
> (212) 845-4495 (Tu, Th)> tel: (732) 512-0171 (M, W, F)> fax: (917) 
438-0894
> _________________________________________________________________
> 
> stall?es directement dans votre Messenger !
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From croero at hotmail.com  Wed Jun 27 16:13:21 2007
From: croero at hotmail.com (Bruce Willy)
Date: Wed, 27 Jun 2007 14:13:21 +0000
Subject: [R] Import from excel
Message-ID: <BAY126-W34886DCE8D0486119A8457C90A0@phx.gbl>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20070627/0b0361a6/attachment.pl 

From ghughes.email at gmail.com  Wed Jun 27 16:50:24 2007
From: ghughes.email at gmail.com (Gareth Hughes)
Date: Wed, 27 Jun 2007 15:50:24 +0100
Subject: [R] lme correlation structures
Message-ID: <3cc99a20706270750w5a77c51eid44db929ad21b5a1@mail.gmail.com>

Hi all,

I've been using SAS proc mixed to fit linear mixed models and would
like to be able to fit the same models in R. Two things in particular:

1) I have longitudinal data and wish to allow for different repeated
measures covariance parameter estimates for different groups (men and
women), each covariance matrix having the same structure. In proc
mixed this would be done by specifying group= in the REPEATED
statement. Is this simple to do in R? (I've tried form=~time|indv/sex
for example but this doesn't seem to do the job).

2) I've read that other correlation structures can be specified. Does
anyone have any examples of how toeplitz or (first-order)
ante-dependence structures can be specified?

Many thanks,

Gareth


From gunter.berton at gene.com  Wed Jun 27 17:06:06 2007
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 27 Jun 2007 08:06:06 -0700
Subject: [R] lme correlation structures
In-Reply-To: <3cc99a20706270750w5a77c51eid44db929ad21b5a1@mail.gmail.com>
Message-ID: <001501c7b8cc$b0655aa0$4d908980@gne.windows.gene.com>

Please read ?lme carefully -- the info you seek is there. In particular, the
weights argument for changing variance weighting by covariates and the
correlation argument for specifying correlation structures.

Pinheiro and Bates's MIXED EFFECT MODELS IN S... is the canonical reference
(which you should get if you want to use R as you said) that exposits the
ideas at greater length.


Bert Gunter
Genentech Nonclinical Statistics

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Gareth Hughes
Sent: Wednesday, June 27, 2007 7:50 AM
To: r-help at stat.math.ethz.ch
Subject: [R] lme correlation structures

Hi all,

I've been using SAS proc mixed to fit linear mixed models and would
like to be able to fit the same models in R. Two things in particular:

1) I have longitudinal data and wish to allow for different repeated
measures covariance parameter estimates for different groups (men and
women), each covariance matrix having the same structure. In proc
mixed this would be done by specifying group= in the REPEATED
statement. Is this simple to do in R? (I've tried form=~time|indv/sex
for example but this doesn't seem to do the job).

2) I've read that other correlation structures can be specified. Does
anyone have any examples of how toeplitz or (first-order)
ante-dependence structures can be specified?

Many thanks,

Gareth

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From luyizhao at fas.harvard.edu  Wed Jun 27 16:07:42 2007
From: luyizhao at fas.harvard.edu (luyizhao at fas.harvard.edu)
Date: Wed, 27 Jun 2007 10:07:42 -0400
Subject: [R] [R-pkgs] New package "tradeCosts"
Message-ID: <1182953262.46826f2e64b47@webmail.fas.harvard.edu>

We would like to announce the availability of the 'tradeCosts' package
in R for analysing transaction costs of trading.  Version 0.1-0 is now available
on CRAN.  To take a look, you can:

> install.packages("tradeCosts")
...
> vignette("tradeCosts")

and play around.

This is the first and very basic version of a package that we hope to
expand over the next few months.

The cost analysis this package performs is currently very basic.  We
are releasing this version with the goal of getting feedback from
potential users on what functionality they would like to see in future
releases of the tradecosts package.

Aaron Schwartz
Luyi Zhao

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages


From carlos.grohmann at gmail.com  Wed Jun 27 17:27:28 2007
From: carlos.grohmann at gmail.com (=?ISO-8859-1?Q?Carlos_"Gu=E2no"_Grohmann?=)
Date: Wed, 27 Jun 2007 16:27:28 +0100
Subject: [R] moving-window (neighborhood) analysis
Message-ID: <bd07447b0706270827h112afea7mc3a2e61541e87b99@mail.gmail.com>

Hello all

I was wondering what would be the best way to do a moving-window
analysis of a matrix? By moving-window I mean that kind of analysis
common in GIS, where each pixel (matrix element) of the resulting map
is a function of it neighbors, and the neighborhood is a square
matrix.
I was hoping there was some function in R that could do that, where I
could define the size of the neighborhood, and then apply some
function to the values, some function I don't have in GIS packages
(like circular statistics).

thanks all.

Carlos


-- 
+-----------------------------------------------------------+
              Carlos Henrique Grohmann - Guano
  Visiting Researcher at Kingston University London - UK
  Geologist M.Sc  - Doctorate Student at IGc-USP - Brazil
Linux User #89721  - carlos dot grohmann at gmail dot com
+-----------------------------------------------------------+
_________________
"Good morning, doctors. I have taken the liberty of removing Windows
95 from my hard drive."
--The winning entry in a "What were HAL's first words" contest judged
by 2001: A SPACE ODYSSEY creator Arthur C. Clarke


From genomenet at gmail.com  Wed Jun 27 17:51:21 2007
From: genomenet at gmail.com (genomenet at gmail.com)
Date: Wed, 27 Jun 2007 08:51:21 -0700
Subject: [R] how to use chi-square to test correlation question
Message-ID: <1106346696.20070627085121@gmail.com>

Hi There,

There are 300 boy students and 100 girl students in a class. One interesting question is whether 
boy is smarter than girl or not.

first given the exam with a difficulty level 1, the number of the student who got A is below
31 for boy, 10 for girl.

Then we increase the difficulty level of the exam to level 2, the number of the student who got A is below
32 for boy, 10 for girl.

We did this 10 times, we got the following table
                                    score
gender  level1 level2 levle3 level4 level5 level6 level7 level 8 level9 level10
boy       31     32      33     34     35     36     37     38     39      40
girl      10     10      10     10     10     10     10     10     10      10


My question is how to use chi-square test to test if score is independent of gender.
That is whether boys is significantly smarter than girls.

I used a chisquare test to do this.
The null hypothesis is score is not correlated with gender. and we can also say
the null hypothesis is boys are the same smart as girls.
the alternative hypothesis is that boys are significantly smarter than girls.

boyscore=c(31,32,33,34,35,36,37,38,39,40)
girlscore=c(10,10,10,10,10,10,10,10,10,10)
ratioscore=boyscore/girlscore;
expratio=300/100;   #300 boy students and 100 girl students

chisq=sum((expratio-ratioscore)^2/expratio)
df=9
pvalue=1-pchisq(chisq,df)

Since the pvalue (0.9984578) is greater than significance level (0.05), we cannot
reject the null hypothesis. Therefore the conclusion is that boys are not significantly 
smarter than girls.
or we can say the conclusion is that score is not correlated with gender.

Am I right?

Thank you very much.

Van


From gunter.berton at gene.com  Wed Jun 27 17:49:50 2007
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 27 Jun 2007 08:49:50 -0700
Subject: [R] moving-window (neighborhood) analysis
In-Reply-To: <bd07447b0706270827h112afea7mc3a2e61541e87b99@mail.gmail.com>
Message-ID: <003101c7b8d2$cbe8e7f0$4d908980@gne.windows.gene.com>

See the "Spatial" section under CRAN's Task views 

Bert Gunter
Genentech Nonclinical Statistics

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Carlos "Gu?no"
Grohmann
Sent: Wednesday, June 27, 2007 8:27 AM
To: r-help at stat.math.ethz.ch
Subject: [R] moving-window (neighborhood) analysis

Hello all

I was wondering what would be the best way to do a moving-window
analysis of a matrix? By moving-window I mean that kind of analysis
common in GIS, where each pixel (matrix element) of the resulting map
is a function of it neighbors, and the neighborhood is a square
matrix.
I was hoping there was some function in R that could do that, where I
could define the size of the neighborhood, and then apply some
function to the values, some function I don't have in GIS packages
(like circular statistics).

thanks all.

Carlos


-- 
+-----------------------------------------------------------+
              Carlos Henrique Grohmann - Guano
  Visiting Researcher at Kingston University London - UK
  Geologist M.Sc  - Doctorate Student at IGc-USP - Brazil
Linux User #89721  - carlos dot grohmann at gmail dot com
+-----------------------------------------------------------+
_________________
"Good morning, doctors. I have taken the liberty of removing Windows
95 from my hard drive."
--The winning entry in a "What were HAL's first words" contest judged
by 2001: A SPACE ODYSSEY creator Arthur C. Clarke

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From afshart at exchange.sba.miami.edu  Wed Jun 27 17:52:36 2007
From: afshart at exchange.sba.miami.edu (Afshartous, David)
Date: Wed, 27 Jun 2007 11:52:36 -0400
Subject: [R] xyplot with par
In-Reply-To: <mailman.9.1182679204.26425.r-help@stat.math.ethz.ch>
Message-ID: <6BCB4D493A447546A8126F24332056E8062D15C6@school1.business.edu>

All,
Is there are a simple way to plot multiple xyplots on the same page
in the code below (it currently overwrites the first plot w/ the
second).
I searched the archives and saw a similar question but the answer didn't
seem to work.
thanks
dave

x1 = rnorm(10)
x2 = rnorm (10)
y1 = rnorm(10)
y2 = rnorm (10)
op = par(mfrow = c(2,1))
xyplot(y1 ~ x1)
xyplot(y2 ~ x2)


From mtmorgan at fhcrc.org  Wed Jun 27 17:56:27 2007
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Wed, 27 Jun 2007 08:56:27 -0700
Subject: [R] CORRECTION: Re:  BioC2007,
 August 6-7 ** early registration ends July 1 **
In-Reply-To: <6phfy4ep7w7.fsf@gopher4.fhcrc.org> (Martin Morgan's message of
	"Tue, 26 Jun 2007 17:18:16 -0700")
References: <6phfy4ep7w7.fsf@gopher4.fhcrc.org>
Message-ID: <6ph8xa5pf10.fsf@gopher4.fhcrc.org>

BioC2007: Where Software and Biology Connect
August 6-7 in Seattle, WA, USA

The BioC2007 developer-focused meeting is on August 8, the day *after*
the main conference.

In addition, I neglected to mention the poster session on Monday
evening.

Best,

Martin Morgan
-- 
Bioconductor / Computational Biology
http://bioconductor.org


Martin Morgan <mtmorgan at fhcrc.org> writes:

> BioC2007: Where Software and Biology Connect
> August 6-7 in Seattle, WA, USA
>
> ** Early registration ends July 1 **
>
> This conference highlights developments in and beyond Bioconductor. A
> major goal is to discuss the use and design of software for analyzing
> high throughput biological data.
>
> Format: 
>   * Scientific talks on both days from 8:30-12:00 
>   * Expanded hands-on lab sessions on both afternoons 1:00-5:30
>   * Technology overviews and social hour in the evening
>
> Get more information and register for the conference at
>
> https://secure.bioconductor.org/BioC2007/
>
> A developer focused meeting is on August 5th. For (preliminary)
> details, please visit:
>
> http://wiki.fhcrc.org/bioc/Seattle_Dev_Meeting_2007
>
> See you in August!
>
> Martin Morgan
> -- 
> Bioconductor / Computational Biology
> http://bioconductor.org
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Martin Morgan
Bioconductor / Computational Biology
http://bioconductor.org


From rvaradhan at jhmi.edu  Wed Jun 27 17:59:30 2007
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Wed, 27 Jun 2007 11:59:30 -0400
Subject: [R] Solving a system of nonlinear equations
Message-ID: <000301c7b8d4$266b6b20$7c94100a@win.ad.jhu.edu>

Hi All,

 

Here is a modification of nlsolve() that I had submitted before.  The new
version of nlsolve() has the option to generate multiple random starting
values in order to improve the chances of locating the zeros of the
nonlinear system.  The last test example in the attached file, the
Freudenstein-Roth function, shows the usefulness of the multiple random
starts.  

 

Hope this is useful,

Ravi.

----------------------------------------------------------------------------
-------

Ravi Varadhan, Ph.D.

Assistant Professor, The Center on Aging and Health

Division of Geriatric Medicine and Gerontology 

Johns Hopkins University

Ph: (410) 502-2619

Fax: (410) 614-9625

Email: rvaradhan at jhmi.edu

Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html

 

----------------------------------------------------------------------------
--------

 

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: nlsolve_R.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070627/dce50cd4/attachment.txt 

From deepayan.sarkar at gmail.com  Wed Jun 27 18:06:50 2007
From: deepayan.sarkar at gmail.com (deepayan.sarkar at gmail.com)
Date: Wed, 27 Jun 2007 09:06:50 -0700
Subject: [R] xyplot with par
In-Reply-To: <6BCB4D493A447546A8126F24332056E8062D15C6@school1.business.edu>
References: <mailman.9.1182679204.26425.r-help@stat.math.ethz.ch>
	<6BCB4D493A447546A8126F24332056E8062D15C6@school1.business.edu>
Message-ID: <eb555e660706270906m39b7ced7ne3c752407b368452@mail.gmail.com>

On 6/27/07, Afshartous, David <afshart at exchange.sba.miami.edu> wrote:
> All,
> Is there are a simple way to plot multiple xyplots on the same page
> in the code below (it currently overwrites the first plot w/ the
> second).
> I searched the archives and saw a similar question but the answer didn't
> seem to work.
> thanks
> dave
>
> x1 = rnorm(10)
> x2 = rnorm (10)
> y1 = rnorm(10)
> y2 = rnorm (10)
> op = par(mfrow = c(2,1))
> xyplot(y1 ~ x1)
> xyplot(y2 ~ x2)

See help(print.trellis), which has examples.

-Deepayan


From kellrott at csbl.bmb.uga.edu  Wed Jun 27 18:58:24 2007
From: kellrott at csbl.bmb.uga.edu (Kyle Ellrott)
Date: Wed, 27 Jun 2007 12:58:24 -0400
Subject: [R] "no applicable method"
Message-ID: <AB724053-3718-4FFE-8342-4ED1AEC5D689@csbl.bmb.uga.edu>

I'm getting started in R, and I'm trying to use one of the gradient  
boosting packages, mboost.  I'm already installed the package with   
install.packages("mboost") and loaded it with library(mboost).
My problem is that when I attempt to call glmboost, I get a message  
that " Error in glmboost() : no applicable method for "glmboost" ".
Does anybody have an idea of what kind of problem this is indicative of?


Kyle Ellrott


From vinodkgul at yahoo.com  Wed Jun 27 18:55:10 2007
From: vinodkgul at yahoo.com (vinod gullu)
Date: Wed, 27 Jun 2007 09:55:10 -0700 (PDT)
Subject: [R] stepAIC on lm() where response is a matrix..
In-Reply-To: <mailman.13.1182938406.20532.r-help@stat.math.ethz.ch>
Message-ID: <20070627165510.25778.qmail@web53808.mail.re2.yahoo.com>

dear R users,

I have fit the lm() on a mtrix of responses. 
i.e M1 = lm(cbind(R1,R2)~ X+Y+0). When i use
summary(M1), it shows details for R1 and R2
separately. Now i want to use stepAIC on these models.
But when i use stepAIC(M1) an error message  comes
saying that dropterm.mlm is not implemented. What is
the way out to use stepAIC in such cases.

regards,


 
____________________________________________________________________________________
The fish are biting.


From Mark.Leeds at morganstanley.com  Wed Jun 27 18:58:28 2007
From: Mark.Leeds at morganstanley.com (Leeds, Mark (IED))
Date: Wed, 27 Jun 2007 12:58:28 -0400
Subject: [R] how to use chi-square to test correlation question
In-Reply-To: <1106346696.20070627085121@gmail.com>
References: <1106346696.20070627085121@gmail.com>
Message-ID: <D3AEEDA31E57474B840BEBC25A8A834401957438@NYWEXMB23.msad.ms.com>

someone else might have another viewpoint but I think your categories
needs to be score categories ( 60-65, 65-70 etc )  
and the data needs to be the number of girls and boys that fall into a
category. I've never seen this "below a certain value" 
Methodology  but maybe it's popular and I just don't know about it. 
I'm unsure if you can assign success and failure in a chi square
framework by "below a certain value". I don't think so. And I think
That you also have seperate multiple experiments ( each level seems like
a new experiment to me ) so your alpha level is going to be messed up
also. I'd be interested in hearing other viewpoints but I'm fairly
certain that your approach needs modifications.



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of
genomenet at gmail.com
Sent: Wednesday, June 27, 2007 11:51 AM
To: r-help-request at stat.math.ethz.ch
Subject: [R] how to use chi-square to test correlation question

Hi There,

There are 300 boy students and 100 girl students in a class. One
interesting question is whether boy is smarter than girl or not.

first given the exam with a difficulty level 1, the number of the
student who got A is below
31 for boy, 10 for girl.

Then we increase the difficulty level of the exam to level 2, the number
of the student who got A is below
32 for boy, 10 for girl.

We did this 10 times, we got the following table
                                    score gender  level1 level2 levle3
level4 level5 level6 level7 level 8 level9 level10
boy       31     32      33     34     35     36     37     38     39
40
girl      10     10      10     10     10     10     10     10     10
10


My question is how to use chi-square test to test if score is
independent of gender.
That is whether boys is significantly smarter than girls.

I used a chisquare test to do this.
The null hypothesis is score is not correlated with gender. and we can
also say the null hypothesis is boys are the same smart as girls.
the alternative hypothesis is that boys are significantly smarter than
girls.

boyscore=c(31,32,33,34,35,36,37,38,39,40)
girlscore=c(10,10,10,10,10,10,10,10,10,10)
ratioscore=boyscore/girlscore;
expratio=300/100;   #300 boy students and 100 girl students

chisq=sum((expratio-ratioscore)^2/expratio)
df=9
pvalue=1-pchisq(chisq,df)

Since the pvalue (0.9984578) is greater than significance level (0.05),
we cannot reject the null hypothesis. Therefore the conclusion is that
boys are not significantly smarter than girls.
or we can say the conclusion is that score is not correlated with
gender.

Am I right?

Thank you very much.

Van

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
--------------------------------------------------------

This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}


From loecher at eden.rutgers.edu  Wed Jun 27 19:25:30 2007
From: loecher at eden.rutgers.edu (Markus Loecher)
Date: Wed, 27 Jun 2007 13:25:30 -0400 (EDT)
Subject: [R] Matlab end operator
Message-ID: <13225635.24491182965129984.JavaMail.tomcat@rainier>

Dear list members,
I use both R and Matlab and find that each has its own strengths. Matlab definitely has the edge when it comes to the interactivity of its graphs.
In addition I find the little operator end extremely useful in indexing arrays. (as in x(1:end,) )
The notation is MUCH more cumbersome in R using nrow() and ncol() recursively (as in x[1:nrow(x), ] ).
Is there a package that might contain an implementation of the end operator ?

Thanks !

Markus


From duvvuru.suman at gmail.com  Wed Jun 27 19:32:28 2007
From: duvvuru.suman at gmail.com (suman Duvvuru)
Date: Wed, 27 Jun 2007 13:32:28 -0400
Subject: [R] Timer
Message-ID: <bac8a0820706271032k63fc9e2dva72226e463724a6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070627/0504ba23/attachment.pl 

From wwwhsd at gmail.com  Wed Jun 27 19:45:12 2007
From: wwwhsd at gmail.com (Henrique Dallazuanna)
Date: Wed, 27 Jun 2007 14:45:12 -0300
Subject: [R] Timer
In-Reply-To: <bac8a0820706271032k63fc9e2dva72226e463724a6@mail.gmail.com>
References: <bac8a0820706271032k63fc9e2dva72226e463724a6@mail.gmail.com>
Message-ID: <da79af330706271045n436ffd8q728404bb2c11f66a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070627/4c93d2c9/attachment.pl 

From deinst at gmail.com  Wed Jun 27 19:06:23 2007
From: deinst at gmail.com (David Einstein)
Date: Wed, 27 Jun 2007 13:06:23 -0400
Subject: [R] Strange RODBC problem
In-Reply-To: <20070626224617.CFA45710@po-d.temple.edu>
References: <20070626224617.CFA45710@po-d.temple.edu>
Message-ID: <56750b780706271006jc09774fpdf498b411853cede@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070627/e073c080/attachment.pl 

From bernard.colin at usherbrooke.ca  Wed Jun 27 20:23:35 2007
From: bernard.colin at usherbrooke.ca (Bernard Colin)
Date: Wed, 27 Jun 2007 18:23:35 -0000
Subject: [R] Re : Help please for graphics!
Message-ID: <000001c7b8e8$2d3b4150$9628d284@AD.DMI.USherbrooke.Ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070627/33d14ad7/attachment.pl 

From christophe at pallier.org  Wed Jun 27 20:43:17 2007
From: christophe at pallier.org (Christophe Pallier)
Date: Wed, 27 Jun 2007 20:43:17 +0200
Subject: [R] Matlab end operator
In-Reply-To: <13225635.24491182965129984.JavaMail.tomcat@rainier>
References: <13225635.24491182965129984.JavaMail.tomcat@rainier>
Message-ID: <dea6cb960706271143g28cf675el12831208c4f0d55a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070627/2130c00c/attachment.pl 

From jholtman at gmail.com  Wed Jun 27 20:56:28 2007
From: jholtman at gmail.com (jim holtman)
Date: Wed, 27 Jun 2007 14:56:28 -0400
Subject: [R] Re : Help please for graphics!
In-Reply-To: <000001c7b8e8$2d3b4150$9628d284@AD.DMI.USherbrooke.Ca>
References: <000001c7b8e8$2d3b4150$9628d284@AD.DMI.USherbrooke.Ca>
Message-ID: <644e1f320706271156i571eabeap4b319ec47d91df5b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070627/4069a8c8/attachment.pl 

From rh at family-krueger.com  Wed Jun 27 21:15:22 2007
From: rh at family-krueger.com (Knut Krueger)
Date: Wed, 27 Jun 2007 21:15:22 +0200
Subject: [R] read.xls problem
Message-ID: <4682B74A.1090504@family-krueger.com>

Hi to all,
I have a strange problem
There was a Excel file with 5 sheets
I deleted sheet 2 and 4.
as all the times before I tried to read the sheets with
data1<- read.xls(excelfile_2,sheet=1, as.is = TRUE ,verbose=FALSE, 
perl="C:/perl/bin/perl.exe")
data2<- read.xls(excelfile_2,sheet=2, as.is = TRUE ,verbose=FALSE, 
perl="C:/perl/bin/perl.exe")
data3<- read.xls(excelfile_2,sheet=3, as.is = TRUE ,verbose=FALSE, 
perl="C:/perl/bin/perl.exe")

but only the folloing code reads the sheets well
data1<- read.xls(excelfile_2,sheet=1, as.is = TRUE ,verbose=FALSE, 
perl="C:/perl/bin/perl.exe")
data3<- read.xls(excelfile_2,sheet=3, as.is = TRUE ,verbose=FALSE, 
perl="C:/perl/bin/perl.exe")
data5<- read.xls(excelfile_2,sheet=5, as.is = TRUE ,verbose=FALSE, 
perl="C:/perl/bin/perl.exe")

Does anybody know whether this is normal?
 I never had this problem before. And if it is normal I wonder about how 
to find the sheet numbers

Regards Knut


From wgavioli at fas.harvard.edu  Wed Jun 27 21:25:41 2007
From: wgavioli at fas.harvard.edu (Wayne Aldo Gavioli)
Date: Wed, 27 Jun 2007 15:25:41 -0400
Subject: [R] Condensed PCA Results
Message-ID: <1182972341.4682b9b55c2c2@webmail.fas.harvard.edu>

Hello all,


I'm currently using R to do PCA Analysis, and was wondering if anyone knew the
specific R Code that could limit the output of the PCA Analysis so that you
only get the Principal Component features as your output and none of the
extraneous words or numbers that you don't want.

If that was unclear, let me use linear regression as an example:

"lm(y~x)" is the normal command for linear regression, but it produces other
text and string aside from the regression coefficients.

"lm(y~x)$coefficients" gives you just the regression coefficients when you carry
out the command.


When I carry out PCA on R, typically I get:


Standard deviations:
[1] 83.732400 14.212402  6.489426  2.4827900

Rotation:
                PC1         PC2         PC3         PC4
Murder   0.04170432 -0.04482166  0.07989066 -0.99492173
Assault  0.99522128 -0.05876003 -0.06756974  0.03893830
UrbanPop 0.04633575  0.97685748 -0.20054629 -0.05816914
Rape     0.07515550  0.20071807  0.97408059  0.07232502


I want to get only:

                PC1         PC2         PC3         PC4
Murder   0.04170432 -0.04482166  0.07989066 -0.99492173
Assault  0.99522128 -0.05876003 -0.06756974  0.03893830
UrbanPop 0.04633575  0.97685748 -0.20054629 -0.05816914
Rape     0.07515550  0.20071807  0.97408059  0.07232502


I want to be able to do this because I am actually carrying out PCA in RExcel. 
I am able to do the PCA analysis using the "prcomp(data)" and "GetArray"
commands, but doing that puts all of the aforementinoed output in a single row
of cells instead of assigning each word and number its own individual cell.

I figured this dealt more with R code than Excel, so I decided to post it here.

Can anyone help me out?  Is there a command that can carry out what I've
mentioned?


Wayne


From katharina.surovcik at cs.uni-goettingen.de  Wed Jun 27 21:35:06 2007
From: katharina.surovcik at cs.uni-goettingen.de (Katharina Surovcik)
Date: Wed, 27 Jun 2007 21:35:06 +0200
Subject: [R] Condensed PCA Results
In-Reply-To: <1182972341.4682b9b55c2c2@webmail.fas.harvard.edu>
References: <1182972341.4682b9b55c2c2@webmail.fas.harvard.edu>
Message-ID: <4682BBEA.6010501@cs.uni-goettingen.de>

if x is your matrix, then
prcomp(x)$rotation
gets you what you want

Katharina

Wayne Aldo Gavioli schrieb:
> Hello all,
>
>
> I'm currently using R to do PCA Analysis, and was wondering if anyone knew the
> specific R Code that could limit the output of the PCA Analysis so that you
> only get the Principal Component features as your output and none of the
> extraneous words or numbers that you don't want.
>
> If that was unclear, let me use linear regression as an example:
>
> "lm(y~x)" is the normal command for linear regression, but it produces other
> text and string aside from the regression coefficients.
>
> "lm(y~x)$coefficients" gives you just the regression coefficients when you carry
> out the command.
>
>
> When I carry out PCA on R, typically I get:
>
>
> Standard deviations:
> [1] 83.732400 14.212402  6.489426  2.4827900
>
> Rotation:
>                 PC1         PC2         PC3         PC4
> Murder   0.04170432 -0.04482166  0.07989066 -0.99492173
> Assault  0.99522128 -0.05876003 -0.06756974  0.03893830
> UrbanPop 0.04633575  0.97685748 -0.20054629 -0.05816914
> Rape     0.07515550  0.20071807  0.97408059  0.07232502
>
>
> I want to get only:
>
>                 PC1         PC2         PC3         PC4
> Murder   0.04170432 -0.04482166  0.07989066 -0.99492173
> Assault  0.99522128 -0.05876003 -0.06756974  0.03893830
> UrbanPop 0.04633575  0.97685748 -0.20054629 -0.05816914
> Rape     0.07515550  0.20071807  0.97408059  0.07232502
>
>
> I want to be able to do this because I am actually carrying out PCA in RExcel. 
> I am able to do the PCA analysis using the "prcomp(data)" and "GetArray"
> commands, but doing that puts all of the aforementinoed output in a single row
> of cells instead of assigning each word and number its own individual cell.
>
> I figured this dealt more with R code than Excel, so I decided to post it here.
>
> Can anyone help me out?  Is there a command that can carry out what I've
> mentioned?
>
>
> Wayne
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ivowel at gmail.com  Wed Jun 27 22:00:30 2007
From: ivowel at gmail.com (ivo welch)
Date: Wed, 27 Jun 2007 16:00:30 -0400
Subject: [R] skeleton for C code?
Message-ID: <50d1c22d0706271300p3c8d9109g1aeafe3908fa419e@mail.gmail.com>

Dear R experts---I would like to write a replacement for the read.csv
function that is less general, but also more efficient.

could someone please provide me with a skeleton function that shows me
how to read the arguments and return a data frame for a call to a C
function that handles

     returned.data.frame = my.read.csv(file, header = TRUE, sep = ",",
quote="\"", dec=".",
              fill = TRUE, comment.char="", ...)

this may be very difficult, of course, in which case writing such a
function would not be worth it.  I guess I would be happy just to
learn how to return a basic data frame that holds data vectors that
are either strings or numbers---nothing more complex.

help appreciated.

/iaw


From jizhang at chori.org  Wed Jun 27 21:59:35 2007
From: jizhang at chori.org (Jiong Zhang, PhD)
Date: Wed, 27 Jun 2007 12:59:35 -0700
Subject: [R]  running saved scripts
Message-ID: <8d027c80f93ee84a943aa733992d2286@mail.chori.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070627/4370e64c/attachment.pl 

From helprhelp at gmail.com  Wed Jun 27 22:11:59 2007
From: helprhelp at gmail.com (Weiwei Shi)
Date: Wed, 27 Jun 2007 16:11:59 -0400
Subject: [R] running saved scripts
In-Reply-To: <8d027c80f93ee84a943aa733992d2286@mail.chori.org>
References: <8d027c80f93ee84a943aa733992d2286@mail.chori.org>
Message-ID: <cdf817830706271311yda55d72r7fba4d964a6a0a80@mail.gmail.com>

put into a file called abc.R or whatever,

source("abc.R")

check ?source

On 6/27/07, Jiong Zhang, PhD <jizhang at chori.org> wrote:
> Hi All,
>
> I have a rather naive question.  I need to run some simple calculations
> such as read.table, resid, and quantile on a data file.  How can I save
> these commands in a text file and ask R to run this text file?  Thanks.
>
> Jiong Zhang
>  The email message (and any attachments) is for the sole use of the intended recipient(s) and may contain confidential information.  Any unauthorized review, use, disclosure or distribution is prohibited.  If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message (and any attachments).  Thank You.
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Weiwei Shi, Ph.D
Research Scientist
GeneGO, Inc.

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III


From rh at family-krueger.com  Wed Jun 27 22:13:26 2007
From: rh at family-krueger.com (Knut Krueger)
Date: Wed, 27 Jun 2007 22:13:26 +0200
Subject: [R] running saved scripts
In-Reply-To: <8d027c80f93ee84a943aa733992d2286@mail.chori.org>
References: <8d027c80f93ee84a943aa733992d2286@mail.chori.org>
Message-ID: <4682C4E6.5070103@family-krueger.com>

Jiong Zhang, PhD schrieb:
> Hi All,
>
> I have a rather naive question.  I need to run some simple calculations
> such as read.table, resid, and quantile on a data file.  How can I save
> these commands in a text file and ask R to run this text file?  Thanks.
>
>   
There is a very comfortable editor including run functions (run all, run 
marked, run until window end and run line by line) available:
http://www.sciviews.org/Tinn-R/
And you can use the R-Editor (in the Menu: File->  new script)
There you can run the marked code or line by line with STGR R

Knut


From Cougar_711 at msn.com  Wed Jun 27 22:38:31 2007
From: Cougar_711 at msn.com (Cougar)
Date: Wed, 27 Jun 2007 16:38:31 -0400
Subject: [R] SEM model fit
Message-ID: <BAY144-DAV62DDC80CB1AE7058E5469A00A0@phx.gbl>


 I wonder if someone could explain why, when I perform confirmatory
factor-analysis model using polychoric correlations why I do not get an
estimated confidence interval for the RMSEA.  My experience with these type
models is that I would obtain a confidence interval estimate.  I did not get
any warning messages with the output.

RESULTS:

Model Chisquare =  1374   Df =  185 Pr(>Chisq) = 0
 Chisquare (null model) =  12284   Df =  210
 Goodness-of-fit index =  0.903
 Adjusted goodness-of-fit index =  0.88
 RMSEA index =  0.0711   90% CI: (NA, NA)
 Bentler-Bonnett NFI =  0.888
 Tucker-Lewis NNFI =  0.888
 Bentler CFI =  0.902
 SRMR =  0.0682
 BIC =  51.4 


SYNTAX

rm(sem.enf.rq)
mdl.rq <- specify.model()
enf                   -> law2,      NA,       1
enf                   -> law3,      lam2,     1
enf                   -> law4,      lam3,     1
enf                   <-> enf,      psi1,     0.6
law2                  <-> law2,     theta1,   0.3
law3                  <-> law3,     theta2,   0.3
law4                  <-> law4,     theta3,   0.5
gender                -> enf,       a1,       0.2
incomex               -> enf,       a2,       0.2
oftdrnkr              -> enf,       a3,       0.2
attn                  -> nvatt,     NA,       1
attn                  -> crimatt,   lam4,     1.3
attn                  -> asltatt,   lam5,     1.2
attn                  <-> attn,     psi2,     0.5
nvatt                 <-> nvatt,    theta4,   0.5
crimatt               <-> crimatt,  theta5,   0.1
asltatt               <-> asltatt,  theta6,   0.2
gender                -> attn,      a4,       0.2
acon                   -> acon1,    NA,       1
acon                   -> acon2,    lam4,     1.5
acon                   <-> acon,    psi2,     0.1
mcon                   -> mvcon1,   NA,       1
mcon                   -> mvcon2,   lam5,     1
mcon                   <-> mcon,    psi3,     0.3
ocon                   -> oicon1,   NA,       1
ocon                   -> oicon2,   lam6,     1
ocon                   <-> ocon,    psi4,     0.2
con                    -> acon,     NA,       1
con                    -> mcon,     lam7,     0.8
con                    -> ocon,     lam8,     0.9
con                   <-> con,     psi5,     0.3
acon1                 <-> acon1,   theta7,   0.4
acon2                 <-> acon2,   theta8,   0.2
mvcon1                <-> mvcon1,  theta9,   0.2
mvcon2                <-> mvcon2,  theta10,   0.3
oicon1                <-> oicon1,  theta11,   0.2
oicon2                <-> oicon2,  theta12,   0.3
gender                -> con,      a5,       0.1
incomex               -> con,      a6,       -0.1
oftdrnkr              -> con,      a7,       -0.2
attn                  -> con,      gam1,     0.2
sev                   -> aophys,   NA,        1
sev                   -> mvphys,   NA,        1
sev                   -> oiphys,   NA,        1
sev                   <-> sev,     psi6,      0.5
aophys                <-> aophys,  theta13,    0.5
mvphys                <-> mvphys,  theta14,    0.5
oiphys                <-> oiphys,  theta14,    0.5
con                   -> sev,      gam3,       0.8
prev                  -> mvpct,    NA,        1
prev                  -> oipct,    NA,        1
prev                  -> alcpct,   NA,        1
prev                  <-> prev,    psi8,      0.4
mvpct                 <-> mvpct,   theta15,    0.5
oipct                 <-> oipct,   theta15,    0.5
alcpct                <-> alcpct,  theta15,    0.5
con                   -> prev,     gam5,       0.8 
prev                  -> enf,      gam6,       0.4

sem.enf.rq <- sem(ram = mdl.rq, S = hcor(dx),  N = nrow(dx), obs.v =
names(dx), raw = F, fixed = names(dx)[4:6], par.size = 's', maxiter = 1e3,
analytic = F, gradtol = 1e-10)  ##set raw to False
summary(obj = sem.enf.rq, dig = 3, conf = 0.9) 

Respectfully,

Frank Lawrence


From waverley.paloalto at gmail.com  Wed Jun 27 22:56:38 2007
From: waverley.paloalto at gmail.com (Waverley)
Date: Wed, 27 Jun 2007 13:56:38 -0700
Subject: [R] exaustive subgrouping or combination
Message-ID: <8ee9d8f20706271356m39480855seebb0e3d18138a05@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070627/bdc8fb08/attachment.pl 

From gonzalezperezmanuel at gmail.com  Wed Jun 27 23:01:00 2007
From: gonzalezperezmanuel at gmail.com (Manuel)
Date: Wed, 27 Jun 2007 23:01:00 +0200
Subject: [R] running Rcmdr
In-Reply-To: <128344.49950.qm@web56610.mail.re3.yahoo.com>
References: <128344.49950.qm@web56610.mail.re3.yahoo.com>
Message-ID: <4682D00C.6010007@gmail.com>

Yes, of course, i know it, and i have installed all packages i need, but 
this is not what i am searching.
I want to do that only with a command line without have to type only 
first R  and after library("Rcmdr");  i only want to type something like 
R < library("Rcmdr") but i know it?s doesn?t work and i?m looking for 
something like that.
I hope you have already understood my question. Thank you

Felipe Carrillo escribi?:
> If you have already installed Rcmdr from the internet (Cran site) then 
> when you open R window if you type         library(Rcmdr)     you 
> should see the R commander window and use it just like you would use R 
> command window.
>
> */Manuel <gonzalezperezmanuel en gmail.com>/* wrote:
>
>     Thanks for your answer, but i think i dont do correctly my question.
>     I need the command line to run Rmdr, like that:
>     R < Rcmdr or R < loadRcmdr.R where loadRcmdr has "library("Rcmdr").
>     or something like that.
>     I tried the last example, but when Rcmdr is executed, later it is
>     closed.
>     About RProfile.site, i dont know what i have to change. If you
>     think its
>     useful to me, please explain me.
>     Thanks.
>
>     Felipe Carrillo escribi?:
>     > First, you need to install the Rcmdr packages and then in the R
>     > Command window or Tinn-R window type "library(Rcmdr)" without the
>     > quotation marks. In addition, if you want Rcmdr to start
>     automatically
>     > everytime you start R, go to the following path C:\Program
>     > Files\R\R-2.5.0\etc\RProfile.site if you installed R in program
>     files,
>     > otherwise follow your own path and type the same command
>     > library(Rcmdr) and the R commander window should pop up
>     everytime you
>     > start R
>     >
>     >
>     > */Manuel /* wrote:
>     >
>     > Hi to all,
>     >
>     > i want to know how can run Rcmdr automatically , or how to load a
>     > library in the call of R
>     >
>     > greetings
>     >
>     > ______________________________________________
>     > R-help en stat.math.ethz.ch mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide
>     > http://www.R-project.org/posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
>     >
>     >
>     >
>     ------------------------------------------------------------------------
>     > Choose the right car based on your needs. Check out Yahoo! Autos
>     new
>     > Car Finder tool.
>     >
>
>     ______________________________________________
>     R-help en stat.math.ethz.ch mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>
> ------------------------------------------------------------------------
> Park yourself in front of a world of choices in alternative vehicles.
> Visit the Yahoo! Auto Green Center. 
> <http://us.rd.yahoo.com/evt=48246/*http://autos.yahoo.com/green_center/;_ylc=X3oDMTE5cDF2bXZzBF9TAzk3MTA3MDc2BHNlYwNtYWlsdGFncwRzbGsDZ3JlZW4tY2VudGVy>


From michael.drescher at ontario.ca  Wed Jun 27 23:15:00 2007
From: michael.drescher at ontario.ca (Drescher, Michael (MNR))
Date: Wed, 27 Jun 2007 17:15:00 -0400
Subject: [R] error message survreg.fit
Message-ID: <76D2AA307C39054DBA8BD42DE44E71A4A9A2F5@CTSPITDCEMMVX14.cihs.ad.gov.on.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070627/e77f0a51/attachment.pl 

From aa2007r at gmail.com  Wed Jun 27 23:18:04 2007
From: aa2007r at gmail.com (AA)
Date: Wed, 27 Jun 2007 17:18:04 -0400
Subject: [R] Matlab end operator
References: <13225635.24491182965129984.JavaMail.tomcat@rainier>
	<dea6cb960706271143g28cf675el12831208c4f0d55a@mail.gmail.com>
Message-ID: <040801c7b900$a6a77780$3927a8c0@treesdalellc.net>

Hi Markus, Christophe

I also use both matlab and R.
I agree with Christophe: you can define the 'end' functionality by nrow or 
length
also have a look at the following link that may be useful.
http://mathesaurus.sourceforge.net/octave-r.html
good luck
AA.
----- Original Message ----- 
From: "Christophe Pallier" <christophe at pallier.org>
To: "Markus Loecher" <loecher at eden.rutgers.edu>
Cc: <r-help at stat.math.ethz.ch>
Sent: Wednesday, June 27, 2007 2:43 PM
Subject: Re: [R] Matlab end operator


> Hello Markus,
>
> On 6/27/07, Markus Loecher <loecher at eden.rutgers.edu> wrote:
>>
>> Dear list members,
>> I use both R and Matlab and find that each has its own strengths. Matlab
>> definitely has the edge when it comes to the interactivity of its graphs.
>
>
> I also use both. R definitely has the edge when it comes to do perform
> statistical data analyses :)
> (and also when you consider the price...)
>
> In addition I find the little operator end extremely useful in indexing
>> arrays. (as in x(1:end,) )
>
>
> You mean 'x(1:end,1:end)' or 'x(:,:)'  (':' is equivalent to "1:end")
>
> When I go from R to Matlab, I tend to forget to type the ':' ("a[,2]" in R
> is "a(:,2)" in Matlab.)
>
> The interest of 'end' is clearer when the starting index is larger than 1 
> as
> in, e.g., 'x(2:end)'
>
> Yet note that in R, you can use negative indexes:
>
>  x[-1]   is the R equivalent of  Matlab's x(2:end)
>
>  x[-(1:(n-1))] is equivalent to x(n:end)
>
>
> I agree that R syntax may be a bit less "elegant" in this particular
> situation (but try to write the equivalent of a[-2,] in Matlab)
> Personally, I would stick to "x[n:length(x)]" (or "a[n:nrow(a),]" for a
> matrix). Anyway this kind of code would probably appear inside a loop and 
> I
> would put the numbers of rows or columns in variables if there are needed
> more than once.
>
> Best,
>
> -- 
> Christophe Pallier
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From edd at debian.org  Wed Jun 27 23:42:25 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 27 Jun 2007 16:42:25 -0500
Subject: [R] running Rcmdr
In-Reply-To: <4682D00C.6010007@gmail.com>
References: <128344.49950.qm@web56610.mail.re3.yahoo.com>
	<4682D00C.6010007@gmail.com>
Message-ID: <18050.55745.33920.412115@basebud.nulle.part>


Either one of these works under Linux. 'r' is our own littler (see Google for
it), Rscript comes with R 2.5.0 or greater

$ r -e 'suppressMessages(library(Rcmdr)); while (TRUE) Sys.sleep(1)'

$ Rscript -e 'suppressMessages(library(Rcmdr)); while (TRUE) Sys.sleep(1)'

Hth, Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From cryan at binghamton.edu  Thu Jun 28 00:50:03 2007
From: cryan at binghamton.edu (Christopher W. Ryan)
Date: Wed, 27 Jun 2007 17:50:03 -0500
Subject: [R] running Rcmdr
In-Reply-To: <4682D00C.6010007@gmail.com>
References: <128344.49950.qm@web56610.mail.re3.yahoo.com>
	<4682D00C.6010007@gmail.com>
Message-ID: <4682E99B.2020502@binghamton.edu>

I am very much a novice R user, and this is my first post to the List,
but given that disclaimer, perhaps you could put library(Rcmdr) as a
line in your Rprofile.site file?  I think this contains commands that
are run every time R is opened.  [At least, I noticed after I installed
my Tinn-R and got it to communicate with R, that certain R packages
necessary for use of Tinn-R now get run every time I open Tinn-R (and R
opens with it.)]

That way, typing R on the command line (might!) run Rcmdr too.

--Chris
Christopher W. Ryan, MD
SUNY Upstate Medical University Clinical Campus at Binghamton
40 Arch Street, Johnson City, NY  13790
cryanatbinghamtondotedu
PGP public keys available at http://home.stny.rr.com/ryancw/

"If you want to build a ship, don't drum up the men to gather wood,
divide the work and give orders. Instead, teach them to yearn for the
vast and endless sea."  [Antoine de St. Exupery]

Manuel wrote:
> Yes, of course, i know it, and i have installed all packages i need, but 
> this is not what i am searching.
> I want to do that only with a command line without have to type only 
> first R  and after library("Rcmdr");  i only want to type something like 
> R < library("Rcmdr") but i know it?s doesn?t work and i?m looking for 
> something like that.
> I hope you have already understood my question. Thank you
> 
> Felipe Carrillo escribi?:
>> If you have already installed Rcmdr from the internet (Cran site) then 
>> when you open R window if you type         library(Rcmdr)     you 
>> should see the R commander window and use it just like you would use R 
>> command window.
>>
>> */Manuel <gonzalezperezmanuel at gmail.com>/* wrote:
>>
>>     Thanks for your answer, but i think i dont do correctly my question.
>>     I need the command line to run Rmdr, like that:
>>     R < Rcmdr or R < loadRcmdr.R where loadRcmdr has "library("Rcmdr").
>>     or something like that.
>>     I tried the last example, but when Rcmdr is executed, later it is
>>     closed.
>>     About RProfile.site, i dont know what i have to change. If you
>>     think its
>>     useful to me, please explain me.
>>     Thanks.
>>
>>     Felipe Carrillo escribi?:
>>     > First, you need to install the Rcmdr packages and then in the R
>>     > Command window or Tinn-R window type "library(Rcmdr)" without the
>>     > quotation marks. In addition, if you want Rcmdr to start
>>     automatically
>>     > everytime you start R, go to the following path C:\Program
>>     > Files\R\R-2.5.0\etc\RProfile.site if you installed R in program
>>     files,
>>     > otherwise follow your own path and type the same command
>>     > library(Rcmdr) and the R commander window should pop up
>>     everytime you
>>     > start R
>>     >
>>     >
>>     > */Manuel /* wrote:
>>     >
>>     > Hi to all,
>>     >
>>     > i want to know how can run Rcmdr automatically , or how to load a
>>     > library in the call of R
>>     >
>>     > greetings
>>     >
>>     > ______________________________________________
>>     > R-help at stat.math.ethz.ch mailing list
>>     > https://stat.ethz.ch/mailman/listinfo/r-help
>>     > PLEASE do read the posting guide
>>     > http://www.R-project.org/posting-guide.html
>>     > and provide commented, minimal, self-contained, reproducible code.
>>     >
>>     >
>>     >
>>     ------------------------------------------------------------------------
>>     > Choose the right car based on your needs. Check out Yahoo! Autos
>>     new
>>     > Car Finder tool.
>>     >
>>
>>     ______________________________________________
>>     R-help at stat.math.ethz.ch mailing list
>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>     PLEASE do read the posting guide
>>     http://www.R-project.org/posting-guide.html
>>     and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> ------------------------------------------------------------------------
>> Park yourself in front of a world of choices in alternative vehicles.
>> Visit the Yahoo! Auto Green Center. 
>> <http://us.rd.yahoo.com/evt=48246/*http://autos.yahoo.com/green_center/;_ylc=X3oDMTE5cDF2bXZzBF9TAzk3MTA3MDc2BHNlYwNtYWlsdGFncwRzbGsDZ3JlZW4tY2VudGVy>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From gunter.berton at gene.com  Wed Jun 27 23:55:34 2007
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 27 Jun 2007 14:55:34 -0700
Subject: [R] exaustive subgrouping or combination
In-Reply-To: <8ee9d8f20706271356m39480855seebb0e3d18138a05@mail.gmail.com>
Message-ID: <008001c7b905$e3aa1ca0$4d908980@gne.windows.gene.com>

Do you realize that for n items, there are 2^(n-1) such groups -- since you
essentially want all possible subsets divided by 2: all possible subsets and
their complements repeats each split twice, backwards and forwards. So this
will quickly become ummm... rather large.

If you really want to do this, one lazy but inefficient way I can think of
is to use expand.grid() to generate your subsets. Here's a toy example that
shows you how with n = 4.

## generate a list with four components each of which 
## is c(TRUE,FALSE) -- note that a data.frame is a list

z <- data.frame(matrix(rep(c(TRUE,FALSE),4),nrow=2)

## Now use expand.grid to get all 2^4 possible 4 vectors as rows

ix <- do.call(expand.grid,z)

## This is essentially what you want. 

apply(ix[1:8,],1,function(x)(1:4)[x])

## gives you the list of first splits, while apply(ix[16:9],... gives the
complements (note reversal of order).


 
Bert Gunter
Genentech Nonclinical Statistics


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Waverley
Sent: Wednesday, June 27, 2007 1:57 PM
To: r-help at stat.math.ethz.ch
Subject: [R] exaustive subgrouping or combination

Dear Colleagues,

I am looking for a package or previous implemented R to subgroup and
exaustively divide a vector of squence into 2 groups.

For example:

1, 2, 3, 4

I want to have a group of
1, (2,3,4)
(1,2), (3,4)
(1,3), (2,4)
(1,4), (2,3)
(1,2,3), 4
(2,3), (1,4)
...

Can someone help me as how to implement this?  I get some imaginary problem
when the sequence becomes large.

Thanks much in advance.

-- 
Waverley @ Palo Alto

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From duvvuru.suman at gmail.com  Thu Jun 28 00:00:05 2007
From: duvvuru.suman at gmail.com (suman Duvvuru)
Date: Wed, 27 Jun 2007 18:00:05 -0400
Subject: [R] Correlation ratio
Message-ID: <bac8a0820706271500k50e5cd80pfb3729310544430a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070627/f84a94a8/attachment.pl 

From luo_weijun at yahoo.com  Thu Jun 28 00:11:44 2007
From: luo_weijun at yahoo.com (Luo Weijun)
Date: Wed, 27 Jun 2007 15:11:44 -0700 (PDT)
Subject: [R] Loading problem with XML_1.9
Message-ID: <776851.76466.qm@web32513.mail.mud.yahoo.com>

Hello all,
I have loading problem with XML_1.9 under 64 bit
R2.3.1, which I got from http://R.research.att.com/.
XML_1.9 works fine under 32 bit R2.5.0. I thought that
could be installation problem, and I tried
install.packages or biocLite, every time the package
installed fine, except some warning messages below:
ld64 warning: in /usr/lib/libxml2.dylib, file does not
contain requested architecture
ld64 warning: in /usr/lib/libz.dylib, file does not
contain requested architecture
ld64 warning: in /usr/lib/libiconv.dylib, file does
not contain requested architecture
ld64 warning: in /usr/lib/libz.dylib, file does not
contain requested architecture
ld64 warning: in /usr/lib/libxml2.dylib, file does not
contain requested architecture

Here is the error messages I got, when XML is loaded:
> library(XML)
Error in dyn.load(x, as.logical(local),
as.logical(now)) : 
        unable to load shared library
'/usr/local/lib64/R/library/XML/libs/XML.so':
  dlopen(/usr/local/lib64/R/library/XML/libs/XML.so,
6): Symbol not found: _xmlMemDisplay
  Referenced from:
/usr/local/lib64/R/library/XML/libs/XML.so
  Expected in: flat namespace
Error: .onLoad failed in 'loadNamespace' for 'XML'
Error: package/namespace load failed for 'XML'

I understand that it has been pointed out that
Sys.getenv("PATH") needs to be revised in the file
XML/R/zzz.R, but I can???t even find that file under
XML/R/ directory. Does anybody have any idea what
might be the problem, and how to solve it? Thanks a
lot!
BTW, the reason I need to use R64 is that I have
memory limitation issue with R 32 bit version when I
load some very large XML trees. 

Session information
> sessionInfo()
Version 2.3.1 Patched (2006-06-27 r38447) 
powerpc64-apple-darwin8.7.0 

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices"
"utils"     "datasets" 
[7] "base"     

Weijun


From croero at hotmail.com  Thu Jun 28 00:51:41 2007
From: croero at hotmail.com (Bruce Willy)
Date: Wed, 27 Jun 2007 22:51:41 +0000
Subject: [R]  Gaussian elimination - singular matrix
Message-ID: <BAY126-W1047995AD827B18A68A6D3C90A0@phx.gbl>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20070627/c9c6e49f/attachment.pl 

From croero at hotmail.com  Thu Jun 28 00:59:38 2007
From: croero at hotmail.com (Bruce Willy)
Date: Wed, 27 Jun 2007 22:59:38 +0000
Subject: [R] Gaussian elimination - singular matrix
Message-ID: <BAY126-W44248566BC145CE474E8FFC90A0@phx.gbl>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20070627/8e34fc9a/attachment.pl 

From adschai at optonline.net  Thu Jun 28 01:41:21 2007
From: adschai at optonline.net (adschai at optonline.net)
Date: Wed, 27 Jun 2007 23:41:21 +0000 (GMT)
Subject: [R] How to discard data out of polr object
Message-ID: <e2a2b0681ced1.4682f5a1@optonline.net>

Hi,

I would like to discard in-sample data that are stored in the polr object out after estimation. All I need are only the coefficients for estimation. I'm wondering if there is anyway to do this? Thank you.

- adschai


From jdnewmil at dcn.davis.ca.us  Thu Jun 28 01:44:40 2007
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 27 Jun 2007 16:44:40 -0700 (PDT)
Subject: [R] Correlation ratio
In-Reply-To: <bac8a0820706271500k50e5cd80pfb3729310544430a@mail.gmail.com>
Message-ID: <Pine.GSO.4.44.0706271643001.26994-100000@wheel.dcn.davis.ca.us>

On Wed, 27 Jun 2007, suman Duvvuru wrote:

> Hi,
>
> I wanted to know how to compute the correlation ratio (eta) between two
> variables using R. Is there any function to compute the correlation ratio.
> Any help will be very much appreciated.

help.search("correlation")
?cancor
?lm

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From adschai at optonline.net  Thu Jun 28 01:51:19 2007
From: adschai at optonline.net (adschai at optonline.net)
Date: Wed, 27 Jun 2007 23:51:19 +0000 (GMT)
Subject: [R] levelplot in lattice
Message-ID: <e32ada36194e5.4682f7f7@optonline.net>

Hi,

I'm new to lattice. So please kindly be patient with me.
I'm trying to arrange groups of levelplots into 3 rows as follows:

Row1: Probabilities as functions of x and y, and conditioned on an event factor vector factor("a","b","c")

Row2: Number of days as functions of  x and y, and conditioned on, again the same event factor("a","b","c")

Row2: Costs as functions of  x and y, and conditioned on, again the same event factor("a","b","c")

I tried the following:

windows();
par(mfrow=c(3,1));
levelplot(z ~ x*y|events, probDat);
levelplot(z ~ x*y|events, daysDat);
levelplot(z ~ x*y|events, costDat);

It does not do what I want. It replace the previous plot every time I call a new levelplot. I can't put them into the same matrix and plot them all at once because the scale of each data type is very different, i.e.g probability=c(0,1), days=c(0,10), etc. I'm wondering if you could suggest a way to solve this problem.

Also, if I would like to put in mathematical notation on the top strip of the plot instead of using text in my events factor vector, what can I do? 

Thank you so much in advance.

- adschai


From jdnewmil at dcn.davis.ca.us  Thu Jun 28 02:00:01 2007
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 27 Jun 2007 17:00:01 -0700 (PDT)
Subject: [R] exaustive subgrouping or combination
In-Reply-To: <8ee9d8f20706271356m39480855seebb0e3d18138a05@mail.gmail.com>
Message-ID: <Pine.GSO.4.44.0706271658170.56-100000@wheel.dcn.davis.ca.us>

On Wed, 27 Jun 2007, Waverley wrote:

> Dear Colleagues,
>
> I am looking for a package or previous implemented R to subgroup and
> exaustively divide a vector of squence into 2 groups.
>
> For example:
>
> 1, 2, 3, 4
>
> I want to have a group of
> 1, (2,3,4)
> (1,2), (3,4)
> (1,3), (2,4)
> (1,4), (2,3)
> (1,2,3), 4
> (2,3), (1,4)
> ...
>
> Can someone help me as how to implement this?

help.search("combinations")
?combn

Have you read the posting guide mentioned at the bottom of
each message on the list?

> I get some imaginary problem
> when the sequence becomes large.
>
> Thanks much in advance.
>
> --
> Waverley @ Palo Alto
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...2k


From deepayan.sarkar at gmail.com  Thu Jun 28 02:00:17 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Wed, 27 Jun 2007 17:00:17 -0700
Subject: [R] levelplot in lattice
In-Reply-To: <e32ada36194e5.4682f7f7@optonline.net>
References: <e32ada36194e5.4682f7f7@optonline.net>
Message-ID: <eb555e660706271700r356b5f00h627d89b59c745183@mail.gmail.com>

On 6/27/07, adschai at optonline.net <adschai at optonline.net> wrote:
> Hi,
>
> I'm new to lattice. So please kindly be patient with me.
> I'm trying to arrange groups of levelplots into 3 rows as follows:
>
> Row1: Probabilities as functions of x and y, and conditioned on an event factor vector factor("a","b","c")
>
> Row2: Number of days as functions of  x and y, and conditioned on, again the same event factor("a","b","c")
>
> Row2: Costs as functions of  x and y, and conditioned on, again the same event factor("a","b","c")
>
> I tried the following:
>
> windows();
> par(mfrow=c(3,1));
> levelplot(z ~ x*y|events, probDat);
> levelplot(z ~ x*y|events, daysDat);
> levelplot(z ~ x*y|events, costDat);
>
> It does not do what I want. It replace the previous plot every time I call a new levelplot. I can't put them into the same matrix and plot them all at once because the scale of each data type is very different, i.e.g probability=c(0,1), days=c(0,10), etc. I'm wondering if you could suggest a way to solve this problem.
>

It all depends on the details. Please give a small reproducible example.

> Also, if I would like to put in mathematical notation on the top strip of the plot instead of using text in my events factor vector, what can I do?

Use expressions (see ?plotmath). Again, please give details.

-Deepayan


From m_olshansky at yahoo.com  Thu Jun 28 02:10:36 2007
From: m_olshansky at yahoo.com (Moshe Olshansky)
Date: Wed, 27 Jun 2007 17:10:36 -0700 (PDT)
Subject: [R] Gaussian elimination - singular matrix
In-Reply-To: <BAY126-W44248566BC145CE474E8FFC90A0@phx.gbl>
Message-ID: <617938.9931.qm@web32208.mail.mud.yahoo.com>

All the nontrivial solutions to AX = 0 are the
eigenvectors of A corresponding to eigenvalue 0 (try
eigen function).
The non-negative solution may or may not exist.  For
example, if A is a 2x2 matrix Aij = 1 for 1 <=i,j <=2
then the only non-trivial solution to AX = 0 is X =
a*(1,-1), where a is any nonzero scalar.  So in this
case there is no non-negative solution. 
Let X1, X2,...,Xk be all the k independent
eigenvectors corresponding to eigenvalue 0, i.e. AXi =
0 for i = 1,2,...,k.  Any linear combination of them,
X = X1,...,Xk, i.e. a1*X1 + ... + ak*Xk is also a
solution of AX = 0.  Let B be a matrix whose COLUMNS
are the vectors X1,...,Xk (B = (X1,...,Xk).  Then
finding a1,...,ak for which all elements of X are
non-negative is equivalent to finding a vector a =
(a1,...,ak) such that B*a >= 0.  Of course a =
(0,...,0) is a solution.  The question whether there
exists another one.  Try to solve the following Linear
Programming problem:
max a1
subject to B*a >= 0
(you can start with a = (0,...,0) which is a feasible
solution).
If you get a non-zero solution fine.  If not try to
solve
min a1
subject to B*a >= 0
if you still get 0 try this with max a2, then min a2,
max a3, min a3, etc.  If all the 2k problems have only
0 solution then there are no nontrivial nonnegative
solutions.  Otherwise you will find it.
Instead of 2k LP (Linear Programming) problems you can
look at one QP (Quadratic Programming) problem:
max a1^2 + a2^2 + ... + ak^2 
subject to B*a >= 0
If there is a nonzero solution a = (a1,...,ak) then X
= a1&X1 +...+ak*Xk is what you are looking for. 
Otherwise there is no nontrivial nonnegative solution.

--- Bruce Willy <croero at hotmail.com> wrote:

> 
> I am sorry, there is just a mistake : the solution
> cannot be unique (because it is a vectorial space)
> (but then I might normalize it)
>  
> can R find one anyway ?
>  
> This is equivalent to finding an eigenvector in
> fact> From: croero at hotmail.com> To:
> r-help at stat.math.ethz.ch> Date: Wed, 27 Jun 2007
> 22:51:41 +0000> Subject: [R] Gaussian elimination -
> singular matrix> > > Hello,> > I hope it is not a
> too stupid question.> > I have a singular matrix A
> (so not invertible).> > I want to find a nontrivial
> nonnegative solution to AX=0 (kernel of A)> > It is
> a special matrix A (so maybe this nonnegative
> solution is unique)> > The authors of the article
> suggest a Gaussian elimination method> > Do you know
> if R can do that automatically ? I have seen that
> "solve" has an option "LAPACK" but it does not seem
> to work with me :(> > Thank you very much>
>
_________________________________________________________________>
> Le blog Messenger de Michel, candidat de la Nouvelle
> Star : analyse, news, coulisses
 A d?couvrir !> >
> [[alternative HTML version deleted]]> 
>
_________________________________________________________________
> Le blog Messenger de Michel, candidat de la Nouvelle
> Star : analyse, news, coulisses
 A d?couvrir !
> 
> 	[[alternative HTML version deleted]]
> 
> > ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From magno_yu at ml.com  Thu Jun 28 02:16:39 2007
From: magno_yu at ml.com (yoooooo)
Date: Wed, 27 Jun 2007 17:16:39 -0700 (PDT)
Subject: [R] restructuring matrix
Message-ID: <11334950.post@talk.nabble.com>


Hi all, 

    let's say I have matrix

People    Desc    Value
Mary      Height    50
Mary      Weight   100
Fanny    Height     60
Fanny     Height    200

Is there a quick way to form the following matrix? 

People   Height    Weight
Mary      50         100
Fanny     60        200

(Assuming I don't know the length of people/desc and let's say these are
characters matrix.. I tried play with row(), col(), etc.. but I don't seem
to find like a duplicate match function... 
I'm trying to write some one/two liner that convert my resulting matrix to
vector and pick the appropriate fields.. etc )

Thanks!

-- 
View this message in context: http://www.nabble.com/restructuring-matrix-tf3991741.html#a11334950
Sent from the R help mailing list archive at Nabble.com.


From m_olshansky at yahoo.com  Thu Jun 28 03:02:53 2007
From: m_olshansky at yahoo.com (Moshe Olshansky)
Date: Wed, 27 Jun 2007 18:02:53 -0700 (PDT)
Subject: [R] restructuring matrix
In-Reply-To: <11334950.post@talk.nabble.com>
Message-ID: <181678.80915.qm@web32215.mail.mud.yahoo.com>

If your original matrix is A then 
unique(A$People) and unique(A$Desc) 
will produce a vector of different people and a vector
of different descriptions.

--- yoooooo <magno_yu at ml.com> wrote:

> 
> Hi all, 
> 
>     let's say I have matrix
> 
> People    Desc    Value
> Mary      Height    50
> Mary      Weight   100
> Fanny    Height     60
> Fanny     Height    200
> 
> Is there a quick way to form the following matrix? 
> 
> People   Height    Weight
> Mary      50         100
> Fanny     60        200
> 
> (Assuming I don't know the length of people/desc and
> let's say these are
> characters matrix.. I tried play with row(), col(),
> etc.. but I don't seem
> to find like a duplicate match function... 
> I'm trying to write some one/two liner that convert
> my resulting matrix to
> vector and pick the appropriate fields.. etc )
> 
> Thanks!
> 
> -- 
> View this message in context:
>
http://www.nabble.com/restructuring-matrix-tf3991741.html#a11334950
> Sent from the R help mailing list archive at
> Nabble.com.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From rossiter at itc.nl  Thu Jun 28 03:06:04 2007
From: rossiter at itc.nl (D G Rossiter)
Date: Wed, 27 Jun 2007 21:06:04 -0400
Subject: [R] Sweave bug? when writing figures / deleting variable in chunk
Message-ID: <4E1EDA98-6048-4144-8168-6EC48D992C20@itc.nl>

I have found a quite strange (to me) behaviour in Sweave. It only  
occurs in the following situation:

1. define a variable in one chunk
2. use it within a subsequent figure-generating chunk
3. delete it at the end of that same chunk
Then the Sweave driver chokes, not finding the variable name when  
generating the figure

Example:

% document bug2.Rnw
\documentclass{article}
\usepackage{Sweave}
\begin{document}
\SweaveOpts{eps=false}
<<>>=
sel <- 1:5
@
<<fig=T>>=
plot(trees[sel,])
rm(sel)
@
\end{document}

Try to sweave:

 > Sweave("bug2.Rnw")
Writing to file bug2.tex
Processing code chunks ...
1 : echo term verbatim
2 : echo term verbatim pdf
Error: no function to return from, jumping to top level
Error in plot(trees[sel, ]) : error in evaluating the argument 'x' in  
selecting a method for function 'plot'
Error in driver$runcode(drobj, chunk, chunkopts) :
	Error in plot(trees[sel, ]) : error in evaluating the argument 'x'  
in selecting a method for function 'plot'

The generated .tex is complete up through the rm() but no figure is  
generated. The file bug2-002.pdf is incomplete (corrupt).

...
\begin{Schunk}
\begin{Sinput}
 > plot(trees[sel, ])
 > rm(sel)
\end{Sinput}
\end{Schunk}

The following ALL eliminate the problem:

0. Executing the code directly, also with ESS
1. <<fig=F>>
2. moving rm(sel) to a separate, later code chunk
3. Stangle the source and then source it
4. don't use a variable, i.e. in this case:  plot(trees[1:5,])

It seems that Sweave is executing the rm(sel)  before it uses it in  
the trees[sel,].

Technical details: R 2.5.0, Mac OS X 10.4.10, PPC
Same behaviour in stand-alone R for Mac and for R within Aquamacs  
using ESS

Workaround: I am putting any deletions into a later code chunk. This  
only has the disadvantage of making more chunks, so now that I know  
what's happening it's no big deal. But it's driving me crazy... am I  
missing something? Thanks!

D. G. Rossiter
Senior University Lecturer
Department of Earth Systems Analysis
International Institute for Geo-Information Science and Earth  
Observation (ITC)
Hengelosestraat 99
PO Box 6, 7500 AA Enschede, The Netherlands
Phone:	+31-(0)53 4874 499
Fax:	+31-(0)53 4874 336
mailto:rossiter--at--itc.nl,  Internet: http://www.itc.nl/personal/ 
rossiter


From magno_yu at ml.com  Thu Jun 28 03:15:52 2007
From: magno_yu at ml.com (yoooooo)
Date: Wed, 27 Jun 2007 18:15:52 -0700 (PDT)
Subject: [R] restructuring matrix
In-Reply-To: <181678.80915.qm@web32215.mail.mud.yahoo.com>
References: <11334950.post@talk.nabble.com>
	<181678.80915.qm@web32215.mail.mud.yahoo.com>
Message-ID: <11335437.post@talk.nabble.com>


Yea... let's say I constructed a matrix with rownames/colnames be those
unique elements.. then what should I do? I don't want to do mapply, etc to
find the field.. I'm wondering if there's a smarter way using row/col..
etc... Thanks!




Moshe Olshansky-2 wrote:
> 
> If your original matrix is A then 
> unique(A$People) and unique(A$Desc) 
> will produce a vector of different people and a vector
> of different descriptions.
> 
> --- yoooooo <magno_yu at ml.com> wrote:
> 
>> 
>> Hi all, 
>> 
>>     let's say I have matrix
>> 
>> People    Desc    Value
>> Mary      Height    50
>> Mary      Weight   100
>> Fanny    Height     60
>> Fanny     Height    200
>> 
>> Is there a quick way to form the following matrix? 
>> 
>> People   Height    Weight
>> Mary      50         100
>> Fanny     60        200
>> 
>> (Assuming I don't know the length of people/desc and
>> let's say these are
>> characters matrix.. I tried play with row(), col(),
>> etc.. but I don't seem
>> to find like a duplicate match function... 
>> I'm trying to write some one/two liner that convert
>> my resulting matrix to
>> vector and pick the appropriate fields.. etc )
>> 
>> Thanks!
>> 
>> -- 
>> View this message in context:
>>
> http://www.nabble.com/restructuring-matrix-tf3991741.html#a11334950
>> Sent from the R help mailing list archive at
>> Nabble.com.
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained,
>> reproducible code.
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/restructuring-matrix-tf3991741.html#a11335437
Sent from the R help mailing list archive at Nabble.com.


From deepayan.sarkar at gmail.com  Thu Jun 28 03:31:20 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Wed, 27 Jun 2007 18:31:20 -0700
Subject: [R] Sweave bug? when writing figures / deleting variable in
	chunk
In-Reply-To: <4E1EDA98-6048-4144-8168-6EC48D992C20@itc.nl>
References: <4E1EDA98-6048-4144-8168-6EC48D992C20@itc.nl>
Message-ID: <eb555e660706271831lf11a311p3801576a15451a91@mail.gmail.com>

On 6/27/07, D G Rossiter <rossiter at itc.nl> wrote:
> I have found a quite strange (to me) behaviour in Sweave. It only
> occurs in the following situation:
>
> 1. define a variable in one chunk
> 2. use it within a subsequent figure-generating chunk
> 3. delete it at the end of that same chunk
> Then the Sweave driver chokes, not finding the variable name when
> generating the figure

The reason is that by default, every fig=TRUE chunk is run twice, once
to produce postscript, once for pdf.

-Deepayan


From Achim.Zeileis at wu-wien.ac.at  Thu Jun 28 03:34:58 2007
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Thu, 28 Jun 2007 03:34:58 +0200
Subject: [R] Sweave bug? when writing figures / deleting variable in
 chunk
In-Reply-To: <4E1EDA98-6048-4144-8168-6EC48D992C20@itc.nl>
References: <4E1EDA98-6048-4144-8168-6EC48D992C20@itc.nl>
Message-ID: <20070628033458.e7babf40.Achim.Zeileis@wu-wien.ac.at>

On Wed, 27 Jun 2007 21:06:04 -0400 D G Rossiter wrote:

> I have found a quite strange (to me) behaviour in Sweave. It only  
> occurs in the following situation:
> 
> 1. define a variable in one chunk
> 2. use it within a subsequent figure-generating chunk
> 3. delete it at the end of that same chunk
> Then the Sweave driver chokes, not finding the variable name when  
> generating the figure

Sweave() executes figure chunks more than once because they might
also create printed output. If you create both EPS and PDF graphics, it
executes them three times (print + EPS + PDF). Hence, data
manipulations should be avoided in figure chunks.

I was also once bitten by this when I permuted columns of a table prior
to plotting and never obtained the desired order...

Fritz, maybe this is worth an entry in the FAQ?
Z

> Example:
> 
> % document bug2.Rnw
> \documentclass{article}
> \usepackage{Sweave}
> \begin{document}
> \SweaveOpts{eps=false}
> <<>>=
> sel <- 1:5
> @
> <<fig=T>>=
> plot(trees[sel,])
> rm(sel)
> @
> \end{document}
> 
> Try to sweave:
> 
>  > Sweave("bug2.Rnw")
> Writing to file bug2.tex
> Processing code chunks ...
> 1 : echo term verbatim
> 2 : echo term verbatim pdf
> Error: no function to return from, jumping to top level
> Error in plot(trees[sel, ]) : error in evaluating the argument 'x'
> in selecting a method for function 'plot'
> Error in driver$runcode(drobj, chunk, chunkopts) :
> 	Error in plot(trees[sel, ]) : error in evaluating the
> argument 'x' in selecting a method for function 'plot'
> 
> The generated .tex is complete up through the rm() but no figure is  
> generated. The file bug2-002.pdf is incomplete (corrupt).
> 
> ...
> \begin{Schunk}
> \begin{Sinput}
>  > plot(trees[sel, ])
>  > rm(sel)
> \end{Sinput}
> \end{Schunk}
> 
> The following ALL eliminate the problem:
> 
> 0. Executing the code directly, also with ESS
> 1. <<fig=F>>
> 2. moving rm(sel) to a separate, later code chunk
> 3. Stangle the source and then source it
> 4. don't use a variable, i.e. in this case:  plot(trees[1:5,])
> 
> It seems that Sweave is executing the rm(sel)  before it uses it in  
> the trees[sel,].
> 
> Technical details: R 2.5.0, Mac OS X 10.4.10, PPC
> Same behaviour in stand-alone R for Mac and for R within Aquamacs  
> using ESS
> 
> Workaround: I am putting any deletions into a later code chunk. This  
> only has the disadvantage of making more chunks, so now that I know  
> what's happening it's no big deal. But it's driving me crazy... am I  
> missing something? Thanks!
> 
> D. G. Rossiter
> Senior University Lecturer
> Department of Earth Systems Analysis
> International Institute for Geo-Information Science and Earth  
> Observation (ITC)
> Hengelosestraat 99
> PO Box 6, 7500 AA Enschede, The Netherlands
> Phone:	+31-(0)53 4874 499
> Fax:	+31-(0)53 4874 336
> mailto:rossiter--at--itc.nl,  Internet: http://www.itc.nl/personal/ 
> rossiter
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.
>


From murdoch at stats.uwo.ca  Thu Jun 28 03:34:37 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 27 Jun 2007 21:34:37 -0400
Subject: [R] Sweave bug? when writing figures / deleting variable in
	chunk
In-Reply-To: <4E1EDA98-6048-4144-8168-6EC48D992C20@itc.nl>
References: <4E1EDA98-6048-4144-8168-6EC48D992C20@itc.nl>
Message-ID: <4683102D.4000504@stats.uwo.ca>

On 27/06/2007 9:06 PM, D G Rossiter wrote:
> I have found a quite strange (to me) behaviour in Sweave. It only  
> occurs in the following situation:
> 
> 1. define a variable in one chunk
> 2. use it within a subsequent figure-generating chunk
> 3. delete it at the end of that same chunk
> Then the Sweave driver chokes, not finding the variable name when  
> generating the figure

By default, Sweave runs figure chunks twice (once for pdf, once for 
eps).  They shouldn't change the environment they need to run in.  Not 
sure where this is documented, but it's well known by people who've been 
bitten by it.

Duncan Murdoch


From dunn at usq.edu.au  Thu Jun 28 03:31:44 2007
From: dunn at usq.edu.au (Peter Dunn)
Date: Thu, 28 Jun 2007 11:31:44 +1000
Subject: [R] Sweave bug? when writing figures / deleting variable in
	chunk
In-Reply-To: <4E1EDA98-6048-4144-8168-6EC48D992C20@itc.nl>
References: <4E1EDA98-6048-4144-8168-6EC48D992C20@itc.nl>
Message-ID: <200706281131.44980.dunn@usq.edu.au>

> I have found a quite strange (to me) behaviour in Sweave. It only
> occurs in the following situation:

You need to understand what Sweave does when it creates pictures:
> <<>>=
> sel <- 1:5
> @
> <<fig=T>>=
> plot(trees[sel,])
> rm(sel)
> @

By default, a eps and pdf version of the graphic is made.
That is, this chunk producing the graphic is *run twice*:
once to make the eps file, once to make the pdf file.

After this code chunk is run once:

> <<fig=T>>=
> plot(trees[sel,])
> rm(sel)

...the variable  sel  is obviously deleted, so the
second time it runs... well, there's your error message.

Best to place the command  rm( sel )  in it's
own separate chunk.

P.

-- 
Dr Peter Dunn  |  dunn <at> usq.edu.au
Faculty of Sciences, USQ; http://www.sci.usq.edu.au/staff/dunn
Aust. Centre for Sustainable Catchments: www.usq.edu.au/acsc

This email (including any attached files) is confidential an...{{dropped}}


From shirley0818 at gmail.com  Thu Jun 28 03:55:31 2007
From: shirley0818 at gmail.com (shirley zhang)
Date: Wed, 27 Jun 2007 21:55:31 -0400
Subject: [R] unequal variance assumption for lme (mixed effect model)
Message-ID: <6fb73d020706271855seedb40dobbc0fe2578de94ea@mail.gmail.com>

Dear Douglas and R-help,

Does lme assume normal distribution AND equal variance among groups
like anova() does? If it does, is there any method like unequal
variance T-test (Welch T) in lme when each group has unequal variance
in my data?

Thanks,
Shirley


From jholtman at gmail.com  Thu Jun 28 03:56:06 2007
From: jholtman at gmail.com (jim holtman)
Date: Wed, 27 Jun 2007 21:56:06 -0400
Subject: [R] restructuring matrix
In-Reply-To: <11334950.post@talk.nabble.com>
References: <11334950.post@talk.nabble.com>
Message-ID: <644e1f320706271856s788071d3of1b10662382444a3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070627/5c6bafb5/attachment.pl 

From spencer.graves at pdf.com  Thu Jun 28 04:09:09 2007
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 27 Jun 2007 19:09:09 -0700
Subject: [R] stepAIC on lm() where response is a matrix..
In-Reply-To: <20070627165510.25778.qmail@web53808.mail.re2.yahoo.com>
References: <20070627165510.25778.qmail@web53808.mail.re2.yahoo.com>
Message-ID: <46831845.9070005@pdf.com>

      I see several options for you: 

      1.  Write a function 'dropterm.mlm', copying 'dropterm.lm' and 
modifying it as you think appropriate.  The function 'dropterm.lm' is 
hidden in a namespace, which you can see from 'methods(dropterm)'.  To 
get it, either use getAnywhere("dropterm.lm") or "MASS:::dropterm.lm".

      2.  Use 'stepAIC' in the univariate mode.  If they both select the 
same model, it would strongly suggest that you would get the same answer 
from a multivariate version.  Fit that multivariate version and be happy. 

      3.  If univariate analyses produce different models and you want a 
common one, take the models you get, and interpolate manually a list of 
alternative plausible models between the two best univariate models.  
Then fit those manually and select the one with the smallest AIC. 

      Hope this helps. 
      Spencer Graves

vinod gullu wrote:
> dear R users,
>
> I have fit the lm() on a mtrix of responses. 
> i.e M1 = lm(cbind(R1,R2)~ X+Y+0). When i use
> summary(M1), it shows details for R1 and R2
> separately. Now i want to use stepAIC on these models.
> But when i use stepAIC(M1) an error message  comes
> saying that dropterm.mlm is not implemented. What is
> the way out to use stepAIC in such cases.
>
> regards,
>
>
>  
> ____________________________________________________________________________________
> The fish are biting.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bates at stat.wisc.edu  Thu Jun 28 04:20:12 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 27 Jun 2007 21:20:12 -0500
Subject: [R] skeleton for C code?
In-Reply-To: <50d1c22d0706271300p3c8d9109g1aeafe3908fa419e@mail.gmail.com>
References: <50d1c22d0706271300p3c8d9109g1aeafe3908fa419e@mail.gmail.com>
Message-ID: <40e66e0b0706271920o15f27e9fq54ab1ba743f520be@mail.gmail.com>

On 6/27/07, ivo welch <ivowel at gmail.com> wrote:
> Dear R experts---I would like to write a replacement for the read.csv
> function that is less general, but also more efficient.
>
> could someone please provide me with a skeleton function that shows me
> how to read the arguments and return a data frame for a call to a C
> function that handles
>
>      returned.data.frame = my.read.csv(file, header = TRUE, sep = ",",
> quote="\"", dec=".",
>               fill = TRUE, comment.char="", ...)
>
> this may be very difficult, of course, in which case writing such a
> function would not be worth it.  I guess I would be happy just to
> learn how to return a basic data frame that holds data vectors that
> are either strings or numbers---nothing more complex.
>
> help appreciated.

Should we assume that you have already read the relevant sections of
the manual "Writing R Extensions"?

The .Call interface is the easiest way to return an object like a data
frame.  I might pass the result back as a list and use something like

do.call(data.frame, .Call("my_csv_reader", file, ...))

rather than duplicating all the error checking that is done in the
data.frame function.


From spencer.graves at pdf.com  Thu Jun 28 04:21:32 2007
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 27 Jun 2007 19:21:32 -0700
Subject: [R] Gaussian elimination - singular matrix
In-Reply-To: <617938.9931.qm@web32208.mail.mud.yahoo.com>
References: <617938.9931.qm@web32208.mail.mud.yahoo.com>
Message-ID: <46831B2C.200@pdf.com>

  RSiteSearch("generalized inverse", "fun") produced 194 hits for me 
just now, including references to the following:

Ginv {haplo.stats}
ginv {MASS}
invgen {far}
Ginv {haplo.score}

At least some of these should provide a solution to a singular system. 
You could further provide side constraints as Moshe suggested, but I 
suspect that 'ginv', for example, might return the minimum length 
solution automatically.

Hope this helps.
Spencer Graves

Moshe Olshansky wrote:
> All the nontrivial solutions to AX = 0 are the
> eigenvectors of A corresponding to eigenvalue 0 (try
> eigen function).
> The non-negative solution may or may not exist.  For
> example, if A is a 2x2 matrix Aij = 1 for 1 <=i,j <=2
> then the only non-trivial solution to AX = 0 is X =
> a*(1,-1), where a is any nonzero scalar.  So in this
> case there is no non-negative solution. 
> Let X1, X2,...,Xk be all the k independent
> eigenvectors corresponding to eigenvalue 0, i.e. AXi =
> 0 for i = 1,2,...,k.  Any linear combination of them,
> X = X1,...,Xk, i.e. a1*X1 + ... + ak*Xk is also a
> solution of AX = 0.  Let B be a matrix whose COLUMNS
> are the vectors X1,...,Xk (B = (X1,...,Xk).  Then
> finding a1,...,ak for which all elements of X are
> non-negative is equivalent to finding a vector a =
> (a1,...,ak) such that B*a >= 0.  Of course a =
> (0,...,0) is a solution.  The question whether there
> exists another one.  Try to solve the following Linear
> Programming problem:
> max a1
> subject to B*a >= 0
> (you can start with a = (0,...,0) which is a feasible
> solution).
> If you get a non-zero solution fine.  If not try to
> solve
> min a1
> subject to B*a >= 0
> if you still get 0 try this with max a2, then min a2,
> max a3, min a3, etc.  If all the 2k problems have only
> 0 solution then there are no nontrivial nonnegative
> solutions.  Otherwise you will find it.
> Instead of 2k LP (Linear Programming) problems you can
> look at one QP (Quadratic Programming) problem:
> max a1^2 + a2^2 + ... + ak^2 
> subject to B*a >= 0
> If there is a nonzero solution a = (a1,...,ak) then X
> = a1&X1 +...+ak*Xk is what you are looking for. 
> Otherwise there is no nontrivial nonnegative solution.
>
> --- Bruce Willy <croero at hotmail.com> wrote:
>
>   
>> I am sorry, there is just a mistake : the solution
>> cannot be unique (because it is a vectorial space)
>> (but then I might normalize it)
>>  
>> can R find one anyway ?
>>  
>> This is equivalent to finding an eigenvector in
>> fact> From: croero at hotmail.com> To:
>> r-help at stat.math.ethz.ch> Date: Wed, 27 Jun 2007
>> 22:51:41 +0000> Subject: [R] Gaussian elimination -
>> singular matrix> > > Hello,> > I hope it is not a
>> too stupid question.> > I have a singular matrix A
>> (so not invertible).> > I want to find a nontrivial
>> nonnegative solution to AX=0 (kernel of A)> > It is
>> a special matrix A (so maybe this nonnegative
>> solution is unique)> > The authors of the article
>> suggest a Gaussian elimination method> > Do you know
>> if R can do that automatically ? I have seen that
>> "solve" has an option "LAPACK" but it does not seem
>> to work with me :(> > Thank you very much>
>>
>>     
> _________________________________________________________________>
>   
>> Le blog Messenger de Michel, candidat de la Nouvelle
>> Star : analyse, news, coulisses? A d?couvrir !> >
>> [[alternative HTML version deleted]]> 
>>
>>     
> _________________________________________________________________
>   
>> Le blog Messenger de Michel, candidat de la Nouvelle
>> Star : analyse, news, coulisses? A d?couvrir !
>>
>> 	[[alternative HTML version deleted]]
>>
>>     
>>> ______________________________________________
>>>       
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained,
>> reproducible code.
>>
>>     
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From adschai at optonline.net  Thu Jun 28 04:32:18 2007
From: adschai at optonline.net (adschai at optonline.net)
Date: Thu, 28 Jun 2007 02:32:18 +0000 (GMT)
Subject: [R] levelplot in lattice
In-Reply-To: <eb555e660706271700r356b5f00h627d89b59c745183@mail.gmail.com>
References: <e32ada36194e5.4682f7f7@optonline.net>
	<eb555e660706271700r356b5f00h627d89b59c745183@mail.gmail.com>
Message-ID: <e7dae06719900.46831db2@optonline.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070628/dc7aa6e8/attachment.pl 

From aragon at berkeley.edu  Thu Jun 28 04:32:57 2007
From: aragon at berkeley.edu (Tomas Aragon)
Date: Wed, 27 Jun 2007 19:32:57 -0700 (PDT)
Subject: [R] epitools and R 2.5
In-Reply-To: <Pine.LNX.4.64.0706110944530.26050@gannet.stats.ox.ac.uk>
Message-ID: <842773.42623.qm@web82007.mail.mud.yahoo.com>


--- Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> On Mon, 11 Jun 2007, Pietro Bulian wrote:
> 
> > At work after updating to R 2.5 I get an error using epitab from
> package
> > epitools, when at home  (R 2.4) I get no error. Could someone help
> me?
> 
> The maintainer: this is a long-standing bug in the package.
> But you have enough information from the error message to correct the
> bug 
> and rebuild the package yourself.
> 
> There are no such versions of R as '2.5' and '2.4' (see the posting 
> guide), but R 2.4.0 did give a warning on your example.
> 
> Note that you are using different versions of epitools in your two 
> locations, a difference you failed to mention and which may be
> important.
> 
> 
> 

Thanks Pietro! I am the maintainer and found the bug.

In the 'epitab' function:

    if (method == "oddsratio") {
    ...
        else {
            fin <- list(tab = tab, measure = oddsratio, 
                  conf.level = conf.level, pvalue = pvalue, )
        }


The comma should not be after the second "pvalue". You can correct this
in your local workspace. I will correct and upload new package. 

Tomas


=======
Tomas Aragon, MD, DrPH
Tel: 510-847-9139 (mobile)
Web: http://www.medepi.net/aragon


From adschai at optonline.net  Thu Jun 28 04:37:04 2007
From: adschai at optonline.net (adschai at optonline.net)
Date: Thu, 28 Jun 2007 02:37:04 +0000 (GMT)
Subject: [R] levelplot in lattice
In-Reply-To: <e7dae06719900.46831db2@optonline.net>
References: <e32ada36194e5.4682f7f7@optonline.net>
	<eb555e660706271700r356b5f00h627d89b59c745183@mail.gmail.com>
	<e7dae06719900.46831db2@optonline.net>
Message-ID: <e44ae10c1cd15.46831ed0@optonline.net>

Sorry. My email editor from my ISP always screws up the text after sending out. Below is my response to you (in plain text).

Thank you Deepayan. Let's do the following exercise to reproduce the problem I'm facing. In the following code, I tried to have plot.rw1 and plot.rw2 shows in two separate rows on my plot windows. However, after the call to the 2nd levelplot, plot of plot.rw2 replace my first plot and the result shows only 1 row on my windows. Any lights on this would be really appreciated. Thank you

x <- seq(0.1,1,0.1);
y <- seq(0.1,1,0.1);
dat <- rnorm(4*length(x)*length(y));

Pa.dat <- expand.grid(x,y);
Pa.dat$z <- dat[1:100];
Pa.dat$cond <- "Pa";

plot.rw1 <- Pa.dat;

Pb.dat <- expand.grid(x,y);
Pb.dat$z <- dat[101:200];
Pb.dat$cond <- "Pb";

plot.rw1 <- rbind(plot.rw1, Pb.dat);
names(plot.rw1) <- c("x","y","z","cond");

Days1.dat <- expand.grid(x,y);
Days1.dat$z <- dat[201:300];
Days1.dat$cond <- "Day Work";

plot.rw2 <- Days1.dat;

Days2.dat <- expand.grid(x,y);
Days2.dat$z <- dat[301:400];
Days2.dat$cond <- "Day Rest";

plot.rw2 <- rbind(plot.rw2, Days2.dat);
names(plot.rw2) <- c("x","y","z","cond");

windows();
par(mfrow=c(2,1));
levelplot(z ~ x*y|cond, plot.rw1);
levelplot(z ~ x*y|cond, plot.rw2);


----- Original Message -----From: adschai at optonline.netDate: Wednesday, June 27, 2007 9:34 pmSubject: Re: [R] levelplot in latticeTo: Deepayan Sarkar Cc: r-help at stat.math.ethz.ch> Thank you Deepayan. Let's do the following exercise to reproduce > the problem I'm facing. In the following code, I tried to have > plot.rw1 and plot.rw2 shows in two separate rows on my plot > windows. However, after the call to the 2nd levelplot, plot of > plot.rw2 replace my first plot and the result shows only 1 row > on my windows. Any lights on this would be really appreciated. > Thank you.x <- seq(0.1,1,0.1);y <- seq(0.1,1,0.1);dat <- > rnorm(4*length(x)*length(y));Pa.dat <- expand.grid(x,y);Pa.dat$z > <- dat[1:100];Pa.dat$cond <- "Pa";plot.rw1 <- Pa.dat;Pb.dat <- > expand.grid(x,y);Pb.dat$z <- dat[101:200];Pb.dat$cond <- > "Pb";plot.rw1 <- rbind(plot.rw1, Pb.dat);names(plot.rw1) <- > c("x","y","z","cond");Days1.dat <- expand.grid(x,y);Days1.dat$z > <- dat[201:300];Days1.dat$cond <- "Day Work";plot.rw2 <- > Days1.dat;Days2.dat <- expand.grid(x,y);Days2.dat$z <- > dat[301:400];Days2.dat$cond <- "Day Rest";plot.rw2 <- > rbind(plot.rw2, Days2.dat);names(plot.rw2) <- > c("x","y","z","cond");windows();pa! r(mfrow=c(2,1));levelplot(z > ~ x*y|cond, plot.rw1);levelplot(z ~ x*y|cond, plot.rw2);----- > Original Message -----From: Deepayan Sarkar Date: Wednesday, > June 27, 2007 7:00 pmSubject: Re: [R] levelplot in latticeTo: > "adschai at optonline.net" Cc: r-help at stat.math.ethz.ch> On > 6/27/07, adschai at optonline.net  wrote:> > Hi,> >> > I'm new to > lattice. So please kindly be patient with me.> > I'm trying to > arrange groups of levelplots into 3 rows as follows:> >> > Row1: > Probabilities as functions of x and y, and conditioned > on an > event factor vector factor("a","b","c")> >> > Row2: Number of > days as functions of  x and y, and conditioned > on, again the > same event factor("a","b","c")> >> > Row2: Costs as functions of > x and y, and conditioned on, > again the same event > factor("a","b","c")> >> > I tried the following:> >> > > windows();> > par(mfrow=c(3,1));> > levelplot(z ~ x*y|events, > probDat);> > levelplot(z ~ x*y|events, daysDat);> > levelplot(z > ~ x*y|events, costDat);> >> > It does no!> t do what I want. It replace the previous plot every > time I > call a n> ew levelplot. I can't put them into the same > matrix and plot > them all at once because the scale of each data > type is very > different, i.e.g probability=c(0,1), days=c(0,10), > etc. I'm > wondering if you could suggest a way to solve this problem.> >> > > It all depends on the details. Please give a small > reproducible > example.> > Also, if I would like to put in > mathematical notation on the > top strip of the plot instead of > using text in my events factor > vector, what can I do?> > Use > expressions (see ?plotmath). Again, please give details.> > -Deepayan>> > 	[[alternative HTML version deleted]]> > ______________________________________________> R-help at stat.math.ethz.ch mailing list> https://stat.ethz.ch/mailman/listinfo/r-help> PLEASE do read the posting guide http://www.R-> project.org/posting-guide.html> and provide commented, minimal, self-contained, reproducible code.>


From s.blomberg1 at uq.edu.au  Thu Jun 28 04:44:29 2007
From: s.blomberg1 at uq.edu.au (Simon Blomberg)
Date: Thu, 28 Jun 2007 12:44:29 +1000
Subject: [R] unequal variance assumption for lme (mixed effect model)
In-Reply-To: <6fb73d020706271855seedb40dobbc0fe2578de94ea@mail.gmail.com>
References: <6fb73d020706271855seedb40dobbc0fe2578de94ea@mail.gmail.com>
Message-ID: <1182998669.4837.11.camel@sib-sblomber01d.sib.uq.edu.au>

The default settings for lme do assume equal variances within groups.
You can change that by using the various varClasses. see ?varClasses. A
simple example would be to allow unequal variances across groups. So if
your call to lme was: 

lme(...,random=~1|group,...)

then to allow each group to have its own variance, use:

lme(...,random=~1|group, weights=varIdent(form=~1|group),...)

You really really should read Pinheiro & Bates (2000). It's all there.

HTH,

Simon.

, On Wed, 2007-06-27 at 21:55 -0400, shirley zhang wrote:
> Dear Douglas and R-help,
> 
> Does lme assume normal distribution AND equal variance among groups
> like anova() does? If it does, is there any method like unequal
> variance T-test (Welch T) in lme when each group has unequal variance
> in my data?
> 
> Thanks,
> Shirley
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
-- 
Simon Blomberg, BSc (Hons), PhD, MAppStat. 
Lecturer and Consultant Statistician 
Faculty of Biological and Chemical Sciences 
The University of Queensland 
St. Lucia Queensland 4072 
Australia

Room 320, Goddard Building (8)
T: +61 7 3365 2506 
email: S.Blomberg1_at_uq.edu.au 

The combination of some data and an aching desire for 
an answer does not ensure that a reasonable answer can 
be extracted from a given body of data. - John Tukey.


From duvvuru.suman at gmail.com  Thu Jun 28 04:51:30 2007
From: duvvuru.suman at gmail.com (suman Duvvuru)
Date: Wed, 27 Jun 2007 22:51:30 -0400
Subject: [R] Correlation ratio
In-Reply-To: <BAY126-W34F737A4DA0AEFD1A8414BC90A0@phx.gbl>
References: <BAY126-W34F737A4DA0AEFD1A8414BC90A0@phx.gbl>
Message-ID: <bac8a0820706271951k2aef1cd3hba372b30f1c3787a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070627/6c1fa826/attachment.pl 

From deepayan.sarkar at gmail.com  Thu Jun 28 05:00:04 2007
From: deepayan.sarkar at gmail.com (deepayan.sarkar at gmail.com)
Date: Wed, 27 Jun 2007 20:00:04 -0700
Subject: [R] levelplot in lattice
In-Reply-To: <e44ae10c1cd15.46831ed0@optonline.net>
References: <e32ada36194e5.4682f7f7@optonline.net>
	<eb555e660706271700r356b5f00h627d89b59c745183@mail.gmail.com>
	<e7dae06719900.46831db2@optonline.net>
	<e44ae10c1cd15.46831ed0@optonline.net>
Message-ID: <eb555e660706272000o5915b796je02b59b8d8aaf035@mail.gmail.com>

On 6/27/07, adschai at optonline.net <adschai at optonline.net> wrote:
> Sorry. My email editor from my ISP always screws up the text after sending
> out. Below is my response to you (in plain text).
>
> Thank you Deepayan. Let's do the following exercise to reproduce the problem
> I'm facing. In the following code, I tried to have plot.rw1 and plot.rw2
> shows in two separate rows on my plot windows. However, after the call to
> the 2nd levelplot, plot of plot.rw2 replace my first plot and the result
> shows only 1 row on my windows. Any lights on this would be really
> appreciated. Thank you
>
> x <- seq(0.1,1,0.1);
> y <- seq(0.1,1,0.1);
> dat <- rnorm(4*length(x)*length(y));
>
> Pa.dat <- expand.grid(x,y);
> Pa.dat$z <- dat[1:100];
> Pa.dat$cond <- "Pa";
>
> plot.rw1 <- Pa.dat;
>
> Pb.dat <- expand.grid(x,y);
> Pb.dat$z <- dat[101:200];
> Pb.dat$cond <- "Pb";
>
> plot.rw1 <- rbind(plot.rw1, Pb.dat);
> names(plot.rw1) <- c("x","y","z","cond");
>
> Days1.dat <- expand.grid(x,y);
> Days1.dat$z <- dat[201:300];
> Days1.dat$cond <- "Day Work";
>
> plot.rw2 <- Days1.dat;
>
> Days2.dat <- expand.grid(x,y);
> Days2.dat$z <- dat[301:400];
> Days2.dat$cond <- "Day Rest";
>
> plot.rw2 <- rbind(plot.rw2, Days2.dat);
> names(plot.rw2) <- c("x","y","z","cond");
>
> windows();
> par(mfrow=c(2,1));
> levelplot(z ~ x*y|cond, plot.rw1);
> levelplot(z ~ x*y|cond, plot.rw2);


## option 1:

levelplot(z ~ x * y | cond,
          make.groups(plot.rw1, plot.rw2))

## equivalent in this case

levelplot(z ~ x * y | cond,
          rbind(plot.rw1, plot.rw2))

## option 2 (not exactly the same)

print(levelplot(z ~ x*y|cond, plot.rw1),
      split = c(1, 2, 1, 2))
print(levelplot(z ~ x*y|cond, plot.rw2),
      split = c(1, 1, 1, 2),
      newpage = FALSE)

-Deepayan


From shirley0818 at gmail.com  Thu Jun 28 05:14:19 2007
From: shirley0818 at gmail.com (shirley zhang)
Date: Wed, 27 Jun 2007 23:14:19 -0400
Subject: [R] unequal variance assumption for lme (mixed effect model)
In-Reply-To: <1182998669.4837.11.camel@sib-sblomber01d.sib.uq.edu.au>
References: <6fb73d020706271855seedb40dobbc0fe2578de94ea@mail.gmail.com>
	<1182998669.4837.11.camel@sib-sblomber01d.sib.uq.edu.au>
Message-ID: <6fb73d020706272014g18d3abb9ob70ab559883b6fb3@mail.gmail.com>

Hi Simon,

Thanks for your reply. Your reply reminds me that book. I've read it
long time ago, but haven't  try the weights option in my projects
yet:)

Is the heteroscedastic test always less powerful because we have to
estimate the within group variance from the given data?

Should we check whether each group has equal variance before using
weights=varIdent()? If we should, what is the function for linear
mixed model?

Thanks,
Shirley

On 6/27/07, Simon Blomberg <s.blomberg1 at uq.edu.au> wrote:
> The default settings for lme do assume equal variances within groups.
> You can change that by using the various varClasses. see ?varClasses. A
> simple example would be to allow unequal variances across groups. So if
> your call to lme was:
>
> lme(...,random=~1|group,...)
>
> then to allow each group to have its own variance, use:
>
> lme(...,random=~1|group, weights=varIdent(form=~1|group),...)
>
> You really really should read Pinheiro & Bates (2000). It's all there.
>
> HTH,
>
> Simon.
>
> , On Wed, 2007-06-27 at 21:55 -0400, shirley zhang wrote:
> > Dear Douglas and R-help,
> >
> > Does lme assume normal distribution AND equal variance among groups
> > like anova() does? If it does, is there any method like unequal
> > variance T-test (Welch T) in lme when each group has unequal variance
> > in my data?
> >
> > Thanks,
> > Shirley
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> --
> Simon Blomberg, BSc (Hons), PhD, MAppStat.
> Lecturer and Consultant Statistician
> Faculty of Biological and Chemical Sciences
> The University of Queensland
> St. Lucia Queensland 4072
> Australia
>
> Room 320, Goddard Building (8)
> T: +61 7 3365 2506
> email: S.Blomberg1_at_uq.edu.au
>
> The combination of some data and an aching desire for
> an answer does not ensure that a reasonable answer can
> be extracted from a given body of data. - John Tukey.
>
>


From ripley at stats.ox.ac.uk  Thu Jun 28 07:24:25 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 28 Jun 2007 06:24:25 +0100 (BST)
Subject: [R] stepAIC on lm() where response is a matrix..
In-Reply-To: <46831845.9070005@pdf.com>
References: <20070627165510.25778.qmail@web53808.mail.re2.yahoo.com>
	<46831845.9070005@pdf.com>
Message-ID: <Pine.LNX.4.64.0706280618590.23081@gannet.stats.ox.ac.uk>

On Wed, 27 Jun 2007, Spencer Graves wrote:

>      I see several options for you:
>
>      1.  Write a function 'dropterm.mlm', copying 'dropterm.lm' and
> modifying it as you think appropriate.  The function 'dropterm.lm' is
> hidden in a namespace, which you can see from 'methods(dropterm)'.  To
> get it, either use getAnywhere("dropterm.lm") or "MASS:::dropterm.lm".

To do so you would have to decide what the AIC was for the mlm model.  If 
the two responses are regarded as independent, this would be easy, but mlm 
is also the basis of 'manova' models: see ?anova.mlm and ?summary.manova. 
Given Spencer's point 2, independence is not normally what people intend 
when fitting a multivariate linear model: more likely they are fitting a 
model with correlated observations not by maximum likelihood (and hence 
AIC is not appropriate).

>      2.  Use 'stepAIC' in the univariate mode.  If they both select the
> same model, it would strongly suggest that you would get the same answer
> from a multivariate version.  Fit that multivariate version and be happy.
>
>      3.  If univariate analyses produce different models and you want a
> common one, take the models you get, and interpolate manually a list of
> alternative plausible models between the two best univariate models.
> Then fit those manually and select the one with the smallest AIC.
>
>      Hope this helps.
>      Spencer Graves
>
> vinod gullu wrote:
>> dear R users,
>>
>> I have fit the lm() on a mtrix of responses.
>> i.e M1 = lm(cbind(R1,R2)~ X+Y+0). When i use
>> summary(M1), it shows details for R1 and R2
>> separately. Now i want to use stepAIC on these models.
>> But when i use stepAIC(M1) an error message  comes
>> saying that dropterm.mlm is not implemented. What is
>> the way out to use stepAIC in such cases.
>>
>> regards,

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Jun 28 07:40:35 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 28 Jun 2007 06:40:35 +0100 (BST)
Subject: [R] Loading problem with XML_1.9
In-Reply-To: <776851.76466.qm@web32513.mail.mud.yahoo.com>
References: <776851.76466.qm@web32513.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.64.0706280629020.23081@gannet.stats.ox.ac.uk>

Please don't post to multiple lists: I have removed the BioC-devel list.
This is about MacOS X, and the appropriate list is R-sig-mac.

There is no intrinsic 64-bit problem: package XML 1.9-0 (sic) works fine 
on 64-bit versions of Solaris and Linux.  Most likely there was an 
installation problem, and you do not have a 64-bit version of libxml2 
installed or in the run-time library path.

On Wed, 27 Jun 2007, Luo Weijun wrote:

> Hello all,
> I have loading problem with XML_1.9 under 64 bit
> R2.3.1, which I got from http://R.research.att.com/.

For MacOS X, unstated.

> XML_1.9 works fine under 32 bit R2.5.0. I thought that
> could be installation problem, and I tried
> install.packages or biocLite, every time the package
> installed fine, except some warning messages below:
> ld64 warning: in /usr/lib/libxml2.dylib, file does not
> contain requested architecture
> ld64 warning: in /usr/lib/libz.dylib, file does not
> contain requested architecture
> ld64 warning: in /usr/lib/libiconv.dylib, file does
> not contain requested architecture
> ld64 warning: in /usr/lib/libz.dylib, file does not
> contain requested architecture
> ld64 warning: in /usr/lib/libxml2.dylib, file does not
> contain requested architecture
>
> Here is the error messages I got, when XML is loaded:
>> library(XML)
> Error in dyn.load(x, as.logical(local),
> as.logical(now)) :
>        unable to load shared library
> '/usr/local/lib64/R/library/XML/libs/XML.so':
>  dlopen(/usr/local/lib64/R/library/XML/libs/XML.so,
> 6): Symbol not found: _xmlMemDisplay
>  Referenced from:
> /usr/local/lib64/R/library/XML/libs/XML.so
>  Expected in: flat namespace
> Error: .onLoad failed in 'loadNamespace' for 'XML'
> Error: package/namespace load failed for 'XML'
>
> I understand that it has been pointed out that
> Sys.getenv("PATH") needs to be revised in the file
> XML/R/zzz.R, but I can???t even find that file under
> XML/R/ directory. Does anybody have any idea what
> might be the problem, and how to solve it? Thanks a
> lot!
> BTW, the reason I need to use R64 is that I have
> memory limitation issue with R 32 bit version when I
> load some very large XML trees.
>
> Session information
>> sessionInfo()
> Version 2.3.1 Patched (2006-06-27 r38447)
> powerpc64-apple-darwin8.7.0
>
> attached base packages:
> [1] "methods"   "stats"     "graphics"  "grDevices"
> "utils"     "datasets"
> [7] "base"
>
> Weijun

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From dlalountas at yahoo.com  Thu Jun 28 07:48:20 2007
From: dlalountas at yahoo.com (denis lalountas)
Date: Wed, 27 Jun 2007 22:48:20 -0700 (PDT)
Subject: [R] WEIBULL FRAILTY MODEL HELP
Message-ID: <924127.18738.qm@web58710.mail.re1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070627/095f2088/attachment.pl 

From smcnary at charm.net  Thu Jun 28 07:55:12 2007
From: smcnary at charm.net (Scot W. McNary)
Date: Thu, 28 Jun 2007 01:55:12 -0400
Subject: [R] Correlation ratio
In-Reply-To: <bac8a0820706271951k2aef1cd3hba372b30f1c3787a@mail.gmail.com>
References: <BAY126-W34F737A4DA0AEFD1A8414BC90A0@phx.gbl>
	<bac8a0820706271951k2aef1cd3hba372b30f1c3787a@mail.gmail.com>
Message-ID: <46834D40.80802@charm.net>

Suman,

Try this:

# some data
example(aov)

# the summary table
anova(npk.aov)

# extract sums of squares
SS <- anova(npk.aov)$"Sum Sq"

SS
#[1] 343.2950000 189.2816667   8.4016667  95.2016667  21.2816667  
33.1350000   0.4816667 185.2866667

# eta-squared for factor N
#SS factor N/SS Total
SS[2]/sum(SS)
#[1] 0.2159850

# partial eta-squared for factor N
# SS factor N/(SS Factor N + SS Residuals)
SS[2]/(sum(SS[2],SS[8]))
#[1] 0.5053328

Hope this helps,

Scot

suman Duvvuru wrote:
> Hi Bruce,
> correlation ratio (eta) is different from correlation coefficient (rho).
> While correlation coefficient captures only a linear relationship btw
> variables, correlation ratio captures both linear and non-linear
> relationships.  It is the defined as the ratio of the variance between
> arrays to the total variance.
>
> Thanks,
> Suman
>
>
> On 6/27/07, Bruce Willy <croero at hotmail.com> wrote:
>   
>>  hello
>>
>> try cor(x, y = NULL, use = "all.obs",
>>      method = c("pearson", "kendall", "spearman"))
>>
>> in the R console, you can type "?cor" to get some help on a particular
>> function
>> and help.search("correlation") if you do know the keyword
>>
>>     
>>> Date: Wed, 27 Jun 2007 18:00:05 -0400
>>> From: duvvuru.suman at gmail.com
>>> To: R-help at stat.math.ethz.ch
>>> Subject: [R] Correlation ratio
>>>
>>> Hi,
>>>
>>> I wanted to know how to compute the correlation ratio (eta) between two
>>> variables using R. Is there any function to compute the correlationratio.
>>>       
>>> Any help will be very much appreciated.
>>>
>>> Thanks,
>>> Suman
>>>
>>>       


-- 
Scot McNary
smcnary at charm dot net


From andrej.kastrin at siol.net  Thu Jun 28 08:22:18 2007
From: andrej.kastrin at siol.net (Andrej Kastrin)
Date: Thu, 28 Jun 2007 08:22:18 +0200
Subject: [R] Populate matrix from data.frame
Message-ID: <4683539A.3030407@siol.net>

Dear all,

I have a data frame
a <- data.frame(cbind(x=c('a','a','a','b','c'), 
y=c('a','b','c','d','e'),z=c(1,2,3,4,5)))
 > a
  x y z
1 a a 1
2 a b 2
3 a c 3
4 b d 4
5 c e 5

and a matrix
mm <- matrix(0,5,5)
colnames(mm) <- c('a','b','c','d','e')
rownames(mm) <- c('a','b','c','d','e')
 > mm
  a b c d e
a 0 0 0 0 0
b 0 0 0 0 0
c 0 0 0 0 0
d 0 0 0 0 0
e 0 0 0 0 0

How to populate matrix in a way that first column of data frame 'a' 
correspond to rownames(mm), second column to colnames(mm) and the third 
column is the element of matrix 'mm'?

Thanks in advance,
Andrej


From ripley at stats.ox.ac.uk  Thu Jun 28 08:27:05 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 28 Jun 2007 07:27:05 +0100 (BST)
Subject: [R] "no applicable method"
In-Reply-To: <AB724053-3718-4FFE-8342-4ED1AEC5D689@csbl.bmb.uga.edu>
References: <AB724053-3718-4FFE-8342-4ED1AEC5D689@csbl.bmb.uga.edu>
Message-ID: <Pine.LNX.4.64.0706271858280.15323@gannet.stats.ox.ac.uk>

On Wed, 27 Jun 2007, Kyle Ellrott wrote:

> I'm getting started in R, and I'm trying to use one of the gradient
> boosting packages, mboost.  I'm already installed the package with
> install.packages("mboost") and loaded it with library(mboost).
> My problem is that when I attempt to call glmboost, I get a message
> that " Error in glmboost() : no applicable method for "glmboost" ".
> Does anybody have an idea of what kind of problem this is indicative of?

The wrong class of input object 'x'.  The help page for glmboost is 
written obscurely, but it seems to imply that it has methods for 'formula' 
and 'matrix'.

Perhaps you passed a data frame?

> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

is pertinent.  With an example and its output we would have been much 
better placed to help you.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Jun 28 08:52:22 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 28 Jun 2007 07:52:22 +0100 (BST)
Subject: [R] Populate matrix from data.frame
In-Reply-To: <4683539A.3030407@siol.net>
References: <4683539A.3030407@siol.net>
Message-ID: <Pine.LNX.4.64.0706280750150.24371@gannet.stats.ox.ac.uk>

On Thu, 28 Jun 2007, Andrej Kastrin wrote:

> Dear all,
>
> I have a data frame
> a <- data.frame(cbind(x=c('a','a','a','b','c'),
> y=c('a','b','c','d','e'),z=c(1,2,3,4,5)))
> > a
>  x y z
> 1 a a 1
> 2 a b 2
> 3 a c 3
> 4 b d 4
> 5 c e 5
>
> and a matrix
> mm <- matrix(0,5,5)
> colnames(mm) <- c('a','b','c','d','e')
> rownames(mm) <- c('a','b','c','d','e')
> > mm
>  a b c d e
> a 0 0 0 0 0
> b 0 0 0 0 0
> c 0 0 0 0 0
> d 0 0 0 0 0
> e 0 0 0 0 0
>
> How to populate matrix in a way that first column of data frame 'a'
> correspond to rownames(mm), second column to colnames(mm) and the third
> column is the element of matrix 'mm'?

mm[cbind(a$x, a$y)] <- a$z

Please read about the forms of indexing matrices in 'An Introduction to 
R'.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From justin_bem at yahoo.fr  Thu Jun 28 09:05:04 2007
From: justin_bem at yahoo.fr (justin bem)
Date: Thu, 28 Jun 2007 07:05:04 +0000 (GMT)
Subject: [R] Re :  restructuring matrix
Message-ID: <20070628070504.88546.qmail@web23003.mail.ird.yahoo.com>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20070628/98b381d8/attachment.pl 

From wolfram at fischer-zim.ch  Thu Jun 28 09:43:57 2007
From: wolfram at fischer-zim.ch (Wolfram Fischer)
Date: Thu, 28 Jun 2007 09:43:57 +0200
Subject: [R] : regular expressions: escaping a dot
Message-ID: <20070628074357.GA4502@s1x.fischer-zim.local>

What's really the problem with:

> regexpr( '\.odt$', "xxxxYodt", perl=TRUE )
	Warning: '\.' is an unrecognized escape in a character string
	Warning: unrecognized escape removed from "\.odt$"
	[1] 5
	attr(,"match.length")
	[1] 4

I know that I could use:
> regexpr( '[.]odt$', "xxxxYodt", perl=TRUE )

But it seems to me that the first expression is also
an accepted regular expression in accordance with perl.

Regards - Wolfram


From tobias.verbeke at businessdecision.com  Thu Jun 28 09:56:47 2007
From: tobias.verbeke at businessdecision.com (Tobias Verbeke)
Date: Thu, 28 Jun 2007 09:56:47 +0200
Subject: [R] : regular expressions: escaping a dot
In-Reply-To: <20070628074357.GA4502@s1x.fischer-zim.local>
References: <20070628074357.GA4502@s1x.fischer-zim.local>
Message-ID: <468369BF.1030604@businessdecision.com>

Wolfram Fischer wrote:

> What's really the problem with:
> 
>> regexpr( '\.odt$', "xxxxYodt", perl=TRUE )
> 	Warning: '\.' is an unrecognized escape in a character string
> 	Warning: unrecognized escape removed from "\.odt$"
> 	[1] 5
> 	attr(,"match.length")
> 	[1] 4
> 
> I know that I could use:
>> regexpr( '[.]odt$', "xxxxYodt", perl=TRUE )
> 
> But it seems to me that the first expression is also
> an accepted regular expression in accordance with perl.

In R you have to escape the "\".

 From the help page of regexpr:

## Double all 'a' or 'b's;  "\" must be escaped, i.e., 'doubled'
gsub("([ab])", "\\1_\\1_", "abc and ABC")

HTH,
Tobias

-- 

Tobias Verbeke - Consultant
Business & Decision Benelux
Rue de la r?volution 8
1000 Brussels - BELGIUM

+32 499 36 33 15
tobias.verbeke at businessdecision.com


From momalta at cict.fiocruz.br  Wed Jun 27 22:38:34 2007
From: momalta at cict.fiocruz.br (Monica Malta)
Date: Wed, 27 Jun 2007 17:38:34 -0300
Subject: [R] Meta-Analysis of proportions
Message-ID: <01dc01c7b8fb$21fc6680$9aa8569d@dcs012S>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070627/987fc1d7/attachment.pl 

From ripley at stats.ox.ac.uk  Thu Jun 28 10:25:07 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 28 Jun 2007 09:25:07 +0100 (BST)
Subject: [R] : regular expressions: escaping a dot
In-Reply-To: <20070628074357.GA4502@s1x.fischer-zim.local>
References: <20070628074357.GA4502@s1x.fischer-zim.local>
Message-ID: <Pine.LNX.4.64.0706280921230.4206@gannet.stats.ox.ac.uk>

On Thu, 28 Jun 2007, Wolfram Fischer wrote:

> What's really the problem with:
>
>> regexpr( '\.odt$', "xxxxYodt", perl=TRUE )
> 	Warning: '\.' is an unrecognized escape in a character string
> 	Warning: unrecognized escape removed from "\.odt$"
> 	[1] 5
> 	attr(,"match.length")
> 	[1] 4
>
> I know that I could use:
>> regexpr( '[.]odt$', "xxxxYodt", perl=TRUE )
>
> But it seems to me that the first expression is also
> an accepted regular expression in accordance with perl.

This is explained in ?regexp (in the See Also of ?regexpr):

      Patterns are described here as they would be printed by 'cat': _do
      remember that backslashes need to be doubled when entering R
      character strings from the keyboard_.

and in the R FAQ and ....

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From chainsawtiney at gmail.com  Thu Jun 28 10:58:03 2007
From: chainsawtiney at gmail.com (Chung-hong Chan)
Date: Thu, 28 Jun 2007 16:58:03 +0800
Subject: [R] Meta-Analysis of proportions
In-Reply-To: <01dc01c7b8fb$21fc6680$9aa8569d@dcs012S>
References: <01dc01c7b8fb$21fc6680$9aa8569d@dcs012S>
Message-ID: <30d7ea360706280158x2e19daa4ocb41febfda944e@mail.gmail.com>

OpenBUGS should be something related to Bayesian statistics.

You may refer to Chapter 12 of Handbook
http://cran.r-project.org/doc/vignettes/HSAUR/Ch_meta_analysis.pdf
It talks about meta-regression.



On 6/28/07, Monica Malta <momalta at cict.fiocruz.br> wrote:
> Dear colleagues,
>
> I'm conducting a meta-analysis of studies evaluating adherence of HIV-positive drug users into AIDS treatment, therefore I'm looking for some advice and syntax suggestion for running the meta-regression using proportions, not the usual OR/RR frequently used on RCT studies.
>
> Have already searched already several handbooks, R-manuals, mailing lists, professors, but... not clue at all...
>
> Does anyone have already tried this? A colleague of mine recently published a similar study on JAMA, but he used OpenBUGS - a software I'm not familiar with...
>
> If there is any tip/suggestion for a possible syntax, could someone send me? I need to finish this paper before my PhD qualify, but I'm completely stuck...
>
> So, any tip will be more than welcome...I will really appreciate it!!!
>
> Thanks in advance and congrats on the amazing mailing-list.
>
>
>
> Bests from Rio de Janeiro, Brazil.
>
> Monica
>
>
>
>
>
> Monica Malta
> Researcher
> Oswaldo Cruz Foundation - FIOCRUZ
> Social Science Department - DCS/ENSP
> Rua Leopoldo Bulhoes, 1480 - room 905
> Manguinhos
> Rio de Janeiro - RJ 21041-210
> Brazil
> phone +55.21.2598-2715
> fax +55.21.2598-2779
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
"The scientists of today think deeply instead of clearly. One must be
sane to think clearly, but one can think deeply and be quite insane."
Nikola Tesla
http://www.macgrass.com


From pburns at pburns.seanet.com  Thu Jun 28 11:28:17 2007
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Thu, 28 Jun 2007 10:28:17 +0100
Subject: [R] Populate matrix from data.frame
In-Reply-To: <Pine.LNX.4.64.0706280750150.24371@gannet.stats.ox.ac.uk>
References: <4683539A.3030407@siol.net>
	<Pine.LNX.4.64.0706280750150.24371@gannet.stats.ox.ac.uk>
Message-ID: <46837F31.1060204@pburns.seanet.com>

You need some caution with Brian's solution as it
depends on the matrix being in the same order as
the factors in the data frame.

a <- data.frame(cbind(x=c('a','a','a','b','c'), 
y=c('a','b','c','d','e'),z=c(1,2,3,4,5)))

mm <- matrix(0,5,5)
colnames(mm) <- c('a','b','c','d','e')
rownames(mm) <- c('a','b','c','d','e')

pp <- mm[5:1, 5:1]

mm[cbind(a$x, a$y)] <- a$z # desired result

pp[cbind(a$x, a$y)] <- a$z # not desired result

It would be nice if the following worked:

mm[cbind(as.character(a$x), as.character(a$y))] <- a$z


Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

Prof Brian Ripley wrote:

>On Thu, 28 Jun 2007, Andrej Kastrin wrote:
>
>  
>
>>Dear all,
>>
>>I have a data frame
>>a <- data.frame(cbind(x=c('a','a','a','b','c'),
>>y=c('a','b','c','d','e'),z=c(1,2,3,4,5)))
>>    
>>
>>>a
>>>      
>>>
>> x y z
>>1 a a 1
>>2 a b 2
>>3 a c 3
>>4 b d 4
>>5 c e 5
>>
>>and a matrix
>>mm <- matrix(0,5,5)
>>colnames(mm) <- c('a','b','c','d','e')
>>rownames(mm) <- c('a','b','c','d','e')
>>    
>>
>>>mm
>>>      
>>>
>> a b c d e
>>a 0 0 0 0 0
>>b 0 0 0 0 0
>>c 0 0 0 0 0
>>d 0 0 0 0 0
>>e 0 0 0 0 0
>>
>>How to populate matrix in a way that first column of data frame 'a'
>>correspond to rownames(mm), second column to colnames(mm) and the third
>>column is the element of matrix 'mm'?
>>    
>>
>
>mm[cbind(a$x, a$y)] <- a$z
>
>Please read about the forms of indexing matrices in 'An Introduction to 
>R'.
>
>  
>


From Bart.Vandewoestyne at telenet.be  Thu Jun 28 11:42:28 2007
From: Bart.Vandewoestyne at telenet.be (Bart Vandewoestyne)
Date: Thu, 28 Jun 2007 11:42:28 +0200
Subject: [R] maximum difference between two ECDF's
Message-ID: <20070628094228.GA12822@forsythe>

Hello,

I have a vector of samples x of length N.  Associated with each
sample x_i is a certain weight w_i.  All the weights are in another
vector w of the same length N.

I have another vector of samples y of length n (small n).  All
these samples have equal weights 1/n.  The ECDF of these samples
is defined as for example at
http://en.wikipedia.org/wiki/Empirical_distribution_function and
I can compute it using the ecdf() function in R.

I define the 'ECDF' of the samples x with their associated
weights in the following way:

F_N(x) = 1/N * sum_{i=1}^{N}w_i * Indicator(x_i <= x)

(does this 'ECDF' have another name???)

So it's basically the same formula as the one on the above URL, but the
only difference is that I multiply the indicator function for x_i with
the weight w_i.

Now suppose F_n(x) is the ECDF of the n samples with equal
weights 1/n, and F_N(x) is the 'ECDF' of the other samples with
their associated weights.

What I now would like to compute is the maximum difference
between these two, so:

max(abs(F_N(x)-F_n(x)))

So it's like computing the Kolmogorov-Smirnov statistic of two
discrete CDF's.

If i didn't have these weights, or if one of the two was a
continuous CDF, then I could simply use the ks.test() function.
However, my situation is different... my first set of samples has
associated weights and therefore the 'ECDF' has a slightly
different definition.

How can I compute max(abs(F_N(x)-F_n(x))) ?  Do there exist
standard functions for this?

Thanks,
Bart

-- 
	"Share what you know.  Learn what you don't."


From birgit.lemcke at systbot.uzh.ch  Thu Jun 28 11:47:58 2007
From: birgit.lemcke at systbot.uzh.ch (Birgit Lemcke)
Date: Thu, 28 Jun 2007 11:47:58 +0200
Subject: [R] Repeat if
Message-ID: <C7B7CCEB-9193-40ED-850F-0385F9C3BB5B@systbot.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070628/e7f2fe72/attachment.pl 

From Joao.Fadista at agrsci.dk  Thu Jun 28 11:55:55 2007
From: Joao.Fadista at agrsci.dk (=?iso-8859-1?Q?Jo=E3o_Fadista?=)
Date: Thu, 28 Jun 2007 11:55:55 +0200
Subject: [R] compare 2 vectors
Message-ID: <EA09C4B2B0F16E44B8F3311629493C0D02ED4F1A@DJFPOST01.djf.agrsci.dk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070628/4c0df913/attachment.pl 

From Jacques.Veslot at avignon.inra.fr  Thu Jun 28 12:05:59 2007
From: Jacques.Veslot at avignon.inra.fr (Jacques VESLOT)
Date: Thu, 28 Jun 2007 12:05:59 +0200
Subject: [R] Repeat if
In-Reply-To: <C7B7CCEB-9193-40ED-850F-0385F9C3BB5B@systbot.uzh.ch>
References: <C7B7CCEB-9193-40ED-850F-0385F9C3BB5B@systbot.uzh.ch>
Message-ID: <46838807.4020907@avignon.inra.fr>

sapply(1:85, function(i) eval(parse(text=paste("range(V", i, ", 
na.rm=T)", sep=""))))

Jacques VESLOT

INRA - Biostatistique & Processus Spatiaux
Site Agroparc 84914 Avignon Cedex 9, France

Tel: +33 (0) 4 32 72 21 58
Fax: +33 (0) 4 32 72 21 84



Birgit Lemcke a ?crit :
> Hello,
> (Power Book G4, Mac OS X, R 2.5.0)
>
> I would like to repeat the function range for 85 Vectors (V1-V85).
> I tried with this code:
>
> i<-0
>  > repeat {
> + i<-i+1
> + if (i<85) next
> + range (Vi, na.rm = TRUE)
> + if (i==85) break
> + }
>
> I presume that the Vi is wrong, because in this syntax i is not known  
> as a variable. But I don?t know how to say that it is a variable here.
> Would be nice if somebody could help me.
> Perhaps I?m thinking too complicated and there is an easier way to do  
> this.
>
> Thanks in advance
>
> Greetings
>
> Birgit
>
> Birgit Lemcke
> Institut f?r Systematische Botanik
> Zollikerstrasse 107
> CH-8008 Z?rich
> Switzerland
> Ph: +41 (0)44 634 8351
> birgit.lemcke at systbot.uzh.ch
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
>   
> ------------------------------------------------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From christophe at pallier.org  Thu Jun 28 12:13:03 2007
From: christophe at pallier.org (Christophe Pallier)
Date: Thu, 28 Jun 2007 12:13:03 +0200
Subject: [R] compare 2 vectors
In-Reply-To: <EA09C4B2B0F16E44B8F3311629493C0D02ED4F1A@DJFPOST01.djf.agrsci.dk>
References: <EA09C4B2B0F16E44B8F3311629493C0D02ED4F1A@DJFPOST01.djf.agrsci.dk>
Message-ID: <dea6cb960706280313v51c703a5seeeffc5f5a63df18@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070628/24e2ac35/attachment.pl 

From antonio.fabio at gmail.com  Thu Jun 28 12:14:31 2007
From: antonio.fabio at gmail.com (Antonio, Fabio Di Narzo)
Date: Thu, 28 Jun 2007 12:14:31 +0200
Subject: [R] compare 2 vectors
In-Reply-To: <EA09C4B2B0F16E44B8F3311629493C0D02ED4F1A@DJFPOST01.djf.agrsci.dk>
References: <EA09C4B2B0F16E44B8F3311629493C0D02ED4F1A@DJFPOST01.djf.agrsci.dk>
Message-ID: <b0808fdc0706280314r5b36f47fm5ec565492ea9c4d3@mail.gmail.com>

setdiff(b, a)

2007/6/28, Jo?o Fadista <Joao.Fadista a agrsci.dk>:
> Dear all,
>
> I would like to take out the values from one vector that are equal to the values in another vector.
>
> Example:
> a <- c(1,2,3,4,5,6,7,8,9)
> b <- c(3,10,20,5,6)
> b_noRepeats = c(10,20)
>
> So I would like to have the vector b without the same values as vector a.
>
>
> Kind regards,
> Jo?o Fadista
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help a stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Antonio, Fabio Di Narzo
Ph.D. student at
Department of Statistical Sciences
University of Bologna, Italy


From christophe at pallier.org  Thu Jun 28 12:14:48 2007
From: christophe at pallier.org (Christophe Pallier)
Date: Thu, 28 Jun 2007 12:14:48 +0200
Subject: [R] compare 2 vectors
In-Reply-To: <dea6cb960706280313v51c703a5seeeffc5f5a63df18@mail.gmail.com>
References: <EA09C4B2B0F16E44B8F3311629493C0D02ED4F1A@DJFPOST01.djf.agrsci.dk>
	<dea6cb960706280313v51c703a5seeeffc5f5a63df18@mail.gmail.com>
Message-ID: <dea6cb960706280314p12e0bf3cg5d0d91dbd2866c68@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070628/4c1321e8/attachment.pl 

From suffenaam at yahoo.com  Thu Jun 28 11:29:14 2007
From: suffenaam at yahoo.com (R. Leenders)
Date: Thu, 28 Jun 2007 17:29:14 +0800 (CST)
Subject: [R] using self-written functions
Message-ID: <105933.73372.qm@web63915.mail.re1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070628/d583e07b/attachment.pl 

From birgit.lemcke at systbot.uzh.ch  Thu Jun 28 12:27:06 2007
From: birgit.lemcke at systbot.uzh.ch (Birgit Lemcke)
Date: Thu, 28 Jun 2007 12:27:06 +0200
Subject: [R] Repeat if
In-Reply-To: <46838807.4020907@avignon.inra.fr>
References: <C7B7CCEB-9193-40ED-850F-0385F9C3BB5B@systbot.uzh.ch>
	<46838807.4020907@avignon.inra.fr>
Message-ID: <B99519F4-41DA-4768-9E5A-0FAEEC5FB5D9@systbot.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070628/983f02ab/attachment.pl 

From john.seers at bbsrc.ac.uk  Thu Jun 28 12:23:17 2007
From: john.seers at bbsrc.ac.uk (john seers (IFR))
Date: Thu, 28 Jun 2007 11:23:17 +0100
Subject: [R] Repeat if
In-Reply-To: <C7B7CCEB-9193-40ED-850F-0385F9C3BB5B@systbot.uzh.ch>
References: <C7B7CCEB-9193-40ED-850F-0385F9C3BB5B@systbot.uzh.ch>
Message-ID: <AAD49F46EAE3F6479E1D46428FAC31CB0181AB40@NBIE2KSRV1.nbi.bbsrc.ac.uk>

 
Hi

I think a for loop would be more what you want.

Something along the lines of:


V<-list(a=c(1,2,3), b=c(2,3,4)) # list of 2 vectors

for ( i in 1:2 ) {          # 2 vectors (replace with 85 ...)
    print(range (V[i], na.rm = TRUE))
}


Regards

JS
 
---

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Birgit Lemcke
Sent: 28 June 2007 10:48
To: R Hilfe
Subject: [R] Repeat if

Hello,
(Power Book G4, Mac OS X, R 2.5.0)

I would like to repeat the function range for 85 Vectors (V1-V85).
I tried with this code:

i<-0
 > repeat {
+ i<-i+1
+ if (i<85) next
+ range (Vi, na.rm = TRUE)
+ if (i==85) break
+ }


From dimitris.rizopoulos at med.kuleuven.be  Thu Jun 28 12:30:05 2007
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Thu, 28 Jun 2007 12:30:05 +0200
Subject: [R] compare 2 vectors
References: <EA09C4B2B0F16E44B8F3311629493C0D02ED4F1A@DJFPOST01.djf.agrsci.dk>
Message-ID: <002f01c7b96f$4b677bd0$0540210a@www.domain>

look at setdiff(), e.g.,

setdiff(b, a)


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Jo?o Fadista" <Joao.Fadista at agrsci.dk>
To: <r-help at stat.math.ethz.ch>
Sent: Thursday, June 28, 2007 11:55 AM
Subject: [R] compare 2 vectors


Dear all,

I would like to take out the values from one vector that are equal to 
the values in another vector.

Example:
a <- c(1,2,3,4,5,6,7,8,9)
b <- c(3,10,20,5,6)
b_noRepeats = c(10,20)

So I would like to have the vector b without the same values as vector 
a.


Kind regards,
Jo?o Fadista





[[alternative HTML version deleted]]




--------------------------------------------------------------------------------


> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm


From christophe at pallier.org  Thu Jun 28 12:34:06 2007
From: christophe at pallier.org (Christophe Pallier)
Date: Thu, 28 Jun 2007 12:34:06 +0200
Subject: [R] Repeat if
In-Reply-To: <C7B7CCEB-9193-40ED-850F-0385F9C3BB5B@systbot.uzh.ch>
References: <C7B7CCEB-9193-40ED-850F-0385F9C3BB5B@systbot.uzh.ch>
Message-ID: <dea6cb960706280334q6b466ac7xf7591e6fba50bc8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070628/72f1c6b2/attachment.pl 

From dieter.vanderelst at gmail.com  Thu Jun 28 12:55:34 2007
From: dieter.vanderelst at gmail.com (Dieter Vanderelst)
Date: Thu, 28 Jun 2007 12:55:34 +0200
Subject: [R] prior covariance in Mclust
Message-ID: <fd0b46f40706280355r4a1e37d5x8ec4842431fae380@mail.gmail.com>

Hello,

I'm trying to use Mclust to fit a Gaussian Mixture Model to a
mulitdimensional data set.

Because  of the specific source of my data, I know that all components
have the same variance and that the covariance between dimensions is
zero (modelname=VII).
Furthermore, I have a reliable estimate of the variance of the components.

I want to to use this estimate as a prior in mclust, hoping that
exploiting this knowledge will yield better estimates of the number of
components and their means (which are the unknowns).

First I have a general question: Is this a sensible thing to do? As
far as I can see (which might be not too far), this will indeed lead
to more robust estimates. But is this true?

Another question concerns the practical side of things. How can I do
this in mclust? I've read through the manual but this leaves me
uncertain about the exact implementation (and earlier posts about this
problem seem not to have been answered by the mailing list).

If specifying a prior for the covariance matrix is possible (and
sensible) in mclust, could someone provide an example of how to
specify a prior on the covariance matrix?

Thank you,
Dieter


From rfrancois at mango-solutions.com  Thu Jun 28 12:55:54 2007
From: rfrancois at mango-solutions.com (Romain Francois)
Date: Thu, 28 Jun 2007 11:55:54 +0100
Subject: [R] compare 2 vectors
In-Reply-To: <dea6cb960706280313v51c703a5seeeffc5f5a63df18@mail.gmail.com>
References: <EA09C4B2B0F16E44B8F3311629493C0D02ED4F1A@DJFPOST01.djf.agrsci.dk>
	<dea6cb960706280313v51c703a5seeeffc5f5a63df18@mail.gmail.com>
Message-ID: <468393BA.50008@mango-solutions.com>

Christophe Pallier wrote:
> On 6/28/07, Jo?o Fadista <Joao.Fadista at agrsci.dk> wrote:
>   
>> I would like to take out the values from one vector that are equal to the
>> values in another vector.
>>
>> Example:
>> a <- c(1,2,3,4,5,6,7,8,9)
>> b <- c(3,10,20,5,6)
>> b_noRepeats = c(10,20)
>>
>>
>>     
>  b[!(b %in% intersect(a,b))]
>
> See ?intersect
>   
Hi,

There is also a pretty useful operator %w/o% in the help page of %in%. see :

 > ?`%in%`
 > a <- c(1,2,3,4,5,6,7,8,9)
 > b <- c(3,10,20,5,6)
 > b %w/o% a
[1] 10 20

Cheers,

Romain

-- 
Mango Solutions
data analysis that delivers

Tel:  +44(0) 1249 467 467
Fax:  +44(0) 1249 467 468
Mob:  +44(0) 7813 526 123


From karlknoblich at yahoo.de  Thu Jun 28 13:08:10 2007
From: karlknoblich at yahoo.de (Karl Knoblick)
Date: Thu, 28 Jun 2007 11:08:10 +0000 (GMT)
Subject: [R] aov and lme differ with interaction in oats example of MASS?
Message-ID: <91690.78118.qm@web26511.mail.ukl.yahoo.com>

Dear R-Community!

The example "oats" in MASS (2nd edition, 10.3, p.309) is calculated for aov and lme without interaction term and the results are the same. 
But I have problems to reproduce the example aov with interaction in MASS (10.2, p.301) with lme. Here the script:

library(MASS)
library(nlme)
options(contrasts = c("contr.treatment", "contr.poly"))
# aov: Y ~ N + V
oats.aov <- aov(Y ~ N + V + Error(B/V), data = oats, qr = T)
summary(oats.aov)
# now lme
oats.lme<-lme(Y ~ N + V, random = ~1 | B/V, data = oats)
anova(oats.lme, type="m") # Ok!
# aov:Y ~ N * V + Error(B/V)
oats.aov2 <- aov(Y ~ N * V + Error(B/V), data = oats, qr = T)
summary(oats.aov2)
# now lme - my trial!
oats.lme2<-lme(Y ~ N * V, random = ~1 | B/V, data = oats)
anova(oats.lme2, type="m")
# differences!!! (except of interaction term)

My questions:
1) Is there a possibility to reproduce the result of aov with interaction using lme?
2) If not, which result of the above is the correct one for the oats example? 

Thanks a lot!
Karl


      __________________________________  Alles was der Gesundheit und Entspannung dient. BE A BETTER MEDIZINMANN! www.yahoo.de/clever


From christophe at pallier.org  Thu Jun 28 13:23:33 2007
From: christophe at pallier.org (Christophe Pallier)
Date: Thu, 28 Jun 2007 13:23:33 +0200
Subject: [R] using self-written functions
In-Reply-To: <105933.73372.qm@web63915.mail.re1.yahoo.com>
References: <105933.73372.qm@web63915.mail.re1.yahoo.com>
Message-ID: <dea6cb960706280423y16045274l1fa0d8dae1e68e07@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070628/f57366dd/attachment.pl 

From gavin.simpson at ucl.ac.uk  Thu Jun 28 13:34:41 2007
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Thu, 28 Jun 2007 12:34:41 +0100
Subject: [R] using self-written functions
In-Reply-To: <105933.73372.qm@web63915.mail.re1.yahoo.com>
References: <105933.73372.qm@web63915.mail.re1.yahoo.com>
Message-ID: <1183030481.9413.17.camel@gsimpson.geog.ucl.ac.uk>

On Thu, 2007-06-28 at 17:29 +0800, R. Leenders wrote:
> Hi, I am pretty new to R, so I apologize for the obvious question.
> I
> have worked with R for a few months now and in the process have written
> several functions that I frequently use in various data analysis
> projects. I tend to give each project a directory of its own and set
> the working directory to that.
> Since there are several tasks that
> need to be accomplished in many of my projects, I frequently want to
> use functions I have written previously. My question is, how do I get
> access to them? The way I do it now is copy the relevant code to the
> script file of the project I am working on at the time and then run it
> so as to make the functions available. But that seems to be
> unnecessarily cumbersome. I used to work a lot with gauss, which had
> the opportunity of putting one's own functions is one directory and
> gauss would then have that directory in its search path always. How can
> I access my own functions in R without having to copy-paste them
> everytime and run them manually so I can call them later? Do I need to
> learn how to write a package and attach the package to make the
> functions available at all times? Is there another way?

Building a package is one way, and not that difficult once you've read
the Writing R Extensions manual.

An alternative is to have a directory where you keep R function scripts.
Put your functions in here in text files with say a .R extension. Then
in R you can source one or more of these R scripts as required, using
the source() function.

Say you have a directory, myScripts at the base of file system
(/home/user say on Linux or C:\ on Windows). in this directory there is
a file called my_r_function.R. To use this script/function in an R
session, you would issue:

## replace /home/user/ with what ever is the correct path for your
## system
source("/home/user/myScripts/my_r_function.R")

Which would make available to your current session any functions defined
in my_r_function.R.

Read ?source for more information.

HTH

G

> 
> thanks, James
> 
> 
> 
> 
>        
> ____________________________________________________________________________________
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Gavin Simpson                 [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From ccleland at optonline.net  Thu Jun 28 13:51:49 2007
From: ccleland at optonline.net (Chuck Cleland)
Date: Thu, 28 Jun 2007 07:51:49 -0400
Subject: [R] Meta-Analysis of proportions
In-Reply-To: <01dc01c7b8fb$21fc6680$9aa8569d@dcs012S>
References: <01dc01c7b8fb$21fc6680$9aa8569d@dcs012S>
Message-ID: <4683A0D5.3050307@optonline.net>

Monica Malta wrote:
> Dear colleagues,
> 
> I'm conducting a meta-analysis of studies evaluating adherence of HIV-positive drug users into AIDS treatment, therefore I'm looking for some advice and syntax suggestion for running the meta-regression using proportions, not the usual OR/RR frequently used on RCT studies.
> 
> Have already searched already several handbooks, R-manuals, mailing lists, professors, but... not clue at all...
> 
> Does anyone have already tried this? A colleague of mine recently published a similar study on JAMA, but he used OpenBUGS - a software I'm not familiar with...
> 
> If there is any tip/suggestion for a possible syntax, could someone send me? I need to finish this paper before my PhD qualify, but I'm completely stuck...
> 
> So, any tip will be more than welcome...I will really appreciate it!!! 
> 
> Thanks in advance and congrats on the amazing mailing-list.

  Specifying adherence as the "effect size", if you can also specify a
sampling variance perhaps you can use a tool like mima
(http://www.wvbauer.com/downloads/mima_tutorial.pdf).  For example,
working with logits rather than proportions directly, consider the
following example data:

> df
   ntot nadhere mod      prop      logit        se
1   100      76   0 0.7600000 -1.1526795 0.2341463
2   125      98   0 0.7840000 -1.2891306 0.2173501
3    50      37   0 0.7400000 -1.0459686 0.3224127
4   200     159   0 0.7950000 -1.3553321 0.1751557
5   150     114   0 0.7600000 -1.1526795 0.1911796
6    80      56   1 0.7000000 -0.8472979 0.2439749
7   160     113   1 0.7062500 -0.8772402 0.1735688
8   200     130   1 0.6500000 -0.6190392 0.1482498
9   120      75   1 0.6250000 -0.5108256 0.1885618
10  105      78   1 0.7428571 -1.0608720 0.2232879

  Then do the meta-regression as follows:

> source("http://www.wvbauer.com/downloads/mima.ssc")

> with(df, mima(yi=logit, vi=se, mods=mod))

Estimate of (Residual) Heterogeneity: 0

Test for (Residual) Heterogeneity:

QE      =  1.2419
df      =  8
p-value =  0.9962

Parameter Estimates:

           [,1]
intrcpt -1.2161
mods     0.4520

Variance-Covariance Matrix of Parameter Estimates:

        intrcpt    mods
intrcpt  0.0436 -0.0436
mods    -0.0436  0.0815

Omnibus Test of all Moderators:

QME     =  2.5058
df      =  1
p-value =  0.1134

Individual Moderator Tests:

        estimate     SE    zval   pval    CI_L    CI_U
intrcpt  -1.2161 0.2089 -5.8213 0.0000 -1.6256 -0.8067
mods      0.4520 0.2856  1.5830 0.1134 -0.1077  1.0117

> Bests from Rio de Janeiro, Brazil.
> 
> Monica  
> 
> Monica Malta
> Researcher
> Oswaldo Cruz Foundation - FIOCRUZ
> Social Science Department - DCS/ENSP
> Rua Leopoldo Bulhoes, 1480 - room 905
> Manguinhos
> Rio de Janeiro - RJ 21041-210
> Brazil
> phone +55.21.2598-2715
> fax +55.21.2598-2779
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From mswierniak at o2.pl  Thu Jun 28 14:00:35 2007
From: mswierniak at o2.pl (jastar)
Date: Thu, 28 Jun 2007 05:00:35 -0700 (PDT)
Subject: [R] Writing - specyfic format
Message-ID: <11341784.post@talk.nabble.com>


Hi all,
I have a trouble - I need to write file in a very specyfic format.
I have two vectors which different lengths and one data.frame (or matrix).
I want to write it to "*.txt" file in following way:
1st row of file is my 1st vector (separate by spacebar)
2nd row of file is 2nd vector (also separate by spacebar)
Rest of this file should be a matrix with elements separated by tab.
For example: a=1, 2, 3, b=4, 5, c=[1, 2, 3, 4, 5, 6;
                                            7, 8, 9, 10, 11, 12,]
and I want to have file (it have to be .txt file) like:
1 2 3
4 5
1     2     3     4     5     6
7     8     9     10   11    12

This thing have to be done automaticly from R.
Is it possible?
Thank you in advance
-- 
View this message in context: http://www.nabble.com/Writing---specyfic-format-tf3994017.html#a11341784
Sent from the R help mailing list archive at Nabble.com.


From P.Dalgaard at biostat.ku.dk  Thu Jun 28 13:43:56 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 28 Jun 2007 13:43:56 +0200
Subject: [R] R 2.5.1 is released
Message-ID: <46839EFC.8070806@biostat.ku.dk>

I've rolled up R-2.5.1.tar.gz a short while ago. This is a maintenance
release and fixes a number of mostly minor bugs and platform issues. See 
the full list of changes below.

You can get it (in a short while) from

http://cran.r-project.org/src/base/R-2/R-2.5.1.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you. Binaries
for various platforms will appear in due course.
 
        For the R Core Team

        Peter Dalgaard

These are the md5sums for the freshly created files, in case you wish
to check that they are uncorrupted:

a8efde35b940278de19730d326f58449  AUTHORS
eb723b61539feef013de476e68b5c50a  COPYING
a6f89e2100d9b6cdffcea4f398e37343  COPYING.LIB
24ad9647e525609bce11f6f6ff9eac2d  FAQ
70447ae7f2c35233d3065b004aa4f331  INSTALL
f04bdfaf8b021d046b8040c8d21dad41  NEWS
88bbd6781faedc788a1cbd434194480c  ONEWS
4f004de59e24a52d0f500063b4603bcb  OONEWS
162f6d5a1bd7c60fd652145e050f3f3c  R-2.5.1.tar.gz
162f6d5a1bd7c60fd652145e050f3f3c  R-latest.tar.gz
433182754c05c2cf7a04ad0da474a1d0  README
020479f381d5f9038dcb18708997f5da  RESOURCES
4eaf8a3e428694523edc16feb0140206  THANKS


Here is the relevant bit of the NEWS file:

                CHANGES IN R VERSION 2.5.1

NEW FEATURES

    o   density(1:20, bw = "SJ") now works as bw.SJ() now tries a larger
        search interval than the default (lower, upper) if it does not
        find a solution within the latter.

    o   The output of library() (no arguments) is now sorted by library
        trees in the order of .libPaths() and not alphabetically.

    o   R_LIBS_USER and R_LIBS_SITE feature possible expansion of
        specifiers for R version specific information as part of the
        startup process.

    o   C-level warning calls now print a more informative context,
        as C-level errors have for a while.

    o   There is a new option "rl_word_breaks" to control the way the
        input line is tokenized in the readline-based terminal
        interface for object- and file-name completion.
        This allows it to be tuned for people who use their space bar
        vs those who do not.  The default now allows filename-completion
        with +-* in the filenames.

    o   If the srcfile argument to parse() is not NULL, it will be added
        to the result as a "srcfile" attribute.

    o   It is no longer possible to interrupt lazy-loading (which was
        only at all likely when lazy-loading environments), which
        would leave the object being loaded in an unusable state.
        This is a temporary measure: error-recovery when evaluating
        promises will be tackled more comprehensively in 2.6.0.

INSTALLATION

    o   'make check' will work with --without-iconv, to accommodate
        building on AIX where the system iconv conflicts with
        libiconv and is not compatible with R's requirements.

    o   There is support for 'DESTDIR': see the R-admin manual.

    o   The texinfo manuals are now converted to HTML with a style
        sheet: in recent versions of makeinfo the markup such as @file
        was being lost in the HTML rendering.

    o   The use of inlining has been tweaked to avoid warnings from
        gcc >= 4.2.0 when compiling in C99 mode (which is the default
        from configure).

BUG FIXES

    o   as.dendrogram() failed on objects of class "dendrogram".

    o   plot(type ="s") (or "S") with many (hundreds of thousands)
        of points could overflow the stack.  (PR#9629)

    o   Coercing an S4 classed object to "matrix" (or other basic class)
        failed to unset the S4 bit.

    o   The 'useS4' argument of print.default() had been broken by an
        unrelated change prior to 2.4.1.  This allowed print() and
        show() to bounce badly constructed S4 objects between
        themselves indefinitely.

    o   Prediction of the seasonal component in HoltWinters() was one
        step out at one point in the calculations.

        decompose() incorrectly computed the 'random' component for a
        multiplicative fit.

    o   Wildcards work again in unlink() on Unix-alikes (they did not
        in 2.5.0).

    o   When qr() used pivoting, the coefficient names in qr.coef() were
        not pivoted to match.  (PR#9623)

    o   UseMethod() could crash R if the first argument was not a
        character string.

    o   R and Rscript on Unix-alikes were not accepting spaces in -e
        arguments (even if quoted).

    o   Hexadecimal integer constants (e.g. 0x10L) were not being parsed
        correctly on platforms where the C function atof did not
        accept hexadecimal prefixes (as required by C99, but not
        implemented in MinGW as used by R on Windows).  (PR#9648)

    o   libRlapack.dylib on Mac OS X had no version information and
        sometimes an invalid identification name.

    o   Rd conversion of \usage treated '\\' as a single backslash in
        all but latex: it now acts consistently with the other
        verbatim-like environments (it was never 'verbatim' despite
        the documentation).

        \code{\.} is now rendered as '\.' in all formats, as
        documented (it was not the case for latex conversion).

        codoc() (and checkDocStyle() and checkDocUsage()) now apply
        the same transformations to \usage as Rd conversion does,
        so {, % and \\ in strings in usages will now be related
        correctly to the help files.

    o   rbind() failed if the only data frame had 0 rows. (PR#9657)

    o   <a data.frame>[i, j] could sometimes select the wrong column
        when j is numeric if there are duplicate column names.

    o   sample(x, size, replace=TRUE, prob) had a memory leak if
        10000 < size <= 100000.

    o   x <- cbind(1:2); rownames(x) <- factor(c("A",NA))  now longer
        segfaults.

    o   R CMD BATCH no longer assumes Sys.unsetenv() is supported (it
        is not on older Solaris systems).

    o   median() returned a logical result when it was 'NA': it now
        returns an NA of appropriate type (e.g. integer or double).

    o   grep(fixed = TRUE, perl = TRUE) ignored 'fixed', although it
        was documented to ignore 'perl'
        Same for [g]regexpr and [g]sub.

    o   getNamespaceExports("base") works again.

    o   runmed(c(), 1) no longer segfaults.

    o   qr.coef(QR, b) failed for an LAPACK-produced QR if b was
        integer or for an over-determined system.

        qr.solve() for an under-determined system produces a
        solution with 0 and not NA for columns which are unused.

    o   segments() was not handling full transparency correctly in PDF.
        (PR#9694)

        Nor was arrows().

    o   callGeneric() inside a method with extra arguments {and hence
        currently defined via .local()} now works.

    o   [g]sub(fixed=TRUE, useBytes=FALSE) could substitute in the
        wrong place in an MBCS locale.

        gregexpr() could give incorrect answers in MBCS locales for
        perl = TRUE or fixed = TRUE (unless useBytes = TRUE).

    o   The legacy quartz() device no longer crashes in locator()
        if the user attempts to close the window.

    o   "CGGStackRestore: gstack underflow" warning is no longer shown
        in legacy quartz() device.

    o   formatC() now limits 'digits' to 50 to avoid problems in
        C-level sprintf in some OSes.

    o   seq.int(x, y, by=z) gave 'x' (and not an error) if
        0 > (y-x)/z > -1.

    o   promptClass() now lists methods, including those for generics in
        other attached packages.

    o   Connection-related functions such as readBin() no longer crash
        when supplied with a non-connection object.

    o   as.character.srcref() didn't handle bad srcref objects cleanly.

    o   predict.nls() no longer requires 'newdata' to contain exactly
        the variable names needed to fit the model: variables used on
        the LHS only are no longer required and further variables are
        allowed.

    o   plot.hclust() had a 'out by one' error, and ignored the last
        object when computing the window region (and could overrun
        arrays).

    o   deriv() was creating results with double (and not integer) dims.

    o   The unserialize code (e.g. as called by load()) looked for a
        function findPackageEnv() to set a saved package environment.
        This was missing, but is now supplied.

    o   [cr]bind could segfault when creating a list matrix result.
        (Reported by Martin Morgan.)

    o   besselI(x, nu, exp=TRUE) and besselY(x, nu) could give wrong
        answers for nu < 0. (Reported by Hiroyuki Kawakatsu.)

    o   [g]sub could confuse a trailing byte '\' for a backreference
        in MBCSs where '\' can occur as a trailing byte (not UTF-8 nor
        EUC-JP, but SJIS and the CJK character sets used on Windows).
        (PR#9751)



-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907

_______________________________________________
R-announce at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From albmont at centroin.com.br  Thu Jun 28 14:21:16 2007
From: albmont at centroin.com.br (Alberto Monteiro)
Date: Thu, 28 Jun 2007 10:21:16 -0200
Subject: [R] compare 2 vectors
In-Reply-To: <468393BA.50008@mango-solutions.com>
References: <EA09C4B2B0F16E44B8F3311629493C0D02ED4F1A@DJFPOST01.djf.agrsci.dk>
	<dea6cb960706280313v51c703a5seeeffc5f5a63df18@mail.gmail.com>
	<468393BA.50008@mango-solutions.com>
Message-ID: <20070628121849.M78770@centroin.com.br>

Romain Francois wrote:
> 
> There is also a pretty useful operator %w/o% in the help page of 
> %in%. see :
> 
>  > ?`%in%`
>  > a <- c(1,2,3,4,5,6,7,8,9)
>  > b <- c(3,10,20,5,6)
>  > b %w/o% a
> [1] 10 20
> 
I don't like the example. It's not obvious, in the expression...

  x[!x %in% y]

... that this is the same as x[!(x %in% y)] and not x[(!x) %in% y]

Alberto Monteiro


From P.Dalgaard at biostat.ku.dk  Thu Jun 28 14:27:30 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 28 Jun 2007 14:27:30 +0200
Subject: [R] aov and lme differ with interaction in oats example of MASS?
In-Reply-To: <91690.78118.qm@web26511.mail.ukl.yahoo.com>
References: <91690.78118.qm@web26511.mail.ukl.yahoo.com>
Message-ID: <4683A932.3020600@biostat.ku.dk>

Karl Knoblick wrote:
> Dear R-Community!
>
> The example "oats" in MASS (2nd edition, 10.3, p.309) is calculated for aov and lme without interaction term and the results are the same. 
> But I have problems to reproduce the example aov with interaction in MASS (10.2, p.301) with lme. Here the script:
>
> library(MASS)
> library(nlme)
> options(contrasts = c("contr.treatment", "contr.poly"))
> # aov: Y ~ N + V
> oats.aov <- aov(Y ~ N + V + Error(B/V), data = oats, qr = T)
> summary(oats.aov)
> # now lme
> oats.lme<-lme(Y ~ N + V, random = ~1 | B/V, data = oats)
> anova(oats.lme, type="m") # Ok!
> # aov:Y ~ N * V + Error(B/V)
> oats.aov2 <- aov(Y ~ N * V + Error(B/V), data = oats, qr = T)
> summary(oats.aov2)
> # now lme - my trial!
> oats.lme2<-lme(Y ~ N * V, random = ~1 | B/V, data = oats)
> anova(oats.lme2, type="m")
> # differences!!! (except of interaction term)
>
> My questions:
> 1) Is there a possibility to reproduce the result of aov with interaction using lme?
>  2) If not, which result of the above is the correct one for the oats example? 
>   

The issue is that you are using marginal tests which will do strange
things when contrasts are not coded "right", and in particular treatment
contrasts are not. Switch to e.g. contr.helmert and the results become
similar. Marginal tests of main effects in the presence of interaction
is not necessarily a good idea and they have been debated here and
elsewhere a number of times before. People don't agree entirely, but the
dividing line is essentially whether it is uniformly or just mostly a
bad idea. It is essentially the discussion of type III SS.

> fortune("type III")

Some of us feel that type III sum of squares and so-called ls-means are
statistical nonsense which should have been left in SAS.
   -- Brian D. Ripley
      s-news (May 1999)


> Thanks a lot!
> Karl
>
>
>       __________________________________  Alles was der Gesundheit und Entspannung dient. BE A BETTER MEDIZINMANN! www.yahoo.de/clever
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From regina.verghis at gmail.com  Thu Jun 28 14:32:42 2007
From: regina.verghis at gmail.com (Regina Verghis)
Date: Thu, 28 Jun 2007 18:02:42 +0530
Subject: [R] Help in Bootstrapping
Message-ID: <49f266b90706280532q3acbb0c7ycb6ef5b5783e7c70@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070628/7b08065a/attachment.pl 

From ghughes.email at gmail.com  Thu Jun 28 14:48:03 2007
From: ghughes.email at gmail.com (Gareth Hughes)
Date: Thu, 28 Jun 2007 13:48:03 +0100
Subject: [R] lme correlation structures
In-Reply-To: <001501c7b8cc$b0655aa0$4d908980@gne.windows.gene.com>
References: <3cc99a20706270750w5a77c51eid44db929ad21b5a1@mail.gmail.com>
	<001501c7b8cc$b0655aa0$4d908980@gne.windows.gene.com>
Message-ID: <3cc99a20706280548x7b9edfc5n8fa64f8a9424adfa@mail.gmail.com>

Thanks for your help. I can weight the variances in the 2 groups using
"weights", as in

lme(Y~1+time+sex+age, random=~1|indv,
correlation=corAR1(form=~time|indv),
weights=varIdent(form=~1|sex),method="ML")

but what I would like is to have a different "phi" estimate for each
gender, not just different variances. Will track down a copy of the
Pinheiro and Bates book...



On 6/27/07, Bert Gunter <gunter.berton at gene.com> wrote:
> Please read ?lme carefully -- the info you seek is there. In particular, the
> weights argument for changing variance weighting by covariates and the
> correlation argument for specifying correlation structures.
>
> Pinheiro and Bates's MIXED EFFECT MODELS IN S... is the canonical reference
> (which you should get if you want to use R as you said) that exposits the
> ideas at greater length.
>
>
> Bert Gunter
> Genentech Nonclinical Statistics
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Gareth Hughes
> Sent: Wednesday, June 27, 2007 7:50 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] lme correlation structures
>
> Hi all,
>
> I've been using SAS proc mixed to fit linear mixed models and would
> like to be able to fit the same models in R. Two things in particular:
>
> 1) I have longitudinal data and wish to allow for different repeated
> measures covariance parameter estimates for different groups (men and
> women), each covariance matrix having the same structure. In proc
> mixed this would be done by specifying group= in the REPEATED
> statement. Is this simple to do in R? (I've tried form=~time|indv/sex
> for example but this doesn't seem to do the job).
>
> 2) I've read that other correlation structures can be specified. Does
> anyone have any examples of how toeplitz or (first-order)
> ante-dependence structures can be specified?
>
> Many thanks,
>
> Gareth
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


From ripley at stats.ox.ac.uk  Thu Jun 28 15:02:29 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 28 Jun 2007 14:02:29 +0100 (BST)
Subject: [R] aov and lme differ with interaction in oats example of MASS?
In-Reply-To: <91690.78118.qm@web26511.mail.ukl.yahoo.com>
References: <91690.78118.qm@web26511.mail.ukl.yahoo.com>
Message-ID: <Pine.LNX.4.64.0706281357460.9361@gannet.stats.ox.ac.uk>

On Thu, 28 Jun 2007, Karl Knoblick wrote:

> Dear R-Community!
>
> The example "oats" in MASS (2nd edition, 10.3, p.309) is calculated for aov and lme without interaction term and the results are the same.
> But I have problems to reproduce the example aov with interaction in MASS (10.2, p.301) with lme. Here the script:
>
> library(MASS)
> library(nlme)
> options(contrasts = c("contr.treatment", "contr.poly"))

That is the problem.  You need true contrasts, so use contr.helmert.  When 
I did so I got the same results from lme and aov for the anovas.

The question of what a 'marginal' AoV means without orthogonality is moot.
The sequential version is fine here.

> # aov: Y ~ N + V
> oats.aov <- aov(Y ~ N + V + Error(B/V), data = oats, qr = T)
> summary(oats.aov)
> # now lme
> oats.lme<-lme(Y ~ N + V, random = ~1 | B/V, data = oats)
> anova(oats.lme, type="m") # Ok!
> # aov:Y ~ N * V + Error(B/V)
> oats.aov2 <- aov(Y ~ N * V + Error(B/V), data = oats, qr = T)
> summary(oats.aov2)
> # now lme - my trial!
> oats.lme2<-lme(Y ~ N * V, random = ~1 | B/V, data = oats)
> anova(oats.lme2, type="m")
> # differences!!! (except of interaction term)
>
> My questions:
> 1) Is there a possibility to reproduce the result of aov with interaction using lme?
> 2) If not, which result of the above is the correct one for the oats example?
>
> Thanks a lot!
> Karl

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From P.Dalgaard at biostat.ku.dk  Thu Jun 28 15:04:43 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 28 Jun 2007 15:04:43 +0200
Subject: [R] : regular expressions: escaping a dot
In-Reply-To: <Pine.LNX.4.64.0706280921230.4206@gannet.stats.ox.ac.uk>
References: <20070628074357.GA4502@s1x.fischer-zim.local>
	<Pine.LNX.4.64.0706280921230.4206@gannet.stats.ox.ac.uk>
Message-ID: <4683B1EB.7030501@biostat.ku.dk>

Prof Brian Ripley wrote:
>
>
> This is explained in ?regexp (in the See Also of ?regexpr):
>
>       Patterns are described here as they would be printed by 'cat': _do
>       remember that backslashes need to be doubled when entering R
>       character strings from the keyboard_.
>
> and in the R FAQ and ....
>
>   
Hmm, that's not actually correct, is it? Perhaps this is better

"...entering R character string literals (i.e., between quote symbols.)"

The counterexample would be

> readLines()
\\abc
[1] "\\\\abc"

(of course it is more important to get people to read the documentation
at all...)

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From Jacques.Veslot at avignon.inra.fr  Thu Jun 28 15:17:43 2007
From: Jacques.Veslot at avignon.inra.fr (Jacques VESLOT)
Date: Thu, 28 Jun 2007 15:17:43 +0200
Subject: [R] Repeat if
In-Reply-To: <B99519F4-41DA-4768-9E5A-0FAEEC5FB5D9@systbot.uzh.ch>
References: <C7B7CCEB-9193-40ED-850F-0385F9C3BB5B@systbot.uzh.ch>
	<46838807.4020907@avignon.inra.fr>
	<B99519F4-41DA-4768-9E5A-0FAEEC5FB5D9@systbot.uzh.ch>
Message-ID: <4683B4F7.2060501@avignon.inra.fr>

you may have a vector with only NA values in it...

max(c(NA,NA), na.rm=T)
[1] -Inf
Warning message:
aucun argument pour max ; -Inf est renvoy?

Jacques VESLOT

INRA - Biostatistique & Processus Spatiaux
Site Agroparc 84914 Avignon Cedex 9, France

Tel: +33 (0) 4 32 72 21 58
Fax: +33 (0) 4 32 72 21 84



Birgit Lemcke a ?crit :
> Thanks that was really a quick answer.
>
> It works but I get this warning message anyway:
>
> 1: kein nicht-fehlendes Argument f?r min; gebe Inf zur?ck (None 
> not-lacking argument for min; give Inf back)
> 2: kein nicht-fehlendes Argument f?r max; gebe -Inf zur?ck 
>
> what does this mean?
>
> Greeting and thanks for your help!
>
> Birgit
>
> Am 28.06.2007 um 12:05 schrieb Jacques VESLOT:
>
>> sapply(1:85, function(i) eval(parse(text=paste("range(V", i, ", 
>> na.rm=T)", sep=""))))
>>
>> Jacques VESLOT
>>
>> INRA - Biostatistique & Processus Spatiaux
>> Site Agroparc 84914 Avignon Cedex 9, France
>>
>> Tel: +33 (0) 4 32 72 21 58
>> Fax: +33 (0) 4 32 72 21 84
>>
>>
>>
>> Birgit Lemcke a ?crit :
>>> Hello,
>>> (Power Book G4, Mac OS X, R 2.5.0)
>>>
>>> I would like to repeat the function range for 85 Vectors (V1-V85).
>>> I tried with this code:
>>>
>>> i<-0
>>>  > repeat {
>>> + i<-i+1
>>> + if (i<85) next
>>> + range (Vi, na.rm = TRUE)
>>> + if (i==85) break
>>> + }
>>>
>>> I presume that the Vi is wrong, because in this syntax i is not 
>>> known  as a variable. But I don?t know how to say that it is a 
>>> variable here.
>>> Would be nice if somebody could help me.
>>> Perhaps I?m thinking too complicated and there is an easier way to 
>>> do  this.
>>>
>>> Thanks in advance
>>>
>>> Greetings
>>>
>>> Birgit
>>>
>>> Birgit Lemcke
>>> Institut f?r Systematische Botanik
>>> Zollikerstrasse 107
>>> CH-8008 Z?rich
>>> Switzerland
>>> Ph: +41 (0)44 634 8351
>>> birgit.lemcke at systbot.uzh.ch <mailto:birgit.lemcke at systbot.uzh.ch>
>>>
>>>
>>>
>>>
>>>
>>>
>>> [[alternative HTML version deleted]]
>>>
>>>   
>>> ------------------------------------------------------------------------
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch <mailto:R-help at stat.math.ethz.ch> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>   
>>>
>
> Birgit Lemcke
> Institut f?r Systematische Botanik
> Zollikerstrasse 107
> CH-8008 Z?rich
> Switzerland
> Ph: +41 (0)44 634 8351
> birgit.lemcke at systbot.uzh.ch <mailto:birgit.lemcke at systbot.uzh.ch>
>  
>
>
>
>


From P.Dalgaard at biostat.ku.dk  Thu Jun 28 15:14:06 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 28 Jun 2007 15:14:06 +0200
Subject: [R] Repeat if
In-Reply-To: <B99519F4-41DA-4768-9E5A-0FAEEC5FB5D9@systbot.uzh.ch>
References: <C7B7CCEB-9193-40ED-850F-0385F9C3BB5B@systbot.uzh.ch>	<46838807.4020907@avignon.inra.fr>
	<B99519F4-41DA-4768-9E5A-0FAEEC5FB5D9@systbot.uzh.ch>
Message-ID: <4683B41E.8050903@biostat.ku.dk>

Birgit Lemcke wrote:
> Thanks that was really a quick answer.
>
> It works but I get this warning message anyway:
>
> 1: kein nicht-fehlendes Argument f?r min; gebe Inf zur?ck (None not- 
> lacking argument for min; give Inf back)
> 2: kein nicht-fehlendes Argument f?r max; gebe -Inf zur?ck
>
> what does this mean?
>
>   

Same as this

> max(c(NA, NA), na.rm=T)
[1] -Inf
Warning message:
no non-missing arguments to max; returning -Inf

which is related to the issues of empty sum(), prod(), any(), and all()
in that it allows a consistent concatenation rule:

max(c(x1,x2)) == max(max(x1), max(x2))

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From vladimir at math.uic.edu  Thu Jun 28 15:42:40 2007
From: vladimir at math.uic.edu (vladimir at math.uic.edu)
Date: Thu, 28 Jun 2007 08:42:40 -0500
Subject: [R] Installing an old package in R-2.4.1
Message-ID: <20070628134240.GA25191@math.uic.edu>

I am new to R.   We have a binary package that was not maintained for
about a year, and the original maintainer is not around anymore.
The package used to work in R-1.5.1.  I used the following steps
to install this package in R-2.4 on WinXP:

  Started the GUI
  Went into the menu "Packages" and selected "Install packages from
  local zip files
  Clicked on the zip file with the package, and clicked "Open"
  
R responded with the message "Updating HTML package descriptions".
I can see the package files in the "library" subdirectory of
R installation:

cd "c:/program files/R/R-2.4.1/library"
find . -name 'Rproj' -print
./file72ae2cd6/Rproj
./file72ae2cd6/Rproj/help/Rproj
./file72ae2cd6/Rproj/R/Rproj
./Rproj
./Rproj/help/Rproj
./Rproj/R/Rproj

( Please don't get confused by the UNIX-style paths, I am using cygwin
shell on Windows ).
However when I go to "Packages->Load package" menu, the Rproj 
package is not listed there.   How would I find out what went wrong?

Thanks,
	Vlad


From birgit.lemcke at systbot.uzh.ch  Thu Jun 28 15:56:53 2007
From: birgit.lemcke at systbot.uzh.ch (Birgit Lemcke)
Date: Thu, 28 Jun 2007 15:56:53 +0200
Subject: [R] Repeat if
In-Reply-To: <4683B4F7.2060501@avignon.inra.fr>
References: <C7B7CCEB-9193-40ED-850F-0385F9C3BB5B@systbot.uzh.ch>
	<46838807.4020907@avignon.inra.fr>
	<B99519F4-41DA-4768-9E5A-0FAEEC5FB5D9@systbot.uzh.ch>
	<4683B4F7.2060501@avignon.inra.fr>
Message-ID: <9BA8DCF9-7D51-4A74-B94A-556EADBA8E9B@systbot.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070628/84218cbf/attachment.pl 

From birgit.lemcke at systbot.uzh.ch  Thu Jun 28 15:58:18 2007
From: birgit.lemcke at systbot.uzh.ch (Birgit Lemcke)
Date: Thu, 28 Jun 2007 15:58:18 +0200
Subject: [R] Repeat if
In-Reply-To: <46838D00.7000805@pburns.seanet.com>
References: <C7B7CCEB-9193-40ED-850F-0385F9C3BB5B@systbot.uzh.ch>
	<46838D00.7000805@pburns.seanet.com>
Message-ID: <CE8D550C-CD33-473E-BF55-AE7092D8298E@systbot.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070628/e46074b4/attachment.pl 

From ripley at stats.ox.ac.uk  Thu Jun 28 16:08:21 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 28 Jun 2007 15:08:21 +0100 (BST)
Subject: [R] : regular expressions: escaping a dot
In-Reply-To: <4683B1EB.7030501@biostat.ku.dk>
References: <20070628074357.GA4502@s1x.fischer-zim.local>
	<Pine.LNX.4.64.0706280921230.4206@gannet.stats.ox.ac.uk>
	<4683B1EB.7030501@biostat.ku.dk>
Message-ID: <Pine.LNX.4.64.0706281506320.10053@gannet.stats.ox.ac.uk>

On Thu, 28 Jun 2007, Peter Dalgaard wrote:

> Prof Brian Ripley wrote:
>>
>>
>> This is explained in ?regexp (in the See Also of ?regexpr):
>>
>>       Patterns are described here as they would be printed by 'cat': _do
>>       remember that backslashes need to be doubled when entering R
>>       character strings from the keyboard_.
>>
>> and in the R FAQ and ....
>>
>>
> Hmm, that's not actually correct, is it? Perhaps this is better
>
> "...entering R character string literals (i.e., between quote symbols.)"
>
> The counterexample would be
>
>> readLines()
> \\abc
> [1] "\\\\abc"
>
> (of course it is more important to get people to read the documentation
> at all...)

The definition of 'character string' used throughout the help is your 
'character string literal', as distinct from an element of a character 
vector.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From birgit.lemcke at systbot.uzh.ch  Thu Jun 28 16:12:02 2007
From: birgit.lemcke at systbot.uzh.ch (Birgit Lemcke)
Date: Thu, 28 Jun 2007 16:12:02 +0200
Subject: [R] Repeat if
In-Reply-To: <AAD49F46EAE3F6479E1D46428FAC31CB0181AB40@NBIE2KSRV1.nbi.bbsrc.ac.uk>
References: <C7B7CCEB-9193-40ED-850F-0385F9C3BB5B@systbot.uzh.ch>
	<AAD49F46EAE3F6479E1D46428FAC31CB0181AB40@NBIE2KSRV1.nbi.bbsrc.ac.uk>
Message-ID: <9E0A66CF-1F3C-4599-AE18-82870C8B91BB@systbot.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070628/c6d09105/attachment.pl 

From birgit.lemcke at systbot.uzh.ch  Thu Jun 28 16:14:04 2007
From: birgit.lemcke at systbot.uzh.ch (Birgit Lemcke)
Date: Thu, 28 Jun 2007 16:14:04 +0200
Subject: [R] Repeat if
In-Reply-To: <dea6cb960706280334q6b466ac7xf7591e6fba50bc8@mail.gmail.com>
References: <C7B7CCEB-9193-40ED-850F-0385F9C3BB5B@systbot.uzh.ch>
	<dea6cb960706280334q6b466ac7xf7591e6fba50bc8@mail.gmail.com>
Message-ID: <A0377A9D-C5A6-4437-A369-443759835487@systbot.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070628/9a919183/attachment.pl 

From alxsal at free.fr  Thu Jun 28 16:25:59 2007
From: alxsal at free.fr (alxsal at free.fr)
Date: Thu, 28 Jun 2007 16:25:59 +0200
Subject: [R] Adding different output to different lattice panels
Message-ID: <1183040759.4683c4f7c087b@imp.free.fr>

I would like to add a reference line to lattice graphs, with the reference line
being different according to the factor level.

Example : Draw 3 dotplots for "a","b" and "c" factors, and then add an
horizontal line at y=10 for panel "a", y=8 for panel "b" and y=6 for panel "4"

I tried the code below, but this draw all three reference lines for each panel.
How do I index the current panel to chose the right reference vector value ?

dat<-data.frame(id=rep(c("a","b","c"),4),val=1:12,quand=rep(c("t1","t2","t3","t4"),each=3))
ref<-c(10,8,6)
plot.new()
datplot<-dotplot(val~quand|id,data=dat,panel=function(...){
panel.dotplot(...)
panel.abline(h=ref)
})
print(datplot)


From john.seers at bbsrc.ac.uk  Thu Jun 28 16:49:39 2007
From: john.seers at bbsrc.ac.uk (john seers (IFR))
Date: Thu, 28 Jun 2007 15:49:39 +0100
Subject: [R] Repeat if
In-Reply-To: <9E0A66CF-1F3C-4599-AE18-82870C8B91BB@systbot.uzh.ch>
References: <C7B7CCEB-9193-40ED-850F-0385F9C3BB5B@systbot.uzh.ch><AAD49F46EAE3F6479E1D46428FAC31CB0181AB40@NBIE2KSRV1.nbi.bbsrc.ac.uk>
	<9E0A66CF-1F3C-4599-AE18-82870C8B91BB@systbot.uzh.ch>
Message-ID: <AAD49F46EAE3F6479E1D46428FAC31CB0181AB42@NBIE2KSRV1.nbi.bbsrc.ac.uk>

 

Hi Birgit

No, you do not have to write all 85 vectors in the first line. I just did not fully appreciate what you were trying to do. 

You could use the "get" option as was suggested somewhere else.

So, if your vectors are V1 to V2 (i.e. 85) say, something like:


V1<-c(1,2,3)
V2<-c(5,2,7)

...

V<-paste("V", 1:2, sep="")
for ( i in 1:length(V) ) {         
	print(range (get(V[i]), na.rm = TRUE))
}


Regards

JS

 
---
 
Web sites:

www.ifr.ac.uk   
www.foodandhealthnetwork.com

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Birgit Lemcke
Sent: 28 June 2007 15:12
To: john seers (IFR)
Cc: R Hilfe
Subject: Re: [R] Repeat if

Hello John,

I tried this code. But I got only the ranges of V1 and V2 what is easily understandable.
Do I have to write in all 85 vectors in the first line?

V<-list(a=c(V1), b=c(V2))

for ( i in 1:85 ) {          # 2 vectors (replace with 85 ...)
+     print(range (V[i], na.rm = TRUE))
+ }


sapply(1:85, function(i) eval(parse(text=paste("range(V", i, ", na.rm=T)", sep=""))))

But thanks anyway.

Greetings

Birgit


Am 28.06.2007 um 12:23 schrieb john seers ((IFR)):

>
> Hi
>
> I think a for loop would be more what you want.
>
> Something along the lines of:
>
>
> V<-list(a=c(1,2,3), b=c(2,3,4)) # list of 2 vectors
>
> for ( i in 1:2 ) {          # 2 vectors (replace with 85 ...)
>     print(range (V[i], na.rm = TRUE))
> }
>
>
> Regards
>
> JS
>
> ---
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Birgit Lemcke
> Sent: 28 June 2007 10:48
> To: R Hilfe
> Subject: [R] Repeat if
>
> Hello,
> (Power Book G4, Mac OS X, R 2.5.0)
>
> I would like to repeat the function range for 85 Vectors (V1-V85).
> I tried with this code:
>
> i<-0
>> repeat {
> + i<-i+1
> + if (i<85) next
> + range (Vi, na.rm = TRUE)
> + if (i==85) break
> + }

Birgit Lemcke
Institut f?r Systematische Botanik
Zollikerstrasse 107
CH-8008 Z?rich
Switzerland
Ph: +41 (0)44 634 8351
birgit.lemcke at systbot.uzh.ch






	[[alternative HTML version deleted]]


From Patrick_Bedard at brown.edu  Thu Jun 28 17:07:29 2007
From: Patrick_Bedard at brown.edu (Patrick Bedard)
Date: Thu, 28 Jun 2007 11:07:29 -0400
Subject: [R] TukeyHSD
Message-ID: <C2A946F1.3FF5%Patrick_Bedard@brown.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070628/2014698e/attachment.pl 

From markus at insightfromdata.com  Thu Jun 28 17:10:51 2007
From: markus at insightfromdata.com (Markus Loecher)
Date: Thu, 28 Jun 2007 11:10:51 -0400
Subject: [R] align() function missing in R ?
Message-ID: <200706281511.l5SFBlat007218@hypatia.math.ethz.ch>

Dear list members,
I switched from Splus to R a few years ago and so far found no 
functionality missing.
However, I am struggling to find the equivalent align() function for 
time series. I did find some reduced functionality such as 
alignDailySeries in package:fCalendar but the full capability of 
aligning two timeseries seems to be missing.
Could this be true ? I am sure there must be a need for this useful function.
Any help would be greatly appreciated.

Thanks !

Markus


From h.wickham at gmail.com  Thu Jun 28 17:12:56 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 28 Jun 2007 17:12:56 +0200
Subject: [R] Adding different output to different lattice panels
In-Reply-To: <1183040759.4683c4f7c087b@imp.free.fr>
References: <1183040759.4683c4f7c087b@imp.free.fr>
Message-ID: <f8e6ff050706280812o4953320ey3b84ab1b9b27e63d@mail.gmail.com>

On 6/28/07, alxsal at free.fr <alxsal at free.fr> wrote:
> I would like to add a reference line to lattice graphs, with the reference line
> being different according to the factor level.
>
> Example : Draw 3 dotplots for "a","b" and "c" factors, and then add an
> horizontal line at y=10 for panel "a", y=8 for panel "b" and y=6 for panel "4"

It's quite easy to do this with ggplot2 (http://had.co.nz/ggplot2) -
see http://had.co.nz/ggplot2/geom_vline.html for examples of both
common and specific reference lines.

Hadley


From buser at stat.math.ethz.ch  Thu Jun 28 17:21:13 2007
From: buser at stat.math.ethz.ch (Christoph Buser)
Date: Thu, 28 Jun 2007 17:21:13 +0200
Subject: [R] embedFonts() and bounding box
Message-ID: <18051.53737.967004.143133@stat.math.ethz.ch>

Dear R gurus

I have a question regarding the function embedFonts().  
I assume the in that function which calls gs, the bounding box
of the eps file is changed. Is that by intention? Do I have
call explicitly some gs-options to avoid it and if yes, how?
Thank you very much for your help.

Best regards,

Christoph Buser

## R example
postscript("test.eps", width = 14, height = 8, 
         onefile = FALSE, horizontal=FALSE, paper="special")
plot(1:10)
dev.off()
embedFonts(file = "test.eps", outfile = "test1.eps")


--------------------------------------------------------------
Christoph Buser <buser at stat.math.ethz.ch>
Seminar fuer Statistik, LEO C13
ETH Zurich	8092 Zurich	 SWITZERLAND
phone: x-41-44-632-4673		fax: 632-1228
http://stat.ethz.ch/~buser/


From christophe at pallier.org  Thu Jun 28 17:28:42 2007
From: christophe at pallier.org (Christophe Pallier)
Date: Thu, 28 Jun 2007 17:28:42 +0200
Subject: [R] TukeyHSD
In-Reply-To: <C2A946F1.3FF5%Patrick_Bedard@brown.edu>
References: <C2A946F1.3FF5%Patrick_Bedard@brown.edu>
Message-ID: <dea6cb960706280828q63e628b5rd2df79e70b52c6e8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070628/e5571ec4/attachment.pl 

From birgit.lemcke at systbot.uzh.ch  Thu Jun 28 17:30:27 2007
From: birgit.lemcke at systbot.uzh.ch (Birgit Lemcke)
Date: Thu, 28 Jun 2007 17:30:27 +0200
Subject: [R] Repeat if
In-Reply-To: <4683B4F7.2060501@avignon.inra.fr>
References: <C7B7CCEB-9193-40ED-850F-0385F9C3BB5B@systbot.uzh.ch>
	<46838807.4020907@avignon.inra.fr>
	<B99519F4-41DA-4768-9E5A-0FAEEC5FB5D9@systbot.uzh.ch>
	<4683B4F7.2060501@avignon.inra.fr>
Message-ID: <DD11FF0E-F5DB-46B7-A36F-3BFDAE1F9133@systbot.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070628/c959e1ba/attachment.pl 

From rmh at temple.edu  Thu Jun 28 17:34:48 2007
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 28 Jun 2007 11:34:48 -0400 (EDT)
Subject: [R] TukeyHSD
Message-ID: <20070628113448.CFE07237@po-d.temple.edu>

TukeyHSD takes an aov object, not an aovlist object.
The result of aov() with an Error() term is an aovlist object.

In the HH package, see ?MMC for an example of how to work
around this limitation.  See the maiz example.

Rich


From spencer.graves at pdf.com  Thu Jun 28 17:39:26 2007
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 28 Jun 2007 08:39:26 -0700
Subject: [R] R.matlab questions
In-Reply-To: <59d7961d0706100505y5021e9b6p678c569451da570f@mail.gmail.com>
References: <8B7B0FD99E8AF541A21609104D1961589122CA@izs-xchg01.izs.fraunhofer.de>	
	<9918327.post@talk.nabble.com>	
	<8B7B0FD99E8AF541A21609104D1961589122DC@izs-xchg01.izs.fraunhofer.de>	
	<9918787.post@talk.nabble.com>	
	<8B7B0FD99E8AF541A21609104D1961589122E6@izs-xchg01.izs.fraunhofer.de>	
	<59d7961d0704191404v72ca1aa0qe89dc7faf9f43779@mail.gmail.com>	
	<4627E89A.2010306@pdf.com>	
	<59d7961d0704191659r199b318fs5f715af1dcb23094@mail.gmail.com>	
	<465F18BF.8050000@pdf.com>	
	<59d7961d0706050440k4e216e10k6b6092b2a9669665@mail.gmail.com>
	<59d7961d0706100505y5021e9b6p678c569451da570f@mail.gmail.com>
Message-ID: <4683D62E.8000307@pdf.com>

Hello:

	  Two questions about R.matlab:

	  1.  How to break a hung R-Matlab connection?

	  2.  How to execute R.matlab commands from within a function?

	
BREAKING AN R-Matlab CONNECTION

	  Sometimes an attempted R.matlab command locks up my computer.  The 
standard R break process interrupts the R command.  However, when I do 
that, the command to Matlab is still pending, and I don't know an easy 
way to interrupt that.  A simple, self-contained example appears below.

	  The easiest way I've found so far to interrupt Matlab is to quit R. 
This will finally release Matlab.


CALLING R.matlab FUNCTIONS FROM WITHIN A FUNCTION

	  An R.matlab function call that works as a direct R command hangs for 
me when executed within an R function.  A simple, self-contained example 
appears below.

How can I work around this?


	  Thanks,
	  Spencer Graves
Using Matlab 7.3.0 (R2006b) under Windows XP Pro.
> sessionInfo()
R version 2.5.0 (2007-04-23)
i386-pc-mingw32

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
States.1252;LC_MONETARY=English_United
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] "splines"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
[7] "methods"   "base"

other attached packages:
R.matlab     R.oo      fda      zoo
  "1.1.3"  "1.2.7"  "1.2.1"  "1.3-1"

###################

#EXAMPLE:  CALLING R.matlab FROM WITHIN A FUCTION?

# 1.  library(R.matlab)
library(R.matlab)
# 2.  Create a Matlab client object to support communications
(matlab <- Matlab())
#     Optionally set setVerbose(..., -2) to get max info
setVerbose(matlab, -2)

# 3.  Start Matlab
# 4.  Ask Matlab to become a slave

#Matlab>> MatlabServer

# 5.  Open the connection from R to MatlabServer
(isOpenMatlab <- open(matlab))

# NOTE:  If Matlab is not frozen:
#R> close(matlab)
# returns local control to Matlab.
# Control of Matlab can be returned to R at any time
# by repeating steps 4 & 5.

# 6.  matlab.compute.a
compute <- evaluate(matlab, "a = 1+2")
(a0 <- getVariable(matlab, "a"))

# The above works fine for me.

# 7.  R.matlab.compute.a function
R.matlab.compute.a <- function(text="a=1+2", matlabClient=matlab){
# text = a Matlab expression that stores 'a'
   ev0 <- evaluate(matlabClient, text)
   getVariable(matlabClient, "a")
}

# The following locks up both R and Matlab for me:
R.matlab.compute.a()


From deepayan.sarkar at gmail.com  Thu Jun 28 17:45:43 2007
From: deepayan.sarkar at gmail.com (deepayan.sarkar at gmail.com)
Date: Thu, 28 Jun 2007 08:45:43 -0700
Subject: [R] Adding different output to different lattice panels
In-Reply-To: <1183040759.4683c4f7c087b@imp.free.fr>
References: <1183040759.4683c4f7c087b@imp.free.fr>
Message-ID: <eb555e660706280845g3af6e59fx807c493a914d50d1@mail.gmail.com>

On 6/28/07, alxsal at free.fr <alxsal at free.fr> wrote:
> I would like to add a reference line to lattice graphs, with the reference
> line
> being different according to the factor level.
>
> Example : Draw 3 dotplots for "a","b" and "c" factors, and then add an
> horizontal line at y=10 for panel "a", y=8 for panel "b" and y=6 for panel
> "4"
>
> I tried the code below, but this draw all three reference lines for each
> panel.
> How do I index the current panel to chose the right reference vector value ?
>
> dat<-data.frame(id=rep(c("a","b","c"),4),val=1:12,quand=rep(c("t1","t2","t3","t4"),each=3))
> ref<-c(10,8,6)
> plot.new()
> datplot<-dotplot(val~quand|id,data=dat,panel=function(...){
> panel.dotplot(...)
> panel.abline(h=ref)
> })
> print(datplot)

dotplot(val~quand|id,data=dat,panel=function(...){
    panel.dotplot(...)
    panel.abline(h = ref[packet.number()])
})

(Things are more complicated if you have more than one conditioning variable.)

-Deepayan


From efg at stowers-institute.org  Thu Jun 28 17:27:09 2007
From: efg at stowers-institute.org (Earl F. Glynn)
Date: Thu, 28 Jun 2007 10:27:09 -0500
Subject: [R] Writing - specyfic format
References: <11341784.post@talk.nabble.com>
Message-ID: <f60k0h$v23$1@sea.gmane.org>

"jastar" <mswierniak at o2.pl> wrote in message 
news:11341784.post at talk.nabble.com...
>
> Hi all,
> I have a trouble - I need to write file in a very specyfic format.
> I have two vectors which different lengths and one data.frame (or matrix).
> I want to write it to "*.txt" file in following way:
> 1st row of file is my 1st vector (separate by spacebar)
> 2nd row of file is 2nd vector (also separate by spacebar)
> Rest of this file should be a matrix with elements separated by tab.
> For example: a=1, 2, 3, b=4, 5, c=[1, 2, 3, 4, 5, 6;
>                                            7, 8, 9, 10, 11, 12,]
> and I want to have file (it have to be .txt file) like:
> 1 2 3
> 4 5
> 1     2     3     4     5     6
> 7     8     9     10   11    12
>
> This thing have to be done automaticly from R.
> Is it possible?

Try this:

a <- 1:3
b <- 4:5
c <- matrix(1:12, 2,6, byrow=TRUE)

outFile <- file("SpecificFormat.txt", "w")
cat(paste(a, sep=" "), "\n", file=outFile)
cat(paste(b, sep=" "), "\n", file=outFile)

for (j in 1:nrow(c))
{
  cat(paste(c[j,], collapse="\t"), "\n", file=outFile)
}

close(outFile)


Resulting output file (with spaces or tabs as specified):
1 2 3
4 5
1 2 3 4 5 6
7 8 9 10 11 12


[But I normally avoid tabs since you cannot "see" them easily with many 
editors.]

efg

Earl F. Glynn
Stowers Institute for Medical Research


From john_d_mchenry at yahoo.com  Thu Jun 28 18:05:05 2007
From: john_d_mchenry at yahoo.com (John McHenry)
Date: Thu, 28 Jun 2007 09:05:05 -0700 (PDT)
Subject: [R] Method dispatch in functions?
Message-ID: <972441.14518.qm@web35410.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070628/c47ce86f/attachment.pl 

From martin.gaston at unavarra.es  Thu Jun 28 18:44:50 2007
From: martin.gaston at unavarra.es (=?UTF-8?Q?Mart=C3=ADn_Gast=C3=B3n?=)
Date: Thu, 28 Jun 2007 09:44:50 -0700 (PDT)
Subject: [R] Error en assign(mname, def, where)
Message-ID: <11346689.post@talk.nabble.com>


Hi R users,
I am working with the fda package but when I call the function pca.fd I
obtain a message error, which I cann't identify. The error say That :
 error in assihn(mname,def,where), is not possible to add links to a
blockade enviroment.
The orther that I'm writting is:

> cp1 <- pca.fd(ind.fd1,nharm=3)

and before it I can to plot the functional data object ind.fd1.
?Have anybody seen this error or any similar message?,
?Any idea?

Thancks for your help
-- 
View this message in context: http://www.nabble.com/Error-en-assign%28mname%2C-def%2C-where%29-tf3995432.html#a11346689
Sent from the R help mailing list archive at Nabble.com.


From med at aghmed.fsnet.co.uk  Thu Jun 28 19:01:44 2007
From: med at aghmed.fsnet.co.uk (Michael Dewey)
Date: Thu, 28 Jun 2007 18:01:44 +0100
Subject: [R] Meta-Analysis of proportions
In-Reply-To: <30d7ea360706280158x2e19daa4ocb41febfda944e@mail.gmail.com>
References: <01dc01c7b8fb$21fc6680$9aa8569d@dcs012S>
	<30d7ea360706280158x2e19daa4ocb41febfda944e@mail.gmail.com>
Message-ID: <Zen-1I3xNL-00045P-VO@pythagoras.zen.co.uk>

At 09:58 28/06/2007, Chung-hong Chan wrote:
>OpenBUGS should be something related to Bayesian statistics.
>
>You may refer to Chapter 12 of Handbook
>http://cran.r-project.org/doc/vignettes/HSAUR/Ch_meta_analysis.pdf
>It talks about meta-regression.
>
>
>
>On 6/28/07, Monica Malta <momalta at cict.fiocruz.br> wrote:
>>Dear colleagues,
>>
>>I'm conducting a meta-analysis of studies evaluating adherence of 
>>HIV-positive drug users into AIDS treatment, therefore I'm looking 
>>for some advice and syntax suggestion for running the 
>>meta-regression using proportions, not the usual OR/RR frequently 
>>used on RCT studies.

Monica, you have a number of options.
1 - weight each study equally
2 - weight each individual equally
3 - use the usual inverse variance procedure, possibly transforming 
the proportions first
4 - something else I have not though of

You could do 3 using rmeta which is available from CRAN. Programming 
1 or 2 is straightforward.
Of course, you do need to decide which corresponds to your scientific question.


>>Have already searched already several handbooks, R-manuals, mailing 
>>lists, professors, but... not clue at all...
>>
>>Does anyone have already tried this? A colleague of mine recently 
>>published a similar study on JAMA, but he used OpenBUGS - a 
>>software I'm not familiar with...
>>
>>If there is any tip/suggestion for a possible syntax, could someone 
>>send me? I need to finish this paper before my PhD qualify, but I'm 
>>completely stuck...
>>
>>So, any tip will be more than welcome...I will really appreciate it!!!
>>
>>Thanks in advance and congrats on the amazing mailing-list.
>>
>>
>>
>>Bests from Rio de Janeiro, Brazil.
>>
>>Monica
>>
>>
>>
>>
>>
>>Monica Malta
>>Researcher
>>Oswaldo Cruz Foundation - FIOCRUZ
>>Social Science Department - DCS/ENSP
>>Rua Leopoldo Bulhoes, 1480 - room 905
>>Manguinhos
>>Rio de Janeiro - RJ 21041-210
>>Brazil
>>phone +55.21.2598-2715
>>fax +55.21.2598-2779
>>         [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>
>--
>"The scientists of today think deeply instead of clearly. One must be
>sane to think clearly, but one can think deeply and be quite insane."
>Nikola Tesla
>http://www.macgrass.com
>
>

Michael Dewey
med at aghmed.fsnet.co.uk
http://www.aghmed.fsnet.co.uk/home.html


From georgehret at gmail.com  Thu Jun 28 19:12:24 2007
From: georgehret at gmail.com (G E)
Date: Thu, 28 Jun 2007 13:12:24 -0400
Subject: [R] R function command on a list
Message-ID: <e4dda3890706281012p63281240ma50a033a190cfe5f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070628/bdf91a37/attachment.pl 

From wwwhsd at gmail.com  Thu Jun 28 19:23:44 2007
From: wwwhsd at gmail.com (Henrique Dallazuanna)
Date: Thu, 28 Jun 2007 14:23:44 -0300
Subject: [R] R function command on a list
In-Reply-To: <e4dda3890706281012p63281240ma50a033a190cfe5f@mail.gmail.com>
References: <e4dda3890706281012p63281240ma50a033a190cfe5f@mail.gmail.com>
Message-ID: <da79af330706281023l3b32982bt5df519fcb8f00065@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070628/4dff2381/attachment.pl 

From jizhang at chori.org  Thu Jun 28 19:40:02 2007
From: jizhang at chori.org (Jiong Zhang, PhD)
Date: Thu, 28 Jun 2007 10:40:02 -0700
Subject: [R]  stack multiple plots on one page
Message-ID: <e5ce2d84d4dcd24383c75b9e2d00ffcf@mail.chori.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070628/8335ac7e/attachment.pl 

From Mark.Leeds at morganstanley.com  Thu Jun 28 19:55:22 2007
From: Mark.Leeds at morganstanley.com (Leeds, Mark (IED))
Date: Thu, 28 Jun 2007 13:55:22 -0400
Subject: [R] Evaluating predictive power with no intercept-statistics
	question - not R question
Message-ID: <D3AEEDA31E57474B840BEBC25A8A83440195744E@NYWEXMB23.msad.ms.com>

I realize that the following has been talked about on this list many
times before in some related way but I
am going to ask for help anyway because I still don't know what to do. 

Suppose I have no intercept models such as the following :

Y = B*X_1 + error
Y = B*X_2 + error
Y = B*X_3 + error
Y = B*X_4 + error

and I run regressions on each ( over the same sample of Y ) and now I
want to evaluate which X has the greatest predictive power.
I'm fairly certain that R squared is not applicable because of the lack
of an intercept but I was wondering what was ? 
Any references to this particular problem or suggestions are
appreciated. I honestly believe that including an intercept is incorrect
For my particular problem. Thanks.

Maybe I could put all the X's in one regression and some kind of
topdownselect or StepAIC algorithm for example ?  Thanks.
--------------------------------------------------------

This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}


From kellrott at csbl.bmb.uga.edu  Thu Jun 28 20:12:49 2007
From: kellrott at csbl.bmb.uga.edu (Kyle Ellrott)
Date: Thu, 28 Jun 2007 14:12:49 -0400
Subject: [R] "no applicable method"
In-Reply-To: <Pine.LNX.4.64.0706271858280.15323@gannet.stats.ox.ac.uk>
References: <AB724053-3718-4FFE-8342-4ED1AEC5D689@csbl.bmb.uga.edu>
	<Pine.LNX.4.64.0706271858280.15323@gannet.stats.ox.ac.uk>
Message-ID: <CC6EFC32-9919-4F1F-97D1-C7EA38F27489@csbl.bmb.uga.edu>

You actually got it right.
I didn't realize there was a difference between a data frame and  
matrix.  What is the difference any way?  Seems like all two  
dimensional arrays should be equivalent.

Kyle



> On Wed, 27 Jun 2007, Kyle Ellrott wrote:
>
>> I'm getting started in R, and I'm trying to use one of the gradient
>> boosting packages, mboost.  I'm already installed the package with
>> install.packages("mboost") and loaded it with library(mboost).
>> My problem is that when I attempt to call glmboost, I get a message
>> that " Error in glmboost() : no applicable method for "glmboost" ".
>> Does anybody have an idea of what kind of problem this is  
>> indicative of?
>
> The wrong class of input object 'x'.  The help page for glmboost is  
> written obscurely, but it seems to imply that it has methods for  
> 'formula' and 'matrix'.
>
> Perhaps you passed a data frame?
>
>> PLEASE do read the posting guide http://www.R-project.org/posting- 
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> is pertinent.  With an example and its output we would have been  
> much better placed to help you.
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From wwwhsd at gmail.com  Thu Jun 28 20:36:47 2007
From: wwwhsd at gmail.com (Henrique Dallazuanna)
Date: Thu, 28 Jun 2007 15:36:47 -0300
Subject: [R] stack multiple plots on one page
In-Reply-To: <e5ce2d84d4dcd24383c75b9e2d00ffcf@mail.chori.org>
References: <e5ce2d84d4dcd24383c75b9e2d00ffcf@mail.chori.org>
Message-ID: <da79af330706281136m1b74ba56h7fcb64f37b6af313@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070628/5741ca75/attachment.pl 

From elvis at xlsolutions-corp.com  Thu Jun 28 20:45:15 2007
From: elvis at xlsolutions-corp.com (elvis at xlsolutions-corp.com)
Date: Thu, 28 Jun 2007 11:45:15 -0700
Subject: [R] Course in Boston** R/Splus Fundamentals and Programming
	Techniques
Message-ID: <20070628114515.9f08cc34deb45d78e54b3b5664e21546.c64e1b9a77.wbe@email.secureserver.net>

XLSolutions Corporation (www.xlsolutions-corp.com) is making a last call
for our July 2007 "R/S-plus Fundamentals and
Programming
Techniques" : www.xlsolutions-corp.com/Rfund.htm

In Boston ***   July 16 - 17, 2007


Reserve your seat now at the early bird rates! Payment due AFTER
the class

Course Description:

This two-day beginner to intermediate R/S-plus course focuses on a
broad spectrum of topics, from reading raw data to a comparison of R
and S. We will learn the essentials of data manipulation, graphical
visualization and R/S-plus programming. We will explore statistical
data analysis tools,including graphics with data sets. How to enhance
your plots, build your own packages (librairies) and connect via
ODBC,etc.
We will perform some statistical modeling and fit linear regression
models. Participants are encouraged to bring data for interactive
sessions

With the following outline:

- An Overview of R and S
- Data Manipulation and Graphics
- Using Lattice Graphics
- A Comparison of R and S-Plus
- How can R Complement SAS?
- Writing Functions
- Avoiding Loops
- Vectorization
- Statistical Modeling
- Project Management
- Techniques for Effective use of R and S
- Enhancing Plots
- Using High-level Plotting Functions
- Building and Distributing Packages (libraries)
- Connecting; ODBC, Rweb, Orca via sockets and via Rjava


Email us for group discounts.
Email Sue Turner: sue at xlsolutions-corp.com
Phone: 206-686-1578
Visit us: www.xlsolutions-corp.com/courselist.htm

Please let us know if you and your colleagues are interested in this
classto take advantage of group discount. Register now to secure your
seat!

Interested in R/Splus Advanced course? email us.


Cheers,
Elvis Miller, PhD
Manager Training.
XLSolutions Corporation
206 686 1578
www.xlsolutions-corp.com
elvis at xlsolutions-corp.com


From bcarvalh at jhsph.edu  Thu Jun 28 20:45:44 2007
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Thu, 28 Jun 2007 14:45:44 -0400
Subject: [R] stack multiple plots on one page
In-Reply-To: <da79af330706281136m1b74ba56h7fcb64f37b6af313@mail.gmail.com>
References: <e5ce2d84d4dcd24383c75b9e2d00ffcf@mail.chori.org>
	<da79af330706281136m1b74ba56h7fcb64f37b6af313@mail.gmail.com>
Message-ID: <617FDEEF-B877-4F65-BBBF-21D1C904A1B4@jhsph.edu>

or just type:

pairs.default

b

On Jun 28, 2007, at 2:36 PM, Henrique Dallazuanna wrote:

> https://svn.r-project.org/R/branches/R-2-5-branch/src/library/ 
> graphics/R/pairs.R
>
> -- 
> Henrique Dallazuanna
> Curitiba-Paran?-Brasil
> 25? 25' 40" S 49? 16' 22" O
>
> On 28/06/07, Jiong Zhang, PhD <jizhang at chori.org> wrote:
>>
>> Hi All,
>>
>> I typed "pairs" to see its code but did not get what I want.  How  
>> do I
>> see its code?
>>
>> What I am trying to do, is to stack about 10 scatter plots on one  
>> page
>> as the way "pairs" does.  I have about 150 variables in my table.
>> Instead of plotting 150X150 pairs using "pairs", I only need to  
>> plot 10
>> pairs.
>>
>> Thanks.
>>
>> jiong
>> The email message (and any attachments) is for the sole use of the
>> intended recipient(s) and may contain confidential information.  Any
>> unauthorized review, use, disclosure or distribution is  
>> prohibited.  If you
>> are not the intended recipient, please contact the sender by reply  
>> email and
>> destroy all copies of the original message (and any attachments).   
>> Thank
>> You.
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at yahoo.ca  Thu Jun 28 21:03:41 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Thu, 28 Jun 2007 15:03:41 -0400 (EDT)
Subject: [R] Function call within a function.
Message-ID: <935534.94598.qm@web32802.mail.mud.yahoo.com>

I am trying to call a funtion within another function
and I clearly am misunderstanding what I should do. 
Below is a simple example.
I know lstfun works on its own but I cannot seem to
figure out how to get it to work within ukn. Basically
I need to create the variable "nts". I have probably
missed something simple in the Intro or FAQ.

Any help would be much appreciated.

EXAMPLE
-------------------------------------------------------------------------------
# create data.frame
cata <- c( 1,1,6,1,1,4)
catb <- c( 1,2,3,4,5,6)
id <- c('a', 'b', 'b', 'a', 'a', 'b')
dd1  <-  data.frame(id, cata,catb)

# function to create list from data.frame
lstfun  <- function(file, alpha , beta ) {
cda  <-  subset(file, file[,1] == alpha)
cdb  <-  subset (file, file[,1]== beta)
list1 <- list(cda,cdb)
}

# funtion to operate on list
ukn  <-  function(file, alpha, beta, nam1){
aa  <- alpha
bb  <- beta
myfile  <- file
nts <- lstfun(myfile, aa, bb)
mysum <- nam1[,3]*5
return(mysum)
}

results <- ukn(dd1, "a", "b", nts$cda)


From georgehret at gmail.com  Thu Jun 28 21:04:57 2007
From: georgehret at gmail.com (Georg Ehret)
Date: Thu, 28 Jun 2007 15:04:57 -0400
Subject: [R] R function command on a list
In-Reply-To: <da79af330706281023l3b32982bt5df519fcb8f00065@mail.gmail.com>
References: <e4dda3890706281012p63281240ma50a033a190cfe5f@mail.gmail.com>
	<da79af330706281023l3b32982bt5df519fcb8f00065@mail.gmail.com>
Message-ID: <e4dda3890706281204x7f3acba0i3e7bcf81e50acdc6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070628/c42535bd/attachment.pl 

From h.wickham at gmail.com  Thu Jun 28 21:29:51 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 28 Jun 2007 21:29:51 +0200
Subject: [R] Error en assign(mname, def, where)
In-Reply-To: <11346689.post@talk.nabble.com>
References: <11346689.post@talk.nabble.com>
Message-ID: <f8e6ff050706281229y606eb8fco1728c2a5024fe5cf@mail.gmail.com>

Hi Martin,

Could you please provide a minimal replicable example so that we can
investigate further.

Thanks,

Hadley

On 6/28/07, Mart?n Gast?n <martin.gaston at unavarra.es> wrote:
>
> Hi R users,
> I am working with the fda package but when I call the function pca.fd I
> obtain a message error, which I cann't identify. The error say That :
>  error in assihn(mname,def,where), is not possible to add links to a
> blockade enviroment.
> The orther that I'm writting is:
>
> > cp1 <- pca.fd(ind.fd1,nharm=3)
>
> and before it I can to plot the functional data object ind.fd1.
> ?Have anybody seen this error or any similar message?,
> ?Any idea?
>
> Thancks for your help
> --
> View this message in context: http://www.nabble.com/Error-en-assign%28mname%2C-def%2C-where%29-tf3995432.html#a11346689
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mtmorgan at fhcrc.org  Thu Jun 28 21:35:00 2007
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Thu, 28 Jun 2007 12:35:00 -0700
Subject: [R] Loading problem with XML_1.9
In-Reply-To: <776851.76466.qm@web32513.mail.mud.yahoo.com> (Luo Weijun's
	message of "Wed, 27 Jun 2007 15:11:44 -0700 (PDT)")
References: <776851.76466.qm@web32513.mail.mud.yahoo.com>
Message-ID: <6phir97j2jf.fsf@gopher4.fhcrc.org>

Weijun --

If memory is a problem, you might try using the 'handler' argument of
xmlTreeParse. This provides access to each node as it is processed, so
that you can, for instance, choose to ignore nodes, or save only
numeric values, or ... I'm not sure whether the entire document is
read into a C 'external pointer', or whether the savings is just in
the R representation of the document.

Also, depending on how you use the resulting document, you might want
to watch out for the memory leak mentioned in
http://www.omegahat.org/RSXML/Changes

Martin

Luo Weijun <luo_weijun at yahoo.com> writes:

> Hello all,
> I have loading problem with XML_1.9 under 64 bit
> R2.3.1, which I got from http://R.research.att.com/.
> XML_1.9 works fine under 32 bit R2.5.0. I thought that
> could be installation problem, and I tried
> install.packages or biocLite, every time the package
> installed fine, except some warning messages below:
> ld64 warning: in /usr/lib/libxml2.dylib, file does not
> contain requested architecture
> ld64 warning: in /usr/lib/libz.dylib, file does not
> contain requested architecture
> ld64 warning: in /usr/lib/libiconv.dylib, file does
> not contain requested architecture
> ld64 warning: in /usr/lib/libz.dylib, file does not
> contain requested architecture
> ld64 warning: in /usr/lib/libxml2.dylib, file does not
> contain requested architecture
>
> Here is the error messages I got, when XML is loaded:
>> library(XML)
> Error in dyn.load(x, as.logical(local),
> as.logical(now)) : 
>         unable to load shared library
> '/usr/local/lib64/R/library/XML/libs/XML.so':
>   dlopen(/usr/local/lib64/R/library/XML/libs/XML.so,
> 6): Symbol not found: _xmlMemDisplay
>   Referenced from:
> /usr/local/lib64/R/library/XML/libs/XML.so
>   Expected in: flat namespace
> Error: .onLoad failed in 'loadNamespace' for 'XML'
> Error: package/namespace load failed for 'XML'
>
> I understand that it has been pointed out that
> Sys.getenv("PATH") needs to be revised in the file
> XML/R/zzz.R, but I can??t even find that file under
> XML/R/ directory. Does anybody have any idea what
> might be the problem, and how to solve it? Thanks a
> lot!
> BTW, the reason I need to use R64 is that I have
> memory limitation issue with R 32 bit version when I
> load some very large XML trees. 
>
> Session information
>> sessionInfo()
> Version 2.3.1 Patched (2006-06-27 r38447) 
> powerpc64-apple-darwin8.7.0 
>
> attached base packages:
> [1] "methods"   "stats"     "graphics"  "grDevices"
> "utils"     "datasets" 
> [7] "base"     
>
> Weijun
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Martin Morgan
Bioconductor / Computational Biology
http://bioconductor.org


From wwwhsd at gmail.com  Thu Jun 28 21:38:47 2007
From: wwwhsd at gmail.com (Henrique Dallazuanna)
Date: Thu, 28 Jun 2007 16:38:47 -0300
Subject: [R] R function command on a list
In-Reply-To: <e4dda3890706281204x7f3acba0i3e7bcf81e50acdc6@mail.gmail.com>
References: <e4dda3890706281012p63281240ma50a033a190cfe5f@mail.gmail.com>
	<da79af330706281023l3b32982bt5df519fcb8f00065@mail.gmail.com>
	<e4dda3890706281204x7f3acba0i3e7bcf81e50acdc6@mail.gmail.com>
Message-ID: <da79af330706281238n22382f7coe13990147ee01abe@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070628/acb7afc3/attachment.pl 

From kirsten-beyer at uiowa.edu  Thu Jun 28 22:00:09 2007
From: kirsten-beyer at uiowa.edu (Kirsten Beyer)
Date: Thu, 28 Jun 2007 15:00:09 -0500
Subject: [R] sampling question
Message-ID: <e9b46960706281300t48ed28dcoaccf8d7121b4dea9@mail.gmail.com>

I am interested in locating a script to implement a sampling scheme
that would basically make it more likely that a particular observation
is chosen based on a weight associated with the observation.  I am
trying to select a sample of ~30 census blocks from each ZIP code area
based on the proportion of women in a ZCTA living in a particular
block.  I want to make it more likely that a block will be chosen if
the proportion of women in a patient's age group in a particular block
is high. Any ideas are appreciated!


From afshart at exchange.sba.miami.edu  Thu Jun 28 22:19:39 2007
From: afshart at exchange.sba.miami.edu (Afshartous, David)
Date: Thu, 28 Jun 2007 16:19:39 -0400
Subject: [R] applying max elementwise to two vectors
In-Reply-To: <mailman.7.1182074404.9166.r-help@stat.math.ethz.ch>
Message-ID: <6BCB4D493A447546A8126F24332056E806301A6B@school1.business.edu>

 
All,

Is there one liner way to obtain the max per observation for two
vectors?
I looked at apply and lapply but it seems that groundwork would have to
be done before applying either of those.  The code below does it but
seems
like overkill.

Thanks!
Dave

x = rnorm(10)
y = rnorm(10)

ind = which(x < y)
z = x
z[ind] <- y[ind]  ## z now contains the max's


From mvinic at gmail.com  Thu Jun 28 22:31:49 2007
From: mvinic at gmail.com (Marcus Vinicius)
Date: Thu, 28 Jun 2007 17:31:49 -0300
Subject: [R] Wilcoxon Rank Sum Test.
Message-ID: <c0792190706281331w1f8088a1hbad0e79cb91d18fd@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070628/7ab4672e/attachment.pl 

From hlynch at umd.edu  Thu Jun 28 22:44:31 2007
From: hlynch at umd.edu (hlynch at umd.edu)
Date: Thu, 28 Jun 2007 16:44:31 -0400 (EDT)
Subject: [R] mixed-effects model using lmer
Message-ID: <20070628164431.AOM68645@po3.mail.umd.edu>

Hello R-users,

I have been trying to fit what I think is a simple mixed-effects model using lmer (from lme4), but I've run into some difficulty that I have not been able to resolve using the existing archives or Pinheiro and Bates (2000).

I am measuring populations (of birds) which change with time at a number of different sites. These sites are grouped into regions. Sites are not measured with any regularity, so each site has a different number of observations. I want to treat the effect of year (i.e. the rate of population change) as a fixed effect which is modeled separately for each region, but I want to allow sites within regions to be random effects. I've come up with the following model, but I'm not sure its correct. Any help would be most appreciated.

fit<-lmer(log.count~site+month+year:region-1+(year:region-1|site))

What my variables mean:
log.count=log(count)
site=factor for the different sites, each site is associated with exactly one region
month=fixed effect for the month of the survey
year:region = allows me to model different year effects for each region

Each site should have a completely separate intercept, so I have chosen to suppress the intercept and use all the factors of site instead.

The difficulty is, of course, with the last term. I want to have sites vary randomly *within* a region, but I don't want them to vary randomly throughout all the regions, i.e. I want the random effects to sum to zero for each region separately. 

My output looks like (using the display() function from Gelman and Hill (2007)):

*******************************
lmer(formula = log.count ~ site + month + year:region - 1 + (year:region - 
    1 | site))
              coef.est coef.se
siteAITC       7.25     0.15  
siteALMI       4.57     0.29  
siteBENE       5.98     0.29  
siteBOOT       7.08     0.17  
siteBROW       6.47     0.14  
(I cut some out here for space) 
siteUSEF       6.97     0.21  
siteWATE       7.38     0.15  
siteYANK       8.31     0.11  
monthJAN      -0.15     0.07  
monthNOV      -0.01     0.07  
year:regionNE -0.16     0.12  
year:regionNW  0.04     0.01  
year:regionSH  0.02     0.02  
year:regionSW  0.07     0.01  

Error terms:
 Groups   Name          Std.Dev. Corr           
 site     year:regionNE 0.12                    
          year:regionNW 0.03     0.00           
          year:regionSH 0.00     0.00 0.00      
          year:regionSW 0.00     0.00 0.00 0.00 
 Residual               0.26                    
---
number of obs: 110, groups: site, 23
AIC = 157.8, DIC = -72.6
deviance = 3.6 

********************************

The coefficients look totally reasonable given all the analysis I've already done on the system. My confusion comes about when I look at the random effects using ranef(fit) and se.ranef(fit):

********************************
>ranef(fit)

An object of class "ranef.lmer"
[[1]]
     year:regionNE year:regionNW year:regionSH year:regionSW
AITC       0.0e+00       0.0e+00       5.8e-10       0.0e+00
ALMI       0.0e+00      -2.3e-04       0.0e+00       0.0e+00
BENE       0.0e+00      -2.1e-17       0.0e+00       0.0e+00
BOOT       0.0e+00       0.0e+00       0.0e+00      -2.4e-09
BROW       3.0e-15       0.0e+00       0.0e+00       0.0e+00
BRYE       0.0e+00      -1.3e-02       0.0e+00       0.0e+00
BRYS       0.0e+00      -8.9e-17       0.0e+00       0.0e+00
CUVE       0.0e+00      -1.7e-02       0.0e+00       0.0e+00
DAMO       0.0e+00      -5.0e-03       0.0e+00       0.0e+00
DANC       0.0e+00      -5.2e-03       0.0e+00       0.0e+00
DOBE       0.0e+00       8.1e-04       0.0e+00       0.0e+00
GEOR       0.0e+00      -9.3e-03       0.0e+00       0.0e+00
HANN       0.0e+00       0.0e+00       3.2e-10       0.0e+00
HERO      -6.3e-16       0.0e+00       0.0e+00       0.0e+00
JOUG       0.0e+00      -2.3e-02       0.0e+00       0.0e+00
MADD       7.3e-16       0.0e+00       0.0e+00       0.0e+00
MOOT       0.0e+00       0.0e+00       0.0e+00       8.7e-11
NEKO       0.0e+00      -2.1e-03       0.0e+00       0.0e+00
PETE       0.0e+00       0.0e+00       0.0e+00       2.5e-09
PLEN       0.0e+00       0.0e+00       0.0e+00      -2.0e-10
USEF       0.0e+00       5.6e-02       0.0e+00       0.0e+00
WATE       0.0e+00       1.8e-02       0.0e+00       0.0e+00
YANK       0.0e+00       0.0e+00      -9.0e-10       0.0e+00

>se.ranef(fit)

$site
     year:regionNE year:regionNW year:regionSH year:regionSW
AITC         0.120        0.0296       5.8e-06       5.8e-06
ALMI         0.120        0.0204       5.8e-06       5.8e-06
BENE         0.120        0.0196       5.8e-06       5.8e-06
BOOT         0.120        0.0296       5.8e-06       5.8e-06
BROW         0.016        0.0296       5.8e-06       5.8e-06
BRYE         0.120        0.0144       5.8e-06       5.8e-06
BRYS         0.120        0.0231       5.8e-06       5.8e-06
CUVE         0.120        0.0136       5.8e-06       5.8e-06
DAMO         0.120        0.0086       5.8e-06       5.8e-06
DANC         0.120        0.0211       5.8e-06       5.8e-06
DOBE         0.120        0.0221       5.8e-06       5.8e-06
GEOR         0.120        0.0153       5.8e-06       5.8e-06
HANN         0.120        0.0296       5.8e-06       5.8e-06
HERO         0.070        0.0296       5.8e-06       5.8e-06
JOUG         0.120        0.0086       5.8e-06       5.8e-06
MADD         0.047        0.0296       5.8e-06       5.8e-06
MOOT         0.120        0.0296       5.8e-06       5.8e-06
NEKO         0.120        0.0148       5.8e-06       5.8e-06
PETE         0.120        0.0296       5.8e-06       5.8e-06
PLEN         0.120        0.0296       5.8e-06       5.8e-06
USEF         0.120        0.0137       5.8e-06       5.8e-06
WATE         0.120        0.0226       5.8e-06       5.8e-06
YANK         0.120        0.0296       5.8e-06       5.8e-06
**************************************

I'm not sure this is correct. For one thing, I get an warning when I run the model that "Estimated variance-covariance for factor 'site' is singular". Also, although the random effects do add to zero for each region (within rounding error), I'm not sure how to interpret their standard errors. Each site is in only one of the four regions, and yet lmer seems to be estimating coefficients and standard errors as though each site was replicated in each region which is not the case. I have tried several other strategies based on suggestions from the archive, but this is the closest I have come to something reasonable. 

Thanks in advance for the help,
Heather Lynch


From spluque at gmail.com  Thu Jun 28 23:03:56 2007
From: spluque at gmail.com (Sebastian P. Luque)
Date: Thu, 28 Jun 2007 16:03:56 -0500
Subject: [R] applying max elementwise to two vectors
References: <mailman.7.1182074404.9166.r-help@stat.math.ethz.ch>
	<6BCB4D493A447546A8126F24332056E806301A6B@school1.business.edu>
Message-ID: <87ir97sseb.fsf@patagonia.sebmags.homelinux.org>

On Thu, 28 Jun 2007 16:19:39 -0400,
"Afshartous, David" <afshart at exchange.sba.miami.edu> wrote:

> All,

> Is there one liner way to obtain the max per observation for two
> vectors?  I looked at apply and lapply but it seems that groundwork
> would have to be done before applying either of those.  The code below
> does it but seems like overkill.

> Thanks!  Dave

> x = rnorm(10) y = rnorm(10)

> ind = which(x < y) z = x z[ind] <- y[ind] ## z now contains the max's

?pmax


-- 
Seb


From NordlDJ at dshs.wa.gov  Thu Jun 28 23:08:08 2007
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Thu, 28 Jun 2007 14:08:08 -0700
Subject: [R] Function call within a function.
In-Reply-To: <935534.94598.qm@web32802.mail.mud.yahoo.com>
References: <935534.94598.qm@web32802.mail.mud.yahoo.com>
Message-ID: <941871A13165C2418EC144ACB212BDB04E1322@dshsmxoly1504g.dshs.wa.lcl>

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of John Kane
> Sent: Thursday, June 28, 2007 12:04 PM
> To: R R-help
> Subject: [R] Function call within a function.
> 
> I am trying to call a funtion within another function
> and I clearly am misunderstanding what I should do. 
> Below is a simple example.
> I know lstfun works on its own but I cannot seem to
> figure out how to get it to work within ukn. Basically
> I need to create the variable "nts". I have probably
> missed something simple in the Intro or FAQ.
> 
> Any help would be much appreciated.
> 
> EXAMPLE
> --------------------------------------------------------------
> -----------------
> # create data.frame
> cata <- c( 1,1,6,1,1,4)
> catb <- c( 1,2,3,4,5,6)
> id <- c('a', 'b', 'b', 'a', 'a', 'b')
> dd1  <-  data.frame(id, cata,catb)
> 
> # function to create list from data.frame
> lstfun  <- function(file, alpha , beta ) {
> cda  <-  subset(file, file[,1] == alpha)
> cdb  <-  subset (file, file[,1]== beta)
> list1 <- list(cda,cdb)
> }
> 
> # funtion to operate on list
> ukn  <-  function(file, alpha, beta, nam1){
> aa  <- alpha
> bb  <- beta
> myfile  <- file
> nts <- lstfun(myfile, aa, bb)
> mysum <- nam1[,3]*5
> return(mysum)
> }
> 
> results <- ukn(dd1, "a", "b", nts$cda)

John,

The first problem I see is one of scope.  nts$cda refers to an object called nts which does not exist in the calling environment (it is local to the function ukn).  So trying to call ukn() with nts results in an error.  Second, even if you pass the name of the object, you will not be able to use it in ukn() in the manner that you are trying.  Your ukn() function definition also requires that it know the inner workings of function lstfun().  Functions generally shouldn't require knowing how other functions work, they should only rely on what value is returned.

You can get what you want by redefining ukn in the following way

# funtion to operate on list
ukn  <-  function(file, alpha, beta, nam1){
aa  <- alpha
bb  <- beta
myfile  <- file
nts <- lstfun(myfile, aa, bb)
mysum <- nts[[nam1]][,3]*5
return(mysum)
}

And change the function call to

results <- ukn(dd1, "a", "b", 1) 

This still leaves the functions coupled in a way that I don't like, but I'm not a good enough R programmer to solve that problem at the moment.  Maybe someone else will come along with a better solution.

Hope this is helpful,

Dan

Daniel J. Nordlund
Research and Data Analysis
Washington State Department of Social and Health Services
Olympia, WA  98504-5204


From gunter.berton at gene.com  Thu Jun 28 23:10:23 2007
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 28 Jun 2007 14:10:23 -0700
Subject: [R] applying max elementwise to two vectors
In-Reply-To: <6BCB4D493A447546A8126F24332056E806301A6B@school1.business.edu>
Message-ID: <002801c7b9c8$be33ebe0$4d908980@gne.windows.gene.com>

Please... use and **read** the docs:

?max   ---> pmax 


Bert Gunter


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Afshartous, David
Sent: Thursday, June 28, 2007 1:20 PM
To: r-help at stat.math.ethz.ch
Subject: [R] applying max elementwise to two vectors

 
All,

Is there one liner way to obtain the max per observation for two
vectors?
I looked at apply and lapply but it seems that groundwork would have to
be done before applying either of those.  The code below does it but
seems
like overkill.

Thanks!
Dave

x = rnorm(10)
y = rnorm(10)

ind = which(x < y)
z = x
z[ind] <- y[ind]  ## z now contains the max's

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From friedrich.leisch at stat.uni-muenchen.de  Thu Jun 28 14:18:31 2007
From: friedrich.leisch at stat.uni-muenchen.de (Friedrich Leisch)
Date: Thu, 28 Jun 2007 14:18:31 +0200
Subject: [R] Sweave bug? when writing figures / deleting variable in
	chunk
In-Reply-To: <7986B8A5-26DD-4BDA-9D75-5DF7F4EDE1B0@itc.nl>
References: <4E1EDA98-6048-4144-8168-6EC48D992C20@itc.nl>
	<20070628033458.e7babf40.Achim.Zeileis@wu-wien.ac.at>
	<7986B8A5-26DD-4BDA-9D75-5DF7F4EDE1B0@itc.nl>
Message-ID: <18051.42775.511099.948097@lxh5.stat.uni-muenchen.de>

>>>>> On Thu, 28 Jun 2007 08:14:44 -0400,
>>>>> D G Rossiter (DGR) wrote:

  > Thanks to the four distinguished R'ers who answered. I have used  
  > Sweave intensively for over a year, and have poured through all the  
  > doc. as well as the help archives, and could find nothing on this. It  
  > is now "well known" to me! since it bit me, but it did cost me a day  
  > of head-scratching and putting it in the shortest possible form for  
  > the list (the original example where this happened was a lot more  
  > complicated).

Sorry!

  > Perhaps it could be documented in Sweave- 
  > manual-20060104.pdf or its successor?

Yes, I'll put it in ASAP.

Best,
Fritz

-- 
-----------------------------------------------------------------------
Prof. Dr. Friedrich Leisch 

Institut f?r Statistik                          Tel: (+49 89) 2180 3165
Ludwig-Maximilians-Universit?t                  Fax: (+49 89) 2180 5308
Ludwigstra?e 33
D-80539 M?nchen                 http://www.stat.uni-muenchen.de/~leisch


From rossiter at itc.nl  Thu Jun 28 14:14:44 2007
From: rossiter at itc.nl (D G Rossiter)
Date: Thu, 28 Jun 2007 08:14:44 -0400
Subject: [R] Sweave bug? when writing figures / deleting variable in
	chunk
In-Reply-To: <20070628033458.e7babf40.Achim.Zeileis@wu-wien.ac.at>
References: <4E1EDA98-6048-4144-8168-6EC48D992C20@itc.nl>
	<20070628033458.e7babf40.Achim.Zeileis@wu-wien.ac.at>
Message-ID: <7986B8A5-26DD-4BDA-9D75-5DF7F4EDE1B0@itc.nl>

Thanks to the four distinguished R'ers who answered. I have used  
Sweave intensively for over a year, and have poured through all the  
doc. as well as the help archives, and could find nothing on this. It  
is now "well known" to me! since it bit me, but it did cost me a day  
of head-scratching and putting it in the shortest possible form for  
the list (the original example where this happened was a lot more  
complicated). Perhaps it could be documented in Sweave- 
manual-20060104.pdf or its successor?

Now I see the reasoning behind it, thanks. I had already determined  
the work-around. The problem is that I distribute the Tangled .R  
files along with the Sweaved PDF doc, so that students etc. can run  
the code. Anything unintuitive in the code confuses people. In this  
case I think it's good pratice to delete temporary variables right  
after they are no longer needed (as in my original example), so  
that's why I want to put it in the same chunk.

Having said that, I am a Sweave devotee, it has radically improved my  
productivity in writing R-based tech. notes.

David Rossiter
ITC Enschede (NL)

On 27 Jun2007, at 21:34, Achim Zeileis wrote:

> On Wed, 27 Jun 2007 21:06:04 -0400 D G Rossiter wrote:
>
>> I have found a quite strange (to me) behaviour in Sweave. It only
>> occurs in the following situation:
>>
>> 1. define a variable in one chunk
>> 2. use it within a subsequent figure-generating chunk
>> 3. delete it at the end of that same chunk
>> Then the Sweave driver chokes, not finding the variable name when
>> generating the figure
>
> Sweave() executes figure chunks more than once because they might
> also create printed output. If you create both EPS and PDF  
> graphics, it
> executes them three times (print + EPS + PDF). Hence, data
> manipulations should be avoided in figure chunks.
>
> I was also once bitten by this when I permuted columns of a table  
> prior
> to plotting and never obtained the desired order...
>
> Fritz, maybe this is worth an entry in the FAQ?
> Z
>
>> Example:
>>
>> % document bug2.Rnw
>> \documentclass{article}
>> \usepackage{Sweave}
>> \begin{document}
>> \SweaveOpts{eps=false}
>> <<>>=
>> sel <- 1:5
>> @
>> <<fig=T>>=
>> plot(trees[sel,])
>> rm(sel)
>> @
>> \end{document}
>>
>> Try to sweave:
>>
>>> Sweave("bug2.Rnw")
>> Writing to file bug2.tex
>> Processing code chunks ...
>> 1 : echo term verbatim
>> 2 : echo term verbatim pdf
>> Error: no function to return from, jumping to top level
>> Error in plot(trees[sel, ]) : error in evaluating the argument 'x'
>> in selecting a method for function 'plot'
>> Error in driver$runcode(drobj, chunk, chunkopts) :
>> 	Error in plot(trees[sel, ]) : error in evaluating the
>> argument 'x' in selecting a method for function 'plot'
>>
>> The generated .tex is complete up through the rm() but no figure is
>> generated. The file bug2-002.pdf is incomplete (corrupt).
>>
>> ...
>> \begin{Schunk}
>> \begin{Sinput}
>>> plot(trees[sel, ])
>>> rm(sel)
>> \end{Sinput}
>> \end{Schunk}
>>
>> The following ALL eliminate the problem:
>>
>> 0. Executing the code directly, also with ESS
>> 1. <<fig=F>>
>> 2. moving rm(sel) to a separate, later code chunk
>> 3. Stangle the source and then source it
>> 4. don't use a variable, i.e. in this case:  plot(trees[1:5,])
>>
>> It seems that Sweave is executing the rm(sel)  before it uses it in
>> the trees[sel,].
>>
>> Technical details: R 2.5.0, Mac OS X 10.4.10, PPC
>> Same behaviour in stand-alone R for Mac and for R within Aquamacs
>> using ESS
>>
>> Workaround: I am putting any deletions into a later code chunk. This
>> only has the disadvantage of making more chunks, so now that I know
>> what's happening it's no big deal. But it's driving me crazy... am I
>> missing something? Thanks!
>>
>> D. G. Rossiter
>> Senior University Lecturer
>> Department of Earth Systems Analysis
>> International Institute for Geo-Information Science and Earth
>> Observation (ITC)
>> Hengelosestraat 99
>> PO Box 6, 7500 AA Enschede, The Netherlands
>> Phone:	+31-(0)53 4874 499
>> Fax:	+31-(0)53 4874 336
>> mailto:rossiter--at--itc.nl,  Internet: http://www.itc.nl/personal/
>> rossiter
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html and provide commented,
>> minimal, self-contained, reproducible code.
>>


From price_ja at hotmail.com  Thu Jun 28 22:47:00 2007
From: price_ja at hotmail.com (Jim Price)
Date: Thu, 28 Jun 2007 13:47:00 -0700 (PDT)
Subject: [R] Changing graphics height when using grid and lattice
Message-ID: <11350733.post@talk.nabble.com>


Hi,

I have recently been playing with the grid package in an attempt to create
some pages containing multiple lattice plots on the same page. However, when
I specify a grid layout with different widths, such as:

pushViewport(viewport(layout = grid.layout(1, 2, unit(c(2, 1), "null"))))

the individual graphs do not end up as the same height - which is a feature
I would prefer to have. 

A complete example is as follows:

### Start of example

library(lattice)
library(Hmisc)
library(grid)


# Incidence data
testData <- data.frame(
	strata = rep(c("CHF : Yes", "CHF : No"), each = 20),
	ae = rep(paste("Adverse Event", 1:10), each = 2),
	trt = rep(c("Active", "Placebo"), 20),
	pct = runif(40, 1, 30)
)

# RR data
testData2 <- data.frame(
	strata = rep(c("CHF : Yes", "CHF : No"), each = 10),
	ae = paste("Adverse Event", 1:10),
	rr = runif(20, 0.5, 5)
)
testData2$lower = testData2$rr / 2
testData2$upper = testData2$rr * 2
	

# Combined plot
testPlots <- function(relativeWidth)
{

plot1<- dotplot(
	ae ~ pct | strata, 
	groups = trt, 
	data = testData,  
	layout = c(1, 2),
	xlab = "Percent",
	auto.key = list(space = "top", columns = 2)
)


plot2 <- Dotplot(
	ae ~ Cbind(rr, log10(lower), log10(upper)) | strata,
	data = testData2,
	panel = function(...)
	{
		panel.Dotplot(...)
		panel.abline(v = 0, col = 'red', lty = 2)
	},
	layout = c(1, 2), 
	scales = list(
		x = list(log = T, at = c(0.125, 0.25, 0.5, 1, 2, 4, 8, 16, 32)),
		y = list(draw = F)
	),
	xlab = "Relative Risk with 95% CI",
	ylab = "",
	key = list(text = list(""))
)


grid.newpage()

pushViewport(viewport(layout = grid.layout(2, 1, heights = unit(c(1, 6),
"null"))))

pushViewport(viewport(layout.pos.col = 1, layout.pos.row = 1))
grid.text("Analysis of Relative Risks of various Adverse Events")
upViewport()

pushViewport(viewport(layout.pos.col = 1, layout.pos.row = 2))


### Change the relative width of the 2 presented graphics
pushViewport(viewport(layout = grid.layout(1, 2, unit(c(relativeWidth, 1),
"null"))))

pushViewport(viewport(layout.pos.col = 1, layout.pos.row = 1))
print(plot1, newpage = F)
upViewport()

pushViewport(viewport(layout.pos.col = 2, layout.pos.row = 1))
print(plot2, newpage = F)
upViewport()

}


# Everything is fine, both graphs maintain the same y-axis
testPlots(1)

# The second graph is now "taller" than the first one
win.graph()
testPlots(3)

##### End of example

I've been through the documentation of both lattice and grid, and I have not
been able to find the answer. I would appreciate any solution!

Regards,

James Price.
-- 
View this message in context: http://www.nabble.com/Changing-graphics-height-when-using-grid-and-lattice-tf3996724.html#a11350733
Sent from the R help mailing list archive at Nabble.com.


From NordlDJ at dshs.wa.gov  Thu Jun 28 23:18:52 2007
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Thu, 28 Jun 2007 14:18:52 -0700
Subject: [R] Wilcoxon Rank Sum Test.
In-Reply-To: <c0792190706281331w1f8088a1hbad0e79cb91d18fd@mail.gmail.com>
References: <c0792190706281331w1f8088a1hbad0e79cb91d18fd@mail.gmail.com>
Message-ID: <941871A13165C2418EC144ACB212BDB04E1323@dshsmxoly1504g.dshs.wa.lcl>


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Marcus Vinicius
> Sent: Thursday, June 28, 2007 1:32 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Wilcoxon Rank Sum Test.
> 
> Dear,
> 
> I'm using R software to evaluate Wilcoxon Rank Sum Test and 
> I' getting one
> Warning message as this:
> 
> > C1dea_com
>  [1] 1.000 0.345 0.200 0.208 0.508 0.480 0.545 0.563 0.451 
> 0.683 0.380 0.913
> 1.000 0.506
> > C1dea_sem
>  [1] 1.000 0.665 0.284 0.394 0.509 0.721 0.545 0.898 0.744 
> 0.683 0.382 0.913
> 1.000 0.970
> 
> 
> > wilcox.test(C1dea_sem,C1dea_com, paired = TRUE, alternative 
> = "two.sided")
> 
>         Wilcoxon signed rank test with continuity correction
> 
> data:  C1dea_sem and C1dea_com
> V = 45, p-value = 0.009152
> alternative hypothesis: true mu is not equal to 0
> 
> Warning message:
> Cannot compute exact p-value with zeroes in: 
> wilcox.test.default(C1dea_sem,
> C1dea_com, paired = TRUE, alternative = "two.sided")
> 
> What is happening?
> 
> Best Regards,
> 
> Marcus Vinicius
> 

Marcus,

It means that you have one or more pairs of observations (5 in your case) where the difference is 0.  The wilcox.test can only compute an approximate p-value under these circumstances.

Hope this is helpful,

Dan

Daniel J. Nordlund
Research and Data Analysis
Washington State Department of Social and Health Services
Olympia, WA  98504-5204


From alxsal at free.fr  Thu Jun 28 23:24:30 2007
From: alxsal at free.fr (Alexandre Salvador)
Date: Thu, 28 Jun 2007 23:24:30 +0200
Subject: [R] Adding different output to different lattice panels
In-Reply-To: <eb555e660706280845g3af6e59fx807c493a914d50d1@mail.gmail.com>
References: <1183040759.4683c4f7c087b@imp.free.fr>
	<eb555e660706280845g3af6e59fx807c493a914d50d1@mail.gmail.com>
Message-ID: <1183065870.4684270ee6d63@imp.free.fr>

Selon deepayan.sarkar at gmail.com:

> On 6/28/07, alxsal at free.fr <alxsal at free.fr> wrote:
> > I would like to add a reference line to lattice graphs, with the reference
> > line
> > being different according to the factor level.
> >
> > Example : Draw 3 dotplots for "a","b" and "c" factors, and then add an
> > horizontal line at y=10 for panel "a", y=8 for panel "b" and y=6 for panel
> > "4"
> >
> > I tried the code below, but this draw all three reference lines for each
> > panel.
> > How do I index the current panel to chose the right reference vector value
> ?
> >
> >
>
dat<-data.frame(id=rep(c("a","b","c"),4),val=1:12,quand=rep(c("t1","t2","t3","t4"),each=3))
> > ref<-c(10,8,6)
> > plot.new()
> > datplot<-dotplot(val~quand|id,data=dat,panel=function(...){
> > panel.dotplot(...)
> > panel.abline(h=ref)
> > })
> > print(datplot)
>
> dotplot(val~quand|id,data=dat,panel=function(...){
>     panel.dotplot(...)
>     panel.abline(h = ref[packet.number()])
> })
>
> (Things are more complicated if you have more than one conditioning
> variable.)
>
> -Deepayan
>

I tried you solution, but the following error appears when I print(datplot):

   Erreur dans as.numeric(h) : impossible de trouver la fonction "packet.number"

I have lattice and grid libraries loaded. The exact code I use is
datplot<-dotplot(val~quand|id,data=dat,panel=function(...){
panel.dotplot(...)
panel.abline(h=ref[packet.number()])
})
print(datplot)
What do I do wrong ?

Note : I usually need to use the indirect datplot<-dotplot(...  and then
print(datplot) when I store my code in a file and use it through
source("myfile.R"). The direct dotplot(... does not open a device whereas it
does if I type directly dotplot(... at the R command line...
Is this normal ?

--
Alexandre Salvador
Tel: +33(0)6.8214.7733


From Greg.Snow at intermountainmail.org  Thu Jun 28 23:25:36 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Thu, 28 Jun 2007 15:25:36 -0600
Subject: [R] applying max elementwise to two vectors
In-Reply-To: <6BCB4D493A447546A8126F24332056E806301A6B@school1.business.edu>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBA5AE7F@LP-EXCHVS07.CO.IHC.COM>

Are you looking for pmax? (look at the help ?pmax and the examples and
see if that does what you want).

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Afshartous, David
> Sent: Thursday, June 28, 2007 2:20 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] applying max elementwise to two vectors
> 
> 
>  
> All,
> 
> Is there one liner way to obtain the max per observation for 
> two vectors?
> I looked at apply and lapply but it seems that groundwork 
> would have to be done before applying either of those.  The 
> code below does it but seems like overkill.
> 
> Thanks!
> Dave
> 
> x = rnorm(10)
> y = rnorm(10)
> 
> ind = which(x < y)
> z = x
> z[ind] <- y[ind]  ## z now contains the max's
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Greg.Snow at intermountainmail.org  Thu Jun 28 23:26:53 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Thu, 28 Jun 2007 15:26:53 -0600
Subject: [R] sampling question
In-Reply-To: <e9b46960706281300t48ed28dcoaccf8d7121b4dea9@mail.gmail.com>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBA5AE82@LP-EXCHVS07.CO.IHC.COM>

The sample function has a prob argument that determines the
probabilities of each element being sampled, put your proportion of
women in there and see if that works for you.

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Kirsten Beyer
> Sent: Thursday, June 28, 2007 2:00 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] sampling question
> 
> I am interested in locating a script to implement a sampling 
> scheme that would basically make it more likely that a 
> particular observation is chosen based on a weight associated 
> with the observation.  I am trying to select a sample of ~30 
> census blocks from each ZIP code area based on the proportion 
> of women in a ZCTA living in a particular block.  I want to 
> make it more likely that a block will be chosen if the 
> proportion of women in a patient's age group in a particular 
> block is high. Any ideas are appreciated!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From afshart at exchange.sba.miami.edu  Thu Jun 28 23:26:53 2007
From: afshart at exchange.sba.miami.edu (Afshartous, David)
Date: Thu, 28 Jun 2007 17:26:53 -0400
Subject: [R] applying max elementwise to two vectors
In-Reply-To: <07E228A5BE53C24CAD490193A7381BBBA5AE7F@LP-EXCHVS07.CO.IHC.COM>
Message-ID: <6BCB4D493A447546A8126F24332056E806337275@school1.business.edu>


thanks all.  yes, pmax(x,y) gets it straight away.  sorry for missing
this
when I checked the docs. 

-----Original Message-----
From: Greg Snow [mailto:Greg.Snow at intermountainmail.org] 
Sent: Thursday, June 28, 2007 5:26 PM
To: Afshartous, David; r-help at stat.math.ethz.ch
Subject: RE: [R] applying max elementwise to two vectors

Are you looking for pmax? (look at the help ?pmax and the examples and
see if that does what you want).

--
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Afshartous, 
> David
> Sent: Thursday, June 28, 2007 2:20 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] applying max elementwise to two vectors
> 
> 
>  
> All,
> 
> Is there one liner way to obtain the max per observation for two 
> vectors?
> I looked at apply and lapply but it seems that groundwork would have 
> to be done before applying either of those.  The code below does it 
> but seems like overkill.
> 
> Thanks!
> Dave
> 
> x = rnorm(10)
> y = rnorm(10)
> 
> ind = which(x < y)
> z = x
> z[ind] <- y[ind]  ## z now contains the max's
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mswierniak at o2.pl  Thu Jun 28 23:27:50 2007
From: mswierniak at o2.pl (jastar)
Date: Thu, 28 Jun 2007 14:27:50 -0700 (PDT)
Subject: [R] Writing - specyfic format
In-Reply-To: <f60k0h$v23$1@sea.gmane.org>
References: <11341784.post@talk.nabble.com> <f60k0h$v23$1@sea.gmane.org>
Message-ID: <11351319.post@talk.nabble.com>


That's exactly what I need.
Thank's a lot!!


Earl F. Glynn wrote:
> 
> "jastar" <mswierniak at o2.pl> wrote in message 
> news:11341784.post at talk.nabble.com...
>>
>> Hi all,
>> I have a trouble - I need to write file in a very specyfic format.
>> I have two vectors which different lengths and one data.frame (or
>> matrix).
>> I want to write it to "*.txt" file in following way:
>> 1st row of file is my 1st vector (separate by spacebar)
>> 2nd row of file is 2nd vector (also separate by spacebar)
>> Rest of this file should be a matrix with elements separated by tab.
>> For example: a=1, 2, 3, b=4, 5, c=[1, 2, 3, 4, 5, 6;
>>                                            7, 8, 9, 10, 11, 12,]
>> and I want to have file (it have to be .txt file) like:
>> 1 2 3
>> 4 5
>> 1     2     3     4     5     6
>> 7     8     9     10   11    12
>>
>> This thing have to be done automaticly from R.
>> Is it possible?
> 
> Try this:
> 
> a <- 1:3
> b <- 4:5
> c <- matrix(1:12, 2,6, byrow=TRUE)
> 
> outFile <- file("SpecificFormat.txt", "w")
> cat(paste(a, sep=" "), "\n", file=outFile)
> cat(paste(b, sep=" "), "\n", file=outFile)
> 
> for (j in 1:nrow(c))
> {
>   cat(paste(c[j,], collapse="\t"), "\n", file=outFile)
> }
> 
> close(outFile)
> 
> 
> Resulting output file (with spaces or tabs as specified):
> 1 2 3
> 4 5
> 1 2 3 4 5 6
> 7 8 9 10 11 12
> 
> 
> [But I normally avoid tabs since you cannot "see" them easily with many 
> editors.]
> 
> efg
> 
> Earl F. Glynn
> Stowers Institute for Medical Research
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/Writing---specyfic-format-tf3994017.html#a11351319
Sent from the R help mailing list archive at Nabble.com.


From jasoncbarnhart at msn.com  Thu Jun 28 23:40:36 2007
From: jasoncbarnhart at msn.com (Jason Barnhart)
Date: Thu, 28 Jun 2007 14:40:36 -0700
Subject: [R] Function call within a function.
References: <935534.94598.qm@web32802.mail.mud.yahoo.com>
Message-ID: <BAY116-DAV16327E3DF47A01B08BDE59CF090@phx.gbl>

The problem isn't the function call.

First, list1 returned by lstfun does not name its elements so nts$cda 
won't work. See code change in lstfun.

Second, specifying nts$cda as the nam1 argument tells R to look for 
the nts object in the environment in which ukn is called.  However, 
the nts object is not created in the parent environment, it is created 
in the ukn's environment.

Third, nam1[,3] should be nam1[2] as there is no third element to this 
list (although and this doesn't resolve the environment issue).

I've modified your code below to work, but there are better ways to go 
about this.  Thomas Lumley has a famous quote regarding parse.  See 
http://tolstoy.newcastle.edu.au/R/e2/help/07/01/8059.html among 
others.

I was once referred to Patrick Burns' S Poetry to learn about the 
"eval(parse(text=)))" paradigm which was very helpful. You may also 
want to brush up on environments (see ?environment) to learn more 
about lexical scoping.

Hope this helps.
-jason

#MODIFIED CODE
# create data.frame
cata <- c( 1,1,6,1,1,4)
catb <- c( 1,2,3,4,5,6)
id <- c('a', 'b', 'b', 'a', 'a', 'b')
dd1 <- data.frame(id, cata,catb)

# function to create list from data.frame
lstfun <- function(file, alpha , beta ) {
cda <- subset(file, file[,1] == alpha)
cdb <- subset (file, file[,1]== beta)
### CODE ADDED HERE
list1 <- list(cda=cda,cdb=cdb)
}

# funtion to operate on list
ukn <- function(file, alpha, beta, nam1){
aa <- alpha
bb <- beta
myfile <- file
nts <- lstfun(myfile, aa, bb)
### CODE ADDED HERE
mysum <- eval(parse(text=nam1))
#mysum <- nam1[,3]*5
return(mysum)
}

results <- ukn(dd1, "a", "b", "nts$cda") ### modified how called.

----- Original Message ----- 
From: "John Kane" <jrkrideau at yahoo.ca>
To: "R R-help" <r-help at stat.math.ethz.ch>
Sent: Thursday, June 28, 2007 12:03 PM
Subject: [R] Function call within a function.


>I am trying to call a funtion within another function
> and I clearly am misunderstanding what I should do.
> Below is a simple example.
> I know lstfun works on its own but I cannot seem to
> figure out how to get it to work within ukn. Basically
> I need to create the variable "nts". I have probably
> missed something simple in the Intro or FAQ.
>
> Any help would be much appreciated.
>
> EXAMPLE
> -------------------------------------------------------------------------------
> # create data.frame
> cata <- c( 1,1,6,1,1,4)
> catb <- c( 1,2,3,4,5,6)
> id <- c('a', 'b', 'b', 'a', 'a', 'b')
> dd1  <-  data.frame(id, cata,catb)
>
> # function to create list from data.frame
> lstfun  <- function(file, alpha , beta ) {
> cda  <-  subset(file, file[,1] == alpha)
> cdb  <-  subset (file, file[,1]== beta)
> list1 <- list(cda,cdb)
> }
>
> # funtion to operate on list
> ukn  <-  function(file, alpha, beta, nam1){
> aa  <- alpha
> bb  <- beta
> myfile  <- file
> nts <- lstfun(myfile, aa, bb)
> mysum <- nam1[,3]*5
> return(mysum)
> }
>
> results <- ukn(dd1, "a", "b", nts$cda)
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Achim.Zeileis at wu-wien.ac.at  Thu Jun 28 23:49:15 2007
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Thu, 28 Jun 2007 23:49:15 +0200
Subject: [R] Wilcoxon Rank Sum Test.
In-Reply-To: <941871A13165C2418EC144ACB212BDB04E1323@dshsmxoly1504g.dshs.wa.lcl>
References: <c0792190706281331w1f8088a1hbad0e79cb91d18fd@mail.gmail.com>
	<941871A13165C2418EC144ACB212BDB04E1323@dshsmxoly1504g.dshs.wa.lcl>
Message-ID: <20070628234915.c4d6479b.Achim.Zeileis@wu-wien.ac.at>

On Thu, 28 Jun 2007 14:18:52 -0700 Nordlund, Dan (DSHS/RDA) wrote:

> 
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch 
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Marcus
> > Vinicius Sent: Thursday, June 28, 2007 1:32 PM
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] Wilcoxon Rank Sum Test.
> > 
> > Dear,
> > 
> > I'm using R software to evaluate Wilcoxon Rank Sum Test and 
> > I' getting one
> > Warning message as this:
> > 
> > > C1dea_com
> >  [1] 1.000 0.345 0.200 0.208 0.508 0.480 0.545 0.563 0.451 
> > 0.683 0.380 0.913
> > 1.000 0.506
> > > C1dea_sem
> >  [1] 1.000 0.665 0.284 0.394 0.509 0.721 0.545 0.898 0.744 
> > 0.683 0.382 0.913
> > 1.000 0.970
> > 
> > 
> > > wilcox.test(C1dea_sem,C1dea_com, paired = TRUE, alternative 
> > = "two.sided")
> > 
> >         Wilcoxon signed rank test with continuity correction
> > 
> > data:  C1dea_sem and C1dea_com
> > V = 45, p-value = 0.009152
> > alternative hypothesis: true mu is not equal to 0
> > 
> > Warning message:
> > Cannot compute exact p-value with zeroes in: 
> > wilcox.test.default(C1dea_sem,
> > C1dea_com, paired = TRUE, alternative = "two.sided")
> > 
> > What is happening?
> > 
> > Best Regards,
> > 
> > Marcus Vinicius
> > 
> 
> Marcus,
> 
> It means that you have one or more pairs of observations (5 in your
> case) where the difference is 0.  The wilcox.test can only compute an
> approximate p-value under these circumstances.

...while wilcox.exact() from package "exactRankTests" can evaluate the
permutation distribution correctly.
Z

> Hope this is helpful,
> 
> Dan
> 
> Daniel J. Nordlund
> Research and Data Analysis
> Washington State Department of Social and Health Services
> Olympia, WA  98504-5204
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.
>


From deepayan.sarkar at gmail.com  Thu Jun 28 23:47:12 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Thu, 28 Jun 2007 14:47:12 -0700
Subject: [R] Adding different output to different lattice panels
In-Reply-To: <1183065870.4684270ee6d63@imp.free.fr>
References: <1183040759.4683c4f7c087b@imp.free.fr>
	<eb555e660706280845g3af6e59fx807c493a914d50d1@mail.gmail.com>
	<1183065870.4684270ee6d63@imp.free.fr>
Message-ID: <eb555e660706281447w448b6a74v8b32bf8c3b6f72fb@mail.gmail.com>

On 6/28/07, Alexandre Salvador <alxsal at free.fr> wrote:
> Selon deepayan.sarkar at gmail.com:
>
> > On 6/28/07, alxsal at free.fr <alxsal at free.fr> wrote:
> > > I would like to add a reference line to lattice graphs, with the reference
> > > line
> > > being different according to the factor level.
> > >
> > > Example : Draw 3 dotplots for "a","b" and "c" factors, and then add an
> > > horizontal line at y=10 for panel "a", y=8 for panel "b" and y=6 for panel
> > > "4"
> > >
> > > I tried the code below, but this draw all three reference lines for each
> > > panel.
> > > How do I index the current panel to chose the right reference vector value
> > ?
> > >
> > >
> >
> dat<-data.frame(id=rep(c("a","b","c"),4),val=1:12,quand=rep(c("t1","t2","t3","t4"),each=3))
> > > ref<-c(10,8,6)
> > > plot.new()
> > > datplot<-dotplot(val~quand|id,data=dat,panel=function(...){
> > > panel.dotplot(...)
> > > panel.abline(h=ref)
> > > })
> > > print(datplot)
> >
> > dotplot(val~quand|id,data=dat,panel=function(...){
> >     panel.dotplot(...)
> >     panel.abline(h = ref[packet.number()])
> > })
> >
> > (Things are more complicated if you have more than one conditioning
> > variable.)
> >
> > -Deepayan
> >
>
> I tried you solution, but the following error appears when I print(datplot):
>
>    Erreur dans as.numeric(h) : impossible de trouver la fonction "packet.number"
>
> I have lattice and grid libraries loaded. The exact code I use is
> datplot<-dotplot(val~quand|id,data=dat,panel=function(...){
> panel.dotplot(...)
> panel.abline(h=ref[packet.number()])
> })
> print(datplot)
> What do I do wrong ?

You are using a very old version of R (or at least old enough that the
packet.number number didn't exist). You haven't told us what version
you are using.

I would encourage you to upgrade, but this might work for now:

dotplot(val~quand|id,data=dat,
        panel=function(..., panel.number){
            panel.dotplot(...)
            panel.abline(h = ref[panel.number])
})

> Note : I usually need to use the indirect datplot<-dotplot(...  and then
> print(datplot) when I store my code in a file and use it through
> source("myfile.R"). The direct dotplot(... does not open a device whereas it
> does if I type directly dotplot(... at the R command line...
> Is this normal ?

Yes, and a FAQ:

http://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-do-lattice_002ftrellis-graphics-not-work_003f

-Deepayan


From alxsal at free.fr  Thu Jun 28 23:57:32 2007
From: alxsal at free.fr (Alexandre Salvador)
Date: Thu, 28 Jun 2007 23:57:32 +0200
Subject: [R] Adding different output to different lattice panels
In-Reply-To: <eb555e660706281447w448b6a74v8b32bf8c3b6f72fb@mail.gmail.com>
References: <1183040759.4683c4f7c087b@imp.free.fr>
	<eb555e660706280845g3af6e59fx807c493a914d50d1@mail.gmail.com>
	<1183065870.4684270ee6d63@imp.free.fr>
	<eb555e660706281447w448b6a74v8b32bf8c3b6f72fb@mail.gmail.com>
Message-ID: <1183067852.46842eccf0586@imp.free.fr>

Selon Deepayan Sarkar <deepayan.sarkar at gmail.com>:

> On 6/28/07, Alexandre Salvador <alxsal at free.fr> wrote:
> > Selon deepayan.sarkar at gmail.com:
> >
> > > On 6/28/07, alxsal at free.fr <alxsal at free.fr> wrote:
> > > > I would like to add a reference line to lattice graphs, with the
> reference
> > > > line
> > > > being different according to the factor level.
> > > >
> > > > Example : Draw 3 dotplots for "a","b" and "c" factors, and then add an
> > > > horizontal line at y=10 for panel "a", y=8 for panel "b" and y=6 for
> panel
> > > > "4"
> > > >
> > > > I tried the code below, but this draw all three reference lines for
> each
> > > > panel.
> > > > How do I index the current panel to chose the right reference vector
> value
> > > ?
> > > >
> > > >
> > >
> >
>
dat<-data.frame(id=rep(c("a","b","c"),4),val=1:12,quand=rep(c("t1","t2","t3","t4"),each=3))
> > > > ref<-c(10,8,6)
> > > > plot.new()
> > > > datplot<-dotplot(val~quand|id,data=dat,panel=function(...){
> > > > panel.dotplot(...)
> > > > panel.abline(h=ref)
> > > > })
> > > > print(datplot)
> > >
> > > dotplot(val~quand|id,data=dat,panel=function(...){
> > >     panel.dotplot(...)
> > >     panel.abline(h = ref[packet.number()])
> > > })
> > >
> > > (Things are more complicated if you have more than one conditioning
> > > variable.)
> > >
> > > -Deepayan
> > >
> >
> > I tried you solution, but the following error appears when I
> print(datplot):
> >
> >    Erreur dans as.numeric(h) : impossible de trouver la fonction
> "packet.number"
> >
> > I have lattice and grid libraries loaded. The exact code I use is
> > datplot<-dotplot(val~quand|id,data=dat,panel=function(...){
> > panel.dotplot(...)
> > panel.abline(h=ref[packet.number()])
> > })
> > print(datplot)
> > What do I do wrong ?
>
> You are using a very old version of R (or at least old enough that the
> packet.number number didn't exist). You haven't told us what version
> you are using.
>
> I would encourage you to upgrade, but this might work for now:
>
> dotplot(val~quand|id,data=dat,
>         panel=function(..., panel.number){
>             panel.dotplot(...)
>             panel.abline(h = ref[panel.number])
> })
>
> > Note : I usually need to use the indirect datplot<-dotplot(...  and then
> > print(datplot) when I store my code in a file and use it through
> > source("myfile.R"). The direct dotplot(... does not open a device whereas
> it
> > does if I type directly dotplot(... at the R command line...
> > Is this normal ?
>
> Yes, and a FAQ:
>
>
http://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-do-lattice_002ftrellis-graphics-not-work_003f
>
> -Deepayan
>
Works all right,
I use Version 2.3.1 (2006-06-01)
I'll upgrade to the newer versions...
Thanks very much,
Cheers

--
Alexandre Salvador
Tel: +33(0)6.8214.7733


From brown_emu at yahoo.com  Fri Jun 29 00:00:38 2007
From: brown_emu at yahoo.com (Stephen Tucker)
Date: Thu, 28 Jun 2007 15:00:38 -0700 (PDT)
Subject: [R] Function call within a function.
In-Reply-To: <935534.94598.qm@web32802.mail.mud.yahoo.com>
Message-ID: <270735.77400.qm@web39704.mail.mud.yahoo.com>

Dear John,

Perhaps I am mistaken in what you are trying to accomplish but it seems like
what is required is that you call lstfun() outside of ukn(). [and remove the
call to lstfun() in ukn()].

nts <- lstfun(myfile, aa, bb)
results <- ukn(dd1, "a", "b", nts$cda)

Alternatively, you can eliminate the fourth argument in ukn() and assign (via
'<-') the results of lstfun() to 'nam1' within ukn() instead of saving to
'nts'...

--- John Kane <jrkrideau at yahoo.ca> wrote:

> I am trying to call a funtion within another function
> and I clearly am misunderstanding what I should do. 
> Below is a simple example.
> I know lstfun works on its own but I cannot seem to
> figure out how to get it to work within ukn. Basically
> I need to create the variable "nts". I have probably
> missed something simple in the Intro or FAQ.
> 
> Any help would be much appreciated.
> 
> EXAMPLE
>
-------------------------------------------------------------------------------
> # create data.frame
> cata <- c( 1,1,6,1,1,4)
> catb <- c( 1,2,3,4,5,6)
> id <- c('a', 'b', 'b', 'a', 'a', 'b')
> dd1  <-  data.frame(id, cata,catb)
> 
> # function to create list from data.frame
> lstfun  <- function(file, alpha , beta ) {
> cda  <-  subset(file, file[,1] == alpha)
> cdb  <-  subset (file, file[,1]== beta)
> list1 <- list(cda,cdb)
> }
> 
> # funtion to operate on list
> ukn  <-  function(file, alpha, beta, nam1){
> aa  <- alpha
> bb  <- beta
> myfile  <- file
> nts <- lstfun(myfile, aa, bb)
> mysum <- nam1[,3]*5
> return(mysum)
> }
> 
> results <- ukn(dd1, "a", "b", nts$cda)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From David.Duffy at qimr.edu.au  Fri Jun 29 00:00:48 2007
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Fri, 29 Jun 2007 08:00:48 +1000 (EST)
Subject: [R]  exaustive subgrouping or combination
In-Reply-To: <mailman.13.1183024805.4590.r-help@stat.math.ethz.ch>
References: <mailman.13.1183024805.4590.r-help@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.64.0706290757300.25798@orpheus.qimr.edu.au>

> Waverley <waverley.paloalto at gmail.com> asked:
> 
> Dear Colleagues,
> 
> I am looking for a package or previous implemented R to subgroup and
> exaustively divide a vector of squence into 2 groups.
> 
> -- 
> Waverley @ Palo Alto

Google "[R] Generating all possible partitions" and you will find some R code
from 2002 or so.

David Duffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v


From ramasamy at cancer.org.uk  Fri Jun 29 00:19:46 2007
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Thu, 28 Jun 2007 23:19:46 +0100
Subject: [R] sampling question
In-Reply-To: <e9b46960706281300t48ed28dcoaccf8d7121b4dea9@mail.gmail.com>
References: <e9b46960706281300t48ed28dcoaccf8d7121b4dea9@mail.gmail.com>
Message-ID: <46843402.8030107@cancer.org.uk>

Lets assume your zcta data looks like this

    set.seed(12345) ## temporary for reproducibility
    zcta <- data.frame( zipcode=LETTERS[1:5], prop=runif(5) )
    zcta
    zipcode      prop
1       A 0.7209039
2       B 0.8757732
3       C 0.7609823
4       D 0.8861246
5       E 0.4564810

This says that 72.1% of the population in zipcode A is female, ..., and 
45.6% in zipcode E is female.


Now suppose you sampled 20 people and you recorded the zipcode (and 
other variables) and stored in 'samp'

    samp <- data.frame( id=1:20,
                        zipcode=LETTERS[ sample(1:5, 20, replace=TRUE) ])


Now, I am not sure what you want to do. But I could see two possible 
meanings from your message.

1) If you want to sample 10 observation, with each observation weighted 
INDEPENDENTLY by the proportion of women in its zipcode, try something 
like the following. The problem with this option is that it depends on 
the prevalence of the zipcodes of the observations.

    comb <- merge( samp, zcta, all.x=T )
    comb <- comb[ order(comb$id), ]
    comb[ sample( comb$id, 10, prob=comb$prop ), ]



2) If you want to sample x% in each zipcode, where x is the proportion 
of women in that zipcode. Then this is what I would call stratified 
sampling. Try this:

    tmp <- split( samp, samp$zipcode )
    out <- NULL

    for( z in names(tmp) ){
       df <- tmp[[z]]
       p  <- zcta[ zcta$zipcode == z, "prop" ]
       out[[z]] <- df[ sample( 1:nrow(df), p*nrow(df) ), ]
    }
    do.call("rbind", out)

You probably need a variant of these but if you need further help, you 
will need to provide more information and better yet examples.

Regards, Adai



Kirsten Beyer wrote:
> I am interested in locating a script to implement a sampling scheme
> that would basically make it more likely that a particular observation
> is chosen based on a weight associated with the observation.  I am
> trying to select a sample of ~30 census blocks from each ZIP code area
> based on the proportion of women in a ZCTA living in a particular
> block.  I want to make it more likely that a block will be chosen if
> the proportion of women in a patient's age group in a particular block
> is high. Any ideas are appreciated!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
>


From deepayan.sarkar at gmail.com  Fri Jun 29 00:24:41 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Thu, 28 Jun 2007 15:24:41 -0700
Subject: [R] Changing graphics height when using grid and lattice
In-Reply-To: <11350733.post@talk.nabble.com>
References: <11350733.post@talk.nabble.com>
Message-ID: <eb555e660706281524g1246d44dicaf58f86dad19226@mail.gmail.com>

On 6/28/07, Jim Price <price_ja at hotmail.com> wrote:
>
> Hi,
>
> I have recently been playing with the grid package in an attempt to create
> some pages containing multiple lattice plots on the same page. However, when
> I specify a grid layout with different widths, such as:
>
> pushViewport(viewport(layout = grid.layout(1, 2, unit(c(2, 1), "null"))))
>
> the individual graphs do not end up as the same height - which is a feature
> I would prefer to have.

The default "padding" between components of a graph is defined as a
proportion of the plot area. In particular, it's unit(0.01, "snpc"),
which makes it the same on both axes. The problem is that when you
have two grid viewports, unit(0.01, "snpc") may give different
physical length.

One option is to set all paddings to 0, which can be done with

myLatticeSettings <- function()
    list(layout.heights =
         list(top.padding = 0,
              main.key.padding = 0,
              key.axis.padding = 0,
              axis.xlab.padding = 0,
              xlab.key.padding = 0,
              key.sub.padding = 0,
              bottom.padding = 0),
         layout.widths =
         list(left.padding = 0,
              key.ylab.padding = 0,
              ylab.axis.padding = 0,
              axis.key.padding = 0,
              right.padding = 0)
         )

trellis.par.set(myLatticeSettings())

This may not be what you want, so another option is to set the
paddings to something absolute; e.g.


myLatticeOptions <- function()
    list(layout.heights =
         list(top.padding = list(x = 1, units = "mm", data = NULL),
              main.key.padding = list(x = 1, units = "mm", data = NULL),
              key.axis.padding = list(x = 1, units = "mm", data = NULL),
              axis.xlab.padding = list(x = 1, units = "mm", data = NULL),
              xlab.key.padding = list(x = 1, units = "mm", data = NULL),
              key.sub.padding = list(x = 1, units = "mm", data = NULL),
              bottom.padding = list(x = 1, units = "mm", data = NULL)),
         layout.widths =
         list(left.padding = list(x = 1, units = "mm", data = NULL),
              key.ylab.padding = list(x = 1, units = "mm", data = NULL),
              ylab.axis.padding = list(x = 1, units = "mm", data = NULL),
              axis.key.padding = list(x = 1, units = "mm", data = NULL),
              right.padding = list(x = 1, units = "mm", data = NULL))
         )

lattice.options(myLatticeOptions())

I'm not particularly attached to the "snpc" solution, so I may change
them at some point.

-Deepayan


From bli1 at bcm.tmc.edu  Fri Jun 29 01:16:38 2007
From: bli1 at bcm.tmc.edu (Bingshan Li)
Date: Thu, 28 Jun 2007 18:16:38 -0500
Subject: [R] logistic regression and dummy variable coding
Message-ID: <46C063CC-95DB-4F69-9D2F-59B105AFAE3B@bcm.tmc.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070628/2759e48e/attachment.pl 

From marc_schwartz at comcast.net  Fri Jun 29 02:41:21 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Thu, 28 Jun 2007 19:41:21 -0500
Subject: [R] logistic regression and dummy variable coding
In-Reply-To: <46C063CC-95DB-4F69-9D2F-59B105AFAE3B@bcm.tmc.edu>
References: <46C063CC-95DB-4F69-9D2F-59B105AFAE3B@bcm.tmc.edu>
Message-ID: <1183077681.4242.46.camel@Bellerophon.localdomain>

On Thu, 2007-06-28 at 18:16 -0500, Bingshan Li wrote:
> Hello everyone,
> 
> I have a variable with several categories and I want to convert this  
> into dummy variables and do logistic regression on it. I used  
> model.matrix to create dummy variables but it always picked the  
> smallest one as the reference. For example,
> 
> model.matrix(~.,data=as.data.frame(letters[1:5]))
> 
> will code 'a' as '0 0 0 0'. But I want to code another category as  
> reference, say 'b'. How to do it in R using model.matrix? Is there  
> other way to do it if model.matrix  has no such functionality?
> 
> Thanks!

See ?relevel

Note that this (creating dummy variables) will be done automatically in
R's modeling functions, which default to treatment contrasts on factors.
model.matrix() is used internally by model functions such as glm().

For example using a single factor:

FL <- factor(letters[1:5])

> FL
[1] a b c d e
Levels: a b c d e

> contrasts(FL)
  b c d e
a 0 0 0 0
b 1 0 0 0
c 0 1 0 0
d 0 0 1 0
e 0 0 0 1



FL.b <- relevel(FL, "b")

> FL.b
[1] a b c d e
Levels: b a c d e

> contrasts(FL.b)
  a c d e
b 0 0 0 0
a 1 0 0 0
c 0 1 0 0
d 0 0 1 0
e 0 0 0 1



See ?contrasts and the Statistical Models section in "An Introduction to
R".

HTH,

Marc Schwartz


From srjafarzadeh at gmail.com  Fri Jun 29 02:44:37 2007
From: srjafarzadeh at gmail.com (Seyed Reza Jafarzadeh)
Date: Thu, 28 Jun 2007 17:44:37 -0700
Subject: [R] logistic regression and dummy variable coding
In-Reply-To: <46C063CC-95DB-4F69-9D2F-59B105AFAE3B@bcm.tmc.edu>
References: <46C063CC-95DB-4F69-9D2F-59B105AFAE3B@bcm.tmc.edu>
Message-ID: <83217d00706281744qacaf3c5uc3c6c43ca25fb09d@mail.gmail.com>

NewVar <- relevel( factor(OldVar), ref = "b")
should create a dummy variable, and change the reference category for the model.

Reza


On 6/28/07, Bingshan Li <bli1 at bcm.tmc.edu> wrote:
> Hello everyone,
>
> I have a variable with several categories and I want to convert this
> into dummy variables and do logistic regression on it. I used
> model.matrix to create dummy variables but it always picked the
> smallest one as the reference. For example,
>
> model.matrix(~.,data=as.data.frame(letters[1:5]))
>
> will code 'a' as '0 0 0 0'. But I want to code another category as
> reference, say 'b'. How to do it in R using model.matrix? Is there
> other way to do it if model.matrix  has no such functionality?
>
> Thanks!
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bli1 at bcm.tmc.edu  Fri Jun 29 03:00:23 2007
From: bli1 at bcm.tmc.edu (Bingshan Li)
Date: Thu, 28 Jun 2007 20:00:23 -0500
Subject: [R] logistic regression and dummy variable coding
In-Reply-To: <83217d00706281744qacaf3c5uc3c6c43ca25fb09d@mail.gmail.com>
References: <46C063CC-95DB-4F69-9D2F-59B105AFAE3B@bcm.tmc.edu>
	<83217d00706281744qacaf3c5uc3c6c43ca25fb09d@mail.gmail.com>
Message-ID: <469C5799-69C9-4E0B-ADE8-A3A647F5A0C7@bcm.tmc.edu>

Hi All,

Now it works. Thanks for all your answers and the explanations are  
very clear.

Bingshan

On Jun 28, 2007, at 7:44 PM, Seyed Reza Jafarzadeh wrote:

> NewVar <- relevel( factor(OldVar), ref = "b")
> should create a dummy variable, and change the reference category  
> for the model.
>
> Reza
>
>
> On 6/28/07, Bingshan Li <bli1 at bcm.tmc.edu> wrote:
>> Hello everyone,
>>
>> I have a variable with several categories and I want to convert this
>> into dummy variables and do logistic regression on it. I used
>> model.matrix to create dummy variables but it always picked the
>> smallest one as the reference. For example,
>>
>> model.matrix(~.,data=as.data.frame(letters[1:5]))
>>
>> will code 'a' as '0 0 0 0'. But I want to code another category as
>> reference, say 'b'. How to do it in R using model.matrix? Is there
>> other way to do it if model.matrix  has no such functionality?
>>
>> Thanks!
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting- 
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From jizhang at chori.org  Fri Jun 29 03:50:08 2007
From: jizhang at chori.org (Jiong Zhang, PhD)
Date: Thu, 28 Jun 2007 18:50:08 -0700
Subject: [R]  why this doesn't work for qqnorm
Message-ID: <255953440977a84a8058562f72dc2b08@mail.chori.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070628/3560fb39/attachment.pl 

From bcarvalh at jhsph.edu  Fri Jun 29 03:58:57 2007
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Thu, 28 Jun 2007 21:58:57 -0400
Subject: [R] why this doesn't work for qqnorm
In-Reply-To: <255953440977a84a8058562f72dc2b08@mail.chori.org>
References: <255953440977a84a8058562f72dc2b08@mail.chori.org>
Message-ID: <7C4CB15D-3BBD-4441-AE0A-F8A31C611974@jhsph.edu>

qqnorm(table[,1])

is what you want, isn't it?

and other forms would include:

par(ask=TRUE)
results = apply(table, 2, qqnorm)
par(ask=FALSE)

b

On Jun 28, 2007, at 9:50 PM, Jiong Zhang, PhD wrote:

> I want to qqnorm every column in a table.  When I try the first column
> using
>
> qqnorm(table$column1), it worked.
>
> But when I use
>
> qqnorm(table[1]), it tells me "Error in stripchart(x1, ...) : invalid
> plotting method".
>
> What happen?  How can I make a function that qqnorms every column?
>
> thanks a lot.
>
> -jiong


From s.blomberg1 at uq.edu.au  Fri Jun 29 05:05:36 2007
From: s.blomberg1 at uq.edu.au (Simon Blomberg)
Date: Fri, 29 Jun 2007 13:05:36 +1000
Subject: [R] why this doesn't work for qqnorm
In-Reply-To: <255953440977a84a8058562f72dc2b08@mail.chori.org>
References: <255953440977a84a8058562f72dc2b08@mail.chori.org>
Message-ID: <1183086336.5165.71.camel@sib-sblomber01d.sib.uq.edu.au>

You need to specify a whole column. try qqnorm(table[,1])

On Thu, 2007-06-28 at 18:50 -0700, Jiong Zhang, PhD wrote:
> I want to qqnorm every column in a table.  When I try the first column
> using
> 
> qqnorm(table$column1), it worked.
> 
> But when I use
> 
> qqnorm(table[1]), it tells me "Error in stripchart(x1, ...) : invalid
> plotting method".
> 
> What happen?  How can I make a function that qqnorms every column?

Try this:

dat <- data.frame(x=rnorm(20), y= rnorm(20), z =rnorm(20))
par(mfrow=c(3,1))
sapply(dat, function (x) {qqnorm (x) ; qqline (x) } )

Cheers,

Simon
> 
> thanks a lot.
> 
> -jiong
>  The email message (and any attachments) is for the sole use of the intended recipient(s) and may contain confidential information.  Any unauthorized review, use, disclosure or distribution is prohibited.  If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message (and any attachments).  Thank You.
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
-- 
Simon Blomberg, BSc (Hons), PhD, MAppStat. 
Lecturer and Consultant Statistician 
Faculty of Biological and Chemical Sciences 
The University of Queensland 
St. Lucia Queensland 4072 
Australia

Room 320, Goddard Building (8)
T: +61 7 3365 2506 
email: S.Blomberg1_at_uq.edu.au 

The combination of some data and an aching desire for 
an answer does not ensure that a reasonable answer can 
be extracted from a given body of data. - John Tukey.


From amirhendi at yahoo.com  Fri Jun 29 07:04:57 2007
From: amirhendi at yahoo.com (Amir_17)
Date: Thu, 28 Jun 2007 22:04:57 -0700 (PDT)
Subject: [R] How can i compute error
Message-ID: <892067.74698.qm@web37904.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070628/f2e1729c/attachment.pl 

From sell_mirage_ne at hotmail.com  Fri Jun 29 07:21:55 2007
From: sell_mirage_ne at hotmail.com (Taka Matzmoto)
Date: Fri, 29 Jun 2007 00:21:55 -0500
Subject: [R] extracting df and MS values from aov
Message-ID: <BAY135-F2482060D9F6557D933551AC7080@phx.gbl>

Dear R users,
I would like to extract df and Mean Sq values. I tried several things (e.g., 
str(model1), names(model1)) but I can't find a way to extract these values.  
I also tried to search using
RSiteSearch. Any help will be appreciated. Thanks Taka,

model1<-aov(dv~iv.1*iv.2*iv.3)

summary(model1)

                           Df Sum Sq Mean Sq
iv.1                   1  3.200   3.200
iv.2                   9 62.200   6.911
iv.3                   3 37.450  12.483
iv.1:iv.2             9 12.050   1.339
iv.1:iv.3             3  7.500   2.500
iv.2:iv.3            27 56.300   2.085
iv.1:iv.2:iv.3      27 25.250   0.935

_________________________________________________________________
PC Magazine?s 2007 editors? choice for best Web mail?award-winning Windows 
Live Hotmail.


From mildenbe at statistik.uni-dortmund.de  Thu Jun 28 15:26:28 2007
From: mildenbe at statistik.uni-dortmund.de (Thoralf Mildenberger)
Date: Thu, 28 Jun 2007 15:26:28 +0200
Subject: [R] [R-pkgs] new package benchden 1.0.0 : benchmark densities for
 nonparametric density estimation
Message-ID: <4683B704.50406@statistik.uni-dortmund.de>

The new package "benchden" 1.0.0 implements 28 benchmark densities for
nonparametric density estimation that were introduced by A. Berlinet and
L. Devroye ("A Comparison of Kernel Density Estimates", Pub. Inst. Stat.
Univ. Paris, XXXVIII, fasc. 3, 1994, 3-59,
http://cg.scs.carleton.ca/~luc/devs.html ). This collection includes a
variety of densities with different degrees of smoothness, different
tail behaviour, different number of modes, with and without infinite 
peaks and also some standard densities like the normal and the uniform. 
There is also a small intersection (e.g. the claw density) with the 
collection of normal mixtures introduced by Marron and Wand and 
implemented in R in the package "nor1mix".
Similar to the test bed functions by Donoho and Johnstone (Blocks, Bumps
etc.) commonly used in regression or the "Peppers" and "Lena" images
popular in image analysis, the densities in this collection should be 
useful for testing and comparing new and existing density estimators.
"benchden" 1.0.0 contains functions for the generation of random
variates as well as density-, distribution- and quantile-functions.
Everything is implemented in typical R-style and the package should
reduce the programming effort needed for simulation studies in
nonparametric density estimation. It also allows for better
reproducibility of the results.

Thoralf Mildenberger, Henrike Weinert and Sebastian Tiemeyer

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages


From rxzhu at scbit.org  Fri Jun 29 08:39:12 2007
From: rxzhu at scbit.org (Ruixin ZHU)
Date: Fri, 29 Jun 2007 14:39:12 +0800
Subject: [R] How to install R 2.5 with Synaptic in Ubuntu?
Message-ID: <1183099152.5873.5.camel@zhurx-desktop>

Dear R-users,

I'm using Ubuntu dapper, which only have R of Version 2.2.1.

Would anybody tell me how to install the latest version of R with 

Synaptic in Ubuntu dapper system.

Thanks!


From p.dalgaard at biostat.ku.dk  Fri Jun 29 08:46:50 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 29 Jun 2007 08:46:50 +0200
Subject: [R] exaustive subgrouping or combination
In-Reply-To: <Pine.LNX.4.64.0706290757300.25798@orpheus.qimr.edu.au>
References: <mailman.13.1183024805.4590.r-help@stat.math.ethz.ch>
	<Pine.LNX.4.64.0706290757300.25798@orpheus.qimr.edu.au>
Message-ID: <4684AADA.5030609@biostat.ku.dk>

David Duffy wrote:
>> Waverley <waverley.paloalto at gmail.com> asked:
>>
>> Dear Colleagues,
>>
>> I am looking for a package or previous implemented R to subgroup and
>> exaustively divide a vector of squence into 2 groups.
>>
>> -- 
>> Waverley @ Palo Alto
>>     
>
> Google "[R] Generating all possible partitions" and you will find some R code
> from 2002 or so.
>
>   
In 2002 this wasn't already in R. These days, help(combn) is more to the 
point:

 mn <- sort(zapsmall(combn(sleep$extra,10,mean)))
 plot(unique(mn),table(mn))
 abline(v=mean(sleep$extra[1:10]))


From mmeredith at wcs.org  Fri Jun 29 08:48:35 2007
From: mmeredith at wcs.org (Mike Meredith)
Date: Thu, 28 Jun 2007 23:48:35 -0700 (PDT)
Subject: [R] using self-written functions
In-Reply-To: <1183030481.9413.17.camel@gsimpson.geog.ucl.ac.uk>
References: <105933.73372.qm@web63915.mail.re1.yahoo.com>
	<1183030481.9413.17.camel@gsimpson.geog.ucl.ac.uk>
Message-ID: <11355842.post@talk.nabble.com>


I use something like Gavin's solution for functions which are not used too
often. The problem with using 'source' is that the user environment gets
cluttered.

I 'save' the most useful functions to a single file ("MMmisc.Rda"), put it
in the HOMEPATH directory (use Sys.getenv("HOMEPATH") to find where that
is), then I put the line

attach(what=paste(Sys.getenv("HOMEPATH"), "MMmisc.Rda", sep="/"))

in Rprofile.site in C:\Program Files\R\R-2.5.0\etc folder.

Works for me! You don't have the luxury of help files, etc, but it's easy to
update.

HTH -- Mike.


Gavin Simpson wrote:
> 
> On Thu, 2007-06-28 at 17:29 +0800, R. Leenders wrote:
>> ... How can
>> I access my own functions in R without having to copy-paste them
>> everytime and run them manually so I can call them later? Do I need to
>> learn how to write a package and attach the package to make the
>> functions available at all times? Is there another way?
> 
> Building a package is one way, and not that difficult once you've read
> the Writing R Extensions manual.
> 
> An alternative is to have a directory where you keep R function scripts.
> Put your functions in here in text files with say a .R extension. Then
> in R you can source one or more of these R scripts as required, using
> the source() function.
> 
> Say you have a directory, myScripts at the base of file system
> (/home/user say on Linux or C:\ on Windows). in this directory there is
> a file called my_r_function.R. To use this script/function in an R
> session, you would issue:
> 
> ## replace /home/user/ with what ever is the correct path for your
> ## system
> source("/home/user/myScripts/my_r_function.R")
> 
> Which would make available to your current session any functions defined
> in my_r_function.R.
> 
> Read ?source for more information.
> 
> HTH
> 
> G
> 
>> 
>> thanks, James
>> 
>> 
>> 
>> 
>>        
>> ____________________________________________________________________________________
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> -- 
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
>  Gavin Simpson                 [t] +44 (0)20 7679 0522
>  ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
>  Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
>  Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
>  UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/using-self-written-functions-tf3993814.html#a11355842
Sent from the R help mailing list archive at Nabble.com.


From maechler at stat.math.ethz.ch  Fri Jun 29 08:50:35 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 29 Jun 2007 08:50:35 +0200
Subject: [R] align() function missing in R ?
In-Reply-To: <200706281511.l5SFBlat007218@hypatia.math.ethz.ch>
References: <200706281511.l5SFBlat007218@hypatia.math.ethz.ch>
Message-ID: <18052.43963.748646.703108@stat.math.ethz.ch>

Hi Markus,

You can't assume that a typical R users knows much about S+.
"R has been beyond S+ for a long time"  
   {{ :-) :-) please Insightful staff, don't start to jump at me !}}
Even I, as a very long time S and Splus user (of the past: 
1987--~1997), have never, I think, used align().

Can you give *reproducible examples* of what  align() does for you?
Then, kind R users will typically show you simple ways to achieve the
same.

Also: R is Free Software (i.e. open source and more), so
      we'd be happy to accept offers of an align() function that
      behaved compatibly (``or better'') than the S-plus one.
Note however that you'd typically not be allowed to copy the
S-plus implementation.

Martin


>>>>> "ML" == Markus Loecher <markus at insightfromdata.com>
>>>>>     on Thu, 28 Jun 2007 11:10:51 -0400 writes:

    ML> Dear list members, I switched from Splus to R a few
    ML> years ago and so far found no functionality missing.
    ML> However, I am struggling to find the equivalent align()
    ML> function for time series. I did find some reduced
    ML> functionality such as alignDailySeries in
    ML> package:fCalendar but the full capability of aligning
    ML> two timeseries seems to be missing.  Could this be true
    ML> ? I am sure there must be a need for this useful
    ML> function.  Any help would be greatly appreciated.

    ML> Thanks !

    ML> Markus


From bcarvalh at jhsph.edu  Fri Jun 29 09:14:12 2007
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Fri, 29 Jun 2007 03:14:12 -0400
Subject: [R] Comparison: glm() vs. bigglm()
Message-ID: <2FAF9CA2-DAC4-4610-AFE6-90E495656FA5@jhsph.edu>

Hi,

Until now, I thought that the results of glm() and bigglm() would  
coincide. Probably a naive assumption?

Anyways, I've been using bigglm() on some datasets I have available.  
One of the sets has >15M observations.

I have 3 continuous predictors (A, B, C) and a binary outcome (Y).  
And tried the following:

m1 <- bigglm(Y~A+B+C, family=binomial(), data=dataset1, chunksize=10e6)
m2 <- bigglm(Y~A*B+C, family=binomial(), data=dataset1, chunksize=10e6)
imp <- m1$deviance-m2$deviance

For my surprise "imp" was negative.

I then tried the same models, using glm() instead... and as I  
expected, "imp" was positive.

I also noticed differences on the coefficients estimated by glm() and  
bigglm() - small differences, though, and CIs for the coefficients (a  
given coefficient compared across methods) overlap.

Are such incrongruences expected? What can I use to check for  
convergence with bigglm(), as this might be one plausible cause for a  
negative difference on the deviances?

Thank you very much,

-benilton

 > sessionInfo()
R version 2.5.0 (2007-04-23)
x86_64-unknown-linux-gnu

locale:
LC_CTYPE=en_US.iso885915;LC_NUMERIC=C;LC_TIME=en_US.iso885915;LC_COLLATE 
=en_US.iso885915;LC_MONETARY=en_US.iso885915;LC_MESSAGES=en_US.iso885915 
;LC_PAPER=en_US.iso885915;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASU 
REMENT=en_US.iso885915;LC_IDENTIFICATION=C

attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets"   
"methods"
[7] "base"

other attached packages:
biglm
"0.4"


From stefan.grosse at gmx.net  Fri Jun 29 09:29:23 2007
From: stefan.grosse at gmx.net (=?iso-8859-1?Q?=22Stefan_Gro=DFe=22?=)
Date: Fri, 29 Jun 2007 09:29:23 +0200
Subject: [R] How to install R 2.5 with Synaptic in Ubuntu?
Message-ID: <20070629072923.172990@gmx.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070629/6145d806/attachment.pl 

From ripley at stats.ox.ac.uk  Fri Jun 29 09:38:55 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 29 Jun 2007 08:38:55 +0100 (BST)
Subject: [R] using self-written functions
In-Reply-To: <11355842.post@talk.nabble.com>
References: <105933.73372.qm@web63915.mail.re1.yahoo.com>
	<1183030481.9413.17.camel@gsimpson.geog.ucl.ac.uk>
	<11355842.post@talk.nabble.com>
Message-ID: <Pine.LNX.4.64.0706290832330.1099@gannet.stats.ox.ac.uk>

One of your home directories on Windows is %HOMEDRIVE%%HOMEPATH% (you do 
need to give the drive), but only one: see the rw-FAQ.

Reading ?file.path will help you not reinvent the wheel.

So I think attach(path.expand("~/MMmisc.rda") is far more portable (as 
well as much more readable).

On Thu, 28 Jun 2007, Mike Meredith wrote:

> I use something like Gavin's solution for functions which are not used too
> often. The problem with using 'source' is that the user environment gets
> cluttered.
>
> I 'save' the most useful functions to a single file ("MMmisc.Rda"), put it
> in the HOMEPATH directory (use Sys.getenv("HOMEPATH") to find where that
> is), then I put the line
>
> attach(what=paste(Sys.getenv("HOMEPATH"), "MMmisc.Rda", sep="/"))
>
> in Rprofile.site in C:\Program Files\R\R-2.5.0\etc folder.

Please don't recommend site-wide setting for user settings, which should 
be in ~/.Rprofile.  See ?Startup.

>
> Works for me! You don't have the luxury of help files, etc, but it's easy to
> update.
>
> HTH -- Mike.
>
>
> Gavin Simpson wrote:
>>
>> On Thu, 2007-06-28 at 17:29 +0800, R. Leenders wrote:
>>> ... How can
>>> I access my own functions in R without having to copy-paste them
>>> everytime and run them manually so I can call them later? Do I need to
>>> learn how to write a package and attach the package to make the
>>> functions available at all times? Is there another way?
>>
>> Building a package is one way, and not that difficult once you've read
>> the Writing R Extensions manual.
>>
>> An alternative is to have a directory where you keep R function scripts.
>> Put your functions in here in text files with say a .R extension. Then
>> in R you can source one or more of these R scripts as required, using
>> the source() function.
>>
>> Say you have a directory, myScripts at the base of file system
>> (/home/user say on Linux or C:\ on Windows). in this directory there is
>> a file called my_r_function.R. To use this script/function in an R
>> session, you would issue:
>>
>> ## replace /home/user/ with what ever is the correct path for your
>> ## system
>> source("/home/user/myScripts/my_r_function.R")
>>
>> Which would make available to your current session any functions defined
>> in my_r_function.R.
>>
>> Read ?source for more information.
>>
>> HTH
>>
>> G
>>
>>>
>>> thanks, James
>>>
>>>
>>>
>>>
>>>
>>> ____________________________________________________________________________________
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> --
>> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
>>  Gavin Simpson                 [t] +44 (0)20 7679 0522
>>  ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
>>  Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
>>  Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
>>  UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
>> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri Jun 29 09:52:17 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 29 Jun 2007 08:52:17 +0100 (BST)
Subject: [R] align() function missing in R ?
In-Reply-To: <18052.43963.748646.703108@stat.math.ethz.ch>
References: <200706281511.l5SFBlat007218@hypatia.math.ethz.ch>
	<18052.43963.748646.703108@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.64.0706290840510.1099@gannet.stats.ox.ac.uk>

On Fri, 29 Jun 2007, Martin Maechler wrote:

> Hi Markus,
>
> You can't assume that a typical R users knows much about S+.
> "R has been beyond S+ for a long time"
>   {{ :-) :-) please Insightful staff, don't start to jump at me !}}
> Even I, as a very long time S and Splus user (of the past:
> 1987--~1997), have never, I think, used align().
>
> Can you give *reproducible examples* of what  align() does for you?
> Then, kind R users will typically show you simple ways to achieve the
> same.
>
> Also: R is Free Software (i.e. open source and more), so
>      we'd be happy to accept offers of an align() function that
>      behaved compatibly (``or better'') than the S-plus one.
> Note however that you'd typically not be allowed to copy the
> S-plus implementation.

align() relates to the S4 time series classes introduced in S-PLUS 5 (or 
so, after 1997).  There are no comparable classes in base R, but there are 
in some of the addon packages - fCalendar has already been mentioned and 
there are others (see the CRAN Econometric task view).

window, ts.union and ts.intersect have done all the alignment on regular 
time series (class "ts") I have ever needed.

>
> Martin
>
>
>>>>>> "ML" == Markus Loecher <markus at insightfromdata.com>
>>>>>>     on Thu, 28 Jun 2007 11:10:51 -0400 writes:
>
>    ML> Dear list members, I switched from Splus to R a few
>    ML> years ago and so far found no functionality missing.
>    ML> However, I am struggling to find the equivalent align()
>    ML> function for time series. I did find some reduced
>    ML> functionality such as alignDailySeries in
>    ML> package:fCalendar but the full capability of aligning
>    ML> two timeseries seems to be missing.  Could this be true
>    ML> ? I am sure there must be a need for this useful
>    ML> function.  Any help would be greatly appreciated.
>
>    ML> Thanks !
>
>    ML> Markus
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri Jun 29 10:20:18 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 29 Jun 2007 09:20:18 +0100 (BST)
Subject: [R] embedFonts() and bounding box
In-Reply-To: <18051.53737.967004.143133@stat.math.ethz.ch>
References: <18051.53737.967004.143133@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.64.0706281801050.13288@gannet.stats.ox.ac.uk>

As embedFonts creates a new file, the bounding box of the original one is 
not relevant.  (Yes, outfile = file by default, but it is still a new 
file.)

I guess the switches

     -dDEVICEWIDTHPOINTS=w -dDEVICEHEIGHTPOINTS=h

might help to create the new file with the bounding box you want.

On Thu, 28 Jun 2007, Christoph Buser wrote:

> Dear R gurus
>
> I have a question regarding the function embedFonts().
> I assume the in that function which calls gs, the bounding box
> of the eps file is changed. Is that by intention? Do I have
> call explicitly some gs-options to avoid it and if yes, how?
> Thank you very much for your help.
>
> Best regards,
>
> Christoph Buser
>
> ## R example
> postscript("test.eps", width = 14, height = 8,
>         onefile = FALSE, horizontal=FALSE, paper="special")
> plot(1:10)
> dev.off()
> embedFonts(file = "test.eps", outfile = "test1.eps")
>
>
> --------------------------------------------------------------
> Christoph Buser <buser at stat.math.ethz.ch>
> Seminar fuer Statistik, LEO C13
> ETH Zurich	8092 Zurich	 SWITZERLAND
> phone: x-41-44-632-4673		fax: 632-1228
> http://stat.ethz.ch/~buser/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From dray at biomserv.univ-lyon1.fr  Fri Jun 29 10:21:00 2007
From: dray at biomserv.univ-lyon1.fr (=?ISO-8859-1?Q?St=E9phane_Dray?=)
Date: Fri, 29 Jun 2007 10:21:00 +0200
Subject: [R] acf and na.pass
Message-ID: <4684C0EC.7050801@biomserv.univ-lyon1.fr>

Hello,
I would like to have some information about acf with missing values.
Let us consider this example:
x=rnorm(100)
x2=x
x2[sample(100,10)]=NA
acf1=acf(x)
acf2=acf(x2,na.action=na.pass)

The computation of the acf is different for the two data sets. Looking 
at the the code reveals that with missing values, the computation of acf 
takes into account the number of pairs of non-NA values (i.e. the number 
of pairs of data that are used to compute the acf, and this number is 
different for each lag). This makes sense for me. Where I have more 
problems, concern the computation of confidence intervall. Here, the 
plot.acf function compute the values using x$n.used, which is equal for 
these two cases to 100. Is there some explanation for this choice ?  I 
would think that the computation of CI would also take into account the 
number of pairs of non-NA values. Is there some references on the topic ?

Thanks in advance,
Sincerely.


-- 
St?phane DRAY (dray at biomserv.univ-lyon1.fr )
Laboratoire BBE-CNRS-UMR-5558, Univ. C. Bernard - Lyon I
43, Bd du 11 Novembre 1918, 69622 Villeurbanne Cedex, France
Tel: 33 4 72 43 27 57       Fax: 33 4 72 43 13 88
http://biomserv.univ-lyon1.fr/~dray/


From bioinfonews at pt.lu  Fri Jun 29 10:43:12 2007
From: bioinfonews at pt.lu (bioinfonews at pt.lu)
Date: Fri, 29 Jun 2007 10:43:12 +0200
Subject: [R] How to add elements to a table
Message-ID: <20070629104312.nq1xs68cu8k04ows@webmail.pt.lu>

Hi,

I've been using R for a few weeks now, but consider myself still a  
newbie, especially in what concerns the basics of data handling in R.

My situation is this:
I read in data from a database using RODBC, and then use "table" to  
produce a table of "counts per years", table which I give to "plot".  
All is well, as long as there are no gaps in the years sequence, but  
now I have the following result (example):

1990 20
1991 15
1995 17
1997  9
1998 10
1999 11
2000  5

The "plot" function is quite intelligent, in the sense that it draws  
appropriate gaps in the x-axis between years, but not intelligent  
enough to interrupt the data line during the gap. This gives the  
impression that, although no year is marked on the x-axis between 1991  
and 1995, there has been data for this period, which is not correct.

What I tried to do is convert the table to a matrix, insert zeros for  
the missing years using rbind and cbind, and convert the result back  
to table. But the structure of this resulting table is not the same as  
for the originating table, so that I need to pass "tab[1,]" to "plot".  
It's no longer a contingency table in fact.

I've seen in the mailing list archives that there is an issue on using  
"table"s when matrixes or other structures would be more appropriate.

I like the "table", because "plot" automatically plots the  
corresponding years on the x-axis, which I find less error-prone than  
adding the tick labels later by hand, i.e. the association between  
years and counts is stronger.

Also, as I tabulate counts of cases per gender, or per age categories,  
I think a contingency table is the right thing to use, isn't it?

I'd be glad on any advice about what would be the best data structure  
to handle my situation, and I'd also like to know how I could  
automagically check a list of "year, cases" rows against a fixed list  
of years, insert zero or "NA" values for missing years, and get an  
easily usable result that I can forward to "plot" or "barplot".

Thanks a lot in advance,

Anne-Marie


From pmilin at ff.ns.ac.yu  Fri Jun 29 11:05:38 2007
From: pmilin at ff.ns.ac.yu (Petar Milin)
Date: Fri, 29 Jun 2007 11:05:38 +0200
Subject: [R] Warning message in Design ...
Message-ID: <1183107938.15290.16.camel@localhost>

Hello!
There were some questions regarding warning messages in Design library,
but no answer how to fix them. What about:

"use of storage.mode(x) <- "single" is deprecated: use mode<- instead"

What does it mean? How to use properly simple model like:

m1 = ols(Y ~ A + B + C, data = someData)

After specifying the model above, warning message to use "mode(x)"
instead of "storage.mode(x)" appears.

Best,
PM


From Jacques.Veslot at avignon.inra.fr  Fri Jun 29 11:11:47 2007
From: Jacques.Veslot at avignon.inra.fr (Jacques VESLOT)
Date: Fri, 29 Jun 2007 11:11:47 +0200
Subject: [R] How to add elements to a table
In-Reply-To: <20070629104312.nq1xs68cu8k04ows@webmail.pt.lu>
References: <20070629104312.nq1xs68cu8k04ows@webmail.pt.lu>
Message-ID: <4684CCD3.1030204@avignon.inra.fr>

 > z <- read.table("clipboard")
 > z
    V1 V2
1 1990 20
2 1991 15
3 1995 17
4 1997  9
5 1998 10
6 1999 11
7 2000  5
 > zz <- merge(data.frame(V1=1990:2000), z, by="V1", all.x=T)
 > plot(zz, type="l")

Jacques VESLOT

INRA - Biostatistique & Processus Spatiaux
Site Agroparc 84914 Avignon Cedex 9, France

Tel: +33 (0) 4 32 72 21 58
Fax: +33 (0) 4 32 72 21 84



bioinfonews at pt.lu a ?crit :
> Hi,
>
> I've been using R for a few weeks now, but consider myself still a  
> newbie, especially in what concerns the basics of data handling in R.
>
> My situation is this:
> I read in data from a database using RODBC, and then use "table" to  
> produce a table of "counts per years", table which I give to "plot".  
> All is well, as long as there are no gaps in the years sequence, but  
> now I have the following result (example):
>
> 1990 20
> 1991 15
> 1995 17
> 1997  9
> 1998 10
> 1999 11
> 2000  5
>
> The "plot" function is quite intelligent, in the sense that it draws  
> appropriate gaps in the x-axis between years, but not intelligent  
> enough to interrupt the data line during the gap. This gives the  
> impression that, although no year is marked on the x-axis between 1991  
> and 1995, there has been data for this period, which is not correct.
>
> What I tried to do is convert the table to a matrix, insert zeros for  
> the missing years using rbind and cbind, and convert the result back  
> to table. But the structure of this resulting table is not the same as  
> for the originating table, so that I need to pass "tab[1,]" to "plot".  
> It's no longer a contingency table in fact.
>
> I've seen in the mailing list archives that there is an issue on using  
> "table"s when matrixes or other structures would be more appropriate.
>
> I like the "table", because "plot" automatically plots the  
> corresponding years on the x-axis, which I find less error-prone than  
> adding the tick labels later by hand, i.e. the association between  
> years and counts is stronger.
>
> Also, as I tabulate counts of cases per gender, or per age categories,  
> I think a contingency table is the right thing to use, isn't it?
>
> I'd be glad on any advice about what would be the best data structure  
> to handle my situation, and I'd also like to know how I could  
> automagically check a list of "year, cases" rows against a fixed list  
> of years, insert zero or "NA" values for missing years, and get an  
> easily usable result that I can forward to "plot" or "barplot".
>
> Thanks a lot in advance,
>
> Anne-Marie
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From petr.pikal at precheza.cz  Fri Jun 29 11:10:34 2007
From: petr.pikal at precheza.cz (Petr PIKAL)
Date: Fri, 29 Jun 2007 11:10:34 +0200
Subject: [R] "no applicable method"
In-Reply-To: <CC6EFC32-9919-4F1F-97D1-C7EA38F27489@csbl.bmb.uga.edu>
Message-ID: <OFA64395C6.246D2B02-ONC1257309.00320FDA-C1257309.00326858@precheza.cz>

Hi

>From help page

A data frame is a list of variables of the same length with unique row 
names, given class "data.frame". 

so something completely different from matrix (which is AFAIK a vector 
with dimensions attribute). Therefore  matrix needs to have all its values 
of the same type (numeric, character) but in data framwe you can mix 
columns with different types.

Regards

Petr Pikal
petr.pikal at precheza.cz

r-help-bounces at stat.math.ethz.ch napsal dne 28.06.2007 20:12:49:

> You actually got it right.
> I didn't realize there was a difference between a data frame and 
> matrix.  What is the difference any way?  Seems like all two 
> dimensional arrays should be equivalent.
> 
> Kyle
> 
> 
> 
> > On Wed, 27 Jun 2007, Kyle Ellrott wrote:
> >
> >> I'm getting started in R, and I'm trying to use one of the gradient
> >> boosting packages, mboost.  I'm already installed the package with
> >> install.packages("mboost") and loaded it with library(mboost).
> >> My problem is that when I attempt to call glmboost, I get a message
> >> that " Error in glmboost() : no applicable method for "glmboost" ".
> >> Does anybody have an idea of what kind of problem this is 
> >> indicative of?
> >
> > The wrong class of input object 'x'.  The help page for glmboost is 
> > written obscurely, but it seems to imply that it has methods for 
> > 'formula' and 'matrix'.
> >
> > Perhaps you passed a data frame?
> >
> >> PLEASE do read the posting guide http://www.R-project.org/posting- 
> >> guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > is pertinent.  With an example and its output we would have been 
> > much better placed to help you.
> >
> > -- 
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From max.e.brown at gmail.com  Fri Jun 29 11:16:59 2007
From: max.e.brown at gmail.com (max.e.brown at gmail.com)
Date: Fri, 29 Jun 2007 11:16:59 +0200
Subject: [R] Problem with library(CarbonEL) in .Rprofile
Message-ID: <m24pkrm86s.fsf@gmail.com>


Hello,

I am a Mac user and prefer the quartz device. So far, I have always
typed the following in manually after starting R via ESS:

library(CarbonEL)
options(device="quartz")

That works without problems, and allows me to use the quartz device
instead of X11.

I put this into my .Rprofile, thinking that this way I don't have to
type this every time I start R. Once I do this (there is nothing else
in the .Rprofile), I get the following error, though:

Error in dyn.load(x, as.logical(local), as.logical(now)) : 
	unable to load shared library '/Library/Frameworks/R.framework/Resources/library/CarbonEL/libs/ppc/CarbonEL.so':
  dlopen(/Library/Frameworks/R.framework/Resources/library/CarbonEL/libs/ppc/CarbonEL.so, 6): Symbol not found: _TransformProcessType
  Referenced from: /Library/Frameworks/R.framework/Resources/library/CarbonEL/libs/ppc/CarbonEL.so
  Expected in: flat namespace
Error in library(CarbonEL) : .First.lib failed for 'CarbonEL'

What do I need to do to get this to work?

Thanks.

Max

Mac OS X 10.4.10
R 2.3.1
CarbonEL 0.1-3


From bioinfonews at pt.lu  Fri Jun 29 11:23:55 2007
From: bioinfonews at pt.lu (bioinfonews at pt.lu)
Date: Fri, 29 Jun 2007 11:23:55 +0200
Subject: [R] How to add elements to a table
In-Reply-To: <4684CCD3.1030204@avignon.inra.fr>
References: <20070629104312.nq1xs68cu8k04ows@webmail.pt.lu>
	<4684CCD3.1030204@avignon.inra.fr>
Message-ID: <20070629112355.6u6czn66kg4s8ggk@webmail.pt.lu>

Thanks a lot! Wow, I know why I love R, things are so incredibly easy  
with R (once you know how ;-) )

Moreover I've found messages in the archive showing how to make plot  
draw as many ticks as I've got years, so everything is OK.

Thanks for the help,

Anne-Marie


Quoting Jacques VESLOT <Jacques.Veslot at avignon.inra.fr>:

>> z <- read.table("clipboard")
>> z
>    V1 V2
> 1 1990 20
> 2 1991 15
> 3 1995 17
> 4 1997  9
> 5 1998 10
> 6 1999 11
> 7 2000  5
>> zz <- merge(data.frame(V1=1990:2000), z, by="V1", all.x=T)
>> plot(zz, type="l")
>
> Jacques VESLOT
>
> INRA - Biostatistique & Processus Spatiaux
> Site Agroparc 84914 Avignon Cedex 9, France
>
> Tel: +33 (0) 4 32 72 21 58
> Fax: +33 (0) 4 32 72 21 84
>
>
>
> bioinfonews at pt.lu a ?crit :
>> Hi,
>>
>> I've been using R for a few weeks now, but consider myself still a   
>>  newbie, especially in what concerns the basics of data handling in  
>> R.
>>
>> My situation is this:
>> I read in data from a database using RODBC, and then use "table" to  
>>   produce a table of "counts per years", table which I give to   
>> "plot".  All is well, as long as there are no gaps in the years   
>> sequence, but  now I have the following result (example):
>>
>> 1990 20
>> 1991 15
>> 1995 17
>> 1997  9
>> 1998 10
>> 1999 11
>> 2000  5
>>
>> The "plot" function is quite intelligent, in the sense that it   
>> draws  appropriate gaps in the x-axis between years, but not   
>> intelligent  enough to interrupt the data line during the gap. This  
>>  gives the  impression that, although no year is marked on the   
>> x-axis between 1991 and 1995, there has been data for this period,   
>> which is not correct.
>>
>> What I tried to do is convert the table to a matrix, insert zeros   
>> for  the missing years using rbind and cbind, and convert the   
>> result back  to table. But the structure of this resulting table is  
>>  not the same as for the originating table, so that I need to pass   
>> "tab[1,]" to "plot".  It's no longer a contingency table in fact.
>>
>> I've seen in the mailing list archives that there is an issue on   
>> using "table"s when matrixes or other structures would be more   
>> appropriate.
>>
>> I like the "table", because "plot" automatically plots the    
>> corresponding years on the x-axis, which I find less error-prone   
>> than  adding the tick labels later by hand, i.e. the association   
>> between  years and counts is stronger.
>>
>> Also, as I tabulate counts of cases per gender, or per age   
>> categories, I think a contingency table is the right thing to use,   
>> isn't it?
>>
>> I'd be glad on any advice about what would be the best data   
>> structure  to handle my situation, and I'd also like to know how I   
>> could  automagically check a list of "year, cases" rows against a   
>> fixed list  of years, insert zero or "NA" values for missing years,  
>>  and get an  easily usable result that I can forward to "plot" or   
>> "barplot".
>>
>> Thanks a lot in advance,
>>
>> Anne-Marie
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From Dietrich.Trenkler at uni-osnabrueck.de  Fri Jun 29 11:26:17 2007
From: Dietrich.Trenkler at uni-osnabrueck.de (Dietrich Trenkler)
Date: Fri, 29 Jun 2007 11:26:17 +0200
Subject: [R] \include-mechanism in Sweave?
Message-ID: <4684D039.2010302@uni-osnabrueck.de>

Dear HelpeRs,

I'm very fond of Sweave and I use it as often as possible.  It'a a pity
I can't use it for larger projects or can I?

For instance suppose I have three files file1.rnw, file2.rnw and
file3.rnw with Sweave code.  Working on file2.rnw I whould like to
exclude file1.rnw and file3.rnw temporarily and joining all of them
later.  This amounts to a mechanism similar to using LaTeX's \include
command.  *Is* there a way to achieve that?

Thank you in advance.

D. Trenkler                

-- 
Dietrich Trenkler c/o Universitaet Osnabrueck 
Rolandstr. 8; D-49069 Osnabrueck, Germany    
email: Dietrich.Trenkler at Uni-Osnabrueck.de


From tobias.verbeke at businessdecision.com  Fri Jun 29 11:54:09 2007
From: tobias.verbeke at businessdecision.com (Tobias Verbeke)
Date: Fri, 29 Jun 2007 11:54:09 +0200
Subject: [R] \include-mechanism in Sweave?
In-Reply-To: <4684D039.2010302@uni-osnabrueck.de>
References: <4684D039.2010302@uni-osnabrueck.de>
Message-ID: <4684D6C1.4090300@businessdecision.com>

Dietrich Trenkler wrote:
> Dear HelpeRs,
> 
> I'm very fond of Sweave and I use it as often as possible.  It'a a pity
> I can't use it for larger projects or can I?
> 
> For instance suppose I have three files file1.rnw, file2.rnw and
> file3.rnw with Sweave code.  Working on file2.rnw I whould like to
> exclude file1.rnw and file3.rnw temporarily and joining all of them
> later.  This amounts to a mechanism similar to using LaTeX's \include
> command.  *Is* there a way to achieve that?


\SweaveInclude{} lets you do just that.

HTH,
Tobias

-- 

Tobias Verbeke - Consultant
Business & Decision Benelux
Rue de la r?volution 8
1000 Brussels - BELGIUM

+32 499 36 33 15
tobias.verbeke at businessdecision.com


From tobias.verbeke at businessdecision.com  Fri Jun 29 11:55:10 2007
From: tobias.verbeke at businessdecision.com (Tobias Verbeke)
Date: Fri, 29 Jun 2007 11:55:10 +0200
Subject: [R] \include-mechanism in Sweave?
In-Reply-To: <4684D6C1.4090300@businessdecision.com>
References: <4684D039.2010302@uni-osnabrueck.de>
	<4684D6C1.4090300@businessdecision.com>
Message-ID: <4684D6FE.9080901@businessdecision.com>

Tobias Verbeke wrote:
> Dietrich Trenkler wrote:
>> Dear HelpeRs,
>>
>> I'm very fond of Sweave and I use it as often as possible.  It'a a pity
>> I can't use it for larger projects or can I?
>>
>> For instance suppose I have three files file1.rnw, file2.rnw and
>> file3.rnw with Sweave code.  Working on file2.rnw I whould like to
>> exclude file1.rnw and file3.rnw temporarily and joining all of them
>> later.  This amounts to a mechanism similar to using LaTeX's \include
>> command.  *Is* there a way to achieve that?
> 
> 
> \SweaveInclude{} lets you do just that.

Oops. \SweaveInput{}

Sorry,
Tobias

-- 

Tobias Verbeke - Consultant
Business & Decision Benelux
Rue de la r?volution 8
1000 Brussels - BELGIUM

+32 499 36 33 15
tobias.verbeke at businessdecision.com


From jim at bitwrit.com.au  Thu Jun 28 13:01:03 2007
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 28 Jun 2007 21:01:03 +1000
Subject: [R] Repeat if
In-Reply-To: <C7B7CCEB-9193-40ED-850F-0385F9C3BB5B@systbot.uzh.ch>
References: <C7B7CCEB-9193-40ED-850F-0385F9C3BB5B@systbot.uzh.ch>
Message-ID: <468394EF.50704@bitwrit.com.au>

Birgit Lemcke wrote:
> Hello,
> (Power Book G4, Mac OS X, R 2.5.0)
> 
> I would like to repeat the function range for 85 Vectors (V1-V85).
> I tried with this code:
> 
> i<-0
>  > repeat {
> + i<-i+1
> + if (i<85) next
> + range (Vi, na.rm = TRUE)
> + if (i==85) break
> + }
> 
> I presume that the Vi is wrong, because in this syntax i is not known  
> as a variable. But I don?t know how to say that it is a variable here.
> Would be nice if somebody could help me.
> Perhaps I?m thinking too complicated and there is an easier way to do  
> this.
> 
Hi Birgit,
This may be what you want:

for(i in 1:85)
  print(do.call("range",list(as.name(paste("V",i,sep="")))))

Jim


From dpleydel at univ-fcomte.fr  Fri Jun 29 13:20:05 2007
From: dpleydel at univ-fcomte.fr (David)
Date: Fri, 29 Jun 2007 13:20:05 +0200
Subject: [R] Another loop avoidance question.
In-Reply-To: <200706280817.09527.Ray.Brownrigg@mcs.vuw.ac.nz>
References: <20070627122913.GA20817@univ-fcomte.fr>
	<200706280817.09527.Ray.Brownrigg@mcs.vuw.ac.nz>
Message-ID: <20070629112005.GB21083@univ-fcomte.fr>

Sorry folks I posted the code with a bug in approach 2. aarrrhh. it should have been...

## Approach 2: loop on k2
output2 = matrix(0,nrow=n,ncol=k2)
pt2 = proc.time(for (i in 1:k2) output2[,i] = rowSums( m1*(m2[,rep(i,3)]) ))
 
> I haven't seen any other response yet (after 8 hours!) but doesn't:
> rowSums(m1)*m2
> do what you want?
> 
> HTH
> Ray Brownrigg

... which is a very long winded way to do exactly what Ray did very
easily. Thanks for the pointer Ray.

Dave


From wwwhsd at gmail.com  Fri Jun 29 13:28:54 2007
From: wwwhsd at gmail.com (Henrique Dallazuanna)
Date: Fri, 29 Jun 2007 08:28:54 -0300
Subject: [R] extracting df and MS values from aov
In-Reply-To: <BAY135-F2482060D9F6557D933551AC7080@phx.gbl>
References: <BAY135-F2482060D9F6557D933551AC7080@phx.gbl>
Message-ID: <da79af330706290428h7b1bb42eqdc968891477dc157@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070629/70ebf37b/attachment.pl 

From jrkrideau at yahoo.ca  Fri Jun 29 13:33:44 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Fri, 29 Jun 2007 07:33:44 -0400 (EDT)
Subject: [R] Function call within a function.
In-Reply-To: <270735.77400.qm@web39704.mail.mud.yahoo.com>
Message-ID: <971107.15623.qm@web32802.mail.mud.yahoo.com>


--- Stephen Tucker <brown_emu at yahoo.com> wrote:

> Dear John,
> 
> Perhaps I am mistaken in what you are trying to
> accomplish but it seems like
> what is required is that you call lstfun() outside
> of ukn(). [and remove the
> call to lstfun() in ukn()].
> 
> nts <- lstfun(myfile, aa, bb)
> results <- ukn(dd1, "a", "b", nts$cda)

Yes this definately will work but seems sloppy.  What
I am doing in 'real' life is trying to sort a set of
data.frames into   a two element list ( lstfun) and
then apply some further subsetting to each data.frame
in the list separately.  
> 
> Alternatively, you can eliminate the fourth argument
> in ukn() and assign (via
> '<-') the results of lstfun() to 'nam1' within ukn()
> instead of saving to
> 'nts'...
Humm, I'll have to think about this. The problem, as I
have set up the program is that nam1 is one of the two
data.frames in the list.  

I may have to reconsider this whole thing.  I have
been trying to use the existing data structures and I
may need to start from scratch.  

Thanks for the help.  You have given me some useful
ideas.

John

> 
> --- John Kane <jrkrideau at yahoo.ca> wrote:
> 
> > I am trying to call a funtion within another
> function
> > and I clearly am misunderstanding what I should
> do. 
> > Below is a simple example.
> > I know lstfun works on its own but I cannot seem
> to
> > figure out how to get it to work within ukn.
> Basically
> > I need to create the variable "nts". I have
> probably
> > missed something simple in the Intro or FAQ.
> > 
> > Any help would be much appreciated.
> > 
> > EXAMPLE
> >
>
-------------------------------------------------------------------------------
> > # create data.frame
> > cata <- c( 1,1,6,1,1,4)
> > catb <- c( 1,2,3,4,5,6)
> > id <- c('a', 'b', 'b', 'a', 'a', 'b')
> > dd1  <-  data.frame(id, cata,catb)
> > 
> > # function to create list from data.frame
> > lstfun  <- function(file, alpha , beta ) {
> > cda  <-  subset(file, file[,1] == alpha)
> > cdb  <-  subset (file, file[,1]== beta)
> > list1 <- list(cda,cdb)
> > }
> > 
> > # funtion to operate on list
> > ukn  <-  function(file, alpha, beta, nam1){
> > aa  <- alpha
> > bb  <- beta
> > myfile  <- file
> > nts <- lstfun(myfile, aa, bb)
> > mysum <- nam1[,3]*5
> > return(mysum)
> > }
> > 
> > results <- ukn(dd1, "a", "b", nts$cda)
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained,
> reproducible code.
> > 
> 
> 
> 
>        
>
____________________________________________________________________________________
> Choose the right car based on your needs.  Check out


>


From jrkrideau at yahoo.ca  Fri Jun 29 13:38:46 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Fri, 29 Jun 2007 07:38:46 -0400 (EDT)
Subject: [R] Function call within a function.
In-Reply-To: <BAY116-DAV16327E3DF47A01B08BDE59CF090@phx.gbl>
Message-ID: <73015.6452.qm@web32809.mail.mud.yahoo.com>


--- Jason Barnhart <jasoncbarnhart at msn.com> wrote:

> The problem isn't the function call.
> 
> First, list1 returned by lstfun does not name its
> elements so nts$cda 
> won't work. See code change in lstfun.

Oh, I see. I missed this completely.  I clearly was a
bit groggy yesterday afternoon.  

> 
> Second, specifying nts$cda as the nam1 argument
> tells R to look for 
> the nts object in the environment in which ukn is
> called.  However, 
> the nts object is not created in the parent
> environment, it is created 
> in the ukn's environment.
> 
> Third, nam1[,3] should be nam1[2] as there is no
> third element to this 
> list (although and this doesn't resolve the
> environment issue).
> 
> I've modified your code below to work, but there are
> better ways to go 
> about this.  Thomas Lumley has a famous quote
> regarding parse.  See 
>
http://tolstoy.newcastle.edu.au/R/e2/help/07/01/8059.html
> among 
> others.
> 
> I was once referred to Patrick Burns' S Poetry to
> learn about the 
> "eval(parse(text=)))" paradigm which was very
> helpful. You may also 
> want to brush up on environments (see ?environment)
> to learn more 
> about lexical scoping.
> 
> Hope this helps.
> -jason
> 
> #MODIFIED CODE
> # create data.frame
> cata <- c( 1,1,6,1,1,4)
> catb <- c( 1,2,3,4,5,6)
> id <- c('a', 'b', 'b', 'a', 'a', 'b')
> dd1 <- data.frame(id, cata,catb)
> 
> # function to create list from data.frame
> lstfun <- function(file, alpha , beta ) {
> cda <- subset(file, file[,1] == alpha)
> cdb <- subset (file, file[,1]== beta)
> ### CODE ADDED HERE
> list1 <- list(cda=cda,cdb=cdb)
> }
> 
> # funtion to operate on list
> ukn <- function(file, alpha, beta, nam1){
> aa <- alpha
> bb <- beta
> myfile <- file
> nts <- lstfun(myfile, aa, bb)
> ### CODE ADDED HERE
> mysum <- eval(parse(text=nam1))
> #mysum <- nam1[,3]*5
> return(mysum)
> }
> 
> results <- ukn(dd1, "a", "b", "nts$cda") ###
> modified how called.
> 
> ----- Original Message ----- 
> From: "John Kane" <jrkrideau at yahoo.ca>
> To: "R R-help" <r-help at stat.math.ethz.ch>
> Sent: Thursday, June 28, 2007 12:03 PM
> Subject: [R] Function call within a function.
> 
> 
> >I am trying to call a funtion within another
> function
> > and I clearly am misunderstanding what I should
> do.
> > Below is a simple example.
> > I know lstfun works on its own but I cannot seem
> to
> > figure out how to get it to work within ukn.
> Basically
> > I need to create the variable "nts". I have
> probably
> > missed something simple in the Intro or FAQ.
> >
> > Any help would be much appreciated.
> >
> > EXAMPLE
> >
>
-------------------------------------------------------------------------------
> > # create data.frame
> > cata <- c( 1,1,6,1,1,4)
> > catb <- c( 1,2,3,4,5,6)
> > id <- c('a', 'b', 'b', 'a', 'a', 'b')
> > dd1  <-  data.frame(id, cata,catb)
> >
> > # function to create list from data.frame
> > lstfun  <- function(file, alpha , beta ) {
> > cda  <-  subset(file, file[,1] == alpha)
> > cdb  <-  subset (file, file[,1]== beta)
> > list1 <- list(cda,cdb)
> > }
> >
> > # funtion to operate on list
> > ukn  <-  function(file, alpha, beta, nam1){
> > aa  <- alpha
> > bb  <- beta
> > myfile  <- file
> > nts <- lstfun(myfile, aa, bb)
> > mysum <- nam1[,3]*5
> > return(mysum)
> > }
> >
> > results <- ukn(dd1, "a", "b", nts$cda)
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained,
> reproducible code.
> > 
> 
>


From birgit.lemcke at systbot.uzh.ch  Fri Jun 29 13:45:35 2007
From: birgit.lemcke at systbot.uzh.ch (Birgit Lemcke)
Date: Fri, 29 Jun 2007 13:45:35 +0200
Subject: [R] Repeat if
In-Reply-To: <468394EF.50704@bitwrit.com.au>
References: <C7B7CCEB-9193-40ED-850F-0385F9C3BB5B@systbot.uzh.ch>
	<468394EF.50704@bitwrit.com.au>
Message-ID: <B56CDA79-AAFE-47FA-8076-15E293B43F3D@systbot.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070629/e7f67e28/attachment.pl 

From albmont at centroin.com.br  Fri Jun 29 14:12:51 2007
From: albmont at centroin.com.br (Alberto Monteiro)
Date: Fri, 29 Jun 2007 10:12:51 -0200
Subject: [R] Fat tails
Message-ID: <20070629115307.M40604@centroin.com.br>

I have a process that generates distributions that look like normal, 
but with fat tails. I would like to model them as if they were
a mix of two normals (with zero mean). Is there any function that
recovers the standard deviations and the probability based on a 
sample?

I would like to generate a sample like this:

r.mydist <- function(n, prob, mean1, sd1=1, mean2, sd2=1) {
  # aesthetical stuff
  if (missing(mean1) & missing(mean2)) mean1 <- 0
  if (missing(mean1)) mean1 <- mean2
  if (missing(mean2)) mean2 <- mean1

  # now, let's work
  # test is true if we must use the first normal (mean1, sd1)
  test <- runif(n) < prob

  # create the return value
  rval <- 0
  rval[n] <- 0

  # generate the first normal when appropriate
  if (any(test))
    rval[test] <- rnorm(sum(test), mean1, sd1)

  # generate the second normal when appropriate
  if (any(!test))
    rval[!test] <- rnorm(sum(!test), mean2, sd2)

  # game over
  return(rval)
}

# test
x <- r.mydist(1000, 0.1, 0, 1, 0, 5)
hist(x)
if (require(fBasics))
  cat("the sample kurtosis is", kurtosis(x), "\n")

Now, with this sample x, how can I get back sd1, sd2 and prob?

Alberto Monteiro


From christophe at pallier.org  Fri Jun 29 14:33:37 2007
From: christophe at pallier.org (Christophe Pallier)
Date: Fri, 29 Jun 2007 14:33:37 +0200
Subject: [R] Repeat if
In-Reply-To: <B56CDA79-AAFE-47FA-8076-15E293B43F3D@systbot.uzh.ch>
References: <C7B7CCEB-9193-40ED-850F-0385F9C3BB5B@systbot.uzh.ch>
	<468394EF.50704@bitwrit.com.au>
	<B56CDA79-AAFE-47FA-8076-15E293B43F3D@systbot.uzh.ch>
Message-ID: <dea6cb960706290533w32cc7718gce288fcfece8dc48@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070629/7c308090/attachment.pl 

From HDoran at air.org  Fri Jun 29 14:29:31 2007
From: HDoran at air.org (Doran, Harold)
Date: Fri, 29 Jun 2007 08:29:31 -0400
Subject: [R] Spectral Decomposition
Message-ID: <2323A6D37908A847A7C32F1E3662C80EE578DA@dc1ex01.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070629/fa3a8589/attachment.pl 

From S.Ellison at lgc.co.uk  Fri Jun 29 14:37:20 2007
From: S.Ellison at lgc.co.uk (S Ellison)
Date: Fri, 29 Jun 2007 13:37:20 +0100
Subject: [R] : regular expressions: escaping a dot
Message-ID: <s6850b21.046@tedmail2.lgc.co.uk>

EOF from a keyboard on Windows is often Ctrl+Z. 

But you're right; it's platform dependent. CtrlZ in Unix has less desirable effects on readLines(). And on your running R process...

Drat.

>>> Peter Dalgaard <P.Dalgaard at biostat.ku.dk> 29/06/2007 12:42:41 >>>
S Ellison wrote:
> Wouldn't it be nice if the Help for readLines mentioned how to introduce an EOF when reading from stdin ...?
>
> Steve E
>
>   
Yes (in a couple of other cases, too) but it is likely platform
dependent. What do you use on Windows and is it the same in the terminal
and the GUI versions? And on Mac?


*******************************************************************
This email and any attachments are confidential. Any use, co...{{dropped}}


From jrkrideau at yahoo.ca  Fri Jun 29 14:41:18 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Fri, 29 Jun 2007 08:41:18 -0400 (EDT)
Subject: [R] Function call within a function.
In-Reply-To: <BAY116-DAV16327E3DF47A01B08BDE59CF090@phx.gbl>
Message-ID: <6373.48861.qm@web32813.mail.mud.yahoo.com>


--- Jason Barnhart <jasoncbarnhart at msn.com> wrote:

> The problem isn't the function call.
> 
> First, list1 returned by lstfun does not name its
> elements so nts$cda 
> won't work. See code change in lstfun.

I missed that entirely.  I was groggier than I
realised yesterday afternoon. I had at least once left
nts in existance in the same environment where ukn is
called, thus getting an intermitant error. In that
environment nts$cda was named!

> 
> Second, specifying nts$cda as the nam1 argument
> tells R to look for 
> the nts object in the environment in which ukn is
> called.  However, 
> the nts object is not created in the parent
> environment, it is created 
> in the ukn's environment.

Yes.  I had already tried calling it within the ukn
environment not realising that I had not named the
elements so this was my last try.  

> 
> Third, nam1[,3] should be nam1[2] as there is no
> third element to this 
> list (although and this doesn't resolve the
> environment issue).

Oops, typo when creating the simple example.  Sorry. 
> 
> I've modified your code below to work, but there are
> better ways to go 
> about this.  Thomas Lumley has a famous quote
> regarding parse.  See 
>
http://tolstoy.newcastle.edu.au/R/e2/help/07/01/8059.html
> among  others.
> 
> I was once referred to Patrick Burns' S Poetry to
> learn about the 
> "eval(parse(text=)))" paradigm which was very
> helpful. You may also 
> want to brush up on environments (see ?environment)
> to learn more 
> about lexical scoping.
> 
> Hope this helps.
> -jason

This has been very helpful though I still do not
understand why one must call nts$cda using the
eval(parse()) command.  Is it because nts is created
within the ukn environment?  

I have had a look at S-Poetry but will need to spend a
lot more time on this.  

I thought that this was not the best way to do things
but I wanted to avoid doing a lot of earlier
manipulations to my data files and so decided to go
with what I had. 


> 
> #MODIFIED CODE
> # create data.frame
> cata <- c( 1,1,6,1,1,4)
> catb <- c( 1,2,3,4,5,6)
> id <- c('a', 'b', 'b', 'a', 'a', 'b')
> dd1 <- data.frame(id, cata,catb)
> 
> # function to create list from data.frame
> lstfun <- function(file, alpha , beta ) {
> cda <- subset(file, file[,1] == alpha)
> cdb <- subset (file, file[,1]== beta)
> ### CODE ADDED HERE
> list1 <- list(cda=cda,cdb=cdb)
> }
> 
> # funtion to operate on list
> ukn <- function(file, alpha, beta, nam1){
> aa <- alpha
> bb <- beta
> myfile <- file
> nts <- lstfun(myfile, aa, bb)
> ### CODE ADDED HERE
> mysum <- eval(parse(text=nam1))
> #mysum <- nam1[,3]*5
> return(mysum)
> }
> 
> results <- ukn(dd1, "a", "b", "nts$cda") ###
> modified how called.
> 
> ----- Original Message ----- 
> From: "John Kane" <jrkrideau at yahoo.ca>
> To: "R R-help" <r-help at stat.math.ethz.ch>
> Sent: Thursday, June 28, 2007 12:03 PM
> Subject: [R] Function call within a function.
> 
> 
> >I am trying to call a funtion within another
> function
> > and I clearly am misunderstanding what I should
> do.
> > Below is a simple example.
> > I know lstfun works on its own but I cannot seem
> to
> > figure out how to get it to work within ukn.
> Basically
> > I need to create the variable "nts". I have
> probably
> > missed something simple in the Intro or FAQ.
> >
> > Any help would be much appreciated.
> >
> > EXAMPLE
> >
>
-------------------------------------------------------------------------------
> > # create data.frame
> > cata <- c( 1,1,6,1,1,4)
> > catb <- c( 1,2,3,4,5,6)
> > id <- c('a', 'b', 'b', 'a', 'a', 'b')
> > dd1  <-  data.frame(id, cata,catb)
> >
> > # function to create list from data.frame
> > lstfun  <- function(file, alpha , beta ) {
> > cda  <-  subset(file, file[,1] == alpha)
> > cdb  <-  subset (file, file[,1]== beta)
> > list1 <- list(cda,cdb)
> > }
> >
> > # funtion to operate on list
> > ukn  <-  function(file, alpha, beta, nam1){
> > aa  <- alpha
> > bb  <- beta
> > myfile  <- file
> > nts <- lstfun(myfile, aa, bb)
> > mysum <- nam1[,3]*5
> > return(mysum)
> > }
> >
> > results <- ukn(dd1, "a", "b", nts$cda)
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained,
> reproducible code.
> > 
> 
>


From f.harrell at vanderbilt.edu  Fri Jun 29 14:40:58 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Fri, 29 Jun 2007 07:40:58 -0500
Subject: [R] logistic regression and dummy variable coding
In-Reply-To: <469C5799-69C9-4E0B-ADE8-A3A647F5A0C7@bcm.tmc.edu>
References: <46C063CC-95DB-4F69-9D2F-59B105AFAE3B@bcm.tmc.edu>	<83217d00706281744qacaf3c5uc3c6c43ca25fb09d@mail.gmail.com>
	<469C5799-69C9-4E0B-ADE8-A3A647F5A0C7@bcm.tmc.edu>
Message-ID: <4684FDDA.4050702@vanderbilt.edu>

Bingshan Li wrote:
> Hi All,
> 
> Now it works. Thanks for all your answers and the explanations are  
> very clear.
> 
> Bingshan

But note that you are not using R correctly unless you are doing a 
simulation and have some special speed issues.  Let the model functions 
do all this for you.

Frank

> 
> On Jun 28, 2007, at 7:44 PM, Seyed Reza Jafarzadeh wrote:
> 
>> NewVar <- relevel( factor(OldVar), ref = "b")
>> should create a dummy variable, and change the reference category  
>> for the model.
>>
>> Reza
>>
>>
>> On 6/28/07, Bingshan Li <bli1 at bcm.tmc.edu> wrote:
>>> Hello everyone,
>>>
>>> I have a variable with several categories and I want to convert this
>>> into dummy variables and do logistic regression on it. I used
>>> model.matrix to create dummy variables but it always picked the
>>> smallest one as the reference. For example,
>>>
>>> model.matrix(~.,data=as.data.frame(letters[1:5]))
>>>
>>> will code 'a' as '0 0 0 0'. But I want to code another category as
>>> reference, say 'b'. How to do it in R using model.matrix? Is there
>>> other way to do it if model.matrix  has no such functionality?
>>>
>>> Thanks!
>>>
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting- 
>>> guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From f.harrell at vanderbilt.edu  Fri Jun 29 14:42:26 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Fri, 29 Jun 2007 07:42:26 -0500
Subject: [R] Warning message in Design ...
In-Reply-To: <1183107938.15290.16.camel@localhost>
References: <1183107938.15290.16.camel@localhost>
Message-ID: <4684FE32.6060603@vanderbilt.edu>

Petar Milin wrote:
> Hello!
> There were some questions regarding warning messages in Design library,
> but no answer how to fix them. What about:
> 
> "use of storage.mode(x) <- "single" is deprecated: use mode<- instead"
> 
> What does it mean? How to use properly simple model like:
> 
> m1 = ols(Y ~ A + B + C, data = someData)
> 
> After specifying the model above, warning message to use "mode(x)"
> instead of "storage.mode(x)" appears.
> 
> Best,
> PM

It's just a warning to be ignored.  It will go away in a future release 
of Design.

Frank

> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From jrkrideau at yahoo.ca  Fri Jun 29 14:54:46 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Fri, 29 Jun 2007 08:54:46 -0400 (EDT)
Subject: [R] Function call within a function.
In-Reply-To: <941871A13165C2418EC144ACB212BDB04E1322@dshsmxoly1504g.dshs.wa.lcl>
Message-ID: <105790.54630.qm@web32813.mail.mud.yahoo.com>

Thanks very much.  A very nice solution.  The
environment problem was the result of one last
deperate try when the actual problem as Jason pointed
out was that I was not naming my list elements and
thought that I had.  

This looks like it will work quite nicely. I am pretty
sure that there is a cleaner way to do this but it is
likely to mean too much manipulation of data earlier
on.  This is a small attempt to extract data in a new
way from a larger project. 

This is greatly appreciated.

 
--- "Nordlund, Dan (DSHS/RDA)" <NordlDJ at dshs.wa.gov>
wrote:

> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch 
> > [mailto:r-help-bounces at stat.math.ethz.ch] On
> Behalf Of John Kane
> > Sent: Thursday, June 28, 2007 12:04 PM
> > To: R R-help
> > Subject: [R] Function call within a function.
> > 
> > I am trying to call a funtion within another
> function
> > and I clearly am misunderstanding what I should
> do. 
> > Below is a simple example.
> > I know lstfun works on its own but I cannot seem
> to
> > figure out how to get it to work within ukn.
> Basically
> > I need to create the variable "nts". I have
> probably
> > missed something simple in the Intro or FAQ.
> > 
> > Any help would be much appreciated.
> > 
> > EXAMPLE
> >
>
--------------------------------------------------------------
> > -----------------
> > # create data.frame
> > cata <- c( 1,1,6,1,1,4)
> > catb <- c( 1,2,3,4,5,6)
> > id <- c('a', 'b', 'b', 'a', 'a', 'b')
> > dd1  <-  data.frame(id, cata,catb)
> > 
> > # function to create list from data.frame
> > lstfun  <- function(file, alpha , beta ) {
> > cda  <-  subset(file, file[,1] == alpha)
> > cdb  <-  subset (file, file[,1]== beta)
> > list1 <- list(cda,cdb)
> > }
> > 
> > # funtion to operate on list
> > ukn  <-  function(file, alpha, beta, nam1){
> > aa  <- alpha
> > bb  <- beta
> > myfile  <- file
> > nts <- lstfun(myfile, aa, bb)
> > mysum <- nam1[,3]*5
> > return(mysum)
> > }
> > 
> > results <- ukn(dd1, "a", "b", nts$cda)
> 
> John,
> 
> The first problem I see is one of scope.  nts$cda
> refers to an object called nts which does not exist
> in the calling environment (it is local to the
> function ukn).  So trying to call ukn() with nts
> results in an error.  Second, even if you pass the
> name of the object, you will not be able to use it
> in ukn() in the manner that you are trying.  Your
> ukn() function definition also requires that it know
> the inner workings of function lstfun().  Functions
> generally shouldn't require knowing how other
> functions work, they should only rely on what value
> is returned.
> 
> You can get what you want by redefining ukn in the
> following way
> 
> # funtion to operate on list
> ukn  <-  function(file, alpha, beta, nam1){
> aa  <- alpha
> bb  <- beta
> myfile  <- file
> nts <- lstfun(myfile, aa, bb)
> mysum <- nts[[nam1]][,3]*5
> return(mysum)
> }
> 
> And change the function call to
> 
> results <- ukn(dd1, "a", "b", 1) 
> 
> This still leaves the functions coupled in a way
> that I don't like, but I'm not a good enough R
> programmer to solve that problem at the moment. 
> Maybe someone else will come along with a better
> solution.
> 
> Hope this is helpful,
> 
> Dan
> 
> Daniel J. Nordlund
> Research and Data Analysis
> Washington State Department of Social and Health
> Services
> Olympia, WA  98504-5204
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From rmh at temple.edu  Fri Jun 29 15:00:33 2007
From: rmh at temple.edu (Richard M. Heiberger)
Date: Fri, 29 Jun 2007 09:00:33 -0400 (EDT)
Subject: [R] Spectral Decomposition
Message-ID: <20070629090033.CFG01707@po-d.temple.edu>

For a general square matrix A, the eigenvalue decomposition is
A = CBC^{-1}
For the special case of symmetric A,
C^{-1} = C'


From markus at insightfromdata.com  Fri Jun 29 15:02:21 2007
From: markus at insightfromdata.com (Markus Loecher)
Date: Fri, 29 Jun 2007 09:02:21 -0400
Subject: [R] align() function missing in R ?
In-Reply-To: <Pine.LNX.4.64.0706290840510.1099@gannet.stats.ox.ac.uk>
References: <200706281511.l5SFBlat007218@hypatia.math.ethz.ch>
	<18052.43963.748646.703108@stat.math.ethz.ch>
	<Pine.LNX.4.64.0706290840510.1099@gannet.stats.ox.ac.uk>
Message-ID: <200706291302.l5TD2wc9015482@hypatia.math.ethz.ch>

Thank you for your responses, I should have given an example of the 
functionality I am looking for, here are three typical scenarios that 
I deal with a lot in my work:

- a regular timeseries with lots of missing values that I want to 
convert to the corresponding regular time series with mssing values 
replaced by NAs, e.g.:
         x = timeSeries(c(0.5,0.2,0.3,0.4,0.3,0.2,0.3), pos = 
c(1,2,5,8,9,12,14));
         x.align = align(x, pos = 1:14, method = "NA");
- a regular timeseries at a coarse scale which I want to linearly 
interpolate to a finer time scale:
         x = ts(1:10, frequency = 4);
         x.align = align(x, frequency = 8, method = "interp")
- an irregular timeseries which I want to linearly interpolate to a 
regular time grid:
         x = timeSeries(c(0.5,0.2,0.3,0.4,0.3,0.2,0.3), pos = 
c(1,2.5,3.2,4.1,5.7,6.5,7.3));
         x.align = align(x, pos = 1:7, method = "interp");

I am wondering how to easily code such a function using only window, 
ts.union and ts.intersect.

Thanks again,
Markus

At 03:52 AM 6/29/2007, Prof Brian Ripley wrote:
>On Fri, 29 Jun 2007, Martin Maechler wrote:
>
>>Hi Markus,
>>
>>You can't assume that a typical R users knows much about S+.
>>"R has been beyond S+ for a long time"
>>   {{ :-) :-) please Insightful staff, don't start to jump at me !}}
>>Even I, as a very long time S and Splus user (of the past:
>>1987--~1997), have never, I think, used align().
>>
>>Can you give *reproducible examples* of what  align() does for you?
>>Then, kind R users will typically show you simple ways to achieve the
>>same.
>>
>>Also: R is Free Software (i.e. open source and more), so
>>      we'd be happy to accept offers of an align() function that
>>      behaved compatibly (``or better'') than the S-plus one.
>>Note however that you'd typically not be allowed to copy the
>>S-plus implementation.
>
>align() relates to the S4 time series classes introduced in S-PLUS 5 
>(or so, after 1997).  There are no comparable classes in base R, but 
>there are in some of the addon packages - fCalendar has already been 
>mentioned and there are others (see the CRAN Econometric task view).
>
>window, ts.union and ts.intersect have done all the alignment on 
>regular time series (class "ts") I have ever needed.
>
>>
>>Martin
>>
>>
>>>>>>>"ML" == Markus Loecher <markus at insightfromdata.com>
>>>>>>>     on Thu, 28 Jun 2007 11:10:51 -0400 writes:
>>
>>    ML> Dear list members, I switched from Splus to R a few
>>    ML> years ago and so far found no functionality missing.
>>    ML> However, I am struggling to find the equivalent align()
>>    ML> function for time series. I did find some reduced
>>    ML> functionality such as alignDailySeries in
>>    ML> package:fCalendar but the full capability of aligning
>>    ML> two timeseries seems to be missing.  Could this be true
>>    ML> ? I am sure there must be a need for this useful
>>    ML> function.  Any help would be greatly appreciated.
>>
>>    ML> Thanks !
>>
>>    ML> Markus
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>--
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From yn19832 at msn.com  Fri Jun 29 15:13:03 2007
From: yn19832 at msn.com (livia)
Date: Fri, 29 Jun 2007 06:13:03 -0700 (PDT)
Subject: [R] cbind
Message-ID: <11359949.post@talk.nabble.com>


Hi, I have a series of return data, a and b are factors. I would like to
build a matrix which contains each vector of "returns". I am thinking about
something as following, but I guess there should be a sensible way of doing
this. 

returns <- split(return, list(regimef, assetf))
cbind(returns[[1]], returns[[2]],...,returns[[n]])

Could anyone give me some advice? Many thanks.
-- 
View this message in context: http://www.nabble.com/cbind-tf3999805.html#a11359949
Sent from the R help mailing list archive at Nabble.com.


From ted.harding at nessie.mcc.ac.uk  Fri Jun 29 15:23:05 2007
From: ted.harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 29 Jun 2007 14:23:05 +0100 (BST)
Subject: [R] Spectral Decomposition
In-Reply-To: <2323A6D37908A847A7C32F1E3662C80EE578DA@dc1ex01.air.org>
Message-ID: <XFMail.070629142305.ted.harding@nessie.mcc.ac.uk>


On 29-Jun-07 12:29:31, Doran, Harold wrote:
> All of my resources for numerical analysis show that the spectral
> decomposition is
> 
> A = CBC'
> 
> Where C are the eigenvectors and B is a diagonal matrix of eigen
> values. Now, using the eigen function in R
> 
># Original matrix
> aa <- matrix(c(1,-1,-1,1), ncol=2)
> 
> ss <- eigen(aa)
> 
># This results yields back the original matrix according to the
> formula above
> ss$vectors %*% diag(ss$values) %*% t(ss$vectors)
> 
> However, for the following I do not get back the original matrix
> using the general formula for the spectral decomposition:
> 
> set.seed(123)
> 
> aa <- matrix(rnorm(16), ncol=4)
> 
> ss <- eigen(aa)
> 
> ss$vectors %*% diag(ss$values) %*% t(ss$vectors)
> 
> However, if I do the following
> 
> A = CBC^{-1}
> 
> I get back the original matrix A
> 
> ss$vectors %*% diag(ss$values) %*% solve(ss$vectors)

Harold, I think the key to the issue is whether your original
matric is symmetric or not. For your formula

  A = C*B*C'

to work, where B is a diagonal matrix (therefore essentially
symmetric) you have -- bearing in mind the reversal of factors --

  A' = ReverseFactorsIn(C'*B'*C) = C*B*C' = A

so A would have to be symmetric. This was the case for your
first example matrix(c(1,-1,-1,1), ncol=2).

However, your second example will not be symmetric, so the
formula will not work, and you will need A = C*B*C^(-1).

If A is not symmetric, you have "left" eigenvectors:

  x'*A = lambda*x'

and "right" eigenvectors:

  A*x = lambda*x

and the "left" eigenvectors are not the same as the "right"
eigenvectors, though you have the same set of eigenvalues lambda
in each case.

You then have

  A = L'*B*R

Of course the most frequent occurrence of this kind of question
in statistics is where A is a covariance or correlation matrix,
which is symmetric by definition.

Hoping this helps!
Ted.

> In my lit search I am not finding an explanation for why this works, so
> I am seeking R-help since there may be a computational rationale that
> can be explained by users (or authors) of the function. In my
> experimentation with some computations it seems that the latter
> approach is more general in that it yields back the matrix I began
> with, but deviates from the formula I commonly see in texts.
> 
> Thanks,
> Harold

--------------------------------------------------------------------
E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 29-Jun-07                                       Time: 14:23:03
------------------------------ XFMail ------------------------------


From ripley at stats.ox.ac.uk  Fri Jun 29 15:24:36 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 29 Jun 2007 14:24:36 +0100 (BST)
Subject: [R] align() function missing in R ?
In-Reply-To: <1183122181-28569@relay0.mail.ox.ac.uk>
References: <200706281511.l5SFBlat007218@hypatia.math.ethz.ch>
	<18052.43963.748646.703108@stat.math.ethz.ch>
	<Pine.LNX.4.64.0706290840510.1099@gannet.stats.ox.ac.uk>
	<1183122181-28569@relay0.mail.ox.ac.uk>
Message-ID: <Pine.LNX.4.64.0706291409470.10093@auk.stats>

On Fri, 29 Jun 2007, Markus Loecher wrote:

> Thank you for your responses, I should have given an example of the 
> functionality I am looking for, here are three typical scenarios that I deal 
> with a lot in my work:
>
> - a regular timeseries with lots of missing values that I want to convert to 
> the corresponding regular time series with mssing values replaced by NAs, 
> e.g.:
>        x = timeSeries(c(0.5,0.2,0.3,0.4,0.3,0.2,0.3), pos = 
> c(1,2,5,8,9,12,14));
>        x.align = align(x, pos = 1:14, method = "NA");
> - a regular timeseries at a coarse scale which I want to linearly interpolate 
> to a finer time scale:
>        x = ts(1:10, frequency = 4);
>        x.align = align(x, frequency = 8, method = "interp")
> - an irregular timeseries which I want to linearly interpolate to a regular 
> time grid:
>        x = timeSeries(c(0.5,0.2,0.3,0.4,0.3,0.2,0.3), pos = 
> c(1,2.5,3.2,4.1,5.7,6.5,7.3));
>        x.align = align(x, pos = 1:7, method = "interp");
>
> I am wondering how to easily code such a function using only window, ts.union 
> and ts.intersect.

Well, the first and third are using timeSeries which is not in R, and more 
to the point there is no support for irregular time series in R itself.
But they seem nothing to do with alignment!

The first is easy by indexing

x.align <- ts(NA_real_, start=1, end=14)
x.align[c(1,2,5,8,9,12,14)] <- c(0.5,0.2,0.3,0.4,0.3,0.2,0.3)

The second and third you can do via approx:

x <- ts(1:10, frequency = 4)
x.align <- ts(approx(unclass(x), xout=seq(1, 10, 0.5))$y, frequency = 8)

pos <- c(1,2.5,3.2,4.1,5.7,6.5,7.3)
x <- c(0.5,0.2,0.3,0.4,0.3,0.2,0.3)
ts(approx(pos, x, 1:7)$y)

I suspect the first can also be done via package 'zoo', which is the sort 
of place I would expect to find this functionality.

>
> Thanks again,
> Markus
>
> At 03:52 AM 6/29/2007, Prof Brian Ripley wrote:
>> On Fri, 29 Jun 2007, Martin Maechler wrote:
>> 
>>> Hi Markus,
>>> 
>>> You can't assume that a typical R users knows much about S+.
>>> "R has been beyond S+ for a long time"
>>>   {{ :-) :-) please Insightful staff, don't start to jump at me !}}
>>> Even I, as a very long time S and Splus user (of the past:
>>> 1987--~1997), have never, I think, used align().
>>> 
>>> Can you give *reproducible examples* of what  align() does for you?
>>> Then, kind R users will typically show you simple ways to achieve the
>>> same.
>>> 
>>> Also: R is Free Software (i.e. open source and more), so
>>>      we'd be happy to accept offers of an align() function that
>>>      behaved compatibly (``or better'') than the S-plus one.
>>> Note however that you'd typically not be allowed to copy the
>>> S-plus implementation.
>> 
>> align() relates to the S4 time series classes introduced in S-PLUS 5 (or 
>> so, after 1997).  There are no comparable classes in base R, but there are 
>> in some of the addon packages - fCalendar has already been mentioned and 
>> there are others (see the CRAN Econometric task view).
>> 
>> window, ts.union and ts.intersect have done all the alignment on regular 
>> time series (class "ts") I have ever needed.
>> 
>>> 
>>> Martin
>>> 
>>> 
>>>>>>>> "ML" == Markus Loecher <markus at insightfromdata.com>
>>>>>>>>     on Thu, 28 Jun 2007 11:10:51 -0400 writes:
>>>
>>>    ML> Dear list members, I switched from Splus to R a few
>>>    ML> years ago and so far found no functionality missing.
>>>    ML> However, I am struggling to find the equivalent align()
>>>    ML> function for time series. I did find some reduced
>>>    ML> functionality such as alignDailySeries in
>>>    ML> package:fCalendar but the full capability of aligning
>>>    ML> two timeseries seems to be missing.  Could this be true
>>>    ML> ? I am sure there must be a need for this useful
>>>    ML> function.  Any help would be greatly appreciated.
>>>
>>>    ML> Thanks !
>>>
>>>    ML> Markus
>>> 
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ted.harding at nessie.mcc.ac.uk  Fri Jun 29 15:42:22 2007
From: ted.harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 29 Jun 2007 14:42:22 +0100 (BST)
Subject: [R] Spectral Decomposition [OOPS]
In-Reply-To: <XFMail.070629142305.ted.harding@nessie.mcc.ac.uk>
Message-ID: <XFMail.070629144222.ted.harding@nessie.mcc.ac.uk>

On 29-Jun-07 13:23:05, Ted Harding wrote:
> [Sorry -- a silly typo in my previous]:
> If A is not symmetric, you have "left" eigenvectors:
> 
>   x'*A = lambda*x'
> 
> and "right" eigenvectors:
> 
>   A*x = lambda*x
> 
> and the "left" eigenvectors are not the same as the "right"
> eigenvectors, though you have the same set of eigenvalues lambda
> in each case.
> 
> You then have
> 
>   A = L'*B*R

Should be:

  A = R*B*L'

in that L'*R = I (unit), so then

  A*R = R*B

so each column (right eigenvector) of R is multiplied by the
corresponding lambda;

  L'*A = B*L'

so each row (left eigenvector) of L' is multiplied by the
corresponding lambda.

Apologies for the slip!
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 29-Jun-07                                       Time: 14:42:19
------------------------------ XFMail ------------------------------


From jholtman at gmail.com  Fri Jun 29 16:00:56 2007
From: jholtman at gmail.com (jim holtman)
Date: Fri, 29 Jun 2007 10:00:56 -0400
Subject: [R] cbind
In-Reply-To: <11359949.post@talk.nabble.com>
References: <11359949.post@talk.nabble.com>
Message-ID: <644e1f320706290700n3568da8ck63e24394c9a8f814@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070629/02b18b90/attachment.pl 

From tobias.verbeke at businessdecision.com  Fri Jun 29 16:05:10 2007
From: tobias.verbeke at businessdecision.com (Tobias Verbeke)
Date: Fri, 29 Jun 2007 16:05:10 +0200
Subject: [R] cbind
In-Reply-To: <11359949.post@talk.nabble.com>
References: <11359949.post@talk.nabble.com>
Message-ID: <46851196.8000604@businessdecision.com>

livia wrote:

> Hi, I have a series of return data, a and b are factors. I would like to
> build a matrix which contains each vector of "returns". I am thinking about
> something as following, but I guess there should be a sensible way of doing
> this. 
> 
> returns <- split(return, list(regimef, assetf))
> cbind(returns[[1]], returns[[2]],...,returns[[n]])

Does

do.call("cbind", returns)

do what you want ?

HTH,
Tobias

-- 

Tobias Verbeke - Consultant
Business & Decision Benelux
Rue de la r?volution 8
1000 Brussels - BELGIUM

+32 499 36 33 15
tobias.verbeke at businessdecision.com


From effe at sestante.net  Fri Jun 29 12:02:15 2007
From: effe at sestante.net (Federico Tomassini)
Date: Fri, 29 Jun 2007 12:02:15 +0200
Subject: [R] shading bar charts
Message-ID: <4684D8A7.5060108@sestante.net>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hi alls,

i have to code a family of bar charts. After reading the doc, i cannot
understand if it is possible to shade the bar colors and how.

With shading i don't mean `density`. I mean something like that:

http://www.advsofteng.com/images/colorcylinder_g.png


Thanks and br

- --
Federico
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.6 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iD8DBQFGhNini7obm7aBjHcRAuvbAJ9y5lM+VoAGdko8hH2NQjrkSfvOlACfVDsT
msphKZGSrswwnBGEssTv4nM=
=aEwU
-----END PGP SIGNATURE-----


From simona.racioppi at libero.it  Fri Jun 29 12:46:46 2007
From: simona.racioppi at libero.it (simona.racioppi)
Date: Fri, 29 Jun 2007 12:46:46 +0200
Subject: [R] GAMS and interactions
Message-ID: <JKE8LY$0B4B5FD8835ED2736BA78A53424AF0AC@libero.it>

Dear all,
I am fitting a generalized additive model with several discrete and continuous predictors, using the library mgcv. 

Basically, I have two questions:

1.
If I model the response variable y with f(x), z and f(x):z, where f(x) has 1 edf and f(x):z has 4 edf, can I model x parametrically, that is considering x and not f(x), and keep in my model f(x):z (note: x and z are continuous)? In other words, if I am going to keep f(x):z, should I keep f(x) to be consistent, even if f(x) has 1 edf??

2.
If I am using a thin plate regression spline, f(w,t), should I put f(w) and f(t) in the equation? I think I should consider f(w,t) only 
 but I am not sure that is equivalent to f(w) + f(t) + f(w,t).

Thank you very much,

Simona




------------------------------------------------------
Leggi GRATIS le tue mail con il telefonino i-mode? di Wind
http://i-mode.wind.it/


From P.Dalgaard at biostat.ku.dk  Fri Jun 29 17:05:29 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 29 Jun 2007 17:05:29 +0200
Subject: [R] Comparison: glm() vs. bigglm()
In-Reply-To: <2FAF9CA2-DAC4-4610-AFE6-90E495656FA5@jhsph.edu>
References: <2FAF9CA2-DAC4-4610-AFE6-90E495656FA5@jhsph.edu>
Message-ID: <46851FB9.1090105@biostat.ku.dk>

Benilton Carvalho wrote:
> Hi,
>
> Until now, I thought that the results of glm() and bigglm() would  
> coincide. Probably a naive assumption?
>
> Anyways, I've been using bigglm() on some datasets I have available.  
> One of the sets has >15M observations.
>
> I have 3 continuous predictors (A, B, C) and a binary outcome (Y).  
> And tried the following:
>
> m1 <- bigglm(Y~A+B+C, family=binomial(), data=dataset1, chunksize=10e6)
> m2 <- bigglm(Y~A*B+C, family=binomial(), data=dataset1, chunksize=10e6)
> imp <- m1$deviance-m2$deviance
>
> For my surprise "imp" was negative.
>
> I then tried the same models, using glm() instead... and as I  
> expected, "imp" was positive.
>
> I also noticed differences on the coefficients estimated by glm() and  
> bigglm() - small differences, though, and CIs for the coefficients (a  
> given coefficient compared across methods) overlap.
>
> Are such incrongruences expected? What can I use to check for  
> convergence with bigglm(), as this might be one plausible cause for a  
> negative difference on the deviances?
>   
It doesn't sound right, but I cannot reproduce your problem on a similar
sized problem (it pretty much killed my machine...). Some observations:

A: You do realize that you are only using 1.5 chunks? (15M vs. 10e6
chunksize)

B: Deviance changes are O(1) under the null hypothesis but the deviances
themselves are O(N). In a smaller variant (N=1e5), I got

> m1$deviance
[1] 138626.4
> m2$deviance
[1] 138626.4
> m2$deviance - m1$deviance
[1] -0.05865785

This does leave some scope for roundoff to creep in. You may want to
play with a lower setting of tol=...

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From bcarvalh at jhsph.edu  Fri Jun 29 17:29:42 2007
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Fri, 29 Jun 2007 11:29:42 -0400
Subject: [R] Comparison: glm() vs. bigglm()
In-Reply-To: <46851FB9.1090105@biostat.ku.dk>
References: <2FAF9CA2-DAC4-4610-AFE6-90E495656FA5@jhsph.edu>
	<46851FB9.1090105@biostat.ku.dk>
Message-ID: <84A499CE-BEF6-435D-85C3-25E2059DFB56@jhsph.edu>

Hi Peter,

thank you very much for your feedback.

As for your observations, I do realize that I'm using 1.5 chunks for  
this particular case (10e6 gives around 8 chunks on other sets).

I just noticed that I didn't add the difference in the deviances that  
I observed:

m1$deviance-m2$deviance
[1] -93196.69

Thank you very much for the suggestion, I'll give it a try.

Best,
benilton

On Jun 29, 2007, at 11:05 AM, Peter Dalgaard wrote:

> Benilton Carvalho wrote:
>> Hi,
>>
>> Until now, I thought that the results of glm() and bigglm() would
>> coincide. Probably a naive assumption?
>>
>> Anyways, I've been using bigglm() on some datasets I have available.
>> One of the sets has >15M observations.
>>
>> I have 3 continuous predictors (A, B, C) and a binary outcome (Y).
>> And tried the following:
>>
>> m1 <- bigglm(Y~A+B+C, family=binomial(), data=dataset1,  
>> chunksize=10e6)
>> m2 <- bigglm(Y~A*B+C, family=binomial(), data=dataset1,  
>> chunksize=10e6)
>> imp <- m1$deviance-m2$deviance
>>
>> For my surprise "imp" was negative.
>>
>> I then tried the same models, using glm() instead... and as I
>> expected, "imp" was positive.
>>
>> I also noticed differences on the coefficients estimated by glm() and
>> bigglm() - small differences, though, and CIs for the coefficients (a
>> given coefficient compared across methods) overlap.
>>
>> Are such incrongruences expected? What can I use to check for
>> convergence with bigglm(), as this might be one plausible cause for a
>> negative difference on the deviances?
>>
> It doesn't sound right, but I cannot reproduce your problem on a  
> similar
> sized problem (it pretty much killed my machine...). Some  
> observations:
>
> A: You do realize that you are only using 1.5 chunks? (15M vs. 10e6
> chunksize)
>
> B: Deviance changes are O(1) under the null hypothesis but the  
> deviances
> themselves are O(N). In a smaller variant (N=1e5), I got
>
>> m1$deviance
> [1] 138626.4
>> m2$deviance
> [1] 138626.4
>> m2$deviance - m1$deviance
> [1] -0.05865785
>
> This does leave some scope for roundoff to creep in. You may want to
> play with a lower setting of tol=...
>
> -- 
>    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45)  
> 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45)  
> 35327907
>


From spencer.graves at pdf.com  Fri Jun 29 17:58:41 2007
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 29 Jun 2007 08:58:41 -0700
Subject: [R] unequal variance assumption for lme (mixed effect model)
In-Reply-To: <6fb73d020706272014g18d3abb9ob70ab559883b6fb3@mail.gmail.com>
References: <6fb73d020706271855seedb40dobbc0fe2578de94ea@mail.gmail.com>	<1182998669.4837.11.camel@sib-sblomber01d.sib.uq.edu.au>
	<6fb73d020706272014g18d3abb9ob70ab559883b6fb3@mail.gmail.com>
Message-ID: <46852C31.80905@pdf.com>

<comments in line>

shirley zhang wrote:
> Hi Simon,
>
> Thanks for your reply. Your reply reminds me that book. I've read it
> long time ago, but haven't  try the weights option in my projects
> yet:)
>
> Is the heteroscedastic test always less powerful because we have to
> estimate the within group variance from the given data?
>   
SG:  In general, I suspect we generally lose power when we estimate more 
parameters. 

SG:  You can check this using the 'simulate.lme' function, whose use is 
illustrated in the seminal work reported in sect. 2.4 of Pinheiro and 
Bates (2000) Mixed-Effects Models in S and S-Plus (Springer). 
> Should we check whether each group has equal variance before using
> weights=varIdent()? If we should, what is the function for linear
> mixed model?
>   
SG:  The general advice I've seen is to avoid excessive 
overparameterization of heterscedasticity and correlations.  However, 
parsimonious correlation had heterscedasticity models would likely be 
wise.  Years ago, George Box expressed concern about people worrying too 
much about outliers, which are often fairly obvious and relatively easy 
to detect, while they worried too little, he thought, about dependence, 
especially serial dependence, which is generally more difficult to 
detect and creates bigger problems in inference than outliers.  He 
wrote, "Why worry about mice when there are tigers about?" 

SG:  Issues of this type can be fairly easily evaluated using 
'simulate.lme'. 

      Hope this helps. 
      Spencer Graves
> Thanks,
> Shirley
>
> On 6/27/07, Simon Blomberg <s.blomberg1 at uq.edu.au> wrote:
>   
>> The default settings for lme do assume equal variances within groups.
>> You can change that by using the various varClasses. see ?varClasses. A
>> simple example would be to allow unequal variances across groups. So if
>> your call to lme was:
>>
>> lme(...,random=~1|group,...)
>>
>> then to allow each group to have its own variance, use:
>>
>> lme(...,random=~1|group, weights=varIdent(form=~1|group),...)
>>
>> You really really should read Pinheiro & Bates (2000). It's all there.
>>
>> HTH,
>>
>> Simon.
>>
>> , On Wed, 2007-06-27 at 21:55 -0400, shirley zhang wrote:
>>     
>>> Dear Douglas and R-help,
>>>
>>> Does lme assume normal distribution AND equal variance among groups
>>> like anova() does? If it does, is there any method like unequal
>>> variance T-test (Welch T) in lme when each group has unequal variance
>>> in my data?
>>>
>>> Thanks,
>>> Shirley
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>       
>> --
>> Simon Blomberg, BSc (Hons), PhD, MAppStat.
>> Lecturer and Consultant Statistician
>> Faculty of Biological and Chemical Sciences
>> The University of Queensland
>> St. Lucia Queensland 4072
>> Australia
>>
>> Room 320, Goddard Building (8)
>> T: +61 7 3365 2506
>> email: S.Blomberg1_at_uq.edu.au
>>
>> The combination of some data and an aching desire for
>> an answer does not ensure that a reasonable answer can
>> be extracted from a given body of data. - John Tukey.
>>
>>
>>     
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From sunnyside500 at gmail.com  Fri Jun 29 18:37:52 2007
From: sunnyside500 at gmail.com (runner)
Date: Fri, 29 Jun 2007 09:37:52 -0700 (PDT)
Subject: [R] regexpr
Message-ID: <11363041.post@talk.nabble.com>


Hi, 

I 'd like to match each member of a list to a target string, e.g.
------------------------------
mylist=c("MN","NY","FL")
g=regexpr(mylist[1], "Those from MN:")
if (g>0)
{
"On list"
}
------------------------------
My question is:

How to add an end-of-string symbol '$' to the to-match string? so that 'M'
won't match.

Of course, "MN$" will work, but i want to use it in a loop; "mylist[i]" is
what i need. I tried "mylist[1]$", but didn't work. So why it doesn't
extrapolate? How to do it?

Thanks a lot!
-- 
View this message in context: http://www.nabble.com/regexpr-tf4000743.html#a11363041
Sent from the R help mailing list archive at Nabble.com.


From bli1 at bcm.tmc.edu  Fri Jun 29 18:53:05 2007
From: bli1 at bcm.tmc.edu (Li, Bingshan)
Date: Fri, 29 Jun 2007 11:53:05 -0500
Subject: [R] logistic regression and dummy variable coding
References: <46C063CC-95DB-4F69-9D2F-59B105AFAE3B@bcm.tmc.edu>	<83217d00706281744qacaf3c5uc3c6c43ca25fb09d@mail.gmail.com>
	<469C5799-69C9-4E0B-ADE8-A3A647F5A0C7@bcm.tmc.edu>
	<4684FDDA.4050702@vanderbilt.edu>
Message-ID: <B0F082E681BDA646B9D0A887A2BBF2E3010D7F79@BCMEVS7.ad.bcm.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070629/4847ad20/attachment.pl 

From mark at wardle.org  Fri Jun 29 19:02:49 2007
From: mark at wardle.org (Mark Wardle)
Date: Fri, 29 Jun 2007 18:02:49 +0100
Subject: [R] \include-mechanism in Sweave?
In-Reply-To: <4684D039.2010302@uni-osnabrueck.de>
References: <4684D039.2010302@uni-osnabrueck.de>
Message-ID: <b59a37130706291002v2efd28enfa1e3a22a5ac5dc7@mail.gmail.com>

Hi Dietrich,

I am writing my thesis, made up of several papers that have been
expanded into chapters. Each "chapter" was a .tex file until I started
using Sweave.

Now each chapter is an .Rnw file. My master LaTeX document has this:

\include{introduction}
\include{epidemiology}
\include{report}

Latex will look for introduction.tex, epidemiology.tex and report.tex.
I can get LaTeX to only process the introduction by using \includeonly

Of course, the .tex files are generated from Rnw files via a Makefile.
This makefile will only re-generate tex files from Rnw files if the
Rnw file is updated (unless you  give it different rules).

See post: http://tolstoy.newcastle.edu.au/R/e2/help/06/11/4891.html

Hope this helps,

Mark

On 29/06/07, Dietrich Trenkler <Dietrich.Trenkler at uni-osnabrueck.de> wrote:
> Dear HelpeRs,
>
> I'm very fond of Sweave and I use it as often as possible.  It'a a pity
> I can't use it for larger projects or can I?
>
> For instance suppose I have three files file1.rnw, file2.rnw and
> file3.rnw with Sweave code.  Working on file2.rnw I whould like to
> exclude file1.rnw and file3.rnw temporarily and joining all of them
> later.  This amounts to a mechanism similar to using LaTeX's \include
> command.  *Is* there a way to achieve that?
>
> Thank you in advance.
>
> D. Trenkler
>
> --
> Dietrich Trenkler c/o Universitaet Osnabrueck
> Rolandstr. 8; D-49069 Osnabrueck, Germany
> email: Dietrich.Trenkler at Uni-Osnabrueck.de
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________________________________
> This email has been scanned by the MessageLabs Email Security System.
> For more information please visit http://www.messagelabs.com/email
> ______________________________________________________________________
>


-- 
Dr. Mark Wardle
Clinical research fellow and specialist registrar, Neurology
Cardiff, UK


From p.dalgaard at biostat.ku.dk  Fri Jun 29 19:04:09 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 29 Jun 2007 19:04:09 +0200
Subject: [R] logistic regression and dummy variable coding
In-Reply-To: <B0F082E681BDA646B9D0A887A2BBF2E3010D7F79@BCMEVS7.ad.bcm.edu>
References: <46C063CC-95DB-4F69-9D2F-59B105AFAE3B@bcm.tmc.edu>	<83217d00706281744qacaf3c5uc3c6c43ca25fb09d@mail.gmail.com>	<469C5799-69C9-4E0B-ADE8-A3A647F5A0C7@bcm.tmc.edu>	<4684FDDA.4050702@vanderbilt.edu>
	<B0F082E681BDA646B9D0A887A2BBF2E3010D7F79@BCMEVS7.ad.bcm.edu>
Message-ID: <46853B89.2050100@biostat.ku.dk>

Li, Bingshan wrote:
> Hi Frank,
>  
> I do not quite get you. What do you mean by simulation and speed issues? I do not see why they have to be considered in logistic regression.
>  
>   
Exactly. So don't use techniques that are only needed when such issues 
do have to be considered.

> Thanks.
>  
> Bingshan
>
> ________________________________
>
> From: Frank E Harrell Jr [mailto:f.harrell at vanderbilt.edu]
> Sent: Fri 6/29/2007 7:40 AM
> To: Li, Bingshan
> Cc: Seyed Reza Jafarzadeh; r-help at stat.math.ethz.ch
> Subject: Re: [R] logistic regression and dummy variable coding
>
>
>
> Bingshan Li wrote:
>   
>> Hi All,
>>
>> Now it works. Thanks for all your answers and the explanations are 
>> very clear.
>>
>> Bingshan
>>     
>
> But note that you are not using R correctly unless you are doing a
> simulation and have some special speed issues.  Let the model functions
> do all this for you.
>
> Frank
>
>   
>> On Jun 28, 2007, at 7:44 PM, Seyed Reza Jafarzadeh wrote:
>>
>>     
>>> NewVar <- relevel( factor(OldVar), ref = "b")
>>> should create a dummy variable, and change the reference category 
>>> for the model.
>>>
>>> Reza
>>>
>>>
>>> On 6/28/07, Bingshan Li <bli1 at bcm.tmc.edu> wrote:
>>>       
>>>> Hello everyone,
>>>>
>>>> I have a variable with several categories and I want to convert this
>>>> into dummy variables and do logistic regression on it. I used
>>>> model.matrix to create dummy variables but it always picked the
>>>> smallest one as the reference. For example,
>>>>
>>>> model.matrix(~.,data=as.data.frame(letters[1:5]))
>>>>
>>>> will code 'a' as '0 0 0 0'. But I want to code another category as
>>>> reference, say 'b'. How to do it in R using model.matrix? Is there
>>>> other way to do it if model.matrix  has no such functionality?
>>>>
>>>> Thanks!
>>>>
>>>>
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at stat.math.ethz.ch mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>>> guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>         
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>     
>
>
> --
> Frank E Harrell Jr   Professor and Chair           School of Medicine
>                       Department of Biostatistics   Vanderbilt University
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jholtman at gmail.com  Fri Jun 29 19:13:48 2007
From: jholtman at gmail.com (jim holtman)
Date: Fri, 29 Jun 2007 13:13:48 -0400
Subject: [R] regexpr
In-Reply-To: <11363041.post@talk.nabble.com>
References: <11363041.post@talk.nabble.com>
Message-ID: <644e1f320706291013j208c3d80ye8da99221ed5781@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070629/d1ed22ba/attachment.pl 

From mvinic at gmail.com  Fri Jun 29 19:44:26 2007
From: mvinic at gmail.com (Marcus Vinicius)
Date: Fri, 29 Jun 2007 14:44:26 -0300
Subject: [R] Installing packages.
Message-ID: <c0792190706291044g7dbcbe9oc0fddfd0285122ad@mail.gmail.com>

Um texto embutido e sem conjunto de caracteres especificado associado...
Nome: n?o dispon?vel
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070629/17f7d932/attachment.pl 

From Suzan.Pool at noaa.gov  Fri Jun 29 19:45:15 2007
From: Suzan.Pool at noaa.gov (Suzan Pool)
Date: Fri, 29 Jun 2007 10:45:15 -0700
Subject: [R] modify tick labels in 3D GAM plot
Message-ID: <4685452B.2080608@noaa.gov>

Hello,

I have a GAM plot in 3D which was generated from the mgcv package 
(plot.gam) which seems to call the persp( ) function from graphics.  
This plot is one of three being plotted in the graphics window to copy 
to a manuscript.  The plot's rotation has been set to clearly show the 
response surface generated in GAM.  The resulting plot is small enough 
that the tick labels overlap tick marks, start in the plot, and overlap 
each other.  I could reduce the font size using cex, however, doing so 
would make it too small for the manuscript.  Using adj in par( ) does 
not change anything in the plot.gam( ) function, only the text( ) 
function.  The tick labels on the x-axis need adjustment to the right 
and those on the y-axis need adjustment to the left.
 
Here is the code:

library(mgcv)
gam.from.mgcv<-gam(response ~ s(var1) + s(var2, var3) + s(var4) + 
offset(var5),
    family=poisson, scale=-1, gamma=1.4, data=globecdata)
par(mfrow=c(1,3))
par(cex=1, xpd=NA)
plot(gam.from.mgcv, select=2, pers=T, theta=-65, phi=20, scale=0,
      xlab="\n\n\nLongitude", ylab="\n\nLatitude", main="",
      ticktype="detailed", expand=0.8)
par(srt=100, adj=0.5)  #angle and alignment to set for z label
text(-0.5,-0.06,"Effect\n\n")  #x,y coordinates to place z label
 
How do I adjust the tick labels?
 
Also, I would like to remove the negative signs from the tick labels on 
the x-axis for longitude.  Is there a way to use the abs( ) function for 
this?
 
Thanks,
Suzan

-- 
Suzan Pool
Oregon State University
Cooperative Institute for Marine Resources Studies


From wwwhsd at gmail.com  Fri Jun 29 19:50:12 2007
From: wwwhsd at gmail.com (Henrique Dallazuanna)
Date: Fri, 29 Jun 2007 14:50:12 -0300
Subject: [R] Installing packages.
In-Reply-To: <c0792190706291044g7dbcbe9oc0fddfd0285122ad@mail.gmail.com>
References: <c0792190706291044g7dbcbe9oc0fddfd0285122ad@mail.gmail.com>
Message-ID: <da79af330706291050h1726e341w477ca3ce6b40de3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070629/03e91705/attachment.pl 

From brown_emu at yahoo.com  Fri Jun 29 20:09:53 2007
From: brown_emu at yahoo.com (Stephen Tucker)
Date: Fri, 29 Jun 2007 11:09:53 -0700 (PDT)
Subject: [R] regexpr
In-Reply-To: <11363041.post@talk.nabble.com>
Message-ID: <914427.39695.qm@web39712.mail.mud.yahoo.com>

I think you are looking for paste().

And you can replace your for loop with lapply(), which will apply regexpr to
every element of 'mylist' (as the first argument, which is 'pattern'). 'text'
can be a vector also:

mylist <- c("MN","NY","FL")
lapply(paste(mylist,"$",sep=""),regexpr,text="Those from MN:")



--- runner <sunnyside500 at gmail.com> wrote:

> 
> Hi, 
> 
> I 'd like to match each member of a list to a target string, e.g.
> ------------------------------
> mylist=c("MN","NY","FL")
> g=regexpr(mylist[1], "Those from MN:")
> if (g>0)
> {
> "On list"
> }
> ------------------------------
> My question is:
> 
> How to add an end-of-string symbol '$' to the to-match string? so that 'M'
> won't match.
> 
> Of course, "MN$" will work, but i want to use it in a loop; "mylist[i]" is
> what i need. I tried "mylist[1]$", but didn't work. So why it doesn't
> extrapolate? How to do it?
> 
> Thanks a lot!
> -- 
> View this message in context:
> http://www.nabble.com/regexpr-tf4000743.html#a11363041
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 



 
____________________________________________________________________________________
Bored stiff? Loosen up...


From Greg.Snow at intermountainmail.org  Fri Jun 29 20:11:34 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Fri, 29 Jun 2007 12:11:34 -0600
Subject: [R] shading bar charts
In-Reply-To: <4684D8A7.5060108@sestante.net>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBA5AF97@LP-EXCHVS07.CO.IHC.COM>

The first question you should ask yourself (and really think about the
answer) is "Why do I want to do this?"

Fancy colors and shadings can detract from a plot rather than enhance
it.  The wrong choice of colors can make bars look bigger or smaller
than they really are.  Reading Tufte's "The visual Display of
Quantitative Information" and Cleveland's "The Elements of Graphing
Data" explain many of these points.

The main graphics functions in R do not do things like this because the
underlying philosophy is that the data should speak for itself and not
need fancy chartjunk.  In fact, some of us on seeing fancy artistic
additions to graphs ask: "what are they trying to hide?".

If, after thinking this through and looking at your data plotted in a
basic chart, you decide that it is still justified to use shading, and
that it enhances the plot rather than detracts from it, then the
following shows one possible approach to doing something like your
example (you will need to modify to match your data):

> library(TeachingDemos)
>
> plot.new()
> plot.window( c(.5, 3.5), c(0,3.2), yaxs='i', xaxs='i')
> subplot( image( cbind( c(1:100,99:1) ), col=heat.colors(100),
axes=FALSE),
+ 	c(0.7,1.3), c(0,1) )
> subplot( image( cbind( c(1:100,99:1) ), col=heat.colors(100),
axes=FALSE),
+ 	c(1.7,2.3), c(0,3) )
> subplot( image( cbind( c(1:100,99:1) ), col=heat.colors(100),
axes=FALSE),
+ 	c(2.7,3.3), c(0,2) )
>
> axis(1, at=1:3, label=c("A","B","C") )
> axis(2, at=pretty(1:3, 2))
> box()

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Federico Tomassini
> Sent: Friday, June 29, 2007 4:02 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] shading bar charts
> 
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
> 
> Hi alls,
> 
> i have to code a family of bar charts. After reading the doc, 
> i cannot understand if it is possible to shade the bar colors and how.
> 
> With shading i don't mean `density`. I mean something like that:
> 
> http://www.advsofteng.com/images/colorcylinder_g.png
> 
> 
> Thanks and br
> 
> - --
> Federico
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.6 (GNU/Linux)
> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org
> 
> iD8DBQFGhNini7obm7aBjHcRAuvbAJ9y5lM+VoAGdko8hH2NQjrkSfvOlACfVDsT
> msphKZGSrswwnBGEssTv4nM=
> =aEwU
> -----END PGP SIGNATURE-----
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From peterson at heritage.nv.gov  Fri Jun 29 19:51:02 2007
From: peterson at heritage.nv.gov (Eric Peterson)
Date: Fri, 29 Jun 2007 10:51:02 -0700
Subject: [R] GAM for censored data? (survival analysis)
Message-ID: <200706291751.l5THp8Z2022258@hypatia.math.ethz.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070629/e9b2c07f/attachment.pl 

From dieter.menne at menne-biomed.de  Fri Jun 29 21:48:25 2007
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Fri, 29 Jun 2007 21:48:25 +0200
Subject: [R] Print grid/ggplot to a metafile
Message-ID: <LPEJLJACLINDNMBMFAFIIEFICIAA.dieter.menne@menne-biomed.de>

Dear UseRs called Hadley, or Paul,

I am trying to print an edited ggplot2/grid graphics to a metafile. With the
commented line below it works, but when I edit the plot by uncommenting the
line, it fails, because it's illegal to have 2 graphics in a metafile. It
works with pdf, but even then I get two plots, which is a nuisance.

I found a workaround by using windows(); savePlot, but it only works in
interactive mode, not when called with something like (Windows)

rterm --no-save < printit.r

Any ideas?

Dieter

#------
library(ggplot2)
win.metafile(file="bar.emf")
mtcars$cyls = factor(mtcars$cyl,
  labels=c("four\ncylinders","six\ncylinders","eight\ncylinders"))
ggplot(mtcars, aes(x=cyls)) + geom_bar()
#grid.gedit("xaxis::labels::label.text",just=c("center","center"))
dev.off()


From anw1950 at gmail.com  Fri Jun 29 21:59:36 2007
From: anw1950 at gmail.com (Roy Wilson)
Date: Fri, 29 Jun 2007 15:59:36 -0400
Subject: [R] R-2.5.1 problem listing dataframe in GUI/CMDLINE
Message-ID: <d488515e0706291259r5cf5a5f6p3c5e63c118c0509b@mail.gmail.com>

I have a dataframe called hawk. Source file looks ok. read.table seems
ok. Can view using R editor. Again looks fine.

Now, I am new to windows version of R. When I type in 'hawk' under
Linux, I expect to see the rows listed. That isn't happening, as shown
below.

> attach(hawk)
> hawk
Error in print.matrix(as.matrix(format.data.frame(x, digits = digits,  :
        7 arguments passed to 'print.default' which requires 9
>

Tried this first in 2.5.0. Then installed 2.5.1, tried in both in R
GUI and R Cmdline. same result. Is this a bug or a mind bug of mine?
:-)


-- 
wwodbomb
email: anw1950 at gmail.com


From ligges at statistik.uni-dortmund.de  Fri Jun 29 22:38:22 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 29 Jun 2007 22:38:22 +0200
Subject: [R] Installing packages.
In-Reply-To: <c0792190706291044g7dbcbe9oc0fddfd0285122ad@mail.gmail.com>
References: <c0792190706291044g7dbcbe9oc0fddfd0285122ad@mail.gmail.com>
Message-ID: <46856DBE.4000004@statistik.uni-dortmund.de>



Marcus Vinicius wrote:
> Dear,
> 
> I'm not getting Installing packages:
> 
> 
>> install.packages(c("exactRankTests"))
> trying URL `http://cran.r-project.org/bin/windows/contrib/2.0/PACKAGES'
> Content type `text/plain' length 26129 bytes
> opened URL
> downloaded 25Kb


This means you are using R-2.0.x? This is really ancient. Please upgrade 
to a more recent version of R.

Before using function from the installed package, you have to load it:

library("exactRankTests")

Uwe Ligges



> trying URL `http://cran.r-
> project.org/bin/windows/contrib/2.0/exactRankTests_0.8-10.zip'
> Content type `application/zip' length 187723 bytes
> opened URL
> downloaded 183Kb
> 
> package 'exactRankTests' successfully unpacked and MD5 sums checked
> 
> Delete downloaded files (y/N)? y
> 
> updating HTML package descriptions
>> ? exactRankTests
> No documentation for 'exactRankTests' in specified packages and libraries:
> you could try 'help.search("exactRankTests")'
> 
> 
> 
> How do I do?
> 
> Thanks a lot.
> 
> Marcus Vinicius
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ligges at statistik.uni-dortmund.de  Fri Jun 29 22:40:39 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 29 Jun 2007 22:40:39 +0200
Subject: [R] R-2.5.1 problem listing dataframe in GUI/CMDLINE
In-Reply-To: <d488515e0706291259r5cf5a5f6p3c5e63c118c0509b@mail.gmail.com>
References: <d488515e0706291259r5cf5a5f6p3c5e63c118c0509b@mail.gmail.com>
Message-ID: <46856E47.6060007@statistik.uni-dortmund.de>



Roy Wilson wrote:
> I have a dataframe called hawk. Source file looks ok. read.table seems
> ok. Can view using R editor. Again looks fine.
> 
> Now, I am new to windows version of R. When I type in 'hawk' under
> Linux, I expect to see the rows listed. That isn't happening, as shown
> below.
> 
>> attach(hawk)
>> hawk
> Error in print.matrix(as.matrix(format.data.frame(x, digits = digits,  :
>         7 arguments passed to 'print.default' which requires 9
> 
> Tried this first in 2.5.0. Then installed 2.5.1, tried in both in R
> GUI and R Cmdline. same result. Is this a bug or a mind bug of mine?
> :-)


Quite probably you are using a new version (R-2.5.x) of R but mixing it 
with some packages for a less recent version of R. Do you have some base 
packages for less recent version of R installed in a non-standard 
library that is in the search path? .libPaths() should reveal other 
libraries.

Uwe Ligges


>


From visser_md at yahoo.com  Fri Jun 29 22:14:04 2007
From: visser_md at yahoo.com (Marco Visser)
Date: Fri, 29 Jun 2007 13:14:04 -0700 (PDT)
Subject: [R] Dominant eigenvector displayed as third (Marco Visser)
Message-ID: <973797.5430.qm@web51912.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070629/ad23a554/attachment.pl 

From spencer.graves at pdf.com  Fri Jun 29 23:03:57 2007
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 29 Jun 2007 14:03:57 -0700
Subject: [R] Dominant eigenvector displayed as third (Marco Visser)
In-Reply-To: <973797.5430.qm@web51912.mail.re2.yahoo.com>
References: <973797.5430.qm@web51912.mail.re2.yahoo.com>
Message-ID: <468573BD.2070505@pdf.com>

      There is no dominant eigenvalue:  The eigenvalues of that matrix 
are the 6 different roots of 5.  All have modulus (or absolute value) = 
1.307660.  When I raised them all to the 6th power, all 6 were 5+0i. 

      Someone else can tell us why this is, but this should suffice as 
an initial answer to your question. 

      Hope this helps. 
      Spencer Graves

Marco Visser wrote:
> Dear R users & Experts,
>
> This is just a curiousity, I was wondering why the dominant eigenvetor and eigenvalue 
> of the following matrix is given as the third. I guess this could complicate automatic selection 
> procedures. 
>
> 0    0    0    0    0    5
> 1    0    0    0    0    0
> 0    1    0    0    0    0
> 0    0    1    0    0    0
> 0    0    0    1    0    0
> 0    0    0    0    1    0
>
> Please copy & paste the following into R;
>
> a=c(0,0,0,0,0,5,1,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0)
> mat=matrix(a, ncol=6,byrow=T)
> eigen(mat)
>
> The matrix is a population matrix for a plant pathogen (Powell et al 2005).
>
> Basically I would really like to know why this happens so I will know if it can occur 
> again. 
>
> Thanks for any comments,
>
> Marco Visser
>
>
> Comment: In Matlab the the dominant eigenvetor and eigenvalue 
> of the described matrix are given as the sixth. Again no idea why.
>
> reference
>
> J. A. Powell, I. Slapnicar and W. van der Werf. Epidemic spread of a lesion-forming 
> plant pathogen - analysis of a mechanistic model with infinite age structure. (2005) 
> Linear Algebra and its Applications 298. p 117-140.  
>
>
>
>
>        
> ____________________________________________________________________________________Ready for the edge of your seat? 
> Check out tonight's top picks on Yahoo! TV. 
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From p.dalgaard at biostat.ku.dk  Fri Jun 29 23:09:37 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 29 Jun 2007 23:09:37 +0200
Subject: [R] Dominant eigenvector displayed as third (Marco Visser)
In-Reply-To: <973797.5430.qm@web51912.mail.re2.yahoo.com>
References: <973797.5430.qm@web51912.mail.re2.yahoo.com>
Message-ID: <46857511.4080602@biostat.ku.dk>

Marco Visser wrote:
> Dear R users & Experts,
>
> This is just a curiousity, I was wondering why the dominant eigenvetor and eigenvalue 
> of the following matrix is given as the third. I guess this could complicate automatic selection 
> procedures. 
>
> 0    0    0    0    0    5
> 1    0    0    0    0    0
> 0    1    0    0    0    0
> 0    0    1    0    0    0
> 0    0    0    1    0    0
> 0    0    0    0    1    0
>
> Please copy & paste the following into R;
>
> a=c(0,0,0,0,0,5,1,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0)
> mat=matrix(a, ncol=6,byrow=T)
> eigen(mat)
>
> The matrix is a population matrix for a plant pathogen (Powell et al 2005).
>
> Basically I would really like to know why this happens so I will know if it can occur 
> again. 
>
> Thanks for any comments,
>
> Marco Visser
>
>
> Comment: In Matlab the the dominant eigenvetor and eigenvalue 
> of the described matrix are given as the sixth. Again no idea why.
>   
????

I get

 > eigen(mat)$values
[1] -0.65383+1.132467i -0.65383-1.132467i  0.65383+1.132467i  
0.65383-1.132467i
[5] -1.30766+0.000000i  1.30766+0.000000i
 > Mod(eigen(mat)$values)
[1] 1.307660 1.307660 1.307660 1.307660 1.307660 1.307660

So all the eigenvalues are equal in modulus. What makes you think one of 
them is "dominant"?


From David.Duffy at qimr.edu.au  Fri Jun 29 23:37:28 2007
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Sat, 30 Jun 2007 07:37:28 +1000 (EST)
Subject: [R] exaustive subgrouping or combination
In-Reply-To: <4684AADA.5030609@biostat.ku.dk>
References: <mailman.13.1183024805.4590.r-help@stat.math.ethz.ch>
	<Pine.LNX.4.64.0706290757300.25798@orpheus.qimr.edu.au>
	<4684AADA.5030609@biostat.ku.dk>
Message-ID: <Pine.LNX.4.64.0706300730250.26396@orpheus.qimr.edu.au>

On Fri, 29 Jun 2007, Peter Dalgaard wrote:

> David Duffy wrote:
>>> Waverley <waverley.paloalto at gmail.com> asked:
>>> 
>>> Dear Colleagues,
>>> 
>>> I am looking for a package or previous implemented R to subgroup and
>>> exaustively divide a vector of squence into 2 groups.
>>> 
>>> -- 
>>> Waverley @ Palo Alto
>>> 
>> 
>> Google "[R] Generating all possible partitions" and you will find some R 
>> code
>> from 2002 or so.
>>
>> 
> In 2002 this wasn't already in R. These days, help(combn) is more to the 
> point:
>
> mn <- sort(zapsmall(combn(sleep$extra,10,mean)))
> plot(unique(mn),table(mn))
> abline(v=mean(sleep$extra[1:10]))
>

As I read it, the original query is about partitioning the set eg
((1 2) 3) ((1 3) 2) (1 (2 3)).

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v


From jasoncbarnhart at msn.com  Fri Jun 29 23:46:16 2007
From: jasoncbarnhart at msn.com (Jason Barnhart)
Date: Fri, 29 Jun 2007 14:46:16 -0700
Subject: [R] Function call within a function.
References: <6373.48861.qm@web32813.mail.mud.yahoo.com>
Message-ID: <BAY116-DAV1019DBD8A86C281D70381ECF080@phx.gbl>

[SNIP]

> 
> This has been very helpful though I still do not
> understand why one must call nts$cda using the
> eval(parse()) command.  Is it because nts is created
> within the ukn environment?  

You don't *have* to use the eval(parse()).  This works just as 
well: mysum <- nts$cda.

However, it appeared to me that you wanted the flexibility to return 
different values depending on the function call.

results <- ukn(dd1, "a", "b", "nts$cda")
results2 <- ukn(dd1, "a", "b", "nts$cdb")

The eval/parse allows you to convert text into objects through 
eval().  So the "nam1" argument is specified by the user to return 
the object of choice.

#Here's a simple example of eval/parse that will run
#from the prompt.
t <- "ls()"
t
parse(text=t)
eval(parse(text=t))

I think Dan Nordlund's comment "Functions generally shouldn't 
require knowing how other functions work, they should only rely 
on what value is returned." is more useful here.  Since R 
provides many ways to accomplish the same thing you can avoid 
eval/parse altogether. 

Note that his solution returned a vector of three values where as 
mine returned a list.  It's unclear which you prefer, and it may 
be neither (especially as this was just a simple example).  

In this simple case, I would return a list with named elements 
and expect all objects returned from this function to have the 
same attributes. Then either "cda" or "cdb" could be used as 
necessary.

As an example, consider a plotting function that requires both 
"cda" and "cdb" in order to plot them simultaneously.

[SNIP]


From ted.harding at nessie.mcc.ac.uk  Fri Jun 29 23:47:05 2007
From: ted.harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 29 Jun 2007 22:47:05 +0100 (BST)
Subject: [R] Dominant eigenvector displayed as third (Marco Visser)
In-Reply-To: <46857511.4080602@biostat.ku.dk>
Message-ID: <XFMail.070629224705.ted.harding@nessie.mcc.ac.uk>

On 29-Jun-07 21:09:37, Peter Dalgaard wrote:
> Marco Visser wrote:
>> This is just a curiousity, I was wondering why the dominant
>> eigenvetor and eigenvalue of the following matrix is given
>> as the third. I guess this could complicate automatic selection 
>> procedures. 
>>
>> 0    0    0    0    0    5
>> 1    0    0    0    0    0
>> 0    1    0    0    0    0
>> 0    0    1    0    0    0
>> 0    0    0    1    0    0
>> 0    0    0    0    1    0
>>[...]
>> Comment: In Matlab the the dominant eigenvetor and eigenvalue 
>> of the described matrix are given as the sixth. Again no idea why.
>>   
> ????
> 
> I get
> 
>  > eigen(mat)$values
> [1] -0.65383+1.132467i -0.65383-1.132467i  0.65383+1.132467i  
> 0.65383-1.132467i
> [5] -1.30766+0.000000i  1.30766+0.000000i
>  > Mod(eigen(mat)$values)
> [1] 1.307660 1.307660 1.307660 1.307660 1.307660 1.307660
> 
> So all the eigenvalues are equal in modulus. What makes you think
> one of them is "dominant"?

When I run it I get eigenvectors 3 and 6 both purely real.
It may be that Marco has confused this with "dominant".

Also, the eigenvalues of these two are real, and have the largest
real parts (+/- 1.3076605).

All others have complex eigenvalues, of which the real parts are
+/- 0.6538302.

It may be that Marco has been misled by this, perceiving the real
part rather than both real and complex parts, and being led to think
that the largest real part corresponds to the largest eigenvalue.

As has been clearly pointed out, this is not the way to look at it!

Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 29-Jun-07                                       Time: 22:47:01
------------------------------ XFMail ------------------------------


From bolker at zoo.ufl.edu  Fri Jun 29 23:49:43 2007
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Fri, 29 Jun 2007 17:49:43 -0400
Subject: [R] Dominant eigenvector displayed as third (Marco Visser)
Message-ID: <46857E77.3020204@zoo.ufl.edu>


 >
 > Marco Visser wrote:
 > > Dear R users & Experts,
 > >
 > > This is just a curiousity, I was wondering why the dominant 
eigenvetor and
eigenvalue
 > > of the following matrix is given as the third. I guess this could 
complicate
automatic selection
 > > procedures.

 > >
 > > Comment: In Matlab the the dominant eigenvetor and eigenvalue
 > > of the described matrix are given as the sixth. Again no idea why.
 > >   
 > ????
 >

  If you want the eigenvalue with the largest REAL PART to be first
(which will be "dominant" in the sense of population dynamics/stability)
then you can just reorder according to

order(-Re(eigen(mat)$values))

  About MATLAB: my guess is that it, too, is ordering
according to modulus -- since the moduli are essentially
all the same, the order will be more or less random
across programs and platforms
(on my Linux machine I got the "dominant" (=largest real part)
eigenvector/value pair 6th, too).

  Ben Bolker


From p.dalgaard at biostat.ku.dk  Fri Jun 29 23:54:09 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 29 Jun 2007 23:54:09 +0200
Subject: [R] exaustive subgrouping or combination
In-Reply-To: <Pine.LNX.4.64.0706300730250.26396@orpheus.qimr.edu.au>
References: <mailman.13.1183024805.4590.r-help@stat.math.ethz.ch>	<Pine.LNX.4.64.0706290757300.25798@orpheus.qimr.edu.au>	<4684AADA.5030609@biostat.ku.dk>
	<Pine.LNX.4.64.0706300730250.26396@orpheus.qimr.edu.au>
Message-ID: <46857F81.40106@biostat.ku.dk>

David Duffy wrote:
> On Fri, 29 Jun 2007, Peter Dalgaard wrote:
>
>   
>> David Duffy wrote:
>>     
>>>> Waverley <waverley.paloalto at gmail.com> asked:
>>>>
>>>> Dear Colleagues,
>>>>
>>>> I am looking for a package or previous implemented R to subgroup and
>>>> exaustively divide a vector of squence into 2 groups.
>>>>
>>>> -- 
>>>> Waverley @ Palo Alto
>>>>
>>>>         
>>> Google "[R] Generating all possible partitions" and you will find some R 
>>> code
>>> from 2002 or so.
>>>
>>>
>>>       
>> In 2002 this wasn't already in R. These days, help(combn) is more to the 
>> point:
>>
>> mn <- sort(zapsmall(combn(sleep$extra,10,mean)))
>> plot(unique(mn),table(mn))
>> abline(v=mean(sleep$extra[1:10]))
>>
>>     
>
> As I read it, the original query is about partitioning the set eg
> ((1 2) 3) ((1 3) 2) (1 (2 3)).
>
>   
Yes, and

 > combn(3,2)
     [,1] [,2] [,3]
[1,]    1    1    2
[2,]    2    3    3

gives you the first group of each of the three partitions


From Jacqueline.Spilak at EC.gc.ca  Sat Jun 30 00:20:32 2007
From: Jacqueline.Spilak at EC.gc.ca (Spilak,Jacqueline [Edm])
Date: Fri, 29 Jun 2007 16:20:32 -0600
Subject: [R] Assign name to a name
Message-ID: <4A6AB38B55B49C44A22E021A83CBEDDB015EB9FF@sr-pnr-exch3.prairie.int.ec.gc.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070629/b4b69cc2/attachment.pl 

From mardones.p at gmail.com  Sat Jun 30 03:34:38 2007
From: mardones.p at gmail.com (Pedro Mardones)
Date: Fri, 29 Jun 2007 21:34:38 -0400
Subject: [R] PCA + xValidation
Message-ID: <83dca7860706291834m76999cd6w53fb0ae47e946558@mail.gmail.com>

Dear R users;
Is there any package or function that I can use to perform LOOCV with
prcomp? Basically I want to use that approach to get an idea of the
"optimal" number of PC.
Thanks for any idea
PM


From pkphlam at gmail.com  Sat Jun 30 03:58:07 2007
From: pkphlam at gmail.com (Patrick Lam)
Date: Fri, 29 Jun 2007 18:58:07 -0700
Subject: [R] Gamma scale parameter in GEE?
Message-ID: <4c8e73360706291858g35d373fbvd8a49de70c6472f8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070629/cf166177/attachment.pl 

From mullera at mcmaster.ca  Sat Jun 30 05:11:11 2007
From: mullera at mcmaster.ca (Andrew Muller)
Date: Fri, 29 Jun 2007 23:11:11 -0400
Subject: [R] Problem installing RGTK2 on ubuntu 7.04
Message-ID: <1183173071.30572.12.camel@happy>

Hello, all

I am trying to install RGTK2 on my Ubuntu 7.04 system. The installation
fails with a message that RGtk2 requires GTK 2.8. As far as I can tell I
have GTK+ 2.10.11 installed. Can anyone suggest a way to proceed? 

Thanks very much. 

Here is the failed installation:

> install.packages("RGtk2")
Warning in install.packages("RGtk2") : argument 'lib' is missing:
using /usr/local/lib/R/site-library
--- Please select a CRAN mirror for use in this session ---
Loading Tcl/Tk interface ... done
trying URL 'http://probability.ca/cran/src/contrib/RGtk2_2.10.11.tar.gz'
Content type 'application/x-tar' length 2329776 bytes
opened URL
==================================================
downloaded 2275Kb

* Installing *source* package 'RGtk2' ...
checking for pkg-config... /usr/bin/pkg-config
checking pkg-config is at least version 0.9.0... yes
checking for GTK... configure: error: GTK version 2.8.0 required
ERROR: configuration failed for package 'RGtk2'
** Removing '/usr/local/lib/R/site-library/RGtk2'

The downloaded packages are in
        /tmp/RtmpTMtchC/downloaded_packages
Warning message:
installation of package 'RGtk2' had non-zero exit status in:
install.packages("RGtk2") 
> 

I am using  R version 2.4.1 (2006-12-18) on a Ubuntu 7.04 system

mullera at happy:~/sandbox/R$ uname -a
Linux happy 2.6.20-16-generic #2 SMP Thu Jun 7 20:19:32 UTC 2007 i686
GNU/Linux

Andrew Muller
McMaster University/Economics
Hamilton, Ontario, Canada


From gongyi.liao at gmail.com  Sat Jun 30 06:14:48 2007
From: gongyi.liao at gmail.com (=?UTF-8?Q?=E5=BB=96=E5=AE=AE=E6=AF=85?=)
Date: Sat, 30 Jun 2007 12:14:48 +0800
Subject: [R] Problem installing RGTK2 on ubuntu 7.04
In-Reply-To: <1183173071.30572.12.camel@happy>
References: <1183173071.30572.12.camel@happy>
Message-ID: <1183176888.17639.0.camel@LiaoLianFa>

On Fri, 2007-06-29 at 23:11 -0400, Andrew Muller wrote:
> Hello, all
> 
> I am trying to install RGTK2 on my Ubuntu 7.04 system. The installation
> fails with a message that RGtk2 requires GTK 2.8. As far as I can tell I
> have GTK+ 2.10.11 installed. Can anyone suggest a way to proceed? 
> 
> Thanks very much. 
> 
> Here is the failed installation:
> 
> > install.packages("RGtk2")
> Warning in install.packages("RGtk2") : argument 'lib' is missing:
> using /usr/local/lib/R/site-library
> --- Please select a CRAN mirror for use in this session ---
> Loading Tcl/Tk interface ... done
> trying URL 'http://probability.ca/cran/src/contrib/RGtk2_2.10.11.tar.gz'
> Content type 'application/x-tar' length 2329776 bytes
> opened URL
> ==================================================
> downloaded 2275Kb
> 
> * Installing *source* package 'RGtk2' ...
> checking for pkg-config... /usr/bin/pkg-config
> checking pkg-config is at least version 0.9.0... yes
> checking for GTK... configure: error: GTK version 2.8.0 required
> ERROR: configuration failed for package 'RGtk2'
> ** Removing '/usr/local/lib/R/site-library/RGtk2'
> 
> The downloaded packages are in
>         /tmp/RtmpTMtchC/downloaded_packages
> Warning message:
> installation of package 'RGtk2' had non-zero exit status in:
> install.packages("RGtk2") 
> > 
> 
> I am using  R version 2.4.1 (2006-12-18) on a Ubuntu 7.04 system
> 
> mullera at happy:~/sandbox/R$ uname -a
> Linux happy 2.6.20-16-generic #2 SMP Thu Jun 7 20:19:32 UTC 2007 i686
> GNU/Linux
> 
> Andrew Muller
> McMaster University/Economics
> Hamilton, Ontario, Canada
> 

apt-get install libgtk2.0-dev
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From edd at debian.org  Sat Jun 30 06:19:50 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 29 Jun 2007 23:19:50 -0500
Subject: [R] Problem installing RGTK2 on ubuntu 7.04
In-Reply-To: <1183173071.30572.12.camel@happy>
References: <1183173071.30572.12.camel@happy>
Message-ID: <18053.55782.9765.869977@basebud.nulle.part>


On 29 June 2007 at 23:11, Andrew Muller wrote:
| I am trying to install RGTK2 on my Ubuntu 7.04 system. The installation
| fails with a message that RGtk2 requires GTK 2.8. As far as I can tell I
| have GTK+ 2.10.11 installed. Can anyone suggest a way to proceed? 

Something is not right in your example below. Do you have the required -dev
packages installed?  For Debian's r-cran-rgtk2 (which you could install from
Ubuntu, albeit in a slightly older version, via 'sudo apt-get install
r-cran-rgtk2'), I use the following Build-Depends:

  libgtk2.0-dev (>= 2.10.12-1), libglade2-dev, libpango1.0-dev, libcairo2-dev
 
If you have all that installed, it should just work fine (and I do use the
direct-from-CRAN method on my computers at work, and have just upgraded RGtk2
there a few days ago).

| I am using  R version 2.4.1 (2006-12-18) on a Ubuntu 7.04 system

FYI there are Ubuntu backports at CRAN. You could get R 2.5.0 without any
effort, and presumably in a few days R 2.5.1 once the porters build the
package as I've put 2.5.1 into Debian.

Hth, Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From amirhendi at yahoo.com  Sat Jun 30 06:33:45 2007
From: amirhendi at yahoo.com (Amir_17)
Date: Fri, 29 Jun 2007 21:33:45 -0700 (PDT)
Subject: [R] How can i compute error?
Message-ID: <241920.96299.qm@web37905.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070629/6d23edf9/attachment.pl 

From brown_emu at yahoo.com  Sat Jun 30 07:20:06 2007
From: brown_emu at yahoo.com (Stephen Tucker)
Date: Fri, 29 Jun 2007 22:20:06 -0700 (PDT)
Subject: [R] Assign name to a name
In-Reply-To: <4A6AB38B55B49C44A22E021A83CBEDDB015EB9FF@sr-pnr-exch3.prairie.int.ec.gc.ca>
Message-ID: <523378.7539.qm@web39707.mail.mud.yahoo.com>

You can just create another variable which contains the "names" you want:


## let
Year <- c(rep(1999,2),rep(2000,2),rep(2001,3))

## one alternative
getYearCode1 <- function(yr) {
  # yr can be a vector
  ifelse(yr==1999,"Year1",
         ifelse(yr==2000,"Year2",
                ifelse(yr==2001,"Year3")))
}

## another alternative
## more appropriate since you probably want 
## a single value returned
getYearCode2 <- function(yr) {
  # yr is a single value
  switch(as.character(yr),
         `1999` = "Year1",
         `2000` = "Year2",
         `2001` = "Year3")
}

## Application:
## single value
getYearCode1(Year[1])
getYearCode2(Year[1])
## on a vector
dataset$YearCode <- getYearCode1(Year)
# or
dataset$YearCode <- sapply(Year,getYearCode2)

## another option is match()
df <- data.frame(Year=c(1999,2000,2001),YearCode=c("Year1","Year2","Year3"))
dataset$YearCode <- df[match(Year,df[,"Year"]),"YearCode"]

##========================================================
## reading from console
subset(dataset,YearCode==scan("",what=""))
subset(dataset,
   YearCode=={x <- function() {cat("YrCode: ");readline("")}; x()})

## or as a function
f <- function(x) {
  g <- function() {
    x <- function() {
      cat("YearCode: ");
      readline("")
    }
    subset(dataset,YearCode==x())
  }
}
getSubset1 <- f(dataset)

## type at console. You will be prompted:
datayear <- getSubset1()

## but easier is
f <- function(x) {
  g <- function(y)
    subset(x,YearCode==y)
}
getSubset2 <- f(dataset)

## type at prompt
datayear <- getSubset1(1999)


--- "Spilak,Jacqueline [Edm]" <Jacqueline.Spilak at EC.gc.ca> wrote:

> I would like to know how I can assign a name to a name.  I have a
> dataset that has different years in it.  I am writing scripts using R
> and I would like to give a month a generic name and then use the generic
> name to do different analysis.  The reason for the generic name would be
> so that I only have to change one thing if I wanted to change the year.
> For example.
> Year1 = 1999
> datayear <- subset(dataset, Year = Year1)
> I would want  to subset for whatever year is in "Year1".  I am not sure
> if R does this but it would be great if it does.  Is there also anyway
> for R to ask the user for the variable in the console without going into
> the script and then use whatever the user puts in. Thanks for the help.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From tyrosine at gmail.com  Sat Jun 30 12:44:06 2007
From: tyrosine at gmail.com (Paul Laub)
Date: Sat, 30 Jun 2007 05:44:06 -0500
Subject: [R] Determining whether a function's return value is assigned
Message-ID: <aba1c4400706300344m3a62826scf6752d6201eb0da@mail.gmail.com>

Dear all,

Does R offer a means by which a function can determine
whether its return value is assigned? I am using R
2.4.1 for Windows.

Suppose what I am looking for is called
"return.value.assigned". Then one might use it like
this

    myfunction <- function () {
        # Create bigobject here

        if (return.value.assigned()) {
            bigobject
        } else {
            summary(bigobject)
        }
    }

and

    x <- myfunction()  # bigobject is assigned

    myfunction()       # summary of bigobject is printed

Octave and MATLAB have the nargout function that does
what I want, and Perl has the wantarray function
detecting the context in which a function is called.
Perhaps match.call() can be made to do what I want,
but, if so, I don't see it in reading the
documentation.

Sincerely,

Paul Laub


From stefan.duke at gmail.com  Sat Jun 30 13:07:01 2007
From: stefan.duke at gmail.com (stefan lhachimi)
Date: Sat, 30 Jun 2007 13:07:01 +0200
Subject: [R] Importing Excel file with merged cells
Message-ID: <a211af3b0706300407i55dd0a82rda560e233d3ceba4@mail.gmail.com>

Dear all,

I have a problem with importing an excel file into R. I can open the
file easily (either saving it as a CSV or using RODBC). But the
original file is using merged cell in its first column, which gives
the name of the observation. (I am dealing with repeated measurements
for the same observation)
So when I open the dataframe in R it looks like this

Col1    Col2 Col3
name1 val1 val2
          val3 val4
....
name2  val5  val6
            val7  val8

Everything is fine, except that the name of the observation is on the
first line and the following are empty. Until a new observation
starts, where a new name appears in the respective row and the
following rows are empty and so on.

The number of rows is fixed for each observation. How can I fill the
column with the proper name (eg take the first string in this column
until you hit a row with a new string, then take this string and go on
until the next string).

Or read the excel file in such a way, that when cells are merged that
when importing it to R all cells created from this merged cell should
have the same content.

Unfortunately, I cannot change the lay-out of the original excel file
as it comes from an commercial data-base and I will have to use it
quite often.

I have the gut feeling that there might be an easy solution out there
as it does not seem to be an uncommon problem.

So if you have  hint or a solution I greatly appreciated it.
Thanks and a nice weekend,
Stefan


From ck at altaica.de  Fri Jun 29 21:32:39 2007
From: ck at altaica.de (Christoph Krammer)
Date: Fri, 29 Jun 2007 21:32:39 +0200
Subject: [R] Plots from categorial data
Message-ID: <009a01c7ba84$416b9f10$0f00a8c0@sydney>

Software zur Erkennung von "Spam" auf dem Rechner

    hypatia.math.ethz.ch

hat die eingegangene E-mail als m??gliche "Spam"-Nachricht identifiziert.
Die urspr??ngliche Nachricht wurde an diesen Bericht angeh??ngt, so dass
Sie sie anschauen k??nnen (falls es doch eine legitime E-Mail ist) oder
??hnliche unerw??nschte Nachrichten in Zukunft markieren k??nnen.
Bei Fragen zu diesem Vorgang wenden Sie sich bitte an

    the administrator of that system

Vorschau: Hello everybody, I want to use R to generate plots from categorial
   data. The data contains results from OCR scans over images with are preprocessed
   by different image filtering techniques. A small sample data set looks as
   following: [...] 

Inhaltsanalyse im Detail:   (5.5 Punkte, 5.0 ben??tigt)

Pkte Regelname              Beschreibung
---- ---------------------- --------------------------------------------------
 0.0 DKIM_POLICY_SIGNSOME   Domain Keys Identified Mail: policy says domain
                            signs some mails
 1.0 BAYES_60               BODY: Spamwahrscheinlichkeit nach Bayes-Test: 60-80%
                            [score: 0.7481]
 4.5 AWL                    AWL: From: address is in the auto white-list


-------------- next part --------------
An embedded message was scrubbed...
From: "Christoph Krammer" <ck at altaica.de>
Subject: Plots from categorial data
Date: Fri, 29 Jun 2007 21:32:39 +0200
Size: 3027
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070629/fafb8ed3/attachment.mht 

From stefan.duke at gmail.com  Sat Jun 30 14:17:30 2007
From: stefan.duke at gmail.com (stefan lhachimi)
Date: Sat, 30 Jun 2007 14:17:30 +0200
Subject: [R] Importing Excel file that has merged cells
Message-ID: <a211af3b0706300517m5767c57dg2e674bbdbefee3f4@mail.gmail.com>

Dear all,

I have a problem with importing an excel file into R. I can open the
file easily (either saving it as a CSV or using RODBC). But the
original file is using merged cell in its first column, which gives
the name of the observation. (I am dealing with repeated measurements
for the same observation)
So when I open the dataframe in R it looks like this

Col1    Col2 Col3
name1 val1 val2
         val3 val4
....
name2  val5  val6
           val7  val8

Everything is fine, except that the name of the observation is on the
first line and the following are empty. Until a new observation
starts, where a new name appears in the respective row and the
following rows are empty and so on.

The number of rows is fixed for each observation. How can I fill the
column with the proper name (eg take the first string in this column
until you hit a row with a new string, then take this string and go on
until the next string).

Or read the excel file in such a way, that when cells are merged that
when importing it to R all cells created from this merged cell should
have the same content.

Unfortunately, I cannot change the lay-out of the original excel file
as it comes from an commercial data-base and I will have to use it
quite often.

I have the gut feeling that there might be an easy solution out there
as it does not seem to be an uncommon problem.

So if you have  hint or a solution I greatly appreciated it.
Thanks and a nice weekend,
Stefan


From mullera at mcmaster.ca  Sat Jun 30 14:45:06 2007
From: mullera at mcmaster.ca (Andrew Muller)
Date: Sat, 30 Jun 2007 08:45:06 -0400
Subject: [R]  Problem installing RGTK2 on ubuntu 7.04
Message-ID: <1183207506.5495.3.camel@happy>


Thanks for the help.  I installed libgtk2.0-dev and RGtk2 is being
installed as I write.

Andrew Muller
McMaster University/Economics


From Lhachimi at demogr.mpg.de  Sat Jun 30 15:18:04 2007
From: Lhachimi at demogr.mpg.de (Lhachimi, Stefan)
Date: Sat, 30 Jun 2007 15:18:04 +0200
Subject: [R] Importing an Excel file that has merged cells
Message-ID: <8B08A3A1EA7AAC41BE24C750338754E60215DAF7@HERMES.demogr.mpg.de>

Dear all,

I have a problem with importing an excel file into R. I can open the
file easily (either saving it as a CSV or using RODBC). But the
original file is using merged cell in its first column, which gives
the name of the observation. (I am dealing with repeated measurements
for the same observation)
So when I open the dataframe in R it looks like this

Col1    Col2 Col3
name1 val1 val2
      val3 val4
....
name2  val5  val6
       val7  val8

Everything is fine, except that the name of the observation is on the
first line and the following rows are empty. Until a new observation
starts, where a new name appears in the respective row and the
following rows are empty and so on.

The number of rows is fixed for each observation. How can I fill the
column with the proper name (eg take the first string in this column
until you hit a row with a new string, then take this string and go on
until the next string).

Or read the excel file in such a way, that when cells are merged that
when importing it to R all cells created from this merged cell should
have the same content.

Unfortunately, I cannot change the lay-out of the original excel file
as it comes from an commercial data-base and I will have to use it
quite often.

I have the gut feeling that there might be an easy solution out there
as it does not seem to be an uncommon problem.

So if you have  hint or a solution I greatly appreciated it.
Thanks and a nice weekend,

Stefan


----------
This mail has been sent through the MPI for Demographic Rese...{{dropped}}


From jholtman at gmail.com  Sat Jun 30 15:49:56 2007
From: jholtman at gmail.com (jim holtman)
Date: Sat, 30 Jun 2007 09:49:56 -0400
Subject: [R] Importing an Excel file that has merged cells
In-Reply-To: <8B08A3A1EA7AAC41BE24C750338754E60215DAF7@HERMES.demogr.mpg.de>
References: <8B08A3A1EA7AAC41BE24C750338754E60215DAF7@HERMES.demogr.mpg.de>
Message-ID: <644e1f320706300649o5dab4fa0g471be1e05ae16a59@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070630/5cb1815f/attachment.pl 

From eric_zoukekang at yahoo.fr  Sat Jun 30 16:00:20 2007
From: eric_zoukekang at yahoo.fr (eric zoukekang)
Date: Sat, 30 Jun 2007 14:00:20 +0000 (GMT)
Subject: [R] import data
Message-ID: <867302.28409.qm@web26615.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070630/5416cdb9/attachment.pl 

From eric_zoukekang at yahoo.fr  Sat Jun 30 16:00:20 2007
From: eric_zoukekang at yahoo.fr (eric zoukekang)
Date: Sat, 30 Jun 2007 14:00:20 +0000 (GMT)
Subject: [R] import data
Message-ID: <867302.28409.qm@web26615.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070630/5416cdb9/attachment-0001.pl 

From ligges at statistik.uni-dortmund.de  Sat Jun 30 15:58:37 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 30 Jun 2007 15:58:37 +0200
Subject: [R] Determining whether a function's return value is assigned
In-Reply-To: <aba1c4400706300344m3a62826scf6752d6201eb0da@mail.gmail.com>
References: <aba1c4400706300344m3a62826scf6752d6201eb0da@mail.gmail.com>
Message-ID: <4686618D.7090301@statistik.uni-dortmund.de>



Paul Laub wrote:
> Dear all,
> 
> Does R offer a means by which a function can determine
> whether its return value is assigned? I am using R
> 2.4.1 for Windows.

Short answer: No.
Long answer: You want to have a class for the object called "bigobject" 
below and a print/show method that provides the summary for objects of 
that class.

Uwe Ligges





> 
> Suppose what I am looking for is called
> "return.value.assigned". Then one might use it like
> this
> 
>     myfunction <- function () {
>         # Create bigobject here
> 
>         if (return.value.assigned()) {
>             bigobject
>         } else {
>             summary(bigobject)
>         }
>     }
> 
> and
> 
>     x <- myfunction()  # bigobject is assigned
> 
>     myfunction()       # summary of bigobject is printed
> 
> Octave and MATLAB have the nargout function that does
> what I want, and Perl has the wantarray function
> detecting the context in which a function is called.
> Perhaps match.call() can be made to do what I want,
> but, if so, I don't see it in reading the
> documentation.
> 
> Sincerely,
> 
> Paul Laub
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From stefan.duke at gmail.com  Sat Jun 30 16:03:44 2007
From: stefan.duke at gmail.com (stefan lhachimi)
Date: Sat, 30 Jun 2007 16:03:44 +0200
Subject: [R] Importing an Excel file that has merged cells
In-Reply-To: <644e1f320706300649o5dab4fa0g471be1e05ae16a59@mail.gmail.com>
References: <8B08A3A1EA7AAC41BE24C750338754E60215DAF7@HERMES.demogr.mpg.de>
	<644e1f320706300649o5dab4fa0g471be1e05ae16a59@mail.gmail.com>
Message-ID: <a211af3b0706300703g71198f82t52aac1ba6e764fe6@mail.gmail.com>

Hi Jim,
it looks perfect!
Thanx a lot!
Have a nice weekend,
Stefan


On 6/30/07, jim holtman <jholtman at gmail.com> wrote:
> I think this does what you want using the 'na.locf' function is zoo:
>
> x <- read.csv('/tote.csv', header=FALSE, skip=4)
> # fill blanks in name column with NAs
> is.na(x$V2) <- x$V2 == ""
> # load the 'zoo' library for the function na.locf
> require(zoo)
> x$V1 <- na.locf(x$V1)  # key
> x$V2 <- na.locf(x$V2)  # name
> head(x,30)
>
>
>
> On 6/30/07, Lhachimi, Stefan <Lhachimi at demogr.mpg.de> wrote:
> >
> > Dear all,
> >
> > I have a problem with importing an excel file into R. I can open the
> > file easily (either saving it as a CSV or using RODBC). But the
> > original file is using merged cell in its first column, which gives
> > the name of the observation. (I am dealing with repeated measurements
> > for the same observation)
> > So when I open the dataframe in R it looks like this
> >
> > Col1    Col2 Col3
> > name1 val1 val2
> >      val3 val4
> > ....
> > name2  val5  val6
> >       val7  val8
> >
> > Everything is fine, except that the name of the observation is on the
> > first line and the following rows are empty. Until a new observation
> > starts, where a new name appears in the respective row and the
> > following rows are empty and so on.
> >
> > The number of rows is fixed for each observation. How can I fill the
> > column with the proper name (eg take the first string in this column
> > until you hit a row with a new string, then take this string and go on
> > until the next string).
> >
> > Or read the excel file in such a way, that when cells are merged that
> > when importing it to R all cells created from this merged cell should
> > have the same content.
> >
> > Unfortunately, I cannot change the lay-out of the original excel file
> > as it comes from an commercial data-base and I will have to use it
> > quite often.
> >
> > I have the gut feeling that there might be an easy solution out there
> > as it does not seem to be an uncommon problem.
> >
> > So if you have  hint or a solution I greatly appreciated it.
> > Thanks and a nice weekend,
> >
> > Stefan
> >
> >
> > ----------
> > This mail has been sent through the MPI for Demographic Rese...{{dropped}}
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
>
> --
> Jim Holtman
> Cincinnati, OH
> +1 513 646 9390
>
> What is the problem you are trying to solve?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mvinic at gmail.com  Sat Jun 30 16:41:55 2007
From: mvinic at gmail.com (Marcus Vinicius)
Date: Sat, 30 Jun 2007 11:41:55 -0300
Subject: [R] Standard Probability Distributions.
Message-ID: <c0792190706300741j458ed50dm2432b655ffbac794@mail.gmail.com>

Um texto embutido e sem conjunto de caracteres especificado associado...
Nome: n?o dispon?vel
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070630/6d94caca/attachment.pl 

From rvaradhan at jhmi.edu  Sat Jun 30 18:10:23 2007
From: rvaradhan at jhmi.edu (RAVI VARADHAN)
Date: Sat, 30 Jun 2007 12:10:23 -0400
Subject: [R] Dominant eigenvector displayed as third (Marco Visser)
In-Reply-To: <468573BD.2070505@pdf.com>
References: <973797.5430.qm@web51912.mail.re2.yahoo.com>
	<468573BD.2070505@pdf.com>
Message-ID: <fbe9862a11848.4686482f@johnshopkins.edu>

Yes, Spencer, your observation is correct, because the characeristic equation det(A - \lambda*I) is a sixth degree polynomial: \lambda^6 - 5 = 0.  So the eigenvalues are the complex numbers (generally) that are located at equal angles on the circle of radius 5^(1/6), at angles 2*pi*k/6, where k runs from 0 to 5.  Thus, the roots are:

z_k = 5^(1/6) * exp(i * 2*pi*k/6), k= 0, 1, ..., 5.

where i = sqrt(-1).

Ravi.

----- Original Message -----
From: Spencer Graves <spencer.graves at pdf.com>
Date: Friday, June 29, 2007 6:51 pm
Subject: Re: [R] Dominant eigenvector displayed as third (Marco Visser)
To: Marco Visser <visser_md at yahoo.com>
Cc: r-help at stat.math.ethz.ch


>       There is no dominant eigenvalue:  The eigenvalues of that matrix 
> 
>  are the 6 different roots of 5.  All have modulus (or absolute value) 
> = 
>  1.307660.  When I raised them all to the 6th power, all 6 were 5+0i. 
> 
>  
>        Someone else can tell us why this is, but this should suffice 
> as 
>  an initial answer to your question. 
>  
>        Hope this helps. 
>        Spencer Graves
>  
>  Marco Visser wrote:
>  > Dear R users & Experts,
>  >
>  > This is just a curiousity, I was wondering why the dominant 
> eigenvetor and eigenvalue 
>  > of the following matrix is given as the third. I guess this could 
> complicate automatic selection 
>  > procedures. 
>  >
>  > 0    0    0    0    0    5
>  > 1    0    0    0    0    0
>  > 0    1    0    0    0    0
>  > 0    0    1    0    0    0
>  > 0    0    0    1    0    0
>  > 0    0    0    0    1    0
>  >
>  > Please copy & paste the following into R;
>  >
>  > a=c(0,0,0,0,0,5,1,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0)
>  > mat=matrix(a, ncol=6,byrow=T)
>  > eigen(mat)
>  >
>  > The matrix is a population matrix for a plant pathogen (Powell et 
> al 2005).
>  >
>  > Basically I would really like to know why this happens so I will 
> know if it can occur 
>  > again. 
>  >
>  > Thanks for any comments,
>  >
>  > Marco Visser
>  >
>  >
>  > Comment: In Matlab the the dominant eigenvetor and eigenvalue 
>  > of the described matrix are given as the sixth. Again no idea why.
>  >
>  > reference
>  >
>  > J. A. Powell, I. Slapnicar and W. van der Werf. Epidemic spread of 
> a lesion-forming 
>  > plant pathogen - analysis of a mechanistic model with infinite age 
> structure. (2005) 
>  > Linear Algebra and its Applications 298. p 117-140.  
>  >
>  >
>  >
>  >
>  >        
>  > 
> ____________________________________________________________________________________Ready 
> for the edge of your seat? 
>  > Check out tonight's top picks on Yahoo! TV. 
>  >
>  > 	[[alternative HTML version deleted]]
>  >
>  > ______________________________________________
>  > R-help at stat.math.ethz.ch mailing list
>  > 
>  > PLEASE do read the posting guide 
>  > and provide commented, minimal, self-contained, reproducible code.
>  >
>  
>  ______________________________________________
>  R-help at stat.math.ethz.ch mailing list
>  
>  PLEASE do read the posting guide 
>  and provide commented, minimal, self-contained, reproducible code.


From mothsailor at googlemail.com  Sat Jun 30 19:15:50 2007
From: mothsailor at googlemail.com (David Barron)
Date: Sat, 30 Jun 2007 18:15:50 +0100
Subject: [R] Standard Probability Distributions.
In-Reply-To: <c0792190706300741j458ed50dm2432b655ffbac794@mail.gmail.com>
References: <c0792190706300741j458ed50dm2432b655ffbac794@mail.gmail.com>
Message-ID: <815b70590706301015l474ae912je59cd220a7594d02@mail.gmail.com>

Have a look in the stats package for the distributions that come with
base R.  There is a package called SuppDists that has some others, and
no doubt there are others.  Try RSiteSearch to look for specific
distributions.

On 30/06/07, Marcus Vinicius <mvinic at gmail.com> wrote:
> Dear all,
> What are the standard probability distributions available in R?
> I need some as Normal-Truncated, Half-Normal, Gamma, Chi-squared, Wishard,
> etc.
> Thanks.
> Marcus Vinicius
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
=================================
David Barron
Said Business School
University of Oxford
Park End Street
Oxford OX1 1HP


From christophe at pallier.org  Sat Jun 30 20:30:51 2007
From: christophe at pallier.org (Christophe Pallier)
Date: Sat, 30 Jun 2007 20:30:51 +0200
Subject: [R] import data
In-Reply-To: <867302.28409.qm@web26615.mail.ukl.yahoo.com>
References: <867302.28409.qm@web26615.mail.ukl.yahoo.com>
Message-ID: <dea6cb960706301130x49ef1970n663cadadb7fcaeeb@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070630/5b636180/attachment.pl 

From christophe at pallier.org  Sat Jun 30 20:34:25 2007
From: christophe at pallier.org (Christophe Pallier)
Date: Sat, 30 Jun 2007 20:34:25 +0200
Subject: [R] import data
In-Reply-To: <dea6cb960706301130x49ef1970n663cadadb7fcaeeb@mail.gmail.com>
References: <867302.28409.qm@web26615.mail.ukl.yahoo.com>
	<dea6cb960706301130x49ef1970n663cadadb7fcaeeb@mail.gmail.com>
Message-ID: <dea6cb960706301134h5265af35g8376b9167c050226@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070630/bcf9fd88/attachment.pl 

From roland.rproject at gmail.com  Sat Jun 30 20:38:49 2007
From: roland.rproject at gmail.com (Roland Rau)
Date: Sat, 30 Jun 2007 14:38:49 -0400
Subject: [R] import data
In-Reply-To: <867302.28409.qm@web26615.mail.ukl.yahoo.com>
References: <867302.28409.qm@web26615.mail.ukl.yahoo.com>
Message-ID: <4686A339.9080601@gmail.com>

Hi Eric,

eric zoukekang wrote:
> Hello!
> I wonder if you might help me with informations about how to import data with a 2.4.1 R version without the menu "Import data".
> Best regards.

the best information about importing data in R is contained in the 
manual "R Data Import/Export" which should be part of your distribution 
of R. I don't know if there were substantial changes between 2.4.1 and 
the current version of R (-> 2.5.1), but the most up-to-date manual can 
be found here in html:
http://cran.r-project.org/doc/manuals/R-data.html
or here in pdf-format:
http://cran.r-project.org/doc/manuals/R-data.pdf

I hope this helps?

Best,
Roland


From ross at biostat.ucsf.edu  Sat Jun 30 21:12:45 2007
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Sat, 30 Jun 2007 12:12:45 -0700
Subject: [R] random numbers
Message-ID: <1183230765.10152.22.camel@corn.betterworld.us>

Although this query was inspired by distributed random number
generation, one of the questions (#2 below) is a single-machine issue.

I call C++ code from R to generate simulated data.  I'm doing this on a
cluster, and use rmpi and rsprng.  While rsprng randomizes R-level
random numbers (e.g., from runif), it has no effect on the C code, which
is completely SPRNG and MPI ignorant.

Currently I generate a seed to pass into the C code, using
as.integer(runif(1, max=.Machine$integer.max)-.Machine$integer.max/2)
It seems to work.

Any comments on this approach?  Here are some issues I see:

1) The much simpler method of using the consecutive integers as seeds
also seemed to work.  This also has the advantage of repeatability.  I
avoided it because I was concerned it wouldn't be random enough.  Would
consecutive integers as in
  parLapply(cluster, seq(nSimulations), function(i) myfunction(seed=i))
be sufficient?

I suppose I could also generate all the random seeds on the master.

2) This got me thinking about how to generate random integers that span
the whole range of 32 bit signed integers.  The method show above only
spans half the range, since .Machine$integer.max = 2^31.  It also makes
some assumptions about the relation between the value in  .Machine
$integer.max and the seed for random numbers.  Interestingly,
integer.max was 2^31 despite running on a 64 bit powerpc, albeit under
the mostly 32 bit OS-X (I think Leopard--not the current one; Darwin
Kernel 7.9.0).

My understanding is that random number generators internally produce 32
bit integers, which then get converted into the desired distribution.
I'm a little surprised there doesn't seem to be a way to get at them.
Or is one supposed to do runif()*2^32-2^31?

3) Vagaries of the underlying C++ random number generator could also
complicate life.


From roland.rproject at gmail.com  Sat Jun 30 21:31:00 2007
From: roland.rproject at gmail.com (Roland Rau)
Date: Sat, 30 Jun 2007 15:31:00 -0400
Subject: [R] Programming Contests for R?
Message-ID: <4686AF74.4080902@gmail.com>

Dear all,

I just saw for the first time the 'Matlab Programming Contest' at 
http://www.mathworks.com/contest/overview.html

Is there something comparable for R? Is someone interested in organizing 
such a thing?

Of course, one can try to solve the Matlab Problems Sets in R, but I 
think it could be fun to have something like this also for R.

Thanks and have a nice weekend everyone,
Roland

P.S. I have the impression that the R-Help ML is some kind of 
programming contest, when people try to contribute more efficient, 
elegant, smaller, faster, ... solutions to a question than someone 
before. :-D


From edd at debian.org  Sat Jun 30 21:48:38 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 30 Jun 2007 14:48:38 -0500
Subject: [R] Programming Contests for R?
In-Reply-To: <4686AF74.4080902@gmail.com>
References: <4686AF74.4080902@gmail.com>
Message-ID: <18054.45974.195155.593835@basebud.nulle.part>


On 30 June 2007 at 15:31, Roland Rau wrote:
| I just saw for the first time the 'Matlab Programming Contest' at 
| http://www.mathworks.com/contest/overview.html
| 
| Is there something comparable for R? Is someone interested in organizing 
| such a thing?

Well, AFAIK there will be some sort of 'R Programming Contest' at UseR in
Ames in August -- see http://www.useR2007.org

Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From edd at debian.org  Sat Jun 30 21:50:24 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 30 Jun 2007 14:50:24 -0500
Subject: [R] random numbers
In-Reply-To: <1183230765.10152.22.camel@corn.betterworld.us>
References: <1183230765.10152.22.camel@corn.betterworld.us>
Message-ID: <18054.46080.604686.469429@basebud.nulle.part>


On 30 June 2007 at 12:12, Ross Boylan wrote:
| I call C++ code from R to generate simulated data.  I'm doing this on a
| cluster, and use rmpi and rsprng.  While rsprng randomizes R-level
| random numbers (e.g., from runif), it has no effect on the C code, which
| is completely SPRNG and MPI ignorant.
| 
| Currently I generate a seed to pass into the C code, using
| as.integer(runif(1, max=.Machine$integer.max)-.Machine$integer.max/2)
| It seems to work.
| 
| Any comments on this approach?  Here are some issues I see:

I may be missing something but given that rsprng is running on your cluster,
you are bound to also have sprng itself -- so why don't you use that from C
or C++  for this purpose?

Hth, Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From ross at biostat.ucsf.edu  Sat Jun 30 22:09:39 2007
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Sat, 30 Jun 2007 13:09:39 -0700
Subject: [R] random numbers
In-Reply-To: <18054.46080.604686.469429@basebud.nulle.part>
References: <1183230765.10152.22.camel@corn.betterworld.us>
	<18054.46080.604686.469429@basebud.nulle.part>
Message-ID: <1183234179.10152.39.camel@corn.betterworld.us>

On Sat, 2007-06-30 at 14:50 -0500, Dirk Eddelbuettel wrote:
> On 30 June 2007 at 12:12, Ross Boylan wrote:
> | I call C++ code from R to generate simulated data.  I'm doing this on a
> | cluster, and use rmpi and rsprng.  While rsprng randomizes R-level
> | random numbers (e.g., from runif), it has no effect on the C code, which
> | is completely SPRNG and MPI ignorant.
> | 
> | Currently I generate a seed to pass into the C code, using
> | as.integer(runif(1, max=.Machine$integer.max)-.Machine$integer.max/2)
> | It seems to work.
> | 
> | Any comments on this approach?  Here are some issues I see:
> 
> I may be missing something but given that rsprng is running on your cluster,
> you are bound to also have sprng itself -- so why don't you use that from C
> or C++  for this purpose?
> 
> Hth, Dirk
Doing so would add considerable complexity, at least as far as I know.

Sometimes I run within an MPI session and sometimes not.  My
understanding is that SPRNG will not work if MPI is absent.  I think
someone on the SPRNG list told me that there wasn't a good way to handle
this at run-time.  Unfortunately, a lot of SPRNG options seem to be
compile-time settings.

Using SPRNG would also complicate my build process, as I'd need autoconf
magic to support it.

Part of the issue is that I want something I can redistribute, not just
something that will work for me on a  one-off basis.

One simple solution would be to build several versions of the library.
A not so simple solution would be to build various random number
generators as separate libraries, and dynamically load the appropriate
one.


From fredrik.bg.lundgren at bredband.net  Sat Jun 30 22:27:54 2007
From: fredrik.bg.lundgren at bredband.net (Fredrik Lundgren)
Date: Sat, 30 Jun 2007 22:27:54 +0200
Subject: [R] "R CMD INSTALL in R 2.5.1 (2007-06-27)"
Message-ID: <000a01c7bb55$250cab30$b4eae455@Larissa>

Hello,

I'm moving from R 2.2.1 (Winows XP) to R 2.5.1 and have problems with 
installing "myfuncs", which worked OK in 2.2.1

R CMD INSTALL myfuns
# gives
installing to ''


---------- Making package myfuncs ------------
  adding build stamp to DESCRIPTION
  installing R files
  installing man source files
  installing indices
  installing help
 >>> Building/Updating help pages for package 'myfuncs'
     Formats: text html latex example chm
  Bland.plot                        text    html    latex   example
  Cook.plot                         text    html    latex   example
  added.var.plot                    text    html    latex   example
  jit.plot                          text    html    latex   example
  waldtest                          text    html    latex   example
  preparing package myfuncs for lazy loading
Warning in list.files(lib, pattern = paste("^", pkg_regexp, sep = ""), 
full = TR
UE) :
         list.files: '' is not a readable directory
Error in findpack(package, lib.loc) : there is no package called 
'myfuncs'
Execution halted
make: *** [lazyload] Error 1
*** Installation of myfuncs failed ***

Removing '/myfuncs'
# end

"installing to '' " at the start appears to be the problem

I have install Rtools 2.5.1 appropriately ( I hope)
my PATH looks like this:

PATH=C:\Program\Rtools\MinGW\bin;C:\Program\R\Rtools\bin;c:\program\imagemagick-
6.1.8-q16;C:\Program\TeXLive\bin\win32;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS
\system32\WBEM;C:\Program\Aspell\bin;C:\Program\Perl\bin\;C:\Program\HTML 
Help W
orkshop;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program\ATI 
T
echnologies\ATI Control 
Panel;C:\Program\R\R-2.5.1\bin;C:\Program\sp2000\cmd;C:\
Program\XEmacs\XEmacs-21.4.13\i586-pc-win32;C:\Program\gnuplot\bin;C:\Program\Ma
yura;C:\Program files\WinEdt Team\WinEdt;C:\Program\Internet 
Explorer;;C:\Progra
m\WinBUGS;C:\Program\Adobe\Acrobat 
7.0\Reader;C:\Program\QuickTime\QTSystem\

To me looks as if R don't know where to install - any help available?

Sincerely Fredrik Lundgren


From ligges at statistik.uni-dortmund.de  Sat Jun 30 23:03:35 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 30 Jun 2007 23:03:35 +0200
Subject: [R] "R CMD INSTALL in R 2.5.1 (2007-06-27)"
In-Reply-To: <000a01c7bb55$250cab30$b4eae455@Larissa>
References: <000a01c7bb55$250cab30$b4eae455@Larissa>
Message-ID: <4686C527.8000002@statistik.uni-dortmund.de>



Fredrik Lundgren wrote:
> Hello,
> 
> I'm moving from R 2.2.1 (Winows XP) to R 2.5.1 and have problems with 
> installing "myfuncs", which worked OK in 2.2.1
> 
> R CMD INSTALL myfuns
> # gives
> installing to ''

Have you set an environment variable such as R_LIBS that is "" rather 
than a sensible directory? (my guess)

Are all the tools up to date?
Do you have another library (except the standard one) defined anywhere?
Can you source() all the R files in your package separately in R-2.5.1?

Uwe Ligges



> 
> 
> ---------- Making package myfuncs ------------
>   adding build stamp to DESCRIPTION
>   installing R files
>   installing man source files
>   installing indices
>   installing help
>  >>> Building/Updating help pages for package 'myfuncs'
>      Formats: text html latex example chm
>   Bland.plot                        text    html    latex   example
>   Cook.plot                         text    html    latex   example
>   added.var.plot                    text    html    latex   example
>   jit.plot                          text    html    latex   example
>   waldtest                          text    html    latex   example
>   preparing package myfuncs for lazy loading
> Warning in list.files(lib, pattern = paste("^", pkg_regexp, sep = ""), 
> full = TR
> UE) :
>          list.files: '' is not a readable directory
> Error in findpack(package, lib.loc) : there is no package called 
> 'myfuncs'
> Execution halted
> make: *** [lazyload] Error 1
> *** Installation of myfuncs failed ***
> 
> Removing '/myfuncs'
> # end
> 
> "installing to '' " at the start appears to be the problem
> 
> I have install Rtools 2.5.1 appropriately ( I hope)
> my PATH looks like this:
> 
> PATH=C:\Program\Rtools\MinGW\bin;C:\Program\R\Rtools\bin;c:\program\imagemagick-
> 6.1.8-q16;C:\Program\TeXLive\bin\win32;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS
> \system32\WBEM;C:\Program\Aspell\bin;C:\Program\Perl\bin\;C:\Program\HTML 
> Help W
> orkshop;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program\ATI 
> T
> echnologies\ATI Control 
> Panel;C:\Program\R\R-2.5.1\bin;C:\Program\sp2000\cmd;C:\
> Program\XEmacs\XEmacs-21.4.13\i586-pc-win32;C:\Program\gnuplot\bin;C:\Program\Ma
> yura;C:\Program files\WinEdt Team\WinEdt;C:\Program\Internet 
> Explorer;;C:\Progra
> m\WinBUGS;C:\Program\Adobe\Acrobat 
> 7.0\Reader;C:\Program\QuickTime\QTSystem\
> 
> To me looks as if R don't know where to install - any help available?
> 
> Sincerely Fredrik Lundgren
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From fredrik.bg.lundgren at bredband.net  Sat Jun 30 23:33:22 2007
From: fredrik.bg.lundgren at bredband.net (Fredrik Lundgren)
Date: Sat, 30 Jun 2007 23:33:22 +0200
Subject: [R] "R CMD INSTALL in R 2.5.1 (2007-06-27)"
References: <000a01c7bb55$250cab30$b4eae455@Larissa>
	<4686C527.8000002@statistik.uni-dortmund.de>
Message-ID: <000701c7bb5e$4956be50$b4eae455@Larissa>

Sorry,
my fault!
I had
# install myfuncs

library(myfuncs)

in the RProfile.site

before I had myfuncs installed

# library(myfuncs)

fixed everything. I could now R CMD INSTALL as before - no problems

Thanks for your help

Fredrik









----- Original Message ----- 
From: "Uwe Ligges" <ligges at statistik.uni-dortmund.de>
To: "Fredrik Lundgren" <fredrik.bg.lundgren at bredband.net>
Cc: "R-help" <r-help at stat.math.ethz.ch>
Sent: Saturday, June 30, 2007 11:03 PM
Subject: Re: [R] "R CMD INSTALL in R 2.5.1 (2007-06-27)"


>
>
> Fredrik Lundgren wrote:
>> Hello,
>>
>> I'm moving from R 2.2.1 (Winows XP) to R 2.5.1 and have problems with 
>> installing "myfuncs", which worked OK in 2.2.1
>>
>> R CMD INSTALL myfuns
>> # gives
>> installing to ''
>
> Have you set an environment variable such as R_LIBS that is "" rather 
> than a sensible directory? (my guess)
>
> Are all the tools up to date?
> Do you have another library (except the standard one) defined 
> anywhere?
> Can you source() all the R files in your package separately in 
> R-2.5.1?
>
> Uwe Ligges
>
>
>
>>
>>
>> ---------- Making package myfuncs ------------
>>   adding build stamp to DESCRIPTION
>>   installing R files
>>   installing man source files
>>   installing indices
>>   installing help
>>  >>> Building/Updating help pages for package 'myfuncs'
>>      Formats: text html latex example chm
>>   Bland.plot                        text    html    latex   example
>>   Cook.plot                         text    html    latex   example
>>   added.var.plot                    text    html    latex   example
>>   jit.plot                          text    html    latex   example
>>   waldtest                          text    html    latex   example
>>   preparing package myfuncs for lazy loading
>> Warning in list.files(lib, pattern = paste("^", pkg_regexp, sep = 
>> ""), full = TR
>> UE) :
>>          list.files: '' is not a readable directory
>> Error in findpack(package, lib.loc) : there is no package called 
>> 'myfuncs'
>> Execution halted
>> make: *** [lazyload] Error 1
>> *** Installation of myfuncs failed ***
>>
>> Removing '/myfuncs'
>> # end
>>
>> "installing to '' " at the start appears to be the problem
>>
>> I have install Rtools 2.5.1 appropriately ( I hope)
>> my PATH looks like this:
>>
>> PATH=C:\Program\Rtools\MinGW\bin;C:\Program\R\Rtools\bin;c:\program\imagemagick-
>> 6.1.8-q16;C:\Program\TeXLive\bin\win32;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS
>> \system32\WBEM;C:\Program\Aspell\bin;C:\Program\Perl\bin\;C:\Program\HTML 
>> Help W
>> orkshop;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program\ATI 
>> T
>> echnologies\ATI Control 
>> Panel;C:\Program\R\R-2.5.1\bin;C:\Program\sp2000\cmd;C:\
>> Program\XEmacs\XEmacs-21.4.13\i586-pc-win32;C:\Program\gnuplot\bin;C:\Program\Ma
>> yura;C:\Program files\WinEdt Team\WinEdt;C:\Program\Internet 
>> Explorer;;C:\Progra
>> m\WinBUGS;C:\Program\Adobe\Acrobat 
>> 7.0\Reader;C:\Program\QuickTime\QTSystem\
>>
>> To me looks as if R don't know where to install - any help available?
>>
>> Sincerely Fredrik Lundgren
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


